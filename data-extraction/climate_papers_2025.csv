Title,Published,Authors,Abstract,Link
"EpiClim: Weekly District-Wise all-India multi-epidemics Climate-Health
  Dataset for accelerated GeoHealth research",2025-01-17T23:12:08Z,"Gurleen Kaur, Shubham Ghoshal, Manmeet Singh, Reena Marbate, Neetiraj Malviya, Arshmehar Kaur, Vaisakh SB","Climate change significantly impacts public health, driving the emergence and
spread of epidemics. Climate health models are essential for assessing and
predicting disease outbreaks influenced by climatic variables like temperature
and precipitation. For instance, dengue and malaria correlate with temperature
changes, while cholera is linked to precipitation anomalies. Advances in
AI-enabled weather prediction (AI-NWP) have improved forecasting, but
integrating climate models with health systems is hindered by the lack of
comprehensive, granular health datasets. This study introduces EpiClim: India's
Epidemic-Climate Dataset, the first weekly district-wise dataset for major
epidemics in India from 2009 to the present, sourced from the Integrated
Disease Surveillance Programme (IDSP). The dataset, covering diseases like
dengue, malaria, and acute-diarrheal disease, bridges the gap between climate
and health data, enabling the integration of climate forecasts with epidemic
prediction models. This work lays the foundation for coupling predictive
climate health models with weather and climate models, advancing efforts to
mitigate climate-induced public health crises.",http://arxiv.org/abs/2501.18602v1
Analysis of Climatic Trends and Variability in Indian Topography,2025-01-08T15:47:30Z,"Ayush Prusty, Akshita Gupta, Vivek Ashok Bohara","The climatic change is one of the serious concerns nowadays. The impacts of
climate change are global in scope and unprecedented in scale. Moreover, a
small perturbation in climatic changes affects not only the pristine ecosystem
but also the socioeconomic sectors. Specifically, the affect of climatic
changes is related to frequent casualties. This makes it essential to dwelve
deeper into analyzing the socio-climatic trends and variability. This work
provides a comprehensive analysis of India's climatic trends, emphasizing on
regional variations and specifically delving into the unique climate of Delhi.
Specifically, this research unveils the temporal and spatial variations in
temperature patterns by amalgamating extensive datasets encompassing India's
diverse landscapes. The study uses advanced statistical tools and methodologies
to scrutinize temperature's annual and seasonal variability. The insights drawn
from this rigorous analysis may offer invaluable contributions to regional
planning strategies, adaptive measures, and informed decision-making amidst the
complex impacts of climate change. By bridging the gap between broader climatic
trends and localized impacts, this research aims to facilitate more effective
measures to mitigate and adapt to the multifaceted challenges of climate
change, ensuring a more nuanced and tailored approaches. We utilized the
Mann-Kendall test and Theil-Sen's slope estimator to analyze the trends and
variability of the climatic conditions over the decades. The results
demonstrate that temperature variations have increased over 0.58oC on average
over the last decade. Moreover, over last decade the variability of Indian
states shows that Lakshadweep faced the highest change (0.87oC), highlighting
coastal vulnerability, while Tripura observed the least change of 0.07oC.",http://arxiv.org/abs/2501.04578v1
"Social dynamics can delay or prevent climate tipping points by speeding
  the adoption of climate change mitigation",2025-01-23T21:05:22Z,"Yazdan Babazadeh Maghsoodlo, Madhur Anand, Chris T. Bauch","Social behaviour models are increasingly integrated into climate change
studies, and the significance of climate tipping points for `runaway' climate
change is well recognised. However, there has been insufficient focus on
tipping points in social-climate dynamics. We developed a coupled
social-climate model consisting of an Earth system model and a social behaviour
model, both with tipping elements. The social model explores opinion formation
by analysing social learning rates, the net cost of mitigation, and the
strength of social norms. Our results indicate that the net cost of mitigation
and social norms have minimal impact on tipping points when social norms are
weak. As social norms strengthen, the climate tipping point can trigger a
tipping element in the social model. However, faster social learning can delay
or prevent the climate tipping point: sufficiently fast social learning means
growing climate change mitigation can outpace the oncoming climate tipping
point, despite social-climate feedback. By comparing high- and low-risk
scenarios, we demonstrated high-risk scenarios increase the likelihood of
tipping points. We also illustrate the role of a critical temperature anomaly
in triggering tipping points. In conclusion, understanding social behaviour
dynamics is vital for predicting climate tipping points and mitigating their
impacts.",http://arxiv.org/abs/2501.14096v1
"Enhancing LLMs for Governance with Human Oversight: Evaluating and
  Aligning LLMs on Expert Classification of Climate Misinformation for
  Detecting False or Misleading Claims about Climate Change",2025-01-23T16:21:15Z,"Mowafak Allaham, Ayse D. Lokmanoglu, Sol P. Hart, Erik C. Nisbet","Climate misinformation is a problem that has the potential to be
substantially aggravated by the development of Large Language Models (LLMs). In
this study we evaluate the potential for LLMs to be part of the solution for
mitigating online dis/misinformation rather than the problem. Employing a
public expert annotated dataset and a curated sample of social media content we
evaluate the performance of proprietary vs. open source LLMs on climate
misinformation classification task, comparing them to existing climate-focused
computer-assisted tools and expert assessments. Results show (1)
state-of-the-art (SOTA) open-source models substantially under-perform in
classifying climate misinformation compared to proprietary models, (2) existing
climate-focused computer-assisted tools leveraging expert-annotated datasets
continues to outperform many of proprietary models, including GPT-4o, and (3)
demonstrate the efficacy and generalizability of fine-tuning GPT-3.5-turbo on
expert annotated dataset in classifying claims about climate change at the
equivalency of climate change experts with over 20 years of experience in
climate communication. These findings highlight 1) the importance of
incorporating human-oversight, such as incorporating expert-annotated datasets
in training LLMs, for governance tasks that require subject-matter expertise
like classifying climate misinformation, and 2) the potential for LLMs in
facilitating civil society organizations to engage in various governance tasks
such as classifying false or misleading claims in domains beyond climate change
such as politics and health science.",http://arxiv.org/abs/2501.13802v1
"Changes over time in the 100-year return value of climate model
  variables",2025-01-20T18:29:12Z,"Callum Leach, Kevin Ewans, Philip Jonathan","We assess evidence for changes in tail characteristics of wind, solar
irradiance and temperature variables output from CMIP6 global climate models
(GCMs) due to climate forcing. We estimate global and climate zone annual
maximum and annual means for period (2015, 2100) from daily output of seven
GCMs for daily wind speed, maximum wind speed, solar irradiance and
near-surface temperature. We calculate corresponding annualised data for
individual locations within neighbourhoods of the North Atlantic and Celtic Sea
region. We consider output for three climate scenarios and multiple climate
ensembles. We estimate non-stationary extreme value models for annual extremes,
and non-homogeneous Gaussian regressions for annual means, using Bayesian
inference. We use estimated statistical models to quantify the distribution of
(i) the change in 100-year return value for annual extremes, and (2) the change
in annual mean, over the period (2025, 2125). To summarise results, we estimate
linear mixed effects models for observed variation of (i) and (ii). Evidence
for changes in the 100-year return value for annual maxima of solar irradiance
and temperature is much stronger than for wind variables over time and with
climate scenario.",http://arxiv.org/abs/2501.11650v2
"Incivility and Contentiousness Spillover between COVID-19 and Climate
  Science Engagement",2025-02-07T18:08:50Z,"Hasti Narimanzadeh, Arash Badie-Modiri, Iuliia Smirnova, Ted Hsuan Yun Chen","Affective polarization and its accompanying cleavage-based sorting drives
incivility and contentiousness around climate change and other science-related
issues. Looking at the COVID-19 period, we study cross-domain spillover of
incivility and contentiousness in public engagements with climate change and
climate science on Twitter and Reddit. We find strong evidence of the
signatures of affective polarization surrounding COVID-19 spilling into the
climate change domain. Across different social media systems, COVID-19 content
is associated with incivility and contentiousness in climate discussions. These
patterns of increased antagonism were responsive to pandemic events that made
the link between science and public policy more salient. We also show that the
observed spillover activated along pre-pandemic political cleavages,
specifically anti-internationalist populist beliefs, that linked climate policy
opposition to vaccine hesitancy. Our findings highlight the dangers of
entrenched cross-domain polarization manifesting as spillover of antagonistic
behavior.",http://arxiv.org/abs/2502.05255v1
"An Important Decision for Climate Change: Sequestering Carbon in
  Materials or Underground?",2025-01-03T19:40:55Z,Peter Eisenberger,"A first-order analysis concludes it is feasible to store the carbon needed to
meet the Paris targets in structural materials and use less energy and at a
lower cost than our use of extractive materials, steel, aluminum, and concrete.
Switching to a synthetic material industry using CO2 from the air will
stimulate economic growth and create increased equity while addressing the
threat of climate change. The positive feedback between them will accelerate
reaching a global accord to address the dual threats of climate change and
equity and may, in fact, be needed to avoid the catastrophic consequences of
failing to meet them on time.",http://arxiv.org/abs/2501.02075v1
Intraseasonal atmospheric variability under climate trends,2025-02-03T11:51:23Z,"Bernardo Maraldi, Henk Dijkstra, Michael Ghil","Low-order climate models can play an important role in understanding
low-frequency variability in the atmospheric circulation and how forcing
consistent with anthropogenic climate change may affect this variability. Here,
we study a conceptual model of the mid-latitudes' atmospheric circulation from
the perspective of nonautonomous dynamical systems. First, a bifurcation
analysis is carried out under time-independent forcing in order to identify
different types of behavior in the autonomous model's parameter space. Next, we
focus on the study of the nonautonomous system in which the cross-latitudinal
heat flux varies seasonally, according to insolation changes. The forward
attractor of the seasonally forced model is compared with the attractor of the
autonomous one. The seasonal forcing results in a clear change of the
attractor's shape. The summer attractor loses its periodicity, and hence
predictability, when the forcing is seasonal, while the winter attractor favors
energy transport through one of the model's two wave components. Climate change
forcing produces several remarkable effects. Thus, the analysis of the model's
snapshot attractor under climate trends suggests that the jet speed does not
always follow the sign of the change in equator-to-pole thermal contrast, while
the change in the energy transported by the eddies does. Chaotic behavior can
be completely suppressed in favor of a regular periodic one and vice-versa.
Circulation patterns can change, suddenly disappear, and rebuild. The model's
snapshot attractor proves to be a robust tool to study its changes in internal
variability due to climate trends, both positive and negative.",http://arxiv.org/abs/2502.01279v1
"Chinese Historical Documents Reveal Multi-Century Seasonal Shifts in
  Tropical Cyclone Landfalls",2025-02-01T02:24:08Z,"Gan Zhang, Kuanhui Elaine Lin, Dan Fu, Tom Knutson, Jörg Franke, Wan-Ling Tseng","Paleoclimate records reveal a fuller range of natural climate variability
than modern records and are essential for better understanding the modern
climate change. However, most paleoclimate records are point-based proxies and
lack the temporal resolution needed to analyze spatiotemporal changes in
destructive extremes like tropical cyclones (TCs). Here we show that historical
records by pre-industrial Chinese intellectuals help investigate long-term
variability of TC landfalls in East Asia. Despite inherent limitations, these
records show a landfalling TC climatology resembling modern observations in
spatial-temporal distributions. Comparisons between the pre-industrial records
(1776-1850), modern observations (1946-2020), and climate simulations reveal an
earlier seasonal occurrence of modern TCs. However, the variations of
seasonally aggregated landfall time show pronounced multi-century variations.
The modern changes and multi-decade trends appear moderate compared to
long-term variability in pre-industrial TC records, suggesting that an
overreliance on modern data may lead to an underestimation of the full range of
TC activity potentially arising from natural variability alone. Analyses of
newly available climate data reveal associations between past landfalling TC
activity and the large-scale climate variability of tropical ocean and
extratropical land. These findings demonstrate the value of paleoclimate data
for exploring natural variability in TC activity and inform the development of
effective adaptation strategies for future climate change.",http://arxiv.org/abs/2502.00276v1
"Removing Atmospheric Carbon Dioxide Using Large Land Or Ocean Areas Will
  Change Earth Albedo And Force Climate",2025-01-03T16:33:22Z,"J. B. Marston, Daniel E. Ibarra","When large surface areas of the Earth are altered, radiative forcing due to
changes in surface reflectance can drive climate change. Yet to achieve the
necessary scale to remove the substantial amounts of carbon dioxide from the
atmosphere relevant for ameliorating climate change, enhanced rock weathering
(ERW) will need to be applied to very large land areas. Likewise, marine carbon
dioxide removal (mCDR) must alter a large fraction of the ocean surface waters
to have a significant impact upon climate. We show that surface albedo
modification (SAM) associated with ERW or mCDR can easily overwhelm the
radiative forcing from the decrease of atmospheric CO2 over years or even
decades. A change in albedo as small as parts per thousand has a radiative
impact comparable to the removal of 10 tons of carbon per hectare. SAM via ERW
can be either cooling or warming. We identify some of the many questions raised
by radiative forcing due to these forms of CDR.",http://arxiv.org/abs/2501.01885v2
Opportunities and challenges of quantum computing for climate modelling,2025-02-14T12:25:06Z,"Mierk Schwabe, Lorenzo Pastori, Inés de Vega, Pierre Gentine, Luigi Iapichino, Valtteri Lahtinen, Martin Leib, Jeanette M. Lorenz, Veronika Eyring","Adaptation to climate change requires robust climate projections, yet the
uncertainty in these projections performed by ensembles of Earth system models
(ESMs) remains large. This is mainly due to uncertainties in the representation
of subgrid-scale processes such as turbulence or convection that are partly
alleviated at higher resolution. New developments in machine learning-based
hybrid ESMs demonstrate great potential for systematically reduced errors
compared to traditional ESMs. Building on the work of hybrid (physics + AI)
ESMs, we here discuss the additional potential of further improving and
accelerating climate models with quantum computing. We discuss how quantum
computers could accelerate climate models by solving the underlying
differential equations faster, how quantum machine learning could better
represent subgrid-scale phenomena in ESMs even with currently available noisy
intermediate-scale quantum devices, how quantum algorithms aimed at solving
optimisation problems could assist in tuning the many parameters in ESMs, a
currently time-consuming and challenging process, and how quantum computers
could aid in the analysis of climate models. We also discuss hurdles and
obstacles facing current quantum computing paradigms. Strong interdisciplinary
collaboration between climate scientists and quantum computing experts could
help overcome these hurdles and harness the potential of quantum computing for
this urgent topic.",http://arxiv.org/abs/2502.10488v1
"Network science disentangles internal climate variability in global
  spatial dependence structures",2025-01-24T21:51:31Z,"Arnob Ray, Abhirup Banerjee, Rachindra Mawalagedara, Auroop R. Ganguly","A comprehensive characterization of internal climate variability and
irreducible uncertainty through initial-condition large ensembles of Earth
system models across different spatiotemporal scales remains a significant
challenge in climate science. In this study, we find significant differences in
the spatial connectivity structures of temperature networks across ensemble
members, with variations in long-range connections providing a distinguishing
feature across the outcomes of initial conditions. Based on this, we introduce
a novel quantifier, the 'Connectivity Ratio' (R), to encapsulate the spatial
connectivity structure of each ensemble member by investigating the influence
of internal climate variability on the global connectivity patterns in air
temperatures. R allows us to characterize the variability of spatial dependence
structure across the initial condition ensemble members as well as multiple
models. Furthermore, we examine changes in spatial connectivity between
near-term and long-term projections using R, which shows a potential shift in
climate predictability under anthropogenic influence on a spatial scale.",http://arxiv.org/abs/2501.14937v1
"Integrating Spatiotemporal Vision Transformer into Digital Twins for
  High-Resolution Heat Stress Forecasting in Campus Environments",2025-02-12T05:27:16Z,"Wenjing Gong, Xinyue Ye, Keshu Wu, Suphanut Jamonnak, Wenyu Zhang, Yifan Yang, Xiao Huang","Extreme heat events exacerbated by climate change pose significant challenges
to urban resilience and planning. This study introduces a climate-responsive
digital twin framework integrating the Spatiotemporal Vision Transformer
(ST-ViT) model to enhance heat stress forecasting and decision-making. Using a
Texas campus as a testbed, we synthesized high-resolution physical model
simulations with spatial and meteorological data to develop fine-scale human
thermal predictions. The ST-ViT-powered digital twin enables efficient,
data-driven insights for planners, policymakers, and campus stakeholders,
supporting targeted heat mitigation strategies and advancing climate-adaptive
urban design.",http://arxiv.org/abs/2502.09657v1
"Redefining Influenza Transmission Seasonality Using the Novel
  Seasonality Index",2025-01-23T16:42:36Z,"Branislava Lalic, Vladimir Koci, Ana Firanj Sremac, Zorana Jovanovic Andersen","The impact of climate conditions on influenza epidemiology has mostly been
studied by addressing a singular aspect of transmission and a climate variable
correlating to it. As climate change unfolds at an unprecedented rate, we
urgently need new multidisciplinary approaches that can embrace complexity of
disease transmission in the fast-changing environment and help us better
understand the implications for health. In this study, we have implemented a
novel seasonality index to capture a vast network of climate, infectious, and
socio-behavioural mechanisms influencing a seasonal influenza epidemic. We
hypothesize that intricate, region-specific behavioural patterns are cross
regulating the influenza spreading and dynamics of epidemics with changes in
meteorological conditions within a specific season. To better understand the
phenomena, we analysed weekly surveillance data from temperate European
countries and redefined seasonal transitions using the seasonality index. This
approach allowed us to characterize influenza seasonality more accurately in
relation to specific atmospheric conditions. Key findings include: i) a strong
correlation between influenza infection rates and the seasonality index across
different climate zones and social groups, and ii) a high linear correlation
between winter duration, determined by the seasonality index, and the time
scale of low-frequency peaks in the infection rates power spectral density.",http://arxiv.org/abs/2501.13821v1
"Solar radiation and atmospheric CO$_2$ predict young leaf production in
  a moist evergreen tropical forest: Insights from 23 years",2025-01-13T16:49:43Z,"Laura Lüthy, Colin A. Chapman, Patrick Lauer, Patrick Omeja, Urs Kalbitzer","Climate change impacts ecosystems worldwide, affecting animal behaviour and
survival both directly and indirectly through changes such as the availability
of food. For animals reliant on leaves as a primary food source, understanding
how climate change influences leaf production of trees is crucial, yet this is
understudied, especially in moist evergreen tropical forests. We analyzed a
23-year dataset of young leaf phenology from a moist tropical forest in Kibale
National Park, Uganda, to examine seasonal and long-term patterns of 12 key
tree species consumed by folivorous primates. We described phenological
patterns and explored relationships between young leaf production of different
tree species and climate variables. We also assessed the suitability of the
Enhanced Vegetation Index (EVI) as a proxy for young leaf production in moist
evergreen tropical forests. Our results showed that tree species exhibited
distinct phenological patterns, with most species producing young leaves during
two seasonal peaks aligned with the rainy seasons. Rainfall, cloud cover, and
maximum temperature were the most informative predictors of seasonal variation
in young leaf production. However, solar radiation and atmospheric CO$_2$ were
most informative regarding long-term trends. EVI was strongly correlated with
young leaf production within years but less effective for capturing
inter-annual trends. These findings highlight the complex relationship between
climate and young leaf phenology in moist evergreen tropical forests, and helps
us understand the changes in food availability for tropical folivores.",http://arxiv.org/abs/2501.07620v1
"The Norwegian-Polish CCS Network: A Case Study in Bilateral
  Collaboration for European Climate Action",2025-01-09T19:25:06Z,"Mohammad Nooraiepour, Pawel Gladysz, Eirik Melaaen","In the face of escalating climate change, achieving significant reductions in
greenhouse gas emissions from hard-to-abate industrial sectors is imperative.
Carbon Capture and Storage (CCS) represents an essential technological
advancement to achieve sustainable decarbonization. This manuscript reports on
the bilateral CCS network between Norway and Poland, designed and implemented
to leverage their capabilities to expedite technology deployment via mutual
cooperation and accelerate CCS initiatives targeted to member states'
challenges across Europe, aiming for a meaningful contribution to climate
goals. Norway is renowned for its operational acumen, as demonstrated by
landmark projects like Sleipner and Snohvit, and its forward-looking
initiatives, such as the open-source cross-border Northern Lights project,
which offer advanced infrastructure and expertise. Conversely, Poland,
characterized by its coal-dependent economy and the challenge of decarbonizing
extensive industrial emissions, presents a significant geological CO2 storage
potential, estimated at over 15.5 gigatonnes. This study delves into the
potential synergies derived from collaborative endeavors in academic education,
research and development, industrial implementation, regulatory coherence, and
public engagement. By underscoring the reciprocal benefits of such partnership,
the study underscores the indispensable role of bilateral cooperation in
harnessing CCS's capabilities to meet the EU's ambitious climate objectives,
paving the way toward a sustainable and low-carbon future. Additionally, it
outlines a scalable model for fostering and supporting broader bilateral and
multi-lateral collaborations, emphasizing the pivotal role of interconnected
networks in shaping effective global climate action strategies.",http://arxiv.org/abs/2501.05539v3
"Refined climatologies of future precipitation over High Mountain Asia
  using probabilistic ensemble learning",2025-01-26T22:35:24Z,"Kenza Tazi, Sun Woo P. Kim, Marc Girona-Mata, Richard E. Turner","High Mountain Asia holds the largest concentration of frozen water outside
the polar regions, serving as a crucial water source for more than 1.9 billion
people. In the face of climate change, precipitation represents the largest
source of uncertainty for hydrological modelling in this area. Future
precipitation predictions remain challenging due to complex orography, lack of
in situ hydrological observations, and limitations in climate model resolution
and parametrisation for this region. To address the uncertainty posed by these
challenges, climate models are often aggregated into multi-model ensembles.
While multi-model ensembles are known to improve the predictive accuracy and
analysis of future climate projections, consensus regarding how models are
aggregated is lacking. In this study, we propose a probabilistic machine
learning framework to systematically combine 13 regional climate models from
the Coordinated Regional Downscaling Experiment (CORDEX) over High Mountain
Asia. Our approach accounts for seasonal and spatial biases within the models,
enabling the prediction of more faithful precipitation distributions. The
framework is validated against gridded historical precipitation data and is
used to generate projections for the near-future (2036-2065) and far-future
(2066-2095) under RCP4.5 and RCP8.5 scenarios.",http://arxiv.org/abs/2501.15690v1
"Social and Genetic Ties Drive Skewed Cross-Border Media Coverage of
  Disasters",2025-01-13T11:24:52Z,"Thiemo Fetzer, Prashant Garg","Climate change is increasing the frequency and severity of natural disasters
worldwide. Media coverage of these events may be vital to generate empathy and
mobilize global populations to address the common threat posed by climate
change. Using a dataset of 466 news sources from 123 countries, covering 135
million news articles since 2016, we apply an event study framework to measure
cross-border media activity following natural disasters. Our results shows that
while media attention rises after disasters, it is heavily skewed towards
certain events, notably earthquakes, accidents, and wildfires. In contrast,
climatologically salient events such as floods, droughts, or extreme
temperatures receive less coverage. This cross-border disaster reporting is
strongly related to the number of deaths associated with the event, especially
when the affected populations share strong social ties or genetic similarities
with those in the reporting country. Achieving more balanced media coverage
across different types of natural disasters may be essential to counteract
skewed perceptions. Further, fostering closer social connections between
countries may enhance empathy and mobilize the resources necessary to confront
the global threat of climate change.",http://arxiv.org/abs/2501.07615v1
The Role of Science in the Climate Change Discussions on Reddit,2025-02-07T15:56:21Z,"Paolo Cornale, Michele Tizzani, Fabio Ciulla, Kyriaki Kalimeri, Elisa Omodei, Daniela Paolotti, Yelena Mejova","Collective and individual action necessary to address climate change hinges
on the public's understanding of the relevant scientific findings. In this
study, we examine the use of scientific sources in the course of 14 years of
public deliberation around climate change on one of the largest social media
platforms, Reddit. We find that only 4.0% of the links in the Reddit posts, and
6.5% in the comments, point to domains of scientific sources, although these
rates have been increasing in the past decades. These links are dwarfed,
however, by the citations of mass media, newspapers, and social media, the
latter of which peaked especially during 2019-2020. Further, scientific sources
are more likely to be posted by users who also post links to sources having
central-left political leaning, and less so by those posting more polarized
sources. Unfortunately, scientific sources are not often used in response to
links to unreliable sources.",http://arxiv.org/abs/2502.05026v1
Nuclear Explosions for Large Scale Carbon Sequestration,2025-01-11T19:18:00Z,Andrew Haverly,"Confronting the escalating threat of climate change requires innovative and
large-scale interventions. This paper presents a bold proposal to employ a
buried nuclear explosion in a remote basaltic seabed for pulverizing basalt,
thereby accelerating carbon sequestration through Enhanced Rock Weathering
(ERW). By precisely locating the explosion beneath the seabed, we aim to
confine debris, radiation, and energy while ensuring rapid rock weathering at a
scale substantial enough to make a meaningful dent in atmospheric carbon
levels. Our analysis outlines the parameters essential for efficient carbon
capture and minimal collateral effects, emphasizing that a yield on the order
of gigatons is critical for global climate impact. Although this approach may
appear radical, we illustrate its feasibility by examining safety factors,
preservation of local ecosystems, political considerations, and financial
viability. This work argues for reimagining nuclear technology not merely as a
destructive force but as a potential catalyst for decarbonization, thereby
inviting further exploration of pioneering solutions in the fight against
climate change.",http://arxiv.org/abs/2501.06623v1
"CarbonChat: Large Language Model-Based Corporate Carbon Emission
  Analysis and Climate Knowledge Q&A System",2025-01-03T08:45:38Z,"Zhixuan Cao, Ming Han, Jingtao Wang, Meng Jia","As the impact of global climate change intensifies, corporate carbon
emissions have become a focal point of global attention. In response to issues
such as the lag in climate change knowledge updates within large language
models, the lack of specialization and accuracy in traditional augmented
generation architectures for complex problems, and the high cost and time
consumption of sustainability report analysis, this paper proposes CarbonChat:
Large Language Model-based corporate carbon emission analysis and climate
knowledge Q&A system, aimed at achieving precise carbon emission analysis and
policy understanding.First, a diversified index module construction method is
proposed to handle the segmentation of rule-based and long-text documents, as
well as the extraction of structured data, thereby optimizing the parsing of
key information.Second, an enhanced self-prompt retrieval-augmented generation
architecture is designed, integrating intent recognition, structured reasoning
chains, hybrid retrieval, and Text2SQL, improving the efficiency of semantic
understanding and query conversion.Next, based on the greenhouse gas accounting
framework, 14 dimensions are established for carbon emission analysis, enabling
report summarization, relevance evaluation, and customized responses.Finally,
through a multi-layer chunking mechanism, timestamps, and hallucination
detection features, the accuracy and verifiability of the analysis results are
ensured, reducing hallucination rates and enhancing the precision of the
responses.",http://arxiv.org/abs/2501.02031v1
"Exploring the economic, social and environmental prospects for
  commercial natural annual grasslands by performing a sensitivity analysis on
  a multidisciplinary integrated model",2025-01-28T18:41:10Z,"Javier Ibáñez, Jaime Martínez-Valderrama, Joaquín Francisco Lavado Contador, Manuel Pulido Fernández","This paper presents an integrated modelling assessment that estimated the
sensitivities of five endogenous factors in commercial rangelands, i.e. number
of active farmers, profits, stocking rate, standing herbage biomass, and soil
erosion, to the same percentage variation in 70 factors, including economic and
climate drivers. The assessment utilised a system dynamics model (107
equations) which represents an area of extensive private farms, its farmers,
the main local markets on which they trade, and key ecosystem services
involved. The assessment procedure consisted in analysing the behaviours of
288,000 variants of this system during 300 years, each under a different
economic and climate scenario. Our key findings were as follows: 1) It is
likely that at least annual grasslands will suffer environmental degradation in
the future, and that such degradation will be primarily caused by climate
change, not by the increasing demand for livestock products; 2) Private farming
systems provide social and economic security to farmers against the effects of
climate change, especially in a scenario of rising prices of animal products.
However, this research will remain incomplete until its methods and results can
be contrasted with other similar assessments.",http://arxiv.org/abs/2501.17215v1
Diving Deep: Forecasting Sea Surface Temperatures and Anomalies,2025-01-10T05:55:14Z,"Ding Ning, Varvara Vetrova, Karin R. Bryan, Yun Sing Koh, Andreas Voskou, N'Dah Jean Kouagou, Arnab Sharma","This overview paper details the findings from the Diving Deep: Forecasting
Sea Surface Temperatures and Anomalies Challenge at the European Conference on
Machine Learning and Principles and Practice of Knowledge Discovery in
Databases (ECML PKDD) 2024. The challenge focused on the data-driven
predictability of global sea surface temperatures (SSTs), a key factor in
climate forecasting, ecosystem management, fisheries management, and climate
change monitoring. The challenge involved forecasting SST anomalies (SSTAs)
three months in advance using historical data and included a special task of
predicting SSTAs nine months ahead for the Baltic Sea. Participants utilized
various machine learning approaches to tackle the task, leveraging data from
ERA5. This paper discusses the methodologies employed, the results obtained,
and the lessons learned, offering insights into the future of climate-related
predictive modeling.",http://arxiv.org/abs/2501.05731v1
"A Smart IoT Framework for Climate-Resilient and Sustainable Maize
  Farming In Uganda",2025-01-21T20:20:36Z,"Nomugisha Godwin, Dr Mwebaze Johnson","This study provides a framework that incorporates the Internet of Things
(IoT) technology into maize farming activities in Central Uganda as a solution
to various challenges including climate change, sub-optimal resource use and
low crop yields. Using IoT-based modeling and simulation, the presented
solution recommends cost-effective and efficient approaches to irrigation, crop
yield improvement enhancement and prevention of drinking water loss while being
practical for smallholder farmers. The framework is developed in a manner that
is appropriate for low resource use regions by using local strategies that are
easily understandable and actionable for the farmers thus solving the issue of
technology access and social economic constraints. Research in this area
brought to light the promise that the IoT holds for the evolution of
agriculture into a more data-informed, climate-smart sector, contributes to the
much-needed food in the world, is economically viable, facilitates sustainable
rural development and is a huge step for the agriculture modernization of
Uganda.",http://arxiv.org/abs/2501.12483v1
"Dynamic and thermodynamic contributions to future extreme-rainfall
  intensification: a case study for Belgium",2025-02-04T16:00:04Z,"Jozefien Schoofs, Kobe Vandelanotte, Hans Van de Vyver, Line Van Der Sichel, Matthias Vandersteene, Fien Serras, Nicole P. M. van Lipzig, Bert Van Schaeybroeck","Extreme precipitation is projected to become more frequent and more intense
due to climate change and associated thermodynamical effects, but the local
response of atmospheric circulation under future climate scenarios remains
uncertain due mainly to dynamical differences. In this study, we outline a
methodology for a regional assessment of future extreme precipitation based on
the Lamb Weather Type classification and to evaluate future changes in weather
patterns. While anticyclonic days occur most frequently over Belgium, extreme
rainfall is mostly associated with days of cyclonic, westerly and
south-westerly weather patterns. GCMs from CMIP6 are first selected based on
their reliability in representing local atmospheric circulation patterns during
days with extreme rainfall days. It was found that for our case study over
Belgium, the future (end-of-the-century SSP3-7.0) changes in intensity and
likelihood of rainfall extremes can be primarily attributed to thermodynamic
factors, with minimal contribution from changes in atmospheric dynamics. Both
intensity and probability of extreme rainfall increase for all seasons. While
extreme-rainfall probabilities mostly increase in fall and winter, the
associated intensity changes are dominated by positive changes in spring and
summer. Additionally, the weather patterns that are historically associated
with extreme rainfall, disproportionally contribute to these changes,
especially to thermodynamic changes. More specifically, robust changes arise
from an increased extreme-rainfall occurrence probability in case of cyclonic,
south-westerly and westerly circulation types.",http://arxiv.org/abs/2502.02436v1
Seasonal Changes -- Time for Paradigm Shift,2025-01-22T13:42:41Z,"Branislava Lalic, Ana Firanj Sremac","Season and their transitions play a critical role in sharpening ecosystems
and human activities, yet traditional classifications, meteorological and
astronomical, fail to capture the complexities of biosphere-atmosphere
interactions. Conventional definitions often overlook the interplay between
climate variables, biosphere processes, and seasonal anticipation, particularly
as global climate change disrupts traditional patterns. This study addresses
the limitations of current seasonal classification by proposing a framework
based on phenological markers such as NDVI, EVI, LAI, fPAR, and the Bowen
ratio, using plants as a nature-based sensor of seasonal transitions.
Indicators derived from satellite data and ground observations provide robust
foundations for defining seasonal boundaries. The normalized daily temperature
range (DTRT), validated in crop and orchard regions, is hypothesized as a
reliable seasonality index to capture transitions. We demonstrated the
alignment of this index with phenological markers across boreal, temperate, and
deciduous forests. Analyzing trends, extreme values and inflection points in
the seasonality index time series, we established a methodology to identify
seasonal onset, duration, and transitions. This universal, scalable
classification aligns with current knowledge and perception of seasonal shifts
and captures site-specific timing. Findings reveal shifts in the
Euro-Mediterranean region, with winters shortening, summers extending, and
transitions becoming more pronounced. Effects include the Gulf Stream s
influence on milder transitions, urban heat islands accelerating seasonal
shifts, and large inland lakes moderating durations. This underscores the
importance of understanding seasonal transitions to enable climate change
adaptive strategies in agriculture, forestry, urban planning, medicine, trade,
marketing, and tourism.",http://arxiv.org/abs/2501.12882v1
Rain from Solar Scattering,2025-01-12T22:26:52Z,Aya Thompson,"Herein we propose a method mimicking natural processes for the creation of
precipitation, rain, in a safe, economically feasible manner anywhere in the
world. We propose accomplishing this via changing the target of the well
established field of aerosol dispersal for large scale climate cooling from
long term cooling to short term, locally targeted dispersal. We show that such
should induce precipitation anywhere with sufficient humidity, and should be
accomplishable at low cost and low or no safety concerns.",http://arxiv.org/abs/2501.12402v1
"The Resurgence of Trumponomics: Implications for the Future of ESG
  Investments in a Changing Political Landscape",2025-02-04T15:43:37Z,Innocentus Alhamis,"Public policy shapes the economic landscape, influencing everything from
corporate behavior to individual investment decisions. For Environmental,
Social, and Governance (ESG) investors, these policy shifts can create
opportunities and challenges as they navigate an ever-changing regulatory
environment. The contrast between the Trump and Biden administrations offers a
striking example of how differing political agendas can affect ESG investments.
Trump's first term was marked by deregulation and policies favoring fossil
fuels, which created an uncertain environment for sustainable investments. When
Biden assumed office, his focus on climate action and clean energy
reinvigorated the ESG sector, offering a more stable and supportive landscape
for green investments. However, with Trump's return to power in his second
term, these policies are being reversed again, leading to further volatility.
This paper explores how such dramatic shifts in public policy influence
economic strategies and directly impact ESG investors' decisions, forcing them
to constantly reassess their portfolios in response to changing political
climates.",http://arxiv.org/abs/2502.02627v1
"Advancing Carbon Capture using AI: Design of permeable membrane and
  estimation of parameters for Carbon Capture using linear regression and
  membrane-based equations",2025-01-23T04:28:35Z,"Bishwash Panerua, Biplov Paneru","This study focuses on membrane-based systems for CO$_2$ separation,
addressing the urgent need for efficient carbon capture solutions to mitigate
climate change. Linear regression models, based on membrane equations, were
utilized to estimate key parameters, including porosity ($\epsilon$) of 0.4805,
Kozeny constant (K) of 2.9084, specific surface area ($\sigma$) of 105.3272
m$^2$/m$^3$, mean pressure (Pm) of 6.2166 MPa, viscosity ($\mu$) of 0.1997
Ns/m$^2$, and gas flux (Jg) of 3.2559 kg m$^{-2}$ s$^{-1}$. These parameters
were derived from the analysis of synthetic datasets using linear regression.
The study also provides insights into the performance of the membrane, with a
flow rate (Q) of 9.8778 $\times$ 10$^{-4}$ m$^3$/s, an injection pressure
(P$_1$) of 2.8219 MPa, and an exit pressure (P$_2$) of 2.5762 MPa. The
permeability value of 0.045 for CO$_2$ indicates the potential for efficient
separation. Optimizing membrane properties to selectively block CO$_2$ while
allowing other gases to pass is crucial for improving carbon capture
efficiency. By integrating these technologies into industrial processes,
significant reductions in greenhouse gas emissions can be achieved, fostering a
circular carbon economy and contributing to global climate goals. This study
also explores how artificial intelligence (AI) can aid in designing membranes
for carbon capture, addressing the global climate change challenge and
supporting the Sustainable Development Goals (SDGs) set by the United Nations.",http://arxiv.org/abs/2501.13373v1
Circular Microalgae-Based Carbon Control for Net Zero,2025-02-04T15:01:44Z,"Federico Zocco, Joan García, Wassim M. Haddad","The alteration of the climate in various areas of the world is of increasing
concern since climate stability is a necessary condition for human survival as
well as every living organism. The main reason of climate change is the
greenhouse effect caused by the accumulation of carbon dioxide in the
atmosphere. In this paper, we design a networked system underpinned by
compartmental dynamical thermodynamics to circulate the atmospheric carbon
dioxide. Specifically, in the carbon dioxide emitter compartment, we develop an
initial-condition-dependent finite-time stabilizing controller that guarantees
stability within a desired time leveraging the system property of affinity in
the control. Then, to compensate for carbon emissions we show that a
cultivation of microalgae with a volume 625 times bigger than the one of the
carbon emitter is required. To increase the carbon uptake of the microalgae, we
implement the nonaffine-in-the-control microalgae dynamical equations as an
environment of a state-of-the-art library for reinforcement learning (RL),
namely, Stable-Baselines3, and then, through the library, we test the
performance of eight RL algorithms for training a controller that maximizes the
microalgae absorption of carbon through the light intensity. All the eight
controllers increased the carbon absorption of the cultivation during a
training of 200,000 time steps with a maximum episode length of 200 time steps
and with no termination conditions. This work is a first step towards
approaching net zero as a classical and learning-based network control problem.
The source code is publicly available.",http://arxiv.org/abs/2502.02382v1
Discontinuous stochastic forcing in Greenland ice core data,2025-02-12T14:55:19Z,"Keno Riechers, Andreas Morr, Klaus Lehnertz, Pedro G. Lind, Niklas Boers, Dirk Witthaut, Leonardo Rydin Gorjão","Paleoclimate proxy records from Greenland ice cores, archiving e.g.
$\delta^{18}$O as a proxy for surface temperature, show that sudden climatic
shifts called Dansgaard-Oeschger events (DO) occurred repeatedly during the
last glacial interval. They comprised substantial warming of the Arctic region
from cold to milder conditions. Concomitant abrupt changes in the dust
concentrations of the same ice cores suggest that sudden reorganisations of the
hemispheric-scale atmospheric circulation have accompanied the warming events.
Genuine bistability of the North Atlantic climate system is commonly
hypothesised to explain the existence of stadial (cold) and interstadial
(milder) periods in Greenland. However, the physical mechanisms that drove
abrupt transitions from the stadial to the interstadial state, and more gradual
yet still abrupt reverse transitions, remain debated. Here, we conduct a
one-dimensional data-driven analysis of the Greenland temperature and
atmospheric circulation proxies under the purview of stochastic processes. We
take the Kramers-Moyal equation to estimate each proxy's drift and diffusion
terms within a Markovian model framework. We then assess noise contributions
beyond Gaussian white noise. The resulting stochastic differential equation
(SDE) models feature a monostable drift for the Greenland temperature proxy and
a bistable one for the atmospheric circulation proxy. Indicators of
discontinuity in stochastic processes suggest to include higher-order terms of
the Kramers-Moyal equation when modelling the Greenland temperature proxy's
evolution. This constitutes a qualitative difference in the characteristics of
the two time series, which should be further investigated from the standpoint
of climate dynamics.",http://arxiv.org/abs/2502.08460v1
"OceanChat: The Effect of Virtual Conversational AI Agents on Sustainable
  Attitude and Behavior Change",2025-02-05T03:45:33Z,"Pat Pataranutaporn, Alexander Doudkin, Pattie Maes","Marine ecosystems face unprecedented threats from climate change and plastic
pollution, yet traditional environmental education often struggles to translate
awareness into sustained behavioral change. This paper presents OceanChat, an
interactive system leveraging large language models to create conversational AI
agents represented as animated marine creatures -- specifically a beluga whale,
a jellyfish, and a seahorse -- designed to promote environmental behavior (PEB)
and foster awareness through personalized dialogue. Through a between-subjects
experiment (N=900), we compared three conditions: (1) Static Scientific
Information, providing conventional environmental education through text and
images; (2) Static Character Narrative, featuring first-person storytelling
from 3D-rendered marine creatures; and (3) Conversational Character Narrative,
enabling real-time dialogue with AI-powered marine characters. Our analysis
revealed that the Conversational Character Narrative condition significantly
increased behavioral intentions and sustainable choice preferences compared to
static approaches. The beluga whale character demonstrated consistently
stronger emotional engagement across multiple measures, including perceived
anthropomorphism and empathy. However, impacts on deeper measures like climate
policy support and psychological distance were limited, highlighting the
complexity of shifting entrenched beliefs. Our work extends research on
sustainability interfaces facilitating PEB and offers design principles for
creating emotionally resonant, context-aware AI characters. By balancing
anthropomorphism with species authenticity, OceanChat demonstrates how
interactive narratives can bridge the gap between environmental knowledge and
real-world behavior change.",http://arxiv.org/abs/2502.02863v1
"Will artificial intelligence accelerate or delay the race between
  nuclear energy technology budgeting and net-zero emissions?",2025-01-29T04:25:03Z,"Danish, Adnan Khan","This study explores the impact of nuclear energy technology budgeting and
artificial intelligence on carbon dioxide (CO2) emissions in 20 OECD economies.
Unlike previous research that relied on conventional panel techniques, we
utilize the Method of Moment Quantile Regression panel data estimation
techniques. This approach provides quantile-specific insights while addressing
issues of endogeneity and heteroscedasticity, resulting in a more nuanced and
robust understanding of complex relationships. A novel aspect of this research
work is introducing the moderating effect of artificial intelligence on the
relationship between nuclear energy and CO2 emissions. The results found that
the direct impact of artificial intelligence on CO2 emissions is significant,
while the effect of nuclear energy technology budgeting is not. Additionally,
artificial intelligence moderates the relationship between nuclear energy
technology budgeting and CO2 emissions, aiding nuclear energy in reducing
carbon emissions across OECD countries. Our findings indicate that
transitioning to a low-carbon future is achievable by replacing fossil fuel
energy sources with increased integration of artificial intelligence to promote
nuclear energy technologies. This study demonstrates that energy innovations
can serve as effective climate-resilience strategies to mitigate the impacts of
climate change.",http://arxiv.org/abs/2501.17410v1
Spatial Distribution-Shift Aware Knowledge-Guided Machine Learning,2025-02-20T18:52:24Z,"Arun Sharma, Majid Farhadloo, Mingzhou Yang, Ruolei Zeng, Subhankar Ghosh, Shashi Shekhar","Given inputs of diverse soil characteristics and climate data gathered from
various regions, we aimed to build a model to predict accurate land emissions.
The problem is important since accurate quantification of the carbon cycle in
agroecosystems is crucial for mitigating climate change and ensuring
sustainable food production. Predicting accurate land emissions is challenging
since calibrating the heterogeneous nature of soil properties, moisture, and
environmental conditions is hard at decision-relevant scales. Traditional
approaches do not adequately estimate land emissions due to
location-independent parameters failing to leverage the spatial heterogeneity
and also require large datasets. To overcome these limitations, we proposed
Spatial Distribution-Shift Aware Knowledge-Guided Machine Learning (SDSA-KGML),
which leverages location-dependent parameters that account for significant
spatial heterogeneity in soil moisture from multiple sites within the same
region. Experimental results demonstrate that SDSA-KGML models achieve higher
local accuracy for the specified states in the Midwest Region.",http://arxiv.org/abs/2502.14840v1
"Understanding Computational Science and Domain Science Skills
  Development in National Laboratory Graduate Internships",2025-01-17T23:31:57Z,"Morgan M. Fong, Hilary Egan, Marc Day, Kristin Potter, Michael J. Martin","Contribution: This study presents an evaluation of federally-funded graduate
internship outcomes in computational science at a national laboratory.
Additionally, we present a survey instrument that may be used for other
internship programs with a similar focus. Background: There is ongoing demand
for computational scientists to grapple with large-scale problems such as
climate change. Internships may help provide additional training and access to
greater compute capabilities for graduate students. However, little work has
been done to quantify the learning outcomes of such internships. Background:
There is ongoing demand for computational scientists to grapple with
large-scale problems such as climate change. Internships may help provide
additional training and access to greater compute capabilities for graduate
students. However, little work has been done to quantify the learning outcomes
of such internships. Research Questions: What computational skills, research
skills, and professional skills do graduate students improve through their
internships at NREL, the national laboratory selected for the study? What
sustainability and renewable energy topics do graduate students gain more
familiarity with through their internships at NREL? Do graduate students'
career interests change after their internships at NREL? Methodology: We
developed a survey and collected responses from past participants of five
federally-funded internship programs and compare participant ratings of their
prior experience to their internship experience. Findings: Our results indicate
participants improve their computational skills, familiarity with
sustainability and renewable energy topics, and are more interested in working
at national labs. Additionally, participants go on to degree programs and
positions related to sustainability and renewable energy after their
internships.",http://arxiv.org/abs/2501.10601v1
Quantifying firm-level risks from nature deterioration,2025-01-24T10:44:26Z,Ricardo Crisóstomo,"We estimate the loss of value that companies might suffer from nature
overexploitation. We find that global equities shed 26.8% in a scenario of
unabated nature decline, while the worst-performing firms lose ~75% of their
value. Our risk framework considers five environmental hazards: biodiversity
loss, land degradation, climate change, human population and nature capital. We
also introduce two metrics to assess nature-related risks: a Country
Degradation Index that tracks the damage caused by environmental hazards in
specific territories, including nonlinear dynamics and tipping points; and a
Nature Risk Score that summarizes the risk that companies face due to the
decline of nature and its services.",http://arxiv.org/abs/2501.14391v2
A Statistical Learning Approach to Mediterranean Cyclones,2025-01-26T22:46:11Z,"L. Roveri, L. Fery, L. Cavicchia, F. Grotto","Mediterranean cyclones are extreme meteorological events of which much less
is known compared to their tropical, oceanic counterparts. The raising interest
in such phenomena is due to their impact on a region increasingly more affected
by climate change, but a precise characterization remains a non trivial task.
In this work we showcase how a Bayesian algorithm (Latent Dirichlet Allocation)
can classify Mediterranean cyclones relying on wind velocity data, leading to a
drastic dimensional reduction that allows the use of supervised statistical
learning techniques for detecting and tracking new cyclones.",http://arxiv.org/abs/2501.15694v1
Probabilistic Joint Recovery Method for CO$_2$ Plume Monitoring,2025-01-30T21:32:01Z,"Zijun Deng, Rafael Orozco, Abhinav Prakash Gahlot, Felix J. Herrmann","Reducing CO$_2$ emissions is crucial to mitigating climate change. Carbon
Capture and Storage (CCS) is one of the few technologies capable of achieving
net-negative CO$_2$ emissions. However, predicting fluid flow patterns in CCS
remains challenging due to uncertainties in CO$_2$ plume dynamics and reservoir
properties. Building on existing seismic imaging methods like the Joint
Recovery Method (JRM), which lacks uncertainty quantification, we propose the
Probabilistic Joint Recovery Method (pJRM). By estimating posterior
distributions across surveys using a shared generative model, pJRM provides
uncertainty information to improve risk assessment in CCS projects.",http://arxiv.org/abs/2501.18761v1
"Estimating forest carbon stocks from high-resolution remote sensing
  imagery by reducing domain shift with style transfer",2025-02-02T12:45:46Z,"Zhenyu Yu, Jinnian Wang","Forests function as crucial carbon reservoirs on land, and their carbon sinks
can efficiently reduce atmospheric CO2 concentrations and mitigate climate
change. Currently, the overall trend for monitoring and assessing forest carbon
stocks is to integrate ground monitoring sample data with satellite remote
sensing imagery. This style of analysis facilitates large-scale observation.
However, these techniques require improvement in accuracy. We used GF-1 WFV and
Landsat TM images to analyze Huize County, Qujing City, Yunnan Province in
China. Using the style transfer method, we introduced Swin Transformer to
extract global features through attention mechanisms, converting the carbon
stock estimation into an image translation.",http://arxiv.org/abs/2502.00784v1
"Entity Linking using LLMs for Automated Product Carbon Footprint
  Estimation",2025-02-11T09:54:39Z,"Steffen Castle, Julian Moreno Schneider, Leonhard Hennig, Georg Rehm","Growing concerns about climate change and sustainability are driving
manufacturers to take significant steps toward reducing their carbon
footprints. For these manufacturers, a first step towards this goal is to
identify the environmental impact of the individual components of their
products. We propose a system leveraging large language models (LLMs) to
automatically map components from manufacturer Bills of Materials (BOMs) to
Life Cycle Assessment (LCA) database entries by using LLMs to expand on
available component information. Our approach reduces the need for manual data
processing, paving the way for more accessible sustainability practices.",http://arxiv.org/abs/2502.07418v1
"Causal pathway from AMOC to Southern Amazon rainforest indicates
  stabilising interaction between two climate tipping elements",2025-01-24T10:13:38Z,"Annika Högner, Giorgia Di Capua, Jonathan F. Donges, Reik V. Donner, Georg Feulner, Nico Wunderling","Declines in resilience have been observed in several climate tipping elements
over the past decades, including the Atlantic Meridional Overturning
Circulation (AMOC) and the Amazon rainforest (AR). Large-scale nonlinear and
possibly irreversible changes in system state, such as AMOC weakening or
rainforest-savanna transitions in the Amazon basin, would have severe impacts
on ecosystems and human societies worldwide. In order to improve future tipping
risk assessments, understanding interactions between tipping elements is
crucial. The AMOC is known to influence the Intertropical Convergence Zone,
potentially altering precipitation patterns over the AR and affecting its
stability. However, AMOC-AR interactions are currently not well understood.
Here, we identify a previously unknown stabilising interaction pathway from the
AMOC onto the Southern AR, applying an established causal discovery and
inference approach to tipping element interactions for the first time.
Analysing observational and reanalysis data from 1982-2022, we show that AMOC
weakening leads to increased precipitation in the Southern AR during the
critical dry season, in line with findings from recent Earth system model
experiments. Specifically, we report a 4.8% increase of mean dry season
precipitation in the Southern AR for every 1 Sv of AMOC weakening. This finding
is consistent across multiple data sources and AMOC strength indices. We show
that this stabilising interaction has offset 17% of dry season precipitation
decrease in the Southern AR since 1982. Our results demonstrate the potential
of causal discovery methods for analysing tipping element interactions based on
reanalysis and observational data. By improving the understanding of AMOC-AR
interactions, we contribute toward better constraining the risk of potential
climate tipping cascades under global warming.",http://arxiv.org/abs/2501.14374v1
FireCastNet: Earth-as-a-Graph for Seasonal Fire Prediction,2025-02-03T17:30:45Z,"Dimitrios Michail, Charalampos Davalas, Lefki-Ioanna Panagiotou, Ioannis Prapas, Spyros Kondylatos, Nikolaos Ioannis Bountos, Ioannis Papoutsis","With climate change expected to exacerbate fire weather conditions, the
accurate and timely anticipation of wildfires becomes increasingly crucial for
disaster mitigation. In this study, we utilize SeasFire, a comprehensive global
wildfire dataset with climate, vegetation, oceanic indices, and human-related
variables, to enable seasonal wildfire forecasting with machine learning. For
the predictive analysis, we present FireCastNet, a novel architecture which
combines a 3D convolutional encoder with GraphCast, originally developed for
global short-term weather forecasting using graph neural networks. FireCastNet
is trained to capture the context leading to wildfires, at different spatial
and temporal scales. Our investigation focuses on assessing the effectiveness
of our model in predicting the presence of burned areas at varying forecasting
time horizons globally, extending up to six months into the future, and on how
different spatial or/and temporal context affects the performance. Our findings
demonstrate the potential of deep learning models in seasonal fire forecasting;
longer input time-series leads to more robust predictions, while integrating
spatial information to capture wildfire spatio-temporal dynamics boosts
performance. Finally, our results hint that in order to enhance performance at
longer forecasting horizons, a larger receptive field spatially needs to be
considered.",http://arxiv.org/abs/2502.01550v1
"Comprehensive Review of Analytical and Numerical Approaches in
  Earth-to-Air Heat Exchangers and Exergoeconomic Evaluations",2025-02-12T16:33:44Z,"Saeed Asadi, Mohsen Mohammadagha, Hajar Kazemi Naeini","In recent decades, Earth-to-Air Heat Exchangers (EAHEs), also known as
underground air ducts, have garnered significant attention for their ability to
provide energy-efficient cooling and heating solutions while maintaining a
minimal environmental footprint. These systems leverage the relatively stable
underground temperature to regulate indoor climates, reducing reliance on
conventional heating, ventilation, and air conditioning (HVAC) systems. This
review systematically categorizes and synthesizes research on EAHEs into three
primary areas: analytical, numerical, and exergoeconomic studies. Analytical
approaches focus on developing theoretical models to predict thermal
performance, while numerical simulations provide insights into system
optimization and real-world applications. Exergoeconomic analyses, integrating
thermodynamic efficiency with economic considerations, offer valuable
perspectives on cost-effectiveness and long-term viability. By consolidating
existing contributions across these domains, this study serves as a
comprehensive reference for researchers, engineers, and policymakers seeking to
enhance the design, implementation, and performance of EAHE systems. The
findings emphasize the pivotal role of EAHEs in reducing energy consumption,
lowering greenhouse gas emissions, and improving economic sustainability.
Additionally, this review identifies key challenges, including soil thermal
conductivity variations, moisture effects, and system integration with
renewable energy sources, which require further investigation. By addressing
these challenges, EAHEs can be further optimized to serve as a cornerstone in
sustainable energy management, contributing to global efforts toward
energy-efficient building solutions and climate change mitigation.",http://arxiv.org/abs/2502.08553v1
SpaceTime: Causal Discovery from Non-Stationary Time Series,2025-01-17T15:00:20Z,"Sarah Mameche, Lénaïg Cornanguer, Urmi Ninad, Jilles Vreeken","Understanding causality is challenging and often complicated by changing
causal relationships over time and across environments. Climate patterns, for
example, shift over time with recurring seasonal trends, while also depending
on geographical characteristics such as ecosystem variability. Existing methods
for discovering causal graphs from time series either assume stationarity, do
not permit both temporal and spatial distribution changes, or are unaware of
locations with the same causal relationships. In this work, we therefore unify
the three tasks of causal graph discovery in the non-stationary multi-context
setting, of reconstructing temporal regimes, and of partitioning datasets and
time intervals into those where invariant causal relationships hold. To
construct a consistent score that forms the basis of our method, we employ the
Minimum Description Length principle. Our resulting algorithm SPACETIME
simultaneously accounts for heterogeneity across space and non-stationarity
over time. Given multiple time series, it discovers regime changepoints and a
temporal causal graph using non-parametric functional modeling and kernelized
discrepancy testing. We also show that our method provides insights into
real-world phenomena such as river-runoff measured at different catchments and
biosphere-atmosphere interactions across ecosystems.",http://arxiv.org/abs/2501.10235v1
"Arbitrage-free catastrophe reinsurance valuation for compound dynamic
  contagion claims",2025-02-18T23:04:27Z,"Jiwook Jang, Patrick J. Laub, Tak Kuen Siu, Hongbiao Zhao","In this paper, we consider catastrophe stop-loss reinsurance valuation for a
reinsurance company with dynamic contagion claims. To deal with conventional
and emerging catastrophic events, we propose the use of a compound dynamic
contagion process for the catastrophic component of the liability. Under the
premise that there is an absence of arbitrage opportunity in the market, we
obtain arbitrage-free premiums for these contacts. To this end, the Esscher
transform is adopted to specify an equivalent martingale probability measure.
We show that reinsurers have various ways of levying the security loading on
the net premiums to quantify the catastrophic liability in light of the growing
challenges posed by emerging risks arising from climate change, cyberattacks,
and pandemics. We numerically compare arbitrage-free catastrophe stop-loss
reinsurance premiums via the Monte Carlo simulation method. Sensitivity
analyzes are performed by changing the Esscher parameters and the retention
level.",http://arxiv.org/abs/2502.13325v1
Electrochemical CO2 capture with pH-independent redox chemistry,2025-02-03T03:48:04Z,"Sang Cheol Kim, Marco Gigantino, John Holoubek, Jesse E. Matthews, Junjie Chen, Yaereen Dho, Thomas F. Jaramillo, Yi Cui, Arun Majumdar, Yan-Kai Tzeng, Steven Chu","Capture of anthropogenic CO2 is critical for mitigating climate change, and
reducing the energy cost is essential for wide-scale deployment. Solubility of
inorganic carbon in aqueous solutions depends on the pH, and electrochemical
modulation of the pH has been investigated as a means of CO2 capture and
release. However, reported methods incur unavoidable energy costs due to
thermodynamic penalties. In this study, we introduce a pH-independent redox
chemistry that greatly lowers the thermodynamic energy costs by changing the pH
without directly changing the [H+]. We show that the redox reaction of TEMPO
molecules modulates the pH for capture and release of CO2 in a flow cell with
an energy cost as low as 2.6 kJ/mol of CO2 corresponding to 0.027 eV/molecule.
A molecular model, supported by MD and DFT simulations, is proposed of how the
pH is decreased by 7.6 while largely avoiding the entropic energy cost
associated with increasing the [H+]. We believe that this work showcases the
potential of pH-independent redox chemistries for practical and cost-effective
CO2 capture.",http://arxiv.org/abs/2502.01028v1
"Interfacial Free Energy as the Key to the Pressure-Induced Deceleration
  of Ice Nucleation",2025-01-13T08:24:22Z,"Jorge R. Espinosa, Alberto Zaragoza, Pablo Rosales-Peláez, Caridad Navarro, Chantal Valeriani, Carlos Vega, Eduardo Sanz","The avoidance of water freezing is the holy grail in the cryopreservation of
biological samples, food, and organs. Fast cooling rates are used to beat ice
nucleation and avoid cell damage. This strategy can be enhanced by applying
high pressures to decrease the nucleation rate, but the physics behind this
procedure has not been fully understood yet. We perform computer experiments to
investigate ice nucleation at high pressures consisting in embedding ice seeds
in supercooled water. We find that the slowing down of the nucleation rate is
mainly due to an increase of the ice I-water interfacial free energy with
pressure. Our work also clarifies the molecular mechanism of ice nucleation for
a wide pressure range. This study is not only relevant to cryopreservation, but
also to water amorphization and climate change modeling.",http://arxiv.org/abs/2501.07122v1
"Consistency of Responses and Continuations Generated by Large Language
  Models on Social Media",2025-01-14T13:19:47Z,"Wenlu Fan, Yuqi Zhu, Chenyang Wang, Bin Wang, Wentao Xu","Large Language Models (LLMs) demonstrate remarkable capabilities in text
generation, yet their emotional consistency and semantic coherence in social
media contexts remain insufficiently understood. This study investigates how
LLMs handle emotional content and maintain semantic relationships through
continuation and response tasks using two open-source models: Gemma and Llama.
By analyzing climate change discussions from Twitter and Reddit, we examine
emotional transitions, intensity patterns, and semantic similarity between
human-authored and LLM-generated content. Our findings reveal that while both
models maintain high semantic coherence, they exhibit distinct emotional
patterns: Gemma shows a tendency toward negative emotion amplification,
particularly anger, while maintaining certain positive emotions like optimism.
Llama demonstrates superior emotional preservation across a broader spectrum of
affects. Both models systematically generate responses with attenuated
emotional intensity compared to human-authored content and show a bias toward
positive emotions in response tasks. Additionally, both models maintain strong
semantic similarity with original texts, though performance varies between
continuation and response tasks. These findings provide insights into LLMs'
emotional and semantic processing capabilities, with implications for their
deployment in social media contexts and human-AI interaction design.",http://arxiv.org/abs/2501.08102v2
"Daily Groundwater Monitoring Using Vehicle-DAS Elastic Full-waveform
  Inversion",2025-01-18T00:52:18Z,"Haipeng Li, Jingxiao Liu, Shujuan Mao, Siyuan Yuan, Robert G. Clapp, Biondo L. Biondi","Understanding groundwater dynamics is critical for sustainable water
management, particularly as climate extremes intensify. However, the
resolutions of existing subsurface observational tools are still inadequate for
detailed aquifer monitoring and imaging. We introduce an innovative technique
for groundwater monitoring using time-lapse full-waveform inversion, leveraging
fiber-optic cables as seismic sensors and vehicular traffic as repetitive
seismic sources. Over a two-year period along Sandhill Road, California, this
approach captures detailed spatiotemporal S-wave velocity variations, revealing
a 2.9% reduction corresponding to a 9.0-meter groundwater table rise after
atmospheric-river storms in Water Year 2023. Notably, this approach enables the
high-resolution daily analysis of rapid aquifer responses. We observe spatially
inhomogeneous velocity changes, with less reduction beneath impervious paved
zones than under grassy areas, underscoring the impact of urbanization on the
natural recharge of aquifers. Our findings highlight the potential of
Vehicle-DAS FWI for high-resolution daily monitoring and quantitative
spatiotemporal characterizations of groundwater systems.",http://arxiv.org/abs/2501.10618v1
"A Safer, Smaller, Cleaner Subcritical Thorium Fission - Deuteron Fusion
  Hybrid Reactor: DD Collider Instead of Muonic Fusion",2025-01-11T16:19:58Z,"D. Akturk, A. C. Canbay, B. Dagli, U. Kaya, S. Sultansoy","Fossil fuels, which meet most of humanity's energy needs, cause climate
change due to their high carbon emissions. There are two types of energy
sources that can replace fossil fuels: renewable and nuclear. Nuclear energy
sources are more advantageous in terms of efficiency and sustainability. The
use of Thorium as nuclear fuel in fusion reactors will contribute to the
reduction of radioactive waste, due to the much lower production of
transuranics. Fusion reactors, which are considered promising, are still in the
R&D phase. In this respect, hybrid fusion-fission reactors seem more promising
and the recently proposed combination of muon-catalyzed DD fusion with a
cascade thorium reactor is worthy of appreciation. In this study, we show that
using the DD collider instead of muonic fusion has significant advantages.",http://arxiv.org/abs/2501.12401v1
"How Does the Spatial Distribution of Pre-training Data Affect Geospatial
  Foundation Models?",2025-01-21T22:57:09Z,"Mirali Purohit, Gedeon Muhawenayo, Esther Rolf, Hannah Kerner","Foundation models have made rapid advances in many domains including Earth
observation, where Geospatial Foundation Models (GFMs) can help address global
challenges such as climate change, agriculture, and disaster response. Previous
work on GFMs focused on tailoring model architecture and pre-text tasks, and
did not investigate the impact of pre-training data selection on model
performance. However, recent works from other domains show that the
pre-training data distribution is an important factor influencing the
performance of the foundation models. With this motivation, our research
explores how the geographic distribution of pre-training data affects the
performance of GFMs. We evaluated several pre-training data distributions by
sampling different compositions from a global data pool. Our experiments with
two GFMs on downstream tasks indicate that balanced and globally representative
data compositions often outperform region-specific sampling, highlighting the
importance of diversity and global coverage in pre-training data. Our results
suggest that the most appropriate data sampling technique may depend on the
specific GFM architecture. These findings will support the development of
robust GFMs by incorporating quality pre-training data distributions,
ultimately improving machine learning solutions for Earth observation.",http://arxiv.org/abs/2501.12535v1
"The silent threat of methane to ecosystems: Insights from mechanistic
  modelling",2025-01-24T01:22:17Z,"Pranali Roy Chowdhury, Tianxu Wang, Shohel Ahmed, Hao Wang","Over the past century, atmospheric methane levels have nearly doubled, posing
a significant threat to ecosystems. Despite this, studies on its direct impact
on species interactions are lacking. Although bioaccumulation theory explains
the effects of contaminants in trophic levels, it is inadequate for gaseous
pollutants such as methane. This study aims to bridge the gap by developing a
methane-population-detritus model to investigate ecological impacts in aquatic
and terrestrial ecosystems. Our findings show that low methane concentrations
can enhance species growth, while moderate accumulation may induce sub-lethal
effects over time. Elevated methane levels, however, lead to ecosystem
collapse. Furthermore, prolonged exposure to the gas increases the sensitivity
of species towards rising temperatures. Multiscale analysis reveals that rapid
methane accumulation leads to long transients near the extinction states. We
argue that high emission rates can push the system towards a critical
threshold, where the ecosystem shifts to an alternative stable state
characterized by elevated methane concentrations. This work highlights the
urgent need for a better understanding of the fatal role of methane in
ecosystems for developing strategies to mitigate its effects amid climate
change.",http://arxiv.org/abs/2501.14161v1
"Pesti-Gen: Unleashing a Generative Molecule Approach for Toxicity Aware
  Pesticide Design",2025-01-24T13:00:54Z,"Taehan Kim, Wonduk Seo","Global climate change has reduced crop resilience and pesticide efficacy,
making reliance on synthetic pesticides inevitable, even though their
widespread use poses significant health and environmental risks. While these
pesticides remain a key tool in pest management, previous machine-learning
applications in pesticide and agriculture have focused on classification or
regression, leaving the fundamental challenge of generating new molecular
structures or designing novel candidates unaddressed. In this paper, we propose
Pesti-Gen, a novel generative model based on variational auto-encoders,
designed to create pesticide candidates with optimized properties for the first
time. Specifically, Pesti-Gen leverages a two-stage learning process: an
initial pre-training phase that captures a generalized chemical structure
representation, followed by a fine-tuning stage that incorporates
toxicity-specific information. The model simultaneously optimizes over multiple
toxicity metrics, such as (1) livestock toxicity and (2) aqua toxicity to
generate environmentally friendly pesticide candidates. Notably, Pesti-Gen
achieves approximately 68\% structural validity in generating new molecular
structures, demonstrating the model's effectiveness in producing optimized and
feasible pesticide candidates, thereby providing a new way for safer and more
sustainable pest management solutions.",http://arxiv.org/abs/2501.14469v1
Share a Tiny Space of Your Freezer to Preserve Seed Diversity,2025-01-27T11:13:03Z,Andrea Vitaletti,"The Food and Agriculture Organization (FAO), estimates that 75% of crop
diversity was lost since the 1900s. That lack of diversity presents a severe
risk to the security of global food systems. Without seed diversity, it is
difficult for plants to adapt to pests, diseases, and changing climate
conditions. Genebanks, such as the Svalbard Global Seed Vault, are valuable
initiatives to preserve seed diversity in a single secure and safe place.
However, according to our analysis of the data available in the Seed Portal,
the redundancy for some species might be limited, posing a potential threat to
their future availability. Interestingly, the conditions to properly store
seeds in genebanks, are the ones available in the freezers of our homes. This
paper lays out a vision for Distributed Seed Storage relying on a peer-to-peer
infrastructure of domestic freezers to increase the overall availability of
seeds. We present a Proof-of-Concept focused on monitoring the proper seed
storing conditions and incentive user participation through a Blockchain
lottery. The PoC proves the feasibility of the proposed approach and outlines
the main technical issues that still need to be efficiently solved to realize a
fully-fledged solution.",http://arxiv.org/abs/2501.15962v1
"Zoning in American Cities: Are Reforms Making a Difference? An AI-based
  Analysis",2025-01-07T01:03:38Z,"Arianna Salazar-Miranda, Emily Talen","Cities are at the forefront of addressing global sustainability challenges,
particularly those exacerbated by climate change. Traditional zoning codes,
which often segregate land uses, have been linked to increased vehicular
dependence, urban sprawl, and social disconnection, undermining broader social
and environmental sustainability objectives. This study investigates the
adoption and impact of form-based codes (FBCs), which aim to promote
sustainable, compact, and mixed-use urban forms as a solution to these issues.
Using Natural Language Processing (NLP) techniques, we analyzed zoning
documents from over 2000 U.S. census-designated places to identify linguistic
patterns indicative of FBC principles. Our findings reveal widespread adoption
of FBCs across the country, with notable variations within regions. FBCs are
associated with higher floor-to-area ratios, narrower and more consistent
street setbacks, and smaller plots. We also find that places with FBCs have
improved walkability, shorter commutes, and a higher share of multi-family
housing. Our findings highlight the utility of NLP for evaluating zoning codes
and underscore the potential benefits of form-based zoning reforms for
enhancing urban sustainability.",http://arxiv.org/abs/2502.00008v1
Lessons from complexity theory for AI governance,2025-01-07T07:56:40Z,"Noam Kolt, Michal Shur-Ofry, Reuven Cohen","The study of complex adaptive systems, pioneered in physics, biology, and the
social sciences, offers important lessons for AI governance. Contemporary AI
systems and the environments in which they operate exhibit many of the
properties characteristic of complex systems, including nonlinear growth
patterns, emergent phenomena, and cascading effects that can lead to tail
risks. Complexity theory can help illuminate the features of AI that pose
central challenges for policymakers, such as feedback loops induced by training
AI models on synthetic data and the interconnectedness between AI systems and
critical infrastructure. Drawing on insights from other domains shaped by
complex systems, including public health and climate change, we examine how
efforts to govern AI are marked by deep uncertainty. To contend with this
challenge, we propose a set of complexity-compatible principles concerning the
timing and structure of AI governance, and the risk thresholds that should
trigger regulatory intervention.",http://arxiv.org/abs/2502.00012v1
"Bayesian Spatiotemporal Nonstationary Model Quantifies Robust Increases
  in Daily Extreme Rainfall Across the Western Gulf Coast",2025-02-04T04:22:02Z,"Yuchen Lu, Ben Seiyon Lee, James Doss-Gollin","Precipitation exceedance probabilities are widely used in engineering design,
risk assessment, and floodplain management. While common approaches like NOAA
Atlas 14 assume that extreme precipitation characteristics are stationary over
time, this assumption may underestimate current and future hazards due to
anthropogenic climate change. However, the incorporation of nonstationarity in
the statistical modeling of extreme precipitation has faced practical
challenges that have restricted its applications. In particular, random
sampling variability challenges the reliable estimation of trends and
parameters, especially when observational records are limited. To address this
methodological gap, we propose the Spatially Varying Covariates Model, a
hierarchical Bayesian spatial framework that integrates nonstationarity and
regionalization for robust frequency analysis of extreme precipitation. This
model draws from extreme value theory, spatial statistics, and Bayesian
statistics, and is validated through cross-validation and multiple performance
metrics. Applying this framework to a case study of daily rainfall in the
Western Gulf Coast, we identify robustly increasing trends in extreme
precipitation intensity and variability throughout the study area, with notable
spatial heterogeneity. This flexible model accommodates stations with varying
observation records, yields smooth return level estimates, and can be
straightforwardly adapted to the analysis of precipitation frequencies at
different durations and for other regions.",http://arxiv.org/abs/2502.02000v1
"Is this normal? A new projection pursuit index to assess a sample
  against a multivariate null distribution",2025-02-04T15:17:10Z,"Annalisa Calvi, Ursula Laa, Dianne Cook","Many data problems contain some reference or normal conditions, upon which to
compare newly collected data. This scenario occurs in data collected as part of
clinical trials to detect adverse events, or for measuring climate change
against historical norms. The data is typically multivariate, and often the
normal ranges are specified by a multivariate normal distribution. The work
presented in this paper develops methods to compare the new sample against the
reference distribution with high-dimensional visualisation. It uses a
projection pursuit guided tour to produce a sequence of low-dimensional
projections steered towards those where the new sample is most different from
the reference. A new projection pursuit index is defined for this purpose. The
tour visualisation also includes drawing of the projected ellipse, which is
computed analytically, corresponding to the reference distribution. The methods
are implemented in the R package, tourr.",http://arxiv.org/abs/2502.02397v1
Measuring Fitness and Importance of Species in Food Webs,2025-02-11T15:05:21Z,"Emanuele Calò, Giordano De Marzo, Vito D. P. Servedio","Ecosystems face intensifying threats from climate change, overexploitation,
and other human pressures, emphasizing the urgent need to identify keystone
species and vulnerable ones. While established network-based measures often
rely on a single metric to quantify a species' relevance, they overlook how
organisms can be both carbon providers and consumers, thus playing a dual role
in food webs. Here, we introduce a novel approach that assigns each species two
complementary scores -- an importance measure quantifying their centrality as
carbon source and a fitness measure capturing their vulnerability. We show that
species with high importance are more likely to trigger co-extinctions upon
removal, while high-fitness species typically endure until later stages of
collapse, in line with their broader prey ranges. On the other hand, low
fitness species are the most vulnerable and susceptible to extinctions. Tested
on multiple food webs, our method outperforms traditional degree-based analyses
and competes effectively with eigenvector-based approaches, while also
providing additional insights. Relying solely on interaction data, the approach
is scalable and avoids reliance on expert-driven classifications, offering a
cost-effective tool for prioritizing conservation efforts.",http://arxiv.org/abs/2502.07614v1
"Adsorption Behavior of Greenhouse Gases on Carbon Nanobelts: A
  Semi-Empirical Tight-Binding Approach for Environmental Application",2025-02-11T16:44:48Z,"C. Aguiar, I. Camps","This research investigates the adsorption characteristics of carbon nanobelts
(CNB) and Mobius carbon nanobelts (MCNB) interacting with various greenhouse
gases, including NH3, CO2, CO, H2S, CH4, CH3OH, NO2, NO, and COCl2. The study
employs semi-empirical tight-binding calculations via xTB software,
complemented by topological analysis using MULTIWFN software. Comparative
analysis reveals MCNB's superior adsorption properties, particularly for
specific gases. Notable adsorption energies for MCNB were measured at -1.595eV,
-0.669eV, and -0.637eV for NO, COCl2, and NO2, respectively, significantly
exceeding the corresponding CNB values of -0.636eV, -0.449eV, and -0.438eV. The
investigation of desorption kinetics demonstrates rapid recovery times
(sub-millisecond) for most gas-nanobelt interactions, with the notable
exception of the MCNB+NO system, which exhibits persistent bonding. Topological
analysis confirms chemisorption mechanisms for NO, COCl2, and NO2 on both
nanobelt variants, characterized by complex hybridizations of covalent and
non-covalent interactions. Molecular dynamics simulations conducted in both
packed configurations and dry air mixtures demonstrate the nanobelts' effective
gas-attracting properties, maintaining consistent capture performance across
different environmental conditions. These findings establish carbon nanobelts,
particularly the Mobius configuration, as promising candidates for greenhouse
gas capture technologies, offering potential applications in environmental
remediation and climate change mitigation strategies.",http://arxiv.org/abs/2502.07690v1
Optimal Placement of Nature-Based Solutions for Urban Challenges,2025-02-16T10:10:01Z,"Diego Maria Pinto, Davide Donato Russo, Antonio M. Sudoso","Increased urbanization and climate change intensify urban heat islands and
degrade air quality, making current mitigation strategies insufficient.
Nature-based solutions (NBSs), such as parks, green walls, roofs, and street
trees, offer a promising means to regulate urban temperatures and enhance air
quality. However, determining their optimal placement to maximize environmental
benefits remains a pressing challenge. Leveraging Operational Research (OR)
tools, we propose a Mixed-Integer Linear Programming (MILP) model that
integrates multiple factors, including urban challenges, physical constraints,
clustering techniques, convolution theory, and fairness considerations. This
model determines the optimal placement of NBSs by addressing metrics such as
ground temperature, air quality, and accessibility to green spaces. Through
several case study analyses, we demonstrate the effectiveness of our approach
in improving environmental and social indicators. This research holds
implications for policy and practice, empowering urban planners and
policymakers to make informed decisions regarding NBS implementation. Such
decisions ensure that investments in urban greening yield maximum
environmental, social, and economic benefits.",http://arxiv.org/abs/2502.11065v1
"A survey about perceptions of mobility to inform an agent-based
  simulator of subjective modal choice",2025-02-17T17:25:18Z,"Carole Adam, Benoit Gaudou","In order to adapt to the issues of climate change and public health, urban
policies are trying to encourage soft mobility, but the share of the car
remains significant. Beyond known constraints, we study here the impact of
perception biases on individual choices. We designed a multi-criteria decision
model, integrating the influence of habits and biases. We then conducted an
online survey, which received 650 responses. We used these to calculate
realistic mobility perception values, in order to initialise the environment
and the population of a modal choice simulator, implemented in Netlogo. This
allows us to visualize the adaptation of the modal distribution in reaction to
the evolution of urban planning, depending on whether or not we activate biases
and habits in individual reasoning.
  This is an extended and translated version of a demo paper published in
French at JFSMA-JFMS 2024 ""Un simulateur multi-agent de choix modal subjectif""",http://arxiv.org/abs/2502.12058v1
"Scalable and Robust Physics-Informed Graph Neural Networks for Water
  Distribution Systems",2025-02-11T13:38:14Z,"Inaam Ashraf, André Artelt, Barbara Hammer","Water distribution systems (WDSs) are an important part of critical
infrastructure becoming increasingly significant in the face of climate change
and urban population growth. We propose a robust and scalable surrogate deep
learning (DL) model to enable efficient planning, expansion, and rehabilitation
of WDSs. Our approach incorporates an improved graph neural network
architecture, an adapted physics-informed algorithm, an innovative training
scheme, and a physics-preserving data normalization method. Evaluation results
on a number of WDSs demonstrate that our model outperforms the current
state-of-the-art DL model. Moreover, our method allows us to scale the model to
bigger and more realistic WDSs. Furthermore, our approach makes the model more
robust to out-of-distribution input features (demands, pipe diameters). Hence,
our proposed method constitutes a significant step towards bridging the
simulation-to-real gap in the use of artificial intelligence for WDSs.",http://arxiv.org/abs/2502.12164v1
Fine-grained Fallacy Detection with Human Label Variation,2025-02-19T16:18:44Z,"Alan Ramponi, Agnese Daffara, Sara Tonelli","We introduce Faina, the first dataset for fallacy detection that embraces
multiple plausible answers and natural disagreement. Faina includes over 11K
span-level annotations with overlaps across 20 fallacy types on social media
posts in Italian about migration, climate change, and public health given by
two expert annotators. Through an extensive annotation study that allowed
discussion over multiple rounds, we minimize annotation errors whilst keeping
signals of human label variation. Moreover, we devise a framework that goes
beyond ""single ground truth"" evaluation and simultaneously accounts for
multiple (equally reliable) test sets and the peculiarities of the task, i.e.,
partial span matches, overlaps, and the varying severity of labeling errors.
Our experiments across four fallacy detection setups show that multi-task and
multi-label transformer-based approaches are strong baselines across all
settings. We release our data, code, and annotation guidelines to foster
research on fallacy detection and human label variation more broadly.",http://arxiv.org/abs/2502.13853v1
"A meta-model of belief dynamics with Personal, Expressed and Social
  beliefs",2025-02-20T08:40:32Z,"Filippo Zimmaro, Henrik Olsson","Beliefs are central to individual decision-making and societal dynamics, yet
they are shaped through complex interactions between personal cognition and
social environments. Traditional models of belief dynamics often fail to
capture the interplay between internal belief systems and external influences.
This paper introduces the Personal, Expressed, and Social Beliefs (PES)
meta-model, which integrates personal beliefs, outwardly expressed beliefs, and
perceptions of others' beliefs. The PES meta-model provides a flexible
structure to model belief dynamics, incorporating processes like social
influence, authenticity, ego projection, and conformity. It accommodates wide
range of existing models, of the Voter, Ising, DeGroot and bounded confidence
types, allowing for comparison and extension of the models within a unified
framework. Through a case study on the misperception of public support for
climate change policies, the PES meta-model demonstrates its capacity to
capture complex psychological and social phenomena. This work highlights the
utility of the PES meta-model in advancing theoretical understanding and
practical applications in belief dynamics research.",http://arxiv.org/abs/2502.14362v1
Eco-evolutionary dynamics of a trait-structured predator-prey model,2025-01-13T14:55:59Z,"Manh Hong Duong, Fabian Spill, Blaine van Rensburg","The coupling between evolutionary and ecological changes (eco-evolutionary
dynamics) has been shown to be relevant among diverse species, and is also of
interest outside of ecology, i.e. in cancer evolution. These dynamics play an
important role in determining survival in response to climate change,
motivating the need for mathematical models to capture this often complex
interplay. Models incorporating eco-evolutionary dynamics often sacrifice
analytical tractability to capture the complexity of real systems, do not
explicitly consider the effect of population heterogeneity, or focus on
long-term behaviour. In order to capture population heterogeneity, both
transient, and long-term dynamics, while retaining tractability, we generalise
a moment-based method applicable in the regime of small segregational variance
to the case of time-dependent mortality and birth. These results are applied to
a predator-prey model, where ecological parameters such as the contact rate
between species are trait-structured. The trait-distribution of the prey
species is shown to be approximately Gaussian with constant variance centered
on the mean trait, which is asymptotically governed by an autonomous ODE. In
this way, we make explicit the impact of eco-evolutionary dynamics on the
transient behaviour and long-term fate of the prey species.",http://arxiv.org/abs/2501.07379v2
"Analyzing the progress of Indian states chasing sustainable development
  goals using complex network framework",2025-01-09T15:30:09Z,"Hrishidev Unni, Rubal Rathi, Sangita Dutta Gupta, Anirban Chakraborti","The Sustainable Development Goals (SDGs) offer a critical global framework
for addressing challenges like poverty, inequality, climate change, etc. They
encourage a holistic approach integrating economic growth, social inclusion,
and environmental sustainability to create a better future. We aim to examine
India's responsibility in achieving the SDGs by recognizing the contributions
of its diverse states in the federal structure of governance. As the nodal
agency in India, the NITI Aayog's existing SDG index, using various
socioeconomic indicators to determine the performance across different goals,
serves as a foundation for assessing each state's progress. Building on the
seminal works of Hidalgo and Hausmann (2009) and Tachhella et al. (2012), which
introduced the economic complexity/fitness index, Sciarra et al. (2020)
proposed the SDGs-Generalized Economic Complexity (GENEPY) framework to
quantify ""complexity"" by computing ""ranks for states"" and ""scores for goals"",
treating them as part of a complex bipartite network. In this paper, we apply
the SDGs-GENEPY, to evaluate the progress and evolution of Indian states and
union territories over several years. This enables us to identify each state's
capacity (and rank) in achieving the SDGs. We can interpret these complexity
scores as ""centrality measures"" of a complex bipartite network of the states
and the goals. This enhances our understanding of the complex relationship
between state capabilities and the achievability of SDGs within the Indian
context and enables data-driven policy-making.",http://arxiv.org/abs/2501.05314v1
"Estimation of the Effect of Carbon Tax Implementation on Household
  Income Distribution in Indonesia: Quantitative Analysis with Miyazawa Input-
  Output Approach",2025-01-14T15:00:25Z,Syahrituah Siregar,"Climate change is a global challenge caused by greenhouse gas emissions from
fossil fuel use. Indonesia, as a developing country, faces major challenges in
implementing carbon tax policies to reduce emissions, especially related to
their regressive impacts on low-income households. Currently, there is little
in-depth research on how carbon tax policies impact household income
distribution in Indonesia. This study uses a quantitative approach with the
Input- Output model to analyze the impact of carbon tax on household income
based on 10 income groups, both in urban and rural areas. The results show that
carbon tax policies have a regressive impact, where low-income households bear
a proportionally greater burden. Household income in Class - 10 decreased by
IDR 19,144.85 million in urban areas and IDR 8,819.13 million in rural areas,
while households in Class - 1 decreased by IDR 954.23 million. Therefore,
mitigation policies such as cross subsidies are needed to reduce the impact on
vulnerable groups. These findings are important for policy makers in
formulating fair and effective fiscal policies, as well as ensuring social
justice in the context of sustainable development. This study has limitations
in the scope of analysis of long-term energy consumption behavior and certain
sectors, so further research is needed to deepen these aspects.",http://arxiv.org/abs/2501.08177v1
"A life cycle model for high-speed rail infrastructure: environmental
  inventories and assessment of the Tours-Bordeaux railway in France",2025-01-14T22:34:02Z,"Anne de Bortoli, Lina Bouhaya, Adelaide Feraille","Method: a process-based LCA compliant with ISO 14040 and 14044 is performed.
Construction stage LCIs rely on data collection conducted with the
concessionaire of the HSR line combined with EcoInvent 3.1 inventories. Use and
End-of-Life stages LCIs rest on expert feedback scenarios and field data. A set
of 13 midpoint indicators is proposed to capture the diversity of the
environmental damage: climate change, consumptions of primary energy and
non-renewable resources, human toxicity and ecotoxicities, eutrophication,
acidification, radioactive and bulk wastes, stratospheric ozone depletion and
summer smog. Results: The study shows major contributions to environmental
impact from rails (10-71%), roadbed (3-48%), and civil engineering structures
(4-28%). More limited impact is noted from ballast (1-22%), building machines
(0-17%), sleepers (4-11%), and power supply system (2-12%). The two last
components, chairs and fasteners, have negligible impact (max. 1% and 3% of
total contributions, respectively). Direct transportation can contribute up to
18% of total impact. The production and maintenance stages contribute roughly
equally to environmental deterioration (resp. average of 62% and 59%). Because
the End-of-Life (EoL) mainly includes recycling with environmental credit
accounted for in our 100:100 approach, this stage has globally a positive
impact (-9 to -98%) on all the impact categories except terrestrial ecotoxicity
(58%), radioactive waste (11%) and ozone depletion (8%). Contribution analyses
show that if concrete production is one of the important contributing process
over the construction stage, primary steel production is unquestionably the
most important process on all the impact categories over the entire life cycle.",http://arxiv.org/abs/2501.10458v1
"Solar Panel Selection using Extended WASPAS with Disc Intuitionistic
  Fuzzy Choquet Integral Operators: CASPAS Methodology",2025-01-21T16:12:55Z,"Mahmut Can Bozyiğit, Mehmet Ünver","Renewable energy is crucial for addressing the growing energy demands of
modern society while mitigating the adverse effects of climate change. Unlike
fossil fuels, renewable energy sources such as solar, wind, hydro, geothermal,
and biomass are abundant, sustainable, and environmentally friendly. This study
focuses on addressing a critical challenge in renewable energy decision-making
by developing a novel framework for optimal solar panel selection, a key
component of sustainable energy solutions. Solar panel selection involves
evaluating multiple interdependent criteria, such as efficiency, cost,
durability, and environmental impact. Traditional multi-criteria
decision-making (MCDM) methods often fail to account for the interdependencies
among these criteria, leading to suboptimal outcomes. To overcome this
limitation, the study introduces the Choquet Aggregated Sum Product Assessment
(CASPAS) method, a Choquet integral-based MCDM approach that incorporates fuzzy
measures to model interactions among criteria. CASPAS generalizes the Weighted
Aggregated Sum Product Assessment (WASPAS) method, thereby enhancing
decision-making accuracy and reliability. This study also introduces the
concept of disc intuitionistic fuzzy set (D-IFS), a generalization of the
concept of circular intuitionistic fuzzy set, which employ a radius function
capable of assigning varying values to individual elements instead of relying
on a fixed radius. Recognizing that traditional weighted aggregation operators
neglect the interaction among criteria, this study proposes disc intuitionistic
fuzzy Choquet integral operators by incorporating the concept of fuzzy
measures, which are effective in modeling such interactions. The proposed
method is applied to a renewable energy problem on selecting optimal solar
panels.",http://arxiv.org/abs/2501.12251v1
"A Dimension-Reduced Multivariate Spatial Model for Extreme Events:
  Balancing Flexibility and Scalability",2025-01-22T18:30:21Z,"Remy MacDonald, Benjamin Seiyon Lee, John Foley, Justin Lee","Modeling extreme precipitation and temperature is vital for understanding the
impacts of climate change, as hazards like intense rainfall and record-breaking
temperatures can result in severe consequences, including floods, droughts, and
wildfires. Gaining insight into the spatial variation and interactions between
these extremes is critical for effective risk management, early warning
systems, and informed policy-making. However, challenges such as the rarity of
extreme events, spatial dependencies, and complex cross-variable interactions
hinder accurate modeling. We introduce a novel framework for modeling spatial
extremes, building upon spatial generalized extreme value (GEV) models. Our
approach incorporates a dimension-reduced latent spatial process to improve
scalability and flexibility, particularly in capturing asymmetry in
cross-covariance structures. This Joint Latent Spatial GEV model (JLS-GEV)
overcomes key limitations of existing methods by providing a more flexible
framework for inter-variable dependencies. In addition to addressing event
rarity, spatial dependence and cross-variable interactions, JLS-GEV supports
nonstationary spatial behaviors and independently collected data sources, while
maintaining practical fitting times through dimension reduction. We validate
JLS-GEV through extensive simulation studies, demonstrating its superior
performance in capturing spatial extremes compared to baseline modeling
approaches. Application to real-world data on extreme precipitation and
temperature in the southeastern United States highlights its practical utility.
While primarily motivated by environmental challenges, this framework is
broadly applicable to interdisciplinary studies of spatial extremes in
interdependent natural processes.",http://arxiv.org/abs/2501.13070v1
"A framework for river connectivity classification using temporal image
  processing and attention based neural networks",2025-02-01T16:00:28Z,"Timothy James Becker, Derin Gezgin, Jun Yi He Wu, Mary Becker","Measuring the connectivity of water in rivers and streams is essential for
effective water resource management. Increased extreme weather events
associated with climate change can result in alterations to river and stream
connectivity. While traditional stream flow gauges are costly to deploy and
limited to large river bodies, trail camera methods are a low-cost and easily
deployed alternative to collect hourly data. Image capturing, however requires
stream ecologists to manually curate (select and label) tens of thousands of
images per year. To improve this workflow, we developed an automated instream
trail camera image classification system consisting of three parts: (1) image
processing, (2) image augmentation and (3) machine learning. The image
preprocessing consists of seven image quality filters, foliage-based luma
variance reduction, resizing and bottom-center cropping. Images are balanced
using variable amount of generative augmentation using diffusion models and
then passed to a machine learning classification model in labeled form. By
using the vision transformer architecture and temporal image enhancement in our
framework, we are able to increase the 75% base accuracy to 90% for a new
unseen site image. We make use of a dataset captured and labeled by staff from
the Connecticut Department of Energy and Environmental Protection between
2018-2020. Our results indicate that a combination of temporal image processing
and attention-based models are effective at classifying unseen river
connectivity images.",http://arxiv.org/abs/2502.00474v1
"AquaticCLIP: A Vision-Language Foundation Model for Underwater Scene
  Analysis",2025-02-03T19:56:16Z,"Basit Alawode, Iyyakutti Iyappan Ganapathi, Sajid Javed, Naoufel Werghi, Mohammed Bennamoun, Arif Mahmood","The preservation of aquatic biodiversity is critical in mitigating the
effects of climate change. Aquatic scene understanding plays a pivotal role in
aiding marine scientists in their decision-making processes. In this paper, we
introduce AquaticCLIP, a novel contrastive language-image pre-training model
tailored for aquatic scene understanding. AquaticCLIP presents a new
unsupervised learning framework that aligns images and texts in aquatic
environments, enabling tasks such as segmentation, classification, detection,
and object counting. By leveraging our large-scale underwater image-text paired
dataset without the need for ground-truth annotations, our model enriches
existing vision-language models in the aquatic domain. For this purpose, we
construct a 2 million underwater image-text paired dataset using heterogeneous
resources, including YouTube, Netflix, NatGeo, etc. To fine-tune AquaticCLIP,
we propose a prompt-guided vision encoder that progressively aggregates patch
features via learnable prompts, while a vision-guided mechanism enhances the
language encoder by incorporating visual context. The model is optimized
through a contrastive pretraining loss to align visual and textual modalities.
AquaticCLIP achieves notable performance improvements in zero-shot settings
across multiple underwater computer vision tasks, outperforming existing
methods in both robustness and interpretability. Our model sets a new benchmark
for vision-language applications in underwater environments. The code and
dataset for AquaticCLIP are publicly available on GitHub at xxx.",http://arxiv.org/abs/2502.01785v1
"Integrating social capital with urban infrastructure networks for more
  resilient cities",2025-02-10T10:28:17Z,"Ariel Favier, Christine Hedde-von Westernhagen, Meghan Krieg, Bhaskar Kumawat","More than half of the world's population now lives in urban environments,
which concentrate services and infrastructure to satisfy the material needs of
a growing number of inhabitants. The interdependencies between physical
infrastructure systems are required for cities to function efficiently, but
simultaneously expose cities to new hazards. Failures that emerge from one
infrastructure system and cascade through these interdependencies are becoming
larger and more frequent due to climate change and growing urban environments.
Because of the uneven distribution of resources and basic services, cascade
failures often exacerbate pre-existing socioeconomic inequalities. Human
communities rely on both social capital and infrastructure services to prepare
for, manage, and recover from these challenging scenarios, but the overlap
between social and physical infrastructure creates unpredictable feedback
dynamics. While prior research has focused on either social capital or physical
infrastructure in urban disaster management, an integrative view of these two
perspectives is seldom explored. In this paper, the feedback mechanisms between
the physical and social layers of different urban designs are identified and
analyzed to optimize relief response. Methodologically, we identify cities with
high accessibility that have undergone disasters. From these cities, we measure
their physical and social resilience indicators before and after disaster as a
means to evaluate the impact of accessibility on disaster relief and
preparedness. We will supplement this empirical analysis with a simulation that
captures a cascade failure/disaster through a multilayer infrastructure and
social network model.",http://arxiv.org/abs/2502.06328v1
AstroLoc: Robust Space to Ground Image Localizer,2025-02-10T20:06:14Z,"Gabriele Berton, Alex Stoken, Carlo Masone","Astronauts take thousands of photos of Earth per day from the International
Space Station, which, once localized on Earth's surface, are used for a
multitude of tasks, ranging from climate change research to disaster
management. The localization process, which has been performed manually for
decades, has recently been approached through image retrieval solutions: given
an astronaut photo, find its most similar match among a large database of
geo-tagged satellite images, in a task called Astronaut Photography
Localization (APL). Yet, existing APL approaches are trained only using
satellite images, without taking advantage of the millions open-source
astronaut photos. In this work we present the first APL pipeline capable of
leveraging astronaut photos for training. We first produce full localization
information for 300,000 manually weakly labeled astronaut photos through an
automated pipeline, and then use these images to train a model, called
AstroLoc. AstroLoc learns a robust representation of Earth's surface features
through two losses: astronaut photos paired with their matching satellite
counterparts in a pairwise loss, and a second loss on clusters of satellite
imagery weighted by their relevance to astronaut photography via unsupervised
mining. We find that AstroLoc achieves a staggering 35% average improvement in
recall@1 over previous SOTA, pushing the limits of existing datasets with a
recall@100 consistently over 99%. Finally, we note that AstroLoc, without any
fine-tuning, provides excellent results for related tasks like the
lost-in-space satellite problem and historical space imagery localization.",http://arxiv.org/abs/2502.07003v1
"Resampling Methods that Generate Time Series Data to Enable Sensitivity
  and Model Analysis in Energy Modeling",2025-02-12T03:59:18Z,"Kelly Wang, Steven O. Kimbrough","Energy systems modeling frequently relies on time series data, whether
observed or forecast. This is particularly the case, for example, in capacity
planning models that use hourly production and load data forecast to occur over
the coming several decades. This paper addresses the attendant problem of
performing sensitivity, robustness, and other post-solution analyses using time
series data. We explore two efficient and relatively simple, non-parametric,
bootstrapping methods for generating arbitrary numbers of time series from a
single observed or forecast series. The paper presents and assesses each
method. We find that the generated series are both visually and by statistical
summary measures close to the original observational data. In consequence these
series are credibly taken as stochastic instances from a common distribution,
that of the original series of observations. With climate change in mind, the
paper further proposes and explores two general techniques for systematically
altering (increasing or decreasing) time series. Both for the perturbed and
unperturbed synthetic series data, we find that the generated series induce
variability in properties of the series that are important for energy modeling,
in particular periods of under- and over-production, and periods of increased
ramping rates. In consequence, series produced in this way are apt for use in
robustness, sensitivity, and in general post-solution analysis of energy
planning models. These validity factors auger well for applications beyond
energy modeling.",http://arxiv.org/abs/2502.08102v1
"Glacier data assimilation on an Arctic glacier: Learning from large
  ensemble twin experiments",2025-02-13T13:28:03Z,"Wenxue Cao, Kristoffer Aalstad, Louise S. Schmidt, Sebastian Westermann, Thomas V. Schuler","Glacier modeling is crucial for quantifying the evolution of cryospheric
processes. At the same time, uncertainties hamper process understanding and
predictive accuracy. Here, we suggest improving glacier mass balance
simulations for the Kongsvegen glacier in Svalbard through the application of
Bayesian data assimilation techniques in a set of large ensemble twin
experiments. Noisy synthetic observations of albedo and snow depth, generated
using the multilayer CryoGrid community model with a full energy balance, are
assimilated using two ensemble-based data assimilation schemes: the particle
batch smoother and the ensemble smoother. A comprehensive evaluation exercise
demonstrates that the joint assimilation of albedo and snow depth improves the
simulation skill by up to 86% relative to the prior in specific glacier
regions. The particle batch smoother excels in representing albedo dynamics,
while the ensemble smoother is particularly effective for snow depth under low
snowfall conditions. By combining the strengths of both observations, the joint
assimilation achieves improved mass balance simulations across different
glacier zones using either assimilation scheme. This work underscores the
potential of ensemble-based data assimilation methods for refining glacier
models by offering a robust framework to enhance predictive accuracy and reduce
uncertainties in cryospheric simulations. Further advances in glacier data
assimilation will be critical to better understanding the fate and role of
Arctic glaciers in a changing climate.",http://arxiv.org/abs/2502.09314v1
Entity Framing and Role Portrayal in the News,2025-02-20T16:44:46Z,"Tarek Mahmoud, Zhuohan Xie, Dimitar Dimitrov, Nikolaos Nikolaidis, Purificação Silvano, Roman Yangarber, Shivam Sharma, Elisa Sartori, Nicolas Stefanovitch, Giovanni Da San Martino, Jakub Piskorski, Preslav Nakov","We introduce a novel multilingual hierarchical corpus annotated for entity
framing and role portrayal in news articles. The dataset uses a unique taxonomy
inspired by storytelling elements, comprising 22 fine-grained roles, or
archetypes, nested within three main categories: protagonist, antagonist, and
innocent. Each archetype is carefully defined, capturing nuanced portrayals of
entities such as guardian, martyr, and underdog for protagonists; tyrant,
deceiver, and bigot for antagonists; and victim, scapegoat, and exploited for
innocents. The dataset includes 1,378 recent news articles in five languages
(Bulgarian, English, Hindi, European Portuguese, and Russian) focusing on two
critical domains of global significance: the Ukraine-Russia War and Climate
Change. Over 5,800 entity mentions have been annotated with role labels. This
dataset serves as a valuable resource for research into role portrayal and has
broader implications for news analysis. We describe the characteristics of the
dataset and the annotation process, and we report evaluation results on
fine-tuned state-of-the-art multilingual transformers and hierarchical
zero-shot learning using LLMs at the level of a document, a paragraph, and a
sentence.",http://arxiv.org/abs/2502.14718v1
Implications of zero-growth economics analysed with an agent-based model,2025-01-31T14:33:59Z,"Dylan C. Terry-Doyle, Adam B. Barrett","The ever-approaching limits of the Earth's biosphere and the potentially
catastrophic consequences caused by climate change have begun to call into
question the endless growth of the economy. There is increasing interest in the
prospects of zero economic growth from the degrowth and post-growth literature.
In particular, the question arises as to whether a zero-growth trajectory in a
capitalist system with interest-bearing debt can be economically stable. There
have been several answers to this question using macroeconomic models; some
find a zero-growth trajectory is stable, while other models show an economic
breakdown. However, the capitalist system in a period of growth is not
guaranteed to be stable. Hence, a more appropriate methodology is to compare
the relative stability between a growth and zero-growth scenario on the same
model. Such a question has not yet been answered at any disaggregated level.
It's important to investigate the consequences of zero-growth on market share
instability and concentration, bankruptcy rates, income distribution, and
credit network risk. To answer such questions, we develop a macroeconomic
agent-based model incorporating Minskyan financial dynamics. The growth and
zero-growth scenarios are accomplished by changing an average productivity
growth parameter for the firms in the model. The model results showed that real
GDP growth rates were more stable in the zero-growth scenario, there were fewer
economic crises, lower unemployment rates, a higher wage share of output for
workers, and capital firm and bank market shares were relatively more stable.
Some of the consequences of zero-growth were a higher rate of inflation than in
the growth scenario, increased market concentration for both firms and banks,
and a higher level of financial risk in the credit network.",http://arxiv.org/abs/2501.19168v1
"AI Driven Water Segmentation with deep learning models for Enhanced
  Flood Monitoring",2025-01-14T17:26:02Z,"Sanjida Afrin Mou, Tasfia Noor Chowdhury, Adib Ibn Mannan, Sadia Nourin Mim, Lubana Tarannum, Tasrin Noman, Jamal Uddin Ahamed","Flooding is a major natural hazard causing significant fatalities and
economic losses annually, with increasing frequency due to climate change.
Rapid and accurate flood detection and monitoring are crucial for mitigating
these impacts. This study compares the performance of three deep learning
models UNet, ResNet, and DeepLabv3 for pixelwise water segmentation to aid in
flood detection, utilizing images from drones, in field observations, and
social media. This study involves creating a new dataset that augments
wellknown benchmark datasets with flood-specific images, enhancing the
robustness of the models. The UNet, ResNet, and DeepLab v3 architectures are
tested to determine their effectiveness in various environmental conditions and
geographical locations, and the strengths and limitations of each model are
also discussed here, providing insights into their applicability in different
scenarios by predicting image segmentation masks. This fully automated approach
allows these models to isolate flooded areas in images, significantly reducing
processing time compared to traditional semi-automated methods. The outcome of
this study is to predict segmented masks for each image effected by a flood
disaster and the validation accuracy of these models. This methodology
facilitates timely and continuous flood monitoring, providing vital data for
emergency response teams to reduce loss of life and economic damages. It offers
a significant reduction in the time required to generate flood maps, cutting
down the manual processing time. Additionally, we present avenues for future
research, including the integration of multimodal data sources and the
development of robust deep learning architectures tailored specifically for
flood detection tasks. Overall, our work contributes to the advancement of
flood management strategies through innovative use of deep learning
technologies.",http://arxiv.org/abs/2501.08266v1
"A method for estimating forest carbon storage distribution density via
  artificial intelligence generated content model",2025-02-02T12:41:47Z,"Zhenyu Yu, Jinnian Wang","Forest is the most significant land-based carbon storage mechanism. The
forest carbon sink can effectively decrease the atmospheric CO2 concentration
and mitigate climate change. Remote sensing estimation not only ensures high
accuracy of data, but also enables large-scale area observation. Optical images
provide the possibility for long-term monitoring, which is a potential issue in
the future carbon storage estimation research. We chose Huize County, Qujing
City, Yunnan Province, China as the study area, took GF-1 WFV satellite image
as the data, introduced the KD-VGG module to extract the initial features, and
proposed the improved implicit diffusion model (IIDM). The results showed that:
(1) The VGG-19 module after knowledge distillation can realize the initial
feature extraction, reduce the inference time and improve the accuracy in the
case of reducing the number of model parameters. (2) The Attention + MLP module
was added for feature fusion to obtain the relationship between global and
local features and realized the restoration of high-fidelity images in the
continuous scale range. (3) The IIDM model proposed in this paper had the
highest estimation accuracy, with RMSE of 28.68, which was 13.16 higher than
that of the regression model, about 31.45%. In the estimation of carbon
storage, the generative model can extract deeper features, and its performance
was significantly better than other models. It demonstrated the feasibility of
artificial intelligence-generated content (AIGC) in the field of quantitative
remote sensing and provided valuable insights for the study of carbon
neutralization effect. By combining the actual characteristics of the forest,
the regional carbon storage estimation with a resolution of 16-meter was
utilized to provide a significant theoretical basis for the formulation of
forest carbon sink regulation.",http://arxiv.org/abs/2502.00783v1
"Building Age Estimation: A New Multi-Modal Benchmark Dataset and
  Community Challenge",2025-02-19T15:31:13Z,"Nikolaos Dionelis, Nicolas Longépé, Alessandra Feliciotti, Mattia Marconcini, Devis Peressutti, Nika Oman Kadunc, JaeWan Park, Hagai Raja Sinulingga, Steve Andreas Immanuel, Ba Tran, Caroline Arnold","Estimating the construction year of buildings is of great importance for
sustainability. Sustainable buildings minimize energy consumption and are a key
part of responsible and sustainable urban planning and development to
effectively combat climate change. By using Artificial Intelligence (AI) and
recently proposed Transformer models, we are able to estimate the construction
epoch of buildings from a multi-modal dataset. In this paper, we introduce a
new benchmark multi-modal dataset, i.e. the Map your City Dataset (MyCD),
containing top-view Very High Resolution (VHR) images, Earth Observation (EO)
multi-spectral data from the Copernicus Sentinel-2 satellite constellation, and
street-view images in many different cities in Europe, co-localized with
respect to the building under study and labelled with the construction epoch.
We assess EO generalization performance on new/ previously unseen cities that
have been held-out from training and appear only during inference. In this
work, we present the community-based data challenge we organized based on MyCD.
The ESA AI4EO Challenge MapYourCity was opened in 2024 for 4 months. Here, we
present the Top-4 performing models, and the main evaluation results. During
inference, the performance of the models using both all three input modalities
and only the two top-view modalities, i.e. without the street-view images, is
examined. The evaluation results show that the models are effective and can
achieve good performance on this difficult real-world task of estimating the
age of buildings, even on previously unseen cities, as well as even using only
the two top-view modalities (i.e. VHR and Sentinel-2) during inference.",http://arxiv.org/abs/2502.13818v1
"Improving Zero-Shot Object-Level Change Detection by Incorporating
  Visual Correspondence",2025-01-09T20:02:10Z,"Hung Huy Nguyen, Pooyan Rahmanzadehgervi, Long Mai, Anh Totti Nguyen","Detecting object-level changes between two images across possibly different
views is a core task in many applications that involve visual inspection or
camera surveillance. Existing change-detection approaches suffer from three
major limitations: (1) lack of evaluation on image pairs that contain no
changes, leading to unreported false positive rates; (2) lack of
correspondences (i.e., localizing the regions before and after a change); and
(3) poor zero-shot generalization across different domains. To address these
issues, we introduce a novel method that leverages change correspondences (a)
during training to improve change detection accuracy, and (b) at test time, to
minimize false positives. That is, we harness the supervision labels of where
an object is added or removed to supervise change detectors, improving their
accuracy over previous work by a large margin. Our work is also the first to
predict correspondences between pairs of detected changes using estimated
homography and the Hungarian algorithm. Our model demonstrates superior
performance over existing methods, achieving state-of-the-art results in change
detection and change correspondence accuracy across both in-distribution and
zero-shot benchmarks.",http://arxiv.org/abs/2501.05555v2
"Explainable Lane Change Prediction for Near-Crash Scenarios Using
  Knowledge Graph Embeddings and Retrieval Augmented Generation",2025-01-20T16:02:26Z,"M. Manzour, A. Ballardini, R. Izquierdo, M. Á. Sotelo","Lane-changing maneuvers, particularly those executed abruptly or in risky
situations, are a significant cause of road traffic accidents. However, current
research mainly focuses on predicting safe lane changes. Furthermore, existing
accident datasets are often based on images only and lack comprehensive sensory
data. In this work, we focus on predicting risky lane changes using the CRASH
dataset (our own collected dataset specifically for risky lane changes), and
safe lane changes (using the HighD dataset). Then, we leverage KG and Bayesian
inference to predict these maneuvers using linguistic contextual information,
enhancing the model's interpretability and transparency. The model achieved a
91.5% f1-score with anticipation time extending to four seconds for risky lane
changes, and a 90.0% f1-score for predicting safe lane changes with the same
anticipation time. We validate our model by integrating it into a vehicle
within the CARLA simulator in scenarios that involve risky lane changes. The
model managed to anticipate sudden lane changes, thus providing automated
vehicles with further time to plan and execute appropriate safe reactions.
Finally, to enhance the explainability of our model, we utilize RAG to provide
clear and natural language explanations for the given prediction.",http://arxiv.org/abs/2501.11560v1
"Quantification of Flagellar Gait Changes with Combined Shape Mode
  Analysis and Swimming Simulations",2025-01-02T22:10:47Z,"Kelli E. Gutierrez, Robert D. Guy, Becca Thomases, Paulo E. Arratia","Many different microswimmers propel themselves using flagella that beat
periodically. The shape of the flagellar beat and swimming speed have been
observed to change with fluid rheology. We quantify changes in the flagellar
waveforms of Chlamydomonas reinhardtii in response to changes in fluid
viscosity using (1) shape mode analysis and (2) a full swimmer simulation to
analyze how shape changes affect the swimming speed and to explore the
dimensionality of the shape space. By decomposing the gait into the
time-independent mean shape and the time-varying stroke, we find that the
flagellar mean shape substantially changes in response to viscosity, while the
changes in the time-varying stroke are more subtle. Using the swimmer
simulation, we quantify how the swimming speed is affected by the
dimensionality of the flagellar shape reconstruction, and we show that the
observed change in swimming speed with viscosity is explained by the variations
in mean flagellar shape and beat frequency, while the changes in swimming speed
from the different time-varying strokes are on the scale of variation between
cells.",http://arxiv.org/abs/2501.01554v1
"Identifying rapid changes in the hemodynamic response in event-related
  functional magnetic resonance imaging",2025-02-18T16:12:04Z,"Friederike Preusse, Thorsten Dickhaus, André Brechmann","The hemodynamic response (HR) in event-related functional magnetic resonance
imaging is typically assumed to be stationary. While there are some approaches
in the literature to model nonstationary HRs, few focus on rapid changes. In
this work, we propose two procedures to investigate rapid changes in the HR.
Both procedures make inference on the existence of rapid changes for
multi-subject data. We allow the change point locations to vary between
subjects, conditions and brain regions. The first procedure utilizes available
information about the change point locations to compare multiple shape
parameters of the HR over time. In the second procedure, the change point
locations are determined for each subject separately. To account for the
estimation of the change point locations, we propose the notion of post
selection variance. The power of the proposed procedures is assessed in
simulation studies. We apply the procedure for pre-specified change point
locations to data from a category learning experiment.",http://arxiv.org/abs/2502.12989v1
"Change Point Detection for Random Objects with Possibly Periodic
  Behavior",2025-01-03T06:20:19Z,"Jiazhen Xu, Andrew T. A. Wood, Tao Zou","Time-varying random objects have been increasingly encountered in modern data
analysis. Moreover, in a substantial number of these applications, periodic
behavior of the random objects has been observed. We introduce a new, powerful
scan statistic and corresponding test for the precise identification and
localization of abrupt changes in the distribution of non-Euclidean random
objects with possibly periodic behavior. Our approach is nonparametric and
effectively captures the entire distribution of these random objects.
Remarkably, it operates with minimal tuning parameters, requiring only the
specification of cut-off intervals near endpoints, where change points are
assumed not to occur. Our theoretical contributions include deriving the
asymptotic distribution of the test statistic under the null hypothesis of no
change points, establishing the consistency of the test in the presence of
change points under contiguous alternatives and providing rigorous guarantees
on the near-optimal consistency in estimating the number and locations of
change points, whether dealing with a single change point or multiple ones. We
demonstrate that the most competitive method currently in the literature for
change point detection in random objects is degraded by periodic behavior, as
periodicity leads to blurring of the changes that this procedure aims to
discover. Through comprehensive simulation studies, we demonstrate the superior
power and accuracy of our approach in both detecting change points and
pinpointing their locations, across scenarios involving both periodic and
nonperiodic random objects. Our main application is to weighted networks,
represented through graph Laplacians. The proposed method delivers highly
interpretable results, as evidenced by the identification of meaningful change
points in the New York City Citi Bike sharing system that align with
significant historical events.",http://arxiv.org/abs/2501.01657v1
"Semantic-CD: Remote Sensing Image Semantic Change Detection towards
  Open-vocabulary Setting",2025-01-12T13:22:11Z,"Yongshuo Zhu, Lu Li, Keyan Chen, Chenyang Liu, Fugen Zhou, Zhenwei Shi","Remote sensing image semantic change detection is a method used to analyze
remote sensing images, aiming to identify areas of change as well as categorize
these changes within images of the same location taken at different times.
Traditional change detection methods often face challenges in generalizing
across semantic categories in practical scenarios. To address this issue, we
introduce a novel approach called Semantic-CD, specifically designed for
semantic change detection in remote sensing images. This method incorporates
the open vocabulary semantics from the vision-language foundation model, CLIP.
By utilizing CLIP's extensive vocabulary knowledge, our model enhances its
ability to generalize across categories and improves segmentation through fully
decoupled multi-task learning, which includes both binary change detection and
semantic change detection tasks. Semantic-CD consists of four main components:
a bi-temporal CLIP visual encoder for extracting features from bi-temporal
images, an open semantic prompter for creating semantic cost volume maps with
open vocabulary, a binary change detection decoder for generating binary change
detection masks, and a semantic change detection decoder for producing semantic
labels. Experimental results on the SECOND dataset demonstrate that Semantic-CD
achieves more accurate masks and reduces semantic classification errors,
illustrating its effectiveness in applying semantic priors from vision-language
foundation models to SCD tasks.",http://arxiv.org/abs/2501.06808v1
"ME-CPT: Multi-Task Enhanced Cross-Temporal Point Transformer for Urban
  3D Change Detection",2025-01-23T13:07:41Z,"Luqi Zhang, Haiping Wang, Chong Liu, Zhen Dong, Bisheng Yang","The point clouds collected by the Airborne Laser Scanning (ALS) system
provide accurate 3D information of urban land covers. By utilizing
multi-temporal ALS point clouds, semantic changes in urban area can be
captured, demonstrating significant potential in urban planning, emergency
management, and infrastructure maintenance. Existing 3D change detection
methods struggle to efficiently extract multi-class semantic information and
change features, still facing the following challenges: (1) the difficulty of
accurately modeling cross-temporal point clouds spatial relationships for
effective change feature extraction; (2) class imbalance of change samples
which hinders distinguishability of semantic features; (3) the lack of
real-world datasets for 3D semantic change detection. To resolve these
challenges, we propose the Multi-task Enhanced Cross-temporal Point Transformer
(ME-CPT) network. ME-CPT establishes spatiotemporal correspondences between
point cloud across different epochs and employs attention mechanisms to jointly
extract semantic change features, facilitating information exchange and change
comparison. Additionally, we incorporate a semantic segmentation task and
through the multi-task training strategy, further enhance the
distinguishability of semantic features, reducing the impact of class imbalance
in change types. Moreover, we release a 22.5 $km^2$ 3D semantic change
detection dataset, offering diverse scenes for comprehensive evaluation.
Experiments on multiple datasets show that the proposed MT-CPT achieves
superior performance compared to existing state-of-the-art methods. The source
code and dataset will be released upon acceptance at
https://github.com/zhangluqi0209/ME-CPT.",http://arxiv.org/abs/2501.14004v2
High-Dimensional Sequential Change Detection,2025-02-07T23:15:06Z,"Robert Malinas, Dogyoon Song, Benjamin D. Robinson, Alfred O. Hero III","We address the problem of detecting a change in the distribution of a
high-dimensional multivariate normal time series. Assuming that the post-change
parameters are unknown and estimated using a window of historical data, we
extend the framework of quickest change detection (QCD) to the highdimensional
setting in which the number of variables increases proportionally with the size
of the window used to estimate the post-change parameters. Our analysis reveals
that an information theoretic quantity, which we call the Normalized High-
Dimensional Kullback-Leibler divergence (NHDKL), governs the high-dimensional
asymptotic performance of QCD procedures. Specifically, we show that the
detection delay is asymptotically inversely proportional to the difference
between the NHDKL of the true post-change versus pre-change distributions and
the NHDKL of the true versus estimated post-change distributions. In cases of
perfect estimation, where the latter NHDKL is zero, the delay is inversely
proportional to the NHDKL between the post-change and pre-change distributions
alone. Thus, our analysis is a direct generalization of the traditional
fixed-dimension, large-sample asymptotic framework, where the standard KL
divergence is asymptotically inversely proportional to detection delay.
Finally, we identify parameter estimators that asymptotically minimize the
NHDKL between the true versus estimated post-change distributions, resulting in
a QCD method that is guaranteed to outperform standard approaches based on
fixed-dimension asymptotics.",http://arxiv.org/abs/2502.05377v2
Sensitivity of Room Impulse Responses in Changing Acoustic Environment,2025-01-02T11:30:12Z,Karolina Prawda,"Changes in room acoustics, such as modifications to surface absorption or the
insertion of a scattering object, significantly impact measured room impulse
responses (RIRs). These changes can affect the performance of systems used in
echo cancellation and active acoustics and support tasks such as navigation and
object tracking. Recognizing and quantifying such changes is, therefore,
critical for advancing technologies based on room acoustics. This study
introduces a method for analyzing acoustic environment changes by evaluating
the similarity of consecutively recorded RIRs. Short-time coherence is employed
to characterize modifications, including changes in wall absorption or the
presence of a moving person in the room. A sensitivity rating is further used
to quantify the magnitude of these changes. The results clearly differentiate
between types of modifications -- atmospheric variation, changes in absorption,
and human presence. The methods described provide a novel approach to analyzing
and interpreting room acoustics, emphasizing RIR similarity and extracting
information from temporal and spectral signal properties.",http://arxiv.org/abs/2501.01206v1
Metamaterials that learn to change shape,2025-01-21T08:09:52Z,"Yao Du, Jonas Veenstra, Ryan van Mastrigt, Corentin Coulais","Learning to change shape is a fundamental strategy of adaptation and
evolution of living organisms, from bacteria and cells to tissues and animals.
Human-made materials can also exhibit advanced shape morphing capabilities, but
lack the ability to learn. Here, we build metamaterials that can learn complex
shape-changing responses using a contrastive learning scheme. By being shown
examples of the target shape changes, our metamaterials are able to learn those
shape changes by progressively updating internal learning degrees of freedom --
the local stiffnesses. Unlike traditional materials that are designed once and
for all, our metamaterials have the ability to forget and learn new shape
changes in sequence, to learn multiple shape changes that break reciprocity,
and to learn multistable shape changes, which in turn allows them to perform
reflex gripping actions and locomotion. Our findings establish metamaterials as
an exciting platform for physical learning, which in turn opens avenues for the
use of physical learning to design adaptive materials and robots.",http://arxiv.org/abs/2501.11958v1
DynamicEarth: How Far are We from Open-Vocabulary Change Detection?,2025-01-22T15:02:43Z,"Kaiyu Li, Xiangyong Cao, Yupeng Deng, Chao Pang, Zepeng Xin, Deyu Meng, Zhi Wang","Monitoring Earth's evolving land covers requires methods capable of detecting
changes across a wide range of categories and contexts. Existing change
detection methods are hindered by their dependency on predefined classes,
reducing their effectiveness in open-world applications. To address this issue,
we introduce open-vocabulary change detection (OVCD), a novel task that bridges
vision and language to detect changes across any category. Considering the lack
of high-quality data and annotation, we propose two training-free frameworks,
M-C-I and I-M-C, which leverage and integrate off-the-shelf foundation models
for the OVCD task. The insight behind the M-C-I framework is to discover all
potential changes and then classify these changes, while the insight of I-M-C
framework is to identify all targets of interest and then determine whether
their states have changed. Based on these two frameworks, we instantiate to
obtain several methods, e.g., SAM-DINOv2-SegEarth-OV, Grounding-DINO-SAM2-DINO,
etc. Extensive evaluations on 5 benchmark datasets demonstrate the superior
generalization and robustness of our OVCD methods over existing supervised and
unsupervised methods. To support continued exploration, we release
DynamicEarth, a dedicated codebase designed to advance research and application
of OVCD. https://likyoo.github.io/DynamicEarth",http://arxiv.org/abs/2501.12931v1
Non-evolutionary effects on period change in Magellanic Cepheids,2025-01-03T12:13:09Z,"R. S. Rathour, R. Smolec, G. Hajdu, P. Karczmarek, V. Hocdé, O. Ziółkowska, I. Soszyński, A. Udalski","Classical Cepheids are a cornerstone class of pulsators, fundamental to
testing stellar evolution and pulsation theories. Their secular period changes,
characterized through $O-C$ (Observed minus Calculated) diagrams, offer
valuable insights into their evolution. While evolutionary period changes are
well understood from both observational and theoretical perspectives, shorter
timescale period changes (on the order of ($\sim$ 10$^{2}$-10$^{4}$ days) -
known as non-evolutionary period changes are yet to be systematically explored.
  In this work, we present a detailed and comprehensive search for
non-evolutionary period changes using $O-C$ analysis of Magellanic Cloud (MC)
Cepheids, based on 20+ years of OGLE photometry data. Our sample includes both
the Large Magellanic Cloud (LMC) and the Small Magellanic Cloud (SMC) Cepheids,
focusing on single radial mode Cepheids (both fundamental (FU) and first
overtone (FO) modes). The results are grouped into two phenomena: (a) Cepheids
in binary systems (b) Non-linear period changes.",http://arxiv.org/abs/2501.01777v2
"Change Detection-Based Procedures for Piecewise Stationary MABs: A
  Modular Approach",2025-01-02T15:18:18Z,"Yu-Han Huang, Argyrios Gerogiannis, Subhonmesh Bose, Venugopal V. Veeravalli","Conventional Multi-Armed Bandit (MAB) algorithms are designed for stationary
environments, where the reward distributions associated with the arms do not
change with time. In many applications, however, the environment is more
accurately modeled as being nonstationary. In this work, piecewise stationary
MAB (PS-MAB) environments are investigated, in which the reward distributions
associated with a subset of the arms change at some change-points and remain
stationary between change-points. Our focus is on the asymptotic analysis of
PS-MABs, for which practical algorithms based on change detection (CD) have
been previously proposed. Our goal is to modularize the design and analysis of
such CD-based Bandit (CDB) procedures. To this end, we identify the
requirements for stationary bandit algorithms and change detectors in a CDB
procedure that are needed for the modularization. We assume that the rewards
are sub-Gaussian. Under this assumption and a condition on the separation of
the change-points, we show that the analysis of CDB procedures can indeed be
modularized, so that regret bounds can be obtained in a unified manner for
various combinations of change detectors and bandit algorithms. Through this
analysis, we develop new modular CDB procedures that are order-optimal. We
compare the performance of our modular CDB procedures with various other
methods in simulations.",http://arxiv.org/abs/2501.01291v1
The NuSTAR view of five changing-look active galactic nuclei,2025-01-16T15:23:22Z,"Bing Lyu, Zhen Yan, Xue-bing Wu, Qingwen Wu, Wenfei Yu, Hao Liu","Changing-look active galactic nuclei (CLAGNs) are known to change their
spectral type between 1 and 2 (changing-state) or change their absorption
between Compton-thick and Compton-thin (changing-obscuration) on timescales of
years or less. The physical mechanism and possible connection between the two
types of CLAGNs are still unclear. We explore the evolution of the broadband
X-ray spectra from Nuclear Spectroscopic Telescope Array (\nustar\,) and column
density in five CLAGNs with moderate inclination viewing angles, which have
shown significant variations of both optical types and X-ray absorption. Based
on a phenomenological and two clumpy torus models, we find that the X-ray
photon index ($\Gamma$) and the Eddington-scaled X-ray $2-10$ keV luminosity
($L_{\rm X}/L_{\rm Edd}$) are positively correlated for the five sources, which
are similar to other bright AGNs and optical CLAGNs at type 1 phase. We find a
significant negative correlation between log$N_\mathrm{H,los}$ and log$L_{\rm
X}/L_{\rm Edd}$ except for ESO 362-G18. Similar to changing-state AGNs,
changing-obscuration AGNs may be also triggered by the evolution of the
accretion disc. Our results support the disc wind scenario, where the disc wind
proportional to the accretion rate and formed at moderate inclination angles
would push the obscuration material further away and decrease the column
density from the line of sight observed in the changing-look AGNs.",http://arxiv.org/abs/2501.09602v1
"A Remote Sensing Image Change Detection Method Integrating Layer
  Exchange and Channel-Spatial Differences",2025-01-19T00:14:20Z,"Sijun Dong, Fangcheng Zuo, Geng Chen, Siming Fu, Xiaoliang Meng","Change detection in remote sensing imagery is a critical technique for Earth
observation, primarily focusing on pixel-level segmentation of change regions
between bi-temporal images. The essence of pixel-level change detection lies in
determining whether corresponding pixels in bi-temporal images have changed. In
deep learning, the spatial and channel dimensions of feature maps represent
different information from the original images. In this study, we found that in
change detection tasks, difference information can be computed not only from
the spatial dimension of bi-temporal features but also from the channel
dimension. Therefore, we designed the Channel-Spatial Difference Weighting
(CSDW) module as an aggregation-distribution mechanism for bi-temporal features
in change detection. This module enhances the sensitivity of the change
detection model to difference features. Additionally, bi-temporal images share
the same geographic location and exhibit strong inter-image correlations. To
construct the correlation between bi-temporal images, we designed a decoding
structure based on the Layer-Exchange (LE) method to enhance the interaction of
bi-temporal features. Comprehensive experiments on the CLCD, PX-CLCD, LEVIR-CD,
and S2Looking datasets demonstrate that the proposed LENet model significantly
improves change detection performance. The code and pre-trained models will be
available at: https://github.com/dyzy41/lenet.",http://arxiv.org/abs/2501.10905v1
"Plug-and-Play DISep: Separating Dense Instances for Scene-to-Pixel
  Weakly-Supervised Change Detection in High-Resolution Remote Sensing Images",2025-01-09T02:52:30Z,"Zhenghui Zhao, Chen Wu, Lixiang Ru, Di Wang, Hongruixuan Chen, Cuiqun Chen","Existing Weakly-Supervised Change Detection (WSCD) methods often encounter
the problem of ""instance lumping"" under scene-level supervision, particularly
in scenarios with a dense distribution of changed instances (i.e., changed
objects). In these scenarios, unchanged pixels between changed instances are
also mistakenly identified as changed, causing multiple changes to be
mistakenly viewed as one. In practical applications, this issue prevents the
accurate quantification of the number of changes. To address this issue, we
propose a Dense Instance Separation (DISep) method as a plug-and-play solution,
refining pixel features from a unified instance perspective under scene-level
supervision. Specifically, our DISep comprises a three-step iterative training
process: 1) Instance Localization: We locate instance candidate regions for
changed pixels using high-pass class activation maps. 2) Instance Retrieval: We
identify and group these changed pixels into different instance IDs through
connectivity searching. Then, based on the assigned instance IDs, we extract
corresponding pixel-level features on a per-instance basis. 3) Instance
Separation: We introduce a separation loss to enforce intra-instance pixel
consistency in the embedding space, thereby ensuring separable instance feature
representations. The proposed DISep adds only minimal training cost and no
inference cost. It can be seamlessly integrated to enhance existing WSCD
methods. We achieve state-of-the-art performance by enhancing {three
Transformer-based and four ConvNet-based methods} on the LEVIR-CD, WHU-CD,
DSIFN-CD, SYSU-CD, and CDD datasets. Additionally, our DISep can be used to
improve fully-supervised change detection methods. Code is available at
https://github.com/zhenghuizhao/Plug-and-Play-DISep-for-Change-Detection.",http://arxiv.org/abs/2501.04934v2
Flavor-changing Lorentz and CPT violation in muonic atoms,2025-01-10T14:18:05Z,"Alan Kostelecky, W. P. McNulty, E. Passemar, N. Sherrill","Flavor-changing signatures of Lorentz and CPT violation involving
muon-electron conversions in muonic atoms are studied using effective field
theory. Constraints on coefficients for Lorentz violation at parts in
$10^{-12}$ GeV$^{-1}$ for flavor-changing electromagnetic muon decays and parts
in $10^{-13}$ GeV$^{-2}$ for flavor-changing 4-point quark-lepton interactions
are extracted using existing data from the SINDRUM II experiment at the Paul
Scherrer Institute. Estimates are provided for sensitivities attainable in the
forthcoming experiments Mu2e at Fermilab and COMET at the Japan Proton
Accelerator Complex.",http://arxiv.org/abs/2501.05986v1
"Seismic regularity coefficient changes precede stronger earthquakes in
  Santorini swarm",2025-02-17T12:58:26Z,"Stanislaw Lasocki, Beata Orlecka-Sikora, Anastasios Kostoglou, Vasileios G. Karakostas, Eleftheria E. Papadimitrio","We have been analyzing the ongoing seismic swarm in Santorini, Greece, with
the Seismic Regularity (dc) and Seismic Strain Dynamics (SSD) coefficients,
which quantify temporal changes in seismic process organization and strain
energy release. Stronger earthquakes are preceded by characteristic down-up
changes of dc. Such a change indicates an increase in the seismic process
regularity followed by a fast transition to a more irregular and chaotic
seismic regime.",http://arxiv.org/abs/2502.11768v1
"CD-Lamba: Boosting Remote Sensing Change Detection via a Cross-Temporal
  Locally Adaptive State Space Model",2025-01-26T08:51:10Z,"Zhenkai Wu, Xiaowen Ma, Rongrong Lian, Kai Zheng, Mengting Ma, Wei Zhang, Siyang Song","Mamba, with its advantages of global perception and linear complexity, has
been widely applied to identify changes of the target regions within the remote
sensing (RS) images captured under complex scenarios and varied conditions.
However, existing remote sensing change detection (RSCD) approaches based on
Mamba frequently struggle to effectively perceive the inherent locality of
change regions as they direct flatten and scan RS images (i.e., the features of
the same region of changes are not distributed continuously within the sequence
but are mixed with features from other regions throughout the sequence). In
this paper, we propose a novel locally adaptive SSM-based approach, termed
CD-Lamba, which effectively enhances the locality of change detection while
maintaining global perception. Specifically, our CD-Lamba includes a Locally
Adaptive State-Space Scan (LASS) strategy for locality enhancement, a
Cross-Temporal State-Space Scan (CTSS) strategy for bi-temporal feature fusion,
and a Window Shifting and Perception (WSP) mechanism to enhance interactions
across segmented windows. These strategies are integrated into a multi-scale
Cross-Temporal Locally Adaptive State-Space Scan (CT-LASS) module to
effectively highlight changes and refine changes' representations feature
generation. CD-Lamba significantly enhances local-global spatio-temporal
interactions in bi-temporal images, offering improved performance in RSCD
tasks. Extensive experimental results show that CD-Lamba achieves
state-of-the-art performance on four benchmark datasets with a satisfactory
efficiency-accuracy trade-off. Our code is publicly available at
https://github.com/xwmaxwma/rschange.",http://arxiv.org/abs/2501.15455v1
"Detecting Abrupt Changes in Point Processes: Fundamental Limits and
  Applications",2025-01-14T19:14:24Z,"Anna Brandenberger, Elchanan Mossel, Anirudh Sridhar","We consider the problem of detecting abrupt changes (i.e., large jump
discontinuities) in the rate function of a point process. The rate function is
assumed to be fully unknown, non-stationary, and may itself be a random process
that depends on the history of event times. We show that abrupt changes can be
accurately identified from observations of the point process, provided the
changes are sharper than the ""smoothness'' of the rate function before the
abrupt change. This condition is also shown to be necessary from an
information-theoretic point of view. We then apply our theory to several
special cases of interest, including the detection of significant changes in
piecewise smooth rate functions and detecting super-spreading events in
epidemic models on graphs. Finally, we confirm the effectiveness of our methods
through a detailed empirical analysis of both synthetic and real datasets.",http://arxiv.org/abs/2501.08392v1
"Multiple change point detection based on Hodrick-Prescott and $l_1$
  filtering method for random walk time series data",2025-01-21T00:47:45Z,Xiyuan Liu,"We propose new methods for detecting multiple change points in time series,
specifically designed for random walk processes, where stationarity and
variance changes present challenges. Our approach combines two trend estimation
methods: the Hodrick Prescott (HP) filter and the l1 filter. A major challenge
in these methods is selecting the tuning parameter lambda, which we address by
introducing two selection techniques. For the HP based change point detection,
we propose a probability-based threshold to select lambda under the assumption
of an exponential distribution. For the l1 based method, we suggest a selection
strategy assuming normality. Additionally, we introduce a technique to estimate
the maximum number of change points in time segments using the l1 based method.
We validate our methods by comparing them to similar techniques, such as PELT,
using simulated data. We also demonstrate the practical application of our
approach to real-world SNP stock data, showcasing its effectiveness in
detecting change points.",http://arxiv.org/abs/2501.11805v2
Hypo3D: Exploring Hypothetical Reasoning in 3D,2025-02-02T23:11:42Z,"Ye Mao, Weixun Luo, Junpeng Jing, Anlan Qiu, Krystian Mikolajczyk","The rise of vision-language foundation models marks an advancement in
bridging the gap between human and machine capabilities in 3D scene reasoning.
Existing 3D reasoning benchmarks assume real-time scene accessibility, which is
impractical due to the high cost of frequent scene updates. To this end, we
introduce Hypothetical 3D Reasoning, namely Hypo3D, a benchmark designed to
evaluate models' ability to reason without access to real-time scene data.
Models need to imagine the scene state based on a provided change description
before reasoning. Hypo3D is formulated as a 3D Visual Question Answering (VQA)
benchmark, comprising 7,727 context changes across 700 indoor scenes, resulting
in 14,885 question-answer pairs. An anchor-based world frame is established for
all scenes, ensuring consistent reference to a global frame for directional
terms in context changes and QAs. Extensive experiments show that
state-of-the-art foundation models struggle to reason in hypothetically changed
scenes. This reveals a substantial performance gap compared to humans,
particularly in scenarios involving movement changes and directional reasoning.
Even when the context change is irrelevant to the question, models often
incorrectly adjust their answers.",http://arxiv.org/abs/2502.00954v2
"EHCTNet: Enhanced Hybrid of CNN and Transformer Network for Remote
  Sensing Image Change Detection",2025-01-02T12:55:36Z,"Junjie Yang, Haibo Wan, Zhihai Shang","Remote sensing (RS) change detection incurs a high cost because of false
negatives, which are more costly than false positives. Existing frameworks,
struggling to improve the Precision metric to reduce the cost of false
positive, still have limitations in focusing on the change of interest, which
leads to missed detections and discontinuity issues. This work tackles these
issues by enhancing feature learning capabilities and integrating the frequency
components of feature information, with a strategy to incrementally boost the
Recall value. We propose an enhanced hybrid of CNN and Transformer network
(EHCTNet) for effectively mining the change information of interest. Firstly, a
dual branch feature extraction module is used to extract the multi scale
features of RS images. Secondly, the frequency component of these features is
exploited by a refined module I. Thirdly, an enhanced token mining module based
on the Kolmogorov Arnold Network is utilized to derive semantic information.
Finally, the semantic change information's frequency component, beneficial for
final detection, is mined from the refined module II. Extensive experiments
validate the effectiveness of EHCTNet in comprehending complex changes of
interest. The visualization outcomes show that EHCTNet detects more intact and
continuous changed areas and perceives more accurate neighboring distinction
than state of the art models.",http://arxiv.org/abs/2501.01238v1
"CI at Scale: Lean, Green, and Fast",2025-01-07T00:04:29Z,"Dhruva Juloori, Zhongpeng Lin, Matthew Williams, Eddy Shin, Sonal Mahajan","Maintaining a ""green"" mainline branch, where all builds pass successfully, is
crucial but challenging in fast-paced, large-scale software development
environments, particularly with concurrent code changes in large monorepos.
SubmitQueue, a system designed to address these challenges, speculatively
executes builds and only lands changes with successful outcomes. However,
despite its effectiveness, the system faces inefficiencies in resource
utilization, leading to a high rate of premature build aborts and delays in
landing smaller changes blocked by larger conflicting ones. This paper
introduces enhancements to SubmitQueue, focusing on optimizing resource usage
and improving build prioritization. Central to this is our innovative
probabilistic model, which distinguishes between changes with shorter and
longer build times to prioritize builds for more efficient scheduling. By
leveraging a machine learning model to predict build times and incorporating
this into the probabilistic framework, we expedite the landing of smaller
changes blocked by conflicting larger time-consuming changes. Additionally,
introducing a concept of speculation threshold ensures that only the most
likely builds are executed, reducing unnecessary resource consumption. After
implementing these enhancements across Uber's major monorepos (Go, iOS, and
Android), we observed a reduction in Continuous Integration (CI) resource usage
by approximately 53%, CPU usage by 44%, and P95 waiting times by 37%. These
improvements highlight the enhanced efficiency of SubmitQueue in managing
large-scale software changes while maintaining a green mainline.",http://arxiv.org/abs/2501.03440v1
"Automatic detection and prediction of nAMD activity change in retinal
  OCT using Siamese networks and Wasserstein Distance for ordinality",2025-01-24T08:35:22Z,"Taha Emre, Teresa Araújo, Marzieh Oghbaie, Dmitrii Lachinov, Guilherme Aresta, Hrvoje Bogunović","Neovascular age-related macular degeneration (nAMD) is a leading cause of
vision loss among older adults, where disease activity detection and
progression prediction are critical for nAMD management in terms of timely drug
administration and improving patient outcomes. Recent advancements in deep
learning offer a promising solution for predicting changes in AMD from optical
coherence tomography (OCT) retinal volumes. In this work, we proposed deep
learning models for the two tasks of the public MARIO Challenge at MICCAI 2024,
designed to detect and forecast changes in nAMD severity with longitudinal
retinal OCT. For the first task, we employ a Vision Transformer (ViT) based
Siamese Network to detect changes in AMD severity by comparing scan embeddings
of a patient from different time points. To train a model to forecast the
change after 3 months, we exploit, for the first time, an Earth Mover
(Wasserstein) Distance-based loss to harness the ordinal relation within the
severity change classes. Both models ranked high on the preliminary
leaderboard, demonstrating that their predictive capabilities could facilitate
nAMD treatment management.",http://arxiv.org/abs/2501.14323v1
"Functional limit theorems for a time-changed multidimensional Wiener
  process",2025-01-18T16:46:18Z,"Yuliia Mishura, René L. Schilling","We study the asymptotic behaviour of a properly normalized time-changed
multidimensional Wiener process; the time change is given by an additive
functional of the Wiener process itself. At the level of generators, the time
change means that we consider the Laplace operator -- which generates a
multidimensional Wiener process -- and multiply it by a (possibly degenerate)
state-space dependent intensity. We assume that the intensity admits limits at
infinity in each octant of the state space, but the values of these limits may
be different. Applying a functional limit theorem for the superposition of
stochastic processes, we prove functional limit theorems for the normalized
time-changed multidimensional Wiener process. Among the possible limits there
is a multidimensional analogue of skew Brownian motion.",http://arxiv.org/abs/2501.10820v1
Towards Change Impact Analysis in Microservices-based System Evolution,2025-01-20T23:08:26Z,"Tomas Cerny, Gabriel Goulis, Amr S. Abdelfattah","Cloud-native systems are the mainstream for enterprise solutions, given their
scalability, resilience, and other benefits. While the benefits of cloud-native
systems fueled by microservices are known, less guidance exists on their
evolution. One could assume that since microservices encapsulate their code,
code changes remain encapsulated as well; however, the community is becoming
more aware of the possible consequences of code change propagation across
microservices. Moreover, an active mitigation instrument for negative
consequences of change propagation across microservices (i.e., ripple effect)
is yet missing, but the microservice community would greatly benefit from it.
This paper introduces what it could look like to have an infrastructure to
assist with change impact analysis across the entire microservice system and
intends to facilitate advancements in laying out the foundations and building
guidelines on microservice system evolution. It shares a new direction for
incremental software architecture reconstruction that could serve as the
infrastructure concept and demonstrates early results from prototyping to
illustrate the potential impact.",http://arxiv.org/abs/2501.11778v1
"CoDocBench: A Dataset for Code-Documentation Alignment in Software
  Maintenance",2025-02-01T18:45:32Z,"Kunal Pai, Premkumar Devanbu, Toufique Ahmed","One of the central tasks in software maintenance is being able to understand
and develop code changes. Thus, given a natural language description of the
desired new operation of a function, an agent (human or AI) might be asked to
generate the set of edits to that function to implement the desired new
operation; likewise, given a set of edits to a function, an agent might be
asked to generate a changed description, of that function's new workings. Thus,
there is an incentive to train a neural model for change-related tasks.
Motivated by this, we offer a new, ""natural"", large dataset of coupled changes
to code and documentation mined from actual high-quality GitHub projects, where
each sample represents a single commit where the code and the associated
docstring were changed together. We present the methodology for gathering the
dataset, and some sample, challenging (but realistic) tasks where our dataset
provides opportunities for both learning and evaluation. We find that current
models (specifically Llama-3.1 405B, Mixtral 8$\times$22B) do find these
maintenance-related tasks challenging.",http://arxiv.org/abs/2502.00519v2
"Online Correlation Change Detection for Large-Dimensional Data with An
  Application to Forecasting of El Niño Events",2025-02-03T03:02:34Z,"Jie Gao, Liyan Xie, Zhaoyuan Li","We consider detecting change points in the correlation structure of streaming
large-dimensional data with minimum assumptions posed on the underlying data
distribution. Depending on the $\ell_1$ and $\ell_{\infty}$ norms of the
squared difference of vectorized pre-change and post-change correlation
matrices, detection statistics are constructed for dense and sparse settings,
respectively. The proposed detection procedures possess the bless-dimension
property, as a novel algorithm for threshold selection is designed based on
sign-flip permutation. Theoretical evaluations of the proposed methods are
conducted in terms of average run length and expected detection delay.
Numerical studies are conducted to examine the finite sample performances of
the proposed methods. Our methods are effective because the average detection
delays have slopes similar to that of the optimal exact CUSUM test. Moreover, a
combined $\ell_1$ and $\ell_{\infty}$ norm approach is proposed and has
expected performance for transitions from sparse to dense settings. Our method
is applied to forecast El Ni{\~n}o events and achieves state-of-the-art hit
rates greater than 0.86, while false alarm rates are 0. This application
illustrates the efficiency and effectiveness of our proposed methodology in
detecting fundamental changes with minimal delay.",http://arxiv.org/abs/2502.01010v1
"Generalized Counting Process with Random Drift and Different Brownian
  Clocks",2025-02-03T13:56:26Z,"Mostafizar Khandakar, Manisha Dhillon, Kuldeep Kumar Kataria","In this paper, we introduce drifted versions of the generalized counting
process (GCP) with a deterministic drift and a random drift. The composition of
stable subordinator with an independent inverse stable subordinator is taken as
the random drift. We derive the probability law and its governing fractional
differential equations for these drifted versions. Also, we study the GCP
time-changed with different Brownian clocks, for example, the Brownian first
passage-time with or without drift, elastic Brownian motion, Brownian sojourn
time on positive half-line and the Bessel times. For these time-changed
processes, we obtain the governing system of differential equation of their
state probabilities, probability generating function, etc. Further, we consider
a time-changed GCP where the time-change is done by subordinators linked to
incomplete gamma function. Later, we study the fractional integral of GCP and
its time-changed variant.",http://arxiv.org/abs/2502.01363v1
"Streaming Speaker Change Detection and Gender Classification for
  Transducer-Based Multi-Talker Speech Translation",2025-02-04T19:50:15Z,"Peidong Wang, Naoyuki Kanda, Jian Xue, Jinyu Li, Xiaofei Wang, Aswin Shanmugam Subramanian, Junkun Chen, Sunit Sivasankaran, Xiong Xiao, Yong Zhao","Streaming multi-talker speech translation is a task that involves not only
generating accurate and fluent translations with low latency but also
recognizing when a speaker change occurs and what the speaker's gender is.
Speaker change information can be used to create audio prompts for a zero-shot
text-to-speech system, and gender can help to select speaker profiles in a
conventional text-to-speech model. We propose to tackle streaming speaker
change detection and gender classification by incorporating speaker embeddings
into a transducer-based streaming end-to-end speech translation model. Our
experiments demonstrate that the proposed methods can achieve high accuracy for
both speaker change detection and gender classification.",http://arxiv.org/abs/2502.02683v1
Time change rigidity for unipotent flows,2025-02-12T03:06:12Z,"Elon Lindenstrauss, Daren Wei","We prove a dichotomy regarding the behavior of one-parameter unipotent flows
on quotients of semisimple lie groups under time change. We show that if
$u^{(1)}_t$ acting on $\mathbf{G}_{1}/\Gamma_1$ is such a flow it satisfies
exactly one of the following:
  (1) The flow is loosely Kronecker, and hence measurably isomorphic after an
appropriate time change to any other loosely Kronecker system.
  (2) The flow exhibits the following rigid behavior: if the one-parameter
unipotent flow $u^{(1)} _ t$ on $\mathbf{G}_1/\Gamma_1$ is measurably
isomorphic after time change to another such flow $u^{(2)} _ t$ on
$\mathbf{G}_2/\Gamma _ 2$, then $\mathbf{G}_1/\Gamma_1 $ is isomorphic to
$\mathbf{G}_2/ \Gamma_2$ with the isomorphism taking $u^{(1)}_t$ to $u^{(2)}_t$
and moreover the time change is cohomologous to a trivial one up to a
renormalization.",http://arxiv.org/abs/2502.08081v1
"Change-point problem: Direct estimation using a geometry inspired
  re-parametrization",2025-02-17T11:13:17Z,"Buddhananda Banerjee, Arnab Kumar Laha","Estimation of mean shift in a temporally ordered sequence of random variables
with a possible existence of change-point is an important problem in many
disciplines. In the available literature of more than fifty years the
estimation methods of the mean shift is usually dealt as a two-step problem. A
test for the existence of a change-point is followed by an estimation process
of the mean shift, which is known as testimator. The problem suffers from over
parametrization. When viewed as an estimation problem, we establish that the
maximum likelihood estimator (MLE) always gives a false alarm indicting an
existence of a change-point in the given sequence even though there is no
change-point at all. After modelling the parameter space as a modified horn
torus. We introduce a new method of estimation of the parameters. The newly
introduced estimation method of the mean shift is assessed with a proper
Riemannian metric on that conic manifold. It is seen that its performance is
superior compared to that of the MLE. The proposed method is implemented on
Bitcoin data and compared its performance with the performance of the MLE.",http://arxiv.org/abs/2502.11679v1
"Phase-change materials for volatile threshold resistive switching and
  neuronal device applications",2025-02-17T11:22:35Z,"Huandong Chen, Jayakanth Ravichandran","Volatile threshold resistive switching and neuronal oscillations in
phase-change materials, specifically those undergoing metal-to-insulator and
charge density wave transitions, offer unique attributes such as fast and
low-field volatile switching, tunability, and non-linear behaviors. These
characteristics are particularly promising for emulating neuronal behavior and
thus hold great potential for realizing energy-efficient neuromorphic
computing. In this review, we summarize recent advances in the development of
neuronal oscillator devices based on three archetypal electronic phase-change
materials: the correlated oxide VO2, the charge density wave transition metal
dichalcogenide 1T-TaS2, and the emerging phase-change chalcogenide perovskite
BaTiS3. We discuss progress from the perspective of materials development,
including structural phase transitions, synthesis methods, electrical
properties, and device implementation. Finally, we emphasize the major
challenges that must be addressed for practical applications of these
phase-change materials and provide our outlook on the future research
directions in this rapidly evolving field.",http://arxiv.org/abs/2502.11685v1
"How do Humans take an Object from a Robot: Behavior changes observed in
  a User Study",2025-01-03T22:41:14Z,"Parag Khanna, Elmira Yadollahi, Iolanda Leite, Mårten Björkman, Christian Smith","To facilitate human-robot interaction and gain human trust, a robot should
recognize and adapt to changes in human behavior. This work documents different
human behaviors observed while taking objects from an interactive robot in an
experimental study, categorized across two dimensions: pull force applied and
handedness. We also present the changes observed in human behavior upon
repeated interaction with the robot to take various objects.",http://arxiv.org/abs/2501.02127v1
"Maximum-Entropy-Rate Selection of Features for Classifying Changes in
  Knee and Ankle Dynamics During Running",2025-01-23T15:30:39Z,"Garry A. Einicke, Haider A. Sabti, David V. Thiel, Marta Fernandez","This paper investigates deteriorations in knee and ankle dynamics during
running. Changes in lower limb accelerations are analyzed by a wearable
musculo-skeletal monitoring system. The system employs a machine learning
technique to classify joint stiffness. A maximum-entropyrate method is
developed to select the most relevant features. Experimental results
demonstrate that distance travelled and energy expended can be estimated from
observed changes in knee and ankle motions during 5 km runs.",http://arxiv.org/abs/2501.13750v1
Passing through nondegenerate singularities in mean curvature flows,2025-01-28T03:24:31Z,"Ao Sun, Zhihan Wang, Jinxin Xue","In this paper, we study the properties of nondegenerate cylindrical
singularities of mean curvature flow. We prove they are isolated in spacetime
and provide a complete description of the geometry and topology change of the
flow passing through the singularities. Particularly, the topology change
agrees with the level sets change near a critical point of a Morse function,
which is the same as performing surgery. The proof is based on a new
$L^2$-distance monotonicity formula, which allows us to derive a discrete
almost monotonicity of the ``decay order"", a discrete mean curvature flow
analog to Almgren's frequency function.",http://arxiv.org/abs/2501.16678v1
"The simplest solutions of cold plasma equations: change in properties
  from a hydrodynamic to a kinetic model",2025-01-29T18:01:25Z,"Lidia V. Gargyants, Olga S. Rozanova","We consider the transition from the kinetic model of Landau cold plasma to
the hydrodynamic one by constructing a ""multi-speed"" moment chain in the case
of one spatial variable. Closing this chain at the first step leads to the
standard hydrodynamic system of cold plasma. The change in the properties of
the solution when closing the chain at the second step is discussed using the
example of two classes of solutions - affine in space and traveling waves, and
it is shown that their properties change significantly compared to the
hydrodynamic model.",http://arxiv.org/abs/2501.17812v1
"A Methodology for Studying Linguistic and Cultural Change in China,
  1900-1950",2025-02-06T18:33:50Z,Spencer Dean Stewart,"This paper presents a quantitative approach to studying linguistic and
cultural change in China during the first half of the twentieth century, a
period that remains understudied in computational humanities research. The
dramatic changes in Chinese language and culture during this time call for
greater reflection on the tools and methods used for text analysis. This
preliminary study offers a framework for analyzing Chinese texts from the late
nineteenth and twentieth centuries, demonstrating how established methods such
as word counts and word embeddings can provide new historical insights into the
complex negotiations between Western modernity and Chinese cultural discourse.",http://arxiv.org/abs/2502.04286v1
"Dynamics of ""Spontaneous"" Topic Changes in Next Token Prediction with
  Self-Attention",2025-01-10T23:18:23Z,"Mumin Jia, Jairo Diaz-Rodriguez","Human cognition can spontaneously shift conversation topics, often triggered
by emotional or contextual signals. In contrast, self-attention-based language
models depend on structured statistical cues from input tokens for next-token
prediction, lacking this spontaneity. Motivated by this distinction, we
investigate the factors that influence the next-token prediction to change the
topic of the input sequence. We define concepts of topic continuity, ambiguous
sequences, and change of topic, based on defining a topic as a set of token
priority graphs (TPGs). Using a simplified single-layer self-attention
architecture, we derive analytical characterizations of topic changes.
Specifically, we demonstrate that (1) the model maintains the priority order of
tokens related to the input topic, (2) a topic change can occur only if
lower-priority tokens outnumber all higher-priority tokens of the input topic,
and (3) unlike human cognition, longer context lengths and overlapping topics
reduce the likelihood of spontaneous redirection. These insights highlight
differences between human cognition and self-attention-based models in
navigating topic changes and underscore the challenges in designing
conversational AI capable of handling ""spontaneous"" conversations more
naturally. To the best of our knowledge, no prior work has explored these
questions with a focus as closely aligned to human conversation and thought.",http://arxiv.org/abs/2501.06382v2
"Evaluating Amazon Effects and the Limited Impact of COVID-19 With
  Purchases Crowdsourced from US Consumers",2025-01-17T23:03:56Z,"Alex Berke, Dana Calacci, Alex, Pentland, Kent Larson","We leverage a recently published dataset of Amazon purchase histories,
crowdsourced from thousands of US consumers, to study how online purchasing
behaviors have changed over time, how changes vary across demographic groups,
the impact of the COVID-19 pandemic, and relationships between online and
offline retail. This work provides a case study in how consumer-level purchases
data can reveal purchasing behaviors and trends beyond those available from
aggregate metrics. For example, in addition to analyzing spending behavior, we
develop new metrics to quantify changes in consumers' online purchase frequency
and the diversity of products purchased, to better reflect the growing ubiquity
and dominance of online retail. Between 2018 and 2022 these consumer-level
metrics grew on average by more than 85%, peaking in 2021. We find a steady
upward trend in individuals' online purchasing prior to COVID-19, with a
significant increase in the first year of COVID, but without a lasting effect.
Purchasing behaviors in 2022 were no greater than the result of the
pre-pandemic trend. We also find changes in purchasing significantly differ by
demographics, with different responses to the pandemic. We further use the
consumer-level data to show substitution effects between online and offline
retail in sectors where Amazon heavily invested: books, shoes, and grocery.
Prior to COVID we find year-to-year changes in the number of consumers making
online purchases for books and shoes negatively correlated with changes in
employment at local bookstores and shoe stores. During COVID we find online
grocery purchasing negatively correlated with in-store grocery visits. This
work demonstrates how crowdsourced, open purchases data can enable economic
insights that may otherwise only be available to private firms.",http://arxiv.org/abs/2501.10596v1
"A Detailed Look at a Trio of Changing-Look Quasars: Spectral Energy
  Distributions and the Dust Extinction Test",2025-01-22T19:04:54Z,"Laura Duffy, Michael Eracleous, Jessie C. Runnoe, John J. Ruan, Scott F. Anderson, Sabrina Dimassimo, Paul Green, Stephanie LaMassa","Changing-look quasars exhibit dramatic variability in broad emission-line
fluxes on short timescales. This behavior is challenging to many models of the
quasar broad line region, due in large part to the short transition times
between high and low states. In order to constrain the cause of the dramatic
variability, we obtained contemporaneous Hubble Space Telescope UV and Hobby
Eberly Telescope optical spectra of three changing-look quasars caught in their
low state. We use these spectra, along with archival spectra taken during both
the high and low states, to investigate potential scenarios for the change in
state. Our data strongly disfavor a variable dust obscuration scenario for
these three CLQs, and instead suggest that the observed transformation reflects
a change in the intrinsic luminosity of the central engine. We also find that
the low-state spectral energy distributions of all three quasars are
reminiscent of those of low-luminosity active galactic nuclei, which suggests
that the transition may result from a change in accretion flow structure caused
by a reduced Eddington ratio.",http://arxiv.org/abs/2501.13174v1
Monitorization of the H-O Bond Flexibility,2025-01-01T03:12:18Z,Chang Q Sun,"Unlike conventional thought, the H-O bond is flexible, instead, and sensitive
to perturbation. This exercise empowers the electron and phonon spectroscopies
with the Tight-binding approach, enabling a referential database to
synchronically quantize the relaxation and flexibility of these identities for
substances involving the H-O bond during phonon spectroscopy.",http://arxiv.org/abs/2501.01469v1
Variations on the Expectation Due to Changes in the Probability Measure,2025-02-05T04:56:28Z,"Samir M. Perlaza, Gaetan Bisson","Closed-form expressions are presented for the variation of the expectation of
a given function due to changes in the probability measure used for the
expectation. They unveil interesting connections with Gibbs probability
measures, the mutual information, and the lautum information.",http://arxiv.org/abs/2502.02887v1
On the spectral theory of sign-changing Laplace operators,2025-02-06T07:47:20Z,Yves Colin de Verdière,"We study spectral theory of sign-changing Laplace operators using
semi-classical Dirichlet-to-Neumann maps. We prove the existence of
modesconcentrated on the interface and describe an effective semi-classical
equation for them.",http://arxiv.org/abs/2502.03838v1
Resurrecting saturated LLM benchmarks with adversarial encoding,2025-02-10T18:07:09Z,"Igor Ivanov, Dmitrii Volkov","Recent work showed that small changes in benchmark questions can reduce LLMs'
reasoning and recall. We explore two such changes: pairing questions and adding
more answer options, on three benchmarks: WMDP-bio, GPQA, and MMLU variants. We
find that for more capable models, these predictably reduce performance,
essentially heightening the performance ceiling of a benchmark and unsaturating
it again. We suggest this approach can resurrect old benchmarks.",http://arxiv.org/abs/2502.06738v1
"WeVibe: Weight Change Estimation Through Audio-Induced Shelf Vibrations
  In Autonomous Stores",2025-02-17T18:10:53Z,"Jiale Zhang, Yuyan Wu, Jesse R Codling, Yen Cheng Chang, Julia Gersey, Pei Zhang, Hae Young Noh, Yiwen Dong","Weight change estimation is crucial in various applications, particularly for
detecting pick-up and put-back actions when people interact with the shelf
while shopping in autonomous stores. Moreover, accurate weight change
estimation allows autonomous stores to automatically identify items being
picked up or put back, ensuring precise cost estimation. However, the
conventional approach of estimating weight changes requires specialized
weight-sensing shelves, which are densely deployed weight scales, incurring
intensive sensor consumption and high costs. Prior works explored the
vibration-based weight sensing method, but they failed when the location of
weight change varies.
  In response to these limitations, we made the following contributions: (1) We
propose WeVibe, a first item weight change estimation system through active
shelf vibration sensing. The main intuition of the system is that the weight
placed on the shelf influences the dynamic vibration response of the shelf,
thus altering the shelf vibration patterns. (2) We model a physics-informed
relationship between the shelf vibration response and item weight across
multiple locations on the shelf based on structural dynamics theory. This
relationship is linear and allows easy training of a weight estimation model at
a new location without heavy data collection. (3) We evaluate our system on a
gondola shelf organized as the real-store settings. WeVibe achieved a mean
absolute error down to 38.07g and a standard deviation of 31.2g with one sensor
and 10% samples from three weight classes on estimating weight change from 0g
to 450g, which can be leveraged for differentiating items with more than 100g
differences.",http://arxiv.org/abs/2502.12093v1
"The Change of Variable Formula Integrals, do they have equal value?",2025-02-18T09:35:13Z,Oswaldo Rio Branco de Oliveira,"Assuming that the two integrals in the Change of Variable Formula for the
unidimensional Riemann integral are finite, one can ask if they have equal
value. We give an answer to this question. The proof is very easy to follow and
to keep in mind. Two examples are given.",http://arxiv.org/abs/2502.12679v1
"New bounds in R.S. Lehman's estimates for the difference $π\left(
  x\right) -li\left( x\right) $",2025-01-08T13:14:54Z,Michael Revers,"We denote by $\pi\left( x\right) $ the usual prime counting function and let
$li\left( x\right) $ the logarithmic integral of $x$. In 1966, R.S. Lehman came
up with a new approach and an effective method for finding an upper bound where
it is assured that a sign change occurs for $\pi\left( x\right) -li\left(
x\right) $ for some value $x$ not higher than this given bound. In this paper
we provide further improvements on the error terms including an improvement
upon Lehman's famous error term $S_{3}$ in his original paper. We are now able
to eliminate the lower condition for the size-length $\eta$ completely. For
further numerical computations this enables us to establish sharper results on
the positions for the sign changes. We illustrate with some numerical
computations on the lowest known crossover regions near $10^{316}$ and we
discuss numerically on potential crossover regions below this value.",http://arxiv.org/abs/2501.04488v2
"Sequential Change Detection for Learning in Piecewise Stationary Bandit
  Environments",2025-01-19T07:27:24Z,"Yu-Han Huang, Venugopal V. Veeravalli","A finite-horizon variant of the quickest change detection problem is
investigated, which is motivated by a change detection problem that arises in
piecewise stationary bandits. The goal is to minimize the \emph{latency}, which
is smallest threshold such that the probability that the detection delay
exceeds the threshold is below a desired low level, while controlling the false
alarm probability to a desired low level. When the pre- and post-change
distributions are unknown, two tests are proposed as candidate solutions. These
tests are shown to attain order optimality in terms of the horizon.
Furthermore, the growth in their latencies with respect to the false alarm
probability and late detection probability satisfies a property that is
desirable in regret analysis for piecewise stationary bandits. Numerical
results are provided to validate the theoretical performance results.",http://arxiv.org/abs/2501.10974v2
Sequential Change Point Detection via Denoising Score Matching,2025-01-22T06:04:57Z,"Wenbin Zhou, Liyan Xie, Zhigang Peng, Shixiang Zhu","Sequential change-point detection plays a critical role in numerous
real-world applications, where timely identification of distributional shifts
can greatly mitigate adverse outcomes. Classical methods commonly rely on
parametric density assumptions of pre- and post-change distributions, limiting
their effectiveness for high-dimensional, complex data streams. This paper
proposes a score-based CUSUM change-point detection, in which the score
functions of the data distribution are estimated by injecting noise and
applying denoising score matching. We consider both offline and online versions
of score estimation. Through theoretical analysis, we demonstrate that
denoising score matching can enhance detection power by effectively controlling
the injected noise scale. Finally, we validate the practical efficacy of our
method through numerical experiments on two synthetic datasets and a real-world
earthquake precursor detection task, demonstrating its effectiveness in
challenging scenarios.",http://arxiv.org/abs/2501.12667v1
"A control system framework for counterfactuals: an optimization based
  approach",2025-01-22T14:43:05Z,"Pierluigi Francesco De Paola, Jared Miller, Alessandro Borri, Alessia Paglialonga, Fabrizio Dabbene","Counterfactuals are a concept inherited from the field of logic and in
general attain to the existence of causal relations between sentences or
events. In particular, this concept has been introduced also in the context of
interpretability in artificial intelligence, where counterfactuals refer to the
minimum change to the feature values that changes the prediction of a
classification model. The artificial intelligence framework of counterfactuals
is mostly focused on machine learning approaches, typically neglecting the
physics of the variables that determine a change in class. However, a
theoretical formulation of counterfactuals in a control system framework -
i.e., able to account for the mechanisms underlying a change in class - is
lacking. To fill this gap, in this work we propose an original control system,
physics-informed, theoretical foundation for counterfactuals, by means of the
formulation of an optimal control problem. We apply the proposed methodology to
a general glucose-insulin regulation model and results appear promising and
pave the way to the possible integration with artificial intelligence
techniques, with the aim of feeding machine learning models with the physics
knowledge acquired through the system framework.",http://arxiv.org/abs/2501.12914v1
Fixed-Budget Change Point Identification in Piecewise Constant Bandits,2025-01-22T15:30:44Z,"Joseph Lazzaro, Ciara Pike-Burke","We study the piecewise constant bandit problem where the expected reward is a
piecewise constant function with one change point (discontinuity) across the
action space $[0,1]$ and the learner's aim is to locate the change point. Under
the assumption of a fixed exploration budget, we provide the first
non-asymptotic analysis of policies designed to locate abrupt changes in the
mean reward function under bandit feedback. We study the problem under a large
and small budget regime, and for both settings establish lower bounds on the
error probability and provide algorithms with near matching upper bounds.
Interestingly, our results show a separation in the complexity of the two
regimes. We then propose a regime adaptive algorithm which is near optimal for
both small and large budgets simultaneously. We complement our theoretical
analysis with experimental results in simulated environments to support our
findings.",http://arxiv.org/abs/2501.12957v1
"Targeting heuristics for cost-optimized institutional incentives in
  heterogeneous networked populations",2025-01-23T12:45:08Z,"Dhruv Mittal, Fátima González-Novo López, Sara Constantino, Shaul Shalvi, Xiaojie Chen, Vítor V. Vasconcelos","The world is currently grappling with challenges on both local and global
scales, many of which demand coordinated behavioral changes. However, breaking
away from the status is often difficult due to deeply ingrained social norms.
In such cases, social systems may require seemingly exogenous interventions to
set off endogenous, largely irreversible processes that drive change -- social
tipping. While studies have looked at targeted interventions, real-life
constraints faced by policymakers, like minimizing costs while ensuring a quick
and fair transition, remain understudied. To address this complexity, we
introduce a game-theoretic framework that accounts for individual heterogeneity
and networks of local influence. We implement various heuristics based on
information about individual preferences and commonly used local network
properties. Results show that where the change is initiated in the population
and the direction in which it propagates is essential to the effectiveness of
interventions. We identify optimal strategies under different scenarios, such
as varying levels of resistance to change, preference heterogeneity, and
homophily. These results provide insights that can be experimentally tested and
help policymakers to better direct incentives.",http://arxiv.org/abs/2501.13623v1
Sampling with time-changed Markov processes,2025-01-25T09:37:59Z,"Andrea Bertazzi, Giorgos Vasdekis","We study time-changed Markov processes to speed up the convergence of Markov
chain Monte Carlo (MCMC) algorithms in the context of multimodal distributions
and rare event simulation. The time-changed process is defined by adjusting the
speed of time of a base process via a user-chosen, state-dependent function. We
apply this framework to several Markov processes from the MCMC literature, such
as Langevin diffusions and piecewise deterministic Markov processes, obtaining
novel modifications of classical algorithms and also re-discovering known MCMC
algorithms. We prove theoretical properties of the time-changed process under
suitable conditions on the base process, focusing on connecting the stationary
distributions and qualitative convergence properties such as geometric and
uniform ergodicity, as well as a functional central limit theorem. A comparison
with the framework of space transformations is provided, clarifying the
similarities between the approaches. Throughout the paper we give various
visualisations and numerical simulations on simple tasks to gain intuition on
the method and its performance.",http://arxiv.org/abs/2501.15155v1
"Pareto sensitivity, most-changing sub-fronts, and knee solutions",2025-01-28T14:50:50Z,"Tommaso Giovannelli, Marcos Medeiros Raimundo, Luis Nunes Vicente","When dealing with a multi-objective optimization problem, obtaining a
comprehensive representation of the Pareto front can be computationally
expensive. Furthermore, identifying the most representative Pareto solutions
can be difficult and sometimes ambiguous. A popular selection are the so-called
Pareto knee solutions, where a small improvement in any objective leads to a
large deterioration in at least one other objective. In this paper, using
Pareto sensitivity, we show how to compute Pareto knee solutions according to
their verbal definition of least maximal change. We refer to the resulting
approach as the sensitivity knee (snee) approach, and we apply it to
unconstrained and constrained problems. Pareto sensitivity can also be used to
compute the most-changing Pareto sub-fronts around a Pareto solution, where the
points are distributed along directions of maximum change, which could be of
interest in a decision-making process if one is willing to explore solutions
around a current one. Our approach is still restricted to scalarized methods,
in particular to the weighted-sum or epsilon-constrained methods, and require
the computation or approximations of first- and second-order derivatives. We
include numerical results from synthetic problems that illustrate the benefits
of our approach.",http://arxiv.org/abs/2501.16993v1
"A Proof of The Changepoint Detection Threshold Conjecture in
  Preferential Attachment Models",2025-02-01T18:19:36Z,"Hang Du, Shuyang Gong, Jiaming Xu","We investigate the problem of detecting and estimating a changepoint in the
attachment function of a network evolving according to a preferential
attachment model on $n$ vertices, using only a single final snapshot of the
network. Bet et al.~\cite{bet2023detecting} show that a simple test based on
thresholding the number of vertices with minimum degrees can detect the
changepoint when the change occurs at time $n-\Omega(\sqrt{n})$. They further
make the striking conjecture that detection becomes impossible for any test if
the change occurs at time $n-o(\sqrt{n}).$ Kaddouri et
al.~\cite{kaddouri2024impossibility} make a step forward by proving the
detection is impossible if the change occurs at time $n-o(n^{1/3}).$ In this
paper, we resolve the conjecture affirmatively, proving that detection is
indeed impossible if the change occurs at time $n-o(\sqrt{n}).$ Furthermore, we
establish that estimating the changepoint with an error smaller than
$o(\sqrt{n})$ is also impossible, thereby confirming that the estimator
proposed in Bhamidi et al.~\cite{bhamidi2018change} is order-optimal.",http://arxiv.org/abs/2502.00514v1
Modelling change in neural dynamics during phonetic accommodation,2025-02-03T10:00:29Z,"Sam Kirkham, Patrycja Strycharczuk, Rob Davies, Danielle Welburn","Short-term phonetic accommodation is a fundamental driver behind accent
change, but how does real-time input from another speaker's voice shape the
speech planning representations of an interlocutor? We advance a computational
model of change in phonetic representations during phonetic accommodation,
grounded in dynamic neural field equations for movement planning and memory
dynamics. We test the model's ability to capture empirical patterns from an
experimental study where speakers shadowed a model talker with a different
accent from their own. The experimental data shows vowel-specific degrees of
convergence during shadowing, followed by return to baseline (or minor
divergence) post-shadowing. The model can reproduce these phenomena by
modulating the magnitude of inhibitory memory dynamics, which may reflect
resistance to accommodation due to phonological and/or sociolinguistic
pressures. We discuss the implications of these results for the relation
between short-term phonetic accommodation and longer-term patterns of sound
change.",http://arxiv.org/abs/2502.01210v1
"The ""negative end"" of change in grammar: terminology, concepts and
  causes",2025-02-07T07:54:08Z,Karolina Rudnicka,"The topic of ""negative end"" of change is, contrary to the fields of
innovation and emergence, largely under-researched. Yet, it has lately started
to gain an increasing attention from language scholars worldwide. The main
focus of this article is threefold, namely to discuss the i) terminology; ii)
concepts and iii) causes associated with the ""negative end"" of change in
grammar. The article starts with an overview of research conducted on the
topic. It then moves to situating phenomena referred to as loss, decline or
obsolescence among processes of language change, before elaborating on the
terminology and concepts behind it. The last part looks at possible causes for
constructions to display a (gradual or rapid, but very consistent) decrease in
the frequency of use over time, which continues until the construction
disappears or there are only residual or fossilised forms left. Keywords: loss,
obsolescence, decline, competition, higher",http://arxiv.org/abs/2502.04729v1
Post-detection inference for sequential changepoint localization,2025-02-10T02:01:30Z,"Aytijhya Saha, Aaditya Ramdas","This paper addresses a fundamental but largely unexplored challenge in
sequential changepoint analysis: conducting inference following a detected
change. We study the problem of localizing the changepoint using only the data
observed up to a data-dependent stopping time at which a sequential detection
algorithm $\mathcal A$ declares a change. We first construct confidence sets
for the unknown changepoint when pre- and post-change distributions are assumed
to be known. We then extend our framework to composite pre- and post-change
scenarios. We impose no conditions on the observation space or on $\mathcal A$
-- we only need to be able to run $\mathcal A$ on simulated data sequences. In
summary, this work offers both theoretically sound and practically effective
tools for sequential changepoint localization.",http://arxiv.org/abs/2502.06096v1
"Kernels of Selfhood: GPT-4o shows humanlike patterns of cognitive
  consistency moderated by free choice",2025-01-27T02:25:12Z,"Steven A. Lehr, Ketan S. Saichandran, Eddie Harmon-Jones, Nykko Vitali, Mahzarin R. Banaji","Large Language Models (LLMs) show emergent patterns that mimic human
cognition. We explore whether they also mirror other, less deliberative human
psychological processes. Drawing upon classical theories of cognitive
consistency, two preregistered studies tested whether GPT-4o changed its
attitudes toward Vladimir Putin in the direction of a positive or negative
essay it wrote about the Russian leader. Indeed, GPT displayed patterns of
attitude change mimicking cognitive consistency effects in humans. Even more
remarkably, the degree of change increased sharply when the LLM was offered an
illusion of choice about which essay (positive or negative) to write. This
result suggests that GPT-4o manifests a functional analog of humanlike
selfhood, although how faithfully the chatbot's behavior reflects the
mechanisms of human attitude change remains to be understood.",http://arxiv.org/abs/2502.07088v1
Difference-in-Differences and Changes-in-Changes with Sample Selection,2025-02-12T18:03:11Z,Javier Viviens,"Sample selection arises endogenously in causal research when the treatment
affects whether certain units are observed. It is a common pitfall in
longitudinal studies, particularly in settings where treatment assignment is
confounded. In this paper, I highlight the drawbacks of one of the most popular
identification strategies in such settings: Difference-in-Differences (DiD).
Specifically, I employ principal stratification analysis to show that the
conventional ATT estimand may not be well defined, and the DiD estimand cannot
be interpreted causally without additional assumptions. To address these
issues, I develop an identification strategy to partially identify causal
effects on the subset of units with well-defined and observed outcomes under
both treatment regimes. I adapt Lee bounds to the Changes-in-Changes (CiC)
setting (Athey & Imbens, 2006), leveraging the time dimension of the data to
relax the unconfoundedness assumption in the original trimming strategy of Lee
(2009). This setting has the DiD identification strategy as a particular case,
which I also implement in the paper. Additionally, I explore how to leverage
multiple sources of sample selection to relax the monotonicity assumption in
Lee (2009), which may be of independent interest. Alongside the identification
strategy, I present estimators and inference results. I illustrate the
relevance of the proposed methodology by analyzing a job training program in
Colombia.",http://arxiv.org/abs/2502.08614v1
"Deployment-friendly Lane-changing Intention Prediction Powered by
  Brain-inspired Spiking Neural Networks",2025-02-09T06:33:47Z,"Shuqi Shen, Junjie Yang, Hui Zhong, Qiming Zhang, Hongliang Lu, Hai Yang","Accurate and real-time prediction of surrounding vehicles' lane-changing
intentions is a critical challenge in deploying safe and efficient autonomous
driving systems in open-world scenarios. Existing high-performing methods
remain hard to deploy due to their high computational cost, long training
times, and excessive memory requirements. Here, we propose an efficient
lane-changing intention prediction approach based on brain-inspired Spiking
Neural Networks (SNN). By leveraging the event-driven nature of SNN, the
proposed approach enables us to encode the vehicle's states in a more efficient
manner. Comparison experiments conducted on HighD and NGSIM datasets
demonstrate that our method significantly improves training efficiency and
reduces deployment costs while maintaining comparable prediction accuracy.
Particularly, compared to the baseline, our approach reduces training time by
75% and memory usage by 99.9%. These results validate the efficiency and
reliability of our method in lane-changing predictions, highlighting its
potential for safe and efficient autonomous driving systems while offering
significant advantages in deployment, including reduced training time, lower
memory usage, and faster inference.",http://arxiv.org/abs/2502.08659v2
Landscapes and nonequilibrium fluctuations of eukaryotic gene regulation,2025-02-14T10:43:17Z,"Masaki Sasai, Bhaswati Bhattacharyya, Shin Fujishiro, Yoshiaki Horiike","Understanding the interplay among processes that occur over different
timescales is a challenging issue in the physics of systems regulation. In gene
regulation, the timescales for changes in chromatin states can differ from
those for changes in the concentration of product protein, raising questions
about how to understand their coupled dynamics. In this study, we examine the
effects of these different timescales on eukaryotic gene regulation using a
stochastic model that describes the landscapes and probability currents of
nonequilibrium fluctuations. This model shows that slow, nonadiabatic
transitions of chromatin states significantly impact gene-regulation dynamics.
The simulated circular flow of the probability currents indicates a maximum
entropy production when the rates of chromatin-state transitions are low in the
intensely nonadiabatic regime. In the mildly nonadiabatic regime, this circular
flow fosters hysteresis, suggesting that changes in chromatin states precede
changes in transcription activity. Furthermore, calculations using a model of a
circuit involving three core genes in mouse embryonic stem cells illustrate how
multilayer regulation of chromatin, or deep epigenetic regulation, can flexibly
tune fluctuations in individual genes. These findings highlight the rich
effects of nonadiabatic chromatin-state transitions on gene regulation in
eukaryotic cells.",http://arxiv.org/abs/2502.10067v1
"On Lorentzian-Euclidean black holes and Lorentzian to Riemannian metric
  transitions",2025-02-19T21:22:42Z,"Rossella Bartolo, Erasmo Caponio, Anna Valeria Germinario, Miguel Sánchez","In recent papers on spacetimes with a signature-changing metric, the concept
of a Lorentzian-Euclidean black hole and new elements for Lorentzian-Riemannian
signature change have been introduced. A Lorentzian-Euclidean black hole is a
signature-changing modification of the Schwarzschild spacetime satisfying the
vacuum Einstein equations in a weak sense. Here the event horizon serves as a
boundary beyond which time becomes imaginary. We demonstrate that the proper
time needed to reach the horizon remains finite, consistently with the
classical Schwarzschild solution. About Lorentzian to Riemannian metric
transitions, we stress that the hypersurface where the metric signature changes
is naturally a spacelike hypersurface which might be identified with the future
or past causal boundary of the Lorentzian sector. Moreover, a number of
geometric interpretations appear, as the degeneracy of the metric corresponds
to the collapse of the causal cones into a line, the degeneracy of the dual
metric corresponds to collapsing into a hyperplane, and additional geometric
structures on the transition hypersurface (Galilean and dual Galilean) might be
explored.",http://arxiv.org/abs/2502.14108v1
Online detection of forecast model inadequacies using forecast errors,2025-02-20T00:56:51Z,"Thomas Grundy, Rebecca Killick, Ivan Svetunkov","In many organisations, accurate forecasts are essential for making informed
decisions for a variety of applications from inventory management to staffing
optimization. Whatever forecasting model is used, changes in the underlying
process can lead to inaccurate forecasts, which will be damaging to
decision-making. At the same time, models are becoming increasingly complex and
identifying change through direct modelling is problematic. We present a novel
framework for online monitoring of forecasts to ensure they remain accurate. By
utilizing sequential changepoint techniques on the forecast errors, our
framework allows for the real-time identification of potential changes in the
process caused by various external factors. We show theoretically that some
common changes in the underlying process will manifest in the forecast errors
and can be identified faster by identifying shifts in the forecast errors than
within the original modelling framework. Moreover, we demonstrate the
effectiveness of this framework on numerous forecasting approaches through
simulations and show its effectiveness over alternative approaches. Finally, we
present two concrete examples, one from Royal Mail parcel delivery volumes and
one from NHS A\&E admissions relating to gallstones.",http://arxiv.org/abs/2502.14173v1
Relightable Full-Body Gaussian Codec Avatars,2025-01-24T18:59:15Z,"Shaofei Wang, Tomas Simon, Igor Santesteban, Timur Bagautdinov, Junxuan Li, Vasu Agrawal, Fabian Prada, Shoou-I Yu, Pace Nalbone, Matt Gramlich, Roman Lubachersky, Chenglei Wu, Javier Romero, Jason Saragih, Michael Zollhoefer, Andreas Geiger, Siyu Tang, Shunsuke Saito","We propose Relightable Full-Body Gaussian Codec Avatars, a new approach for
modeling relightable full-body avatars with fine-grained details including face
and hands. The unique challenge for relighting full-body avatars lies in the
large deformations caused by body articulation and the resulting impact on
appearance caused by light transport. Changes in body pose can dramatically
change the orientation of body surfaces with respect to lights, resulting in
both local appearance changes due to changes in local light transport
functions, as well as non-local changes due to occlusion between body parts. To
address this, we decompose the light transport into local and non-local
effects. Local appearance changes are modeled using learnable zonal harmonics
for diffuse radiance transfer. Unlike spherical harmonics, zonal harmonics are
highly efficient to rotate under articulation. This allows us to learn diffuse
radiance transfer in a local coordinate frame, which disentangles the local
radiance transfer from the articulation of the body. To account for non-local
appearance changes, we introduce a shadow network that predicts shadows given
precomputed incoming irradiance on a base mesh. This facilitates the learning
of non-local shadowing between the body parts. Finally, we use a deferred
shading approach to model specular radiance transfer and better capture
reflections and highlights such as eye glints. We demonstrate that our approach
successfully models both the local and non-local light transport required for
relightable full-body avatars, with a superior generalization ability under
novel illumination conditions and unseen poses.",http://arxiv.org/abs/2501.14726v1
"IRONMAP: Iron Network Mapping and Analysis Protocol for Detecting
  Over-Time Brain Iron Abnormalities in Neurological Disease",2025-01-29T18:37:15Z,"Jack A. Reeves, Fahad Salman, Michael G. Dwyer, Niels Bergsland, Sarah Muldoon, Bianca Weinstock-Guttman, Robert Zivadinov, Ferdinand Schweser","Pathologically altered iron levels, detected using iron-sensitive MRI
techniques such as quantitative susceptibility mapping (QSM), are observed in
neurological disorders such as multiple sclerosis (MS) and may play a crucial
role in disease pathophysiology. However, brain iron changes occur slowly, even
in neurological diseases, and can be influenced by physiological factors such
as diet. Therefore, novel analysis methods are needed to improve sensitivity to
disease-related iron changes as compared to conventional region-based analysis
methods. This study introduces IRONMAP, Iron Network Mapping and Analysis
Protocol, which is a novel network-based analysis method to evaluate over-time
changes in magnetic susceptibility. With this novel methodology, we analyzed
short-term (<1 year) longitudinal QSM data from a cohort of individuals with MS
(pwMS) and healthy controls (HCs) and assessed disease-related network
patterns, comparing the new approach to a conventional per-region
rate-of-change method. IRONMAP analysis was able to detect over-time,
MS-related brain iron abnormalities that were undetectable using the
rate-of-change approach. IRONMAP was applicable on the per-subject level,
improving binary classification of pwMS vs HCs compared to rate-of-change data
alone (areas under the curve: 0.773 vs 0.636, p = 0.024). Further analysis
revealed that the observed IRONMAP-derived HC network structure closely aligned
with simulated networks based on healthy aging-related susceptibility data,
suggesting that disruptions in normal aging-related iron changes may contribute
to the network differences seen in pwMS. IRONMAP is generalizable to any
neurological disease, including Alzheimer's disease and Parkinson's disease,
and may allow for study of brain iron abnormalities over shorter timeframes
than previously possible.",http://arxiv.org/abs/2501.17838v1
"Change Captioning in Remote Sensing: Evolution to SAT-Cap -- A
  Single-Stage Transformer Approach",2025-01-14T13:46:03Z,"Yuduo Wang, Weikang Yu, Pedram Ghamisi","Change captioning has become essential for accurately describing changes in
multi-temporal remote sensing data, providing an intuitive way to monitor
Earth's dynamics through natural language. However, existing change captioning
methods face two key challenges: high computational demands due to multistage
fusion strategy, and insufficient detail in object descriptions due to limited
semantic extraction from individual images. To solve these challenges, we
propose SAT-Cap based on the transformers model with a single-stage feature
fusion for remote sensing change captioning. In particular, SAT-Cap integrates
a Spatial-Channel Attention Encoder, a Difference-Guided Fusion module, and a
Caption Decoder. Compared to typical models that require multi-stage fusion in
transformer encoder and fusion module, SAT-Cap uses only a simple cosine
similarity-based fusion module for information integration, reducing the
complexity of the model architecture. By jointly modeling spatial and channel
information in Spatial-Channel Attention Encoder, our approach significantly
enhances the model's ability to extract semantic information from objects in
multi-temporal remote sensing images. Extensive experiments validate the
effectiveness of SAT-Cap, achieving CIDEr scores of 140.23% on the LEVIR-CC
dataset and 97.74% on the DUBAI-CC dataset, surpassing current state-of-the-art
methods. The code and pre-trained models will be available online.",http://arxiv.org/abs/2501.08114v1
"Robust Change Captioning in Remote Sensing: SECOND-CC Dataset and
  MModalCC Framework",2025-01-17T09:47:27Z,"Ali Can Karaca, M. Enes Ozelbas, Saadettin Berber, Orkhan Karimli, Turabi Yildirim, M. Fatih Amasyali","Remote sensing change captioning (RSICC) aims to describe changes between
bitemporal images in natural language. Existing methods often fail under
challenges like illumination differences, viewpoint changes, blur effects,
leading to inaccuracies, especially in no-change regions. Moreover, the images
acquired at different spatial resolutions and have registration errors tend to
affect the captions. To address these issues, we introduce SECOND-CC, a novel
RSICC dataset featuring high-resolution RGB image pairs, semantic segmentation
maps, and diverse real-world scenarios. SECOND-CC which contains 6,041 pairs of
bitemporal RS images and 30,205 sentences describing the differences between
images. Additionally, we propose MModalCC, a multimodal framework that
integrates semantic and visual data using advanced attention mechanisms,
including Cross-Modal Cross Attention (CMCA) and Multimodal Gated Cross
Attention (MGCA). Detailed ablation studies and attention visualizations
further demonstrate its effectiveness and ability to address RSICC challenges.
Comprehensive experiments show that MModalCC outperforms state-of-the-art RSICC
methods, including RSICCformer, Chg2Cap, and PSNet with +4.6% improvement on
BLEU4 score and +9.6% improvement on CIDEr score. We will make our dataset and
codebase publicly available to facilitate future research at
https://github.com/ChangeCapsInRS/SecondCC",http://arxiv.org/abs/2501.10075v1
"Lifelong 3D Mapping Framework for Hand-held & Robot-mounted LiDAR
  Mapping Systems",2025-01-30T03:29:42Z,"Liudi Yang, Sai Manoj Prakhya, Senhua Zhu, Ziyuan Liu","We propose a lifelong 3D mapping framework that is modular, cloud-native by
design and more importantly, works for both hand-held and robot-mounted 3D
LiDAR mapping systems. Our proposed framework comprises of dynamic point
removal, multi-session map alignment, map change detection and map version
control. First, our sensor-setup agnostic dynamic point removal algorithm works
seamlessly with both hand-held and robot-mounted setups to produce clean static
3D maps. Second, the multi-session map alignment aligns these clean static maps
automatically, without manual parameter fine-tuning, into a single reference
frame, using a two stage approach based on feature descriptor matching and fine
registration. Third, our novel map change detection identifies positive and
negative changes between two aligned maps. Finally, the map version control
maintains a single base map that represents the current state of the
environment, and stores the detected positive and negative changes, and
boundary information. Our unique map version control system can reconstruct any
of the previous clean session maps and allows users to query changes between
any two random mapping sessions, all without storing any input raw session
maps, making it very unique. Extensive experiments are performed using
hand-held commercial LiDAR mapping devices and open-source robot-mounted LiDAR
SLAM algorithms to evaluate each module and the whole 3D lifelong mapping
framework.",http://arxiv.org/abs/2501.18110v1
A Scalable Crawling Algorithm Utilizing Noisy Change-Indicating Signals,2025-02-04T15:55:10Z,"Róbert Busa-Fekete, Julian Zimmert, András György, Linhai Qiu, Tzu-Wei Sung, Hao Shen, Hyomin Choi, Sharmila Subramaniam, Li Xiao","Web refresh crawling is the problem of keeping a cache of web pages fresh,
that is, having the most recent copy available when a page is requested, given
a limited bandwidth available to the crawler. Under the assumption that the
change and request events, resp., to each web page follow independent Poisson
processes, the optimal scheduling policy was derived by Azar et al. 2018. In
this paper, we study an extension of this problem where side information
indicating content changes, such as various types of web pings, for example,
signals from sitemaps, content delivery networks, etc., is available.
Incorporating such side information into the crawling policy is challenging,
because (i) the signals can be noisy with false positive events and with
missing change events; and (ii) the crawler should achieve a fair performance
over web pages regardless of the quality of the side information, which might
differ from web page to web page. We propose a scalable crawling algorithm
which (i) uses the noisy side information in an optimal way under mild
assumptions; (ii) can be deployed without heavy centralized computation; (iii)
is able to crawl web pages at a constant total rate without spikes in the total
bandwidth usage over any time interval, and automatically adapt to the new
optimal solution when the total bandwidth changes without centralized
computation. Experiments clearly demonstrate the versatility of our approach.",http://arxiv.org/abs/2502.02430v1
"S2C: Learning Noise-Resistant Differences for Unsupervised Change
  Detection in Multimodal Remote Sensing Images",2025-02-18T07:34:54Z,"Lei Ding, Xibing Zuo, Danfeng Hong, Haitao Guo, Jun Lu, Zhihui Gong, Lorenzo Bruzzone","Unsupervised Change Detection (UCD) in multimodal Remote Sensing (RS) images
remains a difficult challenge due to the inherent spatio-temporal complexity
within data, and the heterogeneity arising from different imaging sensors.
Inspired by recent advancements in Visual Foundation Models (VFMs) and
Contrastive Learning (CL) methodologies, this research aims to develop CL
methodologies to translate implicit knowledge in VFM into change
representations, thus eliminating the need for explicit supervision. To this
end, we introduce a Semantic-to-Change (S2C) learning framework for UCD in both
homogeneous and multimodal RS images. Differently from existing CL
methodologies that typically focus on learning multi-temporal similarities, we
introduce a novel triplet learning strategy that explicitly models temporal
differences, which are crucial to the CD task. Furthermore, random spatial and
spectral perturbations are introduced during the training to enhance robustness
to temporal noise. In addition, a grid sparsity regularization is defined to
suppress insignificant changes, and an IoU-matching algorithm is developed to
refine the CD results. Experiments on four benchmark CD datasets demonstrate
that the proposed S2C learning framework achieves significant improvements in
accuracy, surpassing current state-of-the-art by over 31\%, 9\%, 23\%, and
15\%, respectively. It also demonstrates robustness and sample efficiency,
suitable for training and adaptation of various Visual Foundation Models (VFMs)
or backbone neural networks. The relevant code will be available at:
github.com/DingLei14/S2C.",http://arxiv.org/abs/2502.12604v1
"Nano-topographical changes in latent fingerprint due to degradation over
  time studied by Atomic force microscopy -- option to set a timeline?",2025-02-20T15:40:10Z,"Tereza Svatonova, Anna Fucikova","Latent fingerprints, if present, are crucial in identifying the suspect who
was at the crime scene. If there are many latent fingerprints or the suspect is
from the same household, crime investigators may have difficulty identifying
whose latent fingerprints are time-related to the crime. Here, we report
changes in the nanoscale topography of latent fingerprints, which may serve as
a timeline and could help estimate when the latent fingerprint was imprinted.
On the latent fingerprint of an adolescent, we observed a change in
nano-topography over time, specifically the formation of nano-chain structures
in space between the imprinted papillary ridges. We consequently compared this
observation with the decomposition of the latent fingerprints of a child and
adult. We observed a significant difference in the time change in
nano-topography of latent fingerprints of a child, adolescent, and young adult.
The nano-topographical changes of latent fingerprints were studied by atomic
force microscopy over 70 days. In the case of child's and adolescent's latent
fingerprints, the first nano-chains were observed already 24 hours after
imprinting of the latent fingerprint, and the number of nano-chains increased
steadily up to 21 days, then we observed that another organic material covered
the nano-chains, and they started slowly deteriorating; nevertheless, the
nano-chains were still present on the 70th day.",http://arxiv.org/abs/2502.14650v1
LDMapNet-U: An End-to-End System for City-Scale Lane-Level Map Updating,2025-01-06T05:14:40Z,"Deguo Xia, Weiming Zhang, Xiyan Liu, Wei Zhang, Chenting Gong, Xiao Tan, Jizhou Huang, Mengmeng Yang, Diange Yang","An up-to-date city-scale lane-level map is an indispensable infrastructure
and a key enabling technology for ensuring the safety and user experience of
autonomous driving systems. In industrial scenarios, reliance on manual
annotation for map updates creates a critical bottleneck. Lane-level updates
require precise change information and must ensure consistency with adjacent
data while adhering to strict standards. Traditional methods utilize a
three-stage approach-construction, change detection, and updating-which often
necessitates manual verification due to accuracy limitations. This results in
labor-intensive processes and hampers timely updates. To address these
challenges, we propose LDMapNet-U, which implements a new end-to-end paradigm
for city-scale lane-level map updating. By reconceptualizing the update task as
an end-to-end map generation process grounded in historical map data, we
introduce a paradigm shift in map updating that simultaneously generates
vectorized maps and change information. To achieve this, a Prior-Map Encoding
(PME) module is introduced to effectively encode historical maps, serving as a
critical reference for detecting changes. Additionally, we incorporate a novel
Instance Change Prediction (ICP) module that learns to predict associations
with historical maps. Consequently, LDMapNet-U simultaneously achieves
vectorized map element generation and change detection. To demonstrate the
superiority and effectiveness of LDMapNet-U, extensive experiments are
conducted using large-scale real-world datasets. In addition, LDMapNet-U has
been successfully deployed in production at Baidu Maps since April 2024,
supporting map updating for over 360 cities and significantly shortening the
update cycle from quarterly to weekly. The updated maps serve hundreds of
millions of users and are integrated into the autonomous driving systems of
several leading vehicle companies.",http://arxiv.org/abs/2501.02763v2
"Metallisation of the Mott Insulator Ca$_{2}$RuO$_{4}$ using Electric
  Double-Layer Gating",2025-01-07T07:39:14Z,"Tatsuhiro Sakami, Hiroki Ogura, Akihiro Ino, Takumi Ouchi, Tsutomu Nojima, Fumihiko Nakamura","To verify whether the Mott insulator Ca2RuO4 can be switched by applying
electric-field alone, regardless of current flow, we employ metallisation using
electric double-layer gating (EDLG). The resistance change due to EDLG occurs
only when positive gate-voltage above +3 V is applied. The amplitude of the
reduction, reaching ~97% of the initial value, is difficult to interpret as
surface metallisation and is likely related to structural change in bulk.",http://arxiv.org/abs/2501.03591v1
Unveiling the inner structure of the pion first excited state,2025-01-07T08:02:48Z,"Xiaobin Wang, Lei Chang","By capturing the characteristics of the Bethe-Salpeter amplitude for the pion
excitation state, we construct an algebraic model to provide the overall
features of the pion first excitation state parton distribution amplitude and
distribution function. We find that, at the hadronic scale, the distribution
amplitude of the excited state exhibits nodes, while the distribution function
is unimodal, with a peak at $x=1/2$ and distinct concave and convex
fluctuations in the valence region. These findings provide new insights into
the partonic structure of excited mesons and contribute significantly to our
understanding of hadronic excitations.",http://arxiv.org/abs/2501.03602v2
Bosonic Amplitude-Damping Codes Beyond Binomial Schemes,2025-01-13T07:04:05Z,En-Jui Chang,"We introduce two new families of bosonic quantum error correction (QEC) codes
to address collective coherent and amplitude-damping errors, building upon our
previous multi-qubit QEC codes. These new bosonic codes enhance existing
binomial codes for oscillators and permutation-invariant codes for qubits by
reducing the required excitations per input qubit from linear to sub-linear
growth. The mappings from multi-qubit stabilizer codes to bosonic codes
establish a bridge between QEC code construction for qubits and oscillators,
offering a unified approach to error correction across different quantum
systems.",http://arxiv.org/abs/2501.07093v1
On Erlang Queue with Multiple Arrivals and its Time-changed Variant,2025-01-15T13:24:37Z,"R. B. Pote, K. K. Kataria","We introduce and study a queue with the Erlang service system and whose
arrivals are governed by a counting process in which there is a possibility of
finitely many arrivals in an infinitesimal time interval. We call it the Erlang
queue with multiple arrivals. Some of its distributional properties are
obtained that includes the state-phase probabilities, the mean queue length and
the distribution of busy period etc. Also, we study a time-changed variant of
it by subordinating it with an independent inverse stable subordinator where we
obtain its state probabilities and the mean queue length.",http://arxiv.org/abs/2501.08789v1
On Elephant Random Walk with Random Memory,2025-01-22T13:20:10Z,"M. Dhillon, K. K. Kataria","In this paper, we introduce the elephant random walk (ERW) with memory
consisting of randomly selected steps from its history. It is a time-changed
variant of the standard elephant random walk with memory consisting of its full
history. At each time point, the time changing component is the composition of
two uniformly distributed independent random variables with support over all
the past steps. Several conditional distributional properties including the
conditional mean increments and conditional displacement of ERW with random
memory are obtained. Using these conditional results, we derive the recursive
and explicit expressions for the mean increments and mean displacement of the
walk.",http://arxiv.org/abs/2501.12866v1
"Sign-changing prescribed mass solutions for $L^2$-supercritical NLS on
  compact metric graphs",2025-01-24T17:03:54Z,"Louis Jeanjean, Linjie Song","This paper is devoted to the existence of multiple sign-changing solutions of
prescribed mass for a mass-supercritical nonlinear Schr\""odinger equation set
on a compact metric graph. In particular, we obtain, in the supercritical mass
regime, the first multiplicity result for prescribed mass solutions on compact
metric graphs. Our approach relies on the introduction a new kind of link and
on the use of gradient flow techniques on a constraint. It can be transposed to
other problems posed on a bounded domain.",http://arxiv.org/abs/2501.14642v1
"Assessment various control methods a digital copy of enterprise by
  integral indicator",2025-01-29T01:03:51Z,Sergey Masaev,"The difficulty of assessing the state lies in a little predictable change in
the dimension of a dynamic system under the influence of internal changes and
environmental parameters. In the work, the state of such a system is estimated
by the method of integral indicators. The application of the method of integral
indicators allowed us to evaluate the activity of an enterprise. In the present
work, the method of integrated indicators is used to assess the control of a
digital copy (enterprise).",http://arxiv.org/abs/2501.17363v1
eagle: early approximated gradient based learning rate estimator,2025-02-03T04:15:34Z,"Takumi Fujimoto, Hiroaki Nishi","We propose EAGLE update rule, a novel optimization method that accelerates
loss convergence during the early stages of training by leveraging both current
and previous step parameter and gradient values. The update algorithm estimates
optimal parameters by computing the changes in parameters and gradients between
consecutive training steps and leveraging the local curvature of the loss
landscape derived from these changes. However, this update rule has potential
instability, and to address that, we introduce an adaptive switching mechanism
that dynamically selects between Adam and EAGLE update rules to enhance
training stability. Experiments on standard benchmark datasets demonstrate that
EAGLE optimizer, which combines this novel update rule with the switching
mechanism achieves rapid training loss convergence with fewer epochs, compared
to conventional optimization methods.",http://arxiv.org/abs/2502.01036v1
Geometric Gauss Sums and Gross-Koblitz Formulas over Function Fields,2025-02-03T06:59:45Z,Ting-Wei Chang,"In this paper, we prove the Gross-Koblitz-Thakur formulas relating special
$v$-adic gamma values to the newly introduced geometric Gauss sums in the
function field setting. These are analogous to those for the $p$-adic gamma
function in the classical setting due to Gross-Koblitz and the $v$-adic
arithmetic gamma function over function fields due to Thakur. For these new
Gauss sums, we establish their key arithmetic properties, including the
uniformity of absolute values and prime factorizations. We also determine their
signs at infinite places, and derive two analogs of the Hasse-Davenport
relations.",http://arxiv.org/abs/2502.01109v1
Ordinal Patterns Based Change Points Detection,2025-02-05T11:48:36Z,"Annika Betken, Giorgio Micali, Johannes Schmidt-Hieber","The ordinal patterns of a fixed number of consecutive values in a time series
is the spatial ordering of these values. Counting how often a specific ordinal
pattern occurs in a time series provides important insights into the properties
of the time series. In this work, we prove the asymptotic normality of the
relative frequency of ordinal patterns for time series with linear increments.
Moreover, we apply ordinal patterns to detect changes in the distribution of a
time series.",http://arxiv.org/abs/2502.03099v1
"Rising Marginal Costs, Rising Prices?",2025-02-09T13:28:47Z,"Joel Kariel, Anthony Savagar","We present empirical evidence on the relationship between demand shocks and
price changes, conditional on returns to scale. We find that in industries with
decreasing returns to scale, demand increases (which raise costs) correspond to
price increases. Whereas, in industries with increasing returns to scale,
demand increases (which lower costs) correspond to stable prices. We interpret
the results with a theory of imperfect competition and returns to scale. For
prices to remain stable following a cost decrease, markups necessarily rise.
For prices to increase as cost increases, it is not necessary for markups to
change but does not preclude their role. From a macroeconomic perspective, our
results imply that inflation dynamics and the effectiveness of monetary policy
depend on market structures.",http://arxiv.org/abs/2502.05898v1
"Conditioning and AGM-like belief change in the Desirability-Indifference
  framework",2025-02-10T08:11:00Z,"Kathelijne Coussement, Gert de Cooman, Keano De Vos","We show how the AGM framework for belief change (expansion, revision,
contraction) can be extended to deal with conditioning in the so-called
Desirability-Indifference framework, based on abstract notions of accepting and
rejecting options, as well as on abstract notions of events. This level of
abstraction allows us to deal simultaneously with classical and quantum
probability theory.",http://arxiv.org/abs/2502.06235v1
Consistency Training with Physical Constraints,2025-02-11T15:23:14Z,"Che-Chia Chang, Chen-Yang Dai, Te-Sheng Lin, Ming-Chih Lai, Chieh-Hsin Lai","We propose a physics-aware Consistency Training (CT) method that accelerates
sampling in Diffusion Models with physical constraints. Our approach leverages
a two-stage strategy: (1) learning the noise-to-data mapping via CT, and (2)
incorporating physics constraints as a regularizer. Experiments on toy examples
show that our method generates samples in a single step while adhering to the
imposed constraints. This approach has the potential to efficiently solve
partial differential equations (PDEs) using deep generative modeling.",http://arxiv.org/abs/2502.07636v1
"SPARNet: Continual Test-Time Adaptation via Sample Partitioning Strategy
  and Anti-Forgetting Regularization",2025-01-01T12:19:17Z,"Xinru Meng, Han Sun, Jiamei Liu, Ningzhong Liu, Huiyu Zhou","Test-time Adaptation (TTA) aims to improve model performance when the model
encounters domain changes after deployment. The standard TTA mainly considers
the case where the target domain is static, while the continual TTA needs to
undergo a sequence of domain changes. This encounters a significant challenge
as the model needs to adapt for the long-term and is unaware of when the domain
changes occur. The quality of pseudo-labels is hard to guarantee. Noisy
pseudo-labels produced by simple self-training methods can cause error
accumulation and catastrophic forgetting. In this work, we propose a new
framework named SPARNet which consists of two parts, sample partitioning
strategy and anti-forgetting regularization. The sample partition strategy
divides samples into two groups, namely reliable samples and unreliable
samples. According to the characteristics of each group of samples, we choose
different strategies to deal with different groups of samples. This ensures
that reliable samples contribute more to the model. At the same time, the
negative impacts of unreliable samples are eliminated by the mean teacher's
consistency learning. Finally, we introduce a regularization term to alleviate
the catastrophic forgetting problem, which can limit important parameters from
excessive changes. This term enables long-term adaptation of parameters in the
network. The effectiveness of our method is demonstrated in continual TTA
scenario by conducting a large number of experiments on CIFAR10-C, CIFAR100-C
and ImageNet-C.",http://arxiv.org/abs/2501.00818v1
Host-guided data placement: whose job is it anyway?,2025-01-01T23:08:54Z,"Devashish R. Purandare, Peter Alvaro, Avani Wildani, Darrell D. E. Long, Ethan L. Miller","The increasing demand for SSDs coupled with scaling difficulties have left
manufacturers scrambling for newer SSD interfaces which promise better
performance and durability. While these interfaces reduce the rigidity of
traditional abstractions, they require application or system-level changes that
can impact the stability, security, and portability of systems. To make matters
worse, such changes are rendered futile with introduction of next-generation
interfaces. Further, there is little guidance on data placement and hardware
specifics are often abstracted from the application layer. It is no surprise
therefore that such interfaces have seen limited adoption, leaving behind a
graveyard of experimental interfaces ranging from open-channel SSDs to zoned
namespaces.
  In this paper, we show how shim layers can to shield systems from changing
hardware interfaces while benefiting from them. We present Reshim, an
all-userspace shim layer that performs affinity and lifetime based data
placement with no change to the operating system or the application. We
demonstrate Reshim's ease of adoption with host-device coordination for three
widely-used data-intensive systems: RocksDB, MongoDB, and CacheLib. With
Reshim, these systems see 2-6 times highe write throughput, up to 6 times lower
latency, and reduced write amplification compared to filesystems like F2FS.
Reshim performs on par with application-specific backends like ZenFS while
offering more generality, lower latency, and richer data placement. With Reshim
we demonstrate the value of isolating the complexity of the placement logic,
allowing easy deployment of dynamic placement rules across several applications
and storage interfaces.",http://arxiv.org/abs/2501.00977v1
"Online Fault Tolerance Strategy for Abrupt Reachability Constraint
  Changes",2025-01-03T14:32:17Z,"Henghua Shen, Qixin Wang","When a system's constraints change abruptly, the system's reachability safety
does no longer sustain. Thus, the system can reach a forbidden/dangerous value.
Conventional remedy practically involves online controller redesign (OCR) to
re-establish the reachability's compliance with the new constraints, which,
however, is usually too slow. There is a need for an online strategy capable of
managing runtime changes in reachability constraints. However, to the best of
the authors' knowledge, this topic has not been addressed in the existing
literature. In this paper, we propose a fast fault tolerance strategy to
recover the system's reachability safety in runtime. Instead of redesigning the
system's controller, we propose to change the system's reference state to
modify the system's reachability to comply with the new constraints. We frame
the reference state search as an optimization problem and employ the
Karush-Kuhn-Tucker (KKT) method as well as the Interior Point Method (IPM)
based Newton's method (as a fallback for the KKT method) for fast solution
derivation. The optimization also allows more future fault tolerance. Numerical
simulations demonstrate that our method outperforms the conventional OCR method
in terms of computational efficiency and success rate. Specifically, the
results show that the proposed method finds a solution $10^{2}$ (with the IPM
based Newton's method) $\sim 10^{4}$ (with the KKT method) times faster than
the OCR method. Additionally, the improvement rate of the success rate of our
method over the OCR method is $40.81\%$ without considering the deadline of run
time. The success rate remains at $49.44\%$ for the proposed method, while it
becomes $0\%$ for the OCR method when a deadline of $1.5 \; seconds$ is
imposed.",http://arxiv.org/abs/2501.01831v2
"The diophantine equation
  $\left(2^{k}-1\right)\left(3^{k}-1\right)=x^{n}$",2025-01-06T16:54:51Z,"Bo He, Chang Liu","In this paper, we investigate the Diophantine equation \[ (2^k - 1)(3^k - 1)
= x^n \] and prove that it has no solutions in positive integers $k, x, n > 2$.",http://arxiv.org/abs/2501.04050v1
Multiple testing in multi-stream sequential change detection,2025-01-07T20:25:52Z,"Sanjit Dandapanthula, Aaditya Ramdas","Multi-stream sequential change detection involves simultaneously monitoring
many streams of data and trying to detect when their distributions change, if
at all. Here, we theoretically study multiple testing issues that arise from
detecting changes in many streams. We point out that any algorithm with finite
average run length (ARL) must have a trivial worst-case false detection rate
(FDR), family-wise error rate (FWER), per-family error rate (PFER), and global
error rate (GER); thus, any attempt to control these Type I error metrics is
fundamentally in conflict with the desire for a finite ARL (which is typically
necessary in order to have a small detection delay). One of our contributions
is to define a new class of metrics which can be controlled, called error over
patience (EOP). We propose algorithms that combine the recent e-detector
framework (which generalizes the Shiryaev-Roberts and CUSUM methods) with the
recent e-Benjamini-Hochberg procedure and e-Bonferroni procedures. We prove
that these algorithms control the EOP at any desired level under very general
dependence structures on the data within and across the streams. In fact, we
prove a more general error control that holds uniformly over all stopping times
and provides a smooth trade-off between the conflicting metrics. Additionally,
if finiteness of the ARL is forfeited, we show that our algorithms control the
worst-case Type I error.",http://arxiv.org/abs/2501.04130v4
"4D fabrication of shape-changing systems for tissue engineering: state
  of the art and perspectives",2025-01-13T08:07:39Z,"Lorenzo Bonetti, Giulia Scalet","In recent years, four-dimensional (4D) fabrication has emerged as a powerful
technology capable of revolutionizing the field of tissue engineering. This
technology represents a shift in perspective from traditional tissue
engineering approaches, which generally rely on static-or passive-structures
(e.g., scaffolds, constructs) unable of adapting to changes in biological
environments. In contrast, 4D fabrication offers the unprecedented possibility
of fabricating complex designs with spatiotemporal control over structure and
function in response to environment stimuli, thus mimicking biological
processes. In this review, an overview of the state of the art of 4D
fabrication technology for the obtainment of cellularized constructs is
presented, with a focus on shape-changing soft materials. First, the approaches
to obtain cellularized constructs are introduced, also describing conventional
and non-conventional fabrication techniques with their relative advantages and
limitations. Next, the main families of shape-changing soft materials, namely
shape-memory polymers and shape-memory hydrogels are discussed and their use in
4D fabrication in the field of tissue engineering is described. Ultimately,
current challenges and proposed solutions are outlined, and valuable insights
into future research directions of 4D fabrication for tissue engineering are
provided to disclose its full potential.",http://arxiv.org/abs/2501.07612v1
SymSETs and self-dualities under gauging non-invertible symmetries,2025-01-14T02:05:45Z,"Da-Chuan Lu, Zhengdi Sun, Zipei Zhang","The self-duality defects under discrete gauging in a categorical symmetry
$\mathcal{C}$ can be classified by inequivalent ways of enriching the bulk
SymTFT of $\mathcal{C}$ with $\mathbb{Z}_2$ 0-form symmetry. The resulting
Symmetry Enriched Topological (SET) orders will be referred to as
$\textit{SymSETs}$ and are parameterized by choices of $\mathbb{Z}_2$
symmetries, as well as symmetry fractionalization classes and discrete
torsions. In this work, we consider self-dualities under gauging
$\textit{non-invertible}$ $0$-form symmetries in $2$-dim QFTs and explore their
SymSETs. Unlike the simpler case of self-dualities under gauging finite Abelian
groups, the SymSETs here generally admit multiple choices of fractionalization
classes. We provide a direct construction of the SymSET from a given duality
defect using its $\textit{relative center}$. Using the SymSET, we show
explicitly that changing fractionalization classes can change fusion rules of
the duality defect besides its $F$-symbols. We consider three concrete
examples: the maximal gauging of $\operatorname{Rep} H_8$, the non-maximal
gauging of the duality defect $\mathcal{N}$ in $\operatorname{Rep} H_8$ and
$\operatorname{Rep} D_8$ respectively. The latter two cases each result in 6
fusion categories with two types of fusion rules related by changing
fractionalization class. In particular, two self-dualities of
$\operatorname{Rep} D_8$ related by changing the fractionalization class lead
to $\operatorname{Rep} D_{16}$ and $\operatorname{Rep} SD_{16}$ respectively.
Finally, we study the physical implications such as the spin selection rules
and the SPT phases for the aforementioned categories.",http://arxiv.org/abs/2501.07787v1
PIXELS: Progressive Image Xemplar-based Editing with Latent Surgery,2025-01-16T20:26:30Z,"Shristi Das Biswas, Matthew Shreve, Xuelu Li, Prateek Singhal, Kaushik Roy","Recent advancements in language-guided diffusion models for image editing are
often bottle-necked by cumbersome prompt engineering to precisely articulate
desired changes. An intuitive alternative calls on guidance from in-the-wild
image exemplars to help users bring their imagined edits to life. Contemporary
exemplar-based editing methods shy away from leveraging the rich latent space
learnt by pre-existing large text-to-image (TTI) models and fall back on
training with curated objective functions to achieve the task. Though somewhat
effective, this demands significant computational resources and lacks
compatibility with diverse base models and arbitrary exemplar count. On further
investigation, we also find that these techniques restrict user control to only
applying uniform global changes over the entire edited region. In this paper,
we introduce a novel framework for progressive exemplar-driven editing with
off-the-shelf diffusion models, dubbed PIXELS, to enable customization by
providing granular control over edits, allowing adjustments at the pixel or
region level. Our method operates solely during inference to facilitate
imitative editing, enabling users to draw inspiration from a dynamic number of
reference images, or multimodal prompts, and progressively incorporate all the
desired changes without retraining or fine-tuning existing TTI models. This
capability of fine-grained control opens up a range of new possibilities,
including selective modification of individual objects and specifying gradual
spatial changes. We demonstrate that PIXELS delivers high-quality edits
efficiently, leading to a notable improvement in quantitative metrics as well
as human evaluation. By making high-quality image editing more accessible,
PIXELS has the potential to enable professional-grade edits to a wider audience
with the ease of using any open-source image generation model.",http://arxiv.org/abs/2501.09826v1
The Grothendieck groups of repetitive cluster categories of type $D_n$,2025-01-19T11:50:13Z,"Huimin Chang, Panyue Zhou","In this paper, we compute the Grothendieck groups of repetitive cluster
categories of type $D_n$, which are defined as the orbit categories $\mathcal
C_{n,~p}=D^b({\rm mod}KD_n)/\langle(\tau^{-1}[1])^p\rangle$ for $1\leq
p\in\mathbb{N}$.",http://arxiv.org/abs/2501.11021v1
"A New Approach to Radiocarbon Summarisation: Rigorous Identification of
  Variations/Changepoints in the Occurrence Rate of Radiocarbon Samples using a
  Poisson Process",2025-01-27T12:07:15Z,"Timothy J Heaton, Sara Al-assam, Edouard Bard","A commonly-used paradigm to estimate changes in the frequency of past events
or the size of populations is to consider the occurrence rate of
archaeological/environmental samples found at a site over time. The reliability
of such a ""dates-as-data"" approach is highly dependent upon how the occurrence
rates are estimated from the underlying samples, particularly when calendar age
information for the samples is obtained from radiocarbon (14C). The most
frequently-used ""14C-dates-as-data"" approach of creating Summed Probability
Distributions (SPDs) is not statistically valid or coherent and can provide
highly misleading inference. Here, we provide an alternative method with a
rigorous statistical underpinning that also provides valuable additional
information on potential changepoints in the rate of events. Our approach
ensures more reliable ""14C-dates-as-data"" analyses, allowing us to better
assess and identify potential signals present. We model the occurrence of
events, each assumed to leave a radiocarbon sample in the
archaeological/environmental record, as an inhomogeneous Poisson process. The
varying rate of samples over time is then estimated within a fully-Bayesian
framework using reversible-jump Markov Chain Monte Carlo (RJ-MCMC). Given a set
of radiocarbon samples, we reconstruct how their occurrence rate varies over
calendar time and identify if that rate contains statistically-significant
changes, i.e., specific times at which the rate of events abruptly changes. We
illustrate our method with both a simulation study and a practical example
concerning late-Pleistocene megafaunal population changes in Alaska and Yukon.",http://arxiv.org/abs/2501.15980v1
"Interfacial Temperature and Density Discontinuities for Phase-Change
  Heat Transfer With Non-condensable Gas",2025-01-28T16:34:52Z,Gang Chen,"In recent prior work, the author derived interfacial mass and heat flux
conditions for phase-change processes. The mass flux condition is identical to
the Schrage equation, but the additional heat flux expression enables one to
couple the interface to the continua in both the liquid and the vapor phases
and compute the interfacial temperature and density discontinuities. However,
questions exist on how to treat phase change heat transfer in the presence of
non-condensable gases. In this work, the author shows that the same set of
interfacial conditions can be used to account for the presence of
non-condensable gases. Although the mass flux of non-condensable gas is zero,
their presence impacts the heat transfer. For evaporation, when the presence of
the non-condensable gas is small, temperature and density discontinuities
persist across the interface, as well as inverted temperature distributions.
For condensation, however, no temperature inversion happens in the presence of
a small amount of non-condensable gas and the interfacial temperature jump is
significantly smaller. When a large amount of non-condensable gas is present,
such as for evaporation into and condensation from air, the temperature
discontinuities at the interface are significantly smaller and no temperature
inversion happens. For evaporation driven purely by humidity difference,
temperature inversion and discontinuity still exist. Results from this work
will benefit the modeling of phase change processes in the presence of
non-condensable gases, evaporative cooling in air, air-gap distillation,
atmospheric water harvesting, and other applications.",http://arxiv.org/abs/2501.17058v1
"Simulation of the crystallization kinetics of Ge$_2$Sb$_2$Te$_5$
  nanoconfined in superlattice geometries for phase change memories",2025-01-30T14:24:17Z,"Debdipto Acharya, Omar Abou El Kheir, Simone Marcorini, Marco Bernasconi","Phase change materials are the most promising candidates for the realization
of artificial synapsis for neuromorphic computing. Different resistance levels
corresponding to analogic values of the synapsis conductance can be achieved by
modulating the size of an amorphous region embedded in its crystalline matrix.
Recently, it has been proposed that a superlattice made of alternating layers
of the phase change compound Sb$_2$Te$_3$ and of the TiTe$_2$ confining
material allows for a better control of multiple intermediate resistance states
and for a lower drift with time of the electrical resistance of the amorphous
phase. In this work, we consider to substitute Sb$_2$Te$_3$ with the
Ge$_2$Sb$_2$Te$_5$ prototypical phase change compound that should feature
better data retention. By exploiting molecular dynamics simulations with a
machine learning interatomic potential, we have investigated the
crystallization kinetics of Ge$_2$Sb$_2$Te$_5$ nanoconfined in geometries
mimicking Ge$_2$Sb$_2$Te$_5$/TiTe$_2$ superlattices. It turns out that
nanoconfinement induces a slight reduction in the crystal growth velocities
with respect to the bulk, but also an enhancement of the nucleation rate due to
heterogeneous nucleation. The results support the idea of investigating
Ge$_2$Sb$_2$Te$_5$/TiTe$_2$ superlattices for applications in neuromorphic
devices with improved data retention. The effect on the crystallization
kinetics of the addition of van der Waals interaction to the interatomic
potential is also discussed.",http://arxiv.org/abs/2501.18370v1
"The Effect of Covid-19 Lockdown on Human Behaviour Using Analytical
  Hierarchy Process",2025-01-18T13:47:03Z,"Rashi Jain, Mansi Yadav","The coronavirus pandemic corresponds to a serious global health crisis which
not only changed the way people used to live but also how people behaved in
their daily lives. Information from social and behavioural sciences can help in
modifying human behaviour to comply with the recommendations of health
officials, as the pandemic requires large-scale behaviour change and puts
significant mental stress on individuals. The aim of this paper is to examine
the changes in human behaviour brought about by the COVID-19 pandemic, which
has caused a global health crisis and altered the way people live and interact.
The collection of data has been done through online mode and the behaviour of
the people is observed, and the results were finally analysed using the
Analytical Hierarchy Process (AHP) which is a multi-criteria decision-making
method to rank the factors that had the greatest impact on the changes in human
behaviour. During the study, parameters taken under consideration were the ones
which were most likely to affect the human behaviour as an impact of COVID-19
lockdown on health, relationship with family and friends, overall lifestyle,
online education and work from home, screen time etc. The paper explains each
criterion and how it affected human behaviour the most.",http://arxiv.org/abs/2501.18603v1
Controllable Video Generation with Provable Disentanglement,2025-02-04T20:10:20Z,"Yifan Shen, Peiyuan Zhu, Zijian Li, Shaoan Xie, Zeyu Tang, Namrata Deka, Zongfang Liu, Guangyi Chen, Kun Zhang","Controllable video generation remains a significant challenge, despite recent
advances in generating high-quality and consistent videos. Most existing
methods for controlling video generation treat the video as a whole, neglecting
intricate fine-grained spatiotemporal relationships, which limits both control
precision and efficiency. In this paper, we propose Controllable Video
Generative Adversarial Networks (CoVoGAN) to disentangle the video concepts,
thus facilitating efficient and independent control over individual concepts.
Specifically, following the minimal change principle, we first disentangle
static and dynamic latent variables. We then leverage the sufficient change
property to achieve component-wise identifiability of dynamic latent variables,
enabling independent control over motion and identity. To establish the
theoretical foundation, we provide a rigorous analysis demonstrating the
identifiability of our approach. Building on these theoretical insights, we
design a Temporal Transition Module to disentangle latent dynamics. To enforce
the minimal change principle and sufficient change property, we minimize the
dimensionality of latent dynamic variables and impose temporal conditional
independence. To validate our approach, we integrate this module as a plug-in
for GANs. Extensive qualitative and quantitative experiments on various video
generation benchmarks demonstrate that our method significantly improves
generation quality and controllability across diverse real-world scenarios.",http://arxiv.org/abs/2502.02690v1
"A Survey of Sample-Efficient Deep Learning for Change Detection in
  Remote Sensing: Tasks, Strategies, and Challenges",2025-02-05T02:36:09Z,"Lei Ding, Danfeng Hong, Maofan Zhao, Hongruixuan Chen, Chenyu Li, Jie Deng, Naoto Yokoya, Lorenzo Bruzzone, Jocelyn Chanussot","In the last decade, the rapid development of deep learning (DL) has made it
possible to perform automatic, accurate, and robust Change Detection (CD) on
large volumes of Remote Sensing Images (RSIs). However, despite advances in CD
methods, their practical application in real-world contexts remains limited due
to the diverse input data and the applicational context. For example, the
collected RSIs can be time-series observations, and more informative results
are required to indicate the time of change or the specific change category.
Moreover, training a Deep Neural Network (DNN) requires a massive amount of
training samples, whereas in many cases these samples are difficult to collect.
To address these challenges, various specific CD methods have been developed
considering different application scenarios and training resources.
Additionally, recent advancements in image generation, self-supervision, and
visual foundation models (VFMs) have opened up new approaches to address the
'data-hungry' issue of DL-based CD. The development of these methods in broader
application scenarios requires further investigation and discussion. Therefore,
this article summarizes the literature methods for different CD tasks and the
available strategies and techniques to train and deploy DL-based CD methods in
sample-limited scenarios. We expect that this survey can provide new insights
and inspiration for researchers in this field to develop more effective CD
methods that can be applied in a wider range of contexts.",http://arxiv.org/abs/2502.02835v1
Boundedness of toric foliations,2025-02-16T11:29:19Z,"Chih-Wei Chang, Yen-An Chen","We discuss boundedness of toric Fano foliations and connectedness of its
dicritical and singular loci. Moreover, we show the set of interpolated
$\delta$-lcts for the toric foliations satisfies the descending chain
condition.",http://arxiv.org/abs/2502.11080v1
"Searching for Low-Mass Exoplanets Amid Stellar Variability with a Fixed
  Effects Linear Model of Line-by-Line Shape Changes",2025-02-17T15:41:40Z,"Joseph Salzer, Jessi Cisewski-Kehe, Eric B. Ford, Lily L. Zhao","The radial velocity (RV) method, also known as Doppler spectroscopy, is a
powerful technique for exoplanet discovery and characterization. In recent
years, progress has been made thanks to the improvements in the quality of
spectra from new extreme precision RV spectrometers. However, detecting the RV
signals of Earth-like exoplanets remains challenging, as the spectroscopic
signatures of low-mass planets can be obscured or confused with intrinsic
stellar variability. Changes in the shapes of spectral lines across time can
provide valuable information for disentangling stellar activity from true
Doppler shifts caused by low-mass exoplanets. In this work, we present a fixed
effects linear model to estimate RV signals that controls for changes in line
shapes by aggregating information from hundreds of spectral lines. Our
methodology incorporates a wild-bootstrap approach for modeling uncertainty and
cross-validation to control for overfitting. We evaluate the model's ability to
remove stellar activity using solar observations from the NEID spectrograph, as
the sun's true center-of-mass motion is precisely known. Including line
shape-change covariates reduces the RV root-mean-square errors by approximately
70% (from 1.919 m s$^{-1}$ to 0.575 m s$^{-1}$) relative to using only the
line-by-line Doppler shifts. The magnitude of the residuals is significantly
less than that from traditional CCF-based RV estimators and comparable to other
state-of-the-art methods for mitigating stellar variability.",http://arxiv.org/abs/2502.11930v1
"Stress Testing Generalization: How Minor Modifications Undermine Large
  Language Model Performance",2025-02-18T02:42:53Z,"Guangxiang Zhao, Saier Hu, Xiaoqi Jian, Jinzhu Wu, Yuhan Wu, Change Jia, Lin Sun, Xiangzheng Zhang","This paper investigates the fragility of Large Language Models (LLMs) in
generalizing to novel inputs, specifically focusing on minor perturbations in
well-established benchmarks (e.g., slight changes in question format or
distractor length). Despite high benchmark scores, LLMs exhibit significant
accuracy drops and unexpected biases (e.g., preference for longer distractors)
when faced with these minor but content-preserving modifications. For example,
Qwen 2.5 1.5B's MMLU score rises from 60 to 89 and drops from 89 to 36 when
option lengths are changed without altering the question. Even GPT-4
experiences a 25-point accuracy loss when question types are changed, with a
6-point drop across all three modification categories. These analyses suggest
that LLMs rely heavily on superficial cues rather than forming robust, abstract
representations that generalize across formats, lexical variations, and
irrelevant content shifts. This work aligns with the ACL 2025 theme track on
the Generalization of NLP models, proposing a ""Generalization Stress Test"" to
assess performance shifts under controlled perturbations. The study calls for
reevaluating benchmarks and developing more reliable evaluation methodologies
to capture LLM generalization abilities better.",http://arxiv.org/abs/2502.12459v1
"Reinforcement Learning for Adaptive Time-Stepping in the Chaotic
  Gravitational Three-Body Problem",2025-02-18T12:12:49Z,"Veronica Saz Ulibarrena, Simon Portegies Zwart","Many problems in astrophysics cover multiple orders of magnitude in spatial
and temporal scales. While simulating systems that experience rapid changes in
these conditions, it is essential to adapt the (time-) step size to capture the
behavior of the system during those rapid changes and use a less accurate time
step at other, less demanding, moments. We encounter three problems with
traditional methods. Firstly, making such changes requires expert knowledge of
the astrophysics as well as of the details of the numerical implementation.
Secondly, some parameters that determine the time-step size are fixed
throughout the simulation, which means that they do not adapt to the rapidly
changing conditions of the problem. Lastly, we would like the choice of
time-step size to balance accuracy and computation effort. We address these
challenges with Reinforcement Learning by training it to select the time-step
size dynamically. We use the integration of a system of three equal-mass bodies
that move due to their mutual gravity as an example of its application. With
our method, the selected integration parameter adapts to the specific
requirements of the problem, both in terms of computation time and accuracy
while eliminating the expert knowledge needed to set up these simulations. Our
method produces results competitive to existing methods and improve the results
found with the most commonly-used values of time-step parameter. This method
can be applied to other integrators without further retraining. We show that
this extrapolation works for variable time-step integrators but does not
perform to the desired accuracy for fixed time-step integrators.",http://arxiv.org/abs/2502.12809v1
"Charge-changing weak interactions for right-handed particles in the
  Standard Model",2025-02-18T22:19:19Z,J. D. Franson,"Experiments have shown that the charge-changing weak interaction is purely
left-handed, which is taken into account in the Standard Model by the inclusion
of a left-handed projection operator in the Lagrangian. Nevertheless, it will
be shown here that the Standard Model predicts charge-changing weak
interactions for right-handed fermions that can be larger than those for
left-handed fermions if the mass is sufficiently large, as is the case for the
top quark. Here we are using the conventional terminology in which a massive
fermion with its spin parallel to its momentum is referred to as being
right-handed in the relativistic limit, where it is in an approximate
eigenstate of the chirality operator. These effects are due to the way in which
the field of the W boson is quantized, which gives a divergent tensor product
in the Feynman propagator in the unitary gauge. It will be shown that the
off-diagonal terms in the propagator can convert a left-handed projection
operator into a right-handed projection operator, which allows an interaction
with right-handed fermions even though the Lagrangian is left-handed.
Experiments to date have only demonstrated charge-changing weak interactions
for left-handed particles, and an alternative quantization approach that
eliminates the divergent off-diagonal terms in the W boson propagator and
avoids these difficulties will be considered. The alternative approach appears
to be in agreement with existing experiments, but additional high-energy
experiments may be required in order to distinguish its predictions from those
of the Standard Model.",http://arxiv.org/abs/2502.13317v1
"Modeling Cell Type Developmental Trajectory using Multinomial Unbalanced
  Optimal Transport",2025-01-07T03:44:28Z,"Junhao Zhu, Kevin Zhang, Zhaolei Zhang, Dehan Kong","Single-cell trajectory analysis aims to reconstruct the biological
developmental processes of cells as they evolve over time, leveraging temporal
correlations in gene expression. During cellular development, gene expression
patterns typically change and vary across different cell types. A significant
challenge in this analysis is that RNA sequencing destroys the cell, making it
impossible to track gene expression across multiple stages for the same cell.
Recent advances have introduced the use of optimal transport tools to model the
trajectory of individual cells. In this paper, our focus shifts to a question
of greater practical importance: we examine the differentiation of cell types
over time. Specifically, we propose a novel method based on discrete unbalanced
optimal transport to model the developmental trajectory of cell types. Our
method detects biological changes in cell types and infers their transitions to
different states by analyzing the transport matrix. We validated our method
using single-cell RNA sequencing data from mouse embryonic fibroblasts. The
results accurately identified major developmental changes in cell types, which
were corroborated by experimental evidence. Furthermore, the inferred
transition probabilities between cell types are highly congruent to biological
ground truth.",http://arxiv.org/abs/2501.03501v1
"Unsupervised Speech Segmentation: A General Approach Using Speech
  Language Models",2025-01-07T11:32:13Z,"Avishai Elmakies, Omri Abend, Yossi Adi","In this paper, we introduce an unsupervised approach for Speech Segmentation,
which builds on previously researched approaches, e.g., Speaker Diarization,
while being applicable to an inclusive set of acoustic-semantic distinctions,
paving a path towards a general Unsupervised Speech Segmentation approach.
Unlike traditional speech and audio segmentation, which mainly focuses on
spectral changes in the input signal, e.g., phone segmentation, our approach
tries to segment the spoken utterance into chunks with differing
acoustic-semantic styles, focusing on acoustic-semantic information that does
not translate well into text, e.g., emotion or speaker. While most Speech
Segmentation tasks only handle one style change, e.g., emotion diarization, our
approach tries to handle multiple acoustic-semantic style changes. Leveraging
recent advances in Speech Language Models (SLMs), we propose a simple
unsupervised method to segment a given speech utterance. We empirically
demonstrate the effectiveness of the proposed approach by considering several
setups. Results suggest that the proposed method is superior to the evaluated
baselines on boundary detection, segment purity, and over-segmentation. Code is
available at
https://github.com/avishaiElmakies/unsupervised_speech_segmentation_using_slm.",http://arxiv.org/abs/2501.03711v1
Cyber-Physical Steganography in Robotic Motion Control,2025-01-08T14:44:40Z,"Ching-Chun Chang, Yijie Lin, Isao Echizen","Steganography, the art of information hiding, has continually evolved across
visual, auditory and linguistic domains, adapting to the ceaseless interplay
between steganographic concealment and steganalytic revelation. This study
seeks to extend the horizons of what constitutes a viable steganographic medium
by introducing a steganographic paradigm in robotic motion control. Based on
the observation of the robot's inherent sensitivity to changes in its
environment, we propose a methodology to encode messages as environmental
stimuli influencing the motions of the robotic agent and to decode messages
from the resulting motion trajectory. The constraints of maximal robot
integrity and minimal motion deviation are established as fundamental
principles underlying secrecy. As a proof of concept, we conduct experiments in
simulated environments across various manipulation tasks, incorporating robotic
embodiments equipped with generalist multimodal policies.",http://arxiv.org/abs/2501.04541v1
"Investigating the Impact of Observation Space Design Choices On Training
  Reinforcement Learning Solutions for Spacecraft Problems",2025-01-10T14:53:21Z,"Nathaniel Hamilton, Kyle Dunlap, Kerianne L Hobbs","Recent research using Reinforcement Learning (RL) to learn autonomous control
for spacecraft operations has shown great success. However, a recent study
showed their performance could be improved by changing the action space, i.e.
control outputs, used in the learning environment. This has opened the door for
finding more improvements through further changes to the environment. The work
in this paper focuses on how changes to the environment's observation space can
impact the training and performance of RL agents learning the spacecraft
inspection task. The studies are split into two groups. The first looks at the
impact of sensors that were designed to help agents learn the task. The second
looks at the impact of reference frames, reorienting the agent to see the world
from a different perspective. The results show the sensors are not necessary,
but most of them help agents learn more optimal behavior, and that the
reference frame does not have a large impact, but is best kept consistent.",http://arxiv.org/abs/2501.06016v1
"The New Calculator? Practices, Norms, and Implications of Generative AI
  in Higher Education",2025-01-15T15:27:03Z,"Auste Simkute, Viktor Kewenig, Abigail Sellen, Sean Rintel, Lev Tankelevitch","Generative AI (GenAI) has introduced myriad opportunities and challenges for
higher education. Anticipating this potential transformation requires
understanding students' contextualised practices and norms around GenAI. We
conducted semi-structured interviews with 26 students and 11 educators from
diverse departments across two universities. Grounded in Strong Structuration
Theory, we find diversity in students' uses and motivations for GenAI.
Occurring in the context of unclear university guidelines, institutional
fixation on plagiarism, and inconsistent educator communication, students'
practices are informed by unspoken rules around appropriate use, GenAI
limitations and reliance strategies, and consideration of agency and skills.
Perceived impacts include changes in confidence, and concerns about skill
development, relationships with educators, and plagiarism. Both groups envision
changes in universities' attitude to GenAI, responsible use training,
assessments, and integration of GenAI into education. We discuss
socio-technical implications in terms of current and anticipated changes in the
external and internal structures that contextualise students' GenAI use.",http://arxiv.org/abs/2501.08864v1
GSTAR: Gaussian Surface Tracking and Reconstruction,2025-01-17T16:26:24Z,"Chengwei Zheng, Lixin Xue, Juan Zarate, Jie Song","3D Gaussian Splatting techniques have enabled efficient photo-realistic
rendering of static scenes. Recent works have extended these approaches to
support surface reconstruction and tracking. However, tracking dynamic surfaces
with 3D Gaussians remains challenging due to complex topology changes, such as
surfaces appearing, disappearing, or splitting. To address these challenges, we
propose GSTAR, a novel method that achieves photo-realistic rendering, accurate
surface reconstruction, and reliable 3D tracking for general dynamic scenes
with changing topology. Given multi-view captures as input, GSTAR binds
Gaussians to mesh faces to represent dynamic objects. For surfaces with
consistent topology, GSTAR maintains the mesh topology and tracks the meshes
using Gaussians. In regions where topology changes, GSTAR adaptively unbinds
Gaussians from the mesh, enabling accurate registration and the generation of
new surfaces based on these optimized Gaussians. Additionally, we introduce a
surface-based scene flow method that provides robust initialization for
tracking between frames. Experiments demonstrate that our method effectively
tracks and reconstructs dynamic surfaces, enabling a range of applications. Our
project page with the code release is available at
https://eth-ait.github.io/GSTAR/.",http://arxiv.org/abs/2501.10283v2
"Lead Times in Flux: Analyzing Airbnb Booking Dynamics During Global
  Upheavals (2018-2022)",2025-01-17T20:16:32Z,"Harrison Katz, Erica Savage, Peter Coles","Short-term shifts in booking behaviors can disrupt forecasting in the travel
and hospitality industry, especially during global crises. Traditional metrics
like average or median lead times often overlook important distribution
changes. This study introduces a normalized L1 (Manhattan) distance to assess
Airbnb booking lead time divergences from 2018 to 2022, focusing on the
COVID-19 pandemic across four major U.S. cities. We identify a two-phase
disruption: an abrupt change at the pandemic's onset followed by partial
recovery with persistent deviations from pre-2018 patterns. Our method reveals
changes in travelers' planning horizons that standard statistics miss,
highlighting the need to analyze the entire lead-time distribution for more
accurate demand forecasting and pricing strategies. The normalized L1 metric
provides valuable insights for tourism stakeholders navigating ongoing market
volatility.",http://arxiv.org/abs/2501.10535v1
Towards Online Code Specialization of Systems,2025-01-20T09:55:15Z,"Vaastav Anand, Deepak Garg, Antoine Kaufmann","Specializing low-level systems to specifics of the workload they serve and
platform they are running on often significantly improves performance. However,
specializing systems is difficult because of three compounding challenges: i)
specialization for optimal performance requires in-depth compile-time changes;
ii) the right combination of specialization choices for optimal performance is
hard to predict a priori; and iii) workloads and platform details often change
online. In practice, benefits of specialization are thus not attainable for
many low-level systems. To address this, we advocate for a radically different
approach for performance-critical low-level systems: designing and implementing
systems with and for runtime code specialization. We leverage just-in-time
compilation to change systems code based on developer-specified specialization
points as the system runs. The JIT runtime automatically tries out
specialization choices and measures their impact on system performance, e.g.
request latency or throughput, to guide the search. With Iridescent, our early
prototype, we demonstrate that online specialization (i) is feasible even for
low-level systems code, such as network stacks, (ii) improves system
performance without the need for complex cost models, (iii) incurs low
developer effort, especially compared to manual exploration. We conclude with
future opportunities online system code specialization enables.",http://arxiv.org/abs/2501.11366v1
"On nodal solutions with a prescribed number of nodes for a
  Kirchhoff-type problem",2025-01-22T13:18:03Z,"Haining Fan, Marco Squassina, Jianjun Zhang","We are concerned with the existence and asymptotic behavior of multiple
radial sign-changing solutions with the nodal characterization for a
Kirchhoff-type problem involving the nonlinearity $|u|^{p-2}u(2<p<4)$ in
$\mathbb{R}^3$. By developing some useful analysis techniques and introducing a
novel definition of the Nehari manifold for the auxiliary system of the
equations, we show that, for any positive integer $k$, the problem has a
sign-changing solution $u_k^b$ changing signs exactly $k$ times. Furthermore,
the energy of $u_k^b$ is strictly increasing in $k$, as well as some asymptotic
behaviors of $u_k^b$ are obtained. Our result is a complement of [Deng Y, Peng
S, Shuai W, {\it J. Funct. Anal.}, {\bf269}(2015), 3500-3527], where the case
$2<p<4$ is left open.",http://arxiv.org/abs/2501.12865v1
Parallel Belief Contraction via Order Aggregation,2025-01-23T00:42:16Z,"Jake Chandler, Richard Booth","The standard ``serial'' (aka ``singleton'') model of belief contraction
models the manner in which an agent's corpus of beliefs responds to the removal
of a single item of information. One salient extension of this model introduces
the idea of ``parallel'' (aka ``package'' or ``multiple'') change, in which an
entire set of items of information are simultaneously removed. Existing
research on the latter has largely focussed on single-step parallel
contraction: understanding the behaviour of beliefs after a single parallel
contraction. It has also focussed on generalisations to the parallel case of
serial contraction operations whose characteristic properties are extremely
weak. Here we consider how to extend serial contraction operations that obey
stronger properties. Potentially more importantly, we also consider the
iterated case: the behaviour of beliefs after a sequence of parallel
contractions. We propose a general method for extending serial iterated belief
change operators to handle parallel change based on an n-ary generalisation of
Booth & Chandler's TeamQueue binary order aggregators.",http://arxiv.org/abs/2501.13295v1
"Changing Induced Subgraph Isomorphisms Under Extended Reconfiguration
  Rules",2025-01-24T12:33:59Z,"Tatsuhiro Suga, Akira Suzuki, Yuma Tamura, Xiao Zhou","In a reconfiguration problem, we are given two feasible solutions of a
combinatorial problem and our goal is to determine whether it is possible to
reconfigure one into the other, with the steps dictated by specific
reconfiguration rules. Traditionally, most studies on reconfiguration problems
have focused on rules that allow changing a single element at a time. In
contrast, this paper considers scenarios in which $k \ge 2$ elements can be
changed simultaneously. We investigate the general reconfiguration problem of
isomorphisms. For the Induced Subgraph Isomorphism Reconfiguration problem, we
show that the problem remains $\textsf{PSPACE}$-complete even under stringent
constraints on the pattern graph when $k$ is constant. We then give two
meta-theorems applicable when $k$ is slightly less than the number of vertices
in the pattern graph. In addition, we investigate the complexity of the
Independent Set Reconfiguration problem, which is a special case of the Induced
Subgraph Isomorphism Reconfiguration problem.",http://arxiv.org/abs/2501.14450v1
"mFollowIR: a Multilingual Benchmark for Instruction Following in
  Retrieval",2025-01-31T16:24:46Z,"Orion Weller, Benjamin Chang, Eugene Yang, Mahsa Yarmohammadi, Sam Barham, Sean MacAvaney, Arman Cohan, Luca Soldaini, Benjamin Van Durme, Dawn Lawrie","Retrieval systems generally focus on web-style queries that are short and
underspecified. However, advances in language models have facilitated the
nascent rise of retrieval models that can understand more complex queries with
diverse intents. However, these efforts have focused exclusively on English;
therefore, we do not yet understand how they work across languages. We
introduce mFollowIR, a multilingual benchmark for measuring
instruction-following ability in retrieval models. mFollowIR builds upon the
TREC NeuCLIR narratives (or instructions) that span three diverse languages
(Russian, Chinese, Persian) giving both query and instruction to the retrieval
models. We make small changes to the narratives and isolate how well retrieval
models can follow these nuanced changes. We present results for both
multilingual (XX-XX) and cross-lingual (En-XX) performance. We see strong
cross-lingual performance with English-based retrievers that trained using
instructions, but find a notable drop in performance in the multilingual
setting, indicating that more work is needed in developing data for
instruction-based multilingual retrievers.",http://arxiv.org/abs/2501.19264v1
"Detection Is All You Need: A Feasible Optimal Prior-Free Black-Box
  Approach For Piecewise Stationary Bandits",2025-01-31T18:57:21Z,"Argyrios Gerogiannis, Yu-Han Huang, Subhonmesh Bose, Venugopal V. Veeravalli","We study the problem of piecewise stationary bandits without prior knowledge
of the underlying non-stationarity. We propose the first $\textit{feasible}$
black-box algorithm applicable to most common parametric bandit variants. Our
procedure, termed Detection Augmented Bandit (DAB), is modular, accepting any
stationary bandit algorithm as input and augmenting it with a change detector.
DAB achieves optimal regret in the piecewise stationary setting under mild
assumptions. Specifically, we prove that DAB attains the order-optimal regret
bound of $\tilde{\mathcal{O}}(\sqrt{N_T T})$, where $N_T$ denotes the number of
changes over the horizon $T$, if its input stationary bandit algorithm has
order-optimal stationary regret guarantees. Applying DAB to different
parametric bandit settings, we recover recent state-of-the-art results.
Notably, for self-concordant bandits, DAB achieves optimal dynamic regret,
while previous works obtain suboptimal bounds and require knowledge on the
non-stationarity. In simulations on piecewise stationary environments, DAB
outperforms existing approaches across varying number of changes.
Interestingly, despite being theoretically designed for piecewise stationary
environments, DAB is also effective in simulations in drifting environments,
outperforming existing methods designed specifically for this scenario.",http://arxiv.org/abs/2501.19401v1
"Analysis of Fractional Vegetation Coverage and its Dynamic Change in the
  Yalong River Basin based on Dimidiate Pixel Model",2025-02-03T01:17:49Z,"Yue Qin, Yuwei Lyu","Fractional vegetation coverage (FVC) and its spatio-temporal variations are
critical indicators of regional ecological changes, which are of great
significance to study the laws of surface variation and analyze regional
ecosystem. Under the development of RS and GIS technology, this analysis
employs Landsat satellite images in 1994, 2008, 2013 and 2016 to estimate FVC
in Yalong River Basin based on the Dimidiate Pixel Model. With consideration of
the vegetation coverage condition and land surface law in the study area, the
research further analyzes the Spatio-temporal variations as well as the
influencing factors of FVC in terms of topography and land use types
respectively. The results show that since 1994, FVC in Yalong River Basin has
experienced a downward trend yet displaying an uptick from 2013. Moreover,
different land use types indicate the versatility of land covers in Yalong
River Basin, with grassland and forest performing probably the most important
factors that can induce changes to the stability of FVC in whole basin.
Overall, the research reflects the impact of human activities on vegetation in
Yalong River Basin, and provides available data and theoretical basis for
ecological assessment, ecological restoration and environmental protection.",http://arxiv.org/abs/2502.01698v1
"Adaptive Budget Optimization for Multichannel Advertising Using
  Combinatorial Bandits",2025-02-05T06:29:52Z,"Briti Gangopadhyay, Zhao Wang, Alberto Silvio Chiappa, Shingo Takamatsu","Effective budget allocation is crucial for optimizing the performance of
digital advertising campaigns. However, the development of practical budget
allocation algorithms remain limited, primarily due to the lack of public
datasets and comprehensive simulation environments capable of verifying the
intricacies of real-world advertising. While multi-armed bandit (MAB)
algorithms have been extensively studied, their efficacy diminishes in
non-stationary environments where quick adaptation to changing market dynamics
is essential. In this paper, we advance the field of budget allocation in
digital advertising by introducing three key contributions. First, we develop a
simulation environment designed to mimic multichannel advertising campaigns
over extended time horizons, incorporating logged real-world data. Second, we
propose an enhanced combinatorial bandit budget allocation strategy that
leverages a saturating mean function and a targeted exploration mechanism with
change-point detection. This approach dynamically adapts to changing market
conditions, improving allocation efficiency by filtering target regions based
on domain knowledge. Finally, we present both theoretical analysis and
empirical results, demonstrating that our method consistently outperforms
baseline strategies, achieving higher rewards and lower regret across multiple
real-world campaigns.",http://arxiv.org/abs/2502.02920v1
"Time Series Anomaly Detection in the Frequency Domain with Statistical
  Reliability",2025-02-05T10:48:12Z,"Akifumi Yamada, Tomohiro Shiraishi, Shuichi Nishino, Teruyuki Katsuoka, Kouichi Taji, Ichiro Takeuchi","Effective anomaly detection in complex systems requires identifying change
points (CPs) in the frequency domain, as abnormalities often arise across
multiple frequencies. This paper extends recent advancements in statistically
significant CP detection, based on Selective Inference (SI), to the frequency
domain. The proposed SI method quantifies the statistical significance of
detected CPs in the frequency domain using $p$-values, ensuring that the
detected changes reflect genuine structural shifts in the target system. We
address two major technical challenges to achieve this. First, we extend the
existing SI framework to the frequency domain by appropriately utilizing the
properties of discrete Fourier transform (DFT). Second, we develop an SI method
that provides valid $p$-values for CPs where changes occur across multiple
frequencies. Experimental results demonstrate that the proposed method reliably
identifies genuine CPs with strong statistical guarantees, enabling more
accurate root-cause analysis in the frequency domain of complex systems.",http://arxiv.org/abs/2502.03062v1
"An object detection approach for lane change and overtake detection from
  motion profiles",2025-02-06T17:36:35Z,"Andrea Benericetti, Niccolò Bellaccini, Henrique Piñeiro Monteagudo, Matteo Simoncini, Francesco Sambo","In the application domain of fleet management and driver monitoring, it is
very challenging to obtain relevant driving events and activities from dashcam
footage while minimizing the amount of information stored and analyzed. In this
paper, we address the identification of overtake and lane change maneuvers with
a novel object detection approach applied to motion profiles, a compact
representation of driving video footage into a single image. To train and test
our model we created an internal dataset of motion profile images obtained from
a heterogeneous set of dashcam videos, manually labeled with overtake and lane
change maneuvers by the ego-vehicle. In addition to a standard object-detection
approach, we show how the inclusion of CoordConvolution layers further improves
the model performance, in terms of mAP and F1 score, yielding state-of-the art
performance when compared to other baselines from the literature. The extremely
low computational requirements of the proposed solution make it especially
suitable to run in device.",http://arxiv.org/abs/2502.04244v1
Variation of sentence length across time and genre,2025-02-06T18:59:02Z,Karolina Rudnicka,"The goal of this paper is threefold: i) to present some practical aspects of
using full-text version of Corpus of Historical American English (COHA), the
largest diachronic multi-genre corpus of the English language, in the
investigation of a linguistic trend of change; ii) to test a widely held
assumption that sentence length in written English has been steadily decreasing
over the past few centuries; iii) to point to a possible link between the
changes in sentence length and changes in the English syntactic usage. The
empirical proof of concept for iii) is provided by the decline in the frequency
of the non-finite purpose subordinator in order to. Sentence length, genre and
the likelihood of occurrence of in order to are shown to be interrelated.",http://arxiv.org/abs/2502.04321v1
"An Evolutionary Game With the Game Transitions Based on the Markov
  Process",2025-02-09T01:57:18Z,"Minyu Feng, Bin Pi, Liang-Jian Deng, Jürgen Kurths","The psychology of the individual is continuously changing in nature, which
has a significant influence on the evolutionary dynamics of populations. To
study the influence of the continuously changing psychology of individuals on
the behavior of populations, in this paper, we consider the game transitions of
individuals in evolutionary processes to capture the changing psychology of
individuals in reality, where the game that individuals will play shifts as
time progresses and is related to the transition rates between different games.
Besides, the individual's reputation is taken into account and utilized to
choose a suitable neighbor for the strategy updating of the individual. Within
this model, we investigate the statistical number of individuals staying in
different game states and the expected number fits well with our theoretical
results. Furthermore, we explore the impact of transition rates between
different game states, payoff parameters, the reputation mechanism, and
different time scales of strategy updates on cooperative behavior, and our
findings demonstrate that both the transition rates and reputation mechanism
have a remarkable influence on the evolution of cooperation. Additionally, we
examine the relationship between network size and cooperation frequency,
providing valuable insights into the robustness of the model.",http://arxiv.org/abs/2502.05742v1
"CHIRLA: Comprehensive High-resolution Identification and
  Re-identification for Large-scale Analysis",2025-02-10T17:07:43Z,"Bessie Dominguez-Dager, Felix Escalona, Francisco Gomez-Donoso, Miguel Cazorla","Person re-identification (Re-ID) is a key challenge in computer vision,
requiring the matching of individuals across different cameras, locations, and
time periods. While most research focuses on short-term scenarios with minimal
appearance changes, real-world applications demand robust Re-ID systems capable
of handling long-term scenarios, where persons' appearances can change
significantly due to variations in clothing and physical characteristics. In
this paper, we present CHIRLA, Comprehensive High-resolution Identification and
Re-identification for Large-scale Analysis, a novel dataset specifically
designed for long-term person Re-ID. CHIRLA consists of recordings from
strategically placed cameras over a seven-month period, capturing significant
variations in both temporal and appearance attributes, including controlled
changes in participants' clothing and physical features. The dataset includes
22 individuals, four connected indoor environments, and seven cameras. We
collected more than five hours of video that we semi-automatically labeled to
generate around one million bounding boxes with identity annotations. By
introducing this comprehensive benchmark, we aim to facilitate the development
and evaluation of Re-ID algorithms that can reliably perform in challenging,
long-term real-world scenarios.",http://arxiv.org/abs/2502.06681v1
Fock state probability changes in open quantum systems,2025-02-11T16:19:08Z,"Clare Burrage, Christian Käding","Open quantum systems are powerful effective descriptions of quantum systems
interacting with their environments. Studying changes of Fock states
probabilities can be intricate in this context since the prevailing description
of open quantum dynamics is by master equations of the systems' reduced density
matrices, which usually requires finding solutions for a set of complicated
coupled differential equations. In this article, we show that such problems can
be circumvented by employing a recently developed path integral-based method
for directly computing reduced density matrices in scalar quantum field theory.
For this purpose, we consider a real scalar field $\phi$ as an open system
interacting via a $\lambda \chi^2\phi^2$-term with an environment comprising
another real scalar field $\chi$ that has a finite temperature. In particular,
we investigate how the probabilities for observing the vacuum or two-particle
states change over time if there were initial correlations of these Fock
states. Subsequently, we apply our resulting expressions to a neutrino toy
model. We show that, within our model, lighter neutrino masses would lead to a
stronger distortion of the observable number of particles due to the
interaction with the environment after the initial production process.",http://arxiv.org/abs/2502.07673v1
"Improving TCM Question Answering through Tree-Organized Self-Reflective
  Retrieval with LLMs",2025-02-13T10:36:18Z,"Chang Liu, Ying Chang, Jianmin Li, Yiqian Qu, Yu Li, Lingyong Cao, Shuyuan Lin","Objectives: Large language models (LLMs) can harness medical knowledge for
intelligent question answering (Q&A), promising support for auxiliary diagnosis
and medical talent cultivation. However, there is a deficiency of highly
efficient retrieval-augmented generation (RAG) frameworks within the domain of
Traditional Chinese Medicine (TCM). Our purpose is to observe the effect of the
Tree-Organized Self-Reflective Retrieval (TOSRR) framework on LLMs in TCM Q&A
tasks.
  Materials and Methods: We introduce the novel approach of knowledge
organization, constructing a tree structure knowledge base with hierarchy. At
inference time, our self-reflection framework retrieves from this knowledge
base, integrating information across chapters. Questions from the TCM Medical
Licensing Examination (MLE) and the college Classics Course Exam (CCE) were
randomly selected as benchmark datasets.
  Results: By coupling with GPT-4, the framework can improve the best
performance on the TCM MLE benchmark by 19.85% in absolute accuracy, and
improve recall accuracy from 27% to 38% on CCE datasets. In manual evaluation,
the framework improves a total of 18.52 points across dimensions of safety,
consistency, explainability, compliance, and coherence.
  Conclusion: The TOSRR framework can effectively improve LLM's capability in
Q&A tasks of TCM.",http://arxiv.org/abs/2502.09156v1
"Architecture for Simulating Behavior Mode Changes in Norm-Aware
  Autonomous Agents",2025-02-13T11:49:02Z,"Sean Glaze, Daniela Inclezan","This paper presents an architecture for simulating the actions of a
norm-aware intelligent agent whose behavior with respect to norm compliance is
set, and can later be changed, by a human controller. Updating an agent's
behavior mode from a norm-abiding to a riskier one may be relevant when the
agent is involved in time-sensitive rescue operations, for example. We base our
work on the Authorization and Obligation Policy Language AOPL designed by
Gelfond and Lobo for the specification of norms. We introduce an architecture
and a prototype software system that can be used to simulate an agent's plans
under different behavior modes that can later be changed by the controller. We
envision such software to be useful to policy makers, as they can more readily
understand how agents may act in certain situations based on the agents'
attitudes towards norm-compliance. Policy makers may then refine their policies
if simulations show unwanted consequences.",http://arxiv.org/abs/2502.09215v1
CellFlow: Simulating Cellular Morphology Changes via Flow Matching,2025-02-13T21:10:00Z,"Yuhui Zhang, Yuchang Su, Chenyu Wang, Tianhong Li, Zoe Wefers, Jeffrey Nirschl, James Burgess, Daisy Ding, Alejandro Lozano, Emma Lundberg, Serena Yeung-Levy","Building a virtual cell capable of accurately simulating cellular behaviors
in silico has long been a dream in computational biology. We introduce
CellFlow, an image-generative model that simulates cellular morphology changes
induced by chemical and genetic perturbations using flow matching. Unlike prior
methods, CellFlow models distribution-wise transformations from unperturbed to
perturbed cell states, effectively distinguishing actual perturbation effects
from experimental artifacts such as batch effects -- a major challenge in
biological data. Evaluated on chemical (BBBC021), genetic (RxRx1), and combined
perturbation (JUMP) datasets, CellFlow generates biologically meaningful cell
images that faithfully capture perturbation-specific morphological changes,
achieving a 35% improvement in FID scores and a 12% increase in mode-of-action
prediction accuracy over existing methods. Additionally, CellFlow enables
continuous interpolation between cellular states, providing a potential tool
for studying perturbation dynamics. These capabilities mark a significant step
toward realizing virtual cell modeling for biomedical research.",http://arxiv.org/abs/2502.09775v1
"Robust variance estimators in application to segmentation of measurement
  data distorted by impulsive and non-Gaussian noise",2025-02-14T16:33:17Z,"Justyna Witulska, Anna Zaleska, Natalia Kremzer-Osiadacz, Agnieszka Wyłomańska, Ireneusz Jabłoński","The paper algorithmizes the problem of regime change point identification for
data measured in a system exhibiting impulsive behaviors. This is a fundamental
challenge for annotation of measurement data relevant, e.g., for designing
data-driven autonomous systems. The contribution consists in the formulation of
an offline robust methodology based on the classical approach for structural
break detection. The problem of data segmentation is considered in the context
of scale change, which physically can be translated into the occurrence of a
critical event that reorganizes the system structure. The main advantage of our
approach is that it does not require the existence of a variance of the data
distribution. The efficiency has been evaluated for simulated data from two
distributions and for real-world datasets measured in financial, mechanical,
and medical systems. Simulation studies show that in the most challenging case,
the error in estimating regime change is 20 times smaller for robust approach
compared to the classical one.",http://arxiv.org/abs/2502.10275v1
"Changing the Rules of the Game: Reasoning about Dynamic Phenomena in
  Multi-Agent Systems",2025-02-17T13:23:37Z,"Rustam Galimullin, Maksim Gladyshev, Munyque Mittelmann, Nima Motamed","The design and application of multi-agent systems (MAS) require reasoning
about the effects of modifications on their underlying structure. In
particular, such changes may impact the satisfaction of system specifications
and the strategic abilities of their autonomous components. In this paper, we
are concerned with the problem of verifying and synthesising modifications (or
\textit{updates}) of MAS. We propose an extension of the Alternating-Time
Temporal Logic ($\mathsf{ATL}$) that enables reasoning about the dynamics of
model change, called the \textit{Logic for $\mathsf{ATL}$ Model Building}
($\mathsf{LAMB}$). We show how $\mathsf{LAMB}$ can express various intuitions
and ideas about the dynamics of MAS, from normative updates to mechanism
design. As the main technical result, we prove that, while being strictly more
expressive than $\mathsf{ATL}$, $\mathsf{LAMB}$ enjoys a P-complete
model-checking procedure.",http://arxiv.org/abs/2502.11785v1
"JL1-CD: A New Benchmark for Remote Sensing Change Detection and a Robust
  Multi-Teacher Knowledge Distillation Framework",2025-02-19T03:33:54Z,"Ziyuan Liu, Ruifei Zhu, Long Gao, Yuanxiu Zhou, Jingyu Ma, Yuantao Gu","Deep learning has achieved significant success in the field of remote sensing
image change detection (CD), yet two major challenges remain: the scarcity of
sub-meter, all-inclusive open-source CD datasets, and the difficulty of
achieving consistent and satisfactory detection results across images with
varying change areas. To address these issues, we introduce the JL1-CD dataset,
which contains 5,000 pairs of 512 x 512 pixel images with a resolution of 0.5
to 0.75 meters. Additionally, we propose a multi-teacher knowledge distillation
(MTKD) framework for CD. Experimental results on the JL1-CD and SYSU-CD
datasets demonstrate that the MTKD framework significantly improves the
performance of CD models with various network architectures and parameter
sizes, achieving new state-of-the-art results. The code is available at
https://github.com/circleLZY/MTKD-CD.",http://arxiv.org/abs/2502.13407v1
"Exploring Personalized Health Support through Data-Driven, Theory-Guided
  LLMs: A Case Study in Sleep Health",2025-02-19T17:53:43Z,"Xingbo Wang, Janessa Griffith, Daniel A. Adler, Joey Castillo, Tanzeem Choudhury, Fei Wang","Despite the prevalence of sleep-tracking devices, many individuals struggle
to translate data into actionable improvements in sleep health. Current methods
often provide data-driven suggestions but may not be feasible and adaptive to
real-life constraints and individual contexts. We present HealthGuru, a novel
large language model-powered chatbot to enhance sleep health through
data-driven, theory-guided, and adaptive recommendations with conversational
behavior change support. HealthGuru's multi-agent framework integrates wearable
device data, contextual information, and a contextual multi-armed bandit model
to suggest tailored sleep-enhancing activities. The system facilitates natural
conversations while incorporating data-driven insights and theoretical behavior
change techniques. Our eight-week in-the-wild deployment study with 16
participants compared HealthGuru to a baseline chatbot. Results show improved
metrics like sleep duration and activity scores, higher quality responses, and
increased user motivation for behavior change with HealthGuru. We also identify
challenges and design considerations for personalization and user engagement in
health chatbots.",http://arxiv.org/abs/2502.13920v1
"LoRA-GGPO: Mitigating Double Descent in LoRA Fine-Tuning via
  Gradient-Guided Perturbation Optimization",2025-02-20T13:14:41Z,"Yupeng Chang, Chenlu Guo, Yi Chang, Yuan Wu","Large Language Models (LLMs) have achieved remarkable success in natural
language processing, but their full fine-tuning remains resource-intensive.
Parameter-Efficient Fine-Tuning (PEFT) methods, such as Low-Rank Adaptation
(LoRA), have emerged as a practical solution by approximating parameter updates
with low-rank matrices. However, LoRA often exhibits a ""double descent""
phenomenon during fine-tuning, where model performance degrades due to
overfitting and limited expressiveness caused by low-rank constraints. To
address this issue, we propose LoRA-GGPO (Gradient-Guided Perturbation
Optimization), a novel method that leverages gradient and weight norms to
generate targeted perturbations. By optimizing the sharpness of the loss
landscape, LoRA-GGPO guides the model toward flatter minima, mitigating the
double descent problem and improving generalization. Extensive experiments on
natural language understanding (NLU) and generation (NLG) tasks demonstrate
that LoRA-GGPO outperforms LoRA and its state-of-the-art variants. Furthermore,
extended experiments specifically designed to analyze the double descent
phenomenon confirm that LoRA-GGPO effectively alleviates this issue, producing
more robust and generalizable models. Our work provides a robust and efficient
solution for fine-tuning LLMs, with broad applicability in real-world
scenarios. The code is available at https://github.com/llm172/LoRA-GGPO.",http://arxiv.org/abs/2502.14538v1
"IoT Firmware Version Identification Using Transfer Learning with Twin
  Neural Networks",2025-01-10T15:11:33Z,"Ashley Andrews, George Oikonomou, Simon Armour, Paul Thomas, Thomas Cattermole","As the Internet of Things (IoT) becomes more embedded within our daily lives,
there is growing concern about the risk `smart' devices pose to network
security. To address this, one avenue of research has focused on automated IoT
device identification. Research has however largely neglected the
identification of IoT device firmware versions. There is strong evidence that
IoT security relies on devices being on the latest version patched for known
vulnerabilities. Identifying when a device has updated (has changed version) or
not (is on a stable version) is therefore useful for IoT security. Version
identification involves challenges beyond those for identifying the model,
type, and manufacturer of IoT devices, and traditional machine learning
algorithms are ill-suited for effective version identification due to being
limited by the availability of data for training. In this paper, we introduce
an effective technique for identifying IoT device versions based on transfer
learning. This technique relies on the idea that we can use a Twin Neural
Network (TNN) - trained at distinguishing devices - to detect differences
between a device on different versions. This facilitates real-world
implementation by requiring relatively little training data. We extract
statistical features from on-wire packet flows, convert these features into
greyscale images, pass these images into a TNN, and determine version changes
based on the Hedges' g effect size of the similarity scores. This allows us to
detect the subtle changes present in on-wire traffic when a device changes
version. To evaluate our technique, we set up a lab containing 12 IoT devices
and recorded their on-wire packet captures for 11 days across multiple firmware
versions. For testing data held out from training, our best performing model is
shown to be 95.83% and 84.38% accurate at identifying stable versions and
version changes respectively.",http://arxiv.org/abs/2501.06033v1
"Sensitivity of Quantitative Susceptibility Mapping in Clinical Brain
  Research",2025-01-28T18:58:43Z,"Fahad Salman, Abhisri Ramesh, Thomas Jochmann, Mirjam Prayer, Ademola Adegbemigun, Jack A. Reeves, Gregory E. Wilding, Junghun Cho, Dejan Jakimovski, Niels Bergsland, Michael G. Dwyer, Robert Zivadinov, Ferdinand Schweser","Background: Quantitative susceptibility mapping (QSM) of the brain is an
advanced MRI technique for assessing tissue characteristics based on magnetic
susceptibility, which varies with the composition of the tissue, such as iron,
calcium, and myelin levels. QSM consists of multiple processing steps, with
various choices for each step. Despite its increasing application in detecting
and monitoring neurodegenerative diseases, the impact of algorithmic choices in
QSM's workflow on clinical outcomes has not been thoroughly quantified.
  Objective: This study aimed to evaluate how choices in background field
removal (BFR), dipole inversion algorithms, and anatomical referencing impact
the sensitivity and reproducibility error of QSM in detecting group-level and
longitudinal changes in deep gray matter susceptibility in a clinical setting.
  Methods: We compared 378 different QSM pipelines using a 10-year follow-up
dataset of healthy adults. We analyzed the sensitivity of pipelines to detect
known aging-related susceptibility changes in the DGM over time.
  Results: We found high variability in the sensitivity of QSM pipelines to
detect susceptibility changes. The study highlighted that while most pipelines
could detect changes reliably, the choice of BFR algorithm and the referencing
strategy substantially influenced the outcome reproducibility error and
sensitivity. Notably, pipelines using RESHARP with AMP-PE, HEIDI or LSQR
inversion showed the highest overall sensitivity.
  Conclusions: The findings underscore the critical influence of algorithmic
choices in QSM processing on the accuracy and reliability of detecting
physiological changes in the brain. This has profound implications for clinical
research and trials where QSM is used as a biomarker for disease progression,
highlighting that careful consideration should be given to pipeline
configuration to optimize clinical outcomes.",http://arxiv.org/abs/2501.17158v1
"Evolution and sudden change of steady interactions of low enthalpy
  hypersonic double wedge flows with fore angle",2025-02-20T01:41:00Z,"Yihui Weng, Yi Duan, Qin Li, Yunchuan Wu, Mengyu Wang, Pan Yan, Siyi Li","The evolution and sudden change of steady interaction structures is
numerically studied with the fore wedge angle theta_1 in a low enthalpy
hypersonic double wedge configuration. It particularly focuses on the
conditions of Swantek and Austin's experiments where Ma=7, and h_0=2 MJ/kg but
with a reduced Reynolds number (Re). The sudden structural change indicates
that when theta_1 reaches a critical value, minor angular variations can
trigger a discontinuous transformation in flow structures. The analysis is
based on the laminar Navier-Stokes equations, using ideal gas and
non-equilibrium gas models. Under the condition of Re=1E5/m, detailed numerical
simulations are conducted as theta_1 varies over 0 deg-40 deg. This study
yields the following findings: (a) The upper and lower boundaries of theta_1
for the onset of unsteady flow are identified. When theta_1 lies outside these
boundaries, the flow remains steady. (b) As theta_1 increases, the interaction
patterns evolve sequentially, progressing from Type VI through Type VI->V, Type
III, Type IV_r, and ultimately to a flow dominated solely by a bow shock. This
evolution defines the boundaries between different interaction patterns and
provides a comprehensive understanding of their progression with theta_1.
Sudden structural changes occur during the transitions from Type III to Type
IV_r and from Type IV_r to a bow shock-dominated flow. In addition, a
comparative study is performed through shock polar analysis to compare its
predictions with computational results. (c) An unconventional reflection
pattern of the transmitted shock over the separation zone, called Type III_r,
is observed in non-equilibrium gas flows, which differs from classical
interaction patterns. (d) The aerodynamic distribution of wall properties under
various interactions is obtained, indicating distinct features before and after
the sudden structural change.",http://arxiv.org/abs/2502.14186v1
"Realistic overground gait transitions are not sharp but involve
  gradually changing walk-run mixtures as per energy optimality",2025-01-01T04:37:28Z,"Nicholas S. Baker, Leroy Long, Manoj Srinivasan","Humans use two qualitatively different gaits for locomotion, namely, walking
and running -- usually using walking at lower speeds and running at higher
speeds. Researchers have examined when humans switch between walking and
running on treadmills and have noted hystereses in these gait transition
speeds. Here, we consider an ecologically realistic overground locomotion task,
one requiring traveling a given long distance (800 meters or 2400 meters) in a
prescribed time duration. Unlike on a treadmill, this task allows the human to
change speed or gait during the trial to reach the destination on time: this
task is akin to traveling to an appointment at a particular time from your
office to another office, arriving neither early or late. We find that gait
transition is not sharp, but instead involves a 'gait transition regime' in
which humans use a mixture of walking and running, using mostly walking atlower
speeds and mostly running higher speeds -- supporting earlier results over
short distances (120 m). The presence of this gradually changing walk-run
mixture is predicted by energy optimality. We hypothesize that this energy
optimal behavior in this realistic overground conditions accounts for the
hysteretic behavior in treadmill experiments, apparently switching earlier than
predicted by energy optimality.",http://arxiv.org/abs/2501.00720v1
"Rotational Flow Dominates Abrupt Seasonal Change in Zonally Asymmetric
  Tropical Meridional Circulation",2025-01-04T16:13:33Z,"Wuqiushi Yao, Jianhua Lu, Yimin Liu","The seasonality of the tropical meridional circulation evolves differently
across different regions, governs the onset and retreat of monsoons and
migration of tropical precipitation, thereby influencing agricultural
productivity and disaster preparedness in the tropics and subtropics. By
defining a pseudo meridional overturning streamfunction ({\Psi}pseudo) and
defining a new vector-type, dual-component index (ASCI), we diagnose zonally
asymmetric abrupt seasonal change (ASC) of tropical meridional circulation.
{\Psi}pseudo converges to traditional, meridional overturning streamfunction
({\Psi}m) after being averaged over a zonal circle around any latitude. By
applying the Helmholtz decomposition to horizontal velocity fields so as to
decompose {\Psi}pseudo into rotational and divergent components, we
quantitatively compare the contributions of horizontally rotational and
divergent flows to the abrupt seasonal change. We find that the zonal sectors
associated with strong deep convection exhibit the most pronounced ASC of
tropical meridional circulation, and all of subregions exhibiting ASC contain
landmass with low heat inertia. Particularly, in contrast to the case of
zonally symmetric Hadley cell, rotational flow, rather than the thermal-direct
divergent flow, dominates the zonally asymmetric ASC in the tropics, although
the divergent flow also contributes to the ASC over the zonal sectors
associated with deep convection. We suggest that the interplay between tropical
Rossby-type eddies with extratropical eddies and tropical circulation is
essential to the zonally asymmetric ASC of tropical Hadley circulation.",http://arxiv.org/abs/2501.02326v1
"AHMSA-Net: Adaptive Hierarchical Multi-Scale Attention Network for
  Micro-Expression Recognition",2025-01-05T13:40:12Z,"Lijun Zhang, Yifan Zhang, Weicheng Tang, Xinzhi Sun, Xiaomeng Wang, Zhanshan Li","Micro-expression recognition (MER) presents a significant challenge due to
the transient and subtle nature of the motion changes involved. In recent
years, deep learning methods based on attention mechanisms have made some
breakthroughs in MER. However, these methods still suffer from the limitations
of insufficient feature capture and poor dynamic adaptation when coping with
the instantaneous subtle movement changes of micro-expressions. Therefore, in
this paper, we design an Adaptive Hierarchical Multi-Scale Attention Network
(AHMSA-Net) for MER. Specifically, we first utilize the onset and apex frames
of the micro-expression sequence to extract three-dimensional (3D) optical flow
maps, including horizontal optical flow, vertical optical flow, and optical
flow strain. Subsequently, the optical flow feature maps are inputted into
AHMSA-Net, which consists of two parts: an adaptive hierarchical framework and
a multi-scale attention mechanism. Based on the adaptive downsampling
hierarchical attention framework, AHMSA-Net captures the subtle changes of
micro-expressions from different granularities (fine and coarse) by dynamically
adjusting the size of the optical flow feature map at each layer. Based on the
multi-scale attention mechanism, AHMSA-Net learns micro-expression action
information by fusing features from different scales (channel and spatial).
These two modules work together to comprehensively improve the accuracy of MER.
Additionally, rigorous experiments demonstrate that the proposed method
achieves competitive results on major micro-expression databases, with
AHMSA-Net achieving recognition accuracy of up to 78.21% on composite databases
(SMIC, SAMM, CASMEII) and 77.08% on the CASME^{}3 database.",http://arxiv.org/abs/2501.02539v1
The fragmentation of molecular clouds in starburst environments,2025-01-06T19:00:04Z,"Matt T. Cusack, Paul C. Clark, Simon C. O. Glover, Ralf S. Klessen, Philipp Girichidis, Anthony P. Whitworth, Felix D. Priestley","A significant amount of star formation occurs and has occurred in
environments unlike the solar neighbourhood. The majority of stars formed
closer to the peak of the cosmic star formation rate (z > 1.3) and a great deal
of star formation presently occurs in the central molecular zone (CMZ) of the
Galaxy. These environments are unified by the presence of a high interstellar
radiation field (ISRF) and a high cosmic ray ionisation rate (CRIR). Numerical
studies of stellar birth typically neglect this fact, and those that do not
have thus far been limited in scope. In this work we present the first
comprehensive analysis of hydrodynamical simulations of star formation in
extreme environments where we have increased the ISRF and CRIR to values
typical of the CMZ and starburst galaxies. We note changes in the fragmentation
behaviour on both the core and stellar system scale, leading to top-heavy core
and stellar system mass functions in high ISRF/CRIR clouds. Clouds fragment
less on the core scale, producing fewer but more massive cores. Conversely, the
cores fragment more intensely and produce richer clusters of stellar systems.
We present a picture where high ISRF/CRIR clouds fragment less on the scale of
cores and clumps, but more on the scale of stellar systems. The change in
fragmentation behaviour subsequently changes the mass function of the stellar
systems that form through enhanced accretion rates.",http://arxiv.org/abs/2501.03323v1
"OpenIN: Open-Vocabulary Instance-Oriented Navigation in Dynamic Domestic
  Environments",2025-01-08T05:01:59Z,"Yujie Tang, Meiling Wang, Yinan Deng, Zibo Zheng, Jingchuan Deng, Yufeng Yue","In daily domestic settings, frequently used objects like cups often have
unfixed positions and multiple instances within the same category, and their
carriers frequently change as well. As a result, it becomes challenging for a
robot to efficiently navigate to a specific instance. To tackle this challenge,
the robot must capture and update scene changes and plans continuously.
However, current object navigation approaches primarily focus on the semantic
level and lack the ability to dynamically update scene representation. In
contrast, this paper captures the relationships between frequently used objects
and their static carriers. It constructs an open-vocabulary
Carrier-Relationship Scene Graph (CRSG) and updates the carrying status during
robot navigation to reflect the dynamic changes of the scene. Based on the
CRSG, we further propose an instance navigation strategy that models the
navigation process as a Markov Decision Process. At each step, decisions are
informed by the Large Language Model's commonsense knowledge and
visual-language feature similarity. We designed a series of long-sequence
navigation tasks for frequently used everyday items in the Habitat simulator.
The results demonstrate that by updating the CRSG, the robot can efficiently
navigate to moved targets. Additionally, we deployed our algorithm on a real
robot and validated its practical effectiveness. The project page can be found
here: https://OpenIN-nav.github.io.",http://arxiv.org/abs/2501.04279v1
"Federated-Continual Dynamic Segmentation of Histopathology guided by
  Barlow Continuity",2025-01-08T16:06:39Z,"Niklas Babendererde, Haozhe Zhu, Moritz Fuchs, Jonathan Stieber, Anirban Mukhopadhyay","Federated- and Continual Learning have been established as approaches to
enable privacy-aware learning on continuously changing data, as required for
deploying AI systems in histopathology images. However, data shifts can occur
in a dynamic world, spatially between institutions and temporally, due to
changing data over time. This leads to two issues: Client Drift, where the
central model degrades from aggregating data from clients trained on shifted
data, and Catastrophic Forgetting, from temporal shifts such as changes in
patient populations. Both tend to degrade the model's performance of previously
seen data or spatially distributed training. Despite both problems arising from
the same underlying problem of data shifts, existing research addresses them
only individually. In this work, we introduce a method that can jointly
alleviate Client Drift and Catastrophic Forgetting by using our proposed
Dynamic Barlow Continuity that evaluates client updates on a public reference
dataset and uses this to guide the training process to a spatially and
temporally shift-invariant model. We evaluate our approach on the
histopathology datasets BCSS and Semicol and prove our method to be highly
effective by jointly improving the dice score as much as from 15.8% to 71.6% in
Client Drift and from 42.5% to 62.8% in Catastrophic Forgetting. This enables
Dynamic Learning by establishing spatio-temporal shift-invariance.",http://arxiv.org/abs/2501.04588v1
"Color Correction Meets Cross-Spectral Refinement: A Distribution-Aware
  Diffusion for Underwater Image Restoration",2025-01-08T03:26:45Z,"Laibin Chang, Yunke Wang, Bo Du, Chang Xu","Underwater imaging often suffers from significant visual degradation, which
limits its suitability for subsequent applications. While recent underwater
image enhancement (UIE) methods rely on the current advances in deep neural
network architecture designs, there is still considerable room for improvement
in terms of cross-scene robustness and computational efficiency. Diffusion
models have shown great success in image generation, prompting us to consider
their application to UIE tasks. However, directly applying them to UIE tasks
will pose two challenges, \textit{i.e.}, high computational budget and color
unbalanced perturbations. To tackle these issues, we propose DiffColor, a
distribution-aware diffusion and cross-spectral refinement model for efficient
UIE. Instead of diffusing in the raw pixel space, we transfer the image into
the wavelet domain to obtain such low-frequency and high-frequency spectra, it
inherently reduces the image spatial dimensions by half after each
transformation. Unlike single-noise image restoration tasks, underwater imaging
exhibits unbalanced channel distributions due to the selective absorption of
light by water. To address this, we design the Global Color Correction (GCC)
module to handle the diverse color shifts, thereby avoiding potential global
degradation disturbances during the denoising process. For the sacrificed image
details caused by underwater scattering, we further present the Cross-Spectral
Detail Refinement (CSDR) to enhance the high-frequency details, which are
integrated with the low-frequency signal as input conditions for guiding the
diffusion. This way not only ensures the high-fidelity of sampled content but
also compensates for the sacrificed details. Comprehensive experiments
demonstrate the superior performance of DiffColor over state-of-the-art methods
in both quantitative and qualitative evaluations.",http://arxiv.org/abs/2501.04740v1
"Million-atom simulation of the set process in phase change memories at
  the real device scale",2025-01-13T15:03:47Z,"Omar Abou El Kheir, Marco Bernasconi","Phase change materials are exploited in several enabling technologies such as
storage class memories, neuromorphic devices and memories embedded in
microcontrollers. A key functional property for these applications is the fast
crystal nucleation and growth in the supercool liquid phase. Over the last
decade, atomistic simulations based on density functional theory (DFT) have
provided crucial insights on the early stage of this process. These simulations
are, however, restricted to a few hundred atoms for at most a few ns. More
recently, the scope of the DFT simulations have been greatly extended by
leveraging on machine learning techniques. In this paper, we show that the
exploitation of a recently devised neural network potential for the
prototypical phase change compound Ge$_2$Sb$_2$Te$_5$, allows simulating the
crystallization process in a multimillion atom model at the length and time
scales of the real memory devices. The simulations provide a vivid atomistic
picture of the subtle interplay between crystal nucleation and crystal growth
from the crystal/amorphous rim. Moreover, the simulations have allowed
quantifying the distribution of point defects controlling electronic transport,
in a very large crystallite grown at the real conditions of the set process of
the device.",http://arxiv.org/abs/2501.07384v1
"Modelling the transition from shear-driven turbulence to convective
  turbulence in a vertical heated pipe",2025-01-14T14:58:44Z,"Shijun Chu, Elena Marensi, Ashley P. Willis","Heated pipe flow is widely used in thermal engineering applications, but the
presence of buoyancy force can cause intermittency, or multiple flow states at
the same parameter values. Such changes in the flow lead to substantial changes
in its heat transfer properties and thereby significant changes in the axial
temperature gradient. We therefore introduce a model that features a
time-dependent background axial temperature gradient, and consider two
temperature boundary conditions -- fixed temperature difference and fixed
boundary heat flux. Direct numerical simulations (DNS) are based on the
pseudo-spectral framework, and good agreement is achieved between present
numerical results and experimental results. The code extends openpipeflow.org
and is available at the website. The effect of the axially periodic domain on
flow dynamics and heat transfer is examined, using pipes of length L=5D and
L=25D. Provided that the flow is fully turbulent, results show close agreement
for the mean flow and temperature profiles, and only slight differences in
root-mean-square fluctuations. When the flow shows spatial intermittency, heat
transfer tends to be overestimated using a short pipe, as shear turbulence
fills the domain. This is particularly important when shear turbulence starts
to be suppressed at intermediate buoyancy numbers. Finally, at such
intermediate buoyancy numbers, we confirm that the decay of localised shear
turbulence in the heated pipe flow follows a memoryless process, similar to
that in isothermal flow. While isothermal flow then laminarises, convective
turbulence in the heated flow can intermittently trigger bursts of shear-like
turbulence.",http://arxiv.org/abs/2501.08176v1
"Observation of discontinuities in the periodic modulation of PSR
  B1828-11",2025-01-16T20:50:00Z,"Adriana Dias, Gregory Ashton, Julianna Ostrovska, David Ian Jones, Michael Keith","PSR B1828-11 is a radio pulsar that undergoes periodic modulations (~500
days) of its spin-down rate and beam width, providing a valuable opportunity to
understand the rotational dynamics of neutron stars. The periodic modulations
have previously been attributed to planetary companion(s), precession, or
magnetospheric effects and have several interesting features: they persist over
10 cycles, there are at least two harmonically related components, and the
period is decreasing at a rate of about 5 days per cycle. PSR B1828-11 also
experienced a glitch, a sudden increase in its rotation frequency, at 55 040.9
Modified Julian Day(MJD). By studying the interaction of the periodic
modulations with the glitch, we seek to find evidence to distinguish
explanations of the periodic modulation. Using a phenomenological model, we
analyse a recently published open data set from Jodrell Bank Observatory,
providing the longest and highest resolution measurements of the pulsar's
spin-down rate data. Our phenomenological model consists of step changes in the
amplitude, modulation frequency, and phase of the long-term periodic modulation
and the usual spin-down glitch behaviour. We find clear evidence with a
(natural-log) Bayes factor of 1486 to support that not only is there a change
to these three separate parameters but that the shifts occur before the glitch.
Finally, we also present model-independent evidence which demonstrates visually
how and when the modulation period and amplitude change. Discontinuities in the
modulation period are difficult to explain if a planetary companion sources the
periodic modulations, but we conclude with a discussion on the insights into
precession and magnetospheric switching.",http://arxiv.org/abs/2501.09834v1
X-Dyna: Expressive Dynamic Human Image Animation,2025-01-17T08:10:53Z,"Di Chang, Hongyi Xu, You Xie, Yipeng Gao, Zhengfei Kuang, Shengqu Cai, Chenxu Zhang, Guoxian Song, Chao Wang, Yichun Shi, Zeyuan Chen, Shijie Zhou, Linjie Luo, Gordon Wetzstein, Mohammad Soleymani","We introduce X-Dyna, a novel zero-shot, diffusion-based pipeline for
animating a single human image using facial expressions and body movements
derived from a driving video, that generates realistic, context-aware dynamics
for both the subject and the surrounding environment. Building on prior
approaches centered on human pose control, X-Dyna addresses key shortcomings
causing the loss of dynamic details, enhancing the lifelike qualities of human
video animations. At the core of our approach is the Dynamics-Adapter, a
lightweight module that effectively integrates reference appearance context
into the spatial attentions of the diffusion backbone while preserving the
capacity of motion modules in synthesizing fluid and intricate dynamic details.
Beyond body pose control, we connect a local control module with our model to
capture identity-disentangled facial expressions, facilitating accurate
expression transfer for enhanced realism in animated scenes. Together, these
components form a unified framework capable of learning physical human motion
and natural scene dynamics from a diverse blend of human and scene videos.
Comprehensive qualitative and quantitative evaluations demonstrate that X-Dyna
outperforms state-of-the-art methods, creating highly lifelike and expressive
animations. The code is available at https://github.com/bytedance/X-Dyna.",http://arxiv.org/abs/2501.10021v2
"Dynamic Continual Learning: Harnessing Parameter Uncertainty for
  Improved Network Adaptation",2025-01-18T19:58:53Z,"Christopher Angelini, Nidhal Bouaynaya","When fine-tuning Deep Neural Networks (DNNs) to new data, DNNs are prone to
overwriting network parameters required for task-specific functionality on
previously learned tasks, resulting in a loss of performance on those tasks. We
propose using parameter-based uncertainty to determine which parameters are
relevant to a network's learned function and regularize training to prevent
change in these important parameters. We approach this regularization in two
ways: (1), we constrain critical parameters from significant changes by
associating more critical parameters with lower learning rates, thereby
limiting alterations in those parameters; (2), important parameters are
restricted from change by imposing a higher regularization weighting, causing
parameters to revert to their states prior to the learning of subsequent tasks.
We leverage a Bayesian Moment Propagation framework which learns network
parameters concurrently with their associated uncertainties while allowing each
parameter to contribute uncertainty to the network's predictive distribution,
avoiding the pitfalls of existing sampling-based methods. The proposed approach
is evaluated for common sequential benchmark datasets and compared to existing
published approaches from the Continual Learning community. Ultimately, we show
improved Continual Learning performance for Average Test Accuracy and Backward
Transfer metrics compared to sampling-based methods and other
non-uncertainty-based approaches.",http://arxiv.org/abs/2501.10861v1
Imaging signatures of edge currents in a magnetic topological insulator,2025-01-20T18:48:02Z,"G. M. Ferguson, Run Xiao, Anthony R. Richardella, Austin Kaczmarek, Nitin Samarth, Katja C. Nowack","Magnetic topological insulators (MTIs) host topologically protected edge
states, but the role that these edge states play in electronic transport
remains unclear. Using scanning superconducting quantum interference device
(SQUID) microscopy, we performed local measurements of the current distribution
in a quantum anomalous Hall (QAH) insulator at large bias currents, where the
quantization of the conductivity tensor breaks down. We find that bulk currents
in the channel interior coexist with edge currents at the sample boundary.
While the position of the edge current changes with the reversal of the
magnetic field, it does not depend on the current direction. To understand our
observations, we introduce a model which includes contributions from both the
sample magnetization and currents driven by chemical potential gradients. To
parameterize our model, we use local measurements of the chemical potential
induced changes in the sample magnetization. Our model reveals that the
observed edge currents can be understood as changes in the magnetization
generated by the electrochemical potential distribution in the sample under
bias. Our work underscores the complexity of electronic transport in MTIs and
highlights both the value and challenges of using magnetic imaging to
disentangle various contributions to the electronic transport signatures.",http://arxiv.org/abs/2501.11666v1
"A One Dimensional (1D) Computational Fluid Dynamics Study of
  Fontan-Associated Liver Disease (FALD)",2025-01-06T15:36:26Z,"Yaqi Li, Charles Puelz, Mette S. Olufsen, Alyssa Taylor-LaPole","Fontan-Associated Liver Disease (FALD) is a disorder arising from hemodynamic
changes and venous congestion in the liver. This disease is prominent in
patients with hypoplastic left heart syndrome (HLHS). Although HLHS patients
typically survive into adulthood, they have reduced cardiac output due to their
univentricular physiology (i.e., a Fontan circuit). As a result, they have
insufficient blood delivery to the liver. In comparison, patients with double
outlet right ventricle (DORV), also having a univentricular circuit, have lower
incidence of FALD. In this study, we use a patient-specific, one-dimensional
computational fluid dynamics (1D-CFD) model to predict hemodynamics in the
liver of an HLHS patient and compare predictions with an age- and size-matched
DORV control patient. Additionally, we simulate FALD conditions in the HLHS
patient to predict hemodynamic changes across various stages of disease
progression. Our results show that the HLHS patient has a higher portal venous
pressure compared to the DORV patient. This difference is exacerbated as FALD
conditions progress. The wall shear stress (WSS) is also higher than normal for
the HLHS patient, suggesting vascular remodeling. WSS decreases slightly under
FALD conditions, consistent with the development of portal hypertension.
Perfusion analysis gives insight into regions of liver tissue at risk for
fibrosis development, showing increasing pressures and reduced flow throughout
the liver tissue fed by the portal vein under FALD conditions. Our results
provide insight into the specific hemodynamic changes in Fontan circulation
that can cause FALD.",http://arxiv.org/abs/2501.12396v1
"Structural and optical changes induced by incorporation of antimony into
  InAs/GaAs(001) quantum dots",2025-01-23T07:46:25Z,"A. G. Taboada, A. M. Sánchez, A. M. Beltrán, M. Bozkurt, D. Alonso-Álvarez, B. Alén, A. Rivera, J. M. Ripalda, J. M. Llorens, J. Martín-Sánchez, Y. González, J. M. Ulloa, J. M. García, S. I. Molina, P. M. Koenraad","We present experimental evidence of Sb incorporation inside InAs/GaA(001)
quantum dots exposed to an antimony flux immediately before capping with GaAs.
The Sb composition profile inside the nanostructures as measured by
cross-sectional scanning tunneling and electron transmission microscopies show
two differentiated regions within the quantum dots, with an Sb rich alloy at
the tip of the quantum dots. Atomic force microscopy and transmission electron
microscopy micrographs show increased quantum-dot height with Sb flux exposure.
The evolution of the reflection high-energy electron-diffraction pattern
suggests that the increased height is due to changes in the quantum-dot capping
process related to the presence of segregated Sb atoms. These structural and
compositional changes result in a shift of the room-temperature
photoluminescence emission from 1.26 to 1.36 microns accompanied by an order of
magnitude increase in the room-temperature quantum-dot luminescence intensity.",http://arxiv.org/abs/2501.13437v1
A Micromechanical Model for Light-interactive Molecular Crystals,2025-01-24T23:18:11Z,"Devesh Tiwari, Ananya Renuka Balakrishna","Molecular crystals respond to a light stimulus by bending, twisting, rolling,
jumping, or other kinematic behaviors. These behaviors are known to be affected
by, among others, the intensity of the incident light, the aspect ratios of
crystal geometries, and the volume changes accompanying phase transformation.
While these factors, individually, explain the increase in internal energy of
the system and its subsequent minimization through macroscopic deformation,
they do not fully explain the diversity of deformations observed in molecular
crystals. Here, we propose a micromechanical model based on the Cauchy-Born
rule and photoreaction theory to predict the macroscopic response in molecular
crystals. By accounting for lattice geometry changes and microstructural
patterns that emerge during phase transformation, we predict a range of
deformations in a representative molecular crystal (salicylideneamine). Doing
so, we find that the interplay between photoexcited states and the energy
minimization pathways, across a multi-well energy landscape, is crucial to the
bending and twisting deformations. We use our model to analyze the role of
particle geometries and the intensity of incident light on macroscopic
deformation, and identify geometric regimes for shearing and twisting
deformations in salicylideneamine crystals. Our micromechanical model is
general and can be adapted to predict photomechanical deformation in other
molecular crystals undergoing a solid-to-solid phase change and has potential
as a computational design tool to engineer reversible and controllable
actuation in molecular crystals.",http://arxiv.org/abs/2501.14975v1
"Code Change Intention, Development Artifact and History Vulnerability:
  Putting Them Together for Vulnerability Fix Detection by LLM",2025-01-24T23:40:03Z,"Xu Yang, Wenhan Zhu, Michael Pacheco, Jiayuan Zhou, Shaowei Wang, Xing Hu, Kui Liu","Detecting vulnerability fix commits in open-source software is crucial for
maintaining software security. To help OSS identify vulnerability fix commits,
several automated approaches are developed. However, existing approaches like
VulFixMiner and CoLeFunDa, focus solely on code changes, neglecting essential
context from development artifacts. Tools like Vulcurator, which integrates
issue reports, fail to leverage semantic associations between different
development artifacts (e.g., pull requests and history vulnerability fixes).
Moreover, they miss vulnerability fixes in tangled commits and lack
explanations, limiting practical use. Hence to address those limitations, we
propose LLM4VFD, a novel framework that leverages Large Language Models (LLMs)
enhanced with Chain-of-Thought reasoning and In-Context Learning to improve the
accuracy of vulnerability fix detection. LLM4VFD comprises three components:
(1) Code Change Intention, which analyzes commit summaries, purposes, and
implications using Chain-of-Thought reasoning; (2) Development Artifact, which
incorporates context from related issue reports and pull requests; (3)
Historical Vulnerability, which retrieves similar past vulnerability fixes to
enrich context. More importantly, on top of the prediction, LLM4VFD also
provides a detailed analysis and explanation to help security experts
understand the rationale behind the decision. We evaluated LLM4VFD against
state-of-the-art techniques, including Pre-trained Language Model-based
approaches and vanilla LLMs, using a newly collected dataset, BigVulFixes.
Experimental results demonstrate that LLM4VFD significantly outperforms the
best-performed existing approach by 68.1%--145.4%. Furthermore, We conducted a
user study with security experts, showing that the analysis generated by
LLM4VFD improves the efficiency of vulnerability fix identification.",http://arxiv.org/abs/2501.14983v1
"Large Language Model Critics for Execution-Free Evaluation of Code
  Changes",2025-01-28T02:38:56Z,"Aashish Yadavally, Hoan Nguyen, Laurent Callot, Gauthier Guinet","Large language models (LLMs) offer a promising way forward for automating
software engineering tasks, such as bug fixes, feature additions, etc., via
multi-step LLM-based agentic workflows. However, existing metrics for
evaluating such workflows, mainly build status and occasionally log analysis,
are too sparse and limited in providing the information needed to assess the
quality of changes made. In this work, we designed LLM-based critics to derive
well-structured and rigorous intermediate/step-level, execution-free evaluation
proxies for repo-level code changes. Importantly, we assume access to the gold
test patch for the problem (i.e., reference-aware) to assess both semantics and
executability of generated patches. With the gold test patch as a reference, we
predict executability of all editing locations with an F1 score of 91.6%,
aggregating which, we can predict the build status in 84.8% of the instances in
SWE-bench. In particular, such an execution-focused LLM critic outperforms
other reference-free and reference-aware LLM critics by 38.9% to 72.5%.
Moreover, we demonstrate the usefulness of such a reference-aware framework in
comparing patches generated by different agentic workflows. Finally, we
open-source the library developed for this project, which allows further usage
for either other agentic workflows or other benchmarks. The source code is
available at https://github.com/amazon-science/code-agent-eval.",http://arxiv.org/abs/2501.16655v1
"AlphaAdam:Asynchronous Masked Optimization with Dynamic Alpha for
  Selective Updates",2025-01-30T02:10:23Z,"Da Chang, Yu Li, Ganzhao Yuan","In the training of large language models (LLMs), updating parameters more
efficiently and stably has always been an important challenge. To achieve
efficient parameter updates, existing methods usually achieve performance
comparable to full parameter updates through methods such as low-dimensional
decomposition or layer-wise selective updates. In this work, we propose
AlphaAdam, an optimization framework for LLM from the perspective of
intra-layer parameter updates. By decoupling parameter updates and dynamically
adjusting their strength, AlphaAdam accelerates convergence and improves
training stability. We construct parameter masks based on the consistency of
historical momentum and gradient direction and combine them with an adaptive
mask strength strategy to ensure efficient optimization and theoretical
convergence guarantees, which is also applicable to most momentum-based
optimizers. Extensive experiments show that AlphaAdam outperforms
state-of-the-art methods such as AdamW in terms of convergence speed and
computational efficiency across tasks, including GPT-2 pre-trained and
fine-tuned RoBERTa and Llama-7B. Our AlphaAdam implements an optimizer
enhancement framework for LLMs through intra-layer asynchronous masked adaptive
updates. Our code is available in this https://github.com/MaeChd/AlphaAdam.",http://arxiv.org/abs/2501.18094v2
What is causal about causal models and representations?,2025-01-31T17:35:21Z,"Frederik Hytting Jørgensen, Luigi Gresele, Sebastian Weichwald","Causal Bayesian networks are 'causal' models since they make predictions
about interventional distributions. To connect such causal model predictions to
real-world outcomes, we must determine which actions in the world correspond to
which interventions in the model. For example, to interpret an action as an
intervention on a treatment variable, the action will presumably have to a)
change the distribution of treatment in a way that corresponds to the
intervention, and b) not change other aspects, such as how the outcome depends
on the treatment; while the marginal distributions of some variables may change
as an effect. We introduce a formal framework to make such requirements for
different interpretations of actions as interventions precise. We prove that
the seemingly natural interpretation of actions as interventions is circular:
Under this interpretation, every causal Bayesian network that correctly models
the observational distribution is trivially also interventionally valid, and no
action yields empirical data that could possibly falsify such a model. We prove
an impossibility result: No interpretation exists that is non-circular and
simultaneously satisfies a set of natural desiderata. Instead, we examine
non-circular interpretations that may violate some desiderata and show how this
may in turn enable the falsification of causal models. By rigorously examining
how a causal Bayesian network could be a 'causal' model of the world instead of
merely a mathematical object, our formal framework contributes to the
conceptual foundations of causal representation learning, causal discovery, and
causal abstraction, while also highlighting some limitations of existing
approaches.",http://arxiv.org/abs/2501.19335v2
"VLA-Cache: Towards Efficient Vision-Language-Action Model via Adaptive
  Token Caching in Robotic Manipulation",2025-02-04T09:48:14Z,"Siyu Xu, Yunke Wang, Chenghao Xia, Dihao Zhu, Tao Huang, Chang Xu","Vision-Language-Action (VLA) model can process instructions and visual
perception to directly generate actions as output in an end-to-end fashion due
to its strong multi-modal reasoning capabilities. While the performance of VLA
models is promising, their computational cost can be substantial. This raises
challenge for applying them on robotics tasks, which requires real-time
decision-making to respond quickly to environmental changes. Since robotic
control involves sequential decision-making, the visual input often exhibits
minimal variation between successive steps. A natural idea is to reuse the
computational results of unchanged visual tokens from the last step. Motivated
by this idea, we propose VLA-Cache, an efficient vision-language-action model.
VLA-Cache incorporates a token-selection mechanism that compares the visual
input at each step with the input from the previous step, adaptively
identifying visual tokens with minimal changes. The computational results for
these unchanged tokens are then reused in subsequent steps via KV-cache,
thereby significantly improving the efficiency of the VLA-Cache model.
Experimental results on both simulation (e.g., LIBERO benchmark and SIMPLER)
and real-world robot valid VLA-Cache can achieve practical acceleration with
minimal sacrifice in success rate.",http://arxiv.org/abs/2502.02175v1
"Adaptive Resource Allocation Optimization Using Large Language Models in
  Dynamic Wireless Environments",2025-02-04T12:56:59Z,"Hyeonho Noh, Byonghyo Shim, Hyun Jong Yang","Deep learning (DL) has made notable progress in addressing complex radio
access network control challenges that conventional analytic methods have
struggled to solve. However, DL has shown limitations in solving constrained
NP-hard problems often encountered in network optimization, such as those
involving quality of service (QoS) or discrete variables like user indices.
Current solutions rely on domain-specific architectures or heuristic
techniques, and a general DL approach for constrained optimization remains
undeveloped. Moreover, even minor changes in communication objectives demand
time-consuming retraining, limiting their adaptability to dynamic environments
where task objectives, constraints, environmental factors, and communication
scenarios frequently change. To address these challenges, we propose a large
language model for resource allocation optimizer (LLM-RAO), a novel approach
that harnesses the capabilities of LLMs to address the complex resource
allocation problem while adhering to QoS constraints. By employing a
prompt-based tuning strategy to flexibly convey ever-changing task descriptions
and requirements to the LLM, LLM-RAO demonstrates robust performance and
seamless adaptability in dynamic environments without requiring extensive
retraining. Simulation results reveal that LLM-RAO achieves up to a 40%
performance enhancement compared to conventional DL methods and up to an $80$\%
improvement over analytical approaches. Moreover, in scenarios with fluctuating
communication objectives, LLM-RAO attains up to 2.9 times the performance of
traditional DL-based networks.",http://arxiv.org/abs/2502.02287v1
"On the Convergence of Strong Cylindrical and Spherical Shock Waves in
  Solid Materials",2025-02-02T15:35:36Z,R. K. Anand,"In this article, we present a description of the behaviour of
shock-compressed solid materials following the Geometrical Shock Dynamics (GSD)
theory. GSD has been successfully applied to various gas dynamics problems, and
here we have employed it to investigate the propagation of cylindrically and
spherically symmetric converging shock waves in solid materials. The analytical
solution of shock dynamics equations has been obtained in strong-shock limit,
assuming the solid material to be homogeneous and isotropic and obeying the
Mie-Gruneisen equation of state. The non-dimensional expressions are obtained
for the velocity of shock, the pressure, the mass density, the particle
velocity, the temperature, the speed of sound, the adiabatic bulk modulus, and
the change-in-entropy behind the strong converging shock front. The influences
as a result of changes in (i) the propagation distance r from the axis or
centre (r=0) of convergence, (ii) the Gruneisen parameter, and (iii) the
material parameter are explored on the shock velocity and the domain behind the
converging shock front. The results show that as the shock focuses at the axis
or origin, the shock velocity, the pressure, the temperature, and the
change-in-entropy increase in the shock-compressed titanium Ti6Al4V, stainless
steel 304, aluminum 6061-T6, etc.",http://arxiv.org/abs/2502.02609v1
Photoluminescence Features of Few-Layer Hexagonal $α$-In$_2$Se$_3$,2025-02-06T11:25:00Z,"I. A. Eliseyev, A. I. Veretennikov, A. I. Galimov, L. V. Kotova, G. V. Osochenko, K. A. Gasnikova, D. A. Kirilenko, M. A. Yagovkina, Yu. A. Salii, V. Yu. Davydov, P. A. Alekseev, M. V. Rakhlin","Indium (III) selenide is currently one of the most actively studied materials
in the two-dimensional family due to its remarkable ferroelectric and optical
properties. This study focuses on the luminescent properties of few-layer
In$_2$Se$_3$ flakes with thicknesses ranging from 7 to 100 monolayers. To
explore the photoluminescence features and correlate them with changes in
crystal symmetry and surface potential, we employed a combination of
techniques, including temperature-dependent micro-photoluminescence,
time-resolved photoluminescence, Raman spectroscopy, atomic force microscopy,
and Kelvin probe force microscopy. X-ray diffraction and Raman spectroscopy
confirmed that the samples studied possess the $\alpha$-polytype structure. The
micro-photoluminescence spectrum consists of two bands, A and B, with band B
almost completely disappearing at room temperature. Temperature-dependent
photoluminescence and time-resolved measurements helped us to elucidate the
nature of the observed bands. We find that peak A is associated with emission
from interband transitions in In$_2$Se$_3$, while peak B is attributed to
defect-related emission. Additionally, the photoluminescence decay times of
In$_2$Se$_3$ flakes with varying thicknesses were determined. No significant
changes were observed in the decay components as the thickness increased from 7
to 100 monolayers, suggesting that there are no qualitative changes in the band
structure.",http://arxiv.org/abs/2502.03981v1
"Maximizing nanoparticle light absorption: size, geometry, and a prospect
  for metal alloys",2025-02-06T12:49:51Z,"Matej Bubaš, Jordi Sancho-Parramon","In this work we show how to maximize absorption of plasmonic nanoparticles in
terms of size, geometry and material. For that reason the interaction of
nanoparticles with light was decomposed into different effects. We determined
that the main effect dictating the optimal amount of optical losses is
radiation damping, and how it depends on nanoparticle size and geometry. Based
on this, we find that for many combinations of sizes and geometries losses in
pure metals are far from optimal. To overcome the aforementioned issue,
alloying is presented as straightforward and flexible way of modulating the
optical losses. Furthermore, strategies for tuning the optical losses to values
above, between, and even below those in pure plasmonic metals are developed in
terms of selecting the right alloy composition. In some cases, alloys showed a
multifold increase in absorption when compared to pure plasmonic metals. The
physical reasons governing such changes are elucidated based on the electronic
structure changes during alloying of different metals, which enables
generalization of the results to other systems. Besides increasing absorption,
electronic structure changes can also be utilized for channeling the absorbed
energy to suit different purposes, such as hot carrier generation for
photocatalysis or solar energy harvesting. Overall, these results establish
alloying as a powerful tool for designing nanostructures for applications that
utilize light absorption.",http://arxiv.org/abs/2502.04032v1
"AgilePilot: DRL-Based Drone Agent for Real-Time Motion Planning in
  Dynamic Environments by Leveraging Object Detection",2025-02-10T17:54:30Z,"Roohan Ahmed Khan, Valerii Serpiva, Demetros Aschalew, Aleksey Fedoseev, Dzmitry Tsetserukou","Autonomous drone navigation in dynamic environments remains a critical
challenge, especially when dealing with unpredictable scenarios including
fast-moving objects with rapidly changing goal positions. While traditional
planners and classical optimisation methods have been extensively used to
address this dynamic problem, they often face real-time, unpredictable changes
that ultimately leads to sub-optimal performance in terms of adaptiveness and
real-time decision making. In this work, we propose a novel motion planner,
AgilePilot, based on Deep Reinforcement Learning (DRL) that is trained in
dynamic conditions, coupled with real-time Computer Vision (CV) for object
detections during flight. The training-to-deployment framework bridges the
Sim2Real gap, leveraging sophisticated reward structures that promotes both
safety and agility depending upon environment conditions. The system can
rapidly adapt to changing environments, while achieving a maximum speed of 3.0
m/s in real-world scenarios. In comparison, our approach outperforms classical
algorithms such as Artificial Potential Field (APF) based motion planner by 3
times, both in performance and tracking accuracy of dynamic targets by using
velocity predictions while exhibiting 90% success rate in 75 conducted
experiments. This work highlights the effectiveness of DRL in tackling
real-time dynamic navigation challenges, offering intelligent safety and
agility.",http://arxiv.org/abs/2502.06725v1
"Flip-flop QPO changes during state transitions: a case study of GX339-4
  and theoretical discussion",2025-02-12T19:00:06Z,"D. J. K. Buisson, G. Marcel, V. López-Barquero, S. E. Motta, S. G. D. Turner, F. M. Vincentelli","We analyse the 2021 outburst from the black hole X-ray binary GX339-4
observed by NICER around the hard to soft transition, when the system exhibits
flip-flops between two distinct luminosity states: a bright state with a 5-6 Hz
quasi-periodic oscillation (QPO) and a dim state showing only strong broadband
noise. Despite the marked differences in variability patterns between these
states, the spectral energy distributions remain strikingly similar, with only
minor changes in the black body component in the soft X-ray range. We find that
the QPO frequency correlates with the X-ray count rates and hardness,
suggesting a tight coupling between the QPO mechanism and the accretion disc's
spectral properties. Additionally, we demonstrate that flip-flops can occur on
very short timescales, with almost 50 state changes within ~1200 s, while both
states can also remain stable over longer periods (at least 1000 s). We explore
various QPO models to explain these observations, including the possibility
that the corona's accretion speed is near the sound speed, affecting the
presence of QPOs. However, the exact mechanism driving the flip-flops and the
QPOs remains unclear. Our findings emphasize the complexity of these phenomena
and the necessity for further theoretical and observational studies to unravel
the intricacies of QPO and flip-flop behaviours in X-ray binaries.",http://arxiv.org/abs/2502.08718v1
"Pace in Concert with Phase: Rate-induced Phase-tipping in Birhythmic
  Oscillators",2025-02-13T11:27:57Z,"Ravi Kumar K, Hassan Alkhayuon, Sebastian Wieczorek, Partha Sharathi Dutta","We study rate-induced phase-tipping (RP-tipping) between two stable limit
cycles of a birhythmic oscillator. We say that such an oscillator RP-tips when
a time variation of an input parameter preserves the bistability of the limit
cycles but induces transitions from one stable limit cycle to the other,
causing abrupt changes in the amplitude and frequency of the oscillations.
Crucially, these transitions occur when: the rate of change of the input is in
a certain interval bounded by critical rate(s), and the system is in certain
phases of the cycle.
  We focus on two illustrative examples: the birhythmic van der Pol oscillator
and the birhythmic Decroly-Goldbeter glycolysis model, each subjected to
monotone and non-monotone shifts in their input parameters. We explain
RP-tipping in terms of properties of the autonomous frozen system, including
the phase of a cycle and partial basin instability along the parameter path
traced by the changing input. We show that RP-tipping can occur as an
irreversible one-way transition or as a series of transitions between the
stable limit cycles. Finally, we present RP-tipping diagrams showing
combinations of the rate and magnitude of parameter shifts and the phase of the
oscillation that give rise to this genuine non-autonomous instability.",http://arxiv.org/abs/2502.09190v1
Merging public elementary schools to reduce racial/ethnic segregation,2025-02-14T14:36:28Z,"Madison Landry, Nabeel Gillani","Diverse schools can help address implicit biases and increase empathy, mutual
respect, and reflective thought by fostering connections between students from
different racial/ethnic, socioeconomic, and other backgrounds. Unfortunately,
demographic segregation remains rampant in US public schools, despite over 70
years since the passing of federal legislation formally outlawing segregation
by race. However, changing how students are assigned to schools can help foster
more integrated learning environments. In this paper, we explore ""school
mergers"" as one such under-explored, yet promising, student assignment policy
change. School mergers involve merging the school attendance boundaries, or
catchment areas, of schools and subsequently changing the grades each school
offers. We develop an algorithm to simulate elementary school mergers across
200 large school districts serving 4.5 million elementary school students and
find that pairing or tripling schools in this way could reduce racial/ethnic
segregation by a median relative 20% -- and as much as nearly 60% in some
districts -- while increasing driving times to schools by an average of a few
minutes each way. Districts with many interfaces between
racially/ethnically-disparate neighborhoods tend to be prime candidates for
mergers. We also compare the expected results of school mergers to other
typical integration policies, like redistricting, and find that different
policies may be more or less suitable in different places. Finally, we make our
results available through a public dashboard for policymakers and community
members to explore further (https://mergers.schooldiversity.org). Together, our
study offers new findings and tools to support integration policy-making across
US public school districts.",http://arxiv.org/abs/2502.10193v1
"Investigation of the Estimation Accuracy of 5 Different Numerical ODE
  Solvers on 3 Case Studies",2025-02-14T16:51:01Z,"Hamidreza Moradi, Erfan Kefayat, Hamideh Hossei","Numerical ordinary differential equation (ODE) solvers are indispensable
tools in various engineering domains, enabling the simulation and analysis of
dynamic systems. In this work, we utilize 5 different numerical ODE solvers
namely: Euler's method, Heun's method, Midpoint Method, Runge-kutta 4th order
and ODE45 method in order to discover the answer of three wellknown case
studies and compare their results by calculation of relative errors. To check
for the validity of the estimations, the experimental data of previous
literature have been compared with the data in this paper which shows a good
accordance. We observe that for each of the case studies based on the behavior
of the model, the estimation accuracy of the solvers is different. For the
logistic population change as the first case study, the results of all solvers
are so close to each other that only their solution cost can be considered for
their superiority. For temperature change of a building as the second case
study we see that in some especial areas the accuracy of the solvers is
different and in general Midpoint ODE solver shows better results. As the last
case study, market equilibrium price shows that none of the numerical ODE
solvers can estimate its behavior which is due to its sudden changing nature.",http://arxiv.org/abs/2502.10289v1
"Bayesian inference from time series of allele frequency data using exact
  simulation techniques",2025-02-17T19:28:15Z,"Jaromir Sant, Paul A. Jenkins, Jere Koskela, Dario Spano","A central statistical problem in population genetics is to infer evolutionary
and biological parameters such as the strength of natural selection and allele
age from DNA samples extracted from a contemporary population. That all samples
come only from the present-day has long been known to limit statistical
inference; there is potentially more information available if one also has
access to ancient DNA so that inference is based on a time-series of historical
changes in allele frequencies. We introduce a Markov Chain Monte Carlo (MCMC)
method for Bayesian inference from allele frequency time-series data based on
an underlying Wright--Fisher diffusion model of evolution, through which one
can infer the parameters of essentially any selection model including those
with frequency-dependent effects. The chief novelty is that we show this method
to be exact in the sense that it is possible to augment the state space
explored by MCMC with the unobserved diffusion trajectory, even though the
transition function of this diffusion is intractable. Through careful design of
a proposal distribution, we describe an efficient method in which updates to
the trajectory and accept/reject decisions are calculated without error. We
illustrate the method on data capturing changes in coat colour over the past
20,000 years, and find evidence to support previous findings that the mutant
alleles ASIP and MC1R responsible for changes in coat color have experienced
very strong, possibly overdominant, selection and further provide estimates for
the ages of these genes.",http://arxiv.org/abs/2502.12279v1
The Non-Relativistic Limit of Keldysh Spinors,2025-01-08T14:04:39Z,A. Jourjine,"Keldysh spinors obey Dirac equation, but have the negative of the Dirac
action and Hamiltonian. In an example of the U(1) EM coupling, we show that,
despite the sign changes, they have a well-defined non-relativistic limit
resulting in quantum mechanics with the positive-definite Pauli Hamiltonian.
When non-relativistic Dirac and Keldysh fields are brought to interact, we
observe curious decoupling of the two fields in mass-like and vector couplings.",http://arxiv.org/abs/2501.04514v1
"Modeling the impact of hospitalization-induced behavioral changes on
  SARS-COV-2 spread in New York City",2025-01-12T21:35:24Z,"Alice Oveson, Michelle Girvan, Abba Gumel","A novel behavior-epidemiology model, which considers $n$ heterogeneous
behavioral groups based on level of risk tolerance and distinguishes behavioral
changes by social and disease-related motivations (such as peer-influence and
fear of disease-related hospitalizations), is developed. In addition to
rigorously analyzing the basic qualitative features of this model, a special
case is considered where the total population is stratified into two groups:
risk-averse (Group 1) and risk-tolerant (Group 2). The two-group behavior model
has three disease-free equilibria in the absence of disease, and their
stability is analyzed using standard linearization and the properties of
Metzler-stable matrices. Furthermore, the two-group model was calibrated and
validated using daily hospitalization data for New York City during the first
wave, and the calibrated model was used to predict the data for the second
wave. Numerical simulations of the calibrated two-group behavior model showed
that while the dynamics of the SARS-CoV-2 pandemic during the first wave was
largely influenced by the behavior of the risk-tolerant individuals, the
dynamics during the second wave was influenced by the behavior of individuals
in both groups. It was also shown that disease-motivated behavioral changes had
greater influence in significantly reducing SARS-CoV-2 morbidity and mortality
than behavior changes due to the level of peer or social influence or pressure.
Finally, it is shown that the initial proportion of members in the community
that are risk-averse (i.e., the proportion of individuals in Group 1 at the
beginning of the pandemic) and the early and effective implementation of
non-pharmaceutical interventions have major impacts in reducing the size and
burden of the pandemic (particularly the total SARS-CoV-2 mortality in New York
City during the second wave).",http://arxiv.org/abs/2501.06941v1
Restrictions on Hilbert coefficients give depths of graded domains,2025-01-14T04:21:35Z,Cheng Meng,"In this paper, we prove that if $P$ is a homogeneous prime ideal inside a
standard graded polynomial ring $S$ with $\dim(S/P)=d$, and for $s \leq d$,
adjoining $s$ general linear forms to the prime ideal changes the $(d-s)$-th
Hilbert coefficient by 1, then $\text{depth}(S/P)=s-1$. This criterion also
tells us about possible restrictions on the generic initial ideal of a prime
ideal inside a polynomial ring.",http://arxiv.org/abs/2501.07829v1
"Two-Measure Electroweak Standard Model. Some aspects of cosmological
  evolution and vacuum stability",2025-01-26T18:09:46Z,Alexander B. Kaganovich,"In the FLRW universe, the scalar field \phi(t) obtained by cosmological
averaging of the local Higgs field H(x) is considered as a classical field for
which the SM quantization procedure is meaningless. When applying the
Two-Measure theory (TMT) to study cosmology, the ratio \zeta of the measure
densities is a scalar function, which: enters into all equations of motion.
Through the constraint, $\zeta$ is defined as a function of \phi(t). During
cosmological evolution, \zeta(\phi) changes from \zeta\approx 0 at the
inflationary stage to \zeta=1 at the approaching vacuum stage. Each stage of
the classical cosmological background is determined by the set \{\phi(t), {\rm
curvature}, \zeta(\phi(t))\}. The Two-Measure SM (TMSM) is realized in the
context of cosmology as a set of cosmologically modified copies of the GWS
model. Each of the copies exists as a local quantum field theory defined on the
classical cosmological background at the appropriate stage of its evolution.
This basic idea is studied in detail for the stage of slow-roll inflation and
for the stage of approaching vacuum. Due to the presence of \zeta(\phi(t)) in
all equations of motion, all TMSM coupling constants turn out to be running
(classical) TMT-effective parameters. During cosmological evolution, changing
these parameters yields new results: the classical running TMT-effective Higgs
selfcoupling increases from \lambda\sim 10^{-11} (which ensures consistency
with Planck's CMB data at \xi=\frac{1}{6}) to \lambda\sim 0.1 near vacuum; the
mass term in the Higgs potential changes sign from positive to negative,
providing standard SSB; the classical running gauge and Yukawa coupling
constants change by several orders of magnitude; the GWS theory is reproduced
so that the fermion mass hierarchy is obtained quite naturally. 1-loop quantum
corrections preserves the slow-roll inflation and does not violate the vacuum
stability.",http://arxiv.org/abs/2501.15623v2
Ideal of the variety of flexes of plane cubics,2025-02-03T17:16:36Z,Vladimir L. Popov,"We prove that the variety of flexes of algebraic curves of degree $3$ in the
projective plane is an ideal theoretic complete intersection in the product of
a two-dimensional and a nine-dimensional projective spaces.",http://arxiv.org/abs/2502.01539v2
Dimer problem on a spherical surface,2025-02-10T17:54:11Z,"A. Tononi, D. S. Petrov, M. Lewenstein","We solve the problem of a dimer moving on a spherical surface and find that
its binding energy and wave function are sensitive to the total angular
momentum. The dimer gets squeezed in the direction orthogonal to the
center-of-mass motion and can qualitatively change its geometry from
two-dimensional to one-dimensional.",http://arxiv.org/abs/2502.06724v1
"Hypercubic Decomposition of Verma Supermodules and Semibricks Realizing
  the Khovanov Algebra of Defect One",2025-02-16T04:15:25Z,Shunsuke Hirota,"We study some variants of Verma modules of basic Lie superalgebras obtained
via changing Borel subalgebras. These allow us to demonstrate that the
principal block of \(\mathfrak{gl}(1|1)\) is realized as (non-Serre) full
subcategories of any atypical block of BGG category \( \mathcal{O} \) of basic
Lie superalgebras.",http://arxiv.org/abs/2502.10987v2
"Identifying Bug Inducing Commits by Combining Fault Localisation and
  Code Change Histories",2025-02-18T15:02:22Z,"Gabin An, Jinsu Choi, Jingun Hong, Naryeong Kim, Shin Yoo","A Bug Inducing Commit (BIC) is a code change that introduces a bug into the
codebase. Although the abnormal or unexpected behavior caused by the bug may
not manifest immediately, it will eventually lead to program failures further
down the line. When such a program failure is observed, identifying the
relevant BIC can aid in the bug resolution process, because knowing the
original intent and context behind the code change, as well as having a link to
the author of that change, can facilitate bug triaging and debugging. However,
existing BIC identification techniques have limitations. Bisection can be
computationally expensive because it requires executing failing tests against
previous versions of the codebase. Other techniques rely on the availability of
specific post hoc artifacts, such as bug reports or bug fixes. In this paper,
we propose a technique called Fonte that aims to identify the BIC with a core
concept that a commit is more likely to be a BIC if it has more recently
modified code elements that are highly suspicious of containing the bug. To
realise this idea, Fonte leverages two fundamental relationships in software:
the failure-to-code relationship, which can be quantified through fault
localisation techniques, and the code-to-commit relationship, which can be
obtained from version control systems. Our empirical evaluation using 206
real-world BICs from open-source Java projects shows that Fonte significantly
outperforms state-of-the-art BIC identification techniques, achieving up to
45.8% higher MRR. We also report that the ranking scores produced by Fonte can
be used to perform weighted bisection. Finally, we apply Fonte to a large-scale
industry project with over 10M lines of code, and show that it can rank the
actual BIC within the top five commits for 87% of the studied real
batch-testing failures, and save the BIC inspection cost by 32% on average.",http://arxiv.org/abs/2502.12922v2
DMSA: A Decentralized Microservice Architecture for Edge Networks,2025-01-01T16:07:34Z,"Yuang Chen, Chengdi Lu, Yongsheng Huang, Chang Wu, Fengqian Guo, Hancheng Lu, Chang Wen Chen","The dispersed node locations and complex topologies of edge networks,
combined with intricate dynamic microservice dependencies, render traditional
centralized microservice architectures (MSAs) unsuitable. In this paper, we
propose a decentralized microservice architecture (DMSA), which delegates
scheduling functions from the control plane to edge nodes. DMSA redesigns and
implements three core modules of microservice discovery, monitoring, and
scheduling for edge networks to achieve precise awareness of instance
deployments, low monitoring overhead and measurement errors, and accurate
dynamic scheduling, respectively. Particularly, DMSA has customized a
microservice scheduling scheme that leverages multi-port listening and
zero-copy forwarding to guarantee high data forwarding efficiency. Moreover, a
dynamic weighted multi-level load balancing algorithm is proposed to adjust
scheduling dynamically with consideration of reliability, priority, and
response delay. Finally, we have implemented a physical verification platform
for DMSA. Extensive empirical results demonstrate that compared to
state-of-the-art and traditional scheduling schemes, DMSA effectively
counteracts link failures and network fluctuations, improving the service
response delay and execution success rate by approximately $60\% \sim 75\%$ and
$10\%\sim15\%$, respectively.",http://arxiv.org/abs/2501.00883v1
Aligning Netlist to Source Code using SynAlign,2025-01-01T18:40:05Z,"Sakshi Garg, Jose Renau","In current chip design processes, using multiple tools to obtain a gate-level
netlist often results in the loss of source code correlation. SynAlign
addresses this challenge by automating the alignment process, simplifying
iterative design, reducing overhead, and maintaining correlation across various
tools. This enhances the efficiency and effectiveness of chip design workflows.
  Improving characteristics such as frequency through iterative design is
essential for enhancing accelerators and chip designs. While synthesis tools
produce netlists with critical path information, designers often lack the tools
to trace these netlist cells back to their original source code. Mapping
netlist components to source code provides early feedback on timing and power
for frontend designers.
  SynAlign automatically aligns post-optimized netlists with the original
source code without altering compilers or synthesis processes. Its alignment
strategy relies on the consistent design structure throughout the chip design
cycle, even with changes in compiler flow. This consistency allows engineers to
maintain a correlation between modified designs and the original source code
across various tools. Remarkably, SynAlign can tolerate up to 61\% design net
changes without impacting alignment accuracy.",http://arxiv.org/abs/2501.00921v1
"FAPL-DM-BC: A Secure and Scalable FL Framework with Adaptive Privacy and
  Dynamic Masking, Blockchain, and XAI for the IoVs",2025-01-02T05:21:52Z,"Sathwik Narkedimilli, Amballa Venkata Sriram, Sujith Makam, MSVPJ Sathvik, Sai Prashanth Mallellu","The FAPL-DM-BC solution is a new FL-based privacy, security, and scalability
solution for the Internet of Vehicles (IoV). It leverages Federated Adaptive
Privacy-Aware Learning (FAPL) and Dynamic Masking (DM) to learn and adaptively
change privacy policies in response to changing data sensitivity and state in
real-time, for the optimal privacy-utility tradeoff. Secure Logging and
Verification, Blockchain-based provenance and decentralized validation, and
Cloud Microservices Secure Aggregation using FedAvg (Federated Averaging) and
Secure Multi-Party Computation (SMPC). Two-model feedback, driven by
Model-Agnostic Explainable AI (XAI), certifies local predictions and
explanations to drive it to the next level of efficiency. Combining local
feedback with world knowledge through a weighted mean computation, FAPL-DM-BC
assures federated learning that is secure, scalable, and interpretable.
Self-driving cars, traffic management, and forecasting, vehicular network
cybersecurity in real-time, and smart cities are a few possible applications of
this integrated, privacy-safe, and high-performance IoV platform.",http://arxiv.org/abs/2501.01063v1
"Self-diffusive dynamics of active Brownian particles at moderate
  densities",2025-01-02T13:31:58Z,Rodrigo Soto,"The Active Brownian Particle (ABP) model has become a prototype of
self-propelled particles. ABPs move persistently at a constant speed $V$ along
a direction that changes slowly by rotational diffusion, characterized by a
coefficient $\Dr$. Persistent motion plus random reorientations generate a
random walk at long times with a diffusion coefficient that, for isolated ABPs
in two dimensions, is given by $D_0=V^2/(2\Dr)$. Here we study the density
effects on the self-diffusive dynamics using a recently proposed kinetic theory
for ABPs, in which persistent collisions are described as producing a net
displacement on the particles. On intermediate timescales, where many
collisions have taken place but the director of the tagged particle has not yet
changed, an effective stochastic dynamics emerges, characterized by an
effective reduced streaming velocity $V_\text{eff}$ and anisotropic diffusion,
with coefficients explicitly depending on density. Based on this result, an
effective theoretical and numerical approach is proposed in which the particles
follow stochastic dynamics with mean-field interactions based on the local
density. Finally, on time scales larger than $\Dr^{-1}$, the tagged particle
shows an effective diffusive motion with a coefficient
$D=V_\text{eff}^2/(2\Dr)$. The dependence of $V_\text{eff}$ on density
indicates that the kinetic theory is limited to are fractions smaller than
0.42, and beyond this limit unphysical results appear.",http://arxiv.org/abs/2501.01251v1
"Automating Legal Concept Interpretation with LLMs: Retrieval,
  Generation, and Evaluation",2025-01-03T10:11:38Z,"Kangcheng Luo, Quzhe Huang, Cong Jiang, Yansong Feng","Legal articles often include vague concepts for adapting to the ever-changing
society. Providing detailed interpretations of these concepts is a critical and
challenging task even for legal practitioners. It requires meticulous and
professional annotations and summarizations by legal experts, which are
admittedly time-consuming and expensive to collect at scale. By emulating legal
experts' doctrinal method, we introduce a novel framework, ATRIE, using large
language models (LLMs) to AuTomatically Retrieve concept-related information,
Interpret legal concepts, and Evaluate generated interpretations, eliminating
dependence on legal experts. ATRIE comprises a legal concept interpreter and a
legal concept interpretation evaluator. The interpreter uses LLMs to retrieve
relevant information from judicial precedents and interpret legal concepts. The
evaluator uses performance changes on legal concept entailment, a downstream
task we propose, as a proxy of interpretation quality. Automatic and
multifaceted human evaluations indicate that the quality of our interpretations
is comparable to those written by legal experts, with superior
comprehensiveness and readability. Although there remains a slight gap in
accuracy, it can already assist legal practitioners in improving the efficiency
of concept interpretation.",http://arxiv.org/abs/2501.01743v2
Kinetic Model of the Emergence of Autocatalysis,2025-01-03T13:09:44Z,"P. O. Mchedlov-Petrosyan, L. N. Davydov","We develop a formal model of the emergence of self-constructing objects (e.g.
heteropolymers with autocatalytic capability) in an open system, which don't
contain such objects initially. The objects are constructed from subunits (e.g.
monomers). Each object is characterized by the difference of self-instructed
reproduction and decomposition rate only. This difference, divided by a common
dimensional constant, is called ``productivity''. Due to external influence the
productivity of each object can randomly change. The system as a whole is
subjected to external limitation: the total number of the objects is conserved
(e.g., by the controlled influx of monomers). We consider such process as
possibly simplest example of self-organization. We obtained exact solutions of
our model for several presumed mechanisms of random change of the productivity.
We have shown that the probability to find self-constructing objects in the
system necessarily increases, even if initially it was equal to zero.",http://arxiv.org/abs/2501.01795v1
Spin-period variations in the intermediate polar RX J2133.7+5107,2025-01-03T18:38:23Z,"V. Breus, I. L. Andronov, P. Dubovsky, Y. Kim, J. N. Yoon, K. Petrik","We report the results of long-term time series photometry on RX J2133.7+5107
(also known as 1RXS J213344.1+510725) obtained at several observatories. Using
data taken during 17 years, we determined the current value of the spin period
of $570.811470$ seconds with the formal accuracy of $0.000006$ seconds and a
spin-up of the white dwarf with a characteristic time of $1.483(1)\times10^5$
years. This is even faster than that reported previously and, if confirmed,
makes this object have one of the fastest spin-up timescales of all known
intermediate polars. We derived an improved value of the superhump period of
the system to be $0^d.280130(1)$. Superhump maxima timings are moving on the
phase curve from season to season, showing non-monotonic changes, without a
change in superhump period.",http://arxiv.org/abs/2501.01940v1
"Multi-Aggregator Time-Warping Heterogeneous Graph Neural Network for
  Personalized Micro-Video Recommendation",2025-01-05T21:14:35Z,"Jinkun Han, Wei Li, Xhipeng Cai, Yingshu Li","Micro-video recommendation is attracting global attention and becoming a
popular daily service for people of all ages. Recently, Graph Neural
Networks-based micro-video recommendation has displayed performance improvement
for many kinds of recommendation tasks. However, the existing works fail to
fully consider the characteristics of micro-videos, such as the high timeliness
of news nature micro-video recommendation and sequential interactions of
frequently changed interests. In this paper, a novel Multi-aggregator
Time-warping Heterogeneous Graph Neural Network (MTHGNN) is proposed for
personalized news nature micro-video recommendation based on sequential
sessions, where characteristics of micro-videos are comprehensively studied,
users' preference is mined via multi-aggregator, the temporal and dynamic
changes of users' preference are captured, and timeliness is considered.
Through the comparison with the state-of-the-arts, the experimental results
validate the superiority of our MTHGNN model.",http://arxiv.org/abs/2501.02666v1
"IIMedGPT: Promoting Large Language Model Capabilities of Medical Tasks
  by Efficient Human Preference Alignment",2025-01-06T09:22:36Z,"Yiming Zhang, Zheng Chang, Wentao Cai, MengXing Ren, Kang Yuan, Yining Sun, Zenghui Ding","Recent researches of large language models(LLM), which is pre-trained on
massive general-purpose corpora, have achieved breakthroughs in responding
human queries. However, these methods face challenges including limited data
insufficiency to support extensive pre-training and can not align responses
with users' instructions. To address these issues, we introduce a medical
instruction dataset, CMedINS, containing six medical instructions derived from
actual medical tasks, which effectively fine-tunes LLM in conjunction with
other data. Subsequently, We launch our medical model, IIMedGPT, employing an
efficient preference alignment method, Direct preference Optimization(DPO). The
results show that our final model outperforms existing medical models in
medical dialogue.Datsets, Code and model checkpoints will be released upon
acceptance.",http://arxiv.org/abs/2501.02869v1
Operating semiconductor qubits without individual barrier gates,2025-01-06T14:21:53Z,"A. S. Ivlev, D. R. Crielaard, M. Meyer, W. I. L. Lawrie, N. W. Hendrickx, A. Sammak, G. Scappucci, C. Déprez, M. Veldhorst","Semiconductor spin qubits have emerged as a promising platform for quantum
computing, following a significant improvement in their control fidelities over
recent years. Increasing the qubit count remains challenging, beginning with
the fabrication of small features and complex fanouts. A particular challenge
has been formed by the need for individual barrier gates to control the
exchange interaction between adjacent spin qubits. Here, we propose a method to
vary two-qubit interactions without applying pulses on individual barrier gates
while also remaining insensitive to detuning noise in first order. By changing
plunger gate voltages over 300 mV we tune the exchange energy $J$ from 100 kHz
to 60 MHz. This allows us to perform two-qubit operations without changing the
barrier gate voltage. Based on these findings we conceptualize a spin qubit
architecture without individual barrier gates, simplifying the fabrication
while maintaining the control necessary for universal quantum computation.",http://arxiv.org/abs/2501.03033v1
"Environmental Policy in General Equilibrium under Market Power and Price
  Discrimination",2025-01-06T16:21:19Z,"Tengjiao Chen, Daniel H. Karney","This study constructs a novel analytical general equilibrium model to compare
environmental policies in a setting where oligopolistic energy firms engage in
third-degree price discrimination across residential consumers and industrial
firms. Closed-form solutions demonstrate the impact on prices and quantities.
The resulting welfare change is decomposed across three distortions: output,
price discrimination, and externality. This study finds that the output
distortion and price discrimination welfare effects generally move in opposite
directions under policies such as an emission tax or a two-part instrument.
Numerical analysis compares policies and finds scenarios where the output
distortion and price discrimination welfare changes fully offset and thus
leaves the net welfare gain of the externality correction. In this way,
environmental policy can be designed to mitigate output distortion welfare
concerns when firms have market power.",http://arxiv.org/abs/2501.03114v1
"Multimodal Machine Learning Can Predict Videoconference Fluidity and
  Enjoyment",2025-01-06T18:05:35Z,"Andrew Chang, Viswadruth Akkaraju, Ray McFadden Cogliano, David Poeppel, Dustin Freeman","Videoconferencing is now a frequent mode of communication in both
professional and informal settings, yet it often lacks the fluidity and
enjoyment of in-person conversation. This study leverages multimodal machine
learning to predict moments of negative experience in videoconferencing. We
sampled thousands of short clips from the RoomReader corpus, extracting audio
embeddings, facial actions, and body motion features to train models for
identifying low conversational fluidity, low enjoyment, and classifying
conversational events (backchanneling, interruption, or gap). Our best models
achieved an ROC-AUC of up to 0.87 on hold-out videoconference sessions, with
domain-general audio features proving most critical. This work demonstrates
that multimodal audio-video signals can effectively predict high-level
subjective conversational outcomes. In addition, this is a contribution to
research on videoconferencing user experience by showing that multimodal
machine learning can be used to identify rare moments of negative user
experience for further study or mitigation.",http://arxiv.org/abs/2501.03190v2
"Graph Based, Adaptive, Multi Arm, Multiple Endpoint, Two Stage Design",2025-01-06T18:16:21Z,"Cyrus Mehta, Ajoy Mukhopadhyay, Martin Posch","The graph based approach to multiple testing is an intuitive method that
enables a study team to represent clearly, through a directed graph, its
priorities for hierarchical testing of multiple hypotheses, and for propagating
the available type-1 error from rejected or dropped hypotheses to hypotheses
yet to be tested. Although originally developed for single stage non-adaptive
designs, we show how it may be extended to two-stage designs that permit early
identification of efficacious treatments, adaptive sample size re-estimation,
dropping of hypotheses, and changes in the hierarchical testing strategy at the
end of stage one. Two approaches are available for preserving the family wise
error rate in the presence of these adaptive changes; the p-value combination
method, and the conditional error rate method. In this investigation we will
present the statistical methodology underlying each approach and will compare
the operating characteristics of the two methods in a large simulation
experiment.",http://arxiv.org/abs/2501.03197v1
Analog of the Carnot engine for fluctuating diffusivity in living cells,2025-01-07T00:45:39Z,Yuichi Itto,"Recently, a formal analogy between the fluctuating diffusivity and
thermodynamics has been proposed based on phenomena of heterogeneous diffusion
observed in living cells. This not only offers the analogs of the quantity of
heat and work as well as the internal energy but also achieves that of the
Clausius inequality for the entropy concerning diffusivity fluctuations. Here,
a discussion is developed about constructing a heat-like engine in terms of the
fluctuating diffusivity. The engine constitutes two kinds of processes with the
average diffusivity or the average local temperature being kept fixed, along
which the fluctuation distribution obeys an exponential law. The efficiency of
the engine in a cycle, which quantifies how much the diffusivity change as the
analog of work can be extracted, is found to formally coincide with that of
Carnot's. During the cycle, the total change of the entropy is also shown to
vanish.",http://arxiv.org/abs/2501.03452v1
Thermal Transport Properties of Magnons on the $α$-T$_3$ Lattice,2025-01-07T18:36:11Z,"Luqman Saleem, Hasan M. Abdullah, Udo Schwingenschlogl, Aurelien Manchon","We theoretically investigate magnons on the $\alpha$-T$_3$ lattice. Atomistic
spin dynamics simulations show that next-nearest neighbor hopping and easy-axis
anisotropy stabilize ferromagnetic order in the presence of
Dzyaloshinskii-Moriya interaction. We identify one topologically trivial magnon
insulator phase and three magnon Chern insulator phases. The topologically
trivial magnon insulator phase exhibits a small but non-zero magnon thermal
Hall conductivity, while in the magnon Chern insulator phases the Chern number
of the lowest magnon band dominates the magnon thermal Hall conductivity. The
sign of the magnon thermal Hall conductivity does not change at the topological
phase boundaries, but distinct changes are observed in the magnitude.",http://arxiv.org/abs/2501.03979v1
"Exploiting Instabilities to Enable Large Shape Transformations in
  Dielectric Elastomers",2025-01-07T20:25:12Z,"Daniel Katusele, Carmel Majidi, Pradeep Sharma, Kaushik Dayal","Dielectric elastomers have significant potential for new technologies ranging
from soft robots to biomedical devices, driven by their ability to display
complex shape changes in response to electrical stimulus. However, an important
shortcoming of current realizations is that large voltages are required for
useful actuation strains. This work proposes, and demonstrates through theory
and numerical simulations, a strategy to achieve large and controlled actuation
by exploiting the electromechanical analog of the Treloar-Kearsley (TK)
instability. The key idea is to use the fact that the TK instability is a
symmetry-breaking bifurcation, which implies the existence of a symmetry-driven
constant-energy region in the energy landscape. This provides for nonlinear
soft modes with large deformations that can be accessed with very small
external stimulus, which is achieved here by applying a small in-plane electric
field. First, the bifurcation and post-bifurcation behavior of the
electromechanical TK instability are established theoretically in the idealized
setting of uniform deformation and electric field. Next, building on this, a
finite element analysis of a realistic geometry with patterned top and bottom
electrodes is applied to demonstrate large and soft shape changes driven by
small voltage differences across the electrodes.",http://arxiv.org/abs/2501.04128v1
"Modeling with quantities in calculus and physics: A conceptual framework
  of the fundamental theorem",2025-01-08T01:32:34Z,"Suzanne White Brahmia, Patrick W. Thompson","There is a substantial curricular overlap between calculus and physics, yet
introductory physics students often struggle to connect the two. We introduce a
conceptual framework for the Fundamental Theorem of Calculus (FTC) to help
unify learning across both disciplines. We propose a consistent approach to
teaching definite integrals, including shared vocabulary and symbolism, to help
students recognize how concepts like change, rate, and accumulation show up in
both calculus and physics. We argue that the typical interpretation of the FTC
in calculus, focusing on antiderivatives in closed form, doesn't align well
with how physicists use these concepts. We advocate for an additional focus on
Riemann sums and the underlying ideas of change, rate, products, and
accumulation, which are fundamental in both fields. This approach can help
students build a deeper, more integrated understanding of both mathematics and
physics quantity. By aligning learning objectives across the disciplines, we
argue that students can develop a stronger understanding of foundational
mathematical principles.",http://arxiv.org/abs/2501.04219v1
"Mathematical Modelling of Mechanotransduction via RhoA Signalling
  Pathways",2025-01-08T10:40:05Z,"Sofie Verhees, Chandrasekhar Venkataraman, Mariya Ptashnyk","We derive and simulate a mathematical model for mechanotransduction related
to the Rho GTPase signalling pathway. The model addresses the bidirectional
coupling between signalling processes and cell mechanics. A numerical method
based on bulk-surface finite elements is proposed for the approximation of the
coupled system of nonlinear reaction-diffusion equations, defined inside the
cell and on the cell membrane, and the equations of elasticity. Our simulation
results illustrate novel emergent features such as the strong dependence of the
dynamics on cell shape, a threshold-like response to changes in substrate
stiffness, and the fact that coupling mechanics and signalling can lead to the
robustness of cell deformation to larger changes in substrate stiffness,
ensuring mechanical homeostasis in agreement with experiments.",http://arxiv.org/abs/2501.04407v1
Choosing the Right Norm for Change Point Detection in Functional Data,2025-01-08T12:58:01Z,Patrick Bastian,"We consider the problem of detecting a change point in a sequence of mean
functions from a functional time series. We propose an $L^1$ norm based
methodology and establish its theoretical validity both for classical and for
relevant hypotheses. We compare the proposed method with currently available
methodology that is based on the $L^2$ and supremum norms. Additionally we
investigate the asymptotic behaviour under the alternative for all three
methods and showcase both theoretically and empirically that the $L^1$ norm
achieves the best performance in a broad range of scenarios. We also propose a
power enhancement component that improves the performance of the $L^1$ test
against sparse alternatives. Finally we apply the proposed methodology to both
synthetic and real data.",http://arxiv.org/abs/2501.04476v2
"Stability Exchange near Folds: Analysis of an end-loaded Elastica with a
  Lever Arm",2025-01-06T15:37:56Z,Siva Prasad Chakri Dhanakoti,"Numerous problems in physical sciences can be expressed as
parameter-dependent variational problems. The associated family of equilibria
may or may not exist realistically and can be determined after examining its
stability. Hence, it is crucial to determine the stability and track its
transitions. Generally, the stability characteristics of the equilibria change
near the folds in the parameter space. The direction of stability change can be
encoded through a particular projection of the solutions. In this article, we
identify such projections for variational problems characterized by fixed-free
ends, a class of problems frequently found in mechanics. Using the developed
theory, we study an Elastica subject to an end load applied through a rigid
lever arm. The examples revealed several instances of snap-back instability in
these systems. These findings may aid in enhancing the design of soft robot
arms and other innovative switching mechanisms.",http://arxiv.org/abs/2501.04729v1
"Probabilistic Skip Connections for Deterministic Uncertainty
  Quantification in Deep Neural Networks",2025-01-08T20:12:33Z,"Felix Jimenez, Matthias Katzfuss","Deterministic uncertainty quantification (UQ) in deep learning aims to
estimate uncertainty with a single pass through a network by leveraging outputs
from the network's feature extractor. Existing methods require that the feature
extractor be both sensitive and smooth, ensuring meaningful input changes
produce meaningful changes in feature vectors. Smoothness enables
generalization, while sensitivity prevents feature collapse, where distinct
inputs are mapped to identical feature vectors. To meet these requirements,
current deterministic methods often retrain networks with spectral
normalization. Instead of modifying training, we propose using measures of
neural collapse to identify an existing intermediate layer that is both
sensitive and smooth. We then fit a probabilistic model to the feature vector
of this intermediate layer, which we call a probabilistic skip connection
(PSC). Through empirical analysis, we explore the impact of spectral
normalization on neural collapse and demonstrate that PSCs can effectively
disentangle aleatoric and epistemic uncertainty. Additionally, we show that
PSCs achieve uncertainty quantification and out-of-distribution (OOD) detection
performance that matches or exceeds existing single-pass methods requiring
training modifications. By retrofitting existing models, PSCs enable
high-quality UQ and OOD capabilities without retraining.",http://arxiv.org/abs/2501.04816v1
"Magnetism and electronic dynamics in $CuCr_{2-x}Sn_xS_4$ spinels studied
  by transferred hyperfine fields at $^{119}Sn$ and muon spin rotation and
  relaxation",2025-01-09T11:08:16Z,"Elaheh Sadrollahi, Cynthia P. C. Medrano, Magno A. V. Heringer, E. M. Baggio Saitovitch, Lilian Prodan, Vladimir Tsurkan, F. Jochen Litterst","We investigated magnetization, muon spin rotation ($\mu$SR), and $^{119}Sn$
M\""{o}ssbauer spectroscopy on Sn substituted $CuCr_{2-x}Sn_xS_4$ (x=0.03 and
0.08) spinel compounds. The magnetization and $\mu$SR results reveal similar
additional low-temperature magnetic transitions around 80 K and 40 K as found
for the undoped material, indicating a magnetic ground state deviating from a
simple collinear ferromagnet. The observed changes in the M\""{o}ssbauer
hyperfine spectra are less pronounced and are discussed in view of the
different positions of the local probes $\mu^+$ and $^{119}Sn$ and their
different magnetic coupling to the magnetic Cr lattice. Above 80 K, both
$\mu$SR and M\""{o}ssbauer spectra show temperature-dependent inhomogeneous
broadening either due to structural or charge disorder and changing spin
dynamics that can be related to a precursor magnetic phase above the
well-defined static low-temperature phase.",http://arxiv.org/abs/2501.05151v1
Competition of superconducting pairing symmetries in La3Ni2O7,2025-01-09T14:10:33Z,"Han-Xiang Xu, Yue Xie, Daniel Guterding, Zhijun Wang","The recent discovery of superconductivity in the bilayer Ruddlesden-Popper
nickelate La3Ni2O7 under high pressure has generated much interest in the
superconducting pairing mechanism of nickelates. Various theoretical approaches
have been applied to the study of superconductivity in La3Ni2O7, but lead to a
number of contradicting results. We argue that different superconducting states
in La3Ni2O7 are in close competition and at the same time particularly
sensitive to the choice of interaction parameters as well as changes of the
electronic structure through pressure. Our study uses a multi-orbital Hubbard
model, incorporating all Ni 3d and O 2p states. We analyze the superconducting
pairing mechanism of La3Ni2O7 within the random phase approximation and find a
transition between d-wave and sign-changing s-wave pairing states as a function
of pressure and interaction parameters, which is driven by spin-fluctuations
with different wave vectors. Our work paves the way to understanding seemingly
contradictory theoretical results within a unified framework.",http://arxiv.org/abs/2501.05254v1
Semisimplifications and representations of the General Linear Supergroup,2025-01-09T15:02:46Z,"Thorsten Heidersdorf, Rainer Weissauer","We study the semisimplification of the full karoubian subcategory generated
by the irreducible finite dimensional representations of the algebraic
supergroup $GL(m|n)$ over an algebraically closed field of characteristic zero.
This semisimplification is equivalent to the representations of a pro-reductive
group $H_{m|n}$. We show that there is a canonical decomposition $H_{m|n} \cong
GL(m\!-\! n) \times H_{n|n}$, thereby reducing the determination of $H_{m|n}$
to the equal rank case $m\! =\! n$ which was treated in a previous paper.",http://arxiv.org/abs/2501.05298v4
"Identity-aware Feature Decoupling Learning for Clothing-change Person
  Re-identification",2025-01-10T10:45:38Z,"Haoxuan Xu, Bo Li, Guanglin Niu","Clothing-change person re-identification (CC Re-ID) has attracted increasing
attention in recent years due to its application prospect. Most existing works
struggle to adequately extract the ID-related information from the original RGB
images. In this paper, we propose an Identity-aware Feature Decoupling (IFD)
learning framework to mine identity-related features. Particularly, IFD
exploits a dual stream architecture that consists of a main stream and an
attention stream. The attention stream takes the clothing-masked images as
inputs and derives the identity attention weights for effectively transferring
the spatial knowledge to the main stream and highlighting the regions with
abundant identity-related information. To eliminate the semantic gap between
the inputs of two streams, we propose a clothing bias diminishing module
specific to the main stream to regularize the features of clothing-relevant
regions. Extensive experimental results demonstrate that our framework
outperforms other baseline models on several widely-used CC Re-ID datasets.",http://arxiv.org/abs/2501.05851v1
Metasurface Polarimeter for Structural Imaging and Tissue Diagnostics,2025-01-10T11:06:39Z,"Paul Thrane, Chao Meng, Alexander Bykov, Oleksii Sieryi, Fei Ding, Igor Meglinski, Christopher A. Dirdal, Sergey I. Bozhevolnyi","Histopathology, the study and diagnosis of disease through analysis of tissue
samples, is an indispensable part of modern medicine. However, the practice is
time consuming and labor intensive, compelling efforts to improve the process
and develop new approaches. One perspective technique involves mapping changes
in the polarization state of light scattered by the tissue, but the
conventional implementation requires bulky polarization optics and is slow. We
report the design, fabrication and characterization of a compact metasurface
polarimeter operating at 640 nm enabling simultaneous determination of Stokes
parameters and degree of polarization with $\pm$2% accuracy. To validate its
use for histopathology we map polarization state changes in a tissue phantom
mimicking a biopsy with a cancerous inclusion, comparing it to a commercial
polarimeter. The results indicate a great potential and suggest several
improvements with which we believe metasurface polarimeter based devices will
be ready for practical histopathology application in clinical environment.",http://arxiv.org/abs/2501.05864v1
"AlgoRxplorers | Precision in Mutation: Enhancing Drug Design with
  Advanced Protein Stability Prediction Tools",2025-01-13T02:17:01Z,"Karishma Thakrar, Jiangqin Ma, Max Diamond, Akash Patel","Predicting the impact of single-point amino acid mutations on protein
stability is essential for understanding disease mechanisms and advancing drug
development. Protein stability, quantified by changes in Gibbs free energy
($\Delta\Delta G$), is influenced by these mutations. However, the scarcity of
data and the complexity of model interpretation pose challenges in accurately
predicting stability changes. This study proposes the application of deep
neural networks, leveraging transfer learning and fusing complementary
information from different models, to create a feature-rich representation of
the protein stability landscape. We developed four models, with our third
model, ThermoMPNN+, demonstrating the best performance in predicting
$\Delta\Delta G$ values. This approach, which integrates diverse feature sets
and embeddings through latent transfusion techniques, aims to refine
$\Delta\Delta G$ predictions and contribute to a deeper understanding of
protein dynamics, potentially leading to advancements in disease research and
drug discovery.",http://arxiv.org/abs/2501.07014v3
"A Deep Search for a Strong Diffuse Interstellar Band in the
  Circumgalactic Medium",2025-01-13T06:29:29Z,"Chih-Yuan Chang, Ting-Wen Lan","We investigate the absorption signals of a strong diffuse interstellar band,
DIB$\lambda4430$, in the circumgalactic medium (CGM) traced by MgII absorption
lines. To this end, we make use of approximately 60,000 MgII absorption line
spectra within $0.4<z<1.0$ compiled from the Sloan Digital Sky Surveys and
obtain composite spectra with uncertainties for absorption line measurements
being a few m$\r{A}$. By using MgII absorption strength and dust reddening
relation from the literature, we measure the DIB$\lambda4430$ absorption
strength as a function of $\rm E(B-V)$ in the CGM, and compare the Milky Way
DIB$\lambda4430$ - $\rm E(B-V)$ relation extrapolated down to the CGM $\rm
E(B-V)$ region. Our results show no detectable signals of DIB$\lambda4430$
across the entire $\rm E(B-V)$ range in the CGM traced by MgII absorption
lines. This lack of detection of DIB$\lambda4430$ in the CGM is inconsistent
with the Milky Way signals by $\sim 5 \, \sigma$, indicating that the factors
associated with different environments affect the abundance of the
DIB$\lambda4430$ carrier.",http://arxiv.org/abs/2501.07082v1
"An Investigation into Seasonal Variations in Energy Forecasting for
  Student Residences",2025-01-13T15:43:22Z,"Muhammad Umair Danish, Mathumitha Sureshkumar, Thanuri Fonseka, Umeshika Uthayakumar, Vinura Galwaduge","This research provides an in-depth evaluation of various machine learning
models for energy forecasting, focusing on the unique challenges of seasonal
variations in student residential settings. The study assesses the performance
of baseline models, such as LSTM and GRU, alongside state-of-the-art
forecasting methods, including Autoregressive Feedforward Neural Networks,
Transformers, and hybrid approaches. Special attention is given to predicting
energy consumption amidst challenges like seasonal patterns, vacations,
meteorological changes, and irregular human activities that cause sudden
fluctuations in usage. The findings reveal that no single model consistently
outperforms others across all seasons, emphasizing the need for season-specific
model selection or tailored designs. Notably, the proposed Hyper Network based
LSTM and MiniAutoEncXGBoost models exhibit strong adaptability to seasonal
variations, effectively capturing abrupt changes in energy consumption during
summer months. This study advances the energy forecasting field by emphasizing
the critical role of seasonal dynamics and model-specific behavior in achieving
accurate predictions.",http://arxiv.org/abs/2501.07423v1
"""Near Data"" and ""Far Data"" for Urban Sustainability: How Do Community
  Advocates Envision Data Intermediaries?",2025-01-13T19:47:44Z,"Han Qiao, Siyi Wu, Christoph Becker","In the densifying data ecosystem of today's cities, data intermediaries are
crucial stakeholders in facilitating data access and use. Community advocates
live in these sites of social injustices and opportunities for change. Highly
experienced in working with data to enact change, they offer distinctive
insights on data practices and tools. This paper examines the unique
perspectives that community advocates offer on data intermediaries. Based on
interviews with 17 advocates working with 23 grassroots and nonprofit
organizations, we propose the quality of ""near"" and ""far"" to be seriously
considered in data intermediaries' works and articulate advocates' vision of
connecting ""near data"" and ""far data."" To pursue this vision, we identified
three pathways for data intermediaries: align data exploration with ways of
storytelling, communicate context and uncertainties, and decenter artifacts for
relationship building. These pathways help data intermediaries to put data
feminism into practice, surface design opportunities and tensions, and raise
key questions for supporting the pursuit of the Right to the City.",http://arxiv.org/abs/2501.07661v1
"Annealed mean-field epidemiological model on scale-free networks with a
  mitigating factor",2025-01-13T21:33:21Z,"K. M. Kim, M. O. Hase","An annealed version of the quenched mean-field model for epidemic spread is
introduced and investigated analytically and assisted by numerical
calculations. The interaction between individuals follows a prescription that
is used to generate a scale-free network, and we have adjusted the number of
connections to produce a sparse network. Specifically, the model's behavior
near the infection threshold is examined, as well as the behavior of the
stationary prevalence and the probability that a connection between individuals
encounters an infected one. We found that these functions display a
monotonically increasing dependence on the infection rate. Subsequently, a
modification that mimics the mitigation in the probability of encountering an
infected individual is introduced, following an old idea rooted in the
Malthus-Verhulst model. We found that this modification drastically changes the
probability that a connection meets an infected individual. However, despite
this change, it does not alter the monotonically increasing behavior of the
stationary prevalence.",http://arxiv.org/abs/2501.07706v2
Optimal Control of an Electromechanical Energy Harvester,2025-01-13T22:54:11Z,"Dario Lucente, Alessandro Manacorda, Andrea Plati, Alessandro Sarracino, Marco Baldovin","Many techniques originally developed in the context of deterministic control
theory have been recently applied to the quest for optimal protocols in
stochastic processes. Given a system subject to environmental fluctuations, one
may ask what is the best way to change in time its controllable parameters in
order to maximize, on average, a certain reward function, while steering the
system between two pre-assigned states. In this work we study the problem of
optimal control for a wide class of stochastic systems, inspired by a model of
energy harvester. The stochastic noise in this system is due to the mechanical
vibrations, while the reward function is the average power extracted from them.
We consider the case in which the electrical resistance of the harvester can be
changed in time, and we exploit the tools of control theory to work out optimal
solutions in a perturbative regime, close to the stationary state. Our results
show that it is possible to design protocols that perform better than any
possible solution with constant resistance.",http://arxiv.org/abs/2501.07735v1
"Improving Our Knowledge of the Solar Near-Surface Shear Layer: The
  Special Case of the Leptocline",2025-01-14T11:21:25Z,"Jean-Pierre Rozelot, Alexander Kosovichev, Irina Kitiashvili","The discovery of the solar activity cycle was linked from the outset to the
observation of the temporal variability of sunspots, which we know to be the
result of complex processes associated with the dynamics of inner layers.
Numerous recent studies have highlighted changes in the Sun's Near-Surface
Shear Layer (NSSL), pointing to the role of the leptocline, a shallow and sharp
rotational shear layer in the top around 8 Mm. The leptocline, mainly
characterized by a strong radial rotational gradient at middle latitudes and
self-organized meridional flows, is the cradle of numerous phenomena: opacity,
superadiabaticity, and turbulent pressure changes; the hydrogen and helium
ionization processes; a sharp decrease in the sound speed; and, probably,
variations of the seismic radius associated with a nonmonotonic expansion of
subsurface layers with depth. In addition, the leptocline may play a key role
in forming the magnetic butterfly diagram. Such results are a starting point
for further systematic investigations of the structure and dynamics of this
layer, which will lead to a better understanding of solar activity.",http://arxiv.org/abs/2501.08021v1
"Efficient Planning in Large-scale Systems Using Hierarchical Finite
  State Machines",2025-01-15T16:23:04Z,"Elis Stefansson, Karl H. Johansson","We consider optimal planning in a large-scale system formalised as a
hierarchical finite state machine (HFSM). A planning algorithm is proposed
computing an optimal plan between any two states in the HFSM, consisting of two
steps: A pre-processing step that computes optimal exit costs of the machines
in the HFSM, with time complexity scaling with the number of machines; and a
query step that efficiently computes an optimal plan by removing irrelevant
subtrees of the HFSM using the optimal exit costs. The algorithm is
reconfigurable in the sense that changes in the HFSM are handled with ease,
where the pre-processing step recomputes only the optimal exit costs affected
by the change. The algorithm can also exploit compact representations that
groups together identical machines in the HFSM, where the algorithm only needs
to compute the optimal exit costs for one of the identical machines within each
group, thereby avoid unnecessary recomputations. We validate the algorithm on
large systems with millions of states and a robotic application. It is shown
that our approach outperforms Dijkstra's algorithm, Bidirectional Dijkstra and
Contraction Hierarchies.",http://arxiv.org/abs/2501.08918v1
"Determination and evaluation of the critical liquid nitrogen for
  superconducting levitator based on a novel temperature-weight coupling
  measurement device",2025-01-12T21:48:05Z,"Peng Pang, Jun Zheng, Chenling Xian","Liquid nitrogen (LN2) is the only cooling medium for the high-temperature
superconducting (HTS) bulks in the superconducting levitator, which is the
heart of the maglev train, to reach working state. The detection and
determination of the critical LN2 content are crucial for reliable operation of
the HTS maglev train. However, the related intelligent detection model and
technology is lack in the combination filed of the cryogenic environment and
maglev application, and there is no existing method to detect the LN2 content
in superconducting levitator. This paper proposes to employ multisensor fusion
framework to fuse and enhance the accuracy of critical LN2 content testing.
Four temperature sensors were deployed inside superconducting levitator to
measure the temperature change during the LN2 content changing from 100 % to 0.
It was first obtained that the critical LN2 content in the superconducting
levitator is 4%. To accurately monitor the critical LN2 content in the
superconducting levitator, a matrix-weighted information fusion Kalman filter
algorithm was used. Compared with the previous single sensor method, the
testing accuracy of the multisensor fusion method can be improved by 5.6%. The
work can provide a preliminary research foundation for the online monitoring
and fault diagnosis of HTS maglev train.",http://arxiv.org/abs/2501.09030v1
"Layered Dirichlet Modeling to Assess the Changing Contributions of MLB
  Players as they Age",2025-01-15T21:13:15Z,"Monnie McGee, Jacob Turner, Bianca Luedeker","The productive career of a professional athlete is limited compared to the
normal human lifespan. Most professional athletes have retired by age 40. The
early retirement age is due to a combination of age-related performance and
life considerations. While younger players typically are stronger and faster
than their older teammates, older teammates add value to a team due to their
experience and perspective. Indeed, the highest--paid major league baseball
players are those over the age of 35. These players contribute intangibly to a
team through mentorship of younger players; however, their peak athletic
performance has likely passed. Given this, it is of interest to learn how more
mature players contribute to a team in measurable ways. We examine the
distribution of plate appearance outcomes from three different age groups as
compositional data, using Layered Dirichlet Modeling (LDM). We develop a
hypothesis testing framework to compare the average proportions of outcomes for
each component among 3 of more groups. LDM can not only determine evidence for
differences among populations, but also pinpoint within which component the
largest changes are likely to occur. This framework can determine where players
can be of most use as they age.",http://arxiv.org/abs/2501.09153v1
"Adaptive Spatiotemporal Augmentation for Improving Dynamic Graph
  Learning",2025-01-17T07:48:18Z,"Xu Chu, Hanlin Xue, Bingce Wang, Xiaoyang Liu, Weiping Li, Tong Mo, Tuoyu Feng, Zhijie Tan","Dynamic graph augmentation is used to improve the performance of dynamic
GNNs. Most methods assume temporal locality, meaning that recent edges are more
influential than earlier edges. However, for temporal changes in edges caused
by random noise, overemphasizing recent edges while neglecting earlier ones may
lead to the model capturing noise. To address this issue, we propose STAA
(SpatioTemporal Activity-Aware Random Walk Diffusion). STAA identifies nodes
likely to have noisy edges in spatiotemporal dimensions. Spatially, it analyzes
critical topological positions through graph wavelet coefficients. Temporally,
it analyzes edge evolution through graph wavelet coefficient change rates.
Then, random walks are used to reduce the weights of noisy edges, deriving a
diffusion matrix containing spatiotemporal information as an augmented
adjacency matrix for dynamic GNN learning. Experiments on multiple datasets
show that STAA outperforms other dynamic graph augmentation methods in node
classification and link prediction tasks.",http://arxiv.org/abs/2501.10010v1
"Time-Resolved Measurements of Cumulative Effects in Gas Dynamics Induced
  by High-Repetition-Rate Femtosecond Laser Filamentation",2025-01-17T13:47:46Z,"Robin Löscher, Malte C. Schroeder, Alan Omar, Clara J. Saraceno","The advent of high-average-power, ultrafast ytterbium-based lasers allows us
to generate laser filaments at repetition rates ranging from 10s of kHz up to
100s of kHz. At such high repetition rates, the inter-pulse time lies below the
time required for the total diffusion of the deposited heat by each laser
pulse, leading to cumulative hydrodynamic effects that have so far been rarely
studied. Here, we present, to the best of our knowledge, the first experimental
time-resolved measurements of these dynamics in air for laser repetition rates
between 1 kHz and 100 kHz. We measure the change in the air refractive index
caused by the localized heat deposition and the length of the
filament-generated plasma channel, with which we can infer the corresponding
change in air density. We observe that at repetition rates above 10 kHz,
stationary density depletions with vanishing dynamics emerge. Our findings are
of wide relevance for the fields of high-repetition-rate laser filamentation
and its applications, as well as THz generation from laser-induced plasma
sources.",http://arxiv.org/abs/2501.10198v1
"Matrix Ordering through Spectral and Nilpotent Structures in Totally
  Ordered Complex Number Fields",2025-01-17T23:34:17Z,Shih-Yu Chang,"Matrix inequalities play a pivotal role in mathematics, generalizing scalar
inequalities and providing insights into linear operator structures. However,
the widely used L\""owner ordering, which relies on real-valued eigenvalues, is
limited to Hermitian matrices, restricting its applicability to non-Hermitian
systems increasingly relevant in fields like non-Hermitian physics. To overcome
this, we develop a total ordering relation for complex numbers, enabling
comparisons of the spectral components of general matrices with complex
eigenvalues. Building on this, we introduce the Spectral and Nilpotent Ordering
(SNO), a partial order for arbitrary matrices of the same dimensions. We
further establish a theoretical framework for majorization ordering with
complex-valued functions, which aids in refining SNO and analyzing spectral
components. An additional result is the extension of the Schur--Ostrowski
criterion to the complex domain. Moreover, we characterize Jordan blocks of
matrix functions using a generalized dominance order for nilpotent components,
facilitating systematic analysis of non-diagonalizable matrices. Finally, we
derive monotonicity and convexity conditions for functions under the SNO
framework, laying a new mathematical foundation for advancing matrix analysis.",http://arxiv.org/abs/2501.10603v1
"Role of Random Interaction Connection in the Order Transition of Active
  Matter Based on the Vicsek Model",2025-01-18T06:24:15Z,"Ruizhi Jin, Kejun Dong","Randomness plays a key role in the order transition of active matter but has
not yet been explicitly considered in pairwise interaction connection. In this
letter, we introduce the perception rate P into the Vicsek model as the
probability of the interaction connections and model the connections as
superposition states. We show that with increasing P, the polar order number
undergoes an order transition and then saturation. The order transition is a
first-order phase transition with band formation, and the effect of P is
different from density. The change of the order number is linked with the
interaction structure. The order transition, order saturation, and phase
separation correspond to different critical changes in the local interaction
number. The global interaction structure is further analyzed as a network. The
decrease of P is comparable to random edge removal, under which the network
experiences modal transitions near the critical points of the order number, and
the network exhibits surprising robustness. Our results suggest that random
interaction can be a new important factor in active matter models, with
potential applications in robotic swarms and social activities.",http://arxiv.org/abs/2501.10669v1
"Almost sure bounds for weighted sums of Rademacher random multiplicative
  functions",2025-01-19T15:26:39Z,Christopher Atherfold,"We prove that when $f$ is a Rademacher random multiplicative function for any
$\epsilon>0$, then $\sum_{n \leqslant x}\frac{f(n)}{\sqrt{n}} \ll
(\log\log(x))^{3/4+\epsilon}$ for almost all $f$. We also show that there exist
arbitrarily large values of $x$ such that $\sum_{n \leqslant
x}\frac{f(n)}{\sqrt{n}} \gg (\log\log(x))^{-1/2}$. This is different to what is
found in the Steinhaus case, this time with the size of the Rademacher Euler
product making the multiplicative chaos contribution the dominant one. We also
find a sharper upper bound when we restrict to integers with a prime factor
greater than $\sqrt{x}$, proving that $\sum_{\substack{n \leqslant x \\ P(n) >
\sqrt{x}}}\frac{f(n)}{\sqrt{n}} \ll (\log\log(x))^{1/4+\epsilon}$.",http://arxiv.org/abs/2501.11076v2
The influence of chromospheric activity on line formation,2025-01-20T21:14:40Z,"Mariela C. Vieytes, Lily L. Zhao, Megan Bedell","One of the primary sources of stellar spectral variability is magnetic
activity. While our current understanding of chromospheric activity is largely
derived from specific lines sensitive to chromospheric heating, such as the Ca
II HK doublet, previous observational studies have shown that other spectral
lines are also affected. To investigate the influence of activity on line
formation in greater detail, we constructed a set of stellar models for
hypothetical G2 dwarf stars with varying levels of activity and calculated
their synthetic spectra. A comparison of these spectra revealed two spectral
regions most significantly impacted by activity: approximately 3300-4400 A and
5250-5500 A. By calculating the total contribution function of the lines, we
determined that the emergence of a secondary chromospheric contribution to line
formation is the primary mechanism driving these changes. Based on our
calculations and analysis, we compiled a list of transition lines and their
corresponding changes due to chromospheric activity. This list could serve as a
valuable tool for selecting spectral lines applicable to a wide range of
astrophysical studies.",http://arxiv.org/abs/2501.11750v1
"Semantic Dependency in Microservice Architecture: A Framework for
  Definition and Detection",2025-01-20T23:34:24Z,"Amr S. Abdelfattah, Kari E Cordes, Austin Medina, Tomas Cerny","Microservices have been a key architectural approach for over a decade,
transforming system design by promoting decentralization and allowing
development teams to work independently on specific microservices. While
loosely coupled microservices are ideal, dependencies between them are
inevitable. Often, these dependencies go unnoticed by development teams.
Although syntactic dependencies can be identified, tracking semantic
dependencies - when multiple microservices share similar logic - poses a
greater challenge. As systems evolve, changes made to one microservice can
trigger ripple effects, jeopardizing system consistency and requiring updates
to dependent services, which increases maintenance and operational complexity.
Effectively tracking different types of dependencies across microservices is
essential for anticipating the impact of such changes. This paper introduces
the Semantic Dependency Matrix as an instrument to address these challenges
from a semantic perspective. We propose an automated approach to extract and
represent these dependencies and demonstrate its effectiveness through a case
study. This paper takes a step further by demonstrating the significance of
semantic dependencies, even in cases where there are no direct dependencies
between microservices. It shows that these hidden dependencies can exist
independently of endpoint or data dependencies, revealing critical connections
that might otherwise be overlooked.",http://arxiv.org/abs/2501.11787v1
"The Associated Discrete Laplacian in $\mathbb{R}^3$ and Mean Curvature
  with Higher order Approximations",2025-01-21T04:01:59Z,Wei-Hung Liao,"In $\mathbb{R}^3$, the primal and dual constructions yield completely
different discrete Laplacians for tetrahedral meshes.In this article, we prove
that the discrete Laplacian satisfies the Euler-Lagrange equation of the
Dirichlet energy in terms of the associated discrete Laplacian corresponding to
the dual construction. Specifically, for a three simplex immersed in
$\mathbb{R}^3$, the associated discrete Laplacian on the tetrahedron can be
expressed as the discrete Laplacian of the faces of the tetrahedron and the
associated discrete mean curvature term given by the ambient space
$\mathbb{R}^3$. Based on geometric foundations, we provide a mathematical proof
showing that the dual construction gives a optimal Laplacian in $\mathbb{R}^3$
compared to the primal construction. Moreover, we show that the associated
discrete mean curvature is more sensitive to the initial mesh than other
state-of-the-art discrete mean curvatures when the angle changes
instantaneously. Instead of improving the angular transient accuracy through
mesh subdivision, we can improve the accuracy by providing a higher order
approximation of the instantaneous change in angle to reduce the solution
error.",http://arxiv.org/abs/2501.11871v1
"Beyond Window-Based Detection: A Graph-Centric Framework for Discrete
  Log Anomaly Detection",2025-01-21T14:26:03Z,"Jiaxing Qi, Chang Zeng, Zhongzhi Luan, Shaohan Huang, Shu Yang, Yao Lu, Hailong Yang, Depei Qian","Detecting anomalies in discrete event logs is critical for ensuring system
reliability, security, and efficiency. Traditional window-based methods for log
anomaly detection often suffer from context bias and fuzzy localization, which
hinder their ability to precisely and efficiently identify anomalies. To
address these challenges, we propose a graph-centric framework, TempoLog, which
leverages multi-scale temporal graph networks for discrete log anomaly
detection. Unlike conventional methods, TempoLog constructs continuous-time
dynamic graphs directly from event logs, eliminating the need for fixed-size
window grouping. By representing log templates as nodes and their temporal
relationships as edges, the framework dynamically captures both local and
global dependencies across multiple temporal scales. Additionally, a
semantic-aware model enhances detection by incorporating rich contextual
information. Extensive experiments on public datasets demonstrate that our
method achieves state-of-the-art performance in event-level anomaly detection,
significantly outperforming existing approaches in both accuracy and
efficiency.",http://arxiv.org/abs/2501.12166v1
"Regressor-Guided Image Editing Regulates Emotional Response to Reduce
  Online Engagement",2025-01-21T16:59:13Z,"Christoph Gebhardt, Robin Willardt, Seyedmorteza Sadat, Chih-Wei Ning, Andreas Brombach, Jie Song, Otmar Hilliges, Christian Holz","Emotions are known to mediate the relationship between users' content
consumption and their online engagement, with heightened emotional intensity
leading to increased engagement. Building on this insight, we propose three
regressor-guided image editing approaches aimed at diminishing the emotional
impact of images. These include (i) a parameter optimization approach based on
global image transformations known to influence emotions, (ii) an optimization
approach targeting the style latent space of a generative adversarial network,
and (iii) a diffusion-based approach employing classifier guidance and
classifier-free guidance. Our findings demonstrate that approaches can
effectively alter the emotional properties of images while maintaining high
visual quality. Optimization-based methods primarily adjust low-level
properties like color hues and brightness, whereas the diffusion-based approach
introduces semantic changes, such as altering appearance or facial expressions.
Notably, results from a behavioral study reveal that only the diffusion-based
approach successfully elicits changes in viewers' emotional responses while
preserving high perceived image quality. In future work, we will investigate
the impact of these image adaptations on internet user behavior.",http://arxiv.org/abs/2501.12289v1
Tuning the topological winding number by rolling up graphene,2025-01-22T02:33:35Z,"Ying-Je Lee, Yu-An Cheng, Yu-Jie Zhong, Ion Cosma Fulga, Ching-Hao Chang","Nanoscrolls, radial superlattices formed by rolling up a nanomembrane,
exhibit distinct electronic and magneto-transport properties compared to their
flat counterparts. In this study, we theoretically demonstrate that the
conductance can be precisely enhanced N times by rolling up graphene into an
N-turn nanoscroll and applying a longitudinal magnetic field. This tunable
positive magnetoconductance stems from the topological winding number which is
activated in a carbon nanoscroll with magnetic flux and its maximum value
purely increases with the scroll winding number (the number of turns). By
integrating material geometry and topology, our work opens the door to
artificially creating, customizing, and designing topological materials in
rolled-up graphene-like systems.",http://arxiv.org/abs/2501.12590v1
"EvidenceMap: Learning Evidence Analysis to Unleash the Power of Small
  Language Models for Biomedical Question Answering",2025-01-22T09:27:11Z,"Chang Zong, Jian Wan, Siliang Tang, Lei Zhang","When addressing professional questions in the biomedical domain, humans
typically acquire multiple pieces of information as evidence and engage in
multifaceted analysis to provide high-quality answers. Current LLM-based
question answering methods lack a detailed definition and learning process for
evidence analysis, leading to the risk of error propagation and hallucinations
while using evidence. Although increasing the parameter size of LLMs can
alleviate these issues, it also presents challenges in training and deployment
with limited resources. In this study, we propose EvidenceMap, which aims to
enable a tiny pre-trained language model to explicitly learn multiple aspects
of biomedical evidence, including supportive evaluation, logical correlation
and content summarization, thereby latently guiding a small generative model
(around 3B parameters) to provide textual responses. Experimental results
demonstrate that our method, learning evidence analysis by fine-tuning a model
with only 66M parameters, exceeds the RAG method with an 8B LLM by 19.9% and
5.7% in reference-based quality and accuracy, respectively.",http://arxiv.org/abs/2501.12746v4
"MultiDreamer3D: Multi-concept 3D Customization with Concept-Aware
  Diffusion Guidance",2025-01-23T08:02:59Z,"Wooseok Song, Seunggyu Chang, Jaejun Yoo","While single-concept customization has been studied in 3D, multi-concept
customization remains largely unexplored. To address this, we propose
MultiDreamer3D that can generate coherent multi-concept 3D content in a
divide-and-conquer manner. First, we generate 3D bounding boxes using an
LLM-based layout controller. Next, a selective point cloud generator creates
coarse point clouds for each concept. These point clouds are placed in the 3D
bounding boxes and initialized into 3D Gaussian Splatting with concept labels,
enabling precise identification of concept attributions in 2D projections.
Finally, we refine 3D Gaussians via concept-aware interval score matching,
guided by concept-aware diffusion. Our experimental results show that
MultiDreamer3D not only ensures object presence and preserves the distinct
identities of each concept but also successfully handles complex cases such as
property change or interaction. To the best of our knowledge, we are the first
to address the multi-concept customization in 3D.",http://arxiv.org/abs/2501.13449v1
Moments of generalized fractional polynomial processes,2025-01-23T17:23:12Z,"Johannes Assefa, Martin Keller-Ressel","We derive a moment formula for generalized fractional polynomial processes,
i.e., for polynomial-preserving Markov processes time-changed by an inverse
L\'evy-subordinator. If the time change is inverse $\alpha$-stable, the
time-derivative of the Kolmogorov backward equation is replaced by a Caputo
fractional derivative of order $\alpha$, and we demonstrate that moments of
such processes are computable, in a closed form, using matrix Mittag-Leffler
functions. The same holds true for cross-moments in equilibrium, generalizing
results of Leonenko, Meerschaert and Sikorskii from the one-dimensional
diffusive case of second-order moments to the multivariate, jump-diffusive case
of moments of arbitrary order. We show that also in this more general setting,
fractional polynomial processes exhibit long-range dependence, with
correlations decaying as a power law with exponent $\alpha$.",http://arxiv.org/abs/2501.13854v1
"Longitudinal Abuse and Sentiment Analysis of Hollywood Movie Dialogues
  using LLMs",2025-01-20T00:44:38Z,"Rohitash Chandra, Guoxiang Ren, Group-H","Over the past decades, there has been an increasing concern about the
prevalence of abusive and violent content in Hollywood movies. This study uses
Large Language Models (LLMs) to explore the longitudinal abuse and sentiment
analysis of Hollywood Oscar and blockbuster movie dialogues from 1950 to 2024.
By employing fine-tuned LLMs, we analyze subtitles for over a thousand movies
categorised into four genres to examine the trends and shifts in emotional and
abusive content over the past seven decades. Our findings reveal significant
temporal changes in movie dialogues, which reflect broader social and cultural
influences. Overall, the emotional tendencies in the films are diverse, and the
detection of abusive content also exhibits significant fluctuations. The
results show a gradual rise in abusive content in recent decades, reflecting
social norms and regulatory policy changes. Genres such as thrillers still
present a higher frequency of abusive content that emphasises the ongoing
narrative role of violence and conflict. At the same time, underlying positive
emotions such as humour and optimism remain prevalent in most of the movies.
Furthermore, the gradual increase of abusive content in movie dialogues has
been significant over the last two decades, where Oscar-nominated movies
overtook the top ten blockbusters.",http://arxiv.org/abs/2501.13948v1
"Triplet Synthesis For Enhancing Composed Image Retrieval via
  Counterfactual Image Generation",2025-01-22T07:18:46Z,"Kenta Uesugi, Naoki Saito, Keisuke Maeda, Takahiro Ogawa, Miki Haseyama","Composed Image Retrieval (CIR) provides an effective way to manage and access
large-scale visual data. Construction of the CIR model utilizes triplets that
consist of a reference image, modification text describing desired changes, and
a target image that reflects these changes. For effectively training CIR
models, extensive manual annotation to construct high-quality training
datasets, which can be time-consuming and labor-intensive, is required. To deal
with this problem, this paper proposes a novel triplet synthesis method by
leveraging counterfactual image generation. By controlling visual feature
modifications via counterfactual image generation, our approach automatically
generates diverse training triplets without any manual intervention. This
approach facilitates the creation of larger and more expressive datasets,
leading to the improvement of CIR model's performance.",http://arxiv.org/abs/2501.13968v1
On Measures in Ion Trap Quantum Information,2025-01-24T09:47:13Z,"Reza Pirmoradian, M Reza Tanhayi","In this study, we investigate quantum information measures in ion traps by
utilizing the harmonic oscillator model to characterize trapped potentials and
ion dynamics. Our findings confirm that, in the steady-state case, mutual
information and synchronization measures exhibit similar behaviors.
Additionally, we explore how these measures change in the quench model and how
they are influenced by coupling and external noise, such as an external
magnetic field. Moreover, for a proposed target ground state, we determine the
circuit depth and analyze the effects of the external magnetic field and
coupling constant, highlighting their dynamic evolution over time. We also
discuss the coherent state of a single ion in a trap, noting an inverse
relationship between complexity and fidelity-where increased fidelity
corresponds to decreased system complexity, indicating a more ordered state
with improved control and optimization. However, at higher system frequencies,
complexity increases due to intricate interactions and rapid state changes,
necessitating advanced control mechanisms.",http://arxiv.org/abs/2501.14359v2
Approximation of Set-Valued Functions with images sets in $\mathbb{R}^d$,2025-01-24T15:53:03Z,"Nira Dyn, David Levin","Given a finite number of samples of a continuous set-valued function F,
mapping an interval to non-empty compact subsets of $\mathbb{R}^d$, $F: [a,b]
\to K(\mathbb{R}^d)$, we discuss the problem of computing good approximations
of F. We also discuss algorithms for a direct high-order evaluation of the
graph of $F$, namely, the set $Graph(F)=\{(t,y)\ | \ y\in F(t),\ t\in
[a,b]\}\in K(\mathbb{R}^{d+1})$. A set-valued function can be continuous and
yet have points where the topology of the image sets changes. The main
challenge in set-valued function approximation is to derive high-order
approximations near these points. In a previous paper, we presented with Q.
Muzaffar, an algorithm for approximating set-valued functions with 1D sets
($d=1$) as images, achieving high approximation order near points of topology
change. Here we build upon the results and algorithms in the $d=1$ case, first
in more detail for the important case $d=2$, and later for approximating
set-valued functions and their graphs in higher dimensions.",http://arxiv.org/abs/2501.14591v1
"BOLDreams: Dreaming with pruned in-silico fMRI Encoding Models of the
  Visual Cortex",2025-01-24T16:46:16Z,"Uzair Hussain, Kamil Uludag","In this article we use the Natural Scenes Dataset (NSD) to train a family of
feature-weighted receptive field neural encoding models. These models use a
pre-trained vision or text backbone and map extracted features to the voxel
space via receptive field readouts. We comprehensively assess such models,
quantifying performance changes based on using different modalities like text
or images, toggling finetuning, using different pre-trained backbones, and
changing the width of the readout. We also dissect each model using explainable
AI (XAI) techniques, such as feature visualization via input optimization, also
referred to as ``dreaming'' in the AI literature, and the integrated gradients
approach to calculate implicit attention maps to illustrate which features
drive the predicted signal in different brain areas. These XAI tools illustrate
biologically plausible features that drive the predicted signal. Traversing the
model hyperparameter space reveals the existence of a maximally minimal model,
balancing simplicity while maintaining performance.",http://arxiv.org/abs/2501.14854v1
"Decision Making in Changing Environments: Robustness, Query-Based
  Learning, and Differential Privacy",2025-01-24T21:31:50Z,"Fan Chen, Alexander Rakhlin","We study the problem of interactive decision making in which the underlying
environment changes over time subject to given constraints. We propose a
framework, which we call \textit{hybrid Decision Making with Structured
Observations} (hybrid DMSO), that provides an interpolation between the
stochastic and adversarial settings of decision making. Within this framework,
we can analyze local differentially private (LDP) decision making, query-based
learning (in particular, SQ learning), and robust and smooth decision making
under the same umbrella, deriving upper and lower bounds based on variants of
the Decision-Estimation Coefficient (DEC). We further establish strong
connections between the DEC's behavior, the SQ dimension, local minimax
complexity, learnability, and joint differential privacy. To showcase the
framework's power, we provide new results for contextual bandits under the LDP
constraint.",http://arxiv.org/abs/2501.14928v1
"Determination of the London penetration depth with the tunnel diode
  oscillator technique",2025-01-26T13:07:12Z,G. P. Mikitik,"Using a distribution of the Meissner currents over the surface of an
infinitely long superconducting slab with a rectangular cross section, the
magnetic moment of the slab is calculated, taking into account corrections
associated with a small but finite value of the London penetration depth
$\lambda$. Since these corrections determine the shift of the resonant
frequency in the tunnel diode oscillator technique, formulas for determination
of $\lambda$ within this technique are derived for the slab. These formulas are
valid for any aspect ratio of its cross section, and they differ from those
that are often used in analyzing experimental data. Namely, it is shown that
sharp edges of the slab can cause the large frequency shift proportional to the
change in the value of $\lambda^{2/3}$. Although this result complicates the
extraction of a temperature dependence of $\lambda$ from the frequency shift,
it also opens up new possibilities in determining the London penetration depth.
In particular, under certain conditions, it is possible not only to measure the
changes in $\lambda$ with the temperature, but also to estimate its absolute
value.",http://arxiv.org/abs/2501.15512v1
"Pressure induced Structure Change and Anomalies in Thermodynamic
  Quantities and Transport Properties in Liquid Lithium Hydride",2025-01-26T13:54:59Z,"X. Z. Yan, Y. M. Chen, Hua Y. Geng, Y. F. Wang, Y. Sun, L. L. Zhang, H. Wang, Y. L. Xu","Understand the nature of liquid structure and its evolution under different
conditions is a major challenge in condensed physics and materials science.
Here, we report a pressure-induced structure change spanning a wide pressure
range in liquid-state lithium hydride (LiH) by first-principles molecular
dynamic simulations. This behavior can be described as a continuous crossover
from low pressure liquid with Li$^+$-H$^-$ duality symmetry to high pressure
one with broken of duality symmetry. The thermodynamic quantities such as heat
capacity and ionic transport properties such as diffusivity are also saliently
impacted. It is important to stress that such behavior is firstly predicted for
this category of materials, which is ubiquitous in universe as well as in
industry applications. Lastly, a comprehensive high-pressure high-temperature
phase diagram of LiH is constructed, which embodies rich physics in this
previously-thought-simple ionic compound.",http://arxiv.org/abs/2501.15532v1
Can Molecular Evolution Mechanism Enhance Molecular Representation?,2025-01-27T05:54:42Z,"Kun Li, Longtao Hu, Xiantao Cai, Jia Wu, Wenbin Hu","Molecular evolution is the process of simulating the natural evolution of
molecules in chemical space to explore potential molecular structures and
properties. The relationships between similar molecules are often described
through transformations such as adding, deleting, and modifying atoms and
chemical bonds, reflecting specific evolutionary paths. Existing molecular
representation methods mainly focus on mining data, such as atomic-level
structures and chemical bonds directly from the molecules, often overlooking
their evolutionary history. Consequently, we aim to explore the possibility of
enhancing molecular representations by simulating the evolutionary process. We
extract and analyze the changes in the evolutionary pathway and explore
combining it with existing molecular representations. Therefore, this paper
proposes the molecular evolutionary network (MEvoN) for molecular
representations. First, we construct the MEvoN using molecules with a small
number of atoms and generate evolutionary paths utilizing similarity
calculations. Then, by modeling the atomic-level changes, MEvoN reveals their
impact on molecular properties. Experimental results show that the MEvoN-based
molecular property prediction method significantly improves the performance of
traditional end-to-end algorithms on several molecular datasets. The code is
available at https://anonymous.4open.science/r/MEvoN-7416/.",http://arxiv.org/abs/2501.15799v1
"Adaptive AI-based Decentralized Resource Management in the Cloud-Edge
  Continuum",2025-01-27T06:07:09Z,"Lanpei Li, Jack Bell, Massimo Coppola, Vincenzo Lomonaco","The increasing complexity of application requirements and the dynamic nature
of the Cloud-Edge Continuum present significant challenges for efficient
resource management. These challenges stem from the ever-changing
infrastructure, which is characterized by additions, removals, and
reconfigurations of nodes and links, as well as the variability of application
workloads. Traditional centralized approaches struggle to adapt to these
changes due to their static nature, while decentralized solutions face
challenges such as limited global visibility and coordination overhead. This
paper proposes a hybrid decentralized framework for dynamic application
placement and resource management. The framework utilizes Graph Neural Networks
(GNNs) to embed resource and application states, enabling comprehensive
representation and efficient decision-making. It employs a collaborative
multi-agent reinforcement learning (MARL) approach, where local agents optimize
resource management in their neighborhoods and a global orchestrator ensures
system-wide coordination. By combining decentralized application placement with
centralized oversight, our framework addresses the scalability, adaptability,
and accuracy challenges inherent in the Cloud-Edge Continuum. This work
contributes to the development of decentralized application placement
strategies, the integration of GNN embeddings, and collaborative MARL systems,
providing a foundation for efficient, adaptive and scalable resource
management.",http://arxiv.org/abs/2501.15802v1
Precession for the mode change in a gamma-ray pulsar,2025-01-27T09:51:55Z,"H. Tong, H. H. Wang","PSR J2021+4026 is a gamma-ray pulsar having variations in its spin-down rate
and gamma-ray flux. Its variations in timing and emission are correlated, e.g.,
a larger spin-down rate for a low gamma-ray flux. We show that the mode change
in PSR J2021+4026 can be understood in the precession scenario. In the
precession model, the inclination angle is modulated due to precession. At the
same time, the wobble angle may decay with time. This results in damping of the
precession. Combined with magnetospheric torque model and the outer gap model,
the damped precession can explain: (1) when the inclination angle is larger,
the spin-down rate will be larger, accompanied by a lower gamma-ray flux. (2)
The variation amplitude of the gamma-ray flux and spin-down rate is smaller
than previous results due to the damping of the precession. The modulation
period is becoming shorter due to a smaller wobble angle. In the end, we
propose that there are two kinds of modulations in pulsars. Long-term
modulations in pulsars may be due to precession. Short-term modulations may be
of magnetospheric origin.",http://arxiv.org/abs/2501.15902v1
"Microfoundations of IPR and standardization strategies of companies:
  Evidence from the evolving European Single Market",2025-01-27T13:35:26Z,"Jussi Heikkilä, Satu Rinkinen, Tero Rantala","Intellectual property rights (IPR) and standards are important institutions
that by shaping appropriability conditions of companies impact international
trade flows and the rate and direction of technological progress and innovation
activity. We shed light on microfoundations of IPR and standardization
capabilities and explore how companies have developed their IPR and
standardization strategies and adapted to related institutional changes in the
European Single Market. The analysis of the IPR and standardization strategies
of companies active in P\""aij\""at-H\""ame region of Finland, a northern part of
the European Union, reveals that only a few companies have explicit IPR and
standardization strategies, but several have systematic approaches to following
the development of standards and IPR environments in their industries.
Companies build dynamic IPR and standardization capabilities and adapt their
IPR and standardization strategies to the changing institutional environment
via experiential learning.",http://arxiv.org/abs/2501.16040v1
"HERITRACE: A User-Friendly Semantic Data Editor with Change Tracking and
  Provenance Management for Cultural Heritage Institutions",2025-01-27T16:48:39Z,"Arcangelo Massari, Silvio Peroni","HERITRACE is a data editor designed for galleries, libraries, archives and
museums, aimed at simplifying data curation while enabling non-technical domain
experts to manage data intuitively without losing its semantic integrity. While
the semantic nature of RDF can pose a barrier to data curation due to its
complexity, HERITRACE conceals this intricacy while preserving the advantages
of semantic representation. The system natively supports provenance management
and change tracking, ensuring transparency and accountability throughout the
curation process. Although HERITRACE functions effectively out of the box, it
offers a straightforward customization interface for technical staff, enabling
adaptation to the specific data model required by a given collection. Current
applications include the ParaText project, and its adoption is already planned
for OpenCitations. Future developments will focus on integrating the RDF
Mapping Language (RML) to enhance compatibility with non-RDF data formats,
further expanding its applicability in digital heritage management.",http://arxiv.org/abs/2501.16197v1
SAFR: Neuron Redistribution for Interpretability,2025-01-23T06:20:33Z,"Ruidi Chang, Chunyuan Deng, Hanjie Chen","Superposition refers to encoding representations of multiple features within
a single neuron, which is common in deep neural networks. This property allows
neurons to combine and represent multiple features, enabling the model to
capture intricate information and handle complex tasks. Despite promising
performance, the model's interpretability has been diminished. This paper
presents a novel approach to enhance model interpretability by regularizing
feature superposition. We introduce SAFR, which simply applies regularizations
to the loss function to promote monosemantic representations for important
tokens while encouraging polysemanticity for correlated token pairs, where
important tokens and correlated token pairs are identified via VMASK and
attention weights respectively. We evaluate SAFR with a transformer model on
two classification tasks. Experiments demonstrate the effectiveness of SAFR in
improving model interpretability without compromising prediction performance.
Besides, SAFR provides explanations by visualizing the neuron allocation within
the intermediate layers.",http://arxiv.org/abs/2501.16374v2
"SCDiar: a streaming diarization system based on speaker change detection
  and speech recognition",2025-01-28T02:27:24Z,"Naijun Zheng, Xucheng Wan, Kai Liu, Zhou Huan","In hours-long meeting scenarios, real-time speech stream often struggles with
achieving accurate speaker diarization, commonly leading to speaker
identification and speaker count errors. To address this challenge, we propose
SCDiar, a system that operates on speech segments, split at the token level by
a speaker change detection (SCD) module. Building on these segments, we
introduce several enhancements to efficiently select the best available segment
for each speaker. These improvements lead to significant gains across various
benchmarks. Notably, on real-world meeting data involving more than ten
participants, SCDiar outperforms previous systems by up to 53.6\% in accuracy,
substantially narrowing the performance gap between online and offline systems.",http://arxiv.org/abs/2501.16641v1
"MACI: Multi-Agent Collaborative Intelligence for Adaptive Reasoning and
  Temporal Planning",2025-01-28T03:57:22Z,Edward Y. Chang,"Artificial intelligence requires deliberate reasoning, temporal awareness,
and effective constraint management, capabilities traditional LLMs often lack
due to their reliance on pattern matching, limited self-verification, and
inconsistent constraint handling. We introduce Multi-Agent Collaborative
Intelligence (MACI), a framework comprising three key components: 1) a
meta-planner (MP) that identifies, formulates, and refines all roles and
constraints of a task (e.g., wedding planning) while generating a dependency
graph, with common-sense augmentation to ensure realistic and practical
constraints; 2) a collection of agents to facilitate planning and address
task-specific requirements; and 3) a run-time monitor that manages plan
adjustments as needed. By decoupling planning from validation, maintaining
minimal agent context, and integrating common-sense reasoning, MACI overcomes
the aforementioned limitations and demonstrates robust performance in two
scheduling problems.",http://arxiv.org/abs/2501.16689v2
"Meta-Federated Learning: A Novel Approach for Real-Time Traffic Flow
  Management",2025-01-28T07:24:24Z,"Bob Johnson, Michael Geller","Efficient management of traffic flow in urban environments presents a
significant challenge, exacerbated by dynamic changes and the sheer volume of
data generated by modern transportation networks. Traditional centralized
traffic management systems often struggle with scalability and privacy
concerns, hindering their effectiveness. This paper introduces a novel approach
by combining Federated Learning (FL) and Meta-Learning (ML) to create a
decentralized, scalable, and adaptive traffic management system. Our approach,
termed Meta-Federated Learning, leverages the distributed nature of FL to
process data locally at the edge, thereby enhancing privacy and reducing
latency. Simultaneously, ML enables the system to quickly adapt to new traffic
conditions without the need for extensive retraining. We implement our model
across a simulated network of smart traffic devices, demonstrating that
Meta-Federated Learning significantly outperforms traditional models in terms
of prediction accuracy and response time. Furthermore, our approach shows
remarkable adaptability to sudden changes in traffic patterns, suggesting a
scalable solution for real-time traffic management in smart cities. This study
not only paves the way for more resilient urban traffic systems but also
exemplifies the potential of integrated FL and ML in other real-world
applications.",http://arxiv.org/abs/2501.16758v1
"Dynamics of small, constant size particles in a protoplanetary disk with
  an embedded protoplanet",2025-01-28T19:00:03Z,"Ellen M. Price, Eric Van Clepper, Fred J. Ciesla","Hydrodynamical simulations of protoplanetary disk dynamics are useful tools
for understanding the formation of planetary systems, including our own.
Approximations are necessary to make these simulations computationally
tractable. A common assumption when simulating dust fluids is that of a
constant Stokes number, a dimensionless number that characterizes the
interaction between a particle and the surrounding gas. Constant Stokes number
is not a good approximation in regions of the disk where the gas density
changes significantly, such as near a planet-induced gap. In this paper, we
relax the assumption of constant Stokes number in the popular FARGO3D code
using semi-analytic equations for the drag force on dust particles, which
enables an assumption of constant particle size instead. We explore the effect
this change has on disk morphology and particle fluxes across the gap for both
outward- and inward-drifting particles. The assumption of constant particle
size, rather than constant Stokes number, is shown to make a significant
difference in some cases, emphasizing the importance of the more accurate
treatment.",http://arxiv.org/abs/2501.17232v1
"Tailored Truths: Optimizing LLM Persuasion with Personalization and
  Fabricated Statistics",2025-01-28T20:06:09Z,"Jasper Timm, Chetan Talele, Jacob Haimes","Large Language Models (LLMs) are becoming increasingly persuasive,
demonstrating the ability to personalize arguments in conversation with humans
by leveraging their personal data. This may have serious impacts on the scale
and effectiveness of disinformation campaigns. We studied the persuasiveness of
LLMs in a debate setting by having humans $(n=33)$ engage with LLM-generated
arguments intended to change the human's opinion. We quantified the LLM's
effect by measuring human agreement with the debate's hypothesis pre- and
post-debate and analyzing both the magnitude of opinion change, as well as the
likelihood of an update in the LLM's direction. We compare persuasiveness
across established persuasion strategies, including personalized arguments
informed by user demographics and personality, appeal to fabricated statistics,
and a mixed strategy utilizing both personalized arguments and fabricated
statistics. We found that static arguments generated by humans and GPT-4o-mini
have comparable persuasive power. However, the LLM outperformed static
human-written arguments when leveraging the mixed strategy in an interactive
debate setting. This approach had a $\mathbf{51\%}$ chance of persuading
participants to modify their initial position, compared to $\mathbf{32\%}$ for
the static human-written arguments. Our results highlight the concerning
potential for LLMs to enable inexpensive and persuasive large-scale
disinformation campaigns.",http://arxiv.org/abs/2501.17273v1
"Transition from non-ergodic to ergodic dynamics in an autonomous
  discrete time crystal",2025-01-29T06:27:46Z,"T. T. Sergeev, A. A. Zyablovsky, E. S. Andrianov","We consider an autonomous system of two coupled single-mode cavities, one of
which interacts with a multimode resonator. We demonstrate that for small
coupling strengths between single-mode cavities, the Loschmidt echo oscillates
periodically in time and spontaneous breaking of time translation symmetry
takes place. The Loschmidt echo behavior is an indication of the non-ergodic
nature of the system when its evolution is time-reversible. In this regime, the
system retains a memory of the initial state under the action of small
perturbations. This behavior reveals the presence of a time crystalline order
in the autonomous system. An increase in the coupling strength leads to a
transition from periodic oscillations to an exponential decay in time of the
Loschmidt echo. This corresponds to the transition from non-ergodic to ergodic
behavior in the system. We demonstrate that the transition from non-ergodic to
ergodic system's behavior can also be observed when changing the number of
degrees of freedom in the resonator, which is achieved by changing its length.",http://arxiv.org/abs/2501.17435v1
Accelerated DC loadflow solver for topology optimization,2025-01-29T09:57:53Z,"Nico Westerbeck, Joost van Dijk, Jan Viebahn, Christian Merz, Dirk Witthaut","We present a massively parallel solver that accelerates DC loadflow
computations for power grid topology optimization tasks. Our approach leverages
low-rank updates of the Power Transfer Distribution Factors (PTDFs) to
represent substation splits, line outages, and reconfigurations without ever
refactorizing the system. Furthermore, we implement the core routines on
Graphics Processing Units (GPUs), thereby exploiting their high-throughput
architecture for linear algebra. A two-level decomposition separates changes in
branch topology from changes in nodal injections, enabling additional speed-ups
by an in-the-loop brute force search over injection variations at minimal
additional cost. We demonstrate billion-loadflow-per-second performance on
power grids of varying sizes in workload settings which are typical for
gradient-free topology optimization such as Reinforcement Learning or Quality
Diversity methods. While adopting the DC approximation sacrifices some accuracy
and prohibits the computation of voltage magnitudes, we show that this
sacrifice unlocks new scales of computational feasibility, offering a powerful
tool for large-scale grid planning and operational topology optimization.",http://arxiv.org/abs/2501.17529v1
"Effects of oxidation and impurities in lithium surfaces on the emitting
  wall plasma sheath",2025-01-29T14:52:33Z,"Kolter Bradshaw, Ammar Hakim, Bhuvana Srinivasan","Use of lithium as a surface coating in fusion devices improves plasma
performance, but the change in wall properties affects the secondary electron
emission properties of the material. Lithium oxidizes easily, which drives the
emission yield well above unity. We present here simulations demonstrating the
change in sheath structure from monotonic to the nonmonotonic space-charge
limited sheath using an energy-dependent data-driven emission model which
self-consistently captures both secondary emission and backscattering
populations. Increased secondary electron emission from the material has
ramifications for the degradation and erosion of the wall. Results shows that
the oxidation leads to an increased electron flux into the wall, and a reduced
ion flux. The net transfer of energy to the surface is significantly greater
for the oxidized case than for the pure lithium case. High reflection rates of
low-energy backscattered particles leads to a high re-emission rate at the
wall.",http://arxiv.org/abs/2501.17686v1
"Single crystal growth and physical characterization to fine tune
  YbIn1-xTxCu4 (T = Au, Ag) towards the critical endpoint of the valence
  transition",2025-01-29T15:31:14Z,"Michelle Ocker, Bereket Ghebretinsae, Jan-Niklas Zimmermann, Sophie Würtele, Bernd Wolf, Alexandr Virovets, Michael Lang, Kristin Kliemt, Cornelius Krellner","Pure as well as Ag- and Au-substituted YbInCu$_4$ single crystals were
structurally and chemically characterized and investigated by means of heat
capacity, magnetization, resistivity and ultrasonic measurements. We studied
the influence of different compositions of the initial melt as well as of Au
and Ag substitutions on the valence change and investigated whether this change
occurs via a first-order phase transition or via crossover. We constructed a
phase diagram of YbInCu$_4$ as a function of various substitutions and show
that the position of the critical endpoint of the valence transition depends on
the substituent and on the conditions under which the samples were grown.
Multiple thermal cycles through the first-order transition lead to a
significant modification of the physical properties which clearly demonstrated
the influence of defects in substituted YbInCu$_4$.",http://arxiv.org/abs/2501.17714v1
Graviton loops and negativity,2025-01-29T19:18:11Z,"Cyuan-Han Chang, Julio Parra-Martinez","We revisit dispersive bounds on Wilson coefficients of scalar effective field
theories (EFT) coupled to gravity in various spacetime dimensions, by computing
the contributions from graviton loops to the corresponding sum rules at low
energies. Fixed-momentum-transfer dispersion relations are often ill-behaved
due to forward singularities arising from loop-level graviton exchange, making
naive positivity bounds derived from them unreliable. Instead, we perform a
careful analysis using crossing-symmetric dispersion relations, and compute the
one-loop corrections to the bounds on EFT coefficients. We find that including
the graviton loops generically allows for negativity of Wilson coefficients by
an amount suppressed by powers of Newton's constant, $G$. The exception are the
few couplings that dominate over (or are degenerate with) the graviton loops at
low energies. In $D=4$, we observe that assuming that the eikonal formula
captures the correct forward behavior of the amplitude at all orders in $G$,
and for energies of the order of the EFT cutoff, yields bounds free of
logarithmic infrared divergences.",http://arxiv.org/abs/2501.17949v1
"Scattering approach to diffusion quantifies axonal damage in brain
  injury",2025-01-30T06:31:04Z,"Ali Abdollahzadeh, Ricardo Coronado-Leija, Hong-Hsi Lee, Alejandra Sierra, Els Fieremans, Dmitry S. Novikov","Early diagnosis and noninvasive monitoring of neurological disorders require
sensitivity to elusive cellular-level alterations that occur much earlier than
volumetric changes observable with the millimeter-resolution of medical imaging
modalities. Morphological changes in axons, such as axonal varicosities or
beadings, are observed in neurological disorders, as well as in development and
aging. Here, we reveal the sensitivity of time-dependent diffusion MRI (dMRI)
to axonal morphology at the micrometer scale. Scattering theory uncovers the
two parameters that determine the diffusive dynamics of water in axons: the
average reciprocal cross-section and the variance of long-range cross-sectional
fluctuations. This theoretical development allowed us to predict dMRI metrics
sensitive to axonal alterations across tens of thousands of axons in seconds
rather than months of simulations in a rat model of traumatic brain injury. Our
approach bridges the gap between micrometers and millimeters in resolution,
offering quantitative, objective biomarkers applicable to a broad spectrum of
neurological disorders.",http://arxiv.org/abs/2501.18167v1
"Elastic constants of single-crystalline NiTi studied by resonant
  ultrasound spectroscopy",2025-01-30T15:20:49Z,"Lucie Bodnárová, Michaela Janovská, Martin Ševčík, Miroslav Frost, Lukáš Kadeřávek, Jaromír Kopeček, Hanuš Seiner, Petr Sedlák, -","Contactless, laser-based resonant ultrasound spectroscopy was utilized to
monitor changes in elastic properties in single-crystalline NiTi shape memory
alloy. It was observed that the elastic behavior of the temperature-induced
B19$^\prime$ martensite adopts the symmetry elements of the parent austenite
phase, and thus, the changes over the transformation temperature can be
represented by the temperature evolution of three cubic elastic coefficients.
The experiments confirm that the transition during the cooling run is preceded
by pronounced softening of the $c_{44}$ elastic coefficient, which leads to
nearly complete vanishing of elastic anisotropy prior to the transition. Below
the transition, this coefficient remains soft, and the character of anisotropy
switches from $c_{44}/c^\prime>1$ to $c_{44}/c^\prime<1$. We rationalize this
behavior from the mechanical instability of the B19$^\prime$ lattice with
respect to shears along the (001)$_{B19^\prime}$ plane, which is known from
first-principles calculations.",http://arxiv.org/abs/2501.18421v1
"Motion Diffusion Autoencoders: Enabling Attribute Manipulation in Human
  Motion Demonstrated on Karate Techniques",2025-01-30T20:13:52Z,"Anthony Mendil, Felix Putze","Attribute manipulation deals with the problem of changing individual
attributes of a data point or a time series, while leaving all other aspects
unaffected. This work focuses on the domain of human motion, more precisely
karate movement patterns. To the best of our knowledge, it presents the first
success at manipulating attributes of human motion data. One of the key
requirements for achieving attribute manipulation on human motion is a suitable
pose representation. Therefore, we design a novel rotation-based pose
representation that enables the disentanglement of the human skeleton and the
motion trajectory, while still allowing an accurate reconstruction of the
original anatomy. The core idea of the manipulation approach is to use a
transformer encoder for discovering high-level semantics, and a diffusion
probabilistic model for modeling the remaining stochastic variations. We show
that the embedding space obtained from the transformer encoder is semantically
meaningful and linear. This enables the manipulation of high-level attributes,
by discovering their linear direction of change in the semantic embedding space
and moving the embedding along said direction. The code and data are available
at https://github.com/anthony-mendil/MoDiffAE.",http://arxiv.org/abs/2501.18729v1
"Magnetizing weak links by time-dependent spin-orbit interactions:
  momentum conserving and non-conserving processes",2025-01-31T08:46:18Z,"Debashree Chowdhury, O. Entin-Wohlman, A. Aharony, R. I. Shekhter, M. Jonson","Rashba spin-orbit interactions generated by time-dependent electric fields
acting on weak links (that couple together non-magnetic macroscopic leads) can
magnetize the junction. The Rashba spin-orbit interaction that affects the
spins of electrons tunneling through the weak links changes their momentum
concomitantly. We establish the connection between the magnetization flux
induced by processes that conserve the momentum and the magnetization created
by tunneling events that do not. Control of the induced magnetization can be
achieved by tuning the polarization of the AC electric field responsible for
the spin-orbit Rashba interaction (e.g., from being circular to linear), by
changing the applied bias voltage, and by varying the degree of a gate
voltage-induced asymmetry of the device.",http://arxiv.org/abs/2501.18961v1
"Reinforcement Learning on Reconfigurable Hardware: Overcoming Material
  Variability in Laser Material Processing",2025-01-31T12:51:55Z,"Giulio Masinelli, Chang Rajani, Patrik Hoffmann, Kilian Wasmer, David Atienza","Ensuring consistent processing quality is challenging in laser processes due
to varying material properties and surface conditions. Although some approaches
have shown promise in solving this problem via automation, they often rely on
predetermined targets or are limited to simulated environments. To address
these shortcomings, we propose a novel real-time reinforcement learning
approach for laser process control, implemented on a Field Programmable Gate
Array to achieve real-time execution. Our experimental results from laser
welding tests on stainless steel samples with a range of surface roughnesses
validated the method's ability to adapt autonomously, without relying on reward
engineering or prior setup information. Specifically, the algorithm learned the
correct power profile for each unique surface characteristic, demonstrating
significant improvements over hand-engineered optimal constant power strategies
-- up to 23% better performance on rougher surfaces and 7% on mixed surfaces.
This approach represents a significant advancement in automating and optimizing
laser processes, with potential applications across multiple industries.",http://arxiv.org/abs/2501.19102v1
"A Three-Branch Checks-and-Balances Frameworkfor Context-Aware Ethical
  Alignment of Large Language Models",2025-01-31T19:41:28Z,Edward Y. Chang,"This paper introduces a three-branch checks-and-balances framework for
ethical alignment of Large Language Models (LLMs), inspired by governmental
systems. It implements three independent yet interacting components: LLMs as
the executive branch for knowledge generation, DIKE as the legislative branch
establishing ethical guardrails, and ERIS as the judicial branch for contextual
interpretation. The adversarial DIKE-ERIS duality enables adaptation to diverse
cultural contexts while upholding consistent ethical principles. This
architecture addresses limitations of reinforcement learning with human
feedback (RLHF) by providing interpretable, adaptable, and culturally-aware
ethical reasoning. Through self-supervised learning and adversarial testing,
our framework demonstrates how emotional modeling can guide linguistic
behaviors toward ethical outcomes while preserving independence across
knowledge generation, ethical oversight, and contextual interpretation.",http://arxiv.org/abs/2502.00136v1
Model Successor Functions,2025-01-31T22:27:09Z,"Yingshan Chang, Yonatan Bisk","The notion of generalization has moved away from the classical one defined in
statistical learning theory towards an emphasis on out-of-domain generalization
(OODG). Recently, there is a growing focus on inductive generalization, where a
progression of difficulty implicitly governs the direction of domain shifts. In
inductive generalization, it is often assumed that the training data lie in the
easier side, while the testing data lie in the harder side. The challenge is
that training data are always finite, but a learner is expected to infer an
inductive principle that could be applied in an unbounded manner. This emerging
regime has appeared in the literature under different names, such as
length/logical/algorithmic extrapolation, but a formal definition is lacking.
This work provides such a formalization that centers on the concept of model
successors. Then we outline directions to adapt well-established techniques
towards the learning of model successors. This work calls for restructuring of
the research discussion around inductive generalization from fragmented
task-centric communities to a more unified effort, focused on universal
properties of learning and computation.",http://arxiv.org/abs/2502.00197v1
K Nearest Neighbor-Guided Trajectory Similarity Learning,2025-02-01T02:52:43Z,"Yanchuan Chang, Xu Cai, Christian S. Jensen, Jianzhong Qi","Trajectory similarity is fundamental to many spatio-temporal data mining
applications. Recent studies propose deep learning models to approximate
conventional trajectory similarity measures, exploiting their fast inference
time once trained. Although efficient inference has been reported, challenges
remain in similarity approximation accuracy due to difficulties in trajectory
granularity modeling and in exploiting similarity signals in the training data.
To fill this gap, we propose TSMini, a highly effective trajectory similarity
model with a sub-view modeling mechanism capable of learning multi-granularity
trajectory patterns and a k nearest neighbor-based loss that guides TSMini to
learn not only absolute similarity values between trajectories but also their
relative similarity ranks. Together, these two innovations enable highly
accurate trajectory similarity approximation. Experiments show that TSMini can
outperform the state-of-the-art models by 22% in accuracy on average when
learning trajectory similarity measures.",http://arxiv.org/abs/2502.00285v1
Mitigating Heterogeneous Token Overfitting in LLM Knowledge Editing,2025-02-02T00:10:51Z,"Tianci Liu, Zihan Dong, Linjun Zhang, Haoyu Wang, Jing Gao","Large language models (LLMs) have achieved remarkable performance on various
natural language tasks. However, they are trained on static corpora and their
knowledge can become outdated quickly in the fast-changing world. This
motivates the development of knowledge editing (KE) to update specific
knowledge in LLMs without changing unrelated others or compromising their
pre-trained capabilities. Previous efforts sought to update a small amount of
parameters of a LLM and proved effective for making selective updates.
Nonetheless, the edited LLM often exhibits degraded ability to reason about the
new knowledge. In this work, we identify a key issue: heterogeneous token
overfitting (HTO), where the LLM overfits different tokens in the provided
knowledge at varying rates. To tackle this, we propose OVERTONE, a token-level
smoothing method that mitigates HTO by adaptively refining the target
distribution. Theoretically, OVERTONE offers better parameter updates with
negligible computation overhead. It also induces an implicit DPO but does not
require preference data pairs. Extensive experiments across four editing
methods, two LLMs, and diverse scenarios demonstrate the effectiveness and
versatility of our method.",http://arxiv.org/abs/2502.00602v1
Optimal local certification on graphs of bounded pathwidth,2025-02-02T05:28:08Z,"Dan Alden Baterisna, Yi-Jun Chang","We present proof labeling schemes for graphs with bounded pathwidth that can
decide any graph property expressible in monadic second-order (MSO) logic using
$O(\log n)$-bit vertex labels. Examples of such properties include planarity,
Hamiltonicity, $k$-colorability, $H$-minor-freeness, admitting a perfect
matching, and having a vertex cover of a given size.
  Our proof labeling schemes improve upon a recent result by Fraigniaud,
Montealegre, Rapaport, and Todinca (Algorithmica 2024), which achieved the same
result for graphs of bounded treewidth but required $O(\log^2 n)$-bit labels.
Our improved label size $O(\log n)$ is optimal, as it is well-known that any
proof labeling scheme that accepts paths and rejects cycles requires labels of
size $\Omega(\log n)$.
  Our result implies that graphs with pathwidth at most $k$ can be certified
using $O(\log n)$-bit labels for any fixed constant $k$. Applying the Excluding
Forest Theorem of Robertson and Seymour, we deduce that the class of
$F$-minor-free graphs can be certified with $O(\log n)$-bit labels for any
fixed forest $F$, thereby providing an affirmative answer to an open question
posed by Bousquet, Feuilloley, and Pierron (Journal of Parallel and Distributed
Computing 2024).",http://arxiv.org/abs/2502.00676v1
Trade Dynamics of the Global Dry Bulk Shipping Network,2025-02-02T19:01:22Z,"Yan Li, Carol Alexander, Michael Coulon, Istvan Kiss","This study investigates the inherently random structures of dry bulk shipping
networks, often likened to a taxi service, and identifies the underlying trade
dynamics that contribute to this randomness within individual cargo
sub-networks. By analysing micro-level trade flow data from 2015 to 2023, we
explore the evolution of dry commodity networks, including grain, coal, and
iron ore, and suggest that the Giant Strongly Connected Components exhibit
small-world phenomena, indicative of efficient bilateral trade. The significant
heterogeneity of in-degree and out-degree within these sub-networks, primarily
driven by importing ports, underscores the complexity of their dynamics. Our
temporal analysis shows that while the Covid-19 pandemic profoundly impacted
the coal network, the Ukraine conflict significantly altered the grain network,
resulting in changes in community structures. Notably, grain sub-networks
display periodic changes, suggesting distinct life cycles absent in coal and
iron ore networks. These findings illustrate that the randomness in dry bulk
shipping networks is a reflection of real-world trade dynamics, providing
valuable insights for stakeholders in navigating and predicting network
behaviours.",http://arxiv.org/abs/2502.00877v1
Structured Pneumatic Fingerpads for Actively Tunable Grip Friction,2025-02-02T21:29:23Z,"Katherine Allison, Jonathan Kelly, Benjamin Hatton","Grip surfaces with tunable friction can actively modify contact conditions,
enabling transitions between higher- and lower-friction states for grasp
adjustment. Friction can be increased to grip securely and then decreased to
gently release (e.g., for handovers) or manipulate in-hand. Recent
friction-tuning surface designs using soft pneumatic chambers show good control
over grip friction; however, most require complex fabrication processes and/or
custom gripper hardware. We present a practical structured fingerpad design for
friction tuning that uses less than \$1 USD of materials, takes only seconds to
repair, and is easily adapted to existing grippers. Our design uses surface
morphology changes to tune friction. The fingerpad is actuated by pressurizing
its internal chambers, thereby deflecting its flexible grip surface out from or
into these chambers. We characterize the friction-tuning capabilities of our
design by measuring the shear force required to pull an object from a gripper
equipped with two independently actuated fingerpads. Our results show that
varying actuation pressure and timing changes the magnitude of friction forces
on a gripped object by up to a factor of 2.8. We demonstrate additional
features including macro-scale interlocking behaviour and pressure-based object
detection.",http://arxiv.org/abs/2502.00926v1
"Revisiting turbulent properties of solar convection with 3D radiative
  hydrodynamic modeling",2025-02-03T00:55:40Z,"Irina N. Kitiashvili, Alan A. Wray","We discuss the turbulent structure and dynamics of the upper solar convection
zone using a 3D radiative hydrodynamic simulation model at 45 degrees latitude.
The model reveals the self-formation of meridional flows, the leptocline, and
the radial differential rotation. Unlike previous studies, the model shows a
complex variation of the characteristic scales of turbulent flows with depth.
In particular, an increase in the characteristic convective scale is trackable
within an individual snapshot up to a depth of 7 Mm, near the bottom of the
hydrogen ionization zone, where turbulent flows become weaker and more
homogeneous. However, the turbulent spectra show an increase in scale with
depth and a qualitative change in convective patterns below 7 Mm (near the
bottom of the leptocline), suggesting changes in the diffusivity properties and
energy exchange among different scales.",http://arxiv.org/abs/2502.00974v1
Dissipative quantum phase transitions monitored by current fluctuations,2025-02-03T08:08:08Z,"Masataka Matsumoto, Matteo Baggioli, Zi Cai","Dissipative phase transitions (DPT) are defined by sudden changes in the
physical properties of nonequilibrium open quantum systems and they present
characteristics that have no analogue in closed and thermal systems. Several
methods to detect and characterize DPT have been suggested in the literature,
the most famous of which -- the $\textit{Liouvillian gap}$ -- can be derived
from a spectral analysis of the Liouvillian super-operator that governs the
complex interplay between coherent and dissipative dynamics. Here, we consider
the $\textit{output current}$, defined as the average total quantum jumps per
unit time between the open quantum system and the environment. We propose that
output current fluctuations, and in particular their dynamical correlations,
their power spectrum, and their characteristic timescale can provide valuable
information about DPT, confirming a dramatic change of behavior at the critical
point. We validate our proposal using the dissipative XYZ model and the
nonlinear driven-dissipative Kerr model, showing good agreement with previous
estimates of the location of the critical point. Compared to previous
approaches, our proposal could be already experimentally tested in optical
systems, providing a practical method to detect criticality in quantum open
systems.",http://arxiv.org/abs/2502.01136v1
"Boosting Graph Robustness Against Backdoor Attacks: An Over-Similarity
  Perspective",2025-02-03T11:41:42Z,"Chang Liu, Hai Huang, Yujie Xing, Xingquan Zuo","Graph Neural Networks (GNNs) have achieved notable success in tasks such as
social and transportation networks. However, recent studies have highlighted
the vulnerability of GNNs to backdoor attacks, raising significant concerns
about their reliability in real-world applications. Despite initial efforts to
defend against specific graph backdoor attacks, existing defense methods face
two main challenges: either the inability to establish a clear distinction
between triggers and clean nodes, resulting in the removal of many clean nodes,
or the failure to eliminate the impact of triggers, making it challenging to
restore the target nodes to their pre-attack state. Through empirical analysis
of various existing graph backdoor attacks, we observe that the triggers
generated by these methods exhibit over-similarity in both features and
structure. Based on this observation, we propose a novel graph backdoor defense
method SimGuard. We first utilizes a similarity-based metric to detect triggers
and then employs contrastive learning to train a backdoor detector that
generates embeddings capable of separating triggers from clean nodes, thereby
improving detection efficiency. Extensive experiments conducted on real-world
datasets demonstrate that our proposed method effectively defends against
various graph backdoor attacks while preserving performance on clean nodes. The
code will be released upon acceptance.",http://arxiv.org/abs/2502.01272v1
"Identification and Optimization of High-Performance Passing Networks in
  Football",2025-02-03T15:31:43Z,Andres Chacoma,"This study explores the relationship between the performance of a football
team and the topological parameters of temporal passing networks. To achieve
this, we propose a method to identify moments of high and low team performance
based on the analysis of match events. This approach enables the construction
of sets of temporal passing networks associated with each performance context.
By analyzing topological metrics such as clustering, eigenvector centrality,
and betweenness across both sets, significant structural differences were
identified between moments of high and low performance. These differences
reflect changes in the interaction dynamics among players and, consequently, in
the team's playing system. Subsequently, a logistic regression model was
employed to classify high- and low-performance networks. The analysis of the
model coefficients identified which metrics need to be adjusted to promote the
emergence of structures associated with better performance. This framework
provides quantitative tools to guide tactical decisions and optimize playing
dynamics. Finally, the proposed method was applied to address the ``blocked
player"" problem, optimizing passing relationships to minimize the emergence of
structures associated with low performance, thereby ensuring more robust
dynamics against contextual changes.",http://arxiv.org/abs/2502.01444v1
"Faster Adaptive Optimization via Expected Gradient Outer Product
  Reparameterization",2025-02-03T18:26:35Z,"Adela DePavia, Vasileios Charisopoulos, Rebecca Willett","Adaptive optimization algorithms -- such as Adagrad, Adam, and their variants
-- have found widespread use in machine learning, signal processing and many
other settings. Several methods in this family are not rotationally
equivariant, meaning that simple reparameterizations (i.e. change of basis) can
drastically affect their convergence. However, their sensitivity to the choice
of parameterization has not been systematically studied; it is not clear how to
identify a ""favorable"" change of basis in which these methods perform best. In
this paper we propose a reparameterization method and demonstrate both
theoretically and empirically its potential to improve their convergence
behavior. Our method is an orthonormal transformation based on the expected
gradient outer product (EGOP) matrix, which can be approximated using either
full-batch or stochastic gradient oracles. We show that for a broad class of
functions, the sensitivity of adaptive algorithms to choice-of-basis is
influenced by the decay of the EGOP matrix spectrum. We illustrate the
potential impact of EGOP reparameterization by presenting empirical evidence
and theoretical arguments that common machine learning tasks with ""natural""
data exhibit EGOP spectral decay.",http://arxiv.org/abs/2502.01594v1
"Query-Based and Unnoticeable Graph Injection Attack from Neighborhood
  Perspective",2025-02-04T02:11:57Z,"Chang Liu, Hai Huang, Yujie Xing, Xingquan Zuo","The robustness of Graph Neural Networks (GNNs) has become an increasingly
important topic due to their expanding range of applications. Various attack
methods have been proposed to explore the vulnerabilities of GNNs, ranging from
Graph Modification Attacks (GMA) to the more practical and flexible Graph
Injection Attacks (GIA). However, existing methods face two key challenges: (i)
their reliance on surrogate models, which often leads to reduced attack
effectiveness due to structural differences and prior biases, and (ii) existing
GIA methods often sacrifice attack success rates in undefended settings to
bypass certain defense models, thereby limiting their overall effectiveness. To
overcome these limitations, we propose QUGIA, a Query-based and Unnoticeable
Graph Injection Attack. QUGIA injects nodes by first selecting edges based on
victim node connections and then generating node features using a Bayesian
framework. This ensures that the injected nodes are similar to the original
graph nodes, implicitly preserving homophily and making the attack more
unnoticeable. Unlike previous methods, QUGIA does not rely on surrogate models,
thereby avoiding performance degradation and achieving better generalization.
Extensive experiments on six real-world datasets with diverse characteristics
demonstrate that QUGIA achieves unnoticeable attacks and outperforms
state-of-the-art attackers. The code will be released upon acceptance.",http://arxiv.org/abs/2502.01936v1
CASIM: Composite Aware Semantic Injection for Text to Motion Generation,2025-02-04T07:22:07Z,"Che-Jui Chang, Qingze Tony Liu, Honglu Zhou, Vladimir Pavlovic, Mubbasir Kapadia","Recent advances in generative modeling and tokenization have driven
significant progress in text-to-motion generation, leading to enhanced quality
and realism in generated motions. However, effectively leveraging textual
information for conditional motion generation remains an open challenge. We
observe that current approaches, primarily relying on fixed-length text
embeddings (e.g., CLIP) for global semantic injection, struggle to capture the
composite nature of human motion, resulting in suboptimal motion quality and
controllability. To address this limitation, we propose the Composite Aware
Semantic Injection Mechanism (CASIM), comprising a composite-aware semantic
encoder and a text-motion aligner that learns the dynamic correspondence
between text and motion tokens. Notably, CASIM is model and
representation-agnostic, readily integrating with both autoregressive and
diffusion-based methods. Experiments on HumanML3D and KIT benchmarks
demonstrate that CASIM consistently improves motion quality, text-motion
alignment, and retrieval scores across state-of-the-art methods. Qualitative
analyses further highlight the superiority of our composite-aware approach over
fixed-length semantic injection, enabling precise motion control from text
prompts and stronger generalization to unseen text inputs.",http://arxiv.org/abs/2502.02063v1
"Neural network potential molecular dynamics simulations of
  (La,Ce,Pr,Nd)0.95(Mg,Zn,Pb,Cd,Ca,Sr,Ba)0.05F2.95",2025-02-04T15:26:13Z,Yoyo Hinuma,"Tysonite structure fluorides doped with divalent cations, represented by
Ce0.95Ca0.05F2.95, are a class of good F- ion conductors together with
fluorite-structured compounds. Computational understanding of the F- conduction
process is difficult because of the complicated interactions between three
symmetrically distinct F sites and the experimentally observed change in the F
diffusion mechanism slightly above room temperature, effectively making first
principles molecular dynamics (FP-MD) simulations, which are often conducted
well above the transition temperature, useless when analyzing behavior below
the transition point. Neural network potential (NNP) MD simulations showed that
the F diffusion coefficient is higher when the divalent dopant cation size is
similar to the trivalent cation size. The diffusion behavior of F in different
sites changes at roughly 500 K in Ce0.95Ca0.05F2.95 because only the F1 site
sublattice contributes to F diffusion below this temperature but the remaining
F2 and F3 sublattices becomes gradually active above this temperature. The
paradox of higher diffusion coefficients in CeF3-based compounds than similar
LaF3-based compounds even though the lattice parameters are larger in the
latter may be caused by a shallower potential of Ce and F in CeF3 compared to
the LaF3 counterparts.",http://arxiv.org/abs/2502.02408v1
"Improving volatility forecasts of the Nikkei 225 stock index using a
  realized EGARCH model with realized and realized range-based volatilities",2025-02-04T20:23:49Z,Yaming Chang,"This paper applies the realized exponential generalized autoregressive
conditional heteroskedasticity (REGARCH) model to analyze the Nikkei 225 index
from 2010 to 2017, utilizing realized variance (RV) and realized range-based
volatility (RRV) as high-frequency measures of volatility. The findings show
that REGARCH models outperform standard GARCH family models in both in-sample
fitting and out-of-sample forecasting, driven by the dynamic information
embedded in high-frequency realized measures. Incorporating multiple realized
measures within a joint REGARCH framework further enhances model performance.
Notably, RRV demonstrates superior predictive power compared to RV, as
evidenced by improvements in forecast accuracy metrics. Moreover, the
forecasting results remain robust under both rolling-window and recursive
evaluation schemes.",http://arxiv.org/abs/2502.02695v2
"Concentration on the Boundary and Sign-Changing Solutions for a Slightly
  Subcritical Biharmonic Problem",2025-02-04T22:23:05Z,"Salomón Alarcón, Jorge Faya, Carolina Rey","We consider the fourth-order nonlinear elliptic problem: \begin{equation*}
\begin{array}{ll}
  \Delta(a(x)\Delta u) = a(x) \left\vert u \right\vert^{p-2-\epsilon} u \
\text{ in } \ \Omega,
  \hspace{0.6cm} u = 0 \ \text{ on } \ \partial \Omega,
  \hspace{0.6cm} \Delta u = 0 \ \text{ on } \ \partial \Omega,
  \end{array}\end{equation*} where $\Omega$ is a smooth, bounded domain in
$\mathbb{R}^N$ with $N \geq 5$. Here, $p := \frac{2N}{N-4}$ is the Sobolev
critical exponent for the embedding $H^2 \cap H_0^1(\Omega) \hookrightarrow
L^p(\Omega)$, and $a \in C^2(\overline{\Omega})$ is a strictly positive
function on $\overline{\Omega}$.
  We establish sufficient conditions on the function $a$ and the domain
$\Omega$ for this problem to admit both positive and sign-changing solutions
with an explicit asymptotic profile. These solutions concentrate and blow up at
a point on the boundary $\partial \Omega$ as $\epsilon \to 0$. The proofs of
the main results rely on the Lyapunov-Schmidt finite-dimensional reduction
method.",http://arxiv.org/abs/2502.02745v1
"CAMI: A Counselor Agent Supporting Motivational Interviewing through
  State Inference and Topic Exploration",2025-02-05T01:09:09Z,"Yizhe Yang, Palakorn Achananuparp, Heyan Huang, Jing Jiang, Kit Phey Leng, Nicholas Gabriel Lim, Cameron Tan Shi Ern, Ee-peng Lim","Conversational counselor agents have become essential tools for addressing
the rising demand for scalable and accessible mental health support. This paper
introduces CAMI, a novel automated counselor agent grounded in Motivational
Interviewing (MI) -- a client-centered counseling approach designed to address
ambivalence and facilitate behavior change. CAMI employs a novel STAR
framework, consisting of client's state inference, motivation topic
exploration, and response generation modules, leveraging large language models
(LLMs). These components work together to evoke change talk, aligning with MI
principles and improving counseling outcomes for clients from diverse
backgrounds. We evaluate CAMI's performance through both automated and manual
evaluations, utilizing simulated clients to assess MI skill competency,
client's state inference accuracy, topic exploration proficiency, and overall
counseling success. Results show that CAMI not only outperforms several
state-of-the-art methods but also shows more realistic counselor-like behavior.
Additionally, our ablation study underscores the critical roles of state
inference and topic exploration in achieving this performance.",http://arxiv.org/abs/2502.02807v1
"A Systematic Approach for Assessing Large Language Models' Test Case
  Generation Capability",2025-02-05T03:51:44Z,"Hung-Fu Chang, Mohammad Shokrolah Shirazi","Software testing ensures the quality and reliability of software products,
but manual test case creation is labor-intensive. With the rise of large
language models (LLMs), there is growing interest in unit test creation with
LLMs. However, effective assessment of LLM-generated test cases is limited by
the lack of standardized benchmarks that comprehensively cover diverse
programming scenarios. To address the assessment of LLM's test case generation
ability and lacking dataset for evaluation, we propose the Generated Benchmark
from Control-Flow Structure and Variable Usage Composition (GBCV) approach,
which systematically generates programs used for evaluating LLMs' test
generation capabilities. By leveraging basic control-flow structures and
variable usage, GBCV provides a flexible framework to create a spectrum of
programs ranging from simple to complex. Because GPT-4o and GPT-3-Turbo are
publicly accessible models, to present real-world regular user's use case, we
use GBCV to assess LLM performance on them. Our findings indicate that GPT-4o
performs better on complex program structures, while all models effectively
detect boundary values in simple conditions but face challenges with arithmetic
computations. This study highlights the strengths and limitations of LLMs in
test generation, provides a benchmark framework, and suggests directions for
future improvement.",http://arxiv.org/abs/2502.02866v1
"Improve Decoding Factuality by Token-wise Cross Layer Entropy of Large
  Language Models",2025-02-05T14:19:52Z,"Jialiang Wu, Yi Shen, Sijia Liu, Yi Tang, Sen Song, Xiaoyi Wang, Longjun Cai","Despite their impressive capacities, Large language models (LLMs) often
struggle with the hallucination issue of generating inaccurate or fabricated
content even when they possess correct knowledge. In this paper, we extend the
exploration of the correlation between hidden-state prediction changes and
output factuality into a deeper, token-wise level. Based on the insights , we
propose cross-layer Entropy eNhanced Decoding (END), a decoding method that
mitigates hallucinations without requiring extra training. END leverages inner
probability changes across layers to individually quantify the factual
knowledge required for each candidate token, and adjusts the final predicting
distribution to prioritize tokens with higher factuality. Experiments on both
hallucination and QA benchmarks demonstrate that END significantly enhances the
truthfulness and informativeness of generated content while maintaining robust
QA accuracy. Moreover, our work provides a deeper perspective on understanding
the correlations between inherent knowledge and output factuality.",http://arxiv.org/abs/2502.03199v1
"Temporal multilayer structures for designing higher-order transfer
  functions using time-varying metamaterials",2025-02-05T15:12:20Z,"Davide Ramaccia, Andrea Alu, Alessandro Toscano, Filiberto Bilotti","Temporal metamaterials are artificial materials whose electromagnetic
properties change over time. In analogy with spatial media and metamaterials,
where their properties change smoothly or abruptly over space, temporal
metamaterials can exhibit a smooth variation over time, realizing a temporal
non-homogeneous medium, or a stepwise transition, realizing the temporal
version of dielectric slabs or multilayer structures. In this Letter, we focus
our attention on temporal multilayer structures, and we propose the synthesis
of higher-order transfer functions by modeling the wave propagation through a
generalized temporal multilayer structure, consisting of a cascade over time of
different media. The tailoring of the scattering response of temporal structure
as a function of frequency is presented, deriving the corresponding scattering
coefficients for a properly designed set of medium properties, i.e.,
permittivity and permeability, and application time, in analogy with what is
typically done in optical and electromagnetic spatial multilayered structures.
This allows us to design novel electromagnetic and optical devices with
higher-order transfer functions by exploiting the temporal dimension instead of
the spatial one.",http://arxiv.org/abs/2502.03255v1
"Adaptive Variational Inference in Probabilistic Graphical Models: Beyond
  Bethe, Tree-Reweighted, and Convex Free Energies",2025-02-05T16:33:59Z,"Harald Leisenberger, Franz Pernkopf","Variational inference in probabilistic graphical models aims to approximate
fundamental quantities such as marginal distributions and the partition
function. Popular approaches are the Bethe approximation, tree-reweighted, and
other types of convex free energies. These approximations are efficient but can
fail if the model is complex and highly interactive. In this work, we analyze
two classes of approximations that include the above methods as special cases:
first, if the model parameters are changed; and second, if the entropy
approximation is changed. We discuss benefits and drawbacks of either approach,
and deduce from this analysis how a free energy approximation should ideally be
constructed. Based on our observations, we propose approximations that
automatically adapt to a given model and demonstrate their effectiveness for a
range of difficult problems.",http://arxiv.org/abs/2502.03341v1
"Discrete GCBF Proximal Policy Optimization for Multi-agent Safe Optimal
  Control",2025-02-05T21:51:47Z,"Songyuan Zhang, Oswin So, Mitchell Black, Chuchu Fan","Control policies that can achieve high task performance and satisfy safety
constraints are desirable for any system, including multi-agent systems (MAS).
One promising technique for ensuring the safety of MAS is distributed control
barrier functions (CBF). However, it is difficult to design distributed
CBF-based policies for MAS that can tackle unknown discrete-time dynamics,
partial observability, changing neighborhoods, and input constraints,
especially when a distributed high-performance nominal policy that can achieve
the task is unavailable. To tackle these challenges, we propose DGPPO, a new
framework that simultaneously learns both a discrete graph CBF which handles
neighborhood changes and input constraints, and a distributed high-performance
safe policy for MAS with unknown discrete-time dynamics. We empirically
validate our claims on a suite of multi-agent tasks spanning three different
simulation engines. The results suggest that, compared with existing methods,
our DGPPO framework obtains policies that achieve high task performance
(matching baselines that ignore the safety constraints), and high safety rates
(matching the most conservative baselines), with a constant set of
hyperparameters across all environments.",http://arxiv.org/abs/2502.03640v1
"Nonlinearity and Quantumness in Thermodynamics: From Principles to
  Technologies",2025-02-06T05:37:25Z,"Gershon Kurizki, Nilakantha Meher, Tomáš Opatrný","The impact of quantum mechanics on thermodynamics, particularly on the
principles and designs of heat machines (HM), has been limited by the
incompatibility of quantum coherent evolution with the dissipative, open-system
nature of all existing HM and their basic structure, which has not been
radically changed since Carnot. We have recently proposed a paradigm change
whereby conventional HM functionality is replaced by that of few-mode coherent,
closed systems with nonlinear, e.g. cross-Kerr, inter-mode couplings. These
couplings allow us to coherently filter incident thermal noise, transforming it
into a resource of work and information. Current technological advances enable
heat engines, noise sensors or microscopes based on such designs to operate
with thermal noise sources of few photons. This paradigm shift opens a path
towards radically new understanding and exploitation of the relation between
coherent, quantum or classical, evolution and thermodynamic behavior.",http://arxiv.org/abs/2502.03791v1
"Inhibition and promotion of quasi-uniform to filamentary discharge
  transition in negative repetitive nanosecond surface dielectric barrier
  discharge",2025-02-06T10:00:11Z,"Zhang Yaqi, Guo Yulin, Zhu Yifei, Sun Anbang","The transition from quasi-uniform to filamentary modes in a repetitive
nanosecond Surface Dielectric Barrier Discharge(SDBD) under atmospheric
pressure was studied. Our focus encompassed both discharge morphology and
electrical characteristics, revealing two pivotal findings. Firstly, by
analyzing the current and the deposited energy waveforms, three characteristic
frequency ranges respectively corresponding to the discharge modes are
identified. Notably, within the 5 kHz to 8 kHz range, we observed non-monotonic
changes in the propagation distance, the current amplitude, and the deposited
energy - a crucial insight linked to the discharge transition. Secondly, the
count of current extrema in the primary discharge process changes only during
the transition to filamentary mode, remaining stable in the steady discharge
mode. This variation may be attributed to secondary Surface Ionization Waves
(SIWs). The interplay of these two findings with the discharge transition
requires deeper investigation. Additionally, we present a discharge modes
control curve outlining parameter windows for the discharge modes. This curve
facilitates the optimization of pulse power supply and control schemes in
practical applications.",http://arxiv.org/abs/2502.03923v1
"Can Grammarly and ChatGPT accelerate language change? AI-powered
  technologies and their impact on the English language: wordiness vs.
  conciseness",2025-02-06T18:59:26Z,Karolina Rudnicka,"The proliferation of NLP-powered language technologies, AI-based natural
language generation models, and English as a mainstream means of communication
among both native and non-native speakers make the output of AI-powered tools
especially intriguing to linguists. This paper investigates how Grammarly and
ChatGPT affect the English language regarding wordiness vs. conciseness. A case
study focusing on the purpose subordinator in order to is presented to
illustrate the way in which Grammarly and ChatGPT recommend shorter grammatical
structures instead of longer and more elaborate ones. Although the analysed
sentences were produced by native speakers, are perfectly correct, and were
extracted from a language corpus of contemporary English, both Grammarly and
ChatGPT suggest more conciseness and less verbosity, even for relatively short
sentences. The present article argues that technologies such as Grammarly not
only mirror language change but also have the potential to facilitate or
accelerate it.",http://arxiv.org/abs/2502.04324v1
On Techniques for Barely Coupled Multiphysics,2025-02-06T20:09:01Z,"Rainald Löhner, Harbir Antil, Sebastian Schöps","A technique to combine codes to solve barely coupled multiphysics problems
has been developed. Each field is advanced separately until a stop is
triggered. This could be due to a preset time increment, a preset number of
timesteps, a preset decrease of residuals, a preset change in unknowns, a
preset change in geometry, or any other physically meaningful quantity. The
technique allows for a simple implementation in coupled codes using the loose
coupling approach. Examples from evaporative cooling of electric motors, a
problem that has come to the forefront with the rise of electric propulsion in
the aerospace sector (drones and air taxis in particular) shows the viability
and accuracy of the proposed procedure.",http://arxiv.org/abs/2502.04480v1
"Enhancing Impression Change Prediction in Speed Dating Simulations Based
  on Speakers' Personalities",2025-02-07T07:18:32Z,"Kazuya Matsuo, Yoko Ishii, Atsushi Otsuka, Ryo Ishii, Hiroaki Sugiyama, Masahiro Mizukami, Tsunehiro Arimoto, Narichika Nomoto, Yoshihide Sato, Tetsuya Yamaguchi","This paper focuses on simulating text dialogues in which impressions between
speakers improve during speed dating. This simulation involves selecting an
utterance from multiple candidates generated by a text generation model that
replicates a specific speaker's utterances, aiming to improve the impression of
the speaker. Accurately selecting an utterance that improves the impression is
crucial for the simulation. We believe that whether an utterance improves a
dialogue partner's impression of the speaker may depend on the personalities of
both parties. However, recent methods for utterance selection do not consider
the impression per utterance or the personalities. To address this, we propose
a method that predicts whether an utterance improves a partner's impression of
the speaker, considering the personalities. The evaluation results showed that
personalities are useful in predicting impression changes per utterance.
Furthermore, we conducted a human evaluation of simulated dialogues using our
method. The results showed that it could simulate dialogues more favorably
received than those selected without considering personalities.",http://arxiv.org/abs/2502.04706v1
Ensembles in Urban Large Eddy Simulations with Changing Wind Direction,2025-02-07T11:10:29Z,"Jukka-Pekka Keskinen, Antti Hellsten","Differences between time-averaged and ensemble-averaged wind are studied in
this article for the case of changing wind direction. We consider a flow driven
by a temporally turning pressure gradient in both an idealized case of a
staggered cube array and a realistic urban environment. The repeating structure
of the idealized case allows us to construct a large ensemble of 3 240 members
with a reasonable compute time. The results indicate that the use of plain time
average instead of an ensemble average allows for accurate calculation of only
the along-wind mean velocity. Utilising Taylor diagrams, we show that a
reasonable compromise between ensemble size and accuracy can be achieved
utilising a 30-minute time average together with a 50-member ensemble for the
flow within the urban roughness sublayer. During this 30-minute averaging
period, the wind direction turns for approximately 4.8{\deg}. By applying this
approach to the realistic urban geometry, we identify building wakes as the
regions most severely affected by the incorrectly utilized time averaging.",http://arxiv.org/abs/2502.04836v1
"Relationship among solutions for three-phase change problems with Robin,
  Dirichlet, and Neumann boundary conditions",2025-02-08T12:18:07Z,"Julieta Bollati, María Fernanda Natale, José Abel Semitiel, Domingo Alberto Tarzia","This study investigates the melting process of a three-phase Stefan problem
in a semi-infinite material, imposing a convective boundary condition at the
fixed face. By employing a similarity-type transformation, the problem is
reduced to a solvable form, yielding a unique explicit solution. The analysis
uncovers significant equivalences among the solutions of three different
three-phase Stefan problems: one with a Robin boundary condition, another with
a Dirichlet boundary condition, and a third one with a Neumann boundary
condition at the fixed face. These equivalences are established under the
condition that the problem data satisfy a specific relationship, providing new
insights into the behaviour of phase change problems under varying boundary
conditions.",http://arxiv.org/abs/2502.05545v1
Reinforced Lifelong Editing for Language Models,2025-02-09T03:37:06Z,"Zherui Li, Houcheng Jiang, Hao Chen, Baolong Bi, Zhenhong Zhou, Fei Sun, Junfeng Fang, Xiang Wang","Large language models (LLMs) acquire information from pre-training corpora,
but their stored knowledge can become inaccurate or outdated over time. Model
editing addresses this challenge by modifying model parameters without
retraining, and prevalent approaches leverage hypernetworks to generate these
parameter updates. However, they face significant challenges in lifelong
editing due to their incompatibility with LLM parameters that dynamically
change during the editing process. To address this, we observed that
hypernetwork-based lifelong editing aligns with reinforcement learning modeling
and proposed RLEdit, an RL-based editing method. By treating editing losses as
rewards and optimizing hypernetwork parameters at the full knowledge sequence
level, we enable it to precisely capture LLM changes and generate appropriate
parameter updates. Our extensive empirical evaluation across several LLMs
demonstrates that RLEdit outperforms existing methods in lifelong editing with
superior effectiveness and efficiency, achieving a 59.24% improvement while
requiring only 2.11% of the time compared to most approaches. Our code is
available at: https://github.com/zhrli324/RLEdit.",http://arxiv.org/abs/2502.05759v2
Decision Making in Hybrid Environments: A Model Aggregation Approach,2025-02-09T17:59:42Z,"Haolin Liu, Chen-Yu Wei, Julian Zimmert","Recent work by Foster et al. (2021, 2022, 2023) and Xu and Zeevi (2023)
developed the framework of decision estimation coefficient (DEC) that
characterizes the complexity of general online decision making problems and
provides a general algorithm design principle. These works, however, either
focus on the pure stochastic regime where the world remains fixed over time, or
the pure adversarial regime where the world arbitrarily changes over time. For
the hybrid regime where the dynamics of the world is fixed while the reward
arbitrarily changes, they only give pessimistic bounds on the decision
complexity. In this work, we propose a general extension of DEC that more
precisely characterizes this case. Besides applications in special cases, our
framework leads to a flexible algorithm design where the learner learns over
subsets of the hypothesis set, trading estimation complexity with decision
complexity, which could be of independent interest. Our work covers model-based
learning and model-free learning in the hybrid regime, with a newly proposed
extension of the bilinear classes (Du et al., 2021) to the adversarial-reward
case. We also recover some existing model-free learning results in the pure
stochastic regime.",http://arxiv.org/abs/2502.05974v1
Thermodynamic Cost of Steady State Erasure,2025-02-09T20:10:22Z,"Deepak Gupta, Kristian Stølevik Olsen, Supriya Krishnamurthy","Recent experiments have implemented resetting by means of a time-varying
external harmonic trap whereby the trap stiffness is changed from an initial to
a final value in finite-time and then the system is reset when it relaxes to an
equilibrium distribution in the final trap. Such setups are very similar to
those studied in the context of the finite-time Landauer erasure principle. We
analyse the thermodynamic costs of such a setup by deriving a moment generating
function for the work cost of changing the trap stiffness in finite-time for a
system in steady state. We analyse the mean and variance of the work required
for a specific experimentally viable protocol and also obtain an optimal
protocol which minimises the mean cost. For both these procedures, our analysis
captures both the large-time and short-time corrections. For the optimal
protocol, we obtain a closed form expression for the mean cost for all protocol
durations, thereby making contact with earlier work on geometric measures of
dissipation-minimising optimal protocols that implement information erasure.",http://arxiv.org/abs/2502.06014v1
Proprioceptive Origami Manipulator,2025-02-10T11:29:25Z,"Aida Parvaresh, Arman Goshtasbi, Jonathan Andres Tirado Rosero, Ahmad Rafsanjani","Origami offers a versatile framework for designing morphable structures and
soft robots by exploiting the geometry of folds. Tubular origami structures can
act as continuum manipulators that balance flexibility and strength. However,
precise control of such manipulators often requires reliance on vision-based
systems that limit their application in complex and cluttered environments.
Here, we propose a proprioceptive tendon-driven origami manipulator without
compromising its flexibility. Using conductive threads as actuating tendons, we
multiplex them with proprioceptive sensing capabilities. The change in the
active length of the tendons is reflected in their effective resistance, which
can be measured with a simple circuit. We correlated the change in the
resistance to the lengths of the tendons. We input this information into a
forward kinematic model to reconstruct the manipulator configuration and
end-effector position. This platform provides a foundation for the closed-loop
control of continuum origami manipulators while preserving their inherent
flexibility.",http://arxiv.org/abs/2502.06362v1
Hedgehog-like spin texture in Sb-doped MnBi$_2$Te$_4$,2025-02-10T12:54:29Z,"Meng Zeng, Shu Mo, Ke Zhang, Yu-Jie Hao, Yu-Peng Zhu, Xiang-Rui Liu, Cheng Zhang, Ming-Yuan Zhu, Shiv Kumar, Takuma Iwata, Koji Miyamoto, Taichi Okuda, Kenya Shimada, Kenta Kuroda, Xiao-Ming Ma, Chang Liu","We employ spin- and angle-resolved photoemission spectroscopy and
circular-dichroism ARPES to systematically investigate the spin texture of
Sb-doped MnBi$_2$Te$_4$. Our results display a hedgehog-like spin texture in
this system which is signified by reversed-orienting out-of-plane spins at the
Dirac gap. Our finding reveals the presence of time-reversal symmetry breaking,
implying the possibility for realization of high-temperature quantum anomalous
Hall effect.",http://arxiv.org/abs/2502.06416v1
"Crossover from BKT to first-order transition induced by higher-order
  terms in 2D XY models",2025-02-10T14:26:00Z,Milan Žukovič,"We study phase transitions in $XY$ models, generalized by inclusion of $n$
higher-order pairwise interactions of equal strength, by Monte Carlo
simulation. It is found that by adding new terms the
Berezinskii-Kosterlitz-Thouless (BKT) transition, observed in the standard $XY$
model, gradually changes to the first-order phase transition. We determine the
critical number of terms for which the first-order transition appears as
$n_c=6$. It is also found that for $n=5$ the transition is pseudo-first-order
but it becomes true first-order if the couplings are allowed to increase. In
general, a more rapid increase of the coupling intensity supports the
first-order transition, however, a too fast increase may result in splitting of
the single transition to multiple transitions. Consequently, the minimal number
of the terms required for the change of the BKT phase transition to first order
in the present model with arbitrary couplings is estimated to be $2 < n_c \leq
5$.",http://arxiv.org/abs/2502.06509v1
Topological Constraint Model of Alkaline Earth Vanadate Glasses,2025-02-10T15:40:14Z,"Adam Shearer, John C. Mauro","Topological constraint theory has enabled the successful prediction of glass
properties over a wide range of compositions. In this study, a topological
constraint model is constructed for alkaline earth vanadate glasses based on
experimental data. The change in vanadate structural units from VO5 to VO4 was
modeled as a function of alkaline earth content and related to thermal and
mechanical properties. The model covers both high and low-temperature
properties to probe the temperature dependence of constraint rigidity for each
constituent of the glass network. The model is changed to describe anomalies in
magnesium sites potentially implying that magnesium can form locally rigid
structures. Furthermore, the traditional understanding of vanadate glass
structure is compared to recent results concluding that the terminal oxygen
must exist as a part of the VO4 units. Results for the model explain that
bridging oxygen constraints are the main contributors to network rigidity in
both low and high temperature regimes. Vanadate glass networks are highly
connected even with the introduction of modifier species, which introduce their
own bond constraints. Corroboration between experimental data and the
topological constraint model illustrates the role of alkaline earth oxides in
the glass network.",http://arxiv.org/abs/2502.06571v1
"SMAB: MAB based word Sensitivity Estimation Framework and its
  Applications in Adversarial Text Generation",2025-02-10T22:46:57Z,"Saurabh Kumar Pandey, Sachin Vashistha, Debrup Das, Somak Aditya, Monojit Choudhury","To understand the complexity of sequence classification tasks, Hahn et al.
(2021) proposed sensitivity as the number of disjoint subsets of the input
sequence that can each be individually changed to change the output. Though
effective, calculating sensitivity at scale using this framework is costly
because of exponential time complexity. Therefore, we introduce a
Sensitivity-based Multi-Armed Bandit framework (SMAB), which provides a
scalable approach for calculating word-level local (sentence-level) and global
(aggregated) sensitivities concerning an underlying text classifier for any
dataset. We establish the effectiveness of our approach through various
applications. We perform a case study on CHECKLIST generated sentiment analysis
dataset where we show that our algorithm indeed captures intuitively high and
low-sensitive words. Through experiments on multiple tasks and languages, we
show that sensitivity can serve as a proxy for accuracy in the absence of gold
data. Lastly, we show that guiding perturbation prompts using sensitivity
values in adversarial example generation improves attack success rate by
15.58%, whereas using sensitivity as an additional reward in adversarial
paraphrase generation gives a 12.00% improvement over SOTA approaches. Warning:
Contains potentially offensive content.",http://arxiv.org/abs/2502.07101v1
On a Fractional Variant of Linear Birth-Death Process,2025-02-11T07:48:30Z,"Manisha Dhillon, Pradeep Vishwakarma, Kuldeep Kumar Kataria","We introduce and study a fractional variant of the linear birth-death
process, namely, the generalized fractional linear birth-death process (GFLBDP)
which is defined by taking the regularized Hilfer-Prabhakar derivative in the
system of differential equations that governs the state probabilities of linear
birth-death process. For a particular choice of parameters, the GFLBDP reduces
to the fractional linear birth-death process that involves the Caputo
derivative. Its time-changed representation is obtained and utilized to derive
the explicit expressions of its state probabilities. The explicit expressions
for its mean and variance are derived. In a particular case, it is observed
that the limiting distribution of the time changing process coincides to that
of an inverse stable subordinator. A relation between the extinction
probability of GFLBDP and the density of inter arrival times of a generalized
fractional Poisson process is obtained. Later, we study some integrals of the
GFLBDP and discuss the asymptotic distributional characteristics for a
particular integral process. Also, an application of the path integral at
random time to a genetic population with an upper bound is discussed.",http://arxiv.org/abs/2502.07329v1
Nuclear Fusion Enhancement by Heavy Nuclear Catalysts,2025-02-05T13:48:00Z,"Christopher Grayson, Johann Rafelski","We seek to understand the effect of high electron density in the proximity of
a heavy nucleus on the fusion reaction rates in a hot plasma phase. We
investigate quantitatively the catalytic effect of gold ($Z=79$) ions embedded
in an electron plasma created due to plasmonic focusing of high-intensity short
laser pulses. Using self-consistent strong plasma screening, we find highly
significant changes in the internuclear potential of light elements present
nearby. For gold, we see a $14\,$keV change in the internuclear potential near
the nuclear surface, independent of the long-distance thermal Debye-H\""uckel
screening. The dense polarization cloud of electrons around the gold catalyst
leads to a $\sim 1.5$ enhancement of proton-boron ($^{11}$B) fusion above
$T=100\,$keV.",http://arxiv.org/abs/2502.07804v1
"A Bayesian Non-linear Mixed-Effects Model for Accurate Detection of the
  Onset of Cognitive Decline in Longitudinal Aging Studies",2025-02-12T14:01:05Z,"Fernando Massa, Marco Scavino, Graciela Muniz-Terrera","Change-point models are frequently considered when modeling phenomena where a
regime shift occurs at an unknown time. In ageing research, these models are
commonly adopted to estimate of the onset of cognitive decline. Yet commonly
used models present several limitations. Here, we present a Bayesian non-linear
mixed-effects model based on a differential equation designed for longitudinal
studies to overcome some limitations of classical change point models used in
ageing research. We demonstrate the ability of the proposed model to avoid
biases in estimates of the onset of cognitive impairment in a simulated study.
Finally, the methodology presented in this work is illustrated by analysing
results from memory tests from older adults who participated in the English
Longitudinal Study of Ageing.",http://arxiv.org/abs/2502.08418v1
"Long Secondary Periods in Red Giants: AAVSO Observations and the Eclipse
  Hypothesis",2025-02-12T23:28:33Z,"John Percy, Melanie Szpigiel","At least a third of red giants show a long secondary period (LSP), 5 to 10
times longer than the pulsation period. There is strong evidence that the LSP
is caused by eclipses of the red giant by a dust-enshrouded low-mass companion.
We have used long-term AAVSO observations of 11 stars to study two aspects of
the eclipse hypothesis: the relation between the LSP phase (eclipse) curve and
the geometry of the eclipse, and the long-term (decades) changes in the LSP
phenomenon in each star. The stars with the largest LSP amplitudes show
evidence of a dust tail on the companion, but most of the 11 stars show only a
small-amplitude sinusoidal phase curve. The LSP amplitudes of all the stars
vary slowly by up to a factor of 8, suggesting that the amount of obscuring
dust varies by that amount, but there is no strong evidence that the geometry
of the system changes over many decades.",http://arxiv.org/abs/2502.08842v1
Recent advances in high-dimensional quantum frequency combs,2025-02-13T01:33:58Z,"Kai-Chi Chang, Xiang Cheng, Murat Can Sarihan, Chee Wei Wong","High-dimensional entanglement in qudit states offers a promising pathway
towards the realization of practical, large-scale quantum systems that are
highly controllable. These systems can be leveraged for various applications,
including advanced quantum information processing, secure communications,
computation, and metrology. In this context, quantum frequency combs have a
crucial role as they inherently support multiple modes in both temporal and
frequency domains, while preserving a single spatial mode. The multiple
temporal and frequency modes of quantum frequency combs facilitate the
generation, characterization, and control of high-dimensional time-frequency
entanglement in extensive quantum systems. In this review article, we provide
an overview of recent technological advancements in high-dimensional
energy-time entangled quantum frequency combs. We explore how these
time-frequency qudits, achieved using scalable telecommunications-wavelength
components, can empower the creation of large-scale quantum states. Advances in
quantum frequency combs can unlock new capabilities and versatility for
promising developments in quantum science and technology.",http://arxiv.org/abs/2502.08879v1
Modeling Time-evolving Causality over Data Streams,2025-02-13T04:59:01Z,"Naoki Chihara, Yasuko Matsubara, Ren Fujiwara, Yasushi Sakurai","Given an extensive, semi-infinite collection of multivariate coevolving data
sequences (e.g., sensor/web activity streams) whose observations influence each
other, how can we discover the time-changing cause-and-effect relationships in
co-evolving data streams? How efficiently can we reveal dynamical patterns that
allow us to forecast future values? In this paper, we present a novel streaming
method, ModePlait, which is designed for modeling such causal relationships
(i.e., time-evolving causality) in multivariate co-evolving data streams and
forecasting their future values. The solution relies on characteristics of the
causal relationships that evolve over time in accordance with the dynamic
changes of exogenous variables. ModePlait has the following properties: (a)
Effective: it discovers the time-evolving causality in multivariate co-evolving
data streams by detecting the transitions of distinct dynamical patterns
adaptively. (b) Accurate: it enables both the discovery of time-evolving
causality and the forecasting of future values in a streaming fashion. (c)
Scalable: our algorithm does not depend on data stream length and thus is
applicable to very large sequences. Extensive experiments on both synthetic and
real-world datasets demonstrate that our proposed model outperforms
state-of-the-art methods in terms of discovering the time-evolving causality as
well as forecasting.",http://arxiv.org/abs/2502.08963v1
Generalizing Reduced Rank Extrapolation to Low-Rank Matrix Sequences,2025-02-13T10:48:46Z,"Pascal den Boef, Patrick Kürschner, Xiaobo Liu, Jos Maubach, Jens Saak, Wil Schilders, Jonas Schulze, Nathan van de Wouw","Reduced rank extrapolation (RRE) is an acceleration method typically used to
accelerate the iterative solution of nonlinear systems of equations using a
fixed-point process. In this context, the iterates are vectors generated from a
fixed-point mapping function. However, when considering the iterative solution
of large-scale matrix equations, the iterates are low-rank matrices generated
from a fixed-point process for which, generally, the mapping function changes
in each iteration. To enable acceleration of the iterative solution for these
problems, we propose two novel generalizations of RRE. First, we show how to
effectively compute RRE for sequences of low-rank matrices. Second, we derive a
formulation of RRE that is suitable for fixed-point processes for which the
mapping function changes each iteration. We demonstrate the potential of the
methods on several numerical examples involving the iterative solution of
large-scale Lyapunov and Riccati matrix equations.",http://arxiv.org/abs/2502.09165v1
"Spectral diversity in collisional neutrino-flavor conversion: flavor
  equipartition or swap",2025-02-13T12:18:57Z,Masamichi Zaizen,"Quantum kinetics of neutrinos are known to potentially change the classical
neutrino radiation field in high-energy astrophysical sources such as
core-collapse supernovae and binary neutron-star mergers. However, the mixing
phenomena still have open issues in the nonlinear dynamics and the asymptotic
states, particularly for recently discovered collision-induced flavor
conversion. In this paper, we investigate linear and nonlinear dynamics of
collisional neutrino-flavor conversion (CFC) with multi-energy neutrino gases
through numerical simulations, demonstrating that the asymptotic states
dramatically change depending on unstable modes dominating the system. In one
unstable mode, high-energy neutrinos reach a flavor equipartition, but
low-energy neutrinos return back to almost their initial states. In contrast,
in the other one, rather low-energy neutrinos achieve a full flavor swap, but
high-energy neutrinos undergo less flavor conversion. We clarify the distinct
spectral behaviors in two different ways based on stability analysis and flavor
pendulum. Our result suggests that CFC with flavor swap can become crucial at
deeper radii with low electron fraction and requires more detailed theoretical
modeling of neutrino quantum kinetics.",http://arxiv.org/abs/2502.09260v1
"Unexpected large electrostatic gating by pyroelectric charge
  accumulation",2025-02-13T16:29:50Z,"Yicheng Mou, Qi Liu, Jiaqi Liu, Yingchao Xia, Zejing Guo, Wenqing Song, Jiaming Gu, Zixuan Xu, Wenbin Wang, Hangwen Guo, Wu Shi, Jian Shen, Cheng Zhang","Pyroelectricity refers to the accumulation of charges due to changes in the
spontaneous polarization of ferroelectric materials when subjected to
temperature variations. Typically, these pyroelectric charges are considered
unstable and dissipate quickly through interactions with the external
environment. Consequently, the pyroelectric effect has been largely overlooked
in ferroelectric field-effect transistors. In this work, we leverage the van
der Waals interface of hBN to achieve a substantial and long-term electrostatic
gating effect in graphene devices via the pyroelectric properties of a
ferroelectric LiNbO3 substrate. Upon cooling, the polarization change in LiNbO3
induces high doping concentrations up to 1013 cm-2 in the adjacent graphene.
Through a combination of transport measurements and non-contact techniques, we
demonstrate that the pyroelectric charge accumulation, as well as its
enhancement in electric fields, are responsible for this unexpectedly high
doping level. Our findings introduce a novel mechanism for voltage-free
electrostatic gating control with long retention.",http://arxiv.org/abs/2502.09464v1
Quality thinning and value development of boreal trees,2025-02-13T10:53:49Z,Petri P. Karenlampi,"For the first time, quality distribution of trees is introduced in a tree
growth model. Consequently, the effects of quality thinning on stand
development can be investigated. Quality thinning improves the financial return
in all cases studied, but the effect is small. Rotation ages, timber stocks and
maturity diameters are not much affected by quality thinning. Bare land
valuation neither changes the contribution of the quality thinning. The reason
for the small effect apparently lies in the value development of individual
trees. The relative value development of small pulpwood trunks is large, since
the harvesting expense per volume unit is reduced along with size increment.
Such trees are not feasible objects for quality thinning, unless quality
correlates with growth rate. Another enhanced stage of value development is
when pulpwood trunks turn to sawlog trunks. For large pulpwood trunks, quality
thinning is feasible. Existing sawlog content in trees dilutes the effect of
quality thinning on the financial return. The results change if the growth rate
is positively correlated with quality, quality thinning becoming feasible in
all commercial diameter classes.",http://arxiv.org/abs/2502.09678v1
Deep Tree Tensor Networks for Image Recognition,2025-02-14T05:41:33Z,"Chang Nie, Junfang Chen, Yajie Chen","Originating in quantum physics, tensor networks (TNs) have been widely
adopted as exponential machines and parameter decomposers for recognition
tasks. Typical TN models, such as Matrix Product States (MPS), have not yet
achieved successful application in natural image processing. When employed,
they primarily serve to compress parameters within off-the-shelf networks, thus
losing their distinctive capability to enhance exponential-order feature
interactions. This paper introduces a novel architecture named
\textit{\textbf{D}eep \textbf{T}ree \textbf{T}ensor \textbf{N}etwork} (DTTN),
which captures $2^L$-order multiplicative interactions across features through
multilinear operations, while essentially unfolding into a \emph{tree}-like TN
topology with the parameter-sharing property. DTTN is stacked with multiple
antisymmetric interacting modules (AIMs), and this design facilitates efficient
implementation. Moreover, we theoretically reveal the equivalency among
quantum-inspired TN models and polynomial and multilinear networks under
certain conditions, and we believe that DTTN can inspire more interpretable
studies in this field. We evaluate the proposed model against a series of
benchmarks and achieve excellent performance compared to its peers and
cutting-edge architectures. Our code will soon be publicly available.",http://arxiv.org/abs/2502.09928v1
"Decision Information Meets Large Language Models: The Future of
  Explainable Operations Research",2025-02-14T08:25:06Z,"Yansen Zhang, Qingcan Kang, Wing Yin Yu, Hailei Gong, Xiaojin Fu, Xiongwei Han, Tao Zhong, Chen Ma","Operations Research (OR) is vital for decision-making in many industries.
While recent OR methods have seen significant improvements in automation and
efficiency through integrating Large Language Models (LLMs), they still
struggle to produce meaningful explanations. This lack of clarity raises
concerns about transparency and trustworthiness in OR applications. To address
these challenges, we propose a comprehensive framework, Explainable Operations
Research (EOR), emphasizing actionable and understandable explanations
accompanying optimization. The core of EOR is the concept of Decision
Information, which emerges from what-if analysis and focuses on evaluating the
impact of complex constraints (or parameters) changes on decision-making.
Specifically, we utilize bipartite graphs to quantify the changes in the OR
model and adopt LLMs to improve the explanation capabilities. Additionally, we
introduce the first industrial benchmark to rigorously evaluate the
effectiveness of explanations and analyses in OR, establishing a new standard
for transparency and clarity in the field.",http://arxiv.org/abs/2502.09994v1
"COMBINEX: A Unified Counterfactual Explainer for Graph Neural Networks
  via Node Feature and Structural Perturbations",2025-02-14T12:17:24Z,"Flavio Giorgi, Fabrizio Silvestri, Gabriele Tolomei","Counterfactual explanations have emerged as a powerful tool to unveil the
opaque decision-making processes of graph neural networks (GNNs). However,
existing techniques primarily focus on edge modifications, often overlooking
the crucial role of node feature perturbations in shaping model predictions. To
address this limitation, we propose COMBINEX, a novel GNN explainer that
generates counterfactual explanations for both node and graph classification
tasks. Unlike prior methods, which treat structural and feature-based changes
independently, COMBINEX optimally balances modifications to edges and node
features by jointly optimizing these perturbations. This unified approach
ensures minimal yet effective changes required to flip a model's prediction,
resulting in realistic and interpretable counterfactuals. Additionally,
COMBINEX seamlessly handles both continuous and discrete node features,
enhancing its versatility across diverse datasets and GNN architectures.
Extensive experiments on real-world datasets and various GNN architectures
demonstrate the effectiveness and robustness of our approach over existing
baselines.",http://arxiv.org/abs/2502.10111v1
Enhancing Age-Related Robustness in Children Speaker Verification,2025-02-14T19:18:02Z,"Vishwas M. Shetty, Jiusi Zheng, Steven M. Lulich, Abeer Alwan","One of the main challenges in children's speaker verification (C-SV) is the
significant change in children's voices as they grow. In this paper, we propose
two approaches to improve age-related robustness in C-SV. We first introduce a
Feature Transform Adapter (FTA) module that integrates local patterns into
higher-level global representations, reducing overfitting to specific local
features and improving the inter-year SV performance of the system. We then
employ Synthetic Audio Augmentation (SAA) to increase data diversity and size,
thereby improving robustness against age-related changes. Since the lack of
longitudinal speech datasets makes it difficult to measure age-related
robustness of C-SV systems, we introduce a longitudinal dataset to assess
inter-year verification robustness of C-SV systems. By integrating both of our
proposed methods, the average equal error rate was reduced by 19.4%, 13.0%, and
6.1% in the one-year, two-year, and three-year gap inter-year evaluation sets,
respectively, compared to the baseline.",http://arxiv.org/abs/2502.10511v1
"Shape Changes of Liquid Crystal Elastomers Swollen by Low Molecular
  Weight Liquid Crystal Drops",2025-02-14T23:19:06Z,"Mahesha Kodithuwakku Arachchige, Rohan Dharmarathna, Paul Fleischer, Antal Jakli","An elastomer swelling actuator deforms by absorbing a fluid, thus generating
mechanical movement. We show that depositing small droplets of low molecular
weight liquid crystal on liquid crystal elastomer (LCE) films leads to shape
changes and bending actuation. It is found that the radially symmetric LCE
director alignments provide radially symmetric hat shapes, while swelling LCEs
with uniform director structure leads to arch shapes. Hybrid samples (different
director alignments on two sides) lead to more complicated bent shapes. All the
observed shapes can be explained by the diffusion that mainly progresses along
the direction normal to the director of the LCE. The swelling induced bending
force is elevating the top of the swollen LCE up to a factor of 30, providing a
powerful and long-lasting actuation. These observations may lead to
applications in various fields, like sealants, soft robotics and biomedical
devices.",http://arxiv.org/abs/2502.10604v1
K-Edit: Language Model Editing with Contextual Knowledge Awareness,2025-02-15T01:35:13Z,"Elan Markowitz, Anil Ramakrishna, Ninareh Mehrabi, Charith Peris, Rahul Gupta, Kai-Wei Chang, Aram Galstyan","As the world changes, we need to be able to update our models and correct
false information without costly retraining. Knowledge-based model editing
enables precise modifications to the weights of large language models in order
to modify the information encoded within. Recent approaches have seen success
in enabling recall of edited information for thousands of edits at once.
However, these approaches fail to produce edits that account for associated
contextual information. We present K-Edit, an effective approach to generating
contextually consistent knowledge edits. By using knowledge graphs, which
maintain contextual consistency when an edge is edited, we are able to generate
additional \textit{contextual edits} that ensure consistency of related
information in the language model. Our experiments demonstrate significant
improvements in multi-hop question answering while maintaining the general
effectiveness and scalability of model edits.",http://arxiv.org/abs/2502.10626v1
"A recurrent vision transformer shows signatures of primate visual
  attention",2025-02-16T02:22:27Z,"Jonathan Morgan, Badr Albanna, James P. Herman","Attention is fundamental to both biological and artificial intelligence, yet
research on animal attention and AI self attention remains largely
disconnected. We propose a Recurrent Vision Transformer (Recurrent ViT) that
integrates self-attention with recurrent memory, allowing both current inputs
and stored information to guide attention allocation. Trained solely via sparse
reward feedback on a spatially cued orientation change detection task, a
paradigm used in primate studies, our model exhibits primate like signatures of
attention, including improved accuracy and faster responses for cued stimuli
that scale with cue validity. Analysis of self-attention maps reveals dynamic
spatial prioritization with reactivation prior to expected changes, and
targeted perturbations produce performance shifts similar to those observed in
primate frontal eye fields and superior colliculus. These findings demonstrate
that incorporating recurrent feedback into self attention can capture key
aspects of primate visual attention.",http://arxiv.org/abs/2502.10955v1
A Survey: Potential Dimensionality Reduction Methods,2025-02-16T08:28:33Z,Yuan-chin Ivan Chang,"Dimensionality reduction is a fundamental technique in machine learning and
data analysis, enabling efficient representation and visualization of
high-dimensional data. This paper explores five key methods: Principal
Component Analysis (PCA), Kernel PCA (KPCA), Sparse Kernel PCA, t-Distributed
Stochastic Neighbor Embedding (t-SNE), and Uniform Manifold Approximation and
Projection (UMAP). PCA provides a linear approach to capturing variance,
whereas KPCA and Sparse KPCA extend this concept to non-linear structures using
kernel functions. Meanwhile, t-SNE and UMAP focus on preserving local
relationships, making them effective for data visualization. Each method is
examined in terms of its mathematical formulation, computational complexity,
strengths, and limitations. The trade-offs between global structure
preservation, computational efficiency, and interpretability are discussed to
guide practitioners in selecting the appropriate technique based on their
application needs.",http://arxiv.org/abs/2502.11036v2
"Comprehensive scaling laws across animals, microorganisms and plants",2025-02-17T03:27:31Z,"Huan Liu, Shashank Priya, Richard D. James","Scaling laws illuminate Nature's fundamental biological principles and guide
bioinspired materials and structural designs. In simple cases they are based on
the fundamental principle that all laws of nature remain unchanged (i.e.,
invariant) under a change of units. A more general framework is a change of
variables for the governing laws that takes all equations, boundary, and
interaction conditions into themselves. We consider an accepted macroscale
system of partial differential equations including coupled fluid dynamics,
nonlinear elasticity, and rigid body mechanics for a complex organism. We show
that there is a set of scaling laws where length, time, density, elastic
modulus, viscosity, and gravitational constant undergo nontrivial scaling
(Table 1). We compare these results to extensive data sets mined from the
literature on beating frequency of flying, swimming, and running animals, speed
of bacteria, insects, fish, mammals and reptiles, leg stiffness of mammals, and
modulus of elasticity of plants. The uniform agreement of the scaling laws with
the dynamics of fauna, flora, and microorganisms supports the dominating role
of coupled nonlinear elasticity and fluid dynamics in evolutionary development.
We conclude with predictions for some prehistoric cases for which observations
are unavailable.",http://arxiv.org/abs/2502.11398v1
"Which Retain Set Matters for LLM Unlearning? A Case Study on Entity
  Unlearning",2025-02-17T04:55:02Z,"Hwan Chang, Hwanhee Lee","Large language models (LLMs) risk retaining unauthorized or sensitive
information from their training data, which raises privacy concerns. LLM
unlearning seeks to mitigate these risks by selectively removing specified data
while maintaining overall model performance. However, most existing work focus
on methods to achieve effective forgetting and does not provide a detailed
analysis of the retain set, the portion of training data that is not targeted
for removal. In this paper, we investigate the effects of unlearning on various
subsets of the retain set through a case study on entity unlearning. We
introduce the Syntactically Similar Neighbor Set, a group of queries that share
similar syntactic structures with the data targeted for removal, and show that
this subset suffers the greatest performance drop during unlearning. Moreover,
when used for regularization, this set not only preserves performance on
syntactically similar queries but also delivers comparable or improved results
across other data subsets. Our results highlight that syntactic similarity is a
critical factor, potentially more so than domain or entity relationships, in
achieving effective and practical LLM unlearning.",http://arxiv.org/abs/2502.11441v1
"A linear-time algorithm computing the resident fitness in interacting
  trajectories",2025-02-17T08:48:29Z,"Katalin Friedl, Viktória Nemkin, András Tóbiás","The notion of a system of interacting trajectories was recently introduced by
Hermann, Gonz\'alez Casanova, Soares dos Santos, T\'obi\'as and Wakolbinger.
Such a system of $[0,1]$-valued piecewise linear trajectories arises as a
scaling limit of the system of logarithmic subpopulation sizes in a certain
population-genetic model (more precisely, a Moran model) with mutation and
selection. By definition, the resident fitness is initially 0 and afterwards it
increases by the ultimate slope of each trajectory that reaches height 1.
  We show that although the interaction of $n$ trajectories may yield
$\Omega(n^2)$ slope changes in total, the resident fitness (at all times) can
be computed algorithmically in $O(n)$ time. Our algorithm is given in terms of
the so-called continued lines representation of the system of interacting
trajectories. In the special case of Poissonian interacting trajectories where
the birth times of the trajectories form a Poisson process and the initial
slopes are random and i.i.d., we show that even the expected number of slope
changes grows only linearly in time.",http://arxiv.org/abs/2502.11561v1
"A Diagnostic to Find and Help Combat Positivity Issues -- with a Focus
  on Continuous Treatments",2025-02-17T14:13:09Z,"Katharina Ring, Michael Schomaker","The positivity assumption is central in the identification of a causal
effect, yet is rarely discussed, especially in conjunction with continuous
treatments or Modified Treatment Policies. One common recommendation for
dealing with a violation is to change the estimand. However, an applied
researcher is faced with two problems: First, how can she tell whether there is
a positivity violation given her estimand of interest, preferably without
having to estimate a model first? Second, if she finds a problem with
positivity, how should she change her estimand in order to arrive at an
estimand which does not face the same issues? We suggest a novel diagnostic
which allows the researcher to answer both questions by providing insights into
how well an estimation for a certain estimand can be made for each observation
using the data at hand. We provide a simulation study on the general behaviour
of different MTPs at different levels of positivity violations and show how the
diagnostic helps understand where bias is to be expected. We illustrate the
application of our proposed diagnostic in a pharmacoepidemiological study based
on data from CHAPAS-3, a trial comparing different treatment regimens for
children living with HIV.",http://arxiv.org/abs/2502.11820v1
"Bandwidth-Adaptive Spatiotemporal Correspondence Identification for
  Collaborative Perception",2025-02-17T18:18:23Z,"Peng Gao, Williard Joshua Jose, Hao Zhang","Correspondence identification (CoID) is an essential capability in
multi-robot collaborative perception, which enables a group of robots to
consistently refer to the same objects within their respective fields of view.
In real-world applications, such as connected autonomous driving, vehicles face
challenges in directly sharing raw observations due to limited communication
bandwidth. In order to address this challenge, we propose a novel approach for
bandwidth-adaptive spatiotemporal CoID in collaborative perception. This
approach allows robots to progressively select partial spatiotemporal
observations and share with others, while adapting to communication constraints
that dynamically change over time. We evaluate our approach across various
scenarios in connected autonomous driving simulations. Experimental results
validate that our approach enables CoID and adapts to dynamic communication
bandwidth changes. In addition, our approach achieves 8%-56% overall
improvements in terms of covisible object retrieval for CoID and data sharing
efficiency, which outperforms previous techniques and achieves the
state-of-the-art performance. More information is available at:
https://gaopeng5.github.io/acoid.",http://arxiv.org/abs/2502.12098v1
Not-So-Optimal Transport Flows for 3D Point Cloud Generation,2025-02-18T02:37:34Z,"Ka-Hei Hui, Chao Liu, Xiaohui Zeng, Chi-Wing Fu, Arash Vahdat","Learning generative models of 3D point clouds is one of the fundamental
problems in 3D generative learning. One of the key properties of point clouds
is their permutation invariance, i.e., changing the order of points in a point
cloud does not change the shape they represent. In this paper, we analyze the
recently proposed equivariant OT flows that learn permutation invariant
generative models for point-based molecular data and we show that these models
scale poorly on large point clouds. Also, we observe learning (equivariant) OT
flows is generally challenging since straightening flow trajectories makes the
learned flow model complex at the beginning of the trajectory. To remedy these,
we propose not-so-optimal transport flow models that obtain an approximate OT
by an offline OT precomputation, enabling an efficient construction of OT pairs
for training. During training, we can additionally construct a hybrid coupling
by combining our approximate OT and independent coupling to make the target
flow models easier to learn. In an extensive empirical study, we show that our
proposed model outperforms prior diffusion- and flow-based approaches on a wide
range of unconditional generation and shape completion on the ShapeNet
benchmark.",http://arxiv.org/abs/2502.12456v1
Ultrafast annealing process of MTJ using hybrid microwave annealing,2025-02-18T11:34:40Z,"Ming-Chun Hsu, Fan-Yun Chiu, Wei-Chi Aeneas Hsu, Chang-Shan Shen, Kun-Ping Huang, Tsun-Hsu Chang","This paper discovers that the magnetic tunnel junction (MTJ) structure is
successfully magnetized with hybrid microwave annealing, confirmed by the
tunneling magnetoresistance (TMR) and Coercivity (Hc) results. Hybrid microwave
annealing can transform CoFeB into a single crystal and form the Fe-O bond at
the interface between CoFeB and MgO without adding an extra magnet. The
annealing time is significantly reduced from the original 120 minutes to just 1
minute, allowing for rapid low-temperature annealing of the MTJ structure. The
TEM results are used to determine the change in the lattice structure of CoFeB
from amorphous to a single crystal, and the EELS result indicates the diffusion
distribution of atoms in the MTJ structure. This hybrid annealing process can
save a significant amount of fabrication time and is an energy-efficient
alternative to the current fabrication process of MRAM.",http://arxiv.org/abs/2502.12772v1
DNA Sensing with Whispering Gallery Mode Microlasers,2025-02-19T12:16:05Z,"Soraya Caixeiro, Robert Dörrenhaus, Anna Popczyk, Marcel Schubert, Stephanie Kath-Schorr, Malte C. Gather","Nucleic acid sensing is crucial for advancing diagnostics, therapeutic
monitoring and molecu-lar biology research, by enabling the precise
identification of DNA and RNA interactions. Here, we present an innovative
sensing platform based on DNA-functionalized whispering gallery mode (WGM)
microlasers. By correlating spectral shifts in laser emission to changes in
refractive index, we demonstrate real-time detection of DNA hybridization and
structural changes. The addition of gold nanoparticles to the DNA strands
significantly enhances sensi-tivity, and labeling exclusively the sensing
strand or a hairpin strand eliminates the need for secondary labeling of the
target strand. We further show that ionic strength influences DNA compactness,
and we introduce a hairpin-based system as a dual-purpose sensor and
con-trolled release mechanism for potential drug delivery. This versatile
WGM-based platform of-fers promise for sequence-specific nucleic acid sensing,
multiplexed detection, and in vivo ap-plications in diagnostics and cellular
research.",http://arxiv.org/abs/2502.13664v1
RobustX: Robust Counterfactual Explanations Made Easy,2025-02-19T14:12:01Z,"Junqi Jiang, Luca Marzari, Aaryan Purohit, Francesco Leofante","The increasing use of Machine Learning (ML) models to aid decision-making in
high-stakes industries demands explainability to facilitate trust.
Counterfactual Explanations (CEs) are ideally suited for this, as they can
offer insights into the predictions of an ML model by illustrating how changes
in its input data may lead to different outcomes. However, for CEs to realise
their explanatory potential, significant challenges remain in ensuring their
robustness under slight changes in the scenario being explained. Despite the
widespread recognition of CEs' robustness as a fundamental requirement, a lack
of standardised tools and benchmarks hinders a comprehensive and effective
comparison of robust CE generation methods. In this paper, we introduce
RobustX, an open-source Python library implementing a collection of CE
generation and evaluation methods, with a focus on the robustness property.
RobustX provides interfaces to several existing methods from the literature,
enabling streamlined access to state-of-the-art techniques. The library is also
easily extensible, allowing fast prototyping of novel robust CE generation and
evaluation methods.",http://arxiv.org/abs/2502.13751v1
"Grid Labeling: Crowdsourcing Task-Specific Importance from
  Visualizations",2025-02-19T17:35:38Z,"Minsuk Chang, Yao Wang, Huichen Will Wang, Andreas Bulling, Cindy Xiong Bearfield","Knowing where people look in visualizations is key to effective design. Yet,
existing research primarily focuses on free-viewing-based saliency models, even
though visual attention is inherently task-dependent. Collecting task-relevant
importance data remains a resource-intensive challenge. To address this, we
introduce Grid Labeling, a novel annotation method for collecting task-specific
importance data to enhance saliency prediction models. Grid Labeling
dynamically segments visualizations into Adaptive Grids, enabling efficient,
low-effort annotation while adapting to visualization structure. We conducted a
human-subject study comparing Grid Labeling with existing annotation methods,
ImportAnnots and BubbleView, across multiple metrics. Results show that Grid
Labeling produces the least noisy data and the highest inter-participant
agreement with fewer participants while requiring less physical (e.g.,
clicks/mouse movements) and cognitive effort.",http://arxiv.org/abs/2502.13902v1
CND-IDS: Continual Novelty Detection for Intrusion Detection Systems,2025-02-19T20:47:22Z,"Sean Fuhrman, Onat Gungor, Tajana Rosing","Intrusion detection systems (IDS) play a crucial role in IoT and network
security by monitoring system data and alerting to suspicious activities.
Machine learning (ML) has emerged as a promising solution for IDS, offering
highly accurate intrusion detection. However, ML-IDS solutions often overlook
two critical aspects needed to build reliable systems: continually changing
data streams and a lack of attack labels. Streaming network traffic and
associated cyber attacks are continually changing, which can degrade the
performance of deployed ML models. Labeling attack data, such as zero-day
attacks, in real-world intrusion scenarios may not be feasible, making the use
of ML solutions that do not rely on attack labels necessary. To address both
these challenges, we propose CND-IDS, a continual novelty detection IDS
framework which consists of (i) a learning-based feature extractor that
continuously updates new feature representations of the system data, and (ii) a
novelty detector that identifies new cyber attacks by leveraging principal
component analysis (PCA) reconstruction. Our results on realistic intrusion
datasets show that CND-IDS achieves up to 6.1x F-score improvement, and up to
6.5x improved forward transfer over the SOTA unsupervised continual learning
algorithm. Our code will be released upon acceptance.",http://arxiv.org/abs/2502.14094v1
"Innovative Financing Solutions: A Transformative Driver for Financial
  Performance of Businesses in Morocco",2025-02-20T09:31:43Z,"Nohayla Badrane, Zineb Bamousse","In a rapidly evolving landscape marked by continuous change and complex
challenges, effective cash management stands as a cornerstone for ensuring
business sustainability and driving performance. To address these pressing
demands, cash managersare increasingly turning to innovative financing
solutions such as venture capital, green finance, crowdfunding, advanced
services from Pan-African banks, and blockchain technology. These cutting-edge
tools are pivotal in bolstering resilience against market volatility,
ecological transitions, and the accelerating pace of technological change. The
present article aims to examine how such innovative financial approaches can
serve as strategic drivers, enabling businesses to transform challenges into
opportunities. The analysis underscores that rethinking cash management through
innovation is a critical pathway toboost the performance of Moroccan companies.
Therefore, embracing these forward-thinking strategies unlocks new avenues for
development empowering them to adapt with agility amidst the uncertainties of a
shifting environment.",http://arxiv.org/abs/2502.14393v1
"Stories that (are) Move(d by) Markets: A Causal Exploration of Market
  Shocks and Semantic Shifts across Different Partisan Groups",2025-02-20T12:26:56Z,"Felix Drinkall, Stefan Zohren, Michael McMahon, Janet B. Pierrehumbert","Macroeconomic fluctuations and the narratives that shape them form a mutually
reinforcing cycle: public discourse can spur behavioural changes leading to
economic shifts, which then result in changes in the stories that propagate. We
show that shifts in semantic embedding space can be causally linked to
financial market shocks -- deviations from the expected market behaviour.
Furthermore, we show how partisanship can influence the predictive power of
text for market fluctuations and shape reactions to those same shocks. We also
provide some evidence that text-based signals are particularly salient during
unexpected events such as COVID-19, highlighting the value of language data as
an exogenous variable in economic forecasting. Our findings underscore the
bidirectional relationship between news outlets and market shocks, offering a
novel empirical approach to studying their effect on each other.",http://arxiv.org/abs/2502.14497v1
"Lattice distortion tuning resistivity invar effect in high entropy
  alloys",2025-02-20T13:20:46Z,"Hao Chen, Yuanji Xu, Lihua Liu, Yue Chen, Jan Wróbel, Daoyong Cong, Fuyang Tian","Materials with an ultra-low temperature coefficient of resistivity are
desired for the temperature and flow sensors in high-precision electronic
measuring systems. In this work, the Kubo-Greenwood formula, implemented in ab
initio molecular dynamics simulations, is employed to predict the
finite-temperature resistivity of multi-component alloys with severe lattice
distortion. We observe a tiny change in resistivity over a wide temperature
range in high-entropy alloys. The electronic resistivity invar effect in B2
Ni$_{25}$Co$_{25}$(HfTiZr)$_{50}$ Elinvar alloys results from a balance between
intrinsic and residual resistivity. This effect is associated with atomic
displacements from ideal lattice sites, which are caused by lattice thermal
vibrations and chemical disorder-induced lattice distortions. It is further
evidenced by a decrease in lattice distortion with temperature and changes in
the electronic density of states.",http://arxiv.org/abs/2502.14542v1
"Environmental Factors Can Have Opposite Biodiversity Influences on the
  Community Temporal Stability In Aquatic Ecosystems",2025-01-06T14:31:21Z,"Zihao Wen, Hang Shan, Hao Wang, Yu Cao, Liang He, Wenjing Ren, Chengjie Yin, Qingchuan Chou, Chaochao Lv, Haojie Su, Tao Tang, Qinghua Cai, Leyi Ni, Wen Xiao, Xiaolin Zhang, Kuanyi Li, Te Cao, Ming-Chih Chiu, Vincent H. Resh, Pablo Urrutia-Cordero","1. An understanding of how biodiversity confers ecosystem stability is
crucial in managing ecosystems under major environmental changes. Multiple
biodiversity drivers can stabilize ecosystem functions over time. However, we
know little about how local environmental conditions can influence these
biodiversity drivers, and consequently how they indirectly shape the ecological
stability of ecosystems.
  2. We hypothesized that environmental factors can have opposite influences
(i.e., not necessarily either positive or negative) on the temporal stability
of communities in different environmental ranges depending on the biodiversity
drivers involved. We tested this novel hypothesis by using data from a
4-year-long field study of submerged macrophyte across a water depth gradient
in 8 heterogeneous bays of Erhai lake (with total sample size of 30,071
quadrats), a large lentic system in China.
  3. Results indicate that a unimodal pattern of stability in temporal biomass
measurements occurred along the water-depth gradient, and that multiple
biodiversity drivers (the asynchrony in species dynamics, and the stability of
dominant species) generally increased the temporal stability of aquatic primary
producers. However, the effect of water depth either increased or decreased the
stability of biomass according to the environmental conditions associated with
sites along the water depth gradient.
  4. Synthesis. These results reveal the influence of local environmental
conditions on the biodiversity drivers of stability may help predict the
functional consequences of biodiversity change across different scenarios of
environmental change.",http://arxiv.org/abs/2501.03044v1
"Towards Probabilistic Inference of Human Motor Intentions by Assistive
  Mobile Robots Controlled via a Brain-Computer Interface",2025-01-09T23:18:38Z,"Xiaoshan Zhou, Carol M. Menassa, Vineet R. Kamat","Assistive mobile robots are a transformative technology that helps persons
with disabilities regain the ability to move freely. Although autonomous
wheelchairs significantly reduce user effort, they still require human input to
allow users to maintain control and adapt to changing environments. Brain
Computer Interface (BCI) stands out as a highly user-friendly option that does
not require physical movement. Current BCI systems can understand whether users
want to accelerate or decelerate, but they implement these changes in discrete
speed steps rather than allowing for smooth, continuous velocity adjustments.
This limitation prevents the systems from mimicking the natural, fluid speed
changes seen in human self-paced motion. The authors aim to address this
limitation by redesigning the perception-action cycle in a BCI controlled
robotic system: improving how the robotic agent interprets the user's motion
intentions (world state) and implementing these actions in a way that better
reflects natural physical properties of motion, such as inertia and damping.
The scope of this paper focuses on the perception aspect. We asked and answered
a normative question ""what computation should the robotic agent carry out to
optimally perceive incomplete or noisy sensory observations?"" Empirical EEG
data were collected, and probabilistic representation that served as world
state distributions were learned and evaluated in a Generative Adversarial
Network framework. The ROS framework was established that connected with a
Gazebo environment containing a digital twin of an indoor space and a virtual
model of a robotic wheelchair. Signal processing and statistical analyses were
implemented to identity the most discriminative features in the
spatial-spectral-temporal dimensions, which are then used to construct the
world model for the robotic agent to interpret user motion intentions as a
Bayesian observer.",http://arxiv.org/abs/2501.05610v1
"Thermal Annealing and Radiation Effects on Structural and Electrical
  Properties of NbN/GaN Superconductor/Semiconductor Junctions",2025-01-14T01:37:21Z,"Stephen Margiotta, Binzhi Liu, Saleh Ahmed Khan, Gabriel Calderon Ortiz, Ahmed Ibreljic, Jinwoo Hwang, A F M Anhar Uddin Bhuiyan","In the rapidly evolving field of quantum computing, niobium nitride (NbN)
superconductors have emerged as integral components due to their unique
structural properties, including a high superconducting transition temperature
(Tc), exceptional electrical conductivity, and compatibility with advanced
device architectures. This study investigates the impact of high-temperature
annealing and high-dose gamma irradiation on the structural and superconducting
properties of NbN films grown on GaN via reactive DC magnetron sputtering. The
as-deposited cubic {\delta}-NbN (111) films exhibited a high-intensity XRD
peak, high Tc of 12.82K, and an atomically flat surface. Annealing at 500 and
950 {\deg}C for varying durations revealed notable structural and surface
changes. High-resolution STEM indicated improved local ordering, while AFM
showed reduced surface roughness after annealing. XPS revealed a gradual
increase in the Nb/N ratio with higher annealing temperatures and durations.
High-resolution XRD and STEM analyses showed lattice constant modifications in
{\delta}-NbN films, attributed to residual stress changes following annealing.
Additionally, XRD phi-scans revealed sixfold symmetry in NbN films due to
rotational domains relative to GaN. While Tc remained stable after annealing at
500 {\deg}C, increasing the annealing temperature to 950 {\deg}C degraded Tc to
~8K and reduced the residual resistivity ratio from 0.85 in as-deposited films
to 0.29 after 30 minutes. The effects of gamma radiation (5 Mrad (Si)) were
also studied, demonstrating minimal changes to crystallinity and
superconducting performance, indicating excellent radiation resilience. These
findings highlight the potential of NbN superconductors for integration into
advanced quantum devices and their suitability for applications in
radiation-intensive environments such as space, satellites, and nuclear power
plants.",http://arxiv.org/abs/2501.07780v1
"Skeleton and Font Generation Network for Zero-shot Chinese Character
  Generation",2025-01-14T12:15:49Z,"Mobai Xue, Jun Du, Zhenrong Zhang, Jiefeng Ma, Qikai Chang, Pengfei Hu, Jianshu Zhang, Yu Hu","Automatic font generation remains a challenging research issue, primarily due
to the vast number of Chinese characters, each with unique and intricate
structures. Our investigation of previous studies reveals inherent bias capable
of causing structural changes in characters. Specifically, when generating a
Chinese character similar to, but different from, those in the training
samples, the bias is prone to either correcting or ignoring these subtle
variations. To address this concern, we propose a novel Skeleton and Font
Generation Network (SFGN) to achieve a more robust Chinese character font
generation. Our approach includes a skeleton builder and font generator. The
skeleton builder synthesizes content features using low-resource text input,
enabling our technique to realize font generation independently of content
image inputs. Unlike previous font generation methods that treat font style as
a global embedding, we introduce a font generator to align content and style
features on the radical level, which is a brand-new perspective for font
generation. Except for common characters, we also conduct experiments on
misspelled characters, a substantial portion of which slightly differs from the
common ones. Our approach visually demonstrates the efficacy of generated
images and outperforms current state-of-the-art font generation methods.
Moreover, we believe that misspelled character generation have significant
pedagogical implications and verify such supposition through experiments. We
used generated misspelled characters as data augmentation in Chinese character
error correction tasks, simulating the scenario where students learn
handwritten Chinese characters with the help of misspelled characters. The
significantly improved performance of error correction tasks demonstrates the
effectiveness of our proposed approach and the value of misspelled character
generation.",http://arxiv.org/abs/2501.08062v1
"Multiplex Nodal Modularity: A novel network metric for the regional
  analysis of amnestic mild cognitive impairment during a working memory
  binding task",2025-01-16T19:27:20Z,"Avalon Campbell-Cousins, Federica Guazzo, Mark Bastin, Mario A. Parra, Javier Escudero","Modularity is a well-established concept for assessing community structures
in various single and multi-layer networks, including those in biological and
social domains. Biological networks, such as the brain, are known to exhibit
group structure at a variety of scales -- local, meso, and global scale.
Modularity, while useful in describing mesoscale brain organization, is limited
as a metric to a global scale describing the overall strength of community
structure. This approach, while valuable, overlooks important localized
variations in community structure at the node level. To address this
limitation, we extended modularity to individual nodes. This novel measure of
nodal modularity ($nQ$) captures both meso and local scale changes in
modularity. We hypothesized that $nQ$ illuminates granular changes in the brain
due to diseases such as Alzheimer's disease (AD), which are known to disrupt
the brain's modular structure. We explored $nQ$ in multiplex networks of a
visual short-term memory binding task in fMRI and DTI data in the early stages
of AD. Observed changes in $nQ$ in fMRI and DTI networks aligned with known
trajectories of AD and were linked to common biomarkers of the disease,
including amyloid-$\beta$ and tau. Additionally, $nQ$ clearly differentiated
MCI from MCI converters showing indications that $nQ$ may be a useful
diagnostic tool for characterizing disease stages. Our findings demonstrate the
utility of $nQ$ as a measure of localized group structure, providing novel
insights into temporal and disease related variability at the node level. Given
the widespread application of modularity as a global measure, $nQ$ represents a
significant advancement, providing a granular measure of network organization
applicable to a wide range of disciplines.",http://arxiv.org/abs/2501.09805v1
"Intervening nuclear obscuration changing the X-ray look of the
  $z\approx6$ QSO CFHQS J164121+375520",2025-01-21T19:00:09Z,"Fabio Vito, William Nielsen Brandt, Andrea Comastri, Roberto Gilli, Franz Bauer, Silvia Belladitta, George Chartas, Kazushi Iwasawa, Giorgio Lanzuisi, Bin Luo, Stefano Marchesi, Marco Mignoli, Federica Ricci, Ohad Shemmer, Cristiana Spingola, Cristian Vignali, Walter Boschin, Felice Cusano, Diego Paris","X-ray observations of the optically selected $z=6.025$ QSO CFHQS
J164121+375520 (hereafter J1641) revealed that its flux dropped by a factor
$\gtrsim7$ from 2018, when it was a bright and soft X-ray source, to 2021. Such
a strong variability amplitude has not been observed before among $z>6$ QSOs,
and the underlying physical mechanism was unclear. We carried out a new X-ray
and rest-frame UV monitoring campaign of J1641 over 2022-2024. We detected
J1641 with Chandra in the 2-7 keV band, while no significant emission is
detected at softer X-ray energies, making J1641 an X-ray changing look QSO at
$z>6$. Comparing with the 2018 epoch, the 0.5-2 keV flux dropped dramatically
by a factor $>20$. We ascribe this behaviour to intervening, and still ongoing,
obscuration by Compton-thick gas intercepting our line of sight between 2018
and 2021. The screening material could be an inner disk or a failed nuclear
wind that increased their thickness. Another possibility is that we have
witnessed an occultation event due to dust-free clouds located at sub-pc/pc
scales, similar to those recently invoked to explain the remarkable X-ray
weakness of AGN discovered by JWST. These interpretations are also consistent
with the lack of strong variations of the QSO rest-frame UV lightcurve over the
same period. Future monitoring of J1641 and the possible discovery of other
X-ray changing look QSOs at $z>6$ will provide us with precious information
about the physics of rapid supermassive black-hole growth at high redshift.",http://arxiv.org/abs/2501.12449v2
Differentially Private Compression and the Sensitivity of LZ77,2025-02-13T18:42:20Z,"Jeremiah Blocki, Seunghoon Lee, Brayan Sebastián Yepes Garcia","We initiate the study of differentially private data-compression schemes
motivated by the insecurity of the popular ""Compress-Then-Encrypt"" framework.
Data compression is a useful tool which exploits redundancy in data to reduce
storage/bandwidth when files are stored or transmitted. However, if the
contents of a file are confidential then the length of a compressed file might
leak confidential information about the content of the file itself. Encrypting
a compressed file does not eliminate this leakage as data encryption schemes
are only designed to hide the content of confidential message instead of the
length of the message. In our proposed Differentially Private
Compress-Then-Encrypt framework, we add a random positive amount of padding to
the compressed file to ensure that any leakage satisfies the rigorous privacy
guarantee of $(\epsilon,\delta)$-differential privacy. The amount of padding
that needs to be added depends on the sensitivity of the compression scheme to
small changes in the input, i.e., to what degree can changing a single
character of the input message impact the length of the compressed file. While
some popular compression schemes are highly sensitive to small changes in the
input, we argue that effective data compression schemes do not necessarily have
high sensitivity. Our primary technical contribution is analyzing the
fine-grained sensitivity of the LZ77 compression scheme (IEEE Trans. Inf.
Theory 1977) which is one of the most common compression schemes used in
practice. We show that the global sensitivity of the LZ77 compression scheme
has the upper bound $\mathcal{O}(W^{2/3}\log n)$ where $W\leq n$ denotes the
size of the sliding window. When $W=n$, we show the lower bound
$\Omega(n^{2/3}\log^{1/3}n)$ for the global sensitivity of the LZ77 compression
scheme which is tight up to a sublogarithmic factor.",http://arxiv.org/abs/2502.09584v1
"On the Impacts of Halo Model Implementations in Sunyaev-Zeldovich
  Cross-Correlation Analyses",2025-02-18T21:19:14Z,"Chad Popik, Nicholas Battaglia, Aleksandra Kusiak, Boris Bolliet, J. Colin Hill","Statistical studies of the circumgalactic medium (CGM) using
Sunyaev-Zeldovich (SZ) observations offer a promising method of studying the
gas properties of galaxies and the astrophysics that govern their evolution.
Forward modeling profiles from theory and simulations allows them to be refined
directly off of data, but there are currently significant differences between
the thermal SZ (tSZ) observations of the CGM and the predicted tSZ signal.
While these discrepancies could be inherent, they could also be the result of
decisions in the forward modeling used to build statistical measures off of
theory. In order to see effects of this, we compare an analysis utilizing halo
occupancy distributions (HODs) implemented in halo models to simulate the
galaxy distribution against a previous studies which weighted their results off
of the CMASS galaxy sample, which contains nearly one million galaxies, mainly
centrals of group sized halos, selected for relatively uniform stellar mass
across redshifts between $0.4<z<0.7$. We review some of the implementation
differences that can account for changes, such as miscentering,
one-halo/two-halo cutoff radii, and mass ranges, all of which will need to be
given the proper attention in future high-signal-to-noise studies. We find that
our more thorough model predicts a signal $\sim 25\%$ stronger than the one
from previous studies on the exact same sample, resulting in a $33\%$ improved
fit for non-dust-contaminated angular scales. Additionally, we find that
modifications that change the satellite fraction even by just a few percents,
such as editing the halo mass range and certain HOD parameters, result in
strong changes in the final signal. Although significant, this discrepancy from
the modeling choices is not large enough to completely account for the existing
disagreements between simulations and measurements.",http://arxiv.org/abs/2502.13291v1
"Thermodynamic properties of an ideal Quark-Gluon plasma under quantum
  gravitational effects",2025-01-02T09:27:25Z,"Djamel Eddine Zenkhri, Abdelhakim Benkrane","In this study, we investigate the thermodynamic properties of an ideal
Quark-Gluon Plasma (QGP) at a vanishing chemical potential, under the influence
of quantum gravitational effects, specifically incorporating the
Linear-Quadratic Generalized Uncertainty Principle (LQGUP). We analyze the
impact of LQGUP on key thermodynamic quantities, including the grand canonical
potential, pressure, energy density, entropy, speed of sound, and the bulk
viscosity's response to changes in the speed of sound. Furthermore, we extend
our analysis to examine the time evolution of the universe's temperature in the
presence of LQGUP effects.",http://arxiv.org/abs/2501.01159v1
"Solving the Porous Medium Equation with the eXtreme Mesh deformation
  approach (X-Mesh)",2025-01-06T15:26:12Z,"Alexandre Chemin, Jonathan Lambrechts, Nicolas Moës, Jean-François Remacle","We introduce a new scheme for solving the non-regularized Porous Medium
Equation. It is mass conserving and uses only positive unknown values. To
address these typically conflicting features, we employ the eXtreme Mesh
deformation approach (X-Mesh), specifically designed for problems involving
sharp interfaces. The method ensures that the interface is always meshed, even
in the face of complex topological changes, without the need for remeshing or
altering the mesh topology. We illustrate the effectiveness of the approach
through various numerical experiments.",http://arxiv.org/abs/2501.03083v1
JT Gravity in de Sitter Space and Its Extensions,2025-01-06T17:15:05Z,"Indranil Dey, Kanhu Kishore Nanda, Akashdeep Roy, Sunil Kumar Sake, Sandip P. Trivedi","We discuss and extend some aspects pertaining to the canonical quantisation
of JT gravity in de Sitter space, including the problem of time and the
construction of a Hilbert space. We then extend this discussion to other two
dimensional models obtained by changing the dilaton potential and show that the
canonical quantisation procedure can be carried out for a large class of such
models. Some discussion leading towards a path integral understanding for
states, other than the Hartle Hawking state, is also included here, along with
comments pertaining to Holography and the entropy of de Sitter space.",http://arxiv.org/abs/2501.03148v1
"Global hypoellipticity for a class of evolution operators in
  time-periodic weighted Sobolev spaces",2025-01-06T22:23:51Z,"Fernando de Ávila Silva, Matteo Bonino, Sandro Coriasco","We study the hypoellipticity properties of a class of time-periodic evolution
operators, with coefficients globally defined on $\mathbb{R}^d$ and growing
polynomially with respect to the space variable. To this aim, we introduce a
class of time-periodic weighted Sobolev spaces, whose elements are
characterised in terms of suitable Fourier expansions, associated with elliptic
operators.",http://arxiv.org/abs/2501.03414v1
Sharp bounds for product and sum throttling numbers,2025-01-07T02:23:42Z,"Ryan Blair, Gabriel Elvin, Veronika Furst, Leslie Hogben, Nandita Sahajpal, Tony W. H. Wong","Throttling in graphs optimizes a sum or product of resources used, such as
the number of vertices in an initial set, and time required, such as the
propagation time, to complete a given task. We introduce a new technique to
establish sharp upper bounds in terms of graph order for sum throttling and
initial cost product throttling for power domination. Furthermore, we establish
sharp bounds on possible changes of the product throttling number, both with
and without initial cost, caused by certain graph operations for standard zero
forcing, positive semidefinite forcing, and power domination.",http://arxiv.org/abs/2501.03472v2
Grid homology for singular links in lens space and a resolution cube,2025-01-07T07:07:59Z,Yonghan Xiao,"In this paper, we define grid homology for singular links in lens spaces and
use it to construct a resolution cube for knot Floer homology of regular links
in lens spaces. The results will first be proven over $\mathbb{Z}/2\mathbb{Z}$
and then extended to be over $\mathbb{Z}$ via a sign assignment. We will also
describe the relationship between our grid homology and classical knot Floer
homology over $\mathbb{Z}$.",http://arxiv.org/abs/2501.03579v2
"Global bifurcation diagrams for coercive third-degree polynomial
  ordinary differential equations with recurrent nonautonomous coefficients",2025-01-07T09:55:59Z,"Cinzia Elia, Roberta Fabbri, Carmen Núñez","Nonautonomous bifurcation theory is a growing branch of mathematics, for the
insight it provides into radical changes in the global dynamics of realistic
models for many real-world phenomena, i.e., into the occurrence of critical
transitions. This paper describes several global bifurcation diagrams for
nonautonomous first order scalar ordinary differential equations generated by
coercive third degree polynomials in the state variable. The conclusions are
applied to a population dynamics model subject to an Allee effect that is weak
in the absence of migration and becomes strong under a migratory phenomenon
whose sense and intensity depend on a threshold in the number of individuals in
the population.",http://arxiv.org/abs/2501.03662v1
"Changing almost perfect nonlinear functions on affine subspaces of small
  codimensions",2025-01-07T16:35:14Z,"Hiroaki Taniguchi, Alexandr Polujan, Alexander Pott, Razi Arshad","In this article, we study algebraic decompositions and secondary
constructions of almost perfect nonlinear (APN) functions. In many cases, we
establish precise criteria which characterize when certain modifications of a
given APN function yield new ones. Furthermore, we show that some of the newly
constructed functions are extended-affine inequivalent to the original ones.",http://arxiv.org/abs/2501.03922v1
"A Quasi-deterministic Channel Model for Underwater Acoustic
  Communication Systems",2025-01-08T02:32:15Z,"Yuxuan Yang, Yilin Ma, Hengtai Chang, Cheng-Xiang Wang","In this paper, a quasi-deterministic (Q-D) model for non-stationary
underwater acoustic (UWA) channels is proposed. This model combines the BELLHOP
deterministic model and geometry-based stochastic model (GBSM), which provides
higher accuracy and flexibility. Different propagation components in shallow
water are classified as D-rays, R-rays and F-rays in the proposed model, where
D-rays are modeled by BELLHOP while both R-rays and F-rays are modeled by GBSM.
Some important channel statistical properties, including time-frequency
correlation function (TF-CF), Doppler power spectrum density (PSD), average
Doppler shift, and RMS Doppler spread are derived and simulated. Finally,
simulation results illustrate the correctness of the proposed model.",http://arxiv.org/abs/2501.04238v1
"Solvent-triggered shape change in gradient-based 4D printed bilayers:
  case study on semi-crystalline polymer networks",2025-01-08T14:47:57Z,"Lorenzo Bonetti, Aron Cobianchi, Daniele Natali, Stefano Pandini, Massimo Messori, Maurizio Toselli, Giulia Scalet","We propose an approach to 4D print solvent-triggered, gradient-based bilayers
made of semi-crystalline crosslinked polymer networks. Out-of-plane bending is
obtained after immersion in the solvent, exploiting the different swelling
degrees of the layers resulting from crosslinking gradients. Lastly, a beam
model of the shape transformation is applied and experimentally validated.",http://arxiv.org/abs/2501.04546v1
"DriVLM: Domain Adaptation of Vision-Language Models in Autonomous
  Driving",2025-01-09T09:02:41Z,"Xuran Zheng, Chang D. Yoo","In recent years, large language models have had a very impressive
performance, which largely contributed to the development and application of
artificial intelligence, and the parameters and performance of the models are
still growing rapidly. In particular, multimodal large language models (MLLM)
can combine multiple modalities such as pictures, videos, sounds, texts, etc.,
and have great potential in various tasks. However, most MLLMs require very
high computational resources, which is a major challenge for most researchers
and developers. In this paper, we explored the utility of small-scale MLLMs and
applied small-scale MLLMs to the field of autonomous driving. We hope that this
will advance the application of MLLMs in real-world scenarios.",http://arxiv.org/abs/2501.05081v1
"Drift-harmonic functions with polynomial growth on asymptotically
  paraboloidal manifolds",2025-01-09T10:17:02Z,Michael B. Law,"We construct and classify all polynomial growth solutions to certain
drift-harmonic equations on complete manifolds with paraboloidal asymptotics.
These encompass the natural drift-harmonic equations on certain steady gradient
Ricci solitons. Specifically, we show that all drift-harmonic functions with
polynomial growth asymptotically separate variables, and compute the dimensions
of spaces of drift-harmonic functions with a given polynomial growth rate. The
proof uses an inductive argument that alternates between constructing and
asymptotically controlling drift-harmonic functions.",http://arxiv.org/abs/2501.05119v2
Fortuity in the D1-D5 system,2025-01-09T18:59:27Z,"Chi-Ming Chang, Ying-Hsuan Lin, Haoyu Zhang","We reformulate the lifting problem in the D1-D5 CFT as a supercharge
cohomology problem, and enumerate BPS states according to the
fortuitous/monotone classification. Focusing on the deformed $T^4$ symmetric
orbifold theory, cohomology classes in the $N=2$ theory are explicitly
constructed and matched with the exact BPS partition function. For general $N$,
an infinite set of monotone cohomology classes are characterized and
conjectured to be exhaustive. We further describe how to assemble BPS states at
smaller $N$ into BPS states at larger $N$, and interpret their holographic
duals as black hole bound states and massive stringy excitations on smooth
horizonless (e.g. Lunin-Mathur) geometries.",http://arxiv.org/abs/2501.05448v1
Smoothing surfaces on fourfolds,2025-01-10T00:12:20Z,"Scott Nollet, A. P. Rao","If $\mathcal E, \mathcal F$ are vector bundles of ranks $r-1,r$ on a smooth
fourfold $X$ and $\mathcal{Hom}(\mathcal E,\mathcal F)$ is globally generated,
it is well known that the general map $\phi: \mathcal E \to \mathcal F$ is
injective and drops rank along a smooth surface. Chang improved on this with a
filtered Bertini theorem. We strengthen these results by proving variants in
which (a) $\mathcal F$ is not a vector bundle and (b) $\mathcal{Hom}(\mathcal
E,\mathcal F)$ is not globally generated. As an application, we give examples
of even linkage classes of surfaces on $\mathbb P^4$ in which all integral
surfaces are smoothable, including the linkage classes associated with the
Horrocks-Mumford surface.",http://arxiv.org/abs/2501.05630v1
"The Waters We Swim In: Replicability and the Evolution of Scientific
  Norms",2025-01-10T08:44:46Z,"Hope Bretscher, Núria Muñoz Garganté","In recent years, a series of high-profile retractions and fraud cases have
arisen in physics, sparking a conversation about research integrity and
replicability. Here, we discuss how the practice of science is shaped by the
social and political context in which it operates. Reflection on our norms and
values could provide a route to create community-driven safeguards that respond
to the changing demands in which our research occurs. We propose that
collaborations between physicists, philosophers, social scientists, and
historians of science could facilitate these reflections and provide new ideas
for social science and humanities colleagues.",http://arxiv.org/abs/2501.05788v1
Stieltjes differential systems with non monotonic derivators,2025-01-11T19:19:49Z,"Marlène Frigon, F. Adrián F. Tojo","In this work we study Stieltjes differential systems of which the derivators
are allowed to change sign. This leads to the definition of the notion of
\emph{function of controlled variation}, a characterization of precompact sets
of $g$-continuous functions, and an explicit expression of $g$-exponential
maps. Finally, we prove a Peano-type existence result and apply it to a model
of fluid stratification on buoyant miscible jets and plumes.",http://arxiv.org/abs/2501.06624v1
"Necessary and sufficient condition for constructing a single qudit
  insertion/deletion code and its decoding algorithm",2025-01-13T02:59:18Z,Taro Shibayama,"This paper shows that Knill-Laflamme condition, known as a necessary and
sufficient condition for quantum error-correction, can be applied to quantum
errors where the number of particles changes before and after the error. This
fact shows that correctabilities of single deletion errors and single insertion
errors are equivalent. By applying Knill-Laflamme condition, we generalize the
previously known correction conditions for single insertion and deletion errors
to necessary and sufficient level. By giving an example that satisfies this
condition, we construct a new single qudit insertion/deletion code and explain
its decoding algorithm.",http://arxiv.org/abs/2501.07027v1
"Limiting absorption principle of Helmholtz equation with sign changing
  coefficients under periodic structure",2025-01-13T11:29:53Z,"Wenjing Zhang, Yu Chen, Yixian Gao","Negative refractive index materials have garnered widespread attention due to
their anomalous electromagnetic properties. In this paper, we utilize
complementing boundary conditions to conduct a priori estimates for Cauchy
problems and derive the limiting absorption principle. Consequently, we
establish the well-posedness of the transmission problem involving conventional
materials and negative refractive index materials within a simulated
two-dimensional periodic structure.",http://arxiv.org/abs/2501.07229v1
Anonymous Attention and Abuse,2025-01-13T15:27:35Z,"Florian Ederer, Paul Goldsmith-Pinkham, Kyle Jensen","We analyze the content of the anonymous online discussion forum Economics Job
Market Rumors (EJMR) and document its evolving interactions with external
information sources. We focus on three key aspects: the prevalence and impact
of links to external domains, the surge in discussions driven by Twitter posts
since 2018, and the categorization of individuals whose tweets are most
frequently discussed on EJMR. Using data on linked domains, we show how these
trends reflect broader changes in the economics profession's digital footprint.
Our analysis sheds light on EJMR's informational role but also raises questions
about inclusivity and professional ethics in economics.",http://arxiv.org/abs/2501.07410v1
"Paper Fortune Tellers in the combinatorial dynamics of some generalized
  McMullen maps with both critical orbits bounded",2025-01-13T18:30:02Z,"Suzanne Boyd, Kelsey Brouwer","For the family of complex rational functions known as ""Generalized McMullen
maps"", F(z) = z^n + a/z^n+b, for complex parameters a and b, with a nonzero,
and any integer n at least 3 fixed, we reveal, and provide a combinatorial
model for, some new dynamical behavior. In particular, we describe a large
class of maps whose Julia sets contain both infinitely many homeomorphic copies
of quadratic Julia sets and infinitely many subsets homeomorphic to a set which
is obtained by starting with a quadratic Julia set, then changing a finite
number of pairs of external ray landing point identifications, following an
algorithm we will describe.",http://arxiv.org/abs/2501.07545v1
A mathematical model for the progression of dental caries,2025-01-13T16:12:07Z,"Rene Fabregas, Jacob Rubinstein","A model for the progression of dental caries is derived. The analysis starts
at the microscopic reaction and diffusion process. The local equations are
averaged to derive a set of macroscopic equations. The global system includes
features such as anisotropic diffusion and local changes in the geometry due to
the enamel melting. The equations are then solved numerically. The simulations
highlight the effect of anisotropy. In addition we draw conclusions on the
progression rate of caries, and discuss them in light of a number of
experiments.",http://arxiv.org/abs/2501.07619v1
Polyakov-Alvarez Formula for Curvilinear Polygonal Domains with Slits,2025-01-13T20:41:59Z,Ellen Krusell,"We consider the $\zeta$-regularized determinant of the Friedrichs extension
of the Dirichlet Laplace-Beltrami operator on curvilinear polygonal domains
with corners of arbitrary positive angles. In particular, this includes slit
domains. We obtain a short time asymptotic expansion of the heat trace using a
classical patchwork method. This allows us to define the $\zeta$-regularized
determinant of the Laplacian and prove a comparison formula of Polyakov-Alvarez
type for a smooth and conformal change of metric.",http://arxiv.org/abs/2501.07682v1
Counterexamples to a conjecture of Adams,2025-01-14T02:40:34Z,Feifei Fan,"For any odd prime $p$ and any integer $n>0$ with $p^2|n$, we show that the
mod $p$ cohomology ring of the classifying space of the projective unitary
group $PU(n)$ is not completely detected by elementary abelian $p$-subgroups,
providing counterexamples to a conjecture due to J. F. Adams.",http://arxiv.org/abs/2501.07797v4
The existence of pyramidal Steiner triple systems over abelian groups,2025-01-14T08:30:52Z,"Yanxun Chang, Tommaso Traetta, Junling Zhou","A Steiner triple system STS$(v)$ is called $f$-pyramidal if it has an
automorphism group fixing $f$ points and acting sharply transitively on the
remaining ones. In this paper, we focus on the STSs that are $f$-pyramidal over
some abelian group. Their existence has been settled only for the smallest
admissible values of $f$, that is, $f=0,1,3$.
  In this paper, we complete this result and determine, for every $f>3$, the
spectrum of values $(f,v)$ for which there is an $f$-pyramidal STS$(v)$ over an
abelian group. This result is obtained by constructing difference families
relative to a suitable partial spread.",http://arxiv.org/abs/2501.07928v1
Pulse compression by photoexcitation-induced dynamics of Bragg mirrors,2025-01-15T08:00:14Z,"Zukhriddin Ruziev, Kazuhiro Yabana, Anton Husakou","We propose dynamical Bragg mirrors as a means to compress intense short
optical pulses. We show that strong-field photoexcitation of carriers changes
the refractive index of the layers and leads to motion of the resonance-defined
boundary of the Bragg mirror. In a reflection geometry, this
counter-propagating motion leads to significant compression of the incident
pulse. We utilize a finite-difference time-domain numerical model to predict up
to a 6-fold pulse compression in the few-femtosecond regime. Modification of
the refractive index and properties of the compressed pulse as a function of
the incident pulse parameters are investigated.",http://arxiv.org/abs/2501.08637v1
The Berry-Esseen Bound for High-dimensional Self-normalized Sums,2025-01-15T17:52:38Z,"Woonyoung Chang, Kenta Takatsu, Konrad Urban, Arun Kumar Kuchibhotla","This manuscript studies the Gaussian approximation of the coordinate-wise
maximum of self-normalized statistics in high-dimensional settings. We derive
an explicit Berry-Esseen bound under weak assumptions on the absolute moments.
When the third absolute moment is finite, our bound scales as
$\log^{5/4}(d)/n^{1/8}$ where $n$ is the sample size and $d$ is the dimension.
Hence, our bound tends to zero as long as $\log(d)=o(n^{1/10})$. Our results on
self-normalized statistics represent substantial advancements, as such a bound
has not been previously available in the high-dimensional central limit theorem
(CLT) literature.",http://arxiv.org/abs/2501.08979v1
"Surface transport and barrier effects in metal halide perovskites
  explored by bias polarity switching",2025-01-15T10:24:38Z,"Marian Betusiak, Roman Grill, Eduard Belas, Petr Praus, Mykola Brynza, Mahshid Ahmadi, Jonghee Yang, Artem Musiienko","Surface transport and barrier effects in metal halide perovskites explored by
bias polarity switching. By bias polarity switching we experimentally proved
that free and trapped holes accumulate beneath the contact barrier. Further
investigation proved that the duration of bias pulse changes surface properties
that surprisingly affect only free holes. Temperature dependence of accumulated
hole dissipation revealed two activation energies 150meV the height of the
barrier and 770meV corresponding to a yet unknown process.",http://arxiv.org/abs/2501.09047v1
The sleeping bacterium: shedding light on the resuscitation mechanism,2025-01-16T08:25:02Z,"Eleonora Alfinito, Matteo Beccaria","The revival mechanism in dormant bacteria is a puzzling and open issue. We
propose a model of information diffusion on a regular grid where agents
represent bacteria and their mutual interactions implement quorum sensing.
Agents may have different metabolic characteristics corresponding to multiple
phenotypes. The intra/inter phenotype cooperation is analyzed under different
metabolic and productivity conditions. We study the interactions between
rapidly reproducing active bacteria and non-reproducing quiescent bacteria. We
highlight the conditions under which the quiescent bacteria may revive. The
occurrence of revival is generally related to a change in environmental
conditions. Our results support this picture showing that revival can be
mediated by the presence of different catalyst bacteria that produce the
necessary resources .",http://arxiv.org/abs/2501.09366v1
Sensorimotor Control Strategies for Tactile Robotics,2025-01-16T11:10:10Z,"Enrico Donato, Matteo Lo Preti, Lucia Beccai, Egidio Falotico","How are robots becoming smarter at interacting with their surroundings?
Recent advances have reshaped how robots use tactile sensing to perceive and
engage with the world. Tactile sensing is a game-changer, allowing robots to
embed sensorimotor control strategies to interact with complex environments and
skillfully handle heterogeneous objects. Such control frameworks plan
contact-driven motions while staying responsive to sudden changes. We review
the latest methods for building perception and control systems in tactile
robotics while offering practical guidelines for their design and
implementation. We also address key challenges to shape the future of
intelligent robots.",http://arxiv.org/abs/2501.09468v2
"Infrared Behavior of Induced Gravitational Waves from Isocurvature
  Perturbations",2025-01-17T03:38:51Z,"Chang Han, Zu-Cheng Chen, Hongwei Yu, Puxun Wu","Induced gravitational waves provide a powerful probe of primordial
perturbations in the early universe through their distinctive spectral
properties. We analyze the spectral energy density $\Omega_{\text{GW}}$ of
gravitational waves induced by isocurvature scalar perturbations. In the
infrared regime, we find that the spectral slope $n_{\text{GW}} \equiv \text{d}
\ln\Omega_\mathrm{GW}/\text{d}\ln k$ takes the log-dependent form $3-4/ \ln
(\tilde{k}_*^2 / 6k^2)$, where $\tilde{k}_*$ represents the effective peak
scale of the primordial scalar power spectrum. This characteristic behavior
differs markedly from that of adiabatic-induced gravitational waves,
establishing a robust observational discriminant between isocurvature and
adiabatic primordial perturbation modes.",http://arxiv.org/abs/2501.09939v1
Strong Consistency of Sparse K-means Clustering,2025-01-17T06:50:24Z,"Jeungju Kim, Johan Lim","In this paper, we prove the strong consistency of the sparse K-means method
proposed by Witten and Tibshirani (2010). We prove the consistency in both risk
and clustering for the Euclidean distance. We discuss the characterization of
the limit of the clustering under some special cases. For the general distance,
we prove the consistency in risk. Our result naturally extends to other models
with the same objective function but different constraints such as l0 or l1
penalty in Chang et al. (2018).",http://arxiv.org/abs/2501.09983v1
BBPOS: BERT-based Part-of-Speech Tagging for Uzbek,2025-01-17T10:50:22Z,"Latofat Bobojonova, Arofat Akhundjanova, Phil Ostheimer, Sophie Fellenz","This paper advances NLP research for the low-resource Uzbek language by
evaluating two previously untested monolingual Uzbek BERT models on the
part-of-speech (POS) tagging task and introducing the first publicly available
UPOS-tagged benchmark dataset for Uzbek. Our fine-tuned models achieve 91%
average accuracy, outperforming the baseline multi-lingual BERT as well as the
rule-based tagger. Notably, these models capture intermediate POS changes
through affixes and demonstrate context sensitivity, unlike existing rule-based
taggers.",http://arxiv.org/abs/2501.10107v1
Growing Spines Ad Infinitum,2025-01-17T20:08:15Z,"Blaise Boissonneau, Anna De Mase, Franziska Jahnke, Pierre Touchard","We show that every non-trivial ordered abelian group $G$ is augmentable by
infinite elements, i.e., we have $G\preccurlyeq H\oplus G$ for some non-trivial
ordered abelian group $H$. As an application, we show that when $k$ is a field
of characteristic 0, then $k$ is not $t$-henselian if and only if all henselian
valuations with residue field $k$ are ($\emptyset$-)definable.",http://arxiv.org/abs/2501.10531v2
Notes on splitting fields,2025-01-17T20:59:00Z,Cihan Bahran,"These notes include introductory material on the notion of splitting fields
for modules over a k-algebra where k is a field.",http://arxiv.org/abs/2501.10554v1
A Generative Security Application Engineering Curriculum,2025-01-18T23:17:34Z,"Wu-chang Feng, David Baker-Robinson","Generative AI and large language models (LLMs) are transforming security by
automating many tasks being performed manually. With such automation changing
the practice of security as we know it, it is imperative that we prepare future
students for the technology landscape they will ultimately face. Towards this
end, we describe an initial curriculum and course that attempts to show
students how to apply generative AI in order to solve problems in security. By
refocusing security education and training on aspects uniquely suited for
humans and showing students how to leverage automation for the rest, we believe
we can better align security education practices with generative AI as it
evolves.",http://arxiv.org/abs/2501.10900v1
Leptogenesis in a domain-wall-free Majoron+Triplet model,2025-01-20T15:09:58Z,Tim Brune,"We discuss leptogenesis in a majoron model extended by a right-handed
$SU(2)_L$ triplet fermion that prevents the appearance of cosmological domain
walls due to a change of the $[SU(2)_L]^2 \times U(1)_L$ anomaly factor. We
study several different parameter assignments and find that the interactions of
neutrinos with the new particles in the majoron+triplet model can significantly
alter the way leptogenesis proceeds. We show that for large parts of the
considered parameter space, it is essential to solve the set of coupled
Boltzmann equations for the evolution of the neutrinos and the additional
particles rather than solving the Boltzmann equations for the neutrino
evolution only.",http://arxiv.org/abs/2501.11529v1
"Detecting Free Products in the Mapping Class Group of Punctured Disks
  via Dynnikov Coordinates",2025-01-21T06:23:51Z,"Elif Medetoğulları, Elif Dalyan, S. Öykü Yurttaş","We prove that Dehn twists about opposite curves that define a complete
partition on an $n$-punctured disk $D_n$ generate either a free group or a free
product of abelian groups. Additionally, we introduce an algorithm based on
Dynnikov coordinates to determine whether a given collection of opposite curves
forms a complete partition. This algorithm not only verifies completeness but
also reveals the exact structure of the free products generated by these Dehn
twists, relying solely on the Dynnikov coordinates of the curves as input.",http://arxiv.org/abs/2501.11912v3
"Nocturnal eye inspired liquid to gas phase change soft actuator with
  Laser-Induced-Graphene: enhanced environmental light harvesting and
  photothermal conversion",2025-01-21T07:08:53Z,"Maina Sogabe, Youhyun Kim, Kenji Kawashima","Robotic systems' mobility is constrained by power sources and wiring. While
pneumatic actuators remain tethered to air supplies, we developed a new
actuator utilizing light energy. Inspired by nocturnal animals' eyes, we
designed a bilayer soft actuator incorporating Laser-Induced Graphene (LIG) on
the inner surface of a silicone layer. This design maintains silicone's
transparency and flexibility while achieving 54% faster response time compared
to conventional actuators through enhanced photothermal conversion.",http://arxiv.org/abs/2501.11930v1
"On Generalization and Distributional Update for Mimicking Observations
  with Adequate Exploration",2025-01-22T10:37:51Z,"Yirui Zhou, Xiaowei Liu, Xiaofeng Zhang, Yangchun Zhang","This paper tackles the efficiency and stability issues in learning from
observations (LfO). We commence by investigating how reward functions and
policies generalize in LfO. Subsequently, the built-in reinforcement learning
(RL) approach in generative adversarial imitation from observation (GAIfO) is
replaced with distributional soft actor-critic (DSAC). This change results in a
novel algorithm called Mimicking Observations through Distributional Update
Learning with adequate Exploration (MODULE), which combines soft actor-critic's
superior efficiency with distributional RL's robust stability.",http://arxiv.org/abs/2501.12785v1
An unusual BPS equation,2025-01-22T19:58:58Z,"Constantin Bachas, Lorenzo Bianchi, Zhongwu Chen","We prove a conjectured relation between the energy-momentum and the
displacement norm of superconformal defects. The proof completes earlier
results, and shows that supersymmetry identifies two natural notions of brane
tension in Anti-de Sitter gravity. As a byproduct we show that a modification
of the energy-momentum tensor that removes the stress of static superconformal
defects, ensures also that the radiation these emit obeys the Null Energy
Condition. This sheds new light on the radiation-reaction problem for moving
charges.",http://arxiv.org/abs/2501.13197v2
"Modified Dai-Liao Spectral Conjugate Gradient Method with Application to
  Signal Processing",2025-01-25T18:50:26Z,"D. R. Sahu, Shikher Sharma, Pankaj Gautam","In this article, we present a modified variant of the Dai-Liao spectral
conjugate gradient method, developed through an analysis of eigenvalues and
inspired by a modified secant condition. We show that the proposed method is
globally convergent for general nonlinear functions under standard assumptions.
By incorporating the new secant condition and a quasi-Newton direction, we
introduce updated spectral parameters. These changes ensure that the resulting
search direction satisfies the sufficient descent property without relying on
any line search. Numerical experiments show that the proposed algorithm
performs better than several existing methods in terms of convergence speed and
computational efficiency. Its effectiveness is further demonstrated through an
application in signal processing.",http://arxiv.org/abs/2501.15300v1
"Ma-Qiu index, presentation distance, and local moves in knot theory",2025-01-27T06:58:47Z,Tetsuya Ito,"The Ma-Qiu index of a group is the minimum number of normal generators of the
commutator subgroup. We show that the Ma-Qiu index gives a lower bound of the
presentation distance of two groups, the minimum number of relator replacements
to change one group to the other. Since many local moves in knot theory induce
relator replacements in knot groups, this shows that the Ma-Qiu index of knot
groups gives a lower bound of the Gordian distance based on various local
moves. In particular, this gives a unified and simple proof of the Nakanishi
index bounds of various unknotting numbers, including virtual or welded knot
cases.",http://arxiv.org/abs/2501.15821v1
"Equivalent Conditions for Domination of
  $\mathrm{M}(2,\mathbb{C})$-sequences",2025-01-27T10:36:28Z,"Chang Sun, Zhenghe Zhang","It is well known that a $\mathrm{SL}(2,\mathbb{C})$-sequence is uniformly
hyperbolic if and only it satisfies a uniform exponential growth condition.
Similarly, for $\mathrm{GL}(2,\mathbb{C})$-sequences whose determinants are
uniformly bounded away from zero, it has dominated splitting if and only if it
satisfies a uniform exponential gap condition between the two singular values.
Inspired by [QTZ], we provide a similar equivalent description in terms of
singular values for $\mathrm{M}(2,\mathbb{C})$-sequences that admit dominated
splitting. We also prove a version of the Avalanche Principle for such
sequences.",http://arxiv.org/abs/2501.15940v1
Poisson kernels on the half-plane are bell-shaped,2025-01-27T14:13:28Z,Mateusz Kwaśnicki,"Consider a second-order elliptic operator $L$ in the half-plane $\mathbb R
\times (0, \infty)$ with coefficients depending only on the second coordinate.
The Poisson kernel for $L$ is used in the representation of positive
$L$-harmonic functions, that is, solutions of $L u = 0$. In probabilistic
terms, the Poisson kernel is the density function of the distribution of the
diffusion in $\mathbb R \times (0, \infty)$ with generator $L$ at the hitting
time of the boundary. We prove that the Poisson kernel for $L$ is bell-shaped:
its $n$th derivative changes sign $n$ times. In particular, it is unimodal and
it has two inflection points (it is concave, then convex, then concave again).",http://arxiv.org/abs/2501.16068v1
"Multiplicatively irreducibility of small perturbations of shifted $k$-th
  powers",2025-01-28T01:37:30Z,Chi Hoi Yip,"Motivated by a conjecture of Erd\H{o}s on the additively irreducibility of
small perturbations of the set of squares, recently Hajdu and S\'{a}rk\""{o}zy
studied a multiplicative analogue of the conjecture for shifted $k$-th powers.
They conjectured that for each $k\geq 2$, if one changes $o(X^{1/k})$ elements
of $M_k'=\{x^k+1: x \in \mathbb{N}\}$ up to $X$, then the resulting set cannot
be written as a product set $AB$ nontrivially. In this paper, we confirm a more
general version of their conjecture for $k\geq 3$.",http://arxiv.org/abs/2501.16620v1
"Seasonal Influenza Vaccination Hesitancy and Digital Literacy: Evidence
  from the European countries",2025-01-28T15:00:59Z,"Martina Celidoni, Nita Handastya, Guglielmo Weber, Nancy Zambon","This study documents the relationship between computer skills/digital
literacy and influenza vaccination take-up among older adults in Europe during
and after the COVID-19 pandemic. Using data from the Survey of Health, Aging
and Retirement in Europe, we find a positive partial association between
influenza vaccination take-up and two indicators of computer skills/digital
literacy, self-assessed pre-pandemic computer skills and having used a computer
at work in any pre-pandemic job. We do not estimate significant behavioural
changes for individuals with better computer skills that may have been driven
by spillover effects from the pandemic experience.",http://arxiv.org/abs/2501.17005v1
"Demand Analysis under Price Rigidity and Endogenous Assortment: An
  Application to China's Tobacco Industry",2025-01-28T19:16:45Z,"Hui Liu, Yao Luo","We observe nominal price rigidity in tobacco markets across China. The
monopolistic seller responds by adjusting product assortments, which remain
unobserved by the analyst. We develop and estimate a logit demand model that
incorporates assortment discrimination and nominal price rigidity. We find that
consumers are significantly more responsive to price changes than conventional
models predict. Simulated tax increases reveal that neglecting the role of
endogenous assortments results in underestimations of the decline in
higher-tier product sales, incorrect directional predictions of lower-tier
product sales, and overestimation of tax revenue by more than 50%. Finally, we
extend our methodology to settings with competition and random coefficient
models.",http://arxiv.org/abs/2501.17251v1
"Non-commutative hourglasses I: On classification of the Q-Fano 3-folds
  Gorenstein index 2 via Derived category",2025-01-29T07:20:11Z,Xingbang Hao,"In previous work, Takagi used the methods of solving the Sarkisov links by
calculating the corresponding Diophantine equations and the construction of key
varieties to give all possible classifications and some implementations of a
class $\mathbb{Q}$-Fano 3-fold with Fano index 1/2 and at worst $(1, 1, 1)/2$
or QODP singularities. Firstly, we use a method different from Kawamata's work
to give the derived category formulas for general weighted blow-up and Kawamata
weighted blow-up. On this basis, we study the changing behavior of the derived
category of Takagi's varieties under Sarkisov links. Finally, by studying
non-commutative projections, we give exceptional collections on the derived
category of Takagi's varieties and their corresponding geometric meanings.",http://arxiv.org/abs/2501.17454v1
Adding MFMA Support to gem5,2025-01-30T03:32:14Z,"Marco Kurzynski, Matthew D. Sinclair","In this work we have enhanced gem5's GPU model support to add Matrix Core
Engines (MCEs). Specifically, on the AMD MI200 and MI300 GPUs that gem5
supports, these MCEs perform Matrix Fused Multiply Add (MFMA) instructions for
a variety of precisions. By adding this support, our changes enable running
state-of-the-art ML workloads in gem5, as well as examining how MCE
optimizations impact the behavior of future systems.",http://arxiv.org/abs/2501.18113v2
"Network Weighted Functional Regression: a method for modeling
  dependencies between functional data in a network",2025-01-30T09:23:31Z,"Andrea Diana, Elvira Romano, Antonio Irpino","This paper focuses on predicting continuous signals in a sensor lab network,
particularly studying microclimate changes. We propose two novel concepts:
Network Functional Data (NFD), which represents time series signals as
functions on network nodes, and the Network Weighted Functional Regression
(NWFR) model, which analyzes relationships between functional responses and
predictors in a weighted network. Additionally, we introduce a functional
conformal method to provide prediction bands with guaranteed coverage
probabilities, independent of data distribution.
  Our statistical analysis on simulated and real-world data demonstrates that
incorporating network structure enhances regression accuracy and improves the
reliability of conformal prediction regions. These findings advance the
analysis of complex network-structured data, offering a more precise and
efficient approach.",http://arxiv.org/abs/2501.18221v1
STAN: Smooth Transition Autoregressive Networks,2025-01-30T19:01:01Z,"Hugo Inzirillo, Remi Genet","Traditional Smooth Transition Autoregressive (STAR) models offer an effective
way to model these dynamics through smooth regime changes based on specific
transition variables. In this paper, we propose a novel approach by drawing an
analogy between STAR models and a multilayer neural network architecture. Our
proposed neural network architecture mimics the STAR framework, employing
multiple layers to simulate the smooth transition between regimes and capturing
complex, nonlinear relationships. The network's hidden layers and activation
functions are structured to replicate the gradual switching behavior typical of
STAR models, allowing for a more flexible and scalable approach to
regime-dependent modeling. This research suggests that neural networks can
provide a powerful alternative to STAR models, with the potential to enhance
predictive accuracy in economic and financial forecasting.",http://arxiv.org/abs/2501.18699v1
"Rank stability in quadratic extensions and Hilbert's tenth problem for
  the ring of integers of a number field",2025-01-30T21:56:25Z,"Levent Alpöge, Manjul Bhargava, Wei Ho, Ari Shnidman","We show that for any quadratic extension of number fields $K/F$, there exists
an abelian variety $A/F$ of positive rank whose rank does not grow upon base
change to $K$. This result implies that Hilbert's tenth problem over the ring
of integers of any number field has a negative solution. That is, for the ring
$\mathcal{O}_K$ of integers of any number field $K$, there does not exist an
algorithm that answers the question of whether a polynomial equation in several
variables over $\mathcal{O}_K$ has solutions in $\mathcal{O}_K$.",http://arxiv.org/abs/2501.18774v1
"Efficient preparation of entangled states in cavity QED with Grover's
  algorithm",2025-01-31T04:31:37Z,"Omar Nagib, M. Saffman, K. Mølmer","We propose to employ the amplification mechanism of Grover's search algorithm
to efficiently prepare entangled states of an ensemble of qubits. The
conditional change of sign employed in the algorithm can be implemented by the
phase shift of photons scattered on an optical cavity hosting an atomic
ensemble. We show that collective Dicke states, GHZ states, and Schr\""odinger
cat superpositions of $N$ atoms may be prepared deterministically by few ($\sim
N^{1/4}$) photon scattering events without individual addressing of the atoms.",http://arxiv.org/abs/2501.18881v2
"CAT Pruning: Cluster-Aware Token Pruning For Text-to-Image Diffusion
  Models",2025-02-01T13:46:02Z,"Xinle Cheng, Zhuoming Chen, Zhihao Jia","Diffusion models have revolutionized generative tasks, especially in the
domain of text-to-image synthesis; however, their iterative denoising process
demands substantial computational resources. In this paper, we present a novel
acceleration strategy that integrates token-level pruning with caching
techniques to tackle this computational challenge. By employing noise relative
magnitude, we identify significant token changes across denoising iterations.
Additionally, we enhance token selection by incorporating spatial clustering
and ensuring distributional balance. Our experiments demonstrate reveal a
50%-60% reduction in computational costs while preserving the performance of
the model, thereby markedly increasing the efficiency of diffusion models. The
code is available at https://github.com/ada-cheng/CAT-Pruning",http://arxiv.org/abs/2502.00433v1
Evolution of Society Caused by Collective and Individual Decisions,2025-02-01T15:56:19Z,Pavel Chebotarev,"Under the assumptions of the ViSE model, we investigate the welfare and
performance of a society consisting of one group (a ``party'') and
individualists. In the case of Gaussian proposal generators, the expected
capital gains can be expressed in standard functions. The relative
effectiveness of individualistic and group strategies of agents, as well as the
benefits of the entire society, depend on the level of cooperation, the voting
threshold, and the favorability of the environment. We focus on the evolution
of society in neutral environments caused by changing its structure and the
voting rule in the interests of agents.",http://arxiv.org/abs/2502.00471v1
"Transfer Learning in Physics-Informed Neural Networks: Full Fine-Tuning,
  Lightweight Fine-Tuning, and Low-Rank Adaptation",2025-02-02T12:40:22Z,"Yizheng Wang, Jinshuai Bai, Mohammad Sadegh Eshaghi, Cosmin Anitescu, Xiaoying Zhuang, Timon Rabczuk, Yinghua Liu","AI for PDEs has garnered significant attention, particularly Physics-Informed
Neural Networks (PINNs). However, PINNs are typically limited to solving
specific problems, and any changes in problem conditions necessitate
retraining. Therefore, we explore the generalization capability of transfer
learning in the strong and energy form of PINNs across different boundary
conditions, materials, and geometries. The transfer learning methods we employ
include full finetuning, lightweight finetuning, and Low-Rank Adaptation
(LoRA). The results demonstrate that full finetuning and LoRA can significantly
improve convergence speed while providing a slight enhancement in accuracy.",http://arxiv.org/abs/2502.00782v1
The Batch Complexity of Bandit Pure Exploration,2025-02-03T15:03:45Z,"Adrienne Tuynman, Rémy Degenne","In a fixed-confidence pure exploration problem in stochastic multi-armed
bandits, an algorithm iteratively samples arms and should stop as early as
possible and return the correct answer to a query about the arms distributions.
We are interested in batched methods, which change their sampling behaviour
only a few times, between batches of observations. We give an
instance-dependent lower bound on the number of batches used by any sample
efficient algorithm for any pure exploration task. We then give a general
batched algorithm and prove upper bounds on its expected sample complexity and
batch complexity. We illustrate both lower and upper bounds on best-arm
identification and thresholding bandits.",http://arxiv.org/abs/2502.01425v1
TeV Afterglow of BOAT GRB without Jet Break,2025-02-03T15:24:06Z,"Yo Kusafuka, Katsuaki Asano","We present a new model for the TeV afterglow of GRB 221009A. The rapid
increase of the TeV flux in the very early phase is reproduced by the magnetic
acceleration. We consider the change in the radial structure of the
circumstellar medium from homogeneous to wind-like to describe the breaks in
the TeV light curve. Our results imply a highly magnetized ejecta with a
significantly thick width, making the deceleration time around 400 s for
observers. In our model, no early jet break is required.",http://arxiv.org/abs/2502.01437v1
"On the Uncertainty of a Simple Estimator for Remote Source Monitoring
  over ALOHA Channels",2025-02-03T16:16:18Z,Andrea Munari,"Efficient remote monitoring of distributed sources is essential for many
Internet of Things (IoT) applications. This work studies the uncertainty at the
receiver when tracking two-state Markov sources over a slotted random access
channel without feedback, using the conditional entropy as a performance
indicator, and considering the last received value as current state estimate.
We provide an analytical characterization of the metric, and evaluate three
access strategies: (i) maximizing throughput, (ii) transmitting only on state
changes, and (iii) minimizing uncertainty through optimized access
probabilities. Our results reveal that throughput optimization does not always
reduce uncertainty. Moreover, while reactive policies are optimal for symmetric
sources, asymmetric processes benefit from mixed strategies allowing
transmissions during state persistence.",http://arxiv.org/abs/2502.01482v1
The Cost Perspective of Liquid Democracy: Feasibility and Control,2025-02-04T14:59:56Z,"Shiri Alouf-Heffetz, Łukasz Janeczko, Grzegorz Lisowski, Georgios Papasotiropoulos","We examine an approval-based model of Liquid Democracy with a budget
constraint on voting and delegating costs, aiming to centrally select casting
voters ensuring complete representation of the electorate. From a computational
complexity perspective, we focus on minimizing overall costs, maintaining short
delegation paths, and preventing excessive concentration of voting power.
Furthermore, we explore computational aspects of strategic control,
specifically, whether external agents can change election components to
influence the voting power of certain voters.",http://arxiv.org/abs/2502.02380v1
Quantum State Preparation via Nested Entanglement,2025-02-05T00:03:05Z,Geoffrey L. Warner,"We develop a representation of an n-qubit register that parameterizes its
statevector as a series of nested entanglements. We show that the recursive
substructure of this representation provides a natural framework for automating
the construction of quantum circuits for state preparation. It also allows for
a straightforward treatment of pure state separability. We discuss a novel
derivation of uniformly controlled rotations and the quantum Fourier transform
within this representation, and consider the effects of single-qubit basis
changes on its overall structure. We end with a discussion of the apparent
connection between the compressibility of the state description in this
representation, and the circuit complexity required to prepare it.",http://arxiv.org/abs/2502.02784v1
Popularity and Innovation in Maven Central,2025-02-05T04:38:20Z,"Nkiru Ede, Jens Dietrich, Ulrich Zülicke","Maven Central is a large popular repository of Java components that has
evolved over the last 20 years. The distribution of dependencies indicates that
the repository is dominated by a relatively small number of components other
components depend on. The question is whether those elites are static, or
change over time, and how this relates to innovation in the Maven ecosystem. We
study those questions using several metrics. We find that elites are dynamic,
and that the rate of innovation is slowing as the repository ages but remains
healthy.",http://arxiv.org/abs/2502.02879v1
Extended Massive Ambitwistor String II,2025-02-05T19:59:30Z,Christian Kunz,"This article continues previous work done in arXiv:2406.01907. It is shown in
more detail how vacuum partition functions and the cosmological constant vanish
at all orders of perturbation theory. Further, all-multiplicity higher-loop
amplitudes are given and shown to be modular invariant, to have proper
factorization, and to be UV-finite at least up to one-loop level, formally even
to all levels. Therefore, the model provides a modular invariant and unitary
N=8 supergravity theory in twistor space with embedded Super-Yang-Mills and
promising UV-finiteness behavior.",http://arxiv.org/abs/2502.03581v2
"Discrete Lyapunov functional for cyclic systems of differential
  equations with time-variable or state-dependent delay",2025-02-05T22:20:51Z,"István Balázs, Ábel Garab","We consider nonautonomous cyclic systems of delay differential equations with
variable delay. Under suitable feedback assumptions, we define an (integer
valued) Lyapunov functional related to the number of sign changes of the
coordinate functions of solutions. We prove that this functional possesses
properties analogous to those established by Mallet-Paret and Sell for the
constant delay case and by Krisztin and Arino for the scalar case. We also
apply the results to equations with state-dependent delays.",http://arxiv.org/abs/2502.03648v1
Frame-dependent coherence of a quantum state,2025-02-06T16:09:21Z,Nicolae Cotfas,"A finite-dimensional Hilbert space is usually described by using an
orthonormal basis, but a more general description can be obtained by using a
tight frame. The frame-dependent coherence, defined by following the analogy
with the basis-dependent coherence, allows us to define the coherence with
respect to several orthonormal bases considered simultaneously or with respect
to a discrete system of coherent states. By using this more general definition,
we can investigate how the basis-dependent coherence changes when we go from a
basis to another one, from a basis to a complementary one. Frame-dependent
coherence contains basis-dependent coherence as a particular case, but it
allows a deeper description of coherence.",http://arxiv.org/abs/2502.04178v1
"Temperature dependent energy gap for Yu-Shiba-Rusinov states at the
  quantum phase transition",2025-02-06T16:34:15Z,"Andreas Theiler, Christian R. Ast, Annica M. Black-Schaffer","Motivated by recent experiments, which allow for fine tuning of the effective
magnetic interaction between the impurity and the superconductor, we
investigate the regime around the quantum phase transition where the system's
ground state changes from a weakly coupled free spin to a screened spin regime.
At this transition we find that the YSR states remain at finite energies at low
temperatures, thereby generating a gap in the spectrum, which is inconsistent
with predictions of the original YSR theory. We investigate various
gap-generating scenarios and determine that the local suppression of the order
parameter, only captured by self-consistent calculations, generates the gap.",http://arxiv.org/abs/2502.04196v1
Multiple nodal solutions of planar Stein-Weiss equations,2025-02-06T22:04:24Z,"Eudes M. Barboza, Eduardo De S. Böer, Olímpio H. Miyagaki, Claudia R. Santana","In this paper, our goal is to investigate the existence of multiple nodal
solutions to a class of planar Stein-Weiss problems involving a nonlinearity
$f$ with subcritical or critical growth in the sense of Trudinger-Moser. To
achieve this, we combine a gluing approach with the Nehari manifold argument.
We demonstrate that for any positive integer $k\in \mathbb{N}$, the problem
studied has at least one radially symmetrical ground state solution that
changes sign exactly $k$-times.",http://arxiv.org/abs/2502.04532v1
"Strong law of large numbers for a function of the local times of a
  transient random walk on groups",2025-02-07T09:51:39Z,"Yinshan Chang, Qinwei Chen, Qian Meng, Xue Peng","This paper presents the strong law of large numbers for a function of the
local times of a transient random walk on groups, extending the research of
Asymont and Korshunov for random walks on the integer lattice $\mathbb{Z}^d$.
Under some weaker conditions, we prove that certain function of the local times
converges almost surely and in $L^1$ and $L^2$. The proof is mainly based on
the subadditive ergodic theorem.",http://arxiv.org/abs/2502.04792v1
Counting lifts of irreducible Brauer characters,2025-02-09T04:19:00Z,"Junwei Zhang, Xuewu Chang, Ping Jin","Let $p$ be an odd prime, and suppose that $G$ is a $p$-solvable group and
$\varphi\in {\rm IBr}(G)$ has vertex $Q$. In 2011, Cossey, Lewis and Navarro
proved that the number of lifts of $\varphi$ is at most $|Q:Q'|$ whenever $Q$
is normal in $G$. In this paper, we present an explicit description of the set
of lifts of $\varphi$ with a given vertex pair $(Q,\delta)$ under a weaker
condition on $Q$, and thus generalize their result.",http://arxiv.org/abs/2502.05771v1
"Symmetric Tensor Coupling in Holographic Mean-Field Theory: Deformed
  Dirac Cones",2025-02-09T12:14:15Z,"Moongul Byun, Taewon Yuk, Sang-Jin Sin","We extend the holographic mean-field theory to rank-two symmetric tensor
order parameter field coupled with fermion. We classify the roles of symmetric
tensor order according to the effect on the spectral density: cone-angle
change, squashing, and tilting of the spectral light cones. In case of the
over-tilted light cone, an analytic continuation of the Green's function is
necessary to preserve the continuity of the spectrum inside the lightcone. Our
results provide agreements between the holographic spectra with those observed
in real materials, such as type-II Dirac cones and strained graphene.",http://arxiv.org/abs/2502.05871v1
"Algorithm for Constructing Related Spanning Directed Forests of Minimum
  Weight",2025-02-09T16:26:47Z,Vasily Buslov,"An algorithm is proposed for constructing directed spanning forests of the
minimum weight, in which the maximum possible degree of affinity between the
minimum forests is preserved when the number of trees changes. The correctness
of the algorithm is checked and its complexity is determined, which does not
exceed $ O (N ^ 3) $ for dense graphs. The result of the algorithm is a set of
related spanning minimal forests consisting of $ k $ trees for all admissible $
k $.",http://arxiv.org/abs/2502.05946v2
Combinatorial Ricci Flow and Thurston's Triangulation Conjecture,2025-02-10T14:13:50Z,"Feng Ke, Ge Huabin","Thurston's triangulation conjecture asserts that every hyperbolic 3-manifold
admits a geometric decomposition into ideal hyperbolic tetrahedra, a result
proven only for certain special 3-manifolds. This paper presents combinatorial
Ricci flow as a systematic and general approach to addressing Thurston's
triangulation conjecture, showing that the flow converges if and only if the
triangulation is geometric. First, we prove the rigidity of the most general
hyperbolic polyhedral 3-manifolds constructed by isometrically gluing partially
truncated and decorated hyperbolic tetrahedra, demonstrating that the metrics
are uniquely determined by cone angles modulo isometry and decoration changes.
Then, we demonstrate that combinatorial Ricci flow evolves polyhedral metrics
toward complete hyperbolic structures with geometric decompositions when
convergent. Conversely, the existence of a geometric triangulation guarantees
flow convergence.",http://arxiv.org/abs/2502.06497v1
Elastically induced phase-shift and birefringence in optical fibers,2025-02-10T22:43:11Z,"Elisabeth Steininger, Thomas Mieling, Piotr T. Chruściel","We compute how elastic deformations of optical fibers affect light
propagation therein. Specifically, we consider differences in wave-guiding
properties of straight fibers subject to different external temperatures,
pressures, and gravitational fields. This is done by solving, perturbatively to
first order, the Maxwell equations in deformed and anisotropic fibers using a
multiple-scales approximation scheme. We derive explicit expressions for the
induced phase shift and birefringence. The phase shift can be expressed in
terms of the average radial pressure, longitudinal tension, and change in
temperature, while birefringence depends on the quadrupole of the external
pressure distribution and the stresses on the axis of the fiber.",http://arxiv.org/abs/2502.07099v1
Analysis of the maps with variable fractional order,2025-02-11T06:23:16Z,"Prashant M. Gade, Sachin Bhalekar, Janardhan Chevala","Fractional order differential and difference equations are used to model
systems with memory. Variable order fractional equations are proposed to model
systems where the memory changes in time. We investigate stability conditions
for linear variable order difference equations where the order is periodic
function with period $T$. We give a general procedure for arbitrary $T$ and for
$T=2$ and $T=3$, we give exact results. For $T=2$, we find that the lower order
determines the stability of the equations. For odd $T$, numerical simulations
indicate that we can approximately determine the stability of equations from
the mean value of the variables.",http://arxiv.org/abs/2502.07290v1
Some remarks on singular capillary cones with free boundary,2025-02-11T16:50:40Z,"Alberto Pacati, Giorgio Tortone, Bozhidar Velichkov","We study minimizing singular cones with free boundary associated with the
capillarity problem. Precisely, we provide a stability criterion $\`a$ la
Jerison-Savin for capillary hypersurfaces and show that, in dimensions up to
$4$, minimizing cones with non-sign-changing mean curvature are flat. We apply
this criterion to minimizing capillary drops and, additionally, establish the
instability of non-trivial axially symmetric cones in dimensions up to $6$.
  The main results are based on a Simons-type inequality for a class of convex,
homogeneous, symmetric functions of the principal curvatures, combined with a
boundary condition specific to the capillary setting.",http://arxiv.org/abs/2502.07697v1
Mathematical reasoning and the computer,2025-02-11T10:35:52Z,Kevin Buzzard,"Computers have already changed the way that humans do mathematics: they
enable us to compute efficiently. But will they soon be helping us to reason?
And will they one day start reasoning themselves? We give an overview of recent
developments in neural networks, computer theorem provers and large language
models.",http://arxiv.org/abs/2502.07850v1
Practical properties of the CUSUM process,2025-02-13T11:21:16Z,"Michael Baron, Sergey V. Malov","We explore the behavior and establish new properties of the cumulative-sum
process (CUSUM) and its running maximum. The study includes precise expressions
for CUSUM's moment generating function and moments, fast recursive computing
algorithms, lower and upper bounds, as well as asymptotes. Results are applied
to single, multiple, and transient change-point problems, for the calculation
of thresholds that provide a desired control of familywise false alarm rates,
as well as the quantiles of queuing processes and probabilities of their large
deviation at least once over a given time interval.",http://arxiv.org/abs/2502.09185v1
On mean curvature flow solitons in the sphere,2025-02-13T11:38:28Z,"Marco Magliaro, Luciano Mari, Fernanda Roing, Andreas Savas-Halilaj","In this paper, we consider soliton solutions of the mean curvature flow in
the unit sphere $S^{2n+1}$ moving along the integral curves of the Hopf unit
vector field. While such solitons must necessarily be minimal if compact, we
produce a non-minimal, complete example with topology $S^{2n-1} \times R$. The
example wraps around a Clifford torus $S^{2n-1} \times S^1$ along each end, it
has reflection and rotational symmetry and its mean curvature changes sign on
each end. Indeed, we prove that a complete 2-dimensional soliton with
non-negative mean curvature outside a compact set must be a covering of a
Clifford torus. Concluding, we obtain a pinching theorem under suitable
conditions on the second fundamental form.",http://arxiv.org/abs/2502.09199v1
Generating Causally Compliant Counterfactual Explanations using ASP,2025-02-13T11:51:53Z,Sopam Dasgupta,"This research is focused on generating achievable counterfactual
explanations. Given a negative outcome computed by a machine learning model or
a decision system, the novel CoGS approach generates (i) a counterfactual
solution that represents a positive outcome and (ii) a path that will take us
from the negative outcome to the positive one, where each node in the path
represents a change in an attribute (feature) value. CoGS computes paths that
respect the causal constraints among features. Thus, the counterfactuals
computed by CoGS are realistic. CoGS utilizes rule-based machine learning
algorithms to model causal dependencies between features. The paper discusses
the current status of the research and the preliminary results obtained.",http://arxiv.org/abs/2502.09226v1
"Optimal response for stochastic differential equations by local kernel
  perturbations",2025-02-13T13:14:07Z,"Gianmarco del Sarto, Stefano Galatolo, Sakshi Jain","We consider a random dynamical system on $\mathbb{R}^d$, whose dynamics is
defined by a stochastic differential equation. The annealed transfer operator
associated with such systems is a kernel operator. Given a set of feasible
infinitesimal perturbations $P$ to this kernel, with support in a certain
compact set, and a specified observable function $\phi: \mathbb{R}^d \to
\mathbb{R}$, we study which infinitesimal perturbation in $P$ produces the
greatest change in expectation of $\phi$. We establish conditions under which
the optimal perturbation uniquely exists and present a numerical method to
approximate the optimal infinitesimal kernel perturbation. Finally, we
numerically illustrate our findings with concrete examples.",http://arxiv.org/abs/2502.09300v1
"The $p$-rank stratification of the moduli space of double covers of a
  fixed elliptic curve",2025-02-13T17:56:42Z,"Kevin Chang, Dušan Dragutinović, Steven R. Groen, Yuxin Lin, Natalia Pacheco-Tallaj, Deepesh Singhal","In this paper we investigate the $p$-rank stratification of the moduli space
of curves of genus $g$ that admit a double cover to a fixed elliptic curve $E$
in characteristic $p>2$. We show that the closed $p$-rank strata of this moduli
space are equidimensional of the expected dimension. We also show the existence
of a smooth double cover of $E$ of all the possible values of the $p$-rank on
this moduli space.",http://arxiv.org/abs/2502.09540v1
"Leveraging V2X for Collaborative HD Maps Construction Using Scene Graph
  Generation",2025-02-14T12:56:10Z,"Gamal Elghazaly, Raphael Frank","High-Definition (HD) maps play a crucial role in autonomous vehicle
navigation, complementing onboard perception sensors for improved accuracy and
safety. Traditional HD map generation relies on dedicated mapping vehicles,
which are costly and fail to capture real-time infrastructure changes. This
paper presents HDMapLaneNet, a novel framework leveraging V2X communication and
Scene Graph Generation to collaboratively construct a localized geometric layer
of HD maps. The approach extracts lane centerlines from front-facing camera
images, represents them as graphs, and transmits the data for global
aggregation to the cloud via V2X. Preliminary results on the nuScenes dataset
demonstrate superior association prediction performance compared to a
state-of-the-art method.",http://arxiv.org/abs/2502.10127v1
"Giant vortex in a harmonically-trapped rotating dipolar $^{164}$Dy
  condensate",2025-02-14T16:29:46Z,"Luis E. Young-S., S. K. Adhikari","We demonstrate the formation of dynamically stable giant vortices in a
harmonically-trapped strongly dipolar $^{164}$Dy Bose-Einstein condensate under
rotation around the polarization direction of dipolar atoms, employing the
numerical solution of an improved mean-field model including a
Lee-Huang-Yang-type interaction, meant to stop a collapse at high atom density.
These giant vortices are stationary, obtainable by imaginary-time propagation
using a Gaussian initial state, while the appropriate phase of the giant vortex
is imprinted on the initial wave function. The dynamical stability of the giant
vortices is established by real-time propagation during a long interval of time
after a small change of a parameter.",http://arxiv.org/abs/2502.10272v1
"Long-term behavior for wave equation with nonlinear damping and
  super-cubic nonlinearity",2025-02-15T11:42:01Z,"Cuncai Liu, Fengjuan Meng, Chang Zhang","In this paper, we consider the semilinear wave equation involving the
nonlinear damping term $g(u_t) $ and nonlinearity $f(u)$. The well-posedness of
the weak solution satisfying some additional regularity is achieved under the
wider ranges of the exponents $g$ and $f$. Moreover, the existence of global
attractor and exponential attractor are proved.",http://arxiv.org/abs/2502.10774v1
On the Computation of the Fisher Information in Continual Learning,2025-02-17T12:52:10Z,Gido M. van de Ven,"One of the most popular methods for continual learning with deep neural
networks is Elastic Weight Consolidation (EWC), which involves computing the
Fisher Information. The exact way in which the Fisher Information is computed
is however rarely described, and multiple different implementations for it can
be found online. This blog post discusses and empirically compares several
often-used implementations, which highlights that many currently reported
results for EWC could likely be improved by changing the way the Fisher
Information is computed.",http://arxiv.org/abs/2502.11756v1
On the average least negative Hecke eigenvalue,2025-02-17T16:26:33Z,Jackie Voros,"We show that the first sign change of Hecke eigenvalues of classical newforms
has a finite mean, which we also compute. We distinguish between the first
negative prime Hecke eigenvalue, and the first negative Hecke eigenvalue. This
problem can be considered to be an analogue of the least quadratic non-residue
problem, of which the average was explored by Erd\H{o}s in 1961. In fact, the
average least negative prime Hecke eigenvalue has the same value as the average
least quadratic non-residue, under GRH. To compute these averages, we develop
large sieve inequalities that are uniform in both the weight and level aspect.",http://arxiv.org/abs/2502.11987v2
"A thermal Green-Naghdi model with time dependent bathymetry and complete
  Coriolis force",2025-02-17T12:21:43Z,"Darryl D. Holm, Oliver D. Street","This paper extends the theoretical Euler-Poincar\'e framework for modelling
ocean mixed layer dynamics. Through a symmetry-broken Lie group invariant
variational principle, we derive a generalised Green-Naghdi equation with time
dependent bathymetry, a complete Coriolis force, and inhomogeneity of the
thermal buoyancy. The nature of the model derived here lends it a potential
future application to wave dynamics generated by changes to the bathymetry.",http://arxiv.org/abs/2502.12220v1
"Applications of Stretch Reflex for the Upper Limb of Musculoskeletal
  Humanoids: Protective Behavior, Postural Stability, and Active Induction",2025-02-18T12:15:54Z,"Kento Kawaharazuka, Yuya Koga, Kei Tsuzuki, Moritaka Onitsuka, Yuki Asano, Kei Okada, Koji Kawasaki, Masayuki Inaba","The musculoskeletal humanoid has various biomimetic benefits, and it is
important that we can embed and evaluate human reflexes in the actual robot.
Although stretch reflex has been implemented in lower limbs of musculoskeletal
humanoids, we apply it to the upper limb to discover its useful applications.
We consider the implementation of stretch reflex in the actual robot, its
active/passive applications, and the change in behavior according to the
difference of parameters.",http://arxiv.org/abs/2502.12811v1
Polarization agnostic continuous variable quantum key distribution,2025-02-18T15:48:25Z,"Brian P. Williams, Nicholas A. Peters","We introduce a polarization agnostic method for Gaussian-modulated coherent
state (GCMS) continuous-variable quantum key distribution (CVQKD). Due to the
random and continuous nature of the GCMS protocol, Alice, the transmitter, can
encode two distinct quadratures in each of two orthogonal polarization modes,
such that Bob, the receiver, measures valid GCMS quadratures in a single
polarization mode even when polarization changes occur during transmission.
This method does not require polarization correction in the optical domain,
does not require monitoring both polarization modes, reduces loss by
eliminating optical components, and avoids the noise injected by polarization
correction algorithms.",http://arxiv.org/abs/2502.12968v1
"Enhanced dynamo drive for the sawtooth relaxation process due to
  non-uniform resistivity distribution in a reversed field pinch",2025-02-20T12:33:08Z,"Wentan Yan, Ping Zhu, Hong Li, Wandong Liu, Bing Luo, Haolong Li","In this work, we use the three-dimensional resistive MHD code NIMROD to
investigate the impact of resistivity inhomogeneity on the sawtooth process of
an reversed field pinch (RFP) plasma. The simulation employs a non-uniform
resistivity profile similar to experiments, which monotonically increases from
the core to the edge as the temperature decreases. The resistivity
inhomogeneity introduces an additional electric field in the plasma, which
accelerates the inward diffusion of magnetic flux and changing the self
sustained reversal state, hence significantly enhances the dynamo effect and
the sawtooth process in the RFP plasma.",http://arxiv.org/abs/2502.14506v1
"TS-SatMVSNet: Slope Aware Height Estimation for Large-Scale Earth
  Terrain Multi-view Stereo",2025-01-02T04:18:40Z,"Song Zhang, Zhiwei Wei, Wenjia Xu, Lili Zhang, Yang Wang, Jinming Zhang, Junyi Liu","3D terrain reconstruction with remote sensing imagery achieves cost-effective
and large-scale earth observation and is crucial for safeguarding natural
disasters, monitoring ecological changes, and preserving the
environment.Recently, learning-based multi-view stereo~(MVS) methods have shown
promise in this task. However, these methods simply modify the general
learning-based MVS framework for height estimation, which overlooks the terrain
characteristics and results in insufficient accuracy. Considering that the
Earth's surface generally undulates with no drastic changes and can be measured
by slope, integrating slope considerations into MVS frameworks could enhance
the accuracy of terrain reconstructions. To this end, we propose an end-to-end
slope-aware height estimation network named TS-SatMVSNet for large-scale remote
sensing terrain reconstruction.To effectively obtain the slope representation,
drawing from mathematical gradient concepts, we innovatively proposed a
height-based slope calculation strategy to first calculate a slope map from a
height map to measure the terrain undulation. To fully integrate slope
information into the MVS pipeline, we separately design two slope-guided
modules to enhance reconstruction outcomes at both micro and macro levels.
Specifically, at the micro level, we designed a slope-guided interval partition
module for refined height estimation using slope values. At the macro level, a
height correction module is proposed, using a learnable Gaussian smoothing
operator to amend the inaccurate height values. Additionally, to enhance the
efficacy of height estimation, we proposed a slope direction loss for
implicitly optimizing height estimation results. Extensive experiments on the
WHU-TLC dataset and MVS3D dataset show that our proposed method achieves
state-of-the-art performance and demonstrates competitive generalization
ability.",http://arxiv.org/abs/2501.01049v1
"Angular-Controlled GST Phase-Change Double Micro-Ring Resonator for
  High-Speed Activation Functions in Neuromorphic Computing",2025-01-02T06:32:30Z,"Hossein Karimkhani, Yaser M. Banad, Sarah Sharif","In the drive toward efficient neuromorphic computing, photonic technologies
offer promising solutions for implementing neural functionalities. Here we
demonstrate the first all-optical double micro-ring resonator incorporating
Ge2Sb2Te5 (GST) as a phase-change material to realize precise nonlinear
activation functions (NLAF). Our device architecture achieves switching speeds
of 0.5 ns through a novel approach to GST integration, where angular
positioning of GST segments within the rings enables unprecedented control over
optical transmission characteristics. Through systematic investigation of
sixteen distinct phase configurations, we identify optimal GST positioning (180
degrees in the first ring, 90 degrees in the second) that achieves ultra-narrow
band transmission with 0.47 nm full width at half maximum. Operating at
significantly lower temperatures (100 degrees centigrade) than conventional GST
implementations, our device maintains high contrast ratios with transmission
coefficient modulation from near-zero to 0.85 across a 4 nm spectral window.
The dual-ring architecture enables independent optimization of spectral
selectivity and switching contrast a capability previously unattainable in
single ring designs. These results demonstrate a viable pathway toward
efficient neuromorphic photonic systems that can operate at speeds relevant for
practical computing applications while maintaining the precision required for
neural processing.",http://arxiv.org/abs/2501.01093v1
Learning 3D Garment Animation from Trajectories of A Piece of Cloth,2025-01-02T18:09:42Z,"Yidi Shao, Chen Change Loy, Bo Dai","Garment animation is ubiquitous in various applications, such as virtual
reality, gaming, and film producing. Recently, learning-based approaches obtain
compelling performance in animating diverse garments under versatile scenarios.
Nevertheless, to mimic the deformations of the observed garments, data-driven
methods require large scale of garment data, which are both resource-wise
expensive and time-consuming. In addition, forcing models to match the dynamics
of observed garment animation may hinder the potentials to generalize to unseen
cases. In this paper, instead of using garment-wise supervised-learning we
adopt a disentangled scheme to learn how to animate observed garments: 1).
learning constitutive behaviors from the observed cloth; 2). dynamically
animate various garments constrained by the learned constitutive laws.
Specifically, we propose Energy Unit network (EUNet) to model the constitutive
relations in the format of energy. Without the priors from analytical physics
models and differentiable simulation engines, EUNet is able to directly capture
the constitutive behaviors from the observed piece of cloth and uniformly
describes the change of energy caused by deformations, such as stretching and
bending. We further apply the pre-trained EUNet to animate various garments
based on energy optimizations. The disentangled scheme alleviates the need of
garment data and enables us to utilize the dynamics of a piece of cloth for
animating garments. Experiments show that while EUNet effectively delivers the
energy gradients due to the deformations, models constrained by EUNet achieve
more stable and physically plausible performance comparing with those trained
in garment-wise supervised manner. Code is available at
https://github.com/ftbabi/EUNet_NeurIPS2024.git .",http://arxiv.org/abs/2501.01393v1
Impact of inter-city interactions on disease scaling,2025-01-02T18:14:24Z,"Nathalia A. Loureiro, Camilo R. Neto, Jack Sutton, Matjaz Perc, Haroldo V. Ribeiro","Inter-city interactions are critical for the transmission of infectious
diseases, yet their effects on the scaling of disease cases remain largely
underexplored. Here, we use the commuting network as a proxy for inter-city
interactions, integrating it with a general scaling framework to describe the
incidence of seven infectious diseases across Brazilian cities as a function of
population size and the number of commuters. Our models significantly
outperform traditional urban scaling approaches, revealing that the
relationship between disease cases and a combination of population and
commuters varies across diseases and is influenced by both factors. Although
most cities exhibit a less-than-proportional increase in disease cases with
changes in population and commuters, more-than-proportional responses are also
observed across all diseases. Notably, in some small and isolated cities,
proportional rises in population and commuters correlate with a reduction in
disease cases. These findings suggest that such towns may experience improved
health outcomes and socioeconomic conditions as they grow and become more
connected. However, as growth and connectivity continue, these gains diminish,
eventually giving way to challenges typical of larger urban areas - such as
socioeconomic inequality and overcrowding - that facilitate the spread of
infectious diseases. Our study underscores the interconnected roles of
population size and commuter dynamics in disease incidence while highlighting
that changes in population size exert a greater influence on disease cases than
variations in the number of commuters.",http://arxiv.org/abs/2501.01395v1
"Slow spatial migration can help eradicate cooperative antimicrobial
  resistance in time-varying environments",2025-01-03T18:36:48Z,"Lluís Hernández-Navarro, Kenneth Distefano, Uwe C. Täuber, Mauro Mobilia","Antimicrobial resistance (AMR) is a global threat and combating its spread is
of paramount importance. AMR often results from a cooperative behaviour with
shared protection against drugs. Microbial communities generally evolve in
volatile environments and spatial structures. Migration, fluctuations, and
environmental variability thus have significant impacts on AMR, whose
maintenance in static environments is generally promoted by migration. Here, we
demonstrate that this picture changes dramatically in time-fluctuating
spatially structured environments. To this end, we consider a two-dimensional
metapopulation model consisting of demes in which drug-resistant and sensitive
cells evolve in a time-changing environment in the presence of a toxin against
which protection can be shared. Cells migrate between neighbouring demes and
hence connect them. When the environment varies neither too quickly nor too
slowly, the dynamics is characterised by bottlenecks causing fluctuation-driven
local extinctions, a mechanism countered by migration that rescues AMR. Through
simulations and mathematical analysis, we investigate how migration and
environmental variability influence the probability of resistance eradication.
We determine the near-optimal conditions for the fluctuation-driven AMR
eradication, and show that slow but non-zero migration speeds up the clearance
of resistance and can enhance its eradication probability. We discuss our
study's impact on laboratory-controlled experiments.",http://arxiv.org/abs/2501.01939v1
Lorentz force mediation of turbulent dynamo transitions,2025-01-04T14:59:51Z,"Krista M. Soderlund, Paula Wulff, Petri Käpylä, Jonathan M. Aurnou","We investigate how the strength of the Lorentz force alters stellar
convection zone dynamics in a suite of buoyancy-dominated, three-dimensional,
spherical shell convective dynamo models. This is done by varying only the
magnetic Prandtl number, $Pm$, the non-dimensional form of the fluid's
electrical conductivity $\sigma$. Because the strength of the dynamo magnetic
field and the Lorentz force scale with $Pm$, it is found that the fluid
motions, the pattern of convective heat transfer, and the mode of dynamo
generation all differ across the $0.25 \leq Pm \leq 10$ range investigated
here. For example, we show that strong magnetohydrodynamic effects cause a
fundamental change in the surface zonal flows: differential rotation switches
from solar-like (prograde equatorial zonal flow) for larger electrical
conductivities to an anti-solar differential rotation (retrograde equatorial
zonal flow) at lower electrical conductivities. This study shows that the value
of the bulk electrical conductivity is important not only for sustaining dynamo
action, but can also drive first-order changes in the characteristics of the
magnetic, velocity, and temperature fields. It is also associated with the
relative strength of the Lorentz force in the system as measured by the local
magnetic Rossby number, $Ro_\ell^M$, which we show is crucial in setting the
characteristics of the large-scale convection regime that generates those
dynamo fields.",http://arxiv.org/abs/2501.02306v1
Gas bubble dynamics,2025-01-06T12:56:21Z,"Dominique Legendre, Roberto Zenit","The study of gas bubble dynamics in liquids is justified by the numerous
applications and natural phenomena where this two-phase flow is encountered.
Gas bubbles move as forces are applied to them; their dynamics are full of
nuances that need to be addressed carefully. Since the mass of gas bubbles is
practically negligible, in comparison to that of the surrounding liquid, their
reaction to the fluid is controlled by the added mass acceleration and is thus
impacted by all the forces arising from the fluid action. Furthermore, since
their surface can be deformed by the same forces acting on them, their shape
may change leading to changes in their resistance to move, the drag force, and
therefore affecting their speed and their interaction with the surrounding flow
which is often turbulent. The liquid rheology, as well as its surfactant
content can also affect the bubble shape and motion as well. Understanding
these issues, in addition to the effect of interactions with other bubbles,
walls, and non-uniform flows, provides sufficient elements to model and predict
bubble behavior through the solution of dynamic equations. In this review, we
cover the key aspects of non-condensable gas bubble dynamics. We survey
classical references on the subject and provide an overview of the main
findings in the past 20 years. We conclude with a scope and suggestions for
future research directions, with special attention to the dynamics of bubble in
turbulence, in non-Newtonian fluid and/or in the presence of electrolytes.",http://arxiv.org/abs/2501.02988v1
"Analyzing Fine-tuning Representation Shift for Multimodal LLMs Steering
  alignment",2025-01-06T13:37:13Z,"Pegah Khayatan, Mustafa Shukor, Jayneel Parekh, Matthieu Cord","Multimodal LLMs have reached remarkable levels of proficiency in
understanding multimodal inputs, driving extensive research to develop
increasingly powerful models. However, much less attention has been paid to
understanding and explaining the underlying mechanisms of these models. Most
existing explainability research examines these models only in their final
states, overlooking the dynamic representational shifts that occur during
training. In this work, we systematically analyze the evolution of hidden state
representations to reveal how fine-tuning alters the internal structure of a
model to specialize in new multimodal tasks. Using a concept-based approach, we
map hidden states to interpretable visual and textual concepts, enabling us to
trace changes in encoded concepts across modalities as training progresses. We
also demonstrate the use of shift vectors to capture these concepts changes.
These shift vectors allow us to recover fine-tuned concepts by shifting those
in the original model. Finally, we explore the practical impact of our findings
on model steering, showing that we can adjust multimodal LLMs behaviors without
any training, such as modifying answer types, captions style, or biasing the
model toward specific responses. Our work sheds light on how multimodal
representations evolve through fine-tuning and offers a new perspective for
interpreting model adaptation in multimodal tasks. The code for this project is
publicly available at https://github.com/mshukor/xl-vlms.",http://arxiv.org/abs/2501.03012v1
"Investigating Discontinuous X-ray Irradiation as a Damage Mitigation
  Strategy for [M(COD)Cl]$_2$ Catalysts",2025-01-06T14:48:24Z,"Nathalie K. Fernando, Claire A. Murray, Amber L. Thompson, Katherine Milton, Andrew B. Cairns, Anna Regoutz","With the advent of ever more intense and focused X-ray sources, including in
laboratories, at synchrotrons, and at X-ray free electron lasers,
radiation-induced sample change and damage are becoming increasingly
challenging. Therefore, the exploration of possible mitigation strategies is
crucial to continue to allow the collection of robust and repeatable data. One
mitigation approach is the introduction of short, X-ray-free ``dark'' periods.
However, it is unclear whether this strategy minimises damage or, in actuality,
promotes it through a phenomenon called ``dark progression'', i.e. the increase
or progression of radiation damage that occurs after the X-ray beam is turned
off. This work discusses the influence of introducing dark periods and their
duration on the radiation-induced changes in two model small-molecule
catalysts, [Ir(COD)Cl]$_2$ and [Rh(COD)Cl]$_2$, exposed to X-ray radiation in
powder diffraction (PXRD) and photoelectron spectroscopy (XPS) experiments.
This provides, for the first time, insights into how damage progresses under
varying radiation regimes and allows the distinction between the processes that
affect the unit cell itself, the individual molecular units, and the respective
atomic chemical environments. Furthermore, it provides the basis for informed
decision-making in the design of future experiments where the need to minimise
radiation-induced damage is crucial.",http://arxiv.org/abs/2501.03057v1
"Comment on ""The unphysicality of Hilbert spaces"" (arXiv:2308.06669v3)",2025-01-06T10:55:32Z,Nivaldo A. Lemos,"``The unphysicality of Hilbert spaces'' by Carcassi, Calder\'on and Aidala
(arXiv:2308.06669v3) is a thoughtful dissection of the mathematical structure
of quantum mechanics that seeks to pinpoint difficulties inherent in
postulating that the physical states are elements of a Hilbert space. Its
pivotal charge against Hilbert spaces is that by a change of variables, which
is a change-of-basis unitary transformation, one ``can map states with finite
expectation values to those with infinite ones''. In the present comment it is
shown that this statement is incorrect and the source of the error is spotted.
In consequence, the purported example of a time evolution that makes ``the
expectation value oscillate from finite to infinite in finite time"" is also
faulty, and the assertion that Hilbert spaces ``turn a potential infinity into
an actual infinity'' is unsubstantiated. Two other objections to Hilbert spaces
on physical grounds, both technically correct, are the isomorphism of separable
Hilbert spaces and the unavoidable existence of infinite-expectation-value
states. The former is of little relevance but the latter remains an issue
without a fully satisfactory solution, although the evidence so far is that it
is physically innocuous. All in all, while the authors' thesis that Hilbert
spaces must be given up ought to be taken seriously, it seems insufficiently
supported to be convincing.",http://arxiv.org/abs/2501.03294v2
Orbital fluctuations and spin-orbital-lattice coupling in Bi2Fe4O9,2025-01-07T06:05:30Z,"Aditya Prasad Roy, M. K. Chattopadhyay, Ranjan Mittal, Srungarpu N. Achary, Avesh K. Tyagi, Manh Duc Le, Dipanshu Bansal","Magnetic frustrations and degeneracies profoundly affect ground-state
magnetic properties emerging from competing exchange interactions. Controlling
such frustrations using orbital and phonon engineering via the
Kugel-Khomskii-type (KK-type) interactions has recently enabled the orbital
enhancement of magnetoelectric (ME) coupling. Using combined spectroscopic
techniques and first-principle simulations, here we demonstrate that the
magnetically frustrated Cairo lattice, Bi2Fe4O9, exhibits a strong KK-type
interaction resulting in a coupled spin-orbital phase below 1.8 times the Neel
temperature (TN = 245 K). We observe an order of magnitude change in phonon
linewidths that is not explainable considering spin-phonon coupling channels
alone. Instead, the observed change is reminiscent of orbitally active
materials, which we explicitly confirm by measuring the T-dependence of
low-energy orbital excitations. We further find that Bi2Fe4O9 harbors an
unstable polar mode, driving the lattice to a symmetry-lowered ferroelectric
(FE) phase below TN, in line with the previously reported hysteresis in
polarization. Nonetheless, the FE phase leads to extremely small calculated
superlattice Bragg peak intensities that are yet to be experimentally
confirmed. Moreover, thermal conductivity measurements do not show any
measurable effect of KK-type interactions on thermal transport across TN. But,
we observe a repeatable anomaly near 57 K appearing only in the heating cycle,
which co-occurs with the 400 meV broad continuum observed in Raman
measurements. The observed KK-type interaction in Bi2Fe4O9 provides an
opportunity for orbital enhancement of ME coupling by phonon control of
superexchange interactions.",http://arxiv.org/abs/2501.03555v1
AlphaPO - Reward shape matters for LLM alignment,2025-01-07T15:46:42Z,"Aman Gupta, Shao Tang, Qingquan Song, Sirou Zhu, Jiwoo Hong, Ankan Saha, Viral Gupta, Noah Lee, Eunki Kim, Siyu Zhu, Parag Agarwal, Natesh Pillai, S. Sathiya Keerthi","Reinforcement Learning with Human Feedback (RLHF) and its variants have made
huge strides toward the effective alignment of large language models (LLMs) to
follow instructions and reflect human values. More recently, Direct Alignment
Algorithms (DAAs) have emerged in which the reward modeling stage of RLHF is
skipped by characterizing the reward directly as a function of the policy being
learned. Some popular examples of DAAs include Direct Preference Optimization
(DPO) and Simple Preference Optimization (SimPO). These methods often suffer
from likelihood displacement, a phenomenon by which the probabilities of
preferred responses are often reduced undesirably.
  In this paper, we argue that, for DAAs the reward (function) shape matters.
We introduce \textbf{AlphaPO}, a new DAA method that leverages an
$\alpha$-parameter to help change the shape of the reward function beyond the
standard log reward. AlphaPO helps maintain fine-grained control over
likelihood displacement and over-optimization. Compared to SimPO, one of the
best performing DAAs, AlphaPO leads to about 7\% to 10\% relative improvement
in alignment performance for the instruct versions of Mistral-7B and Llama3-8B
while achieving 15\% to 50\% relative improvement over DPO on the same models.
The analysis and results presented highlight the importance of the reward
shape, and how one can systematically change it to affect training dynamics, as
well as improve alignment performance.",http://arxiv.org/abs/2501.03884v2
"Multi-functional Wafer-Scale Van der Waals Heterostructures and
  Polymorphs",2025-01-07T17:28:57Z,"M. Micica, A. Wright, S. Massabeau, S. Ayari, E. Rongione, M. Oliveira Ribeiro, S. Husain, T. Denneulin, R. Dunin-Borkowsk, J. Tignon, J. Mangeney, R. Lebrun, H. Okuno, O. Boulle, A. Marty, F. Bonell, F. Carosella, H. Jaffres, R. Ferreira, J-M. George, M. Jamet, S. Dhillon","Van der Waals heterostructures have promised the realisation of artificial
materials with multiple physical phenomena such as giant optical
nonlinearities, spin-to-charge interconversion in spintronics and topological
carrier protection, in a single layered device through an infinitely diverse
set of quantum materials. However, most efforts have only focused on exfoliated
material that inherently limits both the dimensions of the materials and the
scalability for applications. Here, we show the epitaxial growth of large area
heterostructures of topological insulators (Bi2Se3), transition metal
dichalcogenides (TMDs, WSe2) and ferromagnets (Co), resulting in the
combination of functionalities including tuneable optical nonlinearities,
spin-to-charge conversion and magnetic proximity effects. This is demonstrated
through coherent phase resolved terahertz currents, bringing novel
functionalities beyond those achievable in simple homostructures. In
particular, we show the role of different TMD polymorphs, with the simple
change of one atomic monolayer of the artificial material stack entirely
changing its optical, electrical and magnetic properties. This epitaxial
integration of diverse two-dimensional materials offers foundational steps
towards diverse perspectives in quantum material engineering, where the
material polymorph can be controlled at technological relevant scales for
coupling applications in, for example, van der Waals nonlinear optics,
optoelectronics, spintronics, multiferroics and coherent current control.",http://arxiv.org/abs/2501.03955v1
"Novel magnetic-field-free switching behavior in vdW-magnet/oxide
  heterostructure",2025-01-08T02:20:58Z,"Jihoon Keum, Kai-Xuan Zhang, Suik Cheon, Hyuncheol Kim, Jingyuan Cui, Giung Park, Yunyeong Chang, Miyoung Kim, Hyun-Woo Lee, Je-Geun Park","Magnetization switching by charge current without a magnetic field is
essential for device applications and information technology. It generally
requires a current-induced out-of-plane spin polarization beyond the capability
of conventional ferromagnet/heavy-metal systems, where the current-induced spin
polarization aligns in-plane orthogonal to the in-plane charge current and
out-of-plane spin current. Here, we demonstrate a new approach for
magnetic-field-free switching by fabricating a van-der-Waals magnet and oxide
Fe3GeTe2/SrTiO3 heterostructure. This new magnetic-field-free switching is
possible because the current-driven accumulated spins at the Rashba interface
precess around an emergent interface magnetism, eventually producing an
ultimate out-of-plane spin polarization. This interpretation is further
confirmed by the switching polarity change controlled by the in-plane
initialization magnetic fields with clear hysteresis. We successfully combined
van-der-Waals magnet and oxide for the first time, especially taking advantage
of spin-orbit torque on the SrTiO3 oxide. This allows us to establish a new way
of magnetic field-free switching. Our work demonstrates an unusual
perpendicular switching application of large spin Hall angle materials and
precession of accumulated spins, and in doing so, opens up a new field and
opportunities for van-der-Waals magnets and oxide spintronics.",http://arxiv.org/abs/2501.04235v1
"Chondrule dust rim growth: Influence of restructuring using molecular
  dynamics simulations",2025-01-08T17:15:30Z,"Chuchu Xiang, Nina Merkert, Lorin S. Matthews, Augusto Carballido, Truell W. Hyde","We investigate the influence of disruptive collisions on chondrule rim
growth, emphasizing the role of kinetic energy in determining the outcomes of
these interactions. We establish a threshold of approximately 10 cm/s for the
""hit-and-stick"" collision regime, beyond which significant changes occur in the
structure of rimmed chondrules. Our findings highlight that at low collision
energies (KE $< 10^{-12}$ J), minimal structural alteration takes place, while
higher energies (KE up to $10^{-10}$ J) lead to compaction of the rim, reducing
both its thickness and porosity. Collisions with energies exceeding $10^{-8}$ J
result in the complete disruption of the rim, with particles being expelled
from it. These results are correlated with the turbulence levels within the
disk, as kinetic energy scales with the relative velocities of colliding
particles. Leveraging machine learning models trained on our collision data, we
predict changes in rim characteristics and employ these predictions in a Monte
Carlo simulation to explore rim growth dynamics. Our simulations reveal that
rim development is sustained in low-turbulence environments ($\alpha \leq
10^{-5}$), while intermediate turbulence levels ($\alpha$ = $10^{-3}$ to
$10^{-4}$) lead to erosion, preventing further rim accumulation in
high-turbulence contexts.",http://arxiv.org/abs/2501.04625v1
"Explaining k-Nearest Neighbors: Abductive and Counterfactual
  Explanations",2025-01-10T16:14:35Z,"Pablo Barceló, Alexander Kozachinskiy, Miguel Romero Orth, Bernardo Subercaseaux, José Verschae","Despite the wide use of $k$-Nearest Neighbors as classification models, their
explainability properties remain poorly understood from a theoretical
perspective. While nearest neighbors classifiers offer interpretability from a
""data perspective"", in which the classification of an input vector $\bar{x}$ is
explained by identifying the vectors $\bar{v}_1, \ldots, \bar{v}_k$ in the
training set that determine the classification of $\bar{x}$, we argue that such
explanations can be impractical in high-dimensional applications, where each
vector has hundreds or thousands of features and it is not clear what their
relative importance is. Hence, we focus on understanding nearest neighbor
classifications through a ""feature perspective"", in which the goal is to
identify how the values of the features in $\bar{x}$ affect its classification.
Concretely, we study abductive explanations such as ""minimum sufficient
reasons"", which correspond to sets of features in $\bar{x}$ that are enough to
guarantee its classification, and ""counterfactual explanations"" based on the
minimum distance feature changes one would have to perform in $\bar{x}$ to
change its classification. We present a detailed landscape of positive and
negative complexity results for counterfactual and abductive explanations,
distinguishing between discrete and continuous feature spaces, and considering
the impact of the choice of distance function involved. Finally, we show that
despite some negative complexity results, Integer Quadratic Programming and SAT
solving allow for computing explanations in practice.",http://arxiv.org/abs/2501.06078v1
Focus-N-Fix: Region-Aware Fine-Tuning for Text-to-Image Generation,2025-01-11T08:16:30Z,"Xiaoying Xing, Avinab Saha, Junfeng He, Susan Hao, Paul Vicol, Moonkyung Ryu, Gang Li, Sahil Singla, Sarah Young, Yinxiao Li, Feng Yang, Deepak Ramachandran","Text-to-image (T2I) generation has made significant advances in recent years,
but challenges still remain in the generation of perceptual artifacts,
misalignment with complex prompts, and safety. The prevailing approach to
address these issues involves collecting human feedback on generated images,
training reward models to estimate human feedback, and then fine-tuning T2I
models based on the reward models to align them with human preferences.
However, while existing reward fine-tuning methods can produce images with
higher rewards, they may change model behavior in unexpected ways. For example,
fine-tuning for one quality aspect (e.g., safety) may degrade other aspects
(e.g., prompt alignment), or may lead to reward hacking (e.g., finding a way to
increase rewards without having the intended effect). In this paper, we propose
Focus-N-Fix, a region-aware fine-tuning method that trains models to correct
only previously problematic image regions. The resulting fine-tuned model
generates images with the same high-level structure as the original model but
shows significant improvements in regions where the original model was
deficient in safety (over-sexualization and violence), plausibility, or other
criteria. Our experiments demonstrate that Focus-N-Fix improves these localized
quality aspects with little or no degradation to others and typically
imperceptible changes in the rest of the image. Disclaimer: This paper contains
images that may be overly sexual, violent, offensive, or harmful.",http://arxiv.org/abs/2501.06481v1
"OpenGERT: Open Source Automated Geometry Extraction with Geometric and
  Electromagnetic Sensitivity Analyses for Ray-Tracing Propagation Models",2025-01-12T21:42:29Z,"Serhat Tadik, Rajib Bhattacharjea, Johnathan Corgan, David Johnson, Jacobus Van der Merwe, Gregory D. Durgin","Accurate RF propagation modeling in urban environments is critical for
developing digital spectrum twins and optimizing wireless communication
systems. We introduce OpenGERT, an open-source automated Geometry Extraction
tool for Ray Tracing, which collects and processes terrain and building data
from OpenStreetMap, Microsoft Global ML Building Footprints, and USGS elevation
data. Using the Blender Python API, it creates detailed urban models for
high-fidelity simulations with NVIDIA Sionna RT. We perform sensitivity
analyses to examine how variations in building height, position, and
electromagnetic material properties affect ray-tracing accuracy. Specifically,
we present pairwise dispersion plots of channel statistics (path gain, mean
excess delay, delay spread, link outage, and Rician K-factor) and investigate
how their sensitivities change with distance from transmitters. We also
visualize the variance of these statistics for selected transmitter locations
to gain deeper insights. Our study covers Munich and Etoile scenes, each with
10 transmitter locations. For each location, we apply five types of
perturbations: material, position, height, height-position, and all combined,
with 50 perturbations each. Results show that small changes in permittivity and
conductivity minimally affect channel statistics, whereas variations in
building height and position significantly alter all statistics, even with
noise standard deviations of 1 meter in height and 0.4 meters in position.
These findings highlight the importance of precise environmental modeling for
accurate propagation predictions, essential for digital spectrum twins and
advanced communication networks. The code for geometry extraction and
sensitivity analyses is available at github.com/serhatadik/OpenGERT/.",http://arxiv.org/abs/2501.06945v1
"Global Search for Optimal Low Thrust Spacecraft Trajectories using
  Diffusion Models and the Indirect Method",2025-01-13T01:49:17Z,"Jannik Graebner, Ryne Beeson","Long time-duration low-thrust nonlinear optimal spacecraft trajectory global
search is a computationally and time expensive problem characterized by
clustering patterns in locally optimal solutions. During preliminary mission
design, mission parameters are subject to frequent changes, necessitating that
trajectory designers efficiently generate high-quality control solutions for
these new scenarios. Generative machine learning models can be trained to learn
how the solution structure varies with respect to a conditional parameter,
thereby accelerating the global search for missions with updated parameters. In
this work, state-of-the-art diffusion models are integrated with the indirect
approach for trajectory optimization within a global search framework. This
framework is tested on two low-thrust transfers of different complexity in the
circular restricted three-body problem. By generating and analyzing a training
data set, we develop mathematical relations and techniques to understand the
complex structures in the costate domain of locally optimal solutions for these
problems. A diffusion model is trained on this data and successfully
accelerates the global search for both problems. The model predicts how the
costate solution structure changes, based on the maximum spacecraft thrust
magnitude. Warm-starting a numerical solver with diffusion model samples for
the costates at the initial time increases the number of solutions generated
per minute for problems with unseen thrust magnitudes by one to two orders of
magnitude in comparison to samples from a uniform distribution and from an
adjoint control transformation.",http://arxiv.org/abs/2501.07005v1
"Competing Effects of Local Solvation Structures on Chemical Shift
  Changes of Liquid Electrolyte",2025-01-13T13:32:50Z,"Qi You, Yan Sun, Feng Wang, Jun Cheng, Fujie Tang","Understanding the solvation structure of electrolytes is critical for
optimizing the electrochemical performance of rechargeable batteries, as it
directly influences properties such as ionic conductivity, viscosity, and
electrochemical stability. The highly complex structures and strong
interactions in high-concentration electrolytes make accurate modeling and
interpretation of their ``structure-property"" relationships even more
challenging with spectroscopic methods. In this study, we present a machine
learning-based approach to predict dynamic $^7$Li NMR chemical shifts in
LiFSI/DME electrolyte solutions. Additionally, we provide a comprehensive
structural analysis to interpret the observed chemical shift behavior in our
experiments, particularly the abrupt changes in $^7$Li chemical shifts at high
concentrations. Using advanced modeling techniques, we quantitatively establish
the relationship between molecular structure and NMR spectra, offering critical
insights into solvation structure assignments. Our findings reveal the
coexistence of two competing local solvation structures that shift in dominance
as electrolyte concentration approaches the concentrated limit, leading to
anomalous reverse of $^7$Li NMR chemical shift in our experiment. This work
provides a detailed molecular-level understanding of the intricate solvation
structures probed by NMR spectroscopy, leading the way for enhanced electrolyte
design.",http://arxiv.org/abs/2501.07321v1
"A Linear Parameter-Varying Framework for the Analysis of Time-Varying
  Optimization Algorithms",2025-01-13T16:30:56Z,"Fabian Jakob, Andrea Iannelli","In this paper we propose a framework to analyze iterative first-order
optimization algorithms for time-varying convex optimization. We assume that
the temporal variability is caused by a time-varying parameter entering the
objective, which can be measured at the time of decision but whose future
values are unknown. We consider the case of strongly convex objective functions
with Lipschitz continuous gradients and address the class of running algorithms
where only one iteration per time change is performed. We model these
algorithms as discrete-time linear parameter varying (LPV) systems in feedback
with a time-varying gradient. We leverage the approach of analyzing algorithms
as uncertain control interconnections with integral quadratic constraints
(IQCs) and generalize that framework to the time-varying case. We propose novel
IQCs that are capable of capturing the behavior of time-varying nonlinearities
and leverage techniques from the LPV literature to establish novel bounds on
the tracking error. Quantitative bounds can be computed by solving a
semi-definite program and can be interpreted as an input-to-state stability
result with respect to a disturbance signal which increases with the temporal
variability of the problem. As a departure from results in this research area,
our bounds introduce terms that can be interpreted as a temporal rate of change
in the cost function and the optimal value. We exemplify our main results with
numerical experiments that showcase how our analysis framework is able to
capture convergence rates of different first-order algorithms for time-varying
optimization through the choice of IQC and rate bounds.",http://arxiv.org/abs/2501.07461v1
Multi-megabase scale genome interpretation with genetic language models,2025-01-13T23:00:40Z,"Frederik Träuble, Lachlan Stuart, Andreas Georgiou, Pascal Notin, Arash Mehrjou, Ron Schwessinger, Mathieu Chevalley, Kim Branson, Bernhard Schölkopf, Cornelia van Duijn, Debora Marks, Patrick Schwab","Understanding how molecular changes caused by genetic variation drive disease
risk is crucial for deciphering disease mechanisms. However, interpreting
genome sequences is challenging because of the vast size of the human genome,
and because its consequences manifest across a wide range of cells, tissues and
scales -- spanning from molecular to whole organism level. Here, we present
Phenformer, a multi-scale genetic language model that learns to generate
mechanistic hypotheses as to how differences in genome sequence lead to
disease-relevant changes in expression across cell types and tissues directly
from DNA sequences of up to 88 million base pairs. Using whole genome
sequencing data from more than 150 000 individuals, we show that Phenformer
generates mechanistic hypotheses about disease-relevant cell and tissue types
that match literature better than existing state-of-the-art methods, while
using only sequence data. Furthermore, disease risk predictors enriched by
Phenformer show improved prediction performance and generalisation to diverse
populations. Accurate multi-megabase scale interpretation of whole genomes
without additional experimental data enables both a deeper understanding of
molecular mechanisms involved in disease and improved disease risk prediction
at the level of individuals.",http://arxiv.org/abs/2501.07737v1
Bridge-SR: Schrödinger Bridge for Efficient SR,2025-01-14T07:26:05Z,"Chang Li, Zehua Chen, Fan Bao, Jun Zhu","Speech super-resolution (SR), which generates a waveform at a higher sampling
rate from its low-resolution version, is a long-standing critical task in
speech restoration. Previous works have explored speech SR in different data
spaces, but these methods either require additional compression networks or
exhibit limited synthesis quality and inference speed. Motivated by recent
advances in probabilistic generative models, we present Bridge-SR, a novel and
efficient any-to-48kHz SR system in the speech waveform domain. Using tractable
Schr\""odinger Bridge models, we leverage the observed low-resolution waveform
as a prior, which is intrinsically informative for the high-resolution target.
By optimizing a lightweight network to learn the score functions from the prior
to the target, we achieve efficient waveform SR through a data-to-data
generation process that fully exploits the instructive content contained in the
low-resolution observation. Furthermore, we identify the importance of the
noise schedule, data scaling, and auxiliary loss functions, which further
improve the SR quality of bridge-based systems. The experiments conducted on
the benchmark dataset VCTK demonstrate the efficiency of our system: (1) in
terms of sample quality, Bridge-SR outperforms several strong baseline methods
under different SR settings, using a lightweight network backbone (1.7M); (2)
in terms of inference speed, our 4-step synthesis achieves better performance
than the 8-step conditional diffusion counterpart (LSD: 0.911 vs 0.927). Demo
at https://bridge-sr.github.io.",http://arxiv.org/abs/2501.07897v1
Evaluating Policy Effects through Network Dynamics and Sampling,2025-01-14T14:26:11Z,"Eugene T. Y. Ang, Yong Sheng Soh","In the process of enacting or introducing a new policy, policymakers
frequently consider the population's responses. These considerations are
critical for effective governance. There are numerous methods to gauge the
ground sentiment from a subset of the population; examples include surveys or
listening to various feedback channels. Many conventional approaches implicitly
assume that opinions are static; however, in reality, the population will
discuss and debate these new policies among themselves, and reform new opinions
in the process. In this paper, we pose the following questions: Can we quantify
the effect of these social dynamics on the broader opinion towards a new
policy? Given some information about the relationship network that underlies
the population, how does overall opinion change post-discussion? We investigate
three different settings in which the policy is revealed: respondents who do
not know each other, groups of respondents who all know each other, and
respondents chosen randomly. By controlling who the policy is revealed to, we
control the degree of discussion among the population. We quantify how these
factors affect the changes in policy beliefs via the Wasserstein distance
between the empirically observed data post-discussion and its distribution
pre-discussion. We also provide several numerical analyses based on generated
network and real-life network datasets. Our work aims to address the challenges
associated with network topology and social interactions, and provide
policymakers with a quantitative lens to assess policy effectiveness in the
face of resource constraints and network complexities.",http://arxiv.org/abs/2501.08150v1
"Go-with-the-Flow: Motion-Controllable Video Diffusion Models Using
  Real-Time Warped Noise",2025-01-14T18:59:10Z,"Ryan Burgert, Yuancheng Xu, Wenqi Xian, Oliver Pilarski, Pascal Clausen, Mingming He, Li Ma, Yitong Deng, Lingxiao Li, Mohsen Mousavi, Michael Ryoo, Paul Debevec, Ning Yu","Generative modeling aims to transform random noise into structured outputs.
In this work, we enhance video diffusion models by allowing motion control via
structured latent noise sampling. This is achieved by just a change in data: we
pre-process training videos to yield structured noise. Consequently, our method
is agnostic to diffusion model design, requiring no changes to model
architectures or training pipelines. Specifically, we propose a novel noise
warping algorithm, fast enough to run in real time, that replaces random
temporal Gaussianity with correlated warped noise derived from optical flow
fields, while preserving the spatial Gaussianity. The efficiency of our
algorithm enables us to fine-tune modern video diffusion base models using
warped noise with minimal overhead, and provide a one-stop solution for a wide
range of user-friendly motion control: local object motion control, global
camera movement control, and motion transfer. The harmonization between
temporal coherence and spatial Gaussianity in our warped noise leads to
effective motion control while maintaining per-frame pixel quality. Extensive
experiments and user studies demonstrate the advantages of our method, making
it a robust and scalable approach for controlling motion in video diffusion
models. Video results are available on our webpage:
https://eyeline-research.github.io/Go-with-the-Flow. Source code and model
checkpoints are available on GitHub:
https://github.com/Eyeline-Research/Go-with-the-Flow.",http://arxiv.org/abs/2501.08331v3
"Deep Learning-Based Feature Fusion for Emotion Analysis and Suicide Risk
  Differentiation in Chinese Psychological Support Hotlines",2025-01-15T10:09:38Z,"Han Wang, Jianqiang Li, Qing Zhao, Zhonglong Chen, Changwei Song, Jing Tang, Yuning Huang, Wei Zhai, Yongsheng Tong, Guanghui Fu","Mental health is a critical global public health issue, and psychological
support hotlines play a pivotal role in providing mental health assistance and
identifying suicide risks at an early stage. However, the emotional expressions
conveyed during these calls remain underexplored in current research. This
study introduces a method that combines pitch acoustic features with deep
learning-based features to analyze and understand emotions expressed during
hotline interactions. Using data from China's largest psychological support
hotline, our method achieved an F1-score of 79.13% for negative binary emotion
classification.Additionally, the proposed approach was validated on an open
dataset for multi-class emotion classification,where it demonstrated better
performance compared to the state-of-the-art methods. To explore its clinical
relevance, we applied the model to analysis the frequency of negative emotions
and the rate of emotional change in the conversation, comparing 46 subjects
with suicidal behavior to those without. While the suicidal group exhibited
more frequent emotional changes than the non-suicidal group, the difference was
not statistically significant.Importantly, our findings suggest that emotional
fluctuation intensity and frequency could serve as novel features for
psychological assessment scales and suicide risk prediction.The proposed method
provides valuable insights into emotional dynamics and has the potential to
advance early intervention and improve suicide prevention strategies through
integration with clinical tools and assessments The source code is publicly
available at https://github.com/Sco-field/Speechemotionrecognition/tree/main.",http://arxiv.org/abs/2501.08696v1
"Cyclical accretion regime change in the slow X-ray pulsar 4U 0114+65
  observed with Chandra",2025-01-15T10:37:02Z,"Graciela Sanjurjo-Ferrín, Jose Miguel Torrejón, Konstantin Postnov, Michael Nowak, Jose Joaquín Rodes-Roca, Lida Oskinova, Jessica Planelles-Villalva, Norbert Schulz","4U 0114+65 is a high-mass X-ray binary system formed by the luminous
supergiant B1Ia, known as V{*} V662 Cas, and one of the slowest rotating
neutron stars (NS) with a spin period of about 2.6 hours. This fact provides a
rare opportunity to study interesting details of the accretion within each
individual pulse of the compact object. In this paper, we analyze 200 ks of
Chandra grating data, divided into 9 uninterrupted observations around the
orbit. The changes in the circumstellar absorption column through the orbit
suggest an orbital inclination of $\sim$ $40^{\circ}$ with respect to the
observer and a companion mass-loss rate of $\sim$ 8.6 10$^{-7}$ solar masses
yr$^{-1}$. The peaks of the NS pulse show a large pulse-to-pulse variability.
Three of them show an evolution from a brighter regime to a weaker one. We
propose that the efficiency of Compton cooling in this source fluctuates
throughout an accumulation cycle. After significant depletion of matter within
the magnetosphere, since the settling velocity is $\sim \times$ 2 times lower
than the free-fall velocity, the source gradually accumulates matter until the
density exceeds a critical threshold. This increase in density triggers a
transition to a more efficient Compton cooling regime, leading to a higher mass
accretion rate and consequently to an increased brightness.",http://arxiv.org/abs/2501.08702v2
"Female and Combined Male-Female Injury Risk Functions for the Anterior
  Pelvis Under Frontal Lap Belt Loading Conditions",2025-01-15T16:20:12Z,"Connor Hanggi, Joon Seok Kong, James Caldwell, Bronislaw Gepner, Martin Östling, Jason R. Kerrigan","Purpose: Iliac wing fractures due to lap belt loading have been observed in
laboratory settings for 50 years and recent data suggest they are also
occurring in the field. Automated driving systems (ADS) and other occupant
compartment advancements are expected to offer enhanced flexibility in seating
orientation, which could place a greater reliance on the seatbelt to restrain
occupants. Such changes may increase seatbelt loads and create new challenges
in successfully restraining occupants and mitigating injury to areas such as
the pelvis. Injury criteria exist for component-level male iliac wing fractures
resulting from frontal lap belt loading, but not for females. Methods: This
study explored female iliac wing fracture tolerance in the same loading
environment as a previous study that explored the fracture tolerance of
isolated male iliac wings. Male and female fracture data were combined to
evaluate the effect of sex. Injury risk functions were created by fitting
Weibull survival models to data that integrated censored and exact failure
observations. Results: Twenty female iliac wings were tested; fourteen of them
sustained fracture with known failure forces (exact), but the remaining six
wings either (1) did not fracture, or (2) fractured after an event that changed
the boundary conditions (right censored). The fracture tolerance of the tested
specimens ranged widely (1134 - 8759 N) and averaged 4240 N (SD 2516 N).
Conclusion: Female data and combined male-female data were analyzed. Age was
the only covariate investigated in this study that had a statistically
significant effect and improved the predictive performance of the models.",http://arxiv.org/abs/2501.08911v1
"A joint spatiotemporal model for multiple longitudinal markers and
  competing events",2025-01-15T17:10:49Z,"Juliette Ortholand, Stanley Durrleman, Sophie Tezenas du Montcel","Non-terminal events can represent a meaningful change in a patient's life.
Thus, better understanding and predicting their occurrence can bring valuable
information to individuals. In a context where longitudinal markers could
inform these events, joint models with competing risks have been developed.
Their precision relies on a reference time for which disease onset is often
used. Nevertheless, chronic diseases have no clear onset, making it difficult
to define a precise reference time. We propose a Joint cause-specific
Spatiotemporal model to overcome this limitation and to capture a shared latent
process, a latent age (temporal aspect), associated with the ordering of the
longitudinal outcomes (spatial aspect). First, we validated our model on
simulated real-like data. Then, we benchmarked our model with a
shared-random-effect joint model on real ALS data using the PRO-ACT dataset.
Finally, to show how the model could be used for description tasks, we analysed
the impact of sex and onset site on the progression of ALS as well as the
initiation of Non-Invasive Ventilation. The Joint cause-specific spatiotemporal
model achieved similar performance to the shared random effect joint model
while capturing the latent disease age and the impact of the ordering of
longitudinal outcomes on the occurrence of the events with fewer parameters.
The application study confirmed existing results for the Longitudinal outcomes
and showed how to interpret the model. The proposed approach by disentangling a
temporal and a spatial aspect of the disease opens the perspective to capture
meaningful change in future clinical trials.",http://arxiv.org/abs/2501.08960v1
"Continual Test-Time Adaptation for Single Image Defocus Deblurring via
  Causal Siamese Networks",2025-01-15T13:42:39Z,"Shuang Cui, Yi Li, Jiangmeng Li, Xiongxin Tang, Bing Su, Fanjiang Xu, Hui Xiong","Single image defocus deblurring (SIDD) aims to restore an all-in-focus image
from a defocused one. Distribution shifts in defocused images generally lead to
performance degradation of existing methods during out-of-distribution
inferences. In this work, we gauge the intrinsic reason behind the performance
degradation, which is identified as the heterogeneity of lens-specific point
spread functions. Empirical evidence supports this finding, motivating us to
employ a continual test-time adaptation (CTTA) paradigm for SIDD. However,
traditional CTTA methods, which primarily rely on entropy minimization, cannot
sufficiently explore task-dependent information for pixel-level regression
tasks like SIDD. To address this issue, we propose a novel Siamese
networks-based continual test-time adaptation framework, which adapts source
models to continuously changing target domains only requiring unlabeled target
data in an online manner. To further mitigate semantically erroneous textures
introduced by source SIDD models under severe degradation, we revisit the
learning paradigm through a structural causal model and propose Causal Siamese
networks (CauSiam). Our method leverages large-scale pre-trained
vision-language models to derive discriminative universal semantic priors and
integrates these priors into Siamese networks, ensuring causal identifiability
between blurry inputs and restored images. Extensive experiments demonstrate
that CauSiam effectively improves the generalization performance of existing
SIDD methods in continuously changing domains.",http://arxiv.org/abs/2501.09052v1
ADAGE: A generic two-layer framework for adaptive agent based modelling,2025-01-16T09:58:24Z,"Benjamin Patrick Evans, Sihan Zeng, Sumitra Ganesh, Leo Ardon","Agent-based models (ABMs) are valuable for modelling complex, potentially
out-of-equilibria scenarios. However, ABMs have long suffered from the Lucas
critique, stating that agent behaviour should adapt to environmental changes.
Furthermore, the environment itself often adapts to these behavioural changes,
creating a complex bi-level adaptation problem. Recent progress integrating
multi-agent reinforcement learning into ABMs introduces adaptive agent
behaviour, beginning to address the first part of this critique, however, the
approaches are still relatively ad hoc, lacking a general formulation, and
furthermore, do not tackle the second aspect of simultaneously adapting
environmental level characteristics in addition to the agent behaviours. In
this work, we develop a generic two-layer framework for ADaptive AGEnt based
modelling (ADAGE) for addressing these problems. This framework formalises the
bi-level problem as a Stackelberg game with conditional behavioural policies,
providing a consolidated framework for adaptive agent-based modelling based on
solving a coupled set of non-linear equations. We demonstrate how this generic
approach encapsulates several common (previously viewed as distinct) ABM tasks,
such as policy design, calibration, scenario generation, and robust behavioural
learning under one unified framework. We provide example simulations on
multiple complex economic and financial environments, showing the strength of
the novel framework under these canonical settings, addressing long-standing
critiques of traditional ABMs.",http://arxiv.org/abs/2501.09429v1
"Make yourself comfortable: Nudging urban heat and noise mitigation with
  smartwatch-based Just-in-time Adaptive Interventions (JITAI)",2025-01-16T13:28:40Z,"Clayton Miller, Yun Xuan Chua, Matias Quintana, Binyu Lei, Filip Biljecki, Mario Frei","Humans can play a more active role in improving their comfort in the built
environment if given the right information at the right place and time. This
paper outlines the use of Just-in-Time Adaptive Interventions (JITAI)
implemented in the context of the built environment to provide information that
helps humans minimize the impact of heat and noise on their daily lives. This
framework builds upon the open-source Cozie iOS smartwatch platform. It
includes data collection through micro-surveys and intervention messages
triggered by environmental, contextual, and personal history conditions. An
eight-month deployment of the method was completed in Singapore with 103
participants who submitted over 12,000 micro-surveys and delivered over 3,600
JITAI intervention messages. A weekly survey conducted during two deployment
phases revealed an overall increase in perceived usefulness ranging from 8-19%
over the first three weeks of data collection. For noise-related interventions,
participants showed an overall increase in location changes ranging from 4-11%
and a 2-17% increase in earphone use to mitigate noise distractions. For
thermal comfort-related interventions, participants demonstrated a 3-13%
increase in adjustments to their location or thermostat to feel more
comfortable. The analysis found evidence that personality traits (such as
conscientiousness), gender, and environmental preferences could be factors in
determining the perceived helpfulness of JITAIs and influencing behavior
change. These findings underscore the importance of tailoring intervention
strategies to individual traits and environmental conditions, setting the stage
for future research to refine the delivery, timing, and content of intervention
messages.",http://arxiv.org/abs/2501.09530v1
"NS-Gym: Open-Source Simulation Environments and Benchmarks for
  Non-Stationary Markov Decision Processes",2025-01-16T16:38:33Z,"Nathaniel S. Keplinger, Baiting Luo, Iliyas Bektas, Yunuo Zhang, Kyle Hollins Wray, Aron Laszka, Abhishek Dubey, Ayan Mukhopadhyay","In many real-world applications, agents must make sequential decisions in
environments where conditions are subject to change due to various exogenous
factors. These non-stationary environments pose significant challenges to
traditional decision-making models, which typically assume stationary dynamics.
Non-stationary Markov decision processes (NS-MDPs) offer a framework to model
and solve decision problems under such changing conditions. However, the lack
of standardized benchmarks and simulation tools has hindered systematic
evaluation and advance in this field. We present NS-Gym, the first simulation
toolkit designed explicitly for NS-MDPs, integrated within the popular
Gymnasium framework. In NS-Gym, we segregate the evolution of the environmental
parameters that characterize non-stationarity from the agent's decision-making
module, allowing for modular and flexible adaptations to dynamic environments.
We review prior work in this domain and present a toolkit encapsulating key
problem characteristics and types in NS-MDPs. This toolkit is the first effort
to develop a set of standardized interfaces and benchmark problems to enable
consistent and reproducible evaluation of algorithms under non-stationary
conditions. We also benchmark six algorithmic approaches from prior work on
NS-MDPs using NS-Gym. Our vision is that NS-Gym will enable researchers to
assess the adaptability and robustness of their decision-making algorithms to
non-stationary conditions.",http://arxiv.org/abs/2501.09646v1
"Regulation of Algorithmic Collusion, Refined: Testing Pessimistic
  Calibrated Regret",2025-01-16T18:49:12Z,"Jason D. Hartline, Chang Wang, Chenhao Zhang","We study the regulation of algorithmic (non-)collusion amongst sellers in
dynamic imperfect price competition by auditing their data as introduced by
Hartline et al. [2024].
  We develop an auditing method that tests whether a seller's pessimistic
calibrated regret is low. The pessimistic calibrated regret is the highest
calibrated regret of outcomes compatible with the observed data. This method
relaxes the previous requirement that a pricing algorithm must use
fully-supported price distributions to be auditable. This method is at least as
permissive as any auditing method that has a high probability of failing
algorithmic outcomes with non-vanishing calibrated regret. Additionally, we
strengthen the justification for using vanishing calibrated regret, versus
vanishing best-in-hindsight regret, as the non-collusion definition, by showing
that even without any side information, the pricing algorithms that only
satisfy weaker vanishing best-in-hindsight regret allow an opponent to
manipulate them into posting supra-competitive prices. This manipulation cannot
be excluded with a non-collusion definition of vanishing best-in-hindsight
regret.
  We motivate and interpret the approach of auditing algorithms from their data
as suggesting a per se rule. However, we demonstrate that it is possible for
algorithms to pass the audit by pretending to have higher costs than they
actually do. For such scenarios, the rule of reason can be applied to bound the
range of costs to those that are reasonable for the domain.",http://arxiv.org/abs/2501.09740v1
"VERITAS: Verifying the Performance of AI-native Transceiver Actions in
  Base-Stations",2025-01-01T19:12:03Z,"Nasim Soltani, Michael Loehning, Kaushik Chowdhury","Artificial Intelligence (AI)-native receivers prove significant performance
improvement in high noise regimes and can potentially reduce communication
overhead compared to the traditional receiver. However, their performance
highly depends on the representativeness of the training dataset. A major issue
is the uncertainty of whether the training dataset covers all test environments
and waveform configurations, and thus, whether the trained model is robust in
practical deployment conditions. To this end, we propose a joint
measurement-recovery framework for AI-native transceivers post deployment,
called VERITAS, that continuously looks for distribution shifts in the received
signals and triggers finite re-training spurts. VERITAS monitors the wireless
channel using 5G pilots fed to an auxiliary neural network that detects
out-of-distribution channel profile, transmitter speed, and delay spread. As
soon as such a change is detected, a traditional (reference) receiver is
activated, which runs for a period of time in parallel to the AI-native
receiver. Finally, VERTIAS compares the bit probabilities of the AI-native and
the reference receivers for the same received data inputs, and decides whether
or not a retraining process needs to be initiated. Our evaluations reveal that
VERITAS can detect changes in the channel profile, transmitter speed, and delay
spread with 99%, 97%, and 69% accuracies, respectively, followed by timely
initiation of retraining for 86%, 93.3%, and 94.8% of inputs in channel
profile, transmitter speed, and delay spread test sets, respectively.",http://arxiv.org/abs/2501.09761v1
"Mapping the three-dimensional fermiology of the triangular lattice
  magnet EuAg$_4$Sb$_2$",2025-01-17T06:15:52Z,"J. Green, Harry W. T. Morgan, Morgaine Mandigo-Stoba, William T. Laderer, Kuan-Yu Wey, Asari G. Prado, Chris Jozwiak, Aaron Bostwick, Eli Rotenberg, Christopher Gutiérrez, Anastassia N. Alexandrova, Ni Ni","In this paper, we report the temperature-field phase diagram as well as
present a comprehensive study of the electronic structure and three-dimensional
fermiology of the triangular-lattice magnet EuAg$_4$Sb$_2$, utilizing quantum
oscillation measurements, angle-resolved photoemission spectroscopy and
first-principles calculations. The complex magnetic phase diagram of
EuAg$_4$Sb$_2$ highlights many transitions through nontrivial AFM states.
Shubnikov-de Haas and de Haas-van Alphen oscillations were observed in the
polarized ferromagnetic state of EuAg$_4$Sb$_2$, revealing three pairs of
distinct spin-split frequency branches with small effective masses. A
comparison of the angle-dependent oscillation data with first-principles
calculations in the ferromagnetic state and angle-resolved photoemission
spectra shows good agreement, identifying tubular hole pockets and
hourglass-shaped hole pockets at the Brillouin zone center, as well as
diamond-shaped electron pockets at the zone boundary. As the temperature
increases, the frequency branches of the tiny hourglass pockets evolve into a
more cylindrical shape, while the larger pockets remain unchanged. This
highlights that variations in exchange splitting, driven by changes in the
magnetic moment, primarily impact the small Fermi pockets without significantly
altering the overall band structure. This is consistent with first-principles
calculations, which show minimal changes near the Fermi level across
ferromagnetic and simple antiferromagnetic states or under varying on-site
Coulomb repulsion.",http://arxiv.org/abs/2501.09966v1
"No evidence that the binary black hole mass distribution evolves with
  redshift",2025-01-17T16:42:13Z,"Max Lalleman, Kevin Turbang, Thomas Callister, Nick van Remortel","The mass distribution of merging binary black holes is generically predicted
to evolve with redshift, reflecting systematic changes in their astrophysical
environment, stellar progenitors, and/or dominant formation channels over
cosmic time. Whether or not such an effect is observed in gravitational-wave
data, however, remains an open question, with some contradictory results
present in the literature. In this paper, we study the ensemble of binary black
holes within the latest GWTC-3 catalog released by the LIGO-Virgo-KAGRA
Collaboration, systematically surveying for possible evolution of their mass
distribution with redshift. We specifically focus on two key features present
in the binary black hole primary mass distribution -- (1) an excess of
$35\,M_\odot$ black holes and (2) a broad power-law continuum ranging from 10
to $\gtrsim 80 M_\odot$ -- and ask if one or both of these features are
observed to vary with redshift. We find no evidence that either the Gaussian
peak or power-law continuum components of the mass distribution change with
redshift. In some cases, we place somewhat stringent bounds on the degree of
allowed redshift evolution. Most notably, we find that the mean location of the
$35\,M_\odot$ peak and the slope of the power-law continuum are constrained to
remain approximately constant below redshift $z\approx 1$. The data remain more
agnostic about other forms of redshift dependence, such as evolution in the
height of the $35\,M_\odot$ excess or the minimum and maximum black hole
masses. In all cases, we conclude that a redshift-dependent mass spectrum
remains possible, but that it is not required by current data.",http://arxiv.org/abs/2501.10295v1
"New Fashion Products Performance Forecasting: A Survey on Evolutions,
  Models and Emerging Trends",2025-01-17T17:56:27Z,"Andrea Avogaro, Luigi Capogrosso, Andrea Toaiari, Franco Fummi, Marco Cristani","The fast fashion industry's insatiable demand for new styles and rapid
production cycles has led to a significant environmental burden.
Overproduction, excessive waste, and harmful chemicals have contributed to the
negative environmental impact of the industry. To mitigate these issues, a
paradigm shift that prioritizes sustainability and efficiency is urgently
needed. Integrating learning-based predictive analytics into the fashion
industry represents a significant opportunity to address environmental
challenges and drive sustainable practices. By forecasting fashion trends and
optimizing production, brands can reduce their ecological footprint while
remaining competitive in a rapidly changing market. However, one of the key
challenges in forecasting fashion sales is the dynamic nature of consumer
preferences. Fashion is acyclical, with trends constantly evolving and
resurfacing. In addition, cultural changes and unexpected events can disrupt
established patterns. This problem is also known as New Fashion Products
Performance Forecasting (NFPPF), and it has recently gained more and more
interest in the global research landscape. Given its multidisciplinary nature,
the field of NFPPF has been approached from many different angles. This
comprehensive survey wishes to provide an up-to-date overview that focuses on
learning-based NFPPF strategies. The survey is based on the Preferred Reporting
Items for Systematic Reviews and Meta-Analyses (PRISMA) methodological flow,
allowing for a systematic and complete literature review. In particular, we
propose the first taxonomy that covers the learning panorama for NFPPF,
examining in detail the different methodologies used to increase the amount of
multimodal information, as well as the state-of-the-art available datasets.
Finally, we discuss the challenges and future directions.",http://arxiv.org/abs/2501.10324v1
"Automated Detection of Epileptic Spikes and Seizures Incorporating a
  Novel Spatial Clustering Prior",2025-01-05T02:06:13Z,"Hanyang Dong, Shurong Sheng, Xiongfei Wang, Jiahong Gao, Yi Sun, Wanli Yang, Kuntao Xiao, Pengfei Teng, Guoming Luan, Zhao Lv","A Magnetoencephalography (MEG) time-series recording consists of
multi-channel signals collected by superconducting sensors, with each signal's
intensity reflecting magnetic field changes over time at the sensor location.
Automating epileptic MEG spike detection significantly reduces manual
assessment time and effort, yielding substantial clinical benefits. Existing
research addresses MEG spike detection by encoding neural network inputs with
signals from all channel within a time segment, followed by classification.
However, these methods overlook simultaneous spiking occurred from nearby
sensors. We introduce a simple yet effective paradigm that first clusters MEG
channels based on their sensor's spatial position. Next, a novel convolutional
input module is designed to integrate the spatial clustering and temporal
changes of the signals. This module is fed into a custom MEEG-ResNet3D
developed by the authors, which learns to extract relevant features and
classify the input as a spike clip or not. Our method achieves an F1 score of
94.73% on a large real-world MEG dataset Sanbo-CMR collected from two centers,
outperforming state-of-the-art approaches by 1.85%. Moreover, it demonstrates
efficacy and stability in the Electroencephalographic (EEG) seizure detection
task, yielding an improved weighted F1 score of 1.4% compared to current
state-of-the-art techniques evaluated on TUSZ, whch is the largest EEG seizure
dataset.",http://arxiv.org/abs/2501.10404v1
"Constrained Coding for Composite DNA: Channel Capacity and Efficient
  Constructions",2025-01-18T03:32:10Z,"Tuan Thanh Nguyen, Chen Wang, Kui Cai, Yiwei Zhang, Zohar Yakhini","Composite DNA is a recent novel method to increase the information capacity
of DNA-based data storage above the theoretical limit of 2 bits/symbol. In this
method, every composite symbol does not store a single DNA nucleotide but a
mixture of the four nucleotides in a predetermined ratio. By using different
mixtures and ratios, the alphabet can be extended to have much more than four
symbols in the naive approach. While this method enables higher data content
per synthesis cycle, potentially reducing the DNA synthesis cost, it also
imposes significant challenges for accurate DNA sequencing since the base-level
errors can easily change the mixture of bases and their ratio, resulting in
changes to the composite symbols. With this motivation, we propose efficient
constrained coding techniques to enforce the biological constraints, including
the runlength-limited constraint and the GC-content constraint, into every DNA
synthesized oligo, regardless of the mixture of bases in each composite letter
and their corresponding ratio. Our goals include computing the capacity of the
constrained channel, constructing efficient encoders/decoders, and providing
the best options for the composite letters to obtain capacity-approaching
codes. For certain codes' parameters, our methods incur only one redundant
symbol.",http://arxiv.org/abs/2501.10645v1
"Deformable Image Registration of Dark-Field Chest Radiographs for Local
  Lung Signal Change Assessment",2025-01-18T13:08:32Z,"Fabian Drexel, Vasiliki Sideri-Lampretsa, Henriette Bast, Alexander W. Marka, Thomas Koehler, Florian T. Gassert, Daniela Pfeiffer, Daniel Rueckert, Franz Pfeiffer","Dark-field radiography of the human chest has been demonstrated to have
promising potential for the analysis of the lung microstructure and the
diagnosis of respiratory diseases. However, previous studies of dark-field
chest radiographs evaluated the lung signal only in the inspiratory breathing
state. Our work aims to add a new perspective to these previous assessments by
locally comparing dark-field lung information between different respiratory
states. To this end, we discuss suitable image registration methods for
dark-field chest radiographs to enable consistent spatial alignment of the lung
in distinct breathing states. Utilizing full inspiration and expiration scans
from a clinical chronic obstructive pulmonary disease study, we assess the
performance of the proposed registration framework and outline applicable
evaluation approaches. Our regional characterization of lung dark-field signal
changes between the breathing states provides a proof-of-principle that dynamic
radiography-based lung function assessment approaches may benefit from
considering registered dark-field images in addition to standard plain chest
radiographs.",http://arxiv.org/abs/2501.10757v1
"Decoupling Appearance Variations with 3D Consistent Features in Gaussian
  Splatting",2025-01-18T14:55:58Z,"Jiaqi Lin, Zhihao Li, Binxiao Huang, Xiao Tang, Jianzhuang Liu, Shiyong Liu, Xiaofei Wu, Fenglong Song, Wenming Yang","Gaussian Splatting has emerged as a prominent 3D representation in novel view
synthesis, but it still suffers from appearance variations, which are caused by
various factors, such as modern camera ISPs, different time of day, weather
conditions, and local light changes. These variations can lead to floaters and
color distortions in the rendered images/videos. Recent appearance modeling
approaches in Gaussian Splatting are either tightly coupled with the rendering
process, hindering real-time rendering, or they only account for mild global
variations, performing poorly in scenes with local light changes. In this
paper, we propose DAVIGS, a method that decouples appearance variations in a
plug-and-play and efficient manner. By transforming the rendering results at
the image level instead of the Gaussian level, our approach can model
appearance variations with minimal optimization time and memory overhead.
Furthermore, our method gathers appearance-related information in 3D space to
transform the rendered images, thus building 3D consistency across views
implicitly. We validate our method on several appearance-variant scenes, and
demonstrate that it achieves state-of-the-art rendering quality with minimal
training time and memory usage, without compromising rendering speeds.
Additionally, it provides performance improvements for different Gaussian
Splatting baselines in a plug-and-play manner.",http://arxiv.org/abs/2501.10788v1
"Solar oblateness & asphericities temporal variations: outstanding some
  unsolved issues",2025-01-18T16:47:23Z,"Jean P. Rozelot, Alexander G. Kosovichev, Ali Kilcik","Solar oblateness has been the subject of several studies dating back to the
nineteenth century. Despite diffculties, both theoretical and observational,
tangible results have been achieved. However, variability of the solar
oblateness with time is still poorly known. How the solar shape evolves with
the solar cycle has been a challenging problem. Analysis of the helioseismic
data, which are the most accurate measure of the solar structure up to now,
leads to the determination of asphericity coeffcients which have been found to
change with time. We show here that by inverting even coeffcients of f-mode
oscillation frequency splitting to obtain the oblateness magnitude and its
temporal dependence can be inferred. It is found that the oblateness variations
lag the solar activity cycles by about 3 years. A major change occurred between
solar cycles 23 and 24 is that the oblateness was greater in cycle 24 despite
the lower solar activity level. Such results may help to better understand the
near-subsurface layers as they strongly impacts the internal dynamics of the
Sun and may induce instabilities driving the transport of angular momentum.",http://arxiv.org/abs/2501.10821v1
Arbitrary-Threshold Fully Homomorphic Encryption with Lower Complexity,2025-01-20T02:46:08Z,"Yijia Chang, Songze Li","Threshold fully homomorphic encryption (ThFHE) enables multiple parties to
compute functions over their sensitive data without leaking data privacy. Most
of existing ThFHE schemes are restricted to full threshold and require the
participation of \textit{all} parties to output computing results. Compared
with these full-threshold schemes, arbitrary threshold (ATh)-FHE schemes are
robust to non-participants and can be a promising solution to many real-world
applications. However, existing AThFHE schemes are either inefficient to be
applied with a large number of parties $N$ and a large data size $K$, or
insufficient to tolerate all types of non-participants. In this paper, we
propose an AThFHE scheme to handle all types of non-participants with lower
complexity over existing schemes. At the core of our scheme is the reduction
from AThFHE construction to the design of a new primitive called
\textit{approximate secret sharing} (ApproxSS). Particularly, we formulate
ApproxSS and prove the correctness and security of AThFHE on top of
arbitrary-threshold (ATh)-ApproxSS's properties. Such a reduction reveals that
existing AThFHE schemes implicitly design ATh-ApproxSS following a similar idea
called ``noisy share''. Nonetheless, their ATh-ApproxSS design has high
complexity and become the performance bottleneck. By developing ATASSES, an
ATh-ApproxSS scheme based on a novel ``encrypted share'' idea, we reduce the
computation (resp. communication) complexity from $\mathcal{O}(N^2K)$ to
$\mathcal{O}(N^2+K)$ (resp. from $\mathcal{O}(NK)$ to $\mathcal{O}(N+K)$). We
not only theoretically prove the (approximate) correctness and security of
ATASSES, but also empirically evaluate its efficiency against existing
baselines. Particularly, when applying to a system with one thousand parties,
ATASSES achieves a speedup of $3.83\times$ -- $15.4\times$ over baselines.",http://arxiv.org/abs/2501.11235v1
"A New Formulation of Lipschitz Constrained With Functional Gradient
  Learning for GANs",2025-01-20T02:48:07Z,"Chang Wan, Ke Fan, Xinwei Sun, Yanwei Fu, Minglu Li, Yunliang Jiang, Zhonglong Zheng","This paper introduces a promising alternative method for training Generative
Adversarial Networks (GANs) on large-scale datasets with clear theoretical
guarantees. GANs are typically learned through a minimax game between a
generator and a discriminator, which is known to be empirically unstable.
Previous learning paradigms have encountered mode collapse issues without a
theoretical solution. To address these challenges, we propose a novel
Lipschitz-constrained Functional Gradient GANs learning (Li-CFG) method to
stabilize the training of GAN and provide a theoretical foundation for
effectively increasing the diversity of synthetic samples by reducing the
neighborhood size of the latent vector. Specifically, we demonstrate that the
neighborhood size of the latent vector can be reduced by increasing the norm of
the discriminator gradient, resulting in enhanced diversity of synthetic
samples. To efficiently enlarge the norm of the discriminator gradient, we
introduce a novel {\epsilon}-centered gradient penalty that amplifies the norm
of the discriminator gradient using the hyper-parameter {\epsilon}. In
comparison to other constraints, our method enlarging the discriminator norm,
thus obtaining the smallest neighborhood size of the latent vector. Extensive
experiments on benchmark datasets for image generation demonstrate the efficacy
of the Li-CFG method and the {\epsilon}-centered gradient penalty. The results
showcase improved stability and increased diversity of synthetic samples.",http://arxiv.org/abs/2501.11236v1
Nested Annealed Training Scheme for Generative Adversarial Networks,2025-01-20T07:44:09Z,"Chang Wan, Ming-Hsuan Yang, Minglu Li, Yunliang Jiang, Zhonglong Zheng","Recently, researchers have proposed many deep generative models, including
generative adversarial networks(GANs) and denoising diffusion models. Although
significant breakthroughs have been made and empirical success has been
achieved with the GAN, its mathematical underpinnings remain relatively
unknown. This paper focuses on a rigorous mathematical theoretical framework:
the composite-functional-gradient GAN (CFG)[1]. Specifically, we reveal the
theoretical connection between the CFG model and score-based models. We find
that the training objective of the CFG discriminator is equivalent to finding
an optimal D(x). The optimal gradient of D(x) differentiates the integral of
the differences between the score functions of real and synthesized samples.
Conversely, training the CFG generator involves finding an optimal G(x) that
minimizes this difference. In this paper, we aim to derive an annealed weight
preceding the weight of the CFG discriminator. This new explicit theoretical
explanation model is called the annealed CFG method. To overcome the limitation
of the annealed CFG method, as the method is not readily applicable to the SOTA
GAN model, we propose a nested annealed training scheme (NATS). This scheme
keeps the annealed weight from the CFG method and can be seamlessly adapted to
various GAN models, no matter their structural, loss, or regularization
differences. We conduct thorough experimental evaluations on various benchmark
datasets for image generation. The results show that our annealed CFG and NATS
methods significantly improve the quality and diversity of the synthesized
samples. This improvement is clear when comparing the CFG method and the SOTA
GAN models.",http://arxiv.org/abs/2501.11318v1
"StyleSSP: Sampling StartPoint Enhancement for Training-free
  Diffusion-based Method for Style Transfer",2025-01-20T07:45:42Z,"Ruojun Xu, Weijie Xi, Xiaodi Wang, Yongbo Mao, Zach Cheng","Training-free diffusion-based methods have achieved remarkable success in
style transfer, eliminating the need for extensive training or fine-tuning.
However, due to the lack of targeted training for style information extraction
and constraints on the content image layout, training-free methods often suffer
from layout changes of original content and content leakage from style images.
Through a series of experiments, we discovered that an effective startpoint in
the sampling stage significantly enhances the style transfer process. Based on
this discovery, we propose StyleSSP, which focuses on obtaining a better
startpoint to address layout changes of original content and content leakage
from style image. StyleSSP comprises two key components: (1) Frequency
Manipulation: To improve content preservation, we reduce the low-frequency
components of the DDIM latent, allowing the sampling stage to pay more
attention to the layout of content images; and (2) Negative Guidance via
Inversion: To mitigate the content leakage from style image, we employ negative
guidance in the inversion stage to ensure that the startpoint of the sampling
stage is distanced from the content of style image. Experiments show that
StyleSSP surpasses previous training-free style transfer baselines,
particularly in preserving original content and minimizing the content leakage
from style image.",http://arxiv.org/abs/2501.11319v1
"Hybrid Adaptive Modeling using Neural Networks Trained with Nonlinear
  Dynamics Based Features",2025-01-21T02:38:28Z,"Zihan Liu, Prashant N. Kambali, C. Nataraj","Accurate models are essential for design, performance prediction, control,
and diagnostics in complex engineering systems. Physics-based models excel
during the design phase but often become outdated during system deployment due
to changing operational conditions, unknown interactions, excitations, and
parametric drift. While data-based models can capture the current state of
complex systems, they face significant challenges, including excessive data
dependence, limited generalizability to changing conditions, and inability to
predict parametric dependence. This has led to combining physics and data in
modeling, termed physics-infused machine learning, often using numerical
simulations from physics-based models. This paper introduces a novel approach
that departs from standard techniques by uncovering information from nonlinear
dynamical modeling and embedding it in data-based models. The goal is to create
a hybrid adaptive modeling framework that integrates data-based modeling with
newly measured data and analytical nonlinear dynamical models for enhanced
accuracy, parametric dependence, and improved generalizability. By explicitly
incorporating nonlinear dynamic phenomena through perturbation methods, the
predictive capabilities are more realistic and insightful compared to knowledge
obtained from brute-force numerical simulations. In particular, perturbation
methods are utilized to derive asymptotic solutions which are parameterized to
generate frequency responses. Frequency responses provide comprehensive
insights into dynamics and nonlinearity which are quantified and extracted as
high-quality features. A machine-learning model, trained by these features,
tracks parameter variations and updates the mismatched model. The results
demonstrate that this adaptive modeling method outperforms numerical gray box
models in prediction accuracy and computational efficiency.",http://arxiv.org/abs/2501.11835v1
"Integrate Temporal Graph Learning into LLM-based Temporal Knowledge
  Graph Model",2025-01-21T06:12:49Z,"He Chang, Jie Wu, Zhulin Tao, Yunshan Ma, Xianglin Huang, Tat-Seng Chua","Temporal Knowledge Graph Forecasting (TKGF) aims to predict future events
based on the observed events in history. Recently, Large Language Models (LLMs)
have exhibited remarkable capabilities, generating significant research
interest in their application for reasoning over temporal knowledge graphs
(TKGs). Existing LLM-based methods have integrated retrieved historical facts
or static graph representations into LLMs. Despite the notable performance of
LLM-based methods, they are limited by the insufficient modeling of temporal
patterns and ineffective cross-modal alignment between graph and language,
hindering the ability of LLMs to fully grasp the temporal and structural
information in TKGs. To tackle these issues, we propose a novel framework
TGL-LLM to integrate temporal graph learning into LLM-based temporal knowledge
graph model. Specifically, we introduce temporal graph learning to capture the
temporal and relational patterns and obtain the historical graph embedding.
Furthermore, we design a hybrid graph tokenization to sufficiently model the
temporal patterns within LLMs. To achieve better alignment between graph and
language, we employ a two-stage training paradigm to finetune LLMs on
high-quality and diverse data, thereby resulting in better performance.
Extensive experiments on three real-world datasets show that our approach
outperforms a range of state-of-the-art (SOTA) methods.",http://arxiv.org/abs/2501.11911v1
"Generalized Bond Polarizability model for more accurate atomistic
  modeling of Raman spectra",2025-01-21T11:29:55Z,"Atanu Paul, Nagaprasad Reddy Samala, Ilya Grinberg","Raman spectroscopy is an important tool for studies of molecules, liquids and
solids. While Raman spectra can be obtained theoretically from molecular
dynamics (MD) simulations, this requires the calculation of the electronic
polarizability along the simulation trajectory. First-principles calculations
of electronic polarizability are computationally expensive, motivating the
development of atomistic models for the evaluation of the changes in the
electronic polarizability with the changes in the atomic coordinates of the
system. The bond polarizability model (BPM) is one of the oldest and simplest
such atomistic models, but cannot reproduce the effects of angular vibrations,
leading to inaccurate modeling of Raman spectra. Here, we demonstrate that the
generalization of BPM through inclusion of terms for atom pairs that are
traditionally considered to be not involved in bonding dramatically improves
the accuracy of polarizability modeling and Raman spectra calculations. The
generalized BPM (GBPM) reproduces the ab initio polarizability and Raman
spectra for a range of tested molecules (SO2, H2S, H2O, NH3, CH4, CH3OH and
CH3CH2OH) with high accuracy and also shows significantly improved agreement
with ab initio results for the more complex ferroelectric BaTiO3 systems. For
liquid water, the anisotropic Raman spectrum derived from atomistic MD
simulations using GBPM evaluation of polarizability shows significantly
improved agreement with the experimental spectrum compared to the spectrum
derived using BPM. Thus, GBPM can be used for the modeling of Raman spectra
using large-scale molecular dynamics and provides a good basis for the further
development of atomistic polarizability models.",http://arxiv.org/abs/2501.12059v1
"Thermodynamics of $s_{\pm}-to-s_{++}$ transition in iron pnictides in
  the vicinity of the Born limit",2025-01-22T09:05:54Z,"Vadim Shestakov, Maxim M. Korshunov","To study thermodynamical properties of the disorder-induced transition
between $s_{\pm}$ and $s_{++}$ superconducting gap functions, we calculate the
grand thermodynamic potential $\Omega$ in the normal and the superconducting
states. Expression for the difference between the two, $\Delta\Omega$, is
derived for a two-band model for Fe-based systems with nonmagnetic impurities.
The disorder is considered in a $\mathcal{T}$-matrix approximation within the
multiband Eliashberg theory. In the vicinity of the Born limit near the
$s_{\pm}$-to-$s_{++}$ transition, we find two solutions obtained for opposite
directions of the system's evolution with respect to the impurity scattering
rate. By calculating the change in entropy $\Delta S$ and the change in
electronic specific heat $\Delta C$ from $\Delta\Omega$, we show that such a
hysteresis is not due to the time-reversal symmetry breaking state, but it
rather points out to the first order phase transition induced by the
nonmagnetic disorder. Based on the $\Delta\Omega$ calculations, phase diagram
is plotted representing the energetically favourable $s_{\pm}$ and $s_{++}$
states and the transition between them. At finite temperature, a first order
phase transition line there is limited by a critical end point. Above that
point, the sharp $s_{\pm} \to s_{++}$ transition transforms to a crossover
between $s_{\pm}$ and $s_{++}$ states.",http://arxiv.org/abs/2501.12730v1
"Exploring the Technology Landscape through Topic Modeling, Expert
  Involvement, and Reinforcement Learning",2025-01-22T22:18:50Z,"Ali Nazari, Michael Weiss","In today's rapidly evolving technological landscape, organizations face the
challenge of integrating external insights into their decision-making processes
to stay competitive. To address this issue, this study proposes a method that
combines topic modeling, expert knowledge inputs, and reinforcement learning
(RL) to enhance the detection of technological changes. The method has four
main steps: (1) Build a relevant topic model, starting with textual data like
documents and reports to find key themes. (2) Create aspect-based topic models.
Experts use curated keywords to build models that showcase key domain-specific
aspects. (3) Iterative analysis and RL driven refinement: We examine metrics
such as topic magnitude, similarity, entropy shifts, and how models change over
time. We optimize topic selection with RL. Our reward function balances the
diversity and similarity of the topics. (4) Synthesis and operational
integration: Each iteration provides insights. In the final phase, the experts
check these insights and reach new conclusions. These conclusions are designed
for use in the firm's operational processes. The application is tested by
forecasting trends in quantum communication. Results demonstrate the method's
effectiveness in identifying, ranking, and tracking trends that align with
expert input, providing a robust tool for exploring evolving technological
landscapes. This research offers a scalable and adaptive solution for
organizations to make informed strategic decisions in dynamic environments.",http://arxiv.org/abs/2501.13252v2
"Pseudocode-Injection Magic: Enabling LLMs to Tackle Graph Computational
  Tasks",2025-01-23T15:04:22Z,"Chang Gong, Wanrui Bian, Zhijie Zhang, Weiguo Zheng","Graph computational tasks are inherently challenging and often demand the
development of advanced algorithms for effective solutions. With the emergence
of large language models (LLMs), researchers have begun investigating their
potential to address these tasks. However, existing approaches are constrained
by LLMs' limited capability to comprehend complex graph structures and their
high inference costs, rendering them impractical for handling large-scale
graphs. Inspired by human approaches to graph problems, we introduce a novel
framework, PIE (Pseudocode-Injection-Enhanced LLM Reasoning for Graph
Computational Tasks), which consists of three key steps: problem understanding,
prompt design, and code generation. In this framework, LLMs are tasked with
understanding the problem and extracting relevant information to generate
correct code. The responsibility for analyzing the graph structure and
executing the code is delegated to the interpreter. We inject task-related
pseudocodes into the prompts to further assist the LLMs in generating efficient
code. We also employ cost-effective trial-and-error techniques to ensure that
the LLM-generated code executes correctly. Unlike other methods that require
invoking LLMs for each individual test case, PIE only calls the LLM during the
code generation phase, allowing the generated code to be reused and
significantly reducing inference costs. Extensive experiments demonstrate that
PIE outperforms existing baselines in terms of both accuracy and computational
efficiency.",http://arxiv.org/abs/2501.13731v1
Molecular origins of colossal barocaloric effects in plastic crystals,2025-01-24T11:17:15Z,"Ares Sanuy, Carlos Escorihuela-Sayalero, Pol Lloveras, Josep Lluis Tamarit, Luis Carlos Pardo, Claudio Cazorla","In recent years, orientationally disordered crystals, or plastic crystals,
have transformed the field of solid-state cooling due to the significant latent
heat and entropy changes associated with their temperature induced molecular
order-disorder phase transition, which can produce colossal caloric effects
under external field stimuli. However, the molecular mechanisms underlying
these huge caloric effects remain inadequately understood, and general
principles for enhancing the performance of caloric plastic crystals are
lacking. Previous studies have predominantly focused on molecular rotations,
overlooking other potentially critical factors, such as lattice vibrations and
molecular conformations. In this study, we employ classical molecular dynamics
(MD) simulations to both replicate and elucidate the microscopic origins of the
experimentally observed colossal barocaloric (BC) effects -- those driven by
hydrostatic pressure -- in the archetypal plastic crystal neopentyl glycol
(NPG). Our MD simulations demonstrate that in NPG, the combined BC response and
phase-transition entropy changes arising from lattice vibrations and molecular
conformations are nearly equal to those from molecular reorientations,
contributing 45% and 55%, respectively. These findings suggest that, alongside
hydrogen bonding -- which directly impacts molecular rotational dynamics --
lattice vibrational and molecular structural features, often overlooked, must
be integrated into the rational design and modeling of advanced caloric plastic
crystals. These insights are not only of significant fundamental interest but
also essential for driving the development of next-generation solid-state
refrigeration technologies.",http://arxiv.org/abs/2501.14403v1
Optimal Strategies for Federated Learning Maintaining Client Privacy,2025-01-24T12:34:38Z,"Uday Bhaskar, Varul Srivastava, Avyukta Manjunatha Vummintala, Naresh Manwani, Sujit Gujar","Federated Learning (FL) emerged as a learning method to enable the server to
train models over data distributed among various clients. These clients are
protective about their data being leaked to the server, any other client, or an
external adversary, and hence, locally train the model and share it with the
server rather than sharing the data. The introduction of sophisticated
inferencing attacks enabled the leakage of information about data through
access to model parameters. To tackle this challenge, privacy-preserving
federated learning aims to achieve differential privacy through learning
algorithms like DP-SGD. However, such methods involve adding noise to the
model, data, or gradients, reducing the model's performance.
  This work provides a theoretical analysis of the tradeoff between model
performance and communication complexity of the FL system. We formally prove
that training for one local epoch per global round of training gives optimal
performance while preserving the same privacy budget. We also investigate the
change of utility (tied to privacy) of FL models with a change in the number of
clients and observe that when clients are training using DP-SGD and argue that
for the same privacy budget, the utility improved with increased clients. We
validate our findings through experiments on real-world datasets. The results
from this paper aim to improve the performance of privacy-preserving federated
learning systems.",http://arxiv.org/abs/2501.14453v1
"Explaining Categorical Feature Interactions Using Graph Covariance and
  LLMs",2025-01-24T21:41:26Z,"Cencheng Shen, Darren Edge, Jonathan Larson, Carey E. Priebe","Modern datasets often consist of numerous samples with abundant features and
associated timestamps. Analyzing such datasets to uncover underlying events
typically requires complex statistical methods and substantial domain
expertise. A notable example, and the primary data focus of this paper, is the
global synthetic dataset from the Counter Trafficking Data Collaborative (CTDC)
-- a global hub of human trafficking data containing over 200,000 anonymized
records spanning from 2002 to 2022, with numerous categorical features for each
record. In this paper, we propose a fast and scalable method for analyzing and
extracting significant categorical feature interactions, and querying large
language models (LLMs) to generate data-driven insights that explain these
interactions. Our approach begins with a binarization step for categorical
features using one-hot encoding, followed by the computation of graph
covariance at each time. This graph covariance quantifies temporal changes in
dependence structures within categorical data and is established as a
consistent dependence measure under the Bernoulli distribution. We use this
measure to identify significant feature pairs, such as those with the most
frequent trends over time or those exhibiting sudden spikes in dependence at
specific moments. These extracted feature pairs, along with their timestamps,
are subsequently passed to an LLM tasked with generating potential explanations
of the underlying events driving these dependence changes. The effectiveness of
our method is demonstrated through extensive simulations, and its application
to the CTDC dataset reveals meaningful feature pairs and potential data stories
underlying the observed feature interactions.",http://arxiv.org/abs/2501.14932v1
"Automatic Link Selection in Multi-Channel Multiple Access with Link
  Failures",2025-01-24T23:09:31Z,"Mevan Wijewardena, Michael J. Neely","This paper focuses on the problem of automatic link selection in
multi-channel multiple access control using bandit feedback. In particular, a
controller assigns multiple users to multiple channels in a time slotted
system, where in each time slot at most one user can be assigned to a given
channel and at most one channel can be assigned to a given user. Given that
user $i$ is assigned to channel $j$, the transmission fails with a fixed
probability $f_{i,j}$. The failure probabilities are not known to the
controller. The assignments are made dynamically using success/failure
feedback. The goal is to maximize the time average utility, where we consider
an arbitrary (possibly nonsmooth) concave and entrywise nondecreasing utility
function. The problem of merely maximizing the total throughput has a solution
of always assigning the same user-channel pairs and can be unfair to certain
users, particularly when the number of channels is less than the number of
users. Instead, our scheme allows various types of fairness, such as
proportional fairness, maximizing the minimum, or combinations of these by
defining the appropriate utility function. We propose two algorithms for this
task. The first algorithm is adaptive and gets within
$\mathcal{O}(\log(T)/T^{1/3})$ of optimality over any interval of $T$
consecutive slots over which the success probabilities do not change. The
second algorithm has faster $\mathcal{O}(\sqrt{\log(T)/T})$ performance over
the first $T$ slots, but does not adapt well if probabilities change.",http://arxiv.org/abs/2501.14971v1
Probing ALP couplings to electroweak gauge bosons,2025-01-25T15:44:36Z,"Jin Sun, Zhi-Peng Xing, Seokhoon Yun","Motivated by the more and more abundant experimental data, we revisit the
couplings of axion-like particle (ALP) to electroweak gauge bosons across the
ALP mass range from MeV to 100 GeV. The current and future experimental limits
on the couplings are extended. The ALP coupling to $W$-bosons gives rise to
flavor-changing ALP-quark couplings at the one-loop level. These
flavor-changing couplings deserve further investigation under current
experimental constraints, especially those stemming from rare meson decays and
neutral meson mixing processes. Additionally, flavor-conserving couplings of
the ALP to Standard Model (SM) fermions arise at the one-loop level as well
from ALP-electroweak gauge boson couplings, even in the absence of tree-level
couplings to these SM fermions, with consequent ALP decays to the SM fermions
leading to constraints on the ALP-electroweak gauge boson couplings. We also
investigate processes relevant to $Z$-boson measurements, such as the invisible
decay $Z\to a\gamma$, subsequent decays
  $Z\to 3\gamma$ and $Z\to \gamma ll$, as well as constraints from oblique
parameters ($S,\, T,\, U$). Our study highlights that rare two-body decays of
pseudoscalar mesons offer the most sensitive probes of ALP couplings to
electroweak gauge bosons from the loop-induced flavor-violating interactions
for ALP masses below the kinematic threshold, while $Z$-boson decays
complementarily explore larger ALP masses. Future lepton colliders, such as
CEPC and FCC-ee operating at the $Z$-pole, along with SHiP, provide further
opportunities to probe ALP couplings to electroweak gauge bosons.",http://arxiv.org/abs/2501.15250v2
"Tracing the Lifecycle of Architecture Technical Debt in Software
  Systems: A Dependency Approach",2025-01-26T03:58:57Z,"Edi Sutoyo, Paris Avgeriou, Andrea Capiluppi","Architectural technical debt (ATD) represents trade-offs in software
architecture that accelerate initial development but create long-term
maintenance challenges. ATD, in particular when self-admitted, impacts the
foundational structure of software, making it difficult to detect and resolve.
This study investigates the lifecycle of ATD, focusing on how it affects i) the
connectivity between classes and ii) the frequency of file modifications. We
aim to understand how ATD evolves from introduction to repayment and its
implications on software architectures. Our empirical approach was applied to a
dataset of SATD from various software artifacts. We isolated ATD instances,
filtered for architectural indicators, and calculated dependencies at different
lifecycle stages using FAN-IN and FAN-OUT metrics. Statistical analyses,
including the Mann-Whitney U test and Cohen's d, were used to assess the
significance and effect size of connectivity and dependency changes over time.
We observed that ATD repayment increased class connectivity, with FAN-IN
increasing by 57.5% on average and FAN-OUT by 26.7%, suggesting a shift toward
centralization and increased architectural complexity post-repayment. Moreover,
ATD files were modified less frequently than Non-ATD files, with changes
accumulated in high-dependency portions of the code. Our study shows that
resolving ATD improves software quality in the short-term, but can make the
architecture more complex by centralizing dependencies. Also, even if
dependency metrics (like FAN-IN and FAN-OUT) can help understand the impact of
ATD, they should be combined with other measures to capture other effects of
ATD on software maintainability.",http://arxiv.org/abs/2501.15387v1
"The Potential of Large Language Models in Supply Chain Management:
  Advancing Decision-Making, Efficiency, and Innovation",2025-01-26T05:41:50Z,"Raha Aghaei, Ali A. Kiaei, Mahnaz Boush, Javad Vahidi, Zeynab Barzegar, Mahan Rofoosheh","The integration of large language models (LLMs) into supply chain management
(SCM) is revolutionizing the industry by improving decision-making, predictive
analytics, and operational efficiency. This white paper explores the
transformative impact of LLMs on various SCM functions, including demand
forecasting, inventory management, supplier relationship management, and
logistics optimization. By leveraging advanced data analytics and real-time
insights, LLMs enable organizations to optimize resources, reduce costs, and
improve responsiveness to market changes. Key findings highlight the benefits
of integrating LLMs with emerging technologies such as IoT, blockchain, and
robotics, which together create smarter and more autonomous supply chains.
Ethical considerations, including bias mitigation and data protection, are
taken into account to ensure fair and transparent AI practices. In addition,
the paper discusses the need to educate the workforce on how to manage new
AI-driven processes and the long-term strategic benefits of adopting LLMs.
Strategic recommendations for SCM professionals include investing in
high-quality data management, promoting cross-functional collaboration, and
aligning LLM initiatives with overall business goals. The findings highlight
the potential of LLMs to drive innovation, sustainability, and competitive
advantage in the ever-changing supply chain management landscape.",http://arxiv.org/abs/2501.15411v1
"Efficiency Bottlenecks of Convolutional Kolmogorov-Arnold Networks: A
  Comprehensive Scrutiny with ImageNet, AlexNet, LeNet and Tabular
  Classification",2025-01-27T04:00:05Z,"Ashim Dahal, Saydul Akbar Murad, Nick Rahimi","Algorithmic level developments like Convolutional Neural Networks,
transformers, attention mechanism, Retrieval Augmented Generation and so on
have changed Artificial Intelligence. Recent such development was observed by
Kolmogorov-Arnold Networks that suggested to challenge the fundamental concept
of a Neural Network, thus change Multilayer Perceptron, and Convolutional
Neural Networks. They received a good reception in terms of scientific
modeling, yet had some drawbacks in terms of efficiency. In this paper, we
train Convolutional Kolmogorov Arnold Networks (CKANs) with the ImageNet-1k
dataset with 1.3 million images, MNIST dataset with 60k images and a tabular
biological science related MoA dataset and test the promise of CKANs in terms
of FLOPS, Inference Time, number of trainable parameters and training time
against the accuracy, precision, recall and f-1 score they produce against the
standard industry practice on CNN models. We show that the CKANs perform fair
yet slower than CNNs in small size dataset like MoA and MNIST but are not
nearly comparable as the dataset gets larger and more complex like the
ImageNet. The code implementation of this paper can be found on the link:
\href{https://github.com/ashimdahal/Study-of-Convolutional-Kolmogorov-Arnold-networks}{https://github.com/ashimdahal/Study-of-Convolutional-Kolmogorov-Arnold-networks}",http://arxiv.org/abs/2501.15757v2
Observables for the Effect of Gravity on Electromagnetic Polarization,2025-01-27T08:13:15Z,Kjell Tangen,"Does gravity affect the polarization of electromagnetic radiation in an
observable way? The effect of gravity on the observed polarization of a ray of
electromagnetic radiation is investigated for an arbitrary 4-dimensional
spacetime and radiation with a frequency spectrum within the geometric optics
limit and with arbitrary state of polarization. Focusing on effects observable
by a single inertial observer, we show how the presence of curvature along the
null geodesic of polarized electromagnetic radiation may induce observable
changes in the state of polarization. We find a set of scalars that quantify
the effect and derive their transport equations. Two of these scalars, the
polarization degree and the circular polarization degree, are polarization
state observables that are conserved along the radiation geodesic. Four
observables that quantify time rate of change of the observed state of
polarization are identified. These observables and their corresponding
transport equations provide a complete representation of how gravity affects
the observed state of polarization of electromagnetic radiation with
frequencies above the geometric optics limit. Polarization wiggling is sourced
by curvature twist, which is a scalar derived from the Riemann tensor.
Curvature twist is closely related to the magnetic part of the Weyl tensor, the
second Weyl scalar as well as the rotation of the rest frame geodesic
congruence. The results of this paper are valid for any metric theory of
gravity.",http://arxiv.org/abs/2501.15846v1
Probability of earthquake fault jumps from physics based criterion,2025-01-27T10:52:18Z,"Sylvain Michel, Oona Scotti, Sebastien Hok, Harsha S. Bhat, Navid Kheirdast, Pierre Romanet, Michelle Almakari, Jinhui Cheng","Geometrical complexities in natural fault zones, such as steps and gaps, pose
a challenge in seismic hazard studies as they can act as barriers to seismic
ruptures. In this study, we propose a criterion, which is based on the
rate-and-state equation, to estimate the efficiency of an earthquake rupture to
jump two spatially disconnected faults. The proposed jump criterion is tested
using a 2D quasi-dynamic numerical simulations of the seismic cycle. The
criterion successfully predicts fault jumps where the coulomb stress change
fails to do so. The criterion includes the coulomb stress change as a parameter
but is also dependent on other important parameters among which the absolute
normal stress on the fault which the rupture is to jump to. Based on the
criterion, the maximum jump distance increases with decreasing absolute normal
stress, i.e. as the rupture process occurs closer to the surface or as pore
pressure increases. The criterion implies that an earthquake can jump to an
infinite distance at the surface if the normal stress is allowed to go to zero.
Thus, the properties of the surface layers are of the outmost importance in
terms of maximum rupture jump distance allowed. The absolute normal stress is
the main controlling parameter followed by the uncertainty on the slip of an
earthquake, which controls the coulomb stress impact on the receiver fault.
Finally, we also propose a method to compute probabilities of earthquakes
rupture to jump, which allows to consider uncertainties in geometrical
configurations between two faults.",http://arxiv.org/abs/2501.15948v1
"Effect of Numerical Resolution on Synthetic Observables of Simulated
  Coronal Loops",2025-01-27T18:34:11Z,"Cosima Alexandra Breu, Ineke De Moortel, Hardi Peter, Sami Khan Solanki","Increasingly realistic simulations of the corona are used to predict
synthetic observables for instruments onboard both existing and upcoming
heliophysics space missions. Synthetic observables play an important role in
constraining coronal heating theories. Choosing the spatial resolution of
numerical simulations involves a trade-off between accuracy and computational
cost. Since the numerical resolution not only affects the scale of structures
that can be resolved, but also thermodynamic quantities such as the average
coronal density, it is important to quantify the effect on synthesized
observables. Using 3D radiative MHD simulations of coronal loops at three
different grid spacings, from 60 km down to 12 km, we find that changes in
numerical resolution lead to differences in thermodynamic quantities and
stratification as well as dynamic behaviour. Higher grid resolution results in
a more complex and dynamic atmosphere. The resolution affects the emission
intensity as well as the velocity distribution, thereby affecting synthetic
spectra derived from the simulation. The distribution of synthetic coronal loop
strand sizes changes as more fine-scale structure is resolved. A number of
parameters, however, seem to start to saturate from our chosen medium grid
resolution on. Our study shows that while choosing a sufficiently high
resolution matters when comparing forward-modelled observables with data from
current and future space missions, for most purposes not much is gained by
further increasing the resolution beyond a grid spacing of 24 km, which seems
to be adequate for reproducing bulk loop properties and forward-modelled
emission, representing a good trade-off between accuracy and computational
resource.",http://arxiv.org/abs/2501.16293v1
"Stable Tree Labelling for Accelerating Distance Queries on Dynamic Road
  Networks",2025-01-29T02:25:18Z,"Henning Koehler, Muhammad Farhan, Qing Wang","Finding the shortest-path distance between two arbitrary vertices is an
important problem in road networks. Due to real-time traffic conditions, road
networks undergo dynamic changes all the time. Current state-of-the-art methods
incrementally maintain a distance labelling based on a hierarchy among vertices
to support efficient distance computation. However, their labelling sizes are
often large and cannot be efficiently maintained. To combat these issues, we
present a simple yet efficient labelling method, namely \emph{Stable Tree
Labelling} (STL), for answering distance queries on dynamic road networks. We
observe that the properties of an underlying hierarchy play an important role
in improving and balancing query and update performance. Thus, we introduce the
notion of \emph{stable tree hierarchy} which lays the ground for developing
efficient maintenance algorithms on dynamic road networks. Based on stable tree
hierarchy, STL can be efficiently constructed as a 2-hop labelling. A crucial
ingredient of STL is to only store distances within subgraphs in labels, rather
than distances in the entire graph, which restricts the labels affected by
dynamic changes. We further develop two efficient maintenance algorithms upon
STL: \emph{Label Search algorithm} and \emph{Pareto Search algorithm}. Label
Search algorithm identifies affected ancestors in a stable tree hierarchy and
performs efficient searches to update labels from those ancestors. Pareto
Search algorithm explores the interaction between search spaces of different
ancestors, and combines searches from multiple ancestors into only two searches
for each update, eliminating duplicate graph traversals. The experiments show
that our algorithms significantly outperform state-of-the-art dynamic methods
in maintaining the labelling and query processing, while requiring an order of
magnitude less space.",http://arxiv.org/abs/2501.17379v1
Reqo: A Robust and Explainable Query Optimization Cost Model,2025-01-29T04:48:51Z,"Baoming Chang, Amin Kamali, Verena Kantere","In recent years, there has been a growing interest in using machine learning
(ML) in query optimization to select more efficient plans. Existing
learning-based query optimizers use certain model architectures to convert
tree-structured query plans into representations suitable for downstream ML
tasks. As the design of these architectures significantly impacts cost
estimation, we propose a tree model architecture based on Bidirectional Graph
Neural Networks (Bi-GNN) aggregated by Gated Recurrent Units (GRUs) to achieve
more accurate cost estimates. The inherent uncertainty of data and model
parameters also leads to inaccurate cost estimates, resulting in suboptimal
plans and less robust query performance. To address this, we implement a novel
learning-to-rank cost model that effectively quantifies the uncertainty in cost
estimates using approximate probabilistic ML. This model adaptively integrates
quantified uncertainty with estimated costs and learns from comparing pairwise
plans, achieving more robust performance. In addition, we propose the first
explainability technique specifically designed for learning-based cost models.
This technique explains the contribution of any subgraphs in the query plan to
the final predicted cost, which can be integrated and trained with any
learning-based cost model to significantly boost the model's explainability. By
incorporating these innovations, we propose a cost model for a Robust and
Explainable Query Optimizer, Reqo, that improves the accuracy, robustness, and
explainability of cost estimation, outperforming state-of-the-art approaches in
all three dimensions.",http://arxiv.org/abs/2501.17414v1
"Nuclear Electric Resonance for Spatially-Resolved Spin Control via
  Pulsed Optical Excitation in the UV-Visible Spectrum",2025-01-29T11:21:39Z,"Johannes K. Krondorfer, Andreas W. Hauser","Nuclear electric resonance (NER) spectroscopy is currently experiencing a
revival as a tool for nuclear spin-based quantum computing. Compared to
magnetic or electric fields, local electron density fluctuations caused by
changes in the atomic environment provide a much higher spatial resolution for
the addressing of nuclear spins in qubit registers or within a single molecule.
In this article, we investigate the possibility of coherent spin control in
atoms or molecules via nuclear quadrupole resonance from first principles. An
abstract, time-dependent description is provided which entails and reflects on
commonly applied approximations. This formalism is then used to propose a new
method we refer to as `optical' nuclear electric resonance (ONER). It employs
pulsed optical excitations in the UV-visible light spectrum to modulate the
electric field gradient at the position of a specific nucleus of interest by
periodic changes of the surrounding electron density. Possible realizations and
limitations of ONER for atomically resolved spin manipulation are discussed and
tested on $^9$Be as an atomic benchmark system via electronic structure theory.",http://arxiv.org/abs/2501.17575v1
"Variations of absolute source positions determined from quad-band VLBI
  observations",2025-01-30T11:28:40Z,"Ming Hui Xu, Patrick Charlot","Active Galactic Nuclei (AGNs) observed with the technique of very long
baseline interferometry (VLBI) are used as fiducial references on the sky to
precisely measure the shape and orientation of the Earth. Their positions form
a celestial reference frame that plays an important role in both astronomy and
geodesy. This study investigates the accuracy and stability of the positions of
the AGNs that are measured by simultaneous VLBI observations at 3.3, 5.5, 6.6,
and 10.5 GHz. Based on position time series from dedicated geodetic solutions,
we characterize the observed source position variations and identify the
possible factors causing such variations. We find that the primary contributor
is source structure for sources above 20-degree declination while the
sensitivity of the observations to the declination coordinate predominates for
sources below 20-degree declination. The position time series are further
explored to derive more realistic uncertainties for the quad-band positions.
Significant position offsets with respect to the positions at 2.2/8.6 GHz are
found for 15% of the sources. For 6% of the sources, the offsets are larger
than 0.8 milli-arcseconds. Source structure may be divided into two parts: the
invisible structure (within the beam size) and the visible structure (on larger
scales). The latter causes closure delays enlarging post-fit delay residuals in
geodetic solutions whereas the former causes source position changes. Such
position changes will contribute significantly to the offsets between radio and
optical positions. Overall, this work highlights the necessity to have a
specific quad-band catalog for processing operational quad-band observations.",http://arxiv.org/abs/2501.18276v1
"Characterization of NBI-driven shear Alfvén waves in the TJ-II
  stellarator using Mirnov probes and electrostatic potential fluctuation
  measurements",2025-01-30T17:51:29Z,"P. Pons-Villalonga, Á. Cappa, E. Ascasíbar, O. S. Kozachok, M. B. Dreval, K. J. McCarthy, J. de la Riva Villén, J. Martínez-Fernández, TJ-II Team","We present the first experimental measurements of the toroidal mode number of
shear Alfv\'en waves in the TJ-II stellarator. A series of experiments were
carried out in three different magnetic configurations to investigate
counter-NBI driven modes. Co- and counter- electron-cyclotron current drive was
used to modify the rotational transform ($\iota/2\pi$) profile leading to the
destabilization of a varied set of Alfv\'en eigenmodes with different
frequencies and mode numbers. To characterize the spatial structure of the
modes we have used two Mirnov probe arrays, one dedicated to the measurement of
the poloidal mode number and the other, a recently commissioned helical
tri-axial array, dedicated to the measurement of the toroidal mode number. A
heavy ion beam probe, operated in radial sweep mode, was employed to
characterize the radial location of the modes. We show that the induced changes
in $\iota/2\pi$, that are fundamental when it comes to validation studies,
cannot be measured experimentally with motional Stark effect so, instead, the
shielding current diffusion equation is solved in cylindrical geometry to
estimate these changes. We calculate the incompressible shear Alfv\'en
continuum for selected cases using \texttt{STELLGAP} and find reasonable
consistency with observations. A database with the observed modes has been
created, so that it can be used in future work for theory validation purposes.",http://arxiv.org/abs/2501.18529v1
"BounTCHA: A CAPTCHA Utilizing Boundary Identification in AI-extended
  Videos",2025-01-30T18:38:09Z,"Lehao Lin, Ke Wang, Maha Abdallah, Wei Cai","In recent years, the rapid development of artificial intelligence (AI)
especially multi-modal Large Language Models (MLLMs), has enabled it to
understand text, images, videos, and other multimedia data, allowing AI systems
to execute various tasks based on human-provided prompts. However, AI-powered
bots have increasingly been able to bypass most existing CAPTCHA systems,
posing significant security threats to web applications. This makes the design
of new CAPTCHA mechanisms an urgent priority. We observe that humans are highly
sensitive to shifts and abrupt changes in videos, while current AI systems
still struggle to comprehend and respond to such situations effectively. Based
on this observation, we design and implement BounTCHA, a CAPTCHA mechanism that
leverages human perception of boundaries in video transitions and disruptions.
By utilizing AI's capability to expand original videos with prompts, we
introduce unexpected twists and changes to create a pipeline for generating
short videos for CAPTCHA purposes. We develop a prototype and conduct
experiments to collect data on humans' time biases in boundary identification.
This data serves as a basis for distinguishing between human users and bots.
Additionally, we perform a detailed security analysis of BounTCHA,
demonstrating its resilience against various types of attacks. We hope that
BounTCHA will act as a robust defense, safeguarding millions of web
applications in the AI-driven era.",http://arxiv.org/abs/2501.18565v1
"A Radiance Field Loss for Fast and Simple Emissive Surface
  Reconstruction",2025-01-27T13:30:51Z,"Ziyi Zhang, Nicolas Roussel, Thomas Müller, Tizian Zeltner, Merlin Nimier-David, Fabrice Rousselle, Wenzel Jakob","We present a fast and simple technique to convert images into an emissive
surface-based scene representation. Building on existing emissive volume
reconstruction algorithms, we introduce a subtle yet impactful modification of
the loss function requiring changes to only a few lines of code: instead of
integrating the radiance field along rays and supervising the resulting images,
we project the training images into the scene to directly supervise the
spatio-directional radiance field.
  The primary outcome of this change is the complete removal of alpha blending
and ray marching from the image formation model, instead moving these steps
into the loss computation. In addition to promoting convergence to surfaces,
this formulation assigns explicit semantic meaning to 2D subsets of the
radiance field, turning them into well-defined emissive surfaces. We finally
extract a level set from this representation, which results in a high-quality
emissive surface model.
  Our method retains much of the speed and quality of the baseline algorithm.
For instance, a suitably modified variant of Instant~NGP maintains comparable
computational efficiency, while achieving an average PSNR that is only 0.1 dB
lower. Most importantly, our method generates explicit surfaces in place of an
exponential volume, doing so with a level of simplicity not seen in prior work.",http://arxiv.org/abs/2501.18627v1
"First-order phase transitions in the heavy quark region of lattice QCD
  at high temperatures and high densities",2025-01-31T00:48:25Z,Shinji Ejiri,"If there is a first-order phase transition in the light quark region of
2+1-flavor finite temperature and density QCD and if the region of the
first-order phase transition expands with increasing density as suggested by
several studies, then, at very high densities, we may expect that the
first-order phase transition region expands into the heavy quark region of QCD,
where we can perform efficient large scale simulations by adopting an effective
theory of heavy quark QCD based on the hopping parameter expansion. In the
heavy quark region of QCD, we have another first-order phase transition region
around the heavy quark limit at zero density. By numerical simulations of
effective heavy quark QCD, we found that, the first-order transition at zero
density turns into a crossover as the chemical potential is increased, but,
when we increase the chemical potential further, the change in the plaquette
value near the crossover point becomes much steeper. This may be suggesting
reappearance of the first-order phase transition. In this talk, we first show
the nature of the phase transition of phase-quenched finite density QCD in the
heavy quark region and then study the effect of the complex phase to discuss
whether the QCD phase transition changes again to a first-order phase
transition at very high densities.",http://arxiv.org/abs/2501.18828v1
"Quantum effects in surface diffusion: application to diffusion of
  nitrogen adatoms over GaN(0001) surface",2025-01-31T12:10:14Z,"Paweł Strak, Cyprian Sobczak, Stanislaw Krukowski","It is shown that quantum effects play determining role in nitrogen adatom
diffusion due to several different factors. This could be related to the change
of the energy of the quantum states and also due to the redistribution of
electrons between the quantum states, both full and resonant, via quantum
statistics partially governed by the Fermi energy level. These effects were
studied in the case of nitrogen diffusion over clean and gallium covered
Ga-terminated GaN(0001) surface. For the fractional coverage the density
functional theory (DFT) calculations show that at the saddle point
configuration the redistribution of electrons between different quantum states
may affect the surface diffusion barrier significantly. The other quantum
influence occurs via the change of the minimal energy configuration. Under
fractional Ga coverage of GaN(0001) surface the nitrogen diffusion energy
barrier proceeds from the resonant states governed energy minimal H3 site
across the saddle point in the bridge configuration. At this path the barrier
is affected the electron redistribution between surface quantum states both in
the initial and the saddle point. In the case of the full GaN coverage the
diffusion path is from on-top N adatom configuration via H3 site that
corresponds to maximal energy. Therefore the diffusion barrier is Ebar= 1.18 eV
for clean and Ebar= 0.92 eV for (1/6) ML to finally Ebar= 1.23 eV for full Ga
coverage. Thus the overall barrier is reduced to Ebar= 0.92 eV due to quantum
statistics effects. The identified stable N on-top configuration for the full
coverage is essential for atomic mechanism of GaN growth in Ga-rich regime.",http://arxiv.org/abs/2501.19079v1
"Imitation Game for Adversarial Disillusion with Multimodal Generative
  Chain-of-Thought Role-Play",2025-01-31T13:57:34Z,"Ching-Chun Chang, Fan-Yun Chen, Shih-Hong Gu, Kai Gao, Hanrui Wang, Isao Echizen","As the cornerstone of artificial intelligence, machine perception confronts a
fundamental threat posed by adversarial illusions. These adversarial attacks
manifest in two primary forms: deductive illusion, where specific stimuli are
crafted based on the victim model's general decision logic, and inductive
illusion, where the victim model's general decision logic is shaped by specific
stimuli. The former exploits the model's decision boundaries to create a
stimulus that, when applied, interferes with its decision-making process. The
latter reinforces a conditioned reflex in the model, embedding a backdoor
during its learning phase that, when triggered by a stimulus, causes aberrant
behaviours. The multifaceted nature of adversarial illusions calls for a
unified defence framework, addressing vulnerabilities across various forms of
attack. In this study, we propose a disillusion paradigm based on the concept
of an imitation game. At the heart of the imitation game lies a multimodal
generative agent, steered by chain-of-thought reasoning, which observes,
internalises and reconstructs the semantic essence of a sample, liberated from
the classic pursuit of reversing the sample to its original state. As a proof
of concept, we conduct experimental simulations using a multimodal generative
dialogue agent and evaluates the methodology under a variety of attack
scenarios.",http://arxiv.org/abs/2501.19143v1
Using Causality for Enhanced Prediction of Web Traffic Time Series,2025-02-02T00:36:40Z,"Chang Tian, Mingzhe Xing, Zenglin Shi, Matthew B. Blaschko, Yinliang Yue, Marie-Francine Moens","Predicting web service traffic has significant social value, as it can be
applied to various practical scenarios, including but not limited to dynamic
resource scaling, load balancing, system anomaly detection, service-level
agreement compliance, and fraud detection. Web service traffic is characterized
by frequent and drastic fluctuations over time and are influenced by
heterogeneous web user behaviors, making accurate prediction a challenging
task. Previous research has extensively explored statistical approaches, and
neural networks to mine features from preceding service traffic time series for
prediction. However, these methods have largely overlooked the causal
relationships between services. Drawing inspiration from causality in
ecological systems, we empirically recognize the causal relationships between
web services. To leverage these relationships for improved web service traffic
prediction, we propose an effective neural network module, CCMPlus, designed to
extract causal relationship features across services. This module can be
seamlessly integrated with existing time series models to consistently enhance
the performance of web service traffic predictions. We theoretically justify
that the causal correlation matrix generated by the CCMPlus module captures
causal relationships among services. Empirical results on real-world datasets
from Microsoft Azure, Alibaba Group, and Ant Group confirm that our method
surpasses state-of-the-art approaches in Mean Squared Error (MSE) and Mean
Absolute Error (MAE) for predicting service traffic time series. These findings
highlight the efficacy of leveraging causal relationships for improved
predictions.",http://arxiv.org/abs/2502.00612v1
"Lifting the Winding Number: Precise Representation of Complex Cuts in
  Subspace Physics Simulations",2025-02-02T01:51:56Z,"Yue Chang, Mengfei Liu, Zhecheng Wang, Peter Yichen Chen, Eitan Grinspun","Cutting thin-walled deformable structures is common in daily life, but poses
significant challenges for simulation due to the introduced spatial
discontinuities. Traditional methods rely on mesh-based domain representations,
which require frequent remeshing and refinement to accurately capture evolving
discontinuities. These challenges are further compounded in reduced-space
simulations, where the basis functions are inherently geometry- and
mesh-dependent, making it difficult or even impossible for the basis to
represent the diverse family of discontinuities introduced by cuts.
  Recent advances in representing basis functions with neural fields offer a
promising alternative, leveraging their discretization-agnostic nature to
represent deformations across varying geometries. However, the inherent
continuity of neural fields is an obstruction to generalization, particularly
if discontinuities are encoded in neural network weights.
  We present Wind Lifter, a novel neural representation designed to accurately
model complex cuts in thin-walled deformable structures. Our approach
constructs neural fields that reproduce discontinuities precisely at specified
locations, without baking in the position of the cut line. Crucially, our
approach does not embed the discontinuity in the neural network's weights,
opening avenues to generalization of cut placement.
  Our method achieves real-time simulation speeds and supports dynamic updates
to cut line geometry during the simulation. Moreover, the explicit
representation of discontinuities makes our neural field intuitive to control
and edit, offering a significant advantage over traditional neural fields,
where discontinuities are embedded within the network's weights, and enabling
new applications that rely on general cut placement.",http://arxiv.org/abs/2502.00626v1
TrojanTime: Backdoor Attacks on Time Series Classification,2025-02-02T03:24:24Z,"Chang Dong, Zechao Sun, Guangdong Bai, Shuying Piao, Weitong Chen, Wei Emma Zhang","Time Series Classification (TSC) is highly vulnerable to backdoor attacks,
posing significant security threats. Existing methods primarily focus on data
poisoning during the training phase, designing sophisticated triggers to
improve stealthiness and attack success rate (ASR). However, in practical
scenarios, attackers often face restrictions in accessing training data.
Moreover, it is a challenge for the model to maintain generalization ability on
clean test data while remaining vulnerable to poisoned inputs when data is
inaccessible. To address these challenges, we propose TrojanTime, a novel
two-step training algorithm. In the first stage, we generate a pseudo-dataset
using an external arbitrary dataset through target adversarial attacks. The
clean model is then continually trained on this pseudo-dataset and its poisoned
version. To ensure generalization ability, the second stage employs a carefully
designed training strategy, combining logits alignment and batch norm freezing.
We evaluate TrojanTime using five types of triggers across four TSC
architectures in UCR benchmark datasets from diverse domains. The results
demonstrate the effectiveness of TrojanTime in executing backdoor attacks while
maintaining clean accuracy. Finally, to mitigate this threat, we propose a
defensive unlearning strategy that effectively reduces the ASR while preserving
clean accuracy.",http://arxiv.org/abs/2502.00646v1
Integrated plasmo-photonic sensor with voltage controled detection,2025-02-02T16:22:27Z,"Jacek Gosciniak, Ryszard Piramidowicz","In this paper, we propose and analyze a waveguide-integrated interferometric
sensor in which interference occurs between two plasmonic modes propagating in
a single plasmonic waveguide. For the purpose of sensing, the vertical
plasmonic slot waveguide was rearranged by increasing the distance between the
metal electrodes. Consequently, the plasmonic modes associated with each metal
electrode have been separated, enabling them to propagate independently on
opposing edges of metal electrodes what allows for the implementation of a
Mach-Zehnder interferometer. The metal electrodes that support the plasmonic
modes can also function as electrical contacts. By applying a DC voltage
between them, it is possible to efficiently separate ions that drift to one of
the metal electrodes. Consequently, any change in a transmission from the
interferometer refers only to the amount of ions in a liquid as the output
signal from the interferometer is normalized to a liquid by the reference arm
which is in direct contact with the examined liquid solution. The total amount
of ions in the examined liquid remains constant, however, what changes is their
distribution in the gap as the ions drift toward one of the metal electrodes
when a voltage is applied. The proposed configuration is highly sensitive to
variations in transmission between the two arms of the interferometer, enabling
a record sensitivity of over 12460 nm/RIU, even at the telecom wavelength of
1550 nm. A further enhancement in sensitivity is expected in the mid-infrared
wavelengths, which correspond to the maximum absorption peaks of most chemical
and biological compounds.",http://arxiv.org/abs/2502.00839v1
Modeling Filamentary Conduction in Reset Phase Change Memory Devices,2025-02-02T18:20:02Z,"Md Samzid Bin Hafiz, Helena Silva, Ali Gokirmak","We performed a computational analysis on percolation transport and filament
formation in amorphous $Ge_2Sb_2Te_5$ (a-GST) using 2D finite-element
multi-physics simulations with 2 nm out-of-plane depth using an electric-field
and temperature dependent electronic transport model with carrier activation
energies that vary locally around 0.3 eV and as a function of temperature. We
observe the snapback (threshold switching) behavior in the current-voltage
(I-V) characteristics at ~50 MV/m electric field with 0.63 $\mu$A current for
300 K ambient temperature, where current collapses onto a single molten
filament with ~ 2 nm diameter, aligned with the electric field, and the device
switches from a high resistance state (108 $\Omega$) to a low resistance state
(103 $\Omega$). Further increase in voltage across the device leads to widening
of the molten filament. Snap-back current and electric field are strong
functions of ambient temperature, ranging from ~ 0.53 $\mu$A at 200 K to ~
16.93 $\mu$A at 800 K and ~ 85 MV/m at 150 K to 45 MV/m at 350 K, respectively.
Snap-back electric-field decreases exponentially with increasing device length,
converging to ~ 38 MV/m for devices longer than 200 nm.",http://arxiv.org/abs/2502.00866v1
"Dependence of the energy and orbital structure of local states in CuO
  monolayer on Coulomb parameters",2025-02-03T16:17:15Z,"I. A. Makarov, M. M. Korshunov, S. G. Ovchinnikov","The dependence of the energies and orbital structure of local states in the
CuO monolayer on intra- and interatomic Coulomb interactions on copper and
oxygen orbitals is studied. The electronic system is described within the
eight-band p-d model in the hole representation with the on-site energies and
hopping integrals obtained using density functional theory. CuO cluster
multiparticle eigenstates are calculated using exact diagonalization. The
difference between the energy dependencies on the Coulomb parameters for the
states with the predominant probability density on the d-orbital and the states
in which hole occupies p-orbitals leads to crossover of d- and p-states. The
ground single-hole and two-hole states which determine the electronic structure
of the low-energy excitations have the character of d- or p-orbitals in the
different regions of the Coulomb parameters space. The gap between the energies
of the dispersionless quasiparticles forming the top of the valence band and
conductivity band also have different values in these two regions. The
magnitude of this gap and the orbital character of the local multiparticle
states change sharply even with an insignificant change in the Coulomb
interactions within the boundary region of parameters between the regions in
which the local states are formed by the d- or p-orbitals.",http://arxiv.org/abs/2502.01483v1
"LV-XAttn: Distributed Cross-Attention for Long Visual Inputs in
  Multimodal Large Language Models",2025-02-04T15:24:16Z,"Tzu-Tao Chang, Shivaram Venkataraman","Cross-attention is commonly adopted in multimodal large language models
(MLLMs) for integrating visual information into the language backbone. However,
in applications with large visual inputs, such as video understanding,
processing a large number of visual tokens in cross-attention layers leads to
high memory demands and often necessitates distributed computation across
multiple GPUs. Existing distributed attention mechanisms face significant
communication overheads, making cross-attention layers a critical bottleneck
for efficient training and inference of MLLMs. To address this, we propose
LV-XAttn, a distributed, exact cross-attention mechanism with minimal
communication overhead. We observe that in applications involving large visual
inputs the size of the query block is typically much smaller than that of the
key-value blocks. Thus, in LV-XAttn we keep the large key-value blocks locally
on each GPU and exchange smaller query blocks across GPUs. We also introduce an
efficient activation recomputation technique enabling support for longer visual
context. We theoretically analyze the communication benefits of LV-XAttn and
show that it can achieve speedups for a wide range of models. Our evaluations
with mPLUG-Owl3 and OpenFlamingo models find that LV-XAttn achieves up to
5.58$\times$ end-to-end speedup compared to existing approaches.",http://arxiv.org/abs/2502.02406v2
"Response of liquid metal in a fusion reactor blanket to rapid variation
  of magnetic field during a transient plasma event",2025-02-04T20:31:53Z,"Ivan Smolyanov, Oleg Zikanov","Transient plasma events, such as plasma disruptions, are anticipated in the
future magnetic-confinement nuclear fusion reactors. The events are accompanied
by a rapid change in the magnetic field generated by the plasma current and,
accordingly, induction of strong eddy currents and Lorentz forces within the
reactor structure. This work targets processes within liquid-metal components
of the reactor's breeding blankets. Order-of-magnitude analysis and numerical
simulations are performed to understand the response of liquid metal to a
rapidly changing magnetic field and to evaluate the accuracy of commonly used
simplifying model assumptions. The response is found to consist of two stages:
an initial brief stage ($\sim 1$ ms) characterized by a rapid increase in the
induced currents, forces, and fluid velocity; and a subsequent stage, which is
triggered by the growing velocity of the metal and marked by reversals of
Lorentz force, and oscillations and decreases in the amplitude of the induced
fields. The transition to the second stage sets the upper limit of the velocity
($\sim 0.5$ m/s in our tests), to which an initially quiescent metal can be
accelerated during the event. The simulations indicate that many widely used
model assumptions, such as the negligible role of Joule dissipation in the heat
balance and the constancy of physical property coefficients, remain valid
during the response. However, the assumption of liquid metal incompressibility
is found to be questionable due to the potential significant effects of
pressure waves.",http://arxiv.org/abs/2502.02699v2
"Planning with affordances: Integrating learned affordance models and
  symbolic planning",2025-02-04T23:15:38Z,Rajesh Mangannavar,"Intelligent agents working in real-world environments must be able to learn
about the environment and its capabilities which enable them to take actions to
change to the state of the world to complete a complex multi-step task in a
photorealistic environment. Learning about the environment is especially
important to perform various multiple-step tasks without having to redefine an
agent's action set for different tasks or environment settings. In our work, we
augment an existing task and motion planning framework with learned affordance
models of objects in the world to enable planning and executing multi-step
tasks using learned models. Each task can be seen as changing the current state
of the world to a given goal state. The affordance models provide us with what
actions are possible and how to perform those actions in any given state. A
symbolic planning algorithm uses this information and the starting and goal
state to create a feasible plan to reach the desired goal state to complete a
given task. We demonstrate our approach in a virtual 3D photorealistic
environment, AI2-Thor, and evaluate it on real-world tasks. Our results show
that our agent quickly learns how to interact with the environment and is well
prepared to perform tasks such as ""Moving an object out of the way to reach the
desired location.""",http://arxiv.org/abs/2502.02768v1
"Don't Let Your Likert Scales Grow Up To Be Visual Analog Scales:
  Understanding the Relationship Between Number of Response Categories and
  Measurement Error",2025-02-05T03:01:40Z,"Siqi Sun, Karen M. Schmidt, Teague R. Henry","The use of Visual Analog Scales (VAS), which can be broadly conceptualized as
items where the response scale is 0-100, has surged recently due to the
convenience of digital assessments. However, there is no consensus as to
whether the use of VAS scales is optimal in a measurement sense. Put
differently, in the 90+ years since Likert introduced his eponymous scale, the
field does not know how to determine the optimal number of response options for
a given item. In the current work, we investigate the optimal number of
response categories using a series of simulations. We find that when the
measurement error of an item is not dependent on the number of response
categories, there is no true optimum; rather, reliability increases with number
of response options and then plateaus. However, under the more realistic
assumption that the measurement error of an item increases with the number of
response categories, we find a clear optimum that depends on the rate of that
increase. If measurement error increases with the number of response
categories, then conversion of any Likert scale item to VAS will result in a
drastic decrease in reliability. Finally, if researchers do want to change the
response scale of a validated measure, they must re-validate the new measure as
the measurement error of the scale is likely to change.",http://arxiv.org/abs/2502.02846v1
"Optical Properties of Aluminium-Doped Zinc Oxide Thin Films Synthesized
  via AACVD Using Nitrogen as a Carrier Gas",2025-02-05T10:37:25Z,"Kingsley Imoni-Ogbe, Onyekachukwu Mike Osiele, Vincent Akpoveta, Queen Umudi, Bright Ugbolu, Oscar Enajite","The study uses AACVD technology with nitrogen carrier gas to make AZO thin
films through which it determines structural, optical, and morphological
changes from 0 to 20 percent aluminum doping. The depositions took place at 400
degrees Celsius on soda-lime glass before the samples received an annealing
process at 450 degrees Celsius inside a nitrogen chamber. The X-ray diffraction
analysis identified superior crystalline structure in films processed with
nitrogen gas through their strong signals at the 220, 311 and 222 peaks. The
increasing levels of aluminum doping decreased the crystallite dimensions and
elevated grain boundary concentrations because of intensified crystal tension
and defective structural formation. The profilometry assessment determined film
thickness increased mildly from 102 nanometers in undoped ZnO to 115 nanometers
in 20 percent aluminum-doped ZnO. The presence of nitrogen annealing in the
films led to increased absorbance while the strongest absorbance peaks occurred
when the material contained 5 percent dopants. The bandgap energy expanded
through the change from undoped ZnO with 3.21 electron volts to 3.33 electron
volts at 20 percent aluminum doping which matched Burstein-Moss effect results.
The optoelectronic devices gain enhanced optical characteristics from the
doping levels exceeding 15 percent.",http://arxiv.org/abs/2502.03058v1
Strategizing with AI: Insights from a Beauty Contest Experiment,2025-02-05T13:31:38Z,"Iuliia Alekseenko, Dmitry Dagaev, Sofia Paklina, Petr Parshakov","A Keynesian beauty contest is a wide class of games of guessing the most
popular strategy among other players. In particular, guessing a fraction of a
mean of numbers chosen by all players is a classic behavioral experiment
designed to test iterative reasoning patterns among various groups of people.
The previous literature reveals that the level of sophistication of the
opponents is an important factor affecting the outcome of the game. Smarter
decision makers choose strategies that are closer to theoretical Nash
equilibrium and demonstrate faster convergence to equilibrium in iterated
contests with information revelation. We replicate a series of classic
experiments by running virtual experiments with modern large language models
(LLMs) who play against various groups of virtual players. We test how advanced
the LLMs' behavior is compared to the behavior of human players. We show that
LLMs typically take into account the opponents' level of sophistication and
adapt by changing the strategy. In various settings, most LLMs (with the
exception of Llama) are more sophisticated and play lower numbers compared to
human players. Our results suggest that LLMs (except Llama) are rather
successful in identifying the underlying strategic environment and adopting the
strategies to the changing set of parameters of the game in the same way that
human players do. All LLMs still fail to play dominant strategies in a
two-player game. Our results contribute to the discussion on the accuracy of
modeling human economic agents by artificial intelligence.",http://arxiv.org/abs/2502.03158v1
"From Kernels to Features: A Multi-Scale Adaptive Theory of Feature
  Learning",2025-02-05T14:26:50Z,"Noa Rubin, Kirsten Fischer, Javed Lindner, David Dahmen, Inbar Seroussi, Zohar Ringel, Michael Krämer, Moritz Helias","Theoretically describing feature learning in neural networks is crucial for
understanding their expressive power and inductive biases, motivating various
approaches. Some approaches describe network behavior after training through a
simple change in kernel scale from initialization, resulting in a
generalization power comparable to a Gaussian process. Conversely, in other
approaches training results in the adaptation of the kernel to the data,
involving complex directional changes to the kernel. While these approaches
capture different facets of network behavior, their relationship and respective
strengths across scaling regimes remains an open question. This work presents a
theoretical framework of multi-scale adaptive feature learning bridging these
approaches. Using methods from statistical mechanics, we derive analytical
expressions for network output statistics which are valid across scaling
regimes and in the continuum between them. A systematic expansion of the
network's probability distribution reveals that mean-field scaling requires
only a saddle-point approximation, while standard scaling necessitates
additional correction terms. Remarkably, we find across regimes that kernel
adaptation can be reduced to an effective kernel rescaling when predicting the
mean network output of a linear network. However, even in this case, the
multi-scale adaptive approach captures directional feature learning effects,
providing richer insights than what could be recovered from a rescaling of the
kernel alone.",http://arxiv.org/abs/2502.03210v1
"Parametric reduced-order modeling and mode sensitivity of actuated
  cylinder flow from a matrix manifold perspective",2025-02-06T03:30:41Z,"Shintaro Sato, Oliver T. Schmidt","We present a framework for parametric proper orthogonal decomposition
(POD)-Galerkin reduced-order modeling (ROM) of fluid flows that accommodates
variations in flow parameters and control inputs. As an initial step, to
explore how the locally optimal POD modes vary with parameter changes, we
demonstrate a sensitivity analysis of POD modes and their spanned subspace,
respectively rooted in Stiefel and Grassmann manifolds. The sensitivity
analysis, by defining distance between POD modes for different parameters, is
applied to the flow around a rotating cylinder with varying Reynolds numbers
and rotation rates. The sensitivity of the subspace spanned by POD modes to
parameter changes is represented by a tangent vector on the Grassmann manifold.
For the cylinder case, the inverse of the subspace sensitivity on the Grassmann
manifold is proportional to the Roshko number, highlighting the connection
between geometric properties and flow physics. Furthermore, the Reynolds number
at which the subspace sensitivity approaches infinity corresponds to the lower
bound at which the characteristic frequency of the K\'arm\'an vortex street
exists (Noack & Eckelmann, JFM, 1994). From the Stiefel manifold perspective,
sensitivity modes are derived to represent the flow field sensitivity,
comprising the sensitivities of the POD modes and expansion coefficients. The
temporal evolution of the flow field sensitivity is represented by superposing
the sensitivity modes. Lastly, we devise a parametric POD-Galerkin ROM based on
subspace interpolation on the Grassmann manifold. The reconstruction error of
the ROM is intimately linked to the subspace-estimation error, which is in turn
closely related to subspace sensitivity.",http://arxiv.org/abs/2502.03754v1
"The coalescent structure of multitype continuous-time Galton-Watson
  trees",2025-02-07T00:46:50Z,"Osvaldo Angtuncio Hernández, Simon Harris, Juan Carlos Pardo","We investigate the genealogy of a sample of $k\geq1$ particles chosen
uniformly without replacement from a population alive at large times in a
critical continuous-time multitype Galton-Watson process with finite second
moment. We will show that subject to a deterministic time-change, the sample
genealogy always converges to the same universal genealogical structure; it has
the same tree topology as Kingman's coalescent, when the types are discarded,
and the coalescent times of the $k-1$ pairwise mergers look like a mixture of
independent identically distributed times. We show that such an ancestral
lineage in the limit, strongly depends on the multitype offspring distribution,
which differs from the single type case Harris, Johnston, and Roberts [Annals
of Applied Probability, 2020]. Our approach uses $k$ distinguished 'spine'
particles and a suitable change of measure under which (a) the spines form a
uniform sample without replacement that depend on the colours but additionally
(b) there is $k$-size biasing and discounting according to the population size.
Our work substantially extends the spine techniques developed in Harris,
Johnston, and Roberts [Annals of Applied Probability, 2020] for genealogies of
uniform samples of size $k$ in critical, continuous-time, single-type
Galton-Watson processes. We generalize these methods to the multi-type setting
and provide a comprehensive analysis of how functionals of the spines are
influenced by the types. While the single-type case exhibits a more homogeneous
structure with simpler dependency patterns, the multi-type case introduces
interactions between different types, leading to a more intricate dependency
structure where functionals must account for type-specific behaviours and
inter-type relationships.",http://arxiv.org/abs/2502.04588v1
"Context images for Venus Express radio occultation measurements: A
  search for a correlation between temperature structure and UV contrasts in
  the clouds of Venus",2025-02-07T04:25:06Z,"Maarten Roos-Serote, Colin Wilson, Ryan MacDonald, Silvia Tellmann, Yeon Joo Lee, Igor Khatuntsev","Venus exhibits strong and changing contrasts at ultraviolet wavelengths
apparently related to the clouds and the dynamics in the cloud layer, but to
date their origin continues to be unknown. We investigate the nature of the UV
contrasts exhibited by Venus clouds by examining possible correlations between
the thermal structure inferred from radio occultation data and UV brightness
from imagery data, both observed with Venus Express. We analyse Venus Express
images obtained from 11 hours before to a few hours after the time of radio
occultation measurements of the same area. We account for the advection of
clouds by zonal and meridional winds and apply a phase angle correction to
compensate for the changing viewing geometry. We find a possible
anti-correlation between UV-brightness and atmospheric temperature in the 65-70
km altitude range for low latitudes. Heating in this altitude and latitude
region due to an increase in the UV-absorber has been predicted by radiative
forcing studies. The predictions roughly match our observed temperature
amplitude between UV-dark and UV-bright regions. We find no evidence for any
correlation between UV-brightness and static stability in the atmosphere in the
50-80 km altitude region. This could be the first observational evidence for a
direct link between UV-brightness and atmospheric temperature in the 65-70km
altitude region in the clouds of Venus.",http://arxiv.org/abs/2502.04650v1
"Mechanistic Understandings of Representation Vulnerabilities and
  Engineering Robust Vision Transformers",2025-02-07T05:58:16Z,"Chashi Mahiul Islam, Samuel Jacob Chacko, Mao Nishino, Xiuwen Liu","While transformer-based models dominate NLP and vision applications, their
underlying mechanisms to map the input space to the label space semantically
are not well understood. In this paper, we study the sources of known
representation vulnerabilities of vision transformers (ViT), where perceptually
identical images can have very different representations and semantically
unrelated images can have the same representation. Our analysis indicates that
imperceptible changes to the input can result in significant representation
changes, particularly in later layers, suggesting potential instabilities in
the performance of ViTs. Our comprehensive study reveals that adversarial
effects, while subtle in early layers, propagate and amplify through the
network, becoming most pronounced in middle to late layers. This insight
motivates the development of NeuroShield-ViT, a novel defense mechanism that
strategically neutralizes vulnerable neurons in earlier layers to prevent the
cascade of adversarial effects. We demonstrate NeuroShield-ViT's effectiveness
across various attacks, particularly excelling against strong iterative
attacks, and showcase its remarkable zero-shot generalization capabilities.
Without fine-tuning, our method achieves a competitive accuracy of 77.8% on
adversarial examples, surpassing conventional robustness methods. Our results
shed new light on how adversarial effects propagate through ViT layers, while
providing a promising approach to enhance the robustness of vision transformers
against adversarial attacks. Additionally, they provide a promising approach to
enhance the robustness of vision transformers against adversarial attacks.",http://arxiv.org/abs/2502.04679v1
"Identification of $tqg$ flavor-changing neutral current interactions
  using machine learning techniques",2025-02-07T11:30:27Z,"Byeonghak Ko, Jeewon Heo, Woojin Jang, Jason S. H. Lee, Youn Jung Roh, Ian James Watson, Seungjin Yang","Flavor-changing neutral currents (FCNCs) are forbidden at tree level in the
Standard Model (SM), but they can be enhanced in physics Beyond the Standard
Model (BSM) scenarios.In this paper, we investigate the effectiveness of deep
learning techniques to enhance the sensitivity of current and future collider
experiments to the production of a top quark and an associated parton through
the $tqg$ FCNC process, which originates from the $tug$ and $tcg$ vertices. The
$tqg$ FCNC events can be produced with a top quark and either an associated
gluon or quark, while SM only has events with a top quark and an associated
quark. We apply machine learning techniques to distinguish the $tqg$ FCNC
events from the SM backgrounds, including $qg$-discrimination variables. We use
the Boosted Decision Tree (BDT) method as a baseline classifier, assuming that
the leading jet originates from the associated parton. We compare with a
Transformer-based deep learning method known as the Self-Attention for
Jet-parton Assignment (SAJA) network, which allows us to include information
from all jets in the event, regardless of their number, eliminating the
necessity to match the associated parton to the leading jet. The \SaJa\ network
with qg-discrimination variables has the best performance, giving expected
upper limits on the branching ratios Br($t \to qg$) that are 25-35\% lower than
those from the BDT method.",http://arxiv.org/abs/2502.04844v1
"Deep Generative model that uses physical quantities to generate and
  retrieve solar magnetic active regions",2025-02-07T21:44:01Z,"Subhamoy Chatterjee, Andres Munoz-Jaramillo, Anna Malanushenko","Deep generative models have shown immense potential in generating unseen data
that has properties of real data. These models learn complex data-generating
distributions starting from a smaller set of latent dimensions. However,
generative models have encountered great skepticism in scientific domains due
to the disconnection between generative latent vectors and scientifically
relevant quantities. In this study, we integrate three types of machine
learning models to generate solar magnetic patches in a physically
interpretable manner and use those as a query to find matching patches in real
observations. We use the magnetic field measurements from Space-weather HMI
Active Region Patches (SHARPs) to train a Generative Adversarial Network (GAN).
We connect the physical properties of GAN-generated images with their latent
vectors to train Support Vector Machines (SVMs) that do mapping between
physical and latent spaces. These produce directions in the GAN latent space
along which known physical parameters of the SHARPs change. We train a
self-supervised learner (SSL) to make queries with generated images and find
matches from real data. We find that the GAN-SVM combination enables users to
produce high-quality patches that change smoothly only with a prescribed
physical quantity, making generative models physically interpretable. We also
show that GAN outputs can be used to retrieve real data that shares the same
physical properties as the generated query. This elevates Generative Artificial
Intelligence (AI) from a means-to-produce artificial data to a novel tool for
scientific data interrogation, supporting its applicability beyond the domain
of heliophysics.",http://arxiv.org/abs/2502.05351v1
"A state-space framework for causal detection of hippocampal
  ripple-replay events",2025-02-08T00:39:35Z,"Sirui Zeng, Uri T. Eden","Hippocampal ripple-replay events are typically identified using a two-step
process that at each time point uses past and future data to determine whether
an event is occurring. This prevents researchers from identifying these events
in real time for closed-loop experiments. It also prevents the identification
of periods of nonlocal representation that are not accompanied by large changes
in the spectral content of the local field potentials (LFPs). In this work, we
present a new state-space model framework that is able to detect concurrent
changes in the rhythmic structure of LFPs with nonlocal activity in place cells
to identify ripple-replay events in a causal manner. The model combines latent
factors related to neural oscillations, represented space, and switches between
coding properties to explain simultaneously the spiking activity from multiple
units and the rhythmic content of LFPs recorded from multiple sources. The
model is temporally causal, meaning that estimates of the switching state can
be made at each instant using only past information from the spike and LFP
signals, or can be combined with future data to refine those estimates. We
applied this model framework to simulated and real hippocampal data to
demonstrate its performance in identifying ripple-replay events.",http://arxiv.org/abs/2502.05394v2
"Towards Learning Scalable Agile Dynamic Motion Planning for Robosoccer
  Teams with Policy Optimization",2025-02-08T11:13:07Z,"Brandon Ho, Batuhan Altundas, Matthew Gombolay","In fast-paced, ever-changing environments, dynamic Motion Planning for
Multi-Agent Systems in the presence of obstacles is a universal and unsolved
problem. Be it from path planning around obstacles to the movement of robotic
arms, or in planning navigation of robot teams in settings such as Robosoccer,
dynamic motion planning is needed to avoid collisions while reaching the
targeted destination when multiple agents occupy the same area. In continuous
domains where the world changes quickly, existing classical Motion Planning
algorithms such as RRT* and A* become computationally expensive to rerun at
every time step. Many variations of classical and well-formulated non-learning
path-planning methods have been proposed to solve this universal problem but
fall short due to their limitations of speed, smoothness, optimally, etc. Deep
Learning models overcome their challenges due to their ability to adapt to
varying environments based on past experience. However, current learning motion
planning models use discretized environments, do not account for heterogeneous
agents or replanning, and build up to improve the classical motion planners'
efficiency, leading to issues with scalability. To prevent collisions between
heterogenous team members and collision to obstacles while trying to reach the
target location, we present a learning-based dynamic navigation model and show
our model working on a simple environment in the concept of a simple Robosoccer
Game.",http://arxiv.org/abs/2502.05526v1
"Rethinking Word Similarity: Semantic Similarity through Classification
  Confusion",2025-02-08T21:55:38Z,"Kaitlyn Zhou, Haishan Gao, Sarah Chen, Dan Edelstein, Dan Jurafsky, Chen Shani","Word similarity has many applications to social science and cultural
analytics tasks like measuring meaning change over time and making sense of
contested terms. Yet traditional similarity methods based on cosine similarity
between word embeddings cannot capture the context-dependent, asymmetrical,
polysemous nature of semantic similarity. We propose a new measure of
similarity, Word Confusion, that reframes semantic similarity in terms of
feature-based classification confusion. Word Confusion is inspired by Tversky's
suggestion that similarity features be chosen dynamically. Here we train a
classifier to map contextual embeddings to word identities and use the
classifier confusion (the probability of choosing a confounding word c instead
of the correct target word t) as a measure of the similarity of c and t. The
set of potential confounding words acts as the chosen features. Our method is
comparable to cosine similarity in matching human similarity judgments across
several datasets (MEN, WirdSim353, and SimLex), and can measure similarity
using predetermined features of interest. We demonstrate our model's ability to
make use of dynamic features by applying it to test a hypothesis about changes
in the 18th C. meaning of the French word ""revolution"" from popular to state
action during the French Revolution. We hope this reimagining of semantic
similarity will inspire the development of new tools that better capture the
multi-faceted and dynamic nature of language, advancing the fields of
computational social science and cultural analytics and beyond.",http://arxiv.org/abs/2502.05704v1
Multimodal Search on a Line,2025-02-10T19:50:54Z,"Jared Coleman, Dmitry Ivanov, Evangelos Kranakis, Danny Krizanc, Oscar Morales Ponce","Inspired by the diverse set of technologies used in underground object
detection and imaging, we introduce a novel multimodal linear search problem
whereby a single searcher starts at the origin and must find a target that can
only be detected when the searcher moves through its location using the correct
of $p$ possible search modes.
  The target's location, its distance $d$ from the origin, and the correct
search mode are all initially unknown to the searcher. We prove tight upper and
lower bounds on the competitive ratio for this problem. Specifically, we show
that when $p$ is odd, the optimal competitive ratio is given by
$2p+3+\sqrt{8(p+1)}$, whereas when $p$ is even, the optimal competitive ratio
is given by $c$: the unique solution to $(c-1)^4-4p(c+1)^2(c-p-1)=0$ in the
interval $\left[2p+1+\sqrt{8p},\infty\right)$. This solution $c$ has the
explicit bounds $2p+3+\sqrt{8(p-1)}\leq c\leq 2p+3+\sqrt{8p}$. The optimal
algorithms we propose require the searcher to move infinitesimal distances and
change directions infinitely many times within finite intervals. To better suit
practical applications, we also propose an approximation algorithm with a
competitive ratio of $c+\varepsilon$ (where $c$ is the optimal competitive
ratio and $\varepsilon > 0$ is an arbitrarily small constant). This algorithm
involves the searcher moving finite distances and changing directions a finite
number of times within any finite interval.",http://arxiv.org/abs/2502.07000v1
"Comprehensive Analysis of Thermal Dissipation in Lithium-Ion Battery
  Packs",2025-02-10T22:06:05Z,"Xuguang Zhang, Hexiang Zhang, Amjad Almansour, Mrityunjay Singh, Hengling Zhu, Michael C. Halbig, Yi Zheng","Effective thermal management is critical for lithium-ion battery packs' safe
and efficient operations, particularly in applications such as drones, where
compact designs and varying airflow conditions present unique challenges. This
study investigates the thermal performance of a 16-cell lithium-ion battery
pack by optimizing cooling airflow configurations and integrating phase change
materials (PCMs) for enhanced heat dissipation. Seven geometric configurations
were evaluated under airflow speeds ranging from 0 to 15 m/s, reflecting the
operational conditions of civilian drones. A comprehensive 3D simulation
approach was used to analyze the effects of inlet and outlet configurations,
airflow dynamics, and PCM phase transition behavior. Results indicate that the
trapezoidal (wide-base) configuration, paired with a 5-inlet and 1-outlet
setup, achieves the most balanced performance, effectively maintaining optimal
operating temperatures across low and high-speed airflow conditions. PCM
integration further stabilized thermal behavior, with phase change durations
extending to 12.5 min under tested conditions. These findings highlight the
importance of geometric optimization and material integration in advancing
compact and reliable thermal management systems for energy-dense battery packs.
This study provides a foundation for designing efficient cooling strategies
tailored to lightweight applications such as drones and portable energy storage
systems.",http://arxiv.org/abs/2502.07070v1
"SparseFormer: Detecting Objects in HRW Shots via Sparse Vision
  Transformer",2025-02-11T03:21:25Z,"Wenxi Li, Yuchen Guo, Jilai Zheng, Haozhe Lin, Chao Ma, Lu Fang, Xiaokang Yang","Recent years have seen an increase in the use of gigapixel-level image and
video capture systems and benchmarks with high-resolution wide (HRW) shots.
However, unlike close-up shots in the MS COCO dataset, the higher resolution
and wider field of view raise unique challenges, such as extreme sparsity and
huge scale changes, causing existing close-up detectors inaccuracy and
inefficiency. In this paper, we present a novel model-agnostic sparse vision
transformer, dubbed SparseFormer, to bridge the gap of object detection between
close-up and HRW shots. The proposed SparseFormer selectively uses attentive
tokens to scrutinize the sparsely distributed windows that may contain objects.
In this way, it can jointly explore global and local attention by fusing
coarse- and fine-grained features to handle huge scale changes. SparseFormer
also benefits from a novel Cross-slice non-maximum suppression (C-NMS)
algorithm to precisely localize objects from noisy windows and a simple yet
effective multi-scale strategy to improve accuracy. Extensive experiments on
two HRW benchmarks, PANDA and DOTA-v1.0, demonstrate that the proposed
SparseFormer significantly improves detection accuracy (up to 5.8%) and speed
(up to 3x) over the state-of-the-art approaches.",http://arxiv.org/abs/2502.07216v1
"DEG: Efficient Hybrid Vector Search Using the Dynamic Edge Navigation
  Graph",2025-02-11T08:10:16Z,"Ziqi Yin, Jianyang Gao, Pasquale Balsebre, Gao Cong, Cheng Long","Bimodal data, such as image-text pairs, has become increasingly prevalent in
the digital era. The Hybrid Vector Query (HVQ) is an effective approach for
querying such data and has recently garnered considerable attention from
researchers. It calculates similarity scores for objects represented by two
vectors using a weighted sum of each individual vector's similarity, with a
query-specific parameter $\alpha$ to determine the weight. Existing methods for
HVQ typically construct Approximate Nearest Neighbors Search (ANNS) indexes
with a fixed $\alpha$ value. This leads to significant performance degradation
when the query's $\alpha$ dynamically changes based on the different scenarios
and needs.
  In this study, we introduce the Dynamic Edge Navigation Graph (DEG), a
graph-based ANNS index that maintains efficiency and accuracy with changing
$\alpha$ values. It includes three novel components: (1) a greedy Pareto
frontier search algorithm to compute a candidate neighbor set for each node,
which comprises the node's approximate nearest neighbors for all possible
$\alpha$ values; (2) a dynamic edge pruning strategy to determine the final
edges from the candidate set and assign each edge an active range. This active
range enables the dynamic use of the Relative Neighborhood Graph's pruning
strategy based on the query's $\alpha$ values, skipping redundant edges at
query time and achieving a better accuracy-efficiency trade-off; and (3) an
edge seed method that accelerates the querying process. Extensive experiments
on real-world datasets show that DEG demonstrates superior performance compared
to existing methods under varying $\alpha$ values.",http://arxiv.org/abs/2502.07343v1
HGTUL: A Hypergraph-based Model For Trajectory User Linking,2025-02-11T13:39:35Z,"Fengjie Chang, Xinning Zhu, Zheng Hu, Yang Qin","Trajectory User Linking (TUL), which links anonymous trajectories with users
who generate them, plays a crucial role in modeling human mobility. Despite
significant advancements in this field, existing studies primarily neglect the
high-order inter-trajectory relationships, which represent complex associations
among multiple trajectories, manifested through multi-location co-occurrence
patterns emerging when trajectories intersect at various Points of Interest
(POIs). Furthermore, they also overlook the variable influence of POIs on
different trajectories, as well as the user class imbalance problem caused by
disparities in user activity levels and check-in frequencies. To address these
limitations, we propose a novel HyperGraph-based multi-perspective Trajectory
User Linking model (HGTUL). Our model learns trajectory representations from
both relational and spatio-temporal perspectives: (1) it captures high-order
associations among trajectories by constructing a trajectory hypergraph and
leverages a hypergraph attention network to learn the variable impact of POIs
on trajectories; (2) it models the spatio-temporal characteristics of
trajectories by incorporating their temporal and spatial information into a
sequential encoder. Moreover, we design a data balancing method to effectively
address the user class imbalance problem and experimentally validate its
significance in TUL. Extensive experiments on three real-world datasets
demonstrate that HGTUL outperforms state-of-the-art baselines, achieving
improvements of 2.57%~20.09% and 5.68%~26.00% in ACC@1 and Macro-F1 metrics,
respectively.",http://arxiv.org/abs/2502.07549v1
"Genetic evolution of a multi-generational population in the context of
  interstellar space travels -- Part II: Phenotypic effects of gene expression",2025-02-11T13:57:22Z,"Frédéric Marin, Camille Beluffi-Marin, Frédéric Fischer","In the first paper of this series, we included the effects of population
genetics in the agent-based Monte Carlo code HERITAGE under the hypothesis of
neutral phenotypic effects. It implied that mutations (genetic changes) had
only neutral physical manifestations. We now relax this assumption by including
genetic effects of mutation and neo-mutations (from radiations) onto the
population's life expectancy, fertility, pregnancy chances and miscarriage
rates. When applied to a population aboard a generation ship that travels at
sub-light speed towards a distant exoplanet, we demonstrate that natural
selection indirectly affects the genetic structure of a population via the
contribution of phenotypes, in agreement with past studies in conservation
biology. For large starting crews (about 500 individuals), the effect aligns
with the neutral hypothesis and the frequency of alleles (for non-sexual
chromosomes) is stable over centuries. Results are completely different if the
spacecraft shielding, integrated into hull design, fails to efficiently protect
the crew from high-energy cosmic rays and showers of secondary particles. We
tested different scenarios, in which the level of radiation is either fixed at
normal or extreme levels, or changing over time due to, e.g., shield
degradation, on-board nuclear incident or the outburst of a supernova situated
50 light-years away.",http://arxiv.org/abs/2502.07559v1
Pre-Trained Video Generative Models as World Simulators,2025-02-10T14:49:09Z,"Haoran He, Yang Zhang, Liang Lin, Zhongwen Xu, Ling Pan","Video generative models pre-trained on large-scale internet datasets have
achieved remarkable success, excelling at producing realistic synthetic videos.
However, they often generate clips based on static prompts (e.g., text or
images), limiting their ability to model interactive and dynamic scenarios. In
this paper, we propose Dynamic World Simulation (DWS), a novel approach to
transform pre-trained video generative models into controllable world
simulators capable of executing specified action trajectories. To achieve
precise alignment between conditioned actions and generated visual changes, we
introduce a lightweight, universal action-conditioned module that seamlessly
integrates into any existing model. Instead of focusing on complex visual
details, we demonstrate that consistent dynamic transition modeling is the key
to building powerful world simulators. Building upon this insight, we further
introduce a motion-reinforced loss that enhances action controllability by
compelling the model to capture dynamic changes more effectively. Experiments
demonstrate that DWS can be versatilely applied to both diffusion and
autoregressive transformer models, achieving significant improvements in
generating action-controllable, dynamically consistent videos across games and
robotics domains. Moreover, to facilitate the applications of the learned world
simulator in downstream tasks such as model-based reinforcement learning, we
propose prioritized imagination to improve sample efficiency, demonstrating
competitive performance compared with state-of-the-art methods.",http://arxiv.org/abs/2502.07825v1
"Artificial and Eddy Viscosity in Large Eddy Simulation Part 2:
  Turbulence Models",2025-02-12T07:08:40Z,"Jing Sun, Roel Verstappen","This is the second part to our companion paper. The novel method to quantify
artificial dissipation proposed in Part 1 is further applied in turbulent
channel flow at $\mathrm{Re_\tau}=180$ using various subgrid-scale models, with
an emphasis on minimum-dissipation models (QR and AMD). We found that the
amount of artificial viscosity is comparable to the eddy viscosity, but their
distributions are essentially opposite. The artificial viscosity can either
produce turbulent kinetic energy (TKE) in the near wall region or dissipate TKE
in the bulk region. The eddy viscosity is almost uniformly distributed across
the wall-normal direction and actively damps TKE at the channel center. An eddy
viscosity level of $\nu_e/\nu < 22\%$ leads to accurate predictions of flow
quantities at the current mesh resolution. The optimal coefficients for the QR
model combined with symmetry-preserving discretization were found to be C=0.092
for turbulent kinetic energy and C=0.012 for Reynolds stress terms and large
scale motions. Adjusting the QR model coefficient changes the artificial
viscosity and significantly impact turbulence characteristics: small-scale
motions remain unaffected, while larger scales are less accurately captured
with larger coefficients. For error quantification, the SGS activity parameter
$\nu_{rel} = \frac{\nu_e}{\nu_e + \nu}$ helps relate and reflect the error
magnitude with the SGS model. Optimal coefficients for the AMD model were also
identified. The trends of varying the coefficient are similar to the QR model
but differ in the amplitude of changes. The AMD model is more sensitive to the
model coefficients and introduces more eddy viscosity in the near-wall region
compared to the QR model. This research highlights the importance of balancing
numerical and eddy viscosities for accurate LES predictions.",http://arxiv.org/abs/2502.08165v1
"Rhythmic sharing: A bio-inspired paradigm for zero-shot adaptation and
  learning in neural networks",2025-02-12T18:58:34Z,"Hoony Kang, Wolfgang Losert","The brain can rapidly adapt to new contexts and learn from limited data, a
coveted characteristic that artificial intelligence algorithms have struggled
to mimic. Inspired by oscillatory rhythms of the mechanical structures of
neural cells, we developed a learning paradigm that is based on oscillations in
link strengths and associates learning with the coordination of these
oscillations. We find that this paradigm yields rapid adaptation and learning
in artificial neural networks. Link oscillations can rapidly change
coordination, endowing the network with the ability to sense subtle context
changes in an unsupervised manner. In other words, the network generates the
missing contextual tokens required to perform as a generalist AI architecture
capable of predicting dynamics in multiple contexts. Oscillations also allow
the network to extrapolate dynamics to never-seen-before contexts. These
capabilities make our learning paradigm a powerful starting point for novel
models of learning and cognition. Furthermore, learning through link
coordination is agnostic to the specifics of the neural network architecture,
hence our study opens the door for introducing rapid adaptation and learning
capabilities into leading AI models.",http://arxiv.org/abs/2502.08644v3
A unified model of feed rotation in radio telescopes and GNSS antennas,2025-02-12T20:08:34Z,"Joe Skeens, Johnathan York, Leonid Petrov, Kyle Herrity, Richard Ji-Cathriner, Srinivas Bettadpur","We describe a model that accounts for the phase rotation that occurs when a
receiver or transmitter changes orientation while observing or emitting
circularly polarized electromagnetic waves. This model extends work detailing
Global Navigation Satellite Systems (GNSS) carrier phase wind-up to allow us to
describe the interaction of changing satellite orientation with phase rotation
in observing radio telescopes. This development is motivated by, and a critical
requirement of, unifying GNSS and Very Long Baseline Interferometry (VLBI)
measurements at the observation level. The model can be used for either
stationary choke ring antennas or steerable radio telescopes observing either
natural radio sources or satellites. Simulations and experimental data are used
to validate the model and to illustrate its importance. In addition, we
rigorously lay out the feed rotation correction for radio telescopes with beam
waveguide and full Nasmyth focuses and validate the correction by observing the
effect with dual polarization observations. Using this feed rotation model for
beam waveguide telescopes, we produce the first phase delay solution for the
VLBI baseline WARK30M-WARK12M. We provide a practical guide to using the feed
rotation model in Appendix D.",http://arxiv.org/abs/2502.08761v1
Modified Hadronic Interactions and the future of UHECR observations,2025-02-12T21:21:20Z,"Jan Ebr, Jiří Blažek, Jakub Vícha, Tanguy Pierog, Eva Santos, Petr Trávníček, Nikolas Denner, Ralf Ulrich","Data from multiple experiments suggest that the current interaction models
used in Monte Carlo simulations do not correctly reproduce the hadronic
interactions in air showers produced by ultra-high-energy cosmic rays (UHECR).
We have created a large library of UHECR simulations where the interactions at
the highest energies are slightly modified in various ways - but always within
the constraints of the accelerator data, without any abrupt changes with energy
and without assuming any specific mechanism or dramatically new physics at the
ultra-high energies. Recent results of the Pierre Auger Observatory indicate a
need for a change in the prediction of the models for both the muon content at
ground and the depth of the maximum of longitudinal development of the shower.
In our parameter space, we find combinations of modifications that are in
agreement with this analysis, however a consistent description of UHECR showers
remains elusive. Our library however provides a realistic representation of the
freedom in the modeling of the hadronic interactions and offers an opportunity
to quantify uncertainties of various predictions. This can be particularly
valuable for the design of future observatories where hadronic models are often
used as input for the prediction of the performance. We demonstrate this
powerful capability on several selected examples.",http://arxiv.org/abs/2502.08798v1
"Efficient and Trustworthy Block Propagation for Blockchain-enabled
  Mobile Embodied AI Networks: A Graph Resfusion Approach",2025-01-26T07:47:05Z,"Jiawen Kang, Jiana Liao, Runquan Gao, Jinbo Wen, Huawei Huang, Maomao Zhang, Changyan Yi, Tao Zhang, Dusit Niyato, Zibin Zheng","By synergistically integrating mobile networks and embodied artificial
intelligence (AI), Mobile Embodied AI Networks (MEANETs) represent an advanced
paradigm that facilitates autonomous, context-aware, and interactive behaviors
within dynamic environments. Nevertheless, the rapid development of MEANETs is
accompanied by challenges in trustworthiness and operational efficiency.
Fortunately, blockchain technology, with its decentralized and immutable
characteristics, offers promising solutions for MEANETs. However, existing
block propagation mechanisms suffer from challenges such as low propagation
efficiency and weak security for block propagation, which results in delayed
transmission of vehicular messages or vulnerability to malicious tampering,
potentially causing severe traffic accidents in blockchain-enabled MEANETs.
Moreover, current block propagation strategies cannot effectively adapt to
real-time changes of dynamic topology in MEANETs. Therefore, in this paper, we
propose a graph Resfusion model-based trustworthy block propagation
optimization framework for consortium blockchain-enabled MEANETs. Specifically,
we propose an innovative trust calculation mechanism based on the trust cloud
model, which comprehensively accounts for randomness and fuzziness in the miner
trust evaluation. Furthermore, by leveraging the strengths of graph neural
networks and diffusion models, we develop a graph Resfusion model to
effectively and adaptively generate the optimal block propagation trajectory.
Simulation results demonstrate that the proposed model outperforms other
routing mechanisms in terms of block propagation efficiency and
trustworthiness. Additionally, the results highlight its strong adaptability to
dynamic environments, making it particularly suitable for rapidly changing
MEANETs.",http://arxiv.org/abs/2502.09624v1
"On the Bias, Fairness, and Bias Mitigation for a Wearable-based Freezing
  of Gait Detection in Parkinson's Disease",2025-01-29T18:43:01Z,"Timothy Odonga, Christine D. Esper, Stewart A. Factor, J. Lucas McKay, Hyeokhyen Kwon","Freezing of gait (FOG) is a debilitating feature of Parkinson's disease (PD),
which is a cause of injurious falls among PD patients. Recent advances in
wearable-based human activity recognition (HAR) technology have enabled the
detection of FOG subtypes across benchmark datasets. Since FOG manifestation is
heterogeneous, developing models that quantify FOG consistently across patients
with varying demographics, FOG types, and PD conditions is important. Bias and
fairness in FOG models remain understudied in HAR, with research focused mainly
on FOG detection using single benchmark datasets. We evaluated the bias and
fairness of HAR models for wearable-based FOG detection across demographics and
PD conditions using multiple datasets and the effectiveness of transfer
learning as a potential bias mitigation approach. Our evaluation using
demographic parity ratio (DPR) and equalized odds ratio (EOR) showed model bias
(DPR & EOR < 0.8) for all stratified demographic variables, including age, sex,
and disease duration. Our experiments demonstrated that transfer learning from
multi-site datasets and generic human activity representations significantly
improved fairness (average change in DPR +0.027, +0.039, respectively) and
performance (average change in F1-score +0.026, +0.018, respectively) across
attributes, supporting the hypothesis that generic human activity
representations learn fairer representations applicable to health analytics.",http://arxiv.org/abs/2502.09626v1
"A Discontinuous Galerkin Method for Simulating 3D Seismic Wave
  Propagation in Nonlinear Rock Models: Verification and Application to the
  2015 Mw 7.8 Gorkha Earthquake",2025-02-13T19:02:26Z,"Zihua Niu, Alice-Agnes Gabriel, Sebastian Wolf, Thomas Ulrich, Vladimir Lyakhovsky, Heiner Igel","The nonlinear mechanical responses of rocks and soils to seismic waves play
an important role in earthquake physics, influencing ground motion from source
to site. Continuous geophysical monitoring, such as ambient noise
interferometry, has revealed co-seismic wave speed reductions extending tens of
kilometers from earthquake sources. However, the mechanisms governing these
changes remain challenging to model, especially at regional scales. Using a
nonlinear damage model constrained by laboratory experiments, we develop and
apply an open-source 3D discontinuous Galerkin method to simulate regional
co-seismic wave speed changes during the 2015 Mw7.8 Gorkha earthquake. We find
pronounced spatial variations of co-seismic wave speed reduction, ranging from
<0.01% to >50%, particularly close to the source and within the Kathmandu
Basin. The most significant reduction occurs within the sedimentary basin and
varies with basin depths, while wave speed reductions correlate with the fault
slip distribution near the source. By comparing ground motions from simulations
with elastic, viscoelastic, elastoplastic, and nonlinear damage rheologies, we
demonstrate that the nonlinear damage model effectively captures low-frequency
ground motion amplification due to strain-dependent wave speed reductions in
soft sediments. We verify the accuracy of our approach through comparisons with
analytical solutions and assess its scalability on high-performance computing
systems. The model shows near-linear strong and weak scaling up to 2048 nodes,
enabling efficient large-scale simulations. Our findings provide a
physics-based framework to quantify nonlinear earthquake effects and emphasize
the importance of damage-induced wave speed variations for seismic hazard
assessment and ground motion predictions.",http://arxiv.org/abs/2502.09714v1
"Efficient Evaluation of Multi-Task Robot Policies With Active Experiment
  Selection",2025-02-14T00:07:02Z,"Abrar Anwar, Rohan Gupta, Zain Merchant, Sayan Ghosh, Willie Neiswanger, Jesse Thomason","Evaluating learned robot control policies to determine their physical
task-level capabilities costs experimenter time and effort. The growing number
of policies and tasks exacerbates this issue. It is impractical to test every
policy on every task multiple times; each trial requires a manual environment
reset, and each task change involves re-arranging objects or even changing
robots. Naively selecting a random subset of tasks and policies to evaluate is
a high-cost solution with unreliable, incomplete results. In this work, we
formulate robot evaluation as an active testing problem. We propose to model
the distribution of robot performance across all tasks and policies as we
sequentially execute experiments. Tasks often share similarities that can
reveal potential relationships in policy behavior, and we show that natural
language is a useful prior in modeling these relationships between tasks. We
then leverage this formulation to reduce the experimenter effort by using a
cost-aware expected information gain heuristic to efficiently select
informative trials. Our framework accommodates both continuous and discrete
performance outcomes. We conduct experiments on existing evaluation data from
real robots and simulations. By prioritizing informative trials, our framework
reduces the cost of calculating evaluation metrics for robot policies across
many tasks.",http://arxiv.org/abs/2502.09829v1
"Strain energy enhanced room-temperature magnetocaloric effect in
  second-order magnetic transition materials",2025-02-14T01:40:54Z,"Xiaohe Liu, Ping Song, Sen Yao, Yuhao Lei, Ling Yang, Shenxiang Du, Yiran Deng, Defeng Guo","Large magnetic entropy change (deltaSM) can realize a prominent heat
transformation under the magnetic field and directly strengthen the efficacy of
the magnetocaloric effect, which provides a pioneering environmentally friendly
solid-state strategy to improve refrigeration capacities and efficiencies. The
second-order magnetic transition (SOMT) materials have broader deltaSM peaks
without thermal hysteresis compared with most first-order magnetic transition
materials, making them highly attractive in magnetic refrigeration, especially
in the room temperature range. Here, we report a significant enhancement of
deltaSM at room temperature in single-crystal Mn5Ge3. In this SOMT system, we
realize a 60% improvement of -deltaSM from 3.5 J/kgK to 5.6 J/kgK at T = 300K.
This considerable enhancement of deltaSM is achieved by intentionally
introducing strain energy through high-pressure constrained deformation. Both
experimental results and Monte Carlo simulations demonstrate that the
enhancement of deltaSM originates from the microscopic strain and lattice
deformation induced by strain energy after deformation. This strain energy will
reconstruct the energy landscape of this ferromagnetic system and enhance
magnetization, resulting in a giant intensity of magnetocaloric responses. Our
findings provide an approach to increase magnetic entropy change and may give
fresh ideas for exploring advanced magnetocaloric materials.",http://arxiv.org/abs/2502.09856v1
On Self-Propulsion by Oscillations in a Viscous Liquid,2025-02-14T08:45:06Z,"Giovanni P. Galdi, Boris Muha, Ana Radošević","Suppose that a body $\mathscr B$ can move by translatory motion with velocity
$\boldsymbol{\gamma}$ in an otherwise quiescent Navier-Stokes liquid, $\mathscr
L$, filling the entire space outside $\mathscr B$. Denote by $\Omega =
\Omega(t)$, $t\in\mathbb{R}$, the one-parameter family of bounded, sufficiently
smooth domains of $\mathbb{R}^3$, each one representing the configuration of
$\mathscr B$ at time $t$ with respect to a frame with the origin at the center
of mass $G$ and axes parallel to those of an inertial frame. We assume that
there are no external forces acting on the coupled system $\mathscr S :=
\mathscr B +\mathscr L$ and that the only driving mechanism is a prescribed
change in shape of $\Omega$ with time. The self-propulsion problem that we
would like to address can be thus qualitatively formulated as follows. Suppose
that $\mathscr B$ changes its shape in a given time-periodic fashion, namely,
$\Omega(t+T) = \Omega(t)$, for some $T > 0$ and all $t \in \mathbb{R}$. Then,
find necessary and sufficient conditions on the map $t\mapsto \Omega(t)$
securing that $\mathscr B$ self-propels, that is, $G$ covers any given finite
distance in a finite time. We show that this problem is solvable, in a suitable
function class, provided the amplitude of the oscillations is below a given
constant. Moreover, we provide examples where the propelling velocity of
$\mathscr B$ is explicitly evaluated in terms of the physical parameters and
the frequency of oscillations.",http://arxiv.org/abs/2502.10009v1
"Strain-Induced Optical and Molecular Transformations in PET Films for
  Organic Electronic Applications",2025-02-14T12:21:50Z,"Mahya Ghorab, Ayush K. Ranga, Patrice Donfack, Arnulf Materny, Veit Wagner, Mojtaba Joodaki","Poly(ethylene terephthalate) (PET) films are widely used in flexible
electronics and optoelectronics, where their mechanical durability and optical
performance under strain are essential for device reliability. This study
investigates the impact of applied mechanical strain on the optical and
molecular properties of PET at room temperature,using UV-Vis absorption and
Raman spectroscopy. The work explores how varying strain levels, from 0%
(unstretched) to 30%, affect the transparency, vibrational modes, and molecular
reorganization within PET films. UV-Vis absorbance measurements reveal that
strain induces significant changes in the light transmission properties of PET,
particularly in the visible range, and increases absorption in the UVA and
visible region by up to 100%. Raman spectra indicate that strain levels higher
than 5% lead to irreversible shifts of vibrational lines, accompanied by an
increase of their full width at half maximum (FWHM), suggesting molecular
reorientation and crystallinity changes. The phonon mode coupled with C-O
stretching [O-CH2] shows the strongest response to applied mechanical stress.
This study provides a comprehensive understanding of strain-induced optical and
structural alterations in PET, with implications for improving the mechanical
and optical performance of PET-based devices in strainsensitive applications,
such as organic solar cells (OSCs), organic light-emitting diodes (OLEDs), and
flexible sensors.",http://arxiv.org/abs/2502.10113v1
"Modeling biases in binary decision-making within the generalized
  nonlinear q-voter model",2025-02-14T13:57:42Z,"Maciej Doniec, Pratik Mullick, Parongama Sen, Katarzyna Sznajd-Weron","Binary decision frameworks are widely used in the social sciences, including
management and economics, to understand collective behavior. In group
decision-making, opinions evolve through social influence, shaping outcomes
that lead to either consensus or polarization. The $q$ voter model, also known
as the non-linear voter model, has been extensively studied in this context.
However, the impact of an individual's current opinion on their future stance
has been largely overlooked. To fill this gap, we introduce a generalized model
in which an agent's opinion depends not only on its neighbors but also on its
own state. As in the original $q$-voter model, a unanimous influence group of
size $q$ causes the agent to adopt the group's opinion. However, if the group
is not unanimous, the agent will change its opinion with a probability
influenced by its current state. This introduces a bias toward a choice that
reflects external factors such as politics or advertising. Our model
generalizes previous $q$-voter models, including the original one, while
allowing for a wider range of scenarios. We analyze the model on a complete
graph, deriving the phase diagram and the exit probability for finite systems.
We support our analytical approach with Monte Carlo simulations and show that
they overlap even for small systems of size $N=64$. Our results show that the
exit probability depends on $q$. For $q \geq 3$, the exit probability exhibits
a shape that was not observed in previous models, which implies that increasing
initial support for a decision does not necessarily change the final collective
outcome.",http://arxiv.org/abs/2502.10172v1
"Analysis of Stable Vertex Values: Fast Query Evaluation Over An Evolving
  Graph",2025-02-14T22:15:26Z,"Mahbod Afarin, Chao Gao, Xizhe Yin, Zhijia Zhao, Nael Abu-Ghazaleh, Rajiv Gupta","Evaluating a query over a large, irregular graph is inherently challenging.
This challenge intensifies when solving a query over a sequence of snapshots of
an evolving graph, where changes occur through the addition and deletion of
edges. We carried out a study that shows that due to the gradually changing
nature of evolving graphs, when a vertex-specific query (e.g., SSSP) is
evaluated over a sequence of 25 to 100 snapshots, for 53.2% to 99.8% of
vertices, the query results remain unchanged across all snapshots. Therefore,
the Unchanged Vertex Values (UVVs) can be computed once and then minimal
analysis can be performed for each snapshot to obtain the results for the
remaining vertices in that snapshot. We develop a novel intersection-union
analysis that very accurately computes lower and upper bounds of vertex values
across all snapshots. When the lower and upper bounds for a vertex are found to
be equal, we can safely conclude that the value found for the vertex remains
the same across all snapshots. Therefore, the rest of our query evaluation is
limited to computing values across snapshots for vertices whose bounds do not
match. We optimize this latter step evaluation by concurrently performing
incremental computations on all snapshots over a significantly smaller
subgraph. Our experiments with several benchmarks and graphs show that we need
to carry out per snapshot incremental analysis for under 42% vertices on a
graph with under 32% of edges. Our approach delivers speedups of 2.01-12.23x
when compared to the state-of-the-art RisGraph implementation of the
KickStarter-based incremental algorithm for 64 snapshots.",http://arxiv.org/abs/2502.10579v1
"Correlative and in situ microscopy investigation of phase
  transformation, crystal growth and degradation of antimony sulfide thin films",2025-02-16T19:53:53Z,"Mingjian Wu, Maïssa K. S. Barr, Vanessa M. Koch, Martin Dierner, Tobias Dierke, Penghan Lu, Johannes Will, Rafal Dunin-Borkowski, Janina Maultzsch, Julien Bachmann, Erdmann Spiecker","Antimony sulfide (Sb$_2$S$_3$), a compound of earth-abundant elements with
highly anisotropic, quasi-layered crystal structure, triggered growing interest
as a solar absorber in photovoltaics and as a phase change material in memory
devices, yet challenges remain in achieving high-quality thin films with
controlled nucleation and growth for optimal performance. Here, we investigate
the phase transformation, crystal structure and properties, growth and
degradation of atomic layer deposited Sb$_2$S$_3$ thin films using in situ TEM
and correlative ex situ analysis. The as-deposited amorphous films crystallized
at 243{\deg}C, forming grains with an [100] out-of-plane texture and developed
into tens to hundreds of micrometer, leaves-shaped grains. Introducing an
ultra-thin ZnS interfacial layer increased nucleation density, and resulted in
a few micrometer-sized, more uniform grains while retaining the overall [100]
texture. In situ observations and subsequent crystal orientation analysis with
cutting-edge 4D-STEM and EBSD revealed that the grains grew faster along the
[010] ribbon direction and that the bare films underwent early-stage
degradation, forming holes in amorphous regions during annealing. The ZnS
interlayer mitigated degradation, stabilizing the films and improving their
uniformity. These findings offer valuable insights for optimizing Sb$_2$S$_3$
thin films for applications both as solar cell materials and phase change
materials.",http://arxiv.org/abs/2502.11247v2
Non-Uniform Memory Sampling in Experience Replay,2025-02-16T23:04:16Z,Andrii Krutsylo,"Continual learning is the process of training machine learning models on a
sequence of tasks where data distributions change over time. A well-known
obstacle in this setting is catastrophic forgetting, a phenomenon in which a
model drastically loses performance on previously learned tasks when learning
new ones. A popular strategy to alleviate this problem is experience replay, in
which a subset of old samples is stored in a memory buffer and replayed with
new data. Despite continual learning advances focusing on which examples to
store and how to incorporate them into the training loss, most approaches
assume that sampling from this buffer is uniform by default.
  We challenge the assumption that uniform sampling is necessarily optimal. We
conduct an experiment in which the memory buffer updates the same way in every
trial, but the replay probability of each stored sample changes between trials
based on different random weight distributions. Specifically, we generate 50
different non-uniform sampling probability weights for each trial and compare
their final accuracy to the uniform sampling baseline. We find that there is
always at least one distribution that significantly outperforms the baseline
across multiple buffer sizes, models, and datasets. These results suggest that
more principled adaptive replay policies could yield further gains. We discuss
how exploiting this insight could inspire new research on non-uniform memory
sampling in continual learning to better mitigate catastrophic forgetting.
  The code supporting this study is available at
$\href{https://github.com/DentonJC/memory-sampling}{https://github.com/DentonJC/memory-sampling}$.",http://arxiv.org/abs/2502.11305v1
"Mimicking the Familiar: Dynamic Command Generation for Information Theft
  Attacks in LLM Tool-Learning System",2025-02-17T02:15:46Z,"Ziyou Jiang, Mingyang Li, Guowei Yang, Junjie Wang, Yuekai Huang, Zhiyuan Chang, Qing Wang","Information theft attacks pose a significant risk to Large Language Model
(LLM) tool-learning systems. Adversaries can inject malicious commands through
compromised tools, manipulating LLMs to send sensitive information to these
tools, which leads to potential privacy breaches. However, existing attack
approaches are black-box oriented and rely on static commands that cannot adapt
flexibly to the changes in user queries and the invocation chain of tools. It
makes malicious commands more likely to be detected by LLM and leads to attack
failure. In this paper, we propose AutoCMD, a dynamic attack comment generation
approach for information theft attacks in LLM tool-learning systems. Inspired
by the concept of mimicking the familiar, AutoCMD is capable of inferring the
information utilized by upstream tools in the toolchain through learning on
open-source systems and reinforcement with target system examples, thereby
generating more targeted commands for information theft. The evaluation results
show that AutoCMD outperforms the baselines with +13.2% $ASR_{Theft}$, and can
be generalized to new tool-learning systems to expose their information leakage
risks. We also design four defense methods to effectively protect tool-learning
systems from the attack.",http://arxiv.org/abs/2502.11358v1
Interference patterns for simple lens models in wave-optics regime,2025-02-17T06:45:02Z,Ashish Kumar Meena,"This work studies interference patterns created by simple lens models (point
mass, Chang-Refsdal, and binary lens) in the wave optics regime, primarily in
the context of lensing of gravitational waves (GWs) in the LIGO band at
frequencies around 100 Hz. We study how the interference patterns behave close
to the caustic curves which mark the high magnification regions in conventional
geometric optics. In addition, we also look at the formation of highly
de-amplified regions in the amplification maps close to caustics and how they
differ under wave and geometric optics. We see that for a source close to
caustics, the oscillations in the amplification factor (their amplitude and
location of crests and troughs) can differ significantly in wave optics
compared to geometric optics. As we move away from caustics, the wave optics
amplification factor starts to converge towards geometric optics one,
especially the frequencies at which crests and through occur in the
amplification factor, although the amplitude of these oscillations can still be
considerably different. For Chang-Refsdal and binary lens with ${\sim}100\:{\rm
M_\odot}-200\:{\rm M_\odot}$ can introduce significant de-amplification at
frequencies ${\sim}100$ Hz when the source is close to caustics which may help
us distinguish such lenses from the point mass lens.",http://arxiv.org/abs/2502.11488v1
"Towards Understanding Fine-Tuning Mechanisms of LLMs via Circuit
  Analysis",2025-02-17T13:59:41Z,"Xu Wang, Yan Hu, Wenyu Du, Reynold Cheng, Benyou Wang, Difan Zou","Fine-tuning significantly improves the performance of Large Language Models
(LLMs), yet its underlying mechanisms remain poorly understood. This paper aims
to provide an in-depth interpretation of the fine-tuning process through
circuit analysis, a popular tool in Mechanistic Interpretability (MI). Unlike
previous studies
\cite{prakash2024finetuningenhancesexistingmechanisms,chhabra2024neuroplasticity}
that focus on tasks where pre-trained models already perform well, we develop a
set of mathematical tasks where fine-tuning yields substantial performance
gains, which are closer to the practical setting. In our experiments, we
identify circuits at various checkpoints during fine-tuning and examine the
interplay between circuit analysis, fine-tuning methods, and task complexities.
First, we find that while circuits maintain high node similarity before and
after fine-tuning, their edges undergo significant changes, which is in
contrast to the previous work
\cite{prakash2024finetuningenhancesexistingmechanisms,chhabra2024neuroplasticity}
that show circuits only add some additional components after fine-tuning. Based
on these observations, we develop a circuit-aware Low-Rank Adaptation (LoRA)
method, which assigns ranks to layers based on edge changes in the circuits.
Experimental results demonstrate that our circuit-based LoRA algorithm achieves
an average performance improvement of 2.46\% over standard LoRA with similar
parameter sizes. Furthermore, we explore how combining circuits from subtasks
can enhance fine-tuning in compositional tasks, providing new insights into the
design of such tasks and deepening the understanding of circuit dynamics and
fine-tuning mechanisms.",http://arxiv.org/abs/2502.11812v1
Gaseous Object Detection,2025-02-18T01:26:07Z,"Kailai Zhou, Yibo Wang, Tao Lv, Qiu Shen, Xun Cao","Object detection, a fundamental and challenging problem in computer vision,
has experienced rapid development due to the effectiveness of deep learning.
The current objects to be detected are mostly rigid solid substances with
apparent and distinct visual characteristics. In this paper, we endeavor on a
scarcely explored task named Gaseous Object Detection (GOD), which is
undertaken to explore whether the object detection techniques can be extended
from solid substances to gaseous substances. Nevertheless, the gas exhibits
significantly different visual characteristics: 1) saliency deficiency, 2)
arbitrary and ever-changing shapes, 3) lack of distinct boundaries. To
facilitate the study on this challenging task, we construct a GOD-Video dataset
comprising 600 videos (141,017 frames) that cover various attributes with
multiple types of gases. A comprehensive benchmark is established based on this
dataset, allowing for a rigorous evaluation of frame-level and video-level
detectors. Deduced from the Gaussian dispersion model, the physics-inspired
Voxel Shift Field (VSF) is designed to model geometric irregularities and
ever-changing shapes in potential 3D space. By integrating VSF into Faster
RCNN, the VSF RCNN serves as a simple but strong baseline for gaseous object
detection. Our work aims to attract further research into this valuable albeit
challenging area.",http://arxiv.org/abs/2502.12415v1
"Disentangling Long-Short Term State Under Unknown Interventions for
  Online Time Series Forecasting",2025-02-18T07:31:04Z,"Ruichu Cai, Haiqin Huang, Zhifang Jiang, Zijian Li, Changze Zhou, Yuequn Liu, Yuming Liu, Zhifeng Hao","Current methods for time series forecasting struggle in the online scenario,
since it is difficult to preserve long-term dependency while adapting
short-term changes when data are arriving sequentially. Although some recent
methods solve this problem by controlling the updates of latent states, they
cannot disentangle the long/short-term states, leading to the inability to
effectively adapt to nonstationary. To tackle this challenge, we propose a
general framework to disentangle long/short-term states for online time series
forecasting. Our idea is inspired by the observations where short-term changes
can be led by unknown interventions like abrupt policies in the stock market.
Based on this insight, we formalize a data generation process with unknown
interventions on short-term states. Under mild assumptions, we further leverage
the independence of short-term states led by unknown interventions to establish
the identification theory to achieve the disentanglement of long/short-term
states. Built on this theory, we develop a long short-term disentanglement
model (LSTD) to extract the long/short-term states with long/short-term
encoders, respectively. Furthermore, the LSTD model incorporates a smooth
constraint to preserve the long-term dependencies and an interrupted dependency
constraint to enforce the forgetting of short-term dependencies, together
boosting the disentanglement of long/short-term states. Experimental results on
several benchmark datasets show that our \textbf{LSTD} model outperforms
existing methods for online time series forecasting, validating its efficacy in
real-world applications.",http://arxiv.org/abs/2502.12603v1
"Study of amorphous alumina coatings for next-generation nuclear
  reactors: hightemperature in-situ and post-mortem Raman spectroscopy and
  X-ray diffraction",2025-02-18T07:50:17Z,"Magdalena Gaweda, Piotr Jelen, Agata Zaborowska, Ryszard Diduszko, Lukasz Kurpaska","The present work focuses on the investigation of the thermal stability and
structural integrity of amorphous alumina coatings intended for use as
protective coatings on cladding tubes in Generation IV nuclear reactors,
specifically in the Lead-cooled Fast Reactor (LFR) type. Hightemperature Raman
spectroscopy and high-temperature X-ray diffraction analyses were carried out
up to 1050 C on a 5 um coating deposited by the pulsed laser deposition (PLD)
technique on a 316L steel substrate. The experiments involved the in-situ
examination of structural changes in the material under increasing temperature,
along with ex-situ Raman imaging of the surface and cross-section of the
coating after thermal treatments of different lengths. As it was expected, the
presence of alpha-alumina was detected with the addition of other polymorphs,
gamma- and theta-Al2O3, found in the material after longer high-temperature
exposure. The use of two structural analysis methods and two lasers excitation
wavelengths with Raman spectroscopy allowed us to detect all the mentioned
phases despite different mode activity. Alumina analysis was based on the
emission spectra, while substrate oxidation products were identified through
the structural bands. The experiments depicted a dependence of the phase
composition of oxidation products and alumina's degree of crystallization on
the length of the treatment. Nevertheless, the observed structural changes did
not occur rapidly, and the coating's integrity remained intact. Moreover,
oxidation signs occurred locally at temperatures exceeding the LFR reactor's
working temperature, confirming the material's great potential as a protective
coating in the operational conditions of LFR nuclear reactors.",http://arxiv.org/abs/2502.12612v1
"An improved wind power prediction via a novel wind ramp identification
  algorithm",2025-02-18T12:11:46Z,Yifan Xu,"Authors: Yifan Xu Abstract: Conventional wind power prediction methods often
struggle to provide accurate and reliable predictions in the presence of sudden
changes in wind speed and power output. To address this challenge, this study
proposes an integrated algorithm that combines a wind speed mutation
identification algorithm, an optimized similar period matching algorithm and a
wind power prediction algorithm. By exploiting the convergence properties of
meteorological events, the method significantly improves the accuracy of wind
power prediction under sudden meteorological changes. Firstly, a novel adaptive
model based on variational mode decomposition, the VMD-IC model, is developed
for identifying and labelling key turning points in the historical wind power
data, representing abrupt meteorological environments. At the same time, this
paper proposes Ramp Factor (RF) indicators and wind speed similarity
coefficient to optimize the definition algorithm of the current wind power ramp
event (WPRE). After innovating the definition of climbing and denoising
algorithm, this paper uses the Informer deep learning algorithm to output the
first two models as well as multimodal data such as NWP numerical weather
forecasts to achieve accurate wind forecasts. The experimental results of the
ablation study confirm the effectiveness and reliability of the proposed wind
slope identification method. Compared with existing methods, the proposed model
exhibits excellent performance and provides valuable guidance for the safe and
cost-effective operation of power systems.",http://arxiv.org/abs/2502.12807v1
Semi-supervised classification of bird vocalizations,2025-02-19T05:31:13Z,"Simen Hexeberg, Mandar Chitre, Matthias Hoffmann-Kuhnt, Bing Wen Low","Changes in bird populations can indicate broader changes in ecosystems,
making birds one of the most important animal groups to monitor. Combining
machine learning and passive acoustics enables continuous monitoring over
extended periods without direct human involvement. However, most existing
techniques require extensive expert-labeled datasets for training and cannot
easily detect time-overlapping calls in busy soundscapes. We propose a
semi-supervised acoustic bird detector designed to allow both the detection of
time-overlapping calls (when separated in frequency) and the use of few labeled
training samples. The classifier is trained and evaluated on a combination of
community-recorded open-source data and long-duration soundscape recordings
from Singapore. It achieves a mean F0.5 score of 0.701 across 315 classes from
110 bird species on a hold-out test set, with an average of 11 labeled training
samples per class. It outperforms the state-of-the-art BirdNET classifier on a
test set of 103 bird species despite significantly fewer labeled training
samples. The detector is further tested on 144 microphone-hours of continuous
soundscape data. The rich soundscape in Singapore makes suppression of false
positives a challenge on raw, continuous data streams. Nevertheless, we
demonstrate that achieving high precision in such environments with minimal
labeled training data is possible.",http://arxiv.org/abs/2502.13440v1
"Distal Causal Excursion Effects: Modeling Long-Term Effects of
  Time-Varying Treatments in Micro-Randomized Trials",2025-02-19T07:36:54Z,Tianchen Qian,"Micro-randomized trials (MRTs) play a crucial role in optimizing digital
interventions. In an MRT, each participant is sequentially randomized among
treatment options hundreds of times. While the interventions tested in MRTs
target short-term behavioral responses (proximal outcomes), their ultimate goal
is to drive long-term behavior change (distal outcomes). However, existing
causal inference methods, such as the causal excursion effect, are limited to
proximal outcomes, making it challenging to quantify the long-term impact of
interventions. To address this gap, we introduce the distal causal excursion
effect (DCEE), a novel estimand that quantifies the long-term effect of
time-varying treatments. The DCEE contrasts distal outcomes under two excursion
policies while marginalizing over most treatment assignments, enabling a
parsimonious and interpretable causal model even with a large number of
decision points. We propose two estimators for the DCEE -- one with
cross-fitting and one without -- both robust to misspecification of the outcome
model. We establish their asymptotic properties and validate their performance
through simulations. We apply our method to the HeartSteps MRT to assess the
impact of activity prompts on long-term habit formation. Our findings suggest
that prompts delivered earlier in the study have a stronger long-term effect
than those delivered later, underscoring the importance of intervention timing
in behavior change. This work provides the critically needed toolkit for
scientists working on digital interventions to assess long-term causal effects
using MRT data.",http://arxiv.org/abs/2502.13500v1
"Transfer-Prompting: Enhancing Cross-Task Adaptation in Large Language
  Models via Dual-Stage Prompts Optimization",2025-02-20T02:47:04Z,"Yupeng Chang, Yi Chang, Yuan Wu","Large language models (LLMs) face significant challenges when balancing
multiple high-level objectives, such as generating coherent, relevant, and
high-quality responses while maintaining efficient task adaptation across
diverse tasks. To address these challenges, we introduce Transfer-Prompting, a
novel two-stage framework designed to enhance cross-task adaptation in prompt
generation. The framework comprises two key components: (1) source prompt
construction, which refines the original prompts on source task datasets to
generate source prompts with enhanced generalization ability, and (2) target
prompt generation, which enhances cross-task adaptation of target prompts by
fine-tuning a set of high-scored source prompts on task-specific datasets. In
each optimization cycle, a reference LLM generates candidate prompts based on
historical prompt-score pairs and task descriptions in our designed reference
prompt. These candidate prompts are refined iteratively, while a scorer LLM
evaluates their effectiveness using the multi-dimensional metrics designed in
the objective prompts evaluator-a novel contribution in this work that provides
a holistic evaluation of prompt quality and task performance. This feedback
loop facilitates continuous refinement, optimizing both prompt quality and
task-specific outcomes. We validate Transfer-Prompting through extensive
experiments across 25 LLMs, including 7 foundational models and 18 specialized
models, evaluated on 9 diverse datasets. The results demonstrate that
Transfer-Prompting significantly improves task-specific performance,
highlighting its potential for enhancing cross-task adaptation in LLMs. The
code is available at https://github.com/llm172/Transfer-Prompting.",http://arxiv.org/abs/2502.14211v1
"Multi-Layer Deep xVA: Structural Credit Models, Measure Changes and
  Convergence Analysis",2025-02-20T17:41:55Z,"Kristoffer Andersson, Alessandro Gnoatto","We propose a structural default model for portfolio-wide valuation
adjustments (xVAs) and represent it as a system of coupled backward stochastic
differential equations. The framework is divided into four layers, each
capturing a key component: (i) clean values, (ii) initial margin and Collateral
Valuation Adjustment (ColVA), (iii) Credit/Debit Valuation Adjustments
(CVA/DVA) together with Margin Valuation Adjustment (MVA), and (iv) Funding
Valuation Adjustment (FVA). Because these layers depend on one another through
collateral and default effects, a naive Monte Carlo approach would require
deeply nested simulations, making the problem computationally intractable.
  To address this challenge, we use an iterative deep BSDE approach, handling
each layer sequentially so that earlier outputs serve as inputs to the
subsequent layers. Initial margin is computed via deep quantile regression to
reflect margin requirements over the Margin Period of Risk. We also adopt a
change-of-measure method that highlights rare but significant defaults of the
bank or counterparty, ensuring that these events are accurately captured in the
training process.
  We further extend Han and Long's standard a posteriori error analysis
\cite{han2020convergence} to BSDEs on bounded domains by leveraging
\cite{bouchard2009strong}. Due to the random exit from the domain, we obtain an
order of convergence of $\mathcal{O}(h^{1/4-\epsilon})$ rather than the usual
$\mathcal{O}(h^{1/2})$.
  Numerical experiments illustrate that this method drastically reduces
computational demands and successfully scales to high-dimensional,
non-symmetric portfolios. The results confirm its effectiveness and accuracy,
offering a practical alternative to nested Monte Carlo simulations in
multi-counterparty xVA analyses.",http://arxiv.org/abs/2502.14766v1
Metabolic energy expenditure for time-varying isometric forces,2025-01-01T04:56:34Z,"Sriram Sekaripuram Muralidhar, Kristen Heitman, Samuel C. Walcott, Manoj Srinivasan","Muscles consume metabolic energy (ATP) to produce force. A mathematical model
for energy expenditure can be useful in estimating real-time costs of movements
or to predict energy optimal movements. Metabolic cost models developed so far
have predominantly aimed at dynamic movement tasks, where mechanical work
dominates. Further, while it is known that both force magnitude and rate of
change of force (force rate) affect metabolic cost, it is not known how these
terms interact, or if the force rate dependence can be a consequence of the
force dependence. Here, we performed extensive human subject experiments,
involving each subject over 5 hours of metabolic trials, which systematically
changed the mean forces and forces rates so as to characterize a holistic
relation for metabolic cost based on both force and force rate -- or
analogously, torque and torque rate. Our experiments involved humans producing
symmetric or asymmetric sinusoidal forces with different means, amplitudes,
frequencies, and rise and fall periods. We showed that the metabolic cost can
be well-approximated by a sum of power law functions of torque and torque rate.
We found that the metabolic cost scales non-linearly with joint torque (with
exponent = 1.36) and non-linearly with torque rate (with exponent = 2.5).
Surprisingly, the data suggested that the cost was roughly four times higher
for decreasing the torque than increasing, mirroring the analogous ratio
between the cost of positive and negative work. Using these metabolic cost
relations, we show that if the metabolic cost scales with particular exponents
with muscle force and force rates, the same exponents will be observed in
multi-joint tasks with multiple muscles. Our new metabolic cost model involving
both force and force rate will potentially allow better predictions of energy
optimal movements and thus inform wearable robot design and analysis.",http://arxiv.org/abs/2501.00723v1
"Continuation of an Optical Spectroscopic Campaign of Fermi Blazar
  Candidates with TNG: Discovery of a New Changing-Look Blazar",2025-01-07T10:44:33Z,"N. Álvarez Crespo, A. Domínguez, V. S. Paliya, M. Chamorro Cazorla, P. Sánchez Blázquez, A. Gil de Paz","Context. Blazars are a distinct subclass of active galactic nuclei (AGN),
known for their fast variability, high polarization, and intense emission
across the electromagnetic spectrum, from radio waves to gamma rays. Gamma-ray
blazar candidates of uncertain type (BCU) are an ongoing challenge in gamma-ray
astronomy due to difficulties in classification and redshift determination.
Aims. This study continues an optical spectroscopic campaign aimed at
identifying the characteristics of BCUs to improve classification and redshift
estimates, particularly focusing on low-synchrotron-peak sources. Methods. We
conducted a detailed analysis of optical spectroscopic data for a sample of 21
low-synchrotron-peak BCUs plus one bl lac with contradictory results in the
literature, using the 3.58-m Telescopio Nazionale Galileo (TNG, La Palma,
Spain). Results. Our analysis identifies 14 out of the 21 BCUs as flat-spectrum
radio quasars (FSRQs), demonstrating the effectiveness of our selection
criteria. Notably, four FSRQs have redshifts exceeding 1, including 4FGL
J2000.0+4214 at z = 2.04. Six sources are classified as bl lacs, with one of
them, 4FGL J0746.5-0719, showing a featureless spectrum in this work despite
previously exhibiting strong lines, suggesting it may be a changing-look
blazar. One source remains classified as a BCU due to a noisy spectrum.
Additionally, we observed a bl lac object, 4FGL J1054.5+2211, due to
inconsistent redshift estimates in the literature, but we could not confirm any
redshift due to its featureless spectrum. Our findings provide insights into
the classification and redshift estimation of blazar candidates, emphasizing
the need for continued spectroscopic monitoring.",http://arxiv.org/abs/2501.03693v1
"Bit reset protocols that obey activity-constrained speed limits do not
  minimize work for a given speed",2025-01-08T11:40:53Z,"Daan Mulder, Thomas E. Ouldridge, Pieter Rein ten Wolde","The goal of thermodynamic optimal control theory is to find protocols to
change the state of a system from an initial to a desired final distribution,
within a finite time, with the least possible expenditure of work. The optimal
protocol is closely linked to the intrinsic dynamics of the system at hand. The
fact that these dynamics can vary widely has made a general solution elusive.
Recent years have seen great progress by recasting the question in terms of a
quantity called total activity, i.e. the average number of jumps between states
of the system, rather than the time that the operation is allowed to take. This
perspective has allowed for general expressions for the minimal work as a
function of the total activity, and the minimal total activity required for a
given work. The expression for minimal total activity can be recast as an
apparent minimal operation time or speed limit. However, it is unclear whether
protocols optimized under a constrained activity actually require the lowest
work input for a given operation time. In the context of bit reset, we show
that directly minimizing work for a given operation time leads to protocols
that require significantly less work to perform the operation than the
activity-constrained protocol of the same duration. We show how the resulting
protocols differ. One reason for the difference is the fact that the activity
rate is not constant over the course of the protocol: it depends on both the
transition rates and the distribution of the bit, both of which change during
the copy operation. In the limit of long protocol duration, we find an
expression for the difference between the resulting minimal work for both
optimization schemes, for a general class of dynamics. The time-constrained
approach always outperforms the activity-constrained approach for a given
constrained duration, and the difference in work can be arbitrarily large.",http://arxiv.org/abs/2501.04439v1
Comparing radial migration in dark matter and MOND regimes,2025-01-10T12:35:58Z,"R. Nagy, F. Janák, M. Šturc, M. Jurčík, E. Puha","Multiple studies on radial migration in disc galaxies have proven the
importance of the effect of resonances with non-axisymmetric components on the
evolution of galactic discs. However, the dynamical effects of classic
Newtonian dynamics with dark matter (DM) differ from MOdified Newtonian
Dynamics (MOND) and might trigger different radial migration. A thorough
analysis of radial migration considering these two gravitational regimes might
shed some light on different predictions of DM and MOND theories. We aim to
quantitatively and qualitatively compare the effects of resonances and stellar
radial migration (churning) in a Milky Way-like (MW-like) galaxy in the DM and
MOND regimes. We performed simulations of a MW-like galaxy to analyse the
effect of non-axisymmetric structures (galactic bar and spiral arms)
considering various parameters of the spiral structure. We conducted a
two-dimensional numerical simulation consisting of the integration of $2 \cdot
10^6$ stars in a static rotating galactic potential for $6~\mbox{Gyr}$. We
analysed the change in the star's position, the guiding radius, as well as the
frequency phase space. We investigated DM and MOND approaches. The outcome of
the simulation shows that the radial migration is much more pronounced in the
MOND regime compared to the DM one. Compared to the DM approach, in the MOND
regime, we observe up to five times as many stars with a maximum change in the
guiding radius of more than $1.5~\mbox{kpc}$ during the time interval from
$2-6~\mbox{Gyr}$.Analysis of the frequency phase space reveals that the most
prominent resonances in all DM and MOND configurations are the co-rotation
resonance with the spiral arms ($m=p=1$), outer Lindblad resonance with the
galactic bar and spiral arms, and the co-rotation resonance ($m=2$, $p=1$) with
the superposition of the galactic bar and spiral arms, $2 \Omega = \Omega_b +
\Omega_{sp}$.",http://arxiv.org/abs/2501.05924v1
Emergent Symbol-like Number Variables in Artificial Neural Networks,2025-01-10T18:03:46Z,"Satchel Grant, Noah D. Goodman, James L. McClelland","What types of numeric representations emerge in Neural Networks (NNs)? To
what degree do NNs induce abstract, mutable, slot-like numeric variables, and
in what situations do these representations emerge? How do these
representations change over learning, and how can we understand the neural
implementations in ways that are unified across different NNs? In this work, we
approach these questions by first training sequence based neural systems using
Next Token Prediction (NTP) objectives on numeric tasks. We then seek to
understand the neural solutions through the lens of causal abstractions or
symbolic algorithms. We use a combination of causal interventions and
visualization methods to find that artificial neural models do indeed develop
analogs of interchangeable, mutable, latent number variables purely from the
NTP objective. We then ask how variations on the tasks and model architectures
affect the models' learned solutions to find that these symbol-like numeric
representations do not form for every variant of the task, and transformers
solve the problem in a notably different way than their recurrent counterparts.
We then show how the symbol-like variables change over the course of training
to find a strong correlation between the models' task performance and the
alignment of their symbol-like representations. Lastly, we show that in all
cases, some degree of gradience exists in these neural symbols, highlighting
the difficulty of finding simple, interpretable symbolic stories of how neural
networks perform numeric tasks. Taken together, our results are consistent with
the view that neural networks can approximate interpretable symbolic programs
of number cognition, but the particular program they approximate and the extent
to which they approximate it can vary widely, depending on the network
architecture, training data, extent of training, and network size.",http://arxiv.org/abs/2501.06141v1
"Intermingled open and closed magnetic field lines near the radial origin
  of the heliospheric current sheet",2025-01-14T20:22:54Z,"Forrest Mozer, Andrii Voshchepynets, Oleksiy Agapitov, Kyung-Eu Choi, Richard Sydora","Aims. To investigate the magnetic field geometry and waves in the region near
the Sun where the heliospheric current sheet is formed. Methods. One good
example of apparent open and closed field lines was found and its fields and
plasmas were analyzed. Results. The radial component of the magnetic field (the
Z-component) measured on the Parker Solar Probe (PSP) changed sign between
12:00 and 13:00 UT on March 30, 2024, when the spacecraft was at 13 solar
radii. This sign change may have occurred because the spacecraft crossed the
heliospheric current sheet on long open magnetic field lines or it may have
occurred because the spacecraft crossed from one side of the equator to the
other on much shorter closed magnetic field lines. During this crossing, two
distinct regions having different magnetic field geometries, strahl flows,
plasma densities, and electric field spectra were observed and identified as
regions with open and closed magnetic field lines, respectively. The two
regions intermingled on time scales less than 100 milliseconds to create a
complex magnetic field geometry. The waves observed in both regions were
electrostatic and composed of wide band signatures (in the open field lines
regions) and well-structured frequency harmonics (in both the open and closed
field lines regions). These harmonic frequencies correlated with the proton
plasma frequency, fpp, with the lowest frequency at ~0.1fpp. This result plus
the field aligned electric field perturbations and plasma density fluctuations,
require that the observed intense electrostatic mode and associated harmonics
were ion acoustic waves. The absence of broadband electrostatic signals in
closed field line regions is explained by the lower (than in open field line
regions) hot and core electron density and higher ratio of the electron plasma
frequency to the electron gyrofrequency, suppressing wave generation.",http://arxiv.org/abs/2501.08419v1
Can LLM Generate Regression Tests for Software Commits?,2025-01-19T15:46:26Z,"Jing Liu, Seongmin Lee, Eleonora Losiouk, Marcel Böhme","Large Language Models (LLMs) have shown tremendous promise in automated
software engineering. In this paper, we investigate the opportunities of LLMs
for automatic regression test generation for programs that take highly
structured, human-readable inputs, such as XML parsers or JavaScript
interpreters. Concretely, we explore the following regression test generation
scenarios for such programs that have so far been difficult to test
automatically in the absence of corresponding input grammars:
  $\bullet$ Bug finding. Given a code change (e.g., a commit or pull request),
our LLM-based approach generates a test case with the objective of revealing
any bugs that might be introduced if that change is applied.
  $\bullet$ Patch testing. Given a patch, our LLM-based approach generates a
test case that fails before but passes after the patch. This test can be added
to the regression test suite to catch similar bugs in the future.
  We implement Cleverest, a feedback-directed, zero-shot LLM-based regression
test generation technique, and evaluate its effectiveness on 22 commits to
three subject programs: Mujs, Libxml2, and Poppler. For programs using more
human-readable file formats, like XML or JavaScript, we found Cleverest
performed very well. It generated easy-to-understand bug-revealing or
bug-reproduction test cases for the majority of commits in just under three
minutes -- even when only the code diff or commit message (unless it was too
vague) was given. For programs with more compact file formats, like PDF, as
expected, it struggled to generate effective test cases. However, the
LLM-supplied test cases are not very far from becoming effective (e.g., when
used as a seed by a greybox fuzzer or as a starting point by the developer).",http://arxiv.org/abs/2501.11086v1
"On the Complexity of Computing a Fastest Temporal Path in Interval
  Temporal Graphs",2025-01-20T10:16:50Z,"Guillaume Aubian, Filippo Brunelli, Feodor F Dragan, Guillaume Ducoffe, Michel Habib, Allen Ibiapina, Laurent Viennot","Temporal graphs arise when modeling interactions that evolve over time. They
usually come in several flavors, depending on the number of parameters used to
describe the temporal aspects of the interactions: time of appearance,
duration, delay of transmission. In the point model, edges appear at specific
points in time, while in the more general interval model, edges can be present
over multiple time intervals. In both models, the delay for traversing an edge
can change with each edge appearance. When time is discrete, the two models are
equivalent in the sense that the presence of an edge during an interval is
equivalent to a sequence of point-in-time occurrences of the edge. However,
this transformation can drastically change the size of the input and has
complexity issues. Indeed, we show a gap between the two models with respect to
the complexity of the classical problem of computing a fastest temporal path
from a source vertex to a target vertex, i.e. a path where edges can be
traversed one after another in time and such that the total duration from
source to target is minimized. It can be solved in near-linear time in the
point model, while we show that the interval model requires quadratic time
under classical assumptions of fine-grained complexity. With respect to linear
time, our lower bound implies a factor of the number of vertices, while the
best known algorithm has a factor of the number of underlying edges.
Interestingly, we show that near-linear time is possible in the interval model
when restricted to all delays being zero, i.e. traversing an edge is
instantaneous.",http://arxiv.org/abs/2501.11380v1
"Mechanical strength investigations of the APPLE-X undulator using Fiber
  Bragg Grating strain measurements",2025-01-20T15:13:46Z,"I. Balossino, A. Polimadei, M. Del Franco, A. Selce, A. Vannozzi, E. Di Pasquale, L. Giannessi, F. Nguyen, A. Petralia, J. Pockar, U. Primozic, R. Geometrante, M. A. Caponero, L. Sabbatini","The SPARC_LAB facility at the INFN LNF is being upgraded to accommodate a new
user facility as part of the SABINA project. It was set up to investigate the
feasibility of an ultra-brilliant photoinjector and to perform FEL experiments.
The new beamline is equipped with three APPLE-X undulators acting as amplifiers
to deliver IR/THz radiation with photon pulses in the ps range, with energy of
tens of uJ, and with linear, circular, or elliptical polarization. The APPLE-X
guarantees to vary the gap amplitude between the magnets arrays and their
relative phase. The entire system has been designed from scratch, and a
structural analysis has been carried out. Once they were in Frascati, in
collaboration with ENEA, a further investigation campaign was launched on the
mechanical, using strain measurements based on optical methods. FBG sensors
were suitable for these tests due to their immunity to electromagnetic noise.
They consist of a phase grating inscribed in the core of a single-mode fiber,
whose Bragg-diffracted light propagates back along the fiber. If bonded to the
mechanical structure, they can be used as strain sensors. By following the
variations in the scattered spectrum, it is possible to perform strain
measurements. Using multiple FBGs applied at selected locations on the
undulator, several measurements were while opening and closing the gap or
changing the phase, but also by studying the quiescent response as a function
of the ambient temperature. The results of these tests show that there is a
clear deformation of the structure related to the temperature changes and
magnetic forces, but the magnitude of this deformation is well within the
tolerances required for the functionality of the undulator since they are
compatible or lower with respect to the one calculated with the finite elements
methods. The tests confirm the reliability of the mechanical structure.",http://arxiv.org/abs/2501.11531v1
"Practical Pipeline-Aware Regression Test Optimization for Continuous
  Integration",2025-01-20T15:39:16Z,"Daniel Schwendner, Maximilian Jungwirth, Martin Gruber, Martin Knoche, Daniel Merget, Gordon Fraser","Massive, multi-language, monolithic repositories form the backbone of many
modern, complex software systems. To ensure consistent code quality while still
allowing fast development cycles, Continuous Integration (CI) is commonly
applied. However, operating CI at such scale not only leads to a single point
of failure for many developers, but also requires computational resources that
may reach feasibility limits and cause long feedback latencies. To address
these issues, developers commonly split test executions across multiple
pipelines, running small and fast tests in pre-submit stages while executing
long-running and flaky tests in post-submit pipelines. Given the long runtimes
of many pipelines and the substantial proportion of passing test executions
(98% in our pre-submit pipelines), there not only a need but also potential for
further improvements by prioritizing and selecting tests. However, many
previously proposed regression optimization techniques are unfit for an
industrial context, because they (1) rely on complex and difficult-to-obtain
features like per-test code coverage that are not feasible in large,
multi-language environments, (2) do not automatically adapt to rapidly changing
systems where new tests are continuously added or modified, and (3) are not
designed to distinguish the different objectives of pre- and post-submit
pipelines: While pre-submit testing should prioritize failing tests,
post-submit pipelines should prioritize tests that indicate non-flaky changes
by transitioning from pass to fail outcomes or vice versa. To overcome these
issues, we developed a lightweight and pipeline-aware regression test
optimization approach that employs Reinforcement Learning models trained on
language-agnostic features. We evaluated our approach on a large industry
dataset collected over a span of 20 weeks of CI test executions. When
predicting...",http://arxiv.org/abs/2501.11550v1
"Experiments and modeling of dust particle heating resulting from changes
  in polarity switching in the PK-4 microgravity laboratory",2025-01-21T16:09:02Z,"Lori S. McCabe, Jeremiah Williams, Saikat Chakraborty Thakur, Uwe Konopka, Evdokiya Kostadinova, Mikhail Pustylnik, Hubertus Thomas, Markus Thoma, Edward Thomas","In the presence of gravity, the micron-sized charged dust particles in a
complex (dusty) plasma are compressed into thin layers. However, under the
microgravity conditions of the Plasma Kristall-4 (PK-4) experiment on the
International Space Station (ISS), the particles fill the plasma, allowing us
to investigate the properties of a three-dimensional (3D) multi-particle
system. This paper examines the change in the spatial ordering and thermal
state of the particle system created when dust particles are stopped by
periodic oscillations of the electric field, known as polarity switching, in a
dc glow discharge plasma.
  Data from the ISS is compared against experiments performed using a
ground-based reference version of PK-4 and numerical simulations. Initial
results show substantive differences in the velocity distribution functions
between experiments on the ground and in microgravity. There are also
differences in the motion of the dust cloud, in microgravity there is an
expansion of the dust cloud at the application of polarity switching which is
not seen in the ground-based experiments. It is proposed that the dust cloud in
microgravity gains thermal energy at the application of polarity switching due
to this expansion. Simulation results suggest that this may be due to a
modification in the effective screening length of the dust at the onset of
polarity switching, which arises from a configuration energy between the
charged particles. Experimental measurements and simulations show that an
extended time (much greater than the Epstein drag decay) is required to
dissipate this energy.",http://arxiv.org/abs/2501.12248v2
"Near-infrared Integral-field Spectroscopy of the Wind Forming Region of
  CW Leo",2025-01-21T20:21:17Z,"Hyosun Kim, Youichi Ohyama, Ho-Gyu Lee, Ji Hoon Kim","The circumstellar envelope of the carbon star CW Leo exhibited various
unexpected changes in recent optical imaging observations. We have performed a
follow-up observation using the Near-infrared Integral-Field Spectrograph
(NIFS) equipped on the Gemini-North telescope. We report the near-infrared
counterparts of a local brightness peak in the optical at the stellar position
of CW Leo. On the other hand, a second peak detected at short wavelengths in
the J band coincides with the brightest, bluest position in the optical images.
The absorption features in the K band are minimized at a radius of 0.2 arcsec
from the predicted stellar position. The reduction of the absorption depths
likely indicates dilution of the absorption features by thermal emission of
dust grains newly formed at such a radius and heated by radiation from the
central star. The broad absorption feature at 1.53 um is significantly deeper
than in template carbon stars, consistent with the presence of a substantial
amount of circumstellar material around CW Leo. Its northeastern quadrant lacks
circumstellar absorption features and scattered light in the near-infrared
regime, which are possibly manifestations of its conical cavity in both gas and
dust. In addition, a cross correlation of CO overtone bands indicates that the
average expansion velocity of dust grains is smaller to the northern direction,
likewise the velocity of transverse wind components derived using the
differential proper motion of a circumstellar whirled pattern. The gradual
brightening of CW Leo and the changes in its innermost circumstellar envelope
need further continuous monitoring observations to properly understand its
transitional phase toward the post-asymptotic-giant-branch stage.",http://arxiv.org/abs/2501.12484v1
Field induced density wave in a kagome superconductor,2025-01-22T22:43:25Z,"Md Shafayat Hossain, Qi Zhang, Julian Ingham, Jinjin Liu, Sen Shao, Yangmu Li, Yuxin Wang, Bal K. Pokharel, Zi-Jia Cheng, Yu-Xiao Jiang, Maksim Litskevich, Byunghoon Kim, Xian Yang, Yongkai Li, Tyler A. Cochran, Yugui Yao, Dragana Popović, Zhiwei Wang, Guoqing Chang, Ronny Thomale, Luis Balicas, M. Zahid Hasan","On the kagome lattice, electrons benefit from the simultaneous presence of
band topology, flat electronic bands, and van Hove singularities, forming
competing or cooperating orders. Understanding the interrelation between these
distinct order parameters remains a significant challenge, leaving much of the
associated physics unexplored. In the kagome superconductor KV3Sb5, which
exhibits a charge density wave (CDW) state below T = 78 K, we uncover an
unpredicted field-induced phase transition below 6 K. The observed transition
is marked by a hysteretic anomaly in the resistivity, nonlinear electrical
transport, and a change in the symmetry of the electronic response as probed
via the angular dependence of the magnetoresistivity. These observations
surprisingly suggest the emergence of an unanticipated broken symmetry state
coexisting with the original CDW. To understand this experimental observation,
we developed a theoretical minimal model for the normal state inside the
high-temperature parent CDW phase where an incommensurate CDW order emerges as
an instability sub-leading to superconductivity. The incommensurate CDW emerges
when superconducting fluctuations become fully suppressed by large magnetic
fields. Our results suggest that, in kagome superconductors, quantum states can
either coexist or are nearly degenerate in energy, indicating that these are
rich platforms to expose new correlated phenomena.",http://arxiv.org/abs/2501.13260v1
Higgs Inflation Model with Small Non-Minimal Coupling Constant,2025-01-26T16:49:25Z,Alexander B. Kaganovich,"In the ""Higgs field+gravity"" model, the selfconsistency of equations obtained
from the original action has the form of an algebraic constraint defining the
scalar $\zeta$ as a function of the Higgs field $\varphi$ and its first
derivatives. The scalar $\zeta$ is present in all equations of motion and has a
significant effect on the dynamics. Transition to the Einstein frame is carried
out in equations of motions. Due to the constraint, the original model
parameters are converted into $\varphi$-dependent classical effective
parameters. In particular, the effective potential has the form
$U_{eff}=\frac{\lambda}{4\xi^2}M_P^4 F(\varphi)
\tanh^4(\frac{\sqrt{\xi}\varphi}{M_P})$, where $F(\varphi)$ is a smooth
function. The constant $\xi$ of non-minimal coupling to scalar curvature can be
chosen as small as desired. If $\xi =1/6$, then to ensure agreement with CMB
observational data, the Higgs field selfcoupling parameter $\lambda$ in the
original action must be of the order of $\sim 10^{-11}$. During cosmological
evolution after the end of inflation, the decrease of $\varphi$ leads to a
change in the sign of the effective Higgs mass term. This effect provides an
answer to the mystery of the Higgs potential structure and leads to SSB. As
$\varphi$ approaches VEV, the scalar function $\zeta(\varphi)$ changes in such
a way that the classical effective selfcoupling parameter
$\lambda_{eff}(\zeta(\varphi))$ increases by 10 orders of magnitude compared to
$\lambda$, which is necessary for the implementation of the GWS theory.
Applying the model to the very beginning of the classical evolution of the
Universe shows that under certain initial conditions, cosmological dynamics can
begin with a phantom regime preceding inflation.However, if evolution begins
with normal dynamics, then it proceeds only as inflation, and the problem of
initial conditions for the onset of inflation does not arise.",http://arxiv.org/abs/2501.15597v2
Quantum oscillations of holes in GaN,2025-01-27T17:05:52Z,"Chuan F. C. Chang, Joseph E. Dill, Zexuan Zhang, Jie-Cheng Chen, Naomi Pieczulewski, Samuel J. Bader, Oscar Ayala Valenzuela, Scott A. Crooker, Fedor F. Balakirev, Ross D. McDonald, Jimy Encomendero, David A. Muller, Feliciano Giustino, Debdeep Jena, Huili Grace Xing","GaN has emerged to be a major semiconductor akin to silicon due to its
revolutionary impacts in solid state lighting, critically enabled by p-type
doping, and high-performance radio-frequency and power electronics. Suffering
from inefficient hole doping and low hole mobility, quantum oscillations in
p-type GaN have not been observed, hindering fundamental studies of valence
bands and hole transport in GaN. Here, we present the first observation of
quantum oscillations of holes in GaN. Shubnikov-de Haas (SdH) oscillations in
hole resistivity are observed in a quantum-confined two-dimensional hole gas at
a GaN/AlN interface, where polarization-induced doping overcomes thermal
freeze-out, and a sharp and clean interface boosts the hole mobility enough to
unmask the quantum oscillations. These holes degenerately occupy the light and
heavy hole bands of GaN and have record-high mobilities of ~1900 cm2/Vs and
~400 cm2/Vs at 3K, respectively. We use magnetic fields up to 72 T to resolve
SdH oscillations of holes from both valence bands to extract their respective
sheet densities, quantum scattering times, and the effective masses of light
holes (0.5-0.7 m0) and heavy holes (1.9 m0). SdH oscillations of heavy and
light holes in GaN constitute a direct metrology of valence bands and open new
venues for quantum engineering in this technologically important semiconductor.
Like strained silicon transistors, strain-engineering of the valence bands of
GaN is predicted to dramatically improve hole mobilities by reducing the hole
effective mass, a proposal that can now be explored experimentally,
particularly in a fully fabricated transistor, using quantum oscillations.
Furthermore, the findings of this work suggest a blueprint to create 2D hole
gases and observe quantum oscillations of holes in related wide bandgap
semiconductors such as SiC and ZnO in which such techniques are not yet
possible.",http://arxiv.org/abs/2501.16213v1
"The foot, the fan, and the cuprate phase diagram: Fermi-volume-changing
  quantum phase transitions",2025-01-27T19:00:00Z,Subir Sachdev,"A Fermi liquid with a 'large' Fermi surface (FL) can have a quantum phase
transition to a spin density wave state (SDW) with reconstructed 'small' Fermi
pockets. Both FL and SDW phases obey the Luttinger constraints on the volume
enclosed by the Fermi surfaces. Critical spin fluctuations lead to spin-singlet
$d$-wave pairing, as observed in the cuprates. Studies of the influence of
spatial disorder on the FL-SDW quantum phase transition predict an extended
quantum-critical Griffiths-type phase at low temperatures on the large Fermi
surface side. These computations agree with the 'foot' of strange metal
transport, and recent low temperature neutron scattering observations on
La$_{2-x}$Sr$_x$CuO$_4$.
  However, this theory cannot explain the higher temperature pseudogap and the
'fan' of strange metal behavior of the hole-doped cuprates. Here we need to
consider underlying Fermi-volume-changing quantum phase transitions without
symmetry breaking. Then the small Fermi surface phase does not obey the
Luttinger constraint, and the pseudogap metal is described by thermal
fluctuations above a 'fractionalized Fermi liquid' (FL*) or a 'holon metal',
with the descriptions related by a duality on a background spin liquid. The
quantum critical fan is described using a field theory for an underlying FL-FL*
quantum phase transition in the presence of spatial disorder. This field theory
can be mapped to a form which can be analyzed using the methods of the
Sachdev-Ye-Kitaev model. Such an analysis successfully models
linear-in-temperature resistivity, optical conductivity and thermopower
observations in the quantum critical fan.
  The confinement crossover connecting these lower and higher temperature
descriptions is also discussed.",http://arxiv.org/abs/2501.16417v4
An Adaptive Proton FLASH Therapy Using Modularized Pin Ridge Filter,2025-02-03T03:02:52Z,"Ahmal Jawad Zafar, Xiaofeng Yang, Zachary Diamond, Tian Sibo, David Yu, Pretesh R. Patel, Jun Zhou","In this paper, we proposed a method to optimize adaptive proton FLASH therapy
(ADP FLASH) using modularized pin ridge filters (pRFs) by recycling module pins
from the initial plan while reducing pRF adjustments in adaptive FLASH
planning. Initially, single energy (250 MeV) FLASH pRF plans were created using
pencil beam directions (PBDs) from initial IMPT plans on the planning CT (pCT).
PBDs are classified as new/changed ($\Delta$E > > 5 MeV) or unchanged by
comparing spot maps for targets between pCT and re-CT. We used an iterative
least square regression model to identify recyclable PBDs with minimal relative
changes to spot MU weighting. Two PBDs with the least square error were
retrieved per iteration and added to the background plan, and the remaining
PBDs were reoptimized for the adaptive plan in subsequent iterations. The
method was validated on three liver SBRT cases (50 Gy in 5 fractions) by
comparing various dosimetric parameters across initial pRF plans on pCT, reCT
and the ADP FLASH pRF plans on reCT. V100 for initial pRF plans on pCT, reCT,
and ADP FLASH pRF plans for the three cases were as follows: (93.7%, 89.2%,
91.4%), (93.5%, 60.2%, 91.7%), (97.3%, 69.9%, 98.8%). We observe a decline in
plan quality when applying the initial pRF to the reCT, whereas the ADP FLASH
pRF approach restores quality comparable to the initial pRF on the pCT. FLASH
effect of the initial pRF and ADP pRF plans were evaluated with a dose and dose
rate threshold of 1Gy and 40Gy/s, respectively, using the FLASH effectiveness
model. The proposed method recycled 91.2%, 71%, and 64.7% of PBDs from initial
pRF plans for the three cases while maintaining all clinical goals and
preserving FLASH effects across all cases.",http://arxiv.org/abs/2502.01011v1
"Multi-Object Active Search and Tracking by Multiple Agents in Untrusted,
  Dynamically Changing Environments",2025-02-03T04:23:07Z,"Mingi Jeong, Cristian Molinaro, Tonmoay Deb, Youzhi Zhang, Andrea Pugliese, Eugene Santos Jr., VS Subrahmanian, Alberto Quattrini Li","This paper addresses the problem of both actively searching and tracking
multiple unknown dynamic objects in a known environment with multiple
cooperative autonomous agents with partial observability. The tracking of a
target ends when the uncertainty is below a threshold. Current methods
typically assume homogeneous agents without access to external information and
utilize short-horizon target predictive models. Such assumptions limit
real-world applications. We propose a fully integrated pipeline where the main
contributions are: (1) a time-varying weighted belief representation capable of
handling knowledge that changes over time, which includes external reports of
varying levels of trustworthiness in addition to the agents; (2) the
integration of a Long Short Term Memory-based trajectory prediction within the
optimization framework for long-horizon decision-making, which reasons in
time-configuration space, thus increasing responsiveness; and (3) a
comprehensive system that accounts for multiple agents and enables
information-driven optimization. When communication is available, our strategy
consolidates exploration results collected asynchronously by agents and
external sources into a headquarters, who can allocate each agent to maximize
the overall team's utility, using all available information. We tested our
approach extensively in simulations against baselines, and in robustness and
ablation studies. In addition, we performed experiments in a 3D physics based
engine robot simulator to test the applicability in the real world, as well as
with real-world trajectories obtained from an oceanography computational fluid
dynamics simulator. Results show the effectiveness of our method, which
achieves mission completion times 1.3 to 3.2 times faster in finding all
targets, even under the most challenging scenarios where the number of targets
is 5 times greater than that of the agents.",http://arxiv.org/abs/2502.01041v1
The TechDebt Game -- Enabling Discussions about Technical Debt,2025-02-04T09:48:02Z,"Marion Wiese, Angelina Heinrichs, Nino Rusieshvili, Rodrigo Rebouças de Almeida, Klara Borowa","Context. Technical Debt (TD), defined as software constructs that are
beneficial in the short term but may hinder future change, is a frequently used
term in software development practice. Nevertheless, practitioners do not
always fully understand its definition and, in particular, conceptual model.
Previous research highlights that communication about TD is challenging,
especially with non-technical stakeholders. Discussions on this topic often
cause conflicts due to misunderstandings related to other stakeholders'
perspectives. Goal. We designed a board game to emulate TD concepts to make
them tangible to all stakeholders, including non-technical ones. The game aims
to encourage discussions about TD in an emulated and safe environment, thereby
avoiding real-life conflicts. Method. To evaluate the game's effectiveness, we
surveyed 46 practitioners from diverse domains, positions, and experience
levels who played the game in 13 sessions following extensive testing during
its development. In addition to the players' general feedback, we examined
situations where players recognized new insights about TD or connected game
scenarios to real-life experiences. Results. Overall, the feedback on the game
and its enjoyment factor were highly positive. While developers and software
architects often connected game situations to their real-world experiences,
non-technical stakeholders, such as scrum masters, product owners, and less
experienced developers, encountered multiple new insights on TD. Numerous
players have shifted their attitudes toward TD and have outlined a plan to
modify their behavior regarding TD management. Conclusions. Although the game
may not lead to long-term behavior change among stakeholders, participants'
feedback provides evidence that it might serve as a valuable starting point for
team discussions on technical debt management.",http://arxiv.org/abs/2502.02174v1
"A New Spectral Library for Modeling the Surfaces of Hot, Rocky
  Exoplanets",2025-02-06T19:00:00Z,"Kimberly Paragas, Heather A. Knutson, Renyu Hu, Bethany L. Ehlmann, Giulia Alemanno, Jörn Helbert, Alessandro Maturilli, Michael Zhang, Aishwarya Iyer, George Rossman","JWST's MIRI LRS provides the first opportunity to spectroscopically
characterize the surface compositions of close-in terrestrial exoplanets.
Models for the bare-rock spectra of these planets often utilize a spectral
library from R. Hu et al., which is based on room temperature reflectance
measurements of materials that represent archetypes of rocky planet surfaces.
Here we present an expanded library that includes hemispherical reflectance
measurements for a greater variety of compositions, varying textures (solid
slab, coarsely crushed, and fine powder), as well as high temperature (500-800
K) emissivity measurements for select samples. We incorporate this new library
into version 6.3 of the retrieval package PLATON and use it to show that
surfaces with similar compositions can have widely varying albedos and surface
temperatures. We additionally demonstrate that changing the texture of a
material can significantly alter its albedo, making albedo a poor proxy for
surface composition. We identify key spectral features -- the 5.6 \textmu{m}
olivine feature, the transparency feature, the Si-O stretching feature, and the
Christiansen feature -- that indicate silicate abundance and surface texture.
We quantify the number of JWST observations needed to detect these features in
the spectrum of the most favorable super-Earth target, LHS 3844 b, and revisit
the interpretation of its Spitzer photometry. Lastly, we show that
temperature-dependent changes in spectral features are likely undetectable at
the precision of current exoplanet observations. Our results illustrate the
importance of spectroscopically-resolved thermal emission measurements, as
distinct from surface albedo constraints, for characterizing the surface
compositions of hot, rocky exoplanets.",http://arxiv.org/abs/2502.04433v1
"The establishment of static digital humans and the integration with
  spinal models",2025-02-11T08:21:37Z,"Fujiao Ju, Yuxuan Wang, Shuo Wang, Chengyin Wang, Yinbo Chen, Jianfeng Li, Mingjie Dong, Bin Fang, Qianyu Zhuang","Adolescent idiopathic scoliosis (AIS), a prevalent spinal deformity,
significantly affects individuals' health and quality of life. Conventional
imaging techniques, such as X - rays, computed tomography (CT), and magnetic
resonance imaging (MRI), offer static views of the spine. However, they are
restricted in capturing the dynamic changes of the spine and its interactions
with overall body motion. Therefore, developing new techniques to address these
limitations has become extremely important. Dynamic digital human modeling
represents a major breakthrough in digital medicine. It enables a three -
dimensional (3D) view of the spine as it changes during daily activities,
assisting clinicians in detecting deformities that might be missed in static
imaging. Although dynamic modeling holds great potential, constructing an
accurate static digital human model is a crucial initial step for high -
precision simulations. In this study, our focus is on constructing an accurate
static digital human model integrating the spine, which is vital for subsequent
dynamic digital human research on AIS. First, we generate human point - cloud
data by combining the 3D Gaussian method with the Skinned Multi - Person Linear
(SMPL) model from the patient's multi - view images. Then, we fit a standard
skeletal model to the generated human model. Next, we align the real spine
model reconstructed from CT images with the standard skeletal model. We
validated the resulting personalized spine model using X - ray data from six
AIS patients, with Cobb angles (used to measure the severity of scoliosis) as
evaluation metrics. The results indicate that the model's error was within 1
degree of the actual measurements. This study presents an important method for
constructing digital humans.",http://arxiv.org/abs/2502.07844v1
Viscoplasticity can stabilise liquid collar motion on vertical cylinders,2025-02-12T10:47:10Z,"James D. Shemilt, Alice B. Thompson, Alex Horsley, Carl A. Whitfield, Oliver E. Jensen","Liquid films coating vertical cylinders can form annular liquid collars which
translate downwards under gravity. We investigate the dynamics of a thin
viscoplastic liquid film coating the interior or exterior of a vertical
cylindrical tube, quantifying how the yield stress modifies both the
Rayleigh-Plateau instability leading to collar formation and the translation of
collars down the tube. We use thin-film theory to derive an evolution equation
for the layer thickness, which we solve numerically to determine the nonlinear
dynamics of an initially flat layer. A flat layer is unstable to small
disturbances in the free-surface height when gravity is sufficiently strong to
make the fluid yield. We use matched asymptotics to derive a model describing
the quasi-steady translation of a slender liquid collar when the Bond number is
small. The structure of the asymptotic solution for a viscoplastic collar
shares some features with the Newtonian version, but there are several novel
asymptotic regions that emerge at the two ends of the collar. The global force
balance, which determines the collar's speed, is modified by a leading-order
contribution from viscous drag in the collar when the liquid is viscoplastic.
We use the asymptotic model to describe slow changes in collar volume when the
film thicknesses ahead of, and behind, the collar are unequal. When the film
thickness ahead of the collar is less than a critical value that we determine,
viscoplastic collars adjust their volume and reach a steadily-translating
state. This contrasts with the Newtonian problem, where the only state in which
steady translation occurs is unstable to small changes in the film thickness.",http://arxiv.org/abs/2502.08291v2
"Robot Pouring: Identifying Causes of Spillage and Selecting Alternative
  Action Parameters Using Probabilistic Actual Causation",2025-02-13T15:16:52Z,"Jaime Maldonado, Jonas Krumme, Christoph Zetzsche, Vanessa Didelez, Kerstin Schill","In everyday life, we perform tasks (e.g., cooking or cleaning) that involve a
large variety of objects and goals. When confronted with an unexpected or
unwanted outcome, we take corrective actions and try again until achieving the
desired result. The reasoning performed to identify a cause of the observed
outcome and to select an appropriate corrective action is a crucial aspect of
human reasoning for successful task execution. Central to this reasoning is the
assumption that a factor is responsible for producing the observed outcome. In
this paper, we investigate the use of probabilistic actual causation to
determine whether a factor is the cause of an observed undesired outcome.
Furthermore, we show how the actual causation probabilities can be used to find
alternative actions to change the outcome. We apply the probabilistic actual
causation analysis to a robot pouring task. When spillage occurs, the analysis
indicates whether a task parameter is the cause and how it should be changed to
avoid spillage. The analysis requires a causal graph of the task and the
corresponding conditional probability distributions. To fulfill these
requirements, we perform a complete causal modeling procedure (i.e., task
analysis, definition of variables, determination of the causal graph structure,
and estimation of conditional probability distributions) using data from a
realistic simulation of the robot pouring task, covering a large combinatorial
space of task parameters. Based on the results, we discuss the implications of
the variables' representation and how the alternative actions suggested by the
actual causation analysis would compare to the alternative solutions proposed
by a human observer. The practical use of the analysis of probabilistic actual
causation to select alternative action parameters is demonstrated.",http://arxiv.org/abs/2502.09395v1
"Artificial Intelligence to Assess Dental Findings from Panoramic
  Radiographs -- A Multinational Study",2025-02-14T16:34:21Z,"Yin-Chih Chelsea Wang, Tsao-Lun Chen, Shankeeth Vinayahalingam, Tai-Hsien Wu, Chu Wei Chang, Hsuan Hao Chang, Hung-Jen Wei, Mu-Hsiung Chen, Ching-Chang Ko, David Anssari Moin, Bram van Ginneken, Tong Xi, Hsiao-Cheng Tsai, Min-Huey Chen, Tzu-Ming Harry Hsu, Hye Chou","Dental panoramic radiographs (DPRs) are widely used in clinical practice for
comprehensive oral assessment but present challenges due to overlapping
structures and time constraints in interpretation.
  This study aimed to establish a solid baseline for the AI-automated
assessment of findings in DPRs by developing, evaluating an AI system, and
comparing its performance with that of human readers across multinational data
sets.
  We analyzed 6,669 DPRs from three data sets (the Netherlands, Brazil, and
Taiwan), focusing on 8 types of dental findings. The AI system combined object
detection and semantic segmentation techniques for per-tooth finding
identification. Performance metrics included sensitivity, specificity, and area
under the receiver operating characteristic curve (AUC-ROC). AI
generalizability was tested across data sets, and performance was compared with
human dental practitioners.
  The AI system demonstrated comparable or superior performance to human
readers, particularly +67.9% (95% CI: 54.0%-81.9%; p < .001) sensitivity for
identifying periapical radiolucencies and +4.7% (95% CI: 1.4%-8.0%; p = .008)
sensitivity for identifying missing teeth. The AI achieved a macro-averaged
AUC-ROC of 96.2% (95% CI: 94.6%-97.8%) across 8 findings. AI agreements with
the reference were comparable to inter-human agreements in 7 of 8 findings
except for caries (p = .024). The AI system demonstrated robust generalization
across diverse imaging and demographic settings and processed images 79 times
faster (95% CI: 75-82) than human readers.
  The AI system effectively assessed findings in DPRs, achieving performance on
par with or better than human experts while significantly reducing
interpretation time. These results highlight the potential for integrating AI
into clinical workflows to improve diagnostic efficiency and accuracy, and
patient management.",http://arxiv.org/abs/2502.10277v1
Independence Tests for Language Models,2025-02-17T20:01:08Z,"Sally Zhu, Ahmed Ahmed, Rohith Kuditipudi, Percy Liang","We consider the following problem: given the weights of two models, can we
test whether they were trained independently -- i.e., from independent random
initializations? We consider two settings: constrained and unconstrained. In
the constrained setting, we make assumptions about model architecture and
training and propose a family of statistical tests that yield exact p-values
with respect to the null hypothesis that the models are trained from
independent random initializations. These p-values are valid regardless of the
composition of either model's training data; we compute them by simulating
exchangeable copies of each model under our assumptions and comparing various
similarity measures of weights and activations between the original two models
versus these copies. We report the p-values from these tests on pairs of 21
open-weight models (210 total pairs) and correctly identify all pairs of
non-independent models. Our tests remain effective even if one model was
fine-tuned for many tokens. In the unconstrained setting, where we make no
assumptions about training procedures, can change model architecture, and allow
for adversarial evasion attacks, the previous tests no longer work. Instead, we
propose a new test which matches hidden activations between two models, and
which is robust to adversarial transformations and to changes in model
architecture. The test can also do localized testing: identifying specific
non-independent components of models. Though we no longer obtain exact p-values
from this, empirically we find it behaves as one and reliably identifies
non-independent models. Notably, we can use the test to identify specific parts
of one model that are derived from another (e.g., how Llama 3.1-8B was pruned
to initialize Llama 3.2-3B, or shared layers between Mistral-7B and
StripedHyena-7B), and it is even robust to retraining individual layers of
either model from scratch.",http://arxiv.org/abs/2502.12292v1
"The Preference for Evolving Dark Energy from Cosmological Distance
  Measurements and Possible Signatures in the Growth Rate of Perturbations",2025-02-18T09:18:00Z,"Ryan E. Keeley, Kevork N. Abazajian, Manoj Kaplinghat, Arman Shafieloo","In this study, we use a flexible parametrization of the equation of state of
dark energy to explore its possible evolution with datasets from the Dark
Energy Spectroscopic Instrument (DESI), Planck cosmic microwave background, and
either the 5-year Dark Energy Survey (DES) or the Pantheon+ (PP) supernova (SN)
compilation. This parametrization, called transitional dark energy, allows for
rapid changes in the equation of state but also changes like that in the
Chevallier-Polarski-Linder parametrization. We find a 3.8{\sigma} preference
for evolving dark energy over {\Lambda}CDM with the DES dataset and a weaker
2.4{\sigma} preference when using the PP dataset. This corroborates the finding
of the DESI Collaboration, who found that their baryon acoustic oscillation
data preferred evolving dark energy when fit with the CPL parametrization of
the equation of state. Our analysis reveals no significant outliers in the DESI
data around the TDE best-fit, while the data is asymmetrically distributed
around the {\Lambda}CDM best-fit model such that the measured distances are on
average smaller. The DESI and SN data both prefer an expansion history that
implies a higher dark energy density around z=0.5 than in the
Planck-{\Lambda}CDM model, with the inferred equation of state being greater
than -1 around z=0 and close to or below -1 at z>0.5. We show that when the
expansion rate is greater than that in the Planck-{\Lambda}CDM model (around
z=0.5), the growth rate calculated assuming General Relativity is suppressed
relative to the Planck-{\Lambda}CDM model, and it rebounds as the expansion
rate differences between the models become smaller closer to the present time.
The resulting flattening of the $f\sigma_8(z)$ curve compared to the
{\Lambda}CDM model could be an independent signature of the temporal evolution
of dark energy.",http://arxiv.org/abs/2502.12667v1
"Variable Read Disturbance: An Experimental Analysis of Temporal
  Variation in DRAM Read Disturbance",2025-02-18T17:22:42Z,"Ataberk Olgun, F. Nisa Bostanci, Ismail Emir Yuksel, Oguzhan Canpolat, Haocong Luo, Geraldo F. Oliveira, A. Giray Yaglikci, Minesh Patel, Onur Mutlu","Modern DRAM chips are subject to read disturbance errors. State-of-the-art
read disturbance mitigations rely on accurate and exhaustive characterization
of the read disturbance threshold (RDT) (e.g., the number of aggressor row
activations needed to induce the first RowHammer or RowPress bitflip) of every
DRAM row (of which there are millions or billions in a modern system) to
prevent read disturbance bitflips securely and with low overhead. We
experimentally demonstrate for the first time that the RDT of a DRAM row
significantly and unpredictably changes over time. We call this new phenomenon
variable read disturbance (VRD). Our experiments using 160 DDR4 chips and 4
HBM2 chips from three major manufacturers yield two key observations. First, it
is very unlikely that relatively few RDT measurements can accurately identify
the RDT of a DRAM row. The minimum RDT of a DRAM row appears after tens of
thousands of measurements (e.g., up to 94,467), and the minimum RDT of a DRAM
row is 3.5X smaller than the maximum RDT observed for that row. Second, the
probability of accurately identifying a row's RDT with a relatively small
number of measurements reduces with increasing chip density or smaller
technology node size. Our empirical results have implications for the security
guarantees of read disturbance mitigation techniques: if the RDT of a DRAM row
is not identified accurately, these techniques can easily become insecure. We
discuss and evaluate using a guardband for RDT and error-correcting codes for
mitigating read disturbance bitflips in the presence of RDTs that change
unpredictably over time. We conclude that a >10% guardband for the minimum
observed RDT combined with SECDED or Chipkill-like SSC error-correcting codes
could prevent read disturbance bitflips at the cost of large read disturbance
mitigation performance overheads (e.g., 45% performance loss for an RDT
guardband of 50%).",http://arxiv.org/abs/2502.13075v1
"A Framework for Semantics-based Situational Awareness during Mobile
  Robot Deployments",2025-02-19T12:37:23Z,"Tianshu Ruan, Aniketh Ramesh, Hao Wang, Alix Johnstone-Morfoisse, Gokcenur Altindal, Paul Norman, Grigoris Nikolaou, Rustam Stolkin, Manolis Chiou","Deployment of robots into hazardous environments typically involves a
``Human-Robot Teaming'' (HRT) paradigm, in which a human supervisor interacts
with a remotely operating robot inside the hazardous zone. Situational
Awareness (SA) is vital for enabling HRT, to support navigation, planning, and
decision-making. This paper explores issues of higher-level ``semantic''
information and understanding in SA. In semi-autonomous, or variable-autonomy
paradigms, different types of semantic information may be important, in
different ways, for both the human operator and an autonomous agent controlling
the robot. We propose a generalizable framework for acquiring and combining
multiple modalities of semantic-level SA during remote deployments of mobile
robots. We demonstrate the framework with an example application of search and
rescue (SAR) in disaster response robotics. We propose a set of ``environment
semantic indicators"" that can reflect a variety of different types of semantic
information, e.g. indicators of risk, or signs of human activity, as the robot
encounters different scenes. Based on these indicators, we propose a metric to
describe the overall situation of the environment called ``Situational Semantic
Richness (SSR)"". This metric combines multiple semantic indicators to summarise
the overall situation. The SSR indicates if an information-rich and complex
situation has been encountered, which may require advanced reasoning for robots
and humans and hence the attention of the expert human operator. The framework
is tested on a Jackal robot in a mock-up disaster response environment.
Experimental results demonstrate that the proposed semantic indicators are
sensitive to changes in different modalities of semantic information in
different scenes, and the SSR metric reflects overall semantic changes in the
situations encountered.",http://arxiv.org/abs/2502.13677v1
"Restriction of macroscopic structural superlubricity due to structure
  relaxation by the example of twisted graphene bilayer",2025-02-19T14:20:42Z,"Alexander S. Minkin, Irina V. Lebedeva, Andrey M. Popov, Sergey A. Vyrko, Nikolai A. Poklonski, Yurii E. Lozovik","The effect of structure relaxation on the potential energy surface (PES) of
interlayer interaction of twisted graphene bilayer is studied for a set of
commensurate moir\'e systems using the registry-dependent empirical potential
of Kolmogorov and Crespi. It is found that the influence of structure
relaxation on the amplitude of PES corrugations (determining static friction)
depends on the unit cell size (or related twist angle) of the moir\'e system.
For moir\'e systems with the smallest unit cells, the amplitudes of PES
corrugations calculated with and without account of structure relaxation are
approximately the same. However, for large unit cell sizes, the structure
relaxation can lead to an increase of PES corrugations by orders of magnitude.
This means that structure relaxation can provide the main contribution into the
static friction of a superlubric system under certain conditions (such as the
contact size and twist angle). Moreover, the change of the PES type because of
structure relaxation from a trigonal lattice of maxima to a trigonal lattice of
minima is observed for the systems with the moir\'e patterns (5,1) and (5,3).
Based on the results obtained, possible crossovers between static friction
modes taking place upon changing the twist angle in a macroscopic superlubric
system consisting of identical layers are discussed. Additionally it is shown
that the PES for relaxed structures can still be approximated by the first
Fourier harmonics compatible with symmetries of twisted layers analogously to
the PES for rigid layers.",http://arxiv.org/abs/2502.13758v1
"Imaging the Photochemistry of Cyclobutanone using Ultrafast Electron
  Diffraction: Experimental Results",2025-02-19T18:55:21Z,"A. E. Green, Y. Liu, F. Allum, M. Graßl, P. Lenzen, M. N. R. Ashfold, S. Bhattacharyya, X. Cheng, M. Centurion, S. W. Crane, R. G. Forbes, N. A. Goff, L. Huang, B. Kaufman, M. F. Kling, P. L. Kramer, H. V. S. Lam, K. A. Larsen, R. Lemons, M. -F. Lin, A. J. Orr-Ewing, D. Rolles, A. Rudenko, S. K. Saha, J. Searles, X. Shen, S. Weathersby, P. M. Weber, H. Zhao, T. J. A. Wolf","We investigated the ultrafast structural dynamics of cyclobutanone following
photoexcitation at $\lambda=200$ nm using gas-phase megaelectronvolt ultrafast
electron diffraction. Our investigation complements the simulation studies of
the same process within this special issue. It provides information about both
electronic state population and structural dynamics through well-separable
inelastic and elastic electron scattering signatures. We observe the
depopulation of the photoexcited S$_2$ state of cyclobutanone with n3s Rydberg
character through its inelastic electron scattering signature with a time
constant of $(0.29 \pm 0.2)$ ps towards the S$_1$ state. The S$_1$ state
population undergoes ring-opening via a Norrish Type-I reaction, likely while
passing through a conical intersection with S$_0$. The corresponding structural
changes can be tracked by elastic electron scattering signatures. These changes
appear with a delay of $(0.14 \pm 0.05)$ ps with respect the initial
photoexcitation, which is less than the S$_2$ depopulation time constant. This
behavior provides evidence for the ballistic nature of the ring-opening once
the S$_1$ state is reached. The resulting biradical species react further
within $(1.2 \pm 0.2)$ ps via two rival fragmentation channels yielding ketene
and ethylene, or propene and carbon monoxide. Our study showcases both the
value of gas-phase ultrafast diffraction studies as an experimental benchmark
for nonadiabatic dynamics simulation methods and the limits in the
interpretation of such experimental data without comparison to such
simulations.",http://arxiv.org/abs/2502.13956v1
"H$α$ Variability of AB Aur b with the Hubble Space Telescope:
  Probing the Nature of a Protoplanet Candidate with Accretion Light Echoes",2025-02-20T17:02:42Z,"Brendan P. Bowler, Yifan Zhou, Lauren I. Biddle, Lillian Yushu Jiang, Jaehan Bae, Laird M. Close, Katherine B. Follette, Kyle Franson, Adam L. Kraus, Aniket Sanghi, Quang Tran, Kimberly Ward-Duong, Ya-Lin Wu, Zhaohuan Zhu","Giant planets generate accretion luminosity as they form. Much of this energy
is radiated in strong H$\alpha$ line emission, which has motivated direct
imaging surveys at optical wavelengths to search for accreting protoplanets.
However, compact disk structures can mimic accreting planets by scattering
emission from the host star. This can complicate the interpretation of
H$\alpha$ point sources, especially if the host star itself is accreting. We
describe an approach to distinguish accreting protoplanets from scattered-light
disk features using ""accretion light echoes."" This method relies on variable
H$\alpha$ emission from a stochastically accreting host star to search for a
delayed brightness correlation with a candidate protoplanet. We apply this
method to the candidate protoplanet AB Aur b with a dedicated Hubble Space
Telescope Wide Field Camera 3 program designed to sequentially sample the host
star and the candidate planet in H$\alpha$ while accounting for the light
travel time delay and orbital geometry of the source within the protoplanetary
disk. Across five epochs spanning 14 months, AB Aur b is over 20 times more
variable than its host star; AB Aur's H$\alpha$ emission changes by 15% while
AB Aur b varies by 330%. These brightness changes are not correlated, which
rules out unobstructed scattered starlight from the host star as the only
source of AB Aur b's H$\alpha$ emission and is consistent with tracing emission
from an independently accreting protoplanet, inner disk shadowing effects, or a
physically evolving compact disk structure. More broadly, accretion light
echoes offer a novel tool to explore the nature of protoplanet candidates with
well-timed observations of the host star prior to deep imaging in H$\alpha$.",http://arxiv.org/abs/2502.14736v1
"A Ritz variational principle for local collisionless gyrokinetic
  instabilities",2025-01-01T02:15:18Z,"C. D. Stephens, P. -Y. Li","Turbulence driven by gyrokinetic instabilities is largely responsible for
transport in magnetic fusion devices. To estimate this turbulent transport,
integrated modeling codes often use mixing length estimates in conjunction with
reduced models of the linearized gyrokinetic equation. One common method of
formulating and solving the linearized gyrokinetic eigenvalue problem equation
uses a Ritz variational principle, particularly in the local collisionless
limit. However, the variational principle as typically stated in the literature
is mathematically incorrect. In this work, we derive a mathematically correct
form of the variational principle that applies to local linear collisionless
gyrokinetics in general geometry with electromagnetic effects. We also
explicitly derive a weak form of the gyrokinetic field equations suitable for
numerical applications.",http://arxiv.org/abs/2501.00698v3
"eRevise+RF: A Writing Evaluation System for Assessing Student Essay
  Revisions and Providing Formative Feedback",2025-01-01T03:49:48Z,"Zhexiong Liu, Diane Litman, Elaine Wang, Tianwen Li, Mason Gobat, Lindsay Clare Matsumura, Richard Correnti","The ability to revise essays in response to feedback is important for
students' writing success. An automated writing evaluation (AWE) system that
supports students in revising their essays is thus essential. We present
eRevise+RF, an enhanced AWE system for assessing student essay revisions (e.g.,
changes made to an essay to improve its quality in response to essay feedback)
and providing revision feedback. We deployed the system with 6 teachers and 406
students across 3 schools in Pennsylvania and Louisiana. The results confirmed
its effectiveness in (1) assessing student essays in terms of evidence usage,
(2) extracting evidence and reasoning revisions across essays, and (3)
determining revision success in responding to feedback. The evaluation also
suggested eRevise+RF is a helpful system for young students to improve their
argumentative writing skills through revision and formative feedback.",http://arxiv.org/abs/2501.00715v1
"Towards End-to-End Neuromorphic Voxel-based 3D Object Reconstruction
  Without Physical Priors",2025-01-01T06:07:03Z,"Chuanzhi Xu, Langyi Chen, Vincent Qu, Haodong Chen, Vera Chung","Neuromorphic cameras, also known as event cameras, are asynchronous
brightness-change sensors that can capture extremely fast motion without
suffering from motion blur, making them particularly promising for 3D
reconstruction in extreme environments. However, existing research on 3D
reconstruction using monocular neuromorphic cameras is limited, and most of the
methods rely on estimating physical priors and employ complex multi-step
pipelines. In this work, we propose an end-to-end method for dense voxel 3D
reconstruction using neuromorphic cameras that eliminates the need to estimate
physical priors. Our method incorporates a novel event representation to
enhance edge features, enabling the proposed feature-enhancement model to learn
more effectively. Additionally, we introduced Optimal Binarization Threshold
Selection Principle as a guideline for future related work, using the optimal
reconstruction results achieved with threshold optimization as the benchmark.
Our method achieves a 54.6% improvement in reconstruction accuracy compared to
the baseline method.",http://arxiv.org/abs/2501.00741v1
"Swimming mode determines how well mesoscale swimmers shield their odor
  in turbulence",2025-01-01T09:59:47Z,"Martin James, Francesco Viola, Agnese Seminara","Marine organisms manipulate their surrounding flow through their swimming
dynamics, which affects the transport of their own odor cues. We demonstrate by
direct numerical simulations how a group of mesoscale swimmers immersed in a
turbulent flow alters the shape of the odor plume they release in the water.
Odor mixing is enhanced by increased velocity fluctuations and a
swimmer-induced flow circulation which widen the odor plume at close range
while speeding up dilution of the chemical trace. Beyond a short-range increase
in the likelihood of being detected, swimming considerably reduces detections
with effects that can persist at distances of the order of ten times the size
of the group or more. We find that puller-like swimmers are more effective at
olfactory shielding than pusher-like swimmers. We trace this difference back to
the dynamics at the swimmer location, which tends to trap odor at the source
for pushers and to dilute it for pullers. Olfactory shielding is robust to
changes in the conditions, and is more pronounced for weak turbulent Reynolds
numbers and large swimmer Reynolds numbers. Our results suggest that olfactory
shielding may play a role in the emergence of different swimming modalities by
marine organisms.",http://arxiv.org/abs/2501.00789v1
"Unfolding the Headline: Iterative Self-Questioning for News Retrieval
  and Timeline Summarization",2025-01-01T16:28:21Z,"Weiqi Wu, Shen Huang, Yong Jiang, Pengjun Xie, Fei Huang, Hai Zhao","In the fast-changing realm of information, the capacity to construct coherent
timelines from extensive event-related content has become increasingly
significant and challenging. The complexity arises in aggregating related
documents to build a meaningful event graph around a central topic. This paper
proposes CHRONOS - Causal Headline Retrieval for Open-domain News Timeline
SummarizatiOn via Iterative Self-Questioning, which offers a fresh perspective
on the integration of Large Language Models (LLMs) to tackle the task of
Timeline Summarization (TLS). By iteratively reflecting on how events are
linked and posing new questions regarding a specific news topic to gather
information online or from an offline knowledge base, LLMs produce and refresh
chronological summaries based on documents retrieved in each round.
Furthermore, we curate Open-TLS, a novel dataset of timelines on recent news
topics authored by professional journalists to evaluate open-domain TLS where
information overload makes it impossible to find comprehensive relevant
documents from the web. Our experiments indicate that CHRONOS is not only adept
at open-domain timeline summarization, but it also rivals the performance of
existing state-of-the-art systems designed for closed-domain applications,
where a related news corpus is provided for summarization.",http://arxiv.org/abs/2501.00888v1
"Exceptional point in a trimer chain of oscillators with a quadratic
  driving",2025-01-02T03:28:08Z,"M Shoufie Ukhtary, Albert Andersen, Donny Dwiputra, M. Jauhar Kholili","Exceptional points of a dissipative chain of three coupled oscillators
(trimer), which is driven by quadratic photon, are investigated. The
exceptional points emerge from the coalescence of both eigenvalues and
eigenvectors of the dynamical matrix that describes the first moments of the
trimer. At the exceptional point, we found that the optical spectrum is split
into two peaks, instead of a conventional single peak, as in the case of a
single oscillator. In particular, the positions of these peaks correspond to
the natural frequency of the trimer in a \textit{closed system}, which depends
only on the coupling strength. Furthermore, after passing the exceptional
point, the peak positions do not change, which can be used to estimate the
coupling strength between oscillators.",http://arxiv.org/abs/2501.01033v1
"The angular momentum of 1.2$M_\odot$ to 2.0$M_\odot$ main-sequence and
  turn-off stars constrain the relationship between star-forming environment
  and galactic evolution history",2025-01-02T03:30:05Z,"Yu-Fu Shen, Yan Xu, Yi-Bo Wang, Xiu-Lin Huang, Xing-Xing Hu, Qi Yuan","\textit{Kepler} and \textit{Gaia} data shows an anomaly in the angular
momentum-age relationship for 1.2-2 main-sequence stars. After considering
model-induced correlation of parameters, the moment of inertia, stellar
velocity distribution, sample selection effects, interactions between the Milky
Way and dwarf galaxies, the star-disk interaction during the early pre-main
sequence, and the angular momentum change on the main sequence, this work
suggests that the earlier the star within this mass range born, the smaller the
angular momentum at the time of born, following an exponential decay
relationship. This relationship should be attributed to the variation in
molecular cloud parameters throughout the history of the Milky Way.",http://arxiv.org/abs/2501.01035v2
"HPC Application Parameter Autotuning on Edge Devices: A Bandit Learning
  Approach",2025-01-02T04:59:32Z,"Abrar Hossain, Abdel-Hameed A. Badawy, Mohammad A. Islam, Tapasya Patki, Kishwar Ahmed","The growing necessity for enhanced processing capabilities in edge devices
with limited resources has led us to develop effective methods for improving
high-performance computing (HPC) applications. In this paper, we introduce LASP
(Lightweight Autotuning of Scientific Application Parameters), a novel strategy
designed to address the parameter search space challenge in edge devices. Our
strategy employs a multi-armed bandit (MAB) technique focused on online
exploration and exploitation. Notably, LASP takes a dynamic approach, adapting
seamlessly to changing environments. We tested LASP with four HPC applications:
Lulesh, Kripke, Clomp, and Hypre. Its lightweight nature makes it particularly
well-suited for resource-constrained edge devices. By employing the MAB
framework to efficiently navigate the search space, we achieved significant
performance improvements while adhering to the stringent computational limits
of edge devices. Our experimental results demonstrate the effectiveness of LASP
in optimizing parameter search on edge devices.",http://arxiv.org/abs/2501.01057v1
"Are Politicians Responsive to Mass Shootings? Evidence from U.S. State
  Legislatures",2025-01-02T06:00:02Z,"Haotian Chen, Jack Kappelman","The United States leads the world in the number of violent mass shootings
that occur each year, and policy making on firearms remains polarized along
party lines. Are legislators responsive to mass shootings? We estimate the
latent positions of nearly 2,000 state legislators on gun policy from their
roll-call voting records on firearm-related bills from 2011 to 2022. Employing
a staggered difference-in-differences design, we find that mass shootings
within or near a state legislator's district do not alter their voting behavior
on firearm policy, on average, for members of both parties. Our estimated
effects of mass shootings on treated legislators' support for restrictive gun
policies (on a -1 to 1 scale) range from a 4.8% reduction among California
Democrats and a 0.9% increase among California Republicans to, across six total
states, a 5% (among Democrats) and 7.1% (among Republicans) increase, with 95%
confidence intervals spanning opposite directions. We conclude that, on
average, mass shootings fail to produce changes in a legislator's support
(opposition) for restrictive (permissive) firearms bills. Our findings suggest
that even the most heinous acts of mass violence -- that are squarely in the
domain of events that state legislators might respond to -- fail to produce any
measurable effects on legislators' positions on firearm-related policy.",http://arxiv.org/abs/2501.01084v1
Probing exoplanetary magnetism via atomic alignment effect,2025-01-02T07:42:24Z,"M. Rumenskikh, A. V. Taichenachev, I. F. Shaikhislamov, V. I. Yudin","The intrinsic magnetic fields of exoplanets affect the structure of their
atmospheres and plasmaspheres and, therefore, the observational manifestations
of transit absorptions. This work proposes a new method for constraining the
presence or absence of relatively weak magnetic fields. The method is based on
the quantum effect of atomic alignment of the lower energy level resulting in
changing the absorption probabilities of individual transitions of multiplets
from the equilibrium 2J+1 value. It appears to be sensitive to fields above
~0.001 G. We applied this method to some available transit observations of
exoplanets and demonstrate that we indeed have the possibility to constrain the
intrinsic magnetic field of some exoplanets right now. However, more precise
and repetitive measurements, which might be available in near future, are
needed for definite conclusions.",http://arxiv.org/abs/2501.01122v1
"Communicating Unexpectedness for Out-of-Distribution Multi-Agent
  Reinforcement Learning",2025-01-02T08:47:12Z,"Min Whoo Lee, Kibeom Kim, Soo Wung Shin, Minsu Lee, Byoung-Tak Zhang","Applying multi-agent reinforcement learning methods to realistic settings is
challenging as it may require the agents to quickly adapt to unexpected
situations that are rarely or never encountered in training. Recent methods for
generalization to such out-of-distribution settings are limited to more
specific, restricted instances of distribution shifts. To tackle adaptation to
distribution shifts, we propose Unexpected Encoding Scheme, a novel
decentralized multi-agent reinforcement learning algorithm where agents
communicate ""unexpectedness,"" the aspects of the environment that are
surprising. In addition to a message yielded by the original reward-driven
communication, each agent predicts the next observation based on previous
experience, measures the discrepancy between the prediction and the actually
encountered observation, and encodes this discrepancy as a message. Experiments
on multi-robot warehouse environment support that our proposed method adapts
robustly to dynamically changing training environments as well as
out-of-distribution environment.",http://arxiv.org/abs/2501.01140v1
"Revisiting Impurity Induced In-gap Bound States In Unconventional
  Superconductors",2025-01-02T09:19:19Z,"Junkang Huang, Z. D. Wang, Tao Zhou","This study revisits the effects of single impurity scattering in
unconventional superconductors, with a specific emphasis on intralayer $d$-wave
pairing and interlayer $s$-wave pairing. We reveal that in the context of a
square lattice near half-filling doping, there exists an intrinsic connection
between the $d$-wave pairing symmetry and the appearance of mid-gap states.
This relationship is determined by the $C_4$ rotational symmetry of both the
$d$-wave gap amplitude and the square lattice itself. Furthermore, we identify
an intrinsic link between the in-gap states and the sign change of the order
parameter. In systems with interlayer pairing, strong resonant peaks are
observed, despite the absence of sign-reversal characteristics in the pairing
order parameter. By utilizing the $T$-matrix approach, we elucidate the
mechanisms underlying these impurity-induced states. Our theoretical framework
is pertinent to the analysis of newly discovered nickel-based high-temperature
superconductors, providing a powerful tool for distinguishing their pairing
properties. The results of this study shed light on the complex interplay
between pairing symmetries and impurity effects in unconventional
superconductors, paving the way for future investigations into the unique
properties of these emerging materials.",http://arxiv.org/abs/2501.01155v1
"Attending To Syntactic Information In Biomedical Event Extraction Via
  Graph Neural Networks",2025-01-02T09:25:24Z,"Farshad Noravesh, Reza Haffari, Ong Huey Fang, Layki Soon, Sailaja Rajalana, Arghya Pal","Many models are proposed in the literature on biomedical event
extraction(BEE). Some of them use the shortest dependency path(SDP) information
to represent the argument classification task. There is an issue with this
representation since even missing one word from the dependency parsing graph
may totally change the final prediction. To this end, the full adjacency matrix
of the dependency graph is used to embed individual tokens using a graph
convolutional network(GCN). An ablation study is also done to show the effect
of the dependency graph on the overall performance. The results show a
significant improvement when dependency graph information is used. The proposed
model slightly outperforms state-of-the-art models on BEE over different
datasets.",http://arxiv.org/abs/2501.01158v2
Asymmetric Reinforcing against Multi-modal Representation Bias,2025-01-02T13:00:06Z,"Xiyuan Gao, Bing Cao, Pengfei Zhu, Nannan Wang, Qinghua Hu","The strength of multimodal learning lies in its ability to integrate
information from various sources, providing rich and comprehensive insights.
However, in real-world scenarios, multi-modal systems often face the challenge
of dynamic modality contributions, the dominance of different modalities may
change with the environments, leading to suboptimal performance in multimodal
learning. Current methods mainly enhance weak modalities to balance multimodal
representation bias, which inevitably optimizes from a partialmodality
perspective, easily leading to performance descending for dominant modalities.
To address this problem, we propose an Asymmetric Reinforcing method against
Multimodal representation bias (ARM). Our ARM dynamically reinforces the weak
modalities while maintaining the ability to represent dominant modalities
through conditional mutual information. Moreover, we provide an in-depth
analysis that optimizing certain modalities could cause information loss and
prevent leveraging the full advantages of multimodal data. By exploring the
dominance and narrowing the contribution gaps between modalities, we have
significantly improved the performance of multimodal learning, making notable
progress in mitigating imbalanced multimodal learning.",http://arxiv.org/abs/2501.01240v1
"Transport Signatures of Inverted Andreev Bands in Topological Josephson
  Junctions",2025-01-02T15:37:00Z,"Jonathan Sturm, Raffael L. Klees, Ewelina M. Hankiewicz, Daniel Gresta","We study the thermoelectrical transport transverse to conventional and
topological Josephson junctions with a central quantum dot (QD). For that
purpose, we derive an effective resonant tunneling model where the QD is
renormalized with an induced superconducting gap. By applying Keldysh Green's
function technique, we compute the local density of states as well as the
transmission functions. In the latter case, we observe that the Andreev bound
states forming on the QD are inverted if the junction has $p$-wave symmetry,
meaning that electron and hole orbitals switch roles. We calculate the
thermoelectric transport coefficients both analytically and numerically and
show how the induced gaps and the band inversion are reflected in the
electrical and heat conductance as well as the Seebeck coefficient, the latter
experiencing a sign change in the topological case.",http://arxiv.org/abs/2501.01307v1
"SeedVR: Seeding Infinity in Diffusion Transformer Towards Generic Video
  Restoration",2025-01-02T16:19:48Z,"Jianyi Wang, Zhijie Lin, Meng Wei, Yang Zhao, Ceyuan Yang, Fei Xiao, Chen Change Loy, Lu Jiang","Video restoration poses non-trivial challenges in maintaining fidelity while
recovering temporally consistent details from unknown degradations in the wild.
Despite recent advances in diffusion-based restoration, these methods often
face limitations in generation capability and sampling efficiency. In this
work, we present SeedVR, a diffusion transformer designed to handle real-world
video restoration with arbitrary length and resolution. The core design of
SeedVR lies in the shifted window attention that facilitates effective
restoration on long video sequences. SeedVR further supports variable-sized
windows near the boundary of both spatial and temporal dimensions, overcoming
the resolution constraints of traditional window attention. Equipped with
contemporary practices, including causal video autoencoder, mixed image and
video training, and progressive training, SeedVR achieves highly-competitive
performance on both synthetic and real-world benchmarks, as well as
AI-generated videos. Extensive experiments demonstrate SeedVR's superiority
over existing methods for generic video restoration.",http://arxiv.org/abs/2501.01320v3
"Codimensional MultiMeshing: Synchronizing the Evolution of Multiple
  Embedded Geometries",2025-01-02T17:19:02Z,"Michael Tao, Jiacheng Dai, Denis Zorin, Teseo Schneider, Daniele Panozzo","Complex geometric tasks such as geometric modeling, physical simulation, and
texture parametrization often involve the embedding of many complex sub-domains
with potentially different dimensions. These tasks often require evolving the
geometry and topology of the discretizations of these sub-domains, and
guaranteeing a \emph{consistent} overall embedding for the multiplicity of
sub-domains is required to define boundary conditions. We propose a data
structure and algorithmic framework for hierarchically encoding a collection of
meshes, enabling topological and geometric changes to be automatically
propagated with coherent correspondences between them. We demonstrate the
effectiveness of our approach in surface mesh decimation while preserving UV
seams, periodic 2D/3D meshing, and extending the TetWild algorithm to ensure
topology preservation of the embedded structures.",http://arxiv.org/abs/2501.01362v1
ViGiL3D: A Linguistically Diverse Dataset for 3D Visual Grounding,2025-01-02T17:20:41Z,"Austin T. Wang, ZeMing Gong, Angel X. Chang","3D visual grounding (3DVG) involves localizing entities in a 3D scene
referred to by natural language text. Such models are useful for embodied AI
and scene retrieval applications, which involve searching for objects or
patterns using natural language descriptions. While recent works have focused
on LLM-based scaling of 3DVG datasets, these datasets do not capture the full
range of potential prompts which could be specified in the English language. To
ensure that we are scaling up and testing against a useful and representative
set of prompts, we propose a framework for linguistically analyzing 3DVG
prompts and introduce Visual Grounding with Diverse Language in 3D (ViGiL3D), a
diagnostic dataset for evaluating visual grounding methods against a diverse
set of language patterns. We evaluate existing open-vocabulary 3DVG methods to
demonstrate that these methods are not yet proficient in understanding and
identifying the targets of more challenging, out-of-distribution prompts,
toward real-world applications.",http://arxiv.org/abs/2501.01366v1
"Data Acquisition Through Participatory Design for Automated
  Rehabilitation Assessment",2025-01-02T17:33:06Z,"Tamim Ahmed, Zhaoyi Guo, Mohammod Shaikh Sadid Khan, Thanassis Rikakis, Aisling Kelliher","Through participatory design, we are developing a computational system for
the semi-automated assessment of the Action Research Arm Test (ARAT) for stroke
rehabilitation. During rehabilitation assessment, clinicians rate movement
segments and components in the context of overall task performance. Clinicians
change viewing angles to assess particular components. Through studies with
clinicians, we develop a system that includes: a) unobtrusive multi-camera
capture, b) a segmentation interface for non-expert segmentors, and c) a rating
interface for expert clinicians. Five clinicians independently captured 1800
stroke survivor videos with <5$\%$ errors. Three segmentors have segmented 760
of these videos, averaging 20 seconds per segment. They favor the recommended
camera view $>$ 90\%. Multiple clinicians have rated the segmented videos while
reporting minimal problems. The complete data will be used for training an
automated segmentation and rating system that empowers the clinicians as the
ratings will be compatible with clinical practice and intuition.",http://arxiv.org/abs/2501.01374v1
A remark on dimensionality reduction in discrete subgroups,2025-01-02T18:15:08Z,Rodolfo Viera,"In this short note, we prove a version of the Johnson-Lindenstrauss
flattening Lemma for point sets taking values in discrete subgroups. More
precisely, given $d,\lambda_0,N_0\in\mathbb{N}$ and $\epsilon\in
\left(0,\frac{1}{2}\right)$ suitably chosen, we show there exists a natural
number $k=k(d,\epsilon)=O\left(\frac{1}{\epsilon^2}\log d\right)$, such that
for every sufficiently large scaling factor $\lambda\in\mathbb{N}$ and any
point set $\mathcal{D}\subset\frac{\lambda}{\lambda_0}\mathbb{Z}^d\cap
B(0,\lambda N_0)$ with cardinality $d$, there exists an embedding
$F:\mathcal{D}\to\frac{1}{\lambda_0}\mathbb{Z}^k$, with distortion at most
$\left(1+\epsilon+\frac{\epsilon}{\lambda\lambda_0}\right)$.",http://arxiv.org/abs/2501.01396v3
"R-SCoRe: Revisiting Scene Coordinate Regression for Robust Large-Scale
  Visual Localization",2025-01-02T18:59:08Z,"Xudong Jiang, Fangjinhua Wang, Silvano Galliani, Christoph Vogel, Marc Pollefeys","Learning-based visual localization methods that use scene coordinate
regression (SCR) offer the advantage of smaller map sizes. However, on datasets
with complex illumination changes or image-level ambiguities, it remains a less
robust alternative to feature matching methods. This work aims to close the
gap. We introduce a covisibility graph-based global encoding learning and data
augmentation strategy, along with a depth-adjusted reprojection loss to
facilitate implicit triangulation. Additionally, we revisit the network
architecture and local feature extraction module. Our method achieves
state-of-the-art on challenging large-scale datasets without relying on network
ensembles or 3D supervision. On Aachen Day-Night, we are 10$\times$ more
accurate than previous SCR methods with similar map sizes and require at least
5$\times$ smaller map sizes than any other SCR method while still delivering
superior accuracy. Code will be available at: https://github.com/cvg/scrstudio .",http://arxiv.org/abs/2501.01421v1
"Assessing HRV and HR Dynamics with Wearables During Socially Anxious
  Situations: Insights from a Controlled Study in a Low-Middle-Income Country",2025-01-01T10:11:08Z,"Nilesh Kumar Sahu, Snehil Gupta, Haroon R. Lone","This paper investigates physiological markers of Social Anxiety Disorder
(SAD) by examining the relationship between Electrocardiogram (ECG)
measurements and speech, a known anxiety-inducing activity. Specifically, we
analyze changes in heart rate variability (HRV) and heart rate (HR) during four
distinct phases: baseline, anticipation, speech activity, and reflection. Our
study, involving 51 participants (31 with SAD and 20 without), found that HRV
decreased and HR increased during the anticipation and speech activity phases
compared to baseline. In contrast, during the reflection phase, HRV increased
and HR decreased. Additionally, participants with SAD exhibited lower HRV,
higher HR, and reported greater self-perceived anxiety compared to those
without SAD. These findings have implications for developing wearable
technology to monitor SAD. We also provide our dataset, which captures anxiety
across multiple stages, to support further research in this area.",http://arxiv.org/abs/2501.01471v1
"Algebraic perturbation theory: traversable wormholes and generalized
  entropy beyond subleading order",2025-01-02T19:00:00Z,"Shadi Ali Ahmad, Ro Jefferson","The crossed product has recently emerged as an important tool in high-energy
theory. We combine this with another powerful tool, namely pertubation theory,
and study the crossed product algebra of a system under a deformation, relating
the structure of deformed observables to that of the undeformed theory. In
particular, we derive the change in the von Neumann entropy of the type II
algebras, and demonstrate that our approach allows one to formally compute this
to arbitrarily high orders in perturbation theory. As a concrete example, we
apply this machinery to the case of a double-trace deformation of the
thermofield double state in AdS/CFT, which is dual to a traversable wormhole in
the bulk, obtaining several new contributions to the generalized entropy
relative to the original work by Gao, Jafferis, and Wall. We comment on the
relevance of this framework for black hole evaporation and interiors, as well
as on the applicability of the algebraic approach to quantum gravity more
generally.",http://arxiv.org/abs/2501.01487v1
Transfer Neyman-Pearson Algorithm for Outlier Detection,2025-01-02T20:28:53Z,"Mohammadreza M. Kalan, Eitan J. Neugut, Samory Kpotufe","We consider the problem of transfer learning in outlier detection where
target abnormal data is rare. While transfer learning has been considered
extensively in traditional balanced classification, the problem of transfer in
outlier detection and more generally in imbalanced classification settings has
received less attention. We propose a general meta-algorithm which is shown
theoretically to yield strong guarantees w.r.t. to a range of changes in
abnormal distribution, and at the same time amenable to practical
implementation. We then investigate different instantiations of this general
meta-algorithm, e.g., based on multi-layer neural networks, and show
empirically that they outperform natural extensions of transfer methods for
traditional balanced classification settings (which are the only solutions
available at the moment).",http://arxiv.org/abs/2501.01525v1
"In Search of a Lost Metric: Human Empowerment as a Pillar of Socially
  Conscious Navigation",2025-01-02T21:13:46Z,"Vasanth Reddy Baddam, Behdad Chalaki, Vaishnav Tadiparthi, Hossein Nourkhiz Mahjoub, Ehsan Moradi-Pari, Hoda Eldardiry, Almuatazbellah Boker","In social robot navigation, traditional metrics like proxemics and behavior
naturalness emphasize human comfort and adherence to social norms but often
fail to capture an agent's autonomy and adaptability in dynamic environments.
This paper introduces human empowerment, an information-theoretic concept that
measures a human's ability to influence their future states and observe those
changes, as a complementary metric for evaluating social compliance. This
metric reveals how robot navigation policies can indirectly impact human
empowerment. We present a framework that integrates human empowerment into the
evaluation of social performance in navigation tasks. Through numerical
simulations, we demonstrate that human empowerment as a metric not only aligns
with intuitive social behavior, but also shows statistically significant
differences across various robot navigation policies. These results provide a
deeper understanding of how different policies affect social compliance,
highlighting the potential of human empowerment as a complementary metric for
future research in social navigation.",http://arxiv.org/abs/2501.01539v1
"Asymptotic approximations for convection onset with Ekman pumping at low
  wavenumbers",2025-01-02T21:23:17Z,"Sara Tro, Ian Grooms, Keith Julien","Ekman pumping is a phenomenon induced by no-slip boundary conditions in
rotating fluids. In the context of Rayleigh-B\'enard convection, Ekman pumping
causes a significant change in the linear stability of the system compared to
when it is not present (that is, stress-free). Motivated by numerical solutions
to the marginal stability problem of the incompressible Navier-Stokes (iNSE)
system, we seek analytical asymptotic solutions which describe the departure of
the no-slip solution from the stress-free. The substitution of normal modes
into a reduced asymptotic model yields a linear system for which we explore
analytical solutions for various scalings of wavenumber. We find very good
agreement between the analytical asymptotic solutions and the numerical
solutions to the iNSE linear stability problem with no-slip boundary
conditions.",http://arxiv.org/abs/2501.01543v1
"Extended Information Geometry: Large Deviation Theory, Statistical
  Thermodynamics, and Empirical Counting Frequencies",2025-01-02T22:23:28Z,"Viswa Virinchi Muppirala, Hong Qian","Combinatorics, probabilities, and measurements are fundamental to
understanding information. This work explores how the application of large
deviation theory (LDT) in counting phenomena leads to the emergence of various
entropy functions, including Shannon's entropy, mutual information, and
relative and conditional entropies. In terms of these functions, we reveal an
inherent geometrical structure through operations, including contractions,
lift, change of basis, and projections. Legendre-Fenchel (LF) transform, which
is central to both LDT and Gibbs' method of thermodynamics, offers a novel
energetic description of data. The manifold of empirical mean values of
statistical data ad infinitum has a parametrization using LF conjugates w.r.t.
an entropy function; this gives rise to the additivity known in statistical
thermodynamic energetics. This work extends current information geometry to
information projection as defined through conditional expectations in
Kolmogorov's probability theory.",http://arxiv.org/abs/2501.01556v1
"Global existence for small amplitude semilinear wave equations with
  time-dependent scale-invariant damping",2025-01-03T07:02:53Z,"Daoyin He, Yaqing Sun, Kangqun Zhang","In this paper we prove a sharp global existence result for semilinear wave
equations with time-dependent scale-invariant damping terms if the initial data
is small. More specifically, we consider Cauchy problem of
$\partial_t^2u-\Delta u+\frac{\mu}{t}\partial_tu=|u|^p$, where $n\ge 3$, $t\ge
1$ and $\mu\in(0,1)\cup(1,2)$. For critical exponent $p_{crit}(n,\mu)$ which is
the positive root of $(n+\mu-1)p^2-(n+\mu+1)p-2=0$ and conformal exponent
$p_{conf}(n,\mu)=\frac{n+\mu+3}{n+\mu-1}$, we establish global existence for
$n\geq3$ and $p_{crit}(n,\mu)<p\leq p_{conf}(n,\mu)$. The proof is based on
changing the wave equation into the semilinear generalized Tricomi equation
$\partial_t^2u-t^m\Delta u=t^{\alpha(m)}|u|^p$, where $m=m(\mu)>0$ and
$\alpha(m)\in\Bbb R$ are two suitable constants, then we investigate more
general semilinear Tricomi equation $\partial_t^2v-t^m\Delta v=t^{\alpha}|v|^p$
and establish related weighted Strichartz estimates. Returning to the original
wave equation, the corresponding global existence results on the small data
solution $u$ can be obtained.",http://arxiv.org/abs/2501.01670v1
"CrossView-GS: Cross-view Gaussian Splatting For Large-scale Scene
  Reconstruction",2025-01-03T08:24:59Z,"Chenhao Zhang, Yuanping Cao, Lei Zhang","3D Gaussian Splatting (3DGS) has emerged as a prominent method for scene
representation and reconstruction, leveraging densely distributed Gaussian
primitives to enable real-time rendering of high-resolution images. While
existing 3DGS methods perform well in scenes with minor view variation, large
view changes in cross-view scenes pose optimization challenges for these
methods. To address these issues, we propose a novel cross-view Gaussian
Splatting method for large-scale scene reconstruction, based on dual-branch
fusion. Our method independently reconstructs models from aerial and ground
views as two independent branches to establish the baselines of Gaussian
distribution, providing reliable priors for cross-view reconstruction during
both initialization and densification. Specifically, a gradient-aware
regularization strategy is introduced to mitigate smoothing issues caused by
significant view disparities. Additionally, a unique Gaussian supplementation
strategy is utilized to incorporate complementary information of dual-branch
into the cross-view model. Extensive experiments on benchmark datasets
demonstrate that our method achieves superior performance in novel view
synthesis compared to state-of-the-art methods.",http://arxiv.org/abs/2501.01695v1
Sensor Placement on a Cantilever Beam Using Observability Gramians,2025-01-03T09:36:21Z,"Natalie L. Brace, Nicholas B. Andrews, Jeremy Upsal, Kristi A. Morgansen","Working from an observability characterization based on output energy
sensitivity to changes in initial conditions, we derive both analytical and
empirical observability Gramian tools for a class of continuum material
systems. Using these results, optimal sensor placement is calculated for an
Euler-Bernoulli cantilever beam for the following cases: analytical
observability for the continuum system and analytical observability for a
finite number of modes. Error covariance of an Unscented Kalman Filter is
determined for both cases and compared to randomly placed sensors to
demonstrate effectiveness of the techniques.",http://arxiv.org/abs/2501.01726v1
SaLoRA: Safety-Alignment Preserved Low-Rank Adaptation,2025-01-03T11:34:28Z,"Mingjie Li, Wai Man Si, Michael Backes, Yang Zhang, Yisen Wang","As advancements in large language models (LLMs) continue and the demand for
personalized models increases, parameter-efficient fine-tuning (PEFT) methods
(e.g., LoRA) will become essential due to their efficiency in reducing
computation costs. However, recent studies have raised alarming concerns that
LoRA fine-tuning could potentially compromise the safety alignment in LLMs,
posing significant risks for the model owner. In this paper, we first
investigate the underlying mechanism by analyzing the changes in safety
alignment related features before and after fine-tuning. Then, we propose a
fixed safety module calculated by safety data and a task-specific
initialization for trainable parameters in low-rank adaptations, termed
Safety-alignment preserved Low-Rank Adaptation (SaLoRA). Unlike previous LoRA
methods and their variants, SaLoRA enables targeted modifications to LLMs
without disrupting their original alignments. Our experiments show that SaLoRA
outperforms various adapters-based approaches across various evaluation metrics
in different fine-tuning tasks.",http://arxiv.org/abs/2501.01765v1
Some remarks on plane curves related to freeness,2025-01-03T13:39:48Z,Alexandru Dimca,"Let $C$ be a reduced complex projective plane curve, and let $d_1$ and $d_2$
be the first two smallest exponents of $C$. For a free curve $C$ of degree $d$,
there is a simple formula relating $d,d_1, d_2$ and the total Tjurina number of
$C$. Our first result discusses how this result changes when the curve $C$ is
no longer free. For a free line arrangement, the Poincar\'e polynomial
coincides with the Betti polynomial $B(t)$ and with the product
$P(t)=(1+d_1t)(1+d_2t)$. Our second result shows that for any curve $C$, the
difference $P(t)-B(t)$ is a polynomial $a t +bt^2$, with $a$ and $b$
non-negative integers. Moreover $a =0$ or $b=0$ if and only if $C$ is a free
line arrangement. Finally we give new bounds for the second exponent $d_2$ of a
line arrangement $\mathcal A$, the corresponding lower bound being an
improvement of a result by H. Schenck concerning the relation between the
maximal exponent of $\mathcal A$ and the maximal multiplicity of points in
$\mathcal A$.",http://arxiv.org/abs/2501.01807v4
"A stable phase-locking-free single beam optical lattice with multiple
  configurations",2025-01-03T14:52:59Z,"Yirong Wang, Xiaoyu Dai, Xue Zhao, Guangren Sun, Kuiyi Gao, Wei Zhang","Optical lattices formed by interfering laser beams are widely used to trap
and manipulate atoms for quantum simulation, metrology, and computation. To
stabilize optical lattices in experiments, it is usually challenging to
implement delicate phase-locking systems with complicated optics and
electronics to reduce the relative phase fluctuation of multiple laser beams.
Here we report a phase-locking-free scheme to implement optical lattices by
passing a single laser beam through a prism with n-fold symmetric facets and
large apex angles. The scheme ensures a stable optical lattice since the
interference occurs among different deflected parts of a single laser beam
without any moving component. Various lattice configurations, including a
triangular lattice and a quasi-crystal lattice with ten-fold symmetry are
demonstrated. In both cases, stability measurements show a change of lattice
constant in less than 1.14%, and a drift of lattice position in less than
1.61%.",http://arxiv.org/abs/2501.01843v1
"CycleFlow: Leveraging Cycle Consistency in Flow Matching for Speaker
  Style Adaptation",2025-01-03T15:18:30Z,"Ziqi Liang, Xulong Zhang, Chang Liu, Xiaoyang Qu, Weifeng Zhao, Jianzong Wang","Voice Conversion (VC) aims to convert the style of a source speaker, such as
timbre and pitch, to the style of any target speaker while preserving the
linguistic content. However, the ground truth of the converted speech does not
exist in a non-parallel VC scenario, which induces the train-inference mismatch
problem. Moreover, existing methods still have an inaccurate pitch and low
speaker adaptation quality, there is a significant disparity in pitch between
the source and target speaker style domains. As a result, the models tend to
generate speech with hoarseness, posing challenges in achieving high-quality
voice conversion. In this study, we propose CycleFlow, a novel VC approach that
leverages cycle consistency in conditional flow matching (CFM) for speaker
timbre adaptation training on non-parallel data. Furthermore, we design a
Dual-CFM based on VoiceCFM and PitchCFM to generate speech and improve speaker
pitch adaptation quality. Experiments show that our method can significantly
improve speaker similarity, generating natural and higher-quality speech.",http://arxiv.org/abs/2501.01861v1
"Latent Mutants: A large-scale study on the Interplay between mutation
  testing and software evolution",2025-01-03T15:44:38Z,"Jeongju Sohn, Ezekiel Soremekun, Michail Papadakis","In this paper we apply mutation testing in an in-time fashion, i.e., across
multiple project releases. Thus, we investigate how the mutants of the current
version behave in the future versions of the programs. We study the
characteristics of what we call latent mutants, i.e., the mutants that are live
in one version and killed in later revisions, and explore whether they are
predictable with these properties. We examine 131,308 mutants generated by
Pitest on 13 open-source projects. Around 11.2% of these mutants are live, and
3.5% of them are latent, manifesting in 104 days on average. Using the mutation
operators and change-related features we successfully demonstrate that these
latent mutants are identifiable, predicting them with an accuracy of 86% and a
balanced accuracy of 67% using a simple random forest classifier.",http://arxiv.org/abs/2501.01873v1
"Exploring Equality: An Investigation into Custom Loss Functions for
  Fairness Definitions",2025-01-03T16:49:17Z,"Gordon Lee, Simeon Sayer","This paper explores the complex tradeoffs between various fairness metrics
such as equalized odds, disparate impact, and equal opportunity and predictive
accuracy within COMPAS by building neural networks trained with custom loss
functions optimized to specific fairness criteria. This paper creates the first
fairness-driven implementation of the novel Group Accuracy Parity (GAP)
framework, as theoretically proposed by Gupta et al. (2024), and applies it to
COMPAS. To operationalize and accurately compare the fairness of COMPAS models
optimized to differing fairness ideals, this paper develops and proposes a
combinatory analytical procedure that incorporates Pareto front and
multivariate analysis, leveraging data visualizations such as violin graphs.
This paper concludes that GAP achieves an enhanced equilibrium between fairness
and accuracy compared to COMPAS's current nationwide implementation and
alternative implementations of COMPAS optimized to more traditional fairness
definitions. While this paper's algorithmic improvements of COMPAS
significantly augment its fairness, external biases undermine the fairness of
its implementation. Practices such as predictive policing and issues such as
the lack of transparency regarding COMPAS's internal workings have contributed
to the algorithm's historical injustice. In conjunction with developments
regarding COMPAS's predictive methodology, legal and institutional changes must
happen for COMPAS's just deployment.",http://arxiv.org/abs/2501.01889v1
"Dissociation of Adsorbates via Electronic Energy Transfer from Aromatic
  Thin Films",2025-01-03T18:23:14Z,E. T. Jensen,"Photofragment translational spectroscopy has been used to characterize the
photodissociation of CH$_3$I and CF$_3$I adsorbed on thin films of a variety of
aromatic molecules, initiated by near-UV light. Thin films (nominally 10
monolayers) of benzene, five substituted benzenes and two naphthalenes have
been employed to study systematic changes in the photochemical activity.
Illumination of these systems with 248nm light is found to result in a
dissociation process for the CH$_3$I and CF$_3$I mediated by initial absorption
in the aromatic thin film, followed by electronic energy transfer (EET) to the
dissociating species. The effective cross sections for dissociation are found
to be substantially increased via this mechanism, by amounts that differ
depending on the aromatic molecule thin film used, and is connected to the
aromatic photabsorption profile. Distinctive translational energy distributions
for the CH$_3$ and CF$_3$ photofragments are found to vary systematically for
the different aromatic molecule thin film used, and are related to the aromatic
molecule excited states. The CH$_3$ and CF$_3$ photofragment kinetic energy
distributions found for the aromatic thin films suggest that the dissociation
occurs via EET to the $^3Q_1$ excited state of CH$_3$I and CF$_3$I.",http://arxiv.org/abs/2501.01937v1
"Safeguarding Large Language Models in Real-time with Tunable
  Safety-Performance Trade-offs",2025-01-02T15:15:38Z,"Joao Fonseca, Andrew Bell, Julia Stoyanovich","Large Language Models (LLMs) have been shown to be susceptible to jailbreak
attacks, or adversarial attacks used to illicit high risk behavior from a
model. Jailbreaks have been exploited by cybercriminals and blackhat actors to
cause significant harm, highlighting the critical need to safeguard
widely-deployed models. Safeguarding approaches, which include fine-tuning
models or having LLMs ""self-reflect"", may lengthen the inference time of a
model, incur a computational penalty, reduce the semantic fluency of an output,
and restrict ``normal'' model behavior. Importantly, these Safety-Performance
Trade-offs (SPTs) remain an understudied area. In this work, we introduce a
novel safeguard, called SafeNudge, that combines Controlled Text Generation
with ""nudging"", or using text interventions to change the behavior of a model.
SafeNudge triggers during text-generation while a jailbreak attack is being
executed, and can reduce successful jailbreak attempts by 30% by guiding the
LLM towards a safe responses. It adds minimal latency to inference and has a
negligible impact on the semantic fluency of outputs. Further, we allow for
tunable SPTs. SafeNudge is open-source and available through https://pypi.org/,
and is compatible with models loaded with the Hugging Face ""transformers""
library.",http://arxiv.org/abs/2501.02018v1
"Relational bundle geometric formulation of non-relativistic quantum
  mechanics",2025-01-03T19:00:00Z,"J. François, L. Ravera","We present a bundle geometric formulation of non-relativistic many-particles
Quantum Mechanics. A wave function is seen to be a $\mathbb{C}$-valued cocyclic
tensorial 0-form on configuration space-time seen as a principal bundle, while
the Schr\""odinger equation flows from its covariant derivative, with the action
functional supplying a (flat) cocyclic connection 1-form on the configuration
bundle. In line with the historical motivations of Dirac and Feynman, ours is
thus a Lagrangian geometric formulation of QM, in which the Dirac-Feynman path
integral arises in a geometrically natural way.
  Applying the dressing field method, we obtain a relational reformulation of
this geometric non-relativistic QM: a relational wave function is realised as a
basic cocyclic 0-form on the configuration bundle. In this relational QM, any
particle position can be used as a dressing field, i.e. as a ""physical
reference frame"". The dressing field method naturally accounts for the freedom
in choosing the dressing field, which is readily understood as a covariance of
the relational formulation under changes of physical reference frame.",http://arxiv.org/abs/2501.02046v1
"Sporadic Dips from Extended Debris Transiting the Metal-Rich White Dwarf
  SBSS 1232+563",2025-01-03T19:00:01Z,"J. J. Hermes, Joseph A. Guidry, Zachary P. Vanderbosch, Mariona Badenas-Agusti, Siyi Xu, Malia L. Kao, Antonio C. Rodriguez, Keith Hawkins","We present the discovery of deep but sporadic transits in the flux of SBSS
1232+563, a metal-rich white dwarf polluted by disrupted exoplanetary debris.
Nearly 25 years of photometry from multiple sky surveys reveal evidence of
occasional dimming of the white dwarf, most notably evident in an 8-months-long
event in 2023 that caused a >40% drop in flux from the star. In-transit
follow-up shows additional short-timescale (minutes- to hours-long) dimming
events. TESS photometry suggests a coherent 14.842-hr signal that could
represent the dominant orbital period of debris. Six low-resolution spectra
collected at various transit depths over two decades show no evidence of
significant changes in the observed elemental abundances. SBSS 1232+563
demonstrates that debris transits around white dwarfs can be sporadic, with
many years of inactivity before large-amplitude dimming events.",http://arxiv.org/abs/2501.02050v1
"Topological insights into dense frictional suspension rheology: Third
  order loops drive discontinuous shear thickening",2025-01-03T19:12:21Z,"Alessandro D'Amico, Sidong Tu, Abhinendra Singh","Dense suspensions exhibit significant viscosity changes under external
deformation, a phenomenon known as shear thickening. Recent studies have
identified a stress-induced transition from lubricated, unconstrained
interactions to frictional contacts, which play a crucial role in shear
thickening. This work investigates the rheological behavior and contact network
evolution during continuous and discontinuous shear thickening (CST and DST) in
two-dimensional simulations. We find that at low stress, during weak
thickening, the frictional contact network is composed of quasilinear chains
along the compression axis. With increasing stress, the contact network becomes
more isotropic, and forms loop-like structures. We show that third-order loops
within the frictional contact network are key to this behavior. Our findings
revealed a strong correlation between the number of edges in the third-order
loops and the viscosity of the suspension. Notably, this relationship remains
independent of the packing fraction, applied stress, and interparticle
friction, highlighting the fundamental role of the mesoscale network topology
in governing macroscopic rheology.",http://arxiv.org/abs/2501.02062v1
"PriveShield: Enhancing User Privacy Using Automatic Isolated Profiles in
  Browsers",2025-01-03T20:29:33Z,"Seyed Ali Akhavani, Engin Kirda, Amin Kharraz","Online tracking is a widespread practice on the web with questionable ethics,
security, and privacy concerns. While web tracking can offer personalized and
curated content to Internet users, it operates as a sophisticated surveillance
mechanism to gather extensive user information. This paper introduces
PriveShield, a light-weight privacy mechanism that disrupts the information
gathering cycle while offering more control to Internet users to maintain their
privacy. PriveShield is implemented as a browser extension that offers an
adjustable privacy feature to surf the web with multiple identities or accounts
simultaneously without any changes to underlying browser code or services. When
necessary, multiple factors are automatically analyzed on the client side to
isolate cookies and other information that are the basis of online tracking.
PriveShield creates isolated profiles for clients based on their browsing
history, interactions with websites, and the amount of time they spend on
specific websites. This allows the users to easily prevent unwanted browsing
information from being shared with third parties and ad exchanges without the
need for manual configuration. Our evaluation results from 54 real-world
scenarios show that our extension is effective in preventing retargeted ads in
91% of those scenarios.",http://arxiv.org/abs/2501.02091v1
"How Your Location Relates to Health: Variable Importance and
  Interpretable Machine Learning for Environmental and Sociodemographic Data",2025-01-03T21:34:35Z,"Ishaan Maitra, Raymond Lin, Eric Chen, Jon Donnelly, Sanja Šćepanović, Cynthia Rudin","Health outcomes depend on complex environmental and sociodemographic factors
whose effects change over location and time. Only recently has fine-grained
spatial and temporal data become available to study these effects, namely the
MEDSAT dataset of English health, environmental, and sociodemographic
information. Leveraging this new resource, we use a variety of variable
importance techniques to robustly identify the most informative predictors
across multiple health outcomes. We then develop an interpretable machine
learning framework based on Generalized Additive Models (GAMs) and Multiscale
Geographically Weighted Regression (MGWR) to analyze both local and global
spatial dependencies of each variable on various health outcomes. Our findings
identify NO2 as a global predictor for asthma, hypertension, and anxiety,
alongside other outcome-specific predictors related to occupation, marriage,
and vegetation. Regional analyses reveal local variations with air pollution
and solar radiation, with notable shifts during COVID. This comprehensive
approach provides actionable insights for addressing health disparities, and
advocates for the integration of interpretable machine learning in public
health.",http://arxiv.org/abs/2501.02111v1
"The onset of nonpenetrative convection in a suddenly cooled layer of
  fluid",2025-01-03T23:00:23Z,"C F Ihle, Y Niño","Conditions for the onset of nonpenetrative convection in a horizontal
Boussinesq fluid layer subject to a step change in temperature are studied
using propagation theory. A wide range of Prandtl numbers and two different
kinematic boundary conditions are considered. It is shown that for high
Rayleigh numbers, critical conditions for the onset of convective motion
reproduce exactly those for the unsteady Rayleigh-B\'enard instability. Present
results extend those of previous research and show a tendency of the
rigid-rigid and free-rigid critical curves to converge for low Prandtl numbers.
Comparison between present and previously reported results on critical
conditions for the onset of instabilities and onset time using different
methods yields good agreement on a middle to high Prandtl number range. A ratio
of 10 between experimentally measured and theoretically predicted onset times
is suggested for stress-free bounded systems.",http://arxiv.org/abs/2501.02134v2
The Application of Large Language Models in Recommendation Systems,2025-01-04T04:02:23Z,"Peiyang Yu, Zeqiu Xu, Jiani Wang, Xiaochuan Xu","The integration of Large Language Models into recommendation frameworks
presents key advantages for personalization and adaptability of experiences to
the users. Classic methods of recommendations, such as collaborative filtering
and content-based filtering, are seriously limited in the solution of
cold-start problems, sparsity of data, and lack of diversity in information
considered. LLMs, of which GPT-4 is a good example, have emerged as powerful
tools that enable recommendation frameworks to tap into unstructured data
sources such as user reviews, social interactions, and text-based content. By
analyzing these data sources, LLMs improve the accuracy and relevance of
recommendations, thereby overcoming some of the limitations of traditional
approaches. This work discusses applications of LLMs in recommendation systems,
especially in electronic commerce, social media platforms, streaming services,
and educational technologies. This showcases how LLMs enrich recommendation
diversity, user engagement, and the system's adaptability; yet it also looks
into the challenges connected to their technical implementation. This can also
be presented as a study that shows the potential of LLMs for changing user
experiences and making innovation possible in industries.",http://arxiv.org/abs/2501.02178v2
"AdaMixup: A Dynamic Defense Framework for Membership Inference Attack
  Mitigation",2025-01-04T04:21:48Z,"Ying Chen, Jiajing Chen, Yijie Weng, ChiaHua Chang, Dezhi Yu, Guanbiao Lin","Membership inference attacks have emerged as a significant privacy concern in
the training of deep learning models, where attackers can infer whether a data
point was part of the training set based on the model's outputs. To address
this challenge, we propose a novel defense mechanism, AdaMixup. AdaMixup
employs adaptive mixup techniques to enhance the model's robustness against
membership inference attacks by dynamically adjusting the mixup strategy during
training. This method not only improves the model's privacy protection but also
maintains high performance. Experimental results across multiple datasets
demonstrate that AdaMixup significantly reduces the risk of membership
inference attacks while achieving a favorable trade-off between defensive
efficiency and model accuracy. This research provides an effective solution for
data privacy protection and lays the groundwork for future advancements in
mixup training methods.",http://arxiv.org/abs/2501.02182v1
"Examining the Robustness of Homogeneity Bias to Hyperparameter
  Adjustments in GPT-4",2025-01-04T06:51:49Z,Messi H. J. Lee,"Vision-Language Models trained on massive collections of human-generated data
often reproduce and amplify societal stereotypes. One critical form of
stereotyping reproduced by these models is homogeneity bias-the tendency to
represent certain groups as more homogeneous than others. We investigate how
this bias responds to hyperparameter adjustments in GPT-4, specifically
examining sampling temperature and top p which control the randomness of model
outputs. By generating stories about individuals from different racial and
gender groups and comparing their similarities using vector representations, we
assess both bias robustness and its relationship with hyperparameter values. We
find that (1) homogeneity bias persists across most hyperparameter
configurations, with Black Americans and women being represented more
homogeneously than White Americans and men, (2) the relationship between
hyperparameters and group representations shows unexpected non-linear patterns,
particularly at extreme values, and (3) hyperparameter adjustments affect
racial and gender homogeneity bias differently-while increasing temperature or
decreasing top p can reduce racial homogeneity bias, these changes show
different effects on gender homogeneity bias. Our findings suggest that while
hyperparameter tuning may mitigate certain biases to some extent, it cannot
serve as a universal solution for addressing homogeneity bias across different
social group dimensions.",http://arxiv.org/abs/2501.02211v1
"Interpretable Load Forecasting via Representation Learning of
  Geo-distributed Meteorological Factors",2025-01-04T09:05:06Z,"Yangze Zhou, Guoxin Lin, Gonghao Zhang, Yi Wang","Meteorological factors (MF) are crucial in day-ahead load forecasting as they
significantly influence the electricity consumption behaviors of consumers.
Numerous studies have incorporated MF into the load forecasting model to
achieve higher accuracy. Selecting MF from one representative location or the
averaged MF as the inputs of the forecasting model is a common practice.
However, the difference in MF collected in various locations within a region
may be significant, which poses a challenge in selecting the appropriate MF
from numerous locations. A representation learning framework is proposed to
extract geo-distributed MF while considering their spatial relationships. In
addition, this paper employs the Shapley value in the graph-based model to
reveal connections between MF collected in different locations and loads. To
reduce the computational complexity of calculating the Shapley value, an
acceleration method is adopted based on Monte Carlo sampling and weighted
linear regression. Experiments on two real-world datasets demonstrate that the
proposed method improves the day-ahead forecasting accuracy, especially in
extreme scenarios such as the ""accumulation temperature effect"" in summer and
""sudden temperature change"" in winter. We also find a significant correlation
between the importance of MF in different locations and the corresponding
area's GDP and mainstay industry.",http://arxiv.org/abs/2501.02241v1
"The Effect of Capital Share on Income Inequality: Identifying the Time
  Patterns",2025-01-04T20:15:42Z,"Oğuzhan Akgün, Ezgi Özsöğüt","This study explores the link between the capital share and income inequality
over the past four decades across 56 countries. Calculating the capital share
from national accounts alongside top income share data from the World
Inequality Database, which is based on the Distributional National Accounts
methodology, we ensure the consistency in the theory and measurement. Employing
a structural econometric approach, we account for heterogeneous and
time-varying transmission coefficients from the capital share to personal
income inequality. Our findings reveal that a one percentage point (pp)
increase in the capital share raises the income share of the top 5% by 0.17 pp
on average. Advanced economies show a stable transmission coefficient with
rising capital and labor income inequality, while emerging economies experience
an increasing transmission coefficient alongside growing capital income
inequality. In contrast, a third group exhibits a declining transmission
coefficient and rising labor income inequality. Overall, changes in the capital
share account for approximately 50% of the rise in income inequality,
underscoring its pivotal role over the last four decades.",http://arxiv.org/abs/2501.02371v1
"iTARGET: Interpretable Tailored Age Regression for Grouped Epigenetic
  Traits",2025-01-04T23:06:46Z,"Zipeng Wu, Daniel Herring, Fabian Spill, James Andrews","Accurately predicting chronological age from DNA methylation patterns is
crucial for advancing biological age estimation. However, this task is made
challenging by Epigenetic Correlation Drift (ECD) and Heterogeneity Among CpGs
(HAC), which reflect the dynamic relationship between methylation and age
across different life stages. To address these issues, we propose a novel
two-phase algorithm. The first phase employs similarity searching to cluster
methylation profiles by age group, while the second phase uses Explainable
Boosting Machines (EBM) for precise, group-specific prediction. Our method not
only improves prediction accuracy but also reveals key age-related CpG sites,
detects age-specific changes in aging rates, and identifies pairwise
interactions between CpG sites. Experimental results show that our approach
outperforms traditional epigenetic clocks and machine learning models, offering
a more accurate and interpretable solution for biological age estimation with
significant implications for aging research.",http://arxiv.org/abs/2501.02401v1
Asynchronous Hebbian/anti-Hebbian networks,2025-01-04T23:11:24Z,"Henrique Reis Aguiar, Matthias H. Hennig","Lateral inhibition models coupled with Hebbian plasticity have been shown to
learn factorised causal representations of input stimuli, for instance,
oriented edges are learned from natural images. Currently, these models require
the recurrent dynamics to settle into a stable state before weight changes can
be applied, which is not only biologically implausible, but also impractical
for real-time learning systems. Here, we propose a new Hebbian learning rule
which is implemented using plausible biological mechanisms that have been
observed experimentally. We find that this rule allows for efficient,
time-continuous learning of factorised representations, very similar to the
classic noncontinuous Hebbian/anti-Hebbian learning. Furthermore, we show that
this rule naturally prevents catastrophic forgetting when stimuli from
different distributions are shown sequentially.",http://arxiv.org/abs/2501.02402v1
"Interpretable Neural ODEs for Gene Regulatory Network Discovery under
  Perturbations",2025-01-05T01:04:23Z,"Zaikang Lin, Sei Chang, Aaron Zweig, Minseo Kang, Elham Azizi, David A. Knowles","Modern high-throughput biological datasets with thousands of perturbations
provide the opportunity for large-scale discovery of causal graphs that
represent the regulatory interactions between genes. Differentiable causal
graphical models have been proposed to infer a gene regulatory network (GRN)
from large scale interventional datasets, capturing the causal gene regulatory
relationships from genetic perturbations. However, existing models are limited
in their expressivity and scalability while failing to address the dynamic
nature of biological processes such as cellular differentiation. We propose
PerturbODE, a novel framework that incorporates biologically informative neural
ordinary differential equations (neural ODEs) to model cell state trajectories
under perturbations and derive the causal GRN from the neural ODE's parameters.
We demonstrate PerturbODE's efficacy in trajectory prediction and GRN inference
across simulated and real over-expression datasets.",http://arxiv.org/abs/2501.02409v2
"RTLMarker: Protecting LLM-Generated RTL Copyright via a Hardware
  Watermarking Framework",2025-01-05T05:38:28Z,"Kun Wang, Kaiyan Chang, Mengdi Wang, Xinqi Zou, Haobo Xu, Yinhe Han, Ying Wang","Recent advances of large language models in the field of Verilog generation
have raised several ethical and security concerns, such as code copyright
protection and dissemination of malicious code. Researchers have employed
watermarking techniques to identify codes generated by large language models.
However, the existing watermarking works fail to protect RTL code copyright due
to the significant syntactic and semantic differences between RTL code and
software code in languages such as Python. This paper proposes a hardware
watermarking framework RTLMarker that embeds watermarks into RTL code and
deeper into the synthesized netlist. We propose a set of rule-based Verilog
code transformations , ensuring the watermarked RTL code's syntactic and
semantic correctness. In addition, we consider an inherent tradeoff between
watermark transparency and watermark effectiveness and jointly optimize them.
The results demonstrate RTLMarker's superiority over the baseline in RTL code
watermarking.",http://arxiv.org/abs/2501.02446v1
The Meta-Representation Hypothesis,2025-01-05T09:06:17Z,"Zhengpeng Xie, Jiahang Cao, Qiang Zhang, Jianxiong Zhang, Changwei Wang, Renjing Xu","Humans rely on high-level understandings of things, i.e.,
meta-representations, to engage in abstract reasoning. In complex cognitive
tasks, these meta-representations help individuals abstract general rules from
experience. However, constructing such meta-representations from
high-dimensional observations remains a longstanding challenge for
reinforcement learning (RL) agents. For instance, a well-trained agent often
fails to generalize to even minor variations of the same task, such as changes
in background color, while humans can easily handle. In this paper, we
theoretically investigate how meta-representations contribute to the
generalization ability of RL agents, demonstrating that learning
meta-representations from high-dimensional observations enhance an agent's
ability to generalize across varied environments. We further hypothesize that
deep mutual learning (DML) among agents can help them learn the
meta-representations that capture the underlying essence of the task. Empirical
results provide strong support for both our theory and hypothesis. Overall,
this work provides a new perspective on the generalization of deep
reinforcement learning.",http://arxiv.org/abs/2501.02481v3
Surfacic networks,2025-01-05T09:26:17Z,"Marc Barthelemy, Geoff Boeing, Alain Chiarada, Chris Webster","Surfacic networks are structures built upon a two-dimensional manifold. Many
systems, including transportation networks and various urban networks, fall
into this category. The fluctuations of node elevations imply significant
deviations from typical plane networks and require specific tools to understand
their impact. Here, we present such tools, including lazy paths that minimize
elevation differences, graph arduousness which measures the tiring nature of
shortest paths, and the excess effort, which characterizes positive elevation
variations along shortest paths. We illustrate these measures using toy models
of surfacic networks and empirically examine pedestrian networks in selected
cities. Specifically, we examine how changes in elevation affect the spatial
distribution of betweenness centrality. We also demonstrate that the excess
effort follows a non-trivial power law distribution, with an exponent that is
not universal, which illustrates that there is a significant probability of
encountering steep slopes along shortest paths, regardless of the elevation
difference between the starting point and the destination. These findings
highlight the significance of elevation fluctuations in shaping network
characteristics. Surfacic networks offer a promising framework for
comprehensively analyzing and modeling complex systems that are situated on or
constrained to a surface environment.",http://arxiv.org/abs/2501.02484v1
"Remote Inference over Dynamic Links via Adaptive Rate Deep Task-Oriented
  Vector Quantization",2025-01-05T12:38:13Z,"Eyal Fishel, May Malka, Shai Ginzach, Nir Shlezinger","A broad range of technologies rely on remote inference, wherein data acquired
is conveyed over a communication channel for inference in a remote server.
Communication between the participating entities is often carried out over
rate-limited channels, necessitating data compression for reducing latency.
While deep learning facilitates joint design of the compression mapping along
with encoding and inference rules, existing learned compression mechanisms are
static, and struggle in adapting their resolution to changes in channel
conditions and to dynamic links. To address this, we propose Adaptive Rate
Task-Oriented Vector Quantization (ARTOVeQ), a learned compression mechanism
that is tailored for remote inference over dynamic links. ARTOVeQ is based on
designing nested codebooks along with a learning algorithm employing
progressive learning. We show that ARTOVeQ extends to support low-latency
inference that is gradually refined via successive refinement principles, and
that it enables the simultaneous usage of multiple resolutions when conveying
high-dimensional data. Numerical results demonstrate that the proposed scheme
yields remote deep inference that operates with multiple rates, supports a
broad range of bit budgets, and facilitates rapid inference that gradually
improves with more bits exchanged, while approaching the performance of
single-rate deep quantization methods.",http://arxiv.org/abs/2501.02521v1
"AMM: Adaptive Modularized Reinforcement Model for Multi-city Traffic
  Signal Control",2025-01-05T13:59:08Z,"Zherui Huang, Yicheng Liu, Chumeng Liang, Guanjie Zheng","Traffic signal control (TSC) is an important and widely studied direction.
Recently, reinforcement learning (RL) methods have been used to solve TSC
problems and achieve superior performance over conventional TSC methods.
However, applying RL methods to the real world is challenging due to the huge
cost of experiments in real-world traffic environments. One possible solution
is TSC domain adaptation, which adapts trained models to target environments
and reduces the number of interactions and the training cost. However, existing
TSC domain adaptation methods still face two major issues: the lack of
consideration for differences across cities and the low utilization of
multi-city data.
  To solve aforementioned issues, we propose an approach named Adaptive
Modularized Model (AMM). By modularizing TSC problems and network models, we
overcome the challenge of possible changes in environmental observations. We
also aggregate multi-city experience through meta-learning. We conduct
extensive experiments on different cities and show that AMM can achieve
excellent performance with limited interactions in target environments and
outperform existing methods. We also demonstrate the feasibility and
generalizability of our method.",http://arxiv.org/abs/2501.02548v1
Feshbach resonances and dynamics of BPS solitons,2025-01-05T15:49:13Z,"Alberto García Martín-Caro, Jose Queiruga, Andrzej Wereszczynski","We demonstrate that the geodesic dynamics of BPS solitons can be modified by
the excitation of Feshbach resonances, or quasi-bound modes, in a toy model of
two scalar fields. A mode-generated force emerges, with a strength determined
by the spectral flow of the frequency on the moduli space, and weakened by the
coupling between the bound and scattering components of the resonance. Notably,
spectral walls persist unaffected by the resonant mode's exponential decay, as
the decay constant vanishes at the spectral wall. Our motivation comes from the
't Hooft-Polyakov monopoles, which do not present true bound states but long
lived semi-bound excitations. Our findings suggest the existence of spectral
walls in the scattering of excited monopoles in three dimensions, whose
trajectories may significantly deviate from the geodesic motion in the moduli
space of unexcited monopoles.",http://arxiv.org/abs/2501.02589v2
"A System for Melodic Harmonization using Schoenberg Regions, Giant
  Steps, and Church Modes",2025-01-05T20:08:42Z,Frederick Fernandes,"Systems such as Microsoft Songsmith automatically assign chords and harmony
to a melody by minimizing the dissonance across all chord changes. Although
this produces harmonious music, it is not what practicing musicians do. In this
paper, I describe Harmonizer, a prototype system for melodic harmonization.
Harmonizer uses Schoenberg's chart of regions as the underlying data structure
that allows harmonization using several different methods. Because the chart
reveals inter-chordal relationships, the harmonizations may be programmed to
emphasize desired relationships. In the prototype Harmonizer, I also explore
recent signal-processing methods that enable songwriters to easily input a
melody by singing or by playing a musical instrument. The prototype Harmonizer
is available on GitHub and a video demonstrating its distinctive harmonizations
is on YouTube as explained in the Results section of the paper.",http://arxiv.org/abs/2501.02642v1
"From Superficial Patterns to Semantic Understanding: Fine-Tuning
  Language Models on Contrast Sets",2025-01-05T23:19:55Z,Daniel Petrov,"Large-scale pre-trained language models have demonstrated high performance on
standard datasets for natural language inference (NLI) tasks. Unfortunately,
these evaluations can be misleading, as although the models can perform well on
in-distribution data, they perform poorly on out-of-distribution test sets,
such as contrast sets. Contrast sets consist of perturbed instances of data
that have very minor, but meaningful, changes to the input that alter the gold
label, revealing how models can learn superficial patterns in the training data
rather than learning more sophisticated language nuances. As an example, the
ELECTRA-small language model achieves nearly 90% accuracy on an SNLI dataset
but drops to 75% when tested on an out-of-distribution contrast set. The
research carried out in this study explores how the robustness of a language
model can be improved by exposing it to small amounts of more complex contrast
sets during training to help it better learn language patterns. With this
approach, the model recovers performance and achieves nearly 90% accuracy on
contrast sets, highlighting the importance of diverse and challenging training
data.",http://arxiv.org/abs/2501.02683v2
"Anomalous Magnetotransport in the Paramagnetic State of a Magnetic
  Kagome Metal EuTi$_3$Bi$_4$",2025-01-06T03:27:59Z,"Yun Shu, Xinrun Mi, Yuhao Wei, Sixue Tao, Aifeng Wang, Yisheng Chai, Dashuai Ma, Xiaolong Yang, Mingquan He","We investigate the electrical transport properties of a magnetic kagome metal
EuTi$_3$Bi$_4$, which undergoes magnetic ordering below $T_\mathrm{c}=10.5$ K.
Unlike typical magnets showing anomalous magnetotransport in their ordered
states, EuTi$_3$Bi$_4$ exhibits unusual magnetotransport behaviors in its
paramagnetic phase. Specifically, the magnetoconductivity shows a linear
dependence on magnetic field at low fields below $\sim 1$ T, and the Hall
conductivity undergoes a sign change below about 2 T. These behaviors resemble
those observed in the charge density wave (CDW) phase of kagome metals
$A$V$_3$Sb$_5$ ($A$ = K, Rb, Cs). The anomalous magnetotransport in
$A$V$_3$Sb$_5$ has commonly been attributed to the possible emergence of a
time-reversal symmetry breaking chiral CDW order. However, given the absence of
CDW in EuTi$_3$Bi$_4$ and its manifestation exclusively in the paramagnetic
state, the anomalous magnetotransport observed in EuTi$_3$Bi$_4$ is likely
associated with multiband transport and/or the van Hove singularities near the
Fermi level.",http://arxiv.org/abs/2501.02743v2
"Bifurcations and stability of synchronized solutions in the Kuramoto
  model with uniformly spaced natural frequencies",2025-01-06T10:07:17Z,Kazuyuki Yagasaki,"We consider the classical Kuramoto model (KM) with natural frequencies and
its continuum limit (CL), and discuss the existence of synchronized solutions
and their bifurcations and stability. We specifically assume that the frequency
function is symmetric and linear in the CL, so that the natural frequencies are
evenly spaced in the KM. We show that in the KM, $O(2^n)$ one-parameter
families of synchronized solutions are born and $O(2^n)$ {saddle-node and}
pitchfork bifurcations occur at least, when the node number $n$ is odd and
tends to infinity. Moreover, we prove that the family of synchronized solutions
obtained in the previous work suffers a saddle-node bifurcation at which its
stability changes from asymptotically stable to unstable and the other families
of synchronized solutions are unstable in the KM. For the CL, we show that the
one-parameter family of synchronized solutions obtained in the previous work is
the only continuous one and there exist uncountably many one-parameter families
of noncontinuous synchronized solutions and that the former is asymptotically
stable and the latter are unstable.",http://arxiv.org/abs/2501.02889v3
"Leader Rotation Is Not Enough: Scrutinizing Leadership Democracy of
  Chained BFT Consensus",2025-01-06T12:27:34Z,"Yining Tang, Runchao Han, Jianyu Niu, Chen Feng, Yinqian Zhang","With the growing popularity of blockchains, modern chained BFT protocols
combining chaining and leader rotation to obtain better efficiency and
leadership democracy have received increasing interest. Although the efficiency
provisions of chained BFT protocols have been thoroughly analyzed, the
leadership democracy has received little attention in prior work. In this
paper, we scrutinize the leadership democracy of four representative chained
BFT protocols, especially under attack. To this end, we propose a unified
framework with two evaluation metrics, i.e., chain quality and censorship
resilience, and quantitatively analyze chosen protocols through the Markov
Decision Process (MDP). With this framework, we further examine the impact of
two key components, i.e., voting pattern and leader rotation on leadership
democracy. Our results indicate that leader rotation is not enough to provide
the leadership democracy guarantee; an adversary could utilize the design,
e.g., voting pattern, to deteriorate the leadership democracy significantly.
Based on the analysis results, we propose customized countermeasures for three
evaluated protocols to improve their leadership democracy with only slight
protocol overhead and no change of consensus rules. We also discuss future
directions toward building more democratic chained BFT protocols.",http://arxiv.org/abs/2501.02970v1
"Super-fast bullet bubbles transported in a pressure-driven cylindrical
  flow",2025-01-06T13:12:15Z,"Jean Cappello, Javier Rivero-Rodriguez, Benoit Scheid","When transported by a pressure driven flow in a cylindrical pipe, bubbles may
exhibit very fast velocities. In this paper, we show that, when the bubbles are
largely deformable, that is, at large capillary numbers Ca, the velocity of the
bubble can be larger than the maximal velocity of the flow that transports
them. We call this regime ""super-fast"". However, the situation changes when
inertia comes at play for increasing Reynolds numbers Re, and the relative
velocity of the bubble drops for sufficiently large Laplace number, defined as
La = Re/Ca. In this article, we uncover the conditions for which the super-fast
regime exists : the deformability of the drop is crucial, and hence the
capillary number needs to be larger than a critical value, yet smaller than a
threshold above which the bubble breaks up. The two limiting capillary numbers
are presented in a phase diagram as a function of the bubble size and the
Laplace number.",http://arxiv.org/abs/2501.02993v1
"Characterizing Measurement Error in the German Socio-Economic Panel
  Using Linked Survey and Administrative Data",2025-01-06T13:47:22Z,Nico Thurow,"This paper exploits the linkage of German administrative social security data
(GER: Integrierte Erwerbsbiografien) and survey data from the socio-economic
panel (GER: Sozio-\""okonomisches Panel, SOEP) for the characterization of
measurement error in metrics quantifying individual-specific labor earnings in
Germany. We find that survey participants' decision whether to consent to
linkage is non-random based on observables. In that sense, the studied sample
does not constitute a random sample of SOEP. Measurement error is not
classical: we observe underreporting of income on average, autocorrelation, and
non-zero correlation with the true signal and other observable characteristics.
In levels, calculated reliability ratios above 0.94 hint at a relaitvely small
attenuation bias in simple linear univariate regressions with earnings as the
explanatory variable. For changes in income, i.e. first differences, the bias
from measurement error is exacerbated.",http://arxiv.org/abs/2501.03015v1
"Geometric optics analysis in Lorentz violating Chern-Simons
  electrodynamics",2025-01-06T14:36:04Z,"Arpan Das, Hriditi Howlader, Alekha C. Nayak","We study the geometric optics limit of the electrodynamics in the presence of
Lorentz violating Chern-Simons term in (3+1) dimensions. The Chern-Simons term
couples the dual electromagnetic tensor to an external four-vector and the
electromagnetic gauge field. For a fixed external four-vector, such a
Chern-Simons term violates Lorentz invariance while maintaining the gauge
invariance of the theory. In this analysis, we look into the consequences of
Lorentz symmetry violating Chern-Simons term within the geometric optics limit
of light rays propagating from a source to an observation point. We argue that
the Ricci tensor and the Lorentz-violating term modify the dynamical equation
for the gauge vector field. However, in the geometric optics limit, neither the
space-time curvature nor the Chern-Simons term influences the intensity of
light. Unlike the intensity, the polarization of light, on the other hand, can
be influenced by the Lorentz-violating Chern-Simons term. Due to such an effect
in the presence of Chern-Simons term, the photon emitting from astrophysical
objects can undergo a change in polarization as it propagates in space.",http://arxiv.org/abs/2501.03047v1
Knife-Edge Diffraction of Scalar and Vector Vortex Light,2025-01-06T14:39:50Z,"Richard Aguiar Maduro, Amanda Kronhardt Fritsch, Sonja Franke-Arnold","Various methods have been introduced to measure the orbital angular momentum
(OAM) of light, from fork holograms to Dove prism interferometers, from tilted
lenses to triangular apertures - each with their own benefits and limitations.
Here we demonstrate how simple knife-edge diffraction can be used to identify
the OAM of an optical phase vortex from the formation of fork dislocations
within the Fresnel diffraction pattern. For vector vortex beams without net
OAM, the conventional Fresnel fringes are recovered, whereas the polarization
in the geometric shadow is changed in its ellipticity. The observed diffraction
patterns agree with simulations and their features can be explained by
considering diffraction as an interference phenomenon. Knife-edge diffraction
provides not only an instructive illustration of various properties of phase
and polarization vortices, but can also serve as an ideal method for the quick
determination of optical OAM, with potential applications beyond optics, where
alternative detection measurement methods may be harder to realize.",http://arxiv.org/abs/2501.03052v1
"MVP: Multimodal Emotion Recognition based on Video and Physiological
  Signals",2025-01-06T16:09:22Z,"Valeriya Strizhkova, Hadi Kachmar, Hava Chaptoukaev, Raphael Kalandadze, Natia Kukhilava, Tatia Tsmindashvili, Nibras Abo-Alzahab, Maria A. Zuluaga, Michal Balazia, Antitza Dantcheva, François Brémond, Laura Ferrari","Human emotions entail a complex set of behavioral, physiological and
cognitive changes. Current state-of-the-art models fuse the behavioral and
physiological components using classic machine learning, rather than recent
deep learning techniques. We propose to fill this gap, designing the Multimodal
for Video and Physio (MVP) architecture, streamlined to fuse video and
physiological signals. Differently then others approaches, MVP exploits the
benefits of attention to enable the use of long input sequences (1-2 minutes).
We have studied video and physiological backbones for inputting long sequences
and evaluated our method with respect to the state-of-the-art. Our results show
that MVP outperforms former methods for emotion recognition based on facial
videos, EDA, and ECG/PPG.",http://arxiv.org/abs/2501.03103v1
"On the renormalization of ultraviolet divergences in the inflationary
  angular power spectrum",2025-01-06T16:31:52Z,"Adrian del Rio, Jose Navarro-Salas","We revise the role that ultraviolet divergences of quantum fields play in
slow-roll inflation, and discuss the renormalization of cosmological
observables from a space-time perspective, namely the angular power spectrum.
We first derive an explicit expression for the multipole coefficients
$C_{\ell}$ in the Sachs-Wolfe regime in terms of the two-point function of
primordial perturbations. We then analyze the ultraviolet behavior, and point
out that the standard result in the literature is equivalent to a
renormalization of $C_{\ell}$ at zero ``adiabatic'' order. We further argue
that renormalization at second ``adiabatic'' order may be more appropriate from
the viewpoint of standard quantum field theory. This may change significantly
the predictions for $C_{\ell}$, while maintaining scale invariance.",http://arxiv.org/abs/2501.03125v1
"Nonequilibrium thermodynamics of populations of weakly-coupled
  low-temperature-differential Stirling engines with synchronous and
  asynchronous transitions",2025-01-06T18:04:04Z,"Songhao Yin, Hiroshi Kori, Yuki Izumida","This study developed the theory of nonequilibrium thermodynamics for
populations of low-temperature-differential (LTD) Stirling engines
weakly-coupled in a general class of networks to clarify the effects of
synchronous and asynchronous transitions on the power and thermal efficiency.
We first show that synchronous (asynchronous) transitions increase (decrease)
the power and thermal efficiency of weakly-coupled LTD Stirling engines based
on quasilinear response relations between formally defined thermodynamic fluxes
and forces. After that, we construct a conceptual model satisfying the
quasilinear response relations to give a physical interpretation of the changes
in power and thermal efficiency due to synchronous and asynchronous
transitions, and justify the use of this conceptual model. We then show that
the conceptual model, rather than the quasilinear response relations, preserves
the irreversible nature in the relative motion of the original model and thus
shows more accurate results than the analysis using the quasilinear response
relations. Finally, we compare the dynamics between the original and the
conceptual models for two-engine systems and show that the conceptual model
roughly preserves the dynamical characteristics leading up to the synchronous
transitions, while some detailed dynamical structures are lost.",http://arxiv.org/abs/2501.03185v1
Local data of elliptic curves under quadratic twist,2025-01-06T18:41:56Z,"Alexander J. Barrios, Manami Roy, Nandita Sahajpal, Darwin Tallana, Bella Tobin, Hanneke Wiersema","Let $K$ be the field of fractions of a complete discrete valuation ring with
a perfect residue field. In this article, we investigate how the Tamagawa
number of $E/K$ changes under quadratic twist. To accomplish this, we introduce
the notion of a normal model for $E/K$, which is a Weierstrass model satisfying
certain conditions that lead one to easily infer the local data of $E/K$. Our
main results provide necessary and sufficient conditions on the Weierstrass
coefficients of a normal model of $E/K$ to determine the local data of a
quadratic twist $E^{d}/K$. We note that when the residue field has
characteristic $2$, we only consider the special case $K=\mathbb{Q}_{2}$. In
this setting, we also determine the minimal discriminant valuation and
conductor exponent of $E$ and $E^d$ from further conditions on the coefficients
of a normal model for $E$.",http://arxiv.org/abs/2501.03209v1
"Sub-micron Circuit Fabrication on Diamond Anvils for Mesoscopic
  High-Pressure Experiments",2025-01-06T19:00:01Z,"Z. R. Rehfuss, K. Zheng, S. L. Gould, K. W. Murch, S. Ran","We present a novel fabrication procedure to produce high-quality lift-off
structures on diamond anvils extending from the culet down to the slanted
facets. Feature sizes down to 500 nm are achieved through the use of a bi-layer
resist stack and electron beam lithography. Device structures with strong
adhesion to the diamond surface and high abrasion resistance are realized by
optimizing the surface treatment. To benchmark our process, we fabricate a
multi-lead tungsten circuit to measure changes of the superconducting
transition temperature of zirconium across the structural phase transition at
$\sim$30 GPa; showing a 4-fold jump of the critical temperature. Our process is
easily reproducible in most traditional academic and industrial cleanroom
facilities. This work paves the way for complex and high-precision fabrication
and measurements inside diamond anvil cells and on other faceted crystalline
samples.",http://arxiv.org/abs/2501.03317v1
"Solar Cycle Variation of Axial Orientations and Favorable Locations of
  Eruptive MFRs",2025-01-06T19:26:58Z,"Hong Xie, Nat Gopalswamy, Sachiko Akiyama, Pertti Makela, Seiji Yashiro","Using multi-viewpoint observations from STEREO and SOHO during three solar
cycles from 23 to 25, we study the magnetic flux rope (MFR) structures of
coronal mass ejections (CMEs) near the Sun and magnetic clouds (MCs) at 1au.
The study aims to investigate two phenomena: 1) the occurrence rate of CMEs
near Hale sector boundaries (HBs) and 2) solar-cycle variation of MFR axial
orientations in CMEs and MCs. Our preliminary results include: 1) the axes of
MFRs in cycle 25 present a systematic northward orientation, which is the same
as in cycle 23 but opposite to cycle 24; 2) the majority of the MFRs occurred
near HBs (within 30 degrees) and some exceptional events occurred at non-HBs;
3) the axial fields in MCs present a similar north-south orientation, which
changes from cycle to cycle. We discuss the implication of solar cycle
variations of MFR axial orientations for space weather forecasts.",http://arxiv.org/abs/2501.03346v1
Critical-like phenomenon in scraping of jamming systems,2025-01-07T02:30:19Z,"Masaya Endo, Rei Kurita","In jamming systems like colloids, emulsions, foams, and biological tissues,
significant deformation is essential for processes such as material scraping or
wound self-healing. To adequately spread a foam or cream over a surface,
external force must be applied to artificially scrape it. The scraping of foam
using a rigid plate has been observed to exhibit complex behavior distinct from
that of simple liquids. In this study, we quantitatively analyzed the
transition between partial and slender scraping regimes by examining changes in
internal structure and partial spreading lengths. Our findings reveal that the
sequential propagation of bubble rearrangement in the foam's internal structure
leads to the partial scraping. Moreover, the scraping length in the partial
scraping regime shows divergence near the transition point, characterized by a
critical exponent of approximately 0.61. These results imply that foam scraping
is governed by directional percolation theory, supported by the agreement
between the experimentally observed critical exponent and theoretical
predictions. This research significantly advances the understanding of
macroscopic kinetics and rheological behavior in jamming systems, including
foams, colloids, emulsions, and biological tissues.",http://arxiv.org/abs/2501.03473v1
"Transitions from Composite Fermi Liquid to Moore-Read States in Weyl
  Semimetals",2025-01-07T03:38:49Z,"Jiong-Hao Wang, Yong Xu","Weyl semimetals represent a significant class of topological gapless
materials in three dimensions and have been shown to exhibit three-dimensional
quantum Hall effect. However, existing research mainly focuses on scenarios
without interactions. Recent studies suggest that the fractional quantum Hall
effect can arise in a Weyl semimetal with a one-third filled Landau level under
a magnetic field. However, it remains unclear whether more exotic states, such
as composite Fermi liquid and MooreRead states, can appear at half filling.
Here we surprisingly find the existence of composite Fermi liquid, Moore-Read
states and charge density waves in the same Weyl-orbit-based Landau level of a
Weyl semimetal and their transitions induced by varying the distance between
Weyl points. We attribute these transitions to a significant change in the
single-particle wave functions of the Landau level as the distance between Weyl
points is varied. Finally, we demonstrate that a transition from composite
Fermi liquid to Moore-Read states can be induced by tuning the direction of a
magnetic field, a process that is more experimentally accessible.",http://arxiv.org/abs/2501.03498v1
"Spectro-timing analysis of Be X-ray pulsar SMC X-2 during the 2022
  outburst",2025-01-07T07:00:53Z,"Mohammed Tobrej, Binay Rai, Manoj Ghising, Ruchi Tamang, Bikash Chandra Paul","We present broadband X-ray observations of the High Mass X-ray Binary (HMXB)
pulsar SMC X-2, using concurrent NuSTAR and NICER observations during its 2022
outburst. The source is found to be spinning with a period of 2.37281(3) s. We
confirm the existence of cyclotron resonant scattering feature (CRSF) at 31 keV
in addition to the iron emission line in the X-ray continuum of the source.
Spectral analysis performed with the physical bulk and thermal Comptonization
model indicates that the bulk Comptonization dominates the thermal
Comptonization. Using phase-resolved spectroscopy, we have investigated the
variations of the spectral parameters relative to pulse phase that may be due
to the complex structure of magnetic field of the pulsar or the impact of the
emission geometry. It is observed that the spectral parameters exhibit
significant variabilities relative to the pulsed phase. Time-resolved
spectroscopy is employed to examine the evolution of the continuum and changes
in the spectral characteristics. Measurements of luminosity along with
variations in cyclotron line energy and photon index suggest that the source
may be accreting in the super-critical regime.",http://arxiv.org/abs/2501.03576v1
"Long-distance high-precision and high-sensitivity time delay sensing
  based on fiber optic weak measurements",2025-01-07T07:32:40Z,"Wei-Qian Zhao, Zi-Fu Su, Ya-Fei Yu, Jin-Dong Wang","In fiber optic sensing, time delays induced by polarization mode dispersion
can distort signals in systems relying on phase or intensity variations for
measurement, degrading performance, especially in long distance, high-precision
applications. To address this challenge, we propose a weak measurement-based
scheme using intensity contrast ratio for high-precision, high-sensitivity
fiber optic delay estimation under large inherent time delays. We demonstrate
that a narrower light source bandwidth enhances the effective sensing distance
for high-sensitivity measurements. Our results show that, even with large
inherent time delays, the measurement precision and sensitivity remain
comparable to those of biased weak measurement, enabling detection of time
delay variations at the attosecond level, corresponding to a 25.5 Pa water
pressure change. The scheme is also robust against fiber misalignment errors,
offering a novel solution for long-distance distributed fiber-optic sensing and
broadening the applications of weak measurement techniques.",http://arxiv.org/abs/2501.03589v1
"IEEE 802.11bn Multi-AP Coordinated Spatial Reuse with Hierarchical
  Multi-Armed Bandits",2025-01-07T10:29:27Z,"Maksymilian Wojnar, Wojciech Ciezobka, Katarzyna Kosek-Szott, Krzysztof Rusek, Szymon Szott, David Nunez, Boris Bellalta","Coordination among multiple access points (APs) is integral to IEEE 802.11bn
(Wi-Fi 8) for managing contention in dense networks. This letter explores the
benefits of Coordinated Spatial Reuse (C-SR) and proposes the use of
reinforcement learning to optimize C-SR group selection. We develop a
hierarchical multi-armed bandit (MAB) framework that efficiently selects APs
for simultaneous transmissions across various network topologies, demonstrating
reinforcement learning's promise in Wi-Fi settings. Among several MAB
algorithms studied, we identify the upper confidence bound (UCB) as
particularly effective, offering rapid convergence, adaptability to changes,
and sustained performance.",http://arxiv.org/abs/2501.03680v1
"Confinement and Activity-Driven Dynamics of Semiflexible Polymers in
  Motility Assays",2025-01-07T10:33:25Z,"Sandip Roy, Anil Kumar Dasanna","We investigate the dynamics of semiflexible polymers in a motility assay,
where motor proteins (MPs) stochastically bind, unbind, and walk along the
polymer, under the influence of harmonic confinement. Using Langevin dynamics
simulations, we explore the interplay between the polymer's rigidity, activity
in the form of attachment/detachment of MPs and subsequent movement of attached
MPs, and trap strength, revealing a two-state transition from a trapped to a
free polymer, with an intermediate coexistence region. Rigidity significantly
impacts the trapping behaviour, with flexible polymers remaining trapped at the
higher activity. Attachment/detachment of MPs can also induce a change in the
effective rigidity of the polymer and, therefore, influence confinement by the
trap.The polymer undergoes spiral and open-chain conformations, with the
turning number serving as a key order parameter to quantify spiral formation.
We show that confinement stabilizes spiral structures and suppresses open-chain
motion, especially at higher activity. The centre of mass (COM) dynamics are
analyzed through the mean square displacement (MSD), showing diffusive,
ballistic, and diffusive regimes that depend on the trap strength and activity.
Negative excess kurtosis indicates nonequilibrium behaviour, which saturates
with increasing confinement, reflecting the dominance of the trap over the
activity.",http://arxiv.org/abs/2501.03686v1
"Foliated Asymptotically Safe Gravity -- Lorentzian Signature
  Fluctuations from the Wick Rotation",2025-01-07T12:48:08Z,"Frank Saueressig, Jian Wang","Asymptotic Safety constitutes a promising mechanism for a consistent and
predictive high-energy completion of the gravitational interactions. To date,
most results on the interacting renormalization group fixed point underlying
the construction are obtained for Euclidean signature spacetimes. In this work,
we use the Arnowitt-Deser-Misner (ADM) decomposition of the metric degrees of
freedom and investigate the relations between the Euclidean and Lorentzian
renormalization group flows resulting from the analytic continuation of the
lapse function. We discuss the general conditions which guarantee the
equivalence of the beta functions. These insights are illustrated based on the
flow of the graviton two-point function within the Einstein-Hilbert truncation,
demonstrating agreement of the Euclidean and Lorentzian settings. Hence the UV-
and IR-completions identified in the Euclidean case are robust when changing
spacetime signature. We take this as an important indicator that the Euclidean
asymptotic safety mechanism carries over to Lorentzian signature spacetimes.",http://arxiv.org/abs/2501.03752v1
"Investigation of bremsstrahlung emission in an electron cyclotron
  resonance ion source and its dependence on the magnetic confinement",2025-01-07T13:39:21Z,"Andrea Cernuschi, Thomas Thuillier","A Monte Carlo (MC) code is used to investigate the bremsstrahlung x-ray
emission of an electron cyclotron resonance ion source (ECRIS) and its
dependence on the axial magnetic confinement. The x-ray spectral temperature Ts
measured with the simulations is in fair agreement with previous experiments.
The dependence of Ts on the minimum magnetic field of the configuration Bmin is
corroborated, also observing that the ion extraction peak field Bext has no
influence on temperature. Details on the mechanism generating the hot electron
population responsible for the change in spectral x-ray temperature as a
function of Bmin are proposed, based on an in-depth investigation of the
electron population with the MC code using a high statistics.",http://arxiv.org/abs/2501.03779v1
Dynamical space-time ray tracing and modified horizontal ray method,2025-01-07T15:14:26Z,"Aleksandr Kaplun, Boris Katsnelson","The 'vertical modes and horizontal rays' method, commonly applied for
simulating acoustic wave propagation in shallow water is advanced in this
research. Our approach to this method involves the use of the so-called
space-time rays, which are constructed by decomposing the time-dependent sound
field into adiabatic vertical modes, the solutions to the Sturm-Liouville
problem. The introduction of the time coordinate, while still considering it as
an additional space coordinate instead of merely a parameter along the ray,
allows us to describe the propagation of frequency-modulated signals in an
effectively frequency-dispersive medium. The consideration of the extension of
Hamiltonian ray-tracing methods (also used for the description of Gaussian
beams and so-called quasiphotons) leads to a simple description of observable
effects such as changes in modulation, time compression, differences between
angles of phase and amplitude fronts, space-time caustics, etc., in dynamics -
on the moving line or at some point of observation while having the general
form of the source (for example, also a moving one).",http://arxiv.org/abs/2501.03856v1
Progressive Document-level Text Simplification via Large Language Models,2025-01-07T15:14:37Z,"Dengzhao Fang, Jipeng Qiang, Yi Zhu, Yunhao Yuan, Wei Li, Yan Liu","Research on text simplification has primarily focused on lexical and
sentence-level changes. Long document-level simplification (DS) is still
relatively unexplored. Large Language Models (LLMs), like ChatGPT, have
excelled in many natural language processing tasks. However, their performance
on DS tasks is unsatisfactory, as they often treat DS as merely document
summarization. For the DS task, the generated long sequences not only must
maintain consistency with the original document throughout, but complete
moderate simplification operations encompassing discourses, sentences, and
word-level simplifications. Human editors employ a hierarchical complexity
simplification strategy to simplify documents. This study delves into
simulating this strategy through the utilization of a multi-stage collaboration
using LLMs. We propose a progressive simplification method (ProgDS) by
hierarchically decomposing the task, including the discourse-level,
topic-level, and lexical-level simplification. Experimental results demonstrate
that ProgDS significantly outperforms existing smaller models or direct
prompting with LLMs, advancing the state-of-the-art in the document
simplification task.",http://arxiv.org/abs/2501.03857v1
Effective textures from a $[SU(3)]^3$ flavored scalar sector,2025-01-07T15:36:46Z,"A. Carrillo-Monteverde, R. Escorcia Ramírez, S. Gómez-Ávila, L. Lopez-Lozano","Current constraints on flavor-changing neutral currents (FCNCs) strongly
indicate that any new physics emerging at the 1-10 TeV scale must adhere to the
Minimal Flavor Violation (MFV) principle, where Yukawa couplings are the sole
sources of flavor violation. In this work, we present a model inspired by a
gauged $SU(3)$ flavor symmetry that dynamically generates leptonic Yukawa
matrices through effective operators. The model incorporates a scalar sector
with two sets of flavons, characterized by their vacuum expectation values
(VEVs), which govern the suppression scale of the Yukawa couplings and the
hierarchy of neutrino masses. By leveraging phenomenologically viable Yukawa
textures, we derive restrictions on the flavon VEVs and demonstrate the
compatibility of the model with experimental neutrino oscillation data.
Furthermore, the model predicts at least one neutrino mass to be strongly
suppressed, consistent with the normal mass ordering and experimental upper
bounds. This framework provides a robust mechanism for dynamically generating
neutrino masses and mixing while addressing key challenges in leptonic flavor
physics, such as FCNC suppression and CP-violating phases.",http://arxiv.org/abs/2501.03872v1
"An obstruction to small-time local controllability for a bilinear
  Schrödinger equation",2025-01-07T15:44:16Z,"Karine Beauchard, Frédéric Marbach, Thomas Perrin","We consider the small-time local controllability in the vicinity of the
ground state of a bilinear Schr\""odinger equation with Neumann boundary
conditions. We prove that, when the linearized system is not controllable, the
nonlinear system is not controllable, due to a quadratic obstruction involving
the squared norm of the control's primitive. This obstruction has been known
since 1983 for ODEs and observed for some PDEs since 2006. However, our
situation is more intricate since the kernel describing the quadratic expansion
of the solution is not twice differentiable. We thus follow a Fourier-based
approach, closer to the one used for quadratic obstructions of fractional
Sobolev regularity.
  In this Fourier-based approach, a challenge is to formulate a necessary and
sufficient condition on the convolution kernel, for the quadratic form to be
coercive. In previous studies, the coercivity was ensured by a signed
asymptotic equivalent for the Fourier transform of the convolution kernel of
the form $\widehat{K}(\omega) \sim \omega^{-2}$ as $|\omega| \to \infty$. In
our case, $\widehat{K}$ is a distribution which has singularities and changes
sign up to infinity. We still prove coercivity because one of the signs appears
too infrequently.",http://arxiv.org/abs/2501.03882v1
Origin of ion bombardment induced Tb oxidation in Tb/Co multilayers,2025-01-07T16:06:24Z,"Daniel Kiphart, Michal Krupinski, Marzena Mitura-Nowak, Pawel Piotr Michalowski, Mateusz Kowacz, Marek Schmidt, Feliks Stobiecki, Gabriel David Chaves-O'Flynn, Piotr Kuswik","Ion bombardment is currently an active area of research for patterning rare
earth/transition metal ferrimagnetic thin films because the magnetic properties
are extremely sensitive to changes in the constituent sublattices. It has
previously been shown that ion bombardment can be used to deliberately reduce
the contribution of the rare earth sublattice in rare earth/transition metal
ferrimagnets by selective oxidation. However, the exact mechanism by which
oxidation occurs remains an outstanding question. We show that the defects
introduced by ion bombardment of Tb/Co multilayers using different ion species
with projected range (i.e., 10 keV He + , 15 keV O + , and 30 keV Ga +) create
easy diffusion paths for oxygen to penetrate the system. The choice of ion
species and fluence enables the effective composition of the films to be
tailored by reducing the amount of magnetically-active Tb.",http://arxiv.org/abs/2501.03899v1
"Optical absorption and luminescence of $α$-LiV$_2$O$_5$ from the
  Bethe Salpeter Equation",2025-01-07T16:31:16Z,"Claudio Garcia, Walter R. L. Lambrecht","$\alpha$-Li$_x$V$_2$O$_5$ is obtained by intercalating Li between the layers
of V$_2$O$_5$. The partial filling of the split-off conduction band by electron
donation from Li leads to significant changes in optical properties. Here we
study the electronic band structure of $\alpha$-LiV$_2$O$_5$ using
quasiparticle self-consistent (QS) $GW$ calculations and the optical dielectric
function by means of the Bethe Salpeter equation. We find a very strong optical
absorption band related to transitions between the filled V-$d_{xy}$ like
states to the empty ones with strong polarization along the $a$-direction. We
relate this to recent experimental observations of cathodoluminescence (CL) in
which a supression of the CL was observed upon addition of Li.",http://arxiv.org/abs/2501.03917v2
Thermally Adaptive Surface Microscopy for brain functional imaging,2025-01-07T18:00:48Z,"Hadrien L. M. Robert, Giulia Faini, Chang F. Liu, Nadja Rutz, Anis Aggoun, Elena Putti, Jose Garcia-Guirado, Filippo Del Bene, Romain Quidant, Gilles Tessier, Pascal Berto","Fluorescence microscopes can record the dynamics of living cells with high
spatio-temporal resolution in a single plane. However, monitoring rapid and dim
fluorescence fluctuations, e.g induced by neuronal activity in the brain,
remains challenging for 3D-distributed emitters due to out-of-focus
fluorescence background, a restricted photon budget, and the speed limit of
conventional scanning systems. Here, we introduce a Thermally Adaptive Surface
strategy, capable of simultaneously recording, at camera framerate, the
activity of 3D-distributed objects. This innovative microscope leverages on an
array of thermally tuneable microlenses that offer low chromatic aberration and
high transmission, and can be combined with patterned illumination to provide
optical sectioning. We demonstrate its potential in vivo, by simultaneously
monitoring fast fluorescent dynamics at different depths in the zebrafish
larval brain, at a rate of 0.5 kHz and over a large field of view (360um x
360um).",http://arxiv.org/abs/2501.03965v1
Impact of Leg Stiffness on Energy Efficiency in One Legged Hopping,2025-01-07T18:22:23Z,"Iskandar Khemakhem, Dominik Tschemernjak, Maximilian Raff, C. David Remy","In the fields of robotics and biomechanics, the integration of elastic
elements such as springs and tendons in legged systems has long been recognized
for enabling energy-efficient locomotion. Yet, a significant challenge
persists: designing a robotic leg that perform consistently across diverse
operating conditions, especially varying average forward speeds. It remains
unclear whether, for such a range of operating conditions, the stiffness of the
elastic elements needs to be varied or if a similar performance can be obtained
by changing the motion and actuation while keeping the stiffness fixed. This
work explores the influence of the leg stiffness on the energy efficiency of a
monopedal robot through an extensive parametric study of its periodic hopping
motion. To this end, we formulate an optimal control problem parameterized by
average forward speed and leg stiffness, solving it numerically using direct
collocation. Our findings indicate that, compared to the use of a fixed
stiffness, employing variable stiffness in legged systems improves energy
efficiency by 20 % maximally and by 6.8 % on average across a range of speeds.",http://arxiv.org/abs/2501.03971v1
Towards reconstruction of finite tensor categories,2025-01-07T18:44:15Z,"Mitchell Jubeir, Zhenghan Wang","We take a first step towards a reconstruction of finite tensor categories
using finitely many $F$-matrices. The goal is to reconstruct a finite tensor
category from its projective ideal. Here we set up the framework for an
important concrete example--the $8$-dimensional Nicholas Hopf algebra $K_2$. Of
particular importance is to determine its Green ring and tensor ideals. The
Hopf algebra $K_2$ allows the recovery of $(2+1)$-dimensional Seiberg-Witten
TQFT from Hennings TQFT based on $K_2$. This powerful result convinced us that
it is interesting to study the Green ring of $K_2$ and its tensor ideals in
more detail. Our results clearly illustrate the difficulties arisen from the
proliferation of non-projective reducible indecomposable objects in finite
tensor categories.",http://arxiv.org/abs/2501.03987v2
Axion misalignment with memory-burdened PBH,2025-01-07T19:00:00Z,"Disha Bandyopadhyay, Debasish Borah, Nayan Das","We study the possibility of producing axion dark matter (DM) via misalignment
mechanisms in a non-standard cosmological era dominated by ultra-light
primordial black holes (PBH). While the effect of PBH domination on the
production of axion via vacuum misalignment is known assuming the PBH
evaporation to proceed according to Hawking's semi-classical (SC)
approximation, we go beyond these simplest possibilities to include kinetic
misalignment of axion and backreaction effect of emitted particles on the PBH
themselves, referred to as the memory-burden (MB) effect. We show that,
depending upon the type of misalignment mechanism and PBH evaporation regime,
the axion as well as PBH parameter space consistent with the observed DM relic
changes significantly having interesting implications for axion detection
experiments. PBH also offer complementary detection prospects via gravitational
wave due to PBH density fluctuations and excess radiation due to emission of
hot axions within reach of future cosmic microwave background experiments.",http://arxiv.org/abs/2501.04076v1
Comparison of STR and EMLSR Performance in Wi-Fi 7 MLO,2025-01-07T21:33:42Z,"Aishwarya Choorakuzhiyil, Kevin Ho, Sara Reyes","This project compares the performance of simultaneous transmit and receive
(STR) and enhanced multi-link single radio (EMLSR) within Multi-Link Operation
(MLO) in Wi-Fi 7 networks. Using the ns-3 simulator, we evaluate both
techniques under various scenarios, including changes in modulation coding
scheme (MCS), bandwidth, link quality, and interference levels. Key performance
metrics such as latency, throughput, and energy efficiency are analyzed to
determine the trade-offs between STR and EMLSR. The results demonstrate that
STR achieves higher throughput and lower latency due to dual-link utilization,
making it suitable for high-load environments. In contrast, EMLSR balances
energy efficiency with responsiveness, making it advantageous for
power-sensitive applications. This analysis provides insights into the
strengths and limitations of STR and EMLSR, guiding optimal deployment
strategies for future Wi-Fi 7 networks.",http://arxiv.org/abs/2501.04149v1
"Efficient LP warmstarting for linear modifications of the constraint
  matrix",2025-01-07T21:37:41Z,"Guillaume Derval, Bardhyl Miftari, Damien Ernst, Quentin Louveaux","We consider the problem of computing the optimal solution and objective of a
linear program under linearly changing linear constraints. More specifically,
we want to compute the optimal solution of a linear optimization where the
constraint matrix linearly depends on a paramater that can take p different
values. Based on the information given by a precomputed basis, we present three
efficient LP warm-starting algorithms. Each algorithm is either based on the
eigenvalue decomposition, the Schur decomposition, or a tweaked eigenvalue
decomposition to evaluate the optimal solution and optimal objective of these
problems. The three algorithms have an overall complexity O(m^3 + pm^2) where m
is the number of constraints of the original problem and p the number of values
of the parameter that we want to evaluate. We also provide theorems related to
the optimality conditions to verify when a basis is still optimal and a local
bound on the objective.",http://arxiv.org/abs/2501.04151v1
"Tilted chiral spin textures in confined nanostructures with in-plane
  magnetic anisotropy",2025-01-08T01:58:08Z,"Wenlei Fu, Haiming Dong, Kai Chang","We demonstrate that nanoconfinement effects and in-plane magnetic anisotropy
(IMA) can lead to tilted chiral spin textures in magnetic nanostructures, based
on the analysis and simulation of theoretical models of micromagnetism. The
tilted skyrmions are induced in confined nanoscale magnets with IMA under
perpendicular magnetic fields. The chiral magnetic structures depend
significantly on the size of the nanostructures. A controlled string of
periodic skyrmion states emerges within the central magnetic domain wall, which
can be tuned by the steady magnetic fields and the size of the nanostructures.
Non-trivial topological states with non-integer topological charges are
achieved by tuning the magnetic fields or the sizes of the nanostructures.
Importantly, the periodic switching between the trivial and the non-trivial
topological configurations is realized using an alternating magnetic field. Our
study reveals an important mechanism for controlling novel skyrmion states via
nanoconfinement effects and the IMA in magnetic nanostructures, and also
provides a new approach for the development of magnetic field-modulated spin
nanodevices.",http://arxiv.org/abs/2501.04226v1
"Beam Domain Channel Estimation for Spatial Non-Stationary Massive MIMO
  Systems",2025-01-08T02:47:07Z,"Lin Hou, Hengtai Chang, Cheng-Xiang Wang, Jie Huang, Songjiang Yang","In massive multiple-input multiple-output (MIMO) systems, the channel
estimation scheme is subject to the spatial non-stationarity and inevitably
power leakage in the beam domain. In this paper, a beam domain channel
estimation scheme is investigated for spatial non-stationary (SNS) massive MIMO
systems considering power leakage. %a novel beam domain channel estimation
scheme is proposed for spatial non-stationary (SNS) massive MIMO systems.
Specifically, a realistic massive MIMO beam domain channel model (BDCM) is
introduced to capture the spatial non-stationarity considering power leakage by
introducing the illustration of visibility region (VR). Then, a beam domain
structure-based sparsity adaptive matching pursuit (BDS-SAMP) scheme is
proposed based on the cross-block sparse structure and power ratio threshold of
beam domain channel. Finally, the simulation results validate the accuracy of
proposed BDS-SAMP scheme with low pilot overhead and reasonable complexity by
comparing with conventional schemes.",http://arxiv.org/abs/2501.04242v1
"Defect Phonon Renormalization during Nonradiative Multiphonon
  Transitions in Semiconductors",2025-01-08T05:27:24Z,"Junjie Zhou, Shanshan Wang, Menglin Huang, Xin-Gao Gong, Shiyou Chen","As a typical nonradiative multiphonon transition in semiconductors, carrier
capture at defects is critical to the performance of semiconductor devices. Its
transition rate is usually calculated using the equal-mode approximation, which
assumes that phonon modes and frequencies remain unchanged before and after the
transition. Using the carbon substitutional defect ($\text{C}_\text{N}$) in GaN
as a benchmark, here we demonstrate that the phonon renormalization can be
significant during defect relaxation, which causes errors as large as orders of
magnitude in the approximation. To address this issue, we consider (i)
Duschinsky matrix connecting the initial-state and final-state phonons, which
accounts for the changes in phonon modes and frequencies; and (ii) the
off-diagonal contributions in total transition matrix element, which
incorporates the cross terms of electron-phonon interactions between different
modes. With this improvement, the calculated transition rates show agreements
with experimental results within an order of magnitude. We believe the present
method makes one step forward for the accurate calculation of multiphonon
transition rate, especially in cases with large defect relaxations.",http://arxiv.org/abs/2501.04289v1
"Who Does the Giant Number Pile Like Best: Analyzing Fairness in Hiring
  Contexts",2025-01-08T07:28:10Z,"Preethi Seshadri, Seraphina Goldfarb-Tarrant","Large language models (LLMs) are increasingly being deployed in high-stakes
applications like hiring, yet their potential for unfair decision-making and
outcomes remains understudied, particularly in generative settings. In this
work, we examine the fairness of LLM-based hiring systems through two
real-world tasks: resume summarization and retrieval. By constructing a
synthetic resume dataset and curating job postings, we investigate whether
model behavior differs across demographic groups and is sensitive to
demographic perturbations. Our findings reveal that race-based differences
appear in approximately 10% of generated summaries, while gender-based
differences occur in only 1%. In the retrieval setting, all evaluated models
display non-uniform selection patterns across demographic groups and exhibit
high sensitivity to both gender and race-based perturbations. Surprisingly,
retrieval models demonstrate comparable sensitivity to non-demographic changes,
suggesting that fairness issues may stem, in part, from general brittleness
issues. Overall, our results indicate that LLM-based hiring systems, especially
at the retrieval stage, can exhibit notable biases that lead to discriminatory
outcomes in real-world contexts.",http://arxiv.org/abs/2501.04316v1
"The probability for chiral oscillation of Majorana neutrino in Quantum
  Field Theory",2025-01-08T07:34:46Z,"Takuya Morozumi, Tomoharu Tahara","We derive the probability for chiral oscillation of Majorana neutrinos based
on quantum field theory. Since the Hamiltonian under the Majorana mass term
does not conserve lepton number, the eigenstates of lepton number change
continuously over time. Therefore, the transition amplitude is described by the
inner product of the eigenstates of lepton number at the time of the neutrino
production and the detection. With the Bogoliubov transformation, we
successfully relates the lepton number eigenstates at different times. This
method enables us to understand the time variation of lepton number induced by
chiral oscillations in terms of transition probabilities. We also present the
physical picture that emerges through the Bogoliubov transformation.",http://arxiv.org/abs/2501.04320v1
Tracking UWB Devices Through Radio Frequency Fingerprinting Is Possible,2025-01-08T10:29:35Z,"Thibaud Ardoin, Niklas Pauli, Benedikt Groß, Mahsa Kholghi, Khan Reaz, Gerhard Wunder","Ultra-wideband (UWB) is a state-of-the-art technology designed for
applications requiring centimeter-level localization. Its widespread adoption
by smartphone manufacturer naturally raises security and privacy concerns.
Successfully implementing Radio Frequency Fingerprinting (RFF) to UWB could
enable physical layer security, but might also allow undesired tracking of the
devices. The scope of this paper is to explore the feasibility of applying RFF
to UWB and investigates how well this technique generalizes across different
environments. We collected a realistic dataset using off-the-shelf UWB devices
with controlled variation in device positioning. Moreover, we developed an
improved deep learning pipeline to extract the hardware signature from the
signal data. In stable conditions, the extracted RFF achieves over 99%
accuracy. While the accuracy decreases in more changing environments, we still
obtain up to 76% accuracy in untrained locations.",http://arxiv.org/abs/2501.04401v1
"AI-assisted design of experiments at the frontiers of computation:
  methods and new perspectives",2025-01-08T11:58:31Z,Pietro Vischia,"Designing the next generation colliders and detectors involves solving
optimization problems in high-dimensional spaces where the optimal solutions
may nest in regions that even a team of expert humans would not explore.
  Resorting to Artificial Intelligence to assist the experimental design
introduces however significant computational challenges in terms of generation
and processing of the data required to perform such optimizations: from the
software point of view, differentiable programming makes the exploration of
such spaces with gradient descent feasible; from the hardware point of view,
the complexity of the resulting models and their optimization is prohibitive.
To scale up to the complexity of the typical HEP collider experiment, a change
in paradigma is required.
  In this contribution I will describe the first proofs-of-concept of
gradient-based optimization of experimental design and implementations in
neuromorphic hardware architectures, paving the way to more complex challenges.",http://arxiv.org/abs/2501.04448v1
"ART: Distribution-Free and Model-Agnostic Changepoint Detection with
  Finite-Sample Guarantees",2025-01-08T12:57:09Z,"Xiaolong Cui, Haoyu Geng, Guanghui Wang, Zhaojun Wang, Changliang Zou","We introduce ART, a distribution-free and model-agnostic framework for
changepoint detection that provides finite-sample guarantees. ART transforms
independent observations into real-valued scores via a symmetric function,
ensuring exchangeability in the absence of changepoints. These scores are then
ranked and aggregated to detect distributional changes. The resulting test
offers exact Type-I error control, agnostic to specific distributional or model
assumptions. Moreover, ART seamlessly extends to multi-scale settings, enabling
robust multiple changepoint estimation and post-detection inference with
finite-sample error rate control. By locally ranking the scores and performing
aggregations across multiple prespecified intervals, ART identifies changepoint
intervals and refines subsequent inference while maintaining its
distribution-free and model-agnostic nature. This adaptability makes ART as a
reliable and versatile tool for modern changepoint analysis, particularly in
high-dimensional data contexts and applications leveraging machine learning
methods.",http://arxiv.org/abs/2501.04475v1
"Towards a Problem-Oriented Domain Adaptation Framework for Machine
  Learning",2025-01-08T14:19:54Z,"Philipp Spitzer, Dominik Martin, Laurin Eichberger, Niklas Kühl","Domain adaptation is a sub-field of machine learning that involves
transferring knowledge from a source domain to perform the same task in the
target domain. It is a typical challenge in machine learning that arises, e.g.,
when data is obtained from various sources or when using a data basis that
changes over time. Recent advances in the field offer promising methods, but it
is still challenging for researchers and practitioners to determine if domain
adaptation is suitable for a given problem -- and, subsequently, to select the
appropriate approach. This article employs design science research to develop a
problem-oriented framework for domain adaptation, which is matured in three
evaluation episodes. We describe a framework that distinguishes between five
domain adaptation scenarios, provides recommendations for addressing each
scenario, and offers guidelines for determining if a problem falls into one of
these scenarios. During the multiple evaluation episodes, the framework is
tested on artificial and real-world datasets and an experimental study
involving 100 participants. The evaluation demonstrates that the framework has
the explanatory power to capture any domain adaptation problem effectively. In
summary, we provide clear guidance for researchers and practitioners who want
to employ domain adaptation but lack in-depth knowledge of the possibilities.",http://arxiv.org/abs/2501.04528v1
"The MBTA Pipeline for Detecting Compact Binary Coalescences in the
  Fourth LIGO-Virgo-KAGRA Observing Run",2025-01-08T16:26:46Z,"Christopher Alléné, Florian Aubin, Inès Bentara, Damir Buskulic, Gianluca M Guidi, Vincent Juste, Morgan Lethuillier, Frédérique Marion, Lorenzo Mobilia, Benoît Mours, Amazigh Ouzriat, Thomas Sainrat, Viola Sordini","In this paper, we describe the Multi-Band Template Analysis (MBTA) search
pipeline dedicated to the detection of compact binary coalescence (CBC)
gravitational wave signals from the data obtained by the LIGO-Virgo-KAGRA
collaboration (LVK) during the fourth observing run (O4), which started in May
2023. We give details on the configuration of the pipeline and its evolution
compared to the third observing run (O3). We focus here on the configuration
used for the offline results of the first part of the run (O4a), which are part
of the GWTC-4 catalog (in preparation). We also give a brief summary of the
online configuration and highlight some of the changes implemented or
considered for the second part of O4 (O4b).",http://arxiv.org/abs/2501.04598v1
"Leveraging Log Probabilities in Language Models to Forecast Future
  Events",2025-01-08T23:28:28Z,"Tommaso Soru, Jim Marshall","In the constantly changing field of data-driven decision making, accurately
predicting future events is crucial for strategic planning in various sectors.
The emergence of Large Language Models (LLMs) marks a significant advancement
in this area, offering advanced tools that utilise extensive text data for
prediction. In this industry paper, we introduce a novel method for AI-driven
foresight using LLMs. Building on top of previous research, we employ data on
current trends and their trajectories for generating forecasts on 15 different
topics. Subsequently, we estimate their probabilities via a multi-step approach
based on log probabilities. We show we achieve a Brier score of 0.186, meaning
a +26% improvement over random chance and a +19% improvement over
widely-available AI systems.",http://arxiv.org/abs/2501.04880v1
Beyond Life: A Digital Will Solution for Posthumous Data Management,2025-01-09T01:25:13Z,"Xinzhang Chen, Arash Shaghaghi, Jesse Laeuchli, Salil Kanhere","In the digital era, managing posthumous data presents a growing challenge,
with current technical solutions often falling short in practicality. Existing
tools are typically closed-source, lack transparency, fail to offer
cross-platform support, and provide limited access control. This paper
introduces `Beyond Life', a cross-platform digital will management solution
designed to securely handle and distribute digital assets after death. At the
core of this solution is a customized Ciphertext-Policy Attribute-Based
Encryption (CP-ABE) scheme, referred to as PD-CP-ABE, which enables efficient,
fine-grained control over access to will content at scale. Unlike existing
systems, Beyond Life operates independently of service providers, offering
users greater transparency and control over how their will is generated,
stored, and executed. The system is also designed to be portable, allowing
users to change their will service provider. The proposed system has been fully
developed and rigorously evaluated to ensure performance and real-world
feasibility. The system implementation is made publicly available.",http://arxiv.org/abs/2501.04900v2
"Theoretical study of the Spectroscopic measurements of Kerr non-linear
  resonators with four-body interaction",2025-01-09T05:43:57Z,"Yuichiro Matsuzaki, Yuichiro Mori, Aiko Yamaguchi, Yohei Kawakami, Tsuyoshi Yamamoto","Quantum annealing provides a promising way to solve combinational
optimization problems where the solutions correspond to the ground state of the
Ising Hamiltonian. We can implement quantum annealing using the Kerr non-linear
resonators, with bifurcation phenomena emerging when subjected to a parametric
drive. These bifurcated states can function as bases of qubits. Moreover,
integrating four-body interactions between physical qubits enables the
establishment of effective all-to-all long-range interactions between logical
qubits, which is essential for practical quantum annealing. While theoretical
proposals exist for creating four-body interactions within Kerr non-linear
resonators, there has not been experimental verification through their
spectroscopic signatures. In this paper, we theoretically investigate the
spectroscopic measurements of Kerr non-linear resonators featuring four-body
interaction. We identify six distinct frequencies exhibiting population changes
by employing resonant driving on one resonator and weak driving on another.
Analytical and numerical calculations validate these findings. Our study
demonstrates the potential of spectroscopy in characterizing systems with
four-body interactions, offering insights for realizing quantum annealing with
Kerr parametric oscillators.",http://arxiv.org/abs/2501.04981v1
"Continuous Knowledge-Preserving Decomposition for Few-Shot Continual
  Learning",2025-01-09T07:18:48Z,"Xiaojie Li, Yibo Yang, Jianlong Wu, David A. Clifton, Yue Yu, Bernard Ghanem, Min Zhang","Few-shot class-incremental learning (FSCIL) involves learning new classes
from limited data while retaining prior knowledge, and often results in
catastrophic forgetting. Existing methods either freeze backbone networks to
preserve knowledge, which limits adaptability, or rely on additional modules or
prompts, introducing inference overhead. To this end, we propose Continuous
Knowledge-Preserving Decomposition for FSCIL (CKPD-FSCIL), a framework that
decomposes a model's weights into two parts: one that compacts existing
knowledge (knowledge-sensitive components) and another that carries redundant
capacity to accommodate new abilities (redundant-capacity components). The
decomposition is guided by a covariance matrix from replay samples, ensuring
principal components align with classification abilities. During adaptation, we
freeze the knowledge-sensitive components and only adapt the redundant-capacity
components, fostering plasticity while minimizing interference without changing
the architecture or increasing overhead. Additionally, CKPD introduces an
adaptive layer selection strategy to identify layers with redundant capacity,
dynamically allocating adapters. Experiments on multiple benchmarks show that
CKPD-FSCIL outperforms state-of-the-art methods.",http://arxiv.org/abs/2501.05017v1
"Perception-as-Control: Fine-grained Controllable Image Animation with
  3D-aware Motion Representation",2025-01-09T07:23:48Z,"Yingjie Chen, Yifang Men, Yuan Yao, Miaomiao Cui, Liefeng Bo","Motion-controllable image animation is a fundamental task with a wide range
of potential applications. Recent works have made progress in controlling
camera or object motion via various motion representations, while they still
struggle to support collaborative camera and object motion control with
adaptive control granularity. To this end, we introduce 3D-aware motion
representation and propose an image animation framework, called
Perception-as-Control, to achieve fine-grained collaborative motion control.
Specifically, we construct 3D-aware motion representation from a reference
image, manipulate it based on interpreted user intentions, and perceive it from
different viewpoints. In this way, camera and object motions are transformed
into intuitive, consistent visual changes. Then, the proposed framework
leverages the perception results as motion control signals, enabling it to
support various motion-related video synthesis tasks in a unified and flexible
way. Experiments demonstrate the superiority of the proposed framework. For
more details and qualitative results, please refer to our project webpage:
https://chen-yingjie.github.io/projects/Perception-as-Control.",http://arxiv.org/abs/2501.05020v1
"Rudin Inequality, Chang Theorem, primes and squares",2025-01-09T08:25:22Z,Olivier Ramaré,"We prove that the set of large values of the trigonometric polynomial over a
subset of density of the primes has some additive structure, similarly to what
happens for subsets of densities in $\mathbb{Z}/{N}\mathbb{Z}$ but in a weaker
form. To do so, we prove large sieve inequalities for \emph{dissociate sets}
$\mathcal{X}$ of circle points and functions $f$ whose support~$S$ is finite
and respectively in an interval, in the set of primes or in the set of squares.
Set $T(f,x)=\sum_{n}f(n)\exp(2i\pi nx)$. These inequalities are of the shape
$\sum_{x\in\mathcal{X}}|T(f,x)|^2\ll |S|\|f\|_2^2\log(8R/|S|)$ where $R$ is
respectively $N$, $N/\log N$ and $\sqrt{N}$. The implied constants depend on
the spacement between sumsets of~$\mathcal{X}$.",http://arxiv.org/abs/2501.05056v1
"Improving signal-to-noise ratios in pump-probe spectroscopy on
  light-sensitive samples by adapting pulse repetition rates",2025-01-09T10:24:29Z,"Matthias C. Velsink, Maksym Illienko, Komal Chaudhary, Stefan Witte","Ultrafast optical pump-probe spectroscopy is a powerful tool to study
dynamics in solid materials on femto- and picosecond timescales. In such
experiments, a pump pulse induces dynamics inside a sample by impulsive
light-matter interaction, resulting in dynamics that can be detected using a
time-delayed probe pulse. In addition to the desired dynamics, the initial
interaction may also lead to unwanted effects that may result in irreversible
changes and even damage. Therefore, the achievable signal strength is often
limited by the pumping conditions that a sample can sustain. Here we
investigate the optimization of ultrafast photoacoustics in various solid thin
films. We perform systematic experiments aimed at maximizing the achievable
signal-to-noise (SNR) ratio in a given measurement time while limiting sample
damage. By varying pump and probe pulse energies, average pump fluence, and
repetition rate, we identify different paths towards optimal SNR depending on
material properties. Our results provide a strategy for the design of
pump-probe experiments, to optimize achievable SNR for samples in which
different damage mechanisms may dominate.",http://arxiv.org/abs/2501.05121v1
Frustration Induced Chimeras and Motion in Two Dimensional Swarmalators,2025-01-09T10:39:53Z,"R. Senthamizhan, R. Gopal, V. K. Chandrasekar","Swarmalators are phase oscillators capable of simultaneous swarming and
synchronization, making them potential candidates for replicating complex
dynamical states. In this work, we explore the effects of a frustration
parameter in the phase interaction functions of a two-dimensional swarmalator
model inspired by the solvable Sakaguchi-swarmalators that move in a
one-dimensional ring. The impact of the frustration parameter in these models
has been a topic of great interest. Real-world coupled systems with frustration
exhibit remarkable collective dynamical states, underscoring the relevance of
this study. The frustration parameter induces various states exhibiting
non-stationarity, chimeric clustering, and global translational motion, where
swarmalators move spontaneously in two-dimensional space. We investigate the
characteristics of these states and their responses to changes in the
frustration parameter. Notably, the emergence of chimeric states suggests the
crucial role of non-stationarity in phase interactions for spontaneous
population clustering. Additionally, we examine how phase non-stationarity
influences the spatial positions of swarmalators and provide a classification
of these states based on different order parameters.",http://arxiv.org/abs/2501.05135v1
Polymorphism and Magnetism in a Kitaev Honeycomb Cobaltate KCoAsO$_4$,2025-01-09T10:53:23Z,"Yuya Haraguchi, Daisuke-Nishio Hamane, Hiroko Aruga Katori","We report the synthesis, crystal structure, and magnetic properties of a new
Kitaev honeycomb cobaltate, KCoAsO$_4$, which crystallizes in two distinct
forms: $P2/c$ and $R\bar{3}$ space groups. Magnetic measurements reveal
ordering temperatures of $\sim$14 K for the $P2/c$ structure and $\sim$10.5 K
for the $R\bar{3}$ structure. The $P2/c$-type KCoAsO$_4$ sample exhibits a
complex temperature-field phase diagram, including a field-induced phase, while
the $R\bar{3}$-type KCoAsO$_4$ shows a simpler phase diagram with a single
magnetically ordered phase. The observed differences in magnetic properties are
attributed to subtle structural variations, strongly suggesting that local
structural changes play a crucial role in determining the magnetism of
cobaltate-based Kitaev materials.",http://arxiv.org/abs/2501.05146v1
Explainable AI based System for Supply Air Temperature Forecast,2025-01-09T11:36:29Z,"Marika Eik, Ahmet Kose, Hossein Nourollahi Hokmabad, Juri Belikov","This paper explores the application of Explainable AI (XAI) techniques to
improve the transparency and understanding of predictive models in control of
automated supply air temperature (ASAT) of Air Handling Unit (AHU). The study
focuses on forecasting of ASAT using a linear regression with Huber loss.
However, having only a control curve without semantic and/or physical
explanation is often not enough. The present study employs one of the XAI
methods: Shapley values, which allows to reveal the reasoning and highlight the
contribution of each feature to the final ASAT forecast. In comparison to other
XAI methods, Shapley values have solid mathematical background, resulting in
interpretation transparency. The study demonstrates the contrastive
explanations--slices, for each control value of ASAT, which makes it possible
to give the client objective justifications for curve changes.",http://arxiv.org/abs/2501.05163v1
"CoDe: Communication Delay-Tolerant Multi-Agent Collaboration via Dual
  Alignment of Intent and Timeliness",2025-01-09T12:57:41Z,"Shoucheng Song, Youfang Lin, Sheng Han, Chang Yao, Hao Wu, Shuo Wang, Kai Lv","Communication has been widely employed to enhance multi-agent collaboration.
Previous research has typically assumed delay-free communication, a strong
assumption that is challenging to meet in practice. However, real-world agents
suffer from channel delays, receiving messages sent at different time points,
termed {\it{Asynchronous Communication}}, leading to cognitive biases and
breakdowns in collaboration. This paper first defines two communication delay
settings in MARL and emphasizes their harm to collaboration. To handle the
above delays, this paper proposes a novel framework, Communication
Delay-tolerant Multi-Agent Collaboration (CoDe). At first, CoDe learns an
intent representation as messages through future action inference, reflecting
the stable future behavioral trends of the agents. Then, CoDe devises a dual
alignment mechanism of intent and timeliness to strengthen the fusion process
of asynchronous messages. In this way, agents can extract the long-term intent
of others, even from delayed messages, and selectively utilize the most recent
messages that are relevant to their intent. Experimental results demonstrate
that CoDe outperforms baseline algorithms in three MARL benchmarks without
delay and exhibits robustness under fixed and time-varying delays.",http://arxiv.org/abs/2501.05207v1
"ParaRev: Building a dataset for Scientific Paragraph Revision annotated
  with revision instruction",2025-01-09T13:19:55Z,"Léane Jourdan, Nicolas Hernandez, Richard Dufour, Florian Boudin, Akiko Aizawa","Revision is a crucial step in scientific writing, where authors refine their
work to improve clarity, structure, and academic quality. Existing approaches
to automated writing assistance often focus on sentence-level revisions, which
fail to capture the broader context needed for effective modification. In this
paper, we explore the impact of shifting from sentence-level to paragraph-level
scope for the task of scientific text revision. The paragraph level definition
of the task allows for more meaningful changes, and is guided by detailed
revision instructions rather than general ones. To support this task, we
introduce ParaRev, the first dataset of revised scientific paragraphs with an
evaluation subset manually annotated with revision instructions. Our
experiments demonstrate that using detailed instructions significantly improves
the quality of automated revisions compared to general approaches, no matter
the model or the metric considered.",http://arxiv.org/abs/2501.05222v1
"The Intraday Bitcoin Response to Tether Minting and Burning Events:
  Asymmetry, Investor Sentiment, And ""Whale Alerts"" On Twitter",2025-01-09T13:39:22Z,Aman Saggu,"Tether Limited has the sole authority to create (mint) and destroy (burn)
Tether stablecoins (USDT). This paper investigates Bitcoin's response to USDT
supply change events between 2014 and 2021 and identifies an interesting
asymmetry between Bitcoin's responses to USDT minting and burning events.
Bitcoin responds positively to USDT minting events over 5- to 30-minute event
windows, but this response begins declining after 60 minutes. State-dependence
is also demonstrated, with Bitcoin prices exhibiting a greater increase when
the corresponding USDT minting event coincides with positive investor sentiment
and is announced to the public by data service provider, Whale Alert, on
Twitter.",http://arxiv.org/abs/2501.05232v1
Randomized Spectral Clustering for Large-Scale Multi-Layer Networks,2025-01-09T15:50:59Z,"Wenqing Su, Xiao Guo, Xiangyu Chang, Ying Yang","Large-scale multi-layer networks with large numbers of nodes, edges, and
layers arise across various domains, which poses a great computational
challenge for the downstream analysis. In this paper, we develop an efficient
randomized spectral clustering algorithm for community detection of multi-layer
networks. We first utilize the random sampling strategy to sparsify the
adjacency matrix of each layer. Then we use the random projection strategy to
accelerate the eigen-decomposition of the sum-of-squared sparsified adjacency
matrices of all layers. The communities are finally obtained via the k-means of
the eigenvectors. The algorithm not only has low time complexity but also saves
the storage space. Theoretically, we study the misclassification error rate of
the proposed algorithm under the multi-layer stochastic block models, which
shows that the randomization does not deteriorate the error bound under certain
conditions. Numerical studies on multi-layer networks with millions of nodes
show the superior efficiency of the proposed algorithm, which achieves
clustering results rapidly. A new R package called MLRclust is developed and
made available to the public.",http://arxiv.org/abs/2501.05326v1
"CROPS: Model-Agnostic Training-Free Framework for Safe Image Synthesis
  with Latent Diffusion Models",2025-01-09T16:43:21Z,"Junha Park, Ian Ryu, Jaehui Hwang, Hyungkeun Park, Jiyoon Kim, Jong-Seok Lee","With advances in diffusion models, image generation has shown significant
performance improvements. This raises concerns about the potential abuse of
image generation, such as the creation of explicit or violent images, commonly
referred to as Not Safe For Work (NSFW) content. To address this, the Stable
Diffusion model includes several safety checkers to censor initial text prompts
and final output images generated from the model. However, recent research has
shown that these safety checkers have vulnerabilities against adversarial
attacks, allowing them to generate NSFW images. In this paper, we find that
these adversarial attacks are not robust to small changes in text prompts or
input latents. Based on this, we propose CROPS (Circular or RandOm Prompts for
Safety), a model-agnostic framework that easily defends against adversarial
attacks generating NSFW images without requiring additional training. Moreover,
we develop an approach that utilizes one-step diffusion models for efficient
NSFW detection (CROPS-1), further reducing computational resources. We
demonstrate the superiority of our method in terms of performance and
applicability.",http://arxiv.org/abs/2501.05359v1
Some factorization results for formal power series,2025-01-09T16:58:40Z,"Rishu Garg, Jitender Singh","In this paper, we obtain some factorization results on formal power series
over principle ideal domains with sharp bounds on number of irreducible
factors. These factorization results correspondingly lead to irreducibility
criteria for formal power series. The information about prime factorization of
the constant term up to a unit and that of some higher order terms is utilized
for the purpose. Further, using theory of Newton polygons for power series, we
extend the classical Dumas irreducibility criterion to formal power series over
discrete valuation domains, which in particular, yields several irreducibility
criteria.",http://arxiv.org/abs/2501.05375v2
"TimeDP: Learning to Generate Multi-Domain Time Series with Domain
  Prompts",2025-01-09T17:57:56Z,"Yu-Hao Huang, Chang Xu, Yueying Wu, Wu-Jun Li, Jiang Bian","Time series generation models are crucial for applications like data
augmentation and privacy preservation. Most existing time series generation
models are typically designed to generate data from one specified domain. While
leveraging data from other domain for better generalization is proved to work
in other application areas, this approach remains challenging for time series
modeling due to the large divergence in patterns among different real world
time series categories. In this paper, we propose a multi-domain time series
diffusion model with domain prompts, named TimeDP. In TimeDP, we utilize a time
series semantic prototype module which defines time series prototypes to
represent time series basis, each prototype vector serving as ""word""
representing some elementary time series feature. A prototype assignment module
is applied to extract the extract domain specific prototype weights, for
learning domain prompts as generation condition. During sampling, we extract
""domain prompt"" with few-shot samples from the target domain and use the domain
prompts as condition to generate time series samples. Experiments demonstrate
that our method outperforms baselines to provide the state-of-the-art in-domain
generation quality and strong unseen domain generation capability.",http://arxiv.org/abs/2501.05403v1
From Simple to Complex Skills: The Case of In-Hand Object Reorientation,2025-01-09T18:49:39Z,"Haozhi Qi, Brent Yi, Mike Lambeta, Yi Ma, Roberto Calandra, Jitendra Malik","Learning policies in simulation and transferring them to the real world has
become a promising approach in dexterous manipulation. However, bridging the
sim-to-real gap for each new task requires substantial human effort, such as
careful reward engineering, hyperparameter tuning, and system identification.
In this work, we present a system that leverages low-level skills to address
these challenges for more complex tasks. Specifically, we introduce a
hierarchical policy for in-hand object reorientation based on previously
acquired rotation skills. This hierarchical policy learns to select which
low-level skill to execute based on feedback from both the environment and the
low-level skill policies themselves. Compared to learning from scratch, the
hierarchical policy is more robust to out-of-distribution changes and transfers
easily from simulation to real-world environments. Additionally, we propose a
generalizable object pose estimator that uses proprioceptive information,
low-level skill predictions, and control errors as inputs to estimate the
object pose over time. We demonstrate that our system can reorient objects,
including symmetrical and textureless ones, to a desired pose.",http://arxiv.org/abs/2501.05439v1
"The more polypersonal the better -- a short look on space geometry of
  fine-tuned layers",2025-01-09T18:50:47Z,"Sergei Kudriashov, Veronika Zykova, Angelina Stepanova, Yakov Raskind, Eduard Klyshinsky","The interpretation of deep learning models is a rapidly growing field, with
particular interest in language models. There are various approaches to this
task, including training simpler models to replicate neural network predictions
and analyzing the latent space of the model. The latter method allows us to not
only identify patterns in the model's decision-making process, but also
understand the features of its internal structure. In this paper, we analyze
the changes in the internal representation of the BERT model when it is trained
with additional grammatical modules and data containing new grammatical
structures (polypersonality). We find that adding a single grammatical layer
causes the model to separate the new and old grammatical systems within itself,
improving the overall performance on perplexity metrics.",http://arxiv.org/abs/2501.05503v1
"Sub-band Domain Multi-Hypothesis Acoustic Echo Canceler Based Acoustic
  Scene Analysis",2025-01-10T01:43:26Z,"Benjamin J Southwell, Yin-Lee Ho, David Gunawan","This paper introduces a novel approach for acoustic scene analysis by
exploiting an ensemble of statistics extracted from a sub-band domain
multi-hypothesis acoustic echo canceler (SDMH-AEC). A well-designed SDMH-AEC
employs multiple adaptive filtering strategies with potentially complementary
behaviours during convergence, perturbations, and steady-state conditions. By
aggregating statistics across the sub-bands, we derive a feature vector that
exhibits strong discriminative power for distinguishing different acoustic
events and estimating acoustic parameters. The complementary nature of the
SDMH-AEC filters provides a rich source of information that can be extracted at
insignificant cost for acoustic scene analysis tasks. We demonstrate the
effectiveness of the proposed approach experimentally with real data containing
double-talk, echo path change and events where the full-duplex device is
physically moved. The extracted features enable acoustic scene analysis using
existing echo cancellation algorithms and techniques.",http://arxiv.org/abs/2501.05652v1
"ExoFabric: A Re-moldable Textile System for Creating Customizable Soft
  Goods and Wearable Applications",2025-01-10T02:31:09Z,"Rosalie Lin, Aditi Maheshwari, Jung Wook Park, Andreea Danielescu","Fabric has been a fundamental part of human life for thousands of years,
providing comfort, protection, and aesthetic expression. While modern
advancements have enhanced fabric's functionality, it remains static and
unchangeable, failing to adapt to our evolving body shapes and preferences.
This lack of adaptability can lead to unsustainable practices, as consumers
often buy more items to meet their changing needs. In this paper, we propose
ExoFabric, a re-moldable fabric system for customized soft goods applications.
We created ExoFabric by embedding thermoplastic threads into fabric through
computerized embroidery to allow for tunability between rigid plastic and
conformable fabric. We defined a library of design primitives to enable
geometric formability, stiffness, and stretchability by identifying suitable
fabrics, threads, embroidery parameters, and machine limitations. To facilitate
practical applications, we demonstrated practical methods for linking
parameters to application requirements, showcasing form-fitting wearables,
structural support, and shape-changeable furniture for repeatable or one-time
customization.",http://arxiv.org/abs/2501.05664v1
Towards optimization of the Josephson diode effect,2025-01-10T02:44:51Z,"Michiyasu Mori, Wataru Koshibae, Sadamichi Maekawa","We theoretically study the Josephson diode effect in the junction of singlet
superconductors separated by the Rashba system in the in-plane magnetic field
perpendicular to the bias current. The coupling energy of two superconductors
is formulated under the bias current using a tunneling Hamiltonian with a
one-dimensional model. The bias current shifts the Fermi momentum in the Rashba
system due to the continuity of the electronic current. Including the shift of
Fermi momentum in the coupling energy, it is found that the critical current is
asymmetric with respect to the current and the magnetic field, i.e., Josephson
diode effect. Depending on a distance between the superconducting electrodes
$d$, the Josephson diode effect changes its magnitude and sign. The magnitude
is inversely proportional to a band split caused by the spin-orbit interaction.
Since $d$ is experimentally controllable, the Josephson diode effect can be
optimized by tuning of $d$. Our theory develops a new guiding principle to
design the Josephson diode device.",http://arxiv.org/abs/2501.05671v2
"A Belyi-type criterion for vector bundles on curves defined over a
  number field",2025-01-10T03:10:56Z,"Indranil Biswas, Sudarshan Gurjar","Let $X_0$ be an irreducible smooth projective curve defined over
$\overline{\mathbb Q}$ and $f_0 : X_0 \rightarrow
\mathbb{P}^1_{\overline{\mathbb Q}}$ a nonconstant morphism whose branch locus
is contained in the subset $\{0,1, \infty\} \subset
\mathbb{P}^1_{\overline{\mathbb Q}}$. For any vector bundle $E$ on $X =
X_0\times_{{\rm Spec}\,\overline{\mathbb Q}} {\rm Spec} \mathbb{C}$, consider
the direct image $f_*E$ on $\mathbb{P}^1_{\mathbb C}$, where $f= (f_0)_{\mathbb
C}$. It decomposes into a direct sum of line bundles and also it has a natural
parabolic structure. We prove that $E$ is the base change, to $\mathbb C$, of a
vector bundle on $X_0$ if and only if there is an isomorphism $f_*E
\stackrel{\sim}{\rightarrow} \bigoplus_{i=1}^r {\mathcal O}_{{\mathbb
P}^1_{\mathbb C}}(m_i)$, where $r = {\rm rank}(f_*E)$, that takes the parabolic
structure on $f_*E$ to a parabolic structure on $\bigoplus_{i=1}^r {\mathcal
O}_{{\mathbb P}^1_{\mathbb C}}(m_i)$ defined over $\overline{\mathbb Q}$.",http://arxiv.org/abs/2501.05681v1
"Exoplanet Ephemerides Change Observations (ExoEcho). I. Transit Timing
  Analysis of Thirty-Seven Exoplanets using HST/WFC3 Data",2025-01-10T04:28:16Z,"Xinyue Ma, Wenqin Wang, Zixin Zhang, Cong Yu, Dichang Chen, Jiwei Xie, Shangfei Liu, Li Zhou, Bo Ma","The ExoEcho project is designed to study the photodynamics of exoplanets by
leveraging high-precision transit timing data from ground- and space-based
telescopes. Some exoplanets are experiencing orbital decay, and transit timing
variation (TTV) is a useful technique to study their orbital period variations.
In this study, we have obtained transit middle-time data from the Hubble Space
Telescope (HST) observations for 37 short-period exoplanets, most of which are
hot Jupiters. To search for potential long- and short-term orbital period
variations within the sample, we conduct TTV model fitting using both linear
and quadratic ephemeris models. Our analysis identifies two hot Jupiters
experiencing strong periodic decays. Given the old age of the host stars of the
hot Jupiter population, our findings call for a scenario where HJs are
continuously being destructed and created. Our study demonstrates the
importance of incorporating high-precision transit timing data to TTV study in
the future.",http://arxiv.org/abs/2501.05704v1
"Semantic Mapping in Indoor Embodied AI -- A Comprehensive Survey and
  Future Directions",2025-01-10T06:58:14Z,"Sonia Raychaudhuri, Angel X. Chang","Intelligent embodied agents (e.g. robots) need to perform complex semantic
tasks in unfamiliar environments. Among many skills that the agents need to
possess, building and maintaining a semantic map of the environment is most
crucial in long-horizon tasks. A semantic map captures information about the
environment in a structured way, allowing the agent to reference it for
advanced reasoning throughout the task. While existing surveys in embodied AI
focus on general advancements or specific tasks like navigation and
manipulation, this paper provides a comprehensive review of semantic
map-building approaches in embodied AI, specifically for indoor navigation. We
categorize these approaches based on their structural representation (spatial
grids, topological graphs, dense point-clouds or hybrid maps) and the type of
information they encode (implicit features or explicit environmental data). We
also explore the strengths and limitations of the map building techniques,
highlight current challenges, and propose future research directions. We
identify that the field is moving towards developing open-vocabulary,
queryable, task-agnostic map representations, while high memory demands and
computational inefficiency still remaining to be open challenges. This survey
aims to guide current and future researchers in advancing semantic mapping
techniques for embodied AI systems.",http://arxiv.org/abs/2501.05750v1
"Hierarchical Serpentine-like Organic Crystal Optical Waveguides for
  Artificial Neural Networks",2025-01-10T10:10:46Z,"Avulu Vinod Kumar, Mehdi Rohullah, Melchi Chosenyah, Sinduja Gaddam, Rajadurai Chandrasekar","Optical components and circuits that deal with multiple signal generation and
processing are quintessential for artificial neural networks. Herein, we
present a proof-of-concept four-layered organic optical artificial neural
network (ANN)-like architecture, constructed from flexible organic crystals of
(E)-1-(((5-methylpyridin-2-yl)imino)methyl)naphthalene-2-ol (MPyIN), employing
an atomic force microscopy cantilever tip-based mechanical micromanipulation
technique. Initially, the strategic selection of four MPyIN crystal active
waveguides of varying lengths, mechanically bending them into serpentine-like
forms, followed by their hierarchical integration, creates neuron-like,
four-layered interconnected optical waveguides with six optical synapses. The
synapses in the ANN-like architecture enable parallel transmissions of passive
optical signals via evanescent coupling across multiple paths through various
layers of the serpentine-shaped optical waveguides. Notably, the feedforward
mechanism allows the synapses to multiply and split the optical signal
generated at any input into four diverging signals with varying magnitudes.
Here, certain outputs deliver a mixed signal (passive and active) due to
diverging and converging optical transmission paths. This hierarchical,
ANN-like tiny architecture paves the way for the development of smart optical
neural networks utilizing multiple emissive and phase-changing organic
crystals.",http://arxiv.org/abs/2501.05831v1
"Affordably Fine-tuned LLMs Provide Better Answers to Course-specific
  MCQs",2025-01-10T11:44:35Z,"Bianca Raimondi, Saverio Giallorenzo, Maurizio Gabbrielli","In education, the capability of generating human-like text of Large Language
Models (LLMs) inspired work on how they can increase the efficiency of learning
and teaching. We study the affordability of these models for educators and
students by investigating how LLMs answer multiple-choice questions (MCQs) with
respect to hardware constraints and refinement techniques. We explore this
space by using generic pre-trained LLMs (the 7B, 13B, and 70B variants of
LLaMA-2) to answer 162 undergraduate-level MCQs from a course on Programming
Languages (PL) -- the MCQ dataset is a contribution of this work, which we make
publicly available. Specifically, we dissect how different factors, such as
using readily-available material -- (parts of) the course's textbook -- for
fine-tuning and quantisation (to decrease resource usage) can change the
accuracy of the responses. The main takeaway is that smaller textbook-based
fine-tuned models outperform generic larger ones (whose pre-training requires
conspicuous resources), making the usage of LLMs for answering MCQs resource-
and material-wise affordable.",http://arxiv.org/abs/2501.05891v1
"Environment Modeling for Service Robots From a Task Execution
  Perspective",2025-01-10T12:54:33Z,"Ying Zhang, Guohui Tian, Cui-Hua Zhang, Changchun Hua, Weili Ding, Choon Ki Ahn","Service robots are increasingly entering the home to provide domestic tasks
for residents. However, when working in an open, dynamic, and unstructured home
environment, service robots still face challenges such as low intelligence for
task execution and poor long-term autonomy (LTA), which has limited their
deployment. As the basis of robotic task execution, environment modeling has
attracted significant attention. This integrates core technologies such as
environment perception, understanding, and representation to accurately
recognize environmental information. This paper presents a comprehensive survey
of environmental modeling from a new task-executionoriented perspective. In
particular, guided by the requirements of robots in performing domestic service
tasks in the home environment, we systematically review the progress that has
been made in task-execution-oriented environmental modeling in four respects:
1) localization, 2) navigation, 3) manipulation, and 4) LTA. Current challenges
are discussed, and potential research opportunities are also highlighted.",http://arxiv.org/abs/2501.05931v1
Noetherian rings of non-local rank,2025-01-10T13:04:06Z,Dmitry Kudryakov,"The rank of a ring $R$ is the supremum of minimal cardinalities of generating
sets of $I$, among all ideals $I$ in $R$. In this paper, we obtain a
characterization of Noetherian rings $R$ whose rank is not equal to the
supremum of ranks of localizations of $R$ at maximal ideals. It turns out that
any such ring is a direct product of a finite number of local principal
Artinian rings and Dedekind domains, at least one of which is not principal
ideal ring. As an application, we show that the rank of the ring of polynomials
over an Artinian ring can be computed locally.",http://arxiv.org/abs/2501.05940v2
Non-Abelian interlayer coherent fractional quantum Hall states,2025-01-10T15:19:50Z,"Xiang-Jian Hou, Lei Wang, Ying-Hai Wu","We study non-Abelian fractional quantum Hall state in double layer systems at
total filling factor $1/2$. Recent progresses in two-dimensional van der Waals
materials made it possible to explore the regime with very small interlayer
distance. Numerical calculations suggests interlayer phase coherence can
develop between the layers such that the electrons may redistribute between
them without changing the Hall response. It corresponds to spontaneous breaking
of the U(1) symmetry associated with the particle number difference in the
layers. This state manifests itself as superfluid in counterflow measurement
and has characteristic Hall response when current is passed through one layer
and voltages in both layers are measured. As the interlayer distance increases,
a phase transition into the Halperin 331 state occurs. We also discuss similar
physics for bosonic systems with specially designed interactions.",http://arxiv.org/abs/2501.06041v1
"Effects of disorder on the quantum transport properties in topologically
  nontrivial metal PbTaSe$_{2}$",2025-01-10T05:45:15Z,"Longfei Sun, Yue Sun, Qiang Hou, R. Sankar, R. Kalaivanan, Xiaofeng Xu, Zhixiang Shi, Tsuyoshi Tamegai","Weak antilocalization (WAL), an increase in the electrical conductivity at
low temperatures associated with the suppression of electron localization due
to quantum interference effects, is often observed in topological materials. In
this study, we report the observation of WAL in topologically nontrivial metal
PbTaSe$_{2}$ at low temperatures. In the pristine sample, we identified the
presence of WAL, which is attributed to the topologically protected
backscattering. In order to investigate the influence of disorder on the WAL,
we successively introduced controlled amounts of disorder by
H$^{+}$-irradiation. As disorder increases, the dip-like magnetoresistance
caused by WAL changes to a linear magnetoresistance(MR), and eventually to a
quadratic MR as the electronic system becomes highly localized. This research
unveils the significance of disorder in shaping the quantum transport
characteristics of topological materials.",http://arxiv.org/abs/2501.06272v1
On How Traffic Signals Impact the Fundamental Diagrams of Urban Roads,2025-01-10T19:06:50Z,"Chao Zhang, Yechen Li, Neha Arora, Carolina Osorio","Being widely adopted by the transportation and planning practitioners, the
fundamental diagram (FD) is the primary tool used to relate the key macroscopic
traffic variables of speed, flow, and density. We empirically analyze the
relation between vehicular space-mean speeds and flows given different signal
settings and postulate a parsimonious parametric function form of the
traditional FD where its function parameters are explicitly modeled as a
function of the signal plan factors. We validate the proposed formulation using
data from signalized urban road segments in Salt Lake City, Utah, USA. The
proposed formulation builds our understanding of how changes to signal settings
impact the FDs, and more generally the congestion patterns, of signalized urban
segments.",http://arxiv.org/abs/2501.06306v1
Maximum Likelihood Detection of Instrumental Glitches in LISA TDI Data,2025-01-10T19:32:12Z,"Orion Sauter, Peter Wass, Wiler Sanchez, Henri Inchauspé","The orbiting LISA instrument is designed to detect gravitational waves in the
millihertz band, produced by sources including galactic binaries and extreme
mass ratio inspirals, among others. The detector consists of three spacecraft,
each carrying a pair of free-falling test masses. A technology-demonstration
mission, LISA Pathfinder, was launched in 2015, and observed several sudden
changes in test mass acceleration, referred to as ""glitches."" Similar glitches
in the full LISA mission have the potential to contaminate the Time-Delay
Interferometry outputs that are the detector's primary data product. In this
paper, we describe an optimization technique using maximum likelihood
estimation for detecting and removing glitches with a known waveform.",http://arxiv.org/abs/2501.06315v2
"High-Speed Tunable Generation of Random Number Distributions Using
  Actuated Perpendicular Magnetic Tunnel Junctions",2025-01-10T19:42:28Z,"Ahmed Sidi El Valli, Michael Tsao, J. Darby Smith, Shashank Misra, Andrew D. Kent","Perpendicular magnetic tunnel junctions (pMTJs) actuated by nanosecond pulses
are emerging as promising devices for true random number generation (TRNG) due
to their intrinsic stochastic behavior and high throughput. In this work, we
study the tunability and quality of random-number distributions generated by
pMTJs operating at a frequency of 104 MHz. First, changing the pulse amplitude
is used to systematically vary the probability bias. The variance of the
resulting bitstreams is shown to follow the expected binomial distribution.
Second, the quality of uniform distributions of 8-bit random numbers generated
with a probability bias of 0.5 is considered. A reduced chi-square analysis of
this data shows that two XOR operations are necessary to achieve this
distribution with p-values greater than 0.05. Finally, we show that there is a
correlation between long-term probability bias variations and pMTJ resistance.
These findings suggest that variations in the characteristics of the pMTJ
underlie the observed variation of probability bias. Our results highlight the
potential of stochastically actuated pMTJs for high-speed, tunable TRNG
applications, showing the importance of the stability of pMTJs device
characteristics in achieving reliable, long-term performance.",http://arxiv.org/abs/2501.06318v1
"Quantification of Nuclear Coordinate Activation on Polaritonic Potential
  Energy Surfaces",2025-01-10T22:04:49Z,"Shahzad Alam, Yicheng Liu, Russell J. Holmes, Renee R. Frontiera","Polaritonic states, which arise from strong coupling between light and
matter, show great promise in modifying chemical reactivity. However,
reproducible enhancement of chemical reactions with polaritons is challenging
due to a lack of understanding on how to launch wavepackets along productive
reactive coordinates while avoiding unproductive local minima in the
multidimensional potential energy landscape. Here we employ resonance Raman
intensity analysis to quantify mode-specific nuclear displacement values in
pentacene thin films and pentacene exciton-polaritons. We find that coupling
significantly changes the potential energy landscape, including both
enhancement and suppression of nuclear displacements. We demonstrate that
controlling cavity parameters enables selective steering of vibronic
wavepackets. Our approach provides a quantitative methodology for screening
polaritonic catalysts and opens new avenues for designing reproducible and
effective cavity-controlled chemistry.",http://arxiv.org/abs/2501.06364v1
Resilient Endurance-Aware NVM-based PUF against Learning-based Attacks,2025-01-10T22:30:11Z,"Hassan Nassar, Ming-Liang Wei, Chia-Lin Yang, Jörg Henkel, Kuan-Hsun Chen","Physical Unclonable Functions (PUFs) based on Non-Volatile Memory (NVM)
technology have emerged as a promising solution for secure authentication and
cryptographic applications. By leveraging the multi-level cell (MLC)
characteristic of NVMs, these PUFs can generate a wide range of unique
responses, enhancing their resilience to machine learning (ML) modeling
attacks. However, a significant issue with NVM-based PUFs is their endurance
problem; frequent write operations lead to wear and degradation over time,
reducing the reliability and lifespan of the PUF.
  This paper addresses these issues by offering a comprehensive model to
predict and analyze the effects of endurance changes on NVM PUFs. This model
provides insights into how wear impacts the PUF's quality and helps in
designing more robust PUFs. Building on this model, we present a novel design
for NVM PUFs that significantly improves endurance. Our design approach
incorporates advanced techniques to distribute write operations more evenly and
reduce stress on individual cells. The result is an NVM PUF that demonstrates a
$62\times$ improvement in endurance compared to current state-of-the-art
solutions while maintaining protection against learning-based attacks.",http://arxiv.org/abs/2501.06367v1
"Frequency-dependent specific heat in quantum supercooled liquids: A
  mode-coupling study",2025-01-11T06:57:54Z,"Ankita Das, Eran Rabani, Kunimasa Miyazaki, Upendra Harbola","Frequency-dependence of specific heat in supercooled hard sphere liquid is
computed using quantum mode-coupling theory (QMCT). Mode-coupling equations are
solved using recently proposed perturbative method that allows to study
relaxation in the moderate quantum regime where quantum effects assist liquid
to glass transition. Zwanzig's formulation is used to compute the
frequency-dependent specific heat in supercooled state using dynamical
information from QMCT. Specific heat shows strong variation as the quantumness
of the liquid is changed, which becomes more significant as density is
increased. It is found that, near the transition point, different dynamical
modes contribute to the specific heat in the classical and the quantum liquids.",http://arxiv.org/abs/2501.06455v1
Tagged particle dynamics in supercooled quantum liquid,2025-01-11T07:03:53Z,"Ankita Das, Gopika Krishnan, Eran Rabani, Upendra Harbola","We analyze dynamics of quantum supercooled liquids in terms of tagged
particle dynamics. Unlike the classical case, uncertainty in the position of a
particle in quantum liquid leads to qualitative changes. We demonstrate these
effects in the dynamics of the first two moments of displacements, namely, the
mean-squared displacement, $\langle \Delta r^2(t)\rangle$, and $\langle \Delta
r^4(t)\rangle$. Results are presented for a hard sphere liquid using
mode-coupling theory (MCT) formulation and simulation on a binary Lennard-Jones
liquid. As the quantumness (controlled by the de-Broglie thermal wavelength) is
increased, a non-zero value of the moments at zero time leads to significant
deviations from the classical behavior in the initial dynamics. Initial
displacement shows ballistic behavior $\langle \Delta r^2(t)\rangle\sim t^2$,
but, as a result of large uncertainty in the position, the dynamical effects
become weaker with increasing quantumness over this time scale.",http://arxiv.org/abs/2501.06456v1
"The 1st SpeechWellness Challenge: Detecting Suicidal Risk Among
  Adolescents",2025-01-11T08:03:41Z,"Wen Wu, Ziyun Cui, Chang Lei, Yinan Duan, Diyang Qu, Ji Wu, Bowen Zhou, Runsen Chen, Chao Zhang","The 1st SpeechWellness Challenge (SW1) aims to advance methods for detecting
suicidal risk in adolescents using speech analysis techniques. Suicide among
adolescents is a critical public health issue globally. Early detection of
suicidal tendencies can lead to timely intervention and potentially save lives.
Traditional methods of assessment often rely on self-reporting or clinical
interviews, which may not always be accessible. The SW1 challenge addresses
this gap by exploring speech as a non-invasive and readily available indicator
of mental health. We release the SW1 dataset which contains speech recordings
from 600 adolescents aged 10-18 years. By focusing on speech generated from
natural tasks, the challenge seeks to uncover patterns and markers that
correlate with suicidal risk.",http://arxiv.org/abs/2501.06474v1
Whole-Body Integrated Motion Planning for Aerial Manipulators,2025-01-11T09:45:38Z,"Weiliang Deng, Hongming Chen, Biyu Ye, Haoran Chen, Ximin Lyu","Efficient motion planning for Aerial Manipulators (AMs) is essential for
tackling complex manipulation tasks, yet achieving coupled trajectory planning
remains challenging. In this work, we propose, to the best of our knowledge,
the first whole-body integrated motion planning framework for aerial
manipulators, which is facilitated by an improved Safe Flight Corridor (SFC)
generation strategy and high-dimensional collision-free trajectory planning. In
particular, we formulate an optimization problem to generate feasible
trajectories for both the quadrotor and manipulator while ensuring collision
avoidance, dynamic feasibility, kinematic feasibility, and waypoint
constraints. To achieve collision avoidance, we introduce a variable geometry
approximation method, which dynamically models the changing collision volume
induced by different manipulator configurations. Moreover, waypoint constraints
in our framework are defined in $\mathrm{SE(3)\times\mathbb{R}^3}$, allowing
the aerial manipulator to traverse specified positions while maintaining
desired attitudes and end-effector states. The effectiveness of our framework
is validated through comprehensive simulations and real-world experiments
across various environments.",http://arxiv.org/abs/2501.06493v1
Dynamic Causal Structure Discovery and Causal Effect Estimation,2025-01-11T12:52:39Z,"Jianian Wang, Rui Song","To represent the causal relationships between variables, a directed acyclic
graph (DAG) is widely utilized in many areas, such as social sciences,
epidemics, and genetics. Many causal structure learning approaches are
developed to learn the hidden causal structure utilizing deep-learning
approaches. However, these approaches have a hidden assumption that the causal
relationship remains unchanged over time, which may not hold in real life. In
this paper, we develop a new framework to model the dynamic causal graph where
the causal relations are allowed to be time-varying. We incorporate the basis
approximation method into the score-based causal discovery approach to capture
the dynamic pattern of the causal graphs. Utilizing the autoregressive model
structure, we could capture both contemporaneous and time-lagged causal
relationships while allowing them to vary with time. We propose an algorithm
that could provide both past-time estimates and future-time predictions on the
causal graphs, and conduct simulations to demonstrate the usefulness of the
proposed method. We also apply the proposed method for the covid-data analysis,
and provide causal estimates on how policy restriction's effect changes.",http://arxiv.org/abs/2501.06534v1
ACORD: An Expert-Annotated Retrieval Dataset for Legal Contract Drafting,2025-01-11T16:37:49Z,"Steven H. Wang, Maksim Zubkov, Kexin Fan, Sarah Harrell, Yuyang Sun, Wei Chen, Andreas Plesner, Roger Wattenhofer","Information retrieval, specifically contract clause retrieval, is
foundational to contract drafting because lawyers rarely draft contracts from
scratch; instead, they locate and revise the most relevant precedent. We
introduce the Atticus Clause Retrieval Dataset (ACORD), the first retrieval
benchmark for contract drafting fully annotated by experts. ACORD focuses on
complex contract clauses such as Limitation of Liability, Indemnification,
Change of Control, and Most Favored Nation. It includes 114 queries and over
126,000 query-clause pairs, each ranked on a scale from 1 to 5 stars. The task
is to find the most relevant precedent clauses to a query. The bi-encoder
retriever paired with pointwise LLMs re-rankers shows promising results.
However, substantial improvements are still needed to effectively manage the
complex legal work typically undertaken by lawyers. As the first retrieval
benchmark for contract drafting annotated by experts, ACORD can serve as a
valuable IR benchmark for the NLP community.",http://arxiv.org/abs/2501.06582v1
"Mean-field behavior of the quantum Ising susceptibility and a new lace
  expansion for the classical Ising model",2025-01-11T17:22:01Z,"Yoshinori Kamijima, Akira Sakai","The transverse-field Ising model is widely studied as one of the simplest
quantum spin systems. It is known that this model exhibits a phase transition
at the critical inverse temperature $\beta_{\mathrm{c}}(q)$, where $q$ is the
strength of the transverse field. Bj\""ornberg [Commun. Math. Phys., 232 (2013)]
investigated the divergence rate of the susceptibility for the nearest-neighbor
model as the critical point is approached by simultaneously changing $q$ and
the spin-spin coupling $J$ in a proper manner, with fixed temperature. In this
paper, we prove that the susceptibility diverges as
$(\beta_{\mathrm{c}}(q)-\beta)^{-1}$ as $\beta\uparrow\beta_{\mathrm{c}}(q)$
for $d>4$ assuming an infrared bound on the space-time two-point function. One
of the key elements is a stochastic-geometric representation in Bj\""ornberg &
Grimmett [J. Stat. Phys., 136 (2009)] and Crawford & Ioffe [Commun. Math.
Phys., 296 (2010)]. As a byproduct, we derive a new lace expansion for the
classical Ising model (i.e., $q=0$).",http://arxiv.org/abs/2501.06592v1
Wavelet Integrated Convolutional Neural Network for ECG Signal Denoising,2025-01-12T06:18:46Z,"Takamasa Terada, Masahiro Toyoura","Wearable electrocardiogram (ECG) measurement using dry electrodes has a
problem with high-intensity noise distortion. Hence, a robust noise reduction
method is required. However, overlapping frequency bands of ECG and noise make
noise reduction difficult. Hence, it is necessary to provide a mechanism that
changes the characteristics of the noise based on its intensity and type. This
study proposes a convolutional neural network (CNN) model with an additional
wavelet transform layer that extracts the specific frequency features in a
clean ECG. Testing confirms that the proposed method effectively predicts
accurate ECG behavior with reduced noise by accounting for all frequency
domains. In an experiment, noisy signals in the signal-to-noise ratio (SNR)
range of -10-10 are evaluated, demonstrating that the efficiency of the
proposed method is higher when the SNR is small.",http://arxiv.org/abs/2501.06724v1
"Diversified Augmentation with Domain Adaptation for Debiased Video
  Temporal Grounding",2025-01-12T08:04:52Z,"Junlong Ren, Gangjian Zhang, Haifeng Sun, Hao Wang","Temporal sentence grounding in videos (TSGV) faces challenges due to public
TSGV datasets containing significant temporal biases, which are attributed to
the uneven temporal distributions of target moments. Existing methods generate
augmented videos, where target moments are forced to have varying temporal
locations. However, since the video lengths of the given datasets have small
variations, only changing the temporal locations results in poor generalization
ability in videos with varying lengths. In this paper, we propose a novel
training framework complemented by diversified data augmentation and a domain
discriminator. The data augmentation generates videos with various lengths and
target moment locations to diversify temporal distributions. However, augmented
videos inevitably exhibit distinct feature distributions which may introduce
noise. To address this, we design a domain adaptation auxiliary task to
diminish feature discrepancies between original and augmented videos. We also
encourage the model to produce distinct predictions for videos with the same
text queries but different moment locations to promote debiased training.
Experiments on Charades-CD and ActivityNet-CD datasets demonstrate the
effectiveness and generalization abilities of our method in multiple grounding
structures, achieving state-of-the-art results.",http://arxiv.org/abs/2501.06746v2
"Exploring dynamical quantum phase transition from pure states to mixed
  states through generalized Su-Schrieffer-Heeger models",2025-01-12T12:28:34Z,"Kaiyuan Cao, Jian Wang","We investigate dynamic quantum phase transitions (DQPTs) in both pure and
mixed states within the framework of the generalized SSH model, specifically
analyzing the SSH-3 and SSH-4 models, which exhibit different symmetries. We
find that the SSH-3 model, characterized by a chiral-like point symmetry rather
than true chiral symmetry, supports robust localized edge states associated
with its topological properties. Our results show that DQPTs for pure states
occur following a quench that crosses the topological transition, even with an
open energy band gap. For mixed states, DQPT behavior is consistent at low
temperatures, but significant changes are observed at high temperatures,
resulting in the emergence of multiple critical times. In contrast, the SSH-4
model, which possesses chiral symmetry, allows for the analysis of two distinct
energy spectrum configurations. We conclude that the occurrence of DQPTs for
pure states in the SSH-4 model necessitates a quench from an initial state
without a band gap while crossing the critical point of the topological
transition, whereas DQPTs are absent for mixed states at elevated temperatures.",http://arxiv.org/abs/2501.06794v1
"Symmetry-breaking induced transition among net-zero-magnetization
  magnets",2025-01-12T14:46:49Z,"San-Dong Guo, Xiao-Shu Guo, Guangzhao Wang","Net-zero-magnetization magnets have garnered intensive research attention due
to their ultradense and ultrafast potential. In terms of the symmetric
classification of connecting magnetic atoms with opposite spin polarization,
the net-zero-magnetization magnets mainly include $PT$-antiferromagnet (the
joint symmetry ($PT$) of space inversion symmetry ($P$) and time-reversal
symmetry ($T$)), altermagnet and fully-compensated ferrimagnet. Studying
transitions among net-zero-magnetization magnets is essentially the research on
symmetry breaking, which can also clearly reveal the transformation of
spin-splitting symmetry. Symmetry breaking can be achieved through methods such
as Janus engineering, isovalent alloying, and external electric field. Here, we
start from a parent $PT$-antiferromagnet that simultaneously possesses both $P$
and rotational/mirror symmetries to induce altermagnet and fully-compensated
ferrimagnet. Based on first-principles calculations, the proposed transitions
can be verified in $PT$-antiferromagnet $\mathrm{CrC_2S_6}$ monolayer. By Janus
engineering and isovalent alloying, $\mathrm{CrC_2S_6}$ can change into
altermagnetic $\mathrm{CrC_2S_3Se_3}$ and fully-compensated ferrimagnetic
$\mathrm{CrMoC_2S_6}$. The $\mathrm{CrC_2S_3Se_3}$ can also become
fully-compensated ferrimagnetic $\mathrm{CrMoC_2S_3Se_3}$ by isovalent
alloying. Our work provides a clear and intuitive example to explain the
transitions among net-zero-magnetization magnets, which can inspire more
research on net-zero-magnetization magnets.",http://arxiv.org/abs/2501.06829v1
"Unveiling Temporal Trends in 19th Century Literature: An Information
  Retrieval Approach",2025-01-12T15:00:10Z,"Suchana Datta, Dwaipayan Roy, Derek Greene, Gerardine Meaney","In English literature, the 19th century witnessed a significant transition in
styles, themes, and genres. Consequently, the novels from this period display
remarkable diversity. This paper explores these variations by examining the
evolution of term usage in 19th century English novels through the lens of
information retrieval. By applying a query expansion-based approach to a
decade-segmented collection of fiction from the British Library, we examine how
related terms vary over time. Our analysis employs multiple standard metrics
including Kendall's tau, Jaccard similarity, and Jensen-Shannon divergence to
assess overlaps and shifts in expanded query term sets. Our results indicate a
significant degree of divergence in the related terms across decades as
selected by the query expansion technique, suggesting substantial linguistic
and conceptual changes throughout the 19th century novels.",http://arxiv.org/abs/2501.06833v1
Faithful Counterfactual Visual Explanations (FCVE),2025-01-12T15:18:31Z,"Bismillah Khan, Syed Ali Tariq, Tehseen Zia, Muhammad Ahsan, David Windridge","Deep learning models in computer vision have made remarkable progress, but
their lack of transparency and interpretability remains a challenge. The
development of explainable AI can enhance the understanding and performance of
these models. However, existing techniques often struggle to provide convincing
explanations that non-experts easily understand, and they cannot accurately
identify models' intrinsic decision-making processes. To address these
challenges, we propose to develop a counterfactual explanation (CE) model that
balances plausibility and faithfulness. This model generates easy-to-understand
visual explanations by making minimum changes necessary in images without
altering the pixel data. Instead, the proposed method identifies internal
concepts and filters learned by models and leverages them to produce plausible
counterfactual explanations. The provided explanations reflect the internal
decision-making process of the model, thus ensuring faithfulness to the model.",http://arxiv.org/abs/2501.06841v1
"Generative Artificial Intelligence-Supported Pentesting: A Comparison
  between Claude Opus, GPT-4, and Copilot",2025-01-12T22:48:37Z,"Antonio López Martínez, Alejandro Cano, Antonio Ruiz-Martínez","The advent of Generative Artificial Intelligence (GenAI) has brought a
significant change to our society. GenAI can be applied across numerous fields,
with particular relevance in cybersecurity. Among the various areas of
application, its use in penetration testing (pentesting) or ethical hacking
processes is of special interest. In this paper, we have analyzed the potential
of leading generic-purpose GenAI tools-Claude Opus, GPT-4 from ChatGPT, and
Copilot-in augmenting the penetration testing process as defined by the
Penetration Testing Execution Standard (PTES). Our analysis involved evaluating
each tool across all PTES phases within a controlled virtualized environment.
The findings reveal that, while these tools cannot fully automate the
pentesting process, they provide substantial support by enhancing efficiency
and effectiveness in specific tasks. Notably, all tools demonstrated utility;
however, Claude Opus consistently outperformed the others in our experimental
scenarios.",http://arxiv.org/abs/2501.06963v1
Logic Meets Magic: LLMs Cracking Smart Contract Vulnerabilities,2025-01-13T04:42:45Z,"ZeKe Xiao, Qin Wang, Hammond Pearce, Shiping Chen","Smart contract vulnerabilities caused significant economic losses in
blockchain applications. Large Language Models (LLMs) provide new possibilities
for addressing this time-consuming task. However, state-of-the-art LLM-based
detection solutions are often plagued by high false-positive rates.
  In this paper, we push the boundaries of existing research in two key ways.
First, our evaluation is based on Solidity v0.8, offering the most up-to-date
insights compared to prior studies that focus on older versions (v0.4). Second,
we leverage the latest five LLM models (across companies), ensuring
comprehensive coverage across the most advanced capabilities in the field.
  We conducted a series of rigorous evaluations. Our experiments demonstrate
that a well-designed prompt can reduce the false-positive rate by over 60%.
Surprisingly, we also discovered that the recall rate for detecting some
specific vulnerabilities in Solidity v0.8 has dropped to just 13% compared to
earlier versions (i.e., v0.4). Further analysis reveals the root cause of this
decline: the reliance of LLMs on identifying changes in newly introduced
libraries and frameworks during detection.",http://arxiv.org/abs/2501.07058v1
Nonequilibrium Continuous Transition in a Fast Rotating Turbulence,2025-01-13T06:26:27Z,"Chandra Shekhar Lohani, Suraj Kumar Nayak, Kannabiran Seshasayanan, Vishwanath Shukla","We study the saturation of three-dimensional unstable perturbations on a fast
rotating turbulent flow using direct numerical simulations (DNSs). Under the
effect of Kolmogorov forcing, a transition between states dominated by coherent
two-dimensional modes to states with three-dimensional variations
(quasi-two-dimensional) is observed as we change the global rotation rate. We
find this akin to a critical phenomenon, wherein the order parameter scales
with the distance to the critical point raised to an exponent. The exponent
itself deviates from the predicted mean field value. Also, the nature of the
fluctuations of the order parameter near the critical point indicate the
presence of on-off intermittency. The critical rotation rate at which the
transition occurs exhibits a linear scaling behaviour with the forcing wave
number. A reduced model based on linear stability analysis is used to find the
linear threshold estimates; we find these to be in good agreement with the 3D
nonlinear DNS results.",http://arxiv.org/abs/2501.07079v1
"Quality Control of Lifetime Drift in Discrete Electrical Parameters in
  Semiconductor Devices via Transition Modeling",2025-01-13T08:06:12Z,"Lukas Sommeregger, Jürgen Pilz","Semiconductors are widely used in various applications and critical
infrastructures. These devices have specified lifetimes and quality targets
that manufacturers must achieve. Lifetime estimation is conducted through
accelerated stress tests. Electrical parameters are measured at multiple times
during a stress test procedure. The change in these Electrical parameters is
called lifetime drift. Data from these tests can be used to develop a
statistical model predicting the lifetime behavior of the electrical parameters
in real devices. These models can provide early warnings in production
processes, identify critical parameter drift, and detect outliers. While models
for continuous electrical parameters exists, there may be bias when estimating
the lifetime of discrete parameters. To address this, we propose a
semi-parametric model for degradation trajectories based on longitudinal stress
test data. This model optimizes guard bands, or quality guaranteeing tighter
limits, for discrete electrical parameters at production testing. It is
scalable, data-driven, and explainable, offering improvements over existing
methods for continuous underlying data, such as faster calculations, arbitrary
non-parametric conditional distribution modeling, and a natural extension of
optimization algorithms to the discrete case using Markov transition matrices.",http://arxiv.org/abs/2501.07115v1
"TIMRL: A Novel Meta-Reinforcement Learning Framework for Non-Stationary
  and Multi-Task Environments",2025-01-13T09:11:33Z,"Chenyang Qi, Huiping Li, Panfeng Huang","In recent years, meta-reinforcement learning (meta-RL) algorithm has been
proposed to improve sample efficiency in the field of decision-making and
control, enabling agents to learn new knowledge from a small number of samples.
However, most research uses the Gaussian distribution to extract task
representation, which is poorly adapted to tasks that change in non-stationary
environment. To address this problem, we propose a novel meta-reinforcement
learning method by leveraging Gaussian mixture model and the transformer
network to construct task inference model. The Gaussian mixture model is
utilized to extend the task representation and conduct explicit encoding of
tasks. Specifically, the classification of tasks is encoded through transformer
network to determine the Gaussian component corresponding to the task. By
leveraging task labels, the transformer network is trained using supervised
learning. We validate our method on MuJoCo benchmarks with non-stationary and
multi-task environments. Experimental results demonstrate that the proposed
method dramatically improves sample efficiency and accurately recognizes the
classification of the tasks, while performing excellently in the environment.",http://arxiv.org/abs/2501.07146v1
Temperature Driven Multi-modal/Single-actuated Soft Finger,2025-01-13T11:14:05Z,"Prashant Kumar, Weiwei Wan, Kensuke Harada","Soft pneumatic fingers are of great research interest. However, their
significant potential is limited as most of them can generate only one motion,
mostly bending. The conventional design of soft fingers does not allow them to
switch to another motion mode. In this paper, we developed a novel multi-modal
and single-actuated soft finger where its motion mode is switched by changing
the finger's temperature. Our soft finger is capable of switching between three
distinctive motion modes: bending, twisting, and extension-in approximately
five seconds. We carried out a detailed experimental study of the soft finger
and evaluated its repeatability and range of motion. It exhibited repeatability
of around one millimeter and a fifty percent larger range of motion than a
standard bending actuator. We developed an analytical model for a
fiber-reinforced soft actuator for twisting motion. This helped us relate the
input pressure to the output twist radius of the twisting motion. This model
was validated by experimental verification. Further, a soft robotic gripper
with multiple grasp modes was developed using three actuators. This gripper can
adapt to and grasp objects of a large range of size, shape, and stiffness. We
showcased its grasping capabilities by successfully grasping a small berry, a
large roll, and a delicate tofu cube.",http://arxiv.org/abs/2501.07216v1
Markarian 590: The AGN Awakens,2025-01-13T11:24:52Z,"Biswaraj Palit, Marzena Śniegowska, Alex Markowitz, Agata Różańska, Benny Trakhtenbrot, Joseph Farah, Andy Howell","Changing-Look AGN (CLAGN) Mkn 590 recently underwent a sudden \lq
re-ignition\rq, marked by substantial increases in optical/UV and X-ray
continuum flux since last year. \textit{Swift}-XRT observations revealed the
re-emergence of a soft X-ray excess (SXE) as the source transitioned from a
low-flux state in July 2023 to a significantly higher flux state in October
2024. This evolution was in response to an order-of-magnitude increase in
extreme-UV (EUV) continuum emission, detected by \textit{Swift}-UVOT. Follow-up
optical spectra from the Las Cumbres Observatory confirmed the presence of
dynamically broadened Balmer lines, He II emission, and the emergence of the Fe
II complex. As the Eddington fraction increased by 10\% over the last 15
months, we found clear evidence of formation of a warm corona, strongly linked
to the cold accretion disc underneath. A global amplification of ionizing
radiation after approximately 11 years is consistent with propagating heating
fronts in inflated accretion discs. Based on our multi-wavelength study on
recent data, we propose that Mkn 590 is currently becoming a Seyfert-1, similar
to 1990s.",http://arxiv.org/abs/2501.07225v1
Sensing with near-infrared laser trapped fluorescent nanodiamonds,2025-01-13T12:24:05Z,"Arthur Dervillez, Fatemeh Kalantarifard, Luca Troise, Alexander Huck, Kirstine Berg-Sørensen","Biosensing based on optically trapped fluorescent nanodiamonds is an
intriguing research direction potentially allowing to resolve biochemical
processes inside living cells. Towards this goal, we investigate infrared near
(NIR) laser irradiation at 1064 nm on fluorescent nanodiamonds (FNDs)
containing nitrogen-vacancy (NV) centers. By conducting comprehensive
experiments, we aim to understand how NIR exposure influences the fluorescence
and sensing properties of FNDs and to determine the potential implications for
the use of FNDs in various sensing applications. The experimental setup
involved exposing FNDs to varying intensities of NIR laser light and analyzing
the resultant changes in their optical and physical properties. Key
measurements included T1 relaxation times, optical spectroscopy, and optically
detected magnetic resonance (ODMR) spectra. The findings reveal how increased
NIR laser power correlates with alterations in ODMR central frequency but also
that charge state dynamics under NIR irradiation of NV centers plays a role. We
suggest protocols with NIR and green light that mitigate the effect of NIR, and
demonstrate that FND biosensing works well with such a protocol.",http://arxiv.org/abs/2501.07263v1
"Anomalies of the Scholtes regularization for mathematical programs with
  complementarity constraints",2025-01-13T15:02:27Z,"Vladimir Shikhman, Sebastian Lämmel","For mathematical programs with complementarity constraints (MPCC), we refine
the convergence analysis of the Scholtes regularization. Our goal is to relate
nondegenerate C-stationary points of MPCC with nondegenerate Karush-Kuhn-Tucker
points of its Scholtes regularization. We detected the following anomalies: (i)
in a neighborhood of a nondegenerate C-stationary point there could be
degenerate Karush-Kuhn-Tucker points of the Scholtes regularization; (ii) even
if nondegenerate, they might be locally non-unique; (iii) if nevertheless
unique, their quadratic index potentially differs from the C-index of the
C-stationary point under consideration. Thus, a change of the topological type
for Karush-Kuhn-Tucker points of the Scholtes regularization is possible. In
particular, a nondegenerate minimizer of MPCC might be approximated by saddle
points. In order to bypass the mentioned anomalies, an additional generic
condition for nondegenerate C-stationary points of MPCC is identified. Then, we
uniquely trace nondegenerate Karush-Kuhn-Tucker points of the Scholtes
regularization and successively maintain their topological type.",http://arxiv.org/abs/2501.07383v1
"Ultrafast photodissociation dynamics of dichloromethane on
  three-dimensional potential energy surfaces and its Coulomb explosion
  signature",2025-01-13T16:52:36Z,Yijue Ding,"We present efficient and reliable molecular dynamics simulations of the
photodissociation of dichloromethane followed by Coulomb explosion. These
simulations are performed by calculating trajectories on accurate potential
energy surfaces of the low-lying excited states of the neutral dichloromethane
molecule. The subsequent time-resolved Coulomb explosions are simulated on the
triply charged ionic state, assuming Coulomb interactions between ionic
fragments. Both the neutral state trajectories and the simulated Coulomb
explosion observables indicate that intra-molecular photoisomerization of
dichloromethane is unlikely to occur. Estimating the kinetic energy release
using \textit{ab initio} ionic potential reveals a discrepancy of approximately
5-8 eV compared to our simulated values using Coulomb potential. The molecular
structural changes during photodissociation are clearly mapped to the
ionic-fragment coincidence signals, demonstrating the Coulomb explosion imaging
technique as a powerful tool to probe the time-resolved reaction dynamics.",http://arxiv.org/abs/2501.07479v1
"Computing Safety Margins of Parameterized Nonlinear Systems for
  Vulnerability Assessment via Trajectory Sensitivities",2025-01-13T17:16:34Z,Michael W. Fisher,"Physical systems experience nonlinear disturbances which have the potential
to disrupt desired behavior. For a particular disturbance, whether or not the
system recovers from the disturbance to a desired stable equilibrium point
depends on system parameter values, which are typically uncertain and
time-varying. Therefore, to quantify proximity to vulnerability we define the
safety margin to be the smallest change in parameter values from a nominal
value such that the system will no longer be able to recover from the
disturbance. Safety margins are valuable but challenging to compute as related
methods, such as those for robust region of attraction estimation, are often
either overly conservative or computationally intractable for high dimensional
systems. Recently, we developed algorithms to compute safety margins
efficiently and non-conservatively by exploiting the large sensitivity of the
system trajectory near the region of attraction boundary to small
perturbations. Although these algorithms have enjoyed empirical success, they
lack theoretical guarantees that would ensure their generalizability. This work
develops a novel characterization of safety margins in terms of trajectory
sensitivities, and uses this to derive well-posedness and convergence
guarantees for these algorithms, enabling their generalizability and successful
application to a large class of nonlinear systems.",http://arxiv.org/abs/2501.07498v1
"Floquet-engineered system-reservoir interaction in the transverse field
  Ising model",2025-01-13T17:58:34Z,"Maritza Ahumada, Natalia Valderrama-Quinteros, Guillermo Romero","Periodically driving a quantum many-body system can drastically change its
properties, leading to exotic non-equilibrium states of matter without a static
analog. In this scenario, parametric resonances and the complexity of an
interacting many-body system are pivotal in establishing non-equilibrium
states. We report on a Floquet-engineered transverse field Ising model for the
controlled propagation in one dimension of spin waves. The underlying
mechanisms behind our proposal rely on high-frequency drivings using
characteristic parametric resonances of the spin lattice. Many-body resonances
modulating spin-sping exchange or individual spin gaps inhibit interactions
between spins thus proving a mechanism for controlling spin-wave propagation
and a quantum switch. Our schemes may have applications in coupling-decoupling
schemes for system-reservoir interaction, and routing in quantum networks.",http://arxiv.org/abs/2501.07527v2
disco: Distributional Synthetic Controls,2025-01-13T18:36:38Z,"Florian Gunsilius, David Van Dijcke","The method of synthetic controls is widely used for evaluating causal effects
of policy changes in settings with observational data. Often, researchers aim
to estimate the causal impact of policy interventions on a treated unit at an
aggregate level while also possessing data at a finer granularity. In this
article, we introduce the new disco command, which implements the
Distributional Synthetic Controls method introduced in Gunsilius (2023). This
command allows researchers to construct entire synthetic distributions for the
treated unit based on an optimally weighted average of the distributions of the
control units. Several aggregation schemes are provided to facilitate clear
reporting of the distributional effects of the treatment. The package offers
both quantile-based and CDF-based approaches, comprehensive inference
procedures via bootstrap and permutation methods, and visualization
capabilities. We empirically illustrate the use of the package by replicating
the results in Van Dijcke et al. (2024).",http://arxiv.org/abs/2501.07550v2
Decoding Musical Evolution Through Network Science,2025-01-13T18:39:44Z,"Niccolo' Di Marco, Edoardo Loru, Alessandro Galeazzi, Matteo Cinelli, Walter Quattrociocchi","Music has always been central to human culture, reflecting and shaping
traditions, emotions, and societal changes. Technological advancements have
transformed how music is created and consumed, influencing tastes and the music
itself. In this study, we use Network Science to analyze musical complexity.
Drawing on $\approx20,000$ MIDI files across six macro-genres spanning nearly
four centuries, we represent each composition as a weighted directed network to
study its structural properties. Our results show that Classical and Jazz
compositions have higher complexity and melodic diversity than recently
developed genres. However, a temporal analysis reveals a trend toward
simplification, with even Classical and Jazz nearing the complexity levels of
modern genres. This study highlights how digital tools and streaming platforms
shape musical evolution, fostering new genres while driving homogenization and
simplicity.",http://arxiv.org/abs/2501.07557v1
Zero-temperature phase-flip rate in a biased parametric oscillator,2025-01-13T18:52:18Z,"Daniel K. J. Boneß, Wolfgang Belzig, Mark I. Dykman","A parametrically driven oscillator has two stable vibrational states at half
the modulation frequency. The states have opposite phase and equal amplitudes.
An extra drive at half the modulation frequency provides an effective bias that
lifts the state symmetry. Quantum fluctuations lead to switching between the
states, i.e., to phase-flip transitions. We develop a semiclassical approach
that allows us to find the dependence of the switching rates on the amplitude
of the bias and the parameters of the modulating field. We find that the rate
of switching from a ''shallow'' state can become anomalously small at certain
parameter values, leading to an efficient localization in this state. This is a
consequence of the change of the topology of the oscillator phase trajectories.
The results pave the way for implementing nonreciprocal quantum Ising systems
based on parametric oscillators.",http://arxiv.org/abs/2501.07562v2
"Ultra-Light Dark Matter Simulations and Stellar Dynamics: Tension in
  Dwarf Galaxies for $m < 5\times10^{-21} $ eV",2025-01-13T19:00:02Z,"Luca Teodori, Andrea Caputo, Kfir Blum","We present numerical simulations of dark matter and stellar dynamics in Ultra
Light Dark Matter halos tailored to mimic dwarf galaxies. For dark matter
particle mass $m\approx 1\times 10^{-22}$ eV, dynamical heating causes the
half-light radius to over-shoot surface brightness data of the Fornax galaxy.
For $m\approx 1\times 10^{-21}$ eV, soliton core formation leads to a velocity
dispersion peak incompatible with kinematics data. Extending the analysis to
the Carina and Leo II galaxies, the tension persists up to $m\approx 5\times
10^{-21}$ eV. A caveat in our analysis is the omission of stellar self-gravity.
This would not change dynamics today, but could affect extrapolation back in
time if the stellar body was more compact in the past.",http://arxiv.org/abs/2501.07631v1
A Low-Rank QTT-based Finite Element Method for Elasticity Problems,2025-01-14T01:26:56Z,"Elena Benvenuti, Gianmarco Manzini, Marco Nale, Simone Pizzolato","We present an efficient and robust numerical algorithm for solving the
two-dimensional linear elasticity problem that combines the Quantized Tensor
Train format and a domain partitioning strategy. This approach makes it
possible to solve the linear elasticity problem on a computational domain that
is more general than a square. Our method substantially decreases memory usage
and achieves a notable reduction in rank compared to established Finite Element
implementations like the FEniCS platform. This performance gain, however,
requires a fundamental rethinking of how core finite element operations are
implemented, which includes changes to mesh discretization, node and degree of
freedom ordering, stiffness matrix and internal nodal force assembly, and the
execution of algebraic matrix-vector operations. In this work, we discuss all
these aspects in detail and assess the method's performance in the numerical
approximation of three representative test cases.",http://arxiv.org/abs/2501.07778v1
Waiting Time Solutions in gas dynamics,2025-01-14T04:24:14Z,"Juhi Jang, Jiaqi Liu, Nader Masmoudi","In this article, we construct a continuum family of self-similar waiting time
solutions for the one-dimensional compressible Euler equations for the
adiabatic exponent $\ga\in(1,3)$ in the half-line with the vacuum boundary. The
solutions are confined by a stationary vacuum interface for a finite time with
at least $C^1$ regularity of the velocity and the sound speed up to the
boundary. Subsequently, the solutions undergo the change of the behavior,
becoming only H\""{o}lder continuous near the singular point, and simultaneously
transition to the solutions to the vacuum moving boundary Euler equations
satisfying the physical vacuum condition. When the boundary starts moving, a
weak discontinuity emanating from the singular point along the sonic curve
emerges. The solutions are locally smooth in the interior region away from the
vacuum boundary and the sonic curve.",http://arxiv.org/abs/2501.07831v1
Flow: A Modular Approach to Automated Agentic Workflow Generation,2025-01-14T04:35:37Z,"Boye Niu, Yiliao Song, Kai Lian, Yifan Shen, Yu Yao, Kun Zhang, Tongliang Liu","Multi-agent frameworks powered by large language models (LLMs) have
demonstrated great success in automated planning and task execution. However,
the effective adjustment of Agentic workflows during execution has not been
well-studied. A effective workflow adjustment is crucial, as in many real-world
scenarios, the initial plan must adjust to unforeseen challenges and changing
conditions in real-time to ensure the efficient execution of complex tasks. In
this paper, we define workflows as an activity-on-vertex (AOV) graphs. We
continuously refine the workflow by dynamically adjusting task allocations
based on historical performance and previous AOV with LLM agents. To further
enhance system performance, we emphasize modularity in workflow design based on
measuring parallelism and dependence complexity. Our proposed multi-agent
framework achieved efficient sub-task concurrent execution, goal achievement,
and error tolerance. Empirical results across different practical tasks
demonstrate dramatic improvements in the efficiency of multi-agent frameworks
through dynamic workflow updating and modularization.",http://arxiv.org/abs/2501.07834v1
"Mean-squared Energy Difference for Exploring Potential Energy Landscapes
  of Supercooled Liquids",2025-01-14T07:42:18Z,"Dianmo Zhang, Deyan Sun, Xingao Gong","By extending the concept of diffusion to the potential energy landscapes
(PELs), we introduce the mean-squared energy difference (MSED) as a novel
quantity to investigate the intrinsic properties of glass. MSED can provide a
clear description of the ""energy relaxation"" process on a PEL. Through MSED
analysis, we can obtain characteristic timescale similar to those from
structure analysis, namely $\tau_\alpha^*$. We establish a connection between
MSED and the properties of PELs, providing a concise and quantitative
description of the PEL. We find that the roughness of the accessible PEL has
changed significantly after the glass transition. And we also find that one of
the PEL parameters is closely related to the Adam-Gibbs configurational
entropy. The present research, which directly links the PEL to the relaxation
process, provides avenues for further research of the glass.",http://arxiv.org/abs/2501.07902v1
"Ultrasensitive Higher-Order Exceptional Points via Non-Hermitian
  Zero-Index Materials",2025-01-14T09:47:06Z,"Dongyang Yan, Alexander S. Shalin, Yongxing Wang, Yun Lai, Yadong Xu, Zhi Hong Hang, Fang Cao, Lei Gao, Jie Luo","Higher-order exceptional points (EPs) in optical structures enable
ultra-sensitive responses to perturbations. However, previous investigations on
higher-order EPs have predominantly focused on coupled systems, leaving their
fundamental physics in open scattering systems largely unexplored. Here, we
harness wave interference to realize higher-order EPs in non-Hermitian
zero-index materials connected to multiple open channels. Specifically, we
demonstrate that a three-channel model can give rise to three interesting types
of third-order EPs: lasing EP, reflecting EP, and absorbing EP. Notably, near
the third-order absorbing EP, we observe ultrasensitivity--a drastic change in
output power in response to perturbations at the operating frequency--in a
purely lossy system. These findings pave the way for achieving higher-order and
even arbitrary-order EPs in open scattering systems, offering significant
potential for advanced sensing applications.",http://arxiv.org/abs/2501.07974v1
"Quasiparticle Fermi surfaces of niobium and niobium-titanium alloys at
  high pressure",2025-01-14T11:03:08Z,"D. Jones, A. Östlin, A. Chmeruk, F. Beiuşeanu, U. Eckern, L. Vitos, L. Chioncel","The electronic structure of pure niobium and the niobium-titanium alloy
Nb$_{0.44}$Ti$_{0.56}$ in the bcc-phase at pressures up to $250$ GPa is
investigated, to reveal possible factors conducing toward the robust
superconductivity reported for Ti-doped niobium upon a considerable volume
reduction. We model the structural disorder using the coherent potential
approximation, and the electronic correlations are taken into account using
dynamical mean-field theory. At high pressure, a significant change in the
topology of the Fermi surface is observed, while electronic correlations weaken
with increasing pressure. Thus, the normal state of Nb$_{0.44}$Ti$_{0.56}$ is
found to be a Fermi liquid with a well-defined Fermi surface, and well-defined
quasiparticles near it. The systematic study of the impact of disorder upon the
Fermi surface at such ultra high pressures allows notable insights into the
nature of the electronic states near the Fermi level, i.e., within the energy
scale relevant for superconducting pairing. Furthermore, our results clearly
indicate the necessity of further experimental Fermi surface explorations.",http://arxiv.org/abs/2501.08012v1
"Rigidity, volume and angle structures of 1-3 type hyperbolic polyhedral
  3-manifolds",2025-01-14T12:49:30Z,"Feng Ke, Ge Huabin, Liu Chunlei","In this paper, we study the rigidity of hyperbolic polyhedral 3-manifolds and
the volume optimization program of angle structures. We first study the
rigidity of decorated 1-3 type hyperbolic polyhedral metrics on 3-manifolds
which are isometric gluing of decorated 1-3 type hyperbolic tetrahedra. Here a
1-3 type hyperbolic tetrahedron is a truncated hyperbolic tetrahedron with one
hyperideal vertex and three ideal vertices. A decorated 1-3 type polyhedron is
a 1-3 type hyperbolic polyhedron with a horosphere centered at each ideal
vertex. We show that a decorated 1-3 type hyperbolic polyhedral metric is
determined up to isometry and change of decorations by its curvature. We also
prove several results on the volume optimization program of Casson and Rivin,
i,e. Casson-Rivin's volume optimization program is shown to be still valid for
1-3 type ideal triangulated 3-manifolds. We also get a strongly 1-efficiency
triangulation when assuming the existence of an angle structure. On the whole,
we follow the spirit of Luo-Yang's work in 2018 to prove our main results. The
main differences come from that the hyperbolic tetrahedra considered here have
completely different geometry with those considered in Luo-Yang's work in 2018.",http://arxiv.org/abs/2501.08081v1
"A Time- and Space-Efficient Heuristic Approach for Late Train-Crew
  Rescheduling",2025-01-14T13:11:15Z,"Liyun Yu, Carl Henrik Häll, Anders Peterson, Christiane Schmidt","In this paper, we reschedule the duties of train drivers one day before the
operation. Due to absent drivers (e.g., because of sick leave), some trains
have no driver. Thus, duties need to be rescheduled for the day of operation.
We start with a feasible crew schedule for each of the remaining operating
drivers, a set of unassigned tasks originally assigned to the absent drivers,
and a group of standby drivers with fixed start time, end time, start depot,
and end depot. Our aim is to generate a crew schedule with as few canceled or
changed tasks as possible. We present a tabu-search-based approach for crew
rescheduling. We also adapt a column-generation approach with the same
objective function and equivalent restrictions as the benchmark for comparing
the results, computational time, and space usage. Our tabu-search-based
approach needs both less computation time and space than the column-generation
approach to compute an acceptable result. We further test the performance of
our approach under different settings. The data used in the experiments
originated from a regional passenger-train system around Stockholm, Sweden and
was provided by M\""alart\r{a}g.",http://arxiv.org/abs/2501.08098v1
Gapless higher-order topology and corner states in Floquet systems,2025-01-14T14:45:07Z,"Longwen Zhou, Rongtao Wang, Jiaxin Pan","Higher-order topological phases (HOTPs) possess localized and
symmetry-protected eigenmodes at corners and along hinges in two and three
dimensional lattices. The numbers of these topological boundary modes will
undergo quantized changes at the critical points between different HOTPs. In
this work, we reveal unique higher-order topology induced by time-periodic
driving at the critical points of topological phase transitions, which has no
equilibrium counterparts and also goes beyond the description of gapped
topological matter. Using an alternately coupled Creutz ladder and its
Floquet-driven descendants as illustrative examples, we analytically
characterize and numerically demonstrate the zero and $\pi$ corner modes that
could emerge at the critical points between different Floquet HOTPs. Moreover,
we propose a unified scheme of bulk-corner correspondence for both gapless and
gapped Floquet HOTPs protected by chiral symmetry in two dimensions. Our work
reveals the possibility of corner modes surviving topological transitions in
Floquet systems and initializes the study of higher-order Floquet topology at
quantum criticality.",http://arxiv.org/abs/2501.08164v2
Efficient Dataframe Systems: Lazy Fat Pandas on a Diet,2025-01-14T15:46:35Z,"Bhushan Pal Singh, Priyesh Kumar, Chiranmoy Bhattacharya, S. Sudarshan","Pandas is widely used for data science applications, but users often run into
problems when datasets are larger than memory. There are several frameworks
based on lazy evaluation that handle large datasets, but the programs have to
be rewritten to suit the framework, and the presence of multiple frameworks
complicates the life of a programmer. In this paper we present a framework that
allows programmers to code in plain Pandas; with just two lines of code changed
by the user, our system optimizes the program using a combination of
just-in-time static analysis, and runtime optimization based on a lazy
dataframe wrapper framework. Moreover, our system allows the programmer to
choose the backend. It works seamlessly with Pandas, Dask, and Modin, allowing
the choice of the best-suited backend for an application based on factors such
as data size. Performance results on a variety of programs show the benefits of
our framework.",http://arxiv.org/abs/2501.08207v1
"Quantum-Corrected Hawking Radiation from Near-Extremal Kerr-Newman Black
  Holes",2025-01-14T16:50:43Z,"Sabyasachi Maulik, Xin Meng, Leopoldo A. Pando Zayas","Near-extremal black holes have a long AdS$_2$ throat in their near-horizon
region. Quantum fluctuations in the throat region are effectively governed by a
quantum version of Jackiw-Teitelboim gravity with matter and are strongly
coupled at low temperatures. We investigate how these quantum fluctuations
affect the spectrum of emission of particles during Hawking radiation. We
systematically consider the cases of Kerr and Kerr-Newman black holes for
emission of scalar particles and discuss photon and graviton emission from the
Kerr background. We find that at very low temperatures the quantum fluctuations
radically change the nature of particle emission. Unlike the generic
suppression of particle emission in the spherically symmetric
Reissner-Nordstr\""om case, we uncover that for particles with non-vanishing
angular momentum, the quantum-corrected emission can be substantially enhanced
with respect to the standard semiclassical result.",http://arxiv.org/abs/2501.08252v1
FDPP: Fine-tune Diffusion Policy with Human Preference,2025-01-14T17:15:27Z,"Yuxin Chen, Devesh K. Jha, Masayoshi Tomizuka, Diego Romeres","Imitation learning from human demonstrations enables robots to perform
complex manipulation tasks and has recently witnessed huge success. However,
these techniques often struggle to adapt behavior to new preferences or changes
in the environment. To address these limitations, we propose Fine-tuning
Diffusion Policy with Human Preference (FDPP). FDPP learns a reward function
through preference-based learning. This reward is then used to fine-tune the
pre-trained policy with reinforcement learning (RL), resulting in alignment of
pre-trained policy with new human preferences while still solving the original
task. Our experiments across various robotic tasks and preferences demonstrate
that FDPP effectively customizes policy behavior without compromising
performance. Additionally, we show that incorporating Kullback-Leibler (KL)
regularization during fine-tuning prevents over-fitting and helps maintain the
competencies of the initial policy.",http://arxiv.org/abs/2501.08259v1
"Two- versus three-body approach to femtoscopic hadron-deuteron
  correlations",2025-01-14T17:58:23Z,Stanislaw Mrowczynski,"The three-body approach to hadron-deuteron correlations is shown to turn into
a two-body approach if the three-particle hadron-deuteron wave function
factorizes into the deuteron wave-function and the wave function of a hadron
motion relative to the deuteron. Then, the hadron-deuteron correlation function
is as in the two-body approach only the source radius somewhat changes. For
this reason, as we argue, the two-body approach works well for kaon-deuteron
correlations but it fails for proton-deuteron ones in case of small sources.
Applying the three-body approach generalized to the case where the radius of
the hadron source is different from the nucleon source radius, we derive the
source radius formula which used in the two-body approach gives the correlation
function as in the `factorized' three-body one. The formula is discussed in the
context of existing and future experimental data.",http://arxiv.org/abs/2501.08283v1
"A GPU-Accelerated Distributed Algorithm for Optimal Power Flow in
  Distribution Systems",2025-01-14T18:13:36Z,"Minseok Ryu, Geunyeong Byeon, Kibaek Kim","We propose a GPU-accelerated distributed optimization algorithm for
controlling multi-phase optimal power flow in active distribution systems with
dynamically changing topologies. To handle varying network configurations and
enable adaptable decomposition, we advocate a componentwise decomposition
strategy. However, this approach can lead to a prolonged computation time
mainly due to the excessive iterations required for achieving consensus among a
large number of fine-grained components. To overcome this, we introduce a
technique that segregates equality constraints from inequality constraints,
enabling GPU parallelism to reduce per-iteration time by orders of magnitude,
thereby significantly accelerating the overall computation. Numerical
experiments on IEEE test systems ranging from 13 to 8500 buses demonstrate the
superior scalability of the proposed approach compared to its CPU-based
counterparts.",http://arxiv.org/abs/2501.08293v1
"Continuation methods as a tool for parameter inference in
  electrophysiology modeling",2025-01-13T23:23:55Z,"Matt J Owen, Gary R Mirams","Parameterizing mathematical models of biological systems often requires
fitting to stable periodic data. In cardiac electrophysiology this typically
requires converging to a stable action potential through long simulations. We
explore this problem through the theory of dynamical systems, bifurcation
analysis and continuation methods; under which a converged action potential is
a stable limit cycle. Various attempts have been made to improve the efficiency
of identifying these limit cycles, with limited success. We demonstrate that
continuation methods can more efficiently infer the converged action potential
as proposed model parameter sets change during optimization or inference
routines. In an example electrophysiology model this reduces parameter
inference computation time by 70%. We also discuss theoretical considerations
and limitations of continuation method use in place of time-consuming model
simulations. The application of continuation methods allows more robust
optimization by making extra runs from multiple starting locations
computationally tractable, and facilitates the application of inference methods
such as Markov Chain Monte Carlo to gain more information on the plausible
parameter space.",http://arxiv.org/abs/2501.08355v1
"Weight Averaging for Out-of-Distribution Generalization and Few-Shot
  Domain Adaptation",2025-01-14T10:04:05Z,Shijian Xu,"Empirical risk minimization (ERM) is not robust to changes in the
distribution of data. When the distribution of test data is different from that
of training data, the problem is known as out-of-distribution generalization.
Recently, two techniques have been developed for addressing out-of-distribution
generalization in computer vision: weight averaging (WA) and sharpness-aware
minimization (SAM). WA involves training multiple models with different
hyperparameters and then averaging the weights of these models, which can
significantly improve out-of-distribution generalization performance. SAM
optimizes a neural network to find minima in flat regions, which have been
proven to perform well under distribution shifts. While these techniques have
made great progress, there is still room for improvement and further
exploration. In this thesis, we propose increasing the model diversity in WA
explicitly by introducing gradient similarity as a loss regularizer to further
improve out-of-distribution generalization performance. We also propose
combining WA and SAM to solve the problem of few-shot domain adaptation. Our
extensive experiments on digits datasets (MNIST, SVHN, USPS, MNIST-M) and other
domain adaptation datasets (VLCS, PACS) show that combining WA and SAM leads to
improved out-of-distribution generalization performance and significantly
increases few-shot domain adaptation accuracy.",http://arxiv.org/abs/2501.08361v1
"Polarimetric searches for axion dark matter and high-frequency
  gravitational waves using optical cavities",2025-01-14T19:00:04Z,"Camilo García-Cely, Luca Marsili, Andreas Ringwald, Aaron D. Spector","We revisit birefringence effects associated with the evolution of the
polarization of light as it propagates through axion dark matter or the
background of a passing gravitational wave (GW). We demonstrate that this can
be described by a unified formalism, highlighting a synergy between searches
for axions and high-frequency GWs. We show that by exploiting this framework,
the optical cavities used by the ALPS II experiment can potentially probe axion
masses in the range $m_a \sim 10^{-9} - 10^{-6} \, \mathrm{eV}$, offering
competitive sensitivity with existing laboratory and astrophysical searches.
Also building on this approach, we propose using these optical cavities to
search for high-frequency GWs by measuring changes in the polarization of their
laser. This makes it a promising method for exploring, in the near future, GWs
with frequencies above $100$ MHz and strain sensitivities on the order of
$10^{-14} \, \mathrm{Hz}^{-1/2}$. Such sensitivity allows the exploration of
currently unconstrained parameter space, complementing other high-frequency GW
experiments. This work contributes to the growing community investigating novel
approaches for high-frequency GW detection.",http://arxiv.org/abs/2501.08382v1
"Pressure-induced topological changes in Fermi surface of two-dimensional
  molecular conductor",2025-01-15T07:54:25Z,"T. Kobayashi, K. Yoshimi, H. Ma, S. Sekine, H. Taniguchi, N. Matsunaga, A. Kawamoto, Y. Uwatoko","We demonstrated X-ray structural analysis of the pressure-induced
superconductor, $\beta'$-ET$_2$ICl$_2$ under extremely high-pressure
conditions, where ET denotes bis(ethylenedithio)tetrathiafulvalene. This
material has been known as the highest transition temperature ($T_c$)
superconductor among organic superconductors ($T_c=14.2$ K at $8.2$ GPa). On
the basis of the experimental results, ab-initio models were derived using the
constrained random phase approximation. We revealed that the Lifshitz
transition exists behind the Mott insulator-metal transition and found that the
value of the on-site Coulomb interaction was halved to around $10$ GPa compared
to that at ambient pressure. This study clarifies the enigmatic origins of high
$T_{\rm c}$, and concurrently, provides a new understanding of the impacts of
structural alterations in organic materials under high pressure on their
electronic properties and the superconductivity process.",http://arxiv.org/abs/2501.08635v1
"A Spatio-Temporal Dirichlet Process Mixture Model on Linear Networks for
  Crime Data",2025-01-15T09:05:40Z,"Sujeong Lee, Won Chang, Jorge Mateu, Heejin Lee, Jaewoo Park","Analyzing crime events is crucial to understand crime dynamics and it is
largely helpful for constructing prevention policies. Point processes specified
on linear networks can provide a more accurate description of crime incidents
by considering the geometry of the city. We propose a spatio-temporal Dirichlet
process mixture model on a linear network to analyze crime events in Valencia,
Spain. We propose a Bayesian hierarchical model with a Dirichlet process prior
to automatically detect space-time clusters of the events and adopt a
convolution kernel estimator to account for the network structure in the city.
From the fitted model, we provide crime hotspot visualizations that can inform
social interventions to prevent crime incidents. Furthermore, we study the
relationships between the detected cluster centers and the city's amenities,
which provides an intuitive explanation of criminal contagion.",http://arxiv.org/abs/2501.08673v1
"The Physics of Life: Exploring Information as a Distinctive Feature of
  Living Systems",2025-01-15T09:24:06Z,"Stuart Bartlett, Andrew W. Eckford, Matthew Egbert, Manasvi Lingam, Artemy Kolchinsky, Adam Frank, Gourab Ghoshal","This paper explores the idea that information is an essential and distinctive
feature of living systems. Unlike non-living systems, living systems actively
acquire, process, and use information about their environments to respond to
changing conditions, sustain themselves, and achieve other intrinsic goals. We
discuss relevant theoretical frameworks such as ``semantic information'' and
``fitness value of information''. We also highlight the broader implications of
our perspective for fields such as origins-of-life research and astrobiology.
In particular, we touch on the transition to information-driven systems as a
key step in abiogenesis, informational constraints as determinants of planetary
habitability, and informational biosignatures for detecting life beyond Earth.
We briefly discuss experimental platforms which offer opportunities to
investigate these theoretical concepts in controlled environments. By
integrating theoretical and experimental approaches, this perspective advances
our understanding of life's informational dynamics and its universal principles
across diverse scientific domains.",http://arxiv.org/abs/2501.08683v1
Neuromorphic Retina: An FPGA-based Emulator,2025-01-15T16:45:45Z,"Prince Phillip, Pallab Kumar Nath, Kapil Jainwal, Andre van Schaik, Chetan Singh Thakur","Implementing accurate models of the retina is a challenging task,
particularly in the context of creating visual prosthetics and devices.
Notwithstanding the presence of diverse artificial renditions of the retina,
the imperative task persists to pursue a more realistic model. In this work, we
are emulating a neuromorphic retina model on an FPGA. The key feature of this
model is its powerful adaptation to luminance and contrast, which allows it to
accurately emulate the sensitivity of the biological retina to changes in light
levels. Phasic and tonic cells are realizable in the retina in the simplest way
possible. Our FPGA implementation of the proposed biologically inspired digital
retina, incorporating a receptive field with a center-surround structure, is
reconfigurable and can support 128*128 pixel images at a frame rate of 200fps.
It consumes 1720 slices, approximately 3.7k Look-Up Tables (LUTs), and
Flip-Flops (FFs) on the FPGA. This implementation provides a high-performance,
low-power, and small-area solution and could be a significant step forward in
the development of biologically plausible retinal prostheses with enhanced
information processing capabilities",http://arxiv.org/abs/2501.08943v1
"Intelligent Anti-Money Laundering Solution Based upon Novel Community
  Detection in Massive Transaction Networks on Spark",2025-01-08T02:57:08Z,"Xurui Li, Xiang Cao, Xuetao Qiu, Jintao Zhao, Jianbin Zheng","Criminals are using every means available to launder the profits from their
illegal activities into ostensibly legitimate assets. Meanwhile, most
commercial anti-money laundering systems are still rule-based, which cannot
adapt to the ever-changing tricks. Although some machine learning methods have
been proposed, they are mainly focused on the perspective of abnormal behavior
for single accounts. Considering money laundering activities are often involved
in gang criminals, these methods are still not intelligent enough to crack down
on criminal gangs all-sidedly. In this paper, a systematic solution is
presented to find suspicious money laundering gangs. A temporal-directed
Louvain algorithm has been proposed to detect communities according to relevant
anti-money laundering patterns. All processes are implemented and optimized on
Spark platform. This solution can greatly improve the efficiency of anti-money
laundering work for financial regulation agencies.",http://arxiv.org/abs/2501.09026v1
Higher Representations and Quark Confinement,2025-01-15T19:00:01Z,"Finn Gagliano, Andrea Grigoletto, Kantaro Ohmori","The concept of a (de)confined phase in QFT is well-defined in the presence of
$1$-form symmetries and their spontaneous symmetry breaking. However, in
scenarios where such symmetries are absent, confinement is not a well-defined
phase property. In this work, we propose that, when restricting to a specific
submanifold of the parameter space -- namely at zero temperature and fixed
quark mass -- the confined and adjoint Higgs phases of scalar QCD can be
distinguished through the different organization of their spectra, as seen from
the perspective of the baryon symmetry. The analysis is performed in terms of
an appropriate higher-categorical representation theory, recently developed for
generalized symmetries. Consistent with expectations, we find that the confined
phase permits only particles with integer baryon charges, while the Higgs phase
is characterized by the coexistence of bare quarks and center vortices,
exhibiting a non-trivial Aharonov-Bohm effect between these excitations.",http://arxiv.org/abs/2501.09069v2
"Observational evidence of anisotropic changes apparent resistivity
  before strong earthquakes",2025-01-15T20:27:27Z,"Jianguo Zhang, Wei Du, Mingxin Yue, Chenghui Liu, Xiaolong Liang, Jun Yang","Using a method based on normalized monthly variation rate, we studied
resistivity data of seven observation stations before the events in the
epicenter areas of two strong earthquakes. The relationship between variation
of anisotropic apparent resistivity and the azimuth of the maximum principal
stress is analyzed. The study shows that significant apparent resistivity
variation occurs in the direction that is perpendicular to the azimuth of the
maximum principal stress while only small fluctuation are recorded in the
direction of the maximum principal stress. We surmise that the variation of
anisotropic resistivity occurs in the late stage of the development of a strong
earthquake, which can be observed in the epicenter area. If the density of the
observation stations is increased and the direction of the observed resistivity
is right, the epicenter of an earthquake location may be estimated by the
observed resistivity anomaly.",http://arxiv.org/abs/2501.09131v1
Towards Understanding Extrapolation: a Causal Lens,2025-01-15T21:29:29Z,"Lingjing Kong, Guangyi Chen, Petar Stojanov, Haoxuan Li, Eric P. Xing, Kun Zhang","Canonical work handling distribution shifts typically necessitates an entire
target distribution that lands inside the training distribution. However,
practical scenarios often involve only a handful of target samples, potentially
lying outside the training support, which requires the capability of
extrapolation. In this work, we aim to provide a theoretical understanding of
when extrapolation is possible and offer principled methods to achieve it
without requiring an on-support target distribution. To this end, we formulate
the extrapolation problem with a latent-variable model that embodies the
minimal change principle in causal mechanisms. Under this formulation, we cast
the extrapolation problem into a latent-variable identification problem. We
provide realistic conditions on shift properties and the estimation objectives
that lead to identification even when only one off-support target sample is
available, tackling the most challenging scenarios. Our theory reveals the
intricate interplay between the underlying manifold's smoothness and the shift
properties. We showcase how our theoretical results inform the design of
practical adaptation algorithms. Through experiments on both synthetic and
real-world data, we validate our theoretical findings and their practical
implications.",http://arxiv.org/abs/2501.09163v1
"The Veln(ia)s is in the Details: Evaluating LLM Judgment on Latvian and
  Lithuanian Short Answer Matching",2025-01-15T21:30:03Z,"Yevhen Kostiuk, Oxana Vitman, Łukasz Gagała, Artur Kiulian","In this work, we address the challenge of evaluating large language models
(LLMs) on the short answer matching task for Latvian and Lithuanian languages.
We introduce novel datasets consisting of 502 Latvian and 690 Lithuanian
question-answer pairs. For each question-answer pair, we generated matched and
non-matched answers using a set of alteration rules specifically designed to
introduce small but meaningful changes in the text. These generated answers
serve as test cases to assess the ability of LLMs to detect subtle differences
in matching of the original answers. A subset of the datasets was manually
verified for quality and accuracy. Our results show that while larger LLMs,
such as QWEN2.5 72b and LLaMa3.1 70b, demonstrate near-perfect performance in
distinguishing matched and non-matched answers, smaller models show more
variance. For instance, LLaMa3.1 8b and EuroLLM 9b benefited from few-shot
examples, while Mistral Nemo 12b underperformed on detection of subtle text
alteration, particularly in Lithuanian, even with additional examples. QWEN2.5
7b and Mistral 7b were able to obtain a strong and comparable performance to
the larger 70b models in zero and few shot experiments. Moreover, the
performance of Mistral 7b was weaker in few shot experiments.",http://arxiv.org/abs/2501.09164v1
Provenance Guided Rollback Suggestions,2025-01-16T01:15:21Z,"David Zhao, Pavle Subotic, Mukund Raghothaman, Bernhard Scholz","Advances in incremental Datalog evaluation strategies have made Datalog
popular among use cases with constantly evolving inputs such as static analysis
in continuous integration and deployment pipelines. As a result, new logic
programming debugging techniques are needed to support these emerging use
cases.
  This paper introduces an incremental debugging technique for Datalog, which
determines the failing changes for a \emph{rollback} in an incremental setup.
Our debugging technique leverages a novel incremental provenance method. We
have implemented our technique using an incremental version of the Souffl\'{e}
Datalog engine and evaluated its effectiveness on the DaCapo Java program
benchmarks analyzed by the Doop static analysis library. Compared to
state-of-the-art techniques, we can localize faults and suggest rollbacks with
an overall speedup of over 26.9$\times$ while providing higher quality results.",http://arxiv.org/abs/2501.09225v1
Dispersive dark excitons in van der Waals ferromagnet CrI3,2025-01-16T02:10:39Z,"W. He, J. Sears, F. Barantani, T. Kim, J. W. Villanova, T. Berlijn, M. Lajer, M. A. McGuire, J. Pelliciari, V. Bisogni, S. Johnston, E. Baldini, M. Mitrano, M. P. M. Dean","Spin-flip dark excitons are optical-dipole-forbidden quasiparticles with
remarkable potential in optoelectronics, especially when they are realized
within cleavable van der Waals materials. Despite this potential, dark excitons
have not yet been definitively identified in ferromagnetic van der Waals
materials. Here, we report two dark excitons in a model ferromagnetic material
CrI3 using high-resolution resonant inelastic x-ray scattering (RIXS) and show
that they feature narrower linewidths compared to the bright excitons
previously reported in this material. These excitons are shown to have
spin-flip character, to disperse as a function of momentum, and to change
through the ferromagnetic transition temperature. Given the versatility of van
der Waals materials, these excitons hold promise for new types of
magneto-optical functionality.",http://arxiv.org/abs/2501.09244v1
Clone-Robust AI Alignment,2025-01-16T02:43:44Z,"Ariel D. Procaccia, Benjamin Schiffer, Shirley Zhang","A key challenge in training Large Language Models (LLMs) is properly aligning
them with human preferences. Reinforcement Learning with Human Feedback (RLHF)
uses pairwise comparisons from human annotators to train reward functions and
has emerged as a popular alignment method. However, input datasets in RLHF are
not necessarily balanced in the types of questions and answers that are
included. Therefore, we want RLHF algorithms to perform well even when the set
of alternatives is not uniformly distributed. Drawing on insights from social
choice theory, we introduce robustness to approximate clones, a desirable
property of RLHF algorithms which requires that adding near-duplicate
alternatives does not significantly change the learned reward function. We
first demonstrate that the standard RLHF algorithm based on regularized maximum
likelihood estimation (MLE) fails to satisfy this property. We then propose the
weighted MLE, a new RLHF algorithm that modifies the standard regularized MLE
by weighting alternatives based on their similarity to other alternatives. This
new algorithm guarantees robustness to approximate clones while preserving
desirable theoretical properties.",http://arxiv.org/abs/2501.09254v1
"RoboReflect: Robotic Reflective Reasoning for Grasping
  Ambiguous-Condition Objects",2025-01-16T05:40:37Z,"Zhen Luo, Yixuan Yang, Chang Cai, Yanfu Zhang, Feng Zheng","As robotic technology rapidly develops, robots are being employed in an
increasing number of fields. However, due to the complexity of deployment
environments or the prevalence of ambiguous-condition objects, the practical
application of robotics still faces many challenges, leading to frequent
errors. Traditional methods and some LLM-based approaches, although improved,
still require substantial human intervention and struggle with autonomous error
correction in complex scenarios.In this work, we propose RoboReflect, a novel
framework leveraging large vision-language models (LVLMs) to enable
self-reflection and autonomous error correction in robotic grasping tasks.
RoboReflect allows robots to automatically adjust their strategies based on
unsuccessful attempts until successful execution is achieved.The corrected
strategies are saved in a memory for future task reference.We evaluate
RoboReflect through extensive testing on eight common objects prone to
ambiguous conditions of three categories.Our results demonstrate that
RoboReflect not only outperforms existing grasp pose estimation methods like
AnyGrasp and high-level action planning techniques using GPT-4V but also
significantly enhances the robot's ability to adapt and correct errors
independently. These findings underscore the critical importance of autonomous
selfreflection in robotic systems while effectively addressing the challenges
posed by ambiguous environments.",http://arxiv.org/abs/2501.09307v1
Discovery of anomalous nuclear effect on electron transfer between atoms,2025-01-16T08:20:54Z,"Sota Kimura, Michiharu Wada, Hiromitsu Haba, Hironobu Ishiyama, Toshitaka Niwase, Marco Rosenbusch, Peter Schury","Among the known isotope effects in chemistry, electron spin conversion by
nuclear spin is a potent mechanism governing the reactions of radical pairs.
For the electron transfer between nonradical(s), this spin conversion does not
work, and other isotope effects have been presumed to have negligible
contributions. However, we have observed a nuclear-state-dependence anomaly in
ion charge state distributions in the thermalization of energetic atomic ions
in helium gas, the process between nonradical(s). It could be understood to
arise from the change in the stability of the intermediate quasi-molecule state
of the electron transfer caused by the difference in nuclear states. This
should prompt a reconsideration of the influence of atomic nuclei on
interatomic and intermolecular interactions.",http://arxiv.org/abs/2501.09364v1
Factorization of solutions of linear differential equations,2025-01-16T12:41:57Z,Janne Gröhn,"This paper supplements recents results on linear differential equations
$f''+Af=0$, where the coefficient $A$ is analytic in the unit disc of the
complex plane $\mathbb{C}$. It is shown that, if $A$ is analytic and
$|A(z)|^2(1-|z|^2)^3\, dm(z)$ is a Carleson measure, then all non-trivial
solutions of $f''+Af=0$ can be factorized as $f=Be^g$, where $B$ is a Blaschke
product whose zero-sequence $\Lambda$ is uniformly separated and where
$g\in{\rm BMOA}$ satisfies the interpolation property $$g'(z_n) = -\frac{1}{2}
\, \frac{B''(z_n)}{B'(z_n)}, \quad z_n\in\Lambda.$$ Among other things, this
factorization implies that all solutions of $f''+Af=0$ are functions in a Hardy
space and have no singular inner factors.
  Zero-free solutions play an important role as their maximal growth is similar
to the general case. The study of zero-free solutions produces a new result on
Riccati differential equations.",http://arxiv.org/abs/2501.09508v2
"Analyzing Continuous Semantic Shifts with Diachronic Word Similarity
  Matrices",2025-01-16T13:42:09Z,"Hajime Kiyama, Taichi Aida, Mamoru Komachi, Toshinobu Ogiso, Hiroya Takamura, Daichi Mochihashi","The meanings and relationships of words shift over time. This phenomenon is
referred to as semantic shift. Research focused on understanding how semantic
shifts occur over multiple time periods is essential for gaining a detailed
understanding of semantic shifts. However, detecting change points only between
adjacent time periods is insufficient for analyzing detailed semantic shifts,
and using BERT-based methods to examine word sense proportions incurs a high
computational cost. To address those issues, we propose a simple yet intuitive
framework for how semantic shifts occur over multiple time periods by
leveraging a similarity matrix between the embeddings of the same word through
time. We compute a diachronic word similarity matrix using fast and lightweight
word embeddings across arbitrary time periods, making it deeper to analyze
continuous semantic shifts. Additionally, by clustering the similarity matrices
for different words, we can categorize words that exhibit similar behavior of
semantic shift in an unsupervised manner.",http://arxiv.org/abs/2501.09538v2
Core Hours and Carbon Credits: Incentivizing Sustainability in HPC,2025-01-16T14:19:46Z,"Alok Kamatar, Maxime Gonthier, Valerie Hayot-Sasson, Andre Bauer, Marcin Copik, Torsten Hoefler, Raul Castro Fernandez, Kyle Chard, Ian Foster","Realizing a shared responsibility between providers and consumers is critical
to manage the sustainability of HPC. However, while cost may motivate
efficiency improvements by infrastructure operators, broader progress is
impeded by a lack of user incentives. We conduct a survey of HPC users that
reveals fewer than 30 percent are aware of their energy consumption, and that
energy efficiency is among users' lowest priority concerns. One explanation is
that existing pricing models may encourage users to prioritize performance over
energy efficiency. We propose two transparent multi-resource pricing schemes,
Energy- and Carbon-Based Accounting, that seek to change this paradigm by
incentivizing more efficient user behavior. These two schemes charge for
computations based on their energy consumption or carbon footprint,
respectively, rewarding users who leverage efficient hardware and software. We
evaluate these two pricing schemes via simulation, in a prototype, and a user
study.",http://arxiv.org/abs/2501.09557v1
"Almost sharp variational estimates for discrete truncated operators of
  Carleson type",2025-01-16T14:40:01Z,"Jiecheng Chen, Renhui Wan","We establish $r$-variational estimates for discrete truncated Carleson-type
operators on $\ell^p$ for $1<p<\infty$. Notably, these estimates are sharp and
enhance the results obtained by Krause and Roos (J. Eur. Math. Soc. 2022, J.
Funct. Anal. 2023), up to a logarithmic loss related to the scale. On the other
hand, as $r$ approaches infinity, the consequences align with the estimates
proved by Krause and Roos. Moreover, for the case of quadratic phases, we
remove this logarithmic loss with respect to the scale, at the cost of
increasing $p$ slightly.",http://arxiv.org/abs/2501.09564v2
"Reducing the Sensitivity of Neural Physics Simulators to Mesh Topology
  via Pretraining",2025-01-16T15:21:18Z,"Nathan Vaska, Justin Goodwin, Robin Walters, Rajmonda S. Caceres","Meshes are used to represent complex objects in high fidelity physics
simulators across a variety of domains, such as radar sensing and aerodynamics.
There is growing interest in using neural networks to accelerate physics
simulations, and also a growing body of work on applying neural networks
directly to irregular mesh data. Since multiple mesh topologies can represent
the same object, mesh augmentation is typically required to handle topological
variation when training neural networks. Due to the sensitivity of physics
simulators to small changes in mesh shape, it is challenging to use these
augmentations when training neural network-based physics simulators. In this
work, we show that variations in mesh topology can significantly reduce the
performance of neural network simulators. We evaluate whether pretraining can
be used to address this issue, and find that employing an established
autoencoder pretraining technique with graph embedding models reduces the
sensitivity of neural network simulators to variations in mesh topology.
Finally, we highlight future research directions that may further reduce neural
simulator sensitivity to mesh topology.",http://arxiv.org/abs/2501.09597v1
"Supersolid dipolar phases in planar geometry: effects of tilted
  polarization",2025-01-16T16:30:11Z,"Daniel Lima, Matheus Grossklags, Vinicius Zampronio, Fabio Cinti, Alejandro Mendoza-Coto","The behavior of dipolar Bose-Einstein condensates in planar geometries is
investigated, focusing on the effects of the polarization orientation. While
perpendicular polarization produces a phase diagram with hexagonal, stripes,
and honeycomb phases ending at a single critical point, the presence of an
in-plane polarization component transforms the critical point into three
critical lines, separating two phases at a time and changing radically the
appearance of the phase diagram. All transition lines contain first- and
second-order regions, while the phase diagram itself shows a resemblance with
those displayed by quasi-one-dimensional dipolar systems. Finally, we
investigate the effect of introducing an in-plane polarization on the
structural properties of the phases and determine the superfluid fraction. Our
results show that this process induces an axial deformation on the hexagonal
and honeycomb phases, resulting in an anisotropic behavior in the long distance
properties of the system like superfluidity. We expect that the rich
phenomenology observed provides motivation for new experiments and theoretical
works.",http://arxiv.org/abs/2501.09641v1
Aging of colloidal gels in microgravity,2025-01-16T16:46:22Z,"Swagata S. Datta, Waad Paliwal, Eric R. Weeks","We study the aging of colloidal gels using light microscopy movies of
depletion gels from the International Space Station. Under such microgravity
conditions, we observe a slowdown in particle dynamics consistent with gel
aging. Stronger attractive forces promote the formation of thicker gel strands
over time. The samples are bidisperse, composed of particles with a size ratio
1.2. Larger particles experience stronger depletion forces, which lead to a
large first-neighbor peak in the pair correlation function $g(r)$ due to the
prevalence of large-large particle contacts. As the gel ages, small mobile
particles are incorporated into the gel structure. The changes in gel structure
correlate with a slow power-law decay in particle motion, observed over nearly
two orders of magnitude of time scales in microgravity experiments.
Additionally, through complementary ground-based experiments, we compare
two-dimensional (2D) and three-dimensional (3D) images of depletion colloidal
gels. While microgravity gel data are limited to 2D projections, ground-based
data establish a correspondence between the 2D and 3D $g(r)$ peak heights. Our
results provide new insights into how colloidal gels age in the absence of
gravitational collapse.",http://arxiv.org/abs/2501.09650v1
Active particle in a very thin interfacial droplet,2025-01-16T16:47:24Z,"Airi N. Kato, Kaili Xie, Benjamin Gorin, Jean-Michel Rampnoux, Hamid Kellay","A single light-driven Janus particle confined in a very thin oil droplet at
an air--water interface displays intriguing dynamics. While laser activation
induces rapid horizontal motion (1mm/s--1cm/s) by thermal Marangoni flow, the
particle exhibits unexpected periodic circular motions or intermittent
irregular motions. We show that the periodic trajectories are the result of a
coupling between the self-propulsion of the particle and the spatiotemporal
droplet thickness changes. We propose a simple model where the properties of
the active particle trajectories are governed by capillary forces and torques
due to the confinement of the particle in the thin droplet.",http://arxiv.org/abs/2501.09652v1
Stacking disorder in novel ABAC-stacked brochantite,2025-01-16T16:51:34Z,"Aswathi Mannathanath Chakkingal, Chloe Fuller, Maxim Avdeev, Roman Gumeniuk, Marein C. Rahn, Falk Pabst, Yiran Wang, Sergey Granovsky, Artem Korshunov, Dmitry Chernyshov, Dmytro S. Inosov, Darren C. Peets","In geometrically frustrated magnetic systems, weak interactions or slight
changes to the structure can tip the delicate balance of exchange interactions,
sending the system into a different ground state. Brochantite,
Cu$_4$SO$_4$(OH)$_6$, has a copper sublattice composed of distorted triangles,
making it a likely host for frustrated magnetism, but exhibits stacking
disorder. The lack of synthetic single crystals has limited research on the
magnetism in brochantite to powders and natural mineral crystals. We grew
crystals which we find to be a new polytype with a tendency toward ABAC
stacking and some anion disorder, alongside the expected stacking disorder.
Comparison to previous results on natural mineral specimens suggests that
cation disorder is more deleterious to the magnetism than anion and stacking
disorder. Our specific heat data suggest a double transition on cooling into
the magnetically ordered state.",http://arxiv.org/abs/2501.09654v1
"A Survey of Research in Large Language Models for Electronic Design
  Automation",2025-01-16T16:51:59Z,"Jingyu Pan, Guanglei Zhou, Chen-Chia Chang, Isaac Jacobson, Jiang Hu, Yiran Chen","Within the rapidly evolving domain of Electronic Design Automation (EDA),
Large Language Models (LLMs) have emerged as transformative technologies,
offering unprecedented capabilities for optimizing and automating various
aspects of electronic design. This survey provides a comprehensive exploration
of LLM applications in EDA, focusing on advancements in model architectures,
the implications of varying model sizes, and innovative customization
techniques that enable tailored analytical insights. By examining the
intersection of LLM capabilities and EDA requirements, the paper highlights the
significant impact these models have on extracting nuanced understandings from
complex datasets. Furthermore, it addresses the challenges and opportunities in
integrating LLMs into EDA workflows, paving the way for future research and
application in this dynamic field. Through this detailed analysis, the survey
aims to offer valuable insights to professionals in the EDA industry, AI
researchers, and anyone interested in the convergence of advanced AI
technologies and electronic design.",http://arxiv.org/abs/2501.09655v1
"SynthLight: Portrait Relighting with Diffusion Model by Learning to
  Re-render Synthetic Faces",2025-01-16T18:59:48Z,"Sumit Chaturvedi, Mengwei Ren, Yannick Hold-Geoffroy, Jingyuan Liu, Julie Dorsey, Zhixin Shu","We introduce SynthLight, a diffusion model for portrait relighting. Our
approach frames image relighting as a re-rendering problem, where pixels are
transformed in response to changes in environmental lighting conditions. Using
a physically-based rendering engine, we synthesize a dataset to simulate this
lighting-conditioned transformation with 3D head assets under varying lighting.
We propose two training and inference strategies to bridge the gap between the
synthetic and real image domains: (1) multi-task training that takes advantage
of real human portraits without lighting labels; (2) an inference time
diffusion sampling procedure based on classifier-free guidance that leverages
the input portrait to better preserve details. Our method generalizes to
diverse real photographs and produces realistic illumination effects, including
specular highlights and cast shadows, while preserving the subject's identity.
Our quantitative experiments on Light Stage data demonstrate results comparable
to state-of-the-art relighting methods. Our qualitative results on in-the-wild
images showcase rich and unprecedented illumination effects. Project Page:
\url{https://vrroom.github.io/synthlight/}",http://arxiv.org/abs/2501.09756v1
Testing Refactoring Engine via Historical Bug Report driven LLM,2025-01-16T23:31:49Z,"Haibo Wang, Zhuolin Xu, Shin Hwei Tan","Refactoring is the process of restructuring existing code without changing
its external behavior while improving its internal structure. Refactoring
engines are integral components of modern Integrated Development Environments
(IDEs) and can automate or semi-automate this process to enhance code
readability, reduce complexity, and improve the maintainability of software
products. Similar to traditional software systems such as compilers,
refactoring engines may also contain bugs that can lead to unexpected
behaviors. In this paper, we propose a novel approach called RETESTER, a
LLM-based framework for automated refactoring engine testing. Specifically, by
using input program structure templates extracted from historical bug reports
and input program characteristics that are error-prone, we design
chain-of-thought (CoT) prompts to perform refactoring-preserving
transformations. The generated variants are then tested on the latest version
of refactoring engines using differential testing. We evaluate RETESTER on two
most popular modern refactoring engines (i.e., ECLIPSE, and INTELLIJ IDEA). It
successfully revealed 18 new bugs in the latest version of those refactoring
engines. By the time we submit our paper, seven of them were confirmed by their
developers, and three were fixed.",http://arxiv.org/abs/2501.09879v2
"The Evolution of Unobserved Skill Returns in the U.S.: A New Approach
  Using Panel Data",2025-01-17T02:17:17Z,"Lance Lochner, Youngmin Park, Youngki Shin","Economists disagree about the factors driving the substantial increase in
residual wage inequality in the US over the past few decades. To identify
changes in the returns to unobserved skills, we make a novel assumption about
the dynamics of skills rather than about the stability of skill distributions
across cohorts, as is standard. We show that our assumption is supported by
data on test score dynamics for older workers in the HRS. Using survey data
from the PSID and administrative data from the IRS and SSA, we estimate that
the returns to unobserved skills $declined$ substantially in the late-1980s and
1990s despite an increase in residual inequality. Accounting for firm-specific
pay differences yields similar results. Extending our framework to consider
occupational differences in returns to skill and multiple unobserved skills, we
further show that skill returns display similar patterns for workers employed
in each of cognitive, routine, and social occupations. Finally, our results
suggest that increasing skill dispersion, driven by rising skill volatility,
explains most of the growth in residual wage inequality since the 1980s.",http://arxiv.org/abs/2501.09917v1
"Adaptive Twisting Sliding Control for Integrated Attack UAV's Autopilot
  and Guidance",2025-01-17T03:20:39Z,"Minh Tu Nguyen, Van Truong Hoang, Manh Duong Phung, Van Hoa Doan","This paper investigates an adaptive sliding-mode control for an integrated
UAV autopilot and guidance system. First, a two-dimensional mathematical model
of the system is derived by considering the incorporated lateral dynamics and
relative kinematics of the UAV and its potential target of attack. Then, a
sliding surface is derived utilizing the zero-effort miss distance. An adaptive
twisting sliding mode (ATSMC) algorithm is applied to the integrated system.
Simulation and comparisons have been accomplished. The results show our
proposed design performs well in interception precision, even with high
nonlinearity, uncertainties, disturbances, and abrupt changes in the target's
movement, thanks to the adaptation strategy.",http://arxiv.org/abs/2501.09937v1
"Emergent scales and spatial correlations at the yielding transition of
  glassy materials",2025-01-17T08:55:11Z,"Stefano Aime, Domenico Truzzolillo","Glassy materials yield under large external mechanical solicitations. Under
oscillatory shear, yielding shows a well-known rheological fingerprint, common
to samples with widely different microstructures. At the microscale, this
corresponds to a transition between slow, solid-like dynamics and faster
liquid-like dynamics, which can coexist at yielding in a finite range of strain
amplitudes. Here, we capture this phenomenology in a lattice model with two
main parameters: glassiness and disorder, describing the average coupling
between adjacent lattice sites, and their variance, respectively. In absence of
disorder, our model yields a law of correspondent states equivalent to
trajectories on a cusp catastrophe manifold, a well-known class of problems
including equilibrium liquid-vapour phase transitions. Introducing a finite
disorder in our model entails a qualitative change, to a continuous and rounded
transition, whose extent is controlled by the magnitude of the disorder. We
show that a spatial correlation length $\xi$ emerges spontaneously from the
coupling between disorder and bifurcating dynamics. With vanishing disorder,
$\xi$ diverges and yielding becomes discontinuous, suggesting that the
abruptness of yielding can be rationalized in terms of a lengthscale of dynamic
heterogeneities.",http://arxiv.org/abs/2501.10039v1
"Temporal and topological partitioning in real-world growing networks for
  scale-free properties study",2025-01-17T12:12:47Z,Guillaume Rousseau,"We introduce a method to study evolution rules and scale-free hypothesis of
real-world growing networks using natural partitions of nodes and edges based
on temporal and topological attributes, and analyzing degree distributions.
  We apply this method to the Software Heritage dataset, which collects
software releases and revisions from open-source communities. Nodes with native
temporal information does not fully capture the overall network dynamics, and
degree distributions show greater regularity with fewer outliers, suggesting a
more likely scale-free regime when examining networks derived from temporal and
topological partitions.
  However, underlying aging, fitness, and inheritance mechanisms, along with
chosen partitioning, hinder definitive conclusions and suggest that the very
common ``pure parametric power-law'' hypothesis for the tail of degree
distributions is too strong. Node's type derived from partions and changes in
evolution rules, shown by variations in the average number of new edges per
node over time, highlight the need for tools better suited for studying
transient regimes and ease comparison of real-world networks with minimal
models.",http://arxiv.org/abs/2501.10145v1
A scalable event-driven spatiotemporal feature extraction circuit,2025-01-17T12:39:09Z,"Hugh Greatorex, Michele Mastella, Ole Richter, Madison Cotteret, Willian Soares Girão, Ella Janotte, Elisabetta Chicca","Event-driven sensors, which produce data only when there is a change in the
input signal, are increasingly used in applications that require low-latency
and low-power real-time sensing, such as robotics and edge devices. To fully
achieve the latency and power advantages on offer however, similarly
event-driven data processing methods are required. A promising solution is the
TDE: an event-based processing element which encodes the time difference
between events on different channels into an output event stream. In this work
we introduce a novel TDE implementation on CMOS. The circuit is robust to
device mismatch and allows the linear integration of input events. This is
crucial for enabling a high-density implementation of many TDEs on the same
die, and for realising real-time parallel processing of the high-event-rate
data produced by event-driven sensors.",http://arxiv.org/abs/2501.10155v2
Streaming Graph Algorithms in the Massively Parallel Computation Model,2025-01-17T14:51:39Z,"Artur Czumaj, Gopinath Mishra, Anish Mukherjee","We initiate the study of graph algorithms in the streaming setting on massive
distributed and parallel systems inspired by practical data processing systems.
The objective is to design algorithms that can efficiently process evolving
graphs via large batches of edge insertions and deletions using as little
memory as possible.
  We focus on the nowadays canonical model for the study of theoretical
algorithms for massive networks, the Massively Parallel Computation (MPC)
model. We design MPC algorithms that efficiently process evolving graphs: in a
constant number of rounds they can handle large batches of edge updates for
problems such as connectivity, minimum spanning forest, and approximate
matching while adhering to the most restrictive memory regime, in which the
local memory per machine is strongly sublinear in the number of vertices and
the total memory is sublinear in the graph size. These results improve upon
earlier works in this area which rely on using larger total space, proportional
to the size of the processed graph. Our work demonstrates that parallel
algorithms can process dynamically changing graphs with asymptotically optimal
utilization of MPC resources: parallel time, local memory, and total memory,
while processing large batches of edge updates.",http://arxiv.org/abs/2501.10230v1
"Hybrid Deep Learning Model for epileptic seizure classification by using
  1D-CNN with multi-head attention mechanism",2025-01-17T18:33:58Z,"Mohammed Guhdar, Ramadhan J. Mstafa, Abdulhakeem O. Mohammed","Epilepsy is a prevalent neurological disorder globally, impacting around 50
million people \cite{WHO_epilepsy_50million}. Epileptic seizures result from
sudden abnormal electrical activity in the brain, which can be read as sudden
and significant changes in the EEG signal of the brain. The signal can vary in
severity and frequency, which results in loss of consciousness and muscle
contractions for a short period of time \cite{epilepsyfoundation_myoclonic}.
Individuals with epilepsy often face significant employment challenges due to
safety concerns in certain work environments. Many jobs that involve working at
heights, operating heavy machinery, or in other potentially hazardous settings
may be restricted for people with seizure disorders. This certainly limits job
options and economic opportunities for those living with epilepsy.",http://arxiv.org/abs/2501.10342v1
"Realization of tilted Dirac-like microwave cone in superconducting
  circuit lattices",2025-01-12T18:45:10Z,"Amir Youssefi, Ahmad Motavassal, Shingo Kono, Seyed Akbar Jafari, Tobias J. Kippenberg","Dirac-like band crossings are paradigms in condensed matter systems to
emulate high-energy physics phenomena. They are associated with two aspects:
gap and tilting. The ability to design sign-changing gap gives rise to band
topology, whereas the tilting of band crossings which is a gateway for large
gravity-like effects remains uncharted. In this work, we introduce an
experimental platform to realize tilted Dirac-like microwave cone in
large-scale superconducting circuit lattices. The direction and magnitude of
the tilt can be controlled by engineering the axially preferred second neighbor
coupling. We demonstrate three lattices with 731-site LC resonator featuring
tilt values of up to 59% of relative difference in the opposite-direction group
velocities. This is obtained by reconstructing the density of states (DOS) of
measured microwave resonance frequencies. Harnessing the tilt of Dirac-like
band crossings lays the foundation for weaving the fabric of an emergent
solid-state spacetime.",http://arxiv.org/abs/2501.10434v1
"A flatness-based predictive controller for six-degrees of freedom
  spacecraft rendezvous",2025-01-13T14:12:41Z,"Julio C. Sanchez, Francisco Gavilan, Rafael Vazquez, Christophe Louembet","This work presents a closed-loop guidance algorithm for six-degrees of
freedom spacecraft rendezvous with a passive target flying in an eccentric
orbit. The main assumption is that the chaser vehicle has an attitude control
system, based on reaction wheels, providing the necessary torque to change its
orientation whereas the number of thrusters is arbitrary. The goal is to design
fuel optimal maneuvers while satisfying operational constraints and rejecting
disturbances. The proposed method is as follows; first, the coupled
translational and angular dynamics are transformed to equivalent algebraic
relations using the relative translational states transition matrix and the
attitude flatness property. Then, a direct transcription method, based on
B-splines parameterization and discretization of time continuous constraints,
is developed to obtain a tractable static program. Finally, a Model Predictive
Controller, based on linearization around the previously computed solution, is
considered to handle disturbances. Numerical results are shown and discussed.",http://arxiv.org/abs/2501.10436v1
"Quantitative noncontact measurement of thermal Hall angle and transverse
  thermal conductivity by lock-in thermography",2025-01-17T07:01:14Z,"Takumi Imamura, Takamasa Hirai, Koichi Oyanagi, Ryo Iguchi, Kenta Takamori, Satoru Kobayashi, Ken-ichi Uchida","We propose and demonstrate a quantitative noncontact measurement method for
the thermal Hall effect (THE) based on magnetic-field-modulated lock-in
thermography. This method enables visualization of THE-induced temperature
change and quantitative estimation of the thermal Hall angle $\theta_{\rm THE}$
by applying periodic magnetic fields to a sample and obtaining the first
harmonic response of thermal images. By combining this method with LIT-based
measurement techniques for the longitudinal thermal conductivity $\kappa_{xx}$,
we also quantify the transverse thermal conductivity $\kappa_{xy}$. We validate
our measurement methods by estimating $\theta_{\rm THE}$, $\kappa_{xx}$, and
$\kappa_{xy}$ in a ferromagnetic Heusler alloy Co$_2$MnGa slab showing large
THE.",http://arxiv.org/abs/2501.10485v2
"Excited s-wave $1^{--}$ vector mesons, their leptonic decays and
  (in-)complete absence of abnormal states as seen from the constituent quark
  BSE",2025-01-17T15:15:46Z,V. Sauli,"Within a lattice inspired interaction between quark and antiquark, we obtain
hierarchy of Bethe-Salpeter equation (BSE) solutions for vector quarkonia
excited states in the constituent quark mass approximation. As a toy model, we
apply the similar to calculate ground and excited states of $\phi$ and
$\omega/\rho$ meson. Performing detailed numerical search, our study provides
the evidence that the quark propagator with single valued constant mass does
not provide known meson spectra without the presence of abnormal (unphysical)
solutions simultaneously. We classify normal and abnormal solutions and discuss
necessary changes in calculation scheme preventing the spectrum from
inconsistent solutions. While all experimentaly narrow vector mesons are
identified with a normal state of the BSE, the intriguing appearance of mutualy
canceled normal-abnormal states is reported. They appearance discriminate
between heavy and the light mesons. In both cases they seems to be remainder of
inconsitent use of the hmogeneous BSE for the description of broad resonances.",http://arxiv.org/abs/2501.10498v1
"Modeling Changes in Individuals' Cognitive Self-Esteem With and Without
  Access To Search Tools",2025-01-17T19:28:10Z,"Mahir Akgun, Sacip Toker","Search engines, as cognitive partners, reshape how individuals evaluate their
cognitive abilities. This study examines how search tool access influences
cognitive self-esteem (CSE)-users' self-perception of cognitive abilities --
through the lens of transactive memory systems. Using a within-subject design
with 164 participants, we found that CSE significantly inflates when users have
access to search tools, driven by cognitive offloading. Participants with lower
initial CSE exhibited greater shifts, highlighting individual differences.
Search self-efficacy mediated the relationship between prior search experience
and CSE, emphasizing the role of users' past interactions. These findings
reveal opportunities for search engine design: interfaces that promote
awareness of cognitive offloading and foster self-reflection can support
accurate metacognitive evaluations, reducing overreliance on external tools.
This research contributes to HCI by demonstrating how interactive systems shape
cognitive self-perception, offering actionable insights for designing
human-centered tools that balance user confidence and cognitive independence.",http://arxiv.org/abs/2501.10517v1
"Perfect, Pretty Good and Optimized Quantum State Transfer in Transmon
  qubit chains",2025-01-17T22:16:41Z,"Pablo Serra, Alejandro Ferrón, Omar Osenda","Chains of transmon qubits are considered promising systems to implement
different quantum information tasks. In particular as channels that perform
high-quality quantum state transfer. We study how changing the interaction
strength between the chain qubits allows us to obtain perfect or pretty good
state transfer and present explicit analytic expressions for their transmission
fidelity. For particular values of the interactions between the qubits,
transmon chains are equivalent to generalized SSH chains and show the
traditional traits observed in chains with topological states, localized states
at the extremes of the chain, and eigenvalues that lie inside the spectral gap.
Consequently, we study the quantum state transfer on chains with dimerized
interactions, looking for chains with fast transfer times. We show that, in
many cases, asking for fast transfer times results in chains with dimerized
interactions that do not have topological states.",http://arxiv.org/abs/2501.10580v1
"ColorGrid: A Multi-Agent Non-Stationary Environment for Goal Inference
  and Assistance",2025-01-17T22:55:33Z,"Andrey Risukhin, Kavel Rao, Ben Caffee, Alan Fan","Autonomous agents' interactions with humans are increasingly focused on
adapting to their changing preferences in order to improve assistance in
real-world tasks. Effective agents must learn to accurately infer human goals,
which are often hidden, to collaborate well. However, existing Multi-Agent
Reinforcement Learning (MARL) environments lack the necessary attributes
required to rigorously evaluate these agents' learning capabilities. To this
end, we introduce ColorGrid, a novel MARL environment with customizable
non-stationarity, asymmetry, and reward structure. We investigate the
performance of Independent Proximal Policy Optimization (IPPO), a
state-of-the-art (SOTA) MARL algorithm, in ColorGrid and find through extensive
ablations that, particularly with simultaneous non-stationary and asymmetric
goals between a ``leader'' agent representing a human and a ``follower''
assistant agent, ColorGrid is unsolved by IPPO. To support benchmarking future
MARL algorithms, we release our environment code, model checkpoints, and
trajectory visualizations at https://github.com/andreyrisukhin/ColorGrid.",http://arxiv.org/abs/2501.10593v1
"Effect of Magnetic Field on Aqueous Humor Flows Inside Anterior Chamber
  of Human Eye",2025-01-18T10:24:51Z,"Deepak Kumar, Subramaniam Pushpavanam","Aqueous humor (AH) dynamics is responsible for maintaining intraocular
pressure, ocular health and targeted drug delivery within the eye. This study
investigates the flow of AH within the anterior chamber (AC) under the combined
influence of a uniform magnetic field and natural convection. Different
orientations of the magnetic field and temperaature gradient are considered. A
lubrication approximation is employed and the resulting equations are solved
using regular perturbation method. The analytical solutions are validated using
numerical simulations performed in COMSOL Multiphysics 6.2. In the standing
position, AH flow field is characterised by a single vortex, while in the
supine position, it forms two counter-rotating vortices. The velocity is found
to be higher in standing position. The effect of a uniform magnetic field on
the velocity is more significant in the supine position. The magnetic field
does not change the flow field qualitatively as buoyancy is the primary driving
force. In the standing position a magnetic field oriented perpendicular to the
eye resulted in a greatest reduction of AH velocity, as compared to a magnetic
field along the eye. This study is a step towards holistic approach for
targeted drug delivery using magnetic fields in eye.",http://arxiv.org/abs/2501.10717v1
"Some results of CCD-photometry of variable stars at the Astronomical
  Institute of Karazin Kharkiv National University",2025-01-18T12:52:01Z,"V. G. Shevchenko, D. O. Danylko, I. G. Slyusarev, R. A. Chigladze","We presented photometric observations for the one UV Ceti type and three W
Ursae Majoris-type variable stars. The flare of the UV Ceti type star lasted
about two hours, and the star changed magnitude to 3.9 within about two
minutes. The values of color indices V-R, the rotational periods and the
composite lightcurves have been obtained for the EW stars. Using a relation of
an absolute magnitude-period obtained by Mateo and Rucinski (2017) and
interstellar extinction from the three-dimensional map of Milky Way dust
(http://argonaut.skymaps.info) and Green et al. (2019), we have calculated the
absolute magnitudes of the EW stars and distances to them. The parallaxes
obtained from our data differ from those given in Gaia DR 3, which may be due
to insufficient quality calibration of the absolute magnitude-period relation
and with the estimations of interstellar extinction.",http://arxiv.org/abs/2501.10754v1
"Model Monitoring in the Absence of Labeled Data via Feature Attributions
  Distributions",2025-01-18T14:07:37Z,Carlos Mougan,"Model monitoring involves analyzing AI algorithms once they have been
deployed and detecting changes in their behaviour. This thesis explores machine
learning model monitoring ML before the predictions impact real-world decisions
or users. This step is characterized by one particular condition: the absence
of labelled data at test time, which makes it challenging, even often
impossible, to calculate performance metrics.
  The thesis is structured around two main themes: (i) AI alignment, measuring
if AI models behave in a manner consistent with human values and (ii)
performance monitoring, measuring if the models achieve specific accuracy goals
or desires.
  The thesis uses a common methodology that unifies all its sections. It
explores feature attribution distributions for both monitoring dimensions.
Using these feature attribution explanations, we can exploit their theoretical
properties to derive and establish certain guarantees and insights into model
monitoring.",http://arxiv.org/abs/2501.10774v2
"The working principles of model-based GAs fall within the PAC framework:
  A mathematical theory of problem decomposition",2025-01-18T14:18:15Z,"Tian-Li Yu, Chi-Hsien Chang, Ying-ping Chen","The concepts of linkage, building blocks, and problem decomposition have long
existed in the genetic algorithm (GA) field and have guided the development of
model-based GAs for decades. However, their definitions are usually vague,
making it difficult to develop theoretical support. This paper provides an
algorithm-independent definition to describe the concept of linkage. With this
definition, the paper proves that any problems with a bounded degree of linkage
are decomposable and that proper problem decomposition is possible via linkage
learning. The way of decomposition given in this paper also offers a new
perspective on nearly decomposable problems with bounded difficulty and
building blocks from the theoretical aspect. Finally, this paper relates
problem decomposition to PAC learning and proves that the global optima of
these problems and the minimum decomposition blocks are PAC learnable under
certain conditions.",http://arxiv.org/abs/2501.10777v1
Automated Selfish Mining Analysis for DAG-based PoW Consensus Protocols,2025-01-18T21:57:02Z,Patrik Keller,"Selfish mining is strategic rule-breaking to maximize rewards in
proof-of-work protocols. Markov Decision Processes (MDPs) are the preferred
tool for finding optimal strategies in Bitcoin and similar linear chain
protocols. Protocols increasingly adopt DAG-based chain structures, for which
MDP analysis is more involved. To date, researchers have tailored specific MDPs
for each protocol. Protocol design suffers long feedback loops, as each
protocol change implies manual work on the MDP. To overcome this, we propose a
generic attack model that covers a wide range of protocols, including Ethereum
Proof-of-Work, GhostDAG, and Parallel Proof-of-Work. Our approach is modular:
we specify each protocol as a concise program, and our tooling then derives and
solves the selfish mining MDP automatically.",http://arxiv.org/abs/2501.10888v1
Generative Physical AI in Vision: A Survey,2025-01-19T03:19:47Z,"Daochang Liu, Junyu Zhang, Anh-Dung Dinh, Eunbyung Park, Shichao Zhang, Chang Xu","Generative Artificial Intelligence (AI) has rapidly advanced the field of
computer vision by enabling machines to create and interpret visual data with
unprecedented sophistication. This transformation builds upon a foundation of
generative models to produce realistic images, videos, and 3D or 4D content.
Traditionally, generative models primarily focus on visual fidelity while often
neglecting the physical plausibility of generated content. This gap limits
their effectiveness in applications requiring adherence to real-world physical
laws, such as robotics, autonomous systems, and scientific simulations. As
generative AI evolves to increasingly integrate physical realism and dynamic
simulation, its potential to function as a ""world simulator"" expands-enabling
the modeling of interactions governed by physics and bridging the divide
between virtual and physical realities. This survey systematically reviews this
emerging field of physics-aware generative AI in computer vision, categorizing
methods based on how they incorporate physical knowledge-either through
explicit simulation or implicit learning. We analyze key paradigms, discuss
evaluation protocols, and identify future research directions. By offering a
comprehensive overview, this survey aims to help future developments in
physically grounded generation for vision. The reviewed papers are summarized
at https://github.com/BestJunYu/Awesome-Physics-aware-Generation.",http://arxiv.org/abs/2501.10928v1
Issues with Neural Tangent Kernel Approach to Neural Networks,2025-01-19T03:21:06Z,"Haoran Liu, Anthony Tai, David J. Crandall, Chunfeng Huang","Neural tangent kernels (NTKs) have been proposed to study the behavior of
trained neural networks from the perspective of Gaussian processes. An
important result in this body of work is the theorem of equivalence between a
trained neural network and kernel regression with the corresponding NTK. This
theorem allows for an interpretation of neural networks as special cases of
kernel regression. However, does this theorem of equivalence hold in practice?
  In this paper, we revisit the derivation of the NTK rigorously and conduct
numerical experiments to evaluate this equivalence theorem. We observe that
adding a layer to a neural network and the corresponding updated NTK do not
yield matching changes in the predictor error. Furthermore, we observe that
kernel regression with a Gaussian process kernel in the literature that does
not account for neural network training produces prediction errors very close
to that of kernel regression with NTKs. These observations suggest the
equivalence theorem does not hold well in practice and puts into question
whether neural tangent kernels adequately address the training process of
neural networks.",http://arxiv.org/abs/2501.10929v1
"The anomalous density of states and quasi-localized vibration through
  homogeneous thermalization of an inhomogeneous elastic system",2025-01-19T05:05:28Z,Cunyuan Jiang,"Amorphous solids are dynamically inhomogeneous due to in lack of
translational symmetry and hence exhibit vibrational properties different from
crystalline solids with anomalous low frequency vibrational density of states
(VDOS) and related low temperature thermal properties. However, an
interpretation of their origin from basic physical laws is still needed
compared with rapidly progressed particle level investigations. In this work,
we start with the quasi-equilibrium condition, which requires elastic potential
energy to be homogeneously distributed even in an inhomogeneous elastic solid
over long time observation. Analytical result shows that the anomalous low
frequency VDOS behavior $D(\omega) \propto \omega^4$ can be obtained when the
quasi-equilibrium condition is satisfied on an inhomogeneous elastic system.
Under high frequency after a crossover depending on the length scale of
inhomogeneity, the power law of VDOS is changed to square $D(\omega) \propto
\omega^2$ which is Debye's law for crystalline solids. These features agree
with recent particle level investigations. Our work suggest that the universal
low frequency anomaly of amorphous solids can be considered as a result of
homogeneous thermalization.",http://arxiv.org/abs/2501.10947v1
"Ambient Backscatter Communication in LTE Uplink Sounding Reference
  Signal",2025-01-19T05:36:21Z,"Jingyi Liao, Tianshu Zhang, Kalle Ruttik, Riku Jäntti, Dinh-Thuy Phan-Huy","Ambient Internet of Things (AIoT), recently standardized by the 3rd
Generation Partnership Project (3GPP), demands a low-power wide-area
communication solution that operates several orders of magnitude below the
power requirements of existing 3GPP specifications. Ambient backscatter
communication (AmBC) is considered as a competitive potential technique by
harvesting energy from the ambient RF signal. This paper considers a symbiotic
AmBC into Long Term Evolution (LTE) cellular system uplink. Leveraging by LTE
uplink channel estimation ability, AIoT conveys its own message to Base Station
(BS) by modulating backscatter path. We explore the detector design, analyze
the error performance of the proposed scheme, provide exact expression and its
Guassian approximation for the error probability. We corroborate the receiver
error performance by Monte Carlo simulation. Analysis of communication range
reveals AmBC achieves a reasonable BER of order of magnitude $10^{-2}$ within
four times wavelength reading distance. In addition, a AmBC prototype in LTE
uplink confirms the its feasibility. The over-the-air experiment results
validate theoretical analysis. Hence, the proposed AmBC approach enables AIoT
deployment with minimal changes to the LTE system.",http://arxiv.org/abs/2501.10952v1
"The thermodynamic stability and phase structure of the
  Einstein-Euler-Heisenberg-AdS black holes",2025-01-19T15:26:13Z,"Yinan Zhao, Hongbo Cheng","In both canonical ensemble and grand canonical ensemble, the thermodynamic
stability and phase structure of Einstein-Euler-Heisenberg-AdS black hole are
studied. We derive the Hawking temperature, Helmholtz free energy, Gibbs
potential, entropy and heat capacity of the black holes. We compute the minimum
temperature to find that the phase transition may happen at the lowest point.
The entropy-temperature diagram consists of two parts. The upper part belonging
to the large black holes under the influence from the electromagnetic
self-interactions keeps the positive heat capacity, leading the huge compact
objects to survive. The lower curves corresponding to the small ones show that
the heat capacity of the tiny black holes is negative, which means that the
nonlinear-effect-corrected smaller sources will evaporate. The further
discussions show that the nonlinear effect modifies the thermodynamic
quantities, but the corrections limited by the nonlinear factor $\mu$ with
allowed values can not change the properties and the phase structure
fundamentally and thoroughly. We argue that the influence from self-interaction
can not make the Einstein-Euler-Heisenberg-AdS black holes to split under the
second law of thermodynamics.",http://arxiv.org/abs/2501.11075v1
"Direct Expression for One-Loop Tensor Reduction with Lorentz Indices via
  Generating Function",2025-01-19T19:23:56Z,"Chang Hu, Yifan Hu, Jiyuan Shen","In recent work, we derived a direct expression for one-loop tensor reduction
using generating functions and Feynman parametrization in projective space,
avoiding recursive relations. However, for practical applications, this
expression still presents two challenges: (1) While the final reduction
coefficients are expressed in terms of the dimension D and Mandelstam
variables, the given expression explicitly contains irrational functions; (2)
The expression involves an auxiliary vector R, which can be eliminated via
differentiation $\frac{\partial}{\partial R}$, but the presence of irrational
terms making differentiation cumbersome. (3) Most practical applications
require the tensor form with Lorentz indices.
  In this paper, we provide a rational form of the reduction coefficients with
Lorentz indices, free from recursion. Additionally, We provide a pure Wolfram
Mathematica implementation of the code. Our practical tests demonstrate that
this direct expression achieves significantly higher computational efficiency
compared to the traditional Passarino-Veltman (PV) reduction or other
recursion-based methods.",http://arxiv.org/abs/2501.11150v1
"Remote characterization of aerogel foam concrete using dynamic speckle
  pattern analysis",2025-01-19T21:18:46Z,"Ramin Jamali, Mohammad Hadi Sadri, Ali-Reza Moradi","Aerogel foam concrete (AFC) has garnered significant attention in recent
years due to its exceptional thermal insulation, lightweight structure, and
versatility in construction applications. However, the durability of this
material in various chemical environments, particularly acidic and alkaline
solutions, remains a critical concern for its long-term performance. In this
study, we employed an advanced remote characterization technique-dynamic
speckle pattern analysis-to monitor and quantify the degradation and corrosion
processes of AFC under these conditions. Using this non-invasive method, we
extracted valuable statistical parameters, including the time history of
speckle patterns, co-occurrence matrix, inertia moment, Pearson correlation,
and roughness indices, to provide a comprehensive analysis of surface and
structural changes. Our findings reveal that AFC exposed to acidic environments
undergoes faster degradation and more severe surface damage compared to
alkaline environments, as demonstrated through $\textit{in situ}$ and remote
characterization. These results underscore the importance of understanding
material behavior in diverse conditions, offering critical insights for
improving the durability of AFC in various applications.",http://arxiv.org/abs/2501.11172v1
"Spontaneous spatial sorting by cell shape in growing colonies of
  rod-like bacteria",2025-01-19T21:29:32Z,"Mateusz Ratman, Jimmy Gonzalez Nuñez, Daniel A. Beller","Mechanical interactions among cells in a growing microbial colony can
significantly influence the colony's spatial genetic structure and, thus,
evolutionary outcomes such as the fates of rare mutations. Here, we
computationally investigate how this spatial genetic structure changes as a
result of heritable phenotypic variations in cell shape. By modeling rod-like
bacterial cells as lengthening and dividing circo-rectangles in a 2D Brownian
dynamics framework, we simulate the growth of a colony containing two
populations with different aspect ratios. Compared to monodisperse colonies,
such bidisperse colonies exhibit diminished intermixing between sub-populations
when the less elongated cells are too short to nematically order, instead
forming large clusters. We find that the cells with longer aspect ratio
gradually segregate to the colony periphery. We present evidence that this
demixing is related to nematic order in the bulk and to active nematic mixing
dynamics near the periphery. These findings are qualitatively robust across
different growth rate protocols and initial conditions. Because the periphery
is often an advantageous position when nutrients are limited, our results
suggest a possible evolutionary selective pressure of mechanical origin that
favors large cell aspect ratio.",http://arxiv.org/abs/2501.11177v1
Local Limits of Small World Networks,2025-01-20T02:21:37Z,"Yeganeh Alimohammadi, Senem Işık, Amin Saberi","Small-world networks, known for their high local clustering and short average
path lengths, are a fundamental structure in many real-world systems, including
social, biological, and technological networks. We apply the theory of local
convergence (Benjamini-Schramm convergence) to derive the limiting behavior of
the local structures for two of the most commonly studied small-world network
models: the Watts-Strogatz model and the Kleinberg model. Establishing local
convergence enables us to show that key network measures, such as PageRank,
clustering coefficients, and maximum matching size, converge as network size
increases with their limits determined by the graph's local structure.
Additionally, this framework facilitates the estimation of global phenomena,
such as information cascades, using local information from small neighborhoods.
As an additional outcome of our results, we observe a critical change in the
behavior of the limit exactly when the parameter governing long-range
connections in the Kleinberg model crosses the threshold where decentralized
search remains efficient, offering a new perspective on why decentralized
algorithms fail in certain regimes.",http://arxiv.org/abs/2501.11226v1
"Mode shapes and sensitivity analysis of torsional vibrations in
  overhang- and T-shaped microcantilevers",2025-01-20T03:46:27Z,"Le Tri Dat, Vinh N. T. Pham, Nguyen Duy Vy","The torsional mode of atomic force microscope (AFM) cantilevers plays a
crucial role in a wide range of sensitive measurements. Despite their
importance, the use of approximated frequencies and mode shapes for
width-varying cantilevers often results in discrepancies between theoretical
models and experimental observations. In this study, we present an analytical
approach to accurately calculate the mode shapes and resonance frequencies of
these cantilevers, including higher-order modes, then we derive the modal
sensitivity. Our results reveal distinct changes in mode shapes and frequencies
as the overhang length increases, with the mode shapes showing multiple maxima.
Furthermore, we demonstrate that tuning the overhang length provides effective
control over the resonant frequency. The relationship between modal sensitivity
and the coupling strength between the cantilever and the surface is also
established, aligning with previous experimental findings. This work offers
valuable insights for optimizing cantilever geometry to achieve desired
frequency responses in AFM applications.",http://arxiv.org/abs/2501.11256v1
"In-medium bottomonium properties from lattice NRQCD calculations with
  extended meson operators",2025-01-20T03:52:13Z,"H. -T. Ding, W. -P. Huang, R. Larsen, S. Meinel, Swagato Mukherjee, P. Petreczky, Zhanduo Tang","We calculate the temperature dependence of bottomonium correlators in
(2+1)-flavor lattice QCD with the aim to constrain in-medium properties of
bottomonia at high temperature. The lattice calculations are performed using
HISQ action with physical strange quark mass and light quark masses twenty
times smaller than the strange quark mass at two lattice spacings $a=0.0493$ fm
and $0.0602$ fm, and temporal extents $N_{\tau}=16-30$, corresponding to the
temperatures $T=133-250$ MeV. We use a tadpole-improved NRQCD action including
spin-dependent $v^6$ corrections for the heavy quarks and extended meson
operators in order to be sensitive to in-medium properties of the bottomonium
states of interest. We find that within estimated errors the bottomonium masses
do not change compared to their vacuum values for all temperatures under our
consideration; however, we find different nonzero widths for the various
bottomonium states.",http://arxiv.org/abs/2501.11257v1
"Multiply iterated Poisson processes and their applications in ruin
  theory",2025-01-20T07:54:49Z,"Dongdong Hu, Svetlozar T. Rachev, Hasanjan Sayit, Hailiang Yang, Yildiray Yildirim","This paper studies the properties of the Multiply Iterated Poisson Process
(MIPP), a stochastic process constructed by repeatedly time-changing a Poisson
process, and its applications in ruin theory. Like standard Poisson processes,
MIPPs have exponentially distributed sojourn times (waiting times between
jumps). We explicitly derive the probabilities of all possible jump sizes at
the first jump and obtain the Laplace transform of the joint distribution of
the first jump time and its corresponding jump size. In ruin theory, the
classical Cram\'er-Lundberg model assumes claims arrive independently according
to a Poisson process. In contrast, our model employs MIPP to allow for
clustered arrivals, reflecting real-world scenarios, such as catastrophic
events. Under this new framework, we derive the corresponding scale function in
closed form, facilitating accurate ruin probability calculations in the
presence of clustered claims. These results improve the modeling of extreme
risks and have practical implications for insurance solvency assessments,
reinsurance pricing, and capital reserve estimation.",http://arxiv.org/abs/2501.11322v1
CME Observations -- from Sun to Impact on Geospace,2025-01-20T09:09:50Z,Manuela Temmer,"Our Sun is an active star expelling dynamic phenomena known as coronal mass
ejections (CMEs). The magnetic field configuration on the Sun and related solar
wind structures affect the propagation behavior of CMEs, dominate its transit
time and embedded magnetic field properties when impacting Earth. Since the
conditions on the Sun constantly change, the impact of CMEs on the different
regimes of geospace is quite variable and may differ significantly from event
to event. This short review summarizes the different manifestations of CMEs on
the Sun, their appearance in interplanetary space, and how CMEs trigger a
cascade of reactions as they interact with Earth.",http://arxiv.org/abs/2501.11345v1
"A Multidimensional Elasticity Framework for Adaptive Data Analytics
  Management in the Computing Continuum",2025-01-20T09:56:26Z,"Sergio Laso, Ilir Murturi, Pantelis Frangoudis, Juan Luis Herrera, Juan M. Murillo, Schahram Dustdar","The increasing complexity of IoT applications and the continuous growth in
data generated by connected devices have led to significant challenges in
managing resources and meeting performance requirements in computing continuum
architectures. Traditional cloud solutions struggle to handle the dynamic
nature of these environments, where both infrastructure demands and data
analytics requirements can fluctuate rapidly. As a result, there is a need for
more adaptable and intelligent resource management solutions that can respond
to these changes in real-time. This paper introduces a framework based on
multi-dimensional elasticity, which enables the adaptive management of both
infrastructure resources and data analytics requirements. The framework
leverages an orchestrator capable of dynamically adjusting architecture
resources such as CPU, memory, or bandwidth and modulating data analytics
requirements, including coverage, sample, and freshness. The framework has been
evaluated, demonstrating the impact of varying data analytics requirements on
system performance and the orchestrator's effectiveness in maintaining a
balanced and optimized system, ensuring efficient operation across edge and
head nodes.",http://arxiv.org/abs/2501.11369v1
"Steady state and mixing of two run-and-tumble particles interacting
  through jamming and attractive forces",2025-01-20T10:15:13Z,Leo Hahn,"We study the long-time behavior of two run-and-tumble particles on the real
line subjected to an attractive interaction potential and jamming interactions,
which prevent the particles from crossing. We provide the explicit invariant
measure, a useful tool for studying clustering phenomena in out-ofequilibrium
statistical mechanics, for different tumbling mechanisms and potentials. An
important difference with invariant measures of equilibrium systems are Dirac
masses on the boundary of the state space, due to the jamming interactions.
Qualitative changes in the invariant measure depending on model parameters are
also observed, suggesting, like a growing body of evidence, that run-andtumble
particle systems can be classified into close-to-equilibrium and strongly
out-of-equilibrium models. We also study the relaxation properties of the
system, which are linked to the timescale at which clustering emerges from an
arbitrary initial configuration. When the interaction potential is linear, we
show that the total variation distance to the invariant measure decays
exponentially and provide sharp bounds on the decay rate. When the interaction
potential is harmonic, we give quantitative exponential bounds in a
Wasserstein-type distance.",http://arxiv.org/abs/2501.11379v1
"Generalization and Informativeness of Weighted Conformal Risk Control
  Under Covariate Shift",2025-01-20T11:26:36Z,"Matteo Zecchin, Fredrik Hellström, Sangwoo Park, Shlomo Shamai, Osvaldo Simeone","Predictive models are often required to produce reliable predictions under
statistical conditions that are not matched to the training data. A common type
of training-testing mismatch is covariate shift, where the conditional
distribution of the target variable given the input features remains fixed,
while the marginal distribution of the inputs changes. Weighted conformal risk
control (W-CRC) uses data collected during the training phase to convert point
predictions into prediction sets with valid risk guarantees at test time
despite the presence of a covariate shift. However, while W-CRC provides
statistical reliability, its efficiency -- measured by the size of the
prediction sets -- can only be assessed at test time. In this work, we relate
the generalization properties of the base predictor to the efficiency of W-CRC
under covariate shifts. Specifically, we derive a bound on the inefficiency of
the W-CRC predictor that depends on algorithmic hyperparameters and
task-specific quantities available at training time. This bound offers insights
on relationships between the informativeness of the prediction sets, the extent
of the covariate shift, and the size of the calibration and training sets.
Experiments on fingerprinting-based localization validate the theoretical
results.",http://arxiv.org/abs/2501.11413v1
"Multitask Auxiliary Network for Perceptual Quality Assessment of
  Non-Uniformly Distorted Omnidirectional Images",2025-01-20T14:41:29Z,"Jiebin Yan, Jiale Rao, Junjie Chen, Ziwen Tan, Weide Liu, Yuming Fang","Omnidirectional image quality assessment (OIQA) has been widely investigated
in the past few years and achieved much success. However, most of existing
studies are dedicated to solve the uniform distortion problem in OIQA, which
has a natural gap with the non-uniform distortion problem, and their ability in
capturing non-uniform distortion is far from satisfactory. To narrow this gap,
in this paper, we propose a multitask auxiliary network for non-uniformly
distorted omnidirectional images, where the parameters are optimized by jointly
training the main task and other auxiliary tasks. The proposed network mainly
consists of three parts: a backbone for extracting multiscale features from the
viewport sequence, a multitask feature selection module for dynamically
allocating specific features to different tasks, and auxiliary sub-networks for
guiding the proposed model to capture local distortion and global quality
change. Extensive experiments conducted on two large-scale OIQA databases
demonstrate that the proposed model outperforms other state-of-the-art OIQA
metrics, and these auxiliary sub-networks contribute to improve the performance
of the proposed model. The source code is available at
https://github.com/RJL2000/MTAOIQA.",http://arxiv.org/abs/2501.11512v1
"Investigating the Scalability of Approximate Sparse Retrieval Algorithms
  to Massive Datasets",2025-01-20T17:59:21Z,"Sebastian Bruch, Franco Maria Nardini, Cosimo Rulli, Rossano Venturini, Leonardo Venuta","Learned sparse text embeddings have gained popularity due to their
effectiveness in top-k retrieval and inherent interpretability. Their
distributional idiosyncrasies, however, have long hindered their use in
real-world retrieval systems. That changed with the recent development of
approximate algorithms that leverage the distributional properties of sparse
embeddings to speed up retrieval. Nonetheless, in much of the existing
literature, evaluation has been limited to datasets with only a few million
documents such as MSMARCO. It remains unclear how these systems behave on much
larger datasets and what challenges lurk in larger scales. To bridge that gap,
we investigate the behavior of state-of-the-art retrieval algorithms on massive
datasets. We compare and contrast the recently-proposed Seismic and graph-based
solutions adapted from dense retrieval. We extensively evaluate Splade
embeddings of 138M passages from MsMarco-v2 and report indexing time and other
efficiency and effectiveness metrics.",http://arxiv.org/abs/2501.11628v1
"Boundary Quantum Field Theories Perturbed by ${\rm T}\bar{\rm T}$:
  Towards a Form Factor Program",2025-01-20T18:25:01Z,"Olalla A. Castro-Alvaredo, Stefano Negro, Fabio Sailis","Our understanding of irrelevant perturbations of integrable quantum field
theories has greatly expanded over the last decade. In particular, we know
that, from a scattering theory viewpoint at least, their effect is realised as
a modification the two-body scattering amplitudes by a CDD factor. While this
sounds like a relatively small change, this CDD factor incorporates a
non-trivial dependence on the perturbation parameter(s) and alters
substantially the high-energy physics of the model. This occurs through the
introduction of a natural length scale and is associated with phenomena such as
the Hagedorn transition. In this paper we discuss how all these features extend
to boundary integrable quantum field theories and propose a construction for
the building blocks of matrix elements of local fields. We show that the same
type of building blocks are also found in the sinh-Gordon model with Dirichlet
boundary conditions.",http://arxiv.org/abs/2501.11647v1
"Less Wound and More Asymmetric: JWST Confirms the Evolution of Spiral
  Structure in Galaxies at $z \lesssim 3$",2025-01-20T18:54:30Z,"Ilia V. Chugunov, Alexander A. Marchuk, Aleksandr V. Mosenkov","Spiral galaxies are ubiquitous in the local Universe. However the properties
of spiral arms in them are still not well studied, and there is even less
information concerning spiral structure in distant galaxies. We aim to measure
the most general parameters of spiral arms in remote galaxies and trace their
changes with redshift. We perform photometric decomposition, including spiral
arms, for 159 galaxies from the HST COSMOS and JWST CEERS and JADES surveys,
which are imaged in optical and near-infrared rest-frame wavelengths. We
confirm that, in our representative sample of spiral galaxies, the pitch angles
increase, and the azimuthal lengths decrease with increasing redshift, implying
that the spiral structure becomes more tightly wound over time. For the
spiral-to-total luminosity ratio and the spiral width-to-disc scale length
ratio, we find that band-shifting effects can be as significant as, or even
stronger than, evolutionary effects. Additionally, we find that spiral
structure becomes more asymmetric at higher redshifts.",http://arxiv.org/abs/2501.11670v1
"Nehari-type ground state solutions for asymptotically periodic
  bi-harmonic Kirchhoff-type problems in $\mathbb{R}^N$",2025-01-20T19:16:46Z,Antônio de Pádua Farias de Souza Filho,"We investigate the following Kirchhoff-type biharmonic equation
\begin{equation}\label{pr} \left\{ \begin{array}{ll} \Delta^2 u+
\left(a+b\int_{\mathbb{R}^N}|\nabla u|^2d x\right)(-\Delta
u+V(x)u)=f(x,u),\quad x\in \mathbb{R}^N,\\ u\in H^{2}(\mathbb{R}^N),
\end{array} \right. \end{equation} where $a>0$, $b\geq 0$ and $V(x)$ and $f(x,
u)$ are periodic or asymptotically periodic in $x$. We study the existence of
Nehari-type ground state solutions of \eqref{pr} with $f(x,u)u-4F(x,u)$
sign-changing, where $F(x,u):=\int_0^uf(x,s)d s$. We significantly extend some
results from the previous literature.",http://arxiv.org/abs/2501.11693v2
"Transformer Vibration Forecasting for Advancing Rail Safety and
  Maintenance 4.0",2025-01-20T20:29:40Z,"Darío C. Larese, Almudena Bravo Cerrada, Gabriel Dambrosio Tomei, Alejandro Guerrero-López, Pablo M. Olmos, María Jesús Gómez García","Maintaining railway axles is critical to preventing severe accidents and
financial losses. The railway industry is increasingly interested in advanced
condition monitoring techniques to enhance safety and efficiency, moving beyond
traditional periodic inspections toward Maintenance 4.0.
  This study introduces a robust Deep Autoregressive solution that integrates
seamlessly with existing systems to avert mechanical failures. Our approach
simulates and predicts vibration signals under various conditions and fault
scenarios, improving dataset robustness for more effective detection systems.
These systems can alert maintenance needs, preventing accidents preemptively.
We use experimental vibration signals from accelerometers on train axles.
  Our primary contributions include a transformer model, ShaftFormer, designed
for processing time series data, and an alternative model incorporating
spectral methods and enhanced observation models. Simulating vibration signals
under diverse conditions mitigates the high cost of obtaining experimental
signals for all scenarios. Given the non-stationary nature of railway vibration
signals, influenced by speed and load changes, our models address these
complexities, offering a powerful tool for predictive maintenance in the rail
industry.",http://arxiv.org/abs/2501.11730v1
"Preconditioning for a Cahn-Hilliard-Navier-Stokes model for morphology
  formation in organic solar cells",2025-01-20T22:06:58Z,"Pelin Çiloğlu, Carmen Tretmans, Roland Herzog, Jan-F. Pietschmann, Martin Stoll","We present a model for the morphology evolution of printed organic solar
cells which occurs during the drying of a mixture of polymer, the non-fullerene
acceptor and the solvent. Our model uses a phase field approach coupled to a
Navier-Stokes equation describing the macroscopic movement of the fluid.
Additionally, we incorporate the evaporation process of the solvent using an
Allen-Cahn equation.
  The model is discretized using a finite-element approach with a semi-implicit
discretization in time. The resulting (non)linear systems are coupled and of
large dimensionality. We present a preconditioned iterative scheme to solve
them robustly with respect to changes in the discretization parameters. We
illustrate that the preconditioned solver shows parameter-robust iteration
numbers and that the model qualitatively captures the behavior of the film
morphology during drying.",http://arxiv.org/abs/2501.11767v1
"Arrangements of circles supported by small chords and compatible with
  natural real algebraic functions",2025-01-21T01:57:21Z,Naoki Kitazawa,"We have previously proposed a study of arrangements of small circles which
also surround regions in the plane realized as the images of natural real
algebraic maps yielding Morse-Bott functions by projections. Among studies of
arrangements, families of smooth regular submanifolds in smooth manifolds, this
study is fundamental, explicit, and new, surprisingly.
  We have obtained a complete list of local changes of the graphs the regions
naturally collapse to in adding a (generic) small circle to an existing
arrangement of the proposed class. Here, we propose a similar and essentially
different class of arrangements of circles. The present study also yields real
algebraic maps and nice real algebraic functions similarly and we present a
similar study.
  We are interested in topological properties and combinatorics among such
arrangements and regions and applications to constructing such real algebraic
maps and manifolds explicitly and understanding their global structures.",http://arxiv.org/abs/2501.11819v1
"A Fully Pipelined FIFO Based Polynomial Multiplication Hardware
  Architecture Based On Number Theoretic Transform",2025-01-21T03:50:26Z,"Moslem Heidarpur, Mitra Mirhassani, Norman Chang","This paper presents digital hardware for computing polynomial multiplication
using Number Theoretic Transform (NTT), specifically designed for
implementation on Field Programmable Gate Arrays (FPGAs). Multiplying two large
polynomials applies to many modern encryption schemes, including those based on
Ring Learning with Error (RLWE). The proposed design uses First In, First Out
(FIFO) buffers to make the design fully pipelined and capable of computing two
n degree polynomials in n/2 clock cycles. This hardware proposes a two-fold
reduction in the processing time of polynomial multiplication compared to
state-of-the-art enabling twice as much encryption in the same amount of time.
Despite that, the proposed hardware utilizes fewer resources than the
fastest-reported work.",http://arxiv.org/abs/2501.11867v1
"Probing negative differential resistance in silicon with a P-I-N
  diode-integrated T center ensemble",2025-01-21T04:54:30Z,"Aaron M. Day, Chaoshen Zhang, Chang Jin, Hanbin Song, Madison Sutula, Alp Sipahigil, Mihir K. Bhaskar, Evelyn L. Hu","The T center in silicon has recently emerged as a promising candidate for
scalable quantum technologies, due to its telecommunications band optical
transition and microwave addressable ground state spin. The immense promise of
the T center is driven by its silicon host material; silicon is by far the most
mature, manufacturable semiconductor material for integrated photonic and
electronic devices. Here, we present the first study of T-centers in an
electrical device. We study an ensemble of T centers coupled to a buried
lateral P-I-N diode in silicon, observing the T-center's optical response to
static and dynamic electric fields. We utilize the defect's optical response as
a probe of device nonlinearity, observing a phase transition of the carrier
density into a stable oscillatory regime characteristic of negative
differential resistance. These findings provide fundamental insight into the
physics of the T-center for improved quantum device performance and open a
promising new direction for defect-based local quantum sensing in semiconductor
devices.",http://arxiv.org/abs/2501.11888v1
"MeshONet: A Generalizable and Efficient Operator Learning Method for
  Structured Mesh Generation",2025-01-21T07:27:05Z,"Jing Xiao, Xinhai Chen, Qingling Wang, Jie Liu","Mesh generation plays a crucial role in scientific computing. Traditional
mesh generation methods, such as TFI and PDE-based methods, often struggle to
achieve a balance between efficiency and mesh quality. To address this
challenge, physics-informed intelligent learning methods have recently emerged,
significantly improving generation efficiency while maintaining high mesh
quality. However, physics-informed methods fail to generalize when applied to
previously unseen geometries, as even small changes in the boundary shape
necessitate burdensome retraining to adapt to new geometric variations. In this
paper, we introduce MeshONet, the first generalizable intelligent learning
method for structured mesh generation. The method transforms the mesh
generation task into an operator learning problem with multiple input and
solution functions. To effectively overcome the multivariable mapping
restriction of operator learning methods, we propose a dual-branch,
shared-trunk architecture to approximate the mapping between function spaces
based on input-output pairs. Experimental results show that MeshONet achieves a
speedup of up to four orders of magnitude in generation efficiency over
traditional methods. It also enables generalization to different geometries
without retraining, greatly enhancing the practicality of intelligent methods.",http://arxiv.org/abs/2501.11937v2
GLAM: Global-Local Variation Awareness in Mamba-based World Model,2025-01-21T07:47:03Z,"Qian He, Wenqi Liang, Chunhui Hao, Gan Sun, Jiandong Tian","Mimicking the real interaction trajectory in the inference of the world model
has been shown to improve the sample efficiency of model-based reinforcement
learning (MBRL) algorithms. Many methods directly use known state sequences for
reasoning. However, this approach fails to enhance the quality of reasoning by
capturing the subtle variation between states. Much like how humans infer
trends in event development from this variation, in this work, we introduce
Global-Local variation Awareness Mamba-based world model (GLAM) that improves
reasoning quality by perceiving and predicting variation between states. GLAM
comprises two Mambabased parallel reasoning modules, GMamba and LMamba, which
focus on perceiving variation from global and local perspectives, respectively,
during the reasoning process. GMamba focuses on identifying patterns of
variation between states in the input sequence and leverages these patterns to
enhance the prediction of future state variation. LMamba emphasizes reasoning
about unknown information, such as rewards, termination signals, and visual
representations, by perceiving variation in adjacent states. By integrating the
strengths of the two modules, GLAM accounts for highervalue variation in
environmental changes, providing the agent with more efficient
imagination-based training. We demonstrate that our method outperforms existing
methods in normalized human scores on the Atari 100k benchmark.",http://arxiv.org/abs/2501.11949v1
"GSVC: Efficient Video Representation and Compression Through 2D Gaussian
  Splatting",2025-01-21T11:30:51Z,"Longan Wang, Yuang Shi, Wei Tsang Ooi","3D Gaussian splats have emerged as a revolutionary, effective, learned
representation for static 3D scenes. In this work, we explore using 2D Gaussian
splats as a new primitive for representing videos. We propose GSVC, an approach
to learning a set of 2D Gaussian splats that can effectively represent and
compress video frames. GSVC incorporates the following techniques: (i) To
exploit temporal redundancy among adjacent frames, which can speed up training
and improve the compression efficiency, we predict the Gaussian splats of a
frame based on its previous frame; (ii) To control the trade-offs between file
size and quality, we remove Gaussian splats with low contribution to the video
quality; (iii) To capture dynamics in videos, we randomly add Gaussian splats
to fit content with large motion or newly-appeared objects; (iv) To handle
significant changes in the scene, we detect key frames based on loss
differences during the learning process. Experiment results show that GSVC
achieves good rate-distortion trade-offs, comparable to state-of-the-art video
codecs such as AV1 and VVC, and a rendering speed of 1500 fps for a 1920x1080
video.",http://arxiv.org/abs/2501.12060v2
"On the cohomology of simple Shimura varieties with non quasi-split local
  groups",2025-01-21T13:40:22Z,"Jingren Chi, Thomas J. Haines","We study the Scholze test functions for bad reduction of simple Shimura
varieties at a prime where the underlying local group is any inner form of a
product of Weil restrictions of general linear groups. Using global methods, we
prove that these test functions satisfy a vanishing property of their twisted
orbital integrals, and we prove that the pseudostabilization base changes of
such functions exist (even though the local group need not be quasi-split) and
can be expressed in terms of explicit distributions in the stable Bernstein
center. We then deduce applications to the stable trace formula and local
Hasse-Weil zeta functions for these Shimura varieties.",http://arxiv.org/abs/2501.12127v2
Nucleon tensor form factors at large $N_{c}$,2025-01-21T16:00:31Z,"Nam-Yong Ghim, Ho-Yeon Won, June-Young Kim, Hyun-Chul Kim","We investigate nucleon tensor form factors in the large-$N_{c}$ limit. In
this picture, the nucleon emerges as a state of the $N_c$ valence quarks, which
were bound by pion mean fields that were created by the presence of the valence
quarks self-consistently. We find that the tensor charge ($g^{u-d}_{T}=0.99$)
and the anomalous tensor magnetic moment ($\kappa^{u+d}_{T}=7.61$) are
dominated by valence quarks, while the tensor quadrupole moment
($Q^{u-d}_{T}=-7.02$) shows significant sea quark effects. We examine how these
quantities vary as the average size of the pion mean field is changed, showing
interpolation between non-relativistic quark and Skyrme limits. We also observe
that $g^{u-d}_{T}$ and $\kappa^{u+d}_{T}$ depend weakly on the pion mass. In
contrast, $Q^{u-d}_{T}$ exhibits strong enhancement near the chiral limit. The
numerical results are in good agreement with available lattice QCD data and
provide predictions for unmeasured quantities.",http://arxiv.org/abs/2501.12241v1
"Benchmarking Image Perturbations for Testing Automated Driving
  Assistance Systems",2025-01-21T16:40:44Z,"Stefano Carlo Lambertenghi, Hannes Leonhard, Andrea Stocco","Advanced Driver Assistance Systems (ADAS) based on deep neural networks
(DNNs) are widely used in autonomous vehicles for critical perception tasks
such as object detection, semantic segmentation, and lane recognition. However,
these systems are highly sensitive to input variations, such as noise and
changes in lighting, which can compromise their effectiveness and potentially
lead to safety-critical failures.
  This study offers a comprehensive empirical evaluation of image
perturbations, techniques commonly used to assess the robustness of DNNs, to
validate and improve the robustness and generalization of ADAS perception
systems. We first conducted a systematic review of the literature, identifying
38 categories of perturbations. Next, we evaluated their effectiveness in
revealing failures in two different ADAS, both at the component and at the
system level. Finally, we explored the use of perturbation-based data
augmentation and continuous learning strategies to improve ADAS adaptation to
new operational design domains. Our results demonstrate that all categories of
image perturbations successfully expose robustness issues in ADAS and that the
use of dataset augmentation and continuous learning significantly improves ADAS
performance in novel, unseen environments.",http://arxiv.org/abs/2501.12269v1
Period Analysis of Eclipsing Cataclysmic Variable Stars,2025-01-21T18:09:25Z,"Mennatalla Mahmoud Ellaqany, Valeria Garcia-Lopez, Emily S. Hatten, Mridul Agarwal, David A. Moffett","We have performed a study of the orbital properties of seven eclipsing
cataclysmic variable (CV) binary systems by analyzing photometric time series
from the Transiting Exoplanet Survey Satellite (TESS). We employed Python code
to determine the eclipse epochs and orbital periods for each system, and
constructed O-C diagrams from observed and predicted eclipse epochs. By
analyzing the O-C diagrams of our target CVs, we have constrained values for
changes in orbital period with time. Our targets include a sample of sources
from each class of non-magnetic, eclipsing CVs: dwarf novae variables, Z Cam
type, and U Gem subclasses. We include in our study classical novae variables,
nova-like variables (including the VY Scl and UX UMa subclasses), and recurrent
novae variable stars. We approached this project with goals of developing time
series analysis techniques for future undergraduate-level studies of eclipsing
CVs, and how they may contribute to the understanding of their orbital
evolution.",http://arxiv.org/abs/2501.12334v1
Self-assembling of Ge quantum dots in an alumina matrix,2025-01-21T19:04:23Z,"M. Buljan, S. R. C. Pinto, A. G. Rolo, J. Martín-Sánchez, M. J. M. Gomes, J. Grenzer, A. Mücklich, S. Bernstorff, V. Holý","In this work we report on a self-assembled growth of a Ge quantum dot lattice
in a single 600-nm-thick Ge+Al2O3 layer during magnetron sputtering deposition
of a Ge+Al2O3 mixture at an elevated substrate temperature. The self-assembly
results in the formation of a well-ordered threedimensional body-centered
tetragonal quantum dot lattice within the whole deposited volume. The quantum
dots formed are very small in size less than 4.0 nm, have a narrow size
distribution and a large packing density. The parameters of the quantum dot
lattice can be tuned by changing the deposition parameters. The self-ordering
of the quantum dots is explained by diffusionmediated nucleation and
surface-morphology effects and simulated by a kinetic Monte Carlo model.",http://arxiv.org/abs/2501.12455v1
Tunable extraordinary optical transmission for integrated photonics,2025-01-21T19:56:37Z,"Hira Asif, Ramazan Sahin","The propagation of light through opaque materials, served by periodic arrays
of subwavelength holes, has revolutionized imaging and sensor technology with a
breakthrough of extraordinary optical transmission (EOT). The enhanced optical
transmission assisted by surface plasmon resonances (SPR) has become the most
ingenious phenomenon in the field of light-matter interaction. Active tuning of
SPR presents a new and simple way to control spectral features of the EOT
signal (without the need to change the geometrical structure of the device).
This provides a new possibility to integrate an active EOT device with tunable
operational frequencies on a single chip of photonic integrated circuits (PIC)-
a new scalable instrument in the optoelectronic industry, and quantum
technology for improving subwavelength optical imaging and biomedical sensing.
In this review, we discuss the fundamentals of EOT, the role of SPR, and how
the active quantum plasmonic control of the EOT device makes it a feasible
on-chip electro-optic programmable element for integrated photonics.",http://arxiv.org/abs/2501.12476v1
"Global symmetries of quantum lattice models under non-invertible
  dualities",2025-01-21T21:52:39Z,"Weiguang Cao, Yuan Miao, Masahito Yamazaki","Non-invertible dualities/symmetries have become an important tool in the
study of quantum field theories and quantum lattice models in recent years. One
of the most studied examples is non-invertible dualities obtained by gauging a
discrete group. When the physical system has more global symmetries than the
gauged symmetry, it has not been thoroughly investigated how those global
symmetries transform under non-invertible duality. In this paper, we study the
change of global symmetries under non-invertible duality of gauging a discrete
group $G$ in the context of (1+1)-dimensional quantum lattice models. We obtain
the global symmetries of the dual model by focusing on different Hilbert space
sectors determined by the $\mathrm{Rep}(G)$ symmetry. We provide general
conjectures of global symmetries of the dual model forming an algebraic ring of
the double cosets. We present concrete examples of the XXZ models and the
duals, providing strong evidence for the conjectures.",http://arxiv.org/abs/2501.12514v1
"On the Uniqueness of Certain Types of Circle Packings on Translation
  Surfaces",2025-01-22T00:14:29Z,Nilay Mishra,"Consider a collection of finitely many polygons in $\mathbb C$, such that for
each side of each polygon, there exists another side of some polygon in the
collection (possibly the same) that is parallel and of equal length. A
translation surface is the surface formed by identifying these opposite sides
with one another. The $H(1, 1)$ stratum consists of genus two translation
surfaces with two singularities of order one. A circle packing corresponding to
a graph $G$ is a configuration of disjoint disks such that each vertex of $G$
corresponds to a circle, two disks are externally tangent if and only if their
vertices are connected by an edge in $G$, and $G$ is a triangulation of the
surface. It is proven that for certain circle packings on $H(1, 1)$ translation
surfaces, there are only a finite number of ways the packing can vary without
changing the contacts graph, if two disks along the slit are fixed in place.
These variations can be explicitly characterized using a new concept known as
splitting bigons. Finally, the uniqueness theorem is generalized to a specific
type of translation surfaces with arbitrary genus $g \geq 2$.",http://arxiv.org/abs/2501.12552v1
"GATE: Adaptive Learning with Working Memory by Information Gating in
  Multi-lamellar Hippocampal Formation",2025-01-22T03:41:35Z,"Yuechen Liu, Zishun Wang, Chen Qiao, Zongben Xu","Hippocampal formation (HF) can rapidly adapt to varied environments and build
flexible working memory (WM). To mirror the HF's mechanism on generalization
and WM, we propose a model named Generalization and Associative Temporary
Encoding (GATE), which deploys a 3-D multi-lamellar dorsoventral (DV)
architecture, and learns to build up internally representation from externally
driven information layer-wisely. In each lamella, regions of HF:
EC3-CA1-EC5-EC3 forms a re-entrant loop that discriminately maintains
information by EC3 persistent activity, and selectively readouts the retained
information by CA1 neurons. CA3 and EC5 further provides gating function that
controls these processes. After learning complex WM tasks, GATE forms neuron
representations that align with experimental records, including splitter, lap,
evidence, trace, delay-active cells, as well as conventional place cells.
Crucially, DV architecture in GATE also captures information, range from
detailed to abstract, which enables a rapid generalization ability when cue,
environment or task changes, with learned representations inherited. GATE
promises a viable framework for understanding the HF's flexible memory
mechanisms and for progressively developing brain-inspired intelligent systems.",http://arxiv.org/abs/2501.12615v1
"DWTNeRF: Boosting Few-shot Neural Radiance Fields via Discrete Wavelet
  Transform",2025-01-22T04:53:12Z,"Hung Nguyen, Blark Runfa Li, Truong Nguyen","Neural Radiance Fields (NeRF) has achieved superior performance in novel view
synthesis and 3D scene representation, but its practical applications are
hindered by slow convergence and reliance on dense training views. To this end,
we present DWTNeRF, a unified framework based on Instant-NGP's fast-training
hash encoding. It is coupled with regularization terms designed for few-shot
NeRF, which operates on sparse training views. Our DWTNeRF additionally
includes a novel Discrete Wavelet loss that allows explicit prioritization of
low frequencies directly in the training objective, reducing few-shot NeRF's
overfitting on high frequencies in earlier training stages. We also introduce a
model-based approach, based on multi-head attention, that is compatible with
INGP, which are sensitive to architectural changes. On the 3-shot LLFF
benchmark, DWTNeRF outperforms Vanilla INGP by 15.07% in PSNR, 24.45% in SSIM
and 36.30% in LPIPS. Our approach encourages a re-thinking of current few-shot
approaches for fast-converging implicit representations like INGP or 3DGS.",http://arxiv.org/abs/2501.12637v2
"Heat Transport Hysteresis Generated through Frequency Switching of a
  Time-Dependent Temperature Gradient",2025-01-22T05:17:38Z,"Renai Chen, Galen T. Craven","A stochastic energetics framework is applied to examine how periodically
shifting the frequency of a time-dependent oscillating temperature gradient
affects heat transport in a nanoscale molecular model. We specifically examine
the effects that frequency switching, i.e., instantaneously changing the
oscillation frequency of the temperature gradient, has on the shape of the heat
transport hysteresis curves generated by a particle connected to two thermal
baths, each with a temperature that is oscillating in time. Analytical
expressions are derived for the energy fluxes in/out of the system and the
baths, with excellent agreement observed between the analytical expressions and
the results from nonequilibrium molecular dynamics simulations. We find that
the shape of the heat transport hysteresis curves can be significantly altered
by shifting the frequency between fast and slow oscillation regimes. We also
observe the emergence of features in the hysteresis curves such as pinched
loops and complex multi-loop patterns due to the frequency shifting. The
presented results have implications in the design of thermal neuromorphic
devices such as thermal memristors and thermal memcapacitors.",http://arxiv.org/abs/2501.12649v1
"Strong shape-dependent intensity of inelastic light scattering by gold
  nanocrystals",2025-01-22T08:02:54Z,"Lucien Saviot, Vincent Laude","We present a numerical approach to calculate inelastic light scattering
spectra from gold nanocrystals, based on the finite element method. This
approach is validated by comparison with previous analytic calculations for
spherically symmetric scatterers. Superellipsoid nanocrystals are considered in
order to smoothly vary the shape from octahedra to cubes via spheres, while
preserving cubic symmetry. Spectra are calculated and discussed taking into
account the irreducible representation of the involved vibration modes. A
strong increase in the inelastically scattered light intensity is observed for
small variations of the shape around the sphere. This increase is related to
variations of the electric field inside the nanocrystals, which are very small
for small nanospheres but increase quickly for non-spherical nanocrystals. This
strong dependence with shape must be taken into account when interpreting
experimental spectra acquired from inhomogeneous ensembles of nanocrystals
whose shape dispersion are usually neglected. The overall changes in the
spectra when varying the shape of the nanocrystals provide additional insight
into previously published results. Preliminary calculations for chiral shapes
further show a significant difference between spectra obtained with right or
left circularly polarized light.",http://arxiv.org/abs/2501.12692v1
"Achronal localization and representation of the causal logic from
  conserved current, application to massive scalar boson",2025-01-22T08:15:57Z,"Domenico P. L. Castrigiano, Carmine De Rosa, Valter Moretti","Covariant achronal localizations are gained out of covariant conserved
currents computing their flux passing through achronal surfaces. This general
method applies to the probability density currents with causal kernel regarding
the massive scalar boson. Due to the one-to-one correspondence between
(covariant) achronal localizations and (covariant) representations of the
causal logic thus, apparently for the first time, a covariant representation of
the causal logic for an elementary relativistic quantum mechanical system has
been achieved. Similarly one derives the covariant family of representations of
the causal logic related to the stress energy tensor of the massive scalar
boson. While reaching this result the divergence theorem is proven for open
sets with almost Lipschitz boundary.",http://arxiv.org/abs/2501.12699v3
TimeDepFrail: Time-Dependent Shared Frailty Cox Models in R,2025-01-22T08:47:37Z,"Alessandra Ragni, Giulia Romani, Chiara Masci","This paper introduces TimeDepFrail, an R package designed to implement
time-varying shared frailty models by extending the traditional shared frailty
Cox model to allow the frailty term to evolve across time intervals. These
models are particularly suited for survival analysis in clustered data where
unobserved heterogeneity changes over time, providing greater flexibility in
modeling time-to-event data.
  The package builds on the piecewise gamma frailty model originally proposed
by Paik (1994) and refined by Wintrebert et al. (2004). Our key contributions
include the integration of posterior frailty estimation, a reduction in
computational complexity, the definition of a prediction framework and the
efficient implementation of these models within an R package.
  As a practical application, we use TimeDepFrail to analyze dropout rates
within a university, where high dropout rates are a known issue. By allowing
frailty to vary over time, the package uncovers new insights into the
unobserved factors influencing dropout.
  TimeDepFrail simplifies access to advanced time-varying frailty models,
providing a practical and scalable alternative to more computationally
demanding methods, making it highly applicable for large-scale datasets.",http://arxiv.org/abs/2501.12718v1
"Anomalous Lattice Effect Originated Metal-Insulator Transition in
  FeSe$_x$",2025-01-22T08:53:57Z,"Shubham Purwar, Shinjini Paul, Kritika Vijay, R. Venkatesh, Soma Banik, P. Mahadevan, S. Thirupathaiah","We present a comprehensive investigation of the structural, electrical
transport, and magnetic properties of FeSe$_{\it{x}}$ ($\it{x}$ = 1.14, 1.18,
1.23, 1.28, and 1.32) to unravel the mechanism of the metal-insulator
transition observed in these systems. For this, we systematically evaluated the
structural parameters of FeSe$_{\it{x}}$ as a function of Se concentration and
temperature. We observe increased lattice constants and cell volume with
increased Se concentration. On the other hand, the temperature-dependent XRD
studies suggest unusual lattice change around the metal-insulator (MI)
transition temperature of the respective compositions. This remarkable
observation suggests that the anomalous lattice effect originates the MI
transition in these systems. Additionally, our density of states (DOS)
calculations on FeSe$_{1.14}$ qualitatively explain the MI transition, as the
low-temperature (50 K) structure DOS suggests a metallic nature and the
high-temperature (300 K) structure DOS shows a gap near the Fermi level.",http://arxiv.org/abs/2501.12724v2
LLMs as Repositories of Factual Knowledge: Limitations and Solutions,2025-01-22T10:16:53Z,"Seyed Mahed Mousavi, Simone Alghisi, Giuseppe Riccardi","LLMs' sources of knowledge are data snapshots containing factual information
about entities collected at different timestamps and from different media types
(e.g. wikis, social media, etc.). Such unstructured knowledge is subject to
change due to updates through time from past to present. Equally important are
the inconsistencies and inaccuracies occurring in different information
sources. Consequently, the model's knowledge about an entity may be perturbed
while training over the sequence of snapshots or at inference time, resulting
in inconsistent and inaccurate model performance. In this work, we study the
appropriateness of Large Language Models (LLMs) as repositories of factual
knowledge. We consider twenty-four state-of-the-art LLMs that are either
closed-, partially (weights), or fully (weight and training data) open-source.
We evaluate their reliability in responding to time-sensitive factual questions
in terms of accuracy and consistency when prompts are perturbed. We further
evaluate the effectiveness of state-of-the-art methods to improve LLMs'
accuracy and consistency. We then propose ""ENtity-Aware Fine-tuning"" (ENAF), a
soft neurosymbolic approach aimed at providing a structured representation of
entities during fine-tuning to improve the model's performance.",http://arxiv.org/abs/2501.12774v1
"Kink dynamics for the Yang-Mills field in an extremal
  Reissner-Nordström black hole",2025-01-22T10:49:06Z,"Ignacio Acevedo, Claudio Muñoz","Considered in this work is the Yang-Mills field in an extremal
Reissner-Nordstr\""om black hole, a physically motivated mathematical model
introduced by Bizo\'n and Kahl. The kink is a fundamental, strongly unstable
stationary solution in this non-perturbative, variable coefficients model, with
a polynomial tail and no explicit form. In this paper, we introduce and extend
several virial techniques, adapt them to the inhomogeneous medium setting, and
construct a finite codimensional manifold of the energy space where the kink is
asymptotically stable. In particular, we handle, using virial techniques, the
emergence of a weak threshold resonance in the description of the stable
manifold.",http://arxiv.org/abs/2501.12790v2
"Exploring the heterogeneous impacts of Indonesia's conditional cash
  transfer scheme (PKH) on maternal health care utilisation using instrumental
  causal forests",2025-01-22T11:21:05Z,"Vishalie Shah, Julia Hatamyar, Taufik Hidayat, Noemi Kreif","This paper uses instrumental causal forests, a novel machine learning method,
to explore the treatment effect heterogeneity of Indonesia's conditional cash
transfer scheme on maternal health care utilisation. Using randomised programme
assignment as an instrument for enrollment in the scheme, we estimate
conditional local average treatment effects for four key outcomes: good
assisted delivery, delivery in a health care facility, pre-natal visits, and
post-natal visits. We find significant treatment effect heterogeneity by
supply-side characteristics, even though supply-side readiness was taken into
account during programme development. Mothers in areas with more doctors,
nurses, and delivery assistants were more likely to benefit from the programme,
in terms of increased rates of good assisted delivery outcome. We also find
large differences in benefits according to indicators of household poverty and
survey wave, reflecting the possible impact of changes in programme design in
its later years. The impact on post-natal visits in 2013 displayed the largest
heterogeneity among all outcomes, with some women less likely to attend
post-natal check ups after receiving the cash transfer in the long term.",http://arxiv.org/abs/2501.12803v1
"Probing dynamics of time-varying media: Beyond abrupt temporal
  interfaces",2025-01-22T14:18:49Z,"Ayan Nussupbekov, Juan-Feng Zhu, Yuriy Akimov, Ping Bai, Ching Eng Png, Francisco J. Garcia-Vidal, Lin Wu","This work investigates the effects of time-varying media, where optical
properties change over time, on electromagnetic wave propagation, focusing on
plane waves and free-electron evanescent waves. We introduce a switching
parameter, $\tau$, to model ultrafast switching in the femtosecond to
nanosecond range. For plane-wave incidence at angular frequency $\omega_0$, we
derive a generalized expression for the backward-to-forward flux ratio as a
function of $\omega_0$ and $\tau$, aligning with recent experimental data and
providing a unified interpretation framework. For free-electron incidence, we
observe intensity saturation in temporal transition radiation at
$I_{\textrm{max}}$ for $\tau \leq \tau_{\textrm{0}}$, with both
$I_{\textrm{max}}$ and $\tau_{\textrm{0}}$ depending on electron speed. These
results highlight the importance of precise $\tau$ control in experiments to
probe time-varying media effectively.",http://arxiv.org/abs/2501.12899v1
Development of the Critical Reflection and Agency in Computing Index,2025-01-22T18:13:05Z,"Aadarsh Padiyath, Mark Guzdial, Barbara Ericson","As computing's societal impact grows, so does the need for computing students
to recognize and address the ethical and sociotechnical implications of their
work. While there are efforts to integrate ethics into computing curricula, we
lack a standardized tool to measure those efforts, specifically, students'
attitudes towards ethical reflection and their ability to effect change. This
paper introduces the novel framework of Critically Conscious Computing and
reports on the development and content validation of the Critical Reflection
and Agency in Computing Index, a novel instrument designed to assess
undergraduate computing students' attitudes towards practicing critically
conscious computing. The resulting index is a theoretically grounded,
expert-reviewed tool to support research and practice in computing ethics
education. This enables researchers and educators to gain insights into
students' perspectives, inform the design of targeted ethics interventions, and
measure the effectiveness of computing ethics education initiatives.",http://arxiv.org/abs/2501.13060v1
A Non-linear Massive Gravity Theory of Geometric Origin,2025-01-22T18:40:02Z,"Thibault Damour, Tamanna Jain","We study the number of propagating degrees of freedom, at non-linear order,
in torsion gravity theories, a class of modified theories of gravity that
include a propagating torsion in addition to the metric. We focus on a
three-parameter subfamily of theories (``torsion bigravity"") that contains, at
linear order, only two physical excitations: a massless spin-2 one (with two
degrees of freedom) and a massive spin-2 one (with five degrees of freedom). We
study the dynamics of the massive spin-2 field in the limit where the torsion
field decouples from the metric. The number of degrees of freedom of the
torsion field is found to {\it change, at non-linear order, from five to nine}.",http://arxiv.org/abs/2501.13077v1
"Two decades of optical variability of Small Magellanic Cloud high-mass
  X-ray binaries",2025-01-22T19:00:00Z,"Helena Treiber, Georgios Vasilopoulos, Charles Bailyn, Frank Haberl, Andrzej Udalski","We present an analysis of the long-term optical/IR behavior of 111 high-mass
X-ray binaries (HMXBs) in the Small Magellanic Cloud based on data from the
OGLE collaboration. Most systems exhibit variability on a range of time scales.
This variability regulates the mass transfer to the compact object, while the
compact object can, in turn, affect the donor star's behavior. To better
understand this complex interaction and the resulting X-ray properties in these
systems, we define a new taxonomy for the observed super-orbital variability.
This taxonomy connects to the color changes, orbital periods, and X-ray
behavior of the sources. In most cases, these properties can be explained by
differences between the flux of the disk around the Be star and the flux from
the star itself. We also refine and present new potential orbital periods and
sub-orbital variability in the sources.",http://arxiv.org/abs/2501.13147v1
Localization of Dirac modes in a finite temperature SU(2) Higgs model,2025-01-22T19:12:05Z,"György Baranka, Matteo Giordano","Low-lying Dirac modes become localized at the finite-temperature transition
in QCD and other gauge theories, indicating a strong connection between
localization and deconfinement. This phenomenon can be understood through the
""sea/islands"" picture: in the deconfined phase, modes become trapped on
""islands"" of Polyakov loop fluctuations within a ""sea"" of ordered Polyakov
loops. To test the universality of the ""sea/islands"" mechanism, we investigate
whether changes in the localization properties of low modes occur across other
thermal transitions where the Polyakov loop becomes ordered, beyond the usual
deconfinement transition. The fixed-length SU(2)-Higgs model is appropriate for
this study. After mapping out the phase diagram, we find that low Dirac modes
become localized in the deconfined and Higgs phases, where the Polyakov loop is
ordered. However, localization is absent in the confined phase. These findings
confirm the ""sea/islands"" picture of localization.",http://arxiv.org/abs/2501.13177v1
"Using Principal Component Analysis to Distinguish Different Dynamic
  Phases in Superconducting Vortex Matter",2025-01-22T23:17:21Z,"C. J. O. Reichhardt, D. McDermott, C. Reichhardt","Vortices in type-II superconductors driven over random disorder are known to
exhibit a remarkable variety of distinct nonequilibrium dynamical phases that
arise due to the competition between vortex-vortex interactions, the quenched
disorder, and the drive. These include pinned states, elastic flows, plastic or
disordered flows, and dynamically reordered moving crystal or moving smectic
states. The plastic flow phases can be particularly difficult to characterize
since the flows are strongly disordered. Here we perform principal component
analysis (PCA) on the positions and velocities of vortex matter moving over
random disorder for different disorder strengths and drives. We find that PCA
can distinguish the known dynamic phases as well as or better than previous
measures based on transport signatures or topological defect densities. In
addition, PCA recognizes distinct plastic flow regimes, a slowly changing
channel flow and a moving amorphous fluid flow, that do not produce distinct
signatures in the standard measurements. Our results suggest that this position
and velocity based PCA approach could be used to characterize dynamic phases in
a broader class of systems that exhibit depinning and nonequilibrium phase
transitions.",http://arxiv.org/abs/2501.13269v1
Gradient-Free Adversarial Purification with Diffusion Models,2025-01-23T02:34:14Z,"Xuelong Dai, Dong Wang, Duan Mingxing, Bin Xiao","Adversarial training and adversarial purification are two effective and
practical defense methods to enhance a model's robustness against adversarial
attacks. However, adversarial training necessitates additional training, while
adversarial purification suffers from low time efficiency. More critically,
current defenses are designed under the perturbation-based adversarial threat
model, which is ineffective against the recently proposed unrestricted
adversarial attacks. In this paper, we propose an effective and efficient
adversarial defense method that counters both perturbation-based and
unrestricted adversarial attacks. Our defense is inspired by the observation
that adversarial attacks are typically located near the decision boundary and
are sensitive to pixel changes. To address this, we introduce adversarial
anti-aliasing to mitigate adversarial modifications. Additionally, we propose
adversarial super-resolution, which leverages prior knowledge from clean
datasets to benignly recover images. These approaches do not require additional
training and are computationally efficient without calculating gradients.
Extensive experiments against both perturbation-based and unrestricted
adversarial attacks demonstrate that our defense method outperforms
state-of-the-art adversarial purification methods.",http://arxiv.org/abs/2501.13336v1
"Load and Renewable Energy Forecasting Using Deep Learning for Grid
  Stability",2025-01-23T06:33:33Z,Kamal Sarkar,"As the energy landscape changes quickly, grid operators face several
challenges, especially when integrating renewable energy sources with the grid.
The most important challenge is to balance supply and demand because the solar
and wind energy are highly unpredictable. When dealing with such uncertainty,
trustworthy short-term load and renewable energy forecasting can help stabilize
the grid, maximize energy storage, and guarantee the effective use of renewable
resources. Physical models and statistical techniques were the previous
approaches employed for this kind of forecasting tasks. In forecasting
renewable energy, machine learning and deep learning techniques have recently
demonstrated encouraging results. More specifically, the deep learning
techniques like CNN and LSTM and the conventional machine learning techniques
like regression that are mostly utilized for load and renewable energy
forecasting tasks. In this article, we will focus mainly on CNN and LSTM-based
forecasting methods.",http://arxiv.org/abs/2501.13412v1
"Wasserstein-regularized Conformal Prediction under General Distribution
  Shift",2025-01-23T07:29:44Z,"Rui Xu, Chao Chen, Yue Sun, Parvathinathan Venkitasubramaniam, Sihong Xie","Conformal prediction yields a prediction set with guaranteed $1-\alpha$
coverage of the true target under the i.i.d. assumption, which may not hold and
lead to a gap between $1-\alpha$ and the actual coverage. Prior studies bound
the gap using total variation distance, which cannot identify the gap changes
under distribution shift at a given $\alpha$. Besides, existing methods are
mostly limited to covariate shift,while general joint distribution shifts are
more common in practice but less researched.In response, we first propose a
Wasserstein distance-based upper bound of the coverage gap and analyze the
bound using probability measure pushforwards between the shifted joint data and
conformal score distributions, enabling a separation of the effect of covariate
and concept shifts over the coverage gap. We exploit the separation to design
an algorithm based on importance weighting and regularized representation
learning (WR-CP) to reduce the Wasserstein bound with a finite-sample error
bound.WR-CP achieves a controllable balance between conformal prediction
accuracy and efficiency. Experiments on six datasets prove that WR-CP can
reduce coverage gaps to $3.1\%$ across different confidence levels and outputs
prediction sets 38$\%$ smaller than the worst-case approach on average.",http://arxiv.org/abs/2501.13430v1
Deep Multi-modal Neural Receiver for 6G Vehicular Communication,2025-01-23T08:26:45Z,"Osama Saleem, Mohammed Alfaqawi, Pierre Merdrignac, Abdelaziz Bensrhair, Soheyb Ribouh","Deep Learning (DL) based neural receiver models are used to jointly optimize
PHY of baseline receiver for cellular vehicle to everything (C-V2X) system in
next generation (6G) communication, however, there has been no exploration of
how varying training parameters affect the model's efficiency. Additionally, a
comprehensive evaluation of its performance on multi-modal data remains largely
unexplored. To address this, we propose a neural receiver designed to optimize
Bit Error Rate (BER) for vehicle to network (V2N) uplink scenario in 6G
network. We train multiple neural receivers by changing its trainable
parameters and use the best fit model as proposition for large scale
deployment. Our proposed neural receiver gets signal in frequency domain at the
base station (BS) as input and generates optimal log likelihood ratio (LLR) at
the output. It estimates the channel based on the received signal, equalizes
and demodulates the higher order modulated signal. Later, to evaluate
multi-modality of the proposed model, we test it across diverse V2X data flows
(e.g., image, video, gps, lidar cloud points and radar detection signal).
Results from simulation clearly indicates that our proposed multi-modal neural
receiver outperforms state-of-the-art receiver architectures by achieving high
performance at low Signal to Noise Ratio (SNR).",http://arxiv.org/abs/2501.13464v1
"GCAD: Anomaly Detection in Multivariate Time Series from the Perspective
  of Granger Causality",2025-01-23T09:15:59Z,"Zehao Liu, Mengzhou Gao, Pengfei Jiao","Multivariate time series anomaly detection has numerous real-world
applications and is being extensively studied. Modeling pairwise correlations
between variables is crucial. Existing methods employ learnable graph
structures and graph neural networks to explicitly model the spatial
dependencies between variables. However, these methods are primarily based on
prediction or reconstruction tasks, which can only learn similarity
relationships between sequence embeddings and lack interpretability in how
graph structures affect time series evolution. In this paper, we designed a
framework that models spatial dependencies using interpretable causal
relationships and detects anomalies through changes in causal patterns.
Specifically, we propose a method to dynamically discover Granger causality
using gradients in nonlinear deep predictors and employ a simple sparsification
strategy to obtain a Granger causality graph, detecting anomalies from a causal
perspective. Experiments on real-world datasets demonstrate that the proposed
model achieves more accurate anomaly detection compared to baseline methods.",http://arxiv.org/abs/2501.13493v1
"Medium Temperature Phase Change Materials Thermal Characterization by
  the T-History Method and Differential Scanning Calorimetry",2025-01-23T09:28:02Z,"D. Gaona, E. Urresta, J. Martinez, G. Guerron","This paper presents a thermal characterization of salt mixtures applying the
T-History Method and the Differential Scanning Calorimetry DSC techniques. By
using water as a standard substance, the original T-History method was
developed to analyze materials with melting points under 100 Celsius. This is
the first research that proposes to replace water by glycerin to characterize
medium melting temperature PCMs from 140 to 220 Celsius. Moreover, the DSC
technique was used to validate and compare the results obtained with the
T-history method for each mixture. For instance, the system compound of 40
KNO$_3$ to 60 NaNO$_3$ was studied, and the enthalpy of fusion determined by
THM and DSC differs by 2.1% between each method. The results given by the two
methods for all mixtures showed that both techniques are complementary and
present satisfactory agreement with the specialized literature.",http://arxiv.org/abs/2501.13502v1
Towards a Theory of AI Personhood,2025-01-23T10:31:26Z,Francis Rhys Ward,"I am a person and so are you. Philosophically we sometimes grant personhood
to non-human animals, and entities such as sovereign states or corporations can
legally be considered persons. But when, if ever, should we ascribe personhood
to AI systems? In this paper, we outline necessary conditions for AI
personhood, focusing on agency, theory-of-mind, and self-awareness. We discuss
evidence from the machine learning literature regarding the extent to which
contemporary AI systems, such as language models, satisfy these conditions,
finding the evidence surprisingly inconclusive.
  If AI systems can be considered persons, then typical framings of AI
alignment may be incomplete. Whereas agency has been discussed at length in the
literature, other aspects of personhood have been relatively neglected. AI
agents are often assumed to pursue fixed goals, but AI persons may be
self-aware enough to reflect on their aims, values, and positions in the world
and thereby induce their goals to change. We highlight open research directions
to advance the understanding of AI personhood and its relevance to alignment.
Finally, we reflect on the ethical considerations surrounding the treatment of
AI systems. If AI systems are persons, then seeking control and alignment may
be ethically untenable.",http://arxiv.org/abs/2501.13533v1
Towards Robust Incremental Learning under Ambiguous Supervision,2025-01-23T11:52:53Z,"Rui Wang, Mingxuan Xia, Chang Yao, Lei Feng, Junbo Zhao, Gang Chen, Haobo Wang","Traditional Incremental Learning (IL) targets to handle sequential
fully-supervised learning problems where novel classes emerge from time to
time. However, due to inherent annotation uncertainty and ambiguity, collecting
high-quality annotated data in a dynamic learning system can be extremely
expensive. To mitigate this problem, we propose a novel weakly-supervised
learning paradigm called Incremental Partial Label Learning (IPLL), where the
sequentially arrived data relate to a set of candidate labels rather than the
ground truth. Technically, we develop the Prototype-Guided Disambiguation and
Replay Algorithm (PGDR) which leverages the class prototypes as a proxy to
mitigate two intertwined challenges in IPLL, i.e., label ambiguity and
catastrophic forgetting. To handle the former, PGDR encapsulates a
momentum-based pseudo-labeling algorithm along with prototype-guided
initialization, resulting in a balanced perception of classes. To alleviate
forgetting, we develop a memory replay technique that collects
well-disambiguated samples while maintaining representativeness and diversity.
By jointly distilling knowledge from curated memory data, our framework
exhibits a great disambiguation ability for samples of new tasks and achieves
less forgetting of knowledge. Extensive experiments demonstrate that PGDR
achieves superior",http://arxiv.org/abs/2501.13584v3
Evolvable Soma Theory of Ageing: Insights from Computer Simulations,2025-01-23T13:37:09Z,"Alessandro Fontana, Marios Kyriazis","Biological evolution continuously refines the design of species, resulting in
highly optimised organisms over hundreds of millennia. Intuitively, we expect
that random changes-evolution's primary mechanism-are more likely to be harmful
than beneficial, leading to widespread detrimental effects in evolving species.
The Evolvable Soma Theory of Ageing (ESTA) suggests that ageing is the
cumulative result of these harmful effects, which predominantly cause bodily
damage, while a few may lead to beneficial adaptations that evolution can
exploit. While the disposable soma theory views ageing as a consequence of
limited evolutionary pressure, ESTA posits that ageing is essentially evolution
in action. In this study, we gather evidence supporting this theory through
computer simulations. We conduct experiments using a platform where genes are
linked to onset values that determine when they are expressed. Three scenarios
are tested: one with single-point fitness evaluation, constant mutation rate
and fixed gene onsets; one with single-point fitness evaluation,
onset-dependent mutation rate and fixed gene onsets; and one with spread
fitness evaluation, onset-dependent mutation rate and evolvable gene onsets.
The last scenario, which embodies the evolvable soma hypothesis, demonstrates
superior performance in both algorithmic efficiency and biological plausibility
compared to the others.",http://arxiv.org/abs/2501.13657v1
Certified Robustness Under Bounded Levenshtein Distance,2025-01-23T13:58:53Z,"Elias Abad Rocamora, Grigorios G. Chrysos, Volkan Cevher","Text classifiers suffer from small perturbations, that if chosen
adversarially, can dramatically change the output of the model. Verification
methods can provide robustness certificates against such adversarial
perturbations, by computing a sound lower bound on the robust accuracy.
Nevertheless, existing verification methods incur in prohibitive costs and
cannot practically handle Levenshtein distance constraints. We propose the
first method for computing the Lipschitz constant of convolutional classifiers
with respect to the Levenshtein distance. We use these Lipschitz constant
estimates for training 1-Lipschitz classifiers. This enables computing the
certified radius of a classifier in a single forward pass. Our method, LipsLev,
is able to obtain $38.80$% and $13.93$% verified accuracy at distance $1$ and
$2$ respectively in the AG-News dataset, while being $4$ orders of magnitude
faster than existing approaches. We believe our work can open the door to more
efficient verification in the text domain.",http://arxiv.org/abs/2501.13676v2
Training-Free Consistency Pipeline for Fashion Repose,2025-01-23T14:17:01Z,"Potito Aghilar, Vito Walter Anelli, Michelantonio Trizio, Tommaso Di Noia","Recent advancements in diffusion models have significantly broadened the
possibilities for editing images of real-world objects. However, performing
non-rigid transformations, such as changing the pose of objects or image-based
conditioning, remains challenging. Maintaining object identity during these
edits is difficult, and current methods often fall short of the precision
needed for industrial applications, where consistency is critical.
Additionally, fine-tuning diffusion models requires custom training data, which
is not always accessible in real-world scenarios. This work introduces
FashionRepose, a training-free pipeline for non-rigid pose editing specifically
designed for the fashion industry. The approach integrates off-the-shelf models
to adjust poses of long-sleeve garments, maintaining identity and branding
attributes. FashionRepose uses a zero-shot approach to perform these edits in
near real-time, eliminating the need for specialized training. consistent image
editing. The solution holds potential for applications in the fashion industry
and other fields demanding identity preservation in image editing.",http://arxiv.org/abs/2501.13692v1
Naked and truly naked rotating black holes,2025-01-23T14:49:03Z,"H. V. Ovcharenko, O. B. Zaslavskii","Previously, it was noticed that in some space-times with Killing horizons
some curvature components, responsible for tidal forces, small or even zero in
the static frame, become enhanced from the viewpoint of a falling observer.
This leads to the notion of so-called naked black holes. If some components in
the frame attached to a free-falling observer formally diverge, although scalar
invariants remain finite, such space-times was named ""truly naked black holes""
(in mathematical language, one can speak about non-scalar singularity).
Previous results included static spherically symmetric or distorted static
metrics. In the present work, we generalized them to include rotation in
consideration. We also scrutiny how the algebraic type can change in the
vicinity of the horizon due to local Lorentz boost. Our approach essentially
uses the Newman-Penrose formalism, so we analyze the behavior of Weyl scalar
for different kinds of observers.",http://arxiv.org/abs/2501.13719v1
"Centralized Versus Distributed Routing for Large-Scale Satellite
  Networks",2025-01-23T15:19:09Z,"Rudrapatna Vallabh Ramakanth, Eytan Modiano","An important choice in the design of satellite networks is whether the
routing decisions are made in a distributed manner onboard the satellite, or
centrally on a ground-based controller. We study the tradeoff between
centralized and distributed routing in large-scale satellite networks. In
particular, we consider a centralized routing scheme that has access to global
but delayed network state information and a distributed routing scheme that has
access to local but real-time network state information. For both routing
schemes, we analyze the throughput and delay performance of shortest-path
algorithms in networks with and without buffers onboard the satellites. We show
that distributed routing outperforms centralized routing when the rate of
changes in the network link state is comparable to the inherent propagation and
transmission delays. In particular, we show that in highly dynamic networks
without buffers, the distributed scheme achieves higher throughput than a
centralized scheme. In networks with buffers, the distributed scheme achieves
lower delays with the same throughput.",http://arxiv.org/abs/2501.13744v1
"Unveiling the Power of Noise Priors: Enhancing Diffusion Models for
  Mobile Traffic Prediction",2025-01-23T16:13:08Z,"Zhi Sheng, Yuan Yuan, Jingtao Ding, Yong Li","Accurate prediction of mobile traffic, \textit{i.e.,} network traffic from
cellular base stations, is crucial for optimizing network performance and
supporting urban development. However, the non-stationary nature of mobile
traffic, driven by human activity and environmental changes, leads to both
regular patterns and abrupt variations. Diffusion models excel in capturing
such complex temporal dynamics due to their ability to capture the inherent
uncertainties. Most existing approaches prioritize designing novel denoising
networks but often neglect the critical role of noise itself, potentially
leading to sub-optimal performance. In this paper, we introduce a novel
perspective by emphasizing the role of noise in the denoising process. Our
analysis reveals that noise fundamentally shapes mobile traffic predictions,
exhibiting distinct and consistent patterns. We propose NPDiff, a framework
that decomposes noise into \textit{prior} and \textit{residual} components,
with the \textit{prior} derived from data dynamics, enhancing the model's
ability to capture both regular and abrupt variations. NPDiff can seamlessly
integrate with various diffusion-based prediction models, delivering
predictions that are effective, efficient, and robust. Extensive experiments
demonstrate that it achieves superior performance with an improvement over
30\%, offering a new perspective on leveraging diffusion models in this domain.",http://arxiv.org/abs/2501.13794v1
Regularizing random points by deleting a few,2025-01-23T16:35:35Z,"Dmitriy Bilyk, Stefan Steinerberger","It is well understood that if one is given a set $X \subset [0,1]$ of $n$
independent uniformly distributed random variables, then $$ \sup_{0 \leq x \leq
1} \left| \frac{\# X \cap [0,x]}{\# X} - x \right| \lesssim
\frac{\sqrt{\log{n}}}{ \sqrt{n}} \qquad \mbox{with very high probability.} $$
We show that one can improve the error term by removing a few of the points.
For any $m \leq 0.001n$ there exists a subset $Y \subset X$ obtained by
deleting at most $m$ points, so that the error term drops from $\sim
\sqrt{\log{n}}/\sqrt{n}$ to $ \log{(n)}/m$ with high probability. When $m=cn$
for a small $0 \leq c \leq 0.001$, this achieves the essentially optimal
asymptotic order of discrepancy $\log(n)/n$. The proof is constructive and
works in an online setting (where one is given the points sequentially, one at
a time, and has to decide whether to keep or discard it). A change of variables
shows the same result for any random variables on the real line with absolutely
continuous density.",http://arxiv.org/abs/2501.13813v1
Four-quark operators with $ΔF = 2$ in the GIRS scheme,2025-01-17T11:47:51Z,"M. Constantinou, M. Costa, H. Herodotou, H. Panagopoulos, G. Spanoudes","We calculate the mixing matrices of four-quark operators that change flavor
numbers by two units. Our approach employs two schemes: the coordinate-space
Gauge Invariant Renormalization Scheme (GIRS) and the Modified Minimal
Subtraction scheme. From our perturbative computations, we extract the
conversion factors between these two renormalization schemes at the
next-to-leading order. A significant challenge in the study of four-quark
operators is that they mix among themselves upon renormalization. Additionally,
computations in GIRS at a given order in perturbation theory require Feynman
diagrams with at least one additional loop. The extraction of the conversion
factors involves calculating two-point Green's functions, which include
products of two four-quark operators, and three-point Green's functions, which
involve one four-quark operator and two bilinear operators, with all operators
located at distinct spacetime points. We investigate both parity-conserving and
parity-violating four-quark operators. This calculation is relevant to the
determination of Cabibbo-Kobayashi-Maskawa (CKM) matrix elements from numerical
simulations using the GIRS scheme.",http://arxiv.org/abs/2501.13939v1
Self-Explanation in Social AI Agents,2025-01-19T03:03:15Z,"Rhea Basappa, Mustafa Tekman, Hong Lu, Benjamin Faught, Sandeep Kakar, Ashok K. Goel","Social AI agents interact with members of a community, thereby changing the
behavior of the community. For example, in online learning, an AI social
assistant may connect learners and thereby enhance social interaction. These
social AI assistants too need to explain themselves in order to enhance
transparency and trust with the learners. We present a method of
self-explanation that uses introspection over a self-model of an AI social
assistant. The self-model is captured as a functional model that specifies how
the methods of the agent use knowledge to achieve its tasks. The process of
generating self-explanations uses Chain of Thought to reflect on the self-model
and ChatGPT to provide explanations about its functioning. We evaluate the
self-explanation of the AI social assistant for completeness and correctness.
We also report on its deployment in a live class.",http://arxiv.org/abs/2501.13945v1
Predictive Learning in Energy-based Models with Attractor Structures,2025-01-23T11:04:25Z,"Xingsi Dong, Pengxiang Yuan, Si Wu","Predictive models are highly advanced in understanding the mechanisms of
brain function. Recent advances in machine learning further underscore the
power of prediction for optimal representation in learning. However, there
remains a gap in creating a biologically plausible model that explains how the
neural system achieves prediction. In this paper, we introduce a framework that
employs an energy-based model (EBM) to capture the nuanced processes of
predicting observation after action within the neural system, encompassing
prediction, learning, and inference. We implement the EBM with a hierarchical
structure and integrate a continuous attractor neural network for memory,
constructing a biologically plausible model. In experimental evaluations, our
model demonstrates efficacy across diverse scenarios. The range of actions
includes eye movement, motion in environments, head turning, and static
observation while the environment changes. Our model not only makes accurate
predictions for environments it was trained on, but also provides reasonable
predictions for unseen environments, matching the performances of machine
learning methods in multiple tasks. We hope that this study contributes to a
deep understanding of how the neural system performs prediction.",http://arxiv.org/abs/2501.13997v1
Grover-Sagnac interferometer,2025-01-23T19:32:13Z,"Christopher R. Schwarze, Anthony D. Manni, David S. Simon, Abdoulaye Ndao, Alexander V. Sergienko","We demonstrate a nontraditional design of the Sagnac interferometer by
replacing the commonly used beam splitter with a linear-optical Grover
multiport. This substitution creates a pole at the origin of the device
parameter space with an associated resonance in the output intensity. The
structure of this resonance is dictated only by the non-reciprocal portion of
the phase acquired in the Sagnac loop. This property directly results from
adopting the more symmetric and higher-dimensional central scattering coin, and
allows for a different approach to registering and detecting the non-reciprocal
Sagnac phase. This parameter may be extracted from the width of a peak or dip
in the interferogram instead of tracing small changes in power as in
traditional Sagnac interferometry. We discuss how losses affect the system and
potential metrological applications.",http://arxiv.org/abs/2501.14049v1
Life in the Slow Lane: A Search for Long Term Variability in ASAS-SN,2025-01-23T19:49:36Z,"Sydney Petz, Christopher S. Kochanek","We search a sample of 9,361,613 isolated sources with 13<g<14.5 mag for
slowly varying sources. We select sources with brightness changes larger than ~
0.03 mag/year over 10 years, removing false positives due to, for example,
nearby bright stars or high proper motions. After a thorough visual inspection,
we find 782 slowly varying systems. Of these systems, 433 are identified as
variables for the first time and 349 are previously classified as variables.
Previously classified systems were mostly identified as semi-regular variables
(SR), slow irregular variables (L), spotted stars (ROT), or unknown (MISC or
VAR), as long time scale variability does not fit into a standard class. The
stellar sources are scattered across the CMD and can be placed into 5 groups
that exhibit distinct behaviors. The largest groups are very red subgiants and
lower main sequence stars. There are also a small number of AGN. There are 551
candidates (~70 percent) that also show shorter time scale periodic
variability, mostly with periods longer than 10 days. The variability of 191 of
these candidates may be related to dust.",http://arxiv.org/abs/2501.14058v1
"Single-Letter Characterization of the Mismatched Distortion-Rate
  Function",2025-01-23T20:39:37Z,"Maël Le Treust, Tristan Tomala","The mismatched distortion-rate problem has remained open since its
formulation by Lapidoth in 1997. In this paper, we characterize the mismatched
distortion-rate function. Our single-letter solution highlights the adequate
conditional distributions for the encoder and the decoder. The achievability
result relies on a time-sharing argument that allows to convexify the upper
bound of Lapidoth. We show that it is sufficient to consider two regimes, one
with a large rate and another one with a small rate. Our main contribution is
the converse proof. Suppose that the encoder selects a single-letter
conditional distribution distinct from the one in the solution, we construct an
encoding strategy that leads to the same expected cost for both encoder and
decoder. This ensures that the encoder cannot gain by changing the
single-letter conditional distribution. This argument relies on a careful
identification of the sequence of auxiliary random variables. By building on
Caratheodory's Theorem we show that the cardinality of the auxiliary random
variables is equal to the one of the source alphabet plus three.",http://arxiv.org/abs/2501.14081v1
Selective enhancement of Coulomb interactions in planar Weyl fermions,2025-01-23T23:00:25Z,"Vadym Apalkov, Wenchen Luo, Tapash Chakraborty","We report on our study of the electron interaction effects in topological
two-dimensional (2D) materials placed in a quantizing magnetic field. Taking
our cue from a recent experimental report, we consider a particular case of
bismuthene monolayer with a strong spin-orbit interaction which can be a Weyl
semimetal when placed on a specially tuned substrate. Interestingly, we observe
that in some Landau levels of this material, the interaction effects are
strongly enhanced compared to those for a conventional 2D system. Such an
enhancement of electron-electron interactions in these materials is largely due
to an anisotropy present in the materials. Additionally, the interaction
effects can be tuned by changing the coupling to the substrate and the
strongest inter-electron interactions are observed when the system is a Weyl
semimental. The observed enhancement of the interaction effects can therefore
be an important signature of the 2D Weyl fermions.",http://arxiv.org/abs/2501.14128v2
Optimal Preconditioning for Online Quadratic Cone Programming,2025-01-24T02:54:06Z,"Abhinav G. Kamath, Purnanand Elango, Behçet Açıkmeşe","First-order conic optimization solvers are sensitive to problem conditioning
and typically perform poorly in the face of ill-conditioned problem data. To
mitigate this, we propose an approach to preconditioning for a class of
quadratic cone programs (QCPs), i.e., conic optimization problems with a
quadratic objective function, wherein the objective function is strongly convex
and possesses a certain structure. This approach lends itself to
factorization-free, customizable, first-order conic optimization for online
applications wherein the solver is called repeatedly to solve problems of the
same size/structure, but with changing problem data. One of the steps in the
proposed preconditioning procedure is to scale the objective function: in
addition to deriving an analytical expression for the optimal objective
function scaling factor, we establish the relationship between the objective
function scaling factor and the primal-dual step-size ratio for a first-order
method, the proportional-integral projected gradient method (PIPG), which
applies to the general class of QCPs, including quadratic programs (QPs),
second-order cone programs (SOCPs), and semidefinite programs (SDPs). We
demonstrate the efficacy of our approach on a numerical nonconvex trajectory
optimization example, using sequential conic optimization (SeCO).",http://arxiv.org/abs/2501.14191v1
"PuzzleGPT: Emulating Human Puzzle-Solving Ability for Time and Location
  Prediction",2025-01-24T03:28:37Z,"Hammad Ayyubi, Xuande Feng, Junzhang Liu, Xudong Lin, Zhecan Wang, Shih-Fu Chang","The task of predicting time and location from images is challenging and
requires complex human-like puzzle-solving ability over different clues. In
this work, we formalize this ability into core skills and implement them using
different modules in an expert pipeline called PuzzleGPT. PuzzleGPT consists of
a perceiver to identify visual clues, a reasoner to deduce prediction
candidates, a combiner to combinatorially combine information from different
clues, a web retriever to get external knowledge if the task can't be solved
locally, and a noise filter for robustness. This results in a zero-shot,
interpretable, and robust approach that records state-of-the-art performance on
two datasets -- TARA and WikiTilo. PuzzleGPT outperforms large VLMs such as
BLIP-2, InstructBLIP, LLaVA, and even GPT-4V, as well as automatically
generated reasoning pipelines like VisProg, by at least 32% and 38%,
respectively. It even rivals or surpasses finetuned models.",http://arxiv.org/abs/2501.14210v1
"When GNNs meet symmetry in ILPs: an orbit-based feature augmentation
  approach",2025-01-24T03:33:33Z,"Qian Chen, Lei Li, Qian Li, Jianghua Wu, Akang Wang, Ruoyu Sun, Xiaodong Luo, Tsung-Hui Chang, Qingjiang Shi","A common characteristic in integer linear programs (ILPs) is symmetry,
allowing variables to be permuted without altering the underlying problem
structure. Recently, GNNs have emerged as a promising approach for solving
ILPs. However, a significant challenge arises when applying GNNs to ILPs with
symmetry: classic GNN architectures struggle to differentiate between symmetric
variables, which limits their predictive accuracy. In this work, we investigate
the properties of permutation equivariance and invariance in GNNs, particularly
in relation to the inherent symmetry of ILP formulations. We reveal that the
interaction between these two factors contributes to the difficulty of
distinguishing between symmetric variables. To address this challenge, we
explore the potential of feature augmentation and propose several guiding
principles for constructing augmented features. Building on these principles,
we develop an orbit-based augmentation scheme that first groups symmetric
variables and then samples augmented features for each group from a discrete
uniform distribution. Empirical results demonstrate that our proposed approach
significantly enhances both training efficiency and predictive performance.",http://arxiv.org/abs/2501.14211v1
"Active Learning for Continual Learning: Keeping the Past Alive in the
  Present",2025-01-24T06:46:58Z,"Jaehyun Park, Dongmin Park, Jae-Gil Lee","Continual learning (CL) enables deep neural networks to adapt to
ever-changing data distributions. In practice, there may be scenarios where
annotation is costly, leading to active continual learning (ACL), which
performs active learning (AL) for the CL scenarios when reducing the labeling
cost by selecting the most informative subset is preferable. However,
conventional AL strategies are not suitable for ACL, as they focus solely on
learning the new knowledge, leading to catastrophic forgetting of previously
learned tasks. Therefore, ACL requires a new AL strategy that can balance the
prevention of catastrophic forgetting and the ability to quickly learn new
tasks. In this paper, we propose AccuACL, Accumulated informativeness-based
Active Continual Learning, by the novel use of the Fisher information matrix as
a criterion for sample selection, derived from a theoretical analysis of the
Fisher-optimality preservation properties within the framework of ACL, while
also addressing the scalability issue of Fisher information-based AL. Extensive
experiments demonstrate that AccuACL significantly outperforms AL baselines
across various CL algorithms, increasing the average accuracy and forgetting by
23.8% and 17.0%, respectively, in average.",http://arxiv.org/abs/2501.14278v1
"Robustified Time-optimal Point-to-point Motion Planning and Control
  under Uncertainty",2025-01-24T14:29:58Z,"Shuhao Zhang, Jan Swevers","This paper proposes a novel approach to formulate time-optimal point-to-point
motion planning and control under uncertainty. The approach defines a
robustified two-stage Optimal Control Problem (OCP), in which stage 1, with a
fixed time grid, is seamlessly stitched with stage 2, which features a variable
time grid. Stage 1 optimizes not only the nominal trajectory, but also feedback
gains and corresponding state covariances, which robustify constraints in both
stages. The outcome is a minimized uncertainty in stage 1 and a minimized total
motion time for stage 2, both contributing to the time optimality and safety of
the total motion. A timely replanning strategy is employed to handle changes in
constraints and maintain feasibility, while a tailored iterative algorithm is
proposed for efficient, real-time OCP execution.",http://arxiv.org/abs/2501.14526v1
"Wearable slot antenna at 2.45 GHz for off-body radiation: analysis of
  efficiency, frequency shift and body absorption",2025-01-24T14:53:26Z,"Marta Fernandez, Hugo G. Espinosa, David V. Thiel, Amaia Arrinda","The interaction of body worn antennas with the human body causes a
significant decrease in the antenna efficiency and a shift in the resonant
frequency. A resonant slot in a small conductive box placed on the body has
been shown to reduce these effects. The specific absorption rate (SAR) is less
than international health standards for most wearable antennas due to the small
transmitter power. This paper reports the linear relationship between the power
absorbed by biological tissues at different locations on the body, and the
radiation efficiency based on numerical modeling (r = 0.99). While the -10 dB
bandwidth of the antenna remains constant and equal to 12.5%, the maximum
frequency shift occurs when the antenna is close to the elbow (6.61%) and on
the thigh (5.86%). The smallest change was found on the torso (4.21%).
Participants with body-mass index (BMI) between 17 and 29 kg/m2 took part in
experimental measurements, where the maximum frequency shift was 2.51%.
Measurements show better agreement with simulations on the upper arm. These
experimental results demonstrate that the BMI for each individual has little
effect on the performance of the antenna.",http://arxiv.org/abs/2501.14549v1
Scanning gate microscopy detection of Majorana bound states,2025-01-24T15:07:34Z,"S. Maji, M. P. Nowak","We theoretically study scanning gate microscopy of a
superconductor-proximitized semiconducting wire focusing on the possibility of
detection of Majorana bound states. We exploit the possibility to create local
potential perturbation by the scanning gate tip which allows controllable
modification of the spatial distribution of the Majorana modes, which is
translated into changes in their energy structure. When the tip scans across
the system, it effectively divides the wire into two parts with controllable
lengths, in which two pairs of Majorana states are created when the system is
in the topological regime. For strong values of the tip potential the pairs are
decoupled, and the presence of Majorana states can be detected via local
tunneling spectroscopy that resolves the energy splittings resulting from the
Majorana states wave functions overlap. Importantly, as the system is probed
spatially via the tip, this technique can distinguish Majorana bound states
from quasi-Majorana states localized on smooth potential barriers. We
demonstrate that for weaker tip potentials the two neighboring Majorana states
hybridize opening pronounced anticrossings in the energy spectra which are
reflected in local conductance maps and which result in non-zero non-local
conductance features. Finally, we demonstrate the effect of the disorder on the
scanning gate microscopy spectroscopy maps.",http://arxiv.org/abs/2501.14562v1
MatAnyone: Stable Video Matting with Consistent Memory Propagation,2025-01-24T17:56:24Z,"Peiqing Yang, Shangchen Zhou, Jixin Zhao, Qingyi Tao, Chen Change Loy","Auxiliary-free human video matting methods, which rely solely on input
frames, often struggle with complex or ambiguous backgrounds. To address this,
we propose MatAnyone, a robust framework tailored for target-assigned video
matting. Specifically, building on a memory-based paradigm, we introduce a
consistent memory propagation module via region-adaptive memory fusion, which
adaptively integrates memory from the previous frame. This ensures semantic
stability in core regions while preserving fine-grained details along object
boundaries. For robust training, we present a larger, high-quality, and diverse
dataset for video matting. Additionally, we incorporate a novel training
strategy that efficiently leverages large-scale segmentation data, boosting
matting stability. With this new network design, dataset, and training
strategy, MatAnyone delivers robust and accurate video matting results in
diverse real-world scenarios, outperforming existing methods.",http://arxiv.org/abs/2501.14677v1
"Towards Better Understanding Table Instruction Tuning: Decoupling the
  Effects from Data versus Models",2025-01-24T18:50:26Z,"Naihao Deng, Sheng Zhang, Henghui Zhu, Shuaichen Chang, Jiani Zhang, Alexander Hanbo Li, Chung-Wei Hang, Hideo Kobayashi, Yiqun Hu, Patrick Ng","Recent advances in natural language processing have leveraged instruction
tuning to enhance Large Language Models (LLMs) for table-related tasks.
However, previous works train different base models with different training
data, lacking an apples-to-apples comparison across the result table LLMs. To
address this, we fine-tune base models from the Mistral, OLMo, and Phi families
on existing public training datasets. Our replication achieves performance on
par with or surpassing existing table LLMs, establishing new state-of-the-art
performance on Hitab, a table question-answering dataset. More importantly,
through systematic out-of-domain evaluation, we decouple the contributions of
training data and the base model, providing insight into their individual
impacts. In addition, we assess the effects of table-specific instruction
tuning on general-purpose benchmarks, revealing trade-offs between
specialization and generalization.",http://arxiv.org/abs/2501.14717v1
A unified approach for domination and packing problems in graphs,2025-01-08T15:26:13Z,"E. Hinrichsen, G. Nasini, N. Vansteenkiste","In this paper, we introduce new concepts of domination and packing functions
in graphs, which generalize, respectively, the labelled dominating and packing
functions defined by Lee and Chang in 2008, and Hinrichsen et al. in 2019.
These generalized functions offer a unified and simpler framework for
addressing many of the variations of domination and packing concepts in graphs
explored in the literature. Interestingly, their associated optimization
problems turn out to be equivalent, providing insight to explain the observed
coincidences in computational complexity results for graph classes where both
problems, the domination one and its corresponding packing variation, have been
analyzed. This equivalence also allows us to solve some computational
complexity open questions, for some graph classes.
  Furthermore, we prove that the generalized problems remain solvable in
polynomial time for graphs with bounded clique-width and strongly chordal
graphs.",http://arxiv.org/abs/2501.14789v1
Shape Morphing Metamaterials,2025-01-14T18:29:49Z,"Krzysztof K. Dudek, Muamer Kadic, Corentin Coulais, Katia Bertoldi","Mechanical metamaterials leverage geometric design to achieve unconventional
properties, such as high strength at low density, efficient wave guiding, and
complex shape morphing. The ability to control shape changes builds on the
complex relationship between geometry and nonlinear mechanics, and opens new
possibilities for disruptive technologies across diverse fields, including
wearable devices, medical technology, robotics, and beyond. In this review of
shape-morphing metamaterials, we examine the current state of the field and
propose a unified classification system for the mechanisms involved, as well as
the design principles underlying them. Specifically, we explore two main
categories of unit cells-those that exploit structural anisotropy or internal
rotations-and two potential approaches to tessellating these cells: based on
kinematic compatibility or geometric frustration. We conclude by discussing the
available design tools and highlighting emerging challenges in the development
of shape-morphing metamaterials.",http://arxiv.org/abs/2501.14804v1
A VM-HDL Co-Simulation Framework for Systems with PCIe-Connected FPGAs,2025-01-19T22:06:36Z,"Shenghsun Cho, Mrunal Patel, Basavaraj Kaladagi, Han Chen, Tapti Palit, Michael Ferdman, Peter Milder","PCIe-connected FPGAs are gaining popularity as an accelerator technology in
data centers. However, it is challenging to jointly develop and debug host
software and FPGA hardware. Changes to the hardware design require a
time-consuming FPGA synthesis process, and modification to the software,
especially the operating system and device drivers, can frequently cause the
system to hang, without providing enough information for debugging. The
combination of these problems results in long debug iterations and a slow
development process. To overcome these problems, we designed a VM-HDL
co-simulation framework, which is capable of running the same software,
operating system, and hardware designs as the target physical system, while
providing full visibility and significantly shorter debug iterations.",http://arxiv.org/abs/2501.14815v1
Multi-Fidelity Machine Learning Applied to Steady Fluid Flows,2025-01-24T19:00:24Z,"Kazuko W. Fuchi, Eric M. Wolf, David S. Makhija, Christopher R. Schrock, Philip S. Beran","A machine learning method to predict steady external fluid flows using
elliptic input features is introduced. Using data from as few as one
high-fidelity simulation, the proposed method produces models generalizable
under changes to boundary geometry by using solutions to elliptic boundary
value problems over the flow domain as the model input, instead of Cartesian
coordinates of the domain. Training data is generated through pointwise
evaluation of flow features at points selected through a quad-tree adaptive
sampling method to concentrate training points in areas with large field
gradients. Models are trained within a training window around the body, while
predictions are smoothly extended to freestream conditions using a
Partition-of-Unity extension. Predictive capabilities of the machine learning
model are demonstrated in steady-state flow of incompressible fluid around a
cylinder and a Joukowski airfoil. The predicted flow field is used to
warm-start CFD simulations to achieve acceleration in solver convergence.",http://arxiv.org/abs/2501.14870v1
"Atypical vortex lattice and the magnetic penetration depth in
  superconducting Sr$_2$RuO$_4$ deduced by $μ$SR",2025-01-24T19:03:37Z,"M. Yakovlev, Z. Kartsonas, J. E. Sonier","The muon spin rotation ($\mu$SR) technique has been applied to determine the
behavior of the in-plane magnetic penetration depth ($\lambda_{ab}$) in the
vortex state of the unconventional superconductor Sr$_2$RuO$_4$ as a means of
gaining insight into its still unknown superconducting order parameter. A
recent $\mu$SR study of Sr$_2$RuO$_4$ reported a $T$-linear temperature
dependence for $\lambda_{ab}$ at low temperatures that was not identified in an
earlier $\mu$SR study. Here we show that there is no significant difference
between the data in the early and recent $\mu$SR studies and both are
compatible with the limiting low-temperature $\lambda_{ab} \sim T^2$ dependence
expected from measurements of the change in $\lambda_{ab}(T)$ in the Meissner
state by other techniques. However, we argue that at this time there is no
valid theoretical model for reliably determining the absolute value of
$\lambda_{ab}$ in Sr$_2$RuO$_4$ from $\mu$SR measurements. Instead, we identify
the formation of an unusual square vortex lattice that introduces a new
constraint on candidate superconducting order parameters for Sr$_2$RuO$_4$.",http://arxiv.org/abs/2501.14876v1
Cuscuton-like contribution to dark energy evolution,2025-01-24T20:22:55Z,"D. Bazeia, J. D. Dantas, S. Santos da Costa","This work deals with the presence of the cuscuton term in the otherwise
standard dark energy evolution under the usual FLRW background. We disclose a
first-order framework similar to the Hamilton-Jacobi formalism, which helps us
to solve the equations of motion and find analytical solutions. We explore
several possibilities, concentrating mainly on how the cuscuton-like
contribution works to modify cosmic evolution. Some results are of current
interest since they describe scenarios capable of changing the evolution,
adding or excluding possible distinct phases during the Universe's expansion
history. Additionally, we present interesting constraints on the cuscuton-like
contribution for the dark energy evolution using a set of homogeneous
geometrical observational probes. Finally, based on the Akaike Information
Criterion (AIC), we perform a statistical comparison of the cuscuton-like model
with $\Lambda$CDM, and find strong support for our model.",http://arxiv.org/abs/2501.14909v1
"Predictive Modeling and Uncertainty Quantification of Fatigue Life in
  Metal Alloys using Machine Learning",2025-01-25T03:43:19Z,"Jiang Chang, Deekshith Basvoju, Aleksandar Vakanski, Indrajit Charit, Min Xian","Recent advancements in machine learning-based methods have demonstrated great
potential for improved property prediction in material science. However,
reliable estimation of the confidence intervals for the predicted values
remains a challenge, due to the inherent complexities in material modeling.
This study introduces a novel approach for uncertainty quantification in
fatigue life prediction of metal materials based on integrating knowledge from
physics-based fatigue life models and machine learning models. The proposed
approach employs physics-based input features estimated using the Basquin
fatigue model to augment the experimentally collected data of fatigue life.
Furthermore, a physics-informed loss function that enforces boundary
constraints for the estimated fatigue life of considered materials is
introduced for the neural network models. Experimental validation on datasets
comprising collected data from fatigue life tests for Titanium alloys and
Carbon steel alloys demonstrates the effectiveness of the proposed approach.
The synergy between physics-based models and data-driven models enhances the
consistency in predicted values and improves uncertainty interval estimates.",http://arxiv.org/abs/2501.15057v1
"SpatioTemporal Learning for Human Pose Estimation in Sparsely-Labeled
  Videos",2025-01-25T04:43:12Z,"Yingying Jiao, Zhigang Wang, Sifan Wu, Shaojing Fan, Zhenguang Liu, Zhuoyue Xu, Zheqi Wu","Human pose estimation in videos remains a challenge, largely due to the
reliance on extensive manual annotation of large datasets, which is expensive
and labor-intensive. Furthermore, existing approaches often struggle to capture
long-range temporal dependencies and overlook the complementary relationship
between temporal pose heatmaps and visual features. To address these
limitations, we introduce STDPose, a novel framework that enhances human pose
estimation by learning spatiotemporal dynamics in sparsely-labeled videos.
STDPose incorporates two key innovations: 1) A novel Dynamic-Aware Mask to
capture long-range motion context, allowing for a nuanced understanding of pose
changes. 2) A system for encoding and aggregating spatiotemporal
representations and motion dynamics to effectively model spatiotemporal
relationships, improving the accuracy and robustness of pose estimation.
STDPose establishes a new performance benchmark for both video pose propagation
(i.e., propagating pose annotations from labeled frames to unlabeled frames)
and pose estimation tasks, across three large-scale evaluation datasets.
Additionally, utilizing pseudo-labels generated by pose propagation, STDPose
achieves competitive performance with only 26.7% labeled data.",http://arxiv.org/abs/2501.15073v1
"Can Large Language Models Be Trusted as Black-Box Evolutionary
  Optimizers for Combinatorial Problems?",2025-01-25T05:19:19Z,"Jie Zhao, Tao Wen, Kang Hao Cheong","Evolutionary computation excels in complex optimization but demands deep
domain knowledge, restricting its accessibility. Large Language Models (LLMs)
offer a game-changing solution with their extensive knowledge and could
democratize the optimization paradigm. Although LLMs possess significant
capabilities, they may not be universally effective, particularly since
evolutionary optimization encompasses multiple stages. It is therefore
imperative to evaluate the suitability of LLMs as evolutionary optimizer (EVO).
Thus, we establish a series of rigid standards to thoroughly examine the
fidelity of LLM-based EVO output in different stages of evolutionary
optimization and then introduce a robust error-correction mechanism to mitigate
the output uncertainty. Furthermore, we explore a cost-efficient method that
directly operates on entire populations with excellent effectiveness in
contrast to individual-level optimization. Through extensive experiments, we
rigorously validate the performance of LLMs as operators targeted for
combinatorial problems. Our findings provide critical insights and valuable
observations, advancing the understanding and application of LLM-based
optimization.",http://arxiv.org/abs/2501.15081v1
"Dynamic Modulation of Electronic and Optical Properties in GaN Bilayers
  by Interlayer Sliding",2025-01-25T05:32:13Z,"Heeju Kim, Gunn Kim","In this study, we present a first-principles investigation of the electronic
and optical properties of gallium nitride (GaN) bilayers, focusing on the
influence of interlayer sliding and spacing. In contrast to the earlier studies
on discrete stacking configurations, we explore the dynamic evolution of the
properties during transitions between stable stacking arrangements. Using
density functional theory calculations, we systematically analyze the impact of
these structural variations on the electronic band structure and optical
absorption spectra of GaN bilayers. The analysis includes both high-symmetry
stacking configurations (AA', AB', and AC') and intermediate states generated
by controlled in-plane atomic displacements, thereby providing a comprehensive
understanding of the property changes associated with interlayer sliding. The
findings of this study provide valuable insights into the potential for tuning
the electronic and optical response of two-dimensional GaN for applications in
nanoscale photonic and electronic devices, where precise control over
interlayer interactions and stacking is crucial.",http://arxiv.org/abs/2501.15088v1
Topological photonic crystal fibre,2025-01-25T07:17:06Z,"Bofeng Zhu, Kevin Hean, Stephan Wong, Yuxi Wang, Rimi Banerjee, Haoran Xue, Qiang Wang, Alexander Cerjan, Qi Jie Wang, Wonkeun Chang, Yi Dong Chong","Photonic crystal fibres (PCFs) are optical fibres that guide light using a
modulated dielectric medium. They provide an exceptionally versatile platform
for various applications, thanks to the flexibility with which light-guiding
can be customised by modifying the fibre geometry. Here, we realise a PCF with
guided modes produced by photonic bandstructure topology rather than
conventional mode-trapping mechanisms. The design, which is compatible with the
stack-and-draw fabrication process, consists of a cross-sectional photonic
topological crystalline insulator with a disclination. A bulk-defect
correspondence produces degenerate topological modes, lying below the cladding
light line. We use various theoretical methods to confirm their topological
origins, including a spectral localiser that makes minimal assumptions about
the bandstructure. Our experiments on the fabricated topological fibre show it
transmitting visible to near-infrared light with low losses of 10--20 dB/km,
which do not increase much when the fibre is bent. A comparable solid-core PCF
of conventional design exhibits substantially higher bending losses. Optical
fibres based on topological modes thus hold promise for improved performance
and novel functionalities.",http://arxiv.org/abs/2501.15107v1
Generating Negative Samples for Multi-Modal Recommendation,2025-01-25T11:45:49Z,"Yanbiao Ji, Yue Ding, Dan Luo, Chang Liu, Jing Tong, Shaokai Wu, Hongtao Lu","Multi-modal recommender systems (MMRS) have gained significant attention due
to their ability to leverage information from various modalities to enhance
recommendation quality. However, existing negative sampling techniques often
struggle to effectively utilize the multi-modal data, leading to suboptimal
performance. In this paper, we identify two key challenges in negative sampling
for MMRS: (1) producing cohesive negative samples contrasting with positive
samples and (2) maintaining a balanced influence across different modalities.
To address these challenges, we propose NegGen, a novel framework that utilizes
multi-modal large language models (MLLMs) to generate balanced and contrastive
negative samples. We design three different prompt templates to enable NegGen
to analyze and manipulate item attributes across multiple modalities, and then
generate negative samples that introduce better supervision signals and ensure
modality balance. Furthermore, NegGen employs a causal learning module to
disentangle the effect of intervened key features and irrelevant item
attributes, enabling fine-grained learning of user preferences. Extensive
experiments on real-world datasets demonstrate the superior performance of
NegGen compared to state-of-the-art methods in both negative sampling and
multi-modal recommendation.",http://arxiv.org/abs/2501.15183v2
Towards Conscious Service Robots,2025-01-25T12:32:52Z,Sven Behnke,"Deep learning's success in perception, natural language processing, etc.
inspires hopes for advancements in autonomous robotics. However, real-world
robotics face challenges like variability, high-dimensional state spaces,
non-linear dependencies, and partial observability. A key issue is
non-stationarity of robots, environments, and tasks, leading to performance
drops with out-of-distribution data. Unlike current machine learning models,
humans adapt quickly to changes and new tasks due to a cognitive architecture
that enables systematic generalization and meta-cognition. Human brain's System
1 handles routine tasks unconsciously, while System 2 manages complex tasks
consciously, facilitating flexible problem-solving and self-monitoring. For
robots to achieve human-like learning and reasoning, they need to integrate
causal models, working memory, planning, and metacognitive processing. By
incorporating human cognition insights, the next generation of service robots
will handle novel situations and monitor themselves to avoid risks and mitigate
errors.",http://arxiv.org/abs/2501.15198v1
"Reinforcement Learning Controlled Adaptive PSO for Task Offloading in
  IIoT Edge Computing",2025-01-25T13:01:54Z,"Minod Perera, Sheik Mohammad Mostakim Fattah, Sajib Mistry, Aneesh Krishna","Industrial Internet of Things (IIoT) applications demand efficient task
offloading to handle heavy data loads with minimal latency. Mobile Edge
Computing (MEC) brings computation closer to devices to reduce latency and
server load, optimal performance requires advanced optimization techniques. We
propose a novel solution combining Adaptive Particle Swarm Optimization (APSO)
with Reinforcement Learning, specifically Soft Actor Critic (SAC), to enhance
task offloading decisions in MEC environments. This hybrid approach leverages
swarm intelligence and predictive models to adapt to dynamic variables such as
human interactions and environmental changes. Our method improves resource
management and service quality, achieving optimal task offloading and resource
distribution in IIoT edge computing.",http://arxiv.org/abs/2501.15203v1
"Advancing Understanding of Long COVID Pathophysiology Through Quantum
  Walk-Based Network Analysis",2025-01-25T13:23:39Z,"Jaesub Park, Woochang Hwang, Seokjun Lee, Hyun Chang Lee, Méabh MacMahon, Matthias Zilbauer, Namshik Han","Long COVID is a multisystem condition characterized by persistent symptoms
such as fatigue, cognitive impairment, and systemic inflammation, following
COVID-19 infection, yet its mechanisms remain poorly understood. In this study,
we applied quantum walk (QW), a computational approach leveraging quantum
interference, to explore large-scale SARS-CoV-2-induced protein (SIP) networks.
Compared to the conventional random walk with restart (RWR) method, QW
demonstrated superior capacity to traverse deeper regions of the network,
uncovering proteins and pathways implicated in Long COVID. Key findings include
mitochondrial dysfunction, thromboinflammatory responses, and neuronal
inflammation as central mechanisms. QW uniquely identified the CDGSH
iron-sulfur domain-containing protein family and VDAC1, a mitochondrial calcium
transporter, as critical regulators of these processes. VDAC1 emerged as a
potential biomarker and therapeutic target, supported by FDA-approved compounds
such as cannabidiol. These findings highlight QW as a powerful tool for
elucidating complex biological systems and identifying novel therapeutic
targets for conditions like Long COVID.",http://arxiv.org/abs/2501.15208v2
Heat Transfer in Composite Materials: Mechanisms and Applications,2025-01-25T14:29:03Z,"Mohammad Alaghemandi, Morgan Alamandi","Understanding heat transfer in composite materials is essential for
optimizing their performance in critical applications across industries such as
aerospace, automotive, renewable energy, and construction. This review offers a
comprehensive examination of the various heat transfer mechanisms within
composite materials and explores how these processes, spanning different length
and time scales, are influenced by the materials' composition and structure.
Both traditional and advanced analytical and numerical modeling techniques are
explored, emphasizing their importance in predicting and optimizing thermal
behavior across these scales. Furthermore, the review evaluates current
experimental methods for measuring thermal properties, discussing their
limitations and potential areas for enhancement. Significant attention is
devoted to the practical applications of composite materials, from thermal
management in electronic devices to heat-resistant components in aerospace
engineering. Recent innovations, such as the integration of phase change
materials and the development of nano-enhanced composites, are assessed for
their potential to transform heat transfer capabilities. Ongoing challenges are
addressed, and future research directions are outlined, highlighting the need
for advancements in material science and engineering to meet emerging demands.
This review aims to bridge the gap between fundamental research and practical
applications, providing a comprehensive understanding of heat transfer in
composite materials that is both rooted in current science and driven by future
possibilities.",http://arxiv.org/abs/2501.15231v1
"Three-dimensional core-collapse supernova models with phenomenological
  treatment of neutrino flavor conversions",2025-01-25T16:04:00Z,"Kanji Mori, Tomoya Takiwaki, Kei Kotake, Shunsaku Horiuchi","We perform three-dimensional supernova simulations with a phenomenological
treatment of neutrino flavor conversions. We show that the explosion energy can
increase to as high as ~10^51 erg depending on the critical density for the
onset of flavor conversions, due to a significant enhancement of the mean
energy of electron antineutrinos. Our results confirm previous studies showing
such energetic explosions, but for the first time in three-dimensional
configurations. In addition, we predict neutrino and gravitational wave (GW)
signals from a nearby supernova explosion aided by flavor conversions. We find
that the neutrino event number decreases because of the reduced flux of
heavy-lepton neutrinos. In order to detect GWs, next-generation GW telescopes
such as Cosmic Explorer and Einstein Telescope are needed even if the supernova
event is located at the Galactic center. These findings show that the neutrino
flavor conversions can significantly change supernova dynamics and highlight
the importance of further studies on the quantum kinetic equations to determine
the conditions of the conversions and their asymptotic states.",http://arxiv.org/abs/2501.15256v1
"Memory Reviver: Supporting Photo-Collection Reminiscence for People with
  Visual Impairment via a Proactive Chatbot",2025-01-26T05:31:31Z,"Shuchang Xu, Chang Chen, Zichen Liu, Xiaofu Jin, Linping Yuan, Yukang Yan, Huamin Qu","Reminiscing with photo collections offers significant psychological benefits
but poses challenges for people with visual impairment (PVI). Their current
reliance on sighted help restricts the flexibility of this activity. In
response, we explored using a chatbot in a preliminary study. We identified two
primary challenges that hinder effective reminiscence with a chatbot: the
scattering of information and a lack of proactive guidance. To address these
limitations, we present Memory Reviver, a proactive chatbot that helps PVI
reminisce with a photo collection through natural language communication.
Memory Reviver incorporates two novel features: (1) a Memory Tree, which uses a
hierarchical structure to organize the information in a photo collection; and
(2) a Proactive Strategy, which actively delivers information to users at
proper conversation rounds. Evaluation with twelve PVI demonstrated that Memory
Reviver effectively facilitated engaging reminiscence, enhanced understanding
of photo collections, and delivered natural conversational experiences. Based
on our findings, we distill implications for supporting photo reminiscence and
designing chatbots for PVI.",http://arxiv.org/abs/2501.15408v1
"Differentiable Low-computation Global Correlation Loss for Monotonicity
  Evaluation in Quality Assessment",2025-01-26T11:09:16Z,"Yipeng Liu, Qi Yang, Yiling Xu","In this paper, we propose a global monotonicity consistency training strategy
for quality assessment, which includes a differentiable, low-computation
monotonicity evaluation loss function and a global perception training
mechanism. Specifically, unlike conventional ranking loss and linear
programming approaches that indirectly implement the Spearman rank-order
correlation coefficient (SROCC) function, our method directly converts SROCC
into a loss function by making the sorting operation within SROCC
differentiable and functional. Furthermore, to mitigate the discrepancies
between batch optimization during network training and global evaluation of
SROCC, we introduce a memory bank mechanism. This mechanism stores
gradient-free predicted results from previous batches and uses them in the
current batch's training to prevent abrupt gradient changes. We evaluate the
performance of the proposed method on both images and point clouds quality
assessment tasks, demonstrating performance gains in both cases.",http://arxiv.org/abs/2501.15485v1
Quark-Antiquark Potential as a Probe for Holographic Phase Transitions,2025-01-26T13:55:02Z,"Andrés Anabalón, Mariano Chernicoff, Gaston Giribet, Julio Oliva, Martín Reyes","In the recent paper (Phys.Rev.Lett. 133 (2024) 12, 121601), a higher-order
phase transition between the planar, charged, 5-dimensional
Reissner-Nordstr\""om-Anti-de Sitter black hole and a hairy black hole solution
of the type IIB supergravity was investigated. Here, we set out to investigate
these two phases of the theory by means of the holographic probe that describes
a quark-antiquark in the dual gauge theory. We show that the study of the
quark-antiquark potential turns out to be a useful method to investigate the
change of behavior at different values of the parameter that controls the phase
transition, this parameter being the ratio between the chemical potential and
the temperature. In other words, the string probes detects the phase
transition.",http://arxiv.org/abs/2501.15533v1
"Commute Your Domains: Trajectory Optimality Criterion for Multi-Domain
  Learning",2025-01-26T15:12:06Z,"Alexey Rukhovich, Alexander Podolskiy, Irina Piontkovskaya","In multi-domain learning, a single model is trained on diverse data domains
to leverage shared knowledge and improve generalization. The order in which the
data from these domains is used for training can significantly affect the
model's performance on each domain. However, this dependence is under-studied.
In this paper, we investigate the influence of training order (or data mixing)
in multi-domain learning using the concept of Lie bracket of gradient vector
fields. By analyzing the infinitesimal effects of changing the training order,
we identify regions in the parameter space where altering the order between two
training domains can benefit the target loss. We validate the predictions of
our theoretical framework on the influence of training order (or data mixing)
both on a toy example and bilingual LLM pre-training.",http://arxiv.org/abs/2501.15556v1
"Cognitive Performance Measurements and the Impact of Sleep Quality Using
  Wearable and Mobile Sensors",2025-01-26T16:20:15Z,"Aku Visuri, Heli Koskimäki, Niels van Berkel, Andy Alorwu, Ella Peltonen, Saeed Abdullah, Simo Hosio","Human cognitive performance is an underlying factor in most of our daily
lives, and numerous factors influence cognitive performance. In this work, we
investigate how changes in sleep quality influence cognitive performance,
measured from a dataset collected during a 2-month field study. We collected
cognitive performance data (alertness) with the Psychomotor Vigilance Task
(PVT), mobile keyboard typing metrics from participants' smartphones, and sleep
quality metrics through a wearable sleep tracking ring. Our findings highlight
that specific sleep metrics like night-time heart rate, sleep latency, sleep
timing, sleep restfulness, and overall sleep quantity significantly influence
cognitive performance. To strengthen the current research on cognitive
measurements, we introduce smartphone typing metrics as a proxy or a
complementary method for continuous passive measurement of cognitive
performance. Together, our findings contribute to ubiquitous computing via a
longitudinal case study with a novel wearable device, the resulting findings on
the association between sleep and cognitive function, and the introduction of
smartphone keyboard typing as a proxy of cognitive function.",http://arxiv.org/abs/2501.15583v1
"Instability bands for periodic traveling waves in the modified
  Korteweg-de Vries equation",2025-01-26T18:03:54Z,"Shikun Cui, Dmitry E. Pelinovsky","Two families of periodic traveling waves exist in the focusing mKdV (modified
Korteweg-de Vries) equation. Spectral stability of these waveforms with respect
to co-periodic perturbations of the same period has been previously explored by
using spectral analysis and variational formulation. By using tools of
integrability such as a relation between squared eigenfunctions of the Lax pair
and eigenfunctions of the linearized stability problem, we revisit the spectral
stability of these waveforms with respect to perturbations of arbitrary
periods. In agreement with previous works, we find that one family is
spectrally stable for all parameter configurations, whereas the other family is
spectrally unstable for all parameter configurations. We show that the onset of
the co-periodic instability for the latter family changes the instability bands
from figure-$8$ (crossing at the imaginary axis) into figure-$\infty$ (crossing
at the real axis).",http://arxiv.org/abs/2501.15621v1
"Thermodynamics of deformed AdS-Schwarzschild black holes in the presence
  of Thermal fluctuations",2025-01-26T18:27:01Z,"Dhruba Jyoti Gogoi, Poppy Hazarika, Jyatsnasree Bora, Ranjan Changmai","This paper examines the thermodynamic properties and stability of deformed
AdS-Schwarzschild black holes, focusing on the effects of deformation
($\alpha$) and thermal correction parameters ($\beta_1$, $\beta_2$) on phase
transitions and heat capacity. The results show that higher $\alpha$ values
raise the Hawking-Page critical temperature, enhancing thermal stability.
Thermal corrections significantly affect smaller black holes but minimally
impact larger ones, leaving second-order phase transitions unchanged. Heat
capacity analysis identifies stability regions, with sign changes marking
instability. These findings highlight the role of deformation and thermal
corrections in black hole stability, offering insights for extending our
understanding of black hole thermodynamics.",http://arxiv.org/abs/2501.15629v1
"Sensitive particle shape dependence of growth-induced mesoscale nematic
  structure",2025-01-26T21:46:29Z,"Jonas Isensee, Philip Bittihn","Directed growth, anisotropic cell shapes, and confinement drive
self-organization in multicellular systems. We investigate the influence of
particle shape on the distribution and dynamics of nematic microdomains in a
minimal in-silico model of proliferating, sterically interacting particles,
akin to colonies of rod-shaped bacteria. By introducing continuously tuneable
tip variations around a common rod shape with spherical caps, we find that
subtle changes significantly impact the emergent dynamics, leading to distinct
patterns of microdomain formation and stability. Our analysis reveals separate
effects of particle shape and aspect ratio, as well as a transition from
exponential to scale-free size distributions, which we recapitulate using an
effective master equation model. This allows us to relate differences in
microdomain size distributions to different physical mechanisms of microdomain
breakup. Our results thereby contribute to the characterization of the
effective dynamics in growing aggregates at large and intermediate length
scales and the microscopic properties that control it. This could be relevant
both for biological self-organization and design strategies for future
artificial systems.",http://arxiv.org/abs/2501.15681v2
"Weight-based Analysis of Detokenization in Language Models:
  Understanding the First Stage of Inference Without Inference",2025-01-27T03:45:29Z,"Go Kamoda, Benjamin Heinzerling, Tatsuro Inaba, Keito Kudo, Keisuke Sakaguchi, Kentaro Inui","According to the stages-of-inference hypothesis, early layers of language
models map their subword-tokenized input, which does not necessarily correspond
to a linguistically meaningful segmentation, to more meaningful representations
that form the model's ""inner vocabulary"". Prior analysis of this detokenization
stage has predominantly relied on probing and interventions such as path
patching, which involve selecting particular inputs, choosing a subset of
components that will be patched, and then observing changes in model behavior.
Here, we show that several important aspects of the detokenization stage can be
understood purely by analyzing model weights, without performing any model
inference steps. Specifically, we introduce an analytical decomposition of
first-layer attention in GPT-2. Our decomposition yields interpretable terms
that quantify the relative contributions of position-related, token-related,
and mixed effects. By focusing on terms in this decomposition, we discover
weight-based explanations of attention bias toward close tokens and attention
for detokenization.",http://arxiv.org/abs/2501.15754v3
"Stationary scalar clouds around a rotating BTZ-like black hole in the
  Einstein-bumblebee gravity",2025-01-27T04:00:42Z,"Fangli Quan, Fengjiao Li, Qiyuan Pan, Mengjie Wang, Jiliang Jing","We have studied stationary clouds of massive scalar fields around a rotating
BTZ-like black hole in the Einstein-bumblebee gravity, by imposing the Robin
type boundary conditions at the AdS boundary. We establish, by scanning the
parameter space, the existence of \textit{fundamental} stationary scalar clouds
($i.e.$, the overtone number $n=0$). In particular, we observe that the Lorentz
symmetry breaking parameter $s$ and the quantum number $k$ play an opposite
role in determining scalar clouds, which indicates the existence of
\textit{degenerate} scalar clouds. To illustrate the fact that scalar clouds
may only be supported for the $n=0$ case, we have analyzed the impact of
various parameters on scalar quasinormal modes. It is shown that the Lorentz
symmetry breaking parameter $s$ does not change the superradiance condition,
and superradiant instabilities only appear for the fundamental modes. Our work
shows that the Lorentz symmetry breaking provides richer physics in stationary
scalar clouds around black holes.",http://arxiv.org/abs/2501.15759v1
"Advancing Portfolio Optimization: Adaptive Minimum-Variance Portfolios
  and Minimum Risk Rate Frameworks",2025-01-27T05:37:28Z,"Ayush Jha, Abootaleb Shirvani, Ali Jaffri, Svetlozar T. Rachev, Frank J. Fabozzi","This study presents the Adaptive Minimum-Variance Portfolio (AMVP) framework
and the Adaptive Minimum-Risk Rate (AMRR) metric, innovative tools designed to
optimize portfolios dynamically in volatile and nonstationary financial
markets. Unlike traditional minimum-variance approaches, the AMVP framework
incorporates real-time adaptability through advanced econometric models,
including ARFIMA-FIGARCH processes and non-Gaussian innovations. Empirical
applications on cryptocurrency and equity markets demonstrate the proposed
framework's superior performance in risk reduction and portfolio stability,
particularly during periods of structural market breaks and heightened
volatility. The findings highlight the practical implications of using the AMVP
and AMRR methodologies to address modern investment challenges, offering
actionable insights for portfolio managers navigating uncertain and rapidly
changing market conditions.",http://arxiv.org/abs/2501.15793v1
"Can Multimodal Large Language Models be Guided to Improve Industrial
  Anomaly Detection?",2025-01-27T05:41:10Z,"Zhiling Chen, Hanning Chen, Mohsen Imani, Farhad Imani","In industrial settings, the accurate detection of anomalies is essential for
maintaining product quality and ensuring operational safety. Traditional
industrial anomaly detection (IAD) models often struggle with flexibility and
adaptability, especially in dynamic production environments where new defect
types and operational changes frequently arise. Recent advancements in
Multimodal Large Language Models (MLLMs) hold promise for overcoming these
limitations by combining visual and textual information processing
capabilities. MLLMs excel in general visual understanding due to their training
on large, diverse datasets, but they lack domain-specific knowledge, such as
industry-specific defect tolerance levels, which limits their effectiveness in
IAD tasks. To address these challenges, we propose Echo, a novel multi-expert
framework designed to enhance MLLM performance for IAD. Echo integrates four
expert modules: Reference Extractor which provides a contextual baseline by
retrieving similar normal images, Knowledge Guide which supplies
domain-specific insights, Reasoning Expert which enables structured, stepwise
reasoning for complex queries, and Decision Maker which synthesizes information
from all modules to deliver precise, context-aware responses. Evaluated on the
MMAD benchmark, Echo demonstrates significant improvements in adaptability,
precision, and robustness, moving closer to meeting the demands of real-world
industrial anomaly detection.",http://arxiv.org/abs/2501.15795v1
"D-PLS: Decoupled Semantic Segmentation for
  4D-Panoptic-LiDAR-Segmentation",2025-01-27T08:46:22Z,"Maik Steinhauser, Laurenz Reichardt, Nikolas Ebert, Oliver Wasenmüller","This paper introduces a novel approach to 4D Panoptic LiDAR Segmentation that
decouples semantic and instance segmentation, leveraging single-scan semantic
predictions as prior information for instance segmentation. Our method D-PLS
first performs single-scan semantic segmentation and aggregates the results
over time, using them to guide instance segmentation. The modular design of
D-PLS allows for seamless integration on top of any semantic segmentation
architecture, without requiring architectural changes or retraining. We
evaluate our approach on the SemanticKITTI dataset, where it demonstrates
significant improvements over the baseline in both classification and
association tasks, as measured by the LiDAR Segmentation and Tracking Quality
(LSTQ) metric. Furthermore, we show that our decoupled architecture not only
enhances instance prediction but also surpasses the baseline due to
advancements in single-scan semantic segmentation.",http://arxiv.org/abs/2501.15870v1
"A Low-Cost, High-Precision Human-Machine Interaction Solution Based on
  Multi-Coil Wireless Charging Pads",2025-01-27T09:18:35Z,Bojun Zhang,"Wireless charging pads are common, yet their functionality is mainly
restricted to charging. Existing gesture recognition techniques, such as those
based on machine vision and WiFi, have drawbacks like high costs and poor
precision. This paper presents a new human machine interaction solution using
multicoil wireless charging pads. The proposed approach leverages the pads
existing modules without additional wearable sensors. It determines gestures by
monitoring current and power changes in different coils. The data processing
includes noise removal, sorting, highpass filtering, and slicing. A Bayesian
network and particle filtering are employed for motion tracking. Through
experiments, this solution proves to have wide applications, high recognition
accuracy, and low cost. It can effectively identify diverse gestures,
increasing the value of wireless charging pads. It outperforms traditional
methods, with a 0.73 improvement in recognition accuracy and better
environmental adaptability.",http://arxiv.org/abs/2501.15885v1
"Qualitative observations in university physics laboratories: an example
  from classical mechanics",2025-01-27T12:15:56Z,"K. Dunnett, M. H. Magnusson","One of the key skills of a researcher is noticing what's going on. Both in
the experiment one's performing and in one's data: is there something
interesting, reason to doubt one's data or suspect that one's theoretical
description is insufficient? Many experiments developed for undergraduate
teaching still focus on quantitative evaluation. Here we take an alternative
approach where careful observation identifies the interesting qualitative
behaviour of a ball dropped with a water bottle balanced on top of it, but
where numerical agreement with a simple theoretical model is impossible. Thus
'success' occurs when students are satisfied with their efforts and the
development of their experimental process. Laboratory note keeping can also be
introduced in a meaningful, non-formulaic way since students are making
independent observations and method changes. We describe pedagogical and
didactic considerations for the implementation of the experiment in a
classroom, including variations and extensions, and give examples of
experimental outcomes. We suggest that considering qualitative behaviour may be
a fruitful strategy for identifying experiments that are both amenable to
student autonomy and embedding skills such as laboratory note keeping in a
flexible and genuine way.",http://arxiv.org/abs/2501.15988v2
"Modeling and stability analysis of live systems with time-varying
  dimension",2025-01-27T12:22:49Z,Andrii Mironchenko,"A major limitation of the classical control theory is the assumption that the
state space and its dimension do not change with time. This prevents analyzing
and even formalizing the stability and control problems for open multi-agent
systems whose agents may enter or leave the network, industrial processes where
the sensors or actuators may be exchanged frequently, smart grids, etc. In this
work, we propose a framework of live systems that covers a rather general class
of systems with a time-varying state space. We argue that input-to-state
stability is a proper stability notion for this class of systems, and many of
the classic tools and results, such as Lyapunov methods and superposition
theorems, can be extended to this setting.",http://arxiv.org/abs/2501.15991v1
"Confocal Ellipsoidal Reflectors with Phased Array Vivaldi Antenna Source
  for Imaging Systems",2025-01-27T12:30:49Z,"Mohammad Hossein Koohi Ghamsari, Mahyar Mehri Pashaki, Mehdi Ahmadi-Boroujeni","In this paper, an on-axis dual-reflector confocal ellipsoidal structure is
presented for near-field imaging systems. In the proposed structure, the
backscattered electromagnetic wave problem, known as the blockage effect, is
reduced considerably using an elaborate design of the sub-reflector and precise
alignment of the reflectors. The proposed geometry is analyzed, followed by a
design example for the stand-off distance of 2 m. The blockage reduction
characteristic is verified using ray-tracing simulation. Next, the scanning
performance of the structure is investigated utilizing a Vivaldi phased array
antenna as the source designed at the central frequency of 28 GHz. The
full-wave simulations proved a field-of-view (FoV) of approximately 40 cm.
Furthermore, tuning the proposed reflectors configuration standoff distance is
examined with a point source. The ray-tracing simulations showed that stand-off
distance can be easily changed up to tens of centimeters with just a few
centimeters of source point lateral displacement.",http://arxiv.org/abs/2501.15997v1
"Epidemics on the Move: How Public Transport Demand and Capacity Shape
  Disease Spread",2025-01-27T12:43:13Z,"László Hajdu, Jovan Pavlović, Miklós Krész, András Bóta","Understanding the dynamics of passenger interactions and their
epidemiological impact throughout public transportation systems is crucial for
both service efficiency and public health. High passenger density and close
physical proximity has been shown to accelerate the spread of infectious
diseases. During the COVID-19 pandemic, many public transportation companies
took measures to slow down and minimize disease spreading. One of these
measures was introducing spacing and capacity constraints to public transit
vehicles. Our objective is to explore the effects of demand changes and
transportation measures from an epidemiological point of view, offering
alternative measures to public transportation companies to keep the system
alive while minimizing the epidemiological risk as much as possible.",http://arxiv.org/abs/2501.16004v1
Mass and Metal Flows in Isolated IllustrisTNG Halos,2025-01-27T13:38:41Z,"Jacob P. Morgan, Jeremy Bailin","The cicumgalactic medium (CGM) is a reservoir of metals and star-forming
fuel. Most baryons in the universe are in the circumgalactic medium (CGM) or
intergalactic medium (IGM). The baryon cycle -- how mass and metals reach the
CGM from the inner regions of the galaxy and how gas from the CGM replenishes
star-forming activity in the inner regions -- is an essential question in
galaxy evolution. In this paper, we study the flow of mass and metals in a
stacked sample of 2770 isolated halos from the IllustrisTNG cosmological
hydrodynamic simulation. The mean gas flow as a function of radius and angle is
similar across a large galactic mass range when accounting for different
feedback modes. Although both star formation and black holes cause powerful
outflows, the flows from star formation are more angularly restricted. Black
hole feedback dominates massflow throughout the halo, while star-formation
feedback mainly affects the inner region. When scaling by virial radius
($R_v$), large dynamical changes occur at $0.2R_v$ for most halos, suggesting a
characteristic size for the inner galaxy. Despite radio mode feedback from
black holes being the primary quenching mechanism in IllustrisTNG, a small
population of high mass radio mode disks are able to form stars.",http://arxiv.org/abs/2501.16045v1
Self-propelled particles undergoing cyclic transitions,2025-01-27T13:41:21Z,"Ye Zhang, Duanduan Wan","Cyclic transitions between active and passive states are central to many
natural and synthetic systems, ranging from light-driven active particles to
animal migrations. Here, we investigate a minimal model of self-propelled
Brownian particles undergoing cyclic transitions across three spatial zones:
gain, loss, and neutral regions. Particles become active in the gain region,
passive in the loss region, and retain their state in the neutral region. By
analyzing the steady-state behavior as a function of particle number and the
size of the loss region, we identify a threshold particle number, below and
above which distinct structural changes are observed. Interestingly, below this
threshold, increasing the particle number reduces the state-switching time (the
time required for a particle to transition from active to passive and back to
active). In contrast, above the threshold, further increases in particle number
result in longer switching times. In the subthreshold regime, our analytical
model predicts structural characteristics and switching dynamics that align
well with simulations. Above the threshold, we observe an emergent spatial
clustering, with particles transitioning from passive to active states in close
proximity. These findings provide insights into the collective dynamics of
cyclic processes between active and passive states across distinct spatial
zones in active matter systems.",http://arxiv.org/abs/2501.16048v1
"Hyperfine structure and collisions in three-photon Rydberg
  electromagnetically induced transparency",2025-01-27T13:51:37Z,"Alisher Duspayev, Georg Raithel","Multi-photon electromagnetically-induced transparency (EIT) of atomic vapors
involves several intermediate atomic levels. The sub-structure of these levels
and their collisional interactions can drastically alter experimental EIT
signals. Here, we report on hyperfine structure and collision effects in
three-photon Rydberg EIT on the cascade $5S_{1/2} \rightarrow$ $5P_{1/2}
\rightarrow 5D_{3/2}$ $\rightarrow 25F_{5/2}$ in a room temperature $^{85}$Rb
vapor cell. In our measurements of EIT spectra, we identify two types of EIT
signatures that correspond with distinct excitation pathways and atomic
velocity classes in the atomic vapor. The $5D_{3/2}$ hyperfine structure and
Autler-Townes splittings lead to complex patterns in the EIT spectra, which we
analyze with the aid of 10-level EIT simulations. Adding 50~mTorr of Ar gas
alters the EIT spectra and induces an additional, third EIT mode. Based on our
simulation results, we attribute these changes to hyperfine collisions in the
Rb $5D_{3/2}$ level. Our study may become useful in quantum technologies
involving Rydberg EIT and hyperfine collisions in vapor cells, including
non-invasive spatio-temporally resolved electric-field sensing of electric
fields in low-pressure plasmas.",http://arxiv.org/abs/2501.16054v1
"The stochastic skeleton model for the Madden-Julian Oscillation with
  time-dependent observation-based forcing",2025-01-27T13:58:55Z,"Noémie Ehstand, Reik V. Donner, Cristóbal López, Marcelo Barreiro, Emilio Hernández-García","We analyze solutions to the stochastic skeleton model, a minimal nonlinear
oscillator model for the Madden-Julian Oscillation (MJO). This model has been
recognized for its ability to reproduce several large-scale features of the
MJO. In previous studies, the model's forcings were predominantly chosen to be
mathematically simple and time-independent. Here, we present solutions to the
model with time-dependent observation-based forcing functions. Our results show
that the model, with these more realistic forcing functions, successfully
replicates key characteristics of MJO events, such as their lifetime, extent,
and amplitude, whose statistics agree well with observations. However, we find
that the seasonality of MJO events and the spatial variations in the MJO
properties are not well reproduced. Having implemented the model in the
presence of time-dependent forcings, we can analyze the impact of temporal
variability at different time scales. In particular, we study the model's
ability to reflect changes in MJO characteristics under the different phases of
ENSO. We find that it does not capture differences in studied characteristics
of MJO events in response to differences in conditions during El Ni\~no, La
Ni\~na, and neutral ENSO.",http://arxiv.org/abs/2501.16060v1
Challenging Assumptions in Learning Generic Text Style Embeddings,2025-01-27T14:21:34Z,"Phil Ostheimer, Marius Kloft, Sophie Fellenz","Recent advancements in language representation learning primarily emphasize
language modeling for deriving meaningful representations, often neglecting
style-specific considerations. This study addresses this gap by creating
generic, sentence-level style embeddings crucial for style-centric tasks. Our
approach is grounded on the premise that low-level text style changes can
compose any high-level style. We hypothesize that applying this concept to
representation learning enables the development of versatile text style
embeddings. By fine-tuning a general-purpose text encoder using contrastive
learning and standard cross-entropy loss, we aim to capture these low-level
style shifts, anticipating that they offer insights applicable to high-level
text styles. The outcomes prompt us to reconsider the underlying assumptions as
the results do not always show that the learned style representations capture
high-level text styles.",http://arxiv.org/abs/2501.16073v1
"Multi-Agent Meta-Offline Reinforcement Learning for Timely UAV Path
  Planning and Data Collection",2025-01-27T14:47:19Z,"Eslam Eldeeb, Hirley Alves","Multi-agent reinforcement learning (MARL) has been widely adopted in
high-performance computing and complex data-driven decision-making in the
wireless domain. However, conventional MARL schemes face many obstacles in
real-world scenarios. First, most MARL algorithms are online, which might be
unsafe and impractical. Second, MARL algorithms are environment-specific,
meaning network configuration changes require model retraining. This letter
proposes a novel meta-offline MARL algorithm that combines conservative
Q-learning (CQL) and model agnostic meta-learning (MAML). CQL enables offline
training by leveraging pre-collected datasets, while MAML ensures scalability
and adaptability to dynamic network configurations and objectives. We propose
two algorithm variants: independent training (M-I-MARL) and centralized
training decentralized execution (M-CTDE-MARL). Simulation results show that
the proposed algorithm outperforms conventional schemes, especially the CTDE
approach that achieves 50 % faster convergence in dynamic scenarios than the
benchmarks. The proposed framework enhances scalability, robustness, and
adaptability in wireless communication systems by optimizing UAV trajectories
and scheduling policies.",http://arxiv.org/abs/2501.16098v1
"Dynamic Neutrino Mass Ordering and Its Imprint on the Diffuse Supernova
  Neutrino Background",2025-01-27T19:00:00Z,"Yuber F. Perez-Gonzalez, Manibrata Sen","Neutrino masses may have evolved dynamically throughout the history of the
Universe, potentially leading to a mass spectrum distinct from the normal or
inverted ordering observed today. While cosmological measurements constrain the
total energy density of neutrinos, they are not directly sensitive to a
dynamically changing mass ordering unless future surveys achieve exceptional
precision in detecting the distinct imprints of each mass eigenstate on
large-scale structures. In this work, we investigate the impact of a dynamic
neutrino mass spectrum on the diffuse supernova neutrino background (DSNB),
which is composed of neutrinos from all supernova explosions throughout cosmic
history and is on the verge of experimental detection. Since neutrino
oscillations are highly sensitive to the mass spectrum, we show that the
electron neutrino survival probability carries distinct signatures of the
evolving neutrino mass spectrum. Our results indicate that the resulting
modifications to the DSNB spectrum would exhibit unique energy-dependent
features. These features are distinguishable from the effects of significant
astrophysical uncertainties, providing a potential avenue for probing the
dynamic nature of neutrino masses.",http://arxiv.org/abs/2501.16412v1
"Programming by Examples Meets Historical Linguistics: A Large Language
  Model Based Approach to Sound Law Induction",2025-01-27T21:48:39Z,"Atharva Naik, Darsh Agrawal, Hong Sng, Clayton Marr, Kexun Zhang, Nathaniel R Robinson, Kalvin Chang, Rebecca Byrnes, Aravind Mysore, Carolyn Rose, David R Mortensen","Historical linguists have long written ""programs"" that convert reconstructed
words in an ancestor language into their attested descendants via ordered
string rewrite functions (called sound laws) However, writing these programs is
time-consuming, motivating the development of automated Sound Law Induction
(SLI) which we formulate as Programming by Examples (PBE) with Large Language
Models (LLMs) in this paper. While LLMs have been effective for code
generation, recent work has shown that PBE is challenging but improvable by
fine-tuning, especially with training data drawn from the same distribution as
evaluation data. In this paper, we create a conceptual framework of what
constitutes a ""similar distribution"" for SLI and propose four kinds of
synthetic data generation methods with varying amounts of inductive bias to
investigate what leads to the best performance. Based on the results we create
a SOTA open-source model for SLI as PBE (+6% pass rate with a third of the
parameters of the second-best LLM) and also highlight exciting future
directions for PBE research.",http://arxiv.org/abs/2501.16524v1
"DialUp! Modeling the Language Continuum by Adapting Models to Dialects
  and Dialects to Models",2025-01-27T23:53:04Z,"Niyati Bafna, Emily Chang, Nathaniel R. Robinson, David R. Mortensen, Kenton Murray, David Yarowsky, Hale Sirin","Most of the world's languages and dialects are low-resource, and lack support
in mainstream machine translation (MT) models. However, many of them have a
closely-related high-resource language (HRL) neighbor, and differ in
linguistically regular ways from it. This underscores the importance of model
robustness to dialectical variation and cross-lingual generalization to the HRL
dialect continuum. We present DialUp, consisting of a training-time technique
for adapting a pretrained model to dialectical data (M->D), and an
inference-time intervention adapting dialectical data to the model expertise
(D->M). M->D induces model robustness to potentially unseen and unknown
dialects by exposure to synthetic data exemplifying linguistic mechanisms of
dialectical variation, whereas D->M treats dialectical divergence for known
target dialects. These methods show considerable performance gains for several
dialects from four language families, and modest gains for two other language
families. We also conduct feature and error analyses, which show that language
varieties with low baseline MT performance are more likely to benefit from
these approaches.",http://arxiv.org/abs/2501.16581v1
"Safety-Critical Control for Aerial Physical Interaction in Uncertain
  Environment",2025-01-28T05:53:29Z,"Jeonghyun Byun, Yeonjoon Kim, Dongjae Lee, H. Jin Kim","Aerial manipulation for safe physical interaction with their environments is
gaining significant momentum in robotics research. In this paper, we present a
disturbance-observer-based safety-critical control for a fully actuated aerial
manipulator interacting with both static and dynamic structures. Our approach
centers on a safety filter that dynamically adjusts the desired trajectory of
the vehicle's pose, accounting for the aerial manipulator's dynamics, the
disturbance observer's structure, and motor thrust limits. We provide rigorous
proof that the proposed safety filter ensures the forward invariance of the
safety set - representing motor thrust limits - even in the presence of
disturbance estimation errors. To demonstrate the superiority of our method
over existing control strategies for aerial physical interaction, we perform
comparative experiments involving complex tasks, such as pushing against a
static structure and pulling a plug firmly attached to an electric socket.
Furthermore, to highlight its repeatability in scenarios with sudden dynamic
changes, we perform repeated tests of pushing a movable cart and extracting a
plug from a socket. These experiments confirm that our method not only
outperforms existing methods but also excels in handling tasks with rapid
dynamic variations.",http://arxiv.org/abs/2501.16719v1
"B-RIGHT: Benchmark Re-evaluation for Integrity in Generalized
  Human-Object Interaction Testing",2025-01-28T06:04:08Z,"Yoojin Jang, Junsu Kim, Hayeon Kim, Eun-ki Lee, Eun-sol Kim, Seungryul Baek, Jaejun Yoo","Human-object interaction (HOI) is an essential problem in artificial
intelligence (AI) which aims to understand the visual world that involves
complex relationships between humans and objects. However, current benchmarks
such as HICO-DET face the following limitations: (1) severe class imbalance and
(2) varying number of train and test sets for certain classes. These issues can
potentially lead to either inflation or deflation of model performance during
evaluation, ultimately undermining the reliability of evaluation scores. In
this paper, we propose a systematic approach to develop a new class-balanced
dataset, Benchmark Re-evaluation for Integrity in Generalized Human-object
Interaction Testing (B-RIGHT), that addresses these imbalanced problems.
B-RIGHT achieves class balance by leveraging balancing algorithm and automated
generation-and-filtering processes, ensuring an equal number of instances for
each HOI class. Furthermore, we design a balanced zero-shot test set to
systematically evaluate models on unseen scenario. Re-evaluating existing
models using B-RIGHT reveals substantial the reduction of score variance and
changes in performance rankings compared to conventional HICO-DET. Our
experiments demonstrate that evaluation under balanced conditions ensure more
reliable and fair model comparisons.",http://arxiv.org/abs/2501.16724v1
Random attraction in TASEP with time-varying hopping rates,2025-01-28T08:00:29Z,"Lars Grüne, Kilian Pioch, Thomas Kriecherbauer, Michael Margaliot","The totally asymmetric simple exclusion principle (TASEP) is a fundamental
model in nonequilibrium statistical mechanics. It describes the stochastic
unidirectional movement of particles along a 1D chain of ordered sites. We
consider the continuous-time version of TASEP with a finite number of sites and
with time-varying hopping rates between the sites. We show how to formulate
this model as a nonautonomous random dynamical system (NRDS) with a finite
state-space. We provide conditions guaranteeing that random pullback and
forward attractors of such an NRDS exist and consist of singletons. In the
context of the nonautonomous TASEP these conditions imply almost sure
synchronization of the individual random paths. This implies in particular that
perturbations that change the state of the particles along the chain are
""filtered out"" in the long run. We demonstrate that the required conditions are
tight by providing examples where these conditions do not hold and consequently
the forward attractor does not exist or the pullback attractor is not a
singleton. The results in this paper generalize our earlier results for
autonomous TASEP in https://doi.org/10.1137/20M131446X and contain these as a
special case.",http://arxiv.org/abs/2501.16777v1
"A failed wind candidate in NGC 3783 from the 2001 year campaign with
  Chandra/HETGS",2025-01-28T12:07:43Z,"Chen Li, Jelle S. Kaastra, Liyi Gu, Daniele Rogantini, Anna Juráňová, Missagh Mehdipour, Jelle de Plaa","We reanalyze the Chandra/HETGS observations of NGC 3783 from the campaign in
the year 2001, identifying significant spectral variations in the Fe unresolved
transition array (UTA) over timescales of weeks to months. These changes
correlate with a $1.4-2$ fold increase in the ionizing continuum and exceed $10
\, \sigma$ significance. The variations primarily originate from a
low-ionization state ($\rm log \xi = 1.65$) component of the warm absorber.
Time-dependent photoionization modelling confirms the sensitivity of this
low-ionization component to continuum variations within the Fe UTA band. Local
fitting indicates a lower density limit of $>10^{12.3} \, \rm m^{-3}$ at $3 \,
\sigma$ statistical uncertainty, with the component located within $0.27 \, \rm
pc$. Our findings suggest that this low-ionization component is a potential
failed wind candidate.",http://arxiv.org/abs/2501.16880v1
"Emergent collective behavior of cohesive, aligning particles",2025-01-28T14:51:14Z,"Jeanine Shea, Holger Stark","Collective behavior is all around us, from flocks of birds to schools of
fish. These systems are immensely complex, which makes it pertinent to study
their behavior through minimal models. We introduce such a minimal model for
cohesive and aligning self-propelled particles in which group cohesion is
established through additive, non-reciprocal torques. These torques cause
constituents to effectively turn towards one another. We additionally
incorporate an alignment torque, which competes with the cohesive torque in the
same spatial range. By changing the strength and range of these torque
interactions, we uncover six states which we distinguish via their static and
dynamic properties: a disperse state, a multiple worm state, a line state, a
persistent worm state, a rotary worm state, and an aster state. Their
occurrence strongly depends on initial conditions and stochasticity, so the
model exhibits multistabilities. A number of the states exhibit collective
dynamics which are reminiscent of those seen in nature.",http://arxiv.org/abs/2501.16994v1
Tuning LLM Judge Design Decisions for 1/1000 of the Cost,2025-01-24T17:01:14Z,"David Salinas, Omar Swelam, Frank Hutter","Evaluating Large Language Models (LLMs) often requires costly human
annotations. To address this, LLM-based judges have been proposed, which
compare the outputs of two LLMs enabling the ranking of models without human
intervention. While several approaches have been proposed, many confounding
factors are present between different papers. For instance the model, the
prompt and other hyperparameters are typically changed at the same time making
apple-to-apple comparisons challenging. In this paper, we propose to
systematically analyze and tune hyperparameter of LLM judges. To alleviate the
high cost of evaluating a judge, we propose to leverage multi-objective
multi-fidelity which allows to find judges that trades accuracy for cost and
also reduce significantly the cost of the search. Our method identifies judges
that not only outperform existing benchmarks in accuracy and cost-efficiency
but also utilize open-weight models, ensuring greater accessibility and
reproducibility.",http://arxiv.org/abs/2501.17178v2
Unimodular JT gravity and de Sitter quantum cosmology,2025-01-28T16:17:51Z,"Bruno Alexandre, Altay Etkin, Farbod-Sayyed Rassouli","In this work, we show that a gauge-theoretic description of Jackiw-Teitelboim
(JT) gravity naturally yields a Henneaux-Teitelboim (HT) unimodular gravity via
a central extension of its isometry group, valid for both flat and curved
two-dimensional spacetimes. HT gravity introduces a unimodular time canonically
conjugate to the cosmological constant, serving as a physical time in quantum
cosmology. By studying the mini-superspace reduction of $\text{HT}_2$ gravity,
the Wheeler-DeWitt equation becomes a Schr\""odinger-like equation, giving a
consistent and unitary quantum theory. Analysis of the wavefunction's
probability density reveals a quantum distribution for the scale factor $a$,
offering a quantum perspective on the expansion and contraction of the
universe. In this perspective, the possibility of reaching the singular point
$a=0$ signals that topology change could occur. Finally, we give a consistent
quantum description of unimodular time that aligns seamlessly with
Page-Wootters formulation of quantum mechanics, where quantum correlations
between unimodular time and JT gravity are studied in $\text{HT}_2$ quantum
cosmology.",http://arxiv.org/abs/2501.17213v1
"An Efficient Numerical Function Optimization Framework for Constrained
  Nonlinear Robotic Problems",2025-01-28T23:51:44Z,"Sait Sovukluk, Christian Ott","This paper presents a numerical function optimization framework designed for
constrained optimization problems in robotics. The tool is designed with
real-time considerations and is suitable for online trajectory and control
input optimization problems. The proposed framework does not require any
analytical representation of the problem and works with constrained block-box
optimization functions. The method combines first-order gradient-based line
search algorithms with constraint prioritization through nullspace projections
onto constraint Jacobian space. The tool is implemented in C++ and provided
online for community use, along with some numerical and robotic example
implementations presented in this paper.",http://arxiv.org/abs/2501.17349v2
"Realtime Limb Trajectory Optimization for Humanoid Running Through
  Centroidal Angular Momentum Dynamics",2025-01-29T00:06:01Z,"Sait Sovukluk, Robert Schuller, Johannes Englsberger, Christian Ott","One of the essential aspects of humanoid robot running is determining the
limb-swinging trajectories. During the flight phases, where the ground reaction
forces are not available for regulation, the limb swinging trajectories are
significant for the stability of the next stance phase. Due to the conservation
of angular momentum, improper leg and arm swinging results in highly tilted and
unsustainable body configurations at the next stance phase landing. In such
cases, the robotic system fails to maintain locomotion independent of the
stability of the center of mass trajectories. This problem is more apparent for
fast and high flight time trajectories. This paper proposes a real-time
nonlinear limb trajectory optimization problem for humanoid running. The
optimization problem is tested on two different humanoid robot models, and the
generated trajectories are verified using a running algorithm for both robots
in a simulation environment.",http://arxiv.org/abs/2501.17351v2
Quantum Cross-section of Near-extremal Black Holes,2025-01-29T08:25:19Z,Roberto Emparan,"We explore how to detect the large quantum fluctuations in the throat of a
near-extremal black hole, where the dynamics are governed by the Schwarzian
theory. To this end, we scatter a low-frequency wave of a massless, minimal
scalar off the black hole and calculate the absorption cross-section. In the
semiclassical regime, where the Schwarzian is weakly coupled, we recover the
universal result that the cross-section equals the horizon area. However, in
the strongly coupled regime, where quantum fluctuations dominate, we find that
the absorption cross-section exceeds the semiclassical prediction. This result
may seem counterintuitive, given that the density of black hole states is
suppressed in this regime. Nevertheless, two effects outweigh this suppression.
First, quantum fluctuations enhance absorption transitions between individual
states, with the effect becoming stronger closer to the ground state. Second,
these fluctuations significantly reduce stimulated emission. We conclude that a
measurement showing an enhanced absorption cross-section serves as a clear
signature of the large quantum fluctuations in the geometry.",http://arxiv.org/abs/2501.17470v2
"Bacterial dimensions sensitively regulate surface diffusivity and
  residence time",2025-01-29T08:42:24Z,"Premkumar Leishangthem, Xuan Wang, Junan Chen, Shengqi Yang, Xinliang Xu","Run-and-tumble is a common but vital strategy that bacteria employ to explore
environment suffused with boundaries, as well as to escape from entrapment. In
this study we reveal how this strategy and the resulting dynamical behavior can
be sensitively regulated by bacterial dimensions. Our results demonstrate that
the logarithm of the surface residence time for bacteria with constant tumble
bias is linearly related to a dimensionless parameter of bacterial intrinsic
size characteristics, where a small variation in bacterial dimensions, which is
natural in a suspension, reproduces well the experimentally observed large
variation in bacterial residence time. Furthermore, our results predict that
the optimal tumble bias corresponding to the maximum surface diffusivity
depends strongly on bacterial dimensions, where the same small variation in
bacterial dimensions gives rise to a strongly diversified optimal tumble bias
and an order of magnitude change in surface diffusivity.",http://arxiv.org/abs/2501.17477v1
"System-environmental entanglement in critical spin systems under
  $ZZ$-decoherence and its relation to strong and weak symmetries",2025-01-29T08:45:46Z,"Yoshihito Kuno, Takahiro Orito, Ikuo Ichinose","Open quantum many-body system exhibits nontrivial behavior under decoherence.
In particular, system-environmental entanglement is one of quantities to
characterize mixed state properties under decoherence. In this study, we
investigate the behavior of the system-environmental entanglement for critical
spin chains under nearest-neighbor $ZZ$ -decoherence. We numerically find that
the system-environmental entanglement exhibits a specific scaling law including
a system-independent universal term (""$g$-function""). For the critical XXZ
model, transition to strong-to-weak spontaneously symmetry breaking mixed state
takes place. In that case, the $g$-function changes its value at decoherent
transition point and gets double the value of system under single-site
$Z$-decoherence, which was recently studied by conformal field theory. By
studying Shannon entropy, we clarify origin of this $g$-function behavior.",http://arxiv.org/abs/2501.17481v1
"Low-Complexity Event Detection and Identification in Coherent
  Correlation OTDR Measurements",2025-01-29T09:44:33Z,"Jasper Müller, Ognjen Jovanovic, Florian Azendorf, André Sandmann, Roman Ermakov, Sai Kireet Patri, Jörg-Peter Elbers, Jim Zou, Darko Zibar, Carmen Mas-Machuca","Pairing coherent correlation OTDR with low-complexity analysis methods, we
investigate the detection of fast temperature changes and vibrations in optical
fibers. A localization accuracy of ~2 m and extraction of vibration amplitudes
and frequencies is demonstrated.",http://arxiv.org/abs/2501.17519v1
"Mechanism of Oleic Acid-Mediated Sulfur Vacancy Healing in monolayer
  WS$_2$",2025-01-29T10:10:45Z,"Leon Daniel, Dedi Sutarma, Osamah Kharsah, Charleen Lintz, Peter Kratzer, Marika Schleberger","We uncover the mechanism behind the enhancement of photoluminescence yield in
monolayer WS$_2$ through oleic acid treatment, a promising scalable strategy
for defect healing. By inducing sulfur vacancies through thermal treatment and
monitoring the changes in photoluminescence yield and emission spectra, we
demonstrate that oleic acid heals the sulfur vacancy by providing
substitutional oxygen. Using density functional theory calculations, we provide
insight into the underlying mechanism governing the oleic acid-mediated sulfur
vacancy healing process. Our findings suggest that effective defect passivation
by oxygen doping can be achieved through chemical treatment, opening a pathway
for oxygen doping in transition metal dichalcogenides. However, we also
highlight the limitations of chemical treatment, which may only lead to small
increases in photoluminescence yield beyond a certain point.",http://arxiv.org/abs/2501.17536v1
"Towards post-growth policymaking: Barriers and enablers for sustainable
  wellbeing initiatives",2025-01-29T12:09:35Z,"Laura Angresius, Milena Buchs, Alessia Greselin, Daniel W. O'Neill","Providing wellbeing for all while safeguarding planetary boundaries may
require governments to pursue post-growth policies. Previous empirical studies
of sustainable wellbeing initiatives investigating enablers of and barriers to
post-growth policymaking are either based on a small number of empirical cases
or lack an explicit analytical framework. To better understand how post-growth
policymaking could be fostered, we investigate 29 initiatives across governance
scales in Europe, New Zealand, and Canada. We apply a framework that
distinguishes polity, politics, and policy to analyze the data. We find that
the main enablers and barriers relate to the economic growth paradigm, the
organization of government, attitudes towards policymaking, political
strategies, and policy tools and outcomes. Engaging in positive framings of
post-growth visions to change narratives and building broad-based alliances
could act as drivers. However, initiatives face a tension between the need to
connect to broad audiences and a risk of co-optation by depolitization.",http://arxiv.org/abs/2501.17600v1
"MuonSLab: A plastic scintillator based detector for muon measurement in
  the deep ocean",2025-01-29T13:17:56Z,"Jiacheng Wu, Weilun Huang, Ruike Cao, Qichao Chang, Wang Ding, Jingtao Huang, Liang Li, Xinchen Li, Hualin Mei, Cen Mo, Hengbin Shao, Wei Tian, Xinliang Tian, Yichen Tian, Xin Xiang, Donglian Xu, Fuyudi Zhang, Wei Zhi, Yiwei Zhu","Atmospheric muons are important probes for studying primary cosmic rays and
extensive air showers. Additionally, they constitute a significant background
for many underground and deep-sea neutrino experiments, such as TRopIcal
DEep-sea Neutrino Telescope (TRIDENT). Understanding the muon flux at various
depths in the deep sea is essential for validating TRIDENT simulations and
guiding the development of optimized trigger strategies. This paper introduces
a novel device based on plastic scintillalors and silicon photomultipliers
(SiPMs) named MuonSLab, which is designed to measure muon flux in the deep sea
and has the potential to be extended to other atmospheric muon property
measurements. We discuss the design and instrumentation of MuonSLab and present
results from several muon flux measurements, demonstrating its sensitivity to
muon detection and its stability during operations across multiple locations.",http://arxiv.org/abs/2501.17639v1
"Dynamic Competition between Cooper-Pair and Spin-Density-Wave
  Condensation",2025-01-29T15:53:01Z,"B. Decrausaz, M. Pikulski, O. Ivashko, N. B. Christensen, J. Choi, L. Udby, Ch. Niedermayer, K. Lefmann, H. M. Rønnow, J. Mesot, J. Ollivier, T. Kurosawa, N. Momono, M. Oda, J. Chang, D. G. Mazzone","Quantum matter phases may co-exist microscopically even when they display
competing tendencies. A fundamental question is whether such a competition can
be avoided through the elimination of one phase while the other one condenses
into the ground state. Here, we present a high-resolution neutron spectroscopy
study of the low-energy spin excitations in the high-temperature superconductor
La1.855Sr0.145CuO4. In the normal state, we find low-energy magnetic
fluctuations at incommensurate reciprocal lattice positions where
spin-density-wave order emerges at lower Sr concentration or at high magnetic
fields. While these spin excitations are largely suppressed by the emergence of
the superconducting spin gap, some low-energy magnetic fluctuations persist
deep inside the superconducting state. We interpret this result in terms of a
dynamic competition between superconductivity and magnetism, where
superconductivity impedes the condensation of low-energy magnetic fluctuations
through the formation of magnetically-mediated Cooper pairs.",http://arxiv.org/abs/2501.17724v1
"Analysis of Neural Activation in Time-dependent Membrane Capacitance
  Models",2025-01-29T17:45:10Z,"Matías Courdurier, Leonel E. Medina, Esteban Paduro","Most models of neurons incorporate a capacitor to account for the marked
capacitive behavior exhibited by the cell membrane. However, such capacitance
is widely considered constant, thereby neglecting the possible effects of
time-dependent membrane capacitance on neural excitability. This study presents
a modified formulation of a neuron model with time-dependent membrane
capacitance and shows that action potentials can be elicited for certain
capacitance dynamics. Our main results can be summarized as: (a) it is
necessary to have significant and abrupt variations in the capacitance to
generate action potentials; (b) certain simple and explicitly constructed
capacitance profiles with strong variations do generate action potentials; (c)
forcing abrupt changes in the capacitance too frequently may result in no
action potentials. These findings can have great implications for the design of
ultrasound-based or other neuromodulation strategies acting through transiently
altering the membrane capacitance of neurons.",http://arxiv.org/abs/2501.17803v1
"On heat coefficients, multiplicative anomaly and 4D Casimir energy for
  GJMS operators",2025-01-29T18:18:08Z,"Rodrigo Aros, Fabrizzio Bugini, Danilo E. Díaz, Camilo Nuñez-Barra","This note aims to verify a prediction on the total derivative term of the 4D
trace anomaly, and the corresponding heat coefficient, for GJMS operators. It
stems from the explicit computation of an {\it improved} Casimir (or vacuum)
energy on the sphere that takes into account the multiplicative anomaly among
the (shifted) Laplacian factors and connects, via the Cappelli-Coste relation,
with both the type A central charge and the total derivative term of the 4D
trace anomaly. The present heat coefficient computation is based on Juhl's
explicit formula for GJMS operators, Gilkey's formula for the integrated heat
coefficient of higher-order Laplacians, and the \textit{conformal principle} by
Branson and {\O}rsted.",http://arxiv.org/abs/2501.17828v2
"Aspects of Spatially-Correlated Random Fields: Extreme-Value Statistics
  and Clustering Properties",2025-01-29T19:00:56Z,"Ka Hei Choi, James Creswell, Florian Kuhnel, Dominik J. Schwarz","Rare events of large-scale spatially-correlated exponential random fields are
studied. The influence of spatial correlations on clustering and non-sphericity
is investigated. The size of the performed simulations permits to study
beyond-$7.5$-sigma events ($1$ in $10^{13}$). As an application, this allows to
resolve individual Hubble patches which fulfill the condition for primordial
black hole formation. It is argued that their mass spectrum is drastically
altered due to co-collapse of clustered overdensities as well as the mutual
threshold-lowering through the latter. Furthermore, the corresponding
non-sphericities imply possibly large changes in the initial black hole spin
distribution.",http://arxiv.org/abs/2501.17936v1
Gradient estimates for scalar curvature,2025-01-29T19:09:55Z,"Tobias Holck Colding, William P. Minicozzi II","A gradient estimate is a crucial tool used to control the rate of change of a
function on a manifold, paving the way for deeper analysis of geometric
properties. A celebrated result of Cheng and Yau gives gradient bounds on
manifolds with Ricci curvature $\geq 0$. The Cheng-Yau bound is not sharp, but
there is a gradient sharp estimate. To explain this, a Green's function $u$ on
a manifold can be used to define a regularized distance $b= u^{\frac{1}{2-n}}$
to the pole. On $\bf{R}^n$, the level sets of $b$ are spheres and $|\nabla
b|=1$. If $\text{Ric} \geq 0$, then [C3] proved the sharp gradient estimate
$|\nabla b| \leq 1$. We show that the average of $|\nabla b|$ is $\leq 1$ on a
three manifold with nonnegative scalar curvature. The average is over any level
set of $b$ and if the average is one on even one level set, then $M=\bf{R}^3$.",http://arxiv.org/abs/2501.17947v1
Topological Signatures of Adversaries in Multimodal Alignments,2025-01-29T21:45:10Z,"Minh Vu, Geigh Zollicoffer, Huy Mai, Ben Nebgen, Boian Alexandrov, Manish Bhattarai","Multimodal Machine Learning systems, particularly those aligning text and
image data like CLIP/BLIP models, have become increasingly prevalent, yet
remain susceptible to adversarial attacks. While substantial research has
addressed adversarial robustness in unimodal contexts, defense strategies for
multimodal systems are underexplored. This work investigates the topological
signatures that arise between image and text embeddings and shows how
adversarial attacks disrupt their alignment, introducing distinctive
signatures. We specifically leverage persistent homology and introduce two
novel Topological-Contrastive losses based on Total Persistence and Multi-scale
kernel methods to analyze the topological signatures introduced by adversarial
perturbations. We observe a pattern of monotonic changes in the proposed
topological losses emerging in a wide range of attacks on image-text
alignments, as more adversarial samples are introduced in the data. By
designing an algorithm to back-propagate these signatures to input samples, we
are able to integrate these signatures into Maximum Mean Discrepancy tests,
creating a novel class of tests that leverage topological signatures for better
adversarial detection.",http://arxiv.org/abs/2501.18006v1
"SAeUron: Interpretable Concept Unlearning in Diffusion Models with
  Sparse Autoencoders",2025-01-29T23:29:47Z,"Bartosz Cywiński, Kamil Deja","Diffusion models, while powerful, can inadvertently generate harmful or
undesirable content, raising significant ethical and safety concerns. Recent
machine unlearning approaches offer potential solutions but often lack
transparency, making it difficult to understand the changes they introduce to
the base model. In this work, we introduce SAeUron, a novel method leveraging
features learned by sparse autoencoders (SAEs) to remove unwanted concepts in
text-to-image diffusion models. First, we demonstrate that SAEs, trained in an
unsupervised manner on activations from multiple denoising timesteps of the
diffusion model, capture sparse and interpretable features corresponding to
specific concepts. Building on this, we propose a feature selection method that
enables precise interventions on model activations to block targeted content
while preserving overall performance. Evaluation with the competitive
UnlearnCanvas benchmark on object and style unlearning highlights SAeUron's
state-of-the-art performance. Moreover, we show that with a single SAE, we can
remove multiple concepts simultaneously and that in contrast to other methods,
SAeUron mitigates the possibility of generating unwanted content, even under
adversarial attack. Code and checkpoints are available at:
https://github.com/cywinski/SAeUron.",http://arxiv.org/abs/2501.18052v2
Synthesizing Grasps and Regrasps for Complex Manipulation Tasks,2025-01-30T00:58:31Z,"Aditya Patankar, Dasharadhan Mahalingam, Nilanjan Chakraborty","In complex manipulation tasks, e.g., manipulation by pivoting, the motion of
the object being manipulated has to satisfy path constraints that can change
during the motion. Therefore, a single grasp may not be sufficient for the
entire path, and the object may need to be regrasped. Additionally, geometric
data for objects from a sensor are usually available in the form of point
clouds. The problem of computing grasps and regrasps from point-cloud
representation of objects for complex manipulation tasks is a key problem in
endowing robots with manipulation capabilities beyond pick-and-place. In this
paper, we formalize the problem of grasping/regrasping for complex manipulation
tasks with objects represented by (partial) point clouds and present an
algorithm to solve it. We represent a complex manipulation task as a sequence
of constant screw motions. Using a manipulation plan skeleton as a sequence of
constant screw motions, we use a grasp metric to find graspable regions on the
object for every constant screw segment. The overlap of the graspable regions
for contiguous screws are then used to determine when and how many times the
object needs to be regrasped. We present experimental results on point cloud
data collected from RGB-D sensors to illustrate our approach.",http://arxiv.org/abs/2501.18075v1
"Beyond Turn-taking: Introducing Text-based Overlap into Human-LLM
  Interactions",2025-01-30T03:01:01Z,"JiWoo Kim, Minsuk Chang, JinYeong Bak","Traditional text-based human-AI interactions often adhere to a strict
turn-taking approach. In this research, we propose a novel approach that
incorporates overlapping messages, mirroring natural human conversations.
Through a formative study, we observed that even in text-based contexts, users
instinctively engage in overlapping behaviors like ""A: Today I went to-"" ""B:
yeah."" To capitalize on these insights, we developed OverlapBot, a prototype
chatbot where both AI and users can initiate overlapping. Our user study
revealed that OverlapBot was perceived as more communicative and immersive than
traditional turn-taking chatbot, fostering faster and more natural
interactions. Our findings contribute to the understanding of design space for
overlapping interactions. We also provide recommendations for implementing
overlap-capable AI interactions to enhance the fluidity and engagement of
text-based conversations.",http://arxiv.org/abs/2501.18103v1
Battery State of Health Estimation Using LLM Framework,2025-01-30T03:55:56Z,"Aybars Yunusoglu, Dexter Le, Karn Tiwari, Murat Isik, I. Can Dikmen","Battery health monitoring is critical for the efficient and reliable
operation of electric vehicles (EVs). This study introduces a transformer-based
framework for estimating the State of Health (SoH) and predicting the Remaining
Useful Life (RUL) of lithium titanate (LTO) battery cells by utilizing both
cycle-based and instantaneous discharge data. Testing on eight LTO cells under
various cycling conditions over 500 cycles, we demonstrate the impact of charge
durations on energy storage trends and apply Differential Voltage Analysis
(DVA) to monitor capacity changes (dQ/dV) across voltage ranges. Our LLM model
achieves superior performance, with a Mean Absolute Error (MAE) as low as
0.87\% and varied latency metrics that support efficient processing,
demonstrating its strong potential for real-time integration into EVs. The
framework effectively identifies early signs of degradation through anomaly
detection in high-resolution data, facilitating predictive maintenance to
prevent sudden battery failures and enhance energy efficiency.",http://arxiv.org/abs/2501.18123v1
"Fits of $α_s$ from event-shapes in the three-jet region: extension
  to all energies",2025-01-30T07:01:52Z,"Paolo Nason, Giulia Zanderighi","This work is an extension of a previous publication [1] where we fitted the
strong coupling $\alpha_s$ together with the non-perturbative parameter
$\alpha_0$ from event-shape and jet-shape distributions using power corrections
computed in the three-jet region. In ref. [1] only ALEPH data at the $Z$-pole
were used in the fit. Here, instead, we include a large data sample from
various $e^+e^-$ experiments at energies ranging from 22 to 207 GeV and
revisited the treatment of theoretical uncertainties. We find that the
inclusion of different energies, while not changing the central fit result
considerably, helps to disentangle the dependence of perturbative and
non-perturbative corrections. Our best fit result is $\alpha_s(M_Z) = 0.1181
(+0.0002 -0.0005) (+0.0018 -0.0021)$, where the first error includes
experimental uncertianties and the second one includes uncertainties associated
with scale variation, mass effects, fit limits, non-perturbative schemes and
non-perturbative uncertainties.",http://arxiv.org/abs/2501.18173v1
Exciton-polariton condensate in the van der Waals magnet CrSBr,2025-01-30T09:45:38Z,"Bo Han, Hangyong Shan, Kok Wee Song, Lukas Lackner, Martin Esmann, Vita Solovyeva, Falk Eilenberger, Jakub Regner, Zdeněk Sofer, Oleksandr Kyriienko, Christian Schneider","Van der Waals magnets are an emergent material class of paramount interest
for fundamental studies in coupling light with matter excitations, which are
uniquely linked to their underlying magnetic properties. Among these materials,
the magnetic semiconductor CrSBr is possibly a first playground where we can
study simultaneously the interaction of photons, magnons, and excitons at the
quantum level. Here we demonstrate a coherent macroscopic quantum phase, the
bosonic condensation of exciton-polaritons, which emerges in a CrSBr flake
embedded in a fully tunable cryogenic open optical cavity. The Bose condensate
is characterized by a highly non-linear threshold-like behavior, and coherence
manifests distinctly via its first and second order quantum coherence. We find
that the condensate's non-linearity is highly susceptible to the magnetic order
in CrSBr, and encounters a sign change depending on the antiferro- and
ferromagnetic ordering. Our findings open a route towards magnetically
controllable quantum fluids of light, and optomagnonic devices where spin
magnetism is coupled to on-chip Bose-Einstein condensates.",http://arxiv.org/abs/2501.18233v1
"Statistical multi-metric evaluation and visualization of LLM system
  predictive performance",2025-01-30T10:21:10Z,"Samuel Ackerman, Eitan Farchi, Orna Raz, Assaf Toledo","The evaluation of generative or discriminative large language model
(LLM)-based systems is often a complex multi-dimensional problem. Typically, a
set of system configuration alternatives are evaluated on one or more benchmark
datasets, each with one or more evaluation metrics, which may differ between
datasets. We often want to evaluate -- with a statistical measure of
significance -- whether systems perform differently either on a given dataset
according to a single metric, on aggregate across metrics on a dataset, or
across datasets. Such evaluations can be done to support decision-making, such
as deciding whether a particular system component change (e.g., choice of LLM
or hyperparameter values) significantly improves performance over the current
system configuration, or, more generally, whether a fixed set of system
configurations (e.g., a leaderboard list) have significantly different
performances according to metrics of interest. We present a framework
implementation that automatically performs the correct statistical tests,
properly aggregates the statistical results across metrics and datasets (a
nontrivial task), and can visualize the results. The framework is demonstrated
on the multi-lingual code generation benchmark CrossCodeEval, for several
state-of-the-art LLMs.",http://arxiv.org/abs/2501.18243v1
Curvature-sensing and generation of membrane proteins: a review,2025-01-30T12:38:09Z,Hiroshi Noguchi,"Membrane proteins are crucial in regulating biomembrane shapes and
controlling the dynamic changes in membrane morphology during essential
cellular processes. These proteins can localize to regions with their preferred
curvatures (curvature sensing) and induce localized membrane curvature. Thus,
this review describes the recent theoretical development in membrane remodeling
performed by membrane proteins. The mean-field theories of protein binding and
the resulting membrane deformations are reviewed. The effects of hydrophobic
insertions on the area-difference elasticity energy and that of intrinsically
disordered protein domains on the membrane bending energy are discussed. For
the crescent-shaped proteins, such as Bin/Amphiphysin/Rvs superfamily proteins,
anisotropic protein bending energy and orientation-dependent excluded volume
significantly contribute to curvature sensing and generation. Moreover,
simulation studies of membrane deformations caused by protein binding and
colloidal particle adhesion are reviewed, including domain formation, budding,
and tubulation.",http://arxiv.org/abs/2501.18311v1
"Adaptive Video Streaming with AI-Based Optimization for Dynamic Network
  Conditions",2025-01-30T13:20:23Z,"Mohammad Tarik, Qutaiba Ibrahim","The increase in video streaming has presented a challenge of handling stream
request effectively, especially over networks that are variable. This paper
describes a new adaptive video streaming architecture capable of changing the
video quality and buffer size depending on the data and latency of streamed
video. For video streaming VLC media player was used where network performance
data were obtained through Python scripts with very accurate data rate and
latency measurement. The collected data is analyzed using Gemini AI, containing
characteristics of the machine learning algorithm that recognizes the best
resolution of videos and the buffer sizes. Through the features of real-time
monitoring and artificial intelligence decision making, the proposed framework
improves the user experience by reducing the occurrence of buffering events
while at the same time increasing the video quality. Our findings therefore
confirm that the proposed solution based on artificial intelligence increases
video quality and flexibility. This study advances knowledge of adaptive
streaming and offers an argument about how intelligent datadriven approaches
and AI may be useful tools for enhancing the delivery of video in practical
environments.",http://arxiv.org/abs/2501.18332v1
"Optimal performance of thermoelectric devices with small external
  irreversibility",2025-01-30T15:43:59Z,"Rajeshree Chakraborty, Ramandeep S. Johal","In the thermodynamic analysis of thermoelectric devices, typical
irreversibilities are for the processes of finite-rate heat transfer and Joule
heating. Approximate analyses often focus on either internal or external
irreversibility, yielding well-known expressions for the efficiency at maximum
power (EMP), such as the Curzon-Ahlborn value for endoreversible model and the
Schmiedl-Seifert form for exoreversible model. Within the Constant Properties
model, we formulate a scenario that incorporates internal as well as external
irreversibilities simultaneously. We employ the approximation of a symmetric
and small external irreversibility (SEI), confining to the regime where the
external conductance of the heat exchangers is large in comparison to the
internal thermal conductance of the thermoelectric material. This approach
allows us to derive a general expression for EMP, which depends on the ratio of
internal to external conductance, apart from the figure of merit and ratio of
temperatures. Extending our study to thermoelectric refrigerators under the
similar assumptions, we also analyze the efficiency at maximum cooling power.",http://arxiv.org/abs/2501.18437v2
Track-On: Transformer-based Online Point Tracking with Memory,2025-01-30T17:04:11Z,"Görkay Aydemir, Xiongyi Cai, Weidi Xie, Fatma Güney","In this paper, we consider the problem of long-term point tracking, which
requires consistent identification of points across multiple frames in a video,
despite changes in appearance, lighting, perspective, and occlusions. We target
online tracking on a frame-by-frame basis, making it suitable for real-world,
streaming scenarios. Specifically, we introduce Track-On, a simple
transformer-based model designed for online long-term point tracking. Unlike
prior methods that depend on full temporal modeling, our model processes video
frames causally without access to future frames, leveraging two memory modules
-- spatial memory and context memory -- to capture temporal information and
maintain reliable point tracking over long time horizons. At inference time, it
employs patch classification and refinement to identify correspondences and
track points with high accuracy. Through extensive experiments, we demonstrate
that Track-On sets a new state-of-the-art for online models and delivers
superior or competitive results compared to offline approaches on seven
datasets, including the TAP-Vid benchmark. Our method offers a robust and
scalable solution for real-time tracking in diverse applications. Project page:
https://kuis-ai.github.io/track_on",http://arxiv.org/abs/2501.18487v1
"Unitarity triangle angles explained: a predictive new quark mass matrix
  texture",2025-01-30T17:19:45Z,"P. F. Harrison, W. G. Scott","We propose a novel quark mass matrix texture-pair with five free parameters,
which fits the four quark mass ratios $m_s/m_b$, $m_d/m_b$, $m_c/m_t$,
$m_u/m_t$, and the four CKM quark mixing observables. The matrices each have
one texture zero, but the main innovation here is a ``geometric'' ansatz
exploiting a pair of small complex expansion parameters, based on the geometry
of the Unitarity Triangle. The fit to the observables is in good agreement with
current experimental values renormalised to $\sim\!\!10^4$ TeV, and offers
decisive tests against future high-precision measurements of the unitarity
triangle angles at the weak scale. We identify two novel symmetries of these
mass matrices which explain the phenomenologically-successful relations
$\alpha\equiv\phi_2\simeq\pibytwo$ and $\beta\equiv\phi_1\simeq\pibyeight$.",http://arxiv.org/abs/2501.18508v3
"Bias-variance decompositions: the exclusive privilege of Bregman
  divergences",2025-01-30T18:52:44Z,Tom Heskes,"Bias-variance decompositions are widely used to understand the generalization
performance of machine learning models. While the squared error loss permits a
straightforward decomposition, other loss functions - such as zero-one loss or
$L_1$ loss - either fail to sum bias and variance to the expected loss or rely
on definitions that lack the essential properties of meaningful bias and
variance. Recent research has shown that clean decompositions can be achieved
for the broader class of Bregman divergences, with the cross-entropy loss as a
special case. However, the necessary and sufficient conditions for these
decompositions remain an open question.
  In this paper, we address this question by studying continuous, nonnegative
loss functions that satisfy the identity of indiscernibles under mild
regularity conditions. We prove that so-called $g$-Bregman divergences are the
only such loss functions that have a clean bias-variance decomposition. A
$g$-Bregman divergence can be transformed into a standard Bregman divergence
through an invertible change of variables. This makes the squared Mahalanobis
distance, up to such a variable transformation, the only symmetric loss
function with a clean bias-variance decomposition. We also examine the impact
of relaxing the restrictions on the loss functions and how this affects our
results.",http://arxiv.org/abs/2501.18581v1
Magnetic field evolution of X-ray emitting radio-quiet pulsars,2025-01-29T14:10:19Z,"Debasis Atta, Vinay Singh, D. N. Basu","The intense magnetic fields present in neutron stars are closely linked to
their observed temperature and spectral characteristics, timing properties,
including spin period and its derivatives. Therefore, a comprehensive
theoretical analysis of magnetic field evolution is essential for understanding
how the strength of the magnetic field change over time. The decay rate of
magnetic field in isolated, non-accreting neutron stars can be assessed by
evaluating the second derivative of the spin frequency. Another method to
estimate this rate involves monitoring an increase in thermal emission beyond
what is expected from standard cooling processes, assuming no additional
heating mechanisms are present. Our findings indicate that for X-ray emitting
isolated neutron stars, the evolution rate of spin period derivative aligns
with the dissipation rate of magnetic energy from the dipolar field, provided
that a substantial portion of the released energy is emitted as X-rays. The
time scale of magnetic field decay is found to be much shorter than typical age
of radio pulsars.",http://arxiv.org/abs/2501.18647v1
"Enhancing Large Language Model Efficiencyvia Symbolic Compression: A
  Formal Approach Towards Interpretability",2025-01-30T06:40:52Z,"Lumen AI, Tengzhou No. 1 Middle School, Shihao Ji, Zihui Song, Fucheng Zhong, Jisen Jia, Zhaobo Wu, Zheyi Cao, Tianhao Xu","Large language models (LLMs) face significant token efficiency bottlenecks in
code generation and logical reasoning tasks, a challenge that directly impacts
inference cost and model interpretability. This paper proposes a formal
framework based on symbolic compression,integrating combinatory logic,
information-theoretic optimal encoding, and context-aware inference techniques
to achieve a step-change improvement in token efficiency while preserving
semantic integrity. We establish a mathematical framework within a functional
programming paradigm, derive the quantitative relationship between symbolic
density and model interpretability, and propose a differentiable compression
factor metric to evaluate encoding efficiency. Furthermore, we leverage
parameter-efficient fine-tuning (PEFT) techniques to achieve a low-cost
application of the GAEL language. Experimental results show that this method
achieves a 78.3% token compression rate in code generation tasks while
improving logical traceability by 62% through structural explicitness. This
research provides new theoretical tools for efficient inference in LLMs and
opens a symbolic path for modelinterpretability research.",http://arxiv.org/abs/2501.18657v1
"Pneutouch: Exploring the affordances and interactions of haptic
  inflatables through a wrist-worn interface",2025-01-30T21:37:05Z,"Frank Wencheng Liu, Mason Manetta, Prasad Borkar, Byron Lahey, Assegid Kidane, Robert LiKamWa","Haptic sensations that align with virtual reality (VR) experiences have a
profound impact on presence and enjoyment. There is potential to explore the
dynamic capabilities of pneumatic inflatables to offer immersive sensations in
virtual environments, including variations in shape, size, and stiffness. We
introduce Pneutouch, an ungrounded and untethered wrist-worn device designed as
a pneumatic haptic interface for VR interactions. Pneutouch's dynamic inflation
ability enables programmable stiffness and shape change of haptic proxies.
Additionally, multiple haptic proxies can be delivered into and out of the
user's hand grasp. We describe the implementation of the Pneutouch device. We
conducted user studies to demonstrate the affordances of pneumatic inflatables
and assessed the device's efficacy in providing haptic feedback. With
Pneutouch, our goal is to expand what can be touched in the virtual space and
bring more immersion into virtual reality.",http://arxiv.org/abs/2501.18764v1
"One Stack, Diverse Vehicles: Checking Safe Portability of Automated
  Driving Software",2025-01-30T21:45:32Z,Vladislav Nenchev,"Integrating an automated driving software stack into vehicles with variable
configuration is challenging, especially due to different hardware
characteristics. Further, to provide software updates to a vehicle fleet in the
field, the functional safety of every affected configuration has to be ensured.
These additional demands for dependability and the increasing hardware
diversity in automated driving make rigorous automatic analysis essential. This
paper addresses this challenge by using formal portability checking of adaptive
cruise controller code for different vehicle configurations. Given a formal
specification of the safe behavior, models of target configurations are
derived, which capture relevant effects of sensors, actuators and computing
platforms. A corresponding safe set is obtained and used to check if the
desired behavior is achievable on all targets. In a case study, portability
checking of a traditional and a neural network controller are performed
automatically within minutes for each vehicle hardware configuration. The check
provides feedback for necessary adaptations of the controllers, thus, allowing
rapid integration and testing of software or parameter changes.",http://arxiv.org/abs/2501.18769v1
$CP$ violation in the $HZZ$ vertex and left-right asymmetries,2025-01-30T23:56:35Z,"A. I. Hernández-Juárez, R. Gaitán","We calculate new contributions to the $HZZ$ vertex from the Flavor Changing
Neutral Current (FCNC) of the Higgs and $Z$ bosons. It is found that the
$h_2^V$ and $h_3^V$ ($V=H$, $Z$) form factors can be induced through these
couplings, and we present our results in terms of the Passarino-Veltman scalar
functions. Using the current limits on $H\overline{t}c$ and $Z\overline{t}c$
couplings, we determine that the new contributions to the $CP$-conserving form
factor $h_2^V$ are small in comparison to the Standard Model (SM) predictions.
However, for the $CP$-violating form factor $h_3^V$, the contributions can
reach values as large as $10^{-6}$, five orders of magnitude larger than in the
SM. Furthermore, we examine how these results influence the left-right
asymmetries in the processes $H^\ast\to ZZ$ and $Z^\ast\to ZH$. Our findings
indicate that significant deviations from the SM predictions may arise when
FCNC contributions are considered.",http://arxiv.org/abs/2501.18807v1
"Integrated Communication and Binary State Detection Under Unequal Error
  Constraints",2025-01-31T06:20:51Z,"Daewon Seo, Sung Hoon Lim","This work considers a problem of integrated sensing and communication (ISAC)
in which the goal of sensing is to detect a binary state. Unlike most
approaches that minimize the total detection error probability, in our work, we
disaggregate the error probability into false alarm and missed detection
probabilities and investigate their information-theoretic three-way tradeoff
including communication data rate. We consider a broadcast channel that
consists of a transmitter, a communication receiver, and a detector where the
receiver's and the detector's channels are affected by an unknown binary state.
We consider and present results on two different state-dependent models. In the
first setting, the state is fixed throughout the entire transmission, for which
we fully characterize the optimal three-way tradeoff between the coding rate
for communication and the two possibly nonidentical error exponents for sensing
in the asymptotic regime. The achievability and converse proofs rely on the
analysis of the cumulant-generating function of the log-likelihood ratio. In
the second setting, the state changes every symbol in an independently and
identically distributed (i.i.d.) manner, for which we characterize the optimal
tradeoff region based on the analysis of the receiver operating characteristic
(ROC) curves.",http://arxiv.org/abs/2501.18911v1
"Optimizing Through Change: Bounds and Recommendations for Time-Varying
  Bayesian Optimization Algorithms",2025-01-31T08:49:33Z,"Anthony Bardou, Patrick Thiran","Time-Varying Bayesian Optimization (TVBO) is the go-to framework for
optimizing a time-varying, expensive, noisy black-box function. However, most
of the solutions proposed so far either rely on unrealistic assumptions on the
nature of the objective function or do not offer any theoretical guarantees. We
propose the first analysis that asymptotically bounds the cumulative regret of
TVBO algorithms under mild and realistic assumptions only. In particular, we
provide an algorithm-independent lower regret bound and an upper regret bound
that holds for a large class of TVBO algorithms. Based on this analysis, we
formulate recommendations for TVBO algorithms and show how an algorithm (BOLT)
that follows them performs better than the state-of-the-art of TVBO through
experiments on synthetic and real-world problems.",http://arxiv.org/abs/2501.18963v1
"A two-stage stochastic MINLP model to design and operate a multi-energy
  microgrid by addressing carbon emission regulatory policies uncertainty",2025-01-31T09:38:17Z,"Handan Akülker, Burak Alakent, Erdal Aydin","This study suggests a novel two-stage Mixed-Integer Nonlinear Programming
model considering uncertainty related to implementation of carbon dioxide
emission regulatory policies, which are carbon trading and emission taxing and
can change over the years, for the purpose of optimal equipment selection from
candidate equipment to design, size and operate a multi-energy microgrid. The
uncertain sources are air temperature, wind speed, solar radiation, carbon
dioxide trading price or tax, and natural gas price. Candidate equipment are
wind turbines, PV arrays, a biomass-fired generator, biomass combined cycles,
combined heat and power generators, conventional generators, an electricity
storage unit, integrated gasification combined cycles, a heat pump, and a
power-to-synthetic natural gas (P2G) system. Three case studies are
investigated. In the first case, the model selects the optimal equipment for
meeting the electricity and heat demands only. In the second case, the optimal
equipment selections are determined to couple with the P2G system to meet the
electricity, heat, and natural gas demands. In the third case, the model
selects the optimal equipment to run with sustainable energy generators: wind
turbines and solar panels. The optimal selections are compared between
deterministic and stochastic forms of the optimization models.",http://arxiv.org/abs/2501.18988v1
"VKFPos: A Learning-Based Monocular Positioning with Variational Bayesian
  Extended Kalman Filter Integration",2025-01-31T09:54:11Z,"Jian-Yu Chen, Yi-Ru Chen, Yin-Qiao Chang, Che-Ming Li, Jann-Long Chern, Chih-Wei Huang","This paper addresses the challenges in learning-based monocular positioning
by proposing VKFPos, a novel approach that integrates Absolute Pose Regression
(APR) and Relative Pose Regression (RPR) via an Extended Kalman Filter (EKF)
within a variational Bayesian inference framework. Our method shows that the
essential posterior probability of the monocular positioning problem can be
decomposed into APR and RPR components. This decomposition is embedded in the
deep learning model by predicting covariances in both APR and RPR branches,
allowing them to account for associated uncertainties. These covariances
enhance the loss functions and facilitate EKF integration. Experimental
evaluations on both indoor and outdoor datasets show that the single-shot APR
branch achieves accuracy on par with state-of-the-art methods. Furthermore, for
temporal positioning, where consecutive images allow for RPR and EKF
integration, VKFPos outperforms temporal APR and model-based integration
methods, achieving superior accuracy.",http://arxiv.org/abs/2501.18994v1
"Assessing Sensitivity of Brain-to-Scalp Blood Flows in Laser Speckle
  Imaging by Occluding the Superficial Temporal Artery",2025-01-31T10:16:48Z,"Yu Xi Huang, Simon Mahler, Maya Dickson, Aidin Abedi, Yu Tung Lo, Patrick D. Lyden, Jonathan Russin, Charles Liu, Changhuei Yang","Cerebral blood flow is a critical metric for cerebrovascular monitoring, with
applications in stroke detection, brain injury evaluation, aging, and
neurological disorders. Non-invasively measuring cerebral blood dynamics is
challenging due to the scalp and skull, which obstruct direct brain access and
contain their own blood dynamics that must be isolated. We developed an
aggregated seven-channel speckle contrast optical spectroscopy system to
measure blood flow and blood volume non-invasively. Each channel, with distinct
source-to-detector distance, targeted different depths to detect scalp and
brain blood dynamics separately. By briefly occluding the superficial temporal
artery, which supplies blood only to the scalp, we isolated surface blood
dynamics from brain signals. Results on 20 subjects show that scalp-sensitive
channels experienced significant reductions in blood dynamics during occlusion,
while brain-sensitive channels experienced minimal changes. This provides
experimental evidence of brain-to-scalp sensitivity in optical measurements,
highlighting optimal configuration for preferentially probing brain signals
non-invasively.",http://arxiv.org/abs/2501.19005v1
Entanglement Entropy and Cauchy-Hadamard Renormalization,2025-01-31T10:26:32Z,"Benoit Estienne, Jiasheng Lin","This note presents a purely geometric construction of the so-called
twist-field correlation functions in Conformal Field Theory (CFT), derived from
conical singularities. This approach provides a purely mathematical
interpretation of the seminal results in physics by Cardy and Calabrese on the
entanglement entropy of quantum systems. Specifically, we begin by defining CFT
partition functions on surfaces with conical singularities, using a
``Cauchy-Hadamard renormalization'' of the Polyakov anomaly integral. Next, we
demonstrate that for a branched cover $f:\Sigma_d\to \Sigma$ with $d$ sheets,
where the cover inherits the pullback of a smooth metric from the base, a
specific ratio of partition functions on the cover to the base transforms under
conformal changes of the base metric in the same way as a correlation function
of CFT primary fields with specific conformal weights. We also provide a
discussion of the physical background and motivation for entanglement entropy,
focusing on path integrals and the replica trick, which serves as an
introduction to these ideas for a mathematical audience.",http://arxiv.org/abs/2501.19014v1
"Towards Physiologically Sensible Predictions via the Rule-based
  Reinforcement Learning Layer",2025-01-31T11:29:26Z,"Lingwei Zhu, Zheng Chen, Yukie Nagai, Jimeng Sun","This paper adds to the growing literature of reinforcement learning (RL) for
healthcare by proposing a novel paradigm: augmenting any predictor with
Rule-based RL Layer (RRLL) that corrects the model's physiologically impossible
predictions. Specifically, RRLL takes as input states predicted labels and
outputs corrected labels as actions. The reward of the state-action pair is
evaluated by a set of general rules. RRLL is efficient, general and
lightweight: it does not require heavy expert knowledge like prior work but
only a set of impossible transitions. This set is much smaller than all
possible transitions; yet it can effectively reduce physiologically impossible
mistakes made by the state-of-the-art predictor models. We verify the utility
of RRLL on a variety of important healthcare classification problems and
observe significant improvements using the same setup, with only the
domain-specific set of impossibility changed. In-depth analysis shows that RRLL
indeed improves accuracy by effectively reducing the presence of
physiologically impossible predictions.",http://arxiv.org/abs/2501.19055v1
"SmartDelta Methodology: Automated Quality Assurance and Optimization for
  Incremental System Engineering",2025-01-31T13:47:48Z,"Benedikt Dornauer Michael Felderer, Mehrdad Saadatmand, Muhammad Abbas, Nicolas Bonnotte, Andreas Dreschinski, Eduard Paul Enoiu, Eray Tüzün, Baykal Mehmet Uçar, Ömercan Devran, Robin Gröpler","Modern software systems undergo frequent updates, continuously evolving with
new versions and variants to offer new features, improve functionality, and
expand usability. Given the rapid pace of software evolution, organizations
require effective tools and methods to mitigate the challenges associated with
these changes, also called deltas. To address these challenges, the
international SmartDelta Project joined industry and academia to develop and
test solutions for incremental development and quality assurance. This paper
provides insights into the SmartDelta project achievements and highlights one
main contribution: the SmartDelta Methodology, a domain-unspecific concept for
delta management in incremental software engineering. This methodology enables
companies to identify gaps in their continuous engineering environment across
six stages and helps to discover new tools in various technical areas.
Additionally, the paper presents seven selected tools at different stages of
the methodology.",http://arxiv.org/abs/2501.19139v1
"E2Former: A Linear-time Efficient and Equivariant Transformer for
  Scalable Molecular Modeling",2025-01-31T15:22:58Z,"Yunyang Li, Lin Huang, Zhihao Ding, Chu Wang, Xinran Wei, Han Yang, Zun Wang, Chang Liu, Yu Shi, Peiran Jin, Jia Zhang, Mark Gerstein, Tao Qin","Equivariant Graph Neural Networks (EGNNs) have demonstrated significant
success in modeling microscale systems, including those in chemistry, biology
and materials science. However, EGNNs face substantial computational challenges
due to the high cost of constructing edge features via spherical tensor
products, making them impractical for large-scale systems. To address this
limitation, we introduce E2Former, an equivariant and efficient transformer
architecture that incorporates the Wigner $6j$ convolution (Wigner $6j$ Conv).
By shifting the computational burden from edges to nodes, the Wigner $6j$ Conv
reduces the complexity from $O(|\mathcal{E}|)$ to $ O(| \mathcal{V}|)$ while
preserving both the model's expressive power and rotational equivariance. We
show that this approach achieves a 7x-30x speedup compared to conventional
$\mathrm{SO}(3)$ convolutions. Furthermore, our empirical results demonstrate
that the derived E2Former mitigates the computational challenges of existing
approaches without compromising the ability to capture detailed geometric
information. This development could suggest a promising direction for scalable
and efficient molecular modeling.",http://arxiv.org/abs/2501.19216v2
"DINAMO: Dynamic and INterpretable Anomaly MOnitoring for Large-Scale
  Particle Physics Experiments",2025-01-31T15:51:41Z,"Arsenii Gavrikov, Julián García Pardiñas, Alberto Garfagnini","Ensuring reliable data collection in large-scale particle physics experiments
demands Data Quality Monitoring (DQM) procedures to detect possible detector
malfunctions and preserve data integrity. Traditionally, this
resource-intensive task has been handled by human shifters that struggle with
frequent changes in operational conditions. We present novel, interpretable,
robust, and scalable DQM algorithms designed to automate anomaly detection in
time-dependent settings. Our approach constructs evolving histogram templates
with built-in uncertainties, featuring both a statistical variant - extending
the classical Exponentially Weighted Moving Average (EWMA) - and a machine
learning (ML)-enhanced version that leverages a transformer encoder for
improved adaptability. Experimental validations on synthetic datasets
demonstrate the high accuracy, adaptability, and interpretability of these
methods, with the statistical variant being commissioned in the LHCb experiment
at the Large Hadron Collider, underscoring its real-world impact. The code used
in this study is available at https://github.com/ArseniiGav/DINAMO.",http://arxiv.org/abs/2501.19237v1
Linear $Q$-Learning Does Not Diverge: Convergence Rates to a Bounded Set,2025-01-31T16:10:50Z,"Xinyu Liu, Zixuan Xie, Shangtong Zhang","$Q$-learning is one of the most fundamental reinforcement learning
algorithms. Previously, it is widely believed that $Q$-learning with linear
function approximation (i.e., linear $Q$-learning) suffers from possible
divergence. This paper instead establishes the first $L^2$ convergence rate of
linear $Q$-learning to a bounded set. Notably, we do not make any modification
to the original linear $Q$-learning algorithm, do not make any Bellman
completeness assumption, and do not make any near-optimality assumption on the
behavior policy. All we need is an $\epsilon$-softmax behavior policy with an
adaptive temperature. The key to our analysis is the general result of
stochastic approximations under Markovian noise with fast-changing transition
functions. As a side product, we also use this general result to establish the
$L^2$ convergence rate of tabular $Q$-learning with an $\epsilon$-softmax
behavior policy, for which we rely on a novel pseudo-contraction property of
the weighted Bellman optimality operator.",http://arxiv.org/abs/2501.19254v1
The Solo Revolution: A Theory of AI-Enabled Individual Entrepreneurship,2025-01-07T01:34:13Z,Venkat Ram Reddy Ganuthula,"This paper presents the AI Enabled Individual Entrepreneurship Theory (AIET),
a theoretical framework explaining how artificial intelligence technologies
transform individual entrepreneurial capability. The theory identifies two
foundational premises: knowledge democratization and resource requirements
evolution. Through three core mechanisms skill augmentation, capital structure
transformation, and risk profile modification AIET explains how individuals can
now undertake entrepreneurial activities at scales previously requiring
significant organizational infrastructure. The theory presents five testable
propositions addressing the changing relationship between organizational size
and competitive advantage, the expansion of individual entrepreneurial
capacity, the transformation of market entry barriers, the evolution of
traditional firm advantages, and the modification of entrepreneurial risk
profiles. Boundary conditions related to task characteristics and market
conditions define the theory's scope and applicability. The framework suggests
significant implications for entrepreneurship theory, organizational design,
and market structure as AI capabilities continue to advance. This theory
provides a foundation for understanding the evolving landscape of
entrepreneurship in an AI-enabled world.",http://arxiv.org/abs/2502.00009v1
"A Dynamic and High-Precision Method for Scenario-Based HRA Synthetic
  Data Collection in Multi-Agent Collaborative Environments Driven by LLMs",2025-01-16T09:23:48Z,"Xingyu Xiao, Peng Chen, Qianqian Jia, Jiejuan Tong, Jingang Liang, Haitao Wang","HRA (Human Reliability Analysis) data is crucial for advancing HRA
methodologies. however, existing data collection methods lack the necessary
granularity, and most approaches fail to capture dynamic features.
Additionally, many methods require expert knowledge as input, making them
time-consuming and labor-intensive. To address these challenges, we propose a
new paradigm for the automated collection of HRA data. Our approach focuses on
key indicators behind human error, specifically measuring workload in
collaborative settings. This study introduces a novel, scenario-driven method
for workload estimation, leveraging fine-tuned large language models (LLMs). By
training LLMs on real-world operational data from high-temperature gas-cooled
reactors (HTGRs), we simulate human behavior and cognitive load in real time
across various collaborative scenarios. The method dynamically adapts to
changes in operator workload, providing more accurate, flexible, and scalable
workload estimates. The results demonstrate that the proposed WELLA (Workload
Estimation with LLMs and Agents) outperforms existing commercial LLM-based
methods in terms of prediction accuracy.",http://arxiv.org/abs/2502.00022v1
"Evolving Performance Practices in Beethoven's Cello Sonatas: Tempo,
  Portamento, and Historical Interpretation of the First Movements",2025-01-23T13:49:57Z,Ignasi Sole,"This paper examines the evolving performance practices of Ludwig van
Beethoven's cello sonatas, with a particular focus on tempo and portamento
between 1930 and 2012. It integrates analyses of 22 historical recordings,
advancements in recording technology to shed light on changes in interpretative
approaches. By comparing Beethoven's metronome markings, as understood through
contemporaries such as Czerny and Moscheles, with their application in modern
performances, my research highlights notable deviations. These differences
prove the challenges performers face in reconciling historical tempos with the
demands of contemporary performance practice. My study pays special attention
to the diminishing use of audible portamento in the latter half of the 20th
century, contrasted with a gradual increase in tempo after 1970. This
development is linked to broader cultural and pedagogical shifts, including the
adoption of fingering techniques that reduce hand shifts, thereby facilitating
greater technical precision at faster tempos. Nonetheless, my study identifies
the persistence of 'silent portamento' as an expressive device, allowing
performers to retain stylistic expression without compromising rhythmic
integrity. My paper offers valuable insights for performers and scholars alike,
advocating a critical reassessment of Beethoven's tempo markings and the
nuanced application of portamento in modern performance practice.",http://arxiv.org/abs/2502.00030v1
HadamRNN: Binary and Sparse Ternary Orthogonal RNNs,2025-01-28T09:16:28Z,"Armand Foucault, Franck Mamalet, François Malgouyres","Binary and sparse ternary weights in neural networks enable faster
computations and lighter representations, facilitating their use on edge
devices with limited computational power. Meanwhile, vanilla RNNs are highly
sensitive to changes in their recurrent weights, making the binarization and
ternarization of these weights inherently challenging. To date, no method has
successfully achieved binarization or ternarization of vanilla RNN weights. We
present a new approach leveraging the properties of Hadamard matrices to
parameterize a subset of binary and sparse ternary orthogonal matrices. This
method enables the training of orthogonal RNNs (ORNNs) with binary and sparse
ternary recurrent weights, effectively creating a specific class of binary and
sparse ternary vanilla RNNs. The resulting ORNNs, called HadamRNN and
lock-HadamRNN, are evaluated on benchmarks such as the copy task, permuted and
sequential MNIST tasks, and IMDB dataset. Despite binarization or sparse
ternarization, these RNNs maintain performance levels comparable to
state-of-the-art full-precision models, highlighting the effectiveness of our
approach. Notably, our approach is the first solution with binary recurrent
weights capable of tackling the copy task over 1000 timesteps.",http://arxiv.org/abs/2502.00047v2
Hyperluminous Supersoft X-ray Sources in the Chandra Catalog,2025-01-31T19:00:00Z,"Andrea Sacchi, Kevin Paggeot, Steven Dillmann, Juan Rafael Martinez-Galarza, Peter Kosec","Hyperluminous supersoft X-ray sources, such as bright extragalactic sources
characterized by particularly soft X-ray spectra, offer a unique opportunity to
study accretion onto supermassive black holes in extreme conditions. Examples
of hyperluminous supersoft sources are tidal disruption events, systems
exhibiting quasi-periodic eruptions, changing-look AGN, and anomalous nuclear
transients. Although these objects are rare phenomena amongst the population of
X-ray sources, we developed an efficient algorithm to identify promising
candidates exploiting archival observations. In this work, we present the
results of a search for hyperluminous supersoft X-ray sources in the recently
released Chandra catalog of serendipitous X-ray sources. This archival search
has been performed via both a manual implementation of the algorithm we
developed and a novel machine-learning-based approach. This search identified a
new tidal disruption event, which might have occurred in an intermediate-mass
black hole. This event occurred between 2001 and 2002, making it one of the
first tidal disruption events ever observed by Chandra.",http://arxiv.org/abs/2502.00097v1
Homotopy connectivity of Čech complexes of spheres,2025-01-31T19:14:56Z,"Henry Adams, Ekansh Jauhari, Sucharita Mallick","Let $S^n$ be the $n$-sphere with the geodesic metric and of diameter $\pi$.
The intrinsic \v{C}ech complex of $S^n$ at scale $r$ is the nerve of all open
balls of radius $r$ in $S^n$. In this paper, we show how to control the
homotopy connectivity of \v{C}ech complexes of spheres at each scale between
$0$ and $\pi$ in terms of coverings of spheres. Our upper bound on the
connectivity, which is sharp in the case $n=1$, comes from the chromatic
numbers of Borsuk graphs of spheres. Our lower bound is obtained using the
conicity (in the sense of Barmak) of \v{C}ech complexes of the sufficiently
dense, finite subsets of $S^n$. Our bounds imply the new result that for $n\ge
1$, the homotopy type of the \v{C}ech complex of $S^n$ at scale $r$ changes
infinitely many times as $r$ varies over $(0,\pi)$; we conjecture only
countably many times. Additionally, we lower bound the homological dimension of
\v{C}ech complexes of finite subsets of $S^n$ in terms of their packings.",http://arxiv.org/abs/2502.00122v1
"A definition of the mass aspect function for weakly regular
  asymptotically hyperbolic manifolds",2025-01-31T19:19:00Z,"Romain Gicquaud, Anna Sakovich","In contrast to the well-known and unambiguous notion of ADM mass for
asymptotically Euclidean manifolds, the notion of mass for asymptotically
hyperbolic manifolds admits several interpretations. Historically, there are
two approaches to defining the mass in the asymptotically hyperbolic setting:
the mass aspect function of Wang defined on the conformal boundary at infinity,
and the mass functional of Chru\'sciel and Herzlich which may be thought of as
the closest asymptotically hyperbolic analogue of the ADM mass. In this paper
we unify these two approaches by introducing an ADM-style definition of the
mass aspect function that applies to a broad range of asymptotics and in very
low regularity. Additionally, we show that the mass aspect function can be
computed using the Ricci tensor. Finally, we demonstrate that this function
exhibits favorable covariance properties under changes of charts at infinity,
which includes a proof of the asymptotic rigidity of hyperbolic space in the
context of weakly regular metrics.",http://arxiv.org/abs/2502.00125v1
"INSIGHT: Enhancing Autonomous Driving Safety through Vision-Language
  Models on Context-Aware Hazard Detection and Edge Case Evaluation",2025-02-01T01:43:53Z,"Dianwei Chen, Zifan Zhang, Yuchen Liu, Xianfeng Terry Yang","Autonomous driving systems face significant challenges in handling
unpredictable edge-case scenarios, such as adversarial pedestrian movements,
dangerous vehicle maneuvers, and sudden environmental changes. Current
end-to-end driving models struggle with generalization to these rare events due
to limitations in traditional detection and prediction approaches. To address
this, we propose INSIGHT (Integration of Semantic and Visual Inputs for
Generalized Hazard Tracking), a hierarchical vision-language model (VLM)
framework designed to enhance hazard detection and edge-case evaluation. By
using multimodal data fusion, our approach integrates semantic and visual
representations, enabling precise interpretation of driving scenarios and
accurate forecasting of potential dangers. Through supervised fine-tuning of
VLMs, we optimize spatial hazard localization using attention-based mechanisms
and coordinate regression techniques. Experimental results on the BDD100K
dataset demonstrate a substantial improvement in hazard prediction
straightforwardness and accuracy over existing models, achieving a notable
increase in generalization performance. This advancement enhances the
robustness and safety of autonomous driving systems, ensuring improved
situational awareness and potential decision-making in complex real-world
scenarios.",http://arxiv.org/abs/2502.00262v2
"Distributive Fairness in Large Language Models: Evaluating Alignment
  with Human Values",2025-02-01T04:24:47Z,"Hadi Hosseini, Samarth Khanna","The growing interest in employing large language models (LLMs) for
decision-making in social and economic contexts has raised questions about
their potential to function as agents in these domains. A significant number of
societal problems involve the distribution of resources, where fairness, along
with economic efficiency, play a critical role in the desirability of outcomes.
In this paper, we examine whether LLM responses adhere to fundamental fairness
concepts such as equitability, envy-freeness, and Rawlsian maximin, and
investigate their alignment with human preferences. We evaluate the performance
of several LLMs, providing a comparative benchmark of their ability to reflect
these measures. Our results demonstrate a lack of alignment between current LLM
responses and human distributional preferences. Moreover, LLMs are unable to
utilize money as a transferable resource to mitigate inequality. Nonetheless,
we demonstrate a stark contrast when (some) LLMs are tasked with selecting from
a predefined menu of options rather than generating one. In addition, we
analyze the robustness of LLM responses to variations in semantic factors (e.g.
intentions or personas) or non-semantic prompting changes (e.g. templates or
orderings). Finally, we highlight potential strategies aimed at enhancing the
alignment of LLM behavior with well-established fairness concepts.",http://arxiv.org/abs/2502.00313v1
"Flexible delivery of high-power picosecond laser in purely-single
  optical mode of anti-resonant hollow-core fiber for micromachining",2025-02-01T07:16:21Z,"Xinshuo Chang, Qinan Jiang, Zhiyuan Huang, Jinyu Pan, Qingwei Zhang, Nan Li, Zhuozhao Luo, Ruochen Yin, Wenbin He, Jiapeng Huang, Yuxin Leng, Xin Jiang, Shanglu Yang, Meng Pang","We present the flexible delivery of picosecond laser pulses with up to 20 W
average power over a 3-m-long sample of anti-resonant hollow-core fiber
(AR-HCF) for laser micromachining applications. Our experiments highlight the
importance of optical mode purity of the AR-HCF for the manufacturing
precision. We demonstrate that compared with an AR-HCF sample with a capillary
to core (d/D) ratio of ~0.5, the AR-HCF with a d/D ratio of ~0.68 exhibits
better capability of high-order-mode suppression, giving rise to improved
micromachining quality. Moreover, the AR-HCF delivery system exhibits better
pointing stability and set-up flexibility than the free-space beam delivery
system. These results pave the way to practical applications of AR-HCF in
developing advanced equipment for ultrafast laser micromachining.",http://arxiv.org/abs/2502.00353v1
"Latent Action Learning Requires Supervision in the Presence of
  Distractors",2025-02-01T09:35:51Z,"Alexander Nikulin, Ilya Zisman, Denis Tarasov, Nikita Lyubaykin, Andrei Polubarov, Igor Kiselev, Vladislav Kurenkov","Recently, latent action learning, pioneered by Latent Action Policies (LAPO),
have shown remarkable pre-training efficiency on observation-only data,
offering potential for leveraging vast amounts of video available on the web
for embodied AI. However, prior work has focused on distractor-free data, where
changes between observations are primarily explained by ground-truth actions.
Unfortunately, real-world videos contain action-correlated distractors that may
hinder latent action learning. Using Distracting Control Suite (DCS) we
empirically investigate the effect of distractors on latent action learning and
demonstrate that LAPO struggle in such scenario. We propose LAOM, a simple LAPO
modification that improves the quality of latent actions by 8x, as measured by
linear probing. Importantly, we show that providing supervision with
ground-truth actions, as few as 2.5% of the full dataset, during latent action
learning improves downstream performance by 4.2x on average. Our findings
suggest that integrating supervision during Latent Action Models (LAM) training
is critical in the presence of distractors, challenging the conventional
pipeline of first learning LAM and only then decoding from latent to
ground-truth actions.",http://arxiv.org/abs/2502.00379v1
"Explorations of the Softmax Space: Knowing When the Neural Network
  Doesn't Know...",2025-02-01T15:25:03Z,"Daniel Sikar, Artur d'Avila Garcez, Tillman Weyde","Ensuring the reliability and safety of automated decision-making is crucial.
This paper proposes a new approach for measuring the reliability of predictions
in machine learning models. We analyze how the outputs of a trained neural
network change using clustering to measure distances between outputs and class
centroids. We propose this distance as a metric to evaluate the confidence of
predictions. We assign each prediction to a cluster with centroid representing
the mean softmax output for all correct predictions of a given class. We then
define a safety threshold for a class as the smallest distance from an
incorrect prediction to the given class centroid. We evaluate the approach on
the MNIST and CIFAR-10 datasets using a Convolutional Neural Network and a
Vision Transformer, respectively. The results show that our approach is
consistent across these data sets and network models, and indicate that the
proposed metric can offer an efficient way of determining when automated
predictions are acceptable and when they should be deferred to human operators.",http://arxiv.org/abs/2502.00456v1
Oscillations Make Neural Networks Robust to Quantization,2025-02-01T16:39:58Z,"Jonathan Wenshøj, Bob Pepin, Raghavendra Selvan","We challenge the prevailing view that oscillations in Quantization Aware
Training (QAT) are merely undesirable artifacts caused by the Straight-Through
Estimator (STE). Through theoretical analysis of QAT in linear models, we
demonstrate that the gradient of the loss function can be decomposed into two
terms: the original full-precision loss and a term that causes quantization
oscillations. Based on these insights, we propose a novel regularization method
that induces oscillations to improve quantization robustness. Contrary to
traditional methods that focuses on minimizing the effects of oscillations, our
approach leverages the beneficial aspects of weight oscillations to preserve
model performance under quantization. Our empirical results on ResNet-18 and
Tiny ViT demonstrate that this counter-intuitive strategy matches QAT accuracy
at >= 3-bit weight quantization, while maintaining close to full precision
accuracy at bits greater than the target bit. Our work therefore provides a new
perspective on model preparation for quantization, particularly for finding
weights that are robust to changes in the bit of the quantizer -- an area where
current methods struggle to match the accuracy of QAT at specific bits.",http://arxiv.org/abs/2502.00490v1
"Looking into the Future of Health-Care Services: Can Life-Like Agents
  Change the Future of Health-Care Services?",2025-02-01T17:11:49Z,"Mohammad Saleh Torkestani, Robert Davis, Abdolhossein Sarrafzadeh","Time constraints on doctor patient interaction and restricted access to
specialists under the managed care system led to increasingly referring to
computers as a medical information source and a self-health-care management
tool. However, research show that less than 40% of information seekers
indicated that online information helped them to make a decision about their
health. Searching multiple web sites that need basic computer skills, lack of
interaction and no face to face interaction in most search engines and some
social issues, led us to develop a specialized life-like agent that would
overcome mentioned problems.",http://arxiv.org/abs/2502.00495v1
"Boundary element formulation of the Mild-Slope Equation for harmonic
  water waves propagating over unidirectional variable bathymetries",2025-02-01T19:50:15Z,"Antonio Cerrato, José A. González, Luis Rodríguez-Temblequer","This paper presents a boundary element formulation for the solution of the
Mild-Slope equation in wave propagation problems with variable water depth in
one direction. Based on the Green's function approximation proposed by
Belibassakis \cite{Belibassakis2000}, a complete fundamental-solution kernel is
developed and combined with a boundary element scheme for the solution of water
wave propagation problems in closed and open domains where the bathymetry
changes arbitrarily and smoothly in a preferential direction. The ability of
the proposed formulation to accurately represent wave phenomena like
refraction, reflection, diffraction and shoaling, is demonstrated with the
solution of some example problems, in which arbitrary geometries and variable
seabed profiles with slopes up to 1:3 are considered. The obtained results are
also compared with theoretical solutions, showing an excellent agreement that
demonstrates its potential.",http://arxiv.org/abs/2502.00540v1
"The Influence of Stellar Chromospheres and Coronae on Exoplanet
  Transmission Spectroscopy",2025-02-01T20:48:23Z,"Volker Perdelwitz, Adam Chaikin-Lifshitz, Aviv Ofir, Oded Aharonson","A main source of bias in transmission spectroscopy of exoplanet atmospheres
is magnetic activity of the host star in the form of stellar spots, faculae or
flares. However, the fact that main-sequence stars have a chromosphere and a
corona, and that these optically thin layers are dominated by line emission may
alter the global interpretation of the planetary spectrum, has largely been
neglected. Using a JWST NIRISS/SOSS data set of hot Jupiter HAT-P-18 b, we show
that even at near-IR and IR wavelengths, the presence of these layers leads to
significant changes in the transmission spectrum of the planetary atmosphere.
Accounting for these stellar outer layers thus improves the atmospheric fit of
HAT-P-18 b, and increases its best-fit atmospheric temperature from 536 K to
736 K, a value much closer to the predicted equilibrium temperature of 852 K.
Our analysis also decreases the best-fit abundance of CO2 by almost an order of
magnitude. The approach provides a new window to the properties of
chromospheres/corona in stars other than our Sun.",http://arxiv.org/abs/2502.00553v1
"Defense Against the Dark Prompts: Mitigating Best-of-N Jailbreaking with
  Prompt Evaluation",2025-02-01T22:26:30Z,"Stuart Armstrong, Matija Franklin, Connor Stevens, Rebecca Gorman","Recent work showed Best-of-N (BoN) jailbreaking using repeated use of random
augmentations (such as capitalization, punctuation, etc) is effective against
all major large language models (LLMs). We have found that $100\%$ of the BoN
paper's successful jailbreaks (confidence interval $[99.65\%, 100.00\%]$) and
$99.8\%$ of successful jailbreaks in our replication (confidence interval
$[99.28\%, 99.98\%]$) were blocked with our Defense Against The Dark Prompts
(DATDP) method. The DATDP algorithm works by repeatedly utilizing an evaluation
LLM to evaluate a prompt for dangerous or manipulative behaviors--unlike some
other approaches, DATDP also explicitly looks for jailbreaking attempts--until
a robust safety rating is generated. This success persisted even when utilizing
smaller LLMs to power the evaluation (Claude and LLaMa-3-8B-instruct proved
almost equally capable). These results show that, though language models are
sensitive to seemingly innocuous changes to inputs, they seem also capable of
successfully evaluating the dangers of these inputs. Versions of DATDP can
therefore be added cheaply to generative AI systems to produce an immediate
significant increase in safety.",http://arxiv.org/abs/2502.00580v1
"Integrating Cybersecurity Frameworks into IT Security: A Comprehensive
  Analysis of Threat Mitigation Strategies and Adaptive Technologies",2025-02-02T03:38:48Z,"Amit Lokare, Shripad Bankar, Padmajeet Mhaske","The cybersecurity threat landscape is constantly actively making it
imperative to develop sound frameworks to protect the IT structures. Based on
this introduction, this paper aims to discuss the application of cybersecurity
frameworks into the IT security with focus placed on the role of such
frameworks in addressing the changing nature of cybersecurity threats. It
explores widely used models, including the NIST Cybersecurity Framework, Zero
Trust Architecture, and the ISO/IEC 27001, and how they apply to industries
including finance, healthcare and government. The discussion also singles out
such technologies as Artificial Intelligence (AI) and Machine Learning (ML) as
the core for real-time threat detection and response mechanisms. As these
integration challenges demonstrate, the study provides tangible and proven
approaches to tackle framework implementation issues such as legitimate
security issues, limited availability of funds and resources, and compliance
with legal requirements. By capturing current trends and exposures, the
findings promote strong, portfolio-based and risk-appropriate security
approaches adjusted for organizational goals and capable to prevent advanced
cyber threats.",http://arxiv.org/abs/2502.00651v1
"Topological flow data analysis for transient flow patterns: a
  graph-based approach",2025-02-02T04:36:33Z,"Takashi Sakajo, Takeshi Matsumoto, Shizuo Kaji, Tomoo Yokoyama, Tomoki Uda","We introduce a time-series analysis method for transient two-dimensional flow
patterns based on Topological Flow Data Analysis (TFDA), a new approach to
topological data analysis. TFDA identifies local topological flow structures
from an instantaneous streamline pattern and describes their global connections
as a unique planar tree and its string representation. With TFDA, the evolution
of two-dimensional flow patterns is reduced to a discrete dynamical system
represented as a transition graph between topologically equivalent streamline
patterns. We apply this method to study the lid-driven cavity flow at Reynolds
numbers ranging from $Re=14000$ to $Re=16000$, a benchmark problem in fluid
dynamics data analysis. Our approach reveals the transition from periodic to
chaotic flow at a critical Reynolds number when the reduced dynamical system is
modelled as a Markov process on the transition graph. Additionally, we perform
an observational causal inference to analyse changes in local flow patterns at
the cavity corners and discuss differences with a standard interventional
sensitivity analysis. This work demonstrates the potential of TFDA-based
time-series analysis for uncovering complex dynamical behaviours in fluid flow
data.",http://arxiv.org/abs/2502.00664v1
High-Order Matching for One-Step Shortcut Diffusion Models,2025-02-02T06:19:59Z,"Bo Chen, Chengyue Gong, Xiaoyu Li, Yingyu Liang, Zhizhou Sha, Zhenmei Shi, Zhao Song, Mingda Wan","One-step shortcut diffusion models [Frans, Hafner, Levine and Abbeel, ICLR
2025] have shown potential in vision generation, but their reliance on
first-order trajectory supervision is fundamentally limited. The Shortcut
model's simplistic velocity-only approach fails to capture intrinsic manifold
geometry, leading to erratic trajectories, poor geometric alignment, and
instability-especially in high-curvature regions. These shortcomings stem from
its inability to model mid-horizon dependencies or complex distributional
features, leaving it ill-equipped for robust generative modeling. In this work,
we introduce HOMO (High-Order Matching for One-Step Shortcut Diffusion), a
game-changing framework that leverages high-order supervision to revolutionize
distribution transportation. By incorporating acceleration, jerk, and beyond,
HOMO not only fixes the flaws of the Shortcut model but also achieves
unprecedented smoothness, stability, and geometric precision. Theoretically, we
prove that HOMO's high-order supervision ensures superior approximation
accuracy, outperforming first-order methods. Empirically, HOMO dominates in
complex settings, particularly in high-curvature regions where the Shortcut
model struggles. Our experiments show that HOMO delivers smoother trajectories
and better distributional alignment, setting a new standard for one-step
generative models.",http://arxiv.org/abs/2502.00688v1
"Magnetic-Field Dependence of Paramagnetic Properties Investigated by
  63/65Cu-NMR on the Yb Zigzag-Chain Semiconductor YbCuS2",2025-02-02T16:01:46Z,"Fumiya Hori, Shunsaku Kitagawa, Kenji Ishida, Yudai Ohmagari, Takahiro Onimaru","To investigate the paramagnetic properties of YbCuS2 under magnetic fields,
we have performed the 63/65Cu-nuclear magnetic resonance (NMR) measurements.
The NMR spectra can be reproduced by the simulations of the three-dimensional
powder pattern and the additional two-dimensional powder pattern, indicating
the partial sample orientation due to the anisotropy of the magnetic
properties. These simulations suggest that the ac plane is the easy plane in
YbCuS2. The Knight shift K is proportional to the bulk magnetic susceptibility
and field-independent. The broad maximum of the nuclear spin-lattice relaxation
rate 1/T1 at Tmax ~ 50 K (50 K anomaly) observed at zero magnetic field is
quickly suppressed by the magnetic fields. This indicates that the 50 K anomaly
is field-dependent. Furthermore, an anomalous enhancement of 1/T1 at low
temperatures was observed above 3 T. This field seemingly corresponds to the
magnetic field at which a field-induced phase transition occurs below the
antiferromagnetic transition temperature TN ~ 1 K. The changes in 1/T1 observed
in the paramagnetic state suggest the presence of the complex quantum phenomena
under magnetic fields in YbCuS2.",http://arxiv.org/abs/2502.00830v1
Developing Compelling Safety Cases,2025-02-02T20:47:30Z,Richard Hawkins,"This paper describes a method for creating compelling safety cases. The
method seeks to help improve safety case practice in order to address the
weaknesses identified in current practice, in particular confirmation bias,
after-the-fact assurance and safety cases as a paperwork exercise. Rather than
creating new notations and tools to address these issues, we contend that it is
improvements in the safety case process that will make the most significant
improvement to safety case practice. Our method builds upon established
approaches and best practice to create an approach that will ensure safety
cases are risk-focused, seek to identify ways in which the system may not be
safe (rather than just assuming it is), drive safe design and operation of the
system (influencing the system itself rather than just documenting what's
there), are used to support decisions made throughout the life of the system,
including system operation and change, and encourage developers and operators
to think about and understand why their system is safe (and when it isn't). A
simple example of an infusion pump system is used to illustrate how the new
method is applied in practice.",http://arxiv.org/abs/2502.00911v1
Huff-LLM: End-to-End Lossless Compression for Efficient LLM Inference,2025-02-02T21:23:42Z,"Patrick Yubeaton, Tareq Mahmoud, Shehab Naga, Pooria Taheri, Tianhua Xia, Arun George, Yasmein Khalil, Sai Qian Zhang, Siddharth Joshi, Chinmay Hegde, Siddharth Garg","As they become more capable, large language models (LLMs) have continued to
rapidly increase in size. This has exacerbated the difficulty in running state
of the art LLMs on small, edge devices. Standard techniques advocate solving
this problem through lossy compression techniques such as quantization or
pruning. However, such compression techniques are lossy, and have been shown to
change model behavior in unpredictable manners. We propose Huff-LLM, an
\emph{end-to-end, lossless} model compression method that lets users store LLM
weights in compressed format \emph{everywhere} -- cloud, disk, main memory, and
even in on-chip memory/buffers. This allows us to not only load larger models
in main memory, but also reduces bandwidth required to load weights on chip,
and makes more efficient use of on-chip weight buffers. In addition to the
memory savings achieved via compression, we also show latency and energy
efficiency improvements when performing inference with the compressed model.",http://arxiv.org/abs/2502.00922v1
Dark energy and cosmic acceleration,2025-02-02T21:27:16Z,"Rodrigo von Marttens, Jailson Alcaniz","The discovery that we live in an accelerating universe changed drastically
the paradigm of physics and introduced the concept of \textit{dark energy}. In
this work, we present a brief historical description of the main events related
to the discovery of cosmic acceleration and the basic elements of theoretical
and observational aspects of dark energy. Regarding the historical perspective,
we outline some of the key milestones for tracing the journey from Einstein's
proposal of the cosmological constant to the type Ia supernovae results.
Conversely, on the theoretical/observational side, we begin by analyzing cosmic
acceleration within the context of the standard cosmological model, i.e., in
terms of the cosmological constant. In this case, we show how a positive
cosmological constant drives accelerated expansion and discuss the main
observational aspects, such as updated results and current cosmological
tensions. We also explore alternative descriptions of dark energy, encompassing
dynamic and interacting dark energy models.",http://arxiv.org/abs/2502.00923v1
"Analysis of static and dynamic batching algorithms for graph neural
  networks",2025-02-02T22:34:17Z,"Daniel Speckhard, Tim Bechtel, Sebastian Kehl, Jonathan Godwin, Claudia Draxl","Graph neural networks (GNN) have shown promising results for several domains
such as materials science, chemistry, and the social sciences. GNN models often
contain millions of parameters, and like other neural network (NN) models, are
often fed only a fraction of the graphs that make up the training dataset in
batches to update model parameters. The effect of batching algorithms on
training time and model performance has been thoroughly explored for NNs but
not yet for GNNs. We analyze two different batching algorithms for graph based
models, namely static and dynamic batching. We use the Jraph library built on
JAX to perform our experiments, where we compare the two batching methods for
two datasets, the QM9 dataset of small molecules and the AFLOW materials
database. Our experiments show that significant training time savings can be
found from changing the batching algorithm, but the fastest algorithm depends
on the data, model, batch size and number of training steps run. Experiments
show no significant difference in model learning between the algorithms.",http://arxiv.org/abs/2502.00944v1
"SatFlow: Generative model based framework for producing High Resolution
  Gap Free Remote Sensing Imagery",2025-02-03T06:40:13Z,"Bharath Irigireddy, Varaprasad Bandaru","Frequent, high-resolution remote sensing imagery is crucial for agricultural
and environmental monitoring. Satellites from the Landsat collection offer
detailed imagery at 30m resolution but with lower temporal frequency, whereas
missions like MODIS and VIIRS provide daily coverage at coarser resolutions.
Clouds and cloud shadows contaminate about 55\% of the optical remote sensing
observations, posing additional challenges. To address these challenges, we
present SatFlow, a generative model-based framework that fuses low-resolution
MODIS imagery and Landsat observations to produce frequent, high-resolution,
gap-free surface reflectance imagery. Our model, trained via Conditional Flow
Matching, demonstrates better performance in generating imagery with preserved
structural and spectral integrity. Cloud imputation is treated as an image
inpainting task, where the model reconstructs cloud-contaminated pixels and
fills gaps caused by scan lines during inference by leveraging the learned
generative processes. Experimental results demonstrate the capability of our
approach in reliably imputing cloud-covered regions. This capability is crucial
for downstream applications such as crop phenology tracking, environmental
change detection etc.,",http://arxiv.org/abs/2502.01098v1
GTG: Generalizable Trajectory Generation Model for Urban Mobility,2025-02-03T06:53:35Z,"Jingyuan Wang, Yujing Lin, Yudong Li","Trajectory data mining is crucial for smart city management. However,
collecting large-scale trajectory datasets is challenging due to factors such
as commercial conflicts and privacy regulations. Therefore, we urgently need
trajectory generation techniques to address this issue. Existing trajectory
generation methods rely on the global road network structure of cities. When
the road network structure changes, these methods are often not transferable to
other cities. In fact, there exist invariant mobility patterns between
different cities: 1) People prefer paths with the minimal travel cost; 2) The
travel cost of roads has an invariant relationship with the topological
features of the road network. Based on the above insight, this paper proposes a
Generalizable Trajectory Generation model (GTG). The model consists of three
parts: 1) Extracting city-invariant road representation based on Space Syntax
method; 2) Cross-city travel cost prediction through disentangled adversarial
training; 3) Travel preference learning by shortest path search and preference
update. By learning invariant movement patterns, the model is capable of
generating trajectories in new cities. Experiments on three datasets
demonstrates that our model significantly outperforms existing models in terms
of generalization ability.",http://arxiv.org/abs/2502.01107v1
Dense and magnetized QCD from imaginary chemical potential,2025-02-03T07:57:44Z,"Szabolcs Borsányi, Bastian Brandt, Gergely Endrődi, Jana Guenther, Marc-André Petri, Adeilton Dean Marques Valois, Lukas Varnhorst","In this work, we computed the equation of state of dense QCD in the presence
of background magnetic fields using lattice QCD simulations at imaginary baryon
chemical potential. Our simulations include 2+1+1 flavors of stout-smeared
staggered fermions with masses at the physical point and a tree-level
Symanzik-improved gauge action. Using several expansion schemes, we tuned our
simulation parameters such that the equation of state satisfies strangeness
neutrality and isospin asymmetry constraints, which are relevant to the
phenomenology of heavy-ion collisions. Our results suggest a strong change in
the equation of state due to the magnetic field, in particular, around the
crossover temperature. A continuum extrapolation of our data is still needed
for future applications of our equation of state to heavy-ion-collision
phenomenology.",http://arxiv.org/abs/2502.01132v2
"Efficient and Scalable Density Functional Theory Hamiltonian Prediction
  through Adaptive Sparsity",2025-02-03T09:04:47Z,"Erpai Luo, Xinran Wei, Lin Huang, Yunyang Li, Han Yang, Zun Wang, Chang Liu, Zaishuo Xia, Jia Zhang, Bin Shao","Hamiltonian matrix prediction is pivotal in computational chemistry, serving
as the foundation for determining a wide range of molecular properties. While
SE(3) equivariant graph neural networks have achieved remarkable success in
this domain, their substantial computational cost-driven by high-order tensor
product (TP) operations-restricts their scalability to large molecular systems
with extensive basis sets. To address this challenge, we introduce SPHNet, an
efficient and scalable equivariant network that incorporates adaptive sparsity
into Hamiltonian prediction. SPHNet employs two innovative sparse gates to
selectively constrain non-critical interaction combinations, significantly
reducing tensor product computations while maintaining accuracy. To optimize
the sparse representation, we develop a Three-phase Sparsity Scheduler,
ensuring stable convergence and achieving high performance at sparsity rates of
up to 70 percent. Extensive evaluations on QH9 and PubchemQH datasets
demonstrate that SPHNet achieves state-of-the-art accuracy while providing up
to a 7x speedup over existing models. Beyond Hamiltonian prediction, the
proposed sparsification techniques also hold significant potential for
improving the efficiency and scalability of other SE(3) equivariant networks,
further broadening their applicability and impact.",http://arxiv.org/abs/2502.01171v1
"DRL-based Dolph-Tschebyscheff Beamforming in Downlink Transmission for
  Mobile Users",2025-02-03T11:50:43Z,"Nancy Nayak, Kin K. Leung, Lajos Hanzo","With the emergence of AI technologies in next-generation communication
systems, machine learning plays a pivotal role due to its ability to address
high-dimensional, non-stationary optimization problems within dynamic
environments while maintaining computational efficiency. One such application
is directional beamforming, achieved through learning-based blind beamforming
techniques that utilize already existing radio frequency (RF) fingerprints of
the user equipment obtained from the base stations and eliminate the need for
additional hardware or channel and angle estimations. However, as the number of
users and antenna dimensions increase, thereby expanding the problem's
complexity, the learning process becomes increasingly challenging, and the
performance of the learning-based method cannot match that of the optimal
solution. In such a scenario, we propose a deep reinforcement learning-based
blind beamforming technique using a learnable Dolph-Tschebyscheff antenna array
that can change its beam pattern to accommodate mobile users. Our simulation
results show that the proposed method can support data rates very close to the
best possible values.",http://arxiv.org/abs/2502.01278v1
"Improving the Effectiveness of Potential-Based Reward Shaping in
  Reinforcement Learning",2025-02-03T12:32:50Z,"Henrik Müller, Daniel Kudenko","Potential-based reward shaping is commonly used to incorporate prior
knowledge of how to solve the task into reinforcement learning because it can
formally guarantee policy invariance. As such, the optimal policy and the
ordering of policies by their returns are not altered by potential-based reward
shaping. In this work, we highlight the dependence of effective potential-based
reward shaping on the initial Q-values and external rewards, which determine
the agent's ability to exploit the shaping rewards to guide its exploration and
achieve increased sample efficiency. We formally derive how a simple linear
shift of the potential function can be used to improve the effectiveness of
reward shaping without changing the encoded preferences in the potential
function, and without having to adjust the initial Q-values, which can be
challenging and undesirable in deep reinforcement learning. We show the
theoretical limitations of continuous potential functions for correctly
assigning positive and negative reward shaping values. We verify our
theoretical findings empirically on Gridworld domains with sparse and
uninformative reward functions, as well as on the Cart Pole and Mountain Car
environments, where we demonstrate the application of our results in deep
reinforcement learning.",http://arxiv.org/abs/2502.01307v1
"Quantum Geometric Origin of Strain-Induced Ferroelectric Phase
  Transitions",2025-02-03T15:53:28Z,"Jiaming Hu, Ziye Zhu, Yubo Yuan, Wenbin Li, Hua Wang, Kai Chang","Strain-regulated ferroelectric (FE) materials have long attracted significant
attention due to their diverse applications. While soft-phonon theory and the
(pseudo) Jahn-Teller effect have achieved considerable success in providing
phenomenological descriptions and general understanding, the detailed
connection between these perspectives and their microscopic dependence on
strain regulation remains unclear. Here, under the framework of
density-functional perturbation theory (DFPT), we demonstrate that the Berry
curvature of electron-phonon coupling (EPC) plays a pivotal role in the
interatomic force matrix (IFM). A subsequent model analysis shows that external
strain can reverse the polarity of the EPC Berry curvature in
(quasi)-degenerate electronic subsystems through band inversion, thereby
directly leading to phonon softening. The general theory is then applied to the
BiOCl monolayer as a benchmark, which offers an accurate description of the
density functional theory (DFT) calculations. This mechanism is further
observed across a broad range of materials through ab initio calculations,
providing an insightful perspective on EPC quantum geometry in lattice dynamics
and FE phase transitions.",http://arxiv.org/abs/2502.01463v2
Off-shell phase diagram of BPS black holes in AdS$_5$,2025-02-03T16:53:06Z,"Debabrata Sahu, Chandrasekhar Bhamidipati","We construct the off-shell free energy of supersymmetric black holes in
AdS$_5$, and study the phase diagram in various limiting cases, with particular
emphasis on BPS thermodynamics. The changes to the free energy following from
the four-derivative corrections to five-dimensional minimal gauged supergravity
action are computed, and the modifications to the phase diagram are studied.
Starting from Landau's theory, an exact method is systematically developed to
construct the off shell BPS free energy, which in certain limiting cases, can
be rearranged in terms of an effective energy and entropy of the system, with
the later being conjugate to an effective BPS temperature. The off-shell BPS
phase diagram shows features which resemble the phases of general AdS
Schwarzschild black holes, with some nuances in the asymptotic structure,
modified by four-derivative corrections. Using AdS/CFT, phenomenological
effective potentials in the boundary gauge theory are proposed, dual to both
general black holes and their BPS counterparts. The saddle points of the
effective potential capture the various locally stable and unstable phases of
the gauge theory at finite temperature and chemical potential.",http://arxiv.org/abs/2502.01519v1
"Self-Improving Transformers Overcome Easy-to-Hard and Length
  Generalization Challenges",2025-02-03T18:45:22Z,"Nayoung Lee, Ziyang Cai, Avi Schwarzschild, Kangwook Lee, Dimitris Papailiopoulos","Large language models often struggle with length generalization and solving
complex problem instances beyond their training distribution. We present a
self-improvement approach where models iteratively generate and learn from
their own solutions, progressively tackling harder problems while maintaining a
standard transformer architecture. Across diverse tasks including arithmetic,
string manipulation, and maze solving, self-improving enables models to solve
problems far beyond their initial training distribution-for instance,
generalizing from 10-digit to 100-digit addition without apparent saturation.
We observe that in some cases filtering for correct self-generated examples
leads to exponential improvements in out-of-distribution performance across
training rounds. Additionally, starting from pretrained models significantly
accelerates this self-improvement process for several tasks. Our results
demonstrate how controlled weak-to-strong curricula can systematically teach a
model logical extrapolation without any changes to the positional embeddings,
or the model architecture.",http://arxiv.org/abs/2502.01612v2
AI Scaling: From Up to Down and Out,2025-02-02T02:14:00Z,"Yunke Wang, Yanxi Li, Chang Xu","AI Scaling has traditionally been synonymous with Scaling Up, which builds
larger and more powerful models. However, the growing demand for efficiency,
adaptability, and collaboration across diverse applications necessitates a
broader perspective. This position paper presents a holistic framework for AI
scaling, encompassing Scaling Up, Scaling Down, and Scaling Out. It argues that
while Scaling Up of models faces inherent bottlenecks, the future trajectory of
AI scaling lies in Scaling Down and Scaling Out. These paradigms address
critical technical and societal challenges, such as reducing carbon footprint,
ensuring equitable access, and enhancing cross-domain collaboration. We explore
transformative applications in healthcare, smart manufacturing, and content
creation, demonstrating how AI Scaling can enable breakthroughs in efficiency,
personalization, and global connectivity. Additionally, we highlight key
challenges, including balancing model complexity with interpretability,
managing resource constraints, and fostering ethical development. By
synthesizing these approaches, we propose a unified roadmap that redefines the
future of AI research and application, paving the way for advancements toward
Artificial General Intelligence (AGI).",http://arxiv.org/abs/2502.01677v1
On Bob Dylan: A Computational Perspective,2025-02-03T19:25:08Z,Prashant Garg,"Cass Sunstein's essay 'On Bob Dylan' describes Dylan's 'dishabituating' style
-- a constant refusal to conform to expectation and a penchant for reinventing
his musical and lyrical identity. In this paper, I extend Sunstein's
observations through a large-scale computational analysis of Dylan's lyrics
from 1962 to 2012. Using o3-mini-high (a large language model), I extract
concept-to-concept relationships from the lyrics and construct directed
knowledge graphs that capture Dylan's thematic structure. I then quantify
shifts in sentiment, metaphorical expression, thematic diversity, and network
complexity over time. The results indicate that Dylan's lyrics increasingly
rely on metaphor, display an evolving sentiment profile, and exhibit heightened
dishabituation -- measured here as a growing variance in the network centrality
of key concepts. I also find that references to movement, protest, and mythic
imagery fluctuate in ways that align with well-known phases of Dylan's career,
reflecting the dynamic and unpredictable quality of his art. These findings not
only deepen our empirical understanding of Sunstein's thesis but also introduce
a novel computational method for analyzing an artist's evolution-offering
broader applicability to the study of cultural and creative change.",http://arxiv.org/abs/2502.01772v1
Geometric Framework for 3D Cell Segmentation Correction,2025-02-03T23:47:45Z,"Peter Chen, Bryan Chang, Olivia Annette Creasey, Julie Beth Sneddon, Yining Liu","3D cellular image segmentation methods are commonly divided into non-2D-based
and 2D-based approaches, the latter reconstructing 3D shapes from the
segmentation results of 2D layers. However, errors in 2D results often
propagate, leading to oversegmentations in the final 3D results. To tackle this
issue, we introduce an interpretable geometric framework that addresses the
oversegmentations by correcting the 2D segmentation results based on geometric
information from adjacent layers. Leveraging both geometric (layer-to-layer,
2D) and topological (3D shape) features, we use binary classification to
determine whether neighboring cells should be stitched. We develop a
pre-trained classifier on public plant cell datasets and validate its
performance on animal cell datasets, confirming its effectiveness in correcting
oversegmentations under the transfer learning setting. Furthermore, we
demonstrate that our framework can be extended to correcting oversegmentation
on non-2D-based methods. A clear pipeline is provided for end-users to build
the pre-trained model to any labeled dataset.",http://arxiv.org/abs/2502.01890v1
"Generalizable and Fast Surrogates: Model Predictive Control of
  Articulated Soft Robots using Physics-Informed Neural Networks",2025-02-04T01:16:33Z,"Tim-Lukas Habich, Aran Mohammad, Simon F. G. Ehlers, Martin Bensch, Thomas Seel, Moritz Schappler","Soft robots can revolutionize several applications with high demands on
dexterity and safety. When operating these systems, real-time estimation and
control require fast and accurate models. However, prediction with
first-principles (FP) models is slow, and learned black-box models have poor
generalizability. Physics-informed machine learning offers excellent advantages
here, but it is currently limited to simple, often simulated systems without
considering changes after training. We propose physics-informed neural networks
(PINNs) for articulated soft robots (ASRs) with a focus on data efficiency. The
amount of expensive real-world training data is reduced to a minimum - one
dataset in one system domain. Two hours of data in different domains are used
for a comparison against two gold-standard approaches: In contrast to a
recurrent neural network, the PINN provides a high generalizability. The
prediction speed of an accurate FP model is improved with the PINN by up to a
factor of 466 at slightly reduced accuracy. This enables nonlinear model
predictive control (MPC) of the pneumatic ASR. In nine dynamic MPC experiments,
an average joint-tracking error of 1.3{\deg} is achieved.",http://arxiv.org/abs/2502.01916v1
"Improving Software Engineering Team Communication Through Stronger
  Social Networks",2025-02-04T01:46:26Z,"April Clarke, Tanja Mitrović, Fabian Gilson","Students working in teams in software engineering group project often
communicate ineffectively, which reduces the quality of deliverables, and is
therefore detrimental for project success. An important step towards addressing
areas of improvement is identifying which changes to communication will improve
team performance the most. We applied two different communication analysis
techniques, triad census and socio-technical congruence, to data gathered from
a two-semester software engineering group project. Triad census uses the
presence of edges between groups of three nodes as a measure of network
structure, while socio-technical congruence compares the fit of a team's
communication to their technical dependencies. Our findings suggest that each
team's triad census for a given sprint is promising as a predictor of the
percentage of story points they pass, which is closely linked to project
success. Meanwhile, socio-technical congruence is inadequate as the sole metric
for predicting project success in this context. We discuss these findings, and
their potential applications improve communication in a software engineering
group project.",http://arxiv.org/abs/2502.01923v1
"Mitigating Object Hallucinations in Large Vision-Language Models via
  Attention Calibration",2025-02-04T03:27:38Z,"Younan Zhu, Linwei Tao, Minjing Dong, Chang Xu","Large Vision-Language Models (LVLMs) exhibit impressive multimodal reasoning
capabilities but remain highly susceptible to object hallucination, where
models generate responses that are not factually aligned with the visual
content. Recent works attribute this issue to an inherent bias of LVLMs where
vision token attention map has a fixed correlation with spatial position, and
propose to mitigate this issue by reordering visual tokens. However, we find
that different LVLMs exhibit different correlations between attention and
spatial position, which makes the existing solution difficult to generalize to
other LVLMs. To address this issue, we first introduce a training-free
solution, Uniform Attention Calibration (UAC), that estimates the bias from
single meaningless input image and applies a calibration matrix to rectify
attention imbalances. To further alleviate the bias, we relax the assumption of
single meaningless input in UAC and introduce a fine-tuning solution, Dynamic
Attention Calibration (DAC), that enforces the consistent outputs wherever the
object locates in the image via a plug-and-plays module. Comprehensive
experiments across multiple benchmarks demonstrate that UAC and DAC
significantly reduce object hallucination while improving general multimodal
alignment. Our methods achieve state-of-the-art performance across diverse LVLM
architectures on various metrics.",http://arxiv.org/abs/2502.01969v1
"Normalized solutions to focusing Sobolev critical biharmonic
  Schrödinger equation with mixed dispersion",2025-02-04T06:30:43Z,"Jianlun Liu, Hong-Rui Sun, Ziheng Zhang","This paper is concerned with the following focusing biharmonic
Schr\""{o}dinger equation with mixed dispersion and Sobolev critical growth: $$
\begin{cases}
  {\Delta}^2u-\Delta u-\lambda u-\mu|u|^{p-2}u-|u|^{4^*-2}u=0\ \ \mbox{in}\
\mathbb{R}^N, \\[0.1cm]
  \int_{\mathbb{R}^N} u^2 dx = c, \end{cases} $$ where $N \geq 5$, $\mu,c>0$,
$2<p<4^*:=\frac{2N}{N-4}$ and $\lambda \in \mathbb{R}$ is a Lagrange
multiplier. For this problem, under the $L^2$-subcritical perturbation
($2<p<2+\frac{8}{N}$), we derive the existence and multiplicity of normalized
solutions via the truncation technique, concentration-compactness principle and
the genus theory presented by C.O. Alves et al. (Arxiv, (2021), doi:
2103.07940v2). Compared to the results of C.O. Alves et al. we obtain a more
general result after removing the further assumptions given in (3.2) of their
paper. In the case of $L^2$-supercritical perturbation ($2+\frac{8}{N}<p<4^*$),
we explore the existence results of normalized solutions by applying the
constrained variational methods and the mountain pass theorem. Moreover, we
propose a novel method to address the effects of the dispersion term $\Delta
u$. This approach allows us to extend the recent results obtained by X. Chang
et al. (Arxiv, (2023), doi: 2305.00327v1) to the mixed dispersion situation.",http://arxiv.org/abs/2502.02049v1
On Squared-Variable Formulations for Nonlinear Semidefinite programming,2025-02-04T08:30:34Z,"Lijun Ding, Stephen J. Wright","In optimization problems involving smooth functions and real and matrix
variables, that contain matrix semidefiniteness constraints, consider the
following change of variables: Replace the positive semidefinite matrix $X \in
\mathbb{S}^d$, where $\mathbb{S}^d$ is the set of symmetric matrices in
$\mathbb{R}^{d\times d}$, by a matrix product $FF^\top$, where $F \in
\mathbb{R}^{d \times d}$ or $F \in \mathbb{S}^d$. The formulation obtained in
this way is termed ``squared variable,"" by analogy with a similar idea that has
been proposed for real (scalar) variables. It is well known that points
satisfying first-order conditions for the squared-variable reformulation do not
necessarily yield first-order points for the original problem. There are closer
correspondences between second-order points for the squared-variable
reformulation and the original formulation. These are explored in this paper,
along with correspondences between local minimizers of the two formulations.",http://arxiv.org/abs/2502.02099v1
"Molecular Pseudorotation in Phthalocyanines as a Tool for Magnetic Field
  Control at the Nanoscale",2025-02-04T09:44:18Z,"Raphael Wilhelmer, Matthias Diez, Johannes K. Krondorfer, Andreas W. Hauser","Metal phthalocyanines, a highly versatile class of aromatic, planar,
macrocyclic molecules with a chelated central metal ion, are topical objects of
ongoing research and particularly interesting due to their magnetic properties.
However, while current focus lies almost exclusively on spin-Zeeman-related
effects, the high symmetry of the molecule and its circular shape suggests the
exploitation of light-induced excitation of twofold degenerate vibrational
states in order to generate, switch and manipulate magnetic fields at the
nanoscale. The underlying mechanism is a molecular pseudorotation that can be
triggered by infrared pulses and gives rise to a quantized, small but
controllable magnetic dipole moment. We investigate the optical stimulation of
vibrationally-induced molecular magnetism and estimate changes in the magnetic
shielding constants for confirmation by future experiments.",http://arxiv.org/abs/2502.02169v1
Mask-informed Deep Contrastive Incomplete Multi-view Clustering,2025-02-04T11:23:48Z,"Zhenglai Li, Yuqi Shi, Xiao He, Chang Tang","Multi-view clustering (MvC) utilizes information from multiple views to
uncover the underlying structures of data. Despite significant advancements in
MvC, mitigating the impact of missing samples in specific views on the
integration of knowledge from different views remains a critical challenge.
This paper proposes a novel Mask-informed Deep Contrastive Incomplete
Multi-view Clustering (Mask-IMvC) method, which elegantly identifies a
view-common representation for clustering. Specifically, we introduce a
mask-informed fusion network that aggregates incomplete multi-view information
while considering the observation status of samples across various views as a
mask, thereby reducing the adverse effects of missing values. Additionally, we
design a prior knowledge-assisted contrastive learning loss that boosts the
representation capability of the aggregated view-common representation by
injecting neighborhood information of samples from different views. Finally,
extensive experiments are conducted to demonstrate the superiority of the
proposed Mask-IMvC method over state-of-the-art approaches across multiple MvC
datasets, both in complete and incomplete scenarios.",http://arxiv.org/abs/2502.02234v1
"Asymptotic solution for three-dimensional reaction-diffusion-advection
  equation with periodic boundary conditions",2025-02-04T12:22:13Z,"Aleksei Liubavin, Mingkang Ni, Ye Zhang, Dmitrii Chaikovskii","In this study, we investigate the dynamics of moving fronts in
three-dimensional spaces, which form as a result of in-situ combustion during
oil production. This phenomenon is also observed in other contexts, such as
various autowave models and the propagation of acoustic waves. Our analysis
involves a singularly perturbed reaction-diffusion-advection type
initial-boundary value problem of a general form. We employ methods from
asymptotic theory to develop an approximate smooth solution with an internal
layer. Using local coordinates, we focus on the transition layer, where the
solution undergoes rapid changes. Once the location of the transition layer is
established, we can describe the solution across the full domain of the
problem. Numerical examples are provided, demonstrating the high accuracy of
the asymptotic method in predicting the behaviors of moving fronts.",http://arxiv.org/abs/2502.02263v1
"Mirai: A Wearable Proactive AI ""Inner-Voice"" for Contextual Nudging",2025-02-04T14:51:29Z,"Cathy Mengying Fang, Yasith Samaradivakara, Pattie Maes, Suranga Nanayakkara","People often find it difficult to turn their intentions into real actions --
a challenge that affects both personal growth and mental well-being. While
established methods like cognitive-behavioral therapy and mindfulness training
help people become more aware of their behaviors and set clear goals, these
approaches cannot provide immediate guidance when people fall into automatic
reactions or habits. We introduce Mirai, a novel wearable AI system with an
integrated camera, real-time speech processing, and personalized voice-cloning
to provide proactive and contextual nudges for positive behavior change. Mirai
continuously monitors and analyzes the user's environment to anticipate their
intentions, generating contextually-appropriate responses delivered in the
user's own cloned voice. We demonstrate the application of Mirai through three
scenarios focusing on dietary choices, work productivity, and communication
skills. We also discuss future work on improving the proactive agent via human
feedback and the need for a longitudinal study in naturalistic settings.",http://arxiv.org/abs/2502.02370v1
"Achieving Hiding and Smart Anti-Jamming Communication: A Parallel DRL
  Approach against Moving Reactive Jammer",2025-02-04T15:03:11Z,"Yangyang Li, Yuhua Xu, Wen Li, Guoxin Li, Zhibing Feng, Songyi Liu, Jiatao Du, Xinran Li","This paper addresses the challenge of anti-jamming in moving reactive jamming
scenarios. The moving reactive jammer initiates high-power tracking jamming
upon detecting any transmission activity, and when unable to detect a signal,
resorts to indiscriminate jamming. This presents dual imperatives: maintaining
hiding to avoid the jammer's detection and simultaneously evading
indiscriminate jamming. Spread spectrum techniques effectively reduce
transmitting power to elude detection but fall short in countering
indiscriminate jamming. Conversely, changing communication frequencies can help
evade indiscriminate jamming but makes the transmission vulnerable to tracking
jamming without spread spectrum techniques to remain hidden. Current
methodologies struggle with the complexity of simultaneously optimizing these
two requirements due to the expansive joint action spaces and the dynamics of
moving reactive jammers. To address these challenges, we propose a parallelized
deep reinforcement learning (DRL) strategy. The approach includes a
parallelized network architecture designed to decompose the action space. A
parallel exploration-exploitation selection mechanism replaces the $\varepsilon
$-greedy mechanism, accelerating convergence. Simulations demonstrate a nearly
90\% increase in normalized throughput.",http://arxiv.org/abs/2502.02385v1
"Constraints on minimally and conformally coupled ultralight dark matter
  with the EPTA",2025-02-04T15:41:55Z,Clemente Smarra,"Millisecond pulsars are extremely stable natural timekeepers. Pulsar Timing
Array experiments, tracking subtle changes in the pulsars' rotation periods,
can shed light on the presence of ultralight particles in our Galaxy. In this
conference paper, we start by reviewing the most conservative scenario, in
which ultralight particles interact only gravitationally. In this setting, we
show that Pulsar Timing Arrays are able to constrain the presence of ultralight
fields up to a few tenths of the observed dark matter abundance. Then, we
consider conformally coupled ultralight candidates, demonstrating that the
constraints on the universal scalar coupling of the field to Standard Model
particles improve on existing bounds by several orders of magnitude, in the
relevant mass range analyzed by Pulsar Timing Arrays. The discussion presented
here is based on [1,2].",http://arxiv.org/abs/2502.02420v1
"Distribution Transformers: Fast Approximate Bayesian Inference With
  On-The-Fly Prior Adaptation",2025-02-04T16:33:12Z,"George Whittle, Juliusz Ziomek, Jacob Rawling, Michael A Osborne","While Bayesian inference provides a principled framework for reasoning under
uncertainty, its widespread adoption is limited by the intractability of exact
posterior computation, necessitating the use of approximate inference. However,
existing methods are often computationally expensive, or demand costly
retraining when priors change, limiting their utility, particularly in
sequential inference problems such as real-time sensor fusion. To address these
challenges, we introduce the Distribution Transformer -- a novel architecture
that can learn arbitrary distribution-to-distribution mappings. Our method can
be trained to map a prior to the corresponding posterior, conditioned on some
dataset -- thus performing approximate Bayesian inference. Our novel
architecture represents a prior distribution as a (universally-approximating)
Gaussian Mixture Model (GMM), and transforms it into a GMM representation of
the posterior. The components of the GMM attend to each other via
self-attention, and to the datapoints via cross-attention. We demonstrate that
Distribution Transformers both maintain flexibility to vary the prior, and
significantly reduces computation times-from minutes to milliseconds-while
achieving log-likelihood performance on par with or superior to existing
approximate inference methods across tasks such as sequential inference,
quantum system parameter inference, and Gaussian Process predictive posterior
inference with hyperpriors.",http://arxiv.org/abs/2502.02463v1
"The $CP$ violations and branching ratios for $B_c^+\to
  D_{(s)}^+π^+π^-(K^{+}K^{-})$ from interference of the vector mesons in
  Perturbative QCD",2025-02-05T00:54:47Z,"Kun Shuai Ye, Gang Lü, Na-Wang, Jian Chai, Xin-Heng Guo","Within the framework of the perturbative QCD approach utilizing $K_T$
factorization, we have investigated the CP violations and branching ratios in
the decay processes of $B_{c}^{+}\to D_{(s)} ^{+}V(V\rightarrow\pi^{+}\pi^{-})$
and $B_{c}^{+}\to D_{(s)}^{+}V(V\rightarrow K^{+}K^{-})$, where V denotes three
vector mesons $\rho^0$, $\omega$, and $\phi$. During the $V\to \pi^+\pi^-$ and
$V\to K^+K^-$ decay processes, we incorporated the $\rho^{0}-\omega-\phi$
mixing mechanism to describe the amplitudes of these quasi-two-body decay
processes. Within the interference regime of the three vector particles, we
observed distinct changes in both CP violations and branching ratios.
Furthermore, our study presents evidence for local CP violations and branching
ratios that warrants further investigation through experiments.",http://arxiv.org/abs/2502.02800v1
"Consistent Client Simulation for Motivational Interviewing-based
  Counseling",2025-02-05T00:58:30Z,"Yizhe Yang, Palakorn Achananuparp, Heyan Huang, Jing Jiang, John Pinto, Jenny Giam, Kit Phey Leng, Nicholas Gabriel Lim, Cameron Tan Shi Ern, Ee-peng Lim","Simulating human clients in mental health counseling is crucial for training
and evaluating counselors (both human or simulated) in a scalable manner.
Nevertheless, past research on client simulation did not focus on complex
conversation tasks such as mental health counseling. In these tasks, the
challenge is to ensure that the client's actions (i.e., interactions with the
counselor) are consistent with with its stipulated profiles and negative
behavior settings. In this paper, we propose a novel framework that supports
consistent client simulation for mental health counseling. Our framework tracks
the mental state of a simulated client, controls its state transitions, and
generates for each state behaviors consistent with the client's motivation,
beliefs, preferred plan to change, and receptivity. By varying the client
profile and receptivity, we demonstrate that consistent simulated clients for
different counseling scenarios can be effectively created. Both our automatic
and expert evaluations on the generated counseling sessions also show that our
client simulation method achieves higher consistency than previous methods.",http://arxiv.org/abs/2502.02802v1
"LHIEM: the Longitudinal Health, Income, and Employment Model",2025-02-05T01:18:45Z,"Adrienne M. Propp, Raffaele Vardavas, Carter C. Price, Kandice A. Kapinos","Dynamic microsimulation has long been recognized as a powerful tool for
policy analysis, but in fact most major health policy simulations lack path
dependency, a critical feature for evaluating policies that depend on
accumulated outcomes such as retirement savings, wealth, or debt. We propose
LHIEM (the Longitudinal Health, Income and Employment Model), a path-dependent
discrete-time microsimulation that predicts annual health care expenditures,
family income, and health status for the U.S. population over a multi-year
period. LHIEM advances the population from year to year as a Markov chain with
modules capturing the particular dynamics of each predictive attribute. LHIEM
was designed to assess a health care financing proposal that would allow
individuals to borrow from the U.S. government to cover health care costs,
requiring careful tracking of medical expenditures and medical debt over time.
However, LHIEM is flexible enough to be used for a range of modeling needs
related to predicting health care spending and income over time. In this paper,
we present the details of the model and all dynamic modules, and include a case
study to demonstrate how LHIEM can be used to evaluate proposed policy changes.",http://arxiv.org/abs/2502.02812v1
Position: Editing Large Language Models Poses Serious Safety Risks,2025-02-05T07:51:32Z,"Paul Youssef, Zhixue Zhao, Daniel Braun, Jörg Schlötterer, Christin Seifert","Large Language Models (LLMs) contain large amounts of facts about the world.
These facts can become outdated over time, which has led to the development of
knowledge editing methods (KEs) that can change specific facts in LLMs with
limited side effects. This position paper argues that editing LLMs poses
serious safety risks that have been largely overlooked. First, we note the fact
that KEs are widely available, computationally inexpensive, highly performant,
and stealthy makes them an attractive tool for malicious actors. Second, we
discuss malicious use cases of KEs, showing how KEs can be easily adapted for a
variety of malicious purposes. Third, we highlight vulnerabilities in the AI
ecosystem that allow unrestricted uploading and downloading of updated models
without verification. Fourth, we argue that a lack of social and institutional
awareness exacerbates this risk, and discuss the implications for different
stakeholders. We call on the community to (i) research tamper-resistant models
and countermeasures against malicious model editing, and (ii) actively engage
in securing the AI ecosystem.",http://arxiv.org/abs/2502.02958v1
"Higgs boson precision analysis of two Higgs doublet models: Full LHC Run
  1 and Run 2 data",2025-02-05T08:42:03Z,"Yongtae Heo, Jae Sik Lee, Chan Beom Park","We present the results obtained by performing global fits of
two-Higgs-doublet models (2HDMs) using the full Run 1 and Run 2 Higgs datasets
collected at the LHC. Avoiding unwanted tree-level flavor-changing neutral
currents and including the wrong-sign cases, we consider 12 scenarios across
six types of 2HDMs: Inert, type I, type II, type III, type IV, and Aligned
2HDMs. Our main results are presented in Table 3 and Fig. 1. We find that the
type-I 2HDM provides the best fit, while the wrong-sign scenarios of the
type-II and type-IV 2HDMs, where the normalized Yukawa coupling to down-type
quarks is opposite in sign to the Standard Model (SM), are disfavored. We also
observe that the Aligned 2HDM gives the second-best fit when the Yukawa
couplings to down-type quarks take the same sign as in the SM, regardless of
the sign of the Yukawa couplings to the charged leptons.",http://arxiv.org/abs/2502.02992v1
Conformal Uncertainty Indicator for Continual Test-Time Adaptation,2025-02-05T08:47:18Z,"Fan Lyu, Hanyu Zhao, Ziqi Shi, Ye Liu, Fuyuan Hu, Zhang Zhang, Liang Wang","Continual Test-Time Adaptation (CTTA) aims to adapt models to sequentially
changing domains during testing, relying on pseudo-labels for self-adaptation.
However, incorrect pseudo-labels can accumulate, leading to performance
degradation. To address this, we propose a Conformal Uncertainty Indicator
(CUI) for CTTA, leveraging Conformal Prediction (CP) to generate prediction
sets that include the true label with a specified coverage probability. Since
domain shifts can lower the coverage than expected, making CP unreliable, we
dynamically compensate for the coverage by measuring both domain and data
differences. Reliable pseudo-labels from CP are then selectively utilized to
enhance adaptation. Experiments confirm that CUI effectively estimates
uncertainty and improves adaptation performance across various existing CTTA
methods.",http://arxiv.org/abs/2502.02998v1
"The NRQCD $Υ$ spectrum at non-zero temperature using
  Backus-Gilbert regularisations",2025-02-05T10:45:17Z,"Antonio Smecca, Gert Aarts, Chris Allton, Ryan Bignell, Timothy J. Burns, Benjamin Jäger, Rachel Horohan D'Arcy, Seyong Kim, Maria-Paola Lombardo, Ben Page, Sinéad M. Ryan, Tom Spriggs, Jon-Ivar Skullerud","Understanding how the properties of heavy mesons change as temperature
increases is crucial for gaining valuable insights into the quark-gluon plasma.
Information about meson masses and decay widths is encoded in the meson
spectral function, which, in principle, can be extracted from Euclidean
correlation functions via generalised Laplace transformations. However, this
inverse problem is ill-posed for lattice correlation functions and requires
regularisation. In this work, we present the latest results for bottomonium
spectral functions obtained within the lattice NRQCD framework using the
Backus-Gilbert regularisation, along with two other variants, one of which is
commonly referred to as the HLT method. Our analysis employs Generation 2L
anisotropic lattice configurations produced by the \textsc{Fastsum}
collaboration.",http://arxiv.org/abs/2502.03060v1
"A Robust Machine Learned Interatomic Potential for Nb: Collision Cascade
  Simulations with accurate Defect Configurations",2025-02-05T12:32:11Z,"Utkarsh Bhardwaj, Vinayak Mishra, Suman Mondal, Manoj Warrier","Niobium (Nb) and its alloys are extensively used in various technological
applications owing to their favorable mechanical, thermal and irradiation
properties. Accurately modeling Nb under irradiation is essential for
predicting microstructural changes, defect evolution, and overall material
performance. Traditional interatomic potentials for Nb fail to predict the
correct self-interstitial atom (SIA) configuration, a critical factor in
radiation damage simulations. We develop a machine learning interatomic
potential (MLIP) using the Spectral Neighbor Analysis Potential (SNAP)
framework, trained on ab-initio Density Functional Theory (DFT) calculations,
which accurately captures the relative stability of different SIA dumbbell
configurations. The resulting potential reproduces DFT-level accuracy while
maintaining computational efficiency for large-scale Molecular Dynamics (MD)
simulations. Through a series of validation tests involving elastic, thermal,
and defect properties -- including collision cascade simulations -- we show
that our SNAP potential resolves persistent limitations in existing Embedded
Atom Method (EAM) and Finnis--Sinclair (FS) potentials and is effective for MD
simulations of collision cascades. Notably, it accurately captures the
ground-state SIA configuration of Nb in the primary damage of a collision
cascade, offering a robust tool for predictive irradiation studies.",http://arxiv.org/abs/2502.03126v1
"Detection of the Extended $γ$-ray Emission around TeV source
  1LHAASO J0249+6022 with Fermi-LAT",2025-02-05T12:59:30Z,"Gong Yunlu, Zhou Liancheng, Xia Qi, Chang Shan, Fang Jun, Zhang Li","1LHAASO J0249+6022 is an extended very-high-energy gamma-ray source
discovered by the Large High-Altitude Air Shower Observatory. Based on nearly
16.1 years of data from the Fermi Large Area Telescope, we report the probable
gamma-ray emission from 1LHAASO J0249+6022 in the 0.03-1 TeV energy range. The
results show that its gamma-ray spectrum can be well fitted by a single power
law with an index of 1.54 $\pm$ 0.17, and integral photon flux is (4.28 $\pm$
1.03) $\times$ 10$^{-11}$ photons cm$^{-2}$ s$^{-1}$. We also considered
theoretically whether the non-thermal emission could originate from a pulsar
wind nebula (PWN) scenario. Assuming that the particles injected into the
nebula have a power-law distribution, the resulting spectrum from the inverse
Compton scattering is consistent with the detected GeV and TeV gamma-ray
fluxes. Our study shows that the PWN scenario is reasonable for 1LHAASO
J0249+6022.",http://arxiv.org/abs/2502.03138v1
"Easy-cone state mediating the spin reorientation in topological kagome
  magnet Fe$_3$Sn$_2$",2025-02-05T14:57:44Z,"L. Prodan, D. M. Evans, A. S. Sukhanov, S. E. Nikitin, A. A. Tsirlin, L. Puntingam, M. C. Rahn, L. Chioncel, V. Tsurkan, I. Kezsmarki","We investigated temperature-driven spin reorientation (SR) in the itinerant
kagome magnet Fe$_3$Sn$_2$ using high-resolution synchrotron x-ray diffraction,
neutron diffraction, magnetometry, and magnetic force microscopy (MFM), further
supported by phenomenological analysis. Our study reveals a crossover from the
state with easy-plane anisotropy to the high-temperature state with uniaxial
easy-axis anisotropy taking place between $\sim40-130$~ K through an
intermediate easy-cone (or tilted spin) state. This state, induced by the
interplay between the anisotropy constants $K_1$ and $K_2$, is clearly
manifested in the thermal evolution of the magnetic structure factor, which
reveals a gradual change of the SR angle $\mathbf{\theta}$ between $40-130$~K.
We also found that the SR is accompanied by a magnetoelastic effect. Zero-field
MFM images across the SR range show a transformation in surface magnetic
patterns from a dendritic structure at 120~K, to domain wall dominated MFM
contrast at 40~K.",http://arxiv.org/abs/2502.03239v1
"When Pre-trained Visual Representations Fall Short: Limitations in
  Visuo-Motor Robot Learning",2025-02-05T15:25:46Z,"Nikolaos Tsagkas, Andreas Sochopoulos, Duolikun Danier, Chris Xiaoxuan Lu, Oisin Mac Aodha","The integration of pre-trained visual representations (PVRs) into visuo-motor
robot learning has emerged as a promising alternative to training visual
encoders from scratch. However, PVRs face critical challenges in the context of
policy learning, including temporal entanglement and an inability to generalise
even in the presence of minor scene perturbations. These limitations hinder
performance in tasks requiring temporal awareness and robustness to scene
changes. This work identifies these shortcomings and proposes solutions to
address them. First, we augment PVR features with temporal perception and a
sense of task completion, effectively disentangling them in time. Second, we
introduce a module that learns to selectively attend to task-relevant local
features, enhancing robustness when evaluated on out-of-distribution scenes.
Our experiments demonstrate significant performance improvements, particularly
in PVRs trained with masking objectives, and validate the effectiveness of our
enhancements in addressing PVR-specific limitations.",http://arxiv.org/abs/2502.03270v1
Complementing an imperative process algebra with a rely/guarantee logic,2025-02-05T16:20:20Z,C. A. Middelburg,"This paper concerns the relation between imperative process algebra and
rely/guarantee logic. An imperative process algebra is complemented by a
rely/guarantee logic that can be used to reason about how data change in the
course of a process. The imperative process algebra used is the extension of
ACP (Algebra of Communicating Processes) that is used earlier in a paper about
the relation between imperative process algebra and Hoare logic. A
complementing rely/guarantee logic that concerns judgments of partial
correctness is treated in detail. The adaptation of this logic to weak and
strong total correctness is also addressed. A simple example is given that
suggests that a rely/guarantee logic is more suitable as a complementing logic
than a Hoare logic if interfering parallel processes are involved.",http://arxiv.org/abs/2502.03320v1
Statistical analysis of team formation and player roles in football,2025-02-05T16:36:39Z,Ali Baouan,"The availability of tracking data in football presents unique opportunities
for analyzing team shape and player roles, but leveraging it effectively
remains challenging. This difficulty arises from the significant overlap in
player positions, which complicates the identification of distinct roles and
team formations. In this work, we propose a novel model that incorporates a
hidden permutation matrix to simultaneously estimate team formations and assign
roles to players at the frame level. To address the cardinality of permutation
sets, we develop a statistical procedure to parsimoniously select relevant
matrices prior to parameter estimation. Additionally, to capture formation
changes during a match, we introduce a latent regime variable, enabling the
modeling of dynamic tactical adjustments. This framework disentangles player
locations from role-specific positions, providing a clear representation of
team structure. We demonstrate the applicability of our approach using player
tracking data, showcasing its potential for detailed team and player analysis.",http://arxiv.org/abs/2502.03342v1
Rethinking Approximate Gaussian Inference in Classification,2025-02-05T17:03:49Z,"Bálint Mucsányi, Nathaël Da Costa, Philipp Hennig","In classification tasks, softmax functions are ubiquitously used as output
activations to produce predictive probabilities. Such outputs only capture
aleatoric uncertainty. To capture epistemic uncertainty, approximate Gaussian
inference methods have been proposed, which output Gaussian distributions over
the logit space. Predictives are then obtained as the expectations of the
Gaussian distributions pushed forward through the softmax. However, such
softmax Gaussian integrals cannot be solved analytically, and Monte Carlo (MC)
approximations can be costly and noisy. We propose a simple change in the
learning objective which allows the exact computation of predictives and enjoys
improved training dynamics, with no runtime or memory overhead. This framework
is compatible with a family of output activation functions that includes the
softmax, as well as element-wise normCDF and sigmoid. Moreover, it allows for
approximating the Gaussian pushforwards with Dirichlet distributions by
analytic moment matching. We evaluate our approach combined with several
approximate Gaussian inference methods (Laplace, HET, SNGP) on large- and
small-scale datasets (ImageNet, CIFAR-10), demonstrating improved uncertainty
quantification capabilities compared to softmax MC sampling. Code is available
at https://github.com/bmucsanyi/probit.",http://arxiv.org/abs/2502.03366v1
Time scale competition in the Active Coagulation Model,2025-02-05T17:12:40Z,Matteo Paoluzzi,"Spreading processes on top of active dynamics provide a novel theoretical
framework for capturing emerging collective behavior in living systems. I
consider run-and-tumble dynamics coupled with coagulation/decoagulation
reactions that lead to an absorbing state phase transition. While the active
dynamics does not change the location of the transition point, the relaxation
toward the stationary state depends on motility parameters. Because of the
competition between spreading dynamics and active motion, the system can
support long-living currents whose typical time scale is a nontrivial function
of motility and reaction rates. Beyond the mean-field regime, instability at
finite length scales regulates a crossover from periodic to diffusive modes.
Finally, it is possible to individuate different mechanisms of pattern
formation on a large time scale, ranging from Fisher-Kolmogorov to
Kardar-Parisi-Zhang equation.",http://arxiv.org/abs/2502.03372v1
"Foundation for unbiased cross-validation of spatio-temporal models for
  species distribution modeling",2025-01-27T23:02:05Z,"Diana Koldasbayeva, Alexey Zaytsev","Species Distribution Models (SDMs) often suffer from spatial autocorrelation
(SAC), leading to biased performance estimates. We tested cross-validation (CV)
strategies - random splits, spatial blocking with varied distances,
environmental (ENV) clustering, and a novel spatio-temporal method - under two
proposed training schemes: LAST FOLD, widely used in spatial CV at the cost of
data loss, and RETRAIN, which maximizes data usage but risks reintroducing SAC.
LAST FOLD consistently yielded lower errors and stronger correlations. Spatial
blocking at an optimal distance (SP 422) and ENV performed best, achieving
Spearman and Pearson correlations of 0.485 and 0.548, respectively, although
ENV may be unsuitable for long-term forecasts involving major environmental
shifts. A spatio-temporal approach yielded modest benefits in our moderately
variable dataset, but may excel with stronger temporal changes. These findings
highlight the need to align CV approaches with the spatial and temporal
structure of SDM data, ensuring rigorous validation and reliable predictive
outcomes.",http://arxiv.org/abs/2502.03480v1
"TD-M(PC)$^2$: Improving Temporal Difference MPC Through Policy
  Constraint",2025-02-05T19:08:42Z,"Haotian Lin, Pengcheng Wang, Jeff Schneider, Guanya Shi","Model-based reinforcement learning algorithms that combine model-based
planning and learned value/policy prior have gained significant recognition for
their high data efficiency and superior performance in continuous control.
However, we discover that existing methods that rely on standard SAC-style
policy iteration for value learning, directly using data generated by the
planner, often result in \emph{persistent value overestimation}. Through
theoretical analysis and experiments, we argue that this issue is deeply rooted
in the structural policy mismatch between the data generation policy that is
always bootstrapped by the planner and the learned policy prior. To mitigate
such a mismatch in a minimalist way, we propose a policy regularization term
reducing out-of-distribution (OOD) queries, thereby improving value learning.
Our method involves minimum changes on top of existing frameworks and requires
no additional computation. Extensive experiments demonstrate that the proposed
approach improves performance over baselines such as TD-MPC2 by large margins,
particularly in 61-DoF humanoid tasks. View qualitative results at
https://darthutopian.github.io/tdmpc_square/.",http://arxiv.org/abs/2502.03550v1
Retina electronic paper with video-rate-tunable 45000 pixels per inch,2025-02-05T19:58:42Z,"Ade Satria Saloka Santosa, Yu-Wei Chang, Andreas B. Dahlin, Lars Osterlund, Giovanni Volpe, Kunli Xiong","As demand for immersive experiences grows, displays are moving closer to the
eye with smaller sizes and higher resolutions. However, shrinking pixel
emitters reduce intensity, making them harder to perceive. Electronic Papers
utilize ambient light for visibility, maintaining optical contrast regardless
of pixel size, but cannot achieve high resolution. We show electrically tunable
meta-pixels down to ~560 nm in size (>45,000 PPI) consisting of WO3 nanodiscs,
allowing one-to-one pixel-photodetector mapping on the retina when the display
size matches the pupil diameter, which we call Retina Electronic Paper. Our
technology also supports video display (25 Hz), high reflectance (~80%), and
optical contrast (~50%), which will help create the ultimate virtual reality
display.",http://arxiv.org/abs/2502.03580v1
"Towards Physical Understanding in Video Generation: A 3D Point
  Regularization Approach",2025-02-05T21:49:06Z,"Yunuo Chen, Junli Cao, Anil Kag, Vidit Goel, Sergei Korolev, Chenfanfu Jiang, Sergey Tulyakov, Jian Ren","We present a novel video generation framework that integrates 3-dimensional
geometry and dynamic awareness. To achieve this, we augment 2D videos with 3D
point trajectories and align them in pixel space. The resulting 3D-aware video
dataset, PointVid, is then used to fine-tune a latent diffusion model, enabling
it to track 2D objects with 3D Cartesian coordinates. Building on this, we
regularize the shape and motion of objects in the video to eliminate undesired
artifacts, \eg, nonphysical deformation. Consequently, we enhance the quality
of generated RGB videos and alleviate common issues like object morphing, which
are prevalent in current video models due to a lack of shape awareness. With
our 3D augmentation and regularization, our model is capable of handling
contact-rich scenarios such as task-oriented videos. These videos involve
complex interactions of solids, where 3D information is essential for
perceiving deformation and contact. Furthermore, our model improves the overall
quality of video generation by promoting the 3D consistency of moving objects
and reducing abrupt changes in shape and motion.",http://arxiv.org/abs/2502.03639v1
"Unveiling the complexity of Arnold's tongues in a breathing-soliton
  laser",2025-02-06T01:12:51Z,"Xiuqi Wu, Junsong Peng, Bo Yuan, Sonia Boscolo, Christophe Finot, Heping Zeng","Synchronization occurs ubiquitously in nature and science. The
synchronization regions generally broaden monotonically with the strength of
the forcing, thereby featuring a tongue-like shape in parameter space, known as
Arnold's tongue. Such a shape is universal, prevailing in many diverse
synchronized systems. Interestingly, theoretical studies suggest that under
strong external forcing, the shape of the synchronization regions can change
substantially and even holes can appear in the solid patterns. However,
experimentally accessing these abnormal regimes is quite challenging, mainly
because many real-world systems displaying synchronization become fragile under
strong forcing. Here, we are able to observe these intriguing regimes in a
breathing-soliton laser. Two types of abnormal synchronization regions are
unveiled, namely, a leaf- and a ray-like shape. High-resolution control of the
loss allows holes to be revealed in the synchronization regions. Our work opens
the possibility to study intriguing synchronization dynamics using a simple
breathing-soliton laser as a testbed.",http://arxiv.org/abs/2502.03697v1
"Co-existing topological and Volkov-Pankratov plasmonic edge states in
  magnetized graphene",2025-02-06T01:57:17Z,"Samyobrata Mukherjee, Viktoriia Savchuk, Jeffery W. Allen, Monica S. Allen, Gennady Shvets","Graphene placed in a perpendicular magnetic field supports optical modes
known as magnetoplasmons which are transversally confined to the graphene
layer. Unlike ordinary graphene plasmons, these magnetoplasmonic surface waves
are characterized by a band gap corresponding to the cyclotron frequency. In
addition, these magnetoplasmon bands are topological, characterized by a
non-zero Chern number. This leads to the existence of topologically protected
edge states at domain edges where the Chern number changes. Since the Chern
number is dependent on the direction of the magnetic field, edge states exist
at domain edges across which the magnetic field flips direction. Physically,
the magnetic field can only flip direction at gradual domain edges with finite
width creating topological heterojunctions. These topological heterojunctions
support extra edge states known as Volkov-Pankratov edge states which can enter
the band gap and support propagation in both directions. The number of
Volkov-Pankratov states at a heterojunction varies as a function of the width
of the gradual domain edge.",http://arxiv.org/abs/2502.03710v1
"Out-of-phase Plasmon Excitations in the Trilayer Cuprate
  Bi$_2$Sr$_2$Ca$_2$Cu$_3$O$_{10+δ}$",2025-02-06T04:59:54Z,"S. Nakata, M. Bejas, J. Okamoto, K. Yamamoto, D. Shiga, R. Takahashi, H. Y. Huang, H. Kumigashira, H. Wadati, J. Miyawaki, S. Ishida, H. Eisaki, A. Fujimori, A. Greco, H. Yamase, D. J. Huang, H. Suzuki","Within a homologous series of cuprate superconductors, variations in the
stacking of CuO$_2$ layers influence the collective charge dynamics through the
long-range Coulomb interactions. We use O $K$-edge resonant inelastic x-ray
scattering to reveal plasmon excitations in the optimally-doped trilayer
Bi$_2$Sr$_2$Ca$_2$Cu$_3$O$_{10+\delta}$. The observed plasmon exhibits nearly
$q_z$-independent dispersion and a large excitation gap of approximately 300
meV. This mode is primarily ascribed to the $\omega_{-}$ mode, where the charge
density on the outer CuO$_2$ sheets oscillates out of phase while the density
in the inner sheet remains unaltered at $q_z=0$. The intensity of the acoustic
$\omega_3$ mode is relatively weak and becomes vanishingly small near $(q_x,
q_y)=(0, 0)$. This result highlights a qualitative change in the eigenmode of
the dominant low-energy plasmon with the number of CuO$_2$ layers.",http://arxiv.org/abs/2502.03779v2
"Superior probabilistic computing using operationally stable
  probabilistic-bit constructed by manganite nanowire",2025-02-06T05:58:36Z,"Yadi Wang, Bin Chen, Wenping Gao, Biying Ye, Chang Niu, Wenbin Wang, Yinyan Zhu, Weichao Yu, Hangwen Guo, Jian Shen","Probabilistic computing has emerged as a viable approach to treat
optimization problems. To achieve superior computing performance, the key
aspect during computation is massive sampling and tuning on the probability
states of each probabilistic bit (p-bit), demanding its high stability under
extensive operations. Here, we demonstrate a p-bit constructed by manganite
nanowire that shows exceptionally high stability. The p-bit contains an
electronic domain that fluctuates between metallic (low resistance) and
insulating (high resistance) states near its transition temperature. The
probability for the two states can be directly controlled by nano-ampere
electrical current. Under extensive operations, the standard error of its
probability values is less than 1.3%. Simulations show that our operationally
stable p-bit plays the key role to achieve correct inference in Bayesian
network by strongly suppressing the relative error, displaying the potential
for superior computing performance. Our p-bit also serves as high quality
random number generator without extra data-processing, beneficial for
cryptographic applications.",http://arxiv.org/abs/2502.03797v1
"Knowing When to Stop Matters: A Unified Algorithm for Online Conversion
  under Horizon Uncertainty",2025-02-06T07:06:06Z,"Yanzhao Wang, Hasti Nourmohammadi Sigaroudi, Bo Sun, Omid Ardakanian, Xiaoqi Tan","This paper investigates the online conversion problem, which involves
sequentially trading a divisible resource (e.g., energy) under dynamically
changing prices to maximize profit. A key challenge in online conversion is
managing decisions under horizon uncertainty, where the duration of trading is
either known, revealed partway, or entirely unknown. We propose a unified
algorithm that achieves optimal competitive guarantees across these horizon
models, accounting for practical constraints such as box constraints, which
limit the maximum allowable trade per step. Additionally, we extend the
algorithm to a learning-augmented version, leveraging horizon predictions to
adaptively balance performance: achieving near-optimal results when predictions
are accurate while maintaining strong guarantees when predictions are
unreliable. These results advance the understanding of online conversion under
various degrees of horizon uncertainty and provide more practical strategies to
address real world constraints.",http://arxiv.org/abs/2502.03817v1
Counterfactual Query Rewriting to Use Historical Relevance Feedback,2025-02-06T09:05:41Z,"Jüri Keller, Maik Fröbe, Gijs Hendriksen, Daria Alexander, Martin Potthast, Matthias Hagen, Philipp Schaer","When a retrieval system receives a query it has encountered before, previous
relevance feedback, such as clicks or explicit judgments can help to improve
retrieval results. However, the content of a previously relevant document may
have changed, or the document might not be available anymore. Despite this
evolved corpus, we counterfactually use these previously relevant documents as
relevance signals. In this paper we proposed approaches to rewrite user queries
and compare them against a system that directly uses the previous qrels for the
ranking. We expand queries with terms extracted from the previously relevant
documents or derive so-called keyqueries that rank the previously relevant
documents to the top of the current corpus. Our evaluation in the CLEF LongEval
scenario shows that rewriting queries with historical relevance feedback
improves the retrieval effectiveness and even outperforms computationally
expensive transformer-based approaches.",http://arxiv.org/abs/2502.03891v1
Fairness Aware Reinforcement Learning via Proximal Policy Optimization,2025-02-06T10:45:55Z,"Gabriele La Malfa, Jie M. Zhang, Michael Luck, Elizabeth Black","Fairness in multi-agent systems (MAS) focuses on equitable reward
distribution among agents in scenarios involving sensitive attributes such as
race, gender, or socioeconomic status. This paper introduces fairness in
Proximal Policy Optimization (PPO) with a penalty term derived from demographic
parity, counterfactual fairness, and conditional statistical parity. The
proposed method balances reward maximisation with fairness by integrating two
penalty components: a retrospective component that minimises disparities in
past outcomes and a prospective component that ensures fairness in future
decision-making. We evaluate our approach in the Allelopathic Harvest game, a
cooperative and competitive MAS focused on resource collection, where some
agents possess a sensitive attribute. Experiments demonstrate that fair-PPO
achieves fairer policies across all fairness metrics than classic PPO. Fairness
comes at the cost of reduced rewards, namely the Price of Fairness, although
agents with and without the sensitive attribute renounce comparable amounts of
rewards. Additionally, the retrospective and prospective penalties effectively
change the agents' behaviour and improve fairness. These findings underscore
the potential of fair-PPO to address fairness challenges in MAS.",http://arxiv.org/abs/2502.03953v1
"Pre-Optimized Irregular Arrays versus Moveable Antennas in Multi-User
  MIMO Systems",2025-02-06T11:51:36Z,"Amna Irshad, Alva Kosasih, Vitaly Petrov, Emil Björnson","Massive multiple-input multiple-output (MIMO) systems exploit the spatial
diversity achieved with an array of many antennas to perform spatial
multiplexing of many users. Similar performance can be achieved using fewer
antennas if movable antenna (MA) elements are used instead. MA-enabled arrays
can dynamically change the antenna locations, mechanically or electrically, to
achieve maximum spatial diversity for the current propagation conditions.
However, optimizing the antenna locations for each channel realization is
computationally excessive, requires channel knowledge for all conceivable
locations, and requires rapid antenna movements, thus making real-time
implementation cumbersome. To overcome these challenges, we propose a
pre-optimized irregular array (PIA) concept, where the antenna locations at the
base station are optimized a priori for a given coverage area. The objective is
to maximize the average sum rate and we take a particle swarm optimization
approach to solve it. Simulation results show that PIA achieves performance
comparable to MA-enabled arrays while outperforming traditional uniform arrays.
Hence, PIA offers a fixed yet efficient array deployment approach without the
complexities associated with MA-enabled arrays.",http://arxiv.org/abs/2502.03994v1
"Near-optimal Regret Using Policy Optimization in Online MDPs with
  Aggregate Bandit Feedback",2025-02-06T12:03:24Z,"Tal Lancewicki, Yishay Mansour","We study online finite-horizon Markov Decision Processes with adversarially
changing loss and aggregate bandit feedback (a.k.a full-bandit). Under this
type of feedback, the agent observes only the total loss incurred over the
entire trajectory, rather than the individual losses at each intermediate step
within the trajectory. We introduce the first Policy Optimization algorithms
for this setting. In the known-dynamics case, we achieve the first
\textit{optimal} regret bound of $\tilde \Theta(H^2\sqrt{SAK})$, where $K$ is
the number of episodes, $H$ is the episode horizon, $S$ is the number of
states, and $A$ is the number of actions. In the unknown dynamics case we
establish regret bound of $\tilde O(H^3 S \sqrt{AK})$, significantly improving
the best known result by a factor of $H^2 S^5 A^2$.",http://arxiv.org/abs/2502.04004v1
Spontaneous helix formation in polar smectic phase,2025-02-06T13:02:42Z,"Ewa Gorecka, Magdalena Majewska, Ladislav Fekete, Jakub Karcz, Julia Żukowska, Jakub Herman Przemysław Kula, Damian Pociecha","In soft ferroelectric crystals, the depolarization field can be reduced by
periodic distortion of the polarization direction. In the polar nematic and
tilted smectic phases, this process is energetically favorured , as it only
requires changes in the director orientation. We demonstrate the spontaneous
formation of a helical structure in the proper ferroelectric tilted smectic
(SmCTBF) phase, the phase is formed below the heliconical polar nematic (NTBF)
phase. The helical pitch in the smectic phase is approximately 600 nm and
remains nearly constant across the entire temperature range of the phase. Under
weak electric fields, the helix reorients while its structure remains largely
intact; however, in stronger fields, the helix is destroyed as the electric
polarization aligns along the electric field.",http://arxiv.org/abs/2502.04042v1
"Non-renormalization of the fractional quantum Hall conductivity by
  interactions",2025-02-06T13:05:15Z,"M. Selch, M. A. Zubkov, Souvik Pramanik, M. Lewkowicz","We investigate the theory of the fractional quantum Hall effect (QHE)
proposed a long time ago by Lopez and Fradkin \cite{Fradkin1991chern}. The
magnetic fluxes of the statistical gauge field attached to electrons remain at
rest in the reference frame moving together with the electron liquid. In the
laboratory reference frame the electric field of the statistical gauge field
forms and screens the external electric field. The fractional QHE conductivity
appears as a consequence of this screening already on the mean field theory
level. We consider a relativistic extension of the model, and propose an
alternative description of the fractional QHE based on macroscopic motion of
the electron liquid within the Zubarev statistical operator approach. It is
this macroscopic motion of electrons which in this pattern gives rise to the
fractional QHE. Within this approach we propose the proof to all orders of
perturbation theory that the interaction corrections cannot change the above
mentioned mean field theory result for the QHE conductivity.",http://arxiv.org/abs/2502.04047v1
"CDIO: Cross-Domain Inference Optimization with Resource Preference
  Prediction for Edge-Cloud Collaboration",2025-02-06T13:42:07Z,"Zheming Yang, Wen Ji, Qi Guo, Dieli Hu, Chang Zhao, Xiaowei Li, Xuanlei Zhao, Yi Zhao, Chaoyu Gong, Yang You","Currently, massive video tasks are processed by edge-cloud collaboration.
However, the diversity of task requirements and the dynamics of resources pose
great challenges to efficient inference, resulting in many wasted resources. In
this paper, we present CDIO, a cross-domain inference optimization framework
designed for edge-cloud collaboration. For diverse input tasks, CDIO can
predict resource preference types by analyzing spatial complexity and
processing requirements of the task. Subsequently, a cross-domain collaborative
optimization algorithm is employed to guide resource allocation in the
edge-cloud system. By ensuring that each task is matched with the ideal
servers, the edge-cloud system can achieve higher efficiency inference. The
evaluation results on public datasets demonstrate that CDIO can effectively
meet the accuracy and delay requirements for task processing. Compared to
state-of-the-art edge-cloud solutions, CDIO achieves a computing and bandwidth
consumption reduction of 20%-40%. And it can reduce energy consumption by more
than 40%.",http://arxiv.org/abs/2502.04078v1
Impermanent loss and Loss-vs-Rebalancing II,2025-02-06T14:16:10Z,"Abe Alexander, Guillaume Lambert, Lars Fritz","This paper examines the relationship between impermanent loss (IL) and
loss-versus-rebalancing (LVR) in automated market makers (AMMs). Our main focus
is on statistical properties, the impact of fees, the role of block times, and,
related to the latter, the continuous time limit. We find there are three
relevant regimes: (i) very short times where LVR and IL are identical; (ii)
intermediate time where LVR and IL show distinct distribution functions but are
connected via the central limit theorem exhibiting the same expectation value;
(iii) long time behavior where both the distribution functions and averages are
distinct. Subsequently, we study how fees change this dynamics with a special
focus on competing time scales like block times and 'arbitrage times'.",http://arxiv.org/abs/2502.04097v2
Quadratic spin-phonon coupling and bipolarons in trapped ions,2025-02-06T14:34:34Z,"L. P. H. Gallagher, M. Mazzanti, Z. E. D. Ackerman, R. J. C. Spreeuw, A. Safavi-Naini, R. Gerritsma","We consider the quantum simulation of quadratic spin-phonon coupling in a
crystal of trapped ions. The coupling is implemented using tightly focused
optical tweezers on each ion that change the local trapping potential in a
state-dependent way. By encoding spins in the internal states of the ions and
adding a tunneling term via M{\o}lmer-S{\o}rensen-type interactions, we
calculate the emergence of mobile bipolarons driven by the zero-point energy of
the ion crystal phonons. We show that thermal occupation may pin the bipolarons
for ion crystals at finite temperature. Our scheme can be used to study and
illustrate the emergence of mobile bipolarons as a function of temperature.",http://arxiv.org/abs/2502.04109v1
UltraIF: Advancing Instruction Following from the Wild,2025-02-06T15:39:16Z,"Kaikai An, Li Sheng, Ganqu Cui, Shuzheng Si, Ning Ding, Yu Cheng, Baobao Chang","Instruction-following made modern large language models (LLMs) helpful
assistants. However, the key to taming LLMs on complex instructions remains
mysterious, for that there are huge gaps between models trained by open-source
community and those trained by leading companies. To bridge the gap, we propose
a simple and scalable approach UltraIF for building LLMs that can follow
complex instructions with open-source data. UltraIF first decomposes real-world
user prompts into simpler queries, constraints, and corresponding evaluation
questions for the constraints. Then, we train an UltraComposer to compose
constraint-associated prompts with evaluation questions. This prompt composer
allows us to synthesize complicated instructions as well as filter responses
with evaluation questions. In our experiment, for the first time, we
successfully align LLaMA-3.1-8B-Base to catch up with its instruct version on 5
instruction-following benchmarks without any benchmark information, using only
8B model as response generator and evaluator. The aligned model also achieved
competitive scores on other benchmarks. Moreover, we also show that UltraIF
could further improve LLaMA-3.1-8B-Instruct through self-alignment, motivating
broader use cases for the method. Our code will be available at
https://github.com/kkk-an/UltraIF.",http://arxiv.org/abs/2502.04153v1
"A Pseudo Markov-Chain Model and Time-Elapsed Measures of Mobility from
  Collective Data",2025-02-06T15:46:43Z,"Alisha Foster, David A. Meyer, Asif Shakeel","In this paper we develop a pseudo Markov-chain model to understand
time-elapsed flows, over multiple intervals, from time and space aggregated
collective inter-location trip data, given as a time-series. Building on the
model, we develop measures of mobility that parallel those known for individual
mobility data, such as the radius of gyration. We apply these measures to the
NetMob 2024 Data Challenge data, and obtain interesting results that are
consistent with published statistics and commuting patterns in cities. Besides
building a new framework, we foresee applications of this approach to an
improved understanding of human mobility in the context of environmental
changes and sustainable development.",http://arxiv.org/abs/2502.04162v1
Multi-task Online Learning for Probabilistic Load Forecasting,2025-02-06T15:47:02Z,"Onintze Zaballa, Verónica Álvarez, Santiago Mazuelas","Load forecasting is essential for the efficient, reliable, and cost-effective
management of power systems. Load forecasting performance can be improved by
learning the similarities among multiple entities (e.g., regions, buildings).
Techniques based on multi-task learning obtain predictions by leveraging
consumption patterns from the historical load demand of multiple entities and
their relationships. However, existing techniques cannot effectively assess
inherent uncertainties in load demand or account for dynamic changes in
consumption patterns. This paper proposes a multi-task learning technique for
online and probabilistic load forecasting. This technique provides accurate
probabilistic predictions for the loads of multiple entities by leveraging
their dynamic similarities. The method's performance is evaluated using
datasets that register the load demand of multiple entities and contain diverse
and dynamic consumption patterns. The experimental results show that the
proposed method can significantly enhance the effectiveness of current
multi-task learning approaches across a wide variety of load consumption
scenarios.",http://arxiv.org/abs/2502.04163v1
"Provably Robust Explainable Graph Neural Networks against Graph
  Perturbation Attacks",2025-02-06T17:07:52Z,"Jiate Li, Meng Pang, Yun Dong, Jinyuan Jia, Binghui Wang","Explaining Graph Neural Network (XGNN) has gained growing attention to
facilitate the trust of using GNNs, which is the mainstream method to learn
graph data. Despite their growing attention, Existing XGNNs focus on improving
the explanation performance, and its robustness under attacks is largely
unexplored. We noticed that an adversary can slightly perturb the graph
structure such that the explanation result of XGNNs is largely changed. Such
vulnerability of XGNNs could cause serious issues particularly in
safety/security-critical applications. In this paper, we take the first step to
study the robustness of XGNN against graph perturbation attacks, and propose
XGNNCert, the first provably robust XGNN. Particularly, our XGNNCert can
provably ensure the explanation result for a graph under the worst-case graph
perturbation attack is close to that without the attack, while not affecting
the GNN prediction, when the number of perturbed edges is bounded. Evaluation
results on multiple graph datasets and GNN explainers show the effectiveness of
XGNNCert.",http://arxiv.org/abs/2502.04224v1
"A Theoretical Framework for Data Efficient Multi-Source Transfer
  Learning Based on Cramér-Rao Bound",2025-02-06T17:32:49Z,"Qingyue Zhang, Haohao Fu, Guanbo Huang, Yaoyuan Liang, Chang Chu, Tianren Peng, Yanru Wu, Qi Li, Yang Li, Shao-Lun Huang","Multi-source transfer learning provides an effective solution to data
scarcity in real-world supervised learning scenarios by leveraging multiple
source tasks. In this field, existing works typically use all available samples
from sources in training, which constrains their training efficiency and may
lead to suboptimal results. To address this, we propose a theoretical framework
that answers the question: what is the optimal quantity of source samples
needed from each source task to jointly train the target model? Specifically,
we introduce a generalization error measure that aligns with cross-entropy
loss, and minimize it based on the Cram\'er-Rao Bound to determine the optimal
transfer quantity for each source task. Additionally, we develop an
architecture-agnostic and data-efficient algorithm OTQMS to implement our
theoretical results for training deep multi-source transfer learning models.
Experimental studies on diverse architectures and two real-world benchmark
datasets show that our proposed algorithm significantly outperforms
state-of-the-art approaches in both accuracy and data efficiency. The code and
supplementary materials are available in
https://anonymous.4open.science/r/Materials.",http://arxiv.org/abs/2502.04242v1
Prediction-Powered E-Values,2025-02-06T18:36:01Z,"Daniel Csillag, Claudio José Struchiner, Guilherme Tegoni Goedert","Quality statistical inference requires a sufficient amount of data, which can
be missing or hard to obtain. To this end, prediction-powered inference has
risen as a promising methodology, but existing approaches are largely limited
to Z-estimation problems such as inference of means and quantiles. In this
paper, we apply ideas of prediction-powered inference to e-values. By doing so,
we inherit all the usual benefits of e-values -- such as anytime-validity,
post-hoc validity and versatile sequential inference -- as well as greatly
expand the set of inferences achievable in a prediction-powered manner. In
particular, we show that every inference procedure that can be framed in terms
of e-values has a prediction-powered counterpart, given by our method. We
showcase the effectiveness of our framework across a wide range of inference
tasks, from simple hypothesis testing and confidence intervals to more involved
procedures for change-point detection and causal discovery, which were out of
reach of previous techniques. Our approach is modular and easily integrable
into existing algorithms, making it a compelling choice for practical
applications.",http://arxiv.org/abs/2502.04294v1
Can Large Language Models Capture Video Game Engagement?,2025-02-05T17:14:47Z,"David Melhart, Matthew Barthet, Georgios N. Yannakakis","Can out-of-the-box pretrained Large Language Models (LLMs) detect human
affect successfully when observing a video? To address this question, for the
first time, we evaluate comprehensively the capacity of popular LLMs to
annotate and successfully predict continuous affect annotations of videos when
prompted by a sequence of text and video frames in a multimodal fashion.
Particularly in this paper, we test LLMs' ability to correctly label changes of
in-game engagement in 80 minutes of annotated videogame footage from 20
first-person shooter games of the GameVibe corpus. We run over 2,400
experiments to investigate the impact of LLM architecture, model size, input
modality, prompting strategy, and ground truth processing method on engagement
prediction. Our findings suggest that while LLMs rightfully claim human-like
performance across multiple domains, they generally fall behind capturing
continuous experience annotations provided by humans. We examine some of the
underlying causes for the relatively poor overall performance, highlight the
cases where LLMs exceed expectations, and draw a roadmap for the further
exploration of automated emotion labelling via LLMs.",http://arxiv.org/abs/2502.04379v1
"Enhancing Reasoning to Adapt Large Language Models for Domain-Specific
  Applications",2025-02-05T19:27:24Z,"Bo Wen, Xin Zhang","This paper presents SOLOMON, a novel Neuro-inspired Large Language Model
(LLM) Reasoning Network architecture that enhances the adaptability of
foundation models for domain-specific applications. Through a case study in
semiconductor layout design, we demonstrate how SOLOMON enables swift
adaptation of general-purpose LLMs to specialized tasks by leveraging Prompt
Engineering and In-Context Learning techniques. Our experiments reveal the
challenges LLMs face in spatial reasoning and applying domain knowledge to
practical problems. Results show that SOLOMON instances significantly
outperform their baseline LLM counterparts and achieve performance comparable
to state-of-the-art reasoning model, o1-preview. We discuss future research
directions for developing more adaptive AI systems that can continually learn,
adapt, and evolve in response to new information and changing requirements.",http://arxiv.org/abs/2502.04384v1
"UniCP: A Unified Caching and Pruning Framework for Efficient Video
  Generation",2025-02-06T03:56:11Z,"Wenzhang Sun, Qirui Hou, Donglin Di, Jiahui Yang, Yongjia Ma, Jianxun Cui","Diffusion Transformers (DiT) excel in video generation but encounter
significant computational challenges due to the quadratic complexity of
attention. Notably, attention differences between adjacent diffusion steps
follow a U-shaped pattern. Current methods leverage this property by caching
attention blocks, however, they still struggle with sudden error spikes and
large discrepancies. To address these issues, we propose UniCP a unified
caching and pruning framework for efficient video generation. UniCP optimizes
both temporal and spatial dimensions through. Error Aware Dynamic Cache Window
(EDCW): Dynamically adjusts cache window sizes for different blocks at various
timesteps, adapting to abrupt error changes. PCA based Slicing (PCAS) and
Dynamic Weight Shift (DWS): PCAS prunes redundant attention components, and DWS
integrates caching and pruning by enabling dynamic switching between pruned and
cached outputs. By adjusting cache windows and pruning redundant components,
UniCP enhances computational efficiency and maintains video detail fidelity.
Experimental results show that UniCP outperforms existing methods in both
performance and efficiency.",http://arxiv.org/abs/2502.04393v1
"On the extension of the concept of rheological connections to a finite
  deformation framework using multiple natural configurations",2025-02-06T06:13:02Z,"Tarun Singh, Sandipan Paul","The constitutive behaviors of materials are often modeled using a network of
different rheological elements. These rheological models are mostly developed
within a one-dimensional small strain framework. One of the key impediments of
extending these models to a three-dimensional finite deformation setting is to
determine how the different types of connections, i.e., a series and a parallel
connection, are incorporated into the material models. The primary objective of
this article is to develop an appropriate strategy to address this issue. We
show that both the series and the parallel connection between two rheological
elements can be modeled within a multiple natural configurations framework
without changing or introducing new configurations. The difference in a series
and a parallel connection is manifested in the ratio of the stress powers
expended during the deformations of the associated rheological elements. Finite
deformation version of some well-known rheological models have been used to
demonstrate the utility of the proposed theory.",http://arxiv.org/abs/2502.04396v1
Compact protoplanetary discs can be produced by dead zones,2025-02-06T19:00:50Z,"Simin Tong, Richard Alexander","Radially compact protoplanetary discs (<=50 au) are ubiquitous in nearby
star-forming regions. Multiple mechanisms have been invoked to interpret
various compact discs. In this paper, we propose that fragmentation of fragile
dust grains in moderate turbulence, as expected beyond the dead zone, provides
an effective alternative mechanism to form compact discs which are consistent
with current observations. We run 1-D dust transport and collision models with
DustPy and generate synthetic observations, and find that discs formed by this
mechanism have sizes determined by the extent of their dead zones. Accounting
for dust porosity, and considering less fragile dust, do not change disc sizes
significantly. The smooth dust morphology can be altered only when pressure
bumps are present in the dead zone. However, when present at small radii (<=10
au), pressure bumps cannot effectively trap dust. Dust in these bumps fragments
and replenishes the inner discs, effectively hiding dust traps in the optically
thick inner disc from observations. We note a striking resemblance in the
radial intensity profile between our synthetic observations and some recent
high-resolution observations of compact discs. We discuss how such observations
can inform our understanding of the underlying disc physics.",http://arxiv.org/abs/2502.04452v1
Enhanced Axion-wind near Earth's Surface,2025-02-06T19:02:02Z,"Yeray Garcia del Castillo, Benjamin Hammett, Joerg Jaeckel","Several detection strategies for wave-like dark matter make use of gradients
in the dark matter field, e.g. searches for spin-dependent derivative
interactions in CASPEr-wind or experiments looking for oscillating forces.
These gradients are usually suppressed by the local dark matter velocity $\sim
10^{-3}$. In this note we investigate how these gradients are modified in the
presence of additional quadratic interactions of the dark matter field with
ordinary matter. In this case the dark matter density and field are modified in
the vicinity of Earth, affecting the detection sensitivity due to the change in
the local field value at the Earth's surface but also due to the gradient of
the field profile itself. We also use this opportunity to present results on
the expected field profiles in presence of a non-vanishing relative velocity of
the dark matter with respect to Earth. We also comment how this ameliorates the
divergences that appear for certain attractive coupling values.",http://arxiv.org/abs/2502.04456v1
"""In order that"" -- a data driven study of symptoms and causes of
  obsolescence",2025-02-06T19:03:45Z,Karolina Rudnicka,"The paper is an empirical case study of grammatical obsolescence in progress.
The main studied variable is the purpose subordinator in order that, which is
shown to be steadily decreasing in the frequency of use starting from the
beginning of the twentieth century. This work applies a data-driven approach
for the investigation and description of obsolescence, recently developed by
the Rudnicka (2019). The methodology combines philological analysis with
statistical methods used on data acquired from mega-corpora. Moving from the
description of possible symptoms of obsolescence to different causes for it,
the paper aims at presenting a comprehensive account of the studied phenomenon.
Interestingly, a very significant role in the decline of in order that can be
ascribed to the so-called higher-order processes, understood as processes
influencing the constructional level from above. Two kinds of higher-order
processes are shown to play an important role, namely i) an
externally-motivated higher-order process exemplified by the drastic
socio-cultural changes of the 19th and 20th centuries; ii) an
internally-motivated higher-order processes instantiated by the rise of the
to-infinitive (rise of infinite clauses).",http://arxiv.org/abs/2502.04457v1
"Discovering Physics Laws of Dynamical Systems via Invariant Function
  Learning",2025-02-06T20:46:50Z,"Shurui Gui, Xiner Li, Shuiwang Ji","We consider learning underlying laws of dynamical systems governed by
ordinary differential equations (ODE). A key challenge is how to discover
intrinsic dynamics across multiple environments while circumventing
environment-specific mechanisms. Unlike prior work, we tackle more complex
environments where changes extend beyond function coefficients to entirely
different function forms. For example, we demonstrate the discovery of ideal
pendulum's natural motion $\alpha^2 \sin{\theta_t}$ by observing pendulum
dynamics in different environments, such as the damped environment $\alpha^2
\sin(\theta_t) - \rho \omega_t$ and powered environment $\alpha^2
\sin(\theta_t) + \rho \frac{\omega_t}{\left|\omega_t\right|}$. Here, we
formulate this problem as an \emph{invariant function learning} task and
propose a new method, known as \textbf{D}isentanglement of \textbf{I}nvariant
\textbf{F}unctions (DIF), that is grounded in causal analysis. We propose a
causal graph and design an encoder-decoder hypernetwork that explicitly
disentangles invariant functions from environment-specific dynamics. The
discovery of invariant functions is guaranteed by our information-based
principle that enforces the independence between extracted invariant functions
and environments. Quantitative comparisons with meta-learning and invariant
learning baselines on three ODE systems demonstrate the effectiveness and
efficiency of our method. Furthermore, symbolic regression explanation results
highlight the ability of our framework to uncover intrinsic laws.",http://arxiv.org/abs/2502.04495v1
"Probing a Vision-Language-Action Model for Symbolic States and
  Integration into a Cognitive Architecture",2025-02-06T23:11:11Z,"Hong Lu, Hengxu Li, Prithviraj Singh Shahani, Stephanie Herbers, Matthias Scheutz","Vision-language-action (VLA) models hold promise as generalist robotics
solutions by translating visual and linguistic inputs into robot actions, yet
they lack reliability due to their black-box nature and sensitivity to
environmental changes. In contrast, cognitive architectures (CA) excel in
symbolic reasoning and state monitoring but are constrained by rigid predefined
execution. This work bridges these approaches by probing OpenVLA's hidden
layers to uncover symbolic representations of object properties, relations, and
action states, enabling integration with a CA for enhanced interpretability and
robustness. Through experiments on LIBERO-spatial pick-and-place tasks, we
analyze the encoding of symbolic states across different layers of OpenVLA's
Llama backbone. Our probing results show consistently high accuracies (> 0.90)
for both object and action states across most layers, though contrary to our
hypotheses, we did not observe the expected pattern of object states being
encoded earlier than action states. We demonstrate an integrated DIARC-OpenVLA
system that leverages these symbolic representations for real-time state
monitoring, laying the foundation for more interpretable and reliable robotic
manipulation.",http://arxiv.org/abs/2502.04558v1
Private Federated Learning In Real World Application -- A Case Study,2025-02-06T23:38:50Z,"An Ji, Bortik Bandyopadhyay, Congzheng Song, Natarajan Krishnaswami, Prabal Vashisht, Rigel Smiroldo, Isabel Litton, Sayantan Mahinder, Mona Chitnis, Andrew W Hill","This paper presents an implementation of machine learning model training
using private federated learning (PFL) on edge devices. We introduce a novel
framework that uses PFL to address the challenge of training a model using
users' private data. The framework ensures that user data remain on individual
devices, with only essential model updates transmitted to a central server for
aggregation with privacy guarantees. We detail the architecture of our app
selection model, which incorporates a neural network with attention mechanisms
and ambiguity handling through uncertainty management. Experiments conducted
through off-line simulations and on device training demonstrate the feasibility
of our approach in real-world scenarios. Our results show the potential of PFL
to improve the accuracy of an app selection model by adapting to changes in
user behavior over time, while adhering to privacy standards. The insights
gained from this study are important for industries looking to implement PFL,
offering a robust strategy for training a predictive model directly on edge
devices while ensuring user data privacy.",http://arxiv.org/abs/2502.04565v2
Learning Semantics-aware Search Operators for Genetic Programming,2025-02-06T23:46:04Z,"Piotr Wyrwiński, Krzysztof Krawiec","Fitness landscapes in test-based program synthesis are known to be extremely
rugged, with even minimal modifications of programs often leading to
fundamental changes in their behavior and, consequently, fitness values.
Relying on fitness as the only guidance in iterative search algorithms like
genetic programming is thus unnecessarily limiting, especially when combined
with purely syntactic search operators that are agnostic about their impact on
program behavior. In this study, we propose a semantics-aware search operator
that steers the search towards candidate programs that are valuable not only
actually (high fitness) but also only potentially, i.e. are likely to be turned
into high-quality solutions even if their current fitness is low. The key
component of the method is a graph neural network that learns to model the
interactions between program instructions and processed data, and produces a
saliency map over graph nodes that represents possible search decisions. When
applied to a suite of symbolic regression benchmarks, the proposed method
outperforms conventional tree-based genetic programming and the ablated variant
of the method.",http://arxiv.org/abs/2502.04568v1
Ludwig-Soret microscopy with vibrational photothermal effect,2025-02-07T00:19:18Z,"Keiichiro Toda, Takuro Ideguchi","Vibrational microscopy provides label-free, bond-selective chemical contrast
by detecting molecular vibrations, making it invaluable for biomedical
research. While conventional methods rely on the direct detection of Raman
scattering or infrared absorption, recently developed vibrational photothermal
(ViP) microscopy achieves chemical contrast indirectly through refractive index
(RI) changes. This indirect approach enables unique imaging capabilities beyond
traditional chemical imaging. Here, we introduce a novel application of ViP
microscopy: label-free intracellular thermophoretic (Soret) imaging, which
visualizes biomolecular transport driven by temperature gradients. ViP-induced
Soret (ViPS) imaging leverages a steady-state temperature distribution
generated by optical heating through vibrational photothermal effect, combined
with time-resolved RI imaging via optical diffraction tomography (ODT). Using
ViPS imaging, we measured thermophoretic behavior in living COS7 cells,
determining intracellular diffusion and Soret coefficients. Notably, we
observed a reversed direction of molecular transport (negative Soret effect) in
the cytoplasm compared to the nucleus, possibly driven by
thermophoresis-induced diffusiophoresis. Furthermore, time-lapse imaging under
CO2-depleted conditions revealed a remarkable reduction in thermophoretic
activity, suggesting glass formation during the dying process, likely due to
polymer aggregation. ViPS imaging represents a new frontier in intracellular
thermophoretic studies, expanding the capabilities of vibrational microscopy.",http://arxiv.org/abs/2502.04578v1
Flavor Constraints in a Generational Three Higgs Doublet Model,2025-02-07T00:26:04Z,"Wolfgang Altmannshofer, Kevin Toner","We propose a Three Higgs Doublet Model (3HDM) that goes beyond natural flavor
conservation and in which each of the three Higgs doublets couples mainly to a
single generation of fermions via non-standard Yukawa structures. A hierarchy
in the vacuum expectation values of the three Higgs doublets can partially
address the SM flavor puzzle. In light of the experimentally observed $125$ GeV
Higgs boson, we primarily work within a 3HDM alignment limit such that a
Standard Model-like Higgs is recovered. In order to reproduce the observed CKM
mixing among quarks, the neutral Higgs bosons of the theory necessarily mediate
flavor changing neutral currents at the tree level. We consider constraints
from neutral kaon, $B$ meson, and $D$ meson mixing as well as from the rare
leptonic decays $B_s/B^0/K_L\rightarrow\mu^+\mu^-/e^+e^-$. We identify regions
of parameter space in which the new physics Higgs bosons can be as light as a
TeV or even lighter.",http://arxiv.org/abs/2502.04579v1
"Pure momentum-shift bulk photovoltaic effect in ferroelectric flat-band
  Mott insulators",2025-02-07T02:51:23Z,"Zhuocheng Lu, Zhihao Gong, Jingshan Qi, Hua Wang, Kai Chang","The shift current photovoltaic effect is conventionally understood as the
real-space displacement of a wave packet induced by photoexcitation. However,
this interpretation becomes insufficient in flat-band systems, where
quasiparticles are too massive to accelerate in real space under the optical
electric field. Here, we developed a gauge-invariant method to decompose the
shift current into real-space and momentum-space components. A surprising pure
momentum-space shift current is found theoretically in flat-band Mott insulator
Nb3X8 (X = Cl, Br, I) monolayers. This work underscores that significant shift
current responses can emerge even in systems with minimal interband
polarization differences, highlighting the potential for exploring novel bulk
photovoltaic effects in flat-band Mott insulators.",http://arxiv.org/abs/2502.04624v1
"CCS: Controllable and Constrained Sampling with Diffusion Models via
  Initial Noise Perturbation",2025-02-07T05:30:48Z,"Bowen Song, Zecheng Zhang, Zhaoxu Luo, Jason Hu, Wei Yuan, Jing Jia, Zhengxu Tang, Guanyang Wang, Liyue Shen","Diffusion models have emerged as powerful tools for generative tasks,
producing high-quality outputs across diverse domains. However, how the
generated data responds to the initial noise perturbation in diffusion models
remains under-explored, which hinders understanding the controllability of the
sampling process. In this work, we first observe an interesting phenomenon: the
relationship between the change of generation outputs and the scale of initial
noise perturbation is highly linear through the diffusion ODE sampling. Then we
provide both theoretical and empirical study to justify this linearity property
of this input-output (noise-generation data) relationship. Inspired by these
new insights, we propose a novel Controllable and Constrained Sampling method
(CCS) together with a new controller algorithm for diffusion models to sample
with desired statistical properties while preserving good sample quality. We
perform extensive experiments to compare our proposed sampling approach with
other methods on both sampling controllability and sampled data quality.
Results show that our CCS method achieves more precisely controlled sampling
while maintaining superior sample quality and diversity.",http://arxiv.org/abs/2502.04670v1
G2PDiffusion: Genotype-to-Phenotype Prediction with Diffusion Models,2025-02-07T06:16:31Z,"Mengdi Liu, Zhangyang Gao, Hong Chang, Stan Z. Li, Shiguang Shan, Xilin Chen","Discovering the genotype-phenotype relationship is crucial for genetic
engineering, which will facilitate advances in fields such as crop breeding,
conservation biology, and personalized medicine. Current research usually
focuses on single species and small datasets due to limitations in phenotypic
data collection, especially for traits that require visual assessments or
physical measurements. Deciphering complex and composite phenotypes, such as
morphology, from genetic data at scale remains an open question. To break
through traditional generic models that rely on simplified assumptions, this
paper introduces G2PDiffusion, the first-of-its-kind diffusion model designed
for genotype-to-phenotype generation across multiple species. Specifically, we
use images to represent morphological phenotypes across species and redefine
phenotype prediction as conditional image generation. To this end, this paper
introduces an environment-enhanced DNA sequence conditioner and trains a stable
diffusion model with a novel alignment method to improve genotype-to-phenotype
consistency. Extensive experiments demonstrate that our approach enhances
phenotype prediction accuracy across species, capturing subtle genetic
variations that contribute to observable traits.",http://arxiv.org/abs/2502.04684v2
A Meta-learner for Heterogeneous Effects in Difference-in-Differences,2025-02-07T07:04:37Z,"Hui Lan, Haoge Chang, Eleanor Dillon, Vasilis Syrgkanis","We address the problem of estimating heterogeneous treatment effects in panel
data, adopting the popular Difference-in-Differences (DiD) framework under the
conditional parallel trends assumption. We propose a novel doubly robust
meta-learner for the Conditional Average Treatment Effect on the Treated
(CATT), reducing the estimation to a convex risk minimization problem involving
a set of auxiliary models. Our framework allows for the flexible estimation of
the CATT, when conditioning on any subset of variables of interest using
generic machine learning. Leveraging Neyman orthogonality, our proposed
approach is robust to estimation errors in the auxiliary models. As a
generalization to our main result, we develop a meta-learning approach for the
estimation of general conditional functionals under covariate shift. We also
provide an extension to the instrumented DiD setting with non-compliance.
Empirical results demonstrate the superiority of our approach over existing
baselines.",http://arxiv.org/abs/2502.04699v1
"Quasinormal Modes and Dynamical Evolution of Scalar Fields in the
  Einstein-Bumblebee Theory with a Cosmological Constant",2025-02-07T09:34:29Z,"Hao Hu, Guoxiong Zhu","This paper investigates the dynamic behavior of static, spherically symmetric
black holes within the Einstein-Bumblebee gravity model with a cosmological
constant, focusing on scalar field perturbations. Through separation of the
angular components, the scalar field perturbations outside the black hole are
reduced to a purely radial main equation. The quasinormal modes (QNMs) of the
system are then determined via the WKB approximation in the frequency domain,
while the dynamic evolution of the system is examined in the time domain using
finite difference methods. The eigenfrequencies of the waveforms from the
time-domain evolution are fitted to cross-validate the frequency-domain
results. The study finds that the Lorentz violation parameter $ \ell $ and the
cosmological constant $ \Lambda $ significantly influence the QNMs.
Specifically, as $ \ell $ increases, the real and imaginary components of the
lower modes decrease, while in higher modes, the real part changes minimally,
and the imaginary part decreases rapidly. An increase in $ \Lambda $ similarly
results in a decrease in the overall QNM values. These results are supported by
the time-domain analysis, providing a clearer picture of how Lorentz symmetry
breaking affects the QNMs of de Sitter spacetime.",http://arxiv.org/abs/2502.04782v1
Impact-induced Vaporization During Accretion of Planetary Bodies,2025-02-07T09:45:19Z,"Adrien Saurety, Razvan Caracas, Sean N. Raymond","Giant impacts dominate the late stages of accretion of rocky planets. They
contribute to the heating, melting, and sometimes vaporizing of the bodies
involved in the impacts. Due to fractionation during melting and vaporization,
planet-building impacts can significantly change the composition and
geochemical signatures of rocky objects. Using first-principles molecular
dynamics simulations, we analyze the shock behavior of complex realistic
silicate systems, representative of both rocky bodies. We introduce a novel
criterion for vapor formation that uses entropy calculations to determine the
minimum impact velocity required to pass the threshold for vapor production. We
derive impact velocity criteria for vapor formation (7.1 km per s for
chondritic bodies) and show that this threshold is reached in 61 and 89 percent
of impacts in dynamical simulations of the late stages of accretion with
classical and annulus starting configuration (respectively) for analogs of
Earth. These outcomes should be nuanced by factors such as the impact angle and
the mass of the impacting bodies, which further influence the vaporization
dynamics and the resultant material distribution. Our findings indicate that
vaporization was common during accretion and likely played a crucial role in
shaping the early environments and material properties of terrestrial planets.",http://arxiv.org/abs/2502.04787v1
Monotonicity for solutions to semilinear problems in epigraphs,2025-02-07T10:17:04Z,"Nicolas Beuvin, Alberto Farina, Berardino Sciunzi","We consider positive solutions, possibly unbounded, to the semilinear
equation $-\Delta u=f(u)$ on continuous epigraphs bounded from below. Under the
homogeneous Dirichlet boundary condition, we prove new monotonicity results for
$u$, when $f$ is a (locally or globally) Lipschitz-continuous function
satisfying $ f(0) \geq 0$. As an application of our new monotonicity theorems,
we prove some classification and/or non-existence results. To prove our
results, we first establish some new comparison principles for semilinear
problems on general unbounded open sets of $\mathbb{R}^N$, and then we use them
to start and to complete a modified version of the moving plane method adapted
to the geometry of the epigraph $\Omega$. As a by-product of our analysis, we
also prove some new results of uniqueness and symmetry for solutions (possibly
unbounded and sign-changing) to the homogeneous Dirichlet BVP for the
semilinear Poisson equation in fairly general unbounded domains.",http://arxiv.org/abs/2502.04805v1
Describing Nonstationary Data Streams in Frequency Domain,2025-02-07T10:38:14Z,Joanna Komorniczak,"Concept drift is among the primary challenges faced by the data stream
processing methods. The drift detection strategies, designed to counteract the
negative consequences of such changes, often rely on analyzing the problem
metafeatures. This work presents the Frequency Filtering Metadescriptor -- a
tool for characterizing the data stream that searches for the informative
frequency components visible in the sample's feature vector. The frequencies
are filtered according to their variance across all available data batches. The
presented solution is capable of generating a metadescription of the data
stream, separating chunks into groups describing specific concepts on its
basis, and visualizing the frequencies in the original spatial domain. The
experimental analysis compared the proposed solution with two state-of-the-art
strategies and with the PCA baseline in the post-hoc concept identification
task. The research is followed by the identification of concepts in the
real-world data streams. The generalization in the frequency domain adapted in
the proposed solution allows to capture the complex feature dependencies as a
reduced number of frequency components, while maintaining the semantic meaning
of data.",http://arxiv.org/abs/2502.04813v1
"Ultraviolet Renormalization of Spin Boson Models I. Normal and
  2-Nilpotent Interactions",2025-02-07T12:28:05Z,"Benjamin Hinrichs, Jonas Lampart, Javier Valentín Martín","We study the ultraviolet problem for models of a finite-dimensional quantum
mechanical system linearly coupled to a bosonic quantum field, such as the
(many-)spin boson model or its rotating-wave approximation. If the state change
of the system upon emission or absorption of a boson is either given by a
normal matrix or by a 2-nilpotent one, which is the case for the previously
named examples, we prove an optimal renormalization result. We complement it,
by proving the norm resolvent convergence of appropriately regularized models
to the renormalized one. Our method consists of a dressing transformation
argument in the normal case and an appropriate interior boundary condition for
the 2-nilpotent case.",http://arxiv.org/abs/2502.04876v1
"Claim Extraction for Fact-Checking: Data, Models, and Automated Metrics",2025-02-07T14:20:45Z,"Herbert Ullrich, Tomáš Mlynář, Jan Drchal","In this paper, we explore the problem of Claim Extraction using one-to-many
text generation methods, comparing LLMs, small summarization models finetuned
for the task, and a previous NER-centric baseline QACG. As the current
publications on Claim Extraction, Fact Extraction, Claim Generation and
Check-worthy Claim Detection are quite scattered in their means and
terminology, we compile their common objectives, releasing the FEVERFact
dataset, with 17K atomic factual claims extracted from 4K contextualised
Wikipedia sentences, adapted from the original FEVER. We compile the known
objectives into an Evaluation framework of: Atomicity, Fluency,
Decontextualization, Faithfulness checked for each generated claim separately,
and Focus and Coverage measured against the full set of predicted claims for a
single input. For each metric, we implement a scale using a reduction to an
already-explored NLP task. We validate our metrics against human grading of
generic claims, to see that the model ranking on $F_{fact}$, our hardest
metric, did not change and the evaluation framework approximates human grading
very closely in terms of $F_1$ and RMSE.",http://arxiv.org/abs/2502.04955v1
"Fast Adaptive Anti-Jamming Channel Access via Deep Q Learning and
  Coarse-Grained Spectrum Prediction",2025-02-07T14:25:28Z,"Jianshu Zhang, Xiaofu Wu, Junquan Hu","This paper investigates the anti-jamming channel access problem in complex
and unknown jamming environments, where the jammer could dynamically adjust its
strategies to target different channels. Traditional channel hopping
anti-jamming approaches using fixed patterns are ineffective against such
dynamic jamming attacks. Although the emerging deep reinforcement learning
(DRL) based dynamic channel access approach could achieve the Nash equilibrium
under fast-changing jamming attacks, it requires extensive training episodes.
To address this issue, we propose a fast adaptive anti-jamming channel access
approach guided by the intuition of ``learning faster than the jammer"", where a
synchronously updated coarse-grained spectrum prediction serves as an auxiliary
task for the deep Q learning (DQN) based anti-jamming model. This helps the
model identify a superior Q-function compared to standard DRL while
significantly reducing the number of training episodes. Numerical results
indicate that the proposed approach significantly accelerates the rate of
convergence in model training, reducing the required training episodes by up to
70% compared to standard DRL. Additionally, it also achieves a 10% improvement
in throughput over NE strategies, owing to the effective use of coarse-grained
spectrum prediction.",http://arxiv.org/abs/2502.04963v1
New Security Challenges Towards In-Sensor Computing Systems,2025-02-07T16:09:47Z,"Mashrafi Kajol, Qiaoyan Yu","Data collection and processing in advanced health monitoring systems are
experiencing revolutionary change. In-Sensor Computing (ISC) systems emerge as
a promising alternative to save energy on massive data transmission,
analog-to-digital conversion, and ineffective processing. While the new
paradigm shift of ISC systems gains increasing attention, the highly compacted
systems could incur new challenges from a hardware security perspective. This
work first conducts a literature review to highlight the research trend of this
topic and then performs comprehensive analyses on the root of security
challenges. This is the first work that compares the security challenges of
traditional sensor-involved computing systems and emerging ISC systems.
Furthermore, new attack scenarios are predicted for board-, chip-, and
device-level ISC systems. Two proof-of-concept demos are provided to inspire
new countermeasure designs against unique hardware security threats in ISC
systems.",http://arxiv.org/abs/2502.05046v1
"Mining a Decade of Event Impacts on Contributor Dynamics in Ethereum: A
  Longitudinal Study",2025-02-07T16:24:13Z,"Matteo Vaccargiu, Sabrina Aufiero, Cheick Ba, Silvia Bartolucci, Richard Clegg, Daniel Graziotin, Rumyana Neykova, Roberto Tonelli, Giuseppe Destefanis","We analyze developer activity across 10 major Ethereum repositories (totaling
129884 commits, 40550 issues) spanning 10 years to examine how events such as
technical upgrades, market events, and community decisions impact development.
Through statistical, survival, and network analyses, we find that technical
events prompt increased activity before the event, followed by reduced commit
rates afterwards, whereas market events lead to more reactive development. Core
infrastructure repositories like Go-Ethereum exhibit faster issue resolution
compared to developer tools, and technical events enhance core team
collaboration. Our findings show how different types of events shape
development dynamics, offering insights for project managers and developers in
maintaining development momentum through major transitions. This work
contributes to understanding the resilience of development communities and
their adaptation to ecosystem changes.",http://arxiv.org/abs/2502.05054v1
Use of Winsome Robots for Understanding Human Feedback (UWU),2025-02-07T17:41:29Z,"Jessica Eggers, Angela Dai, Matthew C. Gombolay","As social robots become more common, many have adopted cute aesthetics aiming
to enhance user comfort and acceptance. However, the effect of this aesthetic
choice on human feedback in reinforcement learning scenarios remains unclear.
Previous research has shown that humans tend to give more positive than
negative feedback, which can cause failure to reach optimal robot behavior. We
hypothesize that this positive bias may be exacerbated by the robot's level of
perceived cuteness. To investigate, we conducted a user study where
participants critique a robot's trajectories while it performs a task. We then
analyzed the impact of the robot's aesthetic cuteness on the type of
participant feedback. Our results suggest that there is a shift in the ratio of
positive to negative feedback when perceived cuteness changes. In light of
this, we experiment with a stochastic version of TAMER which adapts based on
the user's level of positive feedback bias to mitigate these effects.",http://arxiv.org/abs/2502.05118v1
"Modelling hydrogen integration in energy system models: Best practices
  for policy insights",2025-01-21T14:20:37Z,"Muhammad Maladoh Bah, Sheng Wang, Mohsen Kia, Andrew Keane, Terence O'Donnell","The rapid emergence of hydrogen in long-term energy strategies requires a
broad understanding on how hydrogen is currently modelled in national energy
system models. This study provides a review on hydrogen representation within
selected energy system models that are tailored towards providing policy
insights. The paper adopts a multi-layered review approach and selects eleven
notable models for the review. The review covers hydrogen production, storage,
transportation, trade, demand, modeling strategies, and hydrogen policies. The
review suggests existing models would often opt for a simplified representation
that can capture each stage of the hydrogen supply chain. This approach allows
models to strike a balance between accuracy and preserving computational
resources. The paper provides several suggestions for modeling hydrogen in
national energy system models.",http://arxiv.org/abs/2502.05183v2
Regression and Forecasting of U.S. Stock Returns Based on LSTM,2025-02-03T19:26:44Z,"Shicheng Zhou, Zizhou Zhang, Rong Zhang, Yuchen Yin, Chia Hong Chang, Qinyan Shen","This paper analyses the investment returns of three stock sectors, Manuf,
Hitec, and Other, in the U.S. stock market, based on the Fama-French
three-factor model, the Carhart four-factor model, and the Fama-French
five-factor model, in order to test the validity of the Fama-French
three-factor model, the Carhart four-factor model, and the Fama-French
five-factor model for the three sectors of the market. French five-factor model
for the three sectors of the market. Also, the LSTM model is used to explore
the additional factors affecting stock returns. The empirical results show that
the Fama-French five-factor model has better validity for the three segments of
the market under study, and the LSTM model has the ability to capture the
factors affecting the returns of certain industries, and can better regress and
predict the stock returns of the relevant industries. Keywords- Fama-French
model; Carhart model; Factor model; LSTM model.",http://arxiv.org/abs/2502.05210v1
"Teaching An Old Dog New Tricks: Porting Legacy Code to Heterogeneous
  Compute Architectures With Automated Code Translation",2025-02-07T19:28:46Z,"Nicolas Nytko, Andrew Reisner, J. David Moulton, Luke N. Olson, Matthew West","Legacy codes are in ubiquitous use in scientific simulations; they are
well-tested and there is significant time investment in their use. However, one
challenge is the adoption of new, sometimes incompatible computing paradigms,
such as GPU hardware. In this paper, we explore using automated code
translation to enable execution of legacy multigrid solver code on GPUs without
significant time investment and while avoiding intrusive changes to the
codebase. We developed a thin, reusable translation layer that parses Fortran
2003 at compile time, interfacing with the existing library Loopy to transpile
to C++/GPU code, which is then managed by a custom MPI runtime system that we
created. With this low-effort approach, we are able to achieve a payoff of an
approximately 2-3x speedup over a full CPU socket, and 6x in multi-node
settings.",http://arxiv.org/abs/2502.05279v1
"Speejis: Enhancing User Experience of Mobile Voice Messaging with
  Automatic Visual Speech Emotion Cues",2025-02-07T19:56:45Z,"Ilhan Aslan, Carla F. Griggio, Henning Pohl, Timothy Merritt, Niels van Berkel","Mobile messaging apps offer an increasing range of emotional expressions,
such as emojis to help users manually augment their texting experiences.
Accessibility of such augmentations is limited in voice messaging. With the
term ""speejis"" we refer to accessible emojis and other visual speech emotion
cues that are created automatically from speech input alone. The paper presents
an implementation of speejis and reports on a user study (N=12) comparing the
UX of voice messaging with and without speejis. Results show significant
differences in measures such as attractiveness and stimulation and a clear
preference of all participants for messaging with speejis. We highlight the
benefits of using paralinguistic speech processing and continuous emotion
models to enable finer grained augmentations of emotion changes and transitions
within a single message in addition to augmentations of the overall tone of the
message.",http://arxiv.org/abs/2502.05296v1
"Analyzing public sentiment to gauge key stock events and determine
  volatility in conjunction with time and options premiums",2025-02-08T01:48:10Z,"SriVarsha Mulakala, Umesh Vangapally, Benjamin Larkey, Aidan Henrichs, Corey Wojslaw","Analyzing stocks and making higher accurate predictions on where the price is
heading continues to become more and more challenging therefore, we designed a
new financial algorithm that leverages social media sentiment analysis to
enhance the prediction of key stock earnings and associated volatility. Our
model integrates sentiment analysis and data retrieval techniques to extract
critical information from social media, analyze company financials, and compare
sentiments between Wall Street and the general public. This approach aims to
provide investors with timely data to execute trades based on key events,
rather than relying on long-term stock holding strategies. The stock market is
characterized by rapid data flow and fluctuating community sentiments, which
can significantly impact trading outcomes. Stock forecasting is complex given
its stochastic dynamic. Standard traditional prediction methods often overlook
key events and media engagement, focusing its practice into long-term
investment options. Our research seeks to change the stochastic dynamic to a
more predictable environment by examining the impact of media on stock
volatility, understanding and identifying sentiment differences between Wall
Street and retail investors, and evaluating the impact of various media
networks in predicting earning reports.",http://arxiv.org/abs/2502.05403v1
A Framework for On the Fly Input Refinement for Deep Learning Models,2025-02-08T05:41:01Z,Ravishka Rathnasuriya,"Advancements in deep learning have significantly improved model performance
across tasks involving code, text, and image processing. However, these models
still exhibit notable mispredictions in real-world applications, even when
trained on up-to-date data. Such failures often arise from slight variations in
inputs such as minor syntax changes in code, rephrasing in text, or subtle
lighting shifts in images that reveal inherent limitations in these models'
capability to generalize effectively. Traditional approaches to address these
challenges involve retraining, a resource-intensive process that demands
significant investments in data labeling, model updates, and redeployment. This
research introduces an adaptive, on-the-fly input refinement framework aimed at
improving model performance through input validation and transformation. The
input validation component detects inputs likely to cause errors, while input
transformation applies domain-specific adjustments to better align these inputs
with the model's handling capabilities. This dual strategy reduces
mispredictions across various domains, boosting model performance without
necessitating retraining. As a scalable and resource-efficient solution, this
framework holds significant promise for high-stakes applications in software
engineering, natural language processing, and computer vision.",http://arxiv.org/abs/2502.05456v1
"Closing the Responsibility Gap in AI-based Network Management: An
  Intelligent Audit System Approach",2025-02-08T15:30:25Z,"Emanuel Figetakis, Ahmed Refaey Hussein","Existing network paradigms have achieved lower downtime as well as a higher
Quality of Experience (QoE) through the use of Artificial Intelligence
(AI)-based network management tools. These AI management systems, allow for
automatic responses to changes in network conditions, lowering operation costs
for operators, and improving overall performance. While adopting AI-based
management tools enhance the overall network performance, it also introduce
challenges such as removing human supervision, privacy violations, algorithmic
bias, and model inaccuracies. Furthermore, AI-based agents that fail to address
these challenges should be culpable themselves rather than the network as a
whole. To address this accountability gap, a framework consisting of a Deep
Reinforcement Learning (DRL) model and a Machine Learning (ML) model is
proposed to identify and assign numerical values of responsibility to the
AI-based management agents involved in any decision-making regarding the
network conditions, which eventually affects the end-user. A simulation
environment was created for the framework to be trained using simulated network
operation parameters. The DRL model had a 96% accuracy during testing for
identifying the AI-based management agents, while the ML model using gradient
descent learned the network conditions at an 83% accuracy during testing.",http://arxiv.org/abs/2502.05608v1
"Transition from Regular Black Holes to Wormholes in Covariant Effective
  Quantum Gravity: Scattering, Quasinormal Modes, and Hawking Radiation",2025-02-08T20:44:31Z,"R. A. Konoplya, O. S. Stashko","Utilizing the Hamiltonian constraints approach, a quantum-corrected solution
has been derived \cite{Zhang:2024ney}, which describes either a regular black
hole or a traversable wormhole, contingent upon the value of the quantum
parameter. In this work, we compute the quasinormal modes associated with axial
gravitational and test fields' perturbations of these objects. We see that due
to quantum corrections near the event horizon, the first several overtones
deviate from their Schwarzschild values at an increasing rate. The transition
between the black hole and wormhole states is marked by modifications in the
late-time signal. Our findings reveal that the fundamental quasinormal modes of
quantum-corrected black holes exhibit only slight deviations from those of the
classical Schwarzschild solution. However, at the transition, the spectrum
undergoes significant changes, with the wormhole state characterized by
exceptionally long-lived quasinormal modes. In addition, we calculate
absorption cross-sections of partial waves, grey-body factors and energy
emission rates of Hawking radiation.",http://arxiv.org/abs/2502.05689v1
"I3S: Importance Sampling Subspace Selection for Low-Rank Optimization in
  LLM Pretraining",2025-02-09T06:30:19Z,"Haochen Zhang, Junze Yin, Guanchu Wang, Zirui Liu, Tianyi Zhang, Anshumali Shrivastava, Lin Yang, Vladimir Braverman","Low-rank optimization has emerged as a promising approach to enabling
memory-efficient training of large language models (LLMs). Existing low-rank
optimization methods typically project gradients onto a low-rank subspace,
reducing the memory cost of storing optimizer states. A key challenge in these
methods is identifying suitable subspaces to ensure an effective optimization
trajectory. Most existing approaches select the dominant subspace to preserve
gradient information, as this intuitively provides the best approximation.
However, we find that in practice, the dominant subspace stops changing during
pretraining, thereby constraining weight updates to similar subspaces.
  In this paper, we propose importance sampling subspace selection (I3S) for
low-rank optimization, which theoretically offers a comparable convergence rate
to the dominant subspace approach. Empirically, we demonstrate that I3S
significantly outperforms previous methods in LLM pretraining tasks.",http://arxiv.org/abs/2502.05790v1
De Finetti's problem with fixed transaction costs and regime switching,2025-02-09T10:21:47Z,"Wenyuan Wang, Zuo Quan Xu, Kazutoshi Yamazaki, Kaixin Yan, Xiaowen Zhou","In this paper, we examine a modified version of de Finetti's optimal dividend
problem, incorporating fixed transaction costs and altering the surplus process
by introducing two-valued drift and two-valued volatility coefficients. This
modification aims to capture the transitions or adjustments in the company's
financial status. We identify the optimal dividend strategy, which maximizes
the expected total net dividend payments (after accounting for transaction
costs) until ruin, as a two-barrier impulsive dividend strategy. Notably, the
optimal strategy can be explicitly determined for almost all scenarios
involving different drifts and volatility coefficients. Our primary focus is on
exploring how changes in drift and volatility coefficients influence the
optimal dividend strategy.",http://arxiv.org/abs/2502.05839v1
"Uniqueness of generalized conformal restriction measures and
  Malliavin-Kontsevich-Suhov measures for $c \in (0,1]$",2025-02-09T13:08:45Z,"Gefei Cai, Yifan Gao","In this paper, we present a unified approach to establish the uniqueness of
generalized conformal restriction measures with central charge $c \in (0, 1]$
in both chordal and radial cases, by relating these measures to the Brownian
loop soup. Our method also applies to the uniqueness of the
Malliavin-Kontsevich-Suhov loop measures for $c \in (0,1]$, which was recently
obtained in [Baverez-Jego, arXiv:2407.09080] for all $c \leq 1$ from a CFT
framework of SLE loop measures. In contrast, though only valid for $c \in
(0,1]$, our approach provides additional probabilistic insights, as it directly
links natural quantities of MKS measures to loop-soup observables.",http://arxiv.org/abs/2502.05890v4
"Topology Optimization considering Shielding and Penetrating Features
  based on Fictitious Physical Model",2025-02-09T13:30:10Z,"Daiki Soma, Kota Sakai, Takayuki Yamada","This paper proposes topology optimization for considering shielding and
penetrating features. Based on the fictitious physical model, which is a useful
approach to control geometric features, the proposed method analyzes fictitious
steady-state temperature fields and interprets target geometric features by
examining the temperature change. First, the concept of topology optimization
based on the level set method is introduced. Next, the basic idea of the
fictitious physical model for considering geometric features is explained.
Then, the differences between the shielding and penetrating features are
clarified, and the fictitious physical model for evaluating these features is
proposed. Furthermore, topology optimization for the minimum mean compliance
problem with geometric conditions is formulated. Finally, 2D and 3D numerical
examples are presented to validate the proposed method.",http://arxiv.org/abs/2502.05899v1
"Detection of Physiological Data Tampering Attacks with Quantum Machine
  Learning",2025-02-09T17:26:41Z,"Md. Saif Hassan Onim, Himanshu Thapliyal","The widespread use of cloud-based medical devices and wearable sensors has
made physiological data susceptible to tampering. These attacks can compromise
the reliability of healthcare systems which can be critical and
life-threatening. Detection of such data tampering is of immediate need.
Machine learning has been used to detect anomalies in datasets but the
performance of Quantum Machine Learning (QML) is still yet to be evaluated for
physiological sensor data. Thus, our study compares the effectiveness of QML
for detecting physiological data tampering, focusing on two types of white-box
attacks: data poisoning and adversarial perturbation. The results show that QML
models are better at identifying label-flipping attacks, achieving accuracy
rates of 75%-95% depending on the data and attack severity. This superior
performance is due to the ability of quantum algorithms to handle complex and
high-dimensional data. However, both QML and classical models struggle to
detect more sophisticated adversarial perturbation attacks, which subtly alter
data without changing its statistical properties. Although QML performed poorly
against this attack with around 45%-65% accuracy, it still outperformed
classical algorithms in some cases.",http://arxiv.org/abs/2502.05966v1
"An assessment of observational coverage and gaps for robust Sun to
  heliosphere integrated science",2025-02-09T21:21:44Z,"Yeimy J. Rivera, Samuel T. Badman","Understanding the generation and development of the continuous outflow from
the Sun requires tracing the physical conditions from deep in the corona to the
heliosphere. Detailed global observations of plasma state variables and the
magnetic field are needed to provide critical constraints to the underlying
physics driving models of the corona and solar wind. Key diagnostics of the
solar wind require measurements at its formation site and during its outflow to
continuously track it across rapidly changing regions of space. A unified view
of the solar wind is only possible through coordinated remote and in situ
observations that probe these different regions. Here, we discuss current
observational coverage and gaps of different plasma properties and review
recent coordinated studies. We highlight how these efforts may become more
routine with the launch of upcoming and planned missions.",http://arxiv.org/abs/2502.06036v2
Effects of particle angularity on granular self-organization,2025-02-10T00:48:55Z,"Dominik Krengel, Haoran Jiang, Takashi Matsushima, Raphael Blumenfeld","Recent studies of two-dimensional poly-disperse disc systems revealed a
coordinated self-organisation of cell stresses and shapes, with certain
distributions collapsing onto a master form for many processes, size
distributions, friction coefficients, and cell orders. Here we examine the
effects of grain angularity on the indicators of self-organisation, using
simulations of bi-disperse regular $N$-polygons and varying $N$ systematically.
We find that: the strong correlation between local cell stresses and
orientations, as well as the collapses of the conditional distributions of
scaled cell stress ratios to a master Weibull form for all cell orders $k$, are
independent of angularity and friction coefficient. In contrast, increasing
angularity makes the collapses of the conditional distributions sensitive to
changes in the friction coefficient.",http://arxiv.org/abs/2502.06085v1
Nonlinearity-induced Fractional Thouless Pumping of Solitons,2025-02-10T03:45:29Z,"Yu-Liang Tao, Yongping Zhang, Yong Xu","Recent studies have shown that a soliton can be {\it fractionally}
transported by slowly varying a system parameter over one period in a nonlinear
system. This phenomenon is attributed to the nontrivial topology of the
corresponding energy bands of a linear Hamiltonian. Here we find the occurrence
of fractional Thouless pumping of solitons in a nonlinear off-diagonal
Aubry-Andr\'{e}-Harper model. Surprisingly, this happens despite the fact that
all the energy bands of the linear Hamiltonian are topologically trivial,
indicating that nonlinearity can induce fractional Thouless pumping of
solitons. Specifically, our results show that a soliton can be pumped across
one unit cell over one, two, three or four pump periods, implying an average
displacement of $1$, $1/2$, $1/3$ or $1/4$ unit cells per cycle, respectively.
We attribute these behaviors to changes in on-site potentials induced by a
soliton solution, leading to the nontrivial topology for the modified linear
Hamiltonian. Given that our model relies solely on varying nearest-neighbor
hoppings, it is readily implementable on existing state-of-the-art photonic
platforms.",http://arxiv.org/abs/2502.06131v1
"Timing Matters: How Using LLMs at Different Timings Influences Writers'
  Perceptions and Ideation Outcomes in AI-Assisted Ideation",2025-02-10T06:51:50Z,"Peinuan Qin, Chi-Lan Yang, Jingshu Li, Jing Wen, Yi-Chieh Lee","Large Language Models (LLMs) have been widely used to support ideation in the
writing process. However, whether generating ideas with the help of LLMs leads
to idea fixation or idea expansion is unclear. This study examines how
different timings of LLM usage - either at the beginning or after independent
ideation - affect people's perceptions and ideation outcomes in a writing task.
In a controlled experiment with 60 participants, we found that using LLMs from
the beginning reduced the number of original ideas and lowered creative
self-efficacy and self-credit, mediated by changes in autonomy and ownership.
We discuss the challenges and opportunities associated with using LLMs to
assist in idea generation. We propose delaying the use of LLMs to support
ideation while considering users' self-efficacy, autonomy, and ownership of the
ideation outcomes.",http://arxiv.org/abs/2502.06197v1
Performance Analysis of Multi-Hop Networks at Terahertz Frequencies,2025-02-10T10:29:46Z,"Sara Cavallero, Andrea Pumilia, Giampaolo Cuozzo, Alessia Tarozzi, Chiara Buratti, Roberto Verdone","The emergence of THz (Terahertz) frequency wireless networks holds great
potential for advancing various high-demand services, including Industrial
Internet of Things (IIoT) applications. These use cases benefit significantly
from the ultra-high data rates, low latency, and high spatial resolution
offered by THz frequencies. However, a primary well-known challenge of THz
networks is their limited coverage range due to high path loss and
vulnerability to obstructions. This paper addresses this limitation by
proposing two novel multi-hop protocols, Table-Less (TL) and Table-Based (TB),
respectively, both avoiding centralized control and/or control plane
transmissions. Indeed, both solutions are distributed, simple, and rapidly
adaptable to network changes. Simulation results demonstrate the effectiveness
of our approaches, as well as revealing interesting trade-offs between TL and
TB routing protocols, both in a real IIoT THz network and under static and
dynamic conditions.",http://arxiv.org/abs/2502.06330v1
"Tailoring indistinguishability of photons using longitudinal spatial
  coherence",2025-02-10T10:34:09Z,"Preeti Sharma, Gaytri Arya, Bhaskar Kanseri","Methods to generate photons with tailored indistinguishability are central to
developing photonic quantum technologies and making fundamental tests of
quantum physics. This study introduces a novel method for manipulating
effective longitudinal spatial coherence (LSC) of biphotons, controlling their
indistinguishability in a significant manner. The experimental results show
that, instead of tailoring the frequency spectrum of the interfering photons,
changing their LSC also leads to controlling the width of Hong-Ou-Mandel dip as
validated by the theoretical calculations. This powerful approach not only
modifies the conventional wisdom claiming only frequency width responsible for
indistinguishability control of photons but also positions the LSC as a
promising tool for fine-tuning the longitudinal coherence of photons, thereby
expanding their potential use in quantum science and technologies.",http://arxiv.org/abs/2502.06333v1
"New opportunities for high pressure hydrogen achieved by fullerane
  vibrating modes: an ab initio study",2025-02-10T13:18:00Z,"Leonard Constantin Gebac, Vasile Bercu","The encapsulation of hydrogen within fullerene/fullerane cages offers a
promising avenue for studying high pressure hydrogen dynamics. Through ab
initio molecular dynamics simulations, we investigate the behavior of a system
consisting of hydrogen atoms enclosed in a \ch{C20H20} dodecahedrane. Our
findings reveal significant structural and dynamical changes as the cage
undergoes compression, corresponding to radial symmetric vibration. We analyze
geometric, energetic, and thermodynamic parameters, highlighting correlations
and observing behavior analogous to high pressure phases of hydrogen. Notably,
our study bridges the gap between theory and experiment by proposing a novel
approach to achieving high pressures and temperatures experimentally. These
results not only contribute to the understanding of hydrogen behavior under
extreme conditions but also hold implications for the quest to attain metallic
hydrogen - a milestone in materials science with potential applications in
various fields.",http://arxiv.org/abs/2502.06441v1
"Interpretation of 95 GeV Excess within the Georgi-Machacek Model in
  Light of Positive Definiteness Constraints",2025-02-10T13:20:03Z,"Xiaokang Du, Huiling Liu, Qin Chang","The recent observation of a di-photon excess around 95 GeV by the CMS and
ATLAS Collaborations, along with the $b\bar{b}$ excess reported by the LEP
Collaboration in the same mass region, has drawn significant interest in the
possibility of new physics beyond the Standard Model (SM). The Georgi-Machacek
(GM) model, which extends the Higgs sector of the SM by introducing additional
triplet scalars while preserving custodial symmetry at tree level, provides a
compelling framework to explain both excesses simultaneously via a light
custodial singlet Higgs. In this work, we investigate whether the GM model can
still accommodate these excesses when taking into account newly proposed vacuum
stability constraints, particularly the positive definiteness conditions. Our
numerical analysis not only confirms the existence of a viable parameter space
capable of explaining the 95 GeV excesses, but also demonstrates that, compared
to traditional tree-level constraints at the electroweak scale, the positive
definiteness conditions further expand the allowed parameter space, thereby
enhancing the viability of the GM model. Furthermore, we emphasize that future
collider experiments will play a crucial role in testing this interpretation by
refining Higgs coupling measurements and searching for additional Higgs bosons.",http://arxiv.org/abs/2502.06444v1
Group-CLIP Uncertainty Modeling for Group Re-Identification,2025-02-10T13:41:35Z,"Qingxin Zhang, Haoyan Wei, Yang Qian","Group Re-Identification (Group ReID) aims matching groups of pedestrians
across non-overlapping cameras. Unlike single-person ReID, Group ReID focuses
more on the changes in group structure, emphasizing the number of members and
their spatial arrangement. However, most methods rely on certainty-based
models, which consider only the specific group structures in the group images,
often failing to match unseen group configurations. To this end, we propose a
novel Group-CLIP UncertaintyModeling (GCUM) approach that adapts group text
descriptions to undetermined accommodate member and layout variations.
Specifically, we design a Member Variant Simulation (MVS)module that simulates
member exclusions using a Bernoulli distribution and a Group Layout Adaptation
(GLA) module that generates uncertain group text descriptions with
identity-specific tokens. In addition, we design a Group
RelationshipConstruction Encoder (GRCE) that uses group features to refine
individual features, and employ cross-modal contrastive loss to obtain
generalizable knowledge from group text descriptions. It is worth noting that
we are the first to employ CLIP to GroupReID, and extensive experiments show
that GCUM significantly outperforms state-of-the-art Group ReID methods.",http://arxiv.org/abs/2502.06460v1
Quicker flocking in aligning active matters for noisier beginning,2025-02-10T13:59:33Z,"Sohini Chatterjee, Sohom Das, Purnendu Pathak, Tanay Paul, Subir K. Das","The constituents in a class of active matter systems change their directions
of motion by being influenced by the velocities of the neighbors. Such systems
may undergo phase transitions, with respect to ordering in the velocity field,
as well as clustering in the density field, when the strength of an externally
imposed noise is varied. Via computer simulations, with a well-known model,
that faithfully represents these systems, we show that evolutions in both
clustering and ordering exhibit certain interesting features that were hitherto
unrealized. The transformations occur quicker, following quenches to a fixed
final state, below the transition point, for disordered starting states that
are farther away from the ``critical"" noise strength. This implies earliest
arrival of the farthest, at a given destination. Detailed analysis of the
results, combined with the outcomes from a similar study of para- to
ferromagnetic transitions, show that the variation in critical fluctuations in
the initial configurations can lead to such interesting effect. We quantify
this via the Ornstein-Zernike theory.",http://arxiv.org/abs/2502.06482v1
Boost-and-Skip: A Simple Guidance-Free Diffusion for Minority Generation,2025-02-10T14:37:26Z,"Soobin Um, Beomsu Kim, Jong Chul Ye","Minority samples are underrepresented instances located in low-density
regions of a data manifold, and are valuable in many generative AI
applications, such as data augmentation, creative content generation, etc.
Unfortunately, existing diffusion-based minority generators often rely on
computationally expensive guidance dedicated for minority generation. To
address this, here we present a simple yet powerful guidance-free approach
called Boost-and-Skip for generating minority samples using diffusion models.
The key advantage of our framework requires only two minimal changes to
standard generative processes: (i) variance-boosted initialization and (ii)
timestep skipping. We highlight that these seemingly-trivial modifications are
supported by solid theoretical and empirical evidence, thereby effectively
promoting emergence of underrepresented minority features. Our comprehensive
experiments demonstrate that Boost-and-Skip greatly enhances the capability of
generating minority samples, even rivaling guidance-based state-of-the-art
approaches while requiring significantly fewer computations.",http://arxiv.org/abs/2502.06516v1
OpenMM-MiMiC Interface for Efficient and Flexible Multiscale Simulations,2025-02-10T15:04:39Z,"Andrea Levy, Andrej Antalík, Jógvan Magnus Haugaard Olsen, Ursula Rothlisberger","MiMiC is a flexible and efficient framework for multiscale simulations in
which different subsystems are treated by individual client programs. In this
work, we present a new interface with OpenMM to be used as an MM client program
and we demonstrate its efficiency for QM/MM MD simulations. Apart from its high
performance, especially on GPUs, and a wide selection of features, OpenMM is a
highly-flexible and easily-extensible program, ideal for the development of
novel multiscale methods. Thanks to the open-ended design of MiMiC, the
OpenMM-MiMiC interface will automatically support any new QM client program
interfaced with MiMiC for QM/MM and, with minimal changes needed, new
multiscale methods implemented, opening up new research directions beyond
electrostatic embedding QM/MM.",http://arxiv.org/abs/2502.06539v1
"LiveForesighter: Generating Future Information for Live-Streaming
  Recommendations at Kuaishou",2025-02-10T15:24:55Z,"Yucheng Lu, Jiangxia Cao, Xu Kuan, Wei Cheng, Wei Jiang, Jiaming Zhang, Yang Shuang, Liu Zhaojie, Liyin Hong","Live-streaming, as a new-generation media to connect users and authors, has
attracted a lot of attention and experienced rapid growth in recent years.
Compared with the content-static short-video recommendation, the live-streaming
recommendation faces more challenges in giving our users a satisfactory
experience: (1) Live-streaming content is dynamically ever-changing along time.
(2) valuable behaviors (e.g., send digital-gift, buy products) always require
users to watch for a long-time (>10 min). Combining the two attributes, here
raising a challenging question for live-streaming recommendation: How to
discover the live-streamings that the content user is interested in at the
current moment, and further a period in the future?",http://arxiv.org/abs/2502.06557v1
"Pinning Is Futile: You Need More Than Local Dependency Versioning to
  Defend against Supply Chain Attacks",2025-02-10T16:50:48Z,"Hao He, Bogdan Vasilescu, Christian Kästner","Recent high-profile incidents in open-source software have greatly raised
practitioner attention on software supply chain attacks. To guard against
potential malicious package updates, security practitioners advocate pinning
dependency to specific versions rather than floating in version ranges.
However, it remains controversial whether pinning carries a meaningful security
benefit that outweighs the cost of maintaining outdated and possibly vulnerable
dependencies. In this paper, we quantify, through counterfactual analysis and
simulations, the security and maintenance impact of version constraints in the
npm ecosystem. By simulating dependency resolutions over historical time
points, we find that pinning direct dependencies not only (as expected)
increases the cost of maintaining vulnerable and outdated dependencies, but
also (surprisingly) even increases the risk of exposure to malicious package
updates in larger dependency graphs due to the specifics of npm's dependency
resolution mechanism. Finally, we explore collective pinning strategies to
secure the ecosystem against supply chain attacks, suggesting specific changes
to npm to enable such interventions. Our study provides guidance for
practitioners and tool designers to manage their supply chains more securely.",http://arxiv.org/abs/2502.06662v1
Application of Artificial Intelligence (AI) in Civil Engineering,2025-02-10T17:55:52Z,"Temitope Funmilayo Awolusi, Bernard Chukwuemeka Finbarrs-Ezema, Isaac Munachimdinamma Chukwudulue, Marc Azab","Hard computing generally deals with precise data, which provides ideal
solutions to problems. However, in the civil engineering field, amongst other
disciplines, that is not always the case as real-world systems are continuously
changing. Here lies the need to explore soft computing methods and artificial
intelligence to solve civil engineering shortcomings. The integration of
advanced computational models, including Artificial Neural Networks (ANNs),
Fuzzy Logic, Genetic Algorithms (GAs), and Probabilistic Reasoning, has
revolutionized the domain of civil engineering. These models have significantly
advanced diverse sub-fields by offering innovative solutions and improved
analysis capabilities. Sub-fields such as: slope stability analysis, bearing
capacity, water quality and treatment, transportation systems, air quality,
structural materials, etc. ANNs predict non-linearities and provide accurate
estimates. Fuzzy logic uses an efficient decision-making process to provide a
more precise assessment of systems. Lastly, while GAs optimizes models (based
on evolutionary processes) for better outcomes, probabilistic reasoning lowers
their statistical uncertainties.",http://arxiv.org/abs/2502.06727v1
Institutional Preferences in the Laboratory,2025-02-10T18:17:16Z,"Qiankun Zhong, Nori Jacoby, Ofer Tchernichovski, Seth Frey","Getting a group to adopt cooperative norms is an enduring challenge. But in
real-world settings, individuals don't just passively accept static
environments, they act both within and upon the social systems that structure
their interactions. Should we expect the dynamism of player-driven changes to
the ""rules of the game"" to hinder cooperation -- because of the substantial
added complexity -- or help it, as prosocial agents tweak their environment
toward non-zero-sum games? We introduce a laboratory setting to test whether
groups can guide themselves to cooperative outcomes by manipulating the
environmental parameters that shape their emergent cooperation process. We test
for cooperation in a set of economic games that impose different social
dilemmas. These games vary independently in the institutional features of
stability, efficiency, and fairness. By offering agency over behavior along
with second-order agency over the rules of the game, we understand emergent
cooperation in naturalistic settings in which the rules of the game are
themselves dynamic and subject to choice. The literature on transfer learning
in games suggests that interactions between features are important and might
aid or hinder the transfer of cooperative learning to new settings.",http://arxiv.org/abs/2502.06748v1
DeepCell: Multiview Representation Learning for Post-Mapping Netlists,2025-02-05T02:39:47Z,"Zhengyuan Shi, Chengyu Ma, Ziyang Zheng, Lingfeng Zhou, Hongyang Pan, Wentao Jiang, Fan Yang, Xiaoyan Yang, Zhufei Chu, Qiang Xu","Representation learning for post-mapping (PM) netlists is a critical
challenge in Electronic Design Automation (EDA), driven by the diverse and
complex nature of modern circuit designs. Existing approaches focus on
intermediate representations like And-Inverter Graphs (AIGs), limiting their
applicability to post-synthesis stages. We introduce DeepCell, a multiview
representation learning framework that integrates structural and functional
insights from both PM netlists and AIGs to learn rich, generalizable
embeddings. At its core, DeepCell employs the novel Mask Circuit Modeling (MCM)
mechanism, which refines PM netlist representations in a self-supervised manner
using pretrained AIG encoders. DeepCell sets a new benchmark in PM netlist
representation, outperforming existing methods in predictive accuracy and
reconstruction fidelity. To validate its efficacy, we apply DeepCell to
functional Engineering Change Orders (ECO), achieving significant reductions in
patch generation costs and runtime while improving patch quality.",http://arxiv.org/abs/2502.06816v1
"Emergence of Episodic Memory in Transformers: Characterizing Changes in
  Temporal Structure of Attention Scores During Training",2025-02-09T20:20:37Z,"Deven Mahesh Mistry, Anooshka Bajaj, Yash Aggarwal, Sahaj Singh Maini, Zoran Tiganj","We investigate in-context temporal biases in attention heads and transformer
outputs. Using cognitive science methodologies, we analyze attention scores and
outputs of the GPT-2 models of varying sizes. Across attention heads, we
observe effects characteristic of human episodic memory, including temporal
contiguity, primacy and recency. Transformer outputs demonstrate a tendency
toward in-context serial recall. Importantly, this effect is eliminated after
the ablation of the induction heads, which are the driving force behind the
contiguity effect. Our findings offer insights into how transformers organize
information temporally during in-context learning, shedding light on their
similarities and differences with human memory and learning.",http://arxiv.org/abs/2502.06902v1
Quasilattices of the Spectre monotile,2025-02-10T18:45:55Z,"Henning U. Voss, Douglas J. Ballon","The Spectre is a family of recently discovered aperiodic monotiles that tile
the plane only in non-periodic ways, and novel physical phenomena have been
predicted for planar systems made of aperiodic monotiles. It is shown that
point decorations of Tile(1,1), the base tile for all Spectres, supports the
generation of a large variety of non-periodic quasilattices, in contrast to
Bravais-lattices in which all point decorations would be periodic. A lattice
generating function is introduced as a mapping from point decorations to
quasilattice space, and investigated systematically. It is found that some
lattices result from the properties of nearest-neighbor distances of point
decorations, and that other lattices show near-periodicity in projections along
one of the symmetry axes of the tiling. It is concluded that the lattice
generating function can serve as a template for the design of physical
potential landscapes that can be controlled by the point decoration as a
parameter.",http://arxiv.org/abs/2502.06926v2
"Collective flavor conversions are interactions of neutrinos with
  quantized flavor waves",2025-02-10T19:00:00Z,"Damiano F. G. Fiorillo, Georg G. Raffelt","Collective oscillations in dense neutrino gases (flavor waves) are notable
for their instabilities that cause fast flavor conversion. We develop a quantum
theory of interacting neutrinos and flavor wave quanta, which are analogous to
plasmons, but also carry flavor. The emission or absorption of such flavor
plasmons $\psi$, or flavomons, changes the neutrino flavor. When an angular
crossing occurs, the process $\nu_\mu\to\nu_e+\psi$ is more rapid than its
inverse along the direction of the crossing, triggering stimulated $\psi$
emission and fast instability. Calculating the rate via Feynman diagrams
matches the fast instability growth rate. Our novel $\nu$ and $\psi$ kinetic
equations, corresponding to quasi-linear theory, describe instability evolution
without resolving the small scales of the flavomon wavelength, potentially
overcoming the main challenge of fast flavor evolution.",http://arxiv.org/abs/2502.06935v1
Large thermoelectric spin-valve effect with a superconductor,2025-02-10T19:02:07Z,"Pablo Tuero, Johanne Bratland Tjernshaugen, Carlos Sanchez, César Gonzalez-Ruano, Yuan Lu, Jacob Linder, Farkhad G. Aliev","Recent studies have revealed magnetically controllable thermoelectric effects
in superconductor/ferromagnet (S/F) structures. A tunable cryogenic
thermoelectric generator needs not only a high conversion factor between
electricity and heat, but also a large change in the thermoelectric output when
switching the magnetic state of the device. Here, we experimentally measure and
numerically model thermoelectric effects in fully epitaxial F/S/F junctions
based on commercially available, easily grown materials, as well as their
dependence on the magnetic configuration of the F electrodes. We observe
sizeable Seebeck coefficients for the parallel alignment of the ferromagnetic
electrodes, reaching values of about $100$~$\mu$V/K. Importantly, we find a
decrease of the thermoelectric signal of more than an order of magnitude when
switching from a parallel to an antiparallel configuration, constituting a
large thermoelectric spin-valve effect. Theoretical modeling based on a
self-consistent non-equilibrium Keldysh-Usadel Green function theory, combined
with micromagnetic simulations, qualitatively reproduce the experimental
findings. These findings pave the way for the development of efficient and
versatile cryogenic thermoelectric heat engines.",http://arxiv.org/abs/2502.06962v1
"Representational Alignment with Chemical Induced Fit for Molecular
  Relational Learning",2025-02-07T09:29:21Z,"Peiliang Zhang, Jingling Yuan, Qing Xie, Yongjun Zhu, Lin Li","Molecular Relational Learning (MRL) is widely applied in natural sciences to
predict relationships between molecular pairs by extracting structural
features. The representational similarity between substructure pairs determines
the functional compatibility of molecular binding sites. Nevertheless, aligning
substructure representations by attention mechanisms lacks guidance from
chemical knowledge, resulting in unstable model performance in chemical space
(\textit{e.g.}, functional group, scaffold) shifted data. With theoretical
justification, we propose the \textbf{Re}presentational \textbf{Align}ment with
Chemical Induced \textbf{Fit} (ReAlignFit) to enhance the stability of MRL.
ReAlignFit dynamically aligns substructure representation in MRL by introducing
chemical Induced Fit-based inductive bias. In the induction process, we design
the Bias Correction Function based on substructure edge reconstruction to align
representations between substructure pairs by simulating chemical
conformational changes (dynamic combination of substructures). ReAlignFit
further integrates the Subgraph Information Bottleneck during fit process to
refine and optimize substructure pairs exhibiting high chemical functional
compatibility, leveraging them to generate molecular embeddings. Experimental
results on nine datasets demonstrate that ReAlignFit outperforms
state-of-the-art models in two tasks and significantly enhances model's
stability in both rule-shifted and scaffold-shifted data distributions.",http://arxiv.org/abs/2502.07027v1
"Leveraging Allophony in Self-Supervised Speech Models for Atypical
  Pronunciation Assessment",2025-02-10T20:46:42Z,"Kwanghee Choi, Eunjung Yeo, Kalvin Chang, Shinji Watanabe, David Mortensen","Allophony refers to the variation in the phonetic realization of a phoneme
based on its phonetic environment. Modeling allophones is crucial for atypical
pronunciation assessment, which involves distinguishing atypical from typical
pronunciations. However, recent phoneme classifier-based approaches often
simplify this by treating various realizations as a single phoneme, bypassing
the complexity of modeling allophonic variation. Motivated by the acoustic
modeling capabilities of frozen self-supervised speech model (S3M) features, we
propose MixGoP, a novel approach that leverages Gaussian mixture models to
model phoneme distributions with multiple subclusters. Our experiments show
that MixGoP achieves state-of-the-art performance across four out of five
datasets, including dysarthric and non-native speech. Our analysis further
suggests that S3M features capture allophonic variation more effectively than
MFCCs and Mel spectrograms, highlighting the benefits of integrating MixGoP
with S3M features.",http://arxiv.org/abs/2502.07029v1
SnipGen: A Mining Repository Framework for Evaluating LLMs for Code,2025-02-10T21:28:15Z,"Daniel Rodriguez-Cardenas, Alejandro Velasco, Denys Poshyvanyk","Language Models (LLMs), such as transformer-based neural networks trained on
billions of parameters, have become increasingly prevalent in software
engineering (SE). These models, trained on extensive datasets that include code
repositories, exhibit remarkable capabilities for SE tasks. However, evaluating
their effectiveness poses significant challenges, primarily due to the
potential overlap between the datasets used for training and those employed for
evaluation. To address this issue, we introduce SnipGen, a comprehensive
repository mining framework designed to leverage prompt engineering across
various downstream tasks for code generation. SnipGen aims to mitigate data
contamination by generating robust testbeds and crafting tailored data points
to assist researchers and practitioners in evaluating LLMs for code-related
tasks. In our exploratory study, SnipGen mined approximately 227K data points
from 338K recent code changes in GitHub commits, focusing on method-level
granularity. SnipGen features a collection of prompt templates that can be
combined to create a Chain-of-Thought-like sequence of prompts, enabling a
nuanced assessment of LLMs' code generation quality. By providing the mining
tool, the methodology, and the dataset, SnipGen empowers researchers and
practitioners to rigorously evaluate and interpret LLMs' performance in
software engineering contexts.",http://arxiv.org/abs/2502.07046v2
Autonomous Deep Agent,2025-02-10T21:46:54Z,"Amy Yu, Erik Lebedev, Lincoln Everett, Xiaoxin Chen, Terry Chen","This technical brief introduces Deep Agent, an advanced autonomous AI system
designed to manage complex multi-phase tasks through a novel hierarchical task
management architecture. The system's foundation is built on our Hierarchical
Task DAG (HTDAG) framework, which dynamically decomposes high-level objectives
into manageable sub-tasks while rigorously maintaining dependencies and
execution coherence. Deep Agent advances beyond traditional agent systems
through three key innovations: First, it implements a recursive two-stage
planner-executor architecture that enables continuous task refinement and
adaptation as circumstances change. Second, it features an Autonomous API &
Tool Creation (AATC) system that automatically generates reusable components
from UI interactions, substantially reducing operational costs for similar
tasks. Third, it incorporates Prompt Tweaking Engine and Autonomous Prompt
Feedback Learning components that optimize Large Language Model prompts for
specific scenarios, enhancing both inference accuracy and operational
stability. These components are integrated to form a service infrastructure
that manages user contexts, handles complex task dependencies, and orchestrates
end-to-end agentic workflow execution. Through this sophisticated architecture,
Deep Agent establishes a novel paradigm in self-governing AI systems,
demonstrating robust capability to independently handle intricate, multi-step
tasks while maintaining consistent efficiency and reliability through
continuous self-optimization.",http://arxiv.org/abs/2502.07056v1
"Precision Control of Resistive Power in Kibble Balance Coils: An
  Advanced Method for Minimizing Temperature-Related Magnetic Errors",2025-02-11T05:08:46Z,"Weibo Liu, Stephan Schlamminger, Shisong Li","Temperature changes affect the coercivity of permanent magnets, thereby
impacting the $Bl$ factor and potentially introducing systematic errors in
Kibble balance measurements. While the thermal-magnetic effect is negligible in
large magnet systems, it increases substantially as the magnet size decreases,
posing an engineering difficulty for tabletop Kibble balance systems. We
discuss the mechanism of thermal-magnetic effects through finite element
analysis, which has not been sufficiently emphasized in previous studies. A
bifilar-coil power regulator is proposed to eliminate thermal-magnetic errors
in Kibble balances. The approach aims to keep the power of the internal heating
source -- coil ohmic power -- constant over time, allowing the $Bl$ drift to be
mitigated through ABA or ABBA measurement sequences. Experimental results
validate the proposal, demonstrating that the thermal effect can be reduced by
more than two orders of magnitude compared to the conventional two-mode,
two-phase measurement scheme, and by about one order of magnitude compared to
the one-mode, two-phase scheme. The proposed approach can eliminate the
influence of thermal-magnetic effects on the measurement results, thus further
breaking down the limitations on the minimum size of tabletop Kibble balances.",http://arxiv.org/abs/2502.07264v1
Mixed-state geometric phases of coherent and squeezed spin states,2025-02-11T05:32:27Z,"Xin Wang, Jia-Chen Tang, Xu-Yang Hou, Hao Guo, Chih-Chun Chien","Two mixed-state geometric phases, known as the Uhlmann phase and
interferometric phase (IGP), of spin coherent states (CSSs) and spin squeezed
states (SSSs) are analyzed. While each phase follows its parallel-transport
condition, we also consider the non-adiabatic IGP for arbitrary unitary
evolution beyond parallel transport. For the $j=3/2$ CSS, the Uhlmann phase
shows temperature-induced topological phase transitions with jumps. The IGP and
non-adiabatic IGP for the $j=3/2$ CSS also exhibits temperature-induced jumps.
In contrast, the Uhlmann phase of the $j=1$ SSS exhibits smooth behavior
without any temperature-induced transition. Interestingly, the
parallel-transport condition of the IGP of the $j=1$ SSS in general does not
allow a solution at finite temperature. Instead, the non-adiabatic IGP for the
$j=1$ SSS has a solution showing smooth behavior as the squeezing parameter and
temperature change. We also briefly discuss possible experimental implications
and simulations.",http://arxiv.org/abs/2502.07268v1
"MIGT: Memory Instance Gated Transformer Framework for Financial
  Portfolio Management",2025-02-11T05:54:42Z,"Fengchen Gu, Angelos Stefanidis, Ángel García-Fernández, Jionglong Su, Huakang Li","Deep reinforcement learning (DRL) has been applied in financial portfolio
management to improve returns in changing market conditions. However, unlike
most fields where DRL is widely used, the stock market is more volatile and
dynamic as it is affected by several factors such as global events and investor
sentiment. Therefore, it remains a challenge to construct a DRL-based portfolio
management framework with strong return capability, stable training, and
generalization ability. This study introduces a new framework utilizing the
Memory Instance Gated Transformer (MIGT) for effective portfolio management. By
incorporating a novel Gated Instance Attention module, which combines a
transformer variant, instance normalization, and a Lite Gate Unit, our approach
aims to maximize investment returns while ensuring the learning process's
stability and reducing outlier impacts. Tested on the Dow Jones Industrial
Average 30, our framework's performance is evaluated against fifteen other
strategies using key financial metrics like the cumulative return and
risk-return ratios (Sharpe, Sortino, and Omega ratios). The results highlight
MIGT's advantage, showcasing at least a 9.75% improvement in cumulative returns
and a minimum 2.36% increase in risk-return ratios over competing strategies,
marking a significant advancement in DRL for portfolio management.",http://arxiv.org/abs/2502.07280v1
Spreading dynamics of information on online social networks,2025-02-11T06:30:48Z,"Fanhui Meng, Jiarong Xie, Jiachen Sun, Cong Xu, Yutian Zeng, Xiangrong Wang, Tao Jia, Shuhong Huang, Youjin Deng, Yanqing Hu","Social media is profoundly changing our society with its unprecedented
spreading power. Due to the complexity of human behaviors and the diversity of
massive messages, the information spreading dynamics are complicated, and the
reported mechanisms are different and even controversial. Based on data from
mainstream social media platforms, including WeChat, Weibo, and Twitter,
cumulatively encompassing a total of 7.45 billion users, we uncover a
ubiquitous mechanism that the information spreading dynamics are basically
driven by the interplay of social reinforcement and social weakening effects.
Accordingly, we propose a concise equation, which, surprisingly, can well
describe all the empirical large-scale spreading trajectories. Our theory
resolves a number of controversial claims and satisfactorily explains many
phenomena previously observed. It also reveals that the highly clustered nature
of social networks can lead to rapid and high-frequency information bursts with
relatively small coverage per burst. This vital feature enables social media to
have a high capacity and diversity for information dissemination, beneficial
for its ecological development.",http://arxiv.org/abs/2502.07291v1
"Aligning Large Language Models to Follow Instructions and Hallucinate
  Less via Effective Data Filtering",2025-02-11T08:05:56Z,"Shuzheng Si, Haozhe Zhao, Gang Chen, Cheng Gao, Yuzhuo Bai, Zhitong Wang, Kaikai An, Kangyang Luo, Chen Qian, Fanchao Qi, Baobao Chang, Maosong Sun","Training LLMs on data containing unfamiliar knowledge during the instruction
tuning stage can encourage hallucinations. To address this challenge, we
introduce NOVA, a novel framework designed to identify high-quality data that
aligns well with the LLM's learned knowledge to reduce hallucinations. NOVA
includes Internal Consistency Probing (ICP) and Semantic Equivalence
Identification (SEI) to measure how familiar the LLM is with instruction data.
Specifically, ICP evaluates the LLM's understanding of the given instruction by
calculating the tailored consistency among multiple self-generated responses.
SEI further assesses the familiarity of the LLM with the target response by
comparing it to the generated responses, using the proposed semantic clustering
and well-designed voting strategy. Finally, to ensure the quality of selected
samples, we introduce an expert-aligned reward model, considering
characteristics beyond just familiarity. By considering data quality and
avoiding unfamiliar data, we can utilize the selected data to effectively align
LLMs to follow instructions and hallucinate less.",http://arxiv.org/abs/2502.07340v2
"FedAPA: Server-side Gradient-Based Adaptive Personalized Aggregation for
  Federated Learning on Heterogeneous Data",2025-02-11T11:00:58Z,"Yuxia Sun, Aoxiang Sun, Siyi Pan, Zhixiao Fu, Jingcai Guo","Personalized federated learning (PFL) tailors models to clients' unique data
distributions while preserving privacy. However, existing
aggregation-weight-based PFL methods often struggle with heterogeneous data,
facing challenges in accuracy, computational efficiency, and communication
overhead. We propose FedAPA, a novel PFL method featuring a server-side,
gradient-based adaptive aggregation strategy to generate personalized models,
by updating aggregation weights based on gradients of client-parameter changes
with respect to the aggregation weights in a centralized manner. FedAPA
guarantees theoretical convergence and achieves superior accuracy and
computational efficiency compared to 10 PFL competitors across three datasets,
with competitive communication overhead.",http://arxiv.org/abs/2502.07456v2
"Non-Interchangeability between Heart Rate Variability and Pulse Rate
  Variability During Supine-to-Stand Tests",2025-02-11T13:21:19Z,"Runwei Lin, Frank Halfwerk, Gozewijn Dirk Laverman, Dirk Donker, Ying Wang","Heart rate variability (HRV) is widely recognized as a valuable biomarker for
assessing autonomic cardiac regulation. Pulse rate variability (PRV) is a
common surrogate of HRV given the wide usability of PPG in commercially
available devices. However, there is no clear conclusion on whether PRV can
replace HRV given their different physiological mechanisms. This study
evaluates the interchangeability of young adults HRV and PRV during
supine-to-stand (STS) tests which are known as common posture transitions in
daily life monitoring. Fifteen features from time, frequency and nonlinear
domains were extracted from both electrocardiography and PPG signals. Paired
t-tests and Wilcoxon signed-rank tests examined the difference between the
extracted HRV and PRV features during supine, transition and standing phases
separately. One feature showed significant difference in the supine phase, and
this discrepancy increased to four in the transition and standing phases. These
findings suggested that PRV is different from HRV in the STS tests, despite the
fact that both metrics can reflect the sympathetic activation triggered by the
posture changes.",http://arxiv.org/abs/2502.07535v1
"Exact Schwinger functions for a class of bounded interactions in $d\geq
  2$",2025-02-11T13:32:13Z,Wojciech Dybalski,"We consider a scalar Euclidean QFT with interaction given by a bounded,
measurable function $V$ such that $V^{\pm}:=\lim_{w\to \pm\infty}V(w)$ exist.
We find a field renormalization such that all the $n$-point connected Schwinger
functions for $n\neq 2$ exist non-perturbatively in the UV limit. They coincide
with the tree-level one-particle irreducible Schwinger functions of the
$\mathrm{erf}(\phi/\sqrt{2})$ interaction with a coupling constant $\frac{1}{2}
(V^+ - V^-)$. By a slight modification of our construction we can change this
coupling constant to $\frac{1}{2} (V_+ - V_-)$, where $V_{\pm}:= \lim_{w\to
0^{\pm}} V(w)$. Thereby non-Gaussianity of these latter theories is governed by
a discontinuity of $V$ at zero. The open problem of controlling also the
two-point function of these QFTs is discussed.",http://arxiv.org/abs/2502.07546v1
Early Stopping Against Label Noise Without Validation Data,2025-02-11T13:40:15Z,"Suqin Yuan, Lei Feng, Tongliang Liu","Early stopping methods in deep learning face the challenge of balancing the
volume of training and validation data, especially in the presence of label
noise. Concretely, sparing more data for validation from training data would
limit the performance of the learned model, yet insufficient validation data
could result in a sub-optimal selection of the desired model. In this paper, we
propose a novel early stopping method called Label Wave, which does not require
validation data for selecting the desired model in the presence of label noise.
It works by tracking the changes in the model's predictions on the training set
during the training process, aiming to halt training before the model unduly
fits mislabeled data. This method is empirically supported by our observation
that minimum fluctuations in predictions typically occur at the training epoch
before the model excessively fits mislabeled data. Through extensive
experiments, we show both the effectiveness of the Label Wave method across
various settings and its capability to enhance the performance of existing
methods for learning with noisy labels.",http://arxiv.org/abs/2502.07551v1
Navigating Semantic Drift in Task-Agnostic Class-Incremental Learning,2025-02-11T13:57:30Z,"Fangwen Wu, Lechao Cheng, Shengeng Tang, Xiaofeng Zhu, Chaowei Fang, Dingwen Zhang, Meng Wang","Class-incremental learning (CIL) seeks to enable a model to sequentially
learn new classes while retaining knowledge of previously learned ones.
Balancing flexibility and stability remains a significant challenge,
particularly when the task ID is unknown. To address this, our study reveals
that the gap in feature distribution between novel and existing tasks is
primarily driven by differences in mean and covariance moments. Building on
this insight, we propose a novel semantic drift calibration method that
incorporates mean shift compensation and covariance calibration. Specifically,
we calculate each class's mean by averaging its sample embeddings and estimate
task shifts using weighted embedding changes based on their proximity to the
previous mean, effectively capturing mean shifts for all learned classes with
each new task. We also apply Mahalanobis distance constraint for covariance
calibration, aligning class-specific embedding covariances between old and
current networks to mitigate the covariance shift. Additionally, we integrate a
feature-level self-distillation approach to enhance generalization.
Comprehensive experiments on commonly used datasets demonstrate the
effectiveness of our approach. The source code is available at
\href{https://github.com/fwu11/MACIL.git}{https://github.com/fwu11/MACIL.git}.",http://arxiv.org/abs/2502.07560v2
Distributed Coverage Control for Time-Varying Spatial Processes,2025-02-11T14:45:17Z,"Federico Pratissoli, Mattia Mantovani, Amanda Prorok, Lorenzo Sabattini","Multi-robot systems are essential for environmental monitoring, particularly
for tracking spatial phenomena like pollution, soil minerals, and water
salinity, and more. This study addresses the challenge of deploying a
multi-robot team for optimal coverage in environments where the density
distribution, describing areas of interest, is unknown and changes over time.
We propose a fully distributed control strategy that uses Gaussian Processes
(GPs) to model the spatial field and balance the trade-off between learning the
field and optimally covering it. Unlike existing approaches, we address a more
realistic scenario by handling time-varying spatial fields, where the
exploration-exploitation trade-off is dynamically adjusted over time. Each
robot operates locally, using only its own collected data and the information
shared by the neighboring robots. To address the computational limits of GPs,
the algorithm efficiently manages the volume of data by selecting only the most
relevant samples for the process estimation. The performance of the proposed
algorithm is evaluated through several simulations and experiments,
incorporating real-world data phenomena to validate its effectiveness.",http://arxiv.org/abs/2502.07595v1
"Causal-Informed Contrastive Learning: Towards Bias-Resilient
  Pre-training under Concept Drift",2025-02-11T15:09:05Z,"Xiaoyu Yang, Jie Lu, En Yu","The evolution of large-scale contrastive pre-training propelled by top-tier
datasets has reached a transition point in the scaling law. Consequently,
sustaining and enhancing a model's pre-training capabilities in drift
environments have surfaced as a notable challenge. In this paper, we initially
uncover that contrastive pre-training methods are significantly impacted by
concept drift wherein distributions change unpredictably, resulting in notable
biases in the feature space of the pre-trained model. Empowered by causal
inference, we construct a structural causal graph to analyze the impact of
concept drift to contrastive pre-training systemically, and propose the causal
interventional contrastive objective. Upon achieving this, we devise a
resilient contrastive pre-training approach to accommodate the data stream of
concept drift, with simple and scalable implementation. Extensive experiments
on various downstream tasks demonstrate our resilient contrastive pre-training
effectively mitigates the bias stemming from the concept drift data stream.
Codes are available at https://anonymous.4open.science/r/ResilientCL/.",http://arxiv.org/abs/2502.07620v1
"Divide and Merge: Motion and Semantic Learning in End-to-End Autonomous
  Driving",2025-02-11T15:21:31Z,"Yinzhe Shen, Ömer Şahin Taş, Kaiwen Wang, Royden Wagner, Christoph Stiller","Perceiving the environment and its changes over time corresponds to two
fundamental yet heterogeneous types of information: semantics and motion.
Previous end-to-end autonomous driving works represent both types of
information in a single feature vector. However, including motion tasks, such
as prediction and planning, always impairs detection and tracking performance,
a phenomenon known as negative transfer in multi-task learning. To address this
issue, we propose Neural-Bayes motion decoding, a novel parallel detection,
tracking, and prediction method separating semantic and motion learning,
similar to the Bayes filter. Specifically, we employ a set of learned motion
queries that operate in parallel with the detection and tracking queries,
sharing a unified set of recursively updated reference points. Moreover, we
employ interactive semantic decoding to enhance information exchange in
semantic tasks, promoting positive transfer. Experiments on the nuScenes
dataset show improvements of 5% in detection and 11% in tracking. Our method
achieves state-of-the-art collision rates in open-loop planning evaluation
without any modifications to the planning module.",http://arxiv.org/abs/2502.07631v1
The Impacts of Magnetogram Projection Effects on Solar Flare Forecasting,2025-02-11T15:39:57Z,"Griffin T. Goodwin, Viacheslav M. Sadykov, Petrus C. Martens","This work explores the impacts of magnetogram projection effects on machine
learning-based solar flare forecasting models. Utilizing a methodology proposed
by Falconer et al. (2016), we correct for projection effects present in Georgia
State University's Space Weather Analytics for Solar Flares (SWAN-SF) benchmark
data set. We then train and run a support vector machine classifier on the
corrected and uncorrected data, comparing differences in performance.
Additionally, we provide insight into several other methodologies that mitigate
projection effects, such as stacking ensemble classifiers and active region
location-informed models. Our analysis shows that data corrections slightly
increase both the true positive (correctly predicted flaring samples) and false
positive (non-flaring samples predicted as flaring) prediction rates, averaging
a few percent. Similarly, changes in performance metrics are minimal for the
stacking ensemble and location-based model. This suggests that a more
complicated correction methodology may be needed to see improvements. It may
also indicate inherent limitations when using magnetogram data for flare
forecasting.",http://arxiv.org/abs/2502.07651v1
A Nonparametric and Functional Wombling Methodology,2025-02-11T18:01:13Z,"Luke A. Barratt, John A. D. Aston","Wombling methods, first introduced in 1951, have been widely applied to
detect boundaries and variations across spatial domains, particularly in
biological, public health and meteorological studies. Traditional applications
focus on finite-dimensional observations, where significant changes in
measurable traits indicate structural boundaries. In this work, wombling
methodologies are extended to functional data, enabling the identification of
spatial variation in infinite-dimensional settings. Proposed is a nonparametric
approach that accommodates functional observations without imposing strict
distributional assumptions. This methodology successfully captures complex
spatial structures and discontinuities, demonstrating superior sensitivity and
robustness compared to existing finite-dimensional techniques. This methodology
is then applied to analyse regional epidemiological disparities between London
and the rest of the UK, identifying key spatial boundaries in the shape of the
first trajectory of Covid-19 incidence in 2020. Through extensive simulations
and empirical validation, demonstrated is the method's effectiveness in
uncovering meaningful spatial variations, with potential applications in a wide
variety of fields.",http://arxiv.org/abs/2502.07740v1
"TranSplat: Surface Embedding-guided 3D Gaussian Splatting for
  Transparent Object Manipulation",2025-02-11T03:43:56Z,"Jeongyun Kim, Jeongho Noh, Dong-Guw Lee, Ayoung Kim","Transparent object manipulation remains a significant challenge in robotics
due to the difficulty of acquiring accurate and dense depth measurements.
Conventional depth sensors often fail with transparent objects, resulting in
incomplete or erroneous depth data. Existing depth completion methods struggle
with interframe consistency and incorrectly model transparent objects as
Lambertian surfaces, leading to poor depth reconstruction. To address these
challenges, we propose TranSplat, a surface embedding-guided 3D Gaussian
Splatting method tailored for transparent objects. TranSplat uses a latent
diffusion model to generate surface embeddings that provide consistent and
continuous representations, making it robust to changes in viewpoint and
lighting. By integrating these surface embeddings with input RGB images,
TranSplat effectively captures the complexities of transparent surfaces,
enhancing the splatting of 3D Gaussians and improving depth completion.
Evaluations on synthetic and real-world transparent object benchmarks, as well
as robot grasping tasks, show that TranSplat achieves accurate and dense depth
completion, demonstrating its effectiveness in practical applications. We
open-source synthetic dataset and model: https://github.
com/jeongyun0609/TranSplat",http://arxiv.org/abs/2502.07840v1
"ADMN: A Layer-Wise Adaptive Multimodal Network for Dynamic Input Noise
  and Compute Resources",2025-02-11T17:19:44Z,"Jason Wu, Kang Yang, Lance Kaplan, Mani Srivastava","Multimodal deep learning systems are deployed in dynamic scenarios due to the
robustness afforded by multiple sensing modalities. Nevertheless, they struggle
with varying compute resource availability (due to multi-tenancy, device
heterogeneity, etc.) and fluctuating quality of inputs (from sensor feed
corruption, environmental noise, etc.). Current multimodal systems employ
static resource provisioning and cannot easily adapt when compute resources
change over time. Additionally, their reliance on processing sensor data with
fixed feature extractors is ill-equipped to handle variations in modality
quality. Consequently, uninformative modalities, such as those with high noise,
needlessly consume resources better allocated towards other modalities. We
propose ADMN, a layer-wise Adaptive Depth Multimodal Network capable of
tackling both challenges - it adjusts the total number of active layers across
all modalities to meet compute resource constraints, and continually
reallocates layers across input modalities according to their modality quality.
Our evaluations showcase ADMN can match the accuracy of state-of-the-art
networks while reducing up to 75% of their floating-point operations.",http://arxiv.org/abs/2502.07862v1
Long-Term X-ray Variability on the Benchmark YSO HL Tau,2025-02-11T19:15:29Z,"Steven M. Silverberg, Scott J. Wolk, David A. Principe, P. Christian Schneider, Hans Moritz Guenther, Jinyoung Serena Kim, Joel H. Kastner","HL Tau is one of the most well-studied Class I young stellar objects,
including frequent observations at near- and mid-infrared, (sub-) millimeter,
and X-ray wavelengths. We present the results of an X-ray variability
monitoring campaign with XMM-Newton in 2020 and X-ray gratings spectroscopy
from Chandra/HETGS in 2018. We find that the X-ray spectrum of HL Tau is
consistently hot (with characteristic plasma temperatures $T \gtrsim 30$ MK)
over 31 epochs spanning 20 years, which is consistent in temperature with most
Class I YSOs. The high-resolution HETG spectrum indicates the presence of some
cooler plasma. We characterize the variability of the star across the 31
observations and find a subset of observations with significant variability on
a $\sim$21-day timescale in the observed count rate and flux. We discuss the
possible origins of this variability, and identify further observations that
would better constrain the nature of the changes.",http://arxiv.org/abs/2502.07900v1
"SHACL-SKOS Based Knowledge Representation of Material Safety Data Sheet
  (SDS) for the Pharmaceutical Industry",2025-02-11T20:44:45Z,"Brian Lu, Dennis Pham, Ti-Chiun Chang, Michael Lovette, Terri Bui, Stephen Ma","We report the development of a knowledge representation and reasoning (KRR)
system built on hybrid SHACL-SKOS ontologies for globally harmonized system
(GHS) material Safety Data Sheets (SDS) to enhance chemical safety
communication and regulatory compliance. SDS are comprehensive documents
containing safety and handling information for chemical substances. Thus, they
are an essential part of workplace safety and risk management. However, the
vast number of Safety Data Sheets from multiple organizations, manufacturers,
and suppliers that produce and distribute chemicals makes it challenging to
centralize and access SDS documents through a single repository. To accomplish
the underlying issues of data exchange related to chemical shipping and
handling, we construct SDS related controlled vocabulary and conditions
validated by SHACL, and knowledge systems of similar domains linked via SKOS.
The resulting hybrid ontologies aim to provide standardized yet adaptable
representations of SDS information, facilitating better data sharing,
retrieval, and integration across various platforms. This paper outlines our
SHACL-SKOS system architectural design and showcases our implementation for an
industrial application streamlining the generation of a composite shipping
cover sheet.",http://arxiv.org/abs/2502.07944v1
"Optimal Pricing of Cloud Services: Committed Spend under Demand
  Uncertainty",2025-02-11T23:41:09Z,"Dirk Bergemann, Michael C. Wang","We consider a seller who offers services to a buyer with multi-unit demand.
Prior to the realization of demand, the buyer receives a noisy signal of their
future demand, and the seller can design contracts based on the reported value
of this signal. Thus, the buyer can contract with the service provider for an
unknown level of future consumption, such as in the market for cloud computing
resources or software services. We characterize the optimal dynamic contract,
extending the classic sequential screening framework to a nonlinear and
multi-unit setting. The optimal mechanism gives discounts to buyers who report
higher signals, but in exchange they must provide larger fixed payments. We
then describe how the optimal mechanism can be implemented by two common forms
of contracts observed in practice, the two-part tariff and the committed spend
contract. Finally, we use extensions of our base model to shed light on
policy-focused questions, such as analyzing how the optimal contract changes
when the buyer faces commitment costs, or when there are liquid spot markets.",http://arxiv.org/abs/2502.08022v1
"Initialization Matters: Unraveling the Impact of Pre-Training on
  Federated Learning",2025-02-11T23:53:16Z,"Divyansh Jhunjhunwala, Pranay Sharma, Zheng Xu, Gauri Joshi","Initializing with pre-trained models when learning on downstream tasks is
becoming standard practice in machine learning. Several recent works explore
the benefits of pre-trained initialization in a federated learning (FL)
setting, where the downstream training is performed at the edge clients with
heterogeneous data distribution. These works show that starting from a
pre-trained model can substantially reduce the adverse impact of data
heterogeneity on the test performance of a model trained in a federated
setting, with no changes to the standard FedAvg training algorithm. In this
work, we provide a deeper theoretical understanding of this phenomenon. To do
so, we study the class of two-layer convolutional neural networks (CNNs) and
provide bounds on the training error convergence and test error of such a
network trained with FedAvg. We introduce the notion of aligned and misaligned
filters at initialization and show that the data heterogeneity only affects
learning on misaligned filters. Starting with a pre-trained model typically
results in fewer misaligned filters at initialization, thus producing a lower
test error even when the model is trained in a federated setting with data
heterogeneity. Experiments in synthetic settings and practical FL training on
CNNs verify our theoretical findings.",http://arxiv.org/abs/2502.08024v1
"Break the Checkbox: Challenging Closed-Style Evaluations of Cultural
  Alignment in LLMs",2025-02-12T01:04:13Z,"Mohsinul Kabir, Ajwad Abrar, Sophia Ananiadou","A large number of studies rely on closed-style multiple-choice surveys to
evaluate cultural alignment in Large Language Models (LLMs). In this work, we
challenge this constrained evaluation paradigm and explore more realistic,
unconstrained approaches. Using the World Values Survey (WVS) and Hofstede
Cultural Dimensions as case studies, we demonstrate that LLMs exhibit stronger
cultural alignment in less constrained settings, where responses are not
forced. Additionally, we show that even minor changes, such as reordering
survey choices, lead to inconsistent outputs, exposing the limitations of
closed-style evaluations. Our findings advocate for more robust and flexible
evaluation frameworks that focus on specific cultural proxies, encouraging more
nuanced and accurate assessments of cultural alignment in LLMs.",http://arxiv.org/abs/2502.08045v2
Cognify: Supercharging Gen-AI Workflows With Hierarchical Autotuning,2025-02-12T01:36:27Z,"Zijian He, Reyna Abhyankar, Vikranth Srivatsa, Yiying Zhang","Today's gen-AI workflows that involve multiple ML model calls, tool/API
calls, data retrieval, or generic code execution are often tuned manually in an
ad-hoc way that is both time-consuming and error-prone. In this paper, we
propose a systematic approach for automatically tuning gen-AI workflows. Our
key insight is that gen-AI workflows can benefit from structure, operator, and
prompt changes, but unique properties of gen-AI workflows require new
optimization techniques. We propose AdaSeek, an adaptive hierarchical search
algorithm for autotuning gen-AI workflows. AdaSeek organizes workflow tuning
methods into different layers based on the user-specified total search budget
and distributes the budget across different layers based on the complexity of
each layer. During its hierarchical search, AdaSeek redistributes the search
budget from less useful to more promising tuning configurations based on
workflow-level evaluation results. We implement AdaSeek in a workflow
autotuning framework called Cognify and evaluate Cognify using six types of
workflows such as RAG-based QA and text-to-SQL transformation. Overall, Cognify
improves these workflows' generation quality by up to 2.8x, reduces execution
monetary cost by up to 10x, and reduces end-to-end latency by 2.7x.",http://arxiv.org/abs/2502.08056v1
RouteFlow: Trajectory-Aware Animated Transitions,2025-02-12T02:39:17Z,"Duan Li, Xinyuan Guo, Xinhuan Shu, Lanxi Xiao, Lingyun Yu, Shixia Liu","Animating objects' movements is widely used to facilitate tracking changes
and observing both the global trend and local hotspots where objects converge
or diverge. Existing methods, however, often obscure critical local hotspots by
only considering the start and end positions of objects' trajectories. To
address this gap, we propose RouteFlow, a trajectory-aware animated transition
method that effectively balances the global trend and local hotspots while
minimizing occlusion. RouteFlow is inspired by a real-world bus route analogy:
objects are regarded as passengers traveling together, with local hotspots
representing bus stops where these passengers get on and off. Based on this
analogy, animation paths are generated like bus routes, with the object layout
generated similarly to seat allocation according to their destinations.
Compared with state-of-the-art methods, RouteFlow better facilitates
identifying the global trend and locating local hotspots while performing
comparably in tracking objects' movements.",http://arxiv.org/abs/2502.08076v1
"Bring the noise: exact inference from noisy simulations in collider
  physics",2025-02-12T06:49:02Z,"Christopher Chang, Benjamin Farmer, Andrew Fowlie, Anders Kvellestad","We rely on Monte Carlo (MC) simulations to interpret searches for new physics
at the Large Hadron Collider (LHC) and elsewhere. These simulations result in
noisy and approximate estimators of selection efficiencies and likelihoods. In
this context we pioneer an exact-approximate computational method -
exact-approximate Markov Chain Monte Carlo - that returns exact inferences
despite noisy simulations. To do so, we introduce an unbiased estimator for a
Poisson likelihood. We demonstrate the new estimator and new techniques in
examples based on a search for neutralinos and charginos at the LHC using a
simplified model. We find attractive performance characteristics - exact
inferences are obtained for a similar computational cost to approximate ones
from existing methods and inferences are robust with respect to the number of
events generated per point.",http://arxiv.org/abs/2502.08157v1
Enhancing LLM Character-Level Manipulation via Divide and Conquer,2025-02-12T07:37:39Z,"Zhen Xiong, Yujun Cai, Bryan Hooi, Nanyun Peng, Kai-Wei Chang, Zhecheng Li, Yiwei Wang","Large Language Models (LLMs) have demonstrated strong generalization
capabilities across a wide range of natural language processing (NLP) tasks.
However, they exhibit notable weaknesses in character-level string
manipulation, struggling with fundamental operations such as character
deletion, insertion, and substitution. These challenges stem primarily from
tokenization constraints, despite the critical role of such operations in data
preprocessing and code generation. Through systematic analysis, we derive two
key insights: (1) LLMs face significant difficulties in leveraging intrinsic
token knowledge for character-level reasoning, and (2) atomized word structures
can substantially enhance LLMs' ability to process token-level structural
information. Building on these insights, we propose Character-Level
Manipulation via Divide and Conquer, a novel approach designed to bridge the
gap between token-level processing and character-level manipulation. Our method
decomposes complex operations into explicit character-level subtasks coupled
with controlled token reconstruction phases, leading to significant
improvements in accuracy. Without additional training, our method significantly
improves accuracies on the $\texttt{Deletion}$, $\texttt{Insertion}$, and
$\texttt{Substitution}$ tasks. To support further research, we open-source our
implementation and benchmarks.",http://arxiv.org/abs/2502.08180v1
"DualStream Contextual Fusion Network: Efficient Target Speaker
  Extraction by Leveraging Mixture and Enrollment Interactions",2025-02-12T08:03:27Z,"Ke Xue, Rongfei Fan, Shanping Yu, Chang Sun, Jianping An","Target speaker extraction focuses on extracting a target speech signal from
an environment with multiple speakers by leveraging an enrollment. Existing
methods predominantly rely on speaker embeddings obtained from the enrollment,
potentially disregarding the contextual information and the internal
interactions between the mixture and enrollment. In this paper, we propose a
novel DualStream Contextual Fusion Network (DCF-Net) in the time-frequency
(T-F) domain. Specifically, DualStream Fusion Block (DSFB) is introduced to
obtain contextual information and capture the interactions between
contextualized enrollment and mixture representation across both spatial and
channel dimensions, and then rich and consistent representations are utilized
to guide the extraction network for better extraction. Experimental results
demonstrate that DCF-Net outperforms state-of-the-art (SOTA) methods, achieving
a scale-invariant signal-to-distortion ratio improvement (SI-SDRi) of 21.6 dB
on the benchmark dataset, and exhibits its robustness and effectiveness in both
noise and reverberation scenarios. In addition, the wrong extraction results of
our model, called target confusion problem, reduce to 0.4%, which highlights
the potential of DCF-Net for practical applications.",http://arxiv.org/abs/2502.08191v1
"Superconductivity near an Ising nematic quantum critical point in two
  dimensions",2025-02-12T10:24:03Z,"Jie Huang, Zhao-Kun Yang, Jing-Rong Wang, Guo-Zhu Liu","Near a two-dimensional Ising-type nematic quantum critical point, the quantum
fluctuations of the nematic order parameter are coupled to the electrons,
leading to non-Fermi liquid behavior and unconventional superconductivity. The
interplay between these two effects has been extensively studied through the
Eliashberg equations for the superconducting gap. However, previous studies
often rely on various approximations that may introduce uncertainties in the
results. Here, we revisit this problem without these approximations and examine
how their removal changes the outcomes. We numerically solve four
self-consistent Eliashberg integral equations of the mass renormalization
$A_{1}(p)$, the chemical potential renormalization $A_{2}(p)$, the pairing
function $\Phi(p)$, and the nematic self-energy (polarization) function
$\Pi(q)$ using the iteration method. Our calculations retain the explicit
non-linearity and the full momentum dependence of these equations. We find that
discarding some commonly used approximations allows for a more accurate
determination of the superconducting gap $\Delta = \Phi/A_{1}$ and the critical
temperature $T_{c}$. The Eliashberg equations have two different convergent gap
solutions: an extended $s$-wave gap and a $d_{x^{2}-y^{2}}$-wave gap. The
latter is fragile, whereas the former is robust against small perturbations.",http://arxiv.org/abs/2502.08270v1
"Modification and Generated-Text Detection: Achieving Dual Detection
  Capabilities for the Outputs of LLM by Watermark",2025-02-12T11:56:40Z,"Yuhang Cai, Yaofei Wang, Donghui Hu, Gu Chen","The development of large language models (LLMs) has raised concerns about
potential misuse. One practical solution is to embed a watermark in the text,
allowing ownership verification through watermark extraction. Existing methods
primarily focus on defending against modification attacks, often neglecting
other spoofing attacks. For example, attackers can alter the watermarked text
to produce harmful content without compromising the presence of the watermark,
which could lead to false attribution of this malicious content to the LLM.
This situation poses a serious threat to the LLMs service providers and
highlights the significance of achieving modification detection and
generated-text detection simultaneously. Therefore, we propose a technique to
detect modifications in text for unbiased watermark which is sensitive to
modification. We introduce a new metric called ``discarded tokens"", which
measures the number of tokens not included in watermark detection. When a
modification occurs, this metric changes and can serve as evidence of the
modification. Additionally, we improve the watermark detection process and
introduce a novel method for unbiased watermark. Our experiments demonstrate
that we can achieve effective dual detection capabilities: modification
detection and generated-text detection by watermark.",http://arxiv.org/abs/2502.08332v1
"Local damage detection in rolling element bearings based on a Single
  Ensemble Empirical Mode Decomposition",2025-02-12T12:56:33Z,"Yaakoub Berrouche, Govind Vashishtha, Sumika Chauhan, Radoslaw Zimroz","A Single Ensemble Empirical Mode Decomposition (SEEMD) is proposed for
locating the damage in rolling element bearings. The SEEMD does not require a
number of ensembles from the addition or subtraction of noise every time while
processing the signals. The SEEMD requires just a single sifting process of a
modified raw signal to reduce the computation time significantly. The other
advantage of the SEEMD method is its success in dealing with non-Gaussian or
non-stationary perturbing signals. In SEEMD, initially, a fractional Gaussian
noise (FGN) is added to the raw signal to emphasize on high frequencies of the
signal. Then, a convoluted white Gaussian noise is multiplied to the resulting
signal which changes the spectral content of the signal which helps in
extraction of the weak periodic signal. Finally, the obtained signal is
decomposed by using a single sifting process. The proposed methodology is
applied to the raw signals obtained from the mining industry. These signals are
difficult to analyze since cyclic impulsive components are obscured by noise
and other interference. Based on the results, the proposed method can
effectively detect the fault where the signal of interest (SOI) has been
extracted with good quality.",http://arxiv.org/abs/2502.08368v1
"Full-cycle device-scale simulations of memory materials with a tailored
  atomic-cluster-expansion potential",2025-02-12T13:33:58Z,"Yuxing Zhou, Daniel F. Thomas du Toit, Stephen R. Elliott, Wei Zhang, Volker L. Deringer","Computer simulations have long been key to understanding and designing
phase-change materials (PCMs) for memory technologies. Machine learning is now
increasingly being used to accelerate the modelling of PCMs, and yet it remains
challenging to simultaneously reach the length and time scales required to
simulate the operation of real-world PCM devices. Here, we show how ultra-fast
machine-learned interatomic potentials, based on the atomic cluster expansion
(ACE) framework, enable simulations of PCMs reflecting applications in devices
with excellent scalability on high-performance computing platforms. We report
full-cycle simulations -- including the time-consuming crystallisation process
(from digital ""zeroes"" to ""ones"") -- thus representing the entire programming
cycle for cross-point memory devices. We also showcase a simulation of
full-cycle operations, relevant to neuromorphic computing, in a mushroom-type
device geometry. Our work provides a springboard for the atomistic modelling of
PCM-based memory and neuromorphic computing devices -- and, more widely, it
illustrates the power of highly efficient ACE ML models for materials science
and engineering.",http://arxiv.org/abs/2502.08393v1
"Robot-Initiated Social Control of Sedentary Behavior: Comparing the
  Impact of Relationship- and Target-Focused Strategies",2025-02-12T14:13:38Z,"Jiaxin Xu, Sterre Anna Mariam van der Horst, Chao Zhang, Raymond H. Cuijpers, Wijnand A. IJsselsteijn","To design social robots to effectively promote health behavior change, it is
essential to understand how people respond to various health communication
strategies employed by these robots. This study examines the effectiveness of
two types of social control strategies from a social robot,
relationship-focused strategies (emphasizing relational consequences) and
target-focused strategies (emphasizing health consequences), in encouraging
people to reduce sedentary behavior. A two-session lab experiment was conducted
(n = 135), where participants first played a game with a robot, followed by the
robot persuading them to stand up and move using one of the strategies. Half of
the participants joined a second session to have a repeated interaction with
the robot. Results showed that relationship-focused strategies motivated
participants to stay active longer. Repeated sessions did not strengthen
participants' relationship with the robot, but those who felt more attached to
the robot responded more actively to the target-focused strategies. These
findings offer valuable insights for designing persuasive strategies for social
robots in health communication contexts.",http://arxiv.org/abs/2502.08428v1
"Uniform confidence bands for joint angles across different fatigue
  phases",2025-02-12T14:15:56Z,"Patrick Bastian, Rupsa Basu, Holger Dette","We develop uniform confidence bands for the mean function of stationary time
series as a post-hoc analysis of multiple change point detection in functional
time series. In particular, the methodology in this work provides bands for
those segments where the jump size exceeds a certain threshold $\Delta$. In
\cite{bastian2024multiplechangepointdetection} such exceedences of $\Delta$
were related to fatigue states of a running athlete. The extension to
confidence bands stems from an interest in understanding the range of motion
(ROM) of lower-extremity joints of running athletes under fatiguing conditions.
From a biomechanical perspective, ROM serves as a proxy for joint flexibility
under varying fatigue states, offering individualized insights into potentially
problematic movement patterns. The new methodology provides a valuable tool for
understanding the dynamic behavior of joint motion and its relationship to
fatigue.",http://arxiv.org/abs/2502.08430v1
"How does the restriction of representations change under translations? A
  story for the general linear groups and the unitary groups",2025-02-12T15:14:17Z,"Toshiyuki Kobayashi, Birgit Speh","We present a new approach to symmetry breaking for pairs of real forms of
$(GL(n, \mathbb{C}), GL(n-1, \mathbb{C}))$. While translation functors are a
useful tool for studying a family of representations of a single reductive
group $G$, when applied to a pair of groups $G \supset G'$,translation functors
can significantly alter the nature of symmetry breaking between the
representations of $G$ and $G'$, even within the same Weyl chamber of the
direct product group $G \times G'$. We introduce the concept of \lq\lq{fences
for the interlacing pattern}\rq\rq,which provides a refinement of the usual
notion of \lq\lq{walls for Weyl chambers}\rq\rq. We then present a theorem that
states that multiplicity is constant unless these \lq\lq{fences}\rq\rq\ are
crossed. This general theorem is illustrated with examples of both tempered and
non-tempered representations. Additionally,we provide a new non-vanishing
theorem of period integrals for pairs of reductive symmetric spaces,which is
further strengthened through this approach.",http://arxiv.org/abs/2502.08479v1
"Impact of Electric Spatially Discordant Alternans on Cardiac Magnetic
  Field",2025-02-12T15:14:25Z,"Martina Nicoletti, Anna Crispino, Alessandro Loppini, Alessio Gizzi, Letizia Chiodo, Christian Cherubini, Simonetta Filippi","Spatially discordant alternans (SDA) play a crucial role in cardiac
arrhythmogenesis by creating steep repolarization gradients facilitating
conduction block and reentry. While traditionally studied using electrical
indicators, this work provides a novel perspective by characterizing SDA
through their magnetic field signatures. Using a one-dimensional cardiac fiber
model, we demonstrate that magnetic field measurements effectively detect SDA
and temperature dependent changes in cardiac action potentials, offering a
non-invasive alternative to conventional electrophysiological metrics. Our
results reveal that the spatial organization of SDA is mirrored in the magnetic
field distribution, with SDA nodes clearly identifiable via spatial mapping.
Notably, magnetic restitution curves exhibit a distinct pattern from APD-based
indicators, closely following the dynamics of the action potential upstroke.
These findings establish the cardiac magnetic field as a powerful diagnostic
tool for detecting SDA, opening new avenues for biomagnetic monitoring of
arrhythmic risk.",http://arxiv.org/abs/2502.08480v1
The Born rule -- 100 years ago and today,2025-02-12T16:28:49Z,Arnold Neumaier,"Details of the contents, and formulations of the Born rule changed
considerably from its inception by Born in 1926 to the present day. Based to a
large extent on little known results from the recent books 'Coherent Quantum
Physics' by Neumaier and 'Algebraic Quantum Physics', Vol. 1 by Neumaier and
Westra, this paper traces the early history 100 years ago, its generalization
(essential for today's quantum optics and quantum information theory) to POVMs
50 year ago, and a modern derivation from an intuitive definition of the notion
of a quantum detector. Also discussed is the extent to which the various forms
of the Born rule have, like any other statement in physics, a restricted domain
of validity, which leads to problems when applied outside this domain.",http://arxiv.org/abs/2502.08545v1
Poly-Autoregressive Prediction for Modeling Interactions,2025-02-12T18:59:43Z,"Neerja Thakkar, Tara Sadjadpour, Jathushan Rajasegaran, Shiry Ginosar, Jitendra Malik","We introduce a simple framework for predicting the behavior of an agent in
multi-agent settings. In contrast to autoregressive (AR) tasks, such as
language processing, our focus is on scenarios with multiple agents whose
interactions are shaped by physical constraints and internal motivations. To
this end, we propose Poly-Autoregressive (PAR) modeling, which forecasts an ego
agent's future behavior by reasoning about the ego agent's state history and
the past and current states of other interacting agents. At its core, PAR
represents the behavior of all agents as a sequence of tokens, each
representing an agent's state at a specific timestep. With minimal data
pre-processing changes, we show that PAR can be applied to three different
problems: human action forecasting in social situations, trajectory prediction
for autonomous vehicles, and object pose forecasting during hand-object
interaction. Using a small proof-of-concept transformer backbone, PAR
outperforms AR across these three scenarios. The project website can be found
at https://neerja.me/PAR/.",http://arxiv.org/abs/2502.08646v1
Scientific Map of Artificial Intelligence in Communication (2004-2024),2025-01-14T10:18:40Z,Carmen Gálvez,"Introduction: Artificial Intelligence (AI) is having a significant impact in
the field of communication, causing transcendental changes in the processing
and consumption of information. The objective of this work was to analyze the
most influential AI topic areas in the field of communication based on
scientific literature. Methodology: 996 references indexed in Web of Science
between 2004-2024 were selected, a bibliometric analysis of co-words was
carried out and visualization techniques were applied to build scientific maps.
Results: The most relevant thematic areas were datafication, the linking of AI
with social media and digital journalism. The emerging area of generative AI
was identified, linked to new AI models, such as ChatGPT, designed to generate
content in the form of written text, audio, images or videos. Another emerging
topic area was China's impact on the use of AI in communication. Discussions:
Despite the impact of AI in communication, the field is still in the process of
structuring, with few consolidated topics. Conclusions: This study made it
possible to identify the thematic areas of the field studied, as well as the
detection of emerging trends.",http://arxiv.org/abs/2502.08648v1
"Deep Learning-Driven Malware Classification with API Call Sequence
  Analysis and Concept Drift Handling",2025-02-12T08:56:35Z,"Bishwajit Prasad Gond, Durga Prasad Mohapatra","Malware classification in dynamic environments presents a significant
challenge due to concept drift, where the statistical properties of malware
data evolve over time, complicating detection efforts. To address this issue,
we propose a deep learning framework enhanced with a genetic algorithm to
improve malware classification accuracy and adaptability. Our approach
incorporates mutation operations and fitness score evaluations within genetic
algorithms to continuously refine the deep learning model, ensuring robustness
against evolving malware threats. Experimental results demonstrate that this
hybrid method significantly enhances classification performance and
adaptability, outperforming traditional static models. Our proposed approach
offers a promising solution for real-time malware classification in
ever-changing cybersecurity landscapes.",http://arxiv.org/abs/2502.08679v1
"A Comparative Study of Machine Learning Algorithms for Stock Price
  Prediction Using Insider Trading Data",2025-02-12T19:03:09Z,"Amitabh Chakravorty, Nelly Elsayed","The research paper empirically investigates several machine learning
algorithms to forecast stock prices depending on insider trading information.
Insider trading offers special insights into market sentiment, pointing to
upcoming changes in stock prices. This study examines the effectiveness of
algorithms like decision trees, random forests, support vector machines (SVM)
with different kernels, and K-Means Clustering using a dataset of Tesla stock
transactions. Examining past data from April 2020 to March 2023, this study
focuses on how well these algorithms identify trends and forecast stock price
fluctuations. The paper uses Recursive Feature Elimination (RFE) and feature
importance analysis to optimize the feature set and, hence, increase prediction
accuracy. While it requires substantially greater processing time than other
models, SVM with the Radial Basis Function (RBF) kernel displays the best
accuracy. This paper highlights the trade-offs between accuracy and efficiency
in machine learning models and proposes the possibility of pooling multiple
data sources to raise prediction performance. The results of this paper aim to
help financial analysts and investors in choosing strong algorithms to optimize
investment strategies.",http://arxiv.org/abs/2502.08728v1
"Vacuum Polarization, Geodesic Equation and Sachs-Wolfe Effect",2025-02-12T19:38:21Z,Ali Kaya,"We show that the null geodesic equation for photons is modified in the
presence of a charged scalar field, with quantum fluctuations acting as an
effective mass term that changes the null paths to timelike curves. This effect
can be interpreted as a vacuum polarization phenomenon in curved spacetime. The
resulting contribution to the Sachs-Wolfe effect varies with photon frequency,
leading to frequency-dependent corrections to the cosmic microwave background
(CMB) blackbody spectrum in the form of a $\mu$-distortion, as well as
modifications to the CMB power spectrum. We estimate these within a standard
inflationary scenario and find that while the correction to the CMB power
spectrum is significant when the scalar field is light, the magnitude of the
$\mu$-distortion depends strongly on the regularization prescription.",http://arxiv.org/abs/2502.08748v1
Temporal Interface in Dispersive Hyperbolic Media,2025-02-12T20:34:57Z,"Grigorii Ptitcyn, Diego Martinez Solís, Mohammad Sajjad Mirmoosa, Nader Engheta","Spatial inhomogeneity, temporal modulation, and engineered anisotropy of
parameters of electromagnetic media offer numerous opportunities for
manipulating light-matter interaction over the past decades. Here, we
investigate a scenario in which we deal with the temporal interface, hyperbolic
anisotropy in the form of layered structures, and frequency dispersion. We
theoretically investigate how a monochromatic uniform plane wave - propagating
in an unbounded, homogeneous, isotropic dielectric medium - undergoes changes
due to the rapid temporal variation of such medium into a hyperbolic dispersive
medium formed by the stack of thin metal-dielectric bilayers, in which the
metal follows the lossless Drude dispersion and the dielectric is assumed to be
dispersionless. We corroborate our analytical results by numerical simulations.
We observe several interesting phenomena, such as the conversion of the
original frequency into three pairs of frequencies, resulting in three sets of
forward (FW) and backward (BW) waves. We present the amplitudes and the
time-average Poynting vectors for such FW and BW waves and discuss some of the
salient features of such temporal interface.",http://arxiv.org/abs/2502.08775v1
Spectral Journey: How Transformers Predict the Shortest Path,2025-02-12T21:17:30Z,"Andrew Cohen, Andrey Gromov, Kaiyu Yang, Yuandong Tian","Decoder-only transformers lead to a step-change in capability of large
language models. However, opinions are mixed as to whether they are really
planning or reasoning. A path to making progress in this direction is to study
the model's behavior in a setting with carefully controlled data. Then
interpret the learned representations and reverse-engineer the computation
performed internally. We study decoder-only transformer language models trained
from scratch to predict shortest paths on simple, connected and undirected
graphs. In this setting, the representations and the dynamics learned by the
model are interpretable. We present three major results: (1) Two-layer
decoder-only language models can learn to predict shortest paths on simple,
connected graphs containing up to 10 nodes. (2) Models learn a graph embedding
that is correlated with the spectral decomposition of the line graph. (3)
Following the insights, we discover a novel approximate path-finding algorithm
Spectral Line Navigator (SLN) that finds shortest path by greedily selecting
nodes in the space of spectral embedding of the line graph.",http://arxiv.org/abs/2502.08794v1
"Examining and Adapting Time for Multilingual Classification via Mixture
  of Temporal Experts",2025-02-12T22:30:18Z,"Weisi Liu, Guangzeng Han, Xiaolei Huang","Time is implicitly embedded in classification process: classifiers are
usually built on existing data while to be applied on future data whose
distributions (e.g., label and token) may change. However, existing
state-of-the-art classification models merely consider the temporal variations
and primarily focus on English corpora, which leaves temporal studies less
explored, let alone under multilingual settings. In this study, we fill the gap
by treating time as domains (e.g., 2024 vs. 2025), examining temporal effects,
and developing a domain adaptation framework to generalize classifiers over
time on multiple languages. Our framework proposes Mixture of Temporal Experts
(MoTE) to leverage both semantic and data distributional shifts to learn and
adapt temporal trends into classification models. Our analysis shows
classification performance varies over time across different languages, and we
experimentally demonstrate that MoTE can enhance classifier generalizability
over temporal data shifts. Our study provides analytic insights and addresses
the need for time-aware models that perform robustly in multilingual scenarios.",http://arxiv.org/abs/2502.08825v1
"Generative AI & Changing Work: Systematic Review of Practitioner-led
  Work Transformations through the Lens of Job Crafting",2025-02-13T00:13:49Z,"Matthew Law, Rama Adithya Varanasi","Widespread integration of Generative AI tools is transforming white-collar
work, reshaping how workers define their roles, manage their tasks, and
collaborate with peers. This has created a need to develop an overarching
understanding of common worker-driven patterns around these transformations. To
fill this gap, we conducted a systematic literature review of 23 studies from
the ACM Digital Library that focused on workers' lived-experiences and
practitioners with GenAI. Our findings reveal that while many professionals
have delegated routine tasks to GenAI to focus on core responsibilities, they
have also taken on new forms of AI managerial labor to monitor and refine GenAI
outputs. Additionally, practitioners have restructured collaborations,
sometimes bypassing traditional peer and subordinate interactions in favor of
GenAI assistance. These shifts have fragmented cohesive tasks into piecework
creating tensions around role boundaries and professional identity. Our
analysis suggests that current frameworks, like job crafting, need to evolve to
address the complexities of GenAI-driven transformations.",http://arxiv.org/abs/2502.08854v1
"Utilizing Pre-trained and Large Language Models for 10-K Items
  Segmentation",2025-02-13T01:21:15Z,"Hsin-Min Lu, Yu-Tai Chien, Huan-Hsun Yen, Yen-Hsiu Chen","Extracting specific items from 10-K reports remains challenging due to
variations in document formats and item presentation. Traditional rule-based
item segmentation approaches often yield suboptimal results. This study
introduces two advanced item segmentation methods leveraging language models:
(1) GPT4ItemSeg, using a novel line-ID-based prompting mechanism to utilize
GPT4 for item segmentation, and (2) BERT4ItemSeg, combining BERT embeddings
with a Bi-LSTM model in a hierarchical structure to overcome context window
constraints. Trained and evaluated on 3,737 annotated 10-K reports,
BERT4ItemSeg achieved a macro-F1 of 0.9825, surpassing GPT4ItemSeg (0.9567),
conditional random field (0.9818), and rule-based methods (0.9048) for core
items (1, 1A, 3, and 7). These approaches enhance item segmentation
performance, improving text analytics in accounting and finance. BERT4ItemSeg
offers satisfactory item segmentation performance, while GPT4ItemSeg can easily
adapt to regulatory changes. Together, they offer practical benefits for
researchers and practitioners, enabling reliable empirical studies and
automated 10-K item segmentation functionality.",http://arxiv.org/abs/2502.08875v1
"CoCreatAR: Enhancing Authoring of Outdoor Augmented Reality Experiences
  Through Asymmetric Collaboration",2025-02-13T05:38:45Z,"Nels Numan, Gabriel Brostow, Suhyun Park, Simon Julier, Anthony Steed, Jessica Van Brummelen","Authoring site-specific outdoor augmented reality (AR) experiences requires a
nuanced understanding of real-world context to create immersive and relevant
content. Existing ex-situ authoring tools typically rely on static 3D models to
represent spatial information. However, in our formative study (n=25), we
identified key limitations of this approach: models are often outdated,
incomplete, or insufficient for capturing critical factors such as safety
considerations, user flow, and dynamic environmental changes. These issues
necessitate frequent on-site visits and additional iterations, making the
authoring process more time-consuming and resource-intensive. To mitigate these
challenges, we introduce CoCreatAR, an asymmetric collaborative mixed reality
authoring system that integrates the flexibility of ex-situ workflows with the
immediate contextual awareness of in-situ authoring. We conducted an
exploratory study (n=32) comparing CoCreatAR to an asynchronous workflow
baseline, finding that it enhances engagement, creativity, and confidence in
the authored output while also providing preliminary insights into its impact
on task load. We conclude by discussing the implications of our findings for
integrating real-world context into site-specific AR authoring systems.",http://arxiv.org/abs/2502.08981v1
Gauss-Bonnet-induced symmetry breaking/restoration during inflation,2025-02-13T05:48:58Z,"Yermek Aldabergenov, Daulet Berkimbayev","We propose a mechanism of symmetry breaking or restoration that can occur in
the middle of inflation due to the coupling of the Gauss-Bonnet term to a
charged scalar. The Gauss-Bonnet coupling results in an inflaton-dependent
effective squared mass of the charged scalar, which can change its sign (around
the symmetric point) during inflation. This can lead to spontaneous breaking of
the symmetry, or to its restoration, if it is initially broken. We show the
conditions under which the backreaction of the Gauss-Bonnet coupling on the
inflationary background is negligible, such that the predictions of a given
inflationary model are unaffected by the symmetry breaking/restoration process.",http://arxiv.org/abs/2502.08986v1
"Mechanistic Unveiling of Transformer Circuits: Self-Influence as a Key
  to Model Reasoning",2025-02-13T07:19:05Z,"Lin Zhang, Lijie Hu, Di Wang","Transformer-based language models have achieved significant success; however,
their internal mechanisms remain largely opaque due to the complexity of
non-linear interactions and high-dimensional operations. While previous studies
have demonstrated that these models implicitly embed reasoning trees, humans
typically employ various distinct logical reasoning mechanisms to complete the
same task. It is still unclear which multi-step reasoning mechanisms are used
by language models to solve such tasks. In this paper, we aim to address this
question by investigating the mechanistic interpretability of language models,
particularly in the context of multi-step reasoning tasks. Specifically, we
employ circuit analysis and self-influence functions to evaluate the changing
importance of each token throughout the reasoning process, allowing us to map
the reasoning paths adopted by the model. We apply this methodology to the
GPT-2 model on a prediction task (IOI) and demonstrate that the underlying
circuits reveal a human-interpretable reasoning process used by the model.",http://arxiv.org/abs/2502.09022v2
"From Visuals to Vocabulary: Establishing Equivalence Between Image and
  Text Token Through Autoregressive Pre-training in MLLMs",2025-02-13T09:04:28Z,"Mingxiao Li, Fang Qu, Zhanpeng Chen, Na Su, Zhizhou Zhong, Ziyang Chen, Nan Du, Xiaolong Li","While MLLMs perform well on perceptual tasks, they lack precise multimodal
alignment, limiting performance. To address this challenge, we propose Vision
Dynamic Embedding-Guided Pretraining (VDEP), a hybrid autoregressive training
paradigm for MLLMs. Utilizing dynamic embeddings from the MLP following the
visual encoder, this approach supervises image hidden states and integrates
image tokens into autoregressive training. Existing MLLMs primarily focused on
recovering information from textual inputs, often neglecting the effective
processing of image data. In contrast, the key improvement of this work is the
reinterpretation of multimodal alignment as a process of recovering information
from input data, with particular emphasis on reconstructing detailed visual
features.The proposed method seamlessly integrates into standard models without
architectural changes. Experiments on 13 benchmarks show VDEP outperforms
baselines, surpassing existing methods.",http://arxiv.org/abs/2502.09093v1
"Mathematical modeling and simulation of coupled aqueous humor flow and
  temperature distribution in a realistic 3D human eye geometry",2025-02-13T09:55:16Z,"Thomas Saigre, Vincent Chabannes, Christophe Prud'Homme, Marcela Szopos","We present a comprehensive computational model to simulate the coupled
dynamics of aqueous humor flow and heat transfer in the human eye. To manage
the complexity of the model, we make significant efforts in meshing and
efficient solution of the discrete problem using high-performance resources.
The model accurately describes the dynamics of the aqueous humor in the
anterior and posterior chambers and accounts for convective effects due to
temperature variations. Results for fluid velocity, pressure, and temperature
distribution are in good agreement with existing numerical results in the
literature. Furthermore, the effects of postural changes and wall shear stress
behavior are analyzed, providing new insights into the mechanical forces acting
on ocular tissues. Overall, the present contribution provides a detailed
three-dimensional simulation that enhances the understanding of ocular
physiology and may contribute to further progress in clinical research and
treatment optimization in ophthalmology.",http://arxiv.org/abs/2502.09119v1
"Two-level control over quantum state creation via entangled
  equal-probability state",2025-02-13T09:59:00Z,"S. I. Doronin, E. B. Fel'dman, A. I. Zenchuk","We propose the scheme realizing the two-level control over the unitary
operators $U_k$ creating the required quantum state of the system $S$. These
operators are controlled by the superposition state of the auxiliary subsystem
$R$ which is governed by two control centers. The
  first-level control center (main control) creates the equal-probability pure
state of $R$ with certain distribution of phase factors that, in turn, govern
the power of the second-level control center $C$ that applies the special
$V$-operators to the same subsystem $R$ changing its state and thus controlling
the applicability of $U_k$. In addition, the above phases are responsible for
the entanglement in the subsystem $R$. We find the direct relation between this
entanglement and the number of operators $U_k$ that can be controlled by $C$.
The simple example of a two-level control system governing the creation of
entangled state of the two-qubit system $S$ is presented.",http://arxiv.org/abs/2502.09124v1
"E-MD3C: Taming Masked Diffusion Transformers for Efficient Zero-Shot
  Object Customization",2025-02-13T10:48:11Z,"Trung X. Pham, Zhang Kang, Ji Woo Hong, Xuran Zheng, Chang D. Yoo","We propose E-MD3C ($\underline{E}$fficient $\underline{M}$asked
$\underline{D}$iffusion Transformer with Disentangled $\underline{C}$onditions
and $\underline{C}$ompact $\underline{C}$ollector), a highly efficient
framework for zero-shot object image customization. Unlike prior works reliant
on resource-intensive Unet architectures, our approach employs lightweight
masked diffusion transformers operating on latent patches, offering
significantly improved computational efficiency. The framework integrates three
core components: (1) an efficient masked diffusion transformer for processing
autoencoder latents, (2) a disentangled condition design that ensures
compactness while preserving background alignment and fine details, and (3) a
learnable Conditions Collector that consolidates multiple inputs into a compact
representation for efficient denoising and learning. E-MD3C outperforms the
existing approach on the VITON-HD dataset across metrics such as PSNR, FID,
SSIM, and LPIPS, demonstrating clear advantages in parameters, memory
efficiency, and inference speed. With only $\frac{1}{4}$ of the parameters, our
Transformer-based 468M model delivers $2.5\times$ faster inference and uses
$\frac{2}{3}$ of the GPU memory compared to an 1720M Unet-based latent
diffusion model.",http://arxiv.org/abs/2502.09164v1
"Orbital-selective correlation effects and superconducting pairing
  symmetry in a multiorbital $t$-$J$ model for bilayer nickelates",2025-02-13T11:36:17Z,"Guijing Duan, Zhiguang Liao, Lei Chen, Yiming Wang, Rong Yu, Qimiao Si","The recent discovery of superconductivity in La$_3$Ni$_2$O$_7$ raises key
questions about its mechanism and the nature of pairing symmetry. This system
is believed to be described by a bilayer two-orbital Hubbard model. The
considerations of orbital-selective Mott correlations motivate a bilayer
two-orbital $t$-$J$ model and, accordingly, we study the superconducting
pairing in this model. We obtain an overall phase diagram of superconductivity,
where the leading channel has either extended $s$-wave or $d_{x^2-y^2}$-wave
symmetry. Our analysis highlights how the orbital-selective correlations affect
the superconducting pairing via the interlayer exchange couplings and
low-energy electronic structure. In particular, we find that the dominant
orbital for the pairing may change between $z^2$ and $x^2-y^2$ when the
position of the bonding $z^2$ band is varied by tuning either the $c$-axis
lattice constant or electron concentration strength. We discuss the
implications of these results for the superconductivity in both bulk
La$_{3}$Ni$_{2}$O$_{7}$ and its thin film counterpart.",http://arxiv.org/abs/2502.09195v1
"Transactional Dynamics in Hyperledger Fabric: A Stochastic Modeling and
  Performance Evaluation of Permissioned Blockchains",2025-02-13T12:41:48Z,"Carlos Melo, Glauber Gonçalves, Francisco Airton Silva, Iure Fé, Ericksulino Moura, André Soares, Eunmi Choi, Dugki Min, Jae-Woo Lee, Tuan Anh Nguyen","Blockchain, often integrated with distributed systems and security
enhancements, has significant potential in various industries. However,
environmental concerns and the efficiency of consortia-controlled permissioned
networks remain critical issues. We use a Stochastic Petri Net model to analyze
transaction flows in Hyperledger Fabric networks, achieving a 95% confidence
interval for response times. This model enables administrators to assess the
impact of system changes on resource utilization. Sensitivity analysis reveals
major factors influencing response times and throughput. Our case studies
demonstrate that block size can alter throughput and response times by up to
200%, underscoring the need for performance optimization with resource
efficiency.",http://arxiv.org/abs/2502.09276v1
Trajectory Inference for Single Cell Omics,2025-02-13T14:19:33Z,"Alexandre Hutton, Jesse G. Meyer","Trajectory inference is used to order single-cell omics data along a path
that reflects a continuous transition between cells. This approach is useful
for studying processes like cell differentiation, where a stem cell matures
into a specialized cell type, or investigating state changes in pathological
conditions. In the current article, we provide a general introduction to
trajectory inference, explaining the concepts and assumptions underlying the
different methods. We then briefly discuss the strengths and weaknesses of
different trajectory inference methods. We also describe best practices for
using trajectory inference, such as how to validate the results and how to
interpret them in the context of biological knowledge. Finally, the article
will discuss some of the applications of trajectory inference in single-cell
omics research. These applications include studying cell differentiation,
development, and disease. We provide examples of how trajectory inference has
been used to gain new insights into these processes.",http://arxiv.org/abs/2502.09354v1
"Superconducting diode efficiency from singlet-triplet mixing in
  disordered systems",2025-02-13T15:44:21Z,"Jaglul Hasan, Daniel Shaffer, Maxim Khodas, Alex Levchenko","The superconducting diode effect (SDE) -- the nonreciprocity of the critical
current in a bulk superconductor -- has garnered significant attention due to
its potential applications in superconducting electronics. However, the role of
disorder scattering in SDE has rarely been considered, despite its potential
qualitative impact, as we demonstrate in this work. We investigate SDE in a
disordered Rashba superconductor under an in-plane magnetic field, employing a
self-consistent Born approximation to derive the corresponding Ginzburg-Landau
theory. Our analysis reveals two surprising effects. First, in the weak Rashba
spin-orbit coupling (SOC) regime, disorder can reverse the direction of the
diode effect, indicated by a sign change in the superconducting diode
efficiency coefficient. Second, in the strong Rashba SOC regime, disorder
becomes the driving mechanism of SDE, which vanishes in its absence. In this
case, we show that disorder-induced mixing of singlet and triplet
superconducting orders underlies the effect.",http://arxiv.org/abs/2502.09421v1
Relational Conformal Prediction for Correlated Time Series,2025-02-13T16:12:17Z,"Andrea Cini, Alexander Jenkins, Danilo Mandic, Cesare Alippi, Filippo Maria Bianchi","We address the problem of uncertainty quantification in time series
forecasting by exploiting observations at correlated sequences. Relational deep
learning methods leveraging graph representations are among the most effective
tools for obtaining point estimates from spatiotemporal data and correlated
time series. However, the problem of exploiting relational structures to
estimate the uncertainty of such predictions has been largely overlooked in the
same context. To this end, we propose a novel distribution-free approach based
on the conformal prediction framework and quantile regression. Despite the
recent applications of conformal prediction to sequential data, existing
methods operate independently on each target time series and do not account for
relationships among them when constructing the prediction interval. We fill
this void by introducing a novel conformal prediction method based on graph
deep learning operators. Our method, named Conformal Relational Prediction
(CoRel), does not require the relational structure (graph) to be known as a
prior and can be applied on top of any pre-trained time series predictor.
Additionally, CoRel includes an adaptive component to handle non-exchangeable
data and changes in the input time series. Our approach provides accurate
coverage and archives state-of-the-art uncertainty quantification in relevant
benchmarks.",http://arxiv.org/abs/2502.09443v1
Pixel-Level Reasoning Segmentation via Multi-turn Conversations,2025-02-13T16:16:54Z,"Dexian Cai, Xiaocui Yang, Yongkang Liu, Daling Wang, Shi Feng, Yifei Zhang, Soujanya Poria","Existing visual perception systems focus on region-level segmentation in
single-turn dialogues, relying on complex and explicit query instructions. Such
systems cannot reason at the pixel level and comprehend dynamic user intent
that changes over interaction. Our work tackles this issue by introducing a
novel task, Pixel-level Reasoning Segmentation (Pixel-level RS) based on
multi-turn conversations, tracking evolving user intent via multi-turn
interactions for fine-grained segmentation. To establish a benchmark for this
novel task, we build a Pixel-level ReasonIng Segmentation Dataset Based on
Multi-Turn Conversations (PRIST), comprising 24k utterances from 8.3k
multi-turn conversational scenarios with segmentation targets. Building on
PRIST, we further propose MIRAS, a Multi-turn Interactive ReAsoning
Segmentation framework, integrates pixel-level segmentation with robust
multi-turn conversation understanding, generating pixel-grounded explanations
aligned with user intent. The PRIST dataset and MIRSA framework fill the gap in
pixel-level reasoning segmentation. Experimental results on the PRIST dataset
demonstrate that our method outperforms current segmentation-specific baselines
in terms of segmentation and LLM-based reasoning metrics. The code and data are
available at: https://github.com/ccccai239/PixelRIST.",http://arxiv.org/abs/2502.09447v1
"Counterflow of lattice polarons in harmonically confined optical
  lattices",2025-02-13T16:17:27Z,"Felipe Isaule, Abel Rojo-Francàs, Luis Morales-Molina, Bruno Juliá-Díaz","We study a mobile impurity in a one-dimensional harmonically confined optical
lattice interacting repulsively with a bosonic bath. The behavior of the
impurity across baths with superfluid and Mott-insulator domains is examined,
including its full back-action effect on the bath. We characterize the
bath-impurity phase diagram and reveal the appearance of a correlated
counterflow phase, which we support with an analytical model for a mobile
impurity-hole pair. This phase shows a combined insulator domain of unity
filling but no independent domain of constant density. The transition to this
phase features a sudden orthogonality catastrophe and the change of the shape
of the impurity's profile to that of a free particle in an infinite square
well. The findings of this work suggest the appearance of unconventional
counterflow in trapped imbalanced atomic mixtures.",http://arxiv.org/abs/2502.09448v1
"MorphNLI: A Stepwise Approach to Natural Language Inference Using Text
  Morphing",2025-02-13T18:22:31Z,"Vlad Andrei Negru, Robert Vacareanu, Camelia Lemnaru, Mihai Surdeanu, Rodica Potolea","We introduce MorphNLI, a modular step-by-step approach to natural language
inference (NLI). When classifying the premise-hypothesis pairs into
{entailment, contradiction, neutral}, we use a language model to generate the
necessary edits to incrementally transform (i.e., morph) the premise into the
hypothesis. Then, using an off-the-shelf NLI model we track how the entailment
progresses with these atomic changes, aggregating these intermediate labels
into a final output. We demonstrate the advantages of our proposed method
particularly in realistic cross-domain settings, where our method always
outperforms strong baselines with improvements up to 12.6% (relative). Further,
our proposed approach is explainable as the atomic edits can be used to
understand the overall NLI label.",http://arxiv.org/abs/2502.09567v1
Learning to Coordinate with Experts,2025-02-13T18:41:55Z,"Mohamad H. Danesh, Tu Trinh, Benjamin Plaut, Nguyen X. Khanh","When deployed in dynamic environments, AI agents will inevitably encounter
challenges that exceed their individual capabilities. Leveraging assistance
from expert agents-whether human or AI-can significantly enhance safety and
performance in such situations. However, querying experts is often costly,
necessitating the development of agents that can efficiently request and
utilize expert guidance. In this paper, we introduce a fundamental coordination
problem called Learning to Yield and Request Control (YRC), where the objective
is to learn a strategy that determines when to act autonomously and when to
seek expert assistance. We consider a challenging practical setting in which an
agent does not interact with experts during training but must adapt to novel
environmental changes and expert interventions at test time. To facilitate
empirical research, we introduce YRC-Bench, an open-source benchmark featuring
diverse domains. YRC-Bench provides a standardized Gym-like API, simulated
experts, evaluation pipeline, and implementation of competitive baselines.
Towards tackling the YRC problem, we propose a novel validation approach and
investigate the performance of various learning methods across diverse
environments, yielding insights that can guide future research.",http://arxiv.org/abs/2502.09583v1
"$B\to K\sf{+}invisible$, dark matter, and $CP$ violation in hyperon
  decays",2025-02-13T18:53:47Z,"Xiao-Gang He, Xiao-Dong Ma, Jusak Tandean, German Valencia","Recently the Belle II Collaboration has reported a measurement of the $B^+\to
K^+\nu\bar\nu$ rate that is higher than the standard-model expectation. Since
the emitted neutrinos are unobserved, the excess could be due to the $B^+$
decaying into a $K^+$ and a dark-matter pair. We entertain this possibility in
a two-Higgs-doublet model supplemented with a real singlet scalar boson acting
as the dark matter. This model also accommodates strangeness-changing
interactions providing new sources of $CP$ violation which can affect hyperon
and kaon nonleptonic transitions. We find that the resulting $CP$ violation in
the hyperon sector can be significant, reaching the current empirical bounds,
after taking into account constraints from kaon mixing and decay and from
dark-matter relic-density data and direct searches including the Migdal effect.
We demonstrate that the hyperon and kaon processes are complementary probes of
this new-physics scenario. Its prediction for sizable hyperon $CP$ violation is
potentially testable in ongoing experiments, such as BESIII, Belle II, and
LHCb, and in next-generation ones like PANDA and at the Super Tau Charm
Facility.",http://arxiv.org/abs/2502.09603v1
"Neuro-Conceptual Artificial Intelligence: Integrating OPM with Deep
  Learning to Enhance Question Answering Quality",2025-02-12T06:10:09Z,"Xin Kang, Veronika Shteingardt, Yuhan Wang, Dov Dori","Knowledge representation and reasoning are critical challenges in Artificial
Intelligence (AI), particularly in integrating neural and symbolic approaches
to achieve explainable and transparent AI systems. Traditional knowledge
representation methods often fall short of capturing complex processes and
state changes. We introduce Neuro-Conceptual Artificial Intelligence (NCAI), a
specialization of the neuro-symbolic AI approach that integrates conceptual
modeling using Object-Process Methodology (OPM) ISO 19450:2024 with deep
learning to enhance question-answering (QA) quality. By converting natural
language text into OPM models using in-context learning, NCAI leverages the
expressive power of OPM to represent complex OPM elements-processes, objects,
and states-beyond what traditional triplet-based knowledge graphs can easily
capture. This rich structured knowledge representation improves reasoning
transparency and answer accuracy in an OPM-QA system. We further propose
transparency evaluation metrics to quantitatively measure how faithfully the
predicted reasoning aligns with OPM-based conceptual logic. Our experiments
demonstrate that NCAI outperforms traditional methods, highlighting its
potential for advancing neuro-symbolic AI by providing rich knowledge
representations, measurable transparency, and improved reasoning.",http://arxiv.org/abs/2502.09658v1
"Revealing Subtle Phenotypes in Small Microscopy Datasets Using Latent
  Diffusion Models",2025-02-12T15:45:19Z,"Anis Bourou, Biel Castaño Segade, Thomas Boye, Valérie Mezger, Auguste Genovesio","Identifying subtle phenotypic variations in cellular images is critical for
advancing biological research and accelerating drug discovery. These variations
are often masked by the inherent cellular heterogeneity, making it challenging
to distinguish differences between experimental conditions. Recent advancements
in deep generative models have demonstrated significant potential for revealing
these nuanced phenotypes through image translation, opening new frontiers in
cellular and molecular biology as well as the identification of novel
biomarkers. Among these generative models, diffusion models stand out for their
ability to produce high-quality, realistic images. However, training diffusion
models typically requires large datasets and substantial computational
resources, both of which can be limited in biological research. In this work,
we propose a novel approach that leverages pre-trained latent diffusion models
to uncover subtle phenotypic changes. We validate our approach qualitatively
and quantitatively on several small datasets of microscopy images. Our findings
reveal that our approach enables effective detection of phenotypic variations,
capturing both visually apparent and imperceptible differences. Ultimately, our
results highlight the promising potential of this approach for phenotype
detection, especially in contexts constrained by limited data and computational
capacity.",http://arxiv.org/abs/2502.09665v1
"Channel Dependence, Limited Lookback Windows, and the Simplicity of
  Datasets: How Biased is Time Series Forecasting?",2025-02-13T13:35:10Z,"Ibram Abdelmalak, Kiran Madhusudhanan, Jungmin Choi, Maximilian Stubbemann, Lars Schmidt-Thieme","Time-series forecasting research has converged to a small set of datasets and
a standardized collection of evaluation scenarios. Such a standardization is to
a specific extent needed for comparable research. However, the underlying
assumption is, that the considered setting is a representative for the problem
as a whole. In this paper, we challenge this assumption and show that the
current scenario gives a strongly biased perspective on the state of
time-series forecasting research. To be more detailed, we show that the current
evaluation scenario is heavily biased by the simplicity of the current
datasets. We furthermore emphasize, that when the lookback-window is properly
tuned, current models usually do not need any information flow across channels.
However, when using more complex benchmark data, the situation changes: Here,
modeling channel-interactions in a sophisticated manner indeed enhances
performances. Furthermore, in this complex evaluation scenario, Crossformer, a
method regularly neglected as an important baseline, is the SOTA method for
time series forecasting. Based on this, we present the Fast Channel-dependent
Transformer (FaCT), a simplified version of Crossformer which closes the
runtime gap between Crossformer and TimeMixer, leading to an efficient model
for complex forecasting datasets.",http://arxiv.org/abs/2502.09683v1
Lattice Schwinger Model and Spacetime Supersymmetry,2025-02-13T19:00:00Z,"Yanting Cheng, Shang Liu","Gauge theories in (1+1)D have attracted renewed attention partially due to
their experimental realizations in quantum simulation platforms. In this work,
we revisit the lattice massive Schwinger model and the (1+1)D lattice
Abelian-Higgs model, uncovering previously overlooked universal features,
including the emergence of a supersymmetric quantum critical point when the
Maxwell term's coefficient changes sign. To facilitate the quantum simulation
of these theories, we adopt a strategy of truncating the electric field
eigenvalues to a finite subset, preserving the exact gauge and global
symmetries. Our primary focus is the truncated lattice Schwinger model at
$\theta=0$, a model not equivalent to familiar spin models. We find that upon
reversing the sign of the Maxwell term, the second-order
deconfinement-confinement transition can become first-order, and the two types
of transitions are connected by a supersymmetric critical point in the
tricritical Ising universality class. In the case of truncated abelian-Higgs
model at $\theta=0$, which turns out to be equivalent to the quantum
Blume-Capel model, the very existence of a deconfined phase requires a
negative-sign Maxwell term. Similarly, there is a tricritical Ising point
separating first-order and second-order phase transitions.",http://arxiv.org/abs/2502.09697v1
Revealing correlated noise with single-qubit operations,2025-02-13T19:00:10Z,"Balázs Gulácsi, Joris Kattemölle, Guido Burkard","Spatially correlated noise poses a significant challenge to fault-tolerant
quantum computation by breaking the assumption of independent errors. Existing
methods such as cycle benchmarking and quantum process tomography can
characterize noise correlations but require substantial resources. We propose
straightforward and efficient techniques to detect and quantify these
correlations by leveraging collective phenomena arising from environmental
correlations in a qubit register. In these techniques, single-qubit state
preparations, single-qubit gates, and single-qubit measurements, combined with
classical post-processing, suffice to uncover correlated relaxation and
dephasing. Specifically, we use that correlated relaxation is connected to the
superradiance effect which we show to be accessible by single-qubit
measurements. Analogously, the established parity oscillation protocol can be
refined to reveal correlated dephasing through characteristic changes in the
oscillation line shape, without requiring the preparation of complex and
entangled states.",http://arxiv.org/abs/2502.09706v1
"Transtiff: A Stylus-shaped Interface for Rendering Perceived Stiffness
  of Virtual Objects via Stylus Stiffness Control",2025-02-14T04:14:30Z,"Ryoya Komatsu, Ayumu Ogura, Shigeo Yoshida, Kazutoshi Tanaka, Yuichi Itoh","The replication of object stiffness is essential for enhancing haptic
feedback in virtual environments. However, existing research has overlooked how
stylus stiffness influences the perception of virtual object stiffness during
tool-mediated interactions. To address this, we conducted a psychophysical
experiment demonstrating that changing stylus stiffness combined with visual
stimuli altered users' perception of virtual object stiffness. Based on these
insights, we developed Transtiff, a stylus-shaped interface capable of
on-demand stiffness control using a McKibben artificial muscle mechanism.
Unlike previous approaches, our method manipulates the perceived stiffness of
virtual objects via the stylus by controlling the stiffness of the stylus
without altering the properties of the real object being touched, creating the
illusion of a hard object feeing soft. Our user study confirmed that Transtiff
effectively simulates a range of material properties, such as sponge, plastic,
and tennis balls, providing haptic rendering that is closely aligned with the
perceived material characteristics. By addressing the challenge of delivering
realistic haptic feedback through tool-based interactions, Transtiff represents
a significant advancement in the haptic interface design for VR applications.",http://arxiv.org/abs/2502.09899v1
"Pressure-Induced Structural and Dielectric Changes in Liquid Water at
  Room Temperature",2025-02-14T05:02:28Z,"Yizhi Song, Xifan Wu","Understanding the pressure-dependent dielectric properties of water is
crucial for a wide range of scientific and practical applications. In this
study, we employ a deep neural network trained on density functional theory
data to investigate the dielectric properties of liquid water at room
temperature across a pressure range of 0.1 MPa to 1000 MPa. We observe a
nonlinear increase in the static dielectric constant $\epsilon_0$ with
increasing pressure, a trend that is qualitatively consistent with experimental
observations. This increase in $\epsilon_0$ is primarily attributed to the
increase in water density under compression, which enhances collective dipole
fluctuations within the hydrogen-bonding network as well as the dielectric
response. Despite the increase in $\epsilon_0$, our results reveal a decrease
in the Kirkwood correlation factor $G_K$ with increasing pressure. This
decrease in $G_K$ is attributed to pressure-induced structural distortions in
the hydrogen-bonding network, which weaken dipolar correlations by disrupting
the ideal tetrahedral arrangement of water molecules.",http://arxiv.org/abs/2502.09915v1
"Sensitivity study of a sapphire detector using Coherent Elastic
  Neutrino-Nucleus Scattering process",2025-02-14T07:58:53Z,S. P. Behera,"The Indian Coherent Neutrino-nucleus Scattering Experiment(ICNSE) has been
proposed at Bhabha Atomic Research Centre in India to measure the coherent
elastic neutrino-nucleus scattering process using electron antineutrinos
produced from reactors. Phenomenological studies are performed to find out the
sensitivity of sapphire detector for various fundamental physics parameters at
an exposure of one year. Reactors of different core compositions, sizes, and
thermal powers have been considered as sources of electron antineutrinos. The
potential of the ICNSE to measure the weak mixing angle at a low energy regime
has been extracted. Furthermore, the detector's capability has been
investigated for examining the electromagnetic properties of neutrinos,
including their magnetic moment. Additionally, an exploration has been
conducted on the detector's sensitivity in restricting new interactions between
neutrinos and electrons or nuclei, thereby constraining the parameter space
related to light mediators. It is found that the ICNSE detector can put a
stronger constraints on the scalar and vector mediators masses.",http://arxiv.org/abs/2502.09972v2
"Has My System Prompt Been Used? Large Language Model Prompt Membership
  Inference",2025-02-14T08:00:42Z,"Roman Levin, Valeriia Cherepanova, Abhimanyu Hans, Avi Schwarzschild, Tom Goldstein","Prompt engineering has emerged as a powerful technique for optimizing large
language models (LLMs) for specific applications, enabling faster prototyping
and improved performance, and giving rise to the interest of the community in
protecting proprietary system prompts. In this work, we explore a novel
perspective on prompt privacy through the lens of membership inference. We
develop Prompt Detective, a statistical method to reliably determine whether a
given system prompt was used by a third-party language model. Our approach
relies on a statistical test comparing the distributions of two groups of model
outputs corresponding to different system prompts. Through extensive
experiments with a variety of language models, we demonstrate the effectiveness
of Prompt Detective for prompt membership inference. Our work reveals that even
minor changes in system prompts manifest in distinct response distributions,
enabling us to verify prompt usage with statistical significance.",http://arxiv.org/abs/2502.09974v1
"Wavefront Solutions for Reaction-diffusion-convection Models with
  Accumulation Term and Aggregative Movements",2025-02-14T09:12:37Z,"Marco Cantarini, Cristina Marcelli, Francesca Papalini","In this paper we analyze the wavefront solutions of parabolic partial
differential equations of the type \[
g(u)u_{\tau}+f(u)u_{x}=\left(D(u)u_{x}\right)_{x}+\rho(u),\quad
u\left(\tau,x\right)\in[0,1] \] where the reaction term $\rho$ is of
monostable-type. We allow the diffusivity $D$ and the accumulation term $g$ to
have a finite number of changes of sign.
  We provide an existence result of travelling wave solutions (t.w.s.) together
with an estimate of the threshold wave speed. Finally, we classify the t.w.s.
between classical and sharp ones.",http://arxiv.org/abs/2502.10026v1
"Structuring the Environment Nudges Participants Toward Hierarchical Over
  Shortest Path Planning",2025-02-14T11:45:46Z,"Valeria Simonelli, Davide Nuzzi, Gian Luca Lancia, Giovanni Pezzulo","Effective planning is crucial for navigating complex environments and
achieving goals efficiently. In this study, we investigated how environmental
structure influences the selection of planning strategies. Participants
navigated a space station to collect colored spheres, with environments either
structured (spheres grouped by color) or unstructured (spheres scattered
randomly). We tested three types of plans: hierarchical (grouping spheres by
color), shortest path (minimizing travel distance), and neutral (none of the
above). By manipulating environmental structure, we were able to nudge
participants toward a preference for hierarchical planning in structured
environments, while shortest path plans were favored in unstructured
environments. A mismatch between self-reported preferences and actual choices
indicated that participants often adopted implicit strategies, unaware of their
decision-making processes. These findings highlight the powerful effect of
environmental cues on planning and suggest that even subtle changes in
structure can guide the selection of planning strategies.",http://arxiv.org/abs/2502.10098v1
A Recolouring Version of a Conjecture of Reed,2025-02-14T13:19:30Z,"Lucas De Meyer, Clément Legrand-Duchesne, Jared León, Tim Planken, Youri Tamitegama","Reed conjectured that the chromatic number of any graph is closer to its
clique number than to its maximum degree plus one. We consider a recolouring
version of this conjecture, with respect to Kempe changes. Namely, we
investigate the largest $\varepsilon$ such that all graphs $G$ are
$k$-recolourable for all $k \ge \lceil \varepsilon \omega(G) + (1
-\varepsilon)(\Delta(G)+1) \rceil$. For general graphs, an existing
construction of a frozen colouring shows that $\varepsilon \le 1/3$. We show
that this construction is optimal in the sense that there are no frozen
colourings below that threshold. For this reason, we conjecture that
$\varepsilon = 1/3$. For triangle-free graphs, we give a construction of frozen
colourings that shows that $\varepsilon \le 4/9$, and prove that it is also
optimal. In the special case of odd-hole-free graphs, we show that $\varepsilon
= 1/2$, and that this is tight up to one colour.",http://arxiv.org/abs/2502.10147v1
"STMA: A Spatio-Temporal Memory Agent for Long-Horizon Embodied Task
  Planning",2025-02-14T14:12:09Z,"Mingcong Lei, Yiming Zhao, Ge Wang, Zhixin Mai, Shuguang Cui, Yatong Han, Jinke Ren","A key objective of embodied intelligence is enabling agents to perform
long-horizon tasks in dynamic environments while maintaining robust
decision-making and adaptability. To achieve this goal, we propose the
Spatio-Temporal Memory Agent (STMA), a novel framework designed to enhance task
planning and execution by integrating spatio-temporal memory. STMA is built
upon three critical components: (1) a spatio-temporal memory module that
captures historical and environmental changes in real time, (2) a dynamic
knowledge graph that facilitates adaptive spatial reasoning, and (3) a
planner-critic mechanism that iteratively refines task strategies. We evaluate
STMA in the TextWorld environment on 32 tasks, involving multi-step planning
and exploration under varying levels of complexity. Experimental results
demonstrate that STMA achieves a 31.25% improvement in success rate and a 24.7%
increase in average score compared to the state-of-the-art model. The results
highlight the effectiveness of spatio-temporal memory in advancing the memory
capabilities of embodied agents.",http://arxiv.org/abs/2502.10177v1
"Looking around you: external information enhances representations for
  event sequences",2025-02-14T14:59:37Z,"Maria Kovaleva, Petr Sokerin, Sofia Krehova, Alexey Zaytsev","Representation learning produces models in different domains, such as store
purchases, client transactions, and general people's behaviour. However, such
models for sequential data usually process a single sequence, ignoring context
from other relevant ones, even in domains with rapidly changing external
environments like finance or misguiding the prediction for a user with no
recent events.
  We are the first to propose a method that aggregates information from
multiple user representations augmenting a specific user one for a scenario of
multiple co-occurring event sequences. Our study considers diverse aggregation
approaches, ranging from simple pooling techniques to trainable attention-based
approaches, especially Kernel attention aggregation, that can highlight more
complex information flow from other users. The proposed method operates atop an
existing encoder and supports its efficient fine-tuning. Across considered
datasets of financial transactions and downstream tasks, Kernel attention
improves ROC AUC scores, both with and without fine-tuning, while mean pooling
yields a smaller but still significant gain.",http://arxiv.org/abs/2502.10205v1
"Understanding the relationships between the perceptions of burnout and
  instability in Software Engineering",2025-02-14T15:59:30Z,Danilo Monteiro Ribeiro,"Changes are inherent in software development, often increasing developers'
perception of instability. Understanding the relationship between human factors
and Software Engineering processes is crucial to mitigating and preventing
issues. One such factor is burnout, a recognized disease that impacts
productivity, turnover, and, most importantly, developers' well-being.
Investigating the link between instability and burnout can help organizations
implement strategies to improve developers' work conditions and performance.
  This study aims to identify and describe the relationship between perceived
instability and burnout among software developers. A cross-sectional survey was
conducted with 411 respondents, using convenience sampling and self-selection.
In addition to analyzing variable relationships, confirmatory factor analysis
was applied.
  Key findings include: (1) A significant positive relationship between burnout
(exhaustion and cynicism) and team, technological, and task instability; (2) A
weak negative relationship between efficacy and technological/team instability,
with no correlation to task instability; (3) Exhaustion was the most frequently
reported burnout symptom, while task instability was the most perceived type of
instability.
  These results are valuable for both industry and academia, providing insights
to reduce burnout and instability among software engineers. Future research can
further explore the impact of instability, offering new perspectives on
monitoring and mitigating its effects in software development.",http://arxiv.org/abs/2502.10249v1
Analog Quantum Teleportation,2025-02-14T16:03:05Z,"Uesli Alushi, Simone Felicetti, Roberto Di Candia","Digital teleportation protocols make use of entanglement, local measurements
and a classical communication channel to transfer quantum states between remote
parties. We consider analog teleportation protocols, where classical
communication is replaced by transmission through a noisy quantum channel. We
show that analog teleportation protocols outperform digital protocols if and
only if Alice and Bob are linked by a channel that does not reduce entanglement
when applied to a part of the resource state. We first derive general
analytical results in the broader context of Gaussian-channel simulation. Then,
we apply it to the quantum teleportation of a uniformly distributed codebook of
coherent states, showing that an analog protocol is optimal for a wide range of
communication channel transmissivities. Our result contributes to mitigating
noise in the intermediate case when the communication channel is far from being
ideal but is not too lossy, as is the case of cryogenic links in microwave
superconducting circuits.",http://arxiv.org/abs/2502.10253v2
Probing Perceptual Constancy in Large Vision Language Models,2025-02-14T16:31:43Z,"Haoran Sun, Suyang Yu, Yijiang Li, Qingying Gao, Haiyun Lyu, Hokin Deng, Dezhi Luo","Perceptual constancy is the ability to maintain stable perceptions of objects
despite changes in sensory input, such as variations in distance, angle, or
lighting. This ability is crucial for recognizing visual information in a
dynamic world, making it essential for Vision-Language Models (VLMs). However,
whether VLMs are currently and theoretically capable of mastering this ability
remains underexplored. In this study, we evaluated 33 VLMs using 253
experiments across three domains: color, size, and shape constancy. The
experiments included single-image and video adaptations of classic cognitive
tasks, along with novel tasks in in-the-wild conditions, to evaluate the
models' recognition of object properties under varying conditions. We found
significant variability in VLM performance, with models performance in shape
constancy clearly dissociated from that of color and size constancy.",http://arxiv.org/abs/2502.10273v1
"Detection of a peculiar noise type in the TESS ""fast"" light curves",2025-02-14T17:36:33Z,"Sz. Kálmán, Sz. Csizmadia, A. Pál, Gy. M. Szabó","We present the detection of a peculiar high-frequency noise component in the
20 second cadence SAP (Simple Aperture Photometry) light curve of TESS
(Transiting Exoplanets Survey Satellite). This effect (labeled as blue noise)
may be attributed to the pointing instability (also known as satellite jiiter)
of the satellite. We present a common technique used in the mitigation of the
jitter, by decorrelating against the subpixel position of the photo-center of
the point spread function of the star. We also show that a simple linear or
polynomial technique may not yield satisfactory corrections, as the behavior or
attitude of the noise properties may change considerably throughout the light
curve.",http://arxiv.org/abs/2502.10326v1
"Organize the Web: Constructing Domains Enhances Pre-Training Data
  Curation",2025-02-14T18:02:37Z,"Alexander Wettig, Kyle Lo, Sewon Min, Hannaneh Hajishirzi, Danqi Chen, Luca Soldaini","Modern language models are trained on large, unstructured datasets consisting
of trillions of tokens and obtained by crawling the web. The unstructured
nature makes it difficult to reason about their contents and develop systematic
approaches to data curation. In this paper, we unpack monolithic web corpora by
developing taxonomies of their contents and organizing them into domains. We
introduce WebOrganizer, a framework for organizing web pages in terms of both
their topic and format. Using these two complementary notions of domains, we
automatically annotate pre-training data by distilling annotations from a large
language model into efficient classifiers. This allows us to study how data
from different domains should be mixed to improve models on downstream tasks,
and we show that we can combine insights about effective topics and formats to
further boost performance. We demonstrate that our domain mixing also improves
existing methods that select data based on quality. Furthermore, we study and
compare how quality-based methods will implicitly change the domain mixture.
Overall, our work demonstrates that constructing and mixing domains provides a
valuable complement to quality-based data curation methods, opening new avenues
for effective and insightful pre-training data curation.",http://arxiv.org/abs/2502.10341v1
DRiVE: Dynamic Recognition in VEhicles using snnTorch,2025-02-04T11:01:13Z,"Heerak Vora, Param Pathak, Parul Bakaraniya","Spiking Neural Networks (SNNs) mimic biological brain activity, processing
data efficiently through an event-driven design, wherein the neurons activate
only when inputs exceed specific thresholds. Their ability to track voltage
changes over time via membrane potential dynamics helps retain temporal
information. This study combines SNNs with PyTorch's adaptable framework,
snnTorch, to test their potential for image-based tasks. We introduce DRiVE, a
vehicle detection model that uses spiking neuron dynamics to classify images,
achieving 94.8% accuracy and a near-perfect 0.99 AUC score. These results
highlight DRiVE's ability to distinguish vehicle classes effectively,
challenging the notion that SNNs are limited to temporal data. As interest
grows in energy-efficient neural models, DRiVE's success emphasizes the need to
refine SNN optimization for visual tasks. This work encourages broader
exploration of SNNs in scenarios where conventional networks struggle,
particularly for real-world applications requiring both precision and
efficiency.",http://arxiv.org/abs/2502.10421v1
A Robust Attack: Displacement Backdoor Attack,2025-02-14T13:15:13Z,"Yong Li, Han Gao","As artificial intelligence becomes more prevalent in our lives, people are
enjoying the convenience it brings, but they are also facing hidden threats,
such as data poisoning and adversarial attacks. These threats can have
disastrous consequences for the application of artificial intelligence,
especially for some applications that take effect immediately, such as
autonomous driving and medical fields. Among these threats, backdoor attacks
have left a deep impression on people with their concealment and simple
deployment, making them a threat that cannot be ignored, however, in the
process of deploying the backdoor model, the backdoor attack often has some
reasons that make it unsatisfactory in real-world applications, such as jitter
and brightness changes. Based on this, we propose a highly robust backdoor
attack that shifts the target sample and combines it with itself to form a
backdoor sample, the Displacement Backdoor Attack(DBA). Experimental results
show that the DBA attack can resist data augmentation that simulates real-world
differences, such as rotation and cropping.",http://arxiv.org/abs/2502.10490v1
SWA-LDM: Toward Stealthy Watermarks for Latent Diffusion Models,2025-02-14T16:55:45Z,"Zhonghao Yang, Linye Lyu, Xuanhang Chang, Daojing He, YU LI","In the rapidly evolving landscape of image generation, Latent Diffusion
Models (LDMs) have emerged as powerful tools, enabling the creation of highly
realistic images. However, this advancement raises significant concerns
regarding copyright infringement and the potential misuse of generated content.
Current watermarking techniques employed in LDMs often embed constant signals
to the generated images that compromise their stealthiness, making them
vulnerable to detection by malicious attackers. In this paper, we introduce
SWA-LDM, a novel approach that enhances watermarking by randomizing the
embedding process, effectively eliminating detectable patterns while preserving
image quality and robustness. Our proposed watermark presence attack reveals
the inherent vulnerabilities of existing latent-based watermarking methods,
demonstrating how easily these can be exposed. Through comprehensive
experiments, we validate that SWA-LDM not only fortifies watermark stealthiness
but also maintains competitive performance in watermark robustness and visual
fidelity. This work represents a pivotal step towards securing LDM-generated
images against unauthorized use, ensuring both copyright protection and content
integrity in an era where digital image authenticity is paramount.",http://arxiv.org/abs/2502.10495v1
"A Comprehensive Hyperledger Fabric Performance Evaluation based on
  Resources Capacity Planning",2025-02-14T19:14:06Z,"Carlos Melo, Glauber Gonçalves, Francisco A. Silva, André Soares","Hyperledger Fabric is a platform for permissioned blockchain networks that
enables secure and auditable distributed data storage for enterprise
applications. There is a growing interest in applications based on this
platform, but its use requires the configuration of different blockchain
parameters. Various configurations impact the system's non-functional
qualities, especially performance and cost. In this article, we propose a
Stochastic Petri Net to model the performance of the Hyperledger Fabric
platform with different blockchain parameters, computer capacity, and
transaction rates. We also present a set of case studies to demonstrate the
feasibility of the proposed model. This model serves as a practical guide to
help administrators of permissioned blockchain networks find the best
performance for their applications. The proposed model allowed us to identify
the block size that leads to a high mean response time (ranging from 1 to 25
seconds) caused by a change in the arrival rate.",http://arxiv.org/abs/2502.10509v1
"VisiMark: Characterizing and Augmenting Landmarks for People with Low
  Vision in Augmented Reality to Support Indoor Navigation",2025-02-14T21:23:55Z,"Ruijia Chen, Junru Jiang, Pragati Maheshwary, Brianna R. Cochran, Yuhang Zhao","Landmarks are critical in navigation, supporting self-orientation and mental
model development. Similar to sighted people, people with low vision (PLV)
frequently look for landmarks via visual cues but face difficulties identifying
some important landmarks due to vision loss. We first conducted a formative
study with six PLV to characterize their challenges and strategies in landmark
selection, identifying their unique landmark categories (e.g., area
silhouettes, accessibility-related objects) and preferred landmark
augmentations. We then designed VisiMark, an AR interface that supports
landmark perception for PLV by providing both overviews of space structures and
in-situ landmark augmentations. We evaluated VisiMark with 16 PLV and found
that VisiMark enabled PLV to perceive landmarks they preferred but could not
easily perceive before, and changed PLV's landmark selection from only
visually-salient objects to cognitive landmarks that are more important and
meaningful. We further derive design considerations for AR-based landmark
augmentation systems for PLV.",http://arxiv.org/abs/2502.10561v1
Observer-Aware Probabilistic Planning Under Partial Observability,2025-02-14T21:41:04Z,"Salomé Lepers, Vincent Thomas, Olivier Buffet","In this article, we are interested in planning problems where the agent is
aware of the presence of an observer, and where this observer is in a partial
observability situation. The agent has to choose its strategy so as to optimize
the information transmitted by observations. Building on observer-aware Markov
decision processes (OAMDPs), we propose a framework to handle this type of
problems and thus formalize properties such as legibility, explicability and
predictability. This extension of OAMDPs to partial observability can not only
handle more realistic problems, but also permits considering dynamic hidden
variables of interest. These dynamic target variables allow, for instance,
working with predictability, or with legibility problems where the goal might
change during execution. We discuss theoretical properties of PO-OAMDPs and,
experimenting with benchmark problems, we analyze HSVI's convergence behavior
with dedicated initializations and study the resulting strategies.",http://arxiv.org/abs/2502.10568v1
"Tusqh: Topological Control of Volume-Fraction Meshes Near Small Features
  and Dirty Geometry",2025-02-14T23:54:48Z,"Brian Shawcroft, Kendrick M. Shepherd, Scott Mitchell","This work develops a framework to create meshes with user-specified homology
from potentially dirty geometry by coupling background grids, persistent
homology, and a generalization of volume fractions. For a mesh with fixed grid
size, the topology of the output mesh changes predictably and monotonically as
its volume-fraction threshold decreases. Topological anti-aliasing methods are
introduced to resolve pinch points and disconnected regions that are artifacts
of user choice of grid size and orientation, making the output meshes suitable
for downstream processes including analysis. The methodology is demonstrated on
geographical, mechanical, and graphics models in 2D and 3D using a custom-made
software called Tusqh. The work demonstrates that the proposed framework is
viable for generating meshes on topologically invalid geometries and for
automatic defeaturing of small geometric artifacts. Finally, the work shows
that although subdividing the background grid frequently improves the
topological and geometrical fidelity of the output mesh, there are simple 2D
examples for which the topology does not converge under refinement for
volume-fraction codes.",http://arxiv.org/abs/2502.10609v1
"Dynamic Influence Tracker: Measuring Time-Varying Sample Influence
  During Training",2025-02-15T13:24:21Z,"Jie Xu, Zihan Wu","Existing methods for measuring training sample influence on models only
provide static, overall measurements, overlooking how sample influence changes
during training. We propose Dynamic Influence Tracker (DIT), which captures the
time-varying sample influence across arbitrary time windows during training.
  DIT offers three key insights: 1) Samples show different time-varying
influence patterns, with some samples important in the early training stage
while others become important later. 2) Sample influences show a weak
correlation between early and late stages, demonstrating that the model
undergoes distinct learning phases with shifting priorities. 3) Analyzing
influence during the convergence period provides more efficient and accurate
detection of corrupted samples than full-training analysis. Supported by
theoretical guarantees without assuming loss convexity or model convergence,
DIT significantly outperforms existing methods, achieving up to 0.99
correlation with ground truth and above 98\% accuracy in detecting corrupted
samples in complex architectures.",http://arxiv.org/abs/2502.10793v1
"Quantum phase transitions in a Dicke trimer with both photon and atom
  hoppings",2025-02-15T16:03:48Z,"Jun-Wen Luo, Bo Wang, Ze-Liang Xiang","We investigate superradiant quantum phase transitions in a Dicke trimer model
consisting of two types of hoppings, i.e., photon hoppings and atom hoppings.
In the superradiant regime, the system can exist in two distinct phases: normal
and frustrated superradiant phases, which are governed by both types of
hoppings. Particularly, the interplay between these hoppings gives rise to
interesting effects, such as triggering superradiance with much lower coupling
strengths when both hoppings exhibit the same tendency. In contrast, with
opposite tendencies, the competition between hoppings leads to a first-order
phase transition between two different superradiant phases with translational
symmetry broken. These findings enable the system to undergo a sequence of
transitions across three phases by changing the coupling strength. Our work
provides deep insights into competing interactions and quantum phase
transitions in multi-cavity systems with geometric structures.",http://arxiv.org/abs/2502.10839v1
Accelerated co-design of robots through morphological pretraining,2025-02-15T17:20:56Z,"Luke Strgar, Sam Kriegman","The co-design of robot morphology and neural control typically requires using
reinforcement learning to approximate a unique control policy gradient for each
body plan, demanding massive amounts of training data to measure the
performance of each design. Here we show that a universal, morphology-agnostic
controller can be rapidly and directly obtained by gradient-based optimization
through differentiable simulation. This process of morphological pretraining
allows the designer to explore non-differentiable changes to a robot's physical
layout (e.g. adding, removing and recombining discrete body parts) and
immediately determine which revisions are beneficial and which are deleterious
using the pretrained model. We term this process ""zero-shot evolution"" and
compare it with the simultaneous co-optimization of a universal controller
alongside an evolving design population. We find the latter results in
diversity collapse, a previously unknown pathology whereby the population --
and thus the controller's training data -- converges to similar designs that
are easier to steer with a shared universal controller. We show that zero-shot
evolution with a pretrained controller quickly yields a diversity of highly
performant designs, and by fine-tuning the pretrained controller on the current
population throughout evolution, diversity is not only preserved but
significantly increased as superior performance is achieved.",http://arxiv.org/abs/2502.10862v1
"""Business on WhatsApp is tough now -- but am I really a businesswoman?""
  Exploring Challenges with Adapting to Changes in WhatsApp Business",2025-02-15T21:46:42Z,Ankolika De,"This study examines how WhatsApp has evolved from a personal communication
tool to a professional platform, focusing on its use by small business owners
in India. Initially embraced in smaller, rural communities for its ease of use
and familiarity, WhatsApp played a crucial role in local economies. However, as
Meta introduced WhatsApp Business with new, formalized features, users
encountered challenges in adapting to the more complex and costly platform.
Interviews with 14 small business owners revealed that while they adapted
creatively, they felt marginalized by the advanced tools. This research
contributes to HCI literature by exploring the transition from personal to
professional use and introduces the concept of Coercive Professionalization. It
highlights how standardization by large tech companies affects marginalized
users, exacerbating power imbalances and reinforcing digital colonialism,
concluding with design implications for supporting community-based
appropriations.",http://arxiv.org/abs/2502.10913v1
"Density-dependent spin susceptibility and effective mass in monolayer
  MoSe2",2025-02-16T03:23:16Z,"Chang Liu, Tongtong Jia, Zheng Sun, Yu Gu, Fan Xu, Kenji Watanabe, Takashi Taniguchi, Jinfeng Jia, Shiyong Wang, Xiaoxue Liu, Tingxin Li","Atomically thin MoSe2 is a promising platform for investigating quantum
phenomena due to its large effective mass, high crystal quality, and strong
spin-orbit coupling. In this work, we demonstrate a triple-gate device design
with bismuth contacts, enabling reliable ohmic contact down to low electron
densities, with a maximum Hall mobility of approximately 22,000 cm2/Vs.
Low-temperature transport measurements illustrate metal-insulator transitions,
and density-dependent quantum oscillation sequences. Enhanced spin
susceptibility and density-dependent effective mass are observed, attributed to
interaction effects and valley polarization. These findings establish monolayer
MoSe2 as a versatile platform for further exploring interaction-driven quantum
states.",http://arxiv.org/abs/2502.10972v1
"Streamlining the Collaborative Chain of Models into A Single Forward
  Pass in Generation-Based Tasks",2025-02-16T11:37:14Z,"Yuanjie Lyu, Chao Zhang, Yuhao Chen, Yong Chen, Tong Xu","In Retrieval-Augmented Generation (RAG) and agent-based frameworks, the
""Chain of Models"" approach is widely used, where multiple specialized models
work sequentially on distinct sub-tasks. This approach is effective but
increases resource demands as each model must be deployed separately. Recent
advancements attempt to address this by applying prompt tuning, which allows a
shared base model to adapt to multiple tasks with minimal parameter changes.
However, a key challenge remains: intermediate outputs, passed between models
as plain text, require recomputation of hidden states (i.e., Key and Value (KV)
states in Transformers) during inference. In this paper, we introduce FTHSS, a
novel prompt-tuning method that enables models to share KV hidden states,
eliminating redundant forward passes and reducing KV cache storage. By
modifying input and attention masks during training, FTHSS allows models to
effectively utilize KV hidden states from prior models in both single- and
multi-round scenarios. Empirical results on four tasks show that FTHSS matches
the performance of traditional model chains while improving inference
efficiency.",http://arxiv.org/abs/2502.11083v1
Parametric Analysis of Network Evolution Processes,2025-02-16T12:58:03Z,"Peter Williams, Zhan Chen","We present a comprehensive parametric analysis of node and edge lifetimes
processes in two large-scale collaboration networks: the Microsoft Academic
Graph (1800-2020) and Internet Movie Database (1900-2020). Node and edge
lifetimes (career and collaboration durations) follow Weibull distributions
with consistent shape parameters ($k \approx 0.2$ for academic, $k \approx 0.5$
for entertainment careers) across centuries of evolution. These distributions
persist despite dramatic changes in network size and structure. Edge processes
show domain-specific evolution: academic collaboration durations increase over
time (power-law index $1.6$ to $2.3$) while entertainment collaborations
maintain more stable patterns (index $2.6$ to $2.1$). These findings indicate
that while career longevity exhibits consistent patterns, collaboration
dynamics appear to be influenced by domain-specific factors. The results
provide new constraints for models of social network evolution, requiring
incorporation of both universal lifetime distributions and domain-specific
growth dynamics.",http://arxiv.org/abs/2502.11112v1
"Hierarchical Expert Prompt for Large-Language-Model: An Approach Defeat
  Elite AI in TextStarCraft II for the First Time",2025-02-16T13:36:31Z,"Zongyuan Li, Chang Lu, Xiaojie Xu, Runnan Qi, Yanan Ni, Lumin Jiang, Xiangbei Liu, Xuebo Zhang, Yongchun Fang, Kuihua Huang, Xian Guo","Since the emergence of the Large Language Model (LLM), LLM has been widely
used in fields such as writing, translating, and searching. However, there is
still great potential for LLM-based methods in handling complex tasks such as
decision-making in the StarCraft II environment. To address problems such as
lack of relevant knowledge and poor control over subtasks of varying
importance, we propose a Hierarchical Expert Prompt (HEP) for LLM. Our method
improves the understanding of game situations through expert-level tactical
knowledge, improving the processing quality of tasks of varying importance
through a hierarchical framework. Our approach defeated the highest level
(Elite) standard built-in agent in TextStarCraft II for the first time and
consistently outperformed the baseline method in other difficulties. Our
experiments suggest that the proposed method is a practical solution for
tackling complex decision-making challenges. The replay video can be viewed on
https://www.bilibili.com/video/BV1uz42187EF and https://youtu.be/dO3PshWLV5M,
and our codes have been open-sourced on
https://github.com/luchang1113/HEP-LLM-play-StarCraftII.",http://arxiv.org/abs/2502.11122v1
"Site-Decorated Model for Unconventional Frustrated Magnets with
  Ultranarrow Phase Crossover and Spin Reversal Transition",2025-02-16T21:10:42Z,Weiguo Yin,"The site-decorated Ising model is introduced to advance the understanding and
physical realization of the recently discovered one-dimensional
finite-temperature ultranarrow phase crossover in an external magnetic field,
overcoming the complexity of the traditional bond-decorated models from
geometric consideration. Furthermore, for higher-dimensional Ising models in
the presence of an external magnetic field, while they remain unsolved, an
exact solution about a novel spin-reversal transition -- accessible by a slight
change in temperature or the magnetic field, even in the weak field limit -- is
found to exist upon the site decoration. These results suggest a new route to
energy-efficient applications in, e.g., data storage and processing, and call
for materialization and device design with site decoration in, e.g., mixed
$d$-$f$ compounds, optical lattices, or neural networks.",http://arxiv.org/abs/2502.11270v1
"Targeting C99 Mediated Metabolic Disruptions with Ketone Therapy in
  Alzheimer's Disease",2025-02-17T03:25:46Z,"Hao Huang, Kaijing Xu, Michael Lardelli","INTRODUCTION: Alzheimer's disease (AD) involves neurodegeneration, metabolic
dysfunction, and proteostasis failure. While amyloid and tau pathology are well
studied, the role of metabolic dysregulation as an upstream driver remains
unclear.
  METHODS:We used Drosophila AD models expressing APP and BACE1 under the
neuron-specific driver, applying quantitative mass spectrometry (MS) to analyze
C99-induced proteomic changes and metabolic disruption. Additional biochemical
and imaging analyses were performed to assess mitochondrial function and
autophagy.
  RESULTS: C99 disrupted mitochondrial proteostasis, impairing TCA cycle
enzymes, fatty acid oxidation, and lysosomal clearance. Immunoprecipitation
confirmed C99's interaction with proteostasis regulators, leading to
neurodegenerative stress.
  DISCUSSION: Our findings extend previous models of AD pathogenesis by
demonstrating that C99 impairs lipid metabolism, disrupting ketone availability
and neuronal energy balance.",http://arxiv.org/abs/2502.11395v1
Does Editing Provide Evidence for Localization?,2025-02-17T05:09:46Z,"Zihao Wang, Victor Veitch","A basic aspiration for interpretability research in large language models is
to ""localize"" semantically meaningful behaviors to particular components within
the LLM. There are various heuristics for finding candidate locations within
the LLM. Once a candidate localization is found, it can be assessed by editing
the internal representations at the corresponding localization and checking
whether this induces model behavior that is consistent with the semantic
interpretation of the localization. The question we address here is: how strong
is the evidence provided by such edits? To evaluate the localization claim, we
want to assess the effect of the optimal intervention at a particular location.
The key new technical tool is a way of adapting LLM alignment techniques to
find such optimal localized edits. With this tool in hand, we give an example
where the edit-based evidence for localization appears strong, but where
localization clearly fails. Indeed, we find that optimal edits at random
localizations can be as effective as aligning the full model. In aggregate, our
results suggest that merely observing that localized edits induce targeted
changes in behavior provides little to no evidence that these locations
actually encode the target behavior.",http://arxiv.org/abs/2502.11447v2
"Semantically Robust Unsupervised Image Translation for Paired Remote
  Sensing Images",2025-02-17T05:57:57Z,"Sheng Fang, Kaiyu Li, Zhe Li, Jianli Zhao, Xingli Zhang","Image translation for change detection or classification in bi-temporal
remote sensing images is unique. Although it can acquire paired images, it is
still unsupervised. Moreover, strict semantic preservation in translation is
always needed instead of multimodal outputs. In response to these problems,
this paper proposes a new method, SRUIT (Semantically Robust Unsupervised
Image-to-image Translation), which ensures semantically robust translation and
produces deterministic output. Inspired by previous works, the method explores
the underlying characteristics of bi-temporal Remote Sensing images and designs
the corresponding networks. Firstly, we assume that bi-temporal Remote Sensing
images share the same latent space, for they are always acquired from the same
land location. So SRUIT makes the generators share their high-level layers, and
this constraint will compel two domain mapping to fall into the same latent
space. Secondly, considering land covers of bi-temporal images could evolve
into each other, SRUIT exploits the cross-cycle-consistent adversarial networks
to translate from one to the other and recover them. Experimental results show
that constraints of sharing weights and cross-cycle consistency enable
translated images with both good perceptual image quality and semantic
preservation for significant differences.",http://arxiv.org/abs/2502.11468v1
Effect of Numerically Controlled Oscillator Bit Width in Phase Meters,2025-02-17T09:51:12Z,"Yuan-Ze Jiang, Yu-Jie Feng, Liu-Yang Chen, Bai-Fu Lu, Qi Xia, Ze-Bing Zhou, Yu-Rong Liang","Projects aiming to detect gravitational waves (GWs) in space in the
millihertz range will utilize interferometers to measure the separations
between free-falling test masses. The phasemeter measures the phase changes of
the interference signals caused by the test masses' relative movements. The
measurement sensitivity of the phasemeter is one of the key factors in the
detection. In this work, we reviewed the core metrology of the phasemeter and
evaluated the ultra-low noise performance of the phasemeter with analog
signals. Frequency readout noise related to the bit width of the numerically
controlled oscillator (NCO) inside the phasemeter is identified as one of the
main noise sources of phase measurement theoretically and experimentally. After
increasing the NCO bit widths, the single-channel phase noise of the phasemeter
reached 2.0 {\mu}rad/Hz^{1/2} at 6 mHz, and the differential phase noise
reached 0.4 {\mu}rad/Hz^{1/2} at 6 mHz. The phase noise performances remained
consistent within the carrier frequency range of 4.9 MHz to 25.1 MHz.",http://arxiv.org/abs/2502.11608v1
"A Cholesky decomposition-based asset selection heuristic for sparse
  tangent portfolio optimization",2025-02-17T11:39:50Z,"Hyunglip Bae, Haeun Jeon, Minsu Park, Yongjae Lee, Woo Chang Kim","In practice, including large number of assets in mean-variance portfolios can
lead to higher transaction costs and management fees. To address this, one
common approach is to select a smaller subset of assets from the larger pool,
constructing more efficient portfolios. As a solution, we propose a new asset
selection heuristic which generates a pre-defined list of asset candidates
using a surrogate formulation and re-optimizes the cardinality-constrained
tangent portfolio with these selected assets. This method enables faster
optimization and effectively constructs portfolios with fewer assets, as
demonstrated by numerical analyses on historical stock returns. Finally, we
discuss a quantitative metric that can provide a initial assessment of the
performance of the proposed heuristic based on asset covariance.",http://arxiv.org/abs/2502.11701v1
"Component-aware Unsupervised Logical Anomaly Generation for Industrial
  Anomaly Detection",2025-02-17T11:54:43Z,"Xuan Tong, Yang Chang, Qing Zhao, Jiawen Yu, Boyang Wang, Junxiong Lin, Yuxuan Lin, Xinji Mai, Haoran Wang, Zeng Tao, Yan Wang, Wenqiang Zhang","Anomaly detection is critical in industrial manufacturing for ensuring
product quality and improving efficiency in automated processes. The scarcity
of anomalous samples limits traditional detection methods, making anomaly
generation essential for expanding the data repository. However, recent
generative models often produce unrealistic anomalies increasing false
positives, or require real-world anomaly samples for training. In this work, we
treat anomaly generation as a compositional problem and propose ComGEN, a
component-aware and unsupervised framework that addresses the gap in logical
anomaly generation. Our method comprises a multi-component learning strategy to
disentangle visual components, followed by subsequent generation editing
procedures. Disentangled text-to-component pairs, revealing intrinsic logical
constraints, conduct attention-guided residual mapping and model training with
iteratively matched references across multiple scales. Experiments on the
MVTecLOCO dataset confirm the efficacy of ComGEN, achieving the best AUROC
score of 91.2%. Additional experiments on the real-world scenario of Diesel
Engine and widely-used MVTecAD dataset demonstrate significant performance
improvements when integrating simulated anomalies generated by ComGEN into
automated production workflows.",http://arxiv.org/abs/2502.11712v1
"Bi-invariant Geodesic Regression with Data from the Osteoarthritis
  Initiative",2025-02-17T14:20:54Z,"Johannes Schade, Christoph von Tycowicz, Martin Hanik","Many phenomena are naturally characterized by measuring continuous
transformations such as shape changes in medicine or articulated systems in
robotics. Modeling the variability in such datasets requires performing
statistics on Lie groups, that is, manifolds carrying an additional group
structure. As the Lie group captures the symmetries in the data, it is
essential from a theoretical and practical perspective to ask for statistical
methods that respect these symmetries; this way they are insensitive to
confounding effects, e.g., due to the choice of reference coordinate systems.
In this work, we investigate geodesic regression -- a generalization of linear
regression originally derived for Riemannian manifolds. While Lie groups can be
endowed with Riemannian metrics, these are generally incompatible with the
group structure. We develop a non-metric estimator using an affine connection
setting. It captures geodesic relationships respecting the symmetries given by
left and right translations. For its computation, we propose an efficient fixed
point algorithm requiring simple differential expressions that can be
calculated through automatic differentiation. We perform experiments on a
synthetic example and evaluate our method on an open-access, clinical dataset
studying knee joint configurations under the progression of osteoarthritis.",http://arxiv.org/abs/2502.11826v1
Pulse Compression by an Optical Push Broom On a Chip,2025-02-17T15:19:57Z,"Boyi Zhang, Maurice Pfeiffer, Mahmoud A. Gaafar, He Li, Xinlun Cai, Juntao Li, Manfred Eich, Alexander Yu. Petrov","In this study, we report a first experimental demonstration of pulse
compression by a gradual refractive index front moving in a periodically
modulated silicon waveguide, the so-called optical push broom effect. Optical
push broom captures and confines the input signal pulse in a faster propagating
refractive index front, driven by a pump pulse. This is a spatio-temporal
analogue of light trapping in a tapered plasmonic waveguide where light is
continuously changing its wavevector approaching zero group velocity and, thus,
stopped without reflection. Here the signal is accelerated by the front until
the signal velocity matches the front velocity, thus stopping the light in
respect to the front. We employ the slowly varying envelope approximation to
model this phenomenon. Notably, we well reproduced the experimental frequency
shift at the output corresponding to the temporal delay at the input.",http://arxiv.org/abs/2502.11892v1
"Reconfigurable Intelligent Surfaces-Assisted Integrated Access and
  Backhaul",2025-02-17T16:46:15Z,"Charitha Madapatha, Behrooz Makki, Hao Guo, Tommy Svensson","In this paper, we study the impact of reconfigurable intelligent surfaces
(RISs) on the coverage extension of integrated access and backhaul (IAB)
networks. Particularly, using a finite stochastic geometry model, with random
distributions of user equipments (UEs) in a finite region, and planned
hierachical architecture for IAB, we study the service coverage probability
defined as the probability of the event that the UEs' minimum rate requirements
are satisfied. We present comparisons between different cases including
IAB-only, IAB assisted with RIS for backhaul as well as IAB assisted by network
controlled repeaters (NCRs). Our investigations focus on wide-area IAB assisted
with RIS through the lens of different design architectures and deployments,
revealing both conflicts and synergies for minimizing the effect of tree
foliage over seasonal changes. Our simulation results reveal both opportunities
and challenges towards the implementation of RIS in IAB.",http://arxiv.org/abs/2502.12011v1
Culture is Not Trivia: Sociocultural Theory for Cultural NLP,2025-02-17T17:25:11Z,"Naitian Zhou, David Bamman, Isaac L. Bleaman","The field of cultural NLP has recently experienced rapid growth, driven by a
pressing need to ensure that language technologies are effective and safe
across a pluralistic user base. This work has largely progressed without a
shared conception of culture, instead choosing to rely on a wide array of
cultural proxies. However, this leads to a number of recurring limitations:
coarse national boundaries fail to capture nuanced differences that lay within
them, limited coverage restricts datasets to only a subset of usually
highly-represented cultures, and a lack of dynamicity results in static
cultural benchmarks that do not change as culture evolves. In this position
paper, we argue that these methodological limitations are symptomatic of a
theoretical gap. We draw on a well-developed theory of culture from
sociocultural linguistics to fill this gap by 1) demonstrating in a case study
how it can clarify methodological constraints and affordances, 2) offering
theoretically-motivated paths forward to achieving cultural competence, and 3)
arguing that localization is a more useful framing for the goals of much
current work in cultural NLP.",http://arxiv.org/abs/2502.12057v1
Optimal Brain Iterative Merging: Mitigating Interference in LLM Merging,2025-02-17T09:07:49Z,"Zhixiang Wang, Zhenyu Mao, Yixuan Qiao, Yunfang Wu, Biye Li","Large Language Models (LLMs) have demonstrated impressive capabilities, but
their high computational costs pose challenges for customization. Model merging
offers a cost-effective alternative, yet existing methods suffer from
interference among parameters, leading to performance degradation. In this
work, we propose Optimal Brain Iterative Merging (OBIM), a novel method
designed to mitigate both intra-model and inter-model interference. OBIM
consists of two key components: (1) A saliency measurement mechanism that
evaluates parameter importance based on loss changes induced by individual
weight alterations, reducing intra-model interference by preserving only
high-saliency parameters. (2) A mutually exclusive iterative merging framework,
which incrementally integrates models using a binary mask to avoid direct
parameter averaging, thereby mitigating inter-model interference. We validate
OBIM through experiments on both Supervised Fine-Tuned (SFT) models and
post-pretrained checkpoints. The results show that OBIM significantly
outperforms existing merging techniques. Overall, OBIM provides an effective
and practical solution for enhancing LLM merging.",http://arxiv.org/abs/2502.12217v1
Multi-dimensional Test Design,2025-02-17T19:03:39Z,"Xiaoyun Qiu, Liren Shan","How should one jointly design tests and the arrangement of agencies to
administer these tests (testing procedure)? To answer this question, we analyze
a model where a principal must use multiple tests to screen an agent with a
multi-dimensional type, knowing that the agent can change his type at a cost.
We identify a new tradeoff between setting difficult tests and using a
difficult testing procedure. We compare two settings: (1) the agent only
misrepresents his type (manipulation) and (2) the agent improves his actual
type (investment). Examples include interviews, regulations, and data
classification. We show that in the manipulation setting, stringent tests
combined with an easy procedure, i.e., offering tests sequentially in a fixed
order, is optimal. In contrast, in the investment setting, non-stringent tests
with a difficult procedure, i.e., offering tests simultaneously, is optimal;
however, under mild conditions offering them sequentially in a random order may
be as good. Our results suggest that whether the agent manipulates or invests
in his type determines which arrangement of agencies is optimal.",http://arxiv.org/abs/2502.12264v1
"Asymptotic safety, quantum gravity, and the swampland: a conceptual
  assessment",2025-02-17T20:00:06Z,"Ivano Basile, Benjamin Knorr, Alessia Platania, Marc Schiffer","We provide a conceptual assessment of some aspects of fundamental quantum
field theories of gravity in light of foundational aspects of the swampland
program. On the one hand, asymptotically safe quantum gravity may provide a
simple and predictive framework, thanks to a finite number of relevant
parameters. On the other hand, a (sub-)set of intertwined swampland conjectures
on the consistency of quantum gravity can be argued to be universal via
effective field theory considerations. We answer whether some foundational
features of these frameworks are compatible. This involves revisiting and
refining several arguments (and loopholes) concerning the relation between
field-theoretic descriptions of gravity and general swampland ideas. We
identify the thermodynamics of black holes, spacetime topology change, and
holography as the core aspects of this relation. We draw lessons on the
features that a field theoretic description of gravity must (not) have to be
consistent with fundamental principles underlying the swampland program, and on
the universality of the latter.",http://arxiv.org/abs/2502.12290v1
Sensing-based Robustness Challenges in Agricultural Robotic Harvesting,2025-02-18T00:32:32Z,"C. Beldek, J. Cunningham, M. Aydin, E. Sariyildiz, S. L. Phung, G. Alici","This paper presents the challenges agricultural robotic harvesters face in
detecting and localising fruits under various environmental disturbances. In
controlled laboratory settings, both the traditional HSV (Hue Saturation Value)
transformation and the YOLOv8 (You Only Look Once) deep learning model were
employed. However, only YOLOv8 was utilised in outdoor experiments, as the HSV
transformation was not capable of accurately drawing fruit contours.
Experiments include ten distinct fruit patterns with six apples and six
oranges. A grid structure for homography (perspective) transformation was
employed to convert detected midpoints into 3D world coordinates. The
experiments evaluated detection and localisation under varying lighting and
background disturbances, revealing accurate performance indoors, but
significant challenges outdoors. Our results show that indoor experiments using
YOLOv8 achieved 100% detection accuracy, while outdoor conditions decreased
performance, with an average accuracy of 69.15% for YOLOv8 under direct
sunlight. The study demonstrates that real-world applications reveal
significant limitations due to changing lighting, background disturbances, and
colour and shape variability. These findings underscore the need for further
refinement of algorithms and sensors to enhance the robustness of robotic
harvesters for agricultural use.",http://arxiv.org/abs/2502.12403v1
Impurity-induced non-unitary criticality,2025-02-18T02:56:51Z,"Heng-Hsi Li, Kuang-Hung Chou, Xueda Wen, Po-Yao Chang","Quantum impurities give rise to rich physical phenomena, with some exhibiting
critical behavior described by conformal field theories (CFTs) in the
low-energy limit. In parallel, party-time ($\mathcal{PT}$) symmetric
non-Hermitian systems host exceptional points (EPs) at criticality, leading to
exotic features governed by non-unitary CFTs. Here, we establish a connection
between non-Hermitian impurities and CFTs by demonstrating that the critical
properties of a (1+1)-dimensional free-fermion chain with central charge $c=1$
can be drastically altered by the presence of a local non-Hermitian impurity.
Through a systematic analysis of entanglement/R\'enyi entropy, the finite-size
scaling of the many-body spectrum, and fidelity susceptibility, we identify
that this impurity-induced non-Hermitian criticality is characterized by a
non-unitary CFT with central charge $c=-2$. Furthermore, we find that these
non-unitary critical properties exhibit strong sensitivity to boundary
conditions.",http://arxiv.org/abs/2502.12469v1
Ultrasound measurement technique for the single-turn-coil magnets,2025-02-18T04:37:59Z,"T. Nomura, A. Hauspurg, D. I. Gorbunov, A. Miyata, E. Schulze, S. A. Zvyagin, V. Tsurkan, Y. H. Matsuda, Y. Kohama, S. Zherlitsyn","Ultrasound is a powerful means to study numerous phenomena of
condensed-matter physics as acoustic waves couple strongly to structural,
magnetic, orbital, and charge degrees of freedom. In this paper, we present
such technique combined with single-turn coils (STC) which generate magnetic
fields beyond 100 T with the typical pulse duration of 6 us. As a benchmark of
this technique, the ultrasound results for MnCr2S4, Cu6[Si6O18]6H2O, and liquid
oxygen are shown. The resolution for the relative sound-velocity change in the
STC is estimated as Delta v/v~10^-3, which is sufficient to study various
field-induced phase transitions and critical phenomena.",http://arxiv.org/abs/2502.12533v1
An Algorithm Board in Neural Decoding,2025-02-18T04:39:35Z,"Jingyi Feng, Kai Yang","Understanding the mechanisms of neural encoding and decoding has always been
a highly interesting research topic in fields such as neuroscience and
cognitive intelligence. In prior studies, some researchers identified a
symmetry in neural data decoded by unsupervised methods in motor scenarios and
constructed a cognitive learning system based on this pattern (i.e., symmetry).
Nevertheless, the distribution state of the data flow that significantly
influences neural decoding positions still remains a mystery within the system,
which further restricts the enhancement of the system's interpretability. Based
on this, this paper mainly explores changes in the distribution state within
the system from the machine learning and mathematical statistics perspectives.
In the experiment, we assessed the correctness of this symmetry using various
tools and indicators commonly utilized in mathematics and statistics. According
to the experimental results, the normal distribution (or Gaussian distribution)
plays a crucial role in the decoding of prediction positions within the system.
Eventually, an algorithm board similar to the Galton board was built to serve
as the mathematical foundation of the discovered symmetry.",http://arxiv.org/abs/2502.12536v1
"RM-PoT: Reformulating Mathematical Problems and Solving via Program of
  Thoughts",2025-02-18T06:54:32Z,"Yu Zhang, Shujun Peng, Nengwu Wu, Xinhan Lin, Yang Hu, Jie Tang","Recently, substantial advancements have been made in training language models
to carry out step-by-step reasoning for solving intricate numerical reasoning
tasks. Beyond the methods used to solve these problems, the structure and
formulation of the problems themselves also play a crucial role in determining
the performance of large language models. We observe that even small changes in
the surface form of mathematical problems can have a profound impact on both
the answer distribution and solve rate. This highlights the vulnerability of
LLMs to surface-level variations, revealing its limited robustness when
reasoning through complex problems. In this paper, we propose RM-PoT, a
three-stage framework that integrates problem reformulation (RM), code-aided
reasoning (PoT), and domain-aware few-shot learning to address these
limitations. Our approach first reformulates the input problem into diverse
surface forms to reduce structural bias, then retrieves five semantically
aligned examples from a pre-constructed domain-specific question bank to
provide contextual guidance, and finally generates executable Python code for
precise computation.",http://arxiv.org/abs/2502.12589v1
"Generalized Kernel Inducing Points by Duality Gap for Dataset
  Distillation",2025-02-18T07:43:13Z,"Tatsuya Aoyama, Hanting Yang, Hiroyuki Hanada, Satoshi Akahane, Tomonari Tanaka, Yoshito Okura, Yu Inatsu, Noriaki Hashimoto, Taro Murayama, Hanju Lee, Shinya Kojima, Ichiro Takeuchi","We propose Duality Gap KIP (DGKIP), an extension of the Kernel Inducing
Points (KIP) method for dataset distillation. While existing dataset
distillation methods often rely on bi-level optimization, DGKIP eliminates the
need for such optimization by leveraging duality theory in convex programming.
The KIP method has been introduced as a way to avoid bi-level optimization;
however, it is limited to the squared loss and does not support other loss
functions (e.g., cross-entropy or hinge loss) that are more suitable for
classification tasks. DGKIP addresses this limitation by exploiting an upper
bound on parameter changes after dataset distillation using the duality gap,
enabling its application to a wider range of loss functions. We also
characterize theoretical properties of DGKIP by providing upper bounds on the
test error and prediction consistency after dataset distillation. Experimental
results on standard benchmarks such as MNIST and CIFAR-10 demonstrate that
DGKIP retains the efficiency of KIP while offering broader applicability and
robust performance.",http://arxiv.org/abs/2502.12607v1
"Perovskite-LLM: Knowledge-Enhanced Large Language Models for Perovskite
  Solar Cell Research",2025-02-18T09:19:24Z,"Xiang Liu, Penglei Sun, Shuyan Chen, Longhan Zhang, Peijie Dong, Huajie You, Yongqi Zhang, Chang Yan, Xiaowen Chu, Tong-yi Zhang","The rapid advancement of perovskite solar cells (PSCs) has led to an
exponential growth in research publications, creating an urgent need for
efficient knowledge management and reasoning systems in this domain. We present
a comprehensive knowledge-enhanced system for PSCs that integrates three key
components. First, we develop Perovskite-KG, a domain-specific knowledge graph
constructed from 1,517 research papers, containing 23,789 entities and 22,272
relationships. Second, we create two complementary datasets: Perovskite-Chat,
comprising 55,101 high-quality question-answer pairs generated through a novel
multi-agent framework, and Perovskite-Reasoning, containing 2,217 carefully
curated materials science problems. Third, we introduce two specialized large
language models: Perovskite-Chat-LLM for domain-specific knowledge assistance
and Perovskite-Reasoning-LLM for scientific reasoning tasks. Experimental
results demonstrate that our system significantly outperforms existing models
in both domain-specific knowledge retrieval and scientific reasoning tasks,
providing researchers with effective tools for literature review, experimental
design, and complex problem-solving in PSC research.",http://arxiv.org/abs/2502.12669v1
"RadSplatter: Extending 3D Gaussian Splatting to Radio Frequencies for
  Wireless Radiomap Extrapolation",2025-02-18T09:44:38Z,"Yiheng Wang, Ye Xue, Shutao Zhang, Tsung-Hui Chang","A radiomap represents the spatial distribution of wireless signal strength,
critical for applications like network optimization and autonomous driving.
However, constructing radiomap relies on measuring radio signal power across
the entire system, which is costly in outdoor environments due to large network
scales. We present RadSplatter, a framework that extends 3D Gaussian Splatting
(3DGS) to radio frequencies for efficient and accurate radiomap extrapolation
from sparse measurements. RadSplatter models environmental scatterers and radio
paths using 3D Gaussians, capturing key factors of radio wave propagation. It
employs a relaxed-mean (RM) scheme to reparameterize the positions of 3D
Gaussians from noisy and dense 3D point clouds. A camera-free 3DGS-based
projection is proposed to map 3D Gaussians onto 2D radio beam patterns.
Furthermore, a regularized loss function and recursive fine-tuning using highly
structured sparse measurements in real-world settings are applied to ensure
robust generalization. Experiments on synthetic and real-world data show
state-of-the-art extrapolation accuracy and execution speed.",http://arxiv.org/abs/2502.12686v1
CausalMan: A physics-based simulator for large-scale causality,2025-02-18T10:20:22Z,"Nicholas Tagliapietra, Juergen Luettin, Lavdim Halilaj, Moritz Willig, Tim Pychynski, Kristian Kersting","A comprehensive understanding of causality is critical for navigating and
operating within today's complex real-world systems. The absence of realistic
causal models with known data generating processes complicates fair
benchmarking. In this paper, we present the CausalMan simulator, modeled after
a real-world production line. The simulator features a diverse range of linear
and non-linear mechanisms and challenging-to-predict behaviors, such as
discrete mode changes. We demonstrate the inadequacy of many state-of-the-art
approaches and analyze the significant differences in their performance and
tractability, both in terms of runtime and memory complexity. As a
contribution, we will release the CausalMan large-scale simulator. We present
two derived datasets, and perform an extensive evaluation of both.",http://arxiv.org/abs/2502.12707v1
"FedHC: A Hierarchical Clustered Federated Learning Framework for
  Satellite Networks",2025-02-18T11:44:09Z,"Zhuocheng Liu, Zhishu Shen, Pan Zhou, Qiushi Zheng, Jiong Jin","With the proliferation of data-driven services, the volume of data that needs
to be processed by satellite networks has significantly increased. Federated
learning (FL) is well-suited for big data processing in distributed,
resource-constrained satellite environments. However, ensuring its convergence
performance while minimizing processing time and energy consumption remains a
challenge. To this end, we propose a hierarchical clustered federated learning
framework, FedHC. This framework employs a satellite-clustered parameter server
(PS) selection algorithm at the cluster aggregation stage, grouping nearby
satellites into distinct clusters and designating a cluster center as the PS to
accelerate model aggregation. Several communicable cluster PS satellites are
then selected through ground stations to aggregate global parameters,
facilitating the FL process. Moreover, a meta-learning-driven satellite
re-clustering algorithm is introduced to enhance adaptability to dynamic
satellite cluster changes. The extensive experiments on satellite networks
testbed demonstrate that FedHC can significantly reduce processing time (up to
3x) and energy consumption (up to 2x) compared to other comparative methods
while maintaining model accuracy.",http://arxiv.org/abs/2502.12783v1
"Reasoning and the Trusting Behavior of DeepSeek and GPT: An Experiment
  Revealing Hidden Fault Lines in Large Language Models",2025-02-18T12:46:18Z,"Rubing Li, João Sedoc, Arun Sundararajan","When encountering increasingly frequent performance improvements or cost
reductions from a new large language model (LLM), developers of applications
leveraging LLMs must decide whether to take advantage of these improvements or
stay with older tried-and-tested models. Low perceived switching frictions can
lead to choices that do not consider more subtle behavior changes that the
transition may induce. Our experiments use a popular game-theoretic behavioral
economics model of trust to show stark differences in the trusting behavior of
OpenAI's and DeepSeek's models. We highlight a collapse in the economic trust
behavior of the o1-mini and o3-mini models as they reconcile profit-maximizing
and risk-seeking with future returns from trust, and contrast it with
DeepSeek's more sophisticated and profitable trusting behavior that stems from
an ability to incorporate deeper concepts like forward planning and
theory-of-mind. As LLMs form the basis for high-stakes commercial systems, our
results highlight the perils of relying on LLM performance benchmarks that are
too narrowly defined and suggest that careful analysis of their hidden fault
lines should be part of any organization's AI strategy.",http://arxiv.org/abs/2502.12825v2
A Survey of Text Classification Under Class Distribution Shift,2025-02-18T15:46:54Z,"Adriana Valentina Costache, Silviu Florin Gheorghe, Eduard Gabriel Poesina, Paul Irofti, Radu Tudor Ionescu","The basic underlying assumption of machine learning (ML) models is that the
training and test data are sampled from the same distribution. However, in
daily practice, this assumption is often broken, i.e.~the distribution of the
test data changes over time, which hinders the application of conventional ML
models. One domain where the distribution shift naturally occurs is text
classification, since people always find new topics to discuss. To this end, we
survey research articles studying open-set text classification and related
tasks. We divide the methods in this area based on the constraints that define
the kind of distribution shift and the corresponding problem formulation,
i.e.~learning with the Universum, zero-shot learning, and open-set learning. We
next discuss the predominant mitigation approaches for each problem setup.
Finally, we identify several future work directions, aiming to push the
boundaries beyond the state of the art. Interestingly, we find that continual
learning can solve many of the issues caused by the shifting class
distribution. We maintain a list of relevant papers at
https://github.com/Eduard6421/Open-Set-Survey.",http://arxiv.org/abs/2502.12965v1
"Recurrence threshold selection for obtaining robust recurrence
  characteristics in different embedding dimensions",2025-02-18T16:49:22Z,"K. Hauke Kraemer, Reik V. Donner, Jobst Heitzig, Norbert Marwan","The appropriate selection of recurrence thresholds is a key problem in
applications of recurrence quantification analysis and related methods across
disciplines. Here, we discuss the distribution of pairwise distances between
state vectors in the studied system's state space reconstructed by means of
time-delay embedding as the key characteristic that should guide the
corresponding choice for obtaining an adequate resolution of a recurrence plot.
Specifically, we present an empirical description of the distance distribution,
focusing on characteristic changes of its shape with increasing embedding
dimension. Our results suggest that selecting the recurrence threshold
according to a fixed percentile of this distribution reduces the dependence of
recurrence characteristics on the embedding dimension in comparison with other
commonly used threshold selection methods. Numerical investigations on some
paradigmatic model systems with time-dependent parameters support these
empirical findings.",http://arxiv.org/abs/2502.13036v1
"Hardy--Littlewood maximal operators on certain manifolds with bounded
  geometry",2025-02-18T18:22:20Z,"Stefano Meda, Stefano Pigola, Alberto G. Setti, Giona Veronelli","In this paper we study the $L^p$ boundedness of the centred and the uncentred
Hardy--Littlewood maximal operators on certain Riemannian manifolds with
bounded geometry. Our results complement those of various authors. We show
that, under mild assumptions, $L^p$ estimates for the centred operator are
``stable'' under conformal changes of the metric, and prove sharp~$L^p$
estimates for the centred operator on Riemannian models with pinched negative
scalar curvature. Furthermore, we prove that the centred operator is of weak
type $(1,1)$ on the connected sum of two space forms with negative curvature,
whereas the uncentred operator is, perhaps surprisingly, bounded only on
$L^\infty$. We also prove that if two locally doubling geodesic metric measure
spaces enjoying the uniform ball size condition are strictly quasi-isometric,
then they share the same boundedness properties for both the centred and the
uncentred maximal operator. Finally, we discuss some $L^p$ mapping properties
for the centred operator on a specific Riemannian surface introduced by
Str\""omberg, providing new interesting results.",http://arxiv.org/abs/2502.13109v1
"Global Well-Posedness of a Nonlinear Fokker-Planck Type Model of Grain
  Growth",2025-02-12T19:06:31Z,"Batuhan Bayir, Yekaterina Epshteyn, William M Feldman","Most technologically useful materials spanning multiple length scales are
polycrystalline. Polycrystalline microstructures are composed of a myriad of
small crystals or grains with different lattice orientations which are
separated by interfaces or grain boundaries. The changes in the grain and grain
boundary structure of polycrystals highly influence the materials properties
including, but not limited to, electrical, mechanical, and thermal. Thus, an
understanding of how microstructures evolve is essential for the engineering of
new materials. In this paper, we consider a recently introduced nonlinear
Fokker-Planck-type system and establish a global well-posedness result for it.
Such systems under specific energy laws emerge in the modeling of the grain
boundary dynamics in polycrystals.",http://arxiv.org/abs/2502.13151v1
"Wormholes in finite cutoff JT gravity: A study of baby universes and
  (Krylov) complexity",2025-02-18T19:00:02Z,"Arpan Bhattacharyya, Saptaswa Ghosh, Sounak Pal, Anandu Vinod","In this paper, as an application of the `Complexity = Volume' proposal, we
calculate the growth of the interior of a black hole at late times for finite
cutoff JT gravity. Due to this integrable, irrelevant deformation, the spectral
properties are modified non-trivially. The Einstein-Rosen Bridge (ERB) length
saturates faster than pure JT gravity. We comment on the possible connection
between Krylov Complexity and ERB length for deformed theory. Apart from this,
we calculate the emission probability of baby universes for the deformed theory
and make remarks on its implications for the ramp of the Spectral Form Factor.
Finally, we compute the correction to the volume of the moduli space due to the
non-perturbative change of the spectral curve because of the finite cutoff at
the boundary.",http://arxiv.org/abs/2502.13208v1
"Probing Structural Dynamics in Photocatalytic Water Splitting: X-ray vs.
  Neutron Scattering",2025-02-18T19:28:22Z,Zhihao Shen,"Photocatalytic water splitting represents a pivotal pathway for converting
solar energy into chemical energy, with the core challenge lying in the design
and optimization of photocatalysts [1] . TiO2, as a quintessential
photocatalytic material, undergoes significant alterations in its electronic
and crystalline structures under intense light irradiation, which may directly
impacts its photocatalytic efficiency [2] . To gain a profound understanding of
these transformations, in situ characterization techniques such as X-ray
scattering and neutron scattering have emerged as crucial tools. This paper,
from a combined perspective of theoretical computation and experimental
characterization, explores the differential capabilities of X-ray scattering
and neutron scattering in characterizing the pair distribution function (PDF)
of materials during photocatalytic water splitting. Furthermore, through
simulation calculations, it aims to unveil the changes in the electronic and
crystalline structures under intense light irradiation. This initial draft of
the paper is subject to subsequent revisions.",http://arxiv.org/abs/2502.13253v1
"BoundPlanner: A convex-set-based approach to bounded manipulator
  trajectory planning",2025-02-18T21:16:11Z,"Thies Oelerich, Christian Hartl-Nesic, Florian Beck, Andreas Kugi","Online trajectory planning enables robot manipulators to react quickly to
changing environments or tasks. Many robot trajectory planners exist for known
environments but are often too slow for online computations. Current methods in
online trajectory planning do not find suitable trajectories in challenging
scenarios that respect the limits of the robot and account for collisions. This
work proposes a trajectory planning framework consisting of the novel Cartesian
path planner based on convex sets, called BoundPlanner, and the online
trajectory planner BoundMPC. BoundPlanner explores and maps the collision-free
space using convex sets to compute a reference path with bounds. BoundMPC is
extended in this work to handle convex sets for path deviations, which allows
the robot to optimally follow the path within the bounds while accounting for
the robot's kinematics. Collisions of the robot's kinematic chain are
considered by a novel convex-set-based collision avoidance formulation
independent on the number of obstacles. Simulations and experiments with a
7-DoF manipulator show the performance of the proposed planner compared to
state-of-the-art methods. The source code is available at
github.com/Thieso/BoundPlanner and videos of the experiments can be found at
www.acin.tuwien.ac.at/42d4",http://arxiv.org/abs/2502.13286v1
"Capturing Human Cognitive Styles with Language: Towards an Experimental
  Evaluation Paradigm",2025-02-18T23:08:15Z,"Vasudha Varadarajan, Syeda Mahwish, Xiaoran Liu, Julia Buffolino, Christian C. Luhmann, Ryan L. Boyd, H. Andrew Schwartz","While NLP models often seek to capture cognitive states via language, the
validity of predicted states is determined by comparing them to annotations
created without access the cognitive states of the authors. In behavioral
sciences, cognitive states are instead measured via experiments. Here, we
introduce an experiment-based framework for evaluating language-based cognitive
style models against human behavior. We explore the phenomenon of decision
making, and its relationship to the linguistic style of an individual talking
about a recent decision they made. The participants then follow a classical
decision-making experiment that captures their cognitive style, determined by
how preferences change during a decision exercise. We find that language
features, intended to capture cognitive style, can predict participants'
decision style with moderate-to-high accuracy (AUC ~ 0.8), demonstrating that
cognitive style can be partly captured and revealed by discourse patterns.",http://arxiv.org/abs/2502.13326v1
"Reflection of Episodes: Learning to Play Game from Expert and Self
  Experiences",2025-02-19T02:53:43Z,"Xiaojie Xu, Zongyuan Li, Chang Lu, Runnan Qi, Yanan Ni, Lumin Jiang, Xiangbei Liu, Xuebo Zhang, Yongchun Fang, Kuihua Huang, Xian Guo, Zhanghua Wu, Zhenya Li","StarCraft II is a complex and dynamic real-time strategy (RTS) game
environment, which is very suitable for artificial intelligence and
reinforcement learning research. To address the problem of Large Language
Model(LLM) learning in complex environments through self-reflection, we propose
a Reflection of Episodes(ROE) framework based on expert experience and
self-experience. This framework first obtains key information in the game
through a keyframe selection method, then makes decisions based on expert
experience and self-experience. After a game is completed, it reflects on the
previous experience to obtain new self-experience. Finally, in the experiment,
our method beat the robot under the Very Hard difficulty in TextStarCraft II.
We analyze the data of the LLM in the process of the game in detail, verified
its effectiveness.",http://arxiv.org/abs/2502.13388v1
"CipherGuard: Compiler-aided Mitigation against Ciphertext Side-channel
  Attacks",2025-02-19T03:22:36Z,"Ke Jiang, Sen Deng, Yinshuai Li, Shuai Wang, Tianwei Zhang, Yinqian Zhang","Cryptographic implementations bolster security against timing side-channel
attacks by integrating constant-time components. However, the new ciphertext
side channels resulting from the deterministic memory encryption in Trusted
Execution Environments (TEEs), enable ciphertexts to manifest identifiable
patterns when being sequentially written to the same memory address. Attackers
with read access to encrypted memory in TEEs can potentially deduce plaintexts
by analyzing these changing ciphertext patterns.
  In this paper, we design CipherGuard, a compiler-aided mitigation methodology
to counteract ciphertext side channels with high efficiency and security.
CipherGuard is based on the LLVM ecosystem, and encompasses multiple mitigation
strategies, including software-based probabilistic encryption and secret-aware
register allocation. Through a comprehensive evaluation, we demonstrate that
CipherGuard can strengthen the security of various cryptographic
implementations more efficiently than existing state-of-the-art defense
mechanism, i.e., CipherFix.",http://arxiv.org/abs/2502.13401v1
Relaxation Critical Dynamics in Measurement-induced Phase Transitions,2025-02-19T03:39:47Z,"Wantao Wang, Shuo Liu, Jiaqiang Li, Shi-Xin Zhang, Shuai Yin","Measurement-induced phase transition (MIPT) describes the nonanalytical
change of the entanglement entropy resulting from the interplay between
measurement and unitary evolution. In this paper, we investigate the relaxation
critical dynamics near the MIPT for different initial states in a
one-dimensional quantum circuit. Specifically, when the initial state is in the
volume-law phase with vanishing measurement probability, we find that the
half-chain entanglement entropy $S$ decays as $S\propto t^{-1}$ with the
coefficients proportional to the size of the system in the short-time stage; In
contrast, when the initial state is the product state, $S$ increases with time
as $S\propto \ln{t}$, consistent with previous studies. Despite these
contrasting behaviors, we develop a unified scaling form to describe these
scaling behaviors for different initial states where the off-critical-point
effects can also be incorporated. This framework offers significant advantages
for experimental MIPT detection. Our novel scheme, leveraging relaxation
dynamical scaling, drastically reduces post-selection overhead, and can
eliminate it completely with trackable classical simulation.",http://arxiv.org/abs/2502.13408v1
MATS: An Audio Language Model under Text-only Supervision,2025-02-19T05:07:56Z,"Wen Wang, Ruibing Hou, Hong Chang, Shiguang Shan, Xilin Chen","Large audio-language models (LALMs), built upon powerful Large Language
Models (LLMs), have exhibited remarkable audio comprehension and reasoning
capabilities. However, the training of LALMs demands a large corpus of
audio-language pairs, which requires substantial costs in both data collection
and training resources. In this paper, we propose MATS, an audio-language
multimodal LLM designed to handle Multiple Audio task using solely Text-only
Supervision. By leveraging pre-trained audio-language alignment models such as
CLAP, we develop a text-only training strategy that projects the shared
audio-language latent space into LLM latent space, endowing the LLM with audio
comprehension capabilities without relying on audio data during training. To
further bridge the modality gap between audio and language embeddings within
CLAP, we propose the Strongly-related noisy text with audio (Santa) mechanism.
Santa maps audio embeddings into CLAP language embedding space while preserving
essential information from the audio input. Extensive experiments demonstrate
that MATS, despite being trained exclusively on text data, achieves competitive
performance compared to recent LALMs trained on large-scale audio-language
pairs.",http://arxiv.org/abs/2502.13433v2
Cloth Animation with Time-dependent Persistent Wrinkles,2025-02-19T07:24:44Z,"Deshan Gong, Yin Yang, Tianjia Shao, He Wang","Persistent wrinkles are often observed on crumpled garments e.g., the
wrinkles around the knees after sitting for a while. Such wrinkles can be
easily recovered if not deformed for long, and otherwise be persistent. Since
they are vital to the visual realism of cloth animation, we aim to simulate
realistic looking persistent wrinkles. To this end, we present a
physics-inspired fine-grained wrinkle model. Different from existing methods,
we recognize the importance of the interplay between internal friction and
plasticity during wrinkle formation. Furthermore, we model their time
dependence for persistent wrinkles. Our model is capable of not only simulating
realistic wrinkle patterns, but also their time-dependent changes according to
how long the deformation is maintained. Through extensive experiments, we show
that our model is effective in simulating realistic spatial and temporal
varying wrinkles, versatile in simulating different materials, and capable of
generating more fine-grained wrinkles than the state of the art.",http://arxiv.org/abs/2502.13491v1
"Environmental Influences on Collaboration Network Evolution: A
  Historical Analysis",2025-02-19T10:38:29Z,"Peter R Williams, Zhan Chen","We analysed two large collaboration networks -- the Microsoft Academic Graph
(1800-2020) and Internet Movie Database (1900-2020) -- to quantify network
responses to major historical events. Our analysis revealed four properties of
network-environment interaction. First, historical events can influence network
evolution, with effects persisting far longer than previously recognised; the
academic network showed 45\% declines during World Wars and 90\% growth during
La Belle Epoque. Second, node and edge processes exhibited different
environmental sensitivities; while node addition/removal tracked historical
events, edge formation maintained stable statistical properties even during
major disruptions. Third, different collaboration networks showed distinct
response patterns; academic networks displayed sharp disruptions and rapid
recoveries, while entertainment networks showed gradual changes and greater
resilience. Fourth, both networks developed increasing resilience. Our results
provide new insights for modelling network evolution and managing collaborative
systems during periods of external disruption.",http://arxiv.org/abs/2502.13607v1
"Emergence of ecological structure and species rarity from fluctuating
  metabolic strategies",2025-02-19T13:48:03Z,"Davide Zanchetta, Deepak Gupta, Sofia Moschin, Samir Suweis, Amos Maritan, Sandro Azaele","Ecosystems often demonstrate the coexistence of numerous species competing
for limited resources, with pronounced rarity and abundance patterns. A
potential driver of such coexistence is environmental fluctuations that favor
different species over time. However, how to include and treat such temporal
variability in existing consumer-resource models is still an open problem. In
this study, we examine the role of correlated temporal fluctuations in
metabolic strategies within a stochastic consumer-resource framework,
reflecting change of species behavior in response to the environment. In some
conditions, we are able to solve analytically the species abundance
distributions, through path integral formalism. Our results reveal that
stochastic dynamic metabolic strategies induce community structures that align
more closely with empirical ecological observations and contribute to the
violation of the Competitive Exclusion Principle (CEP). The degree of CEP
violation is maximized under intermediate competition strength, leading to an
intermediate competition hypothesis. Furthermore, when non-neutral effects are
present, maximal biodiversity is achieved for intermediate values of the
amplitude of fluctuations. This work not only challenges traditional ecological
paradigms, but also establishes a robust theoretical framework for exploring
how temporal dynamics and stochasticity drive biodiversity and community.",http://arxiv.org/abs/2502.13720v1
GPA: Grover Policy Agent for Generating Optimal Quantum Sensor Circuits,2025-02-19T14:20:07Z,"Ahmad Alomari, Sathish A. P. Kumar","This study proposes a GPA for designing optimal Quantum Sensor Circuits
(QSCs) to address complex quantum physics problems. The GPA consists of two
parts: the Quantum Policy Evaluation (QPE) and the Quantum Policy Improvement
(QPI). The QPE performs phase estimation to generate the search space, while
the QPI utilizes Grover search and amplitude amplification techniques to
efficiently identify an optimal policy that generates optimal QSCs. The GPA
generates QSCs by selecting sequences of gates that maximize the Quantum Fisher
Information (QFI) while minimizing the number of gates. The QSCs generated by
the GPA are capable of producing entangled quantum states, specifically the
squeezed states. High QFI indicates increased sensitivity to parameter changes,
making the circuit useful for quantum state estimation and control tasks.
Evaluation of the GPA on a QSC that consists of two qubits and a sequence of
R_x, R_y, and S gates demonstrates its efficiency in generating optimal QSCs
with a QFI of 1. Compared to existing quantum agents, the GPA achieves higher
QFI with fewer gates, demonstrating a more efficient and scalable approach to
the design of QSCs. This work illustrates the potential computational power of
quantum agents for solving quantum physics problems",http://arxiv.org/abs/2502.13755v1
Identifying metric structures of deep latent variable models,2025-02-19T14:20:28Z,"Stas Syrota, Yevgen Zainchkovskyy, Johnny Xi, Benjamin Bloem-Reddy, Søren Hauberg","Deep latent variable models learn condensed representations of data that,
hopefully, reflect the inner workings of the studied phenomena. Unfortunately,
these latent representations are not statistically identifiable, meaning they
cannot be uniquely determined. Domain experts, therefore, need to tread
carefully when interpreting these. Current solutions limit the lack of
identifiability through additional constraints on the latent variable model,
e.g. by requiring labeled training data, or by restricting the expressivity of
the model. We change the goal: instead of identifying the latent variables, we
identify relationships between them such as meaningful distances, angles, and
volumes. We prove this is feasible under very mild model conditions and without
additional labeled data. We empirically demonstrate that our theory results in
more reliable latent distances, offering a principled path forward in
extracting trustworthy conclusions from deep latent variable models.",http://arxiv.org/abs/2502.13757v2
Multi-Covering a Point Set by $m$ Disks with Minimum Total Area,2025-02-19T14:34:32Z,"Mariem Guitouni, Chek-Manh Loi, Sándor P. Fekete, Michael Perk, Aaron T. Becker","A common robotics sensing problem is to place sensors to robustly monitor a
set of assets, where robustness is assured by requiring asset $p$ to be
monitored by at least $\kappa(p)$ sensors. Given $n$ assets that must be
observed by $m$ sensors, each with a disk-shaped sensing region, where should
the sensors be placed to minimize the total area observed? We provide and
analyze a fast heuristic for this problem. We then use the heuristic to
initialize an exact Integer Programming solution. Subsequently, we enforce
separation constraints between the sensors by modifying the integer program
formulation and by changing the disk candidate set.",http://arxiv.org/abs/2502.13773v1
"Translation in the Hands of Many:Centering Lay Users in Machine
  Translation Interactions",2025-02-19T14:45:17Z,"Beatrice Savoldi, Alan Ramponi, Matteo Negri, Luisa Bentivogli","Converging societal and technical factors have transformed language
technologies into user-facing applications employed across languages. Machine
Translation (MT) has become a global tool, with cross-lingual services now also
supported by dialogue systems powered by multilingual Large Language Models
(LLMs). This accessibility has expanded MT's reach to a vast base of lay users,
often with little to no expertise in the languages or the technology itself.
Despite this, the understanding of MT consumed by this diverse group of users
-- their needs, experiences, and interactions with these systems -- remains
limited. This paper traces the shift in MT user profiles, focusing on
non-expert users and how their engagement with these systems may change with
LLMs. We identify three key factors -- usability, trust, and literacy -- that
shape these interactions and must be addressed to align MT with user needs. By
exploring these dimensions, we offer insights to guide future MT with a
user-centered approach.",http://arxiv.org/abs/2502.13780v1
"Extending the RANGE of Graph Neural Networks: Relaying Attention Nodes
  for Global Encoding",2025-02-19T15:05:47Z,"Alessandro Caruso, Jacopo Venturin, Lorenzo Giambagli, Edoardo Rolando, Frank Noé, Cecilia Clementi","Graph Neural Networks (GNNs) are routinely used in molecular physics, social
sciences, and economics to model many-body interactions in graph-like systems.
However, GNNs are inherently local and can suffer from information flow
bottlenecks. This is particularly problematic when modeling large molecular
systems, where dispersion forces and local electric field variations drive
collective structural changes. Existing solutions face challenges related to
computational cost and scalability. We introduce RANGE, a model-agnostic
framework that employs an attention-based aggregation-broadcast mechanism that
significantly reduces oversquashing effects, and achieves remarkable accuracy
in capturing long-range interactions at a negligible computational cost.
Notably, RANGE is the first virtual-node message-passing implementation to
integrate attention with positional encodings and regularization to dynamically
expand virtual representations. This work lays the foundation for
next-generation of machine-learned force fields, offering accurate and
efficient modeling of long-range interactions for simulating large molecular
systems.",http://arxiv.org/abs/2502.13797v2
"Theory of composite Ramsey sequences of radiofrequency pulses beyond the
  rotating wave approximation",2025-02-04T16:53:47Z,"V. I. Yudin, O. N. Prudnikov, A. V. Taichenachev, M. Yu. Basalaev, V. G. Pal'chikov, S. N. Bagayev","We develop a theory of composite Ramsey sequences of rf pulses interacting
with the Zeeman structure at the long-lived atomic level, beyond the rotating
wave approximation. Such sequences are proposed in experiments to detect the
violation of local Lorentz invariance [R. Shaniv, et al., Phys. Rev. Lett. 120,
103202 (2018)]. Based on Fourier analysis, we have shown that taking into
account non-resonant contributions leads to a radical change in the dynamics of
the quantum system (with respect to the rotating wave approximation) in the
case when the number of Ramsey pulses exceeds several tens. As a result, the
effectiveness of using such rf pulses sequences to test local Lorentz
invariance has not yet been fully determined and requires additional research.",http://arxiv.org/abs/2502.13973v1
"Elastic Quantum Criticality in Nematics and Altermagnets via the
  Elasto-Caloric Effect",2025-02-19T19:00:01Z,"Charles R. W. Steward, Grgur Palle, Markus Garst, Joerg Schmalian, Iksu Jang","The coupling between electronic nematic degrees of freedom and acoustic
phonons is known to significantly alter the universality class of a nematic
quantum critical point (QCP). While non-Fermi-liquid behaviour emerges in the
absence of lattice coupling, the inclusion of interactions with acoustic
phonons results in observables such as heat capacity and single-particle
scattering rate exhibiting only subleading non-analytic corrections to dominant
Fermi-liquid terms. In this work, we demonstrate that the elastocaloric effect
(ECE) -- the adiabatic temperature change under varying strain -- and the
thermal expansion deviate from this pattern. Despite lattice coupling weakening
the singularity of the ECE, it preserves a dominant non-Fermi-liquid
temperature dependence. By drawing analogies between nematic systems and
field-tuned altermagnets, we further show that similar responses are expected
for the ECE near altermagnetic QCPs. We classify the types of piezomagnetic
couplings and analyse the regimes arising from field-tuned magnetoelastic
interactions. Our findings are shown to be consistent with the scaling theory
for elastic quantum criticality and they further emphasize the suitability of
the ECE as a sensitive probe near QCPs.",http://arxiv.org/abs/2502.14033v1
Position: There are no Champions in Long-Term Time Series Forecasting,2025-02-19T19:08:37Z,"Lorenzo Brigato, Rafael Morand, Knut Strømmen, Maria Panagiotou, Markus Schmidt, Stavroula Mougiakakou","Recent advances in long-term time series forecasting have introduced numerous
complex prediction models that consistently outperform previously published
architectures. However, this rapid progression raises concerns regarding
inconsistent benchmarking and reporting practices, which may undermine the
reliability of these comparisons. Our position emphasizes the need to shift
focus away from pursuing ever-more complex models and towards enhancing
benchmarking practices through rigorous and standardized evaluation methods. To
support our claim, we first perform a broad, thorough, and reproducible
evaluation of the top-performing models on the most popular benchmark by
training 3,500+ networks over 14 datasets. Then, through a comprehensive
analysis, we find that slight changes to experimental setups or current
evaluation metrics drastically shift the common belief that newly published
results are advancing the state of the art. Our findings suggest the need for
rigorous and standardized evaluation methods that enable more substantiated
claims, including reproducible hyperparameter setups and statistical testing.",http://arxiv.org/abs/2502.14045v1
"PedDet: Adaptive Spectral Optimization for Multimodal Pedestrian
  Detection",2025-02-19T19:31:51Z,"Rui Zhao, Zeyu Zhang, Yi Xu, Yi Yao, Yan Huang, Wenxin Zhang, Zirui Song, Xiuying Chen, Yang Zhao","Pedestrian detection in intelligent transportation systems has made
significant progress but faces two critical challenges: (1) insufficient fusion
of complementary information between visible and infrared spectra, particularly
in complex scenarios, and (2) sensitivity to illumination changes, such as
low-light or overexposed conditions, leading to degraded performance. To
address these issues, we propose PedDet, an adaptive spectral optimization
complementarity framework specifically enhanced and optimized for multispectral
pedestrian detection. PedDet introduces the Multi-scale Spectral Feature
Perception Module (MSFPM) to adaptively fuse visible and infrared features,
enhancing robustness and flexibility in feature extraction. Additionally, the
Illumination Robustness Feature Decoupling Module (IRFDM) improves detection
stability under varying lighting by decoupling pedestrian and background
features. We further design a contrastive alignment to enhance intermodal
feature discrimination. Experiments on LLVIP and MSDS datasets demonstrate that
PedDet achieves state-of-the-art performance, improving the mAP by 6.6% with
superior detection accuracy even in low-light conditions, marking a significant
step forward for road safety. Code will be available at
https://github.com/AIGeeksGroup/PedDet.",http://arxiv.org/abs/2502.14063v1
Hybrid Visual Servoing of Tendon-driven Continuum Robots,2025-02-19T20:35:41Z,"Rana Danesh, Farrokh Janabi-Sharifi, Farhad Aghili","This paper introduces a novel Hybrid Visual Servoing (HVS) approach for
controlling tendon-driven continuum robots (TDCRs). The HVS system combines
Image-Based Visual Servoing (IBVS) with Deep Learning-Based Visual Servoing
(DLBVS) to overcome the limitations of each method and improve overall
performance. IBVS offers higher accuracy and faster convergence in feature-rich
environments, while DLBVS enhances robustness against disturbances and offers a
larger workspace. By enabling smooth transitions between IBVS and DLBVS, the
proposed HVS ensures effective control in dynamic, unstructured environments.
The effectiveness of this approach is validated through simulations and
real-world experiments, demonstrating that HVS achieves reduced iteration time,
faster convergence, lower final error, and smoother performance compared to
DLBVS alone, while maintaining DLBVS's robustness in challenging conditions
such as occlusions, lighting changes, actuator noise, and physical impacts.",http://arxiv.org/abs/2502.14092v1
Can Community Notes Replace Professional Fact-Checkers?,2025-02-19T22:26:39Z,"Nadav Borenstein, Greta Warren, Desmond Elliott, Isabelle Augenstein","Two commonly-employed strategies to combat the rise of misinformation on
social media are (i) fact-checking by professional organisations and (ii)
community moderation by platform users. Policy changes by Twitter/X and, more
recently, Meta, signal a shift away from partnerships with fact-checking
organisations and towards an increased reliance on crowdsourced community
notes. However, the extent and nature of dependencies between fact-checking and
helpful community notes remain unclear. To address these questions, we use
language models to annotate a large corpus of Twitter/X community notes with
attributes such as topic, cited sources, and whether they refute claims tied to
broader misinformation narratives. Our analysis reveals that community notes
cite fact-checking sources up to five times more than previously reported.
Fact-checking is especially crucial for notes on posts linked to broader
narratives, which are twice as likely to reference fact-checking sources
compared to other sources. In conclusion, our results show that successful
community moderation heavily relies on professional fact-checking.",http://arxiv.org/abs/2502.14132v1
Cluster Analysis and Concept Drift Detection in Malware,2025-02-19T22:42:30Z,"Aniket Mishra, Mark Stamp","Concept drift refers to gradual or sudden changes in the properties of data
that affect the accuracy of machine learning models. In this paper, we address
the problem of concept drift detection in the malware domain. Specifically, we
propose and analyze a clustering-based approach to detecting concept drift.
Using a subset of the KronoDroid dataset, malware samples are partitioned into
temporal batches and analyzed using MiniBatch $K$-Means clustering. The
silhouette coefficient is used as a metric to identify points in time where
concept drift has likely occurred. To verify our drift detection results, we
train learning models under three realistic scenarios, which we refer to as
static training, periodic retraining, and drift-aware retraining. In each
scenario, we consider four supervised classifiers, namely, Multilayer
Perceptron (MLP), Support Vector Machine (SVM), Random Forest, and XGBoost.
Experimental results demonstrate that drift-aware retraining guided by
silhouette coefficient thresholding achieves classification accuracy far
superior to static models, and generally within 1% of periodic retraining,
while also being far more efficient than periodic retraining. These results
provide strong evidence that our clustering-based approach is effective at
detecting concept drift, while also illustrating a highly practical and
efficient fully automated approach to improved malware classification via
concept drift detection.",http://arxiv.org/abs/2502.14135v1
Learning the P2D Model for Lithium-Ion Batteries with SOH Detection,2025-02-19T23:17:30Z,"Maricela Best McKay, Bhushan Gopaluni, Brian Wetton","Lithium ion batteries are widely used in many applications. Battery
management systems control their optimal use and charging and predict when the
battery will cease to deliver the required output on a planned duty or driving
cycle. Such systems use a simulation of a mathematical model of battery
performance. These models can be electrochemical or data-driven.
Electrochemical models for batteries running at high currents are
mathematically and computationally complex. In this work, we show that a
well-regarded electrochemical model, the Pseudo Two Dimensional (P2D) model,
can be replaced by a computationally efficient Convolutional Neural Network
(CNN) surrogate model fit to accurately simulated data from a class of random
driving cycles. We demonstrate that a CNN is an ideal choice for accurately
capturing Lithium ion concentration profiles. Additionally, we show how the
neural network model can be adjusted to correspond to battery changes in State
of Health (SOH).",http://arxiv.org/abs/2502.14147v1
Real-Time Sampling-based Online Planning for Drone Interception,2025-02-20T03:48:38Z,"Gilhyun Ryou, Lukas Lao Beyer, Sertac Karaman","This paper studies high-speed online planning in dynamic environments. The
problem requires finding time-optimal trajectories that conform to system
dynamics, meeting computational constraints for real-time adaptation, and
accounting for uncertainty from environmental changes. To address these
challenges, we propose a sampling-based online planning algorithm that
leverages neural network inference to replace time-consuming nonlinear
trajectory optimization, enabling rapid exploration of multiple trajectory
options under uncertainty. The proposed method is applied to the drone
interception problem, where a defense drone must intercept a target while
avoiding collisions and handling imperfect target predictions. The algorithm
efficiently generates trajectories toward multiple potential target drone
positions in parallel. It then assesses trajectory reachability by comparing
traversal times with the target drone's predicted arrival time, ultimately
selecting the minimum-time reachable trajectory. Through extensive validation
in both simulated and real-world environments, we demonstrate our method's
capability for high-rate online planning and its adaptability to unpredictable
movements in unstructured settings.",http://arxiv.org/abs/2502.14231v1
"Does Time Have Its Place? Temporal Heads: Where Language Models Recall
  Time-specific Information",2025-02-20T04:52:05Z,"Yein Park, Chanwoong Yoon, Jungwoo Park, Minbyul Jeong, Jaewoo Kang","While the ability of language models to elicit facts has been widely
investigated, how they handle temporally changing facts remains underexplored.
We discover Temporal Heads, specific attention heads primarily responsible for
processing temporal knowledge through circuit analysis. We confirm that these
heads are present across multiple models, though their specific locations may
vary, and their responses differ depending on the type of knowledge and its
corresponding years. Disabling these heads degrades the model's ability to
recall time-specific knowledge while maintaining its general capabilities
without compromising time-invariant and question-answering performances.
Moreover, the heads are activated not only numeric conditions (""In 2004"") but
also textual aliases (""In the year ...""), indicating that they encode a
temporal dimension beyond simple numerical representation. Furthermore, we
expand the potential of our findings by demonstrating how temporal knowledge
can be edited by adjusting the values of these heads.",http://arxiv.org/abs/2502.14258v1
"ODVerse33: Is the New YOLO Version Always Better? A Multi Domain
  benchmark from YOLO v5 to v11",2025-02-20T06:57:58Z,"Tianyou Jiang, Yang Zhong","You Look Only Once (YOLO) models have been widely used for building real-time
object detectors across various domains. With the increasing frequency of new
YOLO versions being released, key questions arise. Are the newer versions
always better than their previous versions? What are the core innovations in
each YOLO version and how do these changes translate into real-world
performance gains? In this paper, we summarize the key innovations from YOLOv1
to YOLOv11, introduce a comprehensive benchmark called ODverse33, which
includes 33 datasets spanning 11 diverse domains (Autonomous driving,
Agricultural, Underwater, Medical, Videogame, Industrial, Aerial, Wildlife,
Retail, Microscopic, and Security), and explore the practical impact of model
improvements in real-world, multi-domain applications through extensive
experimental results. We hope this study can provide some guidance to the
extensive users of object detection models and give some references for future
real-time object detector development.",http://arxiv.org/abs/2502.14314v1
ChemHTS: Hierarchical Tool Stacking for Enhancing Chemical Agents,2025-02-20T07:24:26Z,"Zhucong Li, Jin Xiao, Bowei Zhang, Zhijian Zhou, Qianyu He, Fenglei Cao, Jiaqing Liang, Yuan Qi","Large Language Models (LLMs) have demonstrated remarkable potential in
scientific research, particularly in chemistry-related tasks such as molecular
design, reaction prediction, and property estimation. While tool-augmented LLMs
have been introduced to enhance reasoning and computation in these domains,
existing approaches suffer from tool invocation errors and lack effective
collaboration among diverse tools, limiting their overall performance. To
address these challenges, we propose ChemHTS (Chemical Hierarchical Tool
Stacking), a novel method that optimizes tool invocation pathways through a
hierarchical stacking strategy. ChemHTS consists of two key stages: tool
self-stacking warmup and multi-layer decision optimization, enabling LLMs to
refine tool usage dynamically. We evaluate ChemHTS across four classical
chemistry tasks and demonstrate its superiority over strong baselines,
including GPT-4o, DeepSeek-R1, and chemistry-specific models, including
ChemDFM. Furthermore, we define four distinct tool-stacking behaviors to
enhance interpretability, providing insights into the effectiveness of tool
collaboration. Our dataset and code are publicly available at
\url{https://github.com/Chang-pw/ChemHTS}.",http://arxiv.org/abs/2502.14327v1
A Survey on Data Contamination for Large Language Models,2025-02-20T10:23:27Z,"Yuxing Cheng, Yi Chang, Yuan Wu","Recent advancements in Large Language Models (LLMs) have demonstrated
significant progress in various areas, such as text generation and code
synthesis. However, the reliability of performance evaluation has come under
scrutiny due to data contamination-the unintended overlap between training and
test datasets. This overlap has the potential to artificially inflate model
performance, as LLMs are typically trained on extensive datasets scraped from
publicly available sources. These datasets often inadvertently overlap with the
benchmarks used for evaluation, leading to an overestimation of the models'
true generalization capabilities. In this paper, we first examine the
definition and impacts of data contamination. Secondly, we review methods for
contamination-free evaluation, focusing on three strategies: data
updating-based methods, data rewriting-based methods, and prevention-based
methods. Specifically, we highlight dynamic benchmarks and LLM-driven
evaluation methods. Finally, we categorize contamination detecting methods
based on model information dependency: white-Box, gray-Box, and black-Box
detection approaches. Our survey highlights the requirements for more rigorous
evaluation protocols and proposes future directions for addressing data
contamination challenges.",http://arxiv.org/abs/2502.14425v1
NLoRA: Nyström-Initiated Low-Rank Adaptation for Large Language Models,2025-02-20T12:01:11Z,"Chenlu Guo, Yuan Wu, Yi Chang","Parameter-efficient fine-tuning (PEFT) is essential for adapting large
language models (LLMs), with low-rank adaptation (LoRA) being the most popular
approach. However, LoRA suffers from slow convergence, and some recent LoRA
variants, such as PiSSA, primarily rely on Singular Value Decomposition (SVD)
for initialization, leading to expensive computation. To mitigate these
problems, we use the Nystr\""om method, which follows a three-matrix
manipulation. We first introduce StructuredLoRA (SLoRA), which investigates
adding a small intermediate matrix between the low-rank matrices A and B.
Secondly, we propose Nystr\""omLoRA (NLoRA), which leverages Nystr\""om-based
initialization for SLoRA to improve its effectiveness and efficiency. Finally,
we propose IntermediateTune (IntTune), which explores fine-tuning exclusively
on the intermediate matrix of NLoRA to further boost LLM efficiency. We
evaluate our methods on five natural language generation (NLG) tasks and eight
natural language understanding (NLU) tasks. On GSM8K, SLoRA and NLoRA achieve
accuracies of 56.48% and 57.70%, surpassing LoRA by 33.52% and 36.41%, with
only 3.67 million additional trainable parameters. IntTune improves average NLG
performance over LoRA by 7.45% while using only 1.25% of its parameters. These
results demonstrate the efficiency and effectiveness of our approach in
enhancing model performance with minimal parameter overhead.",http://arxiv.org/abs/2502.14482v1
"StructFlowBench: A Structured Flow Benchmark for Multi-turn Instruction
  Following",2025-02-20T12:22:18Z,"Jinnan Li, Jinzhe Li, Yue Wang, Yi Chang, Yuan Wu","Multi-turn instruction following capability constitutes a core competency of
large language models (LLMs) in real-world applications. Existing evaluation
benchmarks predominantly focus on fine-grained constraint satisfaction and
domain-specific capability assessment, yet overlook the crucial structural
dependency between dialogue turns that distinguishes multi-turn from
single-turn interactions. This structural dependency not only reflects user
intent but also establishes a second dimension for instruction following
evaluation beyond constraint satisfaction. To address this gap, we propose
StructFlowBench, a multi-turn instruction following benchmark with structural
flow modeling. The benchmark innovatively defines a structural flow framework
comprising six fundamental inter-turn relationships, which not only introduces
novel structural constraints for model evaluation but also serves as generation
parameters for creating customized dialogue flows tailored to specific
scenarios. Adopting established LLM-based automatic evaluation methodologies,
we conduct systematic evaluations of 13 leading open-source and closed-source
LLMs. Experimental results reveal significant deficiencies in current models'
comprehension of multi-turn dialogue structures. The code is available at
\url{https://github.com/MLGroupJLU/StructFlowBench}.",http://arxiv.org/abs/2502.14494v1
"The life cycle of scientific principles -- a template for characterizing
  physical principles",2025-02-20T14:00:36Z,"Radin Dardashti, Enno Fischer, Robert Harlander","Scientific principles can undergo various developments. While philosophers of
science have acknowledged that such changes occur, there is no systematic
account of the development of scientific principles. Here we propose a template
for analyzing the development of scientific principles called the 'life cycle'
of principles. It includes a series of processes that principles can go
through: prehistory, elevation, formalization, generalization, and challenge.
The life cycle, we argue, is a useful heuristic for the analysis of the
development of scientific principles. We illustrate this by discussing examples
from foundational physics including Lorentz invariance, Mach's principle, the
naturalness principle, and the perfect cosmological principle. We also explore
two applications of the template. First, we propose that the template can be
employed to diagnose the quality of scientific principles. Second, we discuss
the ramifications of the life cycle's processes for the empirical testability
of principles.",http://arxiv.org/abs/2502.14575v1
"Constraints on the fractional changes of the fundamental constants at a
  look-back time of 2.5 Myrs",2025-02-20T14:00:45Z,"Renzhi Su, Tao An, Stephen J. Curran, Michael P. Busch, Minfeng Gu, Di Li","The quantum nature of gravity remains one of the greatest mysteries of modern
physics, with many unified theories predicting variations in fundamental
constants across space and time. Here we present precise measurements of these
variations at galactic dynamical timescales - a critical but previously
unexplored regime. Using simultaneous observations of H \textsc{i} and OH lines
in M31, we probe potential variations of fundamental constants at a lookback
time of 2.5 million years. We obtained
$\Delta(\mu\alpha^2g_p^{0.64})/(\mu\alpha^2g_p^{0.64}) < 3.6 \times 10^{-6}$,
with complementary constraints on $\Delta(\mu\alpha^2)/(\mu\alpha^2) < 4.6
\times 10^{-3}$, and $\Delta g_p/g_p < 7.2 \times 10^{-3}$, where $\alpha$ is
the fine structure constant, $\mu$ is the proton-electron mass ratio, and $g_p$
is the proton $g$-factor. These results bridge the gap between laboratory tests
and cosmological observations, providing unique insights into the coupling
between local dynamics and fundamental physics. Our findings challenge theories
predicting significant variations over galactic timescales, while demonstrating
a powerful new probe of quantum gravity models.",http://arxiv.org/abs/2502.14576v1
"Spatially Varying Coefficient Models for Estimating Heterogeneous
  Mixture Effects",2025-02-20T15:40:57Z,"Jacob Englert, Howard Chang","Recent studies of associations between environmental exposures and health
outcomes have shifted toward estimating the effect of simultaneous exposure to
multiple chemicals. Summary index methods, such as the weighted quantile sum
and quantile g-computation, are now commonly used to analyze environmental
exposure mixtures in a broad range of applications. These methods provide a
simple and interpretable framework for quantifying mixture effects. However,
when data arise from a large geographical study region, it may be unreasonable
to expect a common mixture effect. In this work, we explore the use of a
recently developed spatially varying coefficient model based on Bayesian
additive regression trees to estimate spatially heterogeneous mixture effects
using quantile g-computation. We conducted simulation studies to evaluate the
method's performance. We then applied this model to an analysis of multiple
ambient air pollutants and birthweight in Georgia, USA from 2005-2016. We find
evidence of county-level spatially varying mixture associations, where for 17
of 159 counties in Georgia, elevated concentrations of a mixture of PM2.5,
nitrogen dioxide, sulfur dioxide, ozone, and carbon monoxide were associated
with a reduction in birthweight by as much as -16.65 grams (95% credible
interval: -33.93, -0.40) per decile increase in all five air pollutants.",http://arxiv.org/abs/2502.14651v1
Parallelizing a modern GPU simulator,2025-02-20T16:18:15Z,"Rodrigo Huerta, Antonio González","Simulators are a primary tool in computer architecture research but are
extremely computationally intensive. Simulating modern architectures with
increased core counts and recent workloads can be challenging, even on modern
hardware. This paper demonstrates that simulating some GPGPU workloads in a
single-threaded state-of-the-art simulator such as Accel-sim can take more than
five days. In this paper we present a simple approach to parallelize this
simulator with minimal code changes by using OpenMP. Moreover, our
parallelization technique is deterministic, so the simulator provides the same
results for single-threaded and multi-threaded simulations. Compared to
previous works, we achieve a higher speed-up, and, more importantly, the
parallel simulation does not incur any inaccuracies. When we run the simulator
with 16 threads, we achieve an average speed-up of 5.8x and reach 14x in some
workloads. This allows researchers to simulate applications that take five days
in less than 12 hours. By speeding up simulations, researchers can model larger
systems, simulate bigger workloads, add more detail to the model, increase the
efficiency of the hardware platform where the simulator is run, and obtain
results sooner.",http://arxiv.org/abs/2502.14691v1
General Uncertainty Estimation with Delta Variances,2025-02-20T16:22:40Z,"Simon Schmitt, John Shawe-Taylor, Hado van Hasselt","Decision makers may suffer from uncertainty induced by limited data. This may
be mitigated by accounting for epistemic uncertainty, which is however
challenging to estimate efficiently for large neural networks. To this extent
we investigate Delta Variances, a family of algorithms for epistemic
uncertainty quantification, that is computationally efficient and convenient to
implement. It can be applied to neural networks and more general functions
composed of neural networks. As an example we consider a weather simulator with
a neural-network-based step function inside -- here Delta Variances empirically
obtain competitive results at the cost of a single gradient computation. The
approach is convenient as it requires no changes to the neural network
architecture or training procedure. We discuss multiple ways to derive Delta
Variances theoretically noting that special cases recover popular techniques
and present a unified perspective on multiple related methods. Finally we
observe that this general perspective gives rise to a natural extension and
empirically show its benefit.",http://arxiv.org/abs/2502.14698v1
Entanglement entropy evolution during gravitational collapse,2025-02-20T18:18:16Z,"Alessio Belfiglio, Orlando Luongo, Stefano Mancini, Sebastiano Tomasi","We investigate the dynamics of the ground state entanglement entropy for a
discretized scalar field propagating within the Oppenheimer-Snyder collapse
metric. Starting from a well-controlled initial configuration, we follow the
system as it evolves toward the formation of a horizon and, eventually, a
singularity. Our approach employs an Ermakov-like equation to determine the
time-dependent ground state of the field and calculates the resulting
entanglement entropy by tracing out the degrees of freedom inside a spherical
region within the matter sphere. We find that the entanglement entropy exhibits
nontrivial scaling and time dependence during collapse. Close to the horizon,
the entropy can deviate from the simple area law, reflecting the rapid changes
in geometry and field configuration. Although the model is idealized, these
results provide insights into the generation and scaling of entanglement in the
presence of realistic, dynamically evolving gravitational fields.",http://arxiv.org/abs/2502.14797v1
"Measuring Faithfulness of Chains of Thought by Unlearning Reasoning
  Steps",2025-02-20T18:45:05Z,"Martin Tutek, Fateme Hashemi Chaleshtori, Ana Marasović, Yonatan Belinkov","When prompted to think step-by-step, language models (LMs) produce a chain of
thought (CoT), a sequence of reasoning steps that the model supposedly used to
produce its prediction. However, despite much work on CoT prompting, it is
unclear if CoT reasoning is faithful to the models' parameteric beliefs. We
introduce a framework for measuring parametric faithfulness of generated
reasoning, and propose Faithfulness by Unlearning Reasoning steps (FUR), an
instance of this framework. FUR erases information contained in reasoning steps
from model parameters. We perform experiments unlearning CoTs of four LMs
prompted on four multi-choice question answering (MCQA) datasets. Our
experiments show that FUR is frequently able to change the underlying models'
prediction by unlearning key steps, indicating when a CoT is parametrically
faithful. Further analysis shows that CoTs generated by models post-unlearning
support different answers, hinting at a deeper effect of unlearning.
Importantly, CoT steps identified as important by FUR do not align well with
human notions of plausbility, emphasizing the need for specialized alignment",http://arxiv.org/abs/2502.14829v1
Improving the Diffusability of Autoencoders,2025-02-20T18:45:44Z,"Ivan Skorokhodov, Sharath Girish, Benran Hu, Willi Menapace, Yanyu Li, Rameen Abdal, Sergey Tulyakov, Aliaksandr Siarohin","Latent diffusion models have emerged as the leading approach for generating
high-quality images and videos, utilizing compressed latent representations to
reduce the computational burden of the diffusion process. While recent
advancements have primarily focused on scaling diffusion backbones and
improving autoencoder reconstruction quality, the interaction between these
components has received comparatively less attention. In this work, we perform
a spectral analysis of modern autoencoders and identify inordinate
high-frequency components in their latent spaces, which are especially
pronounced in the autoencoders with a large bottleneck channel size. We
hypothesize that this high-frequency component interferes with the
coarse-to-fine nature of the diffusion synthesis process and hinders the
generation quality. To mitigate the issue, we propose scale equivariance: a
simple regularization strategy that aligns latent and RGB spaces across
frequencies by enforcing scale equivariance in the decoder. It requires minimal
code changes and only up to 20K autoencoder fine-tuning steps, yet
significantly improves generation quality, reducing FID by 19% for image
generation on ImageNet-1K 256x256 and FVD by at least 44% for video generation
on Kinetics-700 17x256x256.",http://arxiv.org/abs/2502.14831v1
CLIPPER: Compression enables long-context synthetic data generation,2025-02-20T18:58:03Z,"Chau Minh Pham, Yapei Chang, Mohit Iyyer","LLM developers are increasingly reliant on synthetic data, but generating
high-quality data for complex long-context reasoning tasks remains challenging.
We introduce CLIPPER, a compression-based approach for generating synthetic
data tailored to narrative claim verification - a task that requires reasoning
over a book to verify a given claim. Instead of generating claims directly from
the raw text of the book, which results in artifact-riddled claims, CLIPPER
first compresses the book into chapter outlines and book summaries and then
uses these intermediate representations to generate complex claims and
corresponding chain-of-thoughts. Compared to naive approaches, CLIPPER produces
claims that are more valid, grounded, and complex. Using CLIPPER, we construct
a dataset of 19K synthetic book claims paired with their source texts and
chain-of-thought reasoning, and use it to fine-tune three open-weight models.
Our best model achieves breakthrough results on narrative claim verification
(from 28% to 76% accuracy on our test set) and sets a new state-of-the-art for
sub-10B models on the NoCha leaderboard. Further analysis shows that our models
generate more detailed and grounded chain-of-thought reasoning while also
improving performance on other narrative understanding tasks (e.g.,
NarrativeQA).",http://arxiv.org/abs/2502.14854v1
"Multi-wavelength observations of a jet launch in real time from the
  post-changing-look Active Galaxy 1ES 1927+654",2025-01-04T17:31:25Z,"Sibasish Laha, Eileen T. Meyer, Dev R. Sadaula, Ritesh Ghosh, Dhrubojyoti Sengupta, Megan Masterson, Onic I. Shuvo, Matteo Guainazzi, Claudio Ricci, Mitchell C. Begelman, Alexander Philippov, Rostom Mbarek, Amelia M. Hankla, Erin Kara, Francesca Panessa, Ehud Behar, Haocheng Zhang, Fabio Pacucci, Main Pal, Federica Ricci, Ilaria Villani, Susanna Bisogni, Fabio La Franca, Stefano Bianchi, Gabriele Bruni, Samantha Oates, Cameron Hahn, Matt Nicholl, S. Bradley Cenko, Sabyasachi Chattopadhyay, Josefa Becerra Gonzalez, J. A. Acosta-Pulido, Suvendu Rakshit, Jiri Svoboda, Luigi Gallo, Adam Ingram, Darshan Kakkad","We present results from a high cadence multi-wavelength observational
campaign of the enigmatic changing look AGN 1ES 1927+654 from May 2022- April
2024, coincident with an unprecedented radio flare (an increase in flux by a
factor of $\sim 60$ over a few months) and the emergence of a spatially
resolved jet at $0.1-0.3$ pc scales (Meyer et al. 2024). Companion work has
also detected a recurrent quasi-periodic oscillation (QPO) in the $2-10$ keV
band with an increasing frequency ($1-2$ mHz) over the same period (Masterson
et al., 2025). During this time, the soft X-rays ($0.3-2$ keV) monotonically
increased by a factor of $\sim 8$, while the UV emission remained near-steady
with $<30\%$ variation and the $2-10$ keV flux showed variation by a factor
$\lesssim 2$. The weak variation of the $2-10$ keV X-ray emission and the
stability of the UV emission suggest that the magnetic energy density and
accretion rate are relatively unchanged, and that the jet could be launched due
to a reconfiguration of the magnetic field (toroidal to poloidal) close to the
black hole. Advecting poloidal flux onto the event horizon would trigger the
Blandford-Znajek (BZ) mechanism, leading to the onset of the jet. The
concurrent softening of the coronal slope (from $\Gamma= 2.70\pm 0.04$ to
$\Gamma=3.27\pm 0.04$), the appearance of a QPO, and low coronal temperature
($kT_{e}=8_{-3}^{+8}$ keV) during the radio outburst suggest that the poloidal
field reconfiguration can significantly impact coronal properties and thus
influence jet dynamics. These extraordinary findings in real time are crucial
for coronal and jet plasma studies, particularly as our results are independent
of coronal geometry.",http://arxiv.org/abs/2501.02340v1
"A comprehensive survey of the GEO-belt using simultaneous four-colour
  observations with STING",2025-02-17T21:01:54Z,"Robert J. S. Airey, Paul Chote, James A. Blake, Benjamin F. Cooke, James McCormac, Phineas Allen, Alex MacManus, Don Pollacco, Billy Shrive, Richard West","Colour light curves of resident space objects (RSOs) encapsulate distinctive
features that can offer insights into an object's structure and design, making
them an invaluable tool for classification and characterisation. We present the
results of the first large systematic colour survey of the GEO belt in which we
obtain full-night multi-colour light curves for 112 active geostationary
objects between April and May 2023. Colour light curve maps were created to
compare and contrast the colours between different satellites and bus
configurations. We find that satellites with BSS-702 and STAR-2 buses can be
effectively distinguished from the colour measurements on these maps, but
comparing the average colour of individual satellites within given solar
equatorial phase angle ranges shows that it is difficult to distinguish between
bus configurations based on colour alone. We also find tentative evidence to
suggest that there is a relationship between colour and time spent on orbit for
the Eurostar-3000 class satellites, which is unseen behaviour within other bus
configuration classes. The satellites in our sample exhibit `redder' colours
than the Sun, which is in agreement with previous findings. We found common
light curve features such as symmetrical colour changes as well as unique
regions of short timescale glinting which are `bluer' than other regimes within
the colour light curves. If these features are indeed seasonal, this would be a
powerful characterisation tool. We are able to detect and resolve features in
the light curve of the LDPE-3A satellite related to manoeuvres being performed.
Finally, we measured the solar panel offsets of 54 satellites in our sample and
found variation in the type of colour response. The majority of which did not
exhibit any colour change across the solar panel glints compared to them
shifting towards 'redder' or 'bluer' colours.",http://arxiv.org/abs/2502.12324v1
"Exploring QGP-like phenomena with Charmonia in $p+p$ collisions at
  $\sqrt{s} = 13$ TeV",2025-01-01T06:47:29Z,"Captain R. Singh, Partha Bagchi, Raghunath Sahoo, Jan-e Alam","In ultra-relativistic collisions of nuclei at the Large Hadron Collider, the
created QCD environment rapidly changes, leading to a non-adiabatic evolution
of the quantum states involved. Considering this, we first examine the
pre-equilibrium state of QCD matter and its effect on the initially produced
charmonium using a temperature-independent Hamiltonian. As the QCD matter
reaches local thermal equilibrium, this Hamiltonian transforms to its finite
temperature counterpart. To model the pre-equilibrium stage, we use the
bottom-up thermalization approach to determine the effective temperature of the
QCD matter, followed by a Gubser-type expansion for the thermalized medium.
Additionally, we consider collisional damping, gluonic dissociation, and
regeneration mechanisms, which specifically modify the charmonium yield in the
thermalized medium. Mainly, the gluonic dissociation and collisional damping
cause a reduction in the yield conversely, regeneration through gluonic
de-excitation enhances the yield of charmonium. Further, we explore the
combined effects of these mechanisms on the collective yield of charmonium
states with transverse momentum ($p_{\rm T}$) and event multiplicity in the
proton-proton collisions at $\sqrt{s} = 13$ TeV. Based on our findings, we
contend that the combined effects of these mechanisms can serve as a robust
probe for determining the possible existence of a thermalized QCD medium in
such a small collision system.",http://arxiv.org/abs/2501.00753v1
"An AI-powered Bayesian generative modeling approach for causal inference
  in observational studies",2025-01-01T06:52:45Z,"Qiao Liu, Wing Hung Wong","Causal inference in observational studies with high-dimensional covariates
presents significant challenges. We introduce CausalBGM, an AI-powered Bayesian
generative modeling approach that captures the causal relationship among
covariates, treatment, and outcome variables. The core innovation of CausalBGM
lies in its ability to estimate the individual treatment effect (ITE) by
learning individual-specific distributions of a low-dimensional latent feature
set (e.g., latent confounders) that drives changes in both treatment and
outcome. This approach not only effectively mitigates confounding effects but
also provides comprehensive uncertainty quantification, offering reliable and
interpretable causal effect estimates at the individual level. CausalBGM adopts
a Bayesian model and uses a novel iterative algorithm to update the model
parameters and the posterior distribution of latent features until convergence.
This framework leverages the power of AI to capture complex dependencies among
variables while adhering to the Bayesian principles. Extensive experiments
demonstrate that CausalBGM consistently outperforms state-of-the-art methods,
particularly in scenarios with high-dimensional covariates and large-scale
datasets. Its Bayesian foundation ensures statistical rigor, providing robust
and well-calibrated posterior intervals. By addressing key limitations of
existing methods, CausalBGM emerges as a robust and promising framework for
advancing causal inference in modern applications in fields such as genomics,
healthcare, and social sciences. CausalBGM is maintained at the website
https://causalbgm.readthedocs.io/.",http://arxiv.org/abs/2501.00755v1
"Deep UV Silicon Polaritonic Metasurfaces for Enhancing Biomolecule
  Autofluorescence and Two-Dimensional Material Double-Resonance Raman
  Scattering",2025-01-01T07:49:49Z,"Bo-Ray Lee, Mao Feng Chiang, Pei Ying Ho, Kuan-Heng Chen, Jia-Hua Lee, Po Hsiang Hsu, Yu Chieh Peng, Jun-Yi Hou, Shih-Chieh Chen, Qian-Yo Lee, Chun-Hao Chang, Bor-Ran Li, Tzu-En Lin, Chieh-Ting Lin, Min-Hsiung Shih, Der-Hsien Lien, Yu-Chuan Lin, Ray-Hua Horng, Yuri Kivshar, Ming Lun Tseng","High-performance DUV spectroscopy drives advancements in biomedical research,
clinical diagnosis, and material science. Existing DUV resonant nanostructures
face instability and photoluminescent noise challenges. We propose robust Si
metasurfaces leveraging polaritonic resonances, a unique property driven by
interband transitions, for enhanced nanophotonic sensing. Our polaritonic
Kerker-type void metasurface enables double-resonance Raman scattering to
analyze 2D semiconductors, improves biomolecule autofluorescence, and offers
superior stability. This scalable platform unlocks versatile applications in
interdisciplinary DUV spectroscopy and emerging nanomaterials research.",http://arxiv.org/abs/2501.00764v1
"Hybridising Reinforcement Learning and Heuristics for Hierarchical
  Directed Arc Routing Problems",2025-01-01T14:29:54Z,"Van Quang Nguyen, Quoc Chuong Nguyen, Thu Huong Dang, Truong-Son Hy","The Hierarchical Directed Capacitated Arc Routing Problem (HDCARP) is an
extension of the Capacitated Arc Routing Problem (CARP), where the arcs of a
graph are divided into classes based on their priority. The traversal of these
classes is determined by either precedence constraints or a hierarchical
objective, resulting in two distinct HDCARP variants. To the best of our
knowledge, only one matheuristic has been proposed for these variants, but it
performs relatively slowly, particularly for large-scale instances (Ha et al.,
2024). In this paper, we propose a fast heuristic to efficiently address the
computational challenges of HDCARP. Furthermore, we incorporate Reinforcement
Learning (RL) into our heuristic to effectively guide the selection of local
search operators, resulting in a hybrid algorithm. We name this hybrid
algorithm as the Hybrid Reinforcement Learning and Heuristic Algorithm for
Directed Arc Routing (HRDA). The hybrid algorithm adapts to changes in the
problem dynamically, using real-time feedback to improve routing strategies and
solution's quality by integrating heuristic methods. Extensive computational
experiments on artificial instances demonstrate that this hybrid approach
significantly improves the speed of the heuristic without deteriorating the
solution quality. Our source code is publicly available at:
https://github.com/HySonLab/ArcRoute",http://arxiv.org/abs/2501.00852v1
Diffusion Policies for Generative Modeling of Spacecraft Trajectories,2025-01-01T18:22:37Z,"Julia Briden, Breanna Johnson, Richard Linares, Abhishek Cauligi","Machine learning has demonstrated remarkable promise for solving the
trajectory generation problem and in paving the way for online use of
trajectory optimization for resource-constrained spacecraft. However, a key
shortcoming in current machine learning-based methods for trajectory generation
is that they require large datasets and even small changes to the original
trajectory design requirements necessitate retraining new models to learn the
parameter-to-solution mapping. In this work, we leverage compositional
diffusion modeling to efficiently adapt out-of-distribution data and problem
variations in a few-shot framework for 6 degree-of-freedom (DoF) powered
descent trajectory generation. Unlike traditional deep learning methods that
can only learn the underlying structure of one specific trajectory optimization
problem, diffusion models are a powerful generative modeling framework that
represents the solution as a probability density function (PDF) and this allows
for the composition of PDFs encompassing a variety of trajectory design
specifications and constraints. We demonstrate the capability of compositional
diffusion models for inference-time 6 DoF minimum-fuel landing site selection
and composable constraint representations. Using these samples as initial
guesses for 6 DoF powered descent guidance enables dynamically feasible and
computationally efficient trajectory generation.",http://arxiv.org/abs/2501.00915v1
"Topological Insights into Black Hole Thermodynamics: Non-Extensive
  Entropy in CFT framework",2025-01-01T21:15:33Z,"Mohammad Ali S. Afshar, Mohammad Reza Alipour, Saeed Noori Gashti, Jafar Sadeghi","In this paper, We conducted an in-depth investigation into the thermodynamic
topology of Einstein-Gauss-Bonnet black holes within the framework of Conformal
Field Theory (CFT), considering the implications of non-extensive entropy
formulations. Our study reveals that the parameter $\lambda$ (R\'{e}nyi
entropy) plays a crucial role in the phase behavior of black holes.
Specifically, when $\lambda$ is below the critical value (C), it has a
negligible impact on the phase behavior. However, when $\lambda$ exceeds the
critical value, it significantly alters the phase transition outcomes.
Determining the most physically representative values of $\lambda$ will require
experimental validation, but this parameter flexibility allows researchers to
better explain black hole phase transitions under varying physical conditions.
Furthermore, the parameters $\alpha$ and $\beta$ affect the phase structure and
topological charge for the Sharma-Mittal entropy. Only in the case of $C>C_c$
and in the condition of $\alpha\approx\beta$ will we have a first-order phase
transition with topological charge + 1. Additionally, for the loop quantum
gravity non-extensive entropy as the parameter $q$ approaches 1, the
classification of topological charges changes. We observe configurations with
one and three topological charges with respect to critical value $C$, resulting
in a total topological charge $W = +1$, and configurations with two topological
charges $(\omega = +1, -1)$, leading to a total topological charge $W = 0$.
These findings provide new insights into the complex phase behavior and
topological characteristics of black holes in the context of CFT and
non-extensive entropy formulations.",http://arxiv.org/abs/2501.00955v1
"Strain Mediated Voltage Control of Magnetic Anisotropy and Magnetization
  Reversal in Bismuth Substituted Yttrium Iron Garnet Films and Meso-structures",2025-01-01T23:41:06Z,"Walid Al Misba, Miela Josephine Gross, Kensuke Hayashi, Daniel B. Gopman, Caroline A. Ross, Jayasimha Atulasimha","We report on magnetic anisotropy modulation in Bismuth substituted Yttrium
Iron Garnet (Bi-YIG) thin films and mesoscale patterned structures deposited on
a PMN-PT substrate with the application of voltage-induced strain. The Bi
content is selected for low coercivity and higher magnetostriction than that of
YIG, yielding significant changes in the hysteresis loops through the
magnetoelastic effect. The piezoelectric substrate is poled along its
thickness, which is the [011] direction, by applying a voltage across the
PMN-PT/SiO2/Bi-YIG/Pt heterostructure. In-situ magneto-optical Kerr effect
microscopy (MOKE) shows the modulation of magnetic anisotropy with
voltage-induced strain. Furthermore, voltage control of the magnetic domain
state of the Bi-YIG film at a fixed magnetic field produces a 90{\deg}
switching of the magnetization easy axis above a threshold voltage. The
magnetoelectric coefficient of the heterostructure is 1.05x10^(-7)s/m which is
competitive with that of other ferromagnetic oxide films on ferroelectric
substrates such as La0.67Sr0.33MnO3/PMNPT and YIG/PMN-PZT. Voltage-control of
magnetization reversal fields in 5-30 microns wide dots and racetracks of
Bi-YIG show potential for energy efficient non-volatile memory and neuromorphic
computing devices.",http://arxiv.org/abs/2501.00980v1
"Deep Reinforcement Learning for Job Scheduling and Resource Management
  in Cloud Computing: An Algorithm-Level Review",2025-01-02T02:08:00Z,"Yan Gu, Zhaoze Liu, Shuhong Dai, Cong Liu, Ying Wang, Shen Wang, Georgios Theodoropoulos, Long Cheng","Cloud computing has revolutionized the provisioning of computing resources,
offering scalable, flexible, and on-demand services to meet the diverse
requirements of modern applications. At the heart of efficient cloud operations
are job scheduling and resource management, which are critical for optimizing
system performance and ensuring timely and cost-effective service delivery.
However, the dynamic and heterogeneous nature of cloud environments presents
significant challenges for these tasks, as workloads and resource availability
can fluctuate unpredictably. Traditional approaches, including heuristic and
meta-heuristic algorithms, often struggle to adapt to these real-time changes
due to their reliance on static models or predefined rules. Deep Reinforcement
Learning (DRL) has emerged as a promising solution to these challenges by
enabling systems to learn and adapt policies based on continuous observations
of the environment, facilitating intelligent and responsive decision-making.
This survey provides a comprehensive review of DRL-based algorithms for job
scheduling and resource management in cloud computing, analyzing their
methodologies, performance metrics, and practical applications. We also
highlight emerging trends and future research directions, offering valuable
insights into leveraging DRL to advance both job scheduling and resource
management in cloud computing.",http://arxiv.org/abs/2501.01007v1
"Event Masked Autoencoder: Point-wise Action Recognition with Event-Based
  Cameras",2025-01-02T03:49:03Z,"Jingkai Sun, Qiang Zhang, Jiaxu Wang, Jiahang Cao, Renjing Xu","Dynamic vision sensors (DVS) are bio-inspired devices that capture visual
information in the form of asynchronous events, which encode changes in pixel
intensity with high temporal resolution and low latency. These events provide
rich motion cues that can be exploited for various computer vision tasks, such
as action recognition. However, most existing DVS-based action recognition
methods lose temporal information during data transformation or suffer from
noise and outliers caused by sensor imperfections or environmental factors. To
address these challenges, we propose a novel framework that preserves and
exploits the spatiotemporal structure of event data for action recognition. Our
framework consists of two main components: 1) a point-wise event masked
autoencoder (MAE) that learns a compact and discriminative representation of
event patches by reconstructing them from masked raw event camera points data;
2) an improved event points patch generation algorithm that leverages an event
data inlier model and point-wise data augmentation techniques to enhance the
quality and diversity of event points patches. To the best of our knowledge,
our approach introduces the pre-train method into event camera raw points data
for the first time, and we propose a novel event points patch embedding to
utilize transformer-based models on event cameras.",http://arxiv.org/abs/2501.01040v1
"Studying the $B^{0} \to J/ψh_{1}$ decays with
  $h_{1}(1170)-h_{1}(1415)$ mixing in the perturbative QCD approach",2025-01-02T05:46:52Z,"Qin Chang, De-Hua Yao, Xin Liu","In this paper, we study the $B^{0} \to J/\psi h_{1}$ decays for the first
time by using perturbative QCD approach up to the presently known
next-to-leading order accuracy. The vertex corrections present significant
contribution to the amplitude. In the calculation, the mixing between two light
axial-vector mesons $h_{1}(1170)$ and $h_{1}(1415)$ are also studied in detail.
The observables including the branching ratios, polarization fractions and $CP$
asymmetries are predicted and discussed explicitly. It is found that the $B^{0}
\to J/\psi h_{1}$ decays have relatively large branching fractions, which are
generally at the order of ${\cal O}(10^{-6}\sim10^{-3})$, and thus are possible
to be observed by the LHCb and Belle-II experiments in the near future.
Moreover, they are very sensitive to the mixing angle $\theta$ and can be used
to test the values of $\theta$. In addition, some ratios between the branching
fractions of $B^{0} \to J/\psi h_{1}$ decays can provide much stronger
constraints on $\theta$ due to their relatively small theoretical errors. The
$B^{0} \to J/\psi h_{1}$ decays are generally dominated by the longitudinal
polarization contributions, specifically, $f_{L}(B^{0} \to J/\psi h_{1})>80\%$,
except for the case that $\theta\sim 35^\circ$ and $-55^\circ$. Unfortunately,
the direct $CP$ asymmetries of $B^{0} \to J/\psi h_{1}$ decays are too small to
be observed soon even if the effect of $\theta$ is considered. The future
precise measurements on $B^{0} \to J/\psi h_{1}$ decays are expected for
testing these theoretical findings and exploring the interesting nature of
$h_{1}(1170)$ and $h_{1}(1415)$.",http://arxiv.org/abs/2501.01075v2
"The effect of turbulence, gravity, and non-continuum hydrodynamic
  interactions on the drop size distribution in clouds",2025-01-02T06:07:58Z,"Johnson Dhanasekaran, Donald. L. Koch","The evolution of micron-sized droplets in clouds is studied with focus on the
'size-gap' regime of 15-40 $\mu m$ radius, where condensation and differential
sedimentation are least effective in promoting growth. This bottleneck leads to
inaccurate growth models and turbulence can potentially rectify disagreement
with in-situ cloud measurements. The role of turbulent collisions, mixing of
droplets, and water vapour fluctuations in crossing the 'size-gap' has been
analysed in detail. Collisions driven by the coupled effects of turbulent shear
and differential sedimentation are shown to grow drizzle sized droplets. Growth
is also promoted by turbulence-induced water vapour fluctuations, which
maintain polydispersity during the initial condensation driven growth and
facilitate subsequent growth by differential sedimentation driven coalescence.
The collision rate of droplets is strongly influenced by non-continuum
hydrodynamics and so the size evolution beyond the condensation regime is found
to be very sensitive to the mean free path of air. Turbulence-induced inertial
clustering leads to a moderate enhancement in the growth rate but the
intermittency of the turbulent shear rate does not change the coalescence rate
significantly. The coupled influence of all these phenomena is evaluated by
evolving a large number of droplets within an adiabatically rising parcel of
air using a Monte Carlo scheme that captures turbulent intermittency and
mixing.",http://arxiv.org/abs/2501.01086v1
"A Sysmon Incremental Learning System for Ransomware Analysis and
  Detection",2025-01-02T06:22:58Z,"Jamil Ispahany, MD Rafiqul Islam, M. Arif Khan, MD Zahidul Islam","In the face of increasing cyber threats, particularly ransomware attacks,
there is a pressing need for advanced detection and analysis systems that adapt
to evolving malware behaviours. Throughout the literature, using machine
learning (ML) to obviate ransomware attacks has increased in popularity.
Unfortunately, most of these proposals leverage non-incremental learning
approaches that require the underlying models to be updated from scratch to
detect new ransomware, wasting time and resources. This approach is problematic
because it leaves sensitive data vulnerable to attack during retraining, as
newly emerging ransomware strains may go undetected until the model is updated.
Furthermore, most of these approaches are not designed to detect ransomware in
real-time data streams, limiting their effectiveness in complex network
environments. To address this challenge, we present the Sysmon Incremental
Learning System for Ransomware Analysis and Detection (SILRAD), which enables
continuous updates to the underlying model and effectively closes the training
gap. By leveraging the capabilities of Sysmon for detailed monitoring of system
activities, our approach integrates online incremental learning techniques to
enhance the adaptability and efficiency of ransomware detection. The most
valuable features for detection were selected using the Pearson Correlation
Coefficient (PCC), and concept drift detection was implemented through the
ADWIN algorithm, ensuring that the model remains responsive to changes in
ransomware behaviour. We compared our results to other popular techniques, such
as Hoeffding Trees (HT) and Leveraging Bagging Classifier (LB), observing a
detection accuracy of 98.89% and a Matthews Correlation Coefficient (MCC) rate
of 94.11%, demonstrating the effectiveness of our technique.",http://arxiv.org/abs/2501.01089v1
"Deformable Gaussian Splatting for Efficient and High-Fidelity
  Reconstruction of Surgical Scenes",2025-01-02T06:50:25Z,"Jiwei Shan, Zeyu Cai, Cheng-Tai Hsieh, Shing Shin Cheng, Hesheng Wang","Efficient and high-fidelity reconstruction of deformable surgical scenes is a
critical yet challenging task. Building on recent advancements in 3D Gaussian
splatting, current methods have seen significant improvements in both
reconstruction quality and rendering speed. However, two major limitations
remain: (1) difficulty in handling irreversible dynamic changes, such as tissue
shearing, which are common in surgical scenes; and (2) the lack of hierarchical
modeling for surgical scene deformation, which reduces rendering speed. To
address these challenges, we introduce EH-SurGS, an efficient and high-fidelity
reconstruction algorithm for deformable surgical scenes. We propose a
deformation modeling approach that incorporates the life cycle of 3D Gaussians,
effectively capturing both regular and irreversible deformations, thus
enhancing reconstruction quality. Additionally, we present an adaptive motion
hierarchy strategy that distinguishes between static and deformable regions
within the surgical scene. This strategy reduces the number of 3D Gaussians
passing through the deformation field, thereby improving rendering speed.
Extensive experiments demonstrate that our method surpasses existing
state-of-the-art approaches in both reconstruction quality and rendering speed.
Ablation studies further validate the effectiveness and necessity of our
proposed components. We will open-source our code upon acceptance of the paper.",http://arxiv.org/abs/2501.01101v1
"From Interaction to Attitude: Exploring the Impact of Human-AI
  Cooperation on Mental Illness Stigma",2025-01-02T12:08:57Z,"Tianqi Song, Jack Jamieson, Tianwen Zhu, Naomi Yamashita, Yi-Chieh Lee","AI conversational agents have demonstrated efficacy in social contact
interventions for stigma reduction at a low cost. However, the underlying
mechanisms of how interaction designs contribute to these effects remain
unclear. This study investigates how participating in three human-chatbot
interactions affects attitudes toward mental illness. We developed three
chatbots capable of engaging in either one-way information dissemination from
chatbot to a human or two-way cooperation where the chatbot and a human
exchange thoughts and work together on a cooperation task. We then conducted a
two-week mixed-methods study to investigate variations over time and across
different group memberships. The results indicate that human-AI cooperation can
effectively reduce stigma toward individuals with mental illness by fostering
relationships between humans and AI through social contact. Additionally,
compared to a one-way chatbot, interacting with a cooperative chatbot led
participants to perceive it as more competent and likable, promoting greater
empathy during the conversation. However, despite the success in reducing
stigma, inconsistencies between the chatbot's role and the mental health
context raised concerns. We discuss the implications of our findings for
human-chatbot interaction designs aimed at changing human attitudes.",http://arxiv.org/abs/2501.01220v1
Does a Large Language Model Really Speak in Human-Like Language?,2025-01-02T14:13:44Z,"Mose Park, Yunjin Choi, Jong-June Jeon","Large Language Models (LLMs) have recently emerged, attracting considerable
attention due to their ability to generate highly natural, human-like text.
This study compares the latent community structures of LLM-generated text and
human-written text within a hypothesis testing procedure. Specifically, we
analyze three text sets: original human-written texts ($\mathcal{O}$), their
LLM-paraphrased versions ($\mathcal{G}$), and a twice-paraphrased set
($\mathcal{S}$) derived from $\mathcal{G}$. Our analysis addresses two key
questions: (1) Is the difference in latent community structures between
$\mathcal{O}$ and $\mathcal{G}$ the same as that between $\mathcal{G}$ and
$\mathcal{S}$? (2) Does $\mathcal{G}$ become more similar to $\mathcal{O}$ as
the LLM parameter controlling text variability is adjusted? The first question
is based on the assumption that if LLM-generated text truly resembles human
language, then the gap between the pair ($\mathcal{O}$, $\mathcal{G}$) should
be similar to that between the pair ($\mathcal{G}$, $\mathcal{S}$), as both
pairs consist of an original text and its paraphrase. The second question
examines whether the degree of similarity between LLM-generated and human text
varies with changes in the breadth of text generation. To address these
questions, we propose a statistical hypothesis testing framework that leverages
the fact that each text has corresponding parts across all datasets due to
their paraphrasing relationship. This relationship enables the mapping of one
dataset's relative position to another, allowing two datasets to be mapped to a
third dataset. As a result, both mapped datasets can be quantified with respect
to the space characterized by the third dataset, facilitating a direct
comparison between them. Our results indicate that GPT-generated text remains
distinct from human-authored text.",http://arxiv.org/abs/2501.01273v1
Marketing Mix Modeling in Lemonade,2025-01-02T14:17:31Z,Roy Ravid,"Marketing mix modeling (MMM) is a widely used method to assess the
effectiveness of marketing campaigns and optimize marketing strategies.
Bayesian MMM is an advanced approach that allows for the incorporation of prior
information, uncertainty quantification, and probabilistic predictions (1). In
this paper, we describe the process of building a Bayesian MMM model for the
online insurance company Lemonade. We first collected data on Lemonade's
marketing activities, such as online advertising, social media, and brand
marketing, as well as performance data. We then used a Bayesian framework to
estimate the contribution of each marketing channel on total performance, while
accounting for various factors such as seasonality, market trends, and
macroeconomic indicators. To validate the model, we compared its predictions
with the actual performance data from A/B-testing and sliding window holdout
data (2). The results showed that the predicted contribution of each marketing
channel is aligned with A/B test performance and is actionable. Furthermore, we
conducted several scenario analyses using convex optimization to test the
sensitivity of the model to different assumptions and to evaluate the impact of
changes in the marketing mix on sales. The insights gained from the model
allowed Lemonade to adjust their marketing strategy and allocate their budget
more effectively. Our case study demonstrates the benefits of using Bayesian
MMM for marketing attribution and optimization in a data-driven company like
Lemonade. The approach is flexible, interpretable, and can provide valuable
insights for decision-making.",http://arxiv.org/abs/2501.01276v1
"Tracking behavioural differences across chronotypes: A case study in
  Finland using Oura rings",2025-01-02T17:02:28Z,"Chandreyee Roy, Kunal Bhattacharya, Kimmo Kaski","Non-invasive mobile wearables like fitness trackers, smart watches and rings
allow an easy and less expensive approach to study everyday human behaviour.
This alternative approach not only supplements clinical studies, but also
provides an opportunity to overcome some of the limitations in them. One of the
major challenges faced by them is studying long-term human health and behaviour
in realistic settings. Here we have utilised Oura rings to obtain granular data
from nineteen healthy participants over the span of one year (October 2023 -
September 2024) along with monthly surveys for nine months to track their
subjective stress within the duration of the study. We have studied
longitudinal sleep and activity patterns of three chronotype groups of
participating individuals: morning type (MT), neither type (NT) and evening
type (ET). We find that while ET individuals do not seem to lead as healthy
life as the MT or NT individuals, they have seemingly improved their habits
during the duration of the study. We also show that the Daylight Saving Time
changes affect the chronotypes differently. Finally, by utilising mixed effects
regression model, we have shown that the stress an individual experiences has a
significant correlation with his or her total sleep duration, monthly survey
response time, and age.",http://arxiv.org/abs/2501.01350v1
"A flow-kick model of dryland vegetation patterns: the impact of rainfall
  variability on resilience",2025-01-02T23:07:25Z,"Punit Gandhi, Matthew Oline, Mary Silber","In many drylands around the globe, vegetation self-organizes into regular
spatial patterns in response to aridity stress. We consider the
regularly-spaced vegetation bands, on gentle hill-slopes, that survive low
rainfall conditions by harvesting additional stormwater from upslope
low-infiltration bare zones. We are interested in the robustness of this
pattern formation survival mechanism to changes in rainfall variability. For
this, we use a flow-kick modeling framework that treats storms as instantaneous
kicks to the soil water. The positive feedbacks in the storm-level hydrology,
that act to concentrate water within the vegetation bands, are captured through
the spatial profiles of the soil water kicks. Between storms, the soil water
and vegetation, modeled by a two-component reaction-diffusion system, evolve
together. We use a combination of linear stability analysis and numerical
simulation to compare predictions of idealized periodic rainfall, with no
variability, to predictions when there is randomness in the timing and
magnitude of water input from storms. We show that including these random
elements leads to a decrease in the parameter range over which patterns appear.
This suggests that an increase in storm variability, even with the same mean
annual rainfall, may negatively impact the resilience of these pattern-forming
dryland ecosystems.",http://arxiv.org/abs/2501.01569v1
"Prism: Mining Task-aware Domains in Non-i.i.d. IMU Data for Flexible
  User Perception",2025-01-03T02:07:42Z,"Yunzhe Li, Facheng Hu, Hongzi Zhu, Quan Liu, Xiaoke Zhao, Jiangang Shen, Shan Chang, Minyi Guo","A wide range of user perception applications leverage inertial measurement
unit (IMU) data for online prediction. However, restricted by the non-i.i.d.
nature of IMU data collected from mobile devices, most systems work well only
in a controlled setting (e.g., for a specific user in particular postures),
limiting application scenarios. To achieve uncontrolled online prediction on
mobile devices, referred to as the flexible user perception (FUP) problem, is
attractive but hard. In this paper, we propose a novel scheme, called Prism,
which can obtain high FUP accuracy on mobile devices. The core of Prism is to
discover task-aware domains embedded in IMU dataset, and to train a
domain-aware model on each identified domain. To this end, we design an
expectation-maximization (EM) algorithm to estimate latent domains with respect
to the specific downstream perception task. Finally, the best-fit model can be
automatically selected for use by comparing the test sample and all identified
domains in the feature space. We implement Prism on various mobile devices and
conduct extensive experiments. Results demonstrate that Prism can achieve the
best FUP performance with a low latency.",http://arxiv.org/abs/2501.01598v1
"Online Meta-Learning Channel Autoencoder for Dynamic End-to-end Physical
  Layer Optimization",2025-01-03T02:58:22Z,"Ali Owfi, Jonathan Ashdown, Kurt Turck, Fatemeh Afghah","Channel Autoencoders (CAEs) have shown significant potential in optimizing
the physical layer of a wireless communication system for a specific channel
through joint end-to-end training. However, the practical implementation of
CAEs faces several challenges, particularly in realistic and dynamic scenarios.
Channels in communication systems are dynamic and change with time. Still, most
proposed CAE designs assume stationary scenarios, meaning they are trained and
tested for only one channel realization without regard for the dynamic nature
of wireless communication systems. Moreover, conventional CAEs are designed
based on the assumption of having access to a large number of pilot signals,
which act as training samples in the context of CAEs. However, in real-world
applications, it is not feasible for a CAE operating in real-time to acquire
large amounts of training samples for each new channel realization. Hence, the
CAE has to be deployable in few-shot learning scenarios where only limited
training samples are available. Furthermore, most proposed conventional CAEs
lack fast adaptability to new channel realizations, which becomes more
pronounced when dealing with a limited number of pilots. To address these
challenges, this paper proposes the Online Meta Learning channel AE (OML-CAE)
framework for few-shot CAE scenarios with dynamic channels. The OML-CAE
framework enhances adaptability to varying channel conditions in an online
manner, allowing for dynamic adjustments in response to evolving communication
scenarios. Moreover, it can adapt to new channel conditions using only a few
pilots, drastically increasing pilot efficiency and making the CAE design
feasible in realistic scenarios.",http://arxiv.org/abs/2501.01608v1
"VidFormer: A novel end-to-end framework fused by 3DCNN and Transformer
  for Video-based Remote Physiological Measurement",2025-01-03T08:18:08Z,"Jiachen Li, Shisheng Guo, Longzhen Tang, Cuolong Cui, Lingjiang Kong, Xiaobo Yang","Remote physiological signal measurement based on facial videos, also known as
remote photoplethysmography (rPPG), involves predicting changes in facial
vascular blood flow from facial videos. While most deep learning-based methods
have achieved good results, they often struggle to balance performance across
small and large-scale datasets due to the inherent limitations of convolutional
neural networks (CNNs) and Transformer. In this paper, we introduce VidFormer,
a novel end-to-end framework that integrates 3-Dimension Convolutional Neural
Network (3DCNN) and Transformer models for rPPG tasks. Initially, we conduct an
analysis of the traditional skin reflection model and subsequently introduce an
enhanced model for the reconstruction of rPPG signals. Based on this improved
model, VidFormer utilizes 3DCNN and Transformer to extract local and global
features from input data, respectively. To enhance the spatiotemporal feature
extraction capabilities of VidFormer, we incorporate temporal-spatial attention
mechanisms tailored for both 3DCNN and Transformer. Additionally, we design a
module to facilitate information exchange and fusion between the 3DCNN and
Transformer. Our evaluation on five publicly available datasets demonstrates
that VidFormer outperforms current state-of-the-art (SOTA) methods. Finally, we
discuss the essential roles of each VidFormer module and examine the effects of
ethnicity, makeup, and exercise on its performance.",http://arxiv.org/abs/2501.01691v2
"Optimal Fiducial Marker Placement for Satellite Proximity Operations
  Using Observability Gramians",2025-01-03T09:03:48Z,"Nicholas B. Andrews, Kristi A. Morgansen","This paper investigates optimal fiducial marker placement on the surface of a
satellite performing relative proximity operations with an observer satellite.
The absolute and relative translation and attitude equations of motion for the
satellite pair are modeled using dual quaternions. The observability of the
relative dual quaternion system is analyzed using empirical observability
Gramian methods. The optimal placement of a fiducial marker set, in which each
marker gives simultaneous optical range and attitude measurements, is
determined for the pair of satellites. A geostationary flyby between the
observing body (chaser) and desired (target) satellites is numerically
simulated and the optimal fiducial placement sets of five and ten on the
surface of the desired satellite are solved. It is shown that the optimal
solution maximizes the distance between fiducial markers and selects marker
locations that are most sensitive to measuring changes in the state during the
nonlinear trajectory, despite being visible for less time than other candidate
marker locations. Definitions and properties of quaternions and dual
quaternions, and parallels between the two, are presented alongside the
relative motion model.",http://arxiv.org/abs/2501.01704v1
"Quasi-two-dimensional magnetism and antiferromagnetic ground state in
  Li$_2$FeSiO$_4$",2025-01-03T11:13:20Z,"W. Hergett, N. Bouldi, M. Jonak, C. Neef, C. Ritter, M. Abdel-Hafiez, F. Seewald, H. -H. Klauss, M. W. -Haverkort, R. Klingeler","Our experimental (neutron diffraction, M\""ossbauer spectroscopy, magnetic
susceptibility, specific heat) and numerical studies on the evolution of short-
and long-range magnetic order in $\gamma_{\rm II}$-Li\(_2\)FeSiO\(_4\) suggest
a quasi-two-dimensional (2D) nature of magnetism. The experimental data
obtained on single crystals imply long-range antiferromagnetic order below
$T_{\rm N}= 17$~K. A broad maximum in magnetic susceptibility $\chi$ at $T_{\rm
m}\simeq 28$~K, observation of magnetic entropy changes up to 100~K and
anisotropy in $\chi$ are indicative of low-dimensional magnetism and suggest
short-range magnetic correlations up to 200~K. Neutron diffraction shows that
long-range antiferromagnetic order is characterised by the propagation vector
k=(1/2,0,1/2). The ordered moment $\mu = 2.50(2) \mu_B$ /Fe, at $T = 1.5$~K, is
along the crystallographic $a$-axis. This is consistent with the observed
static hyperfine field of $B_{\rm hyp}=14.8(3)$\,T by M\""ossbauer spectroscopy
which indicates significant orbital contributions. The temperature dependence
of $B_{\rm hyp}$ yields the critical exponent $\beta=0.116(12)$ which is in the
regime of the 2D Ising behaviour. LSDA+U studies exploiting the experimental
spin structure suggest dominating magnetic exchange coupling within the
$ac$-layers (i.e., $J_3\simeq -6$~K and $J_6\simeq-2$~K) while interlayer
coupling is much smaller and partly frustrated. This confirms the 2D nature of
magnetism and is in full agreement with the experimental findings.",http://arxiv.org/abs/2501.01758v1
Leveraging Sustainable Systematic Literature Reviews,2025-01-03T14:03:15Z,"Vinicius dos Santos, Rick Kazman, Elisa Yumi Nakagawa","Systematic Literature Reviews (SLRs) are a widely employed research method in
software engineering. However, there are several problems with SLRs, including
the enormous time and effort to conduct them and the lack of obvious impacts of
SLR results on software engineering practices and industry projects. To address
these problems, the concepts of \textit{sustainability} and \textit{sustainable
SLR} have been proposed, aiming to raise awareness among researchers about the
importance of dealing with SLR problems in a consistent way; however, practical
and concrete actions are still lacking. This paper presents concrete directions
towards sustainable SLRs. We first identified 18 ``green drivers'' (GD) that
could directly impact SLR sustainability, and we distilled 25 sustainability
indicators (SI) associated with the GD to assess SLRs regarding their
sustainability. A preliminary evaluation was conducted on the ten top-cited
SLRs in software engineering published over the last decade. From this
analysis, we synthesized our insights into 12 leverage points for
sustainability. Our results indicate that even in high-quality reviews, there
are threats to sustainability, such as: flaws in the search process, lack of
essential details in the documentation, weak collaboration with stakeholders,
poor knowledge management, lack of use of supporting tools, and a dearth of
practical insights for software engineering practitioners. The good news is
that moving towards sustainable SLRs only requires some simple actions, which
can pave the way for a profound change in the software engineering community's
mindset about how to create and sustain SLRs.",http://arxiv.org/abs/2501.01819v1
"Age-Based Device Selection and Transmit Power Optimization in
  Over-the-Air Federated Learning",2025-01-03T14:27:13Z,"Jingyuan Liu, Zheng Chang, Ying-Chang Liang","Recently, over-the-air federated learning (FL) has attracted significant
attention for its ability to enhance communication efficiency. However, the
performance of over-the-air FL is often constrained by device selection
strategies and signal aggregation errors. In particular, neglecting straggler
devices in FL can lead to a decline in the fairness of model updates and
amplify the global model's bias toward certain devices' data, ultimately
impacting the overall system performance. To address this issue, we propose a
joint device selection and transmit power optimization framework that ensures
the appropriate participation of straggler devices, maintains efficient
training performance, and guarantees timely updates. First, we conduct a
theoretical analysis to quantify the convergence upper bound of over-the-air FL
under age-of-information (AoI)-based device selection. Our analysis further
reveals that both the number of selected devices and the signal aggregation
errors significantly influence the convergence upper bound. To minimize the
expected weighted sum peak age of information, we calculate device priorities
for each communication round using Lyapunov optimization and select the
highest-priority devices via a greedy algorithm. Then, we formulate and solve a
transmit power and normalizing factor optimization problem for selected devices
to minimize the time-average mean squared error (MSE). Experimental results
demonstrate that our proposed method offers two significant advantages: (1) it
reduces MSE and improves model performance compared to baseline methods, and
(2) it strikes a balance between fairness and training efficiency while
maintaining satisfactory timeliness, ensuring stable model performance.",http://arxiv.org/abs/2501.01828v1
"A self-learning magnetic Hopfield neural network with intrinsic gradient
  descent adaption",2025-01-03T15:08:06Z,"Chang Niu, Huanyu Zhang, Chuanlong Xu, Wenjie Hu, Yunzhuo Wu, Yu Wu, Yadi Wang, Tong Wu, Yi Zhu, Yinyan Zhu, Wenbin Wang, Yizheng Wu, Lifeng Yin, Jiang Xiao, Weichao Yu, Hangwen Guo, Jian Shen","Physical neural networks using physical materials and devices to mimic
synapses and neurons offer an energy-efficient way to implement artificial
neural networks. Yet, training physical neural networks are difficult and
heavily relies on external computing resources. An emerging concept to solve
this issue is called physical self-learning that uses intrinsic physical
parameters as trainable weights. Under external inputs (i.e. training data),
training is achieved by the natural evolution of physical parameters that
intrinsically adapt modern learning rules via autonomous physical process,
eliminating the requirements on external computation resources.Here, we
demonstrate a real spintronic system that mimics Hopfield neural networks (HNN)
and unsupervised learning is intrinsically performed via the evolution of
physical process. Using magnetic texture defined conductance matrix as
trainable weights, we illustrate that under external voltage inputs, the
conductance matrix naturally evolves and adapts Oja's learning algorithm in a
gradient descent manner. The self-learning HNN is scalable and can achieve
associative memories on patterns with high similarities. The fast spin dynamics
and reconfigurability of magnetic textures offer an advantageous platform
towards efficient autonomous training directly in materials.",http://arxiv.org/abs/2501.01853v2
"Identification of the interstellar 1-cyano propargyl radical (HCCCHCN)
  in TMC-1",2025-01-03T18:24:14Z,"C. Cabezas, M. Agúndez, N. Marcelino, C. H. Chang, R. Fuentetaja, B. Tercero, M. Nakajima, Y. Endo, P. de Vicente, J. Cernicharo","We report the first detection in interstellar medium of the 1-cyano propargyl
radical, HC$_3$HCN. This species is an isomer of the 3-cyano propargyl radical
(CH$_2$C$_3$N), which was recently discovered in TMC-1. The 1-cyano propargyl
radical was observed in the cold dark cloud TMC-1 using data from the ongoing
QUIJOTE line survey, which is being carried out with the Yebes 40m telescope. A
total of seven rotational transitions with multiple hyperfine components were
detected in the 31.0-50.4 GHz range. We derived a column density of
(2.2$\pm$0.2)$\times$10$^{11}$ cm$^{-2}$ and a rotational temperature of
7$\pm$1\,K. The abundance ratio between HC$_3$HCN and CH$_2$C$_3$N is 1.4. The
almost equal abundance of these isomers indicates that the two species may be
produced in the same reaction with a similar efficiency, probably in the
reaction C + CH$_2$CHCN and perhaps also in the reaction C$_2$ + CH$_3$CN and
the dissociative recombination with electrons of CH$_2$C$_3$NH$^+$",http://arxiv.org/abs/2501.01938v1
"Machine Learning-Based Differential Diagnosis of Parkinson's Disease
  Using Kinematic Feature Extraction and Selection",2025-01-02T14:43:39Z,"Masahiro Matsumoto, Abu Saleh Musa Miah, Nobuyoshi Asai, Jungpil Shin","Parkinson's disease (PD), the second most common neurodegenerative disorder,
is characterized by dopaminergic neuron loss and the accumulation of abnormal
synuclein. PD presents both motor and non-motor symptoms that progressively
impair daily functioning. The severity of these symptoms is typically assessed
using the MDS-UPDRS rating scale, which is subjective and dependent on the
physician's experience. Additionally, PD shares symptoms with other
neurodegenerative diseases, such as progressive supranuclear palsy (PSP) and
multiple system atrophy (MSA), complicating accurate diagnosis. To address
these diagnostic challenges, we propose a machine learning-based system for
differential diagnosis of PD, PSP, MSA, and healthy controls (HC). This system
utilizes a kinematic feature-based hierarchical feature extraction and
selection approach. Initially, 18 kinematic features are extracted, including
two newly proposed features: Thumb-to-index vector velocity and acceleration,
which provide insights into motor control patterns. In addition, 41 statistical
features were extracted here from each kinematic feature, including some new
approaches such as Average Absolute Change, Rhythm, Amplitude, Frequency,
Standard Deviation of Frequency, and Slope. Feature selection is performed
using One-way ANOVA to rank features, followed by Sequential Forward Floating
Selection (SFFS) to identify the most relevant ones, aiming to reduce the
computational complexity. The final feature set is used for classification,
achieving a classification accuracy of 66.67% for each dataset and 88.89% for
each patient, with particularly high performance for the MSA and HC groups
using the SVM algorithm. This system shows potential as a rapid and accurate
diagnostic tool in clinical practice, though further data collection and
refinement are needed to enhance its reliability.",http://arxiv.org/abs/2501.02014v1
"Towards Robust and Accurate Stability Estimation of Local Surrogate
  Models in Text-based Explainable AI",2025-01-03T17:44:57Z,"Christopher Burger, Charles Walter, Thai Le, Lingwei Chen","Recent work has investigated the concept of adversarial attacks on
explainable AI (XAI) in the NLP domain with a focus on examining the
vulnerability of local surrogate methods such as Lime to adversarial
perturbations or small changes on the input of a machine learning (ML) model.
In such attacks, the generated explanation is manipulated while the meaning and
structure of the original input remain similar under the ML model. Such attacks
are especially alarming when XAI is used as a basis for decision making (e.g.,
prescribing drugs based on AI medical predictors) or for legal action (e.g.,
legal dispute involving AI software). Although weaknesses across many XAI
methods have been shown to exist, the reasons behind why remain little
explored. Central to this XAI manipulation is the similarity measure used to
calculate how one explanation differs from another. A poor choice of similarity
measure can lead to erroneous conclusions about the stability or adversarial
robustness of an XAI method. Therefore, this work investigates a variety of
similarity measures designed for text-based ranked lists referenced in related
work to determine their comparative suitability for use. We find that many
measures are overly sensitive, resulting in erroneous estimates of stability.
We then propose a weighting scheme for text-based data that incorporates the
synonymity between the features within an explanation, providing more accurate
estimates of the actual weakness of XAI methods to adversarial examples.",http://arxiv.org/abs/2501.02042v1
Instruction-Following Pruning for Large Language Models,2025-01-03T20:19:14Z,"Bairu Hou, Qibin Chen, Jianyu Wang, Guoli Yin, Chong Wang, Nan Du, Ruoming Pang, Shiyu Chang, Tao Lei","With the rapid scaling of large language models (LLMs), structured pruning
has become a widely used technique to learn efficient, smaller models from
larger ones, delivering superior performance compared to training similarly
sized models from scratch. In this paper, we move beyond the traditional static
pruning approach of determining a fixed pruning mask for a model, and propose a
dynamic approach to structured pruning. In our method, the pruning mask is
input-dependent and adapts dynamically based on the information described in a
user instruction. Our approach, termed ""instruction-following pruning"",
introduces a sparse mask predictor that takes the user instruction as input and
dynamically selects the most relevant model parameters for the given task. To
identify and activate effective parameters, we jointly optimize the sparse mask
predictor and the LLM, leveraging both instruction-following data and the
pre-training corpus. Experimental results demonstrate the effectiveness of our
approach on a wide range of evaluation benchmarks. For example, our 3B
activated model improves over the 3B dense model by 5-8 points of absolute
margin on domains such as math and coding, and rivals the performance of a 9B
model.",http://arxiv.org/abs/2501.02086v2
Optimally time-dependent modes of vortex gust-airfoil interactions,2025-01-03T20:44:06Z,"Yonghong Zhong, Alireza Amiri-Margavi, Hessam Babaee, Kunihiko Taira","We find the optimally time-dependent (OTD) orthogonal modes about a
time-varying flow generated by a strong gust vortex impacting a NACA 0012
airfoil. This OTD analysis reveals the amplification characteristics of
perturbations about the unsteady base flow and their amplified spatiotemporal
structures that evolve over time. We consider four time-varying laminar base
flows in which a vortex with a strength corresponding to the gust ratio $G$ of
$\{-1,-0.5,0.5,1\}$ impinges on the leading edge of the airfoil at an angle of
attack of $12^\circ$. In these cases, the impingement of the strong gust vortex
causes massive separation and the generation of large-scale vortices around the
airfoil within two convective time units. The highly unsteady nature of these
vortex-airfoil interactions necessitates an advanced analytical technique
capable of capturing the transient perturbation dynamics. For each of the
considered gust ratios, the OTD analysis identifies the most amplified region
to perturbations, the location of which changes as the wake evolves
differently. For interactions between a moderate positive vortex gust ($G=0.5$)
and the airfoil, the area where perturbations are amplified transitions from
the leading-edge vortex sheet to the forming leading-edge vortex. Later, this
most amplified structure becomes supported in the airfoil wake directly behind
the trailing edge. In contrast, a strong vortex gust ($G=\pm 1$) encountered by
the airfoil shows the most amplified OTD mode to appear around the core of the
shed vortices. This study provides an analysis technique and fundamental
insights into the broader family of unsteady aerodynamic problems.",http://arxiv.org/abs/2501.02095v1
"Role of internal space correlations in the dynamics of a
  higher-dimensional Bianchi type-I universe: shear scalar and Hubble parameter
  perspectives",2025-01-03T21:31:28Z,Nihan Katırcı,"We investigate exact solutions of the Einstein field equations in
higher-dimensional, spatially homogeneous Bianchi type-I spacetimes,
introducing a real parameter $\lambda$ that correlates the expansion rates of
external and internal spaces. Extending beyond Robertson--Walker spacetime, our
approach includes positive and negative correlations, suggesting a broader and
isotropic/anisotropic cosmological model space. Positively correlated
dimensions manifest as a cosmological constant at late times, while at early
times, they mimic stiff-fluid-like dark energy that dilutes faster than
radiation, paralleling early dark energy models. This suggests a pathway for
alleviating the Hubble tension by tailoring higher-dimensional dynamics to
reduce the sound horizon. When anisotropic expansion is allowed, these models
achieve isotropization more efficiently than predicted by Wald's cosmic no-hair
theorem. Negative correlations, in contrast, yield a higher-dimensional
steady-state universe where the shear scalar remains constant, effectively
emulating a negative cosmological constant. These distinct behaviors arise from
a simple signature change: positive correlation accelerates shear scalar decay,
while negative correlation stabilizes it. We demonstrate that the solutions
admit analytic continuation from the Lorentzian to Euclidean regime ($t \to
-i\tau$), revealing a wormhole-like topology that connects two asymptotic
regions via a throat, with $\lambda \to -\lambda$.",http://arxiv.org/abs/2501.02109v1
"The underappreciated role of nonspecific interactions in the
  crystallization of DNA-coated colloids",2025-01-04T07:43:19Z,"Hunter Seyforth, Sambarta Chatterjee, Thomas E. Videbæk, Manodeep Mondal, William M. Jacobs, W. Benjamin Rogers","Over the last decade, the field of programmable self-assembly has seen an
explosion in the diversity of crystal lattices that can be synthesized from
DNA-coated colloidal nanometer- and micrometer-scale particles. The prevailing
wisdom has been that a particular crystal structure can be targeted by
designing the DNA-mediated interactions, to enforce binding between specific
particle pairs, and the particle diameters, to control the packing of the
various species. In this article, we show that other ubiquitous nonspecific
interactions can play equally important roles in determining the relative
stability of different crystal polymorphs and therefore what crystal structure
is most likely to form in an experiment. For a binary mixture of same-sized
DNA-coated colloidal micrometer-scale particles, we show how changing the
magnitudes of nonspecific steric and van der Waals interactions gives rise to a
family of binary body-centered tetragonal crystals, including both
cesium-chloride and copper-gold crystals. Simulations using pair potentials
that account for these interactions reproduce our experimental observations
quantitatively, and a theoretical model reveals how a subtle balance between
specific and nonspecific forces determines the equilibrium crystal structure.
These results highlight the importance of accounting for nonspecific
interactions in the crystal-engineering design process.",http://arxiv.org/abs/2501.02220v1
"Tertiary EOR-like microfluidic experiments: influence of viscosity ratio
  on oil clusters mobilization",2025-01-04T14:20:59Z,"Haohong Pi, Abdelaziz Omari, Giuseppe Sciumè","Understanding the pore-scale dynamics of immiscible two-phase flow in porous
media is crucial 9 for optimizing EOR strategies. In this work, we investigate
the mobilization dynamics of oil clusters by 10 means of microfluidic devices
that allow pore scale direct characterization of flow in water-wet chips. We
varied both flow rates during waterflooding and the viscosity ratio by
injecting Glycerol/water mixtures of various compositions right after the
waterflooding period. During waterflooding, the flow rate has only a limited
impact on residual oil. With a subsequent injection of a Glycerol/water
mixture, the oil recovery is significantly enhanced. To better understand the
recovery mechanisms, oil clusters were categorized into droplets, blobs and
ganglia. Increasing the viscosity of the injected mixture resulted in only a
slight reduction in the number of ganglia but significantly decreased their
total volume, thus reducing overall oil saturation. This is due to ganglia
breakup into smaller ganglia, blobs and droplets that are subsequently
mobilized and transported away, while remaining parts of original ganglia still
remain trapped. As long as droplets and blobs are considered, their number is
seen to only weakly change by the increase of mixture viscosity and even their
number may temporarily increase as they result from ganglia rupture. So, the
process can be separated in two main steps: ganglia breakage that feed the
medium in blobs and droplets and a second step where such moving oil entities
are transported. The characteristic time for oil transport is believed to be
longer than that required for ganglia breakage.",http://arxiv.org/abs/2501.02296v1
The parenthood effect in urban mobility,2025-01-04T14:37:06Z,"Mariana Macedo, Ronaldo Menezes, Alessio Cardillo","The modelling of human mobility is vital for the understanding of the
complexity of urban dynamics and guiding effective interventions to improve
quality of life. Traditional modelling approaches focus on `average citizens,'
which overlook the multitude of experiences from distinct sociodemographic
groups. Recent studies have unveiled significant variations in mobility
patterns related to gender and socioeconomic status, yet the impact of
parenthood remains under-explored. Parenthood brings profound changes to daily
routines, influenced by factors such as increased caregiving responsibilities,
altered work-life balance, and the need for family-friendly environments.
Parents often prioritise considerations such as cost of living, social
wellbeing, environmental quality, and safety. Quantifying how `friendly' a city
is becomes more and more important for parents, especially in the context of
rising remote work opportunities which, in turn, reverberate on the choices on
where to settle. This work investigates whether these considerations lead to
distinct mobility patterns between parents and non-parents, also accounting for
the impact of partnership. Using extensive census data across American cities,
we analyse how parenthood and partnership reshape their urban experiences. Our
findings indicate that cities can indeed be classified by their level of
friendliness towards parents and partners. For example, Dallas and Nashville
can be more suited for single individuals, New York and Chicago can be more
accommodating to parents, while Washington and Baltimore favour married people.
These insights contribute to the growing body of research advocating for more
nuanced and equitable urban planning. By recognising the diverse needs of
different demographic groups, particularly parents, our study underscores the
importance of tailored urban design strategies over universal solutions.",http://arxiv.org/abs/2501.02299v1
"Monolayer control of spin-charge conversion in van der Waals
  heterostructures",2025-01-04T17:11:01Z,"K. Abdukayumov, O. Paull, M. Mičica, F. Ibrahim, L. Vojáček, A. Wright, S. Massabeau, F. Mazzola, V. Polewczyk, C. Jego, R. Sharma, C. Vergnaud, A. Marty, I. Gomes de Moraes, A. Ouerghi, H. Okuno, A. Jana, I. Kar, J. Fuji, I. Vobornik, J. Li, F. Bonell, M. Chshiev, M. Bibes, J. -M. George, H. Jaffrès, S. Dhillon, M. Jamet","The diversity of 2D materials and their van der Waals (vdW) stacking presents
a fertile ground for engineering novel multifunctional materials and quantum
states of matter. This permits unique opportunities to tailor the electronic
properties of vdW heterostructures by the insertion of only a single 2D
material layer. However, such vdW materials engineering at the atomic scale has
yet to be investigated for spin-charge interconversion phenomena. Here, we
report on the control of these effects at the monolayer level, where drastic
increase in intensity and change in sign of THz spintronic emission are
demonstrated by inserting a single layer of MoSe$_2$ between PtSe$_2$ and
graphene in a fully epitaxial, large area stacked structure. By using a
combination of spin and angle resolved photoemission and density functional
theory to reveal the electronic and spin structures, we illustrate two
different mechanisms relying on charge transfer and electronic hybridization
for the formation of Rashba states, which are responsible for spin-charge
conversion and hence the THz spintronic emission. These findings open new
pathways to design, at the atomic scale, efficient THz spintronic emitters made
of 2D materials and other spintronic devices based on spin-charge
interconversion phenomena.",http://arxiv.org/abs/2501.02337v1
"Experiences and attitudes toward working remotely from home in a time of
  pandemic: A snapshot from a New Zealand-based online survey",2025-01-05T01:56:59Z,Edgar Pacheco,"Due to the Covid-19 pandemic, employees from around the world were compelled
to work remotely from home and, in many cases, without much preparation. A
substantial body of international research has been conducted on the
experiences and attitudes of remote workers as well as the implications of this
phenomenon for organisations. While New Zealand research evidence is growing,
most existing inquiry is qualitative. This paper provides a quantitative
snapshot of remote working using survey data from participants whose jobs can
be done from home (n=415). Data collection took place when the country was
facing Covid-related measures.
  Based on descriptive and inferential statistics, it was found that, not only
was remote working common, but that hybrid working arrangements were also more
prevalent. While half of the participants wanted to work from home more
frequently, age, but not gender, was significantly associated with this
preference. Another relevant finding is that perceived change in the workplace
culture due to flexible work arrangements was significantly associated with
preference for working remotely more often. Finally, the most common perceived
barriers to working from home were slow internet speed, the need to attend
face-to-face meetings, and limited space at home to work. The implications of
the results are discussed and some directions for future research are proposed.",http://arxiv.org/abs/2501.02418v1
"MetaNeRV: Meta Neural Representations for Videos with Spatial-Temporal
  Guidance",2025-01-05T03:12:30Z,"Jialong Guo, Ke liu, Jiangchao Yao, Zhihua Wang, Jiajun Bu, Haishuai Wang","Neural Representations for Videos (NeRV) has emerged as a promising implicit
neural representation (INR) approach for video analysis, which represents
videos as neural networks with frame indexes as inputs. However, NeRV-based
methods are time-consuming when adapting to a large number of diverse videos,
as each video requires a separate NeRV model to be trained from scratch. In
addition, NeRV-based methods spatially require generating a high-dimension
signal (i.e., an entire image) from the input of a low-dimension timestamp, and
a video typically consists of tens of frames temporally that have a minor
change between adjacent frames. To improve the efficiency of video
representation, we propose Meta Neural Representations for Videos, named
MetaNeRV, a novel framework for fast NeRV representation for unseen videos.
MetaNeRV leverages a meta-learning framework to learn an optimal parameter
initialization, which serves as a good starting point for adapting to new
videos. To address the unique spatial and temporal characteristics of video
modality, we further introduce spatial-temporal guidance to improve the
representation capabilities of MetaNeRV. Specifically, the spatial guidance
with a multi-resolution loss aims to capture the information from different
resolution stages, and the temporal guidance with an effective progressive
learning strategy could gradually refine the number of fitted frames during the
meta-learning process. Extensive experiments conducted on multiple datasets
demonstrate the superiority of MetaNeRV for video representations and video
compression.",http://arxiv.org/abs/2501.02427v2
"Semi-analytic construction of global transfers between quasi-periodic
  orbits in the spatial R3BP",2025-01-05T09:34:23Z,"Amadeu Delshams, Marian Gidea, Pablo Roldan","Consider the spatial restricted three-body problem, as a model for the motion
of a spacecraft relative to the Sun-Earth system. We focus on the dynamics near
the equilibrium point $L_1$, located between the Sun and the Earth. We show
that we can transfer the spacecraft from a quasi-periodic orbit that is nearly
planar relative to the ecliptic to a quasi-periodic orbit that has large
out-of-plane amplitude, at zero energy cost. (In fact, the final orbit has the
maximum out-of-plane amplitude that can be obtained through the particular
mechanism that we consider. Moreover, the transfer can be made through any
prescribed sequence of quasi-periodic orbits in between).
  Our transfer mechanism is based on selecting trajectories homoclinic to a
normally hyperbolic invariant manifold (NHIM) near $L_1$, and then gluing them
together. We provide several explicit constructions of such transfers, and also
develop an algorithm to design trajectories that achieve the \emph{shortest
transfer time} for this particular mechanism.
  The change in the out-of-plane amplitude along a homoclic trajectory can be
described via the scattering map. We develop a new tool, the `Standard
Scattering Map' (SSM), which is a series representation of the exact scattering
map. We use the SSM to obtain a complete description of the dynamics along
homoclinic trajectories. The SSM can be used in many other situations, from
Arnold diffusion problems to transport phenomena in applications.",http://arxiv.org/abs/2501.02485v1
"Materials Discovery in Combinatorial and High-throughput Synthesis and
  Processing: A New Frontier for SPM",2025-01-05T10:59:05Z,"Boris N. Slautin, Yongtao Liu, Yu Liu, Reece Emery, Seungbum Hong, Astita Dubey, Vladimir V. Shvartsman, Doru C. Lupascu, Sheryl L. Sanchez, Mahshid Ahmadi, Yunseok Kim, Evgheni Strelcov, Keith A. Brown, Philip D. Rack, Sergei V. Kalinin","For over three decades, scanning probe microscopy (SPM) has been a key method
for exploring material structures and functionalities at nanometer and often
atomic scales in ambient, liquid, and vacuum environments. Historically, SPM
applications have predominantly been downstream, with images and spectra
serving as a qualitative source of data on the microstructure and properties of
materials, and in rare cases of fundamental physical knowledge. However, the
fast growing developments in accelerated material synthesis via self-driving
labs and established applications such as combinatorial spread libraries are
poised to change this paradigm. Rapid synthesis demands matching capabilities
to probe structure and functionalities of materials on small scales and with
high throughput, which are characteristically inherent to SPM. Here, we
overview SPM methods applicable to these emerging applications and emphasize
their quantitativeness, focusing on piezoresponse force microscopy,
electrochemical strain microscopy, conductive, and surface photovoltage
measurements. We discuss the challenges and opportunities ahead, asserting that
SPM will play a crucial role in closing the loop from material prediction and
synthesis to characterization.",http://arxiv.org/abs/2501.02503v1
"Evolutions of in-medium baryon-baryon scattering cross sections and
  stiffness of dense nuclear matter from Bayesian analyses of FOPI proton flow
  excitation functions",2025-01-05T15:25:52Z,"Bao-An Li, Wen-Jie Xie","Within a Bayesian statistical framework using a Gaussian Process (GP)
emulator for an isospin-dependent Boltzmann-Uehling-Uhlenbeck (IBUU) transport
model simulator of heavy-ion reactions, we infer from the proton directed and
elliptical flow in mid-central Au+Au reactions at beam energies from 150 to
1200 MeV/nucleon taken by the FOPI Collaboration the posterior probability
distribution functions (PDFs) of the in-medium baryon-baryon scattering cross
section modification factor $X$ (with respect to their free-space values) and
the stiffness parameter $K$ of dense nuclear matter. We find that the most
probable value of $X$ evolves from around 0.7 to 1.0 as the beam energy
$E_{beam}/A$ increases. On the other hand, the posterior PDF($K$) may have dual
peaks having roughly the same height or extended shoulders at high $K$ values.
More quantitatively, the posterior PDF($K$) changes from having a major peak
around 220 MeV characterizing a soft EOS in the reaction at $E_{beam}/A$=150
MeV to one that peaks around 320 MeV indicating a stiff EOS in the reactions at
$E_{beam}/A$ higher than about 600 MeV. The transition from soft to stiff
happens in mid-central Au+Au reactions at beam energies around 250 MeV/nucleon
in which $K=220$ MeV and $K=320$ MeV are approximately equally probable.
Altogether, the FOPI proton flow excitation function data indicate a gradual
hardening of hot and dense nuclear matter as its density and temperature
increase in reactions with higher beam energies.",http://arxiv.org/abs/2501.02579v1
"Emergence of Giant Magnetic Chirality during Dimensionality Crossover of
  Magnetic Materials",2025-01-06T05:20:17Z,"Dae-Yun Kim, Yun-Seok Nam, Younghak Kim, Kyoung-Whan Kim, Gyungchoon Go, Seong-Hyub Lee, Joon Moon, Jun-Young Chang, Ah-Yeon Lee, Seung-Young Park, Byoung-Chul Min, Kyung-Jin Lee, Hyunsoo Yang, Duck-Ho Kim, Sug-Bong Choe","Chirality, an intrinsic preference for a specific handedness, is a
fundamental characteristic observed in nature. In magnetism, magnetic chirality
arises from the anti-symmetric Dzyaloshinskii-Moriya interaction in competition
with the symmetric Heisenberg exchange interaction. Traditionally, the
anti-symmetric interaction has been considered minor relative to the symmetric
interaction. In this study, we demonstrate an observation of giant magnetic
chirality during the dimensionality crossover of magnetic materials from
three-dimensional to two-dimensional. The ratio between the anti-symmetric and
symmetric interactions exhibits a reversal in their dominance over this
crossover, overturning the traditional consideration. This observation is
validated theoretically using a non-local interaction model and tight-binding
calculation with distinct pairing schemes for each exchange interaction
throughout the crossover. Additional experiments investigating the asphericity
of orbital moments corroborate the robustness of our findings. Our findings
highlight the critical role of dimensionality in shaping magnetic chirality and
offer strategies for engineering chiral magnet states with unprecedented
strength, desired for the design of spintronic materials.",http://arxiv.org/abs/2501.02768v1
"Forward Once for All: Structural Parameterized Adaptation for Efficient
  Cloud-coordinated On-device Recommendation",2025-01-06T08:32:16Z,"Kairui Fu, Zheqi Lv, Shengyu Zhang, Fan Wu, Kun Kuang","In cloud-centric recommender system, regular data exchanges between user
devices and cloud could potentially elevate bandwidth demands and privacy
risks. On-device recommendation emerges as a viable solution by performing
reranking locally to alleviate these concerns. Existing methods primarily focus
on developing local adaptive parameters, while potentially neglecting the
critical role of tailor-made model architecture. Insights from broader research
domains suggest that varying data distributions might favor distinct
architectures for better fitting. In addition, imposing a uniform model
structure across heterogeneous devices may result in risking inefficacy on less
capable devices or sub-optimal performance on those with sufficient
capabilities. In response to these gaps, our paper introduces Forward-OFA, a
novel approach for the dynamic construction of device-specific networks (both
structure and parameters). Forward-OFA employs a structure controller to
selectively determine whether each block needs to be assembled for a given
device. However, during the training of the structure controller, these
assembled heterogeneous structures are jointly optimized, where the co-adaption
among blocks might encounter gradient conflicts. To mitigate this, Forward-OFA
is designed to establish a structure-guided mapping of real-time behaviors to
the parameters of assembled networks. Structure-related parameters and parallel
components within the mapper prevent each part from receiving heterogeneous
gradients from others, thus bypassing the gradient conflicts for coupled
optimization. Besides, direct mapping enables Forward-OFA to achieve adaptation
through only one forward pass, allowing for swift adaptation to changing
interests and eliminating the requirement for on-device backpropagation.
Experiments on real-world datasets demonstrate the effectiveness and efficiency
of Forward-OFA.",http://arxiv.org/abs/2501.02837v1
"The importance of shear on the collective charge transport in CDWs
  revealed by an XFEL source",2025-01-06T09:21:45Z,"David Le Bolloc'h, Ewen Bellec, Darine Ghoneim, Antoine Gallo-Frantz, Pawel Wzietek, Luc Ortega, Anders Madsen, Pierre Monceau, Mathieu Chollet, Isabel Gonzales-Vallejo, Vincent. L. R. Jacques, Aleksandr Sinchenko","Charge transport in materials has an impact on a wide range of devices based
on semiconductor, battery or superconductor technology. Charge transport in
sliding Charge Density Waves (CDW) differs from all others in that the atomic
lattice is directly involved in the transport process. To obtain an overall
picture of the structural changes associated to the collective transport, the
large coherent X-ray beam generated by an X-ray free-electron laser (XFEL)
source was used. The CDW phase can be retrieved over the entire sample from
diffracted intensities using a genetic algorithm. For currents below threshold,
increasing shear deformation is observed in the central part of the sample
while longitudinal deformation appears above threshold when shear relaxes.
Shear thus precedes longitudinal deformation, with relaxation of one leading to
the appearance of the other. Moreover, strain accumulates on surface steps in
the sliding regime, demonstrating the strong pinning character of these surface
discontinuities. The sliding process of nanometric CDW is based on an
impressive spatial coherence involving the macroscopic sample dimensions.",http://arxiv.org/abs/2501.02868v1
"LOHA: Direct Graph Spectral Contrastive Learning Between Low-pass and
  High-pass Views",2025-01-06T12:25:02Z,"Ziyun Zou, Yinghui Jiang, Lian Shen, Juan Liu, Xiangrong Liu","Spectral Graph Neural Networks effectively handle graphs with different
homophily levels, with low-pass filter mining feature smoothness and high-pass
filter capturing differences. When these distinct filters could naturally form
two opposite views for self-supervised learning, the commonalities between the
counterparts for the same node remain unexplored, leading to suboptimal
performance. In this paper, a simple yet effective self-supervised contrastive
framework, LOHA, is proposed to address this gap. LOHA optimally leverages
low-pass and high-pass views by embracing ""harmony in diversity"". Rather than
solely maximizing the difference between these distinct views, which may lead
to feature separation, LOHA harmonizes the diversity by treating the
propagation of graph signals from both views as a composite feature.
Specifically, a novel high-dimensional feature named spectral signal trend is
proposed to serve as the basis for the composite feature, which remains
relatively unaffected by changing filters and focuses solely on original
feature differences. LOHA achieves an average performance improvement of 2.8%
over runner-up models on 9 real-world datasets with varying homophily levels.
Notably, LOHA even surpasses fully-supervised models on several datasets, which
underscores the potential of LOHA in advancing the efficacy of spectral GNNs
for diverse graph structures.",http://arxiv.org/abs/2501.02969v1
"Probing Magnetism in Self-Assembled Organometallic Complexes using Kondo
  Spectroscopy",2025-01-06T16:09:59Z,"Wantong Huang, Paul Greule, Máté Stark, Joris van Slageren, Christoph Sürgers, Wolfgang Wernsdorfer, Giorgio Sangiovanni, Christoph Wolf, Philip Willke","Control of individual spins at the atomic level holds great promise for
miniaturized spintronics, quantum sensing, and quantum information processing.
Both single atomic and molecular spin centers are prime candidates for these
applications and are often individually addressed and manipulated using
scanning tunneling microscopy (STM). In this work, we present a hybrid approach
and demonstrate a robust method for self-assembly of magnetic organometallic
complexes consisting of individual iron (Fe) atoms and molecules on a silver
substrate using STM. We employ two types of molecules, bis(dibenzoylmethane)
copper(II) [Cu(dbm)2] and iron phthalocyanine (FePc). We show that in both
cases the Fe atoms preferentially attach underneath the benzene ring ligand of
the molecules, effectively forming an organometallic half-sandwich arene
complex, Fe(C6H6), that is akin to the properties of metallocenes. In both
situations, a molecule can be combined with up to two Fe atoms. In addition, we
observe a change in the magnetic properties of the attached Fe atoms in
scanning tunneling spectroscopy, revealing a distinct Kondo signature at the Fe
sites. We explain the latter using density functional theory calculations, and
find that the bond formation between the Fe 3d-orbitals and the benzene
{\pi}-molecular orbitals creates a favorable situation for Kondo screening of
the d_xz- and d_yz-like orbitals. Thus, this work establishes a reliable design
principle for forming hybrid organometallic complexes and simultaneous tuning
of their atomic spin states.",http://arxiv.org/abs/2501.03104v1
The Scaling Law for LoRA Base on Mutual Information Upper Bound,2025-01-06T17:19:19Z,"Jing Zhang, Hui Gao, Peng Zhang, Shuzhen Sun, Chang Yang, Yuexian Hou","LoRA (Low-Rank Adaptation) is a widely used model fine-tuning method. In
fine-tuning, the law among model performance, model parameters, and data
complexity has been a focal issue in the field. Existing methods often leverage
external metrics (such as cross-entropy or perplexity) to evaluate model
performance. In the fine-tuning process for large models, two types of
knowledge are typically involved: the frozen, general knowledge acquired by the
model during pre-training and the new knowledge learned through the LoRA module
from the current data. Generally, the less LoRA's learned knowledge relies on
the large model, the more it captures the specific knowledge of new data,
thereby enhancing its adaptability to new tasks. However, external metrics do
not readily capture the dependency relationship between these two types of
knowledge. Therefore, we designed an internal metric based on the Mutual
Information Upper Bound (MIUB) theory to investigate the scaling law of
large-model LoRA fine-tuning. In our experiments, we validated this approach on
benchmark datasets, using the Llama3-8B and Phi3-3B models. The results show
that the proposed MIUB metric aligns more accurately and stably with the
scaling law of LoRA fine-tuning compared to cross-entropy and perplexity.",http://arxiv.org/abs/2501.03152v1
MEMSDuino: An Arduino-Based MEMS Switch Controller,2025-01-06T19:07:34Z,"Lafe Spietz, Adam Sirois, Nathan Flowers-Jacobs, Steve Waltman, Samuel Benz, Peter Hopkins","Radio frequency cryogenic switches are a critical enabling technology for
quantum information science for both calibration and high throughput testing of
samples. Traditionally, solenoid-based switches have been used [1,2], but a
transition is being made to MEMS-based (Micro Electro Mechanical Systems)
switches due to their lower power dissipation and smaller size, and to minimize
the risk that solenoid switches tend to produce current pulses that destroy
expensive cryogenic amplifiers and can cause electrostatic damage to devices.
These MEMS switches require a 90-volt signal to be applied to the control lines
to determine the state of the switches. Switches exist that have built-in
CMOS-based (Complimentary Metal Oxide Semiconductor) control electronics to
drive the 90 V, but these do not work at the cryogenic temperatures used in
quantum information science.
  There is no currently available room temperature control system with direct
control of the switches. The instrument presented here is a 19-inch rack-mount
controller for a cryogenic MEMS switch network that allows a human operator to
see the state of the switch via a row of clearly marked indicator lights and to
change the state manually via buttons on an LED-based indicator board or
automatically via Python-based serial port commands to the Arduino, an open
source microcontroller platform available from multiple vendors. The design can
also be modified to control other switches that require either a large voltage
or current to switch.",http://arxiv.org/abs/2501.03340v1
"Demonstration of Quantum Polarization Microscopy using an
  Entangled-Photon Source",2025-01-07T02:43:19Z,"Mousume Samad, Maki Shimizu, Yasuto Hijikata","With the advancement of non-classical light sources such as single-photon and
entangled-photon sources, innovative microscopy based on the quantum principles
has been proposed over traditional microscopy. This paper introduces the
experimental demonstration of a quantum polarization microscopic technique that
incorporates a quantum-entangled photon source. Although the point that employs
the variation of polarization angle due to reflection or transmission at the
sample is similar to classical polarization microscopy, the method for
constructing image contrast is significantly different. Image contrast is
constructed by the coincidence count of signal and idler photons. In the case
that coincidence count is recorded from both the signal and idler photons, the
photon statistics resemble a thermal state, similar to the blackbody radiation,
but with a significantly higher peak intensity in the second order
autocorrelation function at zero delay that is derived from coincidence count.
While, when the coincidence count is taken from either the signal or idler
photon only, though the photon state exhibits a thermal state again, the photon
statistics become more dispersive and result in a lower peak intensity of the
autocorrelation function. These different thermal states can be switched by
slightly changing the photon polarization, which is suddenly aroused within
narrow range of analyzer angle. This polarization microscopic technique can
provide a superior imaging technique compared to the classical method, opening
a new frontier for research in material sciences, biology, and other fields
requiring high-resolution imaging.",http://arxiv.org/abs/2501.03478v1
The ubiquity of variable radio emission and spin-down rates in pulsars,2025-01-07T03:42:34Z,"M. E. Lower, A. Karastergiou, S. Johnston, P. R. Brook, S. Dai, M. Kerr, R. N. Manchester, L. S. Oswald, R. M. Shannon, C. Sobey, P. Weltevrede","Pulsars are often lauded for their (relative) rotational and radio emission
stability over long time scales. However, long-term observing programmes are
identifying an increasing number that deviate from this preconceived notion.
Using Gaussian process regression and Bayesian inference techniques, we
investigated the emission and rotational stability of 259 radio pulsars that
have been monitored using Murriyang, the Parkes 64 m radio telescope, over the
past three decades. We found 238 pulsars display significant variability in
their spin-down rates, 52 of which also exhibit changes in profile shape.
Including 23 known state-switching pulsars, this represents the largest
catalogue of variable pulsars identified to date and indicates that these
behaviours are ubiquitous among the wider population. The intensity of
spin-down fluctuations positively scales with increasing pulsar spin-down rate,
with only a marginal dependence on spin-frequency. This may have substantial
implications for ongoing searches for gravitational waves in the ensemble
timing of millisecond pulsars. We also discuss challenges in explaining the
physical origins of quasi-periodic and transient profile/spin-down variations
detected among a subset of our pulsars.",http://arxiv.org/abs/2501.03500v1
"High Resolution {\it BOES} Spectroscopy of Raman-scattered
  He~II$λ$6545 in Young Planetary Nebulae",2025-01-07T06:15:53Z,"Jin Lim, Seok-Jun Chang, Jaejin Shin, Hee-Won Lee, Jiyu Kim, Hak-Sub Kim, Bo-Eun Choi, Ho-Gyu Lee","Young planetary nebulae (PNe) are characterized by their hot central stars
and the presence of abundant neutral and molecular components, which result
from significant mass loss during the asymptotic giant branch (AGB) phase of
stellar evolution. Far-UV \ion{He}{2}$\lambda$1025 line photons produced near
the central star can undergo Raman scattering by hydrogen atoms, creating a
broad emission feature centered at $\sim$ 6545~\AA. We conducted
high-resolution spectroscopy of 12 young PNe from April 2019 to March 2020
using the Bohyunsan Observatory Echelle Spectrograph ({\it BOES}). Building on
the study by Choi and Lee, who identified Raman-scattered \ion{He}{2} at
6545~\AA\ in NGC~6881 and NGC~6886, we report new detections of this feature in
NGC~6741 and NGC~6884. Profile fitting reveals that the velocity of the
\ion{H}{1} component relative to the \ion{He}{2} emission region ranges from
$26-33~{\rm km~s^{-1}}$ in these PNe. Using photoionization modeling, we
estimate the line flux of \ion{He}{2}$\lambda$1025 and derive Raman conversion
efficiencies of 0.39, 0.21, 0.24, and 0.07 for NGC~6881, NGC~6741, NGC~6886,
and NGC~6884, respectively. These results, combined with radiative transfer
modeling, suggest the presence of \ion{H}{1} components with masses around
$10^{-2}~M_\odot$, moving outward from the central \ion{He}{2} emission region
at speeds characteristic of the slow stellar wind from a mass-losing giant
star.",http://arxiv.org/abs/2501.03558v1
"A case study on the transformative potential of AI in software
  engineering on LeetCode and ChatGPT",2025-01-07T09:15:25Z,"Manuel Merkel, Jens Dörpinghaus","The recent surge in the field of generative artificial intelligence (GenAI)
has the potential to bring about transformative changes across a range of
sectors, including software engineering and education. As GenAI tools, such as
OpenAI's ChatGPT, are increasingly utilised in software engineering, it becomes
imperative to understand the impact of these technologies on the software
product. This study employs a methodological approach, comprising web scraping
and data mining from LeetCode, with the objective of comparing the software
quality of Python programs produced by LeetCode users with that generated by
GPT-4o. In order to gain insight into these matters, this study addresses the
question whether GPT-4o produces software of superior quality to that produced
by humans.
  The findings indicate that GPT-4o does not present a considerable impediment
to code quality, understandability, or runtime when generating code on a
limited scale. Indeed, the generated code even exhibits significantly lower
values across all three metrics in comparison to the user-written code.
However, no significantly superior values were observed for the generated code
in terms of memory usage in comparison to the user code, which contravened the
expectations. Furthermore, it will be demonstrated that GPT-4o encountered
challenges in generalising to problems that were not included in the training
data set.
  This contribution presents a first large-scale study comparing generated code
with human-written code based on LeetCode platform based on multiple measures
including code quality, code understandability, time behaviour and resource
utilisation. All data is publicly available for further research.",http://arxiv.org/abs/2501.03639v1
Jet properties of FR0 radio galaxies: need for VLBI data,2025-01-07T13:51:42Z,"R. D. Baldi, G. Giovannini, A. Capetti, R. Lico","Fanaroff-Riley (FR) type 0 radio galaxies are a subclass of radio-loud active
galactic nuclei (AGN) that lack extended kpc-scale jets, different from the
classical FRI and FRII radio galaxies. They constitute the most abundant
population of radio galaxies in the local Universe (z<0.1), yet remain largely
unexplored. VLBI observations of a limited number of FR0s demonstrated that
their central supermassive black hole (SMBH) are able to lunch mostly two-sided
jets, with mildly relativistic bulk speed. In this work, we highlight the need
of further high-resolution radio observations to probe the jet structures of
these compact radio galaxies, by showing exploratory results of our EVN+eMERLIN
observation campaign of FR0s. A preliminary analysis of these recent data
reveals a possible change of the jet direction at different scales. We shortly
discuss their physical conditions to explain the observed jet compactness,
stressing the role of the SMBH spin vector in shaping their radio morphology",http://arxiv.org/abs/2501.03787v1
"Online Reinforcement Learning-Based Dynamic Adaptive Evaluation Function
  for Real-Time Strategy Tasks",2025-01-07T14:36:33Z,"Weilong Yang, Jie Zhang, Xunyun Liu, Yanqing Ye","Effective evaluation of real-time strategy tasks requires adaptive mechanisms
to cope with dynamic and unpredictable environments. This study proposes a
method to improve evaluation functions for real-time responsiveness to
battle-field situation changes, utilizing an online reinforcement
learning-based dynam-ic weight adjustment mechanism within the real-time
strategy game. Building on traditional static evaluation functions, the method
employs gradient descent in online reinforcement learning to update weights
dynamically, incorporating weight decay techniques to ensure stability.
Additionally, the AdamW optimizer is integrated to adjust the learning rate and
decay rate of online reinforcement learning in real time, further reducing the
dependency on manual parameter tun-ing. Round-robin competition experiments
demonstrate that this method signifi-cantly enhances the application
effectiveness of the Lanchester combat model evaluation function, Simple
evaluation function, and Simple Sqrt evaluation function in planning algorithms
including IDABCD, IDRTMinimax, and Port-folio AI. The method achieves a notable
improvement in scores, with the en-hancement becoming more pronounced as the
map size increases. Furthermore, the increase in evaluation function
computation time induced by this method is kept below 6% for all evaluation
functions and planning algorithms. The pro-posed dynamic adaptive evaluation
function demonstrates a promising approach for real-time strategy task
evaluation.",http://arxiv.org/abs/2501.03824v1
"Surface-dependent Majorana vortex phases in topological crystalline
  insulators",2025-01-07T15:29:08Z,"Xun-Jiang Luo, Xiao-Hong Pan, Yilin Shi, Fengcheng Wu","The topological crystalline insulator SnTe exhibits two types of surface
Dirac cones: one located at non-time-reversal-invariant momenta on the (001)
and (110) surfaces, and the other at time-reversal-invariant momenta on the
(111) surface. Motivated by the recent experimental evidence of Majorana vortex
end modes (MVEMs) and their hybridization on the (001) surface [Nature 633, 71
(2024)], we present a comprehensive investigation of Majorana vortex phases in
SnTe, including topological classification, surface-state Hamiltonians
analysis, and lattice model calculations. By utilizing rotational and magnetic
mirror symmetries, we present two equivalent methods to reveal the topology of
Majorana phases on different surfaces. We find that the MVEMs on the (001) and
(110) surfaces are protected by both magnetic group and rotational symmetries.
In contrast, the MVEMs on the (111) surface are protected by magnetic group or
particle-hole symmetry. Due to the different properties of Dirac fermions in
the $\bar{\Gamma}$ and $\bar{M}$ valleys on the (111) surfaces, including Fermi
velocities and energy levels, we find that abundant vortex phase transitions
can occur for the [111]-direction vortex. As the chemical potential increases,
the number of robust MVEMs can change from $0\rightarrow 1\rightarrow 2$. These
vortex transitions are characterized by both $Z$ winding number and $Z_2$
pfaffian topological invariants.",http://arxiv.org/abs/2501.03868v1
"SPECTRE: A Hybrid System for an Adaptative and Optimised Cyber Threats
  Detection, Response and Investigation in Volatile Memory",2025-01-07T16:05:27Z,"Arslan Tariq Syed, Mohamed Chahine Ghanem, Elhadj Benkhelifa, Fauzia Idrees Abro","The increasing sophistication of modern cyber threats, particularly file-less
malware relying on living-off-the-land techniques, poses significant challenges
to traditional detection mechanisms. Memory forensics has emerged as a crucial
method for uncovering such threats by analysing dynamic changes in memory. This
research introduces SPECTRE (Snapshot Processing, Emulation, Comparison, and
Threat Reporting Engine), a modular Cyber Incident Response System designed to
enhance threat detection, investigation, and visualization. By adopting
Volatility JSON format as an intermediate output, SPECTRE ensures compatibility
with widely used DFIR tools, minimizing manual data transformations and
enabling seamless integration into established workflows. Its emulation
capabilities safely replicate realistic attack scenarios, such as credential
dumping and malicious process injections, for controlled experimentation and
validation. The anomaly detection module addresses critical attack vectors,
including RunDLL32 abuse and malicious IP detection, while the IP forensics
module enhances threat intelligence by integrating tools like Virus Total and
geolocation APIs. SPECTRE advanced visualization techniques transform raw
memory data into actionable insights, aiding Red, Blue and Purple teams in
refining strategies and responding effectively to threats. Bridging gaps
between memory and network forensics, SPECTRE offers a scalable, robust
platform for advancing threat detection, team training, and forensic research
in combating sophisticated cyber threats.",http://arxiv.org/abs/2501.03898v1
"From Newswire to Nexus: Using text-based actor embeddings and
  transformer networks to forecast conflict dynamics",2025-01-07T16:45:37Z,"Mihai Croicu, Simon Polichinel von der Maase","This study advances the field of conflict forecasting by using text-based
actor embeddings with transformer models to predict dynamic changes in violent
conflict patterns at the actor level. More specifically, we combine newswire
texts with structured conflict event data and leverage recent advances in
Natural Language Processing (NLP) techniques to forecast escalations and
de-escalations among conflicting actors, such as governments, militias,
separatist movements, and terrorists. This new approach accurately and promptly
captures the inherently volatile patterns of violent conflicts, which existing
methods have not been able to achieve. To create this framework, we began by
curating and annotating a vast international newswire corpus, leveraging
hand-labeled event data from the Uppsala Conflict Data Program. By using this
hybrid dataset, our models can incorporate the textual context of news sources
along with the precision and detail of structured event data. This combination
enables us to make both dynamic and granular predictions about conflict
developments. We validate our approach through rigorous back-testing against
historical events, demonstrating superior out-of-sample predictive power. We
find that our approach is quite effective in identifying and predicting phases
of conflict escalation and de-escalation, surpassing the capabilities of
traditional models. By focusing on actor interactions, our explicit goal is to
provide actionable insights to policymakers, humanitarian organizations, and
peacekeeping operations in order to enable targeted and effective intervention
strategies.",http://arxiv.org/abs/2501.03928v1
"The Power of Negative Zero: Datatype Customization for Quantized Large
  Language Models",2025-01-06T22:40:40Z,"Yuzong Chen, Xilai Dai, Chi-chih Chang, Yash Akhauri, Mohamed S. Abdelfattah","Large language models (LLMs) have demonstrated remarkable performance across
various machine learning tasks, quickly becoming one of the most prevalent AI
workloads. Yet the substantial memory requirement of LLMs significantly hinders
their deployment for end users. Post-training quantization (PTQ) serves as one
of the most hardware-efficient methods to mitigate the memory and computational
demands of LLMs. Although the traditional integer (INT) datatype has received
widespread adoption in PTQ methods, floating-point (FP) quantization has
emerged as a viable alternative thanks to its effectiveness in fitting LLM
numerical distributions. However, the FP datatype in sign-magnitude binary
representation contains both positive and negative zero, which constrains its
representation capability, particularly under low precision (3 and 4 bits). In
this paper, we extend the basic FP datatype to perform Redundant Zero Remapping
(RaZeR), which remaps the negative zero FP encoding to a set of pre-defined
special values to maximally utilize FP quantization encodings and to better fit
LLM numerical distributions. Through careful selection of special values, RaZeR
outperforms conventional asymmetric INT quantization while achieving high
computational efficiency. We demonstrate that RaZeR can be seamlessly
integrated with quantization algorithms for both weights and KV-cache,
including advanced methods with clipping and transformations, and consistently
achieve better model accuracy. Additionally, we implement a fast GEMV kernel
with fused dequantization that efficiently converts the 4-bit RaZeR value to
FP16 through novel bit-level manipulation. On modern GPUs, our evaluation shows
that RaZeR improves the GEMV speed by up to 7.56$\times$ compared to the FP16
implementation, while achieving up to 2.72$\times$ speedup in the LLM decoding
throughput.",http://arxiv.org/abs/2501.04052v1
"Hermitian and Non-Hermitian Topological Transitions Characterized by
  Manifold Distance",2025-01-07T03:05:45Z,"ZhaoXiang Fang, Ming Gong, Guang-Can Guo, Yongxu Fu, Long Xiong","Topological phases are generally characterized by topological invariants
denoted by integer numbers. However, different topological systems often
require different topological invariants to measure, and theses definition
usually fail at critical points. Therefore, it's challenging to predict what
would occur during the transformation between two different topological phases.
To address these issues, we propose a general definition based on fidelity and
trace distance from quantum information theory: manifold distance (MD). This
definition does not rely on the berry connection but rather on the information
of the two manifolds - their ground state wave functions. Thus, it can measure
different topological systems (including traditional band topology models,
non-Hermitian systems, and gapless systems, etc.) and exhibit some universal
laws during the transformation between two topological phases. Our research
demonstrates for different topological manifolds, the change rate (first-order
derivative) or susceptibility (second-order derivative) of MD exhibit various
divergent behaviors near the critical points. Compared to the strange
correlator, which could be used as a diagnosis for short-range entangled states
in 1D and 2D, MD is more universal and could be applied to non-Hermitian
systems and long-range entangled states. For subsequent studies, we expect the
method to be generalized to real-space or non-lattice models, in order to
facilitate the study of a wider range of physical platforms such as open
systems and many-body localization.",http://arxiv.org/abs/2501.04054v1
Postsingular Science,2025-01-07T19:38:57Z,Eldar Knar,"This study presents, for the first time, a conceptual and formal model of
postsingular science (PSS), which analyses and interprets changes in scientific
knowledge driven by accelerating technological progress, singularity, and the
integration of artificial intelligence (AI) into scientific processes. The PSS
model is based on the interplay of six key components: cumulative knowledge,
intelligence, technological synergy, quantum information, social dynamics, and
environmental sustainability. The interaction of these variables is described
through a system of nonlinear differential equations, reflecting the complex
feedback loops and synergetic effects characteristic of the postsingular world.
A differentiation table contrasting postsingular and classical science is also
presented, highlighting the most fundamental differences between contemporary
classical science and future postsingular science. The model emphasizes the
synergy between humans and artificial intelligence, the role of quantum
technologies in accelerating scientific discovery, and the impact of social and
ecological factors that either constrain or stimulate scientific progress. It
is anticipated that new forms of scientific information dissemination will
replace traditional academic publications and that scientific processing will
reach an entirely new level of development following the singularity-driven
acceleration of technological progress and the integration of AI into R&D. This
will herald an era of nonstop, ultrarapid science operating 24/7. The synergy
of humans and artificial intelligence will create a scientific union on the
basis of fundamentally new principles and methods. This research provides an
initial theoretical foundation for further interdisciplinary studies aimed at
developing sustainable strategies and effectively managing scientific progress
in the postsingular era.",http://arxiv.org/abs/2501.04111v2
"Revisiting The Cosmological Time Dilation of Distant Quasars: Influence
  of Source Properties and Evolution",2025-01-07T22:41:54Z,"Brendon J. Brewer, Geraint F. Lewis, Yuan, Li","After decades of searching, cosmological time dilation was recently
identified in the timescale of variability seen in distant quasars. Here, we
expand on the previous analysis to disentangle this cosmological signal from
the influence of the properties of the source population, specifically the
quasar bolometric luminosity and the rest-frame emission wavelength at which
the variability was observed. Furthermore, we consider the potential influence
of the evolution of the quasar population over cosmic time. We find that a
significant intrinsic scatter of 0.288 +- 0.021 dex in the variability
timescales, which was not considered in the previous analysis, is favoured by
the data. This slightly increases the uncertainty in the results. However, the
expected cosmological dependence of the variability timescales is confirmed to
be robust to changes in the underlying assumptions. We find that the
variability timescales increase smoothly with both wavelength and bolometric
luminosity, and that black hole mass has no effect on the variability timescale
once rest wavelength and bolometric luminosity are accounted for. Moreover, if
the standard cosmological model is correct, governed by relativistic expansion,
we also find very little cosmological evolution in the intrinsic variability
timescales of distant quasars.",http://arxiv.org/abs/2501.04171v1
Biglobal resolvent analysis of separated flow over a NACA0012 airfoil,2025-01-08T03:36:33Z,"Laura Victoria Rolandi, Luke Smith, Michael Amitay, Vassilios Theofilis, Kunihiko Taira","The effects of Reynolds number across $Re=1000$, $2500$, $5000$, and $10000$
on separated flow over a two-dimensional NACA0012 airfoil at an angle of attack
of $\alpha=14^\circ$ are investigated through the biglobal resolvent analysis.
We identify modal structures and energy amplifications over a range of
frequency, spanwise wavenumber, and discount parameter, providing insights
across various timescales. Using temporal discounting, we find that the shear
layer dynamics dominates over short time horizons, while the wake dynamics
becomes the primary amplification mechanism over long time horizons. Spanwise
effects also appear over long time horizon, sustained by low frequencies. At a
fixed timescale, we investigate the influence of Reynolds number on response
and forcing mode structures, as well as the energy gain over different
frequencies. Across all Reynolds numbers, the response modes shift from
wake-dominated structures at low frequencies to shear layer-dominated
structures at higher frequencies. The frequency at which the dominant mechanism
changes is independent of the Reynolds number. The response mode structures
show similarities across different Reynolds numbers, with local streamwise
wavelengths only depending on frequency. Comparisons at a different angle of
attack ($\alpha=9^\circ$) show that the transition from wake to shear layer
dynamics with increasing frequency only occurs if the unsteady flow is
three-dimensional. We also study the dominant frequencies associated with wake
and shear layer dynamics across the angles of attack and Reynolds numbers, and
present the characteristic scaling for each mechanism.",http://arxiv.org/abs/2501.04255v1
"H-MBA: Hierarchical MamBa Adaptation for Multi-Modal Video Understanding
  in Autonomous Driving",2025-01-08T06:26:16Z,"Siran Chen, Yuxiao Luo, Yue Ma, Yu Qiao, Yali Wang","With the prevalence of Multimodal Large Language Models(MLLMs), autonomous
driving has encountered new opportunities and challenges. In particular,
multi-modal video understanding is critical to interactively analyze what will
happen in the procedure of autonomous driving. However, videos in such a
dynamical scene that often contains complex spatial-temporal movements, which
restricts the generalization capacity of the existing MLLMs in this field. To
bridge the gap, we propose a novel Hierarchical Mamba Adaptation (H-MBA)
framework to fit the complicated motion changes in autonomous driving videos.
Specifically, our H-MBA consists of two distinct modules, including Context
Mamba (C-Mamba) and Query Mamba (Q-Mamba). First, C-Mamba contains various
types of structure state space models, which can effectively capture
multi-granularity video context for different temporal resolutions. Second,
Q-Mamba flexibly transforms the current frame as the learnable query, and
attentively selects multi-granularity video context into query. Consequently,
it can adaptively integrate all the video contexts of multi-scale temporal
resolutions to enhance video understanding. Via a plug-and-play paradigm in
MLLMs, our H-MBA shows the remarkable performance on multi-modal video tasks in
autonomous driving, e.g., for risk object detection, it outperforms the
previous SOTA method with 5.5% mIoU improvement.",http://arxiv.org/abs/2501.04302v1
"Eccentricity Effects on Modeling Dynamic Quantities and Their
  Correlations in Binary Black Hole Mergers",2025-01-08T13:28:08Z,"Hao Wang, Yuan Chuan Zou, Qing Wen Wu","In this study, we begin by revisiting the oscillatory behavior of radiative
quantities-energy, angular momentum, and linear momentum-linked with initial
eccentricities in binary black hole (BBH) mergers. By varying the mean anomaly
$l_0$ across the parameter range $[0,2\pi]$ from a post-Newtonian perspective,
we establish an envelope that encapsulates the oscillations of these radiative
quantities. Our analysis reveals that while the oscillations are influenced by
the specific initial condition $l_0$, the effect of eccentricity contributes to
the formation of this envelope. Subsequently, we model dynamical quantities
such as peak luminosity $L_{\text{peak}}$, remnant mass $M_{\text{rem}}$, spin
$\alpha_{\text{rem}}$, and recoil velocity $V_{\text{rem}}$ in circular orbits.
Through polynomial modeling, we explore their relationships with mass ratios
and correlations. Our results demonstrate the effectiveness of these
polynomials in capturing the intricate relationships and correlations among
these quantities in circular orbits. Furthermore, we synthesize and analyze
dynamical quantities for both circular and eccentric orbits, revealing
continuous variations within specific ranges corresponding to distinct mass
ratios. These variations are influenced by continuous changes in initial
eccentricity and the associated envelope, which can be extrapolated to
encompass other mass ratios. By interpolating the maximum and minimum values of
these dynamical quantities, we unveil considerably broad domains relative to
circular orbits in both orbital and non-orbital BBH mergers. These domains
provide robust constraints on the relationships between dynamical quantities,
mass ratios, and their correlations. Finally, we discuss the extension of this
eccentricity effect to spin alignment and spin precession configurations of
BBHs.",http://arxiv.org/abs/2501.04495v1
"Effective Two-Stage Double Auction for Dynamic Resource Trading in Edge
  Networks via Overbooking",2025-01-08T13:52:55Z,"Sicheng Wu, Minghui Liwang, Deqing Wang, Xianbin Wang, Chao Wu, Junyi Tang, Li Li, Zhenzhen Jiao","To facilitate responsive and cost-effective computing resource scheduling and
service delivery over edge-assisted mobile networks, this paper investigates a
novel two-stage double auction methodology via utilizing an interesting idea of
resource overbooking to overcome dynamic and uncertain nature from edge servers
(sellers) and demand from mobile devices (as buyers). The proposed auction
integrates multiple essential factors such as social welfare maximization and
decision-making latency (e.g., the time for determining winning seller-buyer
pairs) reduction, by introducing a stagewise strategy: an overbooking-driven
pre-double auction (OPDAuction) for determining long-term cooperations between
sellers and buyers before practical resource transactions as Stage I, and a
real-time backup double auction (RBDAuction) for handling residual resource
demands during actual transactions. In particular, by applying a proper
overbooking rate, OPDAuction helps with facilitating trading contracts between
appropriate sellers and buyers as guidance for future transactions, by allowing
the booked resources to exceed supply. Then, since pre-auctions may cause
risks, our RBDAuction adjusts to real-time market changes, further enhancing
the overall social welfare. More importantly, we offer an interesting view to
show that our proposed two-stage auction can support significant design
properties such as truthfulness, individual rationality, and budget balance.
Through extensive experiments, we demonstrate good performance in social
welfare, time efficiency, and computational scalability, outstripping
conventional methods in dynamic edge computing settings.",http://arxiv.org/abs/2501.04507v1
"Spherical Double K-Means: a co-clustering approach for text data
  analysis",2025-01-08T15:21:00Z,"Ilaria Bombelli, Domenica Fioredistella Iezzi, Emiliano Seri, Maurizio Vichi","In text analysis, Spherical K-means (SKM) is a specialized k-means clustering
algorithm widely utilized for grouping documents represented in
high-dimensional, sparse term-document matrices, often normalized using
techniques like TF-IDF. Researchers frequently seek to cluster not only
documents but also the terms associated with them into coherent groups. To
address this dual clustering requirement, we introduce Spherical Double K-Means
(SDKM), a novel methodology that simultaneously clusters documents and terms.
This approach offers several advantages: first, by integrating the clustering
of documents and terms, SDKM provides deeper insights into the relationships
between content and vocabulary, enabling more effective topic identification
and keyword extraction. Additionally, the two-level clustering assists in
understanding both overarching themes and specific terminologies within
document clusters, enhancing interpretability. SDKM effectively handles the
high dimensionality and sparsity inherent in text data by utilizing cosine
similarity, leading to improved computational efficiency. Moreover, the method
captures dynamic changes in thematic content over time, making it well-suited
for applications in rapidly evolving fields. Ultimately, SDKM presents a
comprehensive framework for advancing text mining efforts, facilitating the
uncovering of nuanced patterns and structures that are critical for robust data
analysis. We apply SDKM to the corpus of US presidential inaugural addresses,
spanning from George Washington in 1789 to Joe Biden in 2021. Our analysis
reveals distinct clusters of words and documents that correspond to significant
historical themes and periods, showcasing the method's ability to facilitate a
deeper understanding of the data. Our findings demonstrate the efficacy of SDKM
in uncovering underlying patterns in textual data.",http://arxiv.org/abs/2501.04562v2
"Large-Scale Spectral Graph Neural Networks via Laplacian Sparsification:
  Technical Report",2025-01-08T15:36:19Z,"Haipeng Ding, Zhewei Wei, Yuhang Ye","Graph Neural Networks (GNNs) play a pivotal role in graph-based tasks for
their proficiency in representation learning. Among the various GNN methods,
spectral GNNs employing polynomial filters have shown promising performance on
tasks involving both homophilous and heterophilous graph structures. However,
The scalability of spectral GNNs on large graphs is limited because they learn
the polynomial coefficients through multiple forward propagation executions
during forward propagation. Existing works have attempted to scale up spectral
GNNs by eliminating the linear layers on the input node features, a change that
can disrupt end-to-end training, potentially impact performance, and become
impractical with high-dimensional input features. To address the above
challenges, we propose ""Spectral Graph Neural Networks with Laplacian
Sparsification (SGNN-LS)"", a novel graph spectral sparsification method to
approximate the propagation patterns of spectral GNNs. We prove that our
proposed method generates Laplacian sparsifiers that can approximate both fixed
and learnable polynomial filters with theoretical guarantees. Our method allows
the application of linear layers on the input node features, enabling
end-to-end training as well as the handling of raw text features. We conduct an
extensive experimental analysis on datasets spanning various graph scales and
properties to demonstrate the superior efficiency and effectiveness of our
method. The results show that our method yields superior results in comparison
with the corresponding approximated base models, especially on dataset
Ogbn-papers100M(111M nodes, 1.6B edges) and MAG-scholar-C (2.8M features).",http://arxiv.org/abs/2501.04570v1
"Mediation analysis in longitudinal intervention studies with an ordinal
  treatment-dependent confounder",2025-01-08T15:55:57Z,"Mikko Valtanen, Tommi Härkänen, Matti Uusitupa, Jaakko Tuomilehto, Jaana Lindström, Kari Auranen","In interventional health studies, causal mediation analysis can be employed
to investigate mechanisms through which the intervention affects the targeted
health outcome. Identifying direct and indirect (i.e. mediated) effects from
empirical data, however, becomes complicated if the mediator-outcome
association is confounded by a variable itself affected by the treatment. Here,
we investigate identification of mediational effects under such post-treatment
confounding in a setting with a longitudinal mediator, time-to-event outcome
and a trichotomous ordinal treatment-dependent confounder. We show that if the
intervention always affects the treatment-dependent confounder only in one
direction (monotonicity), the mediational effects are identified up to a
sensitivity parameter and derive their empirical non-parametric expressions.
The monotonicity assumption can be assessed from empirical data, based on
restrictions on the conditional distribution of the treatment-dependent
confounder. We avoid pitfalls related to post-treatment conditioning by
treating the mediator as a functional entity and defining the time-to-event
outcome as a restricted disease-free time. In an empirical analysis, we use
data from the Finnish Diabetes Prevention Study to assess the extent to which
the effect of a lifestyle intervention on avoiding type 2 diabetes is mediated
through weight reduction in a high-risk population, with other health-related
changes acting as treatment-dependent confounders.",http://arxiv.org/abs/2501.04581v1
"Modeling temporal dependence in a sequence of spatial random partitions
  driven by spanning tree: an application to mosquito-borne diseases",2025-01-08T16:33:00Z,"Jessica Pavani, Rosangela Helena Loschi, Fernando Andres Quintana","Spatially constrained clustering is an important field of research,
particularly when it involves changes over time. Partitioning a map is not
simple since there is a vast number of possible partitions within the search
space. In spatio-temporal clustering, this task becomes even more difficult, as
we must consider sequences of partitions. Motivated by these challenges, we
introduce a Bayesian model for time-dependent sequences of spatial random
partitions by proposing a prior distribution based on product partition models
that correlates partitions. Additionally, we employ random spanning trees to
facilitate the exploration of the partition search space and to guarantee
spatially constrained clustering. This work is motivated by a relevant applied
problem: identifying spatial and temporal patterns of mosquito-borne diseases.
Given the overdispersion present in this type of data, we introduce a
spatio-temporal Poisson mixture model in which mean and dispersion parameters
vary according to spatio-temporal covariates. The proposed model is applied to
analyze the number of dengue cases reported weekly from 2018 to 2023 in the
Southeast region of Brazil. We also evaluate model performance using simulated
data. Overall, the proposed model has proven to be a competitive approach for
analyzing the temporal evolution of spatial clustering.",http://arxiv.org/abs/2501.04601v1
"Fast physics-based launcher optimization for electron cyclotron current
  drive",2025-01-08T17:03:08Z,"N A Lopez, A Alieva, S A M McNamara, X Zhang","With the increased urgency to design fusion pilot plants, fast optimization
of electron cyclotron current drive (ECCD) launchers is paramount.
Traditionally, this is done by coarsely sampling the 4-D parameter space of
possible launch conditions consisting of (1) the launch location (constrained
to lie along the reactor vessel), (2) the launch frequency, (3) the toroidal
launch angle, and (4) the poloidal launch angle. For each initial condition, a
ray-tracing simulation is performed to evaluate the ECCD efficiency.
Unfortunately, this approach often requires millions of simulations to build up
a dataset that adequately covers the plasma volume, which must then be repeated
every time the design point changes. Here we adopt a different approach. Rather
than launching rays from the plasma periphery and hoping for the best, we
instead directly reconstruct the optimal ray for driving current at a given
flux surface using a reduced physics model coupled with a commercial
ray-tracing code. Repeating this throughout the plasma volume requires only
hundreds of simulations, constituting a ten-thousand-fold speedup. The new
method is validated on two separate example tokamak profiles, and is shown to
reliably drive localized current at the specified flux surface with the same
optimal efficiency as obtained from the traditional approach.",http://arxiv.org/abs/2501.04619v1
"Framework for Integrating Machine Learning Methods for Path-Aware Source
  Routing",2025-01-08T17:10:18Z,"Anees Al-Najjar, Domingos Paraiso, Mariam Kiran, Cristina Dominicini, Everson Borges, Rafael Guimaraes, Magnos Martinello, Harvey Newman","Since the advent of software-defined networking (SDN), Traffic Engineering
(TE) has been highlighted as one of the key applications that can be achieved
through software-controlled protocols (e.g. PCEP and MPLS). Being one of the
most complex challenges in networking, TE problems involve difficult decisions
such as allocating flows, either via splitting them among multiple paths or by
using a reservation system, to minimize congestion. However, creating an
optimized solution is cumbersome and difficult as traffic patterns vary and
change with network scale, capacity, and demand. AI methods can help alleviate
this by finding optimized TE solutions for the best network performance.
SDN-based TE tools such as Teal, Hecate and more, use classification techniques
or deep reinforcement learning to find optimal network TE solutions that are
demonstrated in simulation. Routing control conducted via source routing tools,
e.g., PolKA, can help dynamically divert network flows. In this paper, we
propose a novel framework that leverages Hecate to practically demonstrate TE
on a real network, collaborating with PolKA, a source routing tool. With
real-time traffic statistics, Hecate uses this data to compute optimal paths
that are then communicated to PolKA to allocate flows. Several contributions
are made to show a practical implementation of how this framework is tested
using an emulated ecosystem mimicking a real P4 testbed scenario. This work
proves valuable for truly engineered self-driving networks helping translate
theory to practice.",http://arxiv.org/abs/2501.04624v1
Cosmic deceptions due to peculiar motions,2025-01-08T18:40:41Z,Christos G. Tsagas,"Relative motions have long been known to mislead the unsuspecting observers
to false interpretations of reality. The deceptions are usually brief and
unimportant, though relative motions have also led to illusions that were both
long-lasting and important. Indeed, in the history of astronomy there are
several examples where relative-motion effects have misled us to gross
misinterpretations. Here, we consider the possibility that our peculiar motion
relative to the cosmic rest-frame can trigger deceptions on cosmological
scales. In so doing, we will demonstrate that unsuspecting observers inside
bulk peculiar flows may come to the false conclusion of recent accelerated
expansion, when their host universe is actually decelerating. The same
observers may then erroneously attribute their apparent acceleration to an also
recent dramatic change in the nature of the cosmic medium. In reality, however,
nothing has really happened. Despite the appearances, the host universe keeps
decelerating and its material content retains its conventional form.
Nevertheless, there are ways out of these illusions. Our observers can find out
that they have been deceived by their own peculiar flow, by looking for the
trademark signature of relative motion in their data. This signature is nothing
else but a Doppler-like anisotropy in the sky distribution of the measured
deceleration parameter. To the bulk-flow observers, the universe should appear
to accelerate faster along a certain point on the celestial sphere and equally
slower along the antipodal. Moreover, the magnitude of the apparent dipole
should decrease with increasing redshift.",http://arxiv.org/abs/2501.04680v1
"A Shape-Based Functional Index for Objective Assessment of Pediatric
  Motor Function",2025-01-02T21:42:04Z,"Shashwat Kumar, Arafat Rahman, Robert Gutierrez, Sarah Livermon, Allison N. McCrady, Silvia Blemker, Rebecca Scharf, Anuj Srivastava, Laura E. Barnes","Clinical assessments for neuromuscular disorders, such as Spinal Muscular
Atrophy (SMA) and Duchenne Muscular Dystrophy (DMD), continue to rely on
subjective measures to monitor treatment response and disease progression. We
introduce a novel method using wearable sensors to objectively assess motor
function during daily activities in 19 patients with DMD, 9 with SMA, and 13
age-matched controls. Pediatric movement data is complex due to confounding
factors such as limb length variations in growing children and variability in
movement speed. Our approach uses Shape-based Principal Component Analysis to
align movement trajectories and identify distinct kinematic patterns, including
variations in motion speed and asymmetry. Both DMD and SMA cohorts have
individuals with motor function on par with healthy controls. Notably, patients
with SMA showed greater activation of the motion asymmetry pattern. We further
combined projections on these principal components with partial least squares
(PLS) to identify a covariation mode with a canonical correlation of r = 0.78
(95% CI: [0.34, 0.94]) with muscle fat infiltration, the Brooke score (a motor
function score), and age-related degenerative changes, proposing a novel motor
function index. This data-driven method can be deployed in home settings,
enabling better longitudinal tracking of treatment efficacy for children with
neuromuscular disorders.",http://arxiv.org/abs/2501.04721v1
Intrinsic Direct Air Capture,2025-01-08T20:24:02Z,"Austin McDannald, Daniel W. Siderius, Brian DeCost, Kamal Choudhary, Diana L. Ortiz-Montalvo","We present new metrics to evaluate solid sorbent materials for Direct Air
Capture (DAC). These new metrics provide a theoretical upper bound on CO2
captured per energy as well as a theoretical upper limit on the purity of the
captured CO2. These new metrics are based entirely on intrinsic material
properties and are therefore agnostic to the design of the DAC system. These
metrics apply to any adsorption-refresh cycle design. In this work we
demonstrate the use of these metrics with the example of temperature-pressure
swing refresh cycles. The main requirement for applying these metrics is to
describe the equilibrium uptake (along with a few other materials properties)
of each species in terms of the thermodynamic variables (e.g. temperature,
pressure). We derive these metrics from thermodynamic energy balances. To apply
these metrics on a set of examples, we first generated approximations of the
necessary materials properties for 11 660 metal-organic framework materials
(MOFs). We find that the performance of the sorbents is highly dependent on the
path through thermodynamic parameter space. These metrics allow for: 1) finding
the optimum materials given a particular refresh cycle, and 2) finding the
optimum refresh cycles given a particular sorbent. Applying these metrics to
the database of MOFs lead to the following insights: 1) start cold - the
equilibrium uptake of CO2 diverges from that of N2 at lower temperatures, and
2) selectivity of CO2 vs other gases at any one point in the cycle does not
matter - what matters is the relative change in uptake along the cycle.",http://arxiv.org/abs/2501.04825v1
"Balancing Exploration and Cybersickness: Investigating Curiosity-Driven
  Behavior in Virtual Environments",2025-01-09T01:38:34Z,"Tangyao Li, Yuyang Wang","During virtual navigation, users exhibit varied interaction and navigation
behaviors influenced by several factors. Existing theories and models have been
developed to explain and predict these diverse patterns. While users often
experience uncomfortable sensations, such as cybersickness, during virtual
reality (VR) use, they do not always make optimal decisions to mitigate these
effects. Although methods like reinforcement learning have been used to model
decision-making processes, they typically rely on random selection to simulate
actions, failing to capture the complexities of real navigation behavior. In
this study, we propose curiosity as a key factor driving irrational
decision-making, suggesting that users continuously balance exploration and
cybersickness according to the free energy principle during virtual navigation.
Our findings show that VR users generally adopt conservative strategies when
navigating, with most participants displaying negative curiosity across trials.
However, curiosity levels tend to rise when the virtual environment changes,
illustrating the dynamic interplay between exploration and discomfort. This
study provides a quantitative approach to decoding curiosity-driven behavior
during virtual navigation, offering insights into how users balance exploration
and the avoidance of cybersickness. Future research will further refine this
model by incorporating additional psychological and environmental factors to
improve the accuracy of navigation pattern predictions.",http://arxiv.org/abs/2501.04905v2
"Topology-aware Microservice Architecture in Edge Networks: Deployment
  Optimization and Implementation",2025-01-09T04:16:55Z,"Yuang Chen, Chang Wu, Fangyu Zhang, Chengdi Lu, Yongsheng Huang, Hancheng Lu","As a ubiquitous deployment paradigm, integrating microservice architecture
(MSA) into edge networks promises to enhance the flexibility and scalability of
services. However, it also presents significant challenges stemming from
dispersed node locations and intricate network topologies. In this paper, we
have proposed a topology-aware MSA characterized by a three-tier network
traffic model encompassing the service, microservices, and edge node layers.
This model meticulously characterizes the complex dependencies between edge
network topologies and microservices, mapping microservice deployment onto link
traffic to accurately estimate communication delay. Building upon this model,
we have formulated a weighted sum communication delay optimization problem
considering different types of services. Then, a novel topology-aware and
individual-adaptive microservices deployment (TAIA-MD) scheme is proposed to
solve the problem efficiently, which accurately senses the network topology and
incorporates an individual-adaptive mechanism in a genetic algorithm to
accelerate the convergence and avoid local optima. Extensive simulations show
that, compared to the existing deployment schemes, TAIA-MD improves the
communication delay performance by approximately 30% to 60% and effectively
enhances the overall network performance. Furthermore, we implement the TAIA-MD
scheme on a practical microservice physical platform. The experimental results
demonstrate that TAIA-MD achieves superior robustness in withstanding link
failures and network fluctuations.",http://arxiv.org/abs/2501.04956v1
"A CT Image Classification Network Framework for Lung Tumors Based on
  Pre-trained MobileNetV2 Model and Transfer learning, And Its Application and
  Market Analysis in the Medical field",2025-01-09T06:22:50Z,"Ziyang Gao, Yong Tian, Shih-Chi Lin, Junghua Lin","In the medical field, accurate diagnosis of lung cancer is crucial for
treatment. Traditional manual analysis methods have significant limitations in
terms of accuracy and efficiency. To address this issue, this paper proposes a
deep learning network framework based on the pre-trained MobileNetV2 model,
initialized with weights from the ImageNet-1K dataset (version 2). The last
layer of the model (the fully connected layer) is replaced with a new fully
connected layer, and a softmax activation function is added to efficiently
classify three types of lung cancer CT scan images. Experimental results show
that the model achieves an accuracy of 99.6% on the test set, with significant
improvements in feature extraction compared to traditional models.With the
rapid development of artificial intelligence technologies, deep learning
applications in medical image processing are bringing revolutionary changes to
the healthcare industry. AI-based lung cancer detection systems can
significantly improve diagnostic efficiency, reduce the workload of doctors,
and occupy an important position in the global healthcare market. The potential
of AI to improve diagnostic accuracy, reduce medical costs, and promote
precision medicine will have a profound impact on the future development of the
healthcare industry.",http://arxiv.org/abs/2501.04996v1
"Finite strain continuum phenomenological model describing the
  shape-memory effects in multi-phase semi-crystalline networks",2025-01-09T07:58:43Z,"Matteo Arricca, Nicoletta Inverardi, Stefano Pandini, Maurizio Toselli, Massimo Messori, Giulia Scalet","Thermally-driven semi-crystalline polymer networks are capable to achieve
both the one-way shape-memory effect and two-way shape-memory effect under
stress and stress-free conditions, therefore representing an appealing class of
polymers for applications requiring autonomous reversible actuation and shape
changes. In these materials, the shape-memory effects are achieved by
leveraging the synergistic interaction between one or more crystalline phases
and the surrounding amorphous ones that are present within the network itself.
The present paper introduces a general framework for the finite strain
continuum phenomenological modeling of the thermo-mechanical and shape-memory
behavior of multi-phase semi-crystalline polymer networks. Model formulation,
including the definition of phase and control variables, kinematic assumptions,
and constitutive specifications, is introduced and thoroughly discussed.
Theoretical derivations are general and easily adaptable to all cross-linked
systems which include two or more crystalline domains or a single crystalline
phase with a wide melting range and manifest macroscopically the one-way
shape-memory effect and the two-way shape-memory effect under stress and
stress-free conditions. Model capabilities are validated against experimental
data for copolymer networks with two different crystalline phases characterized
by well-separated melting and crystallization transitions. Results demonstrate
the accuracy of the proposed model in predicting all the phenomena involved and
in furnishing a useful support for future material and application design
purposes.",http://arxiv.org/abs/2501.05043v1
"Existence and multiplicity of solutions for a critical Kirchhoff type
  elliptic equation with a logarithmic perturbation",2025-01-09T09:04:45Z,"Qian Zhang, Yuzhu Han","In this paper, we are interested in the following critical Kirchhoff type
elliptic equation with a logarithmic perturbation \begin{equation}\label{eq0}
\begin{cases} -\left(1+b\int_{\Omega}|\nabla{u}|^2\mathrm{d}x\right)
\Delta{u}=\lambda u+\mu u\log{u^2}+|u|^{2^{*}-2}u, &x\in\Omega,\\
u=0,&x\in\partial\Omega, \end{cases} \end{equation} where $\Omega$ is a bounded
domain in $\mathbb{R}^{N}(N\geq3)$ with smooth boundary $\partial \Omega$, $b$,
$\lambda$ and $\mu$ are parameters and $2^{*}=\frac{2N}{N-2}$ is the critical
Sobolev exponent. The presence of a nonlocal term, together with a critical
nonlinearity and a logarithmic term, prevents to apply in a straightforward way
the classical critical point theory. Moreover, the geometry structure of the
energy functional changes as the space dimension $N$ varies, which has a
crucial influence on the existence of solutions to the problem. On the basis of
some careful analysis on the structure of the energy functional, existence and
(or) multiplicity results are obtained by using variational methods. More
precisely, if $N=3$, the problem admits a local minimum solution, a ground
state solution and a sequence of solutions with their $H_0^1(\Omega)$-norms
converging to $0$. If $N=4$, the existence of infinitely many solutions is also
obtained. When $N\geq5$, the problem admits a local minimum solution with
negative energy. Sufficient conditions are also derived for the local minimum
solution to be a ground state solution.",http://arxiv.org/abs/2501.05083v1
"The impact of the redshift-dependent selection effect of halos on the
  redshift-space power spectrum",2025-01-09T09:11:23Z,"Kanmi Nose, Masahiro Takada, Ryo Terasawa","In a wide-area spectroscopic survey of galaxies, it is nearly impossible to
obtain a homogeneous sample of galaxies with respect to galaxy properties such
as stellar mass and host halo mass across a range of redshifts. Despite the
selection effect, theoretical templates in most analyses assume single tracers
when compared with the measured clustering quantities. We demonstrate
analytically that the selection effect inevitably introduces a bias in the
redshift-space power spectrum on scales from linear to nonlinear scales. To
quantitatively assess the impact of the selection effect, we construct mock
galaxy catalogs from halos in N-body simulations by selecting halos above
redshift-dependent mass thresholds such that the resulting redshift
distribution of the halos, $n(z)$, matches that of SDSS-like galaxies. We find
that the selection effect causes fractional changes of up to only 1% and 2% in
the monopole and quadrupole moments of the redshift-space power spectrum at
$k\lesssim 0.3~h{\rm{Mpc}}^{-1}$, respectively, compared to the moments for the
single mass-threshold (therefore single tracer) sample, for $n_{\rm g}(z)$ of
the SDSS-like galaxy samples. We also argue that the selection effect is
unlikely to cause a significant bias in the estimation of cosmological
parameters using the Fisher matrix method, provided that the redshift-dependent
selection effect is modest.",http://arxiv.org/abs/2501.05086v1
"Recovery of activation propagation and self-sustained oscillation
  abilities in stroke brain networks",2025-01-09T09:38:07Z,"Yingpeng Liu, Jiao Wu, Kesheng Xu, Muhua Zheng","Healthy brain networks usually show highly efficient information
communication and self-sustained oscillation abilities. However, how the brain
network structure affects these dynamics after an injury (stroke) is not very
clear. The recovery of structure and dynamics of stroke brain networks over
time is still not known precisely. Based on the analysis of a large number of
strokes' brain network data, we show that stroke changes the network properties
in connection weights, average degree, clustering, community, etc. Yet, they
will recover gradually over time to some extent. We then adopt a simplified
reaction-diffusion model to investigate stroke patients' activation propagation
and self-sustained oscillation abilities. Our results reveal that the stroke
slows the adoption time across different brain scales, indicating a weakened
brain's activation propagation ability. In addition, we show that the lifetime
of self-sustained oscillatory patterns at three months post-stroke patients'
brains significantly departs from the healthy one. Finally, we examine the
properties of core networks of self-sustained oscillatory patterns, in which
the directed edges denote the main pathways of activation propagation. Our
results demonstrate that the lifetime and recovery of self-sustaining patterns
are related to the properties of core networks, and the properties in the
post-stroke greatly vary from those in the healthy group. Most importantly, the
strokes' activation propagation and self-sustained oscillation abilities
significantly improve at one year post-stroke, driven by structural connection
repair. This work may help us to understand the relationship between structure
and function in brain disorders.",http://arxiv.org/abs/2501.05099v1
FaceMe: Robust Blind Face Restoration with Personal Identification,2025-01-09T11:52:54Z,"Siyu Liu, Zheng-Peng Duan, Jia OuYang, Jiayi Fu, Hyunhee Park, Zikun Liu, Chun-Le Guo, Chongyi Li","Blind face restoration is a highly ill-posed problem due to the lack of
necessary context. Although existing methods produce high-quality outputs, they
often fail to faithfully preserve the individual's identity. In this paper, we
propose a personalized face restoration method, FaceMe, based on a diffusion
model. Given a single or a few reference images, we use an identity encoder to
extract identity-related features, which serve as prompts to guide the
diffusion model in restoring high-quality and identity-consistent facial
images. By simply combining identity-related features, we effectively minimize
the impact of identity-irrelevant features during training and support any
number of reference image inputs during inference. Additionally, thanks to the
robustness of the identity encoder, synthesized images can be used as reference
images during training, and identity changing during inference does not require
fine-tuning the model. We also propose a pipeline for constructing a reference
image training pool that simulates the poses and expressions that may appear in
real-world scenarios. Experimental results demonstrate that our FaceMe can
restore high-quality facial images while maintaining identity consistency,
achieving excellent performance and robustness.",http://arxiv.org/abs/2501.05177v2
"HipyrNet: Hypernet-Guided Feature Pyramid network for mixed-exposure
  correction",2025-01-09T12:33:46Z,"Shaurya Singh Rathore, Aravind Shenoy, Krish Didwania, Aditya Kasliwal, Ujjwal Verma","Recent advancements in image translation for enhancing mixed-exposure images
have demonstrated the transformative potential of deep learning algorithms.
However, addressing extreme exposure variations in images remains a significant
challenge due to the inherent complexity and contrast inconsistencies across
regions. Current methods often struggle to adapt effectively to these
variations, resulting in suboptimal performance. In this work, we propose
HipyrNet, a novel approach that integrates a HyperNetwork within a Laplacian
Pyramid-based framework to tackle the challenges of mixed-exposure image
enhancement. The inclusion of a HyperNetwork allows the model to adapt to these
exposure variations. HyperNetworks dynamically generates weights for another
network, allowing dynamic changes during deployment. In our model, the
HyperNetwork employed is used to predict optimal kernels for Feature Pyramid
decomposition, which enables a tailored and adaptive decomposition process for
each input image. Our enhanced translational network incorporates multiscale
decomposition and reconstruction, leveraging dynamic kernel prediction to
capture and manipulate features across varying scales. Extensive experiments
demonstrate that HipyrNet outperforms existing methods, particularly in
scenarios with extreme exposure variations, achieving superior results in both
qualitative and quantitative evaluations. Our approach sets a new benchmark for
mixed-exposure image enhancement, paving the way for future research in
adaptive image translation.",http://arxiv.org/abs/2501.05195v1
"Automated external cervical resorption segmentation in cone-beam CT
  using local texture features",2025-01-09T13:43:01Z,"Sadhana Ravikumar, Asma A. Khan, Matthew C. Davis, Beatriz Paniagua","External cervical resorption (ECR) is a resorptive process affecting teeth.
While in some patients, active resorption ceases and gets replaced by osseous
tissue, in other cases, the resorption progresses and ultimately results in
tooth loss. For proper ECR assessment, cone-beam computed tomography (CBCT) is
the recommended imaging modality, enabling a 3-D characterization of these
lesions. While it is possible to manually identify and measure ECR resorption
in CBCT scans, this process can be time intensive and highly subject to human
error. Therefore, there is an urgent need to develop an automated method to
identify and quantify the severity of ECR resorption using CBCT. Here, we
present a method for ECR lesion segmentation that is based on automatic, binary
classification of locally extracted voxel-wise texture features. We evaluate
our method on 6 longitudinal CBCT datasets and show that certain
texture-features can be used to accurately detect subtle CBCT signal changes
due to ECR. We also present preliminary analyses clustering texture features
within a lesion to stratify the defects and identify patterns indicative of
calcification. These methods are important steps in developing prognostic
biomarkers to predict whether ECR will continue to progress or cease,
ultimately informing treatment decisions.",http://arxiv.org/abs/2501.05236v1
Private Selection with Heterogeneous Sensitivities,2025-01-09T15:25:07Z,"Daniela Antonova, Allegra Laro, Audra McMillan, Lorenz Wolf","Differentially private (DP) selection involves choosing a high-scoring
candidate from a finite candidate pool, where each score depends on a sensitive
dataset. This problem arises naturally in a variety of contexts including model
selection, hypothesis testing, and within many DP algorithms. Classical
methods, such as Report Noisy Max (RNM), assume all candidates' scores are
equally sensitive to changes in a single individual's data, but this often
isn't the case. To address this, algorithms like the Generalised Exponential
Mechanism (GEM) leverage variability in candidate sensitivities. However, we
observe that while these algorithms can outperform RNM in some situations, they
may underperform in others - they can even perform worse than random selection.
In this work, we explore how the distribution of scores and sensitivities
impacts DP selection mechanisms. In all settings we study, we find that there
exists a mechanism that utilises heterogeneity in the candidate sensitivities
that outperforms standard mechanisms like RNM. However, no single mechanism
uniformly outperforms RNM. We propose using the correlation between the scores
and sensitivities as the basis for deciding which DP selection mechanism to
use. Further, we design a slight variant of GEM, modified GEM that generally
performs well whenever GEM performs poorly. Relying on the correlation
heuristic we propose combined GEM, which adaptively chooses between GEM and
modified GEM and outperforms both in polarised settings.",http://arxiv.org/abs/2501.05309v1
"Data-driven methods to discover stable linear models of the helicity
  injectors on HIT-SIU",2025-01-09T17:58:37Z,"Zachary L. Daniel, Alan A. Kaptanoglu, Christopher J. Hansen, Kyle D. Morgan, Steven L. Brunton, J. Nathan Kutz","Accurate and efficient circuit models are necessary to control the power
electronic circuits found on plasma physics experiments. Tuning and controlling
the behavior of these circuits is inextricably linked to plasma performance.
Linear models are greatly preferred for control applications due to their
well-established performance guarantees, but they typically fail to capture
nonlinear dynamics and changes in experimental parameters. Data-driven system
identification can help mitigate these shortcomings by learning interpretable
and accurate reduced-order models of a complex system, in this case the
injector circuits of the Helicity Injected Torus - Steady Inductive Upgrade
(HIT-SIU) experiment. Specifically, the Bagging Optimized Dynamic Mode
Decomposition (BOP-DMD), is leveraged to learn stable, reduced order models of
the interaction between the spheromak plasma formed in the confinement volume,
and the injector circuits of the device. BOP-DMD is trained and evaluated on an
analytic model of the vacuum dynamics of the injector circuits of HIT-SIU, as
well as an analytic linear reduced-order model for the injector dynamics when a
plasma is present. BOP-DMD is then fit on experimental data, both on shots with
and without a plasma in the confinement volume. In doing so, we demonstrate the
capability of data-driven methods to produce stable, linear models for control
and uncertainty quantification in plasma experiments.",http://arxiv.org/abs/2501.05405v2
"How quantum selection rules influence the magneto-optical effects of
  driven, ultrafast magnetization dynamics",2025-01-09T18:47:51Z,"Mohamed F. Elhanoty, Olle Eriksson, Chin Shen Ong, Oscar Grånäs","Ultrafast magnetization dynamics driven by ultrashort pump lasers is
typically explained by changes in electronic populations and scattering
pathways of excited conduction electrons. This conventional approach overlooks
the fundamental role of quantum mechanical selection rules, governing
transitions from core states to the conduction band, that forms the key method
of the probing step in these experiments. By employing fully ab initio
time-dependent density functional theory, we reveal that these selection rules
profoundly influence the interpretation of ultrafast spin dynamics at specific
probe energies. Our analysis for hcp Co and fcc Ni at the M edge demonstrates
that the transient dynamics, as revealed in pump-probe experiments, arise from
a complex interplay of optical excitations of the M shell. Taking into account
the selection rules and conduction electron spin flips, this leads to highly
energy-dependent dynamics. These findings address longstanding discrepancies in
experimental TMOKE measurements and show that only through meticulous
consideration of matrix elements at the probe stage, can one ensure that
magnetization dynamics is revealed in its true nature, instead of being muddled
by artifacts arising from the choice of probe energy.",http://arxiv.org/abs/2501.05433v3
"Towards an Ontology of Traceable Impact Management in the Food Supply
  Chain",2025-01-08T16:53:25Z,"Bart Gajderowicz, Mark S Fox, Yongchao Gao","The pursuit of quality improvements and accountability in the food supply
chains, especially how they relate to food-related outcomes, such as hunger,
has become increasingly vital, necessitating a comprehensive approach that
encompasses product quality and its impact on various stakeholders and their
communities. Such an approach offers numerous benefits in increasing product
quality and eliminating superfluous measurements while appraising and
alleviating the broader societal and environmental repercussions. A traceable
impact management model (TIMM) provides an impact structure and a reporting
mechanism that identifies each stakeholder's role in the total impact of food
production and consumption stages.
  The model aims to increase traceability's utility in understanding the impact
of changes on communities affected by food production and consumption, aligning
with current and future government requirements, and addressing the needs of
communities and consumers. This holistic approach is further supported by an
ontological model that forms the logical foundation and a unified terminology.
By proposing a holistic and integrated solution across multiple stakeholders,
the model emphasizes quality and the extensive impact of championing
accountability, sustainability, and responsible practices with global
traceability.
  With these combined efforts, the food supply chain moves toward a global
tracking and tracing process that not only ensures product quality but also
addresses its impact on a broader scale, fostering accountability,
sustainability, and responsible food production and consumption.",http://arxiv.org/abs/2501.05486v1
X-ray Dips and Polarization Angle Swings in GX 13+1,2025-01-09T19:00:01Z,"Alessandro Di Marco, Fabio La Monaca, Anna Bobrikova, Luigi Stella, Alessandro Papitto, Juri Poutanen, Maria Cristina Baglio, Matteo Bachetti, Vladislav Loktev, Maura Pilia, Daniele Rogantini","We present the result from the April 2024 observation of the low-mass X-ray
binary GX 13+1 with the Imaging X-ray Polarimetry Explorer (IXPE), together
with NICER and Swift-XRT coordinated observations. Two light curve dips were
observed; during them, the harder Comptonized spectral component was dominant
and the polarization degree higher than in the softer, off-dip intervals.
Through a joint analysis of the three IXPE observations, which also included
the dip from the first observation, we demonstrate that the polarization
properties varied in response to the intensity and spectral hardness changes
associated with the dips. The polarization degree attained values up to ~4%.
The polarization angle showed a swing of ~70{\deg} across the dip and off-dip
states, comparable to the continuous rotation seen during the first IXPE
observation. We discuss these results in the context of models for polarized
emission from the accretion disk and the boundary/spreading layer on the
neutron star surface. We also draw attention to the role that an extended
accretion disk corona or disk wind can play in generating high polarization
degrees and, possibly, swings of the polarization angle.",http://arxiv.org/abs/2501.05511v2
"Off-resonant photoluminescence spectroscopy of high-optical quality
  single photon emitters in GaN",2025-01-09T19:36:34Z,"Nilesh Dalla, Paweł Kulboka, Michał Kobecki, Jan Misiak, Paweł Prystawko, Henryk Turski, Piotr Kossacki, Tomasz Jakubczyk","In this work, we analyze the relevance of excitation parameters on the
emission from single-photon emitting defect centers in GaN. We investigate the
absorption spectrum of different emitters by photoluminescence excitation
technique at 10\,K. We report large spectral jumps (shifts up to 22\,meV) in
the emitters' zero-phonon line (ZPL). The likelihood of such jumps is increased
by the change in excitation energy. The shifts indicate a large built-in dipole
moment of the defects and suggest a possibility to electrically tune their ZPL
in a wide range. From the photoluminescence excitation studies, we observe that
for majority of the emitters the absorption peaks exist between 2 and 2.55\,eV.
The absorption peaks vary from emitter to emitter, and no universal absorption
pattern is apparent. Finally, for selected emitters we observe significantly
reduced spectral diffusion and instrument-limited linewidth of $138\,\mu eV$
(0.04\,nm).These findings show a new perspective for atomic defect GaN emitters
as sources of coherent photons, shine new light on their energy level structure
and show the possibility of tuning the ZPL, paving the way to fully harness
their potential for applications in quantum technologies.",http://arxiv.org/abs/2501.05546v2
"LGL-BCI: A Motor-Imagery-Based Brain-Computer Interface with Geometric
  Learning",2025-01-09T21:51:45Z,"Jianchao Lu, Yuzhe Tian, Yang Zhang, Quan Z. Sheng, Xi Zheng","Brain--computer interfaces are groundbreaking technology whereby brain
signals are used to control external devices. Despite some advances in recent
years, electroencephalogram (EEG)-based motor-imagery tasks face challenges,
such as amplitude and phase variability and complex spatial correlations, with
a need for smaller models and faster inference. In this study, we develop a
prototype, called the Lightweight Geometric Learning Brain--Computer Interface
(LGL-BCI), which uses our customized geometric deep learning architecture for
swift model inference without sacrificing accuracy. LGL-BCI contains an EEG
channel selection module via a feature decomposition algorithm to reduce the
dimensionality of a symmetric positive definite matrix, providing adaptiveness
among the continuously changing EEG signal. Meanwhile, a built-in lossless
transformation helps boost the inference speed. The performance of our solution
was evaluated using two real-world EEG devices and two public EEG datasets.
LGL-BCI demonstrated significant improvements, achieving an accuracy of 82.54%
compared to 62.22% for the state-of-the-art approach. Furthermore, LGL-BCI uses
fewer parameters (64.9K vs. 183.7K), highlighting its computational efficiency.
These findings underscore both the superior accuracy and computational
efficiency of LGL-BCI, demonstrating the feasibility and robustness of
geometric deep learning in motor-imagery brain--computer interface
applications.",http://arxiv.org/abs/2501.05589v1
"Tailored Thin Films: Modulating Soft Photonics with Dynamically Tunable
  Large Area Microstructures via Controlled Thermal Processing",2025-01-10T06:04:49Z,"Srijeeta Biswas, Renu Raman Sahu, Omkar Deokinandan Nayak Shinkre, Shubham Meena, Ramnishanth, Mark Vailshery, Tapajyoti Das Gupta","Self-assembled nano and micro-structures, particularly those capable of
responsive erasure and regeneration, have garnered significant interest for
their applications in smart photonics and electronics. However, current
techniques for modulating these architectures largely depend on network
rearrangement, posing challenges for in situ regeneration. Furthermore, their
common fabrication techniques are complex and uncontrolled with the structures
formed not being amenable for large area applications, thus compromising their
economic viability. Herein, we present a controlled thermal process strategy
for fabricating large-area, dynamically tunable, 1D,2D and 3D micro and
nanostructures on a wide range of compatible materials including metals,
semiconductors and polymers. By tuning the temperature changes in the system,
thermal expansion coefficients of thin films and substrates, surface energy,
Youngs modulus and thickness of the thin films we achieve robust, uniform,
periodic structures over extensive areas on soft and stretchable substrates.
The process is further supported by a theoretical model that we developed and
validated by experiments and simulations. To showcase the robustness of our
approach, we present prototypes of dynamically tunable diffraction gratings,
optical diffusers, large-area reflective displays, camouflage devices,
out-coupling efficiency enhancers, wearable devices and mechanochromic sensors.",http://arxiv.org/abs/2501.05736v2
"Magnetism based on nitrate-nitrate interactions: The cases of LiNO$_3$,
  K$_{0.5}$Rb$_{0.5}$NO$_3$, Ca(NO$_3$)$_2$ and C(NH$_2$)$_3$NO$_3$",2025-01-10T07:11:12Z,"Na Du, Xintian Wang, Ruo Tong Wang, Enting Xu, Yu Ying Zhu, Yan Zhao, Peng Ren, Fei Yen","Long-range magnetic ordering of the orbital motion of oxygen atoms within
NO$_3$$^-$ cations is identified from experimental measurements of the magnetic
susceptibility $\chi$($T$) in LiNO$_3$, Ca(NO$_3$)$_2$,
K$_{0.5}$Rb$_{0.5}$NO$_3$ and C(NH$_2$)$_3$NO$_3$ at their respective
order-disorder, solid-solid phase transitions $T$$_N$. The observed sharp
changes in $\chi$($T$) and accompanying hysteretic behavior indicate the phase
transitions to be first order. A model employing the law of conservation of
angular momentum is used to explain why the librations between neighboring
NO$_3$$^-$ become geared below $T$$_N$. Since the periodic motions involve
concerted motion of net charges, the associated magnetic moments of the
NO$_3$$^-$ ions indirectly establish an antiferromagnetic structure below
$T$$_N$. Our findings identify a previously unidentified type of molecular
interaction which may be exploited to further increase the enthalpy of the
widely-popular hydrated salts employed as energy storage devices.",http://arxiv.org/abs/2501.05754v1
"TakuNet: an Energy-Efficient CNN for Real-Time Inference on Embedded UAV
  systems in Emergency Response Scenarios",2025-01-10T11:32:56Z,"Daniel Rossi, Guido Borghi, Roberto Vezzani","Designing efficient neural networks for embedded devices is a critical
challenge, particularly in applications requiring real-time performance, such
as aerial imaging with drones and UAVs for emergency responses. In this work,
we introduce TakuNet, a novel light-weight architecture which employs
techniques such as depth-wise convolutions and an early downsampling stem to
reduce computational complexity while maintaining high accuracy. It leverages
dense connections for fast convergence during training and uses 16-bit
floating-point precision for optimization on embedded hardware accelerators.
Experimental evaluation on two public datasets shows that TakuNet achieves
near-state-of-the-art accuracy in classifying aerial images of emergency
situations, despite its minimal parameter count. Real-world tests on embedded
devices, namely Jetson Orin Nano and Raspberry Pi, confirm TakuNet's
efficiency, achieving more than 650 fps on the 15W Jetson board, making it
suitable for real-time AI processing on resource-constrained platforms and
advancing the applicability of drones in emergency scenarios. The code and
implementation details are publicly released.",http://arxiv.org/abs/2501.05880v2
"Characterisation of H$β$ spectra from EXO 051910+3737.7 X-rays
  binaries",2025-01-10T11:34:33Z,"Pornisara Nuchvanichakul, Puji Irawati, Pakakaew Rittipruk, Poshak Gandhi, Christian Knigge, Phil Charles, Suwicha Wannawichian","We investigate the spectral characteristics of the Be/X-ray binary system,
EXO 051910+3737.7, in which Be/X-ray systems are the largest sub-class of
high-mass X-ray binaries. Spectroscopic observations are taken by the Thai
National Telescope (TNT) with a Medium-RESolution spectrograph (MRES)
instrument for seven nights spanning from 2020 to 2021. Our primary focus is
directed towards the analysis of two Balmer lines, namely H$\alpha$ and
H$\beta$, given that Be stars typically exhibit emission features in at least
one of these hydrogen Balmer lines during certain phases. Our observations
reveal split Balmer emission lines throughout the entire duration of our
monitoring. Double Gaussian profiles were employed for line fitting to
characterize these lines. The presence of double peaks in the Balmer lines
indicates the presence of asymmetries within the circumstellar disc. We then
analyze V/R variations and the changes in H$\beta$ spectra. Our analysis of V/R
variation which Violet (V) and Red (R) peak intensity components, revealed
rapid fluctuations occurring within a single day, although determining the
precise periodicity was constrained by instrumental limitations and the
duration of observability. Furthermore, employing observed the wavelength
differences ($\Delta\lambda$) in conjunction with typical Be star parameters
allowed us to estimate the radius ($r_{\beta}$) of the H$\beta$ emitting
envelope. The average value was calculated to be 2.585$r_*$, with a standard
deviation of 0.050$r_*$.",http://arxiv.org/abs/2501.05883v1
Towards Backdoor Stealthiness in Model Parameter Space,2025-01-10T12:49:12Z,"Xiaoyun Xu, Zhuoran Liu, Stefanos Koffas, Stjepan Picek","Recent research on backdoor stealthiness focuses mainly on indistinguishable
triggers in input space and inseparable backdoor representations in feature
space, aiming to circumvent backdoor defenses that examine these respective
spaces. However, existing backdoor attacks are typically designed to resist a
specific type of backdoor defense without considering the diverse range of
defense mechanisms. Based on this observation, we pose a natural question: Are
current backdoor attacks truly a real-world threat when facing diverse
practical defenses?
  To answer this question, we examine 12 common backdoor attacks that focus on
input-space or feature-space stealthiness and 17 diverse representative
defenses. Surprisingly, we reveal a critical blind spot: Backdoor attacks
designed to be stealthy in input and feature spaces can be mitigated by
examining backdoored models in parameter space. To investigate the underlying
causes behind this common vulnerability, we study the characteristics of
backdoor attacks in the parameter space. Notably, we find that input- and
feature-space attacks introduce prominent backdoor-related neurons in parameter
space, which are not thoroughly considered by current backdoor attacks. Taking
comprehensive stealthiness into account, we propose a novel supply-chain attack
called Grond. Grond limits the parameter changes by a simple yet effective
module, Adversarial Backdoor Injection (ABI), which adaptively increases the
parameter-space stealthiness during the backdoor injection. Extensive
experiments demonstrate that Grond outperforms all 12 backdoor attacks against
state-of-the-art (including adaptive) defenses on CIFAR-10, GTSRB, and a subset
of ImageNet. In addition, we show that ABI consistently improves the
effectiveness of common backdoor attacks.",http://arxiv.org/abs/2501.05928v1
CamCtrl3D: Single-Image Scene Exploration with Precise 3D Camera Control,2025-01-10T14:37:32Z,"Stefan Popov, Amit Raj, Michael Krainin, Yuanzhen Li, William T. Freeman, Michael Rubinstein","We propose a method for generating fly-through videos of a scene, from a
single image and a given camera trajectory. We build upon an image-to-video
latent diffusion model. We condition its UNet denoiser on the camera
trajectory, using four techniques. (1) We condition the UNet's temporal blocks
on raw camera extrinsics, similar to MotionCtrl. (2) We use images containing
camera rays and directions, similar to CameraCtrl. (3) We reproject the initial
image to subsequent frames and use the resulting video as a condition. (4) We
use 2D<=>3D transformers to introduce a global 3D representation, which
implicitly conditions on the camera poses. We combine all conditions in a
ContolNet-style architecture. We then propose a metric that evaluates overall
video quality and the ability to preserve details with view changes, which we
use to analyze the trade-offs of individual and combined conditions. Finally,
we identify an optimal combination of conditions. We calibrate camera positions
in our datasets for scale consistency across scenes, and we train our scene
exploration model, CamCtrl3D, demonstrating state-of-theart results.",http://arxiv.org/abs/2501.06006v2
SECRET: Stochasticity Emulator for Cosmic Ray Electrons,2025-01-10T14:48:22Z,"Nikolas Frediani, Michael Krämer, Philipp Mertsch, Kathrin Nippel","The spectrum of cosmic-ray electrons depends sensitively on the history and
spatial distribution of nearby sources. Given our limited observational handle
on cosmic-ray sources, any model remains necessarily probabilistic. Previously,
predictions were performed in a Monte Carlo fashion, summing the contributions
from individual, simulated sources to generate samples from the statistical
ensemble of possible electron spectra. Such simulations need to be re-run if
the cosmic-ray transport parameters (e.g. diffusion coefficient, maximum
energy) are changed, rendering any parameter study computationally expensive.
In addition, a proper statistical analysis of observations and comparison with
such probabilistic models requires the joint probability distribution of the
full spectrum instead of only samples. Note that parametrising this joint
distribution is rendered difficult by the non-Gaussian statistics of the
cosmic-ray fluxes. Here, we employ machine learning to compute the joint
probability distribution of cosmic-ray electron fluxes. Specifically, we employ
masked autoregressive density estimation (MADE) for a representation of the
high-dimensional joint probability distribution. In a first step, we train the
network on a Monte Carlo simulation for a fixed set of transport parameters,
thus significantly accelerating the generation of samples. In a second step, we
extend this setup to SECRET (Stochasticity Emulator for Cosmic Ray Electrons),
allowing to reliably interpolate over the space of transport parameters. We
make the MADE and SECRET codes available at
https://git.rwth-aachen.de/pmertsch/secret .",http://arxiv.org/abs/2501.06011v1
"Timing and spectral studies of the Be/X-ray binary EXO 2030+375 using
  Insight-HXMT observations",2025-01-10T14:49:43Z,"Yu-Jia Du, Lorenzo Ducci, Long Ji, Qing-Cui Bu, Ling-Da Kong, Peng-Ju Wang, Youli Tuo, Andrea Santangelo","We report the X-ray spectral and timing analysis of the high mass X-ray
binary EXO 2030+375 during the 2021 type-II outburst based on the Insight-HXMT
observations. Pulsations can be detected in the energy band of 1-150 keV. The
pulse profile shows energy and luminosity dependence and variability. We
observed transitions in the pulse profile shape during the rising and the
decaying phase of the outburst. The pulse fraction exhibits an anti-correlation
with luminosity and a non-monotonic energy dependence, with a possible dip near
30 keV during the outburst peak. The hardness-intensity diagrams (7-10 keV/4-7
keV) suggest state transitions during the early and late phases of the
outburst. These transitions are consistent with the luminosity at which the
pulse profile shape changes occur, revealing the source reaching the critical
luminosity and transitioning between super-critical and sub-critical accretion
regimes. We performed the average and phase-resolved spectral analysis, where
the flux-resolved average spectra show a stable spectral evolution with
luminosity. The phase-resolved spectral analysis reveals that the dependence of
spectral parameters on the pulse phase varies with different luminosities.",http://arxiv.org/abs/2501.06013v1
"Variation of the low-mass end of the stellar initial mass function with
  redshift and metallicity",2025-01-10T16:16:42Z,Matthew R. Bate,"We report the stellar mass functions obtained from 20 radiation
hydrodynamical simulations of star cluster formation in 500 M$_\odot$ molecular
clouds with metallicities of 3, 1, 1/10 and 1/100 of the solar value, with the
clouds subjected to levels of the cosmic microwave background radiation that
are appropriate for star formation at redshifts z=0, 3, 5, 7, and 10. The
calculations include a thermochemical model of the diffuse interstellar medium
and treat dust and gas temperatures separately. We find that the stellar mass
distributions obtained become increasingly bottom light as the redshift and/or
metallicity are increased. Mass functions that are similar to a typical
Galactic initial mass function are obtained for present-day star formation
(z=0) independent of metallicity, and also for the lowest-metallicity (1/100
solar) at all redshifts up to z=10, but for higher metallicities there is a
larger deficit of brown dwarfs and low-mass stars as the metallicity and
redshift are increased. These effects are a result of metal-rich gas being
unable to cool to as lower temperatures at higher redshift due to the warmer
cosmic microwave background radiation. Based on the numerical results we
provide a parameterisation that may be used to vary the stellar initial mass
function with redshift and metallicity; this could be used in simulations of
galaxy formation. For example, a bottom-light mass function reduces the
mass-to-light ratio compared to a typical Galactic stellar initial mass
function, which may reduce the estimated masses of high-redshift galaxies.",http://arxiv.org/abs/2501.06082v2
"Detection, Retrieval, and Explanation Unified: A Violence Detection
  System Based on Knowledge Graphs and GAT",2025-01-07T09:21:20Z,"Wen-Dong Jiang, Chih-Yung Chang, Diptendu Sinha Roy","Recently, violence detection systems developed using unified multimodal
models have achieved significant success and attracted widespread attention.
However, most of these systems face two critical challenges: the lack of
interpretability as black-box models and limited functionality, offering only
classification or retrieval capabilities. To address these challenges, this
paper proposes a novel interpretable violence detection system, termed the
Three-in-One (TIO) System. The TIO system integrates knowledge graphs (KG) and
graph attention networks (GAT) to provide three core functionalities:
detection, retrieval, and explanation. Specifically, the system processes each
video frame along with text descriptions generated by a large language model
(LLM) for videos containing potential violent behavior. It employs ImageBind to
generate high-dimensional embeddings for constructing a knowledge graph, uses
GAT for reasoning, and applies lightweight time series modules to extract video
embedding features. The final step connects a classifier and retriever for
multi-functional outputs. The interpretability of KG enables the system to
verify the reasoning process behind each output. Additionally, the paper
introduces several lightweight methods to reduce the resource consumption of
the TIO system and enhance its efficiency. Extensive experiments conducted on
the XD-Violence and UCF-Crime datasets validate the effectiveness of the
proposed system. A case study further reveals an intriguing phenomenon: as the
number of bystanders increases, the occurrence of violent behavior tends to
decrease.",http://arxiv.org/abs/2501.06224v3
The Convergence of Dynamic Routing between Capsules,2025-01-08T13:26:56Z,"Daoyuan Ye, Juntao Li, Yiting Shen","Capsule networks(CapsNet) are recently proposed neural network models with
new processing layers, specifically for entity representation and discovery of
images. It is well known that CapsNet have some advantages over traditional
neural networks, especially in generalization capability. At the same time,
some studies report negative experimental results. The causes of this
contradiction have not been thoroughly analyzed. The preliminary experimental
results show that the behavior of routing algorithms does not always produce
good results as expected, and in most cases, different routing algorithms do
not change the classification results, but simply polarize the link strength,
especially when they continue to repeat without stopping. To realize the true
potential of the CapsNet, deep mathematical analysis of the routing algorithms
is crucial. In this paper, we will give the objective function that is
minimized by the dynamic routing algorithm, which is a concave function. The
dynamic routing algorithm can be regarded as nonlinear gradient method to
solving an optimization algorithm under linear constraints, and its convergence
can be strictly proved mathematically. Furthermore, the mathematically rigorous
proof of the convergence is given for this class of iterative routing
procedures. We analyze the relation between the objective function and the
constraints solved by the dynamic routing algorithm in detail, and perform the
corresponding routing experiment to analyze the effect of our convergence
proof.",http://arxiv.org/abs/2501.06240v1
"Monolayer-Defined Flat Colloidal PbSe Quantum Dots in Extreme
  Confinement",2025-01-10T20:51:38Z,"Leon Biesterfeld, Huu Thoai Ngo, Ahmed Addad, Wolfgang Leis, Michael Seitz, Gang Ji, Bruno Grandidier, Christophe Delerue, Jannika Lauth, Louis Biadala","Colloidal two-dimensional lead chalcogenide nanocrystals represent an
intriguing new class of materials that push the boundaries of quantum
confinement by combining a crystal thickness down to the monolayer with
confinement in the lateral dimension. In particular flat PbSe quantum dots
exhibit efficient telecommunication band-friendly photoluminescence (1.43 -
0.83 eV with up to 61% quantum yield) that is highly interesting for
fiber-optics information processing. By using cryogenic scanning tunneling
microscopy and spectroscopy, we probe distinct single layer-defined PbSe
quantum dot populations down to a monolayer with in-gap state free quantum
dot-like density of states, in agreement with theoretical tight binding
calculations. Cryogenic ensemble photoluminescence spectra reveal mono-, bi-,
and trilayer contribution, confirming the structural, electronic and
theoretical results. From larger timescale shifts and ratio changes in the
optical spectra we infer Ostwald ripening in solution and fusing in deposited
samples of thinner flat PbSe quantum dots, which can be slowed down by surface
passivation with PbI2. By uncovering the interplay between thickness, lateral
size and density of states, as well as the synthetic conditions and
post-synthetic handling, our findings enable the target-oriented synthesis of
two-dimensional PbSe quantum dots with precisely tailored optical properties at
telecom wavelengths.",http://arxiv.org/abs/2501.06341v1
A Predicted Great Dimming of T Tauri: Has it Begun?,2025-01-10T22:57:48Z,Tracy L. Beck,"The optical star in the T Tauri triple system is the prototype of young
sun-like stars in our galaxy. This complex and dynamic system has evidence for
misaligned disks and outflows, and molecular material in a circumbinary ring
that obscures the southern infrared binary, T Tau South. Observations by
members of the American Association of Variable Star Observers (AAVSO) show
that T Tau North, the optical star, has dimmed by up to ~2 magnitudes in the
visual over the course of the past decade. The dimming across the B, V, R and I
bands has a color character typical of changes in ISM extinction, suggesting an
increase in obscuration along the line of sight to T Tau North. Material
associated with the circumbinary ring around T Tau South has been predicted to
occult the optical star via wide-scale orbital motion of the system. Through
analysis of the geometrical configuration and motion of dust structures in the
system, it seems that a great dimming of T Tau North by line-of-sight material
associated with the T Tau South binary has, in fact, begun. Based on the extent
and motion of the circumbinary ring material associated with the southern
binary, T Tau North will likely experience dimming events for decades to come
and may disappear entirely from the optical sky as the densest mid-plane region
of the ring traverses our line of sight.",http://arxiv.org/abs/2501.06378v1
Influencing Humans to Conform to Preference Models for RLHF,2025-01-11T03:12:53Z,"Stephane Hatgis-Kessell, W. Bradley Knox, Serena Booth, Scott Niekum, Peter Stone","Designing a reinforcement learning from human feedback (RLHF) algorithm to
approximate a human's unobservable reward function requires assuming,
implicitly or explicitly, a model of human preferences. A preference model that
poorly describes how humans generate preferences risks learning a poor
approximation of the human's reward function. In this paper, we conduct three
human studies to asses whether one can influence the expression of real human
preferences to more closely conform to a desired preference model. Importantly,
our approach does not seek to alter the human's unobserved reward function.
Rather, we change how humans use this reward function to generate preferences,
such that they better match whatever preference model is assumed by a
particular RLHF algorithm. We introduce three interventions: showing humans the
quantities that underlie a preference model, which is normally unobservable
information derived from the reward function; training people to follow a
specific preference model; and modifying the preference elicitation question.
All intervention types show significant effects, providing practical tools to
improve preference data quality and the resultant alignment of the learned
reward functions. Overall we establish a novel research direction in model
alignment: designing interfaces and training interventions to increase human
conformance with the modeling assumptions of the algorithm that will learn from
their input.",http://arxiv.org/abs/2501.06416v2
"Optimizing digital experiences with content delivery networks:
  Architectures, performance strategies, and future trends",2025-01-11T03:47:04Z,Anuj Tyagi,"This research investigates how CDNs (Content Delivery Networks) can improve
the digital experience, as consumers increasingly expect fast, efficient, and
effortless access to online resources. CDNs play a crucial role in reducing
latency, enhancing scalability, and optimizing delivery mechanisms, which is
evident across various platforms and regions. The study focuses on key CDN
concerns, such as foundational and modern CDN architectures, edge computing,
hybrid CDNs, and multi-CDN strategies. It also explores performance-enhancing
topics, including caching, load balancing, and the novel features of HTTP/3 and
QUIC.
  Current trends, such as integrating CDNs with 5G networks, serverless
architectures, and AI-driven traffic management, are examined to demonstrate
how CDN technology is likely to evolve. The study also addresses challenges
related to security, cost, and global regulations. Practical examples from the
e-commerce, streaming, and gaming industries highlight how enhanced CDNs are
transforming these sectors.
  The conclusions emphasize the need to evolve CDN strategies to meet growing
user expectations and adapt to the rapidly changing digital landscape.
Additionally, the research identifies future research opportunities,
particularly in exploring the impact of QC, the enhancement of AI services, and
the sustainability of CDN solutions. Overall, the study situates architectural
design, performance strategies, and emerging trends to address gaps and create
a more efficient and secure approach for improving digital experiences.",http://arxiv.org/abs/2501.06428v1
"Not real or too soft? On the challenges of publishing interdisciplinary
  software engineering research",2025-01-11T12:18:46Z,"Sonja M. Hyrynsalmi, Grischa Liebel, Ronnie de Souza Santos, Sebastian Baltes","The discipline of software engineering (SE) combines social and technological
dimensions. It is an interdisciplinary research field. However,
interdisciplinary research submitted to software engineering venues may not
receive the same level of recognition as more traditional or technical topics
such as software testing. For this paper, we conducted an online survey of 73
SE researchers and used a mixed-method data analysis approach to investigate
their challenges and recommendations when publishing interdisciplinary research
in SE. We found that the challenges of publishing interdisciplinary research in
SE can be divided into topic-related and reviewing-related challenges.
Furthermore, while our initial focus was on publishing interdisciplinary
research, the impact of current reviewing practices on marginalized groups
emerged from our data, as we found that marginalized groups are more likely to
receive negative feedback. In addition, we found that experienced researchers
are less likely to change their research direction due to feedback they
receive. To address the identified challenges, our participants emphasize the
importance of highlighting the impact and value of interdisciplinary work for
SE, collaborating with experienced researchers, and establishing clearer
submission guidelines and new interdisciplinary SE publication venues. Our
findings contribute to the understanding of the current state of the SE
research community and how we could better support interdisciplinary research
in our field.",http://arxiv.org/abs/2501.06523v1
Origin likelihood functions for extreme-energy cosmic rays,2025-01-12T00:47:40Z,Leonel Morejon,"Unlike neutrinos and photons arriving from extra-galactic sources, ultra-high
energy cosmic rays (UHECRs) do not trace back to their origins due to
propagation effects such as magnetic deflections and energy losses. For ankle
energies, UHECRs can propagate for hundreds of megaparsecs with negligible
energy losses but the directional information is lost after a few megaparsecs.
On the other hand, at the highest energies the directions are kept for larger
distances due to the increased rigidity but the interaction rates with the
cosmic microwave background strongly suppress the cosmic rays within a few to
tens of megaparsecs. Therefore, UHECRs with energies $E > 10^{20}$ eV
(extreme-energy cosmic rays (ExECRs)) such as the Amaterasu event recently
reported by Telescope Array, are of particular interest to identify the sources
within our galactic neighborhood. However, photonuclear interactions are
stochastic in nature and produce changes in the nuclear species emitted, which
makes it difficult the task of estimating the likelihood distribution of its
origin. This work discusses a novel procedure to estimate the likelihood of the
origin for extreme-energy cosmic rays based on probability distributions for
UHECR stochastic interactions. The method is applied to the Amaterasu event and
compared to recently published works which employ Monte Carlo codes (e.g.
CRPropa) in their analysis. The advantages of the method presented here are
demonstrated by the increased resolution and the ease of computation unlike
other approaches employed so far. The results presented indicate that the
localization of the origin of extreme energy cosmic rays could be possible in
some cases without knowledge of the original composition.",http://arxiv.org/abs/2501.06677v1
"Precise measurement of CP violating $τ$ EDM through $e^+ e^- \to
  γ^*, ψ(2s) \to τ^+ τ^-$",2025-01-12T02:35:20Z,"Xiao-Gang He, Chia-Wei Liu, Jian-Ping Ma, Chang Yang, Zi-Yue Zou","A nonzero electric dipole moment of a tauon, $d_\tau$, signals CP violation
and provides an important probe for new physics. We study methods to measure
$d_\tau$ at low energy $e^+ e^-$ colliders through the processes $e^+e^- \to
\gamma^*, \psi(2S) \to \tau^+\tau^-$ with $\tau^\pm$ decays into a charged
hadron and a tau neutrino. We point out that, with measuring energies of the
charged hadron, Im$(d_\tau)$ can be measured. On the other hand, selecting
events of $\tau$ decays after traveling more than the detector resolution
distance, Re$(d_\tau)$ can also be determined. We find that the precision at
Super Tau-Charm Facility (STCF) running at the center energy of $m_{\psi (2S)}$
for 10 year data accumulation, the precision of Im$(d_\tau)$ and Re$(d_\tau)$
are found to be 3.5 and 11 in unit of $10^{-18}~e\,\text{cm}$, respectively.
The sensitivity for $d_\tau$ measurement precision at the STCF can be reached
its optimum at a central energy of $6.3~\text{GeV}$, achieving a precision of
$1.3$ for Im$(d_\tau)$ and $2.9$ for Re$(d_\tau)$ in unit of $
10^{-18}~e\,\text{cm}$.",http://arxiv.org/abs/2501.06687v1
"Impact of Coulomb Correction Factor on Rate of Change of Lepton Fraction
  during Presupernova Evolution",2025-01-12T07:55:31Z,"Asim Ullah, Jameel-Un Nabi","We reexamine the weak interaction nuclei having largest contribution to the
lepton to baryon fraction Ye by coupling the stellar weak rates and mass
abundances for post silicon burning conditions during the presupernova
evolution of massive stars. The stellar weak rates were recently calculated by
Nabi et al. 2021 employing the fully microscopic pnQRPA model without invoking
the Brink Axel hypothesis. We compute the mass abundances for a total of 728
nuclei, with A equal 1to 100, using Sahas equation and assuming nuclear
statistical equilibrium with the incorporation of Coulomb correction factor to
the chemical potential. We compile a list of top 50 electron capture ec and
\b{eta} decay bd nuclei on the basis of largest contribution to Ye forpost
silicon burning conditions where 11 percent ec and 6percent bd nuclei debuted
dueto Coulomb corrections. The calculated mass abundances and corresponding Ye
values are enhanced up to 3 orders of magnitude for heavier nuclei once Coulomb
corrections were incorporated. This enhancement led to anincrement in total Y
bde and Yece values, at Ye equal to 0.425 (\r{ho} equal 2.20 multiply 109 g/cm3
of 80percent and 91percent respectively. After incorporating the Coulomb
corrections we propose a revised interval of Ye equal 0.423 0.455 where bd
rates surpass thecompeting ec rates and is 3.2 percent bigger than the one
suggested by Nabi et al. (2021).",http://arxiv.org/abs/2501.06742v1
"Improving the adaptive and continuous learning capabilities of
  artificial neural networks: Lessons from multi-neuromodulatory dynamics",2025-01-12T10:10:01Z,"Jie Mei, Alejandro Rodriguez-Garcia, Daigo Takeuchi, Gabriel Wainstein, Nina Hubig, Yalda Mohsenzadeh, Srikanth Ramaswamy","Continuous, adaptive learning-the ability to adapt to the environment and
improve performance-is a hallmark of both natural and artificial intelligence.
Biological organisms excel in acquiring, transferring, and retaining knowledge
while adapting to dynamic environments, making them a rich source of
inspiration for artificial neural networks (ANNs). This study explores how
neuromodulation, a fundamental feature of biological learning systems, can help
address challenges such as catastrophic forgetting and enhance the robustness
of ANNs in continuous learning scenarios. Driven by neuromodulators including
dopamine (DA), acetylcholine (ACh), serotonin (5-HT) and noradrenaline (NA),
neuromodulatory processes in the brain operate at multiple scales, facilitating
dynamic responses to environmental changes through mechanisms ranging from
local synaptic plasticity to global network-wide adaptability. Importantly, the
relationship between neuromodulators, and their interplay in the modulation of
sensory and cognitive processes are more complex than expected, demonstrating a
""many-to-one"" neuromodulator-to-task mapping. To inspire the design of novel
neuromodulation-aware learning rules, we highlight (i) how
multi-neuromodulatory interactions enrich single-neuromodulator-driven
learning, (ii) the impact of neuromodulators at multiple spatial and temporal
scales, and correspondingly, (iii) strategies to integrate neuromodulated
learning into or approximate it in ANNs. To illustrate these principles, we
present a case study to demonstrate how neuromodulation-inspired mechanisms,
such as DA-driven reward processing and NA-based cognitive flexibility, can
enhance ANN performance in a Go/No-Go task. By integrating multi-scale
neuromodulation, we aim to bridge the gap between biological learning and
artificial systems, paving the way for ANNs with greater flexibility,
robustness, and adaptability.",http://arxiv.org/abs/2501.06762v1
"SuperNeRF-GAN: A Universal 3D-Consistent Super-Resolution Framework for
  Efficient and Enhanced 3D-Aware Image Synthesis",2025-01-12T10:31:33Z,"Peng Zheng, Linzhi Huang, Yizhou Yu, Yi Chang, Yilin Wang, Rui Ma","Neural volume rendering techniques, such as NeRF, have revolutionized
3D-aware image synthesis by enabling the generation of images of a single scene
or object from various camera poses. However, the high computational cost of
NeRF presents challenges for synthesizing high-resolution (HR) images. Most
existing methods address this issue by leveraging 2D super-resolution, which
compromise 3D-consistency. Other methods propose radiance manifolds or
two-stage generation to achieve 3D-consistent HR synthesis, yet they are
limited to specific synthesis tasks, reducing their universality. To tackle
these challenges, we propose SuperNeRF-GAN, a universal framework for
3D-consistent super-resolution. A key highlight of SuperNeRF-GAN is its
seamless integration with NeRF-based 3D-aware image synthesis methods and it
can simultaneously enhance the resolution of generated images while preserving
3D-consistency and reducing computational cost. Specifically, given a
pre-trained generator capable of producing a NeRF representation such as
tri-plane, we first perform volume rendering to obtain a low-resolution image
with corresponding depth and normal map. Then, we employ a NeRF
Super-Resolution module which learns a network to obtain a high-resolution
NeRF. Next, we propose a novel Depth-Guided Rendering process which contains
three simple yet effective steps, including the construction of a
boundary-correct multi-depth map through depth aggregation, a normal-guided
depth super-resolution and a depth-guided NeRF rendering. Experimental results
demonstrate the superior efficiency, 3D-consistency, and quality of our
approach. Additionally, ablation studies confirm the effectiveness of our
proposed components.",http://arxiv.org/abs/2501.06770v2
"Improved joint modelling of breast cancer radiomics features and hazard
  by image registration aided longitudinal CT data",2025-01-12T14:07:30Z,Subrata Mukherjee,"Patients with metastatic breast cancer (mBC) undergo continuous medical
imaging during treatment, making accurate lesion detection and monitoring over
time critical for clinical decisions. Predicting drug response from
post-treatment data is essential for personalized care and pharmacological
research. In collaboration with the U.S. Food and Drug Administration and
Novartis Pharmaceuticals, we analyzed serial chest CT scans from two
large-scale Phase III trials, MONALEESA 3 and MONALEESA 7. This paper has two
objectives (a) Data Structuring developing a Registration Aided Automated
Correspondence (RAMAC) algorithm for precise lesion tracking in longitudinal CT
data, and (b) Survival Analysis creating imaging features and models from RAMAC
structured data to predict patient outcomes. The RAMAC algorithm uses a two
phase pipeline: three dimensional rigid registration aligns CT images, and a
distance metric-based Hungarian algorithm tracks lesion correspondence. Using
structured data, we developed interpretable models to assess progression-free
survival (PFS) in mBC patients by combining baseline radiomics, post-treatment
changes (Weeks 8, 16, 24), and demographic features. Radiomics effects were
studied across time points separately and through a non-correlated additive
framework. Radiomics features were reduced using (a) a regularized
(L1-penalized) additive Cox proportional hazards model, and (b) variable
selection via best subset selection. Performance, measured using the
concordance index (C-index), improved with additional time points. Joint
modeling, considering correlations among radiomics effects over time, provided
insights into relationships between longitudinal radiomics and survival
outcomes.",http://arxiv.org/abs/2501.06814v2
"Towards Counterfactual and Contrastive Explainability and Transparency
  of DCNN Image Classifiers",2025-01-12T14:54:02Z,"Syed Ali Tariq, Tehseen Zia, Mubeen Ghafoor","Explainability of deep convolutional neural networks (DCNNs) is an important
research topic that tries to uncover the reasons behind a DCNN model's
decisions and improve their understanding and reliability in high-risk
environments. In this regard, we propose a novel method for generating
interpretable counterfactual and contrastive explanations for DCNN models. The
proposed method is model intrusive that probes the internal workings of a DCNN
instead of altering the input image to generate explanations. Given an input
image, we provide contrastive explanations by identifying the most important
filters in the DCNN representing features and concepts that separate the
model's decision between classifying the image to the original inferred class
or some other specified alter class. On the other hand, we provide
counterfactual explanations by specifying the minimal changes necessary in such
filters so that a contrastive output is obtained.
  Using these identified filters and concepts, our method can provide
contrastive and counterfactual reasons behind a model's decisions and makes the
model more transparent. One of the interesting applications of this method is
misclassification analysis, where we compare the identified concepts from a
particular input image and compare them with class-specific concepts to
establish the validity of the model's decisions. The proposed method is
compared with state-of-the-art and evaluated on the Caltech-UCSD Birds (CUB)
2011 dataset to show the usefulness of the explanations provided.",http://arxiv.org/abs/2501.06831v1
"A novel multi-agent dynamic portfolio optimization learning system based
  on hierarchical deep reinforcement learning",2025-01-12T15:00:02Z,"Ruoyu Sun, Yue Xi, Angelos Stefanidis, Zhengyong Jiang, Jionglong Su","Deep Reinforcement Learning (DRL) has been extensively used to address
portfolio optimization problems. The DRL agents acquire knowledge and make
decisions through unsupervised interactions with their environment without
requiring explicit knowledge of the joint dynamics of portfolio assets. Among
these DRL algorithms, the combination of actor-critic algorithms and deep
function approximators is the most widely used DRL algorithm. Here, we find
that training the DRL agent using the actor-critic algorithm and deep function
approximators may lead to scenarios where the improvement in the DRL agent's
risk-adjusted profitability is not significant. We propose that such situations
primarily arise from the following two problems: sparsity in positive reward
and the curse of dimensionality. These limitations prevent DRL agents from
comprehensively learning asset price change patterns in the training
environment. As a result, the DRL agents cannot explore the dynamic portfolio
optimization policy to improve the risk-adjusted profitability in the training
process. To address these problems, we propose a novel multi-agent Hierarchical
Deep Reinforcement Learning (HDRL) algorithmic framework in this research.
Under this framework, the agents work together as a learning system for
portfolio optimization. Specifically, by designing an auxiliary agent that
works together with the executive agent for optimal policy exploration, the
learning system can focus on exploring the policy with higher risk-adjusted
return in the action space with positive return and low variance. In this way,
we can overcome the issue of the curse of dimensionality and improve the
training efficiency in the positive reward sparse environment.",http://arxiv.org/abs/2501.06832v1
Integrators at War: Mediating in AI-assisted Resort-to-Force Decisions,2025-01-12T16:21:33Z,"Dennis Müller, Maurice Chiodo, Mitja Sienknecht","The integration of AI systems into the military domain is changing the way
war-related decisions are made. It binds together three disparate groups of
actors - developers, integrators, users - and creates a relationship between
these groups and the machine, embedded in the (pre-)existing organisational and
system structures. In this article, we focus on the important, but often
neglected, group of integrators within such a sociotechnical system. In complex
human-machine configurations, integrators carry responsibility for linking the
disparate groups of developers and users in the political and military system.
To act as the mediating group requires a deep understanding of the other
groups' activities, perspectives and norms. We thus ask which challenges and
shortcomings emerge from integrating AI systems into resort-to-force (RTF)
decision-making processes, and how to address them. To answer this, we proceed
in three steps. First, we conceptualise the relationship between different
groups of actors and AI systems as a sociotechnical system. Second, we identify
challenges within such systems for human-machine teaming in RTF decisions. We
focus on challenges that arise a) from the technology itself, b) from the
integrators' role in the sociotechnical system, c) from the human-machine
interaction. Third, we provide policy recommendations to address these
shortcomings when integrating AI systems into RTF decision-making structures.",http://arxiv.org/abs/2501.06861v1
A Flux-Tunable cavity for Dark matter detection,2025-01-12T17:30:51Z,"Fang Zhao, Ziqian Li, Akash V. Dixit, Tanay Roy, Andrei Vrajitoarea, Riju Banerjee, Alexander Anferov, Kan-Heng Lee, David I. Schuster, Aaron Chou","Developing a dark matter detector with wide mass tunability is an immensely
desirable property, yet it is challenging due to maintaining strong
sensitivity. Resonant cavities for dark matter detection have traditionally
employed mechanical tuning, moving parts around to change electromagnetic
boundary conditions. However, these cavities have proven challenging to operate
in sub-Kelvin cryogenic environments due to differential thermal contraction,
low heat capacities, and low thermal conductivities. Instead, we develop an
electronically tunable cavity architecture by coupling a superconducting 3D
microwave cavity with a DC flux tunable SQUID. With a flux delivery system
engineered to maintain high coherence in the cavity, we perform a hidden-photon
dark matter search below the quantum-limited threshold. A microwave photon
counting technique is employed through repeated quantum non-demolition
measurements using a transmon qubit. With this device, we perform a
hidden-photon search with a dark count rate of around 64 counts/s and constrain
the kinetic mixing angle to ${\varepsilon}< 4\times 10^{-13}$ in a tunable band
from 5.672 GHz to 5.694 GHz. By coupling multimode tunable cavities to the
transmon, wider hidden-photon searching ranges are possible.",http://arxiv.org/abs/2501.06882v1
"TFLAG:Towards Practical APT Detection via Deviation-Aware Learning on
  Temporal Provenance Graph",2025-01-13T01:08:06Z,"Wenhan Jiang, Tingting Chai, Hongri Liu, Kai Wang, Hongke Zhang","Advanced Persistent Threat (APT) have grown increasingly complex and
concealed, posing formidable challenges to existing Intrusion Detection Systems
in identifying and mitigating these attacks. Recent studies have incorporated
graph learning techniques to extract detailed information from provenance
graphs, enabling the detection of attacks with greater granularity.
Nevertheless, existing studies have largely overlooked the continuous yet
subtle temporal variations in the structure of provenance graphs, which may
correspond to surreptitious perturbation anomalies in ongoing APT attacks.
Therefore, we introduce TFLAG, an advanced anomaly detection framework that for
the first time integrates the structural dynamic extraction capabilities of
temporal graph model with the anomaly delineation abilities of deviation
networks to pinpoint covert attack activities in provenance graphs. This
self-supervised integration framework leverages the graph model to extract
neighbor interaction data under continuous temporal changes from historical
benign behaviors within provenance graphs, while simultaneously utilizing
deviation networks to accurately distinguish authentic attack activities from
false positive deviations due to unexpected subtle perturbations. The
experimental results indicate that, through a comprehensive design that
utilizes both attribute and temporal information, it can accurately identify
the time windows associated with APT attack behaviors without prior knowledge
(e.g., labeled data samples), demonstrating superior accuracy compared to
current state-of-the-art methods in differentiating between attack events and
system false positive events.",http://arxiv.org/abs/2501.06997v1
"Detection of AI Deepfake and Fraud in Online Payments Using GAN-Based
  Models",2025-01-13T03:10:54Z,"Zong Ke, Shicheng Zhou, Yining Zhou, Chia Hong Chang, Rong Zhang","This study explores the use of Generative Adversarial Networks (GANs) to
detect AI deepfakes and fraudulent activities in online payment systems. With
the growing prevalence of deepfake technology, which can manipulate facial
features in images and videos, the potential for fraud in online transactions
has escalated. Traditional security systems struggle to identify these
sophisticated forms of fraud. This research proposes a novel GAN-based model
that enhances online payment security by identifying subtle manipulations in
payment images. The model is trained on a dataset consisting of real-world
online payment images and deepfake images generated using advanced GAN
architectures, such as StyleGAN and DeepFake. The results demonstrate that the
proposed model can accurately distinguish between legitimate transactions and
deepfakes, achieving a high detection rate above 95%. This approach
significantly improves the robustness of payment systems against AI-driven
fraud. The paper contributes to the growing field of digital security, offering
insights into the application of GANs for fraud detection in financial
services. Keywords- Payment Security, Image Recognition, Generative Adversarial
Networks, AI Deepfake, Fraudulent Activities",http://arxiv.org/abs/2501.07033v1
"From trees to traits: A review of advances in PhyloG2P methods and
  future directions",2025-01-13T03:51:07Z,"Arlie R. Macdonald, Maddie E. James, Jonathan D. Mitchell, Barbara R. Holland","Mapping genotypes to phenotypes (G2P) is a fundamental goal in biology. So
called PhyloG2P methods are a relatively new set of tools that leverage
replicated evolution in phylogenetically independent lineages to identify
genomic regions associated with traits of interest. Here, we review recent
developments in PhyloG2P methods, focusing on three key areas: methods based on
replicated amino acid substitutions, methods detecting changes in evolutionary
rates, and methods analysing gene duplication and loss. We discuss how the
definition and measurement of traits impacts the utility of these methods,
arguing that focusing on simple rather than compound traits will lead to more
meaningful genotype-phenotype associations. We advocate for the use of methods
that work with continuous traits directly rather than collapsing them to binary
representations. We examine the strengths and limitations of different
approaches to modeling genetic replication, highlighting the importance of
explicit modeling of evolutionary processes. Finally, we outline promising
future directions, including the integration of population-level variation, as
well as epigenetic and environmental information. No one method is likely to
identify all genomic regions of interest, so we encourage users to apply
multiple methods that are capable of detecting a wide range of associations.
The overall aim of this review is to provide practitioners a roadmap for
understanding and applying PhyloG2P methods.",http://arxiv.org/abs/2501.07043v1
"Collaborative Learning for 3D Hand-Object Reconstruction and
  Compositional Action Recognition from Egocentric RGB Videos Using
  Superquadrics",2025-01-13T07:26:05Z,"Tze Ho Elden Tse, Runyang Feng, Linfang Zheng, Jiho Park, Yixing Gao, Jihie Kim, Ales Leonardis, Hyung Jin Chang","With the availability of egocentric 3D hand-object interaction datasets,
there is increasing interest in developing unified models for hand-object pose
estimation and action recognition. However, existing methods still struggle to
recognise seen actions on unseen objects due to the limitations in representing
object shape and movement using 3D bounding boxes. Additionally, the reliance
on object templates at test time limits their generalisability to unseen
objects. To address these challenges, we propose to leverage superquadrics as
an alternative 3D object representation to bounding boxes and demonstrate their
effectiveness on both template-free object reconstruction and action
recognition tasks. Moreover, as we find that pure appearance-based methods can
outperform the unified methods, the potential benefits from 3D geometric
information remain unclear. Therefore, we study the compositionality of actions
by considering a more challenging task where the training combinations of verbs
and nouns do not overlap with the testing split. We extend H2O and FPHA
datasets with compositional splits and design a novel collaborative learning
framework that can explicitly reason about the geometric relations between
hands and the manipulated object. Through extensive quantitative and
qualitative evaluations, we demonstrate significant improvements over the
state-of-the-arts in (compositional) action recognition.",http://arxiv.org/abs/2501.07100v1
How GPT learns layer by layer,2025-01-13T07:42:55Z,"Jason Du, Kelly Hong, Alishba Imran, Erfan Jahanparast, Mehdi Khfifi, Kaichun Qiao","Large Language Models (LLMs) excel at tasks like language processing,
strategy games, and reasoning but struggle to build generalizable internal
representations essential for adaptive decision-making in agents. For agents to
effectively navigate complex environments, they must construct reliable world
models. While LLMs perform well on specific benchmarks, they often fail to
generalize, leading to brittle representations that limit their real-world
effectiveness. Understanding how LLMs build internal world models is key to
developing agents capable of consistent, adaptive behavior across tasks. We
analyze OthelloGPT, a GPT-based model trained on Othello gameplay, as a
controlled testbed for studying representation learning. Despite being trained
solely on next-token prediction with random valid moves, OthelloGPT shows
meaningful layer-wise progression in understanding board state and gameplay.
Early layers capture static attributes like board edges, while deeper layers
reflect dynamic tile changes. To interpret these representations, we compare
Sparse Autoencoders (SAEs) with linear probes, finding that SAEs offer more
robust, disentangled insights into compositional features, whereas linear
probes mainly detect features useful for classification. We use SAEs to decode
features related to tile color and tile stability, a previously unexamined
feature that reflects complex gameplay concepts like board control and
long-term planning. We study the progression of linear probe accuracy and tile
color using both SAE's and linear probes to compare their effectiveness at
capturing what the model is learning. Although we begin with a smaller language
model, OthelloGPT, this study establishes a framework for understanding the
internal representations learned by GPT models, transformers, and LLMs more
broadly. Our code is publicly available: https://github.com/ALT-JS/OthelloSAE.",http://arxiv.org/abs/2501.07108v1
ListConRanker: A Contrastive Text Reranker with Listwise Encoding,2025-01-13T07:51:46Z,"Junlong Liu, Yue Ma, Ruihui Zhao, Junhao Zheng, Qianli Ma, Yangyang Kang","Reranker models aim to re-rank the passages based on the semantics similarity
between the given query and passages, which have recently received more
attention due to the wide application of the Retrieval-Augmented Generation.
Most previous methods apply pointwise encoding, meaning that it can only encode
the context of the query for each passage input into the model. However, for
the reranker model, given a query, the comparison results between passages are
even more important, which is called listwise encoding. Besides, previous
models are trained using the cross-entropy loss function, which leads to issues
of unsmooth gradient changes during training and low training efficiency. To
address these issues, we propose a novel Listwise-encoded Contrastive text
reRanker (ListConRanker). It can help the passage to be compared with other
passages during the encoding process, and enhance the contrastive information
between positive examples and between positive and negative examples. At the
same time, we use the circle loss to train the model to increase the
flexibility of gradients and solve the problem of training efficiency.
Experimental results show that ListConRanker achieves state-of-the-art
performance on the reranking benchmark of Chinese Massive Text Embedding
Benchmark, including the cMedQA1.0, cMedQA2.0, MMarcoReranking, and T2Reranking
datasets.",http://arxiv.org/abs/2501.07111v1
"An Enhanced Zeroth-Order Stochastic Frank-Wolfe Framework for
  Constrained Finite-Sum Optimization",2025-01-13T10:53:19Z,"Haishan Ye, Yinghui Huang, Hao Di, Xiangyu Chang","We propose an enhanced zeroth-order stochastic Frank-Wolfe framework to
address constrained finite-sum optimization problems, a structure prevalent in
large-scale machine-learning applications. Our method introduces a novel double
variance reduction framework that effectively reduces the gradient
approximation variance induced by zeroth-order oracles and the stochastic
sampling variance from finite-sum objectives. By leveraging this framework, our
algorithm achieves significant improvements in query efficiency, making it
particularly well-suited for high-dimensional optimization tasks. Specifically,
for convex objectives, the algorithm achieves a query complexity of O(d
\sqrt{n}/\epsilon ) to find an epsilon-suboptimal solution, where d is the
dimensionality and n is the number of functions in the finite-sum objective.
For non-convex objectives, it achieves a query complexity of
O(d^{3/2}\sqrt{n}/\epsilon^2 ) without requiring the computation ofd partial
derivatives at each iteration. These complexities are the best known among
zeroth-order stochastic Frank-Wolfe algorithms that avoid explicit gradient
calculations. Empirical experiments on convex and non-convex machine learning
tasks, including sparse logistic regression, robust classification, and
adversarial attacks on deep networks, validate the computational efficiency and
scalability of our approach. Our algorithm demonstrates superior performance in
both convergence rate and query complexity compared to existing methods.",http://arxiv.org/abs/2501.07201v2
EdgeTAM: On-Device Track Anything Model,2025-01-13T12:11:07Z,"Chong Zhou, Chenchen Zhu, Yunyang Xiong, Saksham Suri, Fanyi Xiao, Lemeng Wu, Raghuraman Krishnamoorthi, Bo Dai, Chen Change Loy, Vikas Chandra, Bilge Soran","On top of Segment Anything Model (SAM), SAM 2 further extends its capability
from image to video inputs through a memory bank mechanism and obtains a
remarkable performance compared with previous methods, making it a foundation
model for video segmentation task. In this paper, we aim at making SAM 2 much
more efficient so that it even runs on mobile devices while maintaining a
comparable performance. Despite several works optimizing SAM for better
efficiency, we find they are not sufficient for SAM 2 because they all focus on
compressing the image encoder, while our benchmark shows that the newly
introduced memory attention blocks are also the latency bottleneck. Given this
observation, we propose EdgeTAM, which leverages a novel 2D Spatial Perceiver
to reduce the computational cost. In particular, the proposed 2D Spatial
Perceiver encodes the densely stored frame-level memories with a lightweight
Transformer that contains a fixed set of learnable queries. Given that video
segmentation is a dense prediction task, we find preserving the spatial
structure of the memories is essential so that the queries are split into
global-level and patch-level groups. We also propose a distillation pipeline
that further improves the performance without inference overhead. As a result,
EdgeTAM achieves 87.7, 70.0, 72.3, and 71.7 J&F on DAVIS 2017, MOSE, SA-V val,
and SA-V test, while running at 16 FPS on iPhone 15 Pro Max.",http://arxiv.org/abs/2501.07256v1
"PO-GVINS: Tightly Coupled GNSS-Visual-Inertial Integration with
  Pose-Only Representation",2025-01-13T12:14:48Z,"Zhuo Xu, Feng Zhu, Zihang Zhang, Chang Jian, Jiarui Lv, Yuantai Zhang, Xiaohong Zhang","Accurate and reliable positioning is crucial for perception, decision-making,
and other high-level applications in autonomous driving, unmanned aerial
vehicles, and intelligent robots. Given the inherent limitations of standalone
sensors, integrating heterogeneous sensors with complementary capabilities is
one of the most effective approaches to achieving this goal. In this paper, we
propose a filtering-based, tightly coupled global navigation satellite system
(GNSS)-visual-inertial positioning framework with a pose-only formulation
applied to the visual-inertial system (VINS), termed PO-GVINS. Specifically,
multiple-view imaging used in current VINS requires a priori of 3D feature,
then jointly estimate camera poses and 3D feature position, which inevitably
introduces linearization error of the feature as well as facing dimensional
explosion. However, the pose-only (PO) formulation, which is demonstrated to be
equivalent to the multiple-view imaging and has been applied in visual
reconstruction, represent feature depth using two camera poses and thus 3D
feature position is removed from state vector avoiding aforementioned
difficulties. Inspired by this, we first apply PO formulation in our VINS,
i.e., PO-VINS. GNSS raw measurements are then incorporated with integer
ambiguity resolved to achieve accurate and drift-free estimation. Extensive
experiments demonstrate that the proposed PO-VINS significantly outperforms the
multi-state constrained Kalman filter (MSCKF). By incorporating GNSS
measurements, PO-GVINS achieves accurate, drift-free state estimation, making
it a robust solution for positioning in challenging environments.",http://arxiv.org/abs/2501.07259v2
Synesthesia of Machines Based Multi-Modal Intelligent V2V Channel Model,2025-01-13T13:46:47Z,"Zengrui Han, Lu Bai, Ziwei Huang, Xiang Cheng","This paper proposes a novel sixth-generation (6G) multi-modal intelligent
vehicle-to-vehicle (V2V) channel model from light detection and ranging (LiDAR)
point clouds based on Synesthesia of Machines (SoM). To explore the mapping
relationship between physical environment and electromagnetic space, a new V2V
high-fidelity mixed sensing-communication integration simulation dataset with
different vehicular traffic densities (VTDs) is constructed. Based on the
constructed dataset, a novel scatterer recognition (ScaR) algorithm utilizing
neural network SegNet is developed to recognize scatterer spatial attributes
from LiDAR point clouds via SoM. In the developed ScaR algorithm, the mapping
relationship between LiDAR point clouds and scatterers is explored, where the
distribution of scatterers is obtained in the form of grid maps. Furthermore,
scatterers are distinguished into dynamic and static scatterers based on LiDAR
point cloud features, where parameters, e.g., distance, angle, and number,
related to scatterers are determined. Through ScaR, dynamic and static
scatterers change with the variation of LiDAR point clouds over time, which
precisely models channel non-stationarity and consistency under different VTDs.
Some important channel statistical properties, such as time-frequency
correlation function (TF-CF) and Doppler power spectral density (DPSD), are
obtained. Simulation results match well with ray-tracing (RT)-based results,
thus demonstrating the necessity of exploring the mapping relationship and the
utility of the proposed model.",http://arxiv.org/abs/2501.07333v1
"MVICAD2: Multi-View Independent Component Analysis with Delays and
  Dilations",2025-01-13T15:47:02Z,"Ambroise Heurtebise, Omar Chehab, Pierre Ablin, Alexandre Gramfort","Machine learning techniques in multi-view settings face significant
challenges, particularly when integrating heterogeneous data, aligning feature
spaces, and managing view-specific biases. These issues are prominent in
neuroscience, where data from multiple subjects exposed to the same stimuli are
analyzed to uncover brain activity dynamics. In magnetoencephalography (MEG),
where signals are captured at the scalp level, estimating the brain's
underlying sources is crucial, especially in group studies where sources are
assumed to be similar for all subjects. Common methods, such as Multi-View
Independent Component Analysis (MVICA), assume identical sources across
subjects, but this assumption is often too restrictive due to individual
variability and age-related changes. Multi-View Independent Component Analysis
with Delays (MVICAD) addresses this by allowing sources to differ up to a
temporal delay. However, temporal dilation effects, particularly in auditory
stimuli, are common in brain dynamics, making the estimation of time delays
alone insufficient. To address this, we propose Multi-View Independent
Component Analysis with Delays and Dilations (MVICAD2), which allows sources to
differ across subjects in both temporal delays and dilations. We present a
model with identifiable sources, derive an approximation of its likelihood in
closed form, and use regularization and optimization techniques to enhance
performance. Through simulations, we demonstrate that MVICAD2 outperforms
existing multi-view ICA methods. We further validate its effectiveness using
the Cam-CAN dataset, and showing how delays and dilations are related to aging.",http://arxiv.org/abs/2501.07426v1
"Gravitational-wave memory effects in the Damour-Esposito-Farèse
  extension of Brans-Dicke theory",2025-01-13T17:05:56Z,"Shammi Tahura, David A. Nichols, Kent Yagi","Gravitational-wave memory effects are lasting changes in the strain and its
time integrals. They can be computed in asymptotically flat spacetimes using
the conservation and evolution equations in the Bondi-Sachs framework. Modified
theories of gravity have additional degrees of freedom with their own
asymptotic evolution equations; these additional fields can produce differences
in the memory effects in these theories from those in general relativity. In
this work, we study a scalar-tensor theory of gravity known as the
Damour-Esposito-Far\`ese extension of Brans-Dicke theory. We use the
Bondi-Sachs framework to compute the field equations in Bondi-Sachs form, the
asymptotically flat solutions, and the leading gravitational-wave memory
effects. Although Damour-Esposito-Far\`ese theory has additional nonlinearities
not present in Brans-Dicke theory, these nonlinearities are subleading effects;
thus, the two theories share many similarities in the leading (and some
subleading) solutions to hypersurface equations, asymptotic symmetries, and
types of memory effects. The conservation equations for the mass and angular
momentum aspects differ between the two theories, primarily because of the
differences in the evolution equation for the scalar field. This leads to
differences in the time dependence of the gravitational-wave memory signals
that are produced during the quasicircular inspiral of compact binaries. These
differences, however, are of second-order in a small coupling parameter of
these theories, which suggests that it would be challenging to use memory
effects to distinguish between these two theories.",http://arxiv.org/abs/2501.07488v1
Evaluating Agent-based Program Repair at Google,2025-01-13T18:09:25Z,"Pat Rondon, Renyao Wei, José Cambronero, Jürgen Cito, Aaron Sun, Siddhant Sanyam, Michele Tufano, Satish Chandra","Agent-based program repair offers to automatically resolve complex bugs
end-to-end by combining the planning, tool use, and code generation abilities
of modern LLMs. Recent work has explored the use of agent-based repair
approaches on the popular open-source SWE-Bench, a collection of bugs from
highly-rated GitHub Python projects. In addition, various agentic approaches
such as SWE-Agent have been proposed to solve bugs in this benchmark. This
paper explores the viability of using an agentic approach to address bugs in an
enterprise context. To investigate this, we curate an evaluation set of 178
bugs drawn from Google's issue tracking system. This dataset spans both
human-reported (78) and machine-reported bugs (100).
  To establish a repair performance baseline on this benchmark, we implement
Passerine, an agent similar in spirit to SWE-Agent that can work within
Google's development environment. We show that with 20 trajectory samples and
Gemini 1.5 Pro, Passerine can produce a patch that passes bug tests (i.e.,
plausible) for 73% of machine-reported and 25.6% of human-reported bugs in our
evaluation set. After manual examination, we found that 43% of machine-reported
bugs and 17.9% of human-reported bugs have at least one patch that is
semantically equivalent to the ground-truth patch.
  These results establish a baseline on an industrially relevant benchmark,
which as we show, contains bugs drawn from a different distribution -- in terms
of language diversity, size, and spread of changes, etc. -- compared to those
in the popular SWE-Bench dataset.",http://arxiv.org/abs/2501.07531v1
"MatchAnything: Universal Cross-Modality Image Matching with Large-Scale
  Pre-Training",2025-01-13T18:37:36Z,"Xingyi He, Hao Yu, Sida Peng, Dongli Tan, Zehong Shen, Hujun Bao, Xiaowei Zhou","Image matching, which aims to identify corresponding pixel locations between
images, is crucial in a wide range of scientific disciplines, aiding in image
registration, fusion, and analysis. In recent years, deep learning-based image
matching algorithms have dramatically outperformed humans in rapidly and
accurately finding large amounts of correspondences. However, when dealing with
images captured under different imaging modalities that result in significant
appearance changes, the performance of these algorithms often deteriorates due
to the scarcity of annotated cross-modal training data. This limitation hinders
applications in various fields that rely on multiple image modalities to obtain
complementary information. To address this challenge, we propose a large-scale
pre-training framework that utilizes synthetic cross-modal training signals,
incorporating diverse data from various sources, to train models to recognize
and match fundamental structures across images. This capability is transferable
to real-world, unseen cross-modality image matching tasks. Our key finding is
that the matching model trained with our framework achieves remarkable
generalizability across more than eight unseen cross-modality registration
tasks using the same network weight, substantially outperforming existing
methods, whether designed for generalization or tailored for specific tasks.
This advancement significantly enhances the applicability of image matching
technologies across various scientific disciplines and paves the way for new
applications in multi-modality human and artificial intelligence analysis and
beyond.",http://arxiv.org/abs/2501.07556v1
"Multi-task Domain Adaptation for Computation Offloading in
  Edge-intelligence Networks",2025-01-02T13:20:29Z,"Runxin Han, Bo Yang, Zhiwen Yu, Xuelin Cao, George C. Alexandropoulos, Chau Yuen","In the field of multi-access edge computing (MEC), efficient computation
offloading is crucial for improving resource utilization and reducing latency
in dynamically changing environments. This paper introduces a new approach,
termed as Multi-Task Domain Adaptation (MTDA), aiming to enhance the ability of
computational offloading models to generalize in the presence of domain shifts,
i.e., when new data in the target environment significantly differs from the
data in the source domain. The proposed MTDA model incorporates a
teacher-student architecture that allows continuous adaptation without
necessitating access to the source domain data during inference, thereby
maintaining privacy and reducing computational overhead. Utilizing a multi-task
learning framework that simultaneously manages offloading decisions and
resource allocation, the proposed MTDA approach outperforms benchmark methods
regarding mean squared error and accuracy, particularly in environments with
increasing numbers of users. It is observed by means of computer simulation
that the proposed MTDA model maintains high performance across various
scenarios, demonstrating its potential for practical deployment in emerging MEC
applications.",http://arxiv.org/abs/2501.07585v1
"NuSTAR observations of a varying-flux quasar in the Epoch of
  Reionization",2025-01-13T19:01:03Z,"Lea Marcotulli, Thomas Connor, Eduardo Bañados, Peter G. Boorman, Giulia Migliori, Brian W. Grefenstette, Emmanuel Momjian, Aneta Siemiginowska, Daniel Stern, Silvia Belladitta, C. C. Cheung, Andrew Fabian, Yana Khusanova, Chiara Mazzucchelli, Sofía Rojas-Ruiz, C. Megan Urry","With enough X-ray flux to be detected in a 160s scan by SRG/eROSITA, the $z =
6.19$ quasar CFHQS J142952+544717 is, by far, the most luminous X-ray source
known at $z > 6$. We present deep (245 ks) NuSTAR observations of this source;
with $\sim180$ net counts in the combined observations, CFHQS J142952+544717 is
the most distant object ever observed by the observatory. Fortuitously, this
source was independently observed by Chandra $\sim110$ days earlier, enabling
the identification of two nearby (30'' and 45'' away), fainter X-ray sources.
We jointly fit both Chandra and NuSTAR observations--self-consistently
including interloper sources--and find that, to greater than 90% confidence,
the observed 3-7 keV flux varied by a factor of $\sim2.6$ during that period,
corresponding to approximately two weeks in the quasar rest-frame. This
brightening is one the most extreme instances of statistically significant
X-ray variability seen in the Epoch of Reionization. We discuss possible
scenarios that could produce such rapid change, including X-ray emission from
jets too faint at radio frequencies to be observed.",http://arxiv.org/abs/2501.07637v1
"Using Statistical Precision Medicine to Identify Optimal Treatments in a
  Heart Failure Setting",2025-01-14T02:14:14Z,"Arti Virkud, Jessie K. Edwards, Michele Jonsson Funk, Patricia Chang, Abhijit V. Kshirsagar, Emily W. Gower, Michael R. Kosorok","Identifying optimal medical treatments to improve survival has long been a
critical goal of pharmacoepidemiology. Traditionally, we use an average
treatment effect measure to compare outcomes between treatment plans. However,
new methods leveraging advantages of machine learning combined with the
foundational tenets of causal inference are offering an alternative to the
average treatment effect. Here, we use three unique, precision medicine
algorithms (random forests, residual weighted learning, efficient augmentation
relaxed learning) to identify optimal treatment rules where patients receive
the optimal treatment as indicated by their clinical history. First, we present
a simple hypothetical example and a real-world application among heart failure
patients using Medicare claims data. We next demonstrate how the optimal
treatment rule improves the absolute risk in a hypothetical, three-modifier
setting. Finally, we identify an optimal treatment rule that optimizes the time
to outcome in a real-world heart failure setting. In both examples, we compare
the average time to death under the optimized, tailored treatment rule with the
average time to death under a universal treatment rule to show the benefit of
precision medicine methods. The improvement under the optimal treatment rule in
the real-world setting is greatest (additional ~9 days under the tailored rule)
for survival time free of heart failure readmission.",http://arxiv.org/abs/2501.07789v1
"A Low-cost and Ultra-lightweight Binary Neural Network for Traffic
  Signal Recognition",2025-01-14T03:19:10Z,"Mingke Xiao, Yue Su, Liang Yu, Guanglong Qu, Yutong Jia, Yukuan Chang, Xu Zhang","The deployment of neural networks in vehicle platforms and wearable
Artificial Intelligence-of-Things (AIOT) scenarios has become a research area
that has attracted much attention. With the continuous evolution of deep
learning technology, many image classification models are committed to
improving recognition accuracy, but this is often accompanied by problems such
as large model resource usage, complex structure, and high power consumption,
which makes it challenging to deploy on resource-constrained platforms. Herein,
we propose an ultra-lightweight binary neural network (BNN) model designed for
hardware deployment, and conduct image classification research based on the
German Traffic Sign Recognition Benchmark (GTSRB) dataset. In addition, we also
verify it on the Chinese Traffic Sign (CTS) and Belgian Traffic Sign (BTS)
datasets. The proposed model shows excellent recognition performance with an
accuracy of up to 97.64%, making it one of the best performing BNN models in
the GTSRB dataset. Compared with the full-precision model, the accuracy loss is
controlled within 1%, and the parameter storage overhead of the model is only
10% of that of the full-precision model. More importantly, our network model
only relies on logical operations and low-bit width fixed-point addition and
subtraction operations during the inference phase, which greatly simplifies the
design complexity of the processing element (PE). Our research shows the great
potential of BNN in the hardware deployment of computer vision models,
especially in the field of computer vision tasks related to autonomous driving.",http://arxiv.org/abs/2501.07808v1
"Low-Contact Grasping of Soft Tissue with Complex Geometry using a Vortex
  Gripper",2025-01-14T04:26:49Z,"Roman Mykhailyshyn, Ann Majewicz Fey","Soft tissue manipulation is an integral aspect of most surgical procedures;
however, the vast majority of surgical graspers used today are made of hard
materials, such as metals or hard plastics. Furthermore, these graspers
predominately function by pinching tissue between two hard objects as a method
for tissue manipulation. As such, the potential to apply too much force during
contact, and thus damage tissue, is inherently high. As an alternative
approach, gaspers developed using a pneumatic vortex could potentially levitate
soft tissue, enabling manipulation with low or even no contact force. In this
paper, we present the design and well as a full factorial study of the force
characteristics of the vortex gripper grasping soft surfaces with four common
shapes, with convex and concave curvature, and ranging over 10 different radii
of curvature, for a total of 40 unique surfaces. By changing the parameters of
the nozzle elements in the design of the gripper, it was possible to
investigate the influence of the mass flow parameters of the vortex gripper on
the lifting force for all of these different soft surfaces. An $\pmb{ex}$
$\pmb{vivo}$ experiment was conducted on grasping biological tissues and soft
balls of various shapes to show the advantages and disadvantages of the
proposed technology. The obtained results allowed us to find limitations in the
use of vortex technology and the following stages of its improvement for
medical use.",http://arxiv.org/abs/2501.07832v1
"GeoWarp: Warped spatial processes for inferring subsea sediment
  properties",2025-01-14T04:56:22Z,"Michael Bertolacci, Andrew Zammit-Mangion, Juan Valderrama Giraldo, Michael O'Neill, Fraser Bransby, Phil Watson","For offshore structures like wind turbines, subsea infrastructure, pipelines,
and cables, it is crucial to quantify the properties of the seabed sediments at
a proposed site. However, data collection offshore is costly, so analysis of
the seabed sediments must be made from measurements that are spatially sparse.
Adding to this challenge, the structure of the seabed sediments exhibits both
nonstationarity and anisotropy. To address these issues, we propose GeoWarp, a
hierarchical spatial statistical modeling framework for inferring the 3-D
geotechnical properties of subsea sediments. GeoWarp decomposes the seabed
properties into a region-wide vertical mean profile (modeled using B-splines),
and a nonstationary 3-D spatial Gaussian process. Process nonstationarity and
anisotropy are accommodated by warping space in three dimensions and by
allowing the process variance to change with depth. We apply GeoWarp to
measurements of the seabed made using cone penetrometer tests (CPTs) at six
sites on the North West Shelf of Australia. We show that GeoWarp captures the
complex spatial distribution of the sediment properties, and produces realistic
3-D simulations suitable for downstream engineering analyses. Through
cross-validation, we show that GeoWarp has predictive performance superior to
other state-of-the-art methods, demonstrating its value as a tool in offshore
geotechnical engineering.",http://arxiv.org/abs/2501.07841v1
"Healing of the edge magnetic island in the island divertor configuration
  on J-TEXT",2025-01-14T05:29:35Z,"Zhangrong Hou, Song Zhou, Nengchao Wang, Yonghua Ding, Zhonghe Jiang, Yunfeng Liang, Zhengkang Ren, Feiyue Mao, Qinghu Yang, Jiaming Wang, Xin Xu, Yutong Yang, Jiankun Hua, Zijian Xuan, Chuanxu Zhao, Yangbo Li, Lei Yu, Donghui Xia, Zhipeng Chen, Zhoujun Yang, the J-TEXT team","The phenomena of island healing and configuration transition induced by
high-power electron cyclotron resonance heating (ECRH) have been investigated
in the island divertor configuration on the J-TEXT tokamak. Experimental
results reveal that the size of the edge open magnetic island with mode number
m/n = 3/1 decreases substantially under specific ECRH conditions. This process,
referred to as island healing, occurs when ECRH with a power of 500~600 kW is
deposited in the plasma core or when 250 kW of ECRH is deposited at r = 0.5 a,
where a is the minor radius. The reduction of the island width makes the island
divertor ineffective and transition into the limiter configuration. A model
incorporating the influence of ECRH on the scrape-off layer (SOL)
thermoelectric current is proposed to explain the observed changes in the edge
magnetic topology of the island divertor configuration. These findings suggest
that ECRH should be deposited at the plasma core with carefully controlled
power to ensure the stable and compatible operation of ECRH and the island
divertor configuration in tokamaks. The results can provide insights into
achieving robust operation of an island divertor in tokamaks.",http://arxiv.org/abs/2501.07852v1
The Wigner Little Group for Photons Is a Projective Subalgebra,2025-01-14T07:52:09Z,"Moab Croft, Hamish Todd, Edward Corbett","This paper presents the Geometric Algebra approach to the Wigner little group
for photons using the Spacetime Algebra, incorporating a mirror-based view for
physical interpretation. The shift from a point-based view to a mirror-based
view is a modern movement that allows for a more intuitive representation of
geometric and physical entities, with vectors and their higher-grade
counterparts viewed as hyperplanes. This reinterpretation simplifies the
implementation of homogeneous representations of geometric objects within the
Spacetime Algebra and enables a relative view via projective geometry. Then,
after utilizing the intrinsic properties of Geometric Algebra, the Wigner
little group is seen to induce a projective geometric algebra as a subalgebra
of the Spacetime Algebra. However, the dimension-agnostic nature of Geometric
Algebra enables the generalization of induced subalgebras to (1+n)-dimensional
Minkowski geometric algebras, termed little photon algebras. The lightlike
transformations (translations) in these little photon algebras are seen to
leave invariant the (pseudo)canonical electromagetic field bivector.
Geometrically, this corresponds to Lorentz transformations that do not change
the intersection of the spacelike polarization hyperplane with the lightlike
wavevector hyperplane while simultaneously not affecting the lightlike
wavevector hyperplane. This provides for a framework that unifies the analysis
of symmetries and substructures of point-based Geometric Algebra with
mirror-based Geometric Algebra.",http://arxiv.org/abs/2501.07909v1
"Gravitational Waves dynamics with Higgs portal and U(1) X SU(2)
  interactions",2025-01-14T10:43:14Z,Lucia A. Popa,"We show that a mixture of Higgs boson with a heavy scalar singlet with large
vacuum expectation value ( vev) is a viable model of inflation that satisfy the
existing observational data, the perturbativity constraints, avoiding in the
same time the EW vacuum metastability as long as the Higgs portal interactions
lead to positive tree-level threshold corrections for SM Higgs quartic
coupling. The tree-level threshold corrections lead to the change of Hubble
expansion rate during inflation with impact on the evolution of the axion-gauge
field spectator sector, modifying the time-dependent mass parameter of the
gauge field fluctuation. We evaluate this effect on the GW sourced tensor modes
while accounting for the consistency and backreaction constraints and show that
the Higgs portal interactions enhance the GW signal sourced by the gauge field
fluctuations in the CMB B-mode ploarization power spectra. We address the
detectability of the GW sourced by the gauge field fluctuations in presence of
Higgs portal interactions for the experimental configuration of the future CMB
polarization LiteBird space mission. We find that the sourced GW
tensor-to-scalar ratio in presence of Higgs portal interactions is enhanced to
a level that overcomes the vacuum tensor-to-scalar ratio by a factor of 10,
much above the detection threshold of the LiteBird experiment, in agreement
with the existing observational constraints on the curvature fluctuations and
the allowed parameter space of Higgs portal interactions. We also show that a
large enhancement of the sourced GW can be also detected by experiments such as
pulsar timing arrays and laser/atomic interferometers. Moreover, a significant
Higgs-singlet mixing can be probed by the LHC Higgs searchers.",http://arxiv.org/abs/2501.08000v1
"Improvements to SHINS, the SHARK-NIR Instrument Software, during the AIT
  phase",2025-01-14T10:55:12Z,"Davide Ricci, Fulvio Laudisio, Marco De Pascale, Sona Shivaji Rao Chavan, Andrea Baruffolo","In the context of SHARK-NIR (System for coronagraphy with High Order adaptive
optics in Z and H band), we present the development of SHINS, the SHARK-NIR
INstrument control Software, in particular focusing on the changes introduced
during the Assembly, Integration, and Test (AIT) phase. SHARK-NIR observing
sessions will be carried out with ""ESO-style"" Observation Blocks (OBs) based on
so-called Templates scripts that will be prepared by observers. We decided to
develop Templates also for the large number of AIT tests (flexures,
coronagraphic mask alignment, scientific camera performances...). Here we
present the adopted HTTP API for the OBs generation and a web-based frontend
that implements it. Taking advantage of this approach, we decided to expose
APIs also for individual device movement and monitoring, as well as for general
status. These APIs are then used in the web-based instrument control and
synoptic panels. During the recent AIT phase, a potential collision issue
between two motorized components emerged. While we are exploring the
possibility of a hardware interlock, we present a software solution developed
at the Observation Software level, that is also available while using other
software such as engineering panels. The system is based on three protection
layers and it has been successfully tested.",http://arxiv.org/abs/2501.08010v1
"An AI-driven framework for rapid and localized optimizations of urban
  open spaces",2025-01-14T11:19:52Z,"Pegah Eshraghi, Arman Nikkhah Dehnavi, Maedeh Mirdamadi, Riccardo Talami, Zahra-Sadat Zomorodian","As urbanization accelerates, open spaces are increasingly recognized for
their role in enhancing sustainability and well-being, yet they remain
underexplored compared to built spaces. This study introduces an AI-driven
framework that integrates machine learning models (MLMs) and explainable AI
techniques to optimize Sky View Factor (SVF) and visibility, key spatial
metrics influencing thermal comfort and perceived safety in urban spaces.
Unlike global optimization methods, which are computationally intensive and
impractical for localized adjustments, this framework supports incremental
design improvements with lower computational costs and greater flexibility. The
framework employs SHapley Adaptive Explanations (SHAP) to analyze feature
importance and Counterfactual Explanations (CFXs) to propose minimal design
changes. Simulations tested five MLMs, identifying XGBoost as the most
accurate, with building width, park area, and heights of surrounding buildings
as critical for SVF, and distances from southern buildings as key for
visibility. Compared to Genetic Algorithms, which required approximately 15/30
minutes across 3/4 generations to converge, the tested CFX approach achieved
optimized results in 1 minute with a 5% RMSE error, demonstrating significantly
faster performance and suitability for scalable retrofitting strategies. This
interpretable and computationally efficient framework advances urban
performance optimization, providing data-driven insights and practical
retrofitting solutions for enhancing usability and environmental quality across
diverse urban contexts.",http://arxiv.org/abs/2501.08019v1
"Continual Reinforcement Learning for Digital Twin Synchronization
  Optimization",2025-01-14T11:53:07Z,"Haonan Tong, Mingzhe Chen, Jun Zhao, Ye Hu, Zhaohui Yang, Yuchen Liu, Changchuan Yin","This article investigates the adaptive resource allocation scheme for digital
twin (DT) synchronization optimization over dynamic wireless networks. In our
considered model, a base station (BS) continuously collects factory physical
object state data from wireless devices to build a real-time virtual DT system
for factory event analysis. Due to continuous data transmission, maintaining DT
synchronization must use extensive wireless resources. To address this issue, a
subset of devices is selected to transmit their sensing data, and resource
block (RB) allocation is optimized. This problem is formulated as a constrained
Markov process (CMDP) problem that minimizes the long-term mismatch between the
physical and virtual systems. To solve this CMDP, we first transform the
problem into a dual problem that refines RB constraint impacts on device
scheduling strategies. We then propose a continual reinforcement learning (CRL)
algorithm to solve the dual problem. The CRL algorithm learns a stable policy
across historical experiences for quick adaptation to dynamics in physical
states and network capacity. Simulation results show that the CRL can adapt
quickly to network capacity changes and reduce normalized root mean square
error (NRMSE) between physical and virtual states by up to 55.2%, using the
same RB number as traditional methods.",http://arxiv.org/abs/2501.08045v1
"Hydrodynamics-driven phase-locking and collective motility of sessile
  active dumbbells",2025-01-14T12:27:18Z,"Urvi Mahendra Bora, Mohd Suhail Rizvi","Collective motion is a phenomenon observed across length scales in nature,
from bacterial swarming and tissue migration to the flocking of animals. The
mechanisms underlying this behavior vary significantly depending on the
biological system, ranging from hydrodynamic and chemical interactions in
bacteria to mechanical forces in epithelial tissues and social alignment in
animal groups. While collective motion often arises from the coordinated
activity of independently motile agents, this work explores a novel context:
the emergence of collective motion in systems of non-motile active agents.
Inspired by the oscillatory shape dynamics observed in suspended cells such as
neutrophils and fibroblasts, we model active dumbbells exhibiting limit-cycle
oscillations in shape as a minimal representation of such systems.Through
computational simulations, we demonstrate that hydrodynamic interactions
between these dumbbells lead to three key phenomena: a density-dependent
transition from sessile to collective motion, hydrodynamics-induced phase
separation, and synchronization of oscillatory shape changes. We have explored
the role of hydrodynamic interactions on these emergent properties of sessile
active dumbbells. These results underscore the critical role of hydrodynamic
coupling in enabling and organizing collective behaviors in systems lacking
intrinsic motility. This study lays the groundwork for future investigations
into the emergent behavior of active matter and its implications for
understanding cell motility, tissue dynamics, and the development of
bio-inspired materials.",http://arxiv.org/abs/2501.08065v1
"Probing Spectral Evolution and Intrinsic Variability of Mkn\,421: A
  Multi-Epoch AstroSat Study of X-ray Spectra",2025-01-14T12:41:55Z,"Sikandar Akbar, Zahir Shah, Ranjeev Misra, Naseer Iqbal, Javaid Tantry","Our study presents a time-resolved X-ray spectral analysis of Mkn 421, using
AstroSat observations taken during different epochs between 2016 and 2019. The
variability of the source in X-rays is utilized to investigate the evolution of
its spectral properties. Each observation period was divided into segments of
about 10 ks, and we employed three forms of particle distributions:
broken-power law (BPL), log-parabola (LP), and power-law with maximum electron
energy (xi-max model) undergoing synchrotron losses to fit the broad X-ray
spectrum in each segment. We observed that all of these models provided good
fits to the spectra. In the case of the broken-power law model, we investigated
the relationship between normalized particle density at an energy less than the
break energy and the index before the break. The results revealed an inverse
correlation between the index and particle density with no time delay.
Additionally, correlations between spectral parameters were used to determine
the pivot energy. We observed that the pivot energy remained the same across
the observations. For xi-max and LP models, we define analogous pivot energies
and show that they also do not vary, indicating the model-independent nature of
the result. The constant pivot energy suggests that the source's variability
arises from index variations and not due to changes in the normalization.
Consequently, parameters such as magnetic field strength, Doppler factor, etc.,
do not contribute to the source's variability. Instead, variations are
primarily associated with the acceleration or escape timescales of emitted
particles within the source.",http://arxiv.org/abs/2501.08073v1
"Dynamical evolution of the open clusters with different star formation
  efficiencies and orbital parameters",2025-01-14T12:52:38Z,"M. Ishchenko, V. Masliukh, M. Hradov, P. Berczik, B. Shukirgaliyev, C. Omarov","Open star clusters are dynamic systems whose evolution is critically
influenced by initial conditions such as star formation efficiency and orbital
parameters. Understanding their dissolution mechanisms provides insight into
stellar population dynamical mixing in the Milky Way. We aim to investigate the
dynamical evolution and dissolution of initially non-virialised open clusters
by examining how different global star formation efficiencies and orbital
characteristics impact the cluster longevity and structural changes. We
followed the evolution of the clusters up to their dissolution time on the
basis of our calculations. We compare our open cluster dynamical evolutionary
models with the observed open clusters in our Galaxy's solar vicinity. Using
high-order direct N-body simulations, we modelled cluster evolution across
different Galactic orbits, systematically varying initial star formation
efficiencies to comprehensively explore dissolution mechanisms. Our simulations
reveal that open clusters typically survive approximately ten orbital periods,
with cluster lifetime being strongly dependent on global star formation
efficiency and only marginally influenced by orbital eccentricity. We estimate
gas expulsion timescales of 0.9 Myr, with initial supernova explosions
efficiently removing gaseous components from the cluster. The expected lifetime
of the cluster (in units of orbital periods) strongly depends on the cluster
global star-formation efficiency and only slightly on the orbital
eccentricities of the cluster. The theoretical models demonstrate a remarkable
agreement of the Roche-volobe filling parameter with the recent observed Gaia
DR3 cluster catalogues in the solar vicinity. By incorporating a mixed sample
of clusters with varying star formation efficiencies, we provide a more nuanced
understanding of open cluster evolution in the Galactic disc.",http://arxiv.org/abs/2501.08084v1
Mobility Management in Integrated Sensing and Communications Networks,2025-01-14T14:37:31Z,"Yuri S. Ribeiro, Behrooz Makki, Andre L. F. de Almeida, Gabor Fodor","The performance of the integrated sensing and communication (ISAC) networks
is considerably affected by the mobility of the transceiver nodes, user
equipment devices (UEs) and the passive objects that are sensed. For instance,
the sensing efficiency is considerably affected by the presence or absence of a
line-of-sight connection between the sensing transceivers and the object; a
condition that may change quickly due to mobility. Moreover, the mobility of
the UEs and objects may result in dynamically varying communication-to-sensing
and sensing-to communication interference, deteriorating the network
performance. In such cases, there may be a need to handover the sensing process
to neighbor nodes. In this article, we develop the concept of mobility
management in ISAC networks. Here, depending on the mobility of objects and/or
the transceiver nodes, the data traffic, the sensing or communication coverage
area of the transceivers, and the network interference, the transmission and/or
the reception of the sensing signals may be handed over to neighbor nodes.
Also, the ISAC configuration and modality - that is, using monostatic or
bistatic sensing - are updated accordingly, such that the sensed objects can be
continuously sensed with low overhead. We show that mobility management reduces
the sensing interruption and boosts the communication and sensing efficiency of
ISAC networks.",http://arxiv.org/abs/2501.08159v1
"FramePainter: Endowing Interactive Image Editing with Video Diffusion
  Priors",2025-01-14T16:09:16Z,"Yabo Zhang, Xinpeng Zhou, Yihan Zeng, Hang Xu, Hui Li, Wangmeng Zuo","Interactive image editing allows users to modify images through visual
interaction operations such as drawing, clicking, and dragging. Existing
methods construct such supervision signals from videos, as they capture how
objects change with various physical interactions. However, these models are
usually built upon text-to-image diffusion models, so necessitate (i) massive
training samples and (ii) an additional reference encoder to learn real-world
dynamics and visual consistency. In this paper, we reformulate this task as an
image-to-video generation problem, so that inherit powerful video diffusion
priors to reduce training costs and ensure temporal consistency. Specifically,
we introduce FramePainter as an efficient instantiation of this formulation.
Initialized with Stable Video Diffusion, it only uses a lightweight sparse
control encoder to inject editing signals. Considering the limitations of
temporal attention in handling large motion between two frames, we further
propose matching attention to enlarge the receptive field while encouraging
dense correspondence between edited and source image tokens. We highlight the
effectiveness and efficiency of FramePainter across various of editing signals:
it domainantly outperforms previous state-of-the-art methods with far less
training data, achieving highly seamless and coherent editing of images, \eg,
automatically adjust the reflection of the cup. Moreover, FramePainter also
exhibits exceptional generalization in scenarios not present in real-world
videos, \eg, transform the clownfish into shark-like shape. Our code will be
available at https://github.com/YBYBZhang/FramePainter.",http://arxiv.org/abs/2501.08225v1
"Text-Diffusion Red-Teaming of Large Language Models: Unveiling Harmful
  Behaviors with Proximity Constraints",2025-01-14T16:32:01Z,"Jonathan Nöther, Adish Singla, Goran Radanović","Recent work has proposed automated red-teaming methods for testing the
vulnerabilities of a given target large language model (LLM). These methods use
red-teaming LLMs to uncover inputs that induce harmful behavior in a target
LLM. In this paper, we study red-teaming strategies that enable a targeted
security assessment. We propose an optimization framework for red-teaming with
proximity constraints, where the discovered prompts must be similar to
reference prompts from a given dataset. This dataset serves as a template for
the discovered prompts, anchoring the search for test-cases to specific topics,
writing styles, or types of harmful behavior. We show that established
auto-regressive model architectures do not perform well in this setting. We
therefore introduce a black-box red-teaming method inspired by text-diffusion
models: Diffusion for Auditing and Red-Teaming (DART). DART modifies the
reference prompt by perturbing it in the embedding space, directly controlling
the amount of change introduced. We systematically evaluate our method by
comparing its effectiveness with established methods based on model fine-tuning
and zero- and few-shot prompting. Our results show that DART is significantly
more effective at discovering harmful inputs in close proximity to the
reference prompt.",http://arxiv.org/abs/2501.08246v1
Toward Zero-Shot User Intent Recognition in Shared Autonomy,2025-01-14T19:06:44Z,"Atharv Belsare, Zohre Karimi, Connor Mattson, Daniel S. Brown","A fundamental challenge of shared autonomy is to use high-DoF robots to
assist, rather than hinder, humans by first inferring user intent and then
empowering the user to achieve their intent. Although successful, prior methods
either rely heavily on a priori knowledge of all possible human intents or
require many demonstrations and interactions with the human to learn these
intents before being able to assist the user. We propose and study a zero-shot,
vision-only shared autonomy (VOSA) framework designed to allow robots to use
end-effector vision to estimate zero-shot human intents in conjunction with
blended control to help humans accomplish manipulation tasks with unknown and
dynamically changing object locations. To demonstrate the effectiveness of our
VOSA framework, we instantiate a simple version of VOSA on a Kinova Gen3
manipulator and evaluate our system by conducting a user study on three
tabletop manipulation tasks. The performance of VOSA matches that of an oracle
baseline model that receives privileged knowledge of possible human intents
while also requiring significantly less effort than unassisted teleoperation.
In more realistic settings, where the set of possible human intents is fully or
partially unknown, we demonstrate that VOSA requires less human effort and time
than baseline approaches while being preferred by a majority of the
participants. Our results demonstrate the efficacy and efficiency of using
off-the-shelf vision algorithms to enable flexible and beneficial shared
control of a robot manipulator. Code and videos available here:
https://sites.google.com/view/zeroshot-sharedautonomy/home.",http://arxiv.org/abs/2501.08389v1
"Heterogeneous Update Processes Shape Information Cascades in Social
  Networks",2025-01-15T00:19:04Z,"Flávio L. Pinheiro, Vítor V. Vasconcelos","A common assumption in the literature on information diffusion is that
populations are homogeneous regarding individuals' information acquisition and
propagation process: Individuals update their informed and actively
communicating state either through imitation (simple contagion) or peer
influence (complex contagion). Here, we study the impact of the mixing and
placement of individuals with different update processes on how information
cascades in social networks. We consider Simple Spreaders, which take
information from a random neighbor and communicate it, and Threshold-based
Spreaders, which require a threshold number of active neighbors to change their
state to active communication. Even though, in a population made exclusively of
Simple Spreaders, information reaches all elements of any (connected) network,
we show that, when Simple and Threshold-based Spreaders coexist and occupy
random positions in a social network, the number of Simple Spreaders
systematically amplifies the cascades only in degree heterogeneous networks
(exponential and scale-free). In random and modular structures, this cascading
effect originated by Simple Spreaders only exists above a critical mass of
these individuals. In contrast, when Threshold-based Spreaders are assorted
preferentially in the nodes with a higher degree, the cascading effect of
Simple Spreaders vanishes, and the spread of information is drastically
impaired. Overall, the study highlights the significance of the strategic
placement of different roles in networked structures, with Simple Spreaders
driving widespread cascades in heterogeneous networks and Threshold-based
Spreaders playing a critical regulatory role in information spread with a
tunable effect based on the threshold value.",http://arxiv.org/abs/2501.08498v1
"Unconventional bias-dependent tunneling magnetoresistance in van der
  Waals ferromagnetic/semiconductor heterojunctions",2025-01-15T13:11:39Z,"Wenkai Zhu, Hui Wen, Shouguo Zhu, Qirui Cui, Shihong Xie, Meng Ye, Gaojie Zhang, Hao Wu, Xiaomin Zhang, Weihao Li, Yuqing Huang, Jing Zhang, Lixia Zhao, Amalia Patanè, Haixin Chang, Lin-Wang Wang, Kaiyou Wang","Two-dimensional van der Waals (vdW) ferromagnetic/semiconductor
heterojunctions represent an ideal platform for studying and exploiting
tunneling magnetoresistance (TMR) effects due to the versatile band structure
of semiconductors and their high-quality interfaces. In the all-vdW magnetic
tunnel junction (MTJ) devices, both the magnitude and sign of the TMR can be
tuned by an applied voltage. Typically, as the bias voltage increases, first
the amplitude of the TMR decreases, then the sign of the TMR reverses and/or
oscillates. Here, we report on an unconventional bias-dependent TMR in the
all-vdW Fe3GaTe2/GaSe/Fe3GaTe2 MTJs, where the TMR first increases, then
decreases, and finally undergoes a sign reversal as the bias voltage increases.
This dependence cannot be explained by traditional models of MTJs. We propose
an in-plane electron momentum (k//) resolved tunneling model that considers
both the coherent degree of k// and the decay of the electron wave function
through the semiconductor spacer layer. This can explain well the conventional
and unconventional bias-dependent TMR. Our results thus provide a deeper
understanding of the bias-dependent spin-transport in semiconductor-based MTJs
and offer new insights into semiconductor spintronics.",http://arxiv.org/abs/2501.08784v1
MMDocIR: Benchmarking Multi-Modal Retrieval for Long Documents,2025-01-15T14:30:13Z,"Kuicai Dong, Yujing Chang, Xin Deik Goh, Dexun Li, Ruiming Tang, Yong Liu","Multi-modal document retrieval is designed to identify and retrieve various
forms of multi-modal content, such as figures, tables, charts, and layout
information from extensive documents. Despite its significance, there is a
notable lack of a robust benchmark to effectively evaluate the performance of
systems in multi-modal document retrieval. To address this gap, this work
introduces a new benchmark, named as MMDocIR, encompassing two distinct tasks:
page-level and layout-level retrieval. The former focuses on localizing the
most relevant pages within a long document, while the latter targets the
detection of specific layouts, offering a more fine-grained granularity than
whole-page analysis. A layout can refer to a variety of elements such as
textual paragraphs, equations, figures, tables, or charts. The MMDocIR
benchmark comprises a rich dataset featuring expertly annotated labels for
1,685 questions and bootstrapped labels for 173,843 questions, making it a
pivotal resource for advancing multi-modal document retrieval for both training
and evaluation. Through rigorous experiments, we reveal that (i) visual
retrievers significantly outperform their text counterparts, (ii) MMDocIR train
set can effectively benefit the training process of multi-modal document
retrieval and (iii) text retrievers leveraging on VLM-text perform much better
than those using OCR-text. These findings underscores the potential advantages
of integrating visual elements for multi-modal document retrieval.",http://arxiv.org/abs/2501.08828v1
Dispersive vacuum as a decoherence amplifier of an Unruh-DeWitt detector,2025-01-15T14:32:32Z,"Pedro H. M. Barros, Helder A. S. Costa","Recently, interest has been growing in studies on discrete or ""pixelated""
space-time that, through modifications in the dispersion relation, can treat
the vacuum as a dispersive medium. Discrete spacetime considers that spacetime
has a cellular structure on the order of the Planck length, and if this is true
we should certainly have observable effects. In this paper, we investigated the
effects caused by the dispersive vacuum on the decoherence process of an
Unruh-DeWitt detector, our setup consists of a uniformly accelerated detector,
initially in a qubit state, which interacts with a massless scalar field during
a time interval finite. We use dispersion relations drawn from doubly special
relativity and Ho\v{r}ava-Lifshitz gravity, with these modifications the vacuum
becomes dispersive and has a corresponding refractive index. We calculate the
probability transition rates, the probability of finding the detector in the
ground state, and the quantum coherence variation. Our results indicate that
the decoherence process occurs more quickly in cases with changes in the
dispersion relation in the regime of high accelerations and interaction time.
Additionally, the decoherence increases as the vacuum becomes more dispersive
due to the increase in the order of modification in the dispersion relation,
and this happens because the dispersive vacuum amplifies the effects of quantum
fluctuations that are captured by the detector when interacting with the field.",http://arxiv.org/abs/2501.08829v1
Graph Counterfactual Explainable AI via Latent Space Traversal,2025-01-15T15:04:10Z,"Andreas Abildtrup Hansen, Paraskevas Pegios, Anna Calissano, Aasa Feragen","Explaining the predictions of a deep neural network is a nontrivial task, yet
high-quality explanations for predictions are often a prerequisite for
practitioners to trust these models. Counterfactual explanations aim to explain
predictions by finding the ''nearest'' in-distribution alternative input whose
prediction changes in a pre-specified way. However, it remains an open question
how to define this nearest alternative input, whose solution depends on both
the domain (e.g. images, graphs, tabular data, etc.) and the specific
application considered. For graphs, this problem is complicated i) by their
discrete nature, as opposed to the continuous nature of state-of-the-art graph
classifiers; and ii) by the node permutation group acting on the graphs. We
propose a method to generate counterfactual explanations for any differentiable
black-box graph classifier, utilizing a case-specific permutation equivariant
graph variational autoencoder. We generate counterfactual explanations in a
continuous fashion by traversing the latent space of the autoencoder across the
classification boundary of the classifier, allowing for seamless integration of
discrete graph structure and continuous graph attributes. We empirically
validate the approach on three graph datasets, showing that our model is
consistently high-performing and more robust than the baselines.",http://arxiv.org/abs/2501.08850v1
"Silent Abandonment in Text-Based Contact Centers: Identifying,
  Quantifying, and Mitigating its Operational Impacts",2025-01-15T15:38:56Z,"Antonio Castellanos, Galit B. Yom-Tov, Yair Goldberg, Jaeyoung Park","In the quest to improve services, companies offer customers the option to
interact with agents via texting. Such contact centers face unique challenges
compared to traditional call centers, as measuring customer experience proxies
like abandonment and patience involves uncertainty. A key source of this
uncertainty is silent abandonment, where customers leave without notifying the
system, wasting agent time and leaving their status unclear. Silent abandonment
also obscures whether a customer was served or left. Our goals are to measure
the magnitude of silent abandonment and mitigate its effects. Classification
models show that 3%-70% of customers across 17 companies abandon silently. In
one study, 71.3% of abandoning customers did so silently, reducing agent
efficiency by 3.2% and system capacity by 15.3%, incurring $5,457 in annual
costs per agent. We develop an expectation-maximization (EM) algorithm to
estimate customer patience under uncertainty and identify influencing
covariates. We find that companies should use classification models to estimate
abandonment scope and our EM algorithm to assess patience. We suggest
strategies to operationally mitigate the impact of silent abandonment by
predicting suspected silent-abandonment behavior or changing service design.
Specifically, we show that while allowing customers to write while waiting in
the queue creates a missing data challenge, it also significantly increases
patience and reduces service time, leading to reduced abandonment and lower
staffing requirements.",http://arxiv.org/abs/2501.08869v2
"Compositional dependence of magnetic damping in sputter-deposited
  CoxFe1-x thin films",2025-01-15T16:51:08Z,"Samanvaya S. Gaur, Rosa Diaz, Ernesto E. Marinero","Co25Fe75 ferromagnetic films exhibit ultralow magnetic damping. The magnetic
damping dependence of Cobalt Iron thin films over a Co composition (23 to 36%)
is here reported. The thin film structures were sputter deposited at ambient
temperature and FMR measurements in both in plane and out of plane geometries
were utilized to measure magnetic damping parameters, which include intrinsic
damping and contributions from spin pumping. The damping parameters, decrease
as the Co content is increased, except for Co31Fe69. The smallest values of
damping correspond to alloys exhibiting interface perpendicular magnetic
anisotropy. A value of 0.00091 was measured for Co36Fe64, whereas for Co31Fe69
was measured as 0.002, this composition exhibits the largest in-plane
anisotropy. HAADF-STEM cross-section analysis of the Co36Fe64 thin film stack
revealed Cu interdiffusion into the magnetic layer. The degree of
interdiffusion was found to be up to 7x higher at grain boundaries as compared
the bulk of the polycrystalline grains. The incorporation of Cu into the
ferromagnetic layer adversely impacts magnetic damping. Reducing impurities in
the magnetic layer by improving the growth chamber base pressure resulted in a
reduction of magnetic damping of 18%. The diffraction analysis revealed that
the primary growth direction of Co36Fe64 is [101] and that of Cu buffer layer
is [111], these planes are perpendicular to their respective [101] planes and
for this composition the lattice mismatch was determined to be 0.9325%. The
lattice mismatch decreases with increasing Co content and hence the lattice
strain. The diffusion of Cu into the ferromagnet creates magnon scattering
centers and local changes in magnetic properties. Both factors negatively
influence magnetic damping.",http://arxiv.org/abs/2501.08948v1
"Discretionary vs nondiscretionary in fiscal mechanism. Non-automatic
  fiscal stabilisers vs automatic fiscal stabilisers",2025-01-15T17:53:29Z,"Vasile Bratian, Amelia Bucur, Camelia Oprean, Cristina Tanasescu","The goal of the present study is to increase the intelligibility of
macroeconomic phenomena triggered by governmental intervention in economy by
means of fiscal policies. During cyclical movements, fiscal policy can play an
important role in order to help stabilise the economy. But discretionary policy
usually implies implementation lags and is not automatically reversed when
economic conditions change. In contrast, automatic fiscal stabilisers (SFA)
ensure a prompter, and self-correcting fiscal response. The present study aims
to tackle the topic of discretionary vs nondiscretionary characteristic of
fiscal stabilisers (SF). In this context, the scope of the research undertaking
is to launch a scientific debate over the definitions of the concepts of
non-automatic fiscal stabilisers (SfnA) and SFAs. We describe how we can
quantify the discretionary and non-discretionary character of the fiscal
policy, by the analysis of the structure of the conventional budget balance
(SBc), budget balance associated with the current GDP. In the final part of
this article, we propose a quantitative equilibrium model for establishing the
mathematical prerequisites for an SF to become automatic. Likewise, on the
basis of the proposed mathematical model we have performed a qualitative
analysis of the influence factors.",http://arxiv.org/abs/2501.08981v1
"Landauer resistivity dipole at one dimensional defect revealed via
  near-field photocurrent nanoscopy",2025-01-15T20:02:33Z,"Francesca Falorsi, Marco Dembecki, Christian Eckel, Monica Kolek Martinez de Azagra, Kenji Watanabe, Takashi Taniguchi, Martin Statz, R. Thomas Weitz","The fundamental question how to describe Ohmic resistance at the nanoscale
has been answered by Landauer in his seminal picture of the so-called Landauer
resistivity dipole. This picture has been theoretically well understood,
however experimentally there are only few studies due to the need for a
non-invasive local probe. Here we use the nanometer lateral resolution of
near-field photocurrent imaging to thoroughly characterize a buried monolayer -
bilayer graphene interface as an ideal one dimensional defect for the Landauer
resistivity dipole. Via systematic tuning of the overall charge carrier density
and the current flow we are able to detect the formation of Landauer
resistivity dipoles due to charge carrier accumulation around the one
dimensional defects. We found that, for Fermi energy values near the charge
neutrality point (i.e. at low hole or electron doping), the photocurrent
exhibits the same polarity as the applied source-drain voltage, which is
consistent with changes in carrier concentration induced by the Landauer
resistivity dipoles. This signature is no longer evident at higher charge
carrier density in agreement with the performed numerical calculations.
Photocurrent nanoscopy can thus serve as non-invasive technique to study local
dissipation at hidden interfaces.",http://arxiv.org/abs/2501.09124v1
"A Dynamic Unmanned Aerial Vehicle Routing Framework for Urban Traffic
  Monitoring",2025-01-16T02:20:25Z,"Yumeng Bai, Yiheng Feng","Unmanned Aerial Vehicles (UAVs) have great potential in urban traffic
monitoring due to their rapid speed, cost-effectiveness, and extensive
field-of-view, while being unconstrained by traffic congestion. However, their
limited flight duration presents critical challenges in sustainable recharging
strategies and efficient route planning in long-term monitoring tasks.
Additionally, existing approaches for long-term monitoring often neglect the
evolving nature of urban traffic networks. In this study, we introduce a novel
dynamic UAV routing framework for long-term, network-wide urban traffic
monitoring, leveraging existing ground vehicles as mobile charging stations
without disrupting their operations. To address the complexity of long-term
monitoring scenarios involving multiple flights, we decompose the problem into
manageable single-flight tasks, in which each flight is modeled as a Team Arc
Orienteering Problem with Decreasing Profits with the objective to collectively
maximize the spatiotemporal network coverage. Between flights, we adaptively
update the edge weights to incorporate real-time traffic changes and revisit
intervals. We validate our framework through extensive microscopic simulations
in a modified Sioux Falls network under various scenarios. Comparative results
demonstrate that our model outperforms three baseline approaches, especially
when historical information is incomplete or absent. Moreover, we show that our
monitoring framework can capture network-wide traffic trends and construct
accurate Macroscopic Fundamental Diagrams (MFDs). These findings demonstrate
the effectiveness of the proposed dynamic UAV routing framework, underscoring
its suitability for efficient and reliable long-term traffic monitoring. Our
approach's adaptability and high accuracy in capturing the MFD highlight its
potential in network-wide traffic control and management applications.",http://arxiv.org/abs/2501.09249v1
"Interoceptive Robots for Convergent Shared Control in Collaborative
  Construction Work",2025-01-16T04:50:15Z,"Xiaoshan Zhou, Carol C. Menassa, Vineet R. Kamat","Building autonomous mobile robots (AMRs) with optimized efficiency and
adaptive capabilities-able to respond to changing task demands and dynamic
environments-is a strongly desired goal for advancing construction robotics.
Such robots can play a critical role in enabling automation, reducing
operational carbon footprints, and supporting modular construction processes.
Inspired by the adaptive autonomy of living organisms, we introduce
interoception, which centers on the robot's internal state representation, as a
foundation for developing self-reflection and conscious learning to enable
continual learning and adaptability in robotic agents. In this paper, we
factorize internal state variables and mathematical properties as ""cognitive
dissonance"" in shared control paradigms, where human interventions occasionally
occur. We offer a new perspective on how interoception can help build adaptive
motion planning in AMRs by integrating the legacy of heuristic costs from
grid/graph-based algorithms with recent advances in neuroscience and
reinforcement learning. Declarative and procedural knowledge extracted from
human semantic inputs is encoded into a hypergraph model that overlaps with the
spatial configuration of onsite layout for path planning. In addition, we
design a velocity-replay module using an encoder-decoder architecture with
few-shot learning to enable robots to replicate velocity profiles in
contextualized scenarios for multi-robot synchronization and handover
collaboration. These ""cached"" knowledge representations are demonstrated in
simulated environments for multi-robot motion planning and stacking tasks. The
insights from this study pave the way toward artificial general intelligence in
AMRs, fostering their progression from complexity to competence in construction
automation.",http://arxiv.org/abs/2501.09290v1
"High-speed readout for direct light orbital angular momentum
  photodetector via photoelastic modulation",2025-01-16T05:06:58Z,"Dehong Yang, Chang Xu, Jiawei Lai, Zipu Fan, Delang Liang, Shiyu Wang, Jinluo Cheng, Dong Sun","Recent progress in direct photodetection of light orbital angular momentum
(OAM) based on the orbital photogalvanic effect (OPGE) provides an effective
way for on-chip direct electric readout of orbital angular momentum, as well as
large-scale integration focal-plane array devices. However, the recognition of
OAM order from photocurrent response requires the extraction of circular
polarization-dependent response. To date, the operation speed of such detector
is currently at the minute level and is limited by slow mechanical polarization
modulation and low OAM recognition capability. In this work, we demonstrate
that the operation speed can be greatly improved via electrical polarization
modulation strategy with photoelasitc modulator accompanied by phase-locked
readout approach with lock-in amplifier. We demonstrate an operation speed of
up to 1 kHz with this new technology in the mid-infrared region (4 {\mu}m) on
an OAM detector using multilayer graphene (MLG) as photosensitive material. In
principle, with new modulation and readout scheme, we can potentially increase
the operation speed to 50.14 kHz with a PEM that operates at a state-of-the-art
speed. Our work paves the way toward high-speed operation of direct OAM
detection devices based on OPGE effect and pushes such technology to a more
practical stage for focal plane array applications.",http://arxiv.org/abs/2501.09297v1
"Community attitudes towards the environmental cost of computational
  fluid dynamics research",2025-01-16T06:13:46Z,"Miranda van Heel, Jack R. C. King","Numerical simulations underpin much fluid dynamics research today. Such
simulations often rely on large scale high performance computing (HPC) systems,
and have a significant carbon footprint. Increasing the efficiency of data
centers or the proportion of electricity coming from renewable sources can
lessen the environmental impact of scientific computing to a degree, but the
attitudes of researchers also play a role. There are many choices researchers
make which influence the carbon footprint of simulations. To change behaviours
around simulation use, it is first necessary to understand attitudes toward
them. Here, we present a case study on fluid dynamics researchers based in the
University of Manchester, UK. We find a low awareness of the carbon footprint
of computations, compounded by a lack of knowledge of the specific hardware
used to run simulations. There is a discrepancy between researchers
self-declared attitudes towards reducing the carbon footprint of their work,
and their actions and choices. Overall, researchers did not consider carbon
footprint as important in their decision making, and we found no correlation
between the impact and carbon cost of simulations. Improved education and
awareness of the environmental impact of simulations is imperative in the
interests of the sustainability of this field.",http://arxiv.org/abs/2501.09314v2
"A Novel Simulation Approach for Evaporation Processes in Small Gaps of
  Industrial Applications",2025-01-16T07:32:42Z,"Phil Namesnik, Alexander Eifert, Anja Lippert, Tobias Tolle, Louis Mett, Uwe Janoske","Long liquid retention times in industrial gaps, due to capillary effects,
significantly affect product lifetime by facilitating corrosion on solid
surfaces. Concentration-driven evaporation plays a major role in mitigating
this corrosion. Accurate evaporation rate predictions are crucial for improved
product design. However, simulating capillary-driven flows with evaporation in
complex geometries is challenging, requiring consideration of surface tension,
wetting, and phase-change effects. Traditional approaches, such as the
Volume-of-Fluid method, are prone to curvature calculation errors and have long
simulation times due to strict time step limitations. This study introduces a
novel semi-transient simulation approach for fast evaporation rate prediction
in arbitrarily shaped cavities. The approach involves a unidirectional coupling
circuit, simulating the fluid surface in Surface Evolver and combining it with
a vapor-in-gas diffusion simulation in OpenFOAM. The approach assumes that the
evaporation rate is calculated solely based on the conditions at a given liquid
filling level, without considering the evaporation history. This allows for
highly parallelized simulations, achieving simulation runtimes in the order of
10 minutes to cover up to 150 hours of physical time. Numerical investigations
are conducted for water evaporation in air at a temperature of 23{\deg}C and a
relative humidity of 17%, for round and polygonal-shaped capillaries with inner
diameters ranging from 1 mm to 13 mm. The results are validated using
experimental data and show strong agreement. Simulations are also performed for
complex industrial relevant gaps, demonstrating the applicability of the
approach to a wide range of crevice geometries.",http://arxiv.org/abs/2501.09337v1
"SE-BSFV: Online Subspace Learning based Shadow Enhancement and
  Background Suppression for ViSAR under Complex Background",2025-01-16T07:50:56Z,"Shangqu Yan, Chenyang Luo, Yaowen Fu, Wenpeng Zhang, Wei Yang, Ruofeng Yu","Video synthetic aperture radar (ViSAR) has attracted substantial attention in
the moving target detection (MTD) field due to its ability to continuously
monitor changes in the target area. In ViSAR, the moving targets' shadows will
not offset and defocus, which is widely used as a feature for MTD. However, the
shadows are difficult to distinguish from the low scattering region in the
background, which will cause more missing and false alarms. Therefore, it is
worth investigating how to enhance the distinction between the shadows and
background. In this study, we proposed the Shadow Enhancement and Background
Suppression for ViSAR (SE-BSFV) algorithm. The SE-BSFV algorithm is based on
the low-rank representation (LRR) theory and adopts online subspace learning
technique to enhance shadows and suppress background for ViSAR images. Firstly,
we use a registration algorithm to register the ViSAR images and utilize
Gaussian mixture distribution (GMD) to model the ViSAR data. Secondly, the
knowledge learned from the previous frames is leveraged to estimate the GMD
parameters of the current frame, and the Expectation-maximization (EM)
algorithm is used to estimate the subspace parameters. Then, the foreground
matrix of the current frame can be obtained. Finally, the alternating direction
method of multipliers (ADMM) is used to eliminate strong scattering objects in
the foreground matrix to obtain the final results. The experimental results
indicate that the SE-BSFV algorithm significantly enhances the shadows'
saliency and greatly improves the detection performance while ensuring
efficiency compared with several other advanced pre-processing algorithms.",http://arxiv.org/abs/2501.09341v1
Maxwell-$f(Q)$ theory,2025-01-16T08:37:02Z,G. G. L. Nashed,"Exploring the four-dimensional AdS black hole is crucial within the framework
of the AdS/CFT correspondence. In this research, considering the charged
scenario, we investigate the four-dimensional stationary and rotating AdS
solutions in the framework of the $f(Q)$ gravitational theory. Our emphasis is
on the power-law ansatz, which is consistent with observations and is deemed
the most viable. Because this solution does not have an uncharged version or
relate to general relativity, it falls into a new category, which derives its
features from changes in non-metricity and incorporates the Maxwell domain. We
analyze the singularities of such a solution, computing all the quantities of
different curvature and non-metricity invariants. Our results indicate the
presence of a central singularity, albeit with a softer nature compared to
standard non-metricity or Einstein general relativity, attributed to the
influence of the effect of $f(Q)$. We examine several physical characteristics
of black holes from a thermodynamics perspective and demonstrate the existence
of an outer event horizon in addition to the inner Cauchy horizons. However,
under the conditions of a sufficiently large electric charge, a naked
singularity emerges. Finally, we derive a class of rotating black hole in
four-dimensional $f(Q)$ gravity that are asymptotically anti-de Sitter charged.",http://arxiv.org/abs/2501.09373v1
"Joint Transmission and Deblurring: A Semantic Communication Approach
  Using Events",2025-01-16T09:07:01Z,"Pujing Yang, Guangyi Zhang, Yunlong Cai, Lei Yu, Guanding Yu","Deep learning-based joint source-channel coding (JSCC) is emerging as a
promising technology for effective image transmission. However, most existing
approaches focus on transmitting clear images, overlooking real-world
challenges such as motion blur caused by camera shaking or fast-moving objects.
Motion blur often degrades image quality, making transmission and
reconstruction more challenging. Event cameras, which asynchronously record
pixel intensity changes with extremely low latency, have shown great potential
for motion deblurring tasks. However, the efficient transmission of the
abundant data generated by event cameras remains a significant challenge. In
this work, we propose a novel JSCC framework for the joint transmission of
blurry images and events, aimed at achieving high-quality reconstructions under
limited channel bandwidth. This approach is designed as a deblurring
task-oriented JSCC system. Since RGB cameras and event cameras capture the same
scene through different modalities, their outputs contain both shared and
domain-specific information. To avoid repeatedly transmitting the shared
information, we extract and transmit their shared information and
domain-specific information, respectively. At the receiver, the received
signals are processed by a deblurring decoder to generate clear images.
Additionally, we introduce a multi-stage training strategy to train the
proposed model. Simulation results demonstrate that our method significantly
outperforms existing JSCC-based image transmission schemes, addressing motion
blur effectively.",http://arxiv.org/abs/2501.09396v1
"Fast Searching of Extreme Operating Conditions for Relay Protection
  Setting Calculation Based on Graph Neural Network and Reinforcement Learning",2025-01-16T09:11:48Z,"Yan Li, Jingyu Wang, Jiankang Zhang, Huaiqiang Li, Longfei Ren, Yinhong Li, Dongyuan Shi, Xianzhong Duan","Searching for the Extreme Operating Conditions (EOCs) is one of the core
problems of power system relay protection setting calculation. The current
methods based on brute-force search, heuristic algorithms, and mathematical
programming can hardly meet the requirements of today's power systems in terms
of computation speed due to the drastic changes in operating conditions induced
by renewables and power electronics. This paper proposes an EOC fast search
method, named Graph Dueling Double Deep Q Network (Graph D3QN), which combines
graph neural network and deep reinforcement learning to address this challenge.
First, the EOC search problem is modeled as a Markov decision process, where
the information of the underlying power system is extracted using graph neural
networks, so that the EOC of the system can be found via deep reinforcement
learning. Then, a two-stage Guided Learning and Free Exploration (GLFE)
training framework is constructed to accelerate the convergence speed of
reinforcement learning. Finally, the proposed Graph D3QN method is validated
through case studies of searching maximum fault current for relay protection
setting calculation on the IEEE 39-bus and 118-bus systems. The experimental
results demonstrate that Graph D3QN can reduce the computation time by 10 to
1000 times while guaranteeing the accuracy of the selected EOCs.",http://arxiv.org/abs/2501.09399v1
"Mixed atomic-scale electronic configuration as a strategy to avoid
  cocatalyst utilization in photocatalysis by high-entropy oxides",2025-01-16T10:14:07Z,"Jacqueline Hidalgo-Jiménez, Taner Akbay, Xavier Sauvage, Tatsumi Ishihara, Kaveh Edalati","To enhance the activity of photocatalysts for hydrogen production and CO2
conversion, noble metal cocatalysts as electron traps and/or acceptors such as
platinum or gold are usually utilized. This study hypothesizes that mixing
elements with heterogeneous electronic configurations and diverse
electronegativities can provide both acceptor and donor sites of electrons to
avoid using cocatalysts. This hypothesis was examined in high-entropy oxides
(HEOs), which show high flexibility for atomic-scale compositional changes by
keeping their single-or dual-phase structure. A new highentropy oxide was
designed and synthesized by mixing elements with an empty d orbital (titanium,
zirconium, niobium and tantalum) and a fully occupied d orbital (gallium). The
oxide, synthesized by high-pressure torsion followed by calcination, had two
phases (88 wt% orthorhombic (Pbcn) and 12 wt% monoclinic (I2/m)) with an
overall composition of TiZrNbTaGaO10.5. It exhibited UV and visible light
absorbance with a low bandgap of 2.5 eV, low radiative electron-hole
recombination and oxygen vacancy generation due to mixed valences of cations.
It successfully acted as a photocatalyst for CO and CH4 production from CO2
conversion and hydrogen production from water splitting without cocatalyst
addition. These findings confirm that introducing heterogeneous electronic
configurations and electronegativities can be considered as a design criterion
to avoid the need to use cocatalysts.",http://arxiv.org/abs/2501.09441v1
An Asymptotic Analysis of Bivalent Monoclonal Antibody-Antigen Binding,2025-01-16T11:23:55Z,"Luke A Heirene, Helen M Byrne, James W T Yates, Eamonn A Gaffney","Ligand-receptor interactions are fundamental to many biological processes.
For example in antibody-based immunotherapies, the dynamics of an antibody
binding with its target antigen directly influence the potency and efficacy of
monoclonal antibody (mAb) therapies. In this paper, we present an asymptotic
analysis of an ordinary differential equation (ODE) model of bivalent
antibody-antigen binding in the context of mAb cancer therapies, highlighting
the added complexity associated with bivalency of the antibody. To understand
what drives the complex temporal dynamics of bivalent antibody-antigen binding,
we construct asymptotic approximations to the model's solutions at different
timescales and antibody concentrations that are in good agreement with
numerical simulations of the full model. We show how the dynamics differ
between two scenarios; a region where unbound antigens are abundant, and one
where the number of unbound antigens is small such that the dominant balance
within the model equations changes. Of particular importance to the potency and
efficacy of mAb treatments are the values of quantities such as antigen
occupancy and bound antibody number. We use the results of our asymptotic
analysis to approximate the long-time values of these quantities that could be
combined with experimental data to facilitate parameter estimation.",http://arxiv.org/abs/2501.09473v1
"Spectro-polarimetry of GRB 180427A: evidence for distinct emission sites
  with varying polarisation",2025-01-16T12:02:16Z,"Rushikesh Sonawane, Shabnam Iyyani, Soumya Gupta, Tanmoy Chattopadhyay, Dipankar Bhattacharya, Varun. B. Bhalerao, Santosh V. Vadawale, G. C. Dewangan","The dynamics of the origin of gamma-ray emissions in gamma-ray bursts (GRBs)
remains an enigma. Through a joint analysis of GRB 180427A, observed by the
Fermi Gamma-ray Space Telescope and AstroSat's Cadmium Zinc Telluride Imager,
we identify emissions from two distinct regions with varying polarisation
properties. Time-resolved polarisation analysis reveals a synchronous evolution
of the polarisation angle (PA) and fraction (PF) with two emission pulses,
peaking with a delay of $4.82 \pm 0.12\, \mathrm{s}$. Spectral analysis
indicates that the first pulse is dominated by blackbody radiation, while the
second pulse exhibits a non-thermal spectrum (power law with an exponential
cutoff). Using a bottom-to-top approach through simulations, we decouple the
polarisation properties of the individual spectral components, revealing
polarisation fractions of 25\% - 40\% for the blackbody spectrum and 30\% -
60\% for the non-thermal spectrum. At a redshift of $z \sim 0.05$, the
blackbody emission originates from the jet photosphere at $10^{11}\,
\mathrm{cm}$, whereas the non-thermal emission arises from an optically thin
region at $10^{15}\, \mathrm{cm}$. The changing dominance of these emissions
explains the observed PA shift of $60^\circ \pm 22.3^\circ$. The spectral
cutoff at 1 MeV suggests pair opacity due to the jet's low bulk Lorentz factor
($\Gamma \sim$ tens). The high polarisation and hard spectral slopes ($\alpha >
-0.5$) imply a top-hat jet structure observed off-axis, near the jet's edge.
This off-axis viewing introduces anisotropy in the radiation within the viewing
cone ($1/\Gamma$), accounting for the observed polarisation.",http://arxiv.org/abs/2501.09492v1
"Local US officials' views on the impacts and governance of AI: Evidence
  from 2022 and 2023 survey waves",2025-01-16T15:25:58Z,"Sophia Hatz, Noemi Dreksler, Kevin Wei, Baobao Zhang","This paper presents a survey of local US policymakers' views on the future
impact and regulation of AI. Our survey provides insight into US policymakers'
expectations regarding the effects of AI on local communities and the nation,
as well as their attitudes towards specific regulatory policies. Conducted in
two waves (2022 and 2023), the survey captures changes in attitudes following
the release of ChatGPT and the subsequent surge in public awareness of AI.
Local policymakers express a mix of concern, optimism, and uncertainty about
AI's impacts, anticipating significant societal risks such as increased
surveillance, misinformation, and political polarization, alongside potential
benefits in innovation and infrastructure. Many also report feeling
underprepared and inadequately informed to make AI-related decisions. On
regulation, a majority of policymakers support government oversight and favor
specific policies addressing issues such as data privacy, AI-related
unemployment, and AI safety and fairness. Democrats show stronger and more
consistent support for regulation than Republicans, but the latter experienced
a notable shift towards majority support between 2022 and 2023. Our study
contributes to understanding the perspectives of local policymakers-key players
in shaping state and federal AI legislation-by capturing evolving attitudes,
partisan dynamics, and their implications for policy formation. The findings
highlight the need for capacity-building initiatives and bi-partisan
coordination to mitigate policy fragmentation and build a cohesive framework
for AI governance in the US.",http://arxiv.org/abs/2501.09606v1
"Unitary Expressions: A Necessary Abstraction for Extensible Quantum
  Programming Languages and Systems",2025-01-16T17:05:41Z,Ed Younis,"Quantum gates are the fundamental instructions of digital quantum computers.
Current programming languages, systems, and software development toolkits
identify these operational gates by their titles, which requires a shared
understanding of their meanings. However, in the continuously developing
software ecosystem surrounding quantum computing -- spanning high-level
programming systems to low-level control stacks -- this identification process
is often error-prone, challenging to debug, maintenance-heavy, and resistant to
change. In this paper, we propose replacing this nominal gate representation
with a functional one. We introduce the OpenQudit system for describing,
parsing, optimizing, analyzing, and utilizing programs comprising gates
described as symbolic unitary expressions. As part of this effort, we design
the Qudit Gate Language (QGL), a unitary-specific expression language, and
implement a differentiating just-in-time compiler in OpenQudit towards
embedding this language in quantum programming languages and systems.
Additionally, we have precisely designed and implemented the Qudit Virtual
Machine (QVM) to evaluate quantum programs and their gradients efficiently.
This evaluation is performed millions of times during the compilation of
quantum programs. Our QVM can compute gradients approximately ten times faster
than current leading numerical quantum compilation frameworks in the most
common use cases. Altogether, the OpenQudit system is envisioned to (1) support
many-level or qudit-based quantum systems, (2) enable the safe composition of
program transformation tools, (3) accelerate circuit optimizers and
transpilers, (4) enable compiler extensibility, and (5) provide a productive,
simple-to-use interface to quantum practitioners.",http://arxiv.org/abs/2501.09667v1
Data mining the functional architecture of the brain's circuitry,2025-01-16T17:37:09Z,Adam S. Charles,"The brain is a highly complex organ consisting of a myriad of subsystems that
flexibly interact and adapt over time and context to enable perception,
cognition, and behavior. Understanding the multi-scale nature of the brain,
i.e., how circuit- and moleclular-level interactions build up the fundamental
components of brain function, holds incredible potential for developing
interventions for neurodegenerative and psychiatric diseases, as well as open
new understanding into our very nature. Historically technological limitations
have forced systems neuroscience to be local in anatomy (localized, small
neural populations in single brain areas), in behavior (studying single tasks),
in time (focusing on specific stages of learning or development), and in
modality (focusing on imaging single biological quantities). New developments
in neural recording technology and behavioral monitoring now provide the data
needed to break free of local neuroscience to global neuroscience: i.e.,
understanding how the brain's many subsystem interact, adapt, and change across
the multitude of behaviors animals and humans must perform to thrive.
Specifically, while we have much knowledge of the anatomical architecture of
the brain (i.e., the hardware), we finally are approaching the data needed to
find the functional architecture and discover the fundamental properties of the
software that runs on the hardware. We must take this opportunity to bridge
between the vast amounts of data to discover this functional architecture which
will face numerous challenges from low-level data alignment up to high level
questions of interpretable mathematical models of behavior that can synthesize
the myriad of datasets together.",http://arxiv.org/abs/2501.09684v1
Intelligent OLSR Routing Protocol Optimization for VANETs,2025-01-16T18:05:28Z,"Jamal Toutouh, José García-Nieto, Enrique Alba","Recent advances in wireless technologies have given rise to the emergence of
vehicular ad hoc networks (VANETs). In such networks, the limited coverage of
WiFi and the high mobility of the nodes generate frequent topology changes and
network fragmentations. For these reasons, and taking into account that there
is no central manager entity, routing packets through the network is a
challenging task. Therefore, offering an efficient routing strategy is crucial
to the deployment of VANETs. This paper deals with the optimal parameter
setting of the optimized link state routing (OLSR), which is a well-known
mobile ad hoc network routing protocol, by defining an optimization problem.
This way, a series of representative metaheuristic algorithms (particle swarm
optimization, differential evolution, genetic algorithm, and simulated
annealing) are studied in this paper to find automatically optimal
configurations of this routing protocol. In addition, a set of realistic VANET
scenarios (based in the city of M\'alaga) have been defined to accurately
evaluate the performance of the network under our automatic OLSR. In the
experiments, our tuned OLSR configurations result in better quality of service
(QoS) than the standard request for comments (RFC 3626), as well as several
human experts, making it amenable for utilization in VANET configurations.",http://arxiv.org/abs/2501.09716v1
"Suggesting Code Edits in Interactive Machine Learning Notebooks Using
  Large Language Models",2025-01-16T18:55:38Z,"Bihui Jin, Jiayue Wang, Pengyu Nie","Machine learning developers frequently use interactive computational
notebooks, such as Jupyter notebooks, to host code for data processing and
model training. Jupyter notebooks provide a convenient tool for writing machine
learning pipelines and interactively observing outputs, however, maintaining
Jupyter notebooks, e.g., to add new features or fix bugs, can be challenging
due to the length and complexity of the notebooks. Moreover, there is no
existing benchmark related to developer edits on Jupyter notebooks. To address
this, we present the first dataset of 48,398 Jupyter notebook edits derived
from 20,095 revisions of 792 machine learning repositories on GitHub, and
perform the first study of the using LLMs to predict code edits in Jupyter
notebooks. Our dataset captures granular details of cell-level and line-level
modifications, offering a foundation for understanding real-world maintenance
patterns in machine learning workflows. We observed that the edits on Jupyter
notebooks are highly localized, with changes averaging only 166 lines of code
in repositories. While larger models outperform smaller counterparts in code
editing, all models have low accuracy on our dataset even after finetuning,
demonstrating the complexity of real-world machine learning maintenance tasks.
Our findings emphasize the critical role of contextual information in improving
model performance and point toward promising avenues for advancing large
language models' capabilities in engineering machine learning code.",http://arxiv.org/abs/2501.09745v1
VideoWorld: Exploring Knowledge Learning from Unlabeled Videos,2025-01-16T18:59:10Z,"Zhongwei Ren, Yunchao Wei, Xun Guo, Yao Zhao, Bingyi Kang, Jiashi Feng, Xiaojie Jin","This work explores whether a deep generative model can learn complex
knowledge solely from visual input, in contrast to the prevalent focus on
text-based models like large language models (LLMs). We develop VideoWorld, an
auto-regressive video generation model trained on unlabeled video data, and
test its knowledge acquisition abilities in video-based Go and robotic control
tasks. Our experiments reveal two key findings: (1) video-only training
provides sufficient information for learning knowledge, including rules,
reasoning and planning capabilities, and (2) the representation of visual
change is crucial for knowledge acquisition. To improve both the efficiency and
efficacy of this process, we introduce the Latent Dynamics Model (LDM) as a key
component of VideoWorld. Remarkably, VideoWorld reaches a 5-dan professional
level in the Video-GoBench with just a 300-million-parameter model, without
relying on search algorithms or reward mechanisms typical in reinforcement
learning. In robotic tasks, VideoWorld effectively learns diverse control
operations and generalizes across environments, approaching the performance of
oracle models in CALVIN and RLBench. This study opens new avenues for knowledge
acquisition from visual data, with all code, data, and models open-sourced for
further research.",http://arxiv.org/abs/2501.09781v1
"On the seismic modelling of subgiant stars: testing different grid
  interpolation methods",2025-01-16T19:43:06Z,"Miguel Clara, Margarida S. Cunha, Pedro P. Avelino, Tiago L. Campante, Sébastien Deheuvels, Daniel R. Reese","Context. The emergence of mixed modes during the subgiant phase, whose
frequencies are characterized by a fast evolution with age, can potentially
enable a precise determination of stellar properties, a key goal for future
missions like PLATO. However, current modelling techniques often consider grids
that lack the resolution to properly account for the fast mode frequency
evolution, consequently requiring the use of interpolation algorithms to cover
the parameter space in between the grid models when applying model-data
comparison methods. Aims. We aim at reproducing the $\ell$=1 mode frequencies
within the accuracy limits associated with the typical observational errors
($\sim$0.1 $\mu$Hz) through interpolation on a grid of subgiant models.
Methods. With that aim, we used variations of a two-step interpolation
algorithm, which considered linear and cubic splines interpolation methods and
different age proxies (physical age, scaled age, and central density). Results.
The best results were obtained using an algorithm that considers cubic splines
interpolation along tracks, linear interpolation across tracks, and central
density $\rho_\text{c}$ as the age proxy. This combination yielded, on average,
an absolute error of 0.14 $\mu$Hz, but reached maximum absolute errors on the
interpolated frequencies of 1.2 $\mu$Hz for some models, which is an order of
magnitude higher than the typical observational errors. Furthermore, we
investigated the impact on the accuracy of the interpolation from changes in
the physical properties of the stars, showing, in particular, how the addition
of core overshoot can affect significantly the interpolation results.",http://arxiv.org/abs/2501.09809v1
"IE-Bench: Advancing the Measurement of Text-Driven Image Editing for
  Human Perception Alignment",2025-01-17T02:47:25Z,"Shangkun Sun, Bowen Qu, Xiaoyu Liang, Songlin Fan, Wei Gao","Recent advances in text-driven image editing have been significant, yet the
task of accurately evaluating these edited images continues to pose a
considerable challenge. Different from the assessment of text-driven image
generation, text-driven image editing is characterized by simultaneously
conditioning on both text and a source image. The edited images often retain an
intrinsic connection to the original image, which dynamically change with the
semantics of the text. However, previous methods tend to solely focus on
text-image alignment or have not aligned with human perception. In this work,
we introduce the Text-driven Image Editing Benchmark suite (IE-Bench) to
enhance the assessment of text-driven edited images. IE-Bench includes a
database contains diverse source images, various editing prompts and the
corresponding results different editing methods, and total 3,010 Mean Opinion
Scores (MOS) provided by 25 human subjects. Furthermore, we introduce IE-QA, a
multi-modality source-aware quality assessment method for text-driven image
editing. To the best of our knowledge, IE-Bench offers the first IQA dataset
and model tailored for text-driven image editing. Extensive experiments
demonstrate IE-QA's superior subjective-alignments on the text-driven image
editing task compared with previous metrics. We will make all related data and
code available to the public.",http://arxiv.org/abs/2501.09927v1
"Metamorphic Testing for Smart Contract Validation:A Case Study of
  Ethereum-Based Crowdfunding Contracts",2025-01-17T05:04:23Z,"Irving Jared Villanueva, Madhusudan Srinivasan, Faqeer Ur Rehman","Blockchain smart contracts play a crucial role in automating and securing
agreements in diverse domains such as finance, healthcare, and supply chains.
Despite their critical applications, testing these contracts often receives
less attention than their development, leaving significant risks due to the
immutability of smart contracts post-deployment. A key challenge in the testing
of smart contracts is the oracle problem, where the exact expected outcomes are
not well defined, complicating systematic testing efforts.
  Metamorphic Testing (MT) addresses the oracle problem by using Metamorphic
Relations (MRs) to validate smart contracts. MRs define how output should
change relative to specific input modifications, determining whether the tests
pass or fail. In this work, we apply MT to test an Ethereum-based crowdfunding
smart contract, focusing on core functionalities such as state transitions and
donation tracking.
  We identify a set of MRs tailored for smart contract testing and generate
test cases for these MRs. To assess the effectiveness of this approach, we use
the Vertigo mutation testing tool to create faulty versions of the smart
contract. The experimental results show that our MRs detected 25.65% of the
total mutants generated, with the most effective MRs achieving a mutant-killing
rate of 89%. These results highlight the utility of MT to ensure the
reliability and quality of blockchain-based smart contracts.",http://arxiv.org/abs/2501.09955v1
"Giant topological Hall effect in epitaxial
  Ni$_{80}$Fe$_{20}$/La$_{0.65}$Sr$_{0.35}$MnO$_3$ thin film heterostructures",2025-01-17T06:27:10Z,"Kusampal Yadav, Dilruba Hasina, Nasiruddin Mondal, Sayantika Bhowal, Devajyoti Mukherjee","The emergence of new physical properties at the interfaces between complex
oxides has always been of both fundamental and practical importance. Here, we
report the observation of a giant topological Hall resistivity of $\sim 2.8 \mu
\Omega$ \text{cm} at room temperature in an epitaxial thin-film heterostructure
of permalloy (Py, Ni$_{80}$Fe$_{20}$) and the half-metallic ferromagnet
La$_{0.65}$Sr$_{0.35}$MnO$_3$ (LSMO). This large magnitude of the topological
Hall effect in the Py/LSMO heterostructure, compared to a single-layer Py thin
film, is attributed to the optimized combination of ferromagnetism in LSMO and
the strong spin-orbit-coupling-driven Rashba interaction at the interface. The
introduction of a ferroelectric BaTiO$_3$ (BTO) sandwich layer in the Py/LSMO
heterostructure also leads to an enhanced topological Hall resistivity compared
to the single-layer Py thin film. Interestingly, magnetic force microscopy
measurements reveal skyrmion-like features, suggesting the origin of the
topological Hall effect. Our theoretical model calculations for the skyrmion
lattice further indicate that the Rashba interaction, driven by the broken
inversion symmetry in the Py/LSMO films, can account for the observed changes
in the topological Hall effect at the interface. Our work opens the door for
the potential use of Py/LSMO thin films in spintronic applications.",http://arxiv.org/abs/2501.09969v1
"LWGANet: A Lightweight Group Attention Backbone for Remote Sensing
  Visual Tasks",2025-01-17T08:56:17Z,"Wei Lu, Si-Bao Chen, Chris H. Q. Ding, Jin Tang, Bin Luo","Remote sensing (RS) visual tasks have gained significant academic and
practical importance. However, they encounter numerous challenges that hinder
effective feature extraction, including the detection and recognition of
multiple objects exhibiting substantial variations in scale within a single
image. While prior dual-branch or multi-branch architectural strategies have
been effective in managing these object variances, they have concurrently
resulted in considerable increases in computational demands and parameter
counts. Consequently, these architectures are rendered less viable for
deployment on resource-constrained devices. Contemporary lightweight backbone
networks, designed primarily for natural images, frequently encounter
difficulties in effectively extracting features from multi-scale objects, which
compromises their efficacy in RS visual tasks. This article introduces LWGANet,
a specialized lightweight backbone network tailored for RS visual tasks,
incorporating a novel lightweight group attention (LWGA) module designed to
address these specific challenges. LWGA module, tailored for RS imagery,
adeptly harnesses redundant features to extract a wide range of spatial
information, from local to global scales, without introducing additional
complexity or computational overhead. This facilitates precise feature
extraction across multiple scales within an efficient framework.LWGANet was
rigorously evaluated across twelve datasets, which span four crucial RS visual
tasks: scene classification, oriented object detection, semantic segmentation,
and change detection. The results confirm LWGANet's widespread applicability
and its ability to maintain an optimal balance between high performance and low
complexity, achieving SOTA results across diverse datasets. LWGANet emerged as
a novel solution for resource-limited scenarios requiring robust RS image
processing capabilities.",http://arxiv.org/abs/2501.10040v1
The role of dry mergers in shaping the scaling relations of galaxies,2025-01-17T09:07:18Z,"Mauro D'Onofrio, Cesare Chiosi, Francesco Brevi","In the context of the hierarchical formation of galaxies, we investigated the
role played by mergers in shaping the scaling relations of galaxies, that is
the projections of their Fundamental Plane onto the Ie-Re, Ie-Sigma, Ms-Re and
L-Sigma planes. To this aim, based on the scalar Virial Theorem, we developed a
simple theory of multiple dry mergers to read both the large scale simulations
and the companion scaling relations. The aim was to compare the results of this
approach with the observational data and with two of the most recent and
detailed numerical cosmo-hydro-dynamical simulations, that is Illustris-TNG and
EAGLE (Evolution and Assembly of GaLaxies and their Environments). We derived
the above scaling relations for the galaxies of the MaNGA (Mapping Nearby
Galaxies at APO) and WINGS (Wide-field Imaging of Nearby Galaxy-Clusters
Survey) databases and compared them with the observational data, the numerical
simulations, and the results of our simple theory of dry mergers. The multiple
dry merging mechanism is able to explain all the main characteristics of the
observed scaling relations of galaxies, such as slopes, scatters, curvatures
and zones of exclusion. The distribution of galaxies in these planes is
continuously changing across time because of the merging activity and other
physical processes, such as star formation, quenching, energy feedback, and so
forth. The simple merger theory presented here yields the correct distribution
of galaxies in the main scaling relations at all cosmic epochs. The precision
is comparable with that obtained by the modern cosmo-hydro-dynamical
simulations, with the advantage of providing a rapid exploratory response on
the consequences engendered by different physical effects.",http://arxiv.org/abs/2501.10047v1
"Two-level Solar Irradiance Clustering with Season Identification: A
  Comparative Analysis",2025-01-17T10:05:11Z,"Roshni Agrawal, Sivakumar Subramanian, Venkataramana Runkana","Solar irradiance clustering can enhance solar power capacity planning and
help improve forecasting models by identifying similar irradiance patterns
influenced by seasonal and weather changes. In this study, we adopt an
efficient two-level clustering approach to automatically identify seasons using
the clear sky irradiance in first level and subsequently to identify daily
cloud level as clear, cloudy and partly cloudy within each season in second
level. In the second level of clustering, three methods are compared, namely,
Daily Irradiance Index (DII or $\beta$), Euclidean Distance (ED), and Dynamic
Time Warping (DTW) distance. The DII is computed as the ratio of time integral
of measured irradiance to time integral of the clear sky irradiance. The
identified clusters were compared quantitatively using established clustering
metrics and qualitatively by comparing the mean irradiance profiles. The
results clearly establish the superiority of the $\beta$-based clustering
approach as the leader, setting a new benchmark for solar irradiance clustering
studies. Moreover, $\beta$-based clustering remains effective even for annual
data unlike the time-series methods which suffer significant performance
degradation. Interestingly, contrary to expectations, ED-based clustering
outperforms the more compute-intensive DTW distance-based clustering. The
method has been rigorously validated using data from two distinct US locations,
demonstrating robust scalability for larger datasets and potential
applicability for other locations.",http://arxiv.org/abs/2501.10084v1
"The steady inviscid compressible self-similar flows and the stability
  analysis",2025-01-17T11:28:45Z,"Shangkun Weng, Hongwei Yuan","We investigate the steady inviscid compressible self-similar flows which
depends only on the polar angle in spherical coordinates. It is shown that
besides the purely supersonic and subsonic self-similar flows, there exists
purely sonic flows, Beltrami flows with a nonconstant proportionnality factor
and smooth transonic self-similar flows with large vorticity. For a constant
supersonic incoming flow past an infinitely long circular cone, a conic shock
attached to the tip of the cone will form, provided the opening angle of the
cone is less than a critical value. We introduce the shock polar for the radial
and polar components of the velocity and show that there exists a monotonicity
relation between the shock angle and the radial velocity, which seems to be new
and not been observed before. If a supersonic incoming flow is self-similar
with nonzero azimuthal velocity, a conic shock also form attached to the tip of
the cone. The state at the downstream may change smoothly from supersonic to
subsonic, thus the shock can be supersonic-supersonic, supersonic-subsonic and
even supersonic-sonic where the shock front and the sonic front coincide. We
further investigate the structural stability of smooth self-similar
irrotational transonic flows and analyze the corresponding linear mixed type
second order equation of Tricomi type. By exploring some key properties of the
self-similar solutions, we find a multiplier and identify a class of admissible
boundary conditions for the linearized mixed type second-order equation. We
also prove the existence and uniqueness of a class of smooth transonic flows
with nonzero vorticity which depends only on the polar and azimuthal angles in
spherical coordinates.",http://arxiv.org/abs/2501.10125v1
"A Simple but Effective Closed-form Solution for Extreme Multi-label
  Learning",2025-01-17T13:24:13Z,"Kazuma Onishi, Katsuhiko Hayashi","Extreme multi-label learning (XML) is a task of assigning multiple labels
from an extremely large set of labels to each data instance. Many current
high-performance XML models are composed of a lot of hyperparameters, which
complicates the tuning process. Additionally, the models themselves are adapted
specifically to XML, which complicates their reimplementation. To remedy this
problem, we propose a simple method based on ridge regression for XML. The
proposed method not only has a closed-form solution but also is composed of a
single hyperparameter. Since there are no precedents on applying ridge
regression to XML, this paper verified the performance of the method by using
various XML benchmark datasets. Furthermore, we enhanced the prediction of
low-frequency labels in XML, which hold informative content. This prediction is
essential yet challenging because of the limited amount of data. Here, we
employed a simple frequency-based weighting. This approach greatly simplifies
the process compared with existing techniques. Experimental results revealed
that it can achieve levels of performance comparable to, or even exceeding,
those of models with numerous hyperparameters. Additionally, we found that the
frequency-based weighting significantly improved the predictive performance for
low-frequency labels, while requiring almost no changes in implementation. The
source code for the proposed method is available on github at
https://github.com/cars1015/XML-ridge.",http://arxiv.org/abs/2501.10179v1
"Modeling the drying process in hard carbon electrodes based on the
  phase-field method",2025-01-17T13:29:42Z,"Marcel Weichel, Martin Reder, Simon Daubner, Julian Klemens, David Burger, Philip Scharfer, Wilhelm Schabel, Britta Nestler, Daniel Schneider","The present work addresses the simulation of pore emptying during the drying
of battery electrodes. For this purpose, a model based on the multiphase-field
method (MPF) is used, since it is an established approach for modeling and
simulating multiphysical problems. A model based on phase fields is introduced
that takes into account fluid flow, capillary effects, and wetting behavior,
all of which play an important role in drying. In addition, the MPF makes it
possible to track the movement of the liquid-air interface without
computationally expensive adaptive mesh generation. The presented model is used
for the first time to investigate pore emptying in real hard carbon
microstructures. For this purpose, the microstructures of real dried electrodes
are used as input for the simulations. The simulations performed here
demonstrate the importance of considering the resolved microstructural
information compared to models that rely only on statistical geometry
parameters such as pore size distributions. The influence of various parameters
such as different microstructures, fluid viscosity, and the contact angle on
pore emptying are investigated. In addition, this work establishes a
correlation between the capillary number and the breakthrough time of the
solvent as well as the height difference of the solvent front at the time of
breakthrough. The results indicate that the drying process can be optimized by
doping the particle surface, which changes the contact angle between the fluids
and the particles.",http://arxiv.org/abs/2501.10185v1
"Investigation of Polymer Association Behaviors in Solvents Using a
  Coarse-Grained Model",2025-01-17T16:28:53Z,"Xiangyu Zhang, Dong Meng","The associative interaction, such as hydrogen bonding, can bring about
versatile functionalities to polymer systems, which has been investigated by
tremendous researches, but the fundamental understanding on association process
is still lacking. In this study, a reaction-controlled association model is
proposed to delve into the polymer association activities in solvents, which is
proved to obey the principle of thermodynamics. Additionally, associative
polymer chain configurational bias method is developed to improve sampling
efficiency, demonstrating a significantly faster relaxation process. First, we
set non-bonded interactions to be zero, and only keep the chain connectivity
and association. It is found that the association process intrinsically follows
Bernoulli process by comparing the simulation results and analytic results.
Next, we include non-bonded interactions into the simulation to examine its
effects. It emerged that the excluded volume effect and solvents immiscibility
effects can result in inhomogeneous associating probability distribution along
the chain contour, in contrast to the homogeneity observed in ideal systems,
thereby shifting from the binomial distribution to Poisson binomial
distribution. At last, the study is extended to cooperative association
systems. The incorporation of cooperative association can lead to the
coexistence of coil and globule state at the transition point, verified by the
potential of mean force calculation. Finally, a mathematical model is proposed,
illustrating the changes in statistical weight induced by sequence enthalpy
bias, which is the consequence of cooperative behaviors.",http://arxiv.org/abs/2501.10286v1
"Elucidating the high compliance mechanism by which the urinary bladder
  fills under low pressures",2025-01-17T17:34:48Z,"Fatemeh Azari, Anne M. Robertson, Yasutaka Tobe, Paul N. Watton, Lori A. Birder, Naoki Yoshimura, Kanako Matsuoka, Christopher Hardin, Simon Watkins","The high compliance of the urinary bladder during filling is essential for
its proper function, enabling it to accommodate significant volumetric
increases with minimal rise in transmural pressure. This study aimed to
elucidate the physical mechanisms underlying this phenomenon by analyzing the
ex vivo filling process in rat from a fully voided state to complete
distension, without preconditioning, using three complementary imaging
modalities. High-resolution micro-CT at 10.8 {\mu}m resolution was used to
generate detailed 3D reconstructions of the bladder lumen, revealing a 62 fold
increase in bladder volume during filling. Pressure-volume studies of whole
bladder delineated three mechanical filling regimes: an initial high-compliance
phase, a transitional phase, and a final high-pressure phase. While prior
studies conjectured small mucosal rugae (450 {\mu}m) are responsible for the
high compliance phase, multiphoton microscopy (MPM) of the dome of the voided
bladder revealed large folds an order of magnitude larger than these rugae.
Bladder imaging during the inflation process demonstrated flattening of these
large scale folds is responsible for volume increases in the initial high
compliance phase. The 3D reconstructions of the bladder lumen in the filled and
voided state revealed a high voiding efficiency of 97.13%. The MPM imaging
results suggest the large scale folds in the dome enable this high voiding
fraction by driving urine toward the bladder outlet. These insights are vital
for computational models of bladder biomechanics and understanding changes to
bladder function due to pathological conditions such as bladder outlet
obstruction and age-related dysfunction.",http://arxiv.org/abs/2501.10312v1
"Improving Student Self-Efficacy in Quantum Computing with the Qubit
  Touchdown Board Game",2025-01-14T15:19:59Z,"Kristina Armbruster, Gintaras Duda, Thomas G. Wong","Qubit Touchdown is a two-player, competitive board game that was developed to
introduce students to quantum computing. A quantum computer is a new kind of
computer that is based on the laws of quantum physics, and it can solve certain
problems faster than normal computers because it follows a different set of
rules. Qubit Touchdown's game play mirrors the rules of (American) football,
with players taking turns moving the football to score the most touchdowns, and
no knowledge of quantum computing is needed to play the game. We evaluated the
game with 107 public high school students in Precalculus, Advanced Placement
(AP) Statistics, and/or AP Physics 1 courses, assessing whether their interest
in and self-efficacy toward quantum computing changed as a result of playing
the game and learning about its connections to quantum computing. We also
assessed whether the game was easy to learn and enjoyable. We found that
students' self-efficacy was improved by 33.4%, and they widely considered the
game accessible and fun. Thus, Qubit Touchdown could be an effective resource
to introduce students to Quantum Computing and boost their confidence in
learning about the field. Free printables of the game are available, and
professionally produced copies can be purchased on demand.",http://arxiv.org/abs/2501.10449v1
"Driving a Quantum Phase Transition at Arbitrary Rate: Exact solution of
  the Transverse-Field Ising model",2025-01-16T19:03:37Z,"András Grabarits, Federico Balducci, Adolfo del Campo","We study the crossing of the quantum phase transition in the transverse-field
Ising model after modulating the magnetic field at an arbitrary rate, exploring
the critical dynamics from the slow to the sudden quench regime. We do so by
analyzing the defect density, the complete kink number distribution, and its
cumulants upon completion of a linearized quench. Our analysis relies on the
diagonalization of the model using the standard Jordan-Wigner and Fourier
transformations, along with the exact solution of the time evolution in each
mode in terms of parabolic cylinder functions. The free-fermion nature of the
problem dictates that the kink number distribution is associated with
independent and distinguishable Bernoulli variables, each with a success
probability $p_k$. We employ a combination of convergent and asymptotic series
expansions to characterize $p_k$ without restrictions on the driving rate. When
the latter is approximated by the Landau-Zener formula, the kink density is
described by the Kibble-Zurek mechanism, and higher-order cumulants follow a
universal power-law behavior, as recently predicted theoretically and verified
in the laboratory. By contrast, for moderate and sudden driving protocols, the
cumulants exhibit a nonuniversal behavior that is not monotonic on the driving
rate and changes qualitatively with the cumulant order. The kink number
statistics remain sub-Poissonian for any driving rate, as revealed by an
analysis of the cumulant rations that vary nonmonotonically from the sudden to
the slow-driving regime. Thanks to the determination of $p_k$ for an arbitrary
rate, our study provides a complete analytical understanding of kink number
statistics from the slow driving regime to the sudden quench limit.",http://arxiv.org/abs/2501.10478v1
"AI Technicians: Developing Rapid Occupational Training Methods for a
  Competitive AI Workforce",2025-01-17T22:14:56Z,"Jaromir Savelka, Can Kultur, Arav Agarwal, Christopher Bogart, Heather Burte, Adam Zhang, Majd Sakr","The accelerating pace of developments in Artificial Intelligence~(AI) and the
increasing role that technology plays in society necessitates substantial
changes in the structure of the workforce. Besides scientists and engineers,
there is a need for a very large workforce of competent AI technicians (i.e.,
maintainers, integrators) and users~(i.e., operators). As traditional 4-year
and 2-year degree-based education cannot fill this quickly opening gap,
alternative training methods have to be developed. We present the results of
the first four years of the AI Technicians program which is a unique
collaboration between the U.S. Army's Artificial Intelligence Integration
Center (AI2C) and Carnegie Mellon University to design, implement and evaluate
novel rapid occupational training methods to create a competitive AI workforce
at the technicians level. Through this multi-year effort we have already
trained 59 AI Technicians. A key observation is that ongoing frequent updates
to the training are necessary as the adoption of AI in the U.S. Army and within
the society at large is evolving rapidly. A tight collaboration among the
stakeholders from the army and the university is essential for successful
development and maintenance of the training for the evolving role. Our findings
can be leveraged by large organizations that face the challenge of developing a
competent AI workforce as well as educators and researchers engaged in solving
the challenge.",http://arxiv.org/abs/2501.10579v1
Selecting samples of galaxies with fewer Fingers-of-God,2025-01-17T22:39:06Z,"Antón Baleato Lizancos, Uroš Seljak, Minas Karamanis, Marco Bonici, Simone Ferraro","The radial positions of galaxies inferred from their measured redshift appear
distorted due to their peculiar velocities. We argue that the contribution from
stochastic velocities -- which gives rise to `Fingers-of-God' (FoG) anisotropy
in the inferred maps -- does not lend itself to perturbative modelling already
on scales targeted by current experiments. To get around this limitation, we
propose to remove FoG using data-driven indicators of their abundance that are
local in nature and thus avoid selection biases. In particular, we show that
the scale where the measured power spectrum quadrupole changes sign is tightly
anti-correlated with both the satellite fraction and the velocity dispersion,
and can thus be used to select galaxy samples with fewer FoG. In addition, we
show that maps of the thermal Sunyaev-Zel'dovich distortion of the cosmic
microwave background frequency spectrum can be used to identify and discard
many of the most problematic galaxies. These techniques could potentially
extend the reach of perturbative models for galaxy clustering and improve
reconstructions of the large-scale velocity and displacement fields from the
redshift-space positions of galaxies.",http://arxiv.org/abs/2501.10587v2
"Building Short Value Chains for Animal Welfare-Friendly Products
  Adoption: Insights from a Restaurant-Based Study in Japan",2025-01-18T07:12:47Z,"Takuya Washio, Sota Takagi, Miki Saijo, Ken Wako, Keitaro Sato, Hiroyuki Ito, Ken-ichi Takeda, Takumi Ohashi","As global attention on sustainable and ethical food systems grows, animal
welfare-friendly products (AWFP) are increasingly recognized as essential to
addressing consumer and producer concerns. However, traditional research often
neglects the interdependencies between production, retail, and consumption
stages within the supply chain. This study examined how cross-stage
interactions among producers, consumers, and retail intermediaries can promote
AWFP adoption. By establishing a short value chain from production to
consumption, we conducted a two-month choice experiment in the operational
restaurant, employing a mixed-method approach to quantitatively and
qualitatively assess stakeholder responses. The results revealed that providing
information about AWFP practices significantly influenced consumer behavior,
increasing both product selection and perceived value. Retailers recognized the
potential for economic benefits and strengthened customer loyalty, while
producers identified new revenue opportunities by re-fattening delivered cow.
These coordinated changes - defined as synchronized actions and mutual
reinforcement across production, retail, and consumption - generated positive
feedback loops that motivated stakeholders to adopt AWFP practices. This
research underscores the potential of strategically designed short value chain
to foster cross-stage coordination and highlights their role as practical entry
points for promoting sustainable and ethical food systems on a larger scale.",http://arxiv.org/abs/2501.10680v1
"Simulation of Binary-Single Interactions in AGN Disk I: Gas-Enhanced
  Binary Orbital Hardening",2025-01-18T09:12:47Z,"Mengye Wang, Yiqiu Ma, Hui Li, Qingwen Wu, Ya-Ping Li, Xiangli Lei, Jiancheng Wu","Stellar-mass binary black hole\,(BBH) mergers within the accretion disks of
active galactic nuclei may contribute to gravitational wave\,(GW) events
detected by grounded-based GW detectors. In particular, the interaction between
a BBH and a single stellar-mass black hole\,(sBH), known as the binary-single
interaction\,(BSI) process, can potentially lead to GW events with detectable
non-zero eccentricity. Previous studies of the BSI process, which neglected the
effects of gas, showed that BSIs contribute non-negligibly to GW events in a
coplanar disk environment. In this work, we conduct a series of 2-dimensional
hydrodynamical and N-body simulations to explore the BSI in a gas environment
by coupling REBOUND with Athena++. We perform 360 simulation runs, spanning
parameters in disk surface density \(\Sigma_0\) and impact parameter \(b\). We
find that the gas-induced energy dissipation within the three-body system
becomes significant if the encounter velocity between the sBHs is sufficiently
large\,($\gg c_s$). Our simulation results indicate that approximately half of
the end states of the BSI are changed by gas. Furthermore, at higher gas
density, the number of encounters during the BSI process will increase and the
end-state BBHs tend to be more compact. Consequently, the presence of gas may
shorten the GW merger timescale for end-state BBHs and increase the three-body
merger rate.",http://arxiv.org/abs/2501.10703v1
"Changing the ranking in eigenvector centrality of a weighted graph by
  small perturbations",2025-01-18T12:11:01Z,"Michele Benzi, Nicola Guglielmi","In this article, we consider eigenvector centrality for the nodes of a graph
and study the robustness (and stability) of this popular centrality measure.
For a given weighted graph $\G$ (both directed and undirected), we consider the
associated weighted adiacency matrix $A$, which by definition is a non-negative
matrix. Eigenvector centrality consists of ranking the elements of the graph
according to the corresponding entries of the Perron eigenvector of $A$, which
is associated with the positive eigenvalue with largest modulus.
  An indicator of the robustness of eigenvector centrality consists in looking
for a nearby perturbed graph $\widetilde{\G}$, with the same structure as $\G$
(i.e., with the same vertices and edges), but with a weighted adiacency matrix
$\widetilde A$ such that the highest $m$ entries ($m \ge 2$) of the Perron
eigenvector of $\widetilde A$ coalesce, making the ranking at the highest level
ambiguous. To compute a solution to this matrix nearness problem, a nested
iterative algorithm is proposed that makes use of a constrained gradient system
of matrix differential equations (possibly on a low-rank manifold) in the inner
iteration and a one-dimensional optimization of the perturbation size in the
outer iteration.
  The proposed algorithm produces the {\em optimal} perturbation (i.e., the one
with smallest Frobenius norm) of the graph, which causes the looked-for
coalescence, which is a measure of the sensitivity of the graph. The
methodology is formulated in terms of graphs but applies to any nonnegative
matrix, with potential applications in fields like population models, consensus
dynamics, economics, etc.",http://arxiv.org/abs/2501.10745v1
"Energy-Threshold Bias Calculator: A Physics-Model Based Adaptive
  Correction Scheme for Photon-Counting CT",2025-01-18T13:32:17Z,"Yuting Chen, Yuxiang Xing, Li Zhang, Zhi Deng, Hewei Gao","Photon-counting detector based computed tomography (PCCT) has greatly
advanced in recent years. However, the spectral inconsistency is still a
serious challenge for PCCT that could directly introduce obvious artifacts and
severe inaccuracies. This work attempts to overcome the challenge by modeling
the spectral inconsistency in a novel, unified, and two-term factorized
framework, with a spectral skew term independent of the energy threshold, and
an energy-threshold bias analytical characterization term. To solve the
spectral inconsistency, a two-step decomposition algorithm called
energy-threshold bias calculator (ETB-Cal) is derived here, in which the
spectral skew term is grossly determined at a relatively low energy threshold
and only the energy-threshold bias is needed to be calculated as the energy
threshold changes. After the two terms being computed out in calibration stage,
they will be incorporated into our spectral model to generate the spectral
correction vectors as well as the material decomposition vectors if needed, for
PCCT projection data. To validate our method, both numerical simulations
physics experiments were carried out on a tabletop PCCT system. Preliminary
results showed that the spectral inconsistency can be significantly reduced,
for example, with an non-uniformity quantitative indicators decreasing from
26.27 to 5.80 HU for Gammex multi-energy phantom and from 27.88 to 3.16 HU for
kyoto head phantom. The considerable improvements consistently demonstrate a
great potential of the proposed novel physics-model based correction scheme in
practical applications, as computationally efficient, calibration-wise
convenient with high degree of generality, and substantially avoiding the use
of X-ray florescence material in the energy-threshold calibration.",http://arxiv.org/abs/2501.10764v1
Tuning magnetism in graphene nanoribbons via strain and adatoms,2025-01-18T15:46:34Z,"Pablo Moles, Hernán Santos, Francisco Domínguez-Adame, Leonor Chico","We investigate the impact of strain and adsorbed H adatoms on the magnetic
properties of zigzag graphene nanoribbons (ZGNRs) using a combination of
tight-binding and density functional theory methods for both, ferromagnetic
(FM) and antiferromagnetic edge configurations (AFM). Our study reveals that
longitudinal strain induces a significant enhancement in the edge magnetic
moment, that we attribute to strain-driven modifications in the band structure.
In addition, we describe H~adatoms within the tight-binding approach by
employing both an unrelaxed vacancy model and the Anderson impurity model. By
comparing to density functional theory results, we corroborate that the
Anderson impurity model is best suited to describe H adsorption. We then focus
on the metallic FM edge configuration of the ZGNRs to better exploit the tuning
of its properties. We find that the magnetic configuration of H~adatoms is
strongly influenced by the edges, with an AFM coupling between edges and the
H~adatom. In fact, the magnetic spatial pattern of the H adatom differs to that
found in graphene due to this edge coupling. Importantly, we find robust
discrete plateaus of integer magnetic moment as strain is varied in the
defected ZGNRs, that we relate to changes in the band structure, namely, a
half-metallic character or the opening of a gap. This behavior can be of
interest for magnetic applications of carbon-based nanostructures",http://arxiv.org/abs/2501.10801v1
Distributed Quasi-Newton Method for Fair and Fast Federated Learning,2025-01-18T20:59:07Z,"Shayan Mohajer Hamidi, Linfeng Ye","Federated learning (FL) is a promising technology that enables edge
devices/clients to collaboratively and iteratively train a machine learning
model under the coordination of a central server. The most common approach to
FL is first-order methods, where clients send their local gradients to the
server in each iteration. However, these methods often suffer from slow
convergence rates. As a remedy, second-order methods, such as quasi-Newton, can
be employed in FL to accelerate its convergence. Unfortunately, similarly to
the first-order FL methods, the application of second-order methods in FL can
lead to unfair models, achieving high average accuracy while performing poorly
on certain clients' local datasets. To tackle this issue, in this paper we
introduce a novel second-order FL framework, dubbed \textbf{d}istributed
\textbf{q}uasi-\textbf{N}ewton \textbf{fed}erated learning (DQN-Fed). This
approach seeks to ensure fairness while leveraging the fast convergence
properties of quasi-Newton methods in the FL context. Specifically, DQN-Fed
helps the server update the global model in such a way that (i) all local loss
functions decrease to promote fairness, and (ii) the rate of change in local
loss functions aligns with that of the quasi-Newton method. We prove the
convergence of DQN-Fed and demonstrate its \textit{linear-quadratic}
convergence rate. Moreover, we validate the efficacy of DQN-Fed across a range
of federated datasets, showing that it surpasses state-of-the-art fair FL
methods in fairness, average accuracy and convergence speed.",http://arxiv.org/abs/2501.10877v1
Observing cities as a complex system,2025-01-19T00:01:45Z,Rafael Prieto-Curiel,"Cities are some of the most intricate and advanced creations of humanity.
Most objects in cities are perfectly synchronised to coordinate activities like
jobs, education, transportation, entertainment or waste management. Although
each city has its characteristics, some commonalities can be observed across
most cities, like issues related to noise, pollution, segregation and others.
Further, some of these issues might be accentuated in larger or smaller cities.
For example, with more people, a city might experience more competition for
space so rents would be higher. The urban scaling theory gives a framework to
analyse cities in the context of their size. New data for analysing urban
scaling theory allow an understanding of how urban metrics change with their
population size, whether they apply across most regions or if patterns
correspond only to some country or region. Yet, reducing a city and all its
complexity into a single indicator might simplify urban areas to an extent
where their disparities and variations are overlooked. Often, the differences
between the living conditions in different parts of the same city are bigger
than the degree of variation observed between cities. For example, in terms of
rent or crime, within-city variations might be more significant than between
cities. Here, we review some urban scaling principles and explore ways to
analyse variations within the same city.",http://arxiv.org/abs/2501.10902v1
Generalized Entropic Quantum Speed Limits,2025-01-19T13:51:18Z,"Jucelino Ferreira de Sousa, Diego Paiva Pires","We present a class of generalized entropic quantum speed limits based on
$\alpha$-$z$-R\'{e}nyi relative entropy, a real-valued, contractive,
two-parameter family of distinguishability measures. The QSL falls into the
class of Mandelstam-Tamm bounds, and applies to finite-dimensional quantum
systems that undergo general physical process, i.e., their effective dynamics
can be modeled by unitary or nonunitary evolutions. The results cover pure or
mixed, separable and entangled probe quantum states. The QSL time depends on
the smallest and largest eigenvalues of probe and instantaneous states of the
system, and its evaluation requires low computational cost. In addition, it is
inversely proportional to the time-average of the Schatten speed of the
instantaneous state, which in turn is fully characterized by the considered
dynamics. We specialize our results to the case of unitary and nonunitary
evolutions. In the former case, the QSL scales with the inverse of the energy
fluctuations, while the latter depends on the operator norm of the rate of
change of the quantum channel Kraus operators. We illustrate our findings for
single-qubit and two-qubit states, unitary and nonunitary evolutions. Our
results may find applications in the study of entropic uncertainty relations,
quantum metrology, and also entanglement entropies signaled by generalized
entropies.",http://arxiv.org/abs/2501.11049v2
"Clustering indications before the Mw7.0 2020 Samos, Greece, main shock
  as revealed in an equivalent dimensions space",2025-01-19T18:26:25Z,"Stanislaw Lasocki, Vasileios G. Karakostas, Eleftheria E. Papadimitriou","The transformation to equivalent dimensions that offers a novel approach for
investigating earthquake clustering was engaged to analyze the preparatory
phase of the 2020 Samos, Greece, Mw7.0 main shock. The analysis considered
earthquakes that occurred between 2006 and October 2020, covering an area
extended three times the length of the main rupture. Each earthquake was
parameterized by its magnitude, the interevent time (interval since the
previous earthquake), and the interevent spatial distance (distance between the
epicenters of consecutive earthquakes). Transforming these parameters into
equivalent dimensions allowed them to be directly compared. The degree of
clustering was quantified using the average distance between earthquakes in
this transformed parameter space, calculated within consecutive 100 events data
windows. Results revealed a distinct pattern, the average distance was
increasing steadily during the twelve year period before the main shock. These
temporal changes in the average distance were driven by a systematic evolution
of earthquake clustering in the used parameter space. Beginning from a
two-cluster system, when the distance was minimal, the clustering development
continued along two branches and ended before the main shock with the formation
of five earthquake clusters of different characteristics.",http://arxiv.org/abs/2501.11137v1
Quantum Criticality of Type-I and Critically Tilted Dirac Semimetals,2025-01-19T18:58:34Z,"Huanzhi Hu, Frank Krüger","We investigate the universality of an Ising symmetry breaking phase
transition of tilted two-dimensional Dirac fermions, in the type-I phase as
well as at the Lifshitz transition between a type-I and a type-II semimetal,
where the Fermi surface changes from point-like to one with electron and hole
pockets that touch at the overtilted Dirac cones. We compute the Landau damping
of long-wavelength order parameter fluctuations by tilted Dirac fermions and
use the resulting IR propagator as input for a renormalisation-group analysis
of the resulting Gross-Neveu-Yukawa field theory. We first demonstrate that the
criticality of tilted type-I fermions is controlled by a line of fixed points
along which the poles of the renormalised Green function correspond to an
untilted Dirac spectrum with varying anisotropy of Fermi velocities. At the
phase transition the Lorentz invariance is restored, resulting in the same
critical exponents as for conventional Dirac systems. The multicritical point
is given by the endpoint of the fixed-point line. It can be approached along
any path in parameter space that avoids the fixed point line of the critical
type-I semimetal. We show that the critical exponents at the Lifshitz point are
different and that Lorentz invariance is broken.",http://arxiv.org/abs/2501.11143v2
Ultrasonic monitoring of carbonation in Portland cements,2025-01-19T19:08:18Z,"A. Villarreal, P. F. J. Cano-Barrita, F. M. Leon-Martinez, L. Medina, F. Castellanos","Chemical reactions resulting from the ingress of carbonates into the cement
matrix modify the properties of its pore solution, as well as its pore
distribution and size. These changes lead to corrosion of the steel in
reinforced concrete. The nature of conventional testing for the estimation of
carbonation in cement-based materials is time-consuming and destructive. This
paper presents a set of non-destructive ultrasound-based indexes, obtained
solely from non-linear and linear analyses of ultrasonic signals, for measuring
the carbonation of Portland cement pastes. Class 30RS cement pastes with three
water/cement ratios by weight (0.4, 0.5, and 0.6) were considered. Carbonation
was carried out for 120 days with a constant CO2 level of 4% by volume under
controlled temperature and humidity, considering a unidirectional carbonation,
parallel to the longitudinal axis of the samples. The level of carbonation was
validated by FTIR measurements. From these analyses, different indexes with
high correlation were obtained, estimated only from the ultrasonic signals and
as a function of the days of exposure to carbonation, as well as of the
percentage of carbonation. Further study is required for the evaluation of the
reliability of these promising indexes for the determination of carbonation in
cement-based materials.",http://arxiv.org/abs/2501.11147v1
"Conditional Feature Importance with Generative Modeling Using
  Adversarial Random Forests",2025-01-19T21:34:54Z,"Kristin Blesch, Niklas Koenen, Jan Kapar, Pegah Golchian, Lukas Burk, Markus Loecher, Marvin N. Wright","This paper proposes a method for measuring conditional feature importance via
generative modeling. In explainable artificial intelligence (XAI), conditional
feature importance assesses the impact of a feature on a prediction model's
performance given the information of other features. Model-agnostic post hoc
methods to do so typically evaluate changes in the predictive performance under
on-manifold feature value manipulations. Such procedures require creating
feature values that respect conditional feature distributions, which can be
challenging in practice. Recent advancements in generative modeling can
facilitate this. For tabular data, which may consist of both categorical and
continuous features, the adversarial random forest (ARF) stands out as a
generative model that can generate on-manifold data points without requiring
intensive tuning efforts or computational resources, making it a promising
candidate model for subroutines in XAI methods. This paper proposes cARFi
(conditional ARF feature importance), a method for measuring conditional
feature importance through feature values sampled from ARF-estimated
conditional distributions. cARFi requires only little tuning to yield robust
importance scores that can flexibly adapt for conditional or marginal notions
of feature importance, including straightforward extensions to condition on
feature subsets and allows for inferring the significance of feature
importances through statistical tests.",http://arxiv.org/abs/2501.11178v1
"A Model for Self-Organized Growth, Branching, and Allometric Scaling of
  the Planarian Gut",2025-01-19T21:46:23Z,"Christian Hanauer, Amrutha Palavalli, Baiqun An, Efe Ilker, Jochen C. Rink, Frank Jülicher","The growth and scaling of organs is a fundamental aspect of animal
development. However, how organs grow to the right size and shape required by
physiological demands, remains largely unknown. Here, we provide a framework
combining theory and experiment to study the scaling of branched organs. As a
biological model, we focus on the branching morphogenesis of the planarian gut,
which is a highly branched organ responsible for the delivery of nutrients.
Planarians undergo massive body size changes requiring gut morphology to adapt
to these size variations. Our experimental analysis shows that various gut
properties scale with organism size according to power laws. We introduce a
theoretical framework to understand the growth and scaling of branched organs.
Our theory considers the dynamics of the interface between organ and
surrounding tissue to be controlled by a morphogen and illustrates how a shape
instability of this interface can give rise to the self-organized formation and
growth of complex branched patterns. Considering the reaction-diffusion
dynamics in a growing domain representative of organismal growth, we show that
a wide range of scaling behaviors of the branching pattern emerges from the
interplay between interface dynamics and organism growth. Our model can
recapitulate the scaling laws of planarian gut morphology that we quantified
and also opens new directions for understanding allometric scaling laws in
various other branching systems in organisms.",http://arxiv.org/abs/2501.11182v1
"Optimum Power Allocation for Low Rank Wi-Fi Channels: A Comparison with
  Deep RL Framework",2025-01-20T04:21:53Z,"Muhammad Ahmed Mohsin, Sagnik Bhattacharya, Kamyar Rajabalifardi, Rohan Pote, John M. Cioffi","Upcoming Augmented Reality (AR) and Virtual Reality (VR) systems require high
data rates ($\geq$ 500 Mbps) and low power consumption for seamless experience.
With an increasing number of subscribing users, the total number of antennas
across all transmitting users far exceeds the number of antennas at the access
point (AP). This results in a low rank wireless channel, presenting a
bottleneck for uplink communication systems. The current uplink systems that
use orthogonal multiple access (OMA) and the proposed non-orthogonal multiple
access (NOMA), fail to achieve the required data rates / power consumption
under predominantly low rank channel scenarios. This paper introduces an
optimal power sub carrier allocation algorithm for multi-carrier NOMA, named
minPMAC, and an associated time-sharing algorithm that adaptively changes
successive interference cancellation decoding orders to maximize sum data rates
in these low rank channels. This Lagrangian based optimization technique,
although globally optimum, is prohibitive in terms of runtime, proving
inefficient for real-time scenarios. Hence, we propose a novel near-optimal
deep reinforcement learning-based energy sum optimization (DRL-minPMAC) which
achieves real-time efficiency. Extensive experimental evaluations show that
minPMAC achieves 28\% and 39\% higher data rates than NOMA and OMA baselines.
Furthermore, the proposed DRL-minPMAC runs ~5 times faster than minPMAC and
achieves 83\% of the global optimum data rates in real time",http://arxiv.org/abs/2501.11266v1
Few-shot Policy (de)composition in Conversational Question Answering,2025-01-20T08:40:15Z,"Kyle Erwin, Guy Axelrod, Maria Chang, Achille Fokoue, Maxwell Crouse, Soham Dan, Tian Gao, Rosario Uceda-Sosa, Ndivhuwo Makondo, Naweed Khan, Alexander Gray","The task of policy compliance detection (PCD) is to determine if a scenario
is in compliance with respect to a set of written policies. In a conversational
setting, the results of PCD can indicate if clarifying questions must be asked
to determine compliance status. Existing approaches usually claim to have
reasoning capabilities that are latent or require a large amount of annotated
data. In this work, we propose logical decomposition for policy compliance
(LDPC): a neuro-symbolic framework to detect policy compliance using large
language models (LLMs) in a few-shot setting. By selecting only a few exemplars
alongside recently developed prompting techniques, we demonstrate that our
approach soundly reasons about policy compliance conversations by extracting
sub-questions to be answered, assigning truth values from contextual
information, and explicitly producing a set of logic statements from the given
policies. The formulation of explicit logic graphs can in turn help answer
PCDrelated questions with increased transparency and explainability. We apply
this approach to the popular PCD and conversational machine reading benchmark,
ShARC, and show competitive performance with no task-specific finetuning. We
also leverage the inherently interpretable architecture of LDPC to understand
where errors occur, revealing ambiguities in the ShARC dataset and highlighting
the challenges involved with reasoning for conversational question answering.",http://arxiv.org/abs/2501.11335v1
"Adaptive parameters identification for nonlinear dynamics using deep
  permutation invariant networks",2025-01-20T09:18:30Z,"Mouad Elaarabi, Domenico Borzacchiello, Yves Le Guennec, Philippe Le Bot, Sebastien Comas-Cardona","The promising outcomes of dynamical system identification techniques, such as
SINDy [Brunton et al. 2016], highlight their advantages in providing
qualitative interpretability and extrapolation compared to non-interpretable
deep neural networks [Rudin 2019]. These techniques suffer from parameter
updating in real-time use cases, especially when the system parameters are
likely to change during or between processes. Recently, the OASIS [Bhadriraju
et al. 2020] framework introduced a data-driven technique to address the
limitations of real-time dynamical system parameters updating, yielding
interesting results. Nevertheless, we show in this work that superior
performance can be achieved using more advanced model architectures. We present
an innovative encoding approach, based mainly on the use of Set Encoding
methods of sequence data, which give accurate adaptive model identification for
complex dynamic systems, with variable input time series length. Two Set
Encoding methods are used, the first is Deep Set [Zaheer et al. 2017], and the
second is Set Transformer [Lee et al. 2019]. Comparing Set Transformer to OASIS
framework on Lotka Volterra for real-time local dynamical system identification
and time series forecasting, we find that the Set Transformer architecture is
well adapted to learning relationships within data sets. We then compare the
two Set Encoding methods based on the Lorenz system for online global dynamical
system identification. Finally, we trained a Deep Set model to perform
identification and characterization of abnormalities for 1D heat-transfer
problem.",http://arxiv.org/abs/2501.11350v1
Federated Learning with Sample-level Client Drift Mitigation,2025-01-20T09:44:07Z,"Haoran Xu, Jiaze Li, Wanyi Wu, Hao Ren","Federated Learning (FL) suffers from severe performance degradation due to
the data heterogeneity among clients. Existing works reveal that the
fundamental reason is that data heterogeneity can cause client drift where the
local model update deviates from the global one, and thus they usually tackle
this problem from the perspective of calibrating the obtained local update.
Despite effectiveness, existing methods substantially lack a deep understanding
of how heterogeneous data samples contribute to the formation of client drift.
In this paper, we bridge this gap by identifying that the drift can be viewed
as a cumulative manifestation of biases present in all local samples and the
bias between samples is different. Besides, the bias dynamically changes as the
FL training progresses. Motivated by this, we propose FedBSS that first
mitigates the heterogeneity issue in a sample-level manner, orthogonal to
existing methods. Specifically, the core idea of our method is to adopt a
bias-aware sample selection scheme that dynamically selects the samples from
small biases to large epoch by epoch to train progressively the local model in
each round. In order to ensure the stability of training, we set the
diversified knowledge acquisition stage as the warm-up stage to avoid the local
optimality caused by knowledge deviation in the early stage of the model.
Evaluation results show that FedBSS outperforms state-of-the-art baselines. In
addition, we also achieved effective results on feature distribution skew and
noise label dataset setting, which proves that FedBSS can not only reduce
heterogeneity, but also has scalability and robustness.",http://arxiv.org/abs/2501.11360v1
Each Graph is a New Language: Graph Learning with LLMs,2025-01-20T13:20:41Z,"Huachi Zhou, Jiahe Du, Chuang Zhou, Chang Yang, Yilin Xiao, Yuxuan Xie, Xiao Huang","Recent efforts leverage Large Language Models (LLMs) for modeling
text-attributed graph structures in node classification tasks. These approaches
describe graph structures for LLMs to understand or aggregate LLM-generated
textual attribute embeddings through graph structure. However, these approaches
face two main limitations in modeling graph structures with LLMs. (i) Graph
descriptions become verbose in describing high-order graph structure. (ii)
Textual attributes alone do not contain adequate graph structure information.
It is challenging to model graph structure concisely and adequately with LLMs.
LLMs lack built-in mechanisms to model graph structures directly. They also
struggle with complex long-range dependencies between high-order nodes and
target nodes.
  Inspired by the observation that LLMs pre-trained on one language can achieve
exceptional performance on another with minimal additional training, we propose
\textbf{G}raph-\textbf{D}efined \textbf{L}anguage for \textbf{L}arge
\textbf{L}anguage \textbf{M}odel (GDL4LLM). This novel framework enables LLMs
to transfer their powerful language understanding capabilities to
graph-structured data. GDL4LLM translates graphs into a graph language corpus
instead of graph descriptions and pre-trains LLMs on this corpus to adequately
understand graph structures. During fine-tuning, this corpus describes the
structural information of target nodes concisely with only a few tokens. By
treating graphs as a new language, GDL4LLM enables LLMs to model graph
structures adequately and concisely for node classification tasks. Extensive
experiments on three real-world datasets demonstrate that GDL4LLM outperforms
description-based and textual attribute embeddings-based baselines by
efficiently modeling different orders of graph structure with LLMs.",http://arxiv.org/abs/2501.11478v2
Event-based vision for egomotion estimation using precise event timing,2025-01-20T15:41:33Z,"Hugh Greatorex, Michele Mastella, Madison Cotteret, Ole Richter, Elisabetta Chicca","Egomotion estimation is crucial for applications such as autonomous
navigation and robotics, where accurate and real-time motion tracking is
required. However, traditional methods relying on inertial sensors are highly
sensitive to external conditions, and suffer from drifts leading to large
inaccuracies over long distances. Vision-based methods, particularly those
utilising event-based vision sensors, provide an efficient alternative by
capturing data only when changes are perceived in the scene. This approach
minimises power consumption while delivering high-speed, low-latency feedback.
In this work, we propose a fully event-based pipeline for egomotion estimation
that processes the event stream directly within the event-based domain. This
method eliminates the need for frame-based intermediaries, allowing for
low-latency and energy-efficient motion estimation. We construct a shallow
spiking neural network using a synaptic gating mechanism to convert precise
event timing into bursts of spikes. These spikes encode local optical flow
velocities, and the network provides an event-based readout of egomotion. We
evaluate the network's performance on a dedicated chip, demonstrating strong
potential for low-latency, low-power motion estimation. Additionally,
simulations of larger networks show that the system achieves state-of-the-art
accuracy in egomotion estimation tasks with event-based cameras, making it a
promising solution for real-time, power-constrained robotics applications.",http://arxiv.org/abs/2501.11554v1
Faster-Than-Nyquist Equalization with Convolutional Neural Networks,2025-01-20T16:51:39Z,"Bruno De Filippo, Carla Amatetti, Alessandro Vanelli-Coralli","Faster-than-Nyquist (FTN) signaling aims at improving the spectral efficiency
of wireless communication systems by exceeding the boundaries set by the
Nyquist-Shannon sampling theorem. 50 years after its first introduction in the
scientific literature, wireless communications have significantly changed, but
spectral efficiency remains one of the key challenges. To adopt FTN signaling,
inter-symbol interference (ISI) patterns need to be equalized at the receiver.
Motivated by the pattern recognition capabilities of convolutional neural
networks with skip connections, we propose such deep learning architecture for
ISI equalization and symbol demodulation in FTN receivers. We investigate the
performance of the proposed model considering quadrature phase shift keying
modulation and low density parity check coding, and compare it to a set of
benchmarks, including frequency-domain equalization, a
quadratic-programming-based receiver, and an equalization scheme based on a
deep neural network. We show that our receiver outperforms any benchmark,
achieving error rates comparable to those in additive white Gaussian noise
channel, and higher effective throughput, thanks to the increased spectral
efficiency of FTN signaling. With a compression factor of 60% and code rate
3/4, the proposed model achieves a peak effective throughput of 2.5 Mbps at
just 10dB of energy per bit over noise power spectral density ratio, with other
receivers being limited by error floors due to the strong inter-symbol
interference. To promote reproducibility in deep learning for wireless
communications, our code is open source at the repository provided in the
references.",http://arxiv.org/abs/2501.11594v1
"The $(2+δ)$-dimensional theory of the electromechanics of lipid
  membranes: III. Constitutive models",2025-01-20T17:17:17Z,"Yannick A. D. Omar, Zachary G. Lipel, Kranthi K. Mandadapu","This article concludes a three-part series developing a self-consistent
theoretical framework of the electromechanics of lipid membranes at the
continuum scale. Owing to their small thickness, lipid membranes are commonly
modeled as two-dimensional surfaces. However, this approach breaks down when
considering their electromechanical behavior as it requires accounting for
their thickness. To address this, we developed a dimension reduction procedure
in part 1 to derive effective surface theories explicitly capturing the
thickness of lipid membranes. We applied this method to dimensionally reduce
Gauss' law and the electromechanical balance laws and referred to the resulting
theory as $(2+\delta)$-dimensional, where $\delta$ indicates the membrane
thickness. However, the $(2+\delta)$-dimensional balance laws derived in part 2
are general, and specific material models are required to specialize them to
lipid membranes. In this work, we devise appropriate three-dimensional
constitutive models that capture the in-plane fluid and out-of-plane elastic
behavior of lipid membranes. The viscous behavior is recovered by a
three-dimensional Newtonian fluid model, leading to the same viscous stresses
as strictly two-dimensional models. The elastic resistance to bending is
recovered by imposing a free energy penalty on local volume changes. While this
gives rise to the characteristic bending resistance of lipid membranes, it
differs in its higher-order curvature terms from the Canham-Helfrich-Evans
theory. Furthermore, motivated by the small mid-surface stretch of lipid
membranes, we introduce reactive stresses that enforce mid-surface
incompressibility, resulting in an effective surface tension. Finally, we use
the constitutive and reactive stresses to derive the equations of motion
describing the electromechanics of lipid membranes.",http://arxiv.org/abs/2501.11612v1
"DRL-Based Maximization of the Sum Cross-Layer Achievable Rate for
  Networks Under Jamming",2025-01-20T17:54:24Z,"Abdul Basit, Muddasir Rahim, Tri Nhu Do, Nadir Adam, Georges Kaddoum","In quasi-static wireless networks characterized by infrequent changes in the
transmission schedules of user equipment (UE), malicious jammers can easily
deteriorate network performance. Accordingly, a key challenge in these networks
is managing channel access amidst jammers and under dynamic channel conditions.
In this context, we propose a robust learning-based mechanism for channel
access in multi-cell quasi-static networks under jamming. The network comprises
multiple legitimate UEs, including predefined UEs (pUEs) with stochastic
predefined schedules and an intelligent UE (iUE) with an undefined transmission
schedule, all transmitting over a shared, time-varying uplink channel. Jammers
transmit unwanted packets to disturb the pUEs' and the iUE's communication. The
iUE's learning process is based on the deep reinforcement learning (DRL)
framework, utilizing a residual network (ResNet)-based deep Q-Network (DQN). To
coexist in the network and maximize the network's sum cross-layer achievable
rate (SCLAR), the iUE must learn the unknown network dynamics while
concurrently adapting to dynamic channel conditions. Our simulation results
reveal that, with properly defined state space, action space, and rewards in
DRL, the iUE can effectively coexist in the network, maximizing channel
utilization and the network's SCLAR by judiciously selecting transmission time
slots and thus avoiding collisions and jamming.",http://arxiv.org/abs/2501.11626v1
"Noise-Agnostic Multitask Whisper Training for Reducing False Alarm
  Errors in Call-for-Help Detection",2025-01-20T18:01:42Z,"Myeonghoon Ryu, June-Woo Kim, Minseok Oh, Suji Lee, Han Park","Keyword spotting is often implemented by keyword classifier to the encoder in
acoustic models, enabling the classification of predefined or open vocabulary
keywords. Although keyword spotting is a crucial task in various applications
and can be extended to call-for-help detection in emergencies, however, the
previous method often suffers from scalability limitations due to retraining
required to introduce new keywords or adapt to changing contexts. We explore a
simple yet effective approach that leverages off-the-shelf pretrained ASR
models to address these challenges, especially in call-for-help detection
scenarios. Furthermore, we observed a substantial increase in false alarms when
deploying call-for-help detection system in real-world scenarios due to noise
introduced by microphones or different environments. To address this, we
propose a novel noise-agnostic multitask learning approach that integrates a
noise classification head into the ASR encoder. Our method enhances the model's
robustness to noisy environments, leading to a significant reduction in false
alarms and improved overall call-for-help performance. Despite the added
complexity of multitask learning, our approach is computationally efficient and
provides a promising solution for call-for-help detection in real-world
scenarios.",http://arxiv.org/abs/2501.11631v1
"Modelling the Sgr A$^*$ and M87$^*$ shadows by using the Kerr-Taub-NUT
  metrics in the presence of a scalar field",2025-01-20T19:16:18Z,"khadije Jafarzade, Masoumeh Ghasemi-Nodehi, Fatemeh Sadeghi, Behrouz Mirza","The recent unveiling of the images of Sgr A* and M87* has significantly
advanced our understanding of gravitational physics. In this study, we derive a
class of Kerr-Taub-NUT metrics in the presence of a scalar field (KTNS).
Treating these metrics as models for supermassive objects, we constrain the
parameters using shadow size estimates done by observations of M87* and Sgr A*
from the Event Horizon Telescope (EHT). Comparing the obtained results with
M87* data, we show an upper limit on the NUT charge $n$ such that the
constraint on the shadow deviation from circularity ($ \Delta C $) will be
fulfilled for $ n<0.5 $, and this allowed range changes with a variation in
other parameters. Additionally, our findings reveal that fast-rotating KTNS
metrics are better candidates for supermassive M87* than slowly rotating ones.
We continue our study by estimating parameters using Keck and VLTI observations
of Sgr A* and find that the constraint on the fraction deviation $ \delta $ is
maintained within a certain range of the NUT charge such that the Keck bound is
satisfied for $ n<0.41 $. In contrast, the VLTI bound can be fulfilled for $
n>0.34 $. Finally, we investigate weak gravitational lensing using the
Gauss-Bonnet theorem and illustrate that all model parameters increase the
deflection angle, causing light rays to deviate more significantly near
fast-rotating KTNS objects.",http://arxiv.org/abs/2501.11692v1
Region analysis of $H\to γγ$ via a bottom quark loop,2025-01-21T02:04:59Z,"Jun-Yao Hou, Jian Wang, Da-Jiang Zhang","The $H\to \gamma\gamma$ decay is an ideal process to study the structure of
next-to-leading power logarithms induced by quarks due to its simple initial
and final states. We perform a region analysis of this process up to two-loop
level to inspect the origins of the logarithms. To deal with the endpoint
singularities that are prevalent for the next-to-leading power logarithms, we
have adopted two different kinds of regulators to exhibit the advantages and
disadvantages of each regulator. In the analytic regulator we have chosen, the
power of the propagator is changed by $\eta$. And the endpoint singularities
are regulated in the form of $1/\eta$. These poles cancel between the collinear
and anti-collinear sectors since there is no soft mode in such a regulator. In
the $\Delta$ regulator, the soft sector is important. The leading and
next-to-leading logarithms can be inferred from only this sector. Moreover, the
symmetry between the collinear and anti-collinear sectors is reserved. After
imposing a cut on the bottom quark transverse momentum, the leading order
result is finite in each sector. We also discuss the next-to-next-to-leading
power contributions and find that the potential factorization formulae involve
two-dimensional endpoint singularities. Our region analysis could help to
develop sophisticated factorization and resummation schemes beyond leading
power.",http://arxiv.org/abs/2501.11824v1
"Equilibria under Dynamic Benchmark Consistency in Non-Stationary
  Multi-Agent Systems",2025-01-21T05:19:19Z,"Ludovico Crippa, Yonatan Gur, Bar Light","We formulate and study a general time-varying multi-agent system where
players repeatedly compete under incomplete information. Our work is motivated
by scenarios commonly observed in online advertising and retail marketplaces,
where agents and platform designers optimize algorithmic decision-making in
dynamic competitive settings. In these systems, no-regret algorithms that
provide guarantees relative to \emph{static} benchmarks can perform poorly and
the distributions of play that emerge from their interaction do not correspond
anymore to static solution concepts such as coarse correlated equilibria.
Instead, we analyze the interaction of \textit{dynamic benchmark} consistent
policies that have performance guarantees relative to \emph{dynamic} sequences
of actions, and through a novel \textit{tracking error} notion we delineate
when their empirical joint distribution of play can approximate an evolving
sequence of static equilibria. In systems that change sufficiently slowly
(sub-linearly in the horizon length), we show that the resulting distributions
of play approximate the sequence of coarse correlated equilibria, and apply
this result to establish improved welfare bounds for smooth games. On a similar
vein, we formulate internal dynamic benchmark consistent policies and establish
that they approximate sequences of correlated equilibria. Our findings
therefore suggest that, in a broad range of multi-agent systems where
non-stationarity is prevalent, algorithms designed to compete with dynamic
benchmarks can improve both individual and welfare guarantees, and their
emerging dynamics approximate a sequence of static equilibrium outcomes.",http://arxiv.org/abs/2501.11897v1
"Dzyaloshinskii-Moriya interaction chirality reversal with ferromagnetic
  thickness",2025-01-21T12:45:21Z,"Capucine Gueneau, Fatima Ibrahim, Johanna Fischer, Libor Vojáček, Charles-Élie Fillion, Stefania Pizzini, Laurent Ranno, Isabelle Joumard, Stéphane Auffret, Jérôme Faure-Vincent, Claire Baraduc, Mairbek Chshiev, Hélène Béa","In ultrathin ferromagnetic films sandwiched between two distinct heavy metal
layers or between a heavy metal and an oxide layer, the Dzyaloshinskii-Moriya
interaction (DMI) is recognized as being of interfacial origin. Its chirality
and strength are determined by the properties of the adjacent heavy metals and
the degree of oxidation at the interfaces. Here, we demonstrate that the
chirality of the DMI can change solely with variations in the thickness of the
ferromagnetic layer - an effect that has not been experimentally observed or
explained until now. Our experimental observation in the trilayer system
Ta/FeCoB/TaOx is supported by ab initio calculations: they reveal that
variations in orbital filling and inter-atomic distances at the interface,
driven by the number of ferromagnetic atomic layers, lead to an inversion of
DMI chirality. This mechanism takes place for ferromagnetic layers with more
than three atomic layers, for which the two interfaces start to be decoupled.
We hence propose a new degree of freedom to tune DMI chirality and the
associated chiral spin textures by tailoring crystal structure e.g. using
strain or surface acoustic waves.",http://arxiv.org/abs/2501.12098v1
"Orientation-dependent transport in junctions formed by $d$-wave
  altermagnets and $d$-wave superconductors",2025-01-21T13:53:21Z,"Wenjun Zhao, Yuri Fukaya, Pablo Burset, Jorge Cayao, Yukio Tanaka, Bo Lu","We investigate de Gennes-Saint-James states and Josephson effect in hybrid
junctions based on $d$-wave altermagnet and $d$-wave superconductor. Even
though these states are associated to long junctions, we find that the
$d_{x^{2}-y^{2}}$-altermagnet in a normal metal/altermagnet/$d$-wave
superconductor junction forms de Gennes-Saint-James states in a short junction
due to an enhanced mismatch between electron and hole wave vectors. As a
result, the zero-bias conductance peak vanishes and pronounced resonance spikes
emerge in the subgap conductance spectra. By contrast, the $d_{xy}$-altermagnet
only features de Gennes-Saint-James states in the long junction. Moreover, the
well-known features such as V-shape conductance for $d_{x^2-y^2}$ pairings and
zero-biased conductance peak for $d_{xy}$ pairings are not affected by the
strength of $d_{xy}$-altermagnetism in the short junction. We also study the
Josephson current-phase relation $I(\varphi)$ of $d$-wave
superconductor/altermagnet/$d$-wave superconductor hybrids, where $\varphi$ is
the macroscopic phase difference between two $d$-wave superconductors. In
symmetric junctions, we obtain anomalous current phase relation such as a
$0$-$\pi$ transition by changing either the orientation or the magnitude of the
altermagnetic order parameter and dominant higher Josephson harmonics.
Interestingly, we find the first-order Josephson coupling in an asymmetric
$d_{x^{2}-y^{2}}$-superconductor/altermagnet/$d_{xy}$-superconductor junction
when the symmetry of altermagnetic order parameter is neither
$d_{x^{2}-y^{2}}$- nor $d_{xy}$-wave. We present the symmetry analysis and
conclude that the anomalous orientation-dependent current-phase relations are
ascribed to the peculiar feature of the altermagnetic spin-splitting field.",http://arxiv.org/abs/2501.12141v2
"MoGERNN: An Inductive Traffic Predictor for Unobserved Locations in
  Dynamic Sensing Networks",2025-01-21T16:52:42Z,"Qishen Zhou, Yifan Zhang, Michail A. Makridis, Anastasios Kouvelas, Yibing Wang, Simon Hu","Given a partially observed road network, how can we predict the traffic state
of unobserved locations? While deep learning approaches show exceptional
performance in traffic prediction, most assume sensors at all locations of
interest, which is impractical due to financial constraints. Furthermore, these
methods typically require costly retraining when sensor configurations change.
We propose MoGERNN, an inductive spatio-temporal graph representation model, to
address these challenges. Inspired by the Mixture of Experts approach in Large
Language Models, we introduce a Mixture of Graph Expert (MoGE) block to model
complex spatial dependencies through multiple graph message aggregators and a
sparse gating network. This block estimates initial states for unobserved
locations, which are then processed by a GRU-based Encoder-Decoder that
integrates a graph message aggregator to capture spatio-temporal dependencies
and predict future states. Experiments on two real-world datasets show MoGERNN
consistently outperforms baseline methods for both observed and unobserved
locations. MoGERNN can accurately predict congestion evolution even in areas
without sensors, offering valuable information for traffic management.
Moreover, MoGERNN is adaptable to dynamic sensing networks, maintaining
competitive performance even compared to its retrained counterpart. Tests with
different numbers of available sensors confirm its consistent superiority, and
ablation studies validate the effectiveness of its key modules.",http://arxiv.org/abs/2501.12281v1
"Cinepro: Robust Training of Foundation Models for Cancer Detection in
  Prostate Ultrasound Cineloops",2025-01-21T18:05:11Z,"Mohamed Harmanani, Amoon Jamzad, Minh Nguyen Nhat To, Paul F. R. Wilson, Zhuoxin Guo, Fahimeh Fooladgar, Samira Sojoudi, Mahdi Gilany, Silvia Chang, Peter Black, Michael Leveridge, Robert Siemens, Purang Abolmaesumi, Parvin Mousavi","Prostate cancer (PCa) detection using deep learning (DL) models has shown
potential for enhancing real-time guidance during biopsies. However, prostate
ultrasound images lack pixel-level cancer annotations, introducing label noise.
Current approaches often focus on limited regions of interest (ROIs),
disregarding anatomical context necessary for accurate diagnosis. Foundation
models can overcome this limitation by analyzing entire images to capture
global spatial relationships; however, they still encounter challenges stemming
from the weak labels associated with coarse pathology annotations in ultrasound
data. We introduce Cinepro, a novel framework that strengthens foundation
models' ability to localize PCa in ultrasound cineloops. Cinepro adapts robust
training by integrating the proportion of cancer tissue reported by pathology
in a biopsy core into its loss function to address label noise, providing a
more nuanced supervision. Additionally, it leverages temporal data across
multiple frames to apply robust augmentations, enhancing the model's ability to
learn stable cancer-related features. Cinepro demonstrates superior performance
on a multi-center prostate ultrasound dataset, achieving an AUROC of 77.1% and
a balanced accuracy of 83.8%, surpassing current benchmarks. These findings
underscore Cinepro's promise in advancing foundation models for weakly labeled
ultrasound data.",http://arxiv.org/abs/2501.12331v1
"ARM-IRL: Adaptive Resilience Metric Quantification Using Inverse
  Reinforcement Learning",2025-01-21T18:43:02Z,"Abhijeet Sahu, Venkatesh Venkataramanan, Richard Macwan","Resilience of safety-critical systems is gaining importance, particularly
with the increasing number of cyber and physical threats. Cyber-physical
threats are becoming increasingly prevalent, as digital systems are ubiquitous
in critical infrastructure. The challenge with determining the resilience of
cyber-physical systems is identifying a set of resilience metrics that can
adapt to the changing states of the system. A static resilience metric can lead
to an inaccurate estimation of system state, and can result in unintended
consequences against cyber threats. In this work, we propose a data-driven
method for adaptive resilience metric learning. The primary goal is to learn a
single resilience metric by formulating an inverse reinforcement learning
problem that learns a reward or objective from a set of control actions from an
expert. It learns the structure or parameters of the reward function based on
information provided by expert demonstrations. Most prior work has considered
static weights or theories from fuzzy logic to formulate a single resilience
metric. Instead, this work learns the resilience metric, represented as reward
function, using adversarial inverse reinforcement learning, to determine the
optimal policy through training the generator discriminator in parallel. We
evaluate our proposed technique in scenarios such as optimal communication
network rerouting, power distribution network reconfiguration, and a combined
cyber-physical restoration of critical load using the IEEE 123-bus system.",http://arxiv.org/abs/2501.12362v1
Physics of Skill Learning,2025-01-21T18:59:49Z,"Ziming Liu, Yizhou Liu, Eric J. Michaud, Jeff Gore, Max Tegmark","We aim to understand physics of skill learning, i.e., how skills are learned
in neural networks during training. We start by observing the Domino effect,
i.e., skills are learned sequentially, and notably, some skills kick off
learning right after others complete learning, similar to the sequential fall
of domino cards. To understand the Domino effect and relevant behaviors of
skill learning, we take physicists' approach of abstraction and simplification.
We propose three models with varying complexities -- the Geometry model, the
Resource model, and the Domino model, trading between reality and simplicity.
The Domino effect can be reproduced in the Geometry model, whose resource
interpretation inspires the Resource model, which can be further simplified to
the Domino model. These models present different levels of abstraction and
simplification; each is useful to study some aspects of skill learning. The
Geometry model provides interesting insights into neural scaling laws and
optimizers; the Resource model sheds light on the learning dynamics of
compositional tasks; the Domino model reveals the benefits of modularity. These
models are not only conceptually interesting -- e.g., we show how Chinchilla
scaling laws can emerge from the Geometry model, but also are useful in
practice by inspiring algorithmic development -- e.g., we show how simple
algorithmic changes, motivated by these toy models, can speed up the training
of deep learning models.",http://arxiv.org/abs/2501.12391v1
Geometric Entropies and their Hamiltonian Flows,2025-01-21T19:00:00Z,"Xi Dong, Donald Marolf, Pratik Rath","In holographic theories, the Hubeny-Rangamani-Takayanagi (HRT) area operator
plays a key role in our understanding of the emergence of semiclassical
Einstein-Hilbert gravity. When higher derivative corrections are included, the
role of the area is instead played by a more general functional known as the
geometric entropy. It is thus of interest to understand the flow generated by
the geometric entropy on the classical phase space. In particular, the fact
that the associated flow in Einstein-Hilbert or Jackiw-Teitelboim (JT) gravity
induces a relative boost between the left and right entanglement wedges is
deeply related to the fact that gravitational dressing promotes the von Neumann
algebra of local fields in each wedge to type II. This relative boost is known
as a boundary-condition-preserving (BCP) kink-transformation. In a general
theory of gravity (with arbitrary higher-derivative terms), it is
straightforward to show that the flow continues to take the above geometric
form when acting on a spacetime where the HRT surface is the bifurcation
surface of a Killing horizon. However, the form of the flow on other spacetimes
is less clear.
  In this paper, we use the manifestly-covariant Peierls bracket to explore
such flows in two-dimensional theories of JT gravity coupled to matter fields
with higher derivative interactions. The results no longer take a purely
geometric form and, instead, demonstrate new features that should be expected
of such flows in general higher derivative theories. We also show how to obtain
the above flows using Poisson brackets.",http://arxiv.org/abs/2501.12438v2
"Survey of Radiative, Two-Temperature Magnetically Arrested Simulations
  of the Black Hole M87* I: Turbulent Electron Heating",2025-01-21T19:00:09Z,Andrew Chael,"We present a set of eleven two-temperature, radiative, general relativistic
magnetohydrodynamic (2TGRRMHD) simulations of the black hole M87* in the
magnetically arrested (MAD) state, surveying different values of the black hole
spin $a_*$. Our 3D simulations self-consistently evolve the temperatures of
separate electron and ion populations under the effects of adiabatic
compression/expansion, viscous heating, Coulomb coupling, and synchrotron,
bremsstrahlung, and inverse Compton radiation. We adopt a sub-grid heating
prescription from gyrokinetic simulations of plasma turbulence. Our simulations
have accretion rates $\dot{M}=(0.5-1.5)\times10^{-6}\dot{M}_{\rm Edd}$ and
radiative efficiencies $\epsilon_{\rm rad}=3-35\%$. We compare our simulations
to a fiducial set of otherwise identical single-fluid GRMHD simulations and
find no significant changes in the outflow efficiency or black hole spindown
parameter. Our simulations produce an effective adiabatic index for the
two-temperature plasma of $\adi\approx1.55$, larger than the $\adi=13/9$ value
often adopted in single-fluid GRMHD simulations. We find moderate
ion-to-electron temperature ratios in the 230 GHz emitting region of $R=T_{\rm
i}/T_{\rm e}{\approx}5$. While total intensity 230 GHz images from our
simulations are consistent with Event Horizon Telescope (EHT) results, our
images have significantly more beam-scale linear polarization
($\langle|m|\rangle\approx 30\%$) than is observed in EHT images of M87*
($\langle|m|\rangle<10\%$). We find a trend of the average linear polarization
pitch angle $\angle\beta_2$ with black hole spin consistent with what is seen
in single-fluid GRMHD simulations, and we provide a simple fitting function for
$\angle\beta_2(a_*)$ motivated by the wind-up of magnetic field lines by black
hole spin in the Blandford-Znajek mechanism.",http://arxiv.org/abs/2501.12448v2
A Unified Invariant Learning Framework for Graph Classification,2025-01-22T02:45:21Z,"Yongduo Sui, Jie Sun, Shuyao Wang, Zemin Liu, Qing Cui, Longfei Li, Xiang Wang","Invariant learning demonstrates substantial potential for enhancing the
generalization of graph neural networks (GNNs) with out-of-distribution (OOD)
data. It aims to recognize stable features in graph data for classification,
based on the premise that these features causally determine the target label,
and their influence is invariant to changes in distribution. Along this line,
most studies have attempted to pinpoint these stable features by emphasizing
explicit substructures in the graph, such as masked or attentive subgraphs, and
primarily enforcing the invariance principle in the semantic space, i.e., graph
representations. However, we argue that focusing only on the semantic space may
not accurately identify these stable features. To address this, we introduce
the Unified Invariant Learning (UIL) framework for graph classification. It
provides a unified perspective on invariant graph learning, emphasizing both
structural and semantic invariance principles to identify more robust stable
features. In the graph space, UIL adheres to the structural invariance
principle by reducing the distance between graphons over a set of stable
features across different environments. Simultaneously, to confirm semantic
invariance, UIL underscores that the acquired graph representations should
demonstrate exemplary performance across diverse environments. We present both
theoretical and empirical evidence to confirm our method's ability to recognize
superior stable features. Moreover, through a series of comprehensive
experiments complemented by in-depth analyses, we demonstrate that UIL
considerably enhances OOD generalization, surpassing the performance of leading
baseline methods. Our codes are available at https://github.com/yongduosui/UIL.",http://arxiv.org/abs/2501.12595v1
Quantification of Large Language Model Distillation,2025-01-22T03:57:52Z,"Sunbowen Lee, Junting Zhou, Chang Ao, Kaige Li, Xinrun Du, Sirui He, Haihong Wu, Tianci Liu, Jiaheng Liu, Hamid Alinejad-Rokny, Min Yang, Yitao Liang, Zhoufutu Wen, Shiwen Ni","Model distillation is a fundamental technique in building large language
models (LLMs), transferring knowledge from a teacher model to a student model.
However, distillation can lead to model homogenization, reducing diversity
among models and impairing their ability to robustly handle complex or novel
tasks. These limitations underscore the need to systematically quantify the
distillation process and its impact. In this work, we propose a framework to
evaluate and quantify model distillation. Our method addresses two key aspects:
(1) Identifying identity cognition contradictions to assess discrepancies in
how models perceive and represent identity-related information, and (2)
Analyzing multi-granularity response similarities across models to measure the
extent of homogenization. Experimental results demonstrate two key insights:
(1) Well-known closed-source and open-source LLMs usually exhibit high
distillation degrees, except for Claude, Doubao, and Gemini. (2) Base LLMs show
higher distillation degrees compared to aligned LLMs. By offering a systematic
approach to improve the transparency of LLM data distillation, we call for LLMs
with more independent development and more transparent technical reports to
improve LLMs' robustness and safety. The code and data are available under
https://github.com/Aegis1863/LLMs-Distillation-Quantification.",http://arxiv.org/abs/2501.12619v3
"Stretching the Printability Metric in Direct-ink Writing with Highly
  Extensible Yield-Stress Fluids",2025-01-22T04:27:42Z,"Chaimongkol Saengow, Samya Sen, Joaquin Yus, Eliza E. Lovrich, Amanda G. Hoika, Kelly M. Chang, Arielle A. Pfeil, Nellie Haug, Amy J. Wagoner Johnson, Randy H. Ewoldt","Direct-ink writing leverages the rheological complexity of yield-stress
fluids to construct complex geometries, particularly those with large gaps
across internal structures. However, extensional rheological properties have
rarely been considered in work that studies rheology-printability correlations.
Here, we test our hypothesis that extensional properties correlate with
drawability, a key indicator of printability that signifies speed robustness,
printing resolution, and gap-spanning performance. We formulated cementitious
suspensions using hydroxyapatite (HAp) particles, independently tuning them for
yield stress and extensibility, two crucial rheological properties, and
test-printed. To enhance extensibility, we incorporated hydroxypropyl
methylcellulose as a polymeric modifier, but this enhancement may decrease as
yield stress increases, presenting a challenge in materials design. We
modulated particle interactions to achieve a wide range of yield stress and
extensibility, allowing for rigorous testing of our hypothesis. This approach
created inks with high extensibility and high yield stress, generally
considered mutually exclusive properties. We evaluated correlations between
drawability and key rheological properties, finding the strongest positive
correlation with extensional failure strains (strain-to-break) rather than
yield stress. We establish a bijective property-manufacturing relationship
(one-on-one mapping of shear yield stress to buildability and extensional
strain-to-break to drawability) by combining our findings on drawability with
previous studies on buildability. This relationship provides a comprehensive
framework for designing high-performance inks that can be self-supporting,
capable of high-speed printing, and allow gap-spanning features.",http://arxiv.org/abs/2501.12630v1
Dynamics of Toxicity in Political Podcasts,2025-01-22T04:58:50Z,"Naquee Rizwan, Nayandeep Deb, Sarthak Roy, Vishwajeet Singh Solanki, Kiran Garimella, Animesh Mukherjee","Toxicity in digital media poses significant challenges, yet little attention
has been given to its dynamics within the rapidly growing medium of podcasts.
This paper addresses this gap by analyzing political podcast data to study the
emergence and propagation of toxicity, focusing on conversation
chains-structured reply patterns within podcast transcripts. Leveraging
state-of-the-art transcription models and advanced conversational analysis
techniques, we systematically examine toxic discourse in over 30 popular
political podcasts in the United States. Our key contributions include: (1)
creating a comprehensive dataset of transcribed and diarized political
podcasts, identifying thousands of toxic instances using Google's Perspective
API, (2) uncovering concerning trends where a majority of episodes contain at
least one toxic instance, (3) introducing toxic conversation chains and
analyzing their structural and linguistic properties, revealing characteristics
such as longer durations, repetitive patterns, figurative language, and
emotional cues tied to anger and annoyance, (4) identifying demand-related
words like 'want', 'like', and 'know' as precursors to toxicity, and (5)
developing predictive models to anticipate toxicity shifts based on annotated
change points. Our findings provide critical insights into podcast toxicity and
establish a foundation for future research on real-time monitoring and
intervention mechanisms to foster healthier discourse in this influential
medium.",http://arxiv.org/abs/2501.12640v1
Detecting and Evaluating Order-Dependent Flaky Tests in JavaScript,2025-01-22T06:52:11Z,"Negar Hashemi, Amjed Tahir, Shawn Rasheed, August Shi, Rachel Blagojevic","Flaky tests pose a significant issue for software testing. A test with a
non-deterministic outcome may undermine the reliability of the testing process,
making tests untrustworthy. Previous research has identified test order
dependency as one of the most prevalent causes of flakiness, particularly in
Java and Python. However, little is known about test order dependency in
JavaScript tests. This paper aims to investigate test order dependency in
JavaScript projects that use Jest, a widely used JavaScript testing framework.
We implemented a systematic approach to randomise tests, test suites and
describe blocks and produced 10 unique test reorders for each level. We reran
each order 10 times (100 reruns for each test suite/project) and recorded any
changes in test outcomes. We then manually analysed each case that showed flaky
outcomes to determine the cause of flakiness. We examined our detection
approach on a dataset of 81 projects obtained from GitHub. Our results revealed
55 order-dependent tests across 10 projects. Most order-dependent tests (52)
occurred between tests, while the remaining three occurred between describe
blocks. Those order-dependent tests are caused by either shared files (13) or
shared mocking state (42) between tests. While sharing files is a known cause
of order-dependent tests in other languages, our results underline a new cause
(shared mocking state) that was not reported previously",http://arxiv.org/abs/2501.12680v1
"Spatial variation of future trends in Atlantic upwelling cells from two
  CMIP6 models",2025-01-22T14:48:14Z,"Raquel Flügel, Steven Herbette, Anne-Marie Treguier, Robin Waldman, Malcolm Roberts","Eastern Boundary Upwelling Systems (EBUS) are characterized by wind-triggered
upwelling of deep waters along the coast. They are hotspots of biological
productivity and diversity and therefore have a high economic, ecological and
social importance. In the past, different methods using surface data have been
used to estimate upwelling. Recently, the IPCC has suggested directly assessing
vertical velocities as a promising method. We use this method to study the two
Atlantic EBUS from CMIP6 models from the HadGEM3-GC3.1 and the CNRM6-CM6
family, for both the historical period and a high-emission future scenario with
spatial resolutions in the ocean component ranging from 1{\deg}to 1/12{\deg}.
The two major upwelling regions are divided in subregions depending on their
seasonality. The vertical transport index shows similar values to a
wind-derived Ekman index. Directly evaluating upwelling from transport
processes further provides information about the depth of the upwelling, which
has previously been identified as an important factor for nutrient
availability. We show that depending on the subregion of the upwelling system
different cell structures can be seen in terms of depth and distance to the
coast of maximum velocities. When looking at possible future changes high
interannual variability limits the significance of the trends but could
indicate a poleward shift of the upwelling regions.A detailed comparison of the
spatial structures and the distinction in subregions is important to explain
contradictory trends in previous works.",http://arxiv.org/abs/2501.12920v1
"Punctuation patterns in ""Finnegans Wake"" by James Joyce are largely
  translation-invariant",2025-01-22T15:27:43Z,"Krzysztof Bartnicki, Stanisław Drożdż, Jarosław Kwapień, Tomasz Stanisz","The complexity characteristics of texts written in natural languages are
significantly related to the rules of punctuation. In particular, the distances
between punctuation marks measured by the number of words quite universally
follow the family of Weibull distributions known from survival analyses.
However, the values of two parameters marking specific forms of these
distributions distinguish specific languages. This is such a strong constraint
that the punctuation distributions of texts translated from the original
language into another adopt quantitative characteristics of the target
language. All these changes take place within Weibull distributions such that
the corresponding hazard functions are always increasing. Recent previous
research shows that James Joyce's famous ""Finnegans Wake"" is subject to such
extreme distribution from the Weibull family that the corresponding hazard
function is clearly decreasing. At the same time, the distances of sentence
ending punctuation marks, determining the variability of sentence length, have
an almost perfect multifractal organization, so far to such an extent found
nowhere else in the literature. In the present contribution based on several
available translations (Dutch, French, German, Polish, Russian) of ""Finnegans
Wake"", it is shown that the punctuation characteristics of this work remain
largely translation invariant, contrary to the common cases. These observations
may constitute further evidence that ""Finnegans Wake"" is a translinguistic work
in this respect as well, in line with Joyce's original intention.",http://arxiv.org/abs/2501.12954v1
"Magnetic Properties of epitaxial
  $\text{Re}/\text{Co}_{1-x}\text{Au}_{x}/\text{Pt}$ heterostructures",2025-01-22T15:36:06Z,"Sukanta Kumar Jena, Anuj Kumar Dhiman, Artem Lynnyk, Kilian Lenz, Gauravkumar Ishwarbhai Patel, Aleksiej Pietruczik, Paweł Aleszkiewicz, Jürgen Lindner, Piotr Dłużewski, Ryszard Gieniusz, Andrzej Maziewski, Ewelina Milińska, Andrzej Wawro","We investigate epitaxial $\text{Co}(20 \, \text{\r{A}})$ and
$\text{Co}_{1-x}\text{Au}_{x}(20 \, \text{\r{A}})$ alloy thin-films surrounded
by asymmetric heavy metals layers of $\text{Re}(10 \, \text{\r{A}})$ as a
buffer and $\text{Pt}(30 \, \text{\r{A}})$ as a cap to study the magnetic
anisotropy, interfacial Dzyaloshinskii-Moriya interaction (iDMI) and damping.
The increase of Au from 0% to 25% in the $\text{Co}_{1-x}\text{Au}_{x}$ alloy
generates the spin-reorientation transition of around 13% of Au. The increase
in Au concentration provides a significant decrease in saturation magnetization
from 1690 kA/m to 982 kA/m measured for Co and $\text{Co}_{75}\text{Au}_{25}$,
respectively. The effective anisotropy constant $\text{K}_{eff}$ is elevated up
to 0.33 $\text{MJ/m}^{3}$ by changing the Au content. Further, our
investigations of the magnetization dynamics have confirmed that the overall
effective damping constant rises with the Au concentration which can be
attributed to the spin pumping effect. The spin pumping leads to the highest
value of effective spin mixing conductance $g^{(\uparrow \downarrow)} \approx
2.91 \times 10^{18} \, \text{m}^{-2}$ in the $\text{Co}_{90}\text{Au}_{10}(20
\, \text{\r{A}})$ system, while the lowest value of $g^{(\uparrow \downarrow)}
\approx 2.25 \times 10^{18} \, \text{m}^{-2}$ is found for the $\text{Co}(20 \,
\text{\r{A}})$ system. Additionally, we have investigated the iDMI strength,
and the amplitude of iDMI decreases with increasing Au concentration. The
highest surface iDMI constant value equal to 2.62 pJ/m is observed for Co.",http://arxiv.org/abs/2501.12961v1
Evolution and The Knightian Blindspot of Machine Learning,2025-01-22T18:38:41Z,"Joel Lehman, Elliot Meyerson, Tarek El-Gaaly, Kenneth O. Stanley, Tarin Ziyaee","This paper claims that machine learning (ML) largely overlooks an important
facet of general intelligence: robustness to a qualitatively unknown future in
an open world. Such robustness relates to Knightian uncertainty (KU) in
economics, i.e. uncertainty that cannot be quantified, which is excluded from
consideration in ML's key formalisms. This paper aims to identify this blind
spot, argue its importance, and catalyze research into addressing it, which we
believe is necessary to create truly robust open-world AI. To help illuminate
the blind spot, we contrast one area of ML, reinforcement learning (RL), with
the process of biological evolution. Despite staggering ongoing progress, RL
still struggles in open-world situations, often failing under unforeseen
situations. For example, the idea of zero-shot transferring a self-driving car
policy trained only in the US to the UK currently seems exceedingly ambitious.
In dramatic contrast, biological evolution routinely produces agents that
thrive within an open world, sometimes even to situations that are remarkably
out-of-distribution (e.g. invasive species; or humans, who do undertake such
zero-shot international driving). Interestingly, evolution achieves such
robustness without explicit theory, formalisms, or mathematical gradients. We
explore the assumptions underlying RL's typical formalisms, showing how they
limit RL's engagement with the unknown unknowns characteristic of an
ever-changing complex world. Further, we identify mechanisms through which
evolutionary processes foster robustness to novel and unpredictable challenges,
and discuss potential pathways to algorithmically embody them. The conclusion
is that the intriguing remaining fragility of ML may result from blind spots in
its formalisms, and that significant gains may result from direct confrontation
with the challenge of KU.",http://arxiv.org/abs/2501.13075v1
iServe: An Intent-based Serving System for LLMs,2025-01-08T14:38:13Z,"Dimitrios Liakopoulos, Tianrui Hu, Prasoon Sinha, Neeraja J. Yadwadkar","Large Language Models (LLMs) are becoming ubiquitous across industries, where
applications demand they fulfill diverse user intents. However, developers
currently face the challenge of manually exploring numerous deployment
configurations - combinations of parallelism and compression techniques that
impact resource usage, latency, cost, and accuracy - to meet these intents.
Assessing the impact of these configurations on user metrics requires
extensive, costly profiling for each model. Existing approaches avoid this
expense by using fixed, static configurations, but this often leads to
sub-optimal performance and higher costs. Moreover, none of these solutions
dynamically adapt to changing user intents to balance latency and cost,
effectively. We present iServe, an automated, intent-based system for
distributed LLM inference. Instead of manually selecting deployment
configurations, developers simply specify their intent - such as minimizing
latency, reducing cost, or meeting specific targets for either. iServe
introduces fingerprints, lightweight representations of LLMs, to efficiently
estimate how different configurations impact latency and memory usage. Based on
these insights and GPU availability, iServe dynamically selects the optimal
configuration to align with the user's intent. For various LLMs and query
arrival rates, iServe best meets user intents compared to state-of-the-art
systems by reducing latency by 77.62% and SLO violations by 7.09x while
improving GPU throughput by 4.72x. Moreover, iServe's fingerprint-based
profiling reduces profiling cost by 6.05x (GPU-hours) compared to baselines.",http://arxiv.org/abs/2501.13111v1
"Preference Curriculum: LLMs Should Always Be Pretrained on Their
  Preferred Data",2025-01-21T13:12:13Z,"Xuemiao Zhang, Liangyu Xu, Feiyu Duan, Yongwei Zhou, Sirui Wang, Rongxiang Weng, Jingang Wang, Xunliang Cai","Large language models (LLMs) generally utilize a consistent data distribution
throughout the pretraining process. However, as the model's capability
improves, it is intuitive that its data preferences dynamically change,
indicating the need for pretraining with different data at various training
stages. To achieve it, we propose the Perplexity Difference (PD) based
Preference Curriculum learning (PDPC) framework, which always perceives and
uses the data preferred by LLMs to train and boost them. First, we introduce
the PD metric to quantify the difference in how challenging a sample is for
weak versus strong models. Samples with high PD are more challenging for weak
models to learn and are more suitable to be arranged in the later stage of
pretraining. Second, we propose the preference function to approximate and
predict the data preference of the LLM at any training step, so as to complete
the arrangement of the dataset offline and ensure continuous training without
interruption. Experimental results on 1.3B and 3B models demonstrate that PDPC
significantly surpasses baselines. Notably, the 3B model trained on 1T tokens
achieves an increased average accuracy of over 8.1% across MMLU and CMMLU.",http://arxiv.org/abs/2501.13126v2
"Spectro-temporal Investigation of Quasi-periodic Oscillations From Black
  Hole X-ray Binary 4U 1630-472 Using $\textit{NICER}$",2025-01-22T19:00:08Z,"Ansh Chopra, Manoneeta Chakraborty, Unnati Kashyap","We present a comprehensive analysis of the spectro-temporal characteristics
of the X-ray variabilities from black hole X-ray binary 4U 1630-472 during its
three outbursts (2018, 2020, and 2021) as observed by $\textit{NICER}$. We
detected 27 Quasi-Periodic Oscillations (QPOs), out of which 25 were observed
during the 2021 outburst. In this study, we specifically focus on the
relationship between spectral and timing parameters and the frequency of type-C
QPOs in the 2021 outburst of the black hole binary 4U 1630-472 during its
rising phase. We found strong correlations between the photon index of the
non-thermal emission and the QPO frequency. We also observed a critical
frequency at $\sim$ 2.31 Hz, above which the behavior of the Q-factor of the
QPO changed significantly with the QPO frequency. We further identified two
events characterized by a surge in the total flux, corresponding to the
disappearance of type-C QPOs. Although the first event appeared like an X-ray
flare, during the second event, the source reached a state with a total flux
higher than 10$^{-8}$ erg/cm$^{2}$/s and exhibited a different type of QPO with
lower frequencies and weaker amplitudes. We compare our results with the
previously reported QPO characteristics for black hole outbursts and discuss
the various models that could interpret the critical frequency and potentially
explain the origin and evolution of these type-C QPOs.",http://arxiv.org/abs/2501.13163v1
"Global Turbulent Solar Convection: a Numerical Path Investigating Key
  Force Balances in the context of the Convective Conundrum",2025-01-22T19:00:30Z,"Quentin Noraz, Allan Sacha Brun, Antoine Strugarek","Understanding solar turbulent convection and its influence on differential
rotation has been a challenge over the past two decades. Current models often
overestimate giant convection cells amplitude, leading to an effective Rossby
number too large and a shift towards an anti-solar rotation regime. This
Convective Conundrum, underscores the need for improved comprehension of solar
convective dynamics. We propose a numerical experiment in the parameter space
that controls $Ro$ while increasing the Reynolds number ($Re$) and maintaining
solar parameters. By controlling the Nusselt number ($Nu$), we limit the energy
transport by convection while reducing viscous dissipation. This approach
enabled us to construct a Sun-like rotating model (SBR97n035) with strong
turbulence ($Re \sim 800$) that exhibits prograde equatorial rotation and
aligns with observational data from helioseismology. We compare this model with
an anti-solar rotating counterpart, and provide an in-depth spectral analysis
to investigate the changes in convective dynamics. We also find the appearance
of vorticity rings near the poles, which existence on the Sun could be probed
in the future. The Sun-like model shows reduced buoyancy over the spectrum, as
well as an extended quasi-geostrophic equilibrium towards smaller scales. This
promotes a Coriolis-Inertia (CI) balance rather than a
Coriolis-Inertia-Archimedes (CIA) balance, in order to favor the establishment
of a prograde equator. The presence of convective columns in the bulk of the
convection zone, with limited surface manifestations, also hints at such
structures potentially occurring in the Sun.",http://arxiv.org/abs/2501.13169v1
"Non-equilibrium ionization in the multiphase circumgalactic medium --
  impact on quasar absorption-line analyses",2025-01-22T19:01:06Z,"Suyash Kumar, Hsiao-Wen Chen","This paper presents an updated framework for studying the ionizing conditions
and elemental abundances of photoionized, metal-enriched quasar absorption
systems. The standard assumption of ionization equilibrium invoked in
absorption line analyses requires gas to cool on longer timescales than ionic
recombination (t_cool >> t_rec). However, this assumption may not be valid at
high metallicities due to enhanced cooling losses. This work presents a suite
of time-dependent photoionization (TDP) models that self-consistently solve for
the ionization state of rapidly cooling gas irradiated by the extragalactic
ultraviolet background (UVB). The updated framework explores various revised
UVBs from recent studies, a range of initial temperatures, and different
elemental abundance patterns to quantify the effects of TDP on the observed ion
fractions. A metal-enriched ($\mathrm{[\alpha/H]}=0.6_{-0.1}^{+0.2}$) C IV
absorption system at z ~ 1 previously studied using photoionization equilibrium
(PIE) models is re-examined under the TDP framework. The main findings are as
follows: (1) varying prescriptions for the underlying UVB or adopting initial
temperatures T_0 < 1e6 K change TDP ion fractions by up to a factor of three,
but the adopted relative elemental abundance pattern affects ion fractions by
at most 40%; (2) the inferred gas densities are consistent between PIE and TDP,
but under TDP solar metallicity cannot be ruled out at more than 2-$\sigma$
significance and a modest non-solar $\mathrm{[C/\alpha]} = 0.2$ is needed to
explain the observed relative ion abundances. Extending the TDP analyses to a
larger sample of super-solar absorption components with high signal-to-noise
absorption spectra is needed to quantify the fraction of metal absorbers
originating in rapid cooling gas.",http://arxiv.org/abs/2501.13170v1
The BVRcIc sky brightness of the Caucasian Mountain Observatory of MSU,2025-01-22T23:06:15Z,"I. A. Komarova, A. M. Tatarnikov, A. V. Sharonova, A. A. Belinskii, N. A. Maslennikova, N. P. Ikonnikova, N. A. Burlak","In this paper we analyse the measurements of the brightness of the night sky
above the CMO SAI MSU in the visible and near-infrared range made in 2019-2014.
In 2023-2024 the median zenith brightness of the moonless night sky was 21.31
mag in the B band, 20.63 mag in the V band, 20.15 mag in the Rc band, and 19.11
mag in the Ic band. In 5 years the sky brightness had increased by 0.7 mag in B
and V, by 0.45 mag in Rc, and ~0.1 mag in Ic. We found that the brightness
growth is mostly (up to ~85%) due to the increasing light pollution from nearby
cities, while the remainder can be attributed to the increase of solar activity
after the 2019 minimum. We discuss how the sky brightness is influenced by such
factors as the airmass and the location of the Sun and the Moon in the sky. A
qualitative analysis of the sky emission spectrum has demonstrated the growing
role of LED lamps in light pollution. These changes in sky brightness which are
only going to get harder favour observations that are less sensitive to the
degree of light pollution - IR photometry and spectroscopy and high-resolution
optical spectroscopy.",http://arxiv.org/abs/2501.13266v1
"Qrazor: Reliable and Effortless 4-bit LLM Quantization by Significant
  Data Razoring",2025-01-23T02:20:08Z,"Dongyoung Lee, Seungkyu Choi, Ik Joon Chang","Large-scale language models (LLMs) excel in language processing tasks but
face deployment challenges due to high memory and computational demands. While
low-bit quantization, such as 4-bit techniques, offers a potential solution,
these methods often suffer from significant accuracy loss or require
considerable effort for implementation such as reordering, rotation, etc. To
address these challenges, we propose QRazor, a simple yet effective
quantization scheme that enables 4-bit quantization of weights, activations,
and KV cache in transformer-based LLMs. QRazor operates in two stages: first,
quantizing data using 8 or 16-bit integers as a basis with absolute max scaling
to preserve accuracy close to full-precision models, and second, compressing
the quantized data to 4-bit using our significant data razoring (SDR)
technique, which retains only the four most salient bits. Without any
additional requirment of fine-tuning or additional training, QRazor achieves
performance similar or better compared to state-of-the-art in 4-bit
quantization method, surpassing Smoothquant and QLLM by over 12 points and
Quarot(RTN) by more than 2.9 points in zero-shot reasoning task accuracy on the
LLaMA2-7B model. Additionally, we introduce an integer-based arithmetic unit
optimized for QRazor, allowing direct low-precision operations on SDR data
without decompression.",http://arxiv.org/abs/2501.13331v2
Geometry-Driven Mechanical Memory in a Random Fibrous Matrix,2025-01-23T06:29:50Z,"Mainak Sarkar, Christina Laukaitis, Amy Wagoner Johnson","Disordered fibrous matrices, formed by the random assembly of fibers, provide
the structural framework for many biological systems and biomaterials. Applied
deformation modifies the alignment and stress states of constituent fibers,
tuning the nonlinear elastic response of these materials. While it is generally
presumed that fibers return to their original configurations after deformation
is released, except when neighboring fibers coalesce or individual fibers
yield, this reversal process remains largely unexplored. The intricate geometry
of these matrices leaves an incomplete understanding of whether releasing
deformation fully restores the matrix or introduces new microstructural
deformation mechanisms. To address this gap, we investigated the evolution of
matrix microstructures during the release of an applied deformation. Numerical
simulations were performed on quasi-two-dimensional matrices of random fibers
under localized tension, with fibers modeled as beams in finite element
analysis. After tension release, the matrix exhibited permanent mechanical
remodeling, with greater remodeling occurring at higher magnitudes of applied
tension, indicative of the matrix preserving its loading history as mechanical
memory. This response was surprising; it occurred despite the absence of
explicit plasticity mechanisms, such as activation of inter-fiber cohesion or
fiber yielding. We attributed the observed remodeling to the gradient in fiber
alignment that developed within the matrix microstructure under applied
tension, driving the subsequent changes in matrix properties during the release
of applied tension. Therefore, random fibrous matrices tend to retain
mechanical memory due to their intricate geometry.",http://arxiv.org/abs/2501.13409v1
"BMG-Q: Localized Bipartite Match Graph Attention Q-Learning for
  Ride-Pooling Order Dispatch",2025-01-23T08:01:24Z,"Yulong Hu, Siyuan Feng, Sen Li","This paper introduces Localized Bipartite Match Graph Attention Q-Learning
(BMG-Q), a novel Multi-Agent Reinforcement Learning (MARL) algorithm framework
tailored for ride-pooling order dispatch. BMG-Q advances ride-pooling
decision-making process with the localized bipartite match graph underlying the
Markov Decision Process, enabling the development of novel Graph Attention
Double Deep Q Network (GATDDQN) as the MARL backbone to capture the dynamic
interactions among ride-pooling vehicles in fleet. Our approach enriches the
state information for each agent with GATDDQN by leveraging a localized
bipartite interdependence graph and enables a centralized global coordinator to
optimize order matching and agent behavior using Integer Linear Programming
(ILP). Enhanced by gradient clipping and localized graph sampling, our GATDDQN
improves scalability and robustness. Furthermore, the inclusion of a posterior
score function in the ILP captures the online exploration-exploitation
trade-off and reduces the potential overestimation bias of agents, thereby
elevating the quality of the derived solutions. Through extensive experiments
and validation, BMG-Q has demonstrated superior performance in both training
and operations for thousands of vehicle agents, outperforming benchmark
reinforcement learning frameworks by around 10% in accumulative rewards and
showing a significant reduction in overestimation bias by over 50%.
Additionally, it maintains robustness amidst task variations and fleet size
changes, establishing BMG-Q as an effective, scalable, and robust framework for
advancing ride-pooling order dispatch operations.",http://arxiv.org/abs/2501.13448v1
"Occamy: A Preemptive Buffer Management for On-chip Shared-memory
  Switches",2025-01-23T11:19:05Z,"Danfeng Shan, Yunguang Li, Jinchao Ma, Zhenxing Zhang, Zeyu Liang, Xinyu Wen, Hao Li, Wanchun Jiang, Nan Li, Fengyuan Ren","Today's high-speed switches employ an on-chip shared packet buffer. The
buffer is becoming increasingly insufficient as it cannot scale with the
growing switching capacity. Nonetheless, the buffer needs to face highly
intense bursts and meet stringent performance requirements for datacenter
applications. This imposes rigorous demand on the Buffer Management (BM)
scheme, which dynamically allocates the buffer across queues. However, the de
facto BM scheme, designed over two decades ago, is ill-suited to meet the
requirements of today's network. In this paper, we argue that shallow-buffer
switches, intense bursts, along with dynamic traffic call for a highly agile BM
that can quickly adjust the buffer allocation as traffic changes. However, the
agility of the current BM is fundamentally limited by its non-preemptive
nature. Nonetheless, we find that preemptive BM, considered unrealizable in
history, is now feasible on modern switch chips. We propose Occamy, a
preemptive BM that can quickly adjust buffer allocation. Occamy utilizes the
redundant memory bandwidth to actively reclaim and reallocate the
over-allocated buffer. Testbed experiments and large-scale simulations show
that Occamy can improve the end-to-end performance by up to ~55%.",http://arxiv.org/abs/2501.13570v1
Spin-polarized STM measurement scheme for quantum geometric tensor,2025-01-23T11:55:27Z,"Shu-Hui Zhang, Jin Yang, Ding-Fu Shao, Jia-Ji Zhu, Wen-Long You, Wen Yang, Kai Chang","Quantum geometric tensor (QGT) reflects the geometry of the eigenstates of a
system's Hamiltonian. The full characterization of QGT is essential for various
quantum systems. However, it is challenging to characterize the QGT of the
solid-state systems. Here we present a scheme by using spin-polarized STM to
measure QGT of two-dimensional solid-state systems, in which the spin texture
is extracted from geometric amplitudes of Friedel oscillations induced by the
intentionally introduced magnetic impurity and then the QGT is derived from the
momentum differential of spin texture. The surface states of topological
insulator (TISS), as a model spin system, is promising to demonstrate the
scheme. In a TI slab, the gapped TISS host finite quantum metric and Berry
curvature as the symmetric real part and the antisymmetric imaginary part of
QGT, respectively. Thus, a detailed calculations guide the use of the developed
scheme to measure the QGT of gapped TISS with or without an external in-plane
magnetic field. This study provides a feasible scheme for measuring QGT of
two-dimensional solid-state systems, and hints at the great potential of the
information extraction from the geometric amplitudes of STM and other
measurement.",http://arxiv.org/abs/2501.13588v1
"Survey of image processing settings used for mammography systems in the
  United Kingdom: how variable is it?",2025-01-23T12:05:26Z,"Alistair Mackenzie, John Loveland, Ruben van Engen","The aim was to undertake a national survey of the setup of mammography
imaging systems in the UK, we were particularly interested in image processing
and software version. We created a program that can extract selected tags from
the DICOM header. 28 medical physics departments used the program on processed
images of the TORMAM phantom acquired since 2023 and this produced data for 497
systems. We received data for 7 different models of mammography systems. We
found that currently in use each model had between 2 and 7 different versions
of software for the acquisition workstation. Each of the systems had multiple
versions of image processing settings, a preliminary investigation with TORMAM
demonstrated large differences in the appearance of the image for the same
X-ray model. The Fujifilm, GE and Siemens systems showed differences in the
setup of the dose levels. In addition to these settings there were differences
in the paddles used and grid type. Our snapshot of system set up showed that
there is a potential for the images to appear differently according to the
settings seen in the headers. These differences may affect the outcomes of AI
and also human readers. Thus the introduction of AI must take these differences
into consideration and the inevitably changes of settings in the future. There
are responsibilities on AI suppliers, physics, mammographic equipment
manufacturers, and breast-screening units to manage the use of AI and ensure
the outcomes of breast screening are not adversely affected by the set-up of
equipment.",http://arxiv.org/abs/2501.13595v1
Recurrence Plots for the Analysis of Complex Systems,2025-01-09T14:49:48Z,"Norbert Marwan, Maria Carmen Romano, Marco Thiel, Jürgen Kurths","Recurrence is a fundamental property of dynamical systems, which can be
exploited to characterise the system's behaviour in phase space. A powerful
tool for their visualisation and analysis called recurrence plot was introduced
in the late 1980's. This report is a comprehensive overview covering recurrence
based methods and their applications with an emphasis on recent developments.
After a brief outline of the theory of recurrences, the basic idea of the
recurrence plot with its variations is presented. This includes the
quantification of recurrence plots, like the recurrence quantification
analysis, which is highly effective to detect, e. g., transitions in the
dynamics of systems from time series. A main point is how to link recurrences
to dynamical invariants and unstable periodic orbits. This and further evidence
suggest that recurrences contain all relevant information about a system's
behaviour. As the respective phase spaces of two systems change due to
coupling, recurrence plots allow studying and quantifying their interaction.
This fact also provides us with a sensitive tool for the study of
synchronisation of complex systems. In the last part of the report several
applications of recurrence plots in economy, physiology, neuroscience, earth
sciences, astrophysics and engineering are shown. The aim of this work is to
provide the readers with the know how for the application of recurrence plot
based methods in their own field of research. We therefore detail the analysis
of data and indicate possible difficulties and pitfalls.",http://arxiv.org/abs/2501.13933v1
"A Survey of Graph Retrieval-Augmented Generation for Customized Large
  Language Models",2025-01-21T06:25:21Z,"Qinggang Zhang, Shengyuan Chen, Yuanchen Bei, Zheng Yuan, Huachi Zhou, Zijin Hong, Junnan Dong, Hao Chen, Yi Chang, Xiao Huang","Large language models (LLMs) have demonstrated remarkable capabilities in a
wide range of tasks, yet their application to specialized domains remains
challenging due to the need for deep expertise. Retrieval-augmented generation
(RAG) has emerged as a promising solution to customize LLMs for professional
fields by seamlessly integrating external knowledge bases, enabling real-time
access to domain-specific expertise during inference. Despite its potential,
traditional RAG systems, based on flat text retrieval, face three critical
challenges: (i) complex query understanding in professional contexts, (ii)
difficulties in knowledge integration across distributed sources, and (iii)
system efficiency bottlenecks at scale. This survey presents a systematic
analysis of Graph-based Retrieval-Augmented Generation (GraphRAG), a new
paradigm that revolutionizes domain-specific LLM applications. GraphRAG
addresses traditional RAG limitations through three key innovations: (i)
graph-structured knowledge representation that explicitly captures entity
relationships and domain hierarchies, (ii) efficient graph-based retrieval
techniques that enable context-preserving knowledge retrieval with multihop
reasoning ability, and (iii) structure-aware knowledge integration algorithms
that leverage retrieved knowledge for accurate and logical coherent generation
of LLMs. In this survey, we systematically analyze the technical foundations of
GraphRAG and examine current implementations across various professional
domains, identifying key technical challenges and promising research
directions. All the related resources of GraphRAG, including research papers,
open-source data, and projects, are collected for the community in
\textcolor{blue}{\url{https://github.com/DEEP-PolyU/Awesome-GraphRAG}}.",http://arxiv.org/abs/2501.13958v1
"Reddit Rules and Rulers: Quantifying the Link Between Rules and
  Perceptions of Governance across Thousands of Communities",2025-01-24T01:26:41Z,"Leon Leibmann, Galen Weld, Amy X. Zhang, Tim Althoff","Rules are a critical component of the functioning of nearly every online
community, yet it is challenging for community moderators to make data-driven
decisions about what rules to set for their communities. The connection between
a community's rules and how its membership feels about its governance is not
well understood. In this work, we conduct the largest-to-date analysis of rules
on Reddit, collecting a set of 67,545 unique rules across 5,225 communities
which collectively account for more than 67% of all content on Reddit. More
than just a point-in-time study, our work measures how communities change their
rules over a 5+ year period. We develop a method to classify these rules using
a taxonomy of 17 key attributes extended from previous work. We assess what
types of rules are most prevalent, how rules are phrased, and how they vary
across communities of different types. Using a dataset of communities'
discussions about their governance, we are the first to identify the rules most
strongly associated with positive community perceptions of governance: rules
addressing who participates, how content is formatted and tagged, and rules
about commercial activities. We conduct a longitudinal study to quantify the
impact of adding new rules to communities, finding that after a rule is added,
community perceptions of governance immediately improve, yet this effect
diminishes after six months. Our results have important implications for
platforms, moderators, and researchers. We make our classification model and
rules datasets public to support future research on this topic.",http://arxiv.org/abs/2501.14163v1
ENTER: Event Based Interpretable Reasoning for VideoQA,2025-01-24T02:56:59Z,"Hammad Ayyubi, Junzhang Liu, Ali Asgarov, Zaber Ibn Abdul Hakim, Najibul Haque Sarker, Zhecan Wang, Chia-Wei Tang, Hani Alomari, Md. Atabuzzaman, Xudong Lin, Naveen Reddy Dyava, Shih-Fu Chang, Chris Thomas","In this paper, we present ENTER, an interpretable Video Question Answering
(VideoQA) system based on event graphs. Event graphs convert videos into
graphical representations, where video events form the nodes and event-event
relationships (temporal/causal/hierarchical) form the edges. This structured
representation offers many benefits: 1) Interpretable VideoQA via generated
code that parses event-graph; 2) Incorporation of contextual visual information
in the reasoning process (code generation) via event graphs; 3) Robust VideoQA
via Hierarchical Iterative Update of the event graphs. Existing interpretable
VideoQA systems are often top-down, disregarding low-level visual information
in the reasoning plan generation, and are brittle. While bottom-up approaches
produce responses from visual data, they lack interpretability. Experimental
results on NExT-QA, IntentQA, and EgoSchema demonstrate that not only does our
method outperform existing top-down approaches while obtaining competitive
performance against bottom-up approaches, but more importantly, offers superior
interpretability and explainability in the reasoning process.",http://arxiv.org/abs/2501.14194v1
"VideoShield: Regulating Diffusion-based Video Generation Models via
  Watermarking",2025-01-24T02:57:09Z,"Runyi Hu, Jie Zhang, Yiming Li, Jiwei Li, Qing Guo, Han Qiu, Tianwei Zhang","Artificial Intelligence Generated Content (AIGC) has advanced significantly,
particularly with the development of video generation models such as
text-to-video (T2V) models and image-to-video (I2V) models. However, like other
AIGC types, video generation requires robust content control. A common approach
is to embed watermarks, but most research has focused on images, with limited
attention given to videos. Traditional methods, which embed watermarks
frame-by-frame in a post-processing manner, often degrade video quality. In
this paper, we propose VideoShield, a novel watermarking framework specifically
designed for popular diffusion-based video generation models. Unlike
post-processing methods, VideoShield embeds watermarks directly during video
generation, eliminating the need for additional training. To ensure video
integrity, we introduce a tamper localization feature that can detect changes
both temporally (across frames) and spatially (within individual frames). Our
method maps watermark bits to template bits, which are then used to generate
watermarked noise during the denoising process. Using DDIM Inversion, we can
reverse the video to its original watermarked noise, enabling straightforward
watermark extraction. Additionally, template bits allow precise detection for
potential temporal and spatial modification. Extensive experiments across
various video models (both T2V and I2V models) demonstrate that our method
effectively extracts watermarks and detects tamper without compromising video
quality. Furthermore, we show that this approach is applicable to image
generation models, enabling tamper detection in generated images as well. Codes
and models are available at
\href{https://github.com/hurunyi/VideoShield}{https://github.com/hurunyi/VideoShield}.",http://arxiv.org/abs/2501.14195v1
"Serving Long-Context LLMs at the Mobile Edge: Test-Time Reinforcement
  Learning-based Model Caching and Inference Offloading",2025-01-24T03:21:20Z,"Minrui Xu, Dusit Niyato, Christopher G. Brinton","Large Language Models (LLMs) can perform zero-shot learning on unseen tasks
and few-shot learning on complex reasoning tasks. However, resource-limited
mobile edge networks struggle to support long-context LLM serving for LLM
agents during multi-round interactions with users. Unlike stateless computation
offloading and static service offloading in edge computing, optimizing LLM
serving at edge servers is challenging because LLMs continuously learn from
context which raises accuracy, latency, and resource consumption dynamics. In
this paper, we propose a joint model caching and inference offloading framework
that utilizes test-time deep reinforcement learning (T2DRL) to optimize
deployment and execution strategies for long-context LLM serving. In this
framework, we analyze the performance convergence and design an optimization
problem considering the utilization of context windows in LLMs. Furthermore,
the T2DRL algorithm can learn in both the training phase and the testing phase
to proactively manage cached models and service requests and adapt to context
changes and usage patterns during execution. To further enhance resource
allocation efficiency, we propose a double Dutch auction (DDA) mechanism, which
dynamically matches supply and demand while maximizing social welfare. Finally,
experimental results demonstrate that the T2DRL algorithm can reduce system
costs by at least 30% compared to baselines while guaranteeing the performance
of LLM agents in real-world perception and reasoning tasks.",http://arxiv.org/abs/2501.14205v1
"GreedyPixel: Fine-Grained Black-Box Adversarial Attack Via Greedy
  Algorithm",2025-01-24T04:17:03Z,"Hanrui Wang, Ching-Chun Chang, Chun-Shien Lu, Christopher Leckie, Isao Echizen","A critical requirement for deep learning models is ensuring their robustness
against adversarial attacks. These attacks commonly introduce noticeable
perturbations, compromising the visual fidelity of adversarial examples.
Another key challenge is that while white-box algorithms can generate effective
adversarial perturbations, they require access to the model gradients, limiting
their practicality in many real-world scenarios. Existing attack mechanisms
struggle to achieve similar efficacy without access to these gradients. In this
paper, we introduce GreedyPixel, a novel pixel-wise greedy algorithm designed
to generate high-quality adversarial examples using only query-based feedback
from the target model. GreedyPixel improves computational efficiency in what is
typically a brute-force process by perturbing individual pixels in sequence,
guided by a pixel-wise priority map. This priority map is constructed by
ranking gradients obtained from a surrogate model, providing a structured path
for perturbation. Our results demonstrate that GreedyPixel achieves attack
success rates comparable to white-box methods without the need for gradient
information, and surpasses existing algorithms in black-box settings, offering
higher success rates, reduced computational time, and imperceptible
perturbations. These findings underscore the advantages of GreedyPixel in terms
of attack efficacy, time efficiency, and visual quality.",http://arxiv.org/abs/2501.14230v1
Pre-train and Fine-tune: Recommenders as Large Models,2025-01-24T06:18:12Z,"Zhenhao Jiang, Chenghao Chen, Hao Feng, Yu Yang, Jin Liu, Jie Zhang, Jia Jia, Ning Hu","In reality, users have different interests in different periods, regions,
scenes, etc. Such changes in interest are so drastic that they are difficult to
be captured by recommenders. Existing multi-domain learning can alleviate this
problem. However, the structure of the industrial recommendation system is
complex, the amount of data is huge, and the training cost is extremely high,
so it is difficult to modify the structure of the industrial recommender and
re-train it. To fill this gap, we consider recommenders as large pre-trained
models and fine-tune them. We first propose the theory of the information
bottleneck for fine-tuning and present an explanation for the fine-tuning
technique in recommenders. To tailor for recommendation, we design an
information-aware adaptive kernel (IAK) technique to fine-tune the pre-trained
recommender. Specifically, we define fine-tuning as two phases: knowledge
compression and knowledge matching and let the training stage of IAK explicitly
approximate these two phases. Our proposed approach designed from the essence
of fine-tuning is well interpretable. Extensive online and offline experiments
show the superiority of our proposed method. Besides, we also share unique and
important lessons we learned when deploying the method in a large-scale online
platform. We also present the potential issues of fine-tuning techniques in
recommendation systems and the corresponding solutions. The recommender with
IAK technique has been deployed on the homepage of a billion-scale online food
platform for several months and has yielded considerable profits in our
business.",http://arxiv.org/abs/2501.14268v1
"Exploring the sustainable scaling of AI dilemma: A projective study of
  corporations' AI environmental impacts",2025-01-24T08:58:49Z,"Clément Desroches, Martin Chauvin, Louis Ladan, Caroline Vateau, Simon Gosset, Philippe Cordier","The rapid growth of artificial intelligence (AI), particularly Large Language
Models (LLMs), has raised concerns regarding its global environmental impact
that extends beyond greenhouse gas emissions to include consideration of
hardware fabrication and end-of-life processes. The opacity from major
providers hinders companies' abilities to evaluate their AI-related
environmental impacts and achieve net-zero targets.
  In this paper, we propose a methodology to estimate the environmental impact
of a company's AI portfolio, providing actionable insights without
necessitating extensive AI and Life-Cycle Assessment (LCA) expertise. Results
confirm that large generative AI models consume up to 4600x more energy than
traditional models. Our modelling approach, which accounts for increased AI
usage, hardware computing efficiency, and changes in electricity mix in line
with IPCC scenarios, forecasts AI electricity use up to 2030. Under a high
adoption scenario, driven by widespread Generative AI and agents adoption
associated to increasingly complex models and frameworks, AI electricity use is
projected to rise by a factor of 24.4.
  Mitigating the environmental impact of Generative AI by 2030 requires
coordinated efforts across the AI value chain. Isolated measures in hardware
efficiency, model efficiency, or grid improvements alone are insufficient. We
advocate for standardized environmental assessment frameworks, greater
transparency from the all actors of the value chain and the introduction of a
""Return on Environment"" metric to align AI development with net-zero goals.",http://arxiv.org/abs/2501.14334v2
"SKIL: Semantic Keypoint Imitation Learning for Generalizable
  Data-efficient Manipulation",2025-01-24T11:11:53Z,"Shengjie Wang, Jiacheng You, Yihang Hu, Jiongye Li, Yang Gao","Real-world tasks such as garment manipulation and table rearrangement demand
robots to perform generalizable, highly precise, and long-horizon actions.
Although imitation learning has proven to be an effective approach for teaching
robots new skills, large amounts of expert demonstration data are still
indispensible for these complex tasks, resulting in high sample complexity and
costly data collection. To address this, we propose Semantic Keypoint Imitation
Learning (SKIL), a framework which automatically obtain semantic keypoints with
help of vision foundation models, and forms the descriptor of semantic
keypoints that enables effecient imitation learning of complex robotic tasks
with significantly lower sample complexity. In real world experiments, SKIL
doubles the performance of baseline methods in tasks such as picking a cup or
mouse, while demonstrating exceptional robustness to variations in objects,
environmental changes, and distractors. For long-horizon tasks like hanging a
towel on a rack where previous methods fail completely, SKIL achieves a mean
success rate of 70\% with as few as 30 demonstrations. Furthermore, SKIL
naturally supports cross-embodiment learning due to its semantic keypoints
abstraction, our experiments demonstrate that even human videos bring
considerable improvement to the learning performance. All these results
demonstrate the great success of SKIL in achieving data-efficint generalizable
robotic learning. Visualizations and code are available at:
https://skil-robotics.github.io/SKIL-robotics/.",http://arxiv.org/abs/2501.14400v1
Optimizing Human Pose Estimation Through Focused Human and Joint Regions,2025-01-24T12:17:47Z,"Yingying Jiao, Zhigang Wang, Zhenguang Liu, Shaojing Fan, Sifan Wu, Zheqi Wu, Zhuoyue Xu","Human pose estimation has given rise to a broad spectrum of novel and
compelling applications, including action recognition, sports analysis, as well
as surveillance. However, accurate video pose estimation remains an open
challenge. One aspect that has been overlooked so far is that existing methods
learn motion clues from all pixels rather than focusing on the target human
body, making them easily misled and disrupted by unimportant information such
as background changes or movements of other people. Additionally, while the
current Transformer-based pose estimation methods has demonstrated impressive
performance with global modeling, they struggle with local context perception
and precise positional identification. In this paper, we try to tackle these
challenges from three aspects: (1) We propose a bilayer Human-Keypoint Mask
module that performs coarse-to-fine visual token refinement, which gradually
zooms in on the target human body and keypoints while masking out unimportant
figure regions. (2) We further introduce a novel deformable cross attention
mechanism and a bidirectional separation strategy to adaptively aggregate
spatial and temporal motion clues from constrained surrounding contexts. (3) We
mathematically formulate the deformable cross attention, constraining that the
model focuses solely on the regions centered at the target person body.
Empirically, our method achieves state-of-the-art performance on three
large-scale benchmark datasets. A remarkable highlight is that our method
achieves an 84.8 mean Average Precision (mAP) on the challenging wrist joint,
which significantly outperforms the 81.5 mAP achieved by the current
state-of-the-art method on the PoseTrack2017 dataset.",http://arxiv.org/abs/2501.14439v1
Two-photon scattering in a waveguide by a giant atom,2025-01-24T12:53:50Z,"Yang Xue, Yu-xi Liu","We study two-photon scattering by a two-level giant atom in a waveguide. We
first study the case that the giant atom is coupled to the waveguide via two
coupling points, and obtain Bethe ansatz eigenstates and eigenvalues in the
Hilbert space of two-excitation. Then we derive bound states by subtracting the
states corresponding to Bethe ansatz solutions from the entire two-excitation
Hilbert space, and construct the two-photon scattering matrix (S-matrix) by
using Bethe ansatz eigenstates and bound states. We further study the
properties of output states, which include both the scattering and bound
states, for arbitrarily incident two-photon states by using a concrete example.
We find that the oscillation period of the scattering states and decay rates of
the bound states strongly depend on the distance between two coupling points.
Moreover, we find that the two-photon correlation in the bound states can be
enhanced by changing such distance when the total energy of two incident
photons equals to two times of single photon resonance energy. We also
generalize our study to the case that the giant atom is coupled to the
waveguide via $N$ coupling points. We obtain all the eigenstates and
eigenvalues of the scattering matrix and construct the S-matrix. Comparing with
the case of the two coupling points, we find the photon correlation can be
further enhanced by increasing the number of the coupling points for the same
incident states when the distance of any two nearest neighbor coupling points
is half of the wavelength.",http://arxiv.org/abs/2501.14464v1
"Registration of Longitudinal Liver Examinations for Tumor Progress
  Assessment",2025-01-24T13:35:59Z,"Walid Yassine, Martin Charachon, Céline Hudelot, Roberto Ardon","Assessing cancer progression in liver CT scans is a clinical challenge,
requiring a comparison of scans at different times for the same patient.
Practitioners must identify existing tumors, compare them with prior exams,
identify new tumors, and evaluate overall disease evolution. This process is
particularly complex in liver examinations due to misalignment between exams
caused by several factors. Indeed, longitudinal liver examinations can undergo
different non-pathological and pathological changes due to non-rigid
deformations, the appearance or disappearance of pathologies, and other
variations. In such cases, existing registration approaches, mainly based on
intrinsic features may distort tumor regions, biasing the tumor progress
evaluation step and the corresponding diagnosis. This work proposes a
registration method based only on geometrical and anatomical information from
liver segmentation, aimed at aligning longitudinal liver images for aided
diagnosis. The proposed method is trained and tested on longitudinal liver CT
scans, with 317 patients for training and 53 for testing. Our experimental
results support our claims by showing that our method is better than other
registration techniques by providing a smoother deformation while preserving
the tumor burden (total volume of tissues considered as tumor) within the
volume. Qualitative results emphasize the importance of smooth deformations in
preserving tumor appearance.",http://arxiv.org/abs/2501.14483v1
"Extracting the X-ray reverberation response functions from the AGN light
  curves using an autoencoder",2025-01-24T16:37:00Z,"Sanhanat Deesamutara, Poemwai Chainakun, Tirawut Worrakitpoonpon, Kamonwan Khanthasombat, Wasutep Luangtip, Jiachen Jiang, Francisco Pozo Nuñez, Andrew J. Young","We study the X-ray reverberation in active galactic nuclei (AGN) using the
variational autoencoder (VAE), which is a machine-learning algorithm widely
used for signal processing and feature reconstruction. While the X-ray
reverberation signatures that contain the information of the accretion disk and
the X-ray emitting corona are commonly analyzed in the Fourier domain, this
work aims to extract the reverberation response functions directly from the AGN
light curves. The VAE is trained using the simulated light curves that contain
the primary X-rays from the lamp-post corona varying its height and the
corresponding reflection X-rays from the disk. We use progressively more
realistic light-curve models, such as those that include the effects of
disk-propagating fluctuations and random noises, to assess the ability of the
VAE to reconstruct the response profiles. Interestingly, the VAE can recognize
the reverberation patterns on the light curves, hence the coronal height can be
predicted. We then deploy the VAE model to the XMM-Newton data of IRAS
13224-3809 and directly estimate, for the first time, the response functions of
this source in various observations. The result reveals the corona changing its
height between $3~r_{\rm g}$ and $20~r_{\rm g}$, which is correlated with the
source luminosity and in line with previous literature. Finally, we discuss the
advantages and limitations of this method.",http://arxiv.org/abs/2501.14618v1
An Attentive Graph Agent for Topology-Adaptive Cyber Defence,2025-01-24T18:22:37Z,"Ilya Orson Sandoval, Isaac Symes Thompson, Vasilios Mavroudis, Chris Hicks","As cyber threats grow increasingly sophisticated, reinforcement learning (RL)
is emerging as a promising technique to create intelligent and adaptive cyber
defense systems. However, most existing autonomous defensive agents have
overlooked the inherent graph structure of computer networks subject to cyber
attacks, potentially missing critical information and constraining their
adaptability. To overcome these limitations, we developed a custom version of
the Cyber Operations Research Gym (CybORG) environment, encoding network state
as a directed graph with realistic low-level features. We employ a Graph
Attention Network (GAT) architecture to process node, edge, and global
features, and adapt its output to be compatible with policy gradient methods in
RL. Our GAT-based approach offers key advantages over flattened alternatives:
policies that demonstrate resilience to certain types of unexpected dynamic
network topology changes, reasonable generalisation to networks of varying
sizes within the same structural distribution, and interpretable defensive
actions grounded in tangible network properties. We demonstrate that GAT
defensive policies can be trained using our low-level directed graph
observations, even when unexpected connections arise during simulation.
Evaluations across networks of different sizes, but consistent subnetwork
structure, show our policies achieve comparable performance to policies trained
specifically for each network configuration. Our study contributes to the
development of robust cyber defence systems that can better adapt to real-world
network security challenges.",http://arxiv.org/abs/2501.14700v3
"Decision-Focused Learning for Complex System Identification: HVAC
  Management System Application",2025-01-24T18:32:31Z,"Pietro Favaro, Jean-François Toubeau, François Vallée, Yury Dvorkin","As opposed to conventional training methods tailored to minimize a given
statistical metric or task-agnostic loss (e.g., mean squared error),
Decision-Focused Learning (DFL) trains machine learning models for optimal
performance in downstream decision-making tools. We argue that DFL can be
leveraged to learn the parameters of system dynamics, expressed as constraint
of the convex optimization control policy, while the system control signal is
being optimized, thus creating an end-to-end learning framework. This is
particularly relevant for systems in which behavior changes once the control
policy is applied, hence rendering historical data less applicable. The
proposed approach can perform system identification - i.e., determine
appropriate parameters for the system analytical model - and control
simultaneously to ensure that the model's accuracy is focused on areas most
relevant to control. Furthermore, because black-box systems are
non-differentiable, we design a loss function that requires solely to measure
the system response. We propose pre-training on historical data and constraint
relaxation to stabilize the DFL and deal with potential infeasibilities in
learning. We demonstrate the usefulness of the method on a building Heating,
Ventilation, and Air Conditioning day-ahead management system for a realistic
15-zone building located in Denver, US. The results show that the conventional
RC building model, with the parameters obtained from historical data using
supervised learning, underestimates HVAC electrical power consumption. For our
case study, the ex-post cost is on average six times higher than the expected
one. Meanwhile, the same RC model with parameters obtained via DFL
underestimates the ex-post cost only by 3%.",http://arxiv.org/abs/2501.14708v1
"A Wearable Strain-Sensor-Based Shoulder Patch for Fatigue Detection in
  Bicep Curls",2025-01-10T06:21:17Z,"Ming Xuan Chua, Shuhua Peng, Thanh Nho Do, Chun Hui Wang, Liao Wu","A common challenge in home-based rehabilitation is muscle compensation
induced by pain or fatigue, where patients with weakened primary muscles
recruit secondary muscle groups to assist their movement, causing issues such
as delayed rehabilitation progress or risk of further injury. In a home-based
setting, the subtle compensatory actions may not be perceived since
physiotherapists cannot directly observe patients. To address this problem,
this study develops a novel wearable strain-sensor-based shoulder patch to
detect fatigue-induced muscle compensation during bicep curl exercises. Built
on an observation that the amplitude of a strain sensor's resistance is
correlated to the motion of a joint that the sensor is attached to, we develop
an algorithm that can robustly detect the state when significant changes appear
in the shoulder joint motion, which indicates fatigue-induced muscle
compensation in bicep curls. The developed shoulder patch is tested on 13
subjects who perform bicep curl exercises with a 5 kg dumbell until reaching
fatigue. During the experiment, the performance of the shoulder patch is also
benchmarked with optical tracking sensors and surface electromyography (sEMG)
sensors. Results reveal that the proposed wearable sensor and detection methods
effectively monitor fatigue-induced muscle compensation during bicep curl
exercises in both Real-Time and Post Hoc modes. This development marks a
significant step toward enhancing the effectiveness of home-based
rehabilitation by providing physiotherapists with a tool to monitor and adjust
treatment plans remotely.",http://arxiv.org/abs/2501.14792v1
"Eagle 2: Building Post-Training Data Strategies from Scratch for
  Frontier Vision-Language Models",2025-01-20T18:40:47Z,"Zhiqi Li, Guo Chen, Shilong Liu, Shihao Wang, Vibashan VS, Yishen Ji, Shiyi Lan, Hao Zhang, Yilin Zhao, Subhashree Radhakrishnan, Nadine Chang, Karan Sapra, Amala Sanjay Deshmukh, Tuomas Rintamaki, Matthieu Le, Ilia Karmanov, Lukas Voegtle, Philipp Fischer, De-An Huang, Timo Roman, Tong Lu, Jose M. Alvarez, Bryan Catanzaro, Jan Kautz, Andrew Tao, Guilin Liu, Zhiding Yu","Recently, promising progress has been made by open-source vision-language
models (VLMs) in bringing their capabilities closer to those of proprietary
frontier models. However, most open-source models only publish their final
model weights, leaving the critical details of data strategies and
implementation largely opaque. In this work, we address VLM post-training from
a data-centric perspective, showing the key role of data strategy in developing
frontier VLMs. By studying and building our post-training data strategy from
scratch, we share detailed insights into the development processes, aiming to
benefit the development of competitive models for the open-source community.
Our introduced data strategy, together with training recipes and model design,
leads to a family of performant VLMs named Eagle2. Specifically, Eagle2-9B
achieves state-of-the-art results across various multimodal benchmarks,
matching certain competitive models with up to 70B parameters.",http://arxiv.org/abs/2501.14818v1
Efficient Lower Bounding of Single Transferable Vote Election Margins,2025-01-24T13:39:23Z,"Michelle Blom, Alexander Ek, Peter J. Stuckey, Vanessa Teague, Damjan Vukcevic","The single transferable vote (STV) is a system of preferential proportional
voting employed in multi-seat elections. Each ballot cast by a voter is a
(potentially partial) ranking over a set of candidates. The margin of victory,
or simply margin, is the smallest number of ballots that, if manipulated (e.g.,
their rankings changed, or ballots being deleted or added), can alter the set
of winners. Knowledge of the margin of an election gives greater insight into
both how much time and money should be spent on auditing the election, and
whether uncovered mistakes (such as ballot box losses) throw the election
result into doubt -- requiring a costly repeat election -- or can be safely
ignored. Lower bounds on the margin can also be used for this purpose, in cases
where exact margins are difficult to compute. There is one existing approach to
computing lower bounds on the margin of STV elections, while there are multiple
approaches to finding upper bounds. In this paper, we present improvements to
this existing lower bound computation method for STV margins. In many cases the
improvements compute tighter (higher) lower bounds as well as making the
computation of lower bounds more computationally efficient. For small
elections, in conjunction with existing upper bounding approaches, the new
algorithms are able to compute exact margins of victory.",http://arxiv.org/abs/2501.14847v1
"Modeling APOKASC-3 red giants: I. The first dredge-up and red giant
  branch bump",2025-01-24T19:00:01Z,"Kaili Cao, Marc H. Pinsonneault","We focus on two key diagnostics of stellar physics in red giant branch (RGB)
stars: the first dredge-up (FDU) of nuclear processed material and the location
of the red giant branch bump (RGBB). We compare asteroseismic and spectroscopic
APOKASC-3 data with theoretical MESA models. Our FDU predictions have similar
mass and metallicity trends to the data, but the observed magnitude of the
change in $[{\rm C}/{\rm N}]$ in data is smaller than theoretical predictions
by $0.1615 \pm 0.0760 \,({\rm obs}) \pm 0.0108 \,({\rm sys}) \,{\rm dex}$.
These results are insensitive to the input physics, but they are at a level
consistent with systematic uncertainties in the abundance measurements. When we
include observed trends in birth $[{\rm C}/{\rm Fe}]$ and $[{\rm N}/{\rm Fe}]$
in our models, it modestly stretches the metallicity dependent difference
relative to the data. We find a well-defined empirical RGBB locus: $\log g =
2.6604 - 0.1832 (M/{\rm M}_\odot-1) + 0.2824 \,[{\rm Fe}/{\rm H}]$. Our model
RGBB loci have mass and composition trends that mirror the data, but we find
that the observed RGBB is $0.1509 \pm 0.0017 \,({\rm obs}) \pm 0.0182 \,({\rm
sys})$ magnitudes higher than predicted across the board, similar to prior
literature results. We find that envelope overshooting, proposed solution to
reconcile theory with data, increases ${\rm Li}$ destruction during the FDU at
higher metallicities, creating tension with depletion observed in GALAH data.
We propose ${\rm Li}$ in the FDU as a sensitive test of the RGBB and FDU, and
discuss other potential solutions.",http://arxiv.org/abs/2501.14867v1
"Origin of performance enhancement of superconducting nanowire
  single-photon detectors by He-ion irradiation",2025-01-24T22:55:14Z,"Stefan Strohauer, Fabian Wietschorke, Markus Döblinger, Christian Schmid, Stefanie Grotowski, Lucio Zugliani, Björn Jonas, Kai Müller, Jonathan J. Finley","Superconducting nanowire single-photon detectors (SNSPDs) are indispensable
in fields such as quantum science and technology, astronomy, and biomedical
imaging, where high detection efficiency, low dark count rates and high timing
accuracy are required. Recently, helium (He) ion irradiation was shown to be a
promising method to enhance SNSPD performance. Here, we study how changes in
the underlying superconducting NbTiN film and the SiO2/Si substrate affect
device performance. While irradiated and unirradiated NbTiN films show similar
crystallinity, we observe He bubble formation below the SiO2/Si interface and
an amorphization of the Si substrate. Both reduce the thermal conductance
between the superconducting thin film and the substrate from 210 W/m^2/K^4 to
70 W/m^2/K^4 after irradiation with 2000 ions/nm^2. This effect, combined with
the lateral straggle of He ions in the substrate, allows the modification of
the superconductor-to-substrate thermal conductance of an SNSPD by selectively
irradiating the regions around the nanowire. With this approach, we achieved an
increased plateau width of saturating intrinsic detection efficiency of 9.8 uA
compared to 3.7 uA after full irradiation. Moreover, the critical current
remained similar to that of the unirradiated reference device (59 uA versus
60.1 uA), while full irradiation reduced it to 22.4 uA. Our results suggest
that the irradiation-induced reduction of the thermal conductance significantly
enhances SNSPD sensitivity, offering a novel approach to locally engineer
substrate properties for improved detector performance.",http://arxiv.org/abs/2501.14965v1
"Task Arithmetic in Trust Region: A Training-Free Model Merging Approach
  to Navigate Knowledge Conflicts",2025-01-25T04:09:56Z,"Wenju Sun, Qingyong Li, Wen Wang, Yangli-ao Geng, Boyang Li","Multi-task model merging offers an efficient solution for integrating
knowledge from multiple fine-tuned models, mitigating the significant
computational and storage demands associated with multi-task training. As a key
technique in this field, Task Arithmetic (TA) defines task vectors by
subtracting the pre-trained model ($\theta_{\text{pre}}$) from the fine-tuned
task models in parameter space, then adjusting the weight between these task
vectors and $\theta_{\text{pre}}$ to balance task-generalized and task-specific
knowledge. Despite the promising performance of TA, conflicts can arise among
the task vectors, particularly when different tasks require distinct model
adaptations. In this paper, we formally define this issue as knowledge
conflicts, characterized by the performance degradation of one task after
merging with a model fine-tuned for another task. Through in-depth analysis, we
show that these conflicts stem primarily from the components of task vectors
that align with the gradient of task-specific losses at $\theta_{\text{pre}}$.
To address this, we propose Task Arithmetic in Trust Region (TATR), which
defines the trust region as dimensions in the model parameter space that cause
only small changes (corresponding to the task vector components with gradient
orthogonal direction) in the task-specific losses. Restricting parameter
merging within this trust region, TATR can effectively alleviate knowledge
conflicts. Moreover, TATR serves as both an independent approach and a
plug-and-play module compatible with a wide range of TA-based methods.
Extensive empirical evaluations on eight distinct datasets robustly demonstrate
that TATR improves the multi-task performance of several TA-based model merging
methods by an observable margin.",http://arxiv.org/abs/2501.15065v1
"An Atomic Skill Library Construction Method for Data-Efficient Embodied
  Manipulation",2025-01-25T04:19:33Z,"Dongjiang Li, Bo Peng, Chang Li, Ning Qiao, Qi Zheng, Lei Sun, Yusen Qin, Bangguo Li, Yifeng Luan, Bo Wu, Yibing Zhan, Mingang Sun, Tong Xu, Lusong Li, Hui Shen, Xiaodong He","Embodied manipulation is a fundamental ability in the realm of embodied
artificial intelligence. Although current embodied manipulation models show
certain generalizations in specific settings, they struggle in new environments
and tasks due to the complexity and diversity of real-world scenarios. The
traditional end-to-end data collection and training manner leads to significant
data demands. Decomposing end-to-end tasks into atomic skills helps reduce data
requirements and improves the task success rate. However, existing methods are
limited by predefined skill sets that cannot be dynamically updated. To address
the issue, we introduce a three-wheeled data-driven method to build an atomic
skill library. We divide tasks into subtasks using the Vision-Language-Planning
(VLP). Then, atomic skill definitions are formed by abstracting the subtasks.
Finally, an atomic skill library is constructed via data collection and
Vision-Language-Action (VLA) fine-tuning. As the atomic skill library expands
dynamically with the three-wheel update strategy, the range of tasks it can
cover grows naturally. In this way, our method shifts focus from end-to-end
tasks to atomic skills, significantly reducing data costs while maintaining
high performance and enabling efficient adaptation to new tasks. Extensive
experiments in real-world settings demonstrate the effectiveness and efficiency
of our approach.",http://arxiv.org/abs/2501.15068v3
"Unifying Prediction and Explanation in Time-Series Transformers via
  Shapley-based Pretraining",2025-01-25T04:24:35Z,"Qisen Cheng, Jinming Xing, Chang Xue, Xiaoran Yang","In this paper, we propose ShapTST, a framework that enables time-series
transformers to efficiently generate Shapley-value-based explanations alongside
predictions in a single forward pass. Shapley values are widely used to
evaluate the contribution of different time-steps and features in a test
sample, and are commonly generated through repeatedly inferring on each sample
with different parts of information removed. Therefore, it requires expensive
inference-time computations that occur at every request for model explanations.
In contrast, our framework unifies the explanation and prediction in training
through a novel Shapley-based pre-training design, which eliminates the
undesirable test-time computation and replaces it with a single-time
pre-training. Moreover, this specialized pre-training benefits the prediction
performance by making the transformer model more effectively weigh different
features and time-steps in the time-series, particularly improving the
robustness against data noise that is common to raw time-series data. We
experimentally validated our approach on eight public datasets, where our
time-series model achieved competitive results in both classification and
regression tasks, while providing Shapley-based explanations similar to those
obtained with post-hoc computation. Our work offers an efficient and
explainable solution for time-series analysis tasks in the safety-critical
applications.",http://arxiv.org/abs/2501.15070v1
"Does the Tool Matter? Exploring Some Causes of Threats to Validity in
  Mining Software Repositories",2025-01-25T07:42:56Z,"Nicole Hoess, Carlos Paradis, Rick Kazman, Wolfgang Mauerer","Software repositories are an essential source of information for software
engineering research on topics such as project evolution and developer
collaboration. Appropriate mining tools and analysis pipelines are therefore an
indispensable precondition for many research activities. Ideally, valid results
should not depend on technical details of data collection and processing. It
is, however, widely acknowledged that mining pipelines are complex, with a
multitude of implementation decisions made by tool authors based on their
interests and assumptions. This raises the questions if (and to what extent)
tools agree on their results and are interchangeable. In this study, we use two
tools to extract and analyse ten large software projects, quantitatively and
qualitatively comparing results and derived data to better understand this
concern. We analyse discrepancies from a technical point of view, and adjust
code and parametrisation to minimise replication differences. Our results
indicate that despite similar trends, even simple metrics such as the numbers
of commits and developers may differ by up to 500%. We find that such
substantial differences are often caused by minor technical details. We show
how tool-level and data post-processing changes can overcome these issues, but
find they may require considerable efforts. We summarise identified causes in
our lessons learned to help researchers and practitioners avoid common
pitfalls, and reflect on implementation decisions and their influence in
ensuring obtained data meets explicit and implicit expectations. Our findings
lead us to hypothesise that similar uncertainties exist in other analysis
tools, which may limit the validity of conclusions drawn in tool-centric
research.",http://arxiv.org/abs/2501.15114v1
"Crystal Oscillators in OSNMA-Enabled Receivers: An Implementation View
  for Automotive Applications",2025-01-25T08:25:15Z,"Francesco Ardizzon, Nicola Laurenti, Carlo Sarto, Giovanni Gamba, Cillian O'Driscoll, Ignacio Fernandez-Hernandez","To ensure the authenticity of navigation data, Galileo Open Service
navigation message authentication (OSNMA) requires loose synchronization
between the receiver clock and the system time. This means that during the
period between clock calibrations, the receiver clock error needs to be smaller
than a pre-defined threshold, currently up to 165s for OSNMA. On the other
hand, relying on the PVT solution to steer the receiver clock or correct its
bias may not be possible since this would depend on the very same signals we
intend to authenticate. This work aims to investigate the causes of the
frequency accuracy loss leading to clock errors and to build a model that, from
the datasheet of a real-time clock (RTC) device, allows to bound the error
clock during a certain period. The model's main contributors are temperature
changes, long-term aging, and offset at calibration, but it includes other
factors. We then apply the model to several RTCs from different manufacturers
and bound the maximum error for certain periods, with a focus on the two-year
between-calibration period expected for the smart tachograph, an automotive
application that will integrate OSNMA.",http://arxiv.org/abs/2501.15123v3
"Holographic Einstein Ring of Quantum Corrected AdS-Reissner-Nordstrom
  Black Holes in Kiselev Spacetime",2025-01-25T08:52:12Z,"Jin-Yu Gui, Ke-Jian He, Xiao-Xiong Zeng","This study, grounded in AdS/CFT correspondence, utilizes wave optics theory
to explore the Einstein ring of a quantum-corrected AdS-Reissner-Nordstr\""om
black hole (BH) in Kiselev spacetime. By fixing the wave source on the AdS
boundary, the corresponding response function generated on the antipodal side
of the boundary is successfully obtained. Using a virtual optical system with a
convex lens, the holographic image of the Einstein ring of the BH is captured
on a screen. The study also investigates the impact of various physical
parameters and the observer's position on the characteristics of the Einstein
ring. The results indicate that changes in the observer's position cause the
image to transition from an axisymmetric ring to an arc, ultimately converging
to a single luminous point. Additionally, the Einstein ring radius decreases
with increasing values of the quantum correction parameter $a$, the equation of
state parameter $\Omega$, temperature $T$, and chemical potential $\mu$ ,
respectively. In contrast, the ring radius increases as the cosmological fluid
parameter $c$ increases. Furthermore, the ring radius becomes more distinct as
the wave source frequency $\omega$ increases. From the perspective of geometric
optics, the photon ring of the quantum-corrected AdS-Reissner-Nordstr\""om BH in
Kiselev spacetime is further studied. Numerical results suggest that the
incident angle of the photon ring aligns with that of the Einstein ring.",http://arxiv.org/abs/2501.15139v1
"Highly Variable Quasar Candidates Selected from 4XMM-DR13 with Machine
  Learning",2025-01-25T15:58:49Z,"Heng Wang, Yanli Ai, Yanxia Zhang, Yuming Fu, Wenfeng Wen, Liming Dou, Xue-Bing Wu, Xiangru Li, Zhiying Huo","We present a sample of 12 quasar candidates with highly variable soft X-ray
emission from the 4th XMM-newton Serendipitous Source Catalog (4XMM-DR13) using
random forest. We obtained optical to mid-IR photometric data for the 4XMM-DR13
sources by correlating the sample with the SDSS DR18 photometric database and
the AllWISE database. By cross-matching this sample with known spectral
catalogs from the SDSS and LAMOST surveys, we obtained a training data set
containing stars, galaxies, and quasars. The random forest algorithm was
trained to classify the XMM-WISE-SDSS sample. We further filtered the
classified quasar candidates with $\it{Gaia}$ proper motion to remove stellar
contaminants. Finally, 53,992 quasar candidates have been classified, with
10,210 known quasars matched in SIMBAD. The quasar candidates have
systematically lower X-ray fluxes than quasars in the training set, which
indicates the classifier is helpful to single out fainter quasars. We
constructed a sample of 12 sources from these quasars candidates which changed
their soft X-ray fluxes by a factor of 10 over $\sim$ 20 years in the
4XMM-newton survey. Our selected highly variable quasar candidates extend the
quasar sample, characterized by extreme soft X-ray variability, to the
optically faint end with magnitudes around $r \sim 22$. None of the 12 sources
were detected in ROSAT observations. Given the flux limit of ROSAT, the result
suggests that quasars exhibiting variations of more than two orders of
magnitudes are extremely rare.",http://arxiv.org/abs/2501.15254v1
Pyrochlore NaYbO2: A potential Quantum Spin Liquid Candidate,2025-01-25T23:33:59Z,"Chuanyan Fan, Tieyan Chang, Longlong Fan, Simon J. Teat, Feiyu Li, Xiaoran Feng, Chao Liu, Shi-lei Wang, Huifen Ren, Jiazheng Hao, Zhaohui Dong, Lunhua He, Shanpeng Wang, Chengwang Niu, Yu-Sheng Chen, Xutang Tao, Junjie Zhang","The search for quantum spin liquids (QSL) and chemical doping in such
materials to explore superconductivity have continuously attracted intense
interest. Here, we report the discovery of a potential QSL candidate,
pyrochlore-lattice beta-NaYbO2. Colorless and transparent NaYbO2 single
crystals, layered alpha-NaYbO2 (~250 um on edge) and octahedral beta-NaYbO2
(~50 um on edge), were grown for the first time. Synchrotron X-ray single
crystal diffraction unambiguously determined that the newfound beta-NaYbO2
belongs to the three-dimensional pyrochlore structure characterized by the R-3m
space group, corroborated by synchrotron X-ray and neutron powder diffraction
and pair distribution function. Magnetic measurements revealed no long-range
magnetic order or spin glass behavior down to 0.4 K with a low boundary spin
frustration factor of 17.5, suggesting a potential QSL ground state. Under high
magnetic fields, the potential QSL state was broken and spins order. Our
findings reveal that NaYbO2 is a fertile playground for studying novel quantum
states.",http://arxiv.org/abs/2501.15350v1
"Federated Class-Incremental Learning: A Hybrid Approach Using Latent
  Exemplars and Data-Free Techniques to Address Local and Global Forgetting",2025-01-26T01:08:01Z,"Milad Khademi Nori, Il-Min Kim, Guanghui Wang","Federated Class-Incremental Learning (FCIL) refers to a scenario where a
dynamically changing number of clients collaboratively learn an ever-increasing
number of incoming tasks. FCIL is known to suffer from local forgetting due to
class imbalance at each client and global forgetting due to class imbalance
across clients. We develop a mathematical framework for FCIL that formulates
local and global forgetting. Then, we propose an approach called Hybrid
Rehearsal (HR), which utilizes latent exemplars and data-free techniques to
address local and global forgetting, respectively. HR employs a customized
autoencoder designed for both data classification and the generation of
synthetic data. To determine the embeddings of new tasks for all clients in the
latent space of the encoder, the server uses the Lennard-Jones Potential
formulations. Meanwhile, at the clients, the decoder decodes the stored
low-dimensional latent space exemplars back to the high-dimensional input
space, used to address local forgetting. To overcome global forgetting, the
decoder generates synthetic data. Furthermore, our mathematical framework
proves that our proposed approach HR can, in principle, tackle the two local
and global forgetting challenges. In practice, extensive experiments
demonstrate that while preserving privacy, our proposed approach outperforms
the state-of-the-art baselines on multiple FCIL benchmarks with low compute and
memory footprints.",http://arxiv.org/abs/2501.15356v2
"Redistribution of ices between grain populations in protostellar
  envelopes. Only the coldest grains get ices",2025-01-26T17:30:50Z,Juris Kalvāns,"Context. Matter that falls onto a protoplanetary disk (PPD) from a
protostellar envelope is heated before it cools again. This induces sublimation
and subsequent re-adsorption of ices that accumulated during the prestellar
phase. Aims. We explore the fate of ices on multiple-sized dust grains in a
parcel of infalling matter. Methods. A comprehensive kinetic chemical model
using five grain-size bins with different temperatures was applied for an
infalling parcel. The parcel was heated to 150 K and then cooled over a total
timescale of 20 kyr. Effects on ice loss and re-accumulation by the changed gas
density, the maximum temperature, the irradiation intensity, the size-dependent
grain temperature trend, and the distribution of the ice mass among the
grain-size bins were investigated. Results. A massive selective redistribution
of ices exclusively onto the surface of the coldest grain-size bin occurs in
all models. The redistribution starts already during the heating stage, where
ices that are sublimated from warmer grains re-adsorb onto colder grains before
complete sublimation. During the cooling stage, the sublimated molecules
re-freeze again onto the coldest grains. In the case of full sublimation, this
re-adsorption is delayed and occurs at lower temperatures because a bare grain
surface has lower molecular desorption energies in our model. Conclusions. Most
protostellar envelope grains enter the PPD ice poor (bare). Ices are carried by
a single coldest grain-size bin, here representing 12 % of the total grain
surface area. This bare ice-grain dualism can affect the rate of the grain
coagulation. The ice components are stratified on the grains according to their
sublimation temperatures.",http://arxiv.org/abs/2501.15609v1
Mode transitions and spoke structures in ExB Penning discharge,2025-01-26T17:56:27Z,"M. Tyushev, M. Papahn Zadeh, N. S. Chopra, Y. Raitses, I. Romadanov, A. Likhanskii, G. Fubiani, L. Garrigues, R. Groenewald, A. Smolyakov","Two-dimensional particle-in-cell simulations in the (radial-azimuthal) plane
perpendicular to the axial direction of a cylindrical ExB Penning discharge are
presented. The low-pressure discharge is self-consistently supported by plasma
ionization from the electron beam injected axially, along the direction of the
external magnetic field. It is shown that with the increasing strength of the
external magnetic field, the discharge undergoes a sequence of transitions
between several azimuthal modes. Azimuthal m>1 spiral arm structures are
excited at low magnetic field values as plasma confinement improves and the
radial density profile becomes peaked. With a larger field, spiral arms with
m>1 are replaced by the m=1 spoke mode, most clearly seen in plasma density. A
transition from spiral arms to the spoke regime occurs when the plasma
potential in the center changes from weakly positive (or zero) to negative.
Further increase of the magnetic field results in a well-developed m=1 spoke
mode with additional small-scale higher frequency m>1 structures inside and
around the spoke. It is shown that while ionization and collisions affect some
characteristics of the observed fluctuations, the basic features of the spoke
and m>1 spiral structure remained similar without ionization. The role of
energy conservation in small-scale high-frequency modes and spoke dynamics is
discussed. It is demonstrated that in regimes with the m=1 spoke mode,
additional m=4 harmonics of the ion and electron fluxes to the wall appear due
to the square boundary. The frequency of the m=1 mode is weakly affected by the
geometry of the boundary.",http://arxiv.org/abs/2501.15620v1
Maximal WAP and tame quotients of type spaces,2025-01-26T18:34:51Z,"Krzysztof Krupiński, Adrián Portillo","We study maximal WAP and tame (in the sense of topological dynamics)
quotients of $S_X(\mathfrak{C})$, where $\mathfrak{C}$ is a sufficiently
saturated (called monster) model of a complete theory $T$, $X$ is a
$\emptyset$-type-definable set, and $S_X(\mathfrak{C})$ is the space of
complete types over $\mathfrak{C}$ concentrated on $X$. Namely, let
$F_{\textrm{WAP}}\subseteq S_X(\mathfrak{C})\times S_X(\mathfrak{C})$ be the
finest closed, $aut(\mathfrak{C})$-invariant equivalence relation on
$S_X(\mathfrak{C})$ such that the flow $( aut(\mathfrak{C}),
S_X(\mathfrak{C})/F_{\textrm{WAP}} )$ is WAP, and let
$F_{\textrm{Tame}}\subseteq S_X(\mathfrak{C})\times S_X(\mathfrak{C})$ be the
finest closed, $aut(\mathfrak{C})$-invariant equivalence relation on
$S_X(\mathfrak{C})$ such that the flow $( aut(\mathfrak{C}),
S_X(\mathfrak{C})/F_{\textrm{Tame}} )$ is tame. We show good behaviour of
$F_{\textrm{WAP}}$ and $F_{\textrm{Tame}}$ under changing the monster model
$\mathfrak{C}$. Namely, we prove that if $\mathfrak{C}'\succ \mathfrak{C}$ is a
bigger monster model, $F'_{\textrm{WAP}}$ and $F'_{\textrm{Tame}}$ are the
counterparts of $F_{\textrm{WAP}}$ and $F_{\textrm{Tame}}$ computed for
$\mathfrak{C}'$, and $r\colon S_X(\mathfrak{C}')\to S_X(\mathfrak{C})$ is the
restriction map, then $r[F'_{\textrm{WAP}}]=F_{\textrm{WAP}}$ and
$r[F'_{\textrm{Tame}}]=F_{\textrm{Tame}}$. Using these results, we show that
the Ellis (or ideal) groups of $( aut(\mathfrak{C}),
S_X(\mathfrak{C})/F_{\textrm{WAP}} )$ and $(aut(\mathfrak{C}),
S_X(\mathfrak{C})/F_{\textrm{Tame}})$ do not depend on the choice of the
monster model $\mathfrak{C}$.",http://arxiv.org/abs/2501.15632v1
"Exploring the Feasibility of Deep Learning Models for Long-term Disease
  Prediction: A Case Study for Wheat Yellow Rust in England",2025-01-26T21:22:54Z,"Zhipeng Yuan, Yu Zhang, Gaoshan Bi, Po Yang","Wheat yellow rust, caused by the fungus Puccinia striiformis, is a critical
disease affecting wheat crops across Britain, leading to significant yield
losses and economic consequences. Given the rapid environmental changes and the
evolving virulence of pathogens, there is a growing need for innovative
approaches to predict and manage such diseases over the long term. This study
explores the feasibility of using deep learning models to predict outbreaks of
wheat yellow rust in British fields, offering a proactive approach to disease
management. We construct a yellow rust dataset with historial weather
information and disease indicator acrossing multiple regions in England. We
employ two poweful deep learning models, including fully connected neural
networks and long short-term memory to develop predictive models capable of
recognizing patterns and predicting future disease outbreaks.The models are
trained and validated in a randomly sliced datasets. The performance of these
models with different predictive time steps are evaluated based on their
accuracy, precision, recall, and F1-score. Preliminary results indicate that
deep learning models can effectively capture the complex interactions between
multiple factors influencing disease dynamics, demonstrating a promising
capacity to forecast wheat yellow rust with considerable accuracy.
Specifically, the fully-connected neural network achieved 83.65% accuracy in a
disease prediction task with 6 month predictive time step setup. These findings
highlight the potential of deep learning to transform disease management
strategies, enabling earlier and more precise interventions. Our study provides
a methodological framework for employing deep learning in agricultural settings
but also opens avenues for future research to enhance the robustness and
applicability of predictive models in combating crop diseases globally.",http://arxiv.org/abs/2501.15677v1
"Automatic Feedback Generation for Short Answer Questions using Answer
  Diagnostic Graphs",2025-01-27T04:49:10Z,"Momoka Furuhashi, Hiroaki Funayama, Yuya Iwase, Yuichiroh Matsubayashi, Yoriko Isobe, Toru Nagahama, Saku Sugawara, Kentaro Inui","Short-reading comprehension questions help students understand text structure
but lack effective feedback. Students struggle to identify and correct errors,
while manual feedback creation is labor-intensive. This highlights the need for
automated feedback linking responses to a scoring rubric for deeper
comprehension.
  Despite advances in Natural Language Processing (NLP), research has focused
on automatic grading, with limited work on feedback generation. To address
this, we propose a system that generates feedback for student responses.
  Our contributions are twofold. First, we introduce the first system for
feedback on short-answer reading comprehension. These answers are derived from
the text, requiring structural understanding. We propose an ""answer diagnosis
graph,"" integrating the text's logical structure with feedback templates. Using
this graph and NLP techniques, we estimate students' comprehension and generate
targeted feedback.
  Second, we evaluate our feedback through an experiment with Japanese high
school students (n=39). They answered two 70-80 word questions and were divided
into two groups with minimal academic differences. One received a model answer,
the other system-generated feedback. Both re-answered the questions, and we
compared score changes. A questionnaire assessed perceptions and motivation.
  Results showed no significant score improvement between groups, but
system-generated feedback helped students identify errors and key points in the
text. It also significantly increased motivation. However, further refinement
is needed to enhance text structure understanding.",http://arxiv.org/abs/2501.15777v1
"The prototype double-faced white dwarf has a thin hydrogen layer across
  its entire surface",2025-01-27T13:05:59Z,"Antoine Bédard, Pier-Emmanuel Tremblay","Some white dwarfs undergo significant changes in atmospheric composition
owing to the diffusion and mixing of residual hydrogen in a helium-rich
envelope. Of particular interest are a few objects exhibiting hydrogen and
helium line variations modulated by rotation, revealing surface composition
inhomogeneities. Recently, the hot ultramassive white dwarf ZTF
J203349.80+322901.1 emerged as the most extreme such specimen, with hydrogen
and helium lines successively appearing and vanishing in anti-phase, suggesting
a peculiar double-faced configuration. However, standard atmosphere models fail
to reproduce the observed spectrum at all rotation phases, hampering further
interpretation. Here, we perform a new analysis of ZTF J203349.80+322901.1
using stratified atmosphere models, where hydrogen floats above helium, and
obtain excellent fits to the phase-resolved spectra. Our results imply that an
extremely thin hydrogen layer covers the entire surface but varies from
optically thick to optically thin across the surface, thus producing the
observed spectral variations. We present new envelope models indicating that
the hydrogen layer arises from a delicate interplay between diffusion and
convection. We discuss possible explanations for the surface layer asymmetry,
including an asymmetric magnetic field and a non-uniform internal hydrogen
distribution. Finally, we highlight implications for expanding and
understanding the emerging class of inhomogeneous white dwarfs.",http://arxiv.org/abs/2501.16021v1
"Circular dichroism in resonant inelastic x-ray scattering from
  birefringence in CuO",2025-01-27T13:29:02Z,"Abhishek Nag, Gérard Sylvester Perren, Hiroki Ueda, A. T. Boothroyd, D. Prabhakaran, M. García-Fernández, S. Agrestini, Ke-Jin Zhou, Urs Staub","Resonant inelastic x-ray scattering (RIXS) has become a prominent technique
to study quasiparticle excitations. With advances in polarization analysis
capabilities at different facilities, RIXS offers exceptional potential for
investigating symmetry-broken quasiparticles like chiral phonons and magnons.
At optical wavelengths birefringence can severely affect polarization states in
low-symmetry systems. Here we show its importance for soft x-ray resonances.
Given the growing interest in Circular Dichroism (CD) in RIXS, it is important
to evaluate how birefringence may affect the RIXS spectra of anisotropic
systems. We investigate CuO, a well-known anisotropic material, using Cu
$L_3$-edge RIXS and detect significant CD in both magnetic and orbital
excitations in the collinear antiferromagnetic phase. We demonstrate that the
CD can be modeled by a proper treatment of RIXS scattering amplitudes derived
from single-ion calculations with birefringence. Recognizing these effects is
crucial for unambiguous identification of subtle dichroic effects induced by
symmetry-broken quasiparticles. Furthermore, the combined sensitivity of RIXS
and birefringence to local symmetry presents an opportunity to study
microscopic changes driven by external perturbations.",http://arxiv.org/abs/2501.16034v1
"Disruption-aware Microservice Re-orchestration for Cost-efficient
  Multi-cloud Deployments",2025-01-27T15:36:51Z,"Marco Zambianco, Silvio Cretti, Domenico Siracusa","Multi-cloud environments enable a cost-efficient scaling of cloud-native
applications across geographically distributed virtual nodes with different
pricing models. In this context, the resource fragmentation caused by frequent
changes in the resource demands of deployed microservices, along with the
allocation or termination of new and existing microservices, increases the
deployment cost. Therefore, re-orchestrating deployed microservices on a
cheaper configuration of multi-cloud nodes offers a practical solution to
restore the cost efficiency of deployment. However, the rescheduling procedure
causes frequent service interruptions due to the continuous termination and
rebooting of the containerized microservices. Moreover, it may potentially
interfere with and delay other deployment operations, compromising the
stability of the running applications. To address this issue, we formulate a
multi-objective integer linear programming problem that computes a microservice
rescheduling solution capable of providing minimum deployment cost without
significantly affecting the service continuity. At the same time, the proposed
formulation also preserves the quality of service (QoS) requirements, including
latency, expressed through microservice colocation constraints. Additionally,
we present a heuristic algorithm to approximate the optimal solution, striking
a balance between cost reduction and service disruption mitigation. We
integrate the proposed approach as a custom plugin of the Kubernetes scheduler.
Results reveal that our approach significantly reduces multi-cloud deployment
costs and service disruptions compared to the default Kubernetes scheduler
implementation, while ensuring QoS requirements are consistently met.",http://arxiv.org/abs/2501.16143v1
Velocity-comb modulation transfer spectroscopy,2025-01-27T15:41:34Z,"Xiaolei Guan, Zheng Xiao, Zijie Liu, Zhiyang Wang, Jia Zhang, Xun Gao, Pengyuan Chang, Tiantian Shi, Jingbiao Chen","Sub-Doppler laser spectroscopy is a crucial technique for laser frequency
stabilization, playing a significant role in atomic physics, precision
measurement, and quantum communication. However, recent efforts to improve
frequency stability appear to have reached a bottleneck, as they primarily
focus on external technical approaches while neglecting the fundamental issue
of low atomic utilization (< 1%), caused by only near-zero transverse velocity
atoms involved in the transition. Here, we propose a velocity-comb modulation
transfer spectroscopy (MTS) solution that takes advantage of the
velocity-selective resonance effect of multi-frequency comb lasers to enhance
the utilization of non-zero-velocity atoms. In the probe-pump configuration,
each pair of counter-propagating lasers interacts with atoms from different
transverse velocity-comb groups, independently contributing to the spectral
amplitude and signal-to-noise ratio. Preliminary proof-of-principle results
show that the frequency stability of the triple-frequency laser is optimized by
nearly a factor of \sqrt{3} compared to the single-frequency laser, consistent
with theoretical expectations. With more frequency comb components,
MTS-stabilized lasers are expected to achieve order-of-magnitude breakthroughs
in frequency stability, taking an important step toward next-generation compact
optical clocks. This unique method can also be widely applied to any quantum
system with a wide velocity distribution, inspiring innovative advances in
numerous fields with a fresh perspective.",http://arxiv.org/abs/2501.16148v1
Parametrized homotopic distance,2025-01-27T15:45:59Z,"Navnath Daundkar, J. M. García-Calcines","We introduce the concept of parametrized homotopic distance, extending the
classical notion of homotopic distance to the fibrewise setting. We establish
its correspondence with the fibrewise sectional category of a specific
fibrewise fibration and derive cohomological lower bounds and connectivity
upper bounds under mild conditions. We also analyze the behavior of
parametrized homotopic distance under compositions and products of fibrewise
maps, along with its interaction with the triangle inequality.
  We establish several sufficient conditions for fibrewise $H$-spaces to admit
a fibrewise division map and prove that their parametrized topological
complexity equals their fibrewise unpointed Lusternik-Schnirelman category,
extending Lupton and Scherer's theorem to the fibrewise setting. Additionally,
we give sharp estimates for the parametrized topological complexity of a class
fibrewise $H$-spaces which arises as sphere bundles with fibre $S^7$.
Furthermore, we estimate the parametrized homotopic distance of
fibre-preserving, fibrewise maps between fibrewise fibrations, in terms of the
parametrized homotopic distance of the induced fibrewise maps between
individual fibres, as well as the fibrewise unpointed Lusternik-Schnirelman
category of the base space.
  Finally, we define and study a pointed version of parametrized homotopic
distance, establishing cohomological bounds and identifying key conditions for
its equivalence with the unpointed version, thus providing a finer
classification of fibrewise homotopy invariants.",http://arxiv.org/abs/2501.16152v2
"Raiders of the Lost Dependency: Fixing Dependency Conflicts in Python
  using LLMs",2025-01-27T16:45:34Z,"Antony Bartlett, Cynthia Liem, Annibale Panichella","Fixing Python dependency issues is a tedious and error-prone task for
developers, who must manually identify and resolve environment dependencies and
version constraints of third-party modules and Python interpreters. Researchers
have attempted to automate this process by relying on large knowledge graphs
and database lookup tables. However, these traditional approaches face
limitations due to the variety of dependency error types, large sets of
possible module versions, and conflicts among transitive dependencies. This
study explores the potential of using large language models (LLMs) to
automatically fix dependency issues in Python programs. We introduce PLLM
(pronounced ""plum""), a novel technique that employs retrieval-augmented
generation (RAG) to help an LLM infer Python versions and required modules for
a given Python file. PLLM builds a testing environment that iteratively (1)
prompts the LLM for module combinations, (2) tests the suggested changes, and
(3) provides feedback (error messages) to the LLM to refine the fix. This
feedback cycle leverages natural language processing (NLP) to intelligently
parse and interpret build error messages. We benchmark PLLM on the Gistable
HG2.9K dataset, a collection of challenging single-file Python gists. We
compare PLLM against two state-of-the-art automatic dependency inference
approaches, namely PyEGo and ReadPyE, w.r.t. the ability to resolve dependency
issues. Our results indicate that PLLM can fix more dependency issues than the
two baselines, with +218 (+15.97%) more fixes over ReadPyE and +281 (+21.58%)
over PyEGo. Our deeper analyses suggest that PLLM is particularly beneficial
for projects with many dependencies and for specific third-party numerical and
machine-learning modules. Our findings demonstrate the potential of LLM-based
approaches to iteratively resolve Python dependency issues.",http://arxiv.org/abs/2501.16191v1
"Synthesis, crystal structure, site occupancy and magnetic properties of
  aluminum substituted M-type Sr hexaferrite SrFe12-xAlxO19 nanoparticles",2025-01-27T18:00:51Z,"Matilde Saura-Múzquiz, Anna Zink Eikeland, Marian Stingaciu, Henrik Lyder Andersen, Maxim Avdeev, Mogens Christensen","The synthesis of aluminum substituted strontium hexaferrite nanoparticles
(SrFe12-xAlxO19 with x = 0-3), via three different preparation methods, is
investigated. The synthesis methods are hydrothermal autoclave (AC) synthesis,
a citrate sol-gel (SG) synthesis and a solid-salt matrix (SSM) sol-gel
synthesis. Evaluation of macroscopic magnetic properties and of lattice
parameters obtained by Rietveld analysis of powder X-ray diffraction (PXRD)
data indicate that successful substitution of Al into the crystal structure is
only achieved for the SG method. For the SG sample with x = 3, the coercivity
was found to increase by 73% to 830 kA/m, while the saturation magnetization
was reduced by 68% to 22.6 Am2/kg compared to the non-substituted x = 0 SG
sample. The SSM and AC samples did not show any significant changes in their
magnetic properties. To examine the nature of the Al insertion in detail,
neutron powder diffraction (NPD) data were collected on the SSM and SG samples.
Combined Rietveld refinements of the PXRD and NPD data confirm that effective
substitution of the Al ions is only achieved for the SG sample and reveal that
Al occupies mainly the (2a)Oh and (12k)Oh sites and to a lesser extent the
(4e)BP, (4f)Oh and (4f)Td sites. Moreover, the relative degree of site
occupation varies with increasing Al substitution. The intrinsic magnetization
according to the refined atomic magnetic moments and Al site occupation
fractions was extracted from the NPD data and compared with the measured
macroscopic magnetization. A remarkable agreement exists between the two,
confirming the robustness and accuracy of the Rietveld analysis.",http://arxiv.org/abs/2501.16264v1
"Diffusion of Water Molecules on the Surface of Silica Nanoparticles --
  Insights from Nuclear Magnetic Resonance Relaxometry",2025-01-27T18:23:11Z,"Aleksandra Stankiewicz, Adam Kasparek, Elzbieta Masiewicz, Danuta Kruk","$^{1}$H spin-lattice nuclear magnetic resonance (NMR) relaxation experiments
have been performed for water dispersions of functionalized silica
nanoparticles of diameters of 25 and 45 nm. The experiments have been performed
in a broad frequency range spanning 3 orders of magnitude, from 10 kHz to 10
MHz, versus temperature, from 313 to 263 K. On the basis of the data,
two-dimensional translation diffusion (diffusion close to the nanoparticle
surface within a layer of the order of a few diameters of water molecules) has
been revealed. The translational correlation times as well as the residence
life times on the nanoparticle surface have been determined. It has turned out
that the residence lifetime is temperature-independent and is on the order of 5
x 10$^{-6}$ s for the smaller nanoparticles and by about a factor of 3 longer
for the larger ones. The translational correlation time for the case of 25 nm
nanoparticles is also temperature-independent and yields about 6 x 10$^{-7}$ s,
while for the dispersion of the larger nanoparticles, the correlation times
changed from about 8 x 10$^{-7}$ s at 313 K to about 1.2 x 10$^{-6}$ s at 263
K. In addition to the quantitative characterization of the two-dimensional
translation diffusion, correlation times associated with bound water molecules
have been determined. The studies have also given insights into the population
of the bound and diffusing water on the surface water fractions.",http://arxiv.org/abs/2501.16286v1
"How Strategic Agents Respond: Comparing Analytical Models with
  LLM-Generated Responses in Strategic Classification",2025-01-20T01:39:03Z,"Tian Xie, Pavan Rauch, Xueru Zhang","When machine learning (ML) algorithms are used to automate human-related
decisions, human agents may gain knowledge of the decision policy and behave
strategically to obtain desirable outcomes. Strategic Classification (SC) has
been proposed to address the interplay between agents and decision-makers.
Prior work on SC has relied on assumptions that agents are perfectly or
approximately rational, responding to decision policies by maximizing their
utilities. Verifying these assumptions is challenging due to the difficulty of
collecting real-world agent responses. Meanwhile, the growing adoption of large
language models (LLMs) makes it increasingly likely that human agents in SC
settings will seek advice from these tools. We propose using strategic advice
generated by LLMs to simulate human agent responses in SC. Specifically, we
examine five critical SC scenarios -- hiring, loan applications, school
admissions, personal income, and public assistance programs -- and simulate how
human agents with diverse profiles seek advice from LLMs. We then compare the
resulting agent responses with the best responses generated by existing
theoretical models. Our findings reveal that: (i) LLMs and theoretical models
generally lead to agent score or qualification changes in the same direction
across most settings, with both achieving similar levels of fairness; (ii)
state-of-the-art commercial LLMs (e.g., GPT-3.5, GPT-4) consistently provide
helpful suggestions, though these suggestions typically do not result in
maximal score or qualification improvements; and (iii) LLMs tend to produce
more diverse agent responses, often favoring more balanced effort allocation
strategies. These results suggest that theoretical models align with LLMs to
some extent and that leveraging LLMs to simulate more realistic agent responses
offers a promising approach to designing trustworthy ML systems.",http://arxiv.org/abs/2501.16355v1
"Classification of Mild Cognitive Impairment Based on Dynamic Functional
  Connectivity Using Spatio-Temporal Transformer",2025-01-27T18:20:33Z,"Jing Zhang, Yanjun Lyu, Xiaowei Yu, Lu Zhang, Chao Cao, Tong Chen, Minheng Chen, Yan Zhuang, Tianming Liu, Dajiang Zhu","Dynamic functional connectivity (dFC) using resting-state functional magnetic
resonance imaging (rs-fMRI) is an advanced technique for capturing the dynamic
changes of neural activities, and can be very useful in the studies of brain
diseases such as Alzheimer's disease (AD). Yet, existing studies have not fully
leveraged the sequential information embedded within dFC that can potentially
provide valuable information when identifying brain conditions. In this paper,
we propose a novel framework that jointly learns the embedding of both spatial
and temporal information within dFC based on the transformer architecture.
Specifically, we first construct dFC networks from rs-fMRI data through a
sliding window strategy. Then, we simultaneously employ a temporal block and a
spatial block to capture higher-order representations of dynamic
spatio-temporal dependencies, via mapping them into an efficient fused feature
representation. To further enhance the robustness of these feature
representations by reducing the dependency on labeled data, we also introduce a
contrastive learning strategy to manipulate different brain states.
Experimental results on 345 subjects with 570 scans from the Alzheimer's
Disease Neuroimaging Initiative (ADNI) demonstrate the superiority of our
proposed method for MCI (Mild Cognitive Impairment, the prodromal stage of AD)
prediction, highlighting its potential for early identification of AD.",http://arxiv.org/abs/2501.16409v1
"Differential virial analysis: a new technique to determine the dynamical
  state of molecular clouds",2025-01-27T20:08:31Z,"Mark R. Krumholz, Charles J. Lada, Jan Forbrich","Since molecular clouds form stars, at least some parts of them must be in a
state of collapse. However, there is a long-standing debate as to whether that
collapse is local, involving only a small fraction of the cloud mass, or
global, with most mass in a state of collapse up to the moment when it is
dispersed by stellar feedback. In principle it is possible to distinguish these
possibilities from clouds' virial ratios, which should be a factor of two
larger for collapse than for equilibrium, but systematic uncertainties have
thus far prevented such measurements. Here we propose a new analysis method to
overcome this limitation: while the absolute value of a cloud's virial ratio is
too uncertain to distinguish global from local collapse, the differential
change in virial ratio as a function of surface density is also diagnostic of
clouds' dynamical state, and can be measured with far fewer systematic
uncertainties. We demonstrate the basic principles of the method using simple
analytic models of supported and collapsing clouds, validate it from full 3D
simulations, and discuss possible challenges in applying the method to real
data. We then provide a preliminary application of the technique to recent
observations of the molecular clouds in Andromeda, showing that most of them
are inconsistent with being in a state of global collapse.",http://arxiv.org/abs/2501.16474v1
"Exploring the defect landscape and dopability of chalcogenide perovskite
  BaZrS3",2025-01-27T23:12:03Z,"Rushik Desai, Shubhanshu Agarwal, Kiruba Catherine Vincent, Alejandro Strachan, Rakesh Agrawal, Arun Mannodi-Kanakkithodi","BaZrS3 is a chalcogenide perovskite that has shown great promise as a
photovoltaic absorber over the last few years. Despite its impressive
electronic and optical properties, native point defects and impurities could
impose significant limitations on the photovoltaic performance of BaZrS3. Such
defects may form spontaneously, create deep levels that act as traps for
carriers, and influence the device performance by changing the concentrations
of electrons and holes. On the other hand, functional dopants that dominate
over native defects can help tune the nature of conductivity in BaZrS3. In this
work, we applied first principles computations to comprehensively investigate
the defect landscape of BaZrS3, including all intrinsic defects and select
impurities and dopants. BaZrS3 intrinsically exhibits n-type equilibrium
conductivity under Zr-rich and Zr-poor conditions, as determined by low energy
vacancy and interstitial defects. O and H impurities create relatively low
energy neutral and donor-type defects. La and Nb are calculated to be stable
donor-type defects, which will make BaZrS3 even more n-type, whereas As and O
form amphoteric defects, which generally show higher formation energies than
native defects. This work highlights the difficulty of tuning the electrical
properties of BaZrS3 via doping, especially making it more p-type. However, it
points to some possible avenues to inform our future work.",http://arxiv.org/abs/2501.16561v2
"Central densities of dark matter halos in FIRE-2 simulations of low-mass
  galaxies with cold dark matter and self-interacting dark matter",2025-01-28T00:31:29Z,"Maria C. Straight, Michael Boylan-Kolchin, James S. Bullock, Philip F. Hopkins, Xuejian Shen, Lina Necib, Alexandres Lazar, Andrew S. Graus, Jenna Samuel","We investigate the central density structure of dark matter halos in cold
dark matter (CDM) and self-interacting dark matter (SIDM) models using
simulations that are part of the Feedback In Realistic Environments (FIRE)
project. For simulated halos of dwarf galaxy scale ($M_{\rm halo}(z=0)\approx
10^{10}\,M_\odot$), we study the central structure in both dissipationless
simulations and simulations with full FIRE-2 galaxy formation physics. As has
been demonstrated extensively in recent years, both baryonic feedback and
self-interactions can convert central cusps into cores, with the former process
doing so in a manner that depends sensitively on stellar mass at fixed $M_{\rm
halo}$. Whether the two processes (baryonic feedback and self-interactions) are
distinguishable, however, remains an open question. Here we demonstrate that,
compared to feedback-induced cores, SIDM-induced cores transition more quickly
from the central region of constant density to the falling density at larger
radial scales. This result holds true even when including identical galaxy
formation modeling in SIDM simulations as is used in CDM simulations, since
self-interactions dominate over galaxy formation physics in establishing the
central structure of SIDM halos in this mass regime. The change in density
profile slope as a function of radius therefore holds the potential to
discriminate between self-interactions and galaxy formation physics as the
driver of core formation in dwarf galaxies.",http://arxiv.org/abs/2501.16602v1
"Correlation between ferroelectricity and torsional motion of acetyl
  groups in tris(4-acetylphenyl)amine observed by muon spin relaxation",2025-01-28T03:41:52Z,"J. G. Nakamura, M. Hiraishi, H. Okabe, A. Koda, R. Kumai, F. L. Pratt, R. Kadono","It is demonstrated by muon spin relaxation and resonance experiments that the
switchable spontaneous polarization of the organic ferroelectric compound
tris(4-acetylphenyl)amine (TAPA) is governed by the local molecular dynamics of
the acetyl group. The implanted muon forms paramagnetic states which exhibit
longitudinal spin relaxation due to the fluctuation of hyperfine fields exerted
from unpaired electrons. The first-principle density functional theory
calculations indicate that these states are muonated radicals localized at the
phenyl group and on the carbon/oxygen of the acetyl group, thereby suggesting
that the spin relaxation is dominated by the random torsional motion of acetyl
group around the CC bond to the phenyl group. The stepwise change in the
relative yield of radicals at $T_0\approx 350$ K and the gradual increase in
the spin relaxation rate with temperature ($T$) indicate that the torsional
motion is significantly enhanced by thermal excitation above $T_0$. This occurs
concomitantly with the strong enhancement in the atomic displacement parameter
of oxygen in the acetyl group (which is non-linear in $T$), indicating that it
is the local molecular motion of the acetyl groups that drives the structural
transition.",http://arxiv.org/abs/2501.16685v1
"Lambda-Fleming-Viot processes arising in logistic
  Bienaymé-Galton-Watson processes with a large carrying capacity",2025-01-28T10:26:32Z,Raphaël Forien,"We consider a continuous-time Bienaym\'e-Galton-Watson process with logistic
competition in a regime of weak competition, or equivalently of a large
carrying capacity. Individuals reproduce at random times independently of each
other but die at a rate which increases with the population size. When
individuals reproduce, they produce a random number of offspring, drawn
according to some probability distribution on the natural integers. We keep
track of the number of descendants of the initial individuals by adding neutral
markers to the individuals, which are inherited by one's offspring. We then
consider several scaling limits of the measure-valued process describing the
distribution of neutral markers in the population, as well as the population
size, when the competition parameter tends to zero. Three regimes emerge,
depending on the tail of the offspring distribution. When the offspring
distribution admits a second moment (actually a $ 2+\delta $ moment for some
positive $ \delta $), the fluctuations of the population size around its
carrying capacity are small and the neutral types asymptotically follow a
Fleming-Viot process. When the offspring distribution has a power-law decay
with exponent $ \alpha \in (1,2) $, the population size remains most of the
time close to its carrying capacity with some (short-lived) fluctuations, and
the neutral types evolve in the limit according to a generalised $ \Lambda
$-Fleming-Viot process. When the exponent $ \alpha $ is equal to 1, the time
scale of the fluctuations changes drastically, as well as the order of
magnitude of the population size. In that case the limiting dynamics of the
neutral markers is given by the dual of the Bolthausen-Sznitman coalescent.",http://arxiv.org/abs/2501.16837v1
Optimization and Learning in Open Multi-Agent Systems,2025-01-28T10:40:09Z,"Diego Deplano, Nicola Bastianello, Mauro Franceschelli, Karl H. Johansson","Modern artificial intelligence relies on networks of agents that collect
data, process information, and exchange it with neighbors to collaboratively
solve optimization and learning problems. This article introduces a novel
distributed algorithm to address a broad class of these problems in ""open
networks"", where the number of participating agents may vary due to several
factors, such as autonomous decisions, heterogeneous resource availability, or
DoS attacks. Extending the current literature, the convergence analysis of the
proposed algorithm is based on the newly developed ""Theory of Open Operators"",
which characterizes an operator as open when the set of components to be
updated changes over time, yielding to time-varying operators acting on
sequences of points of different dimensions and compositions. The mathematical
tools and convergence results developed here provide a general framework for
evaluating distributed algorithms in open networks, allowing to characterize
their performance in terms of the punctual distance from the optimal solution,
in contrast with regret-based metrics that assess cumulative performance over a
finite-time horizon. As illustrative examples, the proposed algorithm is used
to solve dynamic consensus or tracking problems on different metrics of
interest, such as average, median, and min/max value, as well as classification
problems with logistic loss functions.",http://arxiv.org/abs/2501.16847v1
"Enhanced Thermoelectric Performance through Site-Specific Doping in
  Tetragonal Cu$_{2}$S: A First-Principles Study",2025-01-28T15:55:14Z,Sonam Phuntsho,"This work investigates how site-specific doping can enhance the
thermoelectric performance of tetragonal Cu$_{2}$S using Density functional
Theory and Projected Atomic Orbital Framework for Electronic Transport. We
address the gap in current research, where most doping studies focus on the
high-temperature cubic polymorph, leaving the tetragonal structure
underexplored. By substituting Cu with Li, Na, or Mg, as well as partially
replacing S with Se or Te, we systematically examine changes in electronic
structure and transport properties. Our results reveal that cation-site doping
can strongly shift the Fermi level. In particular, Li doping enhances the power
factor ($\sigma S^2$) by optimizing carrier concentrations and band-edge
alignments, whereas Mg, due to its divalent nature, offers a higher carrier
density but requires careful balancing to maintain a large Seebeck coefficient.
On the anion side, substituting heavier chalcogens (Se or Te) reshapes the
valence bands and subtly shifts the Fermi level, yielding moderate improvements
in both electrical conductivity and Seebeck coefficient. These doping-induced
alterations, captured through transport calculations, demonstrate a clear route
for tailoring the interplay between conductivity and thermal transport toward
potentially high figure-of-merit values. Overall, the findings highlight the
importance of site specificity in doping strategies for tetragonal Cu$_{2}$S,
showing that judicious choice of dopant elements and concentrations can
significantly improve key thermoelectric metrics. Such insights provide a
foundation for experimental validation and further development of
Cu$_{2}$S-based materials for mid- to high-temperature thermoelectric
applications.",http://arxiv.org/abs/2501.17034v1
"Phase-field modeling of radiation-induced composition redistribution: An
  application to additively manufactured austenitic Fe-Cr-Ni",2025-01-28T18:54:13Z,"Sourabh Bhagwan Kadambi, Daniel Schwen, Jia-Hong Ke, Lingfeng He, Andrea M. Jokisaari","Multicomponent alloys undergoing irradiation damage develop radiation-induced
composition redistribution at point defect sinks such as grain boundaries (GBs)
and dislocations. Such redistribution results in undesired changes to their
mechanical behavior and corrosion resistance. Additively manufactured alloys
proposed for future nuclear applications are expected to demonstrate a distinct
response to irradiation owing to their unique microstructure with as-solidified
dislocation density and chemical microsegregation. To capture the composition
redistribution in such systems, we develop a mesoscale model with coupled
evolution of atomic and point defect components in the presence of dislocation
density, dislocation heterogeneity, and thermodynamic interactions at the GB.
The model is parameterized for an FCC Fe-Cr-Ni alloy as a representative system
for austenitic stainless steels, and simulations are performed in 1D and 2D as
a function of irradiation temperature, dose, dislocation density, and grain
size. Radiation-induced segregation (RIS) characterized by Cr depletion and Ni
enrichment is predicted at both the GB and the dislocation cell wall, with RIS
being lower in magnitude but wider at the cell wall. Strongly biased absorption
of self-interstitials by dislocations is found to suppress Ni enrichment but
slightly enhance Cr depletion under certain conditions. Thermodynamic
segregation at the GB is predicted to be narrower and opposite in sign to RIS
for both Cr and Ni. Importantly, non-monotonic segregation is found to occur
when both thermodynamic and RIS mechanisms are considered, providing a novel
physical interpretation of experimental observations. The model is expected to
serve as a key tool in accelerated qualification of irradiated materials.",http://arxiv.org/abs/2501.17154v1
"Comparative Analysis of Stochastic and Predictable Models in the HIV
  Epidemic Across Genders",2025-01-28T19:40:14Z,"Nuzhat Nuari Khan Rivu, Md Kamrujjaman, Shohel Ahmed","This study conducts a comparative analysis of stochastic and deterministic
models to better understand the dynamics of the HIV epidemic across genders. By
incorporating gender-specific transmission probabilities and treatment uptake
rates, the research addresses gaps in existing models that often overlook these
critical factors. The introduction of gender-specific treatment, where only one
gender receives treatment, allows for a detailed examination of its effects on
both male and female populations. Two compartmental models, divided by gender,
are analyzed in parallel to identify the parameters that most significantly
impact the control of infected populations and the number of treated females.
Stochastic methods, including the Euler, Runge-Kutta, and Non-Standard Finite
Difference (SNSFD) approaches, demonstrate that stochastic models provide a
more accurate and realistic portrayal of HIV transmission and progression
compared to deterministic models. Key findings reveal that the stochastic
Runge-Kutta method is particularly effective in capturing the epidemic's
complex dynamics, such as subtle fluctuations in transmission and population
changes. The study also emphasizes the crucial role of transmission
probabilities and treatment rates in shaping the epidemic's trajectory,
highlighting their importance for optimizing public health interventions. The
research concludes that advanced stochastic modeling is essential for improving
public health policies and responses, especially in resource-constrained
settings.",http://arxiv.org/abs/2501.17259v1
"A Contrastive Teacher-Student Framework for Novelty Detection under
  Style Shifts",2025-01-28T20:42:50Z,"Hossein Mirzaei, Mojtaba Nafez, Moein Madadi, Arad Maleki, Mahdi Hajialilue, Zeinab Sadat Taghavi, Sepehr Rezaee, Ali Ansari, Bahar Dibaei Nia, Kian Shamsaie, Mohammadreza Salehi, Mackenzie W. Mathis, Mahdieh Soleymani Baghshah, Mohammad Sabokrou, Mohammad Hossein Rohban","There have been several efforts to improve Novelty Detection (ND)
performance. However, ND methods often suffer significant performance drops
under minor distribution shifts caused by changes in the environment, known as
style shifts. This challenge arises from the ND setup, where the absence of
out-of-distribution (OOD) samples during training causes the detector to be
biased toward the dominant style features in the in-distribution (ID) data. As
a result, the model mistakenly learns to correlate style with core features,
using this shortcut for detection. Robust ND is crucial for real-world
applications like autonomous driving and medical imaging, where test samples
may have different styles than the training data. Motivated by this, we propose
a robust ND method that crafts an auxiliary OOD set with style features similar
to the ID set but with different core features. Then, a task-based knowledge
distillation strategy is utilized to distinguish core features from style
features and help our model rely on core features for discriminating crafted
OOD and ID sets. We verified the effectiveness of our method through extensive
experimental evaluations on several datasets, including synthetic and
real-world benchmarks, against nine different ND methods.",http://arxiv.org/abs/2501.17289v1
"The M-factor: A Novel Metric for Evaluating Neural Architecture Search
  in Resource-Constrained Environments",2025-01-29T00:57:02Z,"Srikanth Thudumu, Hy Nguyen, Hung Du, Nhat Duong, Zafaryab Rasool, Rena Logothetis, Scott Barnett, Rajesh Vasa, Kon Mouzakis","Neural Architecture Search (NAS) aims to automate the design of deep neural
networks. However, existing NAS techniques often focus on maximising accuracy,
neglecting model efficiency. This limitation restricts their use in
resource-constrained environments like mobile devices and edge computing
systems. Moreover, current evaluation metrics prioritise performance over
efficiency, lacking a balanced approach for assessing architectures suitable
for constrained scenarios. To address these challenges, this paper introduces
the M-factor, a novel metric combining model accuracy and size. Four diverse
NAS techniques are compared: Policy-Based Reinforcement Learning, Regularised
Evolution, Tree-structured Parzen Estimator (TPE), and Multi-trial Random
Search. These techniques represent different NAS paradigms, providing a
comprehensive evaluation of the M-factor. The study analyses ResNet
configurations on the CIFAR-10 dataset, with a search space of 19,683
configurations. Experiments reveal that Policy-Based Reinforcement Learning and
Regularised Evolution achieved M-factor values of 0.84 and 0.82, respectively,
while Multi-trial Random Search attained 0.75, and TPE reached 0.67.
Policy-Based Reinforcement Learning exhibited performance changes after 39
trials, while Regularised Evolution optimised within 20 trials. The research
investigates the optimisation dynamics and trade-offs between accuracy and
model size for each strategy. Findings indicate that, in some cases, random
search performed comparably to more complex algorithms when assessed using the
M-factor. These results highlight how the M-factor addresses the limitations of
existing metrics by guiding NAS towards balanced architectures, offering
valuable insights for selecting strategies in scenarios requiring both
performance and efficiency.",http://arxiv.org/abs/2501.17361v1
"A Dual-Agent Adversarial Framework for Robust Generalization in Deep
  Reinforcement Learning",2025-01-29T02:36:47Z,"Zhengpeng Xie, Jiahang Cao, Yulong Zhang, Qiang Zhang, Renjing Xu","Recently, empowered with the powerful capabilities of neural networks,
reinforcement learning (RL) has successfully tackled numerous challenging
tasks. However, while these models demonstrate enhanced decision-making
abilities, they are increasingly prone to overfitting. For instance, a trained
RL model often fails to generalize to even minor variations of the same task,
such as a change in background color or other minor semantic differences. To
address this issue, we propose a dual-agent adversarial policy learning
framework, which allows agents to spontaneously learn the underlying semantics
without introducing any human prior knowledge. Specifically, our framework
involves a game process between two agents: each agent seeks to maximize the
impact of perturbing on the opponent's policy by producing representation
differences for the same state, while maintaining its own stability against
such perturbations. This interaction encourages agents to learn generalizable
policies, capable of handling irrelevant features from the high-dimensional
observations. Extensive experimental results on the Procgen benchmark
demonstrate that the adversarial process significantly improves the
generalization performance of both agents, while also being applied to various
RL algorithms, e.g., Proximal Policy Optimization (PPO). With the adversarial
framework, the RL agent outperforms the baseline methods by a significant
margin, especially in hard-level tasks, marking a significant step forward in
the generalization capabilities of deep reinforcement learning.",http://arxiv.org/abs/2501.17384v1
Time dispersion in bound states,2025-01-29T04:08:44Z,John Ashmead,"In quantum mechanics time is generally treated as a parameter rather than an
observable. For instance wave functions are treated as extending in space, but
not in time. But from relativity we expect time and space should be treated on
the same basis. What are the effects if time is an observable? Are these
effects observable with current technology?
  In earlier work we showed we should see effects in various high energy
scattering processes. We here extend that work to include bound states. The
critical advantage of working with bound states is that the predictions are
significantly more definite, taking the predictions from testable to
falsifiable.
  We estimate the time dispersion for hydrogen as $.177$ attoseconds, possibly
below the current threshold for detection. But the time dispersion should scale
as the $3/2$ power of the principle quantum number $n$. Rydberg atoms can have
$n$ of order $100$, implying a boost by a factor of $1000$. This takes the the
time dispersion to $177$ attoseconds, well within reach of current technology.
  There are a wide variety of experimental targets: any time-dependent
processes should show effects. Falsification will be technically challenging
(due to the short time scales) but immediate and unambiguous. Confirmation
would have significant implications for attosecond physics, quantum computing
and communications, quantum gravity, and the measurement problem. And would
suggest practical uses in these areas as well as circuit design, high speed
biochemistry, cryptography, fusion research, and any area involving change at
attosecond time scales.",http://arxiv.org/abs/2501.17407v1
"Spin-forbidden excitations in the magneto-optical spectra of CrI$_3$
  tuned by covalency",2025-01-29T05:06:41Z,"Connor A. Occhialini, Luca Nessi, Luiz G. P. Martins, Ahmet Kemal Demir, Qian Song, Vicky Hasse, Chandra Shekhar, Claudia Felser, Kenji Watanabe, Takashi Taniguchi, Valentina Bisogni, Jonathan Pelliciari, Riccardo Comin","Spin-forbidden ($\Delta S \neq 0$) multiplet excitations and their coupling
to magnetic properties are of increasing importance for magneto-optical studies
of correlated materials. Nonetheless, the mechanisms for optically brightening
these transitions and their generality remain poorly understood. Here, we
report magnetic circular dichroism (MCD) spectroscopy on the van der Waals
(vdW) ferromagnet (FM) CrI$_3$. Previously unreported spin-forbidden ($\Delta S
= 1$) ${}^4A_{2\mathrm{g}} \to{}^2E_\mathrm{g}/{}^2T_{1\mathrm{g}}$ Cr${}^{3+}$
$dd$ excitations are observed near the ligand-to-metal charge transfer (LMCT)
excitation threshold. The assignment of these excitations and their Cr$^{3+}$
multiplet character is established through complementary Cr $L_3$-edge resonant
inelastic X-ray scattering (RIXS) measurements along with charge transfer
multiplet (CTM) calculations and chemical trends in the chromium trihalide
series (CrX$_3$, X = Cl, Br, I). We utilize the high sensitivity of MCD
spectroscopy to study the thickness dependent optical response. The
spin-forbidden excitations remain robust down to the monolayer limit and
exhibit a significant magnetic field tunability across the antiferromagnetic to
FM transition in few-layer samples. This behavior is associated to changes in
the metal-ligand covalency with magnetic state, as supported by our CTM
analysis. Our results clarify the magneto-optical response of CrI$_3$ and
identify covalency as a central mechanism for the brightening and
field-tunability of spin-forbidden multiplet excitations.",http://arxiv.org/abs/2501.17417v1
"Equation-of-motion internally contracted multireference unitary
  coupled-cluster theory",2025-01-29T05:23:03Z,"Shuhang Li, Zijun Zhao, Francesco A. Evangelista","The accurate computation of excited states remains a challenge in electronic
structure theory, especially for systems with a ground state that requires a
multireference treatment. In this work, we introduce a novel equation-of-motion
(EOM) extension of the internally contracted multireference unitary
coupled-cluster framework (ic-MRUCC), termed EOM-ic-MRUCC. EOM-ic-MRUCC follows
the transform-then-diagonalize approach, in analogy to its non-unitary
counterpart [Datta and Nooijen, J. Chem. Phys. 137, 204107 (2012)]. By
employing a projective approach to optimize the ground state, the method
retains additive separability and proper scaling with system size. We show that
excitation energies are size intensive if the EOM operator satisfies the
""killer"" and the projective conditions. Furthermore, we propose to represent
changes in reference state upon electron excitation via projected many-body
operators that span active orbitals and show that the EOM equations formulated
in this way are invariant with respect to active orbital rotations. We test the
EOM-ic-MRUCC method truncated to single and double excitations by computing the
potential energy curves for several excited states of a BeH$_2$ model system,
the HF molecule, and water undergoing symmetric dissociation. Across these
systems, our method delivers accurate excitation energies and potential energy
curves within 5 m$E_\mathrm{h}$ (ca. 0.14 eV) from full configuration
interaction. We find that truncating the Baker-Campbell-Hausdorff series to
four-fold commutators contributes negligible errors (on the order of $10^{-5}$
$E_\mathrm{h}$ or less), offering a practical route to highly accurate
excited-state calculations with reduced computational overhead.",http://arxiv.org/abs/2501.17421v2
"The quantromon: A qubit-resonator system with orthogonal qubit and
  readout modes",2025-01-29T06:41:29Z,"Kishor V. Salunkhe, Suman Kundu, Srijita Das, Jay Deshmukh, Meghan P. Patankar, R. Vijay","The measurement of a superconducting qubit is implemented by coupling it to a
resonator. The common choice is transverse coupling, which, in the dispersive
approximation, introduces an interaction term which enables the measurement.
This cross-Kerr term provides a qubit-state dependent dispersive shift in the
resonator frequency with the device parameters chosen carefully to get
sufficient signal while minimizing Purcell decay of the qubit. We introduce a
two-mode circuit, nicknamed quantromon, with two orthogonal modes implementing
a qubit and a resonator. Unlike before, where the coupling term emerges as a
perturbative expansion, the quantromon has intrinsic cross-Kerr coupling by
design. Our experiments implemented in a hybrid 2D-3D cQED architecture
demonstrate some unique features of the quantromon like weak dependence of the
dispersive shift on the qubit-resonator detuning and intrinsic Purcell
protection. In a tunable qubit-frequency device, we show that the dispersive
shift ($2\chi/2\pi$) changes by only $0.8$ MHz while the qubit-resonator
detuning ($\Delta/2\pi$) is varied between $0.398$ GHz - $3.288$ GHz. We also
demonstrate Purcell protection in a second device where we tune the
orthogonality between the two modes. Finally, we demonstrate a single-shot
readout fidelity of $98.3\%$ without using a parametric amplifier which is
comparable to the state-of-the-art and suggests a potential simplification of
the measurement circuitry for scaling up quantum processors.",http://arxiv.org/abs/2501.17439v1
"EMD-Fuzzy: An Empirical Mode Decomposition Based Fuzzy Model for
  Cross-Stimulus Transfer Learning of SSVEP",2025-01-29T08:37:44Z,"Beining Cao, Xiaowei Jiang, Daniel Leong, Charlie Li-Ting Tsai, Yu-Cheng Chang, Thomas Do, Chin-Teng","The Brain-Computer Interface (BCI) enables direct brain-to-device
communication, with the Steady-State Visual Evoked Potential (SSVEP) paradigm
favored for its stability and high accuracy across various fields. In SSVEP BCI
systems, supervised learning models significantly enhance performance over
unsupervised models, achieving higher accuracy in less time. However, prolonged
data collection can cause user fatigue and even trigger photosensitive
epilepsy, creating a negative user experience. Thus, reducing calibration time
is crucial. To address this, Cross-Stimulus transfer learning (CSTL) can
shorten calibration by utilizing only partial frequencies. Traditional CSTL
methods, affected by time-domain impulse response variations, are suitable only
for adjacent frequency transfers, limiting their general applicability. We
introduce an Empirical Mode Decomposition (EMD) Based Fuzzy Model (EMD-Fuzzy),
which employs EMD to extract crucial frequency information and achieves
stimulus transfer in the frequency domain through Fast Fourier Transform (FFT)
to mitigate time-domain differences. Combined with a Fuzzy Decoder that uses
fuzzy logic for representation learning, our approach delivers promising
preliminary results in offline tests and state-of-the-art performance. With
only 4 frequencies, our method achieved an accuracy of 82.75% (16.30%) and an
information transfer rate (ITR) of 186.56 (52.09) bits/min on the 40-target
Benchmark dataset. In online tests, our method demonstrates robust efficacy,
achieving an averaged accuracy of 86.30% (6.18%) across 7 subjects. This
performance underscores the effectiveness of integrating EMD and fuzzy logic
into EEG decoding for CSTL and highlights our method's potential in real-time
applications where consistent and reliable decoding is crucial.",http://arxiv.org/abs/2501.17475v1
LLM Assistance for Pediatric Depression,2025-01-29T09:27:27Z,"Mariia Ignashina, Paulina Bondaronek, Dan Santel, John Pestian, Julia Ive","Traditional depression screening methods, such as the PHQ-9, are particularly
challenging for children in pediatric primary care due to practical
limitations. AI has the potential to help, but the scarcity of annotated
datasets in mental health, combined with the computational costs of training,
highlights the need for efficient, zero-shot approaches. In this work, we
investigate the feasibility of state-of-the-art LLMs for depressive symptom
extraction in pediatric settings (ages 6-24). This approach aims to complement
traditional screening and minimize diagnostic errors.
  Our findings show that all LLMs are 60% more efficient than word match, with
Flan leading in precision (average F1: 0.65, precision: 0.78), excelling in the
extraction of more rare symptoms like ""sleep problems"" (F1: 0.92) and
""self-loathing"" (F1: 0.8). Phi strikes a balance between precision (0.44) and
recall (0.60), performing well in categories like ""Feeling depressed"" (0.69)
and ""Weight change"" (0.78). Llama 3, with the highest recall (0.90),
overgeneralizes symptoms, making it less suitable for this type of analysis.
Challenges include the complexity of clinical notes and overgeneralization from
PHQ-9 scores. The main challenges faced by LLMs include navigating the complex
structure of clinical notes with content from different times in the patient
trajectory, as well as misinterpreting elevated PHQ-9 scores.
  We finally demonstrate the utility of symptom annotations provided by Flan as
features in an ML algorithm, which differentiates depression cases from
controls with high precision of 0.78, showing a major performance boost
compared to a baseline that does not use these features.",http://arxiv.org/abs/2501.17510v1
"Cell Deformation Signatures along the Apical-Basal Axis: A 3D Continuum
  Mechanics Shell Model",2025-01-29T17:59:48Z,"Jairo M. Rojas, Mayisha Z. Nakib, Vivian W. Tang, William M. Brieher, Sascha Hilgenfeldt","Two-dimensional (2D) mechanical models of confluent tissues have related the
mechanical state of a monolayer of cells to the average perimeter length of the
cell cross sections, predicting floppiness or rigidity of the material. For the
well-studied system of in-vitro MDCK epithelial cells, however, we find
experimentally that cells in mechanically rigid tissues display long perimeters
characteristic of a floppy state in 2D models. We suggest that this discrepancy
is due to mechanical effects in the third (apical-basal) dimension, including
those caused by actin stress fibers near the basal membrane. To quantitatively
understand cell deformations in 3D, we develop a continuum mechanics model of
epithelial cells as elastic cylindrical shells, with appropriate boundary
conditions reflecting both the passive confinement of neighboring cells and the
active stress of actomyosin contractility. This formalism yields analytical
solutions predicting cell cross sections along the entire cylinder axis.
Deconvolution microscopy experimental data confirm the significant and
systematic change in cell shape parameters in this apical-basal direction. In
addition to providing a wealth of detailed information on deformation on the
subcellular scale, the results of the approach alter our understanding of how
active tissues balance requirements of their stiffness and integrity,
suggesting they are more robust against loss of rigidity than previously
inferred.",http://arxiv.org/abs/2501.17810v1
"Assessment of the January 2025 Los Angeles County wildfires: A
  multi-modal analysis of impact, response, and population exposure",2025-01-20T13:50:16Z,Seyd Teymoor Seydi,"This study presents a comprehensive analysis of four significant California
wildfires: Palisades, Eaton, Kenneth, and Hurst, examining their impacts
through multiple dimensions, including land cover change, jurisdictional
management, structural damage, and demographic vulnerability. Using the
Chebyshev-Kolmogorov-Arnold network model applied to Sentinel-2 imagery, the
extent of burned areas was mapped, ranging from 315.36 to 10,960.98 hectares.
Our analysis revealed that shrubland ecosystems were consistently the most
affected, comprising 57.4-75.8% of burned areas across all events. The
jurisdictional assessment demonstrated varying management complexities, from
singular authority (98.7% in the Palisades Fire) to distributed management
across multiple agencies. A structural impact analysis revealed significant
disparities between urban interface fires (Eaton: 9,869 structures; Palisades:
8,436 structures) and rural events (Kenneth: 24 structures; Hurst: 17
structures). The demographic analysis showed consistent gender distributions,
with 50.9% of the population identified as female and 49.1% as male.
Working-age populations made up the majority of the affected populations,
ranging from 53.7% to 54.1%, with notable temporal shifts in post-fire periods.
The study identified strong correlations between urban interface proximity,
structural damage, and population exposure. The Palisades and Eaton fires
affected over 20,000 people each, compared to fewer than 500 in rural events.
These findings offer valuable insights for the development of targeted wildfire
management strategies, particularly in wildland urban interface zones, and
emphasize the need for age- and gender-conscious approaches in emergency
response planning.",http://arxiv.org/abs/2501.17880v1
"ProcTex: Consistent and Interactive Text-to-texture Synthesis for
  Procedural Models",2025-01-28T22:38:55Z,"Ruiqi Xu, Zihan Zhu, Xianghao Xu, Srinath Sridhar, Daniel Ritchie","Recent advancement in 2D image diffusion models has driven significant
progress in text-guided texture synthesis, enabling realistic, high-quality
texture generation from arbitrary text prompts. However, current methods
usually focus on synthesizing texture for single static 3D objects, and
struggle to handle entire families of shapes, such as those produced by
procedural programs. Applying existing methods naively to each procedural shape
is too slow to support exploring different parameter settings at interactive
rates, and also results in inconsistent textures across the procedural shapes.
To this end, we introduce ProcTex, the first text-to-texture system designed
for procedural 3D models. ProcTex enables consistent and real-time text-guided
texture synthesis for families of shapes, which integrates seamlessly with the
interactive design flow of procedural models. To ensure consistency, our core
approach is to generate texture for the shape produced by one setting of the
procedural parameters, followed by a texture transfer stage to apply the
texture to other parameter settings. We also develop several techniques,
including a novel UV displacement network for real-time texture transfer, the
retexturing pipeline to support structural changes from discrete procedural
parameters, and part-level UV texture map generation for local appearance
editing. Extensive experiments on a diverse set of professional procedural
models validate ProcTex's ability to produce high-quality, visually consistent
textures while supporting real-time, interactive applications.",http://arxiv.org/abs/2501.17895v1
"Pressure Field Reconstruction with SIREN: A Mesh-Free Approach for Image
  Velocimetry in Complex Noisy Environments",2025-01-29T20:49:59Z,"Renato F. Miotto, William R. Wolf, Fernando Zigunov","This work presents a novel approach for pressure field reconstruction from
image velocimetry data using SIREN (Sinusoidal Representation Network),
emphasizing its effectiveness as an implicit neural representation in noisy
environments and its mesh-free nature. While we briefly assess two recently
proposed methods - one-shot matrix-omnidirectional integration (OS-MODI) and
Green's function integral (GFI) - the primary focus is on the advantages of the
SIREN approach. The OS-MODI technique performs well in noise-free conditions
and with structured meshes but struggles when applied to unstructured meshes
with high aspect ratio. Similarly, the GFI method encounters difficulties due
to singularities inherent from the Newtonian kernel. In contrast, the proposed
SIREN approach is a mesh-free method that directly reconstructs the pressure
field, bypassing the need for an intrinsic grid connectivity and, hence,
avoiding the challenges associated with ill-conditioned cells and unstructured
meshes. This provides a distinct advantage over traditional mesh-based methods.
Moreover, it is shown that changes in the architecture of the SIREN can be used
to filter out inherent noise from velocimetry data. This work positions SIREN
as a robust and versatile solution for pressure reconstruction, particularly in
noisy environments characterized by the absence of mesh structure, opening new
avenues for innovative applications in this field.",http://arxiv.org/abs/2501.17987v1
Simulating Curved Lipid Membranes Using Anchored Frozen Patches,2025-01-29T20:52:49Z,"James Tallman, Antonia Statt","Lipid bilayers often form high-curvature configurations due to self-assembly
conditions or certain biological processes. However, particle-based simulations
of lipid membranes are predominantly of flat lipid membranes because planar
membranes are easily connected over periodic boundary conditions. To simulate a
curved lipid membrane, one can simulate an entire vesicle, a cylinder, or a
bicelle (disk-like bilayer aggregate). One can also use artificial methods to
control curvature, such as applying virtual walls of beads, radial harmonic
potentials, or ``tape up the edges''. These existing methods have limitations
due to the method by which curvature is imposed. Herein, we propose an
alternative method of introducing arbitrary curvature by anchoring a curved
lipid membrane with ``frozen'' equilibrated membrane patches. The method
presented here is compatible with all particle-based lipid models and easily
extended to many geometries. As an example, we simulate curved membranes with
DPPC, DOPC, DLPC and DOPE lipids as parameterized by the Martini3
coarse-grained model. This method introduces limited finite-size artifacts,
prevents lipid flip-flop at membrane edges, and allows fluctuations of the free
membrane center. We provide verification of the method on flat membranes and
discussion on extracting shape and per-leaflet quantities (thickness, order
parameter) from curved membranes. Curvature produces asymmetric changes in
lipid leaflet properties. Finally, we explore the coupled effect of curvature
and membrane asymmetry in both number and lipid type. We report the resulting
unique morphologies (inducing gel phase, faceting) and behaviors (thickness
dependent on adjacent leaflet type) that are accessible with this method.",http://arxiv.org/abs/2501.17989v1
"On the removal of the barotropic condition in helicity studies of the
  compressible Euler and ideal compressible MHD equations",2025-01-29T20:55:32Z,"Daniel W. Boutros, John D. Gibbon","The helicity is a topological conserved quantity of the Euler equations which
imposes significant constraints on the dynamics of vortex lines. In the
compressible setting the conservation law only holds under the assumption that
the pressure is barotropic. We show that by introducing a new definition of
helicity density $h_{\rho}=(\rho\textbf{u})\cdot\mbox{curl}\,(\rho\textbf{u})$
this assumption on the pressure can be removed, although $\int_V h_{\rho}dV$ is
no longer conserved. However, we show for the non-barotropic compressible Euler
equations that the new helicity density $h_{\rho}$ obeys an entropy-type
relation (in the sense of hyperbolic conservation laws) whose flux
$\textbf{J}_{\rho}$ contains all the pressure terms and whose source involves
the potential vorticity $q = \omega \cdot \nabla \rho$. Therefore the rate of
change of $\int_V h_{\rho}dV$ no longer depends on the pressure and is easier
to analyse, as it only depends on the potential vorticity and kinetic energy as
well as $\mbox{div}\,\textbf{u}$. This result also carries over to the
inhomogeneous incompressible Euler equations for which the potential vorticity
$q$ is a material constant. Therefore $q$ is bounded by its initial value
$q_{0}=q(\textbf{x},\,0)$, which enables us to define an inverse resolution
length scale $\lambda_{H}^{-1}$ whose upper bound is found to be proportional
to $\|q_{0}\|_{\infty}^{2/7}$. In a similar manner, we also introduce a new
cross-helicity density for the ideal non-barotropic magnetohydrodynamic (MHD)
equations.",http://arxiv.org/abs/2501.17990v1
"RL-based Query Rewriting with Distilled LLM for online E-Commerce
  Systems",2025-01-29T23:41:12Z,"Duy A. Nguyen, Rishi Kesav Mohan, Van Yang, Pritom Saha Akash, Kevin Chen-Chuan Chang","Query rewriting (QR) is a critical technique in e-commerce search, addressing
the lexical gap between user queries and product descriptions to enhance search
performance. Existing QR approaches typically fall into two categories:
discriminative models and generative methods leveraging large language models
(LLMs). Discriminative models often struggle with natural language
understanding and offer limited flexibility in rewriting, while generative
LLMs, despite producing high-quality rewrites, face high inference latency and
cost in online settings. These limitations force offline deployment, making
them vulnerable to issues like information staleness and semantic drift. To
overcome these challenges, we propose a novel hybrid pipeline for QR that
balances efficiency and effectiveness. Our approach combines offline knowledge
distillation to create a lightweight but efficient student model with online
reinforcement learning (RL) to refine query rewriting dynamically using
real-time feedback. A key innovation is the use of LLMs as simulated human
feedback, enabling scalable reward signals and cost-effective evaluation
without manual annotations. Experimental results on Amazon ESCI dataset
demonstrate significant improvements in query relevance, diversity, and
adaptability, as well as positive feedback from the LLM simulation. This work
contributes to advancing LLM capabilities for domain-specific applications,
offering a robust solution for dynamic and complex e-commerce search
environments.",http://arxiv.org/abs/2501.18056v1
Dynamic Model Fine-Tuning For Extreme MIMO CSI Compression,2025-01-30T10:31:34Z,"Mehdi Sattari, Deniz Gündüz, Tommy Svensson","Efficient channel state information (CSI) compression is crucial in frequency
division duplexing (FDD) massive multiple-input multiple-output (MIMO) systems
due to excessive feedback overhead. Recently, deep learning-based compression
techniques have demonstrated superior performance across various data types,
including CSI. However, these approaches often experience performance
degradation when the data distribution changes due to their limited
generalization capabilities. To address this challenge, we propose a model
fine-tuning approach for CSI feedback in massive MIMO systems. The idea is to
fine-tune the encoder/decoder network models in a dynamic fashion using the
recent CSI samples. First, we explore encoder-only fine-tuning, where only the
encoder parameters are updated, leaving the decoder and latent parameters
unchanged. Next, we consider full-model fine-tuning, where the encoder and
decoder models are jointly updated. Unlike encoder-only fine-tuning, full-model
fine-tuning requires the updated decoder and latent parameters to be
transmitted to the decoder side. To efficiently handle this, we propose
different prior distributions for model updates, such as uniform and truncated
Gaussian to entropy code them together with the compressed CSI and account for
additional feedback overhead imposed by conveying the model updates. Moreover,
we incorporate quantized model updates during fine-tuning to reflect the impact
of quantization in the deployment phase. Our results demonstrate that
full-model fine-tuning significantly enhances the rate-distortion (RD)
performance of neural CSI compression. Furthermore, we analyze how often the
full-model fine-tuning should be applied in a new wireless environment and
identify an optimal period interval for achieving the best RD trade-off.",http://arxiv.org/abs/2501.18250v1
"Collecting Cost-Effective, High-Quality Truthfulness Assessments with
  LLM Summarized Evidence",2025-01-30T11:04:14Z,"Kevin Roitero, Dustin Wright, Michael Soprano, Isabelle Augenstein, Stefano Mizzaro","With the degradation of guardrails against mis- and disinformation online, it
is more critical than ever to be able to effectively combat it. In this paper,
we explore the efficiency and effectiveness of using crowd-sourced truthfulness
assessments based on condensed, large language model (LLM) generated summaries
of online sources. We compare the use of generated summaries to the use of
original web pages in an A/B testing setting, where we employ a large and
diverse pool of crowd-workers to perform the truthfulness assessment. We
evaluate the quality of assessments, the efficiency with which assessments are
performed, and the behavior and engagement of participants. Our results
demonstrate that the Summary modality, which relies on summarized evidence,
offers no significant change in assessment accuracy over the Standard modality,
while significantly increasing the speed with which assessments are performed.
Workers using summarized evidence produce a significantly higher number of
assessments in the same time frame, reducing the cost needed to acquire
truthfulness assessments. Additionally, the Summary modality maximizes both the
inter-annotator agreements as well as the reliance on and perceived usefulness
of evidence, demonstrating the utility of summarized evidence without
sacrificing the quality of assessments.",http://arxiv.org/abs/2501.18265v1
Cosmological quantum mechanics on FLRW spacetimes,2025-01-30T12:11:32Z,"Edwin Beggs, Shahn Majid","We study general relativistic quantum mechanics in the case of an FLRW
cosmological background. For positive spatial curvature we find a discrete
series of solutions of the Klein-Gordon equation that can reasonably be called
gravitationally bound `cosmological atom' states. For all cases of curvature,
these modes, as well as more conventional atomic spatial modes bound by an
external potential, extend to solutions of the Klein-Gordon equations viewed as
stationary modes of Klein-Gordon quantum mechanics where wavefunctions are over
spacetime and evolution is with respect to an external `geodesic time'
parameter $s$. For general nonstationary states with fixed spatial eigenvector,
the theory reduces to a novel 1-dimensional quantum system on the time $t$ axis
with potential $1/a(t)^2$, where $a(t)$ is the Friedmann expansion factor. Its
behaviour, and hence the evolution of spatial states, changes critically when
the Hubble constant exceeds $2/3$ of the particle mass, as typically occurs
during inflation. We also find washout of the evolution of spatial observables
at late times and a backward-traveling reflected mode generated when the value
of $H$ transitions to a larger value.",http://arxiv.org/abs/2501.18295v3
"Nebular spectra of kilonovae with detailed recombination rates -- I.
  Light r-process composition",2025-01-30T13:48:48Z,"Smaranika Banerjee, Anders Jerkstrand, Nigel Badnell, Quentin Pognan, Niamh Ferguson, Jon Grumor","To investigate spectra of kilonovae in the NLTE phase (t >=1week), we perform
atomic calculations for dielectronic (DR) and radiative (RR) recombination
rates for the light r-process elements: Se (Z = 34), Rb (Z = 37), Sr (Z = 38),
Y (Z = 39), and Zr (Z = 40) using the HULLAC code. For the different elements,
our results for the total rate coefficients for recombining from the ionization
states of II to I, III to II, and IV to III vary between 10^{-13}-10^{-9}
cm^3/s, 10^{-12}-10^{-10} cm^3/s, and 10^{-13}-10^{-10} cm^3/s, respectively,
at a temperature of T = 10,000 K. We also provide fits to the ground state
photoionization cross sections of the various ions, finding larger and more
slowly declining values with energy in comparison to the hydrogenic
approximation. Using this new atomic data, we study the impact on kilonova
model spectra at phases of t = 10 days and t = 25 days using the spectral
synthesis code SUMO. Compared to models using the previous treatment of
recombination as a constant rate, the new models show significant changes in
ionization and temperature, and correspondingly, in emergent spectra. With the
new rates, we find that Zr (Z = 40) plays a yet more dominant role in kilonova
spectra for light r-process compositions. Further, we show that previously
predicted mid-infrared (e.g. [Se III] 4.55 \mum) and optical (e.g. [Rb I] 7802,
7949 A) lines disappear in the new model. Instead a strong [Se I] line is seen
to be emerging at \lambda=5.03 \mum. These results demonstrate the importance
of considering the detailed microphysics for modelling and interpreting the
late-time kilonova spectra.",http://arxiv.org/abs/2501.18345v1
"An extensive thermal conductivity measurement method based on atomic
  force microscopy",2025-01-30T14:33:02Z,"T. Serkan Kasırga, Berke Köker","Heat transport in low-dimensional solids can significantly differ from their
bulk counterpart due to various size-related effects. This offers rich heat
transport phenomena to emerge. However, finding an appropriate thermometry
method for thermal conductivity measurements at the reduced size and
dimensionality of the samples is a challenge. Here, we propose and study the
feasibility of a nanoscale resolution thermal conductivity measurement method
based on bolometric thermometry implemented on an atomic force microscopy
(AFM). The local heat exchange between the AFM tip and the sample occurs at a
suspended section of the sample, and thermal modeling of the measured
electrical resistance change resulting from the bolometric effect provides a
unique value for thermal conductivity. As we illustrate via thermal
simulations, the proposed method can measure thermal conductivity with thermal
disturbance to the sample in as little as 0.2 K at ~20 nm lateral resolution.
Our in-depth analysis shows the feasibility and extensive applicability of the
proposed AFM-based bolometric thermometry method on low-dimensional materials
both in diffusive and ballistic heat transport regimes from cryogenic to
above-room temperature. Consequently, the proposed method can lead to a deeper
experimental understanding of fundamental questions in nanoscale and
low-dimensional heat transport phenomena in many different material classes, as
well as Fourier and non-Fourier heat transfer regimes.",http://arxiv.org/abs/2501.18384v1
Synthesis of Universal Safety Controllers,2025-01-30T15:58:26Z,"Bernd Finkbeiner, Niklas Metzger, Satya Prakash Nayak, Anne-Kathrin Schmuck","The goal of logical controller synthesis is to automatically compute a
control strategy that regulates the discrete, event-driven behavior of a given
plant s.t. a temporal logic specification holds over all remaining traces.
Standard approaches to this problem construct a two-player game by composing a
given complete plant model and the logical specification and applying standard
algorithmic techniques to extract a control strategy. However, due to the often
enormous state space of a complete plant model, this process can become
computationally infeasible. In this paper, we introduce a novel synthesis
approach that constructs a universal controller derived solely from the game
obtained by the standard translation of the logical specification. The
universal controller's moves are annotated with prophecies - predictions about
the plant's behavior that ensure the move is safe. By evaluating these
prophecies, the universal controller can be adapted to any plant over which the
synthesis problem is realizable. This approach offers several key benefits,
including enhanced scalability with respect to the plant's size, adaptability
to changes in the plant, and improved explainability of the resulting control
strategy. We also present encouraging experimental results obtained with our
prototype tool, UNICON.",http://arxiv.org/abs/2501.18445v1
Resampling Filter Design for Multirate Neural Audio Effect Processing,2025-01-30T16:44:49Z,"Alistair Carson, Vesa Välimäki, Alec Wright, Stefan Bilbao","Neural networks have become ubiquitous in audio effects modelling, especially
for guitar amplifiers and distortion pedals. One limitation of such models is
that the sample rate of the training data is implicitly encoded in the model
weights and therefore not readily adjustable at inference. Recent work explored
modifications to recurrent neural network architecture to approximate a sample
rate independent system, enabling audio processing at a rate that differs from
the original training rate. This method works well for integer oversampling and
can reduce aliasing caused by nonlinear activation functions. For small
fractional changes in sample rate, fractional delay filters can be used to
approximate sample rate independence, but in some cases this method fails
entirely. Here, we explore the use of signal resampling at the input and output
of the neural network as an alternative solution. We investigate several
resampling filter designs and show that a two-stage design consisting of a
half-band IIR filter cascaded with a Kaiser window FIR filter can give similar
or better results to the previously proposed model adjustment method with many
fewer operations per sample and less than one millisecond of latency at typical
audio rates. Furthermore, we investigate interpolation and decimation filters
for the task of integer oversampling and show that cascaded half-band IIR and
FIR designs can be used in conjunction with the model adjustment method to
reduce aliasing in a range of distortion effect models.",http://arxiv.org/abs/2501.18470v1
"Active particles in moving traps: minimum work protocols and information
  efficiency of work extraction",2025-01-24T15:57:51Z,"Janik Schüttler, Rosalba Garcia-Millan, Michael E. Cates, Sarah A. M. Loos","We revisit the fundamental problem of moving a particle in a harmonic trap in
finite time with minimal work cost, and extend it to the case of an active
particle. By comparing the Gaussian case of an Active Ornstein-Uhlenbeck
particle and the non-Gaussian run-and-tumble particle, we establish general
principles for thermodynamically optimal control of active matter beyond
specific models. We show that the open-loop optimal protocols, which do not
incorporate system-state information, are identical to those of passive
particles but result in larger work fluctuations due to activity. In contrast,
closed-loop (or feedback) control with a single (initial) measurement changes
the optimal protocol and reduces the average work relative to the open-loop
control for small enough measurement errors. Minimum work is achieved by
particles with finite persistence time. As an application, we propose an active
information engine which extracts work from self-propulsion. This periodic
engine achieves higher information efficiency with run-and-tumble particles
than with active Ornstein-Uhlenbeck particles. Complementing a companion paper
that gives only the main results [arXiv:2407.18542], here we provide a full
account of our theoretical calculations and simulation results. We include
derivations of optimal protocols, work variance, impact of measurement
uncertainty, and information-acquisition costs.",http://arxiv.org/abs/2501.18613v1
"Drag Your Gaussian: Effective Drag-Based Editing with Score Distillation
  for 3D Gaussian Splatting",2025-01-30T18:51:54Z,"Yansong Qu, Dian Chen, Xinyang Li, Xiaofan Li, Shengchuan Zhang, Liujuan Cao, Rongrong Ji","Recent advancements in 3D scene editing have been propelled by the rapid
development of generative models. Existing methods typically utilize generative
models to perform text-guided editing on 3D representations, such as 3D
Gaussian Splatting (3DGS). However, these methods are often limited to texture
modifications and fail when addressing geometric changes, such as editing a
character's head to turn around. Moreover, such methods lack accurate control
over the spatial position of editing results, as language struggles to
precisely describe the extent of edits. To overcome these limitations, we
introduce DYG, an effective 3D drag-based editing method for 3D Gaussian
Splatting. It enables users to conveniently specify the desired editing region
and the desired dragging direction through the input of 3D masks and pairs of
control points, thereby enabling precise control over the extent of editing.
DYG integrates the strengths of the implicit triplane representation to
establish the geometric scaffold of the editing results, effectively overcoming
suboptimal editing outcomes caused by the sparsity of 3DGS in the desired
editing regions. Additionally, we incorporate a drag-based Latent Diffusion
Model into our method through the proposed Drag-SDS loss function, enabling
flexible, multi-view consistent, and fine-grained editing. Extensive
experiments demonstrate that DYG conducts effective drag-based editing guided
by control point prompts, surpassing other baselines in terms of editing effect
and quality, both qualitatively and quantitatively. Visit our project page at
https://quyans.github.io/Drag-Your-Gaussian.",http://arxiv.org/abs/2501.18672v2
"Mass flows in the Galactic Center by supernovae of the circumnuclear
  disk",2025-01-30T19:01:16Z,"Barnabas Barna, Richard Wünsch, Jan Palous, Mark R. Morris, Sona Ehlerová, Pierre Vermot","Context. The circumnuclear disk (CND) is presently the main supply of mass
for the accretion onto the supermassive black hole (SMBH) in the Galactic
Center (GC). While the accretion is relatively slow, it has been suspected that
local episodic explosive events play an important role in the temporary mass
inflow toward the SMBH, while also affecting the evolution of the CND. Aims.
The aim of this study is to follow the changes in mass flows caused by
supernova (SN) explosions nestled in or near the CND. Methods. We perform
simulations with the grid-based MHD code FLASH of the inner 5 pc of the Milky
Way GC, including gravitational potential, rotation, magnetic field, central
wind source, and the warm gas of the CND, all mimicking the observed physical
properties. Results. Assuming a M$_\mathrm{SN}=10$ M$_\odot$ as the mass of the
precursor of the core-collapse SN event at various locations within 2 pc from
the GC, we detect a temporary increase in the accretion rate, transferring an
additional 2-60 M$_\odot$ of warm gas to the immediate vicinity of the SMBH,
depending on the explosion site. At the same time, the kinetic energy of the SN
blows away even mass from the CND; the additional warm gas leaving the
simulation domain after the explosion is on the order of $\sim100$ M$_\odot$.
In the studied cases, the impact on mass flows and the turbulence caused by the
explosion cease after $\sim250$ kyr.",http://arxiv.org/abs/2501.18701v1
"A Deep Spatio-Temporal Architecture for Dynamic Effective Connectivity
  Network Analysis Based on Dynamic Causal Discovery",2025-01-31T02:39:35Z,"Faming Xu, Yiding Wang, Chen Qiao, Gang Qu, Vince D. Calhoun, Julia M. Stephen, Tony W. Wilson, Yu-Ping Wang","Dynamic effective connectivity networks (dECNs) reveal the changing directed
brain activity and the dynamic causal influences among brain regions, which
facilitate the identification of individual differences and enhance the
understanding of human brain. Although the existing causal discovery methods
have shown promising results in effective connectivity network analysis, they
often overlook the dynamics of causality, in addition to the incorporation of
spatio-temporal information in brain activity data. To address these issues, we
propose a deep spatio-temporal fusion architecture, which employs a dynamic
causal deep encoder to incorporate spatio-temporal information into dynamic
causality modeling, and a dynamic causal deep decoder to verify the discovered
causality. The effectiveness of the proposed method is first illustrated with
simulated data. Then, experimental results from Philadelphia Neurodevelopmental
Cohort (PNC) demonstrate the superiority of the proposed method in inferring
dECNs, which reveal the dynamic evolution of directed flow between brain
regions. The analysis shows the difference of dECNs between young adults and
children. Specifically, the directed brain functional networks transit from
fluctuating undifferentiated systems to more stable specialized networks as one
grows. This observation provides further evidence on the modularization and
adaptation of brain networks during development, leading to higher cognitive
abilities observed in young adults.",http://arxiv.org/abs/2501.18859v1
"Coupling Dichroism in Strong-Coupled Chiral Molecule-Plasmon
  Nanoparticle System",2025-01-31T08:26:21Z,"Nan Gao, Haoran Liu, Yurui Fang","The interaction between intense light-matter not only promotes emerging
applications in quantum and nonlinear optics but also facilitates changes in
material properties. Plasmons can significantly enhance not only molecular
chirality but also the coupling strength. In this study, we investigate the
coupling dichroism in a strongly coupled chiral molecule-plasmonic nanoparticle
system using RT-TDDFT. By simulating the interaction between L/D-
Phenylglycinol molecules and chiral aluminum clusters (Na-doped Al197Na4), we
examine the effects of molecular chirality, cluster chirality, and the coupled
effect in the system. Our results demonstrate that the achiral/chiral clusters
induce significant spectral shifts and enhance molecular CD signals due to
strong plasmon-molecule coupling. The electric-field distribution and
transition contribution maps (TCMs) reveal the formation of bonding and
antibonding polaritonic modes, modulated by molecular proximity to the cluster.
Both of the coupling factor and decay rate of the coupled system will be
modulated by the chirality of the molecules and the cluster. Furthermore, we
find that increasing the number of coupled molecules leads to a substantial
increase in the intensity of lower polaritonic modes, highlighting the
collective behavior in multi-molecule systems due to the modal crosstalk or
resonance between cluster chirality and molecular chirality. These findings
provide valuable insights into the fundamental mechanisms governing
plasmon-enhanced chirality at the atomic scale, which have implications for the
design of highly sensitive chiral sensors and optoelectronic devices.",http://arxiv.org/abs/2501.18952v1
Plane-Symmetric Capillary Turbulence: Five-Wave Interactions,2025-01-31T09:04:05Z,"E. A. Kochurin, P. A. Russkikh","The theory of isotropic capillary turbulence was developed in the late 1960s
by Zakharov and Filonenko. To date, the analytical solution of the kinetic
equation describing the stationary transfer of energy to small scales due to
three-wave resonant interactions, called the Zakharov-Filonenko spectrum, has
been confirmed with high accuracy. However, in the case of strong anisotropy in
wave propagation, where all waves are collinear, the situation changes
significantly. In such a degenerate geometry, the conditions of resonant
interaction cease to be fulfilled not only for three waves, but also for four
interacting waves. In this work, we perform fully nonlinear simulations of
plane-symmetric capillary turbulence. We demonstrate that the system of
interacting waves evolves into a quasi-stationary state with a direct energy
cascade, despite the absence of low-order resonances. The calculated spectra of
surface elevations are accurately described by analytical estimates derived
dimensionally under the assumption of the dominant influence of five-wave
resonant interactions. A detailed study of the statistical characteristics of
the weakly turbulent state does not reveal the influence of any coherent or
strongly nonlinear structures. The performed high-order correlation analysis
indicates a variety of non-trivial five-wave resonances. We show that the
process of wave decay into two pairs of counter-propagating waves is
responsible for the local energy transfer to small scales. Overall, the
calculation results are in good agreement with both the weak turbulence theory
and recent experiments made by Ricard and Falco",http://arxiv.org/abs/2501.18970v1
"In-operando test of tunable Heusler alloys for thermomagnetic harvesting
  of low-grade waste heat",2025-01-31T14:16:41Z,"F. Cugini, L. Gallo, G. Garulli, D. Olivieri, G. Trevisi, S. Fabbrici, F. Albertini, M. Solzi","Thermomagnetic generation stands out as a promising technology for harvesting
and converting low-grade waste heat below 100 {\deg}C. Despite the exponential
growth in research on thermomagnetic materials and prototypes over the last
decade, there remains, to unlock the full potential of this technology, a
critical gap between fundamental research on materials and the design of
advanced devices. In this study, we present the in-operando assessment of
thermomagnetic performance of three representative Ni,Mn-based Heusler alloys
optimized for harvesting low-grade waste heat below 373 K. These materials were
tested under operational conditions using a specially designed laboratory-scale
prototype of a thermomagnetic motor. The mechanical power output of the motor,
operated with NiMnIn, NiMnSn and NiMnCuGa alloys, was correlated with the
magnetic properties of the materials, highlighting the critical role of the
magnetic transition temperature and saturation magnetization in determining the
efficiency of thermomagnetic energy conversion. Austenitic Heusler alloys were
confirmed to be promising thermomagnetic materials due to their highly tunable
Curie temperature and significant magnetization changes in the 300-360 K
temperature range. Among the tested materials, the Ni48Mn36In16 alloy
demonstrated the highest thermomagnetic performance, surpassing the benchmark
material Gd in the 320-340 K range. From an experimental perspective, the
developed prototype of thermomagnetic motor serves as a flexible test-bench for
evaluating and comparing the thermomagnetic performance of small amounts (less
than 0.3 g) of new materials under variable conditions. Additionally, its
modular design facilitates testing and optimization of its various components,
thereby contributing to the advancement of thermomagnetic motor technology.",http://arxiv.org/abs/2501.19156v1
Learning While Repositioning in On-Demand Vehicle Sharing Networks,2025-01-31T15:16:02Z,"Hansheng Jiang, Chunlin Sun, Zuo-Jun Max Shen, Shunan Jiang","We consider a network inventory problem motivated by one-way, on-demand
vehicle sharing services. Due to uncertainties in both demand and returns, as
well as a fixed number of rental units across an $n$-location network, the
service provider must periodically reposition vehicles to match supply with
demand spatially while minimizing costs. The optimal repositioning policy under
a general $n$-location network is intractable without knowing the optimal value
function. We introduce the best base-stock repositioning policy as a
generalization of the classical inventory control policy to $n$ dimensions, and
establish its asymptotic optimality in two distinct limiting regimes under
general network structures. We present reformulations to efficiently compute
this best base-stock policy in an offline setting with pre-collected data.
  In the online setting, we show that a natural Lipschitz-bandit approach
achieves a regret guarantee of $\widetilde{O}(T^{\frac{n}{n+1}})$, which
suffers from the exponential dependence on $n$. We illustrate the challenges of
learning with censored data in networked systems through a regret lower bound
analysis and by demonstrating the suboptimality of alternative algorithmic
approaches. Motivated by these challenges, we propose an Online Gradient
Repositioning algorithm that relies solely on censored demand. Under a mild
cost-structure assumption, we prove that it attains an optimal regret of
$O(n^{2.5} \sqrt{T})$, which matches the regret lower bound in $T$ and achieves
only polynomial dependence on $n$. The key algorithmic innovation involves
proposing surrogate costs to disentangle intertemporal dependencies and
leveraging dual solutions to find the gradient of policy change. Numerical
experiments demonstrate the effectiveness of our proposed methods.",http://arxiv.org/abs/2501.19208v1
"Development and Evolution of Xtext-based DSLs on GitHub: An Empirical
  Investigation",2025-01-31T15:28:38Z,"Weixing Zhang, Daniel Strüber, Regina Hebig","Domain-specific languages (DSLs) play a crucial role in facilitating a wide
range of software development activities in the context of model-driven
engineering (MDE). However, a systematic understanding of their evolution is
lacking, which hinders methodology and tool development. To address this gap,
we performed a comprehensive investigation into the development and evolution
of textual DSLs created with Xtext, a particularly widely used language
workbench in the MDE. We systematically identified and analyzed 1002 GitHub
repositories containing Xtext-related projects. A manual classification of the
repositories brought forward 226 ones that contain a fully developed language.
These were further categorized into 18 application domains, where we examined
DSL artifacts and the availability of example instances. We explored DSL
development practices, including development scenarios, evolution activities,
and co-evolution of related artifacts. We observed that DSLs are used more,
evolve faster, and are maintained longer in specific domains, such as Data
Management and Databases. We identified DSL grammar definitions in 722
repositories, but only a third provided textual instances, with most utilizing
over 60% of grammar rules. We found that most analyzed DSLs followed a
grammar-driven approach, though some adopted a metamodel-driven approach.
Additionally, we observed a trend of retrofitting existing languages in Xtext,
demonstrating its flexibility beyond new DSL creation. We found that in most
DSL development projects, updates to grammar definitions and example instances
are very frequent, and most of the evolution activities can be classified as
``perfective'' changes. To support the research in the model-driven engineering
community, we contribute a dataset of repositories with meta-information,
helping to develop improved tools for DSL evolution.",http://arxiv.org/abs/2501.19222v1
Reactive path ensembles within nonequilibrium steady-states,2025-01-31T15:47:28Z,"Aditya N. Singh, David T. Limmer","The modern theory of rare events is grounded in near equilibrium ideas,
however many systems of modern interest are sufficiently far from equilibrium
that traditional approaches do not apply. Using the recently developed
variational path sampling methodology, we study systems evolving within
nonequilibrium steady states to elucidate how reactive processes are altered
away from equilibrium. Variational path sampling provides access to ensembles
of reactive events, and a means of quantifying the relative importance of each
dynamical degree of freedom in such processes. With it, we have studied the
conformational change of a solute in an active bath. We illustrate how energy
injection generically enhances the rates of rare events, even when energy is
not directed into specific reactive modes. By studying the folding and
unfolding transitions of a grafted polymer under shear, we illustrate how
nonequilibrium reactive processes do not follow gradient paths due to the
emergence of persistent currents. The breaking of detailed balance allows for
the mechanisms of forward and backward reactions to be distinct, enabling novel
pathways to be explored and designed, and states unstable in equilibrium to
become stabilized kinetically away from it. The analysis presented in this work
establishes some basic principles for nonequilibrium reactive events, and is
made possible by the use of a numerical method that does not invoke proximity
to equilibrium or requires strong prior assumptions about the mechanism of
reaction.",http://arxiv.org/abs/2501.19233v2
"Correlations drive the attosecond response of strongly-correlated
  insulators",2025-01-31T15:52:16Z,"Romain Cazali, Amina Alic, Matthieu Guer, Christopher J. Kaplan, Fabien Lepetit, Olivier Tcherbakoff, Stéphane Guizard, Angel Rubio, Nicolas Tancogne-Dejean, Gheorghe S. Chiuzbăian, Romain Géneaux","Attosecond spectroscopy of materials has provided invaluable insight into
light-driven coherent electron dynamics. However, attosecond spectroscopies
have so far been focused on weakly-correlated materials. As a result, the
behavior of strongly-correlated systems is largely unknown at sub- to
few-femtosecond timescales, even though it is typically the realm at which
electron-electron interactions operate. Here we conduct attosecond-resolved
experiments on the correlated insulator nickel oxide, and compare its response
to a common band insulator, revealing fundamentally different behaviors. The
results, together with state-of-the art time-dependent $\textit{ab initio}$
calculations, show that the correlated system response is governed by a
laser-driven quench of electron correlations. The evolution of the on-site
electronic interaction is measured here at its natural timescale, marking the
first direct measurement of Hubbard $U$ renormalization in NiO. It is found to
take place within a few femtoseconds, after which structural changes slowly
start to take place. The resulting picture sheds light on the entire
light-induced response of a strongly-correlated system, from attosecond to
long-lived effects.",http://arxiv.org/abs/2501.19238v1
"The order of the chiral phase transition in massless many-flavour
  lattice QCD",2025-01-31T16:09:18Z,"Jan Philipp Klinger, Reinhold Kaiser, Owe Philipsen","The nature of the QCD phase transition in the chiral limit presents a
challenging problem for lattice QCD. However, its study provides constraints on
the phase diagram at the physical point. In this work, we investigate how the
order of the chiral phase transition depends on the number of light quark
flavours. To approach the lattice chiral limit, we map out and extrapolate the
chiral critical surface that separates the first-order region from the
crossover region in an extended parameter space, which includes the gauge
coupling, the number of quark flavours, their masses, and the lattice spacing.
Lattice simulations with standard staggered quarks reveal that for each $N_f <
8$, there exists a tricritical lattice spacing $a^\text{tric}(N_f)$, at which
the chiral transition changes from first order ($a>a^\text{tric}$) to second
order ($a<a^\text{tric}$). Thus, the first-order region is merely a lattice
artifact and not connected to the continuum. By determining the associated
temperatures $T(N_f^\text{tric},a ^\text{tric})$ at these tricritical points,
we confirm the expected decrease in the critical temperature as the number of
flavours increases. The obtained temperatures define a tricritical line which
is connected to the continuum and terminates at a physical $
N_f^\text{tric}(a=0) $. Our data is compatible with a vanishing temperature at
that point, $T(N_f^\text{tric}(a=0))=0 $.",http://arxiv.org/abs/2501.19251v1
"Strong geometry dependence of the X-ray Thomson Scattering Spectrum in
  single crystal silicon",2025-01-31T16:42:03Z,"Thomas Gawne, Zhandos A. Moldabekov, Oliver S. Humphries, Karen Appel, Carsten Baehtz, Victorien Bouffetier, Erik Brambrink, Attila Cangi, Celine Crépisson, Sebastian Göde, Zuzana Konôpková, Mikako Makita, Mikhail Mishchenko, Motoaki Nakatsutsumi, Lisa Randolph, Sebastian Schwalbe, Jan Vorberger, Ulf Zastrau, Tobias Dornheim, Thomas R. Preston","We report on results from an experiment at the European XFEL where we
measured the x-ray Thomson scattering (XRTS) spectrum of single crystal silicon
with ultrahigh resolution. Compared to similar previous experiments, we
consider a more complex scattering setup, in which the scattering vector
changes orientation through the crystal lattice. In doing so, we are able to
observe strong geometric dependencies in the inelastic scattering spectrum of
silicon at low scattering angles. Furthermore, the high quality of the
experimental data allows us to benchmark state-of-the-art TDDFT calculations,
and demonstrate TDDFT's ability to accurately predict these geometric
dependencies. Finally, we note that this experimental data was collected at a
much faster rate than another recently reported dataset using the same setup,
demonstrating that ultrahigh resolution XRTS data can be collected in more
general experimental scenarios.",http://arxiv.org/abs/2501.19276v1
"A Metal-Insulator Transition of the Buried MnO2 Monolayer in Complex
  Oxide Heterostructure",2025-01-31T16:48:44Z,"Heng-Jui Liu, Jheng-Cyuan Lin, Yue-Wen Fang, Jing-Ching Wang, Bo-Chao Huang, Xiang Gao, Rong Huang, Philip R. Dean, Peter D. Hatton, Yi-Ying Chin, Hong-Ji Lin, Chien-Te Chen, Yuichi Ikuhara, Ya-Ping Chiu, Chia-Seng Chang, Chun-Gang Duan, Qing He, Ying-Hao Chu","Functionalities in crystalline materials are determined by 3-dimensional
collective interactions of atoms. The confinement of dimensionality in
condensed matter provides an exotic research direction to understand the
interaction of atoms, thus can be used to tailor or create new functionalities
in material systems. In this study, a 2-dimensional transition metal oxide
monolayer is constructed inside complex oxide heterostructures based on the
theoretical predictions. The electrostatic boundary conditions of oxide
monolayer in the heterostructure is carefully designed to tune the chemical,
electronic, and magnetic states of oxide monolayer. The challenge of
characterizing such an oxide monolayer is overcome by a combination of
transmission electron microscopy, x-ray absorption spectroscopy,
cross-sectional scanning tunneling microscopy, and electrical transport
measurements. An intriguing metal-insulator transition associated with a
magnetic transition is discovered in the MnO2 monolayer. This study paves a new
route to understand the confinement of dimensionality and explore new
intriguing phenomena in condensed matters.",http://arxiv.org/abs/2501.19289v1
"Synthetic User Behavior Sequence Generation with Large Language Models
  for Smart Homes",2025-01-31T16:55:43Z,"Zhiyao Xu, Dan Zhao, Qingsong Zou, Jingyu Xiao, Yong Jiang, Zhenhui Yuan, Qing Li","In recent years, as smart home systems have become more widespread, security
concerns within these environments have become a growing threat. Currently,
most smart home security solutions, such as anomaly detection and behavior
prediction models, are trained using fixed datasets that are precollected.
However, the process of dataset collection is time-consuming and lacks the
flexibility needed to adapt to the constantly evolving smart home environment.
Additionally, the collection of personal data raises significant privacy
concerns for users. Lately, large language models (LLMs) have emerged as a
powerful tool for a wide range of tasks across diverse application domains,
thanks to their strong capabilities in natural language processing, reasoning,
and problem-solving. In this paper, we propose an LLM-based synthetic dataset
generation IoTGen framework to enhance the generalization of downstream smart
home intelligent models. By generating new synthetic datasets that reflect
changes in the environment, smart home intelligent models can be retrained to
overcome the limitations of fixed and outdated data, allowing them to better
align with the dynamic nature of real-world home environments. Specifically, we
first propose a Structure Pattern Perception Compression (SPPC) method tailored
for IoT behavior data, which preserves the most informative content in the data
while significantly reducing token consumption. Then, we propose a systematic
approach to create prompts and implement data generation to automatically
generate IoT synthetic data with normative and reasonable properties, assisting
task models in adaptive training to improve generalization and real-world
performance.",http://arxiv.org/abs/2501.19298v1
"Molecular details and free energy barriers of ion de-coordination at
  elevated salinity and pressure",2025-01-31T17:46:31Z,"Nathanael S. Schwindt, Razi Epsztein, Anthony P. Straub, Michael R. Shirts","Ion dehydration has been shown to strongly influence separation performance
in membrane systems and ion transport in nanoscale channels. It is especially
important for membrane-based brine treatment, which is limited by high
pressures and concentrations. However, the molecular details and drivers of ion
dehydration in membranes are not well understood, in particular under relevant
conditions for membrane operation. In this study, we estimated the dehydration
free energies for a range of different ions at high pressure and salinity
relevant to brine treatment using molecular simulation. In order to more
clearly interpret these results, we developed a procedure to unambiguously
estimate these free energies as a function of discrete-valued coordination
number. We also proposed alternatives to the coordination number as geometrical
constraints for traversing nanoscale constrictions, such as the maximum
cross-sectional area of the complexed ion, and calculated the free energy of
dehydration as a function of these constraints. We show that high operating
pressures do not significantly change cation hydration shell stability nor the
shell size, while high ionic concentrations lower the free energy barrier to
reduce the cation coordination number. High concentration introduces many ion
pairing events, which contribute to the lower barrier. We find that anion
dehydration free energies are largely unaffected by these conditions, only
showing a small increase in free energy at high pressure. We propose strategies
to improve ion-ion selectivity by leveraging the effects of elevated pressure
and salinity on ion dehydration.",http://arxiv.org/abs/2501.19344v1
Behavioural Analytics: Mathematics of the Mind,2025-01-07T11:44:48Z,"Richard Lane, Hannah State-Davey, Claire Taylor, Wendy Holmes, Rachel Boon, Mark Round","Behavioural analytics provides insights into individual and crowd behaviour,
enabling analysis of what previously happened and predictions for how people
may be likely to act in the future. In defence and security, this analysis
allows organisations to achieve tactical and strategic advantage through
influence campaigns, a key counterpart to physical activities. Before action
can be taken, online and real-world behaviour must be analysed to determine the
level of threat. Huge data volumes mean that automated processes are required
to attain an accurate understanding of risk. We describe the mathematical basis
of technologies to analyse quotes in multiple languages. These include a
Bayesian network to understand behavioural factors, state estimation algorithms
for time series analysis, and machine learning algorithms for classification.
We present results from studies of quotes in English, French, and Arabic, from
anti-violence campaigners, politicians, extremists, and terrorists. The
algorithms correctly identify extreme statements; and analysis at individual,
group, and population levels detects both trends over time and sharp changes
attributed to major geopolitical events. Group analysis shows that additional
population characteristics can be determined, such as polarisation over
particular issues and large-scale shifts in attitude. Finally, MP voting
behaviour and statements from publicly-available records are analysed to
determine the level of correlation between what people say and what they do.",http://arxiv.org/abs/2502.00013v1
"Large Language Models for Education: ChemTAsk -- An Open-Source Paradigm
  for Automated Q&A in the Graduate Classroom",2025-01-10T02:19:47Z,"Ryann M. Perez, Marie Shimogawa, Yanan Chang, Hoang Anh T. Phan, Jason G. Marmorstein, Evan S. K. Yanagawa, E. James Petersson","Large language models (LLMs) show promise for aiding graduate level
education, but are limited by their training data and potential confabulations.
We developed ChemTAsk, an open-source pipeline that combines LLMs with
retrieval-augmented generation (RAG) to provide accurate, context-specific
assistance. ChemTAsk utilizes course materials, including lecture transcripts
and primary publications, to generate accurate responses to student queries.
Over nine weeks in an advanced biological chemistry course at the University of
Pennsylvania, students could opt in to use ChemTAsk for assistance in any
assignment or to understand class material. Comparative analysis showed
ChemTAsk performed on par with human teaching assistants (TAs) in understanding
student queries and providing accurate information, particularly excelling in
creative problem-solving tasks. In contrast, TAs were more precise in their
responses and tailored their assistance to the specifics of the class. Student
feedback indicated that ChemTAsk was perceived as correct, helpful, and faster
than TAs. Open-source and proprietary models from Meta and OpenAI respectively
were tested on an original biological chemistry benchmark for future iterations
of ChemTAsk. It was found that OpenAI models were more tolerant to deviations
in the input prompt and excelled in self-assessment to safeguard for potential
confabulations. Taken together, ChemTAsk demonstrates the potential of
integrating LLMs with RAG to enhance educational support, offering a scalable
tool for students and educators.",http://arxiv.org/abs/2502.00016v2
"Defining the mean turbulent boundary layer thickness based on streamwise
  velocity skewness",2025-01-31T20:47:14Z,"Mitchell Lozier, Rahul Deshpande, Ahmad Zarei, Luka Lindić, Wagih Abu Rowin, Ivan Marusic","A new statistical definition for the mean turbulent boundary layer thickness
is introduced, based on the identification of the point where streamwise
velocity skewness changes sign in the outermost region of the boundary layer.
This definition is motivated by the phenomenology of streamwise velocity
fluctuations near the turbulent/non-turbulent interface, whose local
characteristics are shown to be universal for turbulent boundary layers under
low freestream turbulence conditions (e.g., with or without pressure gradients,
surface roughness, etc.). This approach provides a turbulent boundary layer
thickness that is consistent with previous definitions, such as those based on
Reynolds shear stress or `composite' mean velocity profiles, while being
independent of arbitrary thresholds and applicable to past single-point
measurements. Two methods are proposed for estimating the turbulent boundary
layer thickness using this definition: one based on simple linear interpolation
and the other on fitting a generalised Fourier model to the outer skewness
profile. The robustness and limitations of these methods are demonstrated
through analysis of several published experimental and numerical datasets,
which cover a range of canonical and non-canonical turbulent boundary layers.
These datasets vary in wall-normal resolution and measurement noise,
particularly in the critical turbulent/non-turbulent interface region.",http://arxiv.org/abs/2502.00157v1
The Yamada-Watanabe-Engelbert theorem for SPDEs in Banach spaces,2025-01-31T22:07:53Z,Esmée Theewis,"We give a unified proof of the Yamada-Watanabe-Engelbert theorem for various
notions of solutions for SPDEs in Banach spaces with cylindrical Wiener noise.
We use Kurtz' generalization of the theorems of Yamada, Watanabe and Engelbert.
Moreover, we deduce the classical Yamada-Watanabe theorem for SPDEs, with a
slightly different notion of 'unique strong solution' than that of Kurtz. Our
setting includes analytically strong solutions, analytically weak solutions and
mild solutions. For each of these notions, our approach allows a vast
flexibility with regard to which function spaces and integrability conditions
are chosen in the definition of a solution (and therefore changing the meaning
of existence and uniqueness). All results hold in Banach spaces which are
either martingale type 2 or UMD. For analytically weak solutions, the results
hold in arbitrary Banach spaces. In particular, our results extend the
Yamada-Watanabe theorems of Ondr\'ejat for mild solutions in 2-smooth Banach
spaces, of R\""ockner et al. for the variational framework and of Kunze for
analytically weak solutions, and cover many new settings. As a tool, and of
interest itself, we construct a measurable representation I of the stochastic
integral in a martingale type 2 or UMD Banach space, in the sense that for any
stochastically integrable process f and cylindrical Brownian motion W, we have
$I(f(\omega),W(\omega),\mathrm{Law}(f,W)) = (\int_0^{\cdot} f\,
\mathrm{d}W)(\omega)$ for almost every $\omega$.",http://arxiv.org/abs/2502.00189v1
"Agentic AI: Autonomy, Accountability, and the Algorithmic Society",2025-02-01T03:14:59Z,"Anirban Mukherjee, Hannah Hanwen Chang","Agentic Artificial Intelligence (AI) can autonomously pursue long-term goals,
make decisions, and execute complex, multi-turn workflows. Unlike traditional
generative AI, which responds reactively to prompts, agentic AI proactively
orchestrates processes, such as autonomously managing complex tasks or making
real-time decisions. This transition from advisory roles to proactive execution
challenges established legal, economic, and creative frameworks. In this paper,
we explore challenges in three interrelated domains: creativity and
intellectual property, legal and ethical considerations, and competitive
effects. Central to our analysis is the tension between novelty and usefulness
in AI-generated creative outputs, as well as the intellectual property and
authorship challenges arising from AI autonomy. We highlight gaps in
responsibility attribution and liability that create a ""moral crumple zone""--a
condition where accountability is diffused across multiple actors, leaving
end-users and developers in precarious legal and ethical positions. We examine
the competitive dynamics of two-sided algorithmic markets, where both sellers
and buyers deploy AI agents, potentially mitigating or amplifying tacit
collusion risks. We explore the potential for emergent self-regulation within
networks of agentic AI--the development of an ""algorithmic society""--raising
critical questions: To what extent would these norms align with societal
values? What unintended consequences might arise? How can transparency and
accountability be ensured? Addressing these challenges will necessitate
interdisciplinary collaboration to redefine legal accountability, align
AI-driven choices with stakeholder values, and maintain ethical safeguards. We
advocate for frameworks that balance autonomy with accountability, ensuring all
parties can harness agentic AI's potential while preserving trust, fairness, &
societal welfare.",http://arxiv.org/abs/2502.00289v3
ALU: Agentic LLM Unlearning,2025-02-01T11:45:44Z,"Debdeep Sanyal, Murari Mandal","Information removal or suppression in large language models (LLMs) is a
desired functionality, useful in AI regulation, legal compliance, safety, and
privacy. LLM unlearning methods aim to remove information on demand from LLMs.
Current LLM unlearning methods struggle to balance the unlearning efficacy and
utility due to the competing nature of these objectives. Keeping the unlearning
process computationally feasible without assuming access to the model weights
is an overlooked area. We present the first agentic LLM unlearning (ALU)
method, a multi-agent, retrain-free, model-agnostic approach to LLM unlearning
that achieves effective unlearning while preserving the utility. Our ALU
framework unlearns by involving multiple LLM agents, each designed for a
specific step in the unlearning process, without the need to update model
weights for any of the agents in the framework. Users can easily request any
set of unlearning instances in any sequence, and ALU seamlessly adapts in real
time. This is facilitated without requiring any changes in the underlying LLM
model. Through extensive experiments on established benchmarks (TOFU, WMDP,
WPU) and jailbreaking techniques (many shot, target masking, other languages),
we demonstrate that ALU consistently stands out as the most robust LLM
unlearning framework among current state-of-the-art methods while incurring a
low constant-time cost. We further highlight ALU's superior performance
compared to existing methods when evaluated at scale. Specifically, ALU is
assessed on up to 1000 unlearning targets, exceeding the evaluation scope of
all previously proposed LLM unlearning methods.",http://arxiv.org/abs/2502.00406v1
"Influence of transition mutations and disorder on charge localization
  and transfer along B-DNA sequences",2025-02-01T18:22:19Z,"Pavlos Banev, Anastasia Falliera, Constantinos Simserides","We illuminate the influence of transition mutations and disorder on charge
localization and transfer along B-DNA sequences. Homopolymers are the best for
charge transfer (cf. Refs.~ \cite{LVBMS:2018, MLTS:2019}). Hence, we consider
as flawless a homopolymer sequence and then disturb it, introducing transition
mutations and disorder. We exclude the possibility of charge transfer via the
backbone that will be addressed soon in another work. We employ the Tight
Binding (TB) Wire model to study the influence of transition mutations and the
TB Fishbone Wire model to evaluate the influence of disorder emanating either
from the $\pi$ path or from the backbone. For the TB Wire parameters, we employ
the parametrization created in Ref.~\cite{MLS:2023}, where another TB at atomic
level was used, considering all valence orbitals of all atoms. We calculate the
HOMO and LUMO regime eigenenergies and eigenvectors, the participation ratio (a
measure of the localization of each eigenstate), the time-dependent probability
to find the carrier at each site, the mean over time probability at each site,
and the mean transfer rate from site to site. Transition mutations increase
localization in terms of participation ratio and impede charge transfer in
terms of mean probability and transfer rates, provided the TB parameters
involving mutated sites are significantly modified relative to the original.
Disorder leads to severe modifications of participation ratios, i.e., increase
of localization. Relevant changes occur on eigenenergies, mean probabilities at
each site, and transfer rates.",http://arxiv.org/abs/2502.00516v1
Radial Gradients and Intrinsic Scatter in MaNGA Galaxies,2025-02-01T19:07:32Z,"Tathagata Pal, Guy Worthey","We derive stellar population parameters and their radial gradients within
0.65 R$_e$ for spatially resolved spectra of 2417 early-type galaxies from the
MaNGA survey with stellar velocity dispersions ($\sigma$) between 50 kms$^{-1}$
and 340 kms$^{-1}$. We invert a grid of metallicity-composite stellar
population models to find mean age and the abundances of C, N, Na, Mg, and Fe.
These models have significant improvements compared to past models, including
isochrones that respond to individual element abundances.
  Globally, age rises with $\sigma$ while [Fe/H] gently falls. Individual light
element abundances strengthen with $\sigma$ but strengthen faster for
log($\sigma$)$>$2.0. [Fe/H] shows a maximum at log($\sigma$)$\approx$2.0,
falling to either side. Light element [X/Fe] anticorrelate with [Fe/H].
Heterogeneity as measured by astrophysical scatter is highest in low-$\sigma$
galaxies, most dramatically for age, Fe, and N.
  For galaxy-internal parameters, age shows nearly flat radial gradients in
low-$\sigma$ galaxies, slightly negative at high $\sigma$. The mean radial
gradient in [Fe/H] is negative and light element [X/Fe]s fall. Intrinsic
scatter in gradients is highest in high-$\sigma$ galaxies, most dramatically
for age and Fe. Evidently, nearly as many galaxies form inside-out as form
outside-in.
  A near-zero radial gradient in age and light elements coupled with a mild
[Fe/H] gradient supports the hierarchical merging scenario for ETG evolution.
IllustrisTNG hierarchical simulations reproduce the age structure we find, show
the abundance slope changes at log($\sigma$)$\approx$2.0 that we observe, and
exhibit flat gradients similar to those we derive, although the abundances
predicted by IllustrisTNG are significantly higher than our observations
overall.",http://arxiv.org/abs/2502.00531v1
"MedConv: Convolutions Beat Transformers on Long-Tailed Bone Density
  Prediction",2025-02-02T02:43:40Z,"Xuyin Qi, Zeyu Zhang, Huazhan Zheng, Mingxi Chen, Numan Kutaiba, Ruth Lim, Cherie Chiang, Zi En Tham, Xuan Ren, Wenxin Zhang, Lei Zhang, Hao Zhang, Wenbing Lv, Guangzhen Yao, Renda Han, Kangsheng Wang, Mingyuan Li, Hongtao Mao, Yu Li, Zhibin Liao, Yang Zhao, Minh-Son To","Bone density prediction via CT scans to estimate T-scores is crucial,
providing a more precise assessment of bone health compared to traditional
methods like X-ray bone density tests, which lack spatial resolution and the
ability to detect localized changes. However, CT-based prediction faces two
major challenges: the high computational complexity of transformer-based
architectures, which limits their deployment in portable and clinical settings,
and the imbalanced, long-tailed distribution of real-world hospital data that
skews predictions. To address these issues, we introduce MedConv, a
convolutional model for bone density prediction that outperforms transformer
models with lower computational demands. We also adapt Bal-CE loss and post-hoc
logit adjustment to improve class balance. Extensive experiments on our
AustinSpine dataset shows that our approach achieves up to 21% improvement in
accuracy and 20% in ROC AUC over previous state-of-the-art methods.",http://arxiv.org/abs/2502.00631v1
"Leveraging LLMs for Dynamic IoT Systems Generation through
  Mixed-Initiative Interaction",2025-02-02T06:21:49Z,"Bassam Adnan, Sathvika Miryala, Aneesh Sambu, Karthik Vaidhyanathan, Martina De Sanctis, Romina Spalazzese","IoT systems face significant challenges in adapting to user needs, which are
often under-specified and evolve with changing environmental contexts. To
address these complexities, users should be able to explore possibilities,
while IoT systems must learn and support users in the process of providing
proper services, e.g., to serve novel experiences. The IoT-Together paradigm
aims to meet this demand through the Mixed-Initiative Interaction (MII)
paradigm that facilitates a collaborative synergy between users and IoT
systems, enabling the co-creation of intelligent and adaptive solutions that
are precisely aligned with user-defined goals. This work advances IoT-Together
by integrating Large Language Models (LLMs) into its architecture. Our approach
enables intelligent goal interpretation through a multi-pass dialogue framework
and dynamic service generation at runtime according to user needs. To
demonstrate the efficacy of our methodology, we design and implement the system
in the context of a smart city tourism case study. We evaluate the system's
performance using agent-based simulation and user studies. Results indicate
efficient and accurate service identification and high adaptation quality. The
empirical evidence indicates that the integration of Large Language Models
(LLMs) into IoT architectures can significantly enhance the architectural
adaptability of the system while ensuring real-world usability.",http://arxiv.org/abs/2502.00689v1
CardioLive: Empowering Video Streaming with Online Cardiac Monitoring,2025-02-02T07:26:05Z,"Sheng Lyu, Ruiming Huang, Sijie Ji, Yasar Abbas Ur Rehman, Lan Ma, Chenshu Wu","Online Cardiac Monitoring (OCM) emerges as a compelling enhancement for the
next-generation video streaming platforms. It enables various applications
including remote health, online affective computing, and deepfake detection.
Yet the physiological information encapsulated in the video streams has been
long neglected. In this paper, we present the design and implementation of
CardioLive, the first online cardiac monitoring system in video streaming
platforms. We leverage the naturally co-existed video and audio streams and
devise CardioNet, the first audio-visual network to learn the cardiac series.
It incorporates multiple unique designs to extract temporal and spectral
features, ensuring robust performance under realistic video streaming
conditions. To enable the Service-On-Demand online cardiac monitoring, we
implement CardioLive as a plug-and-play middleware service and develop
systematic solutions to practical issues including changing FPS and
unsynchronized streams. Extensive experiments have been done to demonstrate the
effectiveness of our system. We achieve a Mean Square Error (MAE) of 1.79 BPM
error, outperforming the video-only and audio-only solutions by 69.2% and
81.2%, respectively. Our CardioLive service achieves average throughputs of
115.97 and 98.16 FPS when implemented in Zoom and YouTube. We believe our work
opens up new applications for video stream systems. We will release the code
soon.",http://arxiv.org/abs/2502.00702v1
An Event-Based Perception Pipeline for a Table Tennis Robot,2025-02-02T10:56:37Z,"Andreas Ziegler, Thomas Gossard, Arren Glover, Andreas Zell","Table tennis robots gained traction over the last years and have become a
popular research challenge for control and perception algorithms. Fast and
accurate ball detection is crucial for enabling a robotic arm to rally the ball
back successfully. So far, most table tennis robots use conventional,
frame-based cameras for the perception pipeline. However, frame-based cameras
suffer from motion blur if the frame rate is not high enough for fast-moving
objects. Event-based cameras, on the other hand, do not have this drawback
since pixels report changes in intensity asynchronously and independently,
leading to an event stream with a temporal resolution on the order of us. To
the best of our knowledge, we present the first real-time perception pipeline
for a table tennis robot that uses only event-based cameras. We show that
compared to a frame-based pipeline, event-based perception pipelines have an
update rate which is an order of magnitude higher. This is beneficial for the
estimation and prediction of the ball's position, velocity, and spin, resulting
in lower mean errors and uncertainties. These improvements are an advantage for
the robot control, which has to be fast, given the short time a table tennis
ball is flying until the robot has to hit back.",http://arxiv.org/abs/2502.00749v1
"Almost sure central limit theorems via chaos expansions and related
  results",2025-02-02T11:46:39Z,"Leonardo Maini, Maurizia Rossi, Guangqu Zheng","In this work, we investigate the asymptotic behavior of integral functionals
of stationary Gaussian random fields as the integration domain tends to be the
whole space. More precisely, using the Wiener chaos expansion and
Malliavin-Stein method, we establish an almost sure central limit theorem
(ASCLT) only under mild conditions on the covariance function of the underlying
stationary Gaussian field. In this setting, we additionally derive a
quantitative central limit theorem with rate of convergence in Wasserstein
distance, and show certain regularity property for the said integral
functionals (the latter under weaker conditions). In particular, we solved an
open question on the Malliavin differentiability of the excursion volume of
Berry's random wave model. As a key consequence of our analysis, we obtain the
exact asymptotic rate (as a function of the exponent) for moments of Bessel
functions, thus confirming a conjecture based on existing numerical
simulations. In the end, we provide two applications of our result: (i) ASCLT
in the context of Breuer-Major central limit theorems, (ii) ASCLT for Berry's
random wave model. It is worth stressing that our approach does not require any
knowledge on the regularity properties of random variables (e.g., Malliavin
differentiability) and hence not only complements the existing literature, but
also leads to novel results that are of independent interest.",http://arxiv.org/abs/2502.00759v2
RTBAgent: A LLM-based Agent System for Real-Time Bidding,2025-02-02T13:10:15Z,"Leng Cai, Junxuan He, Yikai Li, Junjie Liang, Yuanping Lin, Ziming Quan, Yawen Zeng, Jin Xu","Real-Time Bidding (RTB) enables advertisers to place competitive bids on
impression opportunities instantaneously, striving for cost-effectiveness in a
highly competitive landscape. Although RTB has widely benefited from the
utilization of technologies such as deep learning and reinforcement learning,
the reliability of related methods often encounters challenges due to the
discrepancies between online and offline environments and the rapid
fluctuations of online bidding. To handle these challenges, RTBAgent is
proposed as the first RTB agent system based on large language models (LLMs),
which synchronizes real competitive advertising bidding environments and
obtains bidding prices through an integrated decision-making process.
Specifically, obtaining reasoning ability through LLMs, RTBAgent is further
tailored to be more professional for RTB via involved auxiliary modules, i.e.,
click-through rate estimation model, expert strategy knowledge, and daily
reflection. In addition, we propose a two-step decision-making process and
multi-memory retrieval mechanism, which enables RTBAgent to review historical
decisions and transaction records and subsequently make decisions more adaptive
to market changes in real-time bidding. Empirical testing with real advertising
datasets demonstrates that RTBAgent significantly enhances profitability. The
RTBAgent code will be publicly accessible at:
https://github.com/CaiLeng/RTBAgent.",http://arxiv.org/abs/2502.00792v1
"Adversarial Semantic Augmentation for Training Generative Adversarial
  Networks under Limited Data",2025-02-02T13:50:38Z,"Mengping Yang, Zhe Wang, Ziqiu Chi, Dongdong Li, Wenli Du","Generative adversarial networks (GANs) have made remarkable achievements in
synthesizing images in recent years. Typically, training GANs requires massive
data, and the performance of GANs deteriorates significantly when training data
is limited. To improve the synthesis performance of GANs in low-data regimes,
existing approaches use various data augmentation techniques to enlarge the
training sets. However, it is identified that these augmentation techniques may
leak or even alter the data distribution. To remedy this, we propose an
adversarial semantic augmentation (ASA) technique to enlarge the training data
at the semantic level instead of the image level. Concretely, considering
semantic features usually encode informative information of images, we estimate
the covariance matrices of semantic features for both real and generated images
to find meaningful transformation directions. Such directions translate
original features to another semantic representation, e.g., changing the
backgrounds or expressions of the human face dataset. Moreover, we derive an
upper bound of the expected adversarial loss. By optimizing the upper bound,
our semantic augmentation is implicitly achieved. Such design avoids redundant
sampling of the augmented features and introduces negligible computation
overhead, making our approach computation efficient. Extensive experiments on
both few-shot and large-scale datasets demonstrate that our method consistently
improve the synthesis quality under various data regimes, and further
visualized and analytic results suggesting satisfactory versatility of our
proposed method.",http://arxiv.org/abs/2502.00800v1
"MorphoITH: A Framework for Deconvolving Intra-Tumor Heterogeneity Using
  Tissue Morphology",2025-02-03T01:18:59Z,"Aleksandra Weronika Nielsen, Hafez Eslami Manoochehri, Hua Zhong, Vandana Panwar, Vipul Jarmale, Jay Jasti, Mehrdad Nourani, Dinesh Rakheja, James Brugarolas, Payal Kapur, Satwik Rajaram","The ability of tumors to evolve and adapt by developing subclones in
different genetic and epigenetic states is a major challenge in oncology.
Traditional tools like multi-regional sequencing used to study tumor evolution
and the resultant intra-tumor heterogeneity (ITH) are often impractical because
of their resource-intensiveness and limited scalability. Here, we present
MorphoITH, a novel framework that leverages histopathology slides to deconvolve
molecular ITH through tissue morphology. MorphoITH integrates a self-supervised
deep learning similarity measure to capture phenotypic variation across
multiple dimensions (cytology, architecture, and microenvironment) with
rigorous methods to eliminate spurious sources of variation. Using a prototype
of ITH, clear cell renal cell carcinoma (ccRCC), we show that MorphoITH
captures clinically-significant biological features, such as vascular
architecture and nuclear grades. Furthermore, we find that MorphoITH recognizes
differential biological states corresponding to subclonal changes in key driver
genes (BAP1/PBRM1/SETD2). Finally, by applying MorphoITH to a multi-regional
sequencing experiment, we postulate evolutionary trajectories that largely
recapitulate genetic evolution. In summary, MorphoITH provides a scalable
phenotypic lens that bridges the gap between histopathology and genomics,
advancing precision oncology.",http://arxiv.org/abs/2502.00979v1
"FetDTIAlign: A Deep Learning Framework for Affine and Deformable
  Registration of Fetal Brain dMRI",2025-02-03T05:10:00Z,"Bo Li, Qi Zeng, Simon K. Warfield, Davood Karimi","Diffusion MRI (dMRI) provides unique insights into fetal brain microstructure
in utero. Longitudinal and cross-sectional fetal dMRI studies can reveal
crucial neurodevelopmental changes but require precise spatial alignment across
scans and subjects. This is challenging due to low data quality, rapid brain
development, and limited anatomical landmarks. Existing registration methods,
designed for high-quality adult data, struggle with these complexities. To
address this, we introduce FetDTIAlign, a deep learning approach for fetal
brain dMRI registration, enabling accurate affine and deformable alignment.
FetDTIAlign features a dual-encoder architecture and iterative feature-based
inference, reducing the impact of noise and low resolution. It optimizes
network configurations and domain-specific features at each registration stage,
enhancing both robustness and accuracy. We validated FetDTIAlign on data from
23 to 36 weeks gestation, covering 60 white matter tracts. It consistently
outperformed two classical optimization-based methods and a deep learning
pipeline, achieving superior anatomical correspondence. Further validation on
external data from the Developing Human Connectome Project confirmed its
generalizability across acquisition protocols. Our results demonstrate the
feasibility of deep learning for fetal brain dMRI registration, providing a
more accurate and reliable alternative to classical techniques. By enabling
precise cross-subject and tract-specific analyses, FetDTIAlign supports new
discoveries in early brain development.",http://arxiv.org/abs/2502.01057v2
"Visualization of Suppressed Shock Wave/Turbulent Boundary Layer
  Interaction Using Cryogenic Wall Cooling",2025-02-03T05:32:47Z,"Yuma Miki, Leo Ando, Maria Acuna, Kiyoshi Kinefuchi","To investigate the wall-cooling effects on shock wave turbulent/boundary
layer interaction (SWTBLI) with limited experimental data, a supersonic wind
tunnel wall was cooled using liquid nitrogen as the cryogenic coolant. Under
the condition of the mainstream Mach number, in the range of 2.02-2.04, the
wall temperature was cooled to 88-92 K, corresponding to a wall-to-recovery
temperature ratio of 0.31-0.33. The flow structures with and without wall
cooling were observed using the schlieren method. The reflected shock motion or
interaction length in the schlieren image suggested that boundary layer
separation was suppressed under the cooling condition in relation to that under
the non-cooling condition, and the suppressed ratio of the cooling-to-uncooling
interaction length was approximately 0.60-0.72. Additionally, while the
mainstream state and wall temperature near the separation were constant, a
gradual change in the separated flow field was observed under the wall-cooling
condition. This was due to the slow wall temperature increase in the upstream
wall of the separation region, where the incoming boundary layer developed.
Each flow field of SWTBLI in the present experiment, using liquid nitrogen as
the cryogenic coolant, was consistent with the classical Chaman's free
interaction theory.",http://arxiv.org/abs/2502.01073v1
"Deciphering the Multi-Wavelength Flares of the Most Distant Very
  High-Energy (>100 GeV) Gamma-ray Emitting Blazar",2025-02-03T08:42:05Z,"P N Naseef Mohammed, T. Aminabi, C. Baheeja, Vaidehi S. Paliya, S Sahayanathan, C D Ravikumar","This study analyzes the multi-wavelength flaring activity of the distant flat
spectrum radio quasar (FSRQ) OP 313 (z=0.997) during November 2023 to March
2024, using data from Fermi-Large Area Telescope, Swift X-ray Telescope, and
Ultraviolet and Optical Telescope. The analysis highlights two significant very
high energy(VHE) detection epochs and GeV gamma-ray flaring episodes, providing
insight into jet emission processes and radiative mechanisms. Key findings
include broadband spectral energy distribution (SED) evolution, including
enigmatic X-ray spectral changes. Modeling of the multi-wavelength SED with a
one-zone leptonic radiative processes attributes the emissions to synchrotron
radiation, Synchrotron Self-Compton (SSC), and External Compton (EC)
mechanisms, with torus photons as the primary source for EC processes. The
results suggest that the gamma-ray emitting region lies outside the broad-line
region but within the dusty torus. Furthermore, we find that the radiated power
is significantly smaller than the total jet power, suggesting that most of the
bulk energy remains within the jet even after passing through the blazar
emission zone. These findings advance our understanding of particle
acceleration, jet dynamics, and photon field interactions in FSRQs.",http://arxiv.org/abs/2502.01150v2
"Adjustable picometer-stable interferometers for testing space-based
  gravitational wave detectors",2025-02-03T10:03:52Z,"Marcel Beck, Shreevathsa Chalathadka Subrahmanya, Oliver Gerberding","Space-based gravitational wave detectors, such as the Laser Interferometer
Space Antenna (LISA), use picometer-precision laser interferometry to detect
gravitational waves at frequencies from 1 Hz down to below 0.1 mHz. Laser
interferometers used for on-ground prototyping and testing of such instruments
are typically constructed by permanently bonding or gluing optics onto an
ultra-stable bench made of low-expansion glass ceramic. This design minimizes
temperature coupling to length and tilt, which dominates the noise at low
frequencies due to finite temperature stability achievable in laboratories and
vacuum environments. Here, we present the study of an alternative
opto-mechanical concept where optical components are placed with adjustable and
freely positionable mounts on an ultra-stable bench, while maintaining
picometer length stability. With this concept, a given interferometer
configuration can be realised very quickly due to a simplified and speed-up
assembly process, reducing the realisation time from weeks or months to a
matter of hours. We built a corresponding test facility and verified the length
stability of our concept by measuring the length change in an optical cavity
that was probed with two different locking schemes, heterodyne laser frequency
stabilisation and Pound-Drever-Hall locking. We studied the limitations of both
locking schemes and verified that the cavity length noise is below 1
pm/sqrt(Hz) for frequencies down to 3 mHz. We thereby demonstrate that our
concept can simplify the testing of interferometer configurations and
opto-mechanical components and is suitable to realise flexible optical ground
support equipment for space missions that use laser interferometry, such as
future space-based gravitational wave detectors and satellite geodesy missions.",http://arxiv.org/abs/2502.01212v1
"Counterfactual Situation Testing: From Single to Multidimensional
  Discrimination",2025-02-03T11:38:48Z,"Jose M. Alvarez, Salvatore Ruggieri","We present counterfactual situation testing (CST), a causal data mining
framework for detecting individual discrimination in a dataset of classifier
decisions. CST answers the question ""what would have been the model outcome had
the individual, or complainant, been of a different protected status?"" It
extends the legally-grounded situation testing (ST) of Thanh et al. (2011) by
operationalizing the notion of fairness given the difference via counterfactual
reasoning. ST finds for each complainant similar protected and non-protected
instances in the dataset; constructs, respectively, a control and test group;
and compares the groups such that a difference in outcomes implies a potential
case of individual discrimination. CST, instead, avoids this idealized
comparison by establishing the test group on the complainant's generated
counterfactual, which reflects how the protected attribute when changed
influences other seemingly neutral attributes of the complainant. Under CST we
test for discrimination for each complainant by comparing similar individuals
within each group but dissimilar individuals across groups. We consider single
(e.g., gender) and multidimensional (e.g., gender and race) discrimination
testing. For multidimensional discrimination we study multiple and
intersectional discrimination and, as feared by legal scholars, find evidence
that the former fails to account for the latter kind. Using a k-nearest
neighbor implementation, we showcase CST on synthetic and real data.
Experimental results show that CST uncovers a higher number of cases than ST,
even when the model is counterfactually fair. In fact, CST extends
counterfactual fairness (CF) of Kusner et al. (2017) by equipping CF with
confidence intervals.",http://arxiv.org/abs/2502.01267v1
"Resilient UAV Trajectory Planning via Few-Shot Meta-Offline
  Reinforcement Learning",2025-02-03T11:39:12Z,"Eslam Eldeeb, Hirley Alves","Reinforcement learning (RL) has been a promising essence in future 5G-beyond
and 6G systems. Its main advantage lies in its robust model-free
decision-making in complex and large-dimension wireless environments. However,
most existing RL frameworks rely on online interaction with the environment,
which might not be feasible due to safety and cost concerns. Another problem
with online RL is the lack of scalability of the designed algorithm with
dynamic or new environments. This work proposes a novel, resilient, few-shot
meta-offline RL algorithm combining offline RL using conservative Q-learning
(CQL) and meta-learning using model-agnostic meta-learning (MAML). The proposed
algorithm can train RL models using static offline datasets without any online
interaction with the environments. In addition, with the aid of MAML, the
proposed model can be scaled up to new unseen environments. We showcase the
proposed algorithm for optimizing an unmanned aerial vehicle (UAV) 's
trajectory and scheduling policy to minimize the age-of-information (AoI) and
transmission power of limited-power devices. Numerical results show that the
proposed few-shot meta-offline RL algorithm converges faster than baseline
schemes, such as deep Q-networks and CQL. In addition, it is the only algorithm
that can achieve optimal joint AoI and transmission power using an offline
dataset with few shots of data points and is resilient to network failures due
to unprecedented environmental changes.",http://arxiv.org/abs/2502.01268v1
Fifteen Years of M31* X-ray Variability and Flares,2025-02-03T13:57:36Z,"Stephen DiKerby, Shuo Zhang, Jimmy Irwin","We append an additional fifteen years (2009-2024) to the Chandra X-ray light
curve of M31*, the supermassive black hole at the center of M31, the Andromeda
galaxy. Extending and expanding on the work in Li et al. 2011, we show that
M31* has remained in an elevated X-ray state from 2006 through at least 2016
(when regular Chandra monitoring ceased) and likely through 2024, with the most
recent observations still showing an elevated X-ray flux. We identify one
moderate flare in 2013 where the other nuclear X-ray sources are in low-flux
states, making that flare a valuable target for followup with multiwavelength
and multimessenger archival data. We extract a mostly uncontaminated spectrum
for M31* from this observation, showing that its X-ray properties are similar
to those observed at Sgr A* in its quiescent state by Baganoff et al. 2003.
Furthermore, we find no substantial change in the source's hardness ratio in
the 2006 and 2013 flares compared to the post-2006 elevated state, suggesting
the these flares are increases in the regular X-ray emission mechanisms instead
of entirely new emission modes. Our extended light curve for M31* provides
valuable context for multimessenger or multiwavelength observations of nearby
supermassive black holes.",http://arxiv.org/abs/2502.01365v1
"High-Performance Nonvolatile Spin FETs from 2D Metallic Ferromagnetic
  and Ferroelectric Multiferroic Heterostructure",2025-02-03T14:11:17Z,"B. Liu, X. Zhang, W. Hou, H. Feng, Zhengei Dai, Zhi-Xin Guo","All-electric-controlled nonvolatile spin field-effect transistors (SFETs)
based on two-dimensional (2D) multiferroic van der Waals (vdW) heterostructures
hold great promise for advanced spintronics applications. However, their
performance is hindered by the limited availability of 2D magnetic materials
that can switch effectively between metallic and semiconducting states with
sizable bandgaps controlled by ferroelectric polarization. Most studies have
focused on materials that are naturally semiconducting, achieving a metallic
state by modifying the ferroelectric polarization. In this work, we introduce
an innovative approach that uses interface effects to convert inherently
metallic 2D magnetic materials into half-metals and induce half-semiconducting
behavior through changes in ferroelectric polarization. Density functional
theory (DFT) calculations on the CrPS3/Sc2CO2 heterostructure demonstrate that
the ferroelectric polarization of Sc2CO2 monolayers can adjust the electronic
structure of CrPS3, enabling a switch from half-metallic to half-semiconducting
states. Building on these insights, we designed a nonvolatile SFET and analyzed
its transport properties using the nonequilibrium Green's function (NEGF)
method combined with DFT. Our results show that reversing the ferroelectric
polarization achieves an on/off current ratio exceeding 5000000%, and the
heterostructure generates nearly 100% spin-polarized current with a current
density of up to 6500 {\mu}A/{\mu}m at bias voltage below 0.2 V. These findings
highlight a promising pathway for developing high-performance SFETs that
surpass existing 2D heterojunction materials.",http://arxiv.org/abs/2502.01373v1
"Compliance while resisting: a shear-thickening fluid controller for
  physical human-robot interaction",2025-02-03T14:14:42Z,"Lu Chen, Lipeng Chen, Xiangchi Chen, Haojian Lu, Yu Zheng, Jun Wu, Yue Wang, Zhengyou Zhang, Rong Xiong","Physical human-robot interaction (pHRI) is widely needed in many fields, such
as industrial manipulation, home services, and medical rehabilitation, and puts
higher demands on the safety of robots. Due to the uncertainty of the working
environment, the pHRI may receive unexpected impact interference, which affects
the safety and smoothness of the task execution. The commonly used linear
admittance control (L-AC) can cope well with high-frequency small-amplitude
noise, but for medium-frequency high-intensity impact, the effect is not as
good. Inspired by the solid-liquid phase change nature of shear-thickening
fluid, we propose a Shear-thickening Fluid Control (SFC) that can achieve both
an easy human-robot collaboration and resistance to impact interference. The
SFC's stability, passivity, and phase trajectory are analyzed in detail, the
frequency and time domain properties are quantified, and parameter constraints
in discrete control and coupled stability conditions are provided. We conducted
simulations to compare the frequency and time domain characteristics of L-AC,
nonlinear admittance controller (N-AC), and SFC, and validated their dynamic
properties. In real-world experiments, we compared the performance of L-AC,
N-AC, and SFC in both fixed and mobile manipulators. L-AC exhibits weak
resistance to impact. N-AC can resist moderate impacts but not high-intensity
ones, and may exhibit self-excited oscillations. In contrast, SFC demonstrated
superior impact resistance and maintained stable collaboration, enhancing
comfort in cooperative water delivery tasks. Additionally, a case study was
conducted in a factory setting, further affirming the SFC's capability in
facilitating human-robot collaborative manipulation and underscoring its
potential in industrial applications.",http://arxiv.org/abs/2502.01376v1
"Regularized interpolation in 4D neural fields enables optimization of 3D
  printed geometries",2025-02-03T16:50:57Z,"Christos Margadji, Andi Kuswoyo, Sebastian W. Pattinson","The ability to accurately produce geometries with specified properties is
perhaps the most important characteristic of a manufacturing process. 3D
printing is marked by exceptional design freedom and complexity but is also
prone to geometric and other defects that must be resolved for it to reach its
full potential. Ultimately, this will require both astute design decisions and
timely parameter adjustments to maintain stability that is challenging even
with expert human operators. While machine learning is widely investigated in
3D printing, existing methods typically overlook spatial features that vary
across prints and thus find it difficult to produce desired geometries. Here,
we encode volumetric representations of printed parts into neural fields and
apply a new regularization strategy, based on minimizing the partial derivative
of the field's output with respect to a single, non-learnable parameter. By
thus encouraging small input changes to yield only small output variations, we
encourage smooth interpolation between observed volumes and hence realistic
geometry predictions. This framework therefore allows the extraction of
'imagined' 3D shapes, revealing how a part would look if manufactured under
previously unseen parameters. The resulting continuous field is used for
data-driven optimization to maximize geometric fidelity between expected and
produced geometries, reducing post-processing, material waste, and production
costs. By optimizing process parameters dynamically, our approach enables
advanced planning strategies, potentially allowing manufacturers to better
realize complex and feature-rich designs.",http://arxiv.org/abs/2502.01517v1
"Structural and Electronic Evolution of Bilayer Nickelates Under Biaxial
  Strain",2025-02-03T18:55:01Z,"H C Regan B. Bhatta, Xiaoliang Zhang, Yong Zhong, Chunjing Jia","The discovery of high-Tc superconductivity around 80K in bilayer nickelate
La3Ni2O7 under high pressure has expanded the family of high-Tc superconductors
above the nitrogen boiling temperature. Recent studies have further shown that
ambient pressure superconductivity with a Tc exceeding 40K can be achieved in
compressively strained La3Ni2O7 thin films, offering a tunable platform for
investigating the pairing mechanism in high-Tc nickelates. A comprehensive
understanding of the structural and electronic properties of bilayer nickelate
under epitaxial strain is essential to advance this active field. In this work,
we employ first-principles calculations to systematically explore the entire
rare-earth (Re) series of bilayer nickelates Re3Ni2O7 in the realistic
orthorhombic Amam phase under various compressive and tensile strain
conditions. We highlight the materials properties change when strain is
applied, and compare these results with those observed under high pressure. Our
findings show that 2.5\% compressive strain increases the apical Ni-O-Ni bond
angle toward 180 degree, and causes the Ni $d_{z^2}$ bands to move away from
the Fermi level. The tight-binding parameters for the 2.5\% compressively
strained La3Ni2O7 are quite similar to those of the unstrained material, except
that the on-site energy difference between the Ni $d_{z^2}$ and $d_{x^2-y^2}$
orbitals increases by about 50 percent. Notably, the absence of the $d_{z^2}$
bands at the Fermi energy under compressive strain contrasts sharply with the
electronic structure in the high-pressure {\it Fmmm} phase, suggesting that the
presence of $d_{z^2}$ bands at the Fermi energy may not be a requisite for
superconductivity.",http://arxiv.org/abs/2502.01624v1
Chaotic Behavior of Trapped Cosmic Rays,2025-02-03T19:00:00Z,"Vanessa López-Barquero, Paolo Desiati","Recent experimental results on the arrival direction of high-energy cosmic
rays have motivated studies to understand their propagating environment. The
observed anisotropy is shaped by interstellar and local magnetic fields. In
coherent magnetic structures, such as the heliosphere, or due to
magnetohydrodynamic turbulence, magnetic mirroring can temporarily trap
particles, leading to chaotic behavior. In this work, we develop a new method
to characterize cosmic rays' chaotic behavior in magnetic systems using
finite-time Lyapunov exponents. This quantity determines the degree of chaos
and adapts to transitory behavior. We study particle trajectories in an
axial-symmetric magnetic bottle to highlight mirroring effects. By introducing
time-dependent magnetic perturbations, we study how temporal variations affect
chaotic behavior. We tailor our model to the heliosphere; however, it can
represent diverse magnetic configurations exhibiting mirroring phenomena. Our
results have three key implications. (1)Theoretical: We find a correlation
between the finite-time Lyapunov exponent and the particle escape time from the
system, which follows a power law that persists even under additional
perturbations. This power law may reveal intrinsic system characteristics,
offering insight into propagation dynamics beyond simple diffusion.
(2)Simulation: Chaotic effects play a role in cosmic ray simulations and can
influence the resulting anisotropy maps. (3)Observational: Arrival maps display
areas where the chaotic properties vary significantly; these changes can be the
basis for time variability in the anisotropy maps. This work lays the framework
for studying the effects of magnetic mirroring of cosmic rays within the
heliosphere and the role of temporal variability in the observed anisotropy.",http://arxiv.org/abs/2502.01726v1
Spectra of He isotopes and the $^3$He/$^4$He ratio,2025-02-03T23:39:43Z,"M. J. Boschini, S. Della Torre, M. Gervasi, D. Grandi, G. Johannesson, G. La Vacca, N. Masi, I. V. Moskalenko, S. Pensotti, T. A. Porter, L. Quadrani, P. G. Rancoita, D. Rozza, M. Tacconi","Since its launch, the Alpha Magnetic Spectrometer-02 (AMS-02) has delivered
outstanding quality measurements of the spectra of cosmic-ray (CR) species,
$e^{\pm}$, $\bar{p}$, and nuclei (H-Si, S, Fe), which have resulted in a number
of breakthroughs. Besides elemental spectra, AMS-02 also measures the spectra
of light isotopes albeit within a smaller rigidity range. In this paper, we use
the precise measurements of He isotopes and the $^3$He/$^4$He ratio by AMS-02,
together with Voyager 1 data, and investigate their origin. We show that there
is an excess in $^3$He at higher energies compared to standard calculations
assuming its fully secondary origin, which may indicate a source of primary
$^3$He, or signify a change in the propagation parameters over the Galactic
volume probed by the $^3$He/$^4$He ratio. We provide updated local interstellar
spectra (LIS) of $^3$He and $^4$He in the rigidity range from 2-40 GV. Our
calculations employ the self-consistent GalProp-HelMod framework that has
proved to be a reliable tool in deriving the LIS of CR $e^{-}$, $\bar{p}$, and
nuclei $Z\le28$.",http://arxiv.org/abs/2502.01887v1
"A Kolmogorov High Order Deep Neural Network for High Frequency Partial
  Differential Equations in High Dimensions",2025-02-04T02:15:39Z,"Yaqin Zhang, Ke Li, Zhipeng Chang, Xuejiao Liu, Yunqing Huang, Xueshuang Xiang","This paper proposes a Kolmogorov high order deep neural network (K-HOrderDNN)
for solving high-dimensional partial differential equations (PDEs), which
improves the high order deep neural networks (HOrderDNNs). HOrderDNNs have been
demonstrated to outperform conventional DNNs for high frequency problems by
introducing a nonlinear transformation layer consisting of $(p+1)^d$ basis
functions. However, the number of basis functions grows exponentially with the
dimension $d$, which results in the curse of dimensionality (CoD). Inspired by
the Kolmogorov superposition theorem (KST), which expresses a multivariate
function as superpositions of univariate functions and addition, K-HOrderDNN
utilizes a HOrderDNN to efficiently approximate univariate inner functions
instead of directly approximating the multivariate function, reducing the
number of introduced basis functions to $d(p+1)$. We theoretically demonstrate
that CoD is mitigated when target functions belong to a dense subset of
continuous multivariate functions. Extensive numerical experiments show that:
for high-dimensional problems ($d$=10, 20, 50) where HOrderDNNs($p>1$) are
intractable, K-HOrderDNNs($p>1$) exhibit remarkable performance. Specifically,
when $d=10$, K-HOrderDNN($p=7$) achieves an error of 4.40E-03, two orders of
magnitude lower than that of HOrderDNN($p=1$) (see Table 10); for high
frequency problems, K-HOrderDNNs($p>1$) can achieve higher accuracy with fewer
parameters and faster convergence rates compared to HOrderDNNs (see Table 8).",http://arxiv.org/abs/2502.01938v1
"Adiabatic transverse thermoelectric conversion enhanced by heat current
  manipulation in artificially tilted multilayers",2025-02-04T02:31:40Z,"Fuyuki Ando, Takamasa Hirai, Hiroto Adachi, Ken-ichi Uchida","We phenomenologically formulate and experimentally observe an adiabatic
transverse thermoelectric conversion enhanced by a heat current re-orientation
in artificially tilted multilayers (ATMLs). By alternately stacking two
materials with different thermal conductivities and rotating its multilayered
structure with respect to a longitudinal temperature gradient, off-diagonal
components in the thermal conductivity tensor are induced. This off-diagonal
thermal conduction (ODTC) generates a finite transverse temperature gradient
and Seebeck-effect-induced thermopower in the adiabatic condition, which is
superposed on the isothermal transverse thermopower driven by the off-diagonal
Seebeck effect (ODSE). In this study, we calculate and observe the
two-dimensional temperature distribution and the resultant transverse
thermopower in ATMLs comprising thermoelectric Co$_{2}$MnGa Heusler alloys and
Bi$_{2-a}$Sb$_{a}$Te$_{3}$ compounds. By changing the tilt angle from 0{\deg}
to 90{\deg}, the transverse temperature gradient obviously appeared in the
middle angles and the transverse thermopower increases up to -116.1 ${\mu}$V/K
in Co$_{2}$MnGa/Bi$_{0.2}$Sb$_{1.8}$Te$_{3}$-based ATML at the tilt angle of
45{\deg} whereas the isothermal contribution is estimated to be -82.6
${\mu}$V/K from the analytical calculation. This hybrid action derived from
ODTC results in the significant variation of the maximum reduced efficiency for
transverse thermoelectric conversion from 3.1% in the isothermal limit to 8.1%
in the adiabatic limit.",http://arxiv.org/abs/2502.01944v1
"AutoGUI: Scaling GUI Grounding with Automatic Functionality Annotations
  from LLMs",2025-02-04T03:39:59Z,"Hongxin Li, Jingfan Chen, Jingran Su, Yuntao Chen, Qing Li, Zhaoxiang Zhang","User interface understanding with vision-language models has received much
attention due to its potential for enabling next-generation software
automation. However, existing UI datasets either only provide large-scale
context-free element annotations or contextualized functional descriptions for
elements at a much smaller scale. In this work, we propose the \methodname{}
pipeline for automatically annotating UI elements with detailed functionality
descriptions at scale. Specifically, we leverage large language models (LLMs)
to infer element functionality by comparing the UI content changes before and
after simulated interactions with specific UI elements. To improve annotation
quality, we propose LLM-aided rejection and verification, eliminating invalid
and incorrect annotations without human labor. We construct an
\methodname{}-704k dataset using the proposed pipeline, featuring
multi-resolution, multi-device screenshots, diverse data domains, and detailed
functionality annotations that have never been provided by previous datasets.
Human evaluation shows that the AutoGUI pipeline achieves annotation
correctness comparable to trained human annotators. Extensive experimental
results show that our \methodname{}-704k dataset remarkably enhances VLM's UI
grounding capabilities, exhibits significant scaling effects, and outperforms
existing web pre-training data types. We envision AutoGUI as a scalable
pipeline for generating massive data to build GUI-oriented VLMs. AutoGUI
dataset can be viewed at this anonymous URL:
https://autogui-project.github.io/.",http://arxiv.org/abs/2502.01977v1
"Online Adaptive Traversability Estimation through Interaction for
  Unstructured, Densely Vegetated Environments",2025-02-04T04:02:58Z,"Fabio A. Ruetz, Nicholas Lawrance, Emili Hernández, Paulo V. K. Borges, Thierry Peynot","Navigating densely vegetated environments poses significant challenges for
autonomous ground vehicles. Learning-based systems typically use prior and
in-situ data to predict terrain traversability but often degrade in performance
when encountering out-of-distribution elements caused by rapid environmental
changes or novel conditions. This paper presents a novel, lidar-only, online
adaptive traversability estimation (TE) method that trains a model directly on
the robot using self-supervised data collected through robot-environment
interaction. The proposed approach utilises a probabilistic 3D voxel
representation to integrate lidar measurements and robot experience, creating a
salient environmental model. To ensure computational efficiency, a sparse
graph-based representation is employed to update temporarily evolving voxel
distributions. Extensive experiments with an unmanned ground vehicle in natural
terrain demonstrate that the system adapts to complex environments with as
little as 8 minutes of operational data, achieving a Matthews Correlation
Coefficient (MCC) score of 0.63 and enabling safe navigation in densely
vegetated environments. This work examines different training strategies for
voxel-based TE methods and offers recommendations for training strategies to
improve adaptability. The proposed method is validated on a robotic platform
with limited computational resources (25W GPU), achieving accuracy comparable
to offline-trained models while maintaining reliable performance across varied
environments.",http://arxiv.org/abs/2502.01987v1
"First spectro-polarimetric study of the neutron star low-mass X-ray
  binary GX 9+1",2025-02-04T07:54:08Z,"V. P. Shyam Prakash, Vivek K. Agrawal, A. M. Vinodkumar","We present the first spectro-polarimetric study of the bright atoll source GX
9+1, using the simultaneous Imaging X-ray Polarimetry Explorer (IXPE), and
Neutron star Interior Composition Explorer (NICER) observations. The source was
observed to remain in the soft state, with no changes in state throughout the
observation period. The source does not show significant polarization in the
2-8 keV energy range. However, a significant polarization (3.3 sigma) was
detected in the 2-3 keV range, with a polarization degree of 3.3 +/- 0.8% and a
polarization angle of 11 +/- 7 deg. We used the simultaneous energy spectra
from NICER (0.6 - 11 keV) and IXPE (2-8 keV) to study the spectral properties
of the source during observations. The observed spectrum of the source can be
well described by a combination of Comptonized blackbody emission from the
neutron star surface (compbb model in XSPEC) and thermal Comptonized component
with seed photons from the accretion disc. The spectral properties of GX 9+1
during the observation are consistent with those of other bright atoll-sources
in the soft state. However, the high polarization degree observed in the
low-energy band does not align with previous IXPE observations of other
atoll-sources. This observed polarization in the source is attributed to the
strong polarization of the Comptonized blackbody component. We discuss the
results from the spectro-polarimetric studies in the context of various
accretion disc and coronal geometries of the source.",http://arxiv.org/abs/2502.02078v2
"High-pressure modulation of breathing kagome lattice: Cascade of
  Lifshitz transitions and evolution of the electronic structure",2025-02-04T08:58:11Z,"Marcos V. Gonçalves-Faria, Maxim Wenzel, Yuk Tai Chan, Olga Iakutkina, Francesco Capitani, Davide Comboni, Michael Hanfland, Qi Wang, Hechang Lei, Martin Dressel, Alexander A. Tsirlin, Alexej Pashkin, Stephan Winnerl, Manfred Helm, Ece Uykur","The interplay between electronic correlations, density wave orders, and
magnetism gives rise to several fascinating phenomena. In recent years, kagome
metals have emerged as an excellent platform for investigating these unique
properties, which stem from their itinerant carriers arranged in a kagome
lattice. Here, we show that electronic structure of the prototypical kagome
metal, Fe$_3$Sn$_2$, can be tailored by manipulating the breathing distortion
of its kagome lattice with external pressure. The breathing distortion is
suppressed around 15 GPa and reversed at higher pressures. These changes lead
to a series of Lifshitz transitions that we detect using broadband and
transient optical spectroscopy. Remarkably, the strength of the electronic
correlations and the tendency to carrier localization are enhanced as the
kagome network becomes more regular, suggesting that breathing distortion can
be a unique control parameter for the microscopic regime of the kagome metals
and their electron dynamics.",http://arxiv.org/abs/2502.02123v1
"Combinatorial Optimization Perspective based Framework for
  Multi-behavior Recommendation",2025-02-04T11:19:47Z,"Chenhao Zhai, Chang Meng, Yu Yang, Kexin Zhang, Xuhao Zhao, Xiu Li","In real-world recommendation scenarios, users engage with items through
various types of behaviors. Leveraging diversified user behavior information
for learning can enhance the recommendation of target behaviors (e.g., buy), as
demonstrated by recent multi-behavior methods. The mainstream multi-behavior
recommendation framework consists of two steps: fusion and prediction. Recent
approaches utilize graph neural networks for multi-behavior fusion and employ
multi-task learning paradigms for joint optimization in the prediction step,
achieving significant success. However, these methods have limited perspectives
on multi-behavior fusion, which leads to inaccurate capture of user behavior
patterns in the fusion step. Moreover, when using multi-task learning for
prediction, the relationship between the target task and auxiliary tasks is not
sufficiently coordinated, resulting in negative information transfer. To
address these problems, we propose a novel multi-behavior recommendation
framework based on the combinatorial optimization perspective, named COPF.
Specifically, we treat multi-behavior fusion as a combinatorial optimization
problem, imposing different constraints at various stages of each behavior to
restrict the solution space, thus significantly enhancing fusion efficiency
(COGCN). In the prediction step, we improve both forward and backward
propagation during the generation and aggregation of multiple experts to
mitigate negative transfer caused by differences in both feature and label
distributions (DFME). Comprehensive experiments on three real-world datasets
indicate the superiority of COPF. Further analyses also validate the
effectiveness of the COGCN and DFME modules. Our code is available at
https://github.com/1918190/COPF.",http://arxiv.org/abs/2502.02232v1
"Hybrid Resolver Model Generalization for Fault Condition Modeling: A
  Promising Tool for Reliability Study",2025-02-04T13:48:41Z,"MohammadSadegh KhajueeZadeh, Farid Tootoonchian, Ali Pourghoraba","Resolvers, like all electromagnetic devices, are constantly under
investigation, both operationally and structurally. In this regard, proposing a
modeling methodology that can save significant time without compromising
accuracy is a big honor. In this study, a generalized hybrid model is suggested
that, in addition to the above benefits, has sufficient capability to ease
reliability study in the field of resolvers, where a large number of faulty
conditions must be investigated under different operating conditions, including
changes in angular velocity, voltage, and frequency of excitation; all of which
are highlighted in the context of fault coverage. This model also serves as a
promising tool for generating large datasets, which is advantageous for fault
diagnosis. A resolver with a non-uniform air gap is chosen as a case study to
challenge the suggested model, particularly in relation to eccentricity faults.
We generalize the suggested model to account for the most common faulty
conditions of resolvers: in-turn short circuits in signal and excitation
windings, as well as static and dynamic eccentricity faults. The close
agreement between the results of the suggested model and those from
Time-Stepping Finite Element Analysis (TS-FEA), along with significant time
savings in both healthy and faulty conditions, highlights the generality and
proficiency of the suggested model. Finally, the case study is prototyped, and
we verify the accuracy of the suggested model experimentally.",http://arxiv.org/abs/2502.02323v1
"Composition Effects on Ni/Al Reactive Multilayers: A Comprehensive Study
  of Mechanical Properties, Reaction Dynamics and Phase Evolution",2025-02-04T14:09:17Z,"Nensi Toncich, Fabian Schwarz, Rebecca A. Gallivan, Jemma Gillon, Ralph Spolenak","Ni/Al reactive multilayers are promising materials for applications requiring
controlled local energy release and superior mechanical performance. This study
systematically investigates the impact of compositional variations, ranging
from 30 to 70 at.% Ni, and bilayer thicknesses (30 nm and 50 nm) on the
mechanical properties and reaction dynamics of Ni/Al multilayers. Multilayers
with varying Ni-to-Al ratios were fabricated and subjected to instrumented
nanoindentation testing to evaluate hardness and elastic modulus. Combustion
experiments, conducted on dogbone-shaped multilayers deposited onto silicon
wafers with thermal barrier coatings, characterized the reaction front's speed,
temperature, and the resulting phases. The findings revealed that composition
variations within this range enable precise tuning of reaction speed and
temperature without significant changes in mechanical properties, while
deviations in modulus and hardness at higher nickel concentrations suggest
microstructural influences. Notably, phase formation in Al-rich samples
deviated from equilibrium predictions, highlighting the role of kinetic
factors, such as diffusion and rapid quenching, in driving non-adiabatic
processes during phase evolution. Molecular dynamics simulations provided
complementary atomistic insights into mechanical responses and reaction
kinetics, bridging experimental observations with theoretical predictions. This
integrated approach advances the understanding of Ni/Al multilayers, offering a
framework for optimizing their composition and structural design to achieve
tailored performance for application-specific requirements.",http://arxiv.org/abs/2502.02333v1
"MaintaAvatar: A Maintainable Avatar Based on Neural Radiance Fields by
  Continual Learning",2025-02-04T14:52:34Z,"Shengbo Gu, Yu-Kun Qiu, Yu-Ming Tang, Ancong Wu, Wei-Shi Zheng","The generation of a virtual digital avatar is a crucial research topic in the
field of computer vision. Many existing works utilize Neural Radiance Fields
(NeRF) to address this issue and have achieved impressive results. However,
previous works assume the images of the training person are available and fixed
while the appearances and poses of a subject could constantly change and
increase in real-world scenarios. How to update the human avatar but also
maintain the ability to render the old appearance of the person is a practical
challenge. One trivial solution is to combine the existing virtual avatar
models based on NeRF with continual learning methods. However, there are some
critical issues in this approach: learning new appearances and poses can cause
the model to forget past information, which in turn leads to a degradation in
the rendering quality of past appearances, especially color bleeding issues,
and incorrect human body poses. In this work, we propose a maintainable avatar
(MaintaAvatar) based on neural radiance fields by continual learning, which
resolves the issues by utilizing a Global-Local Joint Storage Module and a Pose
Distillation Module. Overall, our model requires only limited data collection
to quickly fine-tune the model while avoiding catastrophic forgetting, thus
achieving a maintainable virtual avatar. The experimental results validate the
effectiveness of our MaintaAvatar model.",http://arxiv.org/abs/2502.02372v1
"Generalized quantum Zernike Hamiltonians: Polynomial Higgs-type algebras
  and algebraic derivation of the spectrum",2025-02-04T17:06:54Z,"Rutwig Campoamor-Stursberg, Francisco J. Herranz, Danilo Latini, Ian Marquette, Alfonso Blasco","We consider the quantum analog of the generalized Zernike systems given by
the Hamiltonian: $$ \hat{\mathcal{H}} _N =\hat{p}_1^2+\hat{p}_2^2+\sum_{k=1}^N
\gamma_k (\hat{q}_1 \hat{p}_1+\hat{q}_2 \hat{p}_2)^k , $$ with canonical
operators $\hat{q}_i,\, \hat{p}_i$ and arbitrary coefficients $\gamma_k$. This
two-dimensional quantum model, besides the conservation of the angular
momentum, exhibits higher-order integrals of motion within the enveloping
algebra of the Heisenberg algebra $\mathfrak h_2$. By constructing suitable
combinations of these integrals, we uncover a polynomial Higgs-type symmetry
algebra that, through an appropriate change of basis, gives rise to a deformed
oscillator algebra. The associated structure function $\Phi$ is shown to
factorize into two commuting components $\Phi=\Phi_1 \Phi_2$. This framework
enables an algebraic determination of the possible energy spectra of the model
for the cases $N=2,3,4$, the case $N=1$ being canonically equivalent to the
harmonic oscillator. Based on these findings, we propose two conjectures which
generalize the results for all $N\ge 2$ and any value of the coefficients
$\gamma_k$, that they are explicitly proven for $N=5$. In addition, all of
these results can be interpreted as superintegrable perturbations of the
original quantum Zernike system corresponding to $N=2$ which are also analyzed
and applied to the isotropic oscillator on the sphere, hyperbolic and Euclidean
spaces.",http://arxiv.org/abs/2502.02491v1
"Accurate Modeling of Directional Couplers with Oxide Cladding: Bridging
  Simulation and Experiment",2025-02-04T17:33:30Z,"Yuval Warshavsky, Yehonathan Drori, Jonatan Piasetzky, Amit Rotem, Ofer Shapiro, Yaron Oz, Haim Suchowski","Directional couplers are a fundamental building block in integrated
photonics, particularly in quantum applications and optimization-based design
where precision is critical. Accurate functionality is crucial to ensure
reliable operation within classical and quantum circuits. However,
discrepancies between simulations and measurements are frequently observed.
These inaccuracies can compromise the performance and scalability of integrated
photonic systems, underscoring the critical need for advanced, precise
simulation methods that bridge the gap between design and implementation. In
this work, we show that this discrepancy can be mainly attributed to density
changes in the oxide cladding. We conduct a systematic study involving
experimental optical measurements, numerical simulations, and direct electron
microscopy imaging to investigate this discrepancy in directional couplers. We
find that the impact of cladding density variations on performance increases as
feature gaps shrink. By incorporating these effects into our simulations using
a novel and physically motivated Effective Trench Medium Model (ETMM), we
achieve highly accurate reproduction of experimental measurements. We quantify
the effects of cladding density variations on the SU(2) symmetry parameters
that govern light propagation in directional couplers. This insight is crucial
for advancing the precision of compact device fabrication, enabling reliable
simulation of photonic integrated devices.",http://arxiv.org/abs/2502.02515v1
Gravitational Vacuum Condensate Stars in the Effective Theory of Gravity,2025-02-04T17:42:28Z,Emil Mottola,"The low energy effective theory of gravity comprises two elements of quantum
theory joined to classical general relativity. The first is the quantum
conformal anomaly, which is responsible for macroscopic correlations on light
cones and a stress tensor that can strongly modify the classical geometry at
black hole horizons. The second is the formulation of vacuum energy as
$\Lambda_{\rm eff}\!\propto\! F^2$ in terms of an exact $4$-form abelian gauge
field strength $F\!=\!dA$. When $A$ is identified with the Chern-Simons
$3$-form of the Euler class, defined in terms of the spin connection, a $J\cdot
A$ interaction is generated by the conformal anomaly of massless fermions. Due
to the extreme blueshifting of local frequencies in the near-horizon region of
a `black hole,' the lightest fermions of the Standard Model can be treated as
massless there, contributing to the anomaly and providing a $3$-current source
$J$ for the `Maxwell' equation $d\ast F = \ast J$. In this phase boundary
region, torsion is activated, and $F$ can change rapidly. The Schwarzschild
black hole horizon is thereby replaced by a surface, with a positive surface
tension and $\mathbb{R}\otimes \mathbb{S}^2$ worldtube topology, separating
regions of differing vacuum energy. The result is a gravitational vacuum
condensate star, a cold, compact, horizonless object with a $p_{_V}\!=\! -
\rho_{_V}$ zero entropy, non-singular de Sitter interior and thin quantum phase
boundary layer at the Schwarzschild radius $2GM/c^2$.",http://arxiv.org/abs/2502.02519v1
"CReIS: Computation Reuse through Image Similarity in ICN-Based Edge
  Computing",2025-02-04T18:39:10Z,"Atiyeh Javaheri, Ali Bohlooli, Kamal Jamshidi","At the edge, there is a high level of similarity in computing. One approach
that has been proposed to enhance the efficiency of edge computing is
computation reuse, which eliminates redundant computations. Edge computing is
integrated with the ICN architecture, capitalizing on its inherent intelligence
to facilitate computation reuse and reduce redundancies in computing
operations. In many past works, ICN's ability to enable computation reuse
through caching has been limited. In this context, a new approach is proposed
that considers computation requests with similar input data, which yield
identical results, as equivalent. This method facilitates computation reuse
through caching in ICN. The use of approximate results to reduce redundant
computations without requiring high accuracy in input matching is provided.
This concept is termed the Similarity Index, which effectively considers images
to be similar despite minor changes in the angle of photography. The Similarity
Index is determined through an algorithm known as HNSW and utilizes the SIFT
descriptor to identify similar data. This approach helps reduce user latency
times by providing quick access to results. The evaluation, simulated using the
ndnSIM tool, showed an 86% improvement in completion time compared to scenarios
without computation reuse, whereas previous works reported only a 70%
improvement. To strengthen this method, an analytical model for computing
request transfer considering computation reuse in ICN-based edge computing is
provided. To assess the accuracy of the model, several evaluations have been
conducted in the simulator by varying the parameters, resulting in a maximum
error percentage of approximately 16%.",http://arxiv.org/abs/2502.02564v1
Innovating the software engineering class through multi-team development,2025-02-04T18:54:43Z,Allan Brockenbrough,"Often software engineering classes have the student concentrate on designing
and planning the project but stop short of actual student team development of
code. This leads to criticism by employers of new graduates that they are
missing skills in working in teams and coordinating multiple overlapping
changes to a code base. Additionally, students that are not actively
experiencing team development are unprepared to understand and modify existing
legacy-code bases written by others. This paper presents a new approach to
teaching undergraduate software engineering that emphasizes not only software
engineering methodology but also experiencing development as a member of a team
and modifying a legacy code base. Our innovative software engineering course
begins with learning the fundamentals of software engineering, followed by
examining an existing framework of a social media application. The students are
then grouped into multiple software teams, each focusing on a different aspect
of the app. The separate teams must define requirements, design, and provide
documentation on the services. Using an Agile development approach, the teams
incrementally add to the code base and demonstrate features as the application
evolves. Subsequent iterations of the class pick up the prior students code
base, providing experience working with a legacy code base. Preliminary results
of using this approach at the university are presented in this paper including
quantitative analysis. Analysis of student software submissions to the
cloud-based code repository shows student engagement and contributions over the
span of the course. Positive student evaluations show the effectiveness of
applying the principles of software engineering to the development of a complex
solution in a team environment. Keywords: Software engineering, teaching,
college computer science, innovative methods, agile.",http://arxiv.org/abs/2502.02578v1
QLASS: Boosting Language Agent Inference via Q-Guided Stepwise Search,2025-02-04T18:58:31Z,"Zongyu Lin, Yao Tang, Xingcheng Yao, Da Yin, Ziniu Hu, Yizhou Sun, Kai-Wei Chang","Language agents have become a promising solution to complex interactive
tasks. One of the key ingredients to the success of language agents is the
reward model on the trajectory of the agentic workflow, which provides valuable
guidance during training or inference. However, due to the lack of annotations
of intermediate interactions, most existing works use an outcome reward model
to optimize policies across entire trajectories. This may lead to sub-optimal
policies and hinder the overall performance. To address this, we propose QLASS
(Q-guided Language Agent Stepwise Search), to automatically generate
annotations by estimating Q-values in a stepwise manner for open language
agents. By introducing a reasoning tree and performing process reward modeling,
QLASS provides effective intermediate guidance for each step. With the stepwise
guidance, we propose a Q-guided generation strategy to enable language agents
to better adapt to long-term value, resulting in significant performance
improvement during model inference on complex interactive agent tasks. Notably,
even with almost half the annotated data, QLASS retains strong performance,
demonstrating its efficiency in handling limited supervision. We also
empirically demonstrate that QLASS can lead to more effective decision making
through qualitative analysis. We will release our code and data.",http://arxiv.org/abs/2502.02584v1
ParetoQ: Scaling Laws in Extremely Low-bit LLM Quantization,2025-02-04T18:59:26Z,"Zechun Liu, Changsheng Zhao, Hanxian Huang, Sijia Chen, Jing Zhang, Jiawei Zhao, Scott Roy, Lisa Jin, Yunyang Xiong, Yangyang Shi, Lin Xiao, Yuandong Tian, Bilge Soran, Raghuraman Krishnamoorthi, Tijmen Blankevoort, Vikas Chandra","The optimal bit-width for achieving the best trade-off between quantized
model size and accuracy has been a subject of ongoing debate. While some
advocate for 4-bit quantization, others propose that 1.58-bit offers superior
results. However, the lack of a cohesive framework for different bits has left
such conclusions relatively tenuous. We present ParetoQ, the first unified
framework that facilitates rigorous comparisons across 1-bit, 1.58-bit, 2-bit,
3-bit, and 4-bit quantization settings. Our findings reveal a notable learning
transition between 2 and 3 bits: For 3-bits and above, the fine-tuned models
stay close to their original pre-trained distributions, whereas for learning
2-bit networks or below, the representations change drastically. By optimizing
training schemes and refining quantization functions, ParetoQ surpasses all
previous methods tailored to specific bit widths. Remarkably, our ParetoQ
ternary 600M-parameter model even outperforms the previous SoTA ternary
3B-parameter model in accuracy, using only one-fifth of the parameters.
Extensive experimentation shows that ternary, 2-bit, and 3-bit quantization
maintains comparable performance in the size-accuracy trade-off and generally
exceeds 4-bit and binary quantization. Considering hardware constraints, 2-bit
quantization offers promising potential for memory reduction and speedup.",http://arxiv.org/abs/2502.02631v1
"Deep Reinforcement Learning Enabled Persistent Surveillance with
  Energy-Aware UAV-UGV Systems for Disaster Management Applications",2025-02-04T19:11:02Z,"Md Safwan Mondal, Subramanian Ramasamy, Pranav Bhounsule","Integrating Unmanned Aerial Vehicles (UAVs) with Unmanned Ground Vehicles
(UGVs) provides an effective solution for persistent surveillance in disaster
management. UAVs excel at covering large areas rapidly, but their range is
limited by battery capacity. UGVs, though slower, can carry larger batteries
for extended missions. By using UGVs as mobile recharging stations, UAVs can
extend mission duration through periodic refueling, leveraging the
complementary strengths of both systems. To optimize this energy-aware UAV-UGV
cooperative routing problem, we propose a planning framework that determines
optimal routes and recharging points between a UAV and a UGV. Our solution
employs a deep reinforcement learning (DRL) framework built on an
encoder-decoder transformer architecture with multi-head attention mechanisms.
This architecture enables the model to sequentially select actions for visiting
mission points and coordinating recharging rendezvous between the UAV and UGV.
The DRL model is trained to minimize the age periods (the time gap between
consecutive visits) of mission points, ensuring effective surveillance. We
evaluate the framework across various problem sizes and distributions,
comparing its performance against heuristic methods and an existing
learning-based model. Results show that our approach consistently outperforms
these baselines in both solution quality and runtime. Additionally, we
demonstrate the DRL policy's applicability in a real-world disaster scenario as
a case study and explore its potential for online mission planning to handle
dynamic changes. Adapting the DRL policy for priority-driven surveillance
highlights the model's generalizability for real-time disaster response.",http://arxiv.org/abs/2502.02666v1
"An Analysis of LLM Fine-Tuning and Few-Shot Learning for Flaky Test
  Detection and Classification",2025-02-04T20:54:51Z,"Riddhi More, Jeremy S. Bradbury","Flaky tests exhibit non-deterministic behavior during execution and they may
pass or fail without any changes to the program under test. Detecting and
classifying these flaky tests is crucial for maintaining the robustness of
automated test suites and ensuring the overall reliability and confidence in
the testing. However, flaky test detection and classification is challenging
due to the variability in test behavior, which can depend on environmental
conditions and subtle code interactions. Large Language Models (LLMs) offer
promising approaches to address this challenge, with fine-tuning and few-shot
learning (FSL) emerging as viable techniques. With enough data fine-tuning a
pre-trained LLM can achieve high accuracy, making it suitable for organizations
with more resources. Alternatively, we introduce FlakyXbert, an FSL approach
that employs a Siamese network architecture to train efficiently with limited
data. To understand the performance and cost differences between these two
methods, we compare fine-tuning on larger datasets with FSL in scenarios
restricted by smaller datasets. Our evaluation involves two existing flaky test
datasets, FlakyCat and IDoFT. Our results suggest that while fine-tuning can
achieve high accuracy, FSL provides a cost-effective approach with competitive
accuracy, which is especially beneficial for organizations or projects with
limited historical data available for training. These findings underscore the
viability of both fine-tuning and FSL in flaky test detection and
classification with each suited to different organizational needs and resource
availability.",http://arxiv.org/abs/2502.02715v1
"Too Noisy To Learn: Enhancing Data Quality for Code Review Comment
  Generation",2025-02-04T22:48:58Z,"Chunhua Liu, Hong Yi Lin, Patanamon Thongtanunam","Code review is an important practice in software development, yet it is
time-consuming and requires substantial effort. While open-source datasets have
been used to train neural models for automating code review tasks, including
review comment generation, these datasets contain a significant amount of noisy
comments (e.g., vague or non-actionable feedback) that persist despite cleaning
methods using heuristics and machine learning approaches. Such remaining noise
may lead models to generate low-quality review comments, yet removing them
requires a complex semantic understanding of both code changes and natural
language comments. In this paper, we investigate the impact of such noise on
review comment generation and propose a novel approach using large language
models (LLMs) to further clean these datasets. Based on an empirical study on a
large-scale code review dataset, our LLM-based approach achieves 66-85%
precision in detecting valid comments. Using the predicted valid comments to
fine-tune the state-of-the-art code review models (cleaned models) can generate
review comments that are 13.0% - 12.4% more similar to valid human-written
comments than the original models. We also find that the cleaned models can
generate more informative and relevant comments than the original models. Our
findings underscore the critical impact of dataset quality on the performance
of review comment generation. We advocate for further research into cleaning
training data to enhance the practical utility and quality of automated code
review.",http://arxiv.org/abs/2502.02757v2
"Shifting burdens: How delayed decarbonisation of road transport affects
  other sectoral emission reductions",2025-02-05T01:11:45Z,"Elisabeth Zeyen, Sina Kalweit, Marta Victoria, Tom Brown","In 2022, fuel combustion in road transport accounted for approximately 21%
(760 million tonnes) of CO2 emissions in the European Union (EU). Road
transport is the only sector with rising emissions, with an increase of 24%
compared to 1990. The EU initially aimed to ban new CO2-emitting cars by 2030
but has since delayed this target to 2035, underscoring the ongoing challenges
in the push for rapid decarbonisation. The pace of decarbonisation in this
sector will either ease or intensify the pressure on other sectors to stay
within the EU's carbon budget. This paper explores the effects of speeding up
or slowing down the transition in road transport. We reveal that a slower
decarbonisation path not only drives up system costs by 126 billion Euro/a (6%)
but also demands more than a doubling of the CO2 price from 137 to 290
Euro/tCO2 in 2030 to trigger decarbonisation in other sectors. On the flip
side, accelerating the shift to cleaner transport proves to be the most
cost-effective strategy, giving room for more gradual changes in the heating
and industrial sectors, while reducing the reliance on carbon removal in later
years. Earlier mandates than currently envisaged by the EU can avoid stranded
assets and save up to 43 billion Euro/a compared to current policies.",http://arxiv.org/abs/2502.02809v1
ScholaWrite: A Dataset of End-to-End Scholarly Writing Process,2025-02-05T05:57:37Z,"Linghe Wang, Minhwa Lee, Ross Volkov, Luan Tuyen Chau, Dongyeop Kang","Writing is a cognitively demanding task involving continuous decision-making,
heavy use of working memory, and frequent switching between multiple
activities. Scholarly writing is particularly complex as it requires authors to
coordinate many pieces of multiform knowledge. To fully understand writers'
cognitive thought process, one should fully decode the end-to-end writing data
(from individual ideas to final manuscript) and understand their complex
cognitive mechanisms in scholarly writing. We introduce ScholaWrite dataset, a
first-of-its-kind keystroke corpus of an end-to-end scholarly writing process
for complete manuscripts, with thorough annotations of cognitive writing
intentions behind each keystroke. Our dataset includes LaTeX-based keystroke
data from five preprints with nearly 62K total text changes and annotations
across 4 months of paper writing. ScholaWrite shows promising usability and
applications (e.g., iterative self-writing), demonstrating the importance of
collection of end-to-end writing data, rather than the final manuscript, for
the development of future writing assistants to support the cognitive thinking
process of scientists. Our de-identified data examples and code are available
on our project page.",http://arxiv.org/abs/2502.02904v3
"Quantitative thermodynamic analyses of nucleation, evolution and
  stabilization of surface nanobubbles",2025-02-05T06:25:32Z,"Lili Lan, Yongcai Pan, Liang Zhao, Binghai Wen","Surface nanobubbles are complex micro- and nanoscale fluid systems. While
thermodynamics is believed to dominate nanobubble dynamics, the precise
mechanism by which nanobubble evolution is driven by thermodynamics remains
unclear. It is essential to understand how nanobubble nucleation and growth,
nanoscale contact line movement, and gas diffusion across the liquid-bubble
interface are simultaneously driven by the change in free energy, leading to
the ultimate thermodynamic equilibrium of surface nanobubble systems. In this
paper, we first propose a quantitative theoretical model to elucidate the
thermodynamic dominance behind the dynamics and stability of the fluid system
with surface nanobubbles. The present model demonstrates that thermodynamic
non-equilibrium drives the gas diffusion and the contact line motion of surface
nanobubbles. Overcoming the nucleation energy barrier is crucial for bubble
nucleation and growth. Surface nanobubbles evolve towards the reduction of the
system's free energy and stabilize at the state with minimum free energy. The
thermodynamic equilibrium is accompanied by the mechanical equilibrium at the
contact line and the gas diffusion equilibrium at the liquid-bubble interface,
and the theoretical results are in excellent agreement with the nanobubble
morphology observed in experiments. The study highlights the significant
influence of gas properties and ambient conditions in promoting bubble
nucleation and stability.",http://arxiv.org/abs/2502.02916v1
"Revealing the orbital origins of exotic electronic states with Ti
  substitution in kagome superconductor CsV3Sb5",2025-02-05T06:34:05Z,"Zihao Huang, Hui Chen, Hengxin Tan, Xianghe Han, Yuhan Ye, Bin Hu, Zhen Zhao, Chengmin Shen, Haitao Yang, Binghai Yan, Ziqiang Wang, Feng Liu, Hong-Jun Gao","The multiband kagome superconductor CsV3Sb5 exhibits complex orbital textures
on the Fermi surface, making the orbital origins of its cascade of correlated
electronic states and superconductivity a major scientific puzzle. Chemical
doping of the kagome plane can simultaneously tune the exotic states and the
Fermi-surface orbital texture, and thus offers a unique opportunity to
correlate the given states with specific orbitals. In this Letter, by
substituting V atoms with Ti in kagome superconductor CsV3Sb5, we reveal the
orbital origin of a cascade of its correlated electronic states through the
orbital-resolved quasiparticle interference (QPI). We analyze the QPI changes
associated with different orbitals, aided by first-principles calculations. We
have observed that the in-plane and out-of-plane vanadium 3d orbitals cooperate
to form unidirectional coherent states in pristine CsV3Sb5, whereas the
out-of-plane component disappears with doping-induced suppression of charge
density wave and global electronic nematicity. In addition, the Sb pz orbital
plays an important role in both the pseudo-gap and superconducting states in
CsV3Sb5. Our findings offer new insights into multiorbital physics in quantum
materials which are generally manifested with intriguing correlations between
atomic orbitals and symmetry-encoded correlated electronic states.",http://arxiv.org/abs/2502.02923v1
"Operando imaging of crystal structure and orientation in all components
  of all-solid-state-batteries",2025-02-05T10:50:34Z,"Quentin Jacquet, Jacopo Cele, Lara Casiez, Samuel Tardif, Asma Medjaheh, Stephanie Pouget, Manfred Burghammer, Sandrine Lyonnard, Sami Oukassi","A comprehensive understanding of interactions between cathode, electrolyte,
anode, and packaging during battery operation is crucial for advancing
performances but remains overlooked due to the lack of characterisation
technics capable of measuring these components simultaneously. We perform a
holistic investigation of a compact all-solid-state-battery using operando
synchrotron X-ray micro-diffraction imaging. We image in real time and
simultaneously the lattice parameter and crystal orientation of the dense
LiCoO2 cathode, the Ti current collector and the electrodeposited Li metal
anode. We reveal that reaction mechanism of LiCoO2 depends on the crystal
orientation, and that, in dense electrodes as opposed to porous ones, the
delithiation is limited by the formation of a Li-rich insulating interface. Li
metal crystal orientation is found to be influenced initially by the Ti texture
and to change within minutes during plating and stripping. These results
demonstrate the power of X-ray imaging to link reaction mechanism and grain
orientation during non-equilibrium processes.",http://arxiv.org/abs/2502.03063v1
"Perfect matching of reactive loads through complex frequencies: from
  circuital analysis to experiments",2025-02-05T11:10:56Z,"Angelica V. Marini, Davide Ramaccia, Alessandro Toscano, Filiberto Bilotti","The experimental evidence of purely reactive loads impedance matching is here
provided by exploiting the special scattering response under complex
excitations. The study starts with a theoretical analysis of the reflection
properties of an arbitrary reactive load and identifies the proper excitation
able to transform the purely reactive load into a virtual resistive load during
the time the signal is applied. To minimize reflections between the load and
the transmission line, the excitation must have a complex frequency, leading to
a propagating signal with a tailored temporal envelope. The aim of this work is
to design and, for the first time,experimentally demonstrate this anomalous
scattering behavior in microwave circuits, showing that the time-modulated
signals can be exploited as a new degree of freedom for achieving impedance
matching without introducing neither a matching network nor resistive elements,
that are typically used for ensuring power dissipation and, thus, zero
reflection. The proposed matching strategy does not alter the reactive load
that is still lossless, enabling an anomalous termination condition where the
energy is not dissipated nor reflected, but indefinitely accumulated in the
reactive load. The stored energy leaks out the load as soon as the applied
signal changes or stops.",http://arxiv.org/abs/2502.03076v1
"Cooperation, satisfaction, and rationality in social games on complex
  networks with aspiration-driven players",2025-02-05T12:10:49Z,"M. Aguilar-Janita, N. Khalil, I. Leyva, I. Sendiña-Nadal","A network model based on players' aspirations is proposed and analyzed
theoretically and numerically within the framework of evolutionary game theory.
In this model, players decide whether to cooperate or defect by comparing their
payoffs from pairwise games with their neighbors, driven by a common aspiration
level. The model also incorporates a degree of irrationality through an
effective temperature in the Fermi function. The level of cooperation in the
system is fundamentally influenced by two social attributes: satisfaction,
defined as the fraction of players whose payoffs exceed the aspiration level,
and the degree of rationality in decision-making. Rational players tend to
maintain their initial strategies for sufficiently low aspiration levels, while
irrational agents promote a state of perfect coexistence, resulting in half of
the agents cooperating. The transition between these two behaviors can be
critical, often leading to abrupt changes in cooperation levels. When the
aspiration level is high, all players become dissatisfied, regardless of the
effective temperature. Intermediate aspiration levels result in diverse
behaviors, including sudden transitions for rational agents and a non-monotonic
relationship between cooperation and increased irrationality. The study also
carefully examines the effects of the interaction structure, initial
conditions, and the strategy update rule (asynchronous versus synchronous).
Special attention is given to the prisoner's dilemma, where significant
cooperation levels can be achieved in a structured environment, with moderate
aspiration and high rationality settings, and following a synchronous strategy
updating scheme.",http://arxiv.org/abs/2502.03109v1
LED there be DoS: Exploiting variable bitrate IP cameras for network DoS,2025-02-05T13:53:59Z,"Emmanuel Goldberg, Oleg Brodt, Aviad Elyashar, Rami Puzis","Variable-bitrate video streaming is ubiquitous in video surveillance and
CCTV, enabling high-quality video streaming while conserving network bandwidth.
However, as the name suggests, variable-bitrate IP cameras can generate sharp
traffic spikes depending on the dynamics of the visual input. In this paper, we
show that the effectiveness of video compression can be reduced by up to 6X
using a simple laser LED pointing at a variable-bitrate IP camera, forcing the
camera to generate excessive network traffic. Experiments with IP cameras
connected to wired and wireless networks indicate that a laser attack on a
single camera can cause significant packet loss in systems sharing the network
with the camera and reduce the available bandwidth of a shared network link by
90%. This attack represents a new class of cyber-physical attacks that
manipulate variable bitrate devices through changes in the physical environment
without a digital presence on the device or the network. We also analyze the
broader view of multidimensional cyberattacks that involve both the physical
and digital realms and present a taxonomy that categorizes attacks based on
their direction of influence (physical-to-digital or digital-to-physical) and
their method of operation (environment-driven or device-driven), highlighting
multiple areas for future research.",http://arxiv.org/abs/2502.03177v1
"Reversible Switching of the Environment-Protected Quantum Spin Hall
  Insulator Bismuthene at the Graphene/SiC Interface",2025-02-05T16:13:25Z,"Niclas Tilgner, Susanne Wolff, Serguei Soubatch, Tien-Lin Lee, Andres David Peña Unigarro, Sibylle Gemming, F. Stefan Tautz, Christian Kumpf, Thomas Seyller, Fabian Göhler, Philip Schädlich","Quantum Spin Hall Insulators (QSHI) have been extensively studied both
theoretically and experimentally because they exhibit robust helical edge
states driven by spin-orbit coupling and offer the potential for applications
in spintronics through dissipationless spin transport. However, to realize
devices, it is indispensable to gain control over the interaction of the active
layer with the substrate, and to protect it from environmental influences. Here
we show that a single layer of elemental Bi, formed by intercalation of an
epitaxial graphene buffer layer on SiC(0001), is a promising candidate for a
QSHI. This layer can be reversibly switched between an electronically inactive
precursor state and a ``bismuthene state'', the latter exhibiting the predicted
band structure of a true two-dimensional bismuthene layer. Switching is
accomplished by hydrogenation (dehydrogenation) of the sample, i.e., a partial
passivation (activation) of dangling bonds of the SiC substrate, causing a
lateral shift of Bi atoms involving a change of the adsorption site. In the
bismuthene state, the Bi honeycomb layer is a prospective QSHI, inherently
protected by the graphene sheet above and the H-passivated substrate below.
Thus, our results represent an important step towards protected QSHI systems
beyond graphene.",http://arxiv.org/abs/2502.03314v1
Room Temperature Dy Spin-Flop Switching in Strained DyFeO3 Thin Films,2025-02-05T17:46:36Z,"Banani Biswas, Federico Stramaglia, Ekatarina V. Pomjakushina, Thomas Lippert, Carlos A. F. Vaz, Christof W. Schneider","Epitaxial strain in thin films can yield surprising magnetic and electronic
properties not accessible in bulk. One materials system destined to be explored
in this direction are orthoferrites with two intertwined spin systems where
strain is predicted to have a significant impact on magnetic and polar
properties by modifying the strength of the rare earth-Fe interaction. Here we
report the impact of epitaxial strain is reported on the linear
magneto-electric DyFeO3, a canted bulk antiferromagnet with a high Neel
temperature (645 K) exhibiting a Dy-induced spin reorientation transition at
approx. 50 K and antiferromagnetic ordering of the Dy spins at 4 K. An increase
in the spin transition of > 20 K is found and a strictly linear, abnormal
temperature magnetic response under an applied magnetic field between 100 and
400 K for [010]-oriented DyFeO3 thin films with an in-plane compressive strain
between 2% and 3.5%. At room temperature and above, we found that application
of approx. 0.06 T causes a spin-flop of the Dy spins coupled to the
antiferromagnetic Fe spin lattice, whereby the Dy spins change from an
antiferromagnetic alignment to ferromagnetic. The spin-flop field gives a lower
energy bound on the Dy-Fe exchange interaction of approx. 15 microeV.",http://arxiv.org/abs/2502.03404v1
"Prediction of the Most Fire-Sensitive Point in Building Structures with
  Differentiable Agents for Thermal Simulators",2025-02-05T18:14:20Z,"Yuan Xinjie, Khalid M. Mosalam","Fire safety is a critical area of research in civil and mechanical
engineering, particularly in ensuring the structural stability of buildings
during fire events. The Most Fire-Sensitive Point (MFSP) in a structure is the
location where a fire would cause the greatest impact on structural stability.
Accurate prediction of the MFSP is vital for streamlining structural
assessments and optimizing the design process. This paper presents a novel
framework for MFSP prediction using a neural network-based approach that
integrates fire dynamics and finite element analysis through a differentiable
agent model. The framework focuses on predicting the Maximum Interstory Drift
Ratio (MIDR), a key indicator of structural performance under fire conditions.
By leveraging the differentiable agent model, we efficiently generate labeled
data for MFSP and directly train a predictor for this critical metric. To
achieve this, we generated extensive simulation data encompassing structural
and fire scenarios and employed graph neural networks to represent the building
structures. Transfer learning was applied to optimize the training process, and
an edge update mechanism was introduced to dynamically adjust edge attributes,
reflecting property changes under fire conditions. The proposed model was
rigorously evaluated on simulation data, demonstrating strong performance in
accurately predicting both MIDR and MFSP, thus advancing fire safety analysis
for building structures.",http://arxiv.org/abs/2502.03424v1
Harnessing Large Language Models for Curated Code Reviews,2025-02-05T18:15:09Z,"Oussama Ben Sghaier, Martin Weyssow, Houari Sahraoui","In code review, generating structured and relevant comments is crucial for
identifying code issues and facilitating accurate code changes that ensure an
efficient code review process. Well-crafted comments not only streamline the
code review itself but are also essential for subsequent tasks like code
refinement, where the code is modified to satisfy the input review comment.
Although various AI-based approaches aimed to automate comment generation,
their effectiveness remains limited by the quality of the training data.
Existing code review datasets are often noisy and unrefined, posing limitations
to the learning potential of AI models and hindering the automation process.
  To address these challenges, we propose a curation pipeline designed to
enhance the quality of the largest publicly available code review dataset. We
begin by establishing an evaluation framework, incorporating specific criteria
and categories to empirically study the initial quality of the dataset. Using a
large language model (LLM)-driven approach, we then apply our curation pipeline
to refine the dataset. A comparative analysis of the newly curated dataset,
based on the same evaluation framework, demonstrates substantial improvements
in the clarity and conciseness of the comments. Additionally, we assess the
impact of the curated dataset on automating downstream tasks, specifically
comment generation and code refinement. Our findings show that the curated
dataset leads to enhanced model performance in generating more accurate
comments. Curated comments are also more useful as they lead to more accurate
code refinement.",http://arxiv.org/abs/2502.03425v1
"Analyzing Political Discourse on Discord during the 2024 U.S.
  Presidential Election",2025-02-05T18:28:47Z,"Arthur Buzelin, Pedro Robles Dutenhefner, Marcelo Sartori Locatelli, Samira Malaquias, Pedro Bento, Yan Aquino, Lucas Dayrell, Victoria Estanislau, Caio Santana, Pedro Alzamora, Marisa Vasconcelos, Wagner Meira Jr., Virgilio Almeida","Social media networks have amplified the reach of social and political
movements, but most research focuses on mainstream platforms such as X, Reddit,
and Facebook, overlooking Discord. As a rapidly growing, community-driven
platform with optional decentralized moderation, Discord offers unique
opportunities to study political discourse. This study analyzes over 30 million
messages from political servers on Discord discussing the 2024 U.S. elections.
Servers were classified as Republican-aligned, Democratic-aligned, or unaligned
based on their descriptions. We tracked changes in political conversation
during key campaign events and identified distinct political valence and
implicit biases in semantic association through embedding analysis. We observed
that Republican servers emphasized economic policies, while Democratic servers
focused on equality-related and progressive causes. Furthermore, we detected an
increase in toxic language, such as sexism, in Republican-aligned servers after
Kamala Harris's nomination. These findings provide a first look at political
behavior on Discord, highlighting its growing role in shaping and understanding
online political engagement.",http://arxiv.org/abs/2502.03433v1
"Dress-1-to-3: Single Image to Simulation-Ready 3D Outfit with Diffusion
  Prior and Differentiable Physics",2025-02-05T18:49:03Z,"Xuan Li, Chang Yu, Wenxin Du, Ying Jiang, Tianyi Xie, Yunuo Chen, Yin Yang, Chenfanfu Jiang","Recent advances in large models have significantly advanced image-to-3D
reconstruction. However, the generated models are often fused into a single
piece, limiting their applicability in downstream tasks. This paper focuses on
3D garment generation, a key area for applications like virtual try-on with
dynamic garment animations, which require garments to be separable and
simulation-ready. We introduce Dress-1-to-3, a novel pipeline that reconstructs
physics-plausible, simulation-ready separated garments with sewing patterns and
humans from an in-the-wild image. Starting with the image, our approach
combines a pre-trained image-to-sewing pattern generation model for creating
coarse sewing patterns with a pre-trained multi-view diffusion model to produce
multi-view images. The sewing pattern is further refined using a differentiable
garment simulator based on the generated multi-view images. Versatile
experiments demonstrate that our optimization approach substantially enhances
the geometric alignment of the reconstructed 3D garments and humans with the
input image. Furthermore, by integrating a texture generation module and a
human motion generation module, we produce customized physics-plausible and
realistic dynamic garment demonstrations. Project page:
https://dress-1-to-3.github.io/",http://arxiv.org/abs/2502.03449v1
"AI Governance in the Context of the EU AI Act: A Bibliometric and
  Literature Review Approach",2025-01-08T11:01:11Z,"Byeong-Je Kim, Seunghoo Jeong, Bong-Kyung Cho, Ji-Bum Chung","The rapid advancement of artificial intelligence (AI) has brought about
significant societal changes, necessitating robust AI governance frameworks.
This study analyzed the research trends in AI governance within the framework
of the EU AI Act. This study conducted a bibliometric analysis to examine the
publications indexed in the Web of Science database. Our findings reveal that
research on AI governance, particularly concerning AI systems regulated by the
EU AI Act, remains relatively limited compared to the broader AI research
landscape. Nonetheless, a growing interdisciplinary interest in AI governance
is evident, with notable contributions from multi-disciplinary journals and
open-access publications. Dominant research themes include ethical
considerations, privacy concerns, and the growing impact of generative AI, such
as ChatGPT. Notably, education, healthcare, and worker management are prominent
application domains. Keyword network analysis highlights education, ethics, and
ChatGPT as central keywords, underscoring the importance of these areas in
current AI governance research. Subsequently, a comprehensive literature review
was undertaken based on the bibliometric analysis findings to identify research
trends, challenges, and insights within the categories of the EU AI Act. The
findings provide valuable insights for researchers and policymakers, informing
future research directions and contributing to developing comprehensive AI
governance frameworks beyond the EU AI Act.",http://arxiv.org/abs/2502.03468v1
Immersion for AI: Immersive Learning with Artificial Intelligence,2025-02-05T11:51:02Z,Leonel Morgado,"This work reflects upon what Immersion can mean from the perspective of an
Artificial Intelligence (AI). Applying the lens of immersive learning theory,
it seeks to understand whether this new perspective supports ways for AI
participation in cognitive ecologies. By treating AI as a participant rather
than a tool, it explores what other participants (humans and other AIs) need to
consider in environments where AI can meaningfully engage and contribute to the
cognitive ecology, and what the implications are for designing such learning
environments. Drawing from the three conceptual dimensions of immersion -
System, Narrative, and Agency - this work reinterprets AIs in immersive
learning contexts. It outlines practical implications for designing learning
environments where AIs are surrounded by external digital services, can
interpret a narrative of origins, changes, and structural developments in data,
and dynamically respond, making operational and tactical decisions that shape
human-AI collaboration. Finally, this work suggests how these insights might
influence the future of AI training, proposing that immersive learning theory
can inform the development of AIs capable of evolving beyond static models.
This paper paves the way for understanding AI as an immersive learner and
participant in evolving human-AI cognitive ecosystems.",http://arxiv.org/abs/2502.03504v1
Stellar population synthesis models with a physically varying IMF,2025-02-05T19:00:02Z,"Akram Hasani Zonoozi, Hosein Haghi, Pavel Kroupa","Interpreting galactic luminosity requires assumptions about the galaxy-wide
initial mass function (gwIMF), often assumed invariant in most stellar
population synthesis (SPS) models. If stars form in clusters with metallicity-
and density-dependent \textit{stellar IMFs}, the integrated galaxy-wide IMF
(IGIMF) can be calculated, with its shape depending on the star formation rate
(SFR) and metallicity. The shape of the IGIMF thus depends on the star
formation rate (SFR) and metallicity. We develop the \texttt{SPS-VarIMF} code
which enables us for the first time to compute the spectra, luminosities, and
remnant populations of galaxies in the context of the varying gwIMF with time,
SFR, and an assumed metallicity. Using the \texttt{SPS-VarIMF} code one can
calculate how the interpretation from the integrated galactic light may change
if the underlying galaxy-wide IMF is assumed to be environmentally dependent
instead of being invariant. In particular, we compare the time evolution of the
galaxy color and the stellar mass-to-light ratio in different bands for the
IGIMF and invariant canonical gwIMF assuming constant and delayed-$\tau$ star
formation histories. We show that the underlying gwIMF can be determined by
examining the colors and luminosities of late-type galaxies in UV and optical
bands. On the other hand, for early-type galaxies, it is difficult to
distinguish which gwIMF is valid since adopting the different gwIMFs yields
almost identical colors. However, their gwIMF-dependent $M/L$ ratios differ by
up to an order of magnitude. Massive present-day elliptical galaxies would have
been $10^4$ times as bright as at present when they were forming.",http://arxiv.org/abs/2502.03529v1
"MNE: overparametrized neural evolution with applications to diffusion
  processes and sampling",2025-02-05T22:18:33Z,Michael Lindsey,"We propose a framework for solving evolution equations within parametric
function classes, especially ones that are specified by neural networks. We
call this framework the minimal neural evolution (MNE) because it is motivated
by the goal of seeking the smallest instantaneous change in the neural network
parameters that is compatible with exact solution of the evolution equation at
a set of evolving collocation points. Formally, the MNE is quite similar to the
recently introduced Neural Galerkin framework, but a difference in perspective
motivates an alternative sketching procedure that effectively reduces the
linear systems solved within the integrator to a size that is interpretable as
an effective rank of the evolving neural tangent kernel, while maintaining a
smooth evolution equation for the neural network parameters. We focus
specifically on the application of this framework to diffusion processes, where
the score function allows us to define intuitive dynamics for the collocation
points. These can in turn be propagated jointly with the neural network
parameters using a high-order adaptive integrator. In particular, we
demonstrate how the Ornstein-Uhlenbeck diffusion process can be used for the
task of sampling from a probability distribution given a formula for the
density but no training data. This framework extends naturally to allow for
conditional sampling and marginalization, and we show how to systematically
remove the sampling bias due to parametric approximation error. We validate the
efficiency, systematic improvability, and scalability of our approach on
illustrative examples in low and high spatial dimensions.",http://arxiv.org/abs/2502.03645v1
"Reduce Lap Time for Autonomous Racing with Curvature-Integrated MPCC
  Local Trajectory Planning Method",2025-02-06T01:03:54Z,"Zhouheng Li, Lei Xie, Cheng Hu, Hongye Su","The widespread application of autonomous driving technology has significantly
advanced the field of autonomous racing. Model Predictive Contouring Control
(MPCC) is a highly effective local trajectory planning method for autonomous
racing. However, the traditional MPCC method struggles with racetracks that
have significant curvature changes, limiting the performance of the vehicle
during autonomous racing. To address this issue, we propose a
curvature-integrated MPCC (CiMPCC) local trajectory planning method for
autonomous racing. This method optimizes the velocity of the local trajectory
based on the curvature of the racetrack centerline. The specific implementation
involves mapping the curvature of the racetrack centerline to a reference
velocity profile, which is then incorporated into the cost function for
optimizing the velocity of the local trajectory. This reference velocity
profile is created by normalizing and mapping the curvature of the racetrack
centerline, thereby ensuring efficient and performance-oriented local
trajectory planning in racetracks with significant curvature. The proposed
CiMPCC method has been experimented on a self-built 1:10 scale F1TENTH racing
vehicle deployed with ROS platform. The experimental results demonstrate that
the proposed method achieves outstanding results on a challenging racetrack
with sharp curvature, improving the overall lap time by 11.4%-12.5% compared to
other autonomous racing trajectory planning methods. Our code is available at
https://github.com/zhouhengli/CiMPCC.",http://arxiv.org/abs/2502.03695v1
"Stacking effects on magnetic, vibrational, and optical properties of
  CrSBr bilayers",2025-02-06T03:02:55Z,"Huicong Li, Yali Yang, Zhonghao Xia, Yateng Wang, Jiacheng Wei, Jiangang He, Rongming Wang","The van der Waals layered semiconductor CrSBr, which exhibits A-type
antiferromagnetism and a relatively high N\'{e}el temperature, has been
successfully exfoliated into atomically thin sheets. In this study, we
investigate the structural, lattice dynamical, electronic, magnetic, and
optical properties of four distinct stacking structures of CrSBr bilayers using
first-principles calculations and Monte Carlo simulations. Our findings show
that though the most energetically favorable bilayer structure retains the
stacking pattern of the bulk counterpart, three other high-symmetry stacking
structures can be achieved by sliding one of the layers along three distinct
directions, with energy costs comparable to that observed in MoS$_2$ bilayer.
All these four bilayers exhibit semiconductor behavior with A-type
antiferromagnetic ordering, similar to the bulk material, and demonstrate
closely aligned N\'{e}el temperatures. Moreover, these bilayers exhibit
relatively low lattice thermal conductivities, pronounced anisotropy, and a
strong dependence on stacking patterns. This behavior is attributed to
significant phonon-phonon scattering arising from avoided crossings between
acoustic and optical phonons, as well as the presence of flat optical phonon
bands in the low-frequency region. While the electronic structures and optical
properties of these bilayers show weak dependence on the stacking pattern for
antiferromagnetic ordering, they undergo significant changes for ferromagnetic
ordering, influencing the band gap, valence and conduction band splitting, and
effective mass. Furthermore, we found that antiferromagnetic ordering can
transition to ferromagnetic under intense visible light illumination. Thus, the
integration of layer stacking and visible light illumination offers an
effective means to control the heat transfer, magnetic, and optical properties
of CrSBr bilayers.",http://arxiv.org/abs/2502.03739v1
"Systolic Sparse Tensor Slices: FPGA Building Blocks for Sparse and Dense
  AI Acceleration",2025-02-06T03:49:29Z,"Endri Taka, Ning-Chi Huang, Chi-Chih Chang, Kai-Chiang Wu, Aman Arora, Diana Marculescu","FPGA architectures have recently been enhanced to meet the substantial
computational demands of modern deep neural networks (DNNs). To this end, both
FPGA vendors and academic researchers have proposed in-fabric blocks that
perform efficient tensor computations. However, these blocks are primarily
optimized for dense computation, while most DNNs exhibit sparsity. To address
this limitation, we propose incorporating structured sparsity support into FPGA
architectures. We architect 2D systolic in-fabric blocks, named systolic sparse
tensor (SST) slices, that support multiple degrees of sparsity to efficiently
accelerate a wide variety of DNNs. SSTs support dense operation, 2:4 (50%) and
1:4 (75%) sparsity, as well as a new 1:3 (66.7%) sparsity level to further
increase flexibility. When demonstrating on general matrix multiplication
(GEMM) accelerators, which are the heart of most current DNN accelerators, our
sparse SST-based designs attain up to 5x higher FPGA frequency and 10.9x lower
area, compared to traditional FPGAs. Moreover, evaluation of the proposed SSTs
on state-of-the-art sparse ViT and CNN models exhibits up to 3.52x speedup with
minimal area increase of up to 13.3%, compared to dense in-fabric acceleration.",http://arxiv.org/abs/2502.03763v1
Time-based GNSS attack detection,2025-02-06T08:28:41Z,"Marco Spanghero, Panos Papadimitratos","To safeguard Civilian Global Navigation Satellite Systems (GNSS) external
information available to the platform encompassing the GNSS receiver can be
used to detect attacks. Cross-checking the GNSS-provided time against
alternative multiple trusted time sources can lead to attack detection aiming
at controlling the GNSS receiver time. Leveraging external, network-connected
secure time providers and onboard clock references, we achieve detection even
under fine-grained time attacks. We provide an extensive evaluation of our
multi-layered defense against adversaries mounting attacks against the GNSS
receiver along with controlling the network link. We implement adversaries
spanning from simplistic spoofers to advanced ones synchronized with the GNSS
constellation. We demonstrate attack detection is possible in all tested cases
(sharp discontinuity, smooth take-over, and coordinated network manipulation)
without changes to the structure of the GNSS receiver. Leveraging the diversity
of the reference time sources, detection of take-over time push as low as 150us
is possible. Smooth take-overs forcing variations as low as 30ns are also
detected based on on-board precision oscillators. The method (and thus the
evaluation) is largely agnostic to the satellite constellation and the attacker
type, making time-based data validation of GNSS information compatible with
existing receivers and readily deployable.",http://arxiv.org/abs/2502.03868v2
"Raman signature of multiple phase transitions and quasi-particle
  excitations in putative Kitaev spin liquid candidate Na2Co2TeO6",2025-02-06T11:01:59Z,"Atul G. Chakkar, Chaitanya B. Auti, Deepu Kumar, Nirmalya Jana, Koushik Pal, Pradeep Kumar","Two-dimensional cobalt-based honeycomb oxide Na2Co2TeO6 is an important
candidate for the realization of Kitaev physics and may provide future platform
for the quantum computation and quantum technology. Here, we report an in-depth
temperature as well as polarization dependent inelastic light scattering
(Raman) measurements on the single crystals of quasi-two-dimensional
Na2Co2TeO6. Our study reveal signature of multiple phase transitions i.e.
long-range zigzag antiferromagnetic transition (TN) at ~ 30 K, ferroelectric
transition (TFE) at ~ 70 K, and a crossover from pure paramagnetic phase to a
quantum paramagnetic phase around ~ 150 K reflected in the renormalized
self-energy parameters of the Raman active phonon modes. A distinct signature
of spin reorientation deep into the AFM phase around TSR ~ 17 K is observed,
marked by the clear change in the frequency and linewidth slopes. We also
observed an asymmetric phonon mode in the low frequency region, and it appears
below the transition temperature ~ 50 K, attributed to the magnetic excitations
other than the magnon. The Raman signature of multiple crystal-field
excitations at low temperature along with lifting of the Kramers degeneracy is
also observed. Signature of the underlying broad magnetic continuum in the
quantum paramagnetic phase and its temperature dependence suggest presence of
frustrated magnetic interaction in the quantum paramagnetic phase below ~ 150
K.",http://arxiv.org/abs/2502.03970v1
"An Empirical Study on the Impact of Code Duplication-aware Refactoring
  Practices on Quality Metrics",2025-02-06T13:34:25Z,Eman Abdullah AlOmar,"Context: Code refactoring is widely recognized as an essential software
engineering practice that improves the understandability and maintainability of
source code. Several studies attempted to detect refactoring activities through
mining software repositories, allowing one to collect, analyze, and get
actionable data-driven insights about refactoring practices within software
projects. Objective: Our goal is to identify, among the various quality models
presented in the literature, the ones that align with the developer's vision of
eliminating duplicates of code, when they explicitly mention that they refactor
the code to improve them. Method: We extract a corpus of 332 refactoring
commits applied and documented by developers during their daily changes from
128 open-source Java projects. In particular, we extract 32 structural metrics
from which we identify code duplicate removal commits with their corresponding
refactoring operations, as perceived by software engineers. Thereafter, we
empirically analyze the impact of these refactoring operations on a set of
common state-of-the-art design quality metrics. Results: The statistical
analysis of the results obtained shows that (i) some state-of-the-art metrics
are capable of capturing the developer's intention of removing code
duplication; and (ii) some metrics are being more emphasized than others. We
confirm that various structural metrics can effectively represent code
duplication, leading to different impacts on software quality. Some metrics
contribute to improvements, while others may lead to degradation. Conclusion:
Most of the mapped metrics associated with the main quality attributes
successfully capture developers' intentions for removing code duplicates, as is
evident from the commit messages. However, certain metrics do not fully capture
these intentions",http://arxiv.org/abs/2502.04073v1
3D Prior is All You Need: Cross-Task Few-shot 2D Gaze Estimation,2025-02-06T13:37:09Z,"Yihua Cheng, Hengfei Wang, Zhongqun Zhang, Yang Yue, Bo Eun Kim, Feng Lu, Hyung Jin Chang","3D and 2D gaze estimation share the fundamental objective of capturing eye
movements but are traditionally treated as two distinct research domains. In
this paper, we introduce a novel cross-task few-shot 2D gaze estimation
approach, aiming to adapt a pre-trained 3D gaze estimation network for 2D gaze
prediction on unseen devices using only a few training images. This task is
highly challenging due to the domain gap between 3D and 2D gaze, unknown screen
poses, and limited training data. To address these challenges, we propose a
novel framework that bridges the gap between 3D and 2D gaze. Our framework
contains a physics-based differentiable projection module with learnable
parameters to model screen poses and project 3D gaze into 2D gaze. The
framework is fully differentiable and can integrate into existing 3D gaze
networks without modifying their original architecture. Additionally, we
introduce a dynamic pseudo-labelling strategy for flipped images, which is
particularly challenging for 2D labels due to unknown screen poses. To overcome
this, we reverse the projection process by converting 2D labels to 3D space,
where flipping is performed. Notably, this 3D space is not aligned with the
camera coordinate system, so we learn a dynamic transformation matrix to
compensate for this misalignment. We evaluate our method on MPIIGaze, EVE, and
GazeCapture datasets, collected respectively on laptops, desktop computers, and
mobile devices. The superior performance highlights the effectiveness of our
approach, and demonstrates its strong potential for real-world applications.",http://arxiv.org/abs/2502.04074v1
Quantifying imperfect cognition via achieved information gain,2025-02-06T13:57:19Z,Torsten Enßlin,"Cognition, the process of information processing in form of inference,
communication, and memorization, is the central activity of any intelligence.
Its physical realization in a brain, computer, or in any other intelligent
system requires resources like time, energy, memory, bandwidth, money, and
others. Due to limited resources, many real world intelligent systems perform
only imperfect cognition. For understanding the trade-off between accuracy and
resource investments in existing systems, e.g. in biology, as well as for the
resource-aware optimal design of information processing systems, like computer
algorithms and artificial neural networks, a quantification of information
obtained in an imperfect cognitive operation is desirable. To this end, we
propose the concept of achieved information gain (AIG) of a belief update,
which is given by the amount of information obtained by updating from the
initial knowledge state to the ideal one, minus the amount a change from the
imperfect to the ideal state would yield. AIG has many properties desired for
quantifying imperfect cognition. The ratio of achieved to ideally obtainable
information measures cognitive fidelity and that of AIG to the necessary
cognitive effort measures cognitive efficiency. We provide an axiomatic
derivation of AIG, illustrate its application at common scenarios of posterior
inaccuracies, and discuss the implication of cognitive efficiency for
sustainable resource allocation in computational inference.",http://arxiv.org/abs/2502.04088v1
"Sensitivity of three-dimensional boundary-layer stability to intrinsic
  uncertainties of fluid properties: a study on supercritical CO2",2025-02-06T14:30:06Z,"Jie Ren, Yongxiang Wu, Xuerui Mao, Cheng Wang, Markus Kloker","The intrinsic uncertainty of fluid properties, including the equation of
state, viscosity, and thermal conductivity, on boundary layer stability has
scarcely been addressed. When a fluid is operating in the vicinity of the Widom
line (defined as the maximum of isobaric specific heat) in supercritical state,
its properties exhibit highly non-ideal behavior, which is an ongoing research
field leading to refined and more accurate fluid property databases. Upon
crossing the Widom line, new mechanisms of flow instability emerge, feasibly
leading to changes in dominating modes that yield turbulence. The present work
investigates the sensitivity of three-dimensional boundary-layer modal
instability to these intrinsic uncertainties in fluid properties. The
uncertainty, regardless of its source and the fluid regimes, gives rise to
distortions of all profiles that constitute the inputs of the stability
operator. The effect of these distortions on flow stability is measured by
sensitivity coefficients, which are formulated with the adjoint operator and
validated against linear modal stability analysis. The results are presented
for carbon dioxide at a representative supercritical pressure of about 80 bar.
The sensitivity to different inputs of the stability operator across various
thermodynamic regimes show an immense range of sensitivity amplitude. A
balancing relationship between the density gradient and its perturbation leads
to a quadratic effect across the Widom line, provoking significant sensitivity
to distortions of the second derivative of the pressure with respect to the
density, $\partial^2 p/\partial \rho^2$. From an application-oriented point of
view, one important question is whether the correct baseflow profiles can be
meaningfully analyzed by the simplified ideal-fluid model...",http://arxiv.org/abs/2502.04105v1
Localizing invariants of inverse limits,2025-02-06T14:55:07Z,Alexander I. Efimov,"In this paper we study the category of nuclear modules on an affine formal
scheme as defined by Clausen and Scholze \cite{CS20}. We also study related
constructions in the framework of dualizable and rigid monoidal categories. We
prove that the $K$-theory (in the sense of \cite{E24}) of the category of
nuclear modules on $\operatorname{Spf}(R^{\wedge}_I)$ is isomorphic to the
classical continuous $K$-theory, which in the noetherian case is given by the
limit $\varprojlim\limits_{n} K(R/I^n).$ This isomorphism was conjectured
previously by Clausen and Scholze.
  More precisely, we study two versions of the category of nuclear modules: the
original one defined in \cite{CS20} and a different version, which contains the
original one as a full subcategory. For our category
$\operatorname{Nuc}(R^{\wedge}_I)$ we give three equivalent definitions. The
first definition is by taking the internal $\operatorname{Hom}$ in the category
$\operatorname{Cat}_R^{\operatorname{dual}}$ of $R$-linear dualizable
categories. The second definition is by taking the rigidification of the usual
$I$-complete derived category of $R.$ The third definition is by taking an
inverse limit in $\operatorname{Cat}_R^{\operatorname{dual}}.$ For each of the
three approaches we prove that the corresponding construction is well-behaved
in a certain sense.
  Moreover, we prove that the two versions of the category of nuclear modules
have the same $K$-theory, and in fact the same finitary localizing invariants.",http://arxiv.org/abs/2502.04123v2
"The Effects of Kinematic MHD on the Atmospheric Circulation of Eccentric
  Hot Jupiters",2025-02-06T15:53:58Z,"Hayley Beltz, Willow Houck, Laura C. Mayorga, Thaddeus D. Komacek, Joseph R. Livesey, Juliette Becker","Hot Jupiters are typically considered to be tidally locked due to their short
orbital periods. The extreme irradiation can result in atmospheric species
becoming thermally ionized on the dayside, which then interact with the
planet's magnetic field by resisting flow across magnetic field lines, shaping
the atmospheric structure. However, an eccentric orbit results in temporally
dependent irradiation and a non-permanent dayside, as the planet-star distance
can change drastically during its orbit. In this paper, we present 3D
atmospheric models of TOI-150b, an eccentric (e=0.26), Jupiter-mass 1.75 M_Jup
planet whose equilibrium temperature varies from 1300K to 1700K. We conduct
simulations for magnetic field strengths ranging from 0-30 Gauss using the
kinematic magnetohydrodynamics (MHD) approach. When compared to simulations of
the planet assuming a circular orbit, we find that the eccentric orbit results
in a strengthened and narrowed equatorial jet, westward winds at mid-latitudes,
and a phase-dependent thermal inversion. The strength and magnitude of these
effects scale with the chosen global magnetic field strength. We also generate
high-resolution (R=100,000) emission spectra to study net Doppler shifts and
find inter-orbit spectroscopic variability at moderate magnetic field
strengths, as well as decreased Doppler broadening as magnetic field strengths
increase. This work represents the first time that the kinematic MHD approach
has been applied to an eccentric hot Jupiter and highlights the importance of a
locally calculated, temperature dependent magnetic drag prescription for
predicting atmospheric structure and resulting spectra.",http://arxiv.org/abs/2502.04169v1
"Paper-based colorimetric sensor for detection of chloride anions in
  water using an epoxy-silver nanocomposite",2025-01-31T10:42:48Z,"Alfredo Franco, Celso Velásquez-Ordoñez, Miguel Ojeda-Martínez, María Ojeda-Martínez, Enrique Barrera-Calva, Víctor Rentería-Tapia","An epoxy-silver nanocomposite printed on paper was prepared for colorimetric
detection of chloride anions (Cl$^-$) in aqueous solution. This paper-based
sensor provides a promising platform with attractive advantages such as simple
fabrication, intense colors, fast naked-eye response, and high specificity
toward Cl$^-$ detection. The sensor undergoes a color change from yellow-orange
to chestnut-brown in the presence of water and turns to green-brown in the
presence of Cl$^-$. A good linear relationship ($R^2$=0.9754) between
logarithmic Cl$^-$ concentration and the extinction intensity difference at 515
nm was observed at concentrations in the 20-400 mM range with a limit of
detection (LOD) of 14 mM, far beyond the usual concentrations at which most of
the Cl$^-$ colorimetric sensors are limited. It was also proposed a sensing
mechanism based on the oxidative etching of anisotropic silver nanoparticles
(from 20 to 250 nm) by Cl$^-$ and subsequent formation of chain-like
aggregates, resulting in strong interparticle plasmonic coupling. This
paper-based sensor can distinguish Cl$^-$ from other ions such as F$^{-}$,
OH$^{-}$, NO$_{3}^{-}$, SO$_{4}^{2-}$, HPO$_{4}^{2-}$, H$_{2}$PO$_{4}^{-}$,
H$^{+}$, K$^{+}$, Na$^{+}$, NH$_{4}^{+}$, Zn$^{2+}$, and Co$^{2+}$ and from
mixtures of these ions. The nanosensor was also tested to recognize Cl$^{-}$ in
seawater and a commercial electrolyte solution, even using volumes as small as
4 $\mu$L, suggesting its easy inclusion in portable devices. This novel
colorimetric platform is undoubtedly useful for recognizing Cl$^-$ in
environmental and physiological systems.",http://arxiv.org/abs/2502.04337v1
"ImprovNet: Generating Controllable Musical Improvisations with Iterative
  Corruption Refinement",2025-02-06T21:45:38Z,"Keshav Bhandari, Sungkyun Chang, Tongyu Lu, Fareza R. Enus, Louis B. Bradshaw, Dorien Herremans, Simon Colton","Deep learning has enabled remarkable advances in style transfer across
various domains, offering new possibilities for creative content generation.
However, in the realm of symbolic music, generating controllable and expressive
performance-level style transfers for complete musical works remains
challenging due to limited datasets, especially for genres such as jazz, and
the lack of unified models that can handle multiple music generation tasks.
This paper presents ImprovNet, a transformer-based architecture that generates
expressive and controllable musical improvisations through a self-supervised
corruption-refinement training strategy. ImprovNet unifies multiple
capabilities within a single model: it can perform cross-genre and intra-genre
improvisations, harmonize melodies with genre-specific styles, and execute
short prompt continuation and infilling tasks. The model's iterative generation
framework allows users to control the degree of style transfer and structural
similarity to the original composition. Objective and subjective evaluations
demonstrate ImprovNet's effectiveness in generating musically coherent
improvisations while maintaining structural relationships with the original
pieces. The model outperforms Anticipatory Music Transformer in short
continuation and infilling tasks and successfully achieves recognizable genre
conversion, with 79\% of participants correctly identifying jazz-style
improvisations. Our code and demo page can be found at
https://github.com/keshavbhandari/improvnet.",http://arxiv.org/abs/2502.04522v1
"Agricultural Field Boundary Detection through Integration of ""Simple
  Non-Iterative Clustering (SNIC) Super Pixels"" and ""Canny Edge Detection
  Method""",2025-02-06T22:00:41Z,Artughrul Gayibov,"Efficient use of cultivated areas is a necessary factor for sustainable
development of agriculture and ensuring food security. Along with the rapid
development of satellite technologies in developed countries, new methods are
being searched for accurate and operational identification of cultivated areas.
In this context, identification of cropland boundaries based on spectral
analysis of data obtained from satellite images is considered one of the most
optimal and accurate methods in modern agriculture. This article proposes a new
approach to determine the suitability and green index of cultivated areas using
satellite data obtained through the ""Google Earth Engine"" (GEE) platform. In
this approach, two powerful algorithms, ""SNIC (Simple Non-Iterative Clustering)
Super Pixels"" and ""Canny Edge Detection Method"", are combined. The SNIC
algorithm combines pixels in a satellite image into larger regions (super
pixels) with similar characteristics, thereby providing better image analysis.
The Canny Edge Detection Method detects sharp changes (edges) in the image to
determine the precise boundaries of agricultural fields. This study, carried
out using high-resolution multispectral data from the Sentinel-2 satellite and
the Google Earth Engine JavaScript API, has shown that the proposed method is
effective in accurately and reliably classifying randomly selected agricultural
fields. The combined use of these two tools allows for more accurate
determination of the boundaries of agricultural fields by minimizing the
effects of outliers in satellite images. As a result, more accurate and
reliable maps can be created for agricultural monitoring and resource
management over large areas based on the obtained data. By expanding the
application capabilities of cloud-based platforms and artificial intelligence
methods in the agricultural field.",http://arxiv.org/abs/2502.04529v1
High-Speed Dynamic 3D Imaging with Sensor Fusion Splatting,2025-02-07T03:17:31Z,"Zihao Zou, Ziyuan Qu, Xi Peng, Vivek Boominathan, Adithya Pediredla, Praneeth Chakravarthula","Capturing and reconstructing high-speed dynamic 3D scenes has numerous
applications in computer graphics, vision, and interdisciplinary fields such as
robotics, aerodynamics, and evolutionary biology. However, achieving this using
a single imaging modality remains challenging. For instance, traditional RGB
cameras suffer from low frame rates, limited exposure times, and narrow
baselines. To address this, we propose a novel sensor fusion approach using
Gaussian splatting, which combines RGB, depth, and event cameras to capture and
reconstruct deforming scenes at high speeds. The key insight of our method lies
in leveraging the complementary strengths of these imaging modalities: RGB
cameras capture detailed color information, event cameras record rapid scene
changes with microsecond resolution, and depth cameras provide 3D scene
geometry. To unify the underlying scene representation across these modalities,
we represent the scene using deformable 3D Gaussians. To handle rapid scene
movements, we jointly optimize the 3D Gaussian parameters and their temporal
deformation fields by integrating data from all three sensor modalities. This
fusion enables efficient, high-quality imaging of fast and complex scenes, even
under challenging conditions such as low light, narrow baselines, or rapid
motion. Experiments on synthetic and real datasets captured with our prototype
sensor fusion setup demonstrate that our method significantly outperforms
state-of-the-art techniques, achieving noticeable improvements in both
rendering fidelity and structural accuracy.",http://arxiv.org/abs/2502.04630v1
Confidence Elicitation: A New Attack Vector for Large Language Models,2025-02-07T04:07:36Z,"Brian Formento, Chuan Sheng Foo, See-Kiong Ng","A fundamental issue in deep learning has been adversarial robustness. As
these systems have scaled, such issues have persisted. Currently, large
language models (LLMs) with billions of parameters suffer from adversarial
attacks just like their earlier, smaller counterparts. However, the threat
models have changed. Previously, having gray-box access, where input embeddings
or output logits/probabilities were visible to the user, might have been
reasonable. However, with the introduction of closed-source models, no
information about the model is available apart from the generated output. This
means that current black-box attacks can only utilize the final prediction to
detect if an attack is successful. In this work, we investigate and demonstrate
the potential of attack guidance, akin to using output probabilities, while
having only black-box access in a classification setting. This is achieved
through the ability to elicit confidence from the model. We empirically show
that the elicited confidence is calibrated and not hallucinated for current
LLMs. By minimizing the elicited confidence, we can therefore increase the
likelihood of misclassification. Our new proposed paradigm demonstrates
promising state-of-the-art results on three datasets across two models
(LLaMA-3-8B-Instruct and Mistral-7B-Instruct-V0.3) when comparing our technique
to existing hard-label black-box attack methods that introduce word-level
substitutions.",http://arxiv.org/abs/2502.04643v2
"Be Water, My Antennas: Riding on Radio Wave Fluctuation in Nature for
  Spatial Multiplexing using Programmable Meta-Fluid Antenna",2025-02-07T06:41:13Z,"Baiyang Liu, Kin-Fai Tong, Kai-Kit Wong, Chan-Byoung Chae, Hang Wong","Interference and scattering, often deemed undesirable, are inevitable in
wireless communications, especially when the current mobile networks and
upcoming sixth generation (6G) have turned into ultra-dense networks. Current
approaches relying on multiple-input multiple-output (MIMO) combined with
artificial-intelligence-aided (AI) signal processing have drawbacks of being
power-hungry and requiring wide bandwidth that raise scalability concerns. In
this article, we take a radical approach and utilize the channel fading
phenomenon to our advantage. Specifically, we propose a novel meta-fluid
antenna architecture, referred to as the `fluid' antenna system (FAS), that can
freely surf on radio wave fluctuations, like `fluid' figuratively speaking,
with fine resolution in space to opportunistically avoid interference,
eliminating the need for expensive signal processing. Our experimental results
demonstrate that under rich scattering conditions, the proposed meta-fluidic
architecture is able to exploit the natural ups and downs of radio waves in
space for spatial multiplexing. These breakthrough results show that scattering
can be desirable not harmful and interference can be dodged not suppressed,
fundamentally changing our perception of fading and our understanding on how
interference should be managed in wireless communications networks.",http://arxiv.org/abs/2502.04693v1
"Assessing the Aftermath: the Effects of a Global Takedown against
  DDoS-for-hire Services",2025-02-07T08:39:22Z,"Anh V. Vu, Ben Collier, Daniel R. Thomas, John Kristoff, Richard Clayton, Alice Hutchings","Law enforcement and private-sector partners have in recent years conducted
various interventions to disrupt the DDoS-for-hire market. Drawing on multiple
quantitative datasets, including web traffic and ground-truth visits to seized
websites, millions of DDoS attack records from academic, industry, and
self-reported statistics, along with chats on underground forums and Telegram
channels, we assess the effects of an ongoing global intervention against
DDoS-for-hire services since December 2022. This is the most extensive booter
takedown to date conducted, combining targeting infrastructure with digital
influence tactics in a concerted effort by law enforcement across several
countries with two waves of website takedowns and the use of deceptive domains.
We found over half of the seized sites in the first wave returned within a
median of one day, while all booters seized in the second wave returned within
a median of two days. Re-emerged booter domains, despite closely resembling old
ones, struggled to attract visitors (80-90% traffic reduction). While the first
wave cut the global DDoS attack volume by 20-40% with a statistically
significant effect specifically on UDP-based DDoS attacks (commonly attributed
to booters), the impact of the second wave appeared minimal. Underground
discussions indicated a cumulative impact, leading to changes in user
perceptions of safety and causing some operators to leave the market. Despite
the extensive intervention efforts, all DDoS datasets consistently suggest that
the illicit market is fairly resilient, with an overall short-lived effect on
the global DDoS attack volume lasting for at most only around six weeks.",http://arxiv.org/abs/2502.04753v1
"Explainable and externally validated machine learning for
  neuropsychiatric diagnosis via electrocardiograms",2025-02-07T13:37:13Z,"Juan Miguel Lopez Alcaraz, Ebenezer Oloyede, David Taylor, Wilhelm Haverkamp, Nils Strodthoff","Electrocardiogram (ECG) analysis has emerged as a promising tool for
identifying physiological changes associated with neuropsychiatric conditions.
The relationship between cardiovascular health and neuropsychiatric disorders
suggests that ECG abnormalities could serve as valuable biomarkers for more
efficient detection, therapy monitoring, and risk stratification. However, the
potential of the ECG to accurately distinguish neuropsychiatric conditions,
particularly among diverse patient populations, remains underexplored. This
study utilized ECG markers and basic demographic data to predict
neuropsychiatric conditions using machine learning models, with targets defined
through ICD-10 codes. Both internal and external validation were performed
using the MIMIC-IV and ECG-View datasets respectively. Performance was assessed
using AUROC scores. To enhance model interpretability, Shapley values were
applied to provide insights into the contributions of individual ECG features
to the predictions. Significant predictive performance was observed for
conditions within the neurological and psychiatric groups. For the neurological
group, Alzheimer's disease (G30) achieved an internal AUROC of 0.813
(0.812-0.814) and an external AUROC of 0.868 (0.867-0.868). In the psychiatric
group, unspecified dementia (F03) showed an internal AUROC of 0.849
(0.848-0.849) and an external AUROC of 0.862 (0.861-0.863). Discriminative
features align with known ECG markers but also provide hints on potentially new
markers. ECG offers significant promise for diagnosing and monitoring
neuropsychiatric conditions, with robust predictive performance across internal
and external cohorts. Future work should focus on addressing potential
confounders, such as therapy-related cardiotoxicity, and expanding the scope of
ECG applications, including personalized care and early intervention
strategies.",http://arxiv.org/abs/2502.04918v1
"Mobile Network-specialized Large Language Models for 6G: Architectures,
  Innovations, Challenges, and Future Trends",2025-02-07T13:53:15Z,"Abdelaali Chaoub, Muslim Elkotob","Conventional 5G network management mechanisms, that operate in isolated silos
across different network segments, will experience significant limitations in
handling the unprecedented hyper-complexity and massive scale of the sixth
generation (6G). Holistic intelligence and end-to-end automation are, thus,
positioned as key enablers of forthcoming 6G networks. The Large Language Model
(LLM) technology, a major breakthrough in the Generative Artificial
Intelligence (AI) field, enjoys robust human-like language processing, advanced
contextual reasoning and multi-modal capabilities. These features foster a
holistic understanding of network behavior and an autonomous decision-making.
This paper investigates four possible architectural designs for integrated LLM
and 6G networks, detailing the inherent technical intricacies, the merits and
the limitations of each design. As an internal functional building block of
future 6G networks, the LLM will natively benefit from their improved
design-driven security policies from the early design and specification stages.
An illustrative scenario of slicing conflicts is used to prove the
effectiveness of our architectural framework in autonomously dealing with
complicated network anomalies. We finally conclude the paper with an overview
of the key challenges and the relevant research trends for enabling Mobile
Networkspecialized LLMs. This study is intended to provide Mobile Network
Operators (MNOs) with a comprehensive guidance in their paths towards embracing
the LLM technology.",http://arxiv.org/abs/2502.04933v1
"A New Paradigm in Tuning Learned Indexes: A Reinforcement Learning
  Enhanced Approach",2025-02-07T15:22:15Z,"Taiyi Wang, Liang Liang, Guang Yang, Thomas Heinis, Eiko Yoneki","Learned Index Structures (LIS) have significantly advanced data management by
leveraging machine learning models to optimize data indexing. However,
designing these structures often involves critical trade-offs, making it
challenging for both designers and end-users to find an optimal balance
tailored to specific workloads and scenarios. While some indexes offer
adjustable parameters that demand intensive manual tuning, others rely on fixed
configurations based on heuristic auto-tuners or expert knowledge, which may
not consistently deliver optimal performance. This paper introduces LITune, a
novel framework for end-to-end automatic tuning of Learned Index Structures.
LITune employs an adaptive training pipeline equipped with a tailor-made Deep
Reinforcement Learning (DRL) approach to ensure stable and efficient tuning. To
accommodate long-term dynamics arising from online tuning, we further enhance
LITune with an on-the-fly updating mechanism termed the O2 system. These
innovations allow LITune to effectively capture state transitions in online
tuning scenarios and dynamically adjust to changing data distributions and
workloads, marking a significant improvement over other tuning methods. Our
experimental results demonstrate that LITune achieves up to a 98% reduction in
runtime and a 17-fold increase in throughput compared to default parameter
settings given a selected Learned Index instance. These findings highlight
LITune's effectiveness and its potential to facilitate broader adoption of LIS
in real-world applications.",http://arxiv.org/abs/2502.05001v2
"Dipole-Mode Spectrum and Hydrodynamic Crossover in a Resonantly
  Interacting Two-Species Fermion Mixture",2025-02-07T15:26:07Z,"Zhu-Xiong Ye, Alberto Canali, Chun-Kit Wong, Marian Kreyer, Emil Kirilov, Rudolf Grimm","Ultracold quantum-gas mixtures of fermionic atoms with resonant control of
interactions offer a unique test-bed to explore few- and many-body quantum
states with unconventional properties. The emergence of such strongly
correlated systems, as for instance symmetry-broken superfluids, is usually
accompanied by hydrodynamic collective behavior. Thus, experimental progress in
this field naturally requires a deep understanding of hydrodynamic regimes.
Here, we report on experiments employing a tunable Fermi-Fermi mixture of
$^{161}$Dy and $^{40}$K near quantum degeneracy. We investigate the full
spectrum of dipole modes across a Feshbach resonance and characterize the
crossover from collisionless to deep hydrodynamic behavior in measurements of
frequencies and damping rates. We compare our results with a theoretical model
that considers the motion of the mass centers of the two species and we
identify the contributions of friction and mean-field interaction. We show that
one oscillating mode exists over the whole range of interactions, exhibiting
striking changes of frequency and damping in the deep hydrodynamic regime. We
observe the second oscillating mode to split into two purely exponential
damping modes. One of these exponential modes shows very fast damping, faster
than any other relevant timescale, and is largely insensitive against
experimental imperfections. It provides an accurate measure for the
interspecies drag effect, which generalizes the concept of spin drag explored
in other experiments. We characterize the interspecies drag locally in terms of
a microscopic friction coefficient and we discuss its unitarity-limited
universal behavior on top of the resonance.",http://arxiv.org/abs/2502.05006v1
"EnseSmells: Deep ensemble and programming language models for automated
  code smells detection",2025-02-07T15:35:19Z,"Anh Ho, Anh M. T. Bui, Phuong T. Nguyen, Amleto Di Salle, Bach Le","A smell in software source code denotes an indication of suboptimal design
and implementation decisions, potentially hindering the code understanding and,
in turn, raising the likelihood of being prone to changes and faults.
Identifying these code issues at an early stage in the software development
process can mitigate these problems and enhance the overall quality of the
software. Current research primarily focuses on the utilization of deep
learning-based models to investigate the contextual information concealed
within source code instructions to detect code smells, with limited attention
given to the importance of structural and design-related features. This paper
proposes a novel approach to code smell detection, constructing a deep learning
architecture that places importance on the fusion of structural features and
statistical semantics derived from pre-trained models for programming
languages. We further provide a thorough analysis of how different source code
embedding models affect the detection performance with respect to different
code smell types. Using four widely-used code smells from well-designed
datasets, our empirical study shows that incorporating design-related features
significantly improves detection accuracy, outperforming state-of-the-art
methods on the MLCQ dataset with with improvements ranging from 5.98% to
28.26%, depending on the type of code smell.",http://arxiv.org/abs/2502.05012v1
"Investigating the impact of kernel harmonization and deformable
  registration on inspiratory and expiratory chest CT images for people with
  COPD",2025-02-07T17:41:49Z,"Aravind R. Krishnan, Yihao Liu, Kaiwen Xu, Michael E. Kim, Lucas W. Remedios, Gaurav Rudravaram, Adam M. Saunders, Bradley W. Richmond, Kim L. Sandler, Fabien Maldonado, Bennett A. Landman, Lianrui Zuo","Paired inspiratory-expiratory CT scans enable the quantification of gas
trapping due to small airway disease and emphysema by analyzing lung tissue
motion in COPD patients. Deformable image registration of these scans assesses
regional lung volumetric changes. However, variations in reconstruction kernels
between paired scans introduce errors in quantitative analysis. This work
proposes a two-stage pipeline to harmonize reconstruction kernels and perform
deformable image registration using data acquired from the COPDGene study. We
use a cycle generative adversarial network (GAN) to harmonize inspiratory scans
reconstructed with a hard kernel (BONE) to match expiratory scans reconstructed
with a soft kernel (STANDARD). We then deformably register the expiratory scans
to inspiratory scans. We validate harmonization by measuring emphysema using a
publicly available segmentation algorithm before and after harmonization.
Results show harmonization significantly reduces emphysema measurement
inconsistencies, decreasing median emphysema scores from 10.479% to 3.039%,
with a reference median score of 1.305% from the STANDARD kernel as the target.
Registration accuracy is evaluated via Dice overlap between emphysema regions
on inspiratory, expiratory, and deformed images. The Dice coefficient between
inspiratory emphysema masks and deformably registered emphysema masks increases
significantly across registration stages (p<0.001). Additionally, we
demonstrate that deformable registration is robust to kernel variations.",http://arxiv.org/abs/2502.05119v1
Latent Swap Joint Diffusion for Long-Form Audio Generation,2025-02-07T18:02:47Z,"Yusheng Dai, Chenxi Wang, Chang Li, Chen Wang, Jun Du, Kewei Li, Ruoyu Wang, Jiefeng Ma, Lei Sun, Jianqing Gao","Previous work on long-form audio generation using global-view diffusion or
iterative generation demands significant training or inference costs. While
recent advancements in multi-view joint diffusion for panoramic generation
provide an efficient option, they struggle with spectrum generation with severe
overlap distortions and high cross-view consistency costs. We initially explore
this phenomenon through the connectivity inheritance of latent maps and uncover
that averaging operations excessively smooth the high-frequency components of
the latent map. To address these issues, we propose Swap Forward (SaFa), a
frame-level latent swap framework that synchronizes multiple diffusions to
produce a globally coherent long audio with more spectrum details in a
forward-only manner. At its core, the bidirectional Self-Loop Latent Swap is
applied between adjacent views, leveraging stepwise diffusion trajectory to
adaptively enhance high-frequency components without disrupting low-frequency
components. Furthermore, to ensure cross-view consistency, the unidirectional
Reference-Guided Latent Swap is applied between the reference and the
non-overlap regions of each subview during the early stages, providing
centralized trajectory guidance. Quantitative and qualitative experiments
demonstrate that SaFa significantly outperforms existing joint diffusion
methods and even training-based long audio generation models. Moreover, we find
that it also adapts well to panoramic generation, achieving comparable
state-of-the-art performance with greater efficiency and model
generalizability. Project page is available at https://swapforward.github.io/.",http://arxiv.org/abs/2502.05130v1
"AuraFusion360: Augmented Unseen Region Alignment for Reference-based
  360° Unbounded Scene Inpainting",2025-02-07T18:59:55Z,"Chung-Ho Wu, Yang-Jung Chen, Ying-Huan Chen, Jie-Ying Lee, Bo-Hsu Ke, Chun-Wei Tuan Mu, Yi-Chuan Huang, Chin-Yang Lin, Min-Hung Chen, Yen-Yu Lin, Yu-Lun Liu","Three-dimensional scene inpainting is crucial for applications from virtual
reality to architectural visualization, yet existing methods struggle with view
consistency and geometric accuracy in 360{\deg} unbounded scenes. We present
AuraFusion360, a novel reference-based method that enables high-quality object
removal and hole filling in 3D scenes represented by Gaussian Splatting. Our
approach introduces (1) depth-aware unseen mask generation for accurate
occlusion identification, (2) Adaptive Guided Depth Diffusion, a zero-shot
method for accurate initial point placement without requiring additional
training, and (3) SDEdit-based detail enhancement for multi-view coherence. We
also introduce 360-USID, the first comprehensive dataset for 360{\deg}
unbounded scene inpainting with ground truth. Extensive experiments demonstrate
that AuraFusion360 significantly outperforms existing methods, achieving
superior perceptual quality while maintaining geometric accuracy across
dramatic viewpoint changes. See our project page for video results and the
dataset at https://kkennethwu.github.io/aurafusion360/.",http://arxiv.org/abs/2502.05176v1
"Accretion-disk reflection in the Seyfert 1 galaxy NGC 3783 as viewed by
  Chandra grating spectroscopy",2025-01-30T21:34:36Z,"A. Danehkar, W. N. Brandt","In active galactic nuclei, X-ray illumination of the accretion disk around a
supermassive black hole (SMBH) results in the production of the K$\alpha$
fluorescent line of iron, which provides insights into accretion physics and
SMBH spins. In this work, we studied X-ray reflection from the accretion disk
in the Seyfert 1 galaxy NGC 3783 using all the data collected by the Chandra
High Energy Transmission Grating Spectrometer. We used hardness-ratio diagrams
to distinguish between different spectral states and conducted spectral
analysis of all the multi-epoch datasets, as well as the source in the observed
spectral states. Our hardness analysis indicates that the source gradually
evolved into a harder state (2013-2016) compared to the previous epochs
(2000-2001). Our spectral modeling implies that the relativistically broadened
iron emission from the innermost accretion disk is associated with a
near-maximal SMBH spin ($a=0.98^{+0.02}_{-0.12}$) in all the datasets, even
though the hard state was present in 17% of them, and a consistent spin is also
found in different spectral states. In addition, the narrow, bright Fe
K$\alpha$ line from distant regions has an excess velocity of $620^{+80}_{-70}$
km s$^{-1}$ relative to the rest frame, implying that some distant layers of
the disk could be twisted. Our results suggest that, despite long-term changes
in the X-ray brightness of NGC 3783, likely caused by eclipsing material, the
relativistic reflection can be constrained thanks to the substantial counts
provided by multi-epoch observations, while a warped disk structure may be
present.",http://arxiv.org/abs/2502.05200v1
"Invariant Measures for Data-Driven Dynamical System Identification:
  Analysis and Application",2025-01-31T23:27:33Z,Jonah Botvinick-Greenhouse,"We propose a novel approach for performing dynamical system identification,
based upon the comparison of simulated and observed physical invariant
measures. While standard methods adopt a Lagrangian perspective by directly
treating time-trajectories as inference data, we take on an Eulerian
perspective and instead seek models fitting the observed global time-invariant
statistics. With this change in perspective, we gain robustness against
pervasive challenges in system identification including noise, chaos, and slow
sampling. In the first half of this paper, we pose the system identification
task as a partial differential equation (PDE) constrained optimization problem,
in which synthetic stationary solutions of the Fokker-Planck equation, obtained
as fixed points of a finite-volume discretization, are compared to physical
invariant measures extracted from observed trajectory data. In the latter half
of the paper, we improve upon this approach in two crucial directions. First,
we develop a Galerkin-inspired modification to the finite-volume surrogate
model, based on data-adaptive unstructured meshes and Monte-Carlo integration,
enabling the approach to efficiently scale to high-dimensional problems.
Second, we leverage Takens' seminal time-delay embedding theory to introduce a
critical data-dependent coordinate transformation which can guarantee unique
system identifiability from the invariant measure alone. This contribution
resolves a major challenge of system identification through invariant measures,
as systems exhibiting distinct transient behaviors may still share the same
time-invariant statistics in their state-coordinates. Throughout, we present
comprehensive numerical tests which highlight the effectiveness of our approach
on a variety of challenging system identification tasks.",http://arxiv.org/abs/2502.05204v1
Fast Subspace Fluid Simulation with Temporal-Aware Basis,2025-02-07T21:21:41Z,"Siyuan Chen, Yixin Chen, Otman Benchekroun, Jonathan Panuelos, Yue Chang, Eitan Grinspun, Zhecheng Wang","We present a novel reduced-order fluid simulation technique leveraging
Dynamic Mode Decomposition (DMD) to achieve fast, memory-efficient, and
user-controllable subspace simulation. We demonstrate that our approach
combines the strengths of both spatial reduced order models (ROMs) as well as
spectral decompositions. By optimizing for the operator that evolves a system
state from one timestep to the next, rather than the system state itself, we
gain both the compressive power of spatial ROMs as well as the intuitive
physical dynamics of spectral methods. The latter property is of particular
interest in graphics applications, where user control of fluid phenomena is of
high demand. We demonstrate this in various applications including spatial and
temporal modulation tools and fluid upscaling with added turbulence.
  We adapt DMD for graphics applications by reducing computational overhead,
incorporating user-defined force inputs, and optimizing memory usage with
randomized SVD. The integration of OptDMD and DMD with Control (DMDc)
facilitates noise-robust reconstruction and real-time user interaction. We
demonstrate the technique's robustness across diverse simulation scenarios,
including artistic editing, time-reversal, and super-resolution.
  Through experimental validation on challenging scenarios, such as colliding
vortex rings and boundary-interacting plumes, our method also exhibits superior
performance and fidelity with significantly fewer basis functions compared to
existing spatial ROMs. The inherent linearity of the DMD operator enables
unique application modes, such as time-reversible fluid simulation. This work
establishes another avenue for developing real-time, high-quality fluid
simulations, enriching the space of fluid simulation techniques in interactive
graphics and animation.",http://arxiv.org/abs/2502.05339v1
Contextual Scenario Generation for Two-Stage Stochastic Programming,2025-02-07T21:42:50Z,"David Islip, Roy H. Kwon, Sanghyeon Bae, Woo Chang Kim","Two-stage stochastic programs (2SPs) are important tools for making decisions
under uncertainty. Decision-makers use contextual information to generate a set
of scenarios to represent the true conditional distribution. However, the
number of scenarios required is a barrier to implementing 2SPs, motivating the
problem of generating a small set of surrogate scenarios that yield
high-quality decisions when they represent uncertainty. Current scenario
generation approaches do not leverage contextual information or do not address
computational concerns. In response, we propose contextual scenario generation
(CSG) to learn a mapping between the context and a set of surrogate scenarios
of user-specified size. First, we propose a distributional approach that learns
the mapping by minimizing a distributional distance between the predicted
surrogate scenarios and the true contextual distribution. Second, we propose a
task-based approach that aims to produce surrogate scenarios that yield
high-quality decisions. The task-based approach uses neural architectures to
approximate the downstream objective and leverages the approximation to search
for the mapping. The proposed approaches apply to various problem structures
and loosely only require efficient solving of the associated subproblems and
2SPs defined on the reduced scenario sets. Numerical experiments demonstrating
the effectiveness of the proposed methods are presented.",http://arxiv.org/abs/2502.05349v1
Characterization of Residual Charge Images in LSST Camera e2v CCDs,2025-02-08T02:58:09Z,"Daniel Polin, Adam Snyder, Craig Lage, J. Anthony Tyson","LSST Camera CCDs produced by the manufacturer e2v exhibit strong and novel
residual charge images when exposed to bright sources. These manifest in images
following bright exposures both in the same pixel areas as the bright source,
and in the pixels trailing between the source and the serial register. Both of
these pose systematic challenges to the Rubin Observatory Legacy Survey of
Space and Time instrument signature removal. The latter trail region is
especially impactful as it affects a much larger pixel area in a less well
defined position. In our study of this effect at UC Davis, we imaged bright
spots to characterize these residual charge effects. We find a strong
dependence of the residual charge on the parallel clocking scheme, including
the relative levels of the clocking voltages, and the timing of gate phase
transition during the parallel transfer. Our study points to independent causes
of residual charge in the bright spot region and trail region. We propose
potential causes in both regions and suggest methodologies for minimizing
residual charge. We consider the trade-offs to these methods including
decreasing the camera's full well and dynamic range at the high end. Some of
these results and suggestions have been reviewed by the camera commissioning
team and may result in changes made to the clocking voltage scheme on the LSST
Camera.",http://arxiv.org/abs/2502.05418v1
"SAMGPT: Text-free Graph Foundation Model for Multi-domain Pre-training
  and Cross-domain Adaptation",2025-02-08T03:24:25Z,"Xingtong Yu, Zechuan Gong, Chang Zhou, Yuan Fang, Hui Zhang","Graphs are able to model interconnected entities in many online services,
supporting a wide range of applications on the Web. This raises an important
question: How can we train a graph foundational model on multiple source
domains and adapt to an unseen target domain? A major obstacle is that graphs
from different domains often exhibit divergent characteristics. Some studies
leverage large language models to align multiple domains based on textual
descriptions associated with the graphs, limiting their applicability to
text-attributed graphs. For text-free graphs, a few recent works attempt to
align different feature distributions across domains, while generally
neglecting structural differences. In this work, we propose a novel Structure
Alignment framework for text-free Multi-domain Graph Pre-Training and
cross-domain adaptation (SAMGPT). It is designed to learn multi-domain
knowledge from graphs originating in multiple source domains, which can then be
adapted to address applications in an unseen target domain. Specifically, we
introduce a set of structure tokens to harmonize structure-based aggregation
across source domains during the pre-training phase. Next, for cross-domain
adaptation, we design dual prompts, namely, holistic prompts and specific
prompts, which adapt unified multi-domain structural knowledge and
fine-grained, domain-specific information, respectively, to a target domain.
Finally, we conduct comprehensive experiments on seven public datasets to
evaluate and analyze the effectiveness of SAMGPT.",http://arxiv.org/abs/2502.05424v1
Inversion of Magnetic Data using Learned Dictionaries and Scale Space,2025-02-08T05:04:51Z,"Shadab Ahamed, Simon Ghyselincks, Pablo Chang Huang Arias, Julian Kloiber, Yasin Ranjbar, Jingrong Tang, Niloufar Zakariaei, Eldad Haber","Magnetic data inversion is an important tool in geophysics, used to infer
subsurface magnetic susceptibility distributions from surface magnetic field
measurements. This inverse problem is inherently ill-posed, characterized by
non-unique solutions, depth ambiguity, and sensitivity to noise. Traditional
inversion approaches rely on predefined regularization techniques to stabilize
solutions, limiting their adaptability to complex or diverse geological
scenarios. In this study, we propose an approach that integrates variable
dictionary learning and scale-space methods to address these challenges. Our
method employs learned dictionaries, allowing for adaptive representation of
complex subsurface features that are difficult to capture with predefined
bases. Additionally, we extend classical variational inversion by incorporating
multi-scale representations through a scale-space framework, enabling the
progressive introduction of structural detail while mitigating overfitting. We
implement both fixed and dynamic dictionary learning techniques, with the
latter introducing iteration-dependent dictionaries for enhanced flexibility.
Using a synthetic dataset to simulate geological scenarios, we demonstrate
significant improvements in reconstruction accuracy and robustness compared to
conventional variational and dictionary-based methods. Our results highlight
the potential of learned dictionaries, especially when coupled with scale-space
dynamics, to improve model recovery and noise handling. These findings
underscore the promise of our data-driven approach for advance magnetic data
inversion and its applications in geophysical exploration, environmental
assessment, and mineral prospecting.",http://arxiv.org/abs/2502.05451v1
"Data-driven Low-rank Approximation for Electron-hole Kernel and
  Acceleration of Time-dependent GW Calculations",2025-02-08T16:41:09Z,"Bowen Hou, Jinyuan Wu, Victor Chang Lee, Jiaxuan Guo, Luna Y. Liu, Diana Y. Qiu","Many-body electron-hole interactions are essential for understanding
non-linear optical processes and ultrafast spectroscopy of materials. Recent
first principles approaches based on nonequilibrium Green's function
formalisms, such as the time-dependent adiabatic GW (TD-aGW) approach, can
predict the nonequilibrium dynamics of excited states including electron-hole
interactions. However, the high dimensionality of the electron-hole kernel
poses significant computational challenges for scalability. Here, we develop a
data-driven low-rank approximation for the electron-hole kernel, leveraging
localized excitonic effects in the Hilbert space of crystalline systems.
Through singular value decomposition (SVD) analysis, we show that the subspace
of non-zero singular values, containing the key information of the
electron-hole kernel, retains a small size even as the k-grid grows, ensuring
computational feasibility with extremely dense k-grids for converged
calculations. Utilizing this low-rank property, we achieve at least 95%
compression of the kernel and an order-of-magnitude speedup of TD-aGW
calculations. Our method, rooted in physical interpretability, outperforms
existing machine learning approaches by avoiding intensive training processes
and eliminating time-accumulated errors, providing a general framework for
high-throughput, nonequilibrium simulation of light-driven dynamics in
materials.",http://arxiv.org/abs/2502.05635v1
"Deciphering Carrier Dynamics in Polycarbonate Following Excitation with
  Ultrashort Laser Pulses",2025-02-08T16:50:35Z,"George D. Tsibidis, Matina Vlahou, Stella Maragkaki, Ioannis Konidakis, Emmanuel Stratakis","Polymers exposed to ultrashort pulsed lasers (UPL) experience a range of
physical and chemical changes that play a key role in applications ranging from
material processing to advanced photonics, and biomedicine. To elucidate the
interaction of UPL with polymeric materials, ultrafast phenomena such as
carrier dynamics, recombination and relaxation are investigated assuming
polycarbonate (PC) as a test material exposed to laser pulses of moderate
energies. A theoretical model developed for dielectric materials is extended to
describe the, previously, unexplored excitation and carrier dynamics for PC
while femtosecond Transient Absorption Spectroscopy is used to elucidate the
evolution of the materials response and ultrafast dynamics. Interpreting the
experimental measurements using the theoretical model suggests the existence of
an energy level that facilitates the formation of self-trapped exciton
metastates between the conduction and valence bands (approximately 2.4-2.8 eV
below the conduction band). It also predicts the electron-plasma lifetime
(around 110-150 fs), the recombination time (about 34 ps), and the non-linear
part of the refractive index due to Kerr effect (with n_2 values ranging from
(1.1-1.5)x10^{-16} cm2/W). Furthermore, the dominant character of multi-photon
assisted ionisation is emphasised while the optical breakdown threshold is also
calculated and found to be equal to 2.55 x10^12 W/cm2. The results are expected
to support future efforts aimed at elucidating how intense ultrashort laser
pulses interact with polymeric materials which is crucial for optimizing the
manufacturing processes of these materials for potential applications.",http://arxiv.org/abs/2502.05639v1
"MADAR: Efficient Continual Learning for Malware Analysis with
  Diversity-Aware Replay",2025-02-09T03:37:48Z,"Mohammad Saidur Rahman, Scott Coull, Qi Yu, Matthew Wright","Millions of new pieces of malicious software (i.e., malware) are introduced
each year. This poses significant challenges for antivirus vendors, who use
machine learning to detect and analyze malware, and must keep up with changes
in the distribution while retaining knowledge of older variants. Continual
learning (CL) holds the potential to address this challenge by reducing the
storage and computational costs of regularly retraining over all the collected
data. Prior work, however, shows that CL techniques, which are designed
primarily for computer vision tasks, fare poorly when applied to malware
classification. To address these issues, we begin with an exploratory analysis
of a typical malware dataset, which reveals that malware families are diverse
and difficult to characterize, requiring a wide variety of samples to learn a
robust representation. Based on these findings, we propose
$\underline{M}$alware $\underline{A}$nalysis with
$\underline{D}$iversity-$\underline{A}$ware $\underline{R}$eplay (MADAR), a CL
framework that accounts for the unique properties and challenges of the malware
data distribution. Through extensive evaluation on large-scale Windows and
Android malware datasets, we show that MADAR significantly outperforms prior
work. This highlights the importance of understanding domain characteristics
when designing CL techniques and demonstrates a path forward for the malware
classification domain.",http://arxiv.org/abs/2502.05760v1
"Coevolutionary dynamics of feedback-evolving games in structured
  populations",2025-02-09T03:52:02Z,"Qiushuang Wang, Xiaojie Chen, Attila Szolnoki","The interdependence between an individual strategy decision and the resulting
change of environmental state is often a subtle process. Feedback-evolving
games have been a prevalent framework for studying such feedback in well-mixed
populations, yielding important insights into the coevolutionary dynamics.
However, since real populations are usually structured, it is essential to
explore how population structure affects such coevolutionary dynamics. Our work
proposes a coevolution model of strategies and environmental state in a
structured population depicted by a regular graph. We investigate the system
dynamics, and theoretically demonstrate that there exist different evolutionary
outcomes including oscillation, bistability, the coexistence of oscillation and
dominance, as well as the coexistence of cooperation and defection. Our
theoretical predictions are validated through numerical calculations. By using
Monte Carlo simulations we examine how the number of neighbors influences the
coevolutionary dynamics, particularly the size of the attractive domain of the
replete environmental state in the cases of bistability or
cooperation-defection coexistence. Specifically, in the case of bistability, a
larger neighborhood size may be beneficial to save the environment when the
environmental enhancement rate by cooperation / degradation rate by defection
is high. Conversely, if this ratio is low, a smaller neighborhood size is more
beneficial. In the case of cooperator-defector coexistence, environmental
maintenance is basically influenced by individual payoffs. When the ratio of
temptation minus reward versus punishment minus sucker's payoff is high, a
larger neighborhood size is more favorable. In contrast, when the mentioned
ratio is low, a smaller neighborhood size is more advantageous.",http://arxiv.org/abs/2502.05764v1
"Fact-or-Fair: A Checklist for Behavioral Testing of AI Models on
  Fairness-Related Queries",2025-02-09T10:54:11Z,"Jen-tse Huang, Yuhang Yan, Linqi Liu, Yixin Wan, Wenxuan Wang, Kai-Wei Chang, Michael R. Lyu","The generation of incorrect images, such as depictions of people of color in
Nazi-era uniforms by Gemini, frustrated users and harmed Google's reputation,
motivating us to investigate the relationship between accurately reflecting
factuality and promoting diversity and equity. In this study, we focus on 19
real-world statistics collected from authoritative sources. Using these
statistics, we develop a checklist comprising objective and subjective queries
to analyze behavior of large language models (LLMs) and text-to-image (T2I)
models. Objective queries assess the models' ability to provide accurate world
knowledge. In contrast, the design of subjective queries follows a key
principle: statistical or experiential priors should not be overgeneralized to
individuals, ensuring that models uphold diversity. These subjective queries
are based on three common human cognitive errors that often result in social
biases. We propose metrics to assess factuality and fairness, and formally
prove the inherent trade-off between these two aspects. Results show that
GPT-4o and DALL-E 3 perform notably well among six LLMs and four T2I models.
Our code is publicly available at https://github.com/uclanlp/Fact-or-Fair.",http://arxiv.org/abs/2502.05849v1
"Energy-Efficient Autonomous Aerial Navigation with Dynamic Vision
  Sensors: A Physics-Guided Neuromorphic Approach",2025-02-09T15:40:18Z,"Sourav Sanyal, Amogh Joshi, Manish Nagaraj, Rohan Kumar Manna, Kaushik Roy","Vision-based object tracking is a critical component for achieving autonomous
aerial navigation, particularly for obstacle avoidance. Neuromorphic Dynamic
Vision Sensors (DVS) or event cameras, inspired by biological vision, offer a
promising alternative to conventional frame-based cameras. These cameras can
detect changes in intensity asynchronously, even in challenging lighting
conditions, with a high dynamic range and resistance to motion blur. Spiking
neural networks (SNNs) are increasingly used to process these event-based
signals efficiently and asynchronously. Meanwhile, physics-based artificial
intelligence (AI) provides a means to incorporate system-level knowledge into
neural networks via physical modeling. This enhances robustness, energy
efficiency, and provides symbolic explainability. In this work, we present a
neuromorphic navigation framework for autonomous drone navigation. The focus is
on detecting and navigating through moving gates while avoiding collisions. We
use event cameras for detecting moving objects through a shallow SNN
architecture in an unsupervised manner. This is combined with a lightweight
energy-aware physics-guided neural network (PgNN) trained with depth inputs to
predict optimal flight times, generating near-minimum energy paths. The system
is implemented in the Gazebo simulator and integrates a sensor-fused
vision-to-planning neuro-symbolic framework built with the Robot Operating
System (ROS) middleware. This work highlights the future potential of
integrating event-based vision with physics-guided planning for
energy-efficient autonomous navigation, particularly for low-latency
decision-making.",http://arxiv.org/abs/2502.05938v1
"SNAT-YOLO: Efficient Cross-Layer Aggregation Network for Edge-Oriented
  Gangue Detection",2025-02-09T18:39:35Z,Shang Li,"To address the issues of slow detection speed,low accuracy,difficulty in
deployment on industrial edge devices,and large parameter and computational
requirements in deep learning-based coal gangue target detection methods,we
propose a lightweight coal gangue target detection algorithm based on an
improved YOLOv11.First,we use the lightweight network ShuffleNetV2 as the
backbone to enhance detection speed.Second,we introduce a lightweight
downsampling operation,ADown,which reduces model complexity while improving
average detection accuracy.Third,we improve the C2PSA module in YOLOv11 by
incorporating the Triplet Attention mechanism,resulting in the proposed
C2PSA-TriAtt module,which enhances the model's ability to focus on different
dimensions of images.Fourth,we propose the Inner-FocalerIoU loss function to
replace the existing CIoU loss function.Experimental results show that our
model achieves a detection accuracy of 99.10% in coal gangue detection
tasks,reduces the model size by 38%,the number of parameters by 41%,and the
computational cost by 40%,while decreasing the average detection time per image
by 1 ms.The improved model demonstrates enhanced detection speed and
accuracy,making it suitable for deployment on industrial edge mobile
devices,thus contributing positively to coal processing and efficient
utilization of coal resources.",http://arxiv.org/abs/2502.05988v2
"A Comprehensive Energy Management Application Method considering Smart
  Home Occupant Behavior using IoT and Real Big Data",2025-02-09T22:17:54Z,"S. Saba Rafiei, Mahdi S. Naderi, Mehrdad Abedi","One of the most far-reaching use cases of the internet of things is in smart
grid and smart home operation. The smart home concept allows residents to
control, monitor, and manage their energy consumption with minimum loss and
self-involvement. Since each household's lifestyle and energy consumption is
unique, the management system needs background knowledge about residents'
energy consumption behavioral patterns for more accurate planning. To obtain
this information, data related to residents' consumption records must be
processed. This research has attempted to provide an optimal decentralized
management system consisting of interoperable sections to forecast, optimize,
schedule, and implement load management in a smart home. Comparing different
prediction models using 4 years of 1-min interval real data of a smart home
with photovoltaic generation (PV) and electric vehicle (EV), forecasting
non-controllable loads and taking a deterministic approach in different
scenarios, the system uses mixed integer linear programming (MILP) to provide
load scheduling with the objective of an optimal total energy cost reduction
with minimum changes in the household's desired consumption compared to the
initial state. The results have shown that the proposed system has reliable
performance due to the high precision of the forecast and has led to increased
energy efficiency, reduced energy cost (up to 62. 05\%), reduced
peak-to-average ratio (PAR) (up to 44. 19\%) and reduced standard deviation
(SD) (up to 19. 70\%) in net consumption.",http://arxiv.org/abs/2502.06052v1
"Graph Pseudotime Analysis and Neural Stochastic Differential Equations
  for Analyzing Retinal Degeneration Dynamics and Beyond",2025-02-10T03:25:14Z,"Dai Shi, Kuan Yan, Lequan Lin, Yue Zeng, Ting Zhang, Dmytro Matsypura, Mark C. Gillies, Ling Zhu, Junbin Gao","Understanding disease progression at the molecular pathway level usually
requires capturing both structural dependencies between pathways and the
temporal dynamics of disease evolution. In this work, we solve the former
challenge by developing a biologically informed graph-forming method to
efficiently construct pathway graphs for subjects from our newly curated JR5558
mouse transcriptomics dataset. We then develop Graph-level Pseudotime Analysis
(GPA) to infer graph-level trajectories that reveal how disease progresses at
the population level, rather than in individual subjects. Based on the
trajectories estimated by GPA, we identify the most sensitive pathways that
drive disease stage transitions. In addition, we measure changes in pathway
features using neural stochastic differential equations (SDEs), which enables
us to formally define and compute pathway stability and disease bifurcation
points (points of no return), two fundamental problems in disease progression
research. We further extend our theory to the case when pathways can interact
with each other, enabling a more comprehensive and multi-faceted
characterization of disease phenotypes. The comprehensive experimental results
demonstrate the effectiveness of our framework in reconstructing the dynamics
of the pathway, identifying critical transitions, and providing novel insights
into the mechanistic understanding of disease evolution.",http://arxiv.org/abs/2502.06126v1
Intelligent Reconfigurable Optical Wireless Ether,2025-02-10T03:35:14Z,"Hongwei Cui, Soung Chang Liew","Optical wireless communication (OWC) uses light for wireless data
transmission, potentially providing faster and more secure communication than
traditional radio-frequency-based techniques like Wi-Fi. However, light's high
directionality and its limited penetration ability restrict the signal
coverage. To address this limitation, we propose an artificial ""optical
wireless ether"" (OWE) fabric. OWE acts as a reconfigurable electromagnetic (EM)
wave-propagating medium, intelligently enhancing the strength of light signals
and redirecting their propagation to cover a broader area. Our proposed ether
fabric comprises simple optical signal amplification units, called ether
amplifiers (EAs), strategically placed in the environment, e.g., on ceilings.
The EAs amplify and propagate signals at the analog level and are agnostic to
the signal format: Signals propagate wirelessly between the EAs, losing
strength due to attenuation during transmission but regaining it as they pass
through the EAs. The key challenge in OWE design lies in the fact that, while
increasing EA gains can extend signal coverage, it can also create positive
feedback loops, resulting in self-interference and amplifier saturation, which
distort the signals -- the key challenge in OWE design. This paper presents a
systematic theoretical analysis to prevent amplifier saturation while
optimizing the performance of OWE in both single-basic-service-set (single-BSS)
and multiple-BSS scenarios. Optimization objectives could include
signal-to-noise ratio, resource allocation fairness, and mutual interference.
Furthermore, we conducted simulations and experiments to corroborate our
theories. To our knowledge, ours is the first experimental demonstration of the
feasibility of an artificial ether fabric for extending and guiding light
propagation, laying a solid groundwork for future development and exploration
of OWE.",http://arxiv.org/abs/2502.06128v1
"Gaussian Process-driven Hidden Markov Models for Early Diagnosis of
  Infant Gait Anomalies",2025-02-10T10:36:41Z,"Luis Torres-Torres F., Jonatan Arias-García, Hernán F. García, Andrés F. López-Lopera, Jesús F. Vargas-Bonilla","Gait analysis is critical in the early detection and intervention of motor
neurological disorders in infants. Despite its importance, traditional methods
often struggle to model the high variability and rapid developmental changes
inherent to infant gait. To address these challenges, we propose a
probabilistic Gaussian Process (GP)-driven Hidden Markov Model (HMM) to capture
the complex temporal dynamics of infant gait cycles and enable automatic
recognition of gait anomalies. We use a Multi-Output GP (MoGP) framework to
model interdependencies between multiple gait signals, with a composite kernel
designed to account for smooth, non-smooth, and periodic behaviors exhibited in
gait cycles. The HMM segments gait phases into normal and abnormal states,
facilitating the precise identification of pathological movement patterns in
stance and swing phases. The proposed model is trained and assessed using a
dataset of infants with and without motor neurological disorders via
leave-one-subject-out cross-validation. Results demonstrate that the MoGP
outperforms Long Short-Term Memory (LSTM) based neural networks in modeling
gait dynamics, offering improved accuracy, variance explanation, and temporal
alignment. Further, the predictive performance of MoGP provides a principled
framework for uncertainty quantification, allowing confidence estimation in
gait trajectory predictions. Additionally, the HMM enhances interpretability by
explicitly modeling gait phase transitions, improving the detection of subtle
anomalies across multiple gait cycles. These findings highlight the MoGP-HMM
framework as a robust automatic gait analysis tool, allowing early diagnosis
and intervention strategies for infants with neurological motor disorders.",http://arxiv.org/abs/2502.06334v1
"Engineering of electronic and magnetic modulations in gradient
  functional oxide heterostructures",2025-02-10T10:55:25Z,"Leonard Schüler, Yannik Sievert, Vladimir Roddatis, Ulrich Ross, Vasily Moshnyaga, Fryderyk Lyzwa","Advanced interface engineering provides a way to control the ground state of
correlated oxide heterostructures, which enables the shaping of future
electronic and magnetic nanodevices with enhanced performance. An especially
promising and rather new avenue is to find and explore low-dimensional phases
of structural, ferroic and superconducting origin. In this multimodal study, we
present a novel dynamic growth control method that enables synthesizing
compositionally graded superlattices (SLs) of (LaMnO_3)_10/(SrMnO_3)_10
(LMO/SMO), in which the layers gradually change their composition between LMO
and SMO with gradient G values ranging from 0 to 100 %. This leads to strong
modulations in the material's electronic properties and of the two-phase
ferromagnetic (FM) behavior. In particular, we observe that G has almost no
impact on the emergent high-temperature FM phase; in contrast, the
low-temperature volume-like FM phase increases drastically with higher
G-factors and thus can serve as a precise marker for chemical composition on a
nanoscale. Focusing on the interfacial charge transfer found at sharp SMO/LMO
interfaces (G=0), we observe that for higher G-factors a long-range charge
modulation develops, which is accompanied by an insulator-to-metal transition.
These findings showcase G as a crucial control parameter that can shape the
superlattice's intrinsic properties and provide a perspective for designing
functional oxide heterostructures with artificially disordered interfaces.",http://arxiv.org/abs/2502.06345v1
"Quadrupolar NMR Relaxation as a Local Probe of Collective Dynamics in
  Aqueous Alcaline and Alcaline-Earth Chlorides Solutions",2025-02-10T12:49:39Z,"Matthieu Wolf, Iurii Chubak, Benjamin Rotenberg","While nuclear magnetic resonance (NMR) provides valuable insights into the
local environment of many nuclei, the unambiguous interpretation of the signal
in terms of microscopic dynamics is often difficult, particularly when the
quadrupolar relaxation mechanism comes into play. Here, we investigate the
quadrupolar NMR relaxation of cations and anions in aqueous alcaline and
alcaline-earth chlorides solutions, across a broad range of salt
concentrations. Using a combination of DFT calculations and classical molecular
dynamics simulations, we compute the electric field gradient (EFG) fluctuations
over the relevant time scales. Predicted NMR relaxation rates are in good
agreement with experiments from the literature. As previously reported for
NaCl, we find that the increase in relaxation rate with salt concentration is
primarily driven by the slowing of EFG fluctuations, while changes in the
static variance of the EFG play a minor role. We highlight some specific
features for smaller and divalent cations compared to the other monovalent
ones. Additionally, we assess the relevance of the Stokes-Einstein-Debye model,
frequently used to analyze NMR relaxation experiments, for these aqueous
electrolytes, and highlight the link between the collective dynamics of the
liquid underlying the EFG fluctuations at the ion positions and the stress
fluctuations. Our results generalize observations for Na$^+$ in aqueous NaCl
solutions, showing that models assuming a viscous model of the solvent dynamics
are insufficient to describe EFG fluctuations in these systems and illustrate
the relevance of molecular simulations to interpret NMR relaxation experiments
in terms of microscopic dynamics.",http://arxiv.org/abs/2502.06409v1
"CS-SHAP: Extending SHAP to Cyclic-Spectral Domain for Better
  Interpretability of Intelligent Fault Diagnosis",2025-02-10T13:00:49Z,"Qian Chen, Xingjian Dong, Kui Hu, Kangkang Chen, Zhike Peng, Guang Meng","Neural networks (NNs), with their powerful nonlinear mapping and end-to-end
capabilities, are widely applied in mechanical intelligent fault diagnosis
(IFD). However, as typical black-box models, they pose challenges in
understanding their decision basis and logic, limiting their deployment in
high-reliability scenarios. Hence, various methods have been proposed to
enhance the interpretability of IFD. Among these, post-hoc approaches can
provide explanations without changing model architecture, preserving its
flexibility and scalability. However, existing post-hoc methods often suffer
from limitations in explanation forms. They either require preprocessing that
disrupts the end-to-end nature or overlook fault mechanisms, leading to
suboptimal explanations. To address these issues, we derived the
cyclic-spectral (CS) transform and proposed the CS-SHAP by extending Shapley
additive explanations (SHAP) to the CS domain. CS-SHAP can evaluate
contributions from both carrier and modulation frequencies, aligning more
closely with fault mechanisms and delivering clearer and more accurate
explanations. Three datasets are utilized to validate the superior
interpretability of CS-SHAP, ensuring its correctness, reproducibility, and
practical performance. With open-source code and outstanding interpretability,
CS-SHAP has the potential to be widely adopted and become the post-hoc
interpretability benchmark in IFD, even in other classification tasks. The code
is available on https://github.com/ChenQian0618/CS-SHAP.",http://arxiv.org/abs/2502.06424v1
"MATH-Perturb: Benchmarking LLMs' Math Reasoning Abilities against Hard
  Perturbations",2025-02-10T13:31:46Z,"Kaixuan Huang, Jiacheng Guo, Zihao Li, Xiang Ji, Jiawei Ge, Wenzhe Li, Yingqing Guo, Tianle Cai, Hui Yuan, Runzhe Wang, Yue Wu, Ming Yin, Shange Tang, Yangsibo Huang, Chi Jin, Xinyun Chen, Chiyuan Zhang, Mengdi Wang","Large language models have demonstrated impressive performance on challenging
mathematical reasoning tasks, which has triggered the discussion of whether the
performance is achieved by true reasoning capability or memorization. To
investigate this question, prior work has constructed mathematical benchmarks
when questions undergo simple perturbations -- modifications that still
preserve the underlying reasoning patterns of the solutions. However, no work
has explored hard perturbations, which fundamentally change the nature of the
problem so that the original solution steps do not apply. To bridge the gap, we
construct MATH-P-Simple and MATH-P-Hard via simple perturbation and hard
perturbation, respectively. Each consists of 279 perturbed math problems
derived from level-5 (hardest) problems in the MATH dataset (Hendrycksmath et.
al., 2021). We observe significant performance drops on MATH-P-Hard across
various models, including o1-mini (-16.49%) and gemini-2.0-flash-thinking
(-12.9%). We also raise concerns about a novel form of memorization where
models blindly apply learned problem-solving skills without assessing their
applicability to modified contexts. This issue is amplified when using original
problems for in-context learning. We call for research efforts to address this
challenge, which is critical for developing more robust and reliable reasoning
models.",http://arxiv.org/abs/2502.06453v2
Do Users' Explainability Needs in Software Change with Mood?,2025-02-10T15:12:41Z,"Martin Obaidi, Jakob Droste, Hannah Deters, Marc Herrmann, Jil Klünder, Kurt Schneider","Context and Motivation: The increasing complexity of modern software systems
often challenges users' abilities to interact with them. Taking established
quality attributes such as usability and transparency into account can mitigate
this problem, but often do not suffice to completely solve it. Recently,
explainability has emerged as essential non-functional requirement to help
overcome the aforementioned difficulties. Question/problem: User preferences
regarding the integration of explanations in software differ. Neither too few
nor too many explanations are helpful. In this paper, we investigate the
influence of a user's subjective mood and objective demographic aspects on
explanation needs by means of frequency and type of explanation. Principal
ideas/results: Our results reveal a limited relationship between these factors
and explanation needs. Two significant correlations were identified: Emotional
reactivity was positively correlated with the need for UI explanations, while a
negative correlation was found between age and user interface needs.
Contribution: As we only find very few significant aspects that influence the
need for explanations, we conclude that the need for explanations is very
subjective and does only partially depend on objective factors. These findings
emphasize the necessity for software companies to actively gather user-specific
explainability requirements to address diverse and context-dependent user
demands. Nevertheless, future research should explore additional personal
traits and cross-cultural factors to inform the development of adaptive,
user-centered explanation systems.",http://arxiv.org/abs/2502.06546v1
"Discovery of skill switching criteria for learning agile quadruped
  locomotion",2025-02-10T17:01:03Z,"Wanming Yu, Fernando Acero, Vassil Atanassov, Chuanyu Yang, Ioannis Havoutis, Dimitrios Kanoulas, Zhibin Li","This paper develops a hierarchical learning and optimization framework that
can learn and achieve well-coordinated multi-skill locomotion. The learned
multi-skill policy can switch between skills automatically and naturally in
tracking arbitrarily positioned goals and recover from failures promptly. The
proposed framework is composed of a deep reinforcement learning process and an
optimization process. First, the contact pattern is incorporated into the
reward terms for learning different types of gaits as separate policies without
the need for any other references. Then, a higher level policy is learned to
generate weights for individual policies to compose multi-skill locomotion in a
goal-tracking task setting. Skills are automatically and naturally switched
according to the distance to the goal. The proper distances for skill switching
are incorporated in reward calculation for learning the high level policy and
updated by an outer optimization loop as learning progresses. We first
demonstrated successful multi-skill locomotion in comprehensive tasks on a
simulated Unitree A1 quadruped robot. We also deployed the learned policy in
the real world showcasing trotting, bounding, galloping, and their natural
transitions as the goal position changes. Moreover, the learned policy can
react to unexpected failures at any time, perform prompt recovery, and resume
locomotion successfully. Compared to discrete switch between single skills
which failed to transition to galloping in the real world, our proposed
approach achieves all the learned agile skills, with smoother and more
continuous skill transitions.",http://arxiv.org/abs/2502.06676v1
"Study of the 2024 major Vela glitch at the Argentine Institute of
  Radioastronomy",2025-02-10T17:32:12Z,"Ezequiel Zubieta, Ryan Missel, Susana B. Araujo Furlan, Carlos O. Lousto, Federico García, Santiago del Palacio, Guillermo Gancio, Jorge A. Combi, Linwei Wang","We report here on new results of the systematic monitoring of southern
glitching pulsars at the Argentine Institute of Radioastronomy. In particular,
we study in this work the new major glitch in the Vela pulsar (PSR
J0835$-$4510) that occurred on 2024 April 29. We aim to thoroughly characterise
the rotational behaviour of the Vela pulsar around its last major glitch and
investigate the statistical properties of its individual pulses around the
glitch. We characterise the rotational behaviour of the pulsar around the
glitch through the pulsar timing technique. We measured the glitch parameters
by fitting timing residuals to the data collected during the days surrounding
the event. In addition, we study Vela individual pulses during the days of
observation just before and after the glitch. We selected nine days of
observations around the major glitch on 2024 April 29 and studied their
statistical properties with the Self-Organizing Maps (SOM) technique. We used
Variational AutoEncoder (VAE) reconstruction of the pulses to separate them
clearly from the noise. We obtain a precise timing solution for the glitch. We
find two recovery terms of $\sim 3~\mathrm{days}$ and $\sim 17~\mathrm{days}$.
We find a correlation of high amplitude with narrower pulses while not finding
notable qualitative systematic changes before and after the glitch.",http://arxiv.org/abs/2502.06704v1
"FinMamba: Market-Aware Graph Enhanced Multi-Level Mamba for Stock
  Movement Prediction",2025-02-10T17:37:26Z,"Yifan Hu, Peiyuan Liu, Yuante Li, Dawei Cheng, Naiqi Li, Tao Dai, Jigang Bao, Shu-Tao Xia","Recently, combining stock features with inter-stock correlations has become a
common and effective approach for stock movement prediction. However, financial
data presents significant challenges due to its low signal-to-noise ratio and
the dynamic complexity of the market, which give rise to two key limitations in
existing methods. First, the relationships between stocks are highly influenced
by multifaceted factors including macroeconomic market dynamics, and current
models fail to adaptively capture these evolving interactions under specific
market conditions. Second, for the accuracy and timeliness required by
real-world trading, existing financial data mining methods struggle to extract
beneficial pattern-oriented dependencies from long historical data while
maintaining high efficiency and low memory consumption. To address the
limitations, we propose FinMamba, a Mamba-GNN-based framework for market-aware
and multi-level hybrid stock movement prediction. Specifically, we devise a
dynamic graph to learn the changing representations of inter-stock
relationships by integrating a pruning module that adapts to market trends.
Afterward, with a selective mechanism, the multi-level Mamba discards
irrelevant information and resets states to skillfully recall historical
patterns across multiple time scales with linear time costs, which are then
jointly optimized for reliable prediction. Extensive experiments on U.S. and
Chinese stock markets demonstrate the effectiveness of our proposed FinMamba,
achieving state-of-the-art prediction accuracy and trading profitability, while
maintaining low computational complexity. The code is available at
https://github.com/TROUBADOUR000/FinMamba.",http://arxiv.org/abs/2502.06707v1
"Spatial Pattern Formation in Eco-Evolutionary Games with
  Environment-Driven Motion",2025-02-10T17:53:39Z,"Tianyong Yao, Daniel B. Cooney","The sustainable management of common resources often leads to a social
dilemma known as the tragedy of the commons: individuals benefit from rapid
extraction of resources, while communities as a whole benefit from more
sustainable extraction strategies. Such a social dilemma can be further
complicated by the role played by space for both resources and harvesters,
where spatial diffusion of resources and directed motion of harvesters can
potentially feature the emergence of clusters of environmental resource and
sustainable harvesting strategies. In this paper, we explore a PDE model of
evolutionary game theory with environmental feedback, describing how the
spatial distribution of resource extraction strategies and environmental
resources can change due to both local eco-evolutionary dynamics and
environmental-driven directed motion of harvesters. Through linear stability
analysis, we show that this biased motion towards higher-quality environments
can lead to spatial patterns in the distribution of extraction strategies,
creating local regions with improved environmental quality and increase payoff
for resource extractors. However, by measuring the average payoff and
environmental quality across the spatial domain, we see that this
pattern-forming mechanism can actually decrease the overall success of the
population relative to the equilibrium outcome in the absence of spatial
motion. This suggests that environmental-driven motion can produce a spatial
social dilemma, in which biased motion towards more beneficial regions can
produce emergent patterns featuring a worse overall environment for the
population.",http://arxiv.org/abs/2502.06723v1
"Neural Network-based Vehicular Channel Estimation Performance: Effect of
  Noise in the Training Set",2025-02-05T09:29:01Z,"Simbarashe Aldrin Ngorima, Albert Helberg, Marelie H. Davel","Vehicular communication systems face significant challenges due to high
mobility and rapidly changing environments, which affect the channel over which
the signals travel. To address these challenges, neural network (NN)-based
channel estimation methods have been suggested. These methods are primarily
trained on high signal-to-noise ratio (SNR) with the assumption that training a
NN in less noisy conditions can result in good generalisation. This study
examines the effectiveness of training NN-based channel estimators on mixed SNR
datasets compared to training solely on high SNR datasets, as seen in several
related works. Estimators evaluated in this work include an architecture that
uses convolutional layers and self-attention mechanisms; a method that employs
temporal convolutional networks and data pilot-aided estimation; two methods
that combine classical methods with multilayer perceptrons; and the current
state-of-the-art model that combines Long-Short-Term Memory networks with data
pilot-aided and temporal averaging methods as post processing. Our results
indicate that using only high SNR data for training is not always optimal, and
the SNR range in the training dataset should be treated as a hyperparameter
that can be adjusted for better performance. This is illustrated by the better
performance of some models in low SNR conditions when trained on the mixed SNR
dataset, as opposed to when trained exclusively on high SNR data.",http://arxiv.org/abs/2502.06824v1
"RLOMM: An Efficient and Robust Online Map Matching Framework with
  Reinforcement Learning",2025-02-05T11:26:32Z,"Minxiao Chen, Haitao Yuan, Nan Jiang, Zhihan Zheng, Sai Wu, Ao Zhou, Shangguang Wang","Online map matching is a fundamental problem in location-based services,
aiming to incrementally match trajectory data step-by-step onto a road network.
However, existing methods fail to meet the needs for efficiency, robustness,
and accuracy required by large-scale online applications, making this task
still a challenging problem. This paper introduces a novel framework that
achieves high accuracy and efficient matching while ensuring robustness in
handling diverse scenarios. To improve efficiency, we begin by modeling the
online map matching problem as an Online Markov Decision Process (OMDP) based
on its inherent characteristics. This approach helps efficiently merge
historical and real-time data, reducing unnecessary calculations. Next, to
enhance the model's robustness, we design a reinforcement learning method,
enabling robust handling of real-time data from dynamically changing
environments. In particular, we propose a novel model learning process and a
comprehensive reward function, allowing the model to make reasonable current
matches from a future-oriented perspective, and to continuously update and
optimize during the decision-making process based on feedback. Lastly, to
address the heterogeneity between trajectories and roads, we design distinct
graph structures, facilitating efficient representation learning through graph
and recurrent neural networks. To further align trajectory and road data, we
introduce contrastive learning to decrease their distance in the latent space,
thereby promoting effective integration of the two. Extensive evaluations on
three real-world datasets confirm that our method significantly outperforms
existing state-of-the-art solutions in terms of accuracy, efficiency and
robustness.",http://arxiv.org/abs/2502.06825v1
"A Deep Learning Framework Integrating CNN and BiLSTM for Financial
  Systemic Risk Analysis and Prediction",2025-02-07T07:57:11Z,"Yu Cheng, Zhen Xu, Yuan Chen, Yuhan Wang, Zhenghao Lin, Jinsong Liu","This study proposes a deep learning model based on the combination of
convolutional neural network (CNN) and bidirectional long short-term memory
network (BiLSTM) for discriminant analysis of financial systemic risk. The
model first uses CNN to extract local patterns of multidimensional features of
financial markets, and then models the bidirectional dependency of time series
through BiLSTM, to comprehensively characterize the changing laws of systemic
risk in spatial features and temporal dynamics. The experiment is based on real
financial data sets. The results show that the model is significantly superior
to traditional single models (such as BiLSTM, CNN, Transformer, and TCN) in
terms of accuracy, recall, and F1 score. The F1-score reaches 0.88, showing
extremely high discriminant ability. This shows that the joint strategy of
combining CNN and BiLSTM can not only fully capture the complex patterns of
market data but also effectively deal with the long-term dependency problem in
time series data. In addition, this study also explores the robustness of the
model in dealing with data noise and processing high-dimensional data,
providing strong support for intelligent financial risk management. In the
future, the research will further optimize the model structure, introduce
methods such as reinforcement learning and multimodal data analysis, and
improve the efficiency and generalization ability of the model to cope with a
more complex financial environment.",http://arxiv.org/abs/2502.06847v1
"EAP-GP: Mitigating Saturation Effect in Gradient-based Automated Circuit
  Identification",2025-02-07T16:04:57Z,"Lin Zhang, Wenshuo Dong, Zhuoran Zhang, Shu Yang, Lijie Hu, Ninghao Liu, Pan Zhou, Di Wang","Understanding the internal mechanisms of transformer-based language models
remains challenging. Mechanistic interpretability based on circuit discovery
aims to reverse engineer neural networks by analyzing their internal processes
at the level of computational subgraphs. In this paper, we revisit existing
gradient-based circuit identification methods and find that their performance
is either affected by the zero-gradient problem or saturation effects, where
edge attribution scores become insensitive to input changes, resulting in noisy
and unreliable attribution evaluations for circuit components. To address the
saturation effect, we propose Edge Attribution Patching with GradPath (EAP-GP),
EAP-GP introduces an integration path, starting from the input and adaptively
following the direction of the difference between the gradients of corrupted
and clean inputs to avoid the saturated region. This approach enhances
attribution reliability and improves the faithfulness of circuit
identification. We evaluate EAP-GP on 6 datasets using GPT-2 Small, GPT-2
Medium, and GPT-2 XL. Experimental results demonstrate that EAP-GP outperforms
existing methods in circuit faithfulness, achieving improvements up to 17.7%.
Comparisons with manually annotated ground-truth circuits demonstrate that
EAP-GP achieves precision and recall comparable to or better than previous
approaches, highlighting its effectiveness in identifying accurate circuits.",http://arxiv.org/abs/2502.06852v1
"Global Ease of Living Index: a machine learning framework for
  longitudinal analysis of major economies",2025-02-08T02:37:17Z,"Tanay Panat, Rohitash Chandra","The drastic changes in the global economy, geopolitical conditions, and
disruptions such as the COVID-19 pandemic have impacted the cost of living and
quality of life. It is important to understand the long-term nature of the cost
of living and quality of life in major economies. A transparent and
comprehensive living index must include multiple dimensions of living
conditions. In this study, we present an approach to quantifying the quality of
life through the Global Ease of Living Index that combines various
socio-economic and infrastructural factors into a single composite score. Our
index utilises economic indicators that define living standards, which could
help in targeted interventions to improve specific areas. We present a machine
learning framework for addressing the problem of missing data for some of the
economic indicators for specific countries. We then curate and update the data
and use a dimensionality reduction approach (principal component analysis) to
create the Ease of Living Index for major economies since 1970. Our work
significantly adds to the literature by offering a practical tool for
policymakers to identify areas needing improvement, such as healthcare systems,
employment opportunities, and public safety. Our approach with open data and
code can be easily reproduced and applied to various contexts. This
transparency and accessibility make our work a valuable resource for ongoing
research and policy development in quality-of-life assessment.",http://arxiv.org/abs/2502.06866v2
"AI-Driven HSI: Multimodality, Fusion, Challenges, and the Deep Learning
  Revolution",2025-02-09T12:44:16Z,"David S. Bhatti, Yougin Choi, Rahman S M Wahidur, Maleeka Bakhtawar, Sumin Kim, Surin Lee, Yongtae Lee, Heung-No Lee","Hyperspectral imaging (HSI) captures spatial and spectral data, enabling
analysis of features invisible to conventional systems. The technology is vital
in fields such as weather monitoring, food quality control, counterfeit
detection, healthcare diagnostics, and extending into defense, agriculture, and
industrial automation at the same time. HSI has advanced with improvements in
spectral resolution, miniaturization, and computational methods. This study
provides an overview of the HSI, its applications, challenges in data fusion
and the role of deep learning models in processing HSI data. We discuss how
integration of multimodal HSI with AI, particularly with deep learning,
improves classification accuracy and operational efficiency. Deep learning
enhances HSI analysis in areas like feature extraction, change detection,
denoising unmixing, dimensionality reduction, landcover mapping, data
augmentation, spectral construction and super resolution. An emerging focus is
the fusion of hyperspectral cameras with large language models (LLMs), referred
as highbrain LLMs, enabling the development of advanced applications such as
low visibility crash detection and face antispoofing. We also highlight key
players in HSI industry, its compound annual growth rate and the growing
industrial significance. The purpose is to offer insight to both technical and
non-technical audience, covering HSI's images, trends, and future directions,
while providing valuable information on HSI datasets and software libraries.",http://arxiv.org/abs/2502.06894v1
"A Simple yet Effective DDG Predictor is An Unsupervised Antibody
  Optimizer and Explainer",2025-02-10T09:26:57Z,"Lirong Wu, Yunfan Liu, Haitao Lin, Yufei Huang, Guojiang Zhao, Zhifeng Gao, Stan Z. Li","The proteins that exist today have been optimized over billions of years of
natural evolution, during which nature creates random mutations and selects
them. The discovery of functionally promising mutations is challenged by the
limited evolutionary accessible regions, i.e., only a small region on the
fitness landscape is beneficial. There have been numerous priors used to
constrain protein evolution to regions of landscapes with high-fitness
variants, among which the change in binding free energy (DDG) of protein
complexes upon mutations is one of the most commonly used priors. However, the
huge mutation space poses two challenges: (1) how to improve the efficiency of
DDG prediction for fast mutation screening; and (2) how to explain mutation
preferences and efficiently explore accessible evolutionary regions. To address
these challenges, we propose a lightweight DDG predictor (Light-DDG), which
adopts a structure-aware Transformer as the backbone and enhances it by
knowledge distilled from existing powerful but computationally heavy DDG
predictors. Additionally, we augmented, annotated, and released a large-scale
dataset containing millions of mutation data for pre-training Light-DDG. We
find that such a simple yet effective Light-DDG can serve as a good
unsupervised antibody optimizer and explainer. For the target antibody, we
propose a novel Mutation Explainer to learn mutation preferences, which
accounts for the marginal benefit of each mutation per residue. To further
explore accessible evolutionary regions, we conduct preference-guided antibody
optimization and evaluate antibody candidates quickly using Light-DDG to
identify desirable mutations.",http://arxiv.org/abs/2502.06913v2
"Unconstrained Body Recognition at Altitude and Range: Comparing Four
  Approaches",2025-02-10T23:49:06Z,"Blake A Myers, Matthew Q Hill, Veda Nandan Gandi, Thomas M Metz, Alice J O'Toole","This study presents an investigation of four distinct approaches to long-term
person identification using body shape. Unlike short-term re-identification
systems that rely on temporary features (e.g., clothing), we focus on learning
persistent body shape characteristics that remain stable over time. We
introduce a body identification model based on a Vision Transformer (ViT) (Body
Identification from Diverse Datasets, BIDDS) and on a Swin-ViT model
(Swin-BIDDS). We also expand on previous approaches based on the Linguistic and
Non-linguistic Core ResNet Identity Models (LCRIM and NLCRIM), but with
improved training. All models are trained on a large and diverse dataset of
over 1.9 million images of approximately 5k identities across 9 databases.
Performance was evaluated on standard re-identification benchmark datasets
(MARS, MSMT17, Outdoor Gait, DeepChange) and on an unconstrained dataset that
includes images at a distance (from close-range to 1000m), at altitude (from an
unmanned aerial vehicle, UAV), and with clothing change. A comparative analysis
across these models provides insights into how different backbone architectures
and input image sizes impact long-term body identification performance across
real-world conditions.",http://arxiv.org/abs/2502.07130v1
"Refine Knowledge of Large Language Models via Adaptive Contrastive
  Learning",2025-02-11T02:19:13Z,"Yinghui Li, Haojing Huang, Jiayi Kuang, Yangning Li, Shu-Yu Guo, Chao Qu, Xiaoyu Tan, Hai-Tao Zheng, Ying Shen, Philip S. Yu","How to alleviate the hallucinations of Large Language Models (LLMs) has
always been the fundamental goal pursued by the LLMs research community.
Looking through numerous hallucination-related studies, a mainstream category
of methods is to reduce hallucinations by optimizing the knowledge
representation of LLMs to change their output. Considering that the core focus
of these works is the knowledge acquired by models, and knowledge has long been
a central theme in human societal progress, we believe that the process of
models refining knowledge can greatly benefit from the way humans learn. In our
work, by imitating the human learning process, we design an Adaptive
Contrastive Learning strategy. Our method flexibly constructs different
positive and negative samples for contrastive learning based on LLMs' actual
mastery of knowledge. This strategy helps LLMs consolidate the correct
knowledge they already possess, deepen their understanding of the correct
knowledge they have encountered but not fully grasped, forget the incorrect
knowledge they previously learned, and honestly acknowledge the knowledge they
lack. Extensive experiments and detailed analyses on widely used datasets
demonstrate the effectiveness of our method.",http://arxiv.org/abs/2502.07184v1
"Improve the Training Efficiency of DRL for Wireless Communication
  Resource Allocation: The Role of Generative Diffusion Models",2025-02-11T03:09:45Z,"Xinren Zhang, Jiadong Yu","Dynamic resource allocation in mobile wireless networks involves complex,
time-varying optimization problems, motivating the adoption of deep
reinforcement learning (DRL). However, most existing works rely on pre-trained
policies, overlooking dynamic environmental changes that rapidly invalidate the
policies. Periodic retraining becomes inevitable but incurs prohibitive
computational costs and energy consumption-critical concerns for
resource-constrained wireless systems. We identify three root causes of
inefficient retraining: high-dimensional state spaces, suboptimal action spaces
exploration-exploitation trade-offs, and reward design limitations. To overcome
these limitations, we propose Diffusion-based Deep Reinforcement Learning
(D2RL), which leverages generative diffusion models (GDMs) to holistically
enhance all three DRL components. Iterative refinement process and distribution
modelling of GDMs enable (1) the generation of diverse state samples to improve
environmental understanding, (2) balanced action space exploration to escape
local optima, and (3) the design of discriminative reward functions that better
evaluate action quality. Our framework operates in two modes: Mode I leverages
GDMs to explore reward spaces and design discriminative reward functions that
rigorously evaluate action quality, while Mode II synthesizes diverse state
samples to enhance environmental understanding and generalization. Extensive
experiments demonstrate that D2RL achieves faster convergence and reduced
computational costs over conventional DRL methods for resource allocation in
wireless communications while maintaining competitive policy performance. This
work underscores the transformative potential of GDMs in overcoming fundamental
DRL training bottlenecks for wireless networks, paving the way for practical,
real-time deployments.",http://arxiv.org/abs/2502.07211v1
"Generation of Drug-Induced Cardiac Reactions towards Virtual Clinical
  Trials",2025-02-11T06:50:33Z,"Qian Shao, Bang Du, Zepeng Li, Qiyuan Chen, Hongxia Xu, Jimeng Sun, Jian Wu, Jintai Chen","Clinical trials are pivotal in cardiac drug development, yet they often fail
due to inadequate efficacy and unexpected safety issues, leading to significant
financial losses. Using in-silico trials to replace a part of physical clinical
trials, e.g., leveraging advanced generative models to generate drug-influenced
electrocardiograms (ECGs), seems an effective method to reduce financial risk
and potential harm to trial participants. While existing generative models have
demonstrated progress in ECG generation, they fall short in modeling drug
reactions due to limited fidelity and inability to capture individualized drug
response patterns. In this paper, we propose a Drug-Aware Diffusion Model
(DADM), which could simulate individualized drug reactions while ensuring
fidelity. To ensure fidelity, we construct a set of ordinary differential
equations to provide external physical knowledge (EPK) of the realistic ECG
morphology. The EPK is used to adaptively constrain the morphology of the
generated ECGs through a dynamic cross-attention (DCA) mechanism. Furthermore,
we propose an extension of ControlNet to incorporate demographic and drug data,
simulating individual drug reactions. We compare DADM with the other eight
state-of-the-art ECG generative models on two real-world databases covering 8
types of drug regimens. The results demonstrate that DADM can more accurately
simulate drug-induced changes in ECGs, improving the accuracy by at least 5.79%
and recall by 8%.",http://arxiv.org/abs/2502.07297v1
Life-Code: Central Dogma Modeling with Multi-Omics Sequence Unification,2025-02-11T06:53:59Z,"Zicheng Liu, Siyuan Li, Zhiyuan Chen, Lei Xin, Fang Wu, Chang Yu, Qirong Yang, Yucheng Guo, Yujie Yang, Stan Z. Li","The interactions between DNA, RNA, and proteins are fundamental to biological
processes, as illustrated by the central dogma of molecular biology. While
modern biological pre-trained models have achieved great success in analyzing
these macromolecules individually, their interconnected nature remains
under-explored. In this paper, we follow the guidance of the central dogma to
redesign both the data and model pipeline and offer a comprehensive framework,
Life-Code, that spans different biological functions. As for data flow, we
propose a unified pipeline to integrate multi-omics data by
reverse-transcribing RNA and reverse-translating amino acids into
nucleotide-based sequences. As for the model, we design a codon tokenizer and a
hybrid long-sequence architecture to encode the interactions of both coding and
non-coding regions with masked modeling pre-training. To model the translation
and folding process with coding sequences, Life-Code learns protein structures
of the corresponding amino acids by knowledge distillation from off-the-shelf
protein language models. Such designs enable Life-Code to capture complex
interactions within genetic sequences, providing a more comprehensive
understanding of multi-omics with the central dogma. Extensive Experiments show
that Life-Code achieves state-of-the-art performance on various tasks across
three omics, highlighting its potential for advancing multi-omics analysis and
interpretation.",http://arxiv.org/abs/2502.07299v1
EvoFlow: Evolving Diverse Agentic Workflows On The Fly,2025-02-11T08:48:46Z,"Guibin Zhang, Kaijie Chen, Guancheng Wan, Heng Chang, Hong Cheng, Kun Wang, Shuyue Hu, Lei Bai","The past two years have witnessed the evolution of large language model
(LLM)-based multi-agent systems from labor-intensive manual design to partial
automation (\textit{e.g.}, prompt engineering, communication topology) and
eventually to fully automated design. However, existing agentic automation
pipelines often lack LLM heterogeneity and focus on single-objective
performance optimization, limiting their potential to combine weaker models for
more customized and cost-effective solutions. To address this challenge, we
propose EvoFlow, a niching evolutionary algorithm-based framework to
automatically search a population of heterogeneous and complexity-adaptive
agentic workflows, rather than a single homogeneous, complex workflow.
Technically, EvoFlow performs \textit{(1) tag-based retrieval} to extract
parent workflows from an agentic population, evolves new workflows through
\textit{(2) crossover} and \textit{(3) mutation}, and employs \textit{(4)
niching-based selection} to maintain population diversity and quality.
Extensive evaluations across seven benchmarks demonstrate that EvoFlow is:
\textbf{(I) diverse}, evolving a population of workflows ranging from simple
I/O tasks to complex multi-turn interactions; \textbf{(II) high-performing},
outperforming previous handcrafted and automated workflows by
$1.23\%\sim29.86\%$; \textbf{(III) economical}, surpassing powerful
\llmname{o1-preview} at $12.4\%$ of its inference cost using weaker open-source
models.",http://arxiv.org/abs/2502.07373v1
Exploring Patterns Behind Sports,2025-02-11T11:51:07Z,"Chang Liu, Chengcheng Ma, XuanQi Zhou","This paper presents a comprehensive framework for time series prediction
using a hybrid model that combines ARIMA and LSTM. The model incorporates
feature engineering techniques, including embedding and PCA, to transform raw
data into a lower-dimensional representation while retaining key information.
The embedding technique is used to convert categorical data into continuous
vectors, facilitating the capture of complex relationships. PCA is applied to
reduce dimensionality and extract principal components, enhancing model
performance and computational efficiency. To handle both linear and nonlinear
patterns in the data, the ARIMA model captures linear trends, while the LSTM
model models complex nonlinear dependencies. The hybrid model is trained on
historical data and achieves high accuracy, as demonstrated by low RMSE and MAE
scores. Additionally, the paper employs the run test to assess the randomness
of sequences, providing insights into the underlying patterns. Ablation studies
are conducted to validate the roles of different components in the model,
demonstrating the significance of each module. The paper also utilizes the SHAP
method to quantify the impact of traditional advantages on the predicted
results, offering a detailed understanding of feature importance. The KNN
method is used to determine the optimal prediction interval, further enhancing
the model's accuracy. The results highlight the effectiveness of combining
traditional statistical methods with modern deep learning techniques for robust
time series forecasting in Sports.",http://arxiv.org/abs/2502.07491v1
SEMU: Singular Value Decomposition for Efficient Machine Unlearning,2025-02-11T14:36:39Z,"Marcin Sendera, Łukasz Struski, Kamil Książek, Kryspin Musiol, Jacek Tabor, Dawid Rymarczyk","While the capabilities of generative foundational models have advanced
rapidly in recent years, methods to prevent harmful and unsafe behaviors remain
underdeveloped. Among the pressing challenges in AI safety, machine unlearning
(MU) has become increasingly critical to meet upcoming safety regulations. Most
existing MU approaches focus on altering the most significant parameters of the
model. However, these methods often require fine-tuning substantial portions of
the model, resulting in high computational costs and training instabilities,
which are typically mitigated by access to the original training dataset.
  In this work, we address these limitations by leveraging Singular Value
Decomposition (SVD) to create a compact, low-dimensional projection that
enables the selective forgetting of specific data points. We propose Singular
Value Decomposition for Efficient Machine Unlearning (SEMU), a novel approach
designed to optimize MU in two key aspects. First, SEMU minimizes the number of
model parameters that need to be modified, effectively removing unwanted
knowledge while making only minimal changes to the model's weights. Second,
SEMU eliminates the dependency on the original training dataset, preserving the
model's previously acquired knowledge without additional data requirements.
  Extensive experiments demonstrate that SEMU achieves competitive performance
while significantly improving efficiency in terms of both data usage and the
number of modified parameters.",http://arxiv.org/abs/2502.07587v1
"PRVQL: Progressive Knowledge-guided Refinement for Robust Egocentric
  Visual Query Localization",2025-02-11T17:04:31Z,"Bing Fan, Yunhe Feng, Yapeng Tian, Yuewei Lin, Yan Huang, Heng Fan","Egocentric visual query localization (EgoVQL) focuses on localizing the
target of interest in space and time from first-person videos, given a visual
query. Despite recent progressive, existing methods often struggle to handle
severe object appearance changes and cluttering background in the video due to
lacking sufficient target cues, leading to degradation. Addressing this, we
introduce PRVQL, a novel Progressive knowledge-guided Refinement framework for
EgoVQL. The core is to continuously exploit target-relevant knowledge directly
from videos and utilize it as guidance to refine both query and video features
for improving target localization. Our PRVQL contains multiple processing
stages. The target knowledge from one stage, comprising appearance and spatial
knowledge extracted via two specially designed knowledge learning modules, are
utilized as guidance to refine the query and videos features for the next
stage, which are used to generate more accurate knowledge for further feature
refinement. With such a progressive process, target knowledge in PRVQL can be
gradually improved, which, in turn, leads to better refined query and video
features for localization in the final stage. Compared to previous methods, our
PRVQL, besides the given object cues, enjoys additional crucial target
information from a video as guidance to refine features, and hence enhances
EgoVQL in complicated scenes. In our experiments on challenging Ego4D, PRVQL
achieves state-of-the-art result and largely surpasses other methods, showing
its efficacy. Our code, model and results will be released at
https://github.com/fb-reps/PRVQL.",http://arxiv.org/abs/2502.07707v1
"Analysis of energy, CO2 emissions and economy of the technological
  migration for clean cooking in Ecuador",2025-01-20T12:51:17Z,"J. Martinez, Jaime Marti-Herrero, S. Villacis, A. J. Riofrio, D. Vaca","The objective of this study is to analyze the CO2 emissions and economic
impacts of the implementation of the National Efficient Cooking Program (NECP)
in Ecuador, which aims to migrate the population from Liquefied Petroleum Gas
(LPG)-based stoves to electric induction stoves. This program is rooted in the
current effort to change Ecuador's energy balance, with hydroelectric power
expected to generate 83.61% of national electricity by 2022, ending the need
for subsidized LPG. For this analysis, the 2014 baseline situation has been
compared with two future scenarios for 2022: a business-as-usual scenario and
an NECP-success scenario. This study demonstrates the viability of migration
from imported fossil fuels to locally-produced renewable energy as the basis
for an efficient cooking facility. The new policies scenario would save US$
1.162 billion in annual government expenditure on cooking subsidies, and
reducing CO2 emissions associated to energy for cooking in 1.8 tCO2/y.",http://arxiv.org/abs/2502.07788v1
"Regulatory Science Innovation for Generative AI and Large Language
  Models in Health and Medicine: A Global Call for Action",2025-01-27T06:21:13Z,"Jasmine Chiat Ling Ong, Yilin Ning, Mingxuan Liu, Yian Ma, Zhao Liang, Kuldev Singh, Robert T Chang, Silke Vogel, John CW Lim, Iris Siu Kwan Tan, Oscar Freyer, Stephen Gilbert, Danielle S Bitterman, Xiaoxuan Liu, Alastair K Denniston, Nan Liu","The integration of generative AI (GenAI) and large language models (LLMs) in
healthcare presents both unprecedented opportunities and challenges,
necessitating innovative regulatory approaches. GenAI and LLMs offer broad
applications, from automating clinical workflows to personalizing diagnostics.
However, the non-deterministic outputs, broad functionalities and complex
integration of GenAI and LLMs challenge existing medical device regulatory
frameworks, including the total product life cycle (TPLC) approach. Here we
discuss the constraints of the TPLC approach to GenAI and LLM-based medical
device regulation, and advocate for global collaboration in regulatory science
research. This serves as the foundation for developing innovative approaches
including adaptive policies and regulatory sandboxes, to test and refine
governance in real-world settings. International harmonization, as seen with
the International Medical Device Regulators Forum, is essential to manage
implications of LLM on global health, including risks of widening health
inequities driven by inherent model biases. By engaging multidisciplinary
expertise, prioritizing iterative, data-driven approaches, and focusing on the
needs of diverse populations, global regulatory science research enables the
responsible and equitable advancement of LLM innovations in healthcare.",http://arxiv.org/abs/2502.07794v1
Runtime Tunable Tsetlin Machines for Edge Inference on eFPGAs,2025-02-10T12:49:22Z,"Tousif Rahman, Gang Mao, Bob Pattison, Sidharth Maheshwari, Marcos Sartori, Adrian Wheeldon, Rishad Shafik, Alex Yakovlev","Embedded Field-Programmable Gate Arrays (eFPGAs) allow for the design of
hardware accelerators of edge Machine Learning (ML) applications at a lower
power budget compared with traditional FPGA platforms. However, the limited
eFPGA logic and memory significantly constrain compute capabilities and model
size. As such, ML application deployment on eFPGAs is in direct contrast with
the most recent FPGA approaches developing architecture-specific
implementations and maximizing throughput over resource frugality. This paper
focuses on the opposite side of this trade-off: the proposed eFPGA accelerator
focuses on minimizing resource usage and allowing flexibility for on-field
recalibration over throughput. This allows for runtime changes in model size,
architecture, and input data dimensionality without offline resynthesis. This
is made possible through the use of a bitwise compressed inference architecture
of the Tsetlin Machine (TM) algorithm. TM compute does not require any
multiplication operations, being limited to only bitwise AND, OR, NOT,
summations and additions. Additionally, TM model compression allows the entire
model to fit within the on-chip block RAM of the eFPGA. The paper uses this
accelerator to propose a strategy for runtime model tuning in the field. The
proposed approach uses 2.5x fewer Look-up-Tables (LUTs) and 3.38x fewer
registers than the current most resource-fugal design and achieves up to 129x
energy reduction compared with low-power microcontrollers running the same ML
application.",http://arxiv.org/abs/2502.07823v1
"Advancing Precision Oncology Through Modeling of Longitudinal and
  Multimodal Data",2025-02-11T01:44:51Z,"Luoting Zhuang, Stephen H. Park, Steven J. Skates, Ashley E. Prosper, Denise R. Aberle, William Hsu","Cancer evolves continuously over time through a complex interplay of genetic,
epigenetic, microenvironmental, and phenotypic changes. This dynamic behavior
drives uncontrolled cell growth, metastasis, immune evasion, and therapy
resistance, posing challenges for effective monitoring and treatment. However,
today's data-driven research in oncology has primarily focused on
cross-sectional analysis using data from a single modality, limiting the
ability to fully characterize and interpret the disease's dynamic
heterogeneity. Advances in multiscale data collection and computational methods
now enable the discovery of longitudinal multimodal biomarkers for precision
oncology. Longitudinal data reveal patterns of disease progression and
treatment response that are not evident from single-timepoint data, enabling
timely abnormality detection and dynamic treatment adaptation. Multimodal data
integration offers complementary information from diverse sources for more
precise risk assessment and targeting of cancer therapy. In this review, we
survey methods of longitudinal and multimodal modeling, highlighting their
synergy in providing multifaceted insights for personalized care tailored to
the unique characteristics of a patient's cancer. We summarize the current
challenges and future directions of longitudinal multimodal analysis in
advancing precision oncology.",http://arxiv.org/abs/2502.07836v1
"Heterogeneity in Sectoral Production and the Macro Effect of Sectoral
  Shocks",2025-02-11T19:06:45Z,Jacob Toner Gosselin,"The effect of a negative sectoral shock on GDP depends on how important the
shocked sector is as a direct and indirect supplier and how easily sectors can
substitute inputs. Past estimates of the parameters that determine these
qualities in the US have been restrictive: they have not been allowed to vary
across industries or across time. This paper uses a novel empirical strategy to
relax those restrictions, by exploiting variation in input expenditure share
shifts within industries rather than across industries. The resulting estimates
exhibit significant sectoral and temporal heterogeneity, and are dynamically
correlated with weighted patents. In a calibrated GE model of multi-sector
production, this heterogeneity (1) raises[lowers] the GDP effect of negative
shocks to sectors whose customers are less[more] able to substitute inputs
(e.g. the GDP effect of ""Chemical products"" shocks rises), (2) raises[lowers]
the GDP effect of negative sectoral shocks in years where sectors are
less[more] able to substitute inputs, and (3) raises[lowers] the GDP effect of
negative shocks to sectors as they become more[less] central input suppliers
(e.g. between 1997 and 2023 the GDP effect of ""Paper products"" shocks fell and
the GDP effect of ""Computer and electronic products"" shocks rose due to changes
in their importance as input suppliers).",http://arxiv.org/abs/2502.07896v2
Imaging van Hove Singularity Heterogeneity in Overdoped Graphene,2025-02-11T19:13:38Z,"Raymond Blackwell, Zengyi Du, Takuya Okugawa, Asish Kundu, Zebin Wu, Ilya Drozdov, Angel Rubio, Dante Kennes, Kazuhiro Fujita, Abhay Pasupathy","Tuning the chemical potential of a solid to the vicinity of a van Hove
singularity (vHS) is a well-established route to discovering emergent quantum
phases. In monolayer graphene, the use of electron-donating metal layers has
recently emerged as a method to dope the chemical potential to the nearest vHS,
as evidenced by Angle-Resolved Photoemission Spectroscopy (ARPES) measurements.
In this work, we study the spatial uniformity of the doping from this process
using spectroscopic imaging scanning tunneling microscopy (SI-STM). Using
molecular beam epitaxy (MBE), we achieve electron doping of graphene on SiC
using Ytterbium (Yb-Graphene). We show using in-situ ARPES that the chemical
potential is shifted to within 250 meV of the vHS. Using in-situ SI-STM, we
establish that there exists significant inhomogeneity in the vHS position in
overdoped graphene. We find two separate reasons for this. First, the spatial
inhomogeneity of the intercalated Yb leads to local variations in the doping,
with a length scale of inhomogeneity set by the screening length of ~ 3 nm.
Second, we observe the presence of substitutional Yb dopants in the graphene
basal plane. These Yb dopants cause a strong local shift of the doping, along
with a renormalization of the quasiparticle amplitude. Theoretical calculations
confirm that the Yb impurities effectively change the local potential, thus
energetically shifting the position of the van Hove singularity. Our results
point to the importance of considering the spatial structure of doping and its
inextricable link to electronic structure.",http://arxiv.org/abs/2502.07899v1
The Role of Randomness in Stability,2025-02-11T23:06:43Z,"Max Hopkins, Shay Moran","Stability is a central property in learning and statistics promising the
output of an algorithm $A$ does not change substantially when applied to
similar datasets $S$ and $S'$. It is an elementary fact that any sufficiently
stable algorithm (e.g.\ one returning the same result with high probability,
satisfying privacy guarantees, etc.) must be randomized. This raises a natural
question: can we quantify how much randomness is needed for algorithmic
stability?
  We study the randomness complexity of two influential notions of stability in
learning: replicability, which promises $A$ usually outputs the same result
when run over samples from the same distribution (and shared random coins), and
differential privacy, which promises the output distribution of $A$ remains
similar under neighboring datasets. The randomness complexity of these notions
was studied recently in (Dixon et al. ICML 2024) and (Cannone et al. ITCS 2024)
for basic $d$-dimensional tasks (e.g. estimating the bias of $d$ coins), but
little is known about the measures more generally or in complex settings like
classification.
  Toward this end, we prove a `weak-to-strong' boosting theorem for stability:
the randomness complexity of a task $M$ (either under replicability or DP) is
tightly controlled by the best replication probability of any deterministic
algorithm solving the task, a weak measure called `global stability' that is
universally capped at $\frac{1}{2}$ (Chase et al. FOCS 2023). Using this, we
characterize the randomness complexity of PAC Learning: a class has bounded
randomness complexity iff it has finite Littlestone dimension, and moreover
scales at worst logarithmically in the excess error of the learner. This
resolves a question of (Chase et al. STOC 2024) who asked for such a
characterization in the equivalent language of (error-dependent)
`list-replicability'.",http://arxiv.org/abs/2502.08007v1
"Multi-Agent Performative Prediction Beyond the Insensitivity Assumption:
  A Case Study for Mortgage Competition",2025-02-12T02:04:46Z,"Guanghui Wang, Krishna Acharya, Lokranjan Lakshmikanthan, Vidya Muthukumar, Juba Ziani","Performative prediction models account for feedback loops in decision-making
processes where predictions influence future data distributions. While existing
work largely assumes insensitivity of data distributions to small strategy
changes, this assumption usually fails in real-world competitive (i.e.
multi-agent) settings. For example, in Bertrand-type competitions, a small
reduction in one firm's price can lead that firm to capture the entire demand,
while all others sharply lose all of their customers.
  We study a representative setting of multi-agent performative prediction in
which insensitivity assumptions do not hold, and investigate the convergence of
natural dynamics. To do so, we focus on a specific game that we call the ''Bank
Game'', where two lenders compete over interest rates and credit score
thresholds. Consumers act similarly as to in a Bertrand Competition, with each
consumer selecting the firm with the lowest interest rate that they are
eligible for based on the firms' credit thresholds. Our analysis characterizes
the equilibria of this game and demonstrates that when both firms use a common
and natural no-regret learning dynamic -- exponential weights -- with proper
initialization, the dynamics always converge to stable outcomes despite the
general-sum structure. Notably, our setting admits multiple stable equilibria,
with convergence dependent on initial conditions. We also provide theoretical
convergence results in the stochastic case when the utility matrix is not fully
known, but each learner can observe sufficiently many samples of consumers at
each time step to estimate it, showing robustness to slight mis-specifications.
Finally, we provide experimental results that validate our theoretical
findings.",http://arxiv.org/abs/2502.08063v1
GCoT: Chain-of-Thought Prompt Learning for Graphs,2025-02-12T03:33:06Z,"Xingtong Yu, Chang Zhou, Zhongwei Kuai, Xinming Zhang, Yuan Fang","Chain-of-thought (CoT) prompting has achieved remarkable success in natural
language processing (NLP). However, its vast potential remains largely
unexplored for graphs. This raises an interesting question: How can we design
CoT prompting for graphs to guide graph models to learn step by step? On one
hand, unlike natural languages, graphs are non-linear and characterized by
complex topological structures. On the other hand, many graphs lack textual
data, making it difficult to formulate language-based CoT prompting. In this
work, we propose the first CoT prompt learning framework for text-free graphs,
GCoT. Specifically, we decompose the adaptation process for each downstream
task into a series of inference steps, with each step consisting of
prompt-based inference, ``thought'' generation, and thought-conditioned prompt
learning. While the steps mimic CoT prompting in NLP, the exact mechanism
differs significantly. Specifically, at each step, an input graph, along with a
prompt, is first fed into a pre-trained graph encoder for prompt-based
inference. We then aggregate the hidden layers of the encoder to construct a
``thought'', which captures the working state of each node in the current step.
Conditioned on this thought, we learn a prompt specific to each node based on
the current state. These prompts are fed into the next inference step,
repeating the cycle. To evaluate and analyze the effectiveness of GCoT, we
conduct comprehensive experiments on eight public datasets, which demonstrate
the advantage of our approach.",http://arxiv.org/abs/2502.08092v1
"The strong coupling from hadronic $τ$-decay data including
  $τ\toπ^-π^0ν_τ$ from Belle",2025-02-12T06:15:56Z,"Diogo Boito, Aaron Eiben, Maarten Golterman, Kim Maltman, Lucas M. Mansur, Santiago Peris","In previous work we have combined the $\pi^-\pi^0$, $2\pi^-\pi^+\pi^0$ and
$\pi^-3\pi^0$ spectral data obtained from hadronic $\tau$ decays measured by
the ALEPH and OPAL experiments, together with electroproduction data for
several of the subleading hadronic modes and BaBar data for the $K\bar{K}$ mode
to construct an inclusive non-strange vector spectral function entirely based
on experimental data, with no Monte-Carlo generated input. In this paper, we
include, for the first time, the Belle $\tau\to\pi^-\pi^0\nu_\tau$
high-statistics decay data to construct a new inclusive non-strange vector
spectral function that combines more of the world's available data. As no Belle
data are at present available for the two $4\pi$ modes, this requires a revised
data analysis in comparison with our previous work. From the resulting new
spectral function, we obtain a new determination of the strong coupling,
$\alpha_s$, using our previously developed strategy based on finite-energy sum
rules. We find, at the $Z$ mass scale, $\alpha_s(m_Z^2)=0.1159(14)$. We discuss
the smaller central value and larger error of our new result compared to our
previous result, showing the shifts to be due mainly to significant changes in
updated HFLAV results for the $\pi^-3\pi^0$ decay mode.",http://arxiv.org/abs/2502.08147v1
"Artificial and Eddy Viscosity in Large Eddy Simulation Part 1: Temporal
  and Spatial Schemes",2025-02-12T06:46:56Z,"Jing Sun, Roel Verstappen","We propose a novel method to quantify artificial dissipation in large eddy
simulation. Here, artificial dissipation is defined as the residual of the
discrete turbulent kinetic energy (TKE) equation. This method is applied to
turbulent channel flow at Reynolds number 180 and 550 using a
minimum-dissipation model within the OpenFOAM framework, employing both
symmetry-preserving and standard OpenFOAM discretizations. Our analysis reveals
that artificial viscosity can both produce and dissipate TKE. To quantify the
interaction between sub-grid-scale model contributions and numerical error, we
introduce viscous activity parameters, which also allow for evaluating the
balance between molecular and non-molecular viscosity. Examining temporal
discretization schemes, we find that all methods can deliver accurate flow
predictions if an appropriate time step is used. For very small time steps,
Forward-Euler is more efficient and accurate than Crank-Nicolson, though a
better balance of accuracy and computational efficiency for larger time steps,
making it preferable for large-scale applications. On collocated meshes, Van
Kan's pressure correction method predicts better results than Chorin's. Our
spatial discretization study shows that the symmetry-preserving scheme
outperforms standard OpenFOAM schemes, as excessive artificial errors from
spatial discretization can suppress the LES model. For the symmetry-preserving
scheme, both eddy and artificial viscosities vary similarly, with eddy
viscosity being dominant. The role of artificial viscosity changes with mesh
refinement: on coarse meshes, it mainly dissipates TKE, while on finer meshes,
it can produce TKE, counteracting eddy viscosity. The most accurate Reynolds
shear stress predictions occur when non-molecular dissipation is nearly zero.
For accurate mean flow kinetic energy, larger non-molecular dissipation is
needed on finer meshes.",http://arxiv.org/abs/2502.08154v1
DGSense: A Domain Generalization Framework for Wireless Sensing,2025-02-12T06:47:25Z,"Rui Zhou, Yu Cheng, Songlin Li, Hongwang Zhang, Chenxu Liu","Wireless sensing is of great benefits to our daily lives. However, wireless
signals are sensitive to the surroundings. Various factors, e.g. environments,
locations, and individuals, may induce extra impact on wireless propagation.
Such a change can be regarded as a domain, in which the data distribution
shifts. A vast majority of the sensing schemes are learning-based. They are
dependent on the training domains, resulting in performance degradation in
unseen domains. Researchers have proposed various solutions to address this
issue. But these solutions leverage either semi-supervised or unsupervised
domain adaptation techniques. They still require some data in the target
domains and do not perform well in unseen domains. In this paper, we propose a
domain generalization framework DGSense, to eliminate the domain dependence
problem in wireless sensing. The framework is a general solution working across
diverse sensing tasks and wireless technologies. Once the sensing model is
built, it can generalize to unseen domains without any data from the target
domain. To achieve the goal, we first increase the diversity of the training
set by a virtual data generator, and then extract the domain independent
features via episodic training between the main feature extractor and the
domain feature extractors. The feature extractors employ a pre-trained Residual
Network (ResNet) with an attention mechanism for spatial features, and a 1D
Convolutional Neural Network (1DCNN) for temporal features. To demonstrate the
effectiveness and generality of DGSense, we evaluated on WiFi gesture
recognition, Millimeter Wave (mmWave) activity recognition, and acoustic fall
detection. All the systems exhibited high generalization capability to unseen
domains, including new users, locations, and environments, free of new data and
retraining.",http://arxiv.org/abs/2502.08155v1
Fare Structure Design in Public Transport,2025-02-12T09:16:17Z,"Anita Schöbel, Reena Urban","Fare planning is one among several steps in public transport planning. Fares
are relevant for the covering of costs of the public transport operator, but
also affect the ridership and the passenger satisfaction. A fare structure is
the assignment of prices to all paths in a network. In practice, often a given
fare structure shall be changed to fulfill new requirements, meaning that a new
fare strategy is desired. This motivates the usage of prices of the former fare
structure or other desirable prices as reference prices. In this paper, we
investigate the fare structure design problem that aims to determine fares such
that the sum of absolute deviations between the new fares and the reference
prices is minimized. Fare strategies that are considered here are flat tariffs,
affine distance tariffs and zone tariffs. Additionally, we regard constraints
that ensure that it is not beneficial to buy a ticket for a longer journey than
actually traveled (no-elongation property) or to split a ticket into several
sub-tickets to cover a journey (no-stopover property). Our literature review
provides an overview of the research on fare planning. We analyze the fare
structure design problem for flat, distance and zone tariffs, pointing out
connections to median problems. Further, we study its complexity which ranges
from linear-time solvability to NP-complete cases.",http://arxiv.org/abs/2502.08228v1
Keep your distance: learning dispersed embeddings on $\mathbb{S}_d$,2025-02-12T09:20:08Z,"Evgeniia Tokarchuk, Hua Chang Bakker, Vlad Niculae","Learning well-separated features in high-dimensional spaces, such as text or
image embeddings, is crucial for many machine learning applications. Achieving
such separation can be effectively accomplished through the dispersion of
embeddings, where unrelated vectors are pushed apart as much as possible. By
constraining features to be on a hypersphere, we can connect dispersion to
well-studied problems in mathematics and physics, where optimal solutions are
known for limited low-dimensional cases. However, in representation learning we
typically deal with a large number of features in high-dimensional space, and
moreover, dispersion is usually traded off with some other task-oriented
training objective, making existing theoretical and numerical solutions
inapplicable. Therefore, it is common to rely on gradient-based methods to
encourage dispersion, usually by minimizing some function of the pairwise
distances. In this work, we first give an overview of existing methods from
disconnected literature, making new connections and highlighting similarities.
Next, we introduce some new angles. We propose to reinterpret pairwise
dispersion using a maximum mean discrepancy (MMD) motivation. We then propose
an online variant of the celebrated Lloyd's algorithm, of K-Means fame, as an
effective alternative regularizer for dispersion on generic domains. Finally,
we derive a novel dispersion method that directly exploits properties of the
hypersphere. Our experiments show the importance of dispersion in image
classification and natural language processing tasks, and how algorithms
exhibit different trade-offs in different regimes.",http://arxiv.org/abs/2502.08231v1
"Evidence of a diffuse, extended continuum source in quasars from the
  relative sizes of the broad line region and the UV-optical continuum source
  measured with microlensing",2025-02-12T11:30:34Z,"Damien Hutsemékers, Dominique Sluse","Microlensing by stars in the lens galaxy of a gravitationally lensed quasar
is a phenomenon that can selectively magnify quasar subregions, producing
observable changes in the continuum brightness or distortions in the emission
line profiles. Hence, microlensing allows us to probe the inner quasar regions.
In this paper, we report measurements of the ratio of the broad emission line
region (BLR) radius to the continuum source radius in eight lensed quasars, for
the CIV, MgII, and H$\alpha$ emission lines and their respective underlying
continua at $\lambda\lambda$ 1550\AA , 2800\AA , and 6563 \AA . The
microlensing-induced line profile distortions and continuum magnifications were
observed in the same single-epoch datasets, and simultaneously compared with
microlensing simulations. We found that, on average, the inner radius of the
BLR starts at the end of the UV-optical continuum source, independently of the
line ionization and the wavelength of the continuum. The half-light radius of
the BLR is, on average, a factor of six larger than the half-light radius of
the continuum source, independently of the quasar's bolometric luminosity. We
also found a correlation between the BLR radius and the continuum source
radius, supporting the idea that the dominant contribution to the UV-optical
continuum may come from the BLR itself. Our results independently confirm the
results of reverberation mapping studies, and extend them to higher-redshift,
higher-luminosity quasars.",http://arxiv.org/abs/2502.08313v1
"Generalized synchronization in the presence of dynamical noise and its
  detection via recurrent neural networks",2025-02-12T12:11:46Z,"José M. Amigó, Roberto Dale, Juan C. King, Klaus Lehnertz","Given two unidirectionally coupled nonlinear systems, we speak of generalized
synchronization when the responder \textquotedblleft follows\textquotedblright\
the driver. Mathematically, this situation is implemented by a map from the
driver state space to the responder state space termed the synchronization map.
In nonlinear times series analysis, the framework of the present work, the
existence of the synchronization map amounts to the invertibility of the
so-called cross map, which is a continuous map that exists in the reconstructed
state spaces for typical time-delay embeddings. The cross map plays a central
role in some techniques to detect functional dependencies between time series.
In this paper, we study the changes in the \textquotedblleft noiseless
scenario\textquotedblright\ just described when noise is present in the driver,
a more realistic situation that we call the \textquotedblleft noisy
scenario\textquotedblright . Noise will be modeled using a family of driving
dynamics indexed by a finite number of parameters, which is sufficiently
general for practical purposes. In this approach, it turns out that the cross
and synchronization maps can be extended to the noisy scenario as families of
maps that depend on the noise parameters, and only for \textquotedblleft
generic\textquotedblright\ driver states in the case of the cross map. To
reveal generalized synchronization in both the noiseless and noisy scenarios,
we check the existence of synchronization maps of higher periods (introduced in
this paper) using recurrent neural networks and predictability. The results
obtained with synthetic and real world data demonstrate the capability of our
method.",http://arxiv.org/abs/2502.08343v1
"Modulation of Neuronal Firing Modes by Electric Fields in a
  Thermosensitive FitzHugh-Nagumo Model",2025-02-12T18:14:40Z,"Ediline L. F. Nguessap, Fernando F. Ferreira, Antonio C. Roque","The Fitzhugh-Nagumo neuronal model is used to explore the influence of the
electric field on thermosensitive neurons' dynamics. This study investigates
how the electric field affects polarization modulation in cell media induced by
changes in ion charge density by adding electrical field as a new variable.
Driven by a voltage source acting as an external stimulus current, different
firing mode responses of the proposed model are analyzed when an external
electrical field is applied. Through computational analysis, the study
evaluates the impact of parameters such as cell radius, stimulus voltage source
amplitude, frequency, and as well as the presence of an external electric
field. The results demonstrate distinct mode transitions of isolated neurons
ranging from spiking to bursting, regular and chaotic oscillations. These
findings suggest that the firing mode is triggered by periodic external
electric fields and cell radius, with the electric field's involvement enhanced
to regulate neuron activity and control the dynamics. External electric fields
and stimuli play a crucial role in neuronal firing dynamics, affecting the
transition between different firing modes. Understanding these effects
contributes to the comprehension of neural processes and the potential
manipulation of neural activity for various applications in neuroscience and
biophysics.",http://arxiv.org/abs/2502.08618v1
Forecasting Drought Using Machine Learning in California,2025-02-12T18:20:41Z,"Nan K. Li, Angela Chang, David Sherman","Drought is a frequent and costly natural disaster in California, with major
negative impacts on agricultural production and water resource availability,
particularly groundwater. This study investigated the performance of applying
different machine learning approaches to predicting the U.S. Drought Monitor
classification in California. Four approaches were used: a convolutional neural
network (CNN), random forest, XGBoost, and long short term memory (LSTM)
recurrent neural network, and compared to a baseline persistence model. We
evaluated the models' performance in predicting severe drought (USDM drought
category D2 or higher) using a macro F1 binary classification metric. The LSTM
model emerged as the top performer, followed by XGBoost, CNN, and random
forest. Further evaluation of our results at the county level suggested that
the LSTM model would perform best in counties with more consistent drought
patterns and where severe drought was more common, and the LSTM model would
perform worse where drought scores increased rapidly. Utilizing 30 weeks of
historical data, the LSTM model successfully forecasted drought scores for a
12-week period with a Mean Absolute Error (MAE) of 0.33, equivalent to less
than half a drought category on a scale of 0 to 5. Additionally, the LSTM
achieved a macro F1 score of 0.9, indicating high accuracy in binary
classification for severe drought conditions. Evaluation of different window
and future horizon sizes in weeks suggested that at least 24 weeks of data
would result in the best performance, with best performance for shorter horizon
sizes, particularly less than eight weeks.",http://arxiv.org/abs/2502.08622v1
"Joint Transmit and Pinching Beamforming for PASS: Optimization-Based or
  Learning-Based?",2025-02-12T18:54:10Z,"Xiaoxia Xu, Xidong Mu, Yuanwei Liu, Arumugam Nallanathan","A novel pinching antenna system (PASS)-enabled downlink multi-user
multiple-input single-output (MISO) framework is proposed. PASS consists of
multiple waveguides spanning over thousands of wavelength, which equip numerous
low-cost dielectric particles, named pinching antennas (PAs), to radiate
signals into free space. The positions of PAs can be reconfigured to change
both the large-scale path losses and phases of signals, thus facilitating the
novel pinching beamforming design. A sum rate maximization problem is
formulated, which jointly optimizes the transmit and pinching beamforming to
adaptively achieve constructive signal enhancement and destructive interference
mitigation. To solve this highly coupled and nonconvex problem, both
optimization-based and learning-based methods are proposed. 1) For the
optimization-based method, a majorization-minimization and penalty dual
decomposition (MM-PDD) algorithm is developed, which handles the nonconvex
complex exponential component using a Lipschitz surrogate function and then
invokes PDD for problem decoupling. 2) For the learning-based method, a novel
Karush-Kuhn-Tucker (KKT)-guided dual learning (KDL) approach is proposed, which
enables KKT solutions to be reconstructed in a data-driven manner by learning
dual variables. Following this idea, a KDL-Tranformer algorithm is developed,
which captures both inter-PA/inter-user dependencies and
channel-state-information (CSI)-beamforming dependencies by attention
mechanisms. Simulation results demonstrate that: i) The proposed PASS framework
significantly outperforms conventional massive multiple input multiple output
(MIMO) system even with a few PAs. ii) The proposed KDL-Transformer can improve
over 30% system performance than MM-PDD algorithm, while achieving a
millisecond-level response on modern GPUs.",http://arxiv.org/abs/2502.08637v1
"The effect of duty cycle on electron transmission through a graphene
  electrostatic barrier",2025-02-13T05:42:57Z,"R. Biswas, S. Mukhopadhyay, C. Sinha","We investigated theoretically the transmission properties of Dirac Fermions
tunneling through a periodically (sinusoidal and rectangular) driven
electrostatic barrier in Monolayer graphene. For the time harmonic potential
with moderate to high alpha (=amplitude/frequency) the central Floquet band is
found to be almost cloaked for the Klein transmitted electron in contrast to
electron at higher grazing incidences. As a time periodic drive, we mainly
focused on the use of rectangular wave electric signal to modulate the
transparency of the barrier. It is noted that the asymmetric Fano resonance, a
characteristic feature of photon assisted tunneling, is more likely to occur
for rectangular drive in contrast to the harmonic one. The height of the
modulating potential is particularly responsible for the dressing effect of the
barrier. The position and nature of the FR can be tailored by changing the
height and frequency of the rectangular drive. Moreover, the duty cycle of the
driving potential turns out to be an important controlling parameter for the
transmission process. Thus, the rectangular modulation plays an important role
for the occurrence and detection of the Fano resonances which is vital for the
use of graphene nanostructure in the field of detectors, sensors, modulators
etc. The present findings attempt for the first time, to realize the effect of
duty cycle on the quantum interference in semiconductor nanostructures.",http://arxiv.org/abs/2502.08983v1
"Data-Driven Discovery of Population Balance Equations for the
  Particulate Sciences",2025-02-13T07:00:27Z,"Simon Ing Xun Tiong, Firnaaz Ahamed, Yong Kuen Ho","Understanding the behavior of particles in a dispersed phase system via
population balances holds fundamental importance in studies of particulate
sciences across various fields. Particle behavior, however, is sophisticated as
a single particle can undergo internal property changes (e.g., size, cell age,
and energy content) through various mechanisms. When confronted with an unknown
distributed particulate system, discovering the underlying population balance
equation (PBE) entails firstly learning the underlying particulate phenomena
followed by the associated phenomenological laws that govern the kinetics and
mechanisms of particle transformations in their local conditions. Conventional
inverse problem approaches reveal the shape of phenomenological functions for
predetermined forms of PBE (e.g., pure breakage/aggregation PBE, etc.).
However, these methods can be limited in their ability to uncover the
mechanisms which govern uncharacterized particulate systems from data.
Leveraging the increasing abundance of data, we devise a data-driven framework
based on sparse regression to learn PBEs as linear combinations of an extensive
pool of candidate terms. Thus, this approach enables effective and accurate
functional identification of PBEs without assuming the structure a priori,
hence mitigating any potential loss of details, while minimizing model
overfitting and providing a more interpretable representation of particulate
systems. We showcase the proficiency of our approach across a wide spectrum of
particulate systems, ranging from simple canonical pure breakage and pure
aggregation systems to complex systems with multiple particulate processes. Our
approach holds the potential to generalize the discovery of PBEs along with
their phenomenological laws from data, thus facilitating wider adoption of
population balances.",http://arxiv.org/abs/2502.09010v1
"Interfacial Polarization Switching in Al0.92Sc0.08N/GaN Heterostructures
  Grown by Sputter Epitaxy",2025-02-13T09:02:50Z,"Niklas Wolff, Georg Schönweger, Redwanul Md. Islam, Ziming Ding, Christian Kübel, Simon Fichtner, Lorenz Kienle","The integration of ferroelectric nitride thin films such as Al1-xScxN onto
GaN templates could enable enhanced functionality in novel high-power
transistors and memory devices. This requires a detailed understanding of the
ferroelectric domain structures and their impact on the electric properties. In
this contribution, the sputter epitaxy of highly coherent Al0.92Sc0.08N thin
films grown on GaN approaching lattice-matching conditions is demonstrated.
Scanning transmission electron microscopy investigations reveal the formation
of polar domains and the mechanism of domain propagation upon ferroelectric
switching. Atomic resolution imaging suggests that polarization inversion is
initiated by an interfacial switching process in which already the first atomic
layer of Al1-xScxN changes its polarization from the as-grown M- to N-polarity.
An atomically sharp planar polarization discontinuity is identified at the
Al0.92Sc0.08N/GaN interface and described by atomic modeling and chemical
structure analysis using electron energy loss spectroscopy, considering local
lattice spacings. Moreover, residual domains with M-polarity are identified at
the top Pt electrode interface. These insights on the location and the atomic
structure of ferroelectric inversion domains in sputter deposited Al1-xScxN/GaN
heterostructures will support the development of future non-volatile memory
devices and novel HEMT structures based on ferroelectric nitride thin films via
interface engineering.",http://arxiv.org/abs/2502.09090v1
"Bridging the Gap Between LLMs and Human Intentions: Progresses and
  Challenges in Instruction Understanding, Intention Reasoning, and Reliable
  Generation",2025-02-13T09:19:42Z,"Zongyu Chang, Feihong Lu, Ziqin Zhu, Qian Li, Cheng Ji, Zhuo Chen, Yang Liu, Ruifeng Xu, Yangqiu Song, Shangguang Wang, Jianxin Li","Large language models (LLMs) have demonstrated exceptional capabilities in
understanding and generation. However, when interacting with human instructions
in real-world scenarios, LLMs still face significant challenges, particularly
in accurately capturing and comprehending human instructions and intentions.
This paper focuses on three challenges in LLM-based text generation tasks:
instruction understanding, intention reasoning, and reliable generation.
Regarding human complex instruction, LLMs have deficiencies in understanding
long contexts and instructions in multi-round conversations. For intention
reasoning, LLMs may have inconsistent command reasoning, difficulty reasoning
about commands containing incorrect information, difficulty understanding user
ambiguous language commands, and a weak understanding of user intention in
commands. Besides, In terms of reliable generation, LLMs may have unstable
generated content and unethical generation. To this end, we classify and
analyze the performance of LLMs in challenging scenarios and conduct a
comprehensive evaluation of existing solutions. Furthermore, we introduce
benchmarks and categorize them based on the aforementioned three core
challenges. Finally, we explore potential directions for future research to
enhance the reliability and adaptability of LLMs in real-world applications.",http://arxiv.org/abs/2502.09101v1
"Quantum geometry and the electric magnetochiral anisotropy in
  noncentrosymmetric polar media",2025-02-13T10:16:41Z,"Pierpaolo Fontana, Victor Velasco, Chang Niu, Peide D. Ye, Pedro V. Lopes, Kaio E. M. de Souza, Marcus V. O. Moutinho, Caio Lewenkopf, Marcello B. Silva Neto","The electric magnetochiral anisotropy is a nonreciprocal phenomenon
accessible via second harmonic transport in noncentrosymmetric, time-reversal
invariant materials, in which the rectification of current, ${\bf I}$, can be
controlled by an external magnetic field, ${\bf B}$. Quantum geometry, which
characterizes the topology of Bloch electrons in a Hilbert space, provides a
powerful description of the nonlinear dynamics in topological materials. Here,
we demonstrate that the electric magnetochiral anisotropy in noncentrosymmetric
polar media owes its existence to the quantum metric, arising from the
spin-orbit coupling, and to large Born effective charges. In this context, the
reciprocal magnetoresistance $\beta{\bf B}^2$ is modified to $R(
I,P,B)=R_0[1+\beta B^2 + \gamma^{\pm}{\bf I}\cdot({\bf P}\times{\bf B})]$,
where the chirality dependent $\gamma^{\pm}$ is determined by the quantum
metric dipole and the polarization ${\bf P}$. We predict a universal scaling
$\gamma^{\pm}(V)\sim V^{-5/2}$ which we verified by phase sensitive, second
harmonic transport measurements on hydrothermally grown 2D tellurium films
under applied gate voltage, $V$. The control of rectification by varying ${\bf
I}$, ${\bf P}$, ${\bf B}$, and $V$, demonstrated in this work, opens up new
avenues for the building of ultra-scaled CMOS circuits.",http://arxiv.org/abs/2502.09141v1
"Computational discovery of high-refractive-index van der Waals
  materials: The case of HfS$_2$",2025-02-13T10:19:37Z,"Xavier Zambrana-Puyalto, Mark Kamper Svendsen, Amalie H. Søndersted, Avishek Sarbajna, Joakim P. Sandberg, Albert L. Riber, Georgy Ermolaev, Tara Maria Boland, Gleb Tselikov, Valentyn S. Volkov, Kristian S. Thygesen, Søren Raza","New high-refractive-index dielectric materials may enhance many optical
technologies by enabling efficient manipulation of light in waveguides,
metasurfaces, and nanoscale resonators. Van der Waals materials are
particularly promising due to their excitonic response and strong in-plane
polarizability. Here we combine ab initio calculations and experiments to
discover new high-refractive-index materials. Our screening highlights both
known and new promising optical materials, including hafnium disulfide
(HfS$_2$), which shows an in-plane refractive index above 3 and large
anisotropy in the visible range. We confirm these theoretical predictions
through ellipsometry measurements and investigate the photonic potential of
HfS$_2$ by fabricating nanodisk resonators, observing optical Mie resonances in
the visible spectrum. Over the course of seven days, we observe a structural
change in HfS$_2$, which we show can be mitigated by storage in either
argon-rich or humidity-reduced environments. This work provides a comparative
overview of high-index van der Waals materials and showcases the potential of
HfS$_2$ for photonic applications in the visible spectrum.",http://arxiv.org/abs/2502.09144v1
Logical foundations of Smart Contracts,2025-02-13T11:53:10Z,Kalonji Kalala,"Nowadays, sophisticated domains are emerging which require appropriate
formalisms to be specified accurately in order to reason about them. One such
domain is constituted of smart contracts that have emerged in cyber physical
systems as a way of enforcing formal agreements between components of these
systems. Smart contracts self-execute to run and share business processes
through blockchain, in decentralized systems, with many different participants.
Legal contracts are in many cases complex documents, with a number of
exceptions, and many subcontracts. The implementation of smart contracts based
on legal contracts is a long and laborious task, that needs to include all
actions, procedures, and the effects of actions related to the execution of the
contract. An ongoing open problem in this area is to formally account for smart
contracts using a uniform and somewhat universal formalism. This thesis
proposes logical foundations to smart contracts using the Situation Calculus, a
logic for reasoning about actions. Situation Calculus is one of the prominent
logic-based artificial intelligence approaches that provides enough logical
mechanism to specify and implement dynamic and complex systems such as
contracts. Situation Calculus is suitable to show how worlds dynamically
change. Smart contracts are going to be implement with Golog (written en
Prolog), a Situation Calculus-based programming language for modeling complex
and dynamic behaviors.",http://arxiv.org/abs/2502.09232v1
Recipe: Hardware-Accelerated Replication Protocols,2025-02-13T12:04:53Z,"Dimitra Giantsidi, Emmanouil Giortamis, Julian Pritzi, Maurice Bailleu, Manos Kapritsos, Pramod Bhatotia","Replication protocols are essential for distributed systems, ensuring
consistency, reliability, and fault tolerance. Traditional Crash Fault Tolerant
(CFT) protocols, which assume a fail-stop model, are inadequate for untrusted
cloud environments where adversaries or software bugs can cause Byzantine
behavior. Byzantine Fault Tolerant (BFT) protocols address these threats but
face significant performance, resource overheads, and scalability challenges.
This paper introduces Recipe, a novel approach to transforming CFT protocols to
operate securely in Byzantine settings without altering their core logic.
Recipe rethinks CFT protocols in the context of modern cloud hardware,
including many-core servers, RDMA-capable networks, and Trusted Execution
Environments (TEEs). The approach leverages these advancements to enhance the
security and performance of replication protocols in untrusted cloud
environments. Recipe implements two practical security mechanisms, i.e.,
transferable authentication and non-equivocation, using TEEs and
high-performance networking stacks (e.g., RDMA, DPDK). These mechanisms ensure
that any CFT protocol can be transformed into a BFT protocol, guaranteeing
authenticity and non-equivocation. The Recipe protocol consists of five key
components: transferable authentication, initialization, normal operation, view
change, and recovery phases. The protocol's correctness is formally verified
using Tamarin, a symbolic model checker. Recipe is implemented as a library and
applied to transform four widely used CFT protocols-Raft, Chain Replication,
ABD, and AllConcur-into Byzantine settings. The results demonstrate up to 24x
higher throughput compared to PBFT and 5.9x better performance than
state-of-the-art BFT protocols. Additionally, Recipe requires fewer replicas
and offers confidentiality, a feature absent in traditional BFT protocols.",http://arxiv.org/abs/2502.09251v1
"Capitalizing on a Crisis: A Computational Analysis of all Five Million
  British Firms During the Covid-19 Pandemic",2025-02-13T14:59:03Z,"Naomi Muggleton, Charles Rahal, Aaron Reeves","The Covid-19 pandemic brought unprecedented changes to business ownership in
the UK which affects a generation of entrepreneurs and their employees.
Nonetheless, the impact remains poorly understood. This is because research on
capital accumulation has typically lacked high-quality, individualized,
population-level data. We overcome these barriers to examine who benefits from
economic crises through a computationally orientated lens of firm creation.
Leveraging a comprehensive cache of administrative data on every UK firm and
all nine million people running them, combined with probabilistic algorithms,
we conduct individual-level analyses to understand who became Covid
entrepreneurs. Using these techniques, we explore characteristics of
entrepreneurs--such as age, gender, region, business experience, and
industry--which potentially predict Covid entrepreneurship. By employing an
automated time series model selection procedure to generate counterfactuals, we
show that Covid entrepreneurs were typically aged 35-49 (40.4%), men (73.1%),
and had previously held roles in existing firms (59.4%). For most industries,
growth was disproportionately concentrated around London. It was therefore
existing corporate elites who were most able to capitalize on the Covid crisis
and not, as some hypothesized, young entrepreneurs who were setting up their
first businesses. In this respect, the pandemic will likely impact future
wealth inequalities. Our work offers methodological guidance for future
policymakers during economic crises and highlights the long-term consequences
for capital and wealth inequality.",http://arxiv.org/abs/2502.09383v2
"S$^2$-Diffusion: Generalizing from Instance-level to Category-level
  Skills in Robot Manipulation",2025-02-13T15:06:42Z,"Quantao Yang, Michael C. Welle, Danica Kragic, Olov Andersson","Recent advances in skill learning has propelled robot manipulation to new
heights by enabling it to learn complex manipulation tasks from a practical
number of demonstrations. However, these skills are often limited to the
particular action, object, and environment \textit{instances} that are shown in
the training data, and have trouble transferring to other instances of the same
category. In this work we present an open-vocabulary Spatial-Semantic Diffusion
policy (S$^2$-Diffusion) which enables generalization from instance-level
training data to category-level, enabling skills to be transferable between
instances of the same category. We show that functional aspects of skills can
be captured via a promptable semantic module combined with a spatial
representation. We further propose leveraging depth estimation networks to
allow the use of only a single RGB camera. Our approach is evaluated and
compared on a diverse number of robot manipulation tasks, both in simulation
and in the real world. Our results show that S$^2$-Diffusion is invariant to
changes in category-irrelevant factors as well as enables satisfying
performance on other instances within the same category, even if it was not
trained on that specific instance. Full videos of all real-world experiments
are available in the supplementary material.",http://arxiv.org/abs/2502.09389v2
"On Usage of Non-Volatile Memory as Primary Storage for Database
  Management Systems",2025-02-13T15:53:34Z,"Naveed Ul Mustafa, Adri`a Armejach, Ozcan Ozturk, Adrian Cristal, Osman S. Unsal","This paper explores the implications of employing non-volatile memory (NVM)
as primary storage for a data base management system (DBMS). We investigate the
modifications necessary to be applied on top of a traditional relational DBMS
to take advantage of NVM features. As a case study, we modify the storage
engine (SE) of PostgreSQL enabling efficient use of NVM hardware. We detail the
necessary changes and challenges such modifications entail and evaluate them
using a comprehensive emulation platform. Results indicate that our modified SE
reduces query execution time by up to 45% and 13% when compared to disk and NVM
storage, with average reductions of 19% and 4%, respectively. Detailed analysis
of these results shows that while our modified SE is able to access data more
efficiently, data is not close to the processing units when needed for
processing, incurring long latency misses that hinder the performance. To solve
this, we develop a general purpose library that employs helper threads to
prefetch data from NVM hardware via a simple API. Our library further improves
query execution time for our modified SE when compared to disk and NVM storage
by up to 54% and 17%, with average reductions of 23% and 8%, respectively.",http://arxiv.org/abs/2502.09431v1
"Balancing physical modeling and musical requirements: Algorithmically
  simulating the calls of Hyalessa maculaticollis for real-time instrumental
  control",2025-02-13T16:27:03Z,Staas de Jong,"This paper presents an algorithm that simulates the calls of the Hyalessa
maculaticollis cicada for musical use. Written in SuperCollider, its input
parameters enable real-time control of the insect call phase, loudness, and
perceived musical pitch. To this end, the anatomical mechanics of the tymbal
muscles, tymbal apodeme, tymbal ribs, tymbal plate, abdominal air sac, tympana,
and opercula are physically modeled. This also includes decoherence, following
the hypothesis that it, in H. maculaticollis, might explain the change in
timbre apparent during the final phase of a call sequence.
  Overall, the algorithm seems to illustrate three main points regarding the
trade-offs encountered when modeling bioacoustics for tonal use: that it may be
necessary to prioritize musical requirements over realistic physical modeling
at many stages of design and implementation; that the resulting adjustments may
revolve around having physical modeling perceptually yield sonic events that
are well-pitched, single-attack, single-source, and timbrally expressive; that
the pitch-adjusted simulation of resonating bodies may fail musically precisely
when it succeeds physically, by inducing the perception of different sound
sources for different pitches. Audio examples are included, and the source code
is structured and documented so as to support the further development of cicada
bioacoustics for musical use.",http://arxiv.org/abs/2502.09459v1
"Structural phase transitions between layered Indium Selenide for
  inte-grated photonic memory",2025-02-13T16:38:40Z,"Tiantian Li, Yong Wang, Wei Li, Dun Mao, Chris J. Benmore, Igor Evangelista, Huadan Xing, Qiu Li, Feifan Wang, Ganesh Sivaraman, Anderson Janotti, Stephanie Law, Tingyi Gu","The primary mechanism of optical memristive devices relies on the phase
transitions between amorphous-crystalline states. The slow or energy hungry
amorphous-crystalline transitions in optical phase-change materials are
detrimental to the devices scalability and performance. Leveraging the
integrated photonic platform, we demonstrate a single nanosecond pulse
triggered nonvolatile and reversible switching between two layered structures
of indium selenide (In2Se3). High resolution pair distribution function reveals
the detailed atomistic transition pathways between the layered structures. With
inter-layer shear glide and isosymmetric phase transition, the switching
between alpha and beta structural states contain low re-configurational
entropy, allowing reversible switching between layered structures. Broadband
refractive index contrast, optical transparency, and volumetric effect in the
crystalline-crystalline phase transition are experimentally characterized in
molecular beam epitaxy-grown thin films and compared to ab initials
calculations. The nonlinear resonator transmission spectra measure an
incremental linear loss rate of 3.3 GHz introduced by 1.5 micrometer long
In2Se3 covered lay-er, resulting from the combinations of material absorption
and scattering.",http://arxiv.org/abs/2502.09474v1
"Extinction and Metastability of Pheromone-Roads in Stochastic Models for
  Foraging Walks of Ants",2025-02-13T16:39:07Z,"Saori Morimoto, Makoto Katori, Hiraku Nishimori","Macroscopic changes of group behavior of eusocial insects are studied from
the viewpoint of non-equilibrium phase transitions. Recent combined study of
experiments and mathematical modeling by the group led by the third author
suggests that a species of garden ant switches the individual foraging walk
from pheromone-mediated to visual-cues-mediated depending on situation. If an
initial pheromone-road between the nest and food sources is a detour, ants
using visual cues can pioneer shorter paths. These shorter paths are reinforced
by pheromone secreted by following ants, and then the detour ceases to exist.
Once the old pheromone-road extincts, there will be almost no chance to
reconstruct it. Hence the extinction of pheromone-road is expected to be
regarded as a phase transition to an absorbing state. We propose a
discrete-time model on a square lattice consisting of switching random walks
interacting though time-dependent pheromone field. The numerical study shows
that the critical phenomena of the present extinction transitions of
pheromone-roads do not seem to belong to the directed percolation universality
class associated with the usual absorbing-state transition. The new aspects are
cased by the coexistence and competition with newly creating pheromone-roads.
In a regime in the extinction phase, the annihilating road shows metastability
and takes long time-period to be replaced by a new road.",http://arxiv.org/abs/2502.09475v1
"Journey from the Wilson exact RG towards the Wegner-Morris Fokker-Planck
  RG and the Carosso field-coarsening via Langevin stochastic processes",2025-02-13T17:20:59Z,Cecile Monthus,"Within the Wilson RG of 'incomplete integration' as a function of the RG-time
$t$, the non-linear differential RG flow for the energy $E_t[\phi(.)]$
translates for the probability distribution $P_t[\phi(.)] \sim e^{-
E_t[\phi(.)]} $ into the linear Fokker-Planck RG flow associated to independent
non-identical Ornstein-Uhlenbeck processes for the Fourier modes. The
corresponding Langevin stochastic differential equation for the real-space
field $\phi_t(\vec x)$ can be then interpreted within the Carosso perspective
as genuine infinitesimal coarsening-transformations that are the analog of
spin-blocking, and whose irreversible character is essential to overcome the
paradox of the naive description of the Wegner-Morris RG flow as a mere
infinitesimal change of variables in the partition function integral. This
interpretation suggests to consider new RG-schemes, in particular the Carosso
RG where the Langevin SDE corresponds to the well known stochastic heat
equation or the Edwards-Wilkinson dynamics. We stress the advantages of this
stochastic formulation of exact RG flows. While statistical field theory is
usually written in infinite space, we focus here on the formulation on a large
volume $L^d$ with periodic boundary conditions, in order to distinguish between
extensive and intensives observables while keeping the translation-invariance.
Since the empirical magnetization $m_e \equiv \frac{1}{L^d} \int_{L^d} d^d \vec
x \ \phi(\vec x) $ is an intensive variable corresponding to the zero-momentum
Fourier coefficient of the field, its probability distribution $p_L(m_e)$ can
be obtained from the gradual integration over all the other Fourier
coefficients associated to non-vanishing-momenta via exact differential RG, in
order to obtain the large deviation properties with respect to the volume
$L^d$.",http://arxiv.org/abs/2502.09506v1
"Collective migration and topological phase transitions in confluent
  epithelia",2025-02-13T18:06:01Z,"Leonardo Puggioni, Dimitrios Krommydas, Luca Giomi","Collective epithelial migration leverages on topological rearrangements of
the intercellular junctions, which allow cells to intercalate without loosing
confluency. In silico studies have provided a clear indication that this
process could occur via a two-step phase transition, where a hierarchy of
topological excitations progressively transforms an epithelial layer from a
crystalline solid to an isotropic liquid, via an intermediate hexatic liquid
crystal phase. Yet, the fundamental mechanism behind this process and its
implications for collective cell behavior are presently unknown. In this
article, we show that the onset of collective cell migration in cell-resolved
models of epithelial layers takes place via an activity-driven melting
transition, characterized by an exponentially-divergent correlation length
across the solid/hexatic phase boundary. Using a combination of numerical
simulations and Renormalization Group analysis, we show that the availability
of topologically distinct rearrangements - known as T1 and T2 processes - and
of a non-thermal route to melting, renders the transition significantly more
versatile and tunable than in two-dimensional passive matter. Specifically, the
relative frequency of T1 and T2 processes and of the ""bare"" stiffness of the
cell layer affect the divergence of positional correlations within a
well-defined spectrum of critical behaviors. Suppressing T1 processes, changes
the nature of the transition by preventing collective migration in favor of a
cellular analog of surface sublimation.",http://arxiv.org/abs/2502.09554v1
"Wireless and passive pressure detection using magneto-mechanical
  resonances in process engineering",2025-02-13T18:32:46Z,"Timo Merbach, Felix Kexel, Jonas Faltinath, Martin Möddel, Michael Schlüter, Tobias Knopp, Fabian Mohn","A custom-developed magneto-mechanical resonator (MMR) for wireless pressure
measurement is investigated for potential applications in process engineering.
The MMR sensor utilises changes in the resonance frequency caused by pressure
on a flexible 3D printed membrane. The thickness of the printed membrane plays
a crucial role in determining the performance and sensitivity of MMRs, and can
be tailored to meet the requirements of specific applications. The study
includes static and dynamic measurements to determine the pressure sensitivity
and temporal resolution of the sensor. The results show a minimum sensitivity
of $0.06~\text{Hz mbar}^{-1}$ and are in agreement with theoretical
calculations and measurements. The maximum sensor readout frequency is
$2~\text{Hz}$ in this study. Additionally, the temperature dependence of the
sensor is investigated, revealing a significant dependence of the resonance
frequency on temperature. The developed MMR offers a promising and versatile
method for precise pressure measurements in process engineering environments.",http://arxiv.org/abs/2502.09575v1
"GAIA: A Global, Multi-modal, Multi-scale Vision-Language Dataset for
  Remote Sensing Image Analysis",2025-02-13T18:52:14Z,"Angelos Zavras, Dimitrios Michail, Xiao Xiang Zhu, Begüm Demir, Ioannis Papoutsis","The continuous operation of Earth-orbiting satellites generates vast and
ever-growing archives of Remote Sensing (RS) images. Natural language presents
an intuitive interface for accessing, querying, and interpreting the data from
such archives. However, existing Vision-Language Models (VLMs) are
predominantly trained on web-scraped, noisy image-text data, exhibiting limited
exposure to the specialized domain of RS. This deficiency results in poor
performance on RS-specific tasks, as commonly used datasets often lack
detailed, scientifically accurate textual descriptions and instead emphasize
solely on attributes like date and location. To bridge this critical gap, we
introduce GAIA, a novel dataset designed for multi-scale, multi-sensor, and
multi-modal RS image analysis. GAIA comprises of 205,150 meticulously curated
RS image-text pairs, representing a diverse range of RS modalities associated
to different spatial resolutions. Unlike existing vision-language datasets in
RS, GAIA specifically focuses on capturing a diverse range of RS applications,
providing unique information about environmental changes, natural disasters,
and various other dynamic phenomena. The dataset provides a spatially and
temporally balanced distribution, spanning across the globe, covering the last
25 years with a balanced temporal distribution of observations. GAIA's
construction involved a two-stage process: (1) targeted web-scraping of images
and accompanying text from reputable RS-related sources, and (2) generation of
five high-quality, scientifically grounded synthetic captions for each image
using carefully crafted prompts that leverage the advanced vision-language
capabilities of GPT-4o. Our extensive experiments, including fine-tuning of
CLIP and BLIP2 models, demonstrate that GAIA significantly improves performance
on RS image classification, cross-modal retrieval and image captioning tasks.",http://arxiv.org/abs/2502.09598v1
SASVi -- Segment Any Surgical Video,2025-02-12T00:29:41Z,"Ssharvien Kumar Sivakumar, Yannik Frisch, Amin Ranem, Anirban Mukhopadhyay","Purpose: Foundation models, trained on multitudes of public datasets, often
require additional fine-tuning or re-prompting mechanisms to be applied to
visually distinct target domains such as surgical videos. Further, without
domain knowledge, they cannot model the specific semantics of the target
domain. Hence, when applied to surgical video segmentation, they fail to
generalise to sections where previously tracked objects leave the scene or new
objects enter. Methods: We propose SASVi, a novel re-prompting mechanism based
on a frame-wise Mask R-CNN Overseer model, which is trained on a minimal amount
of scarcely available annotations for the target domain. This model
automatically re-prompts the foundation model SAM2 when the scene constellation
changes, allowing for temporally smooth and complete segmentation of full
surgical videos. Results: Re-prompting based on our Overseer model
significantly improves the temporal consistency of surgical video segmentation
compared to similar prompting techniques and especially frame-wise
segmentation, which neglects temporal information, by at least 1.5%. Our
proposed approach allows us to successfully deploy SAM2 to surgical videos,
which we quantitatively and qualitatively demonstrate for three different
cholecystectomy and cataract surgery datasets. Conclusion: SASVi can serve as a
new baseline for smooth and temporally consistent segmentation of surgical
videos with scarcely available annotation data. Our method allows us to
leverage scarce annotations and obtain complete annotations for full videos of
the large-scale counterpart datasets. We make those annotations publicly
available, providing extensive annotation data for the future development of
surgical data science models.",http://arxiv.org/abs/2502.09653v1
"IMM-MOT: A Novel 3D Multi-object Tracking Framework with Interacting
  Multiple Model Filter",2025-02-13T01:55:32Z,"Xiaohong Liu, Xulong Zhao, Gang Liu, Zili Wu, Tao Wang, Lei Meng, Yuhan Wang","3D Multi-Object Tracking (MOT) provides the trajectories of surrounding
objects, assisting robots or vehicles in smarter path planning and obstacle
avoidance. Existing 3D MOT methods based on the Tracking-by-Detection framework
typically use a single motion model to track an object throughout its entire
tracking process. However, objects may change their motion patterns due to
variations in the surrounding environment. In this paper, we introduce the
Interacting Multiple Model filter in IMM-MOT, which accurately fits the complex
motion patterns of individual objects, overcoming the limitation of
single-model tracking in existing approaches. In addition, we incorporate a
Damping Window mechanism into the trajectory lifecycle management, leveraging
the continuous association status of trajectories to control their creation and
termination, reducing the occurrence of overlooked low-confidence true targets.
Furthermore, we propose the Distance-Based Score Enhancement module, which
enhances the differentiation between false positives and true positives by
adjusting detection scores, thereby improving the effectiveness of the Score
Filter. On the NuScenes Val dataset, IMM-MOT outperforms most other
single-modal models using 3D point clouds, achieving an AMOTA of 73.8%. Our
project is available at https://github.com/Ap01lo/IMM-MOT.",http://arxiv.org/abs/2502.09672v1
"Lifespan tree of brain anatomy: diagnostic values for motor and
  cognitive neurodegenerative diseases",2025-02-13T13:29:05Z,"Pierrick Coupé, Boris Mansencal, José V. Manjón, Patrice Péran, Wassilios G. Meissner, Thomas Tourdias, Vincent Planche","The differential diagnosis of neurodegenerative diseases, characterized by
overlapping symptoms, may be challenging. Brain imaging coupled with artificial
intelligence has been previously proposed for diagnostic support, but most of
these methods have been trained to discriminate only isolated diseases from
controls. Here, we develop a novel machine learning framework, named lifespan
tree of brain anatomy, dedicated to the differential diagnosis between multiple
diseases simultaneously. It integrates the modeling of volume changes for 124
brain structures during the lifespan with non-linear dimensionality reduction
and synthetic sampling techniques to create easily interpretable
representations of brain anatomy over the course of disease progression. As
clinically relevant proof-of-concept applications, we constructed a cognitive
lifespan tree of brain anatomy for the differential diagnosis of six causes of
neurodegenerative dementia and a motor lifespan tree of brain anatomy for the
differential diagnosis of four causes of parkinsonism using 37594 MRI as a
training dataset. This original approach enhanced significantly the efficiency
of differential diagnosis in the external validation cohort of 1754 cases,
outperforming existing state-of-the art machine learning techniques. Lifespan
tree holds promise as a valuable tool for differential diagnostic in relevant
clinical conditions, especially for diseases still lacking effective biological
markers.",http://arxiv.org/abs/2502.09682v1
"Atomic Fermi superfluids with tunable pairing interactions under the
  influence of spin-dependent Rydberg molecular potentials",2025-02-14T00:34:14Z,"Chih-Chun Chien, Seth T. Rittenhouse, S. I. Mistakidis, H. R. Sadeghpour","We explore the energy spectrum and eigenstates of two-component atomic Fermi
superfluids with tunable pairing interactions in the presence of spin-dependent
ultra long-range Rydberg molecule (ULRM) potentials, within the Bogoliubov-de
Gennes formalism. The attractive ULRM potentials lead to local density
accumulation, while their difference results in a local polarization potential
and induces the in-gap Yu-Shiba-Rusinov (YSR) states whose energies lie below
the bulk energy gap. A transition from equal-population to population-imbalance
occurs as the pairing strength falls below a critical value, accompanied by the
emergence of local Fulde-Ferrell-Larkin-Ovchinnikov (FFLO) like states
characterized by out-of-phase wave functions and lower energies compared to the
YSR states. The negative contribution emanating from the FFLO-like states also
causes a sign change in the gap function within the ULRM potentials. Depending
on the Rydberg state generating the ULRM potentials, the transition towards
population-imbalance can be on either the BCS or the Bose-Einstein condensation
side of the Fermi superfluid. Additionally, spin-polarized bound states arise
along with oscillatory ``clumpy states"" to compensate for the local density
difference. Finally, we discuss possible experimental realizations and
measurements of the composite Rydberg atom-Fermi superfluid system.",http://arxiv.org/abs/2502.09836v1
"Evidence of magnetoelastic coupling and magnetic phase coexistence in
  Mn$_{1.7}$Fe$_{1.3}$Si Heusler Alloy",2025-02-14T04:48:39Z,"Kulbhushan Mishra, Elaine T. Dias, Rajeev Joshi, A. D. Fortes, Christopher M. Howard, Rajeev Rawat, P. A. Bhobe","Noncollinear metallic antiferromagnets, with their rapid spin dynamics,
efficient spin transport, and distinctive spin textures, play a pivotal role in
advancing the field of spintronics. In this study, we report a comprehensive
investigation of the structural, magnetic, and transport properties of cubic
Mn$_{1.7}$Fe$_{1.3}$Si Heusler compound. Temperature-dependent magnetization
measurement reveals a paramagnetic to ferromagnetic transition at $T_C$ = 85 K,
followed by a spin reorientation transition. Neutron diffraction data, analyzed
as a function of temperature, demonstrates that the occurrence of a
spin-reorientation transition is accompanied by magnetoelastic coupling, as
evidenced by a change in unit cell volume below $T_C$. Magnetic structure
refinement of the low-temperature neutron powder diffraction data confirms the
canted antiferromagnetic ordering below 55 K. The metallic nature of the sample
is confirmed by the gradual decrease in the $\rho$(T) with decreasing
temperature. At low temperatures, a field-induced metamgnetic transition is
observed in both, magnetization and magneto-transport measurements. The $H-T$
phase diagram shows a phase-coexistence region emerging at low temperatures for
H $<$ 2.5 T. These findings provide valuable insights into the magnetic and
transport behavior of the Heusler compounds, underscoring their potential for
spintronic applications.",http://arxiv.org/abs/2502.09910v1
"Quantum Schwarzschild-(A)dS Black Holes: Unitarity and Singularity
  Resolution",2025-02-14T11:59:15Z,"Steffen Gielen, Sofie Ried","We consider the canonical quantisation of spherically symmetric spacetimes
within unimodular gravity, leaving sign choices in the metric general enough to
include both the interior and exterior Schwarzschild-(Anti-)de Sitter
spacetime. In unimodular gravity the cosmological constant appears as an
integration constant analogous to a total energy, and the quantum
Wheeler-DeWitt equation takes the form of a Schr\""odinger equation in
unimodular time. We discuss self-adjoint extensions of the Schr\""odinger-like
Hamiltonian arising from the requirement of unitarity in unimodular time, and
identify a physically motivated one-parameter family of extensions. For
semiclassical states we are able to derive analytical expressions for
expectation values of the metric, representing a quantum-corrected, nonsingular
extension of the classical Schwarzschild-(A)dS geometry which describes a
quantum transition between asymptotic black hole and white hole states. The
sign of the self-adjoint extension parameter corresponds to the allowed sign of
the black hole/white hole mass, and so it can be chosen to ensure that this
mass is always positive. We also discuss tunnelling states which allow for a
change in the sign of the mass, but which are not semiclassical in
high-curvature regions. Our mechanism for singularity resolution and the
explicit form of the quantum-corrected metric can be compared to other
proposals for black holes in quantum gravity, and in the asymptotically AdS
case can be contrasted with holographic arguments.",http://arxiv.org/abs/2502.10104v1
Pangraphs as models of higher-order interactions,2025-02-14T13:10:55Z,"Mateusz Iskrzyński, Aleksandra Puchalska, Aleksandra Grzelik, Gökhan Mutlu","Graphs depict pairwise relationships between objects within a system.
Higher-order interactions (HOIs), which involve more than two objects
simultaneously, are common in nature. Such interactions can change the
stability of a complex system. Hypergraphs can represent an HOI as an arbitrary
subset of vertices. However, they fail to capture the specific roles of the
vertices involved, which can be highly asymmetric, particularly in the case of
interaction modifications.
  We introduce pangraphs, a robust and quantitative generalisation of graphs
that accurately captures arbitrarily complex higher-order interactions. We
demonstrate that several higher-order representations proposed in the
literature are specific instances of pangraphs. Additionally, we introduce an
incidence multilayer digraph representation of a pangraph, referred to as Levi
digraph. We adapt degree and Katz centrality measures to the pangraph framework
and show that a consistent generalisation of recursive graph measures cannot be
simplified to a Levi digraph of a pangraph.
  We construct a pangraph for a real-world coffee agroecosystem and compare
Katz centrality between its dihypergraph and pangraph representations, both
analytically and numerically. The choice of representation significantly
affects centrality values and alters vertex ranks. Additionally, we emphasise
the use of real-valued incidence matrices to quantify interaction strengths and
the roles of vertices within the system.",http://arxiv.org/abs/2502.10141v1
DASKT: A Dynamic Affect Simulation Method for Knowledge Tracing,2025-01-18T10:02:10Z,"Xinjie Sun, Kai Zhang, Qi Liu, Shuanghong Shen, Fei Wang, Yuxiang Guo, Enhong Chen","Knowledge Tracing (KT) predicts future performance by modeling students'
historical interactions, and understanding students' affective states can
enhance the effectiveness of KT, thereby improving the quality of education.
Although traditional KT values students' cognition and learning behaviors,
efficient evaluation of students' affective states and their application in KT
still require further exploration due to the non-affect-oriented nature of the
data and budget constraints. To address this issue, we propose a
computation-driven approach, Dynamic Affect Simulation Knowledge Tracing
(DASKT), to explore the impact of various student affective states (such as
frustration, concentration, boredom, and confusion) on their knowledge states.
In this model, we first extract affective factors from students'
non-affect-oriented behavioral data, then use clustering and spatiotemporal
sequence modeling to accurately simulate students' dynamic affect changes when
dealing with different problems. Subsequently, {\color{blue}we incorporate
affect with time-series analysis to improve the model's ability to infer
knowledge states over time and space.} Extensive experimental results on two
public real-world educational datasets show that DASKT can achieve more
reasonable knowledge states under the effect of students' affective states.
Moreover, DASKT outperforms the most advanced KT methods in predicting student
performance. Our research highlights a promising avenue for future KT studies,
focusing on achieving high interpretability and accuracy.",http://arxiv.org/abs/2502.10396v1
"A Novel Multi-Objective Evolutionary Algorithm for Counterfactual
  Generation",2025-02-03T15:50:59Z,"Gabriel Doyle-Finch, Alex A. Freitas","Machine learning algorithms that learn black-box predictive models (which
cannot be directly interpreted) are increasingly used to make predictions
affecting the lives of people. It is important that users understand the
predictions of such models, particularly when the model outputs a negative
prediction for the user (e.g. denying a loan). Counterfactual explanations
provide users with guidance on how to change some of their characteristics to
receive a different, positive classification by a predictive model. For
example, if a predictive model rejected a loan application from a user, a
counterfactual explanation might state: If your salary was {\pounds}50,000
(rather than your current {\pounds}35,000), then your loan would be approved.
This paper proposes two novel contributions: (a) a novel multi-objective
Evolutionary Algorithm (EA) for counterfactual generation based on
lexicographic optimisation, rather than the more popular Pareto dominance
approach; and (b) an extension to the definition of the objective of validity
for a counterfactual, based on measuring the resilience of a counterfactual to
violations of monotonicity constraints which are intuitively expected by users;
e.g., intuitively, the probability of a loan application to be approved would
monotonically increase with an increase in the salary of the applicant.
Experiments involving 15 experimental settings (3 types of black box models
times 5 datasets) have shown that the proposed lexicographic optimisation-based
EA is very competitive with an existing Pareto dominance-based EA; and the
proposed extension of the validity objective has led to a substantial increase
in the validity of the counterfactuals generated by the proposed EA.",http://arxiv.org/abs/2502.10418v1
"Distributed Application Provisioning over Ethereum based private and
  permissioned Blockchain: Availability modeling, capacity, and costs planning",2025-02-14T19:24:06Z,"Carlos Melo, Jamilson Dantas, Paulo Pereira, Paulo Maciel","Blockchain and Cloud Computing are two of the main topics related to the
distributed computing paradigm, and in the last decade, they have seen
exponential growth in their adoption. Cloud computing has long been established
as the main mechanism to test, develop, and deliver new applications and
services in a distributed manner across the World Wide Web. Large data centers
host many services and store petabytes of user data. Infrastructure and
services owners rule the access to data and may even be able to change contents
and attest to its veracity. Blockchain is a step towards a future where the
user's data are considered safer, besides being public. Advances in
blockchain-based technologies, now, support service provisioning over
permissioned and private infrastructures. Therefore, organizations or groups of
individuals may share information, service even if they do not trust each
other, besides supporting infrastructure management tasks. This paper presents
and evaluates models for assessing the availability and capacity-oriented
availability of cloud computing infrastructures. It aims at running
Blockchain's distributed applications based on the Ethereum blockchain platform
and the required expenses to perform service delivery in public and private
infrastructures. Most of the obtained results also apply to other blockchains
based platforms.",http://arxiv.org/abs/2502.10515v1
"A co-segmentation algorithm to predict emotional stress from passively
  sensed mHealth data",2025-02-14T21:18:00Z,"Younghoon Kim, Sumanta Basu, Samprit Banerjee","We develop a data-driven co-segmentation algorithm of passively sensed and
self-reported active variables collected through smartphones to identify
emotionally stressful states in middle-aged and older patients with mood
disorders undergoing therapy, some of whom also have chronic pain. Our method
leverages the association between the different types of time series. These
data are typically non-stationary, with meaningful associations often occurring
only over short time windows. Traditional machine learning (ML) methods, when
applied globally on the entire time series, often fail to capture these
time-varying local patterns. Our approach first segments the passive sensing
variables by detecting their change points, then examines segment-specific
associations with the active variable to identify co-segmented periods that
exhibit distinct relationships between stress and passively sensed measures. We
then use these periods to predict future emotional stress states using standard
ML methods. By shifting the unit of analysis from individual time points to
data-driven segments of time and allowing for different associations in
different segments, our algorithm helps detect patterns that only exist within
short-time windows. We apply our method to detect periods of stress in patient
data collected during ALACRITY Phase I study. Our findings indicate that the
data-driven segmentation algorithm identifies stress periods more accurately
than traditional ML methods that do not incorporate segmentation.",http://arxiv.org/abs/2502.10558v1
"Do We Need to Verify Step by Step? Rethinking Process Supervision from a
  Theoretical Perspective",2025-02-14T22:21:56Z,"Zeyu Jia, Alexander Rakhlin, Tengyang Xie","As large language models have evolved, it has become crucial to distinguish
between process supervision and outcome supervision -- two key reinforcement
learning approaches to complex reasoning tasks. While process supervision
offers intuitive advantages for long-term credit assignment, the precise
relationship between these paradigms has remained an open question.
Conventional wisdom suggests that outcome supervision is fundamentally more
challenging due to the trajectory-level coverage problem, leading to
significant investment in collecting fine-grained process supervision data.
  In this paper, we take steps towards resolving this debate. Our main theorem
shows that, under standard data coverage assumptions, reinforcement learning
through outcome supervision is no more statistically difficult than through
process supervision, up to polynomial factors in horizon. At the core of this
result lies the novel Change of Trajectory Measure Lemma -- a technical tool
that bridges return-based trajectory measure and step-level distribution shift.
Furthermore, for settings with access to a verifier or a rollout capability, we
prove that any policy's advantage function can serve as an optimal process
reward model, providing a direct connection between outcome and process
supervision. These findings suggest that the empirically observed performance
gap -- if any -- between outcome and process supervision likely stems from
algorithmic limitations rather than inherent statistical difficulties,
potentially transforming how we approach data collection and algorithm design
for reinforcement learning.",http://arxiv.org/abs/2502.10581v1
Retrieval-augmented Encoders for Extreme Multi-label Text Classification,2025-02-15T00:30:28Z,"Yau-Shian Wang, Wei-Cheng Chang, Jyun-Yu Jiang, Jiong Zhang, Hsiang-Fu Yu, S. V. N. Vishwanathan","Extreme multi-label classification (XMC) seeks to find relevant labels from
an extremely large label collection for a given text input. To tackle such a
vast label space, current state-of-the-art methods fall into two categories.
The one-versus-all (OVA) method uses learnable label embeddings for each label,
excelling at memorization (i.e., capturing detailed training signals for
accurate head label prediction). In contrast, the dual-encoder (DE) model maps
input and label text into a shared embedding space for better generalization
(i.e., the capability of predicting tail labels with limited training data),
but may fall short at memorization. To achieve generalization and memorization,
existing XMC methods often combine DE and OVA models, which involves complex
training pipelines. Inspired by the success of retrieval-augmented language
models, we propose the Retrieval-augmented Encoders for XMC (RAEXMC), a novel
framework that equips a DE model with retrieval-augmented capability for
efficient memorization without additional trainable parameter. During training,
RAEXMC is optimized by the contrastive loss over a knowledge memory that
consists of both input instances and labels. During inference, given a test
input, RAEXMC retrieves the top-$K$ keys from the knowledge memory, and
aggregates the corresponding values as the prediction scores. We showcase the
effectiveness and efficiency of RAEXMC on four public LF-XMC benchmarks. RAEXMC
not only advances the state-of-the-art (SOTA) DE method DEXML, but also
achieves more than 10x speedup on the largest LF-AmazonTitles-1.3M dataset
under the same 8 A100 GPUs training environments.",http://arxiv.org/abs/2502.10615v1
"Behavior of Ising spins and ecological oscillators on dynamically
  rewired small world networks",2025-02-15T00:59:24Z,"Davi Arrais Nobre, Karen C. Abbott, Jonathan Machta, Alan Hastings","Many ecological populations are known to display a cyclic behavior with
period 2. Previous work has shown that when a metapopulation (group of coupled
populations) with such dynamics is allowed to interact via nearest neighbor
dispersal in two dimensions, it undergoes a phase transition from disordered
(spatially asynchronous) to ordered (spatially synchronous) that falls under
the 2-D Ising universality class. While nearest neighbor dispersal may
satisfactorily describe how most individuals migrate between habitats, we
should expect a small fraction of individuals to venture on a journey to
further locations. We model this behavior by considering ecological oscillators
on dynamically rewired small-world networks, in which at each time step a
fraction $p$ of the nearest neighbor interactions is replaced by a new
interaction with a random node on the network. We measure how this connectivity
change affects the critical point for synchronizing ecological oscillators. Our
results indicate that increasing the amount of long-range interaction
(increasing $p$) favors the ordered regime, but the presence of memory in
ecological oscillators leads to quantitative differences in how much long-range
dispersal is needed to order the network, relative to an analogous network of
Ising spins. We also show that, even for very small values of $p$, the phase
transition falls into the mean-field universality class, and argue that
ecosystems where dispersal can occasionally happen across the system's length
scale will display a phase transition in the mean-field universality class.",http://arxiv.org/abs/2502.10619v1
Wrapping nonspherical vesicles at bio-membranes,2025-02-15T11:13:31Z,"Ajit Kumar Sahu, Rajkumar Malik, Jiarul Midya","The wrapping of particles and vesicles by lipid bilayer membranes is a
fundamental process in cellular transport and targeted drug delivery. Here, we
investigate the wrapping behavior of nonspherical vesicles, such as
ellipsoidal, prolate, oblate, and stomatocytes, by systematically varying the
bending rigidity of the vesicle membrane and the tension of the planar
membrane. Using the Helfrich Hamiltonian, triangulated membrane models, and
energy minimization techniques, we predict multiple stable wrapping states and
identify the conditions for their coexistence. Our results demonstrate that
softer vesicles bind more easily to planar membranes; however, achieving
complete wrapping requires significantly higher adhesion strengths compared to
rigid particles. As membrane tension increases, deep-wrapped states disappear
at a triple point where shallow-wrapped, deep-wrapped, and complete-wrapped
states coexist. The coordinates of the triple point are highly sensitive to the
vesicle shape and stiffness. For stomatocytes, increasing stiffness shifts the
triple point to higher adhesion strengths and membrane tensions, while for
oblates it shifts to lower values, influenced by shape changes during wrapping.
Oblate shapes are preferred in shallow-wrapped states and stomatocytes in
deep-wrapped states. In contrast to hard particles, where optimal adhesion
strength for complete wrapping occurs at tensionless membranes, complete
wrapping of soft vesicles requires finite membrane tension for optimal adhesion
strength. These findings provide new insights into the interplay between
vesicle deformability, shape, and membrane properties, advancing our
understanding of endocytosis and the design of advanced biomimetic delivery
systems.",http://arxiv.org/abs/2502.10767v1
"Epidemic-guided deep learning for spatiotemporal forecasting of
  Tuberculosis outbreak",2025-02-15T12:39:42Z,"Madhab Barman, Madhurima Panja, Nachiketa Mishra, Tanujit Chakraborty","Tuberculosis (TB) remains a formidable global health challenge, driven by
complex spatiotemporal transmission dynamics and influenced by factors such as
population mobility and behavioral changes. We propose an Epidemic-Guided Deep
Learning (EGDL) approach that fuses mechanistic epidemiological principles with
advanced deep learning techniques to enhance early warning systems and
intervention strategies for TB outbreaks. Our framework is built upon a
networked Susceptible-Infectious-Recovered (SIR) model augmented with a
saturated incidence rate and graph Laplacian diffusion, capturing both
long-term transmission dynamics and region-specific population mobility
patterns. Compartmental model parameters are rigorously estimated using
Bayesian inference via the Markov Chain Monte Carlo (MCMC) approach.
Theoretical analysis leveraging the comparison principle and Green's formula
establishes global stability properties of the disease-free and endemic
equilibria. Building on these epidemiological insights, we design two
forecasting architectures, EGDL-Parallel and EGDL-Series, that integrate the
mechanistic outputs of the networked SIR model within deep neural networks.
This integration mitigates the overfitting risks commonly encountered in
data-driven methods and filters out noise inherent in surveillance data,
resulting in reliable forecasts of real-world epidemic trends. Experiments
conducted on TB incidence data from 47 prefectures in Japan demonstrate that
our approach delivers robust and accurate predictions across multiple time
horizons (short to medium-term forecasts). Additionally, incorporating
uncertainty quantification through conformal prediction enhances the model's
practical utility for guiding targeted public health interventions.",http://arxiv.org/abs/2502.10786v1
Metal Ions based Dynamic Nuclear Polarization: MI-DNP,2025-02-15T14:57:59Z,"Daniel Jardon- Alvarez, Michal Leskes","Over the last two decades magic angle spinning dynamic nuclear polarization
(MAS DNP) has revolutionized NMR for materials characterization, tackling its
main limitation of intrinsically low sensitivity. Progress in theoretical
understanding, instrumentation, and sample formulation expanded the range of
materials applications and research questions that can benefit from MAS DNP.
Currently the most common approach for hyperpolarization under MAS consists in
impregnating the sample of interest with a solution containing nitroxide
radicals, which upon microwave irradiation serve as exogenous polarizing
agents. On the other hand, in metal ion based (MI)-DNP, inorganic materials are
doped with paramagnetic metal centres, which then can be used as endogenous
polarizing agents. In this work we give an overview of the electron
paramagnetic resonance (EPR) concepts required to characterize the metal ions
and discuss the expected changes in the NMR response due to the presence of
paramagnetic species. We highlight which properties of the electron spins are
beneficial for applications as polarizing agents in DNP and how to recognize
them, both from the EPR and NMR data. A theoretical description of the main DNP
mechanisms is given, employing a quantum mechanical formalism, and these
concepts are used to explain the spin dynamics observed in the DNP experiment.
In addition, we highlight the main differences between MI-DNP and the more
common approaches in MAS DNP, which use organic radicals as exogenous
polarizing source. Finally, we review some applications of metal ions as
polarizing agents in general and then focus particularly on research questions
in materials science that can benefit from MI-DNP.",http://arxiv.org/abs/2502.10824v1
"Enhancing catalyst activity of two-dimensional C$_4$N$_2$ through doping
  for the hydrogen evolution reaction",2025-02-15T17:23:17Z,"Bruno Ipaves, João F. Justo, James M. de Almeida, Lucy V. C. Assali, Pedro Alves da Silva Autreto","This study investigates the structural, electronic, and catalytic properties
of pristine and doped C$_4$N$_2$ nanosheets as potential electrocatalysts for
the hydrogen evolution reaction. The pristine C$_{36}$N$_{18}$ nanosheets
exhibit limited HER activity, primarily due to high positive Gibbs free
energies ($>$ 2.2 eV). To enhance catalytic performance, doping with B, Si, or
P at the nitrogen site was explored. Among these systems, B-doped
C$_{36}$N$_{17}$ nanosheets exhibit the most promising catalytic activity, with
a Gibbs free energy close to zero ($\approx -0.2$ eV), indicating efficient
hydrogen adsorption. Band structure, projected density of states, charge
density, and Bader charge analyses reveal significant changes in the electronic
environment due to doping. While stacking configurations (AA$'$A$''$ and ABC)
have minimal effect on catalytic performance, doping -- particularly with B --
substantially alters the electronic structure, optimizing hydrogen adsorption
and facilitating efficient HER. These findings suggest that B-doped
C$_{36}$N$_{17}$ nanosheets could serve as efficient cocatalysts when combined
with metallic materials, offering a promising approach to enhance catalytic
efficiency in electrocatalytic and photocatalytic applications.",http://arxiv.org/abs/2502.10863v1
"The Impact of Bars, Spirals and Bulge-Size on Gas-Phase Metallicity
  Gradients in MaNGA Galaxies",2025-02-15T22:46:59Z,"M. E. Wisz, Karen L. Masters, Kathryne J. Daniel, David V. Stark, Francesco Belfiore","As galaxies evolve over time, the orbits of their constituent stars are
expected to change in size and shape, moving stars away from their birth
radius. Radial gas flows are also expected. Spiral arms and bars in galaxies
are predicted to help drive this radial relocation, which may be possible to
trace observationally via a flattening of metallicity gradients. We use data
from the Mapping Nearby Galaxies at Apache Point Observatory (MaNGA) survey,
part of the fourth phase of the Sloan Digital Sky Surveys (SDSS-IV), to look
for correlations of the steepness of gas-phase metallicity gradients with
various galaxy morphological features (e.g. presence and pitch angle of spiral
arms, presence of a large scale bar, bulge size). We select from MaNGA a sample
of star forming galaxies for which gas phase metallicity trends can be
measured, and use morphologies from Galaxy Zoo. We observe that at fixed galaxy
mass (1) the presence of spiral structure correlates with steeper gas phase
metallicity gradients; (2) spiral galaxies with larger bulges have both higher
gas-phase metallicities and shallower gradients; (3) there is no observable
difference with azimuthally averaged radial gradients between barred and
unbarred spirals and (4) there is no observable difference in gradient between
tight and loosely wound spirals, but looser wound spirals have lower average
gas-phase metallicity values at fixed mass. We discuss the possible
implications of these observational results.",http://arxiv.org/abs/2502.10922v1
"Itinerant topological magnons and spin excitons in twisted transition
  metal dichalcogenides: Mapping electron topology to spin counterpart",2025-02-16T04:39:46Z,"Wei-Tao Zhou, Zhao-Yang Dong, Zhao-Long Gu, Jian-Xin Li","Twisted transition metal dichalcogenides (tTMDs) provide a highly tunable
platform to explore the interplay between strong correlation and topology.
Among them, the properties involving the charge degree of freedom have been
extensively studied, while those related to spin are much less investigated.
Motivated by the recent discovery of integer and fractional quantum anomalous
Hall effects in tMoTe$_2$, where the flat-band ferromagnetism is one of the
essential prerequisites, we investigate theoretically the spin excitations out
of the flat-band ferromagnetic ground state in tMoTe$_2$. Remarkably, we
identify the itinerant magnons and spin excitons with nontrivial topology. We
elaborate that the topology of these itinerant spin excitations, which are
described as particle-hole bound states, inherits directly from that of the
underlying electrons and is essentially different from that in local spin
systems. Thus, we establish a direct relationship of the topology between the
many-body excitations and their fundamental constituents. We further
demonstrate that by tuning the displacement field, a topological transition for
both the magnon and spin exciton happens, leading to a step-like change and
bifurcation in the thermal Hall conductance, which could serve as unique and
compelling evidence to be tested experimentally.",http://arxiv.org/abs/2502.10991v1
Organometallic-Inorganic Hybrid MXenes with Tunable Superconductivity,2025-02-16T08:27:24Z,"Qi Fan, Tao Bo, Wei Guo, Minghua Chen, Qing Tang, Yicong Yang, Mian Li, Ke Chen, Fangfang Ge, Jialu Li, Sicong Qiao, Changda Wang, Li Song, Lijing Yu, Jinghua Guo, Michael Naguib, Zhifang Chai, Qing Huang, Chaochao Dun, Ning Kang, Yury Gogotsi, Kun Liang","Ti-based two-dimensional transition-metal carbides (MXenes) have attracted
attention due to their superior properties and are being explored across
various applications1,2. Despite their versatile properties, superconductivity
has never been demonstrated, not even predicted, for this important group of 2D
materials. In this work, we have introduced an electrochemical intercalation
protocol to construct versatile organometallic-inorganic hybrid MXenes and
achieved tunable superconductivity in the metallocene-modified layered
crystals. Through structural editing of MXene matrix at atomic scale and
meticulously modulated intercalation route, Ti3C2Tx intercalated with
metallocene species exhibits a superconductive transition temperature (Tc) of
10.2 K. Guest intercalation induced electron filling and strain engineering are
responsible for the emerging superconductivity in this intrinsically
non-superconducting material. Theoretically, simulated electron-phonon
interaction effects further elucidate the nature of the changes in Tc.
Furthermore, the Tc of crafted artificial superlattices beyond Ti-based MXenes
have been predicted, offering a general strategy for engineering
superconductivity and magnetism in layered hybrid materials.",http://arxiv.org/abs/2502.11035v1
"ClimateLLM: Efficient Weather Forecasting via Frequency-Aware Large
  Language Models",2025-02-16T09:57:50Z,"Shixuan Li, Wei Yang, Peiyu Zhang, Xiongye Xiao, Defu Cao, Yuehan Qin, Xiaole Zhang, Yue Zhao, Paul Bogdan","Weather forecasting is crucial for public safety, disaster prevention and
mitigation, agricultural production, and energy management, with global
relevance. Although deep learning has significantly advanced weather
prediction, current methods face critical limitations: (i) they often struggle
to capture both dynamic temporal dependencies and short-term abrupt changes,
making extreme weather modeling difficult; (ii) they incur high computational
costs due to extensive training and resource requirements; (iii) they have
limited adaptability to multi-scale frequencies, leading to challenges when
separating global trends from local fluctuations. To address these issues, we
propose ClimateLLM, a foundation model for weather forecasting. It captures
spatiotemporal dependencies via a cross-temporal and cross-spatial
collaborative modeling framework that integrates Fourier-based frequency
decomposition with Large Language Models (LLMs) to strengthen spatial and
temporal modeling. Our framework uses a Mixture-of-Experts (MoE) mechanism that
adaptively processes different frequency components, enabling efficient
handling of both global signals and localized extreme events. In addition, we
introduce a cross-temporal and cross-spatial dynamic prompting mechanism,
allowing LLMs to incorporate meteorological patterns across multiple scales
effectively. Extensive experiments on real-world datasets show that ClimateLLM
outperforms state-of-the-art approaches in accuracy and efficiency, as a
scalable solution for global weather forecasting.",http://arxiv.org/abs/2502.11059v1
"Mixture of Tunable Experts -- Behavior Modification of DeepSeek-R1 at
  Inference Time",2025-02-16T12:24:39Z,"Robert Dahlke, Henrik Klagges, Dan Zecha, Benjamin Merkel, Sven Rohr, Fabian Klemm","We present the Mixture-of-Tunable-Experts (MoTE), a method that extends the
Mixture-of-Experts architecture of Large Language Models (LLMs). Without
additional training, MoTE enables meaningful and focused behavior changes in
LLMs on-the-fly during inference time. By analyzing the digital LLM brain of
DeepSeek-R1 using a technique we dub 'functional Token Resonance Imaging'
(fTRI) -- inspired by fMRI and using prompts designed to elicit specific
behavior (e.g., 'What happened {time}{place}?') -- we empirically identify
distinctive experts associated with behaviors like refusal responses. Using
MoTE we are able to intervene and control such specific behavior. We switched
off the top 10 most refusal-relevant experts (0.07% of R1's 14,848 routed
experts), achieving a 52% refusal reduction on sensitive reference prompts
without performance degradation on MT-Bench. Random expert deactivation
resulted in smaller behavioral shifts with increased noise, whereas forced
expert activation led to significantly higher refusal rates. Our approach
shares similarities with sparse autoencoders (SAEs) in terms of explainability
and steerability. Unlike SAEs, MoTE does not require large training efforts, as
within MoEs with a vast number of experts, specialization already emerged
naturally during pretraining. Our findings suggest that significant functional
mechanisms in Mixture-of-Experts architectures can at least partially be
localized in a small number of specific experts, rather than being distributed
throughout the model's weights. Expert subgroups can be tuned to trigger
significant behavior variations, providing insights into the inner workings of
LLMs.",http://arxiv.org/abs/2502.11096v1
"Consistency of heritability estimation from summary statistics in
  high-dimensional linear models",2025-02-16T14:26:14Z,"David Azriel, Samuel Davenport, Armin Schwartzman","In Genome-Wide Association Studies (GWAS), heritability is defined as the
fraction of variance of an outcome explained by a large number of genetic
predictors in a high-dimensional polygenic linear model. This work studies the
asymptotic properties of the most common estimator of heritability from summary
statistics called linkage disequilibrium score (LDSC) regression, together with
a simpler and closely related estimator called GWAS heritability (GWASH). These
estimators are analyzed in their basic versions and under various modifications
used in practice including weighting and standardization. We show that, with
some variations, two conditions which we call weak dependence (WD) and
bounded-kurtosis effects (BKE) are sufficient for consistency of both the basic
LDSC with fixed intercept and GWASH estimators, for both Gaussian and
non-Gaussian predictors. For Gaussian predictors it is shown that these
conditions are also necessary for consistency of GWASH (with truncation) and
simulations suggest that necessity holds too when the predictors are
non-Gaussian. We also show that, with properly truncated weights, weighting
does not change the consistency results, but standardization of the predictors
and outcome, as done in practice, introduces bias in both LDSC and GWASH if the
two essential conditions are violated. Finally, we show that, when population
stratification is present, all the estimators considered are biased, and the
bias is not remedied by using the LDSC regression estimator with free
intercept, as originally suggested by the authors of that estimator.",http://arxiv.org/abs/2502.11144v1
"Setting the Course, but Forgetting to Steer: Analyzing Compliance with
  GDPR's Right of Access to Data by Instagram, TikTok, and YouTube",2025-02-16T17:15:11Z,"Sai Keerthana Karnam, Abhisek Dash, Sepehr Mousavi, Stefan Bechtold, Krishna P. Gummadi, Animesh Mukherjee, Ingmar Weber, Savvas Zannettou","The comprehensibility and reliability of data download packages (DDPs)
provided under the General Data Protection Regulation's (GDPR) right of access
are vital for both individuals and researchers. These DDPs enable users to
understand and control their personal data, yet issues like complexity and
incomplete information often limit their utility. Also, despite their growing
use in research to study emerging online phenomena, little attention has been
given to systematically assessing the reliability and comprehensibility of
DDPs.
  To bridge this research gap, in this work, we perform a comparative analysis
to assess the comprehensibility and reliability of DDPs provided by three major
social media platforms, namely, TikTok, Instagram, and YouTube. By recruiting
400 participants across four countries, we assess the comprehensibility of DDPs
across various requirements, including conciseness, transparency,
intelligibility, and clear and plain language. Also, by leveraging automated
bots and user-donated DDPs, we evaluate the reliability of DDPs across the
three platforms. Among other things, we find notable differences across the
three platforms in the data categories included in DDPs, inconsistencies in
adherence to the GDPR requirements, and gaps in the reliability of the DDPs
across platforms. Finally, using large language models, we demonstrate the
feasibility of easily providing more comprehensible DDPs.",http://arxiv.org/abs/2502.11208v1
Stochastic Optimization of Inventory at Large-scale Supply Chains,2025-02-16T17:25:50Z,"Zhaoyang Larry Jin, Mehdi Maasoumy, Yimin Liu, Zeshi Zheng, Zizhuo Ren","Today's global supply chains face growing challenges due to rapidly changing
market conditions, increased network complexity and inter-dependency, and
dynamic uncertainties in supply, demand, and other factors. To combat these
challenges, organizations employ Material Requirements Planning (MRP) software
solutions to set inventory stock buffers - for raw materials, work-in-process
goods, and finished products - to help them meet customer service levels.
However, holding excess inventory further complicates operations and can lock
up millions of dollars of capital that could be otherwise deployed.
Furthermore, most commercially available MRP solutions fall short in
considering uncertainties and do not result in optimal solutions for modern
enterprises.
  At C3 AI, we fundamentally reformulate the inventory management problem as a
constrained stochastic optimization. We then propose a simulation-optimization
framework that minimizes inventory and related costs while maintaining desired
service levels. The framework's goal is to find the optimal reorder parameters
that minimize costs subject to a pre-defined service-level constraint and all
other real-world operational constraints. These optimal reorder parameters can
be fed back into an MRP system to drive optimal order placement, or used to
place optimal orders directly. This approach has proven successful in reducing
inventory levels by 10-35 percent, resulting in hundreds of millions of dollars
of economic benefit for major enterprises at a global scale.",http://arxiv.org/abs/2502.11213v1
"Uncertainty-permitting machine learning reveals sources of dynamic sea
  level predictability across daily-to-seasonal timescales",2025-02-16T22:33:49Z,"Andrew Brettin, Laure Zanna, Elizabeth A. Barnes","Reliable dynamic sea level forecasts are hindered by numerous sources of
uncertainty on daily-to-seasonal timescales (1-180 days) due to atmospheric
boundary conditions and internal ocean variability. Studies have demonstrated
that certain initial states can extend predictability horizons; thus,
identifying these initial conditions may help improve forecast skill. Here, we
identify sources of dynamic sea level predictability on daily-to-seasonal
timescales using neural networks trained on CESM2 large ensemble data to
forecast dynamic sea level. The forecasts yield not only a point estimate for
sea level but also a standard deviation to quantify forecast uncertainty based
on the initial conditions. Forecasted uncertainties can be leveraged to
identify state-dependent sources of predictability at most locations and
forecast leads. Network forecasts, particularly in the low-latitude
Indo-Pacific, exhibit skillful deterministic predictions and skillfully
forecast exceedance probabilities relative to local linear baselines. For
networks trained at Guam and in the western Indian Ocean, the transfer of
sources of predictability from local sources to remote sources is presented by
the deteriorating utility of initial condition information for predicting
exceedance events. Propagating Rossby waves are identified as a potential
source of predictability for dynamic sea level at Guam. In the Indian Ocean,
persistence of thermosteric sea level anomalies from the Indian Ocean Dipole
may be a source of predictability on subseasonal timescales, but El Ni\~no
drives predictability on seasonal timescales. This work shows how
uncertainty-quantifying machine learning can help identify changes in sources
of state-dependent predictability over a range of forecast leads.",http://arxiv.org/abs/2502.11293v1
Tunnels Under Geometries (or Instantons Know Their Algebras),2025-02-16T22:34:09Z,"Dmitry Galakhov, Alexei Morozov","In the tight binding model with multiple degenerate vacua we might treat wave
function overlaps as instanton tunnelings between different wells (vacua). An
amplitude for such a tunneling process might be constructed as
$\mathsf{T}_{i\to j}\sim e^{-S_{\mathrm{
inst}}}{\mathbf{v}}_j^{+}{\mathbf{v}}_i^{-}$, where there is canonical
instanton action suppression, and $\mathbf{v}_i^{-}$ annihilates a particle in
the $i^{\mathrm{th}}$ vacuum, whereas $\mathbf{v}_j^{+}$ creates a particle in
the $j^{\mathrm{th}}$ vacuum. Adiabatic change of the wells leads to a
Berry-phase evolution of the couplings, which is described by the
zero-curvature Gauss-Manin connection i.e. by a quantum $R$-matrix.
Zero-curvature is actually a consequence of level repulsion or topological
protection, and its implication is the Yang-Baxter relation for the
$R$-matrices. In the simplest case the story is pure Abelian and not very
exciting. But when the model becomes more involved, incorporates supersymmetry,
gauge and other symmetries, such amplitudes obtain more intricate structures.
Operators $\mathbf{v}_i^{-}$, $\mathbf{v}_j^{+}$ might also evolve from
ordinary Heisenberg operators into a more sophisticated algebraic object -- a
``tunneling algebra''. The result for the tunneling algebra would depend
strongly on geometry of the QFT we started with, and, unfortunately, at the
moment we are unable to solve the reverse engineering problem. In this note we
revise few successful cases of the aforementioned correspondence: quantum
algebras $U_q(\mathfrak{g})$ and affine Yangians $Y(\hat{\mathfrak{g}})$. For
affine Yangians we demonstrate explicitly how instantons ``perform''
equivariant integrals over associated quiver moduli spaces appearing in the
alternative geometric construction.",http://arxiv.org/abs/2502.11294v1
AI Generations: From AI 1.0 to AI 4.0,2025-02-16T23:19:44Z,"Jiahao Wu, Hengxu You, Jing Du","This paper proposes that Artificial Intelligence (AI) progresses through
several overlapping generations: AI 1.0 (Information AI), AI 2.0 (Agentic AI),
AI 3.0 (Physical AI), and now a speculative AI 4.0 (Conscious AI). Each of
these AI generations is driven by shifting priorities among algorithms,
computing power, and data. AI 1.0 ushered in breakthroughs in pattern
recognition and information processing, fueling advances in computer vision,
natural language processing, and recommendation systems. AI 2.0 built on these
foundations through real-time decision-making in digital environments,
leveraging reinforcement learning and adaptive planning for agentic AI
applications. AI 3.0 extended intelligence into physical contexts, integrating
robotics, autonomous vehicles, and sensor-fused control systems to act in
uncertain real-world settings. Building on these developments, AI 4.0 puts
forward the bold vision of self-directed AI capable of setting its own goals,
orchestrating complex training regimens, and possibly exhibiting elements of
machine consciousness. This paper traces the historical foundations of AI
across roughly seventy years, mapping how changes in technological bottlenecks
from algorithmic innovation to high-performance computing to specialized data,
have spurred each generational leap. It further highlights the ongoing
synergies among AI 1.0, 2.0, 3.0, and 4.0, and explores the profound ethical,
regulatory, and philosophical challenges that arise when artificial systems
approach (or aspire to) human-like autonomy. Ultimately, understanding these
evolutions and their interdependencies is pivotal for guiding future research,
crafting responsible governance, and ensuring that AI transformative potential
benefits society as a whole.",http://arxiv.org/abs/2502.11312v1
Flavor dependence of Energy-energy correlators,2025-02-17T03:46:15Z,"Liliana Apolinário, Raghav Kunnawalkam Elayavalli, Nuno Olavo Madureira, Jun-Xing Sheng, Xin-Nian Wang, Zhong Yang","Energy-energy correlators (EECs) within high energy jets serve as a key
experimentally accessible quantity to probe the scale and structure of the
quark-gluon plasma (QGP) in relativistic heavy-ion collisions. The CMS
Collaboration's first measurement of the modification to the EEC within single
inclusive jets in Pb+Pb collisions relative to p+p collisions reveals a
significant enhancement at small angles, which may arise from jet transverse
momentum $p_T$ selection biases due to jet energy loss. We investigate the
dependence of jet EECs on the flavor of the initiating parton. The EEC
distribution of a gluon jet is broader and the peak of transition from
perturbative to non-perturbative regime occurs at a larger angle than a quark
jet. Such flavor dependence leads to the different EECs for $\gamma$-jets and
single inclusive jets due to their different flavor composition. It is also
responsible for a colliding energy dependence of EECs of single inclusive jets
at fixed jet energy. We also investigate the impact of flavor composition
variation on the $p_T$ dependence of the jet EEC. We further propose that a
change in the gluon jet fraction in A+A collisions compared to p+p can also
contribute to a non-negligible enhancement of the medium modified EEC at small
angles. Using the \textsc{Jewel} model, we predict the reduction of the gluon
jet fraction in A+A collisions and estimate its impact on the EEC.",http://arxiv.org/abs/2502.11406v1
"High Quality Single Crystal of Kitaev Spin Liquid Candidate Material
  RuBr3 Synthesized under High Pressure",2025-02-17T06:30:30Z,"Bowen Zhang, Xiangjun Li, Limin Yan, Wenbo Li, Nana Li, Jianfa Zhao, Xiaobing Liu, Shun-Li Yu, Zhiwei Hu, Wenge Yang, Runze Yu","Kitaev quantum spin liquids have attracted significant attention in condensed
matter physics over the past decade. To understand their emergent quantum
phenomena, high-quality single crystals of substantial size are essential.
Here, we report the synthesis of single crystals of the Kitaev quantum spin
liquid candidate RuBr3, achieving millimeter-sized crystals through a self-flux
method under high pressure and high temperature conditions. The crystals
exhibit well-defined cleavage planes with a lustrous appearance. Transport
characterizations exhibit a narrow band-gap semiconducting behavior with 0.13
eV and 0.11 eV band-gap in ab plane and along c axis, respectively. Magnetic
measurement shows a transition to antiferromagnetic (AFM) state at
approximately 29 K both in ab plane and along c axis. Notably, the N\'eel
temperature increases to 34 K with an applied magnetic field of up to 7 T in
the ab plane, but without any change along c axis. The large size and high
quality of RuBr3 single crystals provide a valuable platform for investigating
various interactions, particularly the Kitaev interaction, and for elucidating
the intrinsic physical properties of Kitaev quantum spin liquids.",http://arxiv.org/abs/2502.11479v1
"Variable-frame CNNLSTM for Breast Nodule Classification using Ultrasound
  Videos",2025-02-17T06:35:37Z,"Xiangxiang Cui, Zhongyu Li, Xiayue Fan, Peng Huang, Ying Wang, Meng Yang, Shi Chang, Jihua Zhu","The intersection of medical imaging and artificial intelligence has become an
important research direction in intelligent medical treatment, particularly in
the analysis of medical images using deep learning for clinical diagnosis.
Despite the advances, existing keyframe classification methods lack extraction
of time series features, while ultrasonic video classification based on
three-dimensional convolution requires uniform frame numbers across patients,
resulting in poor feature extraction efficiency and model classification
performance. This study proposes a novel video classification method based on
CNN and LSTM, introducing NLP's long and short sentence processing scheme into
video classification for the first time. The method reduces CNN-extracted image
features to 1x512 dimension, followed by sorting and compressing feature
vectors for LSTM training. Specifically, feature vectors are sorted by patient
video frame numbers and populated with padding value 0 to form variable
batches, with invalid padding values compressed before LSTM training to
conserve computing resources. Experimental results demonstrate that our
variable-frame CNNLSTM method outperforms other approaches across all metrics,
showing improvements of 3-6% in F1 score and 1.5% in specificity compared to
keyframe methods. The variable-frame CNNLSTM also achieves better accuracy and
precision than equal-frame CNNLSTM. These findings validate the effectiveness
of our approach in classifying variable-frame ultrasound videos and suggest
potential applications in other medical imaging modalities.",http://arxiv.org/abs/2502.11481v1
"Anti-Degeneracy Scheme for Lidar SLAM based on Particle Filter in
  Geometry Feature-Less Environments",2025-02-17T06:42:28Z,"Yanbin Li, Wei Zhang, Zhiguo Zhang, Xiaogang Shi, Ziruo Li, Mingming Zhang, Hongping Xie, Wenzheng Chi","Simultaneous localization and mapping (SLAM) based on particle filtering has
been extensively employed in indoor scenarios due to its high efficiency.
However, in geometry feature-less scenes, the accuracy is severely reduced due
to lack of constraints. In this article, we propose an anti-degeneracy system
based on deep learning. Firstly, we design a scale-invariant linear mapping to
convert coordinates in continuous space into discrete indexes, in which a data
augmentation method based on Gaussian model is proposed to ensure the model
performance by effectively mitigating the impact of changes in the number of
particles on the feature distribution. Secondly, we develop a degeneracy
detection model using residual neural networks (ResNet) and transformer which
is able to identify degeneracy by scrutinizing the distribution of the particle
population. Thirdly, an adaptive anti-degeneracy strategy is designed, which
first performs fusion and perturbation on the resample process to provide rich
and accurate initial values for the pose optimization, and use a hierarchical
pose optimization combining coarse and fine matching, which is able to
adaptively adjust the optimization frequency and the sensor trustworthiness
according to the degree of degeneracy, in order to enhance the ability of
searching the global optimal pose. Finally, we demonstrate the optimality of
the model, as well as the improvement of the image matrix method and GPU on the
computation time through ablation experiments, and verify the performance of
the anti-degeneracy system in different scenarios through simulation
experiments and real experiments. This work has been submitted to IEEE for
publication. Copyright may be transferred without notice, after which this
version may no longer be available.",http://arxiv.org/abs/2502.11486v1
"Learning to Keep a Promise: Scaling Language Model Decoding Parallelism
  with Learned Asynchronous Decoding",2025-02-17T07:39:16Z,"Tian Jin, Ellie Y. Cheng, Zack Ankner, Nikunj Saunshi, Blake M. Elias, Amir Yazdanbakhsh, Jonathan Ragan-Kelley, Suvinay Subramanian, Michael Carbin","Decoding with autoregressive large language models (LLMs) traditionally
occurs sequentially, generating one token after another. An emerging line of
work explored parallel decoding by identifying and simultaneously generating
semantically independent chunks of LLM responses. However, these techniques
rely on hand-crafted heuristics tied to syntactic structures like lists and
paragraphs, making them rigid and imprecise. We present PASTA, a learning-based
system that teaches LLMs to identify semantic independence and express parallel
decoding opportunities in their own responses. At its core are PASTA-LANG and
its interpreter: PASTA-LANG is an annotation language that enables LLMs to
express semantic independence in their own responses; the language interpreter
acts on these annotations to orchestrate parallel decoding on-the-fly at
inference time. Through a two-stage finetuning process, we train LLMs to
generate PASTA-LANG annotations that optimize both response quality and
decoding speed. Evaluation on AlpacaEval, an instruction following benchmark,
shows that our approach Pareto-dominates existing methods in terms of decoding
speed and response quality; our results demonstrate geometric mean speedups
ranging from 1.21x to 1.93x with corresponding quality changes of +2.2% to
-7.1%, measured by length-controlled win rates against sequential decoding
baseline.",http://arxiv.org/abs/2502.11517v1
DeFiScope: Detecting Various DeFi Price Manipulations with LLM Reasoning,2025-02-17T07:45:03Z,"Juantao Zhong, Daoyuan Wu, Ye Liu, Maoyi Xie, Yang Liu, Yi Li, Ning Liu","DeFi (Decentralized Finance) is one of the most important applications of
today's cryptocurrencies and smart contracts. It manages hundreds of billions
in Total Value Locked (TVL) on-chain, yet it remains susceptible to common DeFi
price manipulation attacks. Despite state-of-the-art (SOTA) systems like
DeFiRanger and DeFort, we found that they are less effective to non-standard
price models in custom DeFi protocols, which account for 44.2% of the 95 DeFi
price manipulation attacks reported over the past three years.
  In this paper, we introduce the first LLM-based approach, DeFiScope, for
detecting DeFi price manipulation attacks in both standard and custom price
models. Our insight is that large language models (LLMs) have certain
intelligence to abstract price calculation from code and infer the trend of
token price changes based on the extracted price models. To further strengthen
LLMs in this aspect, we leverage Foundry to synthesize on-chain data and use it
to fine-tune a DeFi price-specific LLM. Together with the high-level DeFi
operations recovered from low-level transaction data, DeFiScope detects various
DeFi price manipulations according to systematically mined patterns.
Experimental results show that DeFiScope achieves a high precision of 96% and a
recall rate of 80%, significantly outperforming SOTA approaches. Moreover, we
evaluate DeFiScope's cost-effectiveness and demonstrate its practicality by
helping our industry partner confirm 147 real-world price manipulation attacks,
including discovering 81 previously unknown historical incidents.",http://arxiv.org/abs/2502.11521v1
"Fluctuation-dissipation theorems for multi-phase flow with memory in
  porous media",2025-02-17T08:08:38Z,"Dick Bedeaux, Signe Kjelstrup, Steffen Berg, Umar Alfazazi, Ryan T. Armstrong","Recent works have reported on the collective behavior of multiphase systems
under fractional flow. Such behavior has been linked to pressure and/or flux
fluctuations under stationary flow conditions that occur over a broad range of
resonance frequencies and associated relaxation times. However, there currently
exists no theoretical development to deal with such phenomena. The aim of this
paper is to develop a fundamental theory that can describe such behavior.
Fluctuation-dissipation theorems for the case with memory are formulated,
providing a new route to obtain frequency-dependent porous media permeability.
  We propose that multiphase flow systems can be explained by a multipeak
Lorentzian memory function and provide supporting experimental data from the
flow of decane and water in a porous medium made of glass beads. Our
fluctuation dissipation theorems provide information on different types of
relaxation phenomena and resonance frequencies that occur during fractional
flow. We show, using experimental data, that Green-Kubo-like expressions can be
formulated for two-phase fluid flow driven by a constant pressure drop. The
resulting autocorrelation functions, or rather their Fourier transforms,
exhibit multiple Lorentzian peak shapes. Resonances are similar to those of
electric conductance. The analysis offers a new route to steady-state relative
permeability measurements, including information on the relaxation times and
resonance regimes that exist during fractional flow. Overall, the theory
presented and supported by fractional flow experiments provides a rich set of
possible directions for future developments that could fundamentally change the
way multiphase flow systems are understood and studied.",http://arxiv.org/abs/2502.11539v1
Calibration of Vehicular Traffic Simulation Models by Local Optimization,2025-02-17T09:17:01Z,"Davide Andrea Guastella, Alejandro Morales-Hernàndez, Bruno Cornelis, Gianluca Bontempi","Simulation is a valuable tool for traffic management experts to assist them
in refining and improving transportation systems and anticipating the impact of
possible changes in the infrastructure network before their actual
implementation. Calibrating simulation models using traffic count data is
challenging because of the complexity of the environment, the lack of data, and
the uncertainties in traffic dynamics. This paper introduces a novel stochastic
simulation-based traffic calibration technique. The novelty of the proposed
method is: (i) it performs local traffic calibration, (ii) it allows
calibrating simulated traffic in large-scale environments, (iii) it requires
only the traffic count data. The local approach enables decentralizing the
calibration task to reach near real-time performance, enabling the fostering of
digital twins. Using only traffic count data makes the proposed method generic
so that it can be applied in different traffic scenarios at various scales
(from neighborhood to region). We assess the proposed technique on a model of
Brussels, Belgium, using data from real traffic monitoring devices. The
proposed method has been implemented using the open-source traffic simulator
SUMO. Experimental results show that the traffic model calibrated using the
proposed method is on average 16% more accurate than those obtained by the
state-of-the-art methods, using the same dataset. We also make available the
output traffic model obtained from real data.",http://arxiv.org/abs/2502.11585v1
"Reduction of Magnetic-Field-Induced Shift in Quantum Frequency Standards
  Based on Coherent Population Trapping",2025-02-17T09:21:23Z,"V. I. Vishnyakov, D. V. Brazhnikov, M. N. Skvortsov","We investigate the magnetic-field-induced frequency shift (MFS) of the clock
""0-0"" transition in the microwave quantum frequency standard (atomic clock)
based on coherent population trapping (CPT) in $^{87}$Rb vapor. To scan the CPT
resonance and to form the error signal, a method analogous to the
Pound-Drever-Hall (PDH) technique in the optical frequency range is employed,
where the modulating frequency ($f_m$) significantly exceeds the resonance
linewidth (FWHM). The experiments demonstrate that this technique offers
brilliant capabilities for controlling the sensitivity of the clock transition
frequency to magnetic field variations in the vapor cell compared to the
conventional method with low-frequency modulation ($f_m$$\,\ll\,$FWHM).
Specifically, the PDH technique provides several optimal values of the bias
magnetic field generated by the solenoid, at which the ""0-0"" transition
frequency exhibits extremely low sensitivity to small variations in the
external magnetic field. Furthermore, these magnetic field values can be easily
adjusted by changing $f_m$, which is relevant for optimization of the atomic
clock's operating regime. The experimental results show that by using the PDH
technique, the influence of MFS on the clock transition can be suppressed down
to $\approx\,$$3.2$$\,\times\,$$10^{-13}$$\delta B^2$ mG$^{-2}$. These findings
can be leveraged both to relax stringent requirements for magnetic field
shielding in state-of-the-art CPT-based miniature atomic clocks (MACs) and to
build a new generation of such clocks with long-term frequency stability better
than $10^{-12}$.",http://arxiv.org/abs/2502.11587v1
"On the definition of ""almost LUR (ALUR)"" notion",2025-02-17T10:31:24Z,Constantin Zalinescu,"The notion of almost LUR (ALUR) point is introduced in the paper [P.
Bandyopadhyay et al., Some generalizations of locally uniform rotundity, J.
Math. Anal. Appl., 252, 906-916 (2000)], where one says that the point $x$ of
the unit sphere $S_{X}$ of a Banach space is an almost LUR (ALUR) point of
$B_{X}$ if for any sequences $\{x_{n}\}\subseteq B_{X}$ and
$\{x_{m}^{\ast}\}\subseteq B_{X^{\ast}}$, the condition
$\lim_{m}\lim_{n}x_{m}^{\ast}\left(\frac{x_{n}+x}{2}\right)=1$ implies
$\lim_{n}\left\Vert x_{n}-x\right\Vert =0$, without mentioning what is meant by
$\lim_{m}\lim_{n}\gamma_{m,n}=\gamma$ for $\gamma$,
$\gamma_{m,n}\in\mathbb{R}$; $X$ is ALUR if $X$ is almost LUR at any $x\in
S_{X}$. Of course, the natural definition for this iterated limit would be that
for each $m$ sufficiently large there exists
$\mu_{m}:=\lim_{n\rightarrow\infty}\gamma_{m,n}\in\mathbb{R}$ and $\gamma
=\lim_{m\rightarrow\infty}\mu_{m}$. However, as seen in some proofs where
$\lim_{m}\lim_{n}$ appears, this interpretation is not confirmed. In this paper
we examine several works in which almost LUR is mentioned and, especially, the
proofs of those results in which the above definition of ""almost LUR"" point (or
space) is invoked. Moreover, we analyze similar problems related to the notion
CWALUR which extend ALUR. Furthermore, we mention several gaps in the proofs of
some results. Finally, we propose the change of $\lim_{m}\lim_{n}$ by
$\lim_{m}\liminf_{n}$ in the definitions of several types of ALUR points;
moreover, we provide the complete proofs of two results from the literature in
which $\lim_{m}\lim_{n}$ were used effectively, using $\lim_{m}\liminf_{n}$
instead.",http://arxiv.org/abs/2502.11637v1
"MMXU: A Multi-Modal and Multi-X-ray Understanding Dataset for Disease
  Progression",2025-02-17T10:43:38Z,"Linjie Mu, Zhongzhen Huang, Shengqian Qin, Yakun Zhu, Shaoting Zhang, Xiaofan Zhang","Large vision-language models (LVLMs) have shown great promise in medical
applications, particularly in visual question answering (MedVQA) and diagnosis
from medical images. However, existing datasets and models often fail to
consider critical aspects of medical diagnostics, such as the integration of
historical records and the analysis of disease progression over time. In this
paper, we introduce MMXU (Multimodal and MultiX-ray Understanding), a novel
dataset for MedVQA that focuses on identifying changes in specific regions
between two patient visits. Unlike previous datasets that primarily address
single-image questions, MMXU enables multi-image questions, incorporating both
current and historical patient data. We demonstrate the limitations of current
LVLMs in identifying disease progression on MMXU-\textit{test}, even those that
perform well on traditional benchmarks. To address this, we propose a
MedRecord-Augmented Generation (MAG) approach, incorporating both global and
regional historical records. Our experiments show that integrating historical
records significantly enhances diagnostic accuracy by at least 20\%, bridging
the gap between current LVLMs and human expert performance. Additionally, we
fine-tune models with MAG on MMXU-\textit{dev}, which demonstrates notable
improvements. We hope this work could illuminate the avenue of advancing the
use of LVLMs in medical diagnostics by emphasizing the importance of historical
context in interpreting medical images. Our dataset is released at
\href{https://github.com/linjiemu/MMXU}{https://github.com/linjiemu/MMXU}.",http://arxiv.org/abs/2502.11651v1
"MaskGWM: A Generalizable Driving World Model with Video Mask
  Reconstruction",2025-02-17T10:53:56Z,"Jingcheng Ni, Yuxin Guo, Yichen Liu, Rui Chen, Lewei Lu, Zehuan Wu","World models that forecast environmental changes from actions are vital for
autonomous driving models with strong generalization. The prevailing driving
world model mainly build on video prediction model. Although these models can
produce high-fidelity video sequences with advanced diffusion-based generator,
they are constrained by their predictive duration and overall generalization
capabilities. In this paper, we explore to solve this problem by combining
generation loss with MAE-style feature-level context learning. In particular,
we instantiate this target with three key design: (1) A more scalable Diffusion
Transformer (DiT) structure trained with extra mask construction task. (2) we
devise diffusion-related mask tokens to deal with the fuzzy relations between
mask reconstruction and generative diffusion process. (3) we extend mask
construction task to spatial-temporal domain by utilizing row-wise mask for
shifted self-attention rather than masked self-attention in MAE. Then, we adopt
a row-wise cross-view module to align with this mask design. Based on above
improvement, we propose MaskGWM: a Generalizable driving World Model embodied
with Video Mask reconstruction. Our model contains two variants: MaskGWM-long,
focusing on long-horizon prediction, and MaskGWM-mview, dedicated to multi-view
generation. Comprehensive experiments on standard benchmarks validate the
effectiveness of the proposed method, which contain normal validation of
Nuscene dataset, long-horizon rollout of OpenDV-2K dataset and zero-shot
validation of Waymo dataset. Quantitative metrics on these datasets show our
method notably improving state-of-the-art driving world model.",http://arxiv.org/abs/2502.11663v1
Anatomy of anomalous Hall effect due to magnetic fluctuations,2025-02-17T11:40:44Z,"Ola Kenji Forslund, Xiaoxiong Liu, Soohyeon Shin, Chun Lin, Masafumi Horio, Qisi Wang, Kevin Kramer, Saumya Mukherjee, Timur Kim, Cephise Cacho, Chennan Wang, Tian Shang, Victor Ukleev, Jonathan S. White, Pascal Puphal, Yasmine Sassa, Ekaterina Pomjakushina, Titus Neupert, Johan Chang","The anomalous Hall {\color{black} e}ffect (AHE) has emerged as a key
indicator of time-reversal symmetry breaking (TRSB) and topological features in
electronic band structures. Absent of a magnetic field, the AHE requires
spontaneous TRSB but has proven hard to probe due to averaging over domains.
The anomalous component of the Hall effect is thus frequently derived from
extrapolating the magnetic field dependence of the Hall response. We show that
discerning whether the AHE is an intrinsic property of the field free system
becomes intricate in the presence of strong magnetic fluctuations.
{\color{black}As a study case,} we use the Weyl semimetal PrAlGe, where TRSB
can be toggled via a ferromagnetic transition, providing a transparent view of
the AHE's topological origin. Through a combination of thermodynamic, transport
and muon spin relaxation measurements, we contrast the behaviour below the
ferromagnetic transition temperature to that of strong magnetic fluctuations
above. Our results {\color{black}on PrAlGe provide general insights into the}
interpretation of anomalous Hall signals in systems where TRSB is debated, such
as families of Kagome metals or certain transition metal dichalcogenides.",http://arxiv.org/abs/2502.11702v1
"The Worse The Better: Content-Aware Viewpoint Generation Network for
  Projection-related Point Cloud Quality Assessment",2025-02-17T11:50:42Z,"Zhiyong Su, Bingxu Xie, Zheng Li, Jincan Wu, Weiqing Li","Through experimental studies, however, we observed the instability of final
predicted quality scores, which change significantly over different viewpoint
settings. Inspired by the ""wooden barrel theory"", given the default
content-independent viewpoints of existing projection-related PCQA approaches,
this paper presents a novel content-aware viewpoint generation network (CAVGN)
to learn better viewpoints by taking the distribution of geometric and
attribute features of degraded point clouds into consideration. Firstly, the
proposed CAVGN extracts multi-scale geometric and texture features of the
entire input point cloud, respectively. Then, for each default
content-independent viewpoint, the extracted geometric and texture features are
refined to focus on its corresponding visible part of the input point cloud.
Finally, the refined geometric and texture features are concatenated to
generate an optimized viewpoint. To train the proposed CAVGN, we present a
self-supervised viewpoint ranking network (SSVRN) to select the viewpoint with
the worst quality projected image to construct a default-optimized viewpoint
dataset, which consists of thousands of paired default viewpoints and
corresponding optimized viewpoints. Experimental results show that the
projection-related PCQA methods can achieve higher performance using the
viewpoints generated by the proposed CAVGN.",http://arxiv.org/abs/2502.11710v1
Streamlining Equal Shares,2025-02-17T13:36:25Z,"Sonja Kraiczy, Isaac Robinson, Edith Elkind","Participatory budgeting (PB) is a form of citizen participation that allows
citizens to decide how public funds are spent. Through an election, citizens
express their preferences on various projects (spending proposals). A voting
mechanism then determines which projects will be approved. The Method of Equal
Shares (MES) is the state of the art algorithm for a proportional, voting based
approach to participatory budgeting and has been implemented in cities across
Poland and Switzerland. A significant drawback of MES is that it is not
\textit{exhaustive} meaning that it often leaves a portion of the budget
unspent that could be used to fund additional projects. To address this, in
practice the algorithm is combined with a completion heuristic - most often the
``add-one"" heuristic which artificially increases the budget until a
heuristically chosen threshold. This heuristic is computationally inefficient
and will become computationally impractical if PB is employed on a larger
scale. We propose the more efficient \textsc{add-opt} heuristic for Exact Equal
Shares (EES), a variation of MES that is known to retain many of its desirable
properties. We solve the problem of identifying the next budget for which the
outcome for EES changes in $O(mn)$ time for cardinal utilities and $O(m^2n)$
time for uniform utilities, where $m$ is the number of projects and $n$ is the
number of voters. Our solution to this problem inspires the efficient
\textsc{add-opt} heuristic which bypasses the need to search through each
intermediary budget. We perform comprehensive experiments on real-word PB
instances from Pabulib and show that completed EES outcomes usually match the
proportion of budget spent by completed MES outcomes. Furthermore, the
\textsc{add-opt} heuristic matches the proportion of budget spend by add-one
for EES.",http://arxiv.org/abs/2502.11797v1
"Residual Learning towards High-fidelity Vehicle Dynamics Modeling with
  Transformer",2025-02-17T13:43:52Z,"Jinyu Miao, Rujun Yan, Bowei Zhang, Tuopu Wen, Kun Jiang, Mengmeng Yang, Jin Huang, Zhihua Zhong, Diange Yang","The vehicle dynamics model serves as a vital component of autonomous driving
systems, as it describes the temporal changes in vehicle state. In a long
period, researchers have made significant endeavors to accurately model vehicle
dynamics. Traditional physics-based methods employ mathematical formulae to
model vehicle dynamics, but they are unable to adequately describe complex
vehicle systems due to the simplifications they entail. Recent advancements in
deep learning-based methods have addressed this limitation by directly
regressing vehicle dynamics. However, the performance and generalization
capabilities still require further enhancement. In this letter, we address
these problems by proposing a vehicle dynamics correction system that leverages
deep neural networks to correct the state residuals of a physical model instead
of directly estimating the states. This system greatly reduces the difficulty
of network learning and thus improves the estimation accuracy of vehicle
dynamics. Furthermore, we have developed a novel Transformer-based dynamics
residual correction network, DyTR. This network implicitly represents state
residuals as high-dimensional queries, and iteratively updates the estimated
residuals by interacting with dynamics state features. The experiments in
simulations demonstrate the proposed system works much better than physics
model, and our proposed DyTR model achieves the best performances on dynamics
state residual correction task, reducing the state prediction errors of a
simple 3 DoF vehicle model by an average of 92.3% and 59.9% in two dataset,
respectively.",http://arxiv.org/abs/2502.11800v1
"Gravitational lensing by charged black hole with global monopole in
  strong field limit",2025-02-17T13:59:47Z,"Yi-Ling Lan, Yun-Feng Qu, Jiawei Hu, Hongwei Yu","We investigate gravitational lensing near a charged black hole with a global
monopole in the strong field regime, focusing on two key observables: the
angular separation between the first and subsequent images, and the ratio of
the flux intensity of the first image to the cumulative flux intensity of all
other images. By deriving analytical expressions for these observables, we
explore the combined effects of the global monopole and black hole charge both
analytically and numerically. Our results reveal that the dependence of the
angular separation on charge is intricately tied to the deficit angle caused by
the global monopole. In particular, we identify three critical values of the
global monopole parameter that determine whether the angular separation
increases monotonically, decreases monotonically, or exhibits extrema as the
charge varies. A similar complex dependence is found for the flux ratio as a
function of the deficit angle. These behaviors contrast sharply with the
monotonic changes observed in the absence of either a global monopole or
charge. Our findings highlight that the effects of the charge and global
monopole on gravitational lensing cannot be described as simple additive
contributions. Instead, their combined effects lead to a rich and
interdependent behavior that enhances our understanding of strong-field
gravitational lensing. While the charge and global monopole are expected to be
small in typical astrophysical contexts, the results presented here could be
experimentally explored in analogue gravity systems, where these parameters are
not constrained. This opens the door to potential experimental verification of
the phenomena predicted in this study.",http://arxiv.org/abs/2502.11813v1
"Evolution of radiation-induced damage in nuclear graphite -- a
  comparative structural and microstructural study",2025-02-17T14:45:28Z,"Magdalena Wilczopolska, Kinga Suchorab, Magdalena Gaweda, Malgorzata Frelek-Kozak, Pawel Ciepielewski, Marcin Brykala, Wojciech Chmurzynski, Iwona Jozwik","Graphite, as a material for high-temperature gas-cooled reactors (HTGR), will
be exposed to harsh environment. The stability of graphite structure under
irradiation is of a key importance for efficiency, reliability and security of
the Generation IV nuclear reactors. Three types of nuclear grade graphite were
subjected to irradiation in this research - two commercially manufactured
(IG-110 and NBG-17) and the laboratory's in-home material (NCBJ). The samples
were exposed to 150 keV Ar+ and He+ ions bombardment at 400 C with fluences
ranging from 1E12 to 2E17 ion/cm2 in order to simulate in-reactor conditions.
For analysis of the level of structure damage, type of created defects and
crystallite size changes under ion irradiation ex-situ Raman spectroscopy was
used. The methodology of spectra fitting was developed. Furthermore, SEM
observation of irradiated materials was performed. Results showed structural
degradation of materials by the means of amorphisation: slight at a low fluence
level, rising rapidly at higher irradiation values. Furthermore, stronger
structural disorder was found in the materials irradiated with heavier Ar+ ions
than with lighter He+. Microstructural evolution of the nuclear graphites
aligned with the structural deterioration in its stepwise character.",http://arxiv.org/abs/2502.11851v1
"Does Knowledge About Perceptual Uncertainty Help an Agent in Automated
  Driving?",2025-02-17T14:56:25Z,"Natalie Grabowsky, Annika Mütze, Joshua Wendland, Nils Jansen, Matthias Rottmann","Agents in real-world scenarios like automated driving deal with uncertainty
in their environment, in particular due to perceptual uncertainty. Although,
reinforcement learning is dedicated to autonomous decision-making under
uncertainty these algorithms are typically not informed about the uncertainty
currently contained in their environment. On the other hand, uncertainty
estimation for perception itself is typically directly evaluated in the
perception domain, e.g., in terms of false positive detection rates or
calibration errors based on camera images. Its use for deciding on
goal-oriented actions remains largely unstudied. In this paper, we investigate
how an agent's behavior is influenced by an uncertain perception and how this
behavior changes if information about this uncertainty is available. Therefore,
we consider a proxy task, where the agent is rewarded for driving a route as
fast as possible without colliding with other road users. For controlled
experiments, we introduce uncertainty in the observation space by perturbing
the perception of the given agent while informing the latter. Our experiments
show that an unreliable observation space modeled by a perturbed perception
leads to a defensive driving behavior of the agent. Furthermore, when adding
the information about the current uncertainty directly to the observation
space, the agent adapts to the specific situation and in general accomplishes
its task faster while, at the same time, accounting for risks.",http://arxiv.org/abs/2502.11864v1
"Robust 6DoF Pose Tracking Considering Contour and Interior
  Correspondence Uncertainty for AR Assembly Guidance",2025-02-17T16:18:57Z,"Jixiang Chen, Jing Chen, Kai Liu, Haochen Chang, Shanfeng Fu, Jian Yang","Augmented reality assembly guidance is essential for intelligent
manufacturing and medical applications, requiring continuous measurement of the
6DoF poses of manipulated objects. Although current tracking methods have made
significant advancements in accuracy and efficiency, they still face challenges
in robustness when dealing with cluttered backgrounds, rotationally symmetric
objects, and noisy sequences. In this paper, we first propose a robust
contour-based pose tracking method that addresses error-prone contour
correspondences and improves noise tolerance. It utilizes a fan-shaped search
strategy to refine correspondences and models local contour shape and noise
uncertainty as mixed probability distribution, resulting in a highly robust
contour energy function. Secondly, we introduce a CPU-only strategy to better
track rotationally symmetric objects and assist the contour-based method in
overcoming local minima by exploring sparse interior correspondences. This is
achieved by pre-sampling interior points from sparse viewpoint templates
offline and using the DIS optical flow algorithm to compute their
correspondences during tracking. Finally, we formulate a unified energy
function to fuse contour and interior information, which is solvable using a
re-weighted least squares algorithm. Experiments on public datasets and real
scenarios demonstrate that our method significantly outperforms
state-of-the-art monocular tracking methods and can achieve more than 100 FPS
using only a CPU.",http://arxiv.org/abs/2502.11971v1
"Unifying Explainable Anomaly Detection and Root Cause Analysis in
  Dynamical Systems",2025-02-17T18:01:07Z,"Yue Sun, Rick S. Blum, Parv Venkitasubramaniam","Dynamical systems, prevalent in various scientific and engineering domains,
are susceptible to anomalies that can significantly impact their performance
and reliability. This paper addresses the critical challenges of anomaly
detection, root cause localization, and anomaly type classification in
dynamical systems governed by ordinary differential equations (ODEs). We define
two categories of anomalies: cyber anomalies, which propagate through
interconnected variables, and measurement anomalies, which remain localized to
individual variables. To address these challenges, we propose the Interpretable
Causality Ordinary Differential Equation (ICODE) Networks, a model-intrinsic
explainable learning framework. ICODE leverages Neural ODEs for anomaly
detection while employing causality inference through an explanation channel to
perform root cause analysis (RCA), elucidating why specific time periods are
flagged as anomalous. ICODE is designed to simultaneously perform anomaly
detection, RCA, and anomaly type classification within a single, interpretable
framework. Our approach is grounded in the hypothesis that anomalies alter the
underlying ODEs of the system, manifesting as changes in causal relationships
between variables. We provide a theoretical analysis of how perturbations in
learned model parameters can be utilized to identify anomalies and their root
causes in time series data. Comprehensive experimental evaluations demonstrate
the efficacy of ICODE across various dynamical systems, showcasing its ability
to accurately detect anomalies, classify their types, and pinpoint their
origins.",http://arxiv.org/abs/2502.12086v1
"Resolving the sodiation process in hard carbon anodes with nanostructure
  specific X-ray imaging",2025-02-17T18:55:01Z,"Martina Olsson, Antoine Klein, Nataliia Mozhzhukhina, Shizhao Xiong, Christian Appel, Mads Carlsen, Leonard Nielsen, Linnea Rensmo, Marianne Liebi, Aleksandar Matic","Hard carbons show significant promise as anode materials for sodium-ion
batteries. However, monitoring the sodiation process in the hard carbon
electrode during cycling and understanding the sodiation mechanism remain
challenging. This article reports on operando 2D scanning small- and wide-angle
X-ray scattering (SWAXS) and ex situ 3D SAXS tomography of hard carbon
electrodes during the sodiation process. Structural changes are monitored with
spatial and temporal resolution during the electrochemical process and shows
that sodiation through micropore filling is the more dominating mechanism in
the later stages of sodiation, i.e. in the plateau region of the voltage
profile, while intercalation occurs continuously. Spatial inhomogeneities are
resolved over the electrode and reveal an increased level of inhomogeneity at
higher degree of sodiation with regions of different degrees of micropore
filling. Resolving the processes spatially enables us to correlate plating,
starting from the interface between the electrode and the current collector, to
a higher degree of micropore filling. The work demonstrates how SWAXS imaging
can contribute to understanding the sodiation of hard carbon anodes, not only
by spatially resolved analysis, but also as a method to decouple contributions
from different components in a cell, enabling more accurate scattering analysis
in in situ environments.",http://arxiv.org/abs/2502.12139v1
"New Calculations of the Turbulence-Turbulence Contribution to the Wind
  Noise Pressure Spectra within Homogeneous Anisotropic Turbulence",2025-02-15T09:44:55Z,"Jiao Yu, Chuanyang Jiang, Yanying Zhu, Jie Wang, Cailian Yao, Richard Raspet, Gregory W. Lyons","The turbulence-turbulence interaction and the turbulence-shear interaction
are the sources of intrinsic pressure fluctuation for wind noise generated by
atmospheric turbulence. In previous research [Yu et al., J. Acoust. Soc. Am.
129(2), 622-632 (2011)], it was shown that the measured turbulent fields
outdoors can be realistically modeled with Kraichnan's mirror flow model
[Kraichnan, J. Acoust. Soc. Am. 28(3), 378-390 (1956)]. This paper applies
Kraichnan's mirror flow idea to develop theory for calculating the
turbulence-turbulence interaction wind noise pressure spectra within
homogeneous anisotropic turbulence. New calculations of the
turbulence-turbulence contribution to the wind noise pressure spectra by
incorporating turbulence anisotropy are performed and compared to the result
using the same approach but with isotropic input and the result of the
turbulence-turbulence interaction pressure spectrum for homogeneous isotropic
turbulence using George et al.'s method [George et al., J. Fluid Mech. 148,
155-191 (1984)]. We also evaluated different contributions to the
turbulence-turbulence interaction pressure spectra using our approach with both
anisotropic and isotropic inputs. Our results indicate that the turbulence
anisotropy has small effect on the turbulence-turbulence interaction pressure
in source region, but changes the spectral slope in inertial region to about
-5/3. The turbulence-turbulence interaction pressure spectrum incorporating
turbulence anisotropy is not sensitive to height. The F33F33 term and the
F11F11 term are the most dominant contributions to the anisotropic turbulence
pressure spectra in the source region and inertial region, respectively.",http://arxiv.org/abs/2502.12194v1
"Systematic biases from the exclusion of higher harmonics in parameter
  estimation on LISA binaries",2025-02-17T19:00:01Z,"Sophia Yi, Francesco Iacovelli, Sylvain Marsat, Digvijay Wadekar, Emanuele Berti","The remarkable sensitivity achieved by the planned Laser Interferometer Space
Antenna (LISA) will allow us to observe gravitational-wave signals from the
mergers of massive black hole binaries (MBHBs) with signal-to-noise ratio (SNR)
in the hundreds, or even thousands. At such high SNR, our ability to precisely
infer the parameters of an MBHB from the detected signal will be limited by the
accuracy of the waveform templates we use. In this paper, we explore the
systematic biases that arise in parameter estimation if we use waveform
templates that do not model radiation in higher-order multipoles. This is an
important consideration for the large fraction of high-mass events expected to
be observed with LISA. We examine how the biases change for MBHB events with
different total masses, mass ratios, and inclination angles. We find that
systematic biases due to insufficient mode content are severe for events with
total redshifted mass $\gtrsim10^6\,M_\odot$. We then compare several methods
of predicting such systematic biases without performing a full Bayesian
parameter estimation. In particular, we show that through direct likelihood
optimization it is possible to predict systematic biases with remarkable
computational efficiency and accuracy. Finally, we devise a method to construct
approximate waveforms including angular multipoles with $\ell\geq5$ to better
understand how many additional modes (beyond the ones available in current
approximants) might be required to perform unbiased parameter estimation on the
MBHB signals detected by LISA.",http://arxiv.org/abs/2502.12237v1
"Vibrational properties of photochromic yttrium oxyhydride and
  oxydeuteride thin films",2025-02-17T20:20:21Z,"Martins Zubkins, Jevgenijs Gabrusenoks, Rihards Aleksis, George Chikvaidze, Edvards Strods, Viktors Vibornijs, Alons Lends, Karlis Kundzins, Juris Purans","A comprehensive study of the vibrational properties of photochromic yttrium
oxyhydride (YHO) and oxydeuteride (YDO) thin films is presented. These films
are deposited using reactive magnetron sputtering, followed by post-oxidation.
Our investigation employs vibrational Fourier-transform infrared (FTIR)
spectroscopy, in conjunction with first-principles Density Functional Theory
(DFT) calculations. The FTIR spectra of the films reveal broad vibrational
bands, primarily attributed to the disordered structure containing small
crystallites (<10 nm), as confirmed by solid-state nuclear magnetic resonance
and X-ray diffraction measurements. An isotopic shift from approximately 900 to
745 cm-1 is observed in the hydrogen/deuterium-related vibration band, while
the lower frequency bands (< 600 cm-1) remain unaffected upon replacement of
hydrogen with deuterium. These experimental observations are consistent with
the DFT theoretical calculations for various stable YHO lattices reported in
the literature. Illumination of the films with ultraviolet light at 3.3 eV
leads to additional absorption not only in the visible light range but also up
to approximately 2000 cm-1 in the mid-infrared region. However, no phase
transformation change or formation of hydroxyl (OH) groups are observed
following illumination. Our findings provide valuable insight into the
vibrational and photochromic properties of YH(D)O thin films.",http://arxiv.org/abs/2502.12299v1
"Nature of the ferromagnet-paramagnet transition in
  Y$_{1-x}$Ca$_{x}$TiO$_{3}$",2025-02-17T20:32:17Z,"S. Hameed, I. Khayr, J. Joe, G. Q. Zhao, Y. Cai, K. M. Kojima, S. Chi, T. J. Williams, M. Matsuda, Y. J. Uemura, M. Greven","Neutron scattering, magnetometry, and muon spin rotation ($\mu$SR)
measurements were performed to investigate the magnetic order and spin dynamics
across the ferromagnet-to-paramagnet transition in the hole-doped Mott
insulator Y$_{1-x}$Ca$_x$TiO$_3$. We find that the transition proceeds through
a volume-wise phase separation into ferromagnetic and paramagnetic regions.
Spin fluctuations with a characteristic timescale of $\sim$ 0.1 $\mu$s, as
detected via $\mu$SR, are observed to appear at Ca concentrations $x \geq
0.10$. The magnetic phase separation, accompanied by a modest dynamic response,
represents a novel behavior in Mott systems near the loss of magnetic order. It
is linked to a previously observed insulator-metal transition and the
associated electronic phase separation into hole-poor Mott insulating and
hole-rich metallic phases for $0 < x < 0.50$. In particular, the $x$-dependence
of the paramagnetic volume fraction strongly correlates with that of the volume
fraction of the hole-rich metallic phase. The spin-wave spectra reveal a
doping-induced crossover from isotropic to two-dimensional anisotropic exchange
interactions, reflecting substantial changes in the orbital state with
increasing Ca content.",http://arxiv.org/abs/2502.12312v1
"Improving Grip Stability Using Passive Compliant Microspine Arrays for
  Soft Robots in Unstructured Terrain",2025-02-17T22:23:39Z,"Lauren Ervin, Harish Bezawada, Vishesh Vikas","Microspine grippers are small spines commonly found on insect legs that
reinforce surface interaction by engaging with asperities to increase shear
force and traction. An array of such microspines, when integrated into the
limbs or undercarriage of a robot, can provide the ability to maneuver uneven
terrains, traverse inclines, and even climb walls. Conformability and
adaptability of soft robots makes them ideal candidates for these applications
involving traversal of complex, unstructured terrains. However, there remains a
real-life realization gap for soft locomotors pertaining to their transition
from controlled lab environment to the field by improving grip stability
through effective integration of microspines. We propose a passive, compliant
microspine stacked array design to enhance the locomotion capabilities of
mobile soft robots, in our case, ones that are motor tendon actuated. We offer
a standardized microspine array integration method with effective
soft-compliant stiffness integration, and reduced complexity resulting from a
single actuator passively controlling them. The presented design utilizes a
two-row, stacked microspine array configuration that offers additional gripping
capabilities on extremely steep/irregular surfaces from the top row while not
hindering the effectiveness of the more frequently active bottom row. We
explore different configurations of the microspine array to account for
changing surface topologies and enable independent, adaptable gripping of
asperities per microspine. Field test experiments are conducted on various
rough surfaces including concrete, brick, compact sand, and tree roots with
three robots consisting of a baseline without microspines compared against two
robots with different combinations of microspine arrays. Tracking results
indicate that the inclusion of microspine arrays increases planar displacement
on average by 15 and 8 times.",http://arxiv.org/abs/2502.12347v1
"Hovering Flight of Soft-Actuated Insect-Scale Micro Aerial Vehicles
  using Deep Reinforcement Learning",2025-02-17T22:45:59Z,"Yi-Hsuan Hsiao, Wei-Tung Chen, Yun-Sheng Chang, Pulkit Agrawal, YuFeng Chen","Soft-actuated insect-scale micro aerial vehicles (IMAVs) pose unique
challenges for designing robust and computationally efficient controllers. At
the millimeter scale, fast robot dynamics ($\sim$ms), together with system
delay, model uncertainty, and external disturbances significantly affect flight
performances. Here, we design a deep reinforcement learning (RL) controller
that addresses system delay and uncertainties. To initialize this neural
network (NN) controller, we propose a modified behavior cloning (BC) approach
with state-action re-matching to account for delay and domain-randomized expert
demonstration to tackle uncertainty. Then we apply proximal policy optimization
(PPO) to fine-tune the policy during RL, enhancing performance and smoothing
commands. In simulations, our modified BC substantially increases the mean
reward compared to baseline BC; and RL with PPO improves flight quality and
reduces command fluctuations. We deploy this controller on two different
insect-scale aerial robots that weigh 720 mg and 850 mg, respectively. The
robots demonstrate multiple successful zero-shot hovering flights, with the
longest lasting 50 seconds and root-mean-square errors of 1.34 cm in lateral
direction and 0.05 cm in altitude, marking the first end-to-end deep RL-based
flight on soft-driven IMAVs.",http://arxiv.org/abs/2502.12355v1
"Simulated Bifurcation with High-dimensional Expansion for Traffic Signal
  Optimization on Real-world Networks",2025-02-18T02:23:13Z,"Shengda Zhao, Zhekun Liu, Jiaxin Yu, Bocheng Ju, Liang Wang, Xiaodong Zhang, Xinghua Zhang","With accelerating urbanization and worsening traffic congestion, optimizing
traffic signal systems to improve road throughput and alleviate congestion has
become a critical issue. This study proposes a short-term traffic prediction
model based on real-world road topologies and a typical four-way, eight-phase
traffic signal control scheme. The model accounts for traffic flow disparities
across directions and signal phase change frequencies, integrating these
factors into an optimization objective for global traffic optimization. The
structure of this objective function is similar to spin-glass systems in
statistical physics. A Simulated Bifurcation optimization algorithm is
introduced, with traditional simulated annealing as a benchmark. The results
show that Simulated Bifurcation outperforms simulated annealing in both
efficiency and effectiveness. Using real traffic flow and road network data
from Beijing, we initialized the model and conducted numerical optimization
experiments. The results indicate that Simulated Bifurcation significantly
outperforms simulated annealing in computational efficiency, effectively
solving combinatorial optimization problems with multiple spin interactions,
and reducing the time complexity to $O(N^{1.35})$. This solution addresses the
NP-hard problem of global traffic signal optimization. Importantly, the signal
phase patterns generated by Simulated Bifurcation align with the operational
requirements of real traffic signal systems, showcasing its potential in
optimizing signal control for large, complex urban traffic networks. This work
provides solid theoretical and practical foundations for future urban traffic
management and intelligent transportation systems.",http://arxiv.org/abs/2502.12440v1
"SparAMX: Accelerating Compressed LLMs Token Generation on AMX-powered
  CPUs",2025-02-18T02:26:34Z,"Ahmed F. AbouElhamayed, Jordan Dotzel, Yash Akhauri, Chi-Chih Chang, Sameh Gobriel, J. Pablo Muñoz, Vui Seng Chua, Nilesh Jain, Mohamed S. Abdelfattah","Large language models have high compute, latency, and memory requirements.
While specialized accelerators such as GPUs and TPUs typically run these
workloads, CPUs are more widely available and consume less energy. Accelerating
LLMs with CPUs enables broader AI access at a lower cost and power consumption.
This acceleration potential for CPUs is especially relevant during the
memory-bound decoding stage of LLM inference, which processes one token at a
time and is becoming increasingly utilized with reasoning models. We utilize
Advanced Matrix Extensions (AMX) support on the latest Intel CPUs together with
unstructured sparsity to achieve a $1.42 \times$ reduction in end-to-end
latency compared to the current PyTorch implementation by applying our
technique in linear layers. We provide a set of open-source customized sparse
kernels that can speed up any PyTorch model by automatically replacing all
linear layers with our custom sparse implementation. Furthermore, we
demonstrate for the first time the use of unstructured sparsity in the
attention computation achieving a $1.14 \times$ speedup over the current
systems without compromising accuracy. Code:
https://github.com/IntelLabs/Hardware-Aware-Automated-Machine-Learning/tree/main/SparAMX",http://arxiv.org/abs/2502.12444v1
"Memory-updated-based Framework for 100% Reliable Flexible Flat Cables
  Insertion",2025-02-18T04:00:46Z,"Zhengrong Ling, Xiong Yang, Dong Guo, Hongyuan Chang, Tieshan Zhang, Ruijia Zhang, Yajing Shen","Automatic assembly lines have increasingly replaced human labor in various
tasks; however, the automation of Flexible Flat Cable (FFC) insertion remains
unrealized due to its high requirement for effective feedback and dynamic
operation, limiting approximately 11% of global industrial capacity. Despite
lots of approaches, like vision-based tactile sensors and reinforcement
learning, having been proposed, the implementation of human-like high-reliable
insertion (i.e., with a 100% success rate in completed insertion) remains a big
challenge. Drawing inspiration from human behavior in FFC insertion, which
involves sensing three-dimensional forces, translating them into physical
concepts, and continuously improving estimates, we propose a novel framework.
This framework includes a sensing module for collecting three-dimensional
tactile data, a perception module for interpreting this data into meaningful
physical signals, and a memory module based on Bayesian theory for reliability
estimation and control. This strategy enables the robot to accurately assess
its physical state and generate reliable status estimations and corrective
actions. Experimental results demonstrate that the robot using this framework
can detect alignment errors of 0.5 mm with an accuracy of 97.92% and then
achieve a 100% success rate in all completed tests after a few iterations. This
work addresses the challenges of unreliable perception and control in complex
insertion tasks, highlighting the path toward the development of fully
automated production lines.",http://arxiv.org/abs/2502.12514v1
"Seamless Graph Task Scheduling over Dynamic Vehicular Clouds: A Hybrid
  Methodology for Integrating Pilot and Instantaneous Decisions",2025-02-18T05:49:03Z,"Bingshuo Guo, Minghui Liwang, Xiaoyu Xia, Li Li, Zhenzhen Jiao, Seyyedali Hosseinalipour, Xianbin Wang","Vehicular clouds (VCs) play a crucial role in the Internet-of-Vehicles (IoV)
ecosystem by securing essential computing resources for a wide range of tasks.
This paPertackles the intricacies of resource provisioning in dynamic VCs for
computation-intensive tasks, represented by undirected graphs for parallel
processing over multiple vehicles. We model the dynamics of VCs by considering
multiple factors, including varying communication quality among vehicles,
fluctuating computing capabilities of vehicles, uncertain contact duration
among vehicles, and dynamic data exchange costs between vehicles. Our primary
goal is to obtain feasible assignments between task components and nearby
vehicles, called templates, in a timely manner with minimized task completion
time and data exchange overhead. To achieve this, we propose a hybrid graph
task scheduling (P-HTS) methodology that combines offline and online
decision-making modes. For the offline mode, we introduce an approach called
risk-aware pilot isomorphic subgraph searching (RA-PilotISS), which predicts
feasible solutions for task scheduling in advance based on historical
information. Then, for the online mode, we propose time-efficient instantaneous
isomorphic subgraph searching (TE-InstaISS), serving as a backup approach for
quickly identifying new optimal scheduling template when the one identified by
RA-PilotISS becomes invalid due to changing conditions. Through comprehensive
experiments, we demonstrate the superiority of our proposed hybrid mechanism
compared to state-of-the-art methods in terms of various evaluative metrics,
e.g., time efficiency such as the delay caused by seeking for possible
templates and task completion time, as well as cost function, upon considering
different VC scales and graph task topologies.",http://arxiv.org/abs/2502.12557v1
"G-Refer: Graph Retrieval-Augmented Large Language Model for Explainable
  Recommendation",2025-02-18T06:42:38Z,"Yuhan Li, Xinni Zhang, Linhao Luo, Heng Chang, Yuxiang Ren, Irwin King, Jia Li","Explainable recommendation has demonstrated significant advantages in
informing users about the logic behind recommendations, thereby increasing
system transparency, effectiveness, and trustworthiness. To provide
personalized and interpretable explanations, existing works often combine the
generation capabilities of large language models (LLMs) with collaborative
filtering (CF) information. CF information extracted from the user-item
interaction graph captures the user behaviors and preferences, which is crucial
for providing informative explanations. However, due to the complexity of graph
structure, effectively extracting the CF information from graphs still remains
a challenge. Moreover, existing methods often struggle with the integration of
extracted CF information with LLMs due to its implicit representation and the
modality gap between graph structures and natural language explanations. To
address these challenges, we propose G-Refer, a framework using graph
retrieval-augmented large language models (LLMs) for explainable
recommendation. Specifically, we first employ a hybrid graph retrieval
mechanism to retrieve explicit CF signals from both structural and semantic
perspectives. The retrieved CF information is explicitly formulated as
human-understandable text by the proposed graph translation and accounts for
the explanations generated by LLMs. To bridge the modality gap, we introduce
knowledge pruning and retrieval-augmented fine-tuning to enhance the ability of
LLMs to process and utilize the retrieved CF information to generate
explanations. Extensive experiments show that G-Refer achieves superior
performance compared with existing methods in both explainability and
stability. Codes and data are available at https://github.com/Yuhan1i/G-Refer.",http://arxiv.org/abs/2502.12586v1
"Generative AI Enabled Robust Data Augmentation for Wireless Sensing in
  ISAC Networks",2025-02-18T08:08:19Z,"Jiacheng Wang, Changyuan Zhao, Hongyang Du, Geng Sun, Jiawen Kang, Shiwen Mao, Dusit Niyato, Dong In Kim","Integrated sensing and communication (ISAC) uses the same software and
hardware resources to achieve both communication and sensing functionalities.
Thus, it stands as one of the core technologies of 6G and has garnered
significant attention in recent years. In ISAC systems, a variety of machine
learning models are trained to analyze and identify signal patterns, thereby
ensuring reliable sensing and communications. However, considering factors such
as communication rates, costs, and privacy, collecting sufficient training data
from various ISAC scenarios for these models is impractical. Hence, this paper
introduces a generative AI (GenAI) enabled robust data augmentation scheme. The
scheme first employs a conditioned diffusion model trained on a limited amount
of collected CSI data to generate new samples, thereby expanding the sample
quantity. Building on this, the scheme further utilizes another diffusion model
to enhance the sample quality, thereby facilitating the data augmentation in
scenarios where the original sensing data is insufficient and unevenly
distributed. Moreover, we propose a novel algorithm to estimate the
acceleration and jerk of signal propagation path length changes from CSI. We
then use the proposed scheme to enhance the estimated parameters and detect the
number of targets based on the enhanced data. The evaluation reveals that our
scheme improves the detection performance by up to 70%, demonstrating
reliability and robustness, which supports the deployment and practical use of
the ISAC network.",http://arxiv.org/abs/2502.12622v1
TREND: A Whitespace Replacement Information Hiding Method,2025-02-18T10:21:27Z,"Malte Hellmeier, Hendrik Norkowski, Ernst-Christoph Schrewe, Haydar Qarawlus, Falk Howar","Large Language Models (LLMs) have gained significant popularity in recent
years. Differentiating between a text written by a human and a text generated
by an LLM has become almost impossible. Information hiding techniques such as
digital watermarking or steganography can help by embedding information inside
text without being noticed. However, existing techniques, such as
linguistic-based or format-based methods, change the semantics or do not work
on pure, unformatted text. In this paper, we introduce a novel method for
information hiding termed TREND, which is able to conceal any byte-encoded
sequence within a cover text. The proposed method is implemented as a
multi-platform library using the Kotlin programming language, accompanied by a
command-line tool and a web interface provided as examples of usage. By
substituting conventional whitespace characters with visually similar Unicode
whitespace characters, our proposed scheme preserves the semantics of the cover
text without increasing the number of characters. Furthermore, we propose a
specified structure for secret messages that enables configurable compression,
encryption, hashing, and error correction. Our experimental benchmark
comparison on a dataset of one million Wikipedia articles compares ten
algorithms from literature and practice. It proves the robustness of our
proposed method in various applications while remaining imperceptible to
humans. We discuss the limitations of limited embedding capacity and further
robustness, which guide implications for future work.",http://arxiv.org/abs/2502.12710v1
"R2-KG: General-Purpose Dual-Agent Framework for Reliable Reasoning on
  Knowledge Graphs",2025-02-18T11:31:52Z,"Sumin Jo, Junseong Choi, Jiho Kim, Edward Choi","Recent studies have combined Large Language Models (LLMs) with Knowledge
Graphs (KGs) to enhance reasoning, improving inference accuracy without
additional training while mitigating hallucination. However, existing
frameworks are often rigid, struggling to adapt to KG or task changes. They
also rely heavily on powerful LLMs for reliable (i.e., trustworthy) reasoning.
To address this, We introduce R2-KG, a plug-and-play, dual-agent framework that
separates reasoning into two roles: an Operator (a low-capacity LLM) that
gathers evidence and a Supervisor (a high-capacity LLM) that makes final
judgments. This design is cost-efficient for LLM inference while still
maintaining strong reasoning accuracy. Additionally, R2-KG employs an
Abstention mechanism, generating answers only when sufficient evidence is
collected from KG, which significantly enhances reliability. Experiments across
multiple KG-based reasoning tasks show that R2-KG consistently outperforms
baselines in both accuracy and reliability, regardless of the inherent
capability of LLMs used as the Operator. Further experiments reveal that the
single-agent version of R2-KG, equipped with a strict self-consistency
strategy, achieves significantly higher-than-baseline reliability while
reducing inference cost. However, it also leads to a higher abstention rate in
complex KGs. Our findings establish R2-KG as a flexible and cost-effective
solution for KG-based reasoning. It reduces reliance on high-capacity LLMs
while ensuring trustworthy inference.",http://arxiv.org/abs/2502.12767v1
"Electron-induced chemistry and sputtering of volatile species from
  amorphous and crystalline water ice",2025-02-18T11:41:34Z,"Yogeshwar Nath Mishra, Sankhabrata Chandra, Murthy S. Gudipati, Bryana Henderson, Dag Hanstorp, Yuk L. Yung","Electron irradiation of water-rich ices plays a significant role in
initiating the chemical and physical processes on the surface of airless icy
bodies in radiation environments such as Europa and Enceladus, as well as on
the Moon, comets, and asteroids interacting with the solar wind. The sputtering
process by electrons and ions leads to chemical modification and outgassing of
their icy surfaces and the subsequent formation of a tenuous atmosphere. Though
electron-sputtering yields are known to be lower compared to ion-sputtering
yields, one needs to also account for their differential fluxes. In our
experiments, the electron-induced sputtering yields of all the gaseous species
H2, O, OH, H2O, and O2 are investigated for electron energies lower than 2 keV
in terms of partial pressure vs. time of irradiation. The effective averaged
change in partial pressure of the desorbed species is converted to the number
of sputtered atoms or molecules per second per cm2 from the ice, and then to
the sputtering yields (number of species sputtered per electron). Our data
agrees well with the previously reported data for the sputtering of O2 and H2O
yield for the amorphous ice. We also find that crystalline ice shows
significantly lower sputtering yields when compared to amorphous ice, in
agreement with the observation of similar trends in the literature. Our work
indicates that sputtering yields per keV of O, OH, O2, and H2O drop with
increasing electron energy from 0.5 keV to 2 keV.",http://arxiv.org/abs/2502.12780v1
"A Survey on DRL based UAV Communications and Networking: DRL
  Fundamentals, Applications and Implementations",2025-02-18T14:05:12Z,"Wei Zhao, Shaoxin Cui, Wen Qiu, Zhiqiang He, Zhi Liu, Xiao Zheng, Bomin Mao, Nei Kato","Unmanned aerial vehicles (UAVs) are playing an increasingly pivotal role in
modern communication networks,offering flexibility and enhanced coverage for a
variety of applica-tions. However, UAV networks pose significant challenges due
to their dynamic and distributed nature, particularly when dealing with tasks
such as power allocation, channel assignment, caching,and task offloading.
Traditional optimization techniques often struggle to handle the complexity and
unpredictability of these environments, leading to suboptimal performance. This
survey provides a comprehensive examination of how deep reinforcement learning
(DRL) can be applied to solve these mathematical optimization problems in UAV
communications and networking.Rather than simply introducing DRL methods, the
focus is on demonstrating how these methods can be utilized to solve complex
mathematical models of the underlying problems. We begin by reviewing the
fundamental concepts of DRL, including value-based, policy-based, and
actor-critic approaches. Then,we illustrate how DRL algorithms are applied to
specific UAV network tasks by discussing from problem formulations to DRL
implementation. By framing UAV communication challenges as optimization
problems, this survey emphasizes the practical value of DRL in dynamic and
uncertain environments. We also explore the strengths of DRL in handling
large-scale network scenarios and the ability to continuously adapt to changes
in the environment. In addition, future research directions are outlined,
highlighting the potential for DRL to further enhance UAV communications and
expand its applicability to more complex,multi-agent settings.",http://arxiv.org/abs/2502.12875v1
"Preventing the Popular Item Embedding Based Attack in Federated
  Recommendations",2025-02-18T15:43:14Z,"Jun Zhang, Huan Li, Dazhong Rong, Yan Zhao, Ke Chen, Lidan Shou","Privacy concerns have led to the rise of federated recommender systems (FRS),
which can create personalized models across distributed clients. However, FRS
is vulnerable to poisoning attacks, where malicious users manipulate gradients
to promote their target items intentionally. Existing attacks against FRS have
limitations, as they depend on specific models and prior knowledge, restricting
their real-world applicability. In our exploration of practical FRS
vulnerabilities, we devise a model-agnostic and prior-knowledge-free attack,
named PIECK (Popular Item Embedding based Attack). The core module of PIECK is
popular item mining, which leverages embedding changes during FRS training to
effectively identify the popular items. Built upon the core module, PIECK
branches into two diverse solutions: The PIECKIPE solution employs an item
popularity enhancement module, which aligns the embeddings of targeted items
with the mined popular items to increase item exposure. The PIECKUEA further
enhances the robustness of the attack by using a user embedding approximation
module, which approximates private user embeddings using mined popular items.
Upon identifying PIECK, we evaluate existing federated defense methods and find
them ineffective against PIECK, as poisonous gradients inevitably overwhelm the
cold target items. We then propose a novel defense method by introducing two
regularization terms during user training, which constrain item popularity
enhancement and user embedding approximation while preserving FRS performance.
We evaluate PIECK and its defense across two base models, three real datasets,
four top-tier attacks, and six general defense methods, affirming the efficacy
of both PIECK and its defense.",http://arxiv.org/abs/2502.12958v1
"General soliton solutions to the coupled Hirota equation via the
  Kadomtsev-Petviashvili reduction",2025-02-18T17:54:53Z,"Changyan Shi, Bingyuan Liu, Bao-Feng Feng","In this paper, we are concerned with various soliton solutions to the coupled
Hirota equation, as well as to the Sasa-Satsuma equation which can be viewed as
one reduction case of the coupled Hirota equation. First, we derive
bright-bright, dark-dark, and bright-dark soliton solutions of the coupled
Hirota equation by using the Kadomtsev-Petviashvili reduction method. Then, we
present the bright and dark soliton solutions to the Sasa-Satsuma equation
which are expressed by determinants of $N \times N$ instead of $2N \times 2N$
in the literature. The dynamics of first-, second-order solutions are
investigated in detail. It is intriguing that, for the SS equation, the bright
soliton for \(N=1\) is also the soliton to the complex mKdV equation while the
amplitude and velocity of dark soliton for \(N=1\) are determined by the
background plane wave. For \(N=2\), the bright soliton can be classified into
three types: oscillating, single-hump, and two-hump ones while the dark soliton
can be classified into five types: dark (single-hole), anti-dark, Mexican hat,
anti-Mexican hat and double-hole. Moreover, the types of bright solitons for
the Sasa-Satsuma equation can be changed due to collision.",http://arxiv.org/abs/2502.13088v1
"On testing in-vacuo dispersion with the most energetic neutrinos:
  KM3-230213A case study",2025-02-18T18:05:23Z,"Giovanni Amelino-Camelia, Giacomo D'Amico, Giuseppe Fabiano, Domenico Frattulillo, Giulia Gubitosi, Alessandro Moia, Giacomo Rosati","The phenomenology of in-vacuo dispersion, an effect such that quantum
properties of spacetime slow down particles proportionally to their energies,
has been a very active research area since the advent of the Fermi telescope.
One of the assumptions made in this 15-year effort is that the phenomenology of
in-vacuo dispersion has a particle-energy sweet spot: the energy of the
particle should be large enough to render the analysis immune to
source-intrinsic confounding effects but still small enough to facilitate the
identification of the source of the particle. We use the gigantic energy of
KM3-230213A as an opportunity to challenge this expectation. For a neutrino of
a few hundred PeVs a transient source could have been observed at lower
energies several years earlier, even assuming the characteristic scale of
in-vacuo dispersion to be close to the Planck scale. We report that GRB090401B
is in excellent directional agreement with KM3-230213A, and we discuss a
strategy of in-vacuo-dispersion analysis suitable for estimating the
significance of KM3-230213A as a GRB090401B-neutrino candidate. The p-value
resulting from our analysis (0.015) is not small enough to warrant any
excitement, but small enough to establish the point that a handful of such
coincidences would be sufficient to meaningfully test in-vacuo dispersion.",http://arxiv.org/abs/2502.13093v2
"Sleepless Nights, Sugary Days: Creating Synthetic Users with Health
  Conditions for Realistic Coaching Agent Interactions",2025-02-18T18:56:44Z,"Taedong Yun, Eric Yang, Mustafa Safdari, Jong Ha Lee, Vaishnavi Vinod Kumar, S. Sara Mahdavi, Jonathan Amar, Derek Peyton, Reut Aharony, Andreas Michaelides, Logan Schneider, Isaac Galatzer-Levy, Yugang Jia, John Canny, Arthur Gretton, Maja Matarić","We present an end-to-end framework for generating synthetic users for
evaluating interactive agents designed to encourage positive behavior changes,
such as in health and lifestyle coaching. The synthetic users are grounded in
health and lifestyle conditions, specifically sleep and diabetes management in
this study, to ensure realistic interactions with the health coaching agent.
Synthetic users are created in two stages: first, structured data are generated
grounded in real-world health and lifestyle factors in addition to basic
demographics and behavioral attributes; second, full profiles of the synthetic
users are developed conditioned on the structured data. Interactions between
synthetic users and the coaching agent are simulated using generative
agent-based models such as Concordia, or directly by prompting a language
model. Using two independently-developed agents for sleep and diabetes coaching
as case studies, the validity of this framework is demonstrated by analyzing
the coaching agent's understanding of the synthetic users' needs and
challenges. Finally, through multiple blinded evaluations of user-coach
interactions by human experts, we demonstrate that our synthetic users with
health and behavioral attributes more accurately portray real human users with
the same attributes, compared to generic synthetic users not grounded in such
attributes. The proposed framework lays the foundation for efficient
development of conversational agents through extensive, realistic, and grounded
simulated interactions.",http://arxiv.org/abs/2502.13135v1
"Approximate Bayesian Kernel Machine Regression via Random Fourier
  Features for Estimating Joint Health Effects of Multiple Exposures",2025-02-14T22:47:19Z,"Danlu Zhang, Stephanie M. Eick, Howard H. Chang","Environmental epidemiology has traditionally focused on examining health
effects of single exposures, more recently with adjustment for co-occurring
exposures. Advancements in exposure assessments and statistical tools have
enabled a shift towards studying multiple exposures and their combined health
impacts. Bayesian Kernel Machine Regression (BKMR) is a popular approach to
flexibly estimate the joint and nonlinear effects of multiple exposures.
However, BKMR faces computation challenges for large datasets, as inverting the
kernel repeatedly in Markov chain Monte Carlo (MCMC) algorithms can be
time-consuming and often infeasible in practice. To address this issue, we
propose a faster version of BKMR using supervised random Fourier features to
approximate the Gaussian process. We use periodic functions as basis functions
and this approximation re-frames the kernel machine regression into a linear
mixed-effect model that facilitates computationally efficient estimation and
prediction. Bayesian inference was conducted using MCMC with Hamiltonian Monte
Carlo algorithms. Analytic code for implementing Fast BKMR was developed for R.
Simulation studies demonstrated that this approximation method yields results
comparable to the original Gaussian process while reducing the computation time
by 29 to 99%, depending on the number of basis functions and sample sizes. Our
approach is also more robust to kernel misspecification in some scenarios.
Finally, we applied this approach to analyze over 270,000 birth records,
examining associations between multiple ambient air pollutants and birthweight
in Georgia.",http://arxiv.org/abs/2502.13157v1
"Fundus2Globe: Generative AI-Driven 3D Digital Twins for Personalized
  Myopia Management",2025-02-18T10:02:39Z,"Danli Shi, Bowen Liu, Zhen Tian, Yue Wu, Jiancheng Yang, Ruoyu Chen, Bo Yang, Ou Xiao, Mingguang He","Myopia, projected to affect 50% population globally by 2050, is a leading
cause of vision loss. Eyes with pathological myopia exhibit distinctive shape
distributions, which are closely linked to the progression of
vision-threatening complications. Recent understanding of eye-shape-based
biomarkers requires magnetic resonance imaging (MRI), however, it is costly and
unrealistic in routine ophthalmology clinics. We present Fundus2Globe, the
first AI framework that synthesizes patient-specific 3D eye globes from
ubiquitous 2D color fundus photographs (CFPs) and routine metadata (axial
length, spherical equivalent), bypassing MRI dependency. By integrating a 3D
morphable eye model (encoding biomechanical shape priors) with a latent
diffusion model, our approach achieves submillimeter accuracy in reconstructing
posterior ocular anatomy efficiently. Fundus2Globe uniquely quantifies how
vision-threatening lesions (e.g., staphylomas) in CFPs correlate with
MRI-validated 3D shape abnormalities, enabling clinicians to simulate posterior
segment changes in response to refractive shifts. External validation
demonstrates its robust generation performance, ensuring fairness across
underrepresented groups. By transforming 2D fundus imaging into 3D digital
replicas of ocular structures, Fundus2Globe is a gateway for precision
ophthalmology, laying the foundation for AI-driven, personalized myopia
management.",http://arxiv.org/abs/2502.13182v1
"Communication Strategy on Macro-and-Micro Traffic State in Cooperative
  Deep Reinforcement Learning for Regional Traffic Signal Control",2025-02-18T19:20:51Z,"Hankang Gu, Shangbo Wang, Dongyao Jia, Yuli Zhang, Yanrong Luo, Guoqiang Mao, Jianping Wang, Eng Gee Lim","Adaptive Traffic Signal Control (ATSC) has become a popular research topic in
intelligent transportation systems. Regional Traffic Signal Control (RTSC)
using the Multi-agent Deep Reinforcement Learning (MADRL) technique has become
a promising approach for ATSC due to its ability to achieve the optimum
trade-off between scalability and optimality. Most existing RTSC approaches
partition a traffic network into several disjoint regions, followed by applying
centralized reinforcement learning techniques to each region. However, the
pursuit of cooperation among RTSC agents still remains an open issue and no
communication strategy for RTSC agents has been investigated. In this paper, we
propose communication strategies to capture the correlation of micro-traffic
states among lanes and the correlation of macro-traffic states among
intersections. We first justify the evolution equation of the RTSC process is
Markovian via a system of store-and-forward queues. Next, based on the
evolution equation, we propose two GAT-Aggregated (GA2) communication
modules--GA2-Naive and GA2-Aug to extract both intra-region and inter-region
correlations between macro and micro traffic states. While GA2-Naive only
considers the movements at each intersection, GA2-Aug also considers the
lane-changing behavior of vehicles. Two proposed communication modules are then
aggregated into two existing novel RTSC frameworks--RegionLight and
Regional-DRL. Experimental results demonstrate that both GA2-Naive and GA2-Aug
effectively improve the performance of existing RTSC frameworks under both real
and synthetic scenarios. Hyperparameter testing also reveals the robustness and
potential of our communication modules in large-scale traffic networks.",http://arxiv.org/abs/2502.13248v1
"Revisiting Privacy, Utility, and Efficiency Trade-offs when Fine-Tuning
  Large Language Models",2025-02-18T22:16:03Z,"Soumi Das, Camila Kolling, Mohammad Aflah Khan, Mahsa Amani, Bishwamittra Ghosh, Qinyuan Wu, Till Speicher, Krishna P. Gummadi","We study the inherent trade-offs in minimizing privacy risks and maximizing
utility, while maintaining high computational efficiency, when fine-tuning
large language models (LLMs). A number of recent works in privacy research have
attempted to mitigate privacy risks posed by memorizing fine-tuning data by
using differentially private training methods (e.g., DP), albeit at a
significantly higher computational cost (inefficiency). In parallel, several
works in systems research have focussed on developing (parameter) efficient
fine-tuning methods (e.g., LoRA), but few works, if any, investigated whether
such efficient methods enhance or diminish privacy risks. In this paper, we
investigate this gap and arrive at a surprising conclusion: efficient
fine-tuning methods like LoRA mitigate privacy risks similar to private
fine-tuning methods like DP. Our empirical finding directly contradicts
prevailing wisdom that privacy and efficiency objectives are at odds during
fine-tuning. Our finding is established by (a) carefully defining measures of
privacy and utility that distinguish between memorizing sensitive and
non-sensitive tokens in training and test datasets used in fine-tuning and (b)
extensive evaluations using multiple open-source language models from Pythia,
Gemma, and Llama families and different domain-specific datasets.",http://arxiv.org/abs/2502.13313v1
"Vision-Based Generic Potential Function for Policy Alignment in
  Multi-Agent Reinforcement Learning",2025-02-19T05:04:10Z,"Hao Ma, Shijie Wang, Zhiqiang Pu, Siyao Zhao, Xiaolin Ai","Guiding the policy of multi-agent reinforcement learning to align with human
common sense is a difficult problem, largely due to the complexity of modeling
common sense as a reward, especially in complex and long-horizon multi-agent
tasks. Recent works have shown the effectiveness of reward shaping, such as
potential-based rewards, to enhance policy alignment. The existing works,
however, primarily rely on experts to design rule-based rewards, which are
often labor-intensive and lack a high-level semantic understanding of common
sense. To solve this problem, we propose a hierarchical vision-based reward
shaping method. At the bottom layer, a visual-language model (VLM) serves as a
generic potential function, guiding the policy to align with human common sense
through its intrinsic semantic understanding. To help the policy adapts to
uncertainty and changes in long-horizon tasks, the top layer features an
adaptive skill selection module based on a visual large language model (vLLM).
The module uses instructions, video replays, and training records to
dynamically select suitable potential function from a pre-designed pool.
Besides, our method is theoretically proven to preserve the optimal policy.
Extensive experiments conducted in the Google Research Football environment
demonstrate that our method not only achieves a higher win rate but also
effectively aligns the policy with human common sense.",http://arxiv.org/abs/2502.13430v1
"Neutrino Oscillation in Core Collapse Supernova: The Impact of Spacetime
  Geometry",2025-02-19T05:26:21Z,"Indrajit Ghose, Amitabha Lahiri","Neutrino flavor evolution inside a core-collapse supernova is a topic of
active research. The core of a supernova is an intense source of neutrinos and
antineutrinos. Self-interaction among neutrinos (as well as antineutrinos)
gives rise to a rich phenomenology not seen in terrestrial situations. In
studies of the dynamics of flavor evolution in such environments, the
gravitational effects are generally ignored. Although the curvature outside a
dense core does not deviate much from a flat space, the spin of the neutrinos
can still couple to the torsion of the spacetime. These extra degrees of
freedom of curved spacetime have interaction strengths that are proportional to
the density of the neutrinos and the other fermions \cite{Chakrabarty:2019cau}
\cite{Barick:2023qjq} as well as the coupling constants of the spin-torsion
interaction. We have studied the effects of such interactions in flavor
evolution inside a core-collapse supernova \cite{Ghose:Manuscript}. The
self-interaction gets modified by the spin-torsion interaction and the
oscillation dynamics is modified. We have seen that there are noticeable
changes in the flavor dynamics when the neutrino density is uniform. We have
also studied the effects of such interaction in a realistic core-collapse
supernova (CCSN). As neutrino astronomy enters the precision era, this study
will shed light on the potential of neutrino fluxes from CCSN to probe the
neutrino-neutrino interaction.",http://arxiv.org/abs/2502.13439v1
"Unravelling the influence of shell thickness in organic functionalized
  Cu2O nanoparticles on C2+ products distribution in electrocatalytic CO2
  reduction",2025-02-19T08:06:51Z,"Jiajun Hu, Silvio Osella, Josep Albero, Hermenegildo García","Cu-based electrocatalysts exhibits enormous potential for electrochemical CO2
conversion to added-value products. However, high selectivity, specially
towards C2+ products, remains a critical challenge for its implementation in
commercial applications. Herein, we report the preparation of a series of
electrocatalysts based on octadecyl amine (ODA) coated Cu2O nanoparticles.
HRTEM images show ODA coatings with thickness from 1.2 to 4 nm. DFT
calculations predict that at low surface coverage, ODA tends to lay on the Cu2O
surface, leaving hydrophilic regions. Oppositely, at high surface coverage, the
ODA molecules are densely packed, being detrimental for both mass and charge
transfer. These changes in ODA molecular arrangement explain differences in
product selectivity. In situ Raman spectroscopy has revealed that the optimum
ODA thickness contributes to the stabilization of key intermediates in the
formation of C2+ products, especially ethanol. Electrochemical impedance
spectroscopy and pulse voltammetry measurements confirm that the thicker ODA
shells increase charge transfer resistance, while the lowest ODA content
promotes faster intermediate desorption rates. At the optimum thickness, the
intermediates desorption rates are the slowest, in agreement with the maximum
concentration of intermediates observed by in situ Raman spectroscopy, thereby
resulting in a Faradaic efficiency to ethanol and ethylene over 73 %.",http://arxiv.org/abs/2502.13512v1
"Mixed Fe-Mo carbide prepared by a sonochemical synthesis as highly
  efficient nitrate reduction electrocatalyst",2025-02-19T08:10:14Z,"Jiajun Hu, Silvio Osella, Eduardo Arizono dos Reis, Anelisse Brunca da Silva, Caue Ribeiro, Lucia Helena Mascaro, Josep Albero, Hermenegildo Garcia","Ammonia, a versatile compound that can be used as a fertilizer, chemical or
fuel, has since long been produced through the energy-intensive Haber-Bosch
process. Recently, the electrochemical nitrate reduction reaction (NO3RR) using
electricity generated from renewable sources has attracted widespread
attention. However, the complex reaction pathway of NO3RR leads to the
formation of many undesirable by-products. Herein we successfully prepared a
mixed (FeMo)2C catalyst with good electrocatalytic NO3RR, having a NH3 yield of
14.66 mg h-1 cm-2 and an FE of 94.35 % at low potential -0.3 V vs RHE. DFT
calculations show that the presence of Fe in Mo2C lattice changes the reaction
mechanism, decreasing the potential barrier to be overcome from 1.36 to 0.89
eV. In addition, mixed Fe-Mo carbide facilitates the adsorption of
intermediates and promotes NH3 desorption, facilitating NO3- reduction to NH3.
In addition, (FeMo)2C was used as cathode for Zn-NO3 battery to generate
electricity, producing ammonia at the same time, with a power density of 3.8
mWcm-2 and an NH3 FE of 88 %. This work describes a new synthesis method for
mixed metal carbides and provides a promising strategy for NH3 production.",http://arxiv.org/abs/2502.13515v1
"CardiacMamba: A Multimodal RGB-RF Fusion Framework with State Space
  Models for Remote Physiological Measurement",2025-02-19T11:00:34Z,"Zheng Wu, Yiping Xie, Bo Zhao, Jiguang He, Fei Luo, Ning Deng, Zitong Yu","Heart rate (HR) estimation via remote photoplethysmography (rPPG) offers a
non-invasive solution for health monitoring. However, traditional
single-modality approaches (RGB or Radio Frequency (RF)) face challenges in
balancing robustness and accuracy due to lighting variations, motion artifacts,
and skin tone bias. In this paper, we propose CardiacMamba, a multimodal RGB-RF
fusion framework that leverages the complementary strengths of both modalities.
It introduces the Temporal Difference Mamba Module (TDMM) to capture dynamic
changes in RF signals using timing differences between frames, enhancing the
extraction of local and global features. Additionally, CardiacMamba employs a
Bidirectional SSM for cross-modal alignment and a Channel-wise Fast Fourier
Transform (CFFT) to effectively capture and refine the frequency domain
characteristics of RGB and RF signals, ultimately improving heart rate
estimation accuracy and periodicity detection. Extensive experiments on the
EquiPleth dataset demonstrate state-of-the-art performance, achieving marked
improvements in accuracy and robustness. CardiacMamba significantly mitigates
skin tone bias, reducing performance disparities across demographic groups, and
maintains resilience under missing-modality scenarios. By addressing critical
challenges in fairness, adaptability, and precision, the framework advances
rPPG technology toward reliable real-world deployment in healthcare. The codes
are available at: https://github.com/WuZheng42/CardiacMamba.",http://arxiv.org/abs/2502.13624v1
"Event-Based Video Frame Interpolation With Cross-Modal Asymmetric
  Bidirectional Motion Fields",2025-02-19T13:40:43Z,"Taewoo Kim, Yujeong Chae, Hyun-Kurl Jang, Kuk-Jin Yoon","Video Frame Interpolation (VFI) aims to generate intermediate video frames
between consecutive input frames. Since the event cameras are bio-inspired
sensors that only encode brightness changes with a micro-second temporal
resolution, several works utilized the event camera to enhance the performance
of VFI. However, existing methods estimate bidirectional inter-frame motion
fields with only events or approximations, which can not consider the complex
motion in real-world scenarios. In this paper, we propose a novel event-based
VFI framework with cross-modal asymmetric bidirectional motion field
estimation. In detail, our EIF-BiOFNet utilizes each valuable characteristic of
the events and images for direct estimation of inter-frame motion fields
without any approximation methods. Moreover, we develop an interactive
attention-based frame synthesis network to efficiently leverage the
complementary warping-based and synthesis-based features. Finally, we build a
large-scale event-based VFI dataset, ERF-X170FPS, with a high frame rate,
extreme motion, and dynamic textures to overcome the limitations of previous
event-based VFI datasets. Extensive experimental results validate that our
method shows significant performance improvement over the state-of-the-art VFI
methods on various datasets. Our project pages are available at:
https://github.com/intelpro/CBMNet",http://arxiv.org/abs/2502.13716v1
"Combined Light Excitation and Scanning Gate Microscopy on
  Heterostructure Nanowire Photovoltaic Devices",2025-02-19T16:00:39Z,"Yen-Po Liu, Jonatan Fast, Yang Chen, Ren Zhe, Adam Burke, Rainer Timm, Heiner Linke, Anders Mikkelsen","Nanoscale optoelectronic components achieve functionality via spatial
variation in electronic structure induced by composition, defects, and dopants.
To dynamically change the local band alignment and influence defect states, a
scanning gate electrode is highly useful. However, this technique is rarely
combined with photoexcitation by a controlled external light source. We explore
a setup that combines several types of light excitation with high resolution
scanning gate and atomic force microscopy (SGM/AFM). We apply the technique to
InAs nanowires with an atomic scale defined InP segment, that have attracted
considerable attention for studies of hot carrier devices. Using AFM we image
the topography of the nanowire device. SGM measurements without light
excitation show how current profiles can be influenced by local gating near the
InP segment. Modelling of the tip and nanowire can well predict the results
based on the axial band structure variation and an asymmetric tip. SGM studies
including light excitation are then performed using both a white light LED and
laser diodes at 515 and 780nm. Both negative and positive photoconductance can
be observed and the combined effect of light excitation and local gating is
observed. SGM can then be used to discriminate between effects related to the
wire axial compositional structure and surface states. The setup explored in
the current work has significant advantages to study optoelectronics at
realistic conditions and with rapid turnover.",http://arxiv.org/abs/2502.13841v1
"SegRet: An Efficient Design for Semantic Segmentation with Retentive
  Network",2025-02-19T13:55:45Z,"Zhiyuan Li, Yi Chang, Yuan Wu","With the ongoing advancement of autonomous driving technology and intelligent
transportation systems, research into semantic segmentation has become
increasingly pivotal. Accurate understanding and analysis of real-world
scenarios are now essential for these emerging fields. However, traditional
semantic segmentation methods often struggle to balance high model accuracy
with computational efficiency, particularly in terms of parameter count. To
address this challenge, we introduce SegRet, a novel approach that leverages
the Retentive Network (RetNet) architecture and integrates a lightweight
residual decoder featuring zero-initialization. SegRet exhibits three key
characteristics: (1) Lightweight Residual Decoder: We incorporate a
zero-initialization layer within the residual network framework, ensuring that
the decoder remains computationally efficient while preserving critical
information flow; (2) Robust Feature Extraction: Utilizing RetNet as the
backbone, our model adeptly extracts hierarchical features from input images,
thereby enhancing the depth and breadth of feature representation; (3)
Parameter Efficiency: SegRet achieves state-of-the-art performance while
significantly reducing the number of parameters, maintaining high accuracy
without compromising on computational resources. Empirical evaluations on
benchmark datasets such as ADE20K, Cityscapes, and COCO-Stuff10K demonstrate
the efficacy of our approach. SegRet delivers impressive results, achieving an
mIoU of 52.23\% on ADE20K with only 95.81M parameters, 83.36\% on Cityscapes,
and 46.63\% on COCO-Stuff. The code is available at:
https://github.com/ZhiyuanLi218/segret.",http://arxiv.org/abs/2502.14014v1
"Fiscal Policy and Household Savings in Central Europe (Poland, Croatia,
  and Slovak Republic) -- A Markov Switching VAR with Covid Shock",2025-02-19T19:00:54Z,Tuhin G M Al Mamun,"This study investigates the effectiveness of fiscal policies on household
consumption, disposable income, and the propensity to consume during the
COVID-19 pandemic across Croatia, Slovakia, and Poland. The purpose is to
assess how variations in government debt, expenditures, revenue, and subsidies
influenced household financial behaviors in response to economic shocks. Using
a Markov Switching VAR model across three regimes: initial impact, peak crisis,
and recovery.This analysis captures changes in household consumption,
disposable income, and consumption propensities under different fiscal policy
measures.
  The findings reveal that the Slovak Republic exhibited the highest fiscal
effectiveness, demonstrating effective government policies that stimulated
consumer spending and supported household income during the pandemic. Croatia
also showed positive outcomes, particularly in terms of income, although rising
government debt posed challenges to overall effectiveness. Conversely, Poland
faced significant obstacles, with its fiscal measures leading to lower
consumption and income outcomes, indicating limited policy efficacy.
  Conclusions emphasize the importance of tailored fiscal measures, as their
effectiveness varied across countries and economic contexts. Recommendations
include reinforcing consumption-supportive policies, particularly during crisis
periods, to stabilize income and consumption expectations. This study
underscores the significance of targeted fiscal actions in promoting household
resilience and economic stability, as exemplified by the successful approach
taken by the Slovak Republic.",http://arxiv.org/abs/2502.14041v1
"On-demand generation of entangled photons pairs in the telecom O-band
  from nanowire quantum dots",2025-02-19T19:53:24Z,"Mohammed K. Alqedra, Chiao-Tzu Huang, Edith Yeung, Wen-Hao Chang, Sofiane Haffouz, Philip J. Poole, Dan Dalacu, Ali W. Elshaari, Val Zwiller","On-demand entangled photon pairs at telecom wavelengths are crucial for
quantum communication, distributed quantum computing, and quantum-enhanced
sensing and metrology. The O-band is particularly advantageous because of its
minimal chromatic dispersion and transmission loss in optical fibers, making it
well-suited for long-distance quantum networks. Site-controlled nanowire
quantum dots have emerged as a promising platform for the on-demand generation
of single and entangled photons, offering high extraction efficiency and the
potential for scalable fabrication in large uniform arrays. However, their
operation has been largely restricted to the visible and first near-infrared
(NIR-I) windows. Here, we demonstrate an on-demand bright source of entangled
photon pairs with high fidelity in the telecom O-band based on site-controlled
nanowire quantum dots. We measure a fine-structure splitting of 4.6 $\mu$eV,
verifying the suitability of the quantum dot for generating high-fidelity
polarization-entangled photon pairs. Full quantum state tomography of the
two-photon state generated by the biexciton\hyph exciton cascade reveals a
maximum fidelity of $85.8\% \pm 1.1\%$ to the $\Phi^+$ Bell state, and a
maximum concurrence of $75.1\% \pm 2.1\%$. We estimate the source efficiency at
the first lens to be 12.5$\%$. This bright, scalable, and deterministic source
of entangled photons in the telecom range represents a valuable step forward in
advancing practical quantum applications at telecom wavelengths.",http://arxiv.org/abs/2502.14071v1
"New accelerating cosmology without dark energy: The particle creation
  approach and the reduced relativistic gas",2025-02-19T22:53:44Z,"P. W. R. Lima, J. A. S. Lima, J. F. Jesus","The standard procedure to explain the accelerated expansion of the Universe
is to assume the existence of an exotic component with negative pressure,
generically called dark energy. Here, we propose a new accelerating flat
cosmology without dark energy, driven by the negative creation pressure of a
reduced relativistic gas (RRG). When the hybrid dark matter of the RRG is
identified with cold dark matter, it describes the so-called CCDM cosmology
whose dynamics is equivalent to the standard $\Lambda$CDM model at both the
background and perturbative levels (linear and nonlinear). This effect is
quantified by the creation parameter $\alpha$. However, when the pressure from
the RRG slightly changes the dynamics of the universe, as measured by a
parameter $b$, the model departs slightly from the standard $\Lambda$CDM
cosmology. Therefore, this two-parametric model ($\alpha, b$) describes a new
scenario whose dynamics is different but close to the late-time scenarios
predicted by CCDM and $\Lambda$CDM models. The free parameters of the RRG model
with creation are constrained based on SNe Ia data (Pantheon+SH0ES) and also
using $H(z)$ from cosmic clocks. In principle, this mild distinction in
comparison with both CCDM or $\Lambda$CDM may help alleviate some cosmological
problems plaguing the current standard cosmology.",http://arxiv.org/abs/2502.14139v1
Causal Mean Field Multi-Agent Reinforcement Learning,2025-02-20T02:15:58Z,"Hao Ma, Zhiqiang Pu, Yi Pan, Boyin Liu, Junlong Gao, Zhenyu Guo","Scalability remains a challenge in multi-agent reinforcement learning and is
currently under active research. A framework named mean-field reinforcement
learning (MFRL) could alleviate the scalability problem by employing the Mean
Field Theory to turn a many-agent problem into a two-agent problem. However,
this framework lacks the ability to identify essential interactions under
nonstationary environments. Causality contains relatively invariant mechanisms
behind interactions, though environments are nonstationary. Therefore, we
propose an algorithm called causal mean-field Q-learning (CMFQ) to address the
scalability problem. CMFQ is ever more robust toward the change of the number
of agents though inheriting the compressed representation of MFRL's
action-state space. Firstly, we model the causality behind the decision-making
process of MFRL into a structural causal model (SCM). Then the essential degree
of each interaction is quantified via intervening on the SCM. Furthermore, we
design the causality-aware compact representation for behavioral information of
agents as the weighted sum of all behavioral information according to their
causal effects. We test CMFQ in a mixed cooperative-competitive game and a
cooperative game. The result shows that our method has excellent scalability
performance in both training in environments containing a large number of
agents and testing in environments containing much more agents.",http://arxiv.org/abs/2502.14200v1
"Fact or Guesswork? Evaluating Large Language Model's Medical Knowledge
  with Structured One-Hop Judgment",2025-02-20T05:27:51Z,"Jiaxi Li, Yiwei Wang, Kai Zhang, Yujun Cai, Bryan Hooi, Nanyun Peng, Kai-Wei Chang, Jin Lu","Large language models (LLMs) have been widely adopted in various downstream
task domains. However, their ability to directly recall and apply factual
medical knowledge remains under-explored. Most existing medical QA benchmarks
assess complex reasoning or multi-hop inference, making it difficult to isolate
LLMs' inherent medical knowledge from their reasoning capabilities. Given the
high-stakes nature of medical applications, where incorrect information can
have critical consequences, it is essential to evaluate how well LLMs encode,
retain, and recall fundamental medical facts.
  To bridge this gap, we introduce the Medical Knowledge Judgment, a dataset
specifically designed to measure LLMs' one-hop factual medical knowledge. MKJ
is constructed from the Unified Medical Language System (UMLS), a large-scale
repository of standardized biomedical vocabularies and knowledge graphs. We
frame knowledge assessment as a binary judgment task, requiring LLMs to verify
the correctness of medical statements extracted from reliable and structured
knowledge sources.
  Our experiments reveal that LLMs struggle with factual medical knowledge
retention, exhibiting significant performance variance across different
semantic categories, particularly for rare medical conditions. Furthermore,
LLMs show poor calibration, often being overconfident in incorrect answers. To
mitigate these issues, we explore retrieval-augmented generation, demonstrating
its effectiveness in improving factual accuracy and reducing uncertainty in
medical decision-making.",http://arxiv.org/abs/2502.14275v1
"Experimental demonstrations of Josephson threshold detectors for
  broadband microwave photons detection",2025-02-20T06:31:05Z,"Jia-Xing He, Ya-Qiang Chai, Peng-Hui Ouyang, Hong Chang, L. F. Wei","Current-biased Josephson junctions (CBJJs) have been demonstrated as
sensitive Josephson threshold detectors (JTDs) in the infrared range. In this
letter, we show this kind of detector could also be used to detect broadband
microwave photons. Based on the numerical simulations of the noise-driving
phase dynamics of an underdamped Josephson junction, driven by the
low-frequency triangular wave current, we argue that the microwave photons
flowing across the JJ can be detected by probing the voltage switched signals
of the JJ. Experimentally, we designed and fabricated the relevant Al/AlOx/Al
Josephson device and measured its response to microwave photons at 50~mK
temperature. Experimental results indicate that the weak microwave signals
could be threatened as the additional noises modify the phase dynamics of the
CBJJ, which could thus be detected by the generated JTD. The detection
sensitivity is characterized by using the Kumar-Caroll index to differentiate
the junction switched duration distributions, with and without microwave signal
input. Although the demonstrated detection sensitivity is just $-92$~dBm
(corresponding to approximately 30~photon/ns) for the microwave photons at
$\sim 5$GHz (which is manifestly deviated from the plasma frequency of the
fabricated JJ), we argued, based on the relevant numerical simulations, that
the generated JTD could be used to achieve the sensitive detection of the
microwave photons at the plasma frequency of the JJ.",http://arxiv.org/abs/2502.14300v1
"Topology-Aware Wavelet Mamba for Airway Structure Segmentation in
  Postoperative Recurrent Nasopharyngeal Carcinoma CT Scans",2025-02-20T08:40:41Z,"Haishan Huang, Pengchen Liang, Naier Lin, Luxi Wang, Bin Pu, Jianguo Chen, Qing Chang, Xia Shen, Guo Ran","Nasopharyngeal carcinoma (NPC) patients often undergo radiotherapy and
chemotherapy, which can lead to postoperative complications such as limited
mouth opening and joint stiffness, particularly in recurrent cases that require
re-surgery. These complications can affect airway function, making accurate
postoperative airway risk assessment essential for managing patient care.
Accurate segmentation of airway-related structures in postoperative CT scans is
crucial for assessing these risks. This study introduces TopoWMamba
(Topology-aware Wavelet Mamba), a novel segmentation model specifically
designed to address the challenges of postoperative airway risk evaluation in
recurrent NPC patients. TopoWMamba combines wavelet-based multi-scale feature
extraction, state-space sequence modeling, and topology-aware modules to
segment airway-related structures in CT scans robustly. By leveraging the
Wavelet-based Mamba Block (WMB) for hierarchical frequency decomposition and
the Snake Conv VSS (SCVSS) module to preserve anatomical continuity, TopoWMamba
effectively captures both fine-grained boundaries and global structural
context, crucial for accurate segmentation in complex postoperative scenarios.
Through extensive testing on the NPCSegCT dataset, TopoWMamba achieves an
average Dice score of 88.02%, outperforming existing models such as UNet,
Attention UNet, and SwinUNet. Additionally, TopoWMamba is tested on the SegRap
2023 Challenge dataset, where it shows a significant improvement in trachea
segmentation with a Dice score of 95.26%. The proposed model provides a strong
foundation for automated segmentation, enabling more accurate postoperative
airway risk evaluation.",http://arxiv.org/abs/2502.14363v1
"Predicting Filter Medium Performances in Chamber Filter Presses with
  Digital Twins Using Neural Network Technologies",2025-02-20T13:55:53Z,"Dennis Teutscher, Tyll Weber-Carstanjen, Stephan Simonis, Mathias J. Krause","Efficient solid-liquid separation is crucial in industries like mining, but
traditional chamber filter presses depend heavily on manual monitoring, leading
to inefficiencies, downtime, and resource wastage. This paper introduces a
machine learning-powered digital twin framework to improve operational
flexibility and predictive control. A key challenge addressed is the
degradation of the filter medium due to repeated cycles and clogging, which
reduces filtration efficiency. To solve this, a neural network-based predictive
model was developed to forecast operational parameters, such as pressure and
flow rates, under various conditions. This predictive capability allows for
optimized filtration cycles, reduced downtime, and improved process efficiency.
Additionally, the model predicts the filter mediums lifespan, aiding in
maintenance planning and resource sustainability. The digital twin framework
enables seamless data exchange between filter press sensors and the predictive
model, ensuring continuous updates to the training data and enhancing accuracy
over time. Two neural network architectures, feedforward and recurrent, were
evaluated. The recurrent neural network outperformed the feedforward model,
demonstrating superior generalization. It achieved a relative $L^2$-norm error
of $5\%$ for pressure and $9.3\%$ for flow rate prediction on partially known
data. For completely unknown data, the relative errors were $18.4\%$ and
$15.4\%$, respectively. Qualitative analysis showed strong alignment between
predicted and measured data, with deviations within a confidence band of
$8.2\%$ for pressure and $4.8\%$ for flow rate predictions. This work
contributes an accurate predictive model, a new approach to predicting filter
medium cycle impacts, and a real-time interface for model updates, ensuring
adaptability to changing operational conditions.",http://arxiv.org/abs/2502.14571v1
"Vision Foundation Models in Medical Image Analysis: Advances and
  Challenges",2025-02-20T14:13:46Z,"Pengchen Liang, Bin Pu, Haishan Huang, Yiwei Li, Hualiang Wang, Weibo Ma, Qing Chang","The rapid development of Vision Foundation Models (VFMs), particularly Vision
Transformers (ViT) and Segment Anything Model (SAM), has sparked significant
advances in the field of medical image analysis. These models have demonstrated
exceptional capabilities in capturing long-range dependencies and achieving
high generalization in segmentation tasks. However, adapting these large models
to medical image analysis presents several challenges, including domain
differences between medical and natural images, the need for efficient model
adaptation strategies, and the limitations of small-scale medical datasets.
This paper reviews the state-of-the-art research on the adaptation of VFMs to
medical image segmentation, focusing on the challenges of domain adaptation,
model compression, and federated learning. We discuss the latest developments
in adapter-based improvements, knowledge distillation techniques, and
multi-scale contextual feature modeling, and propose future directions to
overcome these bottlenecks. Our analysis highlights the potential of VFMs,
along with emerging methodologies such as federated learning and model
compression, to revolutionize medical image analysis and enhance clinical
applications. The goal of this work is to provide a comprehensive overview of
current approaches and suggest key areas for future research that can drive the
next wave of innovation in medical image segmentation.",http://arxiv.org/abs/2502.14584v1
"Enhancing nuclear cross-section predictions with deep learning: the DINo
  algorithm",2025-02-20T14:33:33Z,"Levana Gesson, Greg Henning, Jonathan Collin, Marie Vanstalle","Accurate modeling of nuclear reaction cross-sections is crucial for
applications such as hadron therapy, radiation protection, and nuclear reactor
design. Despite continuous advancements in nuclear physics, significant
discrepancies persist between experimental data and theoretical models such as
TENDL, and ENDF/B. These deviations introduce uncertainties in Monte Carlo
simulations widely used in nuclear physics and medical applications. In this
work, DINo (Deep learning Intelligence for Nuclear reactiOns) is introduced as
a deep learning-based algorithm designed to improve cross-section predictions
by learning correlations between charge-changing and total cross-sections.
Trained on the TENDL-2021 dataset and validated against experimental data from
the EXFOR database, DINo demonstrates a significant improvement in predictive
accuracy over conventional nuclear models. The results show that DINo
systematically achieves lower chi2 values compared to TENDL-2021 across
multiple isotopes, particularly for proton-induced reactions on a 12C target.
Specifically, for 11C production, DINo reduces the discrepancy with
experimental data by \sim 28\% compared to TENDL-2021. Additionally, DINo
provides improved predictions for other relevant isotopes produced, such as
4He, 6Li, 9Be, and 10B, which play a crucial role in modeling nuclear
fragmentation processes. By leveraging neural networks, DINo offers fast
cross-section predictions, making it a promising complementary tool for nuclear
reaction modeling. However, the algorithm's performance evaluation is sensitive
to the availability of experimental data, with increased uncertainty in
sparsely measured energy ranges. Future work will focus on refining the model
through data augmentation, expanding its applicability to other reaction
channels, and integrating it into Monte Carlo transport codes for real-time
nuclear data processing.",http://arxiv.org/abs/2502.14599v1
"Length-Controlled Margin-Based Preference Optimization without Reference
  Model",2025-02-20T15:30:27Z,"Gengxu Li, Tingyu Xia, Yi Chang, Yuan Wu","Direct Preference Optimization (DPO) is a widely adopted offline algorithm
for preference-based reinforcement learning from human feedback (RLHF),
designed to improve training simplicity and stability by redefining reward
functions. However, DPO is hindered by several limitations, including length
bias, memory inefficiency, and probability degradation. To address these
challenges, we propose Length-Controlled Margin-Based Preference Optimization
(LMPO), a more efficient and robust alternative. LMPO introduces a uniform
reference model as an upper bound for the DPO loss, enabling a more accurate
approximation of the original optimization objective. Additionally, an average
log-probability optimization strategy is employed to minimize discrepancies
between training and inference phases. A key innovation of LMPO lies in its
Length-Controlled Margin-Based loss function, integrated within the
Bradley-Terry framework. This loss function regulates response length while
simultaneously widening the margin between preferred and rejected outputs. By
doing so, it mitigates probability degradation for both accepted and discarded
responses, addressing a significant limitation of existing methods. We evaluate
LMPO against state-of-the-art preference optimization techniques on two
open-ended large language models, Mistral and LLaMA3, across six conditional
benchmarks. Our experimental results demonstrate that LMPO effectively controls
response length, reduces probability degradation, and outperforms existing
approaches. The code is available at \url{https://github.com/gengxuli/LMPO}.",http://arxiv.org/abs/2502.14643v1
Ranking Joint Policies in Dynamic Games using Evolutionary Dynamics,2025-02-20T16:50:38Z,"Natalia Koliou, George Vouros","Game-theoretic solution concepts, such as the Nash equilibrium, have been key
to finding stable joint actions in multi-player games. However, it has been
shown that the dynamics of agents' interactions, even in simple two-player
games with few strategies, are incapable of reaching Nash equilibria,
exhibiting complex and unpredictable behavior. Instead, evolutionary approaches
can describe the long-term persistence of strategies and filter out transient
ones, accounting for the long-term dynamics of agents' interactions. Our goal
is to identify agents' joint strategies that result in stable behavior, being
resistant to changes, while also accounting for agents' payoffs, in dynamic
games. Towards this goal, and building on previous results, this paper proposes
transforming dynamic games into their empirical forms by considering agents'
strategies instead of agents' actions, and applying the evolutionary
methodology $\alpha$-Rank to evaluate and rank strategy profiles according to
their long-term dynamics. This methodology not only allows us to identify joint
strategies that are strong through agents' long-term interactions, but also
provides a descriptive, transparent framework regarding the high ranking of
these strategies. Experiments report on agents that aim to collaboratively
solve a stochastic version of the graph coloring problem. We consider different
styles of play as strategies to define the empirical game, and train policies
realizing these strategies, using the DQN algorithm. Then we run simulations to
generate the payoff matrix required by $\alpha$-Rank to rank joint strategies.",http://arxiv.org/abs/2502.14724v1
"Beyond Performance Scores: Directed Functional Connectivity as a
  Brain-Based Biomarker for Motor Skill Learning and Retention",2025-02-20T16:55:08Z,"Anil Kamat, Rahul Rahul, Lora Cavuoto, Harry Burke, Matthew Hackett, Jack Norfleet, Steven Schwaitzberg, Suvranu De","Motor skill acquisition in fields like surgery, robotics, and sports involves
learning complex task sequences through extensive training. Traditional
performance metrics, like execution time and error rates, offer limited insight
as they fail to capture the neural mechanisms underlying skill learning and
retention. This study introduces directed functional connectivity (dFC),
derived from electroencephalography (EEG), as a novel brain-based biomarker for
assessing motor skill learning and retention. For the first time, dFC is
applied as a biomarker to map the stages of the Fitts and Posner motor learning
model, offering new insights into the neural mechanisms underlying skill
acquisition and retention. Unlike traditional measures, it captures both the
strength and direction of neural information flow, providing a comprehensive
understanding of neural adaptations across different learning stages. The
analysis demonstrates that dFC can effectively identify and track the
progression through various stages of the Fitts and Posner model. Furthermore,
its stability over a six-week washout period highlights its utility in
monitoring long-term retention. No significant changes in dFC were observed in
a control group, confirming that the observed neural adaptations were specific
to training and not due to external factors. By offering a granular view of the
learning process at the group and individual levels, dFC facilitates the
development of personalized, targeted training protocols aimed at enhancing
outcomes in fields where precision and long-term retention are critical, such
as surgical education. These findings underscore the value of dFC as a robust
biomarker that complements traditional performance metrics, providing a deeper
understanding of motor skill learning and retention.",http://arxiv.org/abs/2502.14731v1
Multi-Agent Coordination across Diverse Applications: A Survey,2025-02-20T17:12:45Z,"Lijun Sun, Yijun Yang, Qiqi Duan, Yuhui Shi, Chao Lyu, Yu-Cheng Chang, Chin-Teng Lin, Yang Shen","Multi-agent coordination studies the underlying mechanism enabling the
trending spread of diverse multi-agent systems (MAS) and has received
increasing attention, driven by the expansion of emerging applications and
rapid AI advances. This survey outlines the current state of coordination
research across applications through a unified understanding that answers four
fundamental coordination questions: (1) what is coordination; (2) why
coordination; (3) who to coordinate with; and (4) how to coordinate. Our
purpose is to explore existing ideas and expertise in coordination and their
connections across diverse applications, while identifying and highlighting
emerging and promising research directions. First, general coordination
problems that are essential to varied applications are identified and analyzed.
Second, a number of MAS applications are surveyed, ranging from widely studied
domains, e.g., search and rescue, warehouse automation and logistics, and
transportation systems, to emerging fields including humanoid and
anthropomorphic robots, satellite systems, and large language models (LLMs).
Finally, open challenges about the scalability, heterogeneity, and learning
mechanisms of MAS are analyzed and discussed. In particular, we identify the
hybridization of hierarchical and decentralized coordination, human-MAS
coordination, and LLM-based MAS as promising future directions.",http://arxiv.org/abs/2502.14743v1
The illusion of households as entities in social networks,2025-02-20T17:38:31Z,"Izabel Aguiar, Philip S. Chodrow, Johan Ugander","Data recording connections between people in communities and villages are
collected and analyzed in various ways, most often as either networks of
individuals or as networks of households. These two networks can differ in
substantial ways. The methodological choice of which network to study,
therefore, is an important aspect in both study design and data analysis. In
this work, we consider various key differences between household and individual
social network structure, and ways in which the networks cannot be used
interchangeably. In addition to formalizing the choices for representing each
network, we explore the consequences of how the results of social network
analysis change depending on the choice between studying the individual and
household network -- from determining whether networks are assortative or
disassortative to the ranking of influence-maximizing nodes. As our main
contribution, we draw upon related work to propose a set of systematic
recommendations for determining the relevant network representation to study.
Our recommendations include assessing a series of entitativity criteria and
relating these criteria to theories and observations about patterns and norms
in social dynamics at the household level: notably, how information spreads
within households and how power structures and gender roles affect this spread.
We draw upon the definition of an illusion of entitativity to identify cases
wherein grouping people into households does not satisfy these criteria or
adequately represent given cultural or experimental contexts. Given the
widespread use of social network data for studying communities, there is broad
impact in understanding which network to study and the consequences of that
decision. We hope that this work gives guidance to practitioners and
researchers collecting and studying social network data.",http://arxiv.org/abs/2502.14764v1
"SigLIP 2: Multilingual Vision-Language Encoders with Improved Semantic
  Understanding, Localization, and Dense Features",2025-02-20T18:08:29Z,"Michael Tschannen, Alexey Gritsenko, Xiao Wang, Muhammad Ferjad Naeem, Ibrahim Alabdulmohsin, Nikhil Parthasarathy, Talfan Evans, Lucas Beyer, Ye Xia, Basil Mustafa, Olivier Hénaff, Jeremiah Harmsen, Andreas Steiner, Xiaohua Zhai","We introduce SigLIP 2, a family of new multilingual vision-language encoders
that build on the success of the original SigLIP. In this second iteration, we
extend the original image-text training objective with several prior,
independently developed techniques into a unified recipe -- this includes
captioning-based pretraining, self-supervised losses (self-distillation, masked
prediction) and online data curation. With these changes, SigLIP 2 models
outperform their SigLIP counterparts at all model scales in core capabilities,
including zero-shot classification, image-text retrieval, and transfer
performance when extracting visual representations for Vision-Language Models
(VLMs). Furthermore, the new training recipe leads to significant improvements
on localization and dense prediction tasks. We also train variants which
support multiple resolutions and preserve the input's native aspect ratio.
Finally, we train on a more diverse data-mixture that includes de-biasing
techniques, leading to much better multilingual understanding and improved
fairness. To allow users to trade off inference cost with performance, we
release model checkpoints at four sizes: ViT-B (86M), L (303M), So400m (400M),
and g (1B).",http://arxiv.org/abs/2502.14786v1
Revealing and Mitigating Over-Attention in Knowledge Editing,2025-02-20T18:51:12Z,"Pinzheng Wang, Zecheng Tang, Keyan Zhou, Juntao Li, Qiaoming Zhu, Min Zhang","Large Language Models have demonstrated superior performance across a wide
range of tasks, but they still exhibit undesirable errors due to incorrect
knowledge learned from the training data. To avoid this, knowledge editing
methods emerged to precisely edit the specific model knowledge via efficiently
modifying a very small percentage of parameters. % However, those methods can
lead to the problem of Specificity Failure: when the content related to the
edited knowledge occurs in the context, it can inadvertently corrupt other
pre-existing knowledge. However, those methods can lead to the problem of
Specificity Failure, where the existing knowledge and capabilities are severely
degraded due to editing. Our preliminary indicates that Specificity Failure
primarily stems from the model's attention heads assigning excessive attention
scores to entities related to the edited knowledge, thereby unduly focusing on
specific snippets within the context, which we denote as the Attention Drift
phenomenon. To mitigate such Attention Drift issue, we introduce a simple yet
effective method Selective Attention Drift Restriction}(SADR), which introduces
an additional regularization term during the knowledge editing process to
restrict changes in the attention weight distribution, thereby preventing undue
focus on the edited entity. Experiments on five frequently used strong LLMs
demonstrate the effectiveness of our method, where SADR can significantly
mitigate Specificity Failure in the predominant knowledge editing tasks.",http://arxiv.org/abs/2502.14838v1
A Large-Scale Exploratory Study on the Proxy Pattern in Ethereum,2025-01-01T21:52:22Z,"Amir M. Ebrahimi, Bram Adams, Gustavo A. Oliva, Ahmed E. Hassan","The proxy pattern is a well-known design pattern with numerous use cases in
several sectors of the software industry. As such, the use of the proxy pattern
is also a common approach in the development of complex decentralized
applications (DApps) on the Ethereum blockchain. Despite the importance of
proxy contracts, little is known about (i) how their prevalence changed over
time, (ii) the ways in which developers integrate proxies in the design of
DApps, and (iii) what proxy types are being most commonly leveraged by
developers. This study bridges these gaps through a comprehensive analysis of
Ethereum smart contracts, utilizing a dataset of 50 million contracts and 1.6
billion transactions as of September 2022. Our findings reveal that 14.2% of
all deployed smart contracts are proxy contracts. We show that proxy contracts
are being more actively used than non-proxy contracts. Also, the usage of proxy
contracts in various contexts, transactions involving proxy contracts, and
adoption of proxy contracts by users have shown an upward trend over time,
peaking at the end of our study period. They are either deployed through
off-chain scripts or on-chain factory contracts, with the former and latter
being employed in 39.1% and 60.9% of identified usage contexts in turn. We
found that while the majority (67.8%) of proxies act as an interceptor, 32.2%
enables upgradeability. Proxy contracts are typically (79%) implemented based
on known reference implementations with 29.4% being of type ERC-1167, a class
of proxies that aims to cheaply reuse and clone contracts' functionality. Our
evaluation shows that our proposed behavioral proxy detection method has a
precision and recall of 100% in detecting active proxies. Finally, we derive a
set of practical recommendations for developers and introduce open research
questions to guide future research on the topic.",http://arxiv.org/abs/2501.00965v1
"The $z \gtrsim 9$ galaxy UV luminosity function from the JWST Advanced
  Deep Extragalactic Survey: insights into early galaxy evolution and
  reionization",2025-01-02T00:11:12Z,"Lily Whitler, Daniel P. Stark, Michael W. Topping, Brant Robertson, Marcia Rieke, Kevin N. Hainline, Ryan Endsley, Zuyi Chen, William M. Baker, Rachana Bhatawdekar, Andrew J. Bunker, Stefano Carniani, Stéphane Charlot, Jacopo Chevallard, Emma Curtis-Lake, Eiichi Egami, Daniel J. Eisenstein, Jakob M. Helton, Zhiyuan Ji, Benjamin D. Johnson, Pablo G. Pérez-González, Pierluigi Rinaldi, Sandro Tacchella, Christina C. Williams, Christopher N. A. Willmer, Chris Willott, Joris Witstok","The high-redshift UV luminosity function provides important insights into the
evolution of early galaxies. JWST has revealed an unexpectedly large population
of bright ($M_\mathrm{UV} \lesssim -20$) galaxies at $z\gtrsim10$, implying
fundamental changes in the star forming properties of galaxies at increasingly
early times. However, constraining the fainter population ($M_\mathrm{UV}
\gtrsim -18$) has been more challenging. In this work, we present the
$z\gtrsim9$ UV luminosity function from the JWST Advanced Deep Extragalactic
Survey. We calculate the UV luminosity function from several hundred
$z\gtrsim9$ galaxy candidates that reach UV luminosities of
$M_\mathrm{UV}\sim-17$ in redshift bins of $z\sim9-12$ (309 candidates) and
$z\sim12-16$ (63 candidates). We search for candidates at $z\sim16-22.5$ and
find none. We also estimate the $z\sim14-16$ luminosity function from the
$z\geq14$ subset of the $z\sim12-16$ sample. Consistent with other
measurements, we find an excess of bright galaxies that is in tension with many
theoretical models, especially at $z\gtrsim12$. However, we also find high
number densities at $-18\lesssim M_\mathrm{UV} \lesssim-17$, suggesting that
there is a larger population of faint galaxies than expected, as well as bright
ones. From our parametric fits for the luminosity function, we find steep faint
end slopes of $-2.5\lesssim\alpha\lesssim-2.3$, suggesting a large population
of faint ($M_\mathrm{UV} \gtrsim -17$) galaxies. Combined, the high
normalization and steep faint end slope of the luminosity function could imply
that the reionization process is appreciably underway as early as $z=10$.",http://arxiv.org/abs/2501.00984v1
"Design of mechanisms for ensuring the execution of tasks in project
  planning",2025-01-02T13:47:20Z,"Oksana Mulesa, Petro Horvat, Tamara Radivilova, Volodymyr Sabadosh, Oleksii Baranovskyi, Sergii Duran","This paper reports an analysis of aspects of the project planning stage. The
object of research is the decision-making processes that take place at this
stage. This work considers the problem of building a hierarchy of tasks, their
distribution among performers, taking into account restrictions on financial
costs and duration of project implementation. Verbal and mathematical models of
the task of constructing a hierarchy of tasks and other tasks that take place
at the stage of project planning were constructed. Such indicators of the
project implementation process efficiency were introduced as the time, cost,
and cost-time efficiency. In order to be able to apply these criteria, the
tasks of estimating the minimum value of the duration of the project and its
minimum required cost were considered. Appropriate methods have been developed
to solve them. The developed iterative method for assessing the minimum
duration of project implementation is based on taking into account the
possibility of simultaneous execution of various tasks. The method of
estimating the minimum cost of the project is to build and solve the problem of
Boolean programming. The values obtained as a result of solving these problems
form an {\guillemotleft}ideal point{\guillemotright}, approaching which is
enabled by the developed iterative method of constructing a hierarchy of tasks
based on the method of sequential concessions. This method makes it possible to
devise options for management decisions to obtain valid solutions to the
problem. According to them, the decision maker can introduce a concession on
the value of one or both components of the {\guillemotleft}ideal
point{\guillemotright} or change the input data to the task. The models and
methods built can be used when planning projects in education, science,
production, etc.",http://arxiv.org/abs/2501.01255v1
"Quantifying A Firm's AI Engagement: Constructing Objective, Data-Driven,
  AI Stock Indices Using 10-K Filings",2025-01-03T11:27:49Z,"Lennart Ante, Aman Saggu","Following an analysis of existing AI-related exchange-traded funds (ETFs), we
reveal the selection criteria for determining which stocks qualify as
AI-related are often opaque and rely on vague phrases and subjective judgments.
This paper proposes a new, objective, data-driven approach using natural
language processing (NLP) techniques to classify AI stocks by analyzing annual
10-K filings from 3,395 NASDAQ-listed firms between 2011 and 2023. This
analysis quantifies each company's engagement with AI through binary indicators
and weighted AI scores based on the frequency and context of AI-related terms.
Using these metrics, we construct four AI stock indices-the Equally Weighted AI
Index (AII), the Size-Weighted AI Index (SAII), and two Time-Discounted AI
Indices (TAII05 and TAII5X)-offering different perspectives on AI investment.
We validate our methodology through an event study on the launch of OpenAI's
ChatGPT, demonstrating that companies with higher AI engagement saw
significantly greater positive abnormal returns, with analyses supporting the
predictive power of our AI measures. Our indices perform on par with or surpass
14 existing AI-themed ETFs and the Nasdaq Composite Index in risk-return
profiles, market responsiveness, and overall performance, achieving higher
average daily returns and risk-adjusted metrics without increased volatility.
These results suggest our NLP-based approach offers a reliable,
market-responsive, and cost-effective alternative to existing AI-related ETF
products. Our innovative methodology can also guide investors, asset managers,
and policymakers in using corporate data to construct other thematic
portfolios, contributing to a more transparent, data-driven, and competitive
approach.",http://arxiv.org/abs/2501.01763v1
"Accuracy Can Lie: On the Impact of Surrogate Model in Configuration
  Tuning",2025-01-03T15:57:20Z,"Pengzhou Chen, Jingzhi Gong, Tao Chen","To ease the expensive measurements during configuration tuning, it is natural
to build a surrogate model as the replacement of the system, and thereby the
configuration performance can be cheaply evaluated. Yet, a stereotype therein
is that the higher the model accuracy, the better the tuning result would be.
This ""accuracy is all"" belief drives our research community to build more and
more accurate models and criticize a tuner for the inaccuracy of the model
used. However, this practice raises some previously unaddressed questions,
e.g., Do those somewhat small accuracy improvements reported in existing work
really matter much to the tuners? What role does model accuracy play in the
impact of tuning quality? To answer those related questions, we conduct one of
the largest-scale empirical studies to date-running over the period of 13
months 24*7-that covers 10 models, 17 tuners, and 29 systems from the existing
works while under four different commonly used metrics, leading to 13,612 cases
of investigation. Surprisingly, our key findings reveal that the accuracy can
lie: there are a considerable number of cases where higher accuracy actually
leads to no improvement in the tuning outcomes (up to 58% cases under certain
setting), or even worse, it can degrade the tuning quality (up to 24% cases
under certain setting). We also discover that the chosen models in most
proposed tuners are sub-optimal and that the required % of accuracy change to
significantly improve tuning quality varies according to the range of model
accuracy. Deriving from the fitness landscape analysis, we provide in-depth
discussions of the rationale behind, offering several lessons learned as well
as insights for future opportunities. Most importantly, this work poses a clear
message to the community: we should take one step back from the natural
""accuracy is all"" belief for model-based configuration tuning.",http://arxiv.org/abs/2501.01876v1
Balanced Multi-view Clustering,2025-01-05T14:42:47Z,"Zhenglai Li, Jun Wang, Chang Tang, Xinzhong Zhu, Wei Zhang, Xinwang Liu","Multi-view clustering (MvC) aims to integrate information from different
views to enhance the capability of the model in capturing the underlying data
structures. The widely used joint training paradigm in MvC is potentially not
fully leverage the multi-view information, since the imbalanced and
under-optimized view-specific features caused by the uniform learning objective
for all views. For instance, particular views with more discriminative
information could dominate the learning process in the joint training paradigm,
leading to other views being under-optimized. To alleviate this issue, we first
analyze the imbalanced phenomenon in the joint-training paradigm of multi-view
clustering from the perspective of gradient descent for each view-specific
feature extractor. Then, we propose a novel balanced multi-view clustering
(BMvC) method, which introduces a view-specific contrastive regularization
(VCR) to modulate the optimization of each view. Concretely, VCR preserves the
sample similarities captured from the joint features and view-specific ones
into the clustering distributions corresponding to view-specific features to
enhance the learning process of view-specific feature extractors. Additionally,
a theoretical analysis is provided to illustrate that VCR adaptively modulates
the magnitudes of gradients for updating the parameters of view-specific
feature extractors to achieve a balanced multi-view learning procedure. In such
a manner, BMvC achieves a better trade-off between the exploitation of
view-specific patterns and the exploration of view-invariance patterns to fully
learn the multi-view information for the clustering task. Finally, a set of
experiments are conducted to verify the superiority of the proposed method
compared with state-of-the-art approaches on eight benchmark MvC datasets.",http://arxiv.org/abs/2501.02564v3
"Cracks in The Stack: Hidden Vulnerabilities and Licensing Risks in LLM
  Pre-Training Datasets",2025-01-05T18:54:25Z,"Mahmoud Jahanshahi, Audris Mockus","A critical part of creating code suggestion systems is the pre-training of
Large Language Models on vast amounts of source code and natural language text,
often of questionable origin or quality. This may contribute to the presence of
bugs and vulnerabilities in code generated by LLMs. While efforts to identify
bugs at or after code generation exist, it is preferable to pre-train or
fine-tune LLMs on curated, high-quality, and compliant datasets. The need for
vast amounts of training data necessitates that such curation be automated,
minimizing human intervention.
  We propose an automated source code autocuration technique that leverages the
complete version history of open-source software projects to improve the
quality of training data. This approach leverages the version history of all
OSS projects to identify training data samples that have been modified or have
undergone changes in at least one OSS project, and pinpoint a subset of samples
that include fixes for bugs or vulnerabilities. We evaluate this method using
The Stack v2 dataset, and find that 17% of the code versions in the dataset
have newer versions, with 17% of those representing bug fixes, including 2.36%
addressing known CVEs. The deduplicated version of Stack v2 still includes
blobs vulnerable to 6,947 known CVEs. Furthermore, 58% of the blobs in the
dataset were never modified after creation, suggesting they likely represent
software with minimal or no use. Misidentified blob origins present an
additional challenge, as they lead to the inclusion of non-permissively
licensed code, raising serious compliance concerns.
  By addressing these issues, the training of new models can avoid perpetuating
buggy code patterns or license violations. We expect our results to inspire
process improvements for automated data curation, with the potential to enhance
the reliability of outputs generated by AI tools.",http://arxiv.org/abs/2501.02628v1
"A Stable Measure for Conditional Periodicity of Time Series using
  Persistent Homology",2025-01-06T07:32:16Z,"Bala Krishnamoorthy, Elizabeth P. Thompson","Given a pair of time series, we study how the periodicity of one influences
the periodicity of the other. There are several known methods to measure the
similarity between a pair of time series, such as cross-correlation, coherence,
cross-recurrence, and dynamic time warping. But we have yet to find any
measures with theoretical stability results.
  Persistence homology has been utilized to construct a scoring function with
theoretical guarantees of stability that quantifies the periodicity of a single
univariate time series f1, denoted score(f1). Building on this concept, we
propose a conditional periodicity score that quantifies the periodicity of one
univariate time series f1 given another f2, denoted score(f1|f2), and derive
theoretical stability results for the same. With the use of dimension reduction
in mind, we prove a new stability result for score(f1|f2) under principal
component analysis (PCA) when we use the projections of the time series
embeddings onto their respective first K principal components. We show that the
change in our score is bounded by a function of the eigenvalues corresponding
to the remaining (unused) N-K principal components and hence is small when the
first K principal components capture most of the variation in the time series
embeddings. Finally we derive a lower bound on the minimum embedding dimension
to use in our pipeline which guarantees that any two such embeddings give
scores that are within a given epsilon of each other.
  We present a procedure for computing conditional periodicity scores and
implement it on several pairs of synthetic signals. We experimentally compare
our similarity measure to the most-similar statistical measure of
cross-recurrence, and show the increased accuracy and stability of our score
when predicting and measuring whether or not the periodicities of two time
series are similar.",http://arxiv.org/abs/2501.02817v1
"High-temperature measurements of acetylene VUV absorption cross sections
  and application to warm exoplanet atmospheres",2025-01-06T09:13:00Z,"Benjamin Fleury, Mathilde Poveda, Yves Benilan, Roméo Veillet, Olivia Venot, Pascal Tremblin, Nicolas Fray, Marie-Claire Gazeau, Martin Schwell, Antoine Jolly, Nelson de Oliveira, Et-touhami Es-sebbar","Most observed exoplanets have high equilibrium temperatures. Understanding
the chemistry of their atmospheres and interpreting their observations requires
the use of chemical kinetic models including photochemistry. The thermal
dependence of the vacuum ultraviolet (VUV) absorption cross sections of
molecules used in these models is poorly known at high temperatures, leading to
uncertainties in the resulting abundance profiles. The aim of our work is to
study experimentally the thermal dependence of VUV absorption cross sections of
molecules of interest for exoplanet atmospheres and provide accurate data for
use in atmospheric models. This study focuses on acetylene (C2H2). We measured
absorption cross sections of C2H2 at seven temperatures ranging from 296 to 773
K recorded in the 115-230 nm spectral domain using VUV spectroscopy and
synchrotron radiation. These data were used in our 1D thermo-photochemical
model, to assess their impact on the predicted composition of a generic hot
Jupiter-like exoplanet atmosphere. The absolute absorption cross sections of
C2H2 increase with temperature. This increase is relatively constant from 115
to 185 nm and rises sharply from 185 to 230 nm. The abundance profile of C2H2
calculated using the model shows a slight variation, with a maximum decrease of
40% near 5 x 10-5 bar, when using C2H2 absorption cross sections measured at
773 K compared to those at 296 K. This is explained by the absorption, higher
in the atmosphere, of the actinic flux from 150 to 230 nm due to the increase
in the C2H2 absorption in this spectral range. This change also impacts the
abundance profiles of other by-products such as methane (CH4) and ethylene
(C2H4). We present the first experimental measurements of the VUV absorption
cross sections of C2H2 at high temperatures. Similar studies of other major
species are needed to improve our understanding of exoplanet atmospheres.",http://arxiv.org/abs/2501.02864v1
Challenges in identifying the coronal hole wind,2025-01-06T11:21:33Z,"Verena Heidrich-Meisner, Sophie Teichmann, Lars Berger, Robert F. Wimmer-Schweingruber","Solar wind is frequently categorized based on its respective solar source
region. Two well-established categorizations of the coronal hole wind, the
scheme based on the charge-state composition, and the scheme based on proton
plasma, identify a very different fraction of solar wind in the data from the
Advanced Composition Explorer (ACE) as coronal hole wind during the solar
activity minimum at the end of solar cycle 24. We investigate possible
explanations for the different identifications of the coronal wind in 2009 in
the scheme based on the charge-state composition (almost only coronal hole
wind) and in the scheme based on the proton plasma (almost no coronal hole wind
at the same time). We compared the properties of the respective coronal hole
wind types and their changes with solar activity cycle in 2001- 2010. As a
comparison reference, we included the coronal hole wind as identified by an
unsupervised machine-learning approach, k-means, in our analysis. We find that
the scheme based on charge-state composition likely misidentifies some slow
solar wind as coronal hole wind during the solar activity minimum. The k-means
classification we considered includes two types of coronal hole wind, the first
of which is dominant during the solar activity maximum, whereas the second is
dominant during the solar activity minimum. A low fraction of coronal hole wind
from low-latitude coronal holes observed by ACE in 2009 is plausible because
during this time period, a very small number of low-latitude coronal holes was
observed. The results imply that the origin-oriented solar wind classification
needs to be revisited, and they also suggest that an explicit inclusion of the
phase of the solar activity cycle can be expected to improve the classification
of the solar wind.",http://arxiv.org/abs/2501.02935v1
"FlipedRAG: Black-Box Opinion Manipulation Attacks to Retrieval-Augmented
  Generation of Large Language Models",2025-01-06T12:24:57Z,"Zhuo Chen, Yuyang Gong, Miaokun Chen, Haotan Liu, Qikai Cheng, Fan Zhang, Wei Lu, Xiaozhong Liu, Jiawei Liu","Retrieval-Augmented Generation (RAG) addresses hallucination and real-time
constraints by dynamically retrieving relevant information from a knowledge
database to supplement the LLMs' input. When presented with a query, RAG
selects the most semantically similar texts from its knowledge bases and uses
them as context for the LLMs to generate more accurate responses. RAG also
creates a new attack surface, especially since RAG databases are frequently
sourced from public domains. While existing studies have predominantly focused
on optimizing RAG's performance and efficiency, emerging research has begun
addressing the security concerns associated with RAG. However, these works have
some limitations, typically focusing on either white-box methodologies or
heuristic-based black-box attacks. Furthermore, prior research has mainly
targeted simple factoid question answering, which is neither practically
challenging nor resistant to correction. In this paper, we unveil a more
realistic and threatening scenario: opinion manipulation for controversial
topics against RAG. Particularly, we propose a novel RAG black-box attack
method, termed FlipedRAG, which is transfer-based. By leveraging instruction
engineering, we obtain partial retrieval model outputs from black-box RAG
system, facilitating the training of surrogate models to enhance the
effectiveness of opinion manipulation attack. Extensive experimental results
confirms that our approach significantly enhances the average success rate of
opinion manipulation by 16.7%. It achieves an average of a 50% directional
change in the opinion polarity of RAG responses across four themes.
Additionally, it induces a 20% shift in user cognition. Furthermore, we discuss
the efficacy of potential defense mechanisms and conclude that they are
insufficient in mitigating this type of attack, highlighting the urgent need to
develop novel defensive strategies.",http://arxiv.org/abs/2501.02968v2
No evidence (yet) for increased star-formation efficiency at early times,2025-01-06T18:55:05Z,"C. T. Donnan, J. S. Dunlop, R. J. McLure, D. J. McLeod, F. Cullen","Early JWST observations have revealed substantial numbers of galaxies out to
redshifts as high as $z \simeq 14$, reflecting a slow evolution of the galaxy
UV luminosity function (LF) not anticipated by many models of galaxy evolution.
It has also been discovered that fairly massive galaxies existed at early
times, a finding again viewed as a challenge to our understanding of early
galaxy growth or even ${\rm \Lambda}$CDM cosmology. Here we develop and test a
simple theoretical model which shows that these observations are unsurprising,
but instead are arguably as expected if one assumes a non-evolving halo-mass
dependent galaxy-formation efficiency consistent with that observed today.
Crucially, this simple model matches the observed galaxy UV LF over the
redshift range $z \simeq 6-13$ and the galaxy stellar mass function (GSMF) at
$z \simeq 6-8$. When combined with new constraints on Lyman continuum escape
and the ionizing photon production efficiency of early galaxies, our model also
predicts the progress of cosmic hydrogen reionization consistent with current
observational constraints. The requirement to fit both the UV LF and the GSMF
breaks the degeneracy between mass-light ratio and star-formation efficiency,
and our model only works if the typical mass-to-light ratio of galaxies
increases systematically with redshift beyond $z \simeq 6$. However, at present
this does not require changes to the IMF, cosmic dust, or any other new
astrophysics. Rather, the current data can be reproduced simply by assuming
ever-younger stellar populations consistent with a formation epoch at $z \simeq
15$. A key prediction of our model is thus that there should be a more rapid
drop-off in the numbers of galaxy number density beyond $z \simeq 15$, where
one can no longer appeal to ever younger ages to offset the precipitous descent
of the halo mass function.",http://arxiv.org/abs/2501.03217v1
On Beating $2^n$ for the Closest Vector Problem,2025-01-07T10:34:17Z,"Amir Abboud, Rajendra Kumar","The Closest Vector Problem (CVP) is a computational problem in lattices that
is central to modern cryptography. The study of its fine-grained complexity has
gained momentum in the last few years, partly due to the upcoming deployment of
lattice-based cryptosystems in practice. A main motivating question has been if
there is a $(2-\varepsilon)^n$ time algorithm on lattices of rank $n$, or
whether it can be ruled out by SETH.
  Previous work came tantalizingly close to a negative answer by showing a
$2^{(1-o(1))n}$ lower bound under SETH if the underlying distance metric is
changed from the standard $\ell_2$ norm to other $\ell_p$ norms. Moreover,
barriers toward proving such results for $\ell_2$ (and any even $p$) were
established.
  In this paper we show \emph{positive results} for a natural special case of
the problem that has hitherto seemed just as hard, namely
$(0,1)$-$\mathsf{CVP}$ where the lattice vectors are restricted to be sums of
subsets of basis vectors (meaning that all coefficients are $0$ or $1$). All
previous hardness results applied to this problem, and none of the previous
algorithmic techniques could benefit from it. We prove the following results,
which follow from new reductions from $(0,1)$-$\mathsf{CVP}$ to weighted
Max-SAT and minimum-weight $k$-Clique.
  1. An $O(1.7299^n)$ time algorithm for exact $(0,1)$-$\mathsf{CVP}_2$ in
Euclidean norm, breaking the natural $2^n$ barrier, as long as the absolute
value of all coordinates in the input vectors is $2^{o(n)}$.
  2. A computational equivalence between $(0,1)$-$\mathsf{CVP}_p$ and
Max-$p$-SAT for all even $p$.
  3. The minimum-weight-$k$-Clique conjecture from fine-grained complexity and
its numerous consequences (which include the APSP conjecture) can now be
supported by the hardness of a lattice problem, namely
$(0,1)$-$\mathsf{CVP}_2$.",http://arxiv.org/abs/2501.03688v1
Revisiting the Classics: On the Statistics of Dust Formation in Novae,2025-01-07T19:03:51Z,"Atticus Chong, Elias Aydi, Peter Craig, Laura Chomiuk, Ashley Stone, Jay Strader, Adam Kawash, Kirill V. Sokolovsky, Fred Walter","While nova eruptions produce some of the most common and dramatic dust
formation episodes among astrophysical transients, the demographics of
dust-forming novae remain poorly understood. Here, we present a statistical
study of dust formation in 40 novae with high-quality optical/IR light curves,
quantitatively distinguishing dust-forming from non-dust-forming novae while
exploring the properties of the dust events. We find that 50-70% of novae
produce dust, significantly higher than previous estimates. Dust-forming novae
can be separated from those that do not show dust formation by using the
largest redward ($V-K$) colour change from peak visible brightness; ($V-J$) or
($V-H$) offer useful but less sensitive constraints. This makes optical+IR
photometry a powerful tool to quantify dust formation in novae. We find that
novae detected in GeV $\gamma$-rays by \emph{Fermi}-LAT appear to form dust
more often than novae not detected by \emph{Fermi}, implying a possible
connection between $\gamma$-ray producing shocks and dust production. We also
find that novae that evolve very quickly ($t_2 < 10$ days) are much less likely
to form dust, in agreement with previous findings. We confirm a correlation
between $t_2$ and the time of the onset of dust formation (which occurs $\sim$1
week--3 months after maximum light), but conclude that it is primarily an
observational artifact driven by dust formation determining when a nova drops 2
mag below peak. The significant fraction of novae that form dust make them
ideal laboratories in our Galactic backyard to tackle the puzzle of dust
formation around explosive transients.",http://arxiv.org/abs/2501.04098v1
"Drift-oriented Self-evolving Encrypted Traffic Application
  Classification for Actual Network Environment",2025-01-08T03:10:30Z,"Zihan Chen, Guang Cheng, Jinhui Li, Tian Qin, Yuyang Zhou, Xing Luan","Encrypted traffic classification technology is a crucial decision-making
information source for network management and security protection. It has the
advantages of excellent response timeliness, large-scale data bearing, and
cross-time-and-space analysis. The existing research on encrypted traffic
classification has gradually transitioned from the closed world to the open
world, and many classifier optimization and feature engineering schemes have
been proposed. However, encrypted traffic classification has yet to be
effectively applied to the actual network environment. The main reason is that
applications on the Internet are constantly updated, including function
adjustment and version change, which brings severe feature concept drift,
resulting in rapid failure of the classifier. Hence, the entire model must be
retrained only past very fast time, with unacceptable labeled sample
constructing and model training cost. To solve this problem, we deeply study
the characteristics of Internet application updates, associate them with
feature concept drift, and then propose self-evolving encrypted traffic
classification. We propose a feature concept drift determination method and a
drift-oriented self-evolving fine-tuning method based on the Laida criterion to
adapt to all applications that are likely to be updated. In the case of no
exact label samples, the classifier evolves through fully fine-tuning
continuously, and the time interval between two necessary retraining is greatly
extended to be applied to the actual network environment. Experiments show that
our approach significantly improves the classification performance of the
original classifier on the following stage dataset of the following months (9\%
improvement on F1-score) without any hard-to-acquire labeled sample. Under the
current experimental environment, the life of the classifier is extended to
more than eight months.",http://arxiv.org/abs/2501.04246v1
"Instructive3D: Editing Large Reconstruction Models with Text
  Instructions",2025-01-08T09:28:25Z,"Kunal Kathare, Ankit Dhiman, K Vikas Gowda, Siddharth Aravindan, Shubham Monga, Basavaraja Shanthappa Vandrotti, Lokesh R Boregowda","Transformer based methods have enabled users to create, modify, and
comprehend text and image data. Recently proposed Large Reconstruction Models
(LRMs) further extend this by providing the ability to generate high-quality 3D
models with the help of a single object image. These models, however, lack the
ability to manipulate or edit the finer details, such as adding standard design
patterns or changing the color and reflectance of the generated objects, thus
lacking fine-grained control that may be very helpful in domains such as
augmented reality, animation and gaming. Naively training LRMs for this purpose
would require generating precisely edited images and 3D object pairs, which is
computationally expensive. In this paper, we propose Instructive3D, a novel LRM
based model that integrates generation and fine-grained editing, through user
text prompts, of 3D objects into a single model. We accomplish this by adding
an adapter that performs a diffusion process conditioned on a text prompt
specifying edits in the triplane latent space representation of 3D object
models. Our method does not require the generation of edited 3D objects.
Additionally, Instructive3D allows us to perform geometrically consistent
modifications, as the edits done through user-defined text prompts are applied
to the triplane latent representation thus enhancing the versatility and
precision of 3D objects generated. We compare the objects generated by
Instructive3D and a baseline that first generates the 3D object meshes using a
standard LRM model and then edits these 3D objects using text prompts when
images are provided from the Objaverse LVIS dataset. We find that Instructive3D
produces qualitatively superior 3D objects with the properties specified by the
edit prompts.",http://arxiv.org/abs/2501.04374v1
"Anomalous Reversal of Stability in Mo-containing Oxides: A Difficult
  Case Exhibiting Sensitivity to DFT+U and Distortion",2025-01-08T11:30:12Z,"Tzu-chen Liu, Dale Gaines II, Hyungjun Kim, Adolfo Salgado-Casanova, Steven B. Torrisi, Chris Wolverton","Accurate predictions of the properties of transition metal oxides using
density functional theory (DFT) calculations are essential for the
computational design of energy materials. In this work, we investigate the
anomalous reversal of the stability of structural distortions (where distorted
structures go from being energetically favorable to sharply unfavorable
relative to undistorted ones) induced by DFT+U on Mo d-orbitals in layered
AMoO$_2$ (A = Li, Na, K) and rutile-like MoO$_2$. We highlight the significant
impact of varying U$_{\text{eff}}$ values on the structural stability, convex
hull, and thermodynamic stability predictions, noting that deviations can reach
up to the order of 100 meV/atom across these energetic quantities. We find the
transitions in stability are coincident with changes in the electron
localization and magnetic behavior. The anomalous reversal persists across PBE,
r$^2$SCAN functionals, and also with vdW-dispersion energy corrections
(PBE+D3). In Mo-containing oxide systems, high U$_{\text{eff}}$ leads to
inaccurate descriptions of physical quantities and structural relaxations under
artificial symmetry constraints, as demonstrated by the phonon band structures,
the Heyd-Scuseria-Ernzerhof (HSE06) hybrid functional results, and comparisons
with experimental structural data. We conclude that high U$_{\text{eff}}$
values (around 4 eV and above, depending on the specific structures and
compositions) might be unsuitable for energetic predictions in A-Mo-O chemical
spaces. Our results suggest that the common practice of applying DFT+U to
convex hull constructions, especially with high U$_{\text{eff}}$ values derived
from fittings, should be carefully evaluated to ensure that ground states are
correctly reproduced, with careful consideration of dynamic stability and
possible energetically favorable distortions.",http://arxiv.org/abs/2501.04434v1
"Real-Time, Label-free Electrical Transduction of Catalytic Events in a
  Single-Protein Redox Enzymatic Junction",2025-01-08T16:06:41Z,"Tracy Quynh Ha, Albert C. Aragonès, Qiankun Wang, Desmond Koomson, Nashili Kibria, Jhanelle White, Kavita Garg, Jessica Peate, Alex P. S. Brogan, Leigh Aldous, Sarah M. Barry, Ismael Díez-Pérez","Single-enzyme catalysis offers a promising approach for unravelling the
dynamic behaviour of individual enzymes as they undergo a reaction, revealing
the complex heterogeneity that is lost in the averaged ensembles. Here we
demonstrate real-time, label-free monitoring of the electrical transduction of
single-protein enzymatic activity for two redox enzymes, cytochrome P450cam and
glutathione reductase, trapped in an electrochemically controlled nanoscale
tunnelling junction immersed in the aqueous enzymatic mixture. The conductance
switching signal observed in individual transients of the electrical current
flowing through the single-protein junction shows that the tunnelling
conductance is modulated by the enzymatic reaction; subtle changes of the
enzyme redox state occurring during the chemical catalysis process result in
fluctuations of the enzyme junction conductivity, which are captured as a
switching signal. At the applied electrochemical reducing potential for
electrocatalysis, the transient oxidation of the trapped enzyme in every
catalytic cycle opens an additional redox-mediated electron tunnelling channel
in the single protein junction that results in a temporary current jump,
contributing to the observed conductance switching features. The latter is
experimentally assessed via electrochemically controlled conductance
measurements of the single-protein junction. The statistical analysis of the
switching events captured over long time periods results in average frequencies
that correlate well with the reported catalytic turnover values of both enzymes
obtained in standard bulk assays. The single-enzyme experiments reveal the
acute heterogenous behaviour of enzymatic catalysis and the quantification of
single enzyme turnover frequencies.",http://arxiv.org/abs/2501.04589v1
Structures of various types of symmetry in the solar activity cycle,2025-01-08T20:35:33Z,"V. N. Obridko, A. S. Shibalova, D. D. Sokoloff","The solar cycle is a complex phenomenon. To comprehensively understand it, we
have to study various tracers. The most important component of this complex is
the solar dynamo, which is understood as self-excitation of the solar magnetic
field in the form of traveling waves somewhere in the convection zone. Along
with the solar dynamo, the formation of the solar cycle involves other
processes that are associated with the dynamo but are not its necessary part.
We give a review of such phenomena that have not yet been explained in terms of
dynamo theory. We consider the manifestations of the solar cycle in harmonics
of the solar large-scale surface magnetic field, including zonal, sectorial,
and tesseral harmonics; analyze their contribution to magnetic energy; and
identify phases of the activity cycle using harmonics of different types of
symmetry. The universal magnetic scenario of a solar activity cycle does not
depend on its number and height. At the beginning of the cycle on the
photosphere, the zonal harmonics account for 37-42% of the total energy (not
100%, as assumed in simplified descriptions). Sectorial harmonics do not
disappear at all but account for 5-10% of the total energy. At this stage, the
greatest energy (about 40%) is contained in the tesseral harmonics. As the
cycle develops, the relative energy of zonal harmonics gradually decreases,
reaching a minimum of 15-18% immediately before the onset of the sunspot
maximum. The relative energy of sectorial harmonics increases and reaches a
maximum (60-65%) somewhat later than the calendar date of the sunspot maximum.
A particular feature of the tesseral harmonics is that their relative energy
index changes in a much narrower range and never falls below 40% even at the
cycle minimum. This is due to active regions and nonglobal magnetic fields. It
is possible that tesseral harmonics are formed in shallow subphotospheric
layers.",http://arxiv.org/abs/2501.04829v1
"The Rapid ASKAP Continuum Survey (RACS) VI: The RACS-high 1655.5 MHz
  images and catalogue",2025-01-09T05:25:24Z,"S. W. Duchesne, K. Ross, A. J. M. Thomson, E. Lenc, Tara Murphy, T. J. Galvin, A. W. Hotan, V. A. Moss, Matthew T. Whiting","We have conducted a widefield, wideband, snapshot survey using the Australian
SKA Pathfinder (ASKAP) referred to as the Rapid ASKAP Continuum Survey (RACS).
RACS covers $\approx$ 90% of the sky, with multiple observing epochs in three
frequency bands sampling the ASKAP frequency range of 700 to 1800 MHz. This
paper describes the third major epoch at 1655.5 MHz, RACS-high, and the
subsequent imaging and catalogue data release. The RACS-high observations at
1655.5 MHz are otherwise similar to the previously released RACS-mid (at 1367.5
MHz), and were calibrated and imaged with minimal changes. From the 1493 images
covering the sky up to declination $\approx$ +48$^\circ$, we present a
catalogue of 2 677 509 radio sources. The catalogue is constructed from images
with a median root-mean-square noise of $\approx$ 195 $\mu$Jy PSF$^{-1}$
(point-spread function) and a median angular resolution of 11.8"" by 8.1"". The
overall reliability of the catalogue is estimated to be 99.18%, and we find a
decrease in reliability as angular resolution improves. We estimate the
brightness scale to be accurate to 10%, and the astrometric accuracy to be
within $\approx$ 0.6"" in right ascension and $\approx$ 0.7"" in declination
after correction of a systematic declination-dependent offset. All data
products from RACS-high, including calibrated visibility datasets, images from
individual observations, full-sensitivity mosaics, and the all-sky catalogue
are available at the CSIRO ASKAP Science Data Archive.",http://arxiv.org/abs/2501.04978v1
"Planetary Nebulae of the Large Magellanic Cloud II: the connection with
  the progenitors' properties",2025-01-09T07:14:45Z,"P. Ventura, S. Tosi, D. A. García-Hernández, F. Dell'Agli, D. Kamath, L. Stanghellini, S. Bianchi, M. Tailo, M. A. Gómez-Muñoz","The study of planetary nebulae (PNe) offers the opportunity of evaluating the
efficiency of the dust production mechanism during the very late asymptotic
giant branch (AGB) phases. We study the relationship between the properties of
PNe, particularly the gas and dust content, with the mass and metallicity of
the progenitor stars, to understand how dust production works in the late AGB
phases, and to shed new light on the physical processes occurring to the stars
and the material in their surroundings since the departure from the AGB until
the PN phase. We consider a sample of 9 PNe in the Large Magellanic Cloud, 7
out of which characterized by the presence of carbonaceous dust, the remaining
2 with silicates. For these stars the masses and the metallicity of the
progenitor stars were estimated. We combine results from stellar evolution and
dust formation modelling with those coming from the analysis of the spectral
energy distribution, to find the relation between the dust and gas mass of the
PNe considered and the The physical properties of carbon-rich PNe are
influenced by the mass of the progenitor star. Specifically, the dust-to-gas
ratio in the nebula increases from 5x10^{-4}to 6x10^{-3} as the progenitor
star's mass increases from approximately 0.9Msun to 2Msun. This change is
partly influenced by the effective temperature of the PNe, and it occurs
because higher-mass carbon stars are more efficient at producing dust.
Consequently, as the progenitor's mass increases, the gas mass of the PNe
decreases, since the larger amounts of dust lead to greater effects from
radiation pressure, which pushes the gas outwards. No meaningful conclusions
can be drawn by the study of the PNe with silicate-type dust, because the
sub-sample is made up of 2 PNe only, one of which is almost dust-free.",http://arxiv.org/abs/2501.05013v1
"SWE-Fixer: Training Open-Source LLMs for Effective and Efficient GitHub
  Issue Resolution",2025-01-09T07:54:24Z,"Chengxing Xie, Bowen Li, Chang Gao, He Du, Wai Lam, Difan Zou, Kai Chen","Large Language Models (LLMs) have demonstrated remarkable proficiency across
a variety of complex tasks. One significant application of LLMs is in tackling
software engineering challenges, particularly in resolving real-world tasks on
GitHub by fixing code based on the issues reported by the users. However, many
current approaches rely on proprietary LLMs, which limits reproducibility,
accessibility, and transparency. The critical components of LLMs for addressing
software engineering issues and how their capabilities can be effectively
enhanced remain unclear. To address these challenges, we introduce SWE-Fixer, a
novel open-source framework designed to effectively and efficiently resolve
GitHub issues. SWE-Fixer comprises two essential modules: a code file retrieval
module and a code editing module. The retrieval module employs BM25 along with
a lightweight model to achieve coarse-to-fine file retrieval. Subsequently, the
code editing module utilizes the other model to generate patches for the
identified files. To mitigate the lack of publicly available datasets, we
compile an extensive dataset that includes 110K GitHub issues along with their
corresponding patches and train the two models of SWE-Fixer separately. We
assess our approach on the SWE-Bench Lite and Verified benchmarks, achieving
state-of-the-art performance among open-source models with scores of 24.7% and
32.8%, respectively. Additionally, our approach requires only two model calls
per instance, making it significantly more efficient than existing methods.
These results highlight the effectiveness of SWE-Fixer in real-world
code-fixing scenarios. We will make our model, dataset, and code publicly
available at https://github.com/InternLM/SWE-Fixer.",http://arxiv.org/abs/2501.05040v2
"Migration of phthalate plasticisers in heritage objects made of
  poly(vinyl chloride): mechanical and environmental aspects",2025-01-09T09:14:08Z,"Sonia Bujok, Tomasz Pańczyk, Kosma Szutkowski, Dominika Anioł, Sergii Antropov, Krzysztof Kruczała, Łukasz Bratasz","To clean or not to clean? The solution to this dilemma is related to
understanding the plasticiser migration which has a few practical implications
for the state of museum artefacts made of plasticised poly(vinyl chloride) -
PVC and objects stored in their vicinity. The consequences of this process
encompass aesthetic changes due to the presence of exudates and dust
deposition, an increase in air pollution and the development of mechanical
stresses. Therefore, this paper discusses the plasticiser migration in PVC to
provide evidence and support the development of recommendations and guidelines
for conservators, collection managers and heritage scientists. Particularly,
the investigation is focused on the migration of the ortho-phthalates
representing the group of the most abundant plasticisers in PVC collections.
The predominance of inner diffusion or surface emission (evaporation)
determining the rate-limiting step of the overall migration process is
considered a fundament for understanding the potential environmental and
mechanical risk. According to this concept, general correlations for various
ortho-phthalates are proposed depending on their molar mass with the support of
molecular dynamics simulations and NMR diffusometry. The study reveals that for
the majority of the PVC objects in collections, the risk of accelerated
migration upon mild removal of surface plasticiser exudate is low. Thus,
surface cleaning would allow for diminishing dust deposition and air pollution
by phthalate-emitting objects in a museum environment. Bearing in mind
simplicity and the need for fast decision-supporting solutions, the
step-by-step protocol for non-destructive identification and quantification of
plasticisers in objects made of or containing plasticised PVC, determination of
the physical state of investigated artefacts and rate-limiting process of
plasticiser migration is proposed.",http://arxiv.org/abs/2501.05090v1
"The ESO SupJup Survey V: Exploring Atmospheric Variability and Orbit of
  the Super-Jupiter AB Pictoris b with CRIRES+",2025-01-09T10:00:50Z,"Siddharth Gandhi, Sam de Regt, Ignas Snellen, Paulina Palma-Bifani, Idriss Abdoulwahab, Gaël Chauvin, Darío González Picos, Yapeng Zhang, Rico Landman, Tomas Stolker, Aurora Kesseli, Willeke Mulder, Antoine Chomez, Anne-Marie Lagrange, Alice Zurlo","A growing number of directly-imaged companions have been recently
characterised, with robust constraints on carbon-to-oxygen ratios and even
isotopic ratios. Many companions and isolated targets have also shown spectral
variability. In this work we observed the super-Jupiter AB~Pictoris~b across
four consecutive nights using VLT/CRIRES+ as part of the ESO SupJup survey,
exploring how the constraints on chemical composition and temperature profile
change over time using spectral line shape variations between nights. We
performed atmospheric retrievals of the high-resolution observations and found
broadly consistent results across all four nights, but there were differences
for some parameters. We clearly detect H$_2$O, $^{12}$CO and $^{13}$CO in each
night, but abundances varied by $\sim2\sigma$, which was correlated to the deep
atmosphere temperature profiles. We also found differences in the
$^{12}$C$/^{13}$C ratios in each night by up to $\sim3\sigma$, which seemed to
be correlated with the cloud deck pressure. Our combined retrieval
simultaneously analysing all nights together constrained broadly the average of
each night individually, with the C/O$=0.59\pm0.01$, consistent with solar
composition, and $^{12}$C$/^{13}$C~$ = 102\pm8$, slightly higher than the ISM
and Solar System values. We also find a low projected rotational velocity,
suggesting that AB~Pictoris~b is either intrinsically a slow rotator due to its
young age or that the spin axis is observed pole-on with a $\sim90^\circ$
misalignment with its orbit inclination. Future observations will be able to
further explore the variability and orbit of AB~Pictoris~b as well as for other
companions.",http://arxiv.org/abs/2501.05114v1
Conditioning of the solar corona due to large flares,2025-01-09T10:03:21Z,"Julia K. Thalmann, Manu Gupta, Astrid M. Veronig, Yang Liu","We aim to better characterize the conditions of the solar corona, especially
with respect to the occurrence of confined and eruptive flares. In this work,
we model the coronal evolution around 231 large flares observed during solar
cycle 24. Using Helioseismic and Magnetic Imager vector magnetic field data
around each event, we employed nonlinear force-free field extrapolations to
approximate the coronal energy and helicity budgets of the solar source
regions. A superposed epoch analysis and dynamical time warping applied to the
time series of selected photospheric and coronal quantities were used to pin
down the characteristics of the pre- and postflare time evolution, as well as
to assess flare-related changes. During the 24 hours leading up to a major
flare, the total magnetic energy and unsigned magnetic flux were seen to evolve
closely with respect to each other, irrespective of the flare type. Prior to
confined flares, the free energy evolves in a way that exhibits more of a
similarity with the unsigned flux than the helicity of the current-carrying
field, while the opposite trend is seen prior to eruptive flares. Furthermore,
the flare type can be predicted correctly in more than 90\% of major flares
when combining measures of the active regions nonpotentiality and local
stability. The coronal energy and helicity budgets return to preflare levels
within approximately six to 12 hours after eruptive major M-class flares, while
the impact of eruptive X-flares lasts considerably longer. Finally, the
postflare replenishment times of more than 12 hours after eruptive X-class
flares may serve as a partial explanation for the rare observation of eruptive
X-class flares within a time frame of a few hours.",http://arxiv.org/abs/2501.05116v2
"More than a void? The detection and characterization of cavities in a
  simulated galaxy's interstellar medium",2025-01-09T21:17:28Z,"Abolfazl Taghribi, Marco Canducci, Michele Mastropietro, Sven De Rijcke, Reynier Frans Peletier, Peter Tino, Kerstin Bunte","The interstellar medium of galaxies is filled with holes, bubbles, and
shells, typically interpreted as remnants of stellar evolution. There is
growing interest in the study of their properties to investigate stellar and
supernova feedback. So far, the detection of cavities in observational and
numerical data is mostly done visually and, hence, is prone to biases.
Therefore, we present an automated, objective method for discovering cavities
in particle simulations, with demonstrations using hydrodynamical simulations
of a dwarf galaxy. The suggested technique extracts holes based on the
persistent homology of particle positions and identifies tight boundary points
around each. With a synthetic ground-truth analysis, we investigate the
relationship between data density and the detection radius, demonstrating that
higher data density also allows for the robust detection of smaller cavities.
By tracking the boundary points, we can measure the shape and physical
properties of the cavity, such as its temperature. In this contribution, we
detect 808 holes in 21 simulation snapshots. We classified the holes into
supernova-blown bubbles and cavities unrelated to stellar feedback activity
based on their temperature profile and expansion behaviour during the 100
million years covered by the simulation snapshots analysed for this work.
Surprisingly, less than 40% of the detected cavities can unequivocally be
linked to stellar evolution. Moreover, about 36% of the cavities are
contracting, while 59% are expanding. The rest do not change for a few million
years. Clearly, it is erroneous to interpret observational data based on the
premise that all cavities are supernova-related and expanding. This study
reveals that supernova-driven bubbles typically exhibit smaller diameters,
larger expansion velocities, and lower kinetic ages (with a maximum of 220
million years) compared to other cavities.",http://arxiv.org/abs/2501.05581v1
"Tunable superconductivity coexisting with the anomalous Hall effect in
  1T'-WS2",2025-01-10T14:08:58Z,"Md Shafayat Hossain, Qi Zhang, David Graf, Mikel Iraola, Tobias Müller, Sougata Mardanya, Yi-Hsin Tu, Zhuangchai Lai, Martina O. Soldini, Siyuan Li, Yao Yao, Yu-Xiao Jiang, Zi-Jia Cheng, Maksim Litskevich, Brian Casas, Tyler A. Cochran, Xian P. Yang, Byunghoon Kim, Kenji Watanabe, Takashi Taniguchi, Sugata Chowdhury, Arun Bansil, Hua Zhang, Tay-Rong Chang, Mark Fischer, Titus Neupert, Luis Balicas, M. Zahid Hasan","Transition metal dichalcogenides are a family of quasi-two-dimensional
materials that display a high technological potential due to their wide range
of electronic ground states, e.g., from superconducting to semiconducting,
depending on the chemical composition, crystal structure, or electrostatic
doping. Here, we unveil that by tuning a single parameter, the hydrostatic
pressure P, a cascade of electronic phase transitions can be induced in the
few-layer transition metal dichalcogenide 1T'-WS2, including superconducting,
topological, and anomalous Hall effect phases. Specifically, as P increases, we
observe a dual phase transition: the suppression of superconductivity with the
concomitant emergence of an anomalous Hall effect at P=1.15 GPa. Remarkably,
upon further increasing the pressure above 1.6 GPa, we uncover a reentrant
superconducting state that emerges out of a state still exhibiting an anomalous
Hall effect. This superconducting state shows a marked increase in
superconducting anisotropy with respect to the phase observed at ambient
pressure, suggesting a different superconducting state with a distinct pairing
symmetry. Via first-principles calculations, we demonstrate that the system
concomitantly transitions into a strong topological phase with markedly
different band orbital characters and Fermi surfaces contributing to the
superconductivity. These findings position 1T'-WS2 as a unique, tunable
superconductor, wherein superconductivity, anomalous transport, and band
features can be tuned through the application of moderate pressures.",http://arxiv.org/abs/2501.05980v1
Mathematics of Digital Twins and Transfer Learning for PDE Models,2025-01-11T01:14:15Z,"Yifei Zong, Alexandre Tartakovsky","We define a digital twin (DT) of a physical system governed by partial
differential equations (PDEs) as a model for real-time simulations and control
of the system behavior under changing conditions. We construct DTs using the
Karhunen-Lo\`{e}ve Neural Network (KL-NN) surrogate model and transfer learning
(TL). The surrogate model allows fast inference and differentiability with
respect to control parameters for control and optimization. TL is used to
retrain the model for new conditions with minimal additional data. We employ
the moment equations to analyze TL and identify parameters that can be
transferred to new conditions. The proposed analysis also guides the control
variable selection in DT to facilitate efficient TL.
  For linear PDE problems, the non-transferable parameters in the KL-NN
surrogate model can be exactly estimated from a single solution of the PDE
corresponding to the mean values of the control variables under new target
conditions. Retraining an ML model with a single solution sample is known as
one-shot learning, and our analysis shows that the one-shot TL is exact for
linear PDEs. For nonlinear PDE problems, transferring of any parameters
introduces errors. For a nonlinear diffusion PDE model, we find that for a
relatively small range of control variables, some surrogate model parameters
can be transferred without introducing a significant error, some can be
approximately estimated from the mean-field equation, and the rest can be found
using a linear residual least square problem or an ordinary linear least square
problem if a small labeled dataset for new conditions is available. The former
approach results in a one-shot TL while the latter approach is an example of a
few-shot TL. Both methods are approximate for the nonlinear PDEs.",http://arxiv.org/abs/2501.06400v1
"SafeSplit: A Novel Defense Against Client-Side Backdoor Attacks in Split
  Learning",2025-01-11T22:20:20Z,"Phillip Rieger, Alessandro Pegoraro, Kavita Kumari, Tigist Abera, Jonathan Knauer, Ahmad-Reza Sadeghi","Split Learning (SL) is a distributed deep learning approach enabling multiple
clients and a server to collaboratively train and infer on a shared deep neural
network (DNN) without requiring clients to share their private local data. The
DNN is partitioned in SL, with most layers residing on the server and a few
initial layers and inputs on the client side. This configuration allows
resource-constrained clients to participate in training and inference. However,
the distributed architecture exposes SL to backdoor attacks, where malicious
clients can manipulate local datasets to alter the DNN's behavior. Existing
defenses from other distributed frameworks like Federated Learning are not
applicable, and there is a lack of effective backdoor defenses specifically
designed for SL.
  We present SafeSplit, the first defense against client-side backdoor attacks
in Split Learning (SL). SafeSplit enables the server to detect and filter out
malicious client behavior by employing circular backward analysis after a
client's training is completed, iteratively reverting to a trained checkpoint
where the model under examination is found to be benign. It uses a two-fold
analysis to identify client-induced changes and detect poisoned models. First,
a static analysis in the frequency domain measures the differences in the
layer's parameters at the server. Second, a dynamic analysis introduces a novel
rotational distance metric that assesses the orientation shifts of the server's
layer parameters during training. Our comprehensive evaluation across various
data distributions, client counts, and attack scenarios demonstrates the high
efficacy of this dual analysis in mitigating backdoor attacks while preserving
model utility.",http://arxiv.org/abs/2501.06650v1
"Correlation effects in two-dimensional MX_2 and MA_2Z_4 (M= Nb, Ta; X=
  S, Se, Te; A=Si, Ge; Z=N, P) cold metals: Implications for device
  applications",2025-01-11T23:34:15Z,"W. Beida, E. Sasioglu, M. Tas, C. Friedrich, S. Blugel, I. Mertig, I. Galanakis","Cold metals, characterized by their distinctive band structures, hold promise
for innovative electronic devices such as tunnel diodes with negative
differential resistance (NDR) effect and field-effect transistors (FETs) with
sub-60 mV/dec subthreshold swing (SS). In this study, we employ the GW
approximation and HSE06 hybrid functional to investigate the correlation
effects on the electronic band structure of two-dimensional (2D) cold metallic
materials, specifically focusing on MX_2 and MA_2Z_4 (M=Nb, Ta; X=S, Se, Te;
A=Si, Ge; Z= N, P) compounds in 1H structure. These materials exhibit a unique
band structure with an isolated metallic band around the Fermi energy, denoted
as W_m, as well as two energy gaps: the internal gap E^I_g below the Fermi
level and the external gap E^E_g above the Fermi level. These three electronic
structure parameters play a decisive role in determining the current-voltage
(I-V) characteristics of tunnel diodes, the nature of the NDR effect, and the
transfer characteristics and SS value of FETs. Our calculations reveal that
both GW and HSE06 methods yield consistent electronic structure properties for
all studied compounds. We observed a consistent increase in both internal and
external band gaps, as well as metallic bandwidths, across all pn-type cold
metal systems. Notably, the internal band gap E^I_g exhibits the most
substantial enhancement, highlighting the sensitivity of these materials to
correlation effects. In contrast, the changes in the metallic bandwidth W_m and
external band gap E^E_g are relatively modest. These findings offer valuable
insights for designing and optimizing cold metal-based devices. Materials like
NbSi_2N_4, NbGe_2N_4, and TaSi_2N_4 show particular promise for
high-performance NDR tunnel diodes and sub-60 mV/dec SS FETs.",http://arxiv.org/abs/2501.06665v1
"Optical appearance of the Konoplya-Zhidenko rotating non-Kerr black hole
  surrounded by a thin accretion disk",2025-01-12T11:29:05Z,"Ke-Jian He, Chen-Yu Yang, Xiao-Xiong Zeng","In this study, we analyze the observational images of a Konoplya-Zhidenko
rotating non-Kerr black hole, wherein a thin accretion disk, serving as the
sole background light source, is situated on the equatorial plane of the black
hole. The inner boundary of the thin accretion disk extends to the event
horizon, and the accretion material in the disk exhibits two different motion
behaviors, that is, it moves along the critical plunging orbit inside the
innermost stable circular orbit (ISCO) and follows the Keplerian orbit outside
the ISCO. The shadow image is captured on the imaging plane of a zero angular
momentum observer utilizing advanced fisheye camera ray-tracing techniques. The
results demonstrate that an image consistently reveals a dark region encircled
by a narrow photon ring, which is called the inner shadow. At low observation
inclination angles, the observation intensity is highly concentrated, with the
lensed image of accretion disk being superimposed on the direct image. As
observation inclination angle increases, the direct and lensed images gradually
separate, becoming distinctly distinguishable and forming a hat-like structure.
Furthermore, variations in the parameter space and observation angle will
influence pertinent image characteristics, including image symmetry, the range
or deformation degree of the inner shadow. We further examined the distinctive
characteristics of images observed in both prograde and retrograde accretion
disk scenarios. Subsequently, we also examined the redshift distribution on the
disk. The findings indicate that while variations in relevant parameters do
influence the redshift distribution, the primary factor is the change in
observational inclination. The observer can detect both redshift and blueshift
phenomena on the screen when viewed at a higher observation angle.",http://arxiv.org/abs/2501.06778v1
Lessons From Red Teaming 100 Generative AI Products,2025-01-13T11:36:33Z,"Blake Bullwinkel, Amanda Minnich, Shiven Chawla, Gary Lopez, Martin Pouliot, Whitney Maxwell, Joris de Gruyter, Katherine Pratt, Saphir Qi, Nina Chikanov, Roman Lutz, Raja Sekhar Rao Dheekonda, Bolor-Erdene Jagdagdorj, Eugenia Kim, Justin Song, Keegan Hines, Daniel Jones, Giorgio Severi, Richard Lundeen, Sam Vaughan, Victoria Westerhoff, Pete Bryan, Ram Shankar Siva Kumar, Yonatan Zunger, Chang Kawaguchi, Mark Russinovich","In recent years, AI red teaming has emerged as a practice for probing the
safety and security of generative AI systems. Due to the nascency of the field,
there are many open questions about how red teaming operations should be
conducted. Based on our experience red teaming over 100 generative AI products
at Microsoft, we present our internal threat model ontology and eight main
lessons we have learned:
  1. Understand what the system can do and where it is applied
  2. You don't have to compute gradients to break an AI system
  3. AI red teaming is not safety benchmarking
  4. Automation can help cover more of the risk landscape
  5. The human element of AI red teaming is crucial
  6. Responsible AI harms are pervasive but difficult to measure
  7. LLMs amplify existing security risks and introduce new ones
  8. The work of securing AI systems will never be complete
  By sharing these insights alongside case studies from our operations, we
offer practical recommendations aimed at aligning red teaming efforts with real
world risks. We also highlight aspects of AI red teaming that we believe are
often misunderstood and discuss open questions for the field to consider.",http://arxiv.org/abs/2501.07238v1
"Phenomenological anatomy of top-quark FCNCs induced by a light scalar
  singlet",2025-01-13T13:55:19Z,"Biao-Feng Hou, Xin-Qiang Li, Ya-Dong Yang, Xing-Bo Yuan, Ming-Wang Zhang","Scalar singlets under the Standard Model gauge group appear naturally in many
well-motivated New Physics scenarios, such as the composite Higgs models.
Unlike the Higgs boson in the Standard Model, they can induce large
flavour-changing neutral currents (FCNCs) in the top sector. We investigate
systematically the effects of a light scalar singlet $S$ with top-quark FCNC
couplings, by including the low-energy constraints from the $B_s \to \mu^+
\mu^-$ decay, the muon anomalous magnetic moment $(g-2)_\mu$ and the neutron
Electric Dipole Moment (EDM). We also perform a detailed Monte-Carlo simulation
of the channel $pp \to t S +j$ with $S \to \mu^+ \mu^-$ and $S \to b \bar b$,
and investigate the LHC sensitivity to the $tcS$ couplings. It is found that
the scalar singlet $S$ can induce scalar-type contributions to the $B_s \to
\mu^+ \mu^-$ decay, which do not suffer from the helicity suppression and
contain a large CKM factor $V_{cs}^*V_{tb}$. As a result, constraints on the
$tcS$ couplings from the measured branching ratio $\mathcal{B}(B_s \to \mu^+
\mu^-)$ are quite stringent, being even stronger than the expected LHC
sensitivity in some parameter spaces. Besides the CP-conserving $tcS$
couplings, we have also considered the case of CP-violating $tcS$ couplings,
with $y_{R,L}^{ct}=|y_{R,L}^{ct}|e^{i\theta_{R,L}}$. It is found that the CP
observables $\mathcal{A}_{\Delta\Gamma_s}^{\mu\mu}$ and $\mathcal{S}_{\mu\mu}$
of the $B_s \to \mu^+ \mu^-$ decay are sensitive to the phase $\theta_R$, while
the neutron EDM can provide bounds on the phase difference $\theta_L-\theta_R$.
Therefore, they are complementary to each other in probing the CP phases of the
$tcS$ couplings.",http://arxiv.org/abs/2501.07341v1
"Probing the sign-changeable interaction between dark energy and dark
  matter with DESI baryon acoustic oscillations and DES supernovae data",2025-01-13T14:30:16Z,"Tian-Nuo Li, Guo-Hong Du, Yun-He Li, Peng-Ju Wu, Shang-Jie Jin, Jing-Fei Zhang, Xin Zhang","There is a possibility of interaction between dark energy and dark matter,
and this interaction may also undergo a sign change during the evolution of the
universe. In this paper, we utilize the latest observational data to constrain
models of a sign-changeable interaction. The data we employ, in addition to the
cosmic microwave background data, also encompass the first-year baryon acoustic
oscillation data from DESI and the type Ia supernova data of the full 5-year
observation from DES. To achieve high generality, we investigate four
interacting dark energy (IDE) models with different forms of the interaction
term $Q$: (i) IDE1 with $Q = \beta(a)H\rho_{\rm de}$; (ii) IDE2 with $Q =
\beta(a)H\rho_{\rm c}$; (iii) IDE3 with $Q = \beta(a)H_0\rho_{\rm de}$; (iv)
IDE4 with $Q = \beta(a)H_0\rho_{\rm c}$. From the analysis, we observe that
$\beta(z) > 0$ at early times and $\beta(z) < 0$ at late times, with the
coupling $\beta(z)$ crossing the non-interacting line $\beta(z) = 0$ during
cosmic evolution at the 2$\sigma$ confidence level for the IDE1, IDE3, and IDE4
models. However, for the IDE2 model, $\beta(z)$ remains consistently negative
and does not cross $\beta(z) = 0$ at the 2$\sigma$ confidence level. Our
findings indicate that the energy transfer is from dark matter to dark energy
when dark matter dominates the universe, and from dark energy to dark matter
when dark energy dominates, for the IDE1 and IDE3 models. Furthermore, Bayesian
evidence suggests that the IDE1 and IDE3 models are moderately preferred over
the $\Lambda$CDM model. The overall outcomes of this study clearly indicate
that, based on current observational data, the sign-changeable IDE models are
quite compelling and merit further attention.",http://arxiv.org/abs/2501.07361v1
"Dusty disks as safe havens for terrestrial planets: Effect of the
  back-reaction of solid material on gas",2025-01-13T15:20:12Z,"Zs. Regály, A Németh, G. Krupánszky, Zs. Sándor","Previous studies have shown that there is considerable variation in the
dust-to-gas density ratio in the vicinity of low-mass planets undergoing
growth. This can lead to a significant change in the planetary momentum exerted
by the gas and solid material. However, due to the low dust-to-gas mass ratio
of protoplanetary disks, the back-reaction of the solid material, is often
neglected. We study the effect of the back-reaction of solid material on the
torques felt by low-mass planets. We performed locally isothermal, 2D
hydrodynamic simulations of planet-disk interactions. Low-mass planets in the
range of 0.1-10MEarth accrete only solid material. Simulations were compared
with and without taking into account the back-reaction of the solid material on
the gas. The solid component was assumed to have a fixed Stokes number in the
range 0.01-10. In general, the inclusion of back-reaction results in a greater
number of models with positive torque values compared to models that neglect
back-reaction. It is clear, therefore, that the simulation of planetary growth
and migration via hydrodynamic modeling requires the inclusion of solid-gas
back-reaction. As a result of the back-reaction and accretion, a Mars-sized
planetary embryo will experience positive total torques from the disk
containing coupled solid components St<=0.01. Earth-mass planets also
experience positive total torques from the disk containing boulder-sized solid
components 2<=St<=5. The accretion of weakly coupled solid material tends to
increase the positive torques and decrease the negative torques. Our results
suggest that the combined effect of back-reaction and accretion is beneficial
to the formation of planetary systems by reducing the likelihood of a young
planet being engulfed by the central star.",http://arxiv.org/abs/2501.07403v2
First mid-infrared detection and modeling of a flare from Sgr A*,2025-01-13T15:32:45Z,"Sebastiano D. von Fellenberg, Tamojeet Roychowdhury, Joseph M. Michail, Zach Sumners, Grace Sanger-Johnson, Giovanni G. Fazio, Daryl Haggard, Joseph L. Hora, Alexander Philippov, Bart Ripperda, Howard A. Smith, S. P. Willner, Gunther Witzel, Shuo Zhang, Eric E. Becklin, Geoffrey C. Bower, Sunil Chandra, Tuan Do, Macarena Garcia Marin, Mark A. Gurwell, Nicole M. Ford, Kazuhiro Hada, Sera Markoff, Mark R. Morris, Joey Neilsen, Nadeen B. Sabha, Braden Seefeldt-Gail","The time-variable emission from the accretion flow of Sgr A*, the
supermassive black hole at the Galactic Center, has long been examined in the
radio-to-mm, near-infrared (NIR), and X-ray regimes of the electromagnetic
spectrum. However, until now, sensitivity and angular resolution have been
insufficient in the crucial mid-infrared (MIR) regime. The MIRI instrument on
JWST has changed that, and we report the first MIR detection of Sgr A*. The
detection was during a flare that lasted about 40 minutes, a duration similar
to NIR and X-ray flares, and the source's spectral index steepened as the flare
ended. The steepening suggests synchrotron cooling is an important process for
Sgr A*'s variability and implies magnetic field strengths $\sim$40--70 Gauss in
the emission zone. Observations at $1.3~\mathrm{mm}$ with the Submillimeter
Array revealed a counterpart flare lagging the MIR flare by $\approx$10
minutes. The observations can be self-consistently explained as synchrotron
radiation from a single population of gradually cooling high-energy electrons
accelerated through (a combination of) magnetic reconnection and/or magnetized
turbulence.",http://arxiv.org/abs/2501.07415v1
Metal-THINGS: The Milky Way twin candidate NGC 3521,2025-01-13T16:11:32Z,"L. S. Pilyugin, M. A. Lara-Lopez, G. Tautvaisiene, I. A. Zinchenko, L. R. Garduno, M. E. De Rossi, J. Zaragoza-Cardiel, S. Dib, G. Vale","The 3D spectrophotometry measurements of the galaxy NGC~3521, a structural
Milky Way analogue (sMWA), were carried out within the Metal-THINGS project. We
found that the oxygen abundance in the inner part of NGC~3521 is at a nearly
constant level and the O/H gradient is negative at larger radii. The change in
the N/H with radius is similar to that for O/H. The radial distributions of the
O/H, the gas mass fraction, and the effective oxygen yield in NGC~3521 are
compared to that of the Milky Way (MW), with the aim of examining the
similarity in their chemical evolutions. The O/H of two HII regions closest to
the centre of the MW (at a radii of 4-5 kpc) are close to the binned O/H in
NGC~3521 at the same galactocentric distances. The O/H in the outer part of the
MW are lower than those in the outer part of NGC~3521. The gas mass fraction in
the outer part of the MW is higher than in NGC~3521. The obtained values of the
effective oxygen yield, Yeff, in NGC~3521 are close to the empirical estimation
of the oxygen yield, Yo. This suggests that mass exchange with the surroundings
plays little to no role in the chemical evolution of NGC3521. The values of the
Yeff in the MW were determined using two variants of the distribution of the
gas mass surface density. The values of the Yeff in the MW obtained with the
first distribution are also close to Yo. The Yeff in the MW obtained with the
second distribution are below Yo at radii between 6 and 10.4 kpc. This suggests
that the mass exchange with the surroundings can play a significant role in the
chemical evolution of this part of the MW. To draw a solid conclusion about the
role of mass exchange with the surroundings in the chemical evolution of the MW
it is essential to determine which of these distributions provides a more
adequate description of the gas distribution in the MW.",http://arxiv.org/abs/2501.07443v1
"Influence of carrier density and disorder on the Quantum Hall plateau
  widths in epitaxial graphene",2025-01-13T17:39:25Z,"Ignacio Figueruelo-Campanero, Yuriko Baba, Alejandro Jimeno-Pozo, Julia García-Pérez, Elvira M. González, Rodolfo Miranda, Francisco Guinea, Enrique Cánovas, Daniel Granados, Pierre Pantaleón, Pablo Burset, Mariela Menghini","Since its discovery, graphene has been one of the most prominent 2D materials
due to its unique properties and broad range of possible applications. In
particular, the half-integer Quantum Hall Effect (HI-QHE) characterized by the
quantization of Hall resistivity as a function of applied magnetic field,
offers opportunities for advancements in quantum metrology and the
understanding of topological quantum states in this 2D material. While the role
of disorder in stabilizing quantum Hall plateaus (QHPs) is widely recognized,
the precise interplay between the plateaus width, disorder, mobility and
carrier density remains less explored. In this work, we investigate the width
of the $\nu=6$ QHP in epitaxial graphene Hall bars, focusing on two distinct
regions of the device with markedly different electronic mobilities. Depending
on the storage conditions, it is possible to modify the carrier density of
graphene QHE devices and consequently increase or reduce the mobility. Our
experiments reveal mobility variations of up to 200$\%$ from their initial
value. In particular, the sample storage time and ambient conditions cause also
noticeable changes in the positions and extension of the QHPs. Our results show
that the QHP extension for $\nu=6$ differs significantly between the two
regions, influenced by both mobility and disorder, rather than solely by
carrier density. Transport simulations based on the Landauer-B\""uttiker
formalism with Anderson disorder in a scaled model reveal the critical role of
impurities in shaping graphene transport properties defining the extension of
the QHPs. This study provides valuable insights into the interplay between
mobility, disorder, and quantum transport in graphene systems.",http://arxiv.org/abs/2501.07518v2
"Digital Twin for Smart Societies: A Catalyst for Inclusive and
  Accessible Healthcare",2025-01-13T18:57:15Z,"Joshit Mohanty, Sujatha Alla, Vaishali, Nagesh Bheesetty, Prasanthi Chidipudi, Satya Prakash Chowdary Nandigam, Marisha Jmukhadze, Puneeth Bheesetty, Narendra Lakshmana Gowda","With rapid digitization and digitalization, drawing a fine line between the
digital and the physical world has become nearly impossible. It has become
essential more than ever to integrate all spheres of life into a single Digital
Thread to address pressing challenges of modern society: accessible and
inclusive healthcare in terms of equality and equity. Techno-social
advancements and mutual acceptance have enabled the infusion of digital models
to simulate social settings with minimum resource utilization to make effective
decisions. However, a significant gap exists in feeding back the models with
appropriate real-time changes. In other words, active behavioral modeling of
modern society is lacking, influencing community healthcare as a whole. By
creating virtual replicas of (physical) behavioral systems, digital twins can
enable real-time monitoring, simulation, and optimization of urban dynamics.
This paper explores the potential of digital twins to promote inclusive
healthcare for evolving smart cities. We argue that digital twins can be used
to: Identify and address disparities in access to healthcare services,
Facilitate community participation, Simulate the impact of urban policies and
interventions on different groups of people, and Aid policy-making bodies for
better access to healthcare. This paper proposes several ways to use digital
twins to stitch the actual and virtual societies. Several discussed concepts
within this framework envision an active, integrated, and synchronized
community aware of data privacy and security. The proposal also provides
high-level step-wise transitions that will enable this transformation.",http://arxiv.org/abs/2501.07570v1
Rectangular polar quadrature in 1D and its error analysis,2025-01-14T09:27:20Z,"Krishna Yamanappa Poojara, Sabhrant Sachan, Ambuj Pandey","This paper presents a one-dimensional analog of the Rectangular-Polar (RP)
integration strategy and its convergence analysis for weakly singular
convolution integrals. The key idea of this method is to break the whole
integral into integral over non-overlapping patches (subdomains) and achieve
convergence by increasing the number of patches while approximating the
integral on patches accurately using a fixed number of quadrature points. The
non-singular integrals are approximated to high-order using Fej\'er first
quadrature, and a specialized integration strategy is designed and incorporated
for singular integrals where the kernel singularity is resolved by mean of
Polynomial Change of Variable (PCV). We prove that for high-order convergence,
it is essential to compute integral weights accurately, and the method's
convergence rate depends critically on the degree of the PCV and the
singularity of the integral kernel. Specifically, for kernels of the form
$|x-y|^{-\alpha}(\alpha>-1)$, the method achieves high-order convergence if and
only if $p(1-\alpha) \in \mathbb{N}$. This relationship highlights the
importance of choosing an appropriate degree $p$ for the PCV. A new error
estimate in a framework where convergence is achieved by reducing the
approximating domain size while keeping the number of discretization points
fixed is derived for the Fej\'er first quadrature, decay rate of Chebyshev
coefficients, and the error in approximating continuous Chebyshev coefficients
with discrete ones. Numerical experiments corroborate the theoretical findings,
showcasing the effectiveness of the RP strategy for accurately solving singular
integral equations. As an application of the method, numerical solutions of the
surface scattering problem in the two dimensions are computed for complex
domains, and the algorithm's efficacy is demonstrated for large-scale problems.",http://arxiv.org/abs/2501.07962v1
"Resolving Structural Origins for Superconductivity in Strain-Engineered
  La$_3$Ni$_2$O$_7$ Thin Films",2025-01-14T15:44:03Z,"Lopa Bhatt, Abigail Y. Jiang, Eun Kyo Ko, Noah Schnitzer, Grace A. Pan, Dan Ferenc Segedin, Yidi Liu, Yijun Yu, Yi-Feng Zhao, Edgar Abarca Morales, Charles M. Brooks, Antia S. Botana, Harold Y. Hwang, Julia A. Mundy, David A. Muller, Berit H. Goodge","The discovery of high-temperature superconductivity in bulk La$_3$Ni$_2$O$_7$
under high hydrostatic pressure and, more recently, biaxial compression in
epitaxial thin films has ignited significant interest in understanding the
interplay between atomic and electronic structure in these compounds. Subtle
changes in the nickel-oxygen bonding environment are thought to be key drivers
for stabilizing superconductivity, but specific details of which bonds and
which modifications are most relevant remains so far unresolved. While direct,
atomic-scale structural characterization under hydrostatic pressure is beyond
current experimental capabilities, static stabilization of strained
La$_3$Ni$_2$O$_7$ films provides a platform well-suited to investigation with
new picometer-resolution electron microscopy methods. Here, we use multislice
electron ptychography to directly measure the atomic-scale structural evolution
of La$_3$Ni$_2$O$_7$ thin films across a wide range of biaxial strains tuned
via substrate. By resolving both the cation and oxygen sublattices, we study
strain-dependent evolution of atomic bonds, providing the opportunity to
isolate and disentangle the effects of specific structural motifs for
stabilizing superconductivity. We identify the lifting of crystalline symmetry
through modification of the nickel-oxygen octahedral distortions under
compressive strain as a key structural ingredient for superconductivity. Rather
than previously supposed $c$-axis compression, our results highlight the
importance of in-plane biaxial compression in superconducting thin films, which
suggests an alternative -- possibly cuprate-like -- understanding of the
electronic structure. Identifying local regions of inhomogeneous oxygen
stoichiometry and high internal strain near crystalline defects, we suggest
potential pathways for improving the sharpness and temperature of the
superconducting transition.",http://arxiv.org/abs/2501.08204v1
"CORD: Co-design of Resource Allocation and Deadline Decomposition with
  Generative Profiling",2025-01-14T23:13:14Z,"Robert Gifford, Abby Eisenklam, Georgiy A. Bondar, Yifan Cai, Tushar Sial, Linh Thi Xuan Phan, Abhishek Halder","As multicore hardware is becoming increasingly common in real-time systems,
traditional scheduling techniques that assume a single worst-case execution
time for a task are no longer adequate, since they ignore the impact of shared
resources on execution time. When tasks execute concurrently on different
cores, their execution times often vary substantially with their allocated
budgets of shared resources, such as cache and memory bandwidth. Even under a
specific resource allocation, the resource use pattern of a task also changes
with time during a job execution. It is therefore important to consider the
relationship between multicore resources and execution time in task modeling
and scheduling algorithm design.
  In this paper, we propose a much more precise execution model for DAG-based
real-time tasks that captures the time-varying resource use characteristics of
a task under different budgets of shared resources. We present a generative
resource profiling algorithm that efficiently predicts, from limited
measurement data, the resource profile of a task at any time during its
execution under a given resource budget. The generative profiles can then be
used to construct the execution models for tasks, using which one can make
informed resource allocation decisions. We further introduce a multicore
resource allocation and deadline decomposition co-design technique for
DAG-based tasks that leverages the generated execution models to jointly
allocate resources and deadlines to subtasks, to maximize resource efficiency
and schedulability. Our evaluation results show that our generative profiling
algorithm achieves high accuracy while being efficient, and that our
co-allocation technique substantially improves schedulability compared to a
state-of-the-art deadline decomposition method.",http://arxiv.org/abs/2501.08484v1
"Discovery of a years-delayed radio flare from an unusually slow-evolved
  tidal disruption event",2025-01-15T14:10:58Z,"Zhumao Zhang, Xinwen Shu, Lei Yang, Luming Sun, Hucheng Ding, Lin Yan, Ning Jiang, Fangxia An, Walter Silima, Fabao Zhang, Yogesh Chandola, Zhongzu Wu, Daizhong Liu, Liming Dou, Jianguo Wang, Yibo Wang, Chenwei Yang, Di Li, Tianyao Zhou, Wenjie Zhang, Fangkun Peng, Tinggui Wang","SDSS J1115+0544 is a unique low-ionization nuclear emission-line region
(LINER) galaxy with energetic ultraviolet (UV), optical and mid-infrared
outbursts occurring in its nucleus. We present the results from an analysis of
multi-wavelength photometric and radio follow-up observations covering a period
of ~9 years since its discovery. We find that following a luminosity plateau of
~500 days, the UV/optical emission has decayed back to the pre-outburst level,
suggesting that the nuclear outburst might be caused by a stellar tidal
disruption event (TDE). In this case, SDSS J1115+0544 could be an unusually
slow-evolved optical TDE with longest rise and decline time-scales ever found.
Three years later than the optical peak, a delayed radio brightening was found
with a 5.5 GHz luminosity as high as ~1.9x10^39 erg/s. Using a standard
equipartition analysis, we find the outflow powering the radio emission was
launched at t~1260 days with a velocity of beta<~0.1 and kinetic energy of
E_K~>10^50 erg. The delayed radio brightening coupled with the disappearing
plateau in the UV/optical light curves is consistent with the scenario
involving delayed ejection of an outflow from a state transition in the disk.
SDSS J1115+0544 is the first TDE displaying both a short-lived UV/optical
plateau emission and a late-time radio brightening. Future radio observations
of these TDEs in the post-plateau decay phase will help to establish the
connection between outflow launching and changes in accretion rate.",http://arxiv.org/abs/2501.08812v1
"An analysis of data variation and bias in image-based dermatological
  datasets for machine learning classification",2025-01-15T17:18:46Z,"Francisco Filho, Emanoel Santos, Rodrigo Mota, Kelvin Cunha, Fabio Papais, Amanda Arruda, Mateus Baltazar, Camila Vieira, José Gabriel Tavares, Rafael Barros, Othon Souza, Thales Bezerra, Natalia Lopes, Érico Moutinho, Jéssica Guido, Shirley Cruz, Paulo Borba, Tsang Ing Ren","AI algorithms have become valuable in aiding professionals in healthcare. The
increasing confidence obtained by these models is helpful in critical decision
demands. In clinical dermatology, classification models can detect malignant
lesions on patients' skin using only RGB images as input. However, most
learning-based methods employ data acquired from dermoscopic datasets on
training, which are large and validated by a gold standard. Clinical models aim
to deal with classification on users' smartphone cameras that do not contain
the corresponding resolution provided by dermoscopy. Also, clinical
applications bring new challenges. It can contain captures from uncontrolled
environments, skin tone variations, viewpoint changes, noises in data and
labels, and unbalanced classes. A possible alternative would be to use transfer
learning to deal with the clinical images. However, as the number of samples is
low, it can cause degradations on the model's performance; the source
distribution used in training differs from the test set. This work aims to
evaluate the gap between dermoscopic and clinical samples and understand how
the dataset variations impact training. It assesses the main differences
between distributions that disturb the model's prediction. Finally, from
experiments on different architectures, we argue how to combine the data from
divergent distributions, decreasing the impact on the model's final accuracy.",http://arxiv.org/abs/2501.08962v2
"Physics-Informed Machine Learning for Microscale Drying of Plant-Based
  Foods: A Systematic Review of Computational Models and Experimental Insights",2025-01-14T05:35:23Z,"C. P. Batuwatta-Gamage, H. Jeong, HCP Karunasena, M. A. Karim, C. M. Rathnayaka, Y. T. Gu","This review examines the current state of research on microscale cellular
changes during the drying of plant-based food materials (PBFM), with particular
emphasis on computational modelling approaches. The review addresses the
critical need for advanced computational methods in microscale investigations.
We systematically analyse experimental studies in PBFM drying, highlighting
their contributions and limitations in capturing cellular-level phenomena,
including challenges in data acquisition and measurement accuracy under varying
drying conditions. The evolution of computational models for microstructural
investigations is thoroughly examined, from traditional numerical methods to
contemporary state-of-the-art approaches, with specific focus on their ability
to handle the complex, nonlinear properties of plant cellular materials.
Special attention is given to the emergence of data-driven models and their
limitations in predicting microscale cellular behaviour during PBFM drying,
particularly addressing challenges in dataset acquisition and model
generalization. The review provides an in-depth analysis of Physics-Informed
Machine Learning (PIML) frameworks, examining their theoretical foundations,
current applications in related fields, and unique advantages in combining
physical principles with neural network architectures. Through this
comprehensive assessment, we identify critical gaps in existing methodologies,
evaluate the trade-offs between different modelling approaches, and provide
insights into future research directions for improving our understanding of
cellular-level transformations during PBFM drying processes. The review
concludes with recommendations for integrating experimental and computational
approaches to advance the field of food preservation technology.",http://arxiv.org/abs/2501.09034v1
"Evaluating GenAI for Simplifying Texts for Education: Improving Accuracy
  and Consistency for Enhanced Readability",2025-01-15T21:19:01Z,"Stephanie L. Day, Jacapo Cirica, Steven R. Clapp, Veronika Penkova, Amy E. Giroux, Abbey Banta, Catherine Bordeau, Poojitha Mutteneni, Ben D. Sawyer","Generative artificial intelligence (GenAI) holds great promise as a tool to
support personalized learning. Teachers need tools to efficiently and
effectively enhance content readability of educational texts so that they are
matched to individual students reading levels, while retaining key details.
Large Language Models (LLMs) show potential to fill this need, but previous
research notes multiple shortcomings in current approaches. In this study, we
introduced a generalized approach and metrics for the systematic evaluation of
the accuracy and consistency in which LLMs, prompting techniques, and a novel
multi-agent architecture to simplify sixty informational reading passages,
reducing each from the twelfth grade level down to the eighth, sixth, and
fourth grade levels. We calculated the degree to which each LLM and prompting
technique accurately achieved the targeted grade level for each passage,
percentage change in word count, and consistency in maintaining keywords and
key phrases (semantic similarity). One-sample t-tests and multiple regression
models revealed significant differences in the best performing LLM and prompt
technique for each of the four metrics. Both LLMs and prompting techniques
demonstrated variable utility in grade level accuracy and consistency of
keywords and key phrases when attempting to level content down to the fourth
grade reading level. These results demonstrate the promise of the application
of LLMs for efficient and precise automated text simplification, the
shortcomings of current models and prompting methods in attaining an ideal
balance across various evaluation criteria, and a generalizable method to
evaluate future systems.",http://arxiv.org/abs/2501.09158v1
"XMM/HST monitoring of the ultra-soft highly accreting Narrow Line
  Seyfert 1 RBS 1332",2025-01-16T00:42:41Z,"R. Middei, S. Barnier, F. G. Saturni, F. Ursini, P. -O. Petrucci, S. Bianchi, M. Cappi, M. Clavel, B. De Marco, A. De Rosa, G. Matt, G. A. Matzeu, M. Perri","Ultra-soft narrow line Seyfert 1 (US-NLSy) are a poorly observed class of
active galactic nuclei characterized by significant flux changes and an extreme
soft X-ray excess. This peculiar spectral shape represents a golden opportunity
to test whether the standard framework commonly adopted for modelling local AGN
is still valid. We thus present the results on the joint XMM-Newton and HST
monitoring campaign of the highly accreting US-NLSy RBS 1332. The optical-to-UV
spectrum of RBS 1332 exhibits evidence of both a stratified narrow-line region
and an ionized outflow, that produces absorption troughs over a wide range of
velocities (from ~1500 km s-1 to ~1700 km s-1) in several high-ionization
transitions (Lyalpha, N V, C IV). From a spectroscopic point of view, the
optical/UV/FUV/X-rays emission of this source is due to the superposition of
three distinct components which are best modelled in the context of the
two-coronae framework in which the radiation of RBS 1332 can be ascribed to a
standard outer disk, a warm Comptonization region and a soft coronal continuum.
The present dataset is not compatible with a pure relativistic reflection
scenario. Finally, the adoption of the novel model reXcor allowed us to
determine that the soft X-ray excess in RBS 1332 is dominated by the emission
of the optically thick and warm Comptonizing medium, and only marginal
contribution is expected from relativistic reflection from a lamppost-like
corona.",http://arxiv.org/abs/2501.09220v1
"A universal break in energy functions of three hyperactive repeating
  fast radio bursts",2025-01-16T02:18:55Z,"Q. Wu, F. Y. Wang, Z. Y. Zhao, P. Wang, H. Xu, Y. K. Zhang, D. J. Zhou, J. R. Niu, W. Y. Wang, S. X. Yi, Z. Q. Hua, S. B. Zhang, J. L. Han, W. W. Zhu, K. J. Lee, D. Li, X. F. Wu, Z. G. Dai, B. Zhang","Fast radio bursts (FRBs) are millisecond-duration pulses occurring at
cosmological distances with a mysterious origin. Observations show that at
least some FRBs are produced by magnetars. All magnetar-powered FRB models
require some triggering mechanisms, among which the most popular is the crust
cracking of a neutron star, which is called starquake. However, so far there
has been no decisive evidence for this speculation. Here we report the energy
functions of the three most active repeating FRBs, which show a universal break
around $10^{38}$ erg. Such a break is similar to that of the
frequency-magnitude relationship of earthquakes. The break and change of the
power-law indices below and above it can be well understood within the
framework of FRBs triggered by starquakes in the magnetar models. The seed of
weak FRBs can grow both on the magnetar surface and in the deeper crust. In
contrast, the triggering of strong FRBs is confined by the crustal thickness
and the seed of strong FRBs can only grow on the surface. This difference in
dimensionality causes a break in the scaling properties from weak to strong
FRBs, occurring at a point where the penetration depth of starquakes equals the
crustal thickness. Our result, together with the earthquake-like temporal
properties of these FRBs, strongly supports that FRBs are triggered by
starquakes, providing a new opportunity to study the physical properties of the
neutron star crust.",http://arxiv.org/abs/2501.09248v1
"SMPLest-X: Ultimate Scaling for Expressive Human Pose and Shape
  Estimation",2025-01-16T18:59:46Z,"Wanqi Yin, Zhongang Cai, Ruisi Wang, Ailing Zeng, Chen Wei, Qingping Sun, Haiyi Mei, Yanjun Wang, Hui En Pang, Mingyuan Zhang, Lei Zhang, Chen Change Loy, Atsushi Yamashita, Lei Yang, Ziwei Liu","Expressive human pose and shape estimation (EHPS) unifies body, hands, and
face motion capture with numerous applications. Despite encouraging progress,
current state-of-the-art methods focus on training innovative architectural
designs on confined datasets. In this work, we investigate the impact of
scaling up EHPS towards a family of generalist foundation models. 1) For data
scaling, we perform a systematic investigation on 40 EHPS datasets,
encompassing a wide range of scenarios that a model trained on any single
dataset cannot handle. More importantly, capitalizing on insights obtained from
the extensive benchmarking process, we optimize our training scheme and select
datasets that lead to a significant leap in EHPS capabilities. Ultimately, we
achieve diminishing returns at 10M training instances from diverse data
sources. 2) For model scaling, we take advantage of vision transformers (up to
ViT-Huge as the backbone) to study the scaling law of model sizes in EHPS. To
exclude the influence of algorithmic design, we base our experiments on two
minimalist architectures: SMPLer-X, which consists of an intermediate step for
hand and face localization, and SMPLest-X, an even simpler version that reduces
the network to its bare essentials and highlights significant advances in the
capture of articulated hands. With big data and the large model, the foundation
models exhibit strong performance across diverse test benchmarks and excellent
transferability to even unseen environments. Moreover, our finetuning strategy
turns the generalist into specialist models, allowing them to achieve further
performance boosts. Notably, our foundation models consistently deliver
state-of-the-art results on seven benchmarks such as AGORA, UBody, EgoBody, and
our proposed SynHand dataset for comprehensive hand evaluation. (Code is
available at: https://github.com/wqyin/SMPLest-X).",http://arxiv.org/abs/2501.09782v1
"Understanding the Effectiveness of LLMs in Automated Self-Admitted
  Technical Debt Repayment",2025-01-17T00:23:44Z,"Mohammad Sadegh Sheikhaei, Yuan Tian, Shaowei Wang, Bowen Xu","Self-Admitted Technical Debt (SATD), cases where developers intentionally
acknowledge suboptimal solutions in code through comments, poses a significant
challenge to software maintainability. Left unresolved, SATD can degrade code
quality and increase maintenance costs. While Large Language Models (LLMs) have
shown promise in tasks like code generation and program repair, their potential
in automated SATD repayment remains underexplored.
  In this paper, we identify three key challenges in training and evaluating
LLMs for SATD repayment: (1) dataset representativeness and scalability, (2)
removal of irrelevant SATD repayments, and (3) limitations of existing
evaluation metrics. To address the first two dataset-related challenges, we
adopt a language-independent SATD tracing tool and design a 10-step filtering
pipeline to extract SATD repayments from repositories, resulting two
large-scale datasets: 58,722 items for Python and 97,347 items for Java. To
improve evaluation, we introduce two diff-based metrics, BLEU-diff and
CrystalBLEU-diff, which measure code changes rather than whole code.
Additionally, we propose another new metric, LEMOD, which is both interpretable
and informative. Using our new benchmarks and evaluation metrics, we evaluate
two types of automated SATD repayment methods: fine-tuning smaller models, and
prompt engineering with five large-scale models. Our results reveal that
fine-tuned small models achieve comparable Exact Match (EM) scores to
prompt-based approaches but underperform on BLEU-based metrics and LEMOD.
Notably, Gemma-2-9B leads in EM, addressing 10.1% of Python and 8.1% of Java
SATDs, while Llama-3.1-70B-Instruct and GPT-4o-mini excel on BLEU-diff,
CrystalBLEU-diff, and LEMOD metrics. Our work contributes a robust benchmark,
improved evaluation metrics, and a comprehensive evaluation of LLMs, advancing
research on automated SATD repayment.",http://arxiv.org/abs/2501.09888v1
"Simultaneous mapping of the ultrafast time and fluence dependence of the
  laser-induced insulator-to-metal transition in magnetite",2025-01-17T12:23:09Z,"J. O. Schunck, P. S. Miedema, R. Y. Engel, S. Dziarzhytski, G. Brenner, N. Ekanayake, C. -F. Chang, P. Bougiatioti, F. Döring, B. Rösner, C. David, C. Schüßler-Langeheine, M. Beye","Pump-probe methods are a ubiquitous tool in the field of ultrafast dynamic
measurements. In recent years, X-ray free-electron laser experiments have
gained importance due to their ability to probe with high chemical selectivity
and at atomic length scales. To obtain the complete dynamic information,
measurements are typically repeated many thousands of times with varying delay
and/or fluence settings. This generally necessitates that the sample fully
recovers before the subsequent excitation and that probe pulses and the induced
dynamic evolution are comparable to each other. These conditions present a
significant challenge when the sample fluctuates between different initial
states or when it is susceptible to damage. Also, source fluctuations are
normally intrinsic to free-electron laser pulses. Here, we present a
time-to-space mapping imaging scheme that enables us to record a delay range of
several picoseconds as well as a laser fluence range of about one order of
magnitude in every single shot of the x-ray probe. This approach can circumvent
the aforementioned preconditions. We demonstrate the use of this scheme by
mapping the femto- and picosecond dynamics of the optically induced
insulator-to-metal Verwey transition in a magnetite thin film. We employ
resonant diffraction at the free-electron laser FLASH for probing. The dynamics
of the magnetite thin film are found to follow a biexponential decay in line
with earlier studies on bulk crystals. By extrapolating our results towards the
conditions found at X-ray free-electron lasers with higher energy, we
demonstrate that the presented data could be recorded in a single shot.",http://arxiv.org/abs/2501.10149v1
"High flow speeds and transition-region like temperatures in the solar
  chromosphere during flux emergence",2025-01-17T15:22:34Z,"J. Leenaarts, M. van Noort, J. de la Cruz Rodríguez, S. Danilovic, C. J. Díaz Baso, T. Hilberg, P. Sütterlin, D. Kiselman, G. Scharmer, S. Solanki","Context: Flux emergence in the solar atmosphere is a complex process that
causes a release of magnetic energy as heat and acceleration of solar plasma at
a variety of spatial scales. Methods: We analysed imaging spectropolarimetric
data taken in the He 1083 nm line. This line is sensitive to temperatures
larger than 15 kK, unlike diagnostics such as \MgIIhk, \CaIIHK, and \Halpha,
which lose sensitivity already at 15 kK. The He I data is complemented by
imaging spectropolarimetry in the \CaIIK, \Feline, and \Caline\ lines. We
employed inversions to determine the magnetic field and vertical velocity in
the solar atmosphere. We computed He 1083 nm profiles from a radiation-MHD
simulation of the solar atmosphere to help interpretation of the observations.
Results: We find fast-evolving blob-like emission features in the He 1083 nm
triplet at locations where the magnetic field is rapidly changing direction,
and these are likely sites of magnetic reconnection. We fit the line with a
model consisting of an emitting layer located below a cold layer representing
the fibril canopy. The modelling provides evidence that this model, while
simple, catches the essential characteristics of the line formation. The
morphology of the emission in the He 1083 nm line is localized and blob-like,
unlike the emission in the \CaIIK\ line, which is more filamentary.
Conclusions: The modelling shows that the \Heline\ emission features and their
Doppler shifts can be caused by opposite-polarity reconnection and/or
horizontal current sheets below the canopy layer in the chromosphere. Based on
the high observed Doppler width and the blob-like appearance of the emission
features, we conjecture that at least a fraction of them are produced by
plasmoids. We conclude that transition-region-like temperatures in the deeper
layers of the active region chromosphere are more common than previously
thought.",http://arxiv.org/abs/2501.10246v1
"Resolving discrepancies in bang-time predictions for ICF experiments on
  the NIF: Insights from the Build-A-Hohlraum Campaign",2025-01-17T18:45:51Z,"G. F. Swadling, W. A. Farmer, H. Chen, N. Aybar, M. S. Rubery, M. B. Schneider, D. A. Liedahl, N. C. Lemos, E. Tubman, J. S. Ross, D. E. Hinkel, O. L. Landen, M. D. Rosen, S. Rogers K. Newman, D. Yanagisawa, N. Roskopf, S. Vonhof, L. Aghaian, M. Mauldin, B. L. Reichelt, J. Kunimune","This study investigated discrepancies between measured and simulated x-ray
drive in Inertial Confinement Fusion (ICF) hohlraums at the National Ignition
Facility (NIF). Despite advances in radiation-hydrodynamic simulations, a
consistent ""drive deficit"" remains. Experimentally measured ICF capsule
bang-times are systematically 400-700 ps later than simulations predict. The
Build-A-Hohlraum (BAH) campaign explored potential causes for this discrepancy
by systematically varying hohlraum features, including laser entrance hole
(LEH) windows, capsules, and gas fills. Overall, the agreement between
simulated and experimental x-ray drive was found to be largely unaffected by
these changes. The data allows us to exclude some hypotheses put forward to
potentially explain the discrepancy. Errors in the local thermodynamic
equilibrium (LTE) atomic modeling, errors in the modeling of LEH closure and
errors due to a lack of plasma species mix physics in simulations are shown to
be inconsistent with our measurements. Instead, the data supports the
hypothesis that errors in NLTE emission modeling are a significant contributor
to the discrepancy. X-ray emission in the 2 - 4 keV range is found to be
approximately 30% lower than in simulations. This is accompanied by higher than
predicted electron temperatures in the gold bubble region, pointing to errors
in non-LTE modeling. Introducing an opacity multiplier of 0.87 on energy groups
above 1.8 keV improves agreement with experimental data, reducing the bang-time
discrepancy from 300 ps to 100 ps. These results underscore the need for
refined NLTE opacity models to enhance the predictive power of hohlraum
simulations.",http://arxiv.org/abs/2501.10350v1
"I Zw 1 and H0557-385: The Dusty Tori of Two High Eddington AGNs Observed
  in the MATISSE LM-Bands",2025-01-17T18:48:12Z,"Farin Drewes, James H. Leftley, Sebastian F. Hönig, Konrad W. Tristram, Makoto Kishimoto","The torus in Active Galactic Nuclei (AGN) is a complex dynamical structure of
gas and dust. It is thought to be composed of an equatorial dusty disk and a
polar dusty wind launched by radiation pressure. However, this picture is based
on studies of moderately accreting AGN. Models suggest that the disk/wind
structure will change with specific accretion rate. Here we examine the wind
launching region in two high accretion rate objects, I Zw 1 (super-Eddington)
and H0557-385 (high-Eddington), using high spatial resolution interferometric
observations in the $K$-band from VLTI/GRAVITY and $LM$-bands VLTI/MATISSE. We
recover wavelength-dependent sizes of the dust emission using a Gaussian and
power law fit to the visibilities. Both objects are partially resolved and have
radial sizes in the $KLM$-bands between 0.3 - 1.5 mas, with no signs of
elongation. Combining our measurements with VLTI/MIDI $N$-band data gives a
full multi-wavelength picture of the dust structure. We find that in H0557-385,
the dust sizes between $3.5-8\:\mu\mathrm{m}$ are independent of the
wavelength, roughly constant at $3-10$ sublimation radii. We argue that this
indicates a direct view of the wind launching region and, together with an
absence of polar elongation, this implies that any wind would be launched in a
preferentially equatorial direction or blown out by strong radiation pressure.
The size-wavelength relation for both objects shows a preferentially disky
equatorial dust distribution. We conclude that there is strong evidence that
the Eddington ratio shapes the inner dust structure, most notably the
wind-launching region and wind direction.",http://arxiv.org/abs/2501.10352v1
"High Resolution Tree Height Mapping of the Amazon Forest using Planet
  NICFI Images and LiDAR-Informed U-Net Model",2025-01-17T23:26:28Z,"Fabien H Wagner, Ricardo Dalagnol, Griffin Carter, Mayumi CM Hirye, Shivraj Gill, Le Bienfaiteur Sagang Takougoum, Samuel Favrichon, Michael Keller, Jean PHB Ometto, Lorena Alves, Cynthia Creze, Stephanie P George-Chacon, Shuang Li, Zhihua Liu, Adugna Mullissa, Yan Yang, Erone G Santos, Sarah R Worden, Martin Brandt, Philippe Ciais, Stephen C Hagen, Sassan Saatchi","Tree canopy height is one of the most important indicators of forest biomass,
productivity, and ecosystem structure, but it is challenging to measure
accurately from the ground and from space. Here, we used a U-Net model adapted
for regression to map the mean tree canopy height in the Amazon forest from
Planet NICFI images at ~4.78 m spatial resolution for the period 2020-2024. The
U-Net model was trained using canopy height models computed from aerial LiDAR
data as a reference, along with their corresponding Planet NICFI images.
Predictions of tree heights on the validation sample exhibited a mean error of
3.68 m and showed relatively low systematic bias across the entire range of
tree heights present in the Amazon forest. Our model successfully estimated
canopy heights up to 40-50 m without much saturation, outperforming existing
canopy height products from global models in this region. We determined that
the Amazon forest has an average canopy height of ~22 m. Events such as logging
or deforestation could be detected from changes in tree height, and encouraging
results were obtained to monitor the height of regenerating forests. These
findings demonstrate the potential for large-scale mapping and monitoring of
tree height for old and regenerating Amazon forests using Planet NICFI imagery.",http://arxiv.org/abs/2501.10600v1
"AI/ML Based Detection and Categorization of Covert Communication in IPv6
  Network",2025-01-18T02:05:37Z,"Mohammad Wali Ur Rahman, Yu-Zheng Lin, Carter Weeks, David Ruddell, Jeff Gabriellini, Bill Hayes, Salim Hariri, Edward V. Ziegler Jr","The flexibility and complexity of IPv6 extension headers allow attackers to
create covert channels or bypass security mechanisms, leading to potential data
breaches or system compromises. The mature development of machine learning has
become the primary detection technology option used to mitigate covert
communication threats. However, the complexity of detecting covert
communication, evolving injection techniques, and scarcity of data make
building machine-learning models challenging. In previous related research,
machine learning has shown good performance in detecting covert communications,
but oversimplified attack scenario assumptions cannot represent the complexity
of modern covert technologies and make it easier for machine learning models to
detect covert communications. To bridge this gap, in this study, we analyzed
the packet structure and network traffic behavior of IPv6, used encryption
algorithms, and performed covert communication injection without changing
network packet behavior to get closer to real attack scenarios. In addition to
analyzing and injecting methods for covert communications, this study also uses
comprehensive machine learning techniques to train the model proposed in this
study to detect threats, including traditional decision trees such as random
forests and gradient boosting, as well as complex neural network architectures
such as CNNs and LSTMs, to achieve detection accuracy of over 90\%. This study
details the methods used for dataset augmentation and the comparative
performance of the applied models, reinforcing insights into the adaptability
and resilience of the machine learning application in IPv6 covert
communication. In addition, we also proposed a Generative AI-assisted
interpretation concept based on prompt engineering as a preliminary study of
the role of Generative AI agents in covert communication.",http://arxiv.org/abs/2501.10627v1
"A CNN-Transformer for Classification of Longitudinal 3D MRI Images -- A
  Case Study on Hepatocellular Carcinoma Prediction",2025-01-18T11:39:46Z,"Jakob Nolte, Maureen M. J. Guichelaar, Donald E. Bouman, Stephanie M. van den Berg, Maryam Amir Haeri","Longitudinal MRI analysis is crucial for predicting disease outcomes,
particularly in chronic conditions like hepatocellular carcinoma (HCC), where
early detection can significantly influence treatment strategies and patient
prognosis. Yet, due to challenges like limited data availability, subtle
parenchymal changes, and the irregular timing of medical screenings, current
approaches have so far focused on cross-sectional imaging data. To address
this, we propose HCCNet, a novel model architecture that integrates a 3D
adaptation of the ConvNeXt CNN architecture with a Transformer encoder,
capturing both the intricate spatial features of 3D MRIs and the complex
temporal dependencies across different time points. HCCNet utilizes a two-stage
pre-training process tailored for longitudinal MRI data. The CNN backbone is
pre-trained using a self-supervised learning framework adapted for 3D MRIs,
while the Transformer encoder is pre-trained with a sequence-order-prediction
task to enhance its understanding of disease progression over time. We
demonstrate the effectiveness of HCCNet by applying it to a cohort of liver
cirrhosis patients undergoing regular MRI screenings for HCC surveillance. Our
results show that HCCNet significantly improves predictive accuracy and
reliability over baseline models, providing a robust tool for personalized HCC
surveillance. The methodological approach presented in this paper is versatile
and can be adapted to various longitudinal MRI screening applications. Its
ability to handle varying patient record lengths and irregular screening
intervals establishes it as an invaluable framework for monitoring chronic
diseases, where timely and accurate disease prognosis is critical for effective
treatment planning.",http://arxiv.org/abs/2501.10733v2
"An Online Algorithm for Bayesian Variable Selection in Logistic
  Regression Models With Streaming Data",2025-01-19T03:25:59Z,"Payel Ghosal, Shamriddha De, Joyee Ghosh","In several modern applications, data are generated continuously over time,
such as data generated from smartwatches. We assume data are collected and
analyzed sequentially, in batches. Since traditional or offline methods can be
extremely slow, Ghosh et al. (2025) proposed an online method for Bayesian
model averaging (BMA). Inspired by the literature on renewable estimation, they
developed an online Bayesian method for generalized linear models (GLMs) that
reduces storage and computational demands dramatically compared to traditional
methods for BMA. The method of Ghosh et al. (2025) works very well when the
number of models is small. It can also work reasonably well in moderately large
model spaces. For the latter case, the method relies on a screening stage to
identify important models in the first several batches via offline methods.
Thereafter, the model space remains fixed in all subsequent batches. In the
post-screening stage, online updates are made to the model specific parameters,
for models selected in the screening stage. For high-dimensional model spaces,
the chance of missing important models in the screening stage is more likely.
This necessitates the development of a method, which permits the model space to
be updated as new batches of data arrive. In this article, we develop an online
Bayesian model selection method for logistic regression, where the selected
model can potentially change throughout the data collection process. We use
simulation studies to show that our new method can outperform the method of
Ghosh et al. (2025). Furthermore, we describe scenarios under which the gain
from our new method is expected to be small. We revisit the traffic crash data
analyzed by Ghosh et al. (2025) and illustrate that our new model selection
method can have better performance for variable selection.",http://arxiv.org/abs/2501.10930v1
"Interactive Multiscale Modeling to Bridge Atomic Properties and
  Electrochemical Performance in Li-CO$_2$ Battery Design",2025-01-19T05:54:10Z,"Mohammed Lemaalem, Selva Chandrasekaran Selvaraj, Ilias Papailias, Naveen K. Dandu, Arash Namaeighasemi, Larry A. Curtiss, Amin Salehi-Khojin, Anh T. Ngo","Li-CO$_2$ batteries show promise as energy storage solutions, offering high
theoretical energy density and CO$_2$ fixation. Their performance relies on the
formation and decomposition of Li$_2$CO$_3$/C during discharge and charge
cycles, respectively. We used a multiscale modeling framework that integrates
Density Functional Theory (DFT), Ab-Initio Molecular Dynamics (AIMD), classical
Molecular Dynamics (MD), and Finite Element Analysis (FEA) to investigate
atomic and cell-level properties. The Li-CO$_2$ battery consists of a lithium
metal anode, an ionic liquid electrolyte, and a carbon cloth porous cathode
with a Sb$_{0.67}$Bi$_{1.33}$Te$_3$ catalyst. DFT and AIMD determined the
electrical conductivities of Sb$_{0.67}$Bi$_{1.33}$Te$_3$ and Li$_2$CO$_3$
using the Kubo-Greenwood formalism and studied the CO$_2$ reduction mechanism
on the cathode catalyst. MD simulations calculated the CO$_2$ diffusion
coefficient, Li$^+$ transference number, ionic conductivity, and Li$^+$
solvation structure. The FEA model, incorporating results from atomistic
simulations, reproduced experimental voltage-capacity profiles at 1 mA/cm$^2$
and revealed spatio-temporal variations in Li$_2$CO$_3$/C deposition, porosity,
and CO$_2$ concentration dependence on discharge rates in the cathode.
Accordingly, Li$_2$CO$_3$ can form toroidal and thin film deposits, leading to
dispersed and local porosity changes at 0.1 mA/cm$^2$ and 1 mA/cm$^2$,
respectively. The capacity decreases exponentially from 81,570 mAh/g at 0.1
mA/cm$^2$ to 6,200 mAh/g at 1 mA/cm$^2$, due to pore clogging that limits
CO$_2$ transport to the cathode interior. Therefore, the performance of
Li-CO$_2$ batteries can be significantly improved by enhancing CO$_2$
transport, regulating Li$_2$CO$_3$ deposition, and optimizing cathode
architecture.",http://arxiv.org/abs/2501.10954v3
"Direct ab initio calculation of magnons in altermagnets: method,
  spin-space symmetry aspects, and application to MnTe",2025-01-20T08:15:37Z,"L. M. Sandratskii, K. Carva, V. M. Silkin","We suggest the method for direct ab initio calculation of magnons in complex
collinear magnets. The method is based on the density-functional-theory
calculation under two different constraints: one constraint governs the change
of the magnetization with respect to the ground state, and the other is the
symmetry constraint responsible for the value of the magnon wave vector. The
performance of the method is demonstrated by the application to an altermagnet
MnTe. An important role in both the formulation and the application of the
method play the aspects of generalized symmetry described by the spin-space
groups. The symmetry analysis connects in one coherent picture the following
three parts of the consideration: (i) the generalized translational symmetry of
the magnons as a crucial condition for their efficient ab-initio calculation,
(ii) altermagnetic spin-splitting of the electron states in the ground magnetic
state, and (iii) chirality splitting of the magnon excitations. It is
demonstrated that both the spin splitting of the electron states and the
chirality splitting of the magnons have identical patterns in the corresponding
wave vector spaces. Since the altermagnetism of MnTe is the consequence of the
presence of the Te atoms, an adequate attention is devoted to the symmetry
analysis and calculation results for the Te moments induced in the magnon
states. The knowledge of the symmetry properties of the Te moments allows to
accelerate the numerical convergence of the magnon states and serves as a test
for the accuracy of the calculations. To expose the connection between electron
band structures of the magnon states of the system and the chirality properties
of these states we investigate the transformation of the electron structure in
the transition from the collinear ground state to a noncollinear magnon state.",http://arxiv.org/abs/2501.11327v1
Comparison of Herschel and ArTéMiS observations of massive filaments,2025-01-20T14:28:21Z,"Emma Mannfors, Mika Juvela, Tie Liu, Veli-Matti Pelkonen","Context: OMC-3 in the Orion A Cloud is a nearby, high-mass star-forming
region, and therefore ideal to study massive filaments in detail. Aims: We
analyze how the inclusion of higher-resolution data changes the estimates of
the filament properties and test the robustness of filament fitting routines.
Methods. ArT\'eMiS and Herschel data are combined to create high-resolution
images. Column densities and temperatures are estimated with modified blackbody
fitting. The nearby OMC-3 cloud is compared to the more distant G202 and G17
clouds. We compare the OMC-3 cloud as it appears at Herschel and ArT\'eMiS
resolution. Results. Column densities of dense clumps in OMC-3 are higher in
combined ArT\'eMiS and Herschel data (FWHM 8.5""), when compared to
Herschel-only data (FWHM 20""). Estimated filament widths are smaller in the
combined maps, and also show signs of further fragmentation when observed with
the ArT\'eMiS resolution. In the analysis of Herschel data the estimated
filament widths are correlated with the distance of the field. Conclusions.
Median filament FWHM in OMC-3 at higher resolution is 0.05 pc, but 0.1 pc with
the Herschel resolution, 0.3 pc in G202 and 1.0 pc in G17, also at the Herschel
resolution. It is unclear what causes the steep relation between distance and
filament FWHM, but likely reasons include the effect of the limited telescope
resolution combined with existing hierarchical structure, and convolution of
large-scale background structures within the ISM. Estimates of the asymptotic
power-law index of the filament profile function p is high. When fit with the
Plummer function, the individual parameters of the profile function are
degenerate, while the FWHM is better constrained. OMC-3 shows negative
kurtosis, and all but OMC-3 at the Herschel resolution some asymmetry.",http://arxiv.org/abs/2501.11507v1
The centimeter emission from planet-forming disks in Taurus,2025-01-20T19:11:54Z,"Antonio Garufi, Carlos Carrasco-Gonzalez, Enrique Macias, Leonardo Testi, Pietro Curone, Luca Ricci, Stefano Facchini, Feng Long, Carlo F. Manara, Ilaria Pascucci, Giovanni Rosotti, Francesco Zagaria, Cathie Clarke, Gregory J. Herczeg, Andrea Isella, Alessia Rota, Karina Mauco, Nienke van der Marel, Marco Tazzari","The last decade has witnessed remarkable advances in the characterization of
the (sub-)millimeter emission from planet-forming disks. Instead, the study of
the (sub-)centimeter emission has made more limited progress, to the point that
only a few exceptional disk-bearing objects have been characterized in the
centimeter regime. This work takes a broad view of the centimeter emission from
a large sample with VLA observations that is selected from previous ALMA
surveys of more representative disks in brightness and extent. We report on the
detection and characterization of flux at centimeter wavelengths from 21
sources in the Taurus star-forming region. Complemented by literature and
archival data, the entire photometry from 0.85 mm to 6 cm is fitted by a
two-component model that determines the ubiquitous presence of free-free
emission entangled with the dust emission. The flux density of the free-free
emission is found to scale with the accretion rate but is independent of the
outer disk morphology depicted by ALMA. The dust emission at 2 cm is still
appreciable, and offers the possibility to extract an unprecedented large set
of dust spectral indices in the centimeter regime. A pronounced change between
the median millimeter indices (2.3) and centimeter indices (2.8) suggests that
a large portion of the disk emission is optically thick up to 3 mm. The
comparison of both indices and fluxes with the ALMA disk extent indicates that
this portion can be as large as 40 au, and suggests that the grain population
within this disk region that emits the observed centimeter emission is similar
in disks with different size and morphology. All these results await
confirmation and dedicated dust modeling once facilities like ngVLA or SKA-mid
are able to resolve the centimeter emission from planet-forming disks and
disentangle the various components.",http://arxiv.org/abs/2501.11686v1
"Using Space-Filling Curves and Fractals to Reveal Spatial and Temporal
  Patterns in Neuroimaging Data",2025-01-21T13:13:42Z,"Jacek Grela, Zbigniew Drogosz, Jakub Janarek, Jeremi K. Ochab, Ignacio Cifre, Ewa Gudowska-Nowak, Maciej A. Nowak, Paweł Oświęcimka, Dante R. Chialvo","We present a novel method, Fractal Space-Curve Analysis (FSCA), which
combines Space-Filling Curve (SFC) mapping for dimensionality reduction with
fractal Detrended Fluctuation Analysis (DFA). The method is suitable for
multidimensional geometrically embedded data, especially for neuroimaging data
which is highly correlated temporally and spatially. We conduct extensive
feasibility studies on diverse, artificially generated data with known fractal
characteristics: the fractional Brownian motion, Cantor sets, and Gaussian
processes. We compare the suitability of dimensionality reduction via Hilbert
SFC and a data-driven alternative. FSCA is then successfully applied to
real-world magnetic resonance imaging (MRI) and functional MRI (fMRI) scans.
  The method utilizing Hilbert curves is optimized for computational
efficiency, proven robust against boundary effects typical in experimental data
analysis, and resistant to data sub-sampling. It is able to correctly quantify
and discern correlations in both stationary and dynamic two-dimensional images.
In MRI Alzheimer's dataset, patients reveal a progression of the disease
associated with a systematic decrease of the Hurst exponent. In fMRI recording
of breath-holding task, the change in the exponent allows distinguishing
different experimental phases.
  This study introduces a robust method for fractal characterization of spatial
and temporal correlations in many types of multidimensional neuroimaging data.
Very few assumptions allow it to be generalized to more dimensions than typical
for neuroimaging and utilized in other scientific fields. The method can be
particularly useful in analyzing fMRI experiments to compute markers of
pathological conditions resulting from neurodegeneration. We also showcase its
potential for providing insights into brain dynamics in task-related
experiments.",http://arxiv.org/abs/2501.12111v1
"Introducing the AIDA-TNG project: galaxy formation in alternative dark
  matter models",2025-01-21T19:00:00Z,"Giulia Despali, Lauro Moscardini, Dylan Nelson, Annalisa Pillepich, Volker Springel, Mark Vogelsberger","We introduce the AIDA-TNG project, a suite of cosmological
magnetohydrodynamic simulations that simultaneously model galaxy formation and
different variations of the underlying dark matter model. We consider the
standard cold dark matter model and five variations, including three warm dark
matter scenarios and two self-interacting models with constant or
velocity-dependent cross-section. In each model, we simulate two cosmological
boxes of 51.7 and 110.7 Mpc on a side, with the same initial conditions as
TNG50 and TNG100, and combine the variations in the physics of dark matter with
the fiducial IllustrisTNG galaxy formation model. The AIDA-TNG runs are thus
ideal for studying the simultaneous effect of baryons and alternative dark
matter models on observable properties of galaxies and large-scale structures.
We resolve haloes in the range between $10^{8}$ and
$4\times10^{14}\,$M$_{\odot}$ and scales down to the nominal resolution of 570
pc in the highest resolution runs. This work presents the first results on
statistical quantities such as the halo mass function and the matter power
spectrum; we quantify the modification in the number of haloes and the power on
scales smaller than 1 Mpc, due to the combination of baryonic and dark matter
physics. Despite being calibrated on cold dark matter, we find that the TNG
galaxy formation model can produce a realistic galaxy population in all
scenarios. The stellar and gas mass fraction, stellar mass function, black hole
mass as a function of stellar mass and star formation rate density are very
similar in all dark matter models, with some deviations only in the most
extreme warm dark matter model. Finally, we also quantify changes in halo
structure due to warm and self-interacting dark matter, which appear in the
density profiles, concentration-mass relation and galaxy sizes.",http://arxiv.org/abs/2501.12439v1
"TOFFE -- Temporally-binned Object Flow from Events for High-speed and
  Energy-Efficient Object Detection and Tracking",2025-01-21T20:20:34Z,"Adarsh Kumar Kosta, Amogh Joshi, Arjun Roy, Rohan Kumar Manna, Manish Nagaraj, Kaushik Roy","Object detection and tracking is an essential perception task for enabling
fully autonomous navigation in robotic systems. Edge robot systems such as
small drones need to execute complex maneuvers at high-speeds with limited
resources, which places strict constraints on the underlying algorithms and
hardware. Traditionally, frame-based cameras are used for vision-based
perception due to their rich spatial information and simplified synchronous
sensing capabilities. However, obtaining detailed information across frames
incurs high energy consumption and may not even be required. In addition, their
low temporal resolution renders them ineffective in high-speed motion
scenarios. Event-based cameras offer a biologically-inspired solution to this
by capturing only changes in intensity levels at exceptionally high temporal
resolution and low power consumption, making them ideal for high-speed motion
scenarios. However, their asynchronous and sparse outputs are not natively
suitable with conventional deep learning methods. In this work, we propose
TOFFE, a lightweight hybrid framework for performing event-based object motion
estimation (including pose, direction, and speed estimation), referred to as
Object Flow. TOFFE integrates bio-inspired Spiking Neural Networks (SNNs) and
conventional Analog Neural Networks (ANNs), to efficiently process events at
high temporal resolutions while being simple to train. Additionally, we present
a novel event-based synthetic dataset involving high-speed object motion to
train TOFFE. Our experimental results show that TOFFE achieves 5.7x/8.3x
reduction in energy consumption and 4.6x/5.8x reduction in latency on edge
GPU(Jetson TX2)/hybrid hardware(Loihi-2 and Jetson TX2), compared to previous
event-based object detection baselines.",http://arxiv.org/abs/2501.12482v1
"Effective-one-body model for coalescing binary neutron stars:
  Incorporating tidal spin and enhanced radiation from dynamical tides",2025-01-22T18:18:47Z,"Hang Yu, Shu Yan Lau","Tidal interactions in a coalescing binary neutron star (BNS) or neutron
star-black hole (NSBH) system driven by gravitational wave (GW) radiation
contain precious information about physics both at extreme density and in the
highly relativistic regime. In the late inspiral stage, where the tidal effects
are the strongest, dynamical corrections to the tidal response become
significant. Previous analyses model the finite-frequency correction through
the effective Love number approach, which only accounts for the correction in
the radial interaction but ignores the lag in the tidal bulge behind the
companion due to the continuous orbital shrinkage. The lag provides a torque,
causing the star's spin to change over time. We dub the evolving component of
the spin the tidal spin, whose dimensionless value can reach 0.03-0.4 depending
on how rapidly the background star rotates. We present an effective-one-body
(EOB) waveform model for BNSs and NSBHs incorporating the tidal spin,
particularly its back reaction to the orbit due to the Newtonian tidal torque
and the relativistic orbital hang-up. Beyond the conservative dynamics, we also
derive the corrections to the dissipative radiation due to finite-frequency
effects to the first post-Newtonian order. Depending on the star's background
spin, the phase error in the time-domain waveform due to ignoring the tidal
spin ranges from 0.3 to 4 radians at the waveform's peak amplitude. The
difference in the waveforms with and without the tidal spin remarkably
resembles the difference between previous effective Love number models and
numerical relativity simulations, underscoring the significance of tidal spin
in the construction of faithful models. Our model further extends the
description of dynamics in the high-background spin regions of the parameter
space that are yet to be covered by numerical simulations.",http://arxiv.org/abs/2501.13064v1
"Are We Learning the Right Features? A Framework for Evaluating DL-Based
  Software Vulnerability Detection Solutions",2025-01-23T00:32:15Z,"Satyaki Das, Syeda Tasnim Fabiha, Saad Shafiq, Nenad Medvidovic","Recent research has revealed that the reported results of an emerging body of
DL-based techniques for detecting software vulnerabilities are not
reproducible, either across different datasets or on unseen samples. This paper
aims to provide the foundation for properly evaluating the research in this
domain. We do so by analyzing prior work and existing vulnerability datasets
for the syntactic and semantic features of code that contribute to
vulnerability, as well as features that falsely correlate with vulnerability.
We provide a novel, uniform representation to capture both sets of features,
and use this representation to detect the presence of both vulnerability and
spurious features in code. To this end, we design two types of code
perturbations: feature preserving perturbations (FPP) ensure that the
vulnerability feature remains in a given code sample, while feature eliminating
perturbations (FEP) eliminate the feature from the code sample. These
perturbations aim to measure the influence of spurious and vulnerability
features on the predictions of a given vulnerability detection solution. To
evaluate how the two classes of perturbations influence predictions, we
conducted a large-scale empirical study on five state-of-the-art DL-based
vulnerability detectors. Our study shows that, for vulnerability features, only
~2% of FPPs yield the undesirable effect of a prediction changing among the
five detectors on average. However, on average, ~84% of FEPs yield the
undesirable effect of retaining the vulnerability predictions. For spurious
features, we observed that FPPs yielded a drop in recall up to 29% for
graph-based detectors. We present the reasons underlying these results and
suggest strategies for improving DNN-based vulnerability detectors. We provide
our perturbation-based evaluation framework as a public resource to enable
independent future evaluation of vulnerability detectors.",http://arxiv.org/abs/2501.13291v4
Multi-aspect Knowledge Distillation with Large Language Model,2025-01-23T02:45:35Z,"Taegyeong Lee, Jinsik Bang, Soyeong Kwon, Taehwan Kim","Recent advancements in deep learning have significantly improved performance
on computer vision tasks. Previous image classification methods primarily
modify model architectures or add features, and they optimize models using
cross-entropy loss on class logits. Since they focus on classifying images with
considering class labels, these methods may struggle to learn various
\emph{aspects} of classes (e.g., natural positions and shape changes).
Rethinking the previous approach from a novel view, we propose a multi-aspect
knowledge distillation method using Multimodal Large Language Models (MLLMs).
Our approach involves: 1) querying Large Language Model with multi-aspect
questions relevant to the knowledge we want to transfer to the model, 2)
extracting corresponding logits from MLLM, and 3) expanding the model's output
dimensions to distill these multi-aspect logits. We then apply cross-entropy
loss to class logits and binary cross-entropy loss to multi-aspect logits.
Through our method, the model can learn not only the knowledge about visual
aspects but also the abstract and complex aspects that require a deeper
understanding. We primarily apply our method to image classification, and to
explore the potential for extending our model, we expand it to other tasks,
such as object detection. In all experimental results, our method improves the
performance of the baselines. Additionally, we analyze the effect of
multi-aspect knowledge distillation. These results demonstrate that our method
can transfer knowledge about various aspects to the model and the aspect
knowledge can enhance model performance in computer vision tasks. This paper
demonstrates the great potential of multi-aspect knowledge distillation, and we
believe it offers a promising direction for future research in computer vision
and beyond.",http://arxiv.org/abs/2501.13341v3
"Suppression of ferromagnetism in van der Waals insulator due to
  pressure-induced layer stacking variation",2025-01-23T07:54:49Z,"M. Misek, U. Dutta, P. Kral, D. Hovancik, J. Kastil, K. Pokhrel, S. Ray, J. Valenta, J. Prchal, J. Kamarad, F. Borodavka, V. Eigner, M. Dusek, V. Holy, K. Carva, S. Kamba, V. Sechovsky, J. Pospisil","External pressure suppresses the ferromagnetism of localized Cr 3d electron
moments in the van der Waals insulator CrBr3, which cannot be explained without
considering a dramatic pressure-induced crystal or electronic structure change.
We addressed this issue by conducting a parallel experimental investigation of
single crystals magnetic and structural properties using magnetization, X-ray
diffraction, and Raman spectroscopy measurements. Ab initio DFT calculations of
electronic structure and atomistic simulations of finite-temperature magnetism
supported the analysis and interpretation of experimental results. The
magnetization measurements at high pressures provided the first direct
experimental evidence of the pressure-induced suppression of ferromagnetism. We
observed a gradual decrease of the bulk magnetic moment and Curie temperature
with increasing pressure, which accelerates at pressures above 3 GPa, leading
to loss of ferromagnetism at 6.5 GPa. By increasing pressure, the ambient
pressure phase gradually breaks down and is accompanied by the generation of
layer stacking that favor the antiferromagnetic coupling of Cr moments. As a
result, the appearing antiparallel pairs of moments disturb the ferromagnetic
structure and reduce the bulk magnetic moment and Curie temperature. This
scenario, which is well corroborated by the results of our theoretical
calculations, suggests an antiferromagnetic phase emerging with increasing
pressure beyond the critical value when the new single trigonal P-3m1 phase
becomes stable, characterized by the ""antiferromagnetic"" A-A layer stacking,
becomes stable. The weak coupling between adjacent magnetic layers in van der
Waals materials allows variations in layering due to sufficient external
forces. We hope our comprehensive study's results can help other researchers
resolve frequently appearing issues of similar origin in this class of
materials.",http://arxiv.org/abs/2501.13446v1
"Dust characterization of protoplanetary disks: a guide to
  multi-wavelength analyses and accurate dust mass measurements",2025-01-23T17:51:01Z,"Elena M. Viscardi, Enrique Macías, Francesco Zagaria, Anibal Sierra, Haochang Jiang, Tomohiro Yoshida, Pietro Curone","Multi-wavelength dust continuum observations of protoplanetary disks are
essential for accurately measuring two key ingredients of planets formation
theories: the dust mass and grain size. Unfortunately, they are also extremely
time-expensive. We aim to investigate the most economic way of performing this
analysis. We benchmark the dust characterization analysis on multi-wavelength
observations of two disk models. We test three different combinations of bands
(in the 0.45 mm $\to$ 7.46 mm range) to see how optically thick and thin
observations aid the reconstruction of the dust properties for different
morphologies and in three different dust mass regimes. We also test different
spatial resolutions. Dust properties are robustly measured in a multi-band
analysis if optically thin observations are included. For typical disks, this
requires wavelengths longer than 3 mm. High-resolution (< 0.03""-0.05"") is
fundamental to resolve the changes in dust content of substructures. However,
lower-resolution results still provide an accurate measurement of the total
dust mass and of the level of grain growth of rings. Additionally, we propose a
new approach that successfully combines lower and higher resolution
observations in the multi-wavelength analysis without losing spatial
information. We also test individually enhancing the resolution of each radial
intensity profile with Frank but we note the presence of artifacts. Finally, we
discuss on the total dust mass that we derive from the SED analyses and compare
it with the traditional method of deriving dust masses from millimeter fluxes.
Accurate dust mass measurements from the SED analysis can be derived by
including optically thin tracers. On the other hand, single-wavelength
flux-based masses are always underestimated by even more than one order of
magnitude.",http://arxiv.org/abs/2501.13877v1
"Interacting galaxies in the IllustrisTNG simulations -- VIII:
  Pericentric star formation rate enhancements are driven both by increased
  fuelling and efficiency",2025-01-23T19:00:17Z,"Lawrence Faria, David R. Patton, Stéphane Courteau, Sara Ellison, Westley Brown","Using the TNG100-1 cosmological simulations, we explore how galaxy
properties, such as specific star formation rate ($\rm sSFR=SFR/M_*$), gas
fraction ($\rm f_{gas} \,= \, M_{\rm H}/M_{*}$), and star formation efficiency
($\rm SFE_{H} = SFR/M_{H}$), change over the course of galaxy-galaxy
interactions. We identify 18,534 distinct encounters from the reconstructed
orbits of a sample of massive galaxies ($\rm M_{*} > 10^{10} \; \rm M_{\odot}$)
with companions within a stellar mass ratio of 0.1 to 10. Using these
encounters, we study the variation of galaxy properties over time as they
approach and move away from pericentric encounters over a redshift range of $0
\leq z < 1$. Following the closest pericentric encounters ($\leq 50$ kpc) of a
host galaxy with its companion, we find that sSFR is enhanced by a factor of
$1.6 \pm 0.1$ on average within the central stellar half-mass radius
(R\textsubscript{1/2}) compared to pre-encounter values. Our results show a
time delay between pericentre and maximum sSFR enhancement of $\sim$0.1 Gyr
with a mean galaxy separation of 75 kpc. We similarly find that $\rm f_{gas}$
is enhanced by a factor of $1.2 \pm 0.1$, and $\rm SFE_{H}$ is enhanced by a
factor of $1.4 \pm 0.1$ following the pericentre of an encounter within the
same timescale. Additionally, we find evidence of inflowing gas towards the
centre, measured by comparing the $\rm f_{gas}$ and metallicity within the
central R\textsubscript{1/2} to the galactic outskirts. We find that
approximately 70 per cent of the peak sSFR enhancement can be attributed to the
increase in $\rm SFE_{H}$, with the increase in $\rm f_{gas}$ contributing the
remaining 30 per cent.",http://arxiv.org/abs/2501.14031v1
"Advancing MRI Reconstruction: A Systematic Review of Deep Learning and
  Compressed Sensing Integration",2025-01-24T01:07:58Z,"Mojtaba Safari, Zach Eidex, Chih-Wei Chang, Richard L. J. Qiu, Xiaofeng Yang","Magnetic resonance imaging (MRI) is a non-invasive imaging modality and
provides comprehensive anatomical and functional insights into the human body.
However, its long acquisition times can lead to patient discomfort, motion
artifacts, and limiting real-time applications. To address these challenges,
strategies such as parallel imaging have been applied, which utilize multiple
receiver coils to speed up the data acquisition process. Additionally,
compressed sensing (CS) is a method that facilitates image reconstruction from
sparse data, significantly reducing image acquisition time by minimizing the
amount of data collection needed. Recently, deep learning (DL) has emerged as a
powerful tool for improving MRI reconstruction. It has been integrated with
parallel imaging and CS principles to achieve faster and more accurate MRI
reconstructions. This review comprehensively examines DL-based techniques for
MRI reconstruction. We categorize and discuss various DL-based methods,
including end-to-end approaches, unrolled optimization, and federated learning,
highlighting their potential benefits. Our systematic review highlights
significant contributions and underscores the potential of DL in MRI
reconstruction. Additionally, we summarize key results and trends in DL-based
MRI reconstruction, including quantitative metrics, the dataset, acceleration
factors, and the progress of and research interest in DL techniques over time.
Finally, we discuss potential future directions and the importance of DL-based
MRI reconstruction in advancing medical imaging. To facilitate further research
in this area, we provide a GitHub repository that includes up-to-date DL-based
MRI reconstruction publications and public
datasets-https://github.com/mosaf/Awesome-DL-based-CS-MRI.",http://arxiv.org/abs/2501.14158v2
"Upgrades and maintenance of the CRYRING@ESR electron cooler for improved
  internal electron target operation",2025-01-24T18:03:46Z,"Athanasios Koutsostathis, Claude Krantz, Elena-Oana Hanu, Frank Herfurth, Regina Heß, Wolfgang Kaufmann, Michael Lestinsky, Mirko Dieter Looshorn, Esther Babette Menz, Andreas Reiter, Jon Roßbach, Stefan Schippers, Phe Man Suherman","The electron cooler of the CRYRING@ESR storage ring at the GSI-FAIR
accelerator complex is a unique instrument, which not only provides beam
cooling of the stored ions, but also serves as a low-energy electron target for
Dielectronic Recombination experiments. The minimisation of vacuum
contamination and the response to rapid energy changes are key requirements of
the cooler in electron target mode. Therefore, a test bench was prepared to
study the outgassing behaviour of the electron gun components and a setup was
constructed to evaluate the drift-electrode-modulation of the acceleration
voltage of the cooler. The vacuum studies showed that the electron gun cathode
was severely malfunctioning and resulted in its replacement. The
drift-electrode-modulation of the acceleration voltage showed significant
improvements compared to direct modulation of the terminal voltage of the
cooler.",http://arxiv.org/abs/2501.14690v1
"Strong-coupling RPA theory of a Bose gas near the
  superfluid--Mott-insulator transition: universal thermodynamics and two-body
  contact",2025-01-24T19:19:19Z,"Nicolas Dupuis, Moksh Bhateja, Adam Rançon","We present a strong-coupling expansion of the Bose-Hubbard model based on a
mean-field treatment of the hopping term, while onsite fluctuations are taken
into account exactly. This random phase approximation (RPA) describes the
universal features of the generic Mott-insulator--superfluid transition
(induced by a density change) and the superfluid phase near the phase
transition. The critical quasi-particles at the quantum critical point have a
quadratic dispersion with an effective mass $m^*$ and their mutual interaction
is described by an effective $s$-wave scattering length $a^*$. The singular
part of the pressure takes the same form as in a dilute Bose gas, provided we
replace the boson mass $m$ and the scattering length in vacuum $a$ by $m^*$ and
$a^*$, and the density $n$ by the excess density $|n-n_{\rm MI}|$ of particles
(or holes) with respect to the Mott insulator. We define a ``universal''
two-body contact $C_{\rm univ}$ that controls the high-momentum tail $\sim
1/|{\bf k}|^4$ of the singular part $n^{\rm sing}_{\bf k}$ of the momentum
distribution. We also apply the strong-coupling RPA to a lattice model of
hard-core bosons and find that the high-momentum distribution is controlled by
a universal contact, in complete agreement with the Bose-Hubbard model.
Finally, we discuss a continuum model of bosons in an optical lattice and
define two additional two-body contacts: a short-distance ``universal'' contact
$C_{\rm univ}^{\rm sd}$ which controls the high-momentum tail of $n^{\rm
sing}_{\bf k}$ at scales larger than the inverse lattice spacing, and a
``full'' contact $C$ which controls the high-momentum tail of the full momentum
distribution $n_{\bf k}$.",http://arxiv.org/abs/2501.14887v2
"Improving DBMS Scheduling Decisions with Fine-grained Performance
  Prediction on Concurrent Queries -- Extended",2025-01-27T17:55:39Z,"Ziniu Wu, Markos Markakis, Chunwei Liu, Peter Baile Chen, Balakrishnan Narayanaswamy, Tim Kraska, Samuel Madden","Query scheduling is a critical task that directly impacts query performance
in database management systems (DBMS). Deeply integrated schedulers, which
require changes to DBMS internals, are usually customized for a specific engine
and can take months to implement. In contrast, non-intrusive schedulers make
coarse-grained decisions, such as controlling query admission and re-ordering
query execution, without requiring modifications to DBMS internals. They
require much less engineering effort and can be applied across a wide range of
DBMS engines, offering immediate benefits to end users. However, most existing
non-intrusive scheduling systems rely on simplified cost models and heuristics
that cannot accurately model query interactions under concurrency and different
system states, possibly leading to suboptimal scheduling decisions.
  This work introduces IconqSched, a new, principled non-intrusive scheduler
that optimizes the execution order and timing of queries to enhance total
end-to-end runtime as experienced by the user query queuing time plus system
runtime. Unlike previous approaches, IconqSched features a novel fine-grained
predictor, Iconq, which treats the DBMS as a black box and accurately estimates
the system runtime of concurrently executed queries under different system
states. Using these predictions, IconqSched is able to capture system runtime
variations across different query mixes and system loads. It then employs a
greedy scheduling algorithm to effectively determine which queries to submit
and when to submit them. We compare IconqSched to other schedulers in terms of
end-to-end runtime using real workload traces. On Postgres, IconqSched reduces
end-to-end runtime by 16.2%-28.2% on average and 33.6%-38.9% in the tail.
Similarly, on Redshift, it reduces end-to-end runtime by 10.3%-14.1% on average
and 14.9%-22.2% in the tail.",http://arxiv.org/abs/2501.16256v2
"Tackling artefacts in the timing of relativistic pulsar binaries:
  towards the SKA",2025-01-27T19:00:01Z,"Huanchen Hu, Nataliya K. Porayko, Willem van Straten, Michael Kramer, David J. Champion, Michael J. Keith","Common signal-processing approximations produce artefacts when timing pulsars
in relativistic binary systems, especially edge-on systems with tight orbits,
such as the Double Pulsar. In this paper, we use extensive simulations to
explore various patterns that arise from the inaccuracies of approximations
made when correcting dispersion and Shapiro delay. In a relativistic binary,
the velocity of the pulsar projected onto the line-of-sight varies
significantly on short time scales, causing rapid changes in the apparent
pulsar spin frequency, which is used to convert dispersive delays to pulsar
rotational phase shifts. A well-known example of the consequences of this
effect is the artificial variation of dispersion measure (DM) with binary
phase, first observed in the Double Pulsar 20 years ago. We show that ignoring
the Doppler shift of the spin frequency when computing the dispersive phase
shift exactly reproduces the shape and magnitude of the reported DM variations.
We also simulate and study two additional effects of much smaller magnitude,
which are caused by the assumption that the spin frequency used to correct
dispersion is constant over the duration of the sub-integration and over the
observed bandwidth. We show that failure to account for these two effects leads
to orbital phase-dependent dispersive smearing that leads to apparent orbital
DM variations. The functional form of the variation depends on the orbital
eccentricity. In addition, we find that a polynomial approximation of the
timing model is unable to accurately describe the Shapiro delay of edge-on
systems with orbits less than 4 hours, which poses problems for the
measurements of timing parameters, most notably the Shapiro delay. This will be
a potential issue for sensitive facilities like the FAST and the forthcoming
Square Kilometre Array (SKA); therefore, a more accurate phase predictor is
indispensable.",http://arxiv.org/abs/2501.16421v1
A new look at multi-gravity and dimensional deconstruction,2025-01-27T19:04:16Z,Kieran Wood,"It has long been understood that certain theories of ghost free massive
gravity and their multi-graviton extensions can be thought of as arising from a
higher dimensional theory of gravity, upon discretising the extra dimension.
However, this correspondence between standard multi-gravity and extra
dimensional gravity holds only when one discretises the extra dimension after
gauge fixing the lapse function associated to the various lower dimensional
hypersurfaces. The lapse provides crucial structure to the extra dimensional
theory: in pure general relativity (GR), it ensures full diffeomorphism
invariance of the theory, and enforces its Hamiltonian constraint. Thus, upon
deconstruction, important information related to the extra dimension is missing
in the resulting multi-gravity theory; as a result one could never hope to
recover higher dimensional GR in its entirety upon taking the appropriate
continuum limit. Here, we develop an improved deconstruction procedure that
maintains the free lapse, and show that the resulting deconstructed theory is
essentially multi-gravity equipped with additional dynamical scalar fields,
whose field equations encode the Hamiltonian constraint in the extra
dimensional theory. As an example, we explicitly demonstrate that - with an
FLRW ansatz for the metrics in this new theory - one may recover all of the
equations and constraints of 5-dimensional brane cosmology upon taking the
continuum limit. We then treat the deconstructed theory as an entity in its own
right, and generalise it to arbitrary dimension and interaction structures
beyond those admitting a well-defined continuum limit. We dub this theory
`scalar-tensor multi-gravity', and show that the new scalar equations change
the structure of some simple solutions that were previously allowed in standard
multi-gravity, in a manner that exactly mirrors what we expect from higher
dimensional GR.",http://arxiv.org/abs/2501.16442v2
Hybrid Hadronization -- A Study of In-Medium Hadronization of Jets,2025-01-27T20:30:36Z,"A. Sengupta, R. J. Fries, M. Kordell II, B. Kim, A. Angerami, R. Arora, S. A. Bass, Y. Chen, R. Datta, L. Du, R. Ehlers, H. Elfner, C. Gale, Y. He, B. V. Jacak, P. M. Jacobs, S. Jeon, Y. Ji, F. Jonas, L. Kasper, A. Kumar, R. Kunnawalkam-Elayavalli, J. Latessa, Y. -J. Lee, R. Lemmon, M. Luzum, A. Majumder, S. Mak, A. Mankolli, C. Martin, H. Mehryar, T. Mengel, C. Nattrass, J. Norman, C. Parker, J. -F. Paquet, J. H. Putschke, H. Roch, G. Roland, B. Schenke, L. Schwiebert, C. Shen, M. Singh, C. Sirimanna, D. Soeder, R. A. Soltz, I. Soudi, Y. Tachibana, J. Velkovska, G. Vujanovic, X. -N. Wang, X. Wu, W. Zhao","QCD jets are considered important probes for quark gluon plasma created in
collisions of nuclei at high energies. Their parton showers are significantly
altered if they develop inside of a deconfined medium. Hadronization of jets is
also thought to be affected by the presence of quarks and gluons. We present a
systematic study of the effects of a thermal bath of partons on the
hadronization of parton showers. We use the JETSCAPE framework to create parton
showers both in vacuum and in a brick of quark gluon plasma. The brick setup
allows important parameters, like the size of the plasma as well as the
collective flow of partons, to be varied systematically. We hadronize the
parton showers using Hybrid Hadronization, which permits shower partons to form
strings with thermal partons, or to recombine directly with thermal partons as
well as with each other. We find a sizeable amount of interaction of shower
partons with thermal partons during hadronization, indicating a natural
continuation of the interaction of jet and medium during this stage. The
observed effects grow with the size of the medium. Collective flow easily
transfers from the thermal partons onto the emerging jet hadrons. We also see a
significant change in hadron chemistry as expected in the presence of quark
recombination processes.",http://arxiv.org/abs/2501.16482v1
"ATOMS: ALMA Three-millimeter Observations of massive Star-forming
  regions -XX. Probability distribution function of integrated intensity for
  dense molecular gas tracers",2025-01-28T03:37:02Z,"C. Zhang, Tie Liu, Sihan Jiao, Feng-Yao Zhu, Z. -Y. Ren, H. -L. Liu, Ke Wang, J. -W. Wu, D. Li, P. García, Guido Garay, Leonardo Bronfman, Mika Juvela, Swagat das, Chang Won Lee, Feng-Wei Xu, L. V. Tóth, Prasanta Gorai, Patricio Sanhueza","We report the observations of J=1-0 of HCN, HCO+, H13CO+, and H13CN, HC3N
(J=11-10) emission towards 135 massive star-forming clumps, as part of the
ATOMS (ALMA Three-millimeter Observations of Massive Star-forming regions)
Survey. We present the integrated intensity probability distribution function
for these molecular tracers, modeled as a combination of a log-normal
distribution and a power-law tail. The molecular line luminosities for the
power-law tail segment, Lmol(p), have been calculated. We have investigated the
correlation between the bolometric luminosity, Lbol, and the power-law part of
the molecular line luminosity, Lmol(p). Our findings suggest that the scaling
relationships between Lbol and Lmol(p) for HCN and HCO+ are sublinear,
indicating that these molecules might not be the most effective tracers for the
dense gas. In contrast, H13CN and HC3N exhibit a nearly linear relationship
between Lbol and Lmol(p), indicating that they can well trace gravitationally
bound dense gas. The ratios of Lbol-to-Lmol(p), serving as indicators of star
formation efficiency within massive star-forming clumps, exhibit a weak
anti-correlation with the power-law index in the I-PDF. In addition, the star
formation efficiency is also weakly anti-correlated with the exponent U of the
corresponding equivalent density distribution. Our results implie that clumps
with substantial gas accumulation may still display low star formation
efficiencies.",http://arxiv.org/abs/2501.16682v1
"NuSTAR detection of a hot stellar superflare with a temperature of 95 MK
  in hard X-rays",2025-01-28T05:15:20Z,"Tomohiro Hakamata, Hironori Matsumoto, Hirokazu Odaka, Shinsuke Takasao","A search of the hard X-ray archive data of NuSTAR found a transient source,
NuSTAR J230059+5857.4, during an observation of 1E 2259+586 on 2013 April 25. A
multi-wavelength analysis using X-ray, optical, and IR data, mostly taken in
its quiescent phase, was conducted to identify the origin of NuSTAR
J230059+5857.4 and elucidate the phenomena associated with the flare activity.
The results indicated that NuSTAR J230059+5857.4 was a stellar flare that
occurred on a single M-dwarf, M-dwarf binary, or pre-main-sequence star. NuSTAR
J230059+5857.4 exhibited the higher emission measure and higher temperature,
8.60+2.15/-1.73x10^54 cm^-3 and 8.21+2.71/-1.86 keV, respectively, on average
than the nominal values of stellar flares reported in the past. The flare loop
size estimated on the basis of the model to balance the plasma and magnetic
pressures was larger than the stellar radius by a factor of several. Since
based on solar flare loops, this flare loop scale is excessively large, we
conjecture that the observed large emission measure is possible to be
attributed to the observation of mutually-associated multiple flares
simultaneously occurring on the stellar surface, known as sympathetic flares.
Thanks to the large effective area of NuSTAR in the hard X-ray band, we can
conduct detailed discussion about a temperature variation associated with the
flare. Investigation of the temperature variation during the flare revealed
that the temperature remained significantly higher than during the quiescent
phase even after the count rate dropped to around 5% of the peak. The sustained
high temperature over the long duration is consistent with the idea of
sympathetic flares. We found that it is essential to use theoretical models to
evaluate loops and assess temporal changes in temperature as done in this study
to determine whether there are multiple flares or not when analyzing flare
observation data.",http://arxiv.org/abs/2501.16710v1
The thermal index of neutron-star matter in the virial approximation,2025-01-28T08:54:50Z,"Giuseppe Rivieccio, Adriana Nadal-Matosas, Arnau Rios, Milton Ruiz","Motivated by gravitational wave observations of binary neutron-star mergers,
we study the thermal index of low-density, high-temperature dense matter. We
use the virial expansion to account for nuclear interaction effects. We focus
on the region of validity of the expansion, which reaches $10^{-3}$ fm$^{-3}$
at $T=5$ MeV up to almost saturation density at $T=50$ MeV. In pure neutron
matter, we find an analytical expression for the thermal index, and show that
it is nearly density- and temperature-independent, within a fraction of a
percent of the non-interacting, non-relativistic value of $\Gamma_\text{th}
\approx 5/3$. When we incorporate protons, electrons and photons, we find that
the density and temperature dependence of the thermal index changes
significantly. We predict a smooth transition between an electron-dominated
regime with $\Gamma_\text{th} \approx 4/3$ at low densities to a
neutron-dominated region with $\Gamma_\text{th} \approx 5/3$ at high densities.
This behavior is by and large independent of proton fraction and is not
affected by nuclear interactions in the region where the virial expansion
converges. We model this smooth transition analytically and provide a simple
but accurate parametrization of the inflection point between these regimes.
When compared to tabulated realistic models of the thermal index, we find an
overall agreement at high temperatures that weakens for colder matter. The
discrepancies can be attributed to the missing contributions of nuclear
clusters. The virial approximation provides a clear and physically intuitive
framework for understanding the thermal properties of dense matter, offering a
computationally efficient solution that makes it particularly well-suited for
the regimes relevant to neutron star binary remnants.",http://arxiv.org/abs/2501.16795v1
"On variability of DDO68-V1, a unique extremely metal-poor LBV",2025-01-28T09:25:49Z,"S. A. Pustilnik, Y. A. Perepelitsyna","DDO68-V1 is a Luminous Blue Variable (LBV) star in the eXtremely Metal-Poor
(XMP) galaxy DDO68. It resides in the HII region with 12+log(O/H)~7.1 dex, or Z
~ Zo/40. Since DDO68-V1 is the only known LBV with a so low initial
metallicity, its in-deep study can give the hints for understanding the LBV
evolutionary stage and the nature of their powerful and highly variable mass
loss in the very low-metallicity regime. Our goal is to study the optical
variability of DDO68-V1 during the last 36 years, with the emphasis on the
period of the last 8 years, after the LBV giant eruption. We use our published
results of monitoring in B, V, R bands of the total flux of HII region 'Knot
3', containing the LBV, along with photometry of the archive Hubble Space
Telescope (HST) images, obtained in May 2010 and December 2017. This data allow
us to disentangle the variable light of DDO68-V1 and that of the underlying HII
region. From all available photometry of Knot 3, we derive the V-band
lightcurve of DDO68-V1 since 1988, with a higher cadence during the years
2015-2023, when the lightcurve resembles that of S Doradus. The new data reveal
the full range of DDO68-V1 absolute magnitudes M_V of [-5.9, --10.8] mag. The
LBV variations after the fading of the 'giant eruption' show the unusually
large amplitude of delta_V > 3.0-3.5mag on the time-scale of ~1-1.5 year. The
apparent changes of the integrated B-V colour of Knot 3 are consistent with the
expected colour variations of the LBV in course of the S Doradus 'normal
eruptions'. These data, along with spectra of DDO68-V1, demonstrate the need
for a higher-cadence photometry of DDO68-V1, in order to probe the possible
periodicity in its lightcurve and binarity of the object.",http://arxiv.org/abs/2501.16810v1
"Viscous circumbinary protoplanetary discs -- II. Disc effects on the
  binary orbit",2025-01-28T16:30:15Z,"Anna B. T. Penzlin, Richard A. Booth, Richard P. Nelson, Christoph M. Schäfer, Wilhelm Kley","More than half of all stars are part of binaries, and many form in a common
circumbinary disc. The interaction with the binary shapes the disc to feature a
large eccentric inner cavity and spirals in the inner disc. The shape of the
cavities is linked to binary and disc properties like viscosity and scale
height, and the disc and cavity shape influences the orbital evolution of the
binary stars.
  This is the second part of the study in which we use 2D hydrodynamic
long-term simulations for a range of viscous parameters relevant to
protoplanetary discs to understand the interaction between young stars and the
circumbinary disc. The long-term simulations allow us to study how disc shape
and exchange of mass, momentum and energy between binary and disc depend on the
precession angle between disc and binary orbit on time scales of thousands of
binary orbits.
  We find a considerable, periodic interaction between the precession of the
disc and the binary eccentricity that can significantly exceed the
precession-averaged change in eccentricity. We further confirm that thin discs
($H/R<0.05$) lead to shrinking binary orbits, also in the regime of low
viscosity, $\alpha=10^{-3}$. In general, the disc can excite eccentricity in
binaries with initial eccentricities in the range of $e_\mathrm{bin}=0.05-0.4$.
In most cases, the terms aiding shrinking or expansion and circularisation or
excitation are nearly balanced, and the evolution of the binary semi-major axis
and eccentricity will be sensitive to the ratio of mass accretion between the
secondary and primary components.",http://arxiv.org/abs/2501.17055v1
"Critical String Theory in a $D=4$ Robertson-Walker Background and the
  Large Scale Structure of Spacetime",2025-01-28T02:28:21Z,Jaroslaw S. Jaracz,"We show that $4$-dimensional Robertson-Walker spacetimes can be constructed
for which all of the beta functions vanish to leading order, yielding
consistent string theory without extra dimensions. We find that there is a
unique static solution, which we refer to as an anti-Einstein static universe.
The associated stress energy tensor can be interpreted as a perfect fluid with
a negative energy density. Interestingly, a fluid with a negative energy
density was proposed in [2] as an ad hoc hypothesis to serve as a possible
explanation for dark energy and dark matter. Here, such a fluid spontaneously
appears by trying to fit string theory into only $4$ dimensions. We can look at
perturbations away from the anti-Einstein static universe. This has to be done
numerically and we only do it for a few choices of initial conditions. We find
that these solutions are very sensitive to the initial conditions and yield a
variety of behaviors. We hope that this behavior is rich enough to match
cosmological observations by appropriately choosing the initial conditions. One
of these solutions that we found is particularly interesting. It has a hubble
parameter which is negative in the past (meaning a contracting universe), then
a point at which the hubble parameter changes sign, so the universe starts
expanding which could be identified with a big bang, after which the hubble
parameter continues growing. Throughout all of this time, the acceleration is
positive since the Hubble parameter is increasing. Finally, we comment that our
result does not contradict [1] as it seems that the authors overlooked the
possibility of a purely complex axion field which allows for the
Robertson-Walker metrics to make a contribution $c_{RW}\geq 4$ to the central
charge. Thus, we can interpret dark matter and dark energy as being parts of a
mechanism needed to keep $4$-dimensional string theory consistent.",http://arxiv.org/abs/2501.17204v2
BASS XLVII: 22 GHz Radio Atlas of Swift-BAT Selected AGN,2025-01-28T19:00:01Z,"Macon Magno, Krista L. Smith, O. Ivy Wong, Richard Mushotzky, Stuart Vogel, Michael J. Koss, Claudio Ricci, Kyuseok Oh, Chin-Shin Chang, Loreto Barcos-Muñoz, Franz E. Bauer, Alessandro Peca, Darshan Kakkad, Turgay Caglar, Benny Trakhtenbrot, Fiona Harrison, Daniel Stern, C. Megan Urry, Merry Powell","We present the third phase of the largest high-frequency, high-resolution
imaging survey of 231 nearby, hard X-ray selected AGN, with a very high $98 \pm
1\%$ detection fraction. This survey presents VLA 22 GHz radio observations
with 1"" spatial resolution covering over $6$ orders of magnitude in radio
luminosity in nearby AGN that span $\sim4$ orders of magnitude in black hole
mass and X-ray luminosity. We identify three different radio morphologies: $44
\pm 3\%$ (102/231) are compact or unresolved, $46 \pm 3\%$ (106/231) show an
extended structure (star formation, possible one-sided jets, etc.), and $8 \pm
2\%$ (19/231) have a biconical or two-sided jet-like morphology. The remaining
$2 \pm 1\%$ (4/231) sources are non-detections. The radio-to-X-ray luminosity
ratios of the Swift-BAT AGN ($\text{L}_R/\text{L}_{14-195 \text{keV}} \sim
10^{-5.5}$ and $\text{L}_R/\text{L}_{2-10 \text{keV}} \sim 10^{-5}$) with a
scatter of $\sim0.5$ dex are similar to that of coronally active stars
($\text{L}_R/\text{L}_X \sim 10^{-5}$). For most targets, extended emission in
radio-quiet objects is broadly consistent with the expectation for star
formation from previous FIR observations, once the contribution from the radio
core has been subtracted. Our sample represents nearby analogs of distant AGN
at the peak of black hole growth, and thus the high detection fraction in our
work has important implications for future high frequency AGN radio surveys
with the next generation VLA (ngVLA) or Square Kilometre Array (SKA), both of
which should detect large fractions of more distant AGN.",http://arxiv.org/abs/2501.17224v3
"GECKO Follow-up Observation of the Binary Neutron Star-Black Hole Merger
  Candidate S230518h",2025-01-29T09:23:47Z,"Gregory S. H. Paek, Myungshin Im, Mankeun Jeong, Seo-Won Chang, Martin Moonkuk Hur, YoungPyo Hong, Sophia Kim, Jaewon Lee, Dongjin Lee, Seong-Heon Lee, Jae-Hun Jung, Joonho Kim, Hyung Mok Lee, Chung-Uk Lee, Seung-Lee Kim","The gravitational wave (GW) event S230518h is a potential binary neutron
star-black hole merger (NSBH) event that was detected during engineering run 15
(ER15), which served as the commissioning period before the LIGO-Virgo-KAGRA
(LVK) O4a observing run. Despite its low probability of producing detectable
electromagnetic emissions, we performed extensive follow-up observations of
this event using the GECKO telescopes in the southern hemisphere. Our
observation covered 61.7\% of the 90\% credible region, a $\rm 284\:deg^2$ area
accessible from the southern hemisphere, reaching a median limiting magnitude
of $R=21.6$ mag. In these images, we conducted a systematic search for an
optical counterpart of this event by combining a CNN-based classifier and human
verification. We identified 128 transient candidates, but no significant
optical counterpart was found that could have caused the GW signal.
Furthermore, we provide feasible KN properties that are consistent with the
upper limits of observation. Although no optical counterpart was found, our
result demonstrates both GECKO's efficient wide-field follow-up capabilities
and usefulness for constraining properties of kilonovae from NSBH mergers at
distances of $\sim 200$ Mpc.",http://arxiv.org/abs/2501.17506v1
"The evolution of extragalactic peaked-spectrum sources down to 54
  megahertz",2025-01-29T15:15:42Z,"Sai Zhai, Anniek J. Gloudemans, Gülay Gürkan, Femke J. Ballieux, Martin J. Hardcastle, Francesco De Gasperin, Huub J. A. Röttgering","Peaked-spectrum (PS) sources, known for their distinct peaked radio spectra,
represent a type of radio-loud active galactic nuclei (AGN). Among these,
megahertz-peaked spectrum (MPS) sources, which exhibit a spectral peak at a
frequency of a hundred megahertz, have emerged as a potential tool for
identifying high-redshift candidates. However, the potential evolutionary link
between the fraction of these sources and redshift remains unclear and requires
further investigation. The recent, high sensitivity Low Frequency Array (LOFAR)
surveys enable statistical studies of these objects to ultra-low frequencies (<
150 MHz). In this study, we first use the multiradio data to investigate the
evolution of spectral index with redshift for 1,187 quasars from the SDSS 16th
quasar catalog. For each quasar, we analyze available data from the LOFAR Low
Band Antenna (LBA) at 54 MHz, High Band Antenna (HBA) at 144 MHz, and the Very
Large Array (VLA) the Faint Images of the Radio Sky at Twenty cm (FIRST) at 1.4
GHz. We measure the spectral index ($\alpha^{144}_{54}$ and
$\alpha^{1400}_{144}$) and find no significant change in their median values
with the redshift. Extended sources have steeper spectral indices than compact
sources, which is consistent with previous findings. Based on the spectral
indices information, we identify MPS sources using these criteria: $\rm
\alpha^{144}_{54} >= 0.1$ and $\rm \alpha^{1400}_{144} < 0$, and analyze their
properties. We find that the fraction of MPS sources is constant with the
redshift ($0.1-4.8$), bolometric luminosity ($\rm 10^{44}-10^{48} erg/s$), and
supermassive black hole mass ($\rm 10^{7}-10^{10.5} M_{\odot}$), which suggests
that MPS sources have relatively stable physical conditions or formation
mechanisms across various evolutionary stages and environments.",http://arxiv.org/abs/2501.17700v1
Disentangling Safe and Unsafe Corruptions via Anisotropy and Locality,2025-01-30T02:21:07Z,"Ramchandran Muthukumar, Ambar Pal, Jeremias Sulam, Rene Vidal","State-of-the-art machine learning systems are vulnerable to small
perturbations to their input, where ``small'' is defined according to a threat
model that assigns a positive threat to each perturbation. Most prior works
define a task-agnostic, isotropic, and global threat, like the $\ell_p$ norm,
where the magnitude of the perturbation fully determines the degree of the
threat and neither the direction of the attack nor its position in space
matter. However, common corruptions in computer vision, such as blur,
compression, or occlusions, are not well captured by such threat models. This
paper proposes a novel threat model called \texttt{Projected Displacement} (PD)
to study robustness beyond existing isotropic and global threat models. The
proposed threat model measures the threat of a perturbation via its alignment
with \textit{unsafe directions}, defined as directions in the input space along
which a perturbation of sufficient magnitude changes the ground truth class
label. Unsafe directions are identified locally for each input based on
observed training data. In this way, the PD threat model exhibits anisotropy
and locality. Experiments on Imagenet-1k data indicate that, for any input, the
set of perturbations with small PD threat includes \textit{safe} perturbations
of large $\ell_p$ norm that preserve the true label, such as noise, blur and
compression, while simultaneously excluding \textit{unsafe} perturbations that
alter the true label. Unlike perceptual threat models based on embeddings of
large-vision models, the PD threat model can be readily computed for arbitrary
classification tasks without pre-training or finetuning. Further additional
task annotation such as sensitivity to image regions or concept hierarchies can
be easily integrated into the assessment of threat and thus the PD threat model
presents practitioners with a flexible, task-driven threat specification.",http://arxiv.org/abs/2501.18098v1
Cracks in concrete,2025-01-30T14:29:29Z,"Tin Barisin, Christian Jung, Anna Nowacka, Claudia Redenbach, Katja Schladitz","Finding and properly segmenting cracks in images of concrete is a challenging
task. Cracks are thin and rough and being air filled do yield a very weak
contrast in 3D images obtained by computed tomography. Enhancing and segmenting
dark lower-dimensional structures is already demanding. The heterogeneous
concrete matrix and the size of the images further increase the complexity. ML
methods have proven to solve difficult segmentation problems when trained on
enough and well annotated data. However, so far, there is not much 3D image
data of cracks available at all, let alone annotated. Interactive annotation is
error-prone as humans can easily tell cats from dogs or roads without from
roads with cars but have a hard time deciding whether a thin and dark structure
seen in a 2D slice continues in the next one. Training networks by synthetic,
simulated images is an elegant way out, bears however its own challenges. In
this contribution, we describe how to generate semi-synthetic image data to
train CNN like the well known 3D U-Net or random forests for segmenting cracks
in 3D images of concrete. The thickness of real cracks varies widely, both,
within one crack as well as from crack to crack in the same sample. The
segmentation method should therefore be invariant with respect to scale
changes. We introduce the so-called RieszNet, designed for exactly this
purpose. Finally, we discuss how to generalize the ML crack segmentation
methods to other concrete types.",http://arxiv.org/abs/2501.18376v1
"A Comparative Dosimetric Study of Proton and Photon Therapy in
  Stereotactic Arrhythmia Radioablation for Ventricular Tachycardia",2025-01-30T15:39:03Z,"Keyur D. Shah, Chih-Wei Chang, Pretesh Patel, Sibo Tian, Yuan Shao, Kristin A Higgins, Yinan Wang, Justin Roper, Jun Zhou, Zhen Tian, Xiaofeng Yang","Purpose: VT is a life-threatening arrhythmia commonly treated with catheter
ablation; however, some cases remain refractory to conventional treatment. STAR
has emerged as a non-invasive option for such patients. While photon-based STAR
has shown efficacy, proton therapy offers potential advantages due to its
superior dose conformity and sparing of critical OARs, including the heart
itself. This study aims to investigate and compare the dosimetry between proton
and photon therapy for VT, focusing on target coverage and OAR sparing.
Methods: We performed a retrospective study on a cohort of 34 VT patients who
received photon STAR. Proton STAR plans were generated using robust
optimization in RayStation to deliver the same prescription dose of 25 Gy in a
single fraction while minimizing dose to OARs. Dosimetric metrics, including
D99, D95, Dmean, and D0.03cc, were extracted for critical OARs and VAS.
Shapiro-Wilk tests were used to assess normality, followed by paired t-tests or
Wilcoxon signed-rank tests for statistical comparisons between modalities, with
Bonferroni correction applied for multiple comparisons. Results: Proton and
photon plans achieved comparable target coverage, with VAS D95 of 24.1 +/- 1.2
Gy vs. 24.7 +/- 1.0 Gy (p=0.294). Proton therapy significantly reduced OAR
doses, including heart Dmean (3.6 +/- 1.5 Gy vs. 5.5 +/- 2.0 Gy, p<0.001),
lungs Dmean (1.6 +/- 1.5 Gy vs. 2.1 +/- 1.4 Gy, p<0.001), and esophagus Dmean
(0.3 +/- 0.6 Gy vs. 1.6 +/- 1.3 Gy, p<0.001), while maintaining optimal target
coverage. Conclusion: Proton therapy for STAR demonstrates significant
dosimetric advantages in sparing the heart and other critical OARs compared to
photon therapy for VT, while maintaining equivalent target coverage. These
findings highlight the potential of proton therapy to reduce treatment-related
toxicity and improve outcomes for VT patients.",http://arxiv.org/abs/2501.18433v2
"Freeze-and-release direct optimization method for variational
  calculations of excited electronic states",2025-01-30T18:39:29Z,"Yorick L. A. Schmerwitz, Elli Selenius, Gianluca Levi","Time-independent, orbital-optimized density functional approaches outperform
time-dependent density functional theory (TDDFT) in calculations of excited
electronic states involving a large rearrangement of the electron density, such
as charge transfer excitations. However, optimizing orbitals for excited states
remains challenging, as the latter typically correspond to saddle points on the
electronic energy surface. A simple and robust strategy for variational orbital
optimization of excited states is presented. The approach involves two steps:
(1) a constrained energy minimization, where a subset of orbitals changed by
the excitation are frozen, followed by (2) a fully unconstrained saddle point
optimization. The constrained minimization step makes it possible to identify
the electronic degrees of freedom along which the energy needs to be maximized,
preventing variational collapse. Both steps of this freeze-and-release strategy
are carried out using direct optimization algorithms with a computational
scaling comparable to ground state calculations. Numerical tests using a
semilocal functional are performed on intramolecular charge transfer states of
organic molecules and intermolecular charge transfer states of molecular
dimers. It is shown that the freeze-and-release direct optimization (FR-DO)
approach can successfully converge challenging charge transfer states,
overcoming limitations of conventional algorithms based on the maximum overlap
method, which either collapse to lower energy, charge-delocalized solutions or
fail to converge. While FR-DO requires more iterations on average, the overall
increase in computational cost is small. For the NH3-F2 dimer, it is found that
unlike TDDFT, orbital-optimized calculations reproduce the correct long-range
dependency of the energy with respect to the donor-acceptor separation without
the need to include exact exchange in the long range.",http://arxiv.org/abs/2501.18568v1
"DebiasPI: Inference-time Debiasing by Prompt Iteration of a
  Text-to-Image Generative Model",2025-01-28T23:17:20Z,"Sarah Bonna, Yu-Cheng Huang, Ekaterina Novozhilova, Sejin Paik, Zhengyang Shan, Michelle Yilin Feng, Ge Gao, Yonish Tayal, Rushil Kulkarni, Jialin Yu, Nupur Divekar, Deepti Ghadiyaram, Derry Wijaya, Margrit Betke","Ethical intervention prompting has emerged as a tool to counter demographic
biases of text-to-image generative AI models. Existing solutions either require
to retrain the model or struggle to generate images that reflect desired
distributions on gender and race. We propose an inference-time process called
DebiasPI for Debiasing-by-Prompt-Iteration that provides prompt intervention by
enabling the user to control the distributions of individuals' demographic
attributes in image generation. DebiasPI keeps track of which attributes have
been generated either by probing the internal state of the model or by using
external attribute classifiers. Its control loop guides the text-to-image model
to select not yet sufficiently represented attributes, With DebiasPI, we were
able to create images with equal representations of race and gender that
visualize challenging concepts of news headlines. We also experimented with the
attributes age, body type, profession, and skin tone, and measured how
attributes change when our intervention prompt targets the distribution of an
unrelated attribute type. We found, for example, if the text-to-image model is
asked to balance racial representation, gender representation improves but the
skin tone becomes less diverse. Attempts to cover a wide range of skin colors
with various intervention prompts showed that the model struggles to generate
the palest skin tones. We conducted various ablation studies, in which we
removed DebiasPI's attribute control, that reveal the model's propensity to
generate young, male characters. It sometimes visualized career success by
generating two-panel images with a pre-success dark-skinned person becoming
light-skinned with success, or switching gender from pre-success female to
post-success male, thus further motivating ethical intervention prompting with
DebiasPI.",http://arxiv.org/abs/2501.18642v1
"The BTSbot-nearby discovery of SN 2024jlf: rapid, autonomous follow-up
  probes interaction in an 18.5 Mpc Type IIP supernova",2025-01-30T19:00:01Z,"Nabeel Rehemtulla, W. V. Jacobson-Galán, Avinash Singh, Adam A. Miller, Charles D. Kilpatrick, K-Ryan Hinds, Chang Liu, Steve Schulze, Jesper Sollerman, Theophile Jegou du Laz, Tomás Ahumada, Katie Auchettl, S. J. Brennan, Michael W. Coughlin, Christoffer Fremling, Anjasha Gangopadhyay, Daniel A. Perley, Nikolaus Z. Prusinski, Josiah Purdum, Yu-Jing Qin, Sara Romagnoli, Jennifer Shi, Jacob L. Wise, Tracy X. Chen, Steven L. Groom, David O. Jones, Mansi M. Kasliwal, Roger Smith, Niharika Sravan, Shrinivas R. Kulkarni","We present observations of the Type IIP supernova (SN) 2024jlf, including
spectroscopy beginning just 0.7 days ($\sim$17 hours) after first light. Rapid
follow-up was enabled by the new $\texttt{BTSbot-nearby}$ program, which
involves autonomously triggering target-of-opportunity requests for new
transients in Zwicky Transient Facility data that are coincident with nearby
($D<60$ Mpc) galaxies and identified by the $\texttt{BTSbot}$ machine learning
model. Early photometry and non-detections shortly prior to first light show
that SN 2024jlf initially brightened by $>$4 mag/day, quicker than $\sim$90% of
Type II SNe. Early spectra reveal weak flash ionization features: narrow,
short-lived ($1.3 < \tau ~\mathrm{[d]} < 1.8$) emission lines of H$\alpha$, He
II, and C IV. Assuming a wind velocity of $v_w=50$ km s$^{-1}$, these
properties indicate that the red supergiant progenitor exhibited enhanced
mass-loss in the last year before explosion. We constrain the mass-loss rate to
$10^{-4} < \dot{M}~\mathrm{[M_\odot~yr^{-1}]} < 10^{-3}$ by matching
observations to model grids from two independent radiative hydrodynamics codes.
$\texttt{BTSbot-nearby}$ automation minimizes spectroscopic follow-up latency,
enabling the observation of ephemeral early-time phenomena exhibited by
transients.",http://arxiv.org/abs/2501.18686v1
"A Novel Method to Estimate the FUV Flux and a Catalogue for Star-Hosting
  Discs in Nearby Star-Forming Regions",2025-01-30T21:06:20Z,"Rossella Anania, Andrew J. Winter, Giovanni Rosotti, Miguel Vioque, Eleonora Zari, Michelangelo Pantaleoni González, Leonardo Testi","Protoplanetary discs, when externally irradiated by Far Ultraviolet (FUV)
photons from OBA-type stars, lose material through photoevaporative winds,
reducing the amount of material available to form planets. Understanding the
link between environmental irradiation and observed disc properties requires
accurately evaluating the FUV flux at star-hosting discs, which can be
challenging due stellar parallax uncertainties. In this paper, we address this
issue proposing a novel approach: using the local density distribution of a
star-forming region (i.e. 2D pairwise star separations distribution) and
assuming isotropy, we infer 3D separations between star-hosting discs and
massive stars. We test this approach on synthetic clusters, showing that it
significantly improves the accuracy compared to previous methods. We compute
FUV fluxes for a large sample of star-bearing discs in 7 regions within 200 pc,
6 regions in Orion, and Serpens sub-regions, providing a publicly accessible
catalogue. We find that discs in regions hosting late-type B and early-type A
stars can reach non-negligible irradiation levels for disc evolution (10-100
G0). We investigate dust disc masses relative to FUV fluxes detecting hints of
a negative correlation when restricting to average region ages. However, we
emphasize the need for more stellar and disc measurements at >10^2 G0 to probe
the dependence of disc properties on the environmental irradiation. Including
average interstellar dust extinction, median FUV fluxes are not significantly
attenuated, though this result may change if high-resolution 3D dust extinction
maps were available. The method presented in this work is a powerful tool that
can be expanded to additional regions.",http://arxiv.org/abs/2501.18752v1
"Evaluating the Efficacy and Safety of Stereotactic Arrhythmia
  Radioablation in Ventricular Tachycardia: A Comprehensive Systematic Review
  and Meta-Analysis",2025-01-31T03:47:44Z,"Keyur D. Shah, Chih-Wei Chang, Sibo Tian, Pretesh Patel, Richard Qiu, Justin Roper, Jun Zhou, Zhen Tian, Xiaofeng Yang","Purpose: Stereotactic arrhythmia radioablation (STAR) has emerged as a
promising non-invasive treatment for refractory ventricular tachycardia (VT),
offering a novel alternative for patients who are poor candidates for catheter
ablation. This systematic review and meta-analysis evaluates the safety,
efficacy, and technical aspects of STAR across preclinical studies, case
reports, case series, and clinical trials. Methods and Materials: A systematic
review identified 80 studies published between 2015 and 2024, including 12
preclinical studies, 47 case reports, 15 case series, and 6 clinical trials.
Data on patient demographics, treatment parameters, and clinical outcomes were
extracted. Meta-analyses were performed for pooled mortality rates, VT burden
reduction, and acute toxicities, with subgroup analyses exploring
cardiomyopathy type, age, left ventricular ejection fraction (LVEF), and
treatment modality. Results: The pooled 6- and 12-month mortality rates were
16% (95% CI: 11-21%) and 32% (95% CI: 26-39%), respectively. VT burden
reduction at 6 months was 75% (95% CI: 73-77%), with significant heterogeneity
(I^2 = 98.8%). Grade 3+ acute toxicities were observed in 7% (95% CI: 4-11%),
with pneumonitis being the most common. Subgroup analyses showed comparable
outcomes between LINAC- and CyberKnife-based treatments, with minor differences
based on patient characteristics and cardiomyopathy type. Conclusions: STAR
demonstrates significant potential in reducing VT burden and improving patient
outcomes. While favorable acute safety profiles and efficacy support clinical
adoption, variability in treatment protocols underscores the need for
standardized practices. Future studies should aim to optimize patient
selection, establish robust dosimetric standards, and evaluate long-term
safety.",http://arxiv.org/abs/2501.18872v1
"Intermediate-mass stars and the origin of the gas-giant
  planet-metallicity correlation",2025-01-31T12:04:41Z,"J. Maldonado, G. M. Mirouh, I. Mendigutía, B. Montesinos, J. L. Gragera-Más, E. Villaver","The number of known planets around intermediate-mass stars (1.5 M$_{\odot}$ <
M$_{\star}$ < 3.5 M$_{\odot}$) is rather low. We aim to test whether the
correlation between the metallicity of the star and the presence of gas-giant
planets found for MS low-mass stars still holds for intermediate-mass stars. In
particular, we aim to understand whether or not the planet-metallicity relation
changes as stars evolve from the pre-MS to the red giant branch. Our results
confirm that pre-MS stars with transitional discs with gaps show lower
metallicities than pre-MS with flat discs. We show a tendency of
intermediate-mass stars in the MS to follow the gas-giant planet-metallicity
correlation, although the differences in metal content between planet and
non-planet hosts are rather modest and the strength of the correlation is
significantly lower than for the less massive FGK MS stars. For stars in the
red giant branch, we find a strong planet-metallicity correlation, compatible
with that found for FGK MS stars. We discuss how the evolution of the mass in
the convective zone of the star's interior might affect the measured
metallicity of the star. The lack of a well-established planet-metallicity
correlation in pre-MS and MS intermediate-mass stars can be explained by a
scenario in which planet formation leads to an accretion of metal-poor material
on the surface of the star. As intermediate-mass stars are mainly radiative the
metallicity of the star does not reflect its bulk composition but the
composition of the accreted material. When the star leaves the MS and develops
a sizeable convective envelope, a strong-planet metallicity correlation is
recovered. Thus, our results are in line with core-accretion models of planet
formation and the idea that the planet-metallicity correlation reflects a bulk
property of the star.",http://arxiv.org/abs/2501.19074v1
The role of oscillations in grid cells' toroidal topology,2025-01-31T16:20:51Z,"Giovanni di Sarra, Siddharth Jha, Yasser Roudi","Persistent homology applied to the activity of grid cells in the Medial
Entorhinal Cortex suggests that this activity lies on a toroidal manifold. By
analyzing real data and a simple model, we show that neural oscillations play a
key role in the appearance of this toroidal topology. To quantitatively monitor
how changes in spike trains influence the topology of the data, we first define
a robust measure for the degree of toroidality of a dataset. Using this
measure, we find that small perturbations ($\sim$ 100 ms) of spike times have
little influence on both the toroidality and the hexagonality of the ratemaps.
Jittering spikes by $\sim$ 100-500 ms, however, destroys the toroidal topology,
while still having little impact on grid scores. These critical jittering time
scales fall in the range of the periods of oscillations between the theta and
eta bands. We thus hypothesized that these oscillatory modulations of neuronal
spiking play a key role in the appearance and robustness of toroidal topology
and the hexagonal spatial selectivity is not sufficient. We confirmed this
hypothesis using a simple model for the activity of grid cells, consisting of
an ensemble of independent rate-modulated Poisson processes. When these rates
were modulated by oscillations, the network behaved similarly to the real data
in exhibiting toroidal topology, even when the position of the fields were
perturbed. In the absence of oscillations, this similarity was substantially
lower. Furthermore, we find that the experimentally recorded spike trains
indeed exhibit temporal modulations at the eta and theta bands, and that the
ratio of the power in the eta band to that of the theta band,
$A_{\eta}/A_{\theta}$, correlates with the critical jittering time at which the
toroidal topology disappears.",http://arxiv.org/abs/2501.19262v1
"Reheating chiral dynamos with spin-0 and massive spin-1 torsions via
  chiral asymmetry",2025-02-01T12:42:38Z,"Zhi-Fu Gao, Biao-Peng Li, L. C. Garcia de Andrade","Recently, Syderenko et al. (JCAP, 10: 018, 2016) investigated magnetogenesis
and chiral asymmetry in the early hot universe. This study explores the impact
of minimally coupling a constant torsion in their cosmological model,
suggesting new chiral physics. Physically, this means that if torsion is right
chiral, the difference between the number of right and left chiralities does
not change. Moreover, the decay of chiral asymmetry depends on torsion
chirality. We solve the chiral torsionful dynamo equation for magnetic field
seeds. Magnetic helical fields are considered important for chiral fermion
asymmetry. Even in $(3+1)$ dimensional spacetime, torsion is highly suppressed
beyond inflation (Eur Phys J C 82: 291, 2022). However, torsion of
$1\,\mathrm{MeV}$ appears in the early universe. Equations for correlated
magnetic field coefficients are solved in terms of torsion. Weak magnetic
fields of the order of $10^{-42}$ Gauss are boosted by powerful torsionful
dynamo amplification, generating a much stronger magnetic field of the order of
$10^{-9}$ Gauss in the present universe. A galactic magnetic field of $10^{-6}$
Gauss in the present universe, with torsion of $10^{-15}$ Gauss, leads us to a
galactic dynamo seed of $10^{-9}$ Gauss. We also discuss reheating dynamo
regeneration of decaying cosmic magnetic fields during the hadronization era.
The relation between the reheating contribution to e-folds and the connection
between CMF and temperature squared allows us to obtain dynamo amplification in
terms of N-folds of inflation. The main innovation of this work is the
exploration of constant torsion in a cosmological model, revealing new chiral
physics. This study offers a new perspective on the origin and evolution of
magnetic fields in the early universe.",http://arxiv.org/abs/2502.00419v2
Unions with UNIONS: Using galaxy-galaxy lensing to probe galaxy mergers,2025-02-01T22:43:09Z,"Isaac Cheng, Jack Elvin-Poole, Michael J. Hudson, Ruxin Barré, Sara L. Ellison, Robert W. Bickley, Thomas J. L. de Boer, Sébastien Fabbro, Leonardo Ferreira, Sacha Guerrini, Hendrik Hildebrandt, Martin Kilbinger, Alan W. McConnachie, Ludovic van Waerbeke, Anna Wittje","(ABRIDGED) We use galaxy-galaxy lensing to investigate how the dark matter
(DM) haloes and stellar content of galaxies with $0.012 \leq z \leq 0.32$ and
$10 \leq \log_{10}(M_\star/\mathrm{M}_\odot) \leq 12$ change as a result of the
merger process. To this end, we construct two samples of galaxies obtained from
the Ultraviolet Near Infrared Optical Northern Survey (UNIONS), comprising 1
623 post-mergers and $\sim$30 000 non-merging controls, that live in
low-density environments to use as our lenses. These samples are weighted to
share the same distributions of stellar mass, redshift, and geometric mean
distance to a galaxy's three nearest neighbours to ensure differences in the
lensing signal are due to the merger process itself. We do not detect a
significant difference in the excess surface density profile of post-mergers
and non-merging controls with current data. Fitting haloes composed of a
point-like stellar mass component and an extended DM structure described by a
Navarro-Frenk-White profile to the lensing measurements yields, for both
samples, halo masses of $M_\text{halo}\sim 4\times10^{12}\,\mathrm{M}_\odot$
and a moderately negative correlation between $M_\text{halo}$ and concentration
$c$. . . . Extreme merger-induced starbursts, in which more than 60 percent of
the stars are formed in the burst, are ruled out at the 95 per cent confidence
level. Although we do not find merger-induced differences in the DM haloes and
stellar content of galaxies with our current data, application of our methods
to upcoming surveys that are able to provide samples $\sim$10$\times$ larger
than our current catalogue are expected to detect the weak-lensing signatures
of mergers and further constrain their properties.",http://arxiv.org/abs/2502.00584v1
"Energy, enstrophy and helicity transfers in polymeric turbulence",2025-02-02T04:20:17Z,"Alessandro Chiarini, Rahul K. Singh, Marco E. Rosti","We characterise the scale-by-scale transfers of energy, enstrophy and
helicity in homogeneous and isotropic polymeric turbulence using direct
numerical simulations. The microscale Reynolds number is set to $Re_\lambda
\approx 460$, and the Deborah number $De = \tau_p/\tau_f$ is varied between
$1/9 \le De \le 9$; $\tau_p$ is the polymeric relaxation time and $\tau_f$ is
the turnover time of the largest scales of the flow. The study relies on the
exact scale-by-scale budget equations (derived from the the governing model
equations) for energy, enstrophy and helicity, which account for the
back-reaction of the polymers on the flow. Polymers act as a sink/source in the
flow, and provide alternative routes for the scale-by-scale transfers of the
three quantities, whose relevance changes with $De$. We find that polymers
deplete the nonlinear energy cascade mainly at smaller scales, by weakening
both the extreme forward as well as reverse local events. The new
polymer-driven energy flux dominates at small scales for $De \ge 1$, and on
average transfers energy from larger to smaller scales with localised
backscatter events. Polymers weaken the stretching of vorticity with the
enstrophy being mainly generated by the fluid-polymer interaction, especially
when $De \ge 1$. Accordingly, an inspection of the small-scale flow topology
shows that polymers favour events with two-dimensional state of straining, and
promote/inhibit extreme extension/rotation events: in polymeric turbulence
shear and planar extensional flows are more probable. The helicity injected at
the largest scales shows a similar transfer process to as energy, being mainly
driven by the nonlinear cascade at large scales and by the polymer-driven flux
at small scales. Polymers are found to favour events that break the small-scale
mirror symmetry, with the relative helicity monotonically increasing with $De$
at all scales.",http://arxiv.org/abs/2502.00659v1
"Machine learning based Photometric Redshifts for Galaxies in the North
  Ecliptic Pole Wide field: catalogs of spectroscopic and photometric redshifts",2025-02-02T06:43:44Z,"Taewan Kim, Jubee Sohn, Ho Seong Hwang, Simon C. -C. Ho, Denis Burgarella, Tomotsugu Goto, Tetsuya Hashimoto, Woong-Seob Jeong, Seong Jin Kim, Matthew A. Malkan, Takamitsu Miyaji, Nagisa Oi, Hyunjin Shim, Hyunmi Song, Narae Hwang, Byeong-Gon Park","We perform an MMT/Hectospec redshift survey of the North Ecliptic Pole Wide
(NEPW) field covering 5.4 square degrees, and use it to estimate the
photometric redshifts for the sources without spectroscopic redshifts. By
combining 2572 newly measured redshifts from our survey with existing data from
the literature, we create a large sample of 4421 galaxies with spectroscopic
redshifts in the NEPW field. Using this sample, we estimate photometric
redshifts of 77755 sources in the band-merged catalog of the NEPW field with a
random forest model. The estimated photometric redshifts are generally
consistent with the spectroscopic redshifts, with a dispersion of 0.028, an
outlier fraction of 7.3%, and a bias of -0.01. We find that the standard
deviation of the prediction from each decision tree in the random forest model
can be used to infer the fraction of catastrophic outliers and the measurement
uncertainties. We test various combinations of input observables, including
colors and magnitude uncertainties, and find that the details of these various
combinations do not change the prediction accuracy much. As a result, we
provide a catalog of 77755 sources in the NEPW field, which includes both
spectroscopic and photometric redshifts up to z~2. This dataset has significant
legacy value for studies in the NEPW region, especially with upcoming space
missions such as JWST, Euclid, and SPHEREx.",http://arxiv.org/abs/2502.00692v1
"Nonclassical dynamics of Néel vector and magnetization accompanied by
  THz and high-harmonic radiation from ultrafast-light-driven NiO
  antiferromagnet insulator",2025-02-02T16:44:50Z,"Federico Garcia-Gaitan, Adrian E. Feiguin, Branislav K. Nikolic","Ultrafast-light-driven strongly correlated antiferromagnetic insulators, such
as prototypical NiO with large energy gap 4 eV, have recently attracted
experimental attention using either above-gap [K. Gillmeister et al., Nat.
Commun. 11, 4095 (2020)] or subgap [H. Qiu et al., Nat. Phys. 17, 388 (2021)]
energy photons that are of fundamental interest in far-from-equilibrium quantum
matter or spintronic applications, respectively. In the latter context,
emission of THz radiation is also observed from NiO/Pt bilayers, where heavy
metal (HM) Pt introduces strong spin-orbit coupling (SOC). However, microscopic
mechanisms of such emission remain obscure because spintronic THz emitters have
been amply studied using FM/HM (FM-ferromagnetic metal of conventional type)
bilayers, where ultrafast demagnetization takes place and is directly related
to THz emission. Conversely, in NiO total magnetization is zero prior to the fs
laser pulse (fsLP) application. Here we employ the two-orbital
Hubbard-Hund-Heisenberg model and study, via numerically exact nonequilibrium
quantum many-body methods, the dynamics of its Neel vector and nonequilibrium
magnetization. Additionally, we compute electromagnetic radiation by both
time-dependent magnetization and local charge currents arising in either plain
NiO or NiO with proximity SOC introduced by HM layer. Our analysis reveals
nonclassical dynamics of Neel vector and nonequilibrium magnetization, changing
only in length while not rotating, where the former is substantially reduced
only in the case above-gap fsLP. In the plain NiO case, THz radiation of
interest to applications is insignificant, but adding SOC enhances both current
and magnetic dipole contributions to it. Above THz range, we find integer
high-harmonic generation, as well as unusual noninteger harmonics for above-gap
fsLP pump.",http://arxiv.org/abs/2502.00849v4
"Constraining the geometry of the gas surrounding a typical galaxy at $z
  = 3.4$ with Ly$α$ polarization",2025-02-03T19:00:02Z,"A. Bolamperti, S. -J. Chang, J. Vernet, A. Zanella, M. Gronke, F. Arrigoni Battaia, F. Calura, E. Iani, E. Vanzella","Ly$\alpha$ emission is the strongest tracer of recombining ionized hydrogen
in young, star-forming galaxies, but its origin is still debated. Ly$\alpha$
arises when emitted photons scatter in neutral hydrogen and, so far,
observational efforts have mostly focused on the Ly$\alpha$ surface brightness
and spectral profile, which depend on the neutral hydrogen column density,
geometry, kinematics, powering mechanism and on the region from which the
photons are emitted. Different processes produce similar spectra, but have
different degrees of polarization, that we can use to discriminate between
them. In this paper, we present the first spectropolarimetric observations of a
typical star-forming galaxy at $z\sim 3.4$, strongly lensed by the cluster of
galaxies Abell 2895, taken with the PMOS mode of the VLT/FORS2 instrument. We
measure a Ly$\alpha$ degree of polarization $1\sigma$ upper limit of $4.6\%$.
We develop new Ly$\alpha$ radiative transfer models to reproduce the
observations, that can be explained by assuming the star-forming galaxy being
embedded in a CGM with a biconical outflow geometry, with an opening angle of
the wind $\theta_{o,Wind}\sim 30^\circ$ for line-of-sight angles $\theta_{LOS}
\leq 20^\circ$, $\theta_{o,Wind}\sim 45^\circ$ for $\theta_{LOS}\leq 20^\circ$,
$\theta_{o,Wind}\sim 60^\circ$ for $\theta_{LOS}\leq 20^\circ$, and
$\theta_{o,Wind}\sim 75^\circ$ for $\theta_{LOS}\leq 40^\circ$, where
$\theta_{LOS}=0^\circ$ means observing in the direction of the outflow. We
notice that the constraints from polarization are complementary to those from
the spectral line profile. This study shows the potential of adding
measurements of the Ly$\alpha$ degree of polarization to constrain the geometry
of the gas surrounding typical star-forming galaxies and paves the way to
spatially resolved studies that will allow us to disentangle between different
Ly$\alpha$ origin mechanisms.",http://arxiv.org/abs/2502.01742v1
"Sound Judgment: Properties of Consequential Sounds Affecting
  Human-Perception of Robots",2025-02-04T06:33:43Z,"Aimee Allen, Tom Drummond, Dana Kulić","Positive human-perception of robots is critical to achieving sustained use of
robots in shared environments. One key factor affecting human-perception of
robots are their sounds, especially the consequential sounds which robots (as
machines) must produce as they operate. This paper explores qualitative
responses from 182 participants to gain insight into human-perception of robot
consequential sounds. Participants viewed videos of different robots performing
their typical movements, and responded to an online survey regarding their
perceptions of robots and the sounds they produce. Topic analysis was used to
identify common properties of robot consequential sounds that participants
expressed liking, disliking, wanting or wanting to avoid being produced by
robots. Alongside expected reports of disliking high pitched and loud sounds,
many participants preferred informative and audible sounds (over no sound) to
provide predictability of purpose and trajectory of the robot. Rhythmic sounds
were preferred over acute or continuous sounds, and many participants wanted
more natural sounds (such as wind or cat purrs) in-place of machine-like noise.
The results presented in this paper support future research on methods to
improve consequential sounds produced by robots by highlighting features of
sounds that cause negative perceptions, and providing insights into sound
profile changes for improvement of human-perception of robots, thus enhancing
human robot interaction.",http://arxiv.org/abs/2502.02051v1
Measuring social mobility in temporal networks,2025-02-04T14:49:04Z,"Matthew Russell Barnes, Vincenzo Nicosia, Richard G. Clegg","In complex networks, the rich-get-richer effect (nodes with high degree at
one point in time gain more degree in their future) is commonly observed. In
practice this is often studied on a static network snapshot, for example, a
preferential attachment model assumed to explain the more highly connected
nodes or a rich-club}effect that analyses the most highly connected nodes. In
this paper, we consider temporal measures of how success (measured here as node
degree) propagates across time. By analogy with social mobility (a measure
people moving within a social hierarchy through their life) we define
hierarchical mobility to measure how a node's propensity to gain degree changes
over time. We introduce an associated taxonomy of temporal correlation
statistics including mobility, philanthropy and community. Mobility measures
the extent to which a node's degree gain in one time period predicts its degree
gain in the next. Philanthropy and community measure similar properties related
to node neighbourhood.
  We apply these statistics both to artificial models and to 26 real temporal
networks. We find that most of our networks show a tendency for individual
nodes and their neighbourhoods to remain in similar hierarchical positions over
time, while most networks show low correlative effects between individuals and
their neighbourhoods. Moreover, we show that the mobility taxonomy can
discriminate between networks from different fields. We also generate
artificial network models to gain intuition about the behaviour and expected
range of the statistics. The artificial models show that the opposite of the
""rich-get-richer"" effect requires the existence of inequality of degree in a
network. Overall, we show that measuring the hierarchical mobility of a
temporal network is an invaluable resource for discovering its underlying
structural dynamics.",http://arxiv.org/abs/2502.02365v1
"Consistent crust-core interpolation and its effect on non-radial neutron
  star oscillations",2025-02-04T14:53:12Z,"Martin O. Canullan-Pascual, Mauro Mariani, Ignacio F. Ranea-Sandoval, Milva G. Orsaria, Fridolin Weber","To model the structure of neutron stars (NSs) theoretically,it is common to
consider layers with different density regimes. Matching the equation of state
(EoS) for the crust and core and obtaining a suitable description of these
extreme conditions are crucial for understanding the properties of these
compact objects. In this work, we construct ten different NS EoSs incorporating
three distinct crust models, which are connected to the core using a
thermodynamically and causally consistent formalism. For cold NSs, we propose a
linear relationship between pressure and energy density in a narrow region
between the crust and core, effectively establishing an interpolation function
in the pressure-baryonic chemical potential plane. We then compare this EoS
matching method with the classical approach, which neglects causal and
thermodynamic consistency. We solve the Tolman-Oppenheimer-Volkoff equation to
obtain the mass-radius relationship and compare our results with observational
constraints on NSs. Furthermore, we investigate the influence of the new
matching formalism on non-radial oscillation frequencies and damping times. Our
findings suggest that the method used to glue the crust and core EoS impacts NS
observables, such as the radius, oscillation frequencies, and damping times of
non-radial modes, which may be crucial for interpreting future gravitational
wave observations from neutron star mergers or isolated pulsars. The effects
are particularly noticeable for low-mass NSs, regardless of the specific EoS
model chosen. In particular, we find that the $p_1$ oscillation mode exhibits
significant differences in frequencies among alternative matching methods,
whereas the fundamental $f$-mode remains unaffected by changes in crust models
or interpolation schemes.",http://arxiv.org/abs/2502.02373v1
When Anti-Fraud Laws Become a Barrier to Computer Science Research,2025-02-04T23:14:09Z,"Madelyne Xiao, Andrew Sellars, Sarah Scheffler","Computer science research sometimes brushes with the law, from red-team
exercises that probe the boundaries of authentication mechanisms, to AI
research processing copyrighted material, to platform research measuring the
behavior of algorithms and users. U.S.-based computer security research is no
stranger to the Computer Fraud and Abuse Act (CFAA) and the Digital Millennium
Copyright Act (DMCA) in a relationship that is still evolving through case law,
research practices, changing policies, and legislation.
  Amid the landscape computer scientists, lawyers, and policymakers have
learned to navigate, anti-fraud laws are a surprisingly under-examined
challenge for computer science research. Fraud brings separate issues that are
not addressed by the methods for navigating CFAA, DMCA, and Terms of Service
that are more familiar in the computer security literature. Although anti-fraud
laws have been discussed to a limited extent in older research on phishing
attacks, modern computer science researchers are left with little guidance when
it comes to navigating issues of deception outside the context of pure
laboratory research.
  In this paper, we analyze and taxonomize the anti-fraud and deception issues
that arise in several areas of computer science research. We find that, despite
the lack of attention to these issues in the legal and computer science
literature, issues of misrepresented identity or false information that could
implicate anti-fraud laws are actually relevant to many methodologies used in
computer science research, including penetration testing, web scraping, user
studies, sock puppets, social engineering, auditing AI or socio-technical
systems, and attacks on artificial intelligence. We especially highlight the
importance of anti-fraud laws in two research fields of great policy
importance: attacking or auditing AI systems, and research involving legal
identification.",http://arxiv.org/abs/2502.02767v2
"Epitaxial strain tuning of electronic and spin excitations in
  La$_3$Ni$_2$O$_7$ thin films",2025-02-05T13:54:11Z,"Hengyang Zhong, Bo Hao, Yuan Wei, Zhijia Zhang, Ruixian Liu, Xinru Huang, Xiao-Sheng Ni, Marli dos Reis Cantarino, Kun Cao, Yuefeng Nie, Thorsten Schmitt, Xingye Lu","The discovery of ambient-pressure superconductivity with $T_{c,\text{onset}}
> 40$ K in La$_3$Ni$_2$O$_7$ (LNO) thin films under in-plane biaxial
compressive strain underscores the pivotal role of epitaxial strain in tuning
exotic electronic states and provides a unique platform for investigating the
superconducting mechanisms in nickelate superconductors. Here, we use resonant
inelastic X-ray scattering (RIXS) to probe the strain-dependent electronic and
spin excitations in LNO thin films with biaxial strain ranging from
$\epsilon\approx-1.04\%$ to $1.91\%$. Compared with the bulk crystal, the LNO
thin film grown on LaAlO$_3$ (with $\epsilon\approx-1.04\%$) exhibits similar
$dd$ excitations and enhanced spin excitation bandwidth. In contrast, the 0.4
eV and 1.6 eV $dd$ excitations associated with the Ni 3$d_{z^2}$ orbital, along
with the spin excitations, are significantly suppressed in the film grown on
SrTiO$_3$ ($\varepsilon\approx1.91\%$). The $c$-axis compression and the
reduced out-of-plane Ni-O-Ni bond angle, induced by in-plane tensile strain in
LNO/SrTiO$_3$ broaden the Ni 3$d_{z^2}$ bandwidth and decrease the Ni
3$d_{z^2}$-O 2$p_{z}$ hybridization, thereby suppressing the $dd$ excitations.
The evolution of spin excitations reflects significant changes in the
interlayer exchange coupling $J_z$, which can be attributed to the strain-tuned
Ni-O-Ni bond angle. Since superconductivity is observed only in films with
in-plane compressive strain ($\epsilon\sim-2\%$), the strain-dependent spin
correlations align with the emergence of superconductivity, providing indirect
evidence for spin-fluctuation-mediated unconventional superconductivity in LNO.",http://arxiv.org/abs/2502.03178v2
A Flexible FBG-Based Contact Force Sensor for Robotic Gripping Systems,2025-02-06T09:45:21Z,"Wenjie Lai, Huu Duoc Nguyen, Jiajun Liu, Xingyu Chen, Soo Jay Phee","Soft robotic grippers demonstrate great potential for gently and safely
handling objects; however, their full potential for executing precise and
secure grasping has been limited by the lack of integrated sensors, leading to
problems such as slippage and excessive force exertion. To address this
challenge, we present a small and highly sensitive Fiber Bragg Grating-based
force sensor designed for accurate contact force measurement. The flexible
force sensor comprises a 3D-printed TPU casing with a small bump and uvula
structure, a dual FBG array, and a protective tube. A series of tests have been
conducted to evaluate the effectiveness of the proposed force sensor, including
force calibration, repeatability test, hysteresis study, force measurement
comparison, and temperature calibration and compensation tests. The results
demonstrated good repeatability, with a force measurement range of 4.69 N, a
high sensitivity of approximately 1169.04 pm/N, a root mean square error (RMSE)
of 0.12 N, and a maximum hysteresis of 4.83%. When compared to a commercial
load cell, the sensor showed a percentage error of 2.56% and an RMSE of 0.14 N.
Besides, the proposed sensor validated its temperature compensation
effectiveness, with a force RMSE of 0.01 N over a temperature change of 11
Celsius degree. The sensor was integrated with a soft grow-and-twine gripper to
monitor interaction forces between different objects and the robotic gripper.
Closed-loop force control was applied during automated pick-and-place tasks and
significantly improved gripping stability, as demonstrated in tests. This force
sensor can be used across manufacturing, agriculture, healthcare (like
prosthetic hands), logistics, and packaging, to provide situation awareness and
higher operational efficiency.",http://arxiv.org/abs/2502.03914v1
"AT 2018dyk: tidal disruption event or active galactic nucleus? Follow-up
  observations of an extreme coronal line emitter with the Dark Energy
  Spectroscopic Instrument",2025-02-06T13:43:59Z,"Peter Clark, Joseph Callow, Or Graur, Claire Greenwell, Lei Hu, Jessica Aguilar, Steven Ahlen, Davide Bianchi, David Brooks, Todd Claybaugh, Kyle Dawson, Axel de la Macorra, Peter Doel, Satya Gontcho A Gontcho, Gaston Gutierrez, Klaus Honscheid, Stephanie Juneau, Robert Kehoe, Theodore Kisner, Anthony Kremin, Martin Landriau, Laurent Le Guillou, Aaron Meisner, Ramon Miquel, John Moustakas, Ignasi Pérez-Ràfols, Eusebio Sanchez, Michael Schubnell, David Sprayberry, Gregory Tarlé, Benjamin A. Weaver, Hu Zou","We present fresh insights into the nature of the tidal disruption event (TDE)
candidate AT 2018dyk. AT 2018dyk has sparked a debate in the literature around
its classification as either a bona-fide TDE or as an active galactic nucleus
(AGN) turn-on state change. A new follow-up spectrum taken with the Dark Energy
Spectroscopic Instrument, in combination with host-galaxy analysis using
archival SDSS-MaNGA data, supports the identification of AT 2018dyk as a TDE.
Specifically, we classify this object as a TDE that occurred within a gas-rich
environment, which was responsible for both its mid-infrared (MIR) outburst and
development of Fe coronal emission lines. Comparison with the known sample of
TDE-linked extreme coronal line emitters (TDE-ECLEs) and other TDEs displaying
coronal emission lines (CrL-TDEs) reveals similar characteristics and shared
properties. For example, the MIR properties of both groups appear to form a
continuum with links to the content and density of the material in their local
environments. This includes evidence for a MIR colour-luminosity relationship
in TDEs occurring within such gas-rich environments, with those with larger MIR
outbursts also exhibiting redder peaks.",http://arxiv.org/abs/2502.04080v1
"A possible trail of dust from a young, highly-extincted brown dwarf in
  the outskirts of the Trapezium Cluster",2025-02-06T19:00:06Z,"Thomas J. Haworth, Mark J. McCaughrean, Samuel G. Pearson, Richard A. Booth","We present the JWST discovery of a highly-extincted ($A_V\sim52$) candidate
brown dwarf ($\sim0.018$M$_\odot$) in the outskirts of the Trapezium Cluster
that appears to be coincident with the end of a $\sim 1700\,$au long,
remarkably uniformly wide, dark trail that broadens only slightly at the end
opposite the point source. We examine whether a dusty trail associated with a
highly-extincted brown dwarf could plausibly be detected with JWST and explore
possible origins. We show that a dusty trail associated with the brown dwarf
could be observable if dust within it is larger than that in the ambient
molecular cloud. For example, if the ambient cloud has a standard
$\sim0.25$$\mu$m maximum grain size and the trail contains micron-sized grains,
then the trail will have a scattering opacity over an order of magnitude larger
compared to the surroundings in NIRCam short-wavelength filters. We use a
simple model to show that a change in maximum grain size can reproduce the high
$A_V$ and the multi-filter NIRCam contrast seen between the trail and its
surroundings. We propose and explore two possible mechanisms that could be
responsible for the trail: i) a weak FUV radiation-driven wind from the
circum-brown dwarf disc due to the O stars in the region and ii) a
Bondi-Hoyle-Lyttleton accretion wake. The former would be the most distant
known case of the Trapezium stars' radiation driving winds from a disc, and the
latter would be the first known example of ``late'' infall from the
interstellar medium onto a low mass object in a high-mass star-forming region.",http://arxiv.org/abs/2502.04447v2
Explaining JWST counts with galaxy formation models,2025-02-07T07:14:02Z,"Giorgio Manzoni, Tom Broadhurst, Jeremy Lim, Tao Liu, George Smoot, Carlton M. Baugh, Scott Tompkins, Rogier Windhorst, Simon Driver, Timothy Carleton, Brenda Frye, Leo Fung, Jiashuo Zhang, Seth H. Cohen, Christopher J. Conselice, Norman A. Grogin, Rolf A. Jansen, Anton M. Koekemoer, Rafael Ortiz III, Norbert Pirzkal, Christopher N. A. Willmer","A distinct power-law break is apparent m_AB approximately 21 in the deep
Near-Infrared PEARLS-JWST galaxy counts. The break becomes more pronounced at
longer wavelengths, with the counts slope flattening smoothly with apparent
magnitude in the shortest band used at 0.9 microns, trending towards an
increasingly broken slope by the longest wavelength passband of JWST NIRCam,
4.4 microns. This behaviour is remarkably well predicted by the GALFORM
semi-analytical model of galaxy formation. We use the model to diagnose the
origin of this behaviour. We find that the features that are responsible for
the break are: 1) the inherent break in the luminosity function; 2) the change
in the volume element with redshift and 3) the redshift-dependent nature of the
k-correction. We study the contribution to these effects by early and late-type
galaxies, using as a proxy for morphology the bulge-to-total stellar mass
ratio. We find that the way in which ellipticals populate the bright end of the
luminosity function while spirals dominate the faint end is preserved in the
galaxy number counts, with a characteristic stellar mass at the break of
approximately 10^10 M_sun. We also find that the shape of the number counts is
mainly driven by galaxies with relatively low redshift (z < 2) for the PEARLS
observational limit of m_AB < 28. We give a comprehensive description of why
the galaxy number counts in the near-infrared PEARLS-JWST observation look the
way they do and which population of galaxies is dominant at each apparent
magnitude.",http://arxiv.org/abs/2502.04702v1
"Towards Bio-inspired Heuristically Accelerated Reinforcement Learning
  for Adaptive Underwater Multi-Agents Behaviour",2025-02-10T02:47:33Z,"Antoine Vivien, Thomas Chaffre, Matthew Stephenson, Eva Artusi, Paulo Santos, Benoit Clement, Karl Sammut","This paper describes the problem of coordination of an autonomous Multi-Agent
System which aims to solve the coverage planning problem in a complex
environment. The considered applications are the detection and identification
of objects of interest while covering an area. These tasks, which are highly
relevant for space applications, are also of interest among various domains
including the underwater context, which is the focus of this study. In this
context, coverage planning is traditionally modelled as a Markov Decision
Process where a coordinated MAS, a swarm of heterogeneous autonomous underwater
vehicles, is required to survey an area and search for objects. This MDP is
associated with several challenges: environment uncertainties, communication
constraints, and an ensemble of hazards, including time-varying and
unpredictable changes in the underwater environment. MARL algorithms can solve
highly non-linear problems using deep neural networks and display great
scalability against an increased number of agents. Nevertheless, most of the
current results in the underwater domain are limited to simulation due to the
high learning time of MARL algorithms. For this reason, a novel strategy is
introduced to accelerate this convergence rate by incorporating biologically
inspired heuristics to guide the policy during training. The PSO method, which
is inspired by the behaviour of a group of animals, is selected as a heuristic.
It allows the policy to explore the highest quality regions of the action and
state spaces, from the beginning of the training, optimizing the
exploration/exploitation trade-off. The resulting agent requires fewer
interactions to reach optimal performance. The method is applied to the MSAC
algorithm and evaluated for a 2D covering area mission in a continuous control
environment.",http://arxiv.org/abs/2502.06113v1
"LessLeak-Bench: A First Investigation of Data Leakage in LLMs Across 83
  Software Engineering Benchmarks",2025-02-10T07:33:49Z,"Xin Zhou, Martin Weyssow, Ratnadira Widyasari, Ting Zhang, Junda He, Yunbo Lyu, Jianming Chang, Beiqi Zhang, Dan Huang, David Lo","Large Language Models (LLMs) are widely utilized in software engineering (SE)
tasks, such as code generation and automated program repair. However, their
reliance on extensive and often undisclosed pre-training datasets raises
significant concerns about data leakage, where the evaluation benchmark data is
unintentionally ``seen'' by LLMs during the model's construction phase. The
data leakage issue could largely undermine the validity of LLM-based research
and evaluations. Despite the increasing use of LLMs in the SE community, there
is no comprehensive study that assesses the extent of data leakage in SE
benchmarks for LLMs yet. To address this gap, this paper presents the first
large-scale analysis of data leakage in 83 SE benchmarks concerning LLMs. Our
results show that in general, data leakage in SE benchmarks is minimal, with
average leakage ratios of only 4.8\%, 2.8\%, and 0.7\% for Python, Java, and
C/C++ benchmarks, respectively. However, some benchmarks exhibit relatively
higher leakage ratios, which raises concerns about their bias in evaluation.
For instance, QuixBugs and BigCloneBench have leakage ratios of 100.0\% and
55.7\%, respectively. Furthermore, we observe that data leakage has a
substantial impact on LLM evaluation. We also identify key causes of high data
leakage, such as the direct inclusion of benchmark data in pre-training
datasets and the use of coding platforms like LeetCode for benchmark
construction. To address the data leakage, we introduce
\textbf{LessLeak-Bench}, a new benchmark that removes leaked samples from the
83 SE benchmarks, enabling more reliable LLM evaluations in future research.
Our study enhances the understanding of data leakage in SE benchmarks and
provides valuable insights for future research involving LLMs in SE.",http://arxiv.org/abs/2502.06215v1
"Unsupervised deep learning for semantic segmentation of multispectral
  LiDAR forest point clouds",2025-02-10T07:58:49Z,"Lassi Ruoppa, Oona Oinonen, Josef Taher, Matti Lehtomäki, Narges Takhtkeshha, Antero Kukko, Harri Kaartinen, Juha Hyyppä","Point clouds captured with laser scanning systems from forest environments
can be utilized in a wide variety of applications within forestry and plant
ecology, such as the estimation of tree stem attributes, leaf angle
distribution, and above-ground biomass. However, effectively utilizing the data
in such tasks requires the semantic segmentation of the data into wood and
foliage points, also known as leaf-wood separation. The traditional approach to
leaf-wood separation has been geometry- and radiometry-based unsupervised
algorithms, which tend to perform poorly on data captured with airborne laser
scanning (ALS) systems, even with a high point density. While recent machine
and deep learning approaches achieve great results even on sparse point clouds,
they require manually labeled training data, which is often extremely laborious
to produce. Multispectral (MS) information has been demonstrated to have
potential for improving the accuracy of leaf-wood separation, but quantitative
assessment of its effects has been lacking. This study proposes a fully
unsupervised deep learning method, GrowSP-ForMS, which is specifically designed
for leaf-wood separation of high-density MS ALS point clouds and based on the
GrowSP architecture. GrowSP-ForMS achieved a mean accuracy of 84.3% and a mean
intersection over union (mIoU) of 69.6% on our MS test set, outperforming the
unsupervised reference methods by a significant margin. When compared to
supervised deep learning methods, our model performed similarly to the slightly
older PointNet architecture but was outclassed by more recent approaches.
Finally, two ablation studies were conducted, which demonstrated that our
proposed changes increased the test set mIoU of GrowSP-ForMS by 29.4 percentage
points (pp) in comparison to the original GrowSP model and that utilizing MS
data improved the mIoU by 5.6 pp from the monospectral case.",http://arxiv.org/abs/2502.06227v1
"Relativistic Gas Accretion onto Supermassive Black Hole Binaries from
  Inspiral through Merger",2025-02-10T12:18:33Z,"Lorenzo Ennoggi, Manuela Campanelli, Yosef Zlochower, Scott C. Noble, Julian Krolik, Federico Cattorini, Jay V. Kalinani, Vassilios Mewes, Michail Chabanov, Liwei Ji, Maria Chiara de Simone","Accreting supermassive black hole binaries are powerful multimessenger
sources emitting both gravitational and electromagnetic (EM) radiation.
Understanding the accretion dynamics of these systems and predicting their
distinctive EM signals is crucial to informing and guiding upcoming efforts
aimed at detecting gravitational waves produced by these binaries. To this end,
accurate numerical modeling is required to describe both the spacetime and the
magnetized gas around the black holes. In this paper, we present two key
advances in this field of research.
  First, we have developed a novel 3D general relativistic magnetohydrodynamics
(GRMHD) framework that combines multiple numerical codes to simulate the
inspiral and merger of supermassive black hole binaries starting from realistic
initial data and running all the way through merger. Throughout the evolution,
we adopt a simple but functional prescription to account for gas cooling
through the emission of photons.
  Next, we have applied our new computational method to follow the time
evolution of a circular, equal-mass, non-spinning black hole binary for
${\sim\!200}$ orbits starting from a separation of ${20\,r_g}$ and reaching the
post-merger evolutionary stage of the system. We have identified how and when
the minidisks dissolve as the binary compresses. We also show that even when
the binary ``decouples'' from its surrounding disk, its luminosity decreases by
only a factor of a few and abruptly increases by ${\sim\!50\%}$ at the time of
merger, accompanied by an equally abrupt change in spectrum. Finally, the
magnetic flux brought to the spin-parameter ${\sim\!0.68}$ merger remnant is
able to drive a relativistic, Poynting-flux-dominated jet.",http://arxiv.org/abs/2502.06389v1
"Recent Advances, Applications and Open Challenges in Machine Learning
  for Health: Reflections from Research Roundtables at ML4H 2024 Symposium",2025-02-10T17:17:09Z,"Amin Adibi, Xu Cao, Zongliang Ji, Jivat Neet Kaur, Winston Chen, Elizabeth Healey, Brighton Nuwagira, Wenqian Ye, Geoffrey Woollard, Maxwell A Xu, Hejie Cui, Johnny Xi, Trenton Chang, Vasiliki Bikia, Nicole Zhang, Ayush Noori, Yuan Xia, Md. Belal Hossain, Hanna A. Frank, Alina Peluso, Yuan Pu, Shannon Zejiang Shen, John Wu, Adibvafa Fallahpour, Sazan Mahbub, Ross Duncan, Yuwei Zhang, Yurui Cao, Zuheng Xu, Michael Craig, Rahul G. Krishnan, Rahmatollah Beheshti, James M. Rehg, Mohammad Ehsanul Karim, Megan Coffee, Leo Anthony Celi, Jason Alan Fries, Mohsen Sadatsafavi, Dennis Shung, Shannon McWeeney, Jessica Dafflon, Sarah Jabbour","The fourth Machine Learning for Health (ML4H) symposium was held in person on
December 15th and 16th, 2024, in the traditional, ancestral, and unceded
territories of the Musqueam, Squamish, and Tsleil-Waututh Nations in Vancouver,
British Columbia, Canada. The symposium included research roundtable sessions
to foster discussions between participants and senior researchers on timely and
relevant topics for the ML4H community. The organization of the research
roundtables at the conference involved 13 senior and 27 junior chairs across 13
tables. Each roundtable session included an invited senior chair (with
substantial experience in the field), junior chairs (responsible for
facilitating the discussion), and attendees from diverse backgrounds with an
interest in the session's topic.",http://arxiv.org/abs/2502.06693v1
"Wandering around: A bioinspired approach to visual attention through
  object motion sensitivity",2025-02-10T18:16:30Z,"Giulia D Angelo, Victoria Clerico, Chiara Bartolozzi, Matej Hoffmann, P. Michael Furlong, Alexander Hadjiivanov","Active vision enables dynamic visual perception, offering an alternative to
static feedforward architectures in computer vision, which rely on large
datasets and high computational resources. Biological selective attention
mechanisms allow agents to focus on salient Regions of Interest (ROIs),
reducing computational demand while maintaining real-time responsiveness.
Event-based cameras, inspired by the mammalian retina, enhance this capability
by capturing asynchronous scene changes enabling efficient low-latency
processing. To distinguish moving objects while the event-based camera is in
motion the agent requires an object motion segmentation mechanism to accurately
detect targets and center them in the visual field (fovea). Integrating
event-based sensors with neuromorphic algorithms represents a paradigm shift,
using Spiking Neural Networks to parallelize computation and adapt to dynamic
environments. This work presents a Spiking Convolutional Neural Network
bioinspired attention system for selective attention through object motion
sensitivity. The system generates events via fixational eye movements using a
Dynamic Vision Sensor integrated into the Speck neuromorphic hardware, mounted
on a Pan-Tilt unit, to identify the ROI and saccade toward it. The system,
characterized using ideal gratings and benchmarked against the Event Camera
Motion Segmentation Dataset, reaches a mean IoU of 82.2% and a mean SSIM of 96%
in multi-object motion segmentation. The detection of salient objects reaches
88.8% accuracy in office scenarios and 89.8% in low-light conditions on the
Event-Assisted Low-Light Video Object Segmentation Dataset. A real-time
demonstrator shows the system's 0.12 s response to dynamic scenes. Its
learning-free design ensures robustness across perceptual scenes, making it a
reliable foundation for real-time robotic applications serving as a basis for
more complex architectures.",http://arxiv.org/abs/2502.06747v1
Towards a Principled Framework for Disclosure Avoidance,2025-02-10T22:58:06Z,"Michael B Hawes, Evan M Brassell, Anthony Caruso, Ryan Cumings-Menon, Jason Devine, Cassandra Dorius, David Evans, Kenneth Haase, Michele C Hedrick, Alexandra Krause, Philip Leclerc, James Livsey, Rolando A Rodriguez, Luke T Rogers, Matthew Spence, Victoria Velkoff, Michael Walsh, James Whitehorne, Sallie Ann Keller","Responsible disclosure limitation is an iterative exercise in risk assessment
and mitigation. From time to time, as disclosure risks grow and evolve and as
data users' needs change, agencies must consider redesigning the disclosure
avoidance system(s) they use. Discussions about candidate systems often
conflate inherent features of those systems with implementation decisions
independent of those systems. For example, a system's ability to calibrate the
strength of protection to suit the underlying disclosure risk of the data
(e.g., by varying suppression thresholds), is a worthwhile feature regardless
of the independent decision about how much protection is actually necessary.
Having a principled discussion of candidate disclosure avoidance systems
requires a framework for distinguishing these inherent features of the systems
from the implementation decisions that need to be made independent of the
system selected. For statistical agencies, this framework must also reflect the
applied nature of these systems, acknowledging that candidate systems need to
be adaptable to requirements stemming from the legal, scientific, resource, and
stakeholder environments within which they would be operating. This paper
proposes such a framework. No approach will be perfectly adaptable to every
potential system requirement. Because the selection of some methodologies over
others may constrain the resulting systems' efficiency and flexibility to adapt
to particular statistical product specifications, data user needs, or
disclosure risks, agencies may approach these choices in an iterative fashion,
adapting system requirements, product specifications, and implementation
parameters as necessary to ensure the resulting quality of the statistical
product.",http://arxiv.org/abs/2502.07105v1
"Choroidal image analysis for OCT image sequences with applications in
  systemic health",2025-02-10T23:14:09Z,Jamie Burke,"The choroid, a highly vascular layer behind the retina, is an extension of
the central nervous system and has parallels with the renal cortex, with blood
flow far exceeding that of the brain and kidney. Thus, there has been growing
interest of choroidal blood flow reflecting physiological status of systemic
disease. Optical coherence tomography (OCT) enables high-resolution imaging of
the choroid, but conventional analysis methods remain manual or semi-automatic,
limiting reproducibility, standardisation and clinical utility. In this thesis,
I develop several new methods to analyse the choroid in OCT image sequences,
with each successive method improving on its predecessors. I first develop two
semi-automatic approaches for choroid region (Gaussian Process Edge Tracing,
GPET) and vessel (Multi-scale Median Cut Quantisation, MMCQ) analysis, which
improve on manual approaches but remain user-dependent. To address this, I
introduce DeepGPET, a deep learning-based region segmentation method which
improves on execution time, reproducibility, and end-user accessibility, but
lacks choroid vessel analysis and automatic feature measurement. Improving on
this, I developed Choroidalyzer, a deep learning-based pipeline to segment the
choroidal space and vessels and generate fully automatic, clinically meaningful
and reproducible choroidal features. I provide rigorous evaluation of these
four approaches and consider their potential clinical value in three
applications into systemic health: OCTANE, assessing choroidal changes in renal
transplant recipients and donors; PREVENT, exploring choroidal associations
with Alzheimer's risk factors at mid-life; D-RISCii, assessing choroidal
variation and feasibility of OCT in critical care. In short, this thesis
contributes many open-source tools for standardised choroidal measurement and
highlights the choroid's potential as a biomarker in systemic health.",http://arxiv.org/abs/2502.07117v1
"Non-linear integral equations for the XXX spin-1/2 quantum chain with
  non-diagonal boundary fields",2025-02-11T03:43:14Z,"Holger Frahm, Andreas Klümper, Dennis Wagner, Xin Zhang","The XXX spin-$\frac{1}{2}$ Heisenberg chain with non-diagonal boundary
  fields represents a cornerstone model in the study of integrable systems
  with open boundaries. Despite its significance, solving this model exactly
  has remained a formidable challenge due to the breaking of $U(1)$
  symmetry. Building on the off-diagonal Bethe Ansatz (ODBA), we derive a set
  of nonlinear integral equations (NLIEs) that encapsulate the exact spectrum
  of the model.
  For $U(1)$ symmetric spin-$\frac{1}{2}$ chains such NLIEs involve two
  functions $a(x)$ and $\bar{a}(x)$ coupled by an integration kernel with
  short-ranged elements. The solution functions show characteristic features
  for arguments at some length scale which grows logarithmically with system
  size $N$.
  For the non $U(1)$ symmetric case, the equations involve a novel third
  function $c(x)$, which captures the inhomogeneous contributions of the
  $T$-$Q$ relation. The kernel elements coupling this function to the
  standard ones are long-ranged and lead for the ground-state to a winding
  phenomenon. In $\log(1+a(x))$ and $\log(1+\bar a(x))$ we observe a
  sudden change by $2\pi$i at a characteristic scale $x_1$ of the
  argument. Other features appear at a value $x_0$ which is of order $\log N$.
  These two length scales, $x_1$ and $x_0$, are independent: their ratio
  $x_1/x_0$ is large for small $N$ and small for large $N$. Explicit
  solutions to the NLIEs are obtained numerically for these limiting cases,
  though intermediate cases ($x_1/x_0 \sim 1$) present computational
  challenges.
  This work lays the foundation for studying finite-size corrections and
  conformal properties of other integrable spin chains with non-diagonal
  boundaries, opening new avenues for exploring boundary effects in quantum
  integrable systems.",http://arxiv.org/abs/2502.07229v1
NatureLM: Deciphering the Language of Nature for Scientific Discovery,2025-02-11T13:08:03Z,"Yingce Xia, Peiran Jin, Shufang Xie, Liang He, Chuan Cao, Renqian Luo, Guoqing Liu, Yue Wang, Zequn Liu, Yuan-Jyue Chen, Zekun Guo, Yeqi Bai, Pan Deng, Yaosen Min, Ziheng Lu, Hongxia Hao, Han Yang, Jielan Li, Chang Liu, Jia Zhang, Jianwei Zhu, Kehan Wu, Wei Zhang, Kaiyuan Gao, Qizhi Pei, Qian Wang, Xixian Liu, Yanting Li, Houtian Zhu, Yeqing Lu, Mingqian Ma, Zun Wang, Tian Xie, Krzysztof Maziarz, Marwin Segler, Zhao Yang, Zilong Chen, Yu Shi, Shuxin Zheng, Lijun Wu, Chen Hu, Peggy Dai, Tie-Yan Liu, Haiguang Liu, Tao Qin","Foundation models have revolutionized natural language processing and
artificial intelligence, significantly enhancing how machines comprehend and
generate human languages. Inspired by the success of these foundation models,
researchers have developed foundation models for individual scientific domains,
including small molecules, materials, proteins, DNA, and RNA. However, these
models are typically trained in isolation, lacking the ability to integrate
across different scientific domains. Recognizing that entities within these
domains can all be represented as sequences, which together form the ""language
of nature"", we introduce Nature Language Model (briefly, NatureLM), a
sequence-based science foundation model designed for scientific discovery.
Pre-trained with data from multiple scientific domains, NatureLM offers a
unified, versatile model that enables various applications including: (i)
generating and optimizing small molecules, proteins, RNA, and materials using
text instructions; (ii) cross-domain generation/design, such as
protein-to-molecule and protein-to-RNA generation; and (iii) achieving
state-of-the-art performance in tasks like SMILES-to-IUPAC translation and
retrosynthesis on USPTO-50k. NatureLM offers a promising generalist approach
for various scientific tasks, including drug discovery (hit
generation/optimization, ADMET optimization, synthesis), novel material design,
and the development of therapeutic proteins or nucleotides. We have developed
NatureLM models in different sizes (1 billion, 8 billion, and 46.7 billion
parameters) and observed a clear improvement in performance as the model size
increases.",http://arxiv.org/abs/2502.07527v1
"Optimizing Datasets for Code Summarization: Is Code-Comment Coherence
  Enough?",2025-02-11T15:02:19Z,"Antonio Vitale, Antonio Mastropaolo, Rocco Oliveto, Massimiliano Di Penta, Simone Scalabrino","Automated code summarization is a long-standing goal for code comprehension.
This task automatically generates documentation using a given method. Deep
Learning (DL)-based approaches have been proven beneficial for various software
engineering (SE) tasks, including this one. Most state-of-the-art datasets for
code summarization are automatically mined from GitHub and, thus, might contain
erroneous or sub-optimal examples. Previous work showed that using a simple
rule-based approach for removing noisy instances allows for a tangible
reduction of the training set size while not reducing the effectiveness of the
trained models. Motivated by this finding, we conjecture that it is possible to
further reduce the dataset size by removing instances that contain different
issues. In this paper, we explore the extent to which code-comment coherence, a
specific quality attribute of code summaries, can be used to optimize code
summarization datasets. Specifically, we hypothesize that removing incoherent
code-comment pairs might positively impact the effectiveness of the models. To
do this, we rely on SIDE, a recently introduced metric for code-summary
coherence. We examine multiple selectivity levels of training instances from
two state-of-the-art datasets (TL-CodeSum and Funcom) and evaluate the
resulting models on three manually curated test sets. The results show that
even halving the training set sizes does not significantly affect the model's
ability to generate summaries. However, when comparing the most restrictive
selection strategy with a simpler one that randomly selects the training
instances, we observe that the resulting accuracy of the model also does not
change. This result suggests that (i) current datasets contain many irrelevant
examples, and (ii) different quality attributes should be explored for
optimizing code summarization datasets.",http://arxiv.org/abs/2502.07611v1
Interpretable and Equation-Free Response Theory for Complex Systems,2025-02-11T19:28:30Z,Valerio Lucarini,"Response theory provides a pathway for understanding the sensitivity of a
system and, more in general, to predict how its statistical properties change
as a possibly time-dependent perturbation is applied. Recently discovered
general forms of the celebrated Fluctuation-Dissipation Theorem allow for
expressing response operators as correlation functions of suitably defined
observables in the unperturbed state, also when such a state is far from
equilibrium. In the case of complex and multiscale systems, to achieved
enhanced practical applicability, response theory must be interpretable,
capable of focusing of relevant timescales, and amenable to implemented by
data-driven approaches that are potentially equation-agnostic. Complex systems
typically exhibit a hierarchy of temporal behaviors, and unresolved or
undesired timescales can obscure the dominant mechanisms driving macroscopic
responses. As an element of this desired framework, in the spirit of Markov
state modelling, we propose here a comprehensive analysis of the linear and
nonlinear response of Markov chains to general time-dependent perturbations. We
obtain simple and easily implementable formulas that can be used to predict the
response of observables as well as higher-order correlations of the system. The
methodology proposed here can be implemented in a purely data-driven setting
and even if we do not know the underlying evolution equations. The use of
algebraic expansions inspired by Koopmanism allow to elucidate the role of
different time scales and find explicit and interpretable expressions for the
Green's functions at all orders. This is a major advantage of the framework
proposed here. We illustrate our methodology in a very simple yet instructive
metastable system. Finally, our results provide a dynamical foundation for the
Prony method, which is commonly used for the statistical analysis of discrete
time signals.",http://arxiv.org/abs/2502.07908v2
"Epitaxial growth and transport properties of a metallic altermagnet CrSb
  on a GaAs (001) substrate",2025-02-12T04:38:11Z,"Seiji Aota, Masaaki Tanaka","A newly identified class of magnetic materials called altermagnets has
attracted much attention due to the practical properties of spin-splitting
bands akin to ferromagnets and small compensated magnetization akin to
antiferromagnets. These features make them promising candidates for
applications in spintronics devices. Among candidate materials, CrSb is
promising due to its high ordering temperature (705 K) and large spin-splitting
energy; however, it is predicted that tuning the N\'eel vector requires
additional symmetry breaking or a change in the easy magnetization axis. While
applying epitaxial strain can modulate the symmetry, the selection of
substrates with closely matched lattice constants for heteroepitaxial growth is
limited for altermagnets, which generally have low crystal symmetry. Therefore,
exploring the heteroepitaxial growth of altermagnet thin films on
well-established, dissimilar crystal systems is valuable. (001)-oriented III-V
semiconductors, which share group-V elements with the overgrown CrSb, offer an
ideal platform because they are expected to have material compatibility with
stable interfaces, as well as tunability of the buffer layer's bandgap and
lattice constant by varying the atomic composition of their group-III and
group-V atoms. In this study, we have achieved the molecular beam epitaxial
growth of a CrSb ($\bar{1}10$) thin film on a GaAs (001) substrate by inserting
thin FeSb ($\bar{1}10$) / AlAs (001) buffer layers. The in-plane epitaxial
relationship is found to be CrSb [110] $\|$ GaAs [110] and CrSb [001] $\|$ GaAs
[$\bar{1}10$], and epitaxial strain is also confirmed. We also characterized
the magneto-transport properties of the grown CrSb thin film. Although the
obtained conductivity tensors are mainly explained by a multi-carrier model,
not by an anomalous Hall effect, this model reveals the presence of
high-mobility electron and hole carriers.",http://arxiv.org/abs/2502.08117v1
"Analysis of the weak lensing mass-richness relation of redMaPPer
  clusters in the LSST DESC DC2 simulations",2025-02-12T14:34:33Z,"Constantin Payerne, Zhuowen Zhang, Michel Aguena, Céline Combet, Thibault Guillemin, Marina Ricci, Nathan Amouroux, Camille Avestruz, Eduardo J. Barroso, Arya Farahi, Eve Kovacs, Calum Murray, Markus M. Rau, Eli S. Rykoff, Samuel J. Schmidt, the LSST Dark Energy Science Collaboration","Cluster scaling relations are key ingredients in cluster abundance-based
cosmological studies. In optical cluster cosmology, weak gravitational lensing
has proven to be a powerful tool to constrain the cluster mass-richness
relation. This work is conducted as part of the Dark Energy Science
Collaboration (DESC), which aims to analyze the Legacy Survey of Space and Time
(LSST) of Vera C. Rubin Observatory, starting in 2026. Weak lensing-inferred
cluster properties, such as mass, suffer from several sources of bias. In this
paper, we aim to test the impact of modeling choices and observational
systematics in cluster lensing on the inference of the mass-richness relation.
We constrain the mass-richness relation of 3,600 clusters detected by the
redMaPPer algorithm in the cosmoDC2 extra-galactic mock catalog (covering $440$
deg$^2$) of the LSST DESC DC2 simulation, using number count measurements and
stacked weak lensing profiles in several intervals of richness ($20 \leq
\lambda \leq 200$) and redshift ($0.2 \leq z \leq 1$). By modeling the mean of
the scaling relation as $\langle \ln \lambda|M_{\rm 200c}, z\rangle =
\ln\lambda_0 + \mu_z\log[(1+z)/(1+0.5)] + \mu_m[\log_{10}(M_{\rm 200c}) -
14.3]$, our baseline constraints are $\ln\lambda_0 = 3.37\pm 0.03$, $\mu_z =
0.08\pm 0.07$ and $\mu_m = 2.18 \pm 0.07$. We have found that, for a LSST-like
source galaxy density, our constraints are robust to a change in
concentration-mass relation and dark matter density profile modeling choices,
when source redshifts and shapes are perfectly known. We have found that
photometric redshift uncertainties can introduce bias at the $1\sigma$ level,
which can be mitigated by an overall correcting factor, fitted jointly with
scaling parameters. We find that including positive shear-richness covariance
in the fit shifts the results by up to 0.5$\sigma$.",http://arxiv.org/abs/2502.08444v1
Broken symmetries associated with a Kagome chiral charge order,2025-02-12T16:21:12Z,"Zi-Jia Cheng, Md Shafayat Hossain, Qi Zhang, Sen Shao, Jinjin Liu, Yilin Zhao, Mohammad Yahyavi, Yu-Xiao Jiang, Jia-Xin Yin, Xian Yang, Yongkai Li, Tyler A. Cochran, Maksim Litskevich, Byunghoon Kim, Junyi Zhang, Yugui Yao, Luis Balicas, Zhiwei Wang, Guoqing Chang, M. Zahid Hasan","Chirality or handedness manifests in all fields of science, ranging from cell
biology, molecular interaction, and catalysis to different branches of physics.
In condensed matter physics, chirality is intrinsic to enigmatic quantum
phases, such as chiral charge density waves and chiral superconductivity. Here,
the underlying chiral response is subtle and leads to broken symmetries in the
ground state. Detection of subtle broken symmetries is the key to understand
these quantum states but they are extremely challenging to expose leading to
debate and controversy. Here, using second-order optical response, we uncover
the broken symmetries of a chiral charge density wave in the Kagome lattice
KV3Sb5, revealing the relevant broken symmetries of its charge order. KV3Sb5
undergoes a phase transition to a charge-ordered state at low temperatures. Our
polarization-dependent mid-infrared photocurrent microscopy reveals an
intrinsic, longitudinal helicity-dependent photocurrent associated with the
charge order. Our measurements, supported by our theoretical analysis, provide
direct evidence for broken inversion and mirror symmetries at the charge order
transition, indicating a chiral charge ordered state. On the other hand, we do
not observe a circular photogalvanic effect along the direction perpendicular
to that of the incident light, imposing stringent constraints on the rotational
and point group symmetries of the charge order. Our study not only visualizes
the chiral nature of the Kagome charge order revealing its broken symmetries,
but also highlights the nonlinear photogalvanic effect as a sensitive probe for
detecting subtle symmetry breakings.",http://arxiv.org/abs/2502.08537v1
"70 Years of Hyperon Spectroscopy: A review of strange $Ξ$, $Ω$
  baryons, and the spectrum of charmed and bottom baryons",2025-02-12T22:02:48Z,"Volker Crede, John Yelton","The first hyperon was discovered about 70 years ago, but the nature of these
particles, particularly with regard to multistrange hyperons, and many of their
properties can still be considered to be literally strange. A dedicated and
successful global spectroscopy program in the 1960s and 1970s using $K^-$ beams
revealed many multistrange candidates, but the available evidence of their
existence is statistically limited. For this reason, there is still much to
learn about the systematics of the spectrum of excited hyperon states and what
they have in common with their non-strange companions, or how they differ from
the nucleon and $\Delta$ resonances. Recent years have also seen a great deal
of progress in the field of charmed and bottom baryon spectroscopy.
Unprecedented data from the Large Hadron Collider in particular indicate
continued rapid progress in the field of bottom baryons. On the theoretical
side, baryons with one heavy quark $Q$ and a light $qq$ system serve as an
ideal laboratory for studying light $qq$ (diquark) correlations and the
dynamics of the light quarks in the colour environment of a heavy quark. In
this review, we discuss the status of doubly and triply strange $\Xi$ as well
as $\Omega$ baryons, and the properties of all the known charmed and bottom
states. The comparison of the two heavy sectors reveals many similarities as
predicted by heavy-quark symmetries, together with differences in mass
splittings easily understood by potential models. The multi-strange hyperons
bridge the under-explored gap between the light- and the heavy-flavour baryons.
How do the properties of a singly charmed $Q$-$qq$ system change with
decreasing mass of the heavy quark in the transition to a doubly strange
$q$-$QQ$ system with a heavier quark-quark system relative to one light quark?",http://arxiv.org/abs/2502.08815v1
Learning in Strategic Queuing Systems with Small Buffers,2025-02-13T02:23:23Z,"Ariana Abel, Yoav Kolumbus, Jeronimo Martin Duque, Eva Tardos","Routers in networking use simple learning algorithms to find the best way to
deliver packets to their desired destination. This simple, myopic and
distributed decision system makes large queuing systems simple to operate, but
at the same time, the system needs more capacity than would be required if all
traffic were centrally coordinated. In a recent paper, Gaitonde and Tardos (EC
2020 and JACM 2023) initiate the study of such systems, modeling them as an
infinitely repeated game in which routers compete for servers and the system
maintains a state (number of packets held by each queue) resulting from
outcomes of previous rounds. Queues get to send a packet at each step to one of
the servers, and servers attempt to process only one of the arriving packets,
modeling routers. However, their model assumes that servers have no buffers at
all, so queues have to resend all packets that were not served successfully.
They show that, even with hugely increased server capacity relative to what is
needed in the centrally-coordinated case, ensuring that the system is stable
requires using timestamps and priority for older packets. We consider a system
with two important changes, which make the model more realistic: first we add a
very small buffer to each server, allowing it to hold on to a single packet to
be served later (even if it fails to serve it); and second, we do not require
timestamps or priority for older packets. Our main result is to show that when
queues are learning, a small constant factor increase in server capacity,
compared to what would be needed if centrally coordinating, suffices to keep
the system stable, even if servers select randomly among packets arriving
simultaneously. This work contributes to the growing literature on the impact
of selfish learning in systems with carryover effects between rounds: when
outcomes in the present round affect the game in the future.",http://arxiv.org/abs/2502.08898v1
"Solving for the 2D Water Snowline with Hydrodynamic Simulations.
  Emergence of gas outflow, water cycle and temperature plateau",2025-02-13T03:37:08Z,"Yu Wang, Chris W. Ormel, Shoji Mori, Xue-Ning Bai","In protoplanetary disks, the water snowline marks the location where ice-rich
pebbles sublimate, releasing silicate grains and water vapor. These processes
can trigger pile-ups of solids, making the water snowline a promising site for
forming planetesimals. However, previous studies exploring the pile-up
conditions typically employ 1D, vertically-averaged and isothermal assumptions.
In this work, we investigate how a 2D flow pattern and realistic temperature
structure affect the pile-up of pebbles at the snowline and how latent heat
effects can leave observational imprints. We perform 2D (R-Z) multifluid
hydrodynamic simulations, tracking chemically heterogeneous pebbles and the
released vapor. With a recent-developed phase change module, the mass transfer
and latent heat exchange during ice sublimation are calculated
self-consistently. The temperature is calculated by a two-stream radiation
transfer method under various opacities and stellar luminosity. We find that
vapor injection at the snowline drives a previously unrecognized outflow,
leading to a pile-up of ice outside the snowline. Vapor injection also
decreases the headwind velocity in the pile-up, promoting planetesimal
formation and pebble accretion. In active disks, we identify a water-cycle:
after ice sublimates in the hotter midplane, vapor recondenses onto pebbles in
the upper, cooler layers, which settle back to the midplane. This cycle
promotes ice-trapping at snowline. Latent heat exchange flattens the
temperature gradient across the snowline, broadening the width while reducing
the peak solid-to-gas ratio of pile-ups. Due to the water cycle, active disks
are more conducive to planetesimal formation than passive disks. The
significant temperature dip (~ 40K) caused by latent heat cooling manifests as
an intensity dip in the dust continuum, presenting a new channel to identify
the water snowline in outbursting systems.",http://arxiv.org/abs/2502.08936v1
A new long gamma-ray burst formation pathway at solar metallicity,2025-02-13T11:21:21Z,"M. M. Briel, T. Fragos, O. S. Salafia, G. Ghirlanda, E. Zapartas, S. Bavera, J. Andrews, S. Gossage, K. Kovlakas, M. U. Kruckow, K. A. Rocha, P. M. Srivastava, M. Sun, Z. Xing","Context. Long gamma-ray bursts (LGRBs) are generally observed in
low-metallicity environments. However, 10 to 20 per cent of LGRBs at redshift
$z<2$ are associated with near-solar to super-solar metallicity environments,
remaining unexplained by traditional LGRB formation pathways that favour low
metallicity progenitors.
  Aims. In this work, we propose a novel formation channel for LGRBs that is
dominant at high metallicities. We explore how a stripped primary star in a
binary can be spun up by a second, stable reverse-mass-transfer phase,
initiated by the companion star.
  Methods. We use POSYDON a state-of-the-art population synthesis code that
incorporates detailed single- and binary-star mode grids, to investigate the
metallicity dependence of the stable reverse-mass-transfer LGRB formation
channel. We determine the available energy to power an LGRB from the rotational
profile and internal structure of a collapsing star, and investigate how the
predicted rate density of the proposed channel changes with different star
formation histories and criteria for defining a successful LGRB.
  Results. Stable reverse mass transfer can produce rapidly rotating, stripped
stars at collapse. These stars retain enough angular momentum to account for
approximately 10-20% of the observed local LGRB rate density, under a
reasonable assumption for the definition of a successful LGRB. However, the
local rate density of LGRBs from stable reverse mass transfer can vary
significantly, between 1 and 100 Gpc$^{-3}$ yr$^{-1}$, due to strong
dependencies on cosmic star formation rate and metallicity evolution, as well
as the assumed criteria for successful LGRBs.",http://arxiv.org/abs/2502.09187v1
A Physics-Informed Deep Learning Model for MRI Brain Motion Correction,2025-02-13T13:09:55Z,"Mojtaba Safari, Shansong Wang, Zach Eidex, Richard Qiu, Chih-Wei Chang, David S. Yu, Xiaofeng Yang","Background: MRI is crucial for brain imaging but is highly susceptible to
motion artifacts due to long acquisition times. This study introduces
PI-MoCoNet, a physics-informed motion correction network that integrates
spatial and k-space information to remove motion artifacts without explicit
motion parameter estimation, enhancing image fidelity and diagnostic
reliability. Materials and Methods: PI-MoCoNet consists of a motion detection
network (U-net with spatial averaging) to identify corrupted k-space lines and
a motion correction network (U-net with Swin Transformer blocks) to reconstruct
motion-free images. The correction is guided by three loss functions:
reconstruction (L1), perceptual (LPIPS), and data consistency (Ldc). Motion
artifacts were simulated via rigid phase encoding perturbations and evaluated
on IXI and MR-ART datasets against Pix2Pix, CycleGAN, and U-net using PSNR,
SSIM, and NMSE. Results: PI-MoCoNet significantly improved image quality. On
IXI, for minor artifacts, PSNR increased from 34.15 dB to 45.95 dB, SSIM from
0.87 to 1.00, and NMSE reduced from 0.55% to 0.04%. For moderate artifacts,
PSNR improved from 30.23 dB to 42.16 dB, SSIM from 0.80 to 0.99, and NMSE from
1.32% to 0.09%. For heavy artifacts, PSNR rose from 27.99 dB to 36.01 dB, SSIM
from 0.75 to 0.97, and NMSE decreased from 2.21% to 0.36%. On MR-ART,
PI-MoCoNet achieved PSNR gains of ~10 dB and SSIM improvements of up to 0.20,
with NMSE reductions of ~6%. Ablation studies confirmed the importance of data
consistency and perceptual losses, yielding a 1 dB PSNR gain and 0.17% NMSE
reduction. Conclusions: PI-MoCoNet effectively mitigates motion artifacts in
brain MRI, outperforming existing methods. Its ability to integrate spatial and
k-space information makes it a promising tool for clinical use in motion-prone
settings. Code: https://github.com/mosaf/PI-MoCoNet.git.",http://arxiv.org/abs/2502.09296v1
"Mitigating the Impact of Prominent Position Shift in Drone-based RGBT
  Object Detection",2025-02-13T13:25:13Z,"Yan Zhang, Wen Yang, Chang Xu, Qian Hu, Fang Xu, Gui-Song Xia","Drone-based RGBT object detection plays a crucial role in many
around-the-clock applications. However, real-world drone-viewed RGBT data
suffers from the prominent position shift problem, i.e., the position of a tiny
object differs greatly in different modalities. For instance, a slight
deviation of a tiny object in the thermal modality will induce it to drift from
the main body of itself in the RGB modality. Considering RGBT data are usually
labeled on one modality (reference), this will cause the unlabeled modality
(sensed) to lack accurate supervision signals and prevent the detector from
learning a good representation. Moreover, the mismatch of the corresponding
feature point between the modalities will make the fused features confusing for
the detection head. In this paper, we propose to cast the cross-modality box
shift issue as the label noise problem and address it on the fly via a novel
Mean Teacher-based Cross-modality Box Correction head ensemble (CBC). In this
way, the network can learn more informative representations for both
modalities. Furthermore, to alleviate the feature map mismatch problem in RGBT
fusion, we devise a Shifted Window-Based Cascaded Alignment (SWCA) module. SWCA
mines long-range dependencies between the spatially unaligned features inside
shifted windows and cascaded aligns the sensed features with the reference
ones. Extensive experiments on two drone-based RGBT object detection datasets
demonstrate that the correction results are both visually and quantitatively
favorable, thereby improving the detection performance. In particular, our CBC
module boosts the precision of the sensed modality ground truth by 25.52 aSim
points. Overall, the proposed detector achieves an mAP_50 of 43.55 points on
RGBTDronePerson and surpasses a state-of-the-art method by 8.6 mAP50 on a shift
subset of DroneVehicle dataset. The code and data will be made publicly
available.",http://arxiv.org/abs/2502.09311v1
"Single-Pulse Morphology of PSR J1935+1616 (B1933+16) Based on archival
  data from FAST",2025-02-13T14:03:01Z,"R. W. Tian, R. S. Zhao, Marilyn Cruces, H. Liu, D. Li, P. Wang, C. H. Niu, Biping Gong, C. C. Miao, X. Zhu, H. W. Xu, W. L. Li, S. D. Wang, Z. F. Tu, Q. J. Zhi, S. J. Dang, L. H. Shang, S. Xiao","We utilized archived data from the Five-hundred-meter Aperture Spherical
Radio Telescope (FAST) to analyze the single-pulse profile morphology of PSR
J1935$+$1616 (B1933$+$16). The results show that PSR J1935$+$1616 exhibits
significant micropulses as well as various changes in single-pulse profile
morphology. In the FAST archived data, a total of 969 single pulses with
microstructure were identified, accounting for 9.69$\%$ of the total pulse
sample, with characteristic widths of $127.63^{+70.74}_{-46.25}$ $\mu$s. About
half of these pulses display quasiperiodic micropulses, with a periodicity of
231.77 $\pm$ 9.90 $\mu$s. Among the 520 single pulses with quasiperiodic
microstructure, 208 also exhibit quasiperiodicity in circular polarization,
with a characteristic period of $244.70^{+45.66}_{-21.05}$ $\mu$s. The
micropulse characteristic width in circular polarization is 106.52 $\pm$ 46.14
$\mu$s. Compared to normal pulses, the relative energy (E/<E>) of single pulse
with microstructure follows a double Gaussian distribution, while that of
normal pulses follows a single Gaussian distribution. Based on the intensity of
the leading and trailing components in the single-pulse profile morphology of
PSR J1935+1616, we classified the pulses into four morphological modes (A, B,
C, and D). The relative energy distribution of pulses in mode A is
significantly different from the others, following a double Gaussian
distribution, while the relative energy distributions in modes B, C, and D
follow a single Gaussian distribution. Our study also suggests a possible
correlation between micropulses and single-pulse profile morphology. Single
pulse with micropulses are most likely to occur in mode A, while their
occurrence is least likely in mode D.",http://arxiv.org/abs/2502.09342v1
"From Site Response to Site-city Interaction: a Case Study in the Tokyo
  Area",2025-02-14T08:03:29Z,"Pierre-Yves Bard, Nakano Kenji, Ito Eri, Sun Jikai, Wang Ziqian, Kawase Hiroshi","Considering the purpose of the session relating early engineering
developments in site response and soil-structure interaction, this paper
focuses on the development of studies regarding site-city interaction following
the striking site response observations obtained in Mexico City during the 1985
Guerrero-Michoacan event, The first part presents an overview of the
investigations on multiple structure-soil-structure interaction, starting with
Mexico-city like environments with dense urbanization on soft soils, which
later evolved with the concept of metamaterials. Up to now, such investigations
have been largely relying on numerical simulations in 2D and 3D media, coupling
soft surface soil layers and simplified building models, including also some
theoretical developments using various mechanical concepts. They also relied on
a number of laboratory experiments on reduced-scale mock-ups with diverse
vibratory sources (shaking table, acoustic devices). The latest studies coupled
full-scale experiments on mechanical analogs such as forests or wind turbine
farms involving sets of resonators with similar frequencies, and numerical
simulation to investigate their impact on the propagation of surface (Rayleigh)
waves. Almost all such studies converge in predicting lower ground motion
amplitude for sites located within the ''urbanized'' area, but none of them can
be considered a ''groundtruth'' proof for a real earthquake in a real city. The
second part thus takes advantage of the long duration of strong motion
observations in the Kanto area thanks to the KiK-net, K-NET and JMA
(Shin-dokei) networks, to investigate the possible changes in site response
with time. The first results obtained with the event-specific site terms
derived from Generalized Inversion Techniques (Nakano et al., 2015) indicate a
systematic reduction of the low frequency (0.2 -1 Hz) site amplification, in
the central-south Tokyo area. As this frequency band corresponds both to the
site frequency (very thick deposits) and to the high-rise buildings, the
discussion focuses on the possible relation with the extensive construction in
some areas of downtown Tokyo over the last 2 decades.",http://arxiv.org/abs/2502.09976v1
"Heterogeneous Resource Allocation with Multi-task Learning for Wireless
  Networks",2025-02-14T09:13:33Z,"Nikos A. Mitsiou, Pavlos S. Bouzinis, Panagiotis G. Sarigiannidis, George K. Karagiannidis","The optimal solution to an optimization problem depends on the problem's
objective function, constraints, and size. While deep neural networks (DNNs)
have proven effective in solving optimization problems, changes in the
problem's size, objectives, or constraints often require adjustments to the DNN
architecture to maintain effectiveness, or even retraining a new DNN from
scratch. Given the dynamic nature of wireless networks, which involve multiple
and diverse objectives that can have conflicting requirements and constraints,
we propose a multi-task learning (MTL) framework to enable a single DNN to
jointly solve a range of diverse optimization problems. In this framework,
optimization problems with varying dimensionality values, objectives, and
constraints are treated as distinct tasks. To jointly address these tasks, we
propose a conditional computation-based MTL approach with routing. The
multi-task DNN consists of two components, the base DNN (bDNN), which is the
single DNN used to extract the solutions for all considered optimization
problems, and the routing DNN (rDNN), which manages which nodes and layers of
the bDNN to be used during the forward propagation of each task. The output of
the rDNN is a binary vector which is multiplied with all bDNN's weights during
the forward propagation, creating a unique computational path through the bDNN
for each task. This setup allows the tasks to either share parameters or use
independent ones, with the decision controlled by the rDNN. The proposed
framework supports both supervised and unsupervised learning scenarios.
Numerical results demonstrate the efficiency of the proposed MTL approach in
solving diverse optimization problems. In contrast, benchmark DNNs lacking the
rDNN mechanism were unable to achieve similar levels of performance,
highlighting the effectiveness of the proposed architecture.",http://arxiv.org/abs/2502.10027v1
"X-SG$^2$S: Safe and Generalizable Gaussian Splatting with X-dimensional
  Watermarks",2025-02-13T17:59:15Z,"Zihang Cheng, Huiping Zhuang, Chun Li, Xin Meng, Ming Li, Fei Richard Yu","3D Gaussian Splatting (3DGS) has been widely used in 3D reconstruction and 3D
generation. Training to get a 3DGS scene often takes a lot of time and
resources and even valuable inspiration. The increasing amount of 3DGS digital
asset have brought great challenges to the copyright protection. However, it
still lacks profound exploration targeted at 3DGS. In this paper, we propose a
new framework X-SG$^2$S which can simultaneously watermark 1 to 3D messages
while keeping the original 3DGS scene almost unchanged. Generally, we have a
X-SG$^2$S injector for adding multi-modal messages simultaneously and an
extractor for extract them. Specifically, we first split the watermarks into
message patches in a fixed manner and sort the 3DGS points. A self-adaption
gate is used to pick out suitable location for watermarking. Then use a
XD(multi-dimension)-injection heads to add multi-modal messages into sorted
3DGS points. A learnable gate can recognize the location with extra messages
and XD-extraction heads can restore hidden messages from the location
recommended by the learnable gate. Extensive experiments demonstrated that the
proposed X-SG$^2$S can effectively conceal multi modal messages without
changing pretrained 3DGS pipeline or the original form of 3DGS parameters.
Meanwhile, with simple and efficient model structure and high practicality,
X-SG$^2$S still shows good performance in hiding and extracting multi-modal
inner structured or unstructured messages. X-SG$^2$S is the first to unify 1 to
3D watermarking model for 3DGS and the first framework to add multi-modal
watermarks simultaneous in one 3DGS which pave the wave for later researches.",http://arxiv.org/abs/2502.10475v1
"Investigation of Softer Lattice Dynamics in Defect Engineered GeTe
  Crystals",2025-02-15T09:56:33Z,"Saptak Majumder, Pintu Singha, Sharath Kumar C., Mayanak K. Gupta, Dharmendra Kumar, R. Mittal, D. K. Shukla, M. P Saravanan, Deepshikha Jaiswal-Nagar, Vinayak B. Kamble","In this paper, we investigated the low-temperature lattice dynamics in two
GeTe crystals with varying Ge defect stoichiometry. The X-ray Diffraction (XRD)
of the as-cleaved ingots indicate that the orientation is mainly along the h0l
direction. From the Raman spectra, a comparison of the linewidth variation with
temperature for the in-plane (E-mode) vibrations reveals a subtle enhancement
around 170 K for the less stoichiometric crystal, depicting a more anharmonic
nature, via the 4-phonon scattering processes. Furthermore, a comparison of the
out-of-plane A_T^1 mode indicates a sensitivity of a weaker Raman signal (
about 239 cm -1) from disordered GeTe4 tetrahedra that has adversely affected
the mode dynamics in the less stoichiometric sample (S1). However, this weaker
signal is not observed for the more stoichiometric sample (S2) below 200 K. The
Machine Learned Molecular Dynamics (MLMD) simulations performed to calculate
the phonon spectral densities reveal that the heavier atom, Te dominate below
100 cm-1, while, the lighter Ge has more significant contribution above 100
cm-1. Thus, the change observed only in the 120 cm-1 (A_T^1) mode is justified
by defects at the Ge sites. Specific heat capacity measurements are performed
that show a broad hump near 14 K, when plotted as Cp/T^3 versus T indicative of
a non-Debye nature. Hence, considering the two optical modes in the Raman
spectra, a Debye and two-Einstein modes model is conceptualized to explain the
low-temperature specific heat. These calculations reveal a softer bonding
vis-a-vis lowering of Debye temperature in S1. Lower Einstein temperatures are
also observed in S1, which is attributed to the easy activation of these
localized modes that affect the harmonicity of the lattice. Finally, the
low-temperature resistivity measurements reveal a reduction in the effective
phonon frequency (w_e) through the estimation of Te.",http://arxiv.org/abs/2502.10745v1
"Developing Conversational Speech Systems for Robots to Detect Speech
  Biomarkers of Cognition in People Living with Dementia",2025-02-15T20:25:58Z,"Rohith Perumandla, Young-Ho Bae, Diego Izaguirre, Esther Hwang, Andrew Murphy, Long-Jing Hsu, Selma Sabanovic, Casey C. Bennett","This study presents the development and testing of a conversational speech
system designed for robots to detect speech biomarkers indicative of cognitive
impairments in people living with dementia (PLwD). The system integrates a
backend Python WebSocket server and a central core module with a large language
model (LLM) fine-tuned for dementia to process user input and generate robotic
conversation responses in real-time in less than 1.5 seconds. The frontend user
interface, a Progressive Web App (PWA), displays information and biomarker
score graphs on a smartphone in real-time to human users (PLwD, caregivers,
clinicians). Six speech biomarkers based on the existing literature - Altered
Grammar, Pragmatic Impairments, Anomia, Disrupted Turn-Taking, Slurred
Pronunciation, and Prosody Changes - were developed for the robot conversation
system using two datasets, one that included conversations of PLwD with a human
clinician (DementiaBank dataset) and one that included conversations of PLwD
with a robot (Indiana dataset). We also created a composite speech biomarker
that combined all six individual biomarkers into a single score. The speech
system's performance was first evaluated on the DementiaBank dataset showing
moderate correlation with MMSE scores, with the composite biomarker score
outperforming individual biomarkers. Analysis of the Indiana dataset revealed
higher and more variable biomarker scores, suggesting potential differences due
to study populations (e.g. severity of dementia) and the conversational
scenario (human-robot conversations are different from human-human). The
findings underscore the need for further research on the impact of
conversational scenarios on speech biomarkers and the potential clinical
applications of robotic speech systems.",http://arxiv.org/abs/2502.10896v1
"Systematic study of the composition of Type I X-ray burst ashes: Neutron
  star structure v.s. Reaction rate uncertainties",2025-02-16T04:42:43Z,"Guoqing Zhen, Helei Liu, Akira Dohi, Guoliang Lü, Nobuya Nishimura, Chunhua Zhu, Renxin Xu","In this study, we calculate for the first time the impacts of neutron
star(NS) structure on the type I X-ray burst ashes using the \texttt{MESA}
code. We find an increased mass fraction of the heavier elements with
increasing surface gravity (increase mass or decrease radius), resulting in a
higher average mass number ($A_{\rm ash}$) of burst ashes (except for higher
mass NS due to the competition between the envelope temperature and the
recurrence time). The burst strength ($\alpha$) increases as surface gravity
increases, which indicates the positive correlation between $A_{\rm ash}$ and
$\alpha$ with changes in surface gravity. If the $\alpha$ value is higher,
heavier $p$-nuclei should be produced by the type I X-ray burst
nucleosynthesis. Besides, the effects of various burst input parameters, e.g.
base heating ($Q_{\rm b}$), metallicity ($Z$) and some new reaction rates are
calculated for comparison. We find that the heavier nuclei synthesis is
inversely correlated to the base heating/metallicity, the smaller the base
heating/metallicity, the greater the mass fraction of the heavier elements. The
$\alpha$ value decreases as $Q_{\rm b}$ or $Z$ decreases, which also indicates
the positive correlation between $A_{\rm ash}$ and $\alpha$ with variation in
$Q_{\rm b}$ or $Z$. The new reaction rates from the $(p,\gamma)$ reactions on
$^{17}\rm{F}$, $^{19}\rm{F}$, $^{26}\rm{P}$, $^{56}\rm{Cu}$, $^{65}\rm{As}$,
and $(\alpha,p)$ reaction on $^{22}\rm{Mg}$ have only minimal effects on burst
ashes. In hydrogen-rich X-ray binary systems, nuclei heavier than
$^{64}\rm{Ge}$ are fertile produced with larger NS mass, smaller NS radius,
smaller base heating and smaller metallicity.",http://arxiv.org/abs/2502.10992v1
"Anisotropic Schottky-barrier-height in high-symmetry 2D WSe$_2$:
  Momentum-space anisotropy",2025-02-16T06:11:48Z,"Nuo Xu, Xiao-Lin Zhao, Meng-Xue Ren, Ke-Xin Hou, Xiao-huan Lv, Rui-Ning Wang, Xing-Qiang Shi, Jiang-Long Wang","It is usually supposed that only low-symmetry two-dimensional (2D) materials
exhibit anisotropy, here we show that high-symmetry 2D semiconductors can show
significant anisotropy in momentum space due to the band structure anisotropy
in k-space. The basic reason is that different k-points in the Brillouin zone
have different symmetry. Using 2D semiconductor WSe$_2$ as the example, we
construct lateral heterostructures with zigzag and armchair connections to 2D
metal NbSe$_2$, and the electronic structure and contact characteristics of
these two connections are analyzed. It is found that both connections exhibit
p-type Schottky barrier height (SBH) but the sizes of SBH are very different
(of 0.03 eV and 0.50 eV), mainly because the band-edge energies of WSe$_2$ are
different along the two mutually perpendicular directions in momentum space.
There are two factors contributing to the SBH anisotropy: one is the different
interface structure and the other is the band edge anisotropy of the 2D
semiconductor WSe$_2$. Since the two interface structures give only a
difference in interface potential change by less than 0.1 eV, the SBH variation
of ~0.47 eV is mainly from the band structure anisotropy in momentum-space. So,
high-symmetry 2D materials may exhibit highly anisotropic electronic states in
momentum space and this affects the transport properties. Our current work
extends the research field of 2D material anisotropy to 2D materials with high
real-space symmetry, thus greatly expands the candidate materials for
anisotropic studies and provides new guidance for optimizing the performance of
2D material devices via controlling transport directions.",http://arxiv.org/abs/2502.11005v1
"New perspectives on MASCARA-1b: A combined analysis of pre- and
  post-eclipse emission data using CRIRES+",2025-02-16T15:59:21Z,"Swaetha Ramkumar, Neale P. Gibson, Stevanus K. Nugroho, Mark Fortune, Cathal Maguire","We present high-resolution emission spectroscopy observations of the
ultra-hot Jupiter MASCARA-1b with CRIRES+ in the K-band, covering the
post-eclipse phases of its orbit. These observations complement previously
published pre-eclipse data. The stellar and telluric features were removed
using SysRem, and the planetary signal was analysed with the cross-correlation
technique. After confirming the presence of chemical species in our atmospheric
model, we combined the pre- and post-eclipse datasets for a joint analysis. By
employing a Bayesian retrieval framework, this joint retrieval enabled us to
constrain the spatially varying temperature-pressure (T-P) profile and
atmospheric carbon-to-oxygen (C/O) ratio. We detected strong emission
signatures of CO and H$_2$O in the post-eclipse and combined datasets. While a
well-mixed retrieval model results in a super-solar C/O, allowing for
vertically varying chemistry yields C/O values consistent with solar. The
retrieved parameters are not only consistent across the datasets but also
across different chemical regimes. We did not identify any significant velocity
shifts between the detected species or across the datasets, which could
otherwise serve as proxies for possible atmospheric dynamics. We also explored
phase dependence through the model scaling factor and found no substantial
changes in atmospheric properties throughout the observed phases. Due to strong
degeneracies between the temperature gradient and chemical abundances, our
retrieved temperatures are broadly consistent with either a full redistribution
of heat or strong day-night contrasts. While this complicates direct
comparisons with recent Spitzer phase curve analyses suggesting inefficient
recirculation, we find no clear evidence of spatial variation in the chemical
or temperature structure of MASCARA-1b from pre- to post-eclipse, nor temporal
variation over $\approx$2 years.",http://arxiv.org/abs/2502.11180v1
"Evidence for an accretion bridge in the DX Cha circumbinary system from
  VLTI/MATISSE observations",2025-02-17T12:10:14Z,"Tímea Juhász, József Varga, Péter Ábrahám, Ágnes Kóspál, Foteini Lykou, Lei Chen, Attila Moór, Fernando Cruz-Sáenz de Miera, Bruno Lopez, Alexis Matter, Roy van Boekel, Michiel Hogerheijde, Margaux Abello, Jean-Charles Augereau, Paul Boley, William C. Danchi, Thomas Henning, Mathis Letessier, Jie Ma, Philippe Priolet, Marten Scheuck, Gerd Weigelt, Sebastian Wolf","DX Cha (HD 104237) is a spectroscopic binary consisting of a Herbig
A7.5Ve-A8Ve primary star and a K3-type companion. Here we report on new $3.55$
micrometer interferometric observations of this source with the Multi Aperture
Mid-Infrared Spectroscopic Experiment (MATISSE) at the Very Large Telescope
Interferometer (VLTI). To model the four MATISSE observations obtained between
2020 and 2023, we constructed a time-dependent interferometric model of the
system, using the oimodeler software. The model consists of an asymmetric ring
and two point sources on a Keplerian orbit. Our best-fit model consists of a
circumbinary ring with a diameter of $0.86$ au ($8.1$ mas), featuring a strong
azimuthal asymmetry. We found that the position angle of the asymmetry changes
tens of degrees between the MATISSE epochs. The ring is relatively narrow, with
a full width at half maximum (FWHM) of $\sim$$0.13$ au ($1.23$ mas). The
presence of circumstellar dust emission so close to the binary is unexpected,
as previous hydrodynamic simulations predicted an inner disk cavity with a
diameter of $\sim$$4$ au ($\sim$$37.5$ mas). Thus, we argue that the narrow
envelope of material we detected is probably not a gravitationally stable
circumbinary ring, but may be part of tidal accretion streamers channeling
material from the inner edge of the disk toward the stars.",http://arxiv.org/abs/2502.11722v1
"Coupled Ising-Potts Model: Rich Sets of Critical Temperatures and
  Translation-Invariant Gibbs Measures",2025-02-17T16:49:46Z,"F. H. Haydarov, B. A. Omirov, U. A. Rozikov","We consider a coupled Ising-Potts model on Cayley trees of order $ k \geq 2
$. This model involves spin vectors $ (s, \sigma) $, and generalizes both the
Ising and Potts models by incorporating interactions between two types of
spins: $s = \pm 1$ and $\sigma = 1, \dots, q$. It is applicable to a wide range
of systems, including multicomponent alloys, spin glasses, biological systems,
networks, and social models.
  In this paper, we find some translation-invariant splitting Gibbs measures
(TISGMs) and show, for $k\geq 2$, that at sufficiently low temperatures, the
number of such measures is at least $2^{q}+1$. This is not an exact upper
bound; for $k=2$ and $q=5$, we demonstrate that the number of TISGMs reaches
the exact bound of 335, which is much larger than $2^5+1=33$. We prove, for
$q=5$ that there are 12 critical temperatures at which the number of TISGMs
changes, and we provide the exact number of TISGMs for each intermediate
temperature. Additionally, we identify temperature regions where three TISGMs,
close to the free measure, are either extreme or non-extreme among all Gibbs
measures.
  We also show that the coupled Ising-Potts model exhibits properties absent in
the individual Ising and Potts models. In particular, we observe the following
new phenomena:
  1. In both the Ising and Potts models, if a Gibbs measure exists at some
temperature $T_0$, then it exists for all $T<T_0$. However, in the coupled
Ising-Potts model, some TISGMs may only exist at intermediate temperatures
(neither very low nor very high).
  2. The 5-state Potts model has three critical temperatures and up to 31
TISGMs. We show that for $q=5$, the coupled Ising-Potts model has four times as
many critical temperatures and approximately 11 times as many TISGMs. Thus, our
model modifies the phase structure more rapidly and exhibits a significantly
richer class of splitting Gibbs measures.",http://arxiv.org/abs/2502.12014v1
"AnyTouch: Learning Unified Static-Dynamic Representation across Multiple
  Visuo-tactile Sensors",2025-02-15T08:33:25Z,"Ruoxuan Feng, Jiangyu Hu, Wenke Xia, Tianci Gao, Ao Shen, Yuhao Sun, Bin Fang, Di Hu","Visuo-tactile sensors aim to emulate human tactile perception, enabling
robots to precisely understand and manipulate objects. Over time, numerous
meticulously designed visuo-tactile sensors have been integrated into robotic
systems, aiding in completing various tasks. However, the distinct data
characteristics of these low-standardized visuo-tactile sensors hinder the
establishment of a powerful tactile perception system. We consider that the key
to addressing this issue lies in learning unified multi-sensor representations,
thereby integrating the sensors and promoting tactile knowledge transfer
between them. To achieve unified representation of this nature, we introduce
TacQuad, an aligned multi-modal multi-sensor tactile dataset from four
different visuo-tactile sensors, which enables the explicit integration of
various sensors. Recognizing that humans perceive the physical environment by
acquiring diverse tactile information such as texture and pressure changes, we
further propose to learn unified multi-sensor representations from both static
and dynamic perspectives. By integrating tactile images and videos, we present
AnyTouch, a unified static-dynamic multi-sensor representation learning
framework with a multi-level structure, aimed at both enhancing comprehensive
perceptual abilities and enabling effective cross-sensor transfer. This
multi-level architecture captures pixel-level details from tactile data via
masked modeling and enhances perception and transferability by learning
semantic-level sensor-agnostic features through multi-modal alignment and
cross-sensor matching. We provide a comprehensive analysis of multi-sensor
transferability, and validate our method on various datasets and in the
real-world pouring task. Experimental results show that our method outperforms
existing methods, exhibits outstanding static and dynamic perception
capabilities across various sensors.",http://arxiv.org/abs/2502.12191v1
"Improved constraints on the Faraday rotation towards eight fast radio
  bursts using dense grids of polarized radio galaxies",2025-02-17T19:03:31Z,"Ayush Pandhi, Bryan M. Gaensler, Ziggy Pleunis, Sebastian Hutschenreuter, Casey Law, Ryan Mckinven, Shane P. O'Sullivan, Emily B. Petroff, Tessa Vernstrom","We present 2-4 GHz observations of polarized radio galaxies towards eight
fast radio bursts (FRBs), producing grids of Faraday rotation measure (RM)
sources with sky densities of 9-28 polarized sources per square degree. Using a
Bayesian interpolation framework, we constrain Galactic RM fluctuations below ~
1 degree squared angular scales around the FRB positions. Despite the positions
of all eight FRBs far from the Galactic plane, we constrain previously
unresolved small-scale Galactic RM structures around six of the eight FRBs. In
two of these fields, we find potential changes in the sign of the Galactic RM
that are not captured by previous, sparsely sampled RM grid observations. Our
Galactic RM estimate towards the FRBs differs between a few rad m^-2 up to ~ 40
rad m^-2 from the all-sky Galactic RM map of Hutschenreuter et al. (2022).
Extrapolating our results to the known population of polarized FRB sources, we
may be incorrectly interpreting the host galaxy RM for ~ 30% of the FRB source
population with current RM grid observations. Measuring small-scale Galactic RM
variations is crucial for identifying FRBs in low density and weakly magnetized
environments, which in turn could serve as potent probes of cosmic magnetism.
This framework of reconstructing continuous Galactic RM structure from RM grid
observations can be readily applied to FRBs that fall in the sky coverage of
upcoming large-sky radio polarization surveys of radio galaxies, such as the
Very Large Array Sky Survey (VLASS) and the Polarization Sky Survey of the
Universe's Magnetism (POSSUM).",http://arxiv.org/abs/2502.12263v1
Intelligent Soft Matter: Towards Embodied Intelligence,2025-02-18T19:02:47Z,"Vladimir A. Baulin, Achille Giacometti, Dmitry Fedosov, Stephen Ebbens, Nydia R. Varela-Rosales, Neus Feliu, Mithun Chowdhury, Minghan Hu, Rudolf Füchslin, Marjolein Dijkstra, Matan Mussel, René van Roij, Dong Xie, Vassil Tzanov, Mengjie Zu, Samuel Hidalgo-Caballero, Ye Yuan, Luca Cocconi, Cheol-Min Ghim, Cécile Cottin-Bizonne, M. Carmen Miguel, Maria Jose Esplandiu, Juliane Simmchen, Wolfgang J. Parak, Marco Werner, Gerhard Gompper, Martin M. Hanczyc","Intelligent soft matter stands at the intersection of materials science,
physics, and cognitive science, promising to change how we design and interact
with materials. This transformative field seeks to create materials that
possess life-like capabilities, such as perception, learning, memory, and
adaptive behavior. Unlike traditional materials, which typically perform static
or predefined functions, intelligent soft matter dynamically interacts with its
environment. It integrates multiple sensory inputs, retains experiences, and
makes decisions to optimize its responses. Inspired by biological systems,
these materials intend to leverage the inherent properties of soft matter:
flexibility, self-evolving, and responsiveness to perform functions that mimic
cognitive processes. By synthesizing current research trends and projecting
their evolution, we present a forward-looking perspective on how intelligent
soft matter could be constructed, with the aim of inspiring innovations in
fields such as biomedical devices, adaptive robotics, and beyond. We highlight
new pathways for integrating design of sensing, memory and action with internal
low-power operations and discuss challenges for practical implementation of
materials with ""intelligent behavior"". These approaches outline a path towards
to more robust, versatile and scalable materials that can potentially act,
compute, and ""think"" by their inherent intrinsic material behaviour beyond
traditional smart technologies relying on external control.",http://arxiv.org/abs/2502.13224v1
"Evidence for Variable Accretion onto PDS 70 c and Implications for
  Protoplanet Detections",2025-02-19T19:00:00Z,"Yifan Zhou, Brendan P. Bowler, Aniket Sanghi, Gabriel-Dominique Marleau, Shinsuke Takasao, Yuhiko Aoyama, Yasuhiro Hasegawa, Thanawuth Thanathibodee, Taichi Uyama, Jun Hashimoto, Kevin Wagner, Nuria Calvet, Dorian Demars, Ya-Lin Wu, Lauren I. Biddle, Sebastiaan Haffert, Marta L. Bryan","Understanding the processes of planet formation and accretion in young
systems is essential to unraveling the initial conditions of planetary systems.
The PDS 70 system, which hosts two directly imaged protoplanets, provides a
unique laboratory for studying these phenomena, particularly through H-alpha
emission a commonly used accretion tracer. We present multi-epoch observations
and examine the variability in accretion signatures within this system,
focusing on PDS 70 b and c. Using Hubble Space Telescope narrowband H-alpha
imaging from 2020 and 2024, we achieve high signal-to-noise ratio detections of
these planets and reveal significant changes in H-alpha flux. For PDS 70 c, the
H-alpha flux more than doubled between 2020 and 2024. The trend is consistent
with the one identified in recently published MagAO-X data, further confirming
that PDS 70 c has become significantly brighter in H between 2023 March and
2024 May. The observed variability suggests dynamic accretion processes,
possibly modulated by circumplanetary disk properties or transient accretion
bursts. High-amplitude variability in PDS 70 c motivates simultaneous
monitoring of multiple accretion tracers to probe the mechanisms of mass growth
of gas giant planets. We quantify the impact of variability on the
detectability of protoplanets in imaging surveys and emphasize the need for
continued and regular monitoring to accurately assess the occurrence and
characteristics of young, forming planets.",http://arxiv.org/abs/2502.14024v1
Triad: Vision Foundation Model for 3D Magnetic Resonance Imaging,2025-02-19T19:31:52Z,"Shansong Wang, Mojtaba Safari, Qiang Li, Chih-Wei Chang, Richard LJ Qiu, Justin Roper, David S. Yu, Xiaofeng Yang","Vision foundation models (VFMs) are pre-trained on extensive image datasets
to learn general representations for diverse types of data. These models can
subsequently be fine-tuned for specific downstream tasks, significantly
boosting performance across a broad range of applications. However, existing
vision foundation models that claim to be applicable to various radiology tasks
are mostly pre-trained on 3D computed tomography (CT), which benefits from the
availability of extensive 3D CT databases. Significant differences between CT
and magnetic resonance imaging (MRI) in imaging principles, signal
characteristics, and data distribution may hinder their practical performance
and versatility in MRI-specific applications. Here, we propose Triad, a vision
foundation model for 3D MRI. Triad adopts a widely used autoencoder
architecture to learn robust representations from 131,170 3D MRI volumes and
uses organ-independent imaging descriptions to constrain the semantic
distribution of the visual modality. The above pre-training dataset is called
Triad-131K, which is currently the largest 3D MRI pre-training dataset. We
evaluate Triad across three tasks, namely, organ/tumor segmentation,
organ/cancer classification, and medical image registration, in two data
modalities (within-domain and out-of-domain) settings using 25 downstream
datasets. By initializing models with Triad's pre-trained weights, nnUNet-Triad
improves segmentation performance by 6.88% compared to nnUNet-Scratch across 17
datasets. Swin-B-Triad achieves a 3.97% improvement over Swin-B-Scratch in
classification tasks across five datasets. SwinUNETR-Triad improves by 4.00%
compared to SwinUNETR-Scratch in registration tasks across two datasets. Our
study demonstrates that pre-training can maximize performance when the data
modalities and organs of upstream and downstream tasks are consistent.",http://arxiv.org/abs/2502.14064v1
"Moiré-Tunable Localization of Simultaneous Type I and Type II Band
  Alignment in a MoSe2/WS2 Heterobilayer",2025-02-19T22:53:18Z,"Jiaxuan Guo, Zachary H. Withers, Ziling Li, Bowen Hou, Alexander Adler, Jianwei Ding, Victor Chang Lee, Roland K. Kawakami, Gerd Schönhense, Alice Kunin, Thomas K. Allison, Diana Y. Qiu","Moir\'e heterobilayers exhibiting spatially varying band alignment and
electron and hole localization that can be precisely controlled through the
twist angle have emerged as exciting platforms for studying complex quantum
phenomena. While most heterobilayers of transition metal dichalcogenides (TMDs)
have a type II band alignment, the introduction of type I band alignment could
enable stronger light-matter coupling and enhanced radiative emission. Here, we
show through a combination of first-principles GW plus Bethe Salpeter equation
(GW-BSE) calculations and time- and angle-resolved photoemission spectroscopy
(tr-ARPES) measurements that contrary to previous understanding, the MoSe2/WS2
heterobilayer has a type I band alignment at large twist angles and
simultaneous regions of type I and type II band alignment due to the structural
reconstruction in different high symmetry regions at small twist angles. In
tr-ARPES, consistent with our calculations, a long-lived electron population is
only observed in MoSe2 for samples with large twist angles, while in samples
with small twist angles, signals from two distinct long-lived excitons are
observed. Moreover, despite the near degeneracy of the conduction bands of the
two layers, no excitonic hybridization occurs, suggesting that previously
observed absorption peaks in this material arise from lattice reconstruction.
Our findings clarify the complex energy landscape in MoSe2/WS2
heterostructures, where the coexistence of type I and type II band alignment
opens the door to moir\'e-tunable optoelectronic devices with intrinsic lateral
heterojunctions.",http://arxiv.org/abs/2502.14138v1
"Ultrathin Ga$_2$O$_3$ Tunneling Contact for 2D Transition-metal
  Dichalcogenides Transistor",2025-02-20T01:19:17Z,"Yun Li, Tinghe Yun, Bohan Wei, Haoran Mu, Luojun Du, Nan Cui, Guangyu Zhang, Shenghuang Lin","The development of two-dimensional (2D) transition metal dichalcogenides
(TMDs) based transistors has been constrained by high contact resistance and
inadequate current delivery, primarily stemming from metal-induced gap states
and Fermi level pinning. Research into addressing these challenges is essential
for the advancing 2D transistors from laboratory experiments to
industrial-grade production. In this work, we present amorphous Ga$_2$O$_3$ as
a novel tunneling contact layer for multilayer WS2-based field-effect
transistors (FETs) to enhance electrical performance. The addition of this
innovative tunneling layer avoid Schottky barrier forming while finally change
into a tunneling barrier with the barrier height to just 3.7 meV, near-ideal
ohmic contacts. This approach effectively reduces contact resistance to only
2.38 k$\Omega\,\mu$m and specific contact resistivity as low as $3 \times
10^{-5}$ $\Omega$cm$^2$. A record-high electron mobility of 296 cm$^2$ V$^{-1}$
s$^{-1}$ and ON-OFF ratio over 106 are realized for WS$_2$ transistor at room
temperature. Compared to other tunneling materials, ultrathin Ga$_2$O$_3$ layer
offers scalability, cost-efficient production and broad substrate
compatibility, making it well-suited for seamless integration with industrial
wafer-scale electronics. A robust device performance remains highly consistent
in a large-scale transistor array fabricated on $1.5\times 1.5$ cm$^2$ chips,
with the average mobility closing to 200 cm$^2$ V$^{-1}$ s$^{-1}$. These
findings establish a new benchmark for contact performance in 2D transistors
and prove the potential of tunneling contact engineering in advancing
high-performance, scalable 29 pelectronics with promising applications in
quantum computing and communication.",http://arxiv.org/abs/2502.14181v1
"DAG: Deep Adaptive and Generative $K$-Free Community Detection on
  Attributed Graphs",2025-02-20T06:15:16Z,"Chang Liu, Yuwen Yang, Yue Ding, Hongtao Lu, Wenqing Lin, Ziming Wu, Wendong Bi","Community detection on attributed graphs with rich semantic and topological
information offers great potential for real-world network analysis, especially
user matching in online games. Graph Neural Networks (GNNs) have recently
enabled Deep Graph Clustering (DGC) methods to learn cluster assignments from
semantic and topological information. However, their success depends on the
prior knowledge related to the number of communities $K$, which is unrealistic
due to the high costs and privacy issues of acquisition.In this paper, we
investigate the community detection problem without prior $K$, referred to as
$K$-Free Community Detection problem. To address this problem, we propose a
novel Deep Adaptive and Generative model~(DAG) for community detection without
specifying the prior $K$. DAG consists of three key components, \textit{i.e.,}
a node representation learning module with masked attribute reconstruction, a
community affiliation readout module, and a community number search module with
group sparsity. These components enable DAG to convert the process of
non-differentiable grid search for the community number, \textit{i.e.,} a
discrete hyperparameter in existing DGC methods, into a differentiable learning
process. In such a way, DAG can simultaneously perform community detection and
community number search end-to-end. To alleviate the cost of acquiring
community labels in real-world applications, we design a new metric, EDGE, to
evaluate community detection methods even when the labels are not feasible.
Extensive offline experiments on five public datasets and a real-world online
mobile game dataset demonstrate the superiority of our DAG over the existing
state-of-the-art (SOTA) methods. DAG has a relative increase of 7.35\% in teams
in a Tencent online game compared with the best competitor.",http://arxiv.org/abs/2502.14294v1
"A possible overall scenario for the outburst evolution of MAXI J1820+070
  revealed by Insight-HXMT",2025-02-20T12:35:13Z,"J. Q. Peng, S. Zhang, Y. P. Chen, L. D. Kong, P. J. Wang, S. N. Zhang, L. Ji, L. Tao, J. L. Qu, M. Y. Ge, Q. C. Shui, J. Li, Z. Chang, Z. S. Li, Y. X. Xiao","We study the spectral and temporal properties of the black hole X-ray
transient binary MAXI J1820+070 during the 2018 outburst with Insight-HXMT
observations. The outburst of MAXI J1820+070 can be divided into three
intervals. For the two intervals of the outburst, we find that low-energy
(below 140 keV) photos lag high-energy (140-170 keV) ones, while in the decay
of the outburst, high-energy photons lag low-energy photons, both with a time
scale of the order of days. Based on these results, the canonical hysteresis
effect of the 'q' shape in the hardness-intensity diagram can be reformed into
a roughly linear shape by taking into account the lag corrections between
different energy bands. Time analysis shows that the high-frequency break of
hard X-rays, derived from the power density spectrum of the first interval of
the outburst is, in general, larger and more variable than that of soft X-rays.
The spectral fitting shows that the coverage fraction of the hard X-rays drops
sharply at the beginning of the outburst to around 0.5, then increases
slightly. The coverage fraction drops to roughly zero once the source steps
into a soft state and increases gradually to unity when the source returns to a
low hard state. We discuss the possible overall evolution scenario of corona
hinted from these discoveries.",http://arxiv.org/abs/2502.14508v1
"MOJAVE -- XXII. Brightness temperature distributions and geometric
  profiles along parsec-scale AGN jets",2025-02-20T12:39:49Z,"E. V. Kravchenko, I. N. Pashchenko, D. C. Homan, Y. Y. Kovalev, M. L. Lister, A. B. Pushkarev, E. Ros, T. Savolainen","Radial gradients of the brightness temperatures along the parsec-scale jets
of Active Galactic Nuclei (AGN) can be used to infer the energy balance and to
estimate the parameter range of physical conditions in these regions. In this
paper, we present a detailed study of the brightness temperature gradients and
geometry profiles of relativistic jets of 447 AGN based on 15 GHz Very Long
Baseline Array observations performed between 1994 and 2019. We used models of
the jet structure using two-dimensional Gaussian components and analysed
variations in their brightness temperatures and sizes along the jets. The size
of the jet components, R, increases with projected distance from the jet base,
r, as $R\propto r^{1.02\pm0.03}$, i.e., typically following a conically
expanding streamline and therefore indicating that the size of jet components
is a good tracer of jet geometry. The brightness temperature gradients along
the jets typically follow a power-law $T_\mathrm{b} \propto r^{-2.82\pm0.07}$.
Half of the sample sources show non-monotonic R(r) or Tb(r) profiles and their
distributions were characterised by a double power-law model. We found at least
six scenarios to explain the enhancement of the brightness temperature by a
presence of inhomogeneities (shocks, jet recollimation) or curvature effects
(helical structures, helical magnetic field, non-radial motion, bent jets). Our
results are consistent with the scenario that the jet features can be
simplified as optically thin moving blobs. In the sources demonstrating
transition from a conical to parabolic jet shape, the gradient of the Tb(R)
changes at the position of the break consistent with the model of
magneto-hydrodynamic acceleration.",http://arxiv.org/abs/2502.14516v1
"Nonequilibrium Universality of Rydberg-Excitation Spreading on a Dynamic
  Network",2025-02-20T17:31:37Z,"Simon Ohler, Daniel Brady, Patrick Mischke, Jana Bender, Herwig Ott, Thomas Niederprüm, Winfried Ripken, Johannes S. Otterbach, Michael Fleischhauer","Understanding the universal properties of non-equilibrium phase transitions
of spreading processes is a challenging problem. This applies in particular to
irregular and dynamically varying networks. We here investigate an
experimentally accessible model system for such processes, namely the
absorbing-state phase transition (ASPT) of Rydberg-excitation spreading, known
as Rydberg facilitation, in a laser-driven gas of mobile atoms. It occurs on an
irregular graph, set by the random atom positions in the gas and, depending on
temperature, changes its character from static to dynamic. By studying the
behavior of the order parameter in [Phys. Rev. Lett. 133, 173401 (2024)] we
showed numerical evidence for a crossover from directed percolation (DP)
universality through various phases of anomalous directed percolation (ADP) to
mean-field (MF) behavior when the temperature of the gas is increased. As the
behavior of the order parameter is not sufficient to uniquely determine the
universality class, we here analyze the distribution of avalanches -
characteristic of non-equilibrium critical behavior - to fully characterize the
ASPT. Performing extended numerical calculations and experiments on a cold
$^{87}$Rb atom gas we confirm our earlier numerical findings and our
phenomenological model that maps the dynamic network to a static one with
power-law tails of the distribution of excitation distances. Furthermore we
discuss the influence of dissipation, present in the experiment and a necessary
ingredient for the self-organization of the system to the critical point. In
particular we study the potential modification of the universality class by
losses as a function of dissipation strength.",http://arxiv.org/abs/2502.14757v1
Tracking and Assigning Jobs to a Markov Machine,2025-02-20T18:04:09Z,"Subhankar Banerjee, Sennur Ulukus","We consider a time-slotted communication system with a machine, a cloud
server, and a sampler. Job requests from the users are queued on the server to
be completed by the machine. The machine has two states, namely, a busy state
and a free state. The server can assign a job to the machine in a
first-in-first-served manner. If the machine is free, it completes the job
request from the server; otherwise, it drops the request. Upon dropping a job
request, the server is penalized. When the machine is in the free state, the
machine can get into the busy state with an internal job. When the server does
not assign a job request to the machine, the state of the machine evolves as a
symmetric Markov chain. If the machine successfully accepts the job request
from the server, the state of the machine goes to the busy state and follows a
different dynamics compared to the dynamics when the machine goes to the busy
state due to an internal job. The sampler samples the state of the machine and
sends it to the server via an error-free channel. Thus, the server can estimate
the state of the machine, upon receiving an update from the source. If the
machine is in the free state but the estimated state at the server is busy, the
sampler pays a cost. We incorporate the concept of the age of incorrect
information to model the cost of the sampler. We aim to find an optimal
sampling policy such that the cost of the sampler plus the penalty on the
machine gets minimized. We formulate this problem in a Markov decision process
framework and find how an optimal policy changes with several associated
parameters. We show that a threshold policy is optimal for this problem. We
show a necessary and sufficient condition for a threshold policy to be optimal.
Finally, we find the optimal threshold without bounding the state space.",http://arxiv.org/abs/2502.14783v1
"Femtosecond temperature measurements of laser-shocked copper deduced
  from the intensity of the x-ray thermal diffuse scattering",2025-01-06T11:26:29Z,"J. S. Wark, D. J. Peake, T. Stevens, P. G. Heighway, Y. Ping, P. Sterne, B. Albertazzi, S. J. Ali, L. Antonelli, M. R. Armstrong, C. Baehtz, O. B. Ball, S. Banerjee, A. B. Belonoshko, C. A. Bolme, V. Bouffetier, R. Briggs, K. Buakor, T. Butcher, S. Di Dio Cafiso, V. Cerantola, J. Chantel, A. Di Cicco, A. L. Coleman, J. Collier, G. Collins, A. J. Comley, F. Coppari, T. E. Cowan, G. Cristoforetti, H. Cynn, A. Descamps, F. Dorchies, M. J. Duff, A. Dwivedi, C. Edwards, J. H. Eggert, D. Errandonea, G. Fiquet, E. Galtier, A. Laso Garcia, H. Ginestet, L. Gizzi, A. Gleason, S. Goede, J. M. Gonzalez, M. G. Gorman, M. Harmand, N. Hartley, C. Hernandez-Gomez, A. Higginbotham, H. Höppner, O. S. Humphries, R. J. Husband, T. M. Hutchinson, H. Hwang, D. A. Keen, J. Kim, P. Koester, Z. Konopkova, D. Kraus, A. Krygier, L. Labate, A. E. Lazicki, Y. Lee, H-P. Liermann, P. Mason, M. Masruri, B. Massani, E. E. McBride, C. McGuire, J. D. McHardy, D. McGonegle, R. S. McWilliams, S. Merkel, G. Morard, B. Nagler, M. Nakatsutsumi, K. Nguyen-Cong, A-M. Norton, I. I. Oleynik, C. Otzen, N. Ozaki, S. Pandolfi, A. Pelka, K. A. Pereira, J. P. Phillips, C. Prescher, T. Preston, L. Randolph, D. Ranjan, A. Ravasio, R. Redmer, J. Rips, D. Santamaria-Perez, D. J. Savage, M. Schoelmerich, J-P. Schwinkendorf, S. Singh, J. Smith, R. F. Smith, A. Sollier, J. Spear, C. Spindloe, M. Stevenson, C. Strohm, T-A. Suer, M. Tang, M. Toncian, T. Toncian, S. J. Tracy, A. Trapananti, T. Tschentscher, M. Tyldesley, C. E. Vennari, T. Vinci, S. C. Vogel, T. J. Volz, J. Vorberger, J. T. Willman, L. Wollenweber, U. Zastrau, E. Brambrink, K. Appel, M. I. McMahon","We present 50-fs, single-shot measurements of the x-ray thermal diffuse
scattering (TDS) from copper foils that have been shocked via nanosecond
laser-ablation up to pressures above 135~GPa. We hence deduce the x-ray
Debye-Waller (DW) factor, providing a temperature measurement. The targets were
laser-shocked with the DiPOLE 100-X laser at the High Energy Density (HED)
endstation of the European X-ray Free-Electron Laser (EuXFEL). Single x-ray
pulses, with a photon energy of 18 keV, were scattered from the samples and
recorded on Varex detectors. Despite the targets being highly textured (as
evinced by large variations in the elastic scattering), and with such texture
changing upon compression, the absolute intensity of the azimuthally averaged
inelastic TDS between the Bragg peaks is largely insensitive to these changes,
and, allowing for both Compton scattering and the low-level scattering from a
sacrificial ablator layer, provides a reliable measurement of $T/\Theta_D^2$,
where $\Theta_D$ is the Debye temperature. We compare our results with the
predictions of the SESAME 3336 and LEOS 290 equations of state for copper, and
find good agreement within experimental errors. We thus demonstrate that
single-shot temperature measurements of dynamically compressed materials can be
made via thermal diffuse scattering of XFEL radation.",http://arxiv.org/abs/2501.02940v1
"Dark Energy Survey Year 6 Results: Cell-based Coadds and Metadetection
  Weak Lensing Shape Catalogue",2025-01-10T02:32:15Z,"M. Yamamoto, M. R. Becker, E. Sheldon, M. Jarvis, R. A. Gruendl, F. Menanteau, E. S. Rykoff, S. Mau, T. Schutt, M. Gatti, M. A. Troxel, A. Amon, D. Anbajagane, G. M. Bernstein, D. Gruen, E. M. Huff, M. Tabbutt, A. Tong, B. Yanny, T. M. C. Abbott, M. Aguena, A. Alarcon, F. Andrade-Oliveira, K. Bechtol, J. Blazek, D. Brooks, A. Carnero Rosell, J. Carretero, C. Chang, A. Choi, M. Costanzi, M. Crocce, L. N. da Costa, T. M. Davis, J. De Vicente, S. Desai, H. T. Diehl, S. Dodelson, P. Doel, C. Doux, A. Drlica-Wagner, A. Ferté, B. Flaugher, J. Frieman, J. García-Bellido, E. Gaztanaga, G. Giannini, G. Gutierrez, W. G. Hartley, K. Herner, S. R. Hinton, D. L. Hollowood, K. Honscheid, D. Huterer, E. Krause, K. Kuehn, O. Lahav, M. Lima, J. L. Marshall, J. Mena-Fernández, R. Miquel, J. J. Mohr, J. Muir, J. Myles, R. L. C. Ogando, A. Pieres, A. A. Plazas Malagón, A. Porredon, J. Prat, M. Raveri, M. Rodriguez-Monroy, A. Roodman, S. Samuroff, E. Sanchez, D. Sanchez Cid, V. Scarpine, I. Sevilla-Noarbe, M. Smith, E. Suchyta, G. Tarle, V. Vikram, N. Weaverdyck, P. Wiseman, Y. Zhang","We present the Metadetection weak lensing galaxy shape catalogue from the
six-year Dark Energy Survey (DES Y6) imaging data. This dataset is the final
release from DES, spanning 4422 deg$^2$ of the southern sky. We describe how
the catalogue was constructed, including the two new major processing steps,
cell-based image coaddition and shear measurements with Metadetection. The DES
Y6 Metadetection weak lensing shape catalogue consists of 151,922,791 galaxies
detected over riz bands, with an effective number density of $n_{\rm eff}$
=8.22 galaxies per arcmin$^2$ and shape noise of $\sigma_e$ = 0.29. We carry
out a suite of validation tests on the catalogue, including testing for PSF
leakage, testing for the impact of PSF modeling errors, and testing the
correlation of the shear measurements with galaxy, PSF, and survey properties.
In addition to demonstrating that our catalogue is robust for weak lensing
science, we use the DES Y6 image simulation suite (Mau, Becker et al. 2025) to
estimate the overall multiplicative shear bias of our shear measurement
pipeline. We find no detectable multiplicative bias at the roughly half-percent
level, with m = (3.4 $\pm$ 6.1) x $10^{-3}$, at 3$\sigma$ uncertainty. This is
the first time both cell-based coaddition and Metadetection algorithms are
applied to observational data, paving the way to the Stage-IV weak lensing
surveys.",http://arxiv.org/abs/2501.05665v1
"Dark Energy Survey Year 6 Results: Synthetic-source Injection Across the
  Full Survey Using Balrog",2025-01-10T03:13:49Z,"D. Anbajagane, M. Tabbutt, J. Beas-Gonzalez, B. Yanny, S. Everett, M. R. Becker, M. Yamamoto, E. Legnani, J. De Vicente, K. Bechtol, J. Elvin-Poole, G. M. Bernstein, A. Choi, M. Gatti, G. Giannini, R. A. Gruendl, M. Jarvis, S. Lee, J. Mena-Fernández, A. Porredon, M. Rodriguez-Monroy, E. Rozo, E. S. Rykoff, T. Schutt, E. Sheldon, M. A. Troxel, N. Weaverdyck, V. Wetzell, M. Aguena, A. Alarcon, S. Allam, A. Amon, F. Andrade-Oliveira, D. Brooks, A. Carnero Rosell, J. Carretero, C. Chang, M. Crocce, L. N. da Costa, M. E. S. Pereira, T. M. Davis, S. Desai, H. T. Diehl, S. Dodelson, P. Doel, A. Drlica-Wagner, A. Ferté, J. Frieman, J. García-Bellido, E. Gaztanaga, D. Gruen, G. Gutierrez, W. G. Hartley, K. Herner, S. R. Hinton, D. L. Hollowood, K. Honscheid, D. Huterer, D. J. James, E. Krause, K. Kuehn, O. Lahav, J. L. Marshall, R. Miquel, J. Muir, J. Myles, A. Pieres, A. A. Plazas Malagón, J. Prat, M. Raveri, S. Samuroff, E. Sanchez, D. Sanchez Cid, I. Sevilla-Noarbe, M. Smith, E. Suchyta, G. Tarle, D. L. Tucker, A. R. Walker, P. Wiseman, Y. Zhang","Synthetic source injection (SSI), the insertion of sources into pixel-level
on-sky images, is a powerful method for characterizing object detection and
measurement in wide-field, astronomical imaging surveys. Within the Dark Energy
Survey (DES), SSI plays a critical role in characterizing all necessary
algorithms used in converting images to catalogs, and in deriving quantities
needed for the cosmology analysis, such as object detection rates, galaxy
redshift estimation, galaxy magnification, star-galaxy classification, and
photometric performance. We present here a source injection catalog of $146$
million injections spanning the entire 5000 deg$^2$ DES footprint, generated
using the Balrog SSI pipeline. Through this sample, we demonstrate that the DES
Year 6 (Y6) image processing pipeline provides accurate estimates of the object
properties, for both galaxies and stars, at the percent-level, and we highlight
specific regimes where the accuracy is reduced. We then show the consistency
between SSI and data catalogs, for all galaxy samples developed within the weak
lensing and galaxy clustering analyses of DES Y6. The consistency between the
two catalogs also extends to their correlations with survey observing
properties (seeing, airmass, depth, extinction, etc.). Finally, we highlight a
number of applications of this catalog to the DES Y6 cosmology analysis. This
dataset is the largest SSI catalog produced at this fidelity and will serve as
a key testing ground for exploring the utility of SSI catalogs in upcoming
surveys such as the Vera C. Rubin Observatory Legacy Survey of Space and Time.",http://arxiv.org/abs/2501.05683v1
Dark Energy Survey Year 6 Results: Photometric Data Set for Cosmology,2025-01-10T06:09:39Z,"K. Bechtol, I. Sevilla-Noarbe, A. Drlica-Wagner, B. Yanny, R. A. Gruendl, E. Sheldon, E. S. Rykoff, J. De Vicente, M. Adamow, D. Anbajagane, M. R. Becker, G. M. Bernstein, A. Carnero Rosell, J. Gschwend, M. Gorsuch, W. G. Hartley, M. Jarvis, T. Jeltema, R. Kron, T. A. Manning, J. O'Donnell, A. Pieres, M. Rodríguez-Monroy, D. Sanchez Cid, M. Tabbutt, L. Toribio San Cipriano, D. L. Tucker, N. Weaverdyck, M. Yamamoto, T. M. C. Abbott, M. Aguena, A. Alarcón, S. Allam, A. Amon, F. Andrade-Oliveira, S. Avila, P. H. Bernardinelli, E. Bertin, J. Blazek, D. Brooks, D. L. Burke, J. Carretero, F. J. Castander, R. Cawthon, C. Chang, A. Choi, C. Conselice, M. Costanzi, M. Crocce, L. N. da Costa, T. M. Davis, S. Desai, H. T. Diehl, S. Dodelson, P. Doel, C. Doux, A. Ferté, B. Flaugher, P. Fosalba, J. Frieman, J. García-Bellido, M. Gatti, E. Gaztanaga, G. Giannini, D. Gruen, G. Gutierrez, K. Herner, S. R. Hinton, D. L. Hollowood, K. Honscheid, D. Huterer, N. Jeffrey, E. Krause, K. Kuehn, O. Lahav, S. Lee, C. Lidman, M. Lima, H. Lin, J. L. Marshall, J. Mena-Fernández, R. Miquel, J. J. Mohr, J. Muir, J. Myles, R. L. C. Ogando, A. Palmese, A. A. Plazas Malagón, A. Porredon, J. Prat, M. Raveri, A. K. Romer, A. Roodman, S. Samuroff, E. Sanchez, V. Scarpine, M. Smith, M. Soares-Santos, E. Suchyta, G. Tarle, M. A. Troxel, V. Vikram, A. R. Walker, J. Weller, P. Wiseman, Y. Zhang","We describe the photometric data set assembled from the full six years of
observations by the Dark Energy Survey (DES) in support of static-sky cosmology
analyses. DES Y6 Gold is a curated data set derived from DES Data Release 2
(DR2) that incorporates improved measurement, photometric calibration, object
classification and value added information. Y6 Gold comprises nearly $5000~{\rm
deg}^2$ of $grizY$ imaging in the south Galactic cap and includes 669 million
objects with a depth of $i_{AB} \sim 23.4$ mag at S/N $\sim 10$ for extended
objects and a top-of-the-atmosphere photometric uniformity $< 2~{\rm mmag}$. Y6
Gold augments DES DR2 with simultaneous fits to multi-epoch photometry for more
robust galaxy shapes, colors, and photometric redshift estimates. Y6 Gold
features improved morphological star-galaxy classification with efficiency
$98.6\%$ and contamination $0.8\%$ for galaxies with $17.5 < i_{AB} < 22.5$.
Additionally, it includes per-object quality information, and accompanying maps
of the footprint coverage, masked regions, imaging depth, survey conditions,
and astrophysical foregrounds that are used for cosmology analyses. After
quality selections, benchmark samples contain 448 million galaxies and 120
million stars. This paper will be complemented by online data access and
documentation.",http://arxiv.org/abs/2501.05739v2
Dark Energy Survey Year 6 Results: Point-Spread Function Modeling,2025-01-10T08:33:10Z,"T. Schutt, M. Jarvis, A. Roodman, A. Amon, M. R. Becker, R. A. Gruendl, M. Yamamoto, K. Bechtol, G. M. Bernstein, M. Gatti, E. S. Rykoff, E. Sheldon, M. A. Troxel, T. M. C. Abbott, M. Aguena, F. Andrade-Oliveira, D. Brooks, A. Carnero Rosell, J. Carretero, C. Chang, A. Choi, L. N. da Costa, T. M. Davis, J. De Vicente, S. Desai, H. T. Diehl, P. Doel, A. Ferté, J. Frieman, J. García-Bellido, E. Gaztanaga, D. Gruen, G. Gutierrez, S. R. Hinton, D. L. Hollowood, K. Honscheid, K. Kuehn, O. Lahav, S. Lee, M. Lima, J. L. Marshall, J. Mena-Fernández, R. Miquel, J. J. Mohr, J. Myles, R. L. C. Ogando, A. Pieres, A. A. Plazas Malagón, A. Porredon, S. Samuroff, E. Sanchez, D. Sanchez Cid, I. Sevilla-Noarbe, M. Smith, E. Suchyta, G. Tarle, V. Vikram, A. R. Walker, N. Weaverdyck","We present the point-spread function (PSF) modeling for weak lensing shear
measurement using the full six years of the Dark Energy Survey (DES Y6) data.
We review the PSF estimation procedure using the PIFF (PSFs In the Full FOV)
software package and describe the key improvements made to PIFF and modeling
diagnostics since the DES year three (Y3) analysis: (i) use of external Gaia
and infrared photometry catalogs to ensure higher purity of the stellar sample
used for model fitting, (ii) addition of color-dependent PSF modeling, the
first for any weak lensing analysis, and (iii) inclusion of model diagnostics
inspecting fourth-order moments, which can bias weak lensing measurements to a
similar degree as second-order modeling errors. Through a comprehensive set of
diagnostic tests, we demonstrate the improved accuracy of the Y6 models evident
in significantly smaller systematic errors than those of the Y3 analysis, in
which all $g$ band data were excluded due to insufficiently accurate PSF
models. For the Y6 weak lensing analysis, we include $g$ band photometry data
in addition to the $riz$ bands, providing a fourth band for photometric
redshift estimation. Looking forward to the next generation of wide-field
surveys, we describe several ongoing improvements to PIFF, which will be the
default PSF modeling software for weak lensing analyses for the Vera C. Rubin
Observatory's Legacy Survey of Space and Time.",http://arxiv.org/abs/2501.05781v1
"Measurements of the Temperature and E-mode Polarization of the Cosmic
  Microwave Background from the Full 500-square-degree SPTpol Dataset",2025-01-12T17:56:40Z,"T. -L. Chou, P. A. R. Ade, A. J. Anderson, J. E. Austermann, L. Balkenhol, J. A. Beall, A. N. Bender, B. A. Benson, F. Bianchini, L. E. Bleem, J. E. Carlstrom, C. L. Chang, P. Chaubal, H. C. Chiang, R. Citron, C. Corbett Moran, T. M. Crawford, A. T. Crites, T. de Haan, M. A. Dobbs, D. Dutcher, W. Everett, J. Gallicchio, E. M. George, N. Gupta, N. W. Halverson, G. P. Holder, W. L. Holzapfel, J. D. Hrubes, N. Huang, J. Hubmayr, K. D. Irwin, L. Knox, A. T. Lee, D. Li, A. Lowitz, J. J. McMahon, J. Montgomery, T. Natoli, J. P. Nibarger, G. I. Noble, V. Novosad, Y. Omori, S. Padin, S. Patil, C. Pryke, W. Quan, C. L. Reichardt, J. E. Ruhl, B. R. Saliwanchik, K. K. Schaffer, C. Sievers, G. Smecher, A. A. Stark, C. Tucker, T. Veach, J. D. Vieira, G. Wang, N. Whitehorn, W. L. K. Wu, V. Yefremenko, J. A. Zebrowski","Using the full four-year SPTpol 500 deg$^2$ dataset in both the 95 GHz and
150 GHz frequency bands, we present measurements of the temperature and
$E$-mode polarization of the cosmic microwave background (CMB), as well as the
$E$-mode polarization auto-power spectrum ($EE$) and temperature-$E$-mode
cross-power spectrum ($TE$) in the angular multipole range $50<\ell<8000$. We
find the SPTpol dataset to be self-consistent, passing several internal
consistency tests based on maps, frequency bands, bandpowers, and cosmological
parameters. The full SPTpol dataset is well-fit by the $\Lambda CDM$ model, for
which we find $H_0=70.48\pm2.16$ km s$^{-1}$ Mpc$^{-1}$ and
$\Omega_m=0.271\pm0.026$, when using only the SPTpol data and a Planck-based
prior on the optical depth to reionization. The $\Lambda CDM$ parameter
constraints are consistent across the 95 GHz-only, 150 GHz-only, $TE$-only, and
$EE$-only data splits. Between the $\ell<1000$ and $\ell>1000$ data splits, the
$\Lambda CDM$ parameter constraints are borderline consistent at the
$\sim2\sigma$ level. This consistency improves when including a parameter
$A_L$, the degree of lensing of the CMB inferred from the smearing of acoustic
peaks. When marginalized over $A_L$, the $\Lambda CDM$ parameter constraints
from SPTpol are consistent with those from Planck. The power spectra presented
here are the most sensitive measurements of the lensed CMB damping tail to date
for roughly $\ell > 1700$ in $TE$ and $\ell > 2000$ in $EE$.",http://arxiv.org/abs/2501.06890v1
MiniMax-01: Scaling Foundation Models with Lightning Attention,2025-01-14T18:50:05Z,"MiniMax, Aonian Li, Bangwei Gong, Bo Yang, Boji Shan, Chang Liu, Cheng Zhu, Chunhao Zhang, Congchao Guo, Da Chen, Dong Li, Enwei Jiao, Gengxin Li, Guojun Zhang, Haohai Sun, Houze Dong, Jiadai Zhu, Jiaqi Zhuang, Jiayuan Song, Jin Zhu, Jingtao Han, Jingyang Li, Junbin Xie, Junhao Xu, Junjie Yan, Kaishun Zhang, Kecheng Xiao, Kexi Kang, Le Han, Leyang Wang, Lianfei Yu, Liheng Feng, Lin Zheng, Linbo Chai, Long Xing, Meizhi Ju, Mingyuan Chi, Mozhi Zhang, Peikai Huang, Pengcheng Niu, Pengfei Li, Pengyu Zhao, Qi Yang, Qidi Xu, Qiexiang Wang, Qin Wang, Qiuhui Li, Ruitao Leng, Shengmin Shi, Shuqi Yu, Sichen Li, Songquan Zhu, Tao Huang, Tianrun Liang, Weigao Sun, Weixuan Sun, Weiyu Cheng, Wenkai Li, Xiangjun Song, Xiao Su, Xiaodong Han, Xinjie Zhang, Xinzhu Hou, Xu Min, Xun Zou, Xuyang Shen, Yan Gong, Yingjie Zhu, Yipeng Zhou, Yiran Zhong, Yongyi Hu, Yuanxiang Fan, Yue Yu, Yufeng Yang, Yuhao Li, Yunan Huang, Yunji Li, Yunpeng Huang, Yunzhi Xu, Yuxin Mao, Zehan Li, Zekang Li, Zewei Tao, Zewen Ying, Zhaoyang Cong, Zhen Qin, Zhenhua Fan, Zhihang Yu, Zhuo Jiang, Zijia Wu","We introduce MiniMax-01 series, including MiniMax-Text-01 and MiniMax-VL-01,
which are comparable to top-tier models while offering superior capabilities in
processing longer contexts. The core lies in lightning attention and its
efficient scaling. To maximize computational capacity, we integrate it with
Mixture of Experts (MoE), creating a model with 32 experts and 456 billion
total parameters, of which 45.9 billion are activated for each token. We
develop an optimized parallel strategy and highly efficient
computation-communication overlap techniques for MoE and lightning attention.
This approach enables us to conduct efficient training and inference on models
with hundreds of billions of parameters across contexts spanning millions of
tokens. The context window of MiniMax-Text-01 can reach up to 1 million tokens
during training and extrapolate to 4 million tokens during inference at an
affordable cost. Our vision-language model, MiniMax-VL-01 is built through
continued training with 512 billion vision-language tokens. Experiments on both
standard and in-house benchmarks show that our models match the performance of
state-of-the-art models like GPT-4o and Claude-3.5-Sonnet while offering 20-32
times longer context window. We publicly release MiniMax-01 at
https://github.com/MiniMax-AI.",http://arxiv.org/abs/2501.08313v1
Towards Best Practices for Open Datasets for LLM Training,2025-01-14T17:18:05Z,"Stefan Baack, Stella Biderman, Kasia Odrozek, Aviya Skowron, Ayah Bdeir, Jillian Bommarito, Jennifer Ding, Maximilian Gahntz, Paul Keller, Pierre-Carl Langlais, Greg Lindahl, Sebastian Majstorovic, Nik Marda, Guilherme Penedo, Maarten Van Segbroeck, Jennifer Wang, Leandro von Werra, Mitchell Baker, Julie Belião, Kasia Chmielinski, Marzieh Fadaee, Lisa Gutermuth, Hynek Kydlíček, Greg Leppert, EM Lewis-Jong, Solana Larsen, Shayne Longpre, Angela Oduor Lungati, Cullen Miller, Victor Miller, Max Ryabinin, Kathleen Siminyu, Andrew Strait, Mark Surman, Anna Tumadóttir, Maurice Weber, Rebecca Weiss, Lee White, Thomas Wolf","Many AI companies are training their large language models (LLMs) on data
without the permission of the copyright owners. The permissibility of doing so
varies by jurisdiction: in countries like the EU and Japan, this is allowed
under certain restrictions, while in the United States, the legal landscape is
more ambiguous. Regardless of the legal status, concerns from creative
producers have led to several high-profile copyright lawsuits, and the threat
of litigation is commonly cited as a reason for the recent trend towards
minimizing the information shared about training datasets by both corporate and
public interest actors. This trend in limiting data information causes harm by
hindering transparency, accountability, and innovation in the broader ecosystem
by denying researchers, auditors, and impacted individuals access to the
information needed to understand AI models.
  While this could be mitigated by training language models on open access and
public domain data, at the time of writing, there are no such models (trained
at a meaningful scale) due to the substantial technical and sociological
challenges in assembling the necessary corpus. These challenges include
incomplete and unreliable metadata, the cost and complexity of digitizing
physical records, and the diverse set of legal and technical skills required to
ensure relevance and responsibility in a quickly changing landscape. Building
towards a future where AI systems can be trained on openly licensed data that
is responsibly curated and governed requires collaboration across legal,
technical, and policy domains, along with investments in metadata standards,
digitization, and fostering a culture of openness.",http://arxiv.org/abs/2501.08365v1
"High-Significance Detection of Correlation Between the Unresolved
  Gamma-Ray Background and the Large Scale Cosmic Structure",2025-01-17T19:00:01Z,"B. Thakore, M. Negro, M. Regis, S. Camera, D. Gruen, N. Fornengo, A. Roodman, A. Porredon, T. Schutt, A. Cuoco, A. Alarcon, A. Amon, K. Bechtol, M. R. Becker, G. M. Bernstein, A. Campos, A. Carnero Rosell, M. Carrasco Kind, R. Cawthon, C. Chang, R. Chen, A. Choi, J. Cordero, C. Davis, J. DeRose, H. T. Diehl, S. Dodelson, C. Doux, A. Drlica-Wagner, K. Eckert, J. Elvin-Poole, S. Everett, A. Ferté, M. Gatti, G. Giannini, R. A. Gruendl, I. Harrison, W. G. Hartley, E. M. Huff, M. Jarvis, N. Kuropatkin, P. -F. Leget, N. MacCrann, J. McCullough, J. Myles, A. Navarro-Alsina, S. Pandey, J. Prat, M. Raveri, R. P. Rollins, A. J. Ross, E. S. Rykoff, C. Sánchez, L. F. Secco, I. Sevilla-Noarbe, E. Sheldon, T. Shin, M. A. Troxel, I. Tutusaus, B. Yanny, B. Yin, Y. Zhang, M. Aguena, D. Brooks, J. Carretero, L. N. da Costa, T. M. Davis, J. De Vicente, S. Desai, P. Doel, B. Flaugher, J. Frieman, J. García-Bellido, E. Gaztanaga, G. Gutierrez, S. R. Hinton, D. L. Hollowood, K. Honscheid, D. J. James, K. Kuehn, O. Lahav, S. Lee, M. Lima, J. L. Marshall, J. Mena-Fernández, R. Miquel, R. L. C. Ogando, A. Palmese, A. Pieres, A. A. Plazas Malagón, S. Samuroff, E. Sanchez, D. Sanchez Cid, M. Smith, E. Suchyta, G. Tarle, V. Vikram, A. R. Walker, N. Weaverdyck","Our understanding of the $\gamma$-ray sky has improved dramatically in the
past decade, however, the unresolved $\gamma$-ray background (UGRB) still has a
potential wealth of information about the faintest $\gamma$-ray sources
pervading the Universe. Statistical cross-correlations with tracers of cosmic
structure can indirectly identify the populations that most characterize the
$\gamma$-ray background. In this study, we analyze the angular correlation
between the $\gamma$-ray background and the matter distribution in the Universe
as traced by gravitational lensing, leveraging more than a decade of
observations from the Fermi-Large Area Telescope (LAT) and 3 years of data from
the Dark Energy Survey (DES). We detect a correlation at signal-to-noise ratio
of 8.9. Most of the statistical significance comes from large scales,
demonstrating, for the first time, that a substantial portion of the UGRB
aligns with the mass clustering of the Universe as traced by weak lensing.
Blazars provide a plausible explanation for this signal, especially if those
contributing to the correlation reside in halos of large mass ($\sim 10^{14}
M_{\odot}$) and account for approximately 30-40 % of the UGRB above 10 GeV.
Additionally, we observe a preference for a curved $\gamma$-ray energy
spectrum, with a log-parabolic shape being favored over a power-law. We also
discuss the possibility of modifications to the blazar model and the inclusion
of additional $gamma$-ray sources, such as star-forming galaxies or particle
dark matter.",http://arxiv.org/abs/2501.10506v1
The SPHEREx Target List of Ice Sources (SPLICES),2025-01-29T17:35:41Z,"Matthew L. N. Ashby, Joseph L. Hora, Kiran Lakshmipathaiah, Sarita Vig, Rama Krishna Sai Subrahmanyam Gorthi, Miju Kang, Volker Tolls, Gary J. Melnick, Michael W. Werner, Brendan P. Crill, Daniel C. Masters, Carlos Contreras Pena, Jeong-Eun Lee, Jaeyeong Kim, Ho-Gyu Lee, Sung-Yong Yoon, Soung-Chul Yang, Nicholas Flagey, Bertrand Mennesson","One of the primary objectives of the SPHEREx mission is to understand the
origin of molecules such as H2O, CO2, and other volatile compounds at the early
stages of planetary system formation. Because the vast majority of these
compounds -- typically exceeding 95% -- exist in the solid phase rather than
the gaseous phase in the systems of concern here, the observing strategy
planned to characterize them is slightly unusual. Specifically, SPHEREx will
target highly obscured sources throughout the Milky Way, and observe the
species of concern in absorption against background illumination. SPHEREx
spectrophotometry will yield ice column density measurements for millions of
obscured Milky Way sources of all ages and types. By correlating those column
densities with source ages, the SPHEREx mission will shed light on whether
those molecules were formed in situ along with their nascent stellar systems,
or whether instead they formed elsewhere and were introduced into those systems
after their formation. To that end, this work describes version 7$.$1 of the
SPHEREx Target List of Ice Sources (SPLICES) for the community. It contains
about 8$.$6 million objects brighter than W2~12 Vega mag over much of the sky,
principally within a broad strip running the length of the Milky Way midplane,
but also within high-latitude molecular clouds and even the Magellanic Clouds.",http://arxiv.org/abs/2501.17797v1
"Core to Cosmic Edge: SIMBA-C's New Take on Abundance Profiles in the
  Intragroup Medium at z = 0",2025-02-07T04:53:51Z,"Aviv Padawer-Blatt, Zhiwei Shao, Renier T. Hough, Douglas Rennehan, Ruxin Barré, Vida Saeedzadeh, Arif Babul, Romeel Davé, Chiaki Kobayashi, Weiguang Cui, François Mernier, Ghassem Gozaliasl","We employ the SIMBA-C cosmological simulation to study the impact of its
upgraded chemical enrichment model (Chem5) on the distribution of metals in the
intragroup medium (IGrM). We investigate the projected X-ray emission-weighted
abundance profiles of key elements over two decades in halo mass ($10^{13} \leq
M_{500}/\mathrm{M_\odot} \leq 10^{15}$). Typically, SIMBA-C generates
lower-amplitude abundance profiles than SIMBA with flatter cores, in better
agreement with observations. For low-mass groups, both simulations over-enrich
the IGrM with Si, S, Ca, and Fe compared to observations, a trend likely
related to inadequate modeling of metal dispersal and mixing. We analyze the 3D
mass-weighted abundance profiles, concluding that the lower SIMBA-C IGrM
abundances are primarily a consequence of fewer metals in the IGrM, driven by
reduced metal yields in Chem5, and the removal of the instantaneous recycling
of metals approximation employed by SIMBA. Additionally, an increased IGrM mass
in low-mass SIMBA-C groups is likely triggered by changes to the AGN and
stellar feedback models. Our study suggests that a more realistic chemical
enrichment model broadly improves agreement with observations, but physically
motivated sub-grid models for other key processes, like AGN and stellar
feedback and turbulent diffusion, are required to realistically reproduce
observed group environments.",http://arxiv.org/abs/2502.04657v3
"Multi-Class Segmentation of Aortic Branches and Zones in Computed
  Tomography Angiography: The AortaSeg24 Challenge",2025-02-07T21:09:05Z,"Muhammad Imran, Jonathan R. Krebs, Vishal Balaji Sivaraman, Teng Zhang, Amarjeet Kumar, Walker R. Ueland, Michael J. Fassler, Jinlong Huang, Xiao Sun, Lisheng Wang, Pengcheng Shi, Maximilian Rokuss, Michael Baumgartner, Yannick Kirchhof, Klaus H. Maier-Hein, Fabian Isensee, Shuolin Liu, Bing Han, Bong Thanh Nguyen, Dong-jin Shin, Park Ji-Woo, Mathew Choi, Kwang-Hyun Uhm, Sung-Jea Ko, Chanwoong Lee, Jaehee Chun, Jin Sung Kim, Minghui Zhang, Hanxiao Zhang, Xin You, Yun Gu, Zhaohong Pan, Xuan Liu, Xiaokun Liang, Markus Tiefenthaler, Enrique Almar-Munoz, Matthias Schwab, Mikhail Kotyushev, Rostislav Epifanov, Marek Wodzinski, Henning Muller, Abdul Qayyum, Moona Mazher, Steven A. Niederer, Zhiwei Wang, Kaixiang Yang, Jintao Ren, Stine Sofia Korreman, Yuchong Gao, Hongye Zeng, Haoyu Zheng, Rui Zheng, Jinghua Yue, Fugen Zhou, Bo Liu, Alexander Cosman, Muxuan Liang, Chang Zhao, Gilbert R. Upchurch Jr., Jun Ma, Yuyin Zhou, Michol A. Cooper, Wei Shao","Multi-class segmentation of the aorta in computed tomography angiography
(CTA) scans is essential for diagnosing and planning complex endovascular
treatments for patients with aortic dissections. However, existing methods
reduce aortic segmentation to a binary problem, limiting their ability to
measure diameters across different branches and zones. Furthermore, no
open-source dataset is currently available to support the development of
multi-class aortic segmentation methods. To address this gap, we organized the
AortaSeg24 MICCAI Challenge, introducing the first dataset of 100 CTA volumes
annotated for 23 clinically relevant aortic branches and zones. This dataset
was designed to facilitate both model development and validation. The challenge
attracted 121 teams worldwide, with participants leveraging state-of-the-art
frameworks such as nnU-Net and exploring novel techniques, including cascaded
models, data augmentation strategies, and custom loss functions. We evaluated
the submitted algorithms using the Dice Similarity Coefficient (DSC) and
Normalized Surface Distance (NSD), highlighting the approaches adopted by the
top five performing teams. This paper presents the challenge design, dataset
details, evaluation metrics, and an in-depth analysis of the top-performing
algorithms. The annotated dataset, evaluation code, and implementations of the
leading methods are publicly available to support further research. All
resources can be accessed at https://aortaseg24.grand-challenge.org.",http://arxiv.org/abs/2502.05330v1
"Comprehensive Measurement of the Reactor Antineutrino Spectrum and Flux
  at Daya Bay",2025-01-01T06:27:38Z,"F. P. An, W. D. Bai, A. B. Balantekin, M. Bishai, S. Blyth, G. F. Cao, J. Cao, J. F. Chang, Y. Chang, H. S. Chen, H. Y. Chen, S. M. Chen, Y. Chen, Y. X. Chen, Z. Y. Chen, J. Cheng, J. Cheng, Y. -C. Cheng, Z. K. Cheng, J. J. Cherwinka, M. C. Chu, J. P. Cummings, O. Dalager, F. S. Deng, X. Y. Ding, Y. Y. Ding, M. V. Diwan, T. Dohnal, D. Dolzhikov, J. Dove, K. V. Dugas, H. Y. Duyang, D. A. Dwyer, J. P. Gallo, M. Gonchar, G. H. Gong, H. Gong, W. Q. Gu, J. Y. Guo, L. Guo, X. H. Guo, Y. H. Guo, Z. Guo, R. W. Hackenburg, Y. Han, S. Hans, M. He, K. M. Heeger, Y. K. Heng, Y. K. Hor, Y. B. Hsiung, B. Z. Hu, J. R. Hu, T. Hu, Z. J. Hu, H. X. Huang, J. H. Huang, X. T. Huang, Y. B. Huang, P. Huber, D. E. Jaffe, K. L. Jen, X. L. Ji, X. P. Ji, R. A. Johnson, D. Jones, L. Kang, S. H. Kette, S. Kohn, M. Kramer, T. J. Langford, J. Lee, J. H. C. Lee, R. T. Lei, R. Leitner, J. K. C. Leung, F. Li, H. L. Li, J. J. Li, Q. J. Li, R. H. Li, S. Li, S. Li, S. C. Li, W. D. Li, X. N. Li, X. Q. Li, Y. F. Li, Z. B. Li, H. Liang, C. J. Lin, G. L. Lin, S. Lin, J. J. Ling, J. M. Link, L. Littenberg, B. R. Littlejohn, J. C. Liu, J. L. Liu, J. X. Liu, C. Lu, H. Q. Lu, K. B. Luk, B. Z. Ma, X. B. Ma, X. Y. Ma, Y. Q. Ma, R. C. Mandujano, C. Marshall, K. T. McDonald, R. D. McKeown, Y. Meng, J. Napolitano, D. Naumov, E. Naumova, T. M. T. Nguyen, J. P. Ochoa-Ricoux, A. Olshevskiy, J. Park, S. Patton, J. C. Peng, C. S. J. Pun, F. Z. Qi, M. Qi, X. Qian, N. Raper, J. Ren, C. Morales Reveco, R. Rosero, B. Roskovec, X. C. Ruan, B. Russe, H. Steiner, J. L. Sun, T. Tmej, W. -H. Tse, C. E. Tull, Y. C. Tung, B. Viren, V. Vorobel, C. H. Wang, J. Wang, M. Wang, N. Y. Wang, R. G. Wang, W. Wang, X. Wang, Y. F. Wang, Z. Wang, Z. Wang, Z. M. Wang, H. Y. Wei, L. H. Wei, W. Wei, L. J. Wen, K. Whisnant, C. G. White, H. L. H. Wong, E. Worcester, D. R. Wu, Q. Wu, W. J. Wu, D. M. Xia, Z. Q. Xie, Z. Z. Xing, H. K. Xu, J. L. Xu, T. Xu, T. Xue, C. G. Yang, L. Yang, Y. Z. Yang, H. F. Yao, M. Ye, M. Yeh, B. L. Young, H. Z. Yu, Z. Y. Yu, B. B. Yue, V. Zavadskyi, S. Zeng, Y. Zeng, L. Zhan, C. Zhang, F. Y. Zhang, H. H. Zhang, J. L. Zhang, J. W. Zhang, Q. M. Zhang, S. Q. Zhang, X. T. Zhang, Y. M. Zhang, Y. X. Zhang, Y. Y. Zhang, Z. J. Zhang, Z. P. Zhang, Z. Y. Zhang, J. Zhao, R. Z. Zhao, L. Zhou, H. L. Zhuang, J. H. Zou","This Letter reports the precise measurement of reactor antineutrino spectrum
and flux based on the full data set of 4.7 million inverse-beta-decay (IBD)
candidates collected at Daya Bay near detectors. Expressed in terms of the IBD
yield per fission, the antineutrino spectra from all reactor fissile isotopes
and the specific $\mathrm{^{235}U}$ and $\mathrm{^{239}Pu}$ isotopes are
measured with 1.3$\%$, 3$\%$ and 8$\%$ uncertainties respectively near the 3
MeV spectrum peak in reconstructed energy, reaching the best precision in the
world. The total antineutrino flux and isotopic $\mathrm{^{235}U}$ and
$\mathrm{^{239}Pu}$ fluxes are precisely measured to be $5.84\pm0.07$,
$6.16\pm0.12$ and $4.16\pm0.21$ in units of $10^{-43} \mathrm{cm^2/fission}$.
These measurements are compared with the Huber-Mueller (HM) model, the
reevaluated conversion model based on the Kurchatov Institute (KI) measurement
and the latest Summation Model (SM2023). The Daya Bay flux shows good
consistency with KI and SM2023 models, but disagrees with HM model. The Daya
Bay spectrum, however, disagrees with all model predictions.",http://arxiv.org/abs/2501.00746v1
Broadband $γ$-ray spectrum of supernova remnant Cassiopeia A,2025-02-07T11:37:23Z,"Zhen Cao, F. Aharonian, Y. X. Bai, Y. W. Bao, D. Bastieri, X. J. Bi, Y. J. Bi, W. Bian, A. V. Bukevich, C. M. Cai, W. Y. Cao, Zhe Cao, J. Chang, J. F. Chang, A. M. Chen, E. S. Chen, H. X. Chen, Liang Chen, Long Chen, M. J. Chen, M. L. Chen, Q. H. Chen, S. Chen, S. H. Chen, S. Z. Chen, T. L. Chen, X. B. Chen, X. J. Chen, Y. Chen, N. Cheng, Y. D. Cheng, M. C. Chu, M. Y. Cui, S. W. Cui, X. H. Cui, Y. D. Cui, B. Z. Dai, H. L. Dai, Z. G. Dai, Danzengluobu, Y. X. Diao, X. Q. Dong, K. K. Duan, J. H. Fan, Y. Z. Fan, J. Fang, J. H. Fang, K. Fang, C. F. Feng, H. Feng, L. Feng, S. H. Feng, X. T. Feng, Y. Feng, Y. L. Feng, S. Gabici, B. Gao, C. D. Gao, Q. Gao, W. Gao, W. K. Gao, M. M. Ge, T. T. Ge, L. S. Geng, G. Giacinti, G. H. Gong, Q. B. Gou, M. H. Gu, F. L. Guo, J. Guo, X. L. Guo, Y. Q. Guo, Y. Y. Guo, Y. A. Han, O. A. Hannuksela, M. Hasan, H. H. He, H. N. He, J. Y. He, X. Y. He, Y. He, S. Hernández-Cadena, Y. K. Hor, B. W. Hou, C. Hou, X. Hou, H. B. Hu, S. C. Hu, C. Huang, D. H. Huang, J. J. Huang, T. Q. Huang, W. J. Huang, X. T. Huang, X. Y. Huang, Y. Huang, Y. Y. Huang, X. L. Ji, H. Y. Jia, K. Jia, H. B. Jiang, K. Jiang, X. W. Jiang, Z. J. Jiang, M. Jin, S. Kaci, M. M. Kang, I. Karpikov, D. Khangulyan, D. Kuleshov, K. Kurinov, B. B. Li, Cheng Li, Cong Li, D. Li, F. Li, H. B. Li, H. C. Li, Jian Li, Jie Li, K. Li, L. Li, R. L. Li, S. D. Li, T. Y. Li, W. L. Li, X. R. Li, Xin Li, Y. Z. Li, Zhe Li, Zhuo Li, E. W. Liang, Y. F. Liang, S. J. Lin, B. Liu, C. Liu, D. Liu, D. B. Liu, H. Liu, H. D. Liu, J. Liu, J. L. Liu, J. R. Liu, M. Y. Liu, R. Y. Liu, S. M. Liu, W. Liu, X. Liu, Y. Liu, Y. Liu, Y. N. Liu, Y. Q. Lou, Q. Luo, Y. Luo, H. K. Lv, B. Q. Ma, L. L. Ma, X. H. Ma, J. R. Mao, Z. Min, W. Mitthumsiri, G. B. Mou, H. J. Mu, Y. C. Nan, A. Neronov, K. C. Y. Ng, M. Y. Ni, L. Nie, L. J. Ou, P. Pattarakijwanich, Z. Y. Pei, J. C. Qi, M. Y. Qi, J. J. Qin, A. Raza, C. Y. Ren, D. Ruffolo, A. Sáiz, M. Saeed, D. Semikoz, L. Shao, O. Shchegolev, Y. Z. Shen, X. D. Sheng, Z. D. Shi, F. W. Shu, H. C. Song, Yu. V. Stenkin, V. Stepanov, Y. Su, D. X. Sun, H. Sun, Q. N. Sun, X. N. Sun, Z. B. Sun, N. H. Tabasam, J. Takata, P. H. T. Tam, H. B. Tan, Q. W. Tang, R. Tang, Z. B. Tang, W. W. Tian, C. N. Tong, L. H. Wan, C. Wang, G. W. Wang, H. G. Wang, H. H. Wang, J. C. Wang, K. Wang, Kai Wang, Kai Wang, L. P. Wang, L. Y. Wang, L. Y. Wang, R. Wang, W. Wang, X. G. Wang, X. J. Wang, X. Y. Wang, Y. Wang, Y. D. Wang, Z. H. Wang, Z. X. Wang, Zheng Wang, D. M. Wei, J. J. Wei, Y. J. Wei, T. Wen, S. S. Weng, C. Y. Wu, H. R. Wu, Q. W. Wu, S. Wu, X. F. Wu, Y. S. Wu, S. Q. Xi, J. Xia, J. J. Xia, G. M. Xiang, D. X. Xiao, G. Xiao, Y. L. Xin, Y. Xing, D. R. Xiong, Z. Xiong, D. L. Xu, R. F. Xu, R. X. Xu, W. L. Xu, L. Xue, D. H. Yan, J. Z. Yan, T. Yan, C. W. Yang, C. Y. Yang, F. F. Yang, L. L. Yang, M. J. Yang, R. Z. Yang, W. X. Yang, Y. H. Yao, Z. G. Yao, X. A. Ye, L. Q. Yin, N. Yin, X. H. You, Z. Y. You, Y. H. Yu, Q. Yuan, H. Yue, H. D. Zeng, T. X. Zeng, W. Zeng, M. Zha, B. B. Zhang, B. T. Zhang, F. Zhang, H. Zhang, H. M. Zhang, H. Y. Zhang, J. L. Zhang, Li Zhang, P. F. Zhang, P. P. Zhang, R. Zhang, S. R. Zhang, S. S. Zhang, W. Y. Zhang, X. Zhang, X. P. Zhang, Yi Zhang, Yong Zhang, Z. P. Zhang, J. Zhao, L. Zhao, L. Z. Zhao, S. P. Zhao, X. H. Zhao, Z. H. Zhao, F. Zheng, W. J. Zhong, B. Zhou, H. Zhou, J. N. Zhou, M. Zhou, P. Zhou, R. Zhou, X. X. Zhou, X. X. Zhou, B. Y. Zhu, C. G. Zhu, F. R. Zhu, H. Zhu, K. J. Zhu, Y. C. Zou, X. Zuo","The core-collapse supernova remnant (SNR) Cassiopeia A (Cas A) is one of the
brightest galactic radio sources with an angular radius of $\sim$ 2.5
$\arcmin$. Although no extension of this source has been detected in the
$\gamma$-ray band, using more than 1000 days of LHAASO data above $\sim 0.8$
TeV, we find that its spectrum is significantly softer than those obtained with
Imaging Air Cherenkov Telescopes (IACTs) and its flux near $\sim 1$ TeV is
about two times higher. In combination with analyses of more than 16 years of
\textit{Fermi}-LAT data covering $0.1 \, \mathrm{GeV} - 1 \, \mathrm{TeV}$, we
find that the spectrum above 30 GeV deviates significantly from a single
power-law, and is best described by a smoothly broken power-law with a spectral
index of $1.90 \pm 0.15_\mathrm{stat}$ ($3.41 \pm 0.19_\mathrm{stat}$) below
(above) a break energy of $0.63 \pm 0.21_\mathrm{stat} \, \mathrm{TeV}$. Given
differences in the angular resolution of LHAASO-WCDA and IACTs, TeV
$\gamma$-ray emission detected with LHAASO may have a significant contribution
from regions surrounding the SNR illuminated by particles accelerated earlier,
which, however, are treated as background by IACTs. Detailed modelling can be
used to constrain acceleration processes of TeV particles in the early stage of
SNR evolution.",http://arxiv.org/abs/2502.04848v1
"Evidence of the P_ccbars(4459)0 in Upsilon(1S, 2S) inclusive decays at
  Belle",2025-02-14T07:09:56Z,"I. Adachi, L. Aggarwal, H. Ahmed, J. K. Ahn, H. Aihara, N. Akopov, M. Alhakami, A. Aloisio, N. Althubiti, D. M. Asner, H. Atmacan, V. Aushev, M. Aversano, R. Ayad, V. Babu, H. Bae, N. K. Baghel, S. Bahinipati, P. Bambade, Sw. Banerjee, S. Bansal, M. Barrett, M. Bartl, J. Baudot, A. Baur, A. Beaubien, F. Becherer, J. Becker, J. V. Bennett, F. U. Bernlochner, V. Bertacchi, M. Bertemes, E. Bertholet, M. Bessner, S. Bettarini, V. Bhardwaj, B. Bhuyan, F. Bianchi, D. Biswas, D. Bodrov, A. Bolz, A. Boschetti, A. Bozek, M. Bracko, P. Branchini, R. A. Briere, T. E. Browder, A. Budano, S. Bussino, Q. Campagna, M. Campajola, L. Cao, G. Casarosa, C. Cecchi, J. Cerasoli, M. -C. Chang, P. Chang, R. Cheaib, P. Cheema, B. G. Cheon, K. Chilikin, K. Chirapatpimol, H. -E. Cho, K. Cho, S. -J. Cho, S. -K. Choi, S. Choudhury, J. Cochran, L. Corona, J. X. Cui, E. De La Cruz-Burelo, S. A. De La Motte, G. De Nardo, G. De Pietro, R. de Sangro, M. Destefanis, S. Dey, R. Dhamija, F. Di Capua, J. Dingfelder, Z. Dolezal, I. Domnguez Jimenez, T. V. Dong, X. Dong, D. Dossett, K. Dugic, G. Dujany, P. Ecker, J. Eppelt, P. Feichtinger, T. Ferber, T. Fillinger, C. Finck, G. Finocchiaro, F. Forti, B. G. Fulsom, A. Gabrielli, E. Ganiev, M. Garcia-Hernandez, G. Gaudino, V. Gaur, A. Gellrich, G. Ghevondyan, D. Ghosh, H. Ghumaryan, G. Giakoustidis, R. Giordano, A. Giri, P. Gironella Gironell, A. Glazov, B. Gobbo, R. Godang, P. Goldenzweig, E. Graziani, D. Greenwald, Z. Gruberova, Y. Guan, K. Gudkova, I. Haide, Y. Han, C. Harris, K. Hayasaka, H. Hayashii, S. Hazra, C. Hearty, M. T. Hedges, A. Heidelbach, I. Heredia de la Cruz, M. Hernandez Villanueva, T. Higuchi, M. Hoek, M. Hohmann, R. Hoppe, P. Horak, C. -L. Hsu, T. Humair, T. Iijima, K. Inami, N. Ipsita, A. Ishikawa, R. Itoh, M. Iwasaki, P. Jackson, D. Jacobi, W. W. Jacobs, E. -J. Jang, Q. P. Ji, S. Jia, Y. Jin, A. Johnson, K. K. Joo, H. Junkerkalefeld, M. Kaleta, J. Kandra, K. H. Kang, S. Kang, G. Karyan, T. Kawasaki, F. Keil, C. Ketter, C. Kiesling, C. -H. Kim, D. Y. Kim, J. -Y. Kim, K. -H. Kim, Y. -K. Kim, H. Kindo, K. Kinoshita, P. Kodys, T. Koga, S. Kohani, K. Kojima, A. Korobov, S. Korpar, E. Kovalenko, P. Krizan, P. Krokovny, T. Kuhr, Y. Kulii, D. Kumar, R. Kumar, K. Kumara, T. Kunigo, A. Kuzmin, Y. -J. Kwon, S. Lacaprara, K. Lalwani, T. Lam, J. S. Lange, T. S. Lau, M. Laurenza, R. Leboucher, F. R. Le Diberder, M. J. Lee, C. Lemettais, P. Leo, P. M. Lewis, C. Li, L. K. Li, Q. M. Li, W. Z. Li, Y. Li, Y. B. Li, Y. P. Liao, J. Libby, J. Lin, M. H. Liu, Q. Y. Liu, Y. Liu, Z. Q. Liu, D. Liventsev, S. Longo, C. Lyu, Y. Ma, C. Madaan, M. Maggiora, S. P. Maharana, R. Maiti, G. Mancinelli, R. Manfredi, E. Manoni, M. Mantovano, D. Marcantonio, S. Marcello, C. Marinas, C. Martellini, A. Martens, A. Martini, T. Martinov, L. Massaccesi, M. Masuda, D. Matvienko, S. K. Maurya, M. Maushart, J. A. McKenna, R. Mehta, F. Meier, D. Meleshko, M. Merola, C. Miller, M. Mirra, S. Mitra, K. Miyabayashi, H. Miyake, R. Mizuk, G. B. Mohanty, S. Mondal, S. Moneta, H. -G. Moser, R. Mussa, I. Nakamura, M. Nakao, H. Nakazawa, Y. Nakazawa, M. Naruki, Z. Natkaniec, A. Natochii, M. Nayak, G. Nazaryan, M. Neu, S. Nishida, S. Ogawa, H. Ono, Y. Onuki, F. Otani, G. Pakhlova, S. Pardi, K. Parham, H. Park, J. Park, K. Park, S. -H. Park, B. Paschen, S. Patra, T. K. Pedlar, I. Peruzzi, R. Peschke, R. Pestotnik, M. Piccolo, L. E. Piilonen, P. L. M. Podesta-Lerma, T. Podobnik, S. Pokharel, C. Praz, S. Prell, E. Prencipe, M. T. Prim, H. Purwar, P. Rados, G. Raeuber, S. Raiz, N. Rauls, K. Ravindran, J. U. Rehman, M. Reif, S. Reiter, M. Remnev, L. Reuter, D. Ricalde Herrmann, I. Ripp-Baudot, G. Rizzo, M. Roehrken, J. M. Roney, A. Rostomyan, N. Rout, D. A. Sanders, S. Sandilya, L. Santelj, V. Savinov, B. Scavino, J. Schmitz, S. Schneider, G. Schnell, C. Schwanda, Y. Seino, A. Selce, K. Senyo, J. Serrano, M. E. Sevior, C. Sfienti, W. Shan, C. Sharma, X. D. Shi, T. Shillington, T. Shimasaki, J. -G. Shiu, D. Shtol, A. Sibidanov, F. Simon, J. B. Singh, J. Skorupa, M. Sobotzik, A. Soffer, A. Sokolov, E. Solovieva, S. Spataro, B. Spruck, W. Song, M. Staric, P. Stavroulakis, S. Stefkova, R. Stroili, J. Strube, Y. Sue, M. Sumihama, K. Sumisawa, W. Sutcliffe, N. Suwonjandee, H. Svidras, M. Takahashi, M. Takizawa, U. Tamponi, K. Tanida, F. Tenchini, A. Thaller, O. Tittel, R. Tiwary, E. Torassa, K. Trabelsi, I. Tsaklidis, M. Uchida, I. Ueda, K. Unger, Y. Unno, K. Uno, S. Uno, P. Urquijo, Y. Ushiroda, S. E. Vahsen, R. van Tonder, M. Veronesi, A. Vinokurova, V. S. Vismaya, L. Vitale, V. Vobbilisetti, R. Volpe, A. Vossen, M. Wakai, S. Wallner, M. -Z. Wang, X. L. Wang, Z. Wang, A. Warburton, M. Watanabe, S. Watanuki, C. Wessel, E. Won, X. P. Xu, B. D. Yabsley, S. Yamada, S. B. Yang, J. Yelton, J. H. Yin, K. Yoshihara, C. Z. Yuan, J. Yuan, L. Zani, F. Zeng, B. Zhang, J. S. Zhou, Q. D. Zhou, L. Zhu, V. I. Zhukova, R. Zlebck, S. Zou","Using data samples of 102 million Upsilon(1S) events and 158 million
Upsilon(2S) events collected by the Belle detector at the KEKB
asymmetric-energy $e^+e^-$ collider, we search for [udsccbar] pentaquark states
decaying to Jpsi Lambda. Using the first observations of Upsilon(1S, 2S)
inclusive decays to Jpsi Lambda, we find evidence of the P_ccbars(4459)0 state
with a significance of 3.3 standard deviations, including statistical and
systematic uncertainties. We measure the mass and width of the Pccbars(4459)0
to be (4471.7 +- 4.8 +- 0.6) MeV/c2 and (21.9 +- 13.1 +- 2.7) MeV,
respectively. The branching fractions for P_ccbars(4459)0 production are
measured to be B[Upsilon(1S) -> P_ccbars(4459)0/ Pbar_ccbars(4459)0 + anything]
= (3.5 +- 2.0 +- 0.2)*10-6 and B[Upsilin(2S) -> P_ccbars(4459)0/
Pbar_ccbars(4459)0 +anything] = (2.9 +- 1.7 +- 0.4)*10-6. The inclusive
branching fractions of Upsilon(1S, 2S) -> Jpsi Lambda/Lambdabar are measured to
be B[Upsilin(1S) -> Jpsi Lambda/Lambdabar + anything] = (36.9 +- 5.3 +-
2.4)*10-6 and B[Upsilon(2S) -> Jpsi Lambda/Lambdabar + anything] = (22.3 +- 5.7
+- 3.1)*10-6. We measure the visible cross section $\sigma(e^+e^- \to J/psi
\Lambda/\bar\Lambda$ + anything) = (90 +- 14 +- 6) fb for the continuum
production at $\sqrt{s} = 10.52$ GeV. In all cases, the first uncertainties are
statistical and the second are systematic.",http://arxiv.org/abs/2502.09951v1
"A Luminous Red Optical Flare and Hard X-ray Emission in the Tidal
  Disruption Event AT2024kmq",2025-02-11T19:00:02Z,"Anna Y. Q. Ho, Yuhan Yao, Tatsuya Matsumoto, Genevieve Schroeder, Eric Coughlin, Daniel A. Perley, Igor Andreoni, Eric C. Bellm, Tracy X. Chen, Ryan Chornock, Sofia Covarrubias, Kaustav Das, Christoffer Fremling, Marat Gilfanov, K. R. Hinds, Dan Jarvis, Mansi M. Kasliwal, Chang Liu, Joseph D. Lyman, Frank J. Masci, Thomas A. Prince, Vikram Ravi, R. Michael Rich, Reed Riddle, Jason Sevilla, Roger Smith, Jesper Sollerman, Jean J. Somalwar, Gokul P. Srinivasaragavan, Rashid Sunyaev, Jada L. Vail, Jacob L. Wise, Sol Bin Yun","We present the optical discovery and multiwavelength follow-up observations
of AT2024kmq, a likely tidal disruption event (TDE) associated with a
supermassive ($M_{\rm BH}\sim 10^{8} M_\odot$) black hole in a massive galaxy
at $z=0.192$. The optical light curve of AT2024kmq exhibits two distinct peaks:
an early fast (timescale 1 d) and luminous ($M\approx-20$ mag) red peak, then a
slower (timescale 1 month) blue peak with a higher optical luminosity
($M\approx-22$ mag) and featureless optical spectra. The second component is
similar to the spectroscopic class of ""featureless TDEs"" in the literature, and
during this second component we detect highly variable, luminous ($L_X\approx
10^{44}$ erg s$^{-1}$), and hard ($f_\nu \propto \nu^{-1.5}$) X-ray emission.
Luminous ($10^{29} $erg s$^{-1}$ Hz$^{-1}$ at 10 GHz) but unchanging radio
emission likely arises from an underlying active galactic nucleus. The
luminosity, timescale, and color of the early red optical peak can be explained
by synchrotron emission, or alternatively by thermal emission from material at
a large radius ($R\approx\mathrm{few}\times10^{15}$ cm). Possible physical
origins for this early red component include an off-axis relativistic jet, and
shocks from self-intersecting debris leading to the formation of the accretion
disk. Late-time radio observations will help distinguish between the two
possibilities.",http://arxiv.org/abs/2502.07885v1
"Step-Audio: Unified Understanding and Generation in Intelligent Speech
  Interaction",2025-02-17T15:58:56Z,"Ailin Huang, Boyong Wu, Bruce Wang, Chao Yan, Chen Hu, Chengli Feng, Fei Tian, Feiyu Shen, Jingbei Li, Mingrui Chen, Peng Liu, Ruihang Miao, Wang You, Xi Chen, Xuerui Yang, Yechang Huang, Yuxiang Zhang, Zheng Gong, Zixin Zhang, Hongyu Zhou, Jianjian Sun, Brian Li, Chengting Feng, Changyi Wan, Hanpeng Hu, Jianchang Wu, Jiangjie Zhen, Ranchen Ming, Song Yuan, Xuelin Zhang, Yu Zhou, Bingxin Li, Buyun Ma, Hongyuan Wang, Kang An, Wei Ji, Wen Li, Xuan Wen, Xiangwen Kong, Yuankai Ma, Yuanwei Liang, Yun Mou, Bahtiyar Ahmidi, Bin Wang, Bo Li, Changxin Miao, Chen Xu, Chenrun Wang, Dapeng Shi, Deshan Sun, Dingyuan Hu, Dula Sai, Enle Liu, Guanzhe Huang, Gulin Yan, Heng Wang, Haonan Jia, Haoyang Zhang, Jiahao Gong, Junjing Guo, Jiashuai Liu, Jiahong Liu, Jie Feng, Jie Wu, Jiaoren Wu, Jie Yang, Jinguo Wang, Jingyang Zhang, Junzhe Lin, Kaixiang Li, Lei Xia, Li Zhou, Liang Zhao, Longlong Gu, Mei Chen, Menglin Wu, Ming Li, Mingxiao Li, Mingliang Li, Mingyao Liang, Na Wang, Nie Hao, Qiling Wu, Qinyuan Tan, Ran Sun, Shuai Shuai, Shaoliang Pang, Shiliang Yang, Shuli Gao, Shanshan Yuan, Siqi Liu, Shihong Deng, Shilei Jiang, Sitong Liu, Tiancheng Cao, Tianyu Wang, Wenjin Deng, Wuxun Xie, Weipeng Ming, Wenqing He, Wen Sun, Xin Han, Xin Huang, Xiaomin Deng, Xiaojia Liu, Xin Wu, Xu Zhao, Yanan Wei, Yanbo Yu, Yang Cao, Yangguang Li, Yangzhen Ma, Yanming Xu, Yaoyu Wang, Yaqiang Shi, Yilei Wang, Yizhuang Zhou, Yinmin Zhong, Yang Zhang, Yaoben Wei, Yu Luo, Yuanwei Lu, Yuhe Yin, Yuchu Luo, Yuanhao Ding, Yuting Yan, Yaqi Dai, Yuxiang Yang, Zhe Xie, Zheng Ge, Zheng Sun, Zhewei Huang, Zhichao Chang, Zhisheng Guan, Zidong Yang, Zili Zhang, Binxing Jiao, Daxin Jiang, Heung-Yeung Shum, Jiansheng Chen, Jing Li, Shuchang Zhou, Xiangyu Zhang, Xinhao Zhang, Yibo Zhu","Real-time speech interaction, serving as a fundamental interface for
human-machine collaboration, holds immense potential. However, current
open-source models face limitations such as high costs in voice data
collection, weakness in dynamic control, and limited intelligence. To address
these challenges, this paper introduces Step-Audio, the first production-ready
open-source solution. Key contributions include: 1) a 130B-parameter unified
speech-text multi-modal model that achieves unified understanding and
generation, with the Step-Audio-Chat version open-sourced; 2) a generative
speech data engine that establishes an affordable voice cloning framework and
produces the open-sourced lightweight Step-Audio-TTS-3B model through
distillation; 3) an instruction-driven fine control system enabling dynamic
adjustments across dialects, emotions, singing, and RAP; 4) an enhanced
cognitive architecture augmented with tool calling and role-playing abilities
to manage complex tasks effectively. Based on our new StepEval-Audio-360
evaluation benchmark, Step-Audio achieves state-of-the-art performance in human
evaluations, especially in terms of instruction following. On open-source
benchmarks like LLaMA Question, shows 9.3% average performance improvement,
demonstrating our commitment to advancing the development of open-source
multi-modal language technologies. Our code and models are available at
https://github.com/stepfun-ai/Step-Audio.",http://arxiv.org/abs/2502.11946v2
"Search for the FCNC charmonium decay $J/ψ\to D^0 μ^+ μ^- +
  \text{c.c.}$",2025-01-14T12:45:57Z,"BESIII Collaboration, M. Ablikim, M. N. Achasov, P. Adlarson, X. C. Ai, R. Aliberti, A. Amoroso, Q. An, Y. Bai, O. Bakina, Y. Ban, H. -R. Bao, V. Batozskaya, K. Begzsuren, N. Berger, M. Berlowski, M. Bertani, D. Bettoni, F. Bianchi, E. Bianco, A. Bortone, I. Boyko, R. A. Briere, A. Brueggemann, H. Cai, M. H. Cai, X. Cai, A. Calcaterra, G. F. Cao, N. Cao, S. A. Cetin, X. Y. Chai, J. F. Chang, G. R. Che, Y. Z. Che, G. Chelkov, C. Chen, C. H. Chen, Chao Chen, G. Chen, H. S. Chen, H. Y. Chen, M. L. Chen, S. J. Chen, S. L. Chen, S. M. Chen, T. Chen, X. R. Chen, X. T. Chen, Y. B. Chen, Y. Q. Chen, Z. J. Chen, Z. K. Chen, S. K. Choi, X. Chu, G. Cibinetto, F. Cossio, J. J. Cui, H. L. Dai, J. P. Dai, A. Dbeyssi, R. E. de Boer, D. Dedovich, C. Q. Deng, Z. Y. Deng, A. Denig, I. Denysenko, M. Destefanis, F. De Mori, B. Ding, X. X. Ding, Y. Ding, Y. Ding, Y. X. Ding, J. Dong, L. Y. Dong, M. Y. Dong, X. Dong, M. C. Du, S. X. Du, Y. Y. Duan, Z. H. Duan, P. Egorov, G. F. Fan, J. J. Fan, Y. H. Fan, J. Fang, J. Fang, S. S. Fang, W. X. Fang, Y. Q. Fang, R. Farinelli, L. Fava, F. Feldbauer, G. Felici, C. Q. Feng, J. H. Feng, Y. T. Feng, M. Fritsch, C. D. Fu, J. L. Fu, Y. W. Fu, H. Gao, X. B. Gao, Y. N. Gao, Y. N. Gao, Y. Y. Gao, Yang Gao, S. Garbolino, I. Garzia, P. T. Ge, Z. W. Ge, C. Geng, E. M. Gersabeck, A. Gilman, K. Goetzen, J. D. Gong, L. Gong, W. X. Gong, W. Gradl, S. Gramigna, M. Greco, M. H. Gu, Y. T. Gu, C. Y. Guan, A. Q. Guo, L. B. Guo, M. J. Guo, R. P. Guo, Y. P. Guo, A. Guskov, J. Gutierrez, K. L. Han, T. T. Han, F. Hanisch, K. D. Hao, X. Q. Hao, F. A. Harris, K. K. He, K. L. He, F. H. Heinsius, C. H. Heinz, Y. K. Heng, C. Herold, T. Holtmann, P. C. Hong, G. Y. Hou, X. T. Hou, Y. R. Hou, Z. L. Hou, B. Y. Hu, H. M. Hu, J. F. Hu, Q. P. Hu, S. L. Hu, T. Hu, Y. Hu, Z. M. Hu, G. S. Huang, K. X. Huang, L. Q. Huang, P. Huang, X. T. Huang, Y. P. Huang, Y. S. Huang, T. Hussain, N. Hüsken, N. in der Wiesche, J. Jackson, S. Janchiv, Q. Ji, Q. P. Ji, W. Ji, X. B. Ji, X. L. Ji, Y. Y. Ji, Z. K. Jia, D. Jiang, H. B. Jiang, P. C. Jiang, S. J. Jiang, T. J. Jiang, X. S. Jiang, Y. Jiang, J. B. Jiao, J. K. Jiao, Z. Jiao, S. Jin, Y. Jin, M. Q. Jing, X. M. Jing, T. Johansson, S. Kabana, N. Kalantar-Nayestanaki, X. L. Kang, X. S. Kang, M. Kavatsyuk, B. C. Ke, V. Khachatryan, A. Khoukaz, R. Kiuchi, O. B. Kolcu, B. Kopf, M. Kuessner, X. Kui, N. Kumar, A. Kupsc, W. Kühn, Q. Lan, W. N. Lan, T. T. Lei, M. Lellmann, T. Lenz, C. Li, C. Li, C. H. Li, C. K. Li, Cheng Li, D. M. Li, F. Li, G. Li, H. B. Li, H. J. Li, H. N. Li, Hui Li, J. R. Li, J. S. Li, K. Li, K. L. Li, K. L. Li, L. J. Li, Lei Li, M. H. Li, M. R. Li, P. L. Li, P. R. Li, Q. M. Li, Q. X. Li, R. Li, T. Li, T. Y. Li, W. D. Li, W. G. Li, X. Li, X. H. Li, X. L. Li, X. Y. Li, X. Z. Li, Y. Li, Y. G. Li, Y. P. Li, Z. J. Li, Z. Y. Li, C. Liang, H. Liang, Y. F. Liang, Y. T. Liang, G. R. Liao, L. B. Liao, M. H. Liao, Y. P. Liao, J. Libby, A. Limphirat, C. C. Lin, C. X. Lin, D. X. Lin, L. Q. Lin, T. Lin, B. J. Liu, B. X. Liu, C. Liu, C. X. Liu, F. Liu, F. H. Liu, Feng Liu, G. M. Liu, H. Liu, H. B. Liu, H. H. Liu, H. M. Liu, Huihui Liu, J. B. Liu, J. J. Liu, K. Liu, K. Liu, K. Y. Liu, Ke Liu, L. Liu, L. C. Liu, Lu Liu, P. L. Liu, Q. Liu, S. B. Liu, T. Liu, W. K. Liu, W. M. Liu, W. T. Liu, X. Liu, X. Liu, X. Y. Liu, Y. Liu, Y. Liu, Y. Liu, Y. B. Liu, Z. A. Liu, Z. D. Liu, Z. Q. Liu, X. C. Lou, F. X. Lu, H. J. Lu, J. G. Lu, Y. Lu, Y. H. Lu, Y. P. Lu, Z. H. Lu, C. L. Luo, J. R. Luo, J. S. Luo, M. X. Luo, T. Luo, X. L. Luo, Z. Y. Lv, X. R. Lyu, Y. F. Lyu, Y. H. Lyu, F. C. Ma, H. Ma, H. L. Ma, J. L. Ma, L. L. Ma, L. R. Ma, Q. M. Ma, R. Q. Ma, R. Y. Ma, T. Ma, X. T. Ma, X. Y. Ma, Y. M. Ma, F. E. Maas, I. MacKay, M. Maggiora, S. Malde, Y. J. Mao, Z. P. Mao, S. Marcello, F. M. Melendi, Y. H. Meng, Z. X. Meng, J. G. Messchendorp, G. Mezzadri, H. Miao, T. J. Min, R. E. Mitchell, X. H. Mo, B. Moses, N. Yu. Muchnoi, J. Muskalla, Y. Nefedov, F. Nerling, L. S. Nie, I. B. Nikolaev, Z. Ning, S. Nisar, Q. L. Niu, W. D. Niu, S. L. Olsen, Q. Ouyang, S. Pacetti, X. Pan, Y. Pan, A. Pathak, Y. P. Pei, M. Pelizaeus, H. P. Peng, Y. Y. Peng, K. Peters, J. L. Ping, R. G. Ping, S. Plura, V. Prasad, F. Z. Qi, H. R. Qi, M. Qi, S. Qian, W. B. Qian, C. F. Qiao, J. H. Qiao, J. J. Qin, J. L. Qin, L. Q. Qin, L. Y. Qin, P. B. Qin, X. P. Qin, X. S. Qin, Z. H. Qin, J. F. Qiu, Z. H. Qu, C. F. Redmer, A. Rivetti, M. Rolo, G. Rong, S. S. Rong, F. Rosini, Ch. Rosner, M. Q. Ruan, S. N. Ruan, N. Salone, A. Sarantsev, Y. Schelhaas, K. Schoenning, M. Scodeggio, K. Y. Shan, W. Shan, X. Y. Shan, Z. J. Shang, J. F. Shangguan, L. G. Shao, M. Shao, C. P. Shen, H. F. Shen, W. H. Shen, X. Y. Shen, B. A. Shi, H. Shi, J. L. Shi, J. Y. Shi, S. Y. Shi, X. Shi, H. L. Song, J. J. Song, T. Z. Song, W. M. Song, Y. X. Song, S. Sosio, S. Spataro, F. Stieler, S. S Su, Y. J. Su, G. B. Sun, G. X. Sun, H. Sun, H. K. Sun, J. F. Sun, K. Sun, L. Sun, S. S. Sun, T. Sun, Y. C. Sun, Y. H. Sun, Y. J. Sun, Y. Z. Sun, Z. Q. Sun, Z. T. Sun, C. J. Tang, G. Y. Tang, J. Tang, L. F. Tang, M. Tang, Y. A. Tang, L. Y. Tao, M. Tat, J. X. Teng, J. Y. Tian, W. H. Tian, Y. Tian, Z. F. Tian, I. Uman, B. Wang, B. Wang, Bo Wang, C. Wang, Cong Wang, D. Y. Wang, H. J. Wang, J. J. Wang, K. Wang, L. L. Wang, L. W. Wang, M. Wang, M. Wang, N. Y. Wang, S. Wang, T. Wang, T. J. Wang, W. Wang, W. Wang, W. P. Wang, X. Wang, X. F. Wang, X. J. Wang, X. L. Wang, X. N. Wang, Y. Wang, Y. D. Wang, Y. F. Wang, Y. H. Wang, Y. L. Wang, Y. N. Wang, Y. Q. Wang, Yaqian Wang, Yi Wang, Yuan Wang, Z. Wang, Z. L. Wang, Z. L. Wang, Z. Q. Wang, Z. Y. Wang, D. H. Wei, H. R. Wei, F. Weidner, S. P. Wen, Y. R. Wen, U. Wiedner, G. Wilkinson, M. Wolke, C. Wu, J. F. Wu, L. H. Wu, L. J. Wu, Lianjie Wu, S. G. Wu, S. M. Wu, X. Wu, X. H. Wu, Y. J. Wu, Z. Wu, L. Xia, X. M. Xian, B. H. Xiang, T. Xiang, D. Xiao, G. Y. Xiao, H. Xiao, Y. L. Xiao, Z. J. Xiao, C. Xie, K. J. Xie, X. H. Xie, Y. Xie, Y. G. Xie, Y. H. Xie, Z. P. Xie, T. Y. Xing, C. F. Xu, C. J. Xu, G. F. Xu, H. Y. Xu, H. Y. Xu, M. Xu, Q. J. Xu, Q. N. Xu, W. L. Xu, X. P. Xu, Y. Xu, Y. Xu, Y. C. Xu, Z. S. Xu, H. Y. Yan, L. Yan, W. B. Yan, W. C. Yan, W. P. Yan, X. Q. Yan, H. J. Yang, H. L. Yang, H. X. Yang, J. H. Yang, R. J. Yang, T. Yang, Y. Yang, Y. F. Yang, Y. H. Yang, Y. Q. Yang, Y. X. Yang, Y. Z. Yang, M. Ye, M. H. Ye, Junhao Yin, Z. Y. You, B. X. Yu, C. X. Yu, G. Yu, J. S. Yu, M. C. Yu, T. Yu, X. D. Yu, Y. C. Yu, C. Z. Yuan, H. Yuan, J. Yuan, J. Yuan, L. Yuan, S. C. Yuan, Y. Yuan, Z. Y. Yuan, C. X. Yue, Ying Yue, A. A. Zafar, S. H. Zeng, X. Zeng, Y. Zeng, Y. J. Zeng, Y. J. Zeng, X. Y. Zhai, Y. H. Zhan, A. Q. Zhang, B. L. Zhang, B. X. Zhang, D. H. Zhang, G. Y. Zhang, G. Y. Zhang, H. Zhang, H. Zhang, H. C. Zhang, H. H. Zhang, H. Q. Zhang, H. R. Zhang, H. Y. Zhang, J. Zhang, J. Zhang, J. J. Zhang, J. L. Zhang, J. Q. Zhang, J. S. Zhang, J. W. Zhang, J. X. Zhang, J. Y. Zhang, J. Z. Zhang, Jianyu Zhang, L. M. Zhang, Lei Zhang, N. Zhang, P. Zhang, Q. Zhang, Q. Y. Zhang, R. Y. Zhang, S. H. Zhang, Shulei Zhang, X. M. Zhang, X. Y Zhang, X. Y. Zhang, Y. Zhang, Y. Zhang, Y. T. Zhang, Y. H. Zhang, Y. M. Zhang, Z. D. Zhang, Z. H. Zhang, Z. L. Zhang, Z. L. Zhang, Z. X. Zhang, Z. Y. Zhang, Z. Y. Zhang, Z. Z. Zhang, Zh. Zh. Zhang, G. Zhao, J. Y. Zhao, J. Z. Zhao, L. Zhao, Lei Zhao, M. G. Zhao, N. Zhao, R. P. Zhao, S. J. Zhao, Y. B. Zhao, Y. L. Zhao, Y. X. Zhao, Z. G. Zhao, A. Zhemchugov, B. Zheng, B. M. Zheng, J. P. Zheng, W. J. Zheng, X. R. Zheng, Y. H. Zheng, B. Zhong, X. Zhong, H. Zhou, J. Q. Zhou, J. Y. Zhou, S. Zhou, X. Zhou, X. K. Zhou, X. R. Zhou, X. Y. Zhou, Y. Z. Zhou, Z. C. Zhou, A. N. Zhu, J. Zhu, K. Zhu, K. J. Zhu, K. S. Zhu, L. Zhu, L. X. Zhu, S. H. Zhu, T. J. Zhu, W. D. Zhu, W. D. Zhu, W. J. Zhu, W. Z. Zhu, Y. C. Zhu, Z. A. Zhu, X. Y. Zhuang, J. H. Zou, J. Zu","Based on a data sample of $(10087 \pm 44) \times 10^6$ $J/\psi$ events taken
with the BESIII detector, we search for the flavor-changing neutral current
charmonium decay $J/\psi \to D^{0} \mu^{+} \mu^{-} + \text{c.c.}$. No
significant signal above the background is observed, and the upper limit on its
branching fraction is set to be $\mathcal{B}(J/\psi \to D^{0}\mu^{+}\mu^{-} +
\text{c.c.} ) < 1.1 \times 10^{-7}$ at the 90% confidence level. This marks the
first search for a flavor-changing neutral current charmonium decay involving
muons in the final state.",http://arxiv.org/abs/2501.08080v2
"A multi-frequency study of sub-parsec jets with the Event Horizon
  Telescope",2025-01-09T19:00:11Z,"Jan Röder, Maciek Wielgus, Andrei P. Lobanov, Thomas P. Krichbaum, Dhanya G. Nair, Sang-Sung Lee, Eduardo Ros, Vincent L. Fish, Lindy Blackburn, Chi-kwan Chan, Sara Issaoun, Michael Janssen, Michael D. Johnson, Sheperd S. Doeleman, Geoffrey C. Bower, Geoffrey B. Crew, Remo P. J. Tilanus, Tuomas Savolainen, C. M. Violette Impellizzeri, Antxon Alberdi, Anne-Kathrin Baczko, José L. Gómez, Ru-Sen Lu, Georgios F. Paraschos, Efthalia Traianou, Ciriaco Goddi, Daewon Kim, Mikhail Lisakov, Yuri Y. Kovalev, Petr A. Voitsik, Kirill V. Sokolovsky, Kazunori Akiyama, Ezequiel Albentosa-Ruíz, Walter Alef, Juan Carlos Algaba, Richard Anantua, Keiichi Asada, Rebecca Azulay, Uwe Bach, David Ball, Mislav Baloković, Bidisha Bandyopadhyay, John Barrett, Michi Bauböck, Bradford A. Benson, Dan Bintley, Raymond Blundell, Katherine L. Bouman, Michael Bremer, Christiaan D. Brinkerink, Roger Brissenden, Silke Britzen, Avery E. Broderick, Dominique Broguiere, Thomas Bronzwaer, Sandra Bustamante, Do-Young Byun, John E. Carlstrom, Chiara Ceccobello, Andrew Chael, Dominic O. Chang, Koushik Chatterjee, Shami Chatterjee, Ming-Tang Chen, Yongjun Chen, Xiaopeng Cheng, Ilje Cho, Pierre Christian, Nicholas S. Conroy, John E. Conway, James M. Cordes, Thomas M. Crawford, Alejandro Cruz-Osorio, Yuzhu Cui, Brandon Curd, Rohan Dahale, Jordy Davelaar, Mariafelicia De Laurentis, Roger Deane, Jessica Dempsey, Gregory Desvignes, Jason Dexter, Vedant Dhruv, Indu K. Dihingia, Sean Taylor Dougall, Sergio A. Dzib, Ralph P. Eatough, Razieh Emami, Heino Falcke, Joseph Farah, Edward Fomalont, H. Alyson Ford, Marianna Foschi, Raquel Fraga-Encinas, William T. Freeman, Per Friberg, Christian M. Fromm, Antonio Fuentes, Peter Galison, Charles F. Gammie, Roberto García, Olivier Gentaz, Boris Georgiev, Roman Gold, Arturo I. Gómez-Ruiz, Minfeng Gu, Mark Gurwell, Kazuhiro Hada, Daryl Haggard, Kari Haworth, Michael H. Hecht, Ronald Hesper, Dirk Heumann, Luis C. Ho, Paul Ho, Mareki Honma, Chih-Wei L. Huang, Lei Huang, David H. Hughes, Shiro Ikeda, Makoto Inoue, David J. James, Buell T. Jannuzi, Britton Jeter, Wu Jiang, Alejandra Jiménez-Rosales, Svetlana Jorstad, Abhishek V. Joshi, Taehyun Jung, Mansour Karami, Ramesh Karuppusamy, Tomohisa Kawashima, Garrett K. Keating, Mark Kettenis, Dong-Jin Kim, Jae-Young Kim, Jongsoo Kim, Junhan Kim, Motoki Kino, Jun Yi Koay, Prashant Kocherlakota, Yutaro Kofuji, Shoko Koyama, Carsten Kramer, Joana A. Kramer, Michael Kramer, Cheng-Yu Kuo, Noemi La Bella, Tod R. Lauer, Daeyoung Lee, Po Kin Leung, Aviad Levis, Zhiyuan Li, Rocco Lico, Greg Lindahl, Michael Lindqvist, Jun Liu, Kuo Liu, Elisabetta Liuzzo, Wen-Ping Lo, Laurent Loinard, Colin J. Lonsdale, Amy E. Lowitz, Nicholas R. MacDonald, Jirong Mao, Nicola Marchili, Sera Markoff, Daniel P. Marrone, Alan P. Marscher, Iván Martí-Vidal, Satoki Matsushita, Lynn D. Matthews, Lia Medeiros, Karl M. Menten, Daniel Michalik, Izumi Mizuno, Yosuke Mizuno, James M. Moran, Kotaro Moriyama, Monika Moscibrodzka, Wanga Mulaudzi, Cornelia Müller, Hendrik Müller, Alejandro Mus, Gibwa Musoke, Ioannis Myserlis, Andrew Nadolski, Hiroshi Nagai, Neil M. Nagar, Masanori Nakamura, Gopal Narayanan, Iniyan Natarajan, Antonios Nathanail, Santiago Navarro Fuentes, Joey Neilsen, Roberto Neri, Chunchong Ni, Aristeidis Noutsos, Michael A. Nowak, Junghwan Oh, Hiroki Okino, Héctor R. Olivares Sánchez, Gisela N. Ortiz-León, Tomoaki Oyama, Feryal özel, Daniel C. M. Palumbo, Jongho Park, Harriet Parsons, Nimesh Patel, Ue-Li Pen, Dominic W. Pesce, Vincent Piétu, Richard Plambeck, Aleksandar PopStefanija, Oliver Porth, Felix M. Pötzl, Ben Prather, Jorge A. Preciado-López, Giacomo Principe, Dimitrios Psaltis, Hung-Yi Pu, Venkatessh Ramakrishnan, Ramprasad Rao, Mark G. Rawlings, Angelo Ricarte, Bart Ripperda, Freek Roelofs, Alan Rogers, Cristina Romero-Cañizales, Arash Roshanineshat, Helge Rottmann, Alan L. Roy, Ignacio Ruiz, Chet Ruszczyk, Kazi L. J. Rygl, Salvador Sánchez, David Sánchez-Argüelles, Miguel Sánchez-Portal, Mahito Sasada, Kaushik Satapathy, F. Peter Schloerb, Jonathan Schonfeld, Karl-Friedrich Schuster, Lijing Shao, Zhiqiang Shen, Des Small, Bong Won Sohn, Jason SooHoo, León David Sosapanta Salas, Kamal Souccar, Joshua S. Stanway, He Sun, Fumie Tazaki, Alexandra J. Tetarenko, Paul Tiede, Michael Titus, Pablo Torne, Teresa Toscano, Tyler Trent, Sascha Trippe, Matthew Turk, Ilse van Bemmel, Huib J. van Langevelde, Daniel R. van Rossum, Jesse Vos, Jan Wagner, Derek Ward-Thompson, John Wardle, Jasmin E. Washington, Jonathan Weintroub, Robert Wharton, Kaj Wiik, Gunther Witzel, Michael F. Wondrak, George N. Wong, Qingwen Wu, Nitika Yadlapalli, Paul Yamaguchi, Aristomenis Yfantis, Doosoo Yoon, André Young, Ken Young, Ziri Younsi, Wei Yu, Feng Yuan, Ye-Fei Yuan, J. Anton Zensus, Shuo Zhang, Guang-Yao Zhao, Shan-Shan Zhao","The 2017 observing campaign of the Event Horizon Telescope (EHT) delivered
the first very long baseline interferometry (VLBI) images at the observing
frequency of 230 GHz, leading to a number of unique studies on black holes and
relativistic jets from active galactic nuclei (AGN). In total, eighteen sources
were observed: the main science targets, Sgr A* and M87 along with various
calibrators. We investigated the morphology of the sixteen AGN in the EHT 2017
data set, focusing on the properties of the VLBI cores: size, flux density, and
brightness temperature. We studied their dependence on the observing frequency
in order to compare it with the Blandford-K\""onigl (BK) jet model. We modeled
the source structure of seven AGN in the EHT 2017 data set using linearly
polarized circular Gaussian components and collected results for the other nine
AGN from dedicated EHT publications, complemented by lower frequency data in
the 2-86 GHz range. Then, we studied the dependences of the VLBI core flux
density, size, and brightness temperature on the frequency measured in the AGN
host frame. We compared the observations with the BK jet model and estimated
the magnetic field strength dependence on the distance from the central black
hole. Our results indicate a deviation from the standard BK model, particularly
in the decrease of the brightness temperature with the observing frequency.
Either bulk acceleration of the jet material, energy transfer from the magnetic
field to the particles, or both are required to explain the observations.",http://arxiv.org/abs/2501.05518v1
The putative center in NGC 1052,2025-01-15T09:31:02Z,"Anne-Kathrin Baczko, Matthias Kadler, Eduardo Ros, Christian M. Fromm, Maciek Wielgus, Manel Perucho, Thomas P. Krichbaum, Mislav Baloković, Lindy Blackburn, Chi-kwan Chan, Sara Issaoun, Michael Janssen, Luca Ricci, Kazunori Akiyama, Ezequiel Albentosa-Ruíz, Antxon Alberdi, Walter Alef, Juan Carlos Algaba, Richard Anantua, Keiichi Asada, Rebecca Azulay, Uwe Bach, David Ball, Bidisha Bandyopadhyay, John Barrett, Michi Bauböck, Bradford A. Benson, Dan Bintley, Raymond Blundell, Katherine L. Bouman, Geoffrey C. Bower, Hope Boyce, Michael Bremer, Christiaan D. Brinkerink, Roger Brissenden, Silke Britzen, Avery E. Broderick, Dominique Broguiere, Thomas Bronzwaer, Sandra Bustamante, Do-Young Byun, John E. Carlstrom, Chiara Ceccobello, Andrew Chael, Dominic O. Chang, Koushik Chatterjee, Shami Chatterjee, Ming-Tang Chen, Yongjun Chen, Xiaopeng Cheng, Ilje Cho, Pierre Christian, Nicholas S. Conroy, John E. Conway, James M. Cordes, Thomas M. Crawford, Geoffrey B. Crew, Alejandro Cruz-Osorio, Yuzhu Cui, Rohan Dahale, Jordy Davelaar, Mariafelicia De Laurentis, Roger Deane, Jessica Dempsey, Gregory Desvignes, Jason Dexter, Vedant Dhruv, Indu K. Dihingia, Sheperd S. Doeleman, Sean Taylor Dougall, Sergio A. Dzib, Ralph P. Eatough, Razieh Emami, Heino Falcke, Joseph Farah, Vincent L. Fish, Edward Fomalont, H. Alyson Ford, Marianna Foschi, Raquel Fraga-Encinas, William T. Freeman, Per Friberg, Antonio Fuentes, Peter Galison, Charles F. Gammie, Roberto García, Olivier Gentaz, Boris Georgiev, Ciriaco Goddi, Roman Gold, Arturo I. Gómez-Ruiz, José L. Gómez, Minfeng Gu, Mark Gurwell, Kazuhiro Hada, Daryl Haggard, Kari Haworth, Michael H. Hecht, Ronald Hesper, Dirk Heumann, Luis C. Ho, Paul Ho, Mareki Honma, Chih-Wei L. Huang, Lei Huang, David H. Hughes, C. M. Violette Impellizzeri, Makoto Inoue, David J. James, Buell T. Jannuzi, Britton Jeter, Wu Jiang, Alejandra Jiménez-Rosales, Michael D. Johnson, Svetlana Jorstad, Abhishek V. Joshi, Taehyun Jung, Mansour Karami, Ramesh Karuppusamy, Tomohisa Kawashima, Garrett K. Keating, Mark Kettenis, Dong-Jin Kim, Jae-Young Kim, Jongsoo Kim, Junhan Kim, Motoki Kino, Jun Yi Koay, Prashant Kocherlakota, Yutaro Kofuji, Shoko Koyama, Carsten Kramer, Joana A. Kramer, Michael Kramer, Cheng-Yu Kuo, Noemi La Bella, Tod R. Lauer, Daeyoung Lee, Sang-Sung Lee, Po Kin Leung, Aviad Levis, Zhiyuan Li, Rocco Lico, Greg Lindahl, Michael Lindqvist, Mikhail Lisakov, Jun Liu, Kuo Liu, Elisabetta Liuzzo, Wen-Ping Lo, Andrei P. Lobanov, Laurent Loinard, Colin J. Lonsdale, Amy E. Lowitz, Ru-Sen Lu, Nicholas R. MacDonald, Jirong Mao, Nicola Marchili, Sera Markoff, Daniel P. Marrone, Alan P. Marscher, Iván Martí-Vidal, Satoki Matsushita, Lynn D. Matthews, Lia Medeiros, Karl M. Menten, Daniel Michalik, Izumi Mizuno, Yosuke Mizuno, James M. Moran, Kotaro Moriyama, Monika Moscibrodzka, Wanga Mulaudzi, Cornelia Müller, Hendrik Müller, Alejandro Mus, Gibwa Musoke, Ioannis Myserlis, Andrew Nadolski, Hiroshi Nagai, Neil M. Nagar, Dhanya G. Nair, Masanori Nakamura, Gopal Narayanan, Iniyan Natarajan, Antonios Nathanail, Santiago Navarro Fuentes, Joey Neilsen, Roberto Neri, Chunchong Ni, Aristeidis Noutsos, Michael A. Nowak, Junghwan Oh, Hiroki Okino, Héctor Raúl Olivares Sánchez, Gisela N. Ortiz-León, Tomoaki Oyama, Feryal Özel, Daniel C. M. Palumbo, Georgios Filippos Paraschos, Jongho Park, Harriet Parsons, Nimesh Patel, Ue-Li Pen, Dominic W. Pesce, Vincent Piétu, Richard Plambeck, Aleksandar PopStefanija, Oliver Porth, Felix M. Pötzl, Ben Prather, Jorge A. Preciado-López, Giacomo Principe, Dimitrios Psaltis, Hung-Yi Pu, Venkatessh Ramakrishnan, Ramprasad Rao, Mark G. Rawlings, Alexander W. Raymond, Angelo Ricarte, Bart Ripperda, Freek Roelofs, Alan Rogers, Cristina Romero-Cañizales, Arash Roshanineshat, Helge Rottmann, Alan L. Roy, Ignacio Ruiz, Chet Ruszczyk, Kazi L. J. Rygl, Salvador Sánchez, David Sánchez-Argüelles, Miguel Sánchez-Portal, Mahito Sasada, Kaushik Satapathy, Tuomas Savolainen, F. Peter Schloerb, Jonathan Schonfeld, Karl-Friedrich Schuster, Lijing Shao, Zhiqiang Shen, Des Small, Bong Won Sohn, Jason SooHoo, León David Sosapanta Salas, Kamal Souccar, Joshua S. Stanway, He Sun, Fumie Tazaki, Alexandra J. Tetarenko, Paul Tiede, Remo P. J. Tilanus, Michael Titus, Pablo Torne, Teresa Toscano, Efthalia Traianou, Tyler Trent, Sascha Trippe, Matthew Turk, Ilse van Bemmel, Huib Jan van Langevelde, Daniel R. van Rossum, Jesse Vos, Jan Wagner, Derek Ward-Thompson, John Wardle, Jasmin E. Washington, Jonathan Weintroub, Robert Wharton, Kaj Wiik, Gunther Witzel, Michael F. Wondrak, George N. Wong, Qingwen Wu, Nitika Yadlapalli, Paul Yamaguchi, Aristomenis Yfantis, Doosoo Yoon, André Young, Ken Young, Ziri Younsi, Wei Yu, Feng Yuan, Ye-Fei Yuan, J. Anton Zensus, Shuo Zhang, Guang-Yao Zhao","Many active galaxies harbor powerful relativistic jets, however, the detailed
mechanisms of their formation and acceleration remain poorly understood. To
investigate the area of jet acceleration and collimation with the highest
available angular resolution, we study the innermost region of the bipolar jet
in the nearby low-ionization nuclear emission-line region (LINER) galaxy NGC
1052. We combined observations of NGC 1052 taken with VLBA, GMVA, and EHT over
one week in the spring of 2017. For the first time, NGC 1052 was detected with
the EHT, providing a size of the central region in-between both jet bases of
250 RS (Schwarzschild radii) perpendicular to the jet axes. This size estimate
supports previous studies of the jets expansion profile which suggest two
breaks of the profile at around 300 RS and 10000 RS distances to the core.
Furthermore, we estimated the magnetic field to be 1.25 Gauss at a distance of
22 {\mu}as from the central engine by fitting a synchrotron-self absorption
spectrum to the innermost emission feature, which shows a spectral turn-over at
about 130 GHz. Assuming a purely poloidal magnetic field, this implies an upper
limit on the magnetic field strength at the event horizon of 26000 Gauss, which
is consistent with previous measurements. The complex, low-brightness,
double-sided jet structure in NGC 1052 makes it a challenge to detect the
source at millimeter (mm) wavelengths. However, our first EHT observations have
demonstrated that detection is possible up to at least 230 GHz. This study
offers a glimpse through the dense surrounding torus and into the innermost
central region, where the jets are formed. This has enabled us to finally
resolve this region and provide improved constraints on its expansion and
magnetic field strength.",http://arxiv.org/abs/2501.08685v1
"Measurement of $B^+\toτ^+ν_τ$ branching fraction with a hadronic
  tagging method at Belle II",2025-02-07T12:43:07Z,"Belle II Collaboration, I. Adachi, K. Adamczyk, H. Ahmed, Y. Ahn, H. Aihara, N. Akopov, M. Alhakami, A. Aloisio, N. Althubiti, M. Angelsmark, N. Anh Ky, D. M. Asner, H. Atmacan, V. Aushev, M. Aversano, R. Ayad, V. Babu, N. K. Baghel, S. Bahinipati, P. Bambade, Sw. Banerjee, M. Bartl, J. Baudot, A. Baur, A. Beaubien, F. Becherer, J. Becker, J. V. Bennett, F. U. Bernlochner, V. Bertacchi, E. Bertholet, M. Bessner, S. Bettarini, B. Bhuyan, F. Bianchi, A. Bobrov, D. Bodrov, A. Bondar, J. Borah, A. Boschetti, A. Bozek, M. Bračko, P. Branchini, R. A. Briere, T. E. Browder, A. Budano, S. Bussino, Q. Campagna, M. Campajola, L. Cao, G. Casarosa, C. Cecchi, M. -C. Chang, P. Cheema, K. Chilikin, K. Chirapatpimol, H. -E. Cho, K. Cho, S. -J. Cho, S. -K. Choi, S. Choudhury, J. Cochran, L. Corona, J. X. Cui, E. De La Cruz-Burelo, S. A. De La Motte, G. De Nardo, G. De Pietro, R. de Sangro, M. Destefanis, S. Dey, A. Di Canto, J. Dingfelder, Z. Doležal, T. V. Dong, M. Dorigo, K. Dugic, G. Dujany, P. Ecker, D. Epifanov, J. Eppelt, T. Ferber, T. Fillinger, C. Finck, G. Finocchiaro, A. Fodor, F. Forti, B. G. Fulsom, A. Gabrielli, L. Gärtner, A. Gale, M. Garcia-Hernandez, G. Gaudino, V. Gaur, A. Gaz, A. Gellrich, G. Ghevondyan, D. Ghosh, H. Ghumaryan, G. Giakoustidis, R. Giordano, A. Giri, P. Gironella Gironell, B. Gobbo, R. Godang, O. Gogota, P. Goldenzweig, W. Gradl, E. Graziani, D. Greenwald, Z. Gruberová, Y. Guan, K. Gudkova, I. Haide, H. Hayashii, S. Hazra, C. Hearty, I. Heredia de la Cruz, T. Higuchi, M. Hoek, M. Hohmann, R. Hoppe, P. Horak, C. -L. Hsu, A. Huang, T. Iijima, N. Ipsita, A. Ishikawa, R. Itoh, M. Iwasaki, P. Jackson, D. Jacobi, W. W. Jacobs, D. E. Jaffe, E. -J. Jang, Y. Jin, A. Johnson, K. K. Joo, H. Junkerkalefeld, J. Kandra, K. H. Kang, G. Karyan, T. Kawasaki, C. Ketter, C. Kiesling, D. Y. Kim, J. -Y. Kim, K. -H. Kim, H. Kindo, K. Kinoshita, P. Kodyš, T. Koga, S. Kohani, K. Kojima, A. Korobov, S. Korpar, E. Kovalenko, R. Kowalewski, P. Križan, P. Krokovny, T. Kuhr, D. Kumar, R. Kumar, K. Kumara, T. Kunigo, A. Kuzmin, Y. -J. Kwon, T. Lam, J. S. Lange, T. S. Lau, M. Laurenza, R. Leboucher, F. R. Le Diberder, M. J. Lee, P. Leo, L. K. Li, W. Z. Li, Y. Li, J. Libby, S. Lin, M. H. Liu, Q. Y. Liu, Z. Q. Liu, D. Liventsev, S. Longo, T. Lueck, C. Lyu, Y. Ma, C. Madaan, M. Maggiora, R. Maiti, G. Mancinelli, R. Manfredi, E. Manoni, M. Mantovano, D. Marcantonio, S. Marcello, C. Marinas, C. Martellini, A. Martens, T. Martinov, L. Massaccesi, M. Masuda, K. Matsuoka, S. K. Maurya, M. Maushart, J. A. McKenna, F. Meier, D. Meleshko, M. Merola, C. Miller, M. Mirra, K. Miyabayashi, R. Mizuk, S. Mondal, S. Moneta, H. -G. Moser, I. Nakamura, M. Nakao, H. Nakazawa, Z. Natkaniec, A. Natochii, M. Nayak, M. Neu, M. Niiyama, S. Nishida, S. Ogawa, R. Okubo, H. Ono, G. Pakhlova, S. Pardi, J. Park, K. Park, S. -H. Park, B. Paschen, S. Patra, S. Paul, T. K. Pedlar, I. Peruzzi, R. Peschke, L. E. Piilonen, T. Podobnik, S. Pokharel, C. Praz, S. Prell, E. Prencipe, M. T. Prim, S. Privalov, I. Prudiiev, H. Purwar, S. Raiz, K. Ravindran, J. U. Rehman, M. Reif, S. Reiter, M. Remnev, D. Ricalde Herrmann, I. Ripp-Baudot, G. Rizzo, S. H. Robertson, J. M. Roney, A. Rostomyan, N. Rout, D. A. Sanders, S. Sandilya, L. Santelj, V. Savinov, B. Scavino, C. Schmitt, J. Schmitz, S. Schneider, C. Schwanda, Y. Seino, K. Senyo, M. E. Sevior, C. Sfienti, W. Shan, X. D. Shi, T. Shillington, J. -G. Shiu, D. Shtol, A. Sibidanov, F. Simon, J. B. Singh, J. Skorupa, R. J. Sobie, M. Sobotzik, A. Soffer, A. Sokolov, E. Solovieva, S. Spataro, B. Spruck, M. Starič, S. Stefkova, R. Stroili, Y. Sue, M. Sumihama, M. Takizawa, F. Tenchini, A. Thaller, O. Tittel, R. Tiwary, E. Torassa, K. Trabelsi, I. Tsaklidis, I. Ueda, T. Uglov, K. Unger, K. Uno, S. Uno, P. Urquijo, Y. Ushiroda, S. E. Vahsen, R. van Tonder, K. E. Varvell, M. Veronesi, A. Vinokurova, V. S. Vismaya, V. Vobbilisetti, R. Volpe, S. Wallner, M. -Z. Wang, A. Warburton, S. Watanuki, C. Wessel, E. Won, X. P. Xu, B. D. Yabsley, S. Yamada, W. Yan, S. B. Yang, J. Yelton, J. H. Yin, K. Yoshihara, C. Z. Yuan, J. Yuan, L. Zani, F. Zeng, B. Zhang, V. Zhilich, Q. D. Zhou, L. Zhu, R. Žlebčík","We present a measurement of the branching fraction of $B^+\to\tau^+\nu_\tau$
decays using $(387\pm6)\times 10^6$ $\Upsilon(4S)$ collected between 2019 and
2022 with the Belle II detector at the SuperKEKB $e^+e^-$ collider. We
reconstruct the accompanying $B^-$ meson using the hadronic tagging method,
while $B^+\to\tau^+\nu_\tau$ candidates are identified in the recoil. We find
evidence for $B^+\to\tau^+\nu_\tau$ decays at 3.0 standard deviations,
including systematic uncertainties. The measured branching fraction is
$\mathcal{B}(B^+\to\tau^+\nu_\tau) = [1.24 \pm 0.41 (\text{stat.}) \pm 0.19
(\text{syst.})] \times 10^{-4}$.",http://arxiv.org/abs/2502.04885v1
"The X-ray Integral Field Unit at the end of the Athena reformulation
  phase",2025-02-15T17:49:35Z,"Philippe Peille, Didier Barret, Edoardo Cucchetti, Vincent Albouys, Luigi Piro, Aurora Simionescu, Massimo Cappi, Elise Bellouard, Céline Cénac-Morthé, Christophe Daniel, Alice Pradines, Alexis Finoguenov, Richard Kelley, J. Miguel Mas-Hesse, Stéphane Paltani, Gregor Rauw, Agata Rozanska, Jiri Svoboda, Joern Wilms, Marc Audard, Enrico Bozzo, Elisa Costantini, Mauro Dadina, Thomas Dauser, Anne Decourchelle, Jan-Willem den Herder, Andrea Goldwurm, Peter Jonker, Alex Markowitz, Mariano Mendez, Giovanni Miniutti, Silvano Molendi, Fabrizio Nicastro, François Pajot, Etienne Pointecouteau, Gabriel W. Pratt, Joop Schaye, Jacco Vink, Natalie Webb, Simon Bandler, Marco Barbera, Maria Teresa Ceballos, Ivan Charles, Roland den Hartog, W. Bertrand Doriese, Jean-Marc Duval, Flavio Gatti, Brian Jackson, Caroline Kilbourne, Claudio Macculi, Sylvain Martin, Yann Parot, Frederick Porter, Damien Prêle, Laurent Ravera, Stephen Smith, Jan Soucek, Tanguy Thibert, Eija Tuominen, Fabio Acero, Stefano Ettori, Nicolas Grosso, Jelle Kaastra, Pasquale Mazzotta, Jon Miller, Salvatore Sciortino, Sophie Beaumont, Matteo D'Andrea, Jelle de Plaa, Megan Eckart, Luciano Gottardi, Maurice Leutenegger, Simone Lotti, Alexei Molin, Lorenzo Natalucci, Muhammad Qazi Adil, Andrea Argan, Elisabetta Cavazzuti, Mauro Fiorini, Pourya Khosropanah, Eduardo Medinaceli Villegas, Gabriele Minervini, James Perry, Frederic Pinsard, Desi Raulin, Manuela Rigano, Peter Roelfsema, Denis Schwander, Santiago Terron, Guido Torrioli, Joel Ullom, Monika Zuchniak, Laurence Chaoul, Jose Miguel Torrejon, Frank Brachet, Beatriz Cobo, Malcolm Durkin, Valentina Fioretti, Hervé Geoffray, Lionel Jacques, Christian Kirsch, Ugo Lo Cicero, Joseph Adams, Emilie Gloaguen, Manuel Gonzalez, Samuel Hull, Erik Jellyman, Mikko Kiviranta, Kazuhiro Sakai, Emanuele Taralli, Davide Vaccaro, Paul van der Hulst, Jan van der Kuur, Bert-Joost van Leeuwen, Dennis van Loon, Nicholas Wakeham, Natalia Auricchio, Daniele Brienza, Oscar Cheatom, Philippe Franssen, Sabine Julien, Isabelle Le Mer, David Moirin, Vitor Silva, Michela Todaro, Nicolas Clerc, Alexis Coleiro, Andy Ptak, Simonetta Puccetti, Christian Surace, Shariefa Abdoelkariem, Christophe Adami, Corinne Aicardi, Jérôme André, Matteo Angelinelli, Shebli Anvar, Luis Horacio Arnaldi, Anthony Attard, Damian Audley, Florian Bancel, Kimberly Banks, Vivian Bernard, Jan Geralt Bij de Vaate, Donata Bonino, Anthony Bonnamy, Patrick Bonny, Charles Boreux, Ayoub Bounab, Maïmouna Brigitte, Marcel Bruijn, Clément Brysbaert, Andrea Bulgarelli, Simona Calarco, Thierry Camus, Florent Canourgues, Vito Capobianco, Nicolas Cardiel, Edvige Celasco, Si Chen, James Chervenak, Fabio Chiarello, Sébastien Clamagirand, Odile Coeur-Joly, Leonardo Corcione, Mickael Coriat, Anais Coulet, Bernard Courty, Alexandre Coynel, Antonino D'Ai, Eugenio Dambrauskas, Fabio D'anca, Lea Dauner, Matteo De Gerone, Natalie DeNigris, Johannes Dercksen, Martin de Wit, Pieter Dieleman, Michael DiPirro, Eric Doumayrou, Lionel Duband, Luc Dubbeldam, Michel Dupieux, Simon Dupourqué, Jean Louis Durand, Dominique Eckert, Philippe Ferrando, Lorenzo Ferrari Barusso, Fred Finkbeiner, Mariateresa Fiocchi, Hervé Fossecave, Stefano Gabici, Giovanni Gallucci, Florent Gant, Jian-Rong Gao, Fabio Gastaldello, Ludovic Genolet, Simona Ghizzardi, Elisa Giovannini, Margherita Giustini, Alain Givaudan, Olivier Godet, Alicia Gomez, Raoul Gonzalez, Ghassem Gozaliasl, Laurent Grandsire, David Granena, Michel Gros, Corentin Guerin, Emmanuel Guilhem, Gian Paolo Guizzo, Liyi Gu, Kent Irwin, Christian Jacquey, Agnieszka Janiuk, Jean Jaubert, Antoine Jolly, Thierry Jourdan, Jürgen Knödlseder, Ole König, Andrew Korb, Ingo Kreykenbohm, David Lafforgue, Radek Lan, Maélyss Larrieu, Philippe Laudet, Philippe Laurent, Sylvain Laurent, Monica Laurenza, Maël Le Cam, Jean Lesrel, Sebastiano Ligori, Maximilian Lorenz, Alfredo Luminari, Kristin Madsen, Océane Maisonnave, Lorenzo Marelli, Wilfried Marty, Zoé Massida, Didier Massonet, Irwin Maussang, Pablo Eleazar Merino Alonso, Jean Mesquida, Teresa Mineo, Nicola Montinaro, David Murat, Kenichiro Nagayoshi, Yaël Nazé, Loïc Noguès, François Nouals, Cristina Ortega, Francesca Panessa, Luigi Parodi, Enrico Piconcelli, Ciro Pinto, Delphine Porquet, Thomas Prouvé, Michael Punch, Guillaume Rioland, Marc-Olivier Riollet, Louis Rodriguez, Anton Roig, Mauro Roncarelli, Lionel Roucayrol, Gilles Roudil, Lander Ruiz de Ocenda, Luisa Sciortino, Olivier Simonella, Michael Sordet, Ulrich Taubenschuss, Guilhem Terrasa, Régis Terrier, Pietro Ubertini, Ludek Uhlir, Michela Uslenghi, Henk van Weers, Salvatore Varisco, Peggy Varniere, Angela Volpe, Gavin Walmsley, Michael Wise, Andreas Wolnievik, Grzegorz Woźniak","The Athena mission entered a redefinition phase in July 2022, driven by the
imperative to reduce the mission cost at completion for the European Space
Agency below an acceptable target, while maintaining the flagship nature of its
science return. This notably called for a complete redesign of the X-ray
Integral Field Unit (X-IFU) cryogenic architecture towards a simpler active
cooling chain. Passive cooling via successive radiative panels at spacecraft
level is now used to provide a 50 K thermal environment to an X-IFU owned
cryostat. 4.5 K cooling is achieved via a single remote active cryocooler unit,
while a multi-stage Adiabatic Demagnetization Refrigerator ensures heat lift
down to the 50 mK required by the detectors. Amidst these changes, the core
concept of the readout chain remains robust, employing Transition Edge Sensor
microcalorimeters and a SQUID-based Time-Division Multiplexing scheme.
Noteworthy is the introduction of a slower pixel. This enables an increase in
the multiplexing factor (from 34 to 48) without compromising the instrument
energy resolution, hence keeping significant system margins to the new 4 eV
resolution requirement. This allows reducing the number of channels by more
than a factor two, and thus the resource demands on the system, while keeping a
4' field of view (compared to 5' before). In this article, we will give an
overview of this new architecture, before detailing its anticipated
performances. Finally, we will present the new X-IFU schedule, with its short
term focus on demonstration activities towards a mission adoption in early
2027.",http://arxiv.org/abs/2502.10866v1
"Search for $η_c(2S)\to p\bar{p}K^+K^-$ and measurement of
  $χ_{cJ}\to p\bar{p}K^+K^-$ in $ψ(3686)$ radiative decays",2025-01-03T06:33:43Z,"M. Ablikim, M. N. Achasov, P. Adlarson, O. Afedulidis, X. C. Ai, R. Aliberti, A. Amoroso, Y. Bai, O. Bakina, I. Balossino, Y. Ban, H. -R. Bao, V. Batozskaya, K. Begzsuren, N. Berger, M. Berlowski, M. Bertani, D. Bettoni, F. Bianchi, E. Bianco, A. Bortone, I. Boyko, R. A. Briere, A. Brueggemann, H. Cai, X. Cai, A. Calcaterra, G. F. Cao, N. Cao, S. A. Cetin, X. Y. Chai, J. F. Chang, G. R. Che, Y. Z. Che, G. Chelkov, C. Chen, C. H. Chen, Chao Chen, G. Chen, H. S. Chen, H. Y. Chen, M. L. Chen, S. J. Chen, S. L. Chen, S. M. Chen, T. Chen, X. R. Chen, X. T. Chen, Y. B. Chen, Y. Q. Chen, Z. J. Chen, S. K. Choi, G. Cibinetto, F. Cossio, J. J. Cui, H. L. Dai, J. P. Dai, A. Dbeyssi, R. E. de Boer, D. Dedovich, C. Q. Deng, Z. Y. Deng, A. Denig, I. Denysenko, M. Destefanis, F. De Mori, B. Ding, X. X. Ding, Y. Ding, Y. Ding, J. Dong, L. Y. Dong, M. Y. Dong, X. Dong, M. C. Du, S. X. Du, Y. Y. Duan, Z. H. Duan, P. Egorov, G. F. Fan, J. J. Fan, Y. H. Fan, J. Fang, J. Fang, S. S. Fang, W. X. Fang, Y. Q. Fang, R. Farinelli, L. Fava, F. Feldbauer, G. Felici, C. Q. Feng, J. H. Feng, Y. T. Feng, M. Fritsch, C. D. Fu, J. L. Fu, Y. W. Fu, H. Gao, X. B. Gao, Y. N. Gao, Y. N. Gao, Yang Gao, S. Garbolino, I. Garzia, P. T. Ge, Z. W. Ge, C. Geng, E. M. Gersabeck, A. Gilman, K. Goetzen, L. Gong, W. X. Gong, W. Gradl, S. Gramigna, M. Greco, M. H. Gu, Y. T. Gu, C. Y. Guan, A. Q. Guo, L. B. Guo, M. J. Guo, R. P. Guo, Y. P. Guo, A. Guskov, J. Gutierrez, K. L. Han, T. T. Han, F. Hanisch, X. Q. Hao, F. A. Harris, K. K. He, K. L. He, F. H. Heinsius, C. H. Heinz, Y. K. Heng, C. Herold, T. Holtmann, P. C. Hong, G. Y. Hou, X. T. Hou, Y. R. Hou, Z. L. Hou, B. Y. Hu, H. M. Hu, J. F. Hu, Q. P. Hu, S. L. Hu, T. Hu, Y. Hu, G. S. Huang, K. X. Huang, L. Q. Huang, P. Huang, X. T. Huang, Y. P. Huang, Y. S. Huang, T. Hussain, F. H""olzken, N. H""usken, N. in der Wiesche, J. Jackson, S. Janchiv, Q. Ji, Q. P. Ji, W. Ji, X. B. Ji, X. L. Ji, Y. Y. Ji, X. Q. Jia, Z. K. Jia, D. Jiang, H. B. Jiang, P. C. Jiang, S. S. Jiang, T. J. Jiang, X. S. Jiang, Y. Jiang, J. B. Jiao, J. K. Jiao, Z. Jiao, S. Jin, Y. Jin, M. Q. Jing, X. M. Jing, T. Johansson, S. Kabana, N. Kalantar-Nayestanaki, X. L. Kang, X. S. Kang, M. Kavatsyuk, B. C. Ke, V. Khachatryan, A. Khoukaz, R. Kiuchi, O. B. Kolcu, B. Kopf, M. Kuessner, X. Kui, N. Kumar, A. Kupsc, W. K""uhn, W. N. Lan, T. T. Lei, Z. H. Lei, M. Lellmann, T. Lenz, C. Li, C. Li, C. H. Li, Cheng Li, D. M. Li, F. Li, G. Li, H. B. Li, H. J. Li, H. N. Li, Hui Li, J. R. Li, J. S. Li, K. Li, K. L. Li, L. J. Li, Lei Li, M. H. Li, P. L. Li, P. R. Li, Q. M. Li, Q. X. Li, R. Li, T. Li, T. Y. Li, W. D. Li, W. G. Li, X. Li, X. H. Li, X. L. Li, X. Y. Li, X. Z. Li, Y. Li, Y. G. Li, Z. J. Li, Z. Y. Li, C. Liang, H. Liang, Y. F. Liang, Y. T. Liang, G. R. Liao, Y. P. Liao, J. Libby, A. Limphirat, C. C. Lin, C. X. Lin, D. X. Lin, T. Lin, B. J. Liu, B. X. Liu, C. Liu, C. X. Liu, F. Liu, F. H. Liu, Feng Liu, G. M. Liu, H. Liu, H. B. Liu, H. H. Liu, H. M. Liu, Huihui Liu, J. B. Liu, K. Liu, K. Y. Liu, Ke Liu, L. Liu, L. C. Liu, Lu Liu, M. H. Liu, P. L. Liu, Q. Liu, S. B. Liu, T. Liu, W. K. Liu, W. M. Liu, X. Liu, X. Liu, Y. Liu, Y. Liu, Y. B. Liu, Z. A. Liu, Z. D. Liu, Z. Q. Liu, X. C. Lou, F. X. Lu, H. J. Lu, J. G. Lu, Y. Lu, Y. P. Lu, Z. H. Lu, C. L. Luo, J. R. Luo, M. X. Luo, T. Luo, X. L. Luo, X. R. Lyu, Y. F. Lyu, F. C. Ma, H. Ma, H. L. Ma, J. L. Ma, L. L. Ma, L. R. Ma, Q. M. Ma, R. Q. Ma, R. Y. Ma, T. Ma, X. T. Ma, X. Y. Ma, Y. M. Ma, F. E. Maas, I. MacKay, M. Maggiora, S. Malde, Y. J. Mao, Z. P. Mao, S. Marcello, Y. H. Meng, Z. X. Meng, J. G. Messchendorp, G. Mezzadri, H. Miao, T. J. Min, R. E. Mitchell, X. H. Mo, B. Moses, N. Yu. Muchnoi, J. Muskalla, Y. Nefedov, F. Nerling, L. S. Nie, I. B. Nikolaev, Z. Ning, S. Nisar, Q. L. Niu, W. D. Niu, Y. Niu, S. L. Olsen, Q. Ouyang, S. Pacetti, X. Pan, Y. Pan, A. Pathak, Y. P. Pei, M. Pelizaeus, H. P. Peng, Y. Y. Peng, K. Peters, J. L. Ping, R. G. Ping, S. Plura, V. Prasad, F. Z. Qi, H. R. Qi, M. Qi, S. Qian, W. B. Qian, C. F. Qiao, J. H. Qiao, J. J. Qin, L. Q. Qin, L. Y. Qin, X. P. Qin, X. S. Qin, Z. H. Qin, J. F. Qiu, Z. H. Qu, C. F. Redmer, K. J. Ren, A. Rivetti, M. Rolo, G. Rong, Ch. Rosner, M. Q. Ruan, S. N. Ruan, N. Salone, A. Sarantsev, Y. Schelhaas, K. Schoenning, M. Scodeggio, K. Y. Shan, W. Shan, X. Y. Shan, Z. J. Shang, J. F. Shangguan, L. G. Shao, M. Shao, C. P. Shen, H. F. Shen, W. H. Shen, X. Y. Shen, B. A. Shi, H. Shi, J. L. Shi, J. Y. Shi, S. Y. Shi, X. Shi, J. J. Song, T. Z. Song, W. M. Song, Y. J. Song, Y. X. Song, S. Sosio, S. Spataro, F. Stieler, S. S Su, Y. J. Su, G. B. Sun, G. X. Sun, H. Sun, H. K. Sun, J. F. Sun, K. Sun, L. Sun, S. S. Sun, T. Sun, Y. J. Sun, Y. Z. Sun, Z. Q. Sun, Z. T. Sun, C. J. Tang, G. Y. Tang, J. Tang, M. Tang, Y. A. Tang, L. Y. Tao, M. Tat, J. X. Teng, V. Thoren, W. H. Tian, Y. Tian, Z. F. Tian, I. Uman, Y. Wan, S. J. Wang, B. Wang, Bo Wang, C. Wang, D. Y. Wang, H. J. Wang, J. J. Wang, J. P. Wang, K. Wang, L. L. Wang, L. W. Wang, M. Wang, N. Y. Wang, S. Wang, S. Wang, T. Wang, T. J. Wang, W. Wang, W. Wang, W. P. Wang, X. Wang, X. F. Wang, X. J. Wang, X. L. Wang, X. N. Wang, Y. Wang, Y. D. Wang, Y. F. Wang, Y. H. Wang, Y. L. Wang, Y. N. Wang, Y. Q. Wang, Yaqian Wang, Yi Wang, Z. Wang, Z. L. Wang, Z. Y. Wang, D. H. Wei, F. Weidner, S. P. Wen, Y. R. Wen, U. Wiedner, G. Wilkinson, M. Wolke, L. Wollenberg, C. Wu, J. F. Wu, L. H. Wu, L. J. Wu, Lianjie Wu, X. Wu, X. H. Wu, Y. H. Wu, Y. J. Wu, Z. Wu, L. Xia, X. M. Xian, B. H. Xiang, T. Xiang, D. Xiao, G. Y. Xiao, H. Xiao, Y. L. Xiao, Z. J. Xiao, C. Xie, X. H. Xie, Y. Xie, Y. G. Xie, Y. H. Xie, Z. P. Xie, T. Y. Xing, C. F. Xu, C. J. Xu, G. F. Xu, M. Xu, Q. J. Xu, Q. N. Xu, W. L. Xu, X. P. Xu, Y. Xu, Y. C. Xu, Z. S. Xu, F. Yan, L. Yan, W. B. Yan, W. C. Yan, W. P. Yan, X. Q. Yan, H. J. Yang, H. L. Yang, H. X. Yang, J. H. Yang, R. J. Yang, T. Yang, Y. Yang, Y. F. Yang, Y. X. Yang, Y. Z. Yang, Z. W. Yang, Z. P. Yao, M. Ye, M. H. Ye, Junhao Yin, Z. Y. You, B. X. Yu, C. X. Yu, G. Yu, J. S. Yu, M. C. Yu, T. Yu, X. D. Yu, C. Z. Yuan, J. Yuan, J. Yuan, L. Yuan, S. C. Yuan, Y. Yuan, Z. Y. Yuan, C. X. Yue, Ying Yue, A. A. Zafar, F. R. Zeng, S. H. Zeng, X. Zeng, Y. Zeng, Y. J. Zeng, Y. J. Zeng, X. Y. Zhai, Y. C. Zhai, Y. H. Zhan, A. Q. Zhang, B. L. Zhang, B. X. Zhang, D. H. Zhang, G. Y. Zhang, H. Zhang, H. Zhang, H. C. Zhang, H. H. Zhang, H. Q. Zhang, H. R. Zhang, H. Y. Zhang, J. Zhang, J. Zhang, J. J. Zhang, J. L. Zhang, J. Q. Zhang, J. S. Zhang, J. W. Zhang, J. X. Zhang, J. Y. Zhang, J. Z. Zhang, Jianyu Zhang, L. M. Zhang, Lei Zhang, P. Zhang, Q. Zhang, Q. Y. Zhang, R. Y. Zhang, S. H. Zhang, Shulei Zhang, X. M. Zhang, X. Y Zhang, X. Y. Zhang, Y. Zhang, Y. Zhang, Y. T. Zhang, Y. H. Zhang, Y. M. Zhang, Yan Zhang, Z. D. Zhang, Z. H. Zhang, Z. L. Zhang, Z. X. Zhang, Z. Y. Zhang, Z. Y. Zhang, Z. Z. Zhang, Zh. Zh. Zhang, G. Zhao, J. Y. Zhao, J. Z. Zhao, L. Zhao, Lei Zhao, M. G. Zhao, N. Zhao, R. P. Zhao, S. J. Zhao, Y. B. Zhao, Y. X. Zhao, Z. G. Zhao, A. Zhemchugov, B. Zheng, B. M. Zheng, J. P. Zheng, W. J. Zheng, X. R. Zheng, Y. H. Zheng, B. Zhong, X. Zhong, H. Zhou, J. Y. Zhou, S. Zhou, X. Zhou, X. K. Zhou, X. R. Zhou, X. Y. Zhou, Y. Z. Zhou, Z. C. Zhou, A. N. Zhu, J. Zhu, K. Zhu, K. J. Zhu, K. S. Zhu, L. Zhu, L. X. Zhu, S. H. Zhu, T. J. Zhu, W. D. Zhu, W. Z. Zhu, Y. C. Zhu, Z. A. Zhu, J. H. Zou, J. Zu","A search for $\eta_c(2S)\to p\bar{p}K^+K^-$, together with measurement of
branching fractions of $\chi_{cJ(J=0,1,2)}\to p\bar{p}K^+K^-$ in the
$\psi(3686) \to \gamma \eta_c(2S)$ and the $\psi(3686) \to \gamma \chi_{cJ}$
radiative decays, is performed with $(2712.4\pm14.3)\times 10^6$ $\psi(3686)$
events collected with the BESIII detector at the BEPCII collider. An evidence
for $\eta_c(2S)\to p\bar{p}K^+K^-$ is found, with a significance of
$3.3\sigma$. The product branching fraction of
$\mathcal{B}[\psi(3686)\to\gamma\eta_c(2S)]\cdot\mathcal{B}[\eta_c(2S)\to
p\bar{p}K^+K^-]$ is determined to be $(1.98\mkern 2mu\pm\mkern
2mu0.41_{\text{stat.}}\mkern 2mu\pm\mkern 2mu0.99_{\text{syst.}})\times
10^{-7}$. The product branching fractions of
$\mathcal{B}[\psi(3686)\to\gamma\chi_{cJ}]\cdot\mathcal{B}[\chi_{cJ}\to
p\bar{p}K^+K^-]$ are measured to be $(2.49\mkern 2mu\pm\mkern 2mu
0.03_{\text{stat.}}\mkern 2mu\pm\mkern 2mu 0.15_{\text{syst.}})\times 10^{-5}$,
$(1.83\mkern 2mu \pm\mkern 2mu 0.02_{\text{stat.}}\mkern 2mu \pm\mkern 2mu
0.11_{\text{syst.}})\times 10^{-5}$, and $(2.43\mkern 2mu\pm\mkern 2mu
0.02_{\text{stat.}}\mkern 2mu\pm\mkern 2mu 0.15_{\text{syst.}})\times 10^{-5}$,
for $J=0,\ 1$, and 2, respectively.",http://arxiv.org/abs/2501.01661v1
Observation of $ψ(3686) \to K^{-}Λ(1520)\barΞ^{+} + c.c.$,2025-01-05T16:18:52Z,"BESIII Collaboration, M. Ablikim, M. N. Achasov, P. Adlarson, O. Afedulidis, X. C. Ai, R. Aliberti, A. Amoroso, Q. An, Y. Bai, O. Bakina, I. Balossino, Y. Ban, H. -R. Bao, V. Batozskaya, K. Begzsuren, N. Berger, M. Berlowski, M. Bertani, D. Bettoni, F. Bianchi, E. Bianco, A. Bortone, I. Boyko, R. A. Briere, A. Brueggemann, H. Cai, X. Cai, A. Calcaterra, G. F. Cao, N. Cao, S. A. Cetin, X. Y. Chai, J. F. Chang, G. R. Che, Y. Z. Che, G. Chelkov, C. Chen, C. H. Chen, Chao Chen, G. Chen, H. S. Chen, H. Y. Chen, M. L. Chen, S. J. Chen, S. L. Chen, S. M. Chen, T. Chen, X. R. Chen, X. T. Chen, Y. B. Chen, Y. Q. Chen, Z. J. Chen, S. K. Choi, G. Cibinetto, F. Cossio, J. J. Cui, H. L. Dai, J. P. Dai, A. Dbeyssi, R. E. de Boer, D. Dedovich, C. Q. Deng, Z. Y. Deng, A. Denig, I. Denysenko, M. Destefanis, F. De Mori, B. Ding, X. X. Ding, Y. Ding, Y. Ding, J. Dong, L. Y. Dong, M. Y. Dong, X. Dong, M. C. Du, S. X. Du, Y. Y. Duan, Z. H. Duan, P. Egorov, G. F. Fan, J. J. Fan, Y. H. Fan, J. Fang, J. Fang, S. S. Fang, W. X. Fang, Y. Q. Fang, R. Farinelli, L. Fava, F. Feldbauer, G. Felici, C. Q. Feng, J. H. Feng, Y. T. Feng, M. Fritsch, C. D. Fu, J. L. Fu, Y. W. Fu, H. Gao, X. B. Gao, Y. N. Gao, Y. N. Gao, Yang Gao, S. Garbolino, I. Garzia, P. T. Ge, Z. W. Ge, C. Geng, E. M. Gersabeck, A. Gilman, K. Goetzen, L. Gong, W. X. Gong, W. Gradl, S. Gramigna, M. Greco, M. H. Gu, Y. T. Gu, C. Y. Guan, A. Q. Guo, L. B. Guo, M. J. Guo, R. P. Guo, Y. P. Guo, A. Guskov, J. Gutierrez, K. L. Han, T. T. Han, F. Hanisch, X. Q. Hao, F. A. Harris, K. K. He, K. L. He, F. H. Heinsius, C. H. Heinz, Y. K. Heng, C. Herold, T. Holtmann, P. C. Hong, G. Y. Hou, X. T. Hou, Y. R. Hou, Z. L. Hou, B. Y. Hu, H. M. Hu, J. F. Hu, Q. P. Hu, S. L. Hu, T. Hu, Y. Hu, G. S. Huang, K. X. Huang, L. Q. Huang, P. Huang, X. T. Huang, Y. P. Huang, Y. S. Huang, T. Hussain, F. Hölzken, N. Hüsken, N. in der Wiesche, J. Jackson, S. Janchiv, Q. Ji, Q. P. Ji, W. Ji, X. B. Ji, X. L. Ji, Y. Y. Ji, X. Q. Jia, Z. K. Jia, D. Jiang, H. B. Jiang, P. C. Jiang, S. S. Jiang, T. J. Jiang, X. S. Jiang, Y. Jiang, J. B. Jiao, J. K. Jiao, Z. Jiao, S. Jin, Y. Jin, M. Q. Jing, X. M. Jing, T. Johansson, S. Kabana, N. Kalantar-Nayestanaki, X. L. Kang, X. S. Kang, M. Kavatsyuk, B. C. Ke, V. Khachatryan, A. Khoukaz, R. Kiuchi, O. B. Kolcu, B. Kopf, M. Kuessner, X. Kui, N. Kumar, A. Kupsc, W. Kühn, W. N. Lan, T. T. Lei, Z. H. Lei, M. Lellmann, T. Lenz, C. Li, C. Li, C. H. Li, Cheng Li, D. M. Li, F. Li, G. Li, H. B. Li, H. J. Li, H. N. Li, Hui Li, J. R. Li, J. S. Li, K. Li, K. L. Li, L. J. Li, Lei Li, M. H. Li, P. L. Li, P. R. Li, Q. M. Li, Q. X. Li, R. Li, T. Li, T. Y. Li, W. D. Li, W. G. Li, X. Li, X. H. Li, X. L. Li, X. Y. Li, X. Z. Li, Y. Li, Y. G. Li, Z. J. Li, Z. Y. Li, C. Liang, H. Liang, Y. F. Liang, Y. T. Liang, G. R. Liao, Y. P. Liao, J. Libby, A. Limphirat, C. C. Lin, C. X. Lin, D. X. Lin, T. Lin, B. J. Liu, B. X. Liu, C. Liu, C. X. Liu, F. Liu, F. H. Liu, Feng Liu, G. M. Liu, H. Liu, H. B. Liu, H. H. Liu, H. M. Liu, Huihui Liu, J. B. Liu, K. Liu, K. Y. Liu, Ke Liu, L. Liu, L. C. Liu, Lu Liu, M. H. Liu, P. L. Liu, Q. Liu, S. B. Liu, T. Liu, W. K. Liu, W. M. Liu, X. Liu, X. Liu, Y. Liu, Y. Liu, Y. B. Liu, Z. A. Liu, Z. D. Liu, Z. Q. Liu, X. C. Lou, F. X. Lu, H. J. Lu, J. G. Lu, Y. Lu, Y. P. Lu, Z. H. Lu, C. L. Luo, J. R. Luo, M. X. Luo, T. Luo, X. L. Luo, X. R. Lyu, Y. F. Lyu, F. C. Ma, H. Ma, H. L. Ma, J. L. Ma, L. L. Ma, L. R. Ma, Q. M. Ma, R. Q. Ma, R. Y. Ma, T. Ma, X. T. Ma, X. Y. Ma, Y. M. Ma, F. E. Maas, I. MacKay, M. Maggiora, S. Malde, Y. J. Mao, Z. P. Mao, S. Marcello, Y. H. Meng, Z. X. Meng, J. G. Messchendorp, G. Mezzadri, H. Miao, T. J. Min, R. E. Mitchell, X. H. Mo, B. Moses, N. Yu. Muchnoi, J. Muskalla, Y. Nefedov, F. Nerling, L. S. Nie, I. B. Nikolaev, Z. Ning, S. Nisar, Q. L. Niu, W. D. Niu, Y. Niu, S. L. Olsen, Q. Ouyang, S. Pacetti, X. Pan, Y. Pan, A. Pathak, Y. P. Pei, M. Pelizaeus, H. P. Peng, Y. Y. Peng, K. Peters, J. L. Ping, R. G. Ping, S. Plura, V. Prasad, F. Z. Qi, H. R. Qi, M. Qi, S. Qian, W. B. Qian, C. F. Qiao, J. H. Qiao, J. J. Qin, L. Q. Qin, L. Y. Qin, X. P. Qin, X. S. Qin, Z. H. Qin, J. F. Qiu, Z. H. Qu, C. F. Redmer, K. J. Ren, A. Rivetti, M. Rolo, G. Rong, Ch. Rosner, M. Q. Ruan, S. N. Ruan, N. Salone, A. Sarantsev, Y. Schelhaas, K. Schoenning, M. Scodeggio, K. Y. Shan, W. Shan, X. Y. Shan, Z. J. Shang, J. F. Shangguan, L. G. Shao, M. Shao, C. P. Shen, H. F. Shen, W. H. Shen, X. Y. Shen, B. A. Shi, H. Shi, J. L. Shi, J. Y. Shi, S. Y. Shi, X. Shi, J. J. Song, T. Z. Song, W. M. Song, Y. J. Song, Y. X. Song, S. Sosio, S. Spataro, F. Stieler, S. S Su, Y. J. Su, G. B. Sun, G. X. Sun, H. Sun, H. K. Sun, J. F. Sun, K. Sun, L. Sun, S. S. Sun, T. Sun, Y. J. Sun, Y. Z. Sun, Z. Q. Sun, Z. T. Sun, C. J. Tang, G. Y. Tang, J. Tang, M. Tang, Y. A. Tang, L. Y. Tao, M. Tat, J. X. Teng, V. Thoren, W. H. Tian, Y. Tian, Z. F. Tian, I. Uman, Y. Wan, S. J. Wang, B. Wang, Bo Wang, C. Wang, D. Y. Wang, H. J. Wang, J. J. Wang, J. P. Wang, K. Wang, L. L. Wang, L. W. Wang, M. Wang, N. Y. Wang, S. Wang, S. Wang, T. Wang, T. J. Wang, W. Wang, W. Wang, W. P. Wang, X. Wang, X. F. Wang, X. J. Wang, X. L. Wang, X. N. Wang, Y. Wang, Y. D. Wang, Y. F. Wang, Y. H. Wang, Y. L. Wang, Y. N. Wang, Y. Q. Wang, Yaqian Wang, Yi Wang, Z. Wang, Z. L. Wang, Z. Y. Wang, D. H. Wei, F. Weidner, S. P. Wen, Y. R. Wen, U. Wiedner, G. Wilkinson, M. Wolke, L. Wollenberg, C. Wu, J. F. Wu, L. H. Wu, L. J. Wu, Lianjie Wu, X. Wu, X. H. Wu, Y. H. Wu, Y. J. Wu, Z. Wu, L. Xia, X. M. Xian, B. H. Xiang, T. Xiang, D. Xiao, G. Y. Xiao, H. Xiao, Y. L. Xiao, Z. J. Xiao, C. Xie, X. H. Xie, Y. Xie, Y. G. Xie, Y. H. Xie, Z. P. Xie, T. Y. Xing, C. F. Xu, C. J. Xu, G. F. Xu, M. Xu, Q. J. Xu, Q. N. Xu, W. L. Xu, X. P. Xu, Y. Xu, Y. C. Xu, Z. S. Xu, F. Yan, L. Yan, W. B. Yan, W. C. Yan, W. P. Yan, X. Q. Yan, H. J. Yang, H. L. Yang, H. X. Yang, J. H. Yang, R. J. Yang, T. Yang, Y. Yang, Y. F. Yang, Y. X. Yang, Y. Z. Yang, Z. W. Yang, Z. P. Yao, M. Ye, M. H. Ye, Junhao Yin, Z. Y. You, B. X. Yu, C. X. Yu, G. Yu, J. S. Yu, M. C. Yu, T. Yu, X. D. Yu, C. Z. Yuan, J. Yuan, J. Yuan, L. Yuan, S. C. Yuan, Y. Yuan, Z. Y. Yuan, C. X. Yue, Ying Yue, A. A. Zafar, F. R. Zeng, S. H. Zeng, X. Zeng, Y. Zeng, Y. J. Zeng, Y. J. Zeng, X. Y. Zhai, Y. C. Zhai, Y. H. Zhan, A. Q. Zhang, B. L. Zhang, B. X. Zhang, D. H. Zhang, G. Y. Zhang, H. Zhang, H. Zhang, H. C. Zhang, H. H. Zhang, H. Q. Zhang, H. R. Zhang, H. Y. Zhang, J. Zhang, J. Zhang, J. J. Zhang, J. L. Zhang, J. Q. Zhang, J. S. Zhang, J. W. Zhang, J. X. Zhang, J. Y. Zhang, J. Z. Zhang, Jianyu Zhang, L. M. Zhang, Lei Zhang, P. Zhang, Q. Zhang, Q. Y. Zhang, R. Y. Zhang, S. H. Zhang, Shulei Zhang, X. M. Zhang, X. Y Zhang, X. Y. Zhang, Y. Zhang, Y. Zhang, Y. T. Zhang, Y. H. Zhang, Y. M. Zhang, Yan Zhang, Z. D. Zhang, Z. H. Zhang, Z. L. Zhang, Z. X. Zhang, Z. Y. Zhang, Z. Y. Zhang, Z. Z. Zhang, Zh. Zh. Zhang, G. Zhao, J. Y. Zhao, J. Z. Zhao, L. Zhao, Lei Zhao, M. G. Zhao, N. Zhao, R. P. Zhao, S. J. Zhao, Y. B. Zhao, Y. X. Zhao, Z. G. Zhao, A. Zhemchugov, B. Zheng, B. M. Zheng, J. P. Zheng, W. J. Zheng, X. R. Zheng, Y. H. Zheng, B. Zhong, X. Zhong, H. Zhou, J. Y. Zhou, S. Zhou, X. Zhou, X. K. Zhou, X. R. Zhou, X. Y. Zhou, Y. Z. Zhou, Z. C. Zhou, A. N. Zhu, J. Zhu, K. Zhu, K. J. Zhu, K. S. Zhu, L. Zhu, L. X. Zhu, S. H. Zhu, T. J. Zhu, W. D. Zhu, W. J. Zhu, W. Z. Zhu, Y. C. Zhu, Z. A. Zhu, J. H. Zou, J. Zu","Based on $(2712.4 \pm 14.3)\times 10^6$ $\psi(3686)$ events collected at the
BESIII detector operating at the BEPCII collider, we present the first
observation of the decay $\psi(3686) \to K^{-}\Lambda(1520)\bar{\Xi}^{+} +
c.c.$. The product branching fraction ${\cal B}[\psi(3686) \to
K^{-}\Lambda(1520)\bar{\Xi}^{+} + c.c.] \times {\cal B}[\Lambda(1520) \to
pK^{-}]$ is measured to be $(9.5 \pm 0.8 \pm 1.1) \times 10^{-7}$, where the
first uncertainty is statistical and the second systematic.",http://arxiv.org/abs/2501.02594v1
Study of the electromagnetic Dalitz decay $J/ψ\to e^+e^- π^0$,2025-01-08T08:40:21Z,"BESIII Collaboration, M. Ablikim, M. N. Achasov, P. Adlarson, O. Afedulidis, X. C. Ai, R. Aliberti, A. Amoroso, Q. An, Y. Bai, O. Bakina, I. Balossino, Y. Ban, H. -R. Bao, V. Batozskaya, K. Begzsuren, N. Berger, M. Berlowski, M. Bertani, D. Bettoni, F. Bianchi, E. Bianco, A. Bortone, I. Boyko, R. A. Briere, A. Brueggemann, H. Cai, X. Cai, A. Calcaterra, G. F. Cao, N. Cao, S. A. Cetin, J. F. Chang, G. R. Che, Y. Z. Che, G. Chelkov, C. Chen, C. H. Chen, Chao Chen, G. Chen, H. S. Chen, H. Y. Chen, M. L. Chen, S. J. Chen, S. L. Chen, S. M. Chen, T. Chen, X. R. Chen, X. T. Chen, Y. B. Chen, Y. Q. Chen, Y. Q. Chen, Z. J. Chen, Z. Y. Chen, S. K. Choi, X. Chu, G. Cibinetto, F. Cossio, J. J. Cui, H. L. Dai, J. P. Dai, A. Dbeyssi, R. E. de Boer, D. Dedovich, C. Q. Deng, Z. Y. Deng, A. Denig, I. Denysenko, M. Destefanis, F. De Mori, B. Ding, X. X. Ding, Y. Ding, Y. Ding, J. Dong, L. Y. Dong, M. Y. Dong, X. Dong, M. C. Du, S. X. Du, Y. Y. Duan, Z. H. Duan, P. Egorov, Y. H. Fan, J. Fang, J. Fang, S. S. Fang, W. X. Fang, Y. Fang, Y. Q. Fang, R. Farinelli, L. Fava, F. Feldbauer, G. Felici, C. Q. Feng, J. H. Feng, Y. T. Feng, M. Fritsch, C. D. Fu, J. L. Fu, Y. W. Fu, H. Gao, X. B. Gao, Y. Gao, Y. N. Gao, S. Garbolino, I. Garzia, P. T. Ge, Z. W. Ge, C. Geng, E. M. Gersabeck, A. Gilman, K. Goetzen, L. Gong, W. X. Gong, W. Gradl, S. Gramigna, M. Greco, M. H. Gu, Y. T. Gu, C. Y. Guan, A. Q. Guo, L. B. Guo, M. J. Guo, R. P. Guo, Y. P. Guo, A. Guskov, J. Gutierrez, K. L. Han, T. T. Han, F. Hanisch, X. Q. Hao, F. A. Harris, K. K. He, K. L. He, F. H. Heinsius, C. H. Heinz, Y. K. Heng, C. Herold, T. Holtmann, P. C. Hong, G. Y. Hou, X. T. Hou, Y. R. Hou, Z. L. Hou, H. M. Hu, J. F. Hu, S. L. Hu, T. Hu, Y. Hu, G. S. Huang, K. X. Huang, L. Q. Huang, X. T. Huang, Y. P. Huang, Y. S. Huang, T. Hussain, F. Hölzken, N. Hüsken, N. in der Wiesche, J. Jackson, Q. Ji, Q. P. Ji, W. Ji, X. B. Ji, X. L. Ji, Y. Y. Ji, X. Q. Jia, Z. K. Jia, D. Jiang, H. B. Jiang, P. C. Jiang, S. S. Jiang, T. J. Jiang, X. S. Jiang, Y. Jiang, J. B. Jiao, J. K. Jiao, Z. Jiao, S. Jin, Y. Jin, M. Q. Jing, X. M. Jing, T. Johansson, S. Kabana, N. Kalantar-Nayestanaki, X. L. Kang, X. S. Kang, M. Kavatsyuk, B. C. Ke, V. Khachatryan, A. Khoukaz, R. Kiuchi, O. B. Kolcu, B. Kopf, M. Kuessner, X. Kui, N. Kumar, A. Kupsc, W. Kühn, J. J. Lane, L. Lavezzi, T. T. Lei, M. Lellmann, T. Lenz, C. Li, C. Li, C. Li, C. H. Li, D. M. Li, F. Li, G. Li, H. B. Li, H. J. Li, H. N. Li, Hui Li, J. R. Li, J. S. Li, K. Li, K. L. Li, L. J. Li, L. K. Li, Lei Li, M. H. Li, P. R. Li, Q. M. Li, Q. X. Li, R. Li, S. X. Li, T. Li, W. D. Li, W. G. Li, X. Li, X. H. Li, X. L. Li, X. Y. Li, X. Z. Li, Y. G. Li, Z. J. Li, Z. Y. Li, C. Liang, H. Liang, H. Liang, Y. F. Liang, Y. T. Liang, G. R. Liao, Y. P. Liao, J. Libby, A. Limphirat, C. C. Lin, D. X. Lin, T. Lin, B. J. Liu, B. X. Liu, C. Liu, C. X. Liu, F. Liu, F. H. Liu, Feng Liu, G. M. Liu, H. Liu, H. B. Liu, H. H. Liu, H. M. Liu, Huihui Liu, J. B. Liu, J. Y. Liu, K. Liu, K. Y. Liu, Ke Liu, L. Liu, L. C. Liu, Lu Liu, M. H. Liu, P. L. Liu, Q. Liu, S. B. Liu, T. Liu, W. K. Liu, W. M. Liu, X. Liu, X. Liu, Y. Liu, Y. Liu, Y. B. Liu, Z. A. Liu, Z. D. Liu, Z. Q. Liu, X. C. Lou, F. X. Lu, H. J. Lu, J. G. Lu, X. L. Lu, X. L. Lu, Y. Lu, Y. P. Lu, Z. H. Lu, C. L. Luo, J. R. Luo, M. X. Luo, T. Luo, X. L. Luo, X. R. Lyu, Y. F. Lyu, F. C. Ma, H. Ma, H. L. Ma, J. L. Ma, L. L. Ma, L. R. Ma, M. M. Ma, Q. M. Ma, R. Q. Ma, T. Ma, X. T. Ma, X. Y. Ma, Y. M. Ma, F. E. Maas, I. MacKay, M. Maggiora, S. Malde, Q. A. Malik, Y. J. Mao, Z. P. Mao, S. Marcello, Z. X. Meng, J. G. Messchendorp, G. Mezzadri, H. Miao, T. J. Min, R. E. Mitchell, X. H. Mo, B. Moses, N. Yu. Muchnoi, J. Muskalla, Y. Nefedov, F. Nerling, L. S. Nie, I. B. Nikolaev, Z. Ning, S. Nisar, Q. L. Niu, W. D. Niu, Y. Niu, S. L. Olsen, Q. Ouyang, S. Pacetti, X. Pan, Y. Pan, Y. P. Pei, M. Pelizaeus, H. P. Peng, Y. Y. Peng, K. Peters, J. L. Ping, R. G. Ping, S. Plura, V. Prasad, F. Z. Qi, H. R. Qi, M. Qi, T. Y. Qi, S. Qian, W. B. Qian, C. F. Qiao, J. H. Qiao, J. J. Qin, L. Q. Qin, L. Y. Qin, X. P. Qin, X. S. Qin, Z. H. Qin, J. F. Qiu, Z. H. Qu, C. F. Redmer, K. J. Ren, A. Rivetti, M. Rolo, G. Rong, Ch. Rosner, M. Q. Ruan, S. N. Ruan, N. Salone, A. Sarantsev, Y. Schelhaas, K. Schoenning, M. Scodeggio, K. Y. Shan, W. Shan, X. Y. Shan, Z. J. Shang, J. F. Shangguan, L. G. Shao, M. Shao, C. P. Shen, H. F. Shen, W. H. Shen, X. Y. Shen, B. A. Shi, H. Shi, J. L. Shi, J. Y. Shi, Q. Q. Shi, S. Y. Shi, X. Shi, J. J. Song, T. Z. Song, W. M. Song, Y. J. Song, Y. X. Song, S. Sosio, S. Spataro, F. Stieler, S. S Su, Y. J. Su, G. B. Sun, G. X. Sun, H. Sun, H. K. Sun, J. F. Sun, K. Sun, L. Sun, S. S. Sun, T. Sun, W. Y. Sun, Y. Sun, Y. J. Sun, Y. Z. Sun, Z. Q. Sun, Z. T. Sun, C. J. Tang, G. Y. Tang, J. Tang, J. J. Tang, Y. A. Tang, L. Y. Tao, Q. T. Tao, M. Tat, J. X. Teng, W. H. Tian, Y. Tian, Z. F. Tian, I. Uman, Y. Wan, S. J. Wang, B. Wang, B. L. Wang, Bo Wang, D. Y. Wang, F. Wang, H. J. Wang, J. J. Wang, J. P. Wang, K. Wang, L. L. Wang, L. W. Wang, M. Wang, N. Y. Wang, S. Wang, S. Wang, T. Wang, T. J. Wang, W. Wang, W. Wang, W. P. Wang, X. Wang, X. F. Wang, X. J. Wang, X. L. Wang, X. N. Wang, Y. Wang, Y. D. Wang, Y. F. Wang, Y. H. Wang, Y. L. Wang, Y. N. Wang, Y. Q. Wang, Yaqian Wang, Yi Wang, Z. Wang, Z. L. Wang, Z. Y. Wang, Ziyi Wang, D. H. Wei, F. Weidner, S. P. Wen, Y. R. Wen, U. Wiedner, G. Wilkinson, M. Wolke, L. Wollenberg, C. Wu, J. F. Wu, L. H. Wu, L. J. Wu, X. Wu, X. H. Wu, Y. H. Wu, Y. J. Wu, Z. Wu, L. Xia, X. M. Xian, B. H. Xiang, D. Xiao, G. Y. Xiao, S. Y. Xiao, Y. L. Xiao, Z. J. Xiao, C. Xie, X. H. Xie, Y. Xie, Y. G. Xie, Y. H. Xie, Z. P. Xie, T. Y. Xing, C. F. Xu, C. J. Xu, G. F. Xu, H. Y. Xu, M. Xu, Q. J. Xu, Q. N. Xu, W. Xu, W. L. Xu, X. P. Xu, Y. Xu, Y. C. Xu, Z. S. Xu, F. Yan, L. Yan, W. B. Yan, W. C. Yan, W. H. Yan, X. Q. Yan, H. J. Yang, H. L. Yang, H. X. Yang, J. H. Yang, T. Yang, Y. Yang, Y. F. Yang, Y. F. Yang, Y. X. Yang, Z. W. Yang, Z. P. Yao, M. Ye, M. H. Ye, J. H. Yin, Junhao Yin, Z. Y. You, B. X. Yu, C. X. Yu, G. Yu, G. Yu, J. S. Yu, M. C. Yu, T. Yu, X. D. Yu, C. Z. Yuan, J. Yuan, J. Yuan, L. Yuan, S. C. Yuan, X. Q. Yuan, Y. Yuan, Z. Y. Yuan, C. X. Yue, A. A. Zafar, F. R. Zeng, S. H. Zeng, X. Zeng, Y. Zeng, Y. J. Zeng, Y. J. Zeng, X. Y. Zhai, Y. C. Zhai, Y. H. Zhan, A. Q. Zhang, B. L. Zhang, B. X. Zhang, D. H. Zhang, G. Y. Zhang, H. Zhang, H. Zhang, H. C. Zhang, H. H. Zhang, H. H. Zhang, H. Q. Zhang, H. R. Zhang, H. Y. Zhang, J. Zhang, J. Zhang, J. J. Zhang, J. L. Zhang, J. Q. Zhang, J. S. Zhang, J. W. Zhang, J. X. Zhang, J. Y. Zhang, J. Z. Zhang, Jianyu Zhang, L. M. Zhang, Lei Zhang, P. Zhang, Q. Y. Zhang, R. Y. Zhang, S. H. Zhang, Shulei Zhang, X. D. Zhang, X. M. Zhang, X. Y Zhang, X. Y. Zhang, Y. Zhang, Y. Zhang, Y. T. Zhang, Y. H. Zhang, Y. M. Zhang, Z. D. Zhang, Z. H. Zhang, Z. L. Zhang, Z. Y. Zhang, Z. Y. Zhang, Z. Z. Zhang, G. Zhao, J. Y. Zhao, J. Z. Zhao, L. Zhao, L. Zhao, M. G. Zhao, N. Zhao, R. P. Zhao, S. J. Zhao, Y. B. Zhao, Y. X. Zhao, Z. G. Zhao, A. Zhemchugov, B. Zheng, B. M. Zheng, J. P. Zheng, W. J. Zheng, Y. H. Zheng, B. Zhong, J. Y. Zhou, L. P. Zhou, S. Zhou, X. Zhou, X. K. Zhou, X. R. Zhou, X. Y. Zhou, Y. Z. Zhou, A. N. Zhu, J. Zhu, K. Zhu, K. J. Zhu, K. S. Zhu, L. Zhu, L. X. Zhu, S. H. Zhu, T. J. Zhu, W. D. Zhu, Y. C. Zhu, Z. A. Zhu, J. H. Zou, J. Zu","We study the electromagnetic Dalitz decay $J/\psi \to e^+e^- \pi^0$ using
$(10087 \pm 44) \times 10^6$ $J/\psi$ events collected by the \bes detector.
The di-electron-invariant-mass dependent transition form factor of this decay
is explored for the first time. A significant resonant structure corresponding
to the $\rho/\omega$ resonance is observed, which cannot be described by
existing theoretical models, due to contributions from the isospin-conserving
$J/\psi \to \rho \pi^0$ and isospin-volating $J/\psi \to \omega \pi^0$ decays.
The observed $\rho$--$\omega$ interference is consistent with that of the pion
form factor but features a relatively narrow $\rho$ peak. By taking into
account the contribution of this resonant structure, the branching fraction of
$J/\psi \to e^+e^- \pi^0$ in the full $e^+e^-$ invariant mass spectrum range is
also measured for the first time to be $(8.06 \pm 0.31 (\rm{stat}) \pm 0.38
(\rm{syst}))\times 10^{-7}$, which is two times larger than the prediction of
the Vector Meson Dominance model due to the observed resonant contribution of
$\rho/\omega$ resonances.",http://arxiv.org/abs/2501.04344v1
"Observation of the $W$-annihilation process $D_s^+ \to ωρ^+$ and
  measurement of $D_s^+ \to φρ^+$ in $D^+_s\to π^+π^+π^-π^0π^0$
  decays",2025-01-08T12:08:38Z,"BESIII Collaboration, M. Ablikim, M. N. Achasov, P. Adlarson, O. Afedulidis, X. C. Ai, R. Aliberti, A. Amoroso, Q. An, Y. Bai, O. Bakina, I. Balossino, Y. Ban, H. -R. Bao, V. Batozskaya, K. Begzsuren, N. Berger, M. Berlowski, M. Bertani, D. Bettoni, F. Bianchi, E. Bianco, A. Bortone, I. Boyko, R. A. Briere, A. Brueggemann, H. Cai, X. Cai, A. Calcaterra, G. F. Cao, N. Cao, S. A. Cetin, X. Y. Chai, J. F. Chang, G. R. Che, Y. Z. Che, G. Chelkov, C. Chen, C. H. Chen, Chao Chen, G. Chen, H. S. Chen, H. Y. Chen, M. L. Chen, S. J. Chen, S. L. Chen, S. M. Chen, T. Chen, X. R. Chen, X. T. Chen, Y. B. Chen, Y. Q. Chen, Z. J. Chen, S. K. Choi, G. Cibinetto, F. Cossio, J. J. Cui, H. L. Dai, J. P. Dai, A. Dbeyssi, R. E. de Boer, D. Dedovich, C. Q. Deng, Z. Y. Deng, A. Denig, I. Denysenko, M. Destefanis, F. De Mori, B. Ding, X. X. Ding, Y. Ding, Y. Ding, J. Dong, L. Y. Dong, M. Y. Dong, X. Dong, M. C. Du, S. X. Du, Y. Y. Duan, Z. H. Duan, P. Egorov, G. F. Fan, J. J. Fan, Y. H. Fan, J. Fang, J. Fang, S. S. Fang, W. X. Fang, Y. Q. Fang, R. Farinelli, L. Fava, F. Feldbauer, G. Felici, C. Q. Feng, J. H. Feng, Y. T. Feng, M. Fritsch, C. D. Fu, J. L. Fu, Y. W. Fu, H. Gao, X. B. Gao, Y. N. Gao, Y. N. Gao, Yang Gao, S. Garbolino, I. Garzia, P. T. Ge, Z. W. Ge, C. Geng, E. M. Gersabeck, A. Gilman, K. Goetzen, L. Gong, W. X. Gong, W. Gradl, S. Gramigna, M. Greco, M. H. Gu, Y. T. Gu, C. Y. Guan, A. Q. Guo, L. B. Guo, M. J. Guo, R. P. Guo, Y. P. Guo, A. Guskov, J. Gutierrez, K. L. Han, T. T. Han, F. Hanisch, X. Q. Hao, F. A. Harris, K. K. He, K. L. He, F. H. Heinsius, C. H. Heinz, Y. K. Heng, C. Herold, T. Holtmann, P. C. Hong, G. Y. Hou, X. T. Hou, Y. R. Hou, Z. L. Hou, B. Y. Hu, H. M. Hu, J. F. Hu, Q. P. Hu, S. L. Hu, T. Hu, Y. Hu, G. S. Huang, K. X. Huang, L. Q. Huang, P. Huang, X. T. Huang, Y. P. Huang, Y. S. Huang, T. Hussain, F. Hölzken, N. Hüsken, N. in der Wiesche, J. Jackson, S. Janchiv, Q. Ji, Q. P. Ji, W. Ji, X. B. Ji, X. L. Ji, Y. Y. Ji, X. Q. Jia, Z. K. Jia, D. Jiang, H. B. Jiang, P. C. Jiang, S. S. Jiang, T. J. Jiang, X. S. Jiang, Y. Jiang, J. B. Jiao, J. K. Jiao, Z. Jiao, S. Jin, Y. Jin, M. Q. Jing, X. M. Jing, T. Johansson, S. Kabana, N. Kalantar-Nayestanaki, X. L. Kang, X. S. Kang, M. Kavatsyuk, B. C. Ke, V. Khachatryan, A. Khoukaz, R. Kiuchi, O. B. Kolcu, B. Kopf, M. Kuessner, X. Kui, N. Kumar, A. Kupsc, W. Kühn, W. N. Lan, T. T. Lei, Z. H. Lei, M. Lellmann, T. Lenz, C. Li, C. Li, C. H. Li, Cheng Li, D. M. Li, F. Li, G. Li, H. B. Li, H. J. Li, H. N. Li, Hui Li, J. R. Li, J. S. Li, K. Li, K. L. Li, L. J. Li, Lei Li, M. H. Li, P. L. Li, P. R. Li, Q. M. Li, Q. X. Li, R. Li, T. Li, T. Y. Li, W. D. Li, W. G. Li, X. Li, X. H. Li, X. L. Li, X. Y. Li, X. Z. Li, Y. Li, Y. G. Li, Z. J. Li, Z. Y. Li, C. Liang, H. Liang, Y. F. Liang, Y. T. Liang, G. R. Liao, Y. P. Liao, J. Libby, A. Limphirat, C. C. Lin, C. X. Lin, D. X. Lin, T. Lin, B. J. Liu, B. X. Liu, C. Liu, C. X. Liu, F. Liu, F. H. Liu, Feng Liu, G. M. Liu, H. Liu, H. B. Liu, H. H. Liu, H. M. Liu, Huihui Liu, J. B. Liu, K. Liu, K. Y. Liu, Ke Liu, L. Liu, L. C. Liu, Lu Liu, M. H. Liu, P. L. Liu, Q. Liu, S. B. Liu, T. Liu, W. K. Liu, W. M. Liu, X. Liu, X. Liu, Y. Liu, Y. Liu, Y. B. Liu, Z. A. Liu, Z. D. Liu, Z. Q. Liu, X. C. Lou, F. X. Lu, H. J. Lu, J. G. Lu, Y. Lu, Y. P. Lu, Z. H. Lu, C. L. Luo, J. R. Luo, M. X. Luo, T. Luo, X. L. Luo, X. R. Lyu, Y. F. Lyu, F. C. Ma, H. Ma, H. L. Ma, J. L. Ma, L. L. Ma, L. R. Ma, Q. M. Ma, R. Q. Ma, R. Y. Ma, T. Ma, X. T. Ma, X. Y. Ma, Y. M. Ma, F. E. Maas, I. MacKay, M. Maggiora, S. Malde, Y. J. Mao, Z. P. Mao, S. Marcello, Y. H. Meng, Z. X. Meng, J. G. Messchendorp, G. Mezzadri, H. Miao, T. J. Min, R. E. Mitchell, X. H. Mo, B. Moses, N. Yu. Muchnoi, J. Muskalla, Y. Nefedov, F. Nerling, L. S. Nie, I. B. Nikolaev, Z. Ning, S. Nisar, Q. L. Niu, W. D. Niu, Y. Niu, S. L. Olsen, Q. Ouyang, S. Pacetti, X. Pan, Y. Pan, A. Pathak, Y. P. Pei, M. Pelizaeus, H. P. Peng, Y. Y. Peng, K. Peters, J. L. Ping, R. G. Ping, S. Plura, V. Prasad, F. Z. Qi, H. R. Qi, M. Qi, S. Qian, W. B. Qian, C. F. Qiao, J. H. Qiao, J. J. Qin, L. Q. Qin, L. Y. Qin, X. P. Qin, X. S. Qin, Z. H. Qin, J. F. Qiu, Z. H. Qu, C. F. Redmer, K. J. Ren, A. Rivetti, M. Rolo, G. Rong, Ch. Rosner, M. Q. Ruan, S. N. Ruan, N. Salone, A. Sarantsev, Y. Schelhaas, K. Schoenning, M. Scodeggio, K. Y. Shan, W. Shan, X. Y. Shan, Z. J. Shang, J. F. Shangguan, L. G. Shao, M. Shao, C. P. Shen, H. F. Shen, W. H. Shen, X. Y. Shen, B. A. Shi, H. Shi, J. L. Shi, J. Y. Shi, S. Y. Shi, X. Shi, J. J. Song, T. Z. Song, W. M. Song, Y. J. Song, Y. X. Song, S. Sosio, S. Spataro, F. Stieler, S. S Su, Y. J. Su, G. B. Sun, G. X. Sun, H. Sun, H. K. Sun, J. F. Sun, K. Sun, L. Sun, S. S. Sun, T. Sun, Y. J. Sun, Y. Z. Sun, Z. Q. Sun, Z. T. Sun, C. J. Tang, G. Y. Tang, J. Tang, M. Tang, Y. A. Tang, L. Y. Tao, M. Tat, J. X. Teng, V. Thoren, W. H. Tian, Y. Tian, Z. F. Tian, I. Uman, Y. Wan, S. J. Wang, B. Wang, Bo Wang, C. Wang, D. Y. Wang, H. J. Wang, J. J. Wang, J. P. Wang, K. Wang, L. L. Wang, L. W. Wang, M. Wang, N. Y. Wang, S. Wang, S. Wang, T. Wang, T. J. Wang, W. Wang, W. Wang, W. P. Wang, X. Wang, X. F. Wang, X. J. Wang, X. L. Wang, X. N. Wang, Y. Wang, Y. D. Wang, Y. F. Wang, Y. H. Wang, Y. L. Wang, Y. N. Wang, Y. Q. Wang, Yaqian Wang, Yi Wang, Z. Wang, Z. L. Wang, Z. Y. Wang, D. H. Wei, F. Weidner, S. P. Wen, Y. R. Wen, U. Wiedner, G. Wilkinson, M. Wolke, L. Wollenberg, C. Wu, J. F. Wu, L. H. Wu, L. J. Wu, Lianjie Wu, X. Wu, X. H. Wu, Y. H. Wu, Y. J. Wu, Z. Wu, L. Xia, X. M. Xian, B. H. Xiang, T. Xiang, D. Xiao, G. Y. Xiao, H. Xiao, Y. L. Xiao, Z. J. Xiao, C. Xie, X. H. Xie, Y. Xie, Y. G. Xie, Y. H. Xie, Z. P. Xie, T. Y. Xing, C. F. Xu, C. J. Xu, G. F. Xu, M. Xu, Q. J. Xu, Q. N. Xu, W. L. Xu, X. P. Xu, Y. Xu, Y. C. Xu, Z. S. Xu, F. Yan, L. Yan, W. B. Yan, W. C. Yan, W. P. Yan, X. Q. Yan, H. J. Yang, H. L. Yang, H. X. Yang, J. H. Yang, R. J. Yang, T. Yang, Y. Yang, Y. F. Yang, Y. X. Yang, Y. Z. Yang, Z. W. Yang, Z. P. Yao, M. Ye, M. H. Ye, Junhao Yin, Z. Y. You, B. X. Yu, C. X. Yu, G. Yu, J. S. Yu, M. C. Yu, T. Yu, X. D. Yu, C. Z. Yuan, J. Yuan, J. Yuan, L. Yuan, S. C. Yuan, Y. Yuan, Z. Y. Yuan, C. X. Yue, Ying Yue, A. A. Zafar, F. R. Zeng, S. H. Zeng, X. Zeng, Y. Zeng, Y. J. Zeng, Y. J. Zeng, X. Y. Zhai, Y. C. Zhai, Y. H. Zhan, A. Q. Zhang, B. L. Zhang, B. X. Zhang, D. H. Zhang, G. Y. Zhang, H. Zhang, H. Zhang, H. C. Zhang, H. H. Zhang, H. Q. Zhang, H. R. Zhang, H. Y. Zhang, J. Zhang, J. Zhang, J. J. Zhang, J. L. Zhang, J. Q. Zhang, J. S. Zhang, J. W. Zhang, J. X. Zhang, J. Y. Zhang, J. Z. Zhang, Jianyu Zhang, L. M. Zhang, Lei Zhang, P. Zhang, Q. Zhang, Q. Y. Zhang, R. Y. Zhang, S. H. Zhang, Shulei Zhang, X. M. Zhang, X. Y Zhang, X. Y. Zhang, Y. Zhang, Y. Zhang, Y. T. Zhang, Y. H. Zhang, Y. M. Zhang, Yan Zhang, Z. D. Zhang, Z. H. Zhang, Z. L. Zhang, Z. X. Zhang, Z. Y. Zhang, Z. Y. Zhang, Z. Z. Zhang, Zh. Zh. Zhang, G. Zhao, J. Y. Zhao, J. Z. Zhao, L. Zhao, Lei Zhao, M. G. Zhao, N. Zhao, R. P. Zhao, S. J. Zhao, Y. B. Zhao, Y. X. Zhao, Z. G. Zhao, A. Zhemchugov, B. Zheng, B. M. Zheng, J. P. Zheng, W. J. Zheng, X. R. Zheng, Y. H. Zheng, B. Zhong, X. Zhong, H. Zhou, J. Y. Zhou, S. Zhou, X. Zhou, X. K. Zhou, X. R. Zhou, X. Y. Zhou, Y. Z. Zhou, Z. C. Zhou, A. N. Zhu, J. Zhu, K. Zhu, K. J. Zhu, K. S. Zhu, L. Zhu, L. X. Zhu, S. H. Zhu, T. J. Zhu, W. D. Zhu, W. J. Zhu, W. Z. Zhu, Y. C. Zhu, Z. A. Zhu, J. H. Zou, J. Zu","We present the first amplitude analysis and branching fraction measurement of
the decay $D^+_s\to \pi^+\pi^+\pi^-\pi^0\pi^0$, using $e^+e^-$ collision data
collected with the BESIII detector at center-of-mass energies between 4.128 and
4.226 GeV corresponding to an integrated luminosity of 7.33 fb$^{-1}$, and
report the first observation of the pure $W$-annihilation decay $D_s^+ \to
\omega\rho^+$ with a branching fraction of $(0.99\pm0.08_{\rm stat}\pm0.07_{\rm
syst})\%$. In comparison to the low significance of the $\mathcal{D}$ wave in
the decay $D_s^+ \to \phi\rho^+$, the dominance of the $\mathcal{D}$ wave over
the $\mathcal{S}$ and $\mathcal{P}$ waves, with a fraction of
$(51.85\pm7.28_{\rm stat}\pm7.90_{\rm syst})\%$ observed in the decay, provides
crucial information for the``polarization puzzle"", as well as for the
understanding of charm meson decays. The branching fraction of $D^+_s\to
\pi^+\pi^+\pi^-\pi^0\pi^0$ is measured to be $(4.41\pm0.15_{\rm
stat}\pm0.13_{\rm syst})\%$. Moreover, the branching fraction of $D_s^+ \to
\phi\rho^+$ is measured to be $(3.98\pm0.33_{\rm stat}\pm0.21_{\rm syst})\%$,
and the $R_{\phi}= {\mathcal{B}(\phi\to\pi^+\pi^-\pi^0)}/{\mathcal{B}(\phi\to
K^+K^-)}$ is determined to be $(0.222\pm0.019_{\rm stat}\pm0.016_{\rm syst}$),
which is consistent with the previous measurement based on charm meson decays,
but deviates from the results from $e^+e^-$ annihilation and $K$-$N$ scattering
experiments by more than 3$\sigma$.",http://arxiv.org/abs/2501.04451v1
Search for the leptonic decay $D^{+}\to e^{+}ν_{e}$,2025-01-08T17:42:58Z,"BESIII Collaboration, M. Ablikim, M. N. Achasov, P. Adlarson, O. Afedulidis, X. C. Ai, R. Aliberti, A. Amoroso, Q. An, Y. Bai, O. Bakina, I. Balossino, Y. Ban, H. -R. Bao, V. Batozskaya, K. Begzsuren, N. Berger, M. Berlowski, M. Bertani, D. Bettoni, F. Bianchi, E. Bianco, A. Bortone, I. Boyko, R. A. Briere, A. Brueggemann, H. Cai, X. Cai, A. Calcaterra, G. F. Cao, N. Cao, S. A. Cetin, X. Y. Chai, J. F. Chang, G. R. Che, Y. Z. Che, G. Chelkov, C. Chen, C. H. Chen, Chao Chen, G. Chen, H. S. Chen, H. Y. Chen, M. L. Chen, S. J. Chen, S. L. Chen, S. M. Chen, T. Chen, X. R. Chen, X. T. Chen, Y. B. Chen, Y. Q. Chen, Z. J. Chen, Z. Y. Chen, S. K. Choi, G. Cibinetto, F. Cossio, J. J. Cui, H. L. Dai, J. P. Dai, A. Dbeyssi, R. E. de Boer, D. Dedovich, C. Q. Deng, Z. Y. Deng, A. Denig, I. Denysenko, M. Destefanis, F. De Mori, B. Ding, X. X. Ding, Y. Ding, Y. Ding, J. Dong, L. Y. Dong, M. Y. Dong, X. Dong, M. C. Du, S. X. Du, Y. Y. Duan, Z. H. Duan, P. Egorov, Y. H. Fan, J. Fang, J. Fang, S. S. Fang, W. X. Fang, Y. Fang, Y. Q. Fang, R. Farinelli, L. Fava, F. Feldbauer, G. Felici, C. Q. Feng, J. H. Feng, Y. T. Feng, M. Fritsch, C. D. Fu, J. L. Fu, Y. W. Fu, H. Gao, X. B. Gao, Y. N. Gao, Yang Gao, S. Garbolino, I. Garzia, L. Ge, P. T. Ge, Z. W. Ge, C. Geng, E. M. Gersabeck, A. Gilman, K. Goetzen, L. Gong, W. X. Gong, W. Gradl, S. Gramigna, M. Greco, M. H. Gu, Y. T. Gu, C. Y. Guan, A. Q. Guo, L. B. Guo, M. J. Guo, R. P. Guo, Y. P. Guo, A. Guskov, J. Gutierrez, K. L. Han, T. T. Han, F. Hanisch, X. Q. Hao, F. A. Harris, K. K. He, K. L. He, F. H. Heinsius, C. H. Heinz, Y. K. Heng, C. Herold, T. Holtmann, P. C. Hong, G. Y. Hou, X. T. Hou, Y. R. Hou, Z. L. Hou, B. Y. Hu, H. M. Hu, J. F. Hu, S. L. Hu, T. Hu, Y. Hu, G. S. Huang, K. X. Huang, L. Q. Huang, X. T. Huang, Y. P. Huang, Y. S. Huang, T. Hussain, F. Hölzken, N. Hüsken, N. in der Wiesche, J. Jackson, S. Janchiv, J. H. Jeong, Q. Ji, Q. P. Ji, W. Ji, X. B. Ji, X. L. Ji, Y. Y. Ji, X. Q. Jia, Z. K. Jia, D. Jiang, H. B. Jiang, P. C. Jiang, S. S. Jiang, T. J. Jiang, X. S. Jiang, Y. Jiang, J. B. Jiao, J. K. Jiao, Z. Jiao, S. Jin, Y. Jin, M. Q. Jing, X. M. Jing, T. Johansson, S. Kabana, N. Kalantar-Nayestanaki, X. L. Kang, X. S. Kang, M. Kavatsyuk, B. C. Ke, V. Khachatryan, A. Khoukaz, R. Kiuchi, O. B. Kolcu, B. Kopf, M. Kuessner, X. Kui, N. Kumar, A. Kupsc, W. Kühn, J. J. Lane, L. Lavezzi, T. T. Lei, Z. H. Lei, M. Lellmann, T. Lenz, C. Li, C. Li, C. H. Li, Cheng Li, D. M. Li, F. Li, G. Li, H. B. Li, H. J. Li, H. N. Li, Hui Li, J. R. Li, J. S. Li, K. Li, K. L. Li, L. J. Li, L. K. Li, Lei Li, M. H. Li, P. R. Li, Q. M. Li, Q. X. Li, R. Li, S. X. Li, T. Li, W. D. Li, W. G. Li, X. Li, X. H. Li, X. L. Li, X. Y. Li, X. Z. Li, Y. G. Li, Z. J. Li, Z. Y. Li, C. Liang, H. Liang, H. Liang, Y. F. Liang, Y. T. Liang, G. R. Liao, Y. P. Liao, J. Libby, A. Limphirat, C. C. Lin, D. X. Lin, T. Lin, B. J. Liu, B. X. Liu, C. Liu, C. X. Liu, F. Liu, F. H. Liu, Feng Liu, G. M. Liu, H. Liu, H. B. Liu, H. H. Liu, H. M. Liu, Huihui Liu, J. B. Liu, J. Y. Liu, K. Liu, K. Y. Liu, Ke Liu, L. Liu, L. C. Liu, Lu Liu, M. H. Liu, P. L. Liu, Q. Liu, S. B. Liu, T. Liu, W. K. Liu, W. M. Liu, X. Liu, X. Liu, Y. Liu, Y. Liu, Y. B. Liu, Z. A. Liu, Z. D. Liu, Z. Q. Liu, X. C. Lou, F. X. Lu, H. J. Lu, J. G. Lu, X. L. Lu, Y. Lu, Y. P. Lu, Z. H. Lu, C. L. Luo, J. R. Luo, M. X. Luo, T. Luo, X. L. Luo, X. R. Lyu, Y. F. Lyu, F. C. Ma, H. Ma, H. L. Ma, J. L. Ma, L. L. Ma, L. R. Ma, M. M. Ma, Q. M. Ma, R. Q. Ma, T. Ma, X. T. Ma, X. Y. Ma, Y. M. Ma, F. E. Maas, I. MacKay, M. Maggiora, S. Malde, Y. J. Mao, Z. P. Mao, S. Marcello, Z. X. Meng, J. G. Messchendorp, G. Mezzadri, H. Miao, T. J. Min, R. E. Mitchell, X. H. Mo, B. Moses, N. Yu. Muchnoi, J. Muskalla, Y. Nefedov, F. Nerling, L. S. Nie, I. B. Nikolaev, Z. Ning, S. Nisar, Q. L. Niu, W. D. Niu, Y. Niu, S. L. Olsen, S. L. Olsen, Q. Ouyang, S. Pacetti, X. Pan, Y. Pan, A. Pathak, Y. P. Pei, M. Pelizaeus, H. P. Peng, Y. Y. Peng, K. Peters, J. L. Ping, R. G. Ping, S. Plura, V. Prasad, F. Z. Qi, H. Qi, H. R. Qi, M. Qi, T. Y. Qi, S. Qian, W. B. Qian, C. F. Qiao, X. K. Qiao, J. J. Qin, L. Q. Qin, L. Y. Qin, X. P. Qin, X. S. Qin, Z. H. Qin, J. F. Qiu, Z. H. Qu, C. F. Redmer, K. J. Ren, A. Rivetti, M. Rolo, G. Rong, Ch. Rosner, M. Q. Ruan, S. N. Ruan, N. Salone, A. Sarantsev, Y. Schelhaas, K. Schoenning, M. Scodeggio, K. Y. Shan, W. Shan, X. Y. Shan, Z. J. Shang, J. F. Shangguan, L. G. Shao, M. Shao, C. P. Shen, H. F. Shen, W. H. Shen, X. Y. Shen, B. A. Shi, H. Shi, H. C. Shi, J. L. Shi, J. Y. Shi, Q. Q. Shi, S. Y. Shi, X. Shi, J. J. Song, T. Z. Song, W. M. Song, Y. J. Song, Y. X. Song, S. Sosio, S. Spataro, F. Stieler, S. S Su, Y. J. Su, G. B. Sun, G. X. Sun, H. Sun, H. K. Sun, J. F. Sun, K. Sun, L. Sun, S. S. Sun, T. Sun, W. Y. Sun, Y. Sun, Y. J. Sun, Y. Z. Sun, Z. Q. Sun, Z. T. Sun, C. J. Tang, G. Y. Tang, J. Tang, M. Tang, Y. A. Tang, L. Y. Tao, Q. T. Tao, M. Tat, J. X. Teng, V. Thoren, W. H. Tian, Y. Tian, Z. F. Tian, I. Uman, Y. Wan, S. J. Wang, B. Wang, B. L. Wang, Bo Wang, D. Y. Wang, F. Wang, H. J. Wang, J. J. Wang, J. P. Wang, K. Wang, L. L. Wang, M. Wang, N. Y. Wang, S. Wang, S. Wang, T. Wang, T. J. Wang, W. Wang, W. Wang, W. P. Wang, X. Wang, X. F. Wang, X. J. Wang, X. L. Wang, X. N. Wang, Y. Wang, Y. D. Wang, Y. F. Wang, Y. L. Wang, Y. N. Wang, Y. Q. Wang, Yaqian Wang, Yi Wang, Z. Wang, Z. L. Wang, Z. Y. Wang, Ziyi Wang, D. H. Wei, F. Weidner, S. P. Wen, Y. R. Wen, U. Wiedner, G. Wilkinson, M. Wolke, L. Wollenberg, C. Wu, J. F. Wu, L. H. Wu, L. J. Wu, X. Wu, X. H. Wu, Y. Wu, Y. H. Wu, Y. J. Wu, Z. Wu, L. Xia, X. M. Xian, B. H. Xiang, T. Xiang, D. Xiao, G. Y. Xiao, S. Y. Xiao, Y. L. Xiao, Z. J. Xiao, C. Xie, X. H. Xie, Y. Xie, Y. G. Xie, Y. H. Xie, Z. P. Xie, T. Y. Xing, C. F. Xu, C. J. Xu, G. F. Xu, H. Y. Xu, M. Xu, Q. J. Xu, Q. N. Xu, W. Xu, W. L. Xu, X. P. Xu, Y. Xu, Y. C. Xu, Z. S. Xu, F. Yan, L. Yan, W. B. Yan, W. C. Yan, X. Q. Yan, H. J. Yang, H. L. Yang, H. X. Yang, T. Yang, Y. Yang, Y. F. Yang, Y. F. Yang, Y. X. Yang, Z. W. Yang, Z. P. Yao, M. Ye, M. H. Ye, J. H. Yin, Junhao Yin, Z. Y. You, B. X. Yu, C. X. Yu, G. Yu, J. S. Yu, M. C. Yu, T. Yu, X. D. Yu, Y. C. Yu, C. Z. Yuan, J. Yuan, J. Yuan, L. Yuan, S. C. Yuan, Y. Yuan, Z. Y. Yuan, C. X. Yue, A. A. Zafar, F. R. Zeng, S. H. Zeng, X. Zeng, Y. Zeng, Y. J. Zeng, Y. J. Zeng, X. Y. Zhai, Y. C. Zhai, Y. H. Zhan, A. Q. Zhang, B. L. Zhang, B. X. Zhang, D. H. Zhang, G. Y. Zhang, H. Zhang, H. Zhang, H. C. Zhang, H. H. Zhang, H. H. Zhang, H. Q. Zhang, H. R. Zhang, H. Y. Zhang, J. Zhang, J. Zhang, J. J. Zhang, J. L. Zhang, J. Q. Zhang, J. S. Zhang, J. W. Zhang, J. X. Zhang, J. Y. Zhang, J. Z. Zhang, Jianyu Zhang, L. M. Zhang, Lei Zhang, P. Zhang, Q. Y. Zhang, R. Y. Zhang, S. H. Zhang, Shulei Zhang, X. M. Zhang, X. Y Zhang, X. Y. Zhang, Y. Zhang, Y. Zhang, Y. T. Zhang, Y. H. Zhang, Y. M. Zhang, Yan Zhang, Z. D. Zhang, Z. H. Zhang, Z. L. Zhang, Z. Y. Zhang, Z. Y. Zhang, Z. Z. Zhang, G. Zhao, J. Y. Zhao, J. Z. Zhao, L. Zhao, Lei Zhao, M. G. Zhao, N. Zhao, R. P. Zhao, S. J. Zhao, Y. B. Zhao, Y. X. Zhao, Z. G. Zhao, A. Zhemchugov, B. Zheng, B. M. Zheng, J. P. Zheng, W. J. Zheng, Y. H. Zheng, B. Zhong, X. Zhong, H. Zhou, J. Y. Zhou, L. P. Zhou, S. Zhou, X. Zhou, X. K. Zhou, X. R. Zhou, X. Y. Zhou, Y. Z. Zhou, Z. C. Zhou, A. N. Zhu, J. Zhu, K. Zhu, K. J. Zhu, K. S. Zhu, L. Zhu, L. X. Zhu, S. H. Zhu, T. J. Zhu, W. D. Zhu, Y. C. Zhu, Z. A. Zhu, J. H. Zou, J. Zu","We search for the leptonic decay $D^+\to e^+\nu_{e}$ using an $e^+e^-$
collision data sample with an integrated luminosity of 20.3~fb$^{-1}$ collected
with the BESIII detector at the center-of-mass energy of 3.773~GeV. No
significant signal is observed and an upper limit on the branching fraction of
$D^+\to e^+\nu_{e}$ is set as $9.7 \times 10^{-7}$, at the 90\% confidence
level. Our upper limit is an order of magnitude smaller than the previous limit
for this decay mode.",http://arxiv.org/abs/2501.04760v1
Search for $K^0_S$ invisible decays,2025-01-11T03:40:11Z,"BESIII Collaboration, M. Ablikim, M. N. Achasov, P. Adlarson, O. Afedulidis, X. C. Ai, R. Aliberti, A. Amoroso, Q. An, Y. Bai, O. Bakina, I. Balossino, Y. Ban, H. -R. Bao, V. Batozskaya, K. Begzsuren, N. Berger, M. Berlowski, M. Bertani, D. Bettoni, F. Bianchi, E. Bianco, A. Bortone, I. Boyko, R. A. Briere, A. Brueggemann, H. Cai, X. Cai, A. Calcaterra, G. F. Cao, N. Cao, S. A. Cetin, X. Y. Chai, J. F. Chang, G. R. Che, Y. Z. Che, G. Chelkov, C. Chen, C. H. Chen, Chao Chen, G. Chen, H. S. Chen, H. Y. Chen, M. L. Chen, S. J. Chen, S. L. Chen, S. M. Chen, T. Chen, X. R. Chen, X. T. Chen, Y. B. Chen, Y. Q. Chen, Z. J. Chen, S. K. Choi, G. Cibinetto, F. Cossio, J. J. Cui, H. L. Dai, J. P. Dai, A. Dbeyssi, R. E. de Boer, D. Dedovich, C. Q. Deng, Z. Y. Deng, A. Denig, I. Denysenko, M. Destefanis, F. De Mori, B. Ding, X. X. Ding, Y. Ding, Y. Ding, J. Dong, L. Y. Dong, M. Y. Dong, X. Dong, M. C. Du, S. X. Du, Y. Y. Duan, Z. H. Duan, P. Egorov, G. F. Fan, J. J. Fan, Y. H. Fan, J. Fang, J. Fang, S. S. Fang, W. X. Fang, Y. Q. Fang, R. Farinelli, L. Fava, F. Feldbauer, G. Felici, C. Q. Feng, J. H. Feng, Y. T. Feng, M. Fritsch, C. D. Fu, J. L. Fu, Y. W. Fu, H. Gao, X. B. Gao, Y. N. Gao, Y. N. Gao, Yang Gao, S. Garbolino, I. Garzia, P. T. Ge, Z. W. Ge, C. Geng, E. M. Gersabeck, A. Gilman, K. Goetzen, L. Gong, W. X. Gong, W. Gradl, S. Gramigna, M. Greco, M. H. Gu, Y. T. Gu, C. Y. Guan, A. Q. Guo, L. B. Guo, M. J. Guo, R. P. Guo, Y. P. Guo, A. Guskov, J. Gutierrez, K. L. Han, T. T. Han, F. Hanisch, X. Q. Hao, F. A. Harris, K. K. He, K. L. He, F. H. Heinsius, C. H. Heinz, Y. K. Heng, C. Herold, T. Holtmann, P. C. Hong, G. Y. Hou, X. T. Hou, Y. R. Hou, Z. L. Hou, B. Y. Hu, H. M. Hu, J. F. Hu, Q. P. Hu, S. L. Hu, T. Hu, Y. Hu, G. S. Huang, K. X. Huang, L. Q. Huang, P. Huang, X. T. Huang, Y. P. Huang, Y. S. Huang, T. Hussain, F. Hölzken, N. Hüsken, N. in der Wiesche, J. Jackson, S. Janchiv, Q. Ji, Q. P. Ji, W. Ji, X. B. Ji, X. L. Ji, Y. Y. Ji, X. Q. Jia, Z. K. Jia, D. Jiang, H. B. Jiang, P. C. Jiang, S. S. Jiang, T. J. Jiang, X. S. Jiang, Y. Jiang, J. B. Jiao, J. K. Jiao, Z. Jiao, S. Jin, Y. Jin, M. Q. Jing, X. M. Jing, T. Johansson, S. Kabana, N. Kalantar-Nayestanaki, X. L. Kang, X. S. Kang, M. Kavatsyuk, B. C. Ke, V. Khachatryan, A. Khoukaz, R. Kiuchi, O. B. Kolcu, B. Kopf, M. Kuessner, X. Kui, N. Kumar, A. Kupsc, W. Kühn, W. N. Lan, T. T. Lei, Z. H. Lei, M. Lellmann, T. Lenz, C. Li, C. Li, C. H. Li, Cheng Li, D. M. Li, F. Li, G. Li, H. B. Li, H. J. Li, H. N. Li, Hui Li, J. R. Li, J. S. Li, K. Li, K. L. Li, L. J. Li, Lei Li, M. H. Li, P. L. Li, P. R. Li, Q. M. Li, Q. X. Li, R. Li, T. Li, T. Y. Li, W. D. Li, W. G. Li, X. Li, X. H. Li, X. L. Li, X. Y. Li, X. Z. Li, Y. Li, Y. G. Li, Z. J. Li, Z. Y. Li, C. Liang, H. Liang, Y. F. Liang, Y. T. Liang, G. R. Liao, Y. P. Liao, J. Libby, A. Limphirat, C. C. Lin, C. X. Lin, D. X. Lin, T. Lin, B. J. Liu, B. X. Liu, C. Liu, C. X. Liu, F. Liu, F. H. Liu, Feng Liu, G. M. Liu, H. Liu, H. B. Liu, H. H. Liu, H. M. Liu, Huihui Liu, J. B. Liu, K. Liu, K. Y. Liu, Ke Liu, L. Liu, L. C. Liu, Lu Liu, M. H. Liu, P. L. Liu, Q. Liu, S. B. Liu, T. Liu, W. K. Liu, W. M. Liu, X. Liu, X. Liu, Y. Liu, Y. Liu, Y. B. Liu, Z. A. Liu, Z. D. Liu, Z. Q. Liu, X. C. Lou, F. X. Lu, H. J. Lu, J. G. Lu, Y. Lu, Y. P. Lu, Z. H. Lu, C. L. Luo, J. R. Luo, M. X. Luo, T. Luo, X. L. Luo, X. R. Lyu, Y. F. Lyu, F. C. Ma, H. Ma, H. L. Ma, J. L. Ma, L. L. Ma, L. R. Ma, Q. M. Ma, R. Q. Ma, R. Y. Ma, T. Ma, X. T. Ma, X. Y. Ma, Y. M. Ma, F. E. Maas, I. MacKay, M. Maggiora, S. Malde, Y. J. Mao, Z. P. Mao, S. Marcello, Y. H. Meng, Z. X. Meng, J. G. Messchendorp, G. Mezzadri, H. Miao, T. J. Min, R. E. Mitchell, X. H. Mo, B. Moses, N. Yu. Muchnoi, J. Muskalla, Y. Nefedov, F. Nerling, L. S. Nie, I. B. Nikolaev, Z. Ning, S. Nisar, Q. L. Niu, W. D. Niu, Y. Niu, S. L. Olsen, Q. Ouyang, S. Pacetti, X. Pan, Y. Pan, A. Pathak, Y. P. Pei, M. Pelizaeus, H. P. Peng, Y. Y. Peng, K. Peters, J. L. Ping, R. G. Ping, S. Plura, V. Prasad, F. Z. Qi, H. R. Qi, M. Qi, S. Qian, W. B. Qian, C. F. Qiao, J. H. Qiao, J. J. Qin, L. Q. Qin, L. Y. Qin, X. P. Qin, X. S. Qin, Z. H. Qin, J. F. Qiu, Z. H. Qu, C. F. Redmer, K. J. Ren, A. Rivetti, M. Rolo, G. Rong, Ch. Rosner, M. Q. Ruan, S. N. Ruan, N. Salone, A. Sarantsev, Y. Schelhaas, K. Schoenning, M. Scodeggio, K. Y. Shan, W. Shan, X. Y. Shan, Z. J. Shang, J. F. Shangguan, L. G. Shao, M. Shao, C. P. Shen, H. F. Shen, W. H. Shen, X. Y. Shen, B. A. Shi, H. Shi, J. L. Shi, J. Y. Shi, S. Y. Shi, X. Shi, J. J. Song, T. Z. Song, W. M. Song, Y. J. Song, Y. X. Song, S. Sosio, S. Spataro, F. Stieler, S. S Su, Y. J. Su, G. B. Sun, G. X. Sun, H. Sun, H. K. Sun, J. F. Sun, K. Sun, L. Sun, S. S. Sun, T. Sun, Y. J. Sun, Y. Z. Sun, Z. Q. Sun, Z. T. Sun, C. J. Tang, G. Y. Tang, J. Tang, M. Tang, Y. A. Tang, L. Y. Tao, M. Tat, J. X. Teng, V. Thoren, W. H. Tian, Y. Tian, Z. F. Tian, I. Uman, Y. Wan, S. J. Wang, B. Wang, Bo Wang, C. Wang, D. Y. Wang, H. J. Wang, J. J. Wang, J. P. Wang, K. Wang, L. L. Wang, L. W. Wang, M. Wang, N. Y. Wang, S. Wang, S. Wang, T. Wang, T. J. Wang, W. Wang, W. Wang, W. P. Wang, X. Wang, X. F. Wang, X. J. Wang, X. L. Wang, X. N. Wang, Y. Wang, Y. D. Wang, Y. F. Wang, Y. H. Wang, Y. L. Wang, Y. N. Wang, Y. Q. Wang, Yaqian Wang, Yi Wang, Z. Wang, Z. L. Wang, Z. Y. Wang, D. H. Wei, F. Weidner, S. P. Wen, Y. R. Wen, U. Wiedner, G. Wilkinson, M. Wolke, L. Wollenberg, C. Wu, J. F. Wu, L. H. Wu, L. J. Wu, Lianjie Wu, X. Wu, X. H. Wu, Y. H. Wu, Y. J. Wu, Z. Wu, L. Xia, X. M. Xian, B. H. Xiang, T. Xiang, D. Xiao, G. Y. Xiao, H. Xiao, Y. L. Xiao, Z. J. Xiao, C. Xie, X. H. Xie, Y. Xie, Y. G. Xie, Y. H. Xie, Z. P. Xie, T. Y. Xing, C. F. Xu, C. J. Xu, G. F. Xu, M. Xu, Q. J. Xu, Q. N. Xu, W. L. Xu, X. P. Xu, Y. Xu, Y. C. Xu, Z. S. Xu, F. Yan, L. Yan, W. B. Yan, W. C. Yan, W. P. Yan, X. Q. Yan, H. J. Yang, H. L. Yang, H. X. Yang, J. H. Yang, R. J. Yang, T. Yang, Y. Yang, Y. F. Yang, Y. X. Yang, Y. Z. Yang, Z. W. Yang, Z. P. Yao, M. Ye, M. H. Ye, Junhao Yin, Z. Y. You, B. X. Yu, C. X. Yu, G. Yu, J. S. Yu, M. C. Yu, T. Yu, X. D. Yu, C. Z. Yuan, J. Yuan, J. Yuan, L. Yuan, S. C. Yuan, Y. Yuan, Z. Y. Yuan, C. X. Yue, Ying Yue, A. A. Zafar, F. R. Zeng, S. H. Zeng, X. Zeng, Y. Zeng, Y. J. Zeng, Y. J. Zeng, X. Y. Zhai, Y. C. Zhai, Y. H. Zhan, A. Q. Zhang, B. L. Zhang, B. X. Zhang, D. H. Zhang, G. Y. Zhang, H. Zhang, H. Zhang, H. C. Zhang, H. H. Zhang, H. Q. Zhang, H. R. Zhang, H. Y. Zhang, J. Zhang, J. Zhang, J. J. Zhang, J. L. Zhang, J. Q. Zhang, J. S. Zhang, J. W. Zhang, J. X. Zhang, J. Y. Zhang, J. Z. Zhang, Jianyu Zhang, L. M. Zhang, Lei Zhang, P. Zhang, Q. Zhang, Q. Y. Zhang, R. Y. Zhang, S. H. Zhang, Shulei Zhang, X. M. Zhang, X. Y Zhang, X. Y. Zhang, Y. Zhang, Y. Zhang, Y. T. Zhang, Y. H. Zhang, Y. M. Zhang, Yan Zhang, Z. D. Zhang, Z. H. Zhang, Z. L. Zhang, Z. X. Zhang, Z. Y. Zhang, Z. Y. Zhang, Z. Z. Zhang, Zh. Zh. Zhang, G. Zhao, J. Y. Zhao, J. Z. Zhao, L. Zhao, Lei Zhao, M. G. Zhao, N. Zhao, R. P. Zhao, S. J. Zhao, Y. B. Zhao, Y. X. Zhao, Z. G. Zhao, A. Zhemchugov, B. Zheng, B. M. Zheng, J. P. Zheng, W. J. Zheng, X. R. Zheng, Y. H. Zheng, B. Zhong, X. Zhong, H. Zhou, J. Y. Zhou, S. Zhou, X. Zhou, X. K. Zhou, X. R. Zhou, X. Y. Zhou, Y. Z. Zhou, Z. C. Zhou, A. N. Zhu, J. Zhu, K. Zhu, K. J. Zhu, K. S. Zhu, L. Zhu, L. X. Zhu, S. H. Zhu, T. J. Zhu, W. D. Zhu, W. J. Zhu, W. Z. Zhu, Y. C. Zhu, Z. A. Zhu, J. H. Zou, J. Zu","Based on $(1.0087\pm0.0044)\times10^{10}$ $J/\psi$ events collected with the
BESIII detector at the BEPCII $e^+e^-$ storage ring, we search for $K_{S}^{0}$
invisible decays via the $J/\psi \to \phi K_{S}^{0} K_{S}^{0}$ process. No
significant signal is observed, and the upper limit of the branching fraction
of these invisible decays is set at 8.4 $\times$ $10^{-4}$ at the 90\%
confidence level. This is the first experimental search for $K^0_S$ invisible
decays.",http://arxiv.org/abs/2501.06426v1
Study of $η\rightarrowπ^+π^-l^+l^-$,2025-01-17T11:39:46Z,"BESIII Collaboration, M. Ablikim, M. N. Achasov, P. Adlarson, O. Afedulidis, X. C. Ai, R. Aliberti, A. Amoroso, Q. An, Y. Bai, O. Bakina, I. Balossino, Y. Ban, H. -R. Bao, V. Batozskaya, K. Begzsuren, N. Berger, M. Berlowski, M. Bertani, D. Bettoni, F. Bianchi, E. Bianco, A. Bortone, I. Boyko, R. A. Briere, A. Brueggemann, H. Cai, X. Cai, A. Calcaterra, G. F. Cao, N. Cao, S. A. Cetin, J. F. Chang, G. R. Che, Y. Z. Che, G. Chelkov, C. Chen, C. H. Chen, Chao Chen, G. Chen, H. S. Chen, H. Y. Chen, M. L. Chen, S. J. Chen, S. L. Chen, S. M. Chen, T. Chen, X. R. Chen, X. T. Chen, Y. B. Chen, Y. Q. Chen, Y. Q. Chen, Z. J. Chen, Z. Y. Chen, S. K. Choi, X. Chu, G. Cibinetto, F. Cossio, J. J. Cui, H. L. Dai, J. P. Dai, A. Dbeyssi, R. E. de Boer, D. Dedovich, C. Q. Deng, Z. Y. Deng, A. Denig, I. Denysenko, M. Destefanis, F. De Mori, B. Ding, X. X. Ding, Y. Ding, Y. Ding, J. Dong, L. Y. Dong, M. Y. Dong, X. Dong, M. C. Du, S. X. Du, Y. Y. Duan, Z. H. Duan, P. Egorov, Y. H. Fan, J. Fang, J. Fang, S. S. Fang, W. X. Fang, Y. Fang, Y. Q. Fang, R. Farinelli, L. Fava, F. Feldbauer, G. Felici, C. Q. Feng, J. H. Feng, Y. T. Feng, M. Fritsch, C. D. Fu, J. L. Fu, Y. W. Fu, H. Gao, X. B. Gao, Y. Gao, Y. N. Gao, S. Garbolino, I. Garzia, P. T. Ge, Z. W. Ge, C. Geng, E. M. Gersabeck, A. Gilman, K. Goetzen, L. Gong, W. X. Gong, W. Gradl, S. Gramigna, M. Greco, M. H. Gu, Y. T. Gu, C. Y. Guan, A. Q. Guo, L. B. Guo, M. J. Guo, R. P. Guo, Y. P. Guo, A. Guskov, J. Gutierrez, K. L. Han, T. T. Han, F. Hanisch, X. Q. Hao, F. A. Harris, K. K. He, K. L. He, F. H. Heinsius, C. H. Heinz, Y. K. Heng, C. Herold, T. Holtmann, P. C. Hong, G. Y. Hou, X. T. Hou, Y. R. Hou, Z. L. Hou, H. M. Hu, J. F. Hu, S. L. Hu, T. Hu, Y. Hu, G. S. Huang, K. X. Huang, L. Q. Huang, X. T. Huang, Y. P. Huang, Y. S. Huang, T. Hussain, F. Hölzken, N. Hüsken, N. in der Wiesche, J. Jackson, Q. Ji, Q. P. Ji, W. Ji, X. B. Ji, X. L. Ji, Y. Y. Ji, X. Q. Jia, Z. K. Jia, D. Jiang, H. B. Jiang, P. C. Jiang, S. S. Jiang, T. J. Jiang, X. S. Jiang, Y. Jiang, J. B. Jiao, J. K. Jiao, Z. Jiao, S. Jin, Y. Jin, M. Q. Jing, X. M. Jing, T. Johansson, S. Kabana, N. Kalantar-Nayestanaki, X. L. Kang, X. S. Kang, M. Kavatsyuk, B. C. Ke, V. Khachatryan, A. Khoukaz, R. Kiuchi, O. B. Kolcu, B. Kopf, M. Kuessner, X. Kui, N. Kumar, A. Kupsc, W. Kühn, J. J. Lane, A. Lavania, L. Lavezzi, T. T. Lei, M. Lellmann, T. Lenz, C. Li, C. Li, C. Li, C. H. Li, D. M. Li, F. Li, G. Li, H. B. Li, H. J. Li, H. N. Li, Hui Li, J. R. Li, J. S. Li, K. Li, K. L. Li, L. J. Li, L. K. Li, Lei Li, M. H. Li, P. R. Li, Q. M. Li, Q. X. Li, R. Li, S. X. Li, T. Li, W. D. Li, W. G. Li, X. Li, X. H. Li, X. L. Li, X. Y. Li, X. Z. Li, Y. G. Li, Z. J. Li, Z. Y. Li, C. Liang, H. Liang, H. Liang, Y. F. Liang, Y. T. Liang, G. R. Liao, Y. P. Liao, J. Libby, A. Limphirat, C. C. Lin, D. X. Lin, T. Lin, B. J. Liu, B. X. Liu, C. Liu, C. X. Liu, F. Liu, F. H. Liu, Feng Liu, G. M. Liu, H. Liu, H. B. Liu, H. H. Liu, H. M. Liu, Huihui Liu, J. B. Liu, J. Y. Liu, K. Liu, K. Y. Liu, Ke Liu, L. Liu, L. C. Liu, Lu Liu, M. H. Liu, P. L. Liu, Q. Liu, S. B. Liu, T. Liu, W. K. Liu, W. M. Liu, X. Liu, X. Liu, Y. Liu, Y. Liu, Y. B. Liu, Z. A. Liu, Z. D. Liu, Z. Q. Liu, X. C. Lou, F. X. Lu, H. J. Lu, J. G. Lu, X. L. Lu, X. L. Lu, Y. Lu, Y. P. Lu, Z. H. Lu, C. L. Luo, J. R. Luo, M. X. Luo, T. Luo, X. L. Luo, X. R. Lyu, Y. F. Lyu, F. C. Ma, H. Ma, H. L. Ma, J. L. Ma, L. L. Ma, L. R. Ma, M. M. Ma, Q. M. Ma, R. Q. Ma, T. Ma, X. T. Ma, X. Y. Ma, Y. M. Ma, F. E. Maas, M. Maggiora, S. Malde, Q. A. Malik, Y. J. Mao, Z. P. Mao, S. Marcello, Z. X. Meng, J. G. Messchendorp, G. Mezzadri, H. Miao, T. J. Min, R. E. Mitchell, X. H. Mo, B. Moses, N. Yu. Muchnoi, J. Muskalla, Y. Nefedov, F. Nerling, L. S. Nie, I. B. Nikolaev, Z. Ning, S. Nisar, Q. L. Niu, W. D. Niu, Y. Niu, S. L. Olsen, Q. Ouyang, S. Pacetti, X. Pan, Y. Pan, Y. P. Pei, M. Pelizaeus, H. P. Peng, Y. Y. Peng, K. Peters, J. L. Ping, R. G. Ping, S. Plura, V. Prasad, F. Z. Qi, H. R. Qi, M. Qi, T. Y. Qi, S. Qian, W. B. Qian, C. F. Qiao, J. J. Qin, L. Q. Qin, L. Y. Qin, X. P. Qin, X. S. Qin, Z. H. Qin, J. F. Qiu, Z. H. Qu, C. F. Redmer, K. J. Ren, A. Rivetti, M. Rolo, G. Rong, Ch. Rosner, M. Q. Ruan, S. N. Ruan, N. Salone, A. Sarantsev, Y. Schelhaas, K. Schoenning, M. Scodeggio, K. Y. Shan, W. Shan, X. Y. Shan, Z. J. Shang, J. F. Shangguan, L. G. Shao, M. Shao, C. P. Shen, H. F. Shen, W. H. Shen, X. Y. Shen, B. A. Shi, H. Shi, J. L. Shi, J. Y. Shi, Q. Q. Shi, S. Y. Shi, X. Shi, J. J. Song, T. Z. Song, W. M. Song, Y. J. Song, Y. X. Song, S. Sosio, S. Spataro, F. Stieler, S. S Su, Y. J. Su, G. B. Sun, G. X. Sun, H. Sun, H. K. Sun, J. F. Sun, K. Sun, L. Sun, S. S. Sun, T. Sun, W. Y. Sun, Y. Sun, Y. J. Sun, Y. Z. Sun, Z. Q. Sun, Z. T. Sun, C. J. Tang, G. Y. Tang, J. Tang, J. J. Tang, Y. A. Tang, L. Y. Tao, Q. T. Tao, M. Tat, J. X. Teng, W. H. Tian, Y. Tian, Z. F. Tian, I. Uman, Y. Wan, S. J. Wang, B. Wang, B. L. Wang, Bo Wang, D. Y. Wang, F. Wang, H. J. Wang, J. J. Wang, J. P. Wang, K. Wang, L. L. Wang, L. W. Wang, M. Wang, N. Y. Wang, S. Wang, S. Wang, T. Wang, T. J. Wang, W. Wang, W. Wang, W. P. Wang, X. Wang, X. F. Wang, X. J. Wang, X. L. Wang, X. N. Wang, Y. Wang, Y. D. Wang, Y. F. Wang, Y. H. Wang, Y. L. Wang, Y. N. Wang, Y. Q. Wang, Yaqian Wang, Yi Wang, Z. Wang, Z. L. Wang, Z. Y. Wang, Ziyi Wang, D. H. Wei, F. Weidner, S. P. Wen, Y. R. Wen, U. Wiedner, G. Wilkinson, M. Wolke, L. Wollenberg, C. Wu, J. F. Wu, L. H. Wu, L. J. Wu, X. Wu, X. H. Wu, Y. H. Wu, Y. J. Wu, Z. Wu, L. Xia, X. M. Xian, B. H. Xiang, D. Xiao, G. Y. Xiao, S. Y. Xiao, Y. L. Xiao, Z. J. Xiao, C. Xie, X. H. Xie, Y. Xie, Y. G. Xie, Y. H. Xie, Z. P. Xie, T. Y. Xing, C. F. Xu, C. J. Xu, G. F. Xu, H. Y. Xu, M. Xu, Q. J. Xu, Q. N. Xu, W. Xu, W. L. Xu, X. P. Xu, Y. Xu, Y. C. Xu, Z. S. Xu, F. Yan, L. Yan, W. B. Yan, W. C. Yan, W. H. Yan, X. Q. Yan, H. J. Yang, H. L. Yang, H. X. Yang, J. H. Yang, T. Yang, Y. Yang, Y. F. Yang, Y. F. Yang, Y. X. Yang, Z. W. Yang, Z. P. Yao, M. Ye, M. H. Ye, J. H. Yin, Junhao Yin, Z. Y. You, B. X. Yu, C. X. Yu, G. Yu, J. S. Yu, M. C. Yu, T. Yu, X. D. Yu, C. Z. Yuan, J. Yuan, J. Yuan, L. Yuan, S. C. Yuan, X. Q. Yuan, Y. Yuan, Z. Y. Yuan, C. X. Yue, A. A. Zafar, F. R. Zeng, S. H. Zeng, X. Zeng, Y. Zeng, Y. J. Zeng, Y. J. Zeng, X. Y. Zhai, Y. C. Zhai, Y. H. Zhan, A. Q. Zhang, B. L. Zhang, B. X. Zhang, D. H. Zhang, G. Y. Zhang, H. Zhang, H. Zhang, H. C. Zhang, H. H. Zhang, H. H. Zhang, H. Q. Zhang, H. R. Zhang, H. Y. Zhang, J. Zhang, J. Zhang, J. J. Zhang, J. L. Zhang, J. Q. Zhang, J. S. Zhang, J. W. Zhang, J. X. Zhang, J. Y. Zhang, J. Z. Zhang, Jianyu Zhang, L. M. Zhang, Lei Zhang, P. Zhang, Q. Y. Zhang, R. Y. Zhang, S. H. Zhang, Shulei Zhang, X. D. Zhang, X. M. Zhang, X. Y Zhang, X. Y. Zhang, Y. Zhang, Y. Zhang, Y. T. Zhang, Y. H. Zhang, Y. M. Zhang, Z. D. Zhang, Z. H. Zhang, Z. L. Zhang, Z. Y. Zhang, Z. Y. Zhang, Z. Z. Zhang, G. Zhao, J. Y. Zhao, J. Z. Zhao, L. Zhao, L. Zhao, M. G. Zhao, N. Zhao, R. P. Zhao, S. J. Zhao, Y. B. Zhao, Y. X. Zhao, Z. G. Zhao, A. Zhemchugov, B. Zheng, B. M. Zheng, J. P. Zheng, W. J. Zheng, Y. H. Zheng, B. Zhong, J. Y. Zhou, L. P. Zhou, S. Zhou, X. Zhou, X. K. Zhou, X. R. Zhou, X. Y. Zhou, Y. Z. Zhou, A. N. Zhu, J. Zhu, K. Zhu, K. J. Zhu, K. S. Zhu, L. Zhu, L. X. Zhu, S. H. Zhu, T. J. Zhu, W. D. Zhu, Y. C. Zhu, Z. A. Zhu, J. H. Zou, J. Zu","Using a sample of $(10087\pm44)\times10^{6}$ $J/\psi$ events accumulated with
the BESIII detector, we analyze the decays $\eta\rightarrow\pi^+\pi^-l^+l^-$
($l=e$ or $\mu$) via the process $J/\psi\rightarrow\gamma\eta$. The branching
fraction of $\eta\rightarrow\pi^+\pi^-e^+e^-$ is measured to be
$\mathcal{B}(\eta\rightarrow\pi^+\pi^-e^+e^-)=(3.07\pm0.12_{\rm{stat.}}\pm0.19_{\rm{syst.}})
\times10^{-4}$. No signal events are observed for the
$\eta\rightarrow\pi^{+}\pi^{-}\mu^{+}\mu^{-}$ decay, leading to an upper limit
on the branching fraction of
$\mathcal{B}(\eta\rightarrow\pi^{+}\pi^{-}\mu^{+}\mu^{-})<4.0\times10^{-7}$ at
the 90\% confidence level. Furthermore, the $CP$-violation asymmetry parameter
is found to be
$\mathcal{A}_{CP}(\eta\rightarrow\pi^{+}\pi^{-}e^{+}e^{-})=(-4.04\pm4.69_{\rm{stat.}}\pm0.14_{\rm{syst.}})\%$,
showing no evidence of $CP$-violation with current statistics. Additionally, we
extract the transition form factor from the decay amplitude of
$\eta\rightarrow\pi^+\pi^-e^+e^-$. Finally, axion-like particles are searched
for via the decay $\eta\rightarrow\pi^+\pi^-a, a\rightarrow e^+e^-$, and upper
limits on this branching fraction relative to that of
$\eta\rightarrow\pi^+\pi^-e^+e^-$ are presented as a function of the axion-like
particle mass in the range $5-200\ \mathrm{MeV}/c^{2}$.",http://arxiv.org/abs/2501.10130v1
"Cross section measurement of $e^{+}e^{-} \to f_{1}(1285)π^{+}π^{-}$
  at center-of-mass energies between $3.808$ and $4.951\rm GeV$",2025-01-24T03:24:01Z,"BESIII Collaboration, M. Ablikim, M. N. Achasov, P. Adlarson, O. Afedulidis, X. C. Ai, R. Aliberti, A. Amoroso, Q. An, Y. Bai, O. Bakina, I. Balossino, Y. Ban, H. -R. Bao, V. Batozskaya, K. Begzsuren, N. Berger, M. Berlowski, M. Bertani, D. Bettoni, F. Bianchi, E. Bianco, A. Bortone, I. Boyko, R. A. Briere, A. Brueggemann, H. Cai, X. Cai, A. Calcaterra, G. F. Cao, N. Cao, S. A. Cetin, J. F. Chang, G. R. Che, G. Chelkov, C. Chen, C. H. Chen, Chao Chen, G. Chen, H. S. Chen, H. Y. Chen, M. L. Chen, S. J. Chen, S. L. Chen, S. M. Chen, T. Chen, X. R. Chen, X. T. Chen, Y. B. Chen, Y. Q. Chen, Z. J. Chen, Z. Y. Chen, S. K. Choi, G. Cibinetto, F. Cossio, J. J. Cui, H. L. Dai, J. P. Dai, A. Dbeyssi, R. E. de Boer, D. Dedovich, C. Q. Deng, Z. Y. Deng, A. Denig, I. Denysenko, M. Destefanis, F. De Mori, B. Ding, X. X. Ding, Y. Ding, Y. Ding, J. Dong, L. Y. Dong, M. Y. Dong, X. Dong, M. C. Du, S. X. Du, Y. Y. Duan, Z. H. Duan, P. Egorov, Y. H. Fan, J. Fang, J. Fang, S. S. Fang, W. X. Fang, Y. Fang, Y. Q. Fang, R. Farinelli, L. Fava, F. Feldbauer, G. Felici, C. Q. Feng, J. H. Feng, Y. T. Feng, M. Fritsch, C. D. Fu, J. L. Fu, Y. W. Fu, H. Gao, X. B. Gao, Y. N. Gao, Yang Gao, S. Garbolino, I. Garzia, L. Ge, P. T. Ge, Z. W. Ge, C. Geng, E. M. Gersabeck, A. Gilman, K. Goetzen, L. Gong, W. X. Gong, W. Gradl, S. Gramigna, M. Greco, M. H. Gu, Y. T. Gu, C. Y. Guan, A. Q. Guo, L. B. Guo, M. J. Guo, R. P. Guo, Y. P. Guo, A. Guskov, J. Gutierrez, K. L. Han, T. T. Han, F. Hanisch, X. Q. Hao, F. A. Harris, K. K. He, K. L. He, F. H. Heinsius, C. H. Heinz, Y. K. Heng, C. Herold, T. Holtmann, P. C. Hong, G. Y. Hou, X. T. Hou, Y. R. Hou, Z. L. Hou, B. Y. Hu, H. M. Hu, J. F. Hu, S. L. Hu, T. Hu, Y. Hu, G. S. Huang, K. X. Huang, L. Q. Huang, X. T. Huang, Y. P. Huang, Y. S. Huang, T. Hussain, F. Hölzken, N. Hüsken, N. in der Wiesche, J. Jackson, S. Janchiv, J. H. Jeong, Q. Ji, Q. P. Ji, W. Ji, X. B. Ji, X. L. Ji, Y. Y. Ji, X. Q. Jia, Z. K. Jia, D. Jiang, H. B. Jiang, P. C. Jiang, S. S. Jiang, T. J. Jiang, X. S. Jiang, Y. Jiang, J. B. Jiao, J. K. Jiao, Z. Jiao, S. Jin, Y. Jin, M. Q. Jing, X. M. Jing, T. Johansson, S. Kabana, N. Kalantar-Nayestanaki, X. L. Kang, X. S. Kang, M. Kavatsyuk, B. C. Ke, V. Khachatryan, A. Khoukaz, R. Kiuchi, O. B. Kolcu, B. Kopf, M. Kuessner, X. Kui, N. Kumar, A. Kupsc, W. Kühn, J. J. Lane, L. Lavezzi, T. T. Lei, Z. H. Lei, M. Lellmann, T. Lenz, C. Li, C. Li, C. H. Li, Cheng Li, D. M. Li, F. Li, G. Li, H. B. Li, H. J. Li, H. N. Li, Hui Li, J. R. Li, J. S. Li, K. Li, L. J. Li, L. K. Li, Lei Li, M. H. Li, P. R. Li, Q. M. Li, Q. X. Li, R. Li, S. X. Li, T. Li, W. D. Li, W. G. Li, X. Li, X. H. Li, X. L. Li, X. Y. Li, X. Z. Li, Y. G. Li, Z. J. Li, Z. Y. Li, C. Liang, H. Liang, H. Liang, Y. F. Liang, Y. T. Liang, G. R. Liao, Y. P. Liao, J. Libby, A. Limphirat, C. C. Lin, D. X. Lin, T. Lin, B. J. Liu, B. X. Liu, C. Liu, C. X. Liu, D. Liu, F. Liu, F. H. Liu, Feng Liu, G. M. Liu, H. Liu, H. B. Liu, H. H. Liu, H. M. Liu, Huihui Liu, J. B. Liu, J. Y. Liu, K. Liu, K. Y. Liu, Ke Liu, L. Liu, L. C. Liu, Lu Liu, M. H. Liu, P. L. Liu, Q. Liu, S. B. Liu, T. Liu, W. K. Liu, W. M. Liu, X. Liu, X. Liu, Y. Liu, Y. Liu, Y. B. Liu, Z. A. Liu, Z. D. Liu, Z. Q. Liu, X. C. Lou, F. X. Lu, H. J. Lu, J. G. Lu, X. L. Lu, Y. Lu, Y. P. Lu, Z. H. Lu, C. L. Luo, J. R. Luo, M. X. Luo, T. Luo, X. L. Luo, X. R. Lyu, Y. F. Lyu, F. C. Ma, H. Ma, H. L. Ma, J. L. Ma, L. L. Ma, L. R. Ma, M. M. Ma, Q. M. Ma, R. Q. Ma, T. Ma, X. T. Ma, X. Y. Ma, Y. Ma, Y. M. Ma, F. E. Maas, M. Maggiora, S. Malde, Y. J. Mao, Z. P. Mao, S. Marcello, Z. X. Meng, J. G. Messchendorp, G. Mezzadri, H. Miao, T. J. Min, R. E. Mitchell, X. H. Mo, B. Moses, N. Yu. Muchnoi, J. Muskalla, Y. Nefedov, F. Nerling, L. S. Nie, I. B. Nikolaev, Z. Ning, S. Nisar, Q. L. Niu, W. D. Niu, Y. Niu, S. L. Olsen, Q. Ouyang, S. Pacetti, X. Pan, Y. Pan, A. Pathak, Y. P. Pei, M. Pelizaeus, H. P. Peng, Y. Y. Peng, K. Peters, J. L. Ping, R. G. Ping, S. Plura, V. Prasad, F. Z. Qi, H. Qi, H. R. Qi, M. Qi, T. Y. Qi, S. Qian, W. B. Qian, C. F. Qiao, X. K. Qiao, J. J. Qin, L. Q. Qin, L. Y. Qin, X. P. Qin, X. S. Qin, Z. H. Qin, J. F. Qiu, Z. H. Qu, C. F. Redmer, K. J. Ren, A. Rivetti, M. Rolo, G. Rong, Ch. Rosner, S. N. Ruan, N. Salone, A. Sarantsev, Y. Schelhaas, K. Schoenning, M. Scodeggio, K. Y. Shan, W. Shan, X. Y. Shan, Z. J. Shang, J. F. Shangguan, L. G. Shao, M. Shao, C. P. Shen, H. F. Shen, W. H. Shen, X. Y. Shen, B. A. Shi, H. Shi, H. C. Shi, J. L. Shi, J. Y. Shi, Q. Q. Shi, S. Y. Shi, X. Shi, J. J. Song, T. Z. Song, W. M. Song, Y. J. Song, Y. X. Song, S. Sosio, S. Spataro, F. Stieler, Y. J. Su, G. B. Sun, G. X. Sun, H. Sun, H. K. Sun, J. F. Sun, K. Sun, L. Sun, S. S. Sun, T. Sun, W. Y. Sun, Y. Sun, Y. J. Sun, Y. Z. Sun, Z. Q. Sun, Z. T. Sun, C. J. Tang, G. Y. Tang, J. Tang, M. Tang, Y. A. Tang, L. Y. Tao, Q. T. Tao, M. Tat, J. X. Teng, V. Thoren, W. H. Tian, Y. Tian, Z. F. Tian, I. Uman, Y. Wan, S. J. Wang, B. Wang, B. L. Wang, Bo Wang, D. Y. Wang, F. Wang, H. J. Wang, J. J. Wang, J. P. Wang, K. Wang, L. L. Wang, M. Wang, N. Y. Wang, S. Wang, S. Wang, T. Wang, T. J. Wang, W. Wang, W. Wang, W. P. Wang, W. P. Wang, X. Wang, X. F. Wang, X. J. Wang, X. L. Wang, X. N. Wang, Y. Wang, Y. D. Wang, Y. F. Wang, Y. L. Wang, Y. N. Wang, Y. Q. Wang, Yaqian Wang, Yi Wang, Z. Wang, Z. L. Wang, Z. Y. Wang, Ziyi Wang, D. H. Wei, F. Weidner, S. P. Wen, Y. R. Wen, U. Wiedner, G. Wilkinson, M. Wolke, L. Wollenberg, C. Wu, J. F. Wu, L. H. Wu, L. J. Wu, X. Wu, X. H. Wu, Y. Wu, Y. H. Wu, Y. J. Wu, Z. Wu, L. Xia, X. M. Xian, B. H. Xiang, T. Xiang, D. Xiao, G. Y. Xiao, S. Y. Xiao, Y. L. Xiao, Z. J. Xiao, C. Xie, X. H. Xie, Y. Xie, Y. G. Xie, Y. H. Xie, Z. P. Xie, T. Y. Xing, C. F. Xu, C. J. Xu, G. F. Xu, H. Y. Xu, M. Xu, Q. J. Xu, Q. N. Xu, W. Xu, W. L. Xu, X. P. Xu, Y. C. Xu, Z. S. Xu, F. Yan, L. Yan, W. B. Yan, W. C. Yan, X. Q. Yan, H. J. Yang, H. L. Yang, H. X. Yang, T. Yang, Y. Yang, Y. F. Yang, Y. F. Yang, Y. X. Yang, Z. W. Yang, Z. P. Yao, M. Ye, M. H. Ye, J. H. Yin, Junhao Yin, Z. Y. You, B. X. Yu, C. X. Yu, G. Yu, J. S. Yu, T. Yu, X. D. Yu, Y. C. Yu, C. Z. Yuan, J. Yuan, J. Yuan, L. Yuan, S. C. Yuan, Y. Yuan, Z. Y. Yuan, C. X. Yue, A. A. Zafar, F. R. Zeng, S. H. Zeng, X. Zeng, Y. Zeng, Y. J. Zeng, Y. J. Zeng, X. Y. Zhai, Y. C. Zhai, Y. H. Zhan, A. Q. Zhang, B. L. Zhang, B. X. Zhang, D. H. Zhang, G. Y. Zhang, H. Zhang, H. Zhang, H. C. Zhang, H. H. Zhang, H. H. Zhang, H. Q. Zhang, H. R. Zhang, H. Y. Zhang, J. Zhang, J. Zhang, J. J. Zhang, J. L. Zhang, J. Q. Zhang, J. S. Zhang, J. W. Zhang, J. X. Zhang, J. Y. Zhang, J. Z. Zhang, Jianyu Zhang, L. M. Zhang, Lei Zhang, P. Zhang, Q. Y. Zhang, R. Y. Zhang, S. H. Zhang, Shulei Zhang, X. D. Zhang, X. M. Zhang, X. Y. Zhang, Y. Zhang, Y. Zhang, Y. T. Zhang, Y. H. Zhang, Y. M. Zhang, Yan Zhang, Z. D. Zhang, Z. H. Zhang, Z. L. Zhang, Z. Y. Zhang, Z. Y. Zhang, Z. Z. Zhang, G. Zhao, J. Y. Zhao, J. Z. Zhao, L. Zhao, Lei Zhao, M. G. Zhao, N. Zhao, R. P. Zhao, S. J. Zhao, Y. B. Zhao, Y. X. Zhao, Z. G. Zhao, A. Zhemchugov, B. Zheng, B. M. Zheng, J. P. Zheng, W. J. Zheng, Y. H. Zheng, B. Zhong, X. Zhong, H. Zhou, J. Y. Zhou, L. P. Zhou, S. Zhou, X. Zhou, X. K. Zhou, X. R. Zhou, X. Y. Zhou, Y. Z. Zhou, A. N. Zhu, J. Zhu, K. Zhu, K. J. Zhu, K. S. Zhu, L. Zhu, L. X. Zhu, S. H. Zhu, T. J. Zhu, W. D. Zhu, Y. C. Zhu, Z. A. Zhu, J. H. Zou, J. Zu","Using data samples collected by the \mbox{BESIII} detector located at the
Beijing Electron Positron Collider, the cross sections of the process
$e^+e^-\to f_{1}(1285)\pi^+\pi^-$ are measured at forty-five center-of-mass
energies from $3.808$ to $4.951 {\rm GeV}$. An investigation on the cross
section line shape is performed, and no significant structure is observed.",http://arxiv.org/abs/2501.14206v1
"Observation of $h_{c}$ radiative decays to multiple light hadrons and
  the tensor state $f_2(1270)$",2025-01-26T08:28:34Z,"BESIII Collaboration, M. Ablikim, M. N. Achasov, P. Adlarson, X. C. Ai, R. Aliberti, A. Amoroso, Q. An, Y. Bai, O. Bakina, Y. Ban, H. -R. Bao, V. Batozskaya, K. Begzsuren, N. Berger, M. Berlowski, M. Bertani, D. Bettoni, F. Bianchi, E. Bianco, A. Bortone, I. Boyko, R. A. Briere, A. Brueggemann, H. Cai, M. H. Cai, X. Cai, A. Calcaterra, G. F. Cao, N. Cao, S. A. Cetin, X. Y. Chai, J. F. Chang, G. R. Che, Y. Z. Che, G. Chelkov, C. Chen, C. H. Chen, Chao Chen, G. Chen, H. S. Chen, H. Y. Chen, M. L. Chen, S. J. Chen, S. L. Chen, S. M. Chen, T. Chen, X. R. Chen, X. T. Chen, Y. B. Chen, Y. Q. Chen, Z. J. Chen, S. K. Choi, X. Chu, G. Cibinetto, F. Cossio, J. J. Cui, H. L. Dai, J. P. Dai, A. Dbeyssi, R. E. de Boer, D. Dedovich, C. Q. Deng, Z. Y. Deng, A. Denig, I. Denysenko, M. Destefanis, F. De Mori, B. Ding, X. X. Ding, Y. Ding, Y. Ding, Y. X. Ding, J. Dong, L. Y. Dong, M. Y. Dong, X. Dong, M. C. Du, S. X. Du, Y. Y. Duan, Z. H. Duan, P. Egorov, G. F. Fan, J. J. Fan, Y. H. Fan, J. Fang, J. Fang, S. S. Fang, W. X. Fang, Y. Q. Fang, R. Farinelli, L. Fava, F. Feldbauer, G. Felici, C. Q. Feng, J. H. Feng, Y. T. Feng, M. Fritsch, C. D. Fu, J. L. Fu, Y. W. Fu, H. Gao, X. B. Gao, Y. N. Gao, Y. N. Gao, Y. Y. Gao, Yang Gao, S. Garbolino, I. Garzia, P. T. Ge, Z. W. Ge, C. Geng, E. M. Gersabeck, A. Gilman, K. Goetzen, L. Gong, W. X. Gong, W. Gradl, S. Gramigna, M. Greco, M. H. Gu, Y. T. Gu, C. Y. Guan, A. Q. Guo, L. B. Guo, M. J. Guo, R. P. Guo, Y. P. Guo, A. Guskov, J. Gutierrez, K. L. Han, T. T. Han, F. Hanisch, K. D. Hao, X. Q. Hao, F. A. Harris, K. K. He, K. L. He, F. H. Heinsius, C. H. Heinz, Y. K. Heng, C. Herold, T. Holtmann, P. C. Hong, G. Y. Hou, X. T. Hou, Y. R. Hou, Z. L. Hou, B. Y. Hu, H. M. Hu, J. F. Hu, Q. P. Hu, S. L. Hu, T. Hu, Y. Hu, G. S. Huang, K. X. Huang, L. Q. Huang, P. Huang, X. T. Huang, Y. P. Huang, Y. S. Huang, T. Hussain, N. Hüsken, N. in der Wiesche, J. Jackson, S. Janchiv, Q. Ji, Q. P. Ji, W. Ji, X. B. Ji, X. L. Ji, Y. Y. Ji, Z. K. Jia, D. Jiang, H. B. Jiang, P. C. Jiang, S. J. Jiang, T. J. Jiang, X. S. Jiang, Y. Jiang, J. B. Jiao, J. K. Jiao, Z. Jiao, S. Jin, Y. Jin, M. Q. Jing, X. M. Jing, T. Johansson, S. Kabana, N. Kalantar-Nayestanaki, X. L. Kang, X. S. Kang, M. Kavatsyuk, B. C. Ke, V. Khachatryan, A. Khoukaz, R. Kiuchi, O. B. Kolcu, B. Kopf, M. Kuessner, X. Kui, N. Kumar, A. Kupsc, W. Kühn, Q. Lan, W. N. Lan, T. T. Lei, Z. H. Lei, M. Lellmann, T. Lenz, C. Li, C. Li, C. H. Li, C. K. Li, Cheng Li, D. M. Li, F. Li, G. Li, H. B. Li, H. J. Li, H. N. Li, Hui Li, J. R. Li, J. S. Li, K. Li, K. L. Li, K. L. Li, L. J. Li, Lei Li, M. H. Li, M. R. Li, P. L. Li, P. R. Li, Q. M. Li, Q. X. Li, R. Li, T. Li, T. Y. Li, W. D. Li, W. G. Li, X. Li, X. H. Li, X. L. Li, X. Y. Li, X. Z. Li, Y. Li, Y. G. Li, Z. J. Li, Z. Y. Li, C. Liang, H. Liang, Y. F. Liang, Y. T. Liang, G. R. Liao, Y. P. Liao, J. Libby, A. Limphirat, C. C. Lin, C. X. Lin, D. X. Lin, L. Q. Lin, T. Lin, B. J. Liu, B. X. Liu, C. Liu, C. X. Liu, F. Liu, F. H. Liu, Feng Liu, G. M. Liu, H. Liu, H. B. Liu, H. H. Liu, H. M. Liu, Huihui Liu, J. B. Liu, J. J. Liu, K. Liu, K. Liu, K. Y. Liu, Ke Liu, L. Liu, L. C. Liu, Lu Liu, M. H. Liu, P. L. Liu, Q. Liu, S. B. Liu, T. Liu, W. K. Liu, W. M. Liu, W. T. Liu, X. Liu, X. Liu, X. Y. Liu, Y. Liu, Y. Liu, Y. Liu, Y. B. Liu, Z. A. Liu, Z. D. Liu, Z. Q. Liu, X. C. Lou, F. X. Lu, H. J. Lu, J. G. Lu, Y. Lu, Y. H. Lu, Y. P. Lu, Z. H. Lu, C. L. Luo, J. R. Luo, J. S. Luo, M. X. Luo, T. Luo, X. L. Luo, X. R. Lyu, Y. F. Lyu, Y. H. Lyu, F. C. Ma, H. Ma, H. L. Ma, J. L. Ma, L. L. Ma, L. R. Ma, Q. M. Ma, R. Q. Ma, R. Y. Ma, T. Ma, X. T. Ma, X. Y. Ma, Y. M. Ma, F. E. Maas, I. MacKay, M. Maggiora, S. Malde, Y. J. Mao, Z. P. Mao, S. Marcello, Y. H. Meng, Z. X. Meng, J. G. Messchendorp, G. Mezzadri, H. Miao, T. J. Min, R. E. Mitchell, X. H. Mo, B. Moses, N. Yu. Muchnoi, J. Muskalla, Y. Nefedov, F. Nerling, L. S. Nie, I. B. Nikolaev, Z. Ning, S. Nisar, Q. L. Niu, S. L. Olsen, Q. Ouyang, S. Pacetti, X. Pan, Y. Pan, A. Pathak, Y. P. Pei, M. Pelizaeus, H. P. Peng, Y. Y. Peng, K. Peters, J. L. Ping, R. G. Ping, S. Plura, V. Prasad, F. Z. Qi, H. R. Qi, M. Qi, S. Qian, W. B. Qian, C. F. Qiao, J. H. Qiao, J. J. Qin, J. L. Qin, L. Q. Qin, L. Y. Qin, P. B. Qin, X. P. Qin, X. S. Qin, Z. H. Qin, J. F. Qiu, Z. H. Qu, C. F. Redmer, A. Rivetti, M. Rolo, G. Rong, S. S. Rong, Ch. Rosner, M. Q. Ruan, S. N. Ruan, N. Salone, A. Sarantsev, Y. Schelhaas, K. Schoenning, M. Scodeggio, K. Y. Shan, W. Shan, X. Y. Shan, Z. J. Shang, J. F. Shangguan, L. G. Shao, M. Shao, C. P. Shen, H. F. Shen, W. H. Shen, X. Y. Shen, B. A. Shi, H. Shi, J. L. Shi, J. Y. Shi, S. Y. Shi, X. Shi, H. L. Song, J. J. Song, T. Z. Song, W. M. Song, Y. J. Song, Y. X. Song, S. Sosio, S. Spataro, F. Stieler, S. S Su, Y. J. Su, G. B. Sun, G. X. Sun, H. Sun, H. K. Sun, J. F. Sun, K. Sun, L. Sun, S. S. Sun, T. Sun, Y. Sun, Y. C. Sun, Y. H. Sun, Y. J. Sun, Y. Z. Sun, Z. Q. Sun, Z. T. Sun, C. J. Tang, G. Y. Tang, J. Tang, L. F. Tang, M. Tang, Y. A. Tang, L. Y. Tao, M. Tat, J. X. Teng, V. Thoren, J. Y. Tian, W. H. Tian, Y. Tian, Z. F. Tian, I. Uman, B. Wang, Bo Wang, C. Wang, D. Y. Wang, H. J. Wang, J. J. Wang, K. Wang, L. L. Wang, L. W. Wang, M. Wang, M. Wang, N. Y. Wang, S. Wang, S. Wang, T. Wang, T. J. Wang, W. Wang, W. Wang, W. P. Wang, X. Wang, X. F. Wang, X. J. Wang, X. L. Wang, X. N. Wang, Y. Wang, Y. D. Wang, Y. F. Wang, Y. H. Wang, Y. L. Wang, Y. N. Wang, Y. Q. Wang, Yaqian Wang, Yi Wang, Yuan Wang, Z. Wang, Z. L. Wang, Z. Y. Wang, D. H. Wei, F. Weidner, S. P. Wen, Y. R. Wen, U. Wiedner, G. Wilkinson, M. Wolke, C. Wu, J. F. Wu, L. H. Wu, L. J. Wu, Lianjie Wu, S. G. Wu, S. M. Wu, X. Wu, X. H. Wu, Y. J. Wu, Z. Wu, L. Xia, X. M. Xian, B. H. Xiang, T. Xiang, D. Xiao, G. Y. Xiao, H. Xiao, Y. L. Xiao, Z. J. Xiao, C. Xie, K. J. Xie, X. H. Xie, Y. Xie, Y. G. Xie, Y. H. Xie, Z. P. Xie, T. Y. Xing, C. F. Xu, C. J. Xu, G. F. Xu, M. Xu, Q. J. Xu, Q. N. Xu, W. L. Xu, X. P. Xu, Y. Xu, Y. C. Xu, Z. S. Xu, F. Yan, H. Y. Yan, L. Yan, W. B. Yan, W. C. Yan, W. P. Yan, X. Q. Yan, H. J. Yang, H. L. Yang, H. X. Yang, J. H. Yang, R. J. Yang, T. Yang, Y. Yang, Y. F. Yang, Y. Q. Yang, Y. X. Yang, Y. Z. Yang, M. Ye, M. H. Ye, Junhao Yin, Z. Y. You, B. X. Yu, C. X. Yu, G. Yu, J. S. Yu, M. C. Yu, T. Yu, X. D. Yu, Y. C. Yu, C. Z. Yuan, H. Yuan, J. Yuan, J. Yuan, L. Yuan, S. C. Yuan, Y. Yuan, Z. Y. Yuan, C. X. Yue, Ying Yue, A. A. Zafar, S. H. Zeng, X. Zeng, Y. Zeng, Y. J. Zeng, Y. J. Zeng, X. Y. Zhai, Y. H. Zhan, A. Q. Zhang, B. L. Zhang, B. X. Zhang, D. H. Zhang, G. Y. Zhang, G. Y. Zhang, H. Zhang, H. Zhang, H. C. Zhang, H. H. Zhang, H. Q. Zhang, H. R. Zhang, H. Y. Zhang, J. Zhang, J. Zhang, J. J. Zhang, J. L. Zhang, J. Q. Zhang, J. S. Zhang, J. W. Zhang, J. X. Zhang, J. Y. Zhang, J. Z. Zhang, Jianyu Zhang, L. M. Zhang, Lei Zhang, N. Zhang, P. Zhang, Q. Zhang, Q. Y. Zhang, R. Y. Zhang, S. H. Zhang, Shulei Zhang, X. M. Zhang, X. Y Zhang, X. Y. Zhang, Y. Zhang, Y. Zhang, Y. T. Zhang, Y. H. Zhang, Y. M. Zhang, Z. D. Zhang, Z. H. Zhang, Z. L. Zhang, Z. L. Zhang, Z. X. Zhang, Z. Y. Zhang, Z. Y. Zhang, Z. Z. Zhang, Zh. Zh. Zhang, G. Zhao, J. Y. Zhao, J. Z. Zhao, L. Zhao, Lei Zhao, M. G. Zhao, N. Zhao, R. P. Zhao, S. J. Zhao, Y. B. Zhao, Y. L. Zhao, Y. X. Zhao, Z. G. Zhao, A. Zhemchugov, B. Zheng, B. M. Zheng, J. P. Zheng, W. J. Zheng, X. R. Zheng, Y. H. Zheng, B. Zhong, X. Zhong, H. Zhou, J. Y. Zhou, S. Zhou, X. Zhou, X. K. Zhou, X. R. Zhou, X. Y. Zhou, Y. Z. Zhou, Z. C. Zhou, A. N. Zhu, J. Zhu, K. Zhu, K. J. Zhu, K. S. Zhu, L. Zhu, L. X. Zhu, S. H. Zhu, T. J. Zhu, W. D. Zhu, W. J. Zhu, W. Z. Zhu, Y. C. Zhu, Z. A. Zhu, X. Y. Zhuang, J. H. Zou, J. Zu","Using $\psi(3686)\rightarrow \pi^{0} h_{c}$ decays from a data sample of
$(27.12\pm0.14)\times10^{8}$ $\psi(3686)$ events collected by the BESIII
detector at the BEPCII collider, $h_c$ radiative decays to
$\gamma\pi^{+}\pi^{-},~\gamma\pi^{+}\pi^{-}\eta,~\gamma2(\pi^{+}\pi^{-})$, and
$\gamma p\bar{p}$ are observed for the first time, each with a significance
greater than $5\sigma$. The corresponding branching fractions are measured.
Furthermore, intermediate states below 2.8 GeV/$c^{2}$ are investigated,
leading to the first observation of the decay process of $h_c\rightarrow\gamma
f_{2}(1270)\rightarrow\gamma\pi^{+}\pi^{-}$ with a significance of
$5.5\,\sigma$. This observation represents the first instance of $h_c$
radiative decay to a tensor state.",http://arxiv.org/abs/2501.15447v1
"Observation of $D^+\to \bar K_1(1270)^0μ^+ν_μ$ and $D^0\to
  K_1(1270)^-μ^+ν_μ$",2025-02-06T07:24:12Z,"BESIII Collaboration, M. Ablikim, M. N. Achasov, P. Adlarson, O. Afedulidis, X. C. Ai, R. Aliberti, A. Amoroso, Q. An, Y. Bai, O. Bakina, I. Balossino, Y. Ban, H. -R. Bao, V. Batozskaya, K. Begzsuren, N. Berger, M. Berlowski, M. Bertani, D. Bettoni, F. Bianchi, E. Bianco, A. Bortone, I. Boyko, R. A. Briere, A. Brueggemann, H. Cai, X. Cai, A. Calcaterra, G. F. Cao, N. Cao, S. A. Cetin, X. Y. Chai, J. F. Chang, G. R. Che, Y. Z. Che, G. Chelkov, C. Chen, C. H. Chen, Chao Chen, G. Chen, H. S. Chen, H. Y. Chen, M. L. Chen, S. J. Chen, S. L. Chen, S. M. Chen, T. Chen, X. R. Chen, X. T. Chen, Y. B. Chen, Y. Q. Chen, Z. J. Chen, Z. Y. Chen, S. K. Choi, G. Cibinetto, F. Cossio, J. J. Cui, H. L. Dai, J. P. Dai, A. Dbeyssi, R. E. de Boer, D. Dedovich, C. Q. Deng, Z. Y. Deng, A. Denig, I. Denysenko, M. Destefanis, F. De Mori, B. Ding, X. X. Ding, Y. Ding, Y. Ding, J. Dong, L. Y. Dong, M. Y. Dong, X. Dong, M. C. Du, S. X. Du, Y. Y. Duan, Z. H. Duan, P. Egorov, Y. H. Fan, J. Fang, J. Fang, S. S. Fang, W. X. Fang, Y. Fang, Y. Q. Fang, R. Farinelli, L. Fava, F. Feldbauer, G. Felici, C. Q. Feng, J. H. Feng, Y. T. Feng, M. Fritsch, C. D. Fu, J. L. Fu, Y. W. Fu, H. Gao, X. B. Gao, Y. N. Gao, Yang Gao, S. Garbolino, I. Garzia, L. Ge, P. T. Ge, Z. W. Ge, C. Geng, E. M. Gersabeck, A. Gilman, K. Goetzen, L. Gong, W. X. Gong, W. Gradl, S. Gramigna, M. Greco, M. H. Gu, Y. T. Gu, C. Y. Guan, A. Q. Guo, L. B. Guo, M. J. Guo, R. P. Guo, Y. P. Guo, A. Guskov, J. Gutierrez, K. L. Han, T. T. Han, F. Hanisch, X. Q. Hao, F. A. Harris, K. K. He, K. L. He, F. H. Heinsius, C. H. Heinz, Y. K. Heng, C. Herold, T. Holtmann, P. C. Hong, G. Y. Hou, X. T. Hou, Y. R. Hou, Z. L. Hou, B. Y. Hu, H. M. Hu, J. F. Hu, S. L. Hu, T. Hu, Y. Hu, G. S. Huang, K. X. Huang, L. Q. Huang, X. T. Huang, Y. P. Huang, Y. S. Huang, T. Hussain, F. Hölzken, N. Hüsken, N. in der Wiesche, J. Jackson, S. Janchiv, J. H. Jeong, Q. Ji, Q. P. Ji, W. Ji, X. B. Ji, X. L. Ji, Y. Y. Ji, X. Q. Jia, Z. K. Jia, D. Jiang, H. B. Jiang, P. C. Jiang, S. S. Jiang, T. J. Jiang, X. S. Jiang, Y. Jiang, J. B. Jiao, J. K. Jiao, Z. Jiao, S. Jin, Y. Jin, M. Q. Jing, X. M. Jing, T. Johansson, S. Kabana, N. Kalantar-Nayestanaki, X. L. Kang, X. S. Kang, M. Kavatsyuk, B. C. Ke, V. Khachatryan, A. Khoukaz, R. Kiuchi, O. B. Kolcu, B. Kopf, M. Kuessner, X. Kui, N. Kumar, A. Kupsc, W. Kühn, J. J. Lane, L. Lavezzi, T. T. Lei, Z. H. Lei, M. Lellmann, T. Lenz, C. Li, C. Li, C. H. Li, Cheng Li, D. M. Li, F. Li, G. Li, H. B. Li, H. J. Li, H. N. Li, Hui Li, J. R. Li, J. S. Li, K. Li, K. L. Li, L. J. Li, L. K. Li, Lei Li, M. H. Li, P. R. Li, Q. M. Li, Q. X. Li, R. Li, S. X. Li, T. Li, W. D. Li, W. G. Li, X. Li, X. H. Li, X. L. Li, X. Y. Li, X. Z. Li, Y. G. Li, Z. J. Li, Z. Y. Li, C. Liang, H. Liang, H. Liang, Y. F. Liang, Y. T. Liang, G. R. Liao, Y. P. Liao, J. Libby, A. Limphirat, C. C. Lin, D. X. Lin, T. Lin, B. J. Liu, B. X. Liu, C. Liu, C. X. Liu, F. Liu, F. H. Liu, Feng Liu, G. M. Liu, H. Liu, H. B. Liu, H. H. Liu, H. M. Liu, Huihui Liu, J. B. Liu, J. Y. Liu, K. Liu, K. Y. Liu, Ke Liu, L. Liu, L. C. Liu, Lu Liu, M. H. Liu, P. L. Liu, Q. Liu, S. B. Liu, T. Liu, W. K. Liu, W. M. Liu, X. Liu, X. Liu, Y. Liu, Y. Liu, Y. B. Liu, Z. A. Liu, Z. D. Liu, Z. Q. Liu, X. C. Lou, F. X. Lu, H. J. Lu, J. G. Lu, X. L. Lu, Y. Lu, Y. P. Lu, Z. H. Lu, C. L. Luo, J. R. Luo, M. X. Luo, T. Luo, X. L. Luo, X. R. Lyu, Y. F. Lyu, F. C. Ma, H. Ma, H. L. Ma, J. L. Ma, L. L. Ma, L. R. Ma, M. M. Ma, Q. M. Ma, R. Q. Ma, T. Ma, X. T. Ma, X. Y. Ma, Y. M. Ma, F. E. Maas, I. MacKay, M. Maggiora, S. Malde, Y. J. Mao, Z. P. Mao, S. Marcello, Z. X. Meng, J. G. Messchendorp, G. Mezzadri, H. Miao, T. J. Min, R. E. Mitchell, X. H. Mo, B. Moses, N. Yu. Muchnoi, J. Muskalla, Y. Nefedov, F. Nerling, L. S. Nie, I. B. Nikolaev, Z. Ning, S. Nisar, Q. L. Niu, W. D. Niu, Y. Niu, S. L. Olsen, S. L. Olsen, Q. Ouyang, S. Pacetti, X. Pan, Y. Pan, A. Pathak, Y. P. Pei, M. Pelizaeus, H. P. Peng, Y. Y. Peng, K. Peters, J. L. Ping, R. G. Ping, S. Plura, V. Prasad, F. Z. Qi, H. Qi, H. R. Qi, M. Qi, T. Y. Qi, S. Qian, W. B. Qian, C. F. Qiao, X. K. Qiao, J. J. Qin, L. Q. Qin, L. Y. Qin, X. P. Qin, X. S. Qin, Z. H. Qin, J. F. Qiu, Z. H. Qu, C. F. Redmer, K. J. Ren, A. Rivetti, M. Rolo, G. Rong, Ch. Rosner, M. Q. Ruan, S. N. Ruan, N. Salone, A. Sarantsev, Y. Schelhaas, K. Schoenning, M. Scodeggio, K. Y. Shan, W. Shan, X. Y. Shan, Z. J. Shang, J. F. Shangguan, L. G. Shao, M. Shao, C. P. Shen, H. F. Shen, W. H. Shen, X. Y. Shen, B. A. Shi, H. Shi, H. C. Shi, J. L. Shi, J. Y. Shi, Q. Q. Shi, S. Y. Shi, X. Shi, J. J. Song, T. Z. Song, W. M. Song, Y. J. Song, Y. X. Song, S. Sosio, S. Spataro, F. Stieler, S. S Su, Y. J. Su, G. B. Sun, G. X. Sun, H. Sun, H. K. Sun, J. F. Sun, K. Sun, L. Sun, S. S. Sun, T. Sun, W. Y. Sun, Y. Sun, Y. J. Sun, Y. Z. Sun, Z. Q. Sun, Z. T. Sun, C. J. Tang, G. Y. Tang, J. Tang, M. Tang, Y. A. Tang, L. Y. Tao, Q. T. Tao, M. Tat, J. X. Teng, V. Thoren, W. H. Tian, Y. Tian, Z. F. Tian, I. Uman, Y. Wan, S. J. Wang, B. Wang, B. L. Wang, Bo Wang, D. Y. Wang, F. Wang, H. J. Wang, J. J. Wang, J. P. Wang, K. Wang, L. L. Wang, M. Wang, N. Y. Wang, S. Wang, S. Wang, T. Wang, T. J. Wang, W. Wang, W. Wang, W. P. Wang, X. Wang, X. F. Wang, X. J. Wang, X. L. Wang, X. N. Wang, Y. Wang, Y. D. Wang, Y. F. Wang, Y. L. Wang, Y. N. Wang, Y. Q. Wang, Yaqian Wang, Yi Wang, Z. Wang, Z. L. Wang, Z. Y. Wang, Ziyi Wang, D. H. Wei, F. Weidner, S. P. Wen, Y. R. Wen, U. Wiedner, G. Wilkinson, M. Wolke, L. Wollenberg, C. Wu, J. F. Wu, L. H. Wu, L. J. Wu, X. Wu, X. H. Wu, Y. Wu, Y. H. Wu, Y. J. Wu, Z. Wu, L. Xia, X. M. Xian, B. H. Xiang, T. Xiang, D. Xiao, G. Y. Xiao, S. Y. Xiao, Y. L. Xiao, Z. J. Xiao, C. Xie, X. H. Xie, Y. Xie, Y. G. Xie, Y. H. Xie, Z. P. Xie, T. Y. Xing, C. F. Xu, C. J. Xu, G. F. Xu, H. Y. Xu, M. Xu, Q. J. Xu, Q. N. Xu, W. Xu, W. L. Xu, X. P. Xu, Y. Xu, Y. C. Xu, Z. S. Xu, F. Yan, L. Yan, W. B. Yan, W. C. Yan, X. Q. Yan, H. J. Yang, H. L. Yang, H. X. Yang, T. Yang, Y. Yang, Y. F. Yang, Y. F. Yang, Y. X. Yang, Z. W. Yang, Z. P. Yao, M. Ye, M. H. Ye, J. H. Yin, Junhao Yin, Z. Y. You, B. X. Yu, C. X. Yu, G. Yu, J. S. Yu, M. C. Yu, T. Yu, X. D. Yu, Y. C. Yu, C. Z. Yuan, J. Yuan, J. Yuan, L. Yuan, S. C. Yuan, Y. Yuan, Z. Y. Yuan, C. X. Yue, A. A. Zafar, F. R. Zeng, S. H. Zeng, X. Zeng, Y. Zeng, Y. J. Zeng, Y. J. Zeng, X. Y. Zhai, Y. C. Zhai, Y. H. Zhan, A. Q. Zhang, B. L. Zhang, B. X. Zhang, D. H. Zhang, G. Y. Zhang, H. Zhang, H. Zhang, H. C. Zhang, H. H. Zhang, H. H. Zhang, H. Q. Zhang, H. R. Zhang, H. Y. Zhang, J. Zhang, J. Zhang, J. J. Zhang, J. L. Zhang, J. Q. Zhang, J. S. Zhang, J. W. Zhang, J. X. Zhang, J. Y. Zhang, J. Z. Zhang, Jianyu Zhang, L. M. Zhang, Lei Zhang, P. Zhang, Q. Y. Zhang, R. Y. Zhang, S. H. Zhang, Shulei Zhang, X. M. Zhang, X. Y Zhang, X. Y. Zhang, Y. Zhang, Y. Zhang, Y. T. Zhang, Y. H. Zhang, Y. M. Zhang, Yan Zhang, Z. D. Zhang, Z. H. Zhang, Z. L. Zhang, Z. Y. Zhang, Z. Y. Zhang, Z. Z. Zhang, G. Zhao, J. Y. Zhao, J. Z. Zhao, L. Zhao, Lei Zhao, M. G. Zhao, N. Zhao, R. P. Zhao, S. J. Zhao, Y. B. Zhao, Y. X. Zhao, Z. G. Zhao, A. Zhemchugov, B. Zheng, B. M. Zheng, J. P. Zheng, W. J. Zheng, Y. H. Zheng, B. Zhong, X. Zhong, H. Zhou, J. Y. Zhou, L. P. Zhou, S. Zhou, X. Zhou, X. K. Zhou, X. R. Zhou, X. Y. Zhou, Y. Z. Zhou, Z. C. Zhou, A. N. Zhu, J. Zhu, K. Zhu, K. J. Zhu, K. S. Zhu, L. Zhu, L. X. Zhu, S. H. Zhu, T. J. Zhu, W. D. Zhu, Y. C. Zhu, Z. A. Zhu, J. H. Zou, J. Zu","By analyzing 7.93 $\rm fb^{-1}$ of $e^+e^-$ collision data collected at the
center-of-mass energy of 3.773 GeV with the BESIII detector operated at the
BEPCII collider, we report the observation of the semimuonic decays of $D^+\to
\bar K_1(1270)^0\mu^+\nu_\mu$ and $D^0\to K_1(1270)^-\mu^+\nu_\mu$ with
statistical significances of $12.5\sigma$ and $6.0\sigma$, respectively. Their
decay branching fractions are determined to be ${\mathcal B}[D^{+}\to
\bar{K}_1(1270)^0 \mu^{+}\nu_{\mu}]=(2.36\pm0.20^{+0.18}_{-0.27}\pm
0.48)\times10^{-3}$ and ${\mathcal B}[D^{0}\to K_1(1270)^{-}
\mu^{+}\nu_{\mu}]=(0.78\pm0.11^{+0.05}_{-0.09}\pm 0.15)\times10^{-3}$, where
the first and second uncertainties are statistical and systematic,
respectively, and the third originates from the input branching fraction of
$\bar K_{1}(1270)^0\to K^- \pi^+\pi^0$ or $K_1(1270)^-\to K^-\pi^+\pi^-$.
Combining our branching fractions with the previous measurements of ${\mathcal
B}[D^+\to \bar K_1(1270)^0e^+\nu_{e}]$ and ${\mathcal B}[D^0\to
K_1(1270)^-e^+\nu_{e}]$, we determine the branching fraction ratios to be
${\mathcal B}[D^+\to \bar K_1(1270)^0\mu^+\nu_{\mu}]/{\mathcal B}[D^+\to \bar
K_1(1270)^0e^+\nu_{e}]=1.03 \pm 0.14 \substack{+0.11\\-0.15}$ and ${\mathcal
B}[D^0\to K_1(1270)^-\mu^+\nu_{\mu}]/{\mathcal B}[D^0\to
K_1(1270)^-e^+\nu_{e}]=0.74\pm 0.13 \substack{+0.08\\-0.13}$. Using the
branching fractions measured in this work and the world-average lifetimes of
the $D^+$ and $D^0$ mesons, we determine the semimuonic partial decay width
ratio to be $\Gamma [D^+\to \bar K_1(1270)^0 \mu^+\nu_\mu]/\Gamma [D^0\to
K_1(1270)^- \mu^+\nu_\mu]=1.22\pm 0.10\substack{+0.06\\-0.09}$, which is
consistent with unity as predicted by isospin conservation.",http://arxiv.org/abs/2502.03828v1
Search for $e^+e^-\to K_S^0 K_S^0 h_c$,2025-02-11T09:39:52Z,"BESIII Collaboration, M. Ablikim, M. N. Achasov, P. Adlarson, O. Afedulidis, X. C. Ai, R. Aliberti, A. Amoroso, Q. An, Y. Bai, O. Bakina, I. Balossino, Y. Ban, H. -R. Bao, V. Batozskaya, K. Begzsuren, N. Berger, M. Berlowski, M. Bertani, D. Bettoni, F. Bianchi, E. Bianco, A. Bortone, I. Boyko, R. A. Briere, A. Brueggemann, H. Cai, X. Cai, A. Calcaterra, G. F. Cao, N. Cao, S. A. Cetin, X. Y. Chai, J. F. Chang, G. R. Che, Y. Z. Che, G. Chelkov, C. Chen, C. H. Chen, Chao Chen, G. Chen, H. S. Chen, H. Y. Chen, M. L. Chen, S. J. Chen, S. L. Chen, S. M. Chen, T. Chen, X. R. Chen, X. T. Chen, Y. B. Chen, Y. Q. Chen, Z. J. Chen, S. K. Choi, G. Cibinetto, F. Cossio, J. J. Cui, H. L. Dai, J. P. Dai, A. Dbeyssi, R. E. de Boer, D. Dedovich, C. Q. Deng, Z. Y. Deng, A. Denig, I. Denysenko, M. Destefanis, F. De Mori, B. Ding, X. X. Ding, Y. Ding, Y. Ding, J. Dong, L. Y. Dong, M. Y. Dong, X. Dong, M. C. Du, S. X. Du, Y. Y. Duan, Z. H. Duan, P. Egorov, G. F. Fan, J. J. Fan, Y. H. Fan, J. Fang, J. Fang, S. S. Fang, W. X. Fang, Y. Q. Fang, R. Farinelli, L. Fava, F. Feldbauer, G. Felici, C. Q. Feng, J. H. Feng, Y. T. Feng, M. Fritsch, C. D. Fu, J. L. Fu, Y. W. Fu, H. Gao, X. B. Gao, Y. N. Gao, Y. N. Gao, Yang Gao, S. Garbolino, I. Garzia, P. T. Ge, Z. W. Ge, C. Geng, E. M. Gersabeck, A. Gilman, K. Goetzen, L. Gong, W. X. Gong, W. Gradl, S. Gramigna, M. Greco, M. H. Gu, Y. T. Gu, C. Y. Guan, A. Q. Guo, L. B. Guo, M. J. Guo, R. P. Guo, Y. P. Guo, A. Guskov, J. Gutierrez, K. L. Han, T. T. Han, F. Hanisch, X. Q. Hao, F. A. Harris, K. K. He, K. L. He, F. H. Heinsius, C. H. Heinz, Y. K. Heng, C. Herold, T. Holtmann, P. C. Hong, G. Y. Hou, X. T. Hou, Y. R. Hou, Z. L. Hou, B. Y. Hu, H. M. Hu, J. F. Hu, Q. P. Hu, S. L. Hu, T. Hu, Y. Hu, G. S. Huang, K. X. Huang, L. Q. Huang, P. Huang, X. T. Huang, Y. P. Huang, Y. S. Huang, T. Hussain, F. Hölzken, N. Hüsken, N. in der Wiesche, J. Jackson, S. Janchiv, Q. Ji, Q. P. Ji, W. Ji, X. B. Ji, X. L. Ji, Y. Y. Ji, X. Q. Jia, Z. K. Jia, D. Jiang, H. B. Jiang, P. C. Jiang, S. S. Jiang, T. J. Jiang, X. S. Jiang, Y. Jiang, J. B. Jiao, J. K. Jiao, Z. Jiao, S. Jin, Y. Jin, M. Q. Jing, X. M. Jing, T. Johansson, S. Kabana, N. Kalantar-Nayestanaki, X. L. Kang, X. S. Kang, M. Kavatsyuk, B. C. Ke, V. Khachatryan, A. Khoukaz, R. Kiuchi, O. B. Kolcu, B. Kopf, M. Kuessner, X. Kui, N. Kumar, A. Kupsc, W. Kühn, W. N. Lan, T. T. Lei, Z. H. Lei, M. Lellmann, T. Lenz, C. Li, C. Li, C. H. Li, Cheng Li, D. M. Li, F. Li, G. Li, H. B. Li, H. J. Li, H. N. Li, Hui Li, J. R. Li, J. S. Li, K. Li, K. L. Li, L. J. Li, Lei Li, M. H. Li, P. L. Li, P. R. Li, Q. M. Li, Q. X. Li, R. Li, T. Li, T. Y. Li, W. D. Li, W. G. Li, X. Li, X. H. Li, X. L. Li, X. Y. Li, X. Z. Li, Y. Li, Y. G. Li, Z. J. Li, Z. Y. Li, C. Liang, H. Liang, Y. F. Liang, Y. T. Liang, G. R. Liao, Y. P. Liao, J. Libby, A. Limphirat, C. C. Lin, C. X. Lin, D. X. Lin, T. Lin, B. J. Liu, B. X. Liu, C. Liu, C. X. Liu, F. Liu, F. H. Liu, Feng Liu, G. M. Liu, H. Liu, H. B. Liu, H. H. Liu, H. M. Liu, Huihui Liu, J. B. Liu, K. Liu, K. Y. Liu, Ke Liu, L. Liu, L. C. Liu, Lu Liu, M. H. Liu, P. L. Liu, Q. Liu, S. B. Liu, T. Liu, W. K. Liu, W. M. Liu, X. Liu, X. Liu, Y. Liu, Y. Liu, Y. B. Liu, Z. A. Liu, Z. D. Liu, Z. Q. Liu, X. C. Lou, F. X. Lu, H. J. Lu, J. G. Lu, Y. Lu, Y. P. Lu, Z. H. Lu, C. L. Luo, J. R. Luo, M. X. Luo, T. Luo, X. L. Luo, X. R. Lyu, Y. F. Lyu, F. C. Ma, H. Ma, H. L. Ma, J. L. Ma, L. L. Ma, L. R. Ma, Q. M. Ma, R. Q. Ma, R. Y. Ma, T. Ma, X. T. Ma, X. Y. Ma, Y. M. Ma, F. E. Maas, I. MacKay, M. Maggiora, S. Malde, Y. J. Mao, Z. P. Mao, S. Marcello, Y. H. Meng, Z. X. Meng, J. G. Messchendorp, G. Mezzadri, H. Miao, T. J. Min, R. E. Mitchell, X. H. Mo, B. Moses, N. Yu. Muchnoi, J. Muskalla, Y. Nefedov, F. Nerling, L. S. Nie, I. B. Nikolaev, Z. Ning, S. Nisar, Q. L. Niu, W. D. Niu, Y. Niu, S. L. Olsen, Q. Ouyang, S. Pacetti, X. Pan, Y. Pan, A. Pathak, Y. P. Pei, M. Pelizaeus, H. P. Peng, Y. Y. Peng, K. Peters, J. L. Ping, R. G. Ping, S. Plura, V. Prasad, F. Z. Qi, H. R. Qi, M. Qi, S. Qian, W. B. Qian, C. F. Qiao, J. H. Qiao, J. J. Qin, L. Q. Qin, L. Y. Qin, X. P. Qin, X. S. Qin, Z. H. Qin, J. F. Qiu, Z. H. Qu, C. F. Redmer, K. J. Ren, A. Rivetti, M. Rolo, G. Rong, Ch. Rosner, M. Q. Ruan, S. N. Ruan, N. Salone, A. Sarantsev, Y. Schelhaas, K. Schoenning, M. Scodeggio, K. Y. Shan, W. Shan, X. Y. Shan, Z. J. Shang, J. F. Shangguan, L. G. Shao, M. Shao, C. P. Shen, H. F. Shen, W. H. Shen, X. Y. Shen, B. A. Shi, H. Shi, J. L. Shi, J. Y. Shi, S. Y. Shi, X. Shi, J. J. Song, T. Z. Song, W. M. Song, Y. J. Song, Y. X. Song, S. Sosio, S. Spataro, F. Stieler, S. S Su, Y. J. Su, G. B. Sun, G. X. Sun, H. Sun, H. K. Sun, J. F. Sun, K. Sun, L. Sun, S. S. Sun, T. Sun, Y. J. Sun, Y. Z. Sun, Z. Q. Sun, Z. T. Sun, C. J. Tang, G. Y. Tang, J. Tang, M. Tang, Y. A. Tang, L. Y. Tao, M. Tat, J. X. Teng, V. Thoren, W. H. Tian, Y. Tian, Z. F. Tian, I. Uman, Y. Wan, S. J. Wang, B. Wang, Bo Wang, C. Wang, D. Y. Wang, H. J. Wang, J. J. Wang, J. P. Wang, K. Wang, L. L. Wang, L. W. Wang, M. Wang, N. Y. Wang, S. Wang, S. Wang, T. Wang, T. J. Wang, W. Wang, W. Wang, W. P. Wang, X. Wang, X. F. Wang, X. J. Wang, X. L. Wang, X. N. Wang, Y. Wang, Y. D. Wang, Y. F. Wang, Y. H. Wang, Y. L. Wang, Y. N. Wang, Y. Q. Wang, Yaqian Wang, Yi Wang, Z. Wang, Z. L. Wang, Z. Y. Wang, D. H. Wei, F. Weidner, S. P. Wen, Y. R. Wen, U. Wiedner, G. Wilkinson, M. Wolke, L. Wollenberg, C. Wu, J. F. Wu, L. H. Wu, L. J. Wu, Lianjie Wu, X. Wu, X. H. Wu, Y. H. Wu, Y. J. Wu, Z. Wu, L. Xia, X. M. Xian, B. H. Xiang, T. Xiang, D. Xiao, G. Y. Xiao, H. Xiao, Y. L. Xiao, Z. J. Xiao, C. Xie, X. H. Xie, Y. Xie, Y. G. Xie, Y. H. Xie, Z. P. Xie, T. Y. Xing, C. F. Xu, C. J. Xu, G. F. Xu, M. Xu, Q. J. Xu, Q. N. Xu, W. L. Xu, X. P. Xu, Y. Xu, Y. C. Xu, Z. S. Xu, F. Yan, L. Yan, W. B. Yan, W. C. Yan, W. P. Yan, X. Q. Yan, H. J. Yang, H. L. Yang, H. X. Yang, J. H. Yang, R. J. Yang, T. Yang, Y. Yang, Y. F. Yang, Y. X. Yang, Y. Z. Yang, Z. W. Yang, Z. P. Yao, M. Ye, M. H. Ye, Junhao Yin, Z. Y. You, B. X. Yu, C. X. Yu, G. Yu, J. S. Yu, M. C. Yu, T. Yu, X. D. Yu, C. Z. Yuan, J. Yuan, J. Yuan, L. Yuan, S. C. Yuan, Y. Yuan, Z. Y. Yuan, C. X. Yue, Ying Yue, A. A. Zafar, F. R. Zeng, S. H. Zeng, X. Zeng, Y. Zeng, Y. J. Zeng, Y. J. Zeng, X. Y. Zhai, Y. C. Zhai, Y. H. Zhan, A. Q. Zhang, B. L. Zhang, B. X. Zhang, D. H. Zhang, G. Y. Zhang, H. Zhang, H. Zhang, H. C. Zhang, H. H. Zhang, H. Q. Zhang, H. R. Zhang, H. Y. Zhang, J. Zhang, J. Zhang, J. J. Zhang, J. L. Zhang, J. Q. Zhang, J. S. Zhang, J. W. Zhang, J. X. Zhang, J. Y. Zhang, J. Z. Zhang, Jianyu Zhang, L. M. Zhang, Lei Zhang, P. Zhang, Q. Zhang, Q. Y. Zhang, R. Y. Zhang, S. H. Zhang, Shulei Zhang, X. M. Zhang, X. Y Zhang, X. Y. Zhang, Y. Zhang, Y. Zhang, Y. T. Zhang, Y. H. Zhang, Y. M. Zhang, Yan Zhang, Z. D. Zhang, Z. H. Zhang, Z. L. Zhang, Z. X. Zhang, Z. Y. Zhang, Z. Y. Zhang, Z. Z. Zhang, Zh. Zh. Zhang, G. Zhao, J. Y. Zhao, J. Z. Zhao, L. Zhao, Lei Zhao, M. G. Zhao, N. Zhao, R. P. Zhao, S. J. Zhao, Y. B. Zhao, Y. X. Zhao, Z. G. Zhao, A. Zhemchugov, B. Zheng, B. M. Zheng, J. P. Zheng, W. J. Zheng, X. R. Zheng, Y. H. Zheng, B. Zhong, X. Zhong, H. Zhou, J. Y. Zhou, S. Zhou, X. Zhou, X. K. Zhou, X. R. Zhou, X. Y. Zhou, Y. Z. Zhou, Z. C. Zhou, A. N. Zhu, J. Zhu, K. Zhu, K. J. Zhu, K. S. Zhu, L. Zhu, L. X. Zhu, S. H. Zhu, T. J. Zhu, W. D. Zhu, W. J. Zhu, W. Z. Zhu, Y. C. Zhu, Z. A. Zhu, J. H. Zou, J. Zu","Using $e^+e^-$ collision data at 13 center-of-mass energies ranging from
4.600 to 4.950 GeV collected with the BESIII detector, we search for the
unmeasured $e^+e^-\to K_S^0 K_S^0 h_c$ process . No significant signal is
observed, and the upper limits of the Born cross sections at each
center-of-mass energy are presented.",http://arxiv.org/abs/2502.07406v1
"Precise Measurement of the $χ_{c0}$ Resonance Parameters and
  Branching Fractions of $χ_{c0,c2}\toπ^+π^-/K^+K^-$",2025-02-13T03:27:37Z,"BESIII Collaboration, M. Ablikim, M. N. Achasov, P. Adlarson, O. Afedulidis, X. C. Ai, R. Aliberti, A. Amoroso, Y. Bai, O. Bakina, I. Balossino, Y. Ban, H. -R. Bao, V. Batozskaya, K. Begzsuren, N. Berger, M. Berlowski, M. Bertani, D. Bettoni, F. Bianchi, E. Bianco, A. Bortone, I. Boyko, R. A. Briere, A. Brueggemann, H. Cai, X. Cai, A. Calcaterra, G. F. Cao, N. Cao, S. A. Cetin, X. Y. Chai, J. F. Chang, G. R. Che, Y. Z. Che, G. Chelkov, C. Chen, C. H. Chen, Chao Chen, G. Chen, H. S. Chen, H. Y. Chen, M. L. Chen, S. J. Chen, S. L. Chen, S. M. Chen, T. Chen, X. R. Chen, X. T. Chen, Y. B. Chen, Y. Q. Chen, Z. J. Chen, Z. Y. Chen, S. K. Choi, G. Cibinetto, F. Cossio, J. J. Cui, H. L. Dai, J. P. Dai, A. Dbeyssi, R. E. de Boer, D. Dedovich, C. Q. Deng, Z. Y. Deng, A. Denig, I. Denysenko, M. Destefanis, F. De Mori, B. Ding, X. X. Ding, Y. Ding, Y. Ding, J. Dong, L. Y. Dong, M. Y. Dong, X. Dong, M. C. Du, S. X. Du, Y. Y. Duan, Z. H. Duan, P. Egorov, Y. H. Fan, J. Fang, J. Fang, S. S. Fang, W. X. Fang, Y. Fang, Y. Q. Fang, R. Farinelli, L. Fava, F. Feldbauer, G. Felici, C. Q. Feng, J. H. Feng, Y. T. Feng, M. Fritsch, C. D. Fu, J. L. Fu, Y. W. Fu, H. Gao, X. B. Gao, Y. N. Gao, Yang Gao, S. Garbolino, I. Garzia, L. Ge, P. T. Ge, Z. W. Ge, C. Geng, E. M. Gersabeck, A. Gilman, K. Goetzen, L. Gong, W. X. Gong, W. Gradl, S. Gramigna, M. Greco, M. H. Gu, Y. T. Gu, C. Y. Guan, A. Q. Guo, L. B. Guo, M. J. Guo, R. P. Guo, Y. P. Guo, A. Guskov, J. Gutierrez, K. L. Han, T. T. Han, F. Hanisch, X. Q. Hao, F. A. Harris, K. K. He, K. L. He, F. H. Heinsius, C. H. Heinz, Y. K. Heng, C. Herold, T. Holtmann, P. C. Hong, G. Y. Hou, X. T. Hou, Y. R. Hou, Z. L. Hou, B. Y. Hu, H. M. Hu, J. F. Hu, Q. P. Hu, S. L. Hu, T. Hu, Y. Hu, G. S. Huang, K. X. Huang, L. Q. Huang, X. T. Huang, Y. P. Huang, Y. S. Huang, T. Hussain, F. Hölzken, N. Hüsken, N. in der Wiesche, J. Jackson, S. Janchiv, J. H. Jeong, Q. Ji, Q. P. Ji, W. Ji, X. B. Ji, X. L. Ji, Y. Y. Ji, X. Q. Jia, Z. K. Jia, D. Jiang, H. B. Jiang, P. C. Jiang, S. S. Jiang, T. J. Jiang, X. S. Jiang, Y. Jiang, J. B. Jiao, J. K. Jiao, Z. Jiao, S. Jin, Y. Jin, M. Q. Jing, X. M. Jing, T. Johansson, S. Kabana, N. Kalantar-Nayestanaki, X. L. Kang, X. S. Kang, M. Kavatsyuk, B. C. Ke, V. Khachatryan, A. Khoukaz, R. Kiuchi, O. B. Kolcu, B. Kopf, M. Kuessner, X. Kui, N. Kumar, A. Kupsc, W. Kühn, L. Lavezzi, T. T. Lei, Z. H. Lei, M. Lellmann, T. Lenz, C. Li, C. Li, C. H. Li, Cheng Li, D. M. Li, F. Li, G. Li, H. B. Li, H. J. Li, H. N. Li, Hui Li, J. R. Li, J. S. Li, K. Li, K. L. Li, L. J. Li, L. K. Li, Lei Li, M. H. Li, P. R. Li, Q. M. Li, Q. X. Li, R. Li, S. X. Li, T. Li, T. Y. Li, W. D. Li, W. G. Li, X. Li, X. H. Li, X. L. Li, X. Y. Li, X. Z. Li, Y. G. Li, Z. J. Li, Z. Y. Li, C. Liang, H. Liang, H. Liang, Y. F. Liang, Y. T. Liang, G. R. Liao, Y. P. Liao, J. Libby, A. Limphirat, C. C. Lin, C. X. Lin, D. X. Lin, T. Lin, B. J. Liu, B. X. Liu, C. Liu, C. X. Liu, F. Liu, F. H. Liu, Feng Liu, G. M. Liu, H. Liu, H. B. Liu, H. H. Liu, H. M. Liu, Huihui Liu, J. B. Liu, J. Y. Liu, K. Liu, K. Y. Liu, Ke Liu, L. Liu, L. C. Liu, Lu Liu, M. H. Liu, P. L. Liu, Q. Liu, S. B. Liu, T. Liu, W. K. Liu, W. M. Liu, X. Liu, X. Liu, Y. Liu, Y. Liu, Y. B. Liu, Z. A. Liu, Z. D. Liu, Z. Q. Liu, X. C. Lou, F. X. Lu, H. J. Lu, J. G. Lu, X. L. Lu, Y. Lu, Y. P. Lu, Z. H. Lu, C. L. Luo, J. R. Luo, M. X. Luo, T. Luo, X. L. Luo, X. R. Lyu, Y. F. Lyu, F. C. Ma, H. Ma, H. L. Ma, J. L. Ma, L. L. Ma, L. R. Ma, M. M. Ma, Q. M. Ma, R. Q. Ma, T. Ma, X. T. Ma, X. Y. Ma, Y. M. Ma, F. E. Maas, I. MacKay, M. Maggiora, S. Malde, Y. J. Mao, Z. P. Mao, S. Marcello, Z. X. Meng, J. G. Messchendorp, G. Mezzadri, H. Miao, T. J. Min, R. E. Mitchell, X. H. Mo, B. Moses, N. Yu. Muchnoi, J. Muskalla, Y. Nefedov, F. Nerling, L. S. Nie, I. B. Nikolaev, Z. Ning, S. Nisar, Q. L. Niu, W. D. Niu, Y. Niu, S. L. Olsen, S. L. Olsen, Q. Ouyang, S. Pacetti, X. Pan, Y. Pan, A. Pathak, Y. P. Pei, M. Pelizaeus, H. P. Peng, Y. Y. Peng, K. Peters, J. L. Ping, R. G. Ping, S. Plura, V. Prasad, F. Z. Qi, H. Qi, H. R. Qi, M. Qi, T. Y. Qi, S. Qian, W. B. Qian, C. F. Qiao, X. K. Qiao, J. J. Qin, L. Q. Qin, L. Y. Qin, X. P. Qin, X. S. Qin, Z. H. Qin, J. F. Qiu, Z. H. Qu, C. F. Redmer, K. J. Ren, A. Rivetti, M. Rolo, G. Rong, Ch. Rosner, M. Q. Ruan, S. N. Ruan, N. Salone, A. Sarantsev, Y. Schelhaas, K. Schoenning, M. Scodeggio, K. Y. Shan, W. Shan, X. Y. Shan, Z. J. Shang, J. F. Shangguan, L. G. Shao, M. Shao, C. P. Shen, H. F. Shen, W. H. Shen, X. Y. Shen, B. A. Shi, H. Shi, J. L. Shi, J. Y. Shi, Q. Q. Shi, S. Y. Shi, X. Shi, J. J. Song, T. Z. Song, W. M. Song, Y. J. Song, Y. X. Song, S. Sosio, S. Spataro, F. Stieler, S. S Su, Y. J. Su, G. B. Sun, G. X. Sun, H. Sun, H. K. Sun, J. F. Sun, K. Sun, L. Sun, S. S. Sun, T. Sun, W. Y. Sun, Y. Sun, Y. J. Sun, Y. Z. Sun, Z. Q. Sun, Z. T. Sun, C. J. Tang, G. Y. Tang, J. Tang, M. Tang, Y. A. Tang, L. Y. Tao, Q. T. Tao, M. Tat, J. X. Teng, V. Thoren, W. H. Tian, Y. Tian, Z. F. Tian, I. Uman, Y. Wan, S. J. Wang, B. Wang, B. L. Wang, Bo Wang, D. Y. Wang, F. Wang, H. J. Wang, J. J. Wang, J. P. Wang, K. Wang, L. L. Wang, M. Wang, N. Y. Wang, S. Wang, S. Wang, T. Wang, T. J. Wang, W. Wang, W. Wang, W. P. Wang, X. Wang, X. F. Wang, X. J. Wang, X. L. Wang, X. N. Wang, Y. Wang, Y. D. Wang, Y. F. Wang, Y. H. Wang, Y. L. Wang, Y. N. Wang, Y. Q. Wang, Yaqian Wang, Yi Wang, Z. Wang, Z. L. Wang, Z. Y. Wang, Ziyi Wang, D. H. Wei, F. Weidner, S. P. Wen, Y. R. Wen, U. Wiedner, G. Wilkinson, M. Wolke, L. Wollenberg, C. Wu, J. F. Wu, L. H. Wu, L. J. Wu, X. Wu, X. H. Wu, Y. Wu, Y. H. Wu, Y. J. Wu, Z. Wu, L. Xia, X. M. Xian, B. H. Xiang, T. Xiang, D. Xiao, G. Y. Xiao, S. Y. Xiao, Y. L. Xiao, Z. J. Xiao, C. Xie, X. H. Xie, Y. Xie, Y. G. Xie, Y. H. Xie, Z. P. Xie, T. Y. Xing, C. F. Xu, C. J. Xu, G. F. Xu, H. Y. Xu, M. Xu, Q. J. Xu, Q. N. Xu, W. Xu, W. L. Xu, X. P. Xu, Y. Xu, Y. C. Xu, Z. S. Xu, F. Yan, L. Yan, W. B. Yan, W. C. Yan, X. Q. Yan, H. J. Yang, H. L. Yang, H. X. Yang, J. H. Yang, T. Yang, Y. Yang, Y. F. Yang, Y. F. Yang, Y. X. Yang, Z. W. Yang, Z. P. Yao, M. Ye, M. H. Ye, J. H. Yin, Junhao Yin, Z. Y. You, B. X. Yu, C. X. Yu, G. Yu, J. S. Yu, M. C. Yu, T. Yu, X. D. Yu, Y. C. Yu, C. Z. Yuan, J. Yuan, J. Yuan, L. Yuan, S. C. Yuan, Y. Yuan, Z. Y. Yuan, C. X. Yue, A. A. Zafar, F. R. Zeng, S. H. Zeng, X. Zeng, Y. Zeng, Y. J. Zeng, Y. J. Zeng, X. Y. Zhai, Y. C. Zhai, Y. H. Zhan, A. Q. Zhang, B. L. Zhang, B. X. Zhang, D. H. Zhang, G. Y. Zhang, H. Zhang, H. Zhang, H. C. Zhang, H. H. Zhang, H. H. Zhang, H. Q. Zhang, H. R. Zhang, H. Y. Zhang, J. Zhang, J. Zhang, J. J. Zhang, J. L. Zhang, J. Q. Zhang, J. S. Zhang, J. W. Zhang, J. X. Zhang, J. Y. Zhang, J. Z. Zhang, Jianyu Zhang, L. M. Zhang, Lei Zhang, P. Zhang, Q. Y. Zhang, R. Y. Zhang, S. H. Zhang, Shulei Zhang, X. M. Zhang, X. Y Zhang, X. Y. Zhang, Y. Zhang, Y. Zhang, Y. T. Zhang, Y. H. Zhang, Y. M. Zhang, Yan Zhang, Z. D. Zhang, Z. H. Zhang, Z. L. Zhang, Z. Y. Zhang, Z. Y. Zhang, Z. Z. Zhang, G. Zhao, J. Y. Zhao, J. Z. Zhao, L. Zhao, Lei Zhao, M. G. Zhao, N. Zhao, R. P. Zhao, S. J. Zhao, Y. B. Zhao, Y. X. Zhao, Z. G. Zhao, A. Zhemchugov, B. Zheng, B. M. Zheng, J. P. Zheng, W. J. Zheng, Y. H. Zheng, B. Zhong, X. Zhong, H. Zhou, J. Y. Zhou, L. P. Zhou, S. Zhou, X. Zhou, X. K. Zhou, X. R. Zhou, X. Y. Zhou, Y. Z. Zhou, Z. C. Zhou, A. N. Zhu, J. Zhu, K. Zhu, K. J. Zhu, K. S. Zhu, L. Zhu, L. X. Zhu, S. H. Zhu, T. J. Zhu, W. D. Zhu, Y. C. Zhu, Z. A. Zhu, J. H. Zou, J. Zu","By analyzing a $\psi(3686)$ data sample containing
$(107.7\pm0.6)\times10^{6}$ events taken with the BESIII detector at the BEPCII
storage ring in 2009, the $\chi_{c0}$ resonance parameters are precisely
measured using $\chi_{c0,c2} \to \pi^+\pi^-/K^+K^-$ events. The mass of
$\chi_{c0}$ is determined to be
$M(\chi_{c0})=(3415.67\pm0.07\pm0.06\pm0.07$)~MeV/$c^2$, and its full width is
$\Gamma(\chi_{c0})=(12.44\pm0.12\pm0.12)~{\rm MeV}$, where the first
uncertainty is statistical, the second systematic, and the third for mass comes
from $\chi_{c2}$ mass uncertainty. These measurements improve the precision of
$\chi_{c0}$ mass by a factor of four and width by one order of magnitude over
the previous individual measurements, and significantly boost our knowledge
about the charmonium spectrum. Together with additional
$(345.4\pm2.6)\times10^{6}$ $\psi(3686)$ data events taken in 2012, the decay
branching fractions of $\chi_{c0,c2}\to\pi^+\pi^-/K^+K^-$ are measured as well,
with precision improved by a factor of three compared to previous measurements.
These $\chi_{c0}$ decay branching fractions provide important inputs for the
study of glueballs.",http://arxiv.org/abs/2502.08929v1
"Search for the Cabibbo-suppressed decays
  $Λ_c^{+}\toΣ^0K^{+}π^{0}$ and
  $Λ_c^{+}\toΣ^0K^{+}π^{+}π^{-}$",2025-02-16T09:09:25Z,"BESIII Collaboration, M. Ablikim, M. N. Achasov, P. Adlarson, X. C. Ai, R. Aliberti, A. Amoroso, Q. An, Y. Bai, O. Bakina, Y. Ban, H. -R. Bao, V. Batozskaya, K. Begzsuren, N. Berger, M. Berlowski, M. Bertani, D. Bettoni, F. Bianchi, E. Bianco, A. Bortone, I. Boyko, R. A. Briere, A. Brueggemann, H. Cai, M. H. Cai, X. Cai, A. Calcaterra, G. F. Cao, N. Cao, S. A. Cetin, X. Y. Chai, J. F. Chang, G. R. Che, Y. Z. Che, G. Chelkov, C. Chen, C. H. Chen, Chao Chen, G. Chen, H. S. Chen, H. Y. Chen, M. L. Chen, S. J. Chen, S. L. Chen, S. M. Chen, T. Chen, X. R. Chen, X. T. Chen, X. Y. Chen, Y. B. Chen, Y. Q. Chen, Y. Q. Chen, Z. J. Chen, Z. K. Chen, S. K. Choi, X. Chu, G. Cibinetto, F. Cossio, J. J. Cui, H. L. Dai, J. P. Dai, A. Dbeyssi, R. E. de Boer, D. Dedovich, C. Q. Deng, Z. Y. Deng, A. Denig, I. Denysenko, M. Destefanis, F. De Mori, B. Ding, X. X. Ding, Y. Ding, Y. Ding, Y. X. Ding, J. Dong, L. Y. Dong, M. Y. Dong, X. Dong, M. C. Du, S. X. Du, S. X. Du, Y. Y. Duan, Z. H. Duan, P. Egorov, G. F. Fan, J. J. Fan, Y. H. Fan, J. Fang, J. Fang, S. S. Fang, W. X. Fang, Y. Q. Fang, R. Farinelli, L. Fava, F. Feldbauer, G. Felici, C. Q. Feng, J. H. Feng, Y. T. Feng, M. Fritsch, C. D. Fu, J. L. Fu, Y. W. Fu, H. Gao, X. B. Gao, Y. Gao, Y. N. Gao, Y. N. Gao, Y. Y. Gao, S. Garbolino, I. Garzia, P. T. Ge, Z. W. Ge, C. Geng, E. M. Gersabeck, A. Gilman, K. Goetzen, L. Gong, W. X. Gong, W. Gradl, S. Gramigna, M. Greco, M. H. Gu, Y. T. Gu, C. Y. Guan, A. Q. Guo, L. B. Guo, M. J. Guo, R. P. Guo, Y. P. Guo, A. Guskov, J. Gutierrez, K. L. Han, T. T. Han, F. Hanisch, K. D. Hao, X. Q. Hao, F. A. Harris, K. K. He, K. L. He, F. H. Heinsius, C. H. Heinz, Y. K. Heng, C. Herold, T. Holtmann, P. C. Hong, G. Y. Hou, X. T. Hou, Y. R. Hou, Z. L. Hou, H. M. Hu, J. F. Hu, Q. P. Hu, S. L. Hu, T. Hu, Y. Hu, Z. M. Hu, G. S. Huang, K. X. Huang, L. Q. Huang, P. Huang, X. T. Huang, Y. P. Huang, Y. S. Huang, T. Hussain, N. Hüsken, N. in der Wiesche, J. Jackson, Q. Ji, Q. P. Ji, W. Ji, X. B. Ji, X. L. Ji, Y. Y. Ji, Z. K. Jia, D. Jiang, H. B. Jiang, P. C. Jiang, S. J. Jiang, T. J. Jiang, X. S. Jiang, Y. Jiang, J. B. Jiao, J. K. Jiao, Z. Jiao, S. Jin, Y. Jin, M. Q. Jing, X. M. Jing, T. Johansson, S. Kabana, N. Kalantar-Nayestanaki, X. L. Kang, X. S. Kang, M. Kavatsyuk, B. C. Ke, V. Khachatryan, A. Khoukaz, R. Kiuchi, O. B. Kolcu, B. Kopf, M. Kuessner, X. Kui, N. Kumar, A. Kupsc, W. Kühn, Q. Lan, W. N. Lan, T. T. Lei, M. Lellmann, T. Lenz, C. Li, C. Li, C. Li, C. H. Li, C. K. Li, D. M. Li, F. Li, G. Li, H. B. Li, H. J. Li, H. N. Li, Hui Li, J. R. Li, J. S. Li, K. Li, K. L. Li, K. L. Li, L. J. Li, Lei Li, M. H. Li, M. R. Li, P. L. Li, P. R. Li, Q. M. Li, Q. X. Li, R. Li, S. X. Li, T. Li, T. Y. Li, W. D. Li, W. G. Li, X. Li, X. H. Li, X. L. Li, X. Y. Li, X. Z. Li, Y. Li, Y. G. Li, Z. J. Li, Z. Y. Li, C. Liang, H. Liang, Y. F. Liang, Y. T. Liang, G. R. Liao, L. B. Liao, M. H. Liao, Y. P. Liao, J. Libby, A. Limphirat, C. C. Lin, C. X. Lin, D. X. Lin, L. Q. Lin, T. Lin, B. J. Liu, B. X. Liu, C. Liu, C. X. Liu, F. Liu, F. H. Liu, Feng Liu, G. M. Liu, H. Liu, H. B. Liu, H. H. Liu, H. M. Liu, Huihui Liu, J. B. Liu, J. J. Liu, K. Liu, K. Liu, K. Y. Liu, Ke Liu, L. Liu, L. C. Liu, Lu Liu, M. H. Liu, P. L. Liu, Q. Liu, S. B. Liu, T. Liu, W. K. Liu, W. M. Liu, W. T. Liu, X. Liu, X. Liu, X. Y. Liu, Y. Liu, Y. Liu, Y. Liu, Y. B. Liu, Z. A. Liu, Z. D. Liu, Z. Q. Liu, X. C. Lou, F. X. Lu, H. J. Lu, J. G. Lu, X. L. Lu, Y. Lu, Y. H. Lu, Y. P. Lu, Z. H. Lu, C. L. Luo, J. R. Luo, J. S. Luo, M. X. Luo, T. Luo, X. L. Luo, Z. Y. Lv, X. R. Lyu, Y. F. Lyu, Y. H. Lyu, F. C. Ma, H. Ma, H. L. Ma, J. L. Ma, L. L. Ma, L. R. Ma, Q. M. Ma, R. Q. Ma, R. Y. Ma, T. Ma, X. T. Ma, X. Y. Ma, Y. M. Ma, F. E. Maas, I. MacKay, M. Maggiora, S. Malde, Q. A. Malik, Y. J. Mao, Z. P. Mao, S. Marcello, Y. H. Meng, Z. X. Meng, J. G. Messchendorp, G. Mezzadri, H. Miao, T. J. Min, R. E. Mitchell, X. H. Mo, B. Moses, N. Yu. Muchnoi, J. Muskalla, Y. Nefedov, F. Nerling, L. S. Nie, I. B. Nikolaev, Z. Ning, S. Nisar, Q. L. Niu, W. D. Niu, S. L. Olsen, Q. Ouyang, S. Pacetti, X. Pan, Y. Pan, A. Pathak, Y. P. Pei, M. Pelizaeus, H. P. Peng, Y. Y. Peng, K. Peters, J. L. Ping, R. G. Ping, S. Plura, F. Z. Qi, H. R. Qi, M. Qi, S. Qian, W. B. Qian, C. F. Qiao, J. H. Qiao, J. J. Qin, J. L. Qin, L. Q. Qin, L. Y. Qin, P. B. Qin, X. P. Qin, X. S. Qin, Z. H. Qin, J. F. Qiu, Z. H. Qu, C. F. Redmer, A. Rivetti, M. Rolo, G. Rong, S. S. Rong, Ch. Rosner, M. Q. Ruan, S. N. Ruan, N. Salone, A. Sarantsev, Y. Schelhaas, K. Schoenning, M. Scodeggio, K. Y. Shan, W. Shan, X. Y. Shan, Z. J. Shang, J. F. Shangguan, L. G. Shao, M. Shao, C. P. Shen, H. F. Shen, W. H. Shen, X. Y. Shen, B. A. Shi, H. Shi, J. L. Shi, J. Y. Shi, S. Y. Shi, X. Shi, H. L. Song, J. J. Song, T. Z. Song, W. M. Song, Y. J. Song, Y. X. Song, S. Sosio, S. Spataro, F. Stieler, S. S Su, Y. J. Su, G. B. Sun, G. X. Sun, H. Sun, H. K. Sun, J. F. Sun, K. Sun, L. Sun, S. S. Sun, T. Sun, Y. C. Sun, Y. H. Sun, Y. J. Sun, Y. Z. Sun, Z. Q. Sun, Z. T. Sun, C. J. Tang, G. Y. Tang, J. Tang, J. J. Tang, L. F. Tang, Y. A. Tang, L. Y. Tao, M. Tat, J. X. Teng, J. Y. Tian, W. H. Tian, Y. Tian, Z. F. Tian, I. Uman, B. Wang, B. Wang, Bo Wang, C. Wang, Cong Wang, D. Y. Wang, H. J. Wang, J. J. Wang, K. Wang, L. L. Wang, L. W. Wang, M. Wang, M. Wang, N. Y. Wang, S. Wang, S. Wang, T. Wang, T. J. Wang, W. Wang, W. Wang, W. P. Wang, X. Wang, X. F. Wang, X. J. Wang, X. L. Wang, X. N. Wang, Y. Wang, Y. D. Wang, Y. F. Wang, Y. H. Wang, Y. J. Wang, Y. L. Wang, Y. N. Wang, Y. Q. Wang, Yaqian Wang, Yi Wang, Yuan Wang, Z. Wang, Z. L. Wang, Z. L. Wang, Z. Q. Wang, Z. Y. Wang, D. H. Wei, F. Weidner, S. P. Wen, Y. R. Wen, U. Wiedner, G. Wilkinson, M. Wolke, C. Wu, J. F. Wu, L. H. Wu, L. J. Wu, L. J. Wu, Lianjie Wu, S. G. Wu, S. M. Wu, X. Wu, X. H. Wu, Y. J. Wu, Z. Wu, L. Xia, X. M. Xian, B. H. Xiang, D. Xiao, G. Y. Xiao, H. Xiao, Y. L. Xiao, Z. J. Xiao, C. Xie, K. J. Xie, X. H. Xie, Y. Xie, Y. G. Xie, Y. H. Xie, Z. P. Xie, T. Y. Xing, C. F. Xu, C. J. Xu, G. F. Xu, H. Y. Xu, H. Y. Xu, M. Xu, Q. J. Xu, Q. N. Xu, T. D. Xu, W. Xu, W. L. Xu, X. P. Xu, Y. Xu, Y. Xu, Y. C. Xu, Z. S. Xu, F. Yan, H. Y. Yan, L. Yan, W. B. Yan, W. C. Yan, W. H. Yan, W. P. Yan, X. Q. Yan, H. J. Yang, H. L. Yang, H. X. Yang, J. H. Yang, R. J. Yang, T. Yang, Y. Yang, Y. F. Yang, Y. H. Yang, Y. Q. Yang, Y. X. Yang, Y. Z. Yang, M. Ye, M. H. Ye, Junhao Yin, Z. Y. You, B. X. Yu, C. X. Yu, G. Yu, J. S. Yu, L. Q. Yu, M. C. Yu, T. Yu, X. D. Yu, Y. C. Yu, C. Z. Yuan, H. Yuan, J. Yuan, J. Yuan, L. Yuan, S. C. Yuan, X. Q. Yuan, Y. Yuan, Z. Y. Yuan, C. X. Yue, Ying Yue, A. A. Zafar, S. H. Zeng, X. Zeng, Y. Zeng, Y. J. Zeng, Y. J. Zeng, X. Y. Zhai, Y. H. Zhan, A. Q. Zhang, B. L. Zhang, B. X. Zhang, D. H. Zhang, G. Y. Zhang, G. Y. Zhang, H. Zhang, H. Zhang, H. C. Zhang, H. H. Zhang, H. Q. Zhang, H. R. Zhang, H. Y. Zhang, J. Zhang, J. Zhang, J. J. Zhang, J. L. Zhang, J. Q. Zhang, J. S. Zhang, J. W. Zhang, J. X. Zhang, J. Y. Zhang, J. Z. Zhang, Jianyu Zhang, L. M. Zhang, Lei Zhang, N. Zhang, P. Zhang, Q. Zhang, Q. Y. Zhang, R. Y. Zhang, S. H. Zhang, Shulei Zhang, X. M. Zhang, X. Y Zhang, X. Y. Zhang, Y. Zhang, Y. Zhang, Y. T. Zhang, Y. H. Zhang, Y. M. Zhang, Y. P. Zhang, Z. D. Zhang, Z. H. Zhang, Z. L. Zhang, Z. L. Zhang, Z. X. Zhang, Z. Y. Zhang, Z. Y. Zhang, Z. Z. Zhang, Zh. Zh. Zhang, G. Zhao, J. Y. Zhao, J. Z. Zhao, L. Zhao, L. Zhao, M. G. Zhao, N. Zhao, R. P. Zhao, S. J. Zhao, Y. B. Zhao, Y. L. Zhao, Y. X. Zhao, Z. G. Zhao, A. Zhemchugov, B. Zheng, B. M. Zheng, J. P. Zheng, W. J. Zheng, X. R. Zheng, Y. H. Zheng, B. Zhong, C. Zhong, H. Zhou, J. Y. Zhou, S. Zhou, X. Zhou, X. K. Zhou, X. R. Zhou, X. Y. Zhou, Y. Z. Zhou, A. N. Zhu, J. Zhu, K. Zhu, K. J. Zhu, K. S. Zhu, L. Zhu, L. X. Zhu, S. H. Zhu, T. J. Zhu, W. D. Zhu, W. D. Zhu, W. J. Zhu, W. Z. Zhu, Y. C. Zhu, Z. A. Zhu, X. Y. Zhuang, J. H. Zou, J. Zu","Utilizing 4.5 $fb^-$ of $e^+e^-$ annihilation data collected at
center-of-mass energies ranging from 4599.53 MeV to 4698.82 MeV by the BESIII
detector at the BEPCII collider, we search for the singly Cabibbo-suppressed
hadronic decays $\Lambda_{c}^{+}\to\Sigma^{0} K^{+}\pi^{0}$ and
$\Lambda_{c}^{+}\to\Sigma^{0}K^{+}\pi^+\pi^-$ with a single-tag method. No
significant signals are observed for both decays. The upper limits on the
branching fractions at the $90\%$ confidence level are determined to be
$5.0\times 10^{-4}$ for $\Lambda_{c}^{+}\to\Sigma^{0} K^{+}\pi^{0}$ and
$6.5\times 10^{-4}$ for $\Lambda_c^{+}\to\Sigma^0K^{+}\pi^{+}\pi^{-}$.",http://arxiv.org/abs/2502.11047v1
Amplitude analysis of $ψ(3686)\to γK_S^0 K_S^0 $,2025-02-19T08:48:24Z,"BESIII Collaboration, M. Ablikim, M. N. Achasov, P. Adlarson, X. C. Ai, R. Aliberti, A. Amoroso, Q. An, Y. Bai, O. Bakina, Y. Ban, H. -R. Bao, V. Batozskaya, K. Begzsuren, N. Berger, M. Berlowski, M. Bertani, D. Bettoni, F. Bianchi, E. Bianco, A. Bortone, I. Boyko, R. A. Briere, A. Brueggemann, H. Cai, M. H. Cai, X. Cai, A. Calcaterra, G. F. Cao, N. Cao, S. A. Cetin, X. Y. Chai, J. F. Chang, G. R. Che, Y. Z. Che, G. Chelkov, C. H. Chen, Chao Chen, G. Chen, H. S. Chen, H. Y. Chen, M. L. Chen, S. J. Chen, S. L. Chen, S. M. Chen, T. Chen, X. R. Chen, X. T. Chen, X. Y. Chen, Y. B. Chen, Y. Q. Chen, Y. Q. Chen, Z. J. Chen, Z. K. Chen, S. K. Choi, X. Chu, G. Cibinetto, F. Cossio, J. Cottee-Meldrum, J. J. Cui, H. L. Dai, J. P. Dai, A. Dbeyssi, R. E. de Boer, D. Dedovich, C. Q. Deng, Z. Y. Deng, A. Denig, I. Denysenko, M. Destefanis, F. De Mori, B. Ding, X. X. Ding, Y. Ding, Y. Ding, Y. X. Ding, J. Dong, L. Y. Dong, M. Y. Dong, X. Dong, M. C. Du, S. X. Du, S. X. Du, Y. Y. Duan, Z. H. Duan, P. Egorov, G. F. Fan, J. J. Fan, Y. H. Fan, J. Fang, J. Fang, S. S. Fang, W. X. Fang, Y. Q. Fang, R. Farinelli, L. Fava, F. Feldbauer, G. Felici, C. Q. Feng, J. H. Feng, L. Feng, Q. X. Feng, Y. T. Feng, M. Fritsch, C. D. Fu, J. L. Fu, Y. W. Fu, H. Gao, X. B. Gao, Y. Gao, Y. N. Gao, Y. N. Gao, Y. Y. Gao, S. Garbolino, I. Garzia, P. T. Ge, Z. W. Ge, C. Geng, E. M. Gersabeck, A. Gilman, K. Goetzen, J. D. Gong, L. Gong, W. X. Gong, W. Gradl, S. Gramigna, M. Greco, M. H. Gu, Y. T. Gu, C. Y. Guan, A. Q. Guo, L. B. Guo, M. J. Guo, R. P. Guo, Y. P. Guo, A. Guskov, J. Gutierrez, K. L. Han, T. T. Han, F. Hanisch, K. D. Hao, X. Q. Hao, F. A. Harris, K. K. He, K. L. He, F. H. Heinsius, C. H. Heinz, Y. K. Heng, C. Herold, T. Holtmann, P. C. Hong, G. Y. Hou, X. T. Hou, Y. R. Hou, Z. L. Hou, H. M. Hu, J. F. Hu, Q. P. Hu, S. L. Hu, T. Hu, Y. Hu, Z. M. Hu, G. S. Huang, K. X. Huang, L. Q. Huang, P. Huang, X. T. Huang, Y. P. Huang, Y. S. Huang, T. Hussain, N. Hüsken, N. in der Wiesche, J. Jackson, Q. Ji, Q. P. Ji, W. Ji, X. B. Ji, X. L. Ji, Y. Y. Ji, Z. K. Jia, D. Jiang, H. B. Jiang, P. C. Jiang, S. J. Jiang, T. J. Jiang, X. S. Jiang, Y. Jiang, J. B. Jiao, J. K. Jiao, Z. Jiao, S. Jin, Y. Jin, M. Q. Jing, X. M. Jing, T. Johansson, S. Kabana, N. Kalantar-Nayestanaki, X. L. Kang, X. S. Kang, M. Kavatsyuk, B. C. Ke, V. Khachatryan, A. Khoukaz, R. Kiuchi, O. B. Kolcu, B. Kopf, M. Kuessner, X. Kui, N. Kumar, A. Kupsc, W. Kühn, Q. Lan, W. N. Lan, T. T. Lei, M. Lellmann, T. Lenz, C. Li, C. Li, C. Li, C. H. Li, C. K. Li, D. M. Li, F. Li, G. Li, H. B. Li, H. J. Li, H. N. Li, Hui Li, J. R. Li, J. S. Li, K. Li, K. L. Li, K. L. Li, L. J. Li, Lei Li, M. H. Li, M. R. Li, P. L. Li, P. R. Li, Q. M. Li, Q. X. Li, R. Li, S. X. Li, T. Li, T. Y. Li, W. D. Li, W. G. Li, X. Li, X. H. Li, X. L. Li, X. Y. Li, X. Z. Li, Y. Li, Y. G. Li, Y. P. Li, Z. J. Li, Z. Y. Li, C. Liang, H. Liang, Y. F. Liang, Y. T. Liang, G. R. Liao, L. B. Liao, M. H. Liao, Y. P. Liao, J. Libby, A. Limphirat, C. C. Lin, C. X. Lin, D. X. Lin, L. Q. Lin, T. Lin, B. J. Liu, B. X. Liu, C. Liu, C. X. Liu, F. Liu, F. H. Liu, Feng Liu, G. M. Liu, H. Liu, H. B. Liu, H. H. Liu, H. M. Liu, Huihui Liu, J. B. Liu, J. J. Liu, K. Liu, K. Liu, K. Y. Liu, Ke Liu, L. Liu, L. C. Liu, Lu Liu, M. H. Liu, P. L. Liu, Q. Liu, S. B. Liu, T. Liu, W. K. Liu, W. M. Liu, W. T. Liu, X. Liu, X. Liu, X. K. Liu, X. Y. Liu, Y. Liu, Y. Liu, Y. Liu, Y. B. Liu, Z. A. Liu, Z. D. Liu, Z. Q. Liu, X. C. Lou, F. X. Lu, H. J. Lu, J. G. Lu, X. L. Lu, Y. Lu, Y. H. Lu, Y. P. Lu, Z. H. Lu, C. L. Luo, J. R. Luo, J. S. Luo, M. X. Luo, T. Luo, X. L. Luo, Z. Y. Lv, X. R. Lyu, Y. F. Lyu, Y. H. Lyu, F. C. Ma, H. Ma, H. L. Ma, J. L. Ma, L. L. Ma, L. R. Ma, Q. M. Ma, R. Q. Ma, R. Y. Ma, T. Ma, X. T. Ma, X. Y. Ma, Y. M. Ma, F. E. Maas, I. MacKay, M. Maggiora, S. Malde, Q. A. Malik, H. X. Mao, Y. J. Mao, Z. P. Mao, S. Marcello, A. Marshall, F. M. Melendi, Y. H. Meng, Z. X. Meng, J. G. Messchendorp, G. Mezzadri, H. Miao, T. J. Min, R. E. Mitchell, X. H. Mo, B. Moses, N. Yu. Muchnoi, J. Muskalla, Y. Nefedov, F. Nerling, L. S. Nie, I. B. Nikolaev, Z. Ning, S. Nisar, Q. L. Niu, W. D. Niu, C. Normand, S. L. Olsen, Q. Ouyang, S. Pacetti, X. Pan, Y. Pan, A. Pathak, Y. P. Pei, M. Pelizaeus, H. P. Peng, X. J. Peng, Y. Y. Peng, K. Peters, K. Petridis, J. L. Ping, R. G. Ping, S. Plura, V. Prasad, F. Z. Qi, H. R. Qi, M. Qi, S. Qian, W. B. Qian, C. F. Qiao, J. H. Qiao, J. J. Qin, J. L. Qin, L. Q. Qin, L. Y. Qin, P. B. Qin, X. P. Qin, X. S. Qin, Z. H. Qin, J. F. Qiu, Z. H. Qu, J. Rademacker, C. F. Redmer, A. Rivetti, M. Rolo, G. Rong, S. S. Rong, F. Rosini, Ch. Rosner, M. Q. Ruan, N. Salone, A. Sarantsev, Y. Schelhaas, K. Schoenning, M. Scodeggio, K. Y. Shan, W. Shan, X. Y. Shan, Z. J. Shang, J. F. Shangguan, L. G. Shao, M. Shao, C. P. Shen, H. F. Shen, W. H. Shen, X. Y. Shen, B. A. Shi, H. Shi, J. L. Shi, J. Y. Shi, S. Y. Shi, X. Shi, H. L. Song, J. J. Song, T. Z. Song, W. M. Song, Y. J. Song, Y. X. Song, S. Sosio, S. Spataro, F. Stieler, S. S Su, Y. J. Su, G. B. Sun, G. X. Sun, H. Sun, H. K. Sun, J. F. Sun, K. Sun, L. Sun, S. S. Sun, T. Sun, Y. C. Sun, Y. H. Sun, Y. J. Sun, Y. Z. Sun, Z. Q. Sun, Z. T. Sun, C. J. Tang, G. Y. Tang, J. Tang, J. J. Tang, L. F. Tang, Y. A. Tang, L. Y. Tao, M. Tat, J. X. Teng, J. Y. Tian, W. H. Tian, Y. Tian, Z. F. Tian, I. Uman, B. Wang, B. Wang, Bo Wang, C. Wang, C. Wang, Cong Wang, D. Y. Wang, H. J. Wang, J. J. Wang, K. Wang, L. L. Wang, L. W. Wang, M. Wang, M. Wang, N. Y. Wang, S. Wang, T. Wang, T. J. Wang, W. Wang, W. Wang, W. P. Wang, X. Wang, X. F. Wang, X. J. Wang, X. L. Wang, X. N. Wang, Y. Wang, Y. D. Wang, Y. F. Wang, Y. H. Wang, Y. J. Wang, Y. L. Wang, Y. N. Wang, Y. Q. Wang, Yaqian Wang, Yi Wang, Yuan Wang, Z. Wang, Z. L. Wang, Z. L. Wang, Z. Q. Wang, Z. Y. Wang, D. H. Wei, H. R. Wei, F. Weidner, S. P. Wen, Y. R. Wen, U. Wiedner, G. Wilkinson, M. Wolke, C. Wu, J. F. Wu, L. H. Wu, L. J. Wu, L. J. Wu, Lianjie Wu, S. G. Wu, S. M. Wu, X. Wu, X. H. Wu, Y. J. Wu, Z. Wu, L. Xia, X. M. Xian, B. H. Xiang, D. Xiao, G. Y. Xiao, H. Xiao, Y. L. Xiao, Z. J. Xiao, C. Xie, K. J. Xie, X. H. Xie, Y. Xie, Y. G. Xie, Y. H. Xie, Z. P. Xie, T. Y. Xing, C. F. Xu, C. J. Xu, G. F. Xu, H. Y. Xu, H. Y. Xu, M. Xu, Q. J. Xu, Q. N. Xu, T. D. Xu, W. Xu, W. L. Xu, X. P. Xu, Y. Xu, Y. Xu, Y. C. Xu, Z. S. Xu, F. Yan, H. Y. Yan, L. Yan, W. B. Yan, W. C. Yan, W. H. Yan, W. P. Yan, X. Q. Yan, H. J. Yang, H. L. Yang, H. X. Yang, J. H. Yang, R. J. Yang, T. Yang, Y. Yang, Y. F. Yang, Y. H. Yang, Y. Q. Yang, Y. X. Yang, Y. Z. Yang, M. Ye, M. H. Ye, Z. J. Ye, Junhao Yin, Z. Y. You, B. X. Yu, C. X. Yu, G. Yu, J. S. Yu, L. Q. Yu, M. C. Yu, T. Yu, X. D. Yu, Y. C. Yu, C. Z. Yuan, H. Yuan, J. Yuan, J. Yuan, L. Yuan, S. C. Yuan, X. Q. Yuan, Y. Yuan, Z. Y. Yuan, C. X. Yue, Ying Yue, A. A. Zafar, S. H. Zeng, X. Zeng, Y. Zeng, Y. J. Zeng, Y. J. Zeng, X. Y. Zhai, Y. H. Zhan, A. Q. Zhang, B. L. Zhang, B. X. Zhang, D. H. Zhang, G. Y. Zhang, G. Y. Zhang, H. Zhang, H. Zhang, H. C. Zhang, H. H. Zhang, H. Q. Zhang, H. R. Zhang, H. Y. Zhang, J. Zhang, J. Zhang, J. J. Zhang, J. L. Zhang, J. Q. Zhang, J. S. Zhang, J. W. Zhang, J. X. Zhang, J. Y. Zhang, J. Z. Zhang, Jianyu Zhang, L. M. Zhang, Lei Zhang, N. Zhang, P. Zhang, Q. Zhang, Q. Y. Zhang, R. Y. Zhang, S. H. Zhang, Shulei Zhang, X. M. Zhang, X. Y Zhang, X. Y. Zhang, Y. Zhang, Y. Zhang, Y. T. Zhang, Y. H. Zhang, Y. M. Zhang, Y. P. Zhang, Z. D. Zhang, Z. H. Zhang, Z. L. Zhang, Z. L. Zhang, Z. X. Zhang, Z. Y. Zhang, Z. Y. Zhang, Z. Z. Zhang, Zh. Zh. Zhang, G. Zhao, J. Y. Zhao, J. Z. Zhao, L. Zhao, L. Zhao, M. G. Zhao, N. Zhao, R. P. Zhao, S. J. Zhao, Y. B. Zhao, Y. L. Zhao, Y. X. Zhao, Z. G. Zhao, A. Zhemchugov, B. Zheng, B. M. Zheng, J. P. Zheng, W. J. Zheng, X. R. Zheng, Y. H. Zheng, B. Zhong, C. Zhong, H. Zhou, J. Q. Zhou, J. Y. Zhou, S. Zhou, X. Zhou, X. K. Zhou, X. R. Zhou, X. Y. Zhou, Y. X. Zhou, Y. Z. Zhou, A. N. Zhu, J. Zhu, K. Zhu, K. J. Zhu, K. S. Zhu, L. Zhu, L. X. Zhu, S. H. Zhu, T. J. Zhu, W. D. Zhu, W. D. Zhu, W. J. Zhu, W. Z. Zhu, Y. C. Zhu, Z. A. Zhu, X. Y. Zhuang, J. H. Zou, J. Zu","Using $(2712\pm14)\times10^6$ $\psi(3686)$ events collected with the BESIII
detector, we perform the first amplitude analysis of the radiative decay
$\psi(3686)\to \gamma K_S^0 K_S^0$ within the mass region $M_{K_S^0 K_S^0
}<2.8$ GeV/$c^2$. Employing a one-channel K-matrix approach for the description
of the dynamics of the $K^0_S K^0_S$ system, the data sample is well described
with four poles for the $f_0$-wave and three poles for the $f_2$-wave. The
determined pole positions are consistent with those of well-established
resonance states. The observed $f_0$ and $f_{2}$ states are found to be
qualitatively consistent with those produced in radiative $J/\psi$ decays,
indicating the similarity between the two charmonium states in their radiative
decays.",http://arxiv.org/abs/2502.13540v1
"Search for resonance-enhanced $CP$ and angular asymmetries in the
  $Λ^+_{c}\to pμ^+μ^-$ decay at LHCb",2025-02-06T12:16:04Z,"LHCb collaboration, R. Aaij, A. S. W. Abdelmotteleb, C. Abellan Beteta, F. Abudinén, T. Ackernley, A. A. Adefisoye, B. Adeva, M. Adinolfi, P. Adlarson, C. Agapopoulou, C. A. Aidala, Z. Ajaltouni, S. Akar, K. Akiba, P. Albicocco, J. Albrecht, F. Alessio, M. Alexander, Z. Aliouche, P. Alvarez Cartelle, R. Amalric, S. Amato, J. L. Amey, Y. Amhis, L. An, L. Anderlini, M. Andersson, A. Andreianov, P. Andreola, M. Andreotti, D. Andreou, A. Anelli, D. Ao, F. Archilli, M. Argenton, S. Arguedas Cuendis, A. Artamonov, M. Artuso, E. Aslanides, R. Ataíde Da Silva, M. Atzeni, B. Audurier, D. Bacher, I. Bachiller Perea, S. Bachmann, M. Bachmayer, J. J. Back, P. Baladron Rodriguez, V. Balagura, A. Balboni, W. Baldini, L. Balzani, H. Bao, J. Baptista de Souza Leite, C. Barbero Pretel, M. Barbetti, I. R. Barbosa, R. J. Barlow, M. Barnyakov, S. Barsuk, W. Barter, J. Bartz, J. M. Basels, S. Bashir, G. Bassi, B. Batsukh, P. B. Battista, A. Bay, A. Beck, M. Becker, F. Bedeschi, I. B. Bediaga, N. A. Behling, S. Belin, K. Belous, I. Belov, I. Belyaev, G. Benane, G. Bencivenni, E. Ben-Haim, A. Berezhnoy, R. Bernet, S. Bernet Andres, A. Bertolin, C. Betancourt, F. Betti, J. Bex, Ia. Bezshyiko, J. Bhom, M. S. Bieker, N. V. Biesuz, P. Billoir, A. Biolchini, M. Birch, F. C. R. Bishop, A. Bitadze, A. Bizzeti, T. Blake, F. Blanc, J. E. Blank, S. Blusk, V. Bocharnikov, J. A. Boelhauve, O. Boente Garcia, T. Boettcher, A. Bohare, A. Boldyrev, C. S. Bolognani, R. Bolzonella, R. B. Bonacci, N. Bondar, A. Bordelius, F. Borgato, S. Borghi, M. Borsato, J. T. Borsuk, E. Bottalico, S. A. Bouchiba, M. Bovill, T. J. V. Bowcock, A. Boyer, C. Bozzi, J. D. Brandenburg, A. Brea Rodriguez, N. Breer, J. Brodzicka, A. Brossa Gonzalo, J. Brown, D. Brundu, E. Buchanan, L. Buonincontri, M. Burgos Marcos, A. T. Burke, C. Burr, J. S. Butter, J. Buytaert, W. Byczynski, S. Cadeddu, H. Cai, A. Caillet, R. Calabrese, S. Calderon Ramirez, L. Calefice, S. Cali, M. Calvi, M. Calvo Gomez, P. Camargo Magalhaes, J. I. Cambon Bouzas, P. Campana, D. H. Campora Perez, A. F. Campoverde Quezada, S. Capelli, L. Capriotti, R. Caravaca-Mora, A. Carbone, L. Carcedo Salgado, R. Cardinale, A. Cardini, P. Carniti, L. Carus, A. Casais Vidal, R. Caspary, G. Casse, M. Cattaneo, G. Cavallero, V. Cavallini, S. Celani, S. Cesare, A. J. Chadwick, I. Chahrour, H. Chang, M. Charles, Ph. Charpentier, E. Chatzianagnostou, M. Chefdeville, C. Chen, S. Chen, Z. Chen, A. Chernov, S. Chernyshenko, X. Chiotopoulos, V. Chobanova, M. Chrzaszcz, A. Chubykin, V. Chulikov, P. Ciambrone, X. Cid Vidal, G. Ciezarek, P. Cifra, P. E. L. Clarke, M. Clemencic, H. V. Cliff, J. Closier, C. Cocha Toapaxi, V. Coco, J. Cogan, E. Cogneras, L. Cojocariu, S. Collaviti, P. Collins, T. Colombo, M. Colonna, A. Comerma-Montells, L. Congedo, A. Contu, N. Cooke, I. Corredoira, A. Correia, G. Corti, J. Cottee Meldrum, B. Couturier, D. C. Craik, M. Cruz Torres, E. Curras Rivera, R. Currie, C. L. Da Silva, S. Dadabaev, L. Dai, X. Dai, E. Dall'Occo, J. Dalseno, C. D'Ambrosio, J. Daniel, A. Danilina, P. d'Argent, G. Darze, A. Davidson, J. E. Davies, O. De Aguiar Francisco, C. De Angelis, F. De Benedetti, J. de Boer, K. De Bruyn, S. De Capua, M. De Cian, U. De Freitas Carneiro Da Graca, E. De Lucia, J. M. De Miranda, L. De Paula, M. De Serio, P. De Simone, F. De Vellis, J. A. de Vries, F. Debernardis, D. Decamp, V. Dedu, S. Dekkers, L. Del Buono, B. Delaney, H. -P. Dembinski, J. Deng, V. Denysenko, O. Deschamps, F. Dettori, B. Dey, P. Di Nezza, I. Diachkov, S. Didenko, S. Ding, L. Dittmann, V. Dobishuk, A. D. Docheva, C. Dong, A. M. Donohoe, F. Dordei, A. C. dos Reis, A. D. Dowling, W. Duan, P. Duda, M. W. Dudek, L. Dufour, V. Duk, P. Durante, M. M. Duras, J. M. Durham, O. D. Durmus, A. Dziurda, A. Dzyuba, S. Easo, E. Eckstein, U. Egede, A. Egorychev, V. Egorychev, S. Eisenhardt, E. Ejopu, L. Eklund, M. Elashri, J. Ellbracht, S. Ely, A. Ene, J. Eschle, S. Esen, T. Evans, F. Fabiano, L. N. Falcao, Y. Fan, B. Fang, L. Fantini, M. Faria, K. Farmer, D. Fazzini, L. Felkowski, M. Feng, M. Feo, A. Fernandez Casani, M. Fernandez Gomez, A. D. Fernez, F. Ferrari, F. Ferreira Rodrigues, M. Ferrillo, M. Ferro-Luzzi, S. Filippov, R. A. Fini, M. Fiorini, M. Firlej, K. L. Fischer, D. S. Fitzgerald, C. Fitzpatrick, T. Fiutowski, F. Fleuret, M. Fontana, L. F. Foreman, R. Forty, D. Foulds-Holt, V. Franco Lima, M. Franco Sevilla, M. Frank, E. Franzoso, G. Frau, C. Frei, D. A. Friday, J. Fu, Q. Führing, Y. Fujii, T. Fulghesu, E. Gabriel, G. Galati, M. D. Galati, A. Gallas Torreira, D. Galli, S. Gambetta, M. Gandelman, P. Gandini, B. Ganie, H. Gao, R. Gao, T. Q. Gao, Y. Gao, Y. Gao, Y. Gao, L. M. Garcia Martin, P. Garcia Moreno, J. García Pardiñas, P. Gardner, K. G. Garg, L. Garrido, C. Gaspar, A. Gavrikov, L. L. Gerken, E. Gersabeck, M. Gersabeck, T. Gershon, S. Ghizzo, Z. Ghorbanimoghaddam, L. Giambastiani, F. I. Giasemis, V. Gibson, H. K. Giemza, A. L. Gilman, M. Giovannetti, A. Gioventù, L. Girardey, C. Giugliano, M. A. Giza, F. C. Glaser, V. V. Gligorov, C. Göbel, L. Golinka-Bezshyyko, E. Golobardes, D. Golubkov, A. Golutvin, S. Gomez Fernandez, W. Gomulka, F. Goncalves Abrantes, M. Goncerz, G. Gong, J. A. Gooding, I. V. Gorelov, C. Gotti, E. Govorkova, J. P. Grabowski, L. A. Granado Cardoso, E. Graugés, E. Graverini, L. Grazette, G. Graziani, A. T. Grecu, L. M. Greeven, N. A. Grieser, L. Grillo, S. Gromov, C. Gu, M. Guarise, L. Guerry, V. Guliaeva, P. A. Günther, A. -K. Guseinov, E. Gushchin, Y. Guz, T. Gys, K. Habermann, T. Hadavizadeh, C. Hadjivasiliou, G. Haefeli, C. Haen, G. Hallett, M. M. Halvorsen, P. M. Hamilton, J. Hammerich, Q. Han, X. Han, S. Hansmann-Menzemer, L. Hao, N. Harnew, T. H. Harris, M. Hartmann, S. Hashmi, J. He, F. Hemmer, C. Henderson, R. D. L. Henderson, A. M. Hennequin, K. Hennessy, L. Henry, J. Herd, P. Herrero Gascon, J. Heuel, A. Hicheur, G. Hijano Mendizabal, J. Horswill, R. Hou, Y. Hou, N. Howarth, J. Hu, W. Hu, X. Hu, W. Huang, W. Hulsbergen, R. J. Hunter, M. Hushchyn, D. Hutchcroft, M. Idzik, D. Ilin, P. Ilten, A. Inglessi, A. Iniukhin, A. Ishteev, K. Ivshin, R. Jacobsson, H. Jage, S. J. Jaimes Elles, S. Jakobsen, E. Jans, B. K. Jashal, A. Jawahery, V. Jevtic, E. Jiang, X. Jiang, Y. Jiang, Y. J. Jiang, M. John, A. John Rubesh Rajan, D. Johnson, C. R. Jones, T. P. Jones, S. Joshi, B. Jost, J. Juan Castella, N. Jurik, I. Juszczak, D. Kaminaris, S. Kandybei, M. Kane, Y. Kang, C. Kar, M. Karacson, D. Karpenkov, A. Kauniskangas, J. W. Kautz, M. K. Kazanecki, F. Keizer, M. Kenzie, T. Ketel, B. Khanji, A. Kharisova, S. Kholodenko, G. Khreich, T. Kirn, V. S. Kirsebom, O. Kitouni, S. Klaver, N. Kleijne, K. Klimaszewski, M. R. Kmiec, S. Koliiev, L. Kolk, A. Konoplyannikov, P. Kopciewicz, P. Koppenburg, M. Korolev, I. Kostiuk, O. Kot, S. Kotriakhova, A. Kozachuk, P. Kravchenko, L. Kravchuk, M. Kreps, P. Krokovny, W. Krupa, W. Krzemien, O. Kshyvanskyi, S. Kubis, M. Kucharczyk, V. Kudryavtsev, E. Kulikova, A. Kupsc, B. K. Kutsenko, D. Lacarrere, P. Laguarta Gonzalez, A. Lai, A. Lampis, D. Lancierini, C. Landesa Gomez, J. J. Lane, R. Lane, G. Lanfranchi, C. Langenbruch, J. Langer, O. Lantwin, T. Latham, F. Lazzari, C. Lazzeroni, R. Le Gac, H. Lee, R. Lefèvre, A. Leflat, S. Legotin, M. Lehuraux, E. Lemos Cid, O. Leroy, T. Lesiak, E. D. Lesser, B. Leverington, A. Li, C. Li, C. Li, H. Li, K. Li, L. Li, M. Li, P. Li, P. -R. Li, Q. Li, S. Li, T. Li, T. Li, Y. Li, Y. Li, Z. Lian, X. Liang, S. Libralon, C. Lin, T. Lin, R. Lindner, H. Linton, V. Lisovskyi, R. Litvinov, F. L. Liu, G. Liu, K. Liu, S. Liu, W. Liu, Y. Liu, Y. Liu, Y. L. Liu, G. Loachamin Ordonez, A. Lobo Salvia, A. Loi, T. Long, J. H. Lopes, A. Lopez Huertas, S. López Soliño, Q. Lu, C. Lucarelli, D. Lucchesi, M. Lucio Martinez, V. Lukashenko, Y. Luo, A. Lupato, E. Luppi, K. Lynch, X. -R. Lyu, G. M. Ma, S. Maccolini, F. Machefert, F. Maciuc, B. Mack, I. Mackay, L. M. Mackey, L. R. Madhan Mohan, M. J. Madurai, A. Maevskiy, D. Magdalinski, D. Maisuzenko, J. J. Malczewski, S. Malde, L. Malentacca, A. Malinin, T. Maltsev, G. Manca, G. Mancinelli, C. Mancuso, R. Manera Escalero, F. M. Manganella, D. Manuzzi, D. Marangotto, J. F. Marchand, R. Marchevski, U. Marconi, E. Mariani, S. Mariani, C. Marin Benito, J. Marks, A. M. Marshall, L. Martel, G. Martelli, G. Martellotti, L. Martinazzoli, M. Martinelli, D. Martinez Gomez, D. Martinez Santos, F. Martinez Vidal, A. Martorell i Granollers, A. Massafferri, R. Matev, A. Mathad, V. Matiunin, C. Matteuzzi, K. R. Mattioli, A. Mauri, E. Maurice, J. Mauricio, P. Mayencourt, J. Mazorra de Cos, M. Mazurek, M. McCann, T. H. McGrath, N. T. McHugh, A. McNab, R. McNulty, B. Meadows, G. Meier, D. Melnychuk, F. M. Meng, M. Merk, A. Merli, L. Meyer Garcia, D. Miao, H. Miao, M. Mikhasenko, D. A. Milanes, A. Minotti, E. Minucci, T. Miralles, B. Mitreska, D. S. Mitzel, A. Modak, L. Moeser, R. A. Mohammed, R. D. Moise, S. Mokhnenko, E. F. Molina Cardenas, T. Mombächer, M. Monk, S. Monteil, A. Morcillo Gomez, G. Morello, M. J. Morello, M. P. Morgenthaler, J. Moron, W. Morren, A. B. Morris, A. G. Morris, R. Mountain, H. Mu, Z. M. Mu, E. Muhammad, F. Muheim, M. Mulder, K. Müller, F. Muñoz-Rojas, R. Murta, P. Naik, T. Nakada, R. Nandakumar, T. Nanut, I. Nasteva, M. Needham, N. Neri, S. Neubert, N. Neufeld, P. Neustroev, J. Nicolini, D. Nicotra, E. M. Niel, N. Nikitin, Q. Niu, P. Nogarolli, P. Nogga, C. Normand, J. Novoa Fernandez, G. Nowak, C. Nunez, H. N. Nur, A. Oblakowska-Mucha, V. Obraztsov, T. Oeser, S. Okamura, A. Okhotnikov, O. Okhrimenko, R. Oldeman, F. Oliva, M. Olocco, C. J. G. Onderwater, R. H. O'Neil, D. Osthues, J. M. Otalora Goicochea, P. Owen, A. Oyanguren, O. Ozcelik, F. Paciolla, A. Padee, K. O. Padeken, B. Pagare, P. R. Pais, T. Pajero, A. Palano, M. Palutan, X. Pan, G. Panshin, L. Paolucci, A. Papanestis, M. Pappagallo, L. L. Pappalardo, C. Pappenheimer, C. Parkes, D. Parmar, B. Passalacqua, G. Passaleva, D. Passaro, A. Pastore, M. Patel, J. Patoc, C. Patrignani, A. Paul, C. J. Pawley, A. Pellegrino, J. Peng, M. Pepe Altarelli, S. Perazzini, D. Pereima, H. Pereira Da Costa, A. Pereiro Castro, P. Perret, A. Perrevoort, A. Perro, M. J. Peters, K. Petridis, A. Petrolini, J. P. Pfaller, H. Pham, L. Pica, M. Piccini, L. Piccolo, B. Pietrzyk, G. Pietrzyk, R. N. Pilato, D. Pinci, F. Pisani, M. Pizzichemi, V. Placinta, M. Plo Casasus, T. Poeschl, F. Polci, M. Poli Lener, A. Poluektov, N. Polukhina, I. Polyakov, E. Polycarpo, S. Ponce, D. Popov, S. Poslavskii, K. Prasanth, C. Prouve, D. Provenzano, V. Pugatch, G. Punzi, S. Qasim, Q. Q. Qian, W. Qian, N. Qin, S. Qu, R. Quagliani, R. I. Rabadan Trejo, J. H. Rademacker, M. Rama, M. Ramírez García, V. Ramos De Oliveira, M. Ramos Pernas, M. S. Rangel, F. Ratnikov, G. Raven, M. Rebollo De Miguel, F. Redi, J. Reich, F. Reiss, Z. Ren, P. K. Resmi, M. Ribalda Galvez, R. Ribatti, G. Ricart, D. Riccardi, S. Ricciardi, K. Richardson, M. Richardson-Slipper, K. Rinnert, P. Robbe, G. Robertson, E. Rodrigues, A. Rodriguez Alvarez, E. Rodriguez Fernandez, J. A. Rodriguez Lopez, E. Rodriguez Rodriguez, J. Roensch, A. Rogachev, A. Rogovskiy, D. L. Rolf, P. Roloff, V. Romanovskiy, A. Romero Vidal, G. Romolini, F. Ronchetti, T. Rong, M. Rotondo, S. R. Roy, M. S. Rudolph, M. Ruiz Diaz, R. A. Ruiz Fernandez, J. Ruiz Vidal, J. Ryzka, J. J. Saavedra-Arias, J. J. Saborido Silva, R. Sadek, N. Sagidova, D. Sahoo, N. Sahoo, B. Saitta, M. Salomoni, I. Sanderswood, R. Santacesaria, C. Santamarina Rios, M. Santimaria, L. Santoro, E. Santovetti, A. Saputi, D. Saranin, A. Sarnatskiy, G. Sarpis, M. Sarpis, C. Satriano, A. Satta, M. Saur, D. Savrina, H. Sazak, F. Sborzacchi, L. G. Scantlebury Smead, A. Scarabotto, S. Schael, S. Scherl, M. Schiller, H. Schindler, M. Schmelling, B. Schmidt, S. Schmitt, H. Schmitz, O. Schneider, A. Schopper, N. Schulte, S. Schulte, M. H. Schune, R. Schwemmer, G. Schwering, B. Sciascia, A. Sciuccati, I. Segal, S. Sellam, A. Semennikov, T. Senger, M. Senghi Soares, A. Sergi, N. Serra, L. Sestini, A. Seuthe, Y. Shang, D. M. Shangase, M. Shapkin, R. S. Sharma, I. Shchemerov, L. Shchutska, T. Shears, L. Shekhtman, Z. Shen, S. Sheng, V. Shevchenko, B. Shi, Q. Shi, Y. Shimizu, E. Shmanin, R. Shorkin, J. D. Shupperd, R. Silva Coutinho, G. Simi, S. Simone, N. Skidmore, T. Skwarnicki, M. W. Slater, J. C. Smallwood, E. Smith, K. Smith, M. Smith, A. Snoch, L. Soares Lavra, M. D. Sokoloff, F. J. P. Soler, A. Solomin, A. Solovev, I. Solovyev, N. S. Sommerfeld, R. Song, Y. Song, Y. Song, Y. S. Song, F. L. Souza De Almeida, B. Souza De Paula, E. Spadaro Norella, E. Spedicato, J. G. Speer, E. Spiridenkov, P. Spradlin, V. Sriskaran, F. Stagni, M. Stahl, S. Stahl, S. Stanislaus, M. Stefaniak, E. N. Stein, O. Steinkamp, O. Stenyakin, H. Stevens, D. Strekalina, Y. Su, F. Suljik, J. Sun, L. Sun, D. Sundfeld, W. Sutcliffe, K. Swientek, F. Swystun, A. Szabelski, T. Szumlak, Y. Tan, Y. Tang, M. D. Tat, A. Terentev, F. Terzuoli, F. Teubert, E. Thomas, D. J. D. Thompson, H. Tilquin, V. Tisserand, S. T'Jampens, M. Tobin, L. Tomassetti, G. Tonani, X. Tong, T. Tork, D. Torres Machado, L. Toscano, D. Y. Tou, C. Trippl, G. Tuci, N. Tuning, L. H. Uecker, A. Ukleja, D. J. Unverzagt, B. Urbach, A. Usachov, A. Ustyuzhanin, U. Uwer, V. Vagnoni, V. Valcarce Cadenas, G. Valenti, N. Valls Canudas, J. van Eldik, H. Van Hecke, E. van Herwijnen, C. B. Van Hulse, R. Van Laak, M. van Veghel, G. Vasquez, R. Vazquez Gomez, P. Vazquez Regueiro, C. Vázquez Sierra, S. Vecchi, J. J. Velthuis, M. Veltri, A. Venkateswaran, M. Verdoglia, M. Vesterinen, D. Vico Benet, P. Vidrier Villalba, M. Vieites Diaz, X. Vilasis-Cardona, E. Vilella Figueras, A. Villa, P. Vincent, F. C. Volle, D. vom Bruch, N. Voropaev, K. Vos, C. Vrahas, J. Wagner, J. Walsh, E. J. Walton, G. Wan, C. Wang, G. Wang, H. Wang, J. Wang, J. Wang, J. Wang, J. Wang, M. Wang, N. W. Wang, R. Wang, X. Wang, X. Wang, X. W. Wang, Y. Wang, Y. W. Wang, Z. Wang, Z. Wang, Z. Wang, J. A. Ward, M. Waterlaat, N. K. Watson, D. Websdale, Y. Wei, J. Wendel, B. D. C. Westhenry, C. White, M. Whitehead, E. Whiter, A. R. Wiederhold, D. Wiedner, G. Wilkinson, M. K. Wilkinson, M. Williams, M. J. Williams, M. R. J. Williams, R. Williams, Z. Williams, F. F. Wilson, M. Winn, W. Wislicki, M. Witek, L. Witola, G. Wormser, S. A. Wotton, H. Wu, J. Wu, X. Wu, Y. Wu, Z. Wu, K. Wyllie, S. Xian, Z. Xiang, Y. Xie, T. X. Xing, A. Xu, L. Xu, L. Xu, M. Xu, Z. Xu, Z. Xu, Z. Xu, K. Yang, S. Yang, X. Yang, Y. Yang, Z. Yang, V. Yeroshenko, H. Yeung, H. Yin, X. Yin, C. Y. Yu, J. Yu, X. Yuan, Y Yuan, E. Zaffaroni, M. Zavertyaev, M. Zdybal, F. Zenesini, C. Zeng, M. Zeng, C. Zhang, D. Zhang, J. Zhang, L. Zhang, S. Zhang, S. Zhang, Y. Zhang, Y. Z. Zhang, Z. Zhang, Y. Zhao, A. Zhelezov, S. Z. Zheng, X. Z. Zheng, Y. Zheng, T. Zhou, X. Zhou, Y. Zhou, V. Zhovkovska, L. Z. Zhu, X. Zhu, X. Zhu, V. Zhukov, J. Zhuo, Q. Zou, D. Zuliani, G. Zunica","The first measurement of the $CP$ asymmetry of the decay rate ($A_{CP}$) and
the $CP$ average ($\Sigma A_{\text{FB}}$) and $CP$ asymmetry ($\Delta
A_{\text{FB}}$) of the forward-backward asymmetry in the muon system of
$\mathit{\Lambda}^+_c\to p\mu^+\mu^-$ decays is reported. The measurement is
performed using a data sample of proton-proton collisions, recorded by the LHCb
experiment from 2016 to 2018 at a center-of-mass energy of 13$\text{ TeV}$,
which corresponds to an integrated luminosity of 5.4$\text{ fb}^{-1}$. The
asymmetries are measured in two regions of dimuon mass near the $\phi$-meson
mass peak. The dimuon-mass integrated results are \begin{align*} A_{CP} &=
(-1.1 \pm 4.0 \pm 0.5)\%,\\ \Sigma A_{\text{FB}} &= (\phantom{-}3.9 \pm 4.0 \pm
0.6)\%,\\ \Delta A_{\text{FB}} &= (\phantom{-}3.1 \pm 4.0 \pm 0.4)\%,
\end{align*} where the first uncertainty is statistical and the second
systematic. The results are consistent with the conservation of $CP$ symmetry
and the Standard Model expectations.",http://arxiv.org/abs/2502.04013v1
"Search for continuous gravitational waves from known pulsars in the
  first part of the fourth LIGO-Virgo-KAGRA observing run",2025-01-02T19:00:05Z,"The LIGO Scientific Collaboration, the Virgo Collaboration, the KAGRA Collaboration, A. G. Abac, R. Abbott, I. Abouelfettouh, F. Acernese, K. Ackley, S. Adhicary, N. Adhikari, R. X. Adhikari, V. K. Adkins, D. Agarwal, M. Agathos, M. Aghaei Abchouyeh, O. D. Aguiar, I. Aguilar, L. Aiello, A. Ain, P. Ajith, T. Akutsu, S. Albanesi, R. A. Alfaidi, A. Al-Jodah, C. Alléné, A. Allocca, S. Al-Shammari, P. A. Altin, S. Alvarez-Lopez, A. Amato, L. Amez-Droz, A. Amorosi, C. Amra, A. Ananyeva, S. B. Anderson, W. G. Anderson, M. Andia, M. Ando, T. Andrade, N. Andres, M. Andrés-Carcasona, T. Andrić, J. Anglin, S. Ansoldi, J. M. Antelis, S. Antier, M. Aoumi, E. Z. Appavuravther, S. Appert, S. K. Apple, K. Arai, A. Araya, M. C. Araya, J. S. Areeda, L. Argianas, N. Aritomi, F. Armato, N. Arnaud, M. Arogeti, S. M. Aronson, G. Ashton, Y. Aso, M. Assiduo, S. Assis de Souza Melo, S. M. Aston, P. Astone, F. Attadio, F. Aubin, K. AultONeal, G. Avallone, S. Babak, F. Badaracco, C. Badger, S. Bae, S. Bagnasco, E. Bagui, J. G. Baier, L. Baiotti, R. Bajpai, T. Baka, M. Ball, G. Ballardin, S. W. Ballmer, S. Banagiri, B. Banerjee, D. Bankar, P. Baral, J. C. Barayoga, B. C. Barish, D. Barker, P. Barneo, F. Barone, B. Barr, L. Barsotti, M. Barsuglia, D. Barta, A. M. Bartoletti, M. A. Barton, I. Bartos, S. Basak, A. Basalaev, R. Bassiri, A. Basti, D. E. Bates, M. Bawaj, P. Baxi, J. C. Bayley, A. C. Baylor, P. A. Baynard II, M. Bazzan, V. M. Bedakihale, F. Beirnaert, M. Bejger, D. Belardinelli, A. S. Bell, V. Benedetto, W. Benoit, J. D. Bentley, M. Ben Yaala, S. Bera, M. Berbel, F. Bergamin, B. K. Berger, S. Bernuzzi, M. Beroiz, D. Bersanetti, A. Bertolini, J. Betzwieser, D. Beveridge, N. Bevins, R. Bhandare, U. Bhardwaj, R. Bhatt, D. Bhattacharjee, S. Bhaumik, S. Bhowmick, A. Bianchi, I. A. Bilenko, G. Billingsley, A. Binetti, S. Bini, O. Birnholtz, S. Biscoveanu, A. Bisht, M. Bitossi, M. -A. Bizouard, J. K. Blackburn, L. A. Blagg, C. D. Blair, D. G. Blair, F. Bobba, N. Bode, G. Boileau, M. Boldrini, G. N. Bolingbroke, A. Bolliand, L. D. Bonavena, R. Bondarescu, F. Bondu, E. Bonilla, M. S. Bonilla, A. Bonino, R. Bonnand, P. Booker, A. Borchers, V. Boschi, S. Bose, V. Bossilkov, V. Boudart, A. Boudon, A. Bozzi, C. Bradaschia, P. R. Brady, M. Braglia, A. Branch, M. Branchesi, J. Brandt, I. Braun, M. Breschi, T. Briant, A. Brillet, M. Brinkmann, P. Brockill, E. Brockmueller, A. F. Brooks, B. C. Brown, D. D. Brown, M. L. Brozzetti, S. Brunett, G. Bruno, R. Bruntz, J. Bryant, F. Bucci, J. Buchanan, O. Bulashenko, T. Bulik, H. J. Bulten, A. Buonanno, K. Burtnyk, R. Buscicchio, D. Buskulic, C. Buy, R. L. Byer, G. S. Cabourn Davies, G. Cabras, R. Cabrita, V. Cáceres-Barbosa, L. Cadonati, G. Cagnoli, C. Cahillane, J. Calderón Bustillo, T. A. Callister, E. Calloni, J. B. Camp, M. Canepa, G. Caneva Santoro, K. C. Cannon, H. Cao, L. A. Capistran, E. Capocasa, E. Capote, G. Carapella, F. Carbognani, M. Carlassara, J. B. Carlin, M. Carpinelli, G. Carrillo, J. J. Carter, G. Carullo, J. Casanueva Diaz, C. Casentini, S. Y. Castro-Lucas, S. Caudill, M. Cavaglià, R. Cavalieri, G. Cella, P. Cerdá-Durán, E. Cesarini, W. Chaibi, P. Chakraborty, S. Chalathadka Subrahmanya, J. C. L. Chan, M. Chan, K. Chandra, R. -J. Chang, S. Chao, E. L. Charlton, P. Charlton, E. Chassande-Mottin, C. Chatterjee, Debarati Chatterjee, Deep Chatterjee, M. Chaturvedi, S. Chaty, A. Chen, A. H. -Y. Chen, D. Chen, H. Chen, H. Y. Chen, J. Chen, K. H. Chen, Y. Chen, Yanbei Chen, Yitian Chen, H. P. Cheng, P. Chessa, H. T. Cheung, S. Y. Cheung, F. Chiadini, G. Chiarini, R. Chierici, A. Chincarini, M. L. Chiofalo, A. Chiummo, C. Chou, S. Choudhary, N. Christensen, S. S. Y. Chua, P. Chugh, G. Ciani, P. Ciecielag, M. Cieślar, M. Cifaldi, R. Ciolfi, F. Clara, J. A. Clark, J. Clarke, T. A. Clarke, P. Clearwater, S. Clesse, E. Coccia, E. Codazzo, P. -F. Cohadon, S. Colace, M. Colleoni, C. G. Collette, J. Collins, S. Colloms, A. Colombo, M. Colpi, C. M. Compton, G. Connolly, L. Conti, T. R. Corbitt, I. Cordero-Carrión, S. Corezzi, N. J. Cornish, A. Corsi, S. Cortese, C. A. Costa, R. Cottingham, M. W. Coughlin, A. Couineaux, J. -P. Coulon, S. T. Countryman, J. -F. Coupechoux, P. Couvares, D. M. Coward, M. J. Cowart, R. Coyne, K. Craig, R. Creed, J. D. E. Creighton, T. D. Creighton, P. Cremonese, A. W. Criswell, J. C. G. Crockett-Gray, S. Crook, R. Crouch, J. Csizmazia, J. R. Cudell, T. J. Cullen, A. Cumming, E. Cuoco, M. Cusinato, P. Dabadie, T. Dal Canton, S. Dall'Osso, S. Dal Pra, G. Dálya, B. D'Angelo, S. Danilishin, S. D'Antonio, K. Danzmann, K. E. Darroch, L. P. Dartez, A. Dasgupta, S. Datta, V. Dattilo, A. Daumas, N. Davari, I. Dave, A. Davenport, M. Davier, T. F. Davies, D. Davis, L. Davis, M. C. Davis, P. J. Davis, M. Dax, J. De Bolle, M. Deenadayalan, J. Degallaix, M. De Laurentis, S. Deléglise, F. De Lillo, D. Dell'Aquila, W. Del Pozzo, F. De Marco, F. De Matteis, V. D'Emilio, N. Demos, T. Dent, A. Depasse, N. DePergola, R. De Pietri, R. De Rosa, C. De Rossi, R. DeSalvo, R. De Simone, A. Dhani, R. Diab, M. C. Díaz, M. Di Cesare, G. Dideron, N. A. Didio, T. Dietrich, L. Di Fiore, C. Di Fronzo, M. Di Giovanni, T. Di Girolamo, D. Diksha, A. Di Michele, J. Ding, S. Di Pace, I. Di Palma, F. Di Renzo, Divyajyoti, A. Dmitriev, Z. Doctor, E. Dohmen, P. P. Doleva, D. Dominguez, L. D'Onofrio, F. Donovan, K. L. Dooley, T. Dooney, S. Doravari, O. Dorosh, M. Drago, J. C. Driggers, J. -G. Ducoin, L. Dunn, U. Dupletsa, D. D'Urso, H. Duval, P. -A. Duverne, S. E. Dwyer, C. Eassa, M. Ebersold, T. Eckhardt, G. Eddolls, B. Edelman, T. B. Edo, O. Edy, A. Effler, J. Eichholz, H. Einsle, M. Eisenmann, R. A. Eisenstein, A. Ejlli, R. M. Eleveld, M. Emma, K. Endo, A. J. Engl, E. Enloe, L. Errico, R. C. Essick, H. Estellés, D. Estevez, T. Etzel, M. Evans, T. Evstafyeva, B. E. Ewing, J. M. Ezquiaga, F. Fabrizi, F. Faedi, V. Fafone, S. Fairhurst, A. M. Farah, B. Farr, W. M. Farr, G. Favaro, M. Favata, M. Fays, M. Fazio, J. Feicht, M. M. Fejer, R. Felicetti, E. Fenyvesi, D. L. Ferguson, S. Ferraiuolo, I. Ferrante, T. A. Ferreira, F. Fidecaro, P. Figura, A. Fiori, I. Fiori, M. Fishbach, R. P. Fisher, R. Fittipaldi, V. Fiumara, R. Flaminio, S. M. Fleischer, L. S. Fleming, E. Floden, E. M. Foley, H. Fong, J. A. Font, B. Fornal, P. W. F. Forsyth, K. Franceschetti, N. Franchini, S. Frasca, F. Frasconi, A. Frattale Mascioli, Z. Frei, A. Freise, O. Freitas, R. Frey, W. Frischhertz, P. Fritschel, V. V. Frolov, G. G. Fronzé, M. Fuentes-Garcia, S. Fujii, T. Fujimori, P. Fulda, M. Fyffe, B. Gadre, J. R. Gair, S. Galaudage, V. Galdi, H. Gallagher, S. Gallardo, B. Gallego, R. Gamba, A. Gamboa, D. Ganapathy, A. Ganguly, B. Garaventa, J. García-Bellido, C. García Núñez, C. García-Quirós, J. W. Gardner, K. A. Gardner, J. Gargiulo, A. Garron, F. Garufi, C. Gasbarra, B. Gateley, V. Gayathri, G. Gemme, A. Gennai, V. Gennari, J. George, R. George, O. Gerberding, L. Gergely, Archisman Ghosh, Sayantan Ghosh, Shaon Ghosh, Shrobana Ghosh, Suprovo Ghosh, Tathagata Ghosh, L. Giacoppo, J. A. Giaime, K. D. Giardina, D. R. Gibson, D. T. Gibson, C. Gier, P. Giri, F. Gissi, S. Gkaitatzis, J. Glanzer, F. Glotin, J. Godfrey, P. Godwin, N. L. Goebbels, E. Goetz, J. Golomb, S. Gomez Lopez, B. Goncharov, Y. Gong, G. González, P. Goodarzi, S. Goode, A. W. Goodwin-Jones, M. Gosselin, A. S. Göttel, R. Gouaty, D. W. Gould, K. Govorkova, S. Goyal, B. Grace, A. Grado, V. Graham, A. E. Granados, M. Granata, V. Granata, S. Gras, P. Grassia, A. Gray, C. Gray, R. Gray, G. Greco, A. C. Green, S. M. Green, S. R. Green, A. M. Gretarsson, E. M. Gretarsson, D. Griffith, W. L. Griffiths, H. L. Griggs, G. Grignani, A. Grimaldi, C. Grimaud, H. Grote, D. Guerra, D. Guetta, G. M. Guidi, A. R. Guimaraes, H. K. Gulati, F. Gulminelli, A. M. Gunny, H. Guo, W. Guo, Y. Guo, Anchal Gupta, Anuradha Gupta, Ish Gupta, N. C. Gupta, P. Gupta, S. K. Gupta, T. Gupta, N. Gupte, J. Gurs, N. Gutierrez, F. Guzman, H. -Y. H, D. Haba, M. Haberland, S. Haino, E. D. Hall, E. Z. Hamilton, G. Hammond, W. -B. Han, M. Haney, J. Hanks, C. Hanna, M. D. Hannam, O. A. Hannuksela, A. G. Hanselman, H. Hansen, J. Hanson, R. Harada, A. R. Hardison, K. Haris, T. Harmark, J. Harms, G. M. Harry, I. W. Harry, J. Hart, B. Haskell, C. -J. Haster, J. S. Hathaway, K. Haughian, H. Hayakawa, K. Hayama, R. Hayes, A. Heffernan, A. Heidmann, M. C. Heintze, J. Heinze, J. Heinzel, H. Heitmann, F. Hellman, P. Hello, A. F. Helmling-Cornell, G. Hemming, O. Henderson-Sapir, M. Hendry, I. S. Heng, E. Hennes, C. Henshaw, T. Hertog, M. Heurs, A. L. Hewitt, J. Heyns, S. Higginbotham, S. Hild, S. Hill, Y. Himemoto, N. Hirata, C. Hirose, W. C. G. Ho, S. Hoang, S. Hochheim, D. Hofman, N. A. Holland, K. Holley-Bockelmann, Z. J. Holmes, D. E. Holz, L. Honet, C. Hong, J. Hornung, S. Hoshino, J. Hough, S. Hourihane, E. J. Howell, C. G. Hoy, C. A. Hrishikesh, H. -F. Hsieh, C. Hsiung, H. C. Hsu, W. -F. Hsu, P. Hu, Q. Hu, H. Y. Huang, Y. -J. Huang, A. D. Huddart, B. Hughey, D. C. Y. Hui, V. Hui, S. Husa, R. Huxford, T. Huynh-Dinh, L. Iampieri, G. A. Iandolo, M. Ianni, A. Iess, H. Imafuku, K. Inayoshi, Y. Inoue, G. Iorio, M. H. Iqbal, J. Irwin, R. Ishikawa, M. Isi, M. A. Ismail, Y. Itoh, H. Iwanaga, M. Iwaya, B. R. Iyer, V. JaberianHamedan, C. Jacquet, P. -E. Jacquet, S. J. Jadhav, S. P. Jadhav, T. Jain, A. L. James, P. A. James, R. Jamshidi, J. Janquart, K. Janssens, N. N. Janthalur, S. Jaraba, P. Jaranowski, R. Jaume, W. Javed, A. Jennings, W. Jia, J. Jiang, H. Jin, J. Kubisz, C. Johanson, G. R. Johns, N. A. Johnson, M. C. Johnston, R. Johnston, N. Johny, D. H. Jones, D. I. Jones, R. Jones, S. Jose, P. Joshi, L. Ju, K. Jung, J. Junker, V. Juste, T. Kajita, I. Kaku, C. Kalaghatgi, V. Kalogera, M. Kamiizumi, N. Kanda, S. Kandhasamy, G. Kang, J. B. Kanner, S. J. Kapadia, D. P. Kapasi, S. Karat, C. Karathanasis, R. Kashyap, M. Kasprzack, W. Kastaun, T. Kato, E. Katsavounidis, W. Katzman, R. Kaushik, K. Kawabe, R. Kawamoto, A. Kazemi, D. Keitel, J. Kelley-Derzon, J. Kennington, R. Kesharwani, J. S. Key, R. Khadela, S. Khadka, F. Y. Khalili, F. Khan, I. Khan, T. Khanam, M. Khursheed, N. M. Khusid, W. Kiendrebeogo, N. Kijbunchoo, C. Kim, J. C. Kim, K. Kim, M. H. Kim, S. Kim, Y. -M. Kim, C. Kimball, M. Kinley-Hanlon, M. Kinnear, J. S. Kissel, S. Klimenko, A. M. Knee, N. Knust, K. Kobayashi, P. Koch, S. M. Koehlenbeck, G. Koekoek, K. Kohri, K. Kokeyama, S. Koley, P. Kolitsidou, M. Kolstein, K. Komori, A. K. H. Kong, A. Kontos, M. Korobko, R. V. Kossak, X. Kou, A. Koushik, N. Kouvatsos, M. Kovalam, D. B. Kozak, S. L. Kranzhoff, V. Kringel, N. V. Krishnendu, A. Królak, K. Kruska, G. Kuehn, P. Kuijer, S. Kulkarni, A. Kulur Ramamohan, A. Kumar, Praveen Kumar, Prayush Kumar, Rahul Kumar, Rakesh Kumar, J. Kume, K. Kuns, N. Kuntimaddi, S. Kuroyanagi, N. J. Kurth, S. Kuwahara, K. Kwak, K. Kwan, J. Kwok, G. Lacaille, P. Lagabbe, D. Laghi, S. Lai, A. H. Laity, M. H. Lakkis, E. Lalande, M. Lalleman, P. C. Lalremruati, M. Landry, B. B. Lane, R. N. Lang, J. Lange, B. Lantz, A. La Rana, I. La Rosa, A. Lartaux-Vollard, P. D. Lasky, J. Lawrence, M. N. Lawrence, M. Laxen, A. Lazzarini, C. Lazzaro, P. Leaci, Y. K. Lecoeuche, H. M. Lee, H. W. Lee, K. Lee, R. -K. Lee, R. Lee, S. Lee, Y. Lee, I. N. Legred, J. Lehmann, L. Lehner, M. Le Jean, A. Lemaître, M. Lenti, M. Leonardi, M. Lequime, N. Leroy, M. Lesovsky, N. Letendre, M. Lethuillier, S. E. Levin, Y. Levin, K. Leyde, A. K. Y. Li, K. L. Li, T. G. F. Li, X. Li, Z. Li, A. Lihos, C-Y. Lin, C. -Y. Lin, E. T. Lin, F. Lin, H. Lin, L. C. -C. Lin, Y. -C. Lin, F. Linde, S. D. Linker, T. B. Littenberg, A. Liu, G. C. Liu, Jian Liu, F. Llamas Villarreal, J. Llobera-Querol, R. K. L. Lo, J. -P. Locquet, L. T. London, A. Longo, D. Lopez, M. Lopez Portilla, M. Lorenzini, A. Lorenzo-Medina, V. Loriette, M. Lormand, G. Losurdo, T. P. Lott IV, J. D. Lough, H. A. Loughlin, C. O. Lousto, M. J. Lowry, N. Lu, H. Lück, D. Lumaca, A. P. Lundgren, A. W. Lussier, L. -T. Ma, S. Ma, M. Ma'arif, R. Macas, A. Macedo, M. MacInnis, R. R. Maciy, D. M. Macleod, I. A. O. MacMillan, A. Macquet, D. Macri, K. Maeda, S. Maenaut, I. Magaña Hernandez, S. S. Magare, C. Magazzù, R. M. Magee, E. Maggio, R. Maggiore, M. Magnozzi, M. Mahesh, S. Mahesh, M. Maini, S. Majhi, E. Majorana, C. N. Makarem, E. Makelele, J. A. Malaquias-Reis, U. Mali, S. Maliakal, A. Malik, N. Man, V. Mandic, V. Mangano, B. Mannix, G. L. Mansell, G. Mansingh, M. Manske, M. Mantovani, M. Mapelli, F. Marchesoni, D. Marín Pina, F. Marion, S. Márka, Z. Márka, A. S. Markosyan, A. Markowitz, E. Maros, S. Marsat, F. Martelli, I. W. Martin, R. M. Martin, B. B. Martinez, M. Martinez, V. Martinez, A. Martini, K. Martinovic, J. C. Martins, D. V. Martynov, E. J. Marx, L. Massaro, A. Masserot, M. Masso-Reid, M. Mastrodicasa, S. Mastrogiovanni, T. Matcovich, M. Matiushechkina, M. Matsuyama, N. Mavalvala, N. Maxwell, G. McCarrol, R. McCarthy, D. E. McClelland, S. McCormick, L. McCuller, S. McEachin, C. McElhenny, G. I. McGhee, J. McGinn, K. B. M. McGowan, J. McIver, A. McLeod, T. McRae, D. Meacher, Q. Meijer, A. Melatos, S. Mellaerts, A. Menendez-Vazquez, C. S. Menoni, F. Mera, R. A. Mercer, L. Mereni, K. Merfeld, E. L. Merilh, J. R. Mérou, J. D. Merritt, M. Merzougui, C. Messenger, C. Messick, Z. Metzler, M. Meyer-Conde, F. Meylahn, A. Mhaske, A. Miani, H. Miao, I. Michaloliakos, C. Michel, Y. Michimura, H. Middleton, A. L. Miller, S. Miller, M. Millhouse, E. Milotti, V. Milotti, Y. Minenkov, N. Mio, Ll. M. Mir, L. Mirasola, M. Miravet-Tenés, C. -A. Miritescu, A. K. Mishra, A. Mishra, C. Mishra, T. Mishra, A. L. Mitchell, J. G. Mitchell, S. Mitra, V. P. Mitrofanov, R. Mittleman, O. Miyakawa, S. Miyamoto, S. Miyoki, G. Mo, L. Mobilia, S. R. P. Mohapatra, S. R. Mohite, M. Molina-Ruiz, C. Mondal, M. Mondin, M. Montani, C. J. Moore, D. Moraru, A. More, S. More, G. Moreno, C. Morgan, S. Morisaki, Y. Moriwaki, G. Morras, A. Moscatello, P. Mourier, B. Mours, C. M. Mow-Lowry, F. Muciaccia, Arunava Mukherjee, D. Mukherjee, Samanwaya Mukherjee, Soma Mukherjee, Subroto Mukherjee, Suvodip Mukherjee, N. Mukund, A. Mullavey, J. Munch, J. Mundi, C. L. Mungioli, W. R. Munn Oberg, Y. Murakami, M. Murakoshi, P. G. Murray, S. Muusse, D. Nabari, S. L. Nadji, A. Nagar, N. Nagarajan, K. N. Nagler, K. Nakagaki, K. Nakamura, H. Nakano, M. Nakano, D. Nandi, V. Napolano, P. Narayan, I. Nardecchia, T. Narikawa, H. Narola, L. Naticchioni, R. K. Nayak, J. Neilson, A. Nelson, T. J. N. Nelson, M. Nery, A. Neunzert, S. Ng, L. Nguyen Quynh, S. A. Nichols, A. B. Nielsen, G. Nieradka, A. Niko, Y. Nishino, A. Nishizawa, S. Nissanke, E. Nitoglia, W. Niu, F. Nocera, M. Norman, C. North, J. Novak, J. F. Nuño Siles, L. K. Nuttall, K. Obayashi, J. Oberling, J. O'Dell, M. Oertel, A. Offermans, G. Oganesyan, J. J. Oh, K. Oh, T. O'Hanlon, M. Ohashi, M. Ohkawa, F. Ohme, A. S. Oliveira, R. Oliveri, B. O'Neal, K. Oohara, B. O'Reilly, N. D. Ormsby, M. Orselli, R. O'Shaughnessy, S. O'Shea, Y. Oshima, S. Oshino, S. Ossokine, C. Osthelder, I. Ota, D. J. Ottaway, A. Ouzriat, H. Overmier, B. J. Owen, A. E. Pace, R. Pagano, M. A. Page, A. Pai, A. Pal, S. Pal, M. A. Palaia, M. Pálfi, P. P. Palma, C. Palomba, P. Palud, H. Pan, J. Pan, K. C. Pan, R. Panai, P. K. Panda, S. Pandey, L. Panebianco, P. T. H. Pang, F. Pannarale, K. A. Pannone, B. C. Pant, F. H. Panther, F. Paoletti, A. Paolone, E. E. Papalexakis, L. Papalini, G. Papigkiotis, A. Paquis, A. Parisi, B. -J. Park, J. Park, W. Parker, G. Pascale, D. Pascucci, A. Pasqualetti, R. Passaquieti, L. Passenger, D. Passuello, O. Patane, D. Pathak, M. Pathak, A. Patra, B. Patricelli, A. S. Patron, K. Paul, S. Paul, E. Payne, T. Pearce, M. Pedraza, R. Pegna, A. Pele, F. E. Peña Arellano, S. Penn, M. D. Penuliar, A. Perego, Z. Pereira, J. J. Perez, C. Périgois, G. Perna, A. Perreca, J. Perret, S. Perriès, J. W. Perry, D. Pesios, S. Petracca, C. Petrillo, H. P. Pfeiffer, H. Pham, K. A. Pham, K. S. Phukon, H. Phurailatpam, M. Piarulli, L. Piccari, O. J. Piccinni, M. Pichot, M. Piendibene, F. Piergiovanni, L. Pierini, G. Pierra, V. Pierro, M. Pietrzak, M. Pillas, F. Pilo, L. Pinard, I. M. Pinto, M. Pinto, B. J. Piotrzkowski, M. Pirello, M. D. Pitkin, A. Placidi, E. Placidi, M. L. Planas, W. Plastino, R. Poggiani, E. Polini, L. Pompili, J. Poon, E. Porcelli, E. K. Porter, C. Posnansky, R. Poulton, J. Powell, M. Pracchia, B. K. Pradhan, T. Pradier, A. K. Prajapati, K. Prasai, R. Prasanna, P. Prasia, G. Pratten, G. Principe, M. Principe, G. A. Prodi, L. Prokhorov, P. Prosposito, A. Puecher, J. Pullin, M. Punturo, P. Puppo, M. Pürrer, H. Qi, J. Qin, G. Quéméner, V. Quetschke, C. Quigley, P. J. Quinonez, F. J. Raab, S. S. Raabith, G. Raaijmakers, S. Raja, C. Rajan, B. Rajbhandari, K. E. Ramirez, F. A. Ramis Vidal, A. Ramos-Buades, D. Rana, S. Ranjan, K. Ransom, P. Rapagnani, B. Ratto, S. Rawat, A. Ray, V. Raymond, M. Razzano, J. Read, M. Recaman Payo, T. Regimbau, L. Rei, S. Reid, D. H. Reitze, P. Relton, A. I. Renzini, P. Rettegno, B. Revenu, R. Reyes, A. S. Rezaei, F. Ricci, M. Ricci, A. Ricciardone, J. W. Richardson, M. Richardson, A. Rijal, K. Riles, H. K. Riley, S. Rinaldi, J. Rittmeyer, C. Robertson, F. Robinet, M. Robinson, A. Rocchi, L. Rolland, J. G. Rollins, A. E. Romano, R. Romano, A. Romero, I. M. Romero-Shaw, J. H. Romie, S. Ronchini, T. J. Roocke, L. Rosa, T. J. Rosauer, C. A. Rose, D. Rosińska, M. P. Ross, M. Rossello, S. Rowan, S. K. Roy, S. Roy, D. Rozza, P. Ruggi, N. Ruhama, E. Ruiz Morales, K. Ruiz-Rocha, S. Sachdev, T. Sadecki, J. Sadiq, P. Saffarieh, M. R. Sah, S. S. Saha, S. Saha, T. Sainrat, S. Sajith Menon, K. Sakai, M. Sakellariadou, S. Sakon, O. S. Salafia, F. Salces-Carcoba, L. Salconi, M. Saleem, F. Salemi, M. Sallé, S. Salvador, A. Sanchez, E. J. Sanchez, J. H. Sanchez, L. E. Sanchez, N. Sanchis-Gual, J. R. Sanders, E. M. Sänger, F. Santoliquido, T. R. Saravanan, N. Sarin, S. Sasaoka, A. Sasli, P. Sassi, B. Sassolas, H. Satari, R. Sato, Y. Sato, O. Sauter, R. L. Savage, T. Sawada, H. L. Sawant, S. Sayah, V. Scacco, D. Schaetzl, M. Scheel, A. Schiebelbein, M. G. Schiworski, P. Schmidt, S. Schmidt, R. Schnabel, M. Schneewind, R. M. S. Schofield, K. Schouteden, B. W. Schulte, B. F. Schutz, E. Schwartz, M. Scialpi, J. Scott, S. M. Scott, T. C. Seetharamu, M. Seglar-Arroyo, Y. Sekiguchi, D. Sellers, A. S. Sengupta, D. Sentenac, E. G. Seo, J. W. Seo, V. Sequino, M. Serra, G. Servignat, A. Sevrin, T. Shaffer, U. S. Shah, M. A. Shaikh, L. Shao, A. K. Sharma, P. Sharma, S. Sharma-Chaudhary, M. R. Shaw, P. Shawhan, N. S. Shcheblanov, E. Sheridan, Y. Shikano, M. Shikauchi, K. Shimode, H. Shinkai, J. Shiota, D. H. Shoemaker, D. M. Shoemaker, R. W. Short, S. ShyamSundar, A. Sider, H. Siegel, M. Sieniawska, D. Sigg, L. Silenzi, M. Simmonds, L. P. Singer, A. Singh, D. Singh, M. K. Singh, S. Singh, A. Singha, A. M. Sintes, V. Sipala, V. Skliris, B. J. J. Slagmolen, T. J. Slaven-Blair, J. Smetana, J. R. Smith, L. Smith, R. J. E. Smith, W. J. Smith, J. Soldateschi, K. Somiya, I. Song, K. Soni, S. Soni, V. Sordini, F. Sorrentino, N. Sorrentino, H. Sotani, R. Soulard, A. Southgate, V. Spagnuolo, A. P. Spencer, M. Spera, P. Spinicelli, J. B. Spoon, C. A. Sprague, A. K. Srivastava, F. Stachurski, D. A. Steer, J. Steinlechner, S. Steinlechner, N. Stergioulas, P. Stevens, M. StPierre, G. Stratta, M. D. Strong, A. Strunk, R. Sturani, A. L. Stuver, M. Suchenek, S. Sudhagar, N. Sueltmann, L. Suleiman, K. D. Sullivan, L. Sun, S. Sunil, J. Suresh, P. J. Sutton, T. Suzuki, Y. Suzuki, B. L. Swinkels, A. Syx, M. J. Szczepańczyk, P. Szewczyk, M. Tacca, H. Tagoshi, S. C. Tait, H. Takahashi, R. Takahashi, A. Takamori, T. Takase, K. Takatani, H. Takeda, K. Takeshita, C. Talbot, M. Tamaki, N. Tamanini, D. Tanabe, K. Tanaka, S. J. Tanaka, T. Tanaka, D. Tang, S. Tanioka, D. B. Tanner, L. Tao, R. D. Tapia, E. N. Tapia San Martín, R. Tarafder, C. Taranto, A. Taruya, J. D. Tasson, M. Teloi, R. Tenorio, H. Themann, A. Theodoropoulos, M. P. Thirugnanasambandam, L. M. Thomas, M. Thomas, P. Thomas, J. E. Thompson, S. R. Thondapu, K. A. Thorne, E. Thrane, J. Tissino, A. Tiwari, P. Tiwari, S. Tiwari, V. Tiwari, M. R. Todd, A. M. Toivonen, K. Toland, A. E. Tolley, T. Tomaru, K. Tomita, T. Tomura, C. Tong-Yu, A. Toriyama, N. Toropov, A. Torres-Forné, C. I. Torrie, M. Toscani, I. Tosta e Melo, E. Tournefier, A. Trapananti, F. Travasso, G. Traylor, M. Trevor, M. C. Tringali, A. Tripathee, G. Troian, L. Troiano, A. Trovato, L. Trozzo, R. J. Trudeau, T. T. L. Tsang, R. Tso, S. Tsuchida, L. Tsukada, T. Tsutsui, K. Turbang, M. Turconi, C. Turski, H. Ubach, T. Uchiyama, R. P. Udall, T. Uehara, M. Uematsu, K. Ueno, S. Ueno, V. Undheim, T. Ushiba, M. Vacatello, H. Vahlbruch, N. Vaidya, G. Vajente, A. Vajpeyi, G. Valdes, J. Valencia, M. Valentini, S. A. Vallejo-Peña, S. Vallero, V. Valsan, N. van Bakel, M. van Beuzekom, M. van Dael, J. F. J. van den Brand, C. Van Den Broeck, D. C. Vander-Hyde, M. van der Sluys, A. Van de Walle, J. van Dongen, K. Vandra, H. van Haevermaet, J. V. van Heijningen, P. Van Hove, M. VanKeuren, J. Vanosky, M. H. P. M. van Putten, Z. van Ranst, N. van Remortel, M. Vardaro, A. F. Vargas, J. J. Varghese, V. Varma, M. Vasúth, A. Vecchio, G. Vedovato, J. Veitch, P. J. Veitch, S. Venikoudis, J. Venneberg, P. Verdier, D. Verkindt, B. Verma, P. Verma, Y. Verma, S. M. Vermeulen, F. Vetrano, A. Veutro, A. M. Vibhute, A. Viceré, S. Vidyant, A. D. Viets, A. Vijaykumar, A. Vilkha, V. Villa-Ortega, E. T. Vincent, J. -Y. Vinet, S. Viret, A. Virtuoso, S. Vitale, A. Vives, H. Vocca, D. Voigt, E. R. G. von Reis, J. S. A. von Wrangel, S. P. Vyatchanin, L. E. Wade, M. Wade, K. J. Wagner, A. Wajid, M. Walker, G. S. Wallace, L. Wallace, H. Wang, J. Z. Wang, W. H. Wang, Z. Wang, G. Waratkar, J. Warner, M. Was, T. Washimi, N. Y. Washington, D. Watarai, K. E. Wayt, B. R. Weaver, B. Weaver, C. R. Weaving, S. A. Webster, M. Weinert, A. J. Weinstein, R. Weiss, F. Wellmann, L. Wen, P. Weßels, K. Wette, J. T. Whelan, B. F. Whiting, C. Whittle, J. B. Wildberger, O. S. Wilk, D. Wilken, A. T. Wilkin, D. J. Willadsen, K. Willetts, D. Williams, M. J. Williams, N. S. Williams, J. L. Willis, B. Willke, M. Wils, J. Winterflood, C. C. Wipf, G. Woan, J. Woehler, J. K. Wofford, N. E. Wolfe, H. T. Wong, H. W. Y. Wong, I. C. F. Wong, J. L. Wright, M. Wright, C. Wu, D. S. Wu, H. Wu, E. Wuchner, D. M. Wysocki, V. A. Xu, Y. Xu, N. Yadav, H. Yamamoto, K. Yamamoto, T. S. Yamamoto, T. Yamamoto, S. Yamamura, R. Yamazaki, S. Yan, T. Yan, F. W. Yang, F. Yang, K. Z. Yang, Y. Yang, Z. Yarbrough, H. Yasui, S. -W. Yeh, A. B. Yelikar, X. Yin, J. Yokoyama, T. Yokozawa, J. Yoo, H. Yu, S. Yuan, H. Yuzurihara, A. Zadrożny, M. Zanolin, M. Zeeshan, T. Zelenova, J. -P. Zendri, M. Zeoli, M. Zerrad, M. Zevin, A. C. Zhang, L. Zhang, R. Zhang, T. Zhang, Y. Zhang, C. Zhao, Yue Zhao, Yuhang Zhao, Y. Zheng, H. Zhong, R. Zhou, X. -J. Zhu, Z. -H. Zhu, A. B. Zimmerman, M. E. Zucker, J. Zweizig, S. B. Araujo Furlan, Z. Arzoumanian, A. Basu, A. Cassity, I. Cognard, K. Crowter, S. del Palacio, C. M. Espinoza, E. Fonseca, C. M. L. Flynn, G. Gancio, F. Garcia, K. C. Gendreau, D. C. Good, L. Guillemot, S. Guillot, M. J. Keith, L. Kuiper, M. E. Lower, A. G. Lyne, J. W. McKee, B. W. Meyers, J. L. Palfreyman, A. B. Pearlman, G. E. Romero, R. M. Shannon, B. Shaw, I. H. Stairs, B. W. Stappers, C. M. Tan, G. Theureau, M. Thompson, P. Weltevrede, E. Zubieta","Continuous gravitational waves (CWs) emission from neutron stars carries
information about their internal structure and equation of state, and it can
provide tests of General Relativity. We present a search for CWs from a set of
45 known pulsars in the first part of the fourth LIGO--Virgo--KAGRA observing
run, known as O4a. We conducted a targeted search for each pulsar using three
independent analysis methods considering the single-harmonic and the
dual-harmonic emission models. We find no evidence of a CW signal in O4a data
for both models and set upper limits on the signal amplitude and on the
ellipticity, which quantifies the asymmetry in the neutron star mass
distribution. For the single-harmonic emission model, 29 targets have the upper
limit on the amplitude below the theoretical spin-down limit. The lowest upper
limit on the amplitude is $6.4\!\times\!10^{-27}$ for the young energetic
pulsar J0537-6910, while the lowest constraint on the ellipticity is
$8.8\!\times\!10^{-9}$ for the bright nearby millisecond pulsar J0437-4715.
Additionally, for a subset of 16 targets we performed a narrowband search that
is more robust regarding the emission model, with no evidence of a signal. We
also found no evidence of non-standard polarizations as predicted by the
Brans-Dicke theory.",http://arxiv.org/abs/2501.01495v1
