Title,Published,Authors,Abstract,Link
Climate Change Conspiracy Theories on Social Media,2021-07-07T15:56:44Z,"Aman Tyagi, Kathleen M. Carley","One of the critical emerging challenges in climate change communication is
the prevalence of conspiracy theories. This paper discusses some of the major
conspiracy theories related to climate change found in a large Twitter corpus.
We use a state-of-the-art stance detection method to find whether conspiracy
theories are more popular among Disbelievers or Believers of climate change. We
then analyze which conspiracy theory is more popular than the others and how
popularity changes with climate change belief. We find that Disbelievers of
climate change are overwhelmingly responsible for sharing messages with
conspiracy theory-related keywords, and not all conspiracy theories are equally
shared. Lastly, we discuss the implications of our findings for climate change
communication.",http://arxiv.org/abs/2107.03318v1
"Trend and Thoughts: Understanding Climate Change Concern using Machine
  Learning and Social Media Data",2021-11-06T19:59:03Z,"Zhongkai Shangguan, Zihe Zheng, Lei Lin","Nowadays social media platforms such as Twitter provide a great opportunity
to understand public opinion of climate change compared to traditional survey
methods. In this paper, we constructed a massive climate change Twitter dataset
and conducted comprehensive analysis using machine learning. By conducting
topic modeling and natural language processing, we show the relationship
between the number of tweets about climate change and major climate events; the
common topics people discuss climate change; and the trend of sentiment. Our
dataset was published on Kaggle
(\url{https://www.kaggle.com/leonshangguan/climate-change-tweets-ids-until-aug-2021})
and can be used in further research.",http://arxiv.org/abs/2111.14929v1
A Climate Change Vulnerability Assessment Framework: A Spatial Approach,2021-08-22T15:50:55Z,"Claudia Cáceres, Yan Li, Brian Hilton","Climate change is affecting every known society, especially for small farmers
in Low-Income Countries because they depend heavily on rain, seasonality
patterns, and known temperature ranges. To build climate change resilient
communities among rural farmers, the first step is to understand the impact of
climate change on the population. This paper proposes a Climate Change
Vulnerability Assessment Framework (CCVAF) to assess climate change
vulnerabilities among rural farmers. The CCVAF framework uses information and
communication technology (ICT) to assess climate change vulnerabilities among
rural farmers by integrating both community level and individual household
level indicators. The CCVAF was instantiated into a GIS-based web application
named THRIVE for different decision-makers to better assess how climate change
is affecting rural farmers in Western Honduras. Qualitative evaluation of the
THRIVE showed that it is an innovative and useful tool. The CCVAF contributes
to not only the knowledge base of the climate change vulnerability assessment
but also the design science literature by providing guidelines to design a
class of climate change vulnerability assessment solutions.",http://arxiv.org/abs/2108.09762v1
"What shapes climate change perceptions in Africa? A random forest
  approach",2021-05-17T14:03:14Z,"Juan B Gonzalez, Alfonso Sanchez","Climate change perceptions are fundamental for adaptation and environmental
policy support. Although Africa is one of the most vulnerable regions to
climate change, little research has focused on how climate change is perceived
in the continent. Using random forest methodology, we analyse Afrobarometer
data (N = 45,732), joint with climatic data, to explore what shapes climate
change perceptions in Africa. We include 5 different dimensions of climate
change perceptions: awareness, belief in its human cause, risk perception, need
to stop it and self-efficacy. Results indicate that perceived agriculture
conditions are crucial for perceiving climate change. Country-level factors and
long-term changes in local weather conditions are among the most important
predictors. Moreover, education level, access to information, poverty,
authoritarian values, and trust in institutions shape individual climate change
perceptions. Demographic effects -- including religion -- seem negligible.
These findings suggest policymakers and environmental communicators how to
frame climate change in Africa to raise awareness, gather public support and
induce adaptation.",http://arxiv.org/abs/2105.07867v1
"A large-scale bibliometric analysis of global climate change research
  between 2001 and 2018",2021-07-17T10:28:28Z,"Hui-Zhen Fu, Ludo Waltman","Global climate change is attracting widespread scientific, political, and
public attention owing to the involvement of international initiatives such as
the Paris Agreement and the Intergovernmental Panel on Climate Change. We
present a large-scale bibliometric analysis based on approximately 120,000
climate change publications between 2001 and 2018 to examine how climate change
is studied in scientific research. Our analysis provides an overview of
scientific knowledge, shifts of research hotspots, global geographical
distribution of research, and focus of individual countries. In our analysis,
we identify five key fields in climate change research: physical sciences,
paleoclimatology, climate-change ecology, climate technology, and climate
policy. We draw the following key conclusions: (1) Over the investigated time
period, the focus of climate change research has shifted from understanding the
climate system toward climate technologies and policies, such as efficient
energy use and legislation. (2) There is an imbalance in scientific production
between developed and developing countries. (3) Geography, national demands,
and national strategies have been important drivers that influence the research
interests and concerns of researchers in different countries. Our study can be
used by researchers and policy makers to reflect on the directions in which
climate change research is developing and discuss priorities for future
research.",http://arxiv.org/abs/2107.08214v1
"NLP for Climate Policy: Creating a Knowledge Platform for Holistic and
  Effective Climate Action",2021-05-12T12:30:02Z,"Pradip Swarnakar, Ashutosh Modi","Climate change is a burning issue of our time, with the Sustainable
Development Goal (SDG) 13 of the United Nations demanding global climate
action. Realizing the urgency, in 2015 in Paris, world leaders signed an
agreement committing to taking voluntary action to reduce carbon emissions.
However, the scale, magnitude, and climate action processes vary globally,
especially between developed and developing countries. Therefore, from
parliament to social media, the debates and discussions on climate change
gather data from wide-ranging sources essential to the policy design and
implementation. The downside is that we do not currently have the mechanisms to
pool the worldwide dispersed knowledge emerging from the structured and
unstructured data sources.
  The paper thematically discusses how NLP techniques could be employed in
climate policy research and contribute to society's good at large. In
particular, we exemplify symbiosis of NLP and Climate Policy Research via four
methodologies. The first one deals with the major topics related to climate
policy using automated content analysis. We investigate the opinions
(sentiments) of major actors' narratives towards climate policy in the second
methodology. The third technique explores the climate actors' beliefs towards
pro or anti-climate orientation. Finally, we discuss developing a Climate
Knowledge Graph.
  The present theme paper further argues that creating a knowledge platform
would help in the formulation of a holistic climate policy and effective
climate action. Such a knowledge platform would integrate the policy actors'
varied opinions from different social sectors like government, business, civil
society, and the scientific community. The research outcome will add value to
effective climate action because policymakers can make informed decisions by
looking at the diverse public opinion on a comprehensive platform.",http://arxiv.org/abs/2105.05621v1
A review of effects of climate change on Agriculture in Africa,2021-08-25T13:08:04Z,"Samuel Asante Gyamerah, Dennis Ikpe","Currently, agriculture in Africa contributes only a tenth to global Green
House Gas (GHG) emissions from agriculture. Despite its relatively low
contribution to GHG, a conundrum of ""climate justice"", adverse impacts of
climate change disproportionately threaten Africa's agriculture, the
Continent's main economic sector. Consequently, we seek to review the effects
of climate change on Agriculture.",http://arxiv.org/abs/2108.12267v1
Graph-based Local Climate Classification in Iran,2021-10-18T11:50:37Z,"Neda Akrami, Koorush Ziarati, Soumyabrata Dev","In this paper, we introduce a novel graph-based method to classify the
regions with similar climate in a local area. We refer our proposed method as
Graph Partition Based Method (GPBM). Our proposed method attempts to overcome
the shortcomings of the current state-of-the-art methods in the literature. It
has no limit on the number of variables that can be used and also preserves the
nature of climate data. To illustrate the capability of our proposed algorithm,
we benchmark its performance with other state-of-the-art climate classification
techniques. The climate data is collected from 24 synoptic stations in Fars
province in southern Iran. The data includes seven climate variables stored as
time series from 1951 to 2017. Our results exhibit that our proposed method
performs a more realistic climate classification with less computational time.
It can save more information during the climate classification process and is
therefore efficient in further data analysis. Furthermore, using our method, we
can introduce seasonal graphs to better investigate seasonal climate changes.
To the best of our knowledge, our proposed method is the first graph-based
climate classification system.",http://arxiv.org/abs/2110.09209v1
"Climate Change Valuation Adjustment (CCVA) using parameterized climate
  change impacts",2021-02-21T21:42:36Z,"Chris Kenyon, Mourad Berrahoui","We introduce Climate Change Valuation Adjustment (CCVA) to capture climate
change impacts on CVA+FVA that are currently invisible assuming typical market
practice. To discuss such impacts on CVA+FVA from changes to instantaneous
hazard rates we introduce a flexible and expressive parameterization to capture
the path of this impact to climate change endpoints, and transient transition
effects. Finally we provide quantification of examples of typical interest
where there is risk of economic stress from sea level change up to 2101, and
from transformations of business models. We find that even with the slowest
possible uniform approach to a climate change impact in 2101 there can still be
significant CVA+FVA impacts on interest rate swaps of 20 years or more
maturity. Transformation effects on CVA+FVA are strongly dependent on timing
and duration of business model transformation. Using a parameterized approach
enables discussion with stakeholders of economic impacts on CVA+FVA, whatever
the details behind the climate impact.",http://arxiv.org/abs/2102.10691v3
"Climate, Agriculture and Food",2021-05-25T16:22:28Z,Ariel Ortiz-Bobea,"Agriculture is arguably the most climate-sensitive sector of the economy.
Growing concerns about anthropogenic climate change have increased research
interest in assessing its potential impact on the sector and in identifying
policies and adaptation strategies to help the sector cope with a changing
climate. This chapter provides an overview of recent advancements in the
analysis of climate change impacts and adaptation in agriculture with an
emphasis on methods. The chapter provides an overview of recent research
efforts addressing key conceptual and empirical challenges. The chapter also
discusses practical matters about conducting research in this area and provides
reproducible R code to perform common tasks of data preparation and model
estimation in this literature. The chapter provides a hands-on introduction to
new researchers in this area.",http://arxiv.org/abs/2105.12044v1
"Quantifying uncertainty about global and regional economic impacts of
  climate change",2021-02-25T18:04:43Z,"Jenny Bjordal, Trude Storelvmo, Anthony A. Smith Jr","The economic impacts of climate change are highly uncertain. Two of the most
important uncertainties are the sensitivity of the climate system and the
so-called damage functions, which relate climate change to economic damages and
benefits. Despite broad awareness of these uncertainties, it is unclear which
of them is most important, both on the global as well as the regional level.
Here we apply different damage functions to data from climate models with
vastly different climate sensitivities, and find that uncertainty in both
climate sensitivity and economic damage per degree of warming are of similar
importance for the global economic impact. Increasing the climate sensitivity
or the sensitivity of the damage function both increases the economic damages
globally. Yet, at the country-level the effect varies depending on the initial
temperature as well as how much the country warms. Our findings emphasise the
importance of including these uncertainties in estimates of future economic
impacts, as they both are vital for the resulting impacts and thus policy
implications.",http://arxiv.org/abs/2102.13051v1
"Handling Climate Change Using Counterfactuals: Using Counterfactuals in
  Data Augmentation to Predict Crop Growth in an Uncertain Climate Future",2021-04-08T18:54:21Z,"Mohammed Temraz, Eoin Kenny, Elodie Ruelle, Laurence Shalloo, Barry Smyth, Mark T Keane","Climate change poses a major challenge to humanity, especially in its impact
on agriculture, a challenge that a responsible AI should meet. In this paper,
we examine a CBR system (PBI-CBR) designed to aid sustainable dairy farming by
supporting grassland management, through accurate crop growth prediction. As
climate changes, PBI-CBRs historical cases become less useful in predicting
future grass growth. Hence, we extend PBI-CBR using data augmentation, to
specifically handle disruptive climate events, using a counterfactual method
(from XAI). Study 1 shows that historical, extreme climate-events (climate
outlier cases) tend to be used by PBI-CBR to predict grass growth during
climate disrupted periods. Study 2 shows that synthetic outliers, generated as
counterfactuals on a outlier-boundary, improve the predictive accuracy of
PBICBR, during the drought of 2018. This study also shows that an
instance-based counterfactual method does better than a benchmark,
constraint-guided method.",http://arxiv.org/abs/2104.04008v1
"AIRCC-Clim: a user-friendly tool for generating regional probabilistic
  climate change scenarios and risk measures",2021-10-30T11:09:03Z,"Francisco Estrada, Oscar Calderón-Bustamante, Wouter Botzen, Julián A. Velasco, Richard S. J. Tol","Complex physical models are the most advanced tools available for producing
realistic simulations of the climate system. However, such levels of realism
imply high computational cost and restrictions on their use for policymaking
and risk assessment. Two central characteristics of climate change are
uncertainty and that it is a dynamic problem in which international actions can
significantly alter climate projections and information needs, including
partial and full compliance of global climate goals. Here we present
AIRCC-Clim, a simple climate model emulator that produces regional
probabilistic climate change projections of monthly and annual temperature and
precipitation, as well as risk measures, based both on standard and
user-defined emissions scenarios for six greenhouse gases. AIRCC-Clim emulates
37 atmosphere-ocean coupled general circulation models with low computational
and technical requirements for the user. This standalone, user-friendly
software is designed for a variety of applications including impact
assessments, climate policy evaluation and integrated assessment modelling.",http://arxiv.org/abs/2111.01762v1
"Analysis of the Evolution of Parametric Drivers of High-End Sea-Level
  Hazards",2021-06-11T01:50:16Z,"Alana Hough, Tony E. Wong","Climate models are critical tools for developing strategies to manage the
risks posed by sea-level rise to coastal communities. While these models are
necessary for understanding climate risks, there is a level of uncertainty
inherent in each parameter in the models. This model parametric uncertainty
leads to uncertainty in future climate risks. Consequently, there is a need to
understand how those parameter uncertainties impact our assessment of future
climate risks and the efficacy of strategies to manage them. Here, we use
random forests to examine the parametric drivers of future climate risk and how
the relative importances of those drivers change over time. We find that the
equilibrium climate sensitivity and a factor that scales the effect of aerosols
on radiative forcing are consistently the most important climate model
parametric uncertainties throughout the 2020 to 2150 interval for both low and
high radiative forcing scenarios. The near-term hazards of high-end sea-level
rise are driven primarily by thermal expansion, while the longer-term hazards
are associated with mass loss from the Antarctic and Greenland ice sheets. Our
results highlight the practical importance of considering time-evolving
parametric uncertainties when developing strategies to manage future climate
risks.",http://arxiv.org/abs/2106.12041v1
"ClimateGAN: Raising Climate Change Awareness by Generating Images of
  Floods",2021-10-06T15:54:57Z,"Victor Schmidt, Alexandra Sasha Luccioni, Mélisande Teng, Tianyu Zhang, Alexia Reynaud, Sunand Raghupathi, Gautier Cosne, Adrien Juraver, Vahe Vardanyan, Alex Hernandez-Garcia, Yoshua Bengio","Climate change is a major threat to humanity, and the actions required to
prevent its catastrophic consequences include changes in both policy-making and
individual behaviour. However, taking action requires understanding the effects
of climate change, even though they may seem abstract and distant. Projecting
the potential consequences of extreme climate events such as flooding in
familiar places can help make the abstract impacts of climate change more
concrete and encourage action. As part of a larger initiative to build a
website that projects extreme climate events onto user-chosen photos, we
present our solution to simulate photo-realistic floods on authentic images. To
address this complex task in the absence of suitable training data, we propose
ClimateGAN, a model that leverages both simulated and real data for
unsupervised domain adaptation and conditional image generation. In this paper,
we describe the details of our framework, thoroughly evaluate components of our
architecture and demonstrate that our model is capable of robustly generating
photo-realistic flooding.",http://arxiv.org/abs/2110.02871v1
Climate-Related Disasters and the Death Toll,2021-09-05T16:15:33Z,"Valerie Chavez-Demoulin, Eric Jondeau, Linda Mhalla","With climate change accelerating, the frequency of climate disasters is
expected to increase in the decades to come. There is ongoing debate as to how
different climatic regions will be affected by such an acceleration. In this
paper, we describe a model for predicting the frequency of climate disasters
and the severity of the resulting number of deaths. The frequency of disasters
is described as a Poisson process driven by aggregate CO2 emissions. The
severity of disasters is described using a generalized Pareto distribution
driven by the trend in regional real gross domestic product (GDP) per capita.
We predict the death toll for different types of climate disasters based on the
projections made by the Intergovernmental Panel on Climate Change for the
population, the regional real GDP per capita, and aggregate CO2 emissions in
the ""sustainable"" and ""business-as-usual"" baseline scenarios.",http://arxiv.org/abs/2109.02111v1
"How are cities pledging net zero? A computational approach to analyzing
  subnational climate strategies",2021-12-14T21:33:39Z,"Siddharth Sachdeva, Angel Hsu, Ian French, Elwin Lim","Cities have become primary actors on climate change and are increasingly
setting goals aimed at net-zero emissions. The rapid proliferation of
subnational governments ""racing to zero"" emissions and articulating their own
climate mitigation plans warrants closer examination to understand how these
actors intend to meet these goals. The scattered, incomplete and heterogeneous
nature of city climate policy documents, however, has made their systemic
analysis challenging. We analyze 318 climate action documents from cities that
have pledged net-zero targets or joined a transnational climate initiative with
this goal using machine learning-based natural language processing (NLP)
techniques. We use these approaches to accomplish two primary goals: 1)
determine text patterns that predict ""ambitious"" net-zero targets, where we
define an ambitious target as one that encompasses a subnational government's
economy-wide emissions; and 2) perform a sectoral analysis to identify patterns
and trade-offs in climate action themes (i.e., land-use, industry, buildings,
etc.). We find that cities that have defined ambitious climate actions tend to
emphasize quantitative metrics and specific high-emitting sectors in their
plans, supported by mentions of governance and citizen participation. Cities
predominantly emphasize energy-related actions in their plans, particularly in
the buildings, transport and heating sectors, but often at the expense of other
sectors, including land-use and climate impacts. The method presented in this
paper provides a replicable, scalable approach to analyzing climate action
plans and a first step towards facilitating cross-city learning.",http://arxiv.org/abs/2112.11207v1
Quantum technologies for climate change: Preliminary assessment,2021-06-23T18:02:19Z,"Casey Berger, Agustin Di Paolo, Tracey Forrest, Stuart Hadfield, Nicolas Sawaya, Michał Stęchły, Karl Thibault","Climate change presents an existential threat to human societies and the
Earth's ecosystems more generally. Mitigation strategies naturally require
solving a wide range of challenging problems in science, engineering, and
economics. In this context, rapidly developing quantum technologies in
computing, sensing, and communication could become useful tools to diagnose and
help mitigate the effects of climate change. However, the intersection between
climate and quantum sciences remains largely unexplored. This preliminary
report aims to identify potential high-impact use-cases of quantum technologies
for climate change with a focus on four main areas: simulating physical
systems, combinatorial optimization, sensing, and energy efficiency. We hope
this report provides a useful resource towards connecting the climate and
quantum science communities, and to this end we identify relevant research
questions and next steps.",http://arxiv.org/abs/2107.05362v1
"PCE-PINNs: Physics-Informed Neural Networks for Uncertainty Propagation
  in Ocean Modeling",2021-05-05T17:52:21Z,"Björn Lütjens, Catherine H. Crawford, Mark Veillette, Dava Newman","Climate models project an uncertainty range of possible warming scenarios
from 1.5 to 5 degree Celsius global temperature increase until 2100, according
to the CMIP6 model ensemble. Climate risk management and infrastructure
adaptation requires the accurate quantification of the uncertainties at the
local level. Ensembles of high-resolution climate models could accurately
quantify the uncertainties, but most physics-based climate models are
computationally too expensive to run as ensemble. Recent works in
physics-informed neural networks (PINNs) have combined deep learning and the
physical sciences to learn up to 15k faster copies of climate submodels.
However, the application of PINNs in climate modeling has so far been mostly
limited to deterministic models. We leverage a novel method that combines
polynomial chaos expansion (PCE), a classic technique for uncertainty
propagation, with PINNs. The PCE-PINNs learn a fast surrogate model that is
demonstrated for uncertainty propagation of known parameter uncertainties. We
showcase the effectiveness in ocean modeling by using the local
advection-diffusion equation.",http://arxiv.org/abs/2105.02939v1
"Computationally-Efficient Climate Predictions using Multi-Fidelity
  Surrogate Modelling",2021-08-03T15:26:42Z,"Ben Hudson, Frederik Nijweide, Isaac Sebenius","Accurately modelling the Earth's climate has widespread applications ranging
from forecasting local weather to understanding global climate change.
Low-fidelity simulations of climate phenomena are readily available, but
high-fidelity simulations are expensive to obtain. We therefore investigate the
potential of Gaussian process-based multi-fidelity surrogate modelling as a way
to produce high-fidelity climate predictions at low cost. Specifically, our
model combines the predictions of a low-fidelity Global Climate Model (GCM) and
those of a high-fidelity Regional Climate Model (RCM) to produce high-fidelity
temperature predictions for a mountainous region on the coastline of Peru. We
are able to produce high-fidelity temperature predictions at significantly
lower computational cost compared to the high-fidelity model alone: our
predictions have an average error of $15.62^\circ\text{C}^2$ yet our approach
only evaluates the high-fidelity model on 6% of the region of interest.",http://arxiv.org/abs/2109.07468v1
Powering Effective Climate Communication with a Climate Knowledge Base,2021-07-23T17:02:06Z,"Kameron B. Rodrigues, Shweta Khushu, Mukut Mukherjee, Andrew Banister, Anthony Hevia, Sampath Duddu, Nikita Bhutani","While many accept climate change and its growing impacts, few converse about
it well, limiting the adoption speed of societal changes necessary to address
it. In order to make effective climate communication easier, we aim to build a
system that presents to any individual the climate information predicted to
best motivate and inspire them to take action given their unique set of
personal values. To alleviate the cold-start problem, the system relies on a
knowledge base (ClimateKB) of causes and effects of climate change, and their
associations to personal values. Since no such comprehensive ClimateKB exists,
we revisit knowledge base construction techniques and build a ClimateKB from
free text. We plan to open source the ClimateKB and associated code to
encourage future research and applications.",http://arxiv.org/abs/2107.11351v1
Demographic perspectives in research on global environmental change,2021-02-01T10:38:54Z,Raya Muttarak,"Human population is at the centre of research on global environmental change.
On the one hand, population dynamics influence the environment and the global
climate system through consumption-based carbon emissions. On the other hand,
health and wellbeing of the population is already being affected by climate
change. The knowledge on population dynamics and population heterogeneity thus
is fundamental in improving our understanding of how population size,
composition and distribution influence global environmental change and how
these changes affect subgroups of population differentially by demographic
characteristics and spatial distribution. Existing theoretical concepts and
methodological tools in demography can be readily applied to the study of
population and global environmental change. In the past couple of decades,
demographic research has enriched climate change research both in the analysis
of the impact of population dynamics on the global climate system as well as
the impact of climate change on human population. What is missing in the
literature is the study that investigates how global environmental change
affect current and future demographic processes and consequently population
trends. If global environmental change does influence fertility, mortality and
migration, the three key demographic components underlying population change,
population estimates and forecast need to adjust from the climate feedback in
population projections. Indisputably, this is the new area of research that
directly requires expertise in population science and contribution from
demographers.",http://arxiv.org/abs/2102.00757v1
Economists' erroneous estimates of damages from climate change,2021-08-17T19:32:56Z,"Stephen Keen, Timothy M. Lenton, Antoine Godin, Devrim Yilmaz, Matheus Grasselli, Timothy J. Garrett","Economists have predicted that damages from global warming will be as low as
2.1% of global economic production for a 3$^\circ$C rise in global average
surface temperature, and 7.9% for a 6$^\circ$C rise. Such relatively trivial
estimates of economic damages -- when these economists otherwise assume that
human economic productivity will be an order of magnitude higher than today --
contrast strongly with predictions made by scientists of significantly reduced
human habitability from climate change. Nonetheless, the coupled economic and
climate models used to make such predictions have been influential in the
international climate change debate and policy prescriptions. Here we review
the empirical work done by economists and show that it severely underestimates
damages from climate change by committing several methodological errors,
including neglecting tipping points, and assuming that economic sectors not
exposed to the weather are insulated from climate change. Most fundamentally,
the influential Integrated Assessment Model DICE is shown to be incapable of
generating an economic collapse, regardless of the level of damages. Given
these flaws, economists' empirical estimates of economic damages from global
warming should be rejected as unscientific, and models that have been
calibrated to them, such as DICE, should not be used to evaluate economic risks
from climate change, or in the development of policy to attenuate damages.",http://arxiv.org/abs/2108.07847v1
Growing polarisation around climate change on social media,2021-12-22T18:49:30Z,"Max Falkenberg, Alessandro Galeazzi, Maddalena Torricelli, Niccolo Di Marco, Francesca Larosa, Madalina Sas, Amin Mekacher, Warren Pearce, Fabiana Zollo, Walter Quattrociocchi, Andrea Baronchelli","Climate change and political polarisation are two of the 21st century's
critical socio-political issues. Here, we investigate their intersection by
studying the discussion around the UN Conference of The Parties on Climate
Change (COP) using Twitter data from 2014 to 2021. First, we reveal a large
increase in ideological polarisation during COP26, following low polarisation
between COP20 and COP25. Second, we show that this increase is driven by
growing right-wing activity, a 4-fold increase since COP21 relative to
pro-climate groups. Finally, we identify a broad range of ''climate
contrarian'' views during COP26, emphasising the theme of ''political
hypocrisy'' as a topic of cross-ideological appeal; contrarian views and
accusations of hypocrisy have become key themes in the Twitter climate
discussion since 2019. With future climate action reliant on negotiations at
COP27 and beyond, our results highlight the importance of monitoring
polarisation, and its impacts, in the public climate discourse.",http://arxiv.org/abs/2112.12137v5
Reconciling high resolution climate datasets using KrigR,2021-08-09T11:42:40Z,"Richard Davy, Erik Kusch","There is an increasing need for high spatial and temporal resolution climate
data for the wide community of researchers interested in climate change and its
consequences. Currently, there is a large mismatch between the spatial
resolutions of global climate model and reanalysis datasets (at best around
0.25o and 0.1o respectively) and the resolutions needed by many end-users of
these datasets, which are typically on the scale of 30 arcseconds (~900m). This
need for improved spatial resolution in climate datasets has motivated several
groups to statistically downscale various combinations of observational or
reanalysis datasets. However, the variety of downscaling methods and inputs
used makes it difficult to reconcile the resultant differences between these
high-resolution datasets. Here we make use of the KrigR R-package to
statistically downscale the world-leading ERA5(-Land) reanalysis data using
kriging. We show that kriging can accurately recover spatial heterogeneity of
climate data given strong relationships with co-variates; that by preserving
the uncertainty associated with the statistical downscaling, one can
investigate and account for confidence in high-resolution climate data; and
that the statistical uncertainty provided by KrigR can explain much of the
difference between widely used high resolution climate datasets (CHELSA,
TerraClimate, and WorldClim2) depending on variable, timescale, and region.
This demonstrates the advantages of using KrigR to generate customized high
spatial and/or temporal resolution climate data.",http://arxiv.org/abs/2108.03957v1
Uncertainty in Climate Science: Not Cause for Inaction,2021-08-19T16:45:43Z,"Juan M. Restrepo, Michael E. Mann","Using observational data and an elementary rigorous statistical fact it is
easily shown that the distribution of Earth's climate is non-stationary.
Examination of records of hundreds of local Industrial Era temperature
histories in the Northern Hemisphere were used to show this fact.
Statistically, the mean of the ensemble has been rising during the Industrial
Era. All of this confirms what climate scientists already know. The issue of
predictions under uncertainties was tackled as well: a simple balance model was
tuned to track an ensemble of climate records. Stochastic parametrizations were
created to capture natural and anthropogenic CO2 forcings. The resulting
stochastic model was then tested against historical data and then used to make
future predictions. This exercise confirmed as well climate science attribution
to significant global warming during the Industrial Era to anthropogenic
activities. The variability of the model due to uncertainties is simply not
large enough to obfuscate a clear rise in the mean temperature in the
Industrial Era. Further, even if the variance of the natural CO2 contribution
is greatly increased artificially (in the model), the fluctuations cannot
account for the current change in the historical mean.
  These outcomes weaken the factual validity of the US administration,
2016-2020, claims that there are too many uncertainties in climate and climate
science to make climate predictions, and further that contemporary reports of
floods, extreme weather, even a rising global mean temperature are simply
manifestations of a climate that always fluctuates within a nature-derived
statistical distribution.",http://arxiv.org/abs/2108.08781v2
Climate-Invariant Machine Learning,2021-12-14T07:02:57Z,"Tom Beucler, Pierre Gentine, Janni Yuval, Ankitesh Gupta, Liran Peng, Jerry Lin, Sungduk Yu, Stephan Rasp, Fiaz Ahmed, Paul A. O'Gorman, J. David Neelin, Nicholas J. Lutsko, Michael Pritchard","Projecting climate change is a generalization problem: we extrapolate the
recent past using physical models across past, present, and future climates.
Current climate models require representations of processes that occur at
scales smaller than model grid size, which have been the main source of model
projection uncertainty. Recent machine learning (ML) algorithms hold promise to
improve such process representations, but tend to extrapolate poorly to climate
regimes they were not trained on. To get the best of the physical and
statistical worlds, we propose a new framework - termed ""climate-invariant"" ML
- incorporating knowledge of climate processes into ML algorithms, and show
that it can maintain high offline accuracy across a wide range of climate
conditions and configurations in three distinct atmospheric models. Our results
suggest that explicitly incorporating physical knowledge into data-driven
models of Earth system processes can improve their consistency, data
efficiency, and generalizability across climate regimes.",http://arxiv.org/abs/2112.08440v5
The climate in climate economics,2021-07-13T15:23:13Z,"Doris Folini, Felix Kübler, Aleksandra Malova, Simon Scheidegger","To analyze climate change mitigation strategies, economists rely on
simplified climate models - climate emulators. We propose a generic and
transparent calibration and evaluation strategy for these climate emulators
that is based on Coupled Model Intercomparison Project, Phase 5 (CMIP5). We
demonstrate that the appropriate choice of the free model parameters can be of
key relevance for the predicted social cost of carbon. We propose to use four
different test cases: two tests to separately calibrate and evaluate the carbon
cycle and temperature response, a test to quantify the transient climate
response, and a final test to evaluate the performance for scenarios close to
those arising from economic models. We re-calibrate the climate part of the
widely used DICE-2016: the multi-model mean as well as extreme, but still
permissible climate sensitivities and carbon cycle responses. We demonstrate
that the functional form of the climate emulator of the DICE-2016 model is fit
for purpose, despite its simplicity, but its carbon cycle and temperature
equations are miscalibrated. We examine the importance of the calibration for
the social cost of carbon in the context of a partial equilibrium setting where
interest rates are exogenous, as well as the simple general equilibrium setting
from DICE-2016. We find that the model uncertainty from different consistent
calibrations of the climate system can change the social cost of carbon by a
factor of four if one assumes a quadratic damage function. When calibrated to
the multi-model mean, our model predicts similar values for the social cost of
carbon as the original DICE-2016, but with a strongly reduced sensitivity to
the discount rate and about one degree less long-term warming. The social cost
of carbon in DICE-2016 is oversensitive to the discount rate, leading to
extreme comparative statics responses to changes in preferences.",http://arxiv.org/abs/2107.06162v3
"Using the Climate App to learn about Planetary Habitability and Climate
  Change",2021-10-26T23:57:30Z,"Lan Xi Zhu, Anthony Courchesne, Nicolas B. Cowan","Simple climate models have been around for more than a century but have
recently come back into fashion: they are useful for explaining global warming
and the habitability of extrasolar planets. The Climate App
(https://www.climateapp.ca) is an interactive web-based application that
describes the radiative transfer governing planetary climate. The App is
currently available in French and English and is suitable for teaching
high-school through college students, or public outreach. The beginner version
can be used to explore the greenhouse effect and planetary albedo, sufficient
for explaining anthropogenic climate change, the Faint Young Sun Paradox, the
habitability of TRAPPIST planets and other simple scenarios. There is also an
advanced option with more atmospheric layers and incorporating the absorption
and scattering of shortwave radiation for students and educators wishing a
deeper dive into atmospheric radiative transfer. A number of pedagogical
activities are being beta tested and rolled out.",http://arxiv.org/abs/2110.14087v1
"Simple El Niño prediction scheme using the signature of climate time
  series",2021-09-05T07:18:53Z,"Nozomi Sugiura, Shinya Kouketsu","El Ni\~{n}o is a typical example of a coupled atmosphere--ocean phenomenon,
but it is unclear whether it can be described quantitatively by a correlation
between relevant climate events. To provide clarity on this issue, we developed
a machine learning-based El Ni\~{n}o prediction model that uses the time series
of climate indices. By transforming the multidimensional time series into the
path signature, the model is able to properly evaluate the order and
nonlinearity of climate events, which allowed us to achieve good forecasting
skill (mean square error = 0.596 for 6-month prediction). In addition, it is
possible to provide information about the sequence of climate events that tend
to change the future NINO3.4 sea surface temperatures. In forecasting
experiments conducted, changes in the North Pacific Index and several NINO
indices were found to be important precursors. The results suggest that El
Ni\~{n}o is predictable to some extent based on the correlation of climate
events.",http://arxiv.org/abs/2109.02013v5
"Applications of large deviation theory in geophysical fluid dynamics and
  climate science",2021-06-25T10:43:01Z,"Vera Melinda Galfi, Valerio Lucarini, Francesco Ragone, Jeroen Wouters","The climate system is a complex, chaotic system with many degrees of freedom
and variability on a vast range of temporal and spatial scales. Attaining a
deeper level of understanding of its dynamical processes is a scientific
challenge of great urgency, especially given the ongoing climate change and the
evolving climate crisis. In statistical physics, complex, many-particle systems
are studied successfully using the mathematical framework of Large Deviation
Theory (LDT). A great potential exists for applying LDT to problems relevant
for geophysical fluid dynamics and climate science. In particular, LDT allows
for understanding the fundamental properties of persistent deviations of
climatic fields from the long-term averages and for associating them to
low-frequency, large scale patterns of climatic variability. Additionally, LDT
can be used in conjunction with so-called rare events algorithms to explore
rarely visited regions of the phase space and thus to study special dynamical
configurations of the climate. These applications are of key importance to
improve our understanding of high-impact weather and climate events.
Furthermore, LDT provides powerful tools for evaluating the probability of
noise-induced transitions between competing metastable states of the climate
system or of its components. This in turn essential for improving our
understanding of the global stability properties of the climate system and of
its predictability of the second kind in the sense of Lorenz. The goal of this
review is manifold. First, we want to provide an introduction to the derivation
of large deviation laws in the context of stochastic processes. We then relate
such results to the existing literature showing the current status of
applications of LDT in climate science and geophysical fluid dynamics. Finally,
we propose some possible lines of future investigations.",http://arxiv.org/abs/2106.13546v1
The macroeconomic cost of climate volatility,2021-07-21T15:22:11Z,"Piergiorgio Alessandri, Haroon Mumtaz","We study the impact of climate volatility on economic growth exploiting data
on 133 countries between 1960 and 2019. We show that the conditional (ex ante)
volatility of annual temperatures increased steadily over time, rendering
climate conditions less predictable across countries, with important
implications for growth. Controlling for concomitant changes in temperatures, a
+1 degree C increase in temperature volatility causes on average a 0.3 percent
decline in GDP growth and a 0.7 percent increase in the volatility of GDP.
Unlike changes in average temperatures, changes in temperature volatility
affect both rich and poor countries.",http://arxiv.org/abs/2108.01617v2
"LACLICHEV: Exploring the History of Climate Change in Latin America
  within Newspapers Digital Collections",2021-05-03T12:45:18Z,"Genoveva Vargas-Solar, José-Luis Zechinelli-Martini, Javier A. Espinosa-Oviedo, Luis M. Vilches-Blázquez","This paper introduces LACLICHEV (Latin American Climate Change Evolution
platform ), a data collections exploration environment for exploring historical
newspapers searching for articles reporting meteorological events. LACLICHEV is
based on data collections' exploration techniques combined with information
retrieval, data analytics, and geographic querying and visualization. This
environment provides tools for curating, exploring and analyzing historical
newspapers articles, their description and location, and the vocabularies used
for referring to meteorological events. The objective being to understand the
content of newspapers and identifying possible patterns and models that can
build a view of the history of climate change in the Latin American region.",http://arxiv.org/abs/2105.00792v1
"The Power of Language: Understanding Sentiment Towards the Climate
  Emergency using Twitter Data",2021-01-25T19:51:10Z,Arman Sarjou,"Understanding how attitudes towards the Climate Emergency vary can hold the
key to driving policy changes for effective action to mitigate climate related
risk. The Oil and Gas industry account for a significant proportion of global
emissions and so it could be speculated that there is a relationship between
Crude Oil Futures and sentiment towards the Climate Emergency. Using Latent
Dirichlet Allocation for Topic Modelling on a bespoke Twitter dataset, this
study shows that it is possible to split the conversation surrounding the
Climate Emergency into 3 distinct topics. Forecasting Crude Oil Futures using
Seasonal AutoRegressive Integrated Moving Average Modelling gives promising
results with a root mean squared error of 0.196 and 0.209 on the training and
testing data respectively. Understanding variation in attitudes towards climate
emergency provides inconclusive results which could be improved using
spatial-temporal analysis methods such as Density Based Clustering (DBSCAN).",http://arxiv.org/abs/2101.10376v1
Episodic deluges in simulated hothouse climates,2021-11-04T19:11:07Z,"Jacob Seeley, Robin Wordsworth","Earth's distant past and potentially its future include extremely warm
""hothouse"" climate states, but little is known about how the atmosphere behaves
in such states. One distinguishing characteristic of hothouse climates is that
they feature lower-tropospheric radiative heating, rather than cooling, due to
the closing of the water vapor infrared window regions. Previous work has
suggested that this could lead to temperature inversions and significant
changes in cloud cover, but no previous modeling of the hothouse regime has
resolved convective-scale turbulent air motions and cloud cover directly, thus
leaving many questions about hothouse radiative heating unanswered. Here, we
conduct simulations that explicitly resolve convection and find that
lower-tropospheric radiative heating in hothouse climates causes the hydrologic
cycle to shift from a quasi-steady regime to a ""relaxation oscillator"" regime,
in which precipitation occurs in short and intense outbursts separated by
multi-day dry spells. The transition to the oscillatory regime is accompanied
by strongly enhanced local precipitation fluxes, a significant increase in
cloud cover, and a transiently positive (unstable) climate feedback parameter.
Our results indicate that hothouse climates may feature a novel form of
""temporal"" convective self-organization, with implications for both cloud
coverage and erosion processes.",http://arxiv.org/abs/2111.03109v1
"Addressing Deep Learning Model Uncertainty in Long-Range Climate
  Forecasting with Late Fusion",2021-12-10T00:00:09Z,"Ken C. L. Wong, Hongzhi Wang, Etienne E. Vos, Bianca Zadrozny, Campbell D. Watson, Tanveer Syeda-Mahmood","Global warming leads to the increase in frequency and intensity of climate
extremes that cause tremendous loss of lives and property. Accurate long-range
climate prediction allows more time for preparation and disaster risk
management for such extreme events. Although machine learning approaches have
shown promising results in long-range climate forecasting, the associated model
uncertainties may reduce their reliability. To address this issue, we propose a
late fusion approach that systematically combines the predictions from multiple
models to reduce the expected errors of the fused results. We also propose a
network architecture with the novel denormalization layer to gain the benefits
of data normalization without actually normalizing the data. The experimental
results on long-range 2m temperature forecasting show that the framework
outperforms the 30-year climate normals, and the accuracy can be improved by
increasing the number of models.",http://arxiv.org/abs/2112.05254v1
"Loosely Conditioned Emulation of Global Climate Models With Generative
  Adversarial Networks",2021-04-29T02:10:08Z,"Alexis Ayala, Christopher Drazic, Brian Hutchinson, Ben Kravitz, Claudia Tebaldi","Climate models encapsulate our best understanding of the Earth system,
allowing research to be conducted on its future under alternative assumptions
of how human-driven climate forces are going to evolve. An important
application of climate models is to provide metrics of mean and extreme climate
changes, particularly under these alternative future scenarios, as these
quantities drive the impacts of climate on society and natural systems. Because
of the need to explore a wide range of alternative scenarios and other sources
of uncertainties in a computationally efficient manner, climate models can only
take us so far, as they require significant computational resources, especially
when attempting to characterize extreme events, which are rare and thus demand
long and numerous simulations in order to accurately represent their changing
statistics. Here we use deep learning in a proof of concept that lays the
foundation for emulating global climate model output for different scenarios.
We train two ""loosely conditioned"" Generative Adversarial Networks (GANs) that
emulate daily precipitation output from a fully coupled Earth system model: one
GAN modeling Fall-Winter behavior and the other Spring-Summer. Our GANs are
trained to produce spatiotemporal samples: 32 days of precipitation over a
64x128 regular grid discretizing the globe. We evaluate the generator with a
set of related performance metrics based upon KL divergence, and find the
generated samples to be nearly as well matched to the test data as the
validation data is to test. We also find the generated samples to accurately
estimate the mean number of dry days and mean longest dry spell in the 32 day
samples. Our trained GANs can rapidly generate numerous realizations at a
vastly reduced computational expense, compared to large ensembles of climate
models, which greatly aids in estimating the statistics of extreme events.",http://arxiv.org/abs/2105.06386v1
"Identifying the atmospheric drivers of drought and heat using a smoothed
  deep learning approach",2021-11-09T18:16:39Z,"Magdalena Mittermeier, Maximilian Weigert, David Rügamer","Europe was hit by several, disastrous heat and drought events in recent
summers. Besides thermodynamic influences, such hot and dry extremes are driven
by certain atmospheric situations including anticyclonic conditions. Effects of
climate change on atmospheric circulations are complex and many open research
questions remain in this context, e.g., on future trends of anticyclonic
conditions. Based on the combination of a catalog of labeled circulation
patterns and spatial atmospheric variables, we propose a smoothed convolutional
neural network classifier for six types of anticyclonic circulations that are
associated with drought and heat. Our work can help to identify important
drivers of hot and dry extremes in climate simulations, which allows to unveil
the impact of climate change on these drivers. We address various challenges
inherent to circulation pattern classification that are also present in other
climate patterns, e.g., subjective labels and unambiguous transition periods.",http://arxiv.org/abs/2111.05303v1
"Inference for extreme spatial temperature events in a changing climate
  with application to Ireland",2021-11-16T17:00:35Z,"Dáire Healy, Jonathan Tawn, Peter Thorne, Andrew Parnell","We investigate the changing nature of the frequency, magnitude and spatial
extent of extreme temperatures in Ireland from 1931 to 2022. We develop an
extreme value model that captures spatial and temporal non-stationarity in
extreme daily maximum temperature data. We model the tails of the marginal
variables using the generalised Pareto distribution and the spatial dependence
of extreme events by a semi-parametric Brown-Resnick r-generalised Pareto
process, with parameters of each model allowed to change over time. We use
weather station observations for modelling extreme events since data from
climate models (not conditioned on observational data) can over-smooth these
events and have trends determined by the specific climate model configuration.
However, climate models do provide valuable information about the detailed
physiography over Ireland and the associated climate response. We propose novel
methods which exploit the climate model data to overcome issues linked to the
sparse and biased sampling of the observations. Our analysis identifies a
temporal change in the marginal behaviour of extreme temperature events over
the study domain, which is much larger than the change in mean temperature
levels over this time window. We illustrate how these characteristics result in
increased spatial coverage of the events that exceed critical temperatures.",http://arxiv.org/abs/2111.08616v2
The climate system and the second law of thermodynamics,2021-02-02T20:33:13Z,"Martin S. Singh, Morgan E O'Neill","The second law of thermodynamics implies a relationship between the net
entropy export by the Earth and its internal irreversible entropy production.
The application of this constraint for the purpose of understanding Earth's
climate is reviewed. Both radiative processes and material processes are
responsible for irreversible entropy production in the climate system. Focusing
on material processes, an entropy budget for the climate system is derived
which accounts for the multi-phase nature of the hydrological cycle. The
entropy budget facilitates a heat-engine perspective of atmospheric
circulations that has been used to propose theories for convective updraft
velocities, tropical cyclone intensity, and the atmospheric meridional heat
transport. Such theories can only be successful, however, if they properly
account for the irreversible entropy production associated with water in all
its phases in the atmosphere. Irreversibility associated with such moist
processes is particularly important in the context of global climate change,
for which the concentration of water vapor in the atmosphere is expected to
increase, and recent developments toward understanding the response of the
atmospheric heat engine to climate change are discussed. Finally, the
application of variational approaches to the climate and geophysical flows is
briefly reviewed, including the use of equilibrium statistical mechanics to
predict behavior of long-lived coherent structures, and the controversial
maximum entropy production principle.",http://arxiv.org/abs/2102.01745v3
"Machine learning reveals how personalized climate communication can both
  succeed and backfire",2021-09-10T20:47:34Z,"Totte Harinen, Alexandre Filipowicz, Shabnam Hakimi, Rumen Iliev, Matthew Klenk, Emily Sumner","Different advertising messages work for different people. Machine learning
can be an effective way to personalise climate communications. In this paper we
use machine learning to reanalyse findings from a recent study, showing that
online advertisements increased some people's belief in climate change while
resulting in decreased belief in others. In particular, we show that the effect
of the advertisements could change depending on people's age and ethnicity.",http://arxiv.org/abs/2109.05104v1
"Assessing present and future risk of water damage using building
  attributes, meteorology and topography",2021-10-29T15:37:15Z,"Claudio Heinrich-Mertsching, Jens Christian Wahl, Alba Ordonez, Marita Stien, John Elvsborg, Ola Haug, Thordis L. Thorarinsdottir","Weather-related risk makes the insurance industry inevitably concerned with
climate and climate change. Buildings hit by pluvial flooding is a key
manifestation of this risk, giving rise to compensations of the induced
physical damages and business interruptions. In this work, we establish a
nationwide, building-specific risk score for water damage associated with
pluvial flooding in Norway. We fit a generalized additive model that relates
the number of water damages to a wide range of explanatory variables that can
be categorized into building attributes, climatological variables and
topographical characteristics. The model assigns a risk score to every location
in Norway, based on local topography and climate, which is not only useful for
insurance companies, but also for city planning. Combining our model with an
ensemble of climate projections allows us to project the (spatially varying)
impacts of climate change on the risk of pluvial flooding towards the middle
and end of the 21st century.",http://arxiv.org/abs/2110.15862v2
Quantum Artificial Intelligence for the Science of Climate Change,2021-07-28T19:00:33Z,"Manmeet Singh, Chirag Dhara, Adarsh Kumar, Sukhpal Singh Gill, Steve Uhlig","Climate change has become one of the biggest global problems increasingly
compromising the Earth's habitability. Recent developments such as the
extraordinary heat waves in California & Canada, and the devastating floods in
Germany point to the role of climate change in the ever-increasing frequency of
extreme weather. Numerical modelling of the weather and climate have seen
tremendous improvements in the last five decades, yet stringent limitations
remain to be overcome. Spatially and temporally localized forecasting is the
need of the hour for effective adaptation measures towards minimizing the loss
of life and property. Artificial Intelligence-based methods are demonstrating
promising results in improving predictions, but are still limited by the
availability of requisite hardware and software required to process the vast
deluge of data at a scale of the planet Earth. Quantum computing is an emerging
paradigm that has found potential applicability in several fields. In this
opinion piece, we argue that new developments in Artificial Intelligence
algorithms designed for quantum computers - also known as Quantum Artificial
Intelligence (QAI) - may provide the key breakthroughs necessary to furthering
the science of climate change. The resultant improvements in weather and
climate forecasts are expected to cascade to numerous societal benefits.",http://arxiv.org/abs/2108.10855v2
"Parameter uncertainty quantification in an idealized GCM with a seasonal
  cycle",2021-07-22T20:52:45Z,"Michael F. Howland, Oliver R. A. Dunbar, Tapio Schneider","Climate models are generally calibrated manually by comparing selected
climate statistics, such as the global top-of-atmosphere energy balance, to
observations. The manual tuning only targets a limited subset of observational
data and parameters. Bayesian calibration can estimate climate model parameters
and their uncertainty using a larger fraction of the available data and
automatically exploring the parameter space more broadly. In Bayesian learning,
it is natural to exploit the seasonal cycle, which has large amplitude,
compared with anthropogenic climate change, in many climate statistics. In this
study, we develop methods for the calibration and uncertainty quantification
(UQ) of model parameters exploiting the seasonal cycle, and we demonstrate a
proof-of-concept with an idealized general circulation model (GCM). Uncertainty
quantification is performed using the calibrate-emulate-sample approach, which
combines stochastic optimization and machine learning emulation to speed up
Bayesian learning. The methods are demonstrated in a perfect-model setting
through the calibration and UQ of a convective parameterization in an idealized
GCM with a seasonal cycle. Calibration and UQ based on seasonally averaged
climate statistics, compared to annually averaged, reduces the calibration
error by up to an order of magnitude and narrows the spread of posterior
distributions by factors between two and five, depending on the variables used
for UQ. The reduction in the size of the parameter posterior distributions
leads to a reduction in the uncertainty of climate model predictions.",http://arxiv.org/abs/2108.00827v1
"Persistence of species in a predator-prey system with climate change and
  either nonlocal or local dispersal",2021-05-04T07:57:19Z,"Wonhyung Choi, Thomas Giletti, Jong-Shenq Guo","We are concerned with the persistence of both predator and prey in a
diffusive predator-prey system with a climate change effect, which is modeled
by a spatial-temporal heterogeneity depending on a moving variable. Moreover,
we consider both the cases of nonlocal and local dispersal. In both these
situations, we first prove the existence of forced waves, which are positive
stationary solutions in the moving frames of the climate change, of either
front or pulse type. Then we address the persistence or extinction of the prey
and the predator separately in various moving frames, and achieve a complete
picture in the local diffusion case. We show that the survival of the species
depends crucially on how the climate change speed compares with the minimal
speed of some pulse type forced waves.",http://arxiv.org/abs/2105.01349v2
"Future operation of hydropower in Europe under high renewable
  penetration and climate change",2021-05-17T12:05:25Z,"Ebbe Kyhl Gøtske, Marta Victoria","The balancing provided by hydropower reservoirs is essential in the
transition towards a decarbonised European energy system, but the resource
might be impacted by future climate change. In this work, we first analyse the
hydropower operation needed to balance a wind and solar dominated European
energy system, to signify whether and to what extent hydropower is required to
operate differently due to the decarbonisation of the energy system. Second, we
apply runoff data achieved with 10 dynamically downscaled climate models with
0.11 x 0.11 deg horizontal and daily resolution to project the future reservoir
inflow at three CO2 emissions scenarios: low (RCP2.6), mid (RCP4.5), and high
emissions (RCP8.5). We show that the decarbonised energy system increases the
ramp rates and seasonality of the hydropower operation. Despite large
interannual and intermodel variability, we found a significant change in annual
inflow due to climate change in 20 out of 22 European countries at the mid and
high emissions scenarios. The seasonal profile, as well as the frequency and
duration of droughts and floods, is also projected to be impacted.",http://arxiv.org/abs/2105.07756v1
"Model estimates for contribution of natural and anthropogenic CO$_2$ and
  CH$_4$ emissions into the atmosphere from the territory of Russia, China, USA
  and Canada to global climate changes in the 21st century",2021-11-23T11:18:44Z,"S. N. Denisov, A. V. Eliseev, I. I. Mokhov","The contribution of anthropogenic and natural greenhouse gases to the
atmosphere from the territory of Russia, China, USA and Canada to global
climate change under different scenarios of anthropogenic emissions in the 21st
century has been assessed. It is shown that the consideration of the changes in
climate conditions can affect the impact indicators of greenhouse gas emissions
on the climate system, especially over long time horizons. In making decisions,
it is necessary to take into account that the role of natural fluxes of
greenhouse gases into the atmosphere from the terrestrial ecosystems can
change. For all the countries considered, the uptake of CO$_2$ by terrestrial
ecosystems under all scenarios of anthropogenic impact begins to decrease in
the second half of the 21st century, so its stabilizing effect may gradually
lose importance. At the same time, methane emissions in all of the considered
regions are increasing significantly. The net effect of these greenhouse gas
natural fluxes in some cases can even lead to warming acceleration by the end
of the 21 st century.",http://arxiv.org/abs/2111.11793v1
"Climate uncertainties caused by unknown land distribution on habitable
  M-Earths",2021-10-08T18:00:03Z,"Evelyn Macdonald, Adiv Paradise, Kristen Menou, Christopher Lee","A planet's surface conditions can significantly impact its climate and
habitability. In this study, we use the 3D general circulation model ExoPlaSim
to systematically vary dayside land cover on a synchronously rotating,
temperate rocky planet under two extreme and opposite continent configurations,
in which either all of the land or all of the ocean is centred at the
substellar point. We identify water vapour and sea ice as competing drivers of
climate, and we isolate land-dependent regimes under which one or the other
dominates. We find that the amount and configuration of land can change the
planet's globally averaged surface temperature by up to 20K, and its
atmospheric water vapour content by several orders of magnitude. The most
discrepant models have partial dayside land cover with opposite continent
configurations. Since transit spectroscopy may permit observations of M-dwarf
planets' atmospheres, but not their surfaces, these land-related climate
differences likely represent a limiting uncertainty in a given planet's
climate, even if its atmospheric composition is known. Our results are robust
to variations in atmospheric CO2 concentration, stellar temperature, and
instellation.",http://arxiv.org/abs/2110.04310v1
Clustering Future Scenarios Based on Predicted Range Maps,2021-01-19T01:48:08Z,"Matthew Davidow, Cory Merow, Judy Che-Castaldo, Toryn Schafer, Marie-Christine Duker, Derek Corcoran, David Matteson","Predictions of biodiversity trajectories under climate change are crucial in
order to act effectively in maintaining the diversity of species. In many
ecological applications, future predictions are made under various global
warming scenarios as described by a range of different climate models. The
outputs of these various predictions call for a reliable interpretation. We
propose a interpretable and flexible two step methodology to measure the
similarity between predicted species range maps and cluster the future scenario
predictions utilizing a spectral clustering technique. We find that clustering
based on ecological impact (predicted species range maps) is mainly driven by
the amount of warming. We contrast this with clustering based only on predicted
climate features, which is driven mainly by climate models. The differences
between these clusterings illustrate that it is crucial to incorporate
ecological information to understand the relevant differences between climate
models. The findings of this work can be used to better synthesize forecasts of
biodiversity loss under the wide spectrum of results that emerge when
considering potential future biodiversity loss.",http://arxiv.org/abs/2101.07408v2
"On the Generalization of Agricultural Drought Classification from
  Climate Data",2021-11-30T14:49:46Z,"Julia Gottfriedsen, Max Berrendorf, Pierre Gentine, Markus Reichstein, Katja Weigel, Birgit Hassler, Veronika Eyring","Climate change is expected to increase the likelihood of drought events, with
severe implications for food security. Unlike other natural disasters, droughts
have a slow onset and depend on various external factors, making drought
detection in climate data difficult. In contrast to existing works that rely on
simple relative drought indices as ground-truth data, we build upon soil
moisture index (SMI) obtained from a hydrological model. This index is directly
related to insufficiently available water to vegetation. Given ERA5-Land
climate input data of six months with land use information from MODIS satellite
observation, we compare different models with and without sequential inductive
bias in classifying droughts based on SMI. We use PR-AUC as the evaluation
measure to account for the class imbalance and obtain promising results despite
a challenging time-based split. We further show in an ablation study that the
models retain their predictive capabilities given input data of coarser
resolutions, as frequently encountered in climate models.",http://arxiv.org/abs/2111.15452v1
Robustness of competing climatic states,2021-02-18T15:24:34Z,"Charline Ragon, Valerio Lembo, Valerio Lucarini, Christian Vérard, Jérôme Kasparian, Maura Brunetti","The climate is a non-equilibrium system undergoing the continuous action of
forcing and dissipation. Under the effect of a spatially inhomogeneous
absorption of solar energy, all the climate components dynamically respond
until an approximate steady state (or attractor) is reached. However, multiple
steady states can co-exist for a given forcing and with the same boundary
conditions. Here, we apply the Thermodynamic Diagnostic Tool (TheDiaTo) to
investigate the statistical properties of five co-existing climates, ranging
from a snowball to an ice-free aquaplanet, obtained in MITgcm coupled
simulations. The aim is to explore the multistability of the climate model
setup by highlighting differences in competing steady states and their
characteristic signatures regarding the meridional transport of heat and water
mass, the Lorenz energy cycle and the material entropy production. We also
investigate how such attractors change when the model configuration is varied.
We consider, in particular, the effect of changing the representation of the
cloud albedo, and of implementing an improved closure of the energy budget. We
find that, even if the dynamics remains on the same attractor, state variables
are modified. The set of metrics in TheDiaTo quantifies such modifications and
represents a valuable tool for model evaluation.",http://arxiv.org/abs/2102.09418v2
"Spatio-temporal quantile regression analysis revealing more nuanced
  patterns of climate change: a study of long-term daily temperature in
  Australia",2021-03-10T00:02:24Z,"Qibin Duan, Clare A. McGrory, Glenn Brown, Kerrie Mengersen, You-Gan Wang","Climate change is commonly associated with an overall increase in mean
temperature in a defined past time period. Many studies consider temperature
trends at the global scale, but the literature is lacking in in-depth analysis
of the temperature trends across Australia in recent decades. In addition to
heterogeneity in mean and median values, daily Australia temperature data
suffers from quasi-periodic heterogeneity in variance. However, this issue has
barely been overlooked in climate research. A contribution of this article is
that we propose a joint model of quantile regression and variability. By
accounting appropriately for the heterogeneity in these types of data, our
analysis reveals that daily maximum temperature is warming by 0.21 Celsius per
decade and daily minimum temperature by 0.13 Celsius per decade. However, our
modeling also shows nuanced patterns of climate change depends on location,
season, and the percentiles of the temperature series over Australia.",http://arxiv.org/abs/2103.05791v1
"Climate Change Sensing through Terahertz Communications: A Disruptive
  Application of 6G Networks",2021-10-06T21:13:32Z,"Lasantha Thakshila Wedage, Bernard Butler, Sasitharan Balasubramaniam, Yevgeni Koucheryavy, Josep M. Jornet","Climate change resulting from the misuse and over-exploitation of natural
resources has affected and continues to impact the planet's ecosystem. This
pressing issue is leading to the development of novel technologies to sense and
measure damaging gas emissions. In parallel, the accelerating evolution of
wireless communication networks is resulting in wider deployment of mobile
telecommunication infrastructure. With 5G technologies already being
commercially deployed, the research community is starting research into new
technologies for 6G. One of the visions for 6G is the use of the terahertz
(THz) spectrum. In this paper, we propose and explore the use of THz spectrum
simultaneously for ultrabroadband communication and atmospheric sensing by
leveraging the absorption of THz signals. Through the use of machine learning,
we present preliminary results on how we can analyze signal path loss and power
spectral density to infer the concentration of different climate-impacting
gases. Our vision is to demonstrate how 6G infrastructure can provide sensor
data for climate change sensing, in addition to its primary purpose of wireless
communication.",http://arxiv.org/abs/2110.03074v1
The IITM Earth System Model (IITM ESM),2021-01-09T19:06:28Z,"R. Krishnan, P. Swapna, Ayantika Dey Choudhury, Sandeep Narayansetti, A. G. Prajeesh, Manmeet Singh, Aditi Modi, Roxy Mathew, Ramesh Vellore, J. Jyoti, T. P. Sabin, J. Sanjay, Sandip Ingle","Earth System Models (ESM) are important tools that allow us to understand and
quantify the physical, chemical & biological mechanisms governing the rates of
change of elements of the Earth System, comprising of the atmosphere, ocean,
land, cryosphere and biosphere (terrestrial and marine) and related components.
ESMs are essentially coupled numerical models which incorporate processes
within and across the different Earth system components and are expressed as
set of mathematical equations. ESMs are useful for enhancing our fundamental
understanding of the climate system, its multi-scale variability, global and
regional climatic phenomena and making projections of future climate change. In
this chapter, we briefly describe the salient aspects of the Indian Institute
of Tropical Meteorology ESM (IITM ESM), that has been developed recently at the
IITM, Pune, India, for investigating long-term climate variability and change
with focus on the South Asian monsoon.",http://arxiv.org/abs/2101.03410v1
Networks of climate change: Connecting causes and consequences,2021-05-20T15:37:09Z,"Petter Holme, Juan C. Rocha","Understanding the causes and consequences of, and devising countermeasures
to, global warming is a profoundly complex problem. Network representations are
sometimes the only way forward, and sometimes able to reduce the complexity of
the original problem. Networks are both necessary and natural elements of
climate science. Furthermore, networks form a mathematical foundation for a
multitude of computational and analytical techniques. We are only beginning to
see the benefits of this connection between the sciences of climate change and
network science. In this review, we cover the wide spectrum of network
applications in the climate-change literature -- what they represent, how they
are analyzed, and what insights they bring. We also discuss network data,
tools, and problems yet to be explored.",http://arxiv.org/abs/2105.12537v2
"A hybrid convolutional neural network/active contour approach to
  segmenting dead trees in aerial imagery",2021-12-06T00:53:51Z,"Jacquelyn A. Shelton, Przemyslaw Polewski, Wei Yao, Marco Heurich","The stability and ability of an ecosystem to withstand climate change is
directly linked to its biodiversity. Dead trees are a key indicator of overall
forest health, housing one-third of forest ecosystem biodiversity, and
constitute 8%of the global carbon stocks. They are decomposed by several
natural factors, e.g. climate, insects and fungi. Accurate detection and
modeling of dead wood mass is paramount to understanding forest ecology, the
carbon cycle and decomposers. We present a novel method to construct precise
shape contours of dead trees from aerial photographs by combining established
convolutional neural networks with a novel active contour model in an energy
minimization framework. Our approach yields superior performance accuracy over
state-of-the-art in terms of precision, recall, and intersection over union of
detected dead trees. This improved performance is essential to meet emerging
challenges caused by climate change (and other man-made perturbations to the
systems), particularly to monitor and estimate carbon stock decay rates,
monitor forest health and biodiversity, and the overall effects of dead wood on
and from climate change.",http://arxiv.org/abs/2112.02725v1
"Changes in the distribution of observed annual maximum temperatures in
  Europe",2021-12-30T16:21:07Z,"Graeme Auld, Gabriele Hegerl, Ioannis Papastathopoulos","In this study we consider the problem of detecting and quantifying changes in
the distribution of the annual maximum daily maximum temperature (TXx) in a
large gridded data set of European daily temperature during the years
1950-2018. Several statistical models are considered, each of which models TXx
using a generalized extreme value (GEV) distribution with the GEV parameters
varying smoothly over space. In contrast to several previous studies which fit
independent GEV models at the grid box level, our models pull information from
neighbouring grid boxes for more efficient parameter estimation. The GEV
location and scale parameters are allowed to vary in time using the log of
atmospheric CO2 as a covariate. Changes are detected most strongly in the GEV
location parameter with the TXx distributions generally shifting towards hotter
temperatures. Averaged across our spatial domain, the 100-year return level of
TXx based on the 2018 climate is approximately 2{\deg}C hotter than that based
on the 1950 climate. Moreover, also averaging across our spatial domain, the
100-year return level of TXx based on the 1950 climate corresponds
approximately to a 6-year return level in the 2018 climate.",http://arxiv.org/abs/2112.15117v1
"The effects of ENSO, climate change and human activities on the water
  level of Lake Toba, Indonesia: a critical literature review",2021-05-19T04:39:51Z,"Hendri Irwandi, Mohammad Syamsu Rosid, Terry Mart","This research quantitatively and qualitatively analyzes the factors
responsible for the water level variations in Lake Toba, North Sumatra
Province, Indonesia. According to several studies carried out from 1993 to
2020, changes in the water level were associated with climate variability,
climate change, and human activities. Furthermore, these studies stated that
reduced rainfall during the rainy season due to the El Nino Southern
Oscillation (ENSO) and the continuous increase in the maximum and average
temperatures were some of the effects of climate change in the Lake Toba
catchment area. Additionally, human interventions such as industrial
activities, population growth, and damage to the surrounding environment of the
Lake Toba watershed had significant impacts in terms of decreasing the water
level. However, these studies were unable to determine the factor that had the
most significant effect, although studies on other lakes worldwide have shown
these factors are the main causes of fluctuations or decreases in water levels.
A simulation study of Lake Toba's water balance showed the possibility of
having a water surplus until the mid-twenty-first century. The input discharge
was predicted to be greater than the output; therefore, Lake Toba could be
optimized without affecting the future water level. However, the climate
projections depicted a different situation, with scenarios predicting the
possibility of extreme climate anomalies, demonstrating drier climatic
conditions in the future. This review concludes that it is necessary to conduct
an in-depth, comprehensive, and systematic study to identify the most dominant
factor among the three that is causing the decrease in the Lake Toba water
level and to describe the future projected water level.",http://arxiv.org/abs/2105.08918v1
Quantification and interpretation of the climate variability record,2021-01-20T10:10:38Z,"Anna S. von der Heydt, Peter Ashwin, Charles D. Camp, Michel Crucifix, Henk A. Dijkstra, Peter Ditlevsen, Timothy M. Lenton","The spectral view of variability is a compelling and adaptable tool for
understanding variability of the climate. In Mitchell (1976) seminal paper, it
was used to express, on one graph with log scales, a very wide range of climate
variations from millions of years to days. The spectral approach is
particularly useful for suggesting causal links between forcing variability and
climate response variability. However, a substantial degree of variability is
intrinsic and the Earth system may respond to external forcing in a complex
manner. There has been an enormous amount of work on understanding climate
variability over the last decades. Hence in this paper, we address the
question: Can we (after 40 years) update the Mitchell (1976) diagram and
provide it with a better interpretation? By reviewing both the extended
observations available for such a diagram and new methodological developments
in the study of the interaction between internal and forced variability over a
wide range of timescales, we give a positive answer to this question. In
addition, we review alternative approaches to the spectral decomposition and
pose some challenges for a more detailed quantification of climate variability.",http://arxiv.org/abs/2101.08050v1
Projections of the Transient State-Dependency of Climate Feedbacks,2021-06-03T08:50:22Z,"Robbin Bastiaansen, Henk A. Dijkstra, Anna S. von der Heydt","When the climate system is forced, e.g. by emission of greenhouse gases, it
responds on multiple time scales. As temperatures rise, feedback processes
might intensify or weaken. Current methods to analyze feedback strength,
however, do not take such state dependency into account; they only consider
changes in (global mean) temperature and assume all feedbacks are linearly
related to that. This makes (transient) changes in feedback strengths almost
intangible and generally leads to underestimation of future warming. Here, we
present a multivariate (and spatially explicit) framework that facilitates
dissection of climate feedbacks over time scales. Using this framework,
information on the composition of projected (transient) future climates and
feedback strengths can be obtained. Moreover, it can be used to make
projections for many emission scenarios through linear response theory. The new
framework is illustrated using the Community Earth System Model version 2
(CESM2).",http://arxiv.org/abs/2106.01692v1
"Knowledge for a warmer world: a patent analysis of climate change
  adaptation technologies",2021-08-08T20:04:39Z,"Kerstin Hötte, Su Jung Jee","Technologies can help strengthen the resilience of our economy against
existential climate-risks. We investigate climate change adaptation
technologies (CCATs) in US patents to understand (1) historical patterns and
drivers of innovation; (2) scientific and technological requirements to develop
and use CCATs; and (3) CCATs' potential technological synergies with
mitigation. First, in contrast to mitigation, innovation in CCATs only slowly
takes off, indicating a relatively low awareness of investors for solutions to
cope with climate risks. Historical trends in environmental regulation, energy
prices, and public support can be associated with patenting in CCATs. Second,
CCATs form two main clusters: science-intensive ones in agriculture, health,
and monitoring technologies; and engineering-intensive ones in coastal, water,
and infrastructure technologies. Analyses of technology-specific scientific and
technological knowledge bases inform directions for how to facilitate
advancement, transfer and use of CCATs. Lastly, CCATs show strong technological
complementarities with mitigation as more than 25% of CCATs bear mitigation
benefits. While not judging about the complementarity of mitigation and
adaptation in general, our results suggest how policymakers can harness these
technological synergies to achieve both goals simultaneously.",http://arxiv.org/abs/2108.03722v2
Predicting Atlantic Multidecadal Variability,2021-10-29T23:56:24Z,"Glenn Liu, Peidong Wang, Matthew Beveridge, Young-Oh Kwon, Iddo Drori","Atlantic Multidecadal Variability (AMV) describes variations of North
Atlantic sea surface temperature with a typical cycle of between 60 and 70
years. AMV strongly impacts local climate over North America and Europe,
therefore prediction of AMV, especially the extreme values, is of great
societal utility for understanding and responding to regional climate change.
This work tests multiple machine learning models to improve the state of AMV
prediction from maps of sea surface temperature, salinity, and sea level
pressure in the North Atlantic region. We use data from the Community Earth
System Model 1 Large Ensemble Project, a state-of-the-art climate model with
3,440 years of data. Our results demonstrate that all of the models we use
outperform the traditional persistence forecast baseline. Predicting the AMV is
important for identifying future extreme temperatures and precipitation, as
well as hurricane activity, in Europe and North America up to 25 years in
advance.",http://arxiv.org/abs/2111.00124v1
Accelerating the timeline for climate action in California,2021-03-13T21:59:00Z,"Daniel M Kammen, Teenie Matlock, Manuel Pastor, David Pellow, Veerabhadran Ramanathan, Tom Steyer, Leah Stokes, Feliz Ventura","The climate emergency increasingly threatens our communities, ecosystems,
food production, health, and economy. It disproportionately impacts lower
income communities, communities of color, and the elderly. Assessments since
the 2018 IPCC 1.5 Celsius report show that current national and sub-national
commitments and actions are insufficient. Fortunately, a suite of solutions
exists now to mitigate the climate crisis if we initiate and sustain actions
today. California, which has a strong set of current targets in place and is
home to clean energy and high technology innovation, has fallen behind in its
climate ambition compared to a number of major governments. California, a
catalyst for climate action globally, can and should ramp up its leadership by
aligning its climate goals with the most recent science, coordinating actions
to make 2030 a point of significant accomplishment. This entails dramatically
accelerating its carbon neutrality and net-negative emissions goal from 2045 to
2030, including advancing clean energy and clean transportation standards, and
accelerating nature-based solutions on natural and working lands. It also means
changing its current greenhouse gas reduction goals both in the percentage and
the timing: cutting emissions by 80 percent (instead of 40 percent) below 1990
levels much closer to 2030 than 2050. These actions will enable California to
save lives, benefit underserved and frontline communities, and save trillions
of dollars. This rededication takes heed of the latest science, accelerating
equitable, job-creating climate policies. While there are significant
challenges to achieving these goals, California can establish policy now that
will unleash innovation and channel market forces, as has happened with solar,
and catalyze positive upward-scaling tipping points for accelerated global
climate action.",http://arxiv.org/abs/2103.07801v1
"Projection Of Temperature And Precipitation For 2020-2100 For Tehran
  Region Using Post-processing Of General Circulation Models Output And
  Artificial Neural Network Approach",2021-09-10T02:06:42Z,"Ehsan Mosadegh, Iman Babaeian","Multi-model projections in climate studies are performed to quantify
uncertainty and improve reliability in climate projections. The challenging
issue is that there is no unique way to obtain performance metrics, nor is
there any consensus about which method would be the best method of combining
models. The goal of this study was to investigate whether combining climate
model projections by artificial neural network (ANN) approach could improve
climate projections and therefore reduce the range of uncertainty. The
equally-weighted model averaging (the mean model) and single climate model
projections (the best model) were also considered as references for the ANN
combination approach. Simulations of present-day climate and future projections
from 15 General Circulation Models (GCMs) for temperature and precipitation
were employed. Results indicated that combining GCM projections by the ANN
combination approach significantly improved the simulations of present-day
temperature and precipitation than the best model and the mean model. The
identity of the best model changed between the two variables and among
stations. Therefore, there was not a unique model which could represent the
best model for all variables and/or stations over the study region. The mean
model was also not skillful in giving a reliable projection of historical
climate. Simulation of temperature indicated that the ANN approach had the best
skill at simulating present-day monthly means than other approaches in all
stations. Simulation of present-day precipitation, however, indicated that the
ANN approach was not the best approach in all stations although it performed
better than the mean model. Multi-model projections of future climate
conditions performed by the ANN approach projected an increase in temperature
and reduction in precipitation in all stations and for all scenarios.",http://arxiv.org/abs/2109.04619v1
Sensitivity analysis of an integrated climate-economic model,2021-03-10T17:57:13Z,"Benjamin M. Bolker, Matheus R. Grasselli, Emma Holmes","We conduct a sensitivity analysis of a new type of integrated
climate-economic model recently proposed in the literature, where the core
economic component is based on the Goodwin-Keen dynamics instead of a
neoclassical growth model. Because these models can exhibit much richer
behaviour, including multiple equilibria, runaway trajectories and unbounded
oscillations, it is crucial to determine how sensitive they are to changes in
underlying parameters. We focus on four economic parameters (markup rate, speed
of price adjustments, coefficient of money illusion, growth rate of
productivity) and two climate parameters (size of upper ocean reservoir,
equilibrium climate sensitivity) and show how their relative effects on the
outcomes of the model can be quantified by methods that can be applied to an
arbitrary number of parameters.",http://arxiv.org/abs/2103.06227v1
"Triggering A Climate Change Dominated ""Anthropocene"": Is It Common Among
  Exocivilizations?",2021-03-10T20:25:28Z,"Ethan Savitch, Adam Frank, Jonathan Carroll-Nellenback, Jacob Haqq-Misra, Axel Kleidon, Marina Alberti","We seek to model the coupled evolution of a planet and a civilization through
the era when energy harvesting by the civilization drives the planet into new
and adverse climate states. In this way we ask if triggering ""anthropocenes"" of
the kind humanity is experiencing now might be a generic feature of
planet-civilization evolution. In this study we focus on the effects of energy
harvesting via combustion and vary the planet's initial atmospheric chemistry
and orbital radius. In our model, energy harvesting increases the
civilization's population growth rate while also, eventually, leading to a
degradation of the planetary climate state (relative to the civilization's
habitability.) We also assume the existence of a Complex Life Habitable Zone in
which very high levels of $CO_2$ are detrimental to multi-cellular animal life
such as those creating technological civilizations. Our models show that the
civilization's growth is truncated by planetary feedback (a ""climate dominated
anthropocene"") for a significant region of the initial parameter space.",http://arxiv.org/abs/2103.06330v1
"Automated Identification of Climate Risk Disclosures in Annual Corporate
  Reports",2021-08-03T11:14:05Z,"David Friederich, Lynn H. Kaack, Alexandra Luccioni, Bjarne Steffen","It is important for policymakers to understand which financial policies are
effective in increasing climate risk disclosure in corporate reporting. We use
machine learning to automatically identify disclosures of five different types
of climate-related risks. For this purpose, we have created a dataset of over
120 manually-annotated annual reports by European firms. Applying our approach
to reporting of 337 firms over the last 20 years, we find that risk disclosure
is increasing. Disclosure of transition risks grows more dynamically than
physical risks, and there are marked differences across industries.
Country-specific dynamics indicate that regulatory environments potentially
have an important role to play for increasing disclosure.",http://arxiv.org/abs/2108.01415v1
Remote sensing and AI for building climate adaptation applications,2021-07-06T15:55:26Z,"Beril Sirmacek, Ricardo Vinuesa","Urban areas are not only one of the biggest contributors to climate change,
but also they are one of the most vulnerable areas with high populations who
would together experience the negative impacts. In this paper, we address some
of the opportunities brought by satellite remote sensing imaging and artificial
intelligence (AI) in order to measure climate adaptation of cities
automatically. We propose a framework combining AI and simulation which may be
useful for extracting indicators from remote-sensing images and may help with
predictive estimation of future states of these climate-adaptation-related
indicators. When such models become more robust and used in real life
applications, they may help decision makers and early responders to choose the
best actions to sustain the well-being of society, natural resources and
biodiversity. We underline that this is an open field and an on-going area of
research for many scientists, therefore we offer an in-depth discussion on the
challenges and limitations of data-driven methods and the predictive estimation
models in general.",http://arxiv.org/abs/2107.02693v2
"Short-term Hourly Streamflow Prediction with Graph Convolutional GRU
  Networks",2021-07-07T20:26:39Z,"Muhammed Sit, Bekir Demiray, Ibrahim Demir","The frequency and impact of floods are expected to increase due to climate
change. It is crucial to predict streamflow, consequently flooding, in order to
prepare and mitigate its consequences in terms of property damage and
fatalities. This paper presents a Graph Convolutional GRUs based model to
predict the next 36 hours of streamflow for a sensor location using the
upstream river network. As shown in experiment results, the model presented in
this study provides better performance than the persistence baseline and a
Convolutional Bidirectional GRU network for the selected study area in
short-term streamflow prediction.",http://arxiv.org/abs/2107.07039v1
"Hybrid physics-based and data-driven modeling with calibrated
  uncertainty for lithium-ion battery degradation diagnosis and prognosis",2021-10-25T11:14:12Z,"Jing Lin, Yu Zhang, Edwin Khoo","Advancing lithium-ion batteries (LIBs) in both design and usage is key to
promoting electrification in the coming decades to mitigate human-caused
climate change. Inadequate understanding of LIB degradation is an important
bottleneck that limits battery durability and safety. Here, we propose hybrid
physics-based and data-driven modeling for online diagnosis and prognosis of
battery degradation. Compared to existing battery modeling efforts, we aim to
build a model with physics as its backbone and statistical learning techniques
as enhancements. Such a hybrid model has better generalizability and
interpretability together with a well-calibrated uncertainty associated with
its prediction, rendering it more valuable and relevant to safety-critical
applications under realistic usage scenarios.",http://arxiv.org/abs/2110.13661v2
"Using Temperature Sensitivity to Estimate Shiftable Electricity Demand:
  Implications for power system investments and climate change",2021-09-01T23:04:48Z,"Michael J. Roberts, Sisi Zhang, Eleanor Yuan, James Jones, Matthias Fripp","Growth of intermittent renewable energy and climate change make it
increasingly difficult to manage electricity demand variability. Centralized
storage can help but is costly. An alternative is to shift demand. Cooling and
heating demands are substantial and can be economically shifted using thermal
storage. To estimate what thermal storage, employed at scale, might do to
reshape electricity loads, we pair fine-scale weather data with hourly
electricity use to estimate the share of temperature-sensitive demand across 31
regions that span the continental United States. We then show how much
variability can be reduced by shifting temperature-sensitive loads, with and
without improved transmission between regions. We find that approximately three
quarters of within-day, within-region demand variability can be eliminated by
shifting just half of temperature-sensitive demand. The variability-reducing
benefits of shifting temperature-sensitive demand complement those gained from
improved interregional transmission, and greatly mitigate the challenge of
serving higher peaks under climate change.",http://arxiv.org/abs/2109.00643v2
Deep Learning-based Extreme Heatwave Forecast,2021-03-17T16:10:06Z,"Valérian Jacques-Dumas, Francesco Ragone, Pierre Borgnat, Patrice Abry, Freddy Bouchet","Because of the impact of extreme heat waves and heat domes on society and
biodiversity, their study is a key challenge. We specifically study
long-lasting extreme heat waves, which are among the most important for climate
impacts. Physics driven weather forecast systems or climate models can be used
to forecast their occurrence or predict their probability. The present work
explores the use of deep learning architectures, trained using outputs of a
climate model, as an alternative strategy to forecast the occurrence of extreme
long-lasting heatwaves. This new approach will be useful for several key
scientific goals which include the study of climate model statistics, building
a quantitative proxy for resampling rare events in climate models, study the
impact of climate change, and should eventually be useful for forecasting.
Fulfilling these important goals implies addressing issues such as class-size
imbalance that is intrinsically associated with rare event prediction,
assessing the potential benefits of transfer learning to address the nested
nature of extreme events (naturally included in less extreme ones). We train a
Convolutional Neural Network, using 1000 years of climate model outputs, with
large-class undersampling and transfer learning. From the observed snapshots of
the surface temperature and the 500 hPa geopotential height fields, the trained
network achieves significant performance in forecasting the occurrence of
long-lasting extreme heatwaves. We are able to predict them at three different
levels of intensity, and as early as 15 days ahead of the start of the event
(30 days ahead of the end of the event).",http://arxiv.org/abs/2103.09743v3
"Coupling physical understanding and statistical modeling to estimate ice
  jam flood frequency in the northern Peace-Athabasca Delta under climate
  change",2021-02-26T02:57:09Z,"Jonathan R. Lamontagne, Martin Jasek, Jared D. Smith","The Peace-Athabasca Delta (PAD) of northwestern Alberta is one of the largest
inland freshwater deltas in the world, laying at the confluence of the Peace
and Athabasca Rivers. The PAD is recognized as a having unique ecological
significance and periodic ice jam flooding from both rivers is an important
feature of its current ecology. Past studies have debated whether a change in
ice jam flood (IJF) frequency on the Peace River has recently occurred, and
what factors might be driving any perceived changes. This study contributes to
this debate by addressing two questions: (1) what factors are most predictive
of Peace River IJFs, and (2) how might climate change impact IJF frequency?
This work starts with a physically-based conceptual model of the necessary
conditions for a large Peace River IJF, and the factors that indicate whether
those conditions are met. Logistic regression is applied to the historical
flood record to determine which combination of hydroclimatic and riverine
factors best predict IJFs and the uncertainty in those relationships given the
available data. Winter precipitation and temperature are most predictive of
Peace River IJFs, while freeze-up elevation contains little predictive power
and is not closely related to IJF occurrence. The best logistic regression
model is forced with downscaled climate change scenarios from multiple climate
models to project IJF frequency for a variety of plausible futures. Parametric
uncertainty in the best logistic regression model is propagated into the
projections using a parametric bootstrap to sample many plausible statistical
models. Although there is variability across emissions scenarios and climate
models, all projections indicate that the frequency of Peace River IJFs is
likely to decrease substantially in the coming decades, and that average
waiting times between future IJFs will likely surpass recent experience.",http://arxiv.org/abs/2102.13282v1
Controlling Weather Field Synthesis Using Variational Autoencoders,2021-07-30T19:17:30Z,"Dario Augusto Borges Oliveira, Jorge Guevara Diaz, Bianca Zadrozny, Campbell Watson","One of the consequences of climate change is anobserved increase in the
frequency of extreme cli-mate events. That poses a challenge for
weatherforecast and generation algorithms, which learnfrom historical data but
should embed an often un-certain bias to create correct scenarios. This
paperinvestigates how mapping climate data to a knowndistribution using
variational autoencoders mighthelp explore such biases and control the
synthesisof weather fields towards more extreme climatescenarios. We
experimented using a monsoon-affected precipitation dataset from southwest
In-dia, which should give a roughly stable pattern ofrainy days and ease our
investigation. We reportcompelling results showing that mapping complexweather
data to a known distribution implementsan efficient control for weather field
synthesis to-wards more (or less) extreme scenarios.",http://arxiv.org/abs/2108.00048v1
"A safety factor approach to designing urban infrastructure for dynamic
  conditions",2021-02-08T19:35:25Z,"Sanjib Sharma, Ben Seiyon Lee, Robert E. Nicholas, Klaus Keller","Current approaches to design flood-sensitive infrastructure typically assume
a stationary rainfall distribution and neglect many uncertainties. These
assumptions are inconsistent with observations that suggest intensifying
extreme precipitation events and the uncertainties surrounding projections of
the coupled natural-human systems. Here we demonstrate a safety factor approach
to designing urban infrastructure in a changing climate. Our results show that
assuming climate stationarity and neglecting deep uncertainties can drastically
underestimate flood risks and lead to poor infrastructure design choices. We
find that climate uncertainty dominates the socioeconomic and engineering
uncertainties that impact the hydraulic reliability in stormwater drainage
systems. We quantify the upfront costs needed to achieve higher hydraulic
reliability and robustness against the deep uncertainties surrounding
projections of rainfall, surface runoff characteristics, and infrastructure
lifetime. Depending on the location, we find that adding safety factors of 1.4
to 1.7 to the standard stormwater pipe design guidance produces robust
performance to the considered deep uncertainties. The insights gained from this
study highlight the need for updating traditional engineering design strategies
to improve infrastructure reliability under socioeconomic and environmental
changes.",http://arxiv.org/abs/2102.04496v4
"Generative modeling of spatio-temporal weather patterns with extreme
  event conditioning",2021-04-26T10:58:44Z,"Konstantin Klemmer, Sudipan Saha, Matthias Kahl, Tianlin Xu, Xiao Xiang Zhu","Deep generative models are increasingly used to gain insights in the
geospatial data domain, e.g., for climate data. However, most existing
approaches work with temporal snapshots or assume 1D time-series; few are able
to capture spatio-temporal processes simultaneously. Beyond this, Earth-systems
data often exhibit highly irregular and complex patterns, for example caused by
extreme weather events. Because of climate change, these phenomena are only
increasing in frequency. Here, we proposed a novel GAN-based approach for
generating spatio-temporal weather patterns conditioned on detected extreme
events. Our approach augments GAN generator and discriminator with an encoded
extreme weather event segmentation mask. These segmentation masks can be
created from raw input using existing event detection frameworks. As such, our
approach is highly modular and can be combined with custom GAN architectures.
We highlight the applicability of our proposed approach in experiments with
real-world surface radiation and zonal wind data.",http://arxiv.org/abs/2104.12469v1
Automatic Claim Review for Climate Science via Explanation Generation,2021-07-30T16:37:45Z,"Shraey Bhatia, Jey Han Lau, Timothy Baldwin","There is unison is the scientific community about human induced climate
change. Despite this, we see the web awash with claims around climate change
scepticism, thus driving the need for fact checking them but at the same time
providing an explanation and justification for the fact check. Scientists and
experts have been trying to address it by providing manually written feedback
for these claims. In this paper, we try to aid them by automating generating
explanation for a predicted veracity label for a claim by deploying the
approach used in open domain question answering of a fusion in decoder
augmented with retrieved supporting passages from an external knowledge. We
experiment with different knowledge sources, retrievers, retriever depths and
demonstrate that even a small number of high quality manually written
explanations can help us in generating good explanations.",http://arxiv.org/abs/2107.14740v1
"Free-Riding for Future: Field Experimental Evidence of Strategic
  Substitutability in Climate Protest",2021-12-17T12:40:51Z,"Johannes Jarke-Neuert, Grischa Perino, Henrike Schwickert","We test the hypothesis that protest participation decisions in an adult
population of potential climate protesters are interdependent. Subjects
(n=1,510) from the four largest German cities were recruited two weeks before
protest date. We measured participation (ex post) and beliefs about the other
subjects' participation (ex ante) in an online survey, used a randomized
informational intervention to induce exogenous variance in beliefs, and
estimated the causal effect of a change in belief on the probability of
participation using a control function approach. Participation decisions are
found to be strategic substitutes: a one percentage-point increase of belief
causes a .67 percentage-point decrease in the probability of participation in
the average subject.",http://arxiv.org/abs/2112.09478v1
Climate Change Adaptation under Heterogeneous Beliefs,2021-01-21T03:44:38Z,"Marcel Nutz, Florian Stebegg","We study strategic interactions between firms with heterogeneous beliefs
about future climate impacts. To that end, we propose a Cournot-type
equilibrium model where firms choose mitigation efforts and production
quantities such as to maximize the expected profits under their subjective
beliefs. It is shown that optimal mitigation efforts are increased by the
presence of uncertainty and act as substitutes; i.e., one firm's lack of
mitigation incentivizes others to act more decidedly, and vice versa.",http://arxiv.org/abs/2101.08424v2
"Modeling of Pan Evaporation Based on the Development of Machine Learning
  Methods",2021-10-10T10:06:16Z,Mustafa Al-Mukhtar,"For effective planning and management of water resources and implementation
of the related strategies, it is important to ensure proper estimation of
evaporation losses, especially in regions that are prone to drought. Changes in
climatic factors, such as changes in temperature, wind speed, sunshine hours,
humidity, and solar radiation can have a significant impact on the evaporation
process. As such, evaporation is a highly non-linear, non-stationary process,
and can be difficult to be modeled based on climatic factors, especially in
different agro-climatic conditions. The aim of this study, therefore, is to
investigate the feasibility of several machines learning (ML) models
(conditional random forest regression, Multivariate Adaptive Regression
Splines, Bagged Multivariate Adaptive Regression Splines, Model Tree M5, K-
nearest neighbor, and the weighted K- nearest neighbor) for modeling the
monthly pan evaporation estimation. This study proposes the development of
newly explored ML models for modeling evaporation losses in three different
locations over the Iraq region based on the available climatic data in such
areas. The evaluation of the performance of the proposed model based on various
evaluation criteria showed the capability of the proposed weighted K- nearest
neighbor model in modeling the monthly evaporation losses in the studies areas
with better accuracy when compared with the other existing models used as a
benchmark in this study.",http://arxiv.org/abs/2110.04749v1
Towards Representation Learning for Atmospheric Dynamics,2021-09-19T07:43:30Z,"Sebastian Hoffmann, Christian Lessig","The prediction of future climate scenarios under anthropogenic forcing is
critical to understand climate change and to assess the impact of potentially
counter-acting technologies. Machine learning and hybrid techniques for this
prediction rely on informative metrics that are sensitive to pertinent but
often subtle influences. For atmospheric dynamics, a critical part of the
climate system, no well established metric exists and visual inspection is
currently still often used in practice. However, this ""eyeball metric"" cannot
be used for machine learning where an algorithmic description is required.
Motivated by the success of intermediate neural network activations as basis
for learned metrics, e.g. in computer vision, we present a novel,
self-supervised representation learning approach specifically designed for
atmospheric dynamics. Our approach, called AtmoDist, trains a neural network on
a simple, auxiliary task: predicting the temporal distance between elements of
a randomly shuffled sequence of atmospheric fields (e.g. the components of the
wind field from reanalysis or simulation). The task forces the network to learn
important intrinsic aspects of the data as activations in its layers and from
these hence a discriminative metric can be obtained. We demonstrate this by
using AtmoDist to define a metric for GAN-based super resolution of vorticity
and divergence. Our upscaled data matches both visually and in terms of its
statistics a high resolution reference closely and it significantly outperform
the state-of-the-art based on mean squared error. Since AtmoDist is
unsupervised, only requires a temporal sequence of fields, and uses a simple
auxiliary task, it has the potential to be of utility in a wide range of
applications.",http://arxiv.org/abs/2109.09076v2
"Predicting Critical Biogeochemistry of the Southern Ocean for Climate
  Monitoring",2021-10-30T00:13:46Z,"Ellen Park, Jae Deok Kim, Nadege Aoki, Yumeng Melody Cao, Yamin Arefeen, Matthew Beveridge, David Nicholson, Iddo Drori","The Biogeochemical-Argo (BGC-Argo) program is building a network of globally
distributed, sensor-equipped robotic profiling floats, improving our
understanding of the climate system and how it is changing. These floats,
however, are limited in the number of variables measured. In this study, we
train neural networks to predict silicate and phosphate values in the Southern
Ocean from temperature, pressure, salinity, oxygen, nitrate, and location and
apply these models to earth system model (ESM) and BGC-Argo data to expand the
utility of this ocean observation network. We trained our neural networks on
observations from the Global Ocean Ship-Based Hydrographic Investigations
Program (GO-SHIP) and use dropout regularization to provide uncertainty bounds
around our predicted values. Our neural network significantly improves upon
linear regression but shows variable levels of uncertainty across the ranges of
predicted variables. We explore the generalization of our estimators to test
data outside our training distribution from both ESM and BGC-Argo data. Our use
of out-of-distribution test data to examine shifts in biogeochemical parameters
and calculate uncertainty bounds around estimates advance the state-of-the-art
in oceanographic data and climate monitoring. We make our data and code
publicly available.",http://arxiv.org/abs/2111.00126v1
"Non-parametric multimodel Regional Frequency Analysis applied to climate
  change detection and attribution",2021-11-01T09:54:12Z,"Philomène Le Gall, Anne-Catherine Favre, Philippe Naveau, Alexandre Tuel","A recurrent question in climate risk analysis is determining how climate
change will affect heavy precipitation patterns. Dividing the globe into
homogeneous sub-regions should improve the modelling of heavy precipitation by
inferring common regional distributional parameters. In addition, in the
detection and attribution (D&A) field, biases due to model errors in global
climate models (GCMs) should be considered to attribute the anthropogenic
forcing effect. Within this D&A context, we propose an efficient clustering
algorithm that, compared to classical regional frequency analysis (RFA)
techniques, is covariate-free and accounts for dependence. It is based on a new
non-parametric dissimilarity that combines both the RFA constraint and the
pairwise dependence. We derive asymptotic properties of our dissimilarity
estimator, and we interpret it for generalised extreme value distributed pairs.
  As a D&A application, we cluster annual daily precipitation maxima of 16 GCMs
from the coupled model intercomparison project. We combine the climatologically
consistent subregions identified for all GCMs. This improves the spatial
clusters coherence and outperforms methods either based on margins or on
dependence. Finally, by comparing the natural forcings partition with the one
with all forcings, we assess the impact of anthropogenic forcing on
precipitation extreme patterns.",http://arxiv.org/abs/2111.00798v1
"Multiple regression analysis of anthropogenic and heliogenic climate
  drivers, and some cautious forecasts",2021-01-13T16:30:32Z,Frank Stefani,"The two main drivers of climate change on sub-Milankovic time scales are
re-assessed by means of a multiple regression analysis. Evaluating linear
combinations of the logarithm of carbon dioxide concentration and the
geomagnetic aa-index as a proxy for solar activity, we reproduce the sea
surface temperature (HadSST) since the middle of the 19th century with an
adjusted $R^2$ value of around 87 per cent for a climate sensitivity (of TCR
type) in the range of 0.6 K until 1.6 K per doubling of CO$_2$. The solution of
the regression is quite sensitive: when including data from the last decade,
the simultaneous occurrence of a strong El Ni\~no on one side and low aa-values
on the other side lead to a preponderance of solutions with relatively high
climate sensitivities around 1.6 K. If those later data are excluded, the
regression leads to a significantly higher weight of the aa-index and a
correspondingly lower climate sensitivity going down to 0.6 K. The plausibility
of such low values is discussed in view of recent experimental and
satellite-borne measurements. We argue that a further decade of data collection
will be needed to allow for a reliable distinction between low and high
sensitivity values. Based on recent ideas about a quasi-deterministic planetary
synchronization of the solar dynamo, we make a first attempt to predict the
aa-index and the resulting temperature anomaly for various typical CO$_2$
scenarios. Even for the highest climate sensitivities, and an unabated linear
CO$_2$ increase, we predict only a mild additional temperature rise of around 1
K until the end of the century, while for the lower values an imminent
temperature drop in the near future, followed by a rather flat temperature
curve, is prognosticated.",http://arxiv.org/abs/2101.05183v1
"Understanding the Farmers, Environmental Citizenship Behaviors Towards
  Climate Change. The Moderating Mediating Role of Environmental Knowledge and
  Ascribed Responsibility",2021-02-23T15:05:51Z,"Immaculate Maumoh, Emmanuel H. Yindi","Knowledge is known to be a pre-condition for an individuals behavior. For the
most efficient informational strategies for education, it is essential that we
identify the types of knowledge that promote behavior effectively and
investigate their structure. The purpose of this paper is therefore to examine
the factors that affect Kenyan farmers, environmental citizenship behavior
(ECB) in the context of Adaptation and mitigation (Climate smart agriculture).
To achieve this objective, a theoretical framework has been developed based on
value belief norm (VBN) theory. Design/methodology/approach, Data were obtained
from 350 farmers using a survey method. Partial lease square structural
equation modelling (PLS-SEM) was used to examine the hypothetical model. The
results of PLS analysis confirm the direct and mediating effect of the causal
sequences of the variables in the VBN model. The moderating role of
Environmental knowledge has been seen to be impactful in Climate Smart
Agriculture.",http://arxiv.org/abs/2102.12378v1
Reconsidering CO2 emissions from Computer Vision,2021-04-18T04:01:40Z,"Andre Fu, Mahdi S. Hosseini, Konstantinos N. Plataniotis","Climate change is a pressing issue that is currently affecting and will
affect every part of our lives. It's becoming incredibly vital we, as a
society, address the climate crisis as a universal effort, including those in
the Computer Vision (CV) community. In this work, we analyze the total cost of
CO2 emissions by breaking it into (1) the architecture creation cost and (2)
the life-time evaluation cost. We show that over time, these costs are
non-negligible and are having a direct impact on our future. Importantly, we
conduct an ethical analysis of how the CV-community is unintentionally
overlooking its own ethical AI principles by emitting this level of CO2. To
address these concerns, we propose adding ""enforcement"" as a pillar of ethical
AI and provide some recommendations for how architecture designers and broader
CV community can curb the climate crisis.",http://arxiv.org/abs/2104.08702v1
"Empirical estimation of anthropogenic and natural contributions to
  surface air temperature trends at different latitudes",2021-12-02T14:25:00Z,"I. I. Mokhov, D. A. Smirnov","How strong are quantitative contributions of the key natural modes of climate
variability and the anthropogenic factor characterized by the changes of the
radiative forcing of greenhouse gases in the atmosphere to the trends of the
surface air temperature at different latitudes of the Northern and Southern
Hemispheres on various time intervals? Such contributions to trends are
estimated here from observation data with the simplest empirical models.
Trivariate autoregressive models are fitted to the data since the 19th century
and used to assess the impact of the anthropogenic forcing together with
different natural climate modes including Atlantic Multidecadal Oscillation,
El-Nino / Southern Oscillation, Interdecadal Pacific Oscillation, Pacific
Decadal Oscillation, and Antarctic Oscillation. For relatively short intervals
of the length of two or three decades, we note considerable contributions of
the climate variability modes which are comparable to the contributions of the
greenhouse gases and even exceed the latter. For longer intervals of about half
a century and greater, the contributions of greenhouse gases dominate at all
latitudes as follows from the present analysis of data for polar, middle and
tropical regions.",http://arxiv.org/abs/2112.01272v1
"Role of Information and ICTs as Determinants of Farmer's Adaptive
  Capacity to Climate Risk: An Empirical Study From Haryana, India",2021-08-22T16:00:06Z,"Priya Chetri, Upasna Sharma, P. Vigneswara Ilavarasan","Using the primary data collected for 463 farmers in six districts of Haryana,
India, the present study attempts to understand the constituents of farmer's
adaptive capacity at local level and how it can be enhanced. We use path
analysis technique using the lavaan package in RStudio to empirically test the
role of information. We find that information is a direct and significant
contributor to enhancing farmers' adaptive capacity. However, even with
exponential growth in use of technology, particularly information and
communication technologies (ICTs), small farmers still lack access to
information which hinders their capacity to respond to weather and climate
risks. Thus, understanding the mechanism that can facilitate exchange and use
of information by the farming community more effectively is important. We take
an ensemble view of ICTs operationalized using ICT ecosystem and find
significant interlinkages between information, technology and the ICT ecosystem
that facilitate learning and information exchange and therefore contribute to
enhancing farmers' adaptive capacity and building resilience to climate shocks.
We find that ICT ecosystem does facilitate access to information and also
mediate the effect of farmer's capability and willingness to use ICTs for
agricultural purposes. Development of sound ICT ecosystem is likely to help
farmers to better respond to changing climate in the future.",http://arxiv.org/abs/2108.09766v1
"Lagged teleconnections of climate variables identified via complex
  rotated Maximum Covariance Analysis",2021-05-10T18:58:08Z,"Niclas Rieger, Álvaro Corral, Estrella Olmedo, Antonio Turiel","A proper description of ocean-atmosphere interactions is key for a correct
understanding of climate evolution. The interplay among the different variables
acting over the climate is complex, often leading to correlations across long
spatial distances (teleconnections). In some occasions, those teleconnections
occur with quite significant temporal shifts that are fundamental for the
understanding of the underlying phenomena but which are poorly captured by
standard methods. Applying orthogonal decomposition such as Maximum Covariance
Analysis (MCA) to geophysical data sets allows to extract common dominant
patterns between two different variables, but generally suffers from (i) the
non-physical orthogonal constraint as well as (ii) the consideration of simple
correlations, whereby temporally offset signals are not detected. Here we
propose an extension, complex rotated MCA, to address both limitations. We
transform our signals using the Hilbert transform and perform the orthogonal
decomposition in complex space, allowing us to correctly correlate out-of-phase
signals. Subsequent Varimax rotation removes the orthogonal constraints,
leading to more physically meaningful modes of geophysical variability. As an
example of application, we have employed this method on sea surface temperature
and continental precipitation; our method successfully captures the temporal
and spatial interactions between these two variables, namely for (i) the
seasonal cycle, (ii) canonical ENSO, (iii) the global warming trend, (iv) the
Pacific Decadal Oscillation, (v) ENSO Modoki and finally (vi) the Atlantic
Meridional Mode. The complex rotated modes of MCA provide information on the
regional amplitude, and under certain conditions, the regional time lag between
changes on ocean temperature and land precipitation.",http://arxiv.org/abs/2105.04618v2
"Modeling the Combined Impact of Rainfall and Storm Tide on Coastal
  Cities under a Changing Climate: Transportation Infrastructure Impacts in
  Norfolk, Virginia USA as a Case Study",2021-08-26T19:51:44Z,"Yawen Shen, Navid Tahvildari, Mohamed M Morsy, Chris Huxley, T. Donna Chen, Jonathan L. Goodall","Low-lying coastal cities across the world are vulnerable to the combined
impact of rainfall and storm tide. However, existing approaches lack the
ability to model the combined effect of these flood mechanisms. Thus, to
increase flood resilience, modeling techniques to improve understanding and
prediction of the combined effect of these flood hazards are critical. To
address this need, this study presents a modeling system for assessing the
combined flood risk to coastal cities under changing climate conditions that
leverages ocean modeling with land surface modeling capable of resolving urban
drainage infrastructure within the city. The modeling approach is demonstrated
in quantifying the future impact on transportation infrastructure within
Norfolk, Virginia USA. A series of combined storms events are modeled for
current (2020) and projected future (2070) climate conditions. Results show
that pluvial flooding causes a larger interruption to the transportation
network compared to tidal flooding under current climate conditions. By 2070,
however, tidal flooding will be the dominant flooding mechanism with even
nuisance flooding expected to happen daily due to SLR. In 2070, nuisance
flooding is expected to cause a 4.6% total link close time (TLC), which is more
than two times that of a 50-year storm surge (1.8% TLC) in 2020. The coupled
model was compared with a widely used but physically simplistic bathtub method
to assess the difference resulting from the more complex modeling presented.
Results show that the bathtub method overestimated the flooded area near the
shoreline by 9.5% and 3.1% for a 10-year storm surge event in 2020 and 2070,
respectively, but underestimated flooded area in the inland region by 9.0% and
4.0% for the same events. The findings demonstrate the benefit of sophisticated
modeling methods in climate adaptive planning and policy in coastal
communities.",http://arxiv.org/abs/2108.12013v1
"Probing the timescale dependency of local and global variations in
  surface air temperature from climate simulations and reconstructions of the
  last millennia",2021-01-31T14:08:42Z,"Beatrice Ellerhoff, Kira Rehfeld","Earth's climate can be understood as a dynamical system that changes due to
external forcing and internal couplings. Essential climate variables, such as
surface air temperature, describe this dynamics. Our current interglacial, the
Holocene (11,700 yr ago to today), has been characterized by small variations
in global mean temperature prior to anthropogenic warming. However, the
mechanisms and spatiotemporal patterns of fluctuations around this mean, called
temperature variability, are poorly understood despite their socio-economic
relevance. Here, we examine discrepancies between temperature variability from
model simulations and paleoclimate reconstructions by categorizing the scaling
behavior of local and global surface air temperature on the timescale of years
to centuries. To this end, we contrast power spectral densities (PSD) and their
power-law scaling using simulated and observation-based temperature series of
the last 6000 yr. We further introduce the spectral gain to disentangle the
externally forced and internally generated variability as a function of
timescale. It is based on our estimate of the joint PSD of radiative forcing,
which exhibits a scale break around the period of 7 yr. We find that local
temperature series from paleoclimate reconstructions show a different scaling
behavior than simulated ones, with a tendency towards stronger persistence
(i.e., correlation between successive values within a time series) on periods
of 10 to 200 yr. Conversely, the PSD and spectral gain of global mean
temperature are consistent across data sets. Our results point to the
limitation of climate models to fully represent local temperature statistics
over decades to centuries. By highlighting the key characteristics of
temperature variability, we pave a way to better constrain possible changes in
temperature variability with global warming and assess future climate risks.",http://arxiv.org/abs/2102.00458v2
Heat Waves -- a hot topic in climate change research,2021-06-25T10:08:45Z,"Werner Marx, Robin Haunschild, Lutz Bornmann","Research on heat waves (periods of excessively hot weather, which may be
accompanied by high humidity) is a newly emerging research topic within the
field of climate change research with high relevance for the whole of society.
In this study, we analyzed the rapidly growing scientific literature dealing
with heat waves. No summarizing overview has been published on this literature
hitherto. We developed a suitable search query to retrieve the relevant
literature covered by the Web of Science (WoS) as complete as possible and to
exclude irrelevant literature (n = 8,011 papers). The time-evolution of the
publications shows that research dealing with heat waves is a highly dynamic
research topic, doubling within about 5 years. An analysis of the thematic
content reveals the most severe heat wave events within the recent decades
(1995 and 2003), the cities and countries/regions affected (United States,
Europe, and Australia), and the ecological and medical impacts (drought, urban
heat islands, excess hospital admissions, and mortality). Risk estimation and
future strategies for adaptation to hot weather are major political issues. We
identified 104 citation classics which include fundamental early works of
research on heat waves and more recent works (which are characterized by a
relatively strong connection to climate change).",http://arxiv.org/abs/2106.13537v2
"Impact of climate change on West Nile virus distribution in South
  America",2021-04-01T21:48:48Z,"Camila Lorenz, Thiago Salomao de Azevedo, Francisco Chiaravalloti-Neto","West Nile virus (WNV) is a vector-borne pathogen of global relevance and is
currently the most widely distributed flavivirus of encephalitis worldwide.
This virus infects birds, humans, horses, and other mammals, and its
transmission cycle occurs in urban and rural areas. Climate conditions have
direct and indirect impacts on vector abundance and virus dynamics within the
mosquito. The significance of environmental variables as drivers in WNV
epidemiology is increasing under the current climate change scenario. In this
study, we used a machine learning algorithm to model WNV distributions in South
America. Our model evaluated eight environmental variables (type of biome,
annual temperature, seasonality of temperature, daytime temperature variation,
thermal amplitude, seasonality of precipitation, annual rainfall, and
elevation) for their contribution to the occurrence of WNV since its
introduction in South America (2004). Our results showed that environmental
variables can directly alter the occurrence of WNV, with lower precipitation
and higher temperatures associated with increased virus incidence. High-risk
areas may be modified in the coming years, becoming more evident with high
greenhouse gas emission levels. Countries such as Bolivia and Paraguay will be
greatly affected, drastically changing their current WNV distribution. Several
Brazilian areas will also increase the likelihood of presenting WNV, mainly in
the Northeast and Midwest regions and the Pantanal biome. The Galapagos Islands
will also probably increase their geographic range suitable for WNV occurrence.
It is necessary to develop preventive policies to minimize potential WNV
infection in humans and enhance active epidemiological surveillance in birds,
humans, and other mammals before it becomes a more significant public health
problem in South America.",http://arxiv.org/abs/2104.00777v1
"Collaborating with communities: Citizen Science Flood Monitoring in
  Urban Informal Settlements",2021-12-14T02:59:36Z,"Erich Wolff, Matthew French, Noor Ilhamsyah, Mere Jane Sawailau, Diego Ramirez-Lovering","Concerns regarding the impacts of climate change on marginalised communities
in the Global South have led to calls for affected communities to be more
active as agents in the process of planning for climate change. While the value
of involving communities in risk management is increasingly accepted, the
development of appropriate tools to support community engagement in flood risk
management projects remains nascent. Using the Revitalising Informal
Settlements and their Environment (RISE) Program as a case study, the article
interrogates the potential of citizen science to include disadvantaged urban
communities in project-level flood risk reduction planning processes. This
project collected more than 5000 photos taken by 26 community members living in
13 informal settlements in Fiji and Indonesia between 2018 and 2020. The case
study documents the method used as well as the results achieved within this
2-year project. It discusses the method developed and implemented, outlines the
main results, and provides lessons learned for others embarking on citizen
science environmental monitoring projects. The case study indicates that the
engagement model and the technology used were key to the success of the
flood-monitoring project. The experiences with the practice of monitoring
floods in collaboration with communities in Fiji and Indonesia provide insights
into how similar projects could advance more participatory risk management
practices. The article identifies how this kind of approach can collect
valuable flood data while also promoting opportunities for local communities to
be heard in the arena of risk reduction and climate change adaptation.",http://arxiv.org/abs/2112.07128v1
A Bayesian Approach for Inferring Sea Ice Loads,2021-02-16T20:51:45Z,"Matthew Parno, Taylor Hodgdon, Brendan West, Devin O'Connor, Arnold Song","The Earth's climate is rapidly changing and some of the most drastic changes
can be seen in the Arctic, where sea ice extent has diminished considerably in
recent years. As the Arctic climate continues to change, gathering in situ sea
ice measurements is increasingly important for understanding the complex
evolution of the Arctic ice pack. To date, observations of ice stresses in the
Arctic have been spatially and temporally sparse. We propose a measurement
framework that would instrument existing sea ice buoys with strain gauges. This
measurement framework uses a Bayesian inference approach to infer ice loads
acting on the buoy from a set of strain gauge measurements. To test our
framework, strain measurements were collected from an experiment where a buoy
was frozen into ice that was subsequently compressed to simulate convergent sea
ice conditions. A linear elastic finite element model was used to describe the
response of the deformable buoy to mechanical loading, allowing us to link the
observed strain on the buoy interior to the applied load on the buoy exterior.
  The approach presented in this paper presents an instrumentation framework
that could use existing buoy platforms as in situ sensors of internal stresses
in the ice pack.",http://arxiv.org/abs/2102.08444v1
"Toward Foundation Models for Earth Monitoring: Proposal for a Climate
  Change Benchmark",2021-12-01T15:38:19Z,"Alexandre Lacoste, Evan David Sherwin, Hannah Kerner, Hamed Alemohammad, Björn Lütjens, Jeremy Irvin, David Dao, Alex Chang, Mehmet Gunturkun, Alexandre Drouin, Pau Rodriguez, David Vazquez","Recent progress in self-supervision shows that pre-training large neural
networks on vast amounts of unsupervised data can lead to impressive increases
in generalisation for downstream tasks. Such models, recently coined as
foundation models, have been transformational to the field of natural language
processing. While similar models have also been trained on large corpuses of
images, they are not well suited for remote sensing data. To stimulate the
development of foundation models for Earth monitoring, we propose to develop a
new benchmark comprised of a variety of downstream tasks related to climate
change. We believe that this can lead to substantial improvements in many
existing applications and facilitate the development of new applications. This
proposal is also a call for collaboration with the aim of developing a better
evaluation process to mitigate potential downsides of foundation models for
Earth monitoring.",http://arxiv.org/abs/2112.00570v1
"Tokenising behaviour change: optimising blockchain technology for
  sustainable transport interventions",2021-04-05T11:06:15Z,"Iain Barclay, Michael Cooper, Alun Preece, Omer Rana, Ian Taylor","Transport makes an impact across SDGs, encompassing climate change, health,
inequality and sustainability. It is also an area in which individuals are able
to make decisions which have potential to collectively contribute to
significant and wide-ranging benefits. Governments and authorities need
citizens to make changes towards adopting sustainable transport behaviours and
behaviour change interventions are being used as tools to foster changes in
travel choices, towards more sustainable modes. Blockchain technology has the
potential to bring new levels of scale to transport behaviour change
interventions, but a rigorous approach to token design is required. This paper
uses a survey of research projects and use cases to analyse current
applications of blockchain technology in transport behaviour change
interventions, and identifies barriers and limitations to achieving targeted
change at scale. The paper draws upon these findings to outline a research
agenda that brings a focus on correlating specific Behaviour Change Techniques
(BCTs) to token design, and defines processes for standardising token designs
in behaviour change tools. The paper further outlines architecture and
operational considerations for blockchain-based platforms in behaviour change
interventions, such that design choices do not compromise opportunities or
wider environmental goals.",http://arxiv.org/abs/2104.01852v1
Computing Research for the Climate Crisis,2021-08-12T18:59:12Z,"Nadya Bliss, Elizabeth Bradley, Claire Monteleoni","Climate change is an existential threat to the United States and the world.
Inevitably, computing will play a key role in mitigation, adaptation, and
resilience in response to this threat. The needs span all areas of computing,
from devices and architectures (e.g., low-power sensor systems for wildfire
monitoring) to algorithms (e.g., predicting impacts and evaluating mitigation),
and robotics (e.g., autonomous UAVs for monitoring and actuation) -- as well as
every level of the software stack, from data management systems and
energy-aware operating systems to hardware/software co-design. The goal of this
white paper is to highlight the role of computing research in addressing
climate change-induced challenges. To that end, we outline six key impact areas
in which these challenges will arise -- energy, environmental justice,
transportation, infrastructure, agriculture, and environmental monitoring and
forecasting -- then identify specific ways in which computing research can help
address the associated problems. These impact areas will create a driving force
behind, and enable, cross-cutting, system-level innovation. We further break
down this information into four broad areas of computing research: devices &
architectures, software, algorithms/AI/robotics, and sociotechnical computing.
  Additional contributions by: Ilkay Altintas (San Diego Supercomputer Center),
Kyri Baker (University of Colorado Boulder), Sujata Banerjee (VMware), Andrew
A. Chien (University of Chicago), Thomas Dietterich (Oregon State University),
Ian Foster (Argonne National Labs), Carla P. Gomes (Cornell University),
Chandra Krintz (University of California, Santa Barbara), Jessica Seddon (World
Resources Institute), and Regan Zane (Utah State University).",http://arxiv.org/abs/2108.05926v2
"Nonstationary seasonal model for daily mean temperature distribution
  bridging bulk and tails",2021-10-19T15:18:00Z,"Mitchell Krock, Julie Bessac, Michael L. Stein, Adam H. Monahan","In traditional extreme value analysis, the bulk of the data is ignored, and
only the tails of the distribution are used for inference. Extreme observations
are specified as values that exceed a threshold or as maximum values over
distinct blocks of time, and subsequent estimation procedures are motivated by
asymptotic theory for extremes of random processes. For environmental data,
nonstationary behavior in the bulk of the distribution, such as seasonality or
climate change, will also be observed in the tails. To accurately model such
nonstationarity, it seems natural to use the entire dataset rather than just
the most extreme values. It is also common to observe different types of
nonstationarity in each tail of a distribution. Most work on extremes only
focuses on one tail of a distribution, but for temperature, both tails are of
interest. This paper builds on a recently proposed parametric model for the
entire probability distribution that has flexible behavior in both tails. We
apply an extension of this model to historical records of daily mean
temperature at several locations across the United States with different
climates and local conditions. We highlight the ability of the method to
quantify changes in the bulk and tails across the year over the past decades
and under different geographic and climatic conditions. The proposed model
shows good performance when compared to several benchmark models that are
typically used in extreme value analysis of temperature.",http://arxiv.org/abs/2110.10046v1
"A high-resolution gridded inventory of coal mine methane emissions for
  India and Australia",2021-07-21T19:27:56Z,"Pankaj Sadavarte, Sudhanshu Pandey, Joannes D. Maasakkers, Hugo Denier van der Gon, Sander Houweling, Ilse Aben","Coal mines are globally an important source of methane and also one of the
largest point sources of methane. We present a high-resolution 0.1deg x 0.1deg
bottom-up gridded emission inventory for methane emissions from coal mines in
India and Australia, which are among the top five coal-producing countries in
2018. The aim is to reduce the uncertainty in local coal mine methane emissions
and to improve the spatial localization to support monitoring and mitigation of
these emissions. For India, we improve the spatial allocation of the emissions
by identifying the exact location of surface and underground coal mines and we
use a tier-2 Intergovernmental Panel on Climate Change (IPCC) methodology to
estimate the emissions from each coal mine using country-specific emission
factors. For Australia, we estimate the emission for each coal mine by
distributing the state-level reported total emissions using proxies of coal
production and the coal basin-specific gas content profile of underground
mines. Comparison of our total coal mine methane emission from India with
existing global inventories showed our estimates are about a factor 3 lower,
but well within the range of the national Indian estimate reported to the
United Nations framework convention on climate change (UNFCCC). For both
countries, the new spatial distribution of the emissions shows a large
difference from the global inventories. Our improved emissions dataset will be
useful for air quality or climate modeling and while assessing the satellite
methane observations.",http://arxiv.org/abs/2107.10317v2
"Quantile based modelling of diurnal temperature range with the
  five-parameter lambda distribution",2021-09-23T07:22:00Z,"Silius M. Vandeskog, Thordis L. Thorarinsdottir, Ingelin Steinsland, Finn Lindgren","Diurnal temperature range is an important variable in climate science that
can provide information regarding climate variability and climate change.
Changes in diurnal temperature range can have implications for hydrology, human
health and ecology, among others. Yet, the statistical literature on modelling
diurnal temperature range is lacking. In this paper we propose to model the
distribution of diurnal temperature range using the five-parameter lambda (FPL)
distribution. Additionally, in order to model diurnal temperature range with
explanatory variables, we propose a distributional quantile regression model
that combines quantile regression with marginal modelling using the FPL
distribution. Inference is performed using the method of quantiles. The models
are fitted to 30 years of daily observations of diurnal temperature range from
112 weather stations in the southern part of Norway. The flexible FPL
distribution shows great promise as a model for diurnal temperature range, and
performs well against competing models. The distributional quantile regression
model is fitted to diurnal temperature range data using geographic, orographic
and climatological explanatory variables. It performs well and captures much of
the spatial variation in the distribution of diurnal temperature range in
Norway.",http://arxiv.org/abs/2109.11180v2
"Shallow geothermal energy potential for heating and cooling of buildings
  with regeneration under climate change scenarios",2021-12-02T12:55:56Z,"Alina Walch, Xiang Li, Jonathan Chambers, Nahid Mohajeri, Selin Yilmaz, Martin Patel, Jean-Louis Scartezzini","Shallow ground-source heat pumps (GSHPs) are a promising technology for
contributing to the decarbonisation of the energy sector. In heating-dominated
climates, the combined use of GSHPs for both heating and cooling increases
their technical potential, defined as the maximum energy that can be exchanged
with the ground, as the re-injection of excess heat from space cooling leads to
a seasonal regeneration of the ground. This paper proposes a new approach to
quantify the technical potential of GSHPs, accounting for effects of seasonal
regeneration, and to estimate the useful energy to supply building energy
demands at regional scale. The useful energy is obtained for direct heat
exchange and for district heating and cooling (DHC) under several scenarios for
climate change and market penetration levels of cooling systems. The case study
in western Switzerland suggests that seasonal regeneration allows for annual
maximum heat extraction densities above 300 kWh/m$^2$ at heat injection
densities above 330 kWh/m$^2$. Results also show that GSHPs may cover up to 55%
of heating demand while covering 57% of service-sector cooling demand for
individual GSHPs in 2050, which increases to around 85% with DHC. The
regional-scale results may serve to inform decision making on strategic areas
for installing GSHPs.",http://arxiv.org/abs/2112.01183v1
"A Zero-Radiation Pressure Sunshade for Supporting Climate Change
  Mitigation",2021-12-27T13:25:09Z,"Olivia Borgue, Andreas M. Hein","Limiting climate change to within the 2 {\deg}C limit requires net zero
emissions of CO2 by 2050. However, the window of opportunity is closing fast.
Geoengineering as the intentional and large-scale manipulation of the
environment and in particular the climate is increasingly discussed as a
complement to ongoing mitigation efforts. As a particular geoengineering
approach, space-based geoengineering blocks or dissipates a fraction of
incoming sunlight via many occulting membranes, located close to the Sun-Earth
Lagrange 1 point. However, the mass of the proposed sunshades, around
$10^7$-$10^8$ tons, and their associated cost render them about $10^3$ times
more costly than terrestrial alternatives. In this article, we propose a novel
sunshade concept, which is between $10^2$ to $10^3$ times lighter than the
lightest existing sunshade concepts. This is achieved via a net zero-radiation
pressure design, based on the use of diffractive metamaterials, removing one of
the major constraints to reducing sunshade mass. The whole sunshade system has
a total mass of approximately $6.2 \times 10^5$ tons and its deployment
requires between $10^2$ to $10^3$ annual launches during a ten-year period. The
achieved cost reduction might render space-based geoengineering competitive to
terrestrial geoengineering approaches.",http://arxiv.org/abs/2112.13652v3
Towards Indirect Top-Down Road Transport Emissions Estimation,2021-03-16T03:30:53Z,"Ryan Mukherjee, Derek Rollend, Gordon Christie, Armin Hadzic, Sally Matson, Anshu Saksena, Marisa Hughes","Road transportation is one of the largest sectors of greenhouse gas (GHG)
emissions affecting climate change. Tackling climate change as a global
community will require new capabilities to measure and inventory road transport
emissions. However, the large scale and distributed nature of vehicle emissions
make this sector especially challenging for existing inventory methods. In this
work, we develop machine learning models that use satellite imagery to perform
indirect top-down estimation of road transport emissions. Our initial
experiments focus on the United States, where a bottom-up inventory was
available for training our models. We achieved a mean absolute error (MAE) of
39.5 kg CO$_{2}$ of annual road transport emissions, calculated on a
pixel-by-pixel (100 m$^{2}$) basis in Sentinel-2 imagery. We also discuss key
model assumptions and challenges that need to be addressed to develop models
capable of generalizing to global geography. We believe this work is the first
published approach for automated indirect top-down estimation of road transport
sector emissions using visual imagery and represents a critical step towards
scalable, global, near-real-time road transportation emissions inventories that
are measured both independently and objectively.",http://arxiv.org/abs/2103.08829v1
"SALT: Sea lice Adaptive Lattice Tracking -- An Unsupervised Approach to
  Generate an Improved Ocean Model",2021-06-24T17:29:42Z,"Ju An Park, Vikram Voleti, Kathryn E. Thomas, Alexander Wong, Jason L. Deglint","Warming oceans due to climate change are leading to increased numbers of
ectoparasitic copepods, also known as sea lice, which can cause significant
ecological loss to wild salmon populations and major economic loss to
aquaculture sites. The main transport mechanism driving the spread of sea lice
populations are near-surface ocean currents. Present strategies to estimate the
distribution of sea lice larvae are computationally complex and limit
full-scale analysis. Motivated to address this challenge, we propose SALT: Sea
lice Adaptive Lattice Tracking approach for efficient estimation of sea lice
dispersion and distribution in space and time. Specifically, an adaptive
spatial mesh is generated by merging nodes in the lattice graph of the Ocean
Model based on local ocean properties, thus enabling highly efficient graph
representation. SALT demonstrates improved efficiency while maintaining
consistent results with the standard method, using near-surface current data
for Hardangerfjord, Norway. The proposed SALT technique shows promise for
enhancing proactive aquaculture management through predictive modelling of sea
lice infestation pressure maps in a changing climate.",http://arxiv.org/abs/2106.13202v1
Power Grid Cascading Failure Mitigation by Reinforcement Learning,2021-08-23T21:41:44Z,Yongli Zhu,"This paper proposes a cascading failure mitigation strategy based on
Reinforcement Learning (RL). The motivation of the Multi-Stage Cascading
Failure (MSCF) problem and its connection with the challenge of climate change
are introduced. The bottom-level corrective control of the MCSF problem is
formulated based on DCOPF (Direct Current Optimal Power Flow). Then, to
mitigate the MSCF issue by a high-level RL-based strategy, physics-informed
reward, action, and state are devised. Besides, both shallow and deep neural
network architectures are tested. Experiments on the IEEE 118-bus system by the
proposed mitigation strategy demonstrate a promising performance in reducing
system collapses.",http://arxiv.org/abs/2108.10424v1
"Estimation of Air Pollution with Remote Sensing Data: Revealing
  Greenhouse Gas Emissions from Space",2021-08-31T14:58:04Z,"Linus Scheibenreif, Michael Mommert, Damian Borth","Air pollution is a major driver of climate change. Anthropogenic emissions
from the burning of fossil fuels for transportation and power generation emit
large amounts of problematic air pollutants, including Greenhouse Gases (GHGs).
Despite the importance of limiting GHG emissions to mitigate climate change,
detailed information about the spatial and temporal distribution of GHG and
other air pollutants is difficult to obtain. Existing models for surface-level
air pollution rely on extensive land-use datasets which are often locally
restricted and temporally static. This work proposes a deep learning approach
for the prediction of ambient air pollution that only relies on remote sensing
data that is globally available and frequently updated. Combining optical
satellite imagery with satellite-based atmospheric column density air pollution
measurements enables the scaling of air pollution estimates (in this case
NO$_2$) to high spatial resolution (up to $\sim$10m) at arbitrary locations and
adds a temporal component to these estimates. The proposed model performs with
high accuracy when evaluated against air quality measurements from ground
stations (mean absolute error $<$6$~\mu g/m^3$). Our results enable the
identification and temporal monitoring of major sources of air pollution and
GHGs.",http://arxiv.org/abs/2108.13902v1
Assessment of Neural Networks for Stream-Water-Temperature Prediction,2021-10-08T17:04:42Z,"Stefanie Mohr, Konstantina Drainas, Juergen Geist","Climate change results in altered air and water temperatures. Increases
affect physicochemical properties, such as oxygen concentration, and can shift
species distribution and survival, with consequences for ecosystem functioning
and services. These ecosystem services have integral value for humankind and
are forecasted to alter under climate warming. A mechanistic understanding of
the drivers and magnitude of expected changes is essential in identifying
system resilience and mitigation measures. In this work, we present a selection
of state-of-the-art Neural Networks (NN) for the prediction of water
temperatures in six streams in Germany. We show that the use of methods that
compare observed and predicted values, exemplified with the Root Mean Square
Error (RMSE), is not sufficient for their assessment. Hence we introduce
additional analysis methods for our models to complement the state-of-the-art
metrics. These analyses evaluate the NN's robustness, possible maximal and
minimal values, and the impact of single input parameters on the output. We
thus contribute to understanding the processes within the NN and help
applicants choose architectures and input parameters for reliable water
temperature prediction models.",http://arxiv.org/abs/2110.04254v1
"Rotation Equivariant Deforestation Segmentation and Driver
  Classification",2021-10-25T16:49:46Z,"Joshua Mitton, Roderick Murray-Smith","Deforestation has become a significant contributing factor to climate change
and, due to this, both classifying the drivers and predicting segmentation maps
of deforestation has attracted significant interest. In this work, we develop a
rotation equivariant convolutional neural network model to predict the drivers
and generate segmentation maps of deforestation events from Landsat 8 satellite
images. This outperforms previous methods in classifying the drivers and
predicting the segmentation map of deforestation, offering a 9% improvement in
classification accuracy and a 7% improvement in segmentation map accuracy. In
addition, this method predicts stable segmentation maps under rotation of the
input image, which ensures that predicted regions of deforestation are not
dependent upon the rotational orientation of the satellite.",http://arxiv.org/abs/2110.13097v2
"Synchronous Glacial Cycles in a Nonsmooth Conceptual Climate Model with
  Asymmetric Hemispheres",2021-01-05T18:50:48Z,"Alice Nadeau, James Walsh, Esther Widiasih","We present a new conceptual model of the Earth's glacial-interglacial cycles,
one leading to governing equations for which the vector field has a hyperplane
of discontinuities. This work extends the classic Budyko- and Sellers-type
conceptual energy balance models of temperature-albedo feedback by removing the
standard assumption of planetary symmetry about the equator. The dynamics of
separate Northern and Southern Hemisphere ice caps are coupled to an equation
representing the annual global mean surface temperature. The system has a
discontinuous switching mechanism based on mass balance principles for the
Northern Hemisphere ice sheet. We show the associated Filippov system admits a
unique nonsmooth and attracting limit cycle that represents the cycling between
glacial and interglacial states. Due to the vastly different time scales
involved, the model presents a nonsmooth geometric perturbation problem, for
which we use ad hoc mathematical techniques to produce the periodic orbit. We
find climatic changes in the Northern Hemisphere drive synchronous changes in
the Southern Hemisphere, as is observed for the Earth on orbital time scales.",http://arxiv.org/abs/2101.01707v1
"DeepWaste: Applying Deep Learning to Waste Classification for a
  Sustainable Planet",2021-01-15T04:06:25Z,Yash Narayan,"Accurate waste disposal, at the point of disposal, is crucial to fighting
climate change. When materials that could be recycled or composted get diverted
into landfills, they cause the emission of potent greenhouse gases such as
methane. Current attempts to reduce erroneous waste disposal are expensive,
inaccurate, and confusing. In this work, we propose DeepWaste, an easy-to-use
mobile app, that utilizes highly optimized deep learning techniques to provide
users instantaneous waste classification into trash, recycling, and compost. We
experiment with several convolution neural network architectures to detect and
classify waste items. Our best model, a deep learning residual neural network
with 50 layers, achieves an average precision of 0.881 on the test set. We
demonstrate the performance and efficiency of our app on a set of real-world
images.",http://arxiv.org/abs/2101.05960v1
Insurance Business and Sustainable Development,2021-02-04T13:54:47Z,"Dietmar Pfeifer, Vivien Langen","In this study, we will discuss recent developments in risk management of the
global financial and insurance business with respect to sustainable
development. So far climate change aspects have been the dominant aspect in
managing sustainability risks and opportunities, accompanied by the development
of several legislative initiatives triggered by supervisory authorities.
However, a sole concentration on these aspects misses out other important
economic and social facets of sustainable development goals formulated by the
UN. Such aspects have very recently come into the focus of the European
Committee concerning the Solvency II project for the European insurance
industry. Clearly the new legislative expectations can be better handled by
larger insurance companies and holdings than by small- and medium-sized mutual
insurance companies which are numerous in central Europe, due to their historic
development starting in the late medieval ages and early modern times. We
therefore also concentrate on strategies within the risk management of such
small- and medium-sized enterprises that can be achieved without much effort,
in particular those that are not directly related to climate change.",http://arxiv.org/abs/2102.02612v1
"How do climate change skeptics engage with opposing views? Understanding
  mechanisms of social identity and cognitive dissonance in an online forum",2021-02-12T13:39:00Z,"Lisa Oswald, Jonathan Bright","Does engagement with opposing views help break down ideological `echo
chambers'; or does it backfire and reinforce them? This question remains
critical as academics, policymakers and activists grapple with the question of
how to regulate political discussion on social media. In this study, we
contribute to the debate by examining the impact of opposing views within a
major climate change skeptic online community on Reddit. A large sample of
posts (N = 3000) was manually coded as either dissonant or consonant which
allowed the automated classification of the full dataset of more than 50,000
posts, with codes inferred from linked websites. We find that ideologically
dissonant submissions act as a stimulant to activity in the community: they
received more attention (comments) than consonant submissions, even though they
received lower scores through up-voting and down-voting. Users who engaged with
dissonant submissions were also more likely to return to the forum. Consistent
with identity theory, confrontation with opposing views triggered activity in
the forum, particularly among users that are highly engaged with the community.
In light of the findings, theory of social identity and echo chambers is
discussed and enhanced.",http://arxiv.org/abs/2102.06516v1
"Detection of Multidecadal Changes in Vegetation Dynamics and Association
  with Intra-annual Climate Variability in the Columbia River Basin",2021-05-19T00:32:58Z,"Andrew B Whetten, Hannah Demler","Leaf Area index is widely used metric for the assessment of vegetation
dynamics and can be used to assess the impact of regional/local climate
conditions. The underlying continuity of high resolution spatio-temporal
phenological processes in the presence of extensive missing values poses a
number of challenges in the detection of changes at a local and regional level.
The feasibility of functional data analysis methods were evaluated to improve
the exploration of such data. In this paper, an investigation of multidecadal
variation of leaf area index (LAI) is conducted in the Columbia Watershed, as
detected by NOAA AVHRR satellite imaging, and its inter- and intra-annual
correlation with maximum temperature and precipitation using the ERA-Interim
Reanalysis from 1996 to 2017. A functional cluster analysis model was
implemented to identify regions in the Columbia Watershed that exhibit similar
long-term greening trends. Across these several regions, the primary source of
annual LAI variation is a trend toward seasonally earlier and higher recordings
of regional average maximum LAI. Further exploratory analysis reveals that
although strongly correlated to LAI, maximum temperature and precipitation do
not exhibit clear longitudinal trends.",http://arxiv.org/abs/2105.08864v1
"RtFPS: An Interactive Map that Visualizes and Predicts Wildfires in the
  US",2021-05-23T08:07:01Z,"Yang Li, Hermawan Mulyono, Ying Chen, Zhiyin Lu, Desmond Chan","Climate change has largely impacted our daily lives. As one of its
consequences, we are experiencing more wildfires. In the year 2020, wildfires
burned a record number of 8,888,297 acres in the US. To awaken people's
attention to climate change, and to visualize the current risk of wildfires, We
developed RtFPS, ""Real-Time Fire Prediction System"". It provides a real-time
prediction visualization of wildfire risk at specific locations base on a
Machine Learning model. It also provides interactive map features that show the
historical wildfire events with environmental info.",http://arxiv.org/abs/2105.10880v2
Urban Tree Species Classification Using Aerial Imagery,2021-07-07T12:30:22Z,"Emily Waters, Mahdi Maktabdar Oghaz, Lakshmi Babu Saheer","Urban trees help regulate temperature, reduce energy consumption, improve
urban air quality, reduce wind speeds, and mitigating the urban heat island
effect. Urban trees also play a key role in climate change mitigation and
global warming by capturing and storing atmospheric carbon-dioxide which is the
largest contributor to greenhouse gases. Automated tree detection and species
classification using aerial imagery can be a powerful tool for sustainable
forest and urban tree management. Hence, This study first offers a pipeline for
generating labelled dataset of urban trees using Google Map's aerial images and
then investigates how state of the art deep Convolutional Neural Network models
such as VGG and ResNet handle the classification problem of urban tree aerial
images under different parameters. Experimental results show our best model
achieves an average accuracy of 60% over 6 tree species.",http://arxiv.org/abs/2107.03182v1
"IowaRain: A Statewide Rain Event Dataset Based on Weather Radars and
  Quantitative Precipitation Estimation",2021-07-07T18:30:38Z,"Muhammed Sit, Bong-Chul Seo, Ibrahim Demir","Effective environmental planning and management to address climate change
could be achieved through extensive environmental modeling with machine
learning and conventional physical models. In order to develop and improve
these models, practitioners and researchers need comprehensive benchmark
datasets that are prepared and processed with environmental expertise that they
can rely on. This study presents an extensive dataset of rainfall events for
the state of Iowa (2016-2019) acquired from the National Weather Service Next
Generation Weather Radar (NEXRAD) system and processed by a quantitative
precipitation estimation system. The dataset presented in this study could be
used for better disaster monitoring, response and recovery by paving the way
for both predictive and prescriptive modeling.",http://arxiv.org/abs/2107.03432v1
"A comparative study of stochastic and deep generative models for
  multisite precipitation synthesis",2021-07-16T18:35:24Z,"Jorge Guevara, Dario Borges, Campbell Watson, Bianca Zadrozny","Future climate change scenarios are usually hypothesized using simulations
from weather generators. However, there only a few works comparing and
evaluating promising deep learning models for weather generation against
classical approaches. This study shows preliminary results making such
evaluations for the multisite precipitation synthesis task. We compared two
open-source weather generators: IBMWeathergen (an extension of the Weathergen
library) and RGeneratePrec, and two deep generative models: GAN and VAE, on a
variety of metrics. Our preliminary results can serve as a guide for improving
the design of deep learning architectures and algorithms for the multisite
precipitation synthesis task.",http://arxiv.org/abs/2107.08074v1
Deep Learning Based Reconstruction of Total Solar Irradiance,2021-07-23T06:33:37Z,"Yasser Abduallah, Jason T. L. Wang, Yucong Shen, Khalid A. Alobaid, Serena Criscuoli, Haimin Wang","The Earth's primary source of energy is the radiant energy generated by the
Sun, which is referred to as solar irradiance, or total solar irradiance (TSI)
when all of the radiation is measured. A minor change in the solar irradiance
can have a significant impact on the Earth's climate and atmosphere. As a
result, studying and measuring solar irradiance is crucial in understanding
climate changes and solar variability. Several methods have been developed to
reconstruct total solar irradiance for long and short periods of time; however,
they are physics-based and rely on the availability of data, which does not go
beyond 9,000 years. In this paper we propose a new method, called TSInet, to
reconstruct total solar irradiance by deep learning for short and long periods
of time that span beyond the physical models' data availability. On the data
that are available, our method agrees well with the state-of-the-art
physics-based reconstruction models. To our knowledge, this is the first time
that deep learning has been used to reconstruct total solar irradiance for more
than 9,000 years.",http://arxiv.org/abs/2107.11042v1
"An awareness-based model to minimize the environmental damage of the
  internet usage: A Longitudinal Study",2021-10-27T00:32:04Z,"Ayodhya Wathuge, Darshana Sedera","The record-breaking increase of internet usage in 2020 with the spread of the
COVID-19 pandemic has made us think about the alarming consequences of it in
the aspect of climate change. As countries go into lockdown the use of the
internet to perform tasks remotely has increased in record numbers. As per the
trend and at times addictive nature of its usage, it is unlikely that the usage
of the internet will decrease in the future reducing its current contribution
to climate change. Considering the sustainability perspective, this study
investigates whether the pervasive nature of internet usage could be reduced by
simply inducing awareness. A population-based survey experiment comprising of
326 respondents was employed to investigate if awareness alone could reduce
individual internet usage.",http://arxiv.org/abs/2111.04453v1
NoFADE: Analyzing Diminishing Returns on CO2 Investment,2021-11-28T05:48:48Z,"Andre Fu, Justin Tran, Andy Xie, Jonathan Spraggett, Elisa Ding, Chang-Won Lee, Kanav Singla, Mahdi S. Hosseini, Konstantinos N. Plataniotis","Climate change continues to be a pressing issue that currently affects
society at-large. It is important that we as a society, including the Computer
Vision (CV) community take steps to limit our impact on the environment. In
this paper, we (a) analyze the effect of diminishing returns on CV methods, and
(b) propose a \textit{``NoFADE''}: a novel entropy-based metric to quantify
model--dataset--complexity relationships. We show that some CV tasks are
reaching saturation, while others are almost fully saturated. In this light,
NoFADE allows the CV community to compare models and datasets on a similar
basis, establishing an agnostic platform.",http://arxiv.org/abs/2111.14059v1
"Prediction of Household-level Heat-Consumption using PSO enhanced SVR
  Model",2021-12-03T13:46:16Z,"Satyaki Chatterjee, Siming Bayer, Andreas Maier","In combating climate change, an effective demand-based energy supply
operation of the district energy system (DES) for heating or cooling is
indispensable. As a consequence, an accurate forecast of heat consumption on
the consumer side poses an important first step towards an optimal energy
supply. However, due to the non-linearity and non-stationarity of heat
consumption data, the prediction of the thermal energy demand of DES remains
challenging. In this work, we propose a forecasting framework for thermal
energy consumption within a district heating system (DHS) based on kernel
Support Vector Regression (kSVR) using real-world smart meter data. Particle
Swarm Optimization (PSO) is employed to find the optimal hyper-parameter for
the kSVR model which leads to the superiority of the proposed methods when
compared to a state-of-the-art ARIMA model. The average MAPE is reduced to
2.07% and 2.64% for the individual meter-specific forecasting and for
forecasting of societal consumption, respectively.",http://arxiv.org/abs/2112.01908v1
"A short review and discussion about the limiting factors, which can hold
  back wind and photovoltaic power plants from its presently exponential growth",2021-11-19T00:17:02Z,"Manfred G. Kratzenberg, Hans Helmut Zürn, Ricardo Rüther","The present nearly exponential growth of the cumulative installation power of
wind and photovoltaic power plants is very promising in the context of a rapid
reduction of the emission of CO2, which can lead to a swift mitigation climate
change if this growth behavior is maintained in the future. In this review we
identify a set of ten limiting factors that can restrain, or halt back, an
exponential growth of these variable renewable power plants (VREs) in the
future. If the exponential growth slows down to a linear growth, such a case
would extent considerably the time to reduce the CO2 emissions and the related
mitigation of climate change. A scenario that would result to a much higher
risk of a future continuation of the economic grow and thrive of the global
economy and human society. We argue that if these limiting factors are
adequately addressed to an exponential expansion VRE power plants is feasible
and can result in the nearly complete avoidance of CO2 emissions as related to
energy generation and consumption in 2030.",http://arxiv.org/abs/2112.10678v1
"Deep Learning and Earth Observation to Support the Sustainable
  Development Goals",2021-12-21T17:11:07Z,"Claudio Persello, Jan Dirk Wegner, Ronny Hänsch, Devis Tuia, Pedram Ghamisi, Mila Koeva, Gustau Camps-Valls","The synergistic combination of deep learning models and Earth observation
promises significant advances to support the sustainable development goals
(SDGs). New developments and a plethora of applications are already changing
the way humanity will face the living planet challenges. This paper reviews
current deep learning approaches for Earth observation data, along with their
application towards monitoring and achieving the SDGs most impacted by the
rapid development of deep learning in Earth observation. We systematically
review case studies to 1) achieve zero hunger, 2) sustainable cities, 3)
deliver tenure security, 4) mitigate and adapt to climate change, and 5)
preserve biodiversity. Important societal, economic and environmental
implications are concerned. Exciting times ahead are coming where algorithms
and Earth data can help in our endeavor to address the climate crisis and
support more sustainable development.",http://arxiv.org/abs/2112.11367v1
"Modeling the Regional Effects of Climate Change on Future Urban Ozone
  Air Quality in Tehran, Iran",2021-09-10T03:21:33Z,"Ehsan Mosadegh, Khosro Ashrafi, Majid Shafiepour Motlagh, Iman Babaeian","Quantifying the impact of climate change on future air quality is a
challenging subject in air quality studies. An ANN model is employed to
simulate hourly O3 concentrations. The model is developed based on hourly
monitored values of temperature, solar radiation, nitrogen monoxide, and
nitrogen dioxide which are monitored during summers (June, July, and August) of
2009-2012 at urban air quality stations in Tehran, Iran. Climate projections by
HadCM3 GCM over the study area, driven by IPCC SRES A1B, A2, and B1 emission
scenarios, are downscaled by LARS-WG5 model over the periods of 2015-2039 and
2040-2064. The projections are calculated by assuming that current emissions
conditions of O3 precursors remain constant in the future. The employed O3
metrics include the number of days exceeding one-hour (1-hr) (120 ppb) and
eight-hour (8-hr) (75 ppb) O3 standards and the number of days exceeding 8-hr
Air Quality Index (AQI). The projected increases in solar radiation and
decreases in precipitation in future summers along with summertime daily
maximum temperature rise of about 1.2 and 3 celsius in the first and second
climate periods respectively are some indications of more favorable conditions
for O3 formation over the study area in the future. Based on pollution
conditions of the violation-free summer of 2012, the summertime exceedance days
of 8-hr O3 standard are projected to increase in the future by about 4.2 days
in the short term and about 12.3 days in the mid-term. Similarly, based on
pollution conditions of the polluted summer of 2010 with 58 O3 exceedance days,
this metric is projected to increase about 4.5 days in the short term and about
14.1 days in the mid-term. Moreover, the number of Unhealthy and Very Unhealthy
days in 8-hr AQI is also projected to increase based on pollution conditions of
both summers.",http://arxiv.org/abs/2109.04644v2
"Idealized 2D Cloud-Resolving Simulations for Tidally Locked Habitable
  Planets",2021-08-09T16:13:17Z,"Qiyu Song, Jun Yang, Hang Luo, Cheng Li, Shizuo Fu","Cloud is critical for planetary climate and habitability, but it is also one
of the most challenging parts of studying planets in and beyond the solar
system. Here we use a cloud-resolving model (CRM) with high resolution (2 km)
in a two-dimensional (2D) configuration to simulate the clouds and circulation
on tidally locked aqua-planets. We find that the substellar area is covered by
deep convective clouds, the nightside is dominated by low-level clouds, and
these two are linked by a global-scale Walker circulation. We further find that
a uniform surface warming causes the substellar cloud width to decrease, but a
reduction in day-night surface temperature contrast or an increase in longwave
radiative cooling rate causes the substellar cloud width to increase. These
relationships can be roughly interpreted based on simple thermodynamic
theories. Comparing the results between CRM and global 3D general circulation
model (GCM), we find that they show qualitatively consistent results, including
the Walker circulation, the substellar clouds, and the responses of the
substellar ascending area and strength to changes in surface temperature or in
its zonal contrast. But, large quantitative differences exist, such as the
magnitude of cloud water path, the cloud width, and their responses to external
forcings. These results increase our confidence in using GCMs for modeling
exoplanetary climates, although large quantitative uncertainties should always
exist. Future work is required to use 3D CRM(s) with realistic radiative
transfer and with the Coriolis force to examine the clouds and climate of
tidally locked planets.",http://arxiv.org/abs/2108.04143v2
"A multispecies pseudoadiabat for simulating condensable-rich exoplanet
  atmospheres",2021-08-29T20:02:52Z,"R. J. Graham, Tim Lichtenberg, Ryan Boukrouche, Ray Pierrehumbert","Central stages in the evolution of rocky, potentially habitable planets may
play out under atmospheric conditions with a large inventory of non-dilute
condensable components. Variations in condensate retention and accompanying
changes in local lapse rate may substantially affect planetary climate and
surface conditions, but there is currently no general theory to effectively
describe such atmospheres. In this article, expanding on the work by Li et al.
(2018), we generalize the single-component moist pseudoadiabat derivation in
Pierrehumbert (2010) to allow for multiple condensing components of arbitrary
diluteness and retained condensate fraction. The introduction of a freely
tunable retained condensate fraction allows for a flexible, self-consistent
treatment of atmospheres with non-dilute condensable components. To test the
pseudoadiabat's capabilities for simulating a diverse range of climates, we
apply the formula to planetary atmospheres with compositions, surface
pressures, and temperatures representing important stages with condensable-rich
atmospheres in the evolution of terrestrial planets: a magma ocean planet in a
runaway greenhouse state; a post-impact, late veneer-analogue planet with a
complex atmospheric composition; and an Archean Earth-like planet near the
outer edge of the classical circumstellar habitable zone. We find that
variations in the retention of multiple non-dilute condensable species can
significantly affect the lapse rate and in turn outgoing radiation and the
spectral signatures of planetary atmospheres. The presented formulation allows
for a more comprehensive treatment of the climate evolution of rocky exoplanets
and early Earth analogues.",http://arxiv.org/abs/2108.12902v1
Towards fully ab initio simulation of atmospheric aerosol nucleation,2021-07-10T09:43:38Z,"Shuai Jiang, Yi-Rong Liu, Teng Huang, Ya-Juan Feng, Chun-Yu Wang, Zhong-Quan Wang, Wei Huang","Atmospheric aerosol nucleation contributes to more than half of cloud
condensation nuclei globally. The emissions, properties and concentrations of
atmospheric aerosols or aerosol precursors could respond significantly to
climate change. Despite the importance for climate, the detailed nucleation
mechanisms are still poorly understood. The ultimate goal of theoretical
understanding aerosol nucleation is to simulate nucleation in ambient
condition, hindered by lack of accurate reactive force field. Here we propose
the reactive force field for nucleation systems with good size scalability
based on deep neural network. The huge computational costs from direct
molecular dynamics in ambient conditions are surmounted by bridging the
simulation in the limited box with cluster kinetics, facilitating the aerosol
nucleation simulation to be fully ab initio. We found that the acid-base
formation rates previously based on hard sphere collision rate constants tend
to be underestimated up to several times. These findings show that the widely
recognized acid-base nucleation observed in the CLOUD (Cosmics Leaving OUtdoor
Droplets) chamber experiments, pristine and polluted environments should be
revisited to considering the contribution of collision enhancement. Besides,
the framework here is transferable to other nucleation systems, potentially
boosting the nucleation parameterizations accuracy generally to effectively
advance the climate model predictions reliability.",http://arxiv.org/abs/2107.04802v2
Simulating cloud-aerosol interactions made by ship emissions,2021-11-09T19:02:32Z,"Lekha Patel, Lyndsay Shand","Satellite imagery can detect temporary cloud trails or ship tracks formed
from aerosols emitted from large ships traversing our oceans, a phenomenon that
global climate models cannot directly reproduce. Ship tracks are observable
examples of marine cloud brightening, a potential solar climate intervention
that shows promise in helping combat climate change. Whether or not a ship's
emission path visibly impacts the clouds above and how long a ship track
visibly persists largely depends on the exhaust type and properties of the
boundary layer with which it mixes. In order to be able to statistically infer
the longevity of ship-emitted aerosols and characterize atmospheric conditions
under which they form, a first step is to simulate, with mathematical surrogate
model rather than an expensive physical model, the path of these cloud-aerosol
interactions with parameters that are inferable from imagery. This will allow
us to compare when/where we would expect to ship tracks to be visible,
independent of atmospheric conditions, with what is actually observed from
satellite imagery to be able to infer under what atmospheric conditions do ship
tracks form. In this paper, we will discuss an approach to stochastically
simulate the behavior of ship induced aerosols parcels within naturally
generated clouds. Our method can use wind fields and potentially relevant
atmospheric variables to determine the approximate movement and behavior of the
cloud-aerosol tracks, and uses a stochastic differential equation (SDE) to
model the persistence behavior of cloud-aerosol paths. This SDE incorporates
both a drift and diffusion term which describes the movement of aerosol parcels
via wind and their diffusivity through the atmosphere, respectively. We
successfully demonstrate our proposed approach with an example using simulated
wind fields and ship paths.",http://arxiv.org/abs/2111.05356v1
"Towards Optimally Weighted Physics-Informed Neural Networks in Ocean
  Modelling",2021-06-16T12:48:13Z,"Taco de Wolff, Hugo Carrillo, Luis Martí, Nayat Sanchez-Pi","The carbon pump of the world's ocean plays a vital role in the biosphere and
climate of the earth, urging improved understanding of the functions and
influences of the ocean for climate change analyses. State-of-the-art
techniques are required to develop models that can capture the complexity of
ocean currents and temperature flows. This work explores the benefits of using
physics-informed neural networks (PINNs) for solving partial differential
equations related to ocean modeling; such as the Burgers, wave, and
advection-diffusion equations. We explore the trade-offs of using data vs.
physical models in PINNs for solving partial differential equations. PINNs
account for the deviation from physical laws in order to improve learning and
generalization. We observed how the relative weight between the data and
physical model in the loss function influence training results, where small
data sets benefit more from the added physics information.",http://arxiv.org/abs/2106.08747v1
Decadal Forecasts with ResDMD: a Residual DMD Neural Network,2021-06-21T13:49:43Z,"Eduardo Rodrigues, Bianca Zadrozny, Campbell Watson, David Gold","Operational forecasting centers are investing in decadal (1-10 year) forecast
systems to support long-term decision making for a more climate-resilient
society. One method that has previously been employed is the Dynamic Mode
Decomposition (DMD) algorithm - also known as the Linear Inverse Model - which
fits linear dynamical models to data. While the DMD usually approximates
non-linear terms in the true dynamics as a linear system with random noise, we
investigate an extension to the DMD that explicitly represents the non-linear
terms as a neural network. Our weight initialization allows the network to
produce sensible results before training and then improve the prediction after
training as data becomes available. In this short paper, we evaluate the
proposed architecture for simulating global sea surface temperatures and
compare the results with the standard DMD and seasonal forecasts produced by
the state-of-the-art dynamical model, CFSv2.",http://arxiv.org/abs/2106.11111v1
Linking Sap Flow Measurements with Earth Observations,2021-08-03T04:40:15Z,"Enrico Tomelleri, Giustino Tonon","While single-tree transpiration is challenging to compare with earth
observation, canopy scale data are suitable for this purpose. To test the
potentialities of the second approach, we equipped the trees at two measurement
sites with sap flow sensors in spruce forests. The sites have contrasting
topography. The measurement period covered the months between June 2020 and
January 2021. To link plot scale transpiration with earth observations, we
utilized Sentinel-2 and local meteorological data. Within a machine learning
framework, we have tested the suitability of earth observations for modelling
canopy transpiration. The R2 of the cross-validated trained models at the
measurement sites was between 0.57 and 0.80. These results demonstrate the
relevance of Sentinel-2 data for the data-driven upscaling of ecosystem fluxes
from plot scale sap flow data. If applied to a broader network of sites and
climatic conditions, such an approach could offer unprecedented possibilities
for investigating our forests' resilience and resistance capacity to an
intensified hydrological cycle in the contest of a changing climate.",http://arxiv.org/abs/2108.01290v1
Predicting Forest Fire Using Remote Sensing Data And Machine Learning,2021-01-06T11:22:55Z,"Suwei Yang, Massimo Lupascu, Kuldeep S. Meel","Over the last few decades, deforestation and climate change have caused
increasing number of forest fires. In Southeast Asia, Indonesia has been the
most affected country by tropical peatland forest fires. These fires have a
significant impact on the climate resulting in extensive health, social and
economic issues. Existing forest fire prediction systems, such as the Canadian
Forest Fire Danger Rating System, are based on handcrafted features and require
installation and maintenance of expensive instruments on the ground, which can
be a challenge for developing countries such as Indonesia. We propose a novel,
cost-effective, machine-learning based approach that uses remote sensing data
to predict forest fires in Indonesia. Our prediction model achieves more than
0.81 area under the receiver operator characteristic (ROC) curve, performing
significantly better than the baseline approach which never exceeds 0.70 area
under ROC curve on the same tasks. Our model's performance remained above 0.81
area under ROC curve even when evaluated with reduced data. The results support
our claim that machine-learning based approaches can lead to reliable and
cost-effective forest fire prediction systems.",http://arxiv.org/abs/2101.01975v1
Long-Range Seasonal Forecasting of 2m-Temperature with Machine Learning,2021-01-29T21:58:49Z,"Etienne E. Vos, Ashley Gritzman, Sibusisiwe Makhanya, Thabang Mashinini, Campbell D. Watson","A significant challenge in seasonal climate prediction is whether a
prediction can beat climatology. We hereby present results from two data-driven
models - a convolutional (CNN) and a recurrent (RNN) neural network - that
predict 2 m temperature out to 52 weeks for six geographically-diverse
locations. The motivation for testing the two classes of ML models is to allow
the CNN to leverage information related to teleconnections and the RNN to
leverage long-term historical temporal signals. The ML models boast improved
accuracy of long-range temperature forecasts up to a lead time of 30 weeks for
PCC and up 52 weeks for RMSESS, however only for select locations. Further
iteration is required to ensure the ML models have value beyond regions where
the climatology has a noticeably reduced correlation skill, namely the tropics.",http://arxiv.org/abs/2102.00085v1
"New Astronomical, Meteorological and Geological Study of Montefiascone
  (VT)",2021-02-24T15:09:06Z,"D. Tasselli, S. Ricci, P. Bianchi","In this work that continues the ""NGICS - New Italian City Geological Study"" a
project of the Department of Climatology and Geology of TS Corporation Srl, we
present the study relating to the Municipality of Montefiascone (VT). We
analyzed 25 years of astronomical, geological, meteorological and climatic
data, comparing them to verify the long-term trend of local variations in
temperatures, detections, solar radiation and geological events, with the
ultimate goal of understanding climate and geological changes a long term in
this geographical area. The analysis is performed using a statistical approach
and attention is used to minimize any effects caused by the error in case of
lack of data.",http://arxiv.org/abs/2102.12334v1
Policy with stochastic hysteresis,2021-04-20T19:52:26Z,"Georgii Riabov, Aleh Tsyvinski","The paper develops a general methodology for analyzing policies with
path-dependency (hysteresis) in stochastic models with forward looking
optimizing agents. Our main application is a macro-climate model with a
path-dependent climate externality. We derive in closed form the dynamics of
the optimal Pigouvian tax, that is, its drift and diffusion coefficients. The
dynamics of the present marginal damages is given by the recently developed
functional It\^o formula. The dynamics of the conditional expectation process
of the future marginal damages is given by a new total derivative formula that
we prove. The total derivative formula represents the evolution of the
conditional expectation process as a sum of the expected dynamics of hysteresis
with respect to time, a form of a time derivative, and the expected dynamics of
hysteresis with the shocks to the trajectory of the stochastic process, a form
of a stochastic derivative. We then generalize the results. First, we propose a
general class of hysteresis functionals that permits significant tractability.
Second, we characterize in closed form the dynamics of the stochastic
hysteresis elasticity that represents the change in the whole optimal policy
process with an introduction of small hysteresis effects. Third, we determine
the optimal policy process.",http://arxiv.org/abs/2104.10225v1
"MAQ-CaF: A Modular Air Quality Calibration and Forecasting method for
  cross-sensitive pollutants",2021-04-22T13:34:06Z,"Yousuf Hashmy, ZillUllah Khan, Rehan Hafiz, Usman Younis, Tausif Tauqeer","The climatic challenges are rising across the globe in general and in worst
hit under-developed countries in particular. The need for accurate measurements
and forecasting of pollutants with low-cost deployment is more pertinent today
than ever before. Low-cost air quality monitoring sensors are prone to
erroneous measurements, frequent downtimes, and uncertain operational
conditions. Such a situation demands a prudent approach to ensure an effective
and flexible calibration scheme. We propose MAQ-CaF, a modular air quality
calibration, and forecasting methodology, that side-steps the challenges of
unreliability through its modular machine learning-based design which leverages
the potential of IoT framework. It stores the calibrated data both locally and
remotely with an added feature of future predictions. Our specially designed
validation process helps to establish the proposed solution's applicability and
flexibility without compromising accuracy. CO, SO2, NO2, O3, PM1.0, PM2.5 and
PM10 were calibrated and monitored with reasonable accuracy. Such an attempt is
a step toward addressing climate change's global challenge through appropriate
monitoring and air quality tracking across a wider geographical region via
affordable monitoring.",http://arxiv.org/abs/2104.12594v1
"Market Potential for CO$_2$ Removal and Sequestration from Renewable
  Natural Gas Production in California",2021-05-04T17:41:38Z,"Jun Wong, Jonathan Santoso, Marjorie Went, Daniel Sanchez","Bioenergy with Carbon Capture and Sequestration (BECCS) is critical for
stringent climate change mitigation, but is commercially and technologically
immature and resource-intensive. In California, state and federal fuel and
climate policies can drive first-markets for BECCS. We develop a spatially
explicit optimization model to assess niche markets for renewable natural gas
(RNG) production with carbon capture and sequestration (CCS) from waste biomass
in California. Existing biomass residues produce biogas and RNG and enable
low-cost CCS through the upgrading process and CO$_2$ truck transport. Under
current state and federal policy incentives, we could capture and sequester 2.9
million MT CO$_2$/year (0.7% of California's 2018 CO$_2$ emissions) and produce
93 PJ RNG/year (4% of California's 2018 natural gas demand) with a profit
maximizing objective. Existing federal and state policies produce profits of
\$11/GJ. Distributed RNG production with CCS potentially catalyzes markets and
technologies for CO$_2$ capture, transport, and storage in California.",http://arxiv.org/abs/2105.01644v1
"Modeling space-time trends and dependence in extreme precipitations of
  Burkina Faso by the approach of the Peaks-Over-Threshold",2021-05-12T10:00:29Z,"Béwentaoré Sawadogo, Diakarya Barro","Modeling extremes of climate variables in the framework of climate change is
a particularly difficult task, since it implies taking into account
spatio-temporal nonstationarities. In this paper, we propose a new method for
estimating extreme precipitation at the points where we have not observations
using information from marginal distributions and dependence structure. To
reach this goal we combine two statistical approaches of extreme values theory
allowing on the one hand to control temporal and spatial non-stationarities via
a tail trend function with a spatio-temporal structure in the marginal
distributions and by modeling on the other hand the dependence structure by a
latent spatial process using generalized `-Pareto processes. This new
methodology for trend analysis of extreme events is applied to rainfall data
from Burkina Faso. We show that extreme precipitation is spatially and
temporally correlated for distances of approximately 200 km. Locally, extreme
rainfall has more of an upward than downward trend.",http://arxiv.org/abs/2105.05548v1
"Eigen Microstates and Their Evolution of Global Ozone at Different
  Geopotential Heights",2021-07-02T05:33:42Z,"Xiaojie Chen, Na Ying, Dean Chen, Yongwen Zhang, Bo Lu, Jingfang Fan, Xiaosong Chen","Studies on stratospheric ozone have attracted much attention due to its
serious impacts on climate changes and its important role as a tracer of
Earth's global circulation. Tropospheric ozone as a main atmospheric pollutant
damages human health as well as the growth of vegetation. Yet there is still a
lack of a theoretical framework to fully describe the variation of ozone. To
understand ozone's spatiotemporal variance, we introduce the eigen microstate
method to analyze the global ozone mass mixing ratio (OMMR) between 1979-01-01
and 2020-06-30 at 37 pressure layers. We find that eigen microstates at
different geopotential heights can capture different climate phenomena and
modes. Without deseasonalization, the first eigen microstates capture the
seasonal effect and reveal that the phase of the intra-annual cycle moves with
the geopotential heights. After deseasonalization, by contrast, the collective
patterns from the overall trend, ENSO, QBO, and tropopause pressure are
identified by the first few significant eigen microstates. The theoretical
framework proposed here can also be applied to other complex Earth systems.",http://arxiv.org/abs/2107.00843v1
Predicting Drought and Subsidence Risks in France,2021-07-16T02:09:30Z,"Arthur Charpentier, Molly James, Hani Ali","The economic consequences of drought episodes are increasingly important,
although they are often difficult to apprehend in part because of the
complexity of the underlying mechanisms. In this article, we will study one of
the consequences of drought, namely the risk of subsidence (or more
specifically clay shrinkage induced subsidence), for which insurance has been
mandatory in France for several decades. Using data obtained from several
insurers, representing about a quarter of the household insurance market, over
the past twenty years, we propose some statistical models to predict the
frequency but also the intensity of these droughts, for insurers, showing that
climate change will have probably major economic consequences on this risk. But
even if we use more advanced models than standard regression-type models (here
random forests to capture non linearity and cross effects), it is still
difficult to predict the economic cost of subsidence claims, even if all
geophysical and climatic information is available.",http://arxiv.org/abs/2107.07668v1
"Contrarian effect in opinion forming: insights from Greta Thunberg
  phenomenon",2021-09-08T08:18:04Z,"Elisa Iacomini, Pierluigi Vellucci","In recent months the figure of Greta Thunberg and the theme of climate
changings quickly became the focus of the debate. This has lead to a
polarization effect in opinion forming about the climate subject. Starting from
the analysis of this phenomenon, we develop an opinion dynamics model in which
several types of contrarians agents are considered. Each agent is supposed to
have an opinion on several topics related to each other, thus the opinions
being formed on these topics are also mutually dependent. The aim of the paper
is to investigate the indirect effects of contrarians agents on the collective
opinion about these topics. Several numerical tests are presented in order to
highlight the main features of the model.",http://arxiv.org/abs/2109.03486v2
Estimation of Corporate Greenhouse Gas Emissions via Machine Learning,2021-09-09T14:50:26Z,"You Han, Achintya Gopal, Liwen Ouyang, Aaron Key","As an important step to fulfill the Paris Agreement and achieve net-zero
emissions by 2050, the European Commission adopted the most ambitious package
of climate impact measures in April 2021 to improve the flow of capital towards
sustainable activities. For these and other international measures to be
successful, reliable data is key. The ability to see the carbon footprint of
companies around the world will be critical for investors to comply with the
measures. However, with only a small portion of companies volunteering to
disclose their greenhouse gas (GHG) emissions, it is nearly impossible for
investors to align their investment strategies with the measures. By training a
machine learning model on disclosed GHG emissions, we are able to estimate the
emissions of other companies globally who do not disclose their emissions. In
this paper, we show that our model provides accurate estimates of corporate GHG
emissions to investors such that they are able to align their investments with
the regulatory measures and achieve net-zero goals.",http://arxiv.org/abs/2109.04318v1
"Stochastic energy balance climate models with Legendre weighted
  diffusion and a cylindrical Wiener process forcing",2021-11-21T11:49:59Z,"Gregorio Díaz, Jesús Ildefonso Díaz","We consider a class of one-dimensional nonlinear stochastic parabolic
problems associated with Sellers and Budyko diffusive energy balance climate
models with a Legendre weighted diffusion and an additive cylindrical Wiener
processes forcing. Our results use in an important way that, under suitable
assumptions on the Wiener processes, a suitable change of variables leads the
problem to a pathwise random PDE, hence an essentially ""deterministic""
formulation depending on a random parameter. Two applications are also given:
the stability of solutions when the Wiener process converges to zero and the
asymptotic behaviour of solutions for large time.",http://arxiv.org/abs/2111.10801v2
"30.000 ways to reach 55% decarbonization of the European electricity
  sector",2021-12-14T09:20:34Z,"Tim T. Pedersen, Mikael Skou Andersen, Marta Victoria, Gorm B. Andresen","Climate change mitigation is a global challenge that, however, needs to be
resolved by national-level authorities, resembling a tragedy of the commons.
This paradox is reflected at European scale, as climate commitments are made by
the EU collectively, but implementation is the responsibility of individual
Member States. Here, we investigate 30.000 near-optimal effort-sharing
scenarios where the European electricity sector is decarbonized by at least 55%
relative to 1990, in line with 2030 ambitions. Using a highly detailed
brownfield electricity system optimization model, the optimal electricity
system is simulated for a suite of effort-sharing scenarios. Results reveal
large inequalities in the efforts required to decarbonize national electricity
sectors, with some countries facing cost-optimal pathways to reach 55% emission
reductions, while others are confronted with relatively high abatement costs.
Specifically, we find that several countries with modest or low levels of GDP
per capita will experience high abatement costs, and when passed over into
electricity prices this may lead to increased energy poverty in certain parts
of Europe",http://arxiv.org/abs/2112.07247v3
"Twitter-COMMs: Detecting Climate, COVID, and Military Multimodal
  Misinformation",2021-12-16T03:37:20Z,"Giscard Biamby, Grace Luo, Trevor Darrell, Anna Rohrbach","Detecting out-of-context media, such as ""mis-captioned"" images on Twitter, is
a relevant problem, especially in domains of high public significance. In this
work we aim to develop defenses against such misinformation for the topics of
Climate Change, COVID-19, and Military Vehicles. We first present a large-scale
multimodal dataset with over 884k tweets relevant to these topics. Next, we
propose a detection method, based on the state-of-the-art CLIP model, that
leverages automatically generated hard image-text mismatches. While this
approach works well on our automatically constructed out-of-context tweets, we
aim to validate its usefulness on data representative of the real world. Thus,
we test it on a set of human-generated fakes created by mimicking in-the-wild
misinformation. We achieve an 11% detection improvement in a high precision
regime over a strong baseline. Finally, we share insights about our best model
design and analyze the challenges of this emerging threat.",http://arxiv.org/abs/2112.08594v2
"PreDisM: Pre-Disaster Modelling With CNN Ensembles for At-Risk
  Communities",2021-12-26T23:48:23Z,"Vishal Anand, Yuki Miura","The machine learning community has recently had increased interest in the
climate and disaster damage domain due to a marked increased occurrences of
natural hazards (e.g., hurricanes, forest fires, floods, earthquakes). However,
not enough attention has been devoted to mitigating probable destruction from
impending natural hazards. We explore this crucial space by predicting
building-level damages on a before-the-fact basis that would allow state actors
and non-governmental organizations to be best equipped with resource
distribution to minimize or preempt losses. We introduce PreDisM that employs
an ensemble of ResNets and fully connected layers over decision trees to
capture image-level and meta-level information to accurately estimate weakness
of man-made structures to disaster-occurrences. Our model performs well and is
responsive to tuning across types of disasters and highlights the space of
preemptive hazard damage modelling.",http://arxiv.org/abs/2112.13465v1
"Recent Ice Trends in Swiss Mountain Lakes: 20-year Analysis of MODIS
  Imagery",2021-03-23T10:25:02Z,"Manu Tom, Tianyu Wu, Emmanuel Baltsavias, Konrad Schindler","Depleting lake ice is a climate change indicator, just like sea-level rise or
glacial retreat. Monitoring Lake Ice Phenology (LIP) is useful because
long-term freezing and thawing patterns serve as sentinels to understand
regional and global climate change. We report a study for the Oberengadin
region of Switzerland, where several small- and medium-sized mountain lakes are
located. We observe the LIP events, such as freeze-up, break-up and ice cover
duration, across two decades (2000-2020) from optical satellite images. We
analyse the time series of MODIS imagery by estimating spatially resolved maps
of lake ice for these Alpine lakes with supervised machine learning. To train
the classifier we rely on reference data annotated manually based on webcam
images. From the ice maps, we derive long-term LIP trends. Since the webcam
data are only available for two winters, we cross-check our results against the
operational MODIS and VIIRS snow products. We find a change in complete freeze
duration of -0.76 and -0.89 days per annum for lakes Sils and Silvaplana,
respectively. Furthermore, we observe plausible correlations of the LIP trends
with climate data measured at nearby meteorological stations. We notice that
mean winter air temperature has a negative correlation with the freeze duration
and break-up events and a positive correlation with the freeze-up events.
Additionally, we observe a strong negative correlation of sunshine during the
winter months with the freeze duration and break-up events.",http://arxiv.org/abs/2103.12434v4
An Encoding Approach for Stable Change Point Detection,2021-05-11T21:00:13Z,"Xiaodong Wang, Fushing Hsieh","Without imposing prior distributional knowledge underlying multivariate time
series of interest, we propose a nonparametric change-point detection approach
to estimate the number of change points and their locations along the temporal
axis. We develop a structural subsampling procedure such that the observations
are encoded into multiple sequences of Bernoulli variables. A maximum
likelihood approach in conjunction with a newly developed searching algorithm
is implemented to detect change points on each Bernoulli process separately.
Then, aggregation statistics are proposed to collectively synthesize
change-point results from all individual univariate time series into consistent
and stable location estimations. We also study a weighting strategy to measure
the degree of relevance for different subsampled groups. Simulation studies are
conducted and shown that the proposed change-point methodology for multivariate
time series has favorable performance comparing with currently popular
nonparametric methods under various settings with different degrees of
complexity. Real data analyses are finally performed on categorical, ordinal,
and continuous time series taken from fields of genetics, climate, and finance.",http://arxiv.org/abs/2105.05341v1
"Uncertainty Analysis Of Future Projections Of Temperature,
  Precipitation, And Solar Radiation Under Global Warming Effect In Tehran,
  Iran",2021-09-10T02:12:00Z,"Ehsan Mosadegh, Iman Babaeian","In order to investigate the scope of uncertainty in projections of GCMs for
Tehran province, a multi-model projection composed of 15 models is employed.
The projected changes in minimum temperature, maximum temperature,
precipitation, and solar radiation under the A1B scenario for Tehran province
are investigated for 2011-2030, 2046-2065, and 2080-2099. GCM projections for
the study region are downscaled by the LARS-WG5 model. Uncertainty among the
projections is evaluated from three perspectives: large-scale climate scenarios
downscaled values, and mean decadal changes. 15 GCMs unanimously project an
increasing trend in the temperature for the study region. Also, uncertainty in
the projections for the summer months is greater than projection uncertainty
for other months. The mean absolute surface temperature increase for the three
periods is projected to be about 0.8{\deg}C, 2.4{\deg}C, and 3.8{\deg}C in the
summers, respectively. The uncertainty of the multi-model projections for
precipitation in summer seasons, and the radiation in the springs and falls is
higher than other seasons for the study region. Model projections indicate that
for the three future periods and relative to their baseline period, springtime
precipitation will decrease about 5\%, 10\%, and 20\%, and springtime radiation
will increase about 0.5\%, 1.5\%, and 3\%, respectively. The projected mean
decadal changes indicate an increase in temperature and radiation and a
decrease in precipitation. Furthermore, the performance of the GCMs in
simulating the baseline climate by the MOTP method does not indicate any
distinct pattern among the GCMs for the study region.",http://arxiv.org/abs/2109.04622v1
"Spatial shifts in productivity of the coastal ocean over the past two
  decades induced by migration of the Pacific Anticyclone and Bakun effect in
  the Humboldt Upwelling Ecosystem",2021-04-16T12:09:14Z,"Nicolas Weidberg, Andres Ospina-Alvarez, Jessica Bonicelli, Mario Barahona, Christopher M. Aiken, Bernardo R. Broitman, Sergio A. Navarrete","Intensification and poleward expansion of upwelling favourable winds have
been predicted as a response to anthropogenic global climate change and have
recently been documented in most Eastern Boundary Upwelling Ecosystems of the
world. To identify how these processes are impacting nearshore oceanographic
habitats and, especially, long term trends of primary productivity in the
Humboldt Upwelling Ecosystem (HUE), we analysed time series of sea level
pressure, wind stress, sea surface and atmospheric surface temperatures, and
Chlorophyll-a, as a proxy for primary productivity, along 26{\deg} - 36{\deg}
S. We show that climate induced trends in primary productivity are highly
heterogeneous across the region. On the one hand, the well documented poleward
migration of the South Pacific Anticyclone (SPA) has led to decreased spring
upwelling winds in the region between ca. 30{\deg} and 34{\deg} S, and to their
intensification to the south. Decreased winds have produced slight increases in
sea surface temperature and a pronounced and meridionally extensive decrease in
surface Chlorophyll-a in this region of central Chile. To the north of 30{\deg}
S, significant increases in upwelling winds, decreased SST, and enhanced
Chlorophyll-a concentration are observed in the nearshore. We show that this
increased in upwelling driven coastal productivity is probably produced by the
increased land-sea pressure gradients (Bakun's effect) that have occurred over
the past two decades north of 30{\deg} S. Thus, climate drivers along the HUE
are inducing contrasting trends in oceanographic conditions and primary
productivity, which can have far-reaching consequences for coastal pelagic and
benthic ecosystems and lead to geographic displacements of the major fisheries.",http://arxiv.org/abs/2104.11698v1
"Modeling Weather-induced Home Insurance Risks with Support Vector
  Machine Regression",2021-03-15T23:13:32Z,"Asim K. Dey, Vyacheslav Lyubchich, Yulia R. Gel","Insurance industry is one of the most vulnerable sectors to climate change.
Assessment of future number of claims and incurred losses is critical for
disaster preparedness and risk management. In this project, we study the effect
of precipitation on a joint dynamics of weather-induced home insurance claims
and losses. We discuss utility and limitations of such machine learning
procedures as Support Vector Machines and Artificial Neural Networks, in
forecasting future claim dynamics and evaluating associated uncertainties. We
illustrate our approach by application to attribution analysis and forecasting
of weather-induced home insurance claims in a middle-sized city in the Canadian
Prairies.",http://arxiv.org/abs/2103.08761v1
"Attentive Neural Processes and Batch Bayesian Optimization for Scalable
  Calibration of Physics-Informed Digital Twins",2021-06-29T15:30:55Z,"Ankush Chakrabarty, Gordon Wichern, Christopher Laughman","Physics-informed dynamical system models form critical components of digital
twins of the built environment. These digital twins enable the design of
energy-efficient infrastructure, but must be properly calibrated to accurately
reflect system behavior for downstream prediction and analysis. Dynamical
system models of modern buildings are typically described by a large number of
parameters and incur significant computational expenditure during simulations.
To handle large-scale calibration of digital twins without exorbitant
simulations, we propose ANP-BBO: a scalable and parallelizable batch-wise
Bayesian optimization (BBO) methodology that leverages attentive neural
processes (ANPs).",http://arxiv.org/abs/2106.15502v1
"WTO GPA and Sustainable Procurement as Tools for Transitioning to a
  Circular Economy",2021-04-10T12:05:13Z,Sareesh Rawat,"We live in an age of consumption with an ever-increasing demand of already
scarce resources and equally fast growing problems of waste generation and
climate change. To tackle these difficult issues, we must learn from mother
nature. Just like waste does not exist in nature, we must strive to create
circular ecosystems where waste is minimized and energy is conserved. This
paper focuses on how public procurement can help us transition to a more
circular economy, while navigating international trade laws that govern it.",http://arxiv.org/abs/2104.04744v1
"A fault slip model to study earthquakes due to pore pressure
  perturbations",2021-04-04T00:54:47Z,"Saumik Dana, Birendra Jha","The burgeoning need to sequester anthropogenic CO$_2$ for climate mitigation
and the need for energy sustenance leading upto enhanced geothermal energy
production has made it incredibly critical to study potential earthquakes due
to fluid activity in the subsurface. These earthquakes result from reactivation
of faults in the subsurface due to pore pressure perturbations. In this work,
we provide a framework to model fault slip due to pore pressure change leading
upto quantifying the earthquake magnitude.",http://arxiv.org/abs/2104.06257v2
"IIITT@LT-EDI-EACL2021-Hope Speech Detection: There is always Hope in
  Transformers",2021-04-19T06:19:13Z,"Karthik Puranik, Adeep Hande, Ruba Priyadharshini, Sajeetha Thavareesan, Bharathi Raja Chakravarthi","In a world filled with serious challenges like climate change, religious and
political conflicts, global pandemics, terrorism, and racial discrimination, an
internet full of hate speech, abusive and offensive content is the last thing
we desire for. In this paper, we work to identify and promote positive and
supportive content on these platforms. We work with several transformer-based
models to classify social media comments as hope speech or not-hope speech in
English, Malayalam and Tamil languages. This paper portrays our work for the
Shared Task on Hope Speech Detection for Equality, Diversity, and Inclusion at
LT-EDI 2021- EACL 2021.",http://arxiv.org/abs/2104.09066v1
"Climate Change Adaptation in the British Columbia Wine Industry Can
  carbon sequestration technology lower the B.C. Wine Industry's greenhouse gas
  emissions?",2021-04-27T17:09:34Z,"Lee Cartier, Svan Lembke","The purpose of this study is to measure the benefits and costs of using
biochar, a carbon sequestration technology, to reduce the B.C Wine Industry's
carbon emissions. An economic model was developed to calculate the value-added
for each of the three sectors that comprise the BC Wine industry. Results
indicate that each sector of the wine value chain is potentially profitable,
with 9,000 tonnes of CO2 sequestered each year. The study is unique in that it
demonstrates that using biochar, produced from wine industry waste, to
sequester atmospheric CO2 can be both profitable and environmentally
sustainable.",http://arxiv.org/abs/2104.13330v1
Estimates of the social cost of carbon have increased over time,2021-05-08T09:59:06Z,Richard S. J. Tol,"A meta-analysis of published estimates shows that the social cost of carbon
has increased as knowledge about climate change accumulates. Correcting for
inflation and emission year and controlling for the discount rate, kernel
density decomposition reveals a non-stationary distribution. In the last 10
years, estimates of the social cost of carbon have increased from $33/tC to
$146/tC for a high discount rate and from $446/tC to $1925/tC for a low
discount rate. Actual carbon prices are almost everywhere below its estimated
value and should therefore go up.",http://arxiv.org/abs/2105.03656v3
"Leveraging Domain Adaptation for Low-Resource Geospatial Machine
  Learning",2021-07-11T06:47:20Z,"Jack Lynch, Sam Wookey","Machine learning in remote sensing has matured alongside a proliferation in
availability and resolution of geospatial imagery, but its utility is
bottlenecked by the need for labeled data. What's more, many labeled geospatial
datasets are specific to certain regions, instruments, or extreme weather
events. We investigate the application of modern domain-adaptation to multiple
proposed geospatial benchmarks, uncovering unique challenges and proposing
solutions to them.",http://arxiv.org/abs/2107.04983v1
Fast-Slow Streamflow Model Using Mass-Conserving LSTM,2021-07-13T13:10:24Z,"Miguel Paredes Quiñones, Maciel Zortea, Leonardo S. A. Martins","Streamflow forecasting is key to effectively managing water resources and
preparing for the occurrence of natural calamities being exacerbated by climate
change. Here we use the concept of fast and slow flow components to create a
new mass-conserving Long Short-Term Memory (LSTM) neural network model. It uses
hydrometeorological time series and catchment attributes to predict daily river
discharges. Preliminary results evidence improvement in skills for different
scores compared to the recent literature.",http://arxiv.org/abs/2107.06057v1
How Computer Science Can Aid Forest Restoration,2021-08-12T16:29:49Z,"Gemma Gordon, Amelia Holcomb, Tom Kelly, Srinivasan Keshav, Jon Ludlum, Anil Madhavapeddy","The world faces two interlinked crises: climate change and loss of
biodiversity. Forest restoration on degraded lands and surplus croplands can
play a significant role both in sequestering carbon and re-establishing
bio-diversity. There is a considerable body of research and practice that
addresses forest restoration. However, there has been little work by computer
scientists to bring powerful computational techniques to bear on this important
area of work, perhaps due to a lack of awareness. In an attempt to bridge this
gap, we present our vision of how techniques from computer science, broadly
speaking, can aid current practice in forest restoration.",http://arxiv.org/abs/2109.07898v1
DEM Super-Resolution with EfficientNetV2,2021-09-20T16:26:58Z,"Bekir Z Demiray, Muhammed Sit, Ibrahim Demir","Efficient climate change monitoring and modeling rely on high-quality
geospatial and environmental datasets. Due to limitations in technical
capabilities or resources, the acquisition of high-quality data for many
environmental disciplines is costly. Digital Elevation Model (DEM) datasets are
such examples whereas their low-resolution versions are widely available,
high-resolution ones are scarce. In an effort to rectify this problem, we
propose and assess an EfficientNetV2 based model. The proposed model increases
the spatial resolution of DEMs up to 16times without additional information.",http://arxiv.org/abs/2109.09661v1
Machine Learning aided Crop Yield Optimization,2021-11-01T14:14:11Z,"Chace Ashcraft, Kiran Karra","We present a crop simulation environment with an OpenAI Gym interface, and
apply modern deep reinforcement learning (DRL) algorithms to optimize yield. We
empirically show that DRL algorithms may be useful in discovering new policies
and approaches to help optimize crop yield, while simultaneously minimizing
constraining factors such as water and fertilizer usage. We propose that this
hybrid plant modeling and data-driven approach for discovering new strategies
to optimize crop yield may help address upcoming global food demands due to
population expansion and climate change.",http://arxiv.org/abs/2111.00963v1
Addressing Privacy Threats from Machine Learning,2021-10-25T03:40:25Z,Mary Anne Smart,"Every year at NeurIPS, machine learning researchers gather and discuss
exciting applications of machine learning in areas such as public health,
disaster response, climate change, education, and more. However, many of these
same researchers are expressing growing concern about applications of machine
learning for surveillance (Nanayakkara et al., 2021). This paper presents a
brief overview of strategies for resisting these surveillance technologies and
calls for greater collaboration between machine learning and human-computer
interaction researchers to address the threats that these technologies pose.",http://arxiv.org/abs/2111.04439v1
Aim in Climate Change and City Pollution,2021-12-30T16:17:46Z,"Pablo Torres, Beril Sirmacek, Sergio Hoyas, Ricardo Vinuesa","The sustainability of urban environments is an increasingly relevant problem.
Air pollution plays a key role in the degradation of the environment as well as
the health of the citizens exposed to it. In this chapter we provide a review
of the methods available to model air pollution, focusing on the application of
machine-learning methods. In fact, machine-learning methods have proved to
importantly increase the accuracy of traditional air-pollution approaches while
limiting the development cost of the models. Machine-learning tools have opened
new approaches to study air pollution, such as flow-dynamics modelling or
remote-sensing methodologies.",http://arxiv.org/abs/2112.15115v1
Readiness of the South African Agricultural Sector to Implement IoT,2021-08-23T11:25:20Z,"In'aam Soeker, Shallen Lusinga, Wallace Chigona","As the world's population increases, so does the demand for food. This demand
for food in turn puts pressure on agriculture in many countries. The impact of
climate change on the environment has made it difficult to produce food that
may be necessary to accommodate the growing population. Due to these concerns,
the agriculture sector is forced to move towards more efficient and sustainable
methods of farming to increase productivity. There is evidence that the use of
technology in agriculture has the potential to improve food production and food
sustainability; thereby addressing the concerns of food security. The Internet
of Things (IoT) has been suggested as a potential tool for farmers to overcome
the impact of climate change on food security. However, there is dearth of
research on the readiness of implementing IoT in South Africa's agricultural
sector. Therefore, this research aims to explore the readiness of the
agricultural sector of South Africa for a wide implementation of IoT. This
research conducts a desktop study through the lens of the PEST framework on the
special case of South Africa. A thematic literature and documents review was
deployed to examine the political, economic, societal and technological factors
that may facilitate or impede the implementation of IoT in the agricultural
sectors of South Africa. The findings suggest that the wide ranging political,
economic, societal and technological constructs enable the implementation of
IoT within South Africa's agricultural sector. The most important include
current policies, technological infrastructure, access to internet, and mobile
technology which places South Africa in a good position to implement IoT in
agriculture.",http://arxiv.org/abs/2108.10081v1
"Linguistic Characterization of Divisive Topics Online: Case Studies on
  Contentiousness in Abortion, Climate Change, and Gun Control",2021-08-30T23:55:38Z,"Jacob Beel, Tong Xiang, Sandeep Soni, Diyi Yang","As public discourse continues to move and grow online, conversations about
divisive topics on social media platforms have also increased. These divisive
topics prompt both contentious and non-contentious conversations. Although what
distinguishes these conversations, often framed as what makes these
conversations contentious, is known in broad strokes, much less is known about
the linguistic signature of these conversations. Prior work has shown that
contentious content and structure can be a predictor for this task, however,
most of them have been focused on conversation in general, very specific
events, or complex structural analysis. Additionally, many models used in prior
work have lacked interpret-ability, a key factor in online moderation. Our work
fills these gaps by focusing on conversations from highly divisive topics
(abortion, climate change, and gun control), operationalizing a set of novel
linguistic and conversational characteristics and user factors, and
incorporating them to build interpretable models. We demonstrate that such
characteristics can largely improve the performance of prediction on this task,
and also enable nuanced interpretability. Our case studies on these three
contentious topics suggest that certain generic linguistic characteristics are
highly correlated with contentiousness in conversations while others
demonstrate significant contextual influences on specific divisive topics.",http://arxiv.org/abs/2108.13556v2
Environmental migration? An overview of the literature,2021-12-28T11:29:03Z,"Maria Cipollina, Luca De Benedictis, Elisa Scibè","The literature on the relationship between environmental factors such as
climatic changes and natural hazards and human mobility (both internal and
international) is characterized by heterogeneous results: some contributions
highlight the role of climate changes as a driver of migratory flows, while
others underline how this impact is mediated by geographical, economic and the
features of the environmental shock. This paper attempts to map this
literature, focusing on economics and empirical essays.
  The paper improves on the existing literature: (a) providing systematic
research of the literature through main bibliographic databases, followed by a
review and bibliometric analysis of all resulting papers; (b) building a
citation-based network of contributions, that hollows to identify four separate
clusters of paper; (c) applying meta-analysis methods on the sample of 96
papers released between 2003 and 2020, published in an academic journal,
working papers series or unpublished studies, providing 3,904 point estimates
of the effect of slow-onset events and 2,065 point estimates of the effect of
fast-onset events.
  Overall, the meta-analytic average effect estimates a small impact of slow-
and rapid-onset variables on migration, however positive and significant. When
the clustering of the literature is accounted for, however, a significant
heterogeneity emerges among the four clusters of papers, giving rise to new
evidence on the formation of club-like convergence of literature outcomes.",http://arxiv.org/abs/2112.14097v2
"Quantifying COVID-19 enforced global changes in atmospheric pollutants
  using cloud computing based remote sensing",2021-01-10T11:07:52Z,"Manmeet Singh, Bhupendra Bahadur Singh, Raunaq Singh, Badimela Upendra, Rupinder Kaur, Sukhpal Singh Gill, Mriganka Sekhar Biswas","Global lockdowns in response to the COVID-19 pandemic have led to changes in
the anthropogenic activities resulting in perceivable air quality improvements.
Although several recent studies have analyzed these changes over different
regions of the globe, these analyses have been constrained due to the usage of
station-based data which is mostly limited upto the metropolitan cities. Also,
the quantifiable changes have been reported only for the developed and
developing regions leaving the poor economies (e.g. Africa) due to the shortage
of in-situ data. Using a comprehensive set of high spatiotemporal resolution
satellites and merged products of air pollutants, we analyze the air quality
across the globe and quantify the improvement resulting from the suppressed
anthropogenic activity during the lockdowns. In particular, we focus on
megacities, capitals and cities with high standards of living to make the
quantitative assessment. Our results offer valuable insights into the spatial
distribution of changes in the air pollutants due to COVID-19 enforced
lockdowns. Statistically significant reductions are observed over megacities
with mean reduction by 19.74%, 7.38% and 49.9% in nitrogen dioxide (NO2),
aerosol optical depth (AOD) and PM 2.5 concentrations. Google Earth Engine
empowered cloud computing based remote sensing is used and the results provide
a testbed for climate sensitivity experiments and validation of
chemistry-climate models. Additionally, Google Earth Engine based apps have
been developed to visualize the changes in a real-time fashion.",http://arxiv.org/abs/2101.03523v3
Natural Selection as the sum over all histories,2021-01-04T12:41:18Z,Clive Edward Neal Sturgess,"If evolution can be connected to the principle of least action, and if it is
depicted in evolution space versus time then it corresponds to the direction of
ultimate causation. As an organism evolves and follows a path of proximate
causation, if the vector is closely parallel to that of the ultimate causation
then the changes will confer desirable attributes which will lead to further
development. If however the variations do not occur in a direction close to the
of the ultimate causation vector the evolved organism will quickly die out.
This may be viewed as similar to Feynmans sum over all histories. Therefore,
the principle of least action gives a direction, but not a purpose, to
evolution. Taking the coevolution model of Lewontin, an equation of motion for
coevolution shows that it is the rate of evolutionary change that responds to
changes in the environment, in line with some evidence. In the face of widely
held views on mass extinctions because of climate change this gives some small
hope.",http://arxiv.org/abs/2101.01563v1
"Non-steady state model of global temperature change: Can we keep
  temperature from rising more than on two degrees?",2021-07-27T23:03:49Z,"Alexei V. Karnaukhov, Elena V. Karnaukhova, Elena P. Popova, Mikhail S. Blinnikov, Konstantin A. Shestibratov, Sergei I. Blinnikov, Vladimir N. Reshetov, Sergei F. Lyuksyutov","We propose a non-steady state model of the global temperature change. The
model describes Earth's surface temperature dynamics under main climate
forcing. The equations were derived from basic physical relationships and
detailed assessment of the numeric parameters used in the model. It shows an
accurate fit with observed changes in the surface mean annual temperature (MAT)
for the past 116 years. Using our model, we analyze the future global
temperature change under scenarios of drastic reductions of
CO\textsubscript{2}. The presence of non-linear feed-backs in the model
indicates on the possibility of exceeding two degrees threshold even under the
carbon dioxide drastic reduction scenario. We discuss the risks associated with
such warming and evaluate possible benefits of developing
CO\textsubscript{2}-absorbing deciduous tree plantations in the boreal zone of
Northern Hemisphere.",http://arxiv.org/abs/2107.13100v1
"Generating Physically-Consistent Satellite Imagery for Climate
  Visualizations",2021-04-10T15:00:15Z,"Björn Lütjens, Brandon Leshchinskiy, Océane Boulais, Farrukh Chishtie, Natalia Díaz-Rodríguez, Margaux Masson-Forsythe, Ana Mata-Payerro, Christian Requena-Mesa, Aruna Sankaranarayanan, Aaron Piña, Yarin Gal, Chedy Raïssi, Alexander Lavin, Dava Newman","Deep generative vision models are now able to synthesize realistic-looking
satellite imagery. But, the possibility of hallucinations prevents their
adoption for risk-sensitive applications, such as generating materials for
communicating climate change. To demonstrate this issue, we train a generative
adversarial network (pix2pixHD) to create synthetic satellite imagery of future
flooding and reforestation events. We find that a pure deep learning-based
model can generate photorealistic flood visualizations but hallucinates floods
at locations that were not susceptible to flooding. To address this issue, we
propose to condition and evaluate generative vision models on segmentation maps
of physics-based flood models. We show that our physics-conditioned model
outperforms the pure deep learning-based model and a handcrafted baseline. We
evaluate the generalization capability of our method to different remote
sensing data and different climate-related events (reforestation). We publish
our code and dataset which includes the data for a third case study of melting
Arctic sea ice and $>$30,000 labeled HD image triplets -- or the equivalent of
5.5 million images at 128x128 pixels -- for segmentation guided image-to-image
translation in Earth observation. Code and data is available at
\url{https://github.com/blutjens/eie-earth-public}.",http://arxiv.org/abs/2104.04785v5
"Hyperspace Neighbor Penetration Approach to Dynamic Programming for
  Model-Based Reinforcement Learning Problems with Slowly Changing Variables in
  A Continuous State Space",2021-06-10T04:58:31Z,"Vincent Zha, Ivey Chiu, Alexandre Guilbault, Jaime Tatis","Slowly changing variables in a continuous state space constitute an important
category of reinforcement learning and see its application in many domains,
such as modeling a climate control system where temperature, humidity, etc.
change slowly over time. However, this subject is less addressed in recent
studies. Classical methods with certain variants, such as Dynamic Programming
with Tile Coding which discretizes the state space, fail to handle slowly
changing variables because those methods cannot capture the tiny changes in
each transition step, as it is computationally expensive or impossible to
establish an extremely granular grid system. In this paper, we introduce a
Hyperspace Neighbor Penetration (HNP) approach that solves the problem. HNP
captures in each transition step the state's partial ""penetration"" into its
neighboring hyper-tiles in the gridded hyperspace, thus does not require the
transition to be inter-tile in order for the change to be captured. Therefore,
HNP allows for a very coarse grid system, which makes the computation feasible.
HNP assumes near linearity of the transition function in a local space, which
is commonly satisfied. In summary, HNP can be orders of magnitude more
efficient than classical method in handling slowly changing variables in
reinforcement learning. We have made an industrial implementation of NHP with a
great success.",http://arxiv.org/abs/2106.05497v1
Selection and mutation in a shifting and fluctuating environment,2021-03-12T14:40:12Z,"Susely Figueroa Iglesias, Sepideh Mirrahimi","We study the evolutionary dynamics of a phenotypically structured population
in a changing environment , where the environmental conditions vary with a
linear trend but in an oscillatory manner. Such phenomena can be described by
parabolic Lotka-Volterra type equations with non-local competition and a time
dependent growth rate. We first study the long time behavior of the solution to
this problem. Next, using an approach based on Hamilton-Jacobi equations we
study asymptotically such long time solutions when the effects of the mutations
are small. We prove that, as the effect of the mutations vanishes, the
phenotypic density of the population concentrates on a single trait which
varies linearly with time, while the size of the population oscillates
periodically. In contrast with the case of an environment without linear shift,
such dominant trait does not have the maximal growth rate in the averaged
environment and there is a cost on the growth rate due to the climate shift. We
also provide an asymptotic expansion for the average size of the population and
for the critical speed above which the population goes extinct, which is
closely related to the derivation of an asymptotic expansion for the Floquet
eigenvalue in terms of the diffusion rate. By mean of a biological example,
this expansion allows to show that the fluctuations on the environment may help
the population to follow the climatic shift in a better way.",http://arxiv.org/abs/2103.07317v2
"The Digital Agricultural Revolution: a Bibliometric Analysis Literature
  Review",2021-03-23T12:27:55Z,"Riccardo Bertoglio, Chiara Corbo, Filippo M. Renga, Matteo Matteucci","The application of digital technologies in agriculture can improve
traditional practices to adapt to climate change, reduce Greenhouse Gases (GHG)
emissions, and promote a sustainable intensification for food security. Some
authors argued that we are experiencing a Digital Agricultural Revolution (DAR)
that will boost sustainable farming. This study aims to find evidence of the
ongoing DAR process and clarify its roots, what it means, and where it is
heading. We investigated the scientific literature with bibliometric analysis
tools to produce an objective and reproducible literature review. We retrieved
4995 articles by querying the Web of Science database in the timespan
2012-2019, and we analyzed the obtained dataset to answer three specific
research questions: i) what is the spectrum of the DAR-related terminology?;
ii) what are the key articles and the most influential journals, institutions,
and countries?; iii) what are the main research streams and the emerging
topics? By grouping the authors' keywords reported on publications, we
identified five main research streams: Climate-Smart Agriculture (CSA),
Site-Specific Management (SSM), Remote Sensing (RS), Internet of Things (IoT),
and Artificial Intelligence (AI). To provide a broad overview of each of these
topics, we analyzed relevant review articles, and we present here the main
achievements and the ongoing challenges. Finally, we showed the trending topics
of the last three years (2017, 2018, 2019).",http://arxiv.org/abs/2103.12488v2
"Impacts of the Cryosphere and Atmosphere on Observed Microseisms
  Generated in the Southern Ocean",2021-08-19T09:52:33Z,"Ross J. Turner, Martin Gal, Mark A. Hemer, Anya M. Reading","The Southern Ocean (in the region 60-180$^\circ$E) south of the Indian Ocean,
Australia, and the West Pacific is noted for the frequent occurrence and
severity of its storms. These storms give rise to high-amplitude secondary
microseisms from sources, including the deep ocean regions, and primary
microseisms where the swells impinge on submarine topographic features. A
better understanding of the varying microseism wavefield enables improvements
to seismic imaging and development of proxy observables to complement sparse in
situ wave observations and hindcast models of the global ocean wave climate. We
analyze 12-26 years of seismic data from 11 seismic stations either on the East
Antarctic coast or sited in the Indian Ocean, Australia, and New Zealand. The
power spectral density of the seismic wavefield is calculated to explore how
the time-changing microseism intensity varies with (i) sea ice coverage
surrounding Antarctica and (ii) the Southern Annular Mode (SAM) climate index.
Variations in sea ice extent are found to be the dominant control on the
microseism intensity at Antarctic stations, which exhibit a seasonal pattern
phase-shifted by 4-5 months compared to stations in other continents. Peaks in
extremal intensity at East Antarctic stations occur in March-April, with the
highest peaks for secondary microseisms occurring during negative SAM events.
This relationship between microseism intensity and the SAM index is opposite to
that observed on the Antarctic Peninsula. This work informs the complexity of
microseism amplitudes in the Southern Hemisphere and assists ongoing
interdisciplinary investigations of interannual variability and long-term
trends.",http://arxiv.org/abs/2108.08590v1
EOS: Atmospheric Radiative Transfer in Habitable Worlds with HELIOS,2021-10-22T10:54:34Z,"Paolo Simonetti, Giovanni Vladilo, Laura Silva, Michele Maris, Stavro L. Ivanovski, Lorenzo Biasiotti, Matej Malik, Jost von Hardenberg","We present EOS, a procedure for determining the Outgoing Longwave Radiation
(OLR) and top-of-atmosphere (TOA) albedo for a wide range of conditions
expected to be present in the atmospheres of rocky planets with temperate
conditions. EOS is based on HELIOS and HELIOS-K, which are novel and publicly
available atmospheric radiative transfer (RT) codes optimized for fast
calculations with GPU processors. These codes were originally developed for the
study of giant planets. In this paper we present an adaptation for applications
to terrestrial-type, habitable planets, adding specific physical recipes for
the gas opacity and vertical structure of the atmosphere. To test the
reliability of the procedure we assessed the impact of changing line opacity
profile, continuum opacity model, atmospheric lapse rate and tropopause
position prescriptions on the OLR and the TOA albedo. The results obtained with
EOS are in line with those of other RT codes running on traditional CPU
processors, while being at least one order of magnitude faster. The adoption of
OLR and TOA albedo data generated with EOS in a zonal and seasonal climate
model correctly reproduce the fluxes of the present-day Earth measured by the
CERES spacecraft. The results of this study disclose the possibility to
incorporate fast RT calculations in climate models aimed at characterizing the
atmospheres of habitable exoplanets.",http://arxiv.org/abs/2110.11702v2
"The Elephant in the Room: Why Transformative Education Must Address the
  Problem of Endless Exponential Economic Growth",2021-01-19T05:23:19Z,"Chirag Dhara, Vandana Singh","A transformative approach to addressing complex social-environmental problems
warrants reexamining our most fundamental assumptions about sustainability and
progress, including the entrenched imperative for limitless economic growth.
Our global resource footprint has grown in lock-step with GDP since the
industrial revolution, spawning the climate and ecological crises. Faith that
technology will eventually decouple resource use from GDP growth is pervasive,
despite there being practically no empirical evidence of decoupling in any
country. We argue that complete long-term decoupling is, in fact, well-nigh
impossible for fundamental physical, mathematical, logical, pragmatic and
behavioural reasons. We suggest that a crucial first step toward a
transformative education is to acknowledge this incompatibility, and provide
examples of where and how our arguments may be incorporated in education. More
broadly, we propose that foregrounding SDG 12 with a functional definition of
sustainability, and educating and upskilling students to this end, must be a
necessary minimum goal of any transformative approach to sustainability
education. Our aim is to provide a conceptual scaffolding around which learning
frameworks may be developed to make room for diverse alternative paths to truly
sustainable social-ecological cultures.",http://arxiv.org/abs/2101.07467v1
"Fire Risk Analysis By Using Sentinel-2 Data: The Case Study Of The
  Vesuvius In Campania, Italy",2021-01-25T19:02:49Z,"Domenico A. G. Dell'Aglio, Massimiliano Gargiulo, Antonio Iodice, Daniele Riccio, Giuseppe Ruello","As sadly known, forest fires are part of a set of natural disasters that have
always affected regions of the world typically characterized by a tropical
climate with long periods of drought. However, due to climate changes of the
recent years, other regions of our planet that were not affected by this plague
have also had to deal with this phenomenon. One of them is certainly the
Italian peninsula, and especially the regions of southern Italy. For this
reason, the scientific community, and in particular that one of the remote
sensing, plays an important role in the development of reliable techniques to
provide useful support to the competent authorities. Therefore, in this work,
the capability of the Normalized Differential Water Index (NDWI), derived from
spaceborne remote sensing (RS) data, is assessed to monitor the forest fires
occurred on a specific study area during the summer of 2017: the volcano
Vesuvius, near Naples (in Campania, Italy). In particular, the index is
obtained from Sentinel-2 multispectral images of the European Space Agency
(ESA), which are free of charge and open accessible. Moreover, the twin
Sentinel-2 (S-2) sensors allows to overcome some restrictions on time delivery
and high frequency observation. These requirements are goodly matched by other
spaceborne sensors, such as MODIS and VIIRS satellites, but at the expense of a
lower spatial resolution.",http://arxiv.org/abs/2101.10352v1
"Impact of lockdowns and winter temperatures on natural gas consumption
  in Europe",2021-04-30T13:25:08Z,"Philippe Ciais, François-Marie Bréon, Stijn Dellaert, Yilong Wang, Katsumasa Tanaka1, Léna Gurriaran, Yann Françoise, Steven Davis, Chaopeng Hong, Josep Penuelas, Ivan Janssens, Michael Obersteiner, Zhu Deng, Zhu Liu","As the COVID-19 virus spread over the world, governments restricted mobility
to slow transmission. Public health measures had different intensities across
European countries but all had significant impact on peoples daily lives and
economic activities, causing a drop of CO2 emissions of about 10% for the whole
year 2020. Here, we analyze changes in natural gas use in the industry and
built environment sectors during the first half of year 2020 with daily gas
flows data from pipeline and storage facilities in Europe. We find that
reductions of industrial gas use reflect decreases in industrial production
across most countries. Surprisingly, natural gas use in buildings also
decreased despite most people being confined at home and cold spells in March
2020. Those reductions that we attribute to the impacts of COVID-19 remain of
comparable magnitude to previous variations induced by cold or warm climate
anomalies in the cold season. We conclude that climate variations played a
larger role than COVID-19 induced stay-home orders in natural gas consumption
across Europe.",http://arxiv.org/abs/2104.14990v1
"Carbon Leakage in a European Power System with Inhomogeneous Carbon
  Prices",2021-05-12T14:00:30Z,"Markus Schlott, Omar El Sayed, Mariia Bilousova, Fabian Hofmann, Alexander Kies, Horst Stöcker","Global warming is one of the main threats to the future of humanity and
extensive emissions of greenhouse gases are found to be the main cause of
global temperature rise as well as climate change. During the last decades
international attention has focused on this issue, as well as on searching for
viable solutions to mitigate global warming. In this context, the pricing of
greenhouse gas emissions turned out to be the most prominent mechanism: First,
to lower the emissions, and second, to capture their external costs. By now,
various carbon dioxide taxes have been adopted by several countries in Europe
and around the world; moreover, the list of these countries is growing.
However, there is no standardized approach and the price for carbon varies
significantly from one country to another. Regionally diversified carbon prices
in turn lead to carbon leakage, which will offset the climate protection goals.
In this paper, a simplified European power system with flexible carbon prices
regarding the Gross Domestic Product (GDP) is investigated. A distribution
parameter that quantifies carbon leakage is defined and varied together with
the base carbon price, where the combination of both parameters describes the
spatially resolved price distribution, i.e. the effective carbon pricing among
the European regions. It is shown that inhomogeneous carbon prices will indeed
lead to significant carbon leakage across the continent, and that coal-fired
electricity generation will remain a cheap and therefore major source of power
in Eastern and South-Eastern Europe - representing a potential risk for the
long term decarbonization targets within the European Union.",http://arxiv.org/abs/2105.05669v1
Accelerating Weather Prediction using Near-Memory Reconfigurable Fabric,2021-07-19T09:41:19Z,"Gagandeep Singh, Dionysios Diamantopoulos, Juan Gómez-Luna, Christoph Hagleitner, Sander Stuijk, Henk Corporaal, Onur Mutlu","Ongoing climate change calls for fast and accurate weather and climate
modeling. However, when solving large-scale weather prediction simulations,
state-of-the-art CPU and GPU implementations suffer from limited performance
and high energy consumption. These implementations are dominated by complex
irregular memory access patterns and low arithmetic intensity that pose
fundamental challenges to acceleration. To overcome these challenges, we
propose and evaluate the use of near-memory acceleration using a reconfigurable
fabric with high-bandwidth memory (HBM). We focus on compound stencils that are
fundamental kernels in weather prediction models. By using high-level synthesis
techniques, we develop NERO, an FPGA+HBM-based accelerator connected through
OCAPI (Open Coherent Accelerator Processor Interface) to an IBM POWER9 host
system. Our experimental results show that NERO outperforms a 16-core POWER9
system by 5.3x and 12.7x when running two different compound stencil kernels.
NERO reduces the energy consumption by 12x and 35x for the same two kernels
over the POWER9 system with an energy efficiency of 1.61 GFLOPS/Watt and 21.01
GFLOPS/Watt. We conclude that employing near-memory acceleration solutions for
weather prediction modeling is promising as a means to achieve both high
performance and high energy efficiency.",http://arxiv.org/abs/2107.08716v2
"Tackling the Overestimation of Forest Carbon with Deep Learning and
  Aerial Imagery",2021-07-23T15:59:52Z,"Gyri Reiersen, David Dao, Björn Lütjens, Konstantin Klemmer, Xiaoxiang Zhu, Ce Zhang","Forest carbon offsets are increasingly popular and can play a significant
role in financing climate mitigation, forest conservation, and reforestation.
Measuring how much carbon is stored in forests is, however, still largely done
via expensive, time-consuming, and sometimes unaccountable field measurements.
To overcome these limitations, many verification bodies are leveraging machine
learning (ML) algorithms to estimate forest carbon from satellite or aerial
imagery. Aerial imagery allows for tree species or family classification, which
improves the satellite imagery-based forest type classification. However,
aerial imagery is significantly more expensive to collect and it is unclear by
how much the higher resolution improves the forest carbon estimation. This
proposal paper describes the first systematic comparison of forest carbon
estimation from aerial imagery, satellite imagery, and ground-truth field
measurements via deep learning-based algorithms for a tropical reforestation
project. Our initial results show that forest carbon estimates from satellite
imagery can overestimate above-ground biomass by up to 10-times for tropical
reforestation projects. The significant difference between aerial and
satellite-derived forest carbon measurements shows the potential for aerial
imagery-based ML algorithms and raises the importance to extend this study to a
global benchmark between options for carbon measurements.",http://arxiv.org/abs/2107.11320v2
"Ocean Mover's Distance: Using Optimal Transport for Analyzing
  Oceanographic Data",2021-11-16T19:14:33Z,"Sangwon Hyun, Aditya Mishra, Christopher L. Follett, Bror Jonsson, Gemma Kulk, Gael Forget, Marie-Fanny Racault, Thomas Jackson, Stephanie Dutkiewicz, Christian L. Müller, Jacob Bien","Remote sensing observations from satellites and global biogeochemical models
have combined to revolutionize the study of ocean biogeochemical cycling, but
comparing the two data streams to each other and across time remains
challenging due to the strong spatial-temporal structuring of the ocean. Here,
we show that the Wasserstein distance provides a powerful metric for harnessing
these structured datasets for better marine ecosystem and climate predictions.
Wasserstein distance complements commonly used point-wise difference methods
such as the root mean squared error, by quantifying differences in terms of
spatial displacement in addition to magnitude. As a test case we consider
Chlorophyll (a key indicator of phytoplankton biomass) in the North-East
Pacific Ocean, obtained from model simulations, in situ measurements, and
satellite observations. We focus on two main applications: 1) Comparing model
predictions with satellite observations, and 2) temporal evolution of
Chlorophyll both seasonally and over longer time frames. Wasserstein distance
successfully isolates temporal and depth variability and quantifies shifts in
biogeochemical province boundaries. It also exposes relevant temporal trends in
satellite Chlorophyll consistent with climate change predictions. Our study
shows that optimal transport vectors underlying Wasserstein distance provide a
novel visualization tool for testing models and better understanding temporal
dynamics in the ocean.",http://arxiv.org/abs/2111.08736v2
"Empathosphere: Promoting Constructive Communication in Ad-hoc Virtual
  Teams through Perspective-taking Spaces",2021-11-27T00:34:34Z,"Pranav Khadpe, Chinmay Kulkarni, Geoff Kaufman","When members of ad-hoc virtual teams need to collectively ideate or
deliberate, they often fail to engage with each others' perspectives in a
constructive manner. At best, this leads to sub-optimal outcomes and, at worst,
it can cause conflicts that lead to teams not wanting to continue working
together. Prior work has attempted to facilitate constructive communication by
highlighting problematic communication patterns and nudging teams to alter
interaction norms. However, these approaches achieve limited success because
they fail to acknowledge two social barriers: (1) it is hard to reset team
norms mid-interaction, and (2) corrective nudges have limited utility unless
team members believe it is safe to voice their opinion and that their opinion
will be heard. This paper introduces Empathosphere, a chat-embedded
intervention to mitigate these barriers and foster constructive communication
in teams. To mitigate the first barrier, Empathosphere leverages the benefits
of ""experimental spaces"" in dampening existing norms and creating a climate
conducive to change. To mitigate the second barrier, Empathosphere harnesses
the benefits of perspective-taking to cultivate a group climate that promotes a
norm of members speaking up and engaging with each other. Empathosphere
achieves this by orchestrating authentic socio-emotional exchanges designed to
induce perspective-taking. A controlled study (N=110) compared Empathosphere to
an alternate intervention strategy of prompting teams to reflect on their team
experience. We found that Empathosphere led to higher work satisfaction,
encouraged more open communication and feedback within teams, and boosted
teams' desire to continue working together. This work demonstrates that
``experimental spaces,'' particularly those that integrate methods of
encouraging perspective-taking, can be a powerful means of improving
communication in virtual teams.",http://arxiv.org/abs/2111.13782v1
"Decreasing water budget of the Australian continent from Grace satellite
  gravity data",2021-01-27T02:09:42Z,"Craig O'Neill, Serena Chandler-Ho","Increasing aridification of continental areas due to global climate change
has impacted freshwater availability, particularly in extremely dry landmasses,
such as Australia. Multiple demands on water resources require integrated basin
management approaches, necessitating knowledge of total water storage, and
changes in water mass. Such monitoring is not practical at continental scales
using traditional methods. Satellite gravity has proven successful at
documenting changes in total water mass at regional scales, and here we use
data from the Grace and Grace-FO missions, spanning 2002 - 2020, to track
regional water budget trends in Australia most heavily utilised basin systems,
including the Murray-Darling Basin. The period of analysis covers the
Millennium drought (2002-2009) and 2010-11 heavy flooding events, which
contribute significant signal variability. However our extended datasets
demonstrate a negative trend in the geoid anomaly over the Murray-Darling Basin
of -1.5mm, equivalent to a water loss rate of -0.91 Gt yr-1. With the exception
of northern Australia, similar scale geoid declines are observed in most
Australian basin systems analysed - implying declining total water storage.
Long-term declines in water availability require concerted management plans,
balancing the requirements of agriculture and industry, with domestic use,
traditional owners, and healthy freshwater ecosystems.",http://arxiv.org/abs/2101.11167v1
"Towards DeepSentinel: An extensible corpus of labelled Sentinel-1 and -2
  imagery and a general-purpose sensor-fusion semantic embedding model",2021-02-11T20:33:47Z,Lucas Kruitwagen,"Earth observation offers new insight into anthropogenic changes to nature,
and how these changes are effecting (and are effected by) the built environment
and the real economy. With the global availability of medium-resolution
(10-30m) synthetic aperture radar (SAR) Sentinel-1 and multispectral Sentinel-2
imagery, machine learning can be employed to offer these insights at scale,
unbiased to the reporting of companies and countries. In this paper, I
introduce DeepSentinel, a data pipeline and experimentation framework for
producing general-purpose semantic embeddings of paired Sentinel-1 and
Sentinel-2 imagery. I document the development of an extensible corpus of
labelled and unlabelled imagery for the purposes of sensor fusion research.
With this new dataset I develop a set of experiments applying popular
self-supervision methods and encoder architectures to a land cover
classification problem. Tile2vec spatial encoding with a self-attention enabled
ResNet model outperforms deeper ResNet variants as well as pretraining with
variational autoencoding and contrastive loss. All supporting and derived data
and code are made publicly available.",http://arxiv.org/abs/2102.06260v1
"Reducing Surface Wetness Leads to Tropical Hydrological Cycle Regime
  Transition",2021-04-14T17:27:24Z,"Bowen Fan, Zhihong Tan, Tiffany A. Shaw, Edwin S. Kite","Earth's modern climate is characterized by wet, rainy deep tropics, however
paleoclimate and planetary science have revealed a wide range of hydrological
cycle regimes connected to different external parameters. Here we investigate
how surface wetness affects the tropical hydrological cycle. When surface
wetness is decreased in an Earth-like general circulation model, the tropics
remain wet but transition from a rainy to rain-free regime. The rain-free
regime occurs when surface precipitation is suppressed as negative evaporation
(surface condensation) balances moisture flux convergence. The regime
transition is dominated by near-surface relative humidity changes in contrast
to the hypothesis that relative humidity changes are small. We show
near-surface relative humidity changes responsible for the regime transition
are controlled by re-evaporation of stratiform precipitation near the lifting
condensation level. Re-evaporation impacts the near-surface through vertical
mixing. Our results reveal a new rain-free tropical hydrological cycle regime
that goes beyond the wet/dry paradigm.",http://arxiv.org/abs/2104.06995v1
"Consequential LCA for territorial and multimodal transportation
  policies: method and application to the free-floating e-scooter disruption in
  Paris",2021-03-01T01:20:32Z,"Anne de Bortoli, Zoi Christoforou","The indirect environmental impacts of transport disruptions in urban mobility
are frequently overlooked due to a lack of appropriate assessment methods.
Consequential Life Cycle Assessment (CLCA) is a method to capture the
environmental consequences of the entire cause and effect chain of these
disruptions but has never been adapted to transportat disruption at the city
scale. This paper proposes a mathematical formalization of CLCA applied to a
territorial mobility change. The method is applied to quantify the impact on
climate change of the breakthrough of free-floating e-scooters (FFES) in Paris.
A FFES user survey is conducted to estimate the modal shifts due to FFES. Trip
substitutions from all the Parisian modes concerned are considered - personal
or shared bicycles and motor scooters, private car, taxi and ride-hailing, bus,
streetcar, metro and RER (the Paris metropolitan area mass rapid transit
system). All these Parisian modes are assessed for the first time using LCA.
Final results estimate that over one year, the FFES generated an extra thirteen
thousand tons of CO2eq under an assumption of one million users, mainly due to
major shifts coming from lower-emitting modes (60% from the metro and the RER,
22% from active modes). Recommendations are given to enhance their carbon
footprint. A scenario analysis shows that increasing the lifetime mileage is
insufficient to get a positive balance: reducing drastically servicing
emissions is also required. A sensitivity analysis switching the French
electricity mix for eleven other country mixes suggests a better climate change
effect of the FFES in similar metropolitan areas with higher electricity carbon
intensity, such as in Germany and China. Finally, the novelty and the limits of
the method are discussed, as well as the results and the role of e-scooters,
micromobility, and shared vehicles towards a sustainable mobility.",http://arxiv.org/abs/2103.00680v1
Sea Ice Forecasting using Attention-based Ensemble LSTM,2021-07-27T21:37:29Z,"Sahara Ali, Yiyi Huang, Xin Huang, Jianwu Wang","Accurately forecasting Arctic sea ice from subseasonal to seasonal scales has
been a major scientific effort with fundamental challenges at play. In addition
to physics-based earth system models, researchers have been applying multiple
statistical and machine learning models for sea ice forecasting. Looking at the
potential of data-driven sea ice forecasting, we propose an attention-based
Long Short Term Memory (LSTM) ensemble method to predict monthly sea ice extent
up to 1 month ahead. Using daily and monthly satellite retrieved sea ice data
from NSIDC and atmospheric and oceanic variables from ERA5 reanalysis product
for 39 years, we show that our multi-temporal ensemble method outperforms
several baseline and recently proposed deep learning models. This will
substantially improve our ability in predicting future Arctic sea ice changes,
which is fundamental for forecasting transporting routes, resource development,
coastal erosion, threats to Arctic coastal communities and wildlife.",http://arxiv.org/abs/2108.00853v2
Li-doped Beryllonitrene for Enhanced Carbon Dioxide Capture,2021-10-06T05:32:35Z,"Andrew Pu, Xuan Luo","In recent years, the scientific community has given more and more attention
to the issue of climate change and global warming, which is largely attributed
to the massive quantity of carbon dioxide emissions. Thus, the demand for a
carbon dioxide capture material is massive and continuously increasing. In this
study, we perform first-principle calculations based on density functional
theory to investigate the carbon dioxide capture ability of pristine and doped
beryllonitrene. Our results show that carbon dioxide had an adsorption energy
of -0.046 eV on pristine beryllonitrene, so it appears that beryllonitrene has
extremely weak carbon dioxide adsorption ability. Pristine beryllonitrene could
be effectively doped with Lithium atoms, and the resulting Li-doped
beryllonitrene had much stronger interactions with carbon dioxide than pristine
beryllonitrene. The adsorption energy for carbon dioxide on Li-doped
beryllonitrene was -0.408 eV. The adsorption of carbon dioxide on Li-doped
beryllonitrene greatly changed the charge density, projected density of states,
and band structure of the material, demonstrating that it was strongly
adsorbed. This suggests that Li-doping is a viable way to enhance the carbon
dioxide capture ability of beryllonitrene and makes it a possible candidate for
an effective CO$_2$ capture material.",http://arxiv.org/abs/2110.02512v1
The emergence of scale-free fires in Australia,2021-10-19T14:29:34Z,"Giorgio Nicoletti, Leonardo Saravia, Fernando Momo, Amos Maritan, Samir Suweis","Between 2019 and 2020, during the country's hottest and driest year on
record, Australia experienced a dramatic bushfire season, with catastrophic
ecological and environmental consequences. Several studies highlighted how such
abrupt changes in fire regimes may have been in large part a consequence of
climate change and other anthropogenic transformations. Here, we analyze the
monthly evolution of the burned area in Australia from 2000 to 2020, obtained
via satellite imaging through the MODIS platform. We find that the 2019-2020
peak is associated with signatures typically found near critical points. We
introduce a modeling framework based on forest-fire models to study the
properties of these emergent fire outbreaks, showing that the behavior observed
during the 2019-2020 fire season matches the one of a percolation transition,
where system-size outbreaks appear. Our model also highlights the existence of
an absorbing phase transition that might be eventually crossed, after which the
vegetation cannot recover.",http://arxiv.org/abs/2110.10014v3
"Sea-level and summer season orbital insolation as drivers of Arctic
  sea-ice",2021-02-03T13:52:57Z,"Claude Hillaire-Marcel, Anne de Vernal, Michel Crucifix","The sea-ice cover of the Arctic Ocean is an important element of the climate
and ocean system in the Northern Hemisphere as it impacts albedo, atmospheric
pressure regimes, CO2-exchange at the ocean/atmosphere interface as well as the
North Atlantic freshwater budget and thermohaline circulation [1]. Due to
global warming, the Arctic sea-ice cover is presently evolving at an
unprecedent rate towards full melt during the summer season, driving the
so-called ""Arctic amplification"" [2]. However, the Arctic sea-ice has also
experienced large amplitude variations, from seasonal to orbital (Milankovitch)
time scales, in the past. Recent studies led to suggest that whereas insolation
has been a major driver of Arctic sea-ice variability through time, sea-level
changes governed the development of ""sea-ice factories"" over shelves (Figure
1), thus fine-tuning the response of the Arctic Ocean to glacial/interglacial
oscillations that is slightly out of phase compared to lower latitudes [3,4].
We discuss below how insolation and sea-level changes may have interacted and
controlled the sea-ice cover of the Arctic Ocean during warm past intervals and
how they could still interfere in the future.",http://arxiv.org/abs/2102.02067v2
Zeoco: An insight into daily carbon footprint consumption,2021-02-11T18:51:41Z,"Karthik Ramakrishnan, Gokul P, Preet Batavia, Shreesh Tripathi","Climate change, which is now considered one of the biggest threats to
humanity, is also the reason behind various other environmental concerns.
Continued negligence might lead us to an irreparably damaged environment. After
the partial failure of the Paris Agreement, it is quite evident that we as
individuals need to come together to bring about a change on a large scale to
have a significant impact. This paper discusses our approach towards obtaining
a realistic measure of the carbon footprint index being consumed by a user
through day-to-day activities performed via a smart phone app and offering
incentives in weekly and monthly leader board rankings along with a reward
system. The app helps ease out decision makings on tasks like travel, shopping,
electricity consumption, and gain a different and rather numerical perspective
over the daily choices.",http://arxiv.org/abs/2102.06185v1
The Dimmest State of the Sun,2021-02-18T17:13:19Z,"K. L. Yeo, S. K. Solanki, N. A. Krivova, M. Rempel, L. S. Anusha, A. I. Shapiro, R. V. Tagirov, V. Witzke","How the solar electromagnetic energy entering the Earth's atmosphere varied
since pre-industrial times is an important consideration in the climate change
debate. Detrimental to this debate, estimates of the change in total solar
irradiance (TSI) since the Maunder minimum, an extended period of weak solar
activity preceding the industrial revolution, differ markedly, ranging from a
drop of 0.75 Wm-2 to a rise of 6.3 Wm-2. Consequently, the exact contribution
by solar forcing to the rise in global temperatures over the past centuries
remains inconclusive. Adopting a novel approach based on state-of-the-art solar
imagery and numerical simulations, we establish the TSI level of the Sun when
it is in its least-active state to be 2.0 +/- 0.7 Wm-2 below the 2019 level.
This means TSI could not have risen since the Maunder minimum by more than this
amount, thus restricting the possible role of solar forcing in global warming.",http://arxiv.org/abs/2102.09487v1
"Two-stage Planning for Electricity-Gas Coupled Integrated Energy System
  with CCUS Considering Carbon Tax and Price Uncertainty",2021-07-19T19:49:27Z,"Ang Xuan, Xinwei Shen, Qinglai Guo, Hongbin Sun","In this article, we propose two-stage planning models for Electricity-Gas
Coupled Integrated Energy System (EGC-IES), in which traditional thermal power
plants (TTPPs) are considered to be retrofitted into carbon capture power
plants (CCPPs), with power to gas (PtG) coupling CCPPs to gas system. The
sizing and siting of carbon capture, utilisation and storage (CCUS)/PtG
facilities, as well as the operation cost of TTPPs/CCPPs/gas sources/PtG, are
all considered in the proposed model, including penalty on carbon emissions and
revenue of CCUS. With changing policy on climate change and carbon emission
regulation, the uncertainties of carbon price and carbon tax are also analysed
and considered in the proposed planning model. The stochastic planning, and
robust planning methods are introduced to verify mutually through economic and
carbon indices. The proposed methods' effectiveness in reducing carbon
emissions, increasing profit of CCUS from EGC-IES are demonstrated through
various cases and discussions.",http://arxiv.org/abs/2107.09127v2
"Estimation of functional diversity and species traits from ecological
  monitoring data",2021-07-29T07:39:49Z,"Alexey Ryabov, Bernd Blasius, Helmut Hillebrand, Irina Olenina, Thilo Gross","The twin crises of climate change and biodiversity loss define a strong need
for functional diversity monitoring. While the availability of high-quality
ecological monitoring data is increasing, the quantification of functional
diversity so far requires the identification of species traits, for which data
is harder to obtain. However, the traits that are relevant for the ecological
function of a species also shape its performance in the environment and hence
should be reflected indirectly in its spatio-temporal distribution. Thus it may
be possible to reconstruct these traits from a sufficiently extensive
monitoring dataset. Here we use diffusion maps, a deterministic and de-facto
parameter-free analysis method, to reconstruct a proxy representation of the
species' traits directly from monitoring data and use it to estimate functional
diversity. We demonstrate this approach both with simulated data and real-world
phytoplankton monitoring data from the Baltic sea. We anticipate that wider
application of this approach to existing data could greatly advance the
analysis of changes in functional biodiversity.",http://arxiv.org/abs/2107.13792v2
"Most Probable Transitions from Metastable to Oscillatory Regimes in a
  Carbon Cycle System",2021-09-30T08:00:31Z,"Wei Wei, Jianyu Hu, Jianyu Chen, Jinqiao Duan","Global climate changes are related to the ocean's store of carbon. We study a
carbonate system of the upper ocean, which has metastable and oscillatory
regimes, under small random fluctuations. We calculate the most probable
transition path via a geometric minimum action method in the context of the
large deviations theory. By examining the most probable transition paths from
metastable to oscillatory regimes for various external carbon input rates, we
find two different transition patterns, which gives us an early warning sign
for the dramatic change in the carbonate state of the ocean.",http://arxiv.org/abs/2109.14905v3
"The impacts of the electricity demand pattern on electricity system cost
  and the electricity supply mix: a comprehensive modeling analysis for Europe",2021-06-10T00:26:34Z,"Xiaoming Kan, Lina Reichenberg, Fredrik Hedenus","Energy system models for long-term planning are widely used to explore the
future electricity system. Typically, to represent the future electricity
demand in these models, historical demand profiles are used directly or scaled
up linearly. Although the volume change for the electricity demand is
considered, the potential change of the demand pattern is ignored. Meanwhile,
the future electricity demand pattern is highly uncertain due to various
factors, including climate change, e-mobility, electric heating, and electric
cooling. We use a techno-economic cost optimization model to investigate a
stylized case and assess the effects on system cost and electricity supply mix
of assuming different demand patterns for the models. Our results show that
differences in diurnal demand patterns affect the system cost by less than 3%.
Similarly, demand profiles with a flat seasonal variation or a winter peak
result in only minor changes in system cost, as compared to the present demand
profile. Demand profiles with a summer peak may display a system cost increase
of up to 8%, whereas the electricity supply mix may differ by a factor of two.
A more detailed case study is conducted for Europe and the results are
consistent with the findings from the stylized case.",http://arxiv.org/abs/2106.05439v1
"High pCO$_2$ reduces sensitivity to CO$_2$ perturbations on temperate,
  Earth-like planets throughout most of habitable zone",2021-04-02T19:55:10Z,R. J. Graham,"The nearly logarithmic radiative impact of CO$_2$ means that planets near the
outer edge of the liquid water habitable zone (HZ) require $\sim$10$^6$x more
CO$_2$ to maintain temperatures conducive to standing liquid water on the
planetary surface than their counterparts near the inner edge. This logarithmic
radiative response also means that atmospheric CO$_2$ changes of a given mass
will have smaller temperature effects on higher pCO$_2$ planets. Ocean pH is
linked to atmospheric pCO$_2$ through seawater carbonate speciation and calcium
carbonate dissolution/precipitation, and the response of pH to changes in
pCO$_2$ also decreases at higher initial pCO$_2$. Here, we use idealized
climate and ocean chemistry models to demonstrate that CO$_2$ perturbations
large enough to cause catastrophic changes to surface temperature and ocean pH
on low-pCO$_2$ planets in the innermost region of the HZ are likely to have
much smaller effects on planets with higher pCO$_2$. Major bouts of
extraterrestrial fossil fuel combustion or volcanic CO$_2$ outgassing on
high-pCO$_2$ planets in the mid-to-outer HZ should have mild or negligible
impacts on surface temperature and ocean pH. Owing to low pCO$_2$, Phanerozoic
Earth's surface environment may be unusually volatile compared to similar
planets receiving lower instellation.",http://arxiv.org/abs/2104.01224v1
"Come back when you are charged! Self-Organized Charging for Electric
  Vehicles",2021-06-08T08:36:16Z,Benjamin Leiding,"Dwindling nonrenewable fuel reserves, progressing severe environmental
pollution, and accelerating climate change require society to reevaluate
existing transportation concepts. While electric vehicles (EVs) have become
more popular and slowly gain widespread adoption, the corresponding battery
charging infrastructures still limits EVs' use in our everyday life. This is
especially true for EV owners that do not have the option to operate charging
hardware, such as wall boxes, at their premises. Charging an EV without an
at-home wall box is time-consuming since the owner has to drive to the charger,
charge the vehicle while waiting nearby, and finally drive back home. Thus, a
convenient and easy-to-use solution is required to overcome the issue and
incentivize EVs for daily commuters. Therefore, we propose an ecosystem and a
service platform for (semi-)autonomous electric vehicles that allow them to
utilize their ""free""-time, e.g., at night, to access public and private
charging infrastructure, charge their batteries, and get back home before the
owner needs the car again. To do so, we utilize the concept of the
Machine-to-Everything Economy (M2X Economy) and outline a decentralized
ecosystem for smart machines that transact, interact and collaborate via
blockchain-based smart contracts to enable a convenient battery charging
marketplace for (semi-)autonomous EVs.",http://arxiv.org/abs/2106.11025v1
"Self-Attentive Ensemble Transformer: Representing Ensemble Interactions
  in Neural Networks for Earth System Models",2021-06-21T18:17:34Z,Tobias Sebastian Finn,"Ensemble data from Earth system models has to be calibrated and
post-processed. I propose a novel member-by-member post-processing approach
with neural networks. I bridge ideas from ensemble data assimilation with
self-attention, resulting into the self-attentive ensemble transformer. Here,
interactions between ensemble members are represented as additive and dynamic
self-attentive part. As proof-of-concept, I regress global ECMWF ensemble
forecasts to 2-metre-temperature fields from the ERA5 reanalysis. I demonstrate
that the ensemble transformer can calibrate the ensemble spread and extract
additional information from the ensemble. As it is a member-by-member approach,
the ensemble transformer directly outputs multivariate and spatially-coherent
ensemble members. Therefore, self-attention and the transformer technique can
be a missing piece for a non-parametric post-processing of ensemble data with
neural networks.",http://arxiv.org/abs/2106.13924v2
"Sensitivity of airborne transmission of enveloped viruses to seasonal
  variation in indoor relative humidity",2021-06-28T21:10:51Z,"Alison Robey, Laura Fierce","In temperate climates, infection rates of enveloped viruses peak during the
winter. While these seasonal trends are established in influenza and human
coronaviruses, the mechanisms driving the variation remain poorly understood
and thus difficult to extend to similar viruses like SARS-CoV-2. In this study,
we use the Quadrature-based model of Respiratory Aerosol and Droplets (QuaRAD)
to explore the sensitivity of airborne transmission to the seasonal variation
in indoor relative humidity across the wide range of relevant conditions, using
SARS-CoV-2 as an example. Relative humidity impacts the evaporation rate and
equilibrium size of airborne particles, which in turn may impact particle
removal rates and virion viability. Across a large ensemble of scenarios, we
found that the dry indoor conditions typical of the winter season lead to
slower inactivation than in the more humid summer season; in poorly ventilated
spaces, this reduction in inactivation rates increases the concentration of
active virions, but this effect was important when the susceptible person was
farther than 2 m downwind of the infectious person. On the other hand, changes
in particle settling velocity with relative humidity did not significantly
affect the removal or travel distance of virus-laden scenarios.",http://arxiv.org/abs/2106.14985v1
"Mobile Phone Location Data for Disasters: A Review from Natural Hazards
  and Epidemics",2021-08-05T21:03:45Z,"Takahiro Yabe, Nicholas K W Jones, P Suresh C Rao, Marta C Gonzalez, Satish V Ukkusuri","Rapid urbanization and climate change trends are intertwined with complex
interactions of various social, economic, and political factors. The increased
trends of disaster risks have recently caused numerous events, ranging from
unprecedented category 5 hurricanes in the Atlantic Ocean to the COVID-19
pandemic. While regions around the world face urgent demands to prepare for,
respond to, and to recover from such disasters, large-scale location data
collected from mobile phone devices have opened up novel approaches to tackle
these challenges. Mobile phone location data have enabled us to observe,
estimate, and model human mobility dynamics at an unprecedented spatio-temporal
granularity and scale. The COVID-19 pandemic has spurred the use of mobile
phone location data for pandemic and disaster response. However, there is a
lack of a comprehensive review that synthesizes the last decade of work
leveraging mobile phone location data and case studies of natural hazards and
epidemics. We address this gap by summarizing the existing work, and pointing
promising areas and future challenges for using data to support disaster
response and recovery.",http://arxiv.org/abs/2108.02849v1
"EVGen: Adversarial Networks for Learning Electric Vehicle Charging Loads
  and Hidden Representations",2021-08-09T00:23:47Z,"Robert Buechler, Emmanuel Balogun, Arun Majumdar, Ram Rajagopal","The nexus between transportation, the power grid, and consumer behavior is
more pronounced than ever before as the race to decarbonize the transportation
sector intensifies. Electrification in the transportation sector has led to
technology shifts and rapid deployment of electric vehicles (EVs). The
potential increase in stochastic and spatially heterogeneous charging load
presents a unique challenge that is not well studied, and will have significant
impacts on grid operations, emissions, and system reliability if not managed
effectively. Realistic scenario generators can help operators prepare, and
machine learning can be leveraged to this end. In this work, we develop
generative adversarial networks (GANs) to learn distributions of electric
vehicle (EV) charging sessions and disentangled representations. We show that
this model structure successfully parameterizes unlabeled temporal and power
patterns without supervision and is able to generate synthetic data conditioned
on these parameters. We benchmark the generation capability of this model with
Gaussian Mixture Models (GMMs), and empirically show that our proposed model
framework is better at capturing charging distributions and temporal dynamics.",http://arxiv.org/abs/2108.03762v1
"Dynamic Modelling of Combined Cycle Power Plant for Load Frequency
  Control With Large Penetration of Renewable Energy",2021-08-09T02:32:05Z,"Songyao Jiang, Takeyoshi Kato","As the concern about climate change and energy shortage grow stronger, the
incorporation of renewable energy in the power system in the future is
foreseeable. In a hybrid power system with a large penetration of PV
generation, PV panel is regarded as a negative load in the power system. With
the accurate prediction of PV output power, load frequency control could be
done by controlling the thermal and hydro power plant in the system. Combined
Cycle Power Plant is widely used because of its great advantages of fast
response and high efficiency. This article is focusing on the mathematical
modelling and analyzing of Combined Cycle Power Plant for the frequency control
purpose in a model of hybrid system with large renewable energy generation.",http://arxiv.org/abs/2108.03783v1
"Self-supervised Contrastive Learning for Irrigation Detection in
  Satellite Imagery",2021-08-12T01:13:04Z,"Chitra Agastya, Sirak Ghebremusse, Ian Anderson, Colorado Reed, Hossein Vahabi, Alberto Todeschini","Climate change has caused reductions in river runoffs and aquifer recharge
resulting in an increasingly unsustainable crop water demand from reduced
freshwater availability. Achieving food security while deploying water in a
sustainable manner will continue to be a major challenge necessitating careful
monitoring and tracking of agricultural water usage. Historically, monitoring
water usage has been a slow and expensive manual process with many
imperfections and abuses. Ma-chine learning and remote sensing developments
have increased the ability to automatically monitor irrigation patterns, but
existing techniques often require curated and labelled irrigation data, which
are expensive and time consuming to obtain and may not exist for impactful
areas such as developing countries. In this paper, we explore an end-to-end
real world application of irrigation detection with uncurated and unlabeled
satellite imagery. We apply state-of-the-art self-supervised deep learning
techniques to optical remote sensing data, and find that we are able to detect
irrigation with up to nine times better precision, 90% better recall and 40%
more generalization ability than the traditional supervised learning methods.",http://arxiv.org/abs/2108.05484v1
"Assessment of waterfront office redevelopment plan on optimal building
  energy demand and rooftop photovoltaics for urban decarbonization",2021-08-20T07:24:36Z,"Younghun Choi, Takuro Kobashi, Yoshiki Yamagata, Akito Murayama","Designing waterfront redevelopment generally focuses on attractiveness,
leisure, and beauty, resulting in various types of building and block shapes
with limited considerations on environmental aspects. However, increasing
climate change impacts necessitate these buildings to be sustainable,
resilient, and zero CO2 emissions. By producing five scenarios (plus existing
buildings) with constant floor areas, we investigated how building and district
form with building integrated photovoltaics (BIPV) affect energy consumption
and production, self-sufficiency, CO2 emission, and energy costs in the context
of waterfront redevelopment in Tokyo. From estimated hourly electricity demands
of the buildings, techno-economic analyses are conducted for rooftop PV systems
for 2018 and 2030 with declining costs of rooftop PV systems. We found that
environmental building designs with rooftop PV system are increasingly
economical in Tokyo with CO2 emission reduction of 2-9% that depends on rooftop
sizes. Payback periods drop from 14 years in 2018 to 6 years in 2030. Toward
net-zero CO2 emissions by 2050, immediate actions are necessary to install
rooftop PVs on existing and new buildings with energy efficiency improvements
by construction industry and building owners. To facilitate such actions,
national and local governments need to adopt appropriate policies.",http://arxiv.org/abs/2108.09029v1
"2020 U.S. presidential election in swing states: Gender differences in
  Twitter conversations",2021-08-21T01:31:03Z,"Amir Karami, Spring B. Clark, Anderson Mackenzie, Dorathea Lee, Michael Zhu, Hannah R. Boyajieff, Bailey Goldschmidt","Social media is commonly used by the public during election campaigns to
express their opinions regarding different issues. Among various social media
channels, Twitter provides an efficient platform for researchers and
politicians to explore public opinion regarding a wide range of topics such as
the economy and foreign policy. Current literature mainly focuses on analyzing
the content of tweets without considering the gender of users. This research
collects and analyzes a large number of tweets and uses computational, human
coding, and statistical analyses to identify topics in more than 300,000 tweets
posted during the 2020 U.S. presidential election and to compare female and
male users regarding the average weight of the discussed topics. Our findings
are based upon a wide range of topics, such as tax, climate change, and the
COVID-19 pandemic. Out of the topics, there exists a significant difference
between female and male users for more than 70% of topics.",http://arxiv.org/abs/2108.09416v2
A machine learning model of Arctic sea ice motions,2021-08-24T19:23:47Z,"Jun Zhai, Cecilia M. Bitz","Sea ice motions play an important role in the polar climate system by
transporting pollutants, heat, water and salt as well as changing the ice
cover. Numerous physics-based models have been constructed to represent the sea
ice dynamical interaction with the atmosphere and ocean. In this study, we
propose a new data-driven deep-learning approach that utilizes a convolutional
neural network (CNN) to model how Arctic sea ice moves in response to surface
winds given its initial ice velocity and concentration a day earlier. Results
show that CNN computes the sea ice response with a correlation of 0.82 on
average with respect to reality, which surpasses a set of local point-wise
predictions and a leading thermodynamic-dynamical model, CICE5. The superior
predictive skill of CNN suggests the important role played by the connective
patterns of the predictors of the sea ice motion.",http://arxiv.org/abs/2108.10925v1
Full-Cycle Energy Consumption Benchmark for Low-Carbon Computer Vision,2021-08-30T18:22:36Z,"Bo Li, Xinyang Jiang, Donglin Bai, Yuge Zhang, Ningxin Zheng, Xuanyi Dong, Lu Liu, Yuqing Yang, Dongsheng Li","The energy consumption of deep learning models is increasing at a
breathtaking rate, which raises concerns due to potential negative effects on
carbon neutrality in the context of global warming and climate change. With the
progress of efficient deep learning techniques, e.g., model compression,
researchers can obtain efficient models with fewer parameters and smaller
latency. However, most of the existing efficient deep learning methods do not
explicitly consider energy consumption as a key performance indicator.
Furthermore, existing methods mostly focus on the inference costs of the
resulting efficient models, but neglect the notable energy consumption
throughout the entire life cycle of the algorithm. In this paper, we present
the first large-scale energy consumption benchmark for efficient computer
vision models, where a new metric is proposed to explicitly evaluate the
full-cycle energy consumption under different model usage intensity. The
benchmark can provide insights for low carbon emission when selecting efficient
deep learning algorithms in different model usage scenarios.",http://arxiv.org/abs/2108.13465v2
"Transfer Learning Approaches for Knowledge Discovery in Grid-based
  Geo-Spatiotemporal Data",2021-10-02T16:55:34Z,"Aishwarya Sarkar, Jien Zhang, Chaoqun Lu, Ali Jannesari","Extracting and meticulously analyzing geo-spatiotemporal features is crucial
to recognize intricate underlying causes of natural events, such as floods.
Limited evidence about hidden factors leading to climate change makes it
challenging to predict regional water discharge accurately. In addition, the
explosive growth in complex geo-spatiotemporal environment data that requires
repeated learning by the state-of-the-art neural networks for every new region
emphasizes the need for new computationally efficient methods, advanced
computational resources, and extensive training on a massive amount of
available monitored data. We, therefore, propose HydroDeep, an effectively
reusable pretrained model to address this problem of transferring knowledge
from one region to another by effectively capturing their intrinsic
geo-spatiotemporal variance. Further, we present four transfer learning
approaches on HydroDeep for spatiotemporal interpretability that improve
Nash-Sutcliffe efficiency by 9% to 108% in new regions with a 95% reduction in
time.",http://arxiv.org/abs/2110.00841v3
"Predicting the Efficiency of CO$_2$ Sequestering by Metal Organic
  Frameworks Through Machine Learning Analysis of Structural and Electronic
  Properties",2021-10-12T05:55:47Z,Mahati Manda,"Due the alarming rate of climate change, the implementation of efficient
CO$_2$ capture has become crucial. This project aims to create an algorithm
that predicts the uptake of CO$_2$ adsorbing Metal-Organic Frameworks (MOFs) by
using Machine Learning. These values will in turn gauge the efficiency of these
MOFs and provide scientists who are looking to maximize the uptake a way to
know whether or not the MOF is worth synthesizing. This algorithm will save
resources such as time and equipment as scientists will be able to disregard
hypothetical MOFs with low efficiencies. In addition, this paper will also
highlight the most important features within the data set. This research will
contribute to enable the rapid synthesis of CO$_2$ adsorbing MOFs.",http://arxiv.org/abs/2110.05753v1
"Losing the battle over best-science guidance early in a crisis: Covid-19
  and beyond",2021-10-18T22:06:38Z,"L. Illari, N. Johnson Restrepo, R. Leahy, N. Velasquez, Y. Lupu, N. F. Johnson","Ensuring widespread public exposure to best-science guidance is crucial in a
crisis, e.g. Covid-19, climate change. Mapping the emitter-receiver dynamics of
Covid-19 guidance among 87 million Facebook users, we uncover a multi-sided
battle over exposure that gets lost well before the pandemic's official
announcement. By the time Covid-19 vaccines emerge, the mainstream majority --
including many parenting communities -- have moved even closer to more extreme
communities. The hidden heterogeneity explains why Facebook's own promotion of
best-science guidance also missed key audience segments. A simple mathematical
model reproduces these exposure dynamics at the system level. Our findings can
be used to tailor guidance at scale while accounting for individual diversity,
and to predict tipping point behavior and system-level responses to
interventions.",http://arxiv.org/abs/2110.09634v1
"DEEPAGÉ: Answering Questions in Portuguese about the Brazilian
  Environment",2021-10-19T14:35:29Z,"Flávio Nakasato Cação, Marcos Menon José, André Seidel Oliveira, Stefano Spindola, Anna Helena Reali Costa, Fábio Gagliardi Cozman","The challenge of climate change and biome conservation is one of the most
pressing issues of our time - particularly in Brazil, where key environmental
reserves are located. Given the availability of large textual databases on
ecological themes, it is natural to resort to question answering (QA) systems
to increase social awareness and understanding about these topics. In this
work, we introduce multiple QA systems that combine in novel ways the BM25
algorithm, a sparse retrieval technique, with PTT5, a pre-trained
state-of-the-art language model. Our QA systems focus on the Portuguese
language, thus offering resources not found elsewhere in the literature. As
training data, we collected questions from open-domain datasets, as well as
content from the Portuguese Wikipedia and news from the press. We thus
contribute with innovative architectures and novel applications, attaining an
F1-score of 36.2 with our best model.",http://arxiv.org/abs/2110.10015v1
"Classification of PS and ABS Black Plastics for WEEE Recycling
  Applications",2021-10-20T12:47:18Z,"Anton Persson, Niklas Dymne, Fernando Alonso-Fernandez","Pollution and climate change are some of the biggest challenges that humanity
is facing. In such a context, efficient recycling is a crucial tool for a
sustainable future. This work is aimed at creating a system that can classify
different types of plastics by using picture analysis, in particular, black
plastics of the type Polystyrene (PS) and Acrylonitrile Butadiene Styrene
(ABS). They are two common plastics from Waste from Electrical and Electronic
Equipment (WEEE). For this purpose, a Convolutional Neural Network has been
tested and retrained, obtaining a validation accuracy of 95%. Using a separate
test set, average accuracy goes down to 86.6%, but a further look at the
results shows that the ABS type is correctly classified 100% of the time, so it
is the PS type that accumulates all the errors. Overall, this demonstrates the
feasibility of classifying black plastics using CNN machine learning
techniques. It is believed that if a more diverse and extensive image dataset
becomes available, a system with higher reliability that generalizes well could
be developed using the proposed methodology.",http://arxiv.org/abs/2110.12896v1
Day-ahead Forecasts of Air Temperature,2021-10-21T10:57:05Z,"Hewei Wang, Muhammad Salman Pathan, Yee Hui Lee, Soumyabrata Dev","Air temperature is an essential factor that directly impacts the weather.
Temperature can be counted as an important sign of climatic change, that
profoundly impacts our health, development, and urban planning. Therefore, it
is vital to design a framework that can accurately predict the temperature
values for considerable lead times. In this paper, we propose a technique based
on exponential smoothing method to accurately predict temperature using
historical values. Our proposed method shows good performance in capturing the
seasonal variability of temperature. We report a root mean square error of
$4.62$ K for a lead time of $3$ days, using daily averages of air temperature
data. Our case study is based on weather stations located in the city of
Alpena, Michigan, United States.",http://arxiv.org/abs/2110.13812v1
"On the Disjoint and Sliding Block Maxima method for piecewise stationary
  time series",2021-10-29T06:46:10Z,"Axel Bücher, Leandra Zanger","Modeling univariate block maxima by the generalized extreme value
distribution constitutes one of the most widely applied approaches in extreme
value statistics. It has recently been found that, for an underlying stationary
time series, respective estimators may be improved by calculating block maxima
in an overlapping way. A proof of concept is provided that the latter finding
also holds in situations that involve certain piecewise stationarities. A weak
convergence result for an empirical process of central interest is provided,
and, as a case-in-point, further details are worked out explicitly for the
probability weighted moment estimator. Irrespective of the serial dependence,
the estimation variance is shown to be smaller for the new estimator, while the
bias was found to be the same or vary comparably little in extensive simulation
experiments. The results are illustrated by Monte Carlo simulation experiments
and are applied to a common situation involving temperature extremes in a
changing climate.",http://arxiv.org/abs/2110.15576v1
"Road Surface Translation Under Snow-covered and Semantic Segmentation
  for Snow Hazard Index",2021-01-14T14:25:12Z,"Takato Yasuno, Junichiro Fujii, Hiroaki Sugawara, Masazumi Amakata","In 2020, there was a record heavy snowfall owing to climate change. In
reality, 2,000 vehicles were stuck on the highway for three days. Because of
the freezing of the road surface, 10 vehicles had a billiard accident. Road
managers are required to provide indicators to alert drivers regarding snow
cover at hazardous locations. This study proposes a deep learning application
with live image post-processing to automatically calculate a snow hazard ratio
indicator. First, the road surface hidden under snow is translated using a
generative adversarial network, pix2pix. Second, snow-covered and road surface
classes are detected by semantic segmentation using DeepLabv3+ with MobileNet
as a backbone. Based on these trained networks, we automatically compute the
road to snow rate hazard index, indicating the amount of snow covered on the
road surface. We demonstrate the applied results to 1,155 live snow images of
the cold region in Japan. We mention the usefulness and the practical
robustness of our study.",http://arxiv.org/abs/2101.05616v4
VConstruct: Filling Gaps in Chl-a Data Using a Variational Autoencoder,2021-01-25T17:49:42Z,"Matthew Ehrler, Neil Ernst","Remote sensing of Chlorophyll-a is vital in monitoring climate change.
Chlorphyll-a measurements give us an idea of the algae concentrations in the
ocean, which lets us monitor ocean health. However, a common problem is that
the satellites used to gather the data are commonly obstructed by clouds and
other artifacts. This means that time series data from satellites can suffer
from spatial data loss.
  There are a number of algorithms that are able to reconstruct the missing
parts of these images to varying degrees of accuracy, with Data INterpolating
Empirical Orthogonal Functions (DINEOF) being the current standard. However,
DINEOF is slow, suffers from accuracy loss in temporally homogenous waters,
reliant on temporal data, and only able to generate a single potential
reconstruction.
  We propose a machine learning approach to reconstruction of Chlorophyll-a
data using a Variational Autoencoder (VAE). Our accuracy results to date are
competitive with but slightly less accurate than DINEOF. We show the benefits
of our method including vastly decreased computation time and ability to
generate multiple potential reconstructions. Lastly, we outline our planned
improvements and future work.",http://arxiv.org/abs/2101.10260v1
"The Market Measure of Carbon Risk and its Impact on the Minimum Variance
  Portfolio",2021-01-26T08:52:15Z,"Théo Roncalli, Théo Le Guenedal, Frédéric Lepetit, Thierry Roncalli, Takaya Sekine","Like ESG investing, climate change is an important concern for asset managers
and owners, and a new challenge for portfolio construction. Until now,
investors have mainly measured carbon risk using fundamental approaches, such
as with carbon intensity metrics. Nevertheless, it has not been proven that
asset prices are directly impacted by these fundamental-based measures. In this
paper, we focus on another approach, which consists in measuring the
sensitivity of stock prices with respect to a carbon risk factor. In our
opinion, carbon betas are market-based measures that are complementary to
carbon intensities or fundamental-based measures when managing investment
portfolios, because carbon betas may be viewed as an extension or
forward-looking measure of the current carbon footprint. In particular, we show
how this new metric can be used to build minimum variance strategies and how
they impact their portfolio construction.",http://arxiv.org/abs/2101.10635v1
A modular framework for extreme weather generation,2021-02-05T15:12:10Z,"Bianca Zadrozny, Campbell D. Watson, Daniela Szwarcman, Daniel Civitarese, Dario Oliveira, Eduardo Rodrigues, Jorge Guevara","Extreme weather events have an enormous impact on society and are expected to
become more frequent and severe with climate change. In this context,
resilience planning becomes crucial for risk mitigation and coping with these
extreme events. Machine learning techniques can play a critical role in
resilience planning through the generation of realistic extreme weather event
scenarios that can be used to evaluate possible mitigation actions. This paper
proposes a modular framework that relies on interchangeable components to
produce extreme weather event scenarios. We discuss possible alternatives for
each of the components and show initial results comparing two approaches on the
task of generating precipitation scenarios.",http://arxiv.org/abs/2102.04534v1
An Overview of Agent-based Traffic Simulators,2021-02-15T12:13:01Z,"Johannes Nguyen, Simon T. Powers, Neil Urquhart, Thomas Farrenkopf, Michael Guckert","Individual traffic significantly contributes to climate change and
environmental degradation. Therefore, innovation in sustainable mobility is
gaining importance as it helps to reduce environmental pollution. However,
effects of new ideas in mobility are difficult to estimate in advance and
strongly depend on the individual traffic participants. The application of
agent technology is particularly promising as it focuses on modelling
heterogeneous individual preferences and behaviours. In this paper, we show how
agent-based models are particularly suitable to address three pressing research
topics in mobility: 1. Social dilemmas in resource utilisation; 2. Digital
connectivity; and 3. New forms of mobility. We then explain how the features of
several agent-based simulators are suitable for addressing these topics. We
assess the capability of simulators to model individual travel behaviour,
discussing implemented features and identifying gaps in functionality that we
consider important.",http://arxiv.org/abs/2102.07505v2
Dynamics of Moisture Transport in Plant Cuticles: The Role of Cellulose,2021-02-17T10:14:17Z,"E. C. Tredenick, G. D. Farquhar","Food production needs to increase significantly in 30 years, and water loss
from plants may hold one key, especially relevant in a time of climate change.
The plant leaf cuticle is the final defence of leaves in drought and at night,
and so by understanding water movement in the leaf with mathematical modelling
techniques, we can move towards future proofing our crops and native plant
ecology. We identify new mechanisms of water movement properties of plant
cuticles and utilise this understanding to create a novel mathematical model.
We model water sorption in astomatous isolated cuticles, utilising three
separate pathways of cellulose, aqueous pores and lipophilic. The results of
the model compare well to data both over time and increasing humidity. The
sensitivity analysis shows that the grouping of parameters influencing plant
species variations has the largest effect on sorption, the parameters
influencing cellulose are very influential, and aqueous pores less so but still
relevant. Cellulose is important to include in a water transport model for
plant cuticles, as it plays a significant role in diffusion and adsorption in
the cuticle and the cuticle surfaces.",http://arxiv.org/abs/2102.08666v1
EscapeWildFire: Assisting People to Escape Wildfires in Real-Time,2021-02-23T08:58:37Z,"Andreas Kamilaris, Jean-Baptiste Filippi, Chirag Padubidri, Jesper Provoost, Savvas Karatsiolis, Ian Cole, Wouter Couwenbergh, Evi Demetriou","Over the past couple of decades, the number of wildfires and area of land
burned around the world has been steadily increasing, partly due to climatic
changes and global warming. Therefore, there is a high probability that more
people will be exposed to and endangered by forest fires. Hence there is an
urgent need to design pervasive systems that effectively assist people and
guide them to safety during wildfires. This paper presents EscapeWildFire, a
mobile application connected to a backend system which models and predicts
wildfire geographical progression, assisting citizens to escape wildfires in
real-time. A small pilot indicates the correctness of the system. The code is
open-source; fire authorities around the world are encouraged to adopt this
approach.",http://arxiv.org/abs/2102.11558v1
"Resilience of Interdependent Urban Socio-Physical Systems using
  Large-Scale Mobility Data: Modeling Recovery Dynamics",2021-04-15T17:06:58Z,"Takahiro Yabe, P. Suresh C. Rao, Satish V. Ukkusuri","Cities are complex systems comprised of socioeconomic systems relying on
critical services delivered by multiple physical infrastructure networks. Due
to interdependencies between social and physical systems, disruptions caused by
natural hazards may cascade across systems, amplifying the impact of disasters.
Despite the increasing threat posed by climate change and rapid urban growth,
how to design interdependencies between social and physical systems to achieve
resilient cities have been largely unexplored. Here, we study the
socio-physical interdependencies in urban systems and their effects on disaster
recovery and resilience, using large-scale mobility data collected from Puerto
Rico during Hurricane Maria. We find that as cities grow in scale and expand
their centralized infrastructure systems, the recovery efficiency of critical
services improves, however, curtails the self-reliance of socio-economic
systems during crises. Results show that maintaining self-reliance among social
systems could be key in developing resilient urban socio-physical systems for
cities facing rapid urban growth.",http://arxiv.org/abs/2104.07603v1
"Rapid Detection of Aircrafts in Satellite Imagery based on Deep Neural
  Networks",2021-04-21T18:13:16Z,"Arsalan Tahir, Muhammad Adil, Arslan Ali","Object detection is one of the fundamental objectives in Applied Computer
Vision. In some of the applications, object detection becomes very challenging
such as in the case of satellite image processing. Satellite image processing
has remained the focus of researchers in domains of Precision Agriculture,
Climate Change, Disaster Management, etc. Therefore, object detection in
satellite imagery is one of the most researched problems in this domain. This
paper focuses on aircraft detection. in satellite imagery using deep learning
techniques. In this paper, we used YOLO deep learning framework for aircraft
detection. This method uses satellite images collected by different sources as
learning for the model to perform detection. Object detection in satellite
images is mostly complex because objects have many variations, types, poses,
sizes, complex and dense background. YOLO has some limitations for small size
objects (less than$\sim$32 pixels per object), therefore we upsample the
prediction grid to reduce the coarseness of the model and to accurately detect
the densely clustered objects. The improved model shows good accuracy and
performance on different unknown images having small, rotating, and dense
objects to meet the requirements in real-time.",http://arxiv.org/abs/2104.11677v1
"The Impact of Brazil on Global Grain Dynamics: A Study on Cross-Market
  Volatility Spillovers",2021-04-22T15:04:47Z,"Felipe Avileis, Mindy Mallory","Brazil rose as a global powerhouse producer of soybeans and corn over the
past 15 years has fundamentally changed global markets in these commodities.
This is arguably due to the development of varieties of soybean and corn
adapted to climates within Brazil, allowing farmers to double-crop corn after
soybeans in the same year. Corn and soybean market participants increasingly
look to Brazil for fundamental price information, and studies have shown that
the two markets have become cointegrated. However little is known about how
much volatility from each market spills over to the other. In this article we
measure volatility spillover ratios between U.S. and Brazilian first crop corn,
second crop corn, and soybeans. We find that linkages between the two countries
increased after double cropping corn after soybeans expanded, volatility
spillover magnitudes expanded, and the direction of volatility spillovers
flipped from U.S. volatility spilling over to Brazil before double cropping, to
Brazil spilling over to U.S. after double cropping.",http://arxiv.org/abs/2104.12706v1
"Vehicle Emissions Prediction with Physics-Aware AI Models: Preliminary
  Results",2021-05-02T01:52:59Z,"Harish Panneer Selvam, Yan Li, Pengyue Wang, William F. Northrop, Shashi Shekhar","Given an on-board diagnostics (OBD) dataset and a physics-based emissions
prediction model, this paper aims to develop an accurate and
computational-efficient AI (Artificial Intelligence) method that predicts
vehicle emissions. The problem is of societal importance because vehicular
emissions lead to climate change and impact human health. This problem is
challenging because the OBD data does not contain enough parameters needed by
high-order physics models. Conversely, related work has shown that low-order
physics models have poor predictive accuracy when using available OBD data.
This paper uses a divergent window co-occurrence pattern detection method to
develop a spatiotemporal variability-aware AI model for predicting emission
values from the OBD datasets. We conducted a case study using real-world OBD
data from a local public transportation agency. Results show that the proposed
AI method has approximately 65% improved predictive accuracy than a non-AI
low-order physics model and is approximately 35% more accurate than a baseline
model.",http://arxiv.org/abs/2105.00375v1
"Hurricane Simulation and Nonstationary Extremal Analysis for a Changing
  Climate",2021-05-10T11:06:45Z,"Meagan Carney, Holger Kantz, Matthew Nicol","Particularly important to hurricane risk assessment for coastal regions is
finding accurate approximations of return probabilities of maximum windspeeds.
Since extremes in maximum windspeed have a direct relationship to minimums in
the central pressure, accurate windspeed return estimates rely heavily on
proper modeling of the central pressure minima. Using the HURDAT2 database, we
show that the central pressure minima of hurricane events can be appropriately
modeled by a nonstationary extreme value distribution. We also provide and
validate a Poisson distribution with a nonstationary rate parameter to model
returns of hurricane events. Using our nonstationary models and numerical
simulation techniques from established literature, we perform a simulation
study to model returns of maximum windspeeds of hurricane events along the
North Atlantic Coast. We show that our revised model agrees with current data
and results in an expectation of higher maximum windspeeds for all regions
along the coast with the highest maximum windspeeds occurring in the northern
part of the coast.",http://arxiv.org/abs/2105.04267v2
Global Assessment of Oil and Gas Methane Ultra-Emitters,2021-04-28T17:55:39Z,"Thomas Lauvaux, Clément Giron, Matthieu Mazzolini, Alexandre d'Aspremont, Riley Duren, Dan Cusworth, Drew Shindell, Philippe Ciais","Methane emissions from oil and gas (O&G) production and transmission
represent a significant contribution to climate change. These emissions
comprise sporadic releases of large amounts of methane during maintenance
operations or equipment failures not accounted for in current inventory
estimates. We collected and analyzed hundreds of very large releases from
atmospheric methane images sampled by the TROPOspheric Monitoring Instrument
(TROPOMI) over 2019 and 2020 to quantify emissions from O&G ultra-emitters.
Ultra-emitters are primarily detected over the largest O&G basins of the world,
following a power-law relationship with noticeable variations across countries
but similar regression slopes. With a total contribution equivalent to 8-12% of
the global O&G production methane emissions, mitigation of ultra-emitters is
largely achievable at low costs and would lead to robust net benefits in
billions of US dollars for the six major producing countries when incorporating
recent estimates of societal costs of methane.",http://arxiv.org/abs/2105.06387v1
"Are renewable energies on a sustained path? Analysis of selected
  case-studies from the pre-pandemic-era",2021-05-17T13:48:57Z,"Alessandro Bessi, Mariangela Guidolin, Piero Manfredi","Provided widespread vaccination will bring the COVID-19 pandemic under full
control worldwide, the contrast to climate change and the energy transition as
one of its main actions will return at the top of national and international
policy agendas. This paper employs multivariate diffusion models to investigate
and quantitatively assess the competitive power of renewable energy
technologies and their perspectives along the invoked energy transition. The
study was conducted for the period 1965-2019 on a number of selected case
studies, that were considered critically representative of the current
transition process in view of their energy and political context. The dynamic
relationship between renewable technologies and natural gas has been at the
core of the analysis, trying to establish whether gas could be considered as a
bridging technology or a lock-in. The main findings show that in all the
analyzed countries RETs have exerted a strongly competitive effect towards gas.
In most cases, gas is found to have a bridging role, aiding the uptake of
renewables.",http://arxiv.org/abs/2105.07834v1
"Wildfires vegetation recovery through satellite remote sensing and
  Functional Data Analysis",2021-05-20T21:56:12Z,"Feliu Serra-Burriel, Pedro Delicado, Fernando M. Cucchietti","In recent years wildfires have caused havoc across the world, especially
aggravated in certain regions, due to climate change. Remote sensing has become
a powerful tool for monitoring fires, as well as for measuring their effects on
vegetation over the following years. We aim to explain the dynamics of
wildfires' effects on a vegetation index (previously estimated by causal
inference through synthetic controls) from pre-wildfire available information
(mainly proceeding from satellites). For this purpose, we use regression models
from Functional Data Analysis, where wildfire effects are considered functional
responses, depending on elapsed time after each wildfire, while pre-wildfire
information acts as scalar covariates. Our main findings show that vegetation
recovery after wildfires is a slow process, affected by many pre-wildfire
conditions, among which the richness and diversity of vegetation is one of the
best predictors for the recovery.",http://arxiv.org/abs/2105.10050v1
"Stochastic resonance and amplification in the ac driven Duffing
  oscillator with added noise",2021-05-27T20:19:30Z,"Adriano A. Batista, A. A. Lisboa de Souza, Raoni S. N. Moreira","Stochastic resonance (SR) is a coherence enhancement effect due to noise that
occurs in periodically-driven nonlinear dynamical systems. A very broad range
of physical and biological systems present this effect such as climate change,
neurons, neural networks, lasers, SQUIDS, and tunnel diodes, among many others.
Early theoretical models of SR dealt only with overdamped bistable oscillators.
Here, we propose a simple model that accounts for SR in an underdamped driven
Duffing oscillator with added white noise. Furthermore, we develop a
theoretical method to predict the effect of white noise on the pump, signal,
and idler responses of a Duffing amplifier. We also calculate the power
spectral density of the response of the Duffing amplifier. This approach may
prove to be useful for assessing the robustness of acoustic, phononic, or
mechanical frequency-comb generation to the presence of noise.",http://arxiv.org/abs/2105.13433v2
"Attention Based Semantic Segmentation on UAV Dataset for Natural
  Disaster Damage Assessment",2021-05-30T13:39:03Z,"Tashnim Chowdhury, Maryam Rahnemoonfar","The detrimental impacts of climate change include stronger and more
destructive hurricanes happening all over the world. Identifying different
damaged structures of an area including buildings and roads are vital since it
helps the rescue team to plan their efforts to minimize the damage caused by a
natural disaster. Semantic segmentation helps to identify different parts of an
image. We implement a novel self-attention based semantic segmentation model on
a high resolution UAV dataset and attain Mean IoU score of around 88% on the
test set. The result inspires to use self-attention schemes in natural disaster
damage assessment which will save human lives and reduce economic losses.",http://arxiv.org/abs/2105.14540v2
A Blockchain-based Carbon Credit Ecosystem,2021-07-01T02:29:57Z,"Soheil Saraji, Mike Borowczak","Climate change and global warming are the significant challenges of the new
century. A viable solution to mitigate greenhouse gas emissions is via a
globally incentivized market mechanism proposed in the Kyoto protocol. In this
view, the carbon dioxide (or other greenhouse gases) emission is considered a
commodity, forming a carbon trading system. There have been attempts in
developing this idea in the past decade with limited success. The main
challenges of current systems are fragmented implementations, lack of
transparency leading to over-crediting and double-spending, and substantial
transaction costs that transfer wealth to brokers and agents. We aim to create
a Carbon Credit Ecosystem using smart contracts that operate in conjunction
with blockchain technology in order to bring more transparency, accessibility,
liquidity, and standardization to carbon markets. This ecosystem includes a
tokenization mechanism to securely digitize carbon credits with clear minting
and burning protocols, a transparent mechanism for distribution of tokens, a
free automated market maker for trading the carbon tokens, and mechanisms to
engage all stakeholders, including the energy industry, project verifiers,
liquidity providers, NGOs, concerned citizens, and governments. This approach
could be used in a variety of other credit/trading systems.",http://arxiv.org/abs/2107.00185v1
"The Risk of Cascading Failures in Electrical Grids Triggered by Extreme
  Weather Events",2021-07-01T15:41:13Z,"Julian M. Stürmer, Anton Plietzsch, Mehrnaz Anvari","One of the serious threats related to climate change is an increase in the
number and severity of extreme weather events. A prominent example are
hurricanes, which result from rising coastal temperatures. Such extreme weather
events can cause extensive damages in infrastructure systems and, potentially,
destroy components in electricity transmission networks, which in turn can lead
to major blackouts. In our recent work, we study the risk of hurricane-induced
cascading failures in power systems of the U.S. East Coast using historical
wind field data sets. For this purpose, we model the destruction of overhead
transmission lines during hurricanes, where each failing line causes a
rerouting of power flow in the system. New power flows can overload additional
lines, which are then automatically deactivated and thereby cause another
rerouting of power flow and so on. Ultimately, a cascade of failures can unfold
that can black out large parts of the power system.",http://arxiv.org/abs/2107.00829v1
"Developing system of wireless sensor network and unmaned aerial vehicle
  for agriculture inspection",2021-06-20T10:07:02Z,"Nguyen Truong Son, Quach Cong Hoang, Dang Thi Huong Giang, Vu Minh Trung, Vuong Quang Huy, Mai Anh Tuan","Agricultural production using high technology is an inevitable trend in
Vietnam. Especially for material crops which typically need large growing
areas, wireless sensor networks has been clearly playing a significant role in
increasing productivity, monitoring pests and diseases, mitigating the impact
of climate change, and reducing the direct labor of cultivators. This paper
constructs an experimental model of agricultural crop field monitoring using a
combination of LoRa wireless sensor networks and unmanned aerial vehicles to
collect data on conditions of weather and soil, plant health, which helps
growers easily making right decisions on solutions for irrigation, pest
treatment, and fertilization with the currently planted crops. The system has
been developed and experimentized in the field to evaluate some basic features
and justified the stability and reliability of the obtained data.",http://arxiv.org/abs/2107.01008v1
Ecosystems are showing symptoms of resilience loss,2021-07-07T15:36:18Z,Juan C. Rocha,"Ecosystems around the world are at risk of critical transitions due to
increasing anthropogenic pressures and climate change. Yet it is unclear where
the risks are higher or where in the world ecosystems are more vulnerable. Here
I measure resilience of primary productivity proxies for marine and terrestrial
ecosystems globally. Up to 29% of global terrestrial ecosystem, and 24% marine
ones, show symptoms of resilience loss. These symptoms are shown in all biomes,
but Arctic tundra and boreal forest are the most affected, as well as the
Indian Ocean and Eastern Pacific. Although the results are likely an
underestimation, they enable the identification of risk areas as well as the
potential synchrony of some transitions, helping prioritize areas for
management interventions and conservation.",http://arxiv.org/abs/2107.03307v2
Single Event Transition Risk: A Measure for Long Term Carbon Exposure,2021-07-14T07:27:38Z,"Suryadeepto Nag, Siddhartha P. Chakrabarty, Sankarshan Basu","Although there is a growing consensus that a low-carbon transition will be
necessary to mitigate the accelerated climate change, the magnitude of
transition-risk for investors is difficult to measure exactly. Investors are
therefore constrained by the unavailability of suitable measures to quantify
the magnitude of the risk and are forced to use the likes of absolute emissions
data or ESG scores in order to manage their portfolios. In this article, we
define the Single Event Transition Risk (SETR) and illustrate how it can be
used to approximate the magnitude of the total exposure of the price of a share
to low-carbon transition. We also discuss potential applications of the single
event framework and the SETR as a risk measure and discuss future direction on
how this can be extended to a system with multiple transition events.",http://arxiv.org/abs/2107.06518v2
"Extreme Precipitation Seasonal Forecast Using a Transformer Neural
  Network",2021-07-14T17:02:15Z,"Daniel Salles Civitarese, Daniela Szwarcman, Bianca Zadrozny, Campbell Watson","An impact of climate change is the increase in frequency and intensity of
extreme precipitation events. However, confidently predicting the likelihood of
extreme precipitation at seasonal scales remains an outstanding challenge.
Here, we present an approach to forecasting the quantiles of the maximum daily
precipitation in each week up to six months ahead using the temporal fusion
transformer (TFT) model. Through experiments in two regions, we compare TFT
predictions with those of two baselines: climatology and a calibrated ECMWF
SEAS5 ensemble forecast (S5). Our results show that, in terms of quantile risk
at six month lead time, the TFT predictions significantly outperform those from
S5 and show an overall small improvement compared to climatology. The TFT also
responds positively to departures from normal that climatology cannot.",http://arxiv.org/abs/2107.06846v1
"The Dynamic Scaling Structure of the Intensity-Area-Duration-Frequency
  Relationship",2021-07-17T05:08:23Z,"Victor Peñaranda, David Serrano, Mahesh Maskey","Changing climate signals and the continuous world population growth requires
proper hydrologic risk analysis to build and operate water resource
infrastructures in a sustainable way. Although modernized computational
facilities are becoming popular to understand complex systems, there is not a
proper approach for the space - time analysis of extreme rainfall events. Many
statistical approaches have been suggested to describe the space-time structure
of rainfall; nevertheless, none of them is good enough to represent, for all
observational scales, the geometrical structure observed in either rainfall
time series or rainfall-derived spatial fields. This research presents a
geometric approach to understand the intensity - area - duration - frequency
(IADF) relationship without losing information or statistical assumptions.
Moreover, this study introduces a promising conceptualization about how
understand the space-time structure of rainfall via codimension functions and
dynamic scaling theory.",http://arxiv.org/abs/2107.08184v2
"Bam-readcount -- rapid generation of basepair-resolution sequence
  metrics",2021-07-27T13:38:47Z,"Ajay Khanna, David E. Larson, Sridhar Nonavinkere Srivatsan, Matthew Mosior, Travis E. Abbott, Susanna Kiwala, Timothy J. Ley, Eric J. Duncavage, Matthew J. Walter, Jason R. Walker, Obi L. Griffith, Malachi Griffith, Christopher A. Miller","Bam-readcount is a utility for generating low-level information about
sequencing data at specific nucleotide positions. Originally designed to help
filter genomic mutation calls, the metrics it outputs are useful as input for
variant detection tools and for resolving ambiguity between variant callers .
In addition, it has found broad applicability in diverse fields including tumor
evolution, single-cell genomics, climate change ecology, and tracking community
spread of SARS-CoV-2. Here we report on the release of version 1.0 of this
tool, which adds CRAM support, among other improvements. It is released under a
permissive MIT license and available at
https://github.com/genome/bam-readcount.",http://arxiv.org/abs/2107.12817v1
Slow Migration of Brine Inclusions in First-Year Sea Ice,2021-09-08T13:37:35Z,"Noa Kraitzman, Keith Promislow, Brian Wetton","We derive a thermodynamically consistent model for phase change in sea ice by
adding salt to the framework introduced by Penrose and Fife. Taking the salt
entropy relative to the liquid water molar fraction provides a transparent
mechanism for salt rejection under ice formation. We identify slow varying
coordinates, including salt density relative to liquid water molarity weighted
by latent heat, and use multiscale analysis to derive a quasi-equilibrium
Stefan-type problem via a sharp interface scaling. The singular limit is
under-determined and the leading order system is closed by imposing local
conservation of salt under interface perturbation. The quasi-steady system
determines interface motion as balance of curvature, temperature gradient, and
salt density. We resolve this numerically for axisymmetric surfaces and show
that the thermal gradients typical of arctic sea ice can have a decisive impact
on the mode of pinch-off of cylindrical brine inclusions and on the size
distribution of the resultant spherical shapes. The density and distribution of
inclusion sizes is a key component of sea ice albedo which factors into global
climate models.",http://arxiv.org/abs/2109.03643v1
Heterogeneous Ensemble for ESG Ratings Prediction,2021-09-21T10:42:24Z,"Tim Krappel, Alex Bogun, Damian Borth","Over the past years, topics ranging from climate change to human rights have
seen increasing importance for investment decisions. Hence, investors (asset
managers and asset owners) who wanted to incorporate these issues started to
assess companies based on how they handle such topics. For this assessment,
investors rely on specialized rating agencies that issue ratings along the
environmental, social and governance (ESG) dimensions. Such ratings allow them
to make investment decisions in favor of sustainability. However, rating
agencies base their analysis on subjective assessment of sustainability
reports, not provided by every company. Furthermore, due to human labor
involved, rating agencies are currently facing the challenge to scale up the
coverage in a timely manner.
  In order to alleviate these challenges and contribute to the overall goal of
supporting sustainability, we propose a heterogeneous ensemble model to predict
ESG ratings using fundamental data. This model is based on feedforward neural
network, CatBoost and XGBoost ensemble members. Given the public availability
of fundamental data, the proposed method would allow cost-efficient and
scalable creation of initial ESG ratings (also for companies without
sustainability reporting). Using our approach we are able to explain 54% of the
variation in ratings R2 using fundamental data and outperform prior work in
this area.",http://arxiv.org/abs/2109.10085v1
"A new look at the anthropogenic global warming consensus: an econometric
  forecast based on the ARIMA model of paleoclimate series",2021-09-21T19:45:49Z,"Gilmar V. F. Santos, Lucas G. Cordeiro, Claudio A. Rojo, Edison L. Leismann","This paper aims to project a climate change scenario using a stochastic
paleotemperature time series model and compare it with the prevailing
consensus. The ARIMA - Autoregressive Integrated Moving Average Process model
was used for this purpose. The results show that the parameter estimates of the
model were below what is established by the anthropogenic current and
governmental organs, such as the IPCC (UN), considering a 100-year scenario,
which suggests a period of temperature reduction and a probable cooling. Thus,
we hope with this study to contribute to the discussion by adding a statistical
element of paleoclimate in counterpoint to the current scientific consensus and
place the debate in a long-term historical dimension, in line with other
existing research on the topic.",http://arxiv.org/abs/2109.10419v2
"Realism of Simulation Models in Serious Gaming: Two case studies from
  Urban Water Management Higher Education",2021-09-22T08:06:43Z,"Darwin Droll, Heinrich Söbke","For games used in educational contexts, realism, i.e., the degree of
congruence between the simulation models used in the games and the real-world
systems represented, is an important characteristic for achieving learning
goals well. However, in the past, the realism of especially entertainment games
has often been identified as insufficient. Thus, this study is investigating
the degree of realism provided by current games. To this purpose, two games in
the domain urban water management, a subdomain of environmental engineering
(EE), are examined. One is ANAWAK, a web-based serious game on water management
and climate change. For ANAWAK, an analysis of the simulation model is
conducted. Second, the simulation model of the entertainment game Cities:
Skylines (CS) is analyzed. In addition, a survey among CS players (N=61) is
conducted. Thereby, different degrees of realism in various EE subdomains are
revealed. All in all, there are still considerable deficits regarding the
degree of realism in the CS simulation model. However, modding as a means of
achieving more realistic simulation models is more widely supported than in the
past.",http://arxiv.org/abs/2109.10572v1
The Boltzmann fair division for distributive justice,2021-09-24T12:17:04Z,"Ji-Won Park, Jaeup U. Kim, Cheol-Min Ghim, Chae Un Kim","Fair division is a significant, long-standing problem and is closely related
to social and economic justice. The conventional division methods such as
cut-and-choose are hardly applicable to realworld problems because of their
complexity and unrealistic assumptions about human behaviors. Here we propose a
fair division method from a completely different perspective, using the
Boltzmann distribution. The Boltzmann distribution adopted from the physical
sciences gives the most probable and unbiased distribution derived from a
goods-centric, rather than a player-centric, division process. The mathematical
model of the Boltzmann fair division was developed for both homogeneous and
heterogeneous division problems, and the players' key factors (contributions,
needs, and preferences) could be successfully integrated. We show that the
Boltzmann fair division is a well-balanced division method maximizing the
players' total utility, and it could be easily finetuned and applicable to
complex real-world problems such as income/wealth redistribution or
international negotiations on fighting climate change.",http://arxiv.org/abs/2109.11917v2
"Identifying Distributional Differences in Convective Evolution Prior to
  Rapid Intensification in Tropical Cyclones",2021-09-24T15:33:29Z,"Trey McNeely, Galen Vincent, Rafael Izbicki, Kimberly M. Wood, Ann B. Lee","Tropical cyclone (TC) intensity forecasts are issued by human forecasters who
evaluate spatio-temporal observations (e.g., satellite imagery) and model
output (e.g., numerical weather prediction, statistical models) to produce
forecasts every 6 hours. Within these time constraints, it can be challenging
to draw insight from such data. While high-capacity machine learning methods
are well suited for prediction problems with complex sequence data, extracting
interpretable scientific information with such methods is difficult. Here we
leverage powerful AI prediction algorithms and classical statistical inference
to identify patterns in the evolution of TC convective structure leading up to
the rapid intensification of a storm, hence providing forecasters and
scientists with key insight into TC behavior.",http://arxiv.org/abs/2109.12029v2
A Variational U-Net for Weather Forecasting,2021-11-05T12:52:15Z,"Pak Hay Kwok, Qi Qi","Not only can discovering patterns and insights from atmospheric data enable
more accurate weather predictions, but it may also provide valuable information
to help tackle climate change. Weather4cast is an open competition that aims to
evaluate machine learning algorithms' capability to predict future atmospheric
states. Here, we describe our third-place solution to Weather4cast. We present
a novel Variational U-Net that combines a Variational Autoencoder's ability to
consider the probabilistic nature of data with a U-Net's ability to recover
fine-grained details. This solution is an evolution from our fourth-place
solution to Traffic4cast 2020 with many commonalities, suggesting its
applicability to vastly different domains, such as weather and traffic.",http://arxiv.org/abs/2111.03476v1
Decoding Causality by Fictitious VAR Modeling,2021-11-14T22:43:02Z,Xingwei Hu,"In modeling multivariate time series for either forecast or policy analysis,
it would be beneficial to have figured out the cause-effect relations within
the data. Regression analysis, however, is generally for correlation relation,
and very few researches have focused on variance analysis for causality
discovery. We first set up an equilibrium for the cause-effect relations using
a fictitious vector autoregressive model. In the equilibrium, long-run
relations are identified from noise, and spurious ones are negligibly close to
zero. The solution, called causality distribution, measures the relative
strength causing the movement of all series or specific affected ones. If a
group of exogenous data affects the others but not vice versa, then, in theory,
the causality distribution for other variables is necessarily zero. The
hypothesis test of zero causality is the rule to decide a variable is
endogenous or not. Our new approach has high accuracy in identifying the true
cause-effect relations among the data in the simulation studies. We also apply
the approach to estimating the causal factors' contribution to climate change.",http://arxiv.org/abs/2111.07465v2
Opinion Dynamics with Conflicting Interests,2021-11-17T21:52:55Z,Patrick Mellacher,"I develop a rather simple agent-based model to capture a co-evolution of
opinion formation, political decision making and economic outcomes. I use this
model to study how societies form opinions if their members have opposing
interests. Agents are connected in a social network and exchange opinions, but
differ with regard to their interests and ability to gain information about
them. I show that inequality in information and economic resources can have a
drastic impact on aggregated opinion. In particular, my model illustrates how a
tiny, but well-informed minority can influence group decisions to their favor.
This effect is amplified if these agents are able to command more economic
resources to advertise their views and if they can target their advertisements
efficiently, as made possible by the rise of information technology. My results
contribute to the understanding of pressing questions such as climate change
denial and highlight the dangers that economic and information inequality can
pose for democracies.",http://arxiv.org/abs/2111.09408v1
"MS-nowcasting: Operational Precipitation Nowcasting with Convolutional
  LSTMs at Microsoft Weather",2021-11-18T21:55:49Z,"Sylwester Klocek, Haiyu Dong, Matthew Dixon, Panashe Kanengoni, Najeeb Kazmi, Pete Luferenko, Zhongjian Lv, Shikhar Sharma, Jonathan Weyn, Siqi Xiang","We present the encoder-forecaster convolutional long short-term memory (LSTM)
deep-learning model that powers Microsoft Weather's operational precipitation
nowcasting product. This model takes as input a sequence of weather radar
mosaics and deterministically predicts future radar reflectivity at lead times
up to 6 hours. By stacking a large input receptive field along the feature
dimension and conditioning the model's forecaster with predictions from the
physics-based High Resolution Rapid Refresh (HRRR) model, we are able to
outperform optical flow and HRRR baselines by 20-25% on multiple metrics
averaged over all lead times.",http://arxiv.org/abs/2111.09954v2
Unique steady annual cycle in marine ecosystem model simulations,2021-11-30T14:15:37Z,"Markus Pfeil, Thomas Slawig","Marine ecosystem models are an important tool to assess the role of the ocean
biota in climate change and to identify relevant biogeochemical processes by
validating the model outputs against observational data. For the assessment of
the marine ecosystem models, the existence and uniqueness of an annual periodic
solution (i.e., a steady annual cycle) is desirable. To analyze the uniqueness
of a steady annual cycle, we performed a larger number of simulations starting
from different initial concentrations for a hierarchy of biogeochemical models
with an increasing complexity. The numerical results suggested that the
simulations finished always with the same steady annual cycle regardless of the
initial concentration. Due to numerical instabilities, some inadmissible
approximations of the steady annual cycle, however, occurred in some cases for
the three most complex biogeochemical models. Our numerical results indicate a
unique steady annual cycle for practical applications.",http://arxiv.org/abs/2111.15424v1
"Altitude and Particle Size Measurements of Noctilucent Clouds by RGB
  Photometry: Radiative Transfer and Correlation Analysis",2021-12-07T18:41:18Z,Oleg S. Ugolnikov,"Noctilucent or polar mesospheric clouds have become visually brighter and
occurred more frequently during the recent years and decades. The study of
possible reasons and relations with climate changes requires data on long-time
trends of mean particle size and altitude. Extended worldwide observational
data is a good tool for this, and it can be provided by simple RGB-photometry
using widely distributed all-sky cameras. Based on observations of bright
expanded clouds in summer 2020 and 2021, the method of mean particle size
determination is developed, results are validated using the radiative transfer
model. The procedure also allows finding the effective 'umbral' altitude of
clouds. The correlation of size and altitude of particles is compared with
existing lidar data and models of particle growth.",http://arxiv.org/abs/2112.03895v1
NEORL: NeuroEvolution Optimization with Reinforcement Learning,2021-12-01T17:55:45Z,"Majdi I. Radaideh, Katelin Du, Paul Seurin, Devin Seyler, Xubo Gu, Haijia Wang, Koroush Shirvan","We present an open-source Python framework for NeuroEvolution Optimization
with Reinforcement Learning (NEORL) developed at the Massachusetts Institute of
Technology. NEORL offers a global optimization interface of state-of-the-art
algorithms in the field of evolutionary computation, neural networks through
reinforcement learning, and hybrid neuroevolution algorithms. NEORL features
diverse set of algorithms, user-friendly interface, parallel computing support,
automatic hyperparameter tuning, detailed documentation, and demonstration of
applications in mathematical and real-world engineering optimization. NEORL
encompasses various optimization problems from combinatorial, continuous, mixed
discrete/continuous, to high-dimensional, expensive, and constrained
engineering optimization. NEORL is tested in variety of engineering
applications relevant to low carbon energy research in addressing solutions to
climate change. The examples include nuclear reactor control and fuel cell
power production. The results demonstrate NEORL competitiveness against other
algorithms and optimization frameworks in the literature, and a potential tool
to solve large-scale optimization problems. More examples and benchmarking of
NEORL can be found here: https://neorl.readthedocs.io/en/latest/index.html",http://arxiv.org/abs/2112.07057v1
"Asymmetric Adaptivity induces Recurrent Synchronization in Complex
  Networks",2021-12-16T08:34:39Z,"Max Thiele, Rico Berner, Peter A. Tass, Eckehard Schöll, Serhiy Yanchuk","Rhythmic activities that alternate between coherent and incoherent phases are
ubiquitous in chemical, ecological, climate, or neural systems. Despite their
importance, general mechanisms for their emergence are little understood. In
order to fill this gap, we present a framework for describing the emergence of
recurrent synchronization in complex networks with adaptive interactions. This
phenomenon is manifested at the macroscopic level by temporal episodes of
coherent and incoherent dynamics that alternate recurrently. At the same time,
the dynamics of the individual nodes do not change qualitatively. We identify
asymmetric adaptation rules and temporal separation between the adaptation and
the dynamics of individual nodes as key features for the emergence of recurrent
synchronization. Our results suggest that asymmetric adaptation might be a
fundamental ingredient for recurrent synchronization phenomena as seen in
pattern generators, e.g., in neuronal systems.",http://arxiv.org/abs/2112.08697v2
"Investigating Opinion Dynamics Models in Agent-Based Simulation of
  Energy Eco-Feedback Programs",2021-12-03T01:06:49Z,"Mohammad Zarei, Mojtaba Maghrebi","According to research, reducing consumer energy demand through behavioural
interventions is an important factor of efforts to reduce greenhouse gas
emissions and climate change.On this basis, feedback interventions that make
energy consumption and conservation efforts apparent are seen as a feasible
method for increasing energy-saving habits. Simulation techniques provide a
convenient and cost-effective tool for examining the parameters that may affect
the amount of energy saved as a result of such interventions. However,
constructing a reliable model that accurately represents real-world processes
is a significant issue. Five Opinion Dynamic (OD) models that depict how
opinion change occurs among individuals interactions are investigated in this
paper, and a Revised OD (ROD) model is suggested to develop more efficient
eco-feedback simulation models. The results show that the influence condition
and the weight-factor of connected opinions have a substantial impact on the
accuracy of simulation outputs when compared to field experiment reports. As a
result, ROD has been proposed for eco-feedback program simulations, as it
provides the nearest approximation to the field data.",http://arxiv.org/abs/2112.12063v2
"Two-phase training mitigates class imbalance for camera trap image
  classification with CNNs",2021-12-29T10:47:45Z,"Farjad Malik, Simon Wouters, Ruben Cartuyvels, Erfan Ghadery, Marie-Francine Moens","By leveraging deep learning to automatically classify camera trap images,
ecologists can monitor biodiversity conservation efforts and the effects of
climate change on ecosystems more efficiently. Due to the imbalanced
class-distribution of camera trap datasets, current models are biased towards
the majority classes. As a result, they obtain good performance for a few
majority classes but poor performance for many minority classes. We used
two-phase training to increase the performance for these minority classes. We
trained, next to a baseline model, four models that implemented a different
versions of two-phase training on a subset of the highly imbalanced Snapshot
Serengeti dataset. Our results suggest that two-phase training can improve
performance for many minority classes, with limited loss in performance for the
other classes. We find that two-phase training based on majority undersampling
increases class-specific F1-scores up to 3.0%. We also find that two-phase
training outperforms using only oversampling or undersampling by 6.1% in
F1-score on average. Finally, we find that a combination of over- and
undersampling leads to a better performance than using them individually.",http://arxiv.org/abs/2112.14491v1
"Critical Risk Indicators (CRIs) for the electric power grid: A survey
  and discussion of interconnected effects",2021-01-19T18:36:50Z,"Judy P. Che-Castaldo, Rémi Cousin, Stefani Daryanto, Grace Deng, Mei-Ling E. Feng, Rajesh K. Gupta, Dezhi Hong, Ryan M. McGranaghan, Olukunle O. Owolabi, Tianyi Qu, Wei Ren, Toryn L. J. Schafer, Ashutosh Sharma, Chaopeng Shen, Mila Getmansky Sherman, Deborah A. Sunter, Lan Wang, David S. Matteson","The electric power grid is a critical societal resource connecting multiple
infrastructural domains such as agriculture, transportation, and manufacturing.
The electrical grid as an infrastructure is shaped by human activity and public
policy in terms of demand and supply requirements. Further, the grid is subject
to changes and stresses due to solar weather, climate, hydrology, and ecology.
The emerging interconnected and complex network dependencies make such
interactions increasingly dynamic causing potentially large swings, thus
presenting new challenges to manage the coupled human-natural system. This
paper provides a survey of models and methods that seek to explore the
significant interconnected impact of the electric power grid and interdependent
domains. We also provide relevant critical risk indicators (CRIs) across
diverse domains that may influence electric power grid risks, including
climate, ecology, hydrology, finance, space weather, and agriculture. We
discuss the convergence of indicators from individual domains to explore
possible systemic risk, i.e., holistic risk arising from cross-domains
interconnections. Our study provides an important first step towards
data-driven analysis and predictive modeling of risks in the coupled
interconnected systems. Further, we propose a compositional approach to risk
assessment that incorporates diverse domain expertise and information, data
science, and computer science to identify domain-specific CRIs and their union
in systemic risk indicators.",http://arxiv.org/abs/2101.07771v4
"A revised lower estimate of ozone columns during Earth's oxygenated
  history",2021-02-23T13:05:16Z,"Gregory Cooke, Dan Marsh, Catherine Walsh, Benjamin Black, Jean-François Lamarque","The history of molecular oxygen (O$_2$) in Earth's atmosphere is still
debated; however, geological evidence supports at least two major episodes
where O$_2$ increased by an order of magnitude or more: the Great Oxidation
Event (GOE) and the Neoproterozoic Oxidation Event. O$_2$ concentrations have
likely fluctuated (between $10^{-3}$ and $1.5$ times the present atmospheric
level) since the GOE $\sim 2.4$ Gyr ago, resulting in a time-varying ozone
(O$_3$) layer. Using a three-dimensional chemistry-climate model, we simulate
changes in O$_3$ in Earth's atmosphere since the GOE and consider the
implications for surface habitability, and glaciation during the
Mesoproterozoic. We find lower O$_3$ columns (reduced by up to $4.68$ times for
a given O$_2$ level) compared to previous work; hence, higher fluxes of
biologically harmful UV radiation would have reached the surface. Reduced O$_3$
leads to enhanced tropospheric production of the hydroxyl radical (OH) which
then substantially reduces the lifetime of methane (CH$_4$). We show that a
CH$_4$ supported greenhouse effect during the Mesoproterozoic is highly
unlikely. The reduced O$_3$ columns we simulate have important implications for
astrobiological and terrestrial habitability, demonstrating the relevance of
three-dimensional chemistry-climate simulations when assessing paleoclimates
and the habitability of faraway worlds.",http://arxiv.org/abs/2102.11675v2
"The TRAPPIST-1 Habitable Atmosphere Intercomparison (THAI). Part III:
  Simulated Observables -- The return of the spectrum",2021-09-23T16:04:38Z,"Thomas J. Fauchez, Geronimo L. Villanueva, Denis E. Sergeev, Martin Turbet, Ian A. Boutle, Kostas Tsigaridis, Michael J. Way, Eric T. Wolf, Shawn D. Domagal-Goldman, Francois Forget, Jacob Haqq-Misra, Ravi K. Kopparapu, James Manners, Nathan J. Mayne","The TRAPPIST-1 Habitable Atmosphere Intercomparison (THAI) is a community
project that aims to quantify how dfferences in general circulation models
(GCMs) could impact the climate prediction for TRAPPIST-1e and, subsequently
its atmospheric characterization in transit. Four GCMs have participated in
THAI so far: ExoCAM, LMD-Generic, ROCKE-3D and the UM. This paper, focused on
the simulated observations, is the third part of a trilogy, following the
analysis of two land planet scenarios (part I) and two aquaplanet scenarios
(part II). Here, we show a robust agreement between the simulated spectra and
the number of transits estimated to detect the land planet atmospheres. For the
aquaplanet ones, using atmospheric data from any of the four GCMs would require
at least 17 transits. This prediction corresponds to UM simulated data which
produces the lowest and thinnest clouds. Between 35-40% more clouds are
predicted by ExoCAM or LMD-G due to higher thick terminator clouds. For the
first time this work provides ""GCM uncertainty error bars"" of 35-40% that need
to be considered in future analyses of transmission spectra. We also analyzed
the inter-transit variability induced by weather patterns and changes of
terminator cloudiness between transits. Its magnitude differs significantly
between the GCMs but its impact on the transmission spectra is within the
measurement uncertainties. THAI has demonstrated the importance of model
intercomparison for exoplanets and also paved the way for a larger project to
develop an intercomparison meta-framework, namely the Climates Using
Interactive Suites of Intercomparisons Nested for Exoplanet Studies (CUISINES).",http://arxiv.org/abs/2109.11460v2
"Combining randomized field experiments with observational satellite data
  to assess the benefits of crop rotations on yields",2021-12-27T14:14:51Z,"Dan M. Kluger, Art B. Owen, David B. Lobell","With climate change threatening agricultural productivity and global food
demand increasing, it is important to better understand which farm management
practices will maximize crop yields in various climatic conditions. To assess
the effectiveness of agricultural practices, researchers often turn to
randomized field experiments, which are reliable for identifying causal effects
but are often limited in scope and therefore lack external validity. Recently,
researchers have also leveraged large observational datasets from satellites
and other sources, which can lead to conclusions biased by confounding
variables or systematic measurement errors. Because experimental and
observational datasets have complementary strengths, in this paper we propose a
method that uses a combination of experimental and observational data in the
same analysis. As a case study, we focus on the causal effect of crop rotation
on corn (maize) and soy yields in the Midwestern United States. We find that,
in terms of root mean squared error, our hybrid method performs 13% better than
using experimental data alone and 26% better than using the observational data
alone in the task of predicting the effect of rotation on corn yield at
held-out experimental sites. Further, the causal estimates based on our method
suggest that benefits of crop rotations on corn yield are lower in years and
locations with high temperatures whereas the benefits of crop rotations on soy
yield are higher in years and locations with high temperatures. In particular,
we estimated that the benefit of rotation on corn yields (and soy yields) was
0.84 t/ha (0.23 t/ha) on average for the top quintile of temperatures, 1.02
t/ha (0.20 t/ha) on average for the whole dataset, and 1.18 t/ha (0.15 t/ha) on
average for the bottom quintile of temperatures.",http://arxiv.org/abs/2112.13700v1
"The Total Solar Irradiance variability in the Evolutionary Timescale and
  its Impact on the Mean Earth's Surface Temperature",2021-06-07T14:36:28Z,"N. T. Shukure, S. B Tessema, N. Gopalswamy","The Sun is the primary source of energy for the Earth. The small changes in
total solar irradiance (TSI) can affect our climate in the longer timescale. In
the evolutionary timescale, the TSI varies by a large amount and hence its
influence on the Earth's mean surface temperature (T$_{s}$) also increases
significantly. We develop a mass-loss dependent analytical model of TSI in the
evolutionary timescale and evaluated its influence on the T$_{s}$. We
determined the numerical solution of TSI for the next 8.23 Gyrs to be used as
an input to evaluate the T$_{s}$ which formulated based on a zero-dimensional
energy balance model. We used the present-day albedo and bulk atmospheric
emissivity of the Earth and Mars as initial and final boundary conditions,
respectively. We found that the TSI increases by 10\% in 1.42 Gyr, by 40\% in
about 3.4 Gyrs, and by 120\% in about 5.229 Gyrs from now, while the T$_{s}$
shows an insignificant change in 1.644 Gyrs and increases to 298.86 K in about
3.4 Gyrs. The T$_{s}$ attains the peak value of 2319.2 K as the Sun evolves to
the red giant and emits the enormous TSI of 7.93$\times10^{6} Wm^{-2}$ in 7.676
Gys. At this temperature Earth likely evolves to be a liquid planet. In our
finding, the absorbed and emitted flux equally increases and approaches the
surface flux in the main sequence, and they are nearly equal beyond the main
sequence, while the flux absorbed by the cloud shows opposite trend.",http://arxiv.org/abs/2106.03657v1
Rotation Invariant Graph Neural Networks using Spin Convolutions,2021-06-17T14:59:34Z,"Muhammed Shuaibi, Adeesh Kolluru, Abhishek Das, Aditya Grover, Anuroop Sriram, Zachary Ulissi, C. Lawrence Zitnick","Progress towards the energy breakthroughs needed to combat climate change can
be significantly accelerated through the efficient simulation of atomic
systems. Simulation techniques based on first principles, such as Density
Functional Theory (DFT), are limited in their practical use due to their high
computational expense. Machine learning approaches have the potential to
approximate DFT in a computationally efficient manner, which could dramatically
increase the impact of computational simulations on real-world problems.
Approximating DFT poses several challenges. These include accurately modeling
the subtle changes in the relative positions and angles between atoms, and
enforcing constraints such as rotation invariance or energy conservation. We
introduce a novel approach to modeling angular information between sets of
neighboring atoms in a graph neural network. Rotation invariance is achieved
for the network's edge messages through the use of a per-edge local coordinate
frame and a novel spin convolution over the remaining degree of freedom. Two
model variants are proposed for the applications of structure relaxation and
molecular dynamics. State-of-the-art results are demonstrated on the
large-scale Open Catalyst 2020 dataset. Comparisons are also performed on the
MD17 and QM9 datasets.",http://arxiv.org/abs/2106.09575v1
"Transmission and Capacity Expansion Planning Against Rising
  Temperatures: A Case Study in Arizona",2021-06-23T23:24:15Z,"J. Kyle Skolfield, Jose Ramirez-Vergara, Adolfo R. Escobedo","The stable and efficient operation of the transmission network is fundamental
to the power system's ability to deliver electricity reliably and cheaply. As
average temperatures continue to rise, the ability of the transmission network
to meet demand is diminished. Higher temperatures lead to congestion by
reducing thermal limits of lines while simultaneously reducing generation
potential. Due to prohibitive costs and limited real estate for building new
lines, it is necessary to consider capacity expansion as well to improve the
functioning and efficiency of the grid. Optimal control, however, requires many
discrete choices, rendering fully accurate models intractable. Furthermore,
temperature changes will impact different regions and climate differently. As
such, it is necessary to model both temperature changes and transmission flows
with high spatial resolution. This work proposes a case study of the
transmission grid centered in Arizona, using a DC optimal power flow
mathematical formulation to plan for future transmission expansion and capacity
expansion to efficiently meet demand. The effects of rising temperatures on
transmission and generation are modeled at the regional level. Several classes
of valid inequalities are employed to speed up the solution process. Multiple
experiments considering different temperature and demand trends are considered
which include each of the above technologies.",http://arxiv.org/abs/2106.12687v1
Mainstreaming of conspiracy theories and misinformation,2021-02-04T02:47:31Z,"N. F. Johnson, N. Velasquez, N. Johnson Restrepo, R. Leahy, R. Sear, N. Gabriel, H. Larson, Y. Lupu","Parents - particularly moms - increasingly consult social media for support
when taking decisions about their young children, and likely also when advising
other family members such as elderly relatives. Minimizing malignant online
influences is therefore crucial to securing their assent for policies ranging
from vaccinations, masks and social distancing against the pandemic, to
household best practices against climate change, to acceptance of future 5G
towers nearby. Here we show how a strengthening of bonds across online
communities during the pandemic, has led to non-Covid-19 conspiracy theories
(e.g. fluoride, chemtrails, 5G) attaining heightened access to mainstream
parent communities. Alternative health communities act as the critical conduits
between conspiracy theorists and parents, and make the narratives more
palatable to the latter. We demonstrate experimentally that these
inter-community bonds can perpetually generate new misinformation, irrespective
of any changes in factual information. Our findings show explicitly why
Facebook's current policies have failed to stop the mainstreaming of
non-Covid-19 and Covid-19 conspiracy theories and misinformation, and why
targeting the largest communities will not work. A simple yet exactly solvable
and empirically grounded mathematical model, shows how modest tailoring of
mainstream communities' couplings could prevent them from tipping against
establishment guidance. Our conclusions should also apply to other social media
platforms and topics.",http://arxiv.org/abs/2102.02382v1
"Understanding the attitudes, knowledge sharing behaviors and task
  performance of core developers: A longitudinal study",2021-02-12T00:01:57Z,"Sherlock A. Licorish, Stephen G. MacDonell","Context: Prior research has established that a few individuals generally
dominate project communication and source code changes during software
development, regardless of task assignments at project initiation. Objective:
While this phenomenon has been noted, prior research has not sought to
understand these dominant individuals. Previous work has found that core
communicators are the gatekeepers of their teams' knowledge, and the
performance of these members was correlated with their teams' success. Building
on this work, we have employed a longitudinal approach to study the way core
developers' attitudes, knowledge sharing behaviors and task performance change
over the course of their project. Method: We first used Social Network Analysis
(SNA) and standard statistical analysis techniques to identify and select
artifacts and central practitioners from ten different software development
teams. We then applied psycholinguistic analysis and directed content analysis
(CA) techniques to interpret the content of these practitioners' messages.
Finally, we inspected core developers' activities at various points in time
during systems' development. Results: Among our findings, we observe that core
developers' attitudes and knowledge sharing behaviors were linked to their
involvement in actual software development and the demands of their wider
project teams. However, core developers appeared to naturally possess high
levels of insightful characteristics. Conclusion: Project performance would
likely benefit from strategies aimed at surrounding core developers with other
competent communicators. Core developers should also be supported by a wider
team who are willing to ask questions and challenge their ideas. Finally, the
availability of adequate communication channels would help with maintaining
positive team climate especially in distributed developments.(Abridged)",http://arxiv.org/abs/2102.06317v1
"Embedding Sustainability in Complex Projects: A Pedagogic Practice
  Simulation Approach",2021-03-28T09:33:23Z,"Caroline N J Tite, David Pontin, Nicholas Dacre","Sustainability is focussed on avoiding the long-term depletion of natural
resources. Under the terms of a government plan to tackle climate change, a
driver for improved sustainability is the cut of greenhouse gas emissions in
the UK to almost zero by 2050. With this type of change, new themes are
continuously being developed which drive complex projects, such as the
development of new power generation methods, which encompass challenging lead
times and demanding requirements. Consideration of the implementation of
strategies and key concepts, which may engender sustainability within complex
projects therefore presents an opportunity for further critical debate, review,
and application through a project management lens. Sustainability incorporation
in project management has been documented in academic literature, with this
emerging field providing new challenges. For example, project management
education can provide a holistic base for the inculcation of sustainability
factors to a range of industries, including complex projects. Likewise,
practitioner interest and approaches to sustainability in project management
are being driven by the recently Chartered Association for Project Management
(APM). Whilst this body makes a significant contribution to the UK economy
across many sectors, it also addresses ongoing sustainability challenges.
Therefore, by drawing on research and practitioner developments, the authors
argue that by connecting with the next generation through practice simulation
approaches, and embedding sustainability issues within project management tools
and methods, improved focus on sustainability in complex project management may
be achieved.",http://arxiv.org/abs/2104.04068v2
"Global temperature goals should determine the time horizons for
  greenhouse gas emission metrics",2021-04-12T14:39:58Z,"Sam Abernethy, Robert B. Jackson","Emission metrics, a crucial tool in setting effective equivalences between
greenhouse gases, currently require a subjective, arbitrary choice of time
horizon. Here, we propose a novel framework that uses a specific temperature
goal to calculate the time horizon that aligns with scenarios achieving that
temperature goal. We analyze the Intergovernmental Panel on Climate Change
Special Report on Global Warming of 1.5 C Scenario Database to find that time
horizons that align with the 1.5 and 2 C global warming goals of the Paris
Agreement are 24 [90% prediction interval: 7, 41] and 58 [90% PI: 41, 74] years
respectively. We then use these time horizons to quantify time-dependent
emission metrics with methane as our main example. We find that the Global
Warming Potential values that align with the 1.5 and 2 C goals are GWP1.5 C =
75 [90% PI: 54, 107] and GWP2 C = 42 [90% PI: 35, 54]; for the Global
Temperature change Potential they are GTP1.5 C = 41 [90% PI: 16, 102] and GTP2
C = 9 [90% PI: 7, 16]. The most commonly used time horizon, 100 years,
underestimates methane emission metrics by 34-38% relative to the values we
calculate that align with the 2 C goal and 63-87% relative to the 1.5 C goal.
To best align emission metrics with the 1.5 C goal of the Paris Agreement, we
recommend a 24-year time horizon, using 2045 as the endpoint time, with its
associated GWP1.5 C = 75 and GTP1.5 C = 41.",http://arxiv.org/abs/2104.05506v2
Optimal Reservoir Operations using Long Short-Term Memory Network,2021-09-07T18:16:22Z,"Asha Devi Singh, Anurag Singh","A reliable forecast of inflows to the reservoir is a key factor in the
optimal operation of reservoirs. Real-time operation of the reservoir based on
forecasts of inflows can lead to substantial economic gains. However, the
forecast of inflow is an intricate task as it has to incorporate the impacts of
climate and hydrological changes. Therefore, the major objective of the present
work is to develop a novel approach based on long short-term memory (LSTM) for
the forecast of inflows. Real-time inflow forecast, in other words, daily
inflow at the reservoir helps in efficient operation of water resources. Also,
daily variations in the release can be monitored efficiently and the
reliability of operation is improved. This work proposes a naive anomaly
detection algorithm baseline based on LSTM. In other words, a strong baseline
to forecast flood and drought for any deep learning-based prediction model. The
practicality of the approach has been demonstrated using the observed daily
data of the past 20 years from Bhakra Dam in India. The results of the
simulations conducted herein clearly indicate the supremacy of the LSTM
approach over the traditional methods of forecasting. Although, experiments are
run on data from Bhakra Dam Reservoir in India, LSTM model, and anomaly
detection algorithm are general purpose and can be applied to any basin with
minimal changes. A distinct practical advantage of the LSTM method presented
herein is that it can adequately simulate non-stationarity and non-linearity in
the historical data.",http://arxiv.org/abs/2109.04255v1
"Constrained scenarios for twenty-first century human population size
  based on the empirical coupling to economic growth",2021-09-29T06:22:43Z,"Barry W. Brook, Jessie C. Buettel, Sanghyun Hong","Growth in the global human population this century will have momentous
consequences for societies and the environment. Population growth has come with
higher aggregate human welfare, but also climate change and biodiversity loss.
Based on the well-established empirical association and plausible causal
relationship between economic and population growth, we devised a novel method
for forecasting population based on Gross Domestic Product (GDP) per capita.
Although not mechanistically causal, our model is intuitive, transparent,
replicable, and grounded on historical data. Our central finding is that a
richer world is likely to be associated with a lower population, an effect
especially pronounced in rapidly developing countries. In our baseline
scenario, where GDP per capita follows a business-as-usual trajectory, global
population is projected to reach 9.2 billion in 2050 and peak in 2062. With 50%
higher annual economic growth, population peaks even earlier, in 2056, and
declines to below 8 billion by the end of the century. Without any economic
growth after 2020, however, the global population will grow to 9.9 billion in
2050 continue rising thereafter. Economic growth has the largest effect on
low-income countries. The gap between the highest and lowest GDP scenarios
reaches almost 4 billion by 2100. Education and family planning are important
determinants of population growth, but economic growth is also likely to be a
driver of slowing population growth by changing incentives for childbearing.
Since economic growth could slow population growth, it will offset
environmental impacts stemming from higher per-capita consumption of food,
water, and energy, and work in tandem with technological innovation.",http://arxiv.org/abs/2109.14209v1
Modelling the transition to a low-carbon energy supply,2021-09-25T12:37:05Z,Alexander Kell,"A transition to a low-carbon electricity supply is crucial to limit the
impacts of climate change. Reducing carbon emissions could help prevent the
world from reaching a tipping point, where runaway emissions are likely.
Runaway emissions could lead to extremes in weather conditions around the world
-- especially in problematic regions unable to cope with these conditions.
However, the movement to a low-carbon energy supply can not happen
instantaneously due to the existing fossil-fuel infrastructure and the
requirement to maintain a reliable energy supply. Therefore, a low-carbon
transition is required, however, the decisions various stakeholders should make
over the coming decades to reduce these carbon emissions are not obvious. This
is due to many long-term uncertainties, such as electricity, fuel and
generation costs, human behaviour and the size of electricity demand. A well
choreographed low-carbon transition is, therefore, required between all of the
heterogenous actors in the system, as opposed to changing the behaviour of a
single, centralised actor. The objective of this thesis is to create a novel,
open-source agent-based model to better understand the manner in which the
whole electricity market reacts to different factors using state-of-the-art
machine learning and artificial intelligence methods. In contrast to other
works, this thesis looks at both the long-term and short-term impact that
different behaviours have on the electricity market by using these
state-of-the-art methods.",http://arxiv.org/abs/2111.00987v1
"State Estimation of the Stefan PDE: A Tutorial on Design and
  Applications to Polar Ice and Batteries",2021-11-23T02:38:00Z,"Shumon Koga, Miroslav Krstic","The Stefan PDE system is a representative model for thermal phase change
phenomena, such as melting and solidification, arising in numerous science and
engineering processes. The mathematical description is given by a Partial
Differential Equation (PDE) of the temperature distribution defined on a
spatial interval with a moving boundary, where the boundary represents the
liquid-solid interface and its dynamics are governed by an Ordinary
Differential Equation (ODE). The PDE-ODE coupling at the boundary is nonlinear
and creates a significant challenge for state estimation with provable
convergence and robustness. This tutorial article presents a state estimation
method based on PDE backstepping for the Stefan system, using measurements only
at the moving boundary. PDE backstepping observer design generates an observer
gain by employing a Volterra transformation of the observer error state into a
desirable target system, solving a Goursat-form PDE for the transformation's
kernel, and performing a Lyapunov analysis of the target observer error system.
The observer is applied to models of problems motivated by climate change and
the need for renewable energy storage: a model of polar ice dynamics and a
model of charging and discharging in lithium-ion batteries. The numerical
results for polar ice demonstrate a robust performance of the designed
estimator with respect to the unmodeled salinity effect in sea ice. The results
for an electrochemical PDE model of a lithium-ion battery with a phase
transition material show the elimination of more than 15 \% error in
State-of-Charge estimate within 5 minutes even in the presence of sensor noise.",http://arxiv.org/abs/2111.11617v1
"Nonlinear effects of instantaneous and delayed state dependence in a
  delayed feedback loop",2021-10-05T07:30:48Z,"Antony R. Humphries, Bernd Krauskopf, Stefan Ruschel, Jan Sieber","We study a scalar, first-order delay differential equation (DDE) with
instantaneous and state-dependent delayed feedback, which itself may be
delayed. The state dependence introduces nonlinearity into an otherwise linear
system. We investigate the ensuing nonlinear dynamics with the case of
instantaneous state dependence as our starting point. We present the
bifurcation diagram in the parameter plane of the two feedback strengths
showing how periodic orbits bifurcate from a curve of Hopf bifurcations and
disappear along a curve where both period and amplitude grow beyond bound as
the orbits become saw-tooth shaped. We then `switch on' the delay within the
state-dependent feedback term, reflected by a parameter $b>0$. Our main
conclusion is that the new parameter $b$ has an immediate effect: as soon as
$b>0$ the bifurcation diagram for $b=0$ changes qualitatively and,
specifically, the nature of the limiting saw-tooth shaped periodic orbits
changes. Moreover, we show $-$ numerically and through center manifold analysis
$-$ that a degeneracy at $b=1/3$ of an equilibrium with a double real
eigenvalue zero leads to a further qualitative change and acts as an organizing
center for the bifurcation diagram.
  Our results demonstrate that state dependence in delayed feedback terms may
give rise to new dynamics and, moreover, that the observed dynamics may change
significantly when the state-dependent feedback depends on past states of the
system. This is expected to have implications for models arising in different
application contexts, such as models of human balancing and conceptual climate
models of delayed action oscillator type.",http://arxiv.org/abs/2110.01850v3
"The impact of outgassing of CO2 and prior calcium precipitation to the
  isotope composition of calcite precipitated on stalagmites. Implications for
  reconstructing climate information from proxies",2021-12-30T09:02:26Z,"Wolfgang Dreybrodt, Jens Fohlmeister","Degassing of CO2 and precipitation of calcite to the surface of stalagmites
can strongly impact isotope signals imprinted into the calcite of these
speleothems. Here, we show that in all the variety of conditions occurring in
nature only two distinct types of degassing exist. First, when a thin film of
calcareous solution comes in contact to cave air lower pCO2 value than that of
the aqueous CO2 in the water, molecular CO2 escapes by physical diffusion in
several seconds. In a next step lasting several ten seconds, pH and DIC in the
solution achieve chemical equilibrium with respect to the CO2 in the cave
atmosphere. This solution becomes supersaturated with respect to calcite.
During precipitation for each unit CaCO3 deposited one molecule of CO2 is
generated and escapes from the solution. This precipitation driven degassing is
active during precipitation only. We show that all variations of out gassing
proposed in the literature are either diffusive outgassing or precipitation
driven degassing and that diffusive outgassing has no influence on the isotope
composition of the HCO3 - pool and consequently on that of calcite. Its isotope
imprint is determined solely by precipitation driven degassing in contrast to
most explanations in the literature. We present a theoretical model of d13C and
d18O that explains the contributions of various parameters such as changes in
temperature, changes of pCO2 in the cave atmosphere, and changes in the drip
intervals to the isotope composition of calcite precipitated to the apex of the
stalagmite. We use this model to calculate quantitatively changes of d13C and
d18O observed in field experiments (Carlson et al., 2020) in agreement to their
experimental data. We also apply our model to prior calcite precipitation (PCP)
in the field as reported by Mickler et al. (2019). We discuss how PCP
influences isotope composition signals. ...",http://arxiv.org/abs/2112.14972v1
"An informed thought experiment exploring the potential for a paradigm
  shift in aquatic food production",2021-03-01T01:55:23Z,"Caitlin D. Kuempel, Halley E. Froehlich, Benjamin S. Halpern","The Neolithic Revolution began c. 10000 years ago and is characterised by the
ultimate, near complete transition from hunting and gathering to agricultural
food production on land. The Neolithic Revolution is thought to have been
catalysed by a combination of local population pressure, cultural diffusion,
property rights and climate change. We undertake a thought experiment that
examines trends in these key hypothesised catalysts and patters of today to
explore whether society could be on a path towards another paradigm shift in
food production: away from hunting of wild fish towards a transition to mostly
fish farming. We find similar environmental and cultural pressures have driven
the rapid rise of aquaculture, during a period that has now been coined the
Blue Revolution, providing impetus for such a transition in coming decades to
centuries. We also highlight the interacting and often mutually reinforcing
impacts of 1)technological and scientific advancement, 2)environmental
awareness and collective action and 3)globalisation and trade influencing the
trajectory and momentum of the Blue Revolution. We present two qualitative
narratives that broadly fall within two future trajectories: 1)a ubiquitous
aquaculture transition and 20commercial aquaculture and fisheries coexistence.
This scenarios approach aims to encourage logical, forward thinking, and
innovative solutions to complex systems dynamics. Scenario-based thought
experiments are useful to explore large scale questions, increase the
accessibility to a wider readership and ideally catalyse discussion around
proactive governance mechanisms. We argue the future is not fixed and society
now has greater foresight and capacity to choose the workable balance between
fisheries sand aquaculture that supports economic, environmental, cultural and
social objectives through combined planning, policies and management.",http://arxiv.org/abs/2103.00690v1
I-Nema: A Biological Image Dataset for Nematode Recognition,2021-03-15T12:29:37Z,"Xuequan Lu, Yihao Wang, Sheldon Fung, Xue Qing","Nematode worms are one of most abundant metazoan groups on the earth,
occupying diverse ecological niches. Accurate recognition or identification of
nematodes are of great importance for pest control, soil ecology,
bio-geography, habitat conservation and against climate changes. Computer
vision and image processing have witnessed a few successes in species
recognition of nematodes; however, it is still in great demand. In this paper,
we identify two main bottlenecks: (1) the lack of a publicly available imaging
dataset for diverse species of nematodes (especially the species only found in
natural environment) which requires considerable human resources in field work
and experts in taxonomy, and (2) the lack of a standard benchmark of
state-of-the-art deep learning techniques on this dataset which demands the
discipline background in computer science. With these in mind, we propose an
image dataset consisting of diverse nematodes (both laboratory cultured and
naturally isolated), which, to our knowledge, is the first time in the
community. We further set up a species recognition benchmark by employing
state-of-the-art deep learning networks on this dataset. We discuss the
experimental results, compare the recognition accuracy of different networks,
and show the challenges of our dataset. We make our dataset publicly available
at: https://github.com/xuequanlu/I-Nema",http://arxiv.org/abs/2103.08335v1
"AGCM-3DLF: Accelerating Atmospheric General Circulation Model via 3D
  Parallelization and Leap-Format",2021-03-18T09:41:15Z,"Hang Cao, Liang Yuan, He Zhang, Yunquan Zhang","The Atmospheric General Circulation Model (AGCM) has been an important
research tool in the study of climate change for decades. As the demand for
high-resolution simulation is becoming urgent, the scalability and simulation
efficiency is faced with great challenges, especially for the
latitude-longitude mesh-based models. In this paper, we propose a highly
scalable 3D atmospheric general circulation model based on leap-format, namely
AGCM-3DLF. Firstly, it utilizes a 3D decomposition method allowing for
parallelism release in all three physical dimensions. Then the leap-format
difference computation scheme is adopted to maintain computational stability in
grid updating and avoid additional filtering at the high latitudes. A novel
shifting window communication algorithm is designed for parallelization of the
unified model. Furthermore, a series of optimizations are conducted to improve
the effectiveness of large-scale simulations. Experiment results in different
platforms demonstrate good efficiency and scalability of the model. AGCM-3DLF
scales up to the entire CAS-Xiandao1 supercomputer (196,608 CPU cores),
attaining the speed of 11.1 simulation-year-per-day (SYPD) at a high resolution
of 25KM. In addition, simulations conducted on the Sunway TaihuLight
supercomputer exhibit a 1.06 million cores scalability with 36.1% parallel
efficiency.",http://arxiv.org/abs/2103.10114v2
A graph theoretical approach to the firebreak locating problem,2021-03-18T09:43:19Z,"Marc Demange, Alessia Di Fonso, Gabriele Di Stefano, Pierpaolo Vittorini","In the last decade, wildfires have become wider and more destructive. The
climate change and the growth of urban areas may further increase the
probability of incidence of large-scale fires. The risk of fire can be lowered
with preventive measures. Among them, firefighting lines are used to stop the
fire from spreading beyond them. Due to high costs of installation and
maintenance, their placement must be carefully planned. In this work, we
address the wildfire management problem from a theoretical point of view and
define a risk function to model the fire diffusion phenomena. The land is
modeled by a mixed graph in which vertices are areas subject to fire with a
certain probability while edges model the probability of fire spreading from
one area to another. To reduce the risk, we introduce the {\sc Windy Firebreak
Location} problem that addresses the optimal positioning of firefighting lines
under budget constraints. We study the complexity of the problem and prove its
hardness even when the graph is planar, bipartite, with maximum degree four and
the propagation probabilities are equal to one. We also show an efficient
polynomial time algorithm for particular instances on trees.",http://arxiv.org/abs/2103.10115v1
"Seasonal Contrast: Unsupervised Pre-Training from Uncurated Remote
  Sensing Data",2021-03-30T18:26:39Z,"Oscar Mañas, Alexandre Lacoste, Xavier Giro-i-Nieto, David Vazquez, Pau Rodriguez","Remote sensing and automatic earth monitoring are key to solve global-scale
challenges such as disaster prevention, land use monitoring, or tackling
climate change. Although there exist vast amounts of remote sensing data, most
of it remains unlabeled and thus inaccessible for supervised learning
algorithms. Transfer learning approaches can reduce the data requirements of
deep learning algorithms. However, most of these methods are pre-trained on
ImageNet and their generalization to remote sensing imagery is not guaranteed
due to the domain gap. In this work, we propose Seasonal Contrast (SeCo), an
effective pipeline to leverage unlabeled data for in-domain pre-training of
remote sensing representations. The SeCo pipeline is composed of two parts.
First, a principled procedure to gather large-scale, unlabeled and uncurated
remote sensing datasets containing images from multiple Earth locations at
different timestamps. Second, a self-supervised algorithm that takes advantage
of time and position invariance to learn transferable representations for
remote sensing applications. We empirically show that models trained with SeCo
achieve better performance than their ImageNet pre-trained counterparts and
state-of-the-art self-supervised learning methods on multiple downstream tasks.
The datasets and models in SeCo will be made public to facilitate transfer
learning and enable rapid progress in remote sensing applications.",http://arxiv.org/abs/2103.16607v2
"Highlighting the Importance of Reducing Research Bias and Carbon
  Emissions in CNNs",2021-06-06T20:42:00Z,"Ahmed Badar, Arnav Varma, Adrian Staniec, Mahmoud Gamal, Omar Magdy, Haris Iqbal, Elahe Arani, Bahram Zonooz","Convolutional neural networks (CNNs) have become commonplace in addressing
major challenges in computer vision. Researchers are not only coming up with
new CNN architectures but are also researching different techniques to improve
the performance of existing architectures. However, there is a tendency to
over-emphasize performance improvement while neglecting certain important
variables such as simplicity, versatility, the fairness of comparisons, and
energy efficiency. Overlooking these variables in architectural design and
evaluation has led to research bias and a significantly negative environmental
impact. Furthermore, this can undermine the positive impact of research in
using deep learning models to tackle climate change. Here, we perform an
extensive and fair empirical study of a number of proposed techniques to gauge
the utility of each technique for segmentation and classification. Our findings
restate the importance of favoring simplicity over complexity in model design
(Occam's Razor). Furthermore, our results indicate that simple standardized
practices can lead to a significant reduction in environmental impact with
little drop in performance. We highlight that there is a need to rethink the
design and evaluation of CNNs to alleviate the issue of research bias and
carbon emissions.",http://arxiv.org/abs/2106.03242v1
"Warning signs for non-Markovian bifurcations: colour blindness and
  scaling laws",2021-06-15T19:00:11Z,"Christian Kuehn, Kerstin Lux, Alexandra Neamtu","Warning signs for tipping points (or critical transitions) have been very
actively studied. Although the theory has been applied successfully in models
and in experiments for many complex systems such as for tipping in climate
systems, there are ongoing debates, when warning signs can be extracted from
data. In this work, we shed light on this debate by considering different types
of underlying noise. Thereby, we significantly advance the general theory of
warning signs for nonlinear stochastic dynamics. A key scenario deals with
stochastic systems approaching a bifurcation point dynamically upon slow
parameter variation. The stochastic fluctuations are generically able to probe
the dynamics near a deterministic attractor to reveal critical slowing down.
Using scaling laws near bifurcations, one can then anticipate the distance to a
bifurcation. Previous warning signs results assume that the noise is Markovian,
most often even white. Here, we study warning signs for non-Markovian systems
including coloured noise and $\alpha$-regular Volterra processes (of which
fractional Brownian motion and the Rosenblatt process are special cases). We
prove that early warning scaling laws can disappear completely or drastically
change their exponent based upon the parameters controlling the noise process.
This provides a clear explanation, why applying standard warning signs results
to reduced models of complex systems may not agree with data-driven studies. We
demonstrate our results numerically in the context of a box model of the
Atlantic Meridional Overturning Circulation (AMOC).",http://arxiv.org/abs/2106.08374v3
"Future urban mobility as a bio-inspired collaborative system of
  multi-functional autonomous vehicles",2021-06-15T15:13:18Z,"Naroa Coretti Sánchez, Juan Múgica González, Luis Alonso Pastor, Kent Larson","The fast urbanization and climate change challenges require solutions that
enable the efficient movement of people and goods in cities. We envision future
cities to be composed of high-performing walkable districts where
transportation needs could be served by fleets of ultra-lightweight shared and
autonomous vehicles. A future in which most vehicles would be autonomous
creates a new paradigm for the possible interactions between vehicles. Natural
swarms are a great example of how rich interactions can be; they can divide
tasks, cluster, build together, or transport cooperatively. The field of swarm
robotics has translated some of the behaviors from natural swarms to artificial
systems, proving to make systems more flexible, scalable, and robust. Inspired
by nature and supported by swarm robotics, this paper proposes a future
mobility in which shared, electric, and autonomous vehicles would be
multi-functional and behave as a collaborative system. In this future, fleets
of multi-functional vehicles would complete different tasks collaboratively,
giving a response to the different urban mobility needs. This paper contributes
with the proposal of a framework for future urban mobility that integrates
current research and mobility trends in a novel and unique way.",http://arxiv.org/abs/2106.09543v2
"A Machine learning approach for rapid disaster response based on
  multi-modal data. The case of housing & shelter needs",2021-07-29T18:22:34Z,"Karla Saldana Ochoa, Tina Comes","Along with climate change, more frequent extreme events, such as flooding and
tropical cyclones, threaten the livelihoods and wellbeing of poor and
vulnerable populations. One of the most immediate needs of people affected by a
disaster is finding shelter. While the proliferation of data on disasters is
already helping to save lives, identifying damages in buildings, assessing
shelter needs, and finding appropriate places to establish emergency shelters
or settlements require a wide range of data to be combined rapidly. To address
this gap and make a headway in comprehensive assessments, this paper proposes a
machine learning workflow that aims to fuse and rapidly analyse multimodal
data. This workflow is built around open and online data to ensure scalability
and broad accessibility. Based on a database of 19 characteristics for more
than 200 disasters worldwide, a fusion approach at the decision level was used.
This technique allows the collected multimodal data to share a common semantic
space that facilitates the prediction of individual variables. Each fused
numerical vector was fed into an unsupervised clustering algorithm called
Self-Organizing-Maps (SOM). The trained SOM serves as a predictor for future
cases, allowing predicting consequences such as total deaths, total people
affected, and total damage, and provides specific recommendations for
assessments in the shelter and housing sector. To achieve such prediction, a
satellite image from before the disaster and the geographic and demographic
conditions are shown to the trained model, which achieved a prediction accuracy
of 62 %",http://arxiv.org/abs/2108.00887v2
"A Channel-Aware Routing Protocol With Nearest Neighbor Regression For
  Underwater Sensor Networks",2021-08-11T06:50:59Z,"Boyu Diao, Chao Li, Qi Wang, Zhulin An, Yongjun Xu","The underwater acoustic channel is one of the most challenging communication
channels. Due to periodical tidal and daily climatic variation, underwater
noise is periodically fluctuating, which result in the periodical changing of
acoustic channel quality in long-term. Also, time-variant channel quality leads
to routing failure. Routing protocols with acoustic channel estimation, namely
underwater channel-aware routing protocols are recently proposed to maintain
the routing performance. However, channel estimation algorithms for these
routing protocols are mostly linear and rarely consider periodicity of acoustic
channels. In this paper, we introduce acoustic channel estimation based on
nearest neighbor regression for underwater acoustic networks. We extend nearest
neighbor regression for SNR (Signal-to-Noise Ratio) time series prediction,
providing an outstanding prediction accuracy for intricately periodical and
fluctuating received SNR time series. Moreover, we propose a quick search
algorithm and use statistical storage compression to optimize the time and
space complexity of the algorithm. In contrast with linear methods, this
algorithm significantly improves channel prediction accuracy (over three times
at most) on both simulation and sea trial data sets. With this channel
estimation method, we then propose a Depth-Based Channel-Aware Routing protocol
(DBCAR). Taking advantage of depth-greedy forwarding and channel-aware reliable
communication, DBCAR has an outstanding network performance on packet delivery
ratio, average energy consumption and average transmission delay which is
validated through extensive simulations.",http://arxiv.org/abs/2108.05057v2
Moser Flow: Divergence-based Generative Modeling on Manifolds,2021-08-18T09:00:24Z,"Noam Rozen, Aditya Grover, Maximilian Nickel, Yaron Lipman","We are interested in learning generative models for complex geometries
described via manifolds, such as spheres, tori, and other implicit surfaces.
Current extensions of existing (Euclidean) generative models are restricted to
specific geometries and typically suffer from high computational costs. We
introduce Moser Flow (MF), a new class of generative models within the family
of continuous normalizing flows (CNF). MF also produces a CNF via a solution to
the change-of-variable formula, however differently from other CNF methods, its
model (learned) density is parameterized as the source (prior) density minus
the divergence of a neural network (NN). The divergence is a local, linear
differential operator, easy to approximate and calculate on manifolds.
Therefore, unlike other CNFs, MF does not require invoking or backpropagating
through an ODE solver during training. Furthermore, representing the model
density explicitly as the divergence of a NN rather than as a solution of an
ODE facilitates learning high fidelity densities. Theoretically, we prove that
MF constitutes a universal density approximator under suitable assumptions.
Empirically, we demonstrate for the first time the use of flow models for
sampling from general curved surfaces and achieve significant improvements in
density estimation, sample quality, and training complexity over existing CNFs
on challenging synthetic geometries and real-world benchmarks from the earth
and climate sciences.",http://arxiv.org/abs/2108.08052v2
"Open source modelling of scenarios for a 100% renewable energy system in
  Barbados incorporating shore-to-ship power and electric vehicles",2021-08-23T11:28:26Z,"André Harewood, Franziska Dettner, Simon Hilpert","The high dependence on imported fuels and the potential for both climate
change mitigation and economic diversification make Barbados' energy system
particularly interesting for detailed transformation analysis. An open source
energy system model is presented here for the analysis of a future Barbadian
energy system. The model was applied in a scenario analysis, using a greenfield
approach, to investigate cost-optimal and 100% renewable energy system
configurations. Within the scenarios, the electrification of private passenger
vehicles and cruise ships through shore-to-ship power supply was modelled to
assess its impact on the energy system and the necessary investment in storage.
Results show that for most scenarios of a system in 2030, a renewable energy
share of over 80% is achieved in cost-optimal cases, even with a growing
demand. The system's levelised costs of electricity range from 0.17 to 0.36
BBD/kWh in the cost-optimal scenarios and increase only moderately for 100%
renewable systems. Under the reasonable assumption of decreasing photovoltaic
investment costs, system costs of a 100% system may be lower than the current
costs. The results show that pumped hydro-storage is a no-regret option for the
Barbadian power system design. Overall, the results highlight the great
potential of renewable energy as well as the technical and economic feasibility
of a 100% renewable energy system for Barbados.",http://arxiv.org/abs/2108.10083v3
Evaluating Fairness in Argument Retrieval,2021-08-23T23:19:35Z,"Sachin Pathiyan Cherumanal, Damiano Spina, Falk Scholer, W. Bruce Croft","Existing commercial search engines often struggle to represent different
perspectives of a search query. Argument retrieval systems address this
limitation of search engines and provide both positive (PRO) and negative (CON)
perspectives about a user's information need on a controversial topic (e.g.,
climate change). The effectiveness of such argument retrieval systems is
typically evaluated based on topical relevance and argument quality, without
taking into account the often differing number of documents shown for the
argument stances (PRO or CON). Therefore, systems may retrieve relevant
passages, but with a biased exposure of arguments. In this work, we analyze a
range of non-stochastic fairness-aware ranking and diversity metrics to
evaluate the extent to which argument stances are fairly exposed in argument
retrieval systems.
  Using the official runs of the argument retrieval task Touch\'e at CLEF 2020,
as well as synthetic data to control the amount and order of argument stances
in the rankings, we show that systems with the best effectiveness in terms of
topical relevance are not necessarily the most fair or the most diverse in
terms of argument stance. The relationships we found between (un)fairness and
diversity metrics shed light on how to evaluate group fairness -- in addition
to topical relevance -- in argument retrieval settings.",http://arxiv.org/abs/2108.10442v2
Feature Selection in High-dimensional Spaces Using Graph-Based Methods,2021-08-28T17:50:43Z,"Swarnadip Ghosh, Somabha Mukherjee, Divyansh Agarwal, Yichen He, Mingzhi Song, Xuejiao Pei","High-dimensional feature selection is a central problem in a variety of
application domains such as machine learning, image analysis, and genomics. In
this paper, we propose graph-based tests as a useful basis for feature
selection. We describe an algorithm for selecting informative features in
high-dimensional data, where each observation comes from one of $K$ different
distributions. Our algorithm can be applied in a completely nonparametric setup
without any distributional assumptions on the data, and it aims at outputting
those features in the data, that contribute the most to the overall
distributional variation. At the heart of our method is the recursive
application of distribution-free graph-based tests on subsets of the feature
set, located at different depths of a hierarchical clustering tree constructed
from the data. Our algorithm recovers all truly contributing features with high
probability, while ensuring optimal control on false-discovery. We show the
superior performance of our method over other existing ones through synthetic
data, and demonstrate the utility of this method on several real-life datasets
from the domains of climate change and biology, wherein our algorithm is not
only able to detect known features expected to be associated with the
underlying process, but also discovers novel targets that can be subsequently
studied.",http://arxiv.org/abs/2108.12682v3
"To Charge or to Sell? EV Pack Useful Life Estimation via LSTMs, CNNs,
  and Autoencoders",2021-10-07T16:09:01Z,"Michael Bosello, Carlo Falcomer, Claudio Rossi, Giovanni Pau","Electric vehicles (EVs) are spreading fast as they promise to provide better
performance and comfort, but above all, to help face climate change. Despite
their success, their cost is still a challenge. Lithium-ion batteries are one
of the most expensive EV components, and have become the standard for energy
storage in various applications. Precisely estimating the remaining useful life
(RUL) of battery packs can encourage their reuse and thus help to reduce the
cost of EVs and improve sustainability. A correct RUL estimation can be used to
quantify the residual market value of the battery pack. The customer can then
decide to sell the battery when it still has a value, i.e., before it exceeds
the end of life of the target application, so it can still be reused in a
second domain without compromising safety and reliability. This paper proposes
and compares two deep learning approaches to estimate the RUL of Li-ion
batteries: LSTM and autoencoders vs. CNN and autoencoders. The autoencoders are
used to extract useful features, while the subsequent network is then used to
estimate the RUL. Compared to what has been proposed so far in the literature,
we employ measures to ensure the method's applicability in the actual deployed
application. Such measures include (1) avoiding using non-measurable variables
as input, (2) employing appropriate datasets with wide variability and
different conditions, and (3) predicting the remaining ampere-hours instead of
the number of cycles. The results show that the proposed methods can generalize
on datasets consisting of numerous batteries with high variance.",http://arxiv.org/abs/2110.03585v2
"A Multi-scale Time-series Dataset with Benchmark for Machine Learning in
  Decarbonized Energy Grids",2021-10-12T20:18:49Z,"Xiangtian Zheng, Nan Xu, Loc Trinh, Dongqi Wu, Tong Huang, S. Sivaranjani, Yan Liu, Le Xie","The electric grid is a key enabling infrastructure for the ambitious
transition towards carbon neutrality as we grapple with climate change. With
deepening penetration of renewable energy resources and electrified
transportation, the reliable and secure operation of the electric grid becomes
increasingly challenging. In this paper, we present PSML, a first-of-its-kind
open-access multi-scale time-series dataset, to aid in the development of
data-driven machine learning (ML) based approaches towards reliable operation
of future electric grids. The dataset is generated through a novel transmission
+ distribution (T+D) co-simulation designed to capture the increasingly
important interactions and uncertainties of the grid dynamics, containing
electric load, renewable generation, weather, voltage and current measurements
over multiple spatio-temporal scales. Using PSML, we provide state-of-the-art
ML baselines on three challenging use cases of critical importance to achieve:
(i) early detection, accurate classification and localization of dynamic
disturbance events; (ii) robust hierarchical forecasting of load and renewable
energy with the presence of uncertainties and extreme events; and (iii)
realistic synthetic generation of physical-law-constrained measurement time
series. We envision that this dataset will enable advances for ML in dynamic
systems, while simultaneously allowing ML researchers to contribute towards
carbon-neutral electricity and mobility.",http://arxiv.org/abs/2110.06324v2
"Alpine Permafrost Modeling: On the influence of topography driven
  lateral fluxes",2021-10-14T08:25:42Z,"Jonas Beddrich, Shubhangi Gupta, Barbara Wohlmuth, Gabriele Chiogna","Alpine permafrost environments are highly vulnerable and sensitive to changes
in regional and global climate trends. Thawing and degradation of permafrost
has numerous adverse environmental, economic, and societal impacts.
Mathematical modeling and numerical simulations provide powerful tools for
predicting the degree of degradation and evolution of subsurface permafrost as
a result of global warming. A particularly significant characteristic of alpine
environments is the high variability in their topography and geomorphology
which drives large lateral thermal and fluid fluxes. Additionally, harsh winds,
extreme weather conditions, and various degrees of saturation have to be
considered. The combination of large lateral fluxes and unsaturated ground
makes alpine systems markedly different from Arctic permafrost environments and
general geotechnical ground freezing applications, and therefore, alpine
permafrost demands its own specialized modeling approaches. In this research
work, we present a multi-physics permafrost model tailored to alpine regions.
In particular, we resolve the ice-water phase transitions, unsaturated
conditions, and capillary actions, and account for the impact of the evolving
pore volume on fluid-matrix interactions. Moreover, the approach is
multi-dimensional, and therefore, inherently resolves fluxes along topographic
gradients. Through numerical cases studies based on the elevation profiles of
the two prominent peaks of the Zugspitze (DE) and the Matterhorn (CH), we show
the strong influence of topography driven thermal and fluid fluxes on active
layer dynamics and the distribution of permafrost.",http://arxiv.org/abs/2110.07217v2
Using attention to model long-term dependencies in occupancy behavior,2021-01-04T13:13:48Z,"Max Kleinebrahm, Jacopo Torriti, Russell McKenna, Armin Ardone, Wolf Fichtner","Models simulating household energy demand based on different occupant and
household types and their behavioral patterns have received increasing
attention over the last years due the need to better understand fundamental
characteristics that shape the demand side. Most of the models described in the
literature are based on Time Use Survey data and Markov chains. Due to the
nature of the underlying data and the Markov property, it is not sufficiently
possible to consider day to day dependencies in occupant behavior. An accurate
mapping of day to day dependencies is of increasing importance for accurately
reproducing mobility patterns and therefore for assessing the charging
flexibility of electric vehicles. This study bridges the gap between energy
related activity modelling and novel machine learning approaches with the
objective to better incorporate findings from the field of social practice
theory in the simulation of occupancy behavior. Weekly mobility data are merged
with daily time use survey data by using attention based models. In a first
step an autoregressive model is presented, which generates synthetic weekly
mobility schedules of individual occupants and thereby captures day to day
dependencies in mobility behavior. In a second step, an imputation model is
presented, which enriches the weekly mobility schedules with detailed
information about energy relevant at home activities. The weekly activity
profiles build the basis for modelling consistent electricity, heat and
mobility demand profiles of households. Furthermore, the approach presented
forms the basis for providing data on socio-demographically differentiated
occupant behavior to the general public.",http://arxiv.org/abs/2101.00940v1
Re-examining the Role of Nuclear Fusion in a Renewables-Based Energy Mix,2021-01-14T17:05:18Z,"T. E. G. Nicholas, T. P. Davis, F. Federici, J. E. Leland, B. S. Patel, C. Vincent, S. H. Ward","Fusion energy is often regarded as a long-term solution to the world's energy
needs. However, even after solving the critical research challenges,
engineering and materials science will still impose significant constraints on
the characteristics of a fusion power plant. Meanwhile, the global energy grid
must transition to low-carbon sources by 2050 to prevent the worst effects of
climate change. We review three factors affecting fusion's future trajectory:
(1) the significant drop in the price of renewable energy, (2) the
intermittency of renewable sources and implications for future energy grids,
and (3) the recent proposition of intermediate-level nuclear waste as a product
of fusion. Within the scenario assumed by our premises, we find that while
there remains a clear motivation to develop fusion power plants, this
motivation is likely weakened by the time they become available. We also
conclude that most current fusion reactor designs do not take these factors
into account and, to increase market penetration, fusion research should
consider relaxed nuclear waste design criteria, raw material availability
constraints and load-following designs with pulsed operation.",http://arxiv.org/abs/2101.05727v1
Optimal sampling and assay for soil organic carbon estimation,2021-01-19T01:23:37Z,Jacob V Spertus,"The world needs around 150 Pg of negative carbon emissions to mitigate
climate change. Global soils may provide a stable, sizeable reservoir to help
achieve this goal by sequestering atmospheric carbon dioxide as soil organic
carbon (SOC). In turn, SOC can support healthy soils and provide a multitude of
ecosystem benefits. To support SOC sequestration, researchers and policy makers
must be able to precisely measure the amount of SOC in a given plot of land.
SOC measurement is typically accomplished by taking soil cores selected at
random from the plot under study, mixing (compositing) some of them together,
and analyzing (assaying) the composited samples in a laboratory. Compositing
reduces assay costs, which can be substantial. Taking samples is also costly.
Given uncertainties and costs in both sampling and assay along with a desired
estimation precision, there is an optimal composite size that will minimize the
budget required to achieve that precision. Conversely, given a fixed budget,
there is a composite size that minimizes uncertainty. In this paper, we
describe and formalize sampling and assay for SOC and derive the optima for
three commonly used assay methods: dry combustion in an elemental analyzer,
loss-on-ignition, and mid-infrared spectroscopy. We demonstrate the utility of
this approach using data from a soil survey conducted in California. We give
recommendations for practice and provide software to implement our framework.",http://arxiv.org/abs/2101.07398v4
"Model and Data Reduction for Data Assimilation: Particle Filters
  Employing Projected Forecasts and Data with Application to a Shallow Water
  Model",2021-01-22T18:10:05Z,"Aishah Albarakati, Marko Budišić, Rose Crocker, Juniper Glass-Klaiber, Sarah Iams, John Maclean, Noah Marshall, Colin Roberts, Erik S. Van Vleck","The understanding of nonlinear, high dimensional flows, e.g, atmospheric and
ocean flows, is critical to address the impacts of global climate change. Data
Assimilation techniques combine physical models and observational data, often
in a Bayesian framework, to predict the future state of the model and the
uncertainty in this prediction. Inherent in these systems are noise (Gaussian
and non-Gaussian), nonlinearity, and high dimensionality that pose challenges
to making accurate predictions. To address these issues we investigate the use
of both model and data dimension reduction based on techniques including
Assimilation in Unstable Subspaces, Proper Orthogonal Decomposition, and
Dynamic Mode Decomposition. Algorithms that take advantage of projected
physical and data models may be combined with Data Analysis techniques such as
Ensemble Kalman Filter and Particle Filter variants. The projected Data
Assimilation techniques are developed for the optimal proposal particle filter
and applied to the Lorenz'96 and Shallow Water Equations to test the efficacy
of our techniques in high dimensional, nonlinear systems.",http://arxiv.org/abs/2101.09252v2
An open-source tool to assess the carbon footprint of research,2021-01-21T09:15:01Z,"Jérôme Mariette, Odile Blanchard, Olivier Berné, Tamara Ben Ari","Research institutions are bound to contribute to greenhouse gas emission
(GHG) reduction efforts for several reasons. First, part of the scientific
community's research deals with climate change issues. Second, scientists
contribute to students' education: they must be consistent and role models.
Third the literature on the carbon footprint of researchers points to the high
level of some individual footprints. In a quest for consistency and role
models, scientists, teams of scientists or universities have started to
quantify their carbon footprints and debate on reduction options. Indeed,
measuring the carbon footprint of research activities requires tools designed
to tackle its specific features. In this paper, we present an open-source web
application, GES 1point5, developed by an interdisciplinary team of scientists
from several research labs in France. GES 1point5 is specifically designed to
estimate the carbon footprint of research activities in France. It operates at
the scale of research labs, i.e. laboratoires, which are the social structures
around which research is organized in France and the smallest decision making
entities in the French research system. The application allows French research
labs to compute their own carbon footprint along a standardized, open protocol.
The data collected in a rapidly growing network of labs will be used as part of
the Labos 1point5 project to estimate France's research carbon footprint. At
the time of submitting this manuscript, 89 research labs had engaged with GES
1point5 to estimate their greenhouse gas emissions. We expect that an
international adoption of GES 1point5 (adapted to fit domestic specifics) could
contribute to establishing a global understanding of the drivers of the
research carbon footprint worldwide and the levers to decrease it.",http://arxiv.org/abs/2101.10124v1
Why polls fail to predict elections,2021-01-27T13:39:45Z,"Zhenkun Zhou, Matteo Serafino, Luciano Cohan, Guido Caldarelli, Hernan A. Makse","In the past decade we have witnessed the failure of traditional polls in
predicting presidential election outcomes across the world. To understand the
reasons behind these failures we analyze the raw data of a trusted pollster
which failed to predict, along with the rest of the pollsters, the surprising
2019 presidential election in Argentina which has led to a major market
collapse in that country. Analysis of the raw and re-weighted data from
longitudinal surveys performed before and after the elections reveals clear
biases (beyond well-known low-response rates) related to mis-representation of
the population and, most importantly, to social-desirability biases, i.e., the
tendency of respondents to hide their intention to vote for controversial
candidates. We then propose a longitudinal opinion tracking method based on
big-data analytics from social media, machine learning, and network theory that
overcomes the limits of traditional polls. The model achieves accurate results
in the 2019 Argentina elections predicting the overwhelming victory of the
candidate Alberto Fern\'andez over the president Mauricio Macri; a result that
none of the traditional pollsters in the country was able to predict. Beyond
predicting political elections, the framework we propose is more general and
can be used to discover trends in society; for instance, what people think
about economics, education or climate change.",http://arxiv.org/abs/2101.11389v1
MiniV2G: An Electric Vehicle Charging Emulator,2021-01-27T22:14:27Z,"Luca Attanasio, Mauro Conti, Denis Donadel, Federico Turrin","The impact of global warming and the imperative to limit climate change have
stimulated the need to develop new solutions based on renewable energy sources.
One of the emerging trends in this endeavor are the Electric Vehicles (EVs),
which use electricity instead of traditional fossil fuels as a power source,
relying on the Vehicle-to-Grid (V2G) paradigm. The novelty of such a paradigm
requires careful analysis to avoid malicious attempts. An attacker can exploit
several surfaces, such as the remote connection between the Distribution Grid
and Charging Supply or the authentication system between the charging Supply
Equipment and the Electric Vehicles. However, V2G architecture's high cost and
complexity in implementation can restrain this field's research capability. In
this paper, we approach this limitation by proposing MiniV2G, an open-source
emulator to simulate Electric Vehicle Charging (EVC) built on top of Mininet
and RiseV2G. MiniV2G is particularly suitable for security researchers to study
and test real V2G charging scenarios. MiniV2G can reproduce with high fidelity
a V2G architecture to easily simulate an EV charging process. Finally, we
present a MiniV2G application and show how MiniV2G can be used to study V2G
communication and develop attacks and countermeasures that can be applied to
real systems. Since we believe our tool can be of great help for research in
this field, we also made it freely available.",http://arxiv.org/abs/2101.11720v1
"Haze seasonal variations of Titan's upper atmosphere during the Cassini
  Mission",2021-02-10T11:24:24Z,"Benoît Seignovert, Pascal Rannou, Robert A. West, Sandrine Vinatier","This study presents a 13 years survey of haze UV extinction profiles,
monitoring the temporal evolution of the detached haze layer (DHL) in Titan's
upper atmosphere (350-600 km). As reported by West et al. 2011 (GRL vol.38,
L06204) at the equator, we show that the DHL is present at all latitudes below
55{\deg}N during the northern winter (2004-2009). Then, it globally sunk and
disappeared in 2012. No permanent DHL was observed between 2012 and 2015. It's
only in late-2015, that a new structure emerged from the Northern hemisphere
and propagated to the equator. This new DHL is not as pronounced as in 2004 and
is much more complex than the one observed earlier. In one specific sequence,
in 2005, we were able to investigate the short time scale variability of the
DHL and no major changes was observed. When both side of the limb were visible
(dawn/dusk), we notice that the extinction of the DHL is slightly higher on the
dawn side. Additionally, during a polar flyby in 2009, we observed the
longitudinal variability of the DHL and spotted some local inhomogeneities.
Finally, comparisons with UVIS stellar occultations and General Climate Models
(GCMs) are both consistent with our findings. However, we noticed that the
timing of the DHL main pattern predicted by the GMCs can be off by up to
30{\deg} in solar longitude. All these observations bring new perspectives on
the seasonal cycle of Titan's upper atmosphere, the evolution of the DHL and
its interaction with the dynamics.",http://arxiv.org/abs/2102.05384v1
Mean Field Models to Regulate Carbon Emissions in Electricity Production,2021-02-18T15:49:55Z,"Rene Carmona, Gokce Dayanikli, Mathieu Lauriere","The most serious threat to ecosystems is the global climate change fueled by
the uncontrolled increase in carbon emissions. In this project, we use mean
field control and mean field game models to analyze and inform the decisions of
electricity producers on how much renewable sources of production ought to be
used in the presence of a carbon tax. The trade-off between higher revenues
from production and the negative externality of carbon emissions is quantified
for each producer who needs to balance in real time reliance on reliable but
polluting (fossil fuel) thermal power stations versus investing in and
depending upon clean production from uncertain wind and solar technologies. We
compare the impacts of these decisions in two different scenarios: 1) the
producers are competitive and hopefully reach a Nash Equilibrium; 2) they
cooperate and reach a Social Optimum. We first prove that both problems have a
unique solution using forward-backward systems of stochastic differential
equations. We then illustrate with numerical experiments the producers'
behavior in each scenario. We further introduce and analyze the impact of a
regulator in control of the carbon tax policy, and we study the resulting
Stackelberg equilibrium with the field of producers.",http://arxiv.org/abs/2102.09434v2
"Upgraded Metallurgical Grade Silicon for solar electricity production: a
  comparative Life Cycle Assessment",2021-02-23T09:21:39Z,"Laura Méndez, Eduardo Forniés, Daniel Garrain, Antonio Pérez Vázquez, Alejandro Souto, Timur Vlasenko","Solar grade silicon (SoG-Si) is a key material for the development of
crystalline silicon photovoltaics (PV), which is expected to reach the
tera-watt level in the next years and around 50TW in 2050. Upgraded
metallurgical grade silicon (UMG-Si) has already demonstrated to be a viable
alternative to standard polysilicon in terms of cost and quality. This study
presents the life cycle assessment (LCA) of UMG obtained by the FerroSolar
process. Moreover, it shows the environmental impacts of PV modules and
electricity generation based on this material. For this, an exhaustive review
of the life cycle inventory (LCI) of PV value chain, from metallurgical grade
silicon (MG-Si) down to electricity generation, has been carried out updating
inputs for all processes. The Balance of System (BoS) has also been updated
with real state of the art data for a fixed open ground large PV site (100 MW).
Two different electricity mixes, with low and high carbon intensities, have
been considered. The results reveal that for PV electricity generation using
UMG instead of polysilicon leads to an overall reduction of Climate change (CC)
emissions of over 20%, along with an improvement of the Energy Payback Time
(EPBT) of 25%, achieving significantly low values, 12 gCO2eq / kWhe and 0.52
years, respectively. Moreover, it is shown that UMG silicon feedstock is not
the main contributor to the carbon and energy footprint of the produced
electricity, leaving the first place to PV module manufacturing.",http://arxiv.org/abs/2102.11571v1
Radiative cooling of colored paint based on Fe3+ doped Y2Ce2O7,2021-02-25T05:05:22Z,"Saichao Dang, Jingbo Xiang, Hongxin Yao, Fan Yang, Hong Ye","Materials with both low absorption of incoming solar radiation and high
emittance in mid-infrared band can be applied for daytime radiative cooling.
Current state-of-the-art materials for passive radiative cooling often utilize
a combination of solar reflector and infrared emitter by different structures,
or even by expensive nanofabricated photonic structures, which limits the
applications in practice. In this study, possessing these two specified
radiative properties, pure Y2Ce2O7 is demonstrated with a performance of
passive radiative cooling. With a bandgap at 375.7 nm, the prepared Y2Ce2O7
shows a high solar reflectance of 91%, while with lattice strain and distortion
of various bonds (e.g., Y-O, Ce-O), it also shows a high emittance of 0.96 in
MIR band. More attracting, the aesthetics performance of Y2Ce2O7 can be
modified by doping Fe3+ ions to change its color from ivory white to light
yellow or red with high NIR reflection and MIR emission, indicating that the
Y2Ce2-xFexO7 shows a better cooling performance than a common paint with a
similar color. According to the field demonstration of cooling performance at
noon time, the Y2Ce2O7 and Y2Ce1.9Fe0.1O7 paints are 2.2 K and 1.8 K lower than
the common white and umber paints, respectively, while at night, all paints are
2.3 K lower than the ambient air. If applied on the envelop of a building, the
simulation shows that the Y2Ce2O7 and Y2Ce1.9Fe0.1O7 paints save 54.45% and
21.14% energy consumption compared with a common white and umber paints,
respectively, in a hot season. The demonstrated Y2Ce2-xFexO7 holds potentials
for energy-saving applications in hot climates.",http://arxiv.org/abs/2102.12686v1
"CLIMAT: Clinically-Inspired Multi-Agent Transformers for Knee
  Osteoarthritis Trajectory Forecasting",2021-04-08T09:53:18Z,"Huy Hoang Nguyen, Simo Saarakkala, Matthew B. Blaschko, Aleksei Tiulpin","In medical applications, deep learning methods are built to automate
diagnostic tasks. However, a clinically relevant question that practitioners
usually face, is how to predict the future trajectory of a disease (prognosis).
Current methods for such a problem often require domain knowledge, and are
complicated to apply. In this paper, we formulate the prognosis prediction
problem as a one-to-many forecasting problem from multimodal data. Inspired by
a clinical decision-making process with two agents -- a radiologist and a
general practitioner, we model a prognosis prediction problem with two
transformer-based components that share information between each other. The
first block in this model aims to analyze the imaging data, and the second
block leverages the internal representations of the first one as inputs, also
fusing them with auxiliary patient data. We show the effectiveness of our
method in predicting the development of structural knee osteoarthritis changes
over time. Our results show that the proposed method outperforms the
state-of-the-art baselines in terms of various performance metrics. In
addition, we empirically show that the existence of the multi-agent
transformers with depths of 2 is sufficient to achieve good performances. Our
code is publicly available at \url{https://github.com/MIPT-Oulu/CLIMAT}.",http://arxiv.org/abs/2104.03642v3
Ice Core Science Meets Computer Vision: Challenges and Perspectives,2021-04-09T15:27:44Z,"P. Bohleber, M. Roman, C. Barbante, S. Vascon, K. Siddiqi, M. Pelillo","Polar ice cores play a central role in studies of the earth's climate system
through natural archives. A pressing issue is the analysis of the oldest,
highly thinned ice core sections, where the identification of paleoclimate
signals is particularly challenging. For this, state-of-the-art imaging by
laser-ablation inductively-coupled plasma mass spectrometry (LA-ICP-MS) has the
potential to be revolutionary due to its combination of micron-scale 2D
chemical information with visual features. However, the quantitative study of
record preservation in chemical images raises new questions that call for the
expertise of the computer vision community. To illustrate this new
inter-disciplinary frontier, we describe a selected set of key questions. One
critical task is to assess the paleoclimate significance of single line
profiles along the main core axis, which we show is a scale-dependent problem
for which advanced image analysis methods are critical. Another important issue
is the evaluation of post-depositional layer changes, for which the chemical
images provide rich information. Accordingly, the time is ripe to begin an
intensified exchange among the two scientific communities of computer vision
and ice core science. The collaborative building of a new framework for
investigating high-resolution chemical images with automated image analysis
techniques will also benefit the already wide-spread application of LA-ICP-MS
chemical imaging in the geosciences.",http://arxiv.org/abs/2104.04430v1
"Applications of physics-informed scientific machine learning in
  subsurface science: A survey",2021-04-10T13:40:22Z,"Alexander Y. Sun, Hongkyu Yoon, Chung-Yan Shih, Zhi Zhong","Geosystems are geological formations altered by humans activities such as
fossil energy exploration, waste disposal, geologic carbon sequestration, and
renewable energy generation. Geosystems also represent a critical link in the
global water-energy nexus, providing both the source and buffering mechanisms
for enabling societal adaptation to climate variability and change. The
responsible use and exploration of geosystems are thus critical to the
geosystem governance, which in turn depends on the efficient monitoring, risk
assessment, and decision support tools for practical implementation. Fast
advances in machine learning (ML) algorithms and novel sensing technologies in
recent years have presented new opportunities for the subsurface research
community to improve the efficacy and transparency of geosystem governance.
Although recent studies have shown the great promise of scientific ML (SciML)
models, questions remain on how to best leverage ML in the management of
geosystems, which are typified by multiscality, high-dimensionality, and data
resolution inhomogeneity. This survey will provide a systematic review of the
recent development and applications of domain-aware SciML in geosystem
researches, with an emphasis on how the accuracy, interpretability,
scalability, defensibility, and generalization skill of ML approaches can be
improved to better serve the geoscientific community.",http://arxiv.org/abs/2104.04764v2
"Paris Agreement requires substantial, broad, and sustained engagements
  beyond COVID-19 public stimulus packages",2021-04-16T19:46:01Z,"Katsumasa Tanaka, Christian Azar, Olivier Boucher, Philippe Ciais, Yann Gaucher, Daniel J. A. Johansson","It has been claimed that COVID-19 public stimulus packages could be
sufficient to meet the short-term energy investment needs to leverage a shift
toward a pathway consistent with the 1.5 degrees C target of the Paris
Agreement. Here we provide complementary perspectives to reiterate that
substantial, broad, and sustained engagements beyond stimulus packages will be
needed for achieving the Paris Agreement long-term targets. Low-carbon
investments will need to scale up and persist over the next several decades
following short-term stimulus packages. The required total energy investments
in the real world can be larger than the currently available estimates from
Integrated Assessment Models (IAMs). Existing databases from IAMs are not
sufficient for analyzing the effect of public spending on emission reduction.
To inform what role COVID-19 stimulus packages and public investments may play
for reaching the Paris Agreement targets, explicit modelling of such policies
is required.",http://arxiv.org/abs/2104.08342v5
"Misinfo Reaction Frames: Reasoning about Readers' Reactions to News
  Headlines",2021-04-18T09:50:11Z,"Saadia Gabriel, Skyler Hallinan, Maarten Sap, Pemi Nguyen, Franziska Roesner, Eunsol Choi, Yejin Choi","Even to a simple and short news headline, readers react in a multitude of
ways: cognitively (e.g. inferring the writer's intent), emotionally (e.g.
feeling distrust), and behaviorally (e.g. sharing the news with their friends).
Such reactions are instantaneous and yet complex, as they rely on factors that
go beyond interpreting factual content of news. We propose Misinfo Reaction
Frames (MRF), a pragmatic formalism for modeling how readers might react to a
news headline. In contrast to categorical schema, our free-text dimensions
provide a more nuanced way of understanding intent beyond being benign or
malicious. We also introduce a Misinfo Reaction Frames corpus, a crowdsourced
dataset of reactions to over 25k news headlines focusing on global crises: the
Covid-19 pandemic, climate change, and cancer. Empirical results confirm that
it is indeed possible for neural models to predict the prominent patterns of
readers' reactions to previously unseen news headlines. Additionally, our user
study shows that displaying machine-generated MRF implications alongside news
headlines to readers can increase their trust in real news while decreasing
their trust in misinformation. Our work demonstrates the feasibility and
importance of pragmatic inferences on news headlines to help enhance AI-guided
misinformation detection and mitigation.",http://arxiv.org/abs/2104.08790v4
"Contracts in Electricity Markets under EU ETS: A Stochastic Programming
  Approach",2021-04-30T15:31:32Z,"Arega Getaneh Abate, Rossana Riccardi, Carlos Ruiz","The European Union Emission Trading Scheme (EU ETS) is a cornerstone of the
EU's strategy to fight climate change and an important device for plummeting
greenhouse gas (GHG) emissions in an economically efficient manner. The power
industry has switched to an auction-based allocation system at the onset of
Phase III of the EU ETS to bring economic efficiency by negating windfall
profits that have been resulted from grandfathered allocation of allowances in
the previous phases. In this work, we analyze and simulate the interaction of
oligopolistic generators in an electricity market with a game-theoretical
framework where the electricity and the emissions markets interact in a
two-stage electricity market. For analytical simplicity, we assume a single
futures market where the electricity is committed at the futures price, and the
emissions allowance is contracted in advance, prior to a spot market where the
energy and allowances delivery takes place. Moreover, a coherent risk measure
is applied (Conditional Value at Risk) to model both risk averse and risk
neutral generators and a two-stage stochastic optimization setting is
introduced to deal with the uncertainty of renewable capacity, demand,
generation, and emission costs. The performance of the proposed equilibrium
model and its main properties are examined through realistic numerical
simulations. Our results show that renewable generators are surging and
substituting conventional generators without compromising social welfare.
Hence, both renewable deployment and emission allowance auctioning are
effectively reducing GHG emissions and promoting low-carbon economic path.",http://arxiv.org/abs/2104.15062v1
"Semi-Supervised Audio Representation Learning for Modeling Beehive
  Strengths",2021-05-21T18:59:29Z,"Tony Zhang, Szymon Zmyslony, Sergei Nozdrenkov, Matthew Smith, Brandon Hopkins","Honey bees are critical to our ecosystem and food security as a pollinator,
contributing 35% of our global agriculture yield. In spite of their importance,
beekeeping is exclusively dependent on human labor and experience-derived
heuristics, while requiring frequent human checkups to ensure the colony is
healthy, which can disrupt the colony. Increasingly, pollinator populations are
declining due to threats from climate change, pests, environmental toxicity,
making their management even more critical than ever before in order to ensure
sustained global food security. To start addressing this pressing challenge, we
developed an integrated hardware sensing system for beehive monitoring through
audio and environment measurements, and a hierarchical semi-supervised deep
learning model, composed of an audio modeling module and a predictor, to model
the strength of beehives. The model is trained jointly on audio reconstruction
and prediction losses based on human inspections, in order to model both
low-level audio features and circadian temporal dynamics. We show that this
model performs well despite limited labels, and can learn an audio embedding
that is useful for characterizing different sound profiles of beehives. This is
the first instance to our knowledge of applying audio-based deep learning to
model beehives and population size in an observational setting across a large
number of hives.",http://arxiv.org/abs/2105.10536v1
"Robustness of electricity systems with nearly 100% share of renewables:
  a worst-case study",2021-05-30T17:00:20Z,"Francisco Gutierrez-Garcia, Angel Arcos-Vargas, Antonio Gomez-Exposito","Several research studies have shown that future sustainable electricity
systems, mostly based on renewable generation and storage, are feasible with
current technologies and costs. However, recent episodes of extreme weather
conditions, probably associated with climate change, cast shades of doubt on
whether the resulting generation portfolios are sufficiently robust to assure,
at all times, a suitable balance between generation and demand, when adverse
conditions are faced. To address this issue, this work elaborates a methodology
intended to determine a sustainable electricity system that can endure extreme
weather conditions, which are likely to occur. First, using hourly production
and demand data from the last decade, along with estimates of new uses of
electricity, a worst-case scenario is constructed, including the storage
capacity and additional photovoltaic power which are needed to serve the demand
on an hourly basis. Next, several key parameters which may have a significant
influence on the LCOE are considered, and a sensitivity analysis is carried out
to determine their real impact, significance and potential trends. The proposed
methodology is then applied to the Spanish system. The results show that, under
the hypotheses and conditions considered in this paper, it is possible to
design a decarbonized electricity system that, taking advantage of existing
sustainable assets, satisfies the long-term needs by providing a reliable
supply at an average cost significantly lower than current market prices.",http://arxiv.org/abs/2105.14582v1
"Decarbonising the EU Power Sector: a Technological and Socio-economic
  Analysis and the Role of Nuclear",2021-07-02T15:07:18Z,"Maria Papadopoulou, Roberto Passalacqua, Domenico Rossetti di Valdalbero, Elena Righi Steele","Low-carbon electricity is a key enabler in combating climate change.
Decarbonising the power sector is now at the centre of global and European
policies. As the IPCC highlights, pathways where the power sector rapidly
decarbonises by 2030 have higher chances of keeping global warming below
1.5$^\circ$C. The electricity sector should be fully decarbonised by 2050 to
meet either the 1.5$^\circ$C or 2$^\circ$C targets. This means that EU policy
efforts should focus on supporting a maximum reduction of emissions per unit of
electricity by 2030 and net-zero emissions by 2050. Reaching these targets is
one of the most pressing questions EU policymakers face today. In light of the
COVID-19 crisis, EU policies should guide a cost-effective, reliable and
environmentally sound transition of the power sector, benefiting EU research
and innovation and its citizens. This meta-analysis provides a novel view on
historical data and compares data from modelling scenarios identified in the
literature. It assesses the current and future role of nuclear energy in
decarbonizing the EU power sector, while reviewing socio-economic implications
that could arise if limited public support nearly excludes nuclear fission
electricity from the future EU power mix. This work highlights relevant
socio-economic policy implications and actionable policy recommendations.",http://arxiv.org/abs/2107.01121v1
"Machine Learning Challenges and Opportunities in the African
  Agricultural Sector -- A General Perspective",2021-07-11T17:48:23Z,Racine Ly,"The improvement of computers' capacities, advancements in algorithmic
techniques, and the significant increase of available data have enabled the
recent developments of Artificial Intelligence (AI) technology. One of its
branches, called Machine Learning (ML), has shown strong capacities in
mimicking characteristics attributed to human intelligence, such as vision,
speech, and problem-solving. However, as previous technological revolutions
suggest, their most significant impacts could be mostly expected on other
sectors that were not traditional users of that technology. The agricultural
sector is vital for African economies; improving yields, mitigating losses, and
effective management of natural resources are crucial in a climate change era.
Machine Learning is a technology with an added value in making predictions,
hence the potential to reduce uncertainties and risk across sectors, in this
case, the agricultural sector. The purpose of this paper is to contextualize
and discuss barriers to ML-based solutions for African agriculture. In the
second section, we provided an overview of ML technology from a historical and
technical perspective and its main driving force. In the third section, we
provided a brief review of the current use of ML in agriculture. Finally, in
section 4, we discuss ML growing interest in Africa and the potential barriers
to creating and using ML-based solutions in the agricultural sector.",http://arxiv.org/abs/2107.05101v1
"National-scale electricity peak load forecasting: Traditional, machine
  learning, or hybrid model?",2021-06-30T15:17:23Z,"Juyong Lee, Youngsang Cho","As the volatility of electricity demand increases owing to climate change and
electrification, the importance of accurate peak load forecasting is
increasing. Traditional peak load forecasting has been conducted through time
series-based models; however, recently, new models based on machine or deep
learning are being introduced. This study performs a comparative analysis to
determine the most accurate peak load-forecasting model for Korea, by comparing
the performance of time series, machine learning, and hybrid models. Seasonal
autoregressive integrated moving average with exogenous variables (SARIMAX) is
used for the time series model. Artificial neural network (ANN), support vector
regression (SVR), and long short-term memory (LSTM) are used for the machine
learning models. SARIMAX-ANN, SARIMAX-SVR, and SARIMAX-LSTM are used for the
hybrid models. The results indicate that the hybrid models exhibit significant
improvement over the SARIMAX model. The LSTM-based models outperformed the
others; the single and hybrid LSTM models did not exhibit a significant
performance difference. In the case of Korea's highest peak load in 2019, the
predictive power of the LSTM model proved to be greater than that of the
SARIMAX-LSTM model. The LSTM, SARIMAX-SVR, and SARIMAX-LSTM models outperformed
the current time series-based forecasting model used in Korea. Thus, Korea's
peak load-forecasting performance can be improved by including machine learning
or hybrid models.",http://arxiv.org/abs/2107.06174v1
"Flood Segmentation on Sentinel-1 SAR Imagery with Semi-Supervised
  Learning",2021-07-18T05:42:10Z,"Sayak Paul, Siddha Ganju","Floods wreak havoc throughout the world, causing billions of dollars in
damages, and uprooting communities, ecosystems and economies. The NASA Impact
Flood Detection competition tasked participants with predicting flooded pixels
after training with synthetic aperture radar (SAR) images in a supervised
setting. We propose a semi-supervised learning pseudo-labeling scheme that
derives confidence estimates from U-Net ensembles, progressively improving
accuracy. Concretely, we use a cyclical approach involving multiple stages (1)
training an ensemble model of multiple U-Net architectures with the provided
high confidence hand-labeled data and, generated pseudo labels or low
confidence labels on the entire unlabeled test dataset, and then, (2) filter
out quality generated labels and, (3) combine the generated labels with the
previously available high confidence hand-labeled dataset. This assimilated
dataset is used for the next round of training ensemble models and the cyclical
process is repeated until the performance improvement plateaus. We post process
our results with Conditional Random Fields. Our approach sets a new
state-of-the-art on the Sentinel-1 dataset with 0.7654 IoU, an impressive
improvement over the 0.60 IoU baseline. Our method, which we release with all
the code and models, can also be used as an open science benchmark for the
Sentinel-1 dataset.",http://arxiv.org/abs/2107.08369v4
"Proceedings of KDD 2021 Workshop on Data-driven Humanitarian Mapping:
  Harnessing Human-Machine Intelligence for High-Stake Public Policy and
  Resilience Planning",2021-08-31T22:41:14Z,"Snehalkumar, S. Gaikwad, Shankar Iyer, Dalton Lunga, Elizabeth Bondi","Humanitarian challenges, including natural disasters, food insecurity,
climate change, racial and gender violence, environmental crises, the COVID-19
coronavirus pandemic, human rights violations, and forced displacements,
disproportionately impact vulnerable communities worldwide. According to UN
OCHA, 235 million people will require humanitarian assistance in 2021. Despite
these growing perils, there remains a notable paucity of data science research
to scientifically inform equitable public policy decisions for improving the
livelihood of at-risk populations. Scattered data science efforts exist to
address these challenges, but they remain isolated from practice and prone to
algorithmic harms concerning lack of privacy, fairness, interpretability,
accountability, transparency, and ethics. Biases in data-driven methods carry
the risk of amplifying inequalities in high-stakes policy decisions that impact
the livelihood of millions of people. Consequently, proclaimed benefits of
data-driven innovations remain inaccessible to policymakers, practitioners, and
marginalized communities at the core of humanitarian actions and global
development. To help fill this gap, we propose the Data-driven Humanitarian
Mapping Research Program, which focuses on developing novel data science
methodologies that harness human-machine intelligence for high-stakes public
policy and resilience planning.
  The proceedings of the 2nd Data-driven Humanitarian Mapping workshop at the
27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining. August 15th,
2021",http://arxiv.org/abs/2109.00100v4
"Proceedings of KDD 2020 Workshop on Data-driven Humanitarian Mapping:
  Harnessing Human-Machine Intelligence for High-Stake Public Policy and
  Resilience Planning",2021-09-01T15:30:25Z,"Snehalkumar, S. Gaikwad, Shankar Iyer, Dalton Lunga, Yu-Ru Lin","Humanitarian challenges, including natural disasters, food insecurity,
climate change, racial and gender violence, environmental crises, the COVID-19
coronavirus pandemic, human rights violations, and forced displacements,
disproportionately impact vulnerable communities worldwide. According to UN
OCHA, 235 million people will require humanitarian assistance in 2021 . Despite
these growing perils, there remains a notable paucity of data science research
to scientifically inform equitable public policy decisions for improving the
livelihood of at-risk populations. Scattered data science efforts exist to
address these challenges, but they remain isolated from practice and prone to
algorithmic harms concerning lack of privacy, fairness, interpretability,
accountability, transparency, and ethics. Biases in data-driven methods carry
the risk of amplifying inequalities in high-stakes policy decisions that impact
the livelihood of millions of people. Consequently, proclaimed benefits of
data-driven innovations remain inaccessible to policymakers, practitioners, and
marginalized communities at the core of humanitarian actions and global
development. To help fill this gap, we propose the Data-driven Humanitarian
Mapping Research Program, which focuses on developing novel data science
methodologies that harness human-machine intelligence for high-stakes public
policy and resilience planning.
  The proceedings of the 1st Data-driven Humanitarian Mapping workshop at the
26th ACM SIGKDD Conference on Knowledge Discovery & Data Mining, August 24th,
2020.",http://arxiv.org/abs/2109.00435v3
Understanding Cycling Mobility: Bologna Case Study,2021-09-09T13:11:35Z,"Taron Davtian, Flavio Bertini, Rajesh Sharma","Understanding human mobility in urban environments is of the utmost
importance to manage traffic and for deploying new resources and services. In
recent years, the problem is exacerbated due to rapid urbanization and climate
changes. In an urban context, human mobility has many facets, and cycling
represents one of the most eco-friendly and efficient/effective ways to move in
touristic and historical cities. The main objective of this work is to study
the cycling mobility within the city of Bologna, Italy. We used six months
dataset that consists of 320,118 self-reported bike trips. In particular, we
performed several descriptive analysis to understand spatial and temporal
patterns of bike users for understanding popular roads, and most favorite
points within the city. This analysis involved several other public datasets in
order to explore variables that can possibly affect the cycling activity, such
as weather, pollution, and events. The main results of this study indicate that
bike usage is more correlated to temperature, and precipitation and has no
correlation to wind speed and pollution. In addition, we also exploited various
machine learning and deep learning approaches for predicting short-term trips
in the near future (that is for the following 30, and 60 minutes), that could
help local governmental agencies for urban planning. Our best model achieved an
R square of 0.91, a Mean Absolute Error of 5.38 and a Root Mean Squared Error
of 8.12 for the 30-minutes time interval.",http://arxiv.org/abs/2109.04243v1
"Preliminary Wildfire Detection Using State-of-the-art PTZ (Pan, Tilt,
  Zoom) Camera Technology and Convolutional Neural Networks",2021-09-10T19:30:37Z,Samarth Shah,"Wildfires are uncontrolled fires in the environment that can be caused by
humans or nature. In 2020 alone, wildfires in California have burned 4.2
million acres, damaged 10,500 buildings or structures, and killed more than 31
people, exacerbated by climate change and a rise in average global
temperatures. This also means there has been an increase in the costs of
extinguishing these treacherous wildfires. The objective of the research is to
detect forest fires in their earlier stages to prevent them from spreading,
prevent them from causing damage to a variety of things, and most importantly,
reduce or eliminate the chances of someone dying from a wildfire. A fire
detection system should be efficient and accurate with respect to extinguishing
wildfires in their earlier stages to prevent the spread of them along with
their consequences. Computer Vision is potentially a more reliable, fast, and
widespread method we need. The current research in the field of preliminary
fire detection has several problems related to unrepresentative data being used
to train models and their existing varied amounts of label imbalance in the
classes of their dataset. We propose a more representative and evenly
distributed data through better settings, lighting, atmospheres, etc., and
class distribution in the entire dataset. After thoroughly examining the
results of this research, it can be inferred that they supported the datasets
strengths by being a viable resource when tested in the real world on
unfamiliar data. This is evident since as the model trains on the dataset, it
is able to generalize on it, hence confirming this is a viable Machine Learning
setting that has practical impact.",http://arxiv.org/abs/2109.05083v1
"SDG Target Interactions: The Philippine Analysis of Indivisible and
  Cancelling Targets",2021-09-12T14:54:46Z,"Vena Pearl Bongolan, Arian Allenson M. Valdez, Roselle Leah K. Rivera","The United Nations developed the 17 Sustainable Development Goals (SDGs),
with 169 targets, to serve as a plan for solving the world's problems and
achieving a more sustainable future. This is modeled as a graph with the
targets as nodes, and with the interaction between targets as the edges of the
graph. An exhaustive binary comparison is done to analyze the intra- and
inter-goal target interactions, entailing over 14000 comparisons. The task is
to assign a 'color' to an edge: positive (indivisible), zero (consistent) or
negative (cancelling). This is done via a panel of experts who will evaluate
the target interactions, through a web application that was developed for
coloring the edges. This is an on-going study, and so far, of the 1256 edges
colored, only 36 are cancelling (negative), or 2.86%; more than 97% are
positive interactions. So far, the ""most negative"" interactions involve:
""Climate Change""; ""Life Below Water""; ""Peace, Justice and Strong Institutions"";
and ""Decent Work and Economic Growth"". Most useful for planning might be the
'graph of beautiful targets' feature, which shows target with non-negative
interactions, and how they connect to each other. These are the targets that
may be worked on simultaneously, and currently has more than 130 nodes. This
study can help researchers analyze which targets enable or constrain each
other, what mitigation can be done to avoid conflicts, and can be configured
for sub-national or regional study. Web app at:
http://sdg-interactions.herokuapp.com/",http://arxiv.org/abs/2109.05532v2
"Validation and Improvement of Data Assimilation for Flood Hydrodynamic
  Modelling Using SAR Imagery Data",2021-09-09T15:18:42Z,"Thanh Huy Nguyen, Anthéa Delmotte, Christophe Fatras, Peter Kettig, Andrea Piacentini, Sophie Ricci","Relevant comprehension of flood hazards has emerged as a crucial necessity,
especially as the severity and the occurrence of flood events intensify with
climate changes. Flood simulation and forecast capability have been greatly
improved thanks to advances in data assimilation. This approach combines
in-situ gauge measurements with hydrodynamic models, aiming to correct the
hydraulic states and reduce the uncertainties in the model parameters, e.g.,
friction coefficients, inflow discharge. These methods depend strongly on the
availability and quality of observations, thus requiring other data sources to
improve the flood simulation and forecast quality. Sentinel-1 images collected
during a flood event were used to classify an observed scene into dry and wet
areas. The study area concerns the Garonne Marmandaise catchment, and focuses
on recent flood event in January-February 2021. In this paper, seven
experiments are carried out, two in free run modes (FR1 and FR2) and five in
data assimilation modes (DA1 to DA5). A model-observation bias was diagnosed
and corrected over the beginning of the flood event. Quantitative assessments
are carried out involving 1D metrics at Vigicrue observing stations and 2D
metrics with respect to the Sentinel-1 derived flood extent maps. They
demonstrate improvements on flood extent representation thanks to the data
assimilation and bias correction.",http://arxiv.org/abs/2109.07470v2
"Estimating Wildfire Evacuation Decision and Departure Timing Using
  Large-Scale GPS Data",2021-09-16T06:40:23Z,"Xilei Zhao, Yiming Xu, Ruggiero Lovreglio, Erica Kuligowski, Daniel Nilsson, Thomas Cova, Alex Wu, Xiang Yan","With increased frequency and intensity due to climate change, wildfires have
become a growing global concern. This creates severe challenges for fire and
emergency services as well as communities in the wildland-urban interface
(WUI). To reduce wildfire risk and enhance the safety of WUI communities,
improving our understanding of wildfire evacuation is a pressing need. To this
end, this study proposes a new methodology to analyze human behavior during
wildfires by leveraging a large-scale GPS dataset. This methodology includes a
home-location inference algorithm and an evacuation-behavior inference
algorithm, to systematically identify different groups of wildfire evacuees
(i.e., self-evacuee, shadow evacuee, evacuee under warning, and ordered
evacuee). We applied the methodology to the 2019 Kincade Fire in Sonoma County,
CA. We found that among all groups of evacuees, self-evacuees and shadow
evacuees accounted for more than half of the evacuees during the Kincade Fire.
The results also show that inside of the evacuation warning/order zones, the
total evacuation compliance rate was around 46% among all the categorized
people. The findings of this study can be used by emergency managers and
planners to better target public outreach campaigns, training protocols, and
emergency communication strategies to prepare WUI households for future
wildfire events.",http://arxiv.org/abs/2109.07745v1
"Echopype: A Python library for interoperable and scalable processing of
  water column sonar data for biological information",2021-10-30T06:41:17Z,"Wu-Jung Lee, Emilio Mayorga, Landung Setiawan, Valentina Staneva","High-frequency sonar systems deployed on a wide array of ocean observing
platforms are creating a deluge of water column sonar data at an unprecedented
speed from all corners of the ocean. Efficient and integrative analysis of
these data, either across different sonar instruments or with other
oceanographic datasets, holds the key to understanding the response of marine
ecosystems to the rapidly changing climate. Here we present Echopype, an
open-source Python software library designed to address this need. By
standardizing water column sonar data from diverse instruments following a
community convention and utilizing the widely embraced netCDF data model to
encode sonar data as labeled, multi-dimensional arrays, Echopype facilitates
intuitive, user-friendly exploration and use of sonar data in an
instrument-agnostic manner. By leveraging existing open-source Python libraries
optimized for distributed computing, Echopype directly enables computational
interoperability and scalability in both local and cloud computing
environments. Echopype's modularized package structure further provides a
conceptually unified implementation framework for expanding its support for
additional instrument raw data formats and incorporating new data analysis
functionalities. We envision the continued development of Echopype as a
catalyst for making information derived from water column sonar data an
integrated component of regional and global ocean observation strategies.",http://arxiv.org/abs/2111.00187v3
"Efficient Hierarchical Bayesian Inference for Spatio-temporal Regression
  Models in Neuroimaging",2021-11-02T15:50:01Z,"Ali Hashemi, Yijing Gao, Chang Cai, Sanjay Ghosh, Klaus-Robert Müller, Srikantan S. Nagarajan, Stefan Haufe","Several problems in neuroimaging and beyond require inference on the
parameters of multi-task sparse hierarchical regression models. Examples
include M/EEG inverse problems, neural encoding models for task-based fMRI
analyses, and climate science. In these domains, both the model parameters to
be inferred and the measurement noise may exhibit a complex spatio-temporal
structure. Existing work either neglects the temporal structure or leads to
computationally demanding inference schemes. Overcoming these limitations, we
devise a novel flexible hierarchical Bayesian framework within which the
spatio-temporal dynamics of model parameters and noise are modeled to have
Kronecker product covariance structure. Inference in our framework is based on
majorization-minimization optimization and has guaranteed convergence
properties. Our highly efficient algorithms exploit the intrinsic Riemannian
geometry of temporal autocovariance matrices. For stationary dynamics described
by Toeplitz matrices, the theory of circulant embeddings is employed. We prove
convex bounding properties and derive update rules of the resulting algorithms.
On both synthetic and real neural data from M/EEG, we demonstrate that our
methods lead to improved performance.",http://arxiv.org/abs/2111.01692v2
"Reactive transport experiments of coupled carbonation and
  serpentinization in a natural serpentinite. Implication for hydrogen
  production and carbon geological storage",2021-10-27T11:23:19Z,"Florian Osselin, Michel Pichavant, Rémi Champallier, Marc Ulrich, Hugues Raimbourg","Serpentinization and carbonation of ultramafic formations is a ubiquitous
phenomenon, which deeply influences the biogeochemical cycles of water,
hydrogen, carbon... while supporting the particular biosphere around the
oceanic hydrothermal vents. Carbonation of peridotites and other mafic and
ultramafic rocks is also a hot topic in the current energy landscape as the
engineered sequestration of mineral CO2 in these formations could help reduce
the atmospheric emissions and cope with climate change. In this study, we
present two reactive percolation experiments performed on a natural
serpentinite dredged from the ultraslow South-West Indian Oceanic Ridge. The
serpentinite cores (length 3-4 cm and dia. 5.6 mm) were subjected for about 10
days to the continuous injection of a NaHCO3-saturated brine at respectively
160{\deg}C and 280{\deg}C. Petrographic and petrophysical results as well as
outlet fluid compositions were compared to numerical batch simulations
performed with the PHREEQC open software allowing to reconstruct the
mineralogical evolution of both cores. The most striking observation is the
fast and dramatic decrease of the permeability for both experiments principally
due to the precipitation of carbonates. On the contrary, serpentine was found
to be less impacting as it precipitates in low-flow zones, out of the main
percolation paths. In total, about 5.6% of the total injected CO2 was retained
in the core, at 280{\deg}C. In the same time, hydrogen was consistently
produced with a total recovered H2 corresponding to 0.8% of the maximum H2
possible. The global behavior of the cores is interpreted as the result from an
interplay between interacting spatio-temporal lengthscales controlled by the
Damkohler number.",http://arxiv.org/abs/2111.02958v1
"Physics-Guided Generative Adversarial Networks for Sea Subsurface
  Temperature Prediction",2021-11-04T23:46:51Z,"Yuxin Meng, Eric Rigall, Xueen Chen, Feng Gao, Junyu Dong, Sheng Chen","Sea subsurface temperature, an essential component of aquatic wildlife,
underwater dynamics and heat transfer with the sea surface, is affected by
global warming in climate change. Existing research is commonly based on either
physics-based numerical models or data based models. Physical modeling and
machine learning are traditionally considered as two unrelated fields for the
sea subsurface temperature prediction task, with very different scientific
paradigms (physics-driven and data-driven). However, we believe both methods
are complementary to each other. Physical modeling methods can offer the
potential for extrapolation beyond observational conditions, while data-driven
methods are flexible in adapting to data and are capable of detecting
unexpected patterns. The combination of both approaches is very attractive and
offers potential performance improvement. In this paper, we propose a novel
framework based on generative adversarial network (GAN) combined with numerical
model to predict sea subsurface temperature. First, a GAN-based model is used
to learn the simplified physics between the surface temperature and the target
subsurface temperature in numerical model. Then, observation data are used to
calibrate the GAN-based model parameters to obtain better prediction. We
evaluate the proposed framework by predicting daily sea subsurface temperature
in the South China sea. Extensive experiments demonstrate the effectiveness of
the proposed framework compared to existing state-of-the-art methods.",http://arxiv.org/abs/2111.03064v1
The climatic interdependence of extreme-rainfall events around the globe,2021-11-02T22:21:46Z,"Zhen Su, Henning Meyerhenke, Jürgen Kurths","The identification of regions of similar climatological behavior can be
utilized for the discovery of spatial relationships over long-range scales,
including teleconnections. In this regard, the global picture of the
interdependence patterns of extreme rainfall events (EREs) still needs to be
further explored. To this end, we propose a top-down complex-network-based
clustering workflow, with the combination of consensus clustering and mutual
correspondences. Consensus clustering provides a reliable community structure
under each dataset, while mutual correspondences build a matching relationship
between different community structures obtained from different datasets. This
approach ensures the robustness of the identified structures when multiple
datasets are available. By applying it simultaneously to two satellite-derived
precipitation datasets, we identify consistent synchronized structures of EREs
around the globe, during boreal summer. Two of them show independent
spatiotemporal characteristics, uncovering the primary compositions of
different monsoon systems. They explicitly manifest the primary intraseasonal
variability in the context of the global monsoon, in particular the `monsoon
jump' over both East Asia and West Africa and the mid-summer drought over
Central America and southern Mexico. Through a case study related to the Asian
summer monsoon (ASM), we verify that the intraseasonal changes of upper-level
atmospheric conditions are preserved by significant connections within the
global synchronization structure. Our work advances network-based clustering
methodology for (i) decoding the spatiotemporal configuration of
interdependence patterns of natural variability and for (ii) the
intercomparison of these patterns, especially regarding their spatial
distributions over different datasets.",http://arxiv.org/abs/2111.03471v1
"Detecting contagious spreading of urban innovations on the global city
  network",2021-11-10T14:35:22Z,"Niklas H. Kitzmann, Pawel Romanczuk, Jonathan F. Donges","Only a fast and global transformation towards decarbonization and
sustainability can keep the Earth in a civilization-friendly state. As hotspots
for (green) innovation and experimentation, cities could play an important role
in this transition. They are also known to profit from each other's ideas, with
policy and technology innovations spreading to other cities. In this way,
cities can be conceptualized as nodes in a globe-spanning learning network. The
dynamics of this process are important for society's response to climate change
and other challenges, but remain poorly understood on a macroscopic level. In
this contribution, we develop an approach to identify whether network-based
complex contagion effects are a feature of sustainability policy adoption by
cities, based on dose-response contagion and surrogate data models. We apply
this methodology to an example data set, comprising empirical data on the
spreading of a public transport innovation (Bus Rapid Transit Systems) and a
global inter-city connection network based on scheduled flight routes. We find
evidence pointing towards a contagious spreading process which cannot be
explained by either the network structure or the increase in global adoption
rate alone. This suggests that the actions of a city's abstract ""global
neighborhood"" within the network of cities may be an important factor in which
policies and innovations are implemented, with potential connections to the
emergence of social tipping processes. The methodology is generic, and can be
used to compare the predictive power for innovation spreading of different
kinds of inter-city network connections, e.g. via transport links, trade, or
co-membership in political networks.",http://arxiv.org/abs/2111.05709v1
"One hundred percent renewable energy generation in 2030 with the lowest
  cost commercially available power plants",2021-11-16T23:15:18Z,"Manfred G. Kratzenberg, Hans Helmut Zürn, Ricardo Rüther","We hypothesize that the present expansion of energy generation by variable
renewable energy (VRE) power plants, such as wind and photovoltaic power
plants, leads to a 100% renewable energy supply in 2030 because of its inherent
exponential growth function. This behavior is related to the exponential cost
reduction of its generated energy and the nearly unconstrained available
potential of its natural resources. The cost reduction results from the
continuous improvements in development, research, manufacturing, and
installation, also showing a growth of its installation power per power plant
or aero generator. We prove that if the historic exponential growth is followed
in the future, it is possible to decarbonize the world's electric energy
systems' power supply in 2026. Furthermore, the global demand on primary energy
can be supplied in 2030, which leads to the total suppression of CO2 emissions
related to the energy need of humanity. Because of the related cost reduction,
energy costs are not anymore relevant. Our extrapolation is based on the
continuation of the historic growth functions of the globally installed PV and
the wind power plants, and we also discuss the conditions necessary to enable a
transition to such a 100% renewable energy production. Considering a
non-constrained growth of VRE power plants' installation power, decarbonization
related to energy generation and use can be accomplished in a much shorter time
frame as previously scheduled. As a result, climate change mitigation, energy
cost reduction, and high employment are attained much earlier than previously
planned.",http://arxiv.org/abs/2111.08829v1
TorchGeo: Deep Learning With Geospatial Data,2021-11-17T02:47:33Z,"Adam J. Stewart, Caleb Robinson, Isaac A. Corley, Anthony Ortiz, Juan M. Lavista Ferres, Arindam Banerjee","Remotely sensed geospatial data are critical for applications including
precision agriculture, urban planning, disaster monitoring and response, and
climate change research, among others. Deep learning methods are particularly
promising for modeling many remote sensing tasks given the success of deep
neural networks in similar computer vision tasks and the sheer volume of
remotely sensed imagery available. However, the variance in data collection
methods and handling of geospatial metadata make the application of deep
learning methodology to remotely sensed data nontrivial. For example, satellite
imagery often includes additional spectral bands beyond red, green, and blue
and must be joined to other geospatial data sources that can have differing
coordinate systems, bounds, and resolutions. To help realize the potential of
deep learning for remote sensing applications, we introduce TorchGeo, a Python
library for integrating geospatial data into the PyTorch deep learning
ecosystem. TorchGeo provides data loaders for a variety of benchmark datasets,
composable datasets for generic geospatial data sources, samplers for
geospatial data, and transforms that work with multispectral imagery. TorchGeo
is also the first library to provide pre-trained models for multispectral
satellite imagery (e.g., models that use all bands from the Sentinel-2
satellites), allowing for advances in transfer learning on downstream remote
sensing tasks with limited labeled data. We use TorchGeo to create reproducible
benchmark results on existing datasets and benchmark our proposed method for
preprocessing geospatial imagery on the fly. TorchGeo is open source and
available on GitHub: https://github.com/microsoft/torchgeo.",http://arxiv.org/abs/2111.08872v4
"A GNN-RNN Approach for Harnessing Geospatial and Temporal Information:
  Application to Crop Yield Prediction",2021-11-17T04:43:25Z,"Joshua Fan, Junwen Bai, Zhiyun Li, Ariel Ortiz-Bobea, Carla P. Gomes","Climate change is posing new challenges to crop-related concerns including
food insecurity, supply stability and economic planning. As one of the central
challenges, crop yield prediction has become a pressing task in the machine
learning field. Despite its importance, the prediction task is exceptionally
complicated since crop yields depend on various factors such as weather, land
surface, soil quality as well as their interactions. In recent years, machine
learning models have been successfully applied in this domain. However, these
models either restrict their tasks to a relatively small region, or only study
over a single or few years, which makes them hard to generalize spatially and
temporally. In this paper, we introduce a novel graph-based recurrent neural
network for crop yield prediction, to incorporate both geographical and
temporal knowledge in the model, and further boost predictive power. Our method
is trained, validated, and tested on over 2000 counties from 41 states in the
US mainland, covering years from 1981 to 2019. As far as we know, this is the
first machine learning method that embeds geographical knowledge in crop yield
prediction and predicts the crop yields at county level nationwide. We also
laid a solid foundation for the comparison with other machine learning
baselines by applying well-known linear models, tree-based models, deep
learning methods and comparing their performance. Experiments show that our
proposed method consistently outperforms the existing state-of-the-art methods
on various metrics, validating the effectiveness of geospatial and temporal
information.",http://arxiv.org/abs/2111.08900v2
"Enhanced monitoring of atmospheric methane from space over the Permian
  basin with hierarchical Bayesian inference",2021-11-24T13:30:49Z,"Clayton Roberts, Oliver Shorttle, Kaisey Mandel, Matthew Jones, Rutger Ijzermans, Bill Hirst, Philip Jonathan","Methane is a strong greenhouse gas, with a higher radiative forcing per unit
mass and shorter atmospheric lifetime than carbon dioxide. The remote sensing
of methane in regions of industrial activity is a key step toward the accurate
monitoring of emissions that drive climate change. Whilst the TROPOspheric
Monitoring Instrument (TROPOMI) on board the Sentinal-5P satellite is capable
of providing daily global measurement of methane columns, data are often
compromised by cloud cover. Here, we develop a statistical model which uses
nitrogen dioxide concentration data from TROPOMI to efficiently predict values
of methane columns, expanding the average daily spatial coverage of
observations of the Permian basin from 16% to 88% in the year 2019. The
addition of predicted methane abundances at locations where direct observations
are not available will support inversion methods for estimating methane
emission rates at shorter timescales than is currently possible.",http://arxiv.org/abs/2111.12486v5
"A CNN based method for Sub-pixel Urban Land Cover Classification using
  Landsat-5 TM and Resourcesat-1 LISS-IV Imagery",2021-12-16T12:48:37Z,"Krishna Kumar Perikamana, Krishnachandran Balakrishnan, Pratyush Tripathy","Time series data of urban land cover is of great utility in analyzing urban
growth patterns, changes in distribution of impervious surface and vegetation
and resulting impacts on urban micro climate. While Landsat data is ideal for
such analysis due to the long time series of free imagery, traditional
per-pixel hard classification fails to yield full potential of the Landsat
data. This paper proposes a sub-pixel classification method that leverages the
temporal overlap of Landsat-5 TM and Resourcesat-1 LISS-IV sensors. We train a
convolutional neural network to predict fractional land cover maps from 30m
Landsat-5 TM data. The reference land cover fractions are estimated from a
hard-classified 5.8m LISS-IV image for Bengaluru from 2011. Further, we
demonstrate the generalizability and superior performance of the proposed model
using data for Mumbai from 2009 and comparing it to the results obtained using
a Random Forest classifier. For both Bengaluru (2011) and Mumbai (2009) data,
Mean Absolute Percentage Error of our CNN model is in the range of 7.2 to 11.3
for both built-up and vegetation fraction prediction at the 30m cell level.
Unlike most recent studies where validation is conducted using data for a
limited spatial extent, our model has been trained and validated using data for
the complete spatial extent of two mega cities for two different time periods.
Hence it can reliably generate 30m built-up and vegetation fraction maps from
Landsat-5 TM time series data to analyze long term urban growth patterns.",http://arxiv.org/abs/2112.08841v1
"Deep Learning Based 3D Point Cloud Regression for Estimating Forest
  Biomass",2021-12-21T16:26:13Z,"Stefan Oehmcke, Lei Li, Katerina Trepekli, Jaime Revenga, Thomas Nord-Larsen, Fabian Gieseke, Christian Igel","Quantification of forest biomass stocks and their dynamics is important for
implementing effective climate change mitigation measures. The knowledge is
needed, e.g., for local forest management, studying the processes driving af-,
re-, and deforestation, and can improve the accuracy of carbon-accounting.
Remote sensing using airborne LiDAR can be used to perform these measurements
of vegetation structure at large scale. We present deep learning systems for
predicting wood volume, above-ground biomass (AGB), and subsequently
above-ground carbon stocks directly from airborne LiDAR point clouds. We devise
different neural network architectures for point cloud regression and evaluate
them on remote sensing data of areas for which AGB estimates have been obtained
from field measurements in the Danish national forest inventory. Our adaptation
of Minkowski convolutional neural networks for regression gave the best
results. The deep neural networks produced significantly more accurate wood
volume, AGB, and carbon stock estimates compared to state-of-the-art approaches
operating on basic statistics of the point clouds. In contrast to other
methods, the proposed deep learning approach does not require a digital terrain
model. We expect this finding to have a strong impact on LiDAR-based analyses
of biomass dynamics.",http://arxiv.org/abs/2112.11335v3
"Effectiveness of Multi-Physics Numerical Model in Simulating Accelerated
  Corrosion with Spatial and Temporal Non Uniformity",2021-12-22T06:17:30Z,"Shanmukha Shetty, Sauvik Banerjee, Siddharth Tallur, Yogesh M. Desai","This study is motivated by the need to develop an efficient numerical model
to simulate non-uniform interfacial degradation of reinforcing steel in
concrete in an accelerated corrosion setup. In this study, a multi physics
finite element (FE) model is presented that takes into consideration the
spatial and temporal non uniformity of corrosion induced degradation in rebar,
and eliminates the assumption of uniform mass loss and its linear variation
with time as per available literature that uses classical approach of Faraday's
law. The model is validated experimentally with accelerated corrosion setup
designed to induce partial corrosion. Further, the possibility of extending
this model to monitor natural corrosion is discussed with required
modifications. Unlike previous studies, pore saturation (PS) is continuously
monitored and its existing experimental correlations with electrolyte
conductivity and oxygen diffusivity in the vicinity of partial corrosion are
adopted so that the model can be extended to simulate natural corrosion. These
evaluations can be made completely nondestructive and in real time to capture
the influence of local environment. The proposed methodology also captures the
effect of differential aeration pertaining to local exposure. Therefore, the
challenges in incorporating influence of local environment by the use of
alternative parameters such as relative humidity from real climate change
predictions are eliminated. It is shown that the multi-physics model is
effective and convenient to simulate the non-uniform time dependent mass loss
with acceptable accuracy and that its capability can be extended to monitor
natural non uniform corrosion on a space time frame.",http://arxiv.org/abs/2112.11683v1
Raw Produce Quality Detection with Shifted Window Self-Attention,2021-12-24T10:16:28Z,"Oh Joon Kwon, Byungsoo Kim, Youngduck Choi","Global food insecurity is expected to worsen in the coming decades with the
accelerated rate of climate change and the rapidly increasing population. In
this vein, it is important to remove inefficiencies at every level of food
production. The recent advances in deep learning can help reduce such
inefficiencies, yet their application has not yet become mainstream throughout
the industry, inducing economic costs at a massive scale. To this point, modern
techniques such as CNNs (Convolutional Neural Networks) have been applied to
RPQD (Raw Produce Quality Detection) tasks. On the other hand, Transformer's
successful debut in the vision among other modalities led us to expect a better
performance with these Transformer-based models in RPQD. In this work, we
exclusively investigate the recent state-of-the-art Swin (Shifted Windows)
Transformer which computes self-attention in both intra- and inter-window
fashion. We compare Swin Transformer against CNN models on four RPQD image
datasets, each containing different kinds of raw produce: fruits and
vegetables, fish, pork, and beef. We observe that Swin Transformer not only
achieves better or competitive performance but also is data- and
compute-efficient, making it ideal for actual deployment in real-world setting.
To the best of our knowledge, this is the first large-scale empirical study on
RPQD task, which we hope will gain more attention in future works.",http://arxiv.org/abs/2112.13845v1
Observation of large and all-season ozone losses over the tropics,2021-12-30T09:25:31Z,Qing-Bin Lu,"This paper reveals a large and all-season ozone hole in the lower
stratosphere over the tropics (30degN-30degS) since the 1980s, where an O3 hole
is defined as an area of O3 loss larger than 25% compared with the undisturbed
atmosphere. The depth of this tropical O3 hole is comparable to that of the
well-known springtime Antarctic O3 hole, whereas its area is about seven times
that of the latter. Similar to the Antarctic O3 hole, approximately 80% of the
normal O3 value is depleted at the center of the tropical O3 hole. The results
strongly indicate that both Antarctic and tropical O3 holes must arise from an
identical physical mechanism, for which the cosmic-ray-driven electron reaction
(CRE) model shows good agreements with observations. The whole-year large
tropical O3 hole could cause a serious global concern as it can lead to
increases in ground-level ultraviolet radiation and affect 50% of Earth's
surface area, home to approximately 50% of the world's population. Moreover,
the presence of the tropical and polar O3 holes is equivalent to the formation
of three 'temperature holes' observed in the stratosphere. These findings will
have significances in understanding planetary physics, ozone depletion, climate
change, and human health.",http://arxiv.org/abs/2112.14977v3
"Distribution and Determinants of Correlation between PM2.5 and O3 in
  China Mainland: Dynamitic simil-Hu Lines",2021-11-13T06:02:36Z,"Chenru Chen, Miaoqing Xu, Shuyi Liu, Dehai Zhu, Jianyu Yang, Bingbo Gao, Ziyue Chen","In recent years, China has made great efforts to control air pollution.
During the governance process, it is found that fine particulate matter (PM2.5)
and ozone (O3) change in the same trend among some areas and the opposite in
others, which brings some difficulties to take measures in a planned way.
Therefore, this study adopted multi-year and large-scale air quality data to
explore the distribution of correlation between PM2.5 and O3, and proposed a
concept called dynamic similar hu lines to replace the single fixed division in
the previous research. Furthermore, this study discussed the causes of
distribution patterns quantitatively with geographical detector and random
forest. The causes included natural factors and anthropogenic factors. And
these factors could be divided into three parts according to the
characteristics of spatial distribution: broadly changing with longitude,
changing with latitude, and having local characteristics. Overall, regions with
relatively more densely population, higher GDP, lower altitude, higher
humidity, higher atmospheric pressure, higher surface temperature, less
sunshine hours and more accumulated precipitation often corresponds to positive
correlation coefficient between PM2.5 and O3, no matter in which season. The
parts with opposite conditions that mentioned above are essentially negative
correlation coefficient. And what's more, humidity, global surface temperature,
air temperature and accumulated precipitation are four decisive factors to form
the distribution of correlation between PM2.5 and O3. In general, collaborative
governance of atmospheric pollutants should consider particular time and space
background and also be based on the local actual socio-economic situations,
geography and geomorphology, climate and meteorology and other comprehensive
factors.",http://arxiv.org/abs/2111.07052v2
"Seed banks can help to maintain the diversity of interacting
  phytoplankton species",2021-03-22T07:56:18Z,"Coralie Picoche, Frédéric Barraquand","Seed formation is part of the reproductive cycle, leading to the accumulation
of resistance stages that can withstand harsh environmental conditions for long
periods of time. At the community level, multiple species with such
long-lasting life stages can be more likely to coexist. While the implications
of this process for biodiversity have been studied in terrestrial plants, seed
banks are usually neglected in phytoplankton multispecies dynamic models, in
spite of widespread empirical evidence for such seed banks. In this study, we
build a metacommunity model of interacting phytoplankton species, including a
resting stage supplying the seed bank. The model is parameterized with
empirically-driven growth rate functions and field-based interaction estimates,
which include both facilitative and competitive interactions. Exchanges between
compartments (coastal pelagic cells, coastal resting cells on the seabed, and
open ocean pelagic cells) are controlled by hydrodynamical parameters to which
the sensitivity of the model is assessed. We consider two models, i.e., with
and without a saturating effect of the interactions on the growth rates. Our
results are consistent between models, and show that a seed bank allows to
maintain all species in the community over 30 years. Indeed, a fraction of the
species are vulnerable to extinction at specific times within the year, but
this process is buffered by their survival in their resting stage. We thus
highlight the potential role of the seed bank in the recurrent re-invasion of
the coastal community, and of coastal environments in re-seeding oceanic
regions. Moreover, the seed bank enables populations to tolerate stronger
interactions within the community as well as more severe changes to the
environment, such as those predicted in a climate change context. Our study
therefore shows how resting stages may help phytoplanktonic diversity
maintenance.",http://arxiv.org/abs/2103.11637v2
"B-ETS: A Trusted Blockchain-based Emissions Trading System for
  Vehicle-to-Vehicle Networks",2021-02-18T21:52:56Z,"Lam Duc Nguyen, Amari N. Lewis, Israel Leyva-Mayorga, Amelia Regan, Petar Popovski","Urban areas are negatively impacted by Carbon Dioxide (CO2 ) and Nitrogen
Oxide (NOx) emissions. In order to achieve a cost-effective reduction of
greenhouse gas emissions and to combat climate change, the European Union (EU)
introduced an Emissions Trading System (ETS) where organizations can buy or
receive emission allowances as needed. The current ETS is a centralized one,
consisting of a set of complex rules. It is currently administered at the
organizational level and is used for fixed-point sources of pollution such as
factories, power plants, and refineries. However, the current ETS cannot
efficiently cope with vehicle mobility, even though vehicles are one of the
primary sources of CO2 and NOx emissions. In this study, we propose a new
distributed Blockchain-based emissions allowance trading system called B-ETS.
This system enables transparent and trustworthy data exchange as well as
trading of allowances among vehicles, relying on vehicle-to-vehicle
communication. In addition, we introduce an economic incentive-based mechanism
that appeals to individual drivers and leads them to modify their driving
behavior in order to reduce emissions. The efficiency of the proposed system is
studied through extensive simulations, showing how increased vehicle
connectivity can lead to a reduction of the emissions generated from those
vehicles. We demonstrate that our method can be used for full life-cycle
monitoring and fuel economy reporting. This leads us to conjecture that the
proposed system could lead to important behavioral changes among the drivers",http://arxiv.org/abs/2102.13477v2
"Analyzing the ""Sleeping Giants"" Activism Model in Brazil",2021-05-16T21:47:30Z,"Bárbara Gomes Ribeiro, Manoel Horta Ribeiro, Virgílio Almeida, Wagner Meira Jr","In 2020, amidst the COVID pandemic and a polarized political climate, the
Sleeping Giants online activist movement gained traction in Brazil. Its
rationale was simple: to curb the spread of misinformation by harming the
advertising revenue of sources that produce this type of content. Like its
international counterparts, Sleeping Giants Brasil (SGB) campaigned against
media outlets using Twitter to ask companies to remove ads from the targeted
outlets. This work presents a thorough quantitative characterization of this
activism model, analyzing the three campaigns carried out by SGB between May
and September 2020. To do so, we use digital traces from both Twitter and
Google Trends, toxicity and sentiment classifiers trained for the Portuguese
language, and an annotated corpus of SGB's tweets. Our key findings were
threefold. First, we found that SGB's requests to companies were largely
successful (with 83.85\% of all 192 targeted companies responding positively)
and that user pressure was correlated to the speed of companies' responses.
Second, there were no significant changes in the online attention and the user
engagement going towards the targeted media outlets in the six months that
followed SGB's campaign (as measured by Google Trends and Twitter engagement).
Third, we observed that user interactions with companies changed only
transiently, even if the companies did not respond to SGB's request. Overall,
our results paint a nuanced portrait of internet activism. On the one hand,
they suggest that SGB was successful in getting companies to boycott specific
media outlets, which may have harmed their advertisement revenue stream. On the
other hand, they also suggest that the activist movement did not impact the
online attention these media outlets received nor the online image of companies
that did not respond positively to their requests.",http://arxiv.org/abs/2105.07523v3
"Vegetation Impact on Atmospheric Moisture Transport under Increasing
  Land-Ocean Temperature Contrasts",2021-12-23T23:51:17Z,"Anastassia M. Makarieva, Andrei V. Nefiodov, Antonio Donato Nobre, Douglas Sheil, Paulo Nobre, Jan Pokorný, Petra Hesslerová, Bai-Lian Li","Destabilization of the water cycle threatens human lives and livelihoods.
Meanwhile our understanding of whether and how changes in vegetation cover
could trigger abrupt transitions in moisture regimes remains incomplete. This
challenge calls for better evidence as well as for the theoretical concepts to
describe it. Here we briefly summarise the theoretical questions surrounding
the role of vegetation cover in the dynamics of a moist atmosphere. We discuss
the previously unrecognized sensitivity of local wind power to condensation
rate as revealed by our analysis of the continuity equation for a gas mixture.
Using the framework of condensation-induced atmospheric dynamics, we then show
that with the temperature contrast between land and ocean increasing up to a
critical threshold, ocean-to-land moisture transport reaches a tipping point
where it can stop or even reverse. Land-ocean temperature contrasts are
affected by both global and regional processes, in particular, by the surface
fluxes of sensible and latent heat that are strongly influenced by vegetation.
Our results clarify how a disturbance of natural vegetation cover, e.g., by
deforestation, can disrupt large-scale atmospheric circulation and moisture
transport. In view of the increasing pressure on natural ecosystems, successful
strategies of mitigating climate change require taking into account the impact
of vegetation on moist atmospheric dynamics. Our analysis provides a
theoretical framework to assess this impact. The available data for Eurasia
indicate that the observed climatological land-ocean temperature contrasts are
close to the threshold. This can explain the increasing fluctuations in the
continental water cycle including droughts and floods and signifies a yet
greater potential importance for large-scale forest conservation.",http://arxiv.org/abs/2112.12880v1
Simulation study on the fleet performance of shared autonomous bicycles,2021-06-17T17:47:08Z,"Naroa Coretti Sánchez, Iñigo Martinez, Luis Alonso Pastor, Kent Larson","Rethinking cities is now more imperative than ever, as society faces global
challenges such as population growth and climate change. The design of cities
can not be abstracted from the design of its mobility system, and, therefore,
efficient solutions must be found to transport people and goods throughout the
city in an ecological way. An autonomous bicycle-sharing system would combine
the most relevant benefits of vehicle sharing, electrification, autonomy, and
micro-mobility, increasing the efficiency and convenience of bicycle-sharing
systems and incentivizing more people to bike and enjoy their cities in an
environmentally friendly way. Due to the uniqueness and radical novelty of
introducing autonomous driving technology into bicycle-sharing systems and the
inherent complexity of these systems, there is a need to quantify the potential
impact of autonomy on fleet performance and user experience. This paper
presents an ad-hoc agent-based simulator that provides an in-depth
understanding of the fleet behavior of autonomous bicycle-sharing systems in
realistic scenarios, including a rebalancing system based on demand prediction.
In addition, this work describes the impact of different parameters on system
efficiency and service quality and quantifies the extent to which an autonomous
system would outperform current bicycle-sharing schemes. The obtained results
show that with a fleet size three and a half times smaller than a station-based
system and eight times smaller than a dockless system, an autonomous system can
provide overall improved performance and user experience even with no
rebalancing. These findings indicate that the remarkable efficiency of an
autonomous bicycle-sharing system could compensate for the additional cost of
autonomous bicycles.",http://arxiv.org/abs/2106.09694v2
Surrogate-based variational data assimilation for tidal modelling,2021-06-08T07:39:38Z,"Rem-Sophia Mouradi, Cédric Goeury, Olivier Thual, Fabrice Zaoui, Pablo Tassi","Data assimilation (DA) is widely used to combine physical knowledge and
observations. It is nowadays commonly used in geosciences to perform parametric
calibration. In a context of climate change, old calibrations can not
necessarily be used for new scenarios. This raises the question of DA
computational cost, as costly physics-based numerical models need to be
reanalyzed. Reduction and metamodelling represent therefore interesting
perspectives, for example proposed in recent contributions as hybridization
between ensemble and variational methods, to combine their advantages
(efficiency, non-linear framework). They are however often based on Monte Carlo
(MC) type sampling, which often requires considerable increase of the ensemble
size for better efficiency, therefore representing a computational burden in
ensemble-based methods as well. To address these issues, two methods to replace
the complex model by a surrogate are proposed and confronted : (i) PODEn3DVAR
directly inspired from PODEn4DVAR, relies on an ensemble-based joint
parameter-state Proper Orthogonal Decomposition (POD), which provides a linear
metamodel ; (ii) POD-PCE-3DVAR, where the model states are POD reduced then
learned using Polynomial Chaos Expansion (PCE), resulting in a non-linear
metamodel. Both metamodels allow to write an approximate cost function whose
minimum can be analytically computed, or deduced by a gradient descent at
negligible cost. Furthermore, adapted metamodelling error covariance matrix is
given for POD-PCE-3DVAR, allowing to substantially improve the metamodel-based
DA analysis. Proposed methods are confronted on a twin experiment, and compared
to classical 3DVAR on a measurement-based problem. Results are promising, in
particular superior with POD-PCE-3DVAR, showing good convergence to classical
3DVAR and robustness to noise.",http://arxiv.org/abs/2106.11926v1
Social physics,2021-10-05T08:05:52Z,"Marko Jusup, Petter Holme, Kiyoshi Kanazawa, Misako Takayasu, Ivan Romic, Zhen Wang, Suncana Gecek, Tomislav Lipic, Boris Podobnik, Lin Wang, Wei Luo, Tin Klanjscek, Jingfang Fan, Stefano Boccaletti, Matjaz Perc","Recent decades have seen a rise in the use of physics methods to study
different societal phenomena. This development has been due to physicists
venturing outside of their traditional domains of interest, but also due to
scientists from other disciplines taking from physics the methods that have
proven so successful throughout the 19th and the 20th century. Here we dub this
field 'social physics' and pay our respect to intellectual mavericks who
nurtured it to maturity. We do so by reviewing the current state of the art.
Starting with a set of topics that are at the heart of modern human societies,
we review research dedicated to urban development and traffic, the functioning
of financial markets, cooperation as the basis for our evolutionary success,
the structure of social networks, and the integration of intelligent machines
into these networks. We then shift our attention to a set of topics that
explore potential threats to society. These include criminal behaviour,
large-scale migrations, epidemics, environmental challenges, and climate
change. We end the coverage of each topic with promising directions for future
research. Based on this, we conclude that the future for social physics is
bright. Physicists studying societal phenomena are no longer a curiosity, but
rather a force to be reckoned with. Notwithstanding, it remains of the utmost
importance that we continue to foster constructive dialogue and mutual respect
at the interfaces of different scientific disciplines.",http://arxiv.org/abs/2110.01866v2
"ESG and Sovereign Risk: What is Priced in by the Bond Market and Credit
  Rating Agencies?",2021-10-13T10:21:51Z,"Raphaël Semet, Thierry Roncalli, Lauren Stagnol","In this paper, we examine the materiality of ESG on country creditworthiness
from a credit risk and fundamental analysis viewpoint. We first determine the
ESG indicators that are most relevant when it comes to explaining the sovereign
bond yield, after controlling the effects of traditional fundamental variables
such as economic strength and credit rating. We also emphasize the major themes
that are directly useful for investors when assessing the country risk premium.
At the global level, we notice that these themes mainly belong to the E and G
pillars. Those results confirm that extra-financial criteria are integrated
into bond pricing. However, we also identify a clear difference between
high-and middle-income countries. Indeed, whereas the S pillar is lagging for
the highest income countries, it is nearly as important as the G pillar for the
middle-income ones. Second, we determine which ESG metrics are indirectly
valuable for assessing a country's solvency. More precisely, we attempt to
infer credit rating solely from extra-financial criteria, that is the ESG
indicators that are priced in by credit rating agencies. We find that there is
no overlap between the set of indicators that predict credit ratings and those
that directly explain sovereign bond yields. The results also highlight the
importance of the G and S pillars when predicting credit ratings. The E pillar
is lagging, suggesting that credit rating agencies are undermining the impact
of climate change and environmental topics on country creditworthiness. This is
consistent with the traditional view that social and governance issues are the
main drivers of the sovereign risk, because they are more specific and less
global than environmental issues. Finally, taking these different results
together, this research shows that opposing extra-financial and fundamental
analysis does not make a lot of sense.",http://arxiv.org/abs/2110.06617v1
"Toward a multidimensional analysis of transmission spectroscopy. Part I:
  Computation of transmission spectra using a 1D, 2D, or 3D atmosphere
  structure",2021-10-22T14:16:14Z,"Aurélien Falco, Tiziano Zingales, William Pluriel, Jérémy Leconte","Considering the relatively high precision that will be reached by future
observatories, it has recently become clear that one dimensional (1D)
atmospheric models, in which the atmospheric temperature and composition of a
planet are considered to vary only in the vertical, will be unable to represent
exoplanetary transmission spectra with a sufficient accuracy. This is
particularly true for warm to (ultra-) hot exoplanets because the atmosphere is
unable to redistribute all the energy deposited on the dayside, creating a
strong thermal and often compositional dichotomy on the planet. This situation
is exacerbated by transmission spectroscopy, which probes the terminator
region. This is the most heterogeneous region of the atmosphere. However, if
being able to compute transmission spectra from 3D atmospheric structures (from
a global climate model, e.g.) is necessary to predict realistic observables, it
is too computationally expensive to be used in a data inversion framework. For
this reason, there is a need for a medium-complexity 2D approach that captures
the most salient features of the 3D model in a sufficiently fast
implementation. With this in mind, we present a new open-source documented
version of Pytmosph3R that handles the computation of transmission spectra for
atmospheres with up to three spatial dimensions and can account for time
variability. Taking the example of an ultra hot Jupiter, we illustrate how the
changing orientation of the planet during the transit can allow us to probe the
horizontal variations in the atmosphere. We further implement our algorithm in
TauREx to allow the community to perform 2D retrievals. We describe our
extensive cross-validation benchmarks and discuss the accuracy and numerical
performance of each model.",http://arxiv.org/abs/2110.11799v2
"Ticks on the run: A mathematical model of Crimean-Congo Haemorrhagic
  Fever (CCHF)-key factors for transmission",2021-01-27T14:59:41Z,"Suman Bhowmick, Khushal Khan Kasi, Jörn Gethmann, Susanne Fischer, Franz J. Conraths, Igor M. Sokolov, Hartmut H. K. Lentz","Crimean-Congo haemorrhagic fever (CCHF) is a tick-borne zoonotic disease
caused by the Crimean-Congo hemorrhagic fever virus (CCHFV). Ticks belonging to
the genus \textit{Hyalomma} are the main vectors and reservoir for the virus.
It is maintained in nature in an endemic vertebrate-tick-vertebrate cycle.
CCHFV is prevalent in wide geographical areas including Asia, Africa,
South-Eastern Europe and the Middle East. Over the last decade, several
outbreaks of CCHFV have been observed in Europe, mainly in Mediterranean
countries. Due to the high case/fatality ratio of CCHFV in human sometimes, it
is of great importance for public health. Climate change and the invasion of
CCHFV vectors in Central Europe suggest that the establishment of the
transmission in Central Europe may be possible in future. We developed a
compartment-based nonlinear Ordinary Differential Equation (ODE) system to
model the disease transmission cycle including blood sucking ticks, livestock
and human. Sensitivity analysis of the basic reproduction number $R_0$ shows
that decreasing in the tick survival time is an efficient method to eradicate
the disease. The model supports us in understanding the influence of different
model parameters on the spread of CCHFV. Tick to tick transmission through
co-feeding and the CCHFV circulation through trasstadial and transovarial
stages are important factors to sustain the disease cycle. The proposed model
dynamics are calibrated through an empirical multi-country analysis and
multidimensional scaling reveals the disease-parameter sets of different
countries burdened with CCHF are different. This necessary information may help
us to select most efficient control strategies.",http://arxiv.org/abs/2101.11471v1
De-carbonization of global energy use during the COVID-19 pandemic,2021-02-05T15:37:57Z,"Zhu Liu, Biqing Zhu, Philippe Ciais, Steven J. Davis, Chenxi Lu, Haiwang Zhong, Piyu Ke, Yanan Cui, Zhu Deng, Duo Cui, Taochun Sun, Xinyu Dou, Jianguang Tan, Rui Guo, Bo Zheng, Katsumasa Tanaka, Wenli Zhao, Pierre Gentine","The COVID-19 pandemic has disrupted human activities, leading to
unprecedented decreases in both global energy demand and GHG emissions. Yet a
little known that there is also a low carbon shift of the global energy system
in 2020. Here, using the near-real-time data on energy-related GHG emissions
from 30 countries (about 70% of global power generation), we show that the
pandemic caused an unprecedented de-carbonization of global power system,
representing by a dramatic decrease in the carbon intensity of power sector
that reached a historical low of 414.9 tCO2eq/GWh in 2020. Moreover, the share
of energy derived from renewable and low-carbon sources (nuclear, hydro-energy,
wind, solar, geothermal, and biomass) exceeded that from coal and oil for the
first time in history in May of 2020. The decrease in global net energy demand
(-1.3% in the first half of 2020 relative to the average of the period in
2016-2019) masks a large down-regulation of fossil-fuel-burning power plants
supply (-6.1%) coincident with a surge of low-carbon sources (+6.2%).
Concomitant changes in the diurnal cycle of electricity demand also favored
low-carbon generators, including a flattening of the morning ramp, a lower
midday peak, and delays in both the morning and midday load peaks in most
countries. However, emission intensities in the power sector have since
rebounded in many countries, and a key question for climate mitigation is thus
to what extent countries can achieve and maintain lower, pandemic-level carbon
intensities of electricity as part of a green recovery.",http://arxiv.org/abs/2102.03240v1
"The effects of temperature acclimation on swimming performance in the
  pelagic Mahi-mahi (Coryphaena hippurus)",2021-02-15T18:39:08Z,"Rachael M. Heuer, John D. Stieglitz, Christina Pasparakis, Ian C. Enochs, Daniel D. Benetti, Martin Grosell","Mahi-mahi (Coryphaena hippurus) are a highly migratory pelagic fish, but
little is known about what environmental factors drive their broad
distribution. This study examined how temperature influences aerobic scope and
swimming performance in mahi. Mahi were acclimated to four temperatures
spanning their natural range (20, 24, 28, and 32{\deg}C; 5-27 days) and
critical swimming speed (Ucrit), metabolic rates, aerobic scope, and optimal
swim speed were measured. Aerobic scope and Ucrit were highest in
28{\deg}C-acclimated fish. 20{\deg}C-acclimated mahi experienced significantly
decreased aerobic scope and Ucrit relative to 28{\deg}C-acclimated fish (57 and
28% declines, respectively). 32{\deg}C-acclimated mahi experienced increased
mortality and a significant 23% decline in Ucrit, and a trend for a 26% decline
in factorial aerobic scope relative to 28{\deg}C-acclimated fish. Absolute
aerobic scope showed a similar pattern to factorial aerobic scope. Our results
are generally in agreement with previously observed distribution patterns for
wild fish. Although thermal performance can vary across life stages, the
highest tested swim performance and aerobic scope found in the present study
(28{\deg}C), aligns with recently observed habitat utilization patterns for
wild mahi and could be relevant for climate change predictions.",http://arxiv.org/abs/2102.07743v2
"Cloud property trends in hot and ultra-hot giant gas planets (WASP-43b,
  WASP-103b, WASP-121b, HAT-P-7b, and WASP-18b)",2021-02-23T13:41:24Z,"Ch. Helling, D. Lewis, D. Samra, L. Carone, V. Graham, O. Herbort, K. L. Chubb, M. Min, R. Waters, V. Parmentier, N. Mayne","Ultra-hot Jupiters are the hottest exoplanets discovered so far. Observations
begin to provide insight into the composition of their extended atmospheres and
their chemical day/night asymmetries. Both are strongly affected by cloud
formation. We explore trends in cloud properties for a sample of five giant gas
planets: WASP-43b, WASP-18b, HAT-P-7b, WASP-103b, and WASP-121b. This provides
a reference frame for cloud properties for the JWST targets WASP-43b and
WASP-121b. We further explore chemically inert tracers to observe geometrical
asymmetries, and if the location of inner boundary of a 3D GCM matters for the
clouds that form. The large day/night temperature differences of ultra-hot
Jupiters cause large chemical asymmetries: cloud-free days but cloudy nights,
atomic vs. molecular gases and respectively different mean molecular weights,
deep thermal ionospheres vs. low-ionised atmospheres, undepleted vs enhanced
C/O. WASP-18b, as the heaviest planet in the sample, has the lowest global C/O.
The global climate may be considered as similar amongst ultra-hot Jupiters, but
different to that of hot gas giants. The local weather, however, is individual
for each planet since the local thermodynamic conditions, and hence the local
cloud and gas properties, differ. The morning and the evening terminator of
ultra-hot Jupiters will carry signatures of their strong chemical asymmetry
such that ingress/egress asymmetries can be expected. An increased C/O ratio is
a clear sign of cloud formation, making cloud modelling a necessity when
utilizing C/O (or other mineral ratios) as tracer for planet formation. The
changing geometrical extension of the atmosphere from the day to the nightside
may be probed through chemically inert species like helium. Ultra-hot Jupiters
are likely to develop deep atmospheric ionospheres which may impact the
atmosphere dynamics through MHD processes.",http://arxiv.org/abs/2102.11688v1
"Dual View on Clear-Sky Top-of-Atmosphere Albedos from Meteosat Second
  Generation Satellites",2021-02-25T23:58:50Z,"Alexandre Payez, Steven Dewitte, Nicolas Clerbaux","Geostationary observations offer the unique opportunity to resolve the
diurnal cycle of the Earth's Radiation Budget at the top of the atmosphere
(TOA), crucial for climate-change studies. However, a drawback of the
continuous temporal coverage of the geostationary orbit is the fixed viewing
geometry. As a consequence, imperfections in the angular distribution models
(ADMs) used in the radiance-to-flux conversion process or residual
angular-dependent narrowband-to-broadband conversion errors can result in
systematic errors of the estimated radiative fluxes. In this work, focusing on
clear-sky reflected TOA observations, we compare the overlapping views from
Meteosat Second Generation satellites at 0{\deg} and 41.5{\deg}E longitude
which enable a quantification of viewing-angle-dependent differences. Using
data derived from SEVIRI, we identify some of the main sources of
discrepancies, and show that they can be significantly reduced at the level of
one month. This is achieved, separately for each satellite, via a masking
procedure followed by an empirical fit at the pixel-level that takes into
account all the clear-sky data from that satellite, calculated separately per
timeslot of the day, over the month of November 2016. The method is then
applied to each month of 2017, and gives a quadratic mean of the albedo
root-mean squared difference over the dual-view region which is comparable from
month to month, with a 2017 average value of 0.01. Sources of discrepancies
include the difficulty to estimate the flux over the sunglint ocean region
close to the limbs, the fact that the data processing does not include
dedicated angular distribution models for the aerosol-over-ocean case, and the
existence of an observer-dependent diurnal-asymmetry artefact affecting the
clear-sky-albedo dependence on the solar zenith angle particularly over land
areas.",http://arxiv.org/abs/2102.13236v2
"The Flare Likelihood and Region Eruption Forecasting (FLARECAST)
  Project: Flare forecasting in the big data & machine learning era",2021-05-12T22:34:57Z,"M. K. Georgoulis, D. S. Bloomfield, M. Piana, A. M. Massone, M. Soldati, P. T. Gallagher, E. Pariat, N. Vilmer, E. Buchlin, F. Baudin, A. Csillaghy, H. Sathiapal, D. R. Jackson, P. Alingery, F. Benvenuto, C. Campi, K. Florios, C. Gontikakis, C. Guennou, J. A. Guerra, I. Kontogiannis, V. Latorre, S. A. Murray, S. -H. Park, S. von Stachelski, A. Torbica, D. Vischi, M. Worsfold","The EU funded the FLARECAST project, that ran from Jan 2015 until Feb 2018.
FLARECAST had a R2O focus, and introduced several innovations into the
discipline of solar flare forecasting. FLARECAST innovations were: first, the
treatment of hundreds of physical properties viewed as promising flare
predictors on equal footing, extending multiple previous works; second, the use
of fourteen (14) different ML techniques, also on equal footing, to optimize
the immense Big Data parameter space created by these many predictors; third,
the establishment of a robust, three-pronged communication effort oriented
toward policy makers, space-weather stakeholders and the wider public.
FLARECAST pledged to make all its data, codes and infrastructure openly
available worldwide. The combined use of 170+ properties (a total of 209
predictors are now available) in multiple ML algorithms, some of which were
designed exclusively for the project, gave rise to changing sets of
best-performing predictors for the forecasting of different flaring levels. At
the same time, FLARECAST reaffirmed the importance of rigorous training and
testing practices to avoid overly optimistic pre-operational prediction
performance. In addition, the project has (a) tested new and revisited
physically intuitive flare predictors and (b) provided meaningful clues toward
the transition from flares to eruptive flares, namely, events associated with
coronal mass ejections (CMEs). These leads, along with the FLARECAST data,
algorithms and infrastructure, could help facilitate integrated space-weather
forecasting efforts that take steps to avoid effort duplication. In spite of
being one of the most intensive and systematic flare forecasting efforts
to-date, FLARECAST has not managed to convincingly lift the barrier of
stochasticity in solar flare occurrence and forecasting: solar flare prediction
thus remains inherently probabilistic.",http://arxiv.org/abs/2105.05993v1
"Microgrid management with weather-based forecasting of energy
  generation, consumption and prices",2021-07-01T09:02:36Z,Jonathan Dumas,"The Intergovernmental Panel on Climate Change proposes different mitigation
strategies to achieve the net emissions reductions that would be required to
follow a pathway that limits global warming to 1.5{\deg}C with no or limited
overshoot. The transition towards a carbon-free society goes through an
inevitable increase in the share of renewable generation in the energy mix and
a drastic decrease in the total consumption of fossil fuels. Therefore, this
thesis studies the integration of renewables in power systems by investigating
forecasting and decision-making tools. Indeed, in contrast to conventional
power plants, renewable energy is subject to uncertainty. Most of the
generation technologies based on renewable sources are non-dispatchable, and
their production is stochastic and complex to predict in advance. A high share
of renewables is challenging for power systems that have been designed and
sized for dispatchable units. In this context, probabilistic forecasts, which
aim at modeling the distribution of all possible future realizations, have
become a vital tool to equip decision-makers, hopefully leading to better
decisions in energy applications. This thesis focuses on two main research
questions: (1) How to produce reliable probabilistic renewable generation
forecasts, consumption, and electricity prices? (2) How to make decisions with
uncertainty using probabilistic forecasts? The thesis perimeter is the energy
management of ""small"" systems such as microgrids at a residential scale on a
day-ahead basis. It is divided into two main parts to propose directions to
address both research questions (1) a forecasting part; (2) a planning and
control part.",http://arxiv.org/abs/2107.01034v7
Global Gridded Daily CO$_2$ Emissions,2021-07-19T02:38:24Z,"Xinyu Dou, Yilong Wang, Philippe Ciais, Frédéric Chevallier, Steven J. Davis, Monica Crippa, Greet Janssens-Maenhout, Diego Guizzardi, Efisio Solazzo, Feifan Yan, Da Huo, Zheng Bo, Zhu Deng, Biqing Zhu, Hengqi Wang, Qiang Zhang, Pierre Gentine, Zhu Liu","Precise and high-resolution carbon dioxide (CO$_2$) emission data is of great
importance of achieving the carbon neutrality around the world. Here we present
for the first time the near-real-time Global Gridded Daily CO$_2$ Emission
Datasets (called GRACED) from fossil fuel and cement production with a global
spatial-resolution of 0.1$^\circ$ by 0.1$^\circ$ and a temporal-resolution of
1-day. Gridded fossil emissions are computed for different sectors based on the
daily national CO$_2$ emissions from near real time dataset (Carbon Monitor),
the spatial patterns of point source emission dataset Global Carbon Grid (GID),
Emission Database for Global Atmospheric Research (EDGAR) and spatiotemporal
patters of satellite nitrogen dioxide (NO$_2$) retrievals. Our study on the
global CO$_2$ emissions responds to the growing and urgent need for
high-quality, fine-grained near-real-time CO2 emissions estimates to support
global emissions monitoring across various spatial scales. We show the spatial
patterns of emission changes for power, industry, residential consumption,
ground transportation, domestic and international aviation, and international
shipping sectors between 2019 and 2020. This help us to give insights on the
relative contributions of various sectors and provides a fast and fine-grained
overview of where and when fossil CO$_2$ emissions have decreased and rebounded
in response to emergencies (e.g. COVID-19) and other disturbances of human
activities than any previously published dataset. As the world recovers from
the pandemic and decarbonizes its energy systems, regular updates of this
dataset will allow policymakers to more closely monitor the effectiveness of
climate and energy policies and quickly adapt.",http://arxiv.org/abs/2107.08586v1
"Country-wide Retrieval of Forest Structure From Optical and SAR
  Satellite Imagery With Deep Ensembles",2021-11-25T16:21:28Z,"Alexander Becker, Stefania Russo, Stefano Puliti, Nico Lang, Konrad Schindler, Jan Dirk Wegner","Monitoring and managing Earth's forests in an informed manner is an important
requirement for addressing challenges like biodiversity loss and climate
change. While traditional in situ or aerial campaigns for forest assessments
provide accurate data for analysis at regional level, scaling them to entire
countries and beyond with high temporal resolution is hardly possible. In this
work, we propose a method based on deep ensembles that densely estimates forest
structure variables at country-scale with 10-meter resolution, using freely
available satellite imagery as input. Our method jointly transforms Sentinel-2
optical images and Sentinel-1 synthetic-aperture radar images into maps of five
different forest structure variables: 95th height percentile, mean height,
density, Gini coefficient, and fractional cover. We train and test our model on
reference data from 41 airborne laser scanning missions across Norway and
demonstrate that it is able to generalize to unseen test regions, achieving
normalized mean absolute errors between 11% and 15%, depending on the variable.
Our work is also the first to propose a variant of so-called Bayesian deep
learning to densely predict multiple forest structure variables with
well-calibrated uncertainty estimates from satellite imagery. The uncertainty
information increases the trustworthiness of the model and its suitability for
downstream tasks that require reliable confidence estimates as a basis for
decision making. We present an extensive set of experiments to validate the
accuracy of the predicted maps as well as the quality of the predicted
uncertainties. To demonstrate scalability, we provide Norway-wide maps for the
five forest structure variables.",http://arxiv.org/abs/2111.13154v3
"Thermal Conductivity measurements of macroscopic frozen Salt Ice analogs
  of Jovian Icy moons in support of the planned JUICE mission",2021-12-10T17:43:20Z,"Cristóbal González Díaz, Sofia Aparicio Secanellas, Guillermo M. Muñoz Caro, José Javier Anaya Velayos, Hector Carrascosa, Margarita G. Hernández, Victoria Muñoz-Iglesias, Ángel Marcos-Fernández, Olga Prieto-Ballesteros, Rosario Lorente, Olivier Witasse, Nicolas Altobelli","The study of thermal properties of frozen salt solutions representative of
ice layers in Jovian moons is crucial to support the JUpiter ICy moons Explorer
(JUICE) (ESA) and Europa Clipper (NASA) missions, which will be launched in the
upcoming years to make detailed observations of the giant gaseous planet
Jupiter and three of its largest moons (Ganymede, Europa, and Callisto), due to
the scarcity of experimental measurements. Therefore, we have conducted a set
of experiments to measure and study the thermal conductivity of macroscopic
frozen salt solutions of particular interest in these regions, including sodium
chloride (NaCl), magnesium sulphate (MgSO$_4$), sodium sulphate (Na$_2$SO$_4$),
and magnesium chloride (MgCl$_2$). Measurements were performed at atmospheric
pressure and temperatures from 0 to -70$^{\circ}$C in a climatic chamber.
Temperature and calorimetry were measured during the course of the experiments.
An interesting side effect of these measurements is that they served to spot
phase changes in the frozen salt solutions, even for very low salt
concentrations. A small sample of the liquid salt-water solution was set aside
for the calorimetry measurements. These experiments and the measurements of
thermal conductivity and calorimetry will be valuable to constrain the chemical
composition, physical state, and temperature of the icy crusts of Ganymede,
Europa, and Callisto.",http://arxiv.org/abs/2112.05697v1
Global Daily CO$_2$ emissions for the year 2020,2021-03-03T16:58:44Z,"Zhu Liu, Zhu Deng, Philippe Ciais, Jianguang Tan, Biqing Zhu, Steven J. Davis, Robbie Andrew, Olivier Boucher, Simon Ben Arous, Pep Canadel, Xinyu Dou, Pierre Friedlingstein, Pierre Gentine, Rui Guo, Chaopeng Hong, Robert B. Jackson, Daniel M. Kammen, Piyu Ke, Corinne Le Quere, Crippa Monica, Greet Janssens-Maenhout, Glen Peters, Katsumasa Tanaka, Yilong Wang, Bo Zheng, Haiwang Zhong, Taochun Sun, Hans Joachim Schellnhuber","The diurnal cycle CO$_2$ emissions from fossil fuel combustion and cement
production reflect seasonality, weather conditions, working days, and more
recently the impact of the COVID-19 pandemic. Here, for the first time we
provide a daily CO$_2$ emission dataset for the whole year of 2020 calculated
from inventory and near-real-time activity data (called Carbon Monitor project:
https://carbonmonitor.org). It was previously suggested from preliminary
estimates that did not cover the entire year of 2020 that the pandemics may
have caused more than 8% annual decline of global CO$_2$ emissions. Here we
show from detailed estimates of the full year data that the global reduction
was only 5.4% (-1,901 MtCO$_2$, ). This decrease is 5 times larger than the
annual emission drop at the peak of the 2008 Global Financial Crisis. However,
global CO$_2$ emissions gradually recovered towards 2019 levels from late April
with global partial re-opening. More importantly, global CO$_2$ emissions even
increased slightly by +0.9% in December 2020 compared with 2019, indicating the
trends of rebound of global emissions. Later waves of COVID-19 infections in
late 2020 and corresponding lockdowns have caused further CO$_2$ emissions
reductions particularly in western countries, but to a much smaller extent than
the declines in the first wave. That even substantial world-wide lockdowns of
activity led to a one-time decline in global CO$_2$ emissions of only 5.4% in
one year highlights the significant challenges for climate change mitigation
that we face in the post-COVID era. These declines are significant, but will be
quickly overtaken with new emissions unless the COVID-19 crisis is utilized as
a break-point with our fossil-fuel trajectory, notably through policies that
make the COVID-19 recovery an opportunity to green national energy and
development plans.",http://arxiv.org/abs/2103.02526v1
"Establishing a non-hydrostatic global atmospheric modeling system
  (iAMAS) at 3-km horizontal resolution with online integrated aerosol
  feedbacks on the Sunway supercomputer of China",2021-12-09T02:55:45Z,"Jun Gu, Jiawang Feng, Xiaoyu Hao, Tao Fang, Chun Zhao, Hong An, Junshi Chen, Mingyue Xu, Jian Li, Wenting Han, Chao Yang, Fang Li, Dexun Chen","During the era of global warming and highly urbanized development, extreme
and high impact weather as well as air pollution incidents influence everyday
life and might even cause the incalculable loss of life and property. Although
with the vast development of numerical simulation of atmosphere, there still
exists substantial forecast biases objectively. To predict extreme weather,
severe air pollution, and abrupt climate change accurately, the numerical
atmospheric model requires not only to simulate meteorology and atmospheric
compositions and their impacts simultaneously involving many sophisticated
physical and chemical processes but also at high spatiotemporal resolution.
Global atmospheric simulation of meteorology and atmospheric compositions
simultaneously at spatial resolutions of a few kilometers remains challenging
due to its intensive computational and input/output (I/O) requirement. Through
multi-dimension-parallelism structuring, aggressive and finer-grained
optimizing, manual vectorizing, and parallelized I/O fragmenting, an integrated
Atmospheric Model Across Scales (iAMAS) was established on the new Sunway
supercomputer platform to significantly increase the computational efficiency
and reduce the I/O cost. The global 3-km atmospheric simulation for meteorology
with online integrated aerosol feedbacks with iAMAS was scaled to 39,000,000
processor cores and achieved the speed of 0.82 simulation day per hour (SDPH)
with routine I/O, which enables us to perform 5-day global weather forecast at
3-km horizontal resolution with online natural aerosol impacts. The results
demonstrate the promising future that the increasing of spatial resolution to a
few kilometers with online integrated aerosol impacts may significantly improve
the global weather forecast.",http://arxiv.org/abs/2112.04668v1
Describing and Localizing Multiple Changes with Transformers,2021-03-25T21:52:03Z,"Yue Qiu, Shintaro Yamamoto, Kodai Nakashima, Ryota Suzuki, Kenji Iwata, Hirokatsu Kataoka, Yutaka Satoh","Change captioning tasks aim to detect changes in image pairs observed before
and after a scene change and generate a natural language description of the
changes. Existing change captioning studies have mainly focused on a single
change.However, detecting and describing multiple changed parts in image pairs
is essential for enhancing adaptability to complex scenarios. We solve the
above issues from three aspects: (i) We propose a simulation-based multi-change
captioning dataset; (ii) We benchmark existing state-of-the-art methods of
single change captioning on multi-change captioning; (iii) We further propose
Multi-Change Captioning transformers (MCCFormers) that identify change regions
by densely correlating different regions in image pairs and dynamically
determines the related change regions with words in sentences. The proposed
method obtained the highest scores on four conventional change captioning
evaluation metrics for multi-change captioning. Additionally, our proposed
method can separate attention maps for each change and performs well with
respect to change localization. Moreover, the proposed framework outperformed
the previous state-of-the-art methods on an existing change captioning
benchmark, CLEVR-Change, by a large margin (+6.1 on BLEU-4 and +9.7 on CIDEr
scores), indicating its general ability in change captioning tasks.",http://arxiv.org/abs/2103.14146v2
Online change-point detection for a transient change,2021-04-06T18:03:29Z,Jack Noonan,"We consider a popular online change-point problem of detecting a transient
change in distributions of i.i.d. random variables. For this change-point
problem, several change-point procedures are formulated and some advanced
results for a particular procedure are surveyed. Some new approximations for
the average run length to false alarm are offered and the power of these
procedures for detecting a transient change in mean of a sequence of normal
random variables is compared.",http://arxiv.org/abs/2104.02734v1
Binary Change Guided Hyperspectral Multiclass Change Detection,2021-12-08T13:17:24Z,"Meiqi Hu, Chen Wu, Bo Du, Liangpei Zhang","Characterized by tremendous spectral information, hyperspectral image is able
to detect subtle changes and discriminate various change classes for change
detection. The recent research works dominated by hyperspectral binary change
detection, however, cannot provide fine change classes information. And most
methods incorporating spectral unmixing for hyperspectral multiclass change
detection (HMCD), yet suffer from the neglection of temporal correlation and
error accumulation. In this study, we proposed an unsupervised Binary Change
Guided hyperspectral multiclass change detection Network (BCG-Net) for HMCD,
which aims at boosting the multiclass change detection result and unmixing
result with the mature binary change detection approaches. In BCG-Net, a novel
partial-siamese united-unmixing module is designed for multi-temporal spectral
unmixing, and a groundbreaking temporal correlation constraint directed by the
pseudo-labels of binary change detection result is developed to guide the
unmixing process from the perspective of change detection, encouraging the
abundance of the unchanged pixels more coherent and that of the changed pixels
more accurate. Moreover, an innovative binary change detection rule is put
forward to deal with the problem that traditional rule is susceptible to
numerical values. The iterative optimization of the spectral unmixing process
and the change detection process is proposed to eliminate the accumulated
errors and bias from unmixing result to change detection result. The
experimental results demonstrate that our proposed BCG-Net could achieve
comparative or even outstanding performance of multiclass change detection
among the state-of-the-art approaches and gain better spectral unmixing results
at the same time.",http://arxiv.org/abs/2112.04493v2
"Change point inference in ergodic diffusion processes based on high
  frequency data",2021-04-23T07:03:27Z,"Yozo Tonaki, Masayuki Uchida","We deal with the change point problem in ergodic diffusion processes based on
high frequency data. Tonaki et al. (2020, 2021) studied the change point
problem for the ergodic diffusion process model. However, the change point
problem for the drift parameter when the diffusion parameter changes is still
open. Therefore, we consider the change detection and the change point
estimation for the drift parameter taking into account that there is a change
point in the diffusion parameter. Moreover, we examine the performance of the
tests and the estimation with numerical simulations.",http://arxiv.org/abs/2104.11438v1
"Auto robust relative radiometric normalization via latent change noise
  modelling",2021-11-24T10:43:55Z,"Shiqi Liu, Lu Wang, Jie Lian, Ting chen, Cong Liu, Xuchen Zhan, Jintao Lu, Jie Liu, Ting Wang, Dong Geng, Hongwei Duan, Yuze Tian","Relative radiometric normalization(RRN) of different satellite images of the
same terrain is necessary for change detection, object
classification/segmentation, and map-making tasks. However, traditional RRN
models are not robust, disturbing by object change, and RRN models precisely
considering object change can not robustly obtain the no-change set. This paper
proposes auto robust relative radiometric normalization methods via latent
change noise modeling. They utilize the prior knowledge that no change points
possess small-scale noise under relative radiometric normalization and that
change points possess large-scale radiometric noise after radiometric
normalization, combining the stochastic expectation maximization method to
quickly and robustly extract the no-change set to learn the relative
radiometric normalization mapping functions. This makes our model theoretically
grounded regarding the probabilistic theory and mathematics deduction.
Specifically, when we select histogram matching as the relative radiometric
normalization learning scheme integrating with the mixture of Gaussian
noise(HM-RRN-MoG), the HM-RRN-MoG model achieves the best performance. Our
model possesses the ability to robustly against clouds/fogs/changes. Our method
naturally generates a robust evaluation indicator for RRN that is the no-change
set root mean square error. We apply the HM-RRN-MoG model to the latter
vegetation/water change detection task, which reduces the radiometric contrast
and NDVI/NDWI differences on the no-change set, generates consistent and
comparable results. We utilize the no-change set into the building change
detection task, efficiently reducing the pseudo-change and boosting the
precision.",http://arxiv.org/abs/2111.12406v1
"Non-Parametric Quickest Detection of a Change in the Mean of an
  Observation Sequence",2021-01-14T02:13:43Z,"Yuchen Liang, Venugopal V. Veeravalli","We study the problem of quickest detection of a change in the mean of an
observation sequence, under the assumption that both the pre- and post-change
distributions have bounded support. We first study the case where the
pre-change distribution is known, and then study the extension where only the
mean and variance of the pre-change distribution are known. In both cases, no
knowledge of the post-change distribution is assumed other than that it has
bounded support. For the case where the pre-change distribution is known, we
derive a test that asymptotically minimizes the worst-case detection delay over
all post-change distributions, as the false alarm rate goes to zero. We then
study the limiting form of the optimal test as the gap between the pre- and
post-change means goes to zero, which we call the Mean-Change Test (MCT). We
show that the MCT can be designed with only knowledge of the mean and variance
of the pre-change distribution. We validate our analysis through numerical
results for detecting a change in the mean of a beta distribution. We also
demonstrate the use of the MCT for pandemic monitoring.",http://arxiv.org/abs/2101.05423v1
Non-Parametric Quickest Mean Change Detection,2021-08-25T17:15:55Z,"Yuchen Liang, Venugopal V. Veeravalli","The problem of quickest detection of a change in the mean of a sequence of
independent observations is studied. The pre-change distribution is assumed to
be stationary, while the post-change distributions are allowed to be
non-stationary. The case where the pre-change distribution is known is studied
first, and then the extension where only the mean and variance of the
pre-change distribution are known. No knowledge of the post-change
distributions is assumed other than that their means are above some
pre-specified threshold larger than the pre-change mean. For the case where the
pre-change distribution is known, a test is derived that asymptotically
minimizes the worst-case detection delay over all possible post-change
distributions, as the false alarm rate goes to zero. Towards deriving this
asymptotically optimal test, some new results are provided for the general
problem of asymptotic minimax robust quickest change detection in
non-stationary settings. Then, the limiting form of the optimal test is studied
as the gap between the pre- and post-change means goes to zero, called the
Mean-Change Test (MCT). It is shown that the MCT can be designed with only
knowledge of the mean and variance of the pre-change distribution. The
performance of the MCT is also characterized when the mean gap is moderate,
under the additional assumption that the distributions of the observations have
bounded support. The analysis is validated through numerical results for
detecting a change in the mean of a beta distribution. The use of the MCT in
monitoring pandemics is also demonstrated.",http://arxiv.org/abs/2108.11348v1
Multipartition model for multiple change point identification,2021-07-23T20:48:03Z,"Ricardo C. Pedroso, Rosangela H. Loschi, Fernando Andrés Quintana","Among the main goals in multiple change point problems are the estimation of
the number and positions of the change points, as well as the regime structure
in the clusters induced by those changes. The product partition model (PPM) is
a widely used approach for the detection of multiple change points. The
traditional PPM assumes that change points split the set of time points in
random clusters that define a partition of the time axis. It is then typically
assumed that sampling model parameter values within each of these blocks are
identical. Because changes in different parameters of the observational model
may occur at different times, the PPM thus fails to identify the parameters
that experienced those changes. A similar problem may occur when detecting
changes in multivariate time series. To solve this important limitation, we
introduce a multipartition model to detect multiple change points occurring in
several parameters at possibly different times. The proposed model assumes that
the changes experienced by each parameter generate a different random partition
of the time axis, which facilitates identifying which parameters have changed
and when they do so. We discuss a partially collapsed Gibbs sampler scheme to
implement posterior simulation under the proposed model. We apply the proposed
model to identify multiple change points in Normal means and variances and
evaluate the performance of the proposed model through Monte Carlo simulations
and data illustrations. Its performance is compared with some previously
proposed approaches for change point problems. These studies show that the
proposed model is competitive and enriches the analysis of change point
problems.",http://arxiv.org/abs/2107.11456v2
"Sequential (Quickest) Change Detection: Classical Results and New
  Directions",2021-04-09T04:35:16Z,"Liyan Xie, Shaofeng Zou, Yao Xie, Venugopal V. Veeravalli","Online detection of changes in stochastic systems, referred to as sequential
change detection or quickest change detection, is an important research topic
in statistics, signal processing, and information theory, and has a wide range
of applications. This survey starts with the basics of sequential change
detection, and then moves on to generalizations and extensions of sequential
change detection theory and methods. We also discuss some new dimensions that
emerge at the intersection of sequential change detection with other areas,
along with a selection of modern applications and remarks on open questions.",http://arxiv.org/abs/2104.04186v1
"Development of Simulation-based Lane Change Control System for
  Autonomous Vehicles",2021-08-12T05:35:21Z,Seongjin Choi,"Originally, the decision and control of the lane change of the vehicle were
on the human driver. In previous studies, the decision-making of lane-changing
of the human drivers was mainly used to increase the individual's benefit.
However, the lane-changing behavior of these human drivers can sometimes have a
bad influence on the overall traffic flow. As technology for autonomous
vehicles develop, lane changing action as well as lane changing decision making
fall within the control category of autonomous vehicles. However, since many of
the current lane-changing decision algorithms of autonomous vehicles are based
on the human driver model, it is hard to know the potential traffic impact of
such lane change. Therefore, in this study, we focused on the decision-making
of lane change considering traffic flow, and accordingly, we study the lane
change control system considering the whole traffic flow. In this research, the
lane change control system predicts the future traffic situation through the
cell transition model, one of the most popular macroscopic traffic simulation
models, and determines the change probability of each lane that minimizes the
total time delay through the genetic algorithm. The lane change control system
then conveys the change probability to this vehicle. In the macroscopic
simulation result, the proposed control system reduced the overall travel time
delay. The proposed system is applied to microscopic traffic simulation, the
oversaturated freeway traffic flow algorithm (OFFA), to evaluate the potential
performance when it is applied to the actual traffic system. In the traffic
flow-density, the maximum traffic flow has been shown to be increased, and the
points in the congestion area have also been greatly reduced. Overall, the time
required for individual vehicles was reduced.",http://arxiv.org/abs/2108.05543v2
"Managing Requirements Change the Informal Way: When Saying 'No' is Not
  an Option",2021-04-02T01:29:50Z,"Waqar Hussain, Didar Zowghi, Tony Clear, Stephen MacDonell, Kelly Blincoe","Software has always been considered as malleable. Changes to software
requirements are inevitable during the development process. Despite many
software engineering advances over several decades, requirements changes are a
source of project risk, particularly when businesses and technologies are
evolving rapidly. Although effectively managing requirements changes is a
critical aspect of software engineering, conceptions of requirements change in
the literature and approaches to their management in practice still seem
rudimentary. The overall goal of this study is to better understand the process
of requirements change management. We present findings from an exploratory case
study of requirements change management in a globally distributed setting. In
this context we noted a contrast with the traditional models of requirements
change. In theory, change control policies and formal processes are considered
as a natural strategy to deal with requirements changes. Yet we observed that
""informal requirements changes"" (InfRc) were pervasive and unavoidable. Our
results reveal an equally 'natural' informal change management process that is
required to handle InfRc in parallel. We present a novel model of requirements
change which, we argue, better represents the phenomenon and more realistically
incorporates both the informal and formal types of change.",http://arxiv.org/abs/2104.00843v1
A large-scale study on human-cloned changes for automated program repair,2021-04-06T09:22:56Z,"Fernanda Madeiral, Thomas Durieux","Research in automatic program repair has shown that real bugs can be
automatically fixed. However, there are several challenges involved in such a
task that are not yet fully addressed. As an example, consider that a
test-suite-based repair tool performs a change in a program to fix a bug
spotted by a failing test case, but then the same or another test case fails.
This could mean that the change is a partial fix for the bug or that another
bug was manifested. However, the repair tool discards the change and possibly
performs other repair attempts. One might wonder if the applied change should
be also applied in other locations in the program so that the bug is fully
fixed. In this paper, we are interested in investigating the extent of bug fix
changes being cloned by developers within patches. Our goal is to investigate
the need of multi-location repair by using identical or similar changes in
identical or similar contexts. To do so, we analyzed 3,049 multi-hunk patches
from the ManySStuBs4J dataset, which is a large dataset of single statement bug
fix changes. We found out that 68% of the multi-hunk patches contain at least
one change clone group. Moreover, most of these patches (70%) are
strictly-cloned ones, which are patches fully composed of changes belonging to
one single change clone group. Finally, most of the strictly-cloned patches
(89%) contain change clones with identical changes, independently of their
contexts. We conclude that automated solutions for creating patches composed of
identical or similar changes can be useful for fixing bugs.",http://arxiv.org/abs/2104.02386v1
"Estimation for change point of discretely observed ergodic diffusion
  processes",2021-02-13T06:34:03Z,"Yozo Tonaki, Yusuke Kaino, Masayuki Uchida","We treat the change point problem in ergodic diffusion processes from
discrete observations. Tonaki et al. (2020) proposed adaptive tests for
detecting changes in the diffusion and drift parameters in ergodic diffusion
models. When any changes are detected by this method, the next question to be
considered is where the change point is. Therefore, we propose the method to
estimate the change point of the parameter for two cases: the case where there
is a change in the diffusion parameter, and the case where there is no change
in the diffusion parameter but a change in the drift parameter. Furthermore, we
present rates of convergence and distributional results of the change point
estimators. Some examples and simulation results are also given.",http://arxiv.org/abs/2102.06871v1
"Task-Related Self-Supervised Learning for Remote Sensing Image Change
  Detection",2021-05-11T11:44:04Z,"Zhinan Cai, Zhiyu Jiang, Yuan Yuan","Change detection for remote sensing images is widely applied for urban change
detection, disaster assessment and other fields. However, most of the existing
CNN-based change detection methods still suffer from the problem of inadequate
pseudo-changes suppression and insufficient feature representation. In this
work, an unsupervised change detection method based on Task-related
Self-supervised Learning Change Detection network with smooth mechanism(TSLCD)
is proposed to eliminate it. The main contributions include: (1) the
task-related self-supervised learning module is introduced to extract spatial
features more effectively. (2) a hard-sample-mining loss function is applied to
pay more attention to the hard-to-classify samples. (3) a smooth mechanism is
utilized to remove some of pseudo-changes and noise. Experiments on four remote
sensing change detection datasets reveal that the proposed TSLCD method
achieves the state-of-the-art for change detection task.",http://arxiv.org/abs/2105.04951v2
How does Software Change?,2021-06-03T14:31:37Z,"Ayushi Rastogi, Georgios Gousios","Software evolves with changes to its codebase over time. Internally, software
changes in response to decisions to include some code change into the codebase
and discard others. Explaining the mechanism of software evolution, this paper
presents a theory of software change. Our theory is grounded in multiple
evidence sources (e.g., GitHub documentation and relevant scientific
literature) relating to the pull-based development model in GitHub. The
resulting theory explains the influence of project-related core concepts (e.g.,
people and governance) as well as its ecosystem on the decision of software
change.",http://arxiv.org/abs/2106.01885v1
Linear Rescaling to Accurately Interpret Logarithms,2021-06-06T09:11:36Z,Nick Huntington-Klein,"The standard approximation of a natural logarithm in statistical analysis
interprets a linear change of \(p\) in \(\ln(X)\) as a \((1+p)\) proportional
change in \(X\), which is only accurate for small values of \(p\). I suggest
base-\((1+p)\) logarithms, where \(p\) is chosen ahead of time. A one-unit
change in \(\log_{1+p}(X)\) is exactly equivalent to a \((1+p)\) proportional
change in \(X\). This avoids an approximation applied too broadly, makes exact
interpretation easier and less error-prone, improves approximation quality when
approximations are used, makes the change of interest a one-log-unit change
like other regression variables, and reduces error from the use of
\(\log(1+X)\).",http://arxiv.org/abs/2106.03070v3
Detection and Estimation of Multiple Transient Changes,2021-12-12T19:55:53Z,"Baron Michael, Malov Sergey V","Change-point detection methods are proposed for the case of temporary
failures, or transient changes, when an unexpected disorder is ultimately
followed by a readjustment and return to the initial state. A base distribution
of the ""in-control"" state changes to an ""out-of-control"" distribution for
unknown periods of time. Likelihood based sequential and retrospective tools
are proposed for the detection and estimation of each pair of change-points.
The accuracy of the obtained change-point estimates is assessed. Proposed
methods offer simultaneous control the familywise false alarm and false
readjustment rates at the pre-chosen levels.",http://arxiv.org/abs/2112.06308v1
"Detection of Abrupt Change in Channel Covariance Matrix for
  Multi-Antenna Communication",2021-09-09T11:55:53Z,"Runnan Liu, Liang Liu, Dazhi He, Wenjun Zhang, Erik G. Larsson","The knowledge of channel covariance matrices is of paramount importance to
the estimation of instantaneous channels and the design of beamforming vectors
in multi-antenna systems. In practice, an abrupt change in channel covariance
matrices may occur due to the change in the environment and the user location.
Although several works have proposed efficient algorithms to estimate the
channel covariance matrices after any change occurs, how to detect such a
change accurately and quickly is still an open problem in the literature. In
this paper, we focus on channel covariance change detection between a
multi-antenna base station (BS) and a single-antenna user equipment (UE). To
provide theoretical performance limit, we first propose a genie-aided change
detector based on the log-likelihood ratio (LLR) test assuming the channel
covariance matrix after change is known, and characterize the corresponding
missed detection and false alarm probabilities. Then, this paper considers the
practical case where the channel covariance matrix after change is unknown. The
maximum likelihood (ML) estimation technique is used to predict the covariance
matrix based on the received pilot signals over a certain number of coherence
blocks, building upon which the LLR-based change detector is employed.
Numerical results show that our proposed scheme can detect the change with low
error probability even when the number of channel samples is small such that
the estimation of the covariance matrix is not that accurate. This result
verifies the possibility to detect the channel covariance change both
accurately and quickly in practice.",http://arxiv.org/abs/2109.04192v1
"Nonvolatile plasmonics based on optically reprogrammable phase change
  materials",2021-12-16T19:21:17Z,Jacek Gosciniak,"We propose here a new platform for a realization of novel nonvolatile optical
switching devices that takes an advantage of high field confinement provided by
plasmonics and multi-state programming capabilities of chalcogenide phase
change materials. A high reduction in the overall energy consumption consists
of a high field enhancement provided by plasmonic that allow to lower the
switching energies and implementation of phase change materials that allow to
operate under a zero-static power consumption. A combination of plasmonics and
phase change materials provide additionally an essential improvement in terms
of a switching time, attenuation contrast and possibility to perform a phase
shift with the wide bandgap phase change materials. In most of the all-optical
switching photonic devices, a switching mechanism is realized optically through
heating of phase change materials. Here, two stage heating process is proposed
that is based on the absorption of light by phase change materials itself, and
a heat transfer from the metal stripe under an absorption of light by a metal.
Thus, compared to any other previously presented optical switches, even a wide
bandgap phase change materials that show zero absorption of light can be
implemented in the proposed structure. The proposed plasmonic waveguide
arrangement is extremely sensitive to any changes of the phase change material
properties, thus, even a minor change of temperature provides an essential
change in the transmitted light.",http://arxiv.org/abs/2112.09163v1
"R$^3$Net:Relation-embedded Representation Reconstruction Network for
  Change Captioning",2021-10-20T00:57:39Z,"Yunbin Tu, Liang Li, Chenggang Yan, Shengxiang Gao, Zhengtao Yu","Change captioning is to use a natural language sentence to describe the
fine-grained disagreement between two similar images. Viewpoint change is the
most typical distractor in this task, because it changes the scale and location
of the objects and overwhelms the representation of real change. In this paper,
we propose a Relation-embedded Representation Reconstruction Network (R$^3$Net)
to explicitly distinguish the real change from the large amount of clutter and
irrelevant changes. Specifically, a relation-embedded module is first devised
to explore potential changed objects in the large amount of clutter. Then,
based on the semantic similarities of corresponding locations in the two
images, a representation reconstruction module (RRM) is designed to learn the
reconstruction representation and further model the difference representation.
Besides, we introduce a syntactic skeleton predictor (SSP) to enhance the
semantic interaction between change localization and caption generation.
Extensive experiments show that the proposed method achieves the
state-of-the-art results on two public datasets.",http://arxiv.org/abs/2110.10328v1
Assessing the Exposure of Software Changes: The DiPiDi Approach,2021-04-01T19:04:01Z,"Mehran Meidani, Maxime Lamothe, Shane McIntosh","Context: Changing a software application with many build-time configuration
settings may introduce unexpected side-effects. For example, a change intended
to be specific to a platform (e.g., Windows) or product configuration (e.g.,
community editions) might impact other platforms or configurations. Moreover, a
change intended to apply to a set of platforms or configurations may be
unintentionally limited to a subset. Indeed, understanding the exposure of
source code changes is an important risk mitigation step in change-based
development approaches. Objective: In this experiment, we seek to evaluate
DiPiDi, a prototype implementation of our approach to assess the exposure of
source code changes by statically analyzing build specifications. We focus our
evaluation on the effectiveness and efficiency of developers when assessing the
exposure of source code changes. Method: We will measure the effectiveness and
efficiency of developers when performing five tasks in which they must identify
the deliverable(s) and conditions under which a change will propagate. We will
assign participants into three groups: without explicit tool support, supported
by existing impact analysis tools, and supported by DiPiDi.",http://arxiv.org/abs/2104.00725v1
"Intercept Graph: An Interactive Radial Visualization for Comparison of
  State Changes",2021-08-19T08:10:42Z,"Shaolun Ruan, Yong Wang, Qiang Guan","State change comparison of multiple data items is often necessary in multiple
application domains, such as medical science, financial engineering, sociology,
biological science, etc. Slope graphs and grouped bar charts have been widely
used to show a ""before-and-after"" story of different data states and indicate
their changes. However, they visualize state changes as either slope or
difference of bars, which has been proved less effective for quantitative
comparison. Also, both visual designs suffer from visual clutter issues with an
increasing number of data items. In this paper, we propose Intercept Graph, a
novel visual design to facilitate effective interactive comparison of state
changes. Specifically, a radial design is proposed to visualize the starting
and ending states of each data item and the line segment length explicitly
encodes the ""state change"". By interactively adjusting the radius of the inner
circular axis, Intercept Graph can smoothly filter the large state changes and
magnify the difference between similar state changes, mitigating the visual
clutter issues and enhancing the effective comparison of state changes. We
conducted a case study through comparing Intercept Graph with slope graphs and
grouped bar charts on real datasets to demonstrate the effectiveness of
Intercept Graph.",http://arxiv.org/abs/2109.10893v1
"Personalized Lane Change Decision Algorithm Using Deep Reinforcement
  Learning Approach",2021-12-17T10:16:43Z,"Daofei Li, Ao Liu","To develop driving automation technologies for human, a human-centered
methodology should be adopted for ensured safety and satisfactory user
experience. Automated lane change decision in dense highway traffic is
challenging, especially when considering the personalized preferences of
different drivers. To fulfill human driver centered decision algorithm
development, we carry out driver-in-the-loop experiments on a
6-Degree-of-Freedom driving simulator. Based on the analysis of the lane change
data by drivers of three specific styles,personalization indicators are
selected to describe the driver preferences in lane change decision. Then a
deep reinforcement learning (RL) approach is applied to design human-like
agents for automated lane change decision, with refined reward and loss
functions to capture the driver preferences.The trained RL agents and benchmark
agents are tested in a two-lane highway driving scenario, and by comparing the
agents with the specific drivers at the same initial states of lane change, the
statistics show that the proposed algorithm can guarantee higher consistency of
lane change decision preferences. The driver personalization indicators and the
proposed RL-based lane change decision algorithm are promising to contribute in
automated lane change system developing.",http://arxiv.org/abs/2112.13646v1
"Investigating and Recommending Co-Changed Entities for JavaScript
  Programs",2021-02-15T22:37:16Z,"Zijian Jiang, Hao Zhong, Na Meng","JavaScript (JS) is one of the most popular programming languages due to its
flexibility and versatility, but maintaining JS code is tedious and
error-prone. In our research, we conducted an empirical study to characterize
the relationship between co-changed software entities (e.g., functions and
variables), and built a machine learning (ML)-based approach to recommend
additional entity to edit given developers' code changes. Specifically, we
first crawled 14,747 commits in 10 open-source projects; for each commit, we
created one or more change dependency graphs (CDGs) to model the
referencer-referencee relationship between co-changed entities. Next, we
extracted the common subgraphs between CDGs to locate recurring co-change
patterns between entities. Finally, based on those patterns, we extracted code
features from co-changed entities and trained an ML model that recommends
entities-to-change given a program commit. According to our empirical
investigation, (1) three recurring patterns commonly exist in all projects; (2)
80%--90% of co-changed function pairs either invoke the same function(s),
access the same variable(s), or contain similar statement(s); (3) our ML-based
approach CoRec recommended entity changes with high accuracy (73%--78%). CoRec
complements prior work because it suggests changes based on program syntax,
textual similarity, as well as software history; it achieved higher accuracy
than two existing tools in our evaluation.",http://arxiv.org/abs/2102.07877v2
"Become a better you: correlation between the change of research
  direction and the change of scientific performance",2021-07-02T18:29:07Z,"Xiaoyao Yu, Boleslaw K. Szymanski, Tao Jia","It is important to explore how scientists decide their research agenda and
the corresponding consequences, as their decisions collectively shape
contemporary science. There are studies focusing on the overall performance of
individuals with different problem choosing strategies. Here we ask a slightly
different but relatively unexplored question: how is a scientist's change of
research agenda associated with her change of scientific performance. Using
publication records of over 14,000 authors in physics, we quantitatively
measure the extent of research direction change and the performance change of
individuals. We identify a strong positive correlation between the direction
change and impact change. Scientists with a larger direction change not only
are more likely to produce works with increased scientific impact compared to
their past ones, but also have a higher growth rate of scientific impact. On
the other hand, the direction change is not associated with productivity
change. Those who stay in familiar topics do not publish faster than those who
venture out and establish themselves in a new field. The gauge of research
direction in this work is uncorrelated with the diversity of research agenda
and the switching probability among topics, capturing the evolution of
individual careers from a new point of view. Though the finding is inevitably
affected by the survival bias, it sheds light on a range of problems in the
career development of individual scientists.",http://arxiv.org/abs/2107.01232v1
Change Detection Meets Visual Question Answering,2021-12-12T22:39:20Z,"Zhenghang Yuan, Lichao Mou, Zhitong Xiong, Xiaoxiang Zhu","The Earth's surface is continually changing, and identifying changes plays an
important role in urban planning and sustainability. Although change detection
techniques have been successfully developed for many years, these techniques
are still limited to experts and facilitators in related fields. In order to
provide every user with flexible access to change information and help them
better understand land-cover changes, we introduce a novel task: change
detection-based visual question answering (CDVQA) on multi-temporal aerial
images. In particular, multi-temporal images can be queried to obtain high
level change-based information according to content changes between two input
images. We first build a CDVQA dataset including multi-temporal
image-question-answer triplets using an automatic question-answer generation
method. Then, a baseline CDVQA framework is devised in this work, and it
contains four parts: multi-temporal feature encoding, multi-temporal fusion,
multi-modal fusion, and answer prediction. In addition, we also introduce a
change enhancing module to multi-temporal feature encoding, aiming at
incorporating more change-related information. Finally, effects of different
backbones and multi-temporal fusion strategies are studied on the performance
of CDVQA task. The experimental results provide useful insights for developing
better CDVQA models, which are important for future research on this task.",http://arxiv.org/abs/2112.06343v2
"Detecting and Understanding Branching Frequency Changes in Process
  Models",2021-03-19T11:26:25Z,"Yang Lu, Qifan Chen, Simon Poon","Business processes are continuously evolving in order to adapt to changes due
to various factors. One type of process changes are branching frequency
changes, which are related to changes in frequencies between different options
when there is an exclusive choice. Existing methods either cannot detect such
changes or cannot provide accurate and comprehensive results. In this paper, we
propose a method which takes both event logs and process models as input and
generates a choice sequence for each exclusive choice in the process model. The
method then identifies change points based on the choice sequences. We evaluate
our method on a real-life event log. Results show that our method can identify
branching frequency changes in process models and provide comprehensive results
to users.",http://arxiv.org/abs/2103.10742v3
"Self-supervised Lesion Change Detection and Localisation in Longitudinal
  Multiple Sclerosis Brain Imaging",2021-06-02T03:34:10Z,"Minh-Son To, Ian G Sarno, Chee Chong, Mark Jenkinson, Gustavo Carneiro","Longitudinal imaging forms an essential component in the management and
follow-up of many medical conditions. The presence of lesion changes on serial
imaging can have significant impact on clinical decision making, highlighting
the important role for automated change detection. Lesion changes can represent
anomalies in serial imaging, which implies a limited availability of
annotations and a wide variety of possible changes that need to be considered.
Hence, we introduce a new unsupervised anomaly detection and localisation
method trained exclusively with serial images that do not contain any lesion
changes. Our training automatically synthesises lesion changes in serial
images, introducing detection and localisation pseudo-labels that are used to
self-supervise the training of our model. Given the rarity of these lesion
changes in the synthesised images, we train the model with the imbalance robust
focal Tversky loss. When compared to supervised models trained on different
datasets, our method shows competitive performance in the detection and
localisation of new demyelinating lesions on longitudinal magnetic resonance
imaging in multiple sclerosis patients. Code for the models will be made
available on GitHub.",http://arxiv.org/abs/2106.00919v1
Unsupervised Learning of General-Purpose Embeddings for Code Changes,2021-06-03T19:08:53Z,"Mikhail Pravilov, Egor Bogomolov, Yaroslav Golubev, Timofey Bryksin","Applying machine learning to tasks that operate with code changes requires
their numerical representation. In this work, we propose an approach for
obtaining such representations during pre-training and evaluate them on two
different downstream tasks - applying changes to code and commit message
generation. During pre-training, the model learns to apply the given code
change in a correct way. This task requires only code changes themselves, which
makes it unsupervised. In the task of applying code changes, our model
outperforms baseline models by 5.9 percentage points in accuracy. As for the
commit message generation, our model demonstrated the same results as
supervised models trained for this specific task, which indicates that it can
encode code changes well and can be improved in the future by pre-training on a
larger dataset of easily gathered code changes.",http://arxiv.org/abs/2106.02087v2
Rank Energy Statistics in the Context of Change Point Detection,2021-08-10T20:18:38Z,Amanda Ng,"In this paper, I propose a general procedure for multivariate
distribution-free nonparametric testing derived from the concept of ranks that
are based upon measure transportation in the context of multiple change point
analysis. I will use this algorithm to estimate both the number of change
points and their locations within an observed multivariate time series. In this
paper, the change point problem is observed in a general setting in which both
the given distribution and number of change points are unknown, rather than
assume the observed time series follows a specific distribution or contains
only one change point as many works in this area of study assume. The intention
of this is to develop a technique for accurately identifying the changes in a
distribution while making as few suppositions as possible. The rank energy
statistic used here is based on energy statistics and has the potential to
detect any change in a distribution. I present the properties of this new
algorithm, which can be used to analyze various datasets, including
hierarchical clustering, testing multivariate normality, gene selection, and
microarray data analysis. This algorithm has also been implemented in the R
package recp, which is available on GitHub.",http://arxiv.org/abs/2108.04903v2
"WRICNet:A Weighted Rich-scale Inception Coder Network for
  Multi-Resolution Remote Sensing Image Change Detection",2021-08-18T02:56:11Z,"Yu Jiang, Lei Hu, Yongmei Zhang, Xin Yang","Majority models of remote sensing image changing detection can only get great
effect in a specific resolution data set. With the purpose of improving change
detection effectiveness of the model in the multi-resolution data set, a
weighted rich-scale inception coder network (WRICNet) is proposed in this
article, which can make a great fusion of shallow multi-scale features, and
deep multi-scale features. The weighted rich-scale inception module of the
proposed can obtain shallow multi-scale features, the weighted rich-scale coder
module can obtain deep multi-scale features. The weighted scale block assigns
appropriate weights to features of different scales, which can strengthen
expressive ability of the edge of the changing area. The performance
experiments on the multi-resolution data set demonstrate that, compared to the
comparative methods, the proposed can further reduce the false alarm outside
the change area, and the missed alarm in the change area, besides, the edge of
the change area is more accurate. The ablation study of the proposed shows that
the training strategy, and improvements of this article can improve the
effectiveness of change detection.",http://arxiv.org/abs/2108.07955v1
"Spatial Context Awareness for Unsupervised Change Detection in Optical
  Satellite Images",2021-10-05T14:13:48Z,"Lukas Kondmann, Aysim Toker, Sudipan Saha, Bernhard Schölkopf, Laura Leal-Taixé, Xiao Xiang Zhu","Detecting changes on the ground in multitemporal Earth observation data is
one of the key problems in remote sensing. In this paper, we introduce Sibling
Regression for Optical Change detection (SiROC), an unsupervised method for
change detection in optical satellite images with medium and high resolution.
SiROC is a spatial context-based method that models a pixel as a linear
combination of its distant neighbors. It uses this model to analyze differences
in the pixel and its spatial context-based predictions in subsequent time
periods for change detection. We combine this spatial context-based change
detection with ensembling over mutually exclusive neighborhoods and
transitioning from pixel to object-level changes with morphological operations.
SiROC achieves competitive performance for change detection with
medium-resolution Sentinel-2 and high-resolution Planetscope imagery on four
datasets. Besides accurate predictions without the need for training, SiROC
also provides a well-calibrated uncertainty of its predictions. This makes the
method especially useful in conjunction with deep-learning based methods for
applications such as pseudo-labeling.",http://arxiv.org/abs/2110.02068v1
Change in Hamiltonian General Relativity with Spinors,2021-10-28T16:21:56Z,J. Brian Pitts,"In Hamiltonian GR, change has seemed to be missing, defined only
asymptotically, or otherwise obscured at best. By construing change as
essential time dependence, can one find change locally in Hamiltonian GR with
spinors?
  This paper is motivated by tendencies in space-time philosophy to slight
fermionic/spinorial matter, in Hamiltonian GR to misplace changes of time
coordinate, and in treatments of the Einstein-Dirac equation to include a
gratuitous local Lorentz gauge symmetry. Spatial dependence is dropped in most
of the paper. To include all and only the coordinate freedom, the
Einstein-Dirac equation is investigated using the Schwinger time gauge and
Kibble-Deser symmetric triad condition as a $3+1$ version of the
DeWitt-Ogievetsky-Polubarinov nonlinear group realization formalism that
dispenses with a tetrad and local Lorentz gauge freedom. Change is the lack of
a time-like stronger-than-Killing field for which the Lie derivative of the
metric-spinor complex vanishes. An appropriate $3+1$-friendly form of the
Rosenfeld-Anderson-Bergmann-Castellani gauge generator $G$, a tuned sum of
first class-constraints, changes the canonical Lagrangian by a total derivative
and implements changes of time coordinate for solutions.",http://arxiv.org/abs/2110.15266v2
"Moving sum data segmentation for stochastics processes based on
  invariance",2021-01-12T18:20:42Z,"Claudia Kirch, Philipp Klein","The segmentation of data into stationary stretches also known as multiple
change point problem is important for many applications in time series analysis
as well as signal processing. Based on strong invariance principles, we analyse
data segmentation methodology using moving sum (MOSUM) statistics for a class
of regime-switching multivariate processes where each switch results in a
change in the drift. In particular, this framework includes the data
segmentation of multivariate partial sum, integrated diffusion and renewal
processes even if the distance between change points is sublinear. We study the
asymptotic behaviour of the corresponding change point estimators, show
consistency and derive the corresponding localisation rates which are minimax
optimal in a variety of situations including an unbounded number of changes in
Wiener processes with drift. Furthermore, we derive the limit distribution of
the change point estimators for local changes - a result that can in principle
be used to derive confidence intervals for the change points.",http://arxiv.org/abs/2101.04651v1
"High-dimensional Change-point Detection Using Generalized Homogeneity
  Metrics",2021-05-19T08:13:51Z,"Shubhadeep Chakraborty, Xianyang Zhang","Change-point detection has been a classical problem in statistics and
econometrics. This work focuses on the problem of detecting abrupt
distributional changes in the data-generating distribution of a sequence of
high-dimensional observations, beyond the first two moments. This has remained
a substantially less explored problem in the existing literature, especially in
the high-dimensional context, compared to detecting changes in the mean or the
covariance structure. We develop a nonparametric methodology to (i) detect an
unknown number of change-points in an independent sequence of high-dimensional
observations and (ii) test for the significance of the estimated change-point
locations. Our approach essentially rests upon nonparametric tests for the
homogeneity of two high-dimensional distributions. We construct a single
change-point location estimator via defining a cumulative sum process in an
embedded Hilbert space. As the key theoretical innovation, we rigorously derive
its limiting distribution under the high dimension medium sample size (HDMSS)
framework. Subsequently we combine our statistic with the idea of wild binary
segmentation to recursively estimate and test for multiple change-point
locations. The superior performance of our methodology compared to other
existing procedures is illustrated via extensive simulation studies as well as
over stock prices data observed during the period of the Great Recession in the
United States.",http://arxiv.org/abs/2105.08976v1
"Nonparametric Detection of Multiple Location-Scale Change Points via
  Wild Binary Segmentation",2021-07-04T22:17:14Z,Gordon J. Ross,"While parametric multiple change point detection has been widely studied,
less attention has been given to the nonparametric task of detecting multiple
change points in a sequence of observations when their distribution is unknown.
Most existing work on this topic is either based on penalized cost functions
which can suffer from false positive detections, or on binary segmentation
which can fail to detect certain configurations of change points. We introduce
a new approach to change point detection which adapts the recently proposed
Wild Binary Segmentation (WBS) procedure to a nonparametric setting. Our
approach is based on the use of rank based test statistics which are especially
powerful at detecting changes in location and/or scale. We show via simulation
that the resulting nonparametric WBS procedure has favorable performance
compared to existing methods, particularly when it comes to detecting changes
in scale. We apply our procedure to study a problem in stylometry involving
change points in an author's writing style, and provide a full implementation
of our algorithm in an associated R package.",http://arxiv.org/abs/2107.01742v1
An unsupervised framework for tracing textual sources of moral change,2021-09-01T20:35:33Z,"Aida Ramezani, Zining Zhu, Frank Rudzicz, Yang Xu","Morality plays an important role in social well-being, but people's moral
perception is not stable and changes over time. Recent advances in natural
language processing have shown that text is an effective medium for informing
moral change, but no attempt has been made to quantify the origins of these
changes. We present a novel unsupervised framework for tracing textual sources
of moral change toward entities through time. We characterize moral change with
probabilistic topical distributions and infer the source text that exerts
prominent influence on the moral time course. We evaluate our framework on a
diverse set of data ranging from social media to news articles. We show that
our framework not only captures fine-grained human moral judgments, but also
identifies coherent source topics of moral change triggered by historical
events. We apply our methodology to analyze the news in the COVID-19 pandemic
and demonstrate its utility in identifying sources of moral change in
high-impact and real-time social events.",http://arxiv.org/abs/2109.00608v1
"The Increased Effect of Elections and Changing Prime Ministers on Topics
  Discussed in the Australian Federal Parliament between 1901 and 2018",2021-11-17T18:55:07Z,"Rohan Alexander, Monica Alexander","Politics and discussion in parliament is likely to be influenced by the party
in power and associated election cycles. However, little is known about the
extent to which these events affect discussion and how this has changed over
time. We systematically analyse how discussion in the Australian Federal
Parliament changes in response to two types of political events: elections and
changed prime ministers. We use a newly constructed dataset of what was said in
the Australian Federal Parliament from 1901 through to 2018 based on extracting
and cleaning available public records. We reduce the dimensionality of
discussion in this dataset by using a correlated topic model to obtain a set of
comparable topics over time. We then relate those topics to the Comparative
Agendas Project, and then analyse the effect of these two types of events using
a Bayesian hierarchical Dirichlet model. We find that: changes in prime
minister tend to be associated with topic changes even when the party in power
does not change; and the effect of elections has been increasing since the
1980s, regardless of whether the election results in a change of prime
minister.",http://arxiv.org/abs/2111.09299v1
Likelihood Scores for Sparse Signal and Change-Point Detection,2021-05-15T04:20:01Z,"Shouri Hu, Jingyan Huang, Hao Chen, Hock Peng Chan","We consider here the identification of change-points on large-scale data
streams. The objective is to find the most efficient way of combining
information across data stream so that detection is possible under the smallest
detectable change magnitude. The challenge comes from the sparsity of
change-points when only a small fraction of data streams undergo change at any
point in time. The most successful approach to the sparsity issue so far has
been the application of hard thresholding such that only local scores from data
streams exhibiting significant changes are considered and added. However the
identification of an optimal threshold is a difficult one. In particular it is
unlikely that the same threshold is optimal for different levels of sparsity.
We propose here a sparse likelihood score for identifying a sparse signal. The
score is a likelihood ratio for testing between the null hypothesis of no
change against an alternative hypothesis in which the change-points or signals
are barely detectable. By the Neyman-Pearson Lemma this score has maximum
detection power at the given alternative. The outcome is that we have a scoring
of data streams that is successful in detecting at the boundary of the
detectable region of signals and change-points. The likelihood score can be
seen as a soft thresholding approach to sparse signal and change-point
detection in which local scores that indicate small changes are down-weighted
much more than local scores indicating large changes. We are able to show
second-order optimality of the sparsity likelihood score in the sense of
achieving successful detection at the minimum detectable order of change
magnitude as well as at the minimum detection asymptotic constant with respect
this order of change.",http://arxiv.org/abs/2105.07137v2
Lexical Semantic Change Discovery,2021-06-06T13:02:38Z,"Sinan Kurtyigit, Maike Park, Dominik Schlechtweg, Jonas Kuhn, Sabine Schulte im Walde","While there is a large amount of research in the field of Lexical Semantic
Change Detection, only few approaches go beyond a standard benchmark evaluation
of existing models. In this paper, we propose a shift of focus from change
detection to change discovery, i.e., discovering novel word senses over time
from the full corpus vocabulary. By heavily fine-tuning a type-based and a
token-based approach on recently published German data, we demonstrate that
both models can successfully be applied to discover new words undergoing
meaning change. Furthermore, we provide an almost fully automated framework for
both evaluation and discovery.",http://arxiv.org/abs/2106.03111v1
"Sign changes of cusp form coefficients on indices that are sums of two
  squares",2021-08-27T22:43:58Z,David Lowry-Duda,"We study sign changes in the sequence $\{ A(n) : n = c^2 + d^2 \}$, where
$A(n)$ are the coefficients of a holomorphic cuspidal Hecke eigenform. After
proving a variant of an axiomatization for detecting and quantifying sign
changes introduced by Meher and Murty, we show that there are at least
$X^{\frac{1}{4} - \epsilon}$ sign changes in each interval $[X, 2X]$ for $X \gg
1$. This improves to $X^{\frac{1}{2} - \epsilon}$ many sign changes assuming
the Generalized Lindel\""{o}f Hypothesis.",http://arxiv.org/abs/2108.12520v1
Graph-based multiple change-point detection,2021-10-04T03:33:21Z,"Yuxuan Zhang, Hao Chen","We propose a new multiple change-point detection framework for multivariate
and non-Euclidean data. First, we combine graph-based statistics with wild
binary segmentation or seeded binary segmentation to search for a pool of
candidate change-points. We then prune the candidate change-points through a
novel goodness-of-fit statistic. Numerical studies show that this new framework
outperforms existing methods under a wide range of settings. The resulting
change-points can further be arranged hierarchically based on the
goodness-of-fit statistic. The new framework is illustrated on a Neuropixels
recording of an awake mouse.",http://arxiv.org/abs/2110.01170v1
Changes in the near-surface shear layer of the Sun,2021-10-26T18:35:11Z,"H. M. Antia, Sarbani Basu","We use helioseismic data obtained over two solar cycles to determine whether
there are changes in the near-surface shear layer (NSSL). We examine this by
determining the radial gradient of the solar rotation rate. The radial gradient
itself shows a solar-cycle dependence, and the changes are more pronounced in
the active latitudes than at adjoining higher latitudes; results at the highest
latitudes (greater than about70 degrees) are unreliable. The pattern changes
with depth, even within the NSSL. We find that the near-surface shear layer is
deeper at lower latitudes than at high latitudes and that the extent of the
layer also shows a small solar-cycle related change.",http://arxiv.org/abs/2110.13952v1
"Max-Type and Sum-Type Procedures for Online Change-Point Detection in
  the Mean of High-Dimensional Data",2021-07-26T02:49:27Z,Jun Li,"We propose two procedures to detect a change in the mean of high-dimensional
online data. One is based on a max-type U-statistic and another is based on a
sum-type U-statistic. Theoretical properties of the two procedures are explored
in the high dimensional setting. More precisely, we derive their average run
lengths (ARLs) when there is no change point, and expected detection delays
(EDDs) when there is a change point. Accuracy of the theoretical results is
confirmed by simulation studies. The practical use of the proposed procedures
is demonstrated by detecting an abrupt change in PM2.5 concentrations. The
current study attempts to extend the results of the CUSUM and Shiryayev-Roberts
procedures previously established in the univariate setting.",http://arxiv.org/abs/2107.11931v1
"A priori estimates for finite-energy sign-changing blowing-up solutions
  of critical elliptic equations",2021-11-03T18:47:07Z,Bruno Premoselli,"We prove sharp pointwise blow-up estimates for finite-energy sign-changing
solutions of critical equations of Schr\""odinger-Yamabe type on a closed
Riemannian manifold $(M,g)$ of dimension $n \ge 3$. This is a generalisation of
the so-called $C^0$-theory for positive solutions of Schr\""odinger-Yamabe type
equations. To deal with the sign-changing case we develop a method of proof
that combines an \emph{a priori} bubble-tree analysis with a finite-dimensional
reduction, and reduces the proof to obtaining sharp \emph{a priori} blow-up
estimates for a linear problem.",http://arxiv.org/abs/2111.02470v2
"Sequential Change Detection through Empirical Distribution and Universal
  Codes",2021-12-14T16:56:47Z,"Vikrant Malik, R. K. Bansal","Universal compression algorithms have been studied in the past for sequential
change detection, where they have been used to estimate the post-change
distribution in the modified version of the Cumulative Sum (CUSUM) Test. In
this paper, we introduce a modified CUSUM test where the pre-change
distribution is also unknown and an empirical version of the pre-change
distribution is used to implement the algorithm. We present a study of various
characteristics of this modified CUSUM Test and then prove its asymptotic
optimality.",http://arxiv.org/abs/2112.07549v1
"Jenss-Bayley Latent Change Score Model with Individual Ratio of Growth
  Acceleration in the Framework of Individual Measurement Occasions",2021-02-27T18:38:16Z,Jin Liu,"Longitudinal data analysis has been widely employed to examine
between-individual differences in within-individual changes. One challenge of
such analyses is that the rate-of-change is only available indirectly when
change patterns are nonlinear with respect to time. Latent change score models
(LCSMs), which can be employed to investigate the change in rate-of-change at
the individual level, have been developed to address this challenge. We extend
an existing LCSM with the Jenss-Bayley growth curve
\cite[Chapter~18]{Grimm2016growth} and propose a novel expression for change
scores that allows for (1) unequally-spaced study waves and (2) individual
measurement occasions around each wave. We also extend the existing model to
estimate the individual ratio of the growth acceleration (that largely
determines the trajectory shape and is viewed as the most important parameter
in the Jenss-Bayley model). We present the proposed model by a simulation study
and a real-world data analysis. Our simulation study demonstrates that the
proposed model can estimate the parameters unbiasedly and precisely and exhibit
target confidence interval coverage. The simulation study also shows that the
proposed model with the novel expression for the change scores outperforms the
existing model. An empirical example using longitudinal reading scores shows
that the model can estimate the individual ratio of the growth acceleration and
generate individual rate-of-change in practice. We also provide the
corresponding code for the proposed model.",http://arxiv.org/abs/2103.00290v3
Self-supervised Change Detection in Multi-view Remote Sensing Images,2021-03-10T09:56:09Z,"Yuxing Chen, Lorenzo Bruzzone","The vast amount of unlabeled multi-temporal and multi-sensor remote sensing
data acquired by the many Earth Observation satellites present a challenge for
change detection. Recently, many generative model-based methods have been
proposed for remote sensing image change detection on such unlabeled data.
However, the high diversities in the learned features weaken the discrimination
of the relevant change indicators in unsupervised change detection tasks.
Moreover, these methods lack research on massive archived images. In this work,
a self-supervised change detection approach based on an unlabeled multi-view
setting is proposed to overcome this limitation. This is achieved by the use of
a multi-view contrastive loss and an implicit contrastive strategy in the
feature alignment between multi-view images. In this approach, a pseudo-Siamese
network is trained to regress the output between its two branches pre-trained
in a contrastive way on a large dataset of multi-temporal homogeneous or
heterogeneous image patches. Finally, the feature distance between the outputs
of the two branches is used to define a change measure, which can be analyzed
by thresholding to get the final binary change map. Experiments are carried out
on five homogeneous and heterogeneous remote sensing image datasets. The
proposed SSL approach is compared with other supervised and unsupervised
state-of-the-art change detection methods. Results demonstrate both
improvements over state-of-the-art unsupervised methods and that the proposed
SSL approach narrows the gap between unsupervised and supervised change
detection.",http://arxiv.org/abs/2103.05969v1
"A volumetric change detection framework using UAV oblique photogrammetry
  - A case study of ultra-high-resolution monitoring of progressive building
  collapse",2021-08-05T18:20:29Z,"Ningli Xu, Debao Huang, Shuang Song, Xiao Ling, Chris Strasbaugh, Alper Yilmaz, Halil Sezen, Rongjun Qin","In this paper, we present a case study that performs an unmanned aerial
vehicle (UAV) based fine-scale 3D change detection and monitoring of
progressive collapse performance of a building during a demolition event.
Multi-temporal oblique photogrammetry images are collected with 3D point clouds
generated at different stages of the demolition. The geometric accuracy of the
generated point clouds has been evaluated against both airborne and terrestrial
LiDAR point clouds, achieving an average distance of 12 cm and 16 cm for roof
and facade respectively. We propose a hierarchical volumetric change detection
framework that unifies multi-temporal UAV images for pose estimation (free of
ground control points), reconstruction, and a coarse-to-fine 3D density change
analysis. This work has provided a solution capable of addressing change
detection on full 3D time-series datasets where dramatic scene content changes
are presented progressively. Our change detection results on the building
demolition event have been evaluated against the manually marked ground-truth
changes and have achieved an F-1 score varying from 0.78 to 0.92, with
consistently high precision (0.92 - 0.99). Volumetric changes through the
demolition progress are derived from change detection and have shown to
favorably reflect the qualitative and quantitative building demolition
progression.",http://arxiv.org/abs/2108.02800v1
"Using Trajectory Compression Rate to Predict Changes in Cybersickness in
  Virtual Reality Games",2021-08-21T16:26:04Z,"Diego Monteiro, Hai-Ning Liang, Xiaohang Tang, Pourang Irani","Identifying cybersickness in virtual reality (VR) applications such as games
in a fast, precise, non-intrusive, and non-disruptive way remains challenging.
Several factors can cause cybersickness, and their identification will help
find its origins and prevent or minimize it. One such factor is virtual
movement. Movement, whether physical or virtual, can be represented in
different forms. One way to represent and store it is with a temporally
annotated point sequence. Because a sequence is memory-consuming, it is often
preferable to save it in a compressed form. Compression allows redundant data
to be eliminated while still preserving changes in speed and direction. Since
changes in direction and velocity in VR can be associated with cybersickness,
changes in compression rate can likely indicate changes in cybersickness
levels. In this research, we explore whether quantifying changes in virtual
movement can be used to estimate variation in cybersickness levels of VR users.
We investigate the correlation between changes in the compression rate of
movement data in two VR games with changes in players' cybersickness levels
captured during gameplay. Our results show (1) a clear correlation between
changes in compression rate and cybersickness, and(2) that a machine learning
approach can be used to identify these changes. Finally, results from a second
experiment show that our approach is feasible for cybersickness inference in
games and other VR applications that involve movement.",http://arxiv.org/abs/2108.09538v1
Quickest Change Detection with Non-Stationary Post-Change Observations,2021-10-04T17:25:01Z,"Yuchen Liang, Alexander G. Tartakovsky, Venugopal V. Veeravalli","The problem of quickest detection of a change in the distribution of a
sequence of independent observations is considered. The pre-change observations
are assumed to be stationary with a known distribution, while the post-change
observations are allowed to be non-stationary with some possible parametric
uncertainty in their distribution. In particular, it is assumed that the
cumulative Kullback-Leibler divergence between the post-change and the
pre-change distributions grows in a certain manner with time after the
change-point. For the case where the post-change distributions are known, a
universal asymptotic lower bound on the delay is derived, as the false alarm
rate goes to zero. Furthermore, a window-limited Cumulative Sum (CuSum)
procedure is developed, and shown to achieve the lower bound asymptotically.
For the case where the post-change distributions have parametric uncertainty, a
window-limited (WL) generalized likelihood-ratio (GLR) CuSum procedure is
developed and is shown to achieve the universal lower bound asymptotically.
Extensions to the case with dependent observations are discussed. The analysis
is validated through numerical results on synthetic data. The use of the
WL-GLR-CuSum procedure in monitoring pandemics is also demonstrated.",http://arxiv.org/abs/2110.01581v3
Cross-validation for change-point regression: pitfalls and solutions,2021-12-06T18:23:12Z,"Florian Pein, Rajen D. Shah","Cross-validation is the standard approach for tuning parameter selection in
many non-parametric regression problems. However its use is less common in
change-point regression, perhaps as its prediction error-based criterion may
appear to permit small spurious changes and hence be less well-suited to
estimation of the number and location of change-points. We show that in fact
the problems of cross-validation with squared error loss are more severe and
can lead to systematic under- or over-estimation of the number of
change-points, and highly suboptimal estimation of the mean function in simple
settings where changes are easily detectable. We propose two simple approaches
to remedy these issues, the first involving the use of absolute error rather
than squared error loss, and the second involving modifying the holdout sets
used. For the latter, we provide conditions that permit consistent estimation
of the number of change-points for a general change-point estimation procedure.
We show these conditions are satisfied for least squares estimation using new
results on its performance when supplied with the incorrect number of
change-points. Numerical experiments show that our new approaches are
competitive with common change-point methods using classical tuning parameter
choices when error distributions are well-specified, but can substantially
outperform these in misspecified models. An implementation of our methodology
is available in the R package crossvalidationCP on CRAN.",http://arxiv.org/abs/2112.03220v3
"A change-point detection method for detecting and locating the abrupt
  changes in distributions of damage-sensitive features of SHM data, with
  application to structural condition assessment",2021-11-16T07:03:22Z,"Xinyi Lei, Zhicheng Chen, Hui Li, Shiyin Wei","Diagnosing the changes of structural behaviors using monitoring data is an
important objective of structural health monitoring (SHM). The changes in
structural behaviors are usually manifested as the feature changes in monitored
structural responses; thus, developing effective methods for automatically
detecting such changes is of considerable significance. Existing methods for
change detection in SHM are mainly used for scalar or vector data, thus
incapable of detecting the changes of the features represented by complex data,
e.g., the probability density functions (PDFs). Detecting the abrupt changes
occurred in the distributions (represented by PDFs) associated with the
damage-sensitive features extracted from SHM data are usually of crucial
interest for structural condition assessment; however, the SHM community still
lacks effective diagnostic tools for detecting such changes. In this study, a
change-point detection method is developed in the functional data-analytic
framework for PDF-valued sequence, and it is leveraged to diagnose the
distributional information break encountered in structural condition
assessment. A major challenge in PDF-valued data modeling or analysis is that
the PDFs are special functional data subjecting to nonlinear constraints. To
tackle this issue, the PDFs are embedded into the Bayes space, and the
associated change-point model is constructed by using the linear structure of
the Bayes space; then, a hypothesis testing procedure is presented for
distributional change-point detection based on the isomorphic mapping between
the Bayes space and a functional linear space. Comprehensive simulation studies
are conducted to validate the effectiveness of the proposed method as well as
demonstrate its superiority over the competing method. Finally, an application
to real SHM data illustrates its practical utility in structural condition
assessment.",http://arxiv.org/abs/2111.08260v2
Weighted-Graph-Based Change Point Detection,2021-03-03T21:03:32Z,"Lizhen Nie, Dan L. Nicolae","We consider the detection and localization of change points in the
distribution of an offline sequence of observations. Based on a nonparametric
framework that uses a similarity graph among observations, we propose new test
statistics when at most one change point occurs and generalize them to multiple
change points settings. The proposed statistics leverage edge weight
information in the graphs, exhibiting substantial improvements in testing power
and localization accuracy in simulations. We derive the null limiting
distribution, provide accurate analytic approximations to control type I error,
and establish theoretical guarantees on the power consistency under contiguous
alternatives for the one change point setting, as well as the minimax
localization rate. In the multiple change points setting, the asymptotic
correctness of the number and location of change points are also guaranteed.
The methods are illustrated on the MIT proximity network data.",http://arxiv.org/abs/2103.02680v1
"Evidence of solar-cycle related structural changes in the solar
  convection zone",2021-06-15T19:26:21Z,Sarbani Basu,"While it has been relatively easy to determine solar-cycle related changes in
solar dynamics, determining changes in structure in the deeper layers of the
Sun has proved to be difficult. By using helioseismic data obtained over two
solar cycles, and sacrificing resolution in favour of lower uncertainties, we
show that there are significant changes in the solar convection zone, and
perhaps even below it. Using MDI data, we find a relative squared sound-speed
difference of $(2.56\pm 0.71)\times 10^{-5}$ at the convection-zone base
between the maximum of solar Cycle~23 and the minimum between Cycles~23 and 24.
The squared sound-speed difference for the maximum of Cycle~24 obtained with
HMI data is $(1.95\pm 0.69)\times 10^{-5}$. GONG data support these results. We
also find that the sound speed in the solar convection zone decreases compared
to the sound speed below it as the Sun becomes more active. We find evidence of
changes in the radial derivative of the sound-speed difference between the
solar minimum and other epochs at the base of the convection zone implying
possible small changes in the position of the convection-zone base, however,
the results are too noisy to make any definitive estimates of the change.",http://arxiv.org/abs/2106.08383v1
Change Detection for Geodatabase Updating,2021-06-27T18:35:10Z,Rongjun Qin,"The geodatabase (vectorized data) nowadays becomes a rather standard digital
city infrastructure; however, updating geodatabase efficiently and economically
remains a fundamental and practical issue in the geospatial industry. The cost
of building a geodatabase is extremely high and labor intensive, and very often
the maps we use have several months and even years of latency. One solution is
to develop more automated methods for (vectorized) geospatial data generation,
which has been proven a difficult task in the past decades. An alternative
solution is to first detect the differences between the new data and the
existing geospatial data, and then only update the area identified as changes.
The second approach is becoming more favored due to its high practicality and
flexibility. A highly relevant technique is change detection. This article aims
to provide an overview the state-of-the-art change detection methods in the
field of Remote Sensing and Geomatics to support the task of updating
geodatabases. Data used for change detection are highly disparate, we therefore
structure our review intuitively based on the dimension of the data, being 1)
change detection with 2D data; 2) change detection with 3D data. Conclusions
will be drawn based on the reviewed efforts in the field, and we will share our
outlooks of the topic of updating geodatabases.",http://arxiv.org/abs/2106.14309v1
"Change is Everywhere: Single-Temporal Supervised Object Change Detection
  in Remote Sensing Imagery",2021-08-16T10:25:15Z,"Zhuo Zheng, Ailong Ma, Liangpei Zhang, Yanfei Zhong","For high spatial resolution (HSR) remote sensing images, bitemporal
supervised learning always dominates change detection using many pairwise
labeled bitemporal images. However, it is very expensive and time-consuming to
pairwise label large-scale bitemporal HSR remote sensing images. In this paper,
we propose single-temporal supervised learning (STAR) for change detection from
a new perspective of exploiting object changes in unpaired images as
supervisory signals. STAR enables us to train a high-accuracy change detector
only using \textbf{unpaired} labeled images and generalize to real-world
bitemporal images. To evaluate the effectiveness of STAR, we design a simple
yet effective change detector called ChangeStar, which can reuse any deep
semantic segmentation architecture by the ChangeMixin module. The comprehensive
experimental results show that ChangeStar outperforms the baseline with a large
margin under single-temporal supervision and achieves superior performance
under bitemporal supervision. Code is available at
https://github.com/Z-Zheng/ChangeStar",http://arxiv.org/abs/2108.07002v3
"RefactorInsight: Enhancing IDE Representation of Changes in Git with
  Refactorings Information",2021-08-25T12:31:44Z,"Zarina Kurbatova, Vladimir Kovalenko, Ioana Savu, Bob Brockbernd, Dan Andreescu, Matei Anton, Roman Venediktov, Elena Tikhomirova, Timofey Bryksin","Inspection of code changes is a time-consuming task that constitutes a big
part of everyday work of software engineers. Existing IDEs provide little
information about the semantics of code changes within the file editor view.
Therefore developers have to track changes across multiple files, which is a
hard task with large codebases.
  In this paper, we present RefactorInsight, a plugin for IntelliJ IDEA that
introduces a smart diff for code changes in Java and Kotlin where refactorings
are auto-folded and provided with their description, thus allowing users to
focus on changes that modify the code behavior like bug fixes and new features.
RefactorInsight supports three usage scenarios: viewing smart diffs with
auto-folded refactorings and hints, inspecting refactorings in pull requests
and in any specific commit in the project change history, and exploring the
refactoring history of methods and classes. The evaluation shows that commit
processing time is acceptable: on median it is less than 0.2 seconds, which
delay does not disrupt developers' IDE workflows.
  RefactorInsight is available at
https://github.com/JetBrains-Research/RefactorInsight. The demonstration video
is available at https://youtu.be/-6L2AKQ66nA.",http://arxiv.org/abs/2108.11202v1
"Estimating the Level and Direction of Phonetic Dialect Change in the
  Northern Netherlands",2021-10-15T08:00:20Z,"Raoul Buurke, Hedwig Sekeres, Wilbert Heeringa, Remco Knooihuizen, Martijn Wieling","This article reports ongoing investigations into phonetic change of dialect
groups in the northern Netherlandic language area, particularly the Frisian and
Low Saxon dialect groups, which are known to differ in vitality. To achieve
this, we combine existing phonetically transcribed corpora with dialectometric
approaches that allow us to quantify change among older male dialect speakers
in a real-time framework. A multidimensional variant of the Levenshtein
distance, combined with methods that induce realistic phonetic distances
between transcriptions, is used to estimate how much dialect groups have
changed between 1990 and 2010, and whether they changed towards Standard Dutch
or away from it. Our analyses indicate that language change is a slow process
in this geographical area. Moreover, the Frisian and Groningen dialect groups
seem to be most stable, while the other Low Saxon varieties (excluding the
Groningen dialect group) were shown to be most prone to change. We offer
possible explanations for our findings, while we discuss shortcomings of the
data and approach in detail, as well as desiderata for future research.",http://arxiv.org/abs/2110.07918v1
"Dynamic Preference Logic meets Iterated Belief Change: Representation
  Results and Postulates Characterization",2021-01-05T17:47:18Z,"Marlo Souza, Álvaro Moreira, Renata Vieira","AGM's belief revision is one of the main paradigms in the study of belief
change operations. Recently, several logics for belief and information change
have been proposed in the literature and used to encode belief change
operations in rich and expressive semantic frameworks. While the connections of
AGM-like operations and their encoding in dynamic doxastic logics have been
studied before by the work of Segerberg, most works on the area of Dynamic
Epistemic Logics (DEL) have not, to our knowledge, attempted to use those
logics as tools to investigate mathematical properties of belief change
operators. This work investigates how Dynamic Preference Logic, a logic in the
DEL family, can be used to study properties of dynamic belief change operators,
focusing on well-known postulates of iterated belief change.",http://arxiv.org/abs/2101.01676v1
Why did the distribution change?,2021-02-26T10:22:59Z,"Kailash Budhathoki, Dominik Janzing, Patrick Bloebaum, Hoiyi Ng","We describe a formal approach based on graphical causal models to identify
the ""root causes"" of the change in the probability distribution of variables.
After factorizing the joint distribution into conditional distributions of each
variable, given its parents (the ""causal mechanisms""), we attribute the change
to changes of these causal mechanisms. This attribution analysis accounts for
the fact that mechanisms often change independently and sometimes only some of
them change. Through simulations, we study the performance of our distribution
change attribution method. We then present a real-world case study identifying
the drivers of the difference in the income distribution between men and women.",http://arxiv.org/abs/2102.13384v2
"Modeling the dynamics of language change: logistic regression,
  Piotrowski's law, and a handful of examples in Polish",2021-04-13T16:03:36Z,"Rafał L. Górski, Maciej Eder","The study discusses modeling diachronic processes by logistic regression. The
phenomenon of nonlinear changes in language was first observed by Raimund
Piotrowski (hence labelled as Piotrowski's law), even if actual linguistic
evidence usually speaks against using the notion of a ""law"" in this context. In
our study, we apply logistic regression models to 9 changes which occurred
between 15th and 18th century in the Polish language. The attested course of
the majority of these changes closely follow the expected values, which proves
that the language change might indeed resemble a nonlinear phase change
scenario. We also extend the original Piotrowski's approach by proposing
polynomial logistic regression for these cases which can hardly be described by
its standard version. Also, we propose to consider individual language change
cases jointly, in order to inspect their possible collinearity or, more likely,
their different dynamics in the function of time. Last but not least, we
evaluate our results by testing the influence of the subcorpus size on the
model's goodness-of-fit.",http://arxiv.org/abs/2104.06324v3
How individuals change language,2021-04-20T19:02:49Z,"Richard A Blythe, William Croft","Languages emerge and change over time at the population level though
interactions between individual speakers. It is, however, hard to directly
observe how a single speaker's linguistic innovation precipitates a
population-wide change in the language, and many theoretical proposals exist.
We introduce a very general mathematical model that encompasses a wide variety
of individual-level linguistic behaviours and provides statistical predictions
for the population-level changes that result from them. This model allows us to
compare the likelihood of empirically-attested changes in definite and
indefinite articles in multiple languages under different assumptions on the
way in which individuals learn and use language. We find that accounts of
language change that appeal primarily to errors in childhood language
acquisition are very weakly supported by the historical data, whereas those
that allow speakers to change incrementally across the lifespan are more
plausible, particularly when combined with social network effects.",http://arxiv.org/abs/2104.10210v1
Locally private online change point detection,2021-05-22T10:03:54Z,"Thomas Berrett, Yi Yu","We study online change point detection problems under the constraint of local
differential privacy (LDP) where, in particular, the statistician does not have
access to the raw data. As a concrete problem, we study a multivariate
nonparametric regression problem. At each time point $t$, the raw data are
assumed to be of the form $(X_t, Y_t)$, where $X_t$ is a $d$-dimensional
feature vector and $Y_t$ is a response variable. Our primary aim is to detect
changes in the regression function $m_t(x)=\mathbb{E}(Y_t |X_t=x)$ as soon as
the change occurs. We provide algorithms which respect the LDP constraint,
which control the false alarm probability, and which detect changes with a
minimal (minimax rate-optimal) delay. To quantify the cost of privacy, we also
present the optimal rate in the benchmark, non-private setting. These
non-private results are also new to the literature and thus are interesting
\emph{per se}. In addition, we study the univariate mean online change point
detection problem, under privacy constraints. This serves as the blueprint of
studying more complicated private change point detection problems.",http://arxiv.org/abs/2105.10675v2
Persistence of Conley-Morse Graphs in Combinatorial Dynamical Systems,2021-07-05T16:12:59Z,"Tamal K. Dey, Marian Mrozek, Ryan Slechta","Multivector fields provide an avenue for studying continuous dynamical
systems in a combinatorial framework. There are currently two approaches in the
literature which use persistent homology to capture changes in combinatorial
dynamical systems. The first captures changes in the Conley index, while the
second captures changes in the Morse decomposition. However, such approaches
have limitations. The former approach only describes how the Conley index
changes across a selected isolated invariant set though the dynamics can be
much more complicated than the behavior of a single isolated invariant set.
Likewise, considering a Morse decomposition omits much information about the
individual Morse sets. In this paper, we propose a method to summarize changes
in combinatorial dynamical systems by capturing changes in the so-called
Conley-Morse graphs. A Conley-Morse graph contains information about both the
structure of a selected Morse decomposition and about the Conley index at each
Morse set in the decomposition. Hence, our method summarizes the changing
structure of a sequence of dynamical systems at a finer granularity than
previous approaches.",http://arxiv.org/abs/2107.02115v2
Finite-time Analysis of Globally Nonstationary Multi-Armed Bandits,2021-07-23T19:02:52Z,"Junpei Komiyama, Edouard Fouché, Junya Honda","We consider nonstationary multi-armed bandit problems where the model
parameters of the arms change over time. We introduce the adaptive resetting
bandit (ADR-bandit), a bandit algorithm class that leverages adaptive windowing
techniques from literature on data streams. We first provide new guarantees on
the quality of estimators resulting from adaptive windowing techniques, which
are of independent interest. Furthermore, we conduct a finite-time analysis of
ADR-bandit in two typical environments: an abrupt environment where changes
occur instantaneously and a gradual environment where changes occur
progressively. We demonstrate that ADR-bandit has nearly optimal performance
when abrupt or gradual changes occur in a coordinated manner that we call
global changes. We demonstrate that forced exploration is unnecessary when we
assume such global changes. Unlike the existing nonstationary bandit
algorithms, ADR-bandit has optimal performance in stationary environments as
well as nonstationary environments with global changes. Our experiments show
that the proposed algorithms outperform the existing approaches in synthetic
and real-world environments.",http://arxiv.org/abs/2107.11419v2
"Impact of individual behavioral changes on epidemic spreading in
  time-varying networks",2021-06-22T02:26:45Z,"Bing Wang, Zeyang Xie, Yuexing Han","Changs in individual behavior often entangles with the dynamic interaction of
individuals, which complicates the epidemic process and brings great challenges
for the understanding and control of the epidemic. In this work, we consider
three kinds of typical behavioral changes in epidemic process that is,
self-quarantine of infected individuals, self-protection of susceptible
individuals, and social distancing between them. We connect the behavioral
changes with individual's social attributes by the activity-driven network with
attractiveness. A mean-field theory is established to derive an analytical
estimate of epidemic threshold for SIS models with individual behavioral
changes, which depends on the correlations between activity, attractiveness and
the number of generative links in the susceptible and infected states. We find
that individual behaviors play different roles in suppressing the epidemic.
Although all the behavioral changes could delay the epidemic by increasing the
epidemic threshold, self-quarantine and social distancing of infected
individuals could effectively decrease the epidemic size. In addition,
simultaneous changes in these behaviors and the timing of implement of them
also play a key role in suppressing the epidemic. These results provide helpful
significance for understanding the interaction of individual behaviors in the
epidemic process.",http://arxiv.org/abs/2107.14143v1
"Internal reverse-biased p-n junctions: a possible origin of the high
  resistance in phase change superlattice",2021-09-14T00:37:09Z,"Bowen Li, Longlong Xu, Yuzheng Guo, Huanglong Li","Phase change superlattice is one of the emerging material technologies for
ultralow-power phase change memories. However, the resistance switching
mechanism of phase change superlattice is still hotly debated. Early electrical
measurements and recent materials characterizations have suggested that the
Kooi phase is very likely to be the as-fabricated low-resistance state. Due to
the difficulty in in-situ characterization at atomic resolution, the structure
of the electrically switched superlattice in its high-resistance state is still
unknown and mainly investigated by theoretical modellings. So far, there has
been no simple model that can unify experimental results obtained from
device-level electrical measurements and atomic-level materials
characterizations. In this work, we carry out atomistic transport modellings of
the phase change superlattice device and propose a simple mechanism accounting
for its high resistance. The modeled high-resistance state is based on the
interfacial phase changed superlattice that has previously been mistaken for
the low-resistance state. This work advances the understanding of phase change
superlattice for emerging memory applications.",http://arxiv.org/abs/2109.06376v1
"Multiple Change Point Detection in Reduced Rank High Dimensional Vector
  Autoregressive Models",2021-09-30T01:16:20Z,"Peiliang Bai, Abolfazl Safikhani, George Michailidis","We study the problem of detecting and locating change points in
high-dimensional Vector Autoregressive (VAR) models, whose transition matrices
exhibit low rank plus sparse structure. We first address the problem of
detecting a single change point using an exhaustive search algorithm and
establish a finite sample error bound for its accuracy. Next, we extend the
results to the case of multiple change points that can grow as a function of
the sample size. Their detection is based on a two-step algorithm, wherein the
first step, an exhaustive search for a candidate change point is employed for
overlapping windows, and subsequently, a backward elimination procedure is used
to screen out redundant candidates. The two-step strategy yields consistent
estimates of the number and the locations of the change points. To reduce
computation cost, we also investigate conditions under which a surrogate VAR
model with a weakly sparse transition matrix can accurately estimate the change
points and their locations for data generated by the original model. This work
also addresses and resolves a number of novel technical challenges posed by the
nature of the VAR models under consideration. The effectiveness of the proposed
algorithms and methodology is illustrated on both synthetic and two real data
sets.",http://arxiv.org/abs/2109.14783v1
"Analyzing Behavioral Changes of Twitter Users After Exposure to
  Misinformation",2021-11-01T04:48:07Z,"Yichen Wang, Richard Han, Tamara Lehman, Qin Lv, Shivakant Mishra","Social media platforms have been exploited to disseminate misinformation in
recent years. The widespread online misinformation has been shown to affect
users' beliefs and is connected to social impact such as polarization. In this
work, we focus on misinformation's impact on specific user behavior and aim to
understand whether general Twitter users changed their behavior after being
exposed to misinformation. We compare the before and after behavior of exposed
users to determine whether the frequency of the tweets they posted, or the
sentiment of their tweets underwent any significant change. Our results
indicate that users overall exhibited statistically significant changes in
behavior across some of these metrics. Through language distance analysis, we
show that exposed users were already different from baseline users before the
exposure. We also study the characteristics of two specific user groups,
multi-exposure and extreme change groups, which were potentially highly
impacted. Finally, we study if the changes in the behavior of the users after
exposure to misinformation tweets vary based on the number of their followers
or the number of followers of the tweet authors, and find that their behavioral
changes are all similar.",http://arxiv.org/abs/2111.00700v1
"Bi-Temporal Semantic Reasoning for the Semantic Change Detection in HR
  Remote Sensing Images",2021-08-13T07:28:09Z,"Lei Ding, Haitao Guo, Sicong Liu, Lichao Mou, Jing Zhang, Lorenzo Bruzzone","Semantic change detection (SCD) extends the multi-class change detection
(MCD) task to provide not only the change locations but also the detailed
land-cover/land-use (LCLU) categories before and after the observation
intervals. This fine-grained semantic change information is very useful in many
applications. Recent studies indicate that the SCD can be modeled through a
triple-branch Convolutional Neural Network (CNN), which contains two temporal
branches and a change branch. However, in this architecture, the communications
between the temporal branches and the change branch are insufficient. To
overcome the limitations in existing methods, we propose a novel CNN
architecture for the SCD, where the semantic temporal features are merged in a
deep CD unit. Furthermore, we elaborate on this architecture to reason the
bi-temporal semantic correlations. The resulting Bi-temporal Semantic Reasoning
Network (Bi-SRNet) contains two types of semantic reasoning blocks to reason
both single-temporal and cross-temporal semantic correlations, as well as a
novel loss function to improve the semantic consistency of change detection
results. Experimental results on a benchmark dataset show that the proposed
architecture obtains significant accuracy improvements over the existing
approaches, while the added designs in the Bi-SRNet further improves the
segmentation of both semantic categories and the changed areas. The codes in
this paper are accessible at: github.com/ggsDing/Bi-SRNet.",http://arxiv.org/abs/2108.06103v4
Deep few-shot learning for bi-temporal building change detection,2021-08-25T14:38:21Z,"Mehdi Khoshboresh-Masouleh, Reza Shah-Hosseini","In real-world applications (e.g., change detection), annotating images is
very expensive. To build effective deep learning models in these applications,
deep few-shot learning methods have been developed and prove to be a robust
approach in small training data. The analysis of building change detection from
high spatial resolution remote sensing observations is important research in
photogrammetry, computer vision, and remote sensing nowadays, which can be
widely used in a variety of real-world applications, such as map updating. As
manual high resolution image interpretation is expensive and time-consuming,
building change detection methods are of high interest. The interest in
developing building change detection approaches from optical remote sensing
images is rapidly increasing due to larger coverages, and lower costs of
optical images. In this study, we focus on building change detection analysis
on a small set of building change from different regions that sit in several
cities. In this paper, a new deep few-shot learning method is proposed for
building change detection using Monte Carlo dropout and remote sensing
observations. The setup is based on a small dataset, including bitemporal
optical images labeled for building change detection.",http://arxiv.org/abs/2108.11262v2
"A systematic search for changing-look quasars in SDSS-II using
  difference spectra",2021-04-29T09:21:52Z,"B. Potts, C. Villforth","""Changing-look quasars"" (CLQs) are active galactic nuclei (AGN) showing
extreme variability that results in a transition from Type 1 to Type 2. The
short timescales of these transitions present a challenge to the unified model
of AGN and the physical processes causing these transitions remain poorly
understood. CLQs also provide interesting samples for the study of AGN host
galaxies since the central emission disappears almost entirely. Previous
searches for CLQs have utilised photometric variability or SDSS classification
changes to systematically identify CLQs, this approach may miss lower
luminosity CLQs. In this paper, we aim to use spectroscopic data to asses if
analysis difference spectra can be used to detect further changing look quasars
missed by photometric searches. We search SDSS-II DR 7 repeat spectra for
sources that exhibit either a disappearance or appearance of both broad line
emission and accretion disk continuum emission by directly analysing the
difference spectrum between two epochs of observation. From a sample of 24,782
objects with difference spectra, our search yielded six CLQs within the
redshift range $0.1 \leq z \leq 0.3$, including four newly identified sources.
Spectral analysis indicates that changes in accretion rate can explain the
changing-look behaviour. While a change in dust extinction fits the changes in
spectral shape, the time-scales of the changes observed are too short for
obscuration from torus clouds. Using difference spectra was shown to be an
effective and sensitive way to detect CLQs. We recover CLQs an order of
magnitude lower in luminosities than those found by photometric searches and
achieve higher completeness than spectroscopic searches relying on pipeline
classification.",http://arxiv.org/abs/2104.14225v1
"S2Looking: A Satellite Side-Looking Dataset for Building Change
  Detection",2021-07-20T03:31:00Z,"Li Shen, Yao Lu, Hao Chen, Hao Wei, Donghai Xie, Jiabao Yue, Rui Chen, Shouye Lv, Bitao Jiang","Building-change detection underpins many important applications, especially
in the military and crisis-management domains. Recent methods used for change
detection have shifted towards deep learning, which depends on the quality of
its training data. The assembly of large-scale annotated satellite imagery
datasets is therefore essential for global building-change surveillance.
Existing datasets almost exclusively offer near-nadir viewing angles. This
limits the range of changes that can be detected. By offering larger
observation ranges, the scroll imaging mode of optical satellites presents an
opportunity to overcome this restriction. This paper therefore introduces
S2Looking, a building-change-detection dataset that contains large-scale
side-looking satellite images captured at various off-nadir angles. The dataset
consists of 5000 bitemporal image pairs of rural areas and more than 65,920
annotated instances of changes throughout the world. The dataset can be used to
train deep-learning-based change-detection algorithms. It expands upon existing
datasets by providing (1) larger viewing angles; (2) large illumination
variances; and (3) the added complexity of rural images. To facilitate {the}
use of the dataset, a benchmark task has been established, and preliminary
tests suggest that deep-learning algorithms find the dataset significantly more
challenging than the closest-competing near-nadir dataset, LEVIR-CD+. S2Looking
may therefore promote important advances in existing building-change-detection
algorithms. The dataset is available at https://github.com/S2Looking/.",http://arxiv.org/abs/2107.09244v3
"Testing the Potential for Radio Variability in Disks around T Tauri
  Stars with Observations and Chemical Modeling",2021-11-03T18:21:41Z,"C. C. Espaillat, E. Macias, J. Wendeborn, R. Franco-Hernandez, N. Calvet, A. Rilinger, L. I. Cleeves, P. D'Alessio","A multiwavelength observing campaign of the T Tauri star (TTS) GM Aur was
undertaken in 2019 December that obtained Swift X-ray and NUV fluxes, HST NUV
spectra, LCOGT ugri and TESS photometry, CHIRON Halpha spectra, ALMA 13CO and
C18O line fluxes, and VLA 3 cm continuum fluxes taken contemporaneously over
one month. The X-ray to optical observations were presented previously. Here we
present the ALMA and VLA data and make comparisons to GM Aur's accretion and
X-ray properties. We report no variability in the observed millimeter CO
emission. Using disk chemistry models, we show that the magnitude of the
changes seen in the FUV luminosity of GM Aur could lead to variation of up to
~6% in CO line emission and changes in the X-ray luminosity could lead to
larger changes of ~25%. However, the FUV and X-ray luminosity increases must
last at least 100 years in order to induce changes, which seems implausible in
the TTS stage; also, these changes would be too small to be detectable by ALMA.
We report no variability in the 3 cm emission observed by the VLA, showing that
changes of less than a factor of ~3 in the accretion rates of TTSs do not lead
to detectable changes in the mass-loss rate traced by the jet at centimeter
wavelengths. We conclude that typically seen changes in the FUV and X-ray
luminosities of TTSs do not lead to observable changes in millimeter CO line
emission or jet centimeter continuum emission.",http://arxiv.org/abs/2111.02454v1
Hölder estimates for resolvents of time-changed Brownian motions,2021-03-03T07:52:39Z,Kouhei Matsuura,"This paper studies time changes of Brownian motions by positive continuous
additive functionals. Under a certain regularity condition on the associated
Revuz measures, we prove that the resolvents of the time-changed Brownian
motions are locally H\""{o}lder continuous in the spatial components. We also
obtain lower bounds for the indice of the H\""{o}lder continuity.",http://arxiv.org/abs/2103.02232v2
The Change of Basis Groupoid,2021-07-12T14:23:52Z,D. A. Wolfram,"We show that the change of basis matrices of a set of $m$ bases of a finite
vector space is a connected groupoid of order $m^2$. We define a general method
to express the elements of change of basis matrices as algebraic expressions
using optimizations of evaluations of vector dot products. Examples are given
with orthogonal polynomials.",http://arxiv.org/abs/2107.05450v1
Fractional Skellam Process of Order $k$,2021-03-16T16:38:09Z,"K. K. Kataria, M. Khandakar","We introduce and study a fractional version of the Skellam process of order
$k$ by time-changing it with an independent inverse stable subordinator. We
call it the fractional Skellam process of order $k$ (FSPoK). An integral
representation for its one-dimensional distributions and their governing system
of fractional differential equations are obtained. We derive the probability
generating function, mean, variance and covariance of the FSPoK which are
utilized to establish its long-range dependence property. Later, we considered
two time-changed versions of the FSPoK. These are obtained by time-changing the
FSPoK by an independent L\'evy subordinator and its inverse. Some
distributional properties and particular cases are discussed for these
time-changed processes.",http://arxiv.org/abs/2103.09187v1
Scalable Bayesian change point detection with spike and slab priors,2021-06-18T23:03:39Z,"Lorenzo Cappello, Oscar Hernan Madrid Padilla, Julia A. Palacios","We study the use of spike and slab priors for consistent estimation of the
number of change points and their locations. Leveraging recent results in the
variable selection literature, we show that an estimator based on spike and
slab priors achieves optimal localization rate in the multiple offline change
point detection problem. Based on this estimator, we propose a Bayesian change
point detection method, which is one of the fastest Bayesian methodologies, and
it is more robust to misspecification of the error terms than the competing
methods. We demonstrate through empirical work the good performance of our
approach vis-a-vis some state-of-the-art benchmarks.",http://arxiv.org/abs/2106.10383v1
"On the long range dependence of time-changed mixed fractional Brownian
  motion model",2021-02-19T22:14:04Z,"Ezzedine Mliki, Shaykhah Alajmi","A time-changed mixed fractional Brownian motion is an iterated process
constructed as the superposition of mixed fractional Brownian motion and other
process. In this paper we consider mixed fractional Brownian motion of
parameters a, b and H\in(0, 1) time-changed by two processes, gamma and
tempered stable subordinators. We present their main properties paying main
attention to the long range dependence. We deduce that the fractional Brownian
motion time-changed by gamma and tempered stable subordinators has long range
dependence property for all H\in(0, 1).",http://arxiv.org/abs/2102.10180v1
"A Prioritized Trajectory Planning Algorithm for Connected and Automated
  Vehicle Mandatory Lane Changes",2021-04-21T21:49:44Z,"Nachuan Li, Austen Z. Fan, Riley Fischer, Wissam Kontar, Bin Ran","We introduce a prioritized system-optimal algorithm for mandatory lane change
(MLC) behavior of connected and automated vehicles (CAV) from a dedicated lane.
Our approach applies a cooperative lane change that prioritizes the decisions
of lane changing vehicles which are closer to the end of the diverging zone
(DZ), and optimizes the predicted total system travel time. Our experiments on
synthetic data show that the proposed algorithm improves the traffic network
efficiency by attaining higher speeds in the dedicated lane and earlier MLC
positions while ensuring a low computational time. Our approach outperforms the
traditional gap acceptance model.",http://arxiv.org/abs/2104.11590v1
"Quantum Disturbance without State Change: Soundness and Locality of
  Disturbance Measures",2021-04-24T08:22:57Z,Masanao Ozawa,"It is often supposed that a quantum system is not disturbed without state
change. In a recent debate, this assumption is used to claim that the
operator-based disturbance measure, a broadly used disturbance measure, has an
unphysical property. Here, we show that a quantum system possibly incurs an
operationally detectable disturbance without state change to rebut the claim.
Moreover, we establish the reliability, formulated as soundness and locality,
of the operator-based disturbance measure, which, we show, quantifies the
disturbance on an observable that manifests in the time-like correlation even
in the case where its probability distribution does not change.",http://arxiv.org/abs/2104.11909v2
"A series expansion formula of the scale matrix with applications in
  change-point detection",2021-09-07T22:47:43Z,"Jevgenijs Ivanovs, Kazutoshi Yamazaki","We introduce a new Levy fluctuation theoretic method to analyze the
cumulative sum (CUSUM) procedure in sequential change-point detection. When
observations are phase-type distributed and the post-change distribution is
given by exponential tilting of its pre-change distribution, the first passage
analysis of the CUSUM statistic is reduced to that of a certain Markov additive
process. We develop a novel series expansion formula of the scale matrix for
Markov additive processes of finite activity, and apply it to derive exact
expressions of the average run length, average detection delay, and false alarm
probability under the CUSUM procedure.",http://arxiv.org/abs/2109.03361v2
"Change of Corner Charge and Adiabatic Current Distribution in Two
  Dimensional Insulators with Inversion Symmetry",2021-09-21T18:33:01Z,Xuzhe Ying,"We discuss the change of the corner charge for noninteracting two dimensional
insulators with inversion symmetry undergoing adiabatic evolution. We show that
the change of the corner charge is accounted for by the adiabatic current
flowing along the edges of the system. The study of systems with quasi-1D
geometry is necessary to derive the analytical expression for the adiabatic
current. This fact suggests that the change of the corner charge is neither a
purely bulk nor edge effect, but rather a mixed one. The derived adiabatic
current was examined and shows good agreement with the numerical calculation of
Benalcazar-Bernevig-Hughes model.",http://arxiv.org/abs/2109.10395v1
Grammatical Profiling for Semantic Change Detection,2021-09-21T18:38:18Z,"Mario Giulianelli, Andrey Kutuzov, Lidia Pivovarova","Semantics, morphology and syntax are strongly interdependent. However, the
majority of computational methods for semantic change detection use
distributional word representations which encode mostly semantics. We
investigate an alternative method, grammatical profiling, based entirely on
changes in the morphosyntactic behaviour of words. We demonstrate that it can
be used for semantic change detection and even outperforms some distributional
semantic methods. We present an in-depth qualitative and quantitative analysis
of the predictions made by our grammatical profiling system, showing that they
are plausible and interpretable.",http://arxiv.org/abs/2109.10397v1
"Super-resolution-based Change Detection Network with Stacked Attention
  Module for Images with Different Resolutions",2021-02-27T11:17:40Z,"Mengxi Liu, Qian Shi, Andrea Marinoni, Da He, Xiaoping Liu, Liangpei Zhang","Change detection, which aims to distinguish surface changes based on
bi-temporal images, plays a vital role in ecological protection and urban
planning. Since high resolution (HR) images cannot be typically acquired
continuously over time, bi-temporal images with different resolutions are often
adopted for change detection in practical applications. Traditional
subpixel-based methods for change detection using images with different
resolutions may lead to substantial error accumulation when HR images are
employed; this is because of intraclass heterogeneity and interclass
similarity. Therefore, it is necessary to develop a novel method for change
detection using images with different resolutions, that is more suitable for HR
images. To this end, we propose a super-resolution-based change detection
network (SRCDNet) with a stacked attention module. The SRCDNet employs a super
resolution (SR) module containing a generator and a discriminator to directly
learn SR images through adversarial learning and overcome the resolution
difference between bi-temporal images. To enhance the useful information in
multi-scale features, a stacked attention module consisting of five
convolutional block attention modules (CBAMs) is integrated to the feature
extractor. The final change map is obtained through a metric learning-based
change decision module, wherein a distance map between bi-temporal features is
calculated. The experimental results demonstrate the superiority of the
proposed method, which not only outperforms all baselines -with the highest F1
scores of 87.40% on the building change detection dataset and 92.94% on the
change detection dataset -but also obtains the best accuracies on experiments
performed with images having a 4x and 8x resolution difference. The source code
of SRCDNet will be available at https://github.com/liumency/SRCDNet.",http://arxiv.org/abs/2103.00188v1
"Causes and Consequences of Magnetic Complexity Changes within
  Interplanetary Coronal Mass Ejections: a Statistical Study",2021-11-24T17:16:19Z,"Camilla Scolini, Réka M. Winslow, Noé Lugaz, Tarik M. Salman, Emma E. Davies, Antoinette B. Galvin","We present the first statistical analysis of complexity changes affecting the
magnetic structure of interplanetary coronal mass ejections (ICMEs), with the
aim of answering the questions: How frequently do ICMEs undergo magnetic
complexity changes during propagation? What are the causes of such changes? Do
the in situ properties of ICMEs differ depending on whether they exhibit
complexity changes? We consider multi-spacecraft observations of 31 ICMEs by
MESSENGER, Venus Express, ACE, and STEREO between 2008 and 2014 while radially
aligned. By analyzing their magnetic properties at the inner and outer
spacecraft, we identify complexity changes which manifest as fundamental
alterations or significant re-orientations of the ICME. Plasma and suprathermal
electron data at 1 au, and simulations of the solar wind enable us to
reconstruct the propagation scenario for each event, and to identify critical
factors controlling their evolution. Results show that ~65% of ICMEs change
their complexity between Mercury and 1 au and that interaction with multiple
large-scale solar wind structures is the driver of these changes. Furthermore,
71% of ICMEs observed at large radial (>0.4 au) but small longitudinal (<15
degrees) separations exhibit complexity changes, indicating that propagation
over large distances strongly affects ICMEs. Results also suggest ICMEs may be
magnetically coherent over angular scales of at least 15 degrees, supporting
earlier theoretical and observational estimates. This work presents statistical
evidence that magnetic complexity changes are consequences of ICME interactions
with large-scale solar wind structures, rather than intrinsic to ICME
evolution, and that such changes are only partly identifiable from in situ
measurements at 1 au.",http://arxiv.org/abs/2111.12637v1
"Probing the disk-corona systems and broad line regions of changing-look
  quasars with X-ray and optical observations",2021-03-03T08:14:39Z,"Xiangyu Jin, John J. Ruan, Daryl Haggard, Marie-Joëlle Gingras, Joseph Hountalas, Chelsea L. MacLeod, Scott F. Anderson, Anh Doan, Michael Eracleous, Paul J. Green, Jessie C. Runnoe","""Changing-look"" quasars are a new class of highly variable active galactic
nuclei that have changed their spectral type over surprisingly short timescales
of just a few years. The origin of this phenomenon is debated, but is likely to
reflect some change in the accretion flow. To investigate the disk-corona
systems in these objects, we measure optical/UV-X-ray spectral indices
($\alpha_{\rm OX}$) and Eddington ratios ($\lambda_{\rm Edd}$) of ten
previously-discovered changing-look quasars at two or more epochs. By comparing
these data with simulated results based on the behavior of X-ray binaries, we
find possible similarities in spectral indices below 1% Eddington ratio. We
further investigate the Eddington ratios of changing-look quasars before and
after their spectral type changes, and find that changing-look quasars cross
the 1% Eddington ratio boundary when their broad emission lines
disappear/emerge. This is consistent with the disk-wind model as the origin of
broad emission lines.",http://arxiv.org/abs/2103.02245v1
Self-Supervised Multisensor Change Detection,2021-02-12T12:31:10Z,"Sudipan Saha, Patrick Ebel, Xiao Xiang Zhu","Most change detection methods assume that pre-change and post-change images
are acquired by the same sensor. However, in many real-life scenarios, e.g.,
natural disaster, it is more practical to use the latest available images
before and after the occurrence of incidence, which may be acquired using
different sensors. In particular, we are interested in the combination of the
images acquired by optical and Synthetic Aperture Radar (SAR) sensors. SAR
images appear vastly different from the optical images even when capturing the
same scene. Adding to this, change detection methods are often constrained to
use only target image-pair, no labeled data, and no additional unlabeled data.
Such constraints limit the scope of traditional supervised machine learning and
unsupervised generative approaches for multi-sensor change detection. Recent
rapid development of self-supervised learning methods has shown that some of
them can even work with only few images. Motivated by this, in this work we
propose a method for multi-sensor change detection using only the unlabeled
target bi-temporal images that are used for training a network in
self-supervised fashion by using deep clustering and contrastive learning. The
proposed method is evaluated on four multi-modal bi-temporal scenes showing
change and the benefits of our self-supervised approach are demonstrated.",http://arxiv.org/abs/2103.05102v3
Change-Point Analysis of Time Series with Evolutionary Spectra,2021-06-03T17:56:24Z,"Alessandro Casini, Pierre Perron","This paper develops change-point methods for the spectrum of a locally
stationary time series. We focus on series with a bounded spectral density that
change smoothly under the null hypothesis but exhibits change-points or becomes
less smooth under the alternative. We address two local problems. The first is
the detection of discontinuities (or breaks) in the spectrum at unknown dates
and frequencies. The second involves abrupt yet continuous changes in the
spectrum over a short time period at an unknown frequency without signifying a
break. Both problems can be cast into changes in the degree of smoothness of
the spectral density over time. We consider estimation and minimax-optimal
testing. We determine the optimal rate for the minimax distinguishable
boundary, i.e., the minimum break magnitude such that we are able to uniformly
control type I and type II errors. We propose a novel procedure for the
estimation of the change-points based on a wild sequential top-down algorithm
and show its consistency under shrinking shifts and possibly growing number of
change-points. Our method can be used across many fields and a companion
program is made available in popular software packages.",http://arxiv.org/abs/2106.02031v3
"External Service Sensing (ESS): Research Framework, Challenges and
  Opportunities",2021-06-17T02:12:11Z,"Zhongjie Wang, Mingyi Liu, Zhiying Tu, Xiaofei Xu","The flourish of web-based services gave birth to the research area
\textit{services computing}, a rapidly-expanding academic community since
nearly 20 years ago. Consensus has been reached on a set of representative
research problems in services computing, such as service selection, service
composition, service recommendation, and service quality prediction. An obvious
fact is that most services keep constant changes to timely adapt to changes of
external business/technical environment and changes of internal development
strategies. However, traditional services computing research does not consider
such changes sufficiently. Many works regard services as \textit{static}
entities; this leads to the situation that some proposed models/algorithms do
not work in real world. Sensing various types of service changes is of great
significance to the practicability and rationality of services computing
research. In this paper, a new research problem \textit{External Service
Sensing} (ESS) is defined to cope with various changes in services, and a
research framework of ESS is presented to elaborate the scope and boundary of
ESS. This framework is composed of four orthogonal dimensions: sensing objects,
sensing contents, sensing channels, and sensing techniques. Each concrete ESS
problem is defined by combining different values in these dimensions, and
existing research work related to service changes can be well adapted to this
framework. Real-world case studies demonstrate the soundness of ESS and its
framework. Finally, some challenges and opportunities in ESS research are
listed for researchers in the services computing community. To the best of our
knowledge, this is the first time to systematically define service
change-related research as a standard services computing problem, and thus
broadening the research scope of services computing.",http://arxiv.org/abs/2106.09208v1
"Responsive Regulation of Dynamic UAV Communication Networks Based on
  Deep Reinforcement Learning",2021-08-25T02:04:13Z,"Ran Zhang, Duc Minh, Nguyen, Miao Wang, Lin X. Cai, Xuemin, Shen","In this chapter, the regulation of Unmanned Aerial Vehicle (UAV)
communication network is investigated in the presence of dynamic changes in the
UAV lineup and user distribution. We target an optimal UAV control policy which
is capable of identifying the upcoming change in the UAV lineup (quit or
join-in) or user distribution, and proactively relocating the UAVs ahead of the
change rather than passively dispatching the UAVs after the change.
Specifically, a deep reinforcement learning (DRL)-based UAV control framework
is developed to maximize the accumulated user satisfaction (US) score for a
given time horizon which is able to handle the change in both the UAV lineup
and user distribution. The framework accommodates the changed dimension of the
state-action space before and after the UAV lineup change by deliberate state
transition design. In addition, to handle the continuous state and action
space, deep deterministic policy gradient (DDPG) algorithm, which is an
actor-critic based DRL, is exploited. Furthermore, to promote the learning
exploration around the timing of the change, the original DDPG is adapted into
an asynchronous parallel computing (APC) structure which leads to a better
training performance in both the critic and actor networks. Finally, extensive
simulations are conducted to validate the convergence of the proposed learning
approach, and demonstrate its capability in jointly handling the dynamics in
UAV lineup and user distribution as well as its superiority over a passive
reaction method.",http://arxiv.org/abs/2108.11012v1
"Analysis of the relation between smartphone usage changes during the
  COVID-19 pandemic and usage preferences on apps",2021-10-04T11:28:20Z,"Yuxuan Yang, Maiko Shigeno","Since the World Health Organization announced the COVID-19 pandemic in March
2020, curbing the spread of the virus has become an international priority. It
has greatly affected people's lifestyles. In this article, we observe and
analyze the impact of the pandemic on people's lives using changes in
smartphone application usage. First, through observing the daily usage change
trends of all users during the pandemic, we can understand and analyze the
effects of restrictive measures and policies during the pandemic on people's
lives. In addition, it is also helpful for the government and health
departments to take more appropriate restrictive measures in the case of future
pandemics. Second, we defined the usage change features and found 9 different
usage change patterns during the pandemic according to clusters of users and
show the diversity of daily usage changes. It helps to understand and analyze
the different impacts of the pandemic and restrictive measures on different
types of people in more detail. Finally, according to prediction models, we
discover the main related factors of each usage change type from user
preferences and demographic information. It helps to predict changes in
smartphone activity during future pandemics or when other restrictive measures
are implemented, which may become a new indicator to judge and manage the risks
of measures or events.",http://arxiv.org/abs/2110.01331v2
"A New Automatic Change Detection Frame-work Based on Region Growing and
  Weighted Local Mutual Information: Analysis of Breast Tumor Response to
  Chemotherapy in Serial MR Images",2021-10-19T20:28:45Z,"Narges Norouzi, Reza Azmi, Nooshin Noshiri, Robab Anbiaee","The automatic analysis of subtle changes between longitudinal MR images is an
important task as it is still a challenging issue in scope of the breast
medical image processing. In this paper we propose an effective automatic
change detection framework composed of two phases since previously used methods
have features with low distinctive power. First, in the preprocessing phase an
intensity normalization method is suggested based on Hierarchical Histogram
Matching (HHM) that is more robust to noise than previous methods. To eliminate
undesirable changes and extract the regions containing significant changes the
proposed Extraction Region of Changes (EROC) method is applied based on
intensity distribution and Hill-Climbing algorithm. Second, in the detection
phase a region growing-based approach is suggested to differentiate significant
changes from unreal ones. Due to using proposed Weighted Local Mutual
Information (WLMI) method to extract high level features and also utilizing the
principle of the local consistency of changes, the proposed approach enjoys
reasonable performance. The experimental results on both simulated and real
longitudinal Breast MR Images confirm the effectiveness of the proposed
framework. Also, this framework outperforms the human expert in some cases
which can detect many lesion evolutions that are missed by expert.",http://arxiv.org/abs/2110.10242v1
Lexical semantic change for Ancient Greek and Latin,2021-01-22T12:04:08Z,"Valerio Perrone, Simon Hengchen, Marco Palma, Alessandro Vatri, Jim Q. Smith, Barbara McGillivray","Change and its precondition, variation, are inherent in languages. Over time,
new words enter the lexicon, others become obsolete, and existing words acquire
new senses. Associating a word's correct meaning in its historical context is a
central challenge in diachronic research. Historical corpora of classical
languages, such as Ancient Greek and Latin, typically come with rich metadata,
and existing models are limited by their inability to exploit contextual
information beyond the document timestamp. While embedding-based methods
feature among the current state of the art systems, they are lacking in the
interpretative power. In contrast, Bayesian models provide explicit and
interpretable representations of semantic change phenomena. In this chapter we
build on GASC, a recent computational approach to semantic change based on a
dynamic Bayesian mixture model. In this model, the evolution of word senses
over time is based not only on distributional information of lexical nature,
but also on text genres. We provide a systematic comparison of dynamic Bayesian
mixture models for semantic change with state-of-the-art embedding-based
models. On top of providing a full description of meaning change over time, we
show that Bayesian mixture models are highly competitive approaches to detect
binary semantic change in both Ancient Greek and Latin.",http://arxiv.org/abs/2101.09069v1
"Tracking fast and slow changes in synaptic weights from simultaneously
  observed pre- and postsynaptic spiking",2021-02-02T23:54:00Z,"Ganchao Wei, Ian H. Stevenson","Synapses change on multiple timescales, ranging from milliseconds to minutes,
due to a combination of both short- and long-term plasticity. Here we develop
an extension of the common Generalized Linear Model to infer both short- and
long-term changes in the coupling between a pre- and post-synaptic neuron based
on observed spiking activity. We model short-term synaptic plasticity using
additive effects that depend on the presynaptic spike timing, and we model
long-term changes in both synaptic weight and baseline firing rate using point
process adaptive smoothing. Using simulations, we first show that this model
can accurately recover time-varying synaptic weights 1) for both depressing and
facilitating synapses, 2) with a variety of long-term changes (including
realistic changes, such as due to STDP), 3) with a range of pre- and
post-synaptic firing rates, and 4) for both excitatory and inhibitory synapses.
We then apply our model to two experimentally recorded putative synaptic
connections. We find that simultaneously tracking fast changes in synaptic
weights, slow changes in synaptic weights, and unexplained variations in
baseline firing is essential. Omitting any one of these factors can lead to
spurious inferences for the others. Altogether, this model provides a flexible
framework for tracking short- and long-term variation in spike transmission.",http://arxiv.org/abs/2102.01803v2
Infinitely many sign changes of the Liouville function on $x^2+d$,2021-04-30T13:53:19Z,Anitha Srinivasan,"We show that the Liouville function changes sign infinitely often for
$x^2+d$.",http://arxiv.org/abs/2104.15004v2
Failures of square in Pmax extensions of Chang models,2021-05-01T18:35:26Z,"Paul B. Larson, Grigor Sargsyan","We show that the statements $\square(\omega_{3})$ and $\square(\omega_{4})$
both fail in the $\mathbb{P}_{\mathrm{max}}$ extension of a variation of the
Chang model introduced by Sargsyan.",http://arxiv.org/abs/2105.00322v1
"An Empirical Review of Deep Learning Frameworks for Change Detection:
  Model Design, Experimental Frameworks, Challenges and Research Needs",2021-05-04T07:42:40Z,"Murari Mandal, Santosh Kumar Vipparthi","Visual change detection, aiming at segmentation of video frames into
foreground and background regions, is one of the elementary tasks in computer
vision and video analytics. The applications of change detection include
anomaly detection, object tracking, traffic monitoring, human machine
interaction, behavior analysis, action recognition, and visual surveillance.
Some of the challenges in change detection include background fluctuations,
illumination variation, weather changes, intermittent object motion, shadow,
fast/slow object motion, camera motion, heterogeneous object shapes and
real-time processing. Traditionally, this problem has been solved using
hand-crafted features and background modelling techniques. In recent years,
deep learning frameworks have been successfully adopted for robust change
detection. This article aims to provide an empirical review of the
state-of-the-art deep learning methods for change detection. More specifically,
we present a detailed analysis of the technical characteristics of different
model designs and experimental frameworks. We provide model design based
categorization of the existing approaches, including the 2D-CNN, 3D-CNN,
ConvLSTM, multi-scale features, residual connections, autoencoders and GAN
based methods. Moreover, an empirical analysis of the evaluation settings
adopted by the existing deep learning methods is presented. To the best of our
knowledge, this is a first attempt to comparatively analyze the different
evaluation frameworks used in the existing deep change detection methods.
Finally, we point out the research needs, future directions and draw our own
conclusions.",http://arxiv.org/abs/2105.01342v1
Self-supervised Remote Sensing Images Change Detection at Pixel-level,2021-05-18T13:28:46Z,"Yuxing Chen, Lorenzo Bruzzone","Deep learning techniques have achieved great success in remote sensing image
change detection. Most of them are supervised techniques, which usually require
large amounts of training data and are limited to a particular application.
Self-supervised methods as an unsupervised approach are popularly used to solve
this problem and are widely used in unsupervised binary change detection tasks.
However, the existing self-supervised methods in change detection are based on
pre-tasks or at patch-level, which may be sub-optimal for pixel-wise change
detection tasks. Therefore, in this work, a pixel-wise contrastive approach is
proposed to overcome this limitation. This is achieved by using contrastive
loss in pixel-level features on an unlabeled multi-view setting. In this
approach, a Siamese ResUnet is trained to obtain pixel-wise representations and
to align features from shifted positive pairs. Meanwhile, vector quantization
is used to augment the learned features in two branches. The final binary
change map is obtained by subtracting features of one branch from features of
the other branch and using the Rosin thresholding method. To overcome the
effects of regular seasonal changes in binary change maps, we also used an
uncertainty method to enhance the temporal robustness of the proposed approach.
Two homogeneous (OSCD and MUDS) datasets and one heterogeneous (California
Flood) dataset are used to evaluate the performance of the proposed approach.
Results demonstrate improvements in both efficiency and accuracy over the
patch-wise multi-view contrastive method.",http://arxiv.org/abs/2105.08501v2
Changes from the Trenches: Should We Automate Them?,2021-05-21T06:43:58Z,"Yaroslav Golubev, Jiawei Li, Viacheslav Bushev, Timofey Bryksin, Iftekhar Ahmed","Code changes constitute one of the most important features of software
evolution. Studying them can provide insights into the nature of software
development and also lead to practical solutions - recommendations and
automations of popular changes for developers.
  In our work, we developed a tool called PythonChangeMiner that allows to
discover code change patterns in the histories of Python projects. We validated
the tool and then employed it to discover patterns in the dataset of 120
projects from four different domains of software engineering. We manually
categorized patterns that occur in more than one project from the standpoint of
their structure and content, and compared different domains and patterns in
that regard. We conducted a survey of the authors of the discovered changes:
82.9% of them said that they can give the change a name and 57.9% expressed
their desire to have the changes automated, indicating the ability of the tool
to discover valuable patterns. Finally, we interviewed 9 members of a popular
integrated development environment (IDE) development team to estimate the
feasibility of automating the discovered changes. It was revealed that
independence from the context and high precision made a pattern a better
candidate for automation. The patterns received mainly positive reviews and
several were ranked as very likely for automation.",http://arxiv.org/abs/2105.10157v2
Adversarially robust change point detection,2021-05-21T15:37:04Z,"Mengchu Li, Yi Yu","Change point detection is becoming increasingly popular in many application
areas. On one hand, most of the theoretically-justified methods are
investigated in an ideal setting without model violations, or merely robust
against identical heavy-tailed noise distribution across time and/or against
isolate outliers; on the other hand, we are aware that there have been
exponentially growing attacks from adversaries, who may pose systematic
contamination on data to purposely create spurious change points or disguise
true change points. In light of the timely need for a change point detection
method that is robust against adversaries, we start with, arguably, the
simplest univariate mean change point detection problem. The adversarial
attacks are formulated through the Huber $\varepsilon$-contamination framework,
which in particular allows the contamination distributions to be different at
each time point. In this paper, we demonstrate a phase transition phenomenon in
change point detection. This detection boundary is a function of the
contamination proportion $\varepsilon$ and is the first time shown in the
literature. In addition, we derive the minimax-rate optimal localisation error
rate, quantifying the cost of accuracy in terms of the contamination
proportion. We propose a computationally feasible method, matching the minimax
lower bound under certain conditions, saving for logarithmic factors. Extensive
numerical experiments are conducted with comparisons to robust change point
detection methods in the existing literature.",http://arxiv.org/abs/2105.10417v2
FCCDN: Feature Constraint Network for VHR Image Change Detection,2021-05-23T06:13:47Z,"Pan Chen, Danfeng Hong, Zhengchao Chen, Xuan Yang, Baipeng Li, Bing Zhang","Change detection is the process of identifying pixelwise differences in
bitemporal co-registered images. It is of great significance to Earth
observations. Recently, with the emergence of deep learning (DL), the power and
feasibility of deep convolutional neural network (CNN)-based methods have been
shown in the field of change detection. However, there is still a lack of
effective supervision for change feature learning. In this work, a feature
constraint change detection network (FCCDN) is proposed. We constrain features
both in bitemporal feature extraction and feature fusion. More specifically, we
propose a dual encoder-decoder network backbone for the change detection task.
At the center of the backbone, we design a nonlocal feature pyramid network to
extract and fuse multiscale features. To fuse bitemporal features in a robust
way, we build a dense connection-based feature fusion module. Moreover, a
self-supervised learning-based strategy is proposed to constrain feature
learning. Based on FCCDN, we achieve state-of-the-art performance on two
building change detection datasets (LEVIR-CD and WHU). On the LEVIR-CD dataset,
we achieve an IoU of 0.8569 and an F1 score of 0.9229. On the WHU dataset, we
achieve an IoU of 0.8820 and an F1 score of 0.9373. Moreover, for the first
time, the acquisition of accurate bitemporal semantic segmentation results is
achieved without using semantic segmentation labels. This is vital for the
application of change detection because it saves the cost of labeling.",http://arxiv.org/abs/2105.10860v2
A Framework for Explainable Concept Drift Detection in Process Mining,2021-05-27T14:03:19Z,"Jan Niklas Adams, Sebastiaan J. van Zelst, Lara Quack, Kathrin Hausmann, Wil M. P. van der Aalst, Thomas Rose","Rapidly changing business environments expose companies to high levels of
uncertainty. This uncertainty manifests itself in significant changes that tend
to occur over the lifetime of a process and possibly affect its performance. It
is important to understand the root causes of such changes since this allows us
to react to change or anticipate future changes. Research in process mining has
so far only focused on detecting, locating and characterizing significant
changes in a process and not on finding root causes of such changes. In this
paper, we aim to close this gap. We propose a framework that adds an
explainability level onto concept drift detection in process mining and
provides insights into the cause-effect relationships behind significant
changes. We define different perspectives of a process, detect concept drifts
in these perspectives and plug the perspectives into a causality check that
determines whether these concept drifts can be causal to each other. We
showcase the effectiveness of our framework by evaluating it on both synthetic
and real event data. Our experiments show that our approach unravels
cause-effect relationships and provides novel insights into executed processes.",http://arxiv.org/abs/2105.13155v1
Change-point Detection for Piecewise Exponential Models,2021-12-07T19:43:52Z,"Philip Cooney, Arthur White","In decision modelling with time to event data, parametric models are often
used to extrapolate the survivor function. One such model is the piecewise
exponential model whereby the hazard function is partitioned into segments,
with the hazard constant within the segment and independent between segments
and the boundaries of these segments are known as change-points. We present an
approach for determining the location and number of change-points in piecewise
exponential models. Inference is performed in a Bayesian framework using Markov
Chain Monte Carlo (MCMC) where the model parameters can be integrated out of
the model and the number of change-points can be sampled as part of the MCMC
scheme. We can estimate both the uncertainty in the change-point locations and
hazards for a given change-point model and obtain a probabilistic
interpretation for the number of change-points. We evaluate model performance
to determine changepoint numbers and locations in a simulation study and show
the utility of the method using two data sets for time to event data. In a
dataset of Glioblastoma patients we use the piecewise exponential model to
describe the general trends in the hazard function. In a data set of heart
transplant patients, we show the piecewise exponential model produces the best
statistical fit and extrapolation amongst other standard parametric models.
Piecewise exponential models may be useful for survival extrapolation if a
long-term constant hazard trend is clinically plausible. A key advantage of
this method is that the number and change-point locations are automatically
estimated rather than specified by the analyst.",http://arxiv.org/abs/2112.03962v1
InDiD: Instant Disorder Detection via Representation Learning,2021-06-04T17:04:13Z,"Evgenia Romanenkova, Alexander Stepikin, Matvey Morozov, Alexey Zaytsev","For sequential data, a change point is a moment of abrupt regime switch in
data streams. Such changes appear in different scenarios, including simpler
data from sensors and more challenging video surveillance data. We need to
detect disorders as fast as possible. Classic approaches for change point
detection (CPD) might underperform for semi-structured sequential data because
they cannot process its structure without a proper representation. We propose a
principled loss function that balances change detection delay and time to a
false alarm. It approximates classic rigorous solutions but is differentiable
and allows representation learning for deep models. We consider synthetic
sequences, real-world data sensors and videos with change points. We carefully
labelled available data with change point moments for video data and released
it for the first time. Experiments suggest that complex data require meaningful
representations tailored for the specificity of the CPD task -- and our
approach provides them outperforming considered baselines. For example, for
explosion detection in video, the F1 score for our method is $0.53$ compared to
baseline scores of $0.31$ and $0.35$.",http://arxiv.org/abs/2106.02602v3
Three-part diachronic semantic change dataset for Russian,2021-06-15T17:12:25Z,"Andrey Kutuzov, Lidia Pivovarova","We present a manually annotated lexical semantic change dataset for Russian:
RuShiftEval. Its novelty is ensured by a single set of target words annotated
for their diachronic semantic shifts across three time periods, while the
previous work either used only two time periods, or different sets of target
words. The paper describes the composition and annotation procedure for the
dataset. In addition, it is shown how the ternary nature of RuShiftEval allows
to trace specific diachronic trajectories: `changed at a particular time period
and stable afterwards' or `was changing throughout all time periods'. Based on
the analysis of the submissions to the recent shared task on semantic change
detection for Russian, we argue that correctly identifying such trajectories
can be an interesting sub-task itself.",http://arxiv.org/abs/2106.08294v1
"Bootstrap confidence intervals for multiple change points based on
  moving sum procedures",2021-06-24T09:07:10Z,"Haeran Cho, Claudia Kirch","The problem of quantifying uncertainty about the locations of multiple change
points by means of confidence intervals is addressed. The asymptotic
distribution of the change point estimators obtained as the local maximisers of
moving sum statistics is derived, where the limit distributions differ
depending on whether the corresponding size of changes is local, i.e. tends to
zero as the sample size increases, or fixed. A bootstrap procedure for
confidence interval generation is proposed which adapts to the unknown
magnitude of changes and guarantees asymptotic validity both for local and
fixed changes. Simulation studies show good performance of the proposed
bootstrap procedure, and some discussions about how it can be extended to
serially dependent errors is provided.",http://arxiv.org/abs/2106.12844v4
"The Grasps Under Varied Object Orientation Dataset: Relation Between
  Grasps and Object Orientation",2021-06-27T06:40:18Z,"Chang Cheng, Yadong Yan, Mingjun Guan, Jianan Zhang, Yu Wang","After a grasp has been planned, if the object orientation changes, the
initial grasp may not have to be modified to accommodate the orientation
change. For example, rotation of a cylinder by any amount around its centerline
does not change its geometric shape relative to the grasper. Objects that can
be approximated to solids of revolution or contain other geometric symmetries
are prevalent in everyday life, and this information can be employed to improve
the efficiency of existing grasp planning models. This paper experimentally
investigates change in human-planned grasps under varied object orientations.
With 13,440 recorded human grasps, our results indicate that during
pick-and-place task of ordinary objects, stable grasps can be achieved with a
small subset of grasp types, and the wrist-related parameters follow normal
distribution.",http://arxiv.org/abs/2106.14158v2
"Occupation Times for Time-changed Processes with Applications to
  Parisian Options",2021-10-14T18:03:00Z,"Joonyong Choi, David Clancy Jr","Stochastic processes time-changed by an inverse subordinator have been
suggested as a way to model the price of assets in illiquid markets, where the
jumps of the subordinator correspond to periods of time where one is unable to
sell an asset. We develop an excursion theory for time-changed reflected
Brownian motion and use this to express the price of certain European options
with Parisian barrier condition in terms of solutions of a time-fractional PDE.
We provide a general description of the occupation measures of time-changed
processes and use this to prove a Ray-Knight theorem for the occupation measure
of a time-changed Brownian motion with negative drift. We also show that the
duration of the excursions on finite time intervals obey a Poisson-Dirichlet
distribution when a reflected Brownian motion is time-changed by an inverse
stable subordinator.",http://arxiv.org/abs/2110.07639v1
"Decentralized Cooperative Lane Changing at Freeway Weaving Areas Using
  Multi-Agent Deep Reinforcement Learning",2021-10-05T18:29:13Z,"Yi Hou, Peter Graf","Frequent lane changes during congestion at freeway bottlenecks such as merge
and weaving areas further reduce roadway capacity. The emergence of deep
reinforcement learning (RL) and connected and automated vehicle technology
provides a possible solution to improve mobility and energy efficiency at
freeway bottlenecks through cooperative lane changing. Deep RL is a collection
of machine-learning methods that enables an agent to improve its performance by
learning from the environment. In this study, a decentralized cooperative
lane-changing controller was developed using proximal policy optimization by
adopting a multi-agent deep RL paradigm. In the decentralized control strategy,
policy learning and action reward are evaluated locally, with each agent
(vehicle) getting access to global state information. Multi-agent deep RL
requires lower computational resources and is more scalable than single-agent
deep RL, making it a powerful tool for time-sensitive applications such as
cooperative lane changing. The results of this study show that cooperative lane
changing enabled by multi-agent deep RL yields superior performance to human
drivers in term of traffic throughput, vehicle speed, number of stops per
vehicle, vehicle fuel efficiency, and emissions. The trained RL policy is
transferable and can be generalized to uncongested, moderately congested, and
extremely congested traffic conditions.",http://arxiv.org/abs/2110.08124v1
"Online non-parametric change-point detection for heterogeneous data
  streams observed over graph nodes",2021-10-20T12:10:15Z,"Alejandro de la Concha, Argyris Kalogeratos, Nicolas Vayatis","Consider a heterogeneous data stream being generated by the nodes of a graph.
The data stream is in essence composed by multiple streams, possibly of
different nature that depends on each node. At a given moment $\tau$, a
change-point occurs for a subset of nodes $C$, signifying the change in the
probability distribution of their associated streams. In this paper we propose
an online non-parametric method to infer $\tau$ based on the direct estimation
of the likelihood-ratio between the post-change and the pre-change distribution
associated with the data stream of each node. We propose a kernel-based method,
under the hypothesis that connected nodes of the graph are expected to have
similar likelihood-ratio estimates when there is no change-point. We
demonstrate the quality of our method on synthetic experiments and real-world
applications.",http://arxiv.org/abs/2110.10518v1
"An Asymptotic Theory of Joint Sequential Changepoint Detection and
  Identification for General Stochastic Models",2021-02-02T04:36:39Z,Alexander G. Tartakovsky,"The paper addresses a joint sequential changepoint detection and
identification/isolation problem for a general stochastic model, assuming that
the observed data may be dependent and non-identically distributed, the prior
distribution of the change point is arbitrary, and the post-change hypotheses
are composite. The developed detection-identification theory generalizes the
changepoint detection theory developed by Tartakovsky (2019) to the case of
multiple composite post-change hypotheses when one has not only to detect a
change as quickly as possible but also to identify (or isolate) the true
post-change distribution. We propose a multi-hypothesis change
detection-identification rule and show that it is nearly optimal, minimizing
moments of the delay to detection as the probability of a false alarm and the
probabilities of misidentification go to zero.",http://arxiv.org/abs/2102.01306v2
"Valid Post-Detection Inference for Change Points Identified Using Trend
  Filtering",2021-04-24T21:00:00Z,"Reza Valiollahi Mehrizi, Shojaeddin Chenouri","There are many research works and methods about change point detection in the
literature. However, there are only a few that provide inference for such
change points after being estimated. This work mainly focuses on a statistical
analysis of change points estimated by the PRUTF algorithm, which incorporates
trend filtering to determine change points in piecewise polynomial signals.
This paper develops a methodology to perform statistical inference, such as
computing p-values and constructing confidence intervals in the newly developed
post-selection inference framework. Our work concerns both cases of known and
unknown error variance. As pointed out in the post-selection inference
literature, the length of such confidence intervals are undesirably long. To
resolve this shortcoming, we also provide two novel strategies, global
post-detection, and local post-detection which are based on the intrinsic
properties of change points. We run our proposed methods on real as well as
simulated data to evaluate their performances.",http://arxiv.org/abs/2104.12022v2
Change Point Detection in Nonstationary Sub-Hourly Wind Time Series,2021-05-24T15:37:54Z,"Sakitha Ariyarathne, Harsha Gangammanavar, Raanju R. Sundararajan","In this paper, we present a change point detection method for detecting
change points in multivariate nonstationary wind speed time series. The change
point method identifies changes in the covariance structure and decomposes the
nonstationary multivariate time series into stationary segments. We also
present parametric and nonparametric simulation techniques to simulate new wind
time series within each stationary segment. The proposed simulation methods
retain statistical properties of the original time series and therefore, can be
employed for simulation-based analysis of power systems planning and operations
problems. We demonstrate the capabilities of the change point detection method
through computational experiments conducted on wind speed time series at
five-minute resolution. We also conduct experiments on the economic dispatch
problem to illustrate the impact of nonstationarity in wind generation on
conventional generation and location marginal prices.",http://arxiv.org/abs/2105.11353v1
Testing for the Presence of Structural Change and Spatial Heterogeneity,2021-07-06T06:34:40Z,"Ruby Anne E. Lemence, Erniel B. Barrios","In a spatial-temporal model, structural change and/or spatial heterogeneity
can easily affect estimation of parameters. Following the spatial-temporal
model in [1], we develop a nonparametric procedure for test-ing the presence of
structural change and spatial heterogeneity using bootstrap techniques and the
forward search algorithm. The time series bootstrap can filter the effect of
temporary structural change in the con-struction of a confidence interval for
the temporal parameter. The forward search will also facilitate the
construction of a robust confidence interval for the spatial parameter. These
confidence intervals are then used in deciding on the null hypothesis that
there is no structural change/spatial heterogeneity. Simulation studies
illustrate the ability of the proposed test procedure in detecting presence of
structural change and spatial heterogeneity under certain conditions.",http://arxiv.org/abs/2107.02417v1
Deep learning approaches to Earth Observation change detection,2021-07-13T14:34:59Z,"Antonio Di Pilato, Nicolò Taggio, Alexis Pompili, Michele Iacobellis, Adriano Di Florio, Davide Passarelli, Sergio Samarelli","The interest for change detection in the field of remote sensing has
increased in the last few years. Searching for changes in satellite images has
many useful applications, ranging from land cover and land use analysis to
anomaly detection. In particular, urban change detection provides an efficient
tool to study urban spread and growth through several years of observation. At
the same time, change detection is often a computationally challenging and
time-consuming task, which requires innovative methods to guarantee optimal
results with unquestionable value and within reasonable time. In this paper we
present two different approaches to change detection (semantic segmentation and
classification) that both exploit convolutional neural networks to achieve good
results, which can be further refined and used in a post-processing workflow
for a large variety of applications.",http://arxiv.org/abs/2107.06132v1
"Estimation of high-dimensional change-points under a group sparsity
  structure",2021-07-19T09:51:57Z,"Hanqing Cai, Tengyao Wang","Change-points are a routine feature of 'big data' observed in the form of
high-dimensional data streams. In many such data streams, the component series
possess group structures and it is natural to assume that changes only occur in
a small number of all groups. We propose a new change point procedure, called
'groupInspect', that exploits the group sparsity structure to estimate a
projection direction so as to aggregate information across the component series
to successfully estimate the change-point in the mean structure of the series.
We prove that the estimated projection direction is minimax optimal, up to
logarithmic factors, when all group sizes are of comparable order. Moreover,
our theory provide strong guarantees on the rate of convergence of the
change-point location estimator. Numerical studies demonstrates the competitive
performance of groupInspect in a wide range of settings and a real data example
confirms the practical usefulness of our procedure.",http://arxiv.org/abs/2107.08724v1
Inference for Change Points in High Dimensional Mean Shift Models,2021-07-19T20:56:15Z,"Abhishek Kaul, George Michailidis","We consider the problem of constructing confidence intervals for the
locations of change points in a high-dimensional mean shift model. To that end,
we develop a locally refitted least squares estimator and obtain component-wise
and simultaneous rates of estimation of the underlying change points. The
simultaneous rate is the sharpest available in the literature by at least a
factor of $\log p,$ while the component-wise one is optimal. These results
enable existence of limiting distributions. Component-wise distributions are
characterized under both vanishing and non-vanishing jump size regimes, while
joint distributions for any finite subset of change point estimates are
characterized under the latter regime, which also yields asymptotic
independence of these estimates. The combined results are used to construct
asymptotically valid component-wise and simultaneous confidence intervals for
the change point parameters. The results are established under a high
dimensional scaling, allowing for diminishing jump sizes, in the presence of
diverging number of change points and under subexponential errors. They are
illustrated on synthetic data and on sensor measurements from smartphones for
activity recognition.",http://arxiv.org/abs/2107.09150v1
"Unsupervised Change Detection in Hyperspectral Images using Feature
  Fusion Deep Convolutional Autoencoders",2021-09-10T16:52:31Z,"Debasrita Chakraborty, Ashish Ghosh","Binary change detection in bi-temporal co-registered hyperspectral images is
a challenging task due to a large number of spectral bands present in the data.
Researchers, therefore, try to handle it by reducing dimensions. The proposed
work aims to build a novel feature extraction system using a feature fusion
deep convolutional autoencoder for detecting changes between a pair of such
bi-temporal co-registered hyperspectral images. The feature fusion considers
features across successive levels and multiple receptive fields and therefore
adds a competitive edge over the existing feature extraction methods. The
change detection technique described is completely unsupervised and is much
more elegant than other supervised or semi-supervised methods which require
some amount of label information. Different methods have been applied to the
extracted features to find the changes in the two images and it is found that
the proposed method clearly outperformed the state of the art methods in
unsupervised change detection for all the datasets.",http://arxiv.org/abs/2109.04990v1
"DisCERN:Discovering Counterfactual Explanations using Relevance Features
  from Neighbourhoods",2021-09-13T09:25:25Z,"Nirmalie Wiratunga, Anjana Wijekoon, Ikechukwu Nkisi-Orji, Kyle Martin, Chamath Palihawadana, David Corsar","Counterfactual explanations focus on ""actionable knowledge"" to help end-users
understand how a machine learning outcome could be changed to a more desirable
outcome. For this purpose a counterfactual explainer needs to discover input
dependencies that relate to outcome changes. Identifying the minimum subset of
feature changes needed to action an output change in the decision is an
interesting challenge for counterfactual explainers. The DisCERN algorithm
introduced in this paper is a case-based counter-factual explainer. Here
counterfactuals are formed by replacing feature values from a nearest unlike
neighbour (NUN) until an actionable change is observed. We show how widely
adopted feature relevance-based explainers (i.e. LIME, SHAP), can inform
DisCERN to identify the minimum subset of ""actionable features"". We demonstrate
our DisCERN algorithm on five datasets in a comparative study with the widely
used optimisation-based counterfactual approach DiCE. Our results demonstrate
that DisCERN is an effective strategy to minimise actionable changes necessary
to create good counterfactual explanations.",http://arxiv.org/abs/2109.05800v1
"BreakBot: Analyzing the Impact of Breaking Changes to Assist Library
  Evolution",2021-11-09T13:16:51Z,"Lina Ochoa, Thomas Degueule, Jean-Rémy Falleri","""If we make this change to our code, how will it impact our clients?"" It is
difficult for library maintainers to answer this simple-yet essential!-question
when evolving their libraries. Library maintainers are constantly balancing
between two opposing positions: make changes at the risk of breaking some of
their clients, or avoid changes and maintain compatibility at the cost of
immobility and growing technical debt. We argue that the lack of objective
usage data and tool support leaves maintainers with their own subjective
perception of their community to make these decisions. We introduce BreakBot, a
bot that analyses the pull requests of Java libraries on GitHub to identify the
breaking changes they introduce and their impact on client projects. Through
static analysis of libraries and clients, it extracts and summarizes objective
data that enrich the code review process by providing maintainers with the
appropriate information to decide whether-and how-changes should be accepted,
directly in the pull requests.",http://arxiv.org/abs/2111.05132v2
"An Adaptive Framework for Reliable Trajectory Following in
  Changing-Contact Robot Manipulation Tasks",2021-11-15T13:54:38Z,"Saif Sidhik, Mohan Sridharan, Dirk Ruiken","We describe a framework for changing-contact robot manipulation tasks that
require the robot to make and break contacts with objects and surfaces. The
discontinuous interaction dynamics of such tasks make it difficult to construct
and use a single dynamics model or control strategy, and the highly non-linear
nature of the dynamics during contact changes can be damaging to the robot and
the objects. We present an adaptive control framework that enables the robot to
incrementally learn to predict contact changes in a changing contact task,
learn the interaction dynamics of the piece-wise continuous system, and provide
smooth and accurate trajectory tracking using a task-space variable impedance
controller. We experimentally compare the performance of our framework against
that of representative control methods to establish that the adaptive control
and incremental learning components of our framework are needed to achieve
smooth control in the presence of discontinuous dynamics in changing-contact
robot manipulation tasks.",http://arxiv.org/abs/2111.07753v1
"Quantification of fracture roughness by change probabilities and Hurst
  exponents",2021-11-16T17:48:54Z,"Tim Gutjahr, Sina Hale, Karsten Keller, Philipp Blum, Steffen Winter","The objective of the current study is to utilize an innovative method called
'change probabilities' for describing fracture roughness. In order to detect
and visualize anisotropy of rock joint surfaces, the roughness of
one-dimensional profiles taken in different directions is quantified. The
central quantifiers, 'change probabilities', are based on counting monotone
changes in discretizations of a profile. These probabilities, which are usually
varying with the scale, can be reinterpreted as scale-dependent Hurst
exponents. For a large class of Gaussian stochastic processes change
probabilities are shown to be directly related to the classical Hurst exponent,
which generalizes a relationship known for fractional Brownian motion. While
being related to this classical roughness measure, the proposed method is more
generally applicable, increasing therefore the flexibility of modeling and
investigating surface profiles. In particular, it allows a quick and efficient
visualization and detection of roughness anisotropy and scale dependence of
roughness.",http://arxiv.org/abs/2111.08661v1
"Some Clustering-based Change-point Detection Methods Applicable to High
  Dimension, Low Sample Size Data",2021-11-28T01:02:16Z,"Trisha Dawn, Angshuman Roy, Alokesh Manna, Anil K. Ghosh","Detection of change-points in a sequence of high-dimensional observations is
a very challenging problem, and this becomes even more challenging when the
sample size (i.e., the sequence length) is small. In this article, we propose
some change-point detection methods based on clustering, which can be
conveniently used in such high dimension, low sample size situations. First, we
consider the single change-point problem. Using k-means clustering based on
some suitable dissimilarity measures, we propose some methods for testing the
existence of a change-point and estimating its location. High-dimensional
behavior of these proposed methods are investigated under appropriate
regularity conditions. Next, we extend our methods for detection of multiple
change-points. We carry out extensive numerical studies to compare the
performance of our proposed methods with some state-of-the-art methods.",http://arxiv.org/abs/2111.14012v1
"Monitoring Deforestation Using Multivariate Bayesian Online Changepoint
  Detection with Outliers",2021-12-24T01:21:03Z,"Laura J. Wendelberger, Josh M. Gray, Brian J. Reich, Alyson G. Wilson","Near real time change detection is important for a variety of Earth
monitoring applications and remains a high priority for remote sensing science.
Data sparsity, subtle changes, seasonal trends, and the presence of outliers
make detecting actual landscape changes challenging. Adams and MacKay (2007)
introduced Bayesian Online Changepoint Detection (BOCPD), a computationally
efficient, exact Bayesian method for change detection. Incorporation of prior
information allows for relaxed dependence on dense data and an extensive stable
period, making this method applicable to relatively short time series and
multiple changepoint detection. In this paper we conduct BOCPD with a
multivariate linear regression framework that supports seasonal trends. We
introduce a mechanism to make BOCPD robust against occasional outliers without
compromising the computational efficiency of an exact posterior change
distribution nor the detection latency. We show via simulations that the method
effectively detects change in the presence of outliers. The method is then
applied to monitor deforestation in Myanmar where we show superior performance
compared to current online changepoint detection methods.",http://arxiv.org/abs/2112.12899v2
"Does chronology matter in JIT defect prediction? A Partial Replication
  Study",2021-03-05T07:33:38Z,"Hadi Jahanshahi, Dhanya Jothimani, Ayşe Başar, Mucahit Cevik","Just-In-Time (JIT) models detect the fix-inducing changes (or defect-inducing
changes). These models are designed based on the assumption that past code
change properties are similar to future ones. However, as the system evolves,
the expertise of developers and/or the complexity of the system also changes.
  In this work, we aim to investigate the effect of code change properties on
JIT models over time. We also study the impact of using recent data as well as
all available data on the performance of JIT models. Further, we analyze the
effect of weighted sampling on the performance of fix-inducing properties of
JIT models. For this purpose, we used datasets from Eclipse JDT, Mozilla,
Eclipse Platform, and PostgreSQL.
  We used five families of change-code properties such as size, diffusion,
history, experience, and purpose. We used Random Forest to train and test the
JIT model and Brier Score and the area under the ROC curve for performance
measurement.
  Our paper suggests that the predictive power of JIT models does not change
over time. Furthermore, we observed that the chronology of data in JIT defect
prediction models can be discarded by considering all the available data. On
the other hand, the importance score of families of code change properties is
found to oscillate over time.
  To mitigate the impact of the evolution of code change properties, it is
recommended to use a weighted sampling approach in which more emphasis is
placed upon the changes occurring closer to the current time. Moreover, since
properties such as ""Expertise of the Developer"" and ""Size"" evolve with time,
the models obtained from old data may exhibit different characteristics
compared to those employing the newer dataset. Hence, practitioners should
constantly retrain JIT models to include fresh data.",http://arxiv.org/abs/2103.03506v1
"Change Point Analysis of Multivariate Data: Using Multivariate
  Rank-based Distribution-free Nonparametric Testing via Measure Transportation
  with Applications in Tumor Microarrays and Dementia",2021-08-12T21:53:46Z,Amanda Ng,"In this paper, I propose a general algorithm for multiple change point
analysis via multivariate distribution-free nonparametric testing based on the
concept of ranks that are defined by measure transportation. Multivariate ranks
and the usual one-dimensional ranks both share an important property: they are
both distribution-free. This finding allows for the creation of nonparametric
tests that are distribution-free under the null hypothesis. This method has
applications in a variety of fields, and in this paper I implement this
algorithm to a microarray dataset for individuals with bladder tumors, an ECoG
snapshot for a patient with epilepsy, and in the context of trajectories of
CASI scores by education level and dementia status. Each change point denotes a
shift in the rate of change of Cognitive Abilities score over years, indicating
the existence of preclinical dementia. Here I will estimate the number of
change points and each of their locations within a multivariate series of
time-ordered observations. This paper will examine the multiple change point
question in a broad setting in which the observed distributions and number of
change points are unspecified, rather than assume the time series observations
follow a parametric model or there is one change point, as many works in this
area assume. The objective here is to create an algorithm for change point
detection while making as few assumptions about the dataset as possible.
Presented are the theoretical properties of this new algorithm and the
conditions under which the approximate number of change points and their
locations can be estimated. This algorithm has also been successfully
implemented in the R package recp, which is available on GitHub. A section of
this paper is dedicated to the execution of this procedure, as well as the use
of the recp package.",http://arxiv.org/abs/2108.05979v3
A Systematic Survey for z < 0.04 Changing-Look AGNs,2021-02-15T05:33:42Z,"Madhooshi R. Senarath, Michael J. I. Brown, Michelle E. Cluver, Thomas H. Jarrett, Christian Wolf, Nicholas P. Ross, John R. Lucey, Vaishali Parkash, Wei J. Hon","We have conducted a systematic survey for z $<$ 0.04 active Galactic nuclei
(AGNs) that may have changed spectral class over the past decade. We use
SkyMapper, Pan-STARRS and the V\'eron-Cetty & V\'eron (2010) catalogue to
search the entire sky for these ``changing-look'' AGNs using a variety of
selection methods, where Pan-STARRS has a coverage of 3$\pi$ steradians (sky
north of Declination $-30^\circ$) and SkyMapper has coverage of $\sim$
21,000$~\rm{deg^2}$ (sky south of Declination $0^\circ$). We use small aperture
photometry to measure how colour and flux have changed over time, where a
change may indicate a change in spectral type. Optical colour and flux are used
as a proxy for changing H$\alpha$ equivalent width, while WISE 3.4 $\mu$m flux
is used to look for changes in the hot dust component. We have identified four
AGNs with varying spectra selected using our optical colour selection method.
Three AGNs were confirmed from recent observations with WiFeS on the 2.3 m
telescope at Siding Spring and the other was identified from archival spectra
alone. From this, we identify two new changing look AGNs; NGC 1346 and 2MASX
J20075129-1108346. We also recover Mrk 915 and Mrk 609, which are known to have
varying spectra in the literature, but they do not meet our specific criteria
for changing look AGNs.",http://arxiv.org/abs/2102.07351v1
"Minimax and adaptive tests for detecting abrupt and possibly transitory
  changes in a Poisson process",2021-06-08T13:41:09Z,"Magalie Fromont, Fabrice Grela, Ronan Le Guével","Motivated by applications in cybersecurity and epidemiology, we consider the
problem of detecting an abrupt change in the intensity of a Poisson process,
characterised by a jump (non transitory change) or a bump (transitory change)
from constant. We propose a complete study from the nonasymptotic minimax
testing point of view, when the constant baseline intensity is known or
unknown. The question of minimax adaptation with respect to each parameter
(height, location, length) of the change is tackled, leading to a comprehensive
overview of the various minimax separation rate regimes. We exhibit three such
regimes and identify the factors of the two phase transitions, by giving the
cost of adaptation to each parameter. For each alternative hypothesis,
depending on the knowledge or not of each change parameter, we propose minimax
or minimax adaptive tests based on linear statistics, close to CUSUM
statistics, or quadratic statistics more adapted to the L 2-distance considered
in our minimax criteria and typically more powerful in practice, as our
simulation study shows. When the change location or length is unknown, our
adaptive tests are constructed from a scan aggregation principle combined with
Bonferroni or min-p level correction, and a conditioning trick when the
baseline intensity is unknown.",http://arxiv.org/abs/2106.04333v1
Online Continual Adaptation with Active Self-Training,2021-06-11T17:51:25Z,"Shiji Zhou, Han Zhao, Shanghang Zhang, Lianzhe Wang, Heng Chang, Zhi Wang, Wenwu Zhu","Models trained with offline data often suffer from continual distribution
shifts and expensive labeling in changing environments. This calls for a new
online learning paradigm where the learner can continually adapt to changing
environments with limited labels. In this paper, we propose a new online
setting -- Online Active Continual Adaptation, where the learner aims to
continually adapt to changing distributions using both unlabeled samples and
active queries of limited labels. To this end, we propose Online Self-Adaptive
Mirror Descent (OSAMD), which adopts an online teacher-student structure to
enable online self-training from unlabeled data, and a margin-based criterion
that decides whether to query the labels to track changing distributions.
Theoretically, we show that, in the separable case, OSAMD has an $O({T}^{2/3})$
dynamic regret bound under mild assumptions, which is aligned with the
$\Omega(T^{2/3})$ lower bound of online learning algorithms with full labels.
In the general case, we show a regret bound of $O({T}^{2/3} + \alpha^* T)$,
where $\alpha^*$ denotes the separability of domains and is usually small. Our
theoretical results show that OSAMD can fast adapt to changing environments
with active queries. Empirically, we demonstrate that OSAMD achieves favorable
regrets under changing environments with limited labels on both simulated and
real-world data, which corroborates our theoretical findings.",http://arxiv.org/abs/2106.06526v2
"Interactive Change Point Detection using optimisation approach and
  Bayesian statistics applied to real world applications",2021-06-17T17:46:05Z,"Rebecca Gedda, Larisa Beilina, Ruomu Tan","Change point detection becomes more and more important as datasets increase
in size, where unsupervised detection algorithms can help users process data.
To detect change points, a number of unsupervised algorithms have been
developed which are based on different principles. One approach is to define an
optimisation problem and minimise a cost function along with a penalty
function. In the optimisation approach, the choice of the cost function affects
the predictions made by the algorithm. In extension to the existing studies, a
new type of cost function using Tikhonov regularisation is introduced. Another
approach uses Bayesian statistics to calculate the posterior probability
distribution of a specific point being a change point. It uses a priori
knowledge on the distance between consecutive change points and a likelihood
function with information about the segments. The optimisation and Bayesian
approaches for offline change point detection are studied and applied to
simulated datasets as well as a real world multi-phase dataset. The approaches
have previously been studied separately and a novelty lies in comparing the
predictions made by the two approaches in a specific setting, consisting of
simulated datasets and a real world example. The study has found that the
performance of the change point detection algorithms are affected by the
features in the data.",http://arxiv.org/abs/2106.09691v1
"Modeling changing-look (CL) AGN phenomenon in 1D using accretion disk
  instabilities",2021-10-25T14:51:57Z,"Marzena Sniegowska, Mikolaj Grzedzielski, Bozena Czerny, Agnieszka Janiuk","Apart from regular, low-level stochastic variability, some AGN occasionally
show exceptionally large changes in the luminosity, spectral shape, and/or
X-ray absorption. The most notable are the changes of the spectral type when
the source classified as a Seyfert 1 becomes a Seyfert 2 galaxy or vice versa.
Thus a name was coined of 'Changing-Look AGN' (CL AGN). The origin of this
phenomenon is still unknown, but for most of the sources, there are strong
arguments in favor of the intrinsic changes. Understanding the nature of such
rapid changes is a challenge to the models of black hole accretion flows since
the timescales of the changes are much shorter than the standard disk viscous
timescales. We aim to model the CL AGN phenomenon assuming that the underlying
mechanism is the time-dependent evolution of a black hole accretion disk
unstable due to the dominant radiation pressure. We use a 1-dimensional,
vertically integrated disk model, but we allow for the presence of the hot
coronal layer above the disk and the presence of the inner purely hot flow. We
focus on the variability timescales and amplitudes, which can be regulated by
the action of large-scale magnetic fields, the description of the disk-corona
coupling, and the presence of an inner optically thin flow, like
Advection-Dominated Accretion Flow (ADAF). We compare model predictions for the
accretion disk around black hole mass 10$^7$M$_{\odot}$.",http://arxiv.org/abs/2110.13013v1
Optimal network online change point localisation,2021-01-14T07:24:39Z,"Yi Yu, Oscar Hernan Madrid Padilla, Daren Wang, Alessandro Rinaldo","We study the problem of online network change point detection. In this
setting, a collection of independent Bernoulli networks is collected
sequentially, and the underlying distributions change when a change point
occurs. The goal is to detect the change point as quickly as possible, if it
exists, subject to a constraint on the number or probability of false alarms.
In this paper, on the detection delay, we establish a minimax lower bound and
two upper bounds based on NP-hard algorithms and polynomial-time algorithms,
i.e., \[ \mbox{detection delay} \begin{cases} \gtrsim \log(1/\alpha)
\frac{\max\{r^2/n, \, 1\}}{\kappa_0^2 n \rho},\\ \lesssim \log(\Delta/\alpha)
\frac{\max\{r^2/n, \, \log(r)\}}{\kappa_0^2 n \rho}, & \mbox{with NP-hard
algorithms},\\ \lesssim \log(\Delta/\alpha) \frac{r}{\kappa_0^2 n \rho}, &
\mbox{with polynomial-time algorithms}, \end{cases} \] where $\kappa_0, n,
\rho, r$ and $\alpha$ are the normalised jump size, network size, entrywise
sparsity, rank sparsity and the overall Type-I error upper bound. All the model
parameters are allowed to vary as $\Delta$, the location of the change point,
diverges. The polynomial-time algorithms are novel procedures that we propose
in this paper, designed for quick detection under two different forms of Type-I
error control. The first is based on controlling the overall probability of a
false alarm when there are no change points, and the second is based on
specifying a lower bound on the expected time of the first false alarm.
Extensive experiments show that, under different scenarios and the
aforementioned forms of Type-I error control, our proposed approaches
outperform state-of-the-art methods.",http://arxiv.org/abs/2101.05477v1
"The thermodynamic principle determining the interface temperature during
  phase change",2021-02-15T18:20:15Z,"Tom Y. Zhao, Neelesh A. Patankar","What is the interface temperature during phase transition (for instance, from
liquid to vapor)? This question remains fundamentally unresolved. In the
modeling of heat transfer problems with no phase change, the temperature and
heat flux continuity conditions lead to the interface temperature. However, in
problems with phase change, the heat flux condition is used to determine the
amount of mass changing phase. This makes the interface temperature
indeterminate unless an additional condition is imposed. A common approach in
the modeling of boiling is to assume that the interface attains the saturation
temperature according some measure of pressure at the interface. This
assumption is usually applied even under highly non-equilibrium scenarios where
significant temperature gradients and mass transport occur across the
interface. In this work, an ab-initio thermodynamic principle is introduced
based on the entropy production at the interface that fully specifies the
associated temperature under non-equilibrium scenarios. Physically, the
thermodynamic principle provides a theoretical limit on the space of possible
phase change rates that can occur by associating the mass flux with a
corresponding interfacial entropy production rate; a stronger statement is made
that a system with sufficient degrees of freedom selects the maximum entropy
production, giving the observed phase change rate and associated interface
properties. This entropic principle captures experimental and computational
values of the interface temperature that can deviate by over $50\%$ from the
assumed saturation values. It also accounts for temperature jumps
(discontinuities) at the interface whose difference can exceed 15 degrees
Celcius. This thermodynamic principle is found to appropriately complete the
phase change problem.",http://arxiv.org/abs/2102.08825v1
"Segmentation of high dimensional means over multi-dimensional change
  points and connections to regression trees",2021-05-20T20:29:48Z,Abhishek Kaul,"This article is motivated by the objective of providing a new analytically
tractable and fully frequentist framework to characterize and implement
regression trees while also allowing a multivariate (potentially high
dimensional) response. The connection to regression trees is made by a high
dimensional model with dynamic mean vectors over multi-dimensional change axes.
Our theoretical analysis is carried out under a single two dimensional change
point setting. An optimal rate of convergence of the proposed estimator is
obtained, which in turn allows existence of limiting distributions.
Distributional behavior of change point estimates are split into two distinct
regimes, the limiting distributions under each regime is then characterized, in
turn allowing construction of asymptotically valid confidence intervals for
$2d$-location of change. All results are obtained under a high dimensional
scaling $s\log^2 p=o(T_wT_h),$ where $p$ is the response dimension, $s$ is a
sparsity parameter, and $T_w,T_h$ are sampling periods along change axes. We
characterize full regression trees by defining a multiple multi-dimensional
change point model. Natural extensions of the single $2d$-change point
estimation methodology are provided. Two applications, first on segmentation of
{\it Infra-red astronomy satellite (IRAS)} data and second to segmentation of
digital images are provided. Methodology and theoretical results are supported
with monte-carlo simulations.",http://arxiv.org/abs/2105.10017v1
"On robust learning in the canonical change point problem under heavy
  tailed errors in finite and growing dimensions",2021-05-25T00:52:45Z,"Debarghya Mukherjee, Moulinath Banerjee, Ya'acov Ritov","This paper presents a number of new findings about the canonical change point
estimation problem. The first part studies the estimation of a change point on
the real line in a simple stump model using the robust Huber estimating
function which interpolates between the $\ell_1$ (absolute deviation) and
$\ell_2$ (least squares) based criteria. While the $\ell_2$ criterion has been
studied extensively, its robust counterparts and in particular, the $\ell_1$
minimization problem have not. We derive the limit distribution of the
estimated change point under the Huber estimating function and compare it to
that under the $\ell_2$ criterion. Theoretical and empirical studies indicate
that it is more profitable to use the Huber estimating function (and in
particular, the $\ell_1$ criterion) under heavy tailed errors as it leads to
smaller asymptotic confidence intervals at the usual levels compared to the
$\ell_2$ criterion. We also compare the $\ell_1$ and $\ell_2$ approaches in a
parallel setting, where one has $m$ independent single change point problems
and the goal is to control the maximal deviation of the estimated change points
from the true values, and establish rigorously that the $\ell_1$ estimation
criterion provides a superior rate of convergence to the $\ell_2$, and that
this relative advantage is driven by the heaviness of the tail of the error
distribution. Finally, we derive minimax optimal rates for the change plane
estimation problem in growing dimensions and demonstrate that Huber estimation
attains the optimal rate while the $\ell_2$ scheme produces a rate sub-optimal
estimator for heavy tailed errors. In the process of deriving our results, we
establish a number of properties about the minimizers of compound Binomial and
compound Poisson processes which are of independent interest.",http://arxiv.org/abs/2105.11591v1
"Semantic-guided Pixel Sampling for Cloth-Changing Person
  Re-identification",2021-07-24T03:41:00Z,"Xiujun Shu, Ge Li, Xiao Wang, Weijian Ruan, Qi Tian","Cloth-changing person re-identification (re-ID) is a new rising research
topic that aims at retrieving pedestrians whose clothes are changed. This task
is quite challenging and has not been fully studied to date. Current works
mainly focus on body shape or contour sketch, but they are not robust enough
due to view and posture variations. The key to this task is to exploit
cloth-irrelevant cues. This paper proposes a semantic-guided pixel sampling
approach for the cloth-changing person re-ID task. We do not explicitly define
which feature to extract but force the model to automatically learn
cloth-irrelevant cues. Specifically, we first recognize the pedestrian's upper
clothes and pants, then randomly change them by sampling pixels from other
pedestrians. The changed samples retain the identity labels but exchange the
pixels of clothes or pants among different pedestrians. Besides, we adopt a
loss function to constrain the learned features to keep consistent before and
after changes. In this way, the model is forced to learn cues that are
irrelevant to upper clothes and pants. We conduct extensive experiments on the
latest released PRCC dataset. Our method achieved 65.8% on Rank1 accuracy,
which outperforms previous methods with a large margin. The code is available
at https://github.com/shuxjweb/pixel_sampling.git.",http://arxiv.org/abs/2107.11522v1
"Semantic Slicing of Architectural Change Commits: Towards Semantic
  Design Review",2021-09-02T00:45:54Z,"Amit Kumar Mondal, Chanchal K. Roy, Kevin A. Schneider, Banani Roy, Sristy Sumana Nath","Software architectural changes involve more than one module or component and
are complex to analyze compared to local code changes. Development teams aiming
to review architectural aspects (design) of a change commit consider many
essential scenarios such as access rules and restrictions on usage of program
entities across modules. Moreover, design review is essential when proper
architectural formulations are paramount for developing and deploying a system.
Untangling architectural changes, recovering semantic design, and producing
design notes are the crucial tasks of the design review process. To support
these tasks, we construct a lightweight tool [4] that can detect and decompose
semantic slices of a commit containing architectural instances. A semantic
slice consists of a description of relational information of involved modules,
their classes, methods and connected modules in a change instance, which is
easy to understand to a reviewer. We extract various directory and naming
structures (DANS) properties from the source code for developing our tool.
Utilizing the DANS properties, our tool first detects architectural change
instances based on our defined metric and then decomposes the slices (based on
string processing). Our preliminary investigation with ten open-source projects
(developed in Java and Kotlin) reveals that the DANS properties produce highly
reliable precision and recall (93-100%) for detecting and generating
architectural slices. Our proposed tool will serve as the preliminary approach
for the semantic design recovery and design summary generation for the project
releases.",http://arxiv.org/abs/2109.00659v1
Change of human mobility during COVID-19: A United States case study,2021-09-18T22:09:39Z,"Justin Elarde, Joon-Seok Kim, Hamdi Kavak, Andreas Züfle, Taylor Anderson","With the onset of COVID-19 and the resulting shelter in place guidelines
combined with remote working practices, human mobility in 2020 has been
dramatically impacted. Existing studies typically examine whether mobility in
specific localities increases or decreases at specific points in time and
relate these changes to certain pandemic and policy events. In this paper, we
study mobility change in the US through a five-step process using mobility
footprint data. (Step 1) Propose the delta Time Spent in Public Places
(Delta-TSPP) as a measure to quantify daily changes in mobility for each US
county from 2019-2020. (Step 2) Conduct Principal Component Analysis (PCA) to
reduce the Delta-TSPP time series of each county to lower-dimensional latent
components of change in mobility. (Step 3) Conduct clustering analysis to find
counties that exhibit similar latent components. (Step 4) Investigate local and
global spatial autocorrelation for each component. (Step 5) Conduct correlation
analysis to investigate how various population characteristics and behavior
correlate with mobility patterns. Results show that by describing each county
as a linear combination of the three latent components, we can explain 59% of
the variation in mobility trends across all US counties. Specifically, change
in mobility in 2020 for US counties can be explained as a combination of three
latent components: 1) long-term reduction in mobility, 2) no change in
mobility, and 3) short-term reduction in mobility. We observe significant
correlations between the three latent components of mobility change and various
population characteristics, including political leaning, population, COVID-19
cases and deaths, and unemployment. We find that our analysis provides a
comprehensive understanding of mobility change in response to the COVID-19
pandemic.",http://arxiv.org/abs/2109.09022v1
"Study of the Influence of an Evolving Galactic Potential on the Orbital
  Properties of 152 Globular clusters with Data from the Gaia EDR3 Catalogue",2021-09-22T08:05:51Z,"A. T. Bajkova, A. A. Smirnov, V. V. Bobylev","We have studied the influence of an evolving gravitational potential of the
Milky Way Galaxy on the orbital motion of 152 globular clusters with proper
motions from the Gaia EDR3 catalogue and mean distances from Baumgardt and
Vasiliev (2021). To construct a semicosmological evolving model potential with
changing masses and sizes of the Galactic components, we have used the
algorithm described in Haghi et al. (2015). The adopted axisymmetric
three-component model potential of the Galaxy includes a spherical bulge, a
flat Miyamoto--Nagai disk, and a spherical Navarro--Frenk--White dark matter
halo.The orbits are integrated backward in time. We compare the orbital
parameters of globular clusters derived in static and evolving potentials when
integrating the orbits for 5 and 12 Gyr backward. For the first time we have
studied the influence of separately a change in the masses and a change in the
sizes of the Galactic components. The changes in the masses and sizes of the
components are shown to act on the orbital parameters in the opposite way. At
small Galactocentric distances this influence is maximally compensated for. The
orbits of distant globular clusters and those with a large apocenter distance
undergo the biggest changes. We show that on time scales up to $-5$~Gyr the
orbits of globular clusters in the case of a potential with both changing
masses and changing sizes of the components undergo, on average, minor changes
compared to the case of a static potential. These changes fit into the limits
of the statistical uncertainties caused by the errors in the data. So, on these
time scales the Galactic potential may be deemed static. We provide tables with
the orbital parameters of globular clusters derived in both static and evolving
potentials.",http://arxiv.org/abs/2109.10570v1
"Online High-Dimensional Change-Point Detection using Topological Data
  Analysis",2021-02-27T03:43:57Z,"Xiaojun Zheng, Simon Mak, Yao Xie","Topological Data Analysis (TDA) is a rapidly growing field, which studies
methods for learning underlying topological structures present in complex data
representations. TDA methods have found recent success in extracting useful
geometric structures for a wide range of applications, including protein
classification, neuroscience, and time-series analysis. However, in many such
applications, one is also interested in sequentially detecting changes in this
topological structure. We propose a new method called Persistence Diagram based
Change-Point (PD-CP), which tackles this problem by integrating the widely-used
persistence diagrams in TDA with recent developments in nonparametric
change-point detection. The key novelty in PD-CP is that it leverages the
distribution of points on persistence diagrams for online detection of
topological changes. We demonstrate the effectiveness of PD-CP in an
application to solar flare monitoring.",http://arxiv.org/abs/2103.00117v2
"Multiscale change point detection via gradual bandwidth adjustment in
  moving sum processes",2021-03-01T15:15:46Z,"Tijana Levajkovic, Michael Messer","A method for the detection of changes in the expectation in univariate
sequences is provided. Moving sum processes are studied. These rely on the
selection of a tuning bandwidth. Here, a framework to overcome bandwidth
selection is presented - the bandwidth adjusts gradually. For that, moving sum
processes are made dependent on both time and the bandwidth: the domain becomes
a triangle. On the triangle, paths are constructed which systematically lead to
change points. An algorithm is provided that estimates change points by
subsequent consideration of paths. Strong consistency for the number and
location of change points is shown. Simulations support estimation precision. A
companion R-package mscp is made available on CRAN.",http://arxiv.org/abs/2103.01060v2
Minimizing Information Leakage of Abrupt Changes in Stochastic Systems,2021-03-02T11:41:10Z,"Alessio Russo, Alexandre Proutiere","This work investigates the problem of analyzing privacy of abrupt changes for
general Markov processes. These processes may be affected by changes, or
exogenous signals, that need to remain private. Privacy refers to the
disclosure of information of these changes through observations of the
underlying Markov chain. In contrast to previous work on privacy, we study the
problem for an online sequence of data. We use theoretical tools from optimal
detection theory to motivate a definition of online privacy based on the
average amount of information per observation of the stochastic system in
consideration. Two cases are considered: the full-information case, where the
eavesdropper measures all but the signals that indicate a change, and the
limited-information case, where the eavesdropper only measures the state of the
Markov process. For both cases, we provide ways to derive privacy upper-bounds
and compute policies that attain a higher privacy level. It turns out that the
problem of computing privacy-aware policies is concave, and we conclude with
some examples and numerical simulations for both cases.",http://arxiv.org/abs/2103.01658v2
"ChangeSim: Towards End-to-End Online Scene Change Detection in
  Industrial Indoor Environments",2021-03-09T11:36:29Z,"Jin-Man Park, Jae-Hyuk Jang, Sahng-Min Yoo, Sun-Kyung Lee, Ue-Hwan Kim, Jong-Hwan Kim","We present a challenging dataset, ChangeSim, aimed at online scene change
detection (SCD) and more. The data is collected in photo-realistic simulation
environments with the presence of environmental non-targeted variations, such
as air turbidity and light condition changes, as well as targeted object
changes in industrial indoor environments. By collecting data in simulations,
multi-modal sensor data and precise ground truth labels are obtainable such as
the RGB image, depth image, semantic segmentation, change segmentation, camera
poses, and 3D reconstructions. While the previous online SCD datasets evaluate
models given well-aligned image pairs, ChangeSim also provides raw unpaired
sequences that present an opportunity to develop an online SCD model in an
end-to-end manner, considering both pairing and detection. Experiments show
that even the latest pair-based SCD models suffer from the bottleneck of the
pairing process, and it gets worse when the environment contains the
non-targeted variations. Our dataset is available at
http://sammica.github.io/ChangeSim/.",http://arxiv.org/abs/2103.05368v2
"Covid-19 Discourse on Twitter: How the Topics, Sentiments, Subjectivity,
  and Figurative Frames Changed Over Time",2021-03-16T10:22:39Z,"Philipp Wicke, Marianna M. Bolognesi","The words we use to talk about the current epidemiological crisis on social
media can inform us on how we are conceptualizing the pandemic and how we are
reacting to its development. This paper provides an extensive explorative
analysis of how the discourse about Covid-19 reported on Twitter changes
through time, focusing on the first wave of this pandemic. Based on an
extensive corpus of tweets (produced between 20th March and 1st July 2020)
first we show how the topics associated with the development of the pandemic
changed through time, using topic modeling. Second, we show how the sentiment
polarity of the language used in the tweets changed from a relatively positive
valence during the first lockdown, toward a more negative valence in
correspondence with the reopening. Third we show how the average subjectivity
of the tweets increased linearly and fourth, how the popular and frequently
used figurative frame of WAR changed when real riots and fights entered the
discourse.",http://arxiv.org/abs/2103.08952v1
Epidemic change-point detection in general integer-valued time series,2021-03-24T16:46:19Z,"Mamadou Lamine Diop, William Kengne","In this paper, we consider the structural change in a class of discrete
valued time series, which the true conditional distribution of the observations
is assumed to be unknown.
  The conditional mean of the process depends on a parameter $\theta^*$ which
may change over time.
  We provide sufficient conditions for the consistency and the asymptotic
normality of the Poisson quasi-maximum likelihood estimator (QMLE) of the
model.
  We consider an epidemic change-point detection and propose a test statistic
based on the QMLE of the parameter. Under the null hypothesis of a constant
parameter (no change), the test statistic converges to a distribution obtained
from a difference of two Brownian bridge. The test statistic diverges to
infinity under the epidemic alternative, which establishes that the proposed
procedure is consistent in power. The effectiveness of the proposed procedure
is illustrated by simulated and real data examples.",http://arxiv.org/abs/2103.13336v2
City-scale Scene Change Detection using Point Clouds,2021-03-26T08:04:13Z,"Zi Jian Yew, Gim Hee Lee","We propose a method for detecting structural changes in a city using images
captured from vehicular mounted cameras over traversals at two different times.
We first generate 3D point clouds for each traversal from the images and
approximate GNSS/INS readings using Structure-from-Motion (SfM). A direct
comparison of the two point clouds for change detection is not ideal due to
inaccurate geo-location information and possible drifts in the SfM. To
circumvent this problem, we propose a deep learning-based non-rigid
registration on the point clouds which allows us to compare the point clouds
for structural change detection in the scene. Furthermore, we introduce a dual
thresholding check and post-processing step to enhance the robustness of our
method. We collect two datasets for the evaluation of our approach. Experiments
show that our method is able to detect scene changes effectively, even in the
presence of viewpoint and illumination differences.",http://arxiv.org/abs/2103.14314v1
Long-term and multi-wavelength evolution of a changing-look AGN Mrk 1018,2021-06-06T08:17:04Z,"Bing Lyu, Zhen Yan, Wenfei Yu, Qingwen Wu","The physical mechanism for triggering the changing-look phenomenon in active
galactic nuclei (AGNs) is still unclear. We explore this issue based on the
multi-wavelength spectral and flux variations for a changing-look AGN Mrk~1018
with long-term observations in the X-ray, optical/ultraviolet(UV), and radio
bands. Both the optical and the X-ray emission experience rapid decay in
changing-look phase during 2010--2015, where a re-flare appears in the
optical/UV and X-ray bands. We find a time lag of $\sim 20 $ days of optical/UV
behind X-ray variations in type 1.9 phase. The 5 GHz radio flux decreases by
$\sim 20$\% in type 1.9 phase during 2016--2017. We find both X-ray photon
index ($\Gamma$) and the optical-to-X-ray spectral index (\alphaox\,) are
anti-correlated with the Eddington scaled 2--10~keV X-ray luminosity
($L_\mathrm{X}/L_\mathrm{Edd}$) in the type 1.9 phase. However, the type 1
phase deviates from these two anti-correlations, which suggests that the change
of broad emission lines might be regulated by the evolution of accretion disk
(e.g., disappearing of the inner cold disk in the type 1.9 phase).",http://arxiv.org/abs/2106.03059v2
Ultra High Dimensional Change Point Detection,2021-06-09T07:50:23Z,"Xin Liu, Liwen Zhang, Zhen Zhang","Structural breaks have been commonly seen in applications. Specifically for
detection of change points in time, research gap still remains on the setting
in ultra high dimension, where the covariates may bear spurious correlations.
In this paper, we propose a two-stage approach to detect change points in ultra
high dimension, by firstly proposing the dynamic titled current correlation
screening method to reduce the input dimension, and then detecting possible
change points in the framework of group variable selection. Not only the
spurious correlation between ultra-high dimensional covariates is taken into
consideration in variable screening, but non-convex penalties are studied in
change point detection in the ultra high dimension. Asymptotic properties are
derived to guarantee the asymptotic consistency of the selection procedure, and
the numerical investigations show the promising performance of the proposed
approach.",http://arxiv.org/abs/2106.04869v1
"Spot the Difference: Detection of Topological Changes via Geometric
  Alignment",2021-06-09T11:49:23Z,"Steffen Czolbe, Aasa Feragen, Oswin Krause","Geometric alignment appears in a variety of applications, ranging from domain
adaptation, optimal transport, and normalizing flows in machine learning;
optical flow and learned augmentation in computer vision and deformable
registration within biomedical imaging. A recurring challenge is the alignment
of domains whose topology is not the same; a problem that is routinely ignored,
potentially introducing bias in downstream analysis. As a first step towards
solving such alignment problems, we propose an unsupervised algorithm for the
detection of changes in image topology. The model is based on a conditional
variational auto-encoder and detects topological changes between two images
during the registration step. We account for both topological changes in the
image under spatial variation and unexpected transformations. Our approach is
validated on two tasks and datasets: detection of topological changes in
microscopy images of cells, and unsupervised anomaly detection brain imaging.",http://arxiv.org/abs/2106.08233v2
Communication in Complex Networks,2021-06-23T08:01:02Z,"Omar De la Cruz Cabrera, Jiafeng Jin, Silvia Noschese, Lothar Reichel","One of the properties of interest in the analysis of networks is \emph{global
communicability}, i.e., how easy or difficult it is, generally, to reach nodes
from other nodes by following edges. Different global communicability measures
provide quantitative assessments of this property, emphasizing different
aspects of the problem.
  This paper investigates the sensitivity of global measures of communicability
to local changes. In particular, for directed, weighted networks, we study how
different global measures of communicability change when the weight of a single
edge is changed; or, in the unweighted case, when an edge is added or removed.
The measures we study include the \emph{total network communicability}, based
on the matrix exponential of the adjacency matrix, and the \emph{Perron network
communicability}, defined in terms of the Perron root of the adjacency matrix
and the associated left and right eigenvectors.
  Finding what local changes lead to the largest changes in global
communicability has many potential applications, including assessing the
resilience of a system to failure or attack, guidance for incremental system
improvements, and studying the sensitivity of global communicability measures
to errors in the network connection data.",http://arxiv.org/abs/2106.12215v2
"Online Verification of Deep Neural Networks under Domain Shift or
  Network Updates",2021-06-24T02:38:27Z,"Tianhao Wei, Changliu Liu","Although neural networks are widely used, it remains challenging to formally
verify the safety and robustness of neural networks in real-world applications.
Existing methods are designed to verify the network before deployment, which
are limited to relatively simple specifications and fixed networks. These
methods are not ready to be applied to real-world problems with complex and/or
dynamically changing specifications and networks. To effectively handle such
problems, verification needs to be performed online when these changes take
place. However, it is still challenging to run existing verification algorithms
online. Our key insight is that we can leverage the temporal dependencies of
these changes to accelerate the verification process. This paper establishes a
novel framework for scalable online verification to solve real-world
verification problems with dynamically changing specifications and/or networks.
We propose three types of acceleration algorithms: Branch Management to reduce
repetitive computation, Perturbation Tolerance to tolerate changes, and
Incremental Computation to reuse previous results. Experiment results show that
our algorithms achieve up to $100\times$ acceleration, and thus show a
promising way to extend neural network verification to real-world applications.",http://arxiv.org/abs/2106.12732v2
Score-Based Change Detection for Gradient-Based Learning Machines,2021-06-27T01:38:11Z,"Lang Liu, Joseph Salmon, Zaid Harchaoui","The widespread use of machine learning algorithms calls for automatic change
detection algorithms to monitor their behavior over time. As a machine learning
algorithm learns from a continuous, possibly evolving, stream of data, it is
desirable and often critical to supplement it with a companion change detection
algorithm to facilitate its monitoring and control. We present a generic
score-based change detection method that can detect a change in any number of
components of a machine learning model trained via empirical risk minimization.
This proposed statistical hypothesis test can be readily implemented for such
models designed within a differentiable programming framework. We establish the
consistency of the hypothesis test and show how to calibrate it to achieve a
prescribed false alarm rate. We illustrate the versatility of the approach on
synthetic and real data.",http://arxiv.org/abs/2106.14122v1
Detecting Changed-Hands Online Review Accounts,2021-06-25T16:41:32Z,"Geli Fei, Shuai Wang, Bing Liu, Leman Akoglu","A reputable social media or review account can be a good cover for spamming
activities. It has become prevalent that spammers buy/sell such accounts openly
on the Web. We call these sold/bought accounts the changed-hands (CH) accounts.
They are hard to detect by existing spam detection algorithms as their spamming
activities are under the disguise of clean histories. In this paper, we first
propose the problem of detecting CH accounts, and then design an effective
detection algorithm which exploits changes in content and writing styles of
individual accounts, and a proposed novel feature selection method that works
at a fine-grained level within each individual account. The proposed method not
only determines if an account has changed hands, but also pinpoints the change
point. Experimental results with online review accounts demonstrate the high
effectiveness of our approach.",http://arxiv.org/abs/2106.15352v1
"Evaluating the impact of increasing temperatures on changes in Soil
  Organic Carbon stocks: sensitivity analysis and non-standard discrete
  approximation",2021-07-30T20:57:30Z,"Fasma Diele, Ilenia Luiso, Carmela Marangi, Angela Martiradonna","A novel model is here introduced for the SOC change index defined as the
normalized difference between the actual Soil Organic Carbon and the value
assumed at an initial reference year. It is tailored on the RothC carbon model
dynamics and assumes as baseline the value of the SOC equilibrium under
constant environmental conditions. A sensitivity analysis is performed to
evaluate the response of the model to changes of temperature, Net Primary
Production (NPP), and land use soil class (forest, grassland, arable). A
non-standard monthly time-stepping procedure has been proposed to approximate
the SOC change index in the Alta Murgia National Park, a protected area in the
Italian Apulia region, selected as test site. In the case of arable class, the
SOC change index exhibits a negative trend which can be inverted by a suitable
organic fertilization program here proposed.",http://arxiv.org/abs/2108.00077v1
"Joint Link Rate Selection and Channel State Change Detection in
  Block-Fading Channels",2021-08-22T14:03:55Z,"Haoyue Tang, Xinyu Hou, Jintao Wang, Jian Song","In this work, we consider the problem of transmission rate selection for a
discrete time point-to-point block fading wireless communication link. The
wireless channel remains constant within the channel coherence time but can
change rapidly across blocks. The goal is to design a link rate selection
strategy that can identify the best transmission rate quickly and adaptively in
quasi-static channels. This problem can be cast into the stochastic bandit
framework, and the unawareness of time-stamps where channel changes
necessitates running change-point detection simultaneously with stochastic
bandit algorithms to improve adaptivity. We present a joint channel
change-point detection and link rate selection algorithm based on Thompson
Sampling (CD-TS) and show it can achieve a sublinear regret with respect to the
number of time steps $T$ when the channel coherence time is larger than a
threshold. We then improve the CD-TS algorithm by considering the fact that
higher transmission rate has higher packet-loss probability. Finally, we
validate the performance of the proposed algorithms through numerical
simulations.",http://arxiv.org/abs/2108.09728v1
"Revizor: A Data-Driven Approach to Automate Frequent Code Changes Based
  on Graph Matching",2021-08-25T12:29:59Z,"Oleg Smirnov, Artyom Lobanov, Yaroslav Golubev, Elena Tikhomirova, Timofey Bryksin","Many code changes that developers make in their projects are repeated and
constitute recurrent change patterns. It is of interest to collect such
patterns from the version history of open-source repositories and suggest the
most useful of them as quick fixes. In this paper, we present Revizor - a tool
aimed to build custom plugins for PyCharm, a popular Python IDE. A
Revizor-based plugin can take change patterns and highlight potential places
for their application in the developer's code editor. If the developer accepts
the quick fix, the plugin automatically performs the edit. Our approach uses a
graph-based representation of code changes, which allows it to support complex
distributed code patterns. Experienced developers have also rated the usability
and the performance of such Revizor-based plugin positively.
  The source code of the tool and test plugin prototype are available on
GitHub: https://github.com/JetBrains-Research/revizor. A demonstration video
with a short tool description can be found on YouTube:
https://youtu.be/5eLs14nco7E.",http://arxiv.org/abs/2108.11199v1
"Fast Online Changepoint Detection via Functional Pruning CUSUM
  statistics",2021-10-15T17:08:06Z,"Gaetano Romano, Idris Eckley, Paul Fearnhead, Guillem Rigaill","Many modern applications of online changepoint detection require the ability
to process high-frequency observations, sometimes with limited available
computational resources. Online algorithms for detecting a change in mean often
involve using a moving window, or specifying the expected size of change. Such
choices affect which changes the algorithms have most power to detect. We
introduce an algorithm, Functional Online CuSUM (FOCuS), which is equivalent to
running these earlier methods simultaneously for all sizes of window, or all
possible values for the size of change. Our theoretical results give tight
bounds on the expected computational cost per iteration of FOCuS, with this
being logarithmic in the number of observations. We show how FOCuS can be
applied to a number of different change in mean scenarios, and demonstrate its
practical utility through its state-of-the art performance at detecting
anomalous behaviour in computer server data.",http://arxiv.org/abs/2110.08205v3
Ctrl-Shift: How Privacy Sentiment Changed from 2019 to 2021,2021-10-18T16:13:02Z,"Angelica Goetzen, Samuel Dooley, Elissa M. Redmiles","People's privacy sentiments influence changes in legislation as well as
technology design and use. While single-point-in-time investigations of privacy
sentiment offer useful insight, study of people's privacy sentiments over time
is also necessary to better understand and anticipate evolving privacy
attitudes. In this work, we use repeated cross-sectional surveys (n=6,676) to
model the sentiments of people in the U.S. toward collection and use of data
for government- and health-related purposes from 2019-2021. After the onset of
COVID-19, we observe significant decreases in respondent acceptance of
government data use and significant increases in acceptance of health-related
data uses. While differences in privacy attitudes between sociodemographic
groups largely decreased over this time period, following the 2020 U.S.
national elections, we observe some of the first evidence that privacy
sentiments may change based on the alignment between a user's politics and the
political party in power. Our results offer insight into how privacy attitudes
may have been impacted by recent events and allow us to identify potential
predictors of changes in privacy attitudes during times of geopolitical or
national change.",http://arxiv.org/abs/2110.09437v2
Pressure-driven phase transitions in bulk HfS$_2$,2021-10-21T09:02:21Z,"M. Grzeszczyk, J. Gawraczyński, T. Woźniak, J. Ibáñez, Z. Muhammad, W. Zhao, M. R. Molas, A. Babiński","The effect of hydrostatic pressure up to 27 GPa on the Raman scattering (RS)
in bulk HfS$_2$ is investigated. There are two transformations of RS spectra,
which take place during compression at pressure between 5.7 GPa and 9.8 GPa as
well as between 12.8 GPa and 15.2 GPa. Seven vibrational modes can be observed
after the transformation, as compared to four modes before the transformation.
The observed change suggests structural change in the material of yet unknown
nature. The frequencies of the RS modes observed above the transformation
change linearly with pressure and corresponding pressure coefficients have been
determined. The other transition manifests itself as a change in the RS
lineshape. While a series of well-defined RS modes are observed under pressure
below the transition, broad spectral bands can be seen at higher pressure. The
overall lineshape of the spectra resembles that of disordered materials. The
lineshape does not change during decompression, which suggests permanent nature
of the high-pressure transition.",http://arxiv.org/abs/2110.10991v1
Employing chunk size adaptation to overcome concept drift,2021-10-25T12:36:22Z,"Jędrzej Kozal, Filip Guzy, Michał Woźniak","Modern analytical systems must be ready to process streaming data and
correctly respond to data distribution changes. The phenomenon of changes in
data distributions is called concept drift, and it may harm the quality of the
used models. Additionally, the possibility of concept drift appearance causes
that the used algorithms must be ready for the continuous adaptation of the
model to the changing data distributions. This work focuses on non-stationary
data stream classification, where a classifier ensemble is used. To keep the
ensemble model up to date, the new base classifiers are trained on the incoming
data blocks and added to the ensemble while, at the same time, outdated models
are removed from the ensemble. One of the problems with this type of model is
the fast reaction to changes in data distributions. We propose a new Chunk
Adaptive Restoration framework that can be adapted to any block-based data
stream classification algorithm. The proposed algorithm adjusts the data chunk
size in the case of concept drift detection to minimize the impact of the
change on the predictive performance of the used model. The conducted
experimental research, backed up with the statistical tests, has proven that
Chunk Adaptive Restoration significantly reduces the model's restoration time.",http://arxiv.org/abs/2110.12881v1
"Self-supervised pre-training enhances change detection in Sentinel-2
  imagery",2021-01-20T13:47:25Z,"Marrit Leenstra, Diego Marcos, Francesca Bovolo, Devis Tuia","While annotated images for change detection using satellite imagery are
scarce and costly to obtain, there is a wealth of unlabeled images being
generated every day. In order to leverage these data to learn an image
representation more adequate for change detection, we explore methods that
exploit the temporal consistency of Sentinel-2 times series to obtain a usable
self-supervised learning signal. For this, we build and make publicly available
(https://zenodo.org/record/4280482) the Sentinel-2 Multitemporal Cities Pairs
(S2MTCP) dataset, containing multitemporal image pairs from 1520 urban areas
worldwide. We test the results of multiple self-supervised learning methods for
pre-training models for change detection and apply it on a public change
detection dataset made of Sentinel-2 image pairs (OSCD).",http://arxiv.org/abs/2101.08122v2
On detecting weak changes in the mean of CHARN models,2021-01-21T13:26:47Z,"Joseph Ngatchou-Wandji, Marwa Ltaifa","We study a likelihood ratio test for detecting multiple {\it weak} changes in
the mean of a class of CHARN models. The locally asymptotically normal (LAN)
structure of the family of likelihoods under study is established. It results
that the test is asymptotically optimal, and an explicit form of its asymptotic
local power is given as a function of candidates change locations and changes
magnitudes. Strategies for weak change-points detection and their locations
estimates are described. The estimates are obtained as the time indices
maximizing an estimate of the local power. A simulation study shows the good
performance of our methods compared to some existing approaches. Our results
are also applied to three sets of real data.",http://arxiv.org/abs/2101.08597v2
"Spectroscopic monitoring of the candidate tidal disruption event in
  F01004-2237",2021-01-24T12:04:12Z,"Giacomo Cannizzaro, Peter G. Jonker, Daniel Mata-Sánchez","We present results of spectroscopic monitoring observations of the
Ultra-Luminous Infra Red Galaxy F01004-2237. This galaxy was observed to
undergo changes in its optical spectrum, detected by comparing a spectrum from
2015 with one from 2000. These changes were coincident with photometric
brightening. The main changes detected in the optical spectrum are enhanced He
II $\lambda$4686 emission and the appearance of He I
$\lambda$3898,$\lambda$5876 emission lines. The favoured interpretation of
these changes was that of a tidal disruption event (TDE) happening in 2010.
However, subsequent work suggested that these changes are caused by another
hitherto unknown reason related to variations in the accretion rate in the
active galactic nucleus (AGN). Our optical spectroscopic monitoring
observations show that the evolution of the He lines is in line with the
evolution seen in TDEs and opposite of what observed from reverberation mapping
studies of AGNs, renewing the discussion on the interpretation of the flare as
a TDE.",http://arxiv.org/abs/2101.09694v1
Adaptive Inference for Change Points in High-Dimensional Data,2021-01-29T02:05:21Z,"Yangfan Zhang, Runmin Wang, Xiaofeng Shao","In this article, we propose a class of test statistics for a change point in
the mean of high-dimensional independent data. Our test integrates the
U-statistic based approach in a recent work by \cite{hdcp} and the $L_q$-norm
based high-dimensional test in \cite{he2018}, and inherits several appealing
features such as being tuning parameter free and asymptotic independence for
test statistics corresponding to even $q$s. A simple combination of test
statistics corresponding to several different $q$s leads to a test with
adaptive power property, that is, it can be powerful against both sparse and
dense alternatives. On the estimation front, we obtain the convergence rate of
the maximizer of our test statistic standardized by sample size when there is
one change-point in mean and $q=2$, and propose to combine our tests with a
wild binary segmentation (WBS) algorithm to estimate the change-point number
and locations when there are multiple change-points. Numerical comparisons
using both simulated and real data demonstrate the advantage of our adaptive
test and its corresponding estimation method.",http://arxiv.org/abs/2101.12357v1
"Urban Change Detection by Fully Convolutional Siamese Concatenate
  Network with Attention",2021-01-31T17:47:16Z,"Farnoosh Heidary, Mehran Yazdi, Maryam Dehghani, Peyman Setoodeh","Change detection (CD) is an important problem in remote sensing, especially
in disaster time for urban management. Most existing traditional methods for
change detection are categorized based on pixel or objects. Object-based models
are preferred to pixel-based methods for handling very high-resolution remote
sensing (VHR RS) images. Such methods can benefit from the ongoing research on
deep learning. In this paper, a fully automatic change-detection algorithm on
VHR RS images is proposed that deploys Fully Convolutional Siamese Concatenate
networks (FC-Siam-Conc). The proposed method uses preprocessing and an
attention gate layer to improve accuracy. Gaussian attention (GA) as a soft
visual attention mechanism is used for preprocessing. GA helps the network to
handle feature maps like biological visual systems. Since the GA parameters
cannot be adjusted during network training, an attention gate layer is
introduced to play the role of GA with parameters that can be tuned among other
network parameters. Experimental results obtained on Onera Satellite Change
Detection (OSCD) and RIVER-CD datasets confirm the superiority of the proposed
architecture over the state-of-the-art algorithms.",http://arxiv.org/abs/2102.00501v1
"A study of referencing changes in preprint-publication pairs across
  multiple fields",2021-02-05T11:21:40Z,"Aliakbar Akbaritabar, Dimity Stephen, Flaminio Squazzoni","Manuscripts have a complex development process with multiple influencing
factors. Reconstructing this process is difficult without large-scale,
comparable data on different versions of manuscripts. Preprints are
increasingly available and may provide access to the earliest manuscript
versions. Here, we matched 6,024 preprint-publication pairs across multiple
fields and examined changes in their reference lists between the manuscript
versions as one aspect of manuscripts' development. We also qualitatively
analysed the context of references to investigate the potential reasons for
changes. We found that 90 percent of references were unchanged between versions
and 8 percent were newly added. We found that manuscripts in the natural and
medical sciences undergo more extensive reframing of the literature while
changes in engineering mostly focused on methodological details. Our
qualitative analysis suggests that peer review increases the methodological
soundness of scientific claims, improves the communication of findings, and
ensures appropriate credit for previous research.",http://arxiv.org/abs/2102.03110v2
"Scalable Inference of Sparsely-changing Markov Random Fields with Strong
  Statistical Guarantees",2021-02-06T13:53:00Z,"Salar Fattahi, Andres Gomez","In this paper, we study the problem of inferring time-varying Markov random
fields (MRF), where the underlying graphical model is both sparse and changes
sparsely over time. Most of the existing methods for the inference of
time-varying MRFs rely on the regularized maximum likelihood estimation (MLE),
that typically suffer from weak statistical guarantees and high computational
time. Instead, we introduce a new class of constrained optimization problems
for the inference of sparsely-changing MRFs. The proposed optimization problem
is formulated based on the exact $\ell_0$ regularization, and can be solved in
near-linear time and memory. Moreover, we show that the proposed estimator
enjoys a provably small estimation error. As a special case, we derive sharp
statistical guarantees for the inference of sparsely-changing Gaussian MRFs
(GMRF) in the high-dimensional regime, showing that such problems can be
learned with as few as one sample per time. Our proposed method is extremely
efficient in practice: it can accurately estimate sparsely-changing graphical
models with more than 500 million variables in less than one hour.",http://arxiv.org/abs/2102.03585v1
"Evidence for distinctive changes in the solar wind helium abundance in
  cycle 24",2021-02-10T11:59:44Z,"Yogesh, D. Chakrabarty, N. Srivastava","The relative abundance of alpha particles with respect to proton, usually
expressed as $A_{He}$ = ($n_\alpha/n_p$)*100, is known to respond to solar
activity although changes in its behaviour in the last four solar cycles are
not known. In this letter, by systematically analysing inter-calibrated
$A_{He}$ data obtained from the first Lagrangian point of the Sun-Earth system,
we show that $A_{He}$ variations are distinctively different in solar cycle 24
as compared to the last three cycles. The frequency of $A_{He}$ = 2-3% events
is significantly higher in slow/intermediate solar winds in cycle 24 as opposed
to the dominance of the typical $A_{He}$ = 4-5% events in the previous three
cycles. Further, the occurrence of $A_{He}$ $\geq$ 10% events is significantly
reduced in cycle 24. Not only that, the changes in delay of $A_{He}$ with
respect to peak sunspot numbers are less sensitive to changes in solar wind
velocity in cycle 24. The investigation suggests that the coronal magnetic
field configuration started undergoing systematic changes starting from cycle
23 and this altered magnetic field configuration affected the way helium got
processed and depleted in the solar atmosphere.",http://arxiv.org/abs/2102.05395v1
"Sequential change-point detection for mutually exciting point processes
  over networks",2021-02-10T20:20:06Z,"Haoyun Wang, Liyan Xie, Yao Xie, Alex Cuozzo, Simon Mak","We present a new CUSUM procedure for sequentially detecting change-point in
the self and mutual exciting processes, a.k.a. Hawkes networks using discrete
events data. Hawkes networks have become a popular model for statistics and
machine learning due to their capability in modeling irregularly observed data
where the timing between events carries a lot of information. The problem of
detecting abrupt changes in Hawkes networks arises from various applications,
including neuronal imaging, sensor network, and social network monitoring.
Despite this, there has not been a computationally and memory-efficient online
algorithm for detecting such changes from sequential data. We present an
efficient online recursive implementation of the CUSUM statistic for Hawkes
processes, both decentralized and memory-efficient, and establish the
theoretical properties of this new CUSUM procedure. We then show that the
proposed CUSUM method achieves better performance than existing methods,
including the Shewhart procedure based on count data, the generalized
likelihood ratio (GLR) in the existing literature, and the standard score
statistic. We demonstrate this via a simulated example and an application to
population code change-detection in neuronal networks.",http://arxiv.org/abs/2102.05724v2
Optimality of Graph Scanning Statistic for Online Community Detection,2021-02-11T02:58:41Z,"Liyan Xie, Yao Xie","Sequential change-point detection for graphs is a fundamental problem for
streaming network data types and has wide applications in social networks and
power systems. Given fixed vertices and a sequence of random graphs, the
objective is to detect the change-point where the underlying distribution of
the random graph changes. In particular, we focus on the local change that only
affects a subgraph. We adopt the classical Erdos-Renyi model and revisit the
generalized likelihood ratio (GLR) detection procedure. The scan statistic is
computed by sequentially estimating the most-likely subgraph where the change
happens. We provide theoretical analysis for the asymptotic optimality of the
proposed procedure based on the GLR framework. We demonstrate the efficiency of
our detection algorithm using simulations.",http://arxiv.org/abs/2102.05821v1
"Contrastive latent variable modeling with application to case-control
  sequencing experiments",2021-02-12T19:26:03Z,"Andrew Jones, F. William Townes, Didong Li, Barbara E. Engelhardt","High-throughput RNA-sequencing (RNA-seq) technologies are powerful tools for
understanding cellular state. Often it is of interest to quantify and summarize
changes in cell state that occur between experimental or biological conditions.
Differential expression is typically assessed using univariate tests to measure
gene-wise shifts in expression. However, these methods largely ignore changes
in transcriptional correlation. Furthermore, there is a need to identify the
low-dimensional structure of the gene expression shift to identify collections
of genes that change between conditions. Here, we propose contrastive latent
variable models designed for count data to create a richer portrait of
differential expression in sequencing data. These models disentangle the
sources of transcriptional variation in different conditions, in the context of
an explicit model of variation at baseline. Moreover, we develop a model-based
hypothesis testing framework that can test for global and gene subset-specific
changes in expression. We test our model through extensive simulations and
analyses with count-based gene expression data from perturbation and
observational sequencing experiments. We find that our methods can effectively
summarize and quantify complex transcriptional changes in case-control
experimental sequencing data.",http://arxiv.org/abs/2102.06731v1
"Using a Cognitive Network Model of Moral and Social Beliefs to Explain
  Belief Change",2021-02-22T03:29:35Z,"Jonas Dalege, Tamara van der Does","Scepticism towards childhood vaccines and genetically modified food has grown
despite scientific evidence of their safety. Beliefs about scientific issues
are difficult to change because they are entrenched within many related moral
concerns and beliefs about what others think. We propose a cognitive network
model which estimates the relationships, dissonance, and randomness between all
related beliefs to derive predictions of the circumstances under which beliefs
change. Using a probabilistic nationally representative longitudinal study, we
found support for our model's predictions: Randomness of the belief networks
decreased over time, for many participants their estimated dissonance related
positively to their self-reported dissonance, and individuals who had high
estimated dissonance of their belief network were more likely to change their
beliefs to reduce this dissonance. This study is the first to combine a
unifying predictive model with an experimental intervention and sheds light on
dynamics of dissonance reduction leading to belief change.",http://arxiv.org/abs/2102.10751v3
"Change Matters: Medication Change Prediction with Recurrent Residual
  Networks",2021-05-05T05:51:30Z,"Chaoqi Yang, Cao Xiao, Lucas Glass, Jimeng Sun","Deep learning is revolutionizing predictive healthcare, including
recommending medications to patients with complex health conditions. Existing
approaches focus on predicting all medications for the current visit, which
often overlaps with medications from previous visits. A more clinically
relevant task is to identify medication changes.
  In this paper, we propose a new recurrent residual network, named MICRON, for
medication change prediction. MICRON takes the changes in patient health
records as input and learns to update a hidden medication vector and the
medication set recurrently with a reconstruction design. The medication vector
is like the memory cell that encodes longitudinal information of medications.
Unlike traditional methods that require the entire patient history for
prediction, MICRON has a residual-based inference that allows for sequential
updating based only on new patient features (e.g., new diagnoses in the recent
visit) more efficiently.
  We evaluated MICRON on real inpatient and outpatient datasets. MICRON
achieves 3.5% and 7.8% relative improvements over the best baseline in F1
score, respectively. MICRON also requires fewer parameters, which significantly
reduces the training time to 38.3s per epoch with 1.5x speed-up.",http://arxiv.org/abs/2105.01876v1
"Stress-Energy in the Conical Vacuum and its Implications for Topology
  Change",2021-05-07T19:42:25Z,Eric B. Jones,"This dissertation presents a semiclassical analysis of conical topology
change in $1+1$ spacetime dimensions wherein, to lowest order, the ambient
spacetime is classical and fixed while the scalar field coupled to it is
quantized. The vacuum expectation value of the scalar field stress-energy
tensor is calculated via two different approaches. The first of these involves
the explicit determination of the so called Sorkin-Johnston state on the cone
and an original regularization scheme, while the latter employs the conformal
vacuum and the more conventional point-splitting renormalization. It is found
that conical topology change seems not to suffer from the same pathologies that
trousers-type topology change does. This provides tentative agreement with
conjectures due to Sorkin and Borde, which attempt to classify topology
changing spacetimes with respect to their Morse critical points and in
particular, that the cone and yarmulke in $1+1$ dimensions lack critical points
of unit Morse index.",http://arxiv.org/abs/2105.03477v1
Collective anomaly detection in High-dimensional VAR Models,2021-05-16T22:53:52Z,"Hyeyoung Maeng, Idris Eckley, Paul Fearnhead","There is increasing interest in detecting collective anomalies: potentially
short periods of time where the features of data change before reverting back
to normal behaviour. We propose a new method for detecting a collective anomaly
in VAR models. Our focus is on situations where the change in the VAR
coefficient matrix at an anomaly is sparse, i.e. a small number of entries of
the VAR coefficient matrix change. To tackle this problem, we propose a test
statistic for a local segment that is built on the lasso estimator of the
change in model parameters. This enables us to detect a sparse change more
efficiently and our lasso-based approach becomes especially advantageous when
the anomalous interval is short. We show that the new procedure controls Type 1
error and has asymptotic power tending to one. The practicality of our approach
is demonstrated through simulations and two data examples, involving New York
taxi trip data and EEG data.",http://arxiv.org/abs/2105.07538v1
"Room to Grow: Understanding Personal Characteristics Behind Self
  Improvement Using Social Media",2021-05-17T17:30:30Z,"MeiXing Dong, Xueming Xu, Yiwei Zhang, Ian Stewart, Rada Mihalcea","Many people aim for change, but not everyone succeeds. While there are a
number of social psychology theories that propose motivation-related
characteristics of those who persist with change, few computational studies
have explored the motivational stage of personal change. In this paper, we
investigate a new dataset consisting of the writings of people who manifest
intention to change, some of whom persist while others do not. Using a variety
of linguistic analysis techniques, we first examine the writing patterns that
distinguish the two groups of people. Persistent people tend to reference more
topics related to long-term self-improvement and use a more complicated writing
style. Drawing on these consistent differences, we build a classifier that can
reliably identify the people more likely to persist, based on their language.
Our experiments provide new insights into the motivation-related behavior of
people who persist with their intention to change.",http://arxiv.org/abs/2105.08031v1
A Bayesian change point model for spatio-temporal data,2021-05-22T04:38:08Z,"Candace Berrett, Brianne Gurney, David Arthur, Todd Moon, Gus P. Williams","Urbanization of an area is known to increase the temperature of the
surrounding area. This phenomenon -- a so-called urban heat island (UHI) --
occurs at a local level over a period of time and has lasting impacts for
historical data analysis. We propose a methodology to examine if long-term
changes in temperature increases and decreases across time exist (and to what
extent) at the local level for a given set of temperature readings at various
locations. Specifically, we propose a Bayesian change point model for
spatio-temporally dependent data where we select the number of change points at
each location using a ""forwards"" selection process using deviance information
criteria (DIC). We then fit the selected model and examine the linear slopes
across time to quantify changes in long-term temperature behavior. We show the
utility of this model and method using a synthetic data set and temperature
measurements from eight stations in Utah consisting of daily temperature data
for 60 years.",http://arxiv.org/abs/2105.10637v2
Controlling Text Edition by Changing Answers of Specific Questions,2021-05-23T20:44:15Z,"Lei Sha, Patrick Hohenecker, Thomas Lukasiewicz","In this paper, we introduce the new task of controllable text edition, in
which we take as input a long text, a question, and a target answer, and the
output is a minimally modified text, so that it fits the target answer. This
task is very important in many situations, such as changing some conditions,
consequences, or properties in a legal document, or changing some key
information of an event in a news text. This is very challenging, as it is hard
to obtain a parallel corpus for training, and we need to first find all text
positions that should be changed and then decide how to change them. We
constructed the new dataset WikiBioCTE for this task based on the existing
dataset WikiBio (originally created for table-to-text generation). We use
WikiBioCTE for training, and manually labeled a test set for testing. We also
propose novel evaluation metrics and a novel method for solving the new task.
Experimental results on the test set show that our proposed method is a good
fit for this novel NLP task.",http://arxiv.org/abs/2105.11018v1
Multifractal test for nonlinear changes in time series,2021-05-26T17:41:12Z,"Damian G. Kelty-Stephen, Elizabeth Lane, Madhur Mangalam","The creativity and emergence of biological and psychological behavior are
nonlinear. However, that does not necessarily mean only that the measurements
of the behaviors are curvilinear. Furthermore, the linear model might fail to
reduce these measurements to a sum of independent random factors, implying
nonlinear changes over time. The present work reviews some of the concepts
implicated in linear changes over time and details the mathematical steps
involved. It introduces multifractality as a mathematical framework helpful in
determining whether and to what degree the measured time series exhibits
nonlinear changes over time. The mathematical steps include multifractal
analysis and surrogate data production for resolving when multifractality
entails nonlinear changes over time. Ultimately, when measurements fail to fit
the structures of the traditional linear model, multifractal modeling gives us
the means to make those nonlinear excursions explicit and perhaps permit the
development of theory that draws on both linear and nonlinear processes.",http://arxiv.org/abs/2105.13113v1
Projected mushroom-type phase-change memory,2021-05-28T09:34:23Z,"Syed Ghazi Sarwat, Timothy M. Philip, Ching-Tzu Chen, Benedikt Kersting, Robert L Bruce, Cheng-Wei Cheng, Ning Li, Nicole Saulnier, Matthew BrightSky, Abu Sebastian","Phase-change memory devices have found applications in in-memory computing
where the physical attributes of these devices are exploited to compute in
place without the need to shuttle data between memory and processing units.
However, non-idealities such as temporal variations in the electrical
resistance have a detrimental impact on the achievable computational precision.
To address this, a promising approach is projecting the phase configuration of
phase change material onto some stable element within the device. Here we
investigate the projection mechanism in a prominent phase-change memory device
architecture, namely mushroom-type phase-change memory. Using nanoscale
projected Ge2Sb2Te5 devices we study the key attributes of state-dependent
resistance, drift coefficients, and phase configurations, and using them reveal
how these devices fundamentally work.",http://arxiv.org/abs/2105.13693v2
"Price change prediction of ultra high frequency financial data based on
  temporal convolutional network",2021-07-01T07:31:37Z,"Wei Dai, Yuan An, Wen Long","Through in-depth analysis of ultra high frequency (UHF) stock price change
data, more reasonable discrete dynamic distribution models are constructed in
this paper. Firstly, we classify the price changes into several categories.
Then, temporal convolutional network (TCN) is utilized to predict the
conditional probability for each category. Furthermore, attention mechanism is
added into the TCN architecture to model the time-varying distribution for
stock price change data. Empirical research on constituent stocks of Chinese
Shenzhen Stock Exchange 100 Index (SZSE 100) found that the TCN framework model
and the TCN (attention) framework have a better overall performance than GARCH
family models and the long short-term memory (LSTM) framework model for the
description of the dynamic process of the UHF stock price change sequence. In
addition, the scale of the dataset reached nearly 10 million, to the best of
our knowledge, there has been no previous attempt to apply TCN to such a
large-scale UHF transaction price dataset in Chinese stock market.",http://arxiv.org/abs/2107.00261v1
"The Changing Lightcurve of the Double-Mode RR Lyrae Variable Star V338
  Boo",2021-07-08T18:07:55Z,"Kenneth Carrell, Ronald Wilhelm, Faith Olsen, Andrew Tom, Garath Vetters, Anna McElhannon","We present an analysis of the lightcurve extracted from Transiting Exoplanet
Survey Satellite Full Frame Images of the double-mode RR Lyrae V338 Boo. We
find that the fundamental mode pulsation is changing in amplitude across the 54
days of observations. The first overtone mode pulsation also changes, but on a
much smaller scale. Harmonics and combinations of the primary pulsation modes
also exhibit unusual behavior. Possible connections with other changes in RR
Lyrae pulsations are discussed, but a full understanding of the cause of the
changes seen in V338 Boo should shed light on some of the most difficult and
unanswered questions in stellar pulsation theory, and astrophysics more
generally.",http://arxiv.org/abs/2107.04054v1
"Skellam and Time-Changed Variants of the Generalized Fractional Counting
  Process",2021-07-17T19:43:21Z,"K. K. Kataria, M. Khandakar","In this paper, we study a Skellam type variant of the generalized counting
process (GCP), namely, the generalized Skellam process. Some of its
distributional properties such as the probability mass function, probability
generating function, mean, variance and covariance are obtained. Its fractional
version, namely, the generalized fractional Skellam process (GFSP) is
considered by time-changing it with an independent inverse stable subordinator.
It is observed that the GFSP is a Skellam type version of the generalized
fractional counting process (GFCP) which is a fractional variant of the GCP. It
is shown that the one-dimensional distributions of the GFSP are not infinitely
divisible. An integral representation for its state probabilities is obtained.
We establish its long-range dependence property by using its variance and
covariance structure. Also, we consider two time-changed versions of the GFCP.
These are obtained by time-changing the GFCP by an independent L\'evy
subordinator and its inverse. Some particular cases of these time-changed
processes are discussed by considering specific L\'evy subordinators.",http://arxiv.org/abs/2107.08307v1
Unsupervised clothing change adaptive person ReID,2021-09-08T15:08:10Z,"Ziyue Zhang, Shuai Jiang, Congzhentao Huang, Richard YiDa Xu","Clothing changes and lack of data labels are both crucial challenges in
person ReID. For the former challenge, people may occur multiple times at
different locations wearing different clothing. However, most of the current
person ReID research works focus on the benchmarks in which a person's clothing
is kept the same all the time. For the last challenge, some researchers try to
make model learn information from a labeled dataset as a source to an unlabeled
dataset. Whereas purely unsupervised training is less used. In this paper, we
aim to solve both problems at the same time. We design a novel unsupervised
model, Sync-Person-Cloud ReID, to solve the unsupervised clothing change person
ReID problem. We developer a purely unsupervised clothing change person ReID
pipeline with person sync augmentation operation and same person feature
restriction. The person sync augmentation is to supply additional same person
resources. These same person's resources can be used as part supervised input
by same person feature restriction. The extensive experiments on clothing
change ReID datasets show the out-performance of our methods.",http://arxiv.org/abs/2109.03702v2
Automatic Y-axis Rescaling in Dynamic Visualizations,2021-09-20T15:20:51Z,"Jacob Fisher, Remco Chang, Eugene Wu","Animated and interactive data visualizations dynamically change the data
rendered in a visualization (e.g., bar chart). As the data changes, the y-axis
may need to be rescaled as the domain of the data changes. Each axis rescaling
potentially improves the readability of the current chart, but may also
disorient the user. In contrast to static visualizations, where there is
considerable literature to help choose the appropriate y-axis scale, there is a
lack of guidance about how and when rescaling should be used in dynamic
visualizations. Existing visualization systems and libraries adapt a fixed
global y-axis, or rescale every time the data changes. Yet, professional
visualizations, such as in data journalism, do not adopt either strategy. They
instead carefully and manually choose when to rescale based on the analysis
task and data. To this end, we conduct a series of Mechanical Turk experiments
to study the potential of dynamic axis rescaling and the factors that affect
its effectiveness. We find that the appropriate rescaling policy is both task-
and data-dependent, and we do not find one clear policy choice for all
situations.",http://arxiv.org/abs/2109.09618v1
"Benchmarking Lane-changing Decision-making for Deep Reinforcement
  Learning",2021-09-22T02:25:27Z,"Junjie Wang, Qichao Zhang, Dongbin Zhao","The development of autonomous driving has attracted extensive attention in
recent years, and it is essential to evaluate the performance of autonomous
driving. However, testing on the road is expensive and inefficient. Virtual
testing is the primary way to validate and verify self-driving cars, and the
basis of virtual testing is to build simulation scenarios. In this paper, we
propose a training, testing, and evaluation pipeline for the lane-changing task
from the perspective of deep reinforcement learning. First, we design lane
change scenarios for training and testing, where the test scenarios include
stochastic and deterministic parts. Then, we deploy a set of benchmarks
consisting of learning and non-learning approaches. We train several
state-of-the-art deep reinforcement learning methods in the designed training
scenarios and provide the benchmark metrics evaluation results of the trained
models in the test scenarios. The designed lane-changing scenarios and
benchmarks are both opened to provide a consistent experimental environment for
the lane-changing task.",http://arxiv.org/abs/2109.10490v1
"Using Sociolinguistic Variables to Reveal Changing Attitudes Towards
  Sexuality and Gender",2021-09-22T22:28:07Z,"Sky CH-Wang, David Jurgens","Individuals signal aspects of their identity and beliefs through linguistic
choices. Studying these choices in aggregate allows us to examine large-scale
attitude shifts within a population. Here, we develop computational methods to
study word choice within a sociolinguistic lexical variable -- alternate words
used to express the same concept -- in order to test for change in the United
States towards sexuality and gender. We examine two variables: i) referents to
significant others, such as the word ""partner"" and ii) referents to an
indefinite person, both of which could optionally be marked with gender. The
linguistic choices in each variable allow us to study increased rates of
acceptances of gay marriage and gender equality, respectively. In longitudinal
analyses across Twitter and Reddit over 87M messages, we demonstrate that
attitudes are changing but that these changes are driven by specific
demographics within the United States. Further, in a quasi-causal analysis, we
show that passages of Marriage Equality Acts in different states are drivers of
linguistic change.",http://arxiv.org/abs/2109.11061v1
"A Strategy to Identify Materials Exhibiting a Large Nonlinear Phononics
  Response: Tuning the Ultrafast Structural Response of LaAlO$_3$ with Pressure",2021-09-27T20:46:44Z,"Jeffrey Z. Kaaret, Guru Khalsa, Nicole A. Benedek","We use theory and first-principles calculations to investigate how structural
changes induced by ultrafast optical excitation of infrared-active phonons
change with hydrostatic pressure in LaAlO$_3$. Our calculations show that the
observed structural changes are sensitive to pressure, with the largest changes
occurring at pressures near the boundary between the cubic perovskite and
rhombohedral phases. We rationalize our findings by defining a figure of merit
that depends only on intrinsic materials quantities, and show that the peak
response near the phase boundary is dictated by different microscopic materials
properties depending on the particular phonon mode being excited. Our work
demonstrates how it is possible to systematically identify materials that may
exhibit particularly large changes in structure and properties due to optical
excitation of infrared-active phonons.",http://arxiv.org/abs/2109.13345v1
"The THREEHUNDRED project: the effect of baryon processes at galaxy
  cluster scale",2021-11-02T20:55:11Z,Weiguang Cui,"The role of baryon models played in hydrodynamic simulations is still
unclear. Future surveys that use cluster statistics to precisely constrain
cosmology models require a better understanding of that. With the
hydro-simulated galaxy clusters from different baryon models (Gadget-MUSIC,
Gadget-X and Gizmo-SIMBA) from the THREEHUNDRED project, we can look into more
details of this question. We find that the galaxy cluster mass change due to
different baryon models is at a few per cent level. However, the mass changes
can be positive or negative, which is depending on the baryon models. Such a
small mass change leaves a weak influence (slightly larger compared to the mass
changes) on both the cumulative halo numbers and the differential halo mass
function (HMF) above the mass completeness. Agreed to the halo mass change, the
halo mass (or HMF) can be increased or decreased with respect to the
dark-matter-only (DMO) run depending on the baryon models.",http://arxiv.org/abs/2111.01889v1
"The eXtreme Mesh deformation approach (X-MESH) for the Stefan
  phase-change model",2021-11-07T21:22:08Z,"Nicolas Moes, Jean-Francois Remacle, Jonathan Lambrechts, Benoit Le, Nicolas Chevaugeon","The eXtreme Mesh deformation approach (X-MESH) is a new paradigm to follow
sharp interfaces without remeshing and without changing the mesh topology. Even
though the mesh does not change its topology, it can follow interfaces that do
change their topology (nucleation, coalescence, splitting). To make this
possible, the key X-MESH idea is to allow elements to reach zero measure. This
permits interface relaying between nodes as well as interface annihilation and
seeding in a time continuous manner. The paper targets the Stefan phase change
model in which the interface (front) is at a given temperature. Several
examples demonstrate the capability of the approach.",http://arxiv.org/abs/2111.04179v3
Cross-Correlated Motions in Azidolysozyme,2021-12-01T16:21:45Z,"Seyedeh Maryam Salehi, Markus Meuwly","The changes in the local and global dynamics of azide-labelled Lysozyme
compared with that of the wild type protein are quantitatively assessed for all
alanine residues along the polypeptide chain. Although attaching -N$_3$ to
alanine residues has been considered to be a minimally invasive change in the
protein it is found that depending on the location of the Alanine residue the
local and global changes in the dynamics differ. For Ala92 the change in the
cross correlated motions are minimal whereas attaching -N$_3$ to Ala90 leads to
pronounced differences in the local and global correlations as quantified by
cross correlation coefficients of the C$_{\alpha}$ atoms. It is also
demonstrated that the spectral region of the asymmetric azide stretch
distinguishes between alanine attachment sites whereas changes in the low
frequency, far-infrared region are less characteristic.",http://arxiv.org/abs/2112.00606v1
"Experimental Observations of the Effects of Intermolecular Van der Waals
  Forces on Entropy",2021-12-02T02:53:11Z,Matthew David Marko,"An experimental effort was conducted to measure the change in internal energy
of non-ideal carbon dioxide as its volume rapidly expanded with the sudden
opening of a valve from one to two compressed gas cylinders. This was achieved
by measuring the mass heat capacity of the gas cylinders and the
manifold-valve, and measuring the change in temperature from the sudden
doubling of volume of the non-ideal carbon dioxide. It was determined that an
empirical equation for the change in internal energy of a non-ideal fluid was
more accurate than previous methods used for estimating the change in internal
energy by estimating the change in entropy. With this empirical equation, a
theoretical ideal Stirling cycle heat engine that exceeds the Carnot efficiency
was realized by utilizing non-ideal carbon dioxide as a working fluid.",http://arxiv.org/abs/2112.01969v8
Kempe changes in degenerate graphs,2021-12-04T11:34:38Z,"Marthe Bonamy, Vincent Delecroix, Clément Legrand-Duchesne","We consider Kempe changes on the $k$-colorings of a graph on $n$ vertices. If
the graph is $(k-1)$-degenerate, then all its $k$-colorings are equivalent up
to Kempe changes. However, the sequence between two $k$-colorings that arises
from the proof may be exponential in the number of vertices. An intriguing open
question is whether it can be turned polynomial. We prove this to be possible
under the stronger assumption that the graph has treewidth at most $k-1$.
Namely, any two $k$-colorings are equivalent up to $O(kn^2)$ Kempe changes. We
investigate other restrictions (list coloring, bounded maximum average degree,
degree bounds). As a main result, we derive that given an $n$-vertex graph with
maximum degree $\Delta$, the $\Delta$-colorings are all equivalent up to
$O(n^2)$ Kempe changes, unless $\Delta = 3$ and some connected component is a
3-prism.",http://arxiv.org/abs/2112.02313v1
"Piecewise survival models: a change-point analysis on herpes zoster
  associated pain data revisited and extended",2021-12-07T13:39:34Z,"Dimitra Eleftheriou, Dimitris Karlis","For many diseases it is reasonable to assume that the hazard rate is not
constant across time, but also that it changes in different time intervals. To
capture this, we work here with a piecewise survival model. One of the major
problems in such piecewise models is to determine the time points of change of
the hazard rate. From the practical point of view this can provide very
important information as it may reflect changes in the progress of a disease.
We present piecewise Weibull regression models with covariates. The time points
where change occurs are assumed unknown and need to be estimated. The equality
of hazard rates across the distinct phases is also examined to verify the exact
number of phases. An example based on herpes zoster data has been used to
demonstrate the usefulness of the developed methodology.",http://arxiv.org/abs/2112.03688v1
Change-point regression with a smooth additive disturbance,2021-12-07T18:15:46Z,Florian Pein,"We assume a nonparametric regression model with signals given by the sum of a
piecewise constant function and a smooth function. To detect the change-points
and estimate the regression functions, we propose PCpluS, a combination of the
fused Lasso and kernel smoothing. In contrast to existing approaches, it
explicitly uses the assumption that the signal can be decomposed into a
piecewise constant and a smooth function when detecting change-points. This is
motivated by several applications and by theoretical results about partial
linear model. Tuning parameters are selected by cross-validation. We argue that
in this setting minimizing the L1-loss is superior to minimizing the L2-loss.
We also highlight important consequences for cross-validation in piecewise
constant change-point regression. Simulations demonstrate that our approach has
a small average mean square error and detects change-points well, and we apply
the methodology to genome sequencing data to detect copy number variations.
Finally, we demonstrate its flexibility by combining it with smoothing splines
and by proposing extensions to multivariate and filtered data.",http://arxiv.org/abs/2112.03878v1
"The Changing Role of Entrepreneurial Universities in the Altering
  Innovation Policy: Opportunities Arising from the Paradigm Change in Light of
  the Experience of Széchenyi István University",2021-12-21T19:38:13Z,"Attila Lajos Makai, Szabolcs Rámháp","The progress made by the entrepreneurial university, which is a newly
emerging category in Hungarian higher education after its change of model, has
not only deepened relations between universities and the industry and
intensified the technology and knowledge transfer processes, but also increased
the role of universities in shaping regional innovation policy. This
transformation places co-operation between the actors of the regional
innovation ecosystem and the relationships between the economic, governmental
and academic systems into a new framework. The purpose of this paper is to
describe the process of the change in the model through a specific example, and
to outline the future possibilities of university involvement in the currently
changing Hungarian innovation policy system.",http://arxiv.org/abs/2112.11499v1
On sign changes of primitive Fourier coefficients of Siegel cusp forms,2021-03-25T17:32:09Z,"Karam Deo Shankhadhar, Prashant Tiwari","In this article, we establish quantitative results for sign changes in
certain subsequences of primitive Fourier coefficients of a non-zero Siegel
cusp form of arbitrary degree over congruence subgroups. As a corollary of our
result for degree two Siegel cusp forms, we get sign changes of its diagonal
Fourier coefficients. In the course of our proofs, we prove the non-vanishing
of certain type of Fourier-Jacobi coefficients of a Siegel cusp form and all
theta components of certain Jacobi cusp forms of arbitrary degree over
congruence subgroups, which are also of independent interest.",http://arxiv.org/abs/2103.13995v2
"Parabolic rectifiability, tangent planes and tangent measures",2021-03-30T14:51:28Z,Pertti Mattila,"We define rectifiability in $\mathbb{R}^{n}\times\mathbb{R}$ with a parabolic
metric in terms of $C^1$ graphs and Lipschitz graphs with small Lipschitz
constants and we characterize it in terms of approximate tangent planes and
tangent measures. We also discuss relations between the parabolic
rectifiability and other notions of rectifiability.",http://arxiv.org/abs/2103.16401v4
MolGrow: A Graph Normalizing Flow for Hierarchical Molecular Generation,2021-02-03T17:48:52Z,"Maksim Kuznetsov, Daniil Polykovskiy","We propose a hierarchical normalizing flow model for generating molecular
graphs. The model produces new molecular structures from a single-node graph by
recursively splitting every node into two. All operations are invertible and
can be used as plug-and-play modules. The hierarchical nature of the latent
codes allows for precise changes in the resulting graph: perturbations in the
top layer cause global structural changes, while perturbations in the
consequent layers change the resulting molecule marginally. The proposed model
outperforms existing generative graph models on the distribution learning task.
We also show successful experiments on global and constrained optimization of
chemical properties using latent codes of the model.",http://arxiv.org/abs/2106.05856v1
Avalanches and Structural Change in Cyclically Sheared Silica Glass,2021-08-17T06:57:00Z,"Himangsu Bhaumik, Giuseppe Foffi, Srikanth Sastry","We investigate avalanches associated with plastic rearrangements and the
nature of structural change in the prototypical strong glass, silica,
computationally. Although qualitative aspects of yielding in silica are similar
to other glasses, we find that the statistics of avalanches exhibits
non-trivial behaviour. Investigating the statistics of avalanches and clusters
in detail, we propose and verify a new relation between exponents
characterizing the size distribution of avalanches and clusters. Across the
yielding transition, anomalous structural change and densification, associated
with a suppression of tetrahedral order, is observed to accompany strain
localisation.",http://arxiv.org/abs/2108.07469v1
The Need for a Fine-grained approach in Just-in-Time Defect Prediction,2021-10-02T00:23:31Z,"Giuseppe Ng, Charibeth Cheng","With software system complexity leading to the rise of software defects,
research efforts have been done on techniques towards predicting software
defects and Just-in-time (JIT) defect prediction which predicts whether a code
change is defective. While using features to determine potentially defective
code change, inspection effort is still significant. As code change can impact
several files, we investigate an open source project to identify potential gaps
with features in JIT perspective. In addition, with a lack of publicly
available JIT dataset that link the features with actual commits, we also
present a new dataset that can be utilized in JIT and semantic analysis.",http://arxiv.org/abs/2110.00579v1
A variational principle for domino tilings of multiply-connected domains,2021-10-13T17:25:26Z,Nikolai Kuchumov,"We study random domino tilings of a multiply-connected domain with a height
function defined on the universal covering space of the domain. We prove a
large deviation principle for the height function in two asymptotic regimes.
The first regime covers all domino tilings of the domain. We also prove a law
of large numbers for height change in this regime. The second regime covers
domino tilings with a given asymptotic height change $r$.",http://arxiv.org/abs/2110.06896v4
"High-resolution land cover change from low-resolution labels: Simple
  baselines for the 2021 IEEE GRSS Data Fusion Contest",2021-01-04T18:33:47Z,"Nikolay Malkin, Caleb Robinson, Nebojsa Jojic","We present simple algorithms for land cover change detection in the 2021 IEEE
GRSS Data Fusion Contest. The task of the contest is to create high-resolution
(1m / pixel) land cover change maps of a study area in Maryland, USA, given
multi-resolution imagery and label data. We study several baseline models for
this task and discuss directions for further research.
  See https://dfc2021.blob.core.windows.net/competition-data/dfc2021_index.txt
for the data and https://github.com/calebrob6/dfc2021-msd-baseline for an
implementation of these baselines.",http://arxiv.org/abs/2101.01154v1
"Effects of Pre- and Post-Processing on type-based Embeddings in Lexical
  Semantic Change Detection",2021-01-22T22:34:15Z,"Jens Kaiser, Sinan Kurtyigit, Serge Kotchourko, Dominik Schlechtweg","Lexical semantic change detection is a new and innovative research field. The
optimal fine-tuning of models including pre- and post-processing is largely
unclear. We optimize existing models by (i) pre-training on large corpora and
refining on diachronic target corpora tackling the notorious small data
problem, and (ii) applying post-processing transformations that have been shown
to improve performance on synchronic tasks. Our results provide a guide for the
application and optimization of lexical semantic change detection models across
various learning scenarios.",http://arxiv.org/abs/2101.09368v2
Cesaro Limits for Fractional Dynamics,2021-02-26T16:53:34Z,"José L. da Silva, Yuri G. Kondratiev","We study the asymptotic behavior of random time changes of dynamical systems.
As random time changes we propose three classes which exhibits different
patterns of asymptotic decays. The subordination principle may be applied to
study the asymptotic behavior of the random time dynamical systems. It turns
out that for the special case of stable subordinators explicit expressions for
the subordination are known and its asymptotic behavior are derived. For more
general classes of random time changes explicit calculations are essentially
more complicated and we reduce our study to the asymptotic behavior of the
corresponding Cesaro limit.",http://arxiv.org/abs/2102.13587v2
"An Analysis of Impact Pathways arising from a Mobile-based Community
  Media Platform in Rural India",2021-04-16T05:55:50Z,"Aparna Moitra, Archna Kumar, Aaditeshwar Seth","Our research presents the case-study of a mobile phone based, voice-driven
platform - Mobile Vaani, established with a goal to empower poor and
marginalized communities to create their own local media. In this paper, we
derive a comprehensive theory of change for Mobile Vaani from data gathered
using the Most Significant Change technique. This paper contributes towards
formulating a theory of change for technology-driven community media platforms
which can be adapted to other ICTD interventions too.",http://arxiv.org/abs/2104.07901v1
"Code generation for productive portable scalable finite element
  simulation in Firedrake",2021-04-16T10:14:54Z,"Jack D. Betteridge, Patrick E. Farrell, David A. Ham","Creating scalable, high performance PDE-based simulations requires a suitable
combination of discretizations, differential operators, preconditioners and
solvers. The required combination changes with the application and with the
available hardware, yet software development time is a severely limited
resource for most scientists and engineers. Here we demonstrate that generating
simulation code from a high-level Python interface provides an effective
mechanism for creating high performance simulations from very few lines of user
code. We demonstrate that moving from one supercomputer to another can require
significant algorithmic changes to achieve scalable performance, but that the
code generation approach enables these algorithmic changes to be achieved with
minimal development effort.",http://arxiv.org/abs/2104.08012v1
"Transfers of some Hecke elements for possibly ramified base change in
  GL_n",2021-04-27T15:57:42Z,Takuya Yamauchi,"In this paper we prove an explicit matching theorem for some Hecke elements
in the case of (possibly ramified) cyclic base change for general linear groups
over local fields of characteristic zero with odd residue characteristic under
a mild assumption. A key observation, based on the works of Waldspurger and
Ganapathy-Varma, is to regard the base change lifts with twisted endoscopic
lifts and replace the condition for the matching orbital integrals with one for
semi-simple descend in the twisted space according to Waldspurger's fundamental
work ""L'endoscopie tordue n'est pas si tordue"".",http://arxiv.org/abs/2104.13286v3
"A general procedure for change-point detection in multivariate time
  series",2021-04-28T14:23:29Z,"Mamadou Lamine Diop, William Kengne","We consider the change-point detection in multivariate continuous and integer
valued time series. We propose a Wald-type statistic based on the estimator
performed by a general contrast function; which can be constructed from the
likelihood, a quasi-likelihood, a least squares method, etc.
  Sufficient conditions are provided to ensure that the statistic convergences
to a well-known distribution under the null hypothesis (of no change) and
diverges to infinity under the alternative; which establishes the consistency
of the procedure. Some examples are detailed to illustrate the scope of
application of the proposed procedure.
  Simulation experiments are conducted to illustrate the asymptotic results.",http://arxiv.org/abs/2104.13789v1
Epidemic change-point detection in general causal time series,2021-05-28T13:50:33Z,"Mamadou Lamine Diop, William Kengne","We consider an epidemic change-point detection in a large class of causal
time series models, including among other processes, AR($\infty$),
ARCH($\infty$), TARCH($\infty$), ARMA-GARCH. A test statistic based on the
Gaussian quasi-maximum likelihood estimator of the parameter is proposed. It is
shown that, under the null hypothesis of no change, the test statistic
converges to a distribution obtained from a difference of two Brownian bridge
and diverges to infinity under the epidemic alternative. Numerical results for
simulation and real data example are provided.",http://arxiv.org/abs/2105.13836v1
Changing the World by Changing the Data,2021-05-28T16:17:22Z,Anna Rogers,"NLP community is currently investing a lot more research and resources into
development of deep learning models than training data. While we have made a
lot of progress, it is now clear that our models learn all kinds of spurious
patterns, social biases, and annotation artifacts. Algorithmic solutions have
so far had limited success. An alternative that is being actively discussed is
more careful design of datasets so as to deliver specific signals. This
position paper maps out the arguments for and against data curation, and argues
that fundamentally the point is moot: curation already is and will be
happening, and it is changing the world. The question is only how much thought
we want to invest into that process.",http://arxiv.org/abs/2105.13947v1
Mutual information disentangles interactions from changing environments,2021-07-19T15:59:10Z,"Giorgio Nicoletti, Daniel Maria Busiello","Real-world systems are characterized by complex interactions of their
internal degrees of freedom, while living in ever-changing environments whose
net effect is to act as additional couplings. Here, we introduce a paradigmatic
interacting model in a switching, but unobserved, environment. We show that the
limiting properties of the mutual information of the system allow for a
disentangling of these two sources of couplings. Further, our approach might
stand as a general method to discriminate complex internal interactions from
equally complex changing environments.",http://arxiv.org/abs/2107.08985v2
A motivic change of variables formula for Artin stacks,2021-09-20T19:17:37Z,"Matthew Satriano, Jeremy Usatine","Let $\mathcal{X} \to Y$ be a birational map from a smooth Artin stack to a
(possibly singular) variety. We prove a change of variables formula that
relates motivic integrals over arcs of $Y$ to motivic integrals over arcs of
$\mathcal{X}$. With a view toward the study of stringy Hodge numbers, this
change of variables formula leads to a new notion of crepantness for the map
$\mathcal{X} \to Y$ that coincides with the usual notion in the special case
that $\mathcal{X}$ is a scheme.",http://arxiv.org/abs/2109.09800v1
Local cohomology tables of sequentially almost Cohen-Macaulay modules,2021-11-15T05:03:39Z,Cheng Meng,"Let $R$ be a polynomial ring over a field. We introduce the concept of
sequentially almost Cohen-Macaulay modules and describe the extremal rays of
the cone of local cohomology tables of finitely generated graded $R$-modules
which are sequentially almost Cohen-Macaulay, and describe some cases when the
local cohomology table of a module of dimension 3 has a nontrivial
decomposition.",http://arxiv.org/abs/2111.07536v2
"CDNet is all you need: Cascade DCN based underwater object detection
  RCNN",2021-11-25T09:35:27Z,Di Chang,"Object detection is a very important basic research direction in the field of
computer vision and a basic method for other advanced tasks in the field of
computer vision. It has been widely used in practical applications such as
object tracking, video behavior recognition and underwater robotics vision. The
Cascade-RCNN and Deformable Convolution Network are both classical and
excellent object detection algorithms. In this report, we evaluate our
Cascade-DCN based method on underwater optical image and acoustics image
datasets with different engineering tricks and augumentation.",http://arxiv.org/abs/2111.12982v1
"Kazhdan-Lusztig Algorithm for Whittaker Modules with Arbitrary
  Infinitesimal Characters",2021-12-14T03:08:22Z,Qixian Zhao,"Let $\mathfrak{g}$ be a complex semisimple Lie algebra. We give a description
of characters of irreducible Whittaker modules for $\mathfrak{g}$ with any
infinitesimal character, along with a Kazhdan-Lusztig algorithm for computing
them. This generalizes Milicic-Soergel's and Romanov's results for integral
infinitesimal characters. As a special case, we recover the non-integral
Kazhdan-Lusztig conjecture for Verma modules.",http://arxiv.org/abs/2112.07132v4
"Manifestations of changes in entanglement and onset of synchronization
  in tomograms",2021-12-25T17:27:43Z,"Soumyabrata Paul, S. Lakshmibala, V. Balakrishnan, S. Ramanan","Quantum state reconstruction for continuous-variable systems such as the
radiation field poses challenges which arise primarily from the large
dimensionality of the Hilbert space. Many proposals for state reconstruction
exist, ranging from standard reconstruction protocols to applications of
machine learning. No universally applicable protocol exists, however, for
extracting the Wigner function from the optical tomogram of an arbitrary state
of light. We establish that nonclassical effects such as entanglement changes
during dynamical evolution and the onset of quantum synchronization are
mirrored in qualitative changes in optical tomograms themselves, circumventing
the need for state reconstruction for this purpose.",http://arxiv.org/abs/2112.13262v1
"Factorized Binary Search: change point detection in the network
  structure of multivariate high-dimensional time series",2021-03-10T21:25:20Z,"Martin Ondrus, Emily Olds, Ivor Cribben","Functional magnetic resonance imaging (fMRI) time series data presents a
unique opportunity to understand the behavior of temporal brain connectivity,
and models that uncover the complex dynamic workings of this organ are of keen
interest in neuroscience. We are motivated to develop accurate change point
detection and network estimation techniques for high-dimensional whole-brain
fMRI data. To this end, we introduce factorized binary search (FaBiSearch), a
novel change point detection method in the network structure of multivariate
high-dimensional time series in order to understand the large-scale
characterizations and dynamics of the brain. FaBiSearch employs non-negative
matrix factorization, an unsupervised dimension reduction technique, and a new
binary search algorithm to identify multiple change points. In addition, we
propose a new method for network estimation for data between change points. We
seek to understand the dynamic mechanism of the brain, particularly for two
fMRI data sets. The first is a resting-state fMRI experiment, where subjects
are scanned over three visits. The second is a task-based fMRI experiment,
where subjects read Chapter 9 of Harry Potter and the Sorcerer's Stone. For the
resting-state data set, we examine the test-retest behavior of dynamic
functional connectivity, while for the task-based data set, we explore network
dynamics during the reading and whether change points across subjects coincide
with key plot twists in the story. Further, we identify hub nodes in the brain
network and examine their dynamic behavior. Finally, we make all the methods
discussed available in the R package fabisearch on CRAN.",http://arxiv.org/abs/2103.06347v3
"Efficacy of Statistical and Artificial Intelligence-based False
  Information Cyberattack Detection Models for Connected Vehicles",2021-08-02T18:50:12Z,"Sakib Mahmud Khan, Gurcan Comert, Mashrur Chowdhury","Connected vehicles (CVs), because of the external connectivity with other CVs
and connected infrastructure, are vulnerable to cyberattacks that can instantly
compromise the safety of the vehicle itself and other connected vehicles and
roadway infrastructure. One such cyberattack is the false information attack,
where an external attacker injects inaccurate information into the connected
vehicles and eventually can cause catastrophic consequences by compromising
safety-critical applications like the forward collision warning. The occurrence
and target of such attack events can be very dynamic, making real-time and
near-real-time detection challenging. Change point models, can be used for
real-time anomaly detection caused by the false information attack. In this
paper, we have evaluated three change point-based statistical models;
Expectation Maximization, Cumulative Summation, and Bayesian Online Change
Point Algorithms for cyberattack detection in the CV data. Also, data-driven
artificial intelligence (AI) models, which can be used to detect known and
unknown underlying patterns in the dataset, have the potential of detecting a
real-time anomaly in the CV data. We have used six AI models to detect false
information attacks and compared the performance for detecting the attacks with
our developed change point models. Our study shows that change points models
performed better in real-time false information attack detection compared to
the performance of the AI models. Change point models having the advantage of
no training requirements can be a feasible and computationally efficient
alternative to AI models for false information attack detection in connected
vehicles.",http://arxiv.org/abs/2108.01124v1
"A Driven Disordered Systems Approach to Biological Evolution in Changing
  Environments",2021-08-13T11:19:14Z,"Suman G Das, Joachim Krug, Muhittin Mungan","Biological evolution of a population is governed by the fitness landscape,
which is a map from genotype to fitness. However, a fitness landscape depends
on the organisms environment, and evolution in changing environments is still
poorly understood. We study a particular model of antibiotic resistance
evolution in bacteria where the antibiotic concentration is an environmental
parameter and the fitness landscapes incorporate tradeoffs between adaptation
to low and high antibiotic concentration. With evolutionary dynamics that
follow fitness gradients, the evolution of the system under slowly changing
antibiotic concentration resembles the athermal dynamics of disordered physical
systems under external drives. Exploiting this resemblance, we show that our
model can be described as a system with interacting hysteretic elements. As in
the case of the driven disordered systems, adaptive evolution under antibiotic
concentration cycling is found to exhibit hysteresis loops and memory
formation. We derive a number of analytical results for quasistatic
concentration changes. We also perform numerical simulations to study how these
effects are modified under driving protocols in which the concentration is
changed in discrete steps. Our approach provides a general framework for
studying motifs of evolutionary dynamics in biological systems in a changing
environment.",http://arxiv.org/abs/2108.06170v2
"Look Before You Leap! Designing a Human-Centered AI System for Change
  Risk Assessment",2021-08-18T02:41:48Z,"Binay Gupta, Anirban Chatterjee, Harika Matha, Kunal Banerjee, Lalitdutt Parsai, Vijay Agneeswaran","Reducing the number of failures in a production system is one of the most
challenging problems in technology driven industries, such as, the online
retail industry. To address this challenge, change management has emerged as a
promising sub-field in operations that manages and reviews the changes to be
deployed in production in a systematic manner. However, it is practically
impossible to manually review a large number of changes on a daily basis and
assess the risk associated with them. This warrants the development of an
automated system to assess the risk associated with a large number of changes.
There are a few commercial solutions available to address this problem but
those solutions lack the ability to incorporate domain knowledge and continuous
feedback from domain experts into the risk assessment process. As part of this
work, we aim to bridge the gap between model-driven risk assessment of change
requests and the assessment of domain experts by building a continuous feedback
loop into the risk assessment process. Here we present our work to build an
end-to-end machine learning system along with the discussion of some of
practical challenges we faced related to extreme skewness in class
distribution, concept drift, estimation of the uncertainty associated with the
model's prediction and the overall scalability of the system.",http://arxiv.org/abs/2108.07951v1
Graph-Based Machine Learning Improves Just-in-Time Defect Prediction,2021-10-11T16:00:02Z,"Jonathan Bryan, Pablo Moriano","The increasing complexity of today's software requires the contribution of
thousands of developers. This complex collaboration structure makes developers
more likely to introduce defect-prone changes that lead to software faults.
Determining when these defect-prone changes are introduced has proven
challenging, and using traditional machine learning (ML) methods to make these
determinations seems to have reached a plateau. In this work, we build
contribution graphs consisting of developers and source files to capture the
nuanced complexity of changes required to build software. By leveraging these
contribution graphs, our research shows the potential of using graph-based ML
to improve Just-In-Time (JIT) defect prediction. We hypothesize that features
extracted from the contribution graphs may be better predictors of defect-prone
changes than intrinsic features derived from software characteristics. We
corroborate our hypothesis using graph-based ML for classifying edges that
represent defect-prone changes. This new framing of the JIT defect prediction
problem leads to remarkably better results. We test our approach on 14
open-source projects and show that our best model can predict whether or not a
code change will lead to a defect with an F1 score as high as 77.55% and a
Matthews correlation coefficient (MCC) as high as 53.16%. This represents a
152% higher F1 score and a 3% higher MCC over the state-of-the-art JIT defect
prediction. We describe limitations, open challenges, and how this method can
be used for operational JIT defect prediction.",http://arxiv.org/abs/2110.05371v3
Modelling Behaviour Change using Cognitive Agent Simulations,2021-10-16T19:19:08Z,Catriona M. Kennedy,"In health psychology, Behaviour Change Theories(BCTs) play an important role
in modelling human goal achievement in adverse environments. Some of these
theories use concepts that are also used in computational modelling of
cognition and affect in AI. Examples include dual-process architecture and
models of motivation. It is therefore important to ask whether some BCTs can be
computationally implemented as cognitive agents in a way that builds on
existing AI research in cognitive architecture. This paper presents
work-in-progress research to apply selected behaviour change theories to
simulated agents, so that an agent is acting according to the theory while
attempting to complete a task in a challenging scenario. Two behaviour change
theories are selected as examples (CEOS and PRIME). The research is focusing on
complex agent architectures required for self-determined goal achievement in
adverse circumstances where the action is difficult to maintain (e.g. healthy
eating at office parties). Such simulations are useful because they can provide
new insights into human behaviour change and improve conceptual precision. In
addition, they can act as a rapid-prototyping environment for technology
development. High-level descriptive simulations also provide an opportunity for
transparency and participatory design, which is important for user ownership of
the behaviour change process.",http://arxiv.org/abs/2110.08645v1
Typed Image-based Programming with Structure Editing,2021-10-18T03:11:15Z,"Jonathan Edwards, Tomas Petricek","Many beloved programming systems are image-based: self-contained worlds that
persist both code and data in a single file. Examples include Smalltalk, LISP,
HyperCard, Flash, and spreadsheets. Image-based programming avoids much of the
complexity of modern programming technology stacks and encourages more casual
and exploratory programming. However conventional file-based programming has
better support for collaboration and deployment. These problems have been
blamed for the limited commercial success of Smalltalk. We propose to enable
collaboration in image-based programming via types and structure editing.
  We focus on the problem of schema change on persistent data. We turn to
static types, which paradoxically require more schema change but also provide a
mechanism to express and execute those changes. To determine those changes we
turn to structure editing, so that we can capture changes in type definitions
with sufficient fidelity to automatically adapt the data to suit. We conjecture
that typical schema changes can be handled through structure editing of static
types.
  That positions us to tackle collaboration with what could be called version
control for structure editing. We present a theory realizing this idea, which
is our main technical contribution. While we focus here on editing types, if we
can extend the approach to cover the entire programming experience then it
would offer a new way to collaborate in image-based programming.",http://arxiv.org/abs/2110.08993v1
"Bridging the short-term and long-term dynamics of economic structural
  change",2021-10-19T00:55:17Z,"James McNerney, Yang Li, Andres Gomez-Lievano, Frank Neffke","Economic transformation -- change in what an economy produces -- is
foundational to development and rising standards of living. Our understanding
of this process has been propelled recently by two branches of work in the
field of economic complexity, one studying how economies diversify, the other
how the complexity of an economy is expressed in the makeup of its output.
However, the connection between these branches is not well understood, nor how
they relate to a classic understanding of structural transformation. Here, we
present a simple dynamical modeling framework that unifies these areas of work,
based on the widespread observation that economies diversify preferentially
into activities that are related to ones they do already. We show how stylized
facts of long-run structural change, as well as complexity metrics, can both
emerge naturally from this one observation. However, complexity metrics take on
new meanings, as descriptions of the long-term changes an economy experiences
rather than measures of complexity per se. This suggests relatedness and
complexity metrics are connected, in a hitherto overlooked way: Both describe
structural change, on different time scales. Whereas relatedness probes
transformation on short time scales, complexity metrics capture long-term
change.",http://arxiv.org/abs/2110.09673v2
"Pandemic model with data-driven phase detection, a study using COVID-19
  data",2021-10-24T14:07:32Z,"Yuansan Liu, Saransh Srivastava, Zuo Huang, Felisa J. Vázquez-Abad","The recent COVID-19 pandemic has promoted vigorous scientific activity in an
effort to understand, advice and control the pandemic. Data is now freely
available at a staggering rate worldwide. Unfortunately, this unprecedented
level of information contains a variety of data sources and formats, and the
models do not always conform to the description of the data. Health officials
have recognized the need for more accurate models that can adjust to sudden
changes, such as produced by changes in behavior or social restrictions. In
this work we formulate a model that fits a ``SIR''-type model concurrently with
a statistical change detection test on the data. The result is a piece wise
autonomous ordinary differential equation, whose parameters change at various
points in time (automatically learned from the data). The main contributions of
our model are: (a) providing interpretation of the parameters, (b) determining
which parameters of the model are more important to produce changes in the
spread of the disease, and (c) using data-driven discovery of sudden changes in
the evolution of the pandemic. Together, these characteristics provide a new
model that better describes the situation and thus, provides better quality of
information for decision making.",http://arxiv.org/abs/2110.12450v1
"Bidders' Responses to Auction Format Change in Internet Display
  Advertising Auctions",2021-10-20T05:06:03Z,"Shumpei Goke, Gabriel Y. Weintraub, Ralph Mastromonaco, Sam Seljan","We study actual bidding behavior when a new auction format gets introduced
into the marketplace. More specifically, we investigate this question using a
novel dataset on internet display advertising auctions that exploits a
staggered adoption by different publishers (sellers) of first-price auctions
(FPAs), instead of the traditional second-price auctions (SPAs). Event study
regression estimates indicate that, immediately after the auction format
change, the revenue per sold impression (price) jumped considerably for the
treated publishers relative to the control publishers, ranging from 35% to 75%
of the pre-treatment price level of the treatment group. Further, we observe
that in later auction format changes the increase in the price levels under
FPAs relative to price levels under SPAs dissipates over time, reminiscent of
the celebrated revenue equivalence theorem. We take this as evidence of
initially insufficient bid shading after the format change rather than an
immediate shift to a new Bayesian Nash equilibrium. Prices then went down as
bidders learned to shade their bids. We also show that bidders' sophistication
impacted their response to the auction format change. Our work constitutes one
of the first field studies on bidders' responses to auction format changes,
providing an important complement to theoretical model predictions. As such, it
provides valuable information to auction designers when considering the
implementation of different formats.",http://arxiv.org/abs/2110.13814v2
Location-Adaptive Change-Point Testing for Time Series,2021-10-28T12:45:44Z,"Linlin Dai, Rui She","We propose a location-adaptive self-normalization (SN) based test for change
points in time series. The SN technique has been extensively used in
change-point detection for its capability to avoid direct estimation of
nuisance parameters. However, we find that the power of the SN-based test is
susceptible to the location of the break and may suffer from a severe power
loss, especially when the change occurs at the early or late stage of the
sequence. This phenomenon is essentially caused by the unbalance of the data
used before and after the change point when one is building a test statistic
based on the cumulative sum (CUSUM) process. Hence, we consider leaving out the
samples far away from the potential locations of change points and propose an
optimal data selection scheme. Based on this scheme, a new SN-based test
statistic adaptive to the locations of breaks is established. The new test can
significantly improve the power of the existing SN-based tests while
maintaining a satisfactory size. It is a unified treatment that can be readily
extended to tests for general quantities of interest, such as the median and
the model parameters. The derived optimal subsample selection strategy is not
specific to the SN-based tests but is applicable to any method that relies on
the CUSUM process, which may provide new insights in the area for future
research.",http://arxiv.org/abs/2110.15071v2
"Morphological Change Forecasting for Prostate Glands using Feature-based
  Registration and Kernel Density Extrapolation",2021-01-16T10:45:55Z,"Qianye Yang, Tom Vercauteren, Yunguan Fu, Francesco Giganti, Nooshin Ghavami, Vasilis Stavrinides, Caroline Moore, Matt Clarkson, Dean Barratt, Yipeng Hu","Organ morphology is a key indicator for prostate disease diagnosis and
prognosis. For instance, In longitudinal study of prostate cancer patients
under active surveillance, the volume, boundary smoothness and their changes
are closely monitored on time-series MR image data. In this paper, we describe
a new framework for forecasting prostate morphological changes, as the ability
to detect such changes earlier than what is currently possible may enable
timely treatment or avoiding unnecessary confirmatory biopsies. In this work,
an efficient feature-based MR image registration is first developed to align
delineated prostate gland capsules to quantify the morphological changes using
the inferred dense displacement fields (DDFs). We then propose to use kernel
density estimation (KDE) of the probability density of the DDF-represented
\textit{future morphology changes}, between current and future time points,
before the future data become available. The KDE utilises a novel distance
function that takes into account morphology, stage-of-progression and
duration-of-change, which are considered factors in such subject-specific
forecasting. We validate the proposed approach on image masks unseen to
registration network training, without using any data acquired at the future
target time points. The experiment results are presented on a longitudinal data
set with 331 images from 73 patients, yielding an average Dice score of 0.865
on a holdout set, between the ground-truth and the image masks warped by the
KDE-predicted-DDFs.",http://arxiv.org/abs/2101.06425v1
"Effect of the sample work function on alkali metal dosing induced
  electronic structure change",2021-01-28T03:40:52Z,"Saegyeol Jung, Yukiaki Ishida, Minsoo Kim, Masamichi Nakajima, Shigeyuki Ishida, Hiroshi Eisaki, Woojae Choi, Yong Seung Kwon, Jonathan Denlinger, Toshio Otsu, Yohei Kobayashi, Soonsang Huh, Changyoung Kim","Alkali metal dosing (AMD) has been widely used as a way to control doping
without chemical substitution. This technique, in combination with angle
resolved photoemission spectroscopy (ARPES), often provides an opportunity to
observe unexpected phenomena. However, the amount of transferred charge and the
corresponding change in the electronic structure vary significantly depending
on the material. Here, we report study on the correlation between the sample
work function and alkali metal induced electronic structure change for three
iron-based superconductors: FeSe, Ba(Fe$_{0.94}$Co$_{0.06}$)$_{2}$As$_{2}$ and
NaFeAs which share a similar Fermi surface topology. Electronic structure
change upon monolayer of alkali metal dosing and the sample work function were
measured by ARPES. Our results show that the degree of electronic structure
change is proportional to the difference between the work function of the
sample and Mulliken's absolute electronegativity of the dosed alkali metal.
This finding provides a possible way to estimate the AMD induced electronic
structure change.",http://arxiv.org/abs/2101.11804v2
"Diff-Net: Image Feature Difference based High-Definition Map Change
  Detection for Autonomous Driving",2021-07-14T22:51:30Z,"Lei He, Shengjie Jiang, Xiaoqing Liang, Ning Wang, Shiyu Song","Up-to-date High-Definition (HD) maps are essential for self-driving cars. To
achieve constantly updated HD maps, we present a deep neural network (DNN),
Diff-Net, to detect changes in them. Compared to traditional methods based on
object detectors, the essential design in our work is a parallel feature
difference calculation structure that infers map changes by comparing features
extracted from the camera and rasterized images. To generate these rasterized
images, we project map elements onto images in the camera view, yielding
meaningful map representations that can be consumed by a DNN accordingly. As we
formulate the change detection task as an object detection problem, we leverage
the anchor-based structure that predicts bounding boxes with different change
status categories. To the best of our knowledge, the proposed method is the
first end-to-end network that tackles the high-definition map change detection
task, yielding a single stage solution. Furthermore, rather than relying on
single frame input, we introduce a spatio-temporal fusion module that fuses
features from history frames into the current, thus improving the overall
performance. Finally, we comprehensively validate our method's effectiveness
using freshly collected datasets. Results demonstrate that our Diff-Net
achieves better performance than the baseline methods and is ready to be
integrated into a map production pipeline maintaining an up-to-date HD map.",http://arxiv.org/abs/2107.07030v2
"Assessing Mediational Processes Using Piecewise Linear Growth Curve
  Models with Individual Measurement Occasions",2021-07-18T01:19:17Z,"Jin Liu, Robert A. Perera","Longitudinal processes often unfold concurrently where the growth of two or
more longitudinal outcomes are associated. Additionally, if the study under
investigation is long, the growth curves may exhibit nonconstant change with
respect to time. Multiple existing studies have developed multivariate growth
models with nonlinear functional forms to explore joint development where two
longitudinal records are correlated over time. However, the relationship
between multiple longitudinal outcomes may also be unidirectional. Accordingly,
it is of interest to estimate regression coefficients of such unidirectional
paths. One statistical tool for such analyses is longitudinal mediation models.
In this study, we develop two models to evaluate mediational processes where
the linear-linear piecewise growth model is utilized to capture the change
patterns. We define the mediational process as either the baseline covariate or
the change in covariate influencing the change in the mediator, which, in turn,
affects the change in the outcome. We present the proposed models through
simulation studies and real-world data analyses. Our simulation studies
demonstrate that the proposed mediational models can provide unbiased and
accurate point estimates with target coverage probabilities with a 95%
confidence interval. The empirical analyses demonstrate that the proposed model
can estimate covariates' direct and indirect effects on the change in the
outcome. We also provide the corresponding code for the proposed models.",http://arxiv.org/abs/2107.08338v2
Towards Practical Integrity in the Smart Home with HomeEndorser,2021-09-10T23:48:51Z,"Kaushal Kafle, Kirti Jagtap, Mansoor Ahmed-Rengers, Trent Jaeger, Adwait Nadkarni","Home automation in modern smart home platforms is often facilitated using
trigger-action routines. While such routines enable flexible automation, they
also lead to an instance of the integrity problem in these systems: untrusted
third-parties may use platform APIs to modify the abstract home objects (AHOs)
that privileged, high-integrity devices such as security cameras rely on (i.e.,
as triggers), thereby transitively attacking them. As most accesses to AHOs are
legitimate, removing the permissions or applying naive information flow
controls would not only fail to prevent these problems, but also break useful
functionality. Therefore, this paper proposes the alternate approach of home
abstraction endorsement, which endorses a proposed change to an AHO by
correlating it with certain specific, preceding, environmental changes. We
present the HomeEndorser framework, which provides a policy model for
specifying endorsement policies for AHOs as changes in device states, relative
to their location, and a platform-based reference monitor for mediating all API
requests to change AHOs against those device states. We evaluate HomeEndorser
on the HomeAssistant platform, finding that we can derive over 1000 policy
rules for HomeEndorser to endorse changes to 6 key AHOs, preventing malice and
accidents for less than 10% overhead for endorsement check microbenchmarks, and
with no false alarms under realistic usage scenarios. In doing so, HomeEndorser
lays the first steps towards providing a practical foundation for ensuring that
API-induced changes to abstract home objects correlate with the physical
realities of the user's environment.",http://arxiv.org/abs/2109.05139v1
"Changing looks of the nucleus of the Seyfert galaxy NGC 1566 compared
  with other changing-look AGNs",2021-11-03T11:51:00Z,Victor L. Oknyansky,"We present results of a long-term optical, UV and X-ray study of variability
of the nearby changing-look (CL) Seyfert NGC 1566 which was observed with the
Swift Observatory from 2007 to 2020. We summarize our previously published
spectroscopic and photometric results and present new observations. We reported
on the alteration in the spectral type of NGC 1566 in 2018 (REF1). Moreover, we
focused on the exceptional postmaximum behavior after 2018 July, when all bands
dropped with some fluctuations (REF2). We observed four significant
re-brightenings in the post-maximum period. We have found differences in X-ray
and UV/Optical variability. The L_uv/L_x-ray ratio was decreased during
2018-2020. New post-maximum spectra covering the period 2018 November 31 to
2019 September 23 show dramatic changes compared to 2018 August 2, with fading
of the broad lines and [Fe X] 6374 until 2019 March (REF2). Effectively, two CL
states were observed for this object: changing to type 1.2 and then returning
to the low state as a type 1.8 Sy. We suggest that the changes are mostly due
to fluctuations in the energy generation.
  Variability properties of NGC1566 are compared with our results for other CL
AGNs.",http://arxiv.org/abs/2111.02818v3
"Multi-agent Reinforcement Learning for Cooperative Lane Changing of
  Connected and Autonomous Vehicles in Mixed Traffic",2021-11-11T17:17:24Z,"Wei Zhou, Dong Chen, Jun Yan, Zhaojian Li, Huilin Yin, Wanchen Ge","Autonomous driving has attracted significant research interests in the past
two decades as it offers many potential benefits, including releasing drivers
from exhausting driving and mitigating traffic congestion, among others.
Despite promising progress, lane-changing remains a great challenge for
autonomous vehicles (AV), especially in mixed and dynamic traffic scenarios.
Recently, reinforcement learning (RL), a powerful data-driven control method,
has been widely explored for lane-changing decision makings in AVs with
encouraging results demonstrated. However, the majority of those studies are
focused on a single-vehicle setting, and lane-changing in the context of
multiple AVs coexisting with human-driven vehicles (HDVs) have received scarce
attention. In this paper, we formulate the lane-changing decision making of
multiple AVs in a mixed-traffic highway environment as a multi-agent
reinforcement learning (MARL) problem, where each AV makes lane-changing
decisions based on the motions of both neighboring AVs and HDVs. Specifically,
a multi-agent advantage actor-critic network (MA2C) is developed with a novel
local reward design and a parameter sharing scheme. In particular, a
multi-objective reward function is proposed to incorporate fuel efficiency,
driving comfort, and safety of autonomous driving. Comprehensive experimental
results, conducted under three different traffic densities and various levels
of human driver aggressiveness, show that our proposed MARL framework
consistently outperforms several state-of-the-art benchmarks in terms of
efficiency, safety and driver comfort.",http://arxiv.org/abs/2111.06318v2
Sign changes of the partial sums of a random multiplicative function,2021-03-09T13:24:32Z,"Marco Aymone, Winston Heap, Jing Zhao","We provide a simple proof that the partial sums $\sum_{n\leq x}f(n)$ of a
Rademacher random multiplicative function $f$ change sign infinitely often as
$x\to\infty$, almost surely.",http://arxiv.org/abs/2103.05413v3
Manifest Spacetime Supersymmetry and the Superstring,2021-06-08T15:30:45Z,Nathan Berkovits,"The algebra of spacetime supersymmetry generators in the RNS formalism for
the superstring closes only up to a picture-changing operation. After adding
non-minimal variables and working in the ""large"" Hilbert space, the algebra
closes without picture-changing and spacetime supersymmetry can be made
manifest. The resulting non-minimal version of the RNS formalism is related by
a field redefinition to the pure spinor formalism.",http://arxiv.org/abs/2106.04448v1
"Megadiff: A Dataset of 600k Java Source Code Changes Categorized by Diff
  Size",2021-08-10T12:32:04Z,"Martin Monperrus, Matias Martinez, He Ye, Fernanda Madeiral, Thomas Durieux, Zhongxing Yu","This paper presents Megadiff, a dataset of source code diffs. It focuses on
Java, with strict inclusion criteria based on commit message and diff size.
Megadiff contains 663 029 Java diffs that can be used for research on commit
comprehension, fault localization, automated program repair, and machine
learning on code changes.",http://arxiv.org/abs/2108.04631v1
More on Change-Making and Related Problems,2021-10-06T04:33:25Z,"Timothy M. Chan, Qizheng He","Given a set of $n$ integer-valued coin types and a target value $t$, the
well-known change-making problem asks for the minimum number of coins that sum
to $t$, assuming an unlimited number of coins in each type. In the more general
all-targets version of the problem, we want the minimum number of coins summing
to $j$, for every $j=0,\ldots,t$. For example, the textbook dynamic programming
algorithms can solve the all-targets problem in $O(nt)$ time. Recently, Chan
and He (SOSA'20) described a number of $O(t\,\textrm{polylog}\,t)$-time
algorithms for the original (single-target) version of the change-making
problem, but not the all-targets version.
  We obtain a number of new results on change-making and related problems,
including:
  1. A new algorithm for the all-targets change-making problem with running
time $\tilde{O}(t^{4/3})$, improving a previous $\tilde{O}(t^{3/2})$-time
algorithm.
  2. A very simple $\tilde{O}(u^2+t)$-time algorithm for the all-targets
change-making problem, where $u$ denotes the maximum coin value. The analysis
of the algorithm uses a theorem of Erd\H{o}s and Graham (1972) on the Frobenius
problem. This algorithm can be extended to solve the all-capacities version of
the unbounded knapsack problem (for integer item weights bounded by $u$).
  3. For the original (single-target) coin changing problem, we describe a
simple modification of one of Chan and He's algorithms that runs in
$\tilde{O}(u)$ time (instead of $\tilde{O}(t)$).
  4. For the original (single-capacity) unbounded knapsack problem, we describe
a simple algorithm that runs in $\tilde{O}(nu)$ time, improving previous
near-$u^2$-time algorithms.
  5. We also observe how one of our ideas implies a new result on the minimum
word break problem, an optimization version of a string problem studied by
Bringmann et al. (FOCS'17), generalizing change-making (which corresponds to
the unary special case).",http://arxiv.org/abs/2110.02503v1
Brown-York Energy in Spacetimes with Horizon,2021-01-02T18:41:26Z,Jarmo Mäkelä,"We obtain a simple relationship between the change in the Brown-York energy
inside of a closed two-surface just outside of a horizon of spacetime, and the
change in the area of that two-surface.",http://arxiv.org/abs/2101.00493v1
On the trace anomaly of Chaudhuri-Choi-Rabinovici model,2021-01-08T05:58:12Z,Yu Nakayama,"Recently a non-supersymmetric conformal field theory with an exactly marginal
deformation in the large $N$ limit was constructed by
Chaudhuri-Choi-Rabinovici. On a non-supersymmetric conformal manifold, $c$
coefficient of the trace anomaly in four dimensions would generically change.
In this model, we, however, find that it does not change at the first
non-trivial order given by three-loop diagrams.",http://arxiv.org/abs/2101.02861v1
Remarks on the Second Homology Groups of Queer Lie Superalgebras,2021-02-02T07:23:15Z,"Yongjie Wang, Zhihua Chang","The aim of this note is to completely determine the second homology group of
the special queer Lie superalgebra $\mathfrak{sq}_n(R)$ coordinatized by a
unital associative superalgebra $R$, which will be achieved via an isomorphism
between the special linear Lie superalgebra $\mathfrak{sl}_{n}(R\otimes Q_1)$
and the special queer Lie superalgebra $\mathfrak{sq}_n(R)$.",http://arxiv.org/abs/2102.01359v1
$\mathsf{PFA}$ and $ω_1$-free compact spaces,2021-04-28T10:57:51Z,"Alan Dow, Klaas Pieter Hart","The Proper Forcing Axiom implies that compact Hausdorff spaces are either
first-countable or contain a converging $\omega_1$-sequence.",http://arxiv.org/abs/2104.13698v3
Changes in Crime Rates During the COVID-19 Pandemic,2021-05-19T00:05:31Z,"Mikaela Meyer, Ahmed Hassafy, Gina Lewis, Prasun Shrestha, Amelia M. Haviland, Daniel S. Nagin","We estimate changes in the rates of five FBI Part 1 crime (homicide, auto
theft, burglary, robbery, and larceny) during the COVID-19 pandemic from March
through December 2020. Using publicly available weekly crime count data from 29
of the 70 largest cities in the U.S. from January 2018 through December 2020,
three different linear regression model specifications are used to detect
changes. One detects whether crime trends in four 2020 pre- and post-pandemic
periods differ from those in 2018 and 2019. A second looks in more detail at
the spring 2020 lockdowns to detect whether crime trends changed over
successive biweekly periods into the lockdown. The third uses a city-level
openness index that we created for the purpose of examining whether the degree
of openness was associated with changing crime rates. For homicide and auto
theft, we find significant increases during all or most of the pandemic. By
contrast, we find significant declines in robbery and larceny during all or
part of the pandemic and no significant changes in burglary over the course of
the pandemic. Only larceny rates fluctuated with the degree of each city's
lockdown.
  It is unusual for crime rates to move in different directions, and the
reasons for the mixed findings for these five Part 1 Index crimes, one with no
change, two with sustained increases, and two with sustained decreases, are not
yet known. We hypothesize that the reasons may be related to changes in
opportunity, and the pandemic provides unique opportunities for future research
to better understand the forces impacting crime rates. In the absence of a
clear understanding of the mechanisms by which the pandemic affected crime, in
the spirit of evidence-based crime policy, we caution against advancing policy
at this time based on lessons learned from the pandemic ""natural experiment.""",http://arxiv.org/abs/2105.08859v1
"Rigidity of joinings for time-changes of unipotent flows on quotients of
  Lorentz groups",2021-07-07T15:29:37Z,Siyuan Tang,"Let $u_{X}^{t}$ be a unipotent flow on $X=SO(n,1)/\Gamma$, $u_{Y}^{t}$ be a
unipotent flow on $Y=G/\Gamma^{\prime}$. Let $\tilde{u}_{X}^{t}$,
$\tilde{u}_{Y}^{t}$ be time-changes of $u_{X}^{t}$, $u_{Y}^{t}$ respectively.
We show the disjointness (in the sense of Furstenberg) between $u_{X}^{t}$ and
$\tilde{u}_{Y}^{t}$ (or $\tilde{u}_{X}^{t}$ and $u_{Y}^{t}$) in certain
situations.
  Our method refines the works of Ratner and extends a recent work of Dong,
Kanigowski and Wei.",http://arxiv.org/abs/2107.03295v1
Stability of regular shrinkers in the network flow,2021-07-09T10:11:02Z,Jui-En Chang,"The singularities of network flow are modeled by self-similarly shrinking
solutions called regular shrinkers. In this paper, we study the stability of
regular shrinkers. We show that all regular shrinkers with two or more enclosed
regions can be perturbed away. Among the regular shrinkers with one enclosed
region, 4-ray star, 5-ray star, fish, and rocket are unstable.",http://arxiv.org/abs/2107.04338v1
"Ergodic convergence rates for time-changed symmetric Lévy processes
  in dimension one",2021-09-03T06:20:47Z,Tao Wang,"We obtain the lower bounds for ergodic convergence rates, including spectral
gaps and convergence rates in strong ergodicity for time-changed symmetric
L\'{e}vy processes by using harmonic function and reversible measure. As direct
applications, explicit sufficient conditions for exponential and strong
ergodicity are given. Some examples are also presented.",http://arxiv.org/abs/2109.01331v2
Dynamic Meta-theorems for Distance and Matching,2021-09-04T14:12:24Z,"Samir Datta, Chetan Gupta, Rahul Jain, Anish Mukherjee, Vimal Raj Sharma, Raghunath Tewari","Reachability, distance, and matching are some of the most fundamental graph
problems that have been of particular interest in dynamic complexity theory in
recent years [DKMSZ18, DMVZ18, DKMTVZ20]. Reachability can be maintained with
first-order update formulas, or equivalently in DynFO in general graphs with n
nodes [DKMSZ18], even under O(log n/loglog n) changes per step [DMVZ18]. In the
context of how large the number of changes can be handled, it has recently been
shown [DKMTVZ20] that under a polylogarithmic number of changes, reachability
is in DynFOpar in planar, bounded treewidth, and related graph classes -- in
fact in any graph where small non-zero circulation weights can be computed in
NC.
  We continue this line of investigation and extend the meta-theorem for
reachability to distance and bipartite maximum matching with the same bounds.
These are amongst the most general classes of graphs known where we can
maintain these problems deterministically without using a majority quantifier
and even maintain witnesses. For the bipartite matching result, modifying the
approach from [FGT], we convert the static non-zero circulation weights to
dynamic matching-isolating weights.
  While reachability is in DynFOar under O(log n/loglog n) changes, no such
bound is known for either distance or matching in any non-trivial class of
graphs under non-constant changes. We show that, in the same classes of graphs
as before, bipartite maximum matching is in DynFOar under O(log n/loglog n)
changes per step. En route to showing this we prove that the rank of a matrix
can be maintained in DynFOar, also under O(log n/loglog n) entry changes,
improving upon the previous O(1) bound [DKMSZ18]. This implies similar
extension for the non-uniform DynFO bound for maximum matching in general
graphs and an alternate algorithm for maintaining reachability under O(log
n/loglog n) changes [DMVZ18].",http://arxiv.org/abs/2109.01875v2
"Stability of a Composite Wave of Two Seperate Strong Viscous Shock Waves
  for 1-D Isentropic Navier-Stokes System",2021-09-06T12:30:02Z,Lin Chang,"In this paper, the large time behavior of solutions of 1-D isentropic
Navier-Stokes system is investigated. It is shown that a composite wave
consisting of two viscous shock waves is stable for the Cauchy problem provided
that the two waves are initially far away from each other. Moreover the
strengths of two waves could be arbitrarily large.",http://arxiv.org/abs/2109.02399v1
"Impact of grain properties on the penetration of intruders near a wall
  into granular matter: a DEM study",2021-11-08T23:39:59Z,"M. Espinosa, E. Altshuler","DEM simulations were used to study the sensitivity of a granular system to
the change of the mechanical properties of the grains, applied to the
penetration of a cylindrical intruder near a vertical wall. The simulations
reproduce a real experimental setup, changing the friction, the Young modulus
and the restitution coefficient of the particles.",http://arxiv.org/abs/2111.04874v1
"A more efficient algorithm to compute the Rand Index for change-point
  problems",2021-12-07T14:52:04Z,Lucas de Oliveira Prates,"In this paper we provide a more efficient algorithm to compute the Rand Index
when the data cluster comes from change-point detection problems. Given $N$
data points and two clusters of size $r$ and $s$, the algorithm runs on
$O(r+s)$ time complexity and $O(1)$ memory complexity. The traditional
algorithm, in contrast, runs on $O(rs+N)$ time complexity and $O(rs)$ memory
complexity.",http://arxiv.org/abs/2112.03738v1
Projective Determinacy from long Chang's Conjecture,2021-12-15T11:51:31Z,Dominik Adolf,"Consider the property $(\aleph_{\omega + 1},\aleph_{\omega + 2},\ldots)
\twoheadrightarrow (\aleph_1,\aleph_2,\ldots)$. Here we will show that this
property with the addition of the General Continuum Hypothesis implies
projective determinacy. Of particular interest here is the use of a variant
covering argument to prove limited instances of mouse reflection. We believe
that this approach could find use for other forms of Chang's Conjecture as
well.",http://arxiv.org/abs/2112.08056v1
"Absolute quantification of real-time PCR data with stage signal
  difference analysis",2021-02-28T06:25:14Z,"Chuanbo Liu, Jin Wang","Real-time PCR, or Real-time Quantitative PCR (qPCR) is an effective approach
to quantify nucleic acid samples. Given the complicated reaction system along
with thermal cycles, there has been long-term confusion on accurately
calculating the initial nucleic acid amounts from the fluorescence signals.
Although many improved algorithms had been proposed, the classical threshold
method is still the primary choice in the routine application. In this study,
we will first illustrate the origin of the linear relationship between the
threshold value and logarithm of the initial nucleic acid amount by
reconstructing the PCR reaction process with stochastic simulations. We then
develop a new method for the absolute quantification of nucleic acid samples
with qPCR. By monitoring the fluorescence signal changes in every stage of the
thermal cycle, we are able to calculate a representation of the step-wise
efficiency change. This is the first work calculated PCR efficiency change
directly from the fluorescence signal, without fitting or sophisticated
analysis. Our results revealed that the efficiency change during the PCR
process is complicated and can not be modeled simply by monotone function
model. Based on the calculated efficiency, we illustrate a new absolute qPCR
analysis method for accurately determining nucleic acid amount. The efficiency
problem is completely avoided in this new method.",http://arxiv.org/abs/2103.00408v1
"Local Change Point Detection and Cleaning of EEMD Signals with
  Application to Acoustic Shockwaves",2021-03-01T23:39:32Z,"Kentaro Hoffman, Jonathan M. Lees, Kai Zhang","The Ensemble Empirical Mode Decomposition (EEMD) has become a preferred
technique to decompose nonlinear and non-stationary signals due to its ability
to create time-varying basis functions. However, current EEMD signal cleaning
techniques are unable to deal with situations where a signal only occurs for a
portion of the entire recording length. By combining change point detection and
statistical hypothesis testing, we demonstrate how to clean a signal to
emphasize unique local changes within each basis function. This not only allows
us to observe which frequency bands are undergoing a change, but also leads to
improved recovery of the underlying information. Using this technique, we
demonstrate improved signal cleaning performance for acoustic shockwave signal
detection. The technique is implemented in R via the LCDSC package.",http://arxiv.org/abs/2103.01352v3
"Glass Transition of the Phase Change Material AIST and its Impact on
  Crystallization",2021-03-11T09:43:29Z,"Julian Pries, Julia Sehringer, Shuai Wei, Pierre Lucas, Matthias Wuttig","Engineering phase change materials (PCM) to realize superior data storage
devices requires a detailed understanding of crystallization kinetics and its
temperature dependence. The temperature dependence of crystallization differs
distinctly between crystallizing from the glassy phase and the undercooled
liquid (UCL). Hence, knowing the phase from which crystallization occurs is
necessary for predicting the switching ability. Here, we measure the glassy
dynamics and crystallization kinetics using calorimetry for heating rates
spanning over six orders of magnitude. Our results show that the prominent PCM
(Ag,In)-doped Sb2Te (AIST) exhibits a change from crystallizing from the glassy
phase to crystallizing from the UCL at a critical heating rate of 5,000 K/s.
Above the glass transition, the activation energy of crystallization changes
drastically enabling rapid crystallization at elevated temperatures.",http://arxiv.org/abs/2103.06565v1
"The role of mobility and sanitary measures on Covid-19 in Costa Rica,
  March through July 2020",2021-03-15T21:43:55Z,"Luis A. Barboza, Paola Vásquez, Gustavo Mery, Fabio Sanchez, Yury E. García, Juan G. Calvo, Tania Rivas, Daniel Salas","The aim of this paper is to infer the effects that changes on human mobility
had on the transmission dynamics during the first four months of the SARS-CoV-2
outbreak in Costa Rica, before community transmission was established in the
country. By using parametric and non parametric detection change-point
techniques we were able to identify two different periods where at least the
trend and variability of new daily cases significantly changed. In order to
combine this information with population movement, we use data from Google
Mobility Trends that allow us to estimate the lag between the rate of new daily
cases and each of the categories established by Google. The information is then
used to establish an association between changes in population mobility and the
sanitary measures taken during the study period.",http://arxiv.org/abs/2103.08732v1
"An Exploratory Study of Project Activity Changepoints in Open Source
  Software Evolution",2021-03-19T20:32:33Z,"James Walden, Noah Burgin, Kuljit Kaur","To explore the prevalence of abrupt changes (changepoints) in open source
project activity, we assembled a dataset of 8,919 projects from the World of
Code. Projects were selected based on age, number of commits, and number of
authors. Using the nonparametric PELT algorithm, we identified changepoints in
project activity time series, finding that more than 90% of projects had
between one and six changepoints. Increases and decreases in project activity
occurred with roughly equal frequency. While most changes are relatively small,
on the order of a few authors or few dozen commits per month, there were long
tails of much larger project activity changes. In future work, we plan to focus
on larger changes to search for common open source lifecycle patterns as well
as common responses to external events.",http://arxiv.org/abs/2103.11013v1
"Semantic 3D Map Change Detection and Update based on Smartphone Visual
  Positioning System",2021-03-21T05:33:21Z,"Max Jwo Lem Lee, Li-Ta Hsu","Accurate localization and 3D maps are increasingly needed for various
artificial intelligence based IoT applications such as augmented reality,
intelligent transportation, crowd monitoring, robotics, etc. This article
proposes a novel semantic 3D map change detection and update based on a
smartphone visual positioning system (VPS) for the outdoor and indoor
environments. The proposed method presents an alternate solution to SLAM for
map update in terms of efficiency, cost, availability, and map reuse. Building
on existing 3D maps of recent years, a system is designed to use artificial
intelligence to identify high-level semantics in images for positioning and map
change detection. Then, a virtual LIDAR that estimates the depth of objects in
the 3D map is used to generate a compact point cloud to update changes in the
scene. We present an excellent performance of localization with respect to
other state-of-the-art smartphone positioning solutions to accurately update
semantic 3D maps. It is shown that the proposed solution can position users
within 1.9m, and update objects with an average error of 2.1m.",http://arxiv.org/abs/2103.11311v1
"Rule-Based Safety-Critical Control Design using Control Barrier
  Functions with Application to Autonomous Lane Change",2021-03-23T08:31:29Z,"Suiyi He, Jun Zeng, Bike Zhang, Koushil Sreenath","This paper develops a new control design for guaranteeing a vehicle's safety
during lane change maneuvers in a complex traffic environment. The proposed
method uses a finite state machine (FSM), where a quadratic program based
optimization problem using control Lyapunov functions and control barrier
functions (CLF-CBF-QP) is used to calculate the system's optimal inputs via
rule-based control strategies. The FSM can make switches between different
states automatically according to the command of driver and traffic
environment, which makes the ego vehicle find a safe opportunity to do a
collision-free lane change maneuver. By using a convex quadratic program, the
controller can guarantee the system's safety at a high update frequency. A set
of pre-designed typical lane change scenarios as well as randomly generated
driving scenarios are simulated to show the performance of our controller.",http://arxiv.org/abs/2103.12382v1
Manipulating Berry curvature of SrRuO3 thin films via epitaxial strain,2021-03-24T03:53:34Z,"Di Tian, Zhiwei Liu, Shengchun Shen, Zhuolu Li, Yu Zhou, Hongquan Liu, Hanghui Chen, Pu Yu","Berry curvature plays a crucial role in exotic electronic states of quantum
materials, such as intrinsic anomalous Hall effect. As Berry curvature is
highly sensitive to subtle changes of electronic band structures, it can be
finely tuned via external stimulus. Here, we demonstrate in SrRuO3 thin films
that both the magnitude and sign of anomalous Hall resistivity can be
effectively controlled with epitaxial strain. Our first-principles calculations
reveal that epitaxial strain induces an additional crystal field splitting and
changes the order of Ru d orbital energies, which alters the Berry curvature
and leads to the sign and magnitude change of anomalous Hall conductivity.
Furthermore, we show that the rotation of Ru magnetic moment in real space of
tensile strained sample can result in an exotic nonmonotonic change of
anomalous Hall resistivity with the sweeping of magnetic field, resembling the
topological Hall effect observed in non-coplanar spin systems. These findings
not only deepen our understanding of anomalous Hall effect in SrRuO3 systems,
but also provide an effective tuning knob to manipulate Berry curvature and
related physical properties in a wide range of quantum materials.",http://arxiv.org/abs/2103.12973v1
"Continual Active Learning for Efficient Adaptation of Machine Learning
  Models to Changing Image Acquisition",2021-06-07T05:39:06Z,"Matthias Perkonigg, Johannes Hofmanninger, Georg Langs","Imaging in clinical routine is subject to changing scanner protocols,
hardware, or policies in a typically heterogeneous set of acquisition hardware.
Accuracy and reliability of deep learning models suffer from those changes as
data and targets become inconsistent with their initial static training set.
Continual learning can adapt to a continuous data stream of a changing imaging
environment. Here, we propose a method for continual active learning on a data
stream of medical images. It recognizes shifts or additions of new imaging
sources - domains -, adapts training accordingly, and selects optimal examples
for labelling. Model training has to cope with a limited labelling budget,
resembling typical real world scenarios. We demonstrate our method on
T1-weighted magnetic resonance images from three different scanners with the
task of brain age estimation. Results demonstrate that the proposed method
outperforms naive active learning while requiring less manual labelling.",http://arxiv.org/abs/2106.03351v1
"Quickest change detection with unknown parameters: Constant complexity
  and near optimality",2021-06-09T13:29:26Z,"Firas Jarboui, Viannet Perchet","We consider the quickest change detection problem where both the parameters
of pre- and post- change distributions are unknown, which prevents the use of
classical simple hypothesis testing. Without additional assumptions, optimal
solutions are not tractable as they rely on some minimax and robust variant of
the objective. As a consequence, change points might be detected too late for
practical applications (in economics, health care or maintenance for instance).
Available constant complexity techniques typically solve a relaxed version of
the problem, deeply relying on very specific probability distributions and/or
some very precise additional knowledge. We consider a totally different
approach that leverages the theoretical asymptotic properties of optimal
solutions to derive a new scalable approximate algorithm with near optimal
performance that runs~in~$\mathcal{O}(1)$, adapted to even more complex
Markovian settings.",http://arxiv.org/abs/2106.05061v1
Online Bayesian inference for multiple changepoints and risk assessment,2021-05-31T13:09:09Z,"Olivier Sorba, C Geissler","The aim of the present study is to detect abrupt trend changes in the mean of
a multidimensional sequential signal. Directly inspired by papers of Fernhead
and Liu ([4] and [5]), this work describes the signal in a hierarchical manner
: the change dates of a time segmentation process trigger the renewal of a
piece-wise constant emission law. Bayesian posterior information on the change
dates and emission parameters is obtained. These estimations can be revised
online, i.e. as new data arrive. This paper proposes explicit formulations
corresponding to various emission laws, as well as a generalization to the case
where only partially observed data are available. Practical applications
include the returns of partially observed multi-asset investment strategies,
when only scant prior knowledge of the movers of the returns is at hand,
limited to some statistical assumptions. This situation is different from the
study of trend changes in the returns of individual assets, where fundamental
exogenous information (news, earnings announcements, controversies, etc.) can
be used.",http://arxiv.org/abs/2106.05834v1
"Measuring the repertoire of age-related behavioral changes in Drosophila
  melanogaster",2021-06-14T17:15:08Z,"Katherine E. Overman, Daniel M. Choi, Kawai Leung, Joshua W. Shaevitz, Gordon J. Berman","Aging affects almost all aspects of an organism -- its morphology, its
physiology, its behavior. Isolating which biological mechanisms are regulating
these changes, however, has proven difficult, potentially due to our inability
to characterize the full repertoire of an animal's behavior across the
lifespan. Using data from fruit flies (D. melanogaster) we measure the full
repertoire of behaviors as a function of age. We observe a sexually dimorphic
pattern of changes in the behavioral repertoire during aging. Although the
stereotypy of the behaviors and the complexity of the repertoire overall
remains relatively unchanged, we find evidence that the observed alterations in
behavior can be explained by changing the fly's overall energy budget,
suggesting potential connections between metabolism, aging, and behavior.",http://arxiv.org/abs/2106.07610v2
Towards a Framework for Changing-Contact Robot Manipulation,2021-06-21T10:44:28Z,"Saif Sidhik, Mohan Sridharan, Dirk Ruiken","Many robot manipulation tasks require the robot to make and break contact
with objects and surfaces. The dynamics of such changing-contact robot
manipulation tasks are discontinuous when contact is made or broken, and
continuous elsewhere. These discontinuities make it difficult to construct and
use a single dynamics model or control strategy for any such task. We present a
framework for smooth dynamics and control of such changing-contact manipulation
tasks. For any given target motion trajectory, the framework incrementally
improves its prediction of when contacts will occur. This prediction and a
model relating approach velocity to impact force modify the velocity profile of
the motion sequence such that it is $C^\infty$ smooth, and help achieve a
desired force on impact. We implement this framework by building on our hybrid
force-motion variable impedance controller for continuous contact tasks. We
experimentally evaluate our framework in the illustrative context of sliding
tasks involving multiple contact changes with transitions between surfaces of
different properties.",http://arxiv.org/abs/2106.10969v1
Computação: O vetor de transformação da sociedade,2021-06-21T21:36:39Z,"Avelino Francisco Zorzo, Andree Luis Alice Raabe, Christian Brackmann","Society is changing, has always changed, and will keep changing. However,
changes are becoming faster and what used to happen between generations, now
happens in the same generation. Computing Science is one of the reasons for
this speed and permeates, basically, every other knowledge area. This paper
(written in Portugu\^es) describes, briefly, the worldwide initiatives to
introduce Computing Science teaching in schools. As the paper's main
conclusion, it is essential to introduce Computing Science and Computational
Thinking for kids before they enter into a university.",http://arxiv.org/abs/2106.11419v1
"Mitigating the Impact of Distributed Generations on Relay Coordination
  Using Fault Current Limiters",2021-06-23T13:50:05Z,"Meisam Ansari, Mostafa Ansari","The use of distributed generation resources, in addition to considerable
benefits, causes some problems in the power system. One of the most critical
problems in the case of disruption is increasing short-circuit current level in
grids, which leads to change the protection devices settings in the downstream
and upstream grid. By using fault current limiters (FCL), short-circuit
currents in grids with distributed generation can be reduced to acceptable
levels, so there is no needed to change the protection relays settings of the
downstream grid (including distributed generations). However, by locating the
FCL in the tie-feeder, the downstream grid is not more effective than the
upstream grid and thus its reliability indices also will be changed. Therefore,
this paper shows that by locating the unidirectional fault current limiter
(UFCL) in the tie-feeder, the necessity of changing in the relay protection
settings of upstream grids is prevented. In this paper, the proposed method is
implemented, and its efficiency is reported in six scenarios.",http://arxiv.org/abs/2106.12406v1
A Closer Look at How Fine-tuning Changes BERT,2021-06-27T17:01:43Z,"Yichu Zhou, Vivek Srikumar","Given the prevalence of pre-trained contextualized representations in today's
NLP, there have been many efforts to understand what information they contain,
and why they seem to be universally successful. The most common approach to use
these representations involves fine-tuning them for an end task. Yet, how
fine-tuning changes the underlying embedding space is less studied. In this
work, we study the English BERT family and use two probing techniques to
analyze how fine-tuning changes the space. We hypothesize that fine-tuning
affects classification performance by increasing the distances between examples
associated with different labels. We confirm this hypothesis with carefully
designed experiments on five different NLP tasks. Via these experiments, we
also discover an exception to the prevailing wisdom that ""fine-tuning always
improves performance"". Finally, by comparing the representations before and
after fine-tuning, we discover that fine-tuning does not introduce arbitrary
changes to representations; instead, it adjusts the representations to
downstream tasks while largely preserving the original spatial structure of the
data points.",http://arxiv.org/abs/2106.14282v3
Change-Point Detection in Dynamic Networks with Missing Links,2021-06-28T08:35:10Z,"Farida Enikeeva, Olga Klopp","Structural changes occur in dynamic networks quite frequently and its
detection is an important question in many situations such as fraud detection
or cybersecurity. Real-life networks are often incompletely observed due to
individual non-response or network size. In the present paper we consider the
problem of change-point detection at a temporal sequence of partially observed
networks. The goal is to test whether there is a change in the network
parameters. Our approach is based on the Matrix CUSUM test statistic and allows
growing size of networks. We show that the proposed test is minimax optimal and
robust to missing links. We also demonstrate the good behavior of our approach
in practice through simulation study and a real-data application.",http://arxiv.org/abs/2106.14470v1
"Sequential Multivariate Change Detection with Calibrated and Memoryless
  False Detection Rates",2021-08-02T13:36:33Z,"Oliver Cobb, Arnaud Van Looveren, Janis Klaise","Responding appropriately to the detections of a sequential change detector
requires knowledge of the rate at which false positives occur in the absence of
change. Setting detection thresholds to achieve a desired false positive rate
is challenging. Existing works resort to setting time-invariant thresholds that
focus on the expected runtime of the detector in the absence of change, either
bounding it loosely from below or targeting it directly but with asymptotic
arguments that we show cause significant miscalibration in practice. We present
a simulation-based approach to setting time-varying thresholds that allows a
desired expected runtime to be accurately targeted whilst additionally keeping
the false positive rate constant across time steps. Whilst the approach to
threshold setting is metric agnostic, we show how the cost of using the popular
quadratic time MMD estimator can be reduced from $O(N^2B)$ to $O(N^2+NB)$
during configuration and from $O(N^2)$ to $O(N)$ during operation, where $N$
and $B$ are the numbers of reference and bootstrap samples respectively.",http://arxiv.org/abs/2108.00883v2
Evolution of emotion semantics,2021-08-05T23:46:22Z,"Aotao Xu, Jennifer E. Stellar, Yang Xu","Humans possess the unique ability to communicate emotions through language.
Although concepts like anger or awe are abstract, there is a shared consensus
about what these English emotion words mean. This consensus may give the
impression that their meaning is static, but we propose this is not the case.
We cannot travel back to earlier periods to study emotion concepts directly,
but we can examine text corpora, which have partially preserved the meaning of
emotion words. Using natural language processing of historical text, we found
evidence for semantic change in emotion words over the past century and that
varying rates of change were predicted in part by an emotion concept's
prototypicality - how representative it is of the broader category of
""emotion"". Prototypicality negatively correlated with historical rates of
emotion semantic change obtained from text-based word embeddings, beyond more
established variables including usage frequency in English and a second
comparison language, French. This effect for prototypicality did not
consistently extend to the semantic category of birds, suggesting its relevance
for predicting semantic change may be category-dependent. Our results suggest
emotion semantics are evolving over time, with prototypical emotion words
remaining semantically stable, while other emotion words evolve more freely.",http://arxiv.org/abs/2108.02887v1
"The response of black hole spark gaps to external changes: A production
  mechanism of rapid TeV flares?",2021-08-06T06:52:46Z,"Shota Kisaka, Amir Levinson, Kenji Toma, Idan Niv","We study the response of a starved Kerr black hole magnetosphere to abrupt
changes in the intensity of disk emission and in the global magnetospheric
current, by means of 1D general relativistic particle-in-cell simulations. Such
changes likely arise from the intermittency of the accretion process. We find
that in cases where the pair production opacity contributed by the soft disk
photons is modest, as in, e.g., M87, such changes can give rise to delayed,
strong TeV flares, dominated by curvature emission of particles accelerated in
the gap. The flare rise time, and the delay between the external variation and
the onset of the flare emitted from the outer gap boundary, are of the order of
the light crossing time of the gap. The rapid, large amplitude TeV flares
observed in M87 and, perhaps, other AGNs may be produced by such a mechanism.",http://arxiv.org/abs/2108.02971v3
Cyclic Cellular Automata and Greenberg-Hastings Models on Regular Trees,2021-08-13T21:24:36Z,"Jason Bello, David Sivakoff","We study the cyclic cellular automaton (CCA) and the Greenberg-Hastings model
(GHM) with $\kappa\ge 3$ colors and contact threshold $\theta\ge 2$ on the
infinite $(d+1)$-regular tree, $T_d$. When the initial state has the uniform
product distribution, we show that these dynamical systems exhibit at least two
distinct phases. For sufficiently large $d$, we show that if $\kappa(\theta-1)
\le d - O(\sqrt{d\kappa \ln(d)})$, then every vertex almost surely changes its
color infinitely often, while if $\kappa\theta \ge d +
O(\kappa\sqrt{d\ln(d)})$, then every vertex almost surely changes its color
only finitely many times. Roughly, this implies that as $d\to \infty$, there is
a phase transition where $\kappa\theta/d = 1$. For the GHM dynamics, in the
scenario where every vertex changes color finitely many times, we moreover give
an exponential tail bound for the distribution of the time of the last color
change at a given vertex.",http://arxiv.org/abs/2108.06404v1
"The Chang-Marshall Trace Inequality for Sobolev functions in domains in
  higher dimensional space $\mathbb{R}^n$",2021-08-15T18:50:41Z,"Jungang Li, Guozhen Lu","In their celebrated work [5], Chang and Marshall established a critical trace
inequality of Moser-Trudinger type for holomorphic functions with mean value
zero on unit disc in the complex plane. The main purpose is to address a
question proposed to us by S. Y. Alice Chang who asked whether the
Chang-Marshall type inequality for holomorphic functions on unit disk in the
complex plane holds for Sobolev functions on general domains in higher
dimensional Euclidean space $\mathbb{R}^n$ for all $n\ge 2$. We partially
answer her question affirmatively.",http://arxiv.org/abs/2108.06792v2
Equivariant Variance Estimation for Multiple Change-point Model,2021-08-21T04:17:25Z,"Ning Hao, Yue Selena Niu, Han Xiao","The variance of noise plays an important role in many change-point detection
procedures and the associated inferences. Most commonly used variance
estimators require strong assumptions on the true mean structure or normality
of the error distribution, which may not hold in applications. More
importantly, the qualities of these estimators have not been discussed
systematically in the literature. In this paper, we introduce a framework of
equivariant variance estimation for multiple change-point models. In
particular, we characterize the set of all equivariant unbiased quadratic
variance estimators for a family of change-point model classes, and develop a
minimax theory for such estimators.",http://arxiv.org/abs/2108.09431v3
"A Generalized Knockoff Procedure for FDR Control in Structural Change
  Detection",2021-08-24T09:25:17Z,"Jingyuan Liu, Ao Sun, Yuan Ke","Controlling false discovery rate (FDR) is crucial for variable selection,
multiple testing, among other signal detection problems. In literature, there
is certainly no shortage of FDR control strategies when selecting individual
features, but the relevant works for structural change detection, such as
profile analysis for piecewise constant coefficients and integration analysis
with multiple data sources, are limited. In this paper, we propose a
generalized knockoff procedure (GKnockoff) for FDR control under such problem
settings. We prove that the GKnockoff possesses pairwise exchangeability, and
is capable of controlling the exact FDR under finite sample sizes. We further
explore GKnockoff under high dimensionality, by first introducing a new
screening method to filter the high-dimensional potential structural changes.
We adopt a data splitting technique to first reduce the dimensionality via
screening and then conduct GKnockoff on the refined selection set. Furthermore,
the powers of proposed methods are systematically studied. Numerical
comparisons with other methods show the superior performance of GKnockoff, in
terms of both FDR control and power. We also implement the proposed methods to
analyze a macroeconomic dataset for detecting changes of driven effects of
economic development on the secondary industry.",http://arxiv.org/abs/2108.10595v2
"HapticBots: Distributed Encountered-type Haptics for VR with Multiple
  Shape-changing Mobile Robots",2021-08-24T16:26:22Z,"Ryo Suzuki, Eyal Ofek, Mike Sinclair, Daneil Leithinger, Mar Gonzalez-Franco","HapticBots introduces a novel encountered-type haptic approach for Virtual
Reality (VR) based on multiple tabletop-size shape-changing robots. These
robots move on a tabletop and change their height and orientation to haptically
render various surfaces and objects on-demand. Compared to previous
encountered-type haptic approaches like shape displays or robotic arms, our
proposed approach has an advantage in deployability, scalability, and
generalizability -- these robots can be easily deployed due to their compact
form factor. They can support multiple concurrent touch points in a large area
thanks to the distributed nature of the robots. We propose and evaluate a novel
set of interactions enabled by these robots which include: 1) rendering haptics
for VR objects by providing just-in-time touch-points on the user's hand, 2)
simulating continuous surfaces with the concurrent height and position change,
and 3) enabling the user to pick up and move VR objects through graspable proxy
objects. Finally, we demonstrate HapticBots with various applications,
including remote collaboration, education and training, design and 3D modeling,
and gaming and entertainment.",http://arxiv.org/abs/2108.10829v1
"On variational principles for polarization responses in
  electromechanical systems",2021-08-25T23:17:27Z,"Yiwei Wang, Chun Liu, Bob Eisenberg","Classical electrodynamics uses a dielectric constant to describe the
polarization response of electromechanical systems to changes in an electric
field. We generalize that description to include a wide variety of responses to
changes in the electric field, as found in most systems and applications.
Electromechanical systems can be found in many physical and biological
applications, such as ion transport in membranes, batteries, and dielectric
elastomers. We present a unified, thermodynamically consistent, variational
framework for modeling electromechanical systems as they respond to changes in
the electric field; that is to say, as they polarize. This framework is
motivated and developed using the classical energetic variational approach
(EnVarA). The coupling between the electric part and the chemo-mechanical parts
of the system is described either by Lagrange multipliers or various energy
relaxations. The classical polarization and its dielectrics and dielectric
constants appear as outputs of this analysis. The Maxwell equations then become
universal conservation laws of charge and current, conjoined to an
electromechanical description of polarization. Polarization describes the
entire electromechanical response to changes in the electric field and can
sometimes be approximated as a dielectric constant or dielectric dispersion.",http://arxiv.org/abs/2108.11512v2
Can an AI agent hit a moving target?,2021-10-06T03:16:54Z,"Rui, Shi","I model the belief formation and decision making processes of economic agents
during a monetary policy regime change (an acceleration in the money supply)
with a deep reinforcement learning algorithm in the AI literature. I show that
when the money supply accelerates, the learning agents only adjust their
actions, which include consumption and demand for real balance, after gathering
learning experience for many periods. This delayed adjustments leads to low
returns during transition periods. Once they start adjusting to the new
environment, their welfare improves. Their changes in beliefs and actions lead
to temporary inflation volatility. I also show that, 1. the AI agents who
explores their environment more adapt to the policy regime change quicker,
which leads to welfare improvements and less inflation volatility, and 2. the
AI agents who have experienced a structural change adjust their beliefs and
behaviours quicker than an inexperienced learning agent.",http://arxiv.org/abs/2110.02474v3
Subspace Change-Point Detection via Low-Rank Matrix Factorisation,2021-10-08T11:36:08Z,"Euan Thomas McGonigle, Hankui Peng","Multivariate time series can often have a large number of dimensions, whether
it is due to the vast amount of collected features or due to how the data
sources are processed. Frequently, the main structure of the high-dimensional
time series can be well represented by a lower dimensional subspace. As vast
quantities of data are being collected over long periods of time, it is
reasonable to assume that the underlying subspace structure would change over
time. In this work, we propose a change-point detection method based on
low-rank matrix factorisation that can detect multiple changes in the
underlying subspace of a multivariate time series. Experimental results on both
synthetic and real data sets demonstrate the effectiveness of our approach and
its advantages against various state-of-the-art methods.",http://arxiv.org/abs/2110.04044v1
"Online network change point detection with missing values and temporal
  dependence",2021-10-13T02:28:32Z,"Haotian Xu, Paromita Dubey, Yi Yu","In this paper we study online change point detection in dynamic networks with
time heterogeneous missing pattern within networks and dependence across the
time course. The missingness probabilities, the entrywise sparsity of networks,
the rank of networks and the jump size in terms of the Frobenius norm, are all
allowed to vary as functions of the pre-change sample size. On top of a
thorough handling of all the model parameters, we notably allow the edges and
missingness to be dependent. To the best of our knowledge, such general
framework has not been rigorously nor systematically studied before in the
literature. We propose a polynomial time change point detection algorithm, with
a version of soft-impute algorithm (e.g. Mazumder et al., 2010; Klopp, 2015) as
the imputation sub-routine. Piecing up these standard sub-routines algorithms,
we are able to solve a brand new problem with sharp detection delay subject to
an overall Type-I error control. Extensive numerical experiments are conducted
demonstrating the outstanding performances of our proposed method in practice.",http://arxiv.org/abs/2110.06450v3
"Masking Effects in Combined Hardness and Stiffness Rendering Using an
  Encountered-Type Haptic Display",2021-10-13T18:53:12Z,"Naghmeh Zamani, Heather Culbertson","Rendering stable hard surfaces is an important problem in haptics for many
tasks, including training simulators for orthopedic surgery or dentistry.
Current impedance devices cannot provide enough force and stiffness to render a
wall, and the high friction and inertia of admittance devices make it difficult
to render free space. We propose to address these limitations by combining
haptic augmented reality, untethered haptic interaction, and an
encountered-type haptic display. We attach a plate with the desired hardness on
the kinesthetic device's end-effector, which the user interacts with using an
untethered stylus. This method allows us to directly change the hardness of the
end-effector based on the rendered object. In this paper, we evaluate how
changing the hardness of the end-effector can mask the device's stiffness and
affect the user's perception. The results of our human subject experiment
indicate that when the end-effector is made of a hard material, it is difficult
for users to perceive when the underlying stiffness being rendered by the
device is changed, but this stiffness change is easy to distinguish while the
end-effector is made of a soft material. These results show promise for our
approach in avoiding the limitations of haptic devices when rendering hard
surfaces.",http://arxiv.org/abs/2110.06982v1
"A fully conservative sharp-interface method for compressible mulitphase
  flows with phase change",2021-10-15T10:37:50Z,"Tian Long, Jinsheng Cai, Shucheng Pan","A fully conservative sharp-interface method is developed for multiphase flows
with phase change. The coupling between two phases is implemented via
introducing the interfacial fluxes, which are obtained by solving a general
Riemann problem with phase change. A novel four-wave model is proposed to
obtain an approximate Riemann solution, which simplifies the eight-dimensional
roo-finding procedure in the exact solver to a sole iteration of the mass flux.
Unlike in the previous research, the jump conditions of all waves are imposed
strictly in the present approximate Riemann solver so that conservation is
guaranteed. Different choices of the fluid states used in the phase change
model are compared, and we have shown that the adjacent states of phase
interface should be used to ensure numerical consistency. To the authors'
knowledge, it has not been reported before in the open literature. With good
agreements, various numerical examples are considered to validate the present
method by comparing the results against the exact solutions or the previous
simulations.",http://arxiv.org/abs/2110.07995v1
"Valid and Exact Statistical Inference for Multi-dimensional Multiple
  Change-Points by Selective Inference",2021-10-18T02:44:34Z,"Ryota Sugiyama, Hiroki Toda, Vo Nguyen Le Duy, Yu Inatsu, Ichiro Takeuchi","In this paper, we study statistical inference of change-points (CPs) in
multi-dimensional sequence. In CP detection from a multi-dimensional sequence,
it is often desirable not only to detect the location, but also to identify the
subset of the components in which the change occurs. Several algorithms have
been proposed for such problems, but no valid exact inference method has been
established to evaluate the statistical reliability of the detected locations
and components. In this study, we propose a method that can guarantee the
statistical reliability of both the location and the components of the detected
changes. We demonstrate the effectiveness of the proposed method by applying it
to the problems of genomic abnormality identification and human behavior
analysis.",http://arxiv.org/abs/2110.08989v1
"Spatial-temporal water area monitoring of Miyun Reservoir using remote
  sensing imagery from 1984 to 2020",2021-10-14T17:24:12Z,"Chang Liu, Hairong Tang, Luyan Ji, Yongchao Zhao","Miyun Reservoir has produced huge benefits in flood control, agricultural
irrigation, power generation, aquaculture, tourism, and urban water supply.
Accurately water mapping is of great significance to the ecological environment
monitoring of the Miyun Reservoir and the management of the South-to-North
Water Diversion Project. On the 60th anniversary of the completion of the Miyun
Reservoir, we took the Miyun Reservoir as the study area and collected all the
Landsat-5 and Landsat-8 remote sensing images from 1984 to 2020 for water
mapping. Based on the spectral, topographical and temporal-spatial
characteristics of water, we proposed an automated method for long-term
researvoir mapping, which can solve the problems caused by cloud, shadow, ice
and snow pixels. Moreover, it can also deal with 'the same objects with
different spectra' and spectral mixed problems. The overall accuracy is as high
as 98.2% for the case with no cloud or snow/ice cover. The landscape division
index is introduced to analyze the morphological changes of Miyun Reservoir.
Based on the mapping results, we analyzed the changes of Miyun Reservoir from
1984 to 2020 and the driving factors of them.",http://arxiv.org/abs/2110.09515v1
"Bayes Factors can only Quantify Evidence w.r.t. Sets of Parameters, not
  w.r.t. (Prior) Distributions on the Parameter",2021-10-19T11:50:20Z,"Patrick Schwaferts, Thomas Augustin","Bayes factors are characterized by both the powerful mathematical framework
of Bayesian statistics and the useful interpretation as evidence
quantification. Former requires a parameter distribution that changes by seeing
the data, latter requires two fixed hypotheses w.r.t. which the evidence
quantification refers to. Naturally, these fixed hypotheses must not change by
seeing the data, only their credibility should! Yet, it is exactly such a
change of the hypotheses themselves (not only their credibility) that occurs by
seeing the data, if their content is represented by parameter distributions (a
recent trend in the context of Bayes factors for about one decade), rendering a
correct interpretation of the Bayes factor rather useless. Instead, this paper
argues that the inferential foundation of Bayes factors can only be maintained,
if hypotheses are sets of parameters, not parameter distributions. In addition,
particular attention has been paid to providing an explicit terminology of the
big picture of statistical inference in the context of Bayes factors as well as
to the distinction between knowledge (formalized by the prior distribution and
being allowed to change) and theoretical positions (formalized as hypotheses
and required to stay fixed) of the phenomenon of interest.",http://arxiv.org/abs/2110.09871v1
"Analysis of memory consumption by neural networks based on
  hyperparameters",2021-10-21T18:49:44Z,Mahendran N,"Deep learning models are trained and deployed in multiple domains. Increasing
usage of deep learning models alarms the usage of memory consumed while
computation by deep learning models. Existing approaches for reducing memory
consumption like model compression, hardware changes are specific. We propose a
generic analysis of memory consumption while training deep learning models in
comparison with hyperparameters used for training. Hyperparameters which
includes the learning rate, batchsize, number of hidden layers and depth of
layers decide the model performance, accuracy of the model. We assume the
optimizers and type of hidden layers as a known values. The change in
hyperparamaters and the number of hidden layers are the variables considered in
this proposed approach. For better understanding of the computation cost, this
proposed analysis studies the change in memory consumption with respect to
hyperparameters as main focus. This results in general analysis of memory
consumption changes during training when set of hyperparameters are altered.",http://arxiv.org/abs/2110.11424v1
"Reanalysis of c-type RR Lyrae Variable BE Dor, Period Modulations and
  Possible Mechanism",2021-10-22T06:40:02Z,"L. -J. Li, S. -B. Qian, L. -Y. Zhu","We reanalyzed the c-type RR Lyrae star BE Dor (MACHO 5.4644.8,
OGLE-LMC-RRLYR-06002) that had been discovered to show cyclic period changes.
The photometric data of several sky surveys (DASCH, MACHO, OGLE, ASAS-SN, and
TESS) were used for analyses. The O-C diagram and pulsation period obtained
from Fourier analysis show significant period modulations in BE Dor. However,
different from the previous viewpoint, the changes are quasi-periodic and
abrupt. Therefore, the light-travel time effect caused by the companion motion
cannot explain the changes. Noting a same subtype star KIC 9453114 with similar
phenomena has a high macroturbulent velocity, and the degree of O-C changes
seem to be positively correlated with these velocities, we consider that the
mechanism leading to period modulation should be caused by the interaction
between turbulent convection and magnetic field activity in the ionization
zone, i.e., the viewpoint of Stothers. It may not explain the general Blazhko
effect but should explain such period modulations in BE Dor and those other
c-type RR Lyrae stars. We hope our discoveries and viewpoints can provide some
information and inspiration for relevant research.",http://arxiv.org/abs/2110.11615v2
Contact Information Flow and Design of Compliance,2021-10-24T13:18:16Z,"Kevin Haninger, Marcel Radke, Richard Hartisch, Jörg Krüger","Identifying changes in contact during contact-rich manipulation can detect
task state or errors, enabling improved robustness and autonomy. The ability to
detect contact is affected by the mechatronic design of the robot, especially
its physical compliance. Established methods can design physical compliance for
many aspects of contact performance (e.g. peak contact force, motion/force
control bandwidth), but are based on time-invariant dynamic models. A change in
contact mode is a discrete change in coupled robot-environment dynamics, not
easily considered in existing design methods. Towards designing robots which
can robustly detect changes in contact mode online, this paper investigates how
mechatronic design can improve contact estimation, with a focus on the impact
of the location and degree of compliance. A design metric of information gain
is proposed which measures how much position/force measurements reduce
uncertainty in the contact mode estimate. This information gain is developed
for fully- and partially-observed systems, as partial observability can arise
from joint flexibility in the robot or environmental inertia. Hardware
experiments with various compliant setups validate that information gain
predicts the speed and certainty with which contact is detected in (i)
monitoring of contact-rich assembly and (ii) collision detection.",http://arxiv.org/abs/2110.12435v2
Detecting model drift using polynomial relations,2021-10-24T18:25:21Z,"Eliran Roffe, Samuel Ackerman, Orna Raz, Eitan Farchi","Machine learning models serve critical functions, such as classifying loan
applicants as good or bad risks. Each model is trained under the assumption
that the data used in training and in the field come from the same underlying
unknown distribution. Often, this assumption is broken in practice. It is
desirable to identify when this occurs, to minimize the impact on model
performance.
  We suggest a new approach to detecting change in the data distribution by
identifying polynomial relations between the data features. We measure the
strength of each identified relation using its R-square value. A strong
polynomial relation captures a significant trait of the data which should
remain stable if the data distribution does not change. We thus use a set of
learned strong polynomial relations to identify drift. For a set of polynomial
relations that are stronger than a given threshold, we calculate the amount of
drift observed for that relation. The amount of drift is measured by
calculating the Bayes Factor for the polynomial relation likelihood of the
baseline data versus field data. We empirically validate the approach by
simulating a range of changes, and identify drift using the Bayes Factor of the
polynomial relation likelihood change.",http://arxiv.org/abs/2110.12506v2
"Testing and Estimating Structural Breaks in Time Series and Panel Data
  in Stata",2021-10-27T16:17:31Z,"Jan Ditzen, Yiannis Karavias, Joakim Westerlund","Identifying structural change is a crucial step in analysis of time series
and panel data. The longer the time span, the higher the likelihood that the
model parameters have changed as a result of major disruptive events, such as
the 2007--2008 financial crisis and the 2020 COVID--19 outbreak. Detecting the
existence of breaks, and dating them is therefore necessary, not only for
estimation purposes but also for understanding drivers of change and their
effect on relationships. This article introduces a new community contributed
command called xtbreak, which provides researchers with a complete toolbox for
analysing multiple structural breaks in time series and panel data. xtbreak can
detect the existence of breaks, determine their number and location, and
provide break date confidence intervals. The new command is used to explore
changes in the relationship between COVID--19 cases and deaths in the US, using
both aggregate and state level data, and in the relationship between approval
ratings and consumer confidence, using a panel of eight countries.",http://arxiv.org/abs/2110.14550v3
"Sparsely Changing Latent States for Prediction and Planning in Partially
  Observable Domains",2021-10-29T17:50:44Z,"Christian Gumbsch, Martin V. Butz, Georg Martius","A common approach to prediction and planning in partially observable domains
is to use recurrent neural networks (RNNs), which ideally develop and maintain
a latent memory about hidden, task-relevant factors. We hypothesize that many
of these hidden factors in the physical world are constant over time, changing
only sparsely. To study this hypothesis, we propose Gated $L_0$ Regularized
Dynamics (GateL0RD), a novel recurrent architecture that incorporates the
inductive bias to maintain stable, sparsely changing latent states. The bias is
implemented by means of a novel internal gating function and a penalty on the
$L_0$ norm of latent state changes. We demonstrate that GateL0RD can compete
with or outperform state-of-the-art RNNs in a variety of partially observable
prediction and control tasks. GateL0RD tends to encode the underlying
generative factors of the environment, ignores spurious temporal dependencies,
and generalizes better, improving sampling efficiency and overall performance
in model-based planning and reinforcement learning tasks. Moreover, we show
that the developing latent states can be easily interpreted, which is a step
towards better explainability in RNNs.",http://arxiv.org/abs/2110.15949v2
"Unraveling the optical contrast in Sb2Te and AgInSbTe phase-change
  materials",2021-01-04T06:03:16Z,"Shehzad Ahmed, Xudong Wang, Yuxing Zhou, Liang Sun, Riccardo Mazzarello, Wei Zhang","Chalcogenide phase-change materials (PCMs) show a significant contrast in
optical reflectivity and electrical resistivity upon crystallization from the
amorphous phase and are leading candidates for non-volatile photonic and
electronic applications. In addition to the flagship Ge2Sb2Te5 phase-change
alloy, doped Sb2Te alloys, in particular AgInSbTe used in rewritable optical
discs, have been widely investigated for decades, and nevertheless the
theoretical insights on the optical properties of this important family of PCMs
are scarce. Here, we carry out thorough ab initio simulations to gain an
atomistic understanding of the optical properties of Sb2Te and AgInSbTe. We
show that the large optical contrast between the amorphous and crystalline
phase stems from the change in bond type in the parent compound Sb2Te. Ag and
In impurities serve mostly the purpose of stabilization of the amorphous phase,
and have marginal impact on the large variation in the dielectric function upon
the phase transitions.",http://arxiv.org/abs/2101.00789v2
Marketing Mix Optimization with Practical Constraints,2021-01-11T02:10:19Z,"Hsin-Chan Huang, Jiefeng Xu, Alvin Lim","In this paper, we address a variant of the marketing mix optimization (MMO)
problem which is commonly encountered in many industries, e.g., retail and
consumer packaged goods (CPG) industries. This problem requires the spend for
each marketing activity, if adjusted, be changed by a non-negligible degree
(minimum change) and also the total number of activities with spend change be
limited (maximum number of changes). With these two additional practical
requirements, the original resource allocation problem is formulated as a mixed
integer nonlinear program (MINLP). Given the size of a realistic problem in the
industrial setting, the state-of-the-art integer programming solvers may not be
able to solve the problem to optimality in a straightforward way within a
reasonable amount of time. Hence, we propose a systematic reformulation to ease
the computational burden. Computational tests show significant improvements in
the solution process.",http://arxiv.org/abs/2101.03663v1
Change-point detection using spectral PCA for multivariate time series,2021-01-12T07:32:39Z,"Shuhao Jiao, Tong Shen, Zhaoxia Yu, Hernando Ombao","We propose a two-stage approach Spec PC-CP to identify change points in
multivariate time series. In the first stage, we obtain a low-dimensional
summary of the high-dimensional time series by Spectral Principal Component
Analysis (Spec-PCA). In the second stage, we apply cumulative sum-type test on
the Spectral PCA component using a binary segmentation algorithm. Compared with
existing approaches, the proposed method is able to capture the lead-lag
relationship in time series. Our simulations demonstrate that the Spec PC-CP
method performs significantly better than competing methods for detecting
change points in high-dimensional time series. The results on epileptic seizure
EEG data and stock data also indicate that our new method can efficiently
{detect} change points corresponding to the onset of the underlying events.",http://arxiv.org/abs/2101.04334v1
Rotating vector model for magnetars,2021-01-11T02:28:26Z,"H. Tong, P. F. Wang, H. G. Wang, Z. Yan","The modification of the rotating vector model in the case of magnetars are
calculated. Magnetars may have twisted magnetic field compared with normal
pulsars. The polarization position angle of magnetars will change in the case
of a twisted magnetic field. For a twisted dipole field, we found that the
position angle will change both vertically and horizontally. During the
untwisting process of the magnetar magnetosphere, the modifications of the
position angle will evolve with time monotonously. This may explain the
evolution of the position angle in magnetar PSR J1622-4950 and XTE J1810-197.
The relation between the emission point and the line of sight will also change.
We suggest every magnetospheric models of magnetars also calculate the
corresponding changes of position angle in their models. Order of magnitude
estimation formula for doing this is given. This opens the possibility to
extract the magnetic field geometry of magnetars from their radio polarization
observations.",http://arxiv.org/abs/2101.04504v1
"Video action recognition for lane-change classification and prediction
  of surrounding vehicles",2021-01-13T13:25:00Z,"Mahdi Biparva, David Fernández-Llorca, Rubén Izquierdo-Gonzalo, John K. Tsotsos","In highway scenarios, an alert human driver will typically anticipate early
cut-in/cut-out maneuvers of surrounding vehicles using visual cues mainly.
Autonomous vehicles must anticipate these situations at an early stage too, to
increase their safety and efficiency. In this work, lane-change recognition and
prediction tasks are posed as video action recognition problems. Up to four
different two-stream-based approaches, that have been successfully applied to
address human action recognition, are adapted here by stacking visual cues from
forward-looking video cameras to recognize and anticipate lane-changes of
target vehicles. We study the influence of context and observation horizons on
performance, and different prediction horizons are analyzed. The different
models are trained and evaluated using the PREVENTION dataset. The obtained
results clearly demonstrate the potential of these methodologies to serve as
robust predictors of future lane-changes of surrounding vehicles proving an
accuracy higher than 90% in time horizons of between 1-2 seconds.",http://arxiv.org/abs/2101.05043v2
"Meta-Reinforcement Learning for Adaptive Motor Control in Changing Robot
  Dynamics and Environments",2021-01-19T12:57:12Z,"Timothée Anne, Jack Wilkinson, Zhibin Li","This work developed a meta-learning approach that adapts the control policy
on the fly to different changing conditions for robust locomotion. The proposed
method constantly updates the interaction model, samples feasible sequences of
actions of estimated the state-action trajectories, and then applies the
optimal actions to maximize the reward. To achieve online model adaptation, our
proposed method learns different latent vectors of each training condition,
which are selected online given the newly collected data. Our work designs
appropriate state space and reward functions, and optimizes feasible actions in
an MPC fashion which are then sampled directly in the joint space considering
constraints, hence requiring no prior design of specific walking gaits. We
further demonstrate the robot's capability of detecting unexpected changes
during interaction and adapting control policies quickly. The extensive
validation on the SpotMicro robot in a physics simulation shows adaptive and
robust locomotion skills under varying ground friction, external pushes, and
different robot models including hardware faults and changes.",http://arxiv.org/abs/2101.07599v1
Challenges for Computational Lexical Semantic Change,2021-01-19T15:01:30Z,"Simon Hengchen, Nina Tahmasebi, Dominik Schlechtweg, Haim Dubossarsky","The computational study of lexical semantic change (LSC) has taken off in the
past few years and we are seeing increasing interest in the field, from both
computational sciences and linguistics. Most of the research so far has focused
on methods for modelling and detecting semantic change using large diachronic
textual data, with the majority of the approaches employing neural embeddings.
While methods that offer easy modelling of diachronic text are one of the main
reasons for the spiking interest in LSC, neural models leave many aspects of
the problem unsolved. The field has several open and complex challenges. In
this chapter, we aim to describe the most important of these challenges and
outline future directions.",http://arxiv.org/abs/2101.07668v1
Leadership and Institutional Reforms,2021-01-21T16:28:31Z,"Matata Ponyo Mapon, Jean-Paul K. Tsasa","Large-scale institutional changes require strong commitment and involvement
of all stakeholders. We use the standard framework of cooperative game theory
developed by Ichiishi (1983, pp. 78-149) to: (i) establish analytically the
difference between policy maker and political leader; (ii) formally study
interactions between a policy maker and his followers; (iii) examine the role
of leadership in the implementation of structural reforms. We show that a
policy maker can be both partisan and non-partisan, while a political leader
can only be non-partisan. Following this distinction, we derive the probability
of success of an institutional change, as well as the nature of the gain that
such a change would generate on the beneficiary population. Based on the
restrictions of this simple mathematical model and using some evidence from the
Congolese experience between 2012 and 2016, we show that institutional changes
can indeed benefit the majority of the population, when policy makers are truly
partisan.",http://arxiv.org/abs/2101.08702v1
Creating a Virtuous Cycle in Performance Testing at MongoDB,2021-01-25T16:47:05Z,David Daly,"It is important to detect changes in software performance during development
in order to avoid performance decreasing release to release or dealing with
costly delays at release time. Performance testing is part of the development
process at MongoDB, and integrated into our continuous integration system. We
describe a set of changes to that performance testing environment designed to
improve testing effectiveness. These changes help improve coverage, provide
faster and more accurate signaling for performance changes, and help us better
understand the state of performance. In addition to each component performing
better, we believe that we have created and exploited a virtuous cycle:
performance test improvements drive impact, which drives more use, which drives
further impact and investment in improvements. Overall, MongoDB is getting
faster and we avoid shipping major performance regressions to our customers
because of this infrastructure.",http://arxiv.org/abs/2101.10231v2
"Raman Spectroscopy and Aging of the Low-Loss Ferrimagnet Vanadium
  Tetracyanoethylene",2021-01-25T17:00:17Z,"H. F. H. Cheung, M. Chilcote, H. Yusuf, D. S. Cormode, Y. Shi, M. E. Flatté, E. Johnston-Halperin, G. D. Fuchs","Vanadium tetracyanoethylene (V[TCNE]$_{x}$, $x\approx 2$) is an organic-based
ferrimagnet with a high magnetic ordering temperature $\mathrm{T_C>600 ~K}$,
low magnetic damping, and growth compatibility with a wide variety of
substrates. However, similar to other organic-based materials, it is sensitive
to air. Although encapsulation of V[TCNE]$_{x}$ with glass and epoxy extends
the film lifetime from an hour to a few weeks, what is limiting its lifetime
remains poorly understood. Here we characterize encapsulated V[TCNE]$_{x}$
films using confocal microscopy, Raman spectroscopy, ferromagnetic resonance
and SQUID magnetometry. We identify the relevant features in the Raman spectra
in agreement with \textit{ab initio} theory, reproducing $\mathrm{C=C,C\equiv
N}$ vibrational modes. We correlate changes in the effective dynamic
magnetization with changes in Raman intensity and in photoluminescence. Based
on changes in Raman spectra, we hypothesize possible structural changes and
aging mechanisms in V[TCNE]$_x$. These findings enable a local optical probe of
V[TCNE]$_{x}$ film quality, which is invaluable in experiments where assessing
film quality with local magnetic characterization is not possible.",http://arxiv.org/abs/2101.10240v1
"Not Now, Ask Later: Users Weaken Their Behavior Change Regimen Over
  Time, But Expect To Re-Strengthen It Imminently",2021-01-27T23:47:21Z,"Geza Kovacs, Zhengxuan Wu, Michael S. Bernstein","How effectively do we adhere to nudges and interventions that help us control
our online browsing habits? If we have a temporary lapse and disable the
behavior change system, do we later resume our adherence, or has the dam
broken? In this paper, we investigate these questions through log analyses of
8,000+ users on HabitLab, a behavior change platform that helps users reduce
their time online. We find that, while users typically begin with
high-challenge interventions, over time they allow themselves to slip into
easier and easier interventions. Despite this, many still expect to return to
the harder interventions imminently: they repeatedly choose to be asked to
change difficulty again on the next visit, declining to have the system save
their preference for easy interventions.",http://arxiv.org/abs/2101.11743v1
Architectural Decay as Predictor of Issue- and Change-Proneness,2021-02-19T09:54:03Z,"Duc Minh Le, Suhrid Karthik, Marcelo Schmitt Laser, Nenad Medvidovic","Architectural decay imposes real costs in terms of developer effort, system
correctness, and performance. Over time, those problems are likely to be
revealed as explicit implementation issues (defects, feature changes, etc.).
Recent empirical studies have demonstrated that there is a significant
correlation between architectural ""smells"" -- manifestations of architectural
decay -- and implementation issues. In this paper, we take a step further in
exploring this phenomenon. We analyze the available development data from 10
open-source software systems and show that information regarding current
architectural decay in these systems can be used to build models that
accurately predict future issue-proneness and change-proneness of the systems'
implementations. As a less intuitive result, we also show that, in cases where
historical data for a system is unavailable, such data from other, unrelated
systems can provide reasonably accurate issue- and change-proneness prediction
capabilities.",http://arxiv.org/abs/2102.09835v1
Distinction and Base Change,2021-02-21T13:32:49Z,U. K. Anandavardhanan,"An irreducible smooth representation of a $p$-adic group $G$ is said to be
distinguished with respect to a subgroup $H$ if it admits a non-trivial
$H$-invariant linear form. When $H$ is the fixed group of an involution on $G$
it is suggested by the works of Herv\'e Jacquet from the nineties that
distinction can be characterized in terms of the principle of functoriality. If
the involution is the Galois involution then a recent conjecture of Dipendra
Prasad predicts a formula for the dimension of the space of invariant linear
forms which once again involves base change. We will describe the proof of this
conjecture (in the generic case) for $SL(n)$ which is joint work with Dipendra
Prasad. Then we describe one more newly discovered connection between
distinction and base change which is that base change information appears in
the constant of proportionality between two natural invariant linear forms on a
distinguished representation. This latter result is for discrete series for
$GL(n)$ and is joint with Nadir Matringe. This paper is a report on the
author's talk in the International Colloquium on Arithmetic Geometry held in
January 2020 at TIFR Mumbai.",http://arxiv.org/abs/2102.10602v1
On Posterior consistency of Bayesian Changepoint models,2021-02-25T15:34:03Z,"Nilabja Guha, Jyotishka Datta","While there have been a lot of recent developments in the context of Bayesian
model selection and variable selection for high dimensional linear models,
there is not much work in the presence of change point in literature, unlike
the frequentist counterpart. We consider a hierarchical Bayesian linear model
where the active set of covariates that affects the observations through a mean
model can vary between different time segments. Such structure may arise in
social sciences/ economic sciences, such as sudden change of house price based
on external economic factor, crime rate changes based on social and
built-environment factors, and others. Using an appropriate adaptive prior, we
outline the development of a hierarchical Bayesian methodology that can select
the true change point as well as the true covariates, with high probability. We
provide the first detailed theoretical analysis for posterior consistency with
or without covariates, under suitable conditions. Gibbs sampling techniques
provide an efficient computational strategy. We also consider small sample
simulation study as well as application to crime forecasting applications.",http://arxiv.org/abs/2102.12938v1
"Change Detection from SAR Images Based on Deformable Residual
  Convolutional Neural Networks",2021-04-06T05:52:25Z,"Junjie Wang, Feng Gao, Junyu Dong","Convolutional neural networks (CNN) have made great progress for synthetic
aperture radar (SAR) images change detection. However, sampling locations of
traditional convolutional kernels are fixed and cannot be changed according to
the actual structure of the SAR images. Besides, objects may appear with
different sizes in natural scenes, which requires the network to have stronger
multi-scale representation ability. In this paper, a novel
\underline{D}eformable \underline{R}esidual Convolutional Neural
\underline{N}etwork (DRNet) is designed for SAR images change detection. First,
the proposed DRNet introduces the deformable convolutional sampling locations,
and the shape of convolutional kernel can be adaptively adjusted according to
the actual structure of ground objects. To create the deformable sampling
locations, 2-D offsets are calculated for each pixel according to the spatial
information of the input images. Then the sampling location of pixels can
adaptively reflect the spatial structure of the input images. Moreover, we
proposed a novel pooling module replacing the vanilla pooling to utilize
multi-scale information effectively, by constructing hierarchical residual-like
connections within one pooling layer, which improve the multi-scale
representation ability at a granular level. Experimental results on three real
SAR datasets demonstrate the effectiveness of the proposed DRNet.",http://arxiv.org/abs/2104.02299v1
On Mixed Iterated Revisions,2021-04-08T07:34:56Z,Paolo Liberatore,"Several forms of iterable belief change exist, differing in the kind of
change and its strength: some operators introduce formulae, others remove them;
some add formulae unconditionally, others only as additions to the previous
beliefs; some only relative to the current situation, others in all possible
cases. A sequence of changes may involve several of them: for example, the
first step is a revision, the second a contraction and the third a refinement
of the previous beliefs. The ten operators considered in this article are shown
to be all reducible to three: lexicographic revision, refinement and severe
withdrawal. In turn, these three can be expressed in terms of lexicographic
revision at the cost of restructuring the sequence. This restructuring needs
not to be done explicitly: an algorithm that works on the original sequence is
shown. The complexity of mixed sequences of belief change operators is also
analyzed. Most of them require only a polynomial number of calls to a
satisfiability checker, some are even easier.",http://arxiv.org/abs/2104.03571v1
"The structure of online social networks modulates the rate of lexical
  change",2021-04-11T13:06:28Z,"Jian Zhu, David Jurgens","New words are regularly introduced to communities, yet not all of these words
persist in a community's lexicon. Among the many factors contributing to
lexical change, we focus on the understudied effect of social networks. We
conduct a large-scale analysis of over 80k neologisms in 4420 online
communities across a decade. Using Poisson regression and survival analysis,
our study demonstrates that the community's network structure plays a
significant role in lexical change. Apart from overall size, properties
including dense connections, the lack of local clusters and more external
contacts promote lexical innovation and retention. Unlike offline communities,
these topic-based communities do not experience strong lexical levelling
despite increased contact but accommodate more niche words. Our work provides
support for the sociolinguistic hypothesis that lexical change is partially
shaped by the structure of the underlying network but also uncovers findings
specific to online communities.",http://arxiv.org/abs/2104.05010v1
"Hierarchical entropy and domain interaction to understand the structure
  in an image",2021-04-20T04:29:13Z,"Nao Uehara, Teruaki Hayashi, Yukio Ohsawa","In this study, we devise a model that introduces two hierarchies into
information entropy. The two hierarchies are the size of the region for which
entropy is calculated and the size of the component that determines whether the
structures in the image are integrated or not. And this model uses two
indicators, hierarchical entropy and domain interaction. Both indicators
increase or decrease due to the integration or fragmentation of the structure
in the image. It aims to help people interpret and explain what the structure
in an image looks like from two indicators that change with the size of the
region and the component. First, we conduct experiments using images and
qualitatively evaluate how the two indicators change. Next, we explain the
relationship with the hidden structure of Vermeer's girl with a pearl earring
using the change of hierarchical entropy. Finally, we clarify the relationship
between the change of domain interaction and the appropriate segment result of
the image by an experiment using a questionnaire.",http://arxiv.org/abs/2104.09754v1
"Balanced-imbalanced transitions in indirect reciprocity dynamics on
  networks",2021-04-21T14:51:23Z,"Koji Oishi, Shuhei Miyano, Kimmo Kaski, Takashi Shimada","Here we investigate the dynamics of indirect reciprocity on networks, a type
of social dynamics in which the attitude of individuals, either cooperative or
antagonistic, toward other individuals changes over time by their actions and
mutual monitoring. We observe an absorbing state phase transition as we change
the network's link or edge density. When the edge density is either small or
large enough, opinions quickly reach an absorbing state, from which opinions
never change anymore once reached. In contrast, if the edge density is in the
middle range the absorbing state is not reached and the state keeps changing
thus being active. The result shows a novel effect of social networks on
spontaneous group formation.",http://arxiv.org/abs/2104.10568v1
"Using Satellite Imagery and Deep Learning to Evaluate the Impact of
  Anti-Poverty Programs",2021-04-23T18:30:09Z,"Luna Yue Huang, Solomon Hsiang, Marco Gonzalez-Navarro","The rigorous evaluation of anti-poverty programs is key to the fight against
global poverty. Traditional evaluation approaches rely heavily on repeated
in-person field surveys to measure changes in economic well-being and thus
program effects. However, this is known to be costly, time-consuming, and often
logistically challenging. Here we provide the first evidence that we can
conduct such program evaluations based solely on high-resolution satellite
imagery and deep learning methods. Our application estimates changes in
household welfare in the context of a recent anti-poverty program in rural
Kenya. The approach we use is based on a large literature documenting a
reliable relationship between housing quality and household wealth. We infer
changes in household wealth based on satellite-derived changes in housing
quality and obtain consistent results with the traditional field-survey based
approach. Our approach can be used to obtain inexpensive and timely insights on
program effectiveness in international development programs.",http://arxiv.org/abs/2104.11772v1
On system rollback and totalised fields,2021-04-24T14:01:01Z,"Mark Burgess, Alva Couch","In system operations it is commonly assumed that arbitrary changes to a
system can be reversed or `rolled back', when errors of judgement and procedure
occur. We point out that this view is flawed and provide an alternative
approach to determining the outcome of changes.
  Convergent operators are fixed-point generators that stem from the basic
properties of multiplication by zero. They are capable of yielding a repeated
and predictable outcome even in an incompletely specified or `open' system. We
formulate such `convergent operators' for configuration change in the language
of groups and rings and show that, in this form, the problem of convergent
reversibility becomes equivalent to the `division by zero' problem. Hence, we
discuss how recent work by Bergstra and Tucker on zero-totalised fields helps
to clear up long-standing confusion about the options for `rollback' in change
management.",http://arxiv.org/abs/2104.11958v1
Joint Linear Trend Recovery Using L1 Regularization,2021-04-30T08:20:06Z,"Xiaoli Gao, Ejaz Ahmed","This paper studies the recovery of a joint piece-wise linear trend from a
time series using L1 regularization approach, called L1 trend filtering (Kim,
Koh and Boyd, 2009). We provide some sufficient conditions under which a L1
trend filter can be well-behaved in terms of mean estimation and change point
detection. The result is two-fold: for the mean estimation, an almost optimal
consistent rate is obtained; for the change point detection, the slope change
in direction can be recovered in a high probability. In addition, we show that
the weak irrepresentable condition, a necessary condition for LASSO model to be
sign consistent (Zhao and Yu, 2006), is not necessary for the consistent change
point detection. The performance of the L1 trend filter is evaluated by some
finite sample simulations studies.",http://arxiv.org/abs/2104.14827v1
Semantic Journeys: Quantifying Change in Emoji Meaning from 2012-2018,2021-05-03T13:35:10Z,"Alexander Robertson, Farhana Ferdousi Liza, Dong Nguyen, Barbara McGillivray, Scott A. Hale","The semantics of emoji has, to date, been considered from a static
perspective. We offer the first longitudinal study of how emoji semantics
changes over time, applying techniques from computational linguistics to six
years of Twitter data. We identify five patterns in emoji semantic development
and find evidence that the less abstract an emoji is, the more likely it is to
undergo semantic change. In addition, we analyse select emoji in more detail,
examining the effect of seasonality and world events on emoji semantics. To aid
future work on emoji and semantics, we make our data publicly available along
with a web-based interface that anyone can use to explore semantic change in
emoji.",http://arxiv.org/abs/2105.00846v2
"Experimental Evidence of a change of Exchange Anisotropy Sign with
  Temperature in Zn-Substituted Cu2OSeO3",2021-05-19T17:39:04Z,"S. H. Moody, P. Nielsen, M. N. Wilson, D. Alba Venero, A. Štefančič, G. Balakrishnan, P. D. Hatton","We report small-angle neutron scattering from the conical state in a single
crystal of Zn-substituted Cu2OSeO3. Using a 3D vector-field magnet to reorient
the conical wavevector, our measurements show that the magnitude of the conical
wavevector changes as a function of crystallographic direction. These changes
are caused by the anisotropic exchange interaction (AEI), whose magnitude
transitions from a maxima to a minima along the <111> and <100>
crystallographic directions respectively. We further find that the AEI constant
undergoes a change of sign from positive to negative with decreasing
temperature. Unlike in the related compound FeGe, where similar behaviour of
the AEI induces a reorientation of the helical wavevector, we show that the
zero field helical wavevector in (Cu0.98Zn0.02)2OSeO3 remains along the <100>
directions at all temperatures due to the competing fourth-order
magnetocrystalline anisotropy becoming dominant at lower temperatures.",http://arxiv.org/abs/2105.09273v1
"Multiple Change Point Detection in Structured VAR Models: the VARDetect
  R Package",2021-05-23T19:45:11Z,"Peiliang Bai, Yue Bai, Abolfazl Safikhani, George Michailidis","Vector Auto-Regressive (VAR) models capture lead-lag temporal dynamics of
multivariate time series data. They have been widely used in macroeconomics,
financial econometrics, neuroscience and functional genomics. In many
applications, the data exhibit structural changes in their autoregressive
dynamics, which correspond to changes in the transition matrices of the VAR
model that specify such dynamics. We present the R package VARDetect that
implements two classes of algorithms to detect multiple change points in
piecewise stationary VAR models. The first exhibits sublinear computational
complexity in the number of time points and is best suited for structured
sparse models, while the second exhibits linear time complexity and is designed
for models whose transition matrices are assumed to have a low rank plus sparse
decomposition. The package also has functions to generate data from the various
variants of VAR models discussed, which is useful in simulation studies, as
well as to visualize the results through network layouts.",http://arxiv.org/abs/2105.11007v3
"Direct Observation of Reversible Heat Absorption in Li-ion Battery
  Enabled by Ultra-Sensitive Thermometry",2021-07-01T17:25:38Z,"Zhe Cheng, Xiaoyang Ji, David G. Cahill","The reversible heat in lithium-ion batteries (LIBs) due to entropy change is
fundamentally important for understanding the chemical reactions in LIBs and
developing proper thermal management strategies. However, the direct
measurements of reversible heat are challenging due to the limited temperature
resolution of applied thermometry. In this work, by developing an
ultra-sensitive thermometry with a differential AC bridge using two
thermistors, the noise-equivalent temperature resolution we achieve (10 uK) is
several orders of magnitude higher than previous thermometry applied on LIBs.
We directly observe reversible heat absorption of a LIR2032 coin cell during
charging with negligible irreversible heat generation and a linear relation
between heat generations and discharging currents. The cell entropy changes
determined from the reversible heat agree excellently with those measured from
temperature dependent open circuit voltage. Moreover, it is found that the
large reversible entropy change can cancel out the irreversible entropy
generation at a charging rate as large as C/3.7 and produce a
zero-heat-dissipation LIB during charging. Our work significantly contributes
to fundamental understanding of the entropy changes and heat generations of the
chemical reactions in LIBs, and reveals that reversible heat absorption can be
an effective way to cool LIBs during charging.",http://arxiv.org/abs/2107.00625v1
Inferring the drivers of language change using spatial models,2021-07-05T14:33:18Z,"James Burridge, Tamsin Blaxter","Discovering and quantifying the drivers of language change is a major
challenge. Hypotheses about causal factors proliferate, but are difficult to
rigorously test. Here we ask a simple question: can 20th Century changes in
English English be explained as a consequence of spatial diffusion, or have
other processes created bias in favour of certain linguistic forms? Using two
of the most comprehensive spatial datasets available, which measure the state
of English at the beginning and end of the 20th century, we calibrate a simple
spatial model so that, initialised with the early state, it evolves into the
later. Our calibrations reveal that while some changes can be explained by
diffusion alone, others are clearly the result of substantial asymmetries
between variants. We discuss the origins of these asymmetries and, as a
by-product, we generate a full spatio-temporal prediction for the spatial
evolution of English features over the 20th Century, and a prediction of the
future.",http://arxiv.org/abs/2107.02056v1
"AdaRL: What, Where, and How to Adapt in Transfer Reinforcement Learning",2021-07-06T16:56:25Z,"Biwei Huang, Fan Feng, Chaochao Lu, Sara Magliacane, Kun Zhang","One practical challenge in reinforcement learning (RL) is how to make quick
adaptations when faced with new environments. In this paper, we propose a
principled framework for adaptive RL, called \textit{AdaRL}, that adapts
reliably and efficiently to changes across domains with a few samples from the
target domain, even in partially observable environments. Specifically, we
leverage a parsimonious graphical representation that characterizes structural
relationships over variables in the RL system. Such graphical representations
provide a compact way to encode what and where the changes across domains are,
and furthermore inform us with a minimal set of changes that one has to
consider for the purpose of policy adaptation. We show that by explicitly
leveraging this compact representation to encode changes, we can efficiently
adapt the policy to the target domain, in which only a few samples are needed
and further policy optimization is avoided. We illustrate the efficacy of AdaRL
through a series of experiments that vary factors in the observation,
transition, and reward functions for Cartpole and Atari games.",http://arxiv.org/abs/2107.02729v4
QoS Prediction for 5G Connected and Automated Driving,2021-07-11T09:19:37Z,"Apostolos Kousaridas, Ramya Panthangi Manjunath, Jose Mauricio Perdomo, Chan Zhou, Ernst Zielinski, Steffen Schmitz, Andreas Pfadler","5G communication system can support the demanding quality-of-service (QoS)
requirements of many advanced vehicle-to-everything (V2X) use cases. However,
the safe and efficient driving, especially of automated vehicles, may be
affected by sudden changes of the provided QoS. For that reason, the prediction
of the QoS changes and the early notification of these predicted changes to the
vehicles have been recently enabled by 5G communication systems. This solution
enables the vehicles to avoid or mitigate the effect of sudden QoS changes at
the application level. This article describes how QoS prediction could be
generated by a 5G communication system and delivered to a V2X application. The
tele-operated driving use case is used as an example to analyze the feasibility
of a QoS prediction scheme. Useful recommendations for the development of a QoS
prediction solution are provided, while open research topics are identified.",http://arxiv.org/abs/2107.05000v1
Resurrecting Address Clustering in Bitcoin,2021-07-12T21:37:01Z,"Malte Möser, Arvind Narayanan","Blockchain analysis is essential for understanding how cryptocurrencies like
Bitcoin are used in practice, and address clustering is a cornerstone of
blockchain analysis. However, current techniques rely on heuristics that have
not been rigorously evaluated or optimized. In this paper, we tackle several
challenges of change address identification and clustering. First, we build a
ground truth set of transactions with known change from the Bitcoin blockchain
that can be used to validate the efficacy of individual change address
detection heuristics. Equipped with this data set, we develop new techniques to
predict change outputs with low false positive rates. After applying our
prediction model to the Bitcoin blockchain, we analyze the resulting clustering
and develop ways to detect and prevent cluster collapse. Finally, we assess the
impact our enhanced clustering has on two exemplary applications.",http://arxiv.org/abs/2107.05749v2
LT-mapper: A Modular Framework for LiDAR-based Lifelong Mapping,2021-07-16T05:33:26Z,"Giseop Kim, Ayoung Kim","Long-term 3D map management is a fundamental capability required by a robot
to reliably navigate in the non-stationary real-world. This paper develops
open-source, modular, and readily available LiDAR-based lifelong mapping for
urban sites. This is achieved by dividing the problem into successive
subproblems: multi-session SLAM (MSS), high/low dynamic change detection, and
positive/negative change management. The proposed method leverages MSS and
handles potential trajectory error; thus, good initial alignment is not
required for change detection. Our change management scheme preserves efficacy
in both memory and computation costs, providing automatic object segregation
from a large-scale point cloud map. We verify the framework's reliability and
applicability even under permanent year-level variation, through extensive
real-world experiments with multiple temporal gaps (from day to year).",http://arxiv.org/abs/2107.07712v1
Emerging mechanisms of magnetocaloric effect in phase-separated metals,2021-07-20T18:23:59Z,"V. V. Ivchenko, P. A. Igoshev","We present a study of the magnetocaloric effect in metallic systems
exhibiting first-order magnetic transitions and focus on consequences of
magnetic phase separation. We account for ferrimagnetic, ferromagnetic, and
Neel antiferromagnetic order. Based on the archetypal Hubbard model being
treated within the mean-field approximation, we provide and explore its
implications on the field-induced entropy change in metallic system with phase
separation. Chosen framework allows us to properly analyze phase volumes'
dependence on parameters of phase-separated (PS) system. Moreover, an account
for phase separation boundaries as functions of magnetic field provides a
natural splitting of the PS region, where each subregion corresponds to a
different temperature dependence of entropy change: moving from one subregion
to the other produces a kink, followed by a strong linear growth of entropy
change. We encounter a second-order magnetic transition from paramagnetic to
antiferromagnetic phase in PS region that occurs for particular parameter
values. Despite the fact that both phases have zero total magnetization, the
transition has a strong impact on entropy change.",http://arxiv.org/abs/2107.09709v1
"Controlled Doping of Double Walled Carbon Nanotubes and Conducting
  Polymers in a Composite: An in situ Raman Spectroelectrochemical Study",2021-07-23T15:17:29Z,"Martin Kalbáč, Ladislav Kavan, Lothar Dunsch","The interaction of double wall carbon nanotubes (DWCNTs) and the conducting
polymer poly(3,4-ethylenedioxythiphene/polystyrenesulfonate (PEDOT/PSS) was
studied by in-situ Raman spectroelectrochemistry. The mixing of DWCNTs with
PEDOT/PSS caused a partial doping of the outer tube of DWCNTs, which was
indicated by the relative change of the Raman intensity of the DWCNTs features.
On the other hand, the bands corresponding to inner tubes of DWCNTs and to the
polymer were almost untouched by assembling both species into a composite. The
in situ Raman spectroelectrochemical experiments have shown that the changes in
electronic structure of inner tubes of DWCNTs embedded in PEDOT/PSS matrix are
dependent on the doping level. While at the low doping level of the composite,
the Raman features of inner tubes of DWCNTs do not change significantly, at
high doping level they reflect the changes caused by the applied
electrochemical potential similar to that observed in the polymer-free DWCNTs.",http://arxiv.org/abs/2107.11297v1
An Aggregation Scheme for Increased Power,2021-07-27T20:09:40Z,"Timothy Lycurgus, Ben B. Hansen","We present an aggregation scheme that increases power in randomized
controlled trials and quasi-experiments when the intervention possesses a
robust and well-articulated theory of change. Longitudinal data analyzing
interventions often include multiple observations on individuals, some of which
may be more likely to manifest a treatment effect than others. An
intervention's theory of change provides guidance as to which of those
observations are best situated to exhibit that treatment effect. Our
power-maximizing weighting for repeated-measurements with delayed-effects
scheme, PWRD aggregation, converts the theory of change into a test statistic
with improved asymptotic relative efficiency, delivering tests with greater
statistical power. We illustrate this method on an IES-funded cluster
randomized trial testing the efficacy of a reading intervention designed to
assist early elementary students at risk of falling behind their peers. The
salient theory of change holds program benefits to be delayed and non-uniform,
experienced after a student's performance stalls. In this instance, the PWRD
technique's effect on power is found to be comparable to that of doubling the
number of clusters in the experiment.",http://arxiv.org/abs/2107.13070v3
"Fully bio-based Poly (Glycerol-Itaconic acid) as supporter for PEG based
  form stable phase change materials",2021-09-01T17:16:56Z,"Guang-Zhong Yin, José Luis Díaz Palencia, De-Yi Wang","A novel fully bio-based Poly (Glycerol-Itaconic acid) (PGI) was designed and
highly efficiently synthesized by solvent-free polycondensation. The Poly
(ethylene glycol) (PEG) was used as the phase change materials (PCM) working
substance and encapsulated by the sustainable PGI supporter. PEG chains were
tightly encapsulated with the PGI supporting material mainly under hydrogen
bonds due to the structural compatibility between PGI and PEG. The PCMs can
achieve high form stability and high phase change enthalpies in the same kinds
of PCMs. Furthermore, the phase change temperatures and enthalpies of the PCMs
can be adjusted conveniently by regulating the PEG content and molecular
weight. Notably, this process extremely facilitates the realization of
efficient mass production due to the eco-friendly nature, high efficiency and
low cost.",http://arxiv.org/abs/2109.00494v1
Pareto-optimal lane-changing motion planning in mixed traffic,2021-09-13T15:56:37Z,"Yang Li, Linbo Li, Daiheng Ni","This paper applies the pareto-optimal concept to LC (lane-changing) motion
planning in the presence of mixed traffic including manual and autonomous
vehicles. Firstly, a multiobjective optimization problem is presented, in which
the comfort, efficiency and safety of the LC vehicle and the surrounding
vehicles are jointly modelled. Thereafter, the pareto-optimal solutions are
obtained through employing the NSGA-II (Non-dominated Sorting Genetic -II)
algorithm. Finally, the experiment section analyzes the (macroscopic and
microscopic) lane-changing impact from a pareto-optimal perspective. Also, a
comprehensive sensitivity analysis is conducted. Our results demonstrate that
our algorithm could significantly reduce the lane-changing impact within its
region, and the total costs are reduced in the range of 10.94% to 48.66%. This
paper could be considered as a preliminary research framework for the
application of the pareto-optimal concept. We hope this research will provide
valuable insights into autonomous driving technology.",http://arxiv.org/abs/2109.06080v3
"Tuning nonlinear second-harmonic generation in AlGaAs nanoantennas via
  chalcogenide phase change material",2021-09-15T11:50:53Z,"Tingting Liu, Xinyuan Fang, Shuyuan Xiao","The ability to engineer nonlinear optical processes in all-dielectric
nanostructures is both of fundamental interest and highly desirable for
high-performance, robust, and miniaturized nonlinear optical devices. Herein,
we propose a novel paradigm for the efficient tuning of second-harmonic
generation (SHG) process in dielectric nanoantennas by integrating with
chalcogenide phase change material. In a design with Ge$_{2}$Sb$_{2}$Te$_{5}$
(GST) film sandwiched between the AlGaAs nanoantennas and AlO$_{x}$ substrate,
the nonlinear SHG signal from the AlGaAs nanoantennas can be boosted via the
resonantly localized field induced by the optically-induced Mie-type
resonances, and further modulated by exploiting the GST
amorphous-to-crystalline phase change in a non-volatile, multi-level manner.
The tuning strategy originates from the modulation of resonant conditions by
changes in the refractive index of GST. With a thorough examination of tuning
performances for different nanoantenna radii, a maximum modulation depth as
high as 540$\%$ is numerically demonstrated. This work not only reveals out the
potential of GST in optical nonlinearity control, but also provides promising
strategy in smart designing tunable and reconfigurable nonlinear optical
devices, e.g., light emitters, modulators, and sensors.",http://arxiv.org/abs/2109.07229v2
"Existence and multiplicity of sign-changing solutions for quasilinear
  Schrödinger equations with sub-cubic nonlinearity",2021-09-18T02:49:59Z,"Hui Zhang, Zhisu liu, Chun-Lei Tang, Jianjun Zhang","In this paper, we consider the quasilinear Schr\""{o}dinger equation
\begin{equation*} -\Delta u+V(x)u-u\Delta(u^2)=g(u),\ \ x\in \mathbb{R}^{3},
\end{equation*} where $V$ and $g$ are continuous functions. Without the
coercive condition on $V$ or the monotonicity condition on $g$, we show that
the problem above has a least energy sign-changing solution and infinitely many
sign-changing solutions. Our results especially solve the problem above in the
case where $g(u)=|u|^{p-2}u$ ($2<p<4$) and complete some recent related works
on sign-changing solutions, in the sense that, in the literature only the case
$g(u)=|u|^{p-2}u$ ($p\geq4$) was considered. The main results in the present
paper are obtained by a new perturbation approach and the method of invariant
sets of descending flow. In addition, in some cases where the functional merely
satisfies the Cerami condition, a deformation lemma under the Cerami condition
is developed.",http://arxiv.org/abs/2109.08810v1
"Waveguide-integrated plasmonic photodetectors and activation function
  units with phase change materials",2021-09-28T08:54:56Z,Jacek Gosciniak,"With a rapidly growing amount of data generated and processed, a search for
more efficient components and architectures such as neuromorphic computing that
are able to perform a more and more complex operations in more efficient way
continue. Here we show that thin films of chalcogenide phase change materials
(semiconductors) can serve as building blocks for novel type of plasmonic
components that operate seamlessly in both electrical and optical domains
without the need for repeated electrical-to-optical conversions. In
consequence, novel waveguide-integrated devices were proposed that are able to
operate simultaneously as photodetectors and activation function units and that
are based on low-loss plasmonic waveguide platform and phase change materials.
Theoretically predicted coupling efficiency exceeding 95 % and extremally low
insertion losses of 0.01 dB/um in connection with an enhanced light-matter
interaction provided by plasmonics enables a realization of very efficient and
compact photodetectors and activation function units. A detection and threshold
mechanism involve a Joule heating of phase change materials through internal or
external metal contacts. With this paper, different arrangements and operation
conditions were analyzed to ensure most efficient on-chip signal processing.",http://arxiv.org/abs/2109.13562v1
"Understanding Working from Home Practical Changes and Adaptations During
  the COVID-19 Pandemic",2021-09-22T15:54:02Z,"Jie Cai, Sarah J Ryu, Hyejin Hannah Kum-Biocca, Donghee Yvette Wohn","While much work focuses on the impacts of the pandemic on people's
psychological and physical health, it is still unclear about the practical
changes and adaptations. In this work, we interviewed 46 participants who were
forced to work from home. Results show that there is an increased reliance on
asynchronous communication, which slowed communication efficiency and decreased
initiative to communicate. The home environment causes distraction from
households and lacked facilities but is embraced by a group of people. Many
people had to passively adapt to the communication and environmental changes
and accept the limitations of technology, a situation that is not sustainable
in the long run. We pointed out how technology can potentially play a larger
role in supporting communication and coping with environmental changes in the
future.",http://arxiv.org/abs/2109.13643v1
"Bang-Bang Control Development of Permeability Changes in a Membrane
  Model",2021-08-15T01:45:37Z,Robert F. Melendy,"The application of systems and control theory to membrane physiology is
presented here. Modeling efforts have focused on describing those
physiologically realistic mechanisms which govern the regulation of membrane
permeability in nerve. The motivation behind identifying such mechanisms lies
in understanding the morphology of neural activity on a meaningful and
analytically tractable level. The suggested merit of integrating control theory
into the analysis lies in providing how a membrane effectively adapts to
changes in permeability and through what governing mechanisms. The value in
producing such an understanding lies in mirroring biological reality in a more
formal manner than could be achieved solely through experimental means. A
bang-bang control policy describing the permeability correction mechanisms is
developed using Liapunov's Stability Criteria. Both changes in membrane
potential and kinetic rates are required to implement the policy. The policy
describes the inherent mechanisms of the membrane which act to drive its
permeability from unstable firing to the resting potential state. It is shown
that these permeability changes in state are governed by a switching function
that depends on the membrane potential and a dominant controlling parameter.
The control policy is discussed in the context of solutions of the
Hodgkin-Huxley Equations of Ionic Hypothesis.",http://arxiv.org/abs/2109.13795v1
Evolution to symmetry,2021-11-02T12:54:56Z,Ferdinand Verhulst,"A natural example of evolution can be described by a time-dependent two
degrees-of-freedom Hamiltonian. We choose the case where initially the
Hamiltonian derives from a general cubic potential, the linearised system has
frequencies 1 and $\omega >0$. The time-dependence produces slow evolution to
discrete (mirror) symmetry in one of the degrees-of-freedom. This changes the
dynamics drastically depending on the frequency ratio $\omega$ and the
timescale of evolution. We analyse the cases $\omega = 1, 2, 3$ where the
ratio's 1,2 turn out to be the most interesting. In an initial phase we find 2
adiabatic invariants with changes near the end of evolution. A remarkable
feature is the vanishing and emergence of normal modes, stability changes and
strong changes of the velocity distribution in phase-space. The problem is
inspired by the dynamics of axisymmetric, rotating galaxies that evolve slowly
to mirror symmetry with respect to the galactic plane, the model formulation is
quite general.",http://arxiv.org/abs/2111.01569v1
DVFL: A Vertical Federated Learning Method for Dynamic Data,2021-11-05T09:26:09Z,"Yuzhi Liang, Yixiang Chen","Federated learning, which solves the problem of data island by connecting
multiple computational devices into a decentralized system, has become a
promising paradigm for privacy-preserving machine learning. This paper studies
vertical federated learning (VFL), which tackles the scenarios where
collaborating organizations share the same set of users but disjoint features.
Contemporary VFL methods are mainly used in static scenarios where the active
party and the passive party have all the data from the beginning and will not
change. However, the data in real life often changes dynamically. To alleviate
this problem, we propose a new vertical federation learning method, DVFL, which
adapts to dynamic data distribution changes through knowledge distillation. In
DVFL, most of the computations are held locally to improve data security and
model efficiency. Our extensive experimental results show that DVFL can not
only obtain results close to existing VFL methods in static scenes, but also
adapt to changes in data distribution in dynamic scenarios.",http://arxiv.org/abs/2111.03341v1
Microstructure and the Boson-peak in thermally-treated In_{x}O films,2021-11-08T05:30:21Z,"Itai Zbeda, Ilana Bar, Z. Ovadyahu","We report on the correlation between the boson-peak and structural changes
associated with thermally-treating amorphous indium-oxide films. In this
process, the resistance of a given sample may decrease by a considerable margin
while its amorphous structure is preserved. In the present study, we focus on
the changes that result from the heat-treatment by employing
electron-microscopy, X-ray, and Raman spectroscopy. These techniques were used
on films with different stoichiometry and thus different carrier-concentration.
The main effect of heat-treatment is material densification, which presumably
results from elimination of micro-voids. The densified system presents better
wavefunction-overlap and more efficient connectivity for the current flow.
X-ray, and electron-beam diffraction experiments indicate that the heat-treated
samples show significantly less spatial heterogeneity with only a moderate
change of the radial-distribution function metrics. These results are
consistent with the changes that occur in the boson-peak characteristics due to
annealing as observed in their Raman spectra.",http://arxiv.org/abs/2111.04277v1
"Distinctive features of oscillatory phenomena in reconstructions of the
  topological structure of electron trajectories on complex Fermi surfaces",2021-11-14T12:54:13Z,A. Ya. Maltsev,"We consider the behavior of classical and quantum oscillations in metals with
complex Fermi surfaces near the directions of $\, {\bf B} \, $ corresponding to
changes in the topological structure of the dynamical system describing the
semiclassical motion of quasiparticles along the Fermi surface. The transitions
through the boundaries of change in this structure are accompanied by sharp
changes in the picture of oscillations, the form of which depends in the most
essential way on the topological type of the corresponding reconstruction. We
list here the main features of such changes for all topological types of
elementary reconstructions and discuss the possibilities of experimental
identification of such types based on these features.",http://arxiv.org/abs/2111.07332v1
"ShapeY: Measuring Shape Recognition Capacity Using Nearest Neighbor
  Matching",2021-11-16T01:21:54Z,"Jong Woo Nam, Amanda S. Rios, Bartlett W. Mel","Object recognition in humans depends primarily on shape cues. We have
developed a new approach to measuring the shape recognition performance of a
vision system based on nearest neighbor view matching within the system's
embedding space. Our performance benchmark, ShapeY, allows for precise control
of task difficulty, by enforcing that view matching span a specified degree of
3D viewpoint change and/or appearance change. As a first test case we measured
the performance of ResNet50 pre-trained on ImageNet. Matching error rates were
high. For example, a 27 degree change in object pitch led ResNet50 to match the
incorrect object 45% of the time. Appearance changes were also highly
disruptive. Examination of false matches indicates that ResNet50's embedding
space is severely ""tangled"". These findings suggest ShapeY can be a useful tool
for charting the progress of artificial vision systems towards human-level
shape recognition capabilities.",http://arxiv.org/abs/2111.08174v1
"From a bistable adsorbate to a switchable interface: tetrachloropyrazine
  on Pt(111)",2021-11-16T13:15:51Z,"Lukas Hörmann, Andreas Jeindl, Oliver T. Hofmann","Virtually all organic (opto)electronic devices rely on organic/inorganic
interfaces with specific properties. These properties are, in turn,
inextricably linked to the interface structure. Therefore, a change in
structure can introduce a shift in function. If this change is reversible, it
would allow constructing a switchable interface. We accomplish this with
tetrachloropyrazine on Pt(111), which exhibits a double-well potential with a
chemisorbed and a physisorbed minimum. These minima have significantly
different adsorption geometries allowing the formation of switchable interface
structures. Importantly, these structures facilitate different work function
changes and coherent fractions (X-ray standing wave measurements), which are
ideal properties to readout the interface state.
  We perform surface structure search using a modified version of the SAMPLE
approach and account for thermodynamic conditions using ab-initio
thermodynamics. This allows investigating millions of commensurate as well as
higher-order commensurate interface structures. We identify three different
classes of structures exhibiting different work function changes and coherent
fractions. Using temperature and pressure as handles we demonstrate the
possibility of reversible switching between those different classes, creating a
dynamic interface for potential applications in organic electronics.",http://arxiv.org/abs/2111.08437v1
"Bipartite Temporal Graphs and the Parameterized Complexity of Multistage
  2-Coloring",2021-11-17T11:43:35Z,"Till Fluschnik, Pascal Kunz","We consider the algorithmic complexity of recognizing bipartite temporal
graphs. Rather than defining these graphs solely by their underlying graph or
individual layers, we define a bipartite temporal graph as one in which every
layer can be 2-colored in a way that results in few changes between any two
consecutive layers. This approach follows the framework of multistage problems
that has received a growing amount of attention in recent years. We investigate
the complexity of recognizing these graphs. We show that this problem is
NP-hard even if there are only two layers or if only one change is allowed
between consecutive layers. We consider the parameterized complexity of the
problem with respect to several structural graph parameters, which we transfer
from the static to the temporal setting in three different ways. Finally, we
consider a version of the problem in which we only restrict the total number of
changes throughout the lifetime of the graph. We show that this variant is
fixed-parameter tractable with respect to the number of changes.",http://arxiv.org/abs/2111.09049v1
Evidence for dynamical changes in Betelgeuse using multi-wavelength data,2021-11-17T16:18:41Z,"Sneha Kachhara, Sandip V. George, Ranjeev Misra, G. Ambika","The reasons behind the Great Dimming and subsequent rising in the brightness
of Betelgeuse between October 2019 and March 2020 still continue to baffle
astronomers. It has been shown by George et. al. (2020) that critical slowing
down preceded the dimming event. This suggested that the dimming was a result
of the change in the nature of the nonlinear dynamics of the star. In this work
we present additional evidence for dynamical changes in Betelgeuse prior to the
Great Dimming event, using nonlinear time series analysis. We study the
relations between the different bands in the photometry data collected from the
Wing photometry (IR/near-IR) and Wasatonic observatory (V-band). We also
analyse how the early warning signals studied previously changed during and
after the Great Dimming.",http://arxiv.org/abs/2111.09218v1
"A General Framework for Lifelong Localization and Mapping in Changing
  Environment",2021-11-22T02:12:54Z,"Min Zhao, Xin Guo, Le Song, Baoxing Qin, Xuesong Shi, Gim Hee Lee, Guanghui Sun","The environment of most real-world scenarios such as malls and supermarkets
changes at all times. A pre-built map that does not account for these changes
becomes out-of-date easily. Therefore, it is necessary to have an up-to-date
model of the environment to facilitate long-term operation of a robot. To this
end, this paper presents a general lifelong simultaneous localization and
mapping (SLAM) framework. Our framework uses a multiple session map
representation, and exploits an efficient map updating strategy that includes
map building, pose graph refinement and sparsification. To mitigate the
unbounded increase of memory usage, we propose a map-trimming method based on
the Chow-Liu maximum-mutual-information spanning tree. The proposed SLAM
framework has been comprehensively validated by over a month of robot
deployment in real supermarket environment. Furthermore, we release the dataset
collected from the indoor and outdoor changing environment with the hope to
accelerate lifelong SLAM research in the community. Our dataset is available at
https://github.com/sanduan168/lifelong-SLAM-dataset.",http://arxiv.org/abs/2111.10946v1
"Methods for measuring noise, purity changes, and entanglement entropy in
  quantum devices and systems",2021-12-01T15:07:29Z,Raam Uzdin,"We present methods for evaluating the rate of change in quantities during
quantum evolution due to coupling to the environment (dissipation hereafter).
The protocol is based on repeating a given quantum circuit (or quantum
operation) twice, thrice, and so on, and measuring an expectation value after
each number of repetitions. We start by applying this method for measuring the
rate of purity changes in quantum circuits. This provides direct information on
the quality of the circuit. Furthermore, the presented scheme enables to
distill the dissipative contribution in the changes of quantities such as
energies and coherence. In particular, this can be applied to the local
Hamiltonians of specific qubits. Thus, our approach can be used to locate
""hotspots"" where the dissipation takes place. A variant of this method can be
used to measure the entanglement buildup in quantum circuits. These methods are
scalable as they involve only a few observables which are relatively easy to
measure in NISQ devices.",http://arxiv.org/abs/2112.00546v1
Painting Asteroids for Planetary Defense,2021-12-07T05:22:08Z,J. I. Katz,"Asteroidal impact threats to the Earth will be predicted a century or more in
advance. Changing an asteroid's albedo changes the force of Solar radiation on
it, and hence its orbit. Albedo may be changed by applying a thin ($\sim
0.1\,\mu$) reflective coat of alkali metal, dispensed as vapor by an orbiting
spacecraft. A complete coat reduces the effective Solar gravity, changing the
orbital period. A Tunguska-class (50 m diameter) asteroid in a nominal orbit
with perihelion 1 AU and aphelion 3 AU ($a = 2\,$AU, $e = 0.5$) may be
displaced along its path by $\sim 1000\,$km in 100 years, sufficient to avoid
impact in a populated area, by application of one kg of lithium or sodium metal
over its entire surface. Alternatively, coating one hemisphere of an asteroid
in an elliptical orbit may produce a Solar radiation torque, analogous to but
distinct from the Yarkovsky effect, displacing it by an Earth radius in $\sim
200$ years. The time required scales as the square root of the asteroid's
diameter (the 1/6 power of its mass) because the displacement increases
quadratically with time, making it possible to prevent the catastrophic impact
of a km-sized asteroid with a minimal mass.",http://arxiv.org/abs/2112.03501v1
"Crossover from nematic to magnetic low-temperature ground state in
  Fe(Se,Te) compounds",2021-12-07T19:28:51Z,"Y. A. Ovchenkov, D. A. Chareev, D. E. Presnov, O. S. Volkova, A. N. Vasiliev","A comparative analysis of the properties of FeSe${}_{1-x}$Te${}_{x}$ crystals
in the range of x values of about 0.4 and pure FeSe crystals is presented. We
found that the anomaly in R (T) at the structural transition for the former
differs significantly from the corresponding anomaly for the latter. This
indicates a change in the type of the ground state in the studied compounds.
Within the framework of the crystal field model, this can be explained as a
consequence of a change in the distortion of the tetrahedral environment of
iron, which leads to a change in the positions of the energy levels within
$t_{2g}$ multiplet. Depending on the mutual position of the degenerate xz and
yz levels and the xy level, the type of transition can change from orbital
ordering to magnetic ordering.",http://arxiv.org/abs/2112.03956v1
Segmenting Time Series via Self-Normalization,2021-12-10T04:24:43Z,"Zifeng Zhao, Feiyu Jiang, Xiaofeng Shao","We propose a novel and unified framework for change-point estimation in
multivariate time series. The proposed method is fully nonparametric, enjoys
effortless tuning and is robust to temporal dependence. One salient and
distinct feature of the proposed method is its versatility, where it allows
change-point detection for a broad class of parameters (such as mean, variance,
correlation and quantile) in a unified fashion. At the core of our method, we
couple the self-normalization (SN) based tests with a novel nested local-window
segmentation algorithm, which seems new in the growing literature of
change-point analysis. Due to the presence of an inconsistent long-run variance
estimator in the SN test, non-standard theoretical arguments are further
developed to derive the consistency and convergence rate of the proposed
SN-based change-point detection method. Extensive numerical experiments and
relevant real data analysis are conducted to illustrate the effectiveness and
broad applicability of our proposed method in comparison with state-of-the-art
approaches in the literature.",http://arxiv.org/abs/2112.05331v3
"Theory of and Experiments on Minimally Invasive Stability Preservation
  in Changing Two-Sided Matching Markets",2021-12-10T19:04:04Z,"Niclas Boehmer, Klaus Heeger, Rolf Niedermeier","Following up on purely theoretical work of Bredereck et al. [AAAI 2020], we
contribute further theoretical insights into adapting stable two-sided
matchings to change. Moreover, we perform extensive empirical studies hinting
at numerous practically useful properties. Our theoretical extensions include
the study of new problems (that is, incremental variants of Almost Stable
Marriage and Hospital Residents), focusing on their (parameterized)
computational complexity and the equivalence of various change types (thus
simplifying algorithmic and complexity-theoretic studies for various natural
change scenarios). Our experimental findings reveal, for instance, that
allowing the new matching to be blocked by a few pairs significantly decreases
the necessary differences between the old and the new stable matching.",http://arxiv.org/abs/2112.05777v1
"A Machine Learning Analysis of Impact of the Covid-19 Pandemic on
  Alcohol Consumption Habit Changes Among Healthcare Workers in the U.S",2021-12-12T15:34:44Z,Mostafa Rezapour,"In this paper, we discuss the impact of the Covid-19 pandemic on alcohol
consumption habit changes among healthcare workers in the United States. We
utilize multiple supervised and unsupervised machine learning methods and
models such as Decision Trees, Logistic Regression, Naive Bayes classifier,
k-Nearest Neighbors, Support Vector Machines, Multilayer perceptron, XGBoost,
CatBoost, LightGBM, Chi-Squared Test and mutual information method on a mental
health survey data obtained from the University of Michigan Inter-University
Consortium for Political and Social Research to find out relationships between
COVID-19 related negative effects and alcohol consumption habit changes among
healthcare workers. Our findings suggest that COVID-19-related school closures,
COVID-19-related work schedule changes and COVID-related news exposure may lead
to an increase in alcohol use among healthcare workers in the United States.",http://arxiv.org/abs/2112.06261v3
Single-Nucleon Energies Changing with Nucleon Number,2021-12-13T15:47:57Z,"J. P. Schiffer, B. P. Kay, J. chen","The broad range of accumulated experimental data on the binding energies for
single-particle states in nuclei is examined as a function of the constituent
number of neutrons and protons and an unexpectedly simple pattern emerges. The
dependence of the energies of neutron states on the number of constituent
protons, or of proton states on the number of neutrons, are very similar to
each other and the sign reflects the well-known strong attraction. For the same
kind of nucleons changing as in the state -- energies for neutron states with
neutron number changing or proton states with protons -- the dependence is at
least a factor of four weaker in magnitude and slightly repulsive, except when
the changing nucleons are only within the same orbit as the state. The
systematics of the accumulated data are presented with a minimum of use made of
model assumptions.",http://arxiv.org/abs/2112.06740v1
"It's Time to Do Something: Mitigating the Negative Impacts of Computing
  Through a Change to the Peer Review Process",2021-12-17T14:51:57Z,"Brent Hecht, Lauren Wilcox, Jeffrey P. Bigham, Johannes Schöning, Ehsan Hoque, Jason Ernst, Yonatan Bisk, Luigi De Russis, Lana Yarosh, Bushra Anjum, Danish Contractor, Cathy Wu","The computing research community needs to work much harder to address the
downsides of our innovations. Between the erosion of privacy, threats to
democracy, and automation's effect on employment (among many other issues), we
can no longer simply assume that our research will have a net positive impact
on the world. While bending the arc of computing innovation towards societal
benefit may at first seem intractable, we believe we can achieve substantial
progress with a straightforward step: making a small change to the peer review
process. As we explain below, we hypothesize that our recommended change will
force computing researchers to more deeply consider the negative impacts of
their work. We also expect that this change will incentivize research and
policy that alleviates computing's negative impacts.",http://arxiv.org/abs/2112.09544v1
"Analysis of Longitudinal Changes in Privacy Behavior of Android
  Applications",2021-12-28T16:21:31Z,"Alexander Yu, Yuvraj Agarwal, Jason I. Hong","Privacy concerns have long been expressed around smart devices, and the
concerns around Android apps have been studied by many past works. Over the
past 10 years, we have crawled and scraped data for almost 1.9 million apps,
and also stored the APKs for 135,536 of them. In this paper, we examine the
trends in how Android apps have changed over time with respect to privacy and
look at it from two perspectives: (1) how privacy behavior in apps have changed
as they are updated over time, (2) how these changes can be accounted for when
comparing third-party libraries and the app's own internals. To study this, we
examine the adoption of HTTPS, whether apps scan the device for other installed
apps, the use of permissions for privacy-sensitive data, and the use of unique
identifiers. We find that privacy-related behavior has improved with time as
apps continue to receive updates, and that the third-party libraries used by
apps are responsible for more issues with privacy. However, we observe that in
the current state of Android apps, there has not been enough of an improvement
in terms of privacy and many issues still need to be addressed.",http://arxiv.org/abs/2112.14205v1
An AGM Approach to Revising Preferences,2021-12-28T18:12:57Z,"Adrian Haret, Johannes P. Wallner","We look at preference change arising out of an interaction between two
elements: the first is an initial preference ranking encoding a pre-existing
attitude; the second element is new preference information signaling input from
an authoritative source, which may come into conflict with the initial
preference. The aim is to adjust the initial preference and bring it in line
with the new preference, without having to give up more information than
necessary. We model this process using the formal machinery of belief change,
along the lines of the well-known AGM approach. We propose a set of fundamental
rationality postulates, and derive the main results of the paper: a set of
representation theorems showing that preference change according to these
postulates can be rationalized as a choice function guided by a ranking on the
comparisons in the initial preference order. We conclude by presenting
operators satisfying our proposed postulates. Our approach thus allows us to
situate preference revision within the larger family of belief change
operators.",http://arxiv.org/abs/2112.14243v1
Lane Change Decision-Making through Deep Reinforcement Learning,2021-12-24T01:36:15Z,"Mukesh Ghimire, Malobika Roy Choudhury, Guna Sekhar Sai Harsha Lagudu","Due to the complexity and volatility of the traffic environment,
decision-making in autonomous driving is a significantly hard problem. In this
project, we use a Deep Q-Network, along with rule-based constraints to make
lane-changing decision. A safe and efficient lane change behavior may be
obtained by combining high-level lateral decision-making with low-level
rule-based trajectory monitoring. The agent is anticipated to perform
appropriate lane-change maneuvers in a real-world-like udacity simulator after
training it for a total of 100 episodes. The results shows that the rule-based
DQN performs better than the DQN method. The rule-based DQN achieves a safety
rate of 0.8 and average speed of 47 MPH",http://arxiv.org/abs/2112.14705v1
On some new types of membrane solutions,2021-12-27T17:21:01Z,Jens Hoppe,"New classes of exact M(em)brane solutions in M+2 dimensional Minkowski space
are presented (some describing non-trivial topology changes, while others
explicitly avoid finite-time singularity formation)",http://arxiv.org/abs/2201.02524v1
"A Harsh Test of Far-Field Scrambling with the Habitable Zone Planet
  Finder and the Hobby Eberly Telescope",2021-03-09T00:15:00Z,"Shubham Kanodia, Samuel Halverson, Joe P. Ninan, Suvrath Mahadevan, Gudmundur Stefansson, Arpita Roy, Lawrence W. Ramsey, Chad F. Bender, Steven Janowiecki, William D. Cochran, Scott A. Diddams, Niv Drory, Michael Endl, Eric B. Ford, Fred Hearty, Andrew J. Metcalf, Andrew Monson, Paul Robertson, Christian Schwab, Ryan C. Terrien, Jason T. Wright","The Habitable zone Planet Finder (HPF) is a fiber fed precise radial velocity
spectrograph at the 10 m Hobby Eberly Telescope (HET). Due to its fixed
altitude design, the HET pupil changes appreciably across a track, leading to
significant changes of the fiber far-field illumination. HPF's fiber scrambler
is designed to suppress the impact of these illumination changes on the radial
velocities -- but the residual impact on the radial velocity measurements has
yet to be probed on sky. We use GJ 411, a bright early type (M2) M dwarf to
probe the effects of far-field input trends due to these pupil variations on
HPF radial velocities (RVs). These large changes ($\sim$ 2x) in pupil area and
centroid present a harsh test of HPF's far-field scrambling. Our results show
that the RVs are effectively decoupled from these extreme far-field input
changes due to pupil centroid offsets, attesting to the effectiveness of the
scrambler design. This experiment allows us to test the impact of these changes
with large pupil variation on-sky, something we would not easily be able to do
at a conventional optical telescope. While the pupil and illumination changes
expected at these other telescopes are small, scaling from our results enables
us to estimate and bound these effects, and show that they are controllable
even for the new and next generation of RV instruments in their quest to beat
down instrumental noise sources towards the goal of a few cm/s.",http://arxiv.org/abs/2103.05148v2
"Multigranular Visual-Semantic Embedding for Cloth-Changing Person
  Re-identification",2021-08-10T09:14:44Z,"Zan Gao, Hongwei Wei, Weili Guan, Weizhi Nie, Meng Liu, Meng Wang","Person reidentification (ReID) is a very hot research topic in machine
learning and computer vision, and many person ReID approaches have been
proposed; however, most of these methods assume that the same person has the
same clothes within a short time interval, and thus their visual appearance
must be similar. However, in an actual surveillance environment, a given person
has a great probability of changing clothes after a long time span, and they
also often take different personal belongings with them. When the existing
person ReID methods are applied in this type of case, almost all of them fail.
To date, only a few works have focused on the cloth-changing person ReID task,
but since it is very difficult to extract generalized and robust features for
representing people with different clothes, their performances need to be
improved. Moreover, visual-semantic information is often ignored. To solve
these issues, in this work, a novel multigranular visual-semantic embedding
algorithm (MVSE) is proposed for cloth-changing person ReID, where visual
semantic information and human attributes are embedded into the network, and
the generalized features of human appearance can be well learned to effectively
solve the problem of clothing changes. Specifically, to fully represent a
person with clothing changes, a multigranular feature representation scheme
(MGR) is employed to focus on the unchanged part of the human, and then a cloth
desensitization network (CDN) is designed to improve the feature robustness of
the approach for the person with different clothing, where different high-level
human attributes are fully utilized. Moreover, to further solve the issue of
pose changes and occlusion under different camera perspectives, a partially
semantically aligned network (PSA) is proposed to obtain the visual-semantic
information that is used to align the human attributes.",http://arxiv.org/abs/2108.04527v1
"Modeling and Representing Conceptual Change in the Learning of
  Successive Theories: The Case of the Classical-Quantum Transition",2021-08-16T06:43:59Z,"Giacomo Zuccarini, Massimiliano Malgieri","Most educational literature on conceptual change concerns the process by
which introductory students acquire scientific knowledge. However, with modern
developments in science and technology, the social significance of learning
successive theories is steadily increasing, thus opening new areas of interest
to discipline-based education research, e.g., quantum logic, quantum
information and communication. Here we present an initial proposal for modeling
the transition from the understanding of a theory to the understanding of its
successor and explore its generative potential by applying it to a concrete
case: the classical-quantum transition in physics. In pursue of such task, we
make coordinated use of contributions not only from research on conceptual
change in education, but also on the history and philosophy of science, on the
teaching and learning of quantum mechanics, on mathematics education. By means
of analytical instruments developed for characterizing conceptual trajectories
at different representational levels, we review empirical literature in the
search for the connections between theory change and cognitive demands. The
analysis shows a rich landscape of changes and new challenges that are absent
in the traditionally considered cases of conceptual change. In order to fully
disclose the educational potential of the analysis, we visualize categorical
changes by means of dynamic frames, identifying recognizable patterns that
answer to students' need of comparability between the older and the new
paradigm. Finally, we show how the frame representation can be used to suggest
pattern-dependent strategies to promote the understanding of the new content,
and may work as a guide to curricular design.",http://arxiv.org/abs/2108.06919v8
"The Atlas of Lane Changes: Investigating Location-dependent Lane Change
  Behaviors Using Measurement Data from a Customer Fleet",2021-06-23T07:29:19Z,"Florian Wirthmüller, Jochen Hipp, Christian Reichenbächer, Manfred Reichert","The prediction of surrounding traffic participants behavior is a crucial and
challenging task for driver assistance and autonomous driving systems. Today's
approaches mainly focus on modeling dynamic aspects of the traffic situation
and try to predict traffic participants behavior based on this. In this article
we take a first step towards extending this common practice by calculating
location-specific a-priori lane change probabilities. The idea behind this is
straight forward: The driving behavior of humans may vary in exactly the same
traffic situation depending on the respective location. E.g. drivers may ask
themselves: Should I pass the truck in front of me immediately or should I wait
until reaching the less curvy part of my route lying only a few kilometers
ahead? Although, such information is far away from allowing behavior prediction
on its own, it is obvious that today's approaches will greatly benefit when
incorporating such location-specific a-priori probabilities into their
predictions. For example, our investigations show that highway interchanges
tend to enhance driver's motivation to perform lane changes, whereas curves
seem to have lane change-dampening effects. Nevertheless, the investigation of
all considered local conditions shows that superposition of various effects can
lead to unexpected probabilities at some locations. We thus suggest dynamically
constructing and maintaining a lane change probability map based on customer
fleet data in order to support onboard prediction systems with additional
information. For deriving reliable lane change probabilities a broad customer
fleet is the key to success.",http://arxiv.org/abs/2107.04029v2
"Quality change: norm or exception? Measurement, Analysis and Detection
  of Quality Change in Wikipedia",2021-11-02T10:51:53Z,"Paramita Das, Bhanu Prakash Reddy Guda, Sasi Bhusan Seelaboyina, Soumya Sarkar, Animesh Mukherjee","Wikipedia has been turned into an immensely popular crowd-sourced
encyclopedia for information dissemination on numerous versatile topics in the
form of subscription free content. It allows anyone to contribute so that the
articles remain comprehensive and updated. For enrichment of content without
compromising standards, the Wikipedia community enumerates a detailed set of
guidelines, which should be followed. Based on these, articles are categorized
into several quality classes by the Wikipedia editors with increasing adherence
to guidelines. This quality assessment task by editors is laborious as well as
demands platform expertise. As a first objective, in this paper, we study
evolution of a Wikipedia article with respect to such quality scales. Our
results show novel non-intuitive patterns emerging from this exploration. As a
second objective we attempt to develop an automated data driven approach for
the detection of the early signals influencing the quality change of articles.
We posit this as a change point detection problem whereby we represent an
article as a time series of consecutive revisions and encode every revision by
a set of intuitive features. Finally, various change point detection algorithms
are used to efficiently and accurately detect the future change points. We also
perform various ablation studies to understand which group of features are most
effective in identifying the change points. To the best of our knowledge, this
is the first work that rigorously explores English Wikipedia article quality
life cycle from the perspective of quality indicators and provides a novel
unsupervised page level approach to detect quality switch, which can help in
automatic content monitoring in Wikipedia thus contributing significantly to
the CSCW community.",http://arxiv.org/abs/2111.01496v1
"Statistical mechanics and Bayesian Inference addressed to the Osborne
  Paradox",2021-03-01T06:24:32Z,Geoffrey Ducournau,"One of the greatest contributors of the 20th century among all academician in
the field of statistical finance, M. F. M. Osborne published in 1956 [6] an
essential paper and proposed to treat the question of stock market motion
through the prism of both the Law of Weber-Fechner [1, 4] and the branch of
physics developed by James Clerk Maxwell, Ludwig Boltzmann and Josiah Willard
Gibbs [3, 5] namely the statistical mechanics. He proposed an improvement of
the known research made by his predecessor Louis Jean-Baptiste Alphonse
Bachelier, by not considering the arithmetic changes of stock prices as means
of statistical measurement, but by drawing on the Weber-Fechner Law, to treat
the changes of prices. Osborne emphasized that as in statistical mechanics, the
probability distribution of the steady-state of subjective change in prices is
determined by the condition of maximum probability, a statement close to the
Gibbs distribution conditions. However, Osborne also admitted that the
empirical observation of the probability distribution of logarithmic changes of
stock prices was emphasizing obvious asymmetries and consequently could not
perfectly confirm his prior theory. The purpose of this paper is to propose an
explanation to what we could call the Osborne paradox and then address an
alternative approach via Bayesian inference regarding the description of the
probability distribution of changes in logarithms of prices that was
thenceforth under the prism of frequentist inference. We show that the stock
market returns are locally described by equilibrium statistical mechanics with
conserved statistics variables, whereas globally there is yet other statistics
with persistent flowing variables that can be effectively described by a
superposition of several statistics on different time scales, namely, a
superstatistics.",http://arxiv.org/abs/2103.00788v1
"DR-TANet: Dynamic Receptive Temporal Attention Network for Street Scene
  Change Detection",2021-03-01T10:01:35Z,"Shuo Chen, Kailun Yang, Rainer Stiefelhagen","Street scene change detection continues to capture researchers' interests in
the computer vision community. It aims to identify the changed regions of the
paired street-view images captured at different times. The state-of-the-art
network based on the encoder-decoder architecture leverages the feature maps at
the corresponding level between two channels to gain sufficient information of
changes. Still, the efficiency of feature extraction, feature correlation
calculation, even the whole network requires further improvement. This paper
proposes the temporal attention and explores the impact of the dependency-scope
size of temporal attention on the performance of change detection. In addition,
based on the Temporal Attention Module (TAM), we introduce a more efficient and
light-weight version - Dynamic Receptive Temporal Attention Module (DRTAM) and
propose the Concurrent Horizontal and Vertical Attention (CHVA) to improve the
accuracy of the network on specific challenging entities. On street scene
datasets `GSV', `TSUNAMI' and `VL-CMU-CD', our approach gains excellent
performance, establishing new state-of-the-art scores without bells and
whistles, while maintaining high efficiency applicable in autonomous vehicles.",http://arxiv.org/abs/2103.00879v2
Investigation of gamma-ray variability and glitches of PSR J1420-6048,2021-03-15T13:52:28Z,"Lupin C. -C. Lin, H. H. Wang, C. Y. Hui, Jumpei Takata, Paul K. H. Yeung, Chin-Ping Hu, Albert K. H. Kong","PSR J1420-6048 is a young gamma-ray pulsar with recurrent glitches. Utilizing
long-term monitoring data obtained from the Fermi Gamma-ray Space Telescope, we
found that PSR J1420-6048 has shown gamma-ray flux variation and we also
detected four glitches between 2008 and 2019. Two of the glitches are
previously unknown, and their gamma-ray spectrum also shows variability between
each glitch. Since the results might be contaminated by background sources, we
discuss whether the observed changes in flux and spectra were caused by
artificial misallocations of photons from a nearby pulsar wind nebula (HESS
J1420-607) and a pulsar (PSR J1418-6058), or a change of the emission geometry
from the target pulsar itself. We examine the correlation of the flux changes
and the alternating pulse structure to investigate whether the emission
geometry in the outer magnetosphere was changing. By assuming the observational
features were not totally resulted from the background environment, we compare
our results with similar phenomena observed in other gamma-ray pulsars and
propose that a strong crust crack can cause timing anomaly of a neutron star,
which can affect the particle accelerations or pair creation regions resulting
in the changes of emission behaviors.",http://arxiv.org/abs/2103.08386v1
"The feature of shadow images and observed luminosity of the Bardeen
  black hole surrounded by different accretions",2021-03-25T08:31:51Z,"Ke-Jian He, Sen Guo, Shuang-Cheng Tan, Guo-Ping Li","In this paper, by exploring the photon motion in the region near the Bardeen
black hole, the shadow and observation properties of the black hole surrounded
by various accretion models are studied. We analyzed the changes in shadow
imaging and observation luminosity when the relevant physical parameters are
changed. For the different spherical accretions background, one can find that
the radius of shadow and the position of photon sphere do not change, but the
observation intensity of shadow in the infalling accretion model is
significantly lower than that of the static case. When the black hole is
surrounded by an optically and thin disk accretion, the contribution of the
photon rings, lensing rings and direct emission to the total observed flux has
also been studied. Under the different forms of the emission modes, the result
shows that the observed brightness is mainly determined by direct emission,
while the lensing rings will provide a small part of the observation flux and
the photon ring can provide a negligible observation flux. By comparing our
results with the Schwarzschild spacetime, it is found that the existence or
change of relevant status parameters will greatly affect the shape and
observation intensity of black hole shadow. These results support that the
change of state parameter will affect the spacetime structure, thus affecting
the observation feature of black hole shadows.",http://arxiv.org/abs/2103.13664v2
Step-Change in Friction under Electrovibration,2021-03-30T16:45:27Z,"Idil Ozdamar, M. Reza Alipour, Benoit P. Delhaye, Philippe Lef`evre, Cagatay Basdogan","Rendering tactile effects on a touch screen via electrovibration has many
potential applications. However, our knowledge on tactile perception of change
in friction and the underlying contact mechanics are both very limited. In this
study, we investigate the tactile perception and the contact mechanics for a
step change in friction under electrovibration during a relative sliding
between finger and the surface of a capacitive touchscreen. First, we conduct
magnitude estimation experiments to investigate the role of normal force and
sliding velocity on the perceived tactile intensity for a step increase and
decrease in friction, called as rising friction (RF) and falling friction (FF).
To investigate the contact mechanics involved in RF and FF, we then measure the
frictional force, the apparent contact area, and the strains acting on the
fingerpad during sliding at a constant velocity under three different normal
loads using a custom-made experimental set-up. The results show that the
participants perceived RF stronger than FF, and both the normal force and
sliding velocity significantly influenced their perception. These results are
supported by our mechanical measurements; the relative change in friction, the
apparent contact area, and the strain in the sliding direction were all higher
for RF than those for FF, especially for low normal forces. Taken together, our
results suggest that different contact mechanics take place during RF and FF
due to the viscoelastic behavior of fingerpad skin, and those differences
influence our tactile perception of a step change in friction.",http://arxiv.org/abs/2103.16489v1
"Counterfactual Invariance to Spurious Correlations: Why and How to Pass
  Stress Tests",2021-05-31T14:39:38Z,"Victor Veitch, Alexander D'Amour, Steve Yadlowsky, Jacob Eisenstein","Informally, a 'spurious correlation' is the dependence of a model on some
aspect of the input data that an analyst thinks shouldn't matter. In machine
learning, these have a know-it-when-you-see-it character; e.g., changing the
gender of a sentence's subject changes a sentiment predictor's output. To check
for spurious correlations, we can 'stress test' models by perturbing irrelevant
parts of input data and seeing if model predictions change. In this paper, we
study stress testing using the tools of causal inference. We introduce
counterfactual invariance as a formalization of the requirement that changing
irrelevant parts of the input shouldn't change model predictions. We connect
counterfactual invariance to out-of-domain model performance, and provide
practical schemes for learning (approximately) counterfactual invariant
predictors (without access to counterfactual examples). It turns out that both
the means and implications of counterfactual invariance depend fundamentally on
the true underlying causal structure of the data -- in particular, whether the
label causes the features or the features cause the label. Distinct causal
structures require distinct regularization schemes to induce counterfactual
invariance. Similarly, counterfactual invariance implies different domain shift
guarantees depending on the underlying causal structure. This theory is
supported by empirical results on text classification.",http://arxiv.org/abs/2106.00545v3
QWin: Enforcing Tail Latency SLO at Shared Storage Backend,2021-06-17T02:10:14Z,"Liuying Ma, Zhenqing Liu, Jin Xiong, Dejun Jiang","Consolidating latency-critical (LC) and best-effort (BE) tenants at storage
backend helps to increase resources utilization. Even if tenants use dedicated
queues and threads to achieve performance isolation, threads are still contend
for CPU cores. Therefore, we argue that it is necessary to partition cores
between LC and BE tenants, and meanwhile each core is dedicated to run a
thread. Expect for frequently changing bursty load, fluctuated service time at
storage backend also drastically changes the need of cores. In order to
guarantee tail latency service level objectives (SLOs), the abrupt changing
need of cores must be satisfied immediately. Otherwise, tail latency SLO
violation happens. Unfortunately, partitioning-based approaches lack the
ability to react the changing need of cores, resulting in extreme spikes in
latency and SLO violation happens. In this paper, we present QWin, a tail
latency SLO aware core allocation to enforce tail latency SLO at shared storage
backend. QWin consists of an SLO-to-core calculation model that accurately
calculates the number of cores combining with definitive runtime load
determined by a flexible request-based window, and an autonomous core
allocation that adjusts cores at adaptive frequency by dynamically changing
core policies. When consolidating multiple LC and BE tenants, QWin outperforms
the-state-of-the-art approaches in guaranteeing tail latency SLO for LC tenants
and meanwhile increasing bandwidth of BE tenants by up to 31x.",http://arxiv.org/abs/2106.09206v1
Do people's user types change over time? An exploratory study,2021-06-18T14:25:21Z,"Ana Cláudia Guimarães Santos, Wilk Oliveira, Juho Hamari, Seiji Isotani","In recent years, different studies have proposed and validated user models
(e.g., Bartle, BrainHex, and Hexad) to represent the different user profiles in
games and gamified settings. However, the results of applying these user models
in practice (e.g., to personalize gamified systems) are still contradictory.
One of the hypotheses for these results is that the user types can change over
time (i.e., user types are dynamic). To start to understand whether user types
can change over time, we conducted an exploratory study analyzing data from 74
participants to identify if their user type (Achiever, Philanthropist,
Socialiser, Free Spirit, Player, and Disruptor) had changed over time (six
months). The results indicate that there is a change in the dominant user type
of the participants, as well as the average scores in the Hexad sub-scales.
These results imply that all the scores should be considered when defining the
Hexad's user type and that the user types are dynamic. Our results contribute
with practical implications, indicating that the personalization currently made
(generally static) may be insufficient to improve the users' experience,
requiring user types to be analyzed continuously and personalization to be done
dynamically.",http://arxiv.org/abs/2106.10148v1
"Coupled and uncoupled sign-changing spikes of singularly perturbed
  elliptic systems",2021-07-31T17:52:36Z,"Mónica Clapp, Mayra Soares","We study the existence and asymptotic behavior of solutions having positive
and sign-changing components to the singularly perturbed system of elliptic
equations \begin{equation*} \begin{cases} -\varepsilon^2\Delta
u_i+u_i=\mu_i|u_i|^{p-2}u_i + \sum\limits_{\substack{j=1 \\ j
\not=i}}^\ell\lambda_{ij}\beta_{ij}|u_j|^{\alpha_{ij}}|u_i|^{\beta_{ij}
-2}u_i,\\ u_i \in H^1_0(\Omega), \quad u_i\neq 0, \qquad i=1,\ldots,\ell,
\end{cases} \end{equation*} in a bounded domain $\Omega$ in $\mathbb{R}^N$,
with $N\geq 4$, $\varepsilon>0$, $\mu_i>0$, $\lambda_{ij}=\lambda_{ji}<0$,
$\alpha_{ij}, \beta_{ij}>1$, $\alpha_{ij}=\beta_{ji}$, $\alpha_{ij} +
\beta_{ij} = p\in (2,2^*)$, and $2^{*}:=\frac{2N}{N-2}$.
  If $\Omega$ is the unit ball we obtain solutions with a prescribed
combination of positive and nonradial sign-changing components exhibiting two
different types of asymptotic behavior as $\varepsilon\to 0$: solutions whose
limit profile is a rescaling of a solution with positive and nonradial
sign-changing components of the limit system \begin{equation*} \begin{cases}
-\Delta u_i+u_i=\mu_i|u_i|^{p-2}u_i + \sum\limits_{\substack{j=1 \\ j
\not=i}}^\ell\lambda_{ij}\beta_{ij}|u_j|^{\alpha_{ij}}|u_i|^{\beta_{ij}
-2}u_i,\\ u_i \in H^1(\mathbb{R}^N), \quad u_i\neq 0, \qquad i=1,\ldots,\ell,
\end{cases} \end{equation*} and solutions whose limit profile is a solution of
the uncoupled system, i.e., after rescaling and translation, the limit profile
of the $i$-th component is a positive or a nonradial sign-changing solution to
the equation $$-\Delta u+u=\mu_i|u|^{p-2}u,\qquad u \in H^1(\mathbb{R}^N),
\qquad u\neq 0.$$",http://arxiv.org/abs/2108.00299v2
"Identifying Wetland Areas in Historical Maps using Deep Convolutional
  Neural Networks",2021-08-09T15:08:07Z,"Niclas Ståhl, Lisa Weimann","1) The local environment and land usages have changed a lot during the past
one hundred years. Historical documents and materials are crucial in
understanding and following these changes. Historical documents are, therefore,
an important piece in the understanding of the impact and consequences of land
usage change. This, in turn, is important in the search of restoration projects
that can be conducted to turn and reduce harmful and unsustainable effects
originating from changes in the land-usage.
  2) This work extracts information on the historical location and geographical
distribution of wetlands, from hand-drawn maps. This is achieved by using deep
learning (DL), and more specifically a convolutional neural network (CNN). The
CNN model is trained on a manually pre-labelled dataset on historical wetlands
in the area of J\""onk\""oping county in Sweden. These are all extracted from the
historical map called ""Generalstabskartan"".
  3) The presented CNN performs well and achieves a $F_1$-score of 0.886 when
evaluated using a 10-fold cross validation over the data. The trained models
are additionally used to generate a GIS layer of the presumable historical
geographical distribution of wetlands for the area that is depicted in the
southern collection in Generalstabskartan, which covers the southern half of
Sweden. This GIS layer is released as an open resource and can be freely used.
  4) To summarise, the presented results show that CNNs can be a useful tool in
the extraction and digitalisation of non-textual information in historical
documents, such as historical maps. A modern GIS material that can be used to
further understand the past land-usage change is produced within this research.",http://arxiv.org/abs/2108.04107v1
Lifelong Computing,2021-08-19T17:19:52Z,"Danny Weyns, Thomas Bäck, Renè Vidal, Xin Yao, Ahmed Nabil Belbachir","Computing systems form the backbone of many aspects of our life, hence they
are becoming as vital as water, electricity, and road infrastructures for our
society. Yet, engineering long running computing systems that achieve their
goals in ever-changing environments pose significant challenges. Currently, we
can build computing systems that adjust or learn over time to match changes
that were anticipated. However, dealing with unanticipated changes, such as
anomalies, novelties, new goals or constraints, requires system evolution,
which remains in essence a human-driven activity. Given the growing complexity
of computing systems and the vast amount of highly complex data to process,
this approach will eventually become unmanageable. To break through the status
quo, we put forward a new paradigm for the design and operation of computing
systems that we coin ""lifelong computing."" The paradigm starts from
computing-learning systems that integrate computing/service modules and
learning modules. Computing warehouses offer such computing elements together
with data sheets and usage guides. When detecting anomalies, novelties, new
goals or constraints, a lifelong computing system activates an evolutionary
self-learning engine that runs online experiments to determine how the
computing-learning system needs to evolve to deal with the changes, thereby
changing its architecture and integrating new computing elements from computing
warehouses as needed. Depending on the domain at hand, some activities of
lifelong computing systems can be supported by humans. We motivate the need for
lifelong computing with a future fish farming scenario, outline a blueprint
architecture for lifelong computing systems, and highlight key research
challenges to realise the vision of lifelong computing.",http://arxiv.org/abs/2108.08802v1
Change of Basis between Classical Orthogonal Polynomials,2021-08-31T05:59:02Z,D. A. Wolfram,"Classical orthogonal polynomials have widespread applications including in
numerical integration, solving differential equations, and interpolation.
Changing basis between classical orthogonal polynomials can affect the
convergence, accuracy, and stability of solutions.
  We provide a general method for changing basis between any pair of classical
orthogonal polynomials by using algebraic expressions called coefficient
functions that evaluate to connection coefficients. The method builds directly
on previous work on the change of basis groupoid. The scope has fifteen kinds
of classical orthogonal polynomials including the classes of Jacobi, Gegenbauer
and generalized Laguerre polynomials.
  The method involves the mappings to and from the monomials for these
polynomial bases. Sixteen coefficient functions appear to be new for
polynomials that do not have definite parity. We derive the remainder from
seven sources in the literature. We give a complete summary of thirty
coefficient functions.
  This enables change of basis to be defined algebraically and uniformly
between any pair of classical orthogonal polynomial bases by using a vector dot
product to compose two coefficient functions to give a third.
  A definition of Jacobi polynomials uses a basis of shifted monomials. We find
a key new mapping between the monomials and Jacobi polynomials by using a
general mapping between shifted monomials and monomials. It yields new mappings
for the Chebyshev polynomials of the third and fourth kinds and their shifted
versions.",http://arxiv.org/abs/2108.13631v1
Physical Context and Timing Aware Sequence Generating GANs,2021-09-28T07:58:53Z,"Hayato Futase, Tomoki Tsujimura, Tetsuya Kajimoto, Hajime Kawarazaki, Toshiyuki Suzuki, Makoto Miwa, Yutaka Sasaki","Generative Adversarial Networks (GANs) have shown remarkable successes in
generating realistic images and interpolating changes between images. Existing
models, however, do not take into account physical contexts behind images in
generating the images, which may cause unrealistic changes. Furthermore, it is
difficult to generate the changes at a specific timing and they often do not
match with actual changes. This paper proposes a novel GAN, named Physical
Context and Timing aware sequence generating GANs (PCTGAN), that generates an
image in a sequence at a specific timing between two images with considering
physical contexts behind them. Our method consists of three components: an
encoder, a generator, and a discriminator. The encoder estimates latent vectors
from the beginning and ending images, their timings, and a target timing. The
generator generates images and the physical contexts at the beginning, ending,
and target timing from the corresponding latent vectors. The discriminator
discriminates whether the generated images and contexts are real or not. In the
experiments, PCTGAN is applied to a data set of sequential changes of shapes in
die forging processes. We show that both timing and physical contexts are
effective in generating sequential images.",http://arxiv.org/abs/2110.04077v1
"Change point detection and image segmentation for time series of
  astrophysical images",2021-01-27T04:37:53Z,"Cong Xu, Hans Moritz Günther, Vinay L. Kashyap, Thomas C. M. Lee, Andreas Zezas","Many astrophysical phenomena are time-varying, in the sense that their
intensity, energy spectrum, and/or the spatial distribution of the emission
suddenly change. This paper develops a method for modeling a time series of
images. Under the assumption that the arrival times of the photons follow a
Poisson process, the data are binned into 4D grids of voxels (time, energy
band, and x-y coordinates), and viewed as a time series of non-homogeneous
Poisson images. The method assumes that at each time point, the corresponding
multi-band image stack is an unknown 3D piecewise constant function including
Poisson noise. It also assumes that all image stacks between any two adjacent
change points (in time domain) share the same unknown piecewise constant
function. The proposed method is designed to estimate the number and the
locations of all the change points (in time domain), as well as all the unknown
piecewise constant functions between any pairs of the change points. The method
applies the minimum description length (MDL) principle to perform this task. A
practical algorithm is also developed to solve the corresponding complicated
optimization problem. Simulation experiments and applications to real datasets
show that the proposed method enjoys very promising empirical properties.
Applications to two real datasets, the XMM observation of a flaring star and an
emerging solar coronal loop, illustrate the usage of the proposed method and
the scientific insight gained from it.",http://arxiv.org/abs/2101.11202v1
Low-skilled Occupations Face the Highest Upskilling Pressure,2021-01-27T16:02:57Z,"Di Tong, Lingfei Wu, James Allen Evans","Substantial scholarship has estimated the susceptibility of jobs to
automation, but little has examined how job contents evolve in the information
age as new technologies substitute for tasks, shifting required skills rather
than eliminating entire jobs. Here we explore patterns of occupational skill
change and characterize occupations and workers subject to the greatest
reskilling requirements. Recent work found that changing skill requirements are
greatest for STEM occupations in the 2010s. Nevertheless, analyzing 167 million
online job posts covering 727 occupations, we find that skill change is
greatest for low-skilled occupations when accounting for distance between
skills. We further investigate the differences in skill change across employer
and market size, as well as social demographic groups. We find that jobs from
small employers and markets experienced larger skill upgrades to catch up with
the skill demands of their large employers and markets. Female and minority
workers are disproportionately employed in low-skilled jobs and face the most
significant skill adjustments. While these varied skill changes could create
uneven reskilling pressures across workers, they may also lead to a narrowing
of gaps in job quality and prospects. We conclude by showcasing our model's
potential to chart job evolution directions using skill embedding spaces.",http://arxiv.org/abs/2101.11505v5
"Predicting the Time Until a Vehicle Changes the Lane Using LSTM-based
  Recurrent Neural Networks",2021-02-02T11:04:22Z,"Florian Wirthmüller, Marvin Klimke, Julian Schlechtriemen, Jochen Hipp, Manfred Reichert","To plan safe and comfortable trajectories for automated vehicles on highways,
accurate predictions of traffic situations are needed. So far, a lot of
research effort has been spent on detecting lane change maneuvers rather than
on estimating the point in time a lane change actually happens. In practice,
however, this temporal information might be even more useful. This paper deals
with the development of a system that accurately predicts the time to the next
lane change of surrounding vehicles on highways using long short-term
memory-based recurrent neural networks. An extensive evaluation based on a
large real-world data set shows that our approach is able to make reliable
predictions, even in the most challenging situations, with a root mean squared
error around 0.7 seconds. Already 3.5 seconds prior to lane changes the
predictions become highly accurate, showing a median error of less than 0.25
seconds. In summary, this article forms a fundamental step towards downstreamed
highly accurate position predictions.",http://arxiv.org/abs/2102.01431v2
"SimCD: Simultaneous Clustering and Differential expression analysis for
  single-cell transcriptomic data",2021-04-04T01:06:18Z,"Seyednami Niyakan, Ehsan Hajiramezanali, Shahin Boluki, Siamak Zamani Dadaneh, Xiaoning Qian","Single-Cell RNA sequencing (scRNA-seq) measurements have facilitated
genome-scale transcriptomic profiling of individual cells, with the hope of
deconvolving cellular dynamic changes in corresponding cell sub-populations to
better understand molecular mechanisms of different development processes.
Several scRNA-seq analysis methods have been proposed to first identify cell
sub-populations by clustering and then separately perform differential
expression analysis to understand gene expression changes. Their corresponding
statistical models and inference algorithms are often designed disjointly. We
develop a new method -- SimCD -- that explicitly models cell heterogeneity and
dynamic differential changes in one unified hierarchical gamma-negative
binomial (hGNB) model, allowing simultaneous cell clustering and differential
expression analysis for scRNA-seq data. Our method naturally defines cell
heterogeneity by dynamic expression changes, which is expected to help achieve
better performances on the two tasks compared to the existing methods that
perform them separately. In addition, SimCD better models dropout (zero
inflation) in scRNA-seq data by both cell- and gene-level factors and obviates
the need for sophisticated pre-processing steps such as normalization, thanks
to the direct modeling of scRNA-seq count data by the rigorous hGNB model with
an efficient Gibbs sampling inference algorithm. Extensive comparisons with the
state-of-the-art methods on both simulated and real-world scRNA-seq count data
demonstrate the capability of SimCD to discover cell clusters and capture
dynamic expression changes. Furthermore, SimCD helps identify several known
genes affected by food deprivation in hypothalamic neuron cell subtypes as well
as some new potential markers, suggesting the capability of SimCD for
bio-marker discovery.",http://arxiv.org/abs/2104.01512v1
Towards Lifelong Learning of End-to-end ASR,2021-04-04T13:48:53Z,"Heng-Jui Chang, Hung-yi Lee, Lin-shan Lee","Automatic speech recognition (ASR) technologies today are primarily optimized
for given datasets; thus, any changes in the application environment (e.g.,
acoustic conditions or topic domains) may inevitably degrade the performance.
We can collect new data describing the new environment and fine-tune the
system, but this naturally leads to higher error rates for the earlier
datasets, referred to as catastrophic forgetting. The concept of lifelong
learning (LLL) aiming to enable a machine to sequentially learn new tasks from
new datasets describing the changing real world without forgetting the
previously learned knowledge is thus brought to attention. This paper reports,
to our knowledge, the first effort to extensively consider and analyze the use
of various approaches of LLL in end-to-end (E2E) ASR, including proposing novel
methods in saving data for past domains to mitigate the catastrophic forgetting
problem. An overall relative reduction of 28.7% in WER was achieved compared to
the fine-tuning baseline when sequentially learning on three very different
benchmark corpora. This can be the first step toward the highly desired ASR
technologies capable of synchronizing with the continuously changing real
world.",http://arxiv.org/abs/2104.01616v3
"Temporal patterns of synchrony in a pyramidal-interneuron gamma (PING)
  network",2021-04-05T21:29:12Z,"Quynh-Anh Nguyen, Leonid L Rubchinsky","Synchronization in neural system plays an important role in many brain
functions. Synchronization in the gamma frequency band (30Hz-100Hz) is involved
in a variety of cognitive phenomena; abnormalities of the gamma synchronization
are found in schizophrenia and autism spectrum disorder. Frequently, the
strength of synchronization is not very high and is intermittent even on short
time scales (a few cycles of oscillations). That is, the network exhibits
intervals of synchronization followed by intervals of desynchronization. Neural
circuits dynamics may show different distributions of desynchronization
durations even if the synchronization strength is fixed. In this study, we use
a conductance-based neural network exhibiting pyramidal-interneuron (PING)
gamma rhythm to study the temporal patterning of synchronized neural
oscillations. We found that changes in the synaptic strength (as well as
changes in the membrane kinetics) can alter the temporal patterning of
synchrony. Moreover, we found that the changes in the temporal pattern of
synchrony may be independent of the changes in the average synchrony strength.
Even though the temporal patterning may vary, there is a tendency for dynamics
with short (although potentially numerous) desynchronizations, similar to what
was observed in experimental studies of neural activity synchronization in the
brain. Recent studies suggested that the short desynchronizations dynamics may
facilitate the formation and the break-up of transient neural assemblies. Thus,
the results of this study suggest that changes of synaptic strength may alter
the temporal patterning of the gamma synchronization as to make the neural
networks more efficient in the formation of neural assemblies and the
facilitation of cognitive phenomena.",http://arxiv.org/abs/2104.02163v1
"Electrochemistry of thin films with operando grazing incidence X-ray
  scattering: bypassing electrolyte scattering for high fidelity time resolved
  studies",2021-04-11T13:00:40Z,"Bryan D. Paulsen, Alexander Giovannitti, Ruiheng Wu, Joseph Strzalka, Qingteng Zhang, Jonathan Rivnay, Christopher J. Takacs","Electroactive polymer thin films undergo repeated reversible structural
change during operation in electrochemical applications. While synchrotron
X-ray scattering is powerful for the characterization of stand-alone and
ex-situ organic thin films, in situ structural characterization has been
underutilized--in large part due to complications arising from supporting
electrolyte scattering. This has greatly hampered the development of
application relevant structure property relationships. Therefore, we have
developed a new methodology for in situ and operando X-ray characterization
that separates the incident and scattered X-ray beam path from the electrolyte.
As a proof of concept, we demonstrate the in situ structural changes of
weakly-scattering, organic mixed ionic-electronic conductor thin films in an
aqueous electrolyte environment, enabling access to previously unexplored
changes in the pi-pi peak and diffuse scatter in situ, while capturing the
solvent swollen thin film structure which was inaccessible in previous ex situ
studies. These in situ measurements improve the sensitivity to structural
changes, capturing minute changes not possible ex situ, and have multimodal
potential such as combined Raman measurements that also serve to validate the
true in situ/operando conditions of the cell. Finally, we examine new
directions enabled by this operando cell design and compare state of the art
measurements.",http://arxiv.org/abs/2104.05009v1
"StylePTB: A Compositional Benchmark for Fine-grained Controllable Text
  Style Transfer",2021-04-12T04:25:09Z,"Yiwei Lyu, Paul Pu Liang, Hai Pham, Eduard Hovy, Barnabás Póczos, Ruslan Salakhutdinov, Louis-Philippe Morency","Text style transfer aims to controllably generate text with targeted
stylistic changes while maintaining core meaning from the source sentence
constant. Many of the existing style transfer benchmarks primarily focus on
individual high-level semantic changes (e.g. positive to negative), which
enable controllability at a high level but do not offer fine-grained control
involving sentence structure, emphasis, and content of the sentence. In this
paper, we introduce a large-scale benchmark, StylePTB, with (1) paired
sentences undergoing 21 fine-grained stylistic changes spanning atomic lexical,
syntactic, semantic, and thematic transfers of text, as well as (2)
compositions of multiple transfers which allow modeling of fine-grained
stylistic changes as building blocks for more complex, high-level transfers. By
benchmarking existing methods on StylePTB, we find that they struggle to model
fine-grained changes and have an even more difficult time composing multiple
styles. As a result, StylePTB brings novel challenges that we hope will
encourage future research in controllable text style transfer, compositional
models, and learning disentangled representations. Solving these challenges
would present important steps towards controllable text generation.",http://arxiv.org/abs/2104.05196v1
"When and Whom to Collaborate with in a Changing Environment: A
  Collaborative Dynamic Bandit Solution",2021-04-14T22:15:58Z,"Chuanhao Li, Qingyun Wu, Hongning Wang","Collaborative bandit learning, i.e., bandit algorithms that utilize
collaborative filtering techniques to improve sample efficiency in online
interactive recommendation, has attracted much research attention as it enjoys
the best of both worlds. However, all existing collaborative bandit learning
solutions impose a stationary assumption about the environment, i.e., both user
preferences and the dependency among users are assumed static over time.
Unfortunately, this assumption hardly holds in practice due to users'
ever-changing interests and dependence relations, which inevitably costs a
recommender system sub-optimal performance in practice.
  In this work, we develop a collaborative dynamic bandit solution to handle a
changing environment for recommendation. We explicitly model the underlying
changes in both user preferences and their dependency relation as a stochastic
process. Individual user's preference is modeled by a mixture of globally
shared contextual bandit models with a Dirichlet Process prior. Collaboration
among users is thus achieved via Bayesian inference over the global bandit
models. Model selection and arm selection for each user are done via Thompson
sampling to balance exploitation and exploration. Our solution is proved to
maintain a standard $\tilde O(\sqrt{T})$ sublinear regret even in such a
challenging environment. And extensive empirical evaluations on both synthetic
and real-world datasets further confirmed the necessity of modeling a changing
environment and our algorithm's practical advantages against several
state-of-the-art online learning solutions.",http://arxiv.org/abs/2104.07150v1
"Demystifying Regular Expression Bugs: A comprehensive study on regular
  expression bug causes, fixes, and testing",2021-04-19T23:58:33Z,"Peipei Wang, Chris Brown, Jamie A. Jennings, Kathryn T. Stolee","Regular expressions cause string-related bugs and open security
vulnerabilities for DOS attacks. However, beyond ReDoS (Regular expression
Denial of Service), little is known about the extent to which regular
expression issues affect software development and how these issues are
addressed in practice. We conduct an empirical study of 356 merged
regex-related pull request bugs from Apache, Mozilla, Facebook, and Google
GitHub repositories. We identify and classify the nature of the regular
expression problems, the fixes, and the related changes in the test code.
  The most important findings in this paper are as follows: 1) incorrect
regular expression behavior is the dominant root cause of regular expression
bugs (165/356, 46.3%). The remaining root causes are incorrect API usage (9.3%)
and other code issues that require regular expression changes in the fix
(29.5%), 2) fixing regular expression bugs is nontrivial as it takes more time
and more lines of code to fix them compared to the general pull requests, 3)
most (51%) of the regex-related pull requests do not contain test code changes.
Certain regex bug types (e.g., compile error, performance issues, regex
representation) are less likely to include test code changes than others, and
4) the dominant type of test code changes in regex-related pull requests is
test case addition (75%). The results of this study contribute to a broader
understanding of the practical problems faced by developers when using, fixing,
and testing regular expressions.",http://arxiv.org/abs/2104.09693v1
Concept Drift Detection from Multi-Class Imbalanced Data Streams,2021-04-20T20:03:54Z,"Łukasz Korycki, Bartosz Krawczyk","Continual learning from data streams is among the most important topics in
contemporary machine learning. One of the biggest challenges in this domain
lies in creating algorithms that can continuously adapt to arriving data.
However, previously learned knowledge may become outdated, as streams evolve
over time. This phenomenon is known as concept drift and must be detected to
facilitate efficient adaptation of the learning model. While there exists a
plethora of drift detectors, all of them assume that we are dealing with
roughly balanced classes. In the case of imbalanced data streams, those
detectors will be biased towards the majority classes, ignoring changes
happening in the minority ones. Furthermore, class imbalance may evolve over
time and classes may change their roles (majority becoming minority and vice
versa). This is especially challenging in the multi-class setting, where
relationships among classes become complex. In this paper, we propose a
detailed taxonomy of challenges posed by concept drift in multi-class
imbalanced data streams, as well as a novel trainable concept drift detector
based on Restricted Boltzmann Machine. It is capable of monitoring multiple
classes at once and using reconstruction error to detect changes in each of
them independently. Our detector utilizes a skew-insensitive loss function that
allows it to handle multiple imbalanced distributions. Due to its trainable
nature, it is capable of following changes in a stream and evolving class
roles, as well as it can deal with local concept drift occurring in minority
classes. Extensive experimental study on multi-class drifting data streams,
enriched with a detailed analysis of the impact of local drifts and changing
imbalance ratios, confirms the high efficacy of our approach.",http://arxiv.org/abs/2104.10228v1
Particle flow rate in silos under rotational shear,2021-04-29T08:41:02Z,"D. Hernández-Delfin, T. Pongó, K. To, T. Börzsönyi, R. C. Hidalgo","Very recently, To et al.~have experimentally explored granular flow in a
cylindrical silo, with a bottom wall that rotates horizontally with respect to
the lateral wall \cite{Kiwing2019}. Here, we numerically reproduce their
experimental findings, in particular, the peculiar behavior of the mass flow
rate $Q$ as a function of the frequency of rotation $f$. Namely, we find that
for small outlet diameters $D$ the flow rate increased with $f$, while for
larger $D$ a non-monotonic behavior is confirmed. Furthermore, using a
coarse-graining technique, we compute the macroscopic density, momentum, and
the stress tensor fields. These results show conclusively that changes in the
discharge process are directly related to changes in the flow pattern from
funnel flow to mass flow. Moreover, by decomposing the mass flux (linear
momentum field) at the orifice into two main factors: macroscopic velocity and
density fields, we obtain that the non-monotonic behavior of the linear
momentum is caused by density changes rather than by changes in the macroscopic
velocity. In addition, by analyzing the spatial distribution of the kinetic
stress, we find that for small orifices increasing rotational shear enhances
the mean kinetic pressure $\langle p^k \rangle$ and the system dilatancy. This
reduces the stability of the arches, and, consequently, the volumetric flow
rate increases monotonically. For large orifices, however, we detected that
$\langle p^k \rangle$ changes non-monotonically, which might explain the
non-monotonic behavior of $Q$ when varying the rotational shear.",http://arxiv.org/abs/2104.14201v1
"Rapid Modification of Neutron Star Surface Magnetic Field: A proposed
  mechanism for explaining Radio Emission State Changes in Pulsars",2021-05-04T10:01:13Z,"U. Geppert, R. Basu, D. Mitra, G. Melikidze, M. Szkudlarek","The radio emission in many pulsars show sudden changes, usually within a
period, that cannot be related to the steady state processes within the inner
acceleration region (IAR) above the polar cap. These changes are often
quasi-periodic in nature, where regular transitions between two or more stable
emission states are seen. The durations of these states show a wide variety
ranging from several seconds to hours at a time. There are strong, small scale
magnetic field structures and huge temperature gradients present at the polar
cap surface. We have considered several processes that can cause temporal
modifications of the local magnetic field structure and strength at the surface
of the polar cap. Using different magnetic field strengths and scales, and also
assuming realistic scales of the temperature gradients, the evolutionary
timescales of different phenomena affecting the surface magnetic field was
estimated. We find that the Hall drift results in faster changes in comparison
to both Ohmic decay and thermoelectric effects. A mechanism based on the
Partially Screened Gap (PSG) model of the IAR has been proposed, where the Hall
and thermoelectric oscillations perturb the polar cap magnetic field to alter
the sparking process in the PSG. This is likely to affect the observed radio
emission resulting in the observed state changes.",http://arxiv.org/abs/2105.01391v1
Migrating Client Code without Change Examples,2021-05-06T01:37:51Z,"Hao Zhong, Na Meng","API developers evolve software libraries to fix bugs, add new features, or
refactor code. To benefit from such library evolution, the programmers of
client projects have to repetitively upgrade their library usages and adapt
their codebases to any library API breaking changes (e.g., API renaming). Such
adaptive changes can be tedious and error-prone. Existing tools provide limited
support to help programmers migrate client projects from old library versions
to new ones. For instance, some tools extract API mappings be-tween library
versions and only suggest simple adaptive changes (i.e., statement updates);
other tools suggest or automate more complicated edits (e.g., statement
insertions) based on user-provided exemplar code migrations. However, when new
library versions are available, it is usually cumbersome and time-consuming for
users to provide sufficient human-crafted samples in order to guide automatic
migration. In this paper, we propose a novel approach, AutoUpdate, to further
improve the state of the art. Instead of learning from change examples, we
designed AutoUpdate to automate migration in a compiler-directed way. Namely,
given a compilation error triggered by upgrading libraries, AutoUpdate exploits
13 migration opera-tors to generate candidate edits, and tentatively applies
each edit until the error is resolved or all edits are explored. We conducted
two experiments. The first experiment involves migrating 371 tutorial examples
between versions of 5 popular libraries. AutoUpdate reduced migration-related
compilation errors for 92.7% of tasks. It eliminated such errors for 32.4% of
tasks, and 33.9% of the tasks have identical edits to manual migrations. In the
second experiment, we applied AutoUpdate to migrate two real client projects of
lucene. AutoUpdate successfully migrated both projects, and the migrated code
passed all tests.",http://arxiv.org/abs/2105.02389v1
"Kolmogorov-Smirnov Test-Based Actively-Adaptive Thompson Sampling for
  Non-Stationary Bandits",2021-05-30T17:28:41Z,"Gourab Ghatak, Hardhik Mohanty, Aniq Ur Rahman","We consider the non-stationary multi-armed bandit (MAB) framework and propose
a Kolmogorov-Smirnov (KS) test based Thompson Sampling (TS) algorithm named
TS-KS, that actively detects change points and resets the TS parameters once a
change is detected. In particular, for the two-armed bandit case, we derive
bounds on the number of samples of the reward distribution to detect the change
once it occurs. Consequently, we show that the proposed algorithm has
sub-linear regret. Contrary to existing works, our algorithm is able to detect
a change when the underlying reward distribution changes even though the mean
reward remains the same. Finally, to test the efficacy of the proposed
algorithm, we employ it in two case-studies: i) task-offloading scenario in
wireless edge-computing, and ii) portfolio optimization. Our results show that
the proposed TS-KS algorithm outperforms not only the static TS algorithm but
also it performs better than other bandit algorithms designed for
non-stationary environments. Moreover, the performance of TS-KS is at par with
the state-of-the-art forecasting algorithms such as Facebook-PROPHET and ARIMA.",http://arxiv.org/abs/2105.14586v2
"DeepChange: A Large Long-Term Person Re-Identification Benchmark with
  Clothes Change",2021-05-31T03:35:00Z,"Peng Xu, Xiatian Zhu","Existing person re-identification (re-id) works mostly consider short-term
application scenarios without clothes change. In real-world, however, we often
dress differently across space and time. To solve this contrast, a few recent
attempts have been made on long-term re-id with clothes change. Currently, one
of the most significant limitations in this field is the lack of a large
realistic benchmark. In this work, we contribute a large, realistic long-term
person re-identification benchmark, named as DeepChange. It has several unique
characteristics: (1) Realistic and rich personal appearance (e.g., clothes and
hair style) and variations: Highly diverse clothes change and styles, with
varying reappearing gaps in time from minutes to seasons, different weather
conditions (e.g., sunny, cloudy, windy, rainy, snowy, extremely cold) and
events (e.g., working, leisure, daily activities). (2) Rich camera setups: Raw
videos were recorded by 17 outdoor varying resolution cameras operating in a
real-world surveillance system. (3) The currently largest number of (17)
cameras, (1, 121) identities, and (178, 407) bounding boxes, over the longest
time span (12 months). Further, we investigate multimodal fusion strategies for
tackling the clothes change challenge. Extensive experiments show that our
fusion models outperform a wide variety of state-of-the-art models on
DeepChange. Our dataset and documents are available at
https://github.com/PengBoXiangShang/deepchange.",http://arxiv.org/abs/2105.14685v4
"EVARS-GPR: EVent-triggered Augmented Refitting of Gaussian Process
  Regression for Seasonal Data",2021-07-06T08:20:28Z,"Florian Haselbeck, Dominik G. Grimm","Time series forecasting is a growing domain with diverse applications.
However, changes of the system behavior over time due to internal or external
influences are challenging. Therefore, predictions of a previously learned
fore-casting model might not be useful anymore. In this paper, we present
EVent-triggered Augmented Refitting of Gaussian Process Regression for Seasonal
Data (EVARS-GPR), a novel online algorithm that is able to handle sudden shifts
in the target variable scale of seasonal data. For this purpose, EVARS-GPR
com-bines online change point detection with a refitting of the prediction
model using data augmentation for samples prior to a change point. Our
experiments on sim-ulated data show that EVARS-GPR is applicable for a wide
range of output scale changes. EVARS-GPR has on average a 20.8 % lower RMSE on
different real-world datasets compared to methods with a similar computational
resource con-sumption. Furthermore, we show that our algorithm leads to a
six-fold reduction of the averaged runtime in relation to all comparison
partners with a periodical refitting strategy. In summary, we present a
computationally efficient online fore-casting algorithm for seasonal time
series with changes of the target variable scale and demonstrate its
functionality on simulated as well as real-world data. All code is publicly
available on GitHub: https://github.com/grimmlab/evars-gpr.",http://arxiv.org/abs/2107.02463v1
Watching Single Unmodified Enzymes at Work,2021-07-13T21:42:06Z,"Cuifeng Ying, Edona Karakaci, Esteban Bermudez-Urena, Alessandro Ianiro, Ceri Foster, Saurabh Awasthi, Anirvan Guha, Louise Bryan, Jonathan List, Sandor Balog, Guillermo P. Acuna, Reuven Gordon, Michael Mayer","Many proteins undergo conformational changes during their activity. A full
understanding of the function of these proteins can only be obtained if
different conformations and transitions between them can be monitored in
aqueous solution, with adequate temporal resolution and, ideally, on a
single-molecule level. Interrogating conformational dynamics of single proteins
remains, however, exquisitely challenging and typically requires site-directed
chemical modification combined with rigorous minimization of possible
artifacts. These obstacles limit the number of single-protein investigations.
The work presented here introduces an approach that traps single unmodified
proteins from solution in a plasmonic hotspot and makes it possible to assign
changes in refractive index to changes in protein conformation while monitoring
these changes for minutes to hours with a temporal resolution at least as fast
as 40 microseconds. The resulting single molecule data reveals that adenylate
kinase employs a hidden enzymatic sub-cycle during catalysis, that citrate
synthase populates a previously unknown intermediate conformation, which is
more important for its enzymatic activity than its well-known open
conformation, that hemoglobin transitions in several steps from its
deoxygenated and rigid T state to its oxygenated and flexible R state, and that
apo-calmodulin thermally unfolds and refolds in steps that correspond to
conformational changes of individual protein domains.",http://arxiv.org/abs/2107.06407v1
Spatiotemporal Characterization of VIIRS Night Light,2021-09-14T18:22:17Z,Christopher Small,"The VIIRS Day Night Band sensor on the Suomi NPP satellite provides almost a
decade of observations of night light. The daily frequency of sampling, without
the temporal averaging of annual composites, requires the distinction between
apparent changes of imaged night light related to the imaging process and
actual changes in the underlying sources of the light being imaged. This study
characterizes night light variability over a range of spatial and temporal
scales to provide a context for interpretation of changes on both subannual and
interannual time scales. This analysis uses a combination of temporal moments,
spatial correlation and Empirical Orthogonal Function (EOF) analysis. A key
result is the pervasive heteroskedasticity of VIIRS monthly mean night light.
Specifically, the monotonic decrease of temporal variability with increasing
mean brightness. Anthropogenic night light is remarkably stable on subannual
time scales. Overall variance partition derived from the eigenvalues of the
spatiotemporal covariance matrix are 88%, 2% and 2% for spatial, seasonal and
interannual variance in the most diverse geographic region on Earth (Eurasia).
Heteroskedasticity is present in all areas for all months, suggesting that
much, if not most, of observed month-to-month variability may result from
luminance of otherwise stable sources subjected to multiple aspects of the
imaging process varying in time. Given the skewed distribution of all night
light arising from radial peripheral dimming of bright sources, even aggregate
metrics using thresholds must be interpreted in light of the fact that much
larger numbers of more variable low luminance pixels may statistically
overwhelm smaller numbers of stable higher luminance pixels and cause apparent
changes related to the imaging process to be interpreted as actual changes in
the light sources.",http://arxiv.org/abs/2109.06913v1
"Source-sink cooperation dynamics constrain institutional evolution in a
  group-structured society",2021-09-16T16:55:20Z,"Laurent Hébert-Dufresne, Timothy M. Waring, Guillaume St-Onge, Meredith T. Niles, Laura Kati Corlew, Matthew P. Dube, Stephanie J. Miller, Nicholas Gotelli, Brian J. McGill","Societies change through time, entailing changes in behaviors and
institutions. We ask how social change occurs when behaviors and institutions
are interdependent. We model a group-structured society in which the
transmission of individual behavior occurs in parallel with the selection of
group-level institutions. We consider a cooperative behavior that generates
collective benefits for groups but does not spread between individuals on its
own. Groups exhibit institutions that increase the diffusion of the behavior
within the group, but also incur a group cost. Groups adopt institutions in
proportion to their fitness. Finally, cooperative behavior may also spread
globally. As expected, we find that cooperation and institutions are mutually
reinforcing. But the model also generates behavioral source-sink dynamics when
cooperation generated in institutional groups spreads to non-institutional
groups, boosting their fitness. Consequently, the global diffusion of
cooperation creates a pattern of institutional free-riding that limits the
evolution of group-beneficial institutions. Our model suggests that, in a
group-structured society, large-scale change in behavior and institutions (i.e.
social change) can be best achieved when the two remain correlated, such as
through the spread successful pilot programs.",http://arxiv.org/abs/2109.08106v1
"Comparison of single and multitask learning for predicting cognitive
  decline based on MRI data",2021-09-21T15:46:42Z,"Vandad Imani, Mithilesh Prakash, Marzieh Zare, Jussi Tohka","The Alzheimer's Disease Assessment Scale-Cognitive subscale (ADAS-Cog) is a
neuropsychological tool that has been designed to assess the severity of
cognitive symptoms of dementia. Personalized prediction of the changes in
ADAS-Cog scores could help in timing therapeutic interventions in dementia and
at-risk populations. In the present work, we compared single and multitask
learning approaches to predict the changes in ADAS-Cog scores based on
T1-weighted anatomical magnetic resonance imaging (MRI). In contrast to most
machine learning-based prediction methods ADAS-Cog changes, we stratified the
subjects based on their baseline diagnoses and evaluated the prediction
performances in each group. Our experiments indicated a positive relationship
between the predicted and observed ADAS-Cog score changes in each diagnostic
group, suggesting that T1-weighted MRI has a predictive value for evaluating
cognitive decline in the entire AD continuum. We further studied whether
correction of the differences in the magnetic field strength of MRI would
improve the ADAS-Cog score prediction. The partial least square-based domain
adaptation slightly improved the prediction performance, but the improvement
was marginal. In summary, this study demonstrated that ADAS-Cog change could
be, to some extent, predicted based on anatomical MRI. Based on this study, the
recommended method for learning the predictive models is a single-task
regularized linear regression due to its simplicity and good performance. It
appears important to combine the training data across all subject groups for
the most effective predictive models.",http://arxiv.org/abs/2109.10266v1
"Are automated static analysis tools worth it? An investigation into
  relative warning density and external software quality",2021-11-17T15:23:24Z,"Alexander Trautsch, Steffen Herbold, Jens Grabowski","Automated Static Analysis Tools (ASATs) are part of software development best
practices. ASATs are able to warn developers about potential problems in the
code. On the one hand, ASATs are based on best practices so there should be a
noticeable effect on software quality. On the other hand, ASATs suffer from
false positive warnings, which developers have to inspect and then ignore or
mark as invalid. In this article, we ask the question if ASATs have a
measurable impact on external software quality, using the example of PMD for
Java. We investigate the relationship between ASAT warnings emitted by PMD on
defects per change and per file. Our case study includes data for the history
of each file as well as the differences between changed files and the project
in which they are contained. We investigate whether files that induce a defect
have more static analysis warnings than the rest of the project. Moreover, we
investigate the impact of two different sets of ASAT rules. We find that, bug
inducing files contain less static analysis warnings than other files of the
project at that point in time. However, this can be explained by the overall
decreasing warning density. When compared with all other changes, we find a
statistically significant difference in one metric for all rules and two
metrics for a subset of rules. However, the effect size is negligible in all
cases, showing that the actual difference in warning density between bug
inducing changes and other changes is small at best.",http://arxiv.org/abs/2111.09188v2
"ORCLSim: A System Architecture for Studying Bicyclist and Pedestrian
  Physiological Behavior Through Immersive Virtual Environments",2021-12-06T23:31:29Z,"Xiang Guo, Austin Angulo, Erin Robartes, T. Donna Chen, Arsalan Heydarian","Injuries and fatalities for vulnerable road users, especially bicyclists and
pedestrians, are on the rise. To better inform design for vulnerable road
users, we need to conduct more studies to evaluate how bicyclist and pedestrian
behavior and physiological states change in different roadway designs and
contextual settings. Previous research highlights the advantages of Immersive
Virtual Environment (IVE) in conducting bicyclist and pedestrian studies. These
environments do not put participants at risk of getting injured, are low-cost
compared to on-road or naturalistic studies and allow researchers to fully
control variables of interest. In this paper, we propose a framework ORCLSim,
to support human sensing techniques within IVE to evaluate bicyclist and
pedestrian physiological and behavioral changes in different contextual
settings. To showcase this framework, we present two case studies where we
collect and analyze pilot data from five participants' physiological and
behavioral responses in an IVE setting, representing real-world roadway
segments and traffic conditions. Results from these case studies indicate that
physiological data is sensitive to road environment changes and real-time
events, especially changes in heart rate and gaze behavior. Additionally, our
preliminary data indicates participants may respond differently to various
roadway settings (e.g., intersections with or without traffic signal). By
analyzing these changes, we can identify how participants' stress levels and
cognitive load is impacted by the simulated surrounding environment. The
ORCLSim system architecture can be further utilized for future studies in
users' behavioral and physiological responses in different virtual reality
settings.",http://arxiv.org/abs/2112.03420v1
IntelliTC: Automating Type Changes in IntelliJ IDEA,2021-12-07T10:31:42Z,"Oleg Smirnov, Ameya Ketkar, Timofey Bryksin, Nikolaos Tsantalis, Danny Dig","Developers often change types of program elements. Such refactoring often
involves updating not only the type of the element itself, but also the API of
all type-dependent references in the code, thus it is tedious and
time-consuming. Despite type changes being more frequent than renamings, just a
few current IDE tools provide partially-automated support only for a small set
of hard-coded types. Researchers have recently proposed a data-driven approach
to inferring API rewrite rules for type change patterns in Java using code
commits history. In this paper, we build upon these recent advances and
introduce IntelliTC - a tool to perform Java type change refactoring. We
implemented it as a plugin for IntelliJ IDEA, a popular Java IDE developed by
JetBrains. We present 3 different ways of providing support for such a
refactoring from the standpoint of the user experience: Classic mode, Suggested
Refactoring, and Inspection mode. To evaluate these modalities of using
IntelliTC, we surveyed 22 experienced software developers. They positively
rated the usefulness of the tool.
  The source code and distribution of the plugin are available on GitHub:
https://github.com/JetBrains-Research/data-driven-type-migration. A
demonstration video is on YouTube: https://youtu.be/pdcfvADA1PY.",http://arxiv.org/abs/2112.03619v2
"Hydrogen related defects in titanium dioxide at the interface to
  palladium",2021-12-11T11:15:56Z,"Mohsen Sotoudeh, Marian David Bongers-Loth, Vladimir Roddatis, Jakub Čížek, Carsten Nowak, Martin Wenderoth, Peter Blöchl, Astrid Pundt","A metal oxide support and a catalytically active metal are the two main
ingredients for complex catalysts used in heterogeneous catalysis. The gas
environment can change the catalyst during the reaction, modifying its
structural and electronic properties. Here, we use monochromated electron
energy loss spectroscopy (EELS) to reveal hydrogen-pressure-dependent changes
of the electronic structure at the Pd/rutile-TiO$_2$ interface in an
environmental transmission electron microscope (ETEM). Hydrogen-induced changes
are observed in rutile-TiO$_2$ within $2$~nm from the interface at $10$~Pa of
hydrogen pressure, in the Ti $L_{3,2}$ EEL spectra. Lower pressures such as
$1$~Pa show no changes in the EEL spectra. We attribute the observed changes in
the EEL spectra to hydrogen-induced defects accumulating in the vicinity of the
interface. Based on DFT calculations, we developed a thermodynamic multistate
defect (TMD) model of the interface and the bulk of the rutile-TiO$_2$. This
TMD model predicts high concentrations of positively charged defects
accumulating at the interface. The presence of the Schottky barrier stabilizes
these defects by significantly lowering their formation energy. Our findings
provide important new insights into catalytic processes taking place at
metal/metal oxide interfaces in hydrogen gas environments.",http://arxiv.org/abs/2112.05953v1
Tracking Most Significant Arm Switches in Bandits,2021-12-27T18:59:05Z,"Joe Suk, Samory Kpotufe","In bandit with distribution shifts, one aims to automatically adapt to
unknown changes in reward distribution, and restart exploration when necessary.
While this problem has been studied for many years, a recent breakthrough of
Auer et al. (2018, 2019) provides the first adaptive procedure to guarantee an
optimal (dynamic) regret $\sqrt{LT}$, for $T$ rounds, and an unknown number $L$
of changes. However, while this rate is tight in the worst case, it remained
open whether faster rates are possible, without prior knowledge, if few changes
in distribution are actually severe.
  To resolve this question, we propose a new notion of significant shift, which
only counts very severe changes that clearly necessitate a restart: roughly,
these are changes involving not only best arm switches, but also involving
large aggregate differences in reward overtime. Thus, our resulting procedure
adaptively achieves rates always faster (sometimes significantly) than
$O(\sqrt{ST})$, where $S\ll L$ only counts best arm switches, while at the same
time, always faster than the optimal $O(V^{\frac{1}{3}}T^{\frac{2}{3}})$ when
expressed in terms of total variation $V$ (which aggregates differences
overtime). Our results are expressed in enough generality to also capture
non-stochastic adversarial settings.",http://arxiv.org/abs/2112.13838v6
"Watch out for Extrinsic Bugs! A Case Study of their Impact in
  Just-In-Time Bug Prediction Models on the OpenStack project",2021-03-28T17:37:34Z,"Gema Rodriguez-Perez, Meiyappan Nagappan, Gregorio Robles","Intrinsic bugs are bugs for which a bug introducing change can be identified
in the version control system of a software. In contrast, extrinsic bugs are
caused by external changes to a software, such as errors in external APIs;
thereby they do not have an explicit bug introducing change in the version
control system. Although most previous research literature has assumed that all
bugs are of intrinsic nature, in a previous study, we show that not all bugs
are intrinsic. This paper shows an example of how considering extrinsic bugs
can affect software engineering research. Specifically, we study the impact of
extrinsic bugs in Just In Time bug prediction by partially replicating a recent
study by McIntosh and Kamei on JIT models. These models are trained using
properties of earlier bug-introducing changes. Since extrinsic bugs do not have
bug introducing changes in the version control system, we manually curate
McIntosh and Kamei's dataset to distinguish between intrinsic and extrinsic
bugs. Then, we address their original research questions, this time removing
extrinsic bugs, to study whether bug-introducing changes are a moving target in
Just-In-Time bug prediction. Finally, we study whether characteristics of
intrinsic and extrinsic bugs are different. Our results show that intrinsic and
extrinsic bugs are of different nature. When removing extrinsic bugs the
performance is different up to 16 % Area Under the Curve points. This indicates
that our JIT models obtain a more accurate representation of the real world. We
conclude that extrinsic bugs negatively impact Just-In-Time models.
Furthermore, we offer evidence that extrinsic bugs should be further
investigated, as they can significantly impact how software engineers
understand bugs.",http://arxiv.org/abs/2103.15180v1
"Breaking Bad? Semantic Versioning and Impact of Breaking Changes in
  Maven Central",2021-10-15T07:20:46Z,"Lina Ochoa, Thomas Degueule, Jean-Rémy Falleri, Jurgen Vinju","Just like any software, libraries evolve to incorporate new features, bug
fixes, security patches, and refactorings. However, when a library evolves, it
may break the contract previously established with its clients by introducing
Breaking Changes (BCs) in its API. These changes might trigger compile-time,
link-time, or run-time errors in client code. As a result, clients may hesitate
to upgrade their dependencies, raising security concerns and making future
upgrades even more difficult.Understanding how libraries evolve helps client
developers to know which changes to expect and where to expect them, and
library developers to understand how they might impact their clients. In the
most extensive study to date, Raemaekers et al. investigate to what extent
developers of Java libraries hosted on the Maven Central Repository (MCR)
follow semantic versioning conventions to signal the introduction of BCs and
how these changes impact client projects. Their results suggest that BCs are
widespread without regard for semantic versioning, with a significant impact on
clients.In this paper, we conduct an external and differentiated replication
study of their work. We identify and address some limitations of the original
protocol and expand the analysis to a new corpus spanning seven more years of
the MCR. We also present a novel static analysis tool for Java bytecode,
Maracas, which provides us with: (i) the set of all BCs between two versions of
a library; and (ii) the set of locations in client code impacted by individual
BCs. Our key findings, derived from the analysis of 119, 879 library upgrades
and 293, 817 clients, contrast with the original study and show that 83.4% of
these upgrades do comply with semantic versioning. Furthermore, we observe that
the tendency to comply with semantic versioning has significantly increased
over time. Finally, we find that most BCs affect code that is not used by any
client, and that only 7.9% of all clients are affected by BCs. These findings
should help (i) library developers to understand and anticipate the impact of
their changes; (ii) library users to estimate library upgrading effort and to
pick libraries that are less likely to break; and (iii) researchers to better
understand the dynamics of library-client co-evolution in Java.",http://arxiv.org/abs/2110.07889v1
"Large change of interlayer vibrational coupling with stacking in
  Mo$_{1-x}$W$_{x}$Te$_{2}$",2021-10-21T01:04:16Z,"John A. Schneeloch, Yu Tao, Jaime A. Fernandez-Baca, Guangyong Xu, Despina Louca","Stacking variations in quasi-2D materials can have an important influence on
material properties, such as changing the topology of the band structure.
Unfortunately, the weakness of van der Waals interactions makes it difficult to
compute the stacking dependence of properties, and even in a material as simple
as graphite the stacking energetics remain unclear. Mo$_{1-x}$W$_{x}$Te$_{2}$
is a material in which three differently-stacked phases are conveniently
accessible by temperature changes: $1T^{\prime}$, $T^*_d$, and the reported
Weyl semimetal phase $T_d$. The transitions proceed via layer sliding, and the
corresponding interlayer shear mode (ISM) is relevant not just for the stacking
energetics, but for understanding the relationship between the Weyl physics and
structural changes. However, the interlayer interactions of
Mo$_{1-x}$W$_{x}$Te$_{2}$ are not well understood, with wide variation in
computed properties. We report inelastic neutron scattering of the ISM in a
Mo$_{0.91}$W$_{0.09}$Te$_{2}$ crystal. The ISM energies are generally
consistent with the linear chain model (LCM), as expected given the weak
interlayer interaction, though there are some discrepancies from predicted
intensities. However, the interlayer force constants $K_x$ in the $T^*_d$ and
$1T^{\prime}$ phases are substantially weaker than that of $T_d$, at 76(3)% and
83(3)%, respectively. Considering that the relative positioning of atoms in
neighboring layers is approximately the same regardless of overall stacking,
our results suggest that longer-range influences, such as stacking-induced band
structure changes, may be responsible for the substantial change in the
interlayer vibrational coupling. These findings should elucidate the stacking
energetics of Mo$_{1-x}$W$_{x}$Te$_{2}$ and other van der Waals layered
materials.",http://arxiv.org/abs/2110.10844v1
"SUTRA: A Novel Approach to Modelling Pandemics with Applications to
  COVID-19",2021-01-22T15:33:16Z,"Manindra Agrawal, Madhuri Kanitkar, Deepu Phillip, Tanima Hajra, Arti Singh, Avaneesh Singh, Prabal Pratap Singh, Mathukumalli Vidyasagar","The Covid-19 pandemic has two key properties: (i) asymptomatic cases (both
detected and undetected) that can result in new infections, and (ii)
time-varying characteristics due to new variants, Non-Pharmaceutical
Interventions etc. We develop a model called SUTRA (Susceptible, Undetected
though infected, Tested positive, and Removed Analysis) that takes into account
both of these two key properties. While applying the model to a region, two
parameters of the model can be learnt from the number of daily new cases found
in the region. Using the learnt values of the parameters the model can predict
the number of daily new cases so long as the learnt parameters do not change
substantially. Whenever any of the two parameters changes due to the key
property (ii) above, the SUTRA model can detect that the values of one or both
of the parameters have changed. Further, the model has the capability to
relearn the changed parameter values, and then use these to carry out the
prediction of the trajectory of the pandemic for the region of concern. The
SUTRA approach can be applied at various levels of granularity, from an entire
country to a district, more specifically, to any large enough region for which
the data of daily new cases are available.
  We have applied the SUTRA model to thirty-two countries, covering more than
half of the world's population. Our conclusions are: (i) The model is able to
capture the past trajectories very well. Moreover, the parameter values, which
we can estimate robustly, help quantify the impact of changes in the pandemic
characteristics. (ii) Unless the pandemic characteristics change significantly,
the model has good predictive capability. (iii) Natural immunity provides
significantly better protection against infection than the currently available
vaccines.",http://arxiv.org/abs/2101.09158v6
"A consistent and conservative Phase-Field model for
  thermo-gas-liquid-solid flows including liquid-solid phase change",2021-02-13T05:34:09Z,"Ziyang Huang, Guang Lin, Arezoo M. Ardekani","In the present study, a consistent and conservative Phase-Field model is
developed to study thermo-gas-liquid-solid flows with liquid-solid phase
change. The proposed model is derived with the help of the consistency
conditions and exactly reduces to the consistent and conservative Phase-Field
method for incompressible two-phase flows, the fictitious domain Brinkman
penalization (FD/BP) method for fluid-structure interactions, and the
Phase-Field model of solidification of pure material. It honors the mass
conservation, defines the volume fractions of individual phases unambiguously,
and therefore captures the volume change due to phase change. The momentum is
conserved when the solid phase is absent, but it changes when the solid phase
appears due to the no-slip condition at the solid boundary. The proposed model
also conserves the energy, preserves the temperature equilibrium, and is
Galilean invariant. A novel continuous surface tension force to confine its
contribution at the gas-liquid interface and a drag force modified from the
Carman-Kozeny equation to reduce solid velocity to zero are proposed. The issue
of initiating phase change in the original Phase-Field model of solidification
is addressed by physically modifying the interpolation function. The
corresponding consistent scheme is developed to solve the model, and the
numerical results agree well with the analytical solutions and the existing
experimental and numerical data. Two challenging problems having a wide range
of material properties and complex dynamics are conducted to demonstrate the
capability of the proposed model.",http://arxiv.org/abs/2102.06863v3
"AdaPool: A Diurnal-Adaptive Fleet Management Framework using Model-Free
  Deep Reinforcement Learning and Change Point Detection",2021-04-01T02:14:01Z,"Marina Haliem, Vaneet Aggarwal, Bharat Bhargava","This paper introduces an adaptive model-free deep reinforcement approach that
can recognize and adapt to the diurnal patterns in the ride-sharing environment
with car-pooling. Deep Reinforcement Learning (RL) suffers from catastrophic
forgetting due to being agnostic to the timescale of changes in the
distribution of experiences. Although RL algorithms are guaranteed to converge
to optimal policies in Markov decision processes (MDPs), this only holds in the
presence of static environments. However, this assumption is very restrictive.
In many real-world problems like ride-sharing, traffic control, etc., we are
dealing with highly dynamic environments, where RL methods yield only
sub-optimal decisions. To mitigate this problem in highly dynamic environments,
we (1) adopt an online Dirichlet change point detection (ODCP) algorithm to
detect the changes in the distribution of experiences, (2) develop a Deep Q
Network (DQN) agent that is capable of recognizing diurnal patterns and making
informed dispatching decisions according to the changes in the underlying
environment. Rather than fixing patterns by time of week, the proposed approach
automatically detects that the MDP has changed, and uses the results of the new
model. In addition to the adaptation logic in dispatching, this paper also
proposes a dynamic, demand-aware vehicle-passenger matching and route planning
framework that dynamically generates optimal routes for each vehicle based on
online demand, vehicle capacities, and locations. Evaluation on New York City
Taxi public dataset shows the effectiveness of our approach in improving the
fleet utilization, where less than 50% of the fleet are utilized to serve the
demand of up to 90% of the requests, while maximizing profits and minimizing
idle times.",http://arxiv.org/abs/2104.00203v2
A Statistical Model of Word Rank Evolution,2021-07-21T08:57:32Z,"Alex John Quijano, Rick Dale, Suzanne Sindi","The availability of large linguistic data sets enables data-driven approaches
to study linguistic change. The Google Books corpus unigram frequency data set
is used to investigate the word rank dynamics in eight languages. We observed
the rank changes of the unigrams from 1900 to 2008 and compared it to a
Wright-Fisher inspired model that we developed for our analysis. The model
simulates a neutral evolutionary process with the restriction of having no
disappearing and added words. This work explains the mathematical framework of
the model - written as a Markov Chain with multinomial transition probabilities
- to show how frequencies of words change in time. From our observations in the
data and our model, word rank stability shows two types of characteristics: (1)
the increase/decrease in ranks are monotonic, or (2) the rank stays the same.
Based on our model, high-ranked words tend to be more stable while low-ranked
words tend to be more volatile. Some words change in ranks in two ways: (a) by
an accumulation of small increasing/decreasing rank changes in time and (b) by
shocks of increase/decrease in ranks. Most words in all of the languages we
have looked at are rank stable, but not as stable as a neutral model would
predict. The stopwords and Swadesh words are observed to be rank stable across
eight languages indicating linguistic conformity in established languages.
These signatures suggest unigram frequencies in all languages have changed in a
manner inconsistent with a purely neutral evolutionary process.",http://arxiv.org/abs/2107.09948v4
"What really changes when developers intend to improve their source code:
  a commit-level study of static metric value and static analysis warning
  changes",2021-09-08T11:02:00Z,"Alexander Trautsch, Johannes Erbel, Steffen Herbold, Jens Grabowski","Many software metrics are designed to measure aspects that are believed to be
related to software quality. Static software metrics, e.g., size, complexity
and coupling are used in defect prediction research as well as software quality
models to evaluate software quality. While this indicates a relationship
between quality and software metrics, the extent of it is not well understood.
Moreover, recent studies found that complexity metrics may be unreliable
indicators for understandability of the source code. To explore this
relationship, we leverage the intent of developers about what constitutes a
quality improvement in their own code base. We manually classify a randomized
sample of 2,533 commits from 54 Java open source projects as quality improving
depending on the intent of the developer by inspecting the commit message. We
distinguish between perfective and corrective maintenance via predefined
guidelines and use this data as ground truth for the fine-tuning of a
state-of-the art deep learning model for natural language processing. We use
the model to increase our data set to 125,482 commits. Based on the resulting
data set, we investigate the differences in size and 14 static source code
metrics between changes that increase quality, as indicated by the developer,
and other changes. We find that quality improving commits are smaller than
other commits. Perfective changes have a positive impact on static source code
metrics while corrective changes do tend to add complexity. Furthermore, we
find that files which are the target of perfective maintenance already have a
lower median complexity than other files. Our study results provide empirical
evidence for which static source code metrics capture quality improvement from
the developers point of view. This has implications for program understanding
as well as code smell detection and recommender systems.",http://arxiv.org/abs/2109.03544v5
Chaos in Qubit Coupled Optomechanical Systems,2021-02-28T14:21:31Z,"Manik Kapil, Amarendra K. Sarma","We have found stable chaotic solutions for optomechanical systems coupled
with a Two-Level System or qubit. In this system methods have been found which
can be used to Tune in and out of Chaos as well as various n-period motions.
This includes achieving chaos by changing the detuning, coupling parameters,
and Power of the driving laser. This allows us to manipulate chaos using either
the qubit or the optical cavity. Chaotic motion was also observed in both the
qubit and cavity by only changing the relative phase between of driving fields
of the two. This gives us the prospect of creating and exploring chaotic motion
in quantum mechanical systems with further ease",http://arxiv.org/abs/2103.00521v1
"Perspectives and Prospects on Transformer Architecture for Cross-Modal
  Tasks with Language and Vision",2021-03-06T05:44:27Z,"Andrew Shin, Masato Ishii, Takuya Narihira","Transformer architectures have brought about fundamental changes to
computational linguistic field, which had been dominated by recurrent neural
networks for many years. Its success also implies drastic changes in
cross-modal tasks with language and vision, and many researchers have already
tackled the issue. In this paper, we review some of the most critical
milestones in the field, as well as overall trends on how transformer
architecture has been incorporated into visuolinguistic cross-modal tasks.
Furthermore, we discuss its current limitations and speculate upon some of the
prospects that we find imminent.",http://arxiv.org/abs/2103.04037v2
"Explaining and Improving BERT Performance on Lexical Semantic Change
  Detection",2021-03-12T13:29:30Z,"Severin Laicher, Sinan Kurtyigit, Dominik Schlechtweg, Jonas Kuhn, Sabine Schulte im Walde","Type- and token-based embedding architectures are still competing in lexical
semantic change detection. The recent success of type-based models in
SemEval-2020 Task 1 has raised the question why the success of token-based
models on a variety of other NLP tasks does not translate to our field. We
investigate the influence of a range of variables on clusterings of BERT
vectors and show that its low performance is largely due to orthographic
information on the target word, which is encoded even in the higher layers of
BERT representations. By reducing the influence of orthography we considerably
improve BERT's performance.",http://arxiv.org/abs/2103.07259v1
To H0 or not to H0?,2021-03-15T21:10:33Z,George Efstathiou,"This paper investigates whether changes to late time physics can resolve the
`Hubble tension'. It is argued that many of the claims in the literature
favouring such solutions are caused by a misunderstanding of how distance
ladder measurements actually work and, in particular, by the inappropriate use
of a distance ladder H0 prior. A dynamics-free inverse distance ladder shows
that changes to late time physics are strongly constrained observationally and
cannot resolve the discrepancy between the SH0ES data and the base LCDM
cosmology inferred from Planck. We propose a statistically rigorous scheme to
replace the use of H0 priors",http://arxiv.org/abs/2103.08723v3
"Block Length Choice for the Bootstrap of Dependent Panel Data -- a
  Comment on Choi and Shin (2020)",2021-03-22T13:07:33Z,"Lea Wegner, Martin Wendler","Choi and Shin (2020) have constructed a bootstrap-based test for
change-points in panels with temporal and and/or cross-sectional dependence.
They have compared their test to several other proposed tests. We demonstrate
that by an appropriate, data-adaptive choice of the block length, the
change-point test by Sharipov, Tewes, Wendler (2016) can at least cope with
mild temporal dependence, the size distortion of this test is not as severe as
claimed by Choi and Shin (2020).",http://arxiv.org/abs/2103.11805v1
"Stability of Large Amplitude Viscous Shock Wave for 1-D Isentropic
  Navier-Stokes System in the Half Space",2021-03-28T13:43:28Z,Lin Chang,"In this paper, the asymptotic-time behavior of solutions to an initial
boundary value problem in the half space for 1-D isentropic Navier-Stokes
system is investigated. It is shown that the viscous shock wave is stable for
an impermeable wall problem where the velocity is zero on the boundary provided
that the shock wave is initially far away from the boundary. Moreover, the
strength of shock wave could be arbitrarily large. This work essentially
improves the result of [A. Matsumura, M. Mei, Convergence to travelling fronts
of solutions of the p-system with viscosity in the presence of a boundary,
Arch. Ration. Mech. Anal., 146(1): 1-22, 1999], where the strength of shock
wave is sufficiently small.",http://arxiv.org/abs/2103.15133v1
An Improved and Extended Bayesian Synthetic Control,2021-03-30T10:48:14Z,Sean Pinkney,"An improved and extended Bayesian synthetic control model is presented,
expanding upon the latent factor model in Tuomaala 2019. The changes we make
include 1) standardization of the data prior to model fit - which improves
efficiency and generalization across different data sets; 2) adding time
varying covariates; 3) adding the ability to have multiple treated units; 4)
fitting the latent factors within the Bayesian model; and, 5) a sparsity
inducing prior to automatically tune the number of latent factors. We
demonstrate the similarity of estimates to two traditional synthetic control
studies in Abadie, Diamond, and Hainmueller 2010 and Abadie, Diamond, and
Hainmueller 2015 and extend to multiple target series with a new example of
estimating digital website visitation from changes in data collection due to
digital privacy laws.",http://arxiv.org/abs/2103.16244v1
Cosmic ray radiography of a human phantom,2021-06-03T01:55:58Z,"Christopher Morris, John Perry, F. E. Merrill","Cosmic ray muons, that reach the earth's surface, provide a natural source of
radiation that is used for radiography. In this paper, we show that radiography
using cosmic radiation background provides a method that can be used to monitor
bulk aspects of human anatomy. We describe a method that can be used to measure
changes in patients as a function of time by radiographing them using
cosmic-ray muons. This could provide hourly readouts of parameters such as lung
density with sufficient sensitivity to detect time changes in inflammation of
the lungs in, e.g., Covid patients.",http://arxiv.org/abs/2106.01542v1
"Large Changes of Atmospheric Mixing Angle $θ_{23}$ with Four Flavor
  Mixing from Planck Scale Effects",2021-06-12T07:50:28Z,"Bipin Singh Koranga, Vivek Kumar Nautiyal","We consider the effects of Planck scale on four flavour neutrino mixings. The
gravational interaction at $M_{x}=M_{\rm planck}$, we find that for degenerate
neurino mass order, the Planck scale effects changes the mixing angle
$\theta'_{23}$, $\theta'_{12}$ values and $\theta'_{13}$, $\theta'_{14}$,
$\theta'_{34}$, $\theta'_{24}$ are unchanged above the GUT scale. In this
paper, we study neutrino mixing in four flavor above the GUT scale.",http://arxiv.org/abs/2106.06709v1
Multi-spectral programmable absorbers,2021-06-13T08:00:47Z,"Yun Meng, Dan Li, Chong Zhang, Yang Wang, Robert E. Simpson, Yi Long","We designed and demonstrated a multi-spectral programmable perfect absorber
that exploits two different phase-change materials. This programmability is
possible by resonantly coupling two phase change materials, a Ge2Sb2Te5 layer
to vanadium dioxide nanoparticles (VO2 NPs). The perfect absorption is
attributed to the coalescence of gap plasmon modes excited between the NPs and
waveguide cavity-like modes excited between the film and the NPs. The
absorptance peak (>90%) can be tuned to four different infrared (IR)
wavelengths from 1906 to 2960 nm by heating the structure to different
temperatures. The perfect absorber is reconfigurable, lithography-free,
large-scale, polarization-insensitive omnidirectional. Our strategy opens a new
path for programmable infrared photonics.",http://arxiv.org/abs/2106.06940v1
Effects of Covid-19 Pandemic on Chinese Commodity Futures Markets,2021-06-17T05:12:15Z,Ahmet Goncu,"In this study, empirical moments and the cointegration for all the liquid
commodity futures traded in the Chinese futures markets are analyzed for the
periods before and after Covid-19, which is important for trading strategies
such as pairs trading. The results show that the positive change in the average
returns of the products such as soybean, corn, corn starch, and iron ore
futures are significantly stronger than other products in the post Covid-19
era, whereas the volatility increased most for silver, petroleum asphalt and
egg futures after the pandemic started. The number of cointegrated pairs are
reduced after the pandemic indicating the differentiation in returns due to the
structural changes caused in the demand and supply conditions across
commodities.",http://arxiv.org/abs/2106.09250v1
Software-Defined Networking for Data Centre Network Management: A Survey,2021-06-18T09:15:13Z,"Jonathan Sherwin, Cormac J. Sreenan","Data centres are growing in numbers and size, and their networks expanding to
carry larger amounts of traffic. The traffic profile is constantly varying,
particularly in cloud data centres where tenants arrive, leave, and may change
their resource requirements in between, and so the network configuration must
change at a commensurate rate. Software-Defined Networking - programmatic
control of network configuration - has been critical to meeting the demands of
modern data centre network management, and has been the subject of intense
focus by the research community, working in conjunction with industry. In this
survey, we review Software-Defined Networking research targeting the management
and operation of data centre networks.",http://arxiv.org/abs/2106.10014v1
Light Pollution Reduction in Nighttime Photography,2021-06-18T10:38:13Z,"Chang Liu, Xiaolin Wu","Nighttime photographers are often troubled by light pollution of unwanted
artificial lights. Artificial lights, after scattered by aerosols in the
atmosphere, can inundate the starlight and degrade the quality of nighttime
images, by reducing contrast and dynamic range and causing hazes. In this paper
we develop a physically-based light pollution reduction (LPR) algorithm that
can substantially alleviate the aforementioned degradations of perceptual
quality and restore the pristine state of night sky. The key to the success of
the proposed LPR algorithm is an inverse method to estimate the spatial
radiance distribution and spectral signature of ground artificial lights.
Extensive experiments are carried out to evaluate the efficacy and limitations
of the LPR algorithm.",http://arxiv.org/abs/2106.10046v1
"AutoTune: Improving End-to-end Performance and Resource Efficiency for
  Microservice Applications",2021-06-18T19:49:46Z,"Michael Alan Chang, Aurojit Panda, Hantao Wang, Yuancheng Tsai, Rahul Balakrishnan, Scott Shenker","Most large web-scale applications are now built by composing collections
(from a few up to 100s or 1000s) of microservices. Operators need to decide how
many resources are allocated to each microservice, and these allocations can
have a large impact on application performance. Manually determining
allocations that are both cost-efficient and meet performance requirements is
challenging, even for experienced operators. In this paper we present AutoTune,
an end-to-end tool that automatically minimizes resource utilization while
maintaining good application performance.",http://arxiv.org/abs/2106.10334v2
Lévy processes linked to the lower-incomplete gamma function,2021-06-23T07:16:22Z,"Luisa Beghin, Costantino Ricciuti","We start by defining a subordinator by means of the lower-incomplete gamma
function. It can be considered as an approximation of the stable subordinator,
easier to be handled thank to its finite activity. A tempered version is also
considered in order to overcome the drawback of infinite moments. Then, we
study L\'{e}vy processes time-changed by these subordinators, with particular
attention to the Brownian case. An approximation of the fractional derivative
(as well as of the fractional power of operators) arises from the analysis of
governing equations. Finally, we show that time-changing the fractional
Brownian motion gives a model of anomalous diffusion, which exhibits a
sub-diffusive behavior.",http://arxiv.org/abs/2106.12201v1
A change of variable for Dahlberg-Kenig-Pipher operators,2021-06-24T16:27:05Z,Joseph Feneuil,"In the present article, we purpose a method to deal with
Dahlberg-Kenig-Pipher (DPK) operators in boundary value problems on the upper
half plane.
  We give a nice subclass of the weak DKP operators that generates the full
class of weak DKP operators under bi-Lipschitz changes of variable on $\mathbb
R^n_+$ that fixe the boundary $\mathbb R^{n-1}$. Therefore, if one wants to
prove a property on DKP operators which is stable by bi-Lipschitz
transformations, one can directly assume that the operator belongs to the
subclass. Our method gives an alternative proof to some past results and
self-improves others beyond the existing literature.",http://arxiv.org/abs/2106.13152v2
"Energy security: key concepts, components, and change of the paradigm",2021-06-30T15:15:30Z,"Julia Edigareva, Tatiana Khimich, Oleg Antonov, Jesus Gonzalez","The authors of the study conduct a legal analysis of the concept of energy
security. Energy is vital for sustainable development, and sustainability is
not only at the heart of development, but also economic, environmental, social
and military policies. To ensure the sustainability of the policy, 'security'
seems to be a mandatory goal to achieve. The article critically assesses the
change in the energy paradigm.",http://arxiv.org/abs/2106.16117v1
TabPert: An Effective Platform for Tabular Perturbation,2021-08-02T02:37:48Z,"Nupur Jain, Vivek Gupta, Anshul Rai, Gaurav Kumar","To truly grasp reasoning ability, a Natural Language Inference model should
be evaluated on counterfactual data. TabPert facilitates this by assisting in
the generation of such counterfactual data for assessing model tabular
reasoning issues. TabPert allows a user to update a table, change its
associated hypotheses, change their labels, and highlight rows that are
important for hypothesis classification. TabPert also captures information
about the techniques used to automatically produce the table, as well as the
strategies employed to generate the challenging hypotheses. These
counterfactual tables and hypotheses, as well as the metadata, can then be used
to explore an existing model's shortcomings methodically and quantitatively.",http://arxiv.org/abs/2108.00603v1
"Impact of Dietary Habits and Opinionated Lifestyle during COVID-19
  Pandemic : A Case Study on Engineering Students",2021-07-30T14:50:01Z,"Arpitha A Deshpande, Aadrika A, Rajeshwari K, Preetha S","COVID-19 pandemic has introduced a new lifestyle due to lockdown. The impact
was on food habits, working hours, and sleeping patterns. The goal of this
study is to detect lifestyle changes caused by confinement during the COVID-19
pandemic, such as dietary habits, physical activities, and to explore changes
in the body weight. A structured questionnaire was used in the study to collect
anthropometric data; daily consumption of particular foods, water intake, food
frequency, and number of meals/day. The data is presented in a graph
illustration to show health , lifestyle trends and the friendship among
engineering students.",http://arxiv.org/abs/2108.04817v1
Random Time Dynamical Systems,2021-08-11T15:00:05Z,"R. Capuani, L. Di Persio, Y. Kondratiev, M. Ricciardi, J. L. da Silva","In this paper, we introduce the concept of random time changes in dynamical
systems. The sub- ordination principle may be applied to study the long time
behavior of the random time systems. We show, under certain assumptions on the
class of random time, that the subordinated system exhibits a slower time decay
which is determined by the random time characteristics. Along the path asymp-
totic, a random time change is reflected in the new velocity of the resulting
dynamics.",http://arxiv.org/abs/2108.05261v1
PixelSynth: Generating a 3D-Consistent Experience from a Single Image,2021-08-12T17:59:31Z,"Chris Rockwell, David F. Fouhey, Justin Johnson","Recent advancements in differentiable rendering and 3D reasoning have driven
exciting results in novel view synthesis from a single image. Despite realistic
results, methods are limited to relatively small view change. In order to
synthesize immersive scenes, models must also be able to extrapolate. We
present an approach that fuses 3D reasoning with autoregressive modeling to
outpaint large view changes in a 3D-consistent manner, enabling scene
synthesis. We demonstrate considerable improvement in single image large-angle
view synthesis results compared to a variety of methods and possible variants
across simulated and real datasets. In addition, we show increased 3D
consistency compared to alternative accumulation methods. Project website:
https://crockwell.github.io/pixelsynth/",http://arxiv.org/abs/2108.05892v1
Nucleation of Grain Boundary Phases,2021-08-15T07:24:13Z,"Ian S. Winter, Robert E. Rudd, Tomas Oppelstrup, Timofey Frolov","We derive a theory that describes homogeneous nucleation of grain boundary
(GB) phases. Our analysis takes account of the energy resulting from the GB
phase junction, the line defect separating two different GB structures, which
is necessarily a dislocation as well as an elastic line force due to the jump
in GB stresses. The theory provides analytic forms for the elastic interactions
and the core energy of the GB phase junction that, along with the change in GB
energy, determine the nucleation barrier. We apply the resulting nucleation
model to simulations of GB phase transformations in tungsten. Our theory
explains why under certain conditions GBs cannot spontaneously change their
structure even to a lower energy state.",http://arxiv.org/abs/2108.06675v1
"A New Asymmetric Copula with Reversible Correlations and Its Application
  to the EU Sovereign Debt Crisis",2021-08-18T23:26:51Z,"Masahito Kobayashi, Jinghui Chen","This paper proposes a novel asymmetric copula based upon bivariate split
normal distribution. This copula can change correlation signs of its upper and
lower tails of distribution independently. As an application, it is shown by
the rolling maximum likelihood estimation that the EU periphery countries
changed sign of the lower tail correlation coefficient from negative to
positive after the sovereign debt crisis started. In contrast, Germany had
negative stock-bond correlation before and after the crisis.",http://arxiv.org/abs/2108.09278v1
On the Topology of J-Groups,2021-08-22T15:28:09Z,Rafael Dahmen,"We introduce the concept of a topological J-group and determine for many
important examples of topological groups if they are topological J-groups or
not.
  Besides other results, we show that the underlying topological space of a
pathwise connected topological J-group is weakly contractible which is a strong
and unexpected obstruction that depends only on the homotopy type of the space.",http://arxiv.org/abs/2108.09755v3
An example of a non-amenable dynamical system which is boundary amenable,2021-08-31T15:54:12Z,"Jacopo Bassi, Florin Radulescu","It is shown that the action of ${\rm SL}(3,\mathbb{Z})$ on the Stone-\u{C}ech
boundary of ${\rm SL}(3,\mathbb{Z}) / {\rm SL}(2,\mathbb{Z}) $ is amenable.
This confirms a prediction by Bekka and Kalantar.",http://arxiv.org/abs/2108.13936v3
"Truncated Euler-Maruyama method for time-changed stochastic differential
  equations with super-linear state variables and Hölder's continuous time
  variables",2021-10-06T14:45:33Z,"Xiaotong Li, Wei Liu, Tianjiao Tang","An explicit numerical method is developed for a class of non-autonomous
time-changed stochastic differential equations, whose coefficients obey
H\""older's continuity in terms of the time variables and are allowed to grow
super-linearly in terms of the state variables. The strong convergence of the
method in the finite time interval is proved and the convergence rate is
obtained. Numerical simulations are provided.",http://arxiv.org/abs/2110.02819v2
DCT: Dynamic Compressive Transformer for Modeling Unbounded Sequence,2021-10-10T15:21:19Z,"Kai-Po Chang, Wei-Yun Ma","In this paper, we propose Dynamic Compressive Transformer (DCT), a
transformer-based framework for modeling the unbounded sequence. In contrast to
the previous baselines which append every sentence representation to memory,
conditionally selecting and appending them is a more reasonable solution to
deal with unlimited long sequences. Our model uses a policy that determines
whether the sequence should be kept in memory with a compressed state or
discarded during the training process. With the benefits of retaining
semantically meaningful sentence information in the memory system, our
experiment results on Enwik8 benchmark show that DCT outperforms the previous
state-of-the-art (SOTA) model.",http://arxiv.org/abs/2110.04821v1
"Local regularity near boundary for the Stokes and Navier-Stokes
  equations",2021-10-14T05:50:54Z,"Tongkeun Chang, Kyungkeun Kang","We are concerned with local regularity of the solutions for the Stokes and
Navier-Stokes equations near boundary. Firstly, we construct a bounded solution
but its normal derivatives are singular in any $L^p$ with $1<p$ locally near
boundary. On the other hand, we present criteria of solutions of the Stokes
equations near boundary to imply that the gradients of solutions are bounded
(in fact, even further H\""{o}lder continuous). Finally, we provide examples of
solutions whose local regularity near boundary is optimal.",http://arxiv.org/abs/2110.07162v2
Stem and topological entropy on Cayley trees,2021-10-18T01:04:11Z,"Jung-Chao Ban, Chih-Hung Chang, Yu-Liang Wu, Yu-Ying Wu","We consider the existence of the topological entropy of shift spaces on a
finitely generated semigroup whose Cayley graph is a tree. The considered
semigroups include free groups. On the other hand, the notion of stem entropy
is introduced. For shift spaces on a strict free semigroup, the stem entropy
coincides with the topological entropy. We reveal a sufficient condition for
the existence of the stem entropy of shift spaces on a semigroup. Furthermore,
we demonstrate that the topological entropy exists in many cases and is
identical to the stem entropy.",http://arxiv.org/abs/2110.08960v1
"TAPL: Dynamic Part-based Visual Tracking via Attention-guided Part
  Localization",2021-10-25T15:05:43Z,"Wei han, Hantao Huang, Xiaoxi Yu","Holistic object representation-based trackers suffer from performance drop
under large appearance change such as deformation and occlusion. In this work,
we propose a dynamic part-based tracker and constantly update the target part
representation to adapt to object appearance change. Moreover, we design an
attention-guided part localization network to directly predict the target part
locations, and determine the final bounding box with the distribution of target
parts. Our proposed tracker achieves promising results on various benchmarks:
VOT2018, OTB100 and GOT-10k",http://arxiv.org/abs/2110.13027v1
"Quantify Change of Inertia and Its Distribution in High Renewable Power
  Grids Using PMU",2021-01-12T16:48:10Z,Shutang You,"This paper proposed an approach to identify the change of inertia
distribution in high renewable power systems. Using the footprints of
electromechanical wave propagation at the distribution level, this approach
provides a new and non-invasive way to aware the system inertia distribution
for primary frequency response. Actual measurements and high renewable dynamic
models validated effectiveness of the approach.",http://arxiv.org/abs/2101.04593v2
Bernoulli hyper-edge percolation on Zd,2021-01-15T12:22:31Z,Yinshan Chang,"We consider Bernoulli hyper-edge percolation on $\mathbb{Z}^d$. This model is
a generalization of Bernoulli bond percolation. An edge connects exactly two
vertices and a hyper-edge connects more than two vertices. As in the classical
Bernoulli bond percolation, we open hyper-edges independently in a homogeneous
manner with certain probabilities parameterized by a parameter $u\in[0,1]$. We
discuss conditions for non-trivial phase transitions when $u$ varies. We
discuss the conditions for the uniqueness of the infinite cluster. Also, we
provide conditions under which the Grimmett-Marstrand type theorem holds in the
supercritical regime.",http://arxiv.org/abs/2101.06082v2
"On a conjecture of Gross, Mansour and Tucker",2021-01-22T20:25:18Z,"Sergei Chmutov, Fabien Vignes-Tourneret","Partial duality is a duality of ribbon graphs relative to a subset of their
edges generalizing the classical Euler-Poincare duality. This operation often
changes the genus. Recently J.L.Gross, T.Mansour, and T.W.Tucker formulated a
conjecture that for any ribbon graph different from plane trees and their
partial duals, there is a subset of edges partial duality relative to which
does change the genus. A family of counterexamples was found by Qi Yan and
Xian'an Jin. In this note we prove that essentially these are the only
counterexamples.",http://arxiv.org/abs/2101.09319v2
Conditional Action and imperfect Erasure of Qubits,2021-01-26T10:32:23Z,Heinz-Jürgen Schmidt,"We consider state changes in quantum theory due to ""conditional action"" and
relate these to the discussion of entropy decrease due to interventions of
""intelligent beings"" and the principles of Szilard and Landauer/Bennett. The
mathematical theory of conditional actions is a special case of the theory of
""instruments"" which describes changes of state due to general measurements and
will therefore be briefly outlined in the present paper. As a detailed example
we consider the imperfect erasure of a qubit that can also be viewed as a
conditional action and will be realized by the coupling of a spin to another
small spin system in its ground state.",http://arxiv.org/abs/2101.10690v1
Vertical magnetic field on boundary of sunspot umbra,2021-01-27T20:15:07Z,"V. Efremov, L. Parfinenko, A. Soloviev","12 stable single sunspots were investigated in two aspects. The outer
boundaries of the sunspots umbra were determined by an independent mathematical
method and the vertical component of the magnetic field at these boundaries was
found. We analyzed data from the SDO station using the segments of the
continuum and magnetic field. It is shown that in a wide range of sunspot
fields, the field average along the contour changes weakly, while the vertical
component of the magnetic field itself, in a particular spot, changes
significantly along the defined contour which reflects the fibrous structure of
the penumbral field.",http://arxiv.org/abs/2101.11675v1
"The Behavioral Economics of Intrapersonal Conflict: A Critical
  Assessment",2021-01-29T11:28:53Z,"Sebastian Krügel, Matthias Uhl","Preferences often change -- even in short time intervals -- due to either the
mere passage of time (present-biased preferences) or changes in environmental
conditions (state-dependent preferences). On the basis of the empirical
findings in the context of state-dependent preferences, we critically discuss
the Aristotelian view of unitary decision makers in economics and urge a more
Heraclitean perspective on human decision-making. We illustrate that the
conceptualization of preferences as present-biased or state-dependent has very
different normative implications under the Aristotelian view, although both
concepts are empirically hard to distinguish. This is highly problematic, as it
renders almost any paternalistic intervention justifiable.",http://arxiv.org/abs/2101.12526v1
"Increasing the price of a university degree does not significantly
  affect enrolment if income contingent loans are available: evidence from HECS
  in Australia",2021-02-08T00:50:45Z,Fabio Italo Martinenghi,"I provide evidence that, when income-contingent loans are available, student
enrolment in university courses is not significantly affected by large
increases in the price of those courses. I use publicly available domestic
enrolment data from Australia. I study whether large increases in the price of
higher education for selected disciplines in Australia in 2009 and in 2012 was
associated with changes in their enrolment growth. I find that large increases
in the price of a course did not lead to significant changes in their enrolment
growth for that course.",http://arxiv.org/abs/2102.03956v1
"Self-organization and shape change by active polarization in nematic
  droplets",2021-02-15T10:25:11Z,"Fabian Jan Schwarzendahl, Pierre Ronceray, Kimberly L. Weirich, Kinjal Dasbiswas","Active forces occurring within cells can drive crucial biological processes
that involve spontaneous organization and shape change, such as cell division.
Motivated by recent in vitro experiments of nematic droplets of cytoskeletal
filaments and motors that self-organize and divide, we present a minimal
hydrodynamic model that combines the nonequilibrium kinetics of motor-filament
interactions with equilibrium nematic phase separation. The motors organize
within droplets and structure filaments into polarized aster defects. At large
motor activity, they can even deform or divide the droplet, or form multi-aster
chains of droplets. Our predicted phase diagram recapitulates these
experimentally observed shapes.",http://arxiv.org/abs/2102.07442v1
A Projection Algorithm for the Unitary Weights,2021-02-19T17:33:17Z,Hao-Yuan Chang,"Unitary neural networks are promising alternatives for solving the exploding
and vanishing activation/gradient problem without the need for explicit
normalization that reduces the inference speed. However, they often require
longer training time due to the additional unitary constraints on their weight
matrices. Here we show a novel algorithm using a backpropagation technique with
Lie algebra for computing approximated unitary weights from their pre-trained,
non-unitary counterparts. The unitary networks initialized with these
approximations can reach the desired accuracies much faster, mitigating their
training time penalties while maintaining inference speedups. Our approach will
be instrumental in the adaptation of unitary networks, especially for those
neural architectures where pre-trained weights are freely available.",http://arxiv.org/abs/2102.10052v1
"Retrain or not retrain: Conformal test martingales for change-point
  detection",2021-02-20T20:39:05Z,"Vladimir Vovk, Ivan Petej, Ilia Nouretdinov, Ernst Ahlberg, Lars Carlsson, Alex Gammerman","We argue for supplementing the process of training a prediction algorithm by
setting up a scheme for detecting the moment when the distribution of the data
changes and the algorithm needs to be retrained. Our proposed schemes are based
on exchangeability martingales, i.e., processes that are martingales under any
exchangeable distribution for the data. Our method, based on conformal
prediction, is general and can be applied on top of any modern prediction
algorithm. Its validity is guaranteed, and in this paper we make first steps in
exploring its efficiency.",http://arxiv.org/abs/2102.10439v1
"Does Bankruptcy Protection Affect Asset Prices? Evidence from changes in
  Homestead Exemptions",2021-02-25T20:32:45Z,"Yildiray Yildirim, Albert Alex Zevelev","Does the ability to protect an asset from unsecured creditors affect its
price? This paper identifies the impact of bankruptcy protection on house
prices using 139 changes in homestead exemptions. Large increases in the
homestead exemption raised house prices 3% before 2005. Smaller exemption
increases, to adjust for inflation, did not affect house prices. The effect
disappeared after BAPCPA, a 2005 federal law designed to prevent bankruptcy
abuse. The effect was bigger in inelastic locations.",http://arxiv.org/abs/2102.13157v1
"Some considerations about reviewing and open-access in scientific
  publishing",2021-04-05T06:50:52Z,"Paolo Politi, Giuseppe Gaeta, Satya N. Majumdar, Antonio Politi, Stefano Ruffo","Scientific research changed profoundly over the last 30 years, in all its
aspects. Scientific publishing has changed as well, mainly because of the
strong increased number of submitted papers and because of the appearance of
Open Access journals and publishers. We propose some reflections on these
issues.",http://arxiv.org/abs/2104.01794v2
"On The Gap Between Software Maintenance Theory and Practitioners'
  Approaches",2021-04-08T15:08:10Z,"Mívian Ferreira, Mariza Bigonha, Kecia A. M. Ferreira","The way practitioners perform maintenance tasks in practice is little known
by researchers. In turn, practitioners are not always up to date with the
proposals provided by the research community. This work investigates the gap
between software maintenance techniques proposed by the research community and
the software maintenance practice. We carried out a survey with 112
practitioners from 92 companies and 12 countries. We concentrate on analyzing
if and how practitioners understand and apply the following subjects: bad
smells, refactoring, software metrics, and change impact analysis. This study
shows that there is a large gap between research approaches and industry
practice in those subjects, especially in change impact analysis and software
metrics.",http://arxiv.org/abs/2104.03824v1
Image-based Virtual Fitting Room,2021-04-08T22:53:08Z,"Zhiling Huang, Junwen Bu, Jie Chen","Virtual fitting room is a challenging task yet useful feature for e-commerce
platforms and fashion designers. Existing works can only detect very few types
of fashion items. Besides they did poorly in changing the texture and style of
the selected fashion items. In this project, we propose a novel approach to
address this problem. We firstly used Mask R-CNN to find the regions of
different fashion items, and secondly used Neural Style Transfer to change the
style of the selected fashion items. The dataset we used is composed of images
from PaperDoll dataset and annotations provided by eBay's ModaNet. We trained 8
models and our best model massively outperformed baseline models both
quantitatively and qualitatively, with 68.72% mAP, 0.2% ASDR.",http://arxiv.org/abs/2104.04104v1
"Symmetry properties of sign-changing solutions to nonlinear parabolic
  equations in unbounded domains",2021-04-09T18:33:06Z,"Juraj Földes, Alberto Saldaña, Tobias Weth","We study the asymptotic (in time) behavior of positive and sign-changing
solutions to nonlinear parabolic problems in the whole space or in the exterior
of a ball with Dirichlet boundary conditions. We show that, under suitable
regularity and stability assumptions, solutions are asymptotically (in time)
foliated Schwarz symmetric, i.e., all elements in the associated omega-limit
set are axially symmetric with respect to a common axis passing through the
origin and are nonincreasing in the polar angle. We also obtain symmetry
results for solutions of H\'enon-type problems, for equilibria (i.e. for
solutions of the corresponding elliptic problem), and for time periodic
solutions.",http://arxiv.org/abs/2104.04555v1
Data-driven Optimization Model for Global Covid-19 Intervention Plans,2021-04-16T02:56:36Z,"Chang Liu, Akshay Budhkar","In the wake of COVID-19, every government huddles to find the best
interventions that will reduce the number of infection cases while minimizing
the economic impact. However, with many intervention policies available, how
should one decide which policy is the best course of action? In this work, we
describe an integer programming approach to prescribe intervention plans that
optimizes for both the minimal number of daily new cases and economic impact.
We present a method to estimate the impact of intervention plans on the number
of cases based on historical data. Finally, we demonstrate visualizations and
summaries of our empirical analyses on the performance of our model with
varying parameters compared to two sets of heuristics.",http://arxiv.org/abs/2104.07865v1
Costlier switching strengthens competition even without advertising,2021-04-18T19:02:30Z,Sander Heinsalu,"Consumers only discover at the first seller which product best fits their
needs, then check its price online, then decide on buying. Switching sellers is
costly. Equilibrium prices fall in the switching cost, eventually to the
monopoly level, despite the exit of lower-value consumers when changing sellers
becomes costlier. More expensive switching makes some buyers exit the market,
leaving fewer inframarginal buyers to the sellers. Marginal buyers may change
in either direction, so for a range of parameters, all firms cut prices.",http://arxiv.org/abs/2104.08934v1
"NewsEdits: A Dataset of Revision Histories for News Articles (Technical
  Report: Data Processing)",2021-04-19T21:15:30Z,"Alexander Spangher, Jonathan May","News article revision histories have the potential to give us novel insights
across varied fields of linguistics and social sciences. In this work, we
present, to our knowledge, the first publicly available dataset of news article
revision histories, or NewsEdits.
  Our dataset is multilingual; it contains 1,278,804 articles with 4,609,430
versions from over 22 English- and French-language newspaper sources based in
three countries. Across version pairs, we count 10.9 million added sentences;
8.9 million changed sentences and 6.8 million removed sentences. Within the
changed sentences, we derive 72 million atomic edits. NewsEdits is, to our
knowledge, the largest corpus of revision histories of any domain.",http://arxiv.org/abs/2104.09647v2
"Thickness Dependence of Magneto-transport Properties in Tungsten
  Ditelluride",2021-04-29T16:28:59Z,"Xurui Zhang, Vivek Kakani, John M. Woods, Judy J. Cha, Xiaoyan Shi","We investigate the electronic structure of tungsten ditelluride (WTe$_2$)
flakes with different thicknesses in magneto-transport studies. The
temperature-dependent resistance and magnetoresistance (MR) measurements both
confirm the breaking of carrier balance induced by thickness reduction, which
suppresses the `turn-on' behavior and large positive MR. The Shubnikov-de-Haas
oscillation studies further confirm the thickness-dependent change of
electronic structure of WTe$_2$ and reveal a possible temperature-sensitive
electronic structure change. Finally, we report the thickness-dependent
anisotropy of Fermi surface, which reveals that multi-layer WTe$_2$ is an
electronic 3D material and the anisotropy decreases as thickness decreases.",http://arxiv.org/abs/2104.14464v1
Adaptive Realized Hyperbolic GARCH Process: Stability and Estimation,2021-04-30T01:30:53Z,"El Hadji Mamadou Sall, El Hadji Deme, Abdou Kâ Diongue","In this paper, we propose an Adaptive Realized Hyperbolic GARCH (A-Realized
HYGARCH) process to model the long memory of high-frequency time series with
possible structural breaks. The structural change is modeled by allowing the
intercept to follow the smooth and flexible function form introduced by Gallant
(1984). In addition, stability conditions of the process are investigated. A
Monte Carlo study is investigated in order to illustrate the performance of the
A-Realized HYGARCH process compared to the Realized HYGARCH with or without
structural change.",http://arxiv.org/abs/2104.14714v1
"Quantitative Evaluation of Alternative Translations in a Corpus of
  Highly Dissimilar Finnish Paraphrases",2021-05-06T07:22:16Z,"Li-Hsin Chang, Sampo Pyysalo, Jenna Kanerva, Filip Ginter","In this paper, we present a quantitative evaluation of differences between
alternative translations in a large recently released Finnish paraphrase corpus
focusing in particular on non-trivial variation in translation. We combine a
series of automatic steps detecting systematic variation with manual analysis
to reveal regularities and identify categories of translation differences. We
find the paraphrase corpus to contain highly non-trivial translation variants
difficult to recognize through automatic approaches.",http://arxiv.org/abs/2105.02477v1
"Contribution of internal degree of freedom of soft molecules to Soret
  effect",2021-05-07T04:22:19Z,"Takeaki Araki, Chikakiyo Natsumi","We studied the Soret effect in binary dimer-monomer mixtures using
non-equilibrium molecular dynamics simulations and investigated the pure
contribution of the internal degree of freedom of flexible molecules to the
Soret effect. We observed that the thermal diffusion factor tends to decrease
and change its sign as the molecules become softer. We proposed two possible
mechanisms of our observations: change of the molecule structures with the
temperature, causing bulkier molecules to migrate to the hotter region;
asymmetry of the restitution between rigid and flexible molecules, due to which
flexible molecules show larger restitution when placed at the hotter region.",http://arxiv.org/abs/2105.03060v1
"Branch cuts: writing, editing, and ramified complexities",2021-05-07T17:09:47Z,Ursula Whitcher,"As I was preparing my tenure application, the University of Wisconsin Board
of Regents voted to redefine tenure, removing many of the institution's
historical protections. Reevaluating my career priorities in light of these
changes and a resurgent two-body problem, I recognized that my fundamental goal
was communicating mathematical ideas. I found a new role as an editor at
Mathematical Reviews, part of the American Mathematical Society. To my
surprise, thinking more about my identity as a writer and editor also changed
my perspective on my own sexuality and gender identity, inspiring new
approaches to leadership.",http://arxiv.org/abs/2105.03394v2
"Modeling change in public sentiment with nonlocal reaction-diffusion
  equations",2021-05-09T12:22:45Z,Joseph L. Shomberg,"This is a brief ""proof of concept"" article that shows nonlocal diffusion is
well suited to the study of pattern formation and the particular application of
public sentiment. We use a nonlocal reaction-diffusion equation to model the
evolution of public sentiment in a population that interacts with other
individuals. We employ a pseudo-random convolution kernel as a symmetric matrix
of lognormally distributed values. This kernel models the influence of
individuals when interacting with others. Change in sentiment emerges and may
converge to a polarized state. Other more complicated states occur whereby a
mixed polarization emerges.",http://arxiv.org/abs/2105.03920v3
"Overcoming Complexity Catastrophe: An Algorithm for Beneficial
  Far-Reaching Adaptation under High Complexity",2021-05-10T12:46:26Z,"Sasanka Sekhar Chanda, Sai Yayavaram","In his seminal work with NK algorithms, Kauffman noted that fitness outcomes
from algorithms navigating an NK landscape show a sharp decline at high
complexity arising from pervasive interdependence among problem dimensions.
This phenomenon - where complexity effects dominate (Darwinian) adaptation
efforts - is called complexity catastrophe. We present an algorithm -
incremental change taking turns (ICTT) - that finds distant configurations
having fitness superior to that reported in extant research, under high
complexity. Thus, complexity catastrophe is not inevitable: a series of
incremental changes can lead to excellent outcomes.",http://arxiv.org/abs/2105.04311v1
"An integral equation for the identification of causal effects in
  nonlinear models",2021-05-11T18:51:03Z,Wing Hung Wong,"When the causal relationship between X and Y is specified by a structural
equation, the causal effect of X on Y is the expected rate of change of Y with
respect to changes in X, when all other variables are kept fixed. This causal
effect is not identifiable from the distribution of (X,Y). We give conditions
under which this causal effect is identified as the solution of an integral
equation based on the distributions of (X,Z) and (Y,Z), where Z is an
instrumental variable.",http://arxiv.org/abs/2105.05299v1
"Measurement of the probe Stark shift of the 87Sr optical lattice clock
  using the frequency modulation spectroscopy",2021-05-21T15:15:20Z,"Qinfang Xu, Xiaotong Lu, Jingjing Xia, Yebing Wang, Hong Chang","With the uncertainty of the optical clocks improving to the order of 10-18,
the probe light used to detect the clock transition has demonstrated
nonnegligible Stark shift, provoking to precisely evaluate this shift. Here, we
demonstrate a frequency modulation technique to realize a large measurement
lever arm of the probe Stark shift with no cost of the measurement accuracy of
the interleaved stabilization method. This frequency-modulated spectrum is
theoretical described and experimental verified. The probe Stark shift
coefficient of the 87Sr optical lattice clock is experimentally determined as
-(45.97+/-3.51) Hz/(W/cm2) using this frequency modulation spectroscopy.",http://arxiv.org/abs/2105.10401v1
Filament structure of random waves,2021-05-24T04:19:39Z,Melissa Tacy,"We investigate the small scale equidistribution properties of random waves in
$\mathbb{R}^{n}$. Numerical evidence suggests that such objects display a fine
scale filament structure. We show that the X-ray along any line segment is
uniformly equidistributed so any limiting behaviour must be weaker than $L^{2}$
scaring. On the other hand, we show that at Planck scale in phase space there
are (with high probability) logarithmic fluctuations above what would be
expected given equidistribution. Taken together these results suggest that the
filament structure may be a configuration space echo of the phase space
concentrations.",http://arxiv.org/abs/2105.11086v3
Empowering Differential Networks Using Bayesian Analysis,2021-05-28T04:46:49Z,"Jarod Smith, Mohammad Arashi, Andriette Bekker","Differential networks (DN) are important tools for modeling the changes in
conditional dependencies between multiple samples. A Bayesian approach for
estimating DNs, from the classical viewpoint, is introduced with a
computationally efficient threshold selection for graphical model
determination. The algorithm separately estimates the precision matrices of the
DN using the Bayesian adaptive graphical lasso procedure. Synthetic experiments
illustrate that the Bayesian DN performs exceptionally well in numerical
accuracy and graphical structure determination in comparison to
state-of-the-art methods. The proposed method is applied to South African
COVID-$19$ data to investigate the change in DN structure between various
phases of the pandemic.",http://arxiv.org/abs/2105.13584v1
"Enhanced diffusion in soft-walled channels with a periodically varying
  curvature",2021-07-05T13:34:31Z,"Thomas Gray, Claudio Castelnovo, Ee Hou Yong","In one-dimension, the diffusion of particles along a line is slowed by the
addition of energy barriers. The same is true in two-dimensions, provided that
the confining channel in which the particles move doesn't change shape.
However, if the shape changes then this is no longer necessarily true; adding
energy barriers can enhance the rate of diffusion, and even restore free
diffusion. We explore these effects for a channel with a sinusoidally varying
curvature.",http://arxiv.org/abs/2107.02014v1
"Origin of nonlinear magnetoelectric response in rare-earth orthoferrite
  perovskite oxides",2021-07-07T13:58:40Z,"Alireza Sasani, Jorge Iñiguez, Eric Bousquet","We report a theoretical study of the non-linear magnetoelectric response of
GdFeO$_3$ through an analytical approach combined with a Heisenberg model which
is fitted against first-principles calculations. Our theory reproduces the
non-linear change of polarization under applied magnetic field reported
experimentally such that it allows to analyze the origin of the large responses
in the different directions. We show that the non-linear character of the
response in these materials originates from the fact that the antiferromagnetic
order of Gd atoms changes non-linearly with respect to the applied magnetic
field. Our model can be generalized to other materials in which the
antiferromagnetic ordering breaks inversion symmetry.",http://arxiv.org/abs/2107.03228v1
"The two-qubit singlet/triplet measurement is universal for quantum
  computing given only maximally-mixed initial states",2021-07-07T14:10:26Z,"Terry Rudolph, Shashank Soyuz Virmani","We prove the STP=BQP conjecture of Freedman, Hastings and Shokrian-Zini [1],
namely that the two-qubit singlet/triplet measurement is quantum
computationally universal given only an initial ensemble of maximally mixed
single qubits. This provides a method for quantum computing that is fully
rotationally symmetric (i.e. reference frame independent), using primitives
that are both physically very-accessible and provably the simplest possible.",http://arxiv.org/abs/2107.03239v3
"Generalization of the Change of Variables Formula with Applications to
  Residual Flows",2021-07-09T10:31:32Z,"Niklas Koenen, Marvin N. Wright, Peter Maaß, Jens Behrmann","Normalizing flows leverage the Change of Variables Formula (CVF) to define
flexible density models. Yet, the requirement of smooth transformations
(diffeomorphisms) in the CVF poses a significant challenge in the construction
of these models. To enlarge the design space of flows, we introduce
$\mathcal{L}$-diffeomorphisms as generalized transformations which may violate
these requirements on zero Lebesgue-measure sets. This relaxation allows e.g.
the use of non-smooth activation functions such as ReLU. Finally, we apply the
obtained results to planar, radial, and contractive residual flows.",http://arxiv.org/abs/2107.04346v1
Stabilizing Neural Control Using Self-Learned Almost Lyapunov Critics,2021-07-11T08:01:07Z,"Ya-Chien Chang, Sicun Gao","The lack of stability guarantee restricts the practical use of learning-based
methods in core control problems in robotics. We develop new methods for
learning neural control policies and neural Lyapunov critic functions in the
model-free reinforcement learning (RL) setting. We use sample-based approaches
and the Almost Lyapunov function conditions to estimate the region of
attraction and invariance properties through the learned Lyapunov critic
functions. The methods enhance stability of neural controllers for various
nonlinear systems including automobile and quadrotor control.",http://arxiv.org/abs/2107.04989v1
Density of compressible types and some consequences,2021-07-12T05:14:08Z,"Martin Bays, Itay Kaplan, Pierre Simon","We study compressible types in the context of (local and global) NIP. By
extending a result in machine learning theory (the existence of a bound on the
recursive teaching dimension), we prove density of compressible types. Using
this, we obtain explicit uniform honest definitions for NIP formulas (answering
a question of Eshel and the second author), and build compressible models in
countable NIP theories.",http://arxiv.org/abs/2107.05197v3
"Solutions of the Dirac equation in one-dimensional variable width
  potential well",2021-06-26T06:26:16Z,Qiuyu Shan,"The Fermi acceleration mechanism is a significant source of cosmic rays. When
the width of a potential well changes over time, the velocity of particles
within the well also changes. For quantum systems, such dynamics should be
described by the Schr\""odinger, Klein-Gordon, and Dirac equations. Previous
studies have solved the Schr\""odinger and Klein-Gordon equations under these
conditions, but no research has addressed the Dirac equation for
spin-$\frac{1}{2}$ particles like electrons. This paper investigates the
solutions of the Dirac equation in a dynamically varying potential well and
demonstrates that Dirac particles can exhibit complex-valued momentum states
via the Fermi acceleration mechanism, enabling Tachyon-like states preparation.",http://arxiv.org/abs/2107.05361v6
The Dynamic Complexity of Acyclic Hypergraph Homomorphisms,2021-07-13T14:21:30Z,"Nils Vortmeier, Ioannis Kokkinis","Finding a homomorphism from some hypergraph $\mathcal{Q}$ (or some relational
structure) to another hypergraph $\mathcal{D}$ is a fundamental problem in
computer science. We show that an answer to this problem can be maintained
under single-edge changes of $\mathcal{Q}$, as long as it stays acyclic, in the
DynFO framework of Patnaik and Immerman that uses updates expressed in
first-order logic. If additionally also changes of $\mathcal{D}$ are allowed,
we show that it is unlikely that existence of homomorphisms can be maintained
in DynFO.",http://arxiv.org/abs/2107.06121v1
"On a parametrized difference equation connecting chaotic and integrable
  mappings",2021-07-17T11:40:48Z,"Tomoko Nagai, Atsushi Nagai, Hiroko Yamaki, Kana Yanuma","We present a new difference equation with two parameters c in [0,1] and A in
[1,4]. This equation is equivalent to the logistic mapping if c=1 and the
Morishita mapping if c=0, which are the well-known chaotic and integrable
mappings, respectively. We first consider the case A=4 and investigate the time
evolution by changing the parameter c in [0,1]. We next change both two
parameters A in [3,4] and c in [0,1] and present the corresponding 3D
bifurcation diagram.",http://arxiv.org/abs/2107.08224v1
"Diffusion-convection reaction equations with sign-changing diffusivity
  and bistable reaction term",2021-07-22T09:03:53Z,"Diego Berti, Andrea Corli, Luisa Malaguti","We consider a reaction-diffusion equation with a convection term in one space
variable, where the diffusion changes sign from the positive to the negative
and the reaction term is bistable. We study the existence of wavefront
solutions, their uniqueness and regularity. The presence of convection reveals
several new features of wavefronts: according to the mutual positions of the
diffusivity and reaction, profiles can occur either for a single value of the
speed or for a bounded interval of such values; uniqueness (up to shifts) is
lost; moreover, plateaus of arbitrary length can appear; profiles can be
singular where the diffusion vanishes.",http://arxiv.org/abs/2107.10530v1
The Impact of Negative Sampling on Contrastive Structured World Models,2021-07-24T19:42:42Z,"Ondrej Biza, Elise van der Pol, Thomas Kipf","World models trained by contrastive learning are a compelling alternative to
autoencoder-based world models, which learn by reconstructing pixel states. In
this paper, we describe three cases where small changes in how we sample
negative states in the contrastive loss lead to drastic changes in model
performance. In previously studied Atari datasets, we show that leveraging time
step correlations can double the performance of the Contrastive Structured
World Model. We also collect a full version of the datasets to study
contrastive learning under a more diverse set of experiences.",http://arxiv.org/abs/2107.11676v1
On Tropical Intersection Theory,2021-07-26T09:45:37Z,Andreas Mihatsch,"We develop a tropical intersection formalism of forms and currents that
extends classical tropical intersection theory in two ways. First, it allows to
work with arbitrary polytopes, also non-rational ones. Second, it allows for
smooth differential forms as coefficients. The intersection product in our
formalism can be defined through the diagonal intersection method of
Allermann--Rau or the fan displacement rule. We prove with a limiting argument
that both definitions agree.",http://arxiv.org/abs/2107.12067v3
Energy gain in a two-gap RF cavity,2021-07-27T18:57:50Z,Alexander Shemyakin,"Velocity of a deeply non-relativistic particle can change during its
acceleration inside an RF cavity significantly enough to cause a deviation of
the energy gain from a linear model. This paper derives formulae for
corrections to the energy gain in a two-gap RF cavity calculated by taking into
account this velocity change in the next approximation. Then, the results are
compared with direct particle tracking of an HWR cavity used at the PIP2IT test
accelerator. The formulae significantly extend the range of parameters where
analytical calculations work with a good accuracy. The approach is applied to
two aspects of cavity phasing.",http://arxiv.org/abs/2107.13041v1
Quasistatic work processes: When slowness implies certainty,2021-07-28T14:55:35Z,"Juyeon Yi, Peter Talkner","Two approaches are outlined to characterize the fluctuation behavior of work
applied to a system by a slow change of a parameter. One approach uses the
adiabatic theorems of quantum and classical mechanics, the other one is based
on the behavior of the correlations of the generalized coordinate that is
conjugate to the changed parameter. Criteria are obtained under which the work
done on small thermally isolated as well as on open systems ceases to fluctuate
in a quasistatic process.",http://arxiv.org/abs/2107.13409v2
"On a hydrodynamic description of waves propagating perpendicular to the
  magnetic field in relativistically hot plasmas",2021-07-28T19:14:03Z,Pavel A. Andreev,"The novel hydrodynamic model of plasmas with the relativistic temperatures
consisted of four equations for the material fields: the concentration and the
velocity field \emph{and} the average reverse relativistic $\gamma$ functor and
the flux of the reverse relativistic $\gamma$ functor is applied to study
high-frequency part of spectrum of electromagnetic waves propagating
perpendicular to the external magnetic field. The thermal effects considered
for the temperatures close to the rest energy of electrons considerably change
the dispersion equation in compare with the nonrelativistic temperatures.
Analytical analysis of the changes is presented.",http://arxiv.org/abs/2107.13603v2
"Purcell effect with extended sources: The role of the cross density of
  states",2021-07-29T14:04:31Z,"R. Carminati, M. Gurioli","We analyze the change in the spontaneous decay rate, or Purcell effect, of an
extended quantum emitter in a structured photonic environment. Based on a
simple theory, we show that the cross-density of states is the central quantity
driving interferences in the emission process. Using numerical simulations in
realistic photonic cavity geometries, we demonstrate that a structured
cross-density of states can induce subradiance or superradiance, and change
subtantially the emission spectrum. Interestingly, the spectral lineshape of
the Purcell effect of an extended source cannot be predicted from the sole
knowledge of the spectral dependence of the local density of states.",http://arxiv.org/abs/2107.13980v3
Imprint of Early Dark Energy in Stochastic Gravitational Wave Background,2021-07-29T18:10:14Z,Chia-Feng Chang,"Early dark energy that relieves Hubble tension leaves a fingerprint in the
primordial stochastic gravitational wave (GW) background that originates from
cosmic string network. The signal is not only detectable with future planned GW
experiments, but also distinguishable from other astrophysical and cosmological
signals in the GW frequency spectrum. We find that the cosmic string GW
spectrum can probe other new physics that influence the universe in
post-Big-Bang-Nucleosynthesis with mid-band GW detection, which extends GW
cosmic archaeology search region.",http://arxiv.org/abs/2107.14258v2
Nonlinear Helmholtz equations with sign-changing diffusion coefficient,2021-07-30T09:53:43Z,"Rainer Mandel, Zoïs Moitier, Barbara Verfürth","In this paper we study nonlinear Helmholtz equations with sign-changing
diffusion coefficients on bounded domains. The existence of an orthonormal
basis of eigenfunctions is established making use of weak T-coercivity theory.
All eigenvalues are proved to be bifurcation points and the bifurcating
branches are investigated both theoretically and numerically. In a
one-dimensional model example we obtain the existence of infinitely many
bifurcating branches that are mutually disjoint, unbounded, and consist of
solutions with a fixed nodal pattern.",http://arxiv.org/abs/2107.14516v4
Pearl vortices in anisotropic superconducting films,2021-09-05T01:59:05Z,"V. G. Kogan, N. Nakagawa, J. R. Kirtley","The magnetic field of vortices in anisotropic superconducting films is
considered in the framework of anisotropic London approach. It is found that at
distances large relative to the core size, the magnetic field normal to the
film surface may change sign.
  We find that the magnetic field attenuates at large distances as $1/r^3$ as
it does in isotropic films, but the anisotropy induces an angular dependence to
the supercurrents which causes the sign of the field to change for anisotropy
parameters $\gamma=\lambda_2/\lambda_1>\sqrt{2}$ in some parts of the $(x,y)$
plane.",http://arxiv.org/abs/2109.01966v1
"On the edge eigenvalues of the precision matrices of nonstationary
  autoregressive processes",2021-09-06T01:42:08Z,Junho Yang,"This paper investigates structural changes in the parameters of first-order
autoregressive models by analyzing the edge eigenvalues of the precision
matrices. Specifically, edge eigenvalues in the precision matrix are observed
if and only if there is a structural change in the autoregressive coefficients.
We show that these edge eigenvalues correspond to the zeros of a determinantal
equation. Additionally, we propose a consistent estimator for detecting
outliers within the panel time series framework, supported by numerical
experiments.",http://arxiv.org/abs/2109.02204v4
On trace of Brownian motion on the boundary of a strip,2021-09-07T13:18:24Z,"Liping Li, Wenjie Sun","The trace of a Markov process is the time changed process of the original
process on the support of the Revuz measure used in the time change. In this
paper, we will concentrate on the reflecting Brownian motions on certain closed
strips. On one hand, we will formulate the concrete expression of the Dirichlet
forms associated with the traces of such reflecting Brownian motions on the
boundary. On the other hand, the limits of these traces as the distance between
the upper and lower boundaries tends to $0$ or $\infty$ will be further
obtained.",http://arxiv.org/abs/2109.03074v1
Webs of Type P,2021-09-08T03:14:38Z,"Nicholas Davidson, Jonathan R. Kujawa, Robert Muth","This paper introduces type P web supercategories. They are defined as
diagrammatic monoidal $k$-linear supercategories via generators and relations.
We study the structure of these categories and provide diagrammatic bases for
their morphism spaces. We also prove these supercategories provide
combinatorial models for the monoidal supercategory generated by the symmetric
powers of the natural module and their duals for the Lie superalgebra of type
P.",http://arxiv.org/abs/2109.03410v2
Analysis of Language Change in Collaborative Instruction Following,2021-09-09T17:51:59Z,"Anna Effenberger, Eva Yan, Rhia Singh, Alane Suhr, Yoav Artzi","We analyze language change over time in a collaborative, goal-oriented
instructional task, where utility-maximizing participants form conventions and
increase their expertise. Prior work studied such scenarios mostly in the
context of reference games, and consistently found that language complexity is
reduced along multiple dimensions, such as utterance length, as conventions are
formed. In contrast, we find that, given the ability to increase instruction
utility, instructors increase language complexity along these previously
studied dimensions to better collaborate with increasingly skilled instruction
followers.",http://arxiv.org/abs/2109.04452v1
Simplified derivation of the Kompaneets equation,2021-09-08T17:11:47Z,Peter W. Milonni,"An isotropic electromagnetic field in a plasma of thermalized electrons
undergoes changes in energy as a result of Compton scattering and an
Einstein-Hopf drag force on the electrons, eventually approaching a
Bose-Einstein photon distribution at the electron temperature. The rate of
change of feld energy due to the combined effects of Compton scattering and the
drag force is shown to be described by the Kompaneets equation for photon
diffusion in frequency space. A similarity is noted between this approach and
Einstein's derivation of the Planck spectrum based on the recoil of atoms as
they absorb and emit radiation.",http://arxiv.org/abs/2109.04895v1
Odd reflections in the Yangian associated with ${\frak gl}(m|n)$,2021-09-20T12:16:41Z,A. I. Molev,"The odd reflections are an effective tool in the Lie superalgebra
representation theory, as they relate non-conjugate Borel subalgebras. We
introduce analogues of the odd reflections for the Yangian ${\rm Y}({\frak
gl}_{m|n})$ and use them to produce a transition rule for the parameters of the
highest weight modules corresponding to a change of the parity sequence. This
leads to a description of the finite-dimensional irreducible representations of
the Yangian associated with an arbitrary parity sequence.",http://arxiv.org/abs/2109.09462v3
Large magnetocaloric effect in $\mbox{Ho}_2\mbox{Pd}_{2}\mbox{Pb}$,2021-09-20T15:22:23Z,"Baidyanath Sahu, R. Djoumessi Fobasso, Buyisiwe M Sondezi, Andre M. Strydom","We report the magnetocaloric effect (MCE) in a polycrystalline plumbide
sample of $\mathrm{Ho_2Pd_2Pb}$. Arc-melted $\mathrm{Ho_2Pd_2Pb}$ crystallizes
in $\mathrm{Mo_2B_2Fe}$ type of tetragonal crystal structure and shows an
antiferromagnetic behavior with N\'{e}el temperature of 4.5 K. The Arrott plots
indicate that $\mathrm{Ho_2Pd_2Pb}$ undergoes a second-order antiferromagnetic
phase transition. The calculated isothermal magnetic entropy change ($\Delta
S_m$), and relative power cooling (refrigeration capacity) for a change of
field 0-8 T are 17.8 J.kg$^{-1}$.K$^{-1}$, and 680(497)~J.kg$^{-1}$
respectively. The obtained results revealed that $\mathrm{Ho_2Pd_2Pb}$ belongs
to a family of large MCE magnetic materials.",http://arxiv.org/abs/2109.09619v1
"Generalized linking-type theorem with applications to strongly
  indefinite problems with sign-changing nonlinearities",2021-09-25T08:23:09Z,"Federico Bernini, Bartosz Bieganowski","We show the linking-type result which allows us to study strongly indefinite
problems with sign-changing nonlinearities. We apply the abstract theory to the
singular Schr\""{o}dinger equation $$ -\Delta u + V(x)u + \frac{a}{r^2} u = f(u)
- \lambda g(u), \quad x = (y,z) \in \mathbb{R}^K \times \mathbb{R}^{N-K}, \ r =
|y|, $$ where $$ 0 \not\in \sigma \left( -\Delta + \frac{a}{r^2} + V(x)
\right). $$ As a consequence we obtain also the existence of solutions to the
nonlinear curl-curl problem.",http://arxiv.org/abs/2109.12310v2
Double parton distributions out of bounds in colour space,2021-09-29T09:37:24Z,"Markus Diehl, Jonathan R. Gaunt, Peter Plossl, Paolo Pichini","We investigate the positivity of double parton distributions with a
non-trivial dependence on the parton colour. It turns out that positivity is
not preserved by leading-order evolution from lower to higher scales, in
contrast to the case in which parton colour is summed over. We also study the
positivity properties of the distributions at small distance between the two
partons, where they can be computed in terms of perturbative splitting kernels
and ordinary parton densities.",http://arxiv.org/abs/2109.14304v2
Electrical conductivity in helical and conical magnetic states,2021-09-30T12:07:03Z,"Shun Okumura, Takahiro Morimoto, Yasuyuki Kato, Yukitoshi Motome","We theoretically study the electrical conductivity in a one-dimensional
helimagnet whose spin texture changes from helimagnetic to conical magnetic,
and to forced ferromagnetic state while increasing the magnetic field along the
helical axis. We find that the conductivity in the helimagnetic state at zero
field depends on the electron filling and the coefficient of the spin-charge
coupling. We also find that the conductivity in the conical magnetic state
changes nonlinearly to the applied field, and the magnetoresistance becomes
negative and positive depending on the model parameters.",http://arxiv.org/abs/2109.15038v1
How electrons Coulomb repulsion changes Graphene band structure,2021-11-02T16:25:33Z,"Rostam Moradian, Poorya Rabibegi","How electron-electron Coulomb repulsion modifies electronic band structure is
a big change in strongly correlated systems. We introduced a method for
calculation of realistic band structure of these systems and eliminating fake
states. By using this method we investigated how electrons repulsion
renormalizes graphene band structure. Our results show that in the dynamical
mean field theory at Coulomb repulsion $u=2.596 t$ a four band semi metal to
four bands anti ferro magnetism phase transition starts while due to inter site
correlation for four sites, $nc=4$, effective medium super cell approximation
it is $u=3.2 t$.",http://arxiv.org/abs/2111.01712v1
Representation Edit Distance as a Measure of Novelty,2021-11-04T11:52:09Z,Joshua Alspector,"Adaptation to novelty is viewed as learning to change and augment existing
skills to confront unfamiliar situations. In this paper, we propose that the
amount of editing of an effective representation (the Representation Edit
Distance or RED) used in a set of skill programs in an agent's mental model is
a measure of difficulty for adaptation to novelty. The RED is an intuitive
approximation to the change in information content in bit strings measured by
comparing pre-novelty and post-novelty skill programs. We also present some
notional examples of how to use RED for predicting difficulty.",http://arxiv.org/abs/2111.02770v1
Evolutionary paths under catastrophes,2021-11-15T13:58:35Z,Rinaldo B. Schinazi,"We introduce a model to study the impact of catastrophes on evolutionary
paths. If we do not allow catastrophes the number of changes in the maximum
fitness of a population grows logarithmically with respect to time. Allowing
catastrophes (no matter how rare) yields a drastically different behavior. When
catastrophes are possible the number of changes in the maximum fitness of the
population grows linearly with time. Moreover, the evolutionary paths are a lot
less predictable when catastrophes are possible. Our results can be seen as
supporting the hypothesis that catastrophes speed up evolution by disrupting
dominant species and creating space for new species to emerge and evolve.",http://arxiv.org/abs/2111.07760v1
A change of measure formula for recursive conditional expectations,2021-11-16T11:02:32Z,"Luca Di Persio, Alessandro Gnoatto, Marco Patacca","In this paper, we derive a representation for the value process associated to
the solutions of FBSDEs in a jump-diffusion setting under multiple probability
measures. Motivated by concrete financial problems, the latter representations
are then applied to devise a generalization of the change of num\'eraire
technique allowing to obtain recursive pricing formulas in the presence of
multiple interest rates and collateralization.",http://arxiv.org/abs/2111.08359v3
"Information dynamics of price and liquidity around the 2017 Bitcoin
  markets crash",2021-11-17T11:56:44Z,"Vaiva Vasiliauskaite, Fabrizio Lillo, Nino Antulov-Fantulin","We study the information dynamics between the largest Bitcoin exchange
markets during the bubble in 2017-2018. By analysing high-frequency
market-microstructure observables with different information theoretic measures
for dynamical systems, we find temporal changes in information sharing across
markets. In particular, we study the time-varying components of predictability,
memory, and synchronous coupling, measured by transfer entropy, active
information storage, and multi-information. By comparing these empirical
findings with several models we argue that some results could relate to
intra-market and inter-market regime shifts, and changes in direction of
information flow between different market observables.",http://arxiv.org/abs/2111.09057v1
"Mesh Sensitivity Analysis for Finite Element Solution of Linear Elliptic
  Partial Differential Equations",2021-11-22T01:13:45Z,"Yinnian He, Weizhang Huang","Mesh sensitivity of finite element solution for linear elliptic partial
differential equations is analyzed. A bound for the change in the finite
element solution is obtained in terms of the mesh deformation and its gradient.
The bound shows how the finite element solution changes continuously with the
mesh. The result holds in any dimension and for arbitrary unstructured
simplicial meshes, general linear elliptic partial differential equations, and
general finite element approximations.",http://arxiv.org/abs/2111.10935v1
"Traffic flow brake light model simulation based on driver behavior
  learning",2021-11-26T14:00:24Z,Rui Shen,"The theory of urban traffic flow has been developed and new types of
meta-automata have emerged and simulate realistic traffic conditions relatively
well. Among these models, the brake light model can simulate the three-phase
traffic flow theory very well. However, the existing brake light model also has
certain shortcomings, in that the model will change the speed of congestion
propagation upward when the model is covariant, which is not realistic, and the
model also lacks simulation parameters for driver behavior. In this paper, we
propose a new model based on the brake light model, which can achieve a certain
degree of simulation of driver behavior by adjusting the parameters, and also
achieve a stabilization of the propagation speed of the congestion wave when
the parameters are changed.",http://arxiv.org/abs/2111.13503v1
Fractional Ito calculus,2021-11-27T20:24:49Z,"Rama Cont, Ruhong Jin","We derive It\^o-type change of variable formulas for smooth functionals of
irregular paths with non-zero $p-$th variation along a sequence of partitions
where $p \geq 1$ is arbitrary, in terms of fractional derivative operators,
extending the results of the F\""ollmer-Ito calculus to the general case of
paths with 'fractional' regularity. In the case where $p$ is not an integer, we
show that the change of variable formula may sometimes contain a non-zero a
'fractional' It\^o remainder term and provide a representation for this
remainder term. These results are then extended to paths with non-zero
$\phi-$variation and multi-dimensional paths. Finally, we derive an isometry
property for the pathwise F\""ollmer integral in terms of $\phi$ variation.",http://arxiv.org/abs/2111.13979v1
"Strain Tensors and Matching Property on Surfaces with the Gauss
  curvature changing sign",2021-11-30T07:58:26Z,"Liang-Biao Chen, Peng-Fei Yao","We prove the regularity of solutions to the strain tensor equation on a
region $S$ with the Gauss curvature changing sign. Furthermore, we obtain the
density property that smooth infinitesimal isometries are dense in the
$W^{2,2}(S,\mathbb{R}^3)$ infinitesimal isometries. Finally, the matching
property is established. Those results are important tools in obtaining
recovery sequences ($\Gamma$-lim sup inequality) for dimensionally-reduced
shell theories in elasticity.",http://arxiv.org/abs/2111.15189v1
"Minor changes make a difference: a case study on the consistency of
  UD-based dependency parsers",2021-11-30T14:06:55Z,"Dmytro Kalpakchi, Johan Boye","Many downstream applications are using dependency trees, and are thus relying
on dependency parsers producing correct, or at least consistent, output.
However, dependency parsers are trained using machine learning, and are
therefore susceptible to unwanted inconsistencies due to biases in the training
data. This paper explores the effects of such biases in four languages -
English, Swedish, Russian, and Ukrainian - though an experiment where we study
the effect of replacing numerals in sentences. We show that such seemingly
insignificant changes in the input can cause large differences in the output,
and suggest that data augmentation can remedy the problems.",http://arxiv.org/abs/2111.15413v1
"Towards Modularity Optimization Using Reinforcement Learning to
  Community Detection in Dynamic Social Networks",2021-11-25T19:55:57Z,Aurélio Ribeiro Costa,"The identification of community structure in a social network is an important
problem tackled in the literature of network analysis. There are many solutions
to this problem using a static scenario, when facing a dynamic scenario some
solutions may be adapted but others simply do not fit, moreover when
considering the demand to analyze constantly growing networks. In this context,
we propose an approach to the problem of community detection in dynamic
networks based on a reinforcement learning strategy to deal with changes on big
networks using a local optimization on the modularity score of the changed
entities. An experiment using synthetic and real-world dynamic network data
shows results comparable to static scenarios.",http://arxiv.org/abs/2111.15623v1
Computing normalisers of intransitive groups,2021-12-01T10:12:47Z,"Mun See Chang, Christopher Jefferson, Colva M. Roney-Dougal","The normaliser problem takes as input subgroups $G$ and $H$ of the symmetric
group $S_n$, and asks one to compute $N_G(H)$. The fastest known algorithm for
this problem is simply exponential, whilst more efficient algorithms are known
for restricted classes of groups. In this paper, we will focus on groups with
many orbits. We give a new algorithm for the normaliser problem for these
groups that performs many orders of magnitude faster than previous
implementations in GAP. We also prove that the normaliser problem for the
special case $G=S_n$ is at least as hard as computing the group of monomial
automorphisms of a linear code over any field of fixed prime order.",http://arxiv.org/abs/2112.00388v1
Forced Changes Only: A New Take on the Law of Inertia,2021-12-04T13:59:30Z,Daniel Hoek,"Newton's First Law of Motion is typically understood to govern only the
motion of force-free bodies. This paper argues on textual and conceptual
grounds that it is in fact a stronger, more general principle. The First Law
limits the extent to which any body can change its state of motion -- even if
that body is subject to impressed forces. The misunderstanding can be traced
back to an error in the first English translation of Newton's Principia, which
was published a few years after Newton's death.",http://arxiv.org/abs/2112.02339v1
"$L^2$-bounds for drilling short geodesics in convex co-compact
  hyperbolic 3-manifolds",2021-12-06T00:53:21Z,"Martin Bridgeman, Kenneth Bromberg","We give $L^2$-bounds on the change in the complex projective structure on the
boundary of conformally compact hyperbolic 3-manifold with incompressible
boundary after drilling short geodesics. We show that the change is bounded by
a universal constant times the square root of the length of the drilled
geodesics. While $L^\infty$-bounds of this type where obtained by the second
author (2004), our bounds here do not depend on the injectivity radius of the
boundary.",http://arxiv.org/abs/2112.02724v2
The invariants of n-dimensional Rubik's Cube,2021-12-06T22:20:47Z,Isaev Roman,"It is well known that Rubik's cube has a set of group invariants. These
values do not change if any layer was rotated, but they can change in case if
some of the cubes were removed from the puzzle, mixed up and returned back. In
this paper, we generalize the puzzle to the case of an arbitrary dimension
after which we describe all the invariants.",http://arxiv.org/abs/2112.03385v1
"Negative magnetoresistance and sign change of the planar Hall effect due
  to the negative off-diagonal effective-mass in Weyl semimetals",2021-12-08T16:45:53Z,"Akiyoshi Yamada, Yuki Fuseya","We theoretically investigated the magnetoresistance (MR) and planar Hall
effect (PHE) in Weyl semimetals based on the semiclassical Boltzmann theory,
focusing on the fine structure of the band dispersion. We identified that the
negative longitudinal MR and sign change in the PHE occur because of the
negative off-diagonal effective-mass with no topological effects or chiral
anomaly physics. Our results highlight the crucial role of the off-diagonal
effective-mass, which can cause anomalous galvanomagnetic effects. We propose
that the PHE creates a dip in their temperature dependence, which enables the
experimental detection of the Weyl point.",http://arxiv.org/abs/2112.04400v1
Contracting on average iterated function systems by metric change,2021-12-13T17:30:02Z,"Katrin Gelfert, Graccyela R. Salcedo","We study contraction conditions for an iterated function system of continuous
maps on a metric space which are chosen randomly, identically and
independently. We investigate metric changes, preserving the topological
structure of the space, which turn the IFS into one which is contracting on
average. For the particular case of a system of $C^1$-diffeomorphisms of the
circle which is proximal and does not have a probability measure simultaneously
invariant by every map, we derive a strongly equivalent metric which contracts
on average.",http://arxiv.org/abs/2112.06819v1
"Self-Organization of Diverse Directional Hierarchical Networks in Simple
  Coupled Maps with Connection Changes",2021-12-14T07:46:01Z,"Taito Nakanishi, Masashi Fujii, Akinori Awazu","We comprehensively studied the morphology of the self-organized effective
network structures that form in simple coupled maps with interelement
synchronization-dependent connection changes. Based on the parameter values,
the spontaneous formation of four types of directional hierarchical networks,
named pair-driven networks, loop-driven networks, hidden trio-driven networks,
and hidden community-driven networks, was observed. This study provides novel
insights into the self-organized complex networks that form in neural networks,
various other biological networks, and social networks.",http://arxiv.org/abs/2112.07212v1
Disordered vector models: from higher spins to incipient strings,2021-12-16T19:04:19Z,"Chi-Ming Chang, Sean Colin-Ellerin, Cheng Peng, Mukund Rangamani","We present a one-parameter family of large $N$ disordered models, with and
without supersymmetry, in three spacetime dimensions. They interpolate from the
critical large $N$ vector model dual to a classical higher spin theory, towards
a theory with a classical string dual. We analyze the spectrum and OPE data of
the theories. While the supersymmetric model is always well-behaved the
non-supersymmetric model is unitary only over a small parameter range. We offer
some speculations on the origin of strings from the higher spins.",http://arxiv.org/abs/2112.09157v2
"Path Integral Method for Proportional Step and Proportional
  Double-Barrier Step Option Pricing",2021-12-16T09:30:01Z,"Qi Chen, Chao Guo","Path integral method in quantum mechanics provides a new thinking for barrier
option pricing. For proportional step options, the option price changing
process is similar to the one dimensional trapezoid potential barrier
scattering problem in quantum mechanics; for double-barrier step options, the
option price changing process is analogous to a particle moving in a finite
symmetric square potential well. Using path integral method, the analytical
expressions of pricing kernel and option price could be derived. Numerical
results of option price as a function of underlying price, potential and
exercise price are shown, which are consistent with the results given by
mathematical method.",http://arxiv.org/abs/2112.09534v3
"Monotonicity of positive solutions to quasilinear elliptic equations in
  half-spaces with a changing-sign nonlinearity",2021-12-16T13:13:05Z,"Francesco Esposito, Alberto Farina, Luigi Montoro, Berardino Sciunzi","In this paper we prove the monotonicity of positive solutions to $ -\Delta_p
u = f(u) $ in half-spaces under zero Dirichlet boundary conditions, for
$(2N+2)/(N+2) < p < 2$ and for a general class of regular changing-sign
nonlinearities $f$. The techniques used in the proof of the main result are
based on a fine use of comparison and maximum principles and on an adaptation
of the celebrated moving plane method to quasilinear elliptic equations in
unbounded domains.",http://arxiv.org/abs/2112.09552v1
"Branched Polymers with Excluded Volume Effects/ Configurations of Comb
  Polymers in Two- and Three-dimensions",2021-12-19T03:30:57Z,"Kazumi Suematsu, Haruo Ogura, Seiichi Inayama, Toshihiko Okamoto","We investigate the excluded volume effects in good solvents for the isolated
comb polymers having $\nu_{0}=1/4$. In particular, we investigate the change of
the size exponent, $\nu$, defined by $\langle s_{N}^{2}\rangle\propto
N^{2\nu}$, for the various fully-expanded configurations. The results show
that, given the fully stretched backbone and side chains, the exponent takes
the value, $\nu=1/2$, irrespective of the configurational isomerization of side
chains; only the pre-exponential factor changes.",http://arxiv.org/abs/2112.10051v2
Bifurcations for Hamiltonian systems,2021-12-20T18:18:35Z,Guangcun Lu,"With the dual variational principle and the saddle point reduction we use the
abstract bifurcation theory recently developed by author in previous work to
prove many new bifurcation results for solutions of four types of Hamiltonian
boundary value problems nonlinearly depending on parameters. The most
interesting and important among them are those alternative results which can
only be proved with our generalized versions of the famous Rabinowitz's
alternative bifurcation theorem.",http://arxiv.org/abs/2112.10726v5
Functional CLT for non-Hermitian random matrices,2021-12-21T17:38:53Z,"László Erdős, Hong Chang Ji","For large dimensional non-Hermitian random matrices $X$ with real or complex
independent, identically distributed, centered entries, we consider the
fluctuations of $f(X)$ as a matrix where $f$ is an analytic function around the
spectrum of $X$. We prove that for a generic bounded square matrix $A$, the
quantity $\mathrm{Tr}f(X)A$ exhibits Gaussian fluctuations as the matrix size
grows to infinity, which consists of two independent modes corresponding to the
tracial and traceless parts of $A$. We find a new formula for the variance of
the traceless part that involves the Frobenius norm of $A$ and the $L^{2}$-norm
of $f$ on the boundary of the limiting spectrum.",http://arxiv.org/abs/2112.11382v1
Newsvendor Model with Deep Reinforcement Learning,2021-12-22T05:52:44Z,Dylan K. Goetting,"I present a deep reinforcement learning (RL) solution to the mathematical
problem known as the Newsvendor model, which seeks to optimize profit given a
probabilistic demand distribution. To reflect a more realistic and complex
situation, the demand distribution can change for different days of the week,
thus changing the optimum behavior. I used a Twin-Delayed Deep Deterministic
Policy Gradient agent (written as completely original code) with both an actor
and critic network to solve this problem. The agent was able to learn optimal
behavior consistent with the analytical solution of the problem, and could
identify separate probability distributions for different days of the week and
behave accordingly.",http://arxiv.org/abs/2112.12544v2
On commutative diagrams consisting of low term exact sequences,2021-12-29T03:41:30Z,Chang Lv,"We establish several useful commutative diagrams consisting of low term exact
sequences attached to {\Grot} spectral sequences, which extends and integrates
the previous ones appeared in literature such as Alexei~N. Skorobogatov [Beyond
the {M}anin obstruction, Invent. Math. (1999)], and [On the elementary
obstruction to the existence of rational points, Mathematical Notes (2007)].
Parts of the diagrams was frequently used in local-global principle to rational
points.",http://arxiv.org/abs/2112.14386v2
Quantum Symmetry on Potts Model,2021-12-29T10:16:19Z,"Debashish Goswami, Sk Asfaq Hossain","We formulate the notion of quantum group symmetry of the Hamiltonian
corresponding to Potts model and compute it for few simple models. Our examples
illustrate how a slight change of the model parameter may result in a drastic
change of the quantum symmetry group, (in some cases, the classical symmetry
group remains unaffected) signifying a case of phase transition.",http://arxiv.org/abs/2112.14485v3
Spin Berry points as crucial for ultrafast demagnetization,2021-02-26T20:16:33Z,"G. P. Zhang, Y. H. Bai, Thomas F. George","Laser-induced ultrafast demagnetization has puzzled researchers around the
world for over two decades. Intrinsic complexity in electronic, magnetic, and
phononic subsystems is difficult to understand microscopically. So far it is
not possible to explain demagnetization using a single mechanism, which
suggests a crucial piece of information still missing. In this paper, we return
to a fundamental aspect of physics: spin and its change within each band in the
entire Brillouin zone. We employ fcc Ni as an example and use an extremely
dense {\bf k} mesh to map out spin changes for every band close to the Fermi
level along all the high symmetry lines. To our surprise, spin angular momentum
at some special {\bf k} points abruptly changes from $\pm \hbar/2$ to $\mp
\hbar/2$ simply by moving from one crystal momentum point to the next. This
explains why intraband transitions, which the spin superdiffusion model is
based upon, can induce a sharp spin moment reduction, and why electric current
can change spin orientation in spintronics. These special {\bf k} points, which
are called spin Berry points, are not random and appear when several bands are
close to each other, so the Berry potential of spin majority states is
different from that of spin minority states. Although within a single band,
spin Berry points jump, when we group several neighboring bands together, they
form distinctive smooth spin Berry lines. It is the band structure that
disrupts those lines. Spin Berry points are crucial to laser-induced ultrafast
demagnetization and spintronics.",http://arxiv.org/abs/2103.00040v1
Digital History and History Teaching in the Digital Age,2021-02-28T11:51:45Z,"Maria Papadopoulou, Zacharoula Smyrnaiou","Digital technologies, such as the Internet and Artificial Intelligence, are
part of our daily lives, influencing broader aspects of our way of life, as
well as the way we interact with the past. Having dramatically changed the ways
in which knowledge is produced and consumed, the algorithmic age has also
radically changed the relationship that the general public has with History.
Fields of History such as Public and Oral History have particularly benefitted
from the rise of digital culture. How does our digital culture affect the way
we think, study, research and teach the past, as historical evidence spreads
rapidly in the public sphere? How do digital technologies promote the study,
writing and teaching of History? What should historians, students of history
and pre-service history teachers be critically aware of, when swarmed with
digitized or born-digital content, constantly growing on the Internet? And
while these changes are now visible globally, how is the discipline of History
situated within the digital transformation rapidly advancing in Greece?
Finally, what are the consequences of these changes for History as a subject
taught at Greek secondary schools? These are some of the issues raised in the
text that follows, which is part of the course materials of the undergraduate
course offered during winter semester 2020-2021 at the School University of
Athens, School of Philosophy, Pedagogy, Psychology. Course Title: 'Pedagogics
of History: Theory and Practice', Academic Institution: School of
Philosophy-Pedagogy-Psychology, University of Athens.",http://arxiv.org/abs/2103.00473v1
Evaluating Robustness of Counterfactual Explanations,2021-03-03T12:16:06Z,"André Artelt, Valerie Vaquet, Riza Velioglu, Fabian Hinder, Johannes Brinkrolf, Malte Schilling, Barbara Hammer","Transparency is a fundamental requirement for decision making systems when
these should be deployed in the real world. It is usually achieved by providing
explanations of the system's behavior. A prominent and intuitive type of
explanations are counterfactual explanations. Counterfactual explanations
explain a behavior to the user by proposing actions -- as changes to the input
-- that would cause a different (specified) behavior of the system. However,
such explanation methods can be unstable with respect to small changes to the
input -- i.e. even a small change in the input can lead to huge or arbitrary
changes in the output and of the explanation. This could be problematic for
counterfactual explanations, as two similar individuals might get very
different explanations. Even worse, if the recommended actions differ
considerably in their complexity, one would consider such unstable
(counterfactual) explanations as individually unfair.
  In this work, we formally and empirically study the robustness of
counterfactual explanations in general, as well as under different models and
different kinds of perturbations. Furthermore, we propose that plausible
counterfactual explanations can be used instead of closest counterfactual
explanations to improve the robustness and consequently the individual fairness
of counterfactual explanations.",http://arxiv.org/abs/2103.02354v3
On the Lack of Consensus Among Technical Debt Detection Tools,2021-03-08T01:48:35Z,"Jason Lefever, Yuanfang Cai, Humberto Cervantes, Rick Kazman, Hongzhou Fang","A vigorous and growing set of technical debt analysis tools have been
developed in recent years -- both research tools and industrial products --
such as Structure 101, SonarQube, and DV8. Each of these tools identifies
problematic files using their own definitions and measures. But to what extent
do these tools agree with each other in terms of the files that they identify
as problematic? If the top-ranked files reported by these tools are largely
consistent, then we can be confident in using any of these tools. Otherwise, a
problem of accuracy arises. In this paper, we report the results of an
empirical study analyzing 10 projects using multiple tools. Our results show
that: 1) these tools report very different results even for the most common
measures, such as size, complexity, file cycles, and package cycles. 2) These
tools also differ dramatically in terms of the set of problematic files they
identify, since each implements its own definitions of ""problematic"". After
normalizing by size, the most problematic file sets that the tools identify
barely overlap. 3) Our results show that code-based measures, other than size
and complexity, do not even moderately correlate with a file's change-proneness
or error-proneness. In contrast, co-change-related measures performed better.
Our results suggest that, to identify files with true technical debt -- those
that experience excessive changes or bugs -- co-change information must be
considered. Code-based measures are largely ineffective at pinpointing true
debt. Finally, this study reveals the need for the community to create
benchmarks and data sets to assess the accuracy of software analysis tools in
terms of commonly used measures.",http://arxiv.org/abs/2103.04506v1
Geometric Change Detection in Digital Twins using 3D Machine Learning,2021-03-15T08:20:16Z,"Tiril Sundby, Julia Maria Graham, Adil Rasheed, Mandar Tabib, Omer San","Digital twins are meant to bridge the gap between real-world physical systems
and virtual representations. Both stand-alone and descriptive digital twins
incorporate 3D geometric models, which are the physical representations of
objects in the digital replica. Digital twin applications are required to
rapidly update internal parameters with the evolution of their physical
counterpart. Due to an essential need for having high-quality geometric models
for accurate physical representations, the storage and bandwidth requirements
for storing 3D model information can quickly exceed the available storage and
bandwidth capacity. In this work, we demonstrate a novel approach to geometric
change detection in the context of a digital twin. We address the issue through
a combined solution of Dynamic Mode Decomposition (DMD) for motion detection,
YOLOv5 for object detection, and 3D machine learning for pose estimation. DMD
is applied for background subtraction, enabling detection of moving foreground
objects in real-time. The video frames containing detected motion are extracted
and used as input to the change detection network. The object detection
algorithm YOLOv5 is applied to extract the bounding boxes of detected objects
in the video frames. Furthermore, the rotational pose of each object is
estimated in a 3D pose estimation network. A series of convolutional neural
networks conducts feature extraction from images and 3D model shapes. Then, the
network outputs the estimated Euler angles of the camera orientation with
respect to the object in the input image. By only storing data associated with
a detected change in pose, we minimize necessary storage and bandwidth
requirements while still being able to recreate the 3D scene on demand.",http://arxiv.org/abs/2103.08201v1
"RoRD: Rotation-Robust Descriptors and Orthographic Views for Local
  Feature Matching",2021-03-15T17:40:25Z,"Udit Singh Parihar, Aniket Gujarathi, Kinal Mehta, Satyajit Tourani, Sourav Garg, Michael Milford, K. Madhava Krishna","The use of local detectors and descriptors in typical computer vision
pipelines work well until variations in viewpoint and appearance change become
extreme. Past research in this area has typically focused on one of two
approaches to this challenge: the use of projections into spaces more suitable
for feature matching under extreme viewpoint changes, and attempting to learn
features that are inherently more robust to viewpoint change. In this paper, we
present a novel framework that combines learning of invariant descriptors
through data augmentation and orthographic viewpoint projection. We propose
rotation-robust local descriptors, learnt through training data augmentation
based on rotation homographies, and a correspondence ensemble technique that
combines vanilla feature correspondences with those obtained through
rotation-robust features. Using a range of benchmark datasets as well as
contributing a new bespoke dataset for this research domain, we evaluate the
effectiveness of the proposed approach on key tasks including pose estimation
and visual place recognition. Our system outperforms a range of baseline and
state-of-the-art techniques, including enabling higher levels of place
recognition precision across opposing place viewpoints and achieves
practically-useful performance levels even under extreme viewpoint changes.",http://arxiv.org/abs/2103.08573v4
"Bonding nature and optical contrast of $TiTe_2$/$Sb_2Te_3$ phase-change
  heterostructure",2021-03-25T03:31:11Z,"Xudong Wang, Yue Wu, Yuxing Zhou, Volker L. Deringer, Wei Zhang","Chalcogenide phase-change materials (PCMs) are regarded as the leading
candidate for storage-class non-volatile memory and neuro-inspired computing.
Recently, using the $TiTe_2$/$Sb_2Te_3$ material combination, a new framework -
phase-change heterostructure (PCH), has been developed and proved to
effectively suppress the noise and drift in electrical resistance upon memory
programming, largely reducing the inter-device variability. However, the
atomic-scale structural and chemical nature of PCH remains to be fully
understood. In this work, we carry out thorough ab initio simulations to assess
the bonding characteristics of the PCH. We show that the $TiTe_2$ crystalline
nanolayers do not chemically interact with the surrounding $Sb_2Te_3$, and are
stabilized by strong covalent and electrostatic Ti-Te interactions, which
create a prohibitively high barrier for atomic migrations along the pulsing
direction. We also find significant contrast in computed dielectric functions
in the PCH, suggesting possible optical applications of this class of devices.
With the more confined space and therefore constrained phase transition
compared to traditional PCM devices, the recently introduced class of PCH-based
devices may lead to improvements in phase-change photonic and optoelectronic
applications with much lower stochasticity during programming.",http://arxiv.org/abs/2103.13583v2
"What happens when a journal converts to Open Access? A bibliometric
  analysis",2021-03-26T15:20:29Z,"Fakhri Momeni, Philipp Mayr, Nicholas Fraser, Isabella Peters","In recent years, increased stakeholder pressure to transition research to
Open Access has led to many journals converting, or 'flipping', from a closed
access (CA) to an open access (OA) publishing model. Changing the publishing
model can influence the decision of authors to submit their papers to a
journal, and increased article accessibility may influence citation behaviour.
In this paper we aimed to understand how flipping a journal to an OA model
influences the journal's future publication volumes and citation impact. We
analysed two independent sets of journals that had flipped to an OA model, one
from the Directory of Open Access Journals (DOAJ) and one from the Open Access
Directory (OAD), and compared their development with two respective control
groups of similar journals. For bibliometric analyses, journals were matched to
the Scopus database. We assessed changes in the number of articles published
over time, as well as two citation metrics at the journal and article level:
the normalised impact factor (IF) and the average relative citations (ARC),
respectively. Our results show that overall, journals that flipped to an OA
model increased their publication output compared to journals that remained
closed. Mean normalised IF and ARC also generally increased following the flip
to an OA model, at a greater rate than was observed in the control groups.
However, the changes appear to vary largely by scientific discipline. Overall,
these results indicate that flipping to an OA publishing model can bring
positive changes to a journal.",http://arxiv.org/abs/2103.14522v1
"Kerr and Faraday rotations in topological flat and dispersive band
  structures",2021-03-28T09:06:29Z,"Alireza Habibi, Ahmad Z. Musthofa, Elaheh Adibi, Johan Ekström, Thomas L. Schmidt, Eddwi H. Hasdeo","Integer quantum Hall (IQH) states and quantum anomalous Hall (QAH) states
show the same static (dc) response but distinct dynamical (ac) response. In
particular, the ac anomalous Hall conductivity profile $\sigma_{yx}(\omega)$ is
sensitive to the band shape of QAH states. For example, dispersive QAH bands
shows resonance profile without a sign change at the band gap while the IQH
states shows the sign change resonance at the cyclotron energy. We argue by
flattening the dispersive QAH bands, $\sigma_{yx}(\omega)$ should recover to
that of flat Landau bands in IQH, thus it is necessary to know the origin of
the sign change. Taking a topological lattice model with tunable bandwidth, we
found that the origin of the sign change is not the band gap but the Van Hove
singularity energy of the QAH bands. In the limit of small bandwidth, the flat
QAH bands recovers $\sigma_{yx}(\omega)$ of the IQH Landau bands. Because of
the Hall response, these topological bands exhibit giant polarization rotation
and ellipticity in the reflected waves (Kerr effect) and rotation in the order
of fine structure constant in the transmitted waves (Faraday effect) with
profile resembles $\sigma_{yx}(\omega)$. Our results serve as a simple guide to
optical characterization for topological flat bands.",http://arxiv.org/abs/2103.15085v2
"Cluster Algebras and Scattering Diagrams, Part II. Cluster Patterns and
  Scattering Diagrams",2021-03-30T13:00:23Z,Tomoki Nakanishi,"We review some important results by Gross, Hacking, Keel, and Kontsevich on
cluster algebra theory, namely, the column sign-coherence of $C$-matrices and
the Laurent positivity, both of which were conjectured by Fomin and Zelevinsky.
We digest and reconstruct the proofs of these conjectures by Gross et al. still
based on their scattering diagram method, however, without relying on toric
geometry. At the same time, we also give a detailed account of the
correspondence between the notions of cluster patterns and scattering diagrams.
Most of the results in this text are found in or translated from the known
results in the literature. However, the approach, the construction of logic and
proofs, and the overall presentation are new. Also, as an application of the
results and the techniques in the text, we show that there is a one-to-one
correspondence between $g$-vectors and cluster variables in cluster patterns
with arbitrary coefficients.",http://arxiv.org/abs/2103.16309v5
Controllable Gradient Item Retrieval,2021-05-31T19:07:17Z,"Haonan Wang, Chang Zhou, Carl Yang, Hongxia Yang, Jingrui He","In this paper, we identify and study an important problem of gradient item
retrieval. We define the problem as retrieving a sequence of items with a
gradual change on a certain attribute, given a reference item and a
modification text. For example, after a customer saw a white dress, she/he
wants to buy a similar one but more floral on it. The extent of ""more floral""
is subjective, thus prompting one floral dress is hard to satisfy the
customer's needs. A better way is to present a sequence of products with
increasingly floral attributes based on the white dress, and allow the customer
to select the most satisfactory one from the sequence. Existing item retrieval
methods mainly focus on whether the target items appear at the top of the
retrieved sequence, but ignore the demand for retrieving a sequence of products
with gradual change on a certain attribute. To deal with this problem, we
propose a weakly-supervised method that can learn a disentangled item
representation from user-item interaction data and ground the semantic meaning
of attributes to dimensions of the item representation. Our method takes a
reference item and a modification as a query. During inference, we start from
the reference item and ""walk"" along the direction of the modification in the
item representation space to retrieve a sequence of items in a gradient manner.
We demonstrate our proposed method can achieve disentanglement through weak
supervision. Besides, we empirically show that an item sequence retrieved by
our method is gradually changed on an indicated attribute and, in the item
retrieval task, our method outperforms existing approaches on three different
datasets.",http://arxiv.org/abs/2106.00062v1
"Debate on Online Social Networks at the Time of COVID-19: An Italian
  Case Study",2021-06-02T08:25:19Z,"Martino Trevisan, Luca Vassio, Danilo Giordano","The COVID-19 pandemic is not only having a heavy impact on healthcare but
also changing people's habits and the society we live in. Countries such as
Italy have enforced a total lockdown lasting several months, with most of the
population forced to remain at home. During this time, online social networks,
more than ever, have represented an alternative solution for social life,
allowing users to interact and debate with each other. Hence, it is of
paramount importance to understand the changing use of social networks brought
about by the pandemic. In this paper, we analyze how the interaction patterns
around popular influencers in Italy changed during the first six months of
2020, within Instagram and Facebook social networks. We collected a large
dataset for this group of public figures, including more than 54 million
comments on over 140 thousand posts for these months. We analyze and compare
engagement on the posts of these influencers and provide quantitative figures
for aggregated user activity. We further show the changes in the patterns of
usage before and during the lockdown, which demonstrated a growth of activity
and sizable daily and weekly variations. We also analyze the user sentiment
through the psycholinguistic properties of comments, and the results testified
the rapid boom and disappearance of topics related to the pandemic. To support
further analyses, we release the anonymized dataset.",http://arxiv.org/abs/2106.01013v1
"Meterwavelength Single-pulse Polarimetric Emission Survey. V. Flux
  density, component spectral variation and emission states",2021-06-02T18:11:22Z,"Rahul Basu, Dipanjan Mitra, George I. Melikidze","We present the flux density measurements of the pulsars observed in the
Meterwavelength single-pulse polarimetric emission survey. The average flux
densities were estimated in 113 pulsars at two frequencies of 325 and 610 MHz
using interferometric imaging. The average profile and single pulse emission in
each pulsar were calibrated using the estimated flux density. We have used the
flux calibrated average profile to study the variation of the spectral index
across the emission beam in 21 pulsars where the core, inner cone and the outer
conal components could be clearly identified. The central core component showed
a steeper increase in emission at the lower frequency compared with conal
emission, with an average difference in spectral index
$\delta\alpha_{core-cone}\sim-0.7$ between the core and the conal components in
this frequency range. In contrast the inner conal components had positive
difference in their spectral index compared to the outer cones with average
difference $\delta\alpha_{in-out}\sim+0.3$. The variation in the spectral index
across the pulse window should provide valuable inputs for constraining the
radio emission processes. The single pulse emission showed the presence of
emission mode changing in 12 pulsars with 3 cases where the phenomenon is being
reported for the first time. In addition we have also detected enhanced
emission for short durations or flaring, in parts or across the entire emission
window in 14 pulsars. The sudden changes in the emission during mode changing
as well as these bursting states are unrelated to the emission mechanism and
suggest the presence of rapid and repetitive changes during the plasma
generation process.",http://arxiv.org/abs/2106.01402v1
Stern and Diffuse Layer Interactions During Ionic Strength Cycling,2021-06-05T13:31:29Z,"Emily Ma, Jeongmin Kim, HanByul Chang, Paul E. Ohno, Richard J. Jodts, Thomas F. Miller III, Franz M. Geiger","Second harmonic generation amplitude and phase measurements are acquired in
real time from fused silica:water interfaces that are subjected to ionic
strength transitions conducted at pH 5.8. In conjunction with atomistic
modeling, we identify correlations between structure in the Stern layer,
encoded in the total second-order nonlinear susceptibility, chi(2)tot, and in
the diffuse layer, encoded in the product of chi(2)tot and the total
interfacial potential, phi(0)tot. chi(2)tot:phi(0)tot correlation plots
indicate that the dynamics in the Stern and diffuse layers are decoupled from
one another under some conditions (large change in ionic strength), while they
change in lockstep under others (smaller change in ionic strength) as the ionic
strength in the aqueous bulk solution varies. The quantitative structural and
electrostatic information obtained also informs on the molecular origin of
hysteresis in ionic strength cycling over fused silica. Atomistic simulations
suggest a prominent role of contact ion pairs (as opposed to solvent-separated
ion pairs) in the Stern layer. Those simulations also indicate that net water
alignment is limited to the first 2 nm from the interface, even at 0 M ionic
strength, highlighting water's polarization as an important contributor to
nonlinear optical signal generation.",http://arxiv.org/abs/2106.02893v1
"FlexParser -- the adaptive log file parser for continuous results in a
  changing world",2021-06-06T16:30:01Z,"Nadine Ruecker, Andreas Maier","Any modern system writes events into files, called log files. Those contain
crucial information which are subject to various analyses. Examples range from
cybersecurity, intrusion detection over usage analyses to trouble shooting.
Before data analysis is possible, desired information needs to be extracted
first out of the semi-structured log messages. State-of-the-art event parsing
often assumes static log events. However, any modern system is updated
consistently and with updates also log file structures can change. We call
those changes ""mutation"" and study parsing performance for different mutation
cases. Latest research discovers mutations using anomaly detection post mortem,
however, does not cover actual continuous parsing. Thus, we propose a novel and
flexible parser, called FlexParser, which can extract desired values despite
gradual changes in the log messages. It implies basic text preprocessing
followed by a supervised Deep Learning method. We train a stateful LSTM on
parsing one event per data set. Statefulness enforces the model to learn log
message structures across several examples. Our model was tested on seven
different, publicly available log file data sets and various kinds of
mutations. Exhibiting an average F1-Score of 0.98, it outperforms other Deep
Learning methods as well as state-of-the-art unsupervised parsers.",http://arxiv.org/abs/2106.03170v2
"A Nonlinear Observability Analysis of Ambient Wind Estimation with
  Uncalibrated Sensors, Inspired by Insect Neural Encoding",2021-06-07T21:35:25Z,Floris van Breugel,"Estimating the direction of ambient fluid flow is key for many flying or
swimming animals and robots, but can only be accomplished through indirect
measurements and active control. Recent work with tethered flying insects
indicates that their sensory representation of orientation, apparent flow,
direction of movement, and control is represented by a 2-dimensional angular
encoding in the central brain. This representation simplifies sensory
integration by projecting the direction (but not scale) of measurements with
different units onto a universal polar coordinate frame. To align these angular
measurements with one another and the motor system does, however, require a
calibration of angular gain and offset for each sensor. This calibration could
change with time due to changes in the environment or physical structure. The
circumstances under which small robots and animals with angular sensors and
changing calibrations could self-calibrate and estimate the direction of
ambient fluid flow while moving remains an open question. Here, a methodical
nonlinear observability analysis is presented to address this. The analysis
shows that it is mathematically feasible to continuously estimate flow
direction and perform regular self-calibrations by adopting frequent changes in
course (or active prevention thereof) and orientation, and requires fusion and
temporal differentiation of three sensory measurements: apparent flow,
orientation (or its derivative), and direction of motion (or its derivative).
These conclusions are consistent with the zigzagging trajectories exhibited by
many plume tracking organisms, suggesting that perhaps flow estimation is a
secondary driver of their trajectory structure.",http://arxiv.org/abs/2106.03974v1
Models of space-time random fields on the sphere,2021-06-09T07:44:57Z,"Mirko D'Ovidio, Enzo Orsingher, Lyudmyla Sakhno","We study general models of random fields associated with non-local equations
in time and space. We discuss the properties of the corresponding angular power
spectrum and find asymptotic results in terms of random time changes.",http://arxiv.org/abs/2106.04865v1
"A non-hyperelliptic curve with torsion Ceresa cycle modulo algebraic
  equivalence",2021-06-15T19:35:39Z,"Arnaud Beauville, Chad Schoen","We exhibit a non-hyperelliptic curve C of genus 3 such that the class of the
Ceresa cycle [C]-[(-1)*C] in JC modulo algebraic equivalence is torsion.",http://arxiv.org/abs/2106.08390v2
RTP Pockels Cell with Nanometer-Level Position Control,2021-06-15T16:33:36Z,"Caryn Palatchi, Kent Paschke","MOLLER is a future experiment designed to measure parity violation in Moller
scattering to extremely high precision. MOLLER will measure the right-left
scattering differential cross-section parity-violating asymmetry APV , in the
elastic scattering of polarized electrons off an unpolarized LH2 target to
extreme ppb precision. To make this measurement, the polarized electron source,
generated with a circularly polarized laser beam, must have the ability to
switch quickly between right and left helicity polarization states. The
polarized source must also maintain minimal right-left helicity correlated beam
asymmetries, including energy changes, position changes, intensity changes, or
spot-size changes. These requirements can be met with appropriate choice and
design of the Pockels cell used to generate the circularly polarized light.
Rubidium Titanyl Phosphate (RTP) has been used in recent years for ultra-fast
Pockels cell switches due to its lack of piezo-electric resonances at
frequencies up to several hundred MHz. However, crystal non-uniformity in this
material leads to poorer extinction ratios than in commonly used KD*P Pockels
cells when used in hald-wave configuration. It leads to voltage dependent beam
steering when used in quarter-wave configuration. Here we present an innovative
RTP Pockels cell design which uses electric field gradients to counteract
crystal non-uniformities and control beam steering down to the nm-level. We
demonstrate this RTP Pockels cell design is capable of producing precisely
controlled polarized electron beam at Jefferson Laboratory, a national
accelerator facility, for current experiments, including the recent PREX II
measurement, as well as the future MOLLER experiment.",http://arxiv.org/abs/2106.09546v1
Profile changes associated with DM events in PSR J1713+0747,2021-06-18T00:28:23Z,"Fang Xi Lin, Hsiu-Hsien Lin, Jing Luo, Robert Main, James McKee, Ue-Li Pen, Dana Simard, Marten H. van Kerkwijk","Propagation effects in the interstellar medium and intrinsic profile changes
can cause variability in the timing of pulsars, which limits the accuracy of
fundamental science done via pulsar timing. One of the best timing pulsars, PSR
J1713+0747, has gone through two `dip' events in its dispersion measure (DM)
time series. If these events reflect real changes in electron column density,
they should lead to multiple imaging. We show that the events are are well
fitted by an underdense corrugated sheet model, and look for associated
variability in the pulse profile using principal component analysis. We find
that there are transient pulse profile variations, but they vary in concert
with the dispersion measure, unlike what is expected from lensing due to a
corrugated sheet. The change is consistent in shape across profiles from both
the Greenbank and Arecibo radio observatories, and its amplitude appears to be
achromatic across the 820-MHz, 1.4-GHz, and 2.3-GHz bands, again unlike
expected from interference between lensed images. This result is puzzling. We
note that some of the predicted lensing effects would need higher time and
frequency resolution data than used in this analysis. Future events appear
likely, and storing baseband data or keeping multiple time-frequency
resolutions will allow more in-depth study of propagation effects and hence
improvements to pulsar timing accuracy.",http://arxiv.org/abs/2106.09851v2
"An empirical evaluation of the usefulness of Tree Kernels for
  Commit-time Defect Detection in large software systems",2021-06-21T01:05:07Z,"Hareem Sahar, Yuxin Liu, Abram Hindle, Denilson Barbosa","Defect detection at commit check-in time prevents the introduction of defects
into software systems. Current defect detection approaches rely on metric-based
models which are not very accurate and whose results are not directly useful
for developers. We propose a method to detect bug-inducing commits by comparing
the incoming changes with all past commits in the project, considering both
those that introduced defects and those that did not. Our method considers
individual changes in the commit separately, at the method-level granularity.
Doing so helps developers as they are informed of specific methods that need
further attention instead of being told that the entire commit is problematic.
Our approach represents source code as abstract syntax trees and uses tree
kernels to estimate the similarity of the code with previous commits. We
experiment with subtree kernels (STK), subset tree kernels (SSTK), or partial
tree kernels (PTK). An incoming change is then classified using a K-NN
classifier on the past changes. We evaluate our approach on the BigCloneBench
benchmark and on the Technical Debt dataset, using the NiCad clone detector as
the baseline. Our experiments with the BigCloneBench benchmark show that the
tree kernel approach can detect clones with a comparable MAP to that of NiCad.
Also, on defect detection with the Technical Debt dataset, tree kernels are
least as effective as NiCad with MRR, F-score, and Accuracy of 0.87, 0.80, and
0.82 respectively.",http://arxiv.org/abs/2106.10789v1
"A Brief Introduction to the Feichtinger Algebra
  $\mathbf{S}_{0}(\mathbb{R})$",2021-06-21T17:44:42Z,Eirik Berge,"This note highlights the key aspects of the Feichtinger algebra
$\mathbf{S}_{0}(\mathbb{R})$ on the real line for non-experts.",http://arxiv.org/abs/2106.11287v2
"Changepoint Detection: An Analysis of the Central England Temperature
  Series",2021-06-23T06:10:21Z,"Xueheng Shi, Claudie Beaulieu, Rebecca Killick, Robert Lund","This paper presents a statistical analysis of structural changes in the
Central England temperature series, one of the longest surface temperature
records available. A changepoint analysis is performed to detect abrupt
changes, which can be regarded as a preliminary step before further analysis is
conducted to identify the causes of the changes (e.g., artificial,
human-induced or natural variability). Regression models with structural
breaks, including mean and trend shifts, are fitted to the series and compared
via two commonly used multiple changepoint penalized likelihood criteria that
balance model fit quality (as measured by likelihood) against parsimony
considerations. Our changepoint model fits, with independent and short-memory
errors, are also compared with a different class of models termed long-memory
models that have been previously used by other authors to describe persistence
features in temperature series. In the end, the optimal model is judged to be
one containing a changepoint in the late 1980s, with a transition to an
intensified warming regime. This timing and warming conclusion is consistent
across changepoint models compared in this analysis. The variability of the
series is not found to be significantly changing, and shift features are judged
to be more plausible than either short- or long-memory autocorrelations. The
final proposed model is one including trend-shifts (both intercept and slope
parameters) with independent errors. The analysis serves as a walk-through
tutorial of different changepoint techniques, illustrating what can be
statistically inferred.",http://arxiv.org/abs/2106.12180v2
Conservation with moving meshes over orography,2021-08-02T12:21:10Z,"Hiroe Yamazaki, Hilary Weller, Colin J. Cotter, Philip A. Browne","Adaptive meshes have the potential to improve the accuracy and efficiency of
atmospheric modelling by increasing resolution where it is most needed. Mesh
re-distribution, or r-adaptivity, adapts by moving the mesh without changing
the connectivity. This avoids some of the challenges with h-adaptivity (adding
and removing points): the solution does not need to be mapped between meshes,
which can be expensive and introduces errors, and there are no load balancing
problems on parallel computers. A long standing problem with both forms of
adaptivity has been changes in volume of the domain as resolution changes at an
uneven boundary. We propose a solution to exact local conservation and
maintenance of uniform fields while the mesh changes volume as it moves over
orography. This is solved by introducing a volume adjustment parameter which
tracks the true cell volumes without using expensive conservative mapping.
  A finite volume solution of the advection equation over orography on moving
meshes is described and results are presented demonstrating improved accuracy
for cost using moving meshes. Exact local conservation and maintenance of
uniform fields is demonstrated and the corrected mesh volume is preserved.
  We use optimal transport to generate meshes which are guaranteed not to
tangle and are equidistributed with respect to a monitor function. This leads
to a Monge-Amp\`{e}re equation which is solved with a Newton solver. The
superiority of the Newton solver over other techniques is demonstrated in the
appendix. However the Newton solver is only efficient if it is applied to the
left hand side of the Monge-Amp\`{e}re equation with fixed point iterations for
the right hand side.",http://arxiv.org/abs/2108.00805v1
Droplets on substrates with oscillating wettability,2021-08-03T12:01:48Z,"Josua Grawitter, Holger Stark","In recent decades novel solid substrates have been designed which change
their wettability in response to light or an electrostatic field. Here, we
investigate a droplet on substrates with oscillating uniform wettability by
varying minimium and maximum contact angles and frequency. To simulate this
situation, we use our previous work [Grawitter and Stark, Soft Matter 17, 2454
(2021)], where we implemented the boundary element method in combination with
the Cox-Voinov law for the contact-line velocity, to determine the fluid flow
inside a droplet. After a transient regime the droplet performs steady
oscillations, the amplitude of which decreases with increasing frequency. For
slow oscillations our numerical results agree well with the linearized
spherical-cap model. They collapse on a master curve when we rescale frequency
by a characteristic relaxation time. In contrast, for fast oscillations we
observe significant deviations from the master curve. The decay of the
susceptibility is weaker and the phase shift between oscillations in
wettability and contact angle stays below the predicted $\pi/2$. The reason
becomes obvious when studying the combined dynamics of droplet height and
contact angle. It reveals non-reciprocal shape changes during one oscillation
period even at low frequencies due to the induced fluid flow inside the
droplet, which are not captured by the spherical-cap model. Similar periodic
non-reciprocal shape changes occur at low frequencies when the droplet is
placed on an oscillating nonuniform wettability profile with six-fold symmetry.
Such profiles are inspired by the light intensity pattern of Laguerre-Gauss
laser modes. Since the non-reciprocal shape changes induce fluid circulation,
which is controllable from the outside, our findings envisage to design
targeted microfluidic transport of solutes inside the droplet.",http://arxiv.org/abs/2108.01429v1
"SIMPT: Process Improvement Using Interactive Simulation of Time-aware
  Process Trees",2021-08-02T10:03:40Z,"Mahsa Pourbafrani, Shuai Jiao, Wil M. P. van der Aalst","Process mining techniques including process discovery, conformance checking,
and process enhancement provide extensive knowledge about processes.
Discovering running processes and deviations as well as detecting performance
problems and bottlenecks are well-supported by process mining tools. However,
all the provided techniques represent the past/current state of the process.
The improvement in a process requires insights into the future states of the
process w.r.t. the possible actions/changes. In this paper, we present a new
tool that enables process owners to extract all the process aspects from their
historical event data automatically, change these aspects, and re-run the
process automatically using an interface. The combination of process mining and
simulation techniques provides new evidence-driven ways to explore ""what-if""
questions. Therefore, assessing the effects of changes in process improvement
is also possible. Our Python-based web-application provides a complete
interactive platform to improve the flow of activities, i.e., process tree,
along with possible changes in all the derived activity, resource, and process
parameters. These parameters are derived directly from an event log without
user-background knowledge.",http://arxiv.org/abs/2108.02052v1
"Forecasting racial dynamics at the neighborhood scale using
  Density-functional Fluctuation Theory",2021-08-05T21:20:55Z,"Yunus A. Kinkhabwala, Boris Barron, Matthew Hall, Tomas A. Arias, Itai Cohen","Racial residential segregation is a defining and enduring feature of U.S.
society, shaping inter-group relations, racial disparities in income and
health, and access to high-quality public goods and services. The design of
policies aimed at addressing these inequities would be better informed by
descriptive models of segregation that are able to predict neighborhood scale
racial sorting dynamics. While coarse regional population projections are
widely accessible, small area population changes remain challenging to predict
because granular data on migration is limited and mobility behaviors are driven
by complex social and idiosyncratic dynamics. Consequently, to account for such
drivers, it is necessary to develop methods that can extract effective
descriptions of their impacts on population dynamics based solely on
statistical analysis of available data. Here, we develop and validate a
Density-Functional Fluctuation Theory (DFFT) that quantifies segregation using
density-dependent functions extracted from population counts and uses these
functions to accurately forecast how the racial/ethnic compositions of
neighborhoods across the US are likely to change. Importantly, DFFT makes
minimal assumptions about the nature of the underlying causes of segregation
and is designed to quantify segregation for neighborhoods with different total
populations in regions with different compositions. This quantification can be
used to accurately forecast both average changes in neighborhood compositions
and the likelihood of more drastic changes such as those associated with
gentrification and neighborhood tipping. As such, DFFT provides a powerful
framework for researchers and policy makers alike to better quantify and
forecast neighborhood-scale segregation and its associated dynamics.",http://arxiv.org/abs/2108.04084v1
"Recognizing and prevention of probable regime shift in density regulated
  and Allee type stochastic harvesting model with application to herring
  conservation",2021-08-17T09:37:31Z,"Anurag Sau, Sabyasachi Bhattacharya, Bapi Saha","An ecological system with multiple stable equilibria is prone to undergo
catastrophic change or regime shift from one steady-state to another. It should
be noted that, if one of the steady states is an extinction state, the
catastrophic change may lead to extinction. A suitable manual measure may
control the prevention of catastrophic changes of different species from one
equilibrium to another. We consider two stochastic models with linear and
nonlinear harvesting terms. We inspect either density regulation or Allee type
density regulated models [Saha et al., Ecological Modelling, 2013], which have
substantial applications in the herring fish population's viability study. Both
the deterministic models we consider here contain bi-stability under certain
restrictions, and in that case, one of the stable states is the extinction
state. We assume that the dynamical system under consideration is closed, i.e.,
immigration and emigration are absent. The demographic noise is introduced in
the system by substituting an ordinary differential equation with a stochastic
differential equation model, where the birth and death rates of the
deterministic process are used to obtain the instantaneous mean and variance in
the stochastic differential equation. Our study reveals that, the catastrophic
changes can be avoided manually by a suitable choice of handling time that will
eventually help to prevent the sudden extinction of the harvested population.
The entire study is illustrated through the herring population size data
obtained from the Global Population Dynamics Database (GPDD) and simulation
experiment.",http://arxiv.org/abs/2108.07534v1
"Adaptive Inverse Mapping: A Model-free Semi-supervised Learning Approach
  towards Robust Imaging through Dynamic Scattering Media",2021-08-18T19:42:14Z,"Xiaowen Hu, Jian Zhao, Jose Enrique Antonio-Lopez, Stefan Gausmann, Rodrigo Amezcua Correa, Axel Schulzgen","Imaging through scattering media is a useful and yet demanding task since it
involves solving for an inverse mapping from speckle images to object images.
It becomes even more challenging when the scattering medium undergoes dynamic
changes. Various approaches have been proposed in recent years. However, to
date, none is able to preserve high image quality without either assuming a
finite number of sources for dynamic changes, assuming a thin scattering
medium, or requiring the access to both ends of the medium. In this paper, we
propose an adaptive inverse mapping (AIP) method which is flexible regarding
any dynamic change and only requires output speckle images after
initialization. We show that the inverse mapping can be corrected through
unsupervised learning if the output speckle images are followed closely. We
test the AIP method on two numerical simulations, namely, a dynamic scattering
system formulated as an evolving transmission matrix and a telescope with a
changing random phase mask at a defocus plane. Then we experimentally apply the
AIP method on a dynamic fiber-optic imaging system. Increased robustness in
imaging is observed in all three cases. With the excellent performance, we see
the great potential of the AIP method in imaging through dynamic scattering
media.",http://arxiv.org/abs/2108.08364v1
"A Projected Gradient Method for Opinion Optimization with Limited
  Changes of Susceptibility to Persuasion",2021-08-22T22:58:15Z,"Naoki Marumo, Atsushi Miyauchi, Akiko Takeda, Akira Tanaka","Many social phenomena are triggered by public opinion that is formed in the
process of opinion exchange among individuals. To date, from the engineering
point of view, a large body of work has been devoted to studying how to
manipulate individual opinions so as to guide public opinion towards the
desired state. Recently, Abebe et al. (KDD 2018) have initiated the study of
the impact of interventions at the level of susceptibility rather than the
interventions that directly modify individual opinions themselves. For the
model, Chan et al. (The Web Conference 2019) designed a local search algorithm
to find an optimal solution in polynomial time. However, it can be seen that
the solution obtained by solving the above model might not be implemented in
real-world scenarios. In fact, as we do not consider the amount of changes of
the susceptibility, it would be too costly to change the susceptibility values
for agents based on the solution.
  In this paper, we study an opinion optimization model that is able to limit
the amount of changes of the susceptibility in various forms. First we
introduce a novel opinion optimization model, where the initial susceptibility
values are given as additional input and the feasible region is defined using
the $\ell_p$-ball centered at the initial susceptibility vector. For the
proposed model, we design a projected gradient method that is applicable to the
case where there are millions of agents. Finally we conduct thorough
experiments using a variety of real-world social networks and demonstrate that
the proposed algorithm outperforms baseline methods.",http://arxiv.org/abs/2108.09865v1
Bernoullicity of lopsided principal algebraic actions,2021-08-23T03:08:14Z,"Hanfeng Li, Kairan Liu","We show that the principal algebraic actions of countably infinite groups
associated to lopsided elements in the integral group ring satisfying some
orderability condition are Bernoulli.",http://arxiv.org/abs/2108.09907v2
"Oh My Mistake!: Toward Realistic Dialogue State Tracking including
  Turnback Utterances",2021-08-28T12:10:50Z,"Takyoung Kim, Yukyung Lee, Hoonsang Yoon, Pilsung Kang, Junseong Bang, Misuk Kim","The primary purpose of dialogue state tracking (DST), a critical component of
an end-to-end conversational system, is to build a model that responds well to
real-world situations. Although we often change our minds from time to time
during ordinary conversations, current benchmark datasets do not adequately
reflect such occurrences and instead consist of over-simplified conversations,
in which no one changes their mind during a conversation. As the main question
inspiring the present study, ""Are current benchmark datasets sufficiently
diverse to handle casual conversations in which one changes their mind after a
certain topic is over?"" We found that the answer is ""No"" because DST models
cannot refer to previous user preferences when template-based turnback
utterances are injected into the dataset. Even in the the simplest
mind-changing (turnback) scenario, the performance of DST models significantly
degenerated. However, we found that this performance degeneration can be
recovered when the turnback scenarios are explicitly designed in the training
set, implying that the problem is not with the DST models but rather with the
construction of the benchmark dataset.",http://arxiv.org/abs/2108.12637v3
"Effect of small cation occupancy and anomalous Griffiths phase disorder
  in nonstoichiometric magnetic perovskites",2021-08-30T14:11:55Z,"Sagar Ghorai, Vitalii Shtender, Petter Ström, Ridha Skini, Peter Svedlindh","The structural, magnetic, magnetocaloric and Griffiths phase (GP) disorder of
non-stoichiometric perovskite manganites La_(0.8-x) Sr_(0.2-y) Mn_(1+x+y) O_3
are reported here. Determination of valence states and structural phases
evidenced that the smaller cations Mn2+ and Mn3+ will not occupy the A-site of
a perovskite under atmospheric synthesis conditions. The same analysis also
supports that the vacancy in the A-site of a perovskite induces a similar
vacancy in the B-site. The La3+ and Sr2+ cation substitutions in the A-site
with vacancy influences the magnetic phase transition temperature (TC)
inversely, which is explained in terms of the electronic bandwidth change. An
anomalous non-linear change of the GP has been observed in the Sr-substituted
compounds. The agglomeration of Mn3+-Mn4+ pairs (denoted as dimerons), into
small ferromagnetic clusters, has been identified as the reason for the
occurrence of the GP. A threshold limit of the dimeron formation explains the
observed non-linear behaviour of the GP formation. The Sr-substituted compounds
show a relatively large value of isothermal entropy change (maximum 3.27 J/kgK
at {\mu}_0 H=2T) owing to its sharp magnetic transition, while the broad change
of magnetization in the La-substituted compound enhances the relative cooling
power (maximum 98 J/kg at {\mu}_0 H=2T).",http://arxiv.org/abs/2108.13251v2
A Broad Ensemble Learning System for Drifting Stream Classification,2021-10-07T15:01:33Z,"Sepehr Bakhshi, Pouya Ghahramanian, Hamed Bonab, Fazli Can","In a data stream environment, classification models must handle concept drift
efficiently and effectively. Ensemble methods are widely used for this purpose;
however, the ones available in the literature either use a large data chunk to
update the model or learn the data one by one. In the former, the model may
miss the changes in the data distribution, and in the latter, the model may
suffer from inefficiency and instability. To address these issues, we introduce
a novel ensemble approach based on the Broad Learning System (BLS), where mini
chunks are used at each update. BLS is an effective lightweight neural
architecture recently developed for incremental learning. Although it is fast,
it requires huge data chunks for effective updates, and is unable to handle
dynamic changes observed in data streams. Our proposed approach named Broad
Ensemble Learning System (BELS) uses a novel updating method that significantly
improves best-in-class model accuracy. It employs an ensemble of output layers
to address the limitations of BLS and handle drifts. Our model tracks the
changes in the accuracy of the ensemble components and react to these changes.
We present the mathematical derivation of BELS, perform comprehensive
experiments with 20 datasets that demonstrate the adaptability of our model to
various drift types, and provide hyperparameter and ablation analysis of our
proposed model. Our experiments show that the proposed approach outperforms
nine state-of-the-art baselines and supplies an overall improvement of 13.28%
in terms of average prequential accuracy.",http://arxiv.org/abs/2110.03540v2
Nodal solutions for singular semilinear elliptic systems,2021-10-11T09:27:18Z,Abdelkrim Moussaoui,"n this paper, we prove existence of nodal solutions for singular semilinear
elliptic systems without variational structure where its both components are of
sign changing. Our approach is based on sub-supersolutions method combined with
perturbation arguments involving singular terms.",http://arxiv.org/abs/2110.05109v1
"Evolutionary drivers, morphological evolution and diversity dynamics of
  a surviving mammal clade: cainotherioids at the Eocene--Oligocene transition",2021-10-11T12:49:30Z,"R. Weppe, Maëva Orliac, G. Guinot, Fabien L. Condamine","The Eocene--Oligocene transition (EOT) represents a period of global
environmental changes particularly marked in Europe and coincides with a
dramatic biotic turnover. Here, using an exceptional fossil preservation, we
document and analyse the diversity dynamics of a mammal clade, Cainotherioidea
(Artiodactyla), that survived the EOT and radiated rapidly immediately after.
We infer their diversification history from Quercy Konzentrat--Lagerst{\""a}tte
(south-west France) at the species level using Bayesian birth--death models. We
show that cainotherioid diversity fluctuated through time, with extinction
events at the EOT and in the late Oligocene, and a major speciation burst in
the early Oligocene. The latter is in line with our finding that cainotherioids
had a high morphological adaptability following environmental changes
throughout the EOT, which probably played a key role in the survival and
evolutionary success of this clade in the aftermath. Speciation is positively
associated with temperature and continental fragmentation in a time-continuous
way, while extinction seems to synchronize with environmental change in a
punctuated way. Within-clade interactions negatively affected the cainotherioid
diversification, while inter-clade competition might explain their final
decline during the late Oligocene. Our results provide a detailed dynamic
picture of the evolutionary history of a mammal clade in a context of global
change.",http://arxiv.org/abs/2110.05232v1
Optimizing Ranking Systems Online as Bandits,2021-10-12T08:07:46Z,Chang Li,"Ranking system is the core part of modern retrieval and recommender systems,
where the goal is to rank candidate items given user contexts. Optimizing
ranking systems online means that the deployed system can serve user requests,
e.g., queries in the web search, and optimize the ranking policy by learning
from user interactions, e.g., clicks. Bandit is a general online learning
framework and can be used in our optimization task. However, due to the unique
features of ranking, there are several challenges in designing bandit
algorithms for ranking system optimization. In this dissertation, we study and
propose solutions for four challenges in optimizing ranking systems online:
effectiveness, safety, nonstationarity, and diversification. First, the
effectiveness is related to how fast the algorithm learns from interactions. We
study the effective online ranker evaluation task and propose the MergeDTS
algorithm to solve the problem effectively. Second, the deployed algorithm
should be safe, which means the algorithm only displays reasonable content to
user requests. To solve the safe online learning to rank problem, we propose
the BubbleRank algorithm. Third, as users change their preferences constantly,
the algorithm should handle the nonstationarity. We formulate this
nonstationary online learning to rank problem as cascade non-stationary bandits
and propose CascadeDUCB and CascadeSWUCB algorithms to solve the problem.
Finally, the contents in ranked lists should be diverse. We consider the
results diversification task and propose the CascadeHybird algorithm that
considers both the item relevance and results diversification when learning
from user interactions.",http://arxiv.org/abs/2110.05807v1
Transmission of coherent information at the onset of interactions,2021-10-13T05:14:38Z,"Emily Kendall, Barbara Šoda, Achim Kempf","In this work, we investigate the parameters governing the rate at which a
quantum channel arises at the onset of an interaction between two systems, $A$
and $B$. In particular, when system $A$ is pre-entangled with an ancilla,
$\tilde{A}$, we quantify the early-time transmission of pre-existing
entanglement by calculating the leading order change in coherent information of
the complementary channel ($A\rightarrow B'$). We show that, when $A$ and $B$
are initially unentangled and $B$ is pure, there is no change in coherent
information to first order, while the leading (second) order change is
divergent. However, this divergence may be regulated by embedding the
conventional notion of coherent information into what we call the family of
$n$-coherent informations, defined using $n$-R\'enyi entropies. We find that
the rate of change of the $n$-coherent information at the onset of the
interaction is governed by a quantity, which we call the $n$-exposure, which
captures the extent to which the initial coherent information of $A$ with
$\tilde{A}$ is exposed to or `seen by' the interaction Hamiltonian between $A$
and $B$. We give examples in qubit systems and in the light-matter interaction.",http://arxiv.org/abs/2110.06499v2
"Synthetic Aperture Radar Image Change Detection via Siamese Adaptive
  Fusion Network",2021-10-18T06:41:44Z,"Yunhao Gao, Feng Gao, Junyu Dong, Qian Du, Heng-Chao Li","Synthetic aperture radar (SAR) image change detection is a critical yet
challenging task in the field of remote sensing image analysis. The task is
non-trivial due to the following challenges: Firstly, intrinsic speckle noise
of SAR images inevitably degrades the neural network because of error gradient
accumulation. Furthermore, the correlation among various levels or scales of
feature maps is difficult to be achieved through summation or concatenation.
Toward this end, we proposed a siamese adaptive fusion network for SAR image
change detection. To be more specific, two-branch CNN is utilized to extract
high-level semantic features of multitemporal SAR images. Besides, an adaptive
fusion module is designed to adaptively combine multiscale responses in
convolutional layers. Therefore, the complementary information is exploited,
and feature learning in change detection is further improved. Moreover, a
correlation layer is designed to further explore the correlation between
multitemporal images. Thereafter, robust feature representation is utilized for
classification through a fully-connected layer with softmax. Experimental
results on four real SAR datasets demonstrate that the proposed method exhibits
superior performance against several state-of-the-art methods. Our codes are
available at https://github.com/summitgao/SAR_CD_SAFNet.",http://arxiv.org/abs/2110.09049v1
"Gradient-Based Mixed Planning with Symbolic and Numeric Action
  Parameters",2021-10-19T14:21:19Z,"Kebing Jin, Hankz Hankui Zhuo, Zhanhao Xiao, Hai Wan, Subbarao Kambhampati","Dealing with planning problems with both logical relations and numeric
changes in real-world dynamic environments is challenging. Existing numeric
planning systems for the problem often discretize numeric variables or impose
convex constraints on numeric variables, which harms the performance when
solving problems. In this paper, we propose a novel algorithm framework to
solve numeric planning problems mixed with logical relations and numeric
changes based on gradient descent. We cast the numeric planning with logical
relations and numeric changes as an optimization problem. Specifically, we
extend syntax to allow parameters of action models to be either objects or
real-valued numbers, which enhances the ability to model real-world numeric
effects. Based on the extended modeling language, we propose a gradient-based
framework to simultaneously optimize numeric parameters and compute appropriate
actions to form candidate plans. The gradient-based framework is composed of an
algorithmic heuristic module based on propositional operations to select
actions and generate constraints for gradient descent, an algorithmic
transition module to update states to next ones, and a loss module to compute
loss. We repeatedly minimize loss by updating numeric parameters and compute
candidate plans until it converges into a valid plan for the planning problem.
In the empirical study, we exhibit that our algorithm framework is both
effective and efficient in solving planning problems mixed with logical
relations and numeric changes, especially when the problems contain obstacles
and non-linear numeric effects.",http://arxiv.org/abs/2110.10007v2
The onset of molecule-spanning dynamics in a multi-domain protein,2021-10-20T10:59:02Z,"Benedikt Sohmen, Christian Beck, Tilo Seydel, Ingo Hoffmann, Bianca Hermann, Mark Nüesch, Marco Grimaldo, Frank Schreiber, Steffen Wolf, Felix Roosen-Runge, Thorsten Hugel","Protein dynamics has been investigated on a wide range of time scales. Nano-
and picosecond dynamics have been assigned to local fluctuations, while slower
dynamics have been attributed to larger conformational changes. However, it is
largely unknown how local fluctuations can lead to global allosteric changes.
Here we show that molecule-spanning dynamics on the 100 ns time scale precede
larger allosteric changes. We assign global real-space movements to dynamic
modes on the 100 ns time scales, which became possible by a combination of
single-molecule fluorescence, quasi-elastic neutron scattering and all-atom MD
simulations. Additionally, we demonstrate the effect of Sba1, a co-chaperone of
Hsp90, on these molecule-spanning dynamics, which implies functional importance
of such dynamics. Our integrative approach provides comprehensive insights into
molecule-spanning dynamics on the nanosecond time scale for a multi-domain
protein and indicates that such dynamics are the molecular basis for allostery
and large conformational changes in proteins.",http://arxiv.org/abs/2110.10483v2
"Operational Characterization of a Public Scientific Datacenter During
  and Beyond the COVID-19 Period",2021-10-23T15:28:43Z,Mehmet Berk Cetin,"Datacenters are imperative for the digital society. They offer services such
as computing, telecommunication, media, and entertainment. Datacenters,
however, consume a lot of power. Thus, Improving datacenter operations is
important and may result in better services, reduced energy consumption and
reduced costs. To improve datacenters, we must understand what is going on
inside them. Therefore, we use operational traces from a scientific cluster in
the Netherlands to investigate and understand how that cluster operates. Due to
work-from-home circumstance, the covid period might have changed our daily
usage of online applications, such as zoom and google meet. In this research,
we focus on the operations of a scientific cluster (LISA) inside the SURF
datacenter. The global pandemic might have changed how the LISA cluster
operates. To understand the change, we collect, combine, and analyze
operational logs from the LISA cluster. The tool to collect the data that
belongs to the non-covid period was accomplished in previous research.
Nonetheless, both the tool and instrument to combine and analyze the traces are
lacking. This research focuses on designing an instrument that can combine and
analyze the traces during and before the coronavirus period. The instrument can
also produce graphs for customarily selected rack, nodes and periods. Moreover,
we characterize the traces that belong to the coronavirus period using the
scientific instrument and additional tools. The outcome of this research helps
us understand how the operations for a scientific cluster (LISA) in the
Netherlands has changed after the global pandemic.",http://arxiv.org/abs/2110.12244v1
Singular loci of sparse resultants,2021-10-26T17:28:36Z,Evgeny Statnik,"We study the singularity locus of the sparse resultant of two univariate
polynomials, and apply our results to estimate singularities of a coordinate
projection of a generic spatial complete intersection curve.",http://arxiv.org/abs/2110.13872v2
"A spatio-temporal analysis of NO$_2$ concentrations during the Italian
  2020 COVID-19 lockdown",2021-10-28T11:02:22Z,"Guido Fioravanti, Michela Cameletti, Sara Martino, Giorgio Cattani, Enrico Pisoni","When a new environmental policy or a specific intervention is taken in order
to improve air quality, it is paramount to assess and quantify - in space and
time - the effectiveness of the adopted strategy. The lockdown measures taken
worldwide in 2020 to reduce the spread of the SARS-CoV- 2 virus can be
envisioned as a policy intervention with an indirect effect on air quality. In
this paper we propose a statistical spatio-temporal model as a tool for
intervention analysis, able to take into account the effect of weather and
other confounding factors, as well as the spatial and temporal correlation
existing in the data. In particular, we focus here on the 2019/2020 relative
change in nitrogen dioxide (NO$_2$) concentrations in the north of Italy, for
the period of March and April during which the lockdown measure was in force.
As an output, we provide a collection of weekly continuous maps, describing the
spatial pattern of the NO$_2$ 2019/2020 relative changes. We found that during
March and April 2020 most of the studied area is characterized by negative
relative changes (median values around -25%), with the exception of the first
week of March and the fourth week of April (median values around 5%). As these
changes cannot be attributed to a weather effect, it is likely that they are a
byproduct of the lockdown measures.",http://arxiv.org/abs/2110.15020v1
"REACT: Distributed Mobile Microservice Execution Enabled by Efficient
  Inter-Process Communication",2021-01-04T11:47:01Z,Chathura Sarathchandra,"The increased mobile connectivity, the range and number of services available
in various computing environments in the network, demand mobile applications to
be highly dynamic to be able to efficiently incorporate those services into
applications, along with other local capabilities on mobile devices. However,
the monolithic structure and mostly static configuration of mobile application
components today limit application's ability to dynamically manage internal
components, to be able to adapt to the user and the environment, and utilize
various services in the network for improving the application experience.
  In this paper, we present REACT, a new Android-based framework that enables
apps to be developed as a collection of loosely coupled microservices (MS). It
allows individual distribution, dynamic management and offloading of MS to be
executed by services in the network, based on contextual changes. REACT aims to
provide i) a framework as an Android Library for creating MS-based apps that
adapt to contextual changes ii) a unified HTTP-based communication mechanism,
using Android Inter-Process Communication (IPC) for transporting requests
between locally running MS, while allowing flexible and transparent switching
between network and IPC requests, when offloading. We evaluate REACT by
implementing a video streaming app that dynamically offloads MS to web services
in the network, adapting to contextual changes. The evaluation shows the
adaptability to contextual changes and reductions in power consumption when
offloading, while our communication mechanism overcomes performance limitations
of Android IPC by enabling efficient transferring of large payloads between
mobile MS.",http://arxiv.org/abs/2101.00902v1
Viewing angle effects in quasar application to cosmology,2021-01-04T21:43:55Z,"Raj Prince, Bozena Czerny, Agnieszka Pollo","The symmetry axes of active galactic nuclei (AGN) are randomly distributed in
space but highly inclined sources are heavily obscured and are not seen as
quasars with broad emission lines. The obscuring torus geometry determines the
average viewing angle, and if the torus geometry changes with the redshift,
this average viewing angle will also change. Thus the ratio between the
isotropic luminosity and observed luminosity may change systematically with
redshift. Therefore, if we use quasars to measure the luminosity distance by
evaluating the isotropic absolute luminosity and measuring the observed flux,
we can have a redshift-dependent bias which can propagate to cosmological
parameters. We propose a toy model for testing the effect of viewing angle
uncertainty on measurement of the luminosity distance. The model is based on
analytical description of the obscuring torus applied to one-parameter
observational data. It illustrates the possible change of the torus covering
factor between the two chosen redshift ranges. We have estimated the possible
error on specific cosmological parameters (H0,Omega_m) for the flat Lambda-CDM
cosmology if a method is calibrated at low redshift and applied to the higher
redshift. The errors on cosmological parameters due to potential dependence of
viewing angle on redshift are found to be potentially significant, and the
effect will have to be accommodated in the future in all quasar-based
cosmological methods. A careful systematic study of AGN mean viewing angle
across redshift is necessary, with the use of appropriate samples and models
which uniquely determine the inclination of each source.",http://arxiv.org/abs/2101.01244v1
Updates to the One-loop Provider NLOX,2021-01-05T01:28:37Z,"Diogenes Figueroa, Seth Quackenbush, Laura Reina, Christian Reuschle","We describe the 1.2 update to NLOX, a computer program for calculations in
high-energy particle physics. New features since the 1.0 release and other
changes are described, along with usage documentation.",http://arxiv.org/abs/2101.01305v1
"Does double-blind peer-review reduce bias? Evidence from a top computer
  science conference",2021-01-07T18:59:26Z,"Mengyi Sun, Jainabou Barry Danfa, Misha Teplitskiy","Peer review is widely regarded as essential for advancing scientific
research. However, reviewers may be biased by authors' prestige or other
characteristics. Double-blind peer review, in which the authors' identities are
masked from the reviewers, has been proposed as a way to reduce reviewer bias.
Although intuitive, evidence for the effectiveness of double-blind peer review
in reducing bias is limited and mixed. Here, we examine the effects of
double-blind peer review on prestige bias by analyzing the peer review files of
5027 papers submitted to the International Conference on Learning
Representations (ICLR), a top computer science conference that changed its
reviewing policy from single-blind peer review to double-blind peer review in
2018. We find that after switching to double-blind review, the scores given to
the most prestigious authors significantly decreased. However, because many of
these papers were above the threshold for acceptance, the change did not affect
paper acceptance decisions significantly. Nevertheless, we show that
double-blind peer review may have improved the quality of the selections by
limiting other (non-author-prestige) biases. Specifically, papers rejected in
the single-blind format are cited more than those rejected under the
double-blind format, suggesting that double-blind review better identifies
poorer quality papers. Interestingly, an apparently unrelated change - the
change of rating scale from 10 to 4 points - likely reduced prestige bias
significantly, to an extent that affected papers' acceptance. These results
provide some support for the effectiveness of double-blind review in reducing
prestige bias, while opening new research directions on the impact of peer
review formats.",http://arxiv.org/abs/2101.02701v1
"Gate-tunable direct and inverse electrocaloric effect in trilayer
  graphene",2021-01-08T15:28:19Z,"Natalia Cortés, Oscar Negrete, Francisco J. Peña, Patricio Vargas","The electrocaloric (EC) effect is the reversible change in temperature and/or
entropy of a material when it is subjected to an adiabatic electric field
change. Our tight-binding calculations linked to Fermi statistics, show that
the EC effect is sensitive to the stacking arrangement in trilayer graphene
(TLG) structures connected to a heat source, and is produced by changes of the
electronic density of states (DOS) near the Fermi level when external gate
fields are applied on the outer graphene layers. We demonstrate the AAA-stacked
TLG presents an inverse EC response (cooling), whereas the EC effect in
ABC-stacked TLG remains direct (heating) regardless of the applied gate field
potential strength. We reveal otherwise the TLG with Bernal-ABA stacking
geometry generates both the inverse and direct EC response in the same sample,
associated with a gate-dependent electronic entropy transition at finite
temperature. By varying the chemical potential to different Fermi levels, we
find maxima and minima of the DOS are located near the extremes of the
electronic entropy, which are correlated with sign changes in the differential
entropy per particle, giving a particular experimentally measurable electronic
entropy spectrum for each TLG geometry. The EC effect in quantum
two-dimensional layered systems may bring a wide variety of prototype van der
Waals materials that could be used as versatile platforms to controlling the
temperature in nanoscale electronic devices required in modern portable on-chip
technologies.",http://arxiv.org/abs/2101.03062v1
Towards Long-term Fairness in Recommendation,2021-01-10T17:36:28Z,"Yingqiang Ge, Shuchang Liu, Ruoyuan Gao, Yikun Xian, Yunqi Li, Xiangyu Zhao, Changhua Pei, Fei Sun, Junfeng Ge, Wenwu Ou, Yongfeng Zhang","As Recommender Systems (RS) influence more and more people in their daily
life, the issue of fairness in recommendation is becoming more and more
important. Most of the prior approaches to fairness-aware recommendation have
been situated in a static or one-shot setting, where the protected groups of
items are fixed, and the model provides a one-time fairness solution based on
fairness-constrained optimization. This fails to consider the dynamic nature of
the recommender systems, where attributes such as item popularity may change
over time due to the recommendation policy and user engagement. For example,
products that were once popular may become no longer popular, and vice versa.
As a result, the system that aims to maintain long-term fairness on the item
exposure in different popularity groups must accommodate this change in a
timely fashion.
  Novel to this work, we explore the problem of long-term fairness in
recommendation and accomplish the problem through dynamic fairness learning. We
focus on the fairness of exposure of items in different groups, while the
division of the groups is based on item popularity, which dynamically changes
over time in the recommendation process. We tackle this problem by proposing a
fairness-constrained reinforcement learning algorithm for recommendation, which
models the recommendation problem as a Constrained Markov Decision Process
(CMDP), so that the model can dynamically adjust its recommendation policy to
make sure the fairness requirement is always satisfied when the environment
changes. Experiments on several real-world datasets verify our framework's
superiority in terms of recommendation performance, short-term fairness, and
long-term fairness.",http://arxiv.org/abs/2101.03584v1
"Accretion Geometry in the Hard State of the Black-Hole X-Ray Binary MAXI
  J1820+070",2021-01-12T14:05:40Z,"Andrzej A. Zdziarski, Marta A. Dzielak, Barbara De Marco, Michal Szanecki, Andrzej Niedzwiecki","We study X-ray spectra from the outburst rise of the accreting black-hole
binary MAXI J1820+070. We find that models having the disk inclinations within
those of either the binary or the jet imply significant changes of the
accretion disk inner radius during the luminous part of the hard spectral
state, with that radius changing from $>$100 to $\sim$10 gravitational radii.
The main trend is a decrease with the decreasing spectral hardness. Our
analysis requires the accretion flow to be structured, with at least two
components with different spectral slopes. The harder component dominates the
bolometric luminosity and produces strong, narrow, X-ray reflection features.
The softer component is responsible for the underlying broader reflection
features. The data are compatible with the harder component having a large
scale height, located downstream the disk truncation radius, and reflecting
mostly from remote parts of the disk. The softer component forms a corona above
the disk up to some transition radius. Our findings can explain the changes of
the characteristic variability time scales, found in other works, as being
driven by the changes of the disk characteristic radii.",http://arxiv.org/abs/2101.04482v3
Consecutive primes which are widely digitally delicate,2021-01-22T00:25:15Z,"Michael Filaseta, Jacob Juillerat","We show that for every positive integer $k$, there exist $k$ consecutive
primes having the property that if any digit of any one of the primes,
including any of the infinitely many leading zero digits, is changed, then that
prime becomes composite.",http://arxiv.org/abs/2101.08898v1
"The convergence rate of of multivariate operators on simplex in Orlicz
  space",2021-01-22T01:38:04Z,"Wan Ma, Lihong Chang, Yongxia Qiang","The approximation of functions in Orlicz space by multivariate operators on
simplex is considered. The convergence rate is given by using modulus of
smoothness.",http://arxiv.org/abs/2101.08915v1
"Insights into the Impact of COVID-19 on Bicycle Usage in Colorado
  Counties",2021-01-20T04:55:03Z,"Abdullah Kurkcu, Ilgin Gokasar, Onur Kalan, Alperen Timurogullari, Burak Altin","Coronavirus, which emerged in China towards the end of 2019 and subsequently
influenced the whole world, has changed the daily lives of people to a great
extent. In many parts of the world, in both cities and rural areas, people have
been forced to stay home weeks. They have only been allowed to leave home for
fundamental needs such as food and health needs, and most started to work from
home. In this period, very few people, including essential workers, had to
leave their homes. Avoiding social contact is proven to be the best method to
reduce the spread of the novel Coronavirus. Because of the COVID-19 pandemic,
people are adapting their behavior to this new reality, and it may change the
type of public events people perform and how people go to these activities.
Consumer behaviors have been altered during the pandemic. While people try to
avoid gatherings, they also stayed away from mass transport modes and turned to
private modes of transportation more -- private cars, private taxis and
bike-sharing systems; even walking became more popular. In this study, we
attempt to analyze how the use of bicycling has changed -- pre- and
post-pandemic -- using open data sources and investigating how socio-economics
characteristics affect this change. The results showed that average income,
average education level, and total population are the most crucial variables
for the Pandemic to Transition period and the Transition to the Normalization
period.",http://arxiv.org/abs/2101.10130v1
"Effect of rate of change of parameter on early warning signals for
  critical transitions",2021-01-28T04:33:24Z,"Induja Pavithran, R. I. Sujith","Many dynamical systems exhibit abrupt transitions or tipping as the control
parameter is varied. In scenarios where the parameter is varied continuously,
the rate of change of control parameter greatly affects the performance of
early warning signals (EWS) for such critical transitions.We study the impact
of variation of the control parameter with a finite rate on the performance of
\textcolor{black}{EWS for critical transitions} in a thermoacoustic system (a
horizontal Rijke tube) exhibiting subcritical Hopf bifurcation. There is a
growing interest in developing early warning signals for tipping in real
systems. Firstly, we explore the efficacy of early warning signals based on
critical slowing down and fractal characteristics. From this study, lag-1
autocorrelation (AC) and Hurst exponent H are found to be good measures to
predict the transition well-before the tipping point. The warning time,
obtained using AC and $H$, reduces with an increase in the rate of change of
the control parameter following an inverse power law relation. Hence, for very
fast rates, the warning time may be too short to perform any control action.
Furthermore, we report the observation of a hyperexponential scaling relation
between the AC and the variance of fluctuations during such dynamic Hopf
bifurcation. We construct a theoretical model for noisy Hopf bifurcation
wherein the control parameter is continuously varied at different rates to
study the effect of rate of change of parameter on EWS. Similar results,
including the hyperexponential scaling, are observed in the model as well.",http://arxiv.org/abs/2101.11811v1
"Influence of Biomass Emissions upon Habitability, Biosignatures and
  Detectability in Earth-like Atmospheres",2021-01-30T12:43:42Z,"Stefanie Gebauer, Iva Vilović, John Lee Grenfell, Fabian Wunderlich, Franz Schreier, Heike Rauer","We investigate atmospheric responses of modeled hypothetical Earth-like
planets in the habitable zone of the M-dwarf AD Leonis to reduced oxygen (O2),
removed biomass (dead Earth), varying carbon dioxide (CO2) and surface relative
humidity (sRH). Results suggest large O2 differences between the reduced O2 and
dead scenarios in the lower but not the upper atmosphere. Ozone (O3) and
nitrous oxide (N2O) also show this behavior. Methane depends on hydroxyl (OH),
its main sink. Abiotic production of N2O occurs in the upper layers.
Chloromethane (CH3Cl) decreases everywhere on decreasing biomass. Changing CO2
(from x1 to x100 present atmospheric level (PAL)) and surface relative humidity
(sRH) (from 0.1 percent to 100 percent) does not influence CH3Cl as much as
lowering biomass. Therefore, CH3Cl can be considered a good biosignature.
Changing sRH and CO2 has a greater influence on temperature than O2 and biomass
alone. Changing the biomass produces ~6 kilometer (km) in effective height (H)
in transmission compared with changing CO2 and sRH ( about 25km). In
transmission O2 is discernible at 0.76 microns for greater than 0.1 PAL. The O3
9.6 micron band was weak for the low O2 runs and difficult to discern from dead
Earth, however O3 at 0.3 microns could serve as an indicator to distinguish
between reduced O2 and dead Earth. Spectral features of N2O and CH3Cl
corresponded to some km H. CH4 could be detectable tens of parsecs away with
ELT except for the 10-4 and 10-6 PAL O2 scenarios. O2 is barely detectable for
the 1 PAL O2 case and unfeasible at lower abundances.",http://arxiv.org/abs/2102.00220v1
"Fake it Till You Make it: Self-Supervised Semantic Shifts for
  Monolingual Word Embedding Tasks",2021-01-30T18:59:43Z,"Maurício Gruppi, Sibel Adalı, Pin-Yu Chen","The use of language is subject to variation over time as well as across
social groups and knowledge domains, leading to differences even in the
monolingual scenario. Such variation in word usage is often called lexical
semantic change (LSC). The goal of LSC is to characterize and quantify language
variations with respect to word meaning, to measure how distinct two language
sources are (that is, people or language models). Because there is hardly any
data available for such a task, most solutions involve unsupervised methods to
align two embeddings and predict semantic change with respect to a distance
measure. To that end, we propose a self-supervised approach to model lexical
semantic change by generating training samples by introducing perturbations of
word vectors in the input corpora. We show that our method can be used for the
detection of semantic change with any alignment method. Furthermore, it can be
used to choose the landmark words to use in alignment and can lead to
substantial improvements over the existing techniques for alignment.
  We illustrate the utility of our techniques using experimental results on
three different datasets, involving words with the same or different meanings.
Our methods not only provide significant improvements but also can lead to
novel findings for the LSC problem.",http://arxiv.org/abs/2102.00290v1
Some remarks on rotation theorems for complex polynomials,2021-02-02T08:04:04Z,V. N. Dubinin,"For any complex polynomial P having all its zeros in the unit disk, we
estimate the rate of change of the argument P (z) when the point z runs through
the boundary of this disk.",http://arxiv.org/abs/2102.01376v1
"Interfacial Tension Modulation of Liquid Metal via Electrochemical
  Oxidation",2021-02-04T02:52:29Z,"Minyung Song, Karen E. Daniels, Abolfazl Kiani, Sahar Rashidnadimi, Michael D. Dickey","This progress report summarizes recent studies of electrochemical oxidation
to modulate the interfacial tension of gallium-based alloys. These alloys,
which are liquid at ambient conditions, have the largest interfacial tension of
any liquid at room temperature. The ability to modulate the tension offers the
possibility to create forces that change the shape and position of the metal.
It has been known since the late 1800s that electrocapillarity-the use of
potential to modulate the electric double layer on the surface of metals in
electrolyte-lowers the interfacial tension of liquid metal. Yet, this
phenomenon can only achieve modest changes in interfacial tension since it is
limited to potential windows that avoid reactions. A recent discovery suggests
that reactions driven by the electrochemical oxidation of gallium alloys cause
the interfacial tension to decrease from ~500 mN/m at 0 V to ~0 mN/m at ~0.8 V,
a change in tension that goes well beyond what is possible via conventional
electrocapillarity or surfactants. The changes in tension are reversible;
reductive potentials return the metal back to a state of high interfacial
tension. This report aims to summarize key work and introduce beginners to this
field by including electrochemistry basics while addressing misconceptions. We
discuss applications that utilize modulations in interfacial tension of liquid
metal and conclude with remaining opportunities and challenges that need
further investigation.",http://arxiv.org/abs/2102.02383v1
"Trajectory Planning for Connected and Automated Vehicles at Isolated
  Signalized Intersections under Mixed Traffic Environment",2021-02-06T05:42:18Z,"Chengyuan Ma, Chunhui Yu, Xiaogunag Yang","Trajectory planning for connected and automated vehicles (CAVs) has the
potential to improve operational efficiency and vehicle fuel economy in traffic
systems. Despite abundant studies in this research area, most of them only
consider trajectory planning in the longitudinal dimension or assume the fully
CAV environment. This study proposes an approach to the decentralized planning
of CAV trajectories at an isolated signalized intersection under the mixed
traffic environment, which consists of connected and human-driven vehicles
(CHVs) and CAVs. A bi-level optimization model is formulated based on discrete
time to optimize the trajectory of a single CAV in both the longitudinal and
lateral dimensions given signal timings and the trajectory information of
surrounding vehicles. The upper-level model optimizes lateral lane-changing
strategies. The lower-level model optimizes longitudinal acceleration profiles
based on the lane-changing strategies from the upper-level model. Minimization
of vehicle delay, fuel consumption, and lane-changing costs are considered in
the objective functions. A Lane-Changing Strategy Tree (LCST) and a Parallel
Monte-Carlo Tree Search (PMCTS) algorithm are designed to solve the bi-level
optimization model. CAV trajectories are planned one by one according to their
distance to the stop bar. A rolling horizon scheme is applied for the dynamic
implementation of the proposed model with time-varying traffic condition.
Numerical studies validate the advantages of the proposed trajectory planning
model compared with the benchmark cases without CAV trajectory planning.",http://arxiv.org/abs/2102.03518v1
"Structural, magnetic, thermodynamic and electrical transport properties
  of a new compound $\mbox{Pr}_2\mbox{Rh}_{2}\mbox{Ga}$",2021-02-08T10:19:06Z,Baidyanath Sahu,"A new ternary intermetallic compound $\mathrm{Pr_2Rh_2Ga}$ was synthesized by
arc-melting and was characterized by powder X-ray diffraction (PXRD),
magnetization, heat capacity $\mathrm{C}_p(\textit{T})$, and electrical
resistivity $\rho(T)$ measurements. PXRD patterns revealed that
$\mathrm{Pr_2Rh_2Ga}$ crystallizes in the $\rm{La_2Ni_3}$-type of orthorhombic
structure with the space group $Cmca$. The temperature variation of magnetic
susceptibility, $\mathrm {C}_p(\textit{T})$ and $\rho(T)$ confirmed that
$\mathrm{Pr_2Rh_2Ga}$ exhibits a ferromagnetic behavior with the transition
temperature of 18 K. The estimated Sommerfeld coefficient $\gamma$ = 640
mJ/($\mathrm{Pr.mole.K^2}$) from the $\mathrm {C}_p(\textit{T})$ results in the
paramagnetic region just above $T_{C}$~was large in comparison to ordinary
metals. In the paramagnetic region $\rho(T)$ data showed a metallic behavior
characteristic of electron - phonon scattering. The maximum negative
magneto-resistance at high field occurs in the region near the magnetic phase
transition temperature. The maximum value of magnetic entropy change ($\rm
-\Delta \textit{S}_{M}$) and adiabatic temperature change ($\rm \Delta
\textit{T}_{ad}$) are $\rm8.2~J/kg.K$ and $\rm3.6~K$, respectively, around the
transition temperature for the change of magnetic field 0-9 T. The calculated
refrigerant capacity is $\rm70~J/kg$, and $\rm135~J/kg$ for a change of
magnetic field 0-5 T and 0-9 T, respectively. Arrott plot derived from
isothermal magnetization and the universal scaling plot by normalizing $\rm
-\Delta \textit{S}_{M}$ confirm that the compound undergoes a second order
ferromagnetic to paramagnetic phase transition.",http://arxiv.org/abs/2102.04106v2
On Euler systems for adjoint Hilbert modular Galois representations,2021-02-11T23:10:47Z,Eric Urban,"We prove the existence of Euler systems for adjoint modular Galois
representations using deformations of
  Galois representations coming from Hilbert modular forms and relate them to
$p$-adic $L$-functions under a conjectural formula for the Fitting ideals of
some equivariant congruence modules for abelian base change.",http://arxiv.org/abs/2102.06305v1
Measuring the Internet during Covid-19 to Evaluate Work-from-Home,2021-02-15T10:13:12Z,"Xiao Song, John Heidemann","Covid-19 has radically changed our lives, with many governments and
businesses mandating work-from-home (WFH) and remote education. However,
work-from-home policy is not always known globally, and even when enacted,
compliance can vary. These uncertainties suggest a need to measure WFH and
confirm actual policy implementation. We show new algorithms that detect WFH
from changes in network use during the day. We show that change-sensitive
networks reflect mobile computer use, detecting WFH from changes in network
intensity, the diurnal and weekly patterns of IP address response. Our
algorithm provides new analysis of existing, continuous, global scans of most
of the responsive IPv4 Internet (about 5.1M /24 blocks). Reuse of existing data
allows us to study the emergence of Covid-19, revealing global reactions. We
demonstrate the algorithm in networks with known ground truth, evaluate the
data reconstruction and algorithm design choices with studies of real-world
data, and validate our approach by testing random samples against news reports.
In addition to Covid-related WFH, we also find other government-mandated
lockdowns. Our results show the first use of network intensity to infer-real
world behavior and policies.",http://arxiv.org/abs/2102.07433v5
Significant Inverse Magnetocaloric Effect induced by Quantum Criticality,2021-02-17T18:22:22Z,"Tao Liu, Xin-Yang Liu, Yuan Gao, Hai Jin, Jun He, Xian-Lei Sheng, Wentao Jin, Ziyu Chen, Wei Li","The criticality-enhanced magnetocaloric effect (MCE) near a field-induced
quantum critical point (QCP) in the spin systems constitutes a very promising
and highly tunable alternative to conventional adiabatic demagnetization
refrigeration. Strong fluctuations in the low-$T$ quantum critical regime can
give rise to a large thermal entropy change and thus significant cooling effect
when approaching the QCP. In this work, through efficient and accurate
many-body calculations, we show there exists a significant inverse MCE(iMCE) in
the spin-1 quantum chain materials(CH$_3$)$_4$NNi(NO$_2$)$_3$ (TMNIN) and
NiCl$_2$-4SC(NH$_2$)$_2$ (DTN), where DTN has substantial low-$T$ refrigeration
capacity while requiring only moderate magnetic fields. The iMCE
characteristics, including the adiabatic temperature change $\Delta T_{\rm
ad}$, isothermal entropy change $\Delta S$, differential Gr\""uneisen parameter,
and the entropy change rate, are obtained with quantum many-body calculations
at finite temperature. The cooling performance, i.e., the efficiency factor and
hold time, of the two compounds is also discussed. Based on the many-body
calculations on realistic models for the spin-chain materials, we conclude that
the compound DTN constitutes a very promising and highly efficient quantum
magnetic coolant with pronounced iMCE properties. We advocate that such quantum
magnets can be used in cryofree refrigeration for space applications and
quantum computing environments.",http://arxiv.org/abs/2102.08919v2
"Demonstrating change from a drop-in space soundscape exhibit by using
  graffiti walls both before and after",2021-02-19T09:50:06Z,"Martin Archer, Natt Day, Sarah Barnes","Impact evaluation in public engagement necessarily requires measuring change.
However, this is extremely challenging for drop-in activities due to their very
nature. We present a novel method of impact evaluation which integrates
graffiti walls into the experience both before and after the main drop-in
activity. The activity in question was a soundscape exhibit, where young
families experienced the usually inaudible sounds of near-Earth space in an
immersive and accessible way. We apply two analysis techniques to the captured
before and after data - quantitative linguistics and thematic analysis. These
analyses reveal significant changes in participants' responses after the
activity compared to before, namely an increased diversity in language used to
describe space and altered conceptions of what space is like. The results
demonstrate that the soundscape was surprisingly effective at innately
communicating key aspects of the underlying science simply through the act of
listening. The impacts also highlight the power of sonification in stimulating
public engagement, which, through reflection, can lead to altered associations,
perceptions, and understanding. Therefore, we show that this novel approach to
drop-in activity evaluation, using graffiti walls both before and after the
activity and applying rigorous analysis to this data, has the power to capture
change and, thus, have a short-term impact. We suggest that commonly used
evaluation tools suitable for drop-in activities, such as graffiti walls,
should be integrated both before and after the main activity in general, rather
than only using them afterwards as is typically the case.",http://arxiv.org/abs/2102.09833v1
Some remarks on vector valued distributions,2021-02-20T18:18:16Z,Tove Dahn,"We argue that the fundamental solution corresponding to a maximal rank
differential operator, where the symbol is regarded as a vector valued
distribution, is not necessarily very regular. Thus, for a fundamental
solution, the property of being very regular, is not invariant to change of
local coordinates.",http://arxiv.org/abs/2102.10411v1
"Phonon thermal transport properties of GaN with symmetry-breaking and
  lattice deformation induced by the electric field",2021-02-25T12:01:17Z,"Dao-Sheng Tang, Bing-Yang Cao","Electric fields commonly exist in semiconductor structures of electronics,
bringing to bear on phonon thermal transport. Also, it is a popular method to
tune thermal transport in solids. In this work, phonon and thermal transport
properties of GaN with wurtzite and zincblende structures at finite electric
field are investigated using first principles calculations from perspectives of
symmetry breaking and lattice deformation. Effects of electric field on phonon
transport properties including phonon dispersion and thermal conductivity from
response of electron density distribution only and response from lattice
changes are studied in zincblende GaN. It is found that the former has a small
but qualitative impact on phonon dispersion relations, i.e., splitting of
phonon branches, since it breaks symmetry of zincblende lattice. While the
latter affects both lattice symmetry and size, causing significant changes of
phonon properties and increase of thermal conductivity. In wurtzite GaN,
space-group-conserved lattice changes at finite electric field are studied with
lattice deformation only, where thermal conductivity decreases at electric
fields significantly with increase of anisotropy, much different from the
changes in zincblende GaN. This work provides a comprehensive understanding on
phonon thermal transport properties in GaN at finite electric field, which
promises to benefit phonon transport tuning and provide reference for thermal
management in GaN-based information and power electronics.",http://arxiv.org/abs/2102.12802v2
The Brauer group of a valuation ring,2021-04-06T04:58:14Z,Vivek Sadhu,"Let $V$ be a valuation ring and $K$ be its field of fraction. We show that
the canonical map $\Br(V) \to \Br(K)$ is injective.",http://arxiv.org/abs/2104.02286v2
Phase Change Memory by GeSbTe Electrodeposition in Crossbar Arrays,2021-04-06T07:52:58Z,"Yasir J Noori, Lingcong Meng, Ayoub H. Jaafar, Wenjian Zhang, Gabriela P. Kissling, Yisong Han, Nema Abdelazim, Kath Leblanc, Nikolay Zhelev, Ruomeng Huang, Richard Beanland, David C. Smith, Gill Reid, Kees de Groot, Philip N. Bartlett","Phase change memories (PCM) is an emerging type of non-volatile memory that
has shown a strong presence in the data-storage market. This technology has
recently attracted significant research interest in the development of non-Von
Neumann computing architectures such as in-memory and neuromorphic computing.
Research in these areas has been primarily motivated by the scalability
potential of phase change materials and their compatibility with industrial
nanofabrication processes. In this work, we are presenting our development of
crossbar phase change memory arrays through the electrodeposition of GeSbTe
(GST). We show that GST can be electrodeposited in microfabricated TiN crossbar
arrays using a scalable process. Our phase switching test of the
electrodeposited materials have shown that a SET/RESET resistance ratio of 2-3
orders of magnitude is achievable with a switching endurance of around 80
cycles. These results represent the first phase switching of electrodeposited
GeSbTe in microfabricated crossbar arrays. Our work paves the way towards
developing large memory arrays involving electrodeposited materials for passive
selectors and phase switching devices. It also opens opportunities for
developing a variety of different electronic devices using electrodeposited
materials.",http://arxiv.org/abs/2104.02340v2
"Augmented World Models Facilitate Zero-Shot Dynamics Generalization From
  a Single Offline Environment",2021-04-12T16:53:55Z,"Philip J. Ball, Cong Lu, Jack Parker-Holder, Stephen Roberts","Reinforcement learning from large-scale offline datasets provides us with the
ability to learn policies without potentially unsafe or impractical
exploration. Significant progress has been made in the past few years in
dealing with the challenge of correcting for differing behavior between the
data collection and learned policies. However, little attention has been paid
to potentially changing dynamics when transferring a policy to the online
setting, where performance can be up to 90% reduced for existing methods. In
this paper we address this problem with Augmented World Models (AugWM). We
augment a learned dynamics model with simple transformations that seek to
capture potential changes in physical properties of the robot, leading to more
robust policies. We not only train our policy in this new setting, but also
provide it with the sampled augmentation as a context, allowing it to adapt to
changes in the environment. At test time we learn the context in a
self-supervised fashion by approximating the augmentation which corresponds to
the new environment. We rigorously evaluate our approach on over 100 different
changed dynamics settings, and show that this simple approach can significantly
improve the zero-shot generalization of a recent state-of-the-art baseline,
often achieving successful policies where the baseline fails.",http://arxiv.org/abs/2104.05632v3
"Symbolic integration in the spirit of Liouville, Abel and Lie",2021-04-13T14:18:19Z,Waldemar Hebisch,"We provide a Liouville principle for integration in terms of elliptic
integrals. Our methods are essentially those of Abel and Liouville changed to
modern notation. We expose Lie theoretic aspect of Liouville's work.",http://arxiv.org/abs/2104.06226v3
Controlling extended criticality via modular connectivity,2021-04-16T07:36:00Z,"Nikita Gutjahr, Philipp Hövel, Aline Viol","Criticality has been conjectured as an integral part of neuronal network
dynamics. Operating at a critical threshold requires precise parameter tuning
and a corresponding mechanism remains an open question. Recent studies have
suggested that topological features observed in brain networks give rise to a
Griffiths phase, leading to power-laws in brain activity dynamics and the
operational benefits of criticality in an extended parameter region. Motivated
by growing evidence of neural correlates of different states of consciousness,
we investigate how topological changes affect the expression of a Griffiths
phase. We analyze the activity decay in modular networks using a
Susceptible-Infected-Susceptible propagation model and find that we can control
the extension of the Griffiths phase by altering intra- and intermodular
connectivity. We find that by adjusting system parameters, we can counteract
changes in critical behavior and maintain a stable critical region despite
changes in network topology. Our results give insight into how structural
network properties affect the emergence of a Griffiths phase and how its
features are linked to established topological network metrics. We discuss how
those findings can contribute to understand the observed changes in functional
brain networks. Finally, we indicate how our results could be useful in the
study of disease spreading.",http://arxiv.org/abs/2104.07939v1
How Does the Vulnerability of an Evolving Power Grid Change?,2021-04-19T06:56:46Z,Balint Hartmann,"In this paper the seven-decade historical dataset of the Hungarian power
system is used to perform vulnerability assessment applying a complex network
approach.",http://arxiv.org/abs/2104.09080v1
Dynamics of lineages in adaptation to a gradual environmental change,2021-04-21T09:18:01Z,"Vincent Calvez, Benoît Henry, Sylvie Méléard, Viet Chi Tran","We investigate a simple quantitative genetics model subjet to a gradual
environmental change from the viewpoint of the phylogenies of the living
individuals. We aim to understand better how the past traits of their ancestors
are shaped by the adaptation to the varying environment. The individuals are
characterized by a one-dimensional trait. The dynamics -- births and deaths --
depend on a time-changing mortality rate that shifts the optimal trait to the
right at constant speed. The population size is regulated by a nonlinear
non-local logistic competition term. The macroscopic behaviour can be described
by a PDE that admits a unique positive stationary solution. In the stationary
regime, the population can persist, but with a lag in the trait distribution
due to the environmental change. For the microscopic (individual-based)
stochastic process, the evolution of the lineages can be traced back using the
historical process, that is, a measure-valued process on the set of continuous
real functions of time. Assuming stationarity of the trait distribution, we
describe the limiting distribution, in large populations, of the path of an
individual drawn at random at a given time $T$. Freezing the non-linearity due
to competition allows the use of a many-to-one identity together with
Feynman-Kac's formula. This path, in reversed time, remains close to a simple
Ornstein-Uhlenbeck process. It shows how the lagged bulk of the present
population stems from ancestors once optimal in trait but still in the tail of
the trait distribution in which they lived.",http://arxiv.org/abs/2104.10427v1
"Linking open-source code commits and MOOC grades to evaluate massive
  online open peer review",2021-04-15T18:27:01Z,"Siruo Wang, Leah R. Jager, Kai Kammers, Aboozar Hadavand, Jeffrey T. Leek","Massive Open Online Courses (MOOCs) have been used by students as a low-cost
and low-touch educational credential in a variety of fields. Understanding the
grading mechanisms behind these course assignments is important for evaluating
MOOC credentials. A common approach to grading free-response assignments is
massive scale peer-review, especially used for assignments that are not easy to
grade programmatically. It is difficult to assess these approaches since the
responses typically require human evaluation. Here we link data from public
code repositories on GitHub and course grades for a large massive-online open
course to study the dynamics of massive scale peer review. This has important
implications for understanding the dynamics of difficult to grade assignments.
Since the research was not hypothesis-driven, we described the results in an
exploratory framework. We find three distinct clusters of repeated peer-review
submissions and use these clusters to study how grades change in response to
changes in code submissions. Our exploration also leads to an important
observation that massive scale peer-review scores are highly variable,
increase, on average, with repeated submissions, and changes in scores are not
closely tied to the code changes that form the basis for the re-submissions.",http://arxiv.org/abs/2104.12555v1
"The potential stickiness of pandemic-induced behavior changes in the
  United States",2021-04-30T00:57:14Z,"Deborah Salon, Matthew Wigginton Conway, Denise Capasso da Silva, Rishabh Singh Chauhan, Sybil Derrible, Kouros Mohammadian, Sara Khoeini, Nathan Parker, Laura Mirtich, Ali Shamshiripour, Ehsan Rahimi, Ram Pendyala","Human behavior is notoriously difficult to change, but a disruption of the
magnitude of the COVID-19 pandemic has the potential to bring about long-term
behavioral changes. During the pandemic, people have been forced to experience
new ways of interacting, working, learning, shopping, traveling, and eating
meals. A critical question going forward is how these experiences have actually
changed preferences and habits in ways that might persist after the pandemic
ends. Many observers have suggested theories about what the future will bring,
but concrete evidence has been lacking. We present evidence on how much U.S.
adults expect their own post-pandemic choices to differ from their pre-pandemic
lifestyles in the areas of telecommuting, restaurant patronage, air travel,
online shopping, transit use, car commuting, uptake of walking and biking, and
home location. The analysis is based on a nationally-representative survey
dataset collected between July and October 2020. Key findings include that the
new normal will feature a doubling of telecommuting, reduced air travel, and
improved quality of life for some.",http://arxiv.org/abs/2104.14708v2
"Measuring diachronic sense change: new models and Monte Carlo methods
  for Bayesian inference",2021-04-14T11:40:21Z,"Schyan Zafar, Geoff Nicholls","In a bag-of-words model, the senses of a word with multiple meanings, e.g.
""bank"" (used either in a river-bank or an institution sense), are represented
as probability distributions over context words, and sense prevalence is
represented as a probability distribution over senses. Both of these may change
with time. Modelling and measuring this kind of sense change is challenging due
to the typically high-dimensional parameter space and sparse datasets. A
recently published corpus of ancient Greek texts contains expert-annotated
sense labels for selected target words. Automatic sense-annotation for the word
""kosmos"" (meaning decoration, order or world) has been used as a test case in
recent work with related generative models and Monte Carlo methods. We adapt an
existing generative sense change model to develop a simpler model for the main
effects of sense and time, and give MCMC methods for Bayesian inference on all
these models that are more efficient than existing methods. We carry out
automatic sense-annotation of snippets containing ""kosmos"" using our model, and
measure the time-evolution of its three senses and their prevalence. As far as
we are aware, ours is the first analysis of this data, within the class of
generative models we consider, that quantifies uncertainty and returns credible
sets for evolving sense prevalence in good agreement with those given by expert
annotation.",http://arxiv.org/abs/2105.00819v2
"Structural Order of the Molecular Adlayer Impacts the Stability of
  Nanoparticle-on-Mirror Plasmonic Cavities",2021-05-12T19:01:33Z,"Aqeel Ahmed, Karla Banjac, Sachin S. Verlekar, Fernando P. Cometto, Magali Lingenfelder, Christophe Galland","Immense field enhancement and nanoscale confinement of light are possible
within nanoparticle-on-mirror (NPoM) plasmonic resonators, which enable novel
optically-activated physical and chemical phenomena, and render these
nanocavities greatly sensitive to minute structural changes, down to the atomic
scale. Although a few of these structural parameters, primarily linked to the
nanoparticle and the mirror morphology, have been identified, the impact of
molecular assembly and organization of the spacer layer between them has often
been left uncharacterized. Here, we experimentally investigate how the complex
and reconfigurable nature of a thiol-based self-assembled monolayer (SAM)
adsorbed on the mirror surface impacts the optical properties of the NPoMs. We
fabricate NPoMs with distinct molecular organizations by controlling the
incubation time of the mirror in the thiol solution. Afterwards, we investigate
the structural changes that occur under laser irradiation by tracking the
bonding dipole plasmon mode, while also monitoring Stokes and anti-Stokes Raman
scattering from the molecules as a probe of their integrity. First, we find an
effective decrease in the SAM height as the laser power increases, compatible
with an irreversible change of molecule orientation caused by heating. Second,
we observe that the nanocavities prepared with a densely packed and more
ordered monolayer of molecules are more prone to changes in their resonance
compared to samples with sparser and more disordered SAMs. Our measurements
indicate that molecular orientation and packing on the mirror surface play a
key role in determining the stability of NPoM structures and hence highlight
the under-recognized significance of SAM characterization in the development of
NPoM-based applications.",http://arxiv.org/abs/2105.05909v1
"Mesoscopic simulations of the in situ NMR spectra of porous carbon based
  supercapacitors: Electronic structure and adsorbent reorganisation effects",2021-05-14T12:15:30Z,"Anagha Sasikumar, Anouar Belhboub, Camille Bacon, Alexander C. Forse, John M. Griffin, Clare P Grey, Patrice Simon, Céline Merlet","In situ NMR spectroscopy is a powerful technique to investigate charge
storage mechanisms in carbon-based supercapacitors thanks to its ability to
distinguish ionic and molecular species adsorbed in the porous electrodes from
those in the bulk electrolyte. The NMR peak corresponding to the adsorbed
species shows a clear change of chemical shift as the applied potential
difference is varied. This variation in chemical shift is thought to originate
from a combination of ion reorganisation in the pores and changes in ring
current shifts due to the changes of electronic density in the carbon. While
previous Density Functional Theory calculations suggested that the electronic
density has a large effect, the relative contributions of these two effects is
challenging to untangle. Here, we use mesoscopic simulations to simulate NMR
spectra and investigate the relative importance of ion reorganisation and ring
currents on the resulting chemical shift. The model is able to predict chemical
shifts in good agreement with NMR experiments and indicates that the ring
currents are the dominant contribution. A thorough analysis of a specific
electrode/electrolyte combination for which detailed NMR experiments have been
reported allows us to confirm that local ion reorganisation has a very limited
effect but the relative quantities of ions in pores of different sizes, which
can change upon charging/discharging, can lead to a significant effect. Our
findings suggest that in situ NMR spectra of supercapacitors may provide
insights into the electronic structure of carbon materials in the future.",http://arxiv.org/abs/2105.06790v1
Fast and Slow Learning of Recurrent Independent Mechanisms,2021-05-18T17:50:32Z,"Kanika Madan, Nan Rosemary Ke, Anirudh Goyal, Bernhard Schölkopf, Yoshua Bengio","Decomposing knowledge into interchangeable pieces promises a generalization
advantage when there are changes in distribution. A learning agent interacting
with its environment is likely to be faced with situations requiring novel
combinations of existing pieces of knowledge. We hypothesize that such a
decomposition of knowledge is particularly relevant for being able to
generalize in a systematic manner to out-of-distribution changes. To study
these ideas, we propose a particular training framework in which we assume that
the pieces of knowledge an agent needs and its reward function are stationary
and can be re-used across tasks. An attention mechanism dynamically selects
which modules can be adapted to the current task, and the parameters of the
selected modules are allowed to change quickly as the learner is confronted
with variations in what it experiences, while the parameters of the attention
mechanisms act as stable, slowly changing, meta-parameters. We focus on pieces
of knowledge captured by an ensemble of modules sparsely communicating with
each other via a bottleneck of attention. We find that meta-learning the
modular aspects of the proposed system greatly helps in achieving faster
adaptation in a reinforcement learning setup involving navigation in a
partially observed grid world with image-level input. We also find that
reversing the role of parameters and meta-parameters does not work nearly as
well, suggesting a particular role for fast adaptation of the dynamically
selected modules.",http://arxiv.org/abs/2105.08710v2
"Polyrotaxane: New Generation of Sustainable, Ultra-flexible, Form-stable
  and Smart Phase Change Materials",2021-05-19T11:49:01Z,"Guang-Zhong Yin, Jose Hobson, Yanyan Duan, De-Yi Wang","The development of thermal energy storage materials is the most attractive
strategy to harvest the solar energy and increase the energy utilization
efficiency. Phase change materials (PCMs) have received much attention in this
research field for several decades. Herein, we reported a new kind of PCM micro
topological structure, design direction, and the ultra-flexible, form-stable
and smart PCMs, polyrotaxane. The structure of polyrotaxane was fully confirmed
by 1H nuclear magnetic resonance,attenuated total reflection-fourier transform
infrared and X-ray diffraction. Then the tensile properties,thermal stability
in the air, phase change energy storage and shape memory properties of the
films were systematically analyzed. The results showed that all the mechanical
performance, thermal stability in air and shape memory properties of
polyrotaxanes were enhanced significantly compared to those of polyethylene
oxide (PEO). The form stability at temperatures above the melting point of PEO
significantly increased with the {\alpha}-CD addition. Further with the high
phase transition enthalpy and excellent cycle performance, the polyrotaxane
films are therefore promising sustainable and advanced form-stable phase change
materials for thermal energy storage. Notably, its ultra-high flexibility,
remolding ability and excellent shape memory properties provide a convenient
way for the intelligent heat treatment packaging of complex and flexible
electronic devices. In addition, this is a totally novel insight for
polyrotaxane application and new design method for form-stable PCMs.",http://arxiv.org/abs/2105.09074v1
"The effect of stream interaction regions on ICME structures observed in
  longitudinal conjunction",2021-05-21T23:10:58Z,"Reka M. Winslow, Camilla Scolini, Noé Lugaz, Antoinette B. Galvin","We study two interplanetary coronal mass ejections (ICMEs) observed at
Mercury and 1 AU by spacecraft in longitudinal conjunction, investigating the
question: what causes the drastic alterations observed in some ICMEs during
propagation, while other ICMEs remain relatively unchanged? Of the two ICMEs,
the first one propagated relatively self-similarly, while the second one
underwent significant changes in its properties. We focus on the presence or
absence of large-scale corotating structures in the ICME propagation space
between Mercury and 1 AU, that have been shown to influence the orientation of
ICME magnetic structures and the properties of ICME sheaths. We determine the
flux rope orientation at the two locations using force-free flux rope fits as
well as the classification by Nieves-Chinchilla et al. (2019). We also use
measurements of plasma properties at 1 AU, the size evolution of the sheaths
and ME with heliocentric distance, and identification of structures in the
propagation space based on in situ data, remote-sensing observations, and
simulations of the steady-state solar wind, to complement our analysis. Results
indicate that the changes observed in one ICME were likely caused by a stream
interaction region, while the ICME exhibiting little change did not interact
with any transients between Mercury and 1 AU. This work provides an example of
how interactions with corotating structures in the solar wind can induce
fundamental changes in ICMEs. Our findings can help lay the foundation for
improved predictions of ICME properties at 1 AU.",http://arxiv.org/abs/2105.10602v1
"Does energy efficiency affect ambient PM2.5? The moderating role of
  energy investment",2021-05-24T03:45:22Z,"Cunyi Yang, Tinghui Li, Khaldoon Albitar","The difficulty of balance between environment and energy consumption makes
countries and enterprises face a dilemma, and improving energy efficiency has
become one of the ways to solve this dilemma. Based on data of 158 countries
from 1980 to 2018, the dynamic TFP of different countries is calculated by
means of the Super-SBM-GML model. The TFP is decomposed into indexes of EC
(Technical Efficiency Change), TC (Technological Change) and EC has been
extended to PEC (Pure Efficiency Change) and SEC (Scale Efficiency Change).
Then the fixed effect model and fixed effect panel quantile model are used to
analyze the moderating effect and exogenous effect of energy efficiency on
PM2.5 concentration on the basis of verifying that energy efficiency can reduce
PM2.5 concentration. We conclude, first, the global energy efficiency has been
continuously improved during the sample period, and both of technological
progress and technical efficiency have been improved. Second, the impact of
energy efficiency on PM2.5 is heterogeneous which is reflected in the various
elements of energy efficiency decomposition. The increase of energy efficiency
can inhibit PM2.5 concentration and the inhibition effect mainly comes from TC
and PEC but SEC promotes PM2.5 emission. Third, energy investment plays a
moderating role in the environmental protection effect of energy efficiency.
Fourth, the impact of energy efficiency on PM2.5 concentration is heterogeneous
in terms of national attribute, which is embodied in the differences of
national development, science & technology development level, new energy
utilization ratio and the role of international energy trade.",http://arxiv.org/abs/2105.11080v1
"Are Privacy Dashboards Good for End Users? Evaluating User Perceptions
  and Reactions to Google's My Activity (Extended Version)",2021-05-28T19:08:43Z,"Florian M. Farke, David G. Balash, Maximilian Golla, Markus Dürmuth, Adam J. Aviv","Privacy dashboards and transparency tools help users review and manage the
data collected about them online. Since 2016, Google has offered such a tool,
My Activity, which allows users to review and delete their activity data from
Google services. We conducted an online survey with $n = 153$ participants to
understand if Google's My Activity, as an example of a privacy transparency
tool, increases or decreases end-users' concerns and benefits regarding data
collection. While most participants were aware of Google's data collection, the
volume and detail was surprising, but after exposure to My Activity,
participants were significantly more likely to be both less concerned about
data collection and to view data collection more beneficially. Only $25\,\%$
indicated that they would change any settings in the My Activity service or
change any behaviors. This suggests that privacy transparency tools are quite
beneficial for online services as they garner trust with their users and
improve their perceptions without necessarily changing users' behaviors. At the
same time, though, it remains unclear if such transparency tools actually
improve end user privacy by sufficiently assisting or motivating users to
change or review data collection settings.",http://arxiv.org/abs/2105.14066v1
Robust Dynamic Network Embedding via Ensembles,2021-05-30T14:44:26Z,"Chengbin Hou, Guoji Fu, Peng Yang, Zheng Hu, Shan He, Ke Tang","Dynamic Network Embedding (DNE) has recently attracted considerable attention
due to the advantage of network embedding in various fields and the dynamic
nature of many real-world networks. An input dynamic network to DNE is often
assumed to have smooth changes over snapshots, which however would not hold for
all real-world scenarios. It is natural to ask if existing DNE methods can
perform well for an input dynamic network without smooth changes. To quantify
it, an index called Degree of Changes (DoCs) is suggested so that the smaller
DoCs indicates the smoother changes. Our comparative study shows several DNE
methods are not robust enough to different DoCs even if the corresponding input
dynamic networks come from the same dataset, which would make these methods
unreliable and hard to use for unknown real-world applications. To propose an
effective and more robust DNE method, we follow the notion of ensembles where
each base learner adopts an incremental Skip-Gram embedding model. To further
boost the performance, a simple yet effective strategy is designed to enhance
the diversity among base learners at each timestep by capturing different
levels of local-global topology. Extensive experiments demonstrate the superior
effectiveness and robustness of the proposed method compared to
state-of-the-art DNE methods, as well as the benefits of special designs in the
proposed method and its scalability.",http://arxiv.org/abs/2105.14557v2
What Do We Learn by Deriving Born's Rule,2021-07-05T22:05:07Z,James Hartle,"Derivations of Borns Rule are of interest because they tell us what's
connected to what in quantum mechanics if we ever need to change or modify it.",http://arxiv.org/abs/2107.02297v1
Radiative contributions to gravitational scattering,2021-07-19T14:09:40Z,"Donato Bini, Thibault Damour, Andrea Geralico","The linear-order effects of radiation-reaction on the classical scattering of
two point masses, in General Relativity, are derived by a
variation-of-constants method. Explicit expressions for the radiation-reaction
contributions to the changes of 4-momentum during scattering are given to
linear order in the radiative losses of energy, linear-momentum and angular
momentum. The polynomial dependence on the masses of the 4-momentum changes is
shown to lead to non-trivial identities relating the various radiative losses.
At order $G^3$ our results lead to a streamlined classical derivation of
results recently derived within a quantum approach. At order $G^4$ we compute
the needed radiative losses to next-to-next-to-leading-order in the
post-Newtonian expansion, thereby reaching the absolute fourth and a half
post-Newtonian level of accuracy in the 4-momentum changes. We also provide
explicit expressions, at the absolute sixth post-Newtonian accuracy, for the
radiation-graviton contribution to {\it conservative} $O(G^4)$ scattering. At
orders $G^5$ and $G^6$ we derive explicit theoretical expressions for the last
two hitherto undetermined parameters describing the fifth-post-Newtonian
dynamics. Our results at the fifth-post-Newtonian level confirm results of
[Nucl. Phys. B \textbf{965}, 115352 (2021)] but exhibit some disagreements with
results of [Phys. Rev. D \textbf{101}, 064033 (2020)].",http://arxiv.org/abs/2107.08896v4
On the accuracy of short-term COVID-19 fatality forecasts,2021-07-21T06:12:22Z,"Nino Antulov-Fantulin, Lucas Böttcher","Forecasting new cases, hospitalizations, and disease-induced deaths is an
important part of infectious disease surveillance and helps guide health
officials in implementing effective countermeasures. For disease surveillance
in the U.S., the Centers for Disease Control and Prevention (CDC) combine more
than 65 individual forecasts of these numbers in an ensemble forecast at
national and state levels. We collected data on CDC ensemble forecasts of
COVID-19 fatalities in the United States, and compare them with easily
interpretable ``Euler'' forecasts serving as a model-free benchmark that is
only based on the local rate of change of the incidence curve. The term ``Euler
method'' is motivated by the eponymous numerical integration scheme that
calculates the value of a function at a future time step based on the current
rate of change. Our results show that CDC ensemble forecasts are not more
accurate than ``Euler'' forecasts on short-term forecasting horizons of one
week. However, CDC ensemble forecasts show a better performance on longer
forecasting horizons. Using the current rate of change in incidences as
estimates of future incidence changes is useful for epidemic forecasting on
short time horizons. An advantage of the proposed method over other forecasting
approaches is that it can be implemented with a very limited amount of work and
without relying on additional data (e.g., human mobility and contact patterns)
and high-performance computing systems.",http://arxiv.org/abs/2107.09891v1
Always on Voting: A Framework for Repetitive Voting on the Blockchain,2021-07-22T10:49:48Z,"Sarad Venugopalan, Ivana Stančíková, Ivan Homoliak","Elections repeat commonly after a fixed time interval, ranging from months to
years. This results in limitations on governance since elected candidates or
policies are difficult to remove before the next elections, if needed, and
allowed by the corresponding law. Participants may decide (through a public
deliberation) to change their choices but have no opportunity to vote for these
choices before the next elections. Another issue is the peak-end effect, where
the judgment of voters is based on how they felt a short time before the
elections. To address these issues, we propose Always on Voting (AoV) -- a
repetitive voting framework that allows participants to vote and change elected
candidates or policies without waiting for the next elections. Participants are
permitted to privately change their vote at any point in time, while the effect
of their change is manifested at the end of each epoch, whose duration is
shorter than the time between two main elections. To thwart the problem of
peak-end effect in epochs, the ends of epochs are randomized and made
unpredictable, while preserved within soft bounds. These goals are achieved
using the synergy between a Bitcoin puzzle oracle, verifiable delay function,
and smart contracts.",http://arxiv.org/abs/2107.10571v6
"Macroscopic modeling of strain-rate dependent energy dissipation of
  superelastic SMAs considering destabilization of martensitic lattice",2021-07-16T09:39:09Z,"A. Kaup, O. Altay, S. Klinkel","Superelastic shape-memory alloys (SMAs) are unique smart materials with a
considerable energy dissipation potential for dynamic loadings with varying
strain-rates. The energy dissipation depends on the latent heat generated by
the austenitic-martensitic transformation and the convection of that heat. Due
to the thermomechanical coupling, the martensitic nucleation stress level and
thus the propagation of martensitic phase fronts strongly depends on the
material temperature. High strain-rate interferes with the release of the
latent heat to the environment and determines quantity, position and
propagation of martensitic transformation bands. Lastly, high strain-rate
reduces the hysteresis surface. The propagation velocity and quantity of
martensitic bands have an impact on martensitic phase stability. The degree of
atomic disorder and accordingly the change in entropy influences the reverse
phase transformation from martensite to austenite. In other words, the
stability of the martensitic state affects the stress level of the reverse
transformation. However, in phenomenological superelastic SMA models, which are
used to simulate energy dissipation behavior, the effects of the rate-dependent
entropy change are not considered in particular. To incorporate the
rate-dependent entropy change, we improved a one-dimensional numerical model by
introducing an additional control variable in the free energy formulation for
solid-solid phase transformation of superelastic SMAs. In this model, the
observed effects of the strain-rate on the reverse transformation are taken
into account by calculating the rate-dependent entropy change. A comparison of
the numerical results with the experimental data shows that the model
calculates the dynamic superelastic hysteresis of SMAs more accurately.",http://arxiv.org/abs/2107.12145v1
"Tracking Fast Neural Adaptation by Globally Adaptive Point Process
  Estimation for Brain-Machine Interface",2021-07-27T05:31:31Z,"Shuhang Chen, Xiang Zhang, Xiang Shen, Yifan Huang, Yiwen Wang","Brain-machine interfaces (BMIs) help the disabled restore body functions by
translating neural activity into digital commands to control external devices.
Neural adaptation, where the brain signals change in response to external
stimuli or movements, plays an important role in BMIs. When subjects purely use
neural activity to brain-control a prosthesis, some neurons will actively
explore a new tuning property to accomplish the movement task. The prediction
of this neural tuning property can help subjects adapt more efficiently to
brain control and maintain good decoding performance. Existing prediction
methods track the slow change of the tuning property in the manual control,
which is not suitable for the fast neural adaptation in brain control. In order
to identify the active neurons in brain control and track their tuning property
changes, we propose a globally adaptive point process method (GaPP) to estimate
the neural modulation state from spike trains, decompose the states into the
hyper preferred direction and reconstruct the kinematics in a dual-model
framework. We implement the method on real data from rats performing a
two-lever discrimination task under manual control and brain control. The
results show our method successfully predicts the neural modulation state and
identifies the neurons that become active in brain control. Compared to
existing methods, ours tracks the fast changes of the hyper preferred direction
from manual control to brain control more accurately and efficiently and
reconstructs the kinematics better and faster.",http://arxiv.org/abs/2107.12609v1
The mystery of energy compensation,2021-07-26T13:13:23Z,Lewis G. Halsey,"The received wisdom on how activity affects energy expenditure is that the
more activity is undertaken, the more calories will have been burned by the end
of the day. Yet traditional hunter-gatherers, who lead physically hard lives,
burn no more calories each day than western populations living in labour-saving
environments. Indeed, there is now a wealth of data, both for humans and other
animals, demonstrating that long-term lifestyle changes involving increases in
exercise or other physical activities do not result in commensurate increases
in daily energy expenditure (DEE). This is because humans and other animals
exhibit a degree of energy compensation at the organismal level, ameliorating
some of the increases in DEE that would occur from the increased activity by
decreasing the energy expended on other biological processes. And energy
compensation can be sizable, reaching many hundreds of calories in humans. But
the processes that are downregulated in the long-term to achieve energy
compensation are far from clear, particularly in humans. We do not know how
energy compensation is achieved. My review here of the literature on relevant
exercise intervention studies, for both humans and other species, indicates
conflict regarding the role that basal metabolic rate (BMR) or low level
activity such as fidgeting play, if any, particularly once changes in body
composition are factored out. In situations where BMR and low-level activity
are not major components of energy compensation, what then drives it? I discuss
how changes in mitochondrial efficiency and changes in circadian fluctuations
in BMR may contribute to our understanding of energy management. Currently
unexplored, these mechanisms and others may provide important insights into the
mystery of how energy compensation is achieved.",http://arxiv.org/abs/2107.13418v1
"Heterogeneous Responses to the U.S. Narrative Tax Changes: Evidence from
  the U.S. States",2021-07-29T00:21:11Z,Masud Alam,"This paper investigates the assumption of homogeneous effects of federal tax
changes across the U.S. states and identifies where and why that assumption may
not be valid. More specifically, what determines the transmission mechanism of
tax shocks at the state level? How vital are states' fiscal structures,
financial conditions, labor market rigidities, and industry mix? Do these
economic and structural characteristics drive the transmission mechanism of the
tax changes at the state level at different horizons? This study employs a
panel factor-augmented vector autoregression (FAVAR) technique to answer these
issues. The findings show that state economies respond homogeneously in terms
of employment and price levels; however, they react heterogeneously in real GDP
and personal income growth. In most states, these reactions are statistically
significant, and the heterogeneity in the effects of tax cuts is significantly
related to the state's fiscal structure, manufacturing and financial
composition, and the labor market's rigidity. A cross-state regression analysis
shows that states with higher tax elasticity, higher personal income tax,
strict labor market regulation, and economic policy uncertainties are
relatively less responsive to federal tax changes. In contrast, the magnitude
of the response in real GDP, personal income, and employment to tax cuts is
relatively higher in states with a larger share of finance, manufacturing,
lower tax burdens, and flexible credit markets.",http://arxiv.org/abs/2107.13678v1
Did the Model Change? Efficiently Assessing Machine Learning API Shifts,2021-07-29T17:41:53Z,"Lingjiao Chen, Tracy Cai, Matei Zaharia, James Zou","Machine learning (ML) prediction APIs are increasingly widely used. An ML API
can change over time due to model updates or retraining. This presents a key
challenge in the usage of the API because it is often not clear to the user if
and how the ML model has changed. Model shifts can affect downstream
application performance and also create oversight issues (e.g. if consistency
is desired). In this paper, we initiate a systematic investigation of ML API
shifts. We first quantify the performance shifts from 2020 to 2021 of popular
ML APIs from Google, Microsoft, Amazon, and others on a variety of datasets. We
identified significant model shifts in 12 out of 36 cases we investigated.
Interestingly, we found several datasets where the API's predictions became
significantly worse over time. This motivated us to formulate the API shift
assessment problem at a more fine-grained level as estimating how the API
model's confusion matrix changes over time when the data distribution is
constant. Monitoring confusion matrix shifts using standard random sampling can
require a large number of samples, which is expensive as each API call costs a
fee. We propose a principled adaptive sampling algorithm, MASA, to efficiently
estimate confusion matrix shifts. MASA can accurately estimate the confusion
matrix shifts in commercial ML APIs using up to 90% fewer samples compared to
random sampling. This work establishes ML API shifts as an important problem to
study and provides a cost-effective approach to monitor such shifts.",http://arxiv.org/abs/2107.14203v1
"Characterizing and Detecting Configuration Compatibility Issues in
  Android Apps",2021-09-01T10:41:38Z,"Huaxun Huang, Ming Wen, Lili Wei, Yepang Liu, Shing-Chi Cheung","XML configuration files are widely used in Android to define an app's user
interface and essential runtime information such as system permissions. As
Android evolves, it might introduce functional changes in the configuration
environment, thus causing compatibility issues that manifest as inconsistent
app behaviors at different API levels. Such issues can often induce software
crashes and inconsistent look-and-feel when running at specific Android
versions. Existing works incur plenty of false positive and false negative
issue-detection rules by conducting trivial data-flow analysis while failing to
model the XML tree hierarchies of the Android configuration files. Besides,
little is known about how the changes in an Android framework can induce such
compatibility issues. To bridge such gaps, we conducted a systematic study by
analyzing 196 real-world issues collected from 43 popular apps. We identified
common patterns of Android framework code changes that induce such
configuration compatibility issues. Based on the findings, we propose
\textsc{ConfDroid} that can automatically extract rules for detecting
configuration compatibility issues. The intuition is to perform symbolic
execution based on a model learned from the common code change patterns.
Experiment results show that ConfDroid can successfully extract 282 valid
issue-detection rules with a precision of 91.9%. Among them, 65 extracted rules
can manifest issues that cannot be detected by the rules of state-of-the-art
baselines. More importantly, 11 out of them have led to the detection of 107
reproducible configuration compatibility issues that the baselines cannot
detect in 30 out of 316 real-world Android apps.",http://arxiv.org/abs/2109.00300v1
"Land use change in agricultural systems: an integrated ecological-social
  simulation model of farmer decisions and cropping system performance based on
  a cellular automata approach",2021-08-10T21:22:49Z,"Diego Ferraro, Daniela Blanco, Sebastián Pessah, Rodrigo Castro","Agricultural systems experience land-use changes that are driven by
population growth and intensification of technological inputs. This results in
land-use and cover change (LUCC) dynamics representing a complex landscape
transformation process. In order to study the LUCC process we developed a
spatially explicit agent-based model in the form of a Cellular Automata
implemented with the Cell-DEVS formalism. The resulting model called AgroDEVS
is used for predicting LUCC dynamics along with their associated economic and
environmental changes. AgroDEVS is structured using behavioral rules and
functions representing a) crop yields, b) weather conditions, c) economic
profit, d) farmer preferences, e) technology level adoption and f) natural
resources consumption based on embodied energy accounting. Using data from a
typical location of the Pampa region (Argentina) for the 1988-2015 period,
simulation exercises showed that the economic goals were achieved, on average,
each 6 out of 10 years, but the environmental thresholds were only achieved in
1.9 out of 10 years. In a set of 50-years simulations, LUCC patterns quickly
converge towards the most profitable crop sequences, with no noticeable
tradeoff between the economic and environmental conditions.",http://arxiv.org/abs/2109.01031v2
Schrödinger-Poisson Solitons: Perturbation Theory,2021-09-04T19:40:51Z,"J. Luna Zagorac, Isabel Sands, Nikhil Padmanabhan, Richard Easther","Self-gravitating quantum matter may exist in a wide range of cosmological and
astrophysical settings from the very early universe through to present-day
boson stars. Such quantum matter arises in a number of different theories,
including the Peccei-Quinn axion and UltraLight (ULDM) or Fuzzy (FDM) dark
matter scenarios. We consider the dynamical evolution of perturbations to the
spherically symmetric soliton, the ground state solution to the
Schr\""{o}dinger-Poisson system common to all these scenarios. We construct the
eigenstates of the Schr\""{o}dinger equation, holding the gravitational
potential fixed to its ground state value. We see that the eigenstates
qualitatively capture the properties seen in full ULDM simulations, including
the soliton ""breathing"" mode, the random walk of the soliton center, and
quadrupolar distortions of the soliton. We then show that the time-evolution of
the gravitational potential and its impact on the perturbations can be well
described within the framework of time-dependent perturbation theory. Applying
our formalism to a synthetic ULDM halo reveals considerable mixing of
eigenstates, even though the overall density profile is relatively stable. Our
results provide a new analytic approach to understanding the evolution of these
systems as well as possibilities for faster approximate simulations.",http://arxiv.org/abs/2109.01920v2
A note on Tsuji's criterion for numerical triviality,2021-09-05T10:04:20Z,Shigetaka Fukuda,"In this study, we give an alternative and elementary proof to Tsuji's
criterion for a Cartier divisor to be numerically trivial.",http://arxiv.org/abs/2109.02034v2
"Towards understanding network topology and robustness of logistics
  systems",2021-09-06T08:36:44Z,"Takahiro Ezaki, Naoto Imura, Katsuhiro Nishinari","Advanced integration of logistics systems has been promoted for the sake of
competitiveness and sustainability. Such efforts will enable more globally
optimal and flexible operations by efficiently utilizing transportation
capacity. At the same time, interconnection of transport operations increases
complexity at a network level, which reduces the predictability of the response
of the system to disruptions. However, our understanding of the behavior of
such systems is still limited. In particular, the topology of the network,
which changes as the systems are integrated, is an important factor that
affects the performance of the entire system. Knowledge of such mechanisms
would be useful in the design and evaluation of integrated logistics. Here, we
developed a simple mathematical model that extracts the essence of the problem
and performed extensive numerical experiments by Monte Carlo simulations for
three scenarios that mimic changes in demand: (i) locally and temporally
increased traffic demand, (ii) globally and temporally increased traffic
demand, and (iii) permanent change in demand pattern, under various conditions
on the type of route-finding algorithm, network structure, and transportation
capacity. Adaptive route-finding algorithms were more effective in square
lattice and random networks, which contained many bypass routes, than in
hub-and-spoke networks. Furthermore, the square lattice and random networks
were robust to the change in the demand pattern and temporal blockage of
delivery paths (e.g., due to high demand). We suggest that such preferable
properties are only present in networks with redundancy and that the bypass
structure is an important criterion for designing network logistics.",http://arxiv.org/abs/2109.02290v2
"Dissipative dynamics of quantum correlation quantifiers under
  decoherence channels",2021-09-05T10:24:23Z,"Nitish Kumar Chandra, Sarang S. Bhosale, Prasanta K. Panigrahi","In this work, we investigate the dynamics of quantum correlations captured by
entropic and geometric measures of discord under the influence of dissipative
channels for widely used two qubit X state with maximally mixed marginals.
Identifying the phenomena of the preservation, sudden change and revival of
quantum correlation quantifiers, we determine their hierarchy of robustness
under memory-less decoherence channels. We find the analytical expressions of
decoherence probabilities at which sudden change occur when the first qubit is
subjected to the decoherence channels for multiple times. We deduce the exact
analytical expression for the preservation time, the duration for which quantum
correlations remain unaffected by noise. We also find the time duration between
the two sudden change phenomena of trace distance discord, and show its inverse
proportionality to the number of times a channel operates on the state. The
constraint relations of decoherence probabilities corresponding to the sudden
change region and preservation phenomena are obtained when both the qubits are
subjected to locally independent quantum channels for multiple times. Our
investigation provides physical insights and possible practical implementation
of the discord measures in noisy environments.",http://arxiv.org/abs/2109.02640v2
"Spectral Evolution of the X-Ray Remnant of SN 1987A: A High-Resolution
  $Chandra$ HETG Study",2021-09-07T05:44:13Z,"Aravind P. Ravi, Sangwook Park, Svetozar A. Zhekov, Marco Miceli, Salvatore Orlando, Kari A. Frank, David N. Burrows","Based on observations with the $Chandra$ X-ray Observatory, we present the
latest spectral evolution of the X-ray remnant of SN 1987A (SNR 1987A). We
present a high-resolution spectroscopic analysis using our new deep ($\sim$312
ks) $Chandra$ HETG observation taken in March 2018, as well as archival
$Chandra$ gratings spectroscopic data taken in 2004, 2007, and 2011 with
similarly deep exposures ($\sim$170 - 350 ks). We perform detailed spectral
model fits to quantify changing plasma conditions over the last 14 years.
Recent changes in electron temperatures and volume emission measures suggest
that the shocks moving through the inner ring have started interacting with
less dense circumstellar material, probably beyond the inner ring. We find
significant changes in the X-ray line flux ratios (among H- and He-like Si and
Mg ions) in 2018, consistent with changes in the thermal conditions of the
X-ray emitting plasma that we infer based on the broadband spectral analysis.
Post-shock electron temperatures suggested by line flux ratios are in the range
$\sim$0.8 - 2.5 keV as of 2018. We do not yet observe any evidence of
substantial abundance enhancement, suggesting that the X-ray emission component
from the reverse-shocked metal-rich ejecta is not yet significant in the
observed X-ray spectrum.",http://arxiv.org/abs/2109.02881v1
"Self-adaptive Architectures in IoT Systems: A Systematic Literature
  Review",2021-09-07T20:11:25Z,"Iván Alfonso, Kelly Garcés, Harold Castro, Jordi Cabot","Over the past few years, the relevance of the Internet of Things (IoT) has
grown significantly and is now a key component of many industrial processes and
even a transparent participant in various activities performed in our daily
life. IoT systems are subjected to changes in the dynamic environments they
operate in. These changes (e.g. variations in bandwidth consumption or new
devices joining/leaving) may impact the Quality of Service (QoS) of the IoT
system. A number of self-adaptation strategies for IoT architectures to better
deal with these changes have been proposed in the literature. Nevertheless,
they focus on isolated types of changes. We lack a comprehensive view of the
trade-offs of each proposal and how they could be combined to cope with
simultaneous events of different types.
  In this paper, we identify, analyze, and interpret relevant studies related
to IoT adaptation and develop a comprehensive and holistic view of the
interplay of different dynamic events, their consequences on QoS, and the
alternatives for the adaptation. To do so, we have conducted a systematic
literature review of existing scientific proposals and defined a research
agenda for the near future based on the findings and weaknesses identified in
the literature.",http://arxiv.org/abs/2109.03312v2
"Photoinduced ultrafast transition of the local correlated structure in
  chalcogenide phase-change materials",2021-09-13T04:52:56Z,"Yingpeng Qi, Nianke Chen, Thomas Vasileiadis, Daniela Zahn, Helene Seiler, Xianbin Li, Ralph Ernstorfer","Revealing the bonding and time-evolving atomic dynamics in functional
materials with complex lattice structures can update the fundamental knowledge
on rich physics therein, and also help to manipulate the material properties as
desired. As the most prototypical chalcogenide phase change material, Ge2Sb2Te5
has been widely used in optical data storage and non-volatile electric memory
due to the fast switching speed and the low energy consumption. However, the
basic understanding of the structural dynamics on the atomic scale is still not
clear. Using femtosecond electron diffraction, structure factor calculation and
TDDFT-MD simulation, we reveal the photoinduced ultrafast transition of the
local correlated structure in the averaged rock-salt phase of Ge2Sb2Te5. The
randomly oriented Peierls distortion among unit cells in the averaged rock-salt
phase of Ge2Sb2Te5 is termed as local correlated structures. The ultrafast
suppression of the local Peierls distortions in individual unit cell gives rise
to a local structure change from the rhombohedral to the cubic geometry within
~ 0.3 ps. In addition, the impact of the carrier relaxation and the large
amount of vacancies to the ultrafast structural response is quantified and
discussed. Our work provides new microscopic insights into contributions of the
local correlated structure to the transient structural and optical responses in
phase change materials. Moreover, we stress the significance of femtosecond
electron diffraction in revealing the local correlated structure in the subunit
cell and the link between the local correlated structure and physical
properties in functional materials with complex microstructures.",http://arxiv.org/abs/2109.05705v2
Non-classifiability of Ergodic Flows up to Time Change,2021-09-13T16:03:07Z,"Marlies Gerber, Philipp Kunde","A time change of a flow $\{T_t\}$, ${t\in\mathbb{R}}$, is a reparametrization
of the orbits of the flow such that each orbit is mapped to itself by an
orientation-preserving homeomorphism of the parameter space. If a flow
$\{S_t\}$ is isomorphic to a flow obtained by a reparametrization of a flow
$\{T_t\}$, then we say that $\{S_t\}$ and $\{T_t\}$ are isomorphic up to a time
change. For ergodic flows $\{S_t\}$ and $\{T_t\}$, Kakutani showed that this
happens if and only if the two flows have Kakutani equivalent transformations
as cross-sections.
  We prove that the Kakutani equivalence relation on ergodic invertible
measure-preserving transformations of a standard non-atomic probability space
is not a Borel set. This shows in a precise way that classification of ergodic
transformations up to Kakutani equivalence is impossible. In particular, our
results imply the non-classifiability of ergodic flows up to isomorphism after
a time change. Moreover, we obtain anti-classification results under
isomorphism for ergodic invertible transformations of a sigma-finite measure
space.
  We also obtain anti-classification results under Kakutani equivalence for
ergodic area-preserving smooth diffeomorphisms of the disk, annulus, and
2-torus, as well as real-analytic diffeomorphisms of the $2$-torus. Our work
generalizes the anti-classification results under isomorphism for ergodic
transformations obtained by Foreman, Rudolph, and Weiss.",http://arxiv.org/abs/2109.06086v2
The impact of the COVID-19 pandemic on academic productivity,2021-09-14T11:24:43Z,"Andrew R. Casey, Ilya Mandel, Prasun K. Ray","'Publish or perish' is an expression describing the pressure on academics to
consistently publish research to ensure a successful career in academia. With a
global pandemic that has changed the world, how has it changed academic
productivity? Here we show that academics are posting just as many publications
on the arXiv pre-print server as if there were no pandemic: 168,630 were posted
in 2020, a +12.6% change from 2019 and $+1.4\sigma$ deviation above the
predicted 162,577 $\pm$ 4,393. However, some immediate impacts are visible in
individual research fields. Conference cancellations have led to sharp drops in
pre-prints, but laboratory closures have had mixed effects. Only some
experimental fields show mild declines in outputs, with most being consistent
on previous years or even increasing above model expectations. The most
significant change is a 50% increase ($+8\sigma$) in quantitative biology
research, all related to the COVID-19 pandemic. Some of these publications are
by biologists using arXiv for the first time, and some are written by
researchers from other fields (e.g., physicists, mathematicians). While
quantitative biology pre-prints have returned to pre-pandemic levels, 20% of
the research in this field is now focussed on the COVID-19 pandemic,
demonstrating a strong shift in research focus.",http://arxiv.org/abs/2109.06591v1
"Internet of Behavior (IoB) and Explainable AI Systems for Influencing
  IoT Behavior",2021-09-15T12:16:11Z,"Haya Elayan, Moayad Aloqaily, Fakhri Karray, Mohsen Guizani","Pandemics and natural disasters over the years have changed the behavior of
people, which has had a tremendous impact on all life aspects. With the
technologies available in each era, governments, organizations, and companies
have used these technologies to track, control, and influence the behavior of
individuals for a benefit. Nowadays, the use of the Internet of Things (IoT),
cloud computing, and artificial intelligence (AI) have made it easier to track
and change the behavior of users through changing IoT behavior. This article
introduces and discusses the concept of the Internet of Behavior (IoB) and its
integration with Explainable AI (XAI) techniques to provide trusted and evident
experience in the process of changing IoT behavior to ultimately improving
users' behavior. Therefore, a system based on IoB and XAI has been proposed in
a use case scenario of electrical power consumption that aims to influence user
consuming behavior to reduce power consumption and cost. The scenario results
showed a decrease of 522.2 kW of active power when compared to original
consumption over a 200-hours period. It also showed a total power cost saving
of 95.04 Euro for the same period. Moreover, decreasing the global active power
will reduce the power intensity through the positive correlation.",http://arxiv.org/abs/2109.07239v2
"Predicting Users' Value Changes by the Friends' Influence from Social
  Media Usage",2021-09-12T09:17:03Z,"Md. Saddam Hossain Mukta, Ahmed Shahriar Sakib, Md. Adnanul Islam, Mohiuddin Ahmed, Mumshad Ahamed Rifat","Basic human values represent a set of values such as security, independence,
success, kindness, and pleasure, which we deem important to our lives. Each of
us holds different values with different degrees of significance. Existing
studies show that values of a person can be identified from their social
network usage. However, the value priority of a person may change over time due
to different factors such as life experiences, influence, social structure and
technology. Existing studies do not conduct any analysis regarding the change
of users' value from the social influence, i.e., group persuasion, form the
social media usage. In our research, first, we predict users' value score by
the influence of friends from their social media usage. We propose a Bounded
Confidence Model (BCM) based value dynamics model from 275 different ego
networks in Facebook that predicts how social influence may persuade a person
to change their value over time. Then, to predict better, we use particle swarm
optimization based hyperparameter tuning technique. We observe that these
optimized hyperparameters produce accurate future value score. We also run our
approach with different machine learning based methods and find support vector
regression (SVR) outperforms other regressor models. By using SVR with the best
hyperparameters of BCM model, we find the lowest Mean Squared Error (MSE) score
0.00347.",http://arxiv.org/abs/2109.08021v1
"Exploring Coevolutionary Dynamics of Competitive Arms-Races Between
  Infinitely Diverse Heterogenous Adaptive Automated Trader-Agents",2021-09-21T20:31:38Z,"Nik Alexandrov, Dave Cliff, Charlie Figuero","We report on a series of experiments in which we study the coevolutionary
""arms-race"" dynamics among groups of agents that engage in adaptive automated
trading in an accurate model of contemporary financial markets. At any one
time, every trader in the market is trying to make as much profit as possible
given the current distribution of different other trading strategies that it
finds itself pitched against in the market; but the distribution of trading
strategies and their observable behaviors is constantly changing, and changes
in any one trader are driven to some extent by the changes in all the others.
Prior studies of coevolutionary dynamics in markets have concentrated on
systems where traders can choose one of a small number of fixed pure
strategies, and can change their choice occasionally, thereby giving a market
with a discrete phase-space, made up of a finite set of possible system states.
Here we present first results from two independent sets of experiments, where
we use minimal-intelligence trading-agents but in which the space of possible
strategies is continuous and hence infinite. Our work reveals that by taking
only a small step in the direction of increased realism we move immediately
into high-dimensional phase-spaces, which then present difficulties in
visualising and understanding the coevolutionary dynamics unfolding within the
system. We conclude that further research is required to establish better
analytic tools for monitoring activity and progress in co-adapting markets. We
have released relevant Python code as open-source on GitHub, to enable others
to continue this work.",http://arxiv.org/abs/2109.10429v1
"Shifting Polarization and Twitter News Influencers between two U.S.
  Presidential Elections",2021-11-03T20:08:54Z,"James Flamino, Alessandro Galezzi, Stuart Feldman, Michael W. Macy, Brendan Cross, Zhenkun Zhou, Matteo Serafino, Alexandre Bovet, Hernan A. Makse, Boleslaw K. Szymanski","Social media are decentralized, interactive, and transformative, empowering
users to produce and spread information to influence others. This has changed
the dynamics of political communication that were previously dominated by
traditional corporate news media. Having hundreds of millions of tweets
collected over the 2016 and 2020 U.S. presidential elections gave us a unique
opportunity to measure the change in polarization and the diffusion of
political information. We analyze the diffusion of political information among
Twitter users and investigate the change of polarization between these
elections and how this change affected the composition and polarization of
influencers and their retweeters. We identify ""influencers"" by their ability to
spread information and classify them into those affiliated with a media
organization, a political organization, or unaffiliated. Most of the top
influencers were affiliated with media organizations during both elections. We
found a clear increase from 2016 to 2020 in polarization among influencers and
among those whom they influence. Moreover, 75% of the top influencers in 2020
were not present in 2016, demonstrating that such status is difficult to
retain. Between 2016 and 2020, 10% of influencers affiliated with media were
replaced by center- or right-orientated influencers affiliated with political
organizations and unaffiliated influencers.",http://arxiv.org/abs/2111.02505v1
Period Change Rates in Large Magellanic Cloud Cepheids Revisited,2021-11-05T13:47:01Z,"N. Rodríguez-Segovia, G. Hajdu, M. Catelan, F. Espinoza-Arancibia, G. Boggiano, C. Cenzano, E. Garcés H., K. Joachimi, C. Muñoz-López, C. Ordenes-Huanca, C. Orquera-Rojas, P. Torres, Á. Valenzuela-Navarro","The period-change rate (PCR) of pulsating variable stars is a useful probe of
changes in their interior structure, and thus of their evolutionary stages. So
far, the PCRs of Classical Cepheids in the Large Magellanic Cloud (LMC) have
been explored in a limited sample of the total population of these variables.
Here we use a template-based method to build observed minus computed (O-C)
period diagrams, from which we can derive PCRs for these stars by taking
advantage of the long time baseline afforded by the Digital Access to a Sky
Century @ Harvard (DASCH) light curves, combined with additional data from the
Optical Gravitational Lensing Experiment (OGLE), the MAssive Compact Halo
Object (MACHO) project, Gaia's Data Release 2, and in some cases the All-Sky
Automated Survey (ASAS). From an initial sample of 2315 sources, our method
provides an unprecedented sample of 1303 LMC Classical Cepheids with accurate
PCRs, the largest for any single galaxy, including the Milky Way. The derived
PCRs are largely compatible with theoretically expected values, as computed by
our team using the Modules for Experiments in Stellar Astrophysics (MESA) code,
as well as with similar previous computations available in the literature.
Additionally, five long-period (P>50 d) sources display a cyclic behavior in
their O-C diagrams, which is clearly incompatible with evolutionary changes.
Finally, on the basis of their large positive PCR values, two first-crossing
Cepheid candidates are identified.",http://arxiv.org/abs/2111.03503v1
"Chemical-state analyses of Ni, Zn, and W ions in NiWO$_4$-ZnWO$_4$ solid
  solutions by X-ray photoelectron spectroscopy",2021-11-07T19:47:05Z,"G. Bakradze, A. Kalinko, A. Kuzmin","The chemical states of Ni, Zn, and W in microcrystalline NiWO$_4$-ZnWO$_4$
solid solutions were studied by X-ray photoelectron spectroscopy. The recorded
spectra of the Ni 2p, Zn 2p, and W 4f photoelectron lines and Ni
L$_2$M$_{23}$M$_{45}$, Zn L$_3$M$_{45}$M$_{45}$, and W N$_4$N$_{67}$N$_{7}$
Auger-transition lines show pronounced changes with increasing Zn
concentration. The positions of the resolved photoelectron and Auger-transition
lines were combined to construct so-called chemical-state plots (Wagner or
Auger-parameter plots) for metal ions in solid solutions. With increasing Zn
concentration, the Auger parameter increases for Ni and decreases for W, thus
evidencing a lowering and an increase of the electronic polarizability around
core-ionized Ni and W ions, respectively. At the same time, the character of
Zn-O bonds and the local structure around Zn ions do not change. It is
concluded that the dilution of NiWO$_4$ with Zn ions is accompanied by an
increase of the Ni-O bond ionicity and an increase of the W-O bond covalency.
These changes are attributed to the charge redistribution among [NiO$_6$] and
[WO$_6$] structural units. We show that a careful in-depth analysis of XPS data
obtained with a laboratory-based X-ray photoelectron spectroscopy system can
give chemically sensitive, qualitative information on the changes in the first
coordination spheres of each metal ion. This information is otherwise
accessible only by synchrotron-based techniques (such as X-ray absorption
spectroscopy).",http://arxiv.org/abs/2111.04162v1
"Exploiting the Power of Levenberg-Marquardt Optimizer with Anomaly
  Detection in Time Series",2021-11-11T05:57:11Z,"Wenyi Wang, John Taylor, Biswajit Bala","The Levenberg-Marquardt (LM) optimization algorithm has been widely used for
solving machine learning problems. Literature reviews have shown that the LM
can be very powerful and effective on moderate function approximation problems
when the number of weights in the network is not more than a couple of hundred.
In contrast, the LM does not seem to perform as well when dealing with pattern
recognition or classification problems, and inefficient when networks become
large (e.g. with more than 500 weights). In this paper, we exploit the true
power of LM algorithm using some real world aircraft datasets. On these
datasets most other commonly used optimizers are unable to detect the anomalies
caused by the changing conditions of the aircraft engine. The challenging
nature of the datasets are the abrupt changes in the time series data. We find
that the LM optimizer has a much better ability to approximate abrupt changes
and detect anomalies than other optimizers. We compare the performance, in
addressing this anomaly/change detection problem, of the LM and several other
optimizers. We assess the relative performance based on a range of measures
including network complexity (i.e. number of weights), fitting accuracy, over
fitting, training time, use of GPUs and memory requirement etc. We also discuss
the issue of robust LM implementation in MATLAB and Tensorflow for promoting
more popular usage of the LM algorithm and potential use of LM optimizer for
large-scale problems.",http://arxiv.org/abs/2111.06060v1
"Attentive Federated Learning for Concept Drift in Distributed 5G Edge
  Networks",2021-11-14T21:48:49Z,"Amir Hossein Estiri, Muthucumaru Maheswaran","Machine learning (ML) is expected to play a major role in 5G edge computing.
Various studies have demonstrated that ML is highly suitable for optimizing
edge computing systems as rapid mobility and application-induced changes occur
at the edge. For ML to provide the best solutions, it is important to
continually train the ML models to include the changing scenarios. The sudden
changes in data distributions caused by changing scenarios (e.g., 5G base
station failures) is referred to as concept drift and is a major challenge to
continual learning. The ML models can present high error rates while the drifts
take place and the errors decrease only after the model learns the
distributions. This problem is more pronounced in a distributed setting where
multiple ML models are being used for different heterogeneous datasets and the
final model needs to capture all concept drifts. In this paper, we show that
using Attention in Federated Learning (FL) is an efficient way of handling
concept drifts. We use a 5G network traffic dataset to simulate concept drift
and test various scenarios. The results indicate that Attention can
significantly improve the concept drift handling capability of FL.",http://arxiv.org/abs/2111.07457v1
Explaining GNN over Evolving Graphs using Information Flow,2021-11-19T04:29:38Z,"Yazheng Liu, Xi Zhang, Sihong Xie","Graphs are ubiquitous in many applications, such as social networks,
knowledge graphs, smart grids, etc.. Graph neural networks (GNN) are the
current state-of-the-art for these applications, and yet remain obscure to
humans. Explaining the GNN predictions can add transparency. However, as many
graphs are not static but continuously evolving, explaining changes in
predictions between two graph snapshots is different but equally important.
Prior methods only explain static predictions or generate coarse or irrelevant
explanations for dynamic predictions. We define the problem of explaining
evolving GNN predictions and propose an axiomatic attribution method to
uniquely decompose the change in a prediction to paths on computation graphs.
The attribution to many paths involving high-degree nodes is still not
interpretable, while simply selecting the top important paths can be suboptimal
in approximating the change. We formulate a novel convex optimization problem
to optimally select the paths that explain the prediction evolution.
Theoretically, we prove that the existing method based on
Layer-Relevance-Propagation (LRP) is a special case of the proposed algorithm
when an empty graph is compared with. Empirically, on seven graph datasets,
with a novel metric designed for evaluating explanations of prediction change,
we demonstrate the superiority of the proposed approach over existing methods,
including LRP, DeepLIFT, and other path selection methods.",http://arxiv.org/abs/2111.10037v1
"Understanding Developers Well-Being and Productivity: a 2-year
  Longitudinal Analysis during the COVID-19 Pandemic",2021-11-19T18:07:21Z,"Daniel Russo, Paul H. P. Hanel, Niels van Berkel","The COVID-19 pandemic has brought significant and enduring shifts in various
aspects of life, including increased flexibility in work arrangements. In a
longitudinal study, spanning 24 months with six measurement points from April
2020 to April 2022, we explore changes in well-being, productivity, social
contacts, and needs of software engineers during this time. Our findings
indicate systematic changes in various variables. For example, well-being and
quality of social contacts increased while emotional loneliness decreased as
lockdown measures were relaxed. Conversely, people's boredom and productivity,
remained stable. Furthermore, a preliminary investigation into the future of
work at the end of the pandemic revealed a consensus among developers for a
preference of hybrid work arrangements. We also discovered that prior job
changes and low job satisfaction were consistently linked to intentions to
change jobs if current work conditions do not meet developers' needs. This
highlights the need for software organizations to adapt to various work
arrangements to remain competitive employers. Building upon our findings and
the existing literature, we introduce the Integrated Job Demands-Resources and
Self-Determination (IJARS) Model as a comprehensive framework to explain the
well-being and productivity of software engineers during the COVID-19 pandemic.",http://arxiv.org/abs/2111.10349v3
"Winds of Change: Impact of COVID-19 on Vaccine-related Opinions of
  Twitter users",2021-11-20T19:33:51Z,"Soham Poddar, Mainack Mondal, Janardan Misra, Niloy Ganguly, Saptarshi Ghosh","Administering COVID-19 vaccines at a societal scale has been deemed as the
most appropriate way to defend against the COVID-19 pandemic. This global
vaccination drive naturally fueled a possibility of Pro-Vaxxers and
Anti-Vaxxers strongly expressing their supports and concerns regarding the
vaccines on social media platforms. Understanding this online discourse is
crucial for policy makers. This understanding is likely to impact the success
of vaccination drives and might even impact the final outcome of our fight
against the pandemic. The goal of this work is to improve this understanding
using the lens of Twitter-discourse data. We first develop a classifier that
categorizes users according to their vaccine-related stance with high precision
(97%). Using this method we detect and investigate specific user-groups who
posted about vaccines in pre-COVID and COVID times. Specifically, we identify
distinct topics that these users talk about, and investigate how
vaccine-related discourse has changed between pre-COVID times and COVID times.
Finally, for the first time, we investigate the change of vaccine-related
stances in Twitter users and shed light on potential reasons for such changes
in stance. Our dataset and classifier are available at
https://github.com/sohampoddar26/covid-vax-stance.",http://arxiv.org/abs/2111.10667v1
"Continual Active Learning Using Pseudo-Domains for Limited Labelling
  Resources and Changing Acquisition Characteristics",2021-11-25T13:11:49Z,"Matthias Perkonigg, Johannes Hofmanninger, Christian Herold, Helmut Prosch, Georg Langs","Machine learning in medical imaging during clinical routine is impaired by
changes in scanner protocols, hardware, or policies resulting in a
heterogeneous set of acquisition settings. When training a deep learning model
on an initial static training set, model performance and reliability suffer
from changes of acquisition characteristics as data and targets may become
inconsistent. Continual learning can help to adapt models to the changing
environment by training on a continuous data stream. However, continual manual
expert labelling of medical imaging requires substantial effort. Thus, ways to
use labelling resources efficiently on a well chosen sub-set of new examples is
necessary to render this strategy feasible.
  Here, we propose a method for continual active learning operating on a stream
of medical images in a multi-scanner setting. The approach automatically
recognizes shifts in image acquisition characteristics - new domains -, selects
optimal examples for labelling and adapts training accordingly. Labelling is
subject to a limited budget, resembling typical real world scenarios. To
demonstrate generalizability, we evaluate the effectiveness of our method on
three tasks: cardiac segmentation, lung nodule detection and brain age
estimation. Results show that the proposed approach outperforms other active
learning methods, while effectively counteracting catastrophic forgetting.",http://arxiv.org/abs/2111.13069v2
TRIP: Refining Image-to-Image Translation via Rival Preferences,2021-11-26T10:30:55Z,"Yinghua Yao, Yuangang Pan, Ivor W. Tsang, Xin Yao","Relative attribute (RA), referring to the preference over two images on the
strength of a specific attribute, can enable fine-grained image-to-image
translation due to its rich semantic information. Existing work based on RAs
however failed to reconcile the goal for fine-grained translation and the goal
for high-quality generation. We propose a new model TRIP to coordinate these
two goals for high-quality fine-grained translation. In particular, we
simultaneously train two modules: a generator that translates an input image to
the desired image with smooth subtle changes with respect to the interested
attributes; and a ranker that ranks rival preferences consisting of the input
image and the desired image. Rival preferences refer to the adversarial ranking
process: (1) the ranker thinks no difference between the desired image and the
input image in terms of the desired attributes; (2) the generator fools the
ranker to believe that the desired image changes the attributes over the input
image as desired. RAs over pairs of real images are introduced to guide the
ranker to rank image pairs regarding the interested attributes only. With an
effective ranker, the generator would ""win"" the adversarial game by producing
high-quality images that present desired changes over the attributes compared
to the input image. The experiments on two face image datasets and one shoe
image dataset demonstrate that our TRIP achieves state-of-art results in
generating high-fidelity images which exhibit smooth changes over the
interested attributes.",http://arxiv.org/abs/2111.13411v1
Enumerations of Universal Cycles for $k$-Permutations,2021-11-27T04:52:22Z,"Zuling Chang, Jie Xue","Universal cycle for $k$-permutations is a cyclic arrangement in which each
$k$-permutation appears exactly once as $k$ consecutive elements. Enumeration
problem of universal cycles for $k$-permutations is discussed and one new
enumerating method is proposed in this paper. Accurate enumerating formulae are
provided when $k=2,3$.",http://arxiv.org/abs/2111.13814v1
"Head and Body: Unified Detector and Graph Network for Person Search in
  Media",2021-11-27T13:09:18Z,"Xiujun Shu, Yusheng Tao, Ruizhi Qiao, Bo Ke, Wei Wen, Bo Ren","Person search in media has seen increasing potential in Internet
applications, such as video clipping and character collection. This task is
common but overlooked by previous person search works which focus on
surveillance scenes. The media scenarios have some different challenges from
surveillance scenes. For example, a person may change his clothes frequently.
To alleviate this issue, this paper proposes a Unified Detector and Graph
Network (UDGNet) for person search in media. UDGNet is the first person search
framework to detect and re-identify the human body and head simultaneously.
Specifically, it first builds two branches based on a unified network to detect
the human body and head, then the detected body and head are used for
re-identification. This dual-task approach can significantly enhance
discriminative learning. To tackle the cloth-changing issue, UDGNet builds two
graphs to explore reliable links among cloth-changing samples and utilizes a
graph network to learn better embeddings. This design effectively enhances the
robustness of person search to cloth-changing challenges. Besides, we
demonstrate that UDGNet can be implemented with both anchor-based and
anchor-free person search frameworks and further achieve performance
improvement. This paper also contributes a large-scale dataset for Person
Search in Media (PSM), which provides both body and head annotations. It is by
far the largest dataset for person search in media. Experiments show that
UDGNet improves the anchor-free model AlignPS by 12.1% in mAP. Meanwhile, it
shows good generalization across surveillance and longterm scenarios. The
dataset and code will be available at: https://github.com/shuxjweb/PSM.git.",http://arxiv.org/abs/2111.13888v1
"A Systematic Analysis of Stellar Populations in the Host Galaxies of
  Changing-look AGNs",2021-12-14T10:40:47Z,"Jun-Jie Jin, Xue-Bing Wu, Xiao-Tong Feng","""Changing-look"" active galactic nuclei (CL-AGNs) are a newly-discovered class
of AGNs that show the appearance (or disappearance) of broad emission lines
within a short time scale (months to years) and are often associated with the
dramatic change of their continuum emissions. They provide us an unprecedented
chance to directly investigate the host galaxy properties with minimal
contamination from the luminous central engine during the ""turn-off"" state,
which is difficult for normal luminous AGNs. In this work, for the first time,
we systematically characterize the stellar populations and star formation
histories (SFHs) of host galaxies for 26 turn-off CL-AGNs using the stellar
population synthesis code STARLIGHT. We find that the stellar populations of
CL-AGNs are similar to that of normal AGNs, excepts that the intermediate
stellar populations contribute more fraction. We estimate their stellar
velocity dispersions ($\rm \sigma_{\star}$) and black hole masses ($\rm
M_{BH,vir}$) and find that CL-AGNs also follow the overall $\rm
M_{BH}-\sigma_{\star}$ relationship. We also confirm the previous claim that
CL-AGNs tend to be biased towards lower Eddington ratio, and their extreme
variabilities are more likely due to the intrinsic changes of accretion rates.
In addition, CL-AGNs with recent star formations (SF) tend to have higher
Eddington ratio. Compared with previous studies, our analysis suggests that
there may be a correlation between the CL-AGN host galaxy properties and their
CL phenomena.",http://arxiv.org/abs/2112.07284v2
Morphology of cooperatively rearranging regions in active glass formers,2021-12-15T11:03:57Z,"Dipanwita Ghoshal, Ashwin Joy","Super cooled liquids display increasingly heterogeneous dynamics as
temperature is lowered towards the glass transition ($T_{g}$). A hallmark of
this dynamical heterogeneity is the spontaneous emergence of cooperative
rearranging regions (CRRs) composed of fast moving particles. While these CRRs
in passive glass formers have been explored in great detail, thus understanding
is severely limited in active glass formers. The existing consensus on the
morphology of CRRs in a passive glass former prioritizes its fast subsets,
composed of fast moving particles. In the present study, we focus on a
synthetic athermal active glass former and show an equal contribution for the
morphology of CRRs from slow subsets as well. Both these subsets exhibit an
exponential distribution in their structure which strongly correlates with the
existence of CRRs. Interestingly, we also observe that the fractal dimensions
($d_{\text{f}}$) of these subsets share both string and compact like morphology
that tends to vary in opposite fashion with the control parameters, namely the
persistent time ($\tau_{p}$) and the effective temperature ($T_{\text{eff}}$).
The fractal dimension $d_{\text{f}}$ measures the roughness or put simply the
compactness of fractal objects at their boundaries. More precisely, molecules
are loosely bound in a structure for which boundary is rough and thereby this
condition facilitates its structural change in terms of size and shape. It is
also a fact that any structural change is a signature of relaxation dynamics in
the context of glass forming liquids. Thus, in the present study, we observe a
change in $d_{\text{f}}$ with $T_{\text{eff}}$ and $\tau_{p}$ from the insights
of morphology variation that causes structural change, both in the BD limit and
non-equilibrium limit.",http://arxiv.org/abs/2112.08039v1
"Skyrmion Alignment and Pinning Effects in a Disordered Multi-Phase
  Skyrmion Material Co8Zn8Mn4",2021-12-16T07:08:45Z,"M. E. Henderson, M. Bleuel, J. Beare, D. G. Cory, B. Heacock, M. G. Huber, G. M. Luke, M. Pula, D. Sarenac, S. Sharma, E. M. Smith, K. Zhernenkov, D. A. Pushin","Underlying disorder in skyrmion materials may both inhibit and facilitate
skyrmion reorientations and changes in topology. The identification of these
disorder-induced topologically active regimes is critical to realizing robust
skyrmion spintronic implementations, yet few studies exist for disordered bulk
samples. Here, we employ small-angle neutron scattering (SANS) and
micromagnetic simulations to examine the influence of skyrmion order on
skyrmion lattice formation, transition, and reorientation dynamics across the
phase space of a disordered polycrystalline Co$_{8}$Zn$_{8}$Mn$_{4}$ bulk
sample. Our measurements reveal a new disordered-to-ordered skyrmion square
lattice transition pathway characterized by the novel promotion of four-fold
order in SANS and accompanied by a change in topology of the system, reinforced
through micromagnetic simulations. Pinning responses are observed to dominate
skyrmion dynamics in the metastable triangular lattice phase, enhancing
skyrmion stabilization through a remarkable and previously undetected skyrmion
memory effect which reproduces previous ordering processes and persists in zero
field. These results uncover the cooperative interplay of anisotropy and
disorder in skyrmion formation and restructuring dynamics, establishing new
tunable pathways for skyrmion manipulation.",http://arxiv.org/abs/2112.08669v2
"Locomotion without force, and impulse via dissipation: Robotic swimming
  in curved space via geometric phase",2021-12-17T19:51:13Z,"Shengkai Li, Tianyu Wang, Velin H. Kojouharov, James McInerney, Yasemin O. Aydin, Enes Aydin, Daniel I. Goldman, D. Zeb Rocklin","Locomotion by shape changes (spermatozoon swimming, snake slithering, bird
flapping) or gas expulsion (rocket firing) is assumed to require environmental
interaction, due to conservation of momentum. As first noted in (Wisdom, 2003)
and later in (Gu\'eron, 2009) and (Avron et al, 2006), in curved space or
spacetime the non-commutativity of translations permits translation without
momentum exchange, just as falling cats and lizards can self-deform to reorient
in flat space without environmental interaction. Translation in curved space
can occur not only in gravitationally induced curved spacetime (where
translation is predicted to be on the order of $10^{-23}$ m per gait cycle) but
also in the curved surfaces encountered by locomotors in real-world
environments. Here we show that a precision robophysical apparatus consisting
of motors driven on curved tracks (and thereby confined to a spherical surface
without a solid substrate) can self-propel without environmental momentum
exchange (impulse) via shape changes that can generate gauge potentials that
manifest as translations. Our system produces shape changes comparable to the
environment's inverse curvatures and generates from zero momentum forward
movement of $10^{-1}$ cm per gait cycle even while resisted by weak
gravitational and frictional forces. Dissipation via friction eventually
arrests the robot but also imbues it with momentum which can be released upon a
cessation of shape changes. This work demonstrates how the interaction between
environmental curvature, active driving and geometric phases yields rich,
exotic phenomena.",http://arxiv.org/abs/2112.09740v2
"Influence of Sequential Changes in the Crude Oil-Water Interfacial
  Tension on Spontaneous Imbibition in Oil-Wet Sandstone",2021-12-24T06:21:08Z,"Anupong Sukee, Tanakon Nunta, Maje Alhaji Haruna, Azim Kalantariasl, Suparit Tangparitkul","Crude oil-water interfacial tension in petroleum reservoir is reduced or
increased due to surfactant injection or surfactant retention, respectively.
Changes in the interfacial tension crucially attribute to a governing capillary
pressure and hence an oil displacement in spontaneous imbibition process. The
current study attempts to elucidate an influence of such changes on spontaneous
imbibition by replacing surfactant concentration consecutively with two
approaches: sequential decrease and sequential increase in the interfacial
tension. Two fluid flow directions were examined simultaneously: co-current and
counter-current flows. With strongly oil-wet wettability, capillarity was a
resisting element to oil displacement and therefore controlled by the oil-water
interfacial tension. The sequential-reduced interfacial tension was found to
weaken such resisting capillary force gradually and resulted in consecutive
incremental oil production. On the contrary, the sequential-increased
interfacial tension initiated the lowest interfacial tension fluid that
produced an immediate large amount of oil, but did not much displace further
oil. The current study observed a greater oil recovery obtained from a
sequential reduction in the interfacial tension scheme (26.9%) compared to a
conventional single reduction scheme (22.4%), with both schemes attaining same
interfacial tension at last. In counter-current imbibition, same
characteristics of oil displacement were observed as in co-current imbibition,
with less oil produced and less sensitive to fluid changes due to negligible
gravitational contribution.",http://arxiv.org/abs/2112.12959v1
Weakly Supervised Change Detection Using Guided Anisotropic Difusion,2021-12-31T10:03:47Z,"Rodrigo Caye Daudt, Bertrand Le Saux, Alexandre Boulch, Yann Gousseau","Large scale datasets created from crowdsourced labels or openly available
data have become crucial to provide training data for large scale learning
algorithms. While these datasets are easier to acquire, the data are frequently
noisy and unreliable, which is motivating research on weakly supervised
learning techniques. In this paper we propose original ideas that help us to
leverage such datasets in the context of change detection. First, we propose
the guided anisotropic diffusion (GAD) algorithm, which improves semantic
segmentation results using the input images as guides to perform edge
preserving filtering. We then show its potential in two weakly-supervised
learning strategies tailored for change detection. The first strategy is an
iterative learning method that combines model optimisation and data cleansing
using GAD to extract the useful information from a large scale change detection
dataset generated from open vector data. The second one incorporates GAD within
a novel spatial attention layer that increases the accuracy of weakly
supervised networks trained to perform pixel-level predictions from image-level
labels. Improvements with respect to state-of-the-art are demonstrated on 4
different public datasets.",http://arxiv.org/abs/2112.15367v1
Matter-driven change of spacetime topology,2021-02-27T11:55:32Z,"J. Ambjørn, Z. Drogosz, J. Gizbert-Studnicki, A. Görlich, J. Jurkiewicz, D. Németh","Using Monte-Carlo computer simulations, we study the impact of matter fields
on the geometry of a typical quantum universe in the CDT model of lattice
quantum gravity. The quantum universe has the size of a few Planck lengths and
the spatial topology of a three-torus. The matter fields are multi-component
scalar fields taking values in a torus with circumference $\delta$ in each
spatial direction, which acts as a new parameter in the CDT model. Changing
$\delta$, we observe a phase transition caused by the scalar field. This
discovery may have important consequences for quantum universes with
non-trivial topology, since the phase transition can change the topology to a
simply connected one.",http://arxiv.org/abs/2103.00198v3
"The effects of large-scale magnetic fields on the model for repeating
  changing-look AGNs",2021-03-01T07:50:27Z,"Xin Pan, Shuang-Liang Li, Xinwu Cao","Periodic outbursts are observed in several changing-look (CL) active galactic
nuclei (AGNs). \citet{sniegowska_possible_2020} suggested a model to explain
the repeating CL in these AGNs, where the periodic outbursts are triggered in a
narrow unstable zone between an inner ADAF and outer thin disk. In this work,
we intend to investigate the effects of large-scale magnetic fields on the
limit cycle behaviors of CL AGNs. The winds driven by magnetic fields can
significantly change the structure of thin disk by taking away the angular
momentum and energy of the disk. It is found that the period of outburst in
repeating CL AGNs can be substantially reduced by the magnetic fields.
Conversely, if we keep the period unchanged, the outburst intensity can be
raised for several times. These results can help to explain the observational
properties of multiple CL AGNs. Besides the magnetic fields, the effects of
transition radius $R_{\rm tr}$, the width of transition zone $\Delta R$ and
Shakura-Sunyaev parameter $\alpha$ are also explored in this work.",http://arxiv.org/abs/2103.00828v1
The rates of growth in an acylindrically hyperbolic group,2021-03-02T02:55:00Z,Koji Fujiwara,"Let $G$ be an acylindrically hyperbolic group on a $\delta$-hyperbolic space
$X$. Assume there exists $M$ such that for any finite generating set $S$ of
$G$, the set $S^M$ contains a hyperbolic element on $X$. Suppose that $G$ is
equationally Noetherian. Then we show the set of the growth rates of $G$ is
well-ordered (Theorem 1.1). The conclusion was known for hyperbolic groups, and
this is a generalization.
  Our result applies to all lattices in simple Lie groups of rank-1 (Theorem
1.3), and more generally, some family of relatively hyperbolic groups (Theorem
1.2). It also applies to the fundamental group, of exponential growth, of a
closed orientable $3$-manifold except for the case that the manifold has
Sol-geometry (Theorem 5.7).",http://arxiv.org/abs/2103.01430v3
"Spatial Attention Point Network for Deep-learning-based Robust
  Autonomous Robot Motion Generation",2021-03-02T09:53:15Z,"Hideyuki Ichiwara, Hiroshi Ito, Kenjiro Yamamoto, Hiroki Mori, Tetsuya Ogata","Deep learning provides a powerful framework for automated acquisition of
complex robotic motions. However, despite a certain degree of generalization,
the need for vast amounts of training data depending on the work-object
position is an obstacle to industrial applications. Therefore, a robot
motion-generation model that can respond to a variety of work-object positions
with a small amount of training data is necessary. In this paper, we propose a
method robust to changes in object position by automatically extracting spatial
attention points in the image for the robot task and generating motions on the
basis of their positions. We demonstrate our method with an LBR iiwa 7R1400
robot arm on a picking task and a pick-and-place task at various positions in
various situations. In each task, the spatial attention points are obtained for
the work objects that are important to the task. Our method is robust to
changes in object position. Further, it is robust to changes in background,
lighting, and obstacles that are not important to the task because it only
focuses on positions that are important to the task.",http://arxiv.org/abs/2103.01598v1
"Unconventional topological transitions in a self-organized magnetic
  ladder",2021-03-02T19:00:00Z,"Maciej M. Maśka, Nicholas Sedlmayr, Aksel Kobiałka, Tadeusz Domański","It is commonly assumed that topological phase transitions in topological
superconductors are accompanied by a closing of the topological gap or a change
of the symmetry of the system. We demonstrate that an unconventional
topological phase transition with neither gap closing nor a change of symmetry
is possible. We consider a nanoscopic length ladder of atoms on a
superconducting substrate, comprising self-organized magnetic moments coupled
to itinerant electrons. For a range of conditions, the ground state of such a
system prefers helical magnetic textures, self-sustaining topologically
nontrivial phase. Abrupt changes in the magnetic order as a function of induced
superconducting pairing or chemical potential can cause topological phase
transitions without closing the topological gap. Furthermore, the ground state
prefers either parallel or anti-parallel configurations along the rungs, and
the anti-parallel configuration causes an emergent time reversal asymmetry
protecting Kramer's pair's of Majorana zero modes, but in a BDI topological
superconductor. We determine the topological invariant and inspect the boundary
Majorana zero modes.",http://arxiv.org/abs/2103.01961v3
Measuring Vacancies: Firm-level Evidence from Two Measures,2021-03-03T09:17:15Z,"Niels-Jakob Harbo Hansen, Hans Henrik Sievertsen","Using firm-level survey- and register-data for both Sweden and Denmark we
show systematic mis-measurement in both vacancy measures. While the
register-based measure on the aggregate constitutes a quarter of the
survey-based measure, the latter is not a super-set of the former. To obtain
the full set of unique vacancies in these two databases, the number of survey
vacancies should be multiplied by approximately 1.2. Importantly, this
adjustment factor varies over time and across firm characteristics. Our
findings have implications for both the search-matching literature and policy
analysis based on vacancy measures: Observed changes in vacancies can be an
outcome of changes in mis-measurement, and are not necessarily changes in the
actual number of vacancies.",http://arxiv.org/abs/2103.02272v1
Product Partition Dynamic Generalized Linear Models,2021-03-03T15:28:35Z,"Victor S. Comitti, Fábio N. Demarqui, Thiago R. dos Santos, Jéssica da Assunção Almeida","Detection and modeling of change-points in time-series can be considerably
challenging. In this paper we approach this problem by incorporating the class
of Dynamic Generalized Linear Models (DGLM) into the well know class of Product
Partition Models (PPM). This new methodology, that we call DGLM-PPM, extends
the PPM to distributions within the Exponential Family while also retaining the
flexibility of the DGLM class. It also provides a framework for Bayesian
multiple change-point detection in dynamic regression models. Inference on the
DGLM-PPM follow the steps of evolution and updating of the DGLM class. A Gibbs
Sampler scheme with an Adaptive Rejection Metropolis Sampling (ARMS) step
appended is used to compute posterior estimates of the relevant quantities. A
simulation study shows that the proposed model provides reasonable estimates of
the dynamic parameters and also assigns high change-point probabilities to the
breaks introduced in the artificial data generated for this work. We also
present a real life data example that highlights the superiority of the
DGLM-PPM over the conventional DGLM in both in-sample and out-of-sample
goodness of fit measures.",http://arxiv.org/abs/2103.02470v1
"Elastocaloric effect in amorphous polymer networks undergoing
  mechanotropic phase transitions",2021-03-03T20:18:45Z,"Jeremy A. Koch, Jeremy A. Herman, Timothy J. White","Deformations of amorphous polymer networks prepared with significant
concentrations of liquid crystalline mesogens have been recently reported to
undergo mechanotropic phase transitions. Here, we report that these
mechanotropic phase transitions are accompanied by an elastocaloric response
($\Delta T = 2.9 \text{ K}$). Applied uniaxial strain to the elastomeric
polymer network transitions the organization of the material from a disordered,
amorphous state (order parameter $Q=0$) to the nematic phase ($Q=0.47$). Both
the magnitude of the elastocaloric temperature change and mechanically induced
order parameter are dependent on the concentration of liquid crystal mesogens
in the material. While the observed temperature changes in these materials are
smaller than those observed in shape memory alloys, the responsivity, defined
as the temperature change divided by the input stress, is larger by an order of
magnitude.",http://arxiv.org/abs/2103.02660v1
"Changing the Narrative Perspective: From Deictic to Anaphoric Point of
  View",2021-03-06T19:03:42Z,"Mike Chen, Razvan Bunescu","We introduce the task of changing the narrative point of view, where
characters are assigned a narrative perspective that is different from the one
originally used by the writer. The resulting shift in the narrative point of
view alters the reading experience and can be used as a tool in fiction writing
or to generate types of text ranging from educational to self-help and
self-diagnosis. We introduce a benchmark dataset containing a wide range of
types of narratives annotated with changes in point of view from deictic (first
or second person) to anaphoric (third person) and describe a pipeline for
processing raw text that relies on a neural architecture for mention selection.
Evaluations on the new benchmark dataset show that the proposed architecture
substantially outperforms the baselines by generating mentions that are less
ambiguous and more natural.",http://arxiv.org/abs/2103.04176v1
"A compact and fast magnetic coil for the interaction manipulation of
  quantum gases with Feshbach resonances",2021-03-09T07:48:04Z,"A. Kell, M. Link, M. Breyer, A. Hoffmann, M. Köhl, K. Gao","Cold atom experiments commonly use broad magnetic Feshbach resonances to
manipulate the interaction between atoms. In order to induce quantum dynamics
by a change of the interaction strength, rapid ($\sim\mu s$) magnetic field
changes over several tens of Gauss are required. Here we present a compact
design of a coil and its control circuit for a change of the magnetic field up
to $36G$ in $3\mu s$. The setup comprises two concentric solenoids with minimal
space requirements, which can be readily added to existing apparatuses. This
design makes the observation of non-equilibrium physics with broad Feshbach
resonances accessible.",http://arxiv.org/abs/2103.05273v1
Adapting User Interfaces with Model-based Reinforcement Learning,2021-03-11T17:24:34Z,"Kashyap Todi, Gilles Bailly, Luis A. Leiva, Antti Oulasvirta","Adapting an interface requires taking into account both the positive and
negative effects that changes may have on the user. A carelessly picked
adaptation may impose high costs to the user -- for example, due to surprise or
relearning effort -- or ""trap"" the process to a suboptimal design immaturely.
However, effects on users are hard to predict as they depend on factors that
are latent and evolve over the course of interaction. We propose a novel
approach for adaptive user interfaces that yields a conservative adaptation
policy: It finds beneficial changes when there are such and avoids changes when
there are none. Our model-based reinforcement learning method plans sequences
of adaptations and consults predictive HCI models to estimate their effects. We
present empirical and simulation results from the case of adaptive menus,
showing that the method outperforms both a non-adaptive and a frequency-based
policy.",http://arxiv.org/abs/2103.06807v1
"Adaptation to Unknown Situations as the Holy Grail of Learning-Based
  Self-Adaptive Systems: Research Directions",2021-03-11T19:07:02Z,"Ivana Dusparic, Nicolas Cardozo","Self-adaptive systems continuously adapt to changes in their execution
environment. Capturing all possible changes to define suitable behaviour
beforehand is unfeasible, or even impossible in the case of unknown changes,
hence human intervention may be required. We argue that adapting to unknown
situations is the ultimate challenge for self-adaptive systems. Learning-based
approaches are used to learn the suitable behaviour to exhibit in the case of
unknown situations, to minimize or fully remove human intervention. While such
approaches can, to a certain extent, generalize existing adaptations to new
situations, there is a number of breakthroughs that need to be achieved before
systems can adapt to general unknown and unforeseen situations. We posit the
research directions that need to be explored to achieve unanticipated
adaptation from the perspective of learning-based self-adaptive systems. At
minimum, systems need to define internal representations of previously unseen
situations on-the-fly, extrapolate the relationship to the previously
encountered situations to evolve existing adaptations, and reason about the
feasibility of achieving their intrinsic goals in the new set of conditions. We
close discussing whether, even when we can, we should indeed build systems that
define their own behaviour and adapt their goals, without involving a human
supervisor.",http://arxiv.org/abs/2103.06908v1
What is Leading Order for LFV in SMEFT?,2021-03-12T11:06:08Z,"Marco Ardu, Sacha Davidson","Upcoming searches for lepton flavour change (LFV) aim to probe New
Physics(NP) scales up to $ \sim 10^4$ TeV, implying that they will be sensitive
to NP at lower scales that is suppressed by loops or small couplings. We
suppose that the NP responsable for LFV is beyond the reach of the LHC and can
be parametrised in Effective Field Theory, introduce a small power-counting
parameter \`a la Cabibbo-Wolfenstein, and assess whether the existing dimension
six operator basis and one-loop RGEs provide a good approximation for LFV. We
find that mu to e flavour-changing observables can be sensitive to a few dozen
dimension eight operators, and to some effects of two-loop anomalous
dimensions, for NP scales below 20-100 TeV. We also explore the effect of some
simplifying assumptions in the one-loop RGEs, such as neglecting
flavour-changing effects.",http://arxiv.org/abs/2103.07212v1
"""Warm Bodies"": A Post-Processing Technique for Animating Dynamic Blood
  Flow on Photos and Avatars",2021-03-14T18:09:42Z,"Daniel McDuff, Ewa Nowara","What breathes life into an embodied agent or avatar? While body motions such
as facial expressions, speech and gestures have been well studied, relatively
little attention has been applied to subtle changes due to underlying
physiology. We argue that subtle pulse signals are important for creating more
lifelike and less disconcerting avatars. We propose a method for animating
blood flow patterns, based on a data-driven physiological model that can be
used to directly augment the appearance of synthetic avatars and
photo-realistic faces. While the changes are difficult for participants to
""see"", they significantly more frequently select faces with blood flow as more
anthropomorphic and animated than faces without blood flow. Furthermore, by
manipulating the frequency of the heart rate in the underlying signal we can
change the perceived arousal of the character.",http://arxiv.org/abs/2103.07987v1
Variety of Scaling Laws for DNA Thermal Denaturation,2021-03-15T21:17:05Z,"Yulian Honchar, Christian von Ferber, Yurij Holovatch","We discuss possible mechanisms that may impact the order of the transition
between denaturated and bound DNA states and lead to changes in the scaling
laws that govern conformational properties of DNA strands. To this end, we
re-consider the Poland-Scheraga model and apply a polymer field theory approach
to calculate entropic exponents associated with the denaturated loop
distribution. We discuss in particular variants of this transition that may
occur due to the properties of the solution and may affect the self- and mutual
interaction of both single and double strands. We find that the effects studied
significantly influence the strength of the first order transition. This is
manifest in particular by the changes in the scaling laws that govern DNA loop
and strand distribution. As a quantitative measure of these changes we present
the values of corresponding scaling exponents. For the $d=4-\varepsilon$ case
we get corresponding $\varepsilon^4$ expansions and evaluate the perturbation
theory expansions at space dimension $d=3$ by means of resummation technique.",http://arxiv.org/abs/2103.08725v1
Group interactions modulate critical mass dynamics in social convention,2021-03-18T17:47:45Z,"Iacopo Iacopini, Giovanni Petri, Andrea Baronchelli, Alain Barrat","How can minorities of individuals overturn social conventions? The theory of
critical mass states that when a committed minority reaches a critical size, a
cascade of behavioural changes can occur, overturning apparently stable social
norms. Evidence comes from theoretical and empirical studies in which
minorities of very different sizes, including extremely small ones, manage to
bring a system to its tipping point. Here, we explore this diversity of
scenarios by introducing group interactions as a crucial element of realism
into a model for social convention. We find that the critical mass necessary to
trigger behaviour change can be very small if individuals have a limited
propensity to change their views. Moreover, the ability of the committed
minority to overturn existing norms depends in a complex way on the group size.
Our findings reconcile the different sizes of critical mass found in previous
investigations and unveil the critical role of groups in such a process. This
further highlights the importance of the emerging field of higher-order
networks, beyond pairwise interactions",http://arxiv.org/abs/2103.10411v3
"A Robust and Accurate Approach to Detect Process Drifts from Event
  Streams",2021-03-19T11:30:47Z,"Yang Lu, Qifan Chen, Simon Poon","Business processes are bound to evolve as a form of adaption to changes, and
such changes are referred as process drifts. Current process drift detection
methods perform well on clean event log data, but the performance can be
tremendously affected by noises. A good process drift detection method should
be accurate, fast, and robust to noises. In this paper, we propose an offline
process drift detection method which identifies each newly observed behaviour
as a candidate drift point and checks if the new behaviour can signify
significant changes to the original process behaviours. In addition, a
bidirectional search method is proposed to accurately locate both the adding
and removing of behaviours. The proposed method can accurately detect drift
points from event logs and is robust to noises. Both artificial and real-life
event logs are used to evaluate our method. Results show that our method can
consistently report accurate process drift time while maintaining a reasonably
fast detection speed.",http://arxiv.org/abs/2103.10749v3
"Nonequilibrium control of thermal and mechanical changes in a levitated
  system",2021-03-19T16:43:48Z,"Markus Rademacher, Michael Konopik, Maxime Debiossac, David Grass, Eric Lutz, Nikolai Kiesel","Fluctuation theorems are fundamental extensions of the second law of
thermodynamics for small nonequilibrium systems. While work and heat are
equally important forms of energy exchange, fluctuation relations have not been
experimentally assessed for the generic situation of simultaneous mechanical
and thermal changes. Thermal driving is indeed generally slow and more
difficult to realize than mechanical driving. Here, we use feedback cooling
techniques to implement fast and controlled temperature variations of an
underdamped levitated microparticle that are one order of magnitude faster than
the equilibration time. Combining mechanical and thermal control, we verify the
validity of a fluctuation theorem that accounts for both contributions, well
beyond the range of linear response theory. Our results allow the investigation
of general far-from-equilibrium processes in microscopic systems that involve
fast mechanical and thermal changes at the same time.",http://arxiv.org/abs/2103.10898v2
AET-EFN: A Versatile Design for Static and Dynamic Event-Based Vision,2021-03-22T08:09:03Z,"Chang Liu, Xiaojuan Qi, Edmund Lam, Ngai Wong","The neuromorphic event cameras, which capture the optical changes of a scene,
have drawn increasing attention due to their high speed and low power
consumption. However, the event data are noisy, sparse, and nonuniform in the
spatial-temporal domain with an extremely high temporal resolution, making it
challenging to design backend algorithms for event-based vision. Existing
methods encode events into point-cloud-based or voxel-based representations,
but suffer from noise and/or information loss. Additionally, there is little
research that systematically studies how to handle static and dynamic scenes
with one universal design for event-based vision. This work proposes the
Aligned Event Tensor (AET) as a novel event data representation, and a neat
framework called Event Frame Net (EFN), which enables our model for event-based
vision under static and dynamic scenes. The proposed AET and EFN are evaluated
on various datasets, and proved to surpass existing state-of-the-art methods by
large margins. Our method is also efficient and achieves the fastest inference
speed among others.",http://arxiv.org/abs/2103.11645v1
"An investigation of higher order moments of empirical financial data and
  the implications to risk",2021-03-24T13:54:08Z,"Luke De Clerk, Sergey Savel'ev","Here, we analyse the behaviour of the higher order standardised moments of
financial time series when we truncate a large data set into smaller and
smaller subsets, referred to below as time windows. We look at the effect of
the economic environment on the behaviour of higher order moments in these time
windows. We observe two different scaling relations of higher order moments
when the data sub sets' length decreases; one for longer time windows and
another for the shorter time windows. These scaling relations drastically
change when the time window encompasses a financial crisis. We also observe a
qualitative change of higher order standardised moments compared to the
gaussian values in response to a shrinking time window. We extend this analysis
to incorporate the effects these scaling relations have upon risk. We decompose
the return series within these time windows and carry out a Value-at-Risk
calculation. In doing so, we observe the manifestation of the scaling relations
through the change in the Value-at-Risk level. Moreover, we model the observed
scaling laws by analysing the hierarchy of rare events on higher order moments.",http://arxiv.org/abs/2103.13199v3
ECINN: Efficient Counterfactuals from Invertible Neural Networks,2021-03-25T09:23:24Z,"Frederik Hvilshøj, Alexandros Iosifidis, Ira Assent","Counterfactual examples identify how inputs can be altered to change the
predicted class of a classifier, thus opening up the black-box nature of, e.g.,
deep neural networks. We propose a method, ECINN, that utilizes the generative
capacities of invertible neural networks for image classification to generate
counterfactual examples efficiently. In contrast to competing methods that
sometimes need a thousand evaluations or more of the classifier, ECINN has a
closed-form expression and generates a counterfactual in the time of only two
evaluations. Arguably, the main challenge of generating counterfactual examples
is to alter only input features that affect the predicted outcome, i.e.,
class-dependent features. Our experiments demonstrate how ECINN alters
class-dependent image regions to change the perceptual and predicted class of
the counterfactuals. Additionally, we extend ECINN to also produce heatmaps
(ECINNh) for easy inspection of, e.g., pairwise class-dependent changes in the
generated counterfactual examples. Experimentally, we find that ECINNh
outperforms established methods that generate heatmap-based explanations.",http://arxiv.org/abs/2103.13701v2
"Impact of the COVID-19 outbreak on Italy's country reputation and stock
  market performance: a sentiment analysis approach",2021-03-13T14:03:11Z,"Gianpaolo Zammarchi, Francesco Mola, Claudio Conversano","During the recent Coronavirus disease 2019 (COVID-19) outbreak, the
microblogging service Twitter has been widely used to share opinions and
reactions to events. Italy was one of the first European countries to be
severely affected by the outbreak and to establish lockdown and stay-at-home
orders, potentially leading to country reputation damage. We resort to
sentiment analysis to investigate changes in opinions about Italy reported on
Twitter before and after the COVID-19 outbreak. Using different lexicons-based
methods, we find a breakpoint corresponding to the date of the first
established case of COVID-19 in Italy that causes a relevant change in
sentiment scores used as proxy of the country reputation. Next, we demonstrate
that sentiment scores about Italy are strongly associated with the levels of
the FTSE-MIB index, the Italian Stock Exchange main index, as they serve as
early detection signals of changes in the values of FTSE-MIB. Finally, we make
a content-based classification of tweets into positive and negative and use two
machine learning classifiers to validate the assigned polarity of tweets posted
before and after the outbreak.",http://arxiv.org/abs/2103.13871v1
Enabling Incremental Training with Forward Pass for Edge Devices,2021-03-25T17:43:04Z,"Dana AbdulQader, Shoba Krishnan, Claudionor N. Coelho Jr","Deep Neural Networks (DNNs) are commonly deployed on end devices that exist
in constantly changing environments. In order for the system to maintain it's
accuracy, it is critical that it is able to adapt to changes and recover by
retraining parts of the network. However, end devices have limited resources
making it challenging to train on the same device. Moreover, training deep
neural networks is both memory and compute intensive due to the backpropagation
algorithm. In this paper we introduce a method using evolutionary strategy (ES)
that can partially retrain the network enabling it to adapt to changes and
recover after an error has occurred. This technique enables training on an
inference-only hardware without the need to use backpropagation and with
minimal resource overhead. We demonstrate the ability of our technique to
retrain a quantized MNIST neural network after injecting noise to the input.
Furthermore, we present the micro-architecture required to enable training on
HLS4ML (an inference hardware architecture) and implement it in Verilog. We
synthesize our implementation for a Xilinx Kintex Ultrascale Field Programmable
Gate Array (FPGA) resulting in less than 1% resource utilization required to
implement the incremental training.",http://arxiv.org/abs/2103.14007v1
Wavelet Spatio-Temporal Change Detection on multi-temporal PolSAR images,2021-03-26T12:55:25Z,"Rodney Fonseca, Aluísio Pinheiro, Abdourrahmane Atto","We introduce WECS (Wavelet Energies Correlation Sreening), an unsupervised
sparse procedure to detect spatio-temporal change points on multi-temporal SAR
(POLSAR) images or even on sequences of very high resolution images. The
procedure is based on wavelet approximation for the multi-temporal images,
wavelet energy apportionment, and ultra-high dimensional correlation screening
for the wavelet coefficients. We present two complimentary wavelet measures in
order to detect sudden and/or cumulative changes, as well as for the case of
stationary or non-stationary multi-temporal images. We show WECS performance on
synthetic multi-temporal image data. We also apply the proposed method to a
time series of 85 satellite images in the border region of Brazil and the
French Guiana. The images were captured from November 08, 2015 to December 09
2017.",http://arxiv.org/abs/2103.14444v1
iLQR for Piecewise-Smooth Hybrid Dynamical Systems,2021-03-26T16:45:23Z,"Nathan J. Kong, George Council, Aaron M. Johnson","Trajectory optimization is a popular strategy for planning trajectories for
robotic systems. However, many robotic tasks require changing contact
conditions, which is difficult due to the hybrid nature of the dynamics. The
optimal sequence and timing of these modes are typically not known ahead of
time. In this work, we extend the Iterative Linear Quadratic Regulator (iLQR)
method to a class of piecewise smooth hybrid dynamical systems by allowing for
changing hybrid modes in the forward pass, using the saltation matrix to update
the gradient information in the backwards pass, and using a reference extension
to account for mode mismatch. We demonstrate these changes on a variety of
hybrid systems and compare the different strategies for computing the
gradients.",http://arxiv.org/abs/2103.14584v2
"Changing the Mind of Transformers for Topically-Controllable Language
  Generation",2021-03-29T05:02:25Z,"Haw-Shiuan Chang, Jiaming Yuan, Mohit Iyyer, Andrew McCallum","Large Transformer-based language models can aid human authors by suggesting
plausible continuations of text written so far. However, current interactive
writing assistants do not allow authors to guide text generation in desired
topical directions. To address this limitation, we design a framework that
displays multiple candidate upcoming topics, of which a user can select a
subset to guide the generation. Our framework consists of two components: (1) a
method that produces a set of candidate topics by predicting the centers of
word clusters in the possible continuations, and (2) a text generation model
whose output adheres to the chosen topics. The training of both components is
self-supervised, using only unlabeled text. Our experiments demonstrate that
our topic options are better than those of standard clustering approaches, and
our framework often generates fluent sentences related to the chosen topics, as
judged by automated metrics and crowdsourced workers.",http://arxiv.org/abs/2103.15335v1
"Remote Sensing Image Translation via Style-Based Recalibration Module
  and Improved Style Discriminator",2021-03-29T11:12:43Z,"Tiange Zhang, Feng Gao, Junyu Dong, Qian Du","Existing remote sensing change detection methods are heavily affected by
seasonal variation. Since vegetation colors are different between winter and
summer, such variations are inclined to be falsely detected as changes. In this
letter, we proposed an image translation method to solve the problem. A
style-based recalibration module is introduced to capture seasonal features
effectively. Then, a new style discriminator is designed to improve the
translation performance. The discriminator can not only produce a decision for
the fake or real sample, but also return a style vector according to the
channel-wise correlations. Extensive experiments are conducted on
season-varying dataset. The experimental results show that the proposed method
can effectively perform image translation, thereby consistently improving the
season-varying image change detection performance. Our codes and data are
available at https://github.com/summitgao/RSIT_SRM_ISD.",http://arxiv.org/abs/2103.15502v1
Text Mining of Stocktwits Data for Predicting Stock Prices,2021-03-13T03:29:14Z,"Mukul Jaggi, Priyanka Mandal, Shreya Narang, Usman Naseem, Matloob Khushi","Stock price prediction can be made more efficient by considering the price
fluctuations and understanding the sentiments of people. A limited number of
models understand financial jargon or have labelled datasets concerning stock
price change. To overcome this challenge, we introduced FinALBERT, an ALBERT
based model trained to handle financial domain text classification tasks by
labelling Stocktwits text data based on stock price change. We collected
Stocktwits data for over ten years for 25 different companies, including the
major five FAANG (Facebook, Amazon, Apple, Netflix, Google). These datasets
were labelled with three labelling techniques based on stock price changes. Our
proposed model FinALBERT is fine-tuned with these labels to achieve optimal
results. We experimented with the labelled dataset by training it on
traditional machine learning, BERT, and FinBERT models, which helped us
understand how these labels behaved with different model architectures. Our
labelling method competitive advantage is that it can help analyse the
historical data effectively, and the mathematical function can be easily
customised to predict stock movement.",http://arxiv.org/abs/2103.16388v1
Less is More: Sparse Sampling for Dense Reaction Predictions,2021-06-03T11:33:59Z,"Kezhou Lin, Xiaohan Wang, Zhedong Zheng, Linchao Zhu, Yi Yang","Obtaining viewer responses from videos can be useful for creators and
streaming platforms to analyze the video performance and improve the future
user experience. In this report, we present our method for 2021 Evoked
Expression from Videos Challenge. In particular, our model utilizes both audio
and image modalities as inputs to predict emotion changes of viewers. To model
long-range emotion changes, we use a GRU-based model to predict one sparse
signal with 1Hz. We observe that the emotion changes are smooth. Therefore, the
final dense prediction is obtained via linear interpolating the signal, which
is robust to the prediction fluctuation. Albeit simple, the proposed method has
achieved pearson's correlation score of 0.04430 on the final private test set.",http://arxiv.org/abs/2106.01764v1
A diachronic evaluation of gender asymmetry in euphemism,2021-06-03T19:00:11Z,"Anna Kapron-King, Yang Xu","The use of euphemisms is a known driver of language change. It has been
proposed that women use euphemisms more than men. Although there have been
several studies investigating gender differences in language, the claim about
euphemism usage has not been tested comprehensively through time. If women do
use euphemisms more, this could mean that women also lead the formation of new
euphemisms and language change over time. Using four large diachronic text
corpora of English, we evaluate the claim that women use euphemisms more than
men through a quantitative analysis. We assembled a list of 106 euphemism-taboo
pairs to analyze their relative use through time by each gender in the corpora.
Contrary to the existing belief, our results show that women do not use
euphemisms with a higher proportion than men. We repeated the analysis using
different subsets of the euphemism-taboo pairs list and found that our result
was robust. Our study indicates that in a broad range of settings involving
both speech and writing, and with varying degrees of formality, women do not
use or form euphemisms more than men.",http://arxiv.org/abs/2106.02083v1
"Large barocaloric effect with high pressure-driving efficiency in
  hexagonal MnNi0.77Fe0.23Ge alloy",2021-06-05T14:27:00Z,"Qingqi Zeng, Jianlei Shen, Enke Liu, Xuekui Xi, Wenhong Wang, Guangheng Wu, Xixiang Zhang","The hydrostatic pressure is expected to be an effective knob to tune the
magnetostructural phase transitions of hexagonal MMX alloy. In this study,
magnetization measurements under hydrostatic pressure were performed on a MMX
martensitic MnNi0.77Fe0.23Ge alloy. The magnetostructural transition
temperature can be efficiently tuned to lower temperatures by applying moderate
pressures, with a giant shift rate of -151 K GPa-1. A temperature span of 30 K
is obtained under the pressure, within which a large magnetic entropy change of
-23 J kg-1 K-1 in a field change of 5 T is induced by the mechanical energy
gain due to the large volume change. Meanwhile, a decoupling of structural and
magnetic transitions is observed at low temperatures when the martensitic
transition temperature is lower than the Curie temperature. These results show
a multi-parameter tunable caloric effect that benefits the solid-state cooling.",http://arxiv.org/abs/2106.02903v1
"Condition Integration Memory Network: An Interpretation of the Meaning
  of the Neuronal Design",2021-05-21T05:59:27Z,Cheng Qian,"Understanding the basic operational logics of the nervous system is essential
to advancing neuroscientific research. However, theoretical efforts to tackle
this fundamental problem are lacking, despite the abundant empirical data about
the brain that has been collected in the past few decades. To address this
shortcoming, this document introduces a hypothetical framework for the
functional nature of primitive neural networks. It analyzes the idea that the
activity of neurons and synapses can symbolically reenact the dynamic changes
in the world and thus enable an adaptive system of behavior. More
significantly, the network achieves this without participating in an
algorithmic structure. When a neuron's activation represents some symbolic
element in the environment, each of its synapses can indicate a potential
change to the element and its future state. The efficacy of a synaptic
connection further specifies the element's particular probability for, or
contribution to, such a change. As it fires, a neuron's activation is
transformed to its postsynaptic targets, resulting in a chronological shift of
the represented elements. As the inherent function of summation in a neuron
integrates the various presynaptic contributions, the neural network mimics the
collective causal relationship of events in the observed environment.",http://arxiv.org/abs/2106.05181v2
"Detection of relativistic fermions in Weyl semimetal TaAs by
  magnetostriction measurements",2021-06-10T21:35:01Z,"T. Cichorek, L. Bochenek, J. Juraszek, Yu. V. Sharlai, G. P. Mikitik","Thus far, a detection of the Dirac or Weyl fermions in topological semimetals
remains often elusive, since in these materials conventional charge carriers
exist as well. Here, measuring a field-induced length change of the prototype
Weyl semimetal TaAs at low temperatures, we find that its $c$-axis
magnetostriction amounts to relatively large values whereas the $a$-axis
magnetostriction exhibits strong variations with changing the orientation of
the applied magnetic field. It is discovered that at magnetic fields above the
ultra-quantum limit, the magnetostriction of TaAs contains a linear-in-field
term, which, as we show, is a hallmark of the Weyl fermions in a material.
Developing a theory for the magnetostriction of noncentrosymmetric topological
semimetals and applying it to TaAs, we additionally find several parameters
characterizing the interaction between the relativistic fermions and elastic
degrees of freedom in this semimetal. Our study shows how dilatometry can be
used to unveil Weyl fermions in candidate topological semimetals.",http://arxiv.org/abs/2106.06062v2
SAR Image Change Detection Based on Multiscale Capsule Network,2021-06-13T01:56:28Z,"Yunhao Gao, Feng Gao, Junyu Dong, Heng-Chao Li","Traditional change detection methods based on convolutional neural networks
(CNNs) face the challenges of speckle noise and deformation sensitivity for
synthetic aperture radar images. To mitigate these issues, we proposed a
Multiscale Capsule Network (Ms-CapsNet) to extract the discriminative
information between the changed and unchanged pixels. On the one hand, the
capsule module is employed to exploit the spatial relationship of features.
Therefore, equivariant properties can be achieved by aggregating the features
from different positions. On the other hand, an adaptive fusion convolution
(AFC) module is designed for the proposed Ms-CapsNet. Higher semantic features
can be captured for the primary capsules. Feature extracted by the AFC module
significantly improves the robustness to speckle noise. The effectiveness of
the proposed Ms-CapsNet is verified on three real SAR datasets. The comparison
experiments with four state-of-the-art methods demonstrated the efficiency of
the proposed method. Our codes are available at
https://github.com/summitgao/SAR_CD_MS_CapsNet.",http://arxiv.org/abs/2106.06896v5
Evolutionary Robust Clustering Over Time for Temporal Data,2021-06-14T09:07:42Z,"Qi Zhao, Bai Yan, Yuhui Shi","In many clustering scenes, data samples' attribute values change over time.
For such data, we are often interested in obtaining a partition for each time
step and tracking the dynamic change of partitions. Normally, a smooth change
is assumed for data to have a temporal smooth nature. Existing algorithms
consider the temporal smoothness as an a priori preference and bias the search
towards the preferred direction. This a priori manner leads to a risk of
converging to an unexpected region because it is not always the case that a
reasonable preference can be elicited given the little prior knowledge about
the data. To address this issue, this paper proposes a new clustering framework
called evolutionary robust clustering over time. One significant innovation of
the proposed framework is processing the temporal smoothness in an a posteriori
manner, which avoids unexpected convergence that occurs in existing algorithms.
Furthermore, the proposed framework automatically tunes the weight of
smoothness without data's affinity matrix and predefined parameters, which
holds better applicability and scalability. The effectiveness and efficiency of
the proposed framework are confirmed by comparing with state-of-the-art
algorithms on both synthetic and real datasets.",http://arxiv.org/abs/2106.07252v1
"Cyclical behavior of evolutionary dynamics in coordination games with
  changing payoffs",2021-06-15T15:33:10Z,George Loginov,"The paper presents a model of two-speed evolution in which the payoffs in the
population game (or, alternatively, the individual preferences) slowly adjust
to changes in the aggregate behavior of the population. The model investigates
how, for a population of myopic agents with homogeneous preferences, changes in
the environment caused by current aggregate behavior may affect future payoffs
and hence alter future behavior. The interaction between the agents is based on
a symmetric two-strategy game with positive externalities and negative feedback
from aggregate behavior to payoffs, so that at every point in time the
population has an incentive to coordinate, whereas over time the more popular
strategy becomes less appealing. Under the best response dynamics and the logit
dynamics with small noise levels the joint trajectories of preferences and
behavior converge to closed orbits around the unique steady state, whereas for
large noise levels the steady state of the logit dynamics becomes a sink. Under
the replicator dynamics the unique steady state of the system is repelling and
the trajectories are unbounded unstable spirals.",http://arxiv.org/abs/2106.08224v1
"Output, Employment, and Price Effects of U.S. Narrative Tax Changes: A
  Factor-Augmented Vector Autoregression Approach",2021-06-21T04:16:25Z,Masud Alam,"This paper examines the short- and long-run effects of U.S. federal personal
income and corporate income tax cuts on a wide array of economic policy
variables in a data-rich environment. Using a panel of U.S. macroeconomic data
set, made up of 132 quarterly macroeconomic series for 1959-2018, the study
estimates factor-augmented vector autoregression (FAVARs) models where an
extended narrative tax changes dataset combined with unobserved factors. The
narrative approach classifies if tax changes are exogenous or endogenous. This
paper identifies narrative tax shocks in the vector autoregression model using
the sign restrictions with Uhlig's (2005) penalty function. Empirical findings
show a significant expansionary effect of tax cuts on the macroeconomic
variables. Cuts in personal and corporate income taxes cause a rise in output,
investment, employment, and consumption; however, cuts in personal taxes appear
to be a more effective fiscal policy tool than the cut in corporate income
taxes. Real GDP, employment, investment, and industrial production increase
significantly and reach their maximum response values two years after personal
income tax cuts. The effects of corporate tax cuts have relatively smaller
effects on output and consumption but show immediate and higher effects on
fixed investment and price levels.",http://arxiv.org/abs/2106.10844v1
Differential forms and cohomology in tropical and complex geometry,2021-06-22T01:47:46Z,Ryota Mikami,"Ducros, Hrushovski, and Loeser gave maps from families of archimedean
diffrential forms to non-archiemedean (or tropical) ones, which are compatible
with integrals on algebraic varieties. In this paper, we introduce slight
modifications of their maps for complex projective varieties which give natural
maps from tropical to the usual Dolbeault cohomology. We also show that our
maps are compatible with integrals on generic semi-algebraic subsets and those
on their weighted tropicalizations. Weighted tropicalizations induce the dual
maps of the above maps of Dolbeault cohomology groups under some assumptions.",http://arxiv.org/abs/2106.11479v4
"Including topology change in Loop Quantum Gravity with topspin network
  formalism with application to homogeneous and isotropic cosmology",2021-06-27T10:28:11Z,Mattia Villani,"We apply topspin network formalism to Loop Quantum Gravity in order to
include in the theory the possibility of changes in the topology of spacetime.
We apply this formalism to three toy models: with the first, we find that the
topology can actually change due to the action of the Hamiltonian constraint
and with the second we find that the final state might be a superposition of
states with different topologies. In the third and last application, we
consider an homogeneous and isotropic Universe, calculating the difference
equation that describes the evolution of the system and which are the final
topological states after the action of the Hamiltonian constraint. For this
last case, we also calculate the transition amplitudes and probabilities from
the initial to the final states.",http://arxiv.org/abs/2106.14188v1
"Matter Effects on Mass Square Difference for Four Flavor Neutrino
  Oscillation",2021-06-30T09:54:06Z,"Vivek Kumar Nautiyal, Bipin Singh Koranga, Ashish Shrivastava, Neelam Das","We consider the matter effects on four flavor neutrino oscillation scheme
(3+1). In presence of sterile neutrino, the simplest four flavor neutrino
mixing there are six mixing angles and three Dirac CP phases. In this paper, we
discuss about the sensitivity of mass square difference effects Delta21,
Delta31, and Delta41 in the matter. We find that in presence of sterile
neutrino for four flavor mixing framework, only solar mass square difference
Delta21 and atmospheric neutrino mass square difference Delta31 change for
different values of Dirac phases and energy. There is no change of sterile
neutrino mass square differences. In this letter, we study the matter effects
on neutrino mass square differences Delta21, Delta31, and Delta41 and calculate
the percentage change with respect to the mass square difference in the matter
by varying energy for four flavor framework.",http://arxiv.org/abs/2106.15945v1
Grounding Representation Similarity with Statistical Testing,2021-08-03T17:58:16Z,"Frances Ding, Jean-Stanislas Denain, Jacob Steinhardt","To understand neural network behavior, recent works quantitatively compare
different networks' learned representations using canonical correlation
analysis (CCA), centered kernel alignment (CKA), and other dissimilarity
measures. Unfortunately, these widely used measures often disagree on
fundamental observations, such as whether deep networks differing only in
random initialization learn similar representations. These disagreements raise
the question: which, if any, of these dissimilarity measures should we believe?
We provide a framework to ground this question through a concrete test:
measures should have sensitivity to changes that affect functional behavior,
and specificity against changes that do not. We quantify this through a variety
of functional behaviors including probing accuracy and robustness to
distribution shift, and examine changes such as varying random initialization
and deleting principal components. We find that current metrics exhibit
different weaknesses, note that a classical baseline performs surprisingly
well, and highlight settings where all metrics appear to fail, thus providing a
challenge set for further improvement.",http://arxiv.org/abs/2108.01661v2
OSCAR-Net: Object-centric Scene Graph Attention for Image Attribution,2021-08-07T23:36:20Z,"Eric Nguyen, Tu Bui, Vishy Swaminathan, John Collomosse","Images tell powerful stories but cannot always be trusted. Matching images
back to trusted sources (attribution) enables users to make a more informed
judgment of the images they encounter online. We propose a robust image hashing
algorithm to perform such matching. Our hash is sensitive to manipulation of
subtle, salient visual details that can substantially change the story told by
an image. Yet the hash is invariant to benign transformations (changes in
quality, codecs, sizes, shapes, etc.) experienced by images during online
redistribution. Our key contribution is OSCAR-Net (Object-centric Scene Graph
Attention for Image Attribution Network); a robust image hashing model inspired
by recent successes of Transformers in the visual domain. OSCAR-Net constructs
a scene graph representation that attends to fine-grained changes of every
object's visual appearance and their spatial relationships. The network is
trained via contrastive learning on a dataset of original and manipulated
images yielding a state of the art image hash for content fingerprinting that
scales to millions of images.",http://arxiv.org/abs/2108.03541v2
"Fractional operators and multi-integral representations for associated
  Legendre functions",2021-08-09T20:32:47Z,Loyal Durand,"In a recent paper, Cohl and Costas-Santos derived a number of interesting
multi-derivative and multi-integral relations for associated Legendre and
Ferrers functions in which the orders of those functions are changed in
integral steps. These are of potential use in a number of physical problems. We
show here how their results can be derived simply from more general relations
involving non-integer changes in the order obtained using the fractional group
operator methods developed earlier for SO(2,1), E(2,1) and its conformal
extension, and SO(3). We also present general integral relations for fractional
changes of the degrees of the functions, and related multi-derivative and
multi-integral representations.",http://arxiv.org/abs/2108.04339v3
"Different molecular filament widths as tracers of accretion onto
  filaments",2021-08-12T15:41:40Z,"Gilberto C. Gómez, Catherine Walsh, Aina Palau","We explore how dense filament widths, when measured using different molecular
species, may change as a consequence of gas accretion toward the filament. As a
gas parcel falls into the filament, it will experience different density,
temperature, and extinction values. The rate at which this environment changes
will affect differently the abundance of different molecules. So, a molecule
that forms quickly will better reflect the local physical conditions a gas
parcel experiences than a slower-forming molecule. Since these differences
depend on how the respective timescales compare, the different molecular
distributions should reflect how rapidly the environment changes, i.e., the
accretion rate toward the filament. We find that the filament widths measured
from time-dependent abundances for C2H, CO, CN, CS, and C3H2, are sensitive the
most to this effect, being those molecules the ones presenting also the wider
filament widths. On the contrary, molecules such as N2H+, NH3, H2CO, HNC or
CH3OH are not so sensitive to accretion and present the narrowest filament
widths. We propose that ratios of filament widths for different tracers could
be a useful tool to estimate the accretion rate onto the filament.",http://arxiv.org/abs/2108.05808v2
Where Did the Web Archive Go?,2021-08-12T19:30:51Z,"Mohamed Aturban, Michael L. Nelson, Michele C. Weigle","To perform a longitudinal investigation of web archives and detecting
variations and changes replaying individual archived pages, or mementos, we
created a sample of 16,627 mementos from 17 public web archives. Over the
course of our 14-month study (November, 2017 - January, 2019), we found that
four web archives changed their base URIs and did not leave a machine-readable
method of locating their new base URIs, necessitating manual rediscovery. Of
the 1,981 mementos in our sample from these four web archives, 537 were
impacted: 517 mementos were rediscovered but with changes in their time of
archiving (or Memento-Datetime), HTTP status code, or the string comprising
their original URI (or URI-R), and 20 of the mementos could not be found at
all.",http://arxiv.org/abs/2108.05939v1
"In-depth Analysis of Durations of Discretionary Lane Changes on Freeway
  Under Varying Traffic Conditions",2021-08-15T01:37:32Z,"Gen Li, Zhen Yang, Yiyong Pan, Jianxiao Ma","This paper aims to investigate the characteristics of durations of
discretionary lane changes (LCs) on freeways based on an enriched dataset. A
comprehensive analysis of LC durations was conducted based on vehicle types, LC
directions and navigation speeds. It was found that the heavy vehicle takes
longer time to complete LC maneuver. The LC direction significantly influences
the durations of passenger cars but has no significant influence on heavy
vehicles. The navigation speed was found to have important influence on LC
durations. However, it has different impacts according to vehicle types and LC
directions. Further analysis of LC durations at different stages showed that
drivers of passenger cars might use different strategies to perform LCs when
they change lanes to different directions. However, drivers of heavy vehicles
in both directions used less time to occupy the target lanes. Results of this
study can be beneficial to understand the mechanism of LC process and the
influence of LC on traffic flow.",http://arxiv.org/abs/2108.06640v3
Detecting changes in covariance via random matrix theory,2021-08-16T20:39:48Z,"Sean Ryan, Rebecca Killick","A novel method is proposed for detecting changes in the covariance structure
of moderate dimensional time series. This non-linear test statistic has a
number of useful properties. Most importantly, it is independent of the
underlying structure of the covariance matrix. We discuss how results from
Random Matrix Theory, can be used to study the behaviour of our test statistic
in a moderate dimensional setting (i.e. the number of variables is comparable
to the length of the data). In particular, we demonstrate that the test
statistic converges point wise to a normal distribution under the null
hypothesis. We evaluate the performance of the proposed approach on a range of
simulated datasets and find that it outperforms a range of alternative recently
proposed methods. Finally, we use our approach to study changes in the amount
of water on the surface of a plot of soil which feeds into model development
for degradation of surface piping.",http://arxiv.org/abs/2108.07340v1
"Yielding transition of a two dimensional glass former under athermal
  cyclic shear deformation",2021-08-17T08:24:33Z,"Himangsu Bhaumik, Giuseppe Foffi, Srikanth Sastry","We study numerically the yielding transition of a two dimensional model glass
subjected to athermal quasi-static cyclic shear deformation, with the aim of
investigating the effect on the yielding behaviour of the degree of annealing,
which in turn depends on the preparation protocol. We find two distinct regimes
of annealing separated by a threshold energy. Poorly annealed glasses
progressively evolve towards the threshold energy as the strain amplitude is
increased towards the yielding value. Well annealed glasses with initial
energies below the threshold energy exhibit stable behaviour, with negligible
change in energy with increasing strain amplitude, till they yield.
Discontinuities in energy and stress at yielding increase with the degree of
annealing, consistently with recent results found in three dimensions. We
observe significant structural change with strain amplitude that closely
mirrors the changes in energy and stresses. We investigate groups of particles
that are involved in plastic rearrangements. We analyse the distributions of
avalanche sizes, of clusters of connected rearranging particles, and related
quantities, employing finite size scaling analysis. We verify previously
investigated relations between exponents characterising these distributions,
and a newly proposed relation between exponents describing avalanche and
cluster size distributions.",http://arxiv.org/abs/2108.07497v1
"A Framework for Understanding AI-Induced Field Change: How AI
  Technologies are Legitimized and Institutionalized",2021-08-18T14:06:08Z,Benjamin Cedric Larsen,"Artificial intelligence (AI) systems operate in increasingly diverse areas,
from healthcare to facial recognition, the stock market, autonomous vehicles,
and so on. While the underlying digital infrastructure of AI systems is
developing rapidly, each area of implementation is subject to different degrees
and processes of legitimization. By combining elements from institutional
theory and information systems-theory, this paper presents a conceptual
framework to analyze and understand AI-induced field-change. The introduction
of novel AI-agents into new or existing fields creates a dynamic in which
algorithms (re)shape organizations and institutions while existing
institutional infrastructures determine the scope and speed at which
organizational change is allowed to occur. Where institutional infrastructure
and governance arrangements, such as standards, rules, and regulations, still
are unelaborate, the field can move fast but is also more likely to be
contested. The institutional infrastructure surrounding AI-induced fields is
generally little elaborated, which could be an obstacle to the broader
institutionalization of AI-systems going forward.",http://arxiv.org/abs/2108.07804v1
"Influence of charged walls and defects on DC resistivity and dielectric
  relaxation in Cu-Cl boracite",2021-08-19T09:37:19Z,"C. Cochard, T. Granzow, C. M. Fernandez-Posada, M. A. Carpenter, R. G. P. McQuaid, J. M. Guy, R. W. Whatmore, J. M. Gregg","Charged domain walls form spontaneously in Cu-Cl boracite on cooling through
the phase transition. These walls exhibit changed conductivity compared to the
bulk and motion consistent with the existence of negative capacitance. Here, we
present the dielectric permittivity and DC resistivity of bulk Cu-Cl boracite
as a function of temperature (-140 {\deg}C to 150 {\deg}C) and frequency (1 mHz
to 10 MHz). The thermal behaviour of the two observed dielectric relaxations
and the DC resistivity is discussed. We propose that the relaxations can be
explained by the existence of point defects, most likely local complexes
created by a change of valence of Cu and accompanying oxygen vacancies. In
addition, the sudden change in resistivity seen at the phase transition
suggests that conductive domain walls contribute significantly to the
conductivity in the ferroelectric phase.",http://arxiv.org/abs/2108.08582v2
"Revealing magnetoelectric coupling effect in polar antiferromagnet
  Fe$_2$Mo$_3$O$_8$ by static and time resolved second harmonic generation",2021-08-23T15:55:43Z,"L. Y. Shi, D. Wu, T. Lin, S. J. Zhang, Q. M. Liu, Z. X. Wang, T. C. Hu, T. Dong, N. L. Wang","We present both static and time-resolved second harmonic generation (SHG)
measurements on polar antiferromagnet Fe$_2$Mo$_3$O$_8$ to monitor the
evolution of the electric polarization change and its coupling to magnetic
order. We find that only one of the second order tensor elements,
$\chi_{ccc}^{(2)}$ ,shows a prominent change below the Neel temperature $T_N =
60$ K, indicating a magnetic order induced electric polarization change along
the c-axis. Time-resolved SHG measurement reveals an ultrafast recovery of the
second order tensor element upon the ultrashort laser excitation with fluence
above 0.3 $mJ/cm^2$, yielding evidence for a photoinduced ultrafast phase
transition from the AFM ordered state to the paramagnetic state. Our work will
help understand the spin induced polarization and the ultrafast optical tuning
effect in Fe$_{2}$Mo$_{3}$O$_{8}$.",http://arxiv.org/abs/2108.10258v1
"Deformable hard particles particles confined in a disordered porous
  matrix",2021-08-23T21:01:12Z,"Alexander Stadik, Gerhard Kahl","With suitably designed Monte Carlo simulations we have investigated the
properties of mobile, impenetrable, yet deformable particles that are immersed
into a porous matrix, the latter one realized via a frozen configuration of
spherical particles. By virtue of a model put forward by Batista and Miller
[Phys. Rev. Lett. {\bf 105}, 088305 (2010)] the fluid particles can change
under the impact of their surrounding (i.e., either other fluid particles or
the matrix) their shape within the class of ellipsoids of revolution; such a
change in shape is related to an energy change which is fed into suitably
defined selection rules in the deformation ""moves"" of the Monte Carlo
simulations. This concept represents a simple, yet powerful model of realistic,
deformable molecules with complex internal structures (such as dendrimers or
polymers). For the evaluation of the properties of the system we have used the
well-known quenched-annealed protocol (with its characteristic double average
prescription) and have analysed the simulation data in terms of static
properties (radial distribution function and aspect ratio distribution of the
ellipsoids) and dynamic features (notably the mean squared displacement). Our
data provide evidence that the degree of deformability of the fluid particles
has a distinct impact on the aforementioned properties of the system.",http://arxiv.org/abs/2108.10410v1
Lagrangian cobordism functor in microlocal sheaf theory I,2021-08-24T18:48:29Z,Wenyuan Li,"Given a Lagrangian cobordism $L$ of Legendrian submanifolds from $\Lambda_-$
to $\Lambda_+$, we construct a functor $\Phi_L^*: Sh^c_{\Lambda_+}(M)
\rightarrow Sh^c_{\Lambda_-}(M) \otimes_{C_{-*}(\Omega_*\Lambda_-)}
C_{-*}(\Omega_*L)$ between sheaf categories of compact objects with singular
support on $\Lambda_\pm$ and its right adjoint on sheaf categories of proper
objects, using Nadler-Shende's work. This gives a sheaf theory description
analogous to the Lagrangian cobordism map on Legendrian contact homologies and
the right adjoint on their unital augmentation categories. We also deduce some
long exact sequences and new obstructions to Lagrangian cobordisms between high
dimensional Legendrian submanifolds.",http://arxiv.org/abs/2108.10914v3
"A Bayesian Surveillance Model to Track Variable Rainfall-Runoff
  Responses for Small Watersheds",2021-08-25T20:53:22Z,"Xiao Peng, John D. Albertson","Understanding dynamics of hydrological responses is essential in producing
skillful runoff forecast. This can be quantitatively done by tracking changes
in hydrology model parameters that represent physical characteristics. In this
study, we implement a Bayesian estimation method in continuously estimating
hydrology model parameters given observations of rainfall and runoff for small
watersheds. The method is coupled with a conceptual hydrology model using a
Gamma distribution-based Instantaneous Unit Hydrograph. The whole analytical
framework is tested using synthetic data as well as observational data from the
Fall Creek watershed. The results show that the Bayesian method can well track
the hidden parameters that change inter-annually. Then the model is applied to
examine temporal and spatial variability of the rainfall-runoff responses and
we find 1) a systematic shift in the rainfall-runoff response for the Fall
Creek watershed around 1943 and 2) a statistically significant relationship
between rainfall-runoff responses and watershed sizes for selected NY
watersheds. Our results demonstrate potential of the Bayesian estimation method
as a rapid surveillance tool in monitoring and tracking changes of hydrological
responses for small watersheds.",http://arxiv.org/abs/2108.11470v2
"Changes in Twitter geolocations: Insights and suggestions for future
  usage",2021-08-27T13:10:16Z,"Anna Kruspe, Matthias Häberle, Eike J. Hoffmann, Samyo Rode-Hasinger, Karam Abdulahhad, Xiao Xiang Zhu","Twitter data has become established as a valuable source of data for various
application scenarios in the past years. For many such applications, it is
necessary to know where Twitter posts (tweets) were sent from or what location
they refer to. Researchers have frequently used exact coordinates provided in a
small percentage of tweets, but Twitter removed the option to share these
coordinates in mid-2019. Moreover, there is reason to suspect that a large
share of the provided coordinates did not correspond to GPS coordinates of the
user even before that. In this paper, we explain the situation and the 2019
policy change and shed light on the various options of still obtaining location
information from tweets. We provide usage statistics including changes over
time, and analyze what the removal of exact coordinates means for various
common research tasks performed with Twitter data. Finally, we make suggestions
for future research requiring geolocated tweets.",http://arxiv.org/abs/2108.12251v3
Revising Ontologies via Models: The ALC-formula Case,2021-08-27T15:04:45Z,"Jandson S. Ribeiro, Ricardo Guimarães, Ana Ozaki","Most approaches for repairing description logic (DL) ontologies aim at
changing the axioms as little as possible while solving inconsistencies,
incoherences and other types of undesired behaviours. As in Belief Change,
these issues are often specified using logical formulae. Instead, in the new
setting for updating DL ontologies that we propose here, the input for the
change is given by a model which we want to add or remove. The main goal is to
minimise the loss of information, without concerning with the syntactic
structure. This new setting is motivated by scenarios where an ontology is
built automatically and needs to be refined or updated. In such situations, the
syntactical form is often irrelevant and the incoming information is not
necessarily given as a formula. We define general operations and conditions on
which they are applicable, and instantiate our approach to the case of
ALC-formulae.",http://arxiv.org/abs/2108.12331v2
"Inequality in Education: A Comparison of Australian Indigenous and
  Nonindigenous Populations",2021-08-29T11:56:12Z,"David Gunawan, William Griffiths, Duangkamon Chotikapanich","Educational achievement distributions for Australian indigenous and
nonindigenous populations in the years 2001, 2006, 2014 and 2017 are
considered. Bayesian inference is used to analyse how these ordinal categorical
distributions have changed over time and to compare indigenous and
nonindigenous distributions. Both the level of educational achievement and
inequality in educational achievement are considered. To compare changes in
levels over time, as well as inequality between the two populations, first
order stochastic dominance and an index of educational poverty are used. To
examine changes in inequality over time, two inequality indices and generalised
Lorenz dominance are considered. Results are presented in terms of posterior
densities for the indices and posterior probabilities for dominance for the
dominance comparisons. We find some evidence of improvement over time,
especially in the lower parts of the indigenous distribution and that
inequality has significantly increased from 2001 to 2017.",http://arxiv.org/abs/2108.12830v1
"Valley-dependent transport in strain engineering graphene
  heterojunctions",2021-10-01T13:07:33Z,"Fei Wan, Xinru Wang, Liehong Liao, Jiayan Zhang, M. N. Chen, G. H. Zhou, Z. B. Siu, Mansoor B. A. Jalil, Yuan Li","We study the effect of the strain on the band structure and the
valley-dependent transport property of graphene heterojunctions. It is found
that valley-dependent separation of electrons can be achieved by utilizing the
strain and on-site energies. In the presence of the strain, the values of the
transmission can be effectively adjusted by changing the strengths of the
strain, while the transport angle basically keeps unchanged. When an extra
on-site energy is simultaneously applied to the central scattering region, not
only are the electrons of valleys K and K' separated into two distinct
transmission lobes in opposite transverse directions, but the transport angles
of two valleys can be significantly changed. Therefore, one can realize an
effective modulation of valley-dependent transport by changing the strength and
stretch angle of the strain and on-site energies, which can be exploited for
graphene-based valleytronics devices.",http://arxiv.org/abs/2110.00374v1
"Temporal Graphs and Temporal Network Characteristics for Bio-Inspired
  Networks During Optimization",2021-10-01T16:16:11Z,"N. DiBrita, K. Eledlebi, H. Hildmann, L. Culley, A. F. Isakovic","Temporal network analysis and time evolution of network characteristics are
powerful tools in describing the changing topology of dynamic networks. This
paper uses such approaches to better visualize and provide analytical measures
for the changes in performance that we observed in Voronoi-type spatial
coverage, particularly for the example of time evolving networks with a
changing number of wireless sensors being deployed. Specifically, our analysis
focuses on the role different combinations of impenetrable obstacles and
environmental noise play in connectivity and overall network structure. It is
shown how the use of (i) temporal network graphs, and (ii) network centrality
and regularity measures illustrate the differences between various options
developed for the balancing act of energy and time efficiency in network
coverage. Lastly, we compare the outcome of these measures with the less
abstract classification variables, such as percent area covered, and cumulative
distance travelled.",http://arxiv.org/abs/2110.00506v1
Calibrated Adversarial Training,2021-10-01T19:17:28Z,"Tianjin Huang, Vlado Menkovski, Yulong Pei, Mykola Pechenizkiy","Adversarial training is an approach of increasing the robustness of models to
adversarial attacks by including adversarial examples in the training set. One
major challenge of producing adversarial examples is to contain sufficient
perturbation in the example to flip the model's output while not making severe
changes in the example's semantical content. Exuberant change in the semantical
content could also change the true label of the example. Adding such examples
to the training set results in adverse effects. In this paper, we present the
Calibrated Adversarial Training, a method that reduces the adverse effects of
semantic perturbations in adversarial training. The method produces pixel-level
adaptations to the perturbations based on novel calibrated robust error. We
provide theoretical analysis on the calibrated robust error and derive an upper
bound for it. Our empirical results show a superior performance of the
Calibrated Adversarial Training over a number of public datasets.",http://arxiv.org/abs/2110.00623v2
"Dynamic instability of individual carbon nanotube growth revealed by in
  situ homodyne polarization microscopy",2021-10-04T07:43:38Z,"Vladimir Pimonov, Huy-Nam Tran, Léonard Monniello, Saïd Tahir, Thierry Michel, Renaud Podor, Michaël Odorico, Christophe Bichara, Vincent Jourdain","Understanding the kinetic selectivity of carbon nanotube growth at the scale
of individual nanotubes is essential for the development of high chiral
selectivity growth methods. Here we demonstrate that homodyne polarization
microscopy can be used for high-throughput imaging of long individual carbon
nanotubes under real growth conditions (at ambient pressure, on a substrate),
and with sub-second time resolution. Our in situ observations on hundreds of
individual nanotubes reveal that about half of them grow at a constant rate all
along their lifetime while the other half exhibits stochastic changes in growth
rates, and switches between growth, pause and shrinkage. Statistical analysis
shows that the growth rate of a given nanotube essentially varies between two
values, with similar average ratio (~1.7) regardless of whether the rate change
is accompanied by a change in chirality. These switches indicate that the
nanotube edge or the catalyst nanoparticle fluctuates between different
configurations during growth.",http://arxiv.org/abs/2110.01226v1
"Thin liquid film as an optical nonlinear-nonlocal medium and memory
  element in integrated optofluidic reservoir computer",2021-10-06T20:55:21Z,"Chengkuan Gao, Prabhav Gaur, Shimon Rubin, Yeshaiahu Fainman","Understanding light-matter interaction enables harnessing physical effects to
translate into new capabilities realized in modern integrated photonics
platforms. Here, we present the design and characterization of optofluidic
components in integrated photonics platform, and numerically predict a series
of novel physical effects which rely on thermocapillary-driven interaction
between waveguide modes to topography changes of optically thin liquid
dielectric film. Our results indicate that this coupling introduces substantial
self-induced phase change in a single channel waveguide, transmittance through
Bragg grating waveguide and nonlocal interaction between adjacent waveguides.
We then employ the self-induced phase change together with the inherent
built-in finite relaxation time of the liquid film, to demonstrate that its
light-driven deformation can serve as a reservoir computer capable to perform
digital and analog tasks, where the gas-liquid interface operates both as a
nonlinear actuator and as an optical memory element.",http://arxiv.org/abs/2110.03066v2
IaaS Signature Change Detection with Performance Noise,2021-10-07T07:27:39Z,"Sheik Mohammad Mostakim Fattah, Athman Bouguettaya","We propose a novel framework to detect changes in the performance behavior of
an IaaS service. The proposed framework leverages the concept of the IaaS
signature to represent an IaaS service's long-term performance behavior. A new
type of performance signature called categorical IaaS signature is introduced
to represent the performance behavior more accurately. A novel performance
noise model is proposed to accurately identify IaaS performance noise and
accurate changes in the performance behavior of an IaaS service. A set of
experiments based on real-world datasets is carried out to evaluate the
effectiveness of the proposed framework.",http://arxiv.org/abs/2110.03229v1
Twist-diameter coupling drives DNA twist changes by salt and temperature,2021-10-07T14:31:06Z,"Chen Zhang, Fujia Tian, Ying Lu, Bing Yuan, Zhi-Jie Tan, Xing-Hua Zhang, Liang Dai","DNA deformations play crucial roles in many biological processes and material
applications. During DNA deformation, DNA structural parameters often exhibit
non-trivial and counterintuitive couplings, such as the twist-stretch and
twist-bending couplings. Here, we reveal an unexpectedly strong negative
twist-diameter coupling through the synergy of magnetic-tweezers experiments,
atomistic molecular dynamics simulations, and theoretical calculations. In
experiments, the DNA twist angle always increases with the concentration of
NaCl, KCl, or RbCl. Our simulations quantitatively reproduce salt-induced twist
changes and reveal the underlying physical mechanism: the reduction of DNA
diameter under a high salt concentration leads to the increase in DNA twist
angle through a strong negative twist-diameter coupling. The twist-diameter
coupling is mediated by two dihedral angles in DNA structure and the coupling
constant is 4.5 kBT/(deg nm) for one base-pair. Based on this coupling
constant, we predict the temperature-dependence of DNA twist -0.0102 deg/K per
bp, which agrees with our and previous experimental results. Our analysis
suggests that the twist-diameter coupling is a common driving force for salt-
and temperature-induced DNA twist changes.",http://arxiv.org/abs/2110.03495v1
"On behavior of conductors, Picard schemes, and Jacobian numbers of
  varieties over imperfect fields",2021-10-08T06:22:32Z,"Ippei Nagamachi, Teppei Takamatsu","Let $X$ be a regular geometrically integral variety over an imperfect field
$K$. Unlike the case of characteristic $0$,
$X':=X\times_{\mathrm{Spec}\,K}\mathrm{Spec}\,K'$ may have singular points for
a (necessarily inseparable) field extension $K'/K$. In this paper, we define
new invariants of the local rings of codimension $1$ points of $X'$, and use
these invariants for the calculation of $\delta$-invariants (, which relate to
genus changes,) and conductors of such points. As a corollary, we give
refinements of Tate's genus change theorem and the Patakfalvi-Waldron Theorem.
Moreover, when $X$ is a curve, we show that the Jacobian number of $X$ is
$2p/(p-1)$ times of the genus change by using the above calculation. In this
case, we also relate the structure of the Picard scheme of $X$ with invariants
of singular points of $X$. To prove such a relation, we give a characterization
of the geometrical normality of algebras over fields of positive
characteristic.",http://arxiv.org/abs/2110.03917v3
"Affective Burst Detection from Speech using Kernel-fusion Dilated
  Convolutional Neural Networks",2021-10-08T12:40:43Z,"Berkay Kopru, Engin Erzin","As speech-interfaces are getting richer and widespread, speech emotion
recognition promises more attractive applications. In the continuous emotion
recognition (CER) problem, tracking changes across affective states is an
important and desired capability. Although CER studies widely use correlation
metrics in evaluations, these metrics do not always capture all the
high-intensity changes in the affective domain. In this paper, we define a
novel affective burst detection problem to accurately capture high-intensity
changes of the affective attributes. For this problem, we formulate a two-class
classification approach to isolate affective burst regions over the affective
state contour. The proposed classifier is a kernel-fusion dilated convolutional
neural network (KFDCNN) architecture driven by speech spectral features to
segment the affective attribute contour into idle and burst sections.
Experimental evaluations are performed on the RECOLA and CreativeIT datasets.
The proposed KFDCNN is observed to outperform baseline feedforward neural
networks on both datasets.",http://arxiv.org/abs/2110.04091v1
Active learning for interactive satellite image change detection,2021-10-08T16:59:12Z,"Hichem Sahbi, Sebastien Deschamps, Andrei Stoian","We introduce in this paper a novel active learning algorithm for satellite
image change detection. The proposed solution is interactive and based on a
question and answer model, which asks an oracle (annotator) the most
informative questions about the relevance of sampled satellite image pairs, and
according to the oracle's responses, updates a decision function iteratively.
We investigate a novel framework which models the probability that samples are
relevant; this probability is obtained by minimizing an objective function
capturing representativity, diversity and ambiguity. Only data with a high
probability according to these criteria are selected and displayed to the
oracle for further annotation. Extensive experiments on the task of satellite
image change detection after natural hazards (namely tornadoes) show the
relevance of the proposed method against the related work.",http://arxiv.org/abs/2110.04250v1
Model-Change Active Learning in Graph-Based Semi-Supervised Learning,2021-10-14T21:47:10Z,"Kevin Miller, Andrea L. Bertozzi","Active learning in semi-supervised classification involves introducing
additional labels for unlabelled data to improve the accuracy of the underlying
classifier. A challenge is to identify which points to label to best improve
performance while limiting the number of new labels. ""Model Change"" active
learning quantifies the resulting change incurred in the classifier by
introducing the additional label(s). We pair this idea with graph-based
semi-supervised learning methods, that use the spectrum of the graph Laplacian
matrix, which can be truncated to avoid prohibitively large computational and
storage costs. We consider a family of convex loss functions for which the
acquisition function can be efficiently approximated using the Laplace
approximation of the posterior distribution. We show a variety of multiclass
examples that illustrate improved performance over prior state-of-art.",http://arxiv.org/abs/2110.07739v2
Controllable Semantic Parsing via Retrieval Augmentation,2021-10-16T03:34:49Z,"Panupong Pasupat, Yuan Zhang, Kelvin Guu","In practical applications of semantic parsing, we often want to rapidly
change the behavior of the parser, such as enabling it to handle queries in a
new domain, or changing its predictions on certain targeted queries. While we
can introduce new training examples exhibiting the target behavior, a mechanism
for enacting such behavior changes without expensive model re-training would be
preferable. To this end, we propose ControllAble Semantic Parser via Exemplar
Retrieval (CASPER). Given an input query, the parser retrieves related
exemplars from a retrieval index, augments them to the query, and then applies
a generative seq2seq model to produce an output parse. The exemplars act as a
control mechanism over the generic generative model: by manipulating the
retrieval index or how the augmented query is constructed, we can manipulate
the behavior of the parser. On the MTOP dataset, in addition to achieving
state-of-the-art on the standard setup, we show that CASPER can parse queries
in a new domain, adapt the prediction toward the specified patterns, or adapt
to new semantic schemas without having to further re-train the model.",http://arxiv.org/abs/2110.08458v2
Valley polarization transition in a two-dimensional electron gas,2021-10-18T18:00:00Z,"Seongjin Ahn, Sankar Das Sarma","We theoretically study transport signatures associated with a spontaneous
2-valley to 1-valley quantum phase transition in a two-dimensional electron gas
(2DEG) tuned by decreasing the 2D carrier density, as claimed in a recent
experiment [Phys. Rev. Lett. 127, 116601 (2021)]. The key issue we focus on is
whether the experimentally measured 2D resistivity as a function of carrier
density is consistent (or not) with an underlying spontaneous
valley-polarization transition as assumed uncritically in the experimental
report. Our theoretical analysis is particularly germane since the experiment
does not directly measure the change in the Fermi surface resulting from the
valley polarization transition, but infers such a transition indirectly through
transport measurements. We validate the experimental claim, showing that indeed
the observed sudden change in the 2D resistivity is quantitatively consistent
with a sudden change in the valley polarization from 2 to 1 at the critical
density.",http://arxiv.org/abs/2110.09528v1
The Origin of Radio Emission in Black Hole X-ray Binaries,2021-10-22T06:09:09Z,"Xiang Liu, Ning Chang, Xin Wang, Qi Yuan","We studied the relation of accretion-jet power and disk luminosity,
especially the jet efficiencies and disk radiative efficiencies for different
accretion disks as well as black hole (BH) spin, in order to explore the origin
of radio emission in black hole X-ray binaries (BHXBs). We found that jet
efficiency increases more rapidly (efficient) than the nearly constant disk
radiative efficiency for thin disk component in high accretion regime, which
could account for the steep track ($\mu>1$) in the observed radio and X-ray
luminosity relations ($L_{\rm R}\propto L_{\rm X}^{\mu}$), but the thin disk
component may not be able to explain the standard track ($\mu\approx 0.6$) in
the BHXBs. For hot accretion flows (HAF), the resulting jet efficiency changes
along with the large range of accretions from quiescent state to nearly
Eddington state, which could account for the standard track in the BHXBs. The
BH spin-jet is discussed for the magnetic arrested disk (MAD) state; in this
state, the spin-jet power might contribute to a linear correlation between jet
power and mass accretion rate for a given source. More accurate observations
are required to test the results.",http://arxiv.org/abs/2110.11607v1
"On Synchronization of Wireless Acoustic Sensor Networks in the Presence
  of Time-varying Sampling Rate Offsets and Speaker Changes",2021-10-25T11:38:03Z,"Tobias Gburrek, Joerg Schmalenstroeer, Reinhold Haeb-Umbach","A wireless acoustic sensor network records audio signals with sampling time
and sampling rate offsets between the audio streams, if the analog-digital
converters (ADCs) of the network devices are not synchronized. Here, we
introduce a new sampling rate offset model to simulate time-varying sampling
frequencies caused, for example, by temperature changes of ADC crystal
oscillators, and propose an estimation algorithm to handle this dynamic aspect
in combination with changing acoustic source positions. Furthermore, we show
how deep neural network based estimates of the distances between microphones
and human speakers can be used to determine the sampling time offsets. This
enables a synchronization of the audio streams to reflect the physical time
differences of flight.",http://arxiv.org/abs/2110.12820v1
Transportation Scenario Planning with Graph Neural Networks,2021-10-25T18:28:14Z,"Ana Alice Peregrino, Soham Pradhan, Zhicheng Liu, Nivan Ferreira, Fabio Miranda","Providing efficient human mobility services and infrastructure is one of the
major concerns of most mid-sized to large cities around the world. A proper
understanding of the dynamics of commuting flows is, therefore, a requisite to
better plan urban areas. In this context, an important task is to study
hypothetical scenarios in which possible future changes are evaluated. For
instance, how the increase in residential units or transportation modes in a
neighborhood will change the commuting flows to or from that region? In this
paper, we propose to leverage GMEL, a recently introduced graph neural network
model, to evaluate changes in commuting flows taking into account different
land use and infrastructure scenarios. We validate the usefulness of our
methodology through real-world case studies set in two large cities in Brazil.",http://arxiv.org/abs/2110.13202v1
Learning Domain Invariant Representations in Goal-conditioned Block MDPs,2021-10-27T08:10:45Z,"Beining Han, Chongyi Zheng, Harris Chan, Keiran Paster, Michael R. Zhang, Jimmy Ba","Deep Reinforcement Learning (RL) is successful in solving many complex Markov
Decision Processes (MDPs) problems. However, agents often face unanticipated
environmental changes after deployment in the real world. These changes are
often spurious and unrelated to the underlying problem, such as background
shifts for visual input agents. Unfortunately, deep RL policies are usually
sensitive to these changes and fail to act robustly against them. This
resembles the problem of domain generalization in supervised learning. In this
work, we study this problem for goal-conditioned RL agents. We propose a
theoretical framework in the Block MDP setting that characterizes the
generalizability of goal-conditioned policies to new environments. Under this
framework, we develop a practical method PA-SkewFit that enhances domain
generalization. The empirical evaluation shows that our goal-conditioned RL
agent can perform well in various unseen test environments, improving by 50%
over baselines.",http://arxiv.org/abs/2110.14248v2
Sequential Detection of a Temporary Change in Multivariate Time Series,2021-10-29T17:31:16Z,"V. Watson, F. Septier, P. Armand, C. Duchenne","In this work, we aim to provide a new and efficient recursive detection
method for temporarily monitored signals. Motivated by the case of the
propagation of an event over a field of sensors, we assumed that the change in
the statistical properties in the monitored signals can only be temporary.
Unfortunately, to our best knowledge, existing recursive and simple detection
techniques such as the ones based on the cumulative sum (CUSUM) do not consider
the temporary aspect of the change in a multivariate time series. In this
paper, we propose a novel simple and efficient sequential detection algorithm,
named Temporary-Event-CUSUM (TE-CUSUM). By combining with a new adaptive way to
aggregate local CUSUM variables from each data stream, we empirically show that
the TE-CUSUM has a very good detection rate in the case of an event passing
through a field of sensors in a very noisy environment.",http://arxiv.org/abs/2110.15935v2
Time dependent signatures of core-collapse supernova neutrinos at HALO,2021-01-05T21:41:40Z,"B. Ekinci, Y. Pehlivan, Amol V. Patwardhan","We calculate the response of a lead-based detector, such as the Helium and
Lead Observatory (HALO) or its planned upgrade HALO-1kt to a galactic
core-collapse supernova. We pay particular attention to the time dependence of
the reaction rates. All reaction rates decrease as the neutrino luminosity
exponentially drops during the cooling period but the ratio of one-neutron (1n)
to two-neutron (2n) event rates in HALO is independent of this overall
decrease. Nevertheless, we find that this ratio still changes with time due to
the changing character of neutrino flavor transformations with the evolving
conditions in the supernova. In the case of inverted hierarchy, this is caused
by the fact that the spectral splits become less and less sharp with the
decreasing luminosity. In the case of normal hierarchy, it is caused by the
passage of the shock wave through the Mikheyev-Smirnov-Wolfenstein resonance
region. However, in both cases, we find that the change in the ratio of 1n to
2n event rates is limited to a few percent.",http://arxiv.org/abs/2101.01797v2
"Independent Action Models and Prediction of Combination Treatment
  Effects for Response Rate, Duration of Response and Tumor Size Change in
  Oncology Drug Development",2021-01-06T21:47:02Z,"Linda Z. Sun, Cai, Wu, Xiaoyun, Li, Cong Chen, Emmett V. Schmidt","An unprecedented number of new cancer targets are in development, and most
are being developed in combination therapies. Early oncology development is
strategically challenged in choosing the best combinations to move forward to
late stage development. The most common early endpoints to be assessed in such
decision-making include objective response rate, duration of response and tumor
size change. In this paper, using independent-drug-action and
Bliss-drug-independence concepts as a foundation, we introduce simple models to
predict combination therapy efficacy for duration of response and tumor size
change. These models complement previous publications using the independent
action models (Palmer 2017, Schmidt 2020) to predict progression-free survival
and objective response rate and serve as new predictive models to understand
drug combinations for early endpoints. The models can be applied to predict the
combination treatment effect for early endpoints given monotherapy data, or to
estimate the possible effect of one monotherapy in the combination if data are
available from the combination therapy and the other monotherapy. Such
quantitative work facilitates efficient oncology drug development.",http://arxiv.org/abs/2101.02280v1
"Magnetism and electrical transport in Y-doped layered iridate
  Sr$_2$IrO$_4$",2021-01-07T18:58:57Z,"Imtiaz Noor Bhatti, A. K. Pramanik","Here, we report an investigation of structural, magnetic and electronic
properties in Y-doped layered iridate (Sr$_{1-x}$Y$_x$)$_2$IrO$_4$ ($x$ $\leq$
0.1). The parent Sr$_2$IrO$_4$ is a well-studied spin-orbit coupling (SOC)
induced insulator with an antiferromagnetic ground state. The Y-doping here
equivalently acts for electron doping without altering the vital parameters
such as, SOC and electron correlation. Experimental results show a minute
change in structural parameters and an equivalent charge conversion from
Ir$^{4+}$ to Ir$^{3+}$. Unlike similarly other electron-doped system, the low
temperature magnetic and electronic state in present series is minimally
influenced. The charge conduction mechanism follows 2-dimensional hopping model
in whole series. Magnetoresistance (MR) data show an interesting sign change
with both temperature and magnetic field. The positive MR both at low
temperature follows weak antilocalization behavior where the sign change in MR
is believed to be caused by an interplay between SOC and magnetic moment.",http://arxiv.org/abs/2101.02699v1
Phase Change Logic via Thermal Cross-Talk for Computation in Memory,2021-01-08T14:21:38Z,"Nadim Kanan, Raihan Sayeed Khan, Zachary Woods, Helena Silva, Ali Gokirmak","We have computationally demonstrated logic function implementations using
lateral and vertical multi-contact phase change devices integrated with CMOS
circuitry, which use thermal cross-talk as a coupling mechanism to implement
logic functions at smaller CMOS footprints. Thermal-crosstalk during the write
operations is utilized to recrystallize the previously amorphized regions to
achieve toggle operations. Amorphized regions formed between different pairs of
write contacts are utilized to isolate read contacts. Typical expected
reduction in CMOS footprint is ~ 50% using the described approach for
toggle-multiplexing, JK-multiplexing and 2x2 routing. The switching speeds of
the phase change devices are in the order of nanoseconds and are inherently
non-volatile. An electro-thermal modeling framework with dynamic materials
models are used to capture the device dynamics, and current and voltage
requirements.",http://arxiv.org/abs/2101.03031v1
"Elastomeric Nematic Colloids, Colloidal Crystals and Microstructures
  with Complex Topology",2021-01-10T16:48:27Z,"Ye Yuan, Patrick Keller, Ivan I. Smalyukh","Control of physical behaviors of nematic colloids and colloidal crystals has
been demonstrated by tuning particle shape, topology, chirality and surface
charging. However, the capability of altering physical behaviors of such soft
matter systems by changing particle shape and the ensuing responses to external
stimuli has remained elusive. We fabricated genus-one nematic elastomeric
colloidal ring-shaped particles and various microstructures using two-photon
photopolymerization. Nematic ordering within both the nano-printed particle and
the surrounding medium leads to anisotropic responses and actuation when
heated. With the thermal control, elastomeric microstructures are capable of
changing from genus-one to genus-zero surface topology. Using these particles
as building blocks, we investigated elastomeric colloidal crystals immersed
within a liquid crystal fluid, which exhibit crystallographic symmetry
transformations. Our findings may lead to colloidal crystals responsive to a
large variety of external stimuli, including electric fields and light.
Pre-designed response of elastomeric nematic colloids, including changes of
colloidal surface topology and lattice symmetry, are of interest for both
fundamental research and applications.",http://arxiv.org/abs/2101.03578v1
"Temperature dependent appearance of exotic matter makes nascent neutron
  stars spin faster",2021-01-12T22:33:30Z,"Francisco Hernandez-Vivanco, Paul D. Lasky, Eric Thrane, Rory Smith, Debarati Chatterjee, Sarmistha Banik, Theo Motta, Anthony Thomas","Neutron stars offer the opportunity to study the behaviour of matter at
densities and temperatures inaccessible to terrestrial experiments.
Gravitational-wave observations of binary neutron star coalescences can
constrain the neutron-star equation of state before and after merger. After the
neutron star binary merges, hyperons can form in the remnant, changing the
behaviour of the neutron-star equation of state. In this study, we use
finite-entropy equations of state to show that a post-merger remnant can spin
up due to cooling. The magnitude of the spin-up depends on the neutron-star
equation of state. If hyperons are present, the post-merger spin-up changes the
peak gravitational-wave frequency by $\sim 540$ Hz, when the entropy per baryon
drops from $s=2$ $k_B$ to $s=0$ $k_B$. If hyperons are not present, the
post-merger spin-up changes by $\sim 360$ Hz, providing a gravitational-wave
signature for exotic matter. We expect the same qualitative behaviour whenever
temperature dependent phase transitions are triggered.",http://arxiv.org/abs/2101.04782v1
Nowcasting Gentrification Using Airbnb Data,2021-01-15T01:08:47Z,"Shomik Jain, Davide Proserpio, Giovanni Quattrone, Daniele Quercia","There is a rumbling debate over the impact of gentrification: presumed
gentrifiers have been the target of protests and attacks in some cities, while
they have been welcome as generators of new jobs and taxes in others. Census
data fails to measure neighborhood change in real-time since it is usually
updated every ten years. This work shows that Airbnb data can be used to
quantify and track neighborhood changes. Specifically, we consider both
structured data (e.g. number of listings, number of reviews, listing
information) and unstructured data (e.g. user-generated reviews processed with
natural language processing and machine learning algorithms) for three major
cities, New York City (US), Los Angeles (US), and Greater London (UK). We find
that Airbnb data (especially its unstructured part) appears to nowcast
neighborhood gentrification, measured as changes in housing affordability and
demographics. Overall, our results suggest that user-generated data from online
platforms can be used to create socioeconomic indices to complement traditional
measures that are less granular, not in real-time, and more costly to obtain.",http://arxiv.org/abs/2101.05924v2
"Work Online, Welfare Calls, and Wine Night: Effects of the COVID-19
  Pandemic on Individuals' Technology Use",2021-01-19T00:43:00Z,"Bill Tomlinson, Rebecca W. Black","The COVID-19 pandemic has changed the ways many people use computational
systems. We conducted an empirical study, using qualitative and quantitative
analyses of free-response surveys completed by 62 US residents, to explore how
COVID-19 affected their computer use across work, education, home life, and
social life. Nearly all participants experienced an increase in computer usage
for themselves or a family member in one or more of the four domains. The
increases involved both increasing frequency of existing uses as well as the
adoption of new types of use. Changes in usage impacted many aspects of
people's lives, including relationships, affective experiences, and life
trajectories. Understanding these changes is important to the future of HCI, as
the field adapts to COVID-19 and potential future pandemics.",http://arxiv.org/abs/2101.07388v1
Dynamical preparation of stripe states in spin-orbit coupled gases,2021-01-20T18:54:53Z,"Josep Cabedo, Joan Claramunt, Alessio Celi","In spinor Bose-Einstein condensates, spin-changing collisions are a
remarkable proxy to coherently realize macroscopic many-body quantum states.
These processes have been, e.g., exploited to generate entanglement, to study
dynamical quantum phase transitions, and proposed for realizing nematic phases
in atomic condensates. In the same systems dressed by Raman beams, the coupling
between spin and momentum induces a spin dependence in the scattering processes
taking place in the gas. Here we show that, at weak couplings, such modulation
of the collisions leads to an effective Hamiltonian which is equivalent to the
one of an artificial spinor gas with spin-changing collisions that are tunable
with the Raman intensity. By exploiting this dressed-basis description, we
propose a robust protocol to coherently drive the spin-orbit coupled condensate
into the ferromagnetic stripe phase via crossing a quantum phase transition of
the effective low-energy model in an excited-state.",http://arxiv.org/abs/2101.08253v3
"Experimental demonstration of memory-enhanced scaling for entanglement
  connection of quantum repeater segments",2021-01-21T10:43:47Z,"Yunfei Pu, Sheng Zhang, Yukai Wu, Nan Jiang, Wei Chang, Chang Li, Luming Duan","The quantum repeater protocol is a promising approach to implement
long-distance quantum communication and large-scale quantum networks. A key
idea of the quantum repeater protocol is to use long-lived quantum memories to
achieve efficient entanglement connection between different repeater segments
with a polynomial scaling. Here we report an experiment which realizes
efficient connection of two quantum repeater segments via on-demand
entanglement swapping by the use of two atomic quantum memories with storage
time of tens of milliseconds. With the memory enhancement, scaling-changing
acceleration is demonstrated in the rate for a successful entanglement
connection. The experimental realization of entanglement connection of two
quantum repeater segments with an efficient memory-enhanced scaling
demonstrates a key advantage of the quantum repeater protocol, which makes a
cornerstone towards future large-scale quantum networks.",http://arxiv.org/abs/2101.08541v3
"Improving Reproducibility of Sputter Deposited Ferroelectric Wurtzite
  Al0.6Sc0.4N Films using In-situ Optical Emission Spectrometry",2021-01-21T18:12:24Z,"Daniel Drury, Keisuke Yazawa, Allison Mis, Kevin Talley, Andriy Zakutayev, Geoff L. Brennecka","High-Sc Al1-xScxN thin films are of tremendous interest because of their
attractive piezoelectric and ferroelectric properties, but overall film quality
and reproducibility are widely reported to suffer as x increases. In this
study, we correlate the structure and electrical properties of Al0.6Sc0.4N with
in-situ observations of glow discharge optical emission during growth. This
in-situ technique uses changes in the Ar(I) and N2(I) emission lines of the
glow discharge during growth to identify films that subsequently exhibit
unacceptable structural and electrical performance. We show that a steady
deposition throughout film growth produces ferroelectric Al0.6Sc0.4N with a
reversible 80 {\mu}C cm-1 polarization and 3.1 MV cm-1 coercive field. In other
films deposited using identical settings, fluctuations in both Ar(I) and N2(I)
line intensities correspond to decreased wurtzite phase purity, nm-scale
changes to the film microstructure, and a non-ferroelectric response. These
results illustrate the power of optical emission spectroscopy for tracking
changes when fabricating process-sensitive samples such as high-Sc Al1-xScxN
films.",http://arxiv.org/abs/2101.08755v1
"Human Interaction Recognition Framework based on Interacting Body Part
  Attention",2021-01-22T06:52:42Z,"Dong-Gyu Lee, Seong-Whan Lee","Human activity recognition in videos has been widely studied and has recently
gained significant advances with deep learning approaches; however, it remains
a challenging task. In this paper, we propose a novel framework that
simultaneously considers both implicit and explicit representations of human
interactions by fusing information of local image where the interaction
actively occurred, primitive motion with the posture of individual subject's
body parts, and the co-occurrence of overall appearance change. Human
interactions change, depending on how the body parts of each human interact
with the other. The proposed method captures the subtle difference between
different interactions using interacting body part attention. Semantically
important body parts that interact with other objects are given more weight
during feature representation. The combined feature of interacting body part
attention-based individual representation and the co-occurrence descriptor of
the full-body appearance change is fed into long short-term memory to model the
temporal dynamics over time in a single framework. We validate the
effectiveness of the proposed method using four widely used public datasets by
outperforming the competing state-of-the-art method.",http://arxiv.org/abs/2101.08967v1
"Laser threshold magnetometry using green light absorption by diamond
  nitrogen vacancies in an external cavity laser",2021-01-22T18:58:05Z,"James L. Webb, Andreas F. L. Poulsen, Robert Staacke, Jan Meijer, Kirstine Berg-Sørensen, Ulrik Lund Andersen, Alexander Huck","Nitrogen vacancy (NV) centers in diamond have attracted considerable recent
interest for use in quantum sensing, promising increased sensitivity for
applications ranging from geophysics to biomedicine. Conventional sensing
schemes involve monitoring the change in red fluorescence from the NV center
under green laser and microwave illumination. Due to the strong fluorescence
background from emission in the NV triplet state and low relative contrast of
any change in output, sensitivity is severely restricted by a high optical shot
noise level. Here, we propose a means to avoid this issue, by using the change
in green pump absorption through the diamond as part of a semiconductor
external cavity laser run close to lasing threshold. We show theoretical
sensitivity to magnetic field on the pT/sqrt(Hz) level is possible using a
diamond with an optimal density of NV centers. We discuss the physical
requirements and limitations of the method, particularly the role of amplified
spontaneous emission near threshold and explore realistic implementations using
current technology.",http://arxiv.org/abs/2101.09277v1
"A Change-Point Based Control Chart for Detecting Sparse Changes in
  High-Dimensional Heteroscedastic Data",2021-01-23T05:38:17Z,"Zezhong Wang, Inez Maria Zwetsloot","Because of the curse-of-dimensionality, high-dimensional processes present
challenges to traditional multivariate statistical process monitoring (SPM)
techniques. In addition, the unknown underlying distribution and complicated
dependency among variables such as heteroscedasticity increase uncertainty of
estimated parameters, and decrease the effectiveness of control charts. In
addition, the requirement of sufficient reference samples limits the
application of traditional charts in high dimension low sample size scenarios
(small n, large p). More difficulties appear in detecting and diagnosing
abnormal behaviors that are caused by a small set of variables, i.e., sparse
changes. In this article, we propose a changepoint based control chart to
detect sparse shifts in the mean vector of high-dimensional heteroscedastic
processes. Our proposed method can start monitoring when the number of
observations is a lot smaller than the dimensionality. The simulation results
show its robustness to nonnormality and heteroscedasticity. A real data example
is used to illustrate the effectiveness of the proposed control chart in
high-dimensional applications. Supplementary material and code are provided
online.",http://arxiv.org/abs/2101.09424v1
"Deep learning based mixed-dimensional GMM for characterizing variability
  in CryoEM",2021-01-25T19:05:23Z,"Muyuan Chen, Steven Ludtke","Structural flexibility and/or dynamic interactions with other molecules is a
critical aspect of protein function. CryoEM provides direct visualization of
individual macromolecules sampling different conformational and compositional
states. While numerous methods are available for computational classification
of discrete states, characterization of continuous conformational changes or
large numbers of discrete state without human supervision remains challenging.
Here we present e2gmm, a machine learning algorithm to determine a
conformational landscape for proteins or complexes using a 3-D Gaussian mixture
model mapped onto 2-D particle images in known orientations. Using a deep
neural network architecture, e2gmm can automatically resolve the structural
heterogeneity within the protein complex and map particles onto a small latent
space describing conformational and compositional changes. This system presents
a more intuitive and flexible representation than other manifold methods
currently in use. We demonstrate this method on both simulated data as well as
three biological systems, to explore compositional and conformational changes
at a range of scales. The software is distributed as part of EMAN2.",http://arxiv.org/abs/2101.10356v2
Energy Non-Conservation in Quantum Mechanics,2021-01-26T19:47:20Z,"Sean M. Carroll, Jackie Lodman","We study the conservation of energy, or lack thereof, when measurements are
performed in quantum mechanics. The expectation value of the Hamiltonian of a
system can clearly change when wave functions collapse in accordance with the
standard textbook (Copenhagen) treatment of quantum measurement, but one might
imagine that the change in energy is compensated by the measuring apparatus or
environment. We show that this is not true; the change in the energy of a state
after measurement can be arbitrarily large, independent of the physical
measurement process. In Everettian quantum theory, while the expectation value
of the Hamiltonian is conserved for the wave function of the universe
(including all the branches), it is not constant within individual worlds. It
should therefore be possible to experimentally measure violations of
conservation of energy, and we suggest an experimental protocol for doing so.",http://arxiv.org/abs/2101.11052v2
"Thermodynamics with pressure and volume of black holes based on two
  assumptions under scalar field scattering",2021-01-27T14:09:28Z,"Benrong Mu, Jing Liang, Xiaobo Guo","Recently, a new assumption was proposed in [Phys. Rev. D 100, no.10, 104022
(2019)]. This assumption considers that the energy of the particle changes the
enthalpy of the black hole after throwing the particle into the black hole.
Using the energy-momentum relation, the results show that the second law of
thermodynamics of the black hole is valid in extended phase space. In this
paper, we discuss the validity of the laws of thermodynamics and the stability
of the horizon of the charged AdS black hole by scalar field scattering under
two assumptions, i.e., the energy flux of the scalar field $dE$ changes the
internal energy of the black hole $dU$ and the energy flux of the scalar field
$dE$ changes the enthalpy of the black hole $dM$.",http://arxiv.org/abs/2101.11414v2
"Spatial statistics of superposition of two uncorrelated speckle patterns
  with polarization diversity",2021-01-31T21:22:30Z,Abhijit Roy,"A detailed theoretical and experimental study on the effect of the
superposition of uncorrelated speckle patterns with polarization diversity on
the spatial statistics of the superposed speckle pattern is presented. It is
shown that depending on the mutual orientation of the polarization vectors of
the constituent speckle patterns, the maximum degree of coherence (DoC) and
degree of polarization (DoP) of the superposed speckle pattern changes between
a maximum and minimum value in a sinusoidal fashion. Moreover, the average
intensity ratio of the constituent speckle patterns is also found to be
affecting these variations. A study of the change in the visibility of the
two-point intensity correlation function also reveals a sinusoidal nature of
the variation and its dependence on the ratio of the average intensity, which
are found to be similar to the variations of the maximum DoC and DoP. A
detailed study on the changes in the normalized probability density function is
also performed for better understanding of the effect on the spatial
statistics.",http://arxiv.org/abs/2102.00539v1
"Spatiotemporal Ground Reaction Force Analysis using Convolutional Neural
  Networks to Analyze Parkinsonian Gait",2021-02-01T04:30:34Z,"Musthaq Ahamed, P. D. S. H. Gunawardane, Nimali T. Medagedara","Parkinson's disease (PD) is a non-curable disease that commonly found among
elders that greatly reduce their quality of life. PD primarily affects the gait
pattern and slowly changes the walking gait from the normality to disability.
The early diagnosing of PD is important for treatments and gait pattern
analysis is used as a technique to diagnose PD. The present paper has
identified the raw spatiotemporal ground reaction force (GRF) as a key
parameter to identify the changes in human gait patterns associated with PD.
The changes in GRF are identified using a convolutional neural network through
pre-processing, conversion, recognition, and performance evaluation. The
proposed algorithm is capable of identifying the severity of the PD and
distinguishing the parkinsonian gait from the healthy gait. The technique has
shown a 97% of accuracy in automatic decision-making process.",http://arxiv.org/abs/2102.00628v1
"Long-term, orbital, and rapid variations of the Be star V923 Aql = HD
  183656",2021-02-01T04:32:04Z,"M. Wolf, P. Harmanec, H. Božić, P. Koubský, S. Yang, D. Ruždjak, M. Šlechta, H. Ak, H. Bakış, V. Bakış, A. Oplištilová, K. Vitovský","We present the latest results of a long-term observational project aimed at
observing, collecting from the literature, and homogenising the light, colour,
and spectral variations of the well-known emission-line Be star V923 Aql. Our
analysis of these parameters confirms that all of the observables exhibit
cyclic changes with variable cycle length between about 1800 and 3000 days, so
far documented for seven consecutive cycles. We show that these variations can
be qualitatively understood within the framework of the model of one-armed
oscillation of the circumstellar disk, with a wave of increased density and
prograde revolution in space. We confirm the binary nature of the object with a
214.716 day period and estimate the probable system properties. We also confirm
the presence of rapid light, and likely also spectral changes. However, we
cannot provide any firm conclusions regarding their nature. A quantitative
modelling study of long-term changes is planned as a follow-up to this work.",http://arxiv.org/abs/2102.00631v1
"Electronic, magnetic and galvanomagnetic properties of Co-based Heusler
  alloys: possible states of a half-metallic ferromagnet and spin gapless
  semiconductor",2021-02-01T16:36:27Z,"A. A. Semiannikova, Yu. A. Perevozchikova, V. Yu Irkhin, E. B. Marchenkova, P. S. Korenistov, V. V. Marchenkov","Parameters of the energy gap and, consequently, electronic, magnetic and
galvanomagnetic properties in different X$_2$YZ Heusler alloys can vary quite
strongly. In particular, half-metallic ferromagnets (HMFs) and spin gapless
semiconductors (SGSs) with almost 100% spin polarization of charge carriers are
promising materials for spintronics. The changes in the electrical, magnetic
and galvanomagnetic properties of the Co$_2$YSi (Y = Ti, V, Cr, Mn, Fe) and
Co$_2$MnZ Heusler alloys (Z = Al, Si, Ga, Ge) in possible HMF and/or SGS states
were followed and their interconnection was established. Significant changes in
the values of the magnetization and residual resistivity were found. At the
same time, the correlations between the changes in these electronic and
magnetic characteristics depending on the number of valence electrons and spin
polarization are observed.",http://arxiv.org/abs/2102.00952v1
Exciting the Goldstone Modes of a Supersolid Spin-Orbit-Coupled Bose Gas,2021-02-03T19:00:04Z,"Kevin T. Geier, Giovanni I. Martone, Philipp Hauke, Sandro Stringari","Supersolidity is deeply connected with the emergence of Goldstone modes,
reflecting the spontaneous breaking of both phase and translational symmetry.
Here, we propose accessible signatures of these modes in harmonically trapped
spin-orbit-coupled Bose-Einstein condensates, where supersolidity appears in
the form of stripes. By suddenly changing the trapping frequency, an axial
breathing oscillation is generated, whose behavior changes drastically at the
critical Raman coupling. Above the transition, a single mode of hybridized
density and spin nature is excited, while below it, we predict a beating effect
signaling the excitation of a Goldstone spin-dipole mode. We further provide
evidence for the Goldstone mode associated with the translational motion of
stripes. Our results open up new perspectives for probing supersolid properties
in experimentally relevant configurations with both symmetric as well as highly
asymmetric intraspecies interactions.",http://arxiv.org/abs/2102.02221v2
"How the Massachusetts Assault Weapons Ban Enforcement Notice Changed
  Firearm Sales",2021-02-04T20:55:31Z,"Meenakshi Balakrishna, Kenneth C. Wilbur","The Massachusetts Attorney General issued an Enforcement Notice in 2016 to
announce a new interpretation of a key phrase in the state's assault weapons
ban. The Enforcement Notice increased sales of tagged assault rifles by 616% in
the first 5 days, followed by a 9% decrease over the next three weeks. Sales of
Handguns and Shotguns did not change significantly. Tagged assault rifle sales
fell 28-30% in 2017 compared to previous years, suggesting that the Enforcement
Notice reduced assault weapon sales but also that many banned weapons continued
to be sold. Tagged assault rifles sold most in 2017 in zip codes with higher
household incomes and proportions of white males. Overall, the results suggest
that the firearm market reacts rapidly to policy changes and partially complies
with firearm restrictions.",http://arxiv.org/abs/2102.02884v1
"Direction and Constraint in Phenotypic Evolution: Dimension Reduction
  and Global Proportionality in Phenotype Fluctuation and Responses",2021-02-05T06:56:23Z,"Kunihiko Kaneko, Chikara Furusawa","A macroscopic theory for describing cellular states during steady-growth is
presented, which is based on the consistency between cellular growth and
molecular replication, as well as the robustness of phenotypes against
perturbations. Adaptive changes in high-dimensional phenotypes were shown to be
restricted within a low-dimensional slow manifold, from which a macroscopic law
for cellular states was derived, which was confirmed by adaptation experiments
on bacteria under stress. Next, the theory was extended to phenotypic
evolution, leading to proportionality between phenotypic responses against
genetic evolution and environmental adaptation. The link between robustness to
noise and mutation, as a result of robustness in developmental dynamics to
perturbations, showed proportionality between phenotypic plasticity by genetic
changes and by environmental noise. Accordingly, directionality and constraint
in phenotypic evolution was quantitatively formulated in terms of phenotypic
fluctuation and the response against environmental change. The evolutionary
relevance of slow modes in controlling high-dimensional phenotypes is
discussed.",http://arxiv.org/abs/2102.03025v1
"Does the Order of Training Samples Matter? Improving Neural Data-to-Text
  Generation with Curriculum Learning",2021-02-06T10:14:18Z,"Ernie Chang, Hui-Syuan Yeh, Vera Demberg","Recent advancements in data-to-text generation largely take on the form of
neural end-to-end systems. Efforts have been dedicated to improving text
generation systems by changing the order of training samples in a process known
as curriculum learning. Past research on sequence-to-sequence learning showed
that curriculum learning helps to improve both the performance and convergence
speed. In this work, we delve into the same idea surrounding the training
samples consisting of structured data and text pairs, where at each update, the
curriculum framework selects training samples based on the model's competence.
Specifically, we experiment with various difficulty metrics and put forward a
soft edit distance metric for ranking training samples. Our benchmarks show
faster convergence speed where training time is reduced by 38.7% and
performance is boosted by 4.84 BLEU.",http://arxiv.org/abs/2102.03554v1
Solving peak theory in the presence of local non-gaussianities,2021-02-08T09:48:14Z,"Flavio Riccardi, Marco Taoso, Alfredo Urbano","We compute the probability density distribution of maxima for a scalar random
field in the presence of local non-gaussianities. The physics outcome of this
analysis is the following. If we focus on maxima whose curvature is larger than
a certain threshold for gravitational collapse, our calculations illustrate how
the fraction of the Universe's mass in the form of primordial black holes
(PBHs) changes in the presence of local non-gaussianities. We find that
previous literature on the subject exponentially overestimate, by many orders
of magnitude, the impact of local non-gaussianities on the PBH abundance. We
explain the origin of this discrepancy, and conclude that, in realistic
single-field inflationary models with ultra slow-roll, one can obtain the same
abundance found with the gaussian approximation simply changing the peak
amplitude of the curvature power spectrum by no more than a factor of two. We
comment about the relevance of non-gaussianities for second-order gravitational
waves.",http://arxiv.org/abs/2102.04084v2
"A Novel Trick to Overcome the Phase Space Volume Change and the Use of
  Hamiltonian Trajectories with an emphasis on the Free Expansion",2021-02-11T17:02:44Z,P. D. Gujrati,"We extend and successfully apply a recently proposed microstate
nonequilibrium thermodynamics to study expansion/contraction processes. Here,
the numbers of initial and final microstates are different so they cannot be
connected by unique Hamiltonian trajectories. This commonly happens when the
phase space volume changes, and has not been studied so far using Hamiltonian
trajectories that can be inverted to yield an identity mapping between initial
and final microstates as the parameter in the Hamiltonian is changed. We
propose a trick to overcome this hurdle with a focus on free expansion in an
isolated system, where the concept of dissipated work is not clear. The trick
is shown to be thermodynamically consistent and can be extremely useful in
simulation. We justify that it is the thermodynamic average of the internal
microwork done by a microstate that is dissipated; this microwork is different
from the exchange microwork with the vacuum, which vanishes. We also establish
that the microwork is nonnegative for free expansion, which is remarkable,
since its sign is not fixed in a general process.",http://arxiv.org/abs/2102.06122v1
"When no news is bad news -- Detection of negative events from news media
  content",2021-02-12T13:14:44Z,"Kristoffer L. Nielbo, Frida Haestrup, Kenneth C. Enevoldsen, Peter B. Vahlstrup, Rebekah B. Baglini, Andreas Roepstorff","During the first wave of Covid-19 information decoupling could be observed in
the flow of news media content. The corollary of the content alignment within
and between news sources experienced by readers (i.e., all news transformed
into Corona-news), was that the novelty of news content went down as media
focused monotonically on the pandemic event. This all-important Covid-19 news
theme turned out to be quite persistent as the pandemic continued, resulting in
the, from a news media's perspective, paradoxical situation where the same news
was repeated over and over. This information phenomenon, where novelty
decreases and persistence increases, has previously been used to track change
in news media, but in this study we specifically test the claim that new
information decoupling behavior of media can be used to reliably detect change
in news media content originating in a negative event, using a Bayesian
approach to change point detection.",http://arxiv.org/abs/2102.06505v1
"Spin injection into vanadium dioxide films from a typical ferromagnetic
  metal, across the metal-insulator transition of the vanadium dioxide films",2021-02-16T07:57:44Z,"Kazuma Tamura, Teruo Kanki, Shun Shirai, Hidekazu Tanaka, Yoshio Teki, Eiji Shikoh","A vanadium dioxide VO2 film shows metal-insulator transition (MIT) induced by
changing environmental temperature. We report the temperature dependence of
electromotive force properties generated in VO2/Ni80Fe20 bilayer junctions
under the ferromagnetic resonance (FMR) of the Ni80Fe20 layer. An electromotive
force generated in a VO2/Ni80Fe20 bilayer junction under the FMR showed a small
change across the MIT temperature of the VO2 film, while the VO2 film
resistance drastically changed. This behavior was not only explained with the
temperature dependence of the electromotive force property generated in the
Ni80Fe20 film itself under the FMR, but also with the generated electromotive
forces due to the inverse spin-Hall effect (ISHE) in the VO2 film under the FMR
of the Ni80Fe20 film. That is, we successfully demonstrated the spin injection
from a Ni80Fe20 film into a VO2 film across the MIT temperature of the VO2
film.",http://arxiv.org/abs/2102.07998v1
A Qualitative Theory of Cognitive Attitudes and their Change,2021-02-16T10:28:49Z,Emiliano Lorini,"We present a general logical framework for reasoning about agents' cognitive
attitudes of both epistemic type and motivational type. We show that it allows
us to express a variety of relevant concepts for qualitative decision theory
including the concepts of knowledge, belief, strong belief, conditional belief,
desire, conditional desire, strong desire and preference. We also present two
extensions of the logic, one by the notion of choice and the other by dynamic
operators for belief change and desire change, and we apply the former to the
analysis of single-stage games under incomplete information. We provide sound
and complete axiomatizations for the basic logic and for its two extensions.
The paper is under consideration in Theory and Practice of Logic Programming
(TPLP).",http://arxiv.org/abs/2102.11025v1
Superconducting Quantum Interference at the Atomic Scale,2021-02-24T19:26:47Z,"S. Karan, H. Huang, C. Padurariu, B. Kubala, A. Theiler, A. Black-Schaffer, G. Morrás, A. Levy Yeyati, J. C. Cuevas, J. Ankerhold, K. Kern, C. R. Ast","A single spin in a Josephson junction can reverse the flow of the
supercurrent. At mesoscopic length scales, such $\pi$-junctions are employed in
various instances from finding the pairing symmetry to quantum computing. In
Yu-Shiba-Rusinov (YSR) states, the atomic scale counterpart of a single spin in
a superconducting tunnel junction, the supercurrent reversal so far has
remained elusive. Using scanning tunneling microscopy (STM), we demonstrate
such a 0 to $\pi$ transition of a Josephson junction through a YSR state as we
continuously change the impurity-superconductor coupling. We detect the sign
change in the critical current by exploiting a second transport channel as
reference in analogy to a superconducting quantum interference device (SQUID),
which provides the STM with the required phase sensitivity. The measured change
in the Josephson current is a signature of the quantum phase transition and
allows its characterization with unprecedented resolution.",http://arxiv.org/abs/2102.12521v2
NodeSRT: A Selective Regression Testing Tool for Node.js Application,2021-03-31T22:23:48Z,Yufeng Chen,"Node.js is one of the most popular frameworks for building web applications.
As software systems mature, the cost of running their entire regression test
suite can become significant. Selective Regression Testing (SRT) is a technique
that executes only a subset of tests the regression test suite can detect
software failures more efficiently. Previous SRT studies mainly focused on
standard desktop applications. Node.js applications are considered hard to
perform test reduction because of Node's asynchronous, event-driven programming
model and because JavaScript is a dynamic programming language. In this paper,
we present NodeSRT, a Selective Regression Testing framework for Node.js
applications. By performing static and dynamic analysis, NodeSRT identifies the
relationship between changed methods and tests, then reduces the regression
test suite to only tests that are affected by the change to improve the
execution time of the regression test suite. To evaluate our selection
technique, we applied NodeSRT to two open-source projects: Uppy and Simorgh,
then compared our approach with the retest-all strategy and current
industry-standard SRT technique: Jest OnlyChange. The results demonstrate that
NodeSRT correctly selects affected tests based on changes and is 250% faster,
450% more precise than the Jest OnlyChange.",http://arxiv.org/abs/2104.00142v1
"A Context Aware and Self Adaptation Strategy for Cloud Service Selection
  and Configuration in Run Time",2021-04-01T23:49:33Z,"Asmae Benali, Bouchra El Asri","Day after day, the number of mobile applications deployed on cloud computing
continues in increasing because o f smartphone capabilities improvement. Cloud
computing has already succeeded in the web based application, for that reason,
the demand for context aware services provided by cloud computing increases. To
customize a cloud service that takes into account th e consumer requirements,
which depend on information change, it brings to light many recent challenges
to cloud computing about environment aware, location aware, time aware. The
cloud provider, moreover, has to manage personalized applications and the con
straints of mobile devices in matters of interaction abilities and
communication restrictions. This paper proposes a strategy for selecting
automatically an appropriate cloud environment that runs out whole
requirements, defines a configuration for the ass ociated cloud environment and
able to easily adapt to the change of the environment on either the user or the
cloud side or both. This process builds on the principles of dynamic software
product lines, Agent oriented software engineering, and the MAPE k m odel to
select and configure cloud environments according to the consumer needs and the
context change.",http://arxiv.org/abs/2104.00813v1
"New class of sixth-order nonhomogeneous $p(x)$-Kirchhoff problems with
  sign-changing weight functions",2021-04-02T12:29:22Z,"M. K. Hamdani, N. T. Chung, D. D. Repovš","We prove the existence of multiple solutions for the following sixth-order
$p(x)$-Kirchhoff-type problem: $-M(\int_\Omega \frac{1}{p(x)}|\nabla \Delta
u|^{p(x)}dx)\Delta^3_{p(x)} u = \lambda f(x)|u|^{q(x)-2}u + g(x)|u|^{r(x)-2}u +
h(x) \ \ \mbox{on} \ \Omega$ and $ \ u=\Delta u=\Delta^2 u=0 \ \ \mbox{on} \
\partial\Omega,$ where $\Omega \subset \mathbb{R}^N$ is a smooth bounded
domain, $N > 3$, $\Delta_{p(x)}^3u = \operatorname{div}\Big(\Delta(|\nabla
\Delta u|^{p(x)-2}\nabla \Delta u)\Big)$ is the $p(x)$-triharmonic operator,
$p,q,r \in C(\overline\Omega)$, $1< p(x) < \frac N3$ for all $x\in
\overline\Omega$, $M(s) = a - bs^\gamma$, $a,b,\gamma>0$, $\lambda>0$, $g:
\Omega \times \mathbb{R} \to \mathbb{R}$ is a nonnegative continuous function
while $f,h : \Omega \times \mathbb{R} \to \mathbb{R}$ are sign-changing
continuous functions in $\Omega$. To the best of our knowledge, this paper is
one of the first contributions to the study of the sixth-order $p(x)$-Kirchhoff
type problems with sign changing Kirchhoff functions.",http://arxiv.org/abs/2104.01012v1
Equilibrium constants of nuclear reactions in supernova explosions,2021-04-04T18:19:49Z,"Jorge A. Muñoz, Marcos A. García, Jorge A. López","We study the change in internal rotational energy in the transformation of
protons to neutrons in the \b{eta}-decay reactions that take place in the
collapse of the iron core of massive stars that precede type II supernova
explosions. We consider an ensemble of electrons, protons, neutrons and
neutrinos undergoing \b{eta}-decay reactions, treat the protons and neutrons as
triatomic rotors, evaluate the equilibrium constant to obtain the change in
rotational energy during the proton-to-neutron transformation. We estimate such
change for a variety of conditions, and compare to the energy released in a
supernova explosion.",http://arxiv.org/abs/2104.01658v1
"Neutrino collective effects during their decoupling era in the early
  universe",2021-04-06T20:25:56Z,Raymond F. Sawyer,"There is an accepted approach to calculation of the neutrino flavor
density-matrix in the halo of a supernova, in which neutrino amplitudes, not
cross-sections, need to be followed carefully in the region above the region of
frequent scatterings. The same reasoning and techniques, applied to the
evolution of neutrino flavors and energy distributions in the early universe in
the era of neutrino decoupling, leads to radical changes in the predictions of
the effects of the neutrino-neutrino interaction. Predictions for the
production of sterile neutrinos, should they exist, will also be changed.",http://arxiv.org/abs/2104.02771v1
Schoenberg correspondence for multifaced independence,2021-04-07T08:28:01Z,Malte Gerhold,"We extend the Schoenberg correspondence for universal independences by
Sch\""urmann and Vo{\ss} to the multivariate setting of Manzel and Sch\""urmann,
covering, e.g., Voiculescu's bifreeness as well as Bo\.zejko and Speicher's
c-free independence. At the same time, we free the proof in the univariate
situation from its dependence on Muraki's classification theorem (which states
that there are only five univariate independences: tensor, free, Boolean,
monotone, and antimonotone independence). In contrast to the univariate case,
the class of multivariate independences considered here is infinite and not yet
fully understood. Furthermore, helpful tools such quantum stochastic calculi
and Fock space constructions, which are used by Sch\""urmann and Vo{\ss} to
prove Schoenberg correspondence in the univariate case, are not available in
general. This problem is overcome by relating convolution exponentials with
respect to different independences to each other, which ultimately allows to
reduce all Schoenberg correspondences for multivariate independences to the
case of convolution semigroups on *-bialgebras.",http://arxiv.org/abs/2104.02985v3
Min(d)ing the President: A text analytic approach to measuring tax news,2021-04-07T17:08:16Z,"Lenard Lieb, Adam Jassem, Rui Jorge Almeida, Nalan Baştürk, Stephan Smeekes","Economic agents react to signals about future tax policy changes.
Consequently, estimating their macroeconomic effects requires identification of
such signals. We propose a novel text analytic approach for transforming
textual information into an economically meaningful time series. Using this
method, we create a tax news measure from all publicly available post-war
communications of U.S. presidents. Our measure predicts the direction and size
of future tax changes and contains signals not present in previously considered
(narrative) measures of tax changes. We investigate the effects of tax news and
find that, for long anticipation horizons, pre-implementation effects lead
initially to contractions in output.",http://arxiv.org/abs/2104.03261v3
"Density-tuned isotherms and dynamic change at phase transition in a
  gate-controlled superconducting system",2021-04-08T09:35:53Z,"Shamashis Sengupta, Miguel Monteverde, Anil Murani, Claire Marrache-Kikuchi, Andres F. Santander-Syro, Franck Fortuna","Two-dimensional electron gases in SrTiO3-based heterostructures provide a
platform to study the real-time evolution of the macroscopic state with a
variation of the carrier density, and the impact of structural properties on
the emergence of the superconducting state. We have explored the isothermal
evolution of the electron gas in AlOx/SrTiO3 by measuring the variation of
resistance with continuous gate-voltage-controlled tuning of its carrier
density. It is seen that condensation of the ordered phase leads to
non-monotonic isotherms within the superconducting dome. The timescale for
dynamic change following changes in gate voltage is measured across the phase
transition. It is found to be tens of seconds near the onset of
superconductivity, significantly larger compared to the normal state. Such a
large timescale governing the kinetics of the phase transition presumably
arises from the strong impact of structural defects and distortions of the
substrate on the development of superconducting islands.",http://arxiv.org/abs/2104.03633v2
"Demand-pull, technology-push, and the direction of technological change",2021-04-10T16:56:53Z,Kerstin Hötte,"This paper studies the impact of Demand-pull (DP) and Technology-push (TP) on
growth, innovation, and the factor bias of technological change in a two-layer
network of input-output (market) and patent citation (innovation) links among
307 6-digit US manufacturing industries in 1977-2012. Two types of TP and DP
are distinguished: (1) DP and TP are between-layer spillovers when market
demand shocks pull innovation and innovation pushes market growth. (2)
Within-layer DP arises if downstream users trigger upstream innovation and
growth, while TP effects spill over from up- to downstream industries. The
results support between- and within-layer TP: Innovation spillovers from
upstream industries drive market growth and innovation. Within the market,
upstream supply shocks stimulate growth, but this effect differs across
industries. DP is not supported but shows a factor bias favoring labor, while
TP comes with a shift towards non-production work. The results are strongest
after the 2000s and shed light on the drivers of recent technological change
and its factor bias.",http://arxiv.org/abs/2104.04813v5
"Magnetogenesis From Baryon Asymmetry During an Early Matter Dominated
  Era",2021-04-10T16:57:05Z,"Fatemeh Elahi, Hadi Mehrabpour","In this paper, we study the simultaneous evolution of baryon asymmetry and
hypermagnetic field amplitude assuming an early matter domination. We contrast
our results to the conventional case where radiation domination during early
universe is assumed. We show that the baryon asymmetry and the hypermagntic
field amplitude can change by orders of magnitude if we assume a non-standard
history of cosmology. That is because the Hubble rate determines which
processes are efficient. We find that a change in Hubble rate can have a
significant impact on when the weak sphalerons become active. As a result of a
change in the evolution of baryonic asymmetry, alters the evolution of
hypermagnetic field amplitude. It is known that if the hypermagnetic field
amplitude is large enough, it can save the baryon asymmetry from diminishing.
We show that whether a small seed of hypermagnetic field amplitude can be
amplified to a large enough value will strongly depend on the history of
cosmology.",http://arxiv.org/abs/2104.04815v2
Limit theorems for prices of options written on semi-Markov processes,2021-04-10T17:02:46Z,"Enrico Scalas, Bruno Toaldo","We consider plain vanilla European options written on an underlying asset
that follows a continuous time semi-Markov multiplicative process. We derive a
formula and a renewal type equation for the martingale option price. In the
case in which intertrade times follow the Mittag-Leffler distribution, under
appropriate scaling, we prove that these option prices converge to the price of
an option written on geometric Brownian motion time-changed with the inverse
stable subordinator. For geometric Brownian motion time changed with an inverse
subordinator, in the more general case when the subordinator's Laplace exponent
is a special Bernstein function, we derive a time-fractional generalization of
the equation of Black and Scholes.",http://arxiv.org/abs/2104.04817v5
SGD Implicitly Regularizes Generalization Error,2021-04-10T23:10:14Z,Daniel A. Roberts,"We derive a simple and model-independent formula for the change in the
generalization gap due to a gradient descent update. We then compare the change
in the test error for stochastic gradient descent to the change in test error
from an equivalent number of gradient descent updates and show explicitly that
stochastic gradient descent acts to regularize generalization error by
decorrelating nearby updates. These calculations depends on the details of the
model only through the mean and covariance of the gradient distribution, which
may be readily measured for particular models of interest. We discuss further
improvements to these calculations and comment on possible implications for
stochastic optimization.",http://arxiv.org/abs/2104.04874v1
Operational approach to metastability,2021-04-11T20:25:27Z,Katarzyna Macieszczak,"In this work, we introduce an information-theoretic approach for considering
changes in dynamics of finitely dimensional open quantum systems governed by
master equations. This experimentally motivated approach arises from
considering how the averages of system observables change with time and
quantifies how non-stationary the system is during a given time regime. By
drawing an analogy with the exponential decay, we are able to further
investigate regimes when such changes are negligible according to the
logarithmic scale of time, and thus the system is approximately stationary.
While this is always the case within the initial and final regimes of the
dynamics, with the system respectively approximated by its initial and
asymptotic states, we show that a distinct regime of approximate stationarity
may arise. In turn, we establish a quantitative description of the phenomenon
of metastability in open quantum systems. The initial relaxation occurring
before the corresponding metastable regime and of the long-time dynamics taking
place afterwards are also characterised. Furthermore, we explain how
metastability relates to the separation in the real part of the master equation
spectrum and connect our approach to the spectral theory of metastability,
clarifying when the latter follows. All of our general results directly
translate to Markovian dynamics of classical stochastic systems.",http://arxiv.org/abs/2104.05095v2
Relaxation process of magnetic friction under sudden changes in velocity,2021-04-13T04:47:48Z,Hisato Komatsu,"Although there have been many studies of statistical mechanical models of
magnetic friction, most of these have focused on the behavior in the steady
state. In this study, we prepare a system composed of a chain and a lattice of
Ising spins that interact with each other, and investigate the relaxation of
the system when the relative velocity $v$ changes suddenly. The situation where
$v$ is given is realized by attaching the chain to a spring, the other end of
which moves with a constant velocity $v$. Numerical simulation finds that, when
the spring constant has a moderate value, the relaxation of the frictional
force is divided into two processes, which are a sudden change and a slow
relaxation. This behavior is also observed on regular solid surfaces, although
caused by different factors than our model. More specifically, the slow
relaxation process is caused by relaxation of the magnetic structure in our
model, but is caused by creep deformation in regular solid surfaces.",http://arxiv.org/abs/2104.05935v1
The challenges of temporal alignment on Twitter during crises,2021-04-17T13:11:41Z,"Aniket Pramanick, Tilman Beck, Kevin Stowe, Iryna Gurevych","Language use changes over time, and this impacts the effectiveness of NLP
systems. This phenomenon is even more prevalent in social media data during
crisis events where meaning and frequency of word usage may change over the
course of days. Contextual language models fail to adapt temporally,
emphasizing the need for temporal adaptation in models which need to be
deployed over an extended period of time. While existing approaches consider
data spanning large periods of time (from years to decades), shorter time spans
are critical for crisis data. We quantify temporal degradation for this
scenario and propose methods to cope with performance loss by leveraging
techniques from domain adaptation. To the best of our knowledge, this is the
first effort to explore effects of rapid language change driven by adversarial
adaptations, particularly during natural and human-induced disasters. Through
extensive experimentation on diverse crisis datasets, we analyze under what
conditions our approaches outperform strong baselines while highlighting the
current limitations of temporal adaptation methods in scenarios where access to
unlabeled data is scarce.",http://arxiv.org/abs/2104.08535v3
"Comparing Correspondences: Video Prediction with Correspondence-wise
  Losses",2021-04-19T17:59:29Z,"Daniel Geng, Max Hamilton, Andrew Owens","Image prediction methods often struggle on tasks that require changing the
positions of objects, such as video prediction, producing blurry images that
average over the many positions that objects might occupy. In this paper, we
propose a simple change to existing image similarity metrics that makes them
more robust to positional errors: we match the images using optical flow, then
measure the visual similarity of corresponding pixels. This change leads to
crisper and more perceptually accurate predictions, and does not require
modifications to the image prediction network. We apply our method to a variety
of video prediction tasks, where it obtains strong performance with simple
network architectures, and to the closely related task of video interpolation.
Code and results are available at our webpage:
https://dangeng.github.io/CorrWiseLosses",http://arxiv.org/abs/2104.09498v2
Price Optimization with Practical Constraints,2021-04-19T20:10:32Z,"Xiaojie Wang, Hsin-Chan Huang, Lanshan Han, Alvin Lim","In this paper, we study a retailer price optimization problem which includes
the practical constraints: maximum number of price changes and minimum amount
of price change (if a change is recommended). We provide a closed-form formula
for the Euclidean projection onto the feasible set defined by these two
constraints, based on which a simple gradient projection algorithm is proposed
to solve the price optimization problem. We study the convergence and solution
quality of the proposed algorithm. We extend the base model to include
upper/lower bounds on the individual product prices and solve it with some
adjustments to the gradient projection algorithm. Numerical results are
reported to demonstrate the performance of the proposed algorithm.",http://arxiv.org/abs/2104.09597v1
Manipulating SGD with Data Ordering Attacks,2021-04-19T22:17:27Z,"Ilia Shumailov, Zakhar Shumaylov, Dmitry Kazhdan, Yiren Zhao, Nicolas Papernot, Murat A. Erdogdu, Ross Anderson","Machine learning is vulnerable to a wide variety of attacks. It is now well
understood that by changing the underlying data distribution, an adversary can
poison the model trained with it or introduce backdoors. In this paper we
present a novel class of training-time attacks that require no changes to the
underlying dataset or model architecture, but instead only change the order in
which data are supplied to the model. In particular, we find that the attacker
can either prevent the model from learning, or poison it to learn behaviours
specified by the attacker. Furthermore, we find that even a single
adversarially-ordered epoch can be enough to slow down model learning, or even
to reset all of the learning progress. Indeed, the attacks presented here are
not specific to the model or dataset, but rather target the stochastic nature
of modern learning procedures. We extensively evaluate our attacks on computer
vision and natural language benchmarks to find that the adversary can disrupt
model training and even introduce backdoors.",http://arxiv.org/abs/2104.09667v2
Efficient Retrieval Optimized Multi-task Learning,2021-04-20T17:16:34Z,"Hengxin Fun, Sunil Gandhi, Sujith Ravi","Recently, there have been significant advances in neural methods for tackling
knowledge-intensive tasks such as open domain question answering (QA). These
advances are fueled by combining large pre-trained language models with
learnable retrieval of documents. Majority of these models use separate
encoders for learning query representation, passage representation for the
retriever and an additional encoder for the downstream task. Using separate
encoders for each stage/task occupies a lot of memory and makes it difficult to
scale to a large number of tasks. In this paper, we propose a novel Retrieval
Optimized Multi-task (ROM) framework for jointly training self-supervised
tasks, knowledge retrieval, and extractive question answering. Our ROM approach
presents a unified and generalizable framework that enables scaling efficiently
to multiple tasks, varying levels of supervision, and optimization choices such
as different learning schedules without changing the model architecture. It
also provides the flexibility of changing the encoders without changing the
architecture of the system. Using our framework, we achieve comparable or
better performance than recent methods on QA, while drastically reducing the
number of parameters.",http://arxiv.org/abs/2104.10129v1
"Structural and topological changes across the liquid-liquid transition
  in water",2021-04-20T17:35:34Z,"Riccardo Foffi, John Russo, Francesco Sciortino","It has recently been shown that the TIP4P/Ice model of water can be studied
numerically in metastable equilibrium at and below its liquid-liquid critical
temperature. We report here simulations along a subcritical isotherm, for which
two liquid states with the same pressure and temperature, but different
density, can be equilibrated. This allows for a clear visualisation of the
structural changes taking place across the transition. We specifically focus on
how the topological properties of the H-bond network change across the
liquid-liquid transition. Our results demonstrate that the structure of the
high-density liquid, characterised by the existence of interstitial molecules
and commonly explained in terms of the collapse of the second neighbour shell,
actually originates from the folding back of long rings, bringing pairs of
molecules separated by several hydrogen-bonds close by in space.",http://arxiv.org/abs/2104.10144v1
Making Differentiable Architecture Search less local,2021-04-21T10:36:43Z,"Erik Bodin, Federico Tomasi, Zhenwen Dai","Neural architecture search (NAS) is a recent methodology for automating the
design of neural network architectures. Differentiable neural architecture
search (DARTS) is a promising NAS approach that dramatically increases search
efficiency. However, it has been shown to suffer from performance collapse,
where the search often leads to detrimental architectures. Many recent works
try to address this issue of DARTS by identifying indicators for early
stopping, regularising the search objective to reduce the dominance of some
operations, or changing the parameterisation of the search problem. In this
work, we hypothesise that performance collapses can arise from poor local
optima around typical initial architectures and weights. We address this issue
by developing a more global optimisation scheme that is able to better explore
the space without changing the DARTS problem formulation. Our experiments show
that our changes in the search algorithm allow the discovery of architectures
with both better test performance and fewer parameters.",http://arxiv.org/abs/2104.10450v1
"How emoji and word embedding helps to unveil emotional transitions
  during online messaging",2021-03-23T12:45:17Z,"Moeen Mostafavi, Michael D. Porter","During online chats, body-language and vocal characteristics are not part of
the communication mechanism making it challenging to facilitate an accurate
interpretation of feelings, emotions, and attitudes. The use of emojis to
express emotional feeling is an alternative approach in these types of
communication. In this project, we focus on modeling a customer's emotion in an
online messaging session with a chatbot. We use Affect Control Theory (ACT) to
predict emotional change during the interaction. To let the customer use
emojis, we also extend the affective dictionaries used by ACT. For this
purpose, we mapped Emoji2vec embedding to the affective space. Our framework
can find emotional change during messaging and how a customer's reaction is
changed accordingly.",http://arxiv.org/abs/2104.11032v1
Deep Lucas-Kanade Homography for Multimodal Image Alignment,2021-04-22T04:11:29Z,"Yiming Zhao, Xinming Huang, Ziming Zhang","Estimating homography to align image pairs captured by different sensors or
image pairs with large appearance changes is an important and general challenge
for many computer vision applications. In contrast to others, we propose a
generic solution to pixel-wise align multimodal image pairs by extending the
traditional Lucas-Kanade algorithm with networks. The key contribution in our
method is how we construct feature maps, named as deep Lucas-Kanade feature map
(DLKFM). The learned DLKFM can spontaneously recognize invariant features under
various appearance-changing conditions. It also has two nice properties for the
Lucas-Kanade algorithm: (1) The template feature map keeps brightness
consistency with the input feature map, thus the color difference is very small
while they are well-aligned. (2) The Lucas-Kanade objective function built on
DLKFM has a smooth landscape around ground truth homography parameters, so the
iterative solution of the Lucas-Kanade can easily converge to the ground truth.
With those properties, directly updating the Lucas-Kanade algorithm on our
feature maps will precisely align image pairs with large appearance changes. We
share the datasets, code, and demo video online.",http://arxiv.org/abs/2104.11693v1
A PMUT Integrated Microfluidic System for Fluid Density Sensing,2021-04-23T19:17:34Z,"Kaustav Roy, Kritank Kalyan, Anuj Ashok, Vijayendra Shastri, Antony Jeyaseelan, Avinandan Mandal, Rudra Pratap","We demonstrate the design, fabrication and use of a dual electrode PMUT
(Piezoelectric Micromachined Ultrasound Transducer) integrated with a
microfluidic channel as a fluid density sensor in both static and dynamic
density-change conditions. The dual electrode configuration makes the PMUT
resonator a self-contained resonant peak-shift sensor and the microfluidic
integration makes this system a versatile fluid density sensing platform that
can be used with extremely low volumes of fluids in various industrial and
healthcare applications. The density measurements carried out here under
flowing fluid conditions demonstrate the potential of this system as a
real-time fluid density monitoring system. We include results of density
measurements in the range of 1020 - 1090 kg/m3 that corresponds to the human
blood density variation generally due to the change in its hemoglobin content.
The sensitivity of the sensor-26.3 Hz/(kg/m3)-is good enough to reliably detect
even 1% change in the hemoglobin content of the human blood. Thus, this system
could potentially be used also as a hemoglobin measurement sensor in healthcare
applications.",http://arxiv.org/abs/2104.11793v1
"High-field specific heat and entropy obtained from adiabatic temperature
  change",2021-04-21T20:04:03Z,"L. S. Paixão, E. O. Usuda, W. Imamura, A. M. G. Carvalho","Specific heat and entropy are relevant thermodynamic properties, which may be
used as macroscopic probes to microscopic properties of materials under ambient
conditions and under high applied fields. However, the measurement of specific
heat under intense external fields can be a challenging task, as well as to
obtain the entropy in the same conditions. Here, we describe a method to obtain
high-field specific heat and entropy from measurements of specific heat under
ambient conditions and direct temperature change induced by adiabatic field
changes. We derive straightforward thermodynamic equations to calculate the
specific heat and entropy and our results agree satisfactorily with
experimental data of specific heat under magnetic field, electric field, and
pressure.",http://arxiv.org/abs/2104.12590v1
Central limit theorems for high dimensional dependent data,2021-04-27T01:08:27Z,"Jinyuan Chang, Xiaohui Chen, Mingcong Wu","Motivated by statistical inference problems in high-dimensional time series
data analysis, we first derive non-asymptotic error bounds for Gaussian
approximations of sums of high-dimensional dependent random vectors on
hyper-rectangles, simple convex sets and sparsely convex sets. We investigate
the quantitative effect of temporal dependence on the rates of convergence to a
Gaussian random vector over three different dependency frameworks
($\alpha$-mixing, $m$-dependent, and physical dependence measure). In
particular, we establish new error bounds under the $\alpha$-mixing framework
and derive faster rate over existing results under the physical dependence
measure. To implement the proposed results in practical statistical inference
problems, we also derive a data-driven parametric bootstrap procedure based on
a kernel estimator for the long-run covariance matrices. We apply the unified
Gaussian and bootstrap approximation results to test mean vectors with combined
$\ell^2$ and $\ell^\infty$ type statistics, change point detection, and
construction of confidence regions for covariance and precision matrices, all
for time series data.",http://arxiv.org/abs/2104.12929v4
"Robust Observer Based Methodology for Frequency and Rate of Change of
  Frequency Estimation in Power Systems",2021-05-03T11:24:53Z,"Abdul Saleem Mir, Abhinav Kumar Singh, Nilanjan Senroy","An observer based adaptive detection methodology (ADM) is proposed for
estimating frequency and its rate of change (RoCoF) of the voltage and/or
current measurements acquired from an instrument transformer. With guaranteed
convergence and stability, the proposed methodology effectively neutralizes the
effect of the measurement distortions like harmonics, decaying DC components
and outliers by adding its counter negative. It is robust to noise statistics,
performs well while encountering step changes in amplitude/phase and is
demonstrably superior to its precursors as established by test results. A
benchmark IEEE NETS/NYPS 16 machine 68 bus power system has been used for
performance evaluation of robust ADM against its precursors and scaled
laboratory setup based on OP5600 multiprocessors was used for establishing its
real-time applicability.",http://arxiv.org/abs/2105.00758v1
Automatic Learning to Detect Concept Drift,2021-05-04T11:10:39Z,"Hang Yu, Tianyu Liu, Jie Lu, Guangquan Zhang","Many methods have been proposed to detect concept drift, i.e., the change in
the distribution of streaming data, due to concept drift causes a decrease in
the prediction accuracy of algorithms. However, the most of current detection
methods are based on the assessment of the degree of change in the data
distribution, cannot identify the type of concept drift. In this paper, we
propose Active Drift Detection with Meta learning (Meta-ADD), a novel framework
that learns to classify concept drift by tracking the changed pattern of error
rates. Specifically, in the training phase, we extract meta-features based on
the error rates of various concept drift, after which a meta-detector is
developed via a prototypical neural network by representing various concept
drift classes as corresponding prototypes. In the detection phase, the learned
meta-detector is fine-tuned to adapt to the corresponding data stream via
stream-based active learning. Hence, Meta-ADD uses machine learning to learn to
detect concept drifts and identify their types automatically, which can
directly support drift understand. The experiment results verify the
effectiveness of Meta-ADD.",http://arxiv.org/abs/2105.01419v1
Optical forces on an oscillating dipole near VO$_2$ phase transition,2021-05-06T07:46:31Z,"Daniela Szilard, Patrícia P. Abrantes, Felipe A. Pinheiro, Felipe S. S. Rosa, Carlos Farina, Wilton J. M. Kort-Kamp","We investigate optical forces on oscillating dipoles close to a phase-change
vanadium dioxide (VO$_2$) film, which exhibits a metal-insulator transition
around $340$ K and low thermal hysteresis. This configuration is related to one
composed of an excited two-level quantum emitter and we employ a classical
description to capture important aspects of the radiation-matter interaction.
We consider both electric and magnetic dipoles for two different
configurations, namely, with the dipole moments parallel and perpendicular to
the VO$_2$ film. By using Bruggeman theory to describe the effective optical
response of the material, we show that, in the near-field regime, the force on
the dipoles can change from attractive to repulsive just by heating the film
for a selected frequency range. We demonstrate that the thermal hysteresis
present in the VO$_2$ transition clearly shows up in the behavior of the
optical forces, setting the grounds for alternative approaches to control
light-matter interactions using phase-change materials.",http://arxiv.org/abs/2105.02493v1
"Context-Based Soft Actor Critic for Environments with Non-stationary
  Dynamics",2021-05-07T15:00:59Z,"Yuan Pu, Shaochen Wang, Xin Yao, Bin Li","The performance of deep reinforcement learning methods prone to degenerate
when applied to environments with non-stationary dynamics. In this paper, we
utilize the latent context recurrent encoders motivated by recent Meta-RL
materials, and propose the Latent Context-based Soft Actor Critic (LC-SAC)
method to address aforementioned issues. By minimizing the contrastive
prediction loss function, the learned context variables capture the information
of the environment dynamics and the recent behavior of the agent. Then combined
with the soft policy iteration paradigm, the LC-SAC method alternates between
soft policy evaluation and soft policy improvement until it converges to the
optimal policy. Experimental results show that the performance of LC-SAC is
significantly better than the SAC algorithm on the MetaWorld ML1 tasks whose
dynamics changes drasticly among different episodes, and is comparable to SAC
on the continuous control benchmark task MuJoCo whose dynamics changes slowly
or doesn't change between different episodes. In addition, we also conduct
relevant experiments to determine the impact of different hyperparameter
settings on the performance of the LC-SAC algorithm and give the reasonable
suggestions of hyperparameter setting.",http://arxiv.org/abs/2105.03310v2
"Perturbative expansion of the fundamental equation of online user
  dynamics for describing changes in eigenfrequencies",2021-05-09T09:14:04Z,"Naoki Hirakura, Masaki Aida","The oscillation model has been proposed as a theoretical framework for
describing user dynamics in online social networks. This model can model the
user dynamics generated by a particular network structure and allow its causal
relationships to be explicitly described. In this paper, by applying
perturbation theory to the fundamental equation of the oscillation model, we
confirm that we can explicitly trace, at least in principle, the changes in
user dynamics associated with changes in the network structure. Specifically,
we formulate perturbative expansions up to infinite order, by drawing on
inferences from regularities found in perturbative expansions; the accuracy of
perturbative expansions of finite order is evaluated by numerical experiments.",http://arxiv.org/abs/2105.03883v1
Nonlinear MHD simulation of core plasma collapse events in stellarators,2021-05-10T05:16:09Z,"Yasuhiro Suzuki, Shimpei Futatani, Joachim Geiger","The core collapse events observed in a stellarator experiment are studied by
a three-dimensional nonlinear MHD simulations. In the low magnetic shear
configuration like the Wendelstein 7-X, the rotational transform profile is
very sensitive to the toroidal current density. The 3D equilibrium with
localized toroidal current density is studied. If the toroidal current density
follows locally in the middle of the plasma minor radius, the rotational
transform is also changed locally. Sometimes, the magnetic topology changes due
to appearing the magnetic island. The nonlinear behaviors of the MHD
instability are studied by a full three-dimensional nonlinear MHD code. It was
found that a following sequence. At first, the high-n ballooning-type mode
structure appears in the plasma core, and then the mode linearly grows. The
high-n ballooning modes nonlinearly couple and saturate. The mode structure
changes to the low-n mode. In that phase, the magnetic field structure becomes
strongly stochastic into the plasma core due to the nonlinear coupling.
Finally, the plasma pressure diffuses along the stochastic field lines, and
then the core plasma pressure drops. This is an important results to interpret
the core collapse event by strong nonlinear coupling.",http://arxiv.org/abs/2105.04119v2
"Quantum electrodynamics in photonic crystals and controllability of
  ionization energy of atoms",2021-05-10T17:08:13Z,"R. Kh. Gainutdinov, A. I. Garifullin, M. A. Khamadeev, M. Kh. Salakhov","The periodic changes in the physical and chemical properties of the chemical
elements are caused by the periodic change of the ionization energies, which
are constant for each element that manifested in the Periodic Table. However,
as has been recently shown the modification of the electromagnetic field in the
photonic crystals gives rise to the modification of the electron
electromagnetic mass. We show that the effect can significantly change the
ionization energy of atoms placed in voids of photonic crystals consisting of
metamaterials with a highly tunable refractive index and voids. The
controllability of these materials gives rise to the controllability of the
ionization energies over a wide range.",http://arxiv.org/abs/2105.04516v1
"Enhanced tunability of two-dimensional electron gas on SrTiO3 through
  heterostructuring",2021-05-13T03:19:53Z,"Hyang Keun Yoo, Luca Moreschini, Andrew L. Walter, Aaron Bostwick, Karsten Horn, Eli Rotenberg, Young Jun Chang","Two-dimensional electron gases (2DEGs) on the SrTiO3 (STO) surface or in
STO-based heterostructures have exhibited many intriguing phenomena, which are
strongly dependent on the 2DEG-carrier density. We report that the tunability
of the 2DEG-carrier density is significantly enhanced by adding a monolayer
LaTiO3 (LTO) onto the STO. Ultraviolet (UV) irradiation induced maximum carrier
density of the 2DEG in LTO/STO is increased by a factor of ~4 times, compared
to that of the bare STO. By oxygen gas exposure, it becomes 10 times smaller
than that of the bare STO. This enhanced tunability is attributed to the
drastic surface property change of a polar LTO layer by UV irradiation and O2
exposure. This indicates that the 2DEG controllability in LTO/STO is more
reliable than that on the bare STO driven by defects, such an oxygen vacancy.",http://arxiv.org/abs/2105.06059v1
"Enhanced passive thermal stealth properties of VO$_2$ thin films via
  gradient W doping",2021-05-13T03:38:29Z,"Hyuk Jin Kim, Young Hwan Choi, Dong Kyu Lee, In Hak Lee, Byoung Ki Choi, Soo-Hyun Phark, Young Jun Chang","Thermal stealth and camouflage have been intensively studied for blending
objects with their surroundings against remote thermal image detection.
Adaptive control of infrared emissivity has been explored extensively as a
promising way of thermal stealth, but it still requires an additional feedback
control. Passive modulation of emissivity, however, has been remained as a
great challenge which requires a precise engineering of emissivity over wide
temperature range. Here, we report a drastic improvement of passive camouflage
thin films capable of concealing thermal objects at near room temperature
without any feedback control, which consists of a vanadium dioxide (VO2) layer
with gradient tungsten (W) concentration. The gradient W-doping widens the
metal-insulator transition width, accomplishing self-adaptive thermal stealth
with a smooth change of emissivity. Our simple approach, applicable to other
similar thermal camouflage materials for improving their passive cloaking, will
find wide applications, such as passive thermal camouflage, urban energy-saving
smart windows, and improved infrared sensors.",http://arxiv.org/abs/2105.06063v1
"Impacts of Time-of-Use Rate Changes on the Electricity Bills of
  Commercial Consumers",2021-05-15T00:41:58Z,"Lane D. Smith, Daniel S. Kirschen","Changes in the profile of prices in wholesale electricity markets prompt
utilities to redesign their tariffs and adjust their time-of-use periods to
ensure a more adequate cost recovery. However, changing the rate structures
could adversely affect commercial consumers by increasing their electricity
bills and hindering their ability to reduce costs using techniques like net
energy metering. As time-of-use periods are adjusted, consumers will need to
rely on the flexibility of distributed energy resources to achieve cost
reductions. This paper explores the effect that Pacific Gas and Electric
Company's redesigned rates have on the electricity bills of consumers with
different demand profiles. Sensitivity analyses are conducted to examine the
effect of asset sizing on reducing costs under each tariff.",http://arxiv.org/abs/2105.07106v1
"On the change of the Weyr characteristics of matrix pencils after
  rank-one perturbations",2021-04-29T17:17:44Z,"Itziar Baragaña, Alicia Roca","The change of the Kronecker structure of a matrix pencil perturbed by another
pencil of rank one has been characterized in terms of the homogeneous invariant
factors and the chains of column and row minimal indices of the initial and the
perturbed pencils. We obtain here a new characterization in terms of the
homogeneous invariant factors and the conjugate partitions of the corresponding
chains of column and row minimal indices of both pencils.
  We also define the generalized Weyr characteristic of an arbitrary matrix
pencil and obtain bounds for the change of it when the pencil is perturbed by
another pencil of rank one. The results improve known results on the problem,
hold for arbitrary perturbation pencils of rank one, and for any algebraically
closed field.",http://arxiv.org/abs/2105.07840v2
"Emotion Eliciting Machine: Emotion Eliciting Conversation Generation
  based on Dual Generator",2021-05-18T03:19:25Z,"Hao Jiang, Yutao Zhu, Xinyu Zhang, Zhicheng Dou, Pan Du, Te Pi, Yantao Jia","Recent years have witnessed great progress on building emotional chatbots.
Tremendous methods have been proposed for chatbots to generate responses with
given emotions. However, the emotion changes of the user during the
conversation has not been fully explored. In this work, we study the problem of
positive emotion elicitation, which aims to generate responses that can elicit
positive emotion of the user, in human-machine conversation. We propose a
weakly supervised Emotion Eliciting Machine (EEM) to address this problem.
Specifically, we first collect weak labels of user emotion status changes in a
conversion based on a pre-trained emotion classifier. Then we propose a dual
encoder-decoder structure to model the generation of responses in both positive
and negative side based on the changes of the user's emotion status in the
conversation. An emotion eliciting factor is introduced on top of the dual
structure to balance the positive and negative emotional impacts on the
generated response during emotion elicitation. The factor also provides a
fine-grained controlling manner for emotion elicitation. Experimental results
on a large real-world dataset show that EEM outperforms the existing models in
generating responses with positive emotion elicitation.",http://arxiv.org/abs/2105.08251v1
Fine-Grained View on Bribery for Group Identification,2021-05-18T09:05:47Z,"Niclas Boehmer, Robert Bredereck, Dušan Knop, Junjie Luo","Given a set of agents qualifying or disqualifying each other, group
identification is the task of identifying a socially qualified subgroup of
agents. Social qualification depends on the specific rule used to aggregate
individual qualifications. The classical bribery problem in this context asks
how many agents need to change their qualifications in order to change the
outcome in a certain way. Complementing previous results showing
polynomial-time solvability or NP-hardness of bribery for various social rules
in the constructive (aiming at making specific agents socially qualified) or
destructive (aiming at making specific agents socially disqualified) setting,
we provide a comprehensive picture of the parameterized computational
complexity landscape. Conceptually, we also consider a more fine-grained
concept of bribery cost, where we ask how many single qualifications need to be
changed, nonunit prices for different bribery actions, and a more general
bribery goal that combines the constructive and destructive setting.",http://arxiv.org/abs/2105.08376v1
Search for period changes in Mira stars,2021-05-19T09:31:53Z,"Roberto Nesci, Gianni Rocchi","We reobserved in the $R_C$ and $i'_{Sloan}$ bands, during the years
2020-2021, seven Mira variables in Cassiopeia, for which historical
$i'_{Sloan}$ light curves were available from Asiago Observatory plates taken
in the years 1967-84. The aim was to check if any of them had undergone a
substantial change in the period or in the light curve shape. Very recent
public data form ZTF-DR5 were also used to expand our time base window. A
marked color change was detected for all the stars along their variability
cycle. The star V890 Cas showed a significant period decrease of 12\% from 483
to 428 days, one of the largest known to date. All the stars, save AV Cas,
showed a smaller variation amplitude in the recent CCD data, possibly due to a
photometric accuracy higher than that of the photographic plates.",http://arxiv.org/abs/2105.09018v1
"Using Geometry to Rank Evenness Measures: Towards a Deeper Understanding
  of Divergence",2021-05-24T20:55:58Z,Kawika Pierson,"While recent work has established divergence as a key framework for
understanding evenness, there is currently no research exploring how the
families of measures within the divergence-based framework relate to each
other. This paper uses geometry to show that, holding order and richness
constant, the families of divergence-based evenness measures nest. This
property allows them to be ranked based on their reactivity to changes in
relatively even assemblages or changes in relatively uneven ones. We establish
this ranking and explore how the distance-based measures relate to it for both
order q=2 and q=1. We also derive a new family of distance-based measures that
captures the angular distance between the vector of relative abundances and a
perfectly even vector and is highly reactive to changes in even assemblages.
Finally, we show that if we only require evenness to be a divergence, then any
smooth, monotonically increasing function of diversity can be made into an
evenness measure. A deeper understanding of how to measure evenness will
require empirical or theoretical research that uncovers which kind of
divergence best reflects the underlying concept.",http://arxiv.org/abs/2105.11532v2
A generalized configuration model with triadic closure,2021-05-25T06:08:18Z,"Ruhui Chang, Duan-Shin Lee, Cheng-Shang Chang","In this paper we present a generalized configuration model with random
triadic closure (GCTC). This model possesses five fundamental properties: large
clustering coefficient, power law degree distribution, short path length,
non-zero Pearson degree correlation, and existence of community structures. We
analytically derive the Pearson degree correlation coefficient and the
clustering coefficient of the proposed model. We select a few datasets of
real-world networks. By simulation, we show that the GCTC model matches very
well with the datasets in terms of Pearson degree correlations and clustering
coefficients. We also test three well-known community detection algorithms on
our model, the datasets and other three prevalent benchmark models. We show
that the GCTC model performs equally well as the other three benchmark models.
Finally, we perform influence diffusion on the GCTC model using the independent
cascade model and the linear threshold model. We show that the influence
spreads of the GCTC model are much closer to those of the datasets than the
other benchmark models. This suggests that the GCTC model is a suitable tool to
study network science problems where degree correlation or clustering plays an
important role.",http://arxiv.org/abs/2105.11688v3
"Change in the orbital period of a binary system due to an outburst in a
  windy accretion disc",2021-05-25T14:24:45Z,"A. L. Avakyan, G. V. Lipunova, K. L. Malanchev, N. I. Shakura","We consider a new mechanism for the removal of the angular momentum from an
X-ray binary system and the change in its orbital period - the mass loss in the
form of a wind from an accretion disc. Both observations and models predict
powerful winds from discs in X-ray transients. We have obtained an analytical
estimate for the increase in the orbital period of a binary system with a wind
from the disc during an outburst, and quantitative estimates are given for the
systems XTE J1118+480, A0620-00 and GRS 1124-68. Resulting rate of period grow
is of order of the observed rates of secular decrease in the period. We also
compare the predicted rate of change in the period of a binary system due to
the flow of matter into the disc and outflow from the second Lagrange point
with the observations. It is concluded that the above mechanisms cannot explain
the observed secular decrease in the period of the three X-ray Novae, and it is
necessary to consider a circumbinary disc that drains the binary's angular
momentum.",http://arxiv.org/abs/2105.11974v1
The Yang-Baxter equation and Thompson's group $F$,2021-05-26T10:06:23Z,Fabienne Chouraqui,"In analogy with non-degenerate involutive set-theoretic solutions of the
Yang-Baxter equation and braces, we define non-degenerate involutive partial
set-theoretic solutions and partial braces. We define the structure group and
the structure inverse monoid of such a solution and prove that if the partial
solution is square-free, then its structure inverse monoid embeds into the
restricted product of a commutative inverse monoid and an inverse symmetric
monoid. Furthermore, we show that there exists a square-free, non-degenerate
involutive partial solution with structure group isomorphic to Thompson's group
$F$.",http://arxiv.org/abs/2105.12445v3
"Do not explain without context: addressing the blind spot of model
  explanations",2021-05-28T12:48:40Z,"Katarzyna Woźnica, Katarzyna Pękala, Hubert Baniecki, Wojciech Kretowicz, Elżbieta Sienkiewicz, Przemysław Biecek","The increasing number of regulations and expectations of predictive machine
learning models, such as so called right to explanation, has led to a large
number of methods promising greater interpretability. High demand has led to a
widespread adoption of XAI techniques like Shapley values, Partial Dependence
profiles or permutational variable importance. However, we still do not know
enough about their properties and how they manifest in the context in which
explanations are created by analysts, reviewed by auditors, and interpreted by
various stakeholders. This paper highlights a blind spot which, although
critical, is often overlooked when monitoring and auditing machine learning
models: the effect of the reference data on the explanation calculation. We
discuss that many model explanations depend directly or indirectly on the
choice of the referenced data distribution. We showcase examples where small
changes in the distribution lead to drastic changes in the explanations, such
as a change in trend or, alarmingly, a conclusion. Consequently, we postulate
that obtaining robust and useful explanations always requires supporting them
with a broader context.",http://arxiv.org/abs/2105.13787v1
Effect of pressure on thermalization of one-dimensional nonlinear chains,2021-05-31T10:10:39Z,"Weicheng Fu, Yong Zhang, Hong Zhao","Pressure plays a vital role in changing the transport properties of matter.
To understand this phenomenon at a microscopic level, we here focus on a more
fundamental problem, i.e., how pressure affects the thermalization properties
of solids. As illustrating examples, we study the thermalization behavior of
the monatomic chain and the mass-disordered chain of
Fermi-Pasta-Ulam-Tsingou-$\beta$ under different strains in the thermodynamic
limit. It is found that the pressure-induced change in nonintegrability results
in qualitatively different thermalization processes for the two kinds of
chains. However, for both cases, the thermalization time follows the same law
-- it is inversely proportional to the square of the nonintegrability strength.
This result suggests that pressure can significantly change the integrability
of a system, which provides a new perspective for understanding the
pressure-dependent thermal transport behavior.",http://arxiv.org/abs/2105.14855v1
Skin-Health Monitoring system using a Wireless Body Area Network,2021-04-15T20:32:54Z,"Suman Kumar, Kazi Amanul Islam Siddiqui, Mukesh Kumary","A new class of sensing paradigm known as lab-onskin where stretchable and
flexible smart sensor devices are integrated into the skin, provides direct
monitoring and diagnostic interfaces to the body. Distributed lab-on-skin
wireless sensors have the ability to provide continuous long term assessment of
the skin health. This paper proposes a distributed skin health monitoring
system using a wireless body area network. The system is responsive to the
dynamic changes in the skin health, and remotely reports on the same. The
proposed algorithm detects the abnormal skin and creates an energy efficient
data aggregation tree covering the affected area while putting the unnecessary
sensors to sleep mode. The algorithm responds to the changing conditions of the
skin by dynamically adapting the size and shape of the monitoring trees to that
of the abnormal skin areas thus providing a comprehensive monitoring.
Simulation results demonstrate the application and utility of the proposed
algorithm for changing wound shapes and sizes.",http://arxiv.org/abs/2105.15100v1
"CLINE: Contrastive Learning with Semantic Negative Examples for Natural
  Language Understanding",2021-07-01T13:34:12Z,"Dong Wang, Ning Ding, Piji Li, Hai-Tao Zheng","Despite pre-trained language models have proven useful for learning
high-quality semantic representations, these models are still vulnerable to
simple perturbations. Recent works aimed to improve the robustness of
pre-trained models mainly focus on adversarial training from perturbed examples
with similar semantics, neglecting the utilization of different or even
opposite semantics. Different from the image processing field, the text is
discrete and few word substitutions can cause significant semantic changes. To
study the impact of semantics caused by small perturbations, we conduct a
series of pilot experiments and surprisingly find that adversarial training is
useless or even harmful for the model to detect these semantic changes. To
address this problem, we propose Contrastive Learning with semantIc Negative
Examples (CLINE), which constructs semantic negative examples unsupervised to
improve the robustness under semantically adversarial attacking. By comparing
with similar and opposite semantic examples, the model can effectively perceive
the semantic changes caused by small perturbations. Empirical results show that
our approach yields substantial improvements on a range of sentiment analysis,
reasoning, and reading comprehension tasks. And CLINE also ensures the
compactness within the same semantics and separability across different
semantics in sentence-level.",http://arxiv.org/abs/2107.00440v1
A topological solution to object segmentation and tracking,2021-07-05T13:52:57Z,"Thomas Tsao, Doris Y. Tsao","The world is composed of objects, the ground, and the sky. Visual perception
of objects requires solving two fundamental challenges: segmenting visual input
into discrete units, and tracking identities of these units despite appearance
changes due to object deformation, changing perspective, and dynamic occlusion.
Current computer vision approaches to segmentation and tracking that approach
human performance all require learning, raising the question: can objects be
segmented and tracked without learning? Here, we show that the mathematical
structure of light rays reflected from environment surfaces yields a natural
representation of persistent surfaces, and this surface representation provides
a solution to both the segmentation and tracking problems. We describe how to
generate this surface representation from continuous visual input, and
demonstrate that our approach can segment and invariantly track objects in
cluttered synthetic video despite severe appearance changes, without requiring
learning.",http://arxiv.org/abs/2107.02036v1
"Electronic and magnetic properties of honeycomb zigzag nanoribbons in
  the in-plane transverse electric field using Kane-Mele-Hubbard model",2021-07-11T19:29:11Z,"J. Ghorbani, M. Ghaffarian","Using the Kane-Mele-Hubbard model in the unrestricted mean field
approximation, the effect of spin-orbit coupling, as an intrinsic parameter,
and an in-plane transverse electric field, as an external parameter, on the
electronic and magnetic properties of honeycomb zigzag nanoribbons are
investigated in the presence of electron-electron interaction. Our calculations
show that each of these parameters has significant effects on the physical
properties of nanoribbons, and each of them independently transitions the
nanoribbon from a magnetic to non-magnetic state. The process of change in some
aspect of physical properties, such as symmetry breaking, separation of spin up
and spin down energy bands, reduction of magnetic order, change of electric
dipole moment and spin current of nanoribbons, which are due to change of these
two parameters are investigated. we will see that spin-orbit coupling in the
competition with the transverse electric field determines the basic physical
properties of the nanoribbon. This research, can provide a better understanding
of two types of topological and non-topological transitions. In addition, the
separation of spin-up and spin-down energy bands and their tuning by these
parameters can be considered as a candidate for use in spintronic instruments.",http://arxiv.org/abs/2107.05120v1
Phase-change perovskite tunable microlaser,2021-07-12T07:44:45Z,"Jingyi Tian, Giorgio Adamo, Hailong Liu, Mengfei Wu, Maciej Klein, Jie Deng, Norman Soo Seng Ang, Ramón Paniagua-Domínguez, Hong Liu, Arseniy I. Kuznetsov, Cesare Soci","Since the invention of the laser, adoption of new gain media and device
architectures has provided solutions to a variety of applications requiring
specific power, size, spectral, spatial, and temporal tunability. Here we
introduce a fundamentally new type of tunable semiconductor laser based on a
phase-change perovskite metasurface that acts simultaneously as gain medium and
optical cavity. As a proof of principle demonstration, we fabricate a
subwavelength-thin perovskite metasurface supporting bound states in the
continuum (BICs). Upon the perovskite structural phase transitions, both its
refractive index and gain vary substantially, inducing fast (1.35 nm/K rate)
and broad spectral tunability (>15 nm in the near-infrared), deterministic
spatial mode hopping between polarization vortexes, and hysteretic optical
bistability of the microlaser. These features highlight the uniqueness of
phase-change perovskite tunable lasers, which may find wide applications in
compact and low-cost optical multiplexers, sensors, memories, and LIDARs.",http://arxiv.org/abs/2107.05239v1
"A Thermodynamically-Consistent Phase Field Crystal Model of
  Solidification with Heat Flux",2021-07-12T16:26:26Z,"C. Wang, S. M. Wise","In this paper we describe a new model for solidification with heat flux using
the phase field crystal (PFC) framework. The equations are thermodynamically
consistent, in the sense that the time rate of change of the entropy density is
positive in the bulk and at the boundaries of the domain of interest. The
resulting model consists of two equations, a heat-like equation and a
mass-conservation equation that describes how the atom density changes in time
and space. The model is simple, yet it can properly capture the variation in
the free energy landscape as the temperature is changed. We describe to
construct a temperature-atom-density phase diagram using this energy landscape,
and we give a simple demonstration of solidification using the model.",http://arxiv.org/abs/2107.05555v1
Exploring the change of semiconductor hole mass under Coulomb scattering,2021-07-13T05:21:37Z,"Shiue-Yuan Shiau, Monique Combescot","Semiconductor valence holes are known to have heavy and light effective
masses; but the consequence of this mass difference on Coulomb scatterings has
been considered intractable and thus ignored up to now. The reason is that the
heavy/light index is quantized along the hole momentum that changes in a
Coulomb scattering; so, a heavy hole can turn light, depending on the
scattering angle. This mass change has never been taken into account in
many-body problems, and a single ``average'' hole mass has been used instead.
In order to study the missed consequences of this crude approximation, the
first necessary step is to determine the Coulomb scatterings with valence holes
in a precise way. We here derive these scatterings from scratch, starting from
the threefold valence-electron spatial level, all the way through the
spin-orbit splitting, the Kohn-Luttinger effective Hamiltonian, its spherical
approximation, and the phase factors that appear when turning from valence
electron to hole operators, that is, all the points of semiconductor physics
that render valence holes so different from a na\""{i}ve positive charge.",http://arxiv.org/abs/2107.05854v1
Spatiotemporal refraction of light in an epsilon-near-zero ITO layer,2021-07-13T10:35:03Z,"Justus Bohn, Ting Shan Luk, Euan Hendry","When light travels through a medium in which the refractive index is rapidly
changing with time, the light will undergo a shift in its frequency. Large
frequency shifting effects have recently been reported for transparent
conductive oxides. These observations have been interpreted as emerging from
temporal changes to the propagation phase in a bulk medium resulting from
temporal variations in the refractive index, an effect referred to as temporal
refraction. Here, we show that the frequency shift in an epsilon-near-zero
(ENZ) layer made of indium tin oxide (ITO) originates not only from this bulk
response, but includes a significant effect resulting from temporal changes to
the spatial boundary conditions. This boundary effect can lead to a dominant
opposing shift to the bulk effect for certain angles. Hence, this process gives
rise to a frequency shift that can be tailored through the angle of incidence,
decoupling the amplitude and phase modulation.",http://arxiv.org/abs/2107.05970v1
Dynamical vortices in electron-phonon superconductors,2021-07-16T17:00:05Z,"Morten H. Christensen, Andrey V. Chubukov","We analyze the structure of an $s-$wave superconducting gap in systems with
electron-phonon attraction and electron-electron repulsion. Earlier works have
found that superconductivity develops despite strong repulsion, but the gap,
$\Delta (\omega_m)$, necessarily changes sign along the Matsubara axis. We
analyze the sign-changing gap function from a topological perspective using the
knowledge that a nodal point of $\Delta (\omega_m)$ is the center of dynamical
vortex. We consider two models with different cutoffs for the repulsive
interaction and trace the vortex positions along the Matsubara axis and in the
upper frequency half plane upon changing the relative strength of the
attractive and repulsive parts of the interaction. We discuss how the presence
of dynamical vortices affects the gap structure along the real axis, detectable
in ARPES experiments.",http://arxiv.org/abs/2107.08012v1
"A Review of Some Techniques for Inclusion of Domain-Knowledge into Deep
  Neural Networks",2021-07-21T18:18:02Z,"Tirtharaj Dash, Sharad Chitlangia, Aditya Ahuja, Ashwin Srinivasan","We present a survey of ways in which existing scientific knowledge are
included when constructing models with neural networks. The inclusion of
domain-knowledge is of special interest not just to constructing scientific
assistants, but also, many other areas that involve understanding data using
human-machine collaboration. In many such instances, machine-based model
construction may benefit significantly from being provided with human-knowledge
of the domain encoded in a sufficiently precise form. This paper examines the
inclusion of domain-knowledge by means of changes to: the input, the
loss-function, and the architecture of deep networks. The categorisation is for
ease of exposition: in practice we expect a combination of such changes will be
employed. In each category, we describe techniques that have been shown to
yield significant changes in the performance of deep neural networks.",http://arxiv.org/abs/2107.10295v4
"Evaluation of In-Person Counseling Strategies To Develop Physical
  Activity Chatbot for Women",2021-07-22T00:39:21Z,"Kai-Hui Liang, Patrick Lange, Yoo Jung Oh, Jingwen Zhang, Yoshimi Fukuoka, Zhou Yu","Artificial intelligence chatbots are the vanguard in technology-based
intervention to change people's behavior. To develop intervention chatbots, the
first step is to understand natural language conversation strategies in human
conversation. This work introduces an intervention conversation dataset
collected from a real-world physical activity intervention program for women.
We designed comprehensive annotation schemes in four dimensions (domain,
strategy, social exchange, and task-focused exchange) and annotated a subset of
dialogs. We built a strategy classifier with context information to detect
strategies from both trainers and participants based on the annotation. To
understand how human intervention induces effective behavior changes, we
analyzed the relationships between the intervention strategies and the
participants' changes in the barrier and social support for physical activity.
We also analyzed how participant's baseline weight correlates to the amount of
occurrence of the corresponding strategy. This work lays the foundation for
developing a personalized physical activity intervention bot. The dataset and
code are available at
https://github.com/KaihuiLiang/physical-activity-counseling",http://arxiv.org/abs/2107.10410v1
"On the Stability Regions of Coded Poisson Receivers with Multiple
  Classes of Users and Receivers",2021-07-22T14:06:17Z,"Chia-Ming Chang, Yi-Jheng Lin, Cheng-Shang~Chang, Duan-Shin Lee","Motivated by the need to provide differentiated quality-of-service (QoS) in
grant-free uplink transmissions in 5G networks and beyond, we extend the
probabilistic analysis of coded Poisson receivers (CPR) to the setting with
multiple classes of users and receivers. For such a CPR system, we prove (under
certain technical conditions) that there is a region, called the stability
region in this paper. Each transmitted packet can be successfully received with
probability 1 when the offered load to the system is within the stability
region. On the other hand, if the offered load is outside the stability region,
there is a nonzero probability that a packet will fail to be received. We then
extend the stability region to the $\epsilon$-stability region for CPR systems
with decoding errors. We also demonstrate the capability of providing
differentiated QoS in such CPR systems by comparing the stability regions under
various parameter settings.",http://arxiv.org/abs/2107.10696v1
Error Floor Analysis of LDPC Column Layered Decoders,2021-07-23T22:59:05Z,"Ali Farsiabi, Amir H. Banihashemi","In this paper, we analyze the error floor of column layered decoders, also
known as shuffled decoders, for low-density parity-check (LDPC) codes under
saturating sum-product algorithm (SPA). To estimate the error floor, we
evaluate the failure rate of different trapping sets (TSs) that contribute to
the frame error rate in the error floor region. For each such TS, we model the
dynamics of SPA in the vicinity of the TS by a linear state-space model that
incorporates the information of the layered message-passing schedule.
Consequently, the model parameters and the failure rate of the TS change as a
result of the change in the order by which the messages of different layers are
updated. This, in turn, causes the error floor of the code to change as a
function of scheduling. Based on the proposed analysis, we then devise an
efficient search algorithm to find a schedule that minimizes the error floor.
Simulation results are presented to verify the accuracy of the proposed error
floor estimation technique.",http://arxiv.org/abs/2107.11479v1
"Solar models and McKean's breakdown theorem for the $μ$CH and $μ$DP
  equations",2021-07-26T00:45:14Z,Stephen C. Preston,"We study the breakdown for $\mu$CH and $\mu$DP equations on the circle, given
by $$m_t + u m_{\theta} + \lambda u_{\theta} m = 0,$$ for $m = \mu(u) -
u_{\theta\theta}$, where $\mu$ is the mean and $\lambda=2$ or $\lambda=3$
respectively. It is already known that if the initial momentum $m_0$ never
changes sign, then smooth solutions exist globally. We prove the converse: if
the initial momentum changes sign, then $C^2$ solutions $u$ must break down in
finite time. The technique is similar to that of McKean, who proved the same
for the Camassa-Holm equation, but we introduce a new perspective involving a
change of variables to treat the equation as a family of planar systems with
central force for which the conserved angular momentum is precisely the
conserved vorticity. We also demonstrate how this perspective can apply to give
some insights for other PDEs of continuum mechanics, such as the
Okamoto-Sakajo-Wunsch equation (and in particular the De Gregorio equation).",http://arxiv.org/abs/2107.11917v2
"Design Guidelines to Increase the Persuasiveness of Achievement Goals
  for Physical Activity",2021-07-27T04:56:52Z,"Maximilian Altmeyer, Pascal Lessel, Atiq Ur Rehman Waqar, Antonio Krüger","Achievement goals are frequently used to support behavior change. However,
they are often not specifically designed for this purpose nor account for the
degree to which a user is already intending to perform the target behavior. In
this paper, we investigate the perceived persuasiveness of different goal types
as defined by the 3x2 Achievement Goal Model, what people like and dislike
about them and the role that behavior change intentions play when aiming at
increasing step counts. We created visualizations for each goal type based on a
qualitative pre-study (N=18) and ensured their comprehensibility (N=18). In an
online experiment (N=118), we show that there are differences in the perception
of these goal types and that behavior change intentions should be considered to
maximize their persuasiveness as goals evolve. Next, we derive design
guidelines on when to use which type of achievement goal and what to consider
when using them",http://arxiv.org/abs/2107.12599v1
"Foldy-Wouthuysen transformation for gapped Dirac fermions in
  two-dimensional semiconducting materials and valley excitons under external
  fields",2021-07-30T07:57:30Z,"Yao-Wen Chang, Yia-Chung Chang","In this work, we provide a detailed derivation of Foldy-Wouthuysen (FW)
transformation for two-dimensional (2D) gapped Dirac fermions under external
fields and apply the formalism to study valley excitons in 2D semiconducting
materials. Similar to relativistic quantum few-body problem, the gapped Dirac
equation can be transformed into a Schr\""{o}dinger equation with ""relativistic""
correction terms. In this 2D materials system, the correction terms can be
interpreted as the Berry-curvature effect. The Hamiltonian for a valley exciton
in external fields can be written based on the FW transformed Dirac
Hamiltonian. Various valley-dependent effects on excitons, such as
fine-structure splittings of exciton energy levels, valley-selected exciton
transitions, and exciton valley Zeeman effect are discussed within this
framework.",http://arxiv.org/abs/2107.14474v1
"Dressed behavior of the quasiparticles lifetime in the unitary limit of
  two unconventional superconductors",2021-09-06T12:38:25Z,"P. Contreras, Dianela Osorio, E. Yu. Beliayev","We compare the quasiparticle lifetime behavior in the unitary limit of two
unconventional superconductors dressed by non-magnetic impurity scattering to
differentiate an anomalous functional behavior in its shape when the disorder
concentration is changed in a triplet paired model with respect to the well
behave singlet model. For singlet paired superconductors, the functional shape
of the lifetime due to elastic scattering around the nodal regions does not
change with the change of the disorder concentration, but for a triplet model
with a tiny gap, an anomalous drop in shape is observed only when small values
of disordering are added. We use a 2D tight-binding parametrization to study
the reduced phase space of the first Brillouin zone, where the low energy
scattering is restricted to the nodal/quasinodal regions for two irreducible
representations of the crystal lattice.",http://arxiv.org/abs/2109.02407v2
"Development of transverse flow at small and large opacities in conformal
  kinetic theory",2021-09-07T19:00:14Z,"Victor E. Ambrus, S. Schlichting, C. Werthmann","We employ an effective kinetic description, based on the Boltzmann equation
in the relaxation time approximation, to study the space-time dynamics and
development of transverse flow of small and large collision systems. By
combining analytical insights in the small opacity limit with numerical
simulations at larger opacities, we are able to describe the development of
transverse flow from very small to very large opacities. Suprisingly, we find
that deviations between kinetic theory and hydrodynamics persist even in the
limit of very large opacities, which can be attributed to the presence of the
early pre-equilibrium phase.",http://arxiv.org/abs/2109.03290v3
"Rates of convergence to non-degenerate asymptotic profiles for fast
  diffusion via energy methods",2021-09-08T22:54:02Z,Goro Akagi,"This paper is concerned with a quantitative analysis of asymptotic behaviors
of (possibly sign-changing) solutions to the Cauchy-Dirichlet problem for the
fast diffusion equation posed on bounded domains with Sobolev subcritical
exponents. More precisely, rates of convergence to non-degenerate asymptotic
profiles will be revealed via an energy method. The sharp rate of convergence
to \emph{positive} ones was recently discussed by Bonforte and Figalli (2021,
CPAM) based on an entropy method. An alternative proof for their result will
also be provided. Furthermore, dynamics of fast diffusion flows with changing
signs will be discussed more specifically under concrete settings; in
particular, exponential stability of some sign-changing asymptotic profiles
will be proved in dumbbell domains for initial data with certain symmetry.",http://arxiv.org/abs/2109.03960v2
"How Does Fine-tuning Affect the Geometry of Embedding Space: A Case
  Study on Isotropy",2021-09-10T08:58:59Z,"Sara Rajaee, Mohammad Taher Pilehvar","It is widely accepted that fine-tuning pre-trained language models usually
brings about performance improvements in downstream tasks. However, there are
limited studies on the reasons behind this effectiveness, particularly from the
viewpoint of structural changes in the embedding space. Trying to fill this
gap, in this paper, we analyze the extent to which the isotropy of the
embedding space changes after fine-tuning. We demonstrate that, even though
isotropy is a desirable geometrical property, fine-tuning does not necessarily
result in isotropy enhancements. Moreover, local structures in pre-trained
contextual word representations (CWRs), such as those encoding token types or
frequency, undergo a massive change during fine-tuning. Our experiments show
dramatic growth in the number of elongated directions in the embedding space,
which, in contrast to pre-trained CWRs, carry the essential linguistic
knowledge in the fine-tuned embedding space, making existing isotropy
enhancement methods ineffective.",http://arxiv.org/abs/2109.04740v1
"Quantum phases transition revealed by the exceptional point in
  Hopfield-Bogoliubov matrix",2021-09-14T09:53:20Z,"Dong Xie, Chunling Xu, An Min Wang","We use the exceptional point in Hopfield-Bogoliubov matrix to find the phase
transition points in the bosonic system. In many previous jobs, the excitation
energy vanished at the critical point. It can be stated equivalently that
quantum critical point is obtained when the determinant of Hopfield-Bogoliubov
matrix vanishes. We analytically obtain the Hopfield-Bogoliubov matrix
corresponding to the general quadratic Hamiltonian. For single-mode system the
appearance of the exceptional point in Hopfield-Bogoliubov matrix is equivalent
to the disappearance of the determinant of Hopfield-Bogoliubov matrix. However,
in multi-mode bosonic system, they are not equivalent except in some special
cases. For example, in the case of perfect symmetry, that is, swapping any two
subsystems and keeping the total Hamiltonian invariable, the exceptional point
and the degenerate point coincide all the time when the phase transition
occurs. When the exceptional point and the degenerate point do not coincide, we
find a significant result. With the increase of two-photon driving intensity,
the normal phase changes to the superradiant phase, then the superradiant phase
changes to the normal phase, and finally the normal phase changes to the
superradiant phase.",http://arxiv.org/abs/2109.06553v1
Behavior of k-NN as an Instance-Based Explanation Method,2021-09-14T22:32:19Z,"Chhavi Yadav, Kamalika Chaudhuri","Adoption of DL models in critical areas has led to an escalating demand for
sound explanation methods. Instance-based explanation methods are a popular
type that return selective instances from the training set to explain the
predictions for a test sample. One way to connect these explanations with
prediction is to ask the following counterfactual question - how does the loss
and prediction for a test sample change when explanations are removed from the
training set? Our paper answers this question for k-NNs which are natural
contenders for an instance-based explanation method. We first demonstrate
empirically that the representation space induced by last layer of a neural
network is the best to perform k-NN in. Using this layer, we conduct our
experiments and compare them to influence functions (IFs)
~\cite{koh2017understanding} which try to answer a similar question. Our
evaluations do indicate change in loss and predictions when explanations are
removed but we do not find a trend between $k$ and loss or prediction change.
We find significant stability in the predictions and loss of MNIST vs.
CIFAR-10. Surprisingly, we do not observe much difference in the behavior of
k-NNs vs. IFs on this question. We attribute this to training set subsampling
for IFs.",http://arxiv.org/abs/2109.06999v1
Site-Selective Dynamics of Ligand-Free and Ligand-Bound Azidolysozyme,2021-09-20T08:13:28Z,"Seyedeh Maryam Salehi, Markus Meuwly","Azido-modified alanine residues (AlaN$_3$) are environment-sensitive,
minimally invasive infrared probes for the site-specific investigation of
protein structure and dynamics. Here, the capability of the label is
investigated to query whether or not a ligand is bound to the active site of
Lysozyme and how the spectroscopy and dynamics change upon ligand binding. The
results demonstrate specific differences for center frequencies of the
asymmetric azide stretch vibration, the long time decay and the static offset
of the frequency fluctuation correlation function - all of which are
experimental observables - between the ligand-free and the ligand-bound,
N$_3$-labelled protein. Changes in dynamics can also be mapped onto changes in
the local and through-space coupling between residues by virtue of dynamical
cross-correlation maps. This makes the azide label a versatile and structurally
sensitive probe to report on the dynamics of proteins in a variety of
environments and for a range of different applications.",http://arxiv.org/abs/2109.09356v1
"A Wavelet Method for Panel Models with Jump Discontinuities in the
  Parameters",2021-09-22T18:14:21Z,"Oualid Bada, Alois Kneip, Dominik Liebl, Tim Mensinger, James Gualtieri, Robin C. Sickles","While a substantial literature on structural break change point analysis
exists for univariate time series, research on large panel data models has not
been as extensive. In this paper, a novel method for estimating panel models
with multiple structural changes is proposed. The breaks are allowed to occur
at unknown points in time and may affect the multivariate slope parameters
individually. Our method adapts Haar wavelets to the structure of the observed
variables in order to detect the change points of the parameters consistently.
We also develop methods to address endogenous regressors within our modeling
framework. The asymptotic property of our estimator is established. In our
application, we examine the impact of algorithmic trading on standard measures
of market quality such as liquidity and volatility over a time period that
covers the financial meltdown that began in 2007. We are able to detect jumps
in regression slope parameters automatically without using ad-hoc subsample
selection criteria.",http://arxiv.org/abs/2109.10950v1
"Using the Carnot cycle to determine changes of the phase transition
  temperature",2021-09-22T20:38:50Z,"Oskar Grocholski, Kornel Howil, Stanisław Rakowski, Piotr Maksymiuk","The Clausius-Clapeyron relation and its analogs in other first-order phase
transitions, such as type-I superconductors, are derived using very elementary
methods, without appealing to the more advanced concepts of entropy or Gibbs
free energy. The reasoning is based on Kelvin's formulation of the second law
of thermodynamics, and should be accessible to high school students. After
recalling some basic facts about the Carnot cycle, we present two very
different systems that undergo discontinuous phase transitions (ice/water and
normal/superconductor), and construct engines that exploit the properties of
these systems to produce work. In each case, we show that if the transition
temperature $T_tr$ were independent of other parameters, such as pressure or
magnetic field, it would be possible to violate Kelvin's principle, i.e., to
construct a perpetuum mobile of the second kind. Since the proposed cyclic
processes can be realized reversibly in the limit of infinitesimal changes in
temperature, their efficiencies must be equal to that of an ordinary Carnot
cycle. We immediately obtain an equation of the form $dT /dX = f(T, X)$, which
governs how the transition temperature changes with the parameter $X$.",http://arxiv.org/abs/2109.11031v1
First passage time and change of entropy,2021-09-24T09:11:59Z,V. V. Ryazanov,"The first-passage time is proposed as an independent thermodynamic parameter
of the statistical distribution that generalizes the Gibbs distribution. The
theory does not include the determination of the first passage statistics
itself. A random process is set that describes a physical phenomenon. The first
passage statistics is determined from this random process. The thermodynamic
parameter conjugated to the first-passage time is the same as the Laplace
transform parameter of the first-passage time distribution in the partition
function. The corresponding partition function is divided into multipliers, one
of which is associated with the equilibrium parameters, and the second one -
with the parameters of the first-passage time distribution. The thermodynamic
parameter conjugated to the first-passage time can be expressed in terms of the
deviation of the entropy from the equilibrium value. Thus, all moments of the
distribution of the first passage time are expressed in terms of the deviation
of the entropy from its equilibrium value and the external forces acting on the
system. By changing the thermodynamic forces, it is possible to change the
first passage time.",http://arxiv.org/abs/2109.11823v2
Magnetostriction and magnetostructural domains in CoTiO$_3$,2021-09-24T12:34:01Z,"K. Dey, M. Hoffmann, R. Klingeler","We report the magnetostrictive length changes of CoTiO$_3$ studied by means
of high-resolution dilatometry in magnetic fields ($B$) up to 15~T. In the
long-range antiferromagnetically ordered phase below $T_N$ = 38~K, the
easy-plane type spin structure undergoes a spin-reorientation transition in the
$ab$ plane in magnetic fields $B || ab \approx 2$~T. We observe pronounced
length changes driven by external magnetic field in this field region
indicating significant magnetoelastic coupling in CoTiO$_3$. Specifically, we
observe anisotropic deformation of the lattice for fields applied in the $ab$
plane. While, for $B \lesssim 2$~T, in-plane magnetostriction shows that the
lattice expands (contracts) parallel (perpendicular) to the field direction,
the opposite behaviour appear at higher fields. Furthermore, there are
remarkable effects of slight changes in the applied uniaxial pressure on the
magnetostrictive response of CoTiO$_3$ persisting to temperatures well above
$T_N$. The data evidence the presence of magnetic domains below $T_N$ as well
as of structural ones in CoTiO$_3$. The presence of magnetic domains in the
spin ordered phase is further evidenced by an additional 3-fold magnetic
anisotropy appearing below $T_N$. We discuss the effects of rotational magnetic
domains on isothermal magnetization and magnetostriction and interpret our
results on the basis of a multi-domain phenomenological model.",http://arxiv.org/abs/2109.11923v1
GV and GW invariants via the enhanced movable cone,2021-09-27T18:23:35Z,"Navid Nabijou, Michael Wemyss","Given any smooth germ of a threefold flopping contraction, we first give a
combinatorial characterisation of which Gopakumar-Vafa (GV) invariants are
non-zero, by prescribing multiplicities to the walls in the movable cone. On
the Gromov-Witten (GW) side, this allows us to describe, and even draw, the
critical locus of the associated quantum potential. We prove that the critical
locus is the infinite hyperplane arrangement of Iyama and the second author,
and moreover that the quantum potential can be reconstructed from a finite
fundamental domain. We then iterate, obtaining a combinatorial description of
the matrix which controls the transformation of the non-zero GV invariants
under a flop. There are three main ingredients and applications: (1) a
construction of flops from simultaneous resolution via cosets, which describes
how the dual graph changes, (2) a closed formula which describes the change in
dimension of the contraction algebra under flop, and (3) a direct and explicit
isomorphism between quantum cohomologies of different crepant resolutions,
giving a Coxeter-style, visual proof of the Crepant Transformation Conjecture
for isolated cDV singularities.",http://arxiv.org/abs/2109.13289v2
"Cooperation Method of Connected and Automated Vehicles at Unsignalized
  Intersections: Lane Changing and Arrival Scheduling",2021-09-29T03:39:52Z,"Chaoyi Chen, Mengchi Cai, Jiawei Wang, Kai Li, Qing Xu, Jianqiang Wang, Keqiang Li","The cooperation of connected and automated vehicles (CAVs) has shown great
potential in improving traffic efficiency during intersection management.
Existing research mainly focuses on intersections where lane changing is
prohibited, which is impractical for real-life implementation. This paper
proposes a two-stage cooperation framework, which decouples the longitudinal
and lateral control of CAVs, allowing them to change to their preferred lanes.
Based on formation control, an iterative framework is initially proposed to
solve the target assignment and path planning problem for multiple CAVs on
multiple lanes. A graph-based minimum clique cover method is then applied to
obtain the optimal scheduling plan for the CAVs. Extensive numerical
simulations for different numbers of vehicles and traffic volumes validate the
effectiveness of the proposed algorithm.",http://arxiv.org/abs/2109.14175v1
Density dependent local structures in InTe phase-change materials,2021-09-29T07:59:02Z,"Suyang Sun, Bo Zhang, Xudong Wang, Wei Zhang","Chalcogenide phase-change materials (PCMs) based random access memory (PCRAM)
is one of the leading candidates for the development of non-volatile memory and
neuro-inspired computing technologies. Recent work shows Indium to be an
important alloying element for PCRAM, while a thorough understanding of the
parent compound InTe, in particular, its amorphous phase, is still lacking. In
this work, we carry out ab initio simulations and chemical bonding analyses on
amorphous and various crystalline polymorphs of InTe. We reveal that the local
geometries are highly density dependent in amorphous structures, forming
In-centered tetrahedral motifs under ambient conditions but defective
octahedral motifs under pressure, which stems from the bonding characters of
its crystalline polymorphs. In addition, our ab initio molecular dynamics
simulations predict rapid crystallization capability of InTe under pressure. At
last, we make a suggestion for better use of Indium and propose an ""active""
device design to utilize both thermal and mechanical effects for phase-change
applications.",http://arxiv.org/abs/2109.14253v1
"A Fast Detection Method of Break Points in Effective Connectivity
  Networks",2021-09-30T00:14:16Z,"Peiliang Bai, Abolfazl Safikhani, George Michailidis","There is increasing interest in identifying changes in the underlying states
of brain networks. The availability of large scale neuroimaging data creates a
strong need to develop fast, scalable methods for detecting and localizing in
time such changes and also identify their drivers, thus enabling
neuroscientists to hypothesize about potential mechanisms. This paper presents
a fast method for detecting break points in exceedingly long time series
neuroimaging data, based on vector autoregressive (Granger causal) models. It
uses a multi-step strategy based on a regularized objective function that leads
to fast identification of candidate break points, followed by clustering steps
to select the final set of break points and subsequent estimation with false
positives control of the underlying Granger causal networks. The latter
provides insights into key changes in network connectivity that led to the
presence of break points. The proposed methodology is illustrated on synthetic
data varying in their length, dimensionality, number of break points, strength
of the signal, and also applied to EEG data related to visual tasks.",http://arxiv.org/abs/2109.14769v2
"Robust and efficient change point detection using novel multivariate
  rank-energy GoF test",2021-10-29T19:08:57Z,"Shoaib Bin Masud, Shuchin Aeron","In this paper, we use and further develop upon a recently proposed
multivariate, distribution-free Goodness-of-Fit (GoF) test based on the theory
of Optimal Transport (OT) called the Rank Energy (RE) [1], for non-parametric
and unsupervised Change Point Detection (CPD) in multivariate time series data.
We show that directly using RE leads to high sensitivity to very small changes
in distributions (causing high false alarms) and it requires large sample
complexity and huge computational cost. To alleviate these drawbacks, we
propose a new GoF test statistic called as soft-Rank Energy (sRE) that is based
on entropy regularized OT and employ it towards CPD. We discuss the advantages
of using sRE over RE and demonstrate that the proposed sRE based CPD
outperforms all the existing methods in terms of Area Under the Curve (AUC) and
F1-score on real and synthetic data sets.",http://arxiv.org/abs/2111.00047v1
On Quantitative Evaluations of Counterfactuals,2021-10-30T05:00:36Z,"Frederik Hvilshøj, Alexandros Iosifidis, Ira Assent","As counterfactual examples become increasingly popular for explaining
decisions of deep learning models, it is essential to understand what
properties quantitative evaluation metrics do capture and equally important
what they do not capture. Currently, such understanding is lacking, potentially
slowing down scientific progress. In this paper, we consolidate the work on
evaluating visual counterfactual examples through an analysis and experiments.
We find that while most metrics behave as intended for sufficiently simple
datasets, some fail to tell the difference between good and bad counterfactuals
when the complexity increases. We observe experimentally that metrics give good
scores to tiny adversarial-like changes, wrongly identifying such changes as
superior counterfactual examples. To mitigate this issue, we propose two new
metrics, the Label Variation Score and the Oracle score, which are both less
vulnerable to such tiny changes. We conclude that a proper quantitative
evaluation of visual counterfactual examples should combine metrics to ensure
that all aspects of good counterfactuals are quantified.",http://arxiv.org/abs/2111.00177v1
"Correlation-Enabled Energy Exchange in Quantum Systems without External
  Driving",2021-10-30T17:50:20Z,"T. Pyhäranta, S. Alipour, A. T. Rezakhani, T. Ala-Nissila","We study the role of correlation in mechanisms of energy exchange between an
interacting bipartite quantum system and its environment by decomposing the
energy of the system to local and correlation-related contributions. When the
system Hamiltonian is time-independent, no external work is performed. In this
case, energy exchange between the system and its environment occurs only due to
the change in the state of the system. We investigate possibility of a special
case where the energy exchange with the environment occurs exclusively due to
changes in the correlation between the constituent parts of the bipartite
system, while their local energies remain constant. We find sufficient
conditions for preserving local energies. It is proven that under these
conditions and within the Gorini-Kossakowski-Lindblad-Sudarshan (GKLS) dynamics
this scenario is not possible for all initial states of the bipartite system.
Nevertheless, it is still possible to find special initial states for which the
local energies remain unchanged during the associated evolution and the whole
energy exchange is only due to the change in the correlation energy. We
illustrate our results with an example.",http://arxiv.org/abs/2111.00296v1
"Dehumanizing Voice Technology: Phonetic & Experiential Consequences of
  Restricted Human-Machine Interaction",2021-11-02T22:49:25Z,"Christian Hildebrand, Donna Hoffman, Tom Novak","The use of natural language and voice-based interfaces gradu-ally transforms
how consumers search, shop, and express their preferences. The current work
explores how changes in the syntactical structure of the interaction with
conversational interfaces (command vs. request based expression modalities)
negatively affects consumers' subjective task enjoyment and systematically
alters objective vocal features in the human voice. We show that requests (vs.
commands) lead to an in-crease in phonetic convergence and lower phonetic
latency, and ultimately a more natural task experience for consumers. To the
best of our knowledge, this is the first work docu-menting that altering the
input modality of how consumers interact with smart objects systematically
affects consumers' IoT experience. We provide evidence that altering the
required input to initiate a conversation with smart objects provokes
systematic changes both in terms of consumers' subjective experience and
objective phonetic changes in the human voice. The current research also makes
a methodological con-tribution by highlighting the unexplored potential of
feature extraction in human voice as a novel data format linking consumers'
vocal features during speech formation and their sub-jective task experiences.",http://arxiv.org/abs/2111.01934v1
Unsupervised Change Detection of Extreme Events Using ML On-Board,2021-11-04T16:45:15Z,"Vít Růžička, Anna Vaughan, Daniele De Martini, James Fulton, Valentina Salvatelli, Chris Bridges, Gonzalo Mateo-Garcia, Valentina Zantedeschi","In this paper, we introduce RaVAEn, a lightweight, unsupervised approach for
change detection in satellite data based on Variational Auto-Encoders (VAEs)
with the specific purpose of on-board deployment. Applications such as disaster
management enormously benefit from the rapid availability of satellite
observations. Traditionally, data analysis is performed on the ground after all
data is transferred - downlinked - to a ground station. Constraint on the
downlink capabilities therefore affects any downstream application. In
contrast, RaVAEn pre-processes the sampled data directly on the satellite and
flags changed areas to prioritise for downlink, shortening the response time.
We verified the efficacy of our system on a dataset composed of time series of
catastrophic events - which we plan to release alongside this publication -
demonstrating that RaVAEn outperforms pixel-wise baselines. Finally we tested
our approach on resource-limited hardware for assessing computational and
memory limitations.",http://arxiv.org/abs/2111.02995v1
"Creating A Coefficient of Change in the Built Environment After a
  Natural Disaster",2021-10-31T20:46:31Z,Karla Saldana Ochoa,"This study proposes a novel method to assess damages in the built environment
using a deep learning workflow to quantify it. Thanks to an automated crawler,
aerial images from before and after a natural disaster of 50 epicenters
worldwide were obtained from Google Earth, generating a 10,000 aerial image
database with a spatial resolution of 2 m per pixel. The study utilizes the
algorithm Seg-Net to perform semantic segmentation of the built environment
from the satellite images in both instances (prior and post-natural disasters).
For image segmentation, Seg-Net is one of the most popular and general CNN
architectures. The Seg-Net algorithm used reached an accuracy of 92% in the
segmentation. After the segmentation, we compared the disparity between both
cases represented as a percentage of change. Such coefficient of change
represents the damage numerically an urban environment had to quantify the
overall damage in the built environment. Such an index can give the government
an estimate of the number of affected households and perhaps the extent of
housing damage.",http://arxiv.org/abs/2111.04462v2
"A Computational Approach to Walt Whitman's Stylistic Changes in Leaves
  of Grass",2021-11-09T20:53:25Z,Jieyan Zhu,"This study analyzes Walt Whitman's stylistic changes in his phenomenal work
Leaves of Grass from a computational perspective and relates findings to
standard literary criticism on Whitman. The corpus consists of all 7 editions
of Leaves of Grass, ranging from the earliest 1855 edition to the 1891-92
""deathbed"" edition. Starting from counting word frequencies, the simplest
stylometry technique, we find consistent shifts in word choice.
Macro-etymological analysis reveals Whitman's increasing preference for words
of specific origins, which is correlated to the increasing lexical complexity
in Leaves of Grass. Principal component analysis, an unsupervised learning
algorithm, reduces the dimensionality of tf-idf vectors to 2 dimensions,
providing a straightforward view of stylistic changes. Finally, sentiment
analysis shows the evolution of Whitman's emotional state throughout his
writing career.",http://arxiv.org/abs/2111.05414v1
"A paradigm shift, or a paradigm adjustment? The evolution of the
  Oleaceae mating system as a small-scale Kuhnian case-study",2021-11-16T12:38:25Z,"A. Francq, P. Saumitou-Laprade, P. Vernet, S. Billiard","Kuhn (1962) proposed an evolutionary model to explain how scientific
knowledge is built, based on the concept of paradigm. Even though Kuhn's model
is general, it has been applied only to a few topics in evolutionary biology,
especially broad-based paradigms. Our goal here is to analyze a small-scale
paradigm change that occurred about the mating system of a Mediterranean shrub:
P. angustifolia (Oleaceae) through the lens of Kuhn's model. We first summarize
the different steps of the paradigm change and replace them in the more general
context of the sex ratio theory. Second, we show how the different steps of the
paradigm changes can be interpreted by Kuhnian concepts and tools. Finally, we
discuss the actual and future status of the new paradigm.",http://arxiv.org/abs/2111.08417v3
"Population based change-point detection for the identification of
  homozygosity islands",2021-11-19T12:53:41Z,"Lucas Prates, Renan B Lemes, Tábita Hünemeier, Florencia Leonardi","In this paper, we propose a new method for offline change-point detection on
some parameters of the distribution of a random vector. We introduce a
penalized maximum likelihood approach that can be efficiently computed by a
dynamic programming algorithm or approximated by a fast greedy binary splitting
algorithm. We prove both algorithms converge almost surely to the set of
change-points under very general assumptions on the distribution and
independent sampling of the random vector. In particular, we show the
assumptions leading to the consistency of the algorithms are satisfied by
categorical and Gaussian random variables. This new approach is motivated by
the problem of identifying homozygosity islands on the genome of individuals in
a population. Our method directly tackles the issue of identification of the
homozygosity islands at the population level, without the need of analyzing
single individuals and then combining the results, as is made nowadays in
state-of-the-art approaches.",http://arxiv.org/abs/2111.10187v1
"Characterization of canonical systems with six types of coins for the
  change-making problem",2021-11-24T10:25:04Z,"Yuma Suzuki, Ryuhei Miyashiro","This paper analyzes a necessary and sufficient condition for the
change-making problem to be solvable with a greedy algorithm. The change-making
problem is to minimize the number of coins used to pay a given value in a
specified currency system. This problem is NP-hard, and therefore the greedy
algorithm does not always yield an optimal solution. Yet for almost all real
currency systems, the greedy algorithm outputs an optimal solution. A currency
system for which the greedy algorithm returns an optimal solution for any value
of payment is called a canonical system. Canonical systems with at most five
types of coins have been characterized in previous studies. In this paper, we
give characterization of canonical systems with six types of coins, and we
propose a partial generalization of characterization of canonical systems.",http://arxiv.org/abs/2111.12392v1
Intuitive Shape Editing in Latent Space,2021-11-24T13:33:10Z,"Tim Elsner, Moritz Ibing, Victor Czech, Julius Nehring-Wirxel, Leif Kobbelt","The use of autoencoders for shape editing or generation through latent space
manipulation suffers from unpredictable changes in the output shape. Our
autoencoder-based method enables intuitive shape editing in latent space by
disentangling latent sub-spaces into style variables and control points on the
surface that can be manipulated independently. The key idea is adding a
Lipschitz-type constraint to the loss function, i.e. bounding the change of the
output shape proportionally to the change in latent space, leading to
interpretable latent space representations. The control points on the surface
that are part of the latent code of an object can then be freely moved,
allowing for intuitive shape editing directly in latent space. We evaluate our
method by comparing to state-of-the-art data-driven shape editing methods. We
further demonstrate the expressiveness of our learned latent space by
leveraging it for unsupervised part segmentation.",http://arxiv.org/abs/2111.12488v3
"Acoustical Analysis of Speech Under Physical Stress in Relation to
  Physical Activities and Physical Literacy",2021-11-20T16:58:26Z,"Si-Ioi Ng, Rui-Si Ma, Tan Lee, Raymond Kim-Wai Sum","Human speech production encompasses physiological processes that naturally
react to physic stress. Stress caused by physical activity (PA), e.g., running,
may lead to significant changes in a person's speech. The major changes are
related to the aspects of pitch level, speaking rate, pause pattern, and
breathiness. The extent of change depends presumably on physical fitness and
well-being of the person, as well as intensity of PA. The general wellness of a
person is further related to his/her physical literacy (PL), which refers to a
holistic description of engagement in PA. This paper presents the development
of a Cantonese speech database that contains audio recordings of speech before
and after physical exercises of different intensity levels. The corpus design
and data collection process are described. Preliminary results of acoustical
analysis are presented to illustrate the impact of PA on pitch level, pitch
range, speaking and articulation rate, and time duration of pauses. It is also
noted that the effect of PA is correlated to some of the PA and PL measures.",http://arxiv.org/abs/2111.12566v2
"Time-resolved reversible optical switching of the ultralow-loss phase
  change material Sb2Se3",2021-11-25T17:28:55Z,"Daniel Lawson, Daniel W. Hewak, Otto L. Muskens, Ioannis Zeimpekis","The antimony-based chalcogenide Sb2Se3 is a rapidly emerging material for
photonic phase change applications owing to its ultra-low optical losses at
telecommunication wavelengths in both crystalline and amorphous phases. Here,
we investigate the dynamical response of these materials from nanoseconds to
milliseconds under optical pumping conditions. We apply bichromatic pump-probe
transient reflectance spectroscopy which is a widely used method to study the
optical performance of optical phase change materials. Amorphous regions of
several hundreds of nanometers in diameter are induced by pulsed excitation of
the material using a wavelength of 488 nm above the absorption edge, while the
transient reflectance is probed using a continuous wave 980 nm laser, well
below the absorption edge of the material. We find vitrification dynamics in
the nanosecond range and observe crystallization on millisecond time scales.
These results show a large five-orders of magnitude difference in time scales
between crystallization and vitrification dynamics in this material. The
insights provided in this work are fundamental for the optimisation of the
material family and its employment in photonic applications.",http://arxiv.org/abs/2111.13182v1
Distribution Shift in Airline Customer Behavior during COVID-19,2021-11-29T20:32:48Z,"Abhinav Garg, Naman Shukla, Lavanya Marla, Sriram Somanchi","Traditional AI approaches in customized (personalized) contextual pricing
applications assume that the data distribution at the time of online pricing is
similar to that observed during training. However, this assumption may be
violated in practice because of the dynamic nature of customer buying patterns,
particularly due to unanticipated system shocks such as COVID-19. We study the
changes in customer behavior for a major airline during the COVID-19 pandemic
by framing it as a covariate shift and concept drift detection problem. We
identify which customers changed their travel and purchase behavior and the
attributes affecting that change using (i) Fast Generalized Subset Scanning and
(ii) Causal Forests. In our experiments with simulated and real-world data, we
present how these two techniques can be used through qualitative analysis.",http://arxiv.org/abs/2111.14938v2
"Light Curves Analysis and Period Study of Two Eclipsing Binaries UZ Lyr
  and BR Cyg",2021-11-30T08:30:09Z,"K. Y. Roobiat, R. Pazhouhesh","Two eclipsing binary systems UZ Lyr and BR Cyg are the semi-detached types
whose secondary component fill its Roche lobe. Although radial velocity and
light curves of these systems have already been investigated separately, both
radial velocity and light curves of them are analyzed simultaneously for the
first time in the present study . Also, the orbital period changes of these
systems are studied. Our results show that the mass transfer between components
have negligible effects on the orbital period changes of these systems, but two
light-time effects are the reasons of the periodic behavior of the O-C curve
for UZ Lyr. We could not remark more information about orbital period changes
for BR Cyg, but we find a new orbital period for it. By radial velocity and
light curves analysis we find a clod spot on the secondary components of BR
Cyg. The new geometrical and physical parameters of both systems are obtained
and their positions on H-R diagram demonstrated.",http://arxiv.org/abs/2111.15203v1
A Quantum Informational Approach to the Problem of Time,2021-12-02T01:30:53Z,"Salman Sajad Wani, James Q. Quach, Mir Faizal, Sebastian Bahamonde, Behnam Pourhassan","Several novel approaches have been proposed to resolve the problem of time by
relating it to change. We argue using quantum information theory that the
Hamiltonian constraint in quantum gravity cannot probe change, so it cannot be
used to obtain a meaningful notion of time. This is due to the absence of
quantum Fisher information with respect to the quantum Hamiltonian of a
time-reparametization invariant system. We also observe that the inability of
this Hamiltonian to probe change can be related to its inability to
discriminate between states of such a system. However, if the
time-reparametization symmetry is spontaneously broken due to the formation of
quantum cosmological time crystals, these problems can be resolved, and it is
possible for time to emerge in quantum gravity.",http://arxiv.org/abs/2112.00918v1
"A higher order Minkowski loss for improved prediction ability of
  acoustic model in ASR",2021-12-02T07:20:08Z,"Vishwanath Pratap Singh, Shakti P. Rath, Abhishek Pandey","Conventional automatic speech recognition (ASR) system uses second-order
minkowski loss during inference time which is suboptimal as it incorporates
only first order statistics in posterior estimation [2]. In this paper we have
proposed higher order minkowski loss (4th Order and 6th Order) during inference
time, without any changes during training time. The main contribution of the
paper is to show that higher order loss uses higher order statistics in
posterior estimation, which improves the prediction ability of acoustic model
in ASR system. We have shown mathematically that posterior probability obtained
due to higher order loss is function of second order posterior and thus the
method can be incorporated in standard ASR system in an easy manner. It is to
be noted that all changes are proposed during test(inference) time, we do not
make any change in any training pipeline. Multiple baseline systems namely,
TDNN1, TDNN2, DNN and LSTM are developed to verify the improvement incurred due
to higher order minkowski loss. All experiments are conducted on LibriSpeech
dataset and performance metrics are word error rate (WER) on ""dev-clean"",
""test-clean"", ""dev-other"" and ""test-other"" datasets.",http://arxiv.org/abs/2112.01023v1
"Inertial range magnetic fluctuation anisotropy observed from PSP first
  seven orbits",2021-12-03T04:44:21Z,"L. -L. Zhao, G. P. Zank, L. Adhikari, M. Nakanotani","Solar wind turbulence is anisotropic with respect to the mean magnetic field.
Anisotropy leads to ambiguity when interpreting in-situ turbulence observations
in the solar wind because an apparent change in the measurements could be due
either to the change of intrinsic turbulence properties or to a simple change
of the spacecraft sampling direction. We demonstrate the ambiguity using the
spectral index and magnetic compressibility in the inertial range observed by
the Parker Solar Probe during its first seven orbits ranging from 0.1 to 0.6
AU. To unravel the effects of the sampling direction, we assess whether the
wavevector anisotropy is consistent with a two-dimensional (2D) plus slab
turbulence transport model and determine the fraction of power in the 2D versus
slab component. Our results confirm that the 2D plus slab model is consistent
with the data and the power ratio between 2D and slab components depends on
radial distance, with the relative power in 2D fluctuations becoming smaller
closer to the Sun.",http://arxiv.org/abs/2112.01711v1
Updating Barcodes and Representatives for Zigzag Persistence,2021-12-04T14:51:55Z,"Tamal K. Dey, Tao Hou","Computing persistence over changing filtrations give rise to a stack of 2D
persistence diagrams where the birth-death points are connected by the
so-called `vines'. We consider computing these vines over changing filtrations
for zigzag persistence. We observe that eight atomic operations are sufficient
for changing one zigzag filtration to another and provide update algorithms for
each of them. Six of these operations that have some analogues to one or
multiple transpositions in the non-zigzag case can be executed as efficiently
as their non-zigzag counterparts. This approach takes advantage of a recently
discovered algorithm for computing zigzag barcodes by converting a zigzag
filtration to a non-zigzag one and then connecting barcodes of the two with a
bijection. The remaining two atomic operations do not have a strict analogue in
the non-zigzag case. For them, we propose algorithms based on explicit
maintenance of representatives (homology cycles) which can be useful in their
own rights for applications requiring explicit updates of representatives.",http://arxiv.org/abs/2112.02352v2
The Price Impact of Generalized Order Flow Imbalance,2021-12-06T11:40:47Z,"Yuhan Su, Zeyu Sun, Jiarong Li, Xianghui Yuan","Order flow imbalance can explain short-term changes in stock price. This
paper considers the change of non-minimum quotation units in real transactions,
and proposes a generalized order flow imbalance construction method to improve
Order Flow Imbalance (OFI) and Stationarized Order Flow Imbalance (log-OFI).
Based on the high-frequency order book snapshot data, we conducted an empirical
analysis of the CSI 500 constituent stocks. In order to facilitate the
presentation, we selected 10 stocks for comparison. The two indicators after
the improvement of the generalized order flow imbalance construction method
both show a better ability to explain changes in stock prices. Especially
Generalized Stationarized Order Flow Imbalance (log-GOFI), using a linear
regression model, on the time scales of 30 seconds, 1 minute, and 5 minutes,
the average R-squared out of sample compared with Order Flow Imbalance (OFI)
32.89%, 38.13% and 42.57%, respectively increased to 83.57%, 85.37% and 86.01%.
In addition, we found that the interpretability of Generalized Stationarized
Order Flow Imbalance (log-GOFI) showed stronger stability on all three time
scales.",http://arxiv.org/abs/2112.02947v1
"Investigating the Impact of 9/11 on The Simpsons through Natural
  Language Processing",2021-12-02T03:45:10Z,Athena Xiourouppa,"The impact of real world events on fictional media is particularly apparent
in the American cartoon series The Simpsons. While there are often very direct
pop culture references evident in the dialogue and visual gags of the show,
subtle changes in tone or sentiment may not be so obvious. Our aim was to use
Natural Language Processing to attempt to search for changes in word frequency,
topic, and sentiment before and after the September 11 terrorist attacks in New
York. No clear trend change was seen, there was a slight decrease in the
average sentiment over time around the relevant period between 2000 and 2002,
but the scripts still maintained an overall positive value, indicating that the
comedic nature of The Simpsons did not wane particularly significantly. The
exploration of other social issues and even specific character statistics is
needed to bolster the findings here.",http://arxiv.org/abs/2112.03025v1
"Cadence: A Practical Time-series Partitioning Algorithm for Unlabeled
  IoT Sensor Streams",2021-12-06T21:13:18Z,"Tahiya Chowdhury, Murtadha Aldeer, Shantanu Laghate, Jorge Ortiz","Timeseries partitioning is an essential step in most machine-learning driven,
sensor-based IoT applications. This paper introduces a sample-efficient,
robust, time-series segmentation model and algorithm. We show that by learning
a representation specifically with the segmentation objective based on maximum
mean discrepancy (MMD), our algorithm can robustly detect time-series events
across different applications. Our loss function allows us to infer whether
consecutive sequences of samples are drawn from the same distribution (null
hypothesis) and determines the change-point between pairs that reject the null
hypothesis (i.e., come from different distributions). We demonstrate its
applicability in a real-world IoT deployment for ambient-sensing based activity
recognition. Moreover, while many works on change-point detection exist in the
literature, our model is significantly simpler and can be fully trained in 9-93
seconds on average with little variation in hyperparameters for data across
different applications. We empirically evaluate Cadence on four popular change
point detection (CPD) datasets where Cadence matches or outperforms existing
CPD techniques.",http://arxiv.org/abs/2112.03360v2
"Change Summarization of Diachronic Scholarly Paper Collections by
  Semantic Evolution Analysis",2021-12-07T11:15:19Z,"Naman Paharia, Muhammad Syafiq Mohd Pozi, Adam Jatowt","The amount of scholarly data has been increasing dramatically over the last
years. For newcomers to a particular science domain (e.g., IR, physics, NLP) it
is often difficult to spot larger trends and to position the latest research in
the context of prior scientific achievements and breakthroughs. Similarly,
researchers in the history of science are interested in tools that allow them
to analyze and visualize changes in particular scientific domains. Temporal
summarization and related methods should be then useful for making sense of
large volumes of scientific discourse data aggregated over time. We demonstrate
a novel approach to analyze the collections of research papers published over
longer time periods to provide a high-level overview of important semantic
changes that occurred over the progress of time. Our approach is based on
comparing word semantic representations over time and aims to support users in
a better understanding of large domain-focused archives of scholarly
publications. As an example dataset we use the ACL Anthology Reference Corpus
that spans from 1979 to 2015 and contains 22,878 scholarly articles.",http://arxiv.org/abs/2112.03634v1
"One for the Future: measuring the mass transfer rate in the ULX M82 X-2
  by using orbital period changes will take millenia",2021-12-07T15:50:11Z,"Andrew King, Jean-Pierre Lasota","Bachetti et al. (2021) have recently claimed to measure the mass transfer
rate in the pulsing ULX system M82 X-2 by following the change of its orbital
period over 7 yr. We reiterate the known point that this method cannot give a
reliable result (or even necessarily predict the correct sign of long-term
period change) without a far longer baseline (here $\gg 1000$~yr) or for
systems with a much higher long-term mass transfer rate ($\gg 10^{-4} \rm
M_{\odot}/{\rm yr}$), if they exist. Applying the method of Bachetti et al.
(2021) to measured orbital period derivatives predicts that the well-studied
quiescent X-ray transients XTEJ1118+480, A0620-00 should currently instead have
steady accretion discs and be bright X-ray sources, while Nova Muscae 1991
should be still brighter (a ULX). But all three sources are observed to be
extremely faint. We conclude that there is no evidence to support the high mass
transfer rate that Bachetti et al. (2021) find for M82 X-2 as it is deduced
from period noise not related to the binary evolution.",http://arxiv.org/abs/2112.03779v1
"Kinematic Modeling of Handed Shearing Auxetics via Piecewise Constant
  Curvature",2021-12-09T05:21:29Z,"Aman Garg, Ian Good, Daniel Revier, Kevin Airis, Jeffrey Lipton","Handed Shearing Auxetics (HSA) are a promising technique for making
motor-driven, soft, continuum robots. Many potential applications from
inspection tasks to solar tracking require accurate kinematic models to predict
the position and orientation of these structures. Currently there are no models
for HSA based continuum platforms. To address this gap we propose to adapt
Piecewise Constant Curvature (PCC) Models using a length change coupling
matrix. This models the interaction of HSA structures in a 2x2 array. The
coupling matrix maps the change in motor angles to length changes and defines
the configuration space in our modified PCC Model. We evaluate our model on a
composite movement encompassing bending, extension and compression behavior.
Our model achieves a positional accuracy with mean error of 5.5mm or 4.5% body
length and standard deviation of 1.72mm. Further, we achieve an angular
accuracy with mean error of -2.8$^\circ$ and standard deviation of 1.9$^\circ$.",http://arxiv.org/abs/2112.04706v1
Coupling between multiple antennas through a plasma cylinder,2021-12-10T06:16:46Z,"L. Chang, L. P. Zhang, X. G. Yuan, Y. J. Chang, J. H. Zhang, X. Yang, Y. Wang, H. S. Zhou, G. N. Luo","The coupling physics between multiple antennas separated axially along a
plasma cylinder is investigated. Experiments are carried out on a recently
built device: Physics ANd Thruster oriented HElicon Research (PANTHER), with an
upgrade of second-stage antennas. Mutual induction currents are measured in
detail. It is found that the existence of plasma column going through these
antennas increase the coupling effects among them significantly. Theoretical
analyses from the perspectives of transformer and magnetic permeability and
moment confirm the reasonability of this phenomenon. This work is of particular
interest for electrodeless plasma source or thruster which employs multiple
antennas for ionisation and acceleration.",http://arxiv.org/abs/2112.05352v1
"Seq-Masks: Bridging the gap between appearance and gait modeling for
  video-based person re-identification",2021-12-10T16:00:20Z,"Zhigang Chang, Zhao Yang, Yongbiao Chen, Qin Zhou, Shibao Zheng","ideo-based person re-identification (Re-ID) aims to match person images in
video sequences captured by disjoint surveillance cameras. Traditional
video-based person Re-ID methods focus on exploring appearance information,
thus, vulnerable against illumination changes, scene noises, camera parameters,
and especially clothes/carrying variations. Gait recognition provides an
implicit biometric solution to alleviate the above headache. Nonetheless, it
experiences severe performance degeneration as camera view varies. In an
attempt to address these problems, in this paper, we propose a framework that
utilizes the sequence masks (SeqMasks) in the video to integrate appearance
information and gait modeling in a close fashion. Specifically, to sufficiently
validate the effectiveness of our method, we build a novel dataset named
MaskMARS based on MARS. Comprehensive experiments on our proposed large wild
video Re-ID dataset MaskMARS evidenced our extraordinary performance and
generalization capability. Validations on the gait recognition metric CASIA-B
dataset further demonstrated the capability of our hybrid model.",http://arxiv.org/abs/2112.05626v1
"The rationality of Stark-Heegner cycles attached to Bianchi modular
  forms -- The base-change scenario",2021-12-14T13:54:15Z,Guhan Venkat,"We study Stark-Heegner cycles attached to Bianchi modular forms, that is
automorphic forms for GL(2) over an imaginary quadratic field F . The
Stark-Heegner cycles are local cohomology classes in the p-adic Galois
representation associated to the Bianchi eigenform. They are conjectured to be
the restriction (at a prime p) of global cohomology classes in the (semistable)
Bloch-Kato Selmer group defined over ring class fields of a relative quadratic
extension K/F. In this paper, we show that these conjectures hold when the
Bianchi eigenform is the base-change of a classical elliptic cuspform.",http://arxiv.org/abs/2112.07402v4
"Changes in polarization dictate necessary approximations for modeling
  electronic de-excitation intensity: an application to X-ray emission",2021-12-19T03:54:26Z,"Subhayan Roychoudhury, Leonardo A. Cunha, Martin Head-Gordon, David Prendergast","We systematically investigate the underlying relations among different levels
of approximation for simulating electronic de-excitations, with a focus on
modeling X-ray emission spectroscopy (XES). Using Fermi's golden rule and
explicit modeling of the initial, core-excited state and the final,
valence-hole state, we show that XES can be accurately modeled by using orbital
optimization for the various final states within a Slater-determinant
framework. However, in this paper, we introduce a much cheaper approach reliant
only on a single self-consistent field for all the final states, and show that
it is typically sufficient. Further approximations reveal that these
fundamentally many-body transitions can be reasonably approximated by
projections of ground state orbitals, but that the ground state alone is
insufficient. Furthermore, except in cases where the core-ionization induces
negligible changes in polarization, linear-response approaches within the
adiabatic approximation will have difficulty in accurately modeling
de-excitation to the core level. Therefore, change in the net dipole moment of
the valence electrons can serve as a metric for the validity of the
linear-response approximation.",http://arxiv.org/abs/2112.10054v1
"Looking Beyond Corners: Contrastive Learning of Visual Representations
  for Keypoint Detection and Description Extraction",2021-12-22T16:27:11Z,"Henrique Siqueira, Patrick Ruhkamp, Ibrahim Halfaoui, Markus Karmann, Onay Urfalioglu","Learnable keypoint detectors and descriptors are beginning to outperform
classical hand-crafted feature extraction methods. Recent studies on
self-supervised learning of visual representations have driven the increasing
performance of learnable models based on deep networks. By leveraging
traditional data augmentations and homography transformations, these networks
learn to detect corners under adverse conditions such as extreme illumination
changes. However, their generalization capabilities are limited to corner-like
features detected a priori by classical methods or synthetically generated
data.
  In this paper, we propose the Correspondence Network (CorrNet) that learns to
detect repeatable keypoints and to extract discriminative descriptions via
unsupervised contrastive learning under spatial constraints. Our experiments
show that CorrNet is not only able to detect low-level features such as
corners, but also high-level features that represent similar objects present in
a pair of input images through our proposed joint guided backpropagation of
their latent space. Our approach obtains competitive results under viewpoint
changes and achieves state-of-the-art performance under illumination changes.",http://arxiv.org/abs/2112.12002v2
"Control of site occupancy by variation of the Zn and Al content in
  NiZnAl ferrite epitaxial films with low magnetic damping",2021-12-23T10:53:33Z,"Julia Lumetzberger, Verena Ney, Anna Zhakarova, Daniel Primetzhofer, Kilian Lenz, Andreas Ney","The structural and magnetic properties of Zn/Al doped nickel ferrite thin
films can be adjusted by changing the Zn and Al content. The films are
epitaxially grown by reactive magnetron sputtering using a triple cluster
system to sputter simultaneously from three different targets. Upon the
variation of the Zn content the films remain fully strained with similar
structural properties, while the magnetic properties are strongly affected. The
saturation magnetization and coercivity as well as resonance position and
linewidth from ferromagnetic resonance (FMR) measurements are altered depending
on the Zn content in the material. The reason for these changes can be
elucidated by investigation of the x-ray magnetic circular dichroism spectra to
gain site and valence specific information with elemental specificity.
Additionally, from a detailed investigation by broadband FMR a minimum in
g-factor and linewidth could be found as a function of film thickness.
Furthermore, the results from a variation of the Al content using the same set
of measurement techniques is given. Other than for Zn, the variation of Al
affects the strain and even more pronounced changes to the magnetic properties
are apparent.",http://arxiv.org/abs/2112.12456v1
"Central exclusive diffractive production of two-pions from continuum and
  decays of resonances in the Regge-eikonal model",2021-12-25T19:27:10Z,R. A. Ryutin,"Calculations of central exclusive diffractive production (CEDP) of two pions
via continuum and resonance mechanism are presented in the Regge-eikonal
approach. Data from STAR, ISR, CDF and CMS were analysed and compared with
theoretical description. Preliminary extraction of $f_0(500)$, $f_0(980)$ and
$f_2(1270)$ couplings to Pomeron, and also $\rho$ meson contribution from
photoproduction mechanism to the CEDP cross-section are considered. We show
possible nuances and problems of calculations and prospects of investigations
at present and future hadron colliders.",http://arxiv.org/abs/2112.13274v3
"Abolitionist Networks: Modeling Language Change in Nineteenth-Century
  Activist Newspapers",2021-03-12T21:26:30Z,"Sandeep Soni, Lauren Klein, Jacob Eisenstein","The abolitionist movement of the nineteenth-century United States remains
among the most significant social and political movements in US history.
Abolitionist newspapers played a crucial role in spreading information and
shaping public opinion around a range of issues relating to the abolition of
slavery. These newspapers also serve as a primary source of information about
the movement for scholars today, resulting in powerful new accounts of the
movement and its leaders. This paper supplements recent qualitative work on the
role of women in abolition's vanguard, as well as the role of the Black press,
with a quantitative text modeling approach. Using diachronic word embeddings,
we identify which newspapers tended to lead lexical semantic innovations -- the
introduction of new usages of specific words -- and which newspapers tended to
follow. We then aggregate the evidence across hundreds of changes into a
weighted network with the newspapers as nodes; directed edge weights represent
the frequency with which each newspaper led the other in the adoption of a
lexical semantic change. Analysis of this network reveals pathways of lexical
semantic influence, distinguishing leaders from followers, as well as others
who stood apart from the semantic changes that swept through this period. More
specifically, we find that two newspapers edited by women -- THE PROVINCIAL
FREEMAN and THE LILY -- led a large number of semantic changes in our corpus,
lending additional credence to the argument that a multiracial coalition of
women led the abolitionist movement in terms of both thought and action. It
also contributes additional complexity to the scholarship that has sought to
tease apart the relation of the abolitionist movement to the women's suffrage
movement, and the vexed racial politics that characterized their relation.",http://arxiv.org/abs/2103.07538v1
"Orbital Evolution of Equal-mass Eccentric Binaries due to a Gas Disk:
  Eccentric Inspirals and Circular Outspirals",2021-03-16T18:00:17Z,"Daniel J. D'Orazio, Paul C. Duffell","We solve the equations of two-dimensional hydrodynamics describing a
circumbinary disk accreting onto an eccentric, equal-mass binary. We compute
the time rate of change of the binary semimajor axis $a$ and eccentricity $e$
over a continuous range of eccentricities spanning $e=0$ to $e=0.9$. We find
that binaries with initial eccentricities $e_0 \lesssim 0.1$ tend to $e=0$,
where the binary semimajor axis expands. All others are attracted to $e \approx
0.4$, where the binary semimajor axis decays. The $e \approx 0.4$ attractor is
caused by a rapid change in the disk response from a nearly origin-symmetric
state to a precessing asymmetric state. The state change causes the time rates
of change $\dot{a}$ and $\dot{e}$ to steeply change sign at the same critical
eccentricity resulting in an attracting solution where $\dot{a} = \dot{e} = 0$.
This does not, however, result in a stalled, eccentric binary. The
finite-transition time between disk states causes the binary eccentricity to
evolve beyond the attracting eccentricity in both directions resulting in
oscillating orbital parameters and a drift of the semimajor axis. For the
chosen disk parameters, binaries with $e_0 \gtrsim 0.1$ evolve toward and then
oscillate around $e \approx 0.4$ where they shrink in semimajor axis. Because
unequal mass binaries grow toward equal mass through preferential accretion,
our results are applicable to a wide range of initial binary mass ratios.
Hence, these findings merit further investigations of this disk transition;
understanding its dependence on disk parameters is vital for determining the
fate of binaries undergoing orbital evolution with a circumbinary disk.",http://arxiv.org/abs/2103.09251v2
"Temporal Cluster Matching for Change Detection of Structures from
  Satellite Imagery",2021-03-17T17:20:16Z,"Caleb Robinson, Anthony Ortiz, Juan M. Lavista Ferres, Brandon Anderson, Daniel E. Ho","Longitudinal studies are vital to understanding dynamic changes of the
planet, but labels (e.g., buildings, facilities, roads) are often available
only for a single point in time. We propose a general model, Temporal Cluster
Matching (TCM), for detecting building changes in time series of remotely
sensed imagery when footprint labels are observed only once. The intuition
behind the model is that the relationship between spectral values inside and
outside of building's footprint will change when a building is constructed (or
demolished). For instance, in rural settings, the pre-construction area may
look similar to the surrounding environment until the building is constructed.
Similarly, in urban settings, the pre-construction areas will look different
from the surrounding environment until construction. We further propose a
heuristic method for selecting the parameters of our model which allows it to
be applied in novel settings without requiring data labeling efforts (to fit
the parameters). We apply our model over a dataset of poultry barns from
2016/2017 high-resolution aerial imagery in the Delmarva Peninsula and a
dataset of solar farms from a 2020 mosaic of Sentinel 2 imagery in India. Our
results show that our model performs as well when fit using the proposed
heuristic as it does when fit with labeled data, and further, that supervised
versions of our model perform the best among all the baselines we test against.
Finally, we show that our proposed approach can act as an effective data
augmentation strategy -- it enables researchers to augment existing structure
footprint labels along the time dimension and thus use imagery from multiple
points in time to train deep learning models. We show that this improves the
spatial generalization of such models when evaluated on the same change
detection task.",http://arxiv.org/abs/2103.09787v2
Dipper-like variability of the Gaia alerted young star V555 Ori,2021-03-18T15:16:49Z,"Zsófia Nagy, Elza Szegedi-Elek, Péter Ábrahám, Ágnes Kóspál, Attila Bódi, Jérôme Bouvier, Mária Kun, Attila Moór, Borbála Cseh, Anikó Farkas-Takács, Ottó Hanyecz, Simon Hodgkin, Bernadett Ignácz, Csaba Kiss, Réka Könyves-Tóth, Levente Kriskovics, Gábor Marton, László Mészáros, András Ordasi, András Pál, Paula Sarkis, Krisztián Sárneczky, Ádám Sódor, László Szabados, Zsófia Marianna Szabó, Róbert Szakáts, Dóra Tarczay-Nehéz, Krisztián Vida, Gabriella Zsidi","V555 Ori is a T Tauri star, whose 1.5 mag brightening was published as a Gaia
science alert in 2017. We carried out optical and near-infrared photometric,
and optical spectroscopic observations to understand the light variations. The
light curves show that V555 Ori was faint before 2017, entered a high state for
about a year, and returned to the faint state by mid-2018. In addition to the
long-term flux evolution, quasi-periodic brightness oscillations were also
evident, with a period of about 5 days. At optical wavelengths both the
long-term and short-term variations exhibited colourless changes, while in the
near-infrared they were consistent with changing extinction. We explain the
brightness variations as the consequence of changing extinction. The object has
a low accretion rate whose variation in itself would not be enough to reproduce
the optical flux changes. This behaviour makes V555 Ori similar to the pre-main
sequence star AA Tau, where the light changes are interpreted as periodic
eclipses of the star by a rotating inner disc warp. The brightness maximum of
V555 Ori was a moderately obscured ($A_V$=2.3 mag) state, while the extinction
in the low state was $A_V$=6.4 mag. We found that while the Gaia alert hinted
at an accretion burst, V555 Ori is a standard dipper, similar to the prototype
AA Tau. However, unlike in AA Tau, the periodic behaviour was also detectable
in the faint phase, implying that the inner disc warp remained stable in both
the high and low states of the system.",http://arxiv.org/abs/2103.10313v2
"Acetaminophen Interactions with Phospholipid Vesicles Induced Changes in
  Morphology and Lipid Dynamics",2021-06-03T23:32:03Z,"Judith U. De Mel, Sudipta Gupta, Sydney Harmon, Laura Stingaciu, Eric W. Roth, Miriam Siebenbuerger, Markus Bleuel, Gerald J. Schneider","Acetaminophen (APAP) or Paracetamol, despite its wide and common use for pain
and fever symptoms, shows a variety of side effects, toxic effects, and
overdose effects. The most common form of toxic effects of APAP is in the liver
where phosphatidylcholine is the major component of the cell membrane with
additional associated functionalities. Although this is the case, the effects
of APAP on pure phospholipid membranes have been largely ignored. Here, we used
DOPC, a commonly found phospholipid in mammalian cell membranes to synthesize
large unilamellar vesicles to investigate how the incorporation of APAP changes
pure lipid vesicle structure, morphology, and fluidity at different
concentrations. We used a combination of dynamic light scattering (DLS),
small-angle neutron and X-ray scattering (SANS, SAXS), cryo TEM for structural
characterization, and neutron spin-echo (NSE) spectroscopy to investigate
dynamics. We showed that the incorporation of Acetaminophen in the lipid
bilayer significantly impacts the spherical phospholipid self-assembly in terms
of its morphology as well as influences the lipid content in the bilayer,
causing a decrease in bending rigidity. We discussed how the overall impact of
APAP molecules on the pure lipid membrane may play a significant role in the
drug's mechanisms of action. Our results showed the incorporation of APAP
reduces membrane rigidity as well as changes the spherical unilamellar vesicles
into much more irregularly shaped vesicles. Although bilayer structure did not
show much change when observed by SAXS, NSE and cryo-TEM results showed the
lipid dynamics change with the addition of APAP in the bilayer which causes the
overall decreased membrane rigidity. A strong effect on the lipid tail motion
was also observed. rigidity. A strong effect on the lipid tail motion was also
observed.",http://arxiv.org/abs/2106.02174v1
"Evolution of Saturn's north polar color and cloud structure between 2012
  and 2017 inferred from Cassini VIMS and ISS observations",2021-07-31T20:53:49Z,"L. A. Sromovsky, K. H. Baines, P. M. Fry","Cassini/ISS imagery and Cassini/VIMS spectral imaging observations from 0.35
to 5.12 microns show that between 2012 and 2017 the region poleward of the
Saturn's northern hexagon changed from dark blue/green to a moderately brighter
gold color, except for the inner eye region (88.2 deg - 90 deg N), which
remained relatively unchanged. These and even more dramatic near-IR changes can
be reproduced by an aerosol model of four compact layers consisting of a
stratospheric haze at an effective pressure near 50 mbar, a deeper haze of
putative diphosphine particles typically near 300 mbar, an ammonia cloud layer
with a base pressure between 0.4 bar and 1.3 bar, and a deeper cloud of a
possible mix of NH4SH and water ice particles within the 2.7 to 4.5 bar region.
Our analysis of the background clouds between the discrete features shows that
between 2013 and 2016 the effective pressures of most layers changed very
little, except for the ammonia ice layer, which decreased from about 1 bar to
0.4 bar near the edge of the eye, but increased to 1 bar inside the eye. Inside
the hexagon there were large increases in optical depth, by up to a factor of
10 near the eye for the putative diphosphine layer and by a factor of four over
most of the hexagon interior. Inside the eye, aerosol optical depths were very
low, suggesting downwelling motions. The high contrast between eye and
surroundings in 2016 was due to substantial increases in optical depths outside
the eye. The color change from blue/green to gold inside most of the hexagon
region can be explained in our model almost entirely by changes in the
stratospheric haze, which increased between 2013 and 2016 by a factor of four
in optical depth and by almost a factor of three in the short-wavelength peak
imaginary index.",http://arxiv.org/abs/2108.00322v1
"Comparison of space weathering spectral changes induced by solar wind
  and micrometeoroid impacts using ion- and femtosecond-laser-irradiated
  olivine and pyroxene",2021-08-02T13:02:53Z,"K. Chrbolková, R. Brunetto, J. Ďurech, T. Kohout, K. Mizohata, P. Malý, V. Dědič, C. Lantz, A. Penttilä, F. Trojánek, A. Maturilli","Space weathering is a process that changes the surface of airless planetary
bodies. Prime space weathering agents are solar wind irradiation and
micrometeoroid bombardment. These processes alter planetary reflectance spectra
and often modify their compositional diagnostic features. In this work we
focused on simulating and comparing the spectral changes caused by solar wind
irradiation and by micrometeoroid bombardment to gain a better understanding of
these individual space weathering processes. We used olivine and pyroxene
pellets as proxies for planetary materials. To simulate solar wind irradiation
we used hydrogen, helium, and argon ions with energies from 5 to 40 keV and
fluences of up to $10^{18}$ particles/cm$^2$. To simulate micrometeoroid
bombardment we used individual femtosecond laser pulses. We analysed the
corresponding evolution of different spectral parameters, which we determined
by applying the Modified Gaussian Model, and we also conducted principal
component analysis. The original mineralogy of the surface influences the
spectral evolution more than the weathering agent, as seen from the diverse
evolution of the spectral slope of olivine and pyroxene upon irradiation. The
spectral slope changes seen in olivine are consistent with observations of
A-type asteroids, while the moderate to no slope changes observed in pyroxene
are consistent with asteroid (4) Vesta. We also observed some differences in
the spectral effects induced by the two weathering agents. Ions simulating
solar wind have a smaller influence on longer wavelengths of the spectra than
laser irradiation simulating micrometeoroid impacts. This is most likely due to
the different penetration depths of ions and laser pulses. Our results suggest
that in some instances it might be possible to distinguish between the
contributions of the two agents on a weathered surface.",http://arxiv.org/abs/2108.00870v1
"A parsec-scale faint jet in the nearby changing-look Seyfert galaxy Mrk
  590",2021-01-12T17:32:00Z,"J. Yang, I. van Bemmel, Z. Paragi, S. Komossa, F. Yuan, X. Yang, T. An, J. Y. Koay, C. Reynolds, J. B. R. Oonk, X. Liu, Q. Wu","Broad Balmer emission lines in active galactic nuclei (AGN) may display
dramatic changes in amplitude, even disappearance and re-appearance in some
sources. As a nearby galaxy at a redshift of z = 0.0264, Mrk 590 suffered such
a cycle of Seyfert type changes between 2006 and 2017. Over the last fifty
years, Mrk 590 also underwent a powerful continuum outburst and a slow fading
from X-rays to radio wavelengths with a peak bolometric luminosity reaching
about ten per cent of the Eddington luminosity. To track its past accretion and
ejection activity, we performed very long baseline interferometry (VLBI)
observations with the European VLBI Network (EVN) at 1.6 GHz in 2015. The EVN
observations reveal a faint (~1.7 mJy) radio jet extending up to ~2.8 mas
(projected scale ~1.4 pc) toward north, and probably resulting from the very
intensive AGN activity. To date, such a parsec-scale jet is rarely seen in the
known changing-look AGN. The finding of the faint jet provides further strong
support for variable accretion as the origin of the type changes in Mrk 590.",http://arxiv.org/abs/2101.04629v1
"Structured regularization based velocity structure estimation in local
  earthquake tomography for the adaptation to velocity discontinuities",2021-04-19T06:21:53Z,"Yohta Yamanaka, Sumito Kurata, Keisuke Yano, Fumiyasu Komaki, Takahiro Shiina, Aitaro Kato","We propose a local earthquake tomography method that applies a structured
regularization technique to determine sharp changes in Earth's seismic velocity
structure using arrival time data of direct waves. Our approach focuses on the
ability to better image two common features that are observed in Earth's
seismic velocity structure: sharp changes in velocities that correspond to
material boundaries, such as the Conrad and Moho discontinuities; and gradual
changes in velocity that are associated with pressure and temperature
distributions in the crust and mantle. We employ different penalty terms in the
vertical and horizontal directions to refine the earthquake tomography. We
utilize a vertical-direction (depth) penalty that takes the form of the l1-sum
of the l2-norms of the second-order differences of the horizontal units in the
vertical direction. This penalty is intended to represent sharp velocity
changes caused by discontinuities by creating a piecewise linear depth profile
of seismic velocity. We set a horizontal-direction penalty term on the basis of
the l2-norm to express gradual velocity tendencies in the horizontal direction,
which has been often used in conventional tomography methods. We use a
synthetic data set to demonstrate that our method provides significant
improvements over velocity structures estimated using conventional methods by
obtaining stable estimates of both steep and gradual changes in velocity.
Furthermore, we apply our proposed method to real seismic data in central Japan
and present the potential of our method for detecting velocity discontinuities
using the observed arrival times from a small number of local earthquakes.",http://arxiv.org/abs/2104.09067v2
Quantifying changes in the British cattle movement network,2021-03-04T22:15:01Z,"Andrew J Duncan, Aaron Reeves, George J Gunn, Roger W Humphry","The Cattle Tracing System database is an online recording system for cattle
births, deaths and between--herd movements in the United Kingdom. Although it
has been thoroughly examined, the most recently reported movement analysis is
from 2009. This article uses the database to construct weighted directed
monthly movement networks for two distinct periods of time, 2004--2006 and
2015--2017, to quantify by how much the underlying structure of the network has
changed. Substantial changes in network structure may influence policy--makers
directly or may influence models built upon the network data, and these in turn
could impact policy--makers and their assessment of risk. Four general network
measures are used (total number of nodes with movements, movements, births and
deaths), in conjunction with network metrics to describe each monthly network.
Two updates of the database were examined to determine by how much the movement
data stored for a particular time period had been cleansed between updates.
Statistical models show that there is a statistically significant effect of the
time period (2004--2006 vs 2015--2017) in the values of all network measures
and six of nine network metrics. Changes in the sizes of both the Giant and
Weakly Strongly Connected components predict reductions in the upper and lower
bounds of the maximum epidemic size. Examination of the updates of the database
show that there are differences in records between updates and therefore
evidence of historical data changing between updates. Accurate modelling of
disease spread through a network requires representative descriptions of the
network. The authors recommend that where possible the most recent available
data always be used for network modelling and that methods of network
prediction be examined to mitigate for the time required for data to become
available.",http://arxiv.org/abs/2104.09270v1
"Cusp in the Symmetry Energy, Speed of Sound in Neutron Stars and
  Emergent Pseudo-Conformal Symmetry",2021-07-05T09:09:50Z,"Hyun Kyu Lee, Yong-Liang Ma, Won-Gi Paeng, Mannque Rho","We review how the ""cusp"" predicted in the nuclear symmetry energy generated
by a topology change at density $n_{1/2}\gsim 2 n_0$ can have a surprising
consequence, so far unrecognized in nuclear physics and astrophysics
communities, on the structure of dense compact-star matter. The topology
change, when translated into nuclear EFT with ""effective"" QCD degrees of
freedom in terms of hidden local and scale symmetries duly taken into account,
predicts an EoS that is soft below and stiff above $n\gsim n_{1/2}$, involving
no low-order phase transitions, and yields the macrophysical properties of
neutron stars consistent -- so far with no tension -- with the astrophysical
observations, including the maximum mass $ 2.0\lsim M/ M_\odot\lsim 2.2$ as
well as the GW data. Furthermore it describes the interior core of the massive
stars populated by baryon-charge-fractionalized quasi-fermions that are neither
baryonic nor quarkonic. It is argued that the cusp ""buried"" in the symmetry
energy resulting from strong correlations with hidden heavy degrees of freedom
leads, at $n\gsim n_{1/2}$, to what we dubbed ""pseudo-conformal"" sound speed,
$v^2_{pcs}/c^2\approx 1/3$, precociously converged from below at $n_{1/2}$. It
is not strictly conformal since the trace of energy-momentum tensor is not zero
even in the chiral limit. This observation with the topology change identified
with the putative hadron-quark continuity, taking place at at density $\gsim 2
n_0$, implies that the quantities accurately measured at $\sim n_0$ cannot give
a stringent constraint for what takes place at the core density of compact
stars $\sim (3-7) n_0$. This is because the change of degrees of freedom in
effective field theory is involved. We discuss the implication of this on the
recent PREX-II ""dilemma"" in the measured skin thickness of $^{208}$Pb.",http://arxiv.org/abs/2107.01879v4
"Sirius: Static Program Repair with Dependence Graph-Based Systematic
  Edit Patterns",2021-07-09T06:15:58Z,"Kunihiro Noda, Haruki Yokoyama, Shinji Kikuchi","Software development often involves systematic edits, similar but
nonidentical changes to many code locations, that are error-prone and laborious
for developers. Mining and learning such systematic edit patterns (SEPs) from
past code changes enable us to detect and repair overlooked buggy code that
requires systematic edits.
  A recent study presented a promising SEP mining technique that is based on
program dependence graphs (PDGs), while traditional approaches leverage
syntax-based representations. PDG-based SEPs are highly expressive and can
capture more meaningful changes than syntax-based ones. The next challenge to
tackle is to apply the same code changes as in PDG-based SEPs to other code
locations; detection and repair of overlooked locations that require systematic
edits. Existing program transformation techniques cannot well address this
challenge because (1) they expect many structural code similarities that are
not guaranteed in PDG-based SEPs or (2) they work on the basis of PDGs but are
limited to specific domains (e.g., API migrations).
  We present in this paper a general-purpose program transformation algorithm
for applying PDG-based SEPs. Our algorithm identifies a small transplantable
structural subtree for each PDG node, thereby adapting code changes from
PDG-based SEPs to other locations. We construct a program repair pipeline
Sirius that incorporates the algorithm and automates the processes of mining
SEPs, detecting overlooked code locations (bugs) that require systematic edits,
and repairing them by applying SEPs.
  We evaluated the repair performance of Sirius with a corpus of open source
software consisting of over 80 repositories. Sirius achieved a precision of
0.710, recall of 0.565, and F1-score of 0.630, while those of the
state-of-the-art technique were 0.470, 0.141, and 0.216, respectively.",http://arxiv.org/abs/2107.04234v1
"Quantitative electronic structure and work-function changes of liquid
  water induced by solute",2021-07-13T15:20:01Z,"Bruno Credidio, Michele Pugini, Sebastian Malerz, Florian Trinter, Uwe Hergenhahn, Iain Wilkinson, Stephan Thürmer, Bernd Winter","Recent advancement in quantitative liquid-jet photoelectron spectroscopy
enables the accurate determination of the absolute-scale electronic energetics
of liquids and species in solution. Our major objective is the determination of
the absolute lowest-ionization energy of liquid water which is found to vary
upon solute addition, and depends on the solute concentration. We discuss two
prototypical aqueous salt solutions, NaI(aq) and tetrabutylammonium iodide,
TBAI(aq), with the latter being a strong surfactant. Considerably different
behavior is revealed: In the NaI(aq) solutions, water's 1b1 energy increases by
300 meV upon increasing the concentration near-saturation concentrations,
whereas for TBAI the energy decreases by about 0.7 eV upon formation of a
surface layer. The solute-induced effects on the solute binding energies are
quantified as well, as inferred from concentration-dependent energy shifts of
the I- 5p peak energy. For NaI(aq), an almost identical I- 5p shift is found as
for the water 1b1 binding energy, with a larger shift occurring in the opposite
direction for the TBAI(aq) solution. We show that this result in NaI(aq) can be
primarily assigned to a change of water's electronic structure in the solution
bulk. In contrast, apparent changes of the 1b1 energy for TBAI(aq) can be
related to changes of the solution work function which could arise from surface
molecular dipoles. Furthermore, for both of the solutions studied here, the
measured water 1b1 binding energies can be correlated with the extensive
solution molecular structure changes occurring at high salt concentrations,
where in the case of NaI(aq), too few water molecules exist to hydrate
individual ions and the solution adopts a crystalline-like phase. We also
comment on the concentration-dependent shape of the 3a1 orbital of liquid water
which is a sensitive signature of water-water hydrogen bond interactions.",http://arxiv.org/abs/2107.06161v2
"Model for the long and orbital brightness variability of the $β$
  Lyrae type binary OGLE-BLG-ECL-157529",2021-07-16T23:32:49Z,"Ronald Mennickent, Gojko Djurašević","Some close binaries of the beta Lyrae type show photometric cycles longer
than the orbital one, which are possibly related to changes in their accretion
disks. We aim to understand the short- and long-scale changes observed in the
light curve of the eclipsing system OGLE-BLG-ECL-157529. In particular, we want
to shed light on the contribution of the disk to these changes, especially
those related to the long cycle, occurring on timescales of hundreds of days.
We studied I-band OGLE photometric times series spanning 18.5 years,
constructing disk models by analyzing the orbital light curve at 52 consecutive
epochs. An optimized simplex algorithm was used to solve the inverse problem by
adjusting the light curve with the best stellar-orbital-disk parameters for the
system. We applied principal components analysis to the parameters to evaluate
their dependence and variability. We constructed a description of the mass
transfer rate in terms of disk parameters. We find that the light variability
can be understood in terms of a variable mass transfer rate and variable
accretion disk. The system brightness at orbital phase 0.25 follows the long
cycle and is correlated with the mass transfer rate and the disk thickness. The
long-cycle brightness variations can be understood in terms of differential
occultation of the hotter star by a disk of variable thickness. Our model fits
the overall light curve during 18.5 years well, including epochs of reversal of
main and secondary eclipse depths. The disk radius cyclically change around the
tidal radius, decoupled from changes in the mass transfer rate or system
brightness, suggesting that viscous delay might explain the non-immediate
response. Although the disk is large and fills a large fraction of the hot star
Roche lobe, Lindblad resonance are far beyond the disk, excluding viscous
dissipation as a major source of photometric variability.",http://arxiv.org/abs/2107.08144v1
"AES Systems Are Both Overstable And Oversensitive: Explaining Why And
  Proposing Defenses",2021-09-24T03:49:38Z,"Yaman Kumar Singla, Swapnil Parekh, Somesh Singh, Junyi Jessy Li, Rajiv Ratn Shah, Changyou Chen","Deep-learning based Automatic Essay Scoring (AES) systems are being actively
used by states and language testing agencies alike to evaluate millions of
candidates for life-changing decisions ranging from college applications to
visa approvals. However, little research has been put to understand and
interpret the black-box nature of deep-learning based scoring algorithms.
Previous studies indicate that scoring models can be easily fooled. In this
paper, we explore the reason behind their surprising adversarial brittleness.
We utilize recent advances in interpretability to find the extent to which
features such as coherence, content, vocabulary, and relevance are important
for automated scoring mechanisms. We use this to investigate the
oversensitivity i.e., large change in output score with a little change in
input essay content) and overstability i.e., little change in output scores
with large changes in input essay content) of AES. Our results indicate that
autoscoring models, despite getting trained as ""end-to-end"" models with rich
contextual embeddings such as BERT, behave like bag-of-words models. A few
words determine the essay score without the requirement of any context making
the model largely overstable. This is in stark contrast to recent probing
studies on pre-trained representation learning models, which show that rich
linguistic features such as parts-of-speech and morphology are encoded by them.
Further, we also find that the models have learnt dataset biases, making them
oversensitive. To deal with these issues, we propose detection-based protection
models that can detect oversensitivity and overstability causing samples with
high accuracies. We find that our proposed models are able to detect unusual
attribution patterns and flag adversarial samples successfully.",http://arxiv.org/abs/2109.11728v3
"Multiscale mechanical model based on patient-specific geometry:
  application to early keratoconus development",2021-11-24T14:41:46Z,"Chloé Giraudet, Jérome Diaz, Patrick Le Tallec, Jean-Marc Allain","Keratoconus is a pathology of the cornea associated with a tissue thinning
and a weakening of its mechanical properties. However, it remains elusive which
aspect is the leading cause of the disease. To investigate this question, we
combined a multiscale model with a patient-geometry in order to simulate the
mechanical response of healthy and pathological corneas under intraocular
pressure. The constitutive behavior of the cornea is described through an
energy function which takes into account the isotropic matrix of the cornea,
the geometric structure of collagen lamellae and the quasi-incompressibility of
the tissue. A micro-sphere description is implemented to take into account the
typical features of the collagen lamellae as obtained experimentally, namely
their orientation, their stiffness and their dispersion, as well as the their
unfolding stretch, at which they start to provide a significant force. A set of
reference parameters is obtained to fit experimental inflation data of the
literature. We show that the most sensitive parameter is the unfolding stretch,
as a small variation of this parameter induces a major change in the corneal
apex displacement. The keratoconus case is then studied by separating the
impact of the geometry and the one of the mechanics. We computed the evolution
of the SimK (a clinical indicator of cornea curvature) and elevation maps: we
were able to reproduce the reported changes of SimK with pressure only by a
mechanical weakening, and not by a change in geomtry. More specifically, the
weakening has to target the lamellae and not the matrix. The mechanical
weakening leads to elevations close to early stage keratoconus, but our model
lacks the remodeling component to couple the change in mechanics with changes
in geometry.",http://arxiv.org/abs/2111.12520v1
Changing-look event in NGC 3516: continuum or obscuration variability?,2021-12-12T18:40:42Z,"Missagh Mehdipour, Gerard A. Kriss, Laura W. Brenneman, Elisa Costantini, Jelle S. Kaastra, Graziella Branduardi-Raymont, Laura Di Gesu, Jacobo Ebrero, Junjie Mao","The Seyfert-1 galaxy NGC 3516 has undergone major spectral changes in recent
years. In 2017 we obtained Chandra, NuSTAR, and Swift observations during its
new low-flux state. Using these observations we model the spectral energy
distribution (SED) and the intrinsic X-ray absorption, and compare the results
with those from historical observations taken in 2006. We thereby investigate
the effects of the changing-look phenomenon on the accretion-powered radiation
and the ionized outflows. Compared to its normal high-flux state in 2006, the
intrinsic bolometric luminosity of NGC 3516 was lower by a factor of 4 to 8
during 2017. Our SED modeling shows a significant decline in the luminosity of
all the continuum components from the accretion disk and the X-ray source. As a
consequence, the reprocessed X-ray emission lines have also become fainter. The
Swift monitoring of NGC 3516 shows remarkable X-ray spectral variability on
short (weeks) and long (years) timescales. We investigate whether this
variability is driven by obscuration or the intrinsic continuum. We find that
the new low-flux spectrum of NGC 3516, and its variability, do not require any
new or variable obscuration, and instead can be explained by changes in the
ionizing SED that result in lowering of the ionization of the warm-absorber
outflows. This in turn induces enhanced X-ray absorption by the warm-absorber
outflows, mimicking the presence of new obscuring gas. Using the response of
the ionized regions to the SED changes, we place constraints on their density
and location.",http://arxiv.org/abs/2112.06297v1
"Long-term photometric and low-resolution spectroscopic analysis of five
  contact binaries",2021-12-23T06:34:37Z,"Alaxender Panchal, Yogesh C. Joshi, Peter De Cat, Sugriva Nath Tiwari","A photometric and spectroscopic investigation is performed on five W Ursae
Majoris eclipsing binaries (EWs) J015818.6+260247 (hereinafter as J0158b),
J073248.4+405538 (hereinafter as J0732), J101330.8+494846 (hereinafter as
J1013), J132439.8+130747 (hereinafter as J1324) and J152450.7+245943
(hereinafter as J1524). The photometric data are collected with the help of the
1.3\,m Devasthal Fast Optical Telescope (DFOT), the 1.04\,m Sampurnanand
Telescope (ST) and the TESS space mission. The low-resolution spectra of the
4\,m Large Sky Area Multi-Object Fiber Spectroscopic Telescope (LAMOST) are
used for spectroscopic analysis. The orbital period change of these systems is
determined using our and previously available photometric data from different
surveys. The orbital period of J1013 and J1524 is changing with a rate of
$-2.552(\pm0.249)\times 10^{-7}$ days $yr^{-1}$ and $-6.792(\pm0.952)\times
10^{-8}$ days $yr^{-1}$, respectively, while others do not show any orbital
period change. The orbital period change of J1013 and J1524 corresponds to a
mass transfer rate of $2.199\times10^{-7} M_{\odot}\,yr^{-1}$ and
$6.151\times10^{-8}M_{\odot}\,yr^{-1}$ from the primary to the secondary
component in these systems. It is likely that angular momentum loss via
magnetic braking may also be responsible for the observed orbital period change
in the case of J1524. All systems have a mass-ratio lower than 0.5, except
J0158b with a mass-ratio of 0.71. All the systems are shallow type contact
binaries. The J0158b and J1524 are A-subtype while others are W-subtype. The
$H_{\alpha}$ emission line region is compared with template spectra prepared
using two inactive stars with the help of STARMOD program. The J0158, J1324 and
J1524 systems show excess emission in the residual spectra after subtraction of
the template.",http://arxiv.org/abs/2112.12379v1
"Patch-NetVLAD: Multi-Scale Fusion of Locally-Global Descriptors for
  Place Recognition",2021-03-02T05:53:32Z,"Stephen Hausler, Sourav Garg, Ming Xu, Michael Milford, Tobias Fischer","Visual Place Recognition is a challenging task for robotics and autonomous
systems, which must deal with the twin problems of appearance and viewpoint
change in an always changing world. This paper introduces Patch-NetVLAD, which
provides a novel formulation for combining the advantages of both local and
global descriptor methods by deriving patch-level features from NetVLAD
residuals. Unlike the fixed spatial neighborhood regime of existing local
keypoint features, our method enables aggregation and matching of deep-learned
local features defined over the feature-space grid. We further introduce a
multi-scale fusion of patch features that have complementary scales (i.e. patch
sizes) via an integral feature space and show that the fused features are
highly invariant to both condition (season, structure, and illumination) and
viewpoint (translation and rotation) changes. Patch-NetVLAD outperforms both
global and local feature descriptor-based methods with comparable compute,
achieving state-of-the-art visual place recognition results on a range of
challenging real-world datasets, including winning the Facebook Mapillary
Visual Place Recognition Challenge at ECCV2020. It is also adaptable to user
requirements, with a speed-optimised version operating over an order of
magnitude faster than the state-of-the-art. By combining superior performance
with improved computational efficiency in a configurable framework,
Patch-NetVLAD is well suited to enhance both stand-alone place recognition
capabilities and the overall performance of SLAM systems.",http://arxiv.org/abs/2103.01486v1
"Linear and Nonlinear Viscoelasticity of Concentrated Thermoresponsive
  Microgel Suspensions",2021-03-03T01:04:04Z,"Gaurav Chaudhary, Ashesh Ghosh, Jin Gu Kang, Paul V. Braun, Randy H. Ewoldt, Kenneth S. Schweizer","This is an integrated experimental and theoretical study of the dynamics and
rheology of self-crosslinked, slightly charged, temperature responsive soft
Poly(N-isopropylacrylamide) (pNIPAM) microgels over a wide range of
concentration and temperature spanning the sharp change in particle size and
intermolecular interactions across the lower critical solution temperature
(LCST). Dramatic, non-monotonic changes in viscoelasticity are observed with
temperature, with distinctive concentration dependences in the dense fluid,
glassy, and soft-jammed states. Motivated by our experimental observations, we
formulate a minimalistic model for the size dependence of a single microgel
particle and the change of interparticle interaction from purely repulsive to
attractive upon heating. Using microscopic equilibrium and time-dependent
statistical mechanical theories, theoretical predictions are quantitatively
compared with experimental measurements of the shear modulus. Good agreement is
found for the nonmonotonic temperature behavior that originates as a
consequence of the competition between reduced microgel packing fraction and
increasing interpar-ticle attractions. Testable predictions are made for
nonlinear rheological properties such as the yield stress and strain. To the
best of our knowledge, this is the first attempt to quantitatively understand
in a unified manner the viscoelasticity of dense, temperature-responsive
microgel suspensions spanning a wide range of temperatures and concentrations.",http://arxiv.org/abs/2103.02108v1
"Dual Labor Market and the ""Phillips Curve Puzzle""",2021-03-11T06:08:05Z,"Hideaki Aoyama, Corrado Di Guilmi, Yoshi Fujiwara, Hiroshi Yoshikawa","Low inflation was once a welcome to both policy makers and the public.
However, Japan's experience during the 1990's changed the consensus view on
price of economists and central banks around the world. Facing deflation and
zero interest bound at the same time, Bank of Japan had difficulty in
conducting effective monetary policy. It made Japan's stagnation unusually
prolonged. Too low inflation which annoys central banks today is translated
into the ""Phillips curve puzzle"". In the US and Japan, in the course of
recovery from the Great Recession after the 2008 global financial crisis, the
unemployment rate had steadily declined to the level which was commonly
regarded as lower than the natural rate or NAIRU. And yet, inflation stayed
low. In this paper, we consider a minimal model of dual labor market to explore
what kind of change in the economy makes the Phillips curve flat. The level of
bargaining power of workers, the elasticity of the supply of labor to wage in
the secondary market, and the composition of the workforce are the main factors
in explaining the flattening of the Phillips curve. We argue that the changes
we consider in the model, in fact, has plausibly made the Phillips curve flat
in recent years.",http://arxiv.org/abs/2103.06482v1
"A new method for identifying what Cupid's invisible hand is doing. Is it
  spreading color blindness while turning us more ""picky'' about spousal
  education?",2021-03-11T22:54:29Z,"Anna Naszodi, Francisco Mendonca","We develop a method suitable for detecting whether racial homophily is on the
rise and also whether the economic divide (i.e., the gap between individuals
with different education levels and thereby with different abilities to
generate income) is growing in a society. We identify these changes with the
changing aggregate marital preferences over the partners' race and education
level through their effects on the share of inter-racial couples and the share
of educationally homogamous couples. These shares are shaped not only by
preferences, but also by the distributions of marriageable men and women by
traits. The method proposed is designed to control for changes in the trait
distributions from one generation to another. By applying the method, we find
the economic divide in the US to display a U-curve pattern between 1960 and
2010 followed by its slightly negative trend between 2010 and 2015. The
identified trend of racial homophily suggests that the American society has
become more and more permissive towards racial intermarriages since 1970.
Finally, we refute the aggregate version of the status-cast exchange hypothesis
based on the joint dynamics of the economic divide and the racial homophily.",http://arxiv.org/abs/2103.06991v2
"Temperature dependent phase stability of Mo-Nb-Ta-W refractory
  high-entropy alloys",2021-03-14T15:26:14Z,"Varnita Bajpai, Soumyadipta Maiti, Shashank Mishra, Beena Rai","In this study Mo-Nb-Ta-W refractory high-entropy alloys (R-HEAs) have been
studied for their phase stability for a wide temperature range (100 K to 2000
K). The equilibrium thermodynamic phases are determined by the changes in
enthalpy and entropy. The enthalpy changes at any temperature are simulated by
embedded atom method (EAM) potential based hybrid Monte Carlo molecular
dynamics (MC/MD) simulations. Configurational entropy was calculated by
quasichemical method. The EAM potentials were all calculated based on the
physical input parameters of elements like atomic volume, cohesive energy,
elastic constants etc. It was found that the MC/MD evolved equilibrium
structures and the degree of local chemical short-range order/clustering
(SRO/SRC) largely depend on the ordering enthalpies for various temperatures.
The ordering transition temperature is close to 700 K, which is also
substantiated by the experimental powder X-ray diffractions done in synchrotron
beam. Large increase of degree of next-neighbor B2-type ordering of Mo-Ta pairs
and decrease of that Nb-W pairs were observed. This was also expected from the
trends of density functional theory (DFT) based ab-initio simulations done in
the literature and discussed in this work. The simulated diffraction pattern
and changes in scattering intensity due to the chemical SRO and SRC was
investigated. The diffraction trends were explained with the help of the
features of the evolved nanostructure morphology. The developed methodologies
may be helpful in prior prediction of long-term phase stability in
multi-element alloys by reducing the number of costly experiments.",http://arxiv.org/abs/2103.07951v1
"Constrained plasticity reserve as a natural way to control frequency and
  weights in spiking neural networks",2021-03-15T05:22:14Z,"Oleg Nikitin, Olga Lukyanova, Alex Kunin","Biological neurons have adaptive nature and perform complex computations
involving the filtering of redundant information. However, most common neural
cell models, including biologically plausible, such as Hodgkin-Huxley or
Izhikevich, do not possess predictive dynamics on a single-cell level.
Moreover, the modern rules of synaptic plasticity or interconnections weights
adaptation also do not provide grounding for the ability of neurons to adapt to
the ever-changing input signal intensity. While natural neuron synaptic growth
is precisely controlled and restricted by protein supply and recycling, weight
correction rules such as widely used STDP are efficiently unlimited in change
rate and scale. The present article introduces new mechanics of interconnection
between neuron firing rate homeostasis and weight change through STDP growth
bounded by abstract protein reserve, controlled by the intracellular
optimization algorithm. We show how these cellular dynamics help neurons filter
out the intense noise signals to help neurons keep a stable firing rate. We
also examine that such filtering does not affect the ability of neurons to
recognize the correlated inputs in unsupervised mode. Such an approach might be
used in the machine learning domain to improve the robustness of AI systems.",http://arxiv.org/abs/2103.08143v2
"Variable compliance and geometry regulation of Soft-Bubble grippers with
  active pressure control",2021-03-15T20:49:34Z,"Sihah Joonhigh, Naveen Kuppuswamy, Andrew Beaulieu, Alex Alspach, Russ Tedrake","While compliant grippers have become increasingly commonplace in robot
manipulation, finding the right stiffness and geometry for grasping the widest
variety of objects remains a key challenge. Adjusting both stiffness and
gripper geometry on the fly may provide the versatility needed to manipulate
the large range of objects found in domestic environments. We present a system
for actively controlling the geometry (inflation level) and compliance of
Soft-bubble grippers - air filled, highly compliant parallel gripper fingers
incorporating visuotactile sensing. The proposed system enables large,
controlled changes in gripper finger geometry and grasp stiffness, as well as
simple in-hand manipulation. We also demonstrate, despite these changes, the
continued viability of advanced perception capabilities such as dense geometry
and shear force measurement - we present a straightforward extension of our
previously presented approach for measuring shear induced displacements using
the internal imaging sensor and taking into account pressure and geometry
changes. We quantify the controlled variation of grasp-free geometry, grasp
stiffness and contact patch geometry resulting from pressure regulation and we
demonstrate new capabilities for the gripper in the home by grasping in
constrained spaces, manipulating tools requiring lower and higher stiffness
grasps, as well as contact patch modulation.",http://arxiv.org/abs/2103.08710v1
Worst Smells and Their Worst Reasons,2021-03-17T09:45:08Z,"Davide Falessi, Rick Kazman","The aims of this paper are: 1) to identify ""worst smells"", i.e., bad smells
that never have a good reason to exist, 2) to determine the frequency,
change-proneness, and severity associated with worst smells, and 3) to identify
the ""worst reasons"", i.e., the reasons for introducing these worst smells in
the first place. To achieve these aims we ran a survey with 71 developers. We
learned that 80 out of 314 catalogued code smells are ""worst""; that is,
developers agreed that these 80 smells should never exist in any code base. We
then checked the frequency and change-proneness of these worst smells on 27
large Apache open-source projects. Our results show insignificant differences,
in both frequency and change proneness, between worst and non-worst smells.
That is to say, these smells are just as damaging as other smells, but there is
never any justifiable reason to introduce them. Finally, in follow-up phone
interviews with five developers we confirmed that these smells are indeed
worst, and the interviewees proposed seven reasons for why they may be
introduced in the first place. By explicitly identifying these seven reasons,
project stakeholders can, through quality gates or reviews, ensure that such
smells are never accepted in a code base, thus improving quality without
compromising other goals such as agility or time to market.",http://arxiv.org/abs/2103.09537v1
Coherence of oscillations in matter and supernova neutrinos,2021-03-18T10:31:44Z,"Yago P. Porto-Silva, Alexei Yu. Smirnov","We study the propagation coherence for neutrino oscillations in media with
different density profiles. For each profile, we find the dependence of the
coherence length, $L_{coh}$, on neutrino energy and address the issue of
correspondence of results in the distance and energy-momentum representations.
The key new feature in matter is existence of energy ranges with enhanced
coherence around the energies $E_0$ of ""infinite coherence"" at which $L_{coh}
\rightarrow \infty$. In the configuration space, the infinite coherence
corresponds to equality of the (effective) group velocities of the eigenstates.
In constant density medium, there is a unique $E_0$, which coincides with the
MSW resonance energy of oscillations of mass states and is close to the MSW
resonance energy of flavor states. In the case of massless neutrinos or
negligible masses in a very dense medium the coherence persists continuously.
In the adiabatic case, the infinite coherence is realized for periodic density
change. Adiabaticity violation changes the shape factors of the wave packets
(WPs) and leads to their spread. In a medium with sharp density changes
(jumps), splitting of the eigenstates occurs at crossing of each jump. We study
the increase of the coherence length in a single jump and periodic density
jumps - castle-wall (CW) profiles. For the CW profile, there are several $E_0$
corresponding to parametric resonances. We outlined applications of the results
for supernova neutrinos. In particular, we show that coherence between two
shock wave fronts leads to observable oscillation effects, and our analysis
suggests that the decoherence can be irrelevant for flavor transformations in
the central parts of collapsing stars.",http://arxiv.org/abs/2103.10149v1
"Plasmonically enhanced spectrally selective narrowband MWIR and LWIR
  light detection based on hybrid nanopatterned graphene and phase changing
  vanadium oxide heterostructure operating close to room temperature",2021-03-18T15:14:11Z,"Muhammad Waqas Shabbir, Sayan Chandra, Michael N. Leuenberger","We present the model of an ultrasensitive mid-infrared (mid-IR) photodetector
operating in the mid-wavelength infrared (MWIR) and long-wavelength infrared
(LWIR) domains consisting of a hybrid heterostructure made of nanopatterned
graphene (NPG) and vanadium dioxide (VO$_2$) which exhibits a large
responsivity of $R\sim 10^4$ V/W, a detectivity exceeding $D^*\sim 10^{10}$ J,
and a sensitivity in terms of noise-equivalent power $\mathrm{NEP}\sim 100$
fW/$\sqrt{\rm Hz}$ close to room temperature by taking advantage of the phase
change of a thin VO$_2$ film. Our proposed photodetector can reach an
absorption of nearly 100\% in monolayer graphene due to localized surface
plasmons (LSPs) around the patterned circular holes. The geometry of the
nanopattern and an electrostatic gate potential can be used to tune the
absorption peak in the mid-IR regime between 3 and 12 $\mu$m. After the photon
absorption by the NPG sheet and the resulting phase change of VO$_2$ from
insulating to metallic phase the applied bias voltage $V_b$ triggers a current
through the VO$_2$ sheet, which can be detected electronically in about 1 ms,
shorter than the detection times of current VO$_2$ bolometers. Our envisioned
mid-IR photodetector reaches detectivities of cryogenically cooled HgCdTe
photodetectors and sensitivities larger than VO$_2$ microbolometers while
operating close to room temperature.",http://arxiv.org/abs/2103.10311v1
Time-Domain Hybrid PAM for Data-Rate and Distance Adaptive UWOC System,2021-03-08T11:26:50Z,"T. Kodama, M. Aizat, F. Kobori, T. Kimura, Y. Inoue, M. Jinno","The challenge for next-generation underwater optical wireless communication
systems is to develop optical transceivers that can operate with low power
consumption by maximizing the transmission capacity according to the
transmission distance between transmitters and receivers. This study proposes
an underwater wireless optical communication (UWOC) system using an optical
transceiver with an optimum transmission rate for the deep sea with near-pure
water properties. As a method for actualizing an optical transceiver with an
optimum transmission rate in a UWOC system, time-domain hybrid pulse amplitude
modulation (PAM) (TDHP) using a transmission rate and distance-adaptive
intensity modulation/direct detection optical transceiver is considered. In the
TDHP method, variable transmission capacity is actualized while changing the
generation ratio of two intensity-modulated signals with different noise
immunities in the time domain. Three different color laser diodes (LDs), red,
blue, and green are used in an underwater channel transmission transceiver that
comprises the LD and a photodiode. The maximum transmission distance while
changing the incidence of PAM 2 and PAM 4 signals that calibrate the TDHP in a
pure transmission line and how the maximum transmission distance changes when
the optical transmitter/receiver spatial optical system is altered from the
optimum conditions are clarified based on numerical calculation and simulation.
To the best knowledge of the authors, there is no other research on data-rate
and distance adaptive UWOC system that applies the TDHP signal with power
optimization between two modulation formats.",http://arxiv.org/abs/2103.11789v1
"An Efficient Interference-Aware Constrained Massive MIMO Beamforming for
  mm-Wave JSDM",2021-03-22T19:59:00Z,"Murat Bayraktar, Gokhan Muzaffer Guvensen","Low-complexity beamformer design with practical constraints is an attractive
research area for hybrid analog/digital systems in mm-wave massive
multiple-input multiple-output (MIMO). This paper investigates
interference-aware pre-beamformer (analog beamformer) design for joint spatial
division and multiplexing (JSDM) which is a user-grouping based two-stage
beamforming method. Single-carrier frequency domain equalization (SC-FDE) is
employed in uplink frequency-selective channels. First, unconstrained slowly
changing statistical analog beamformer of each group, namely, generalized
eigenbeamformer (GEB) which has strong interference suppression capability is
designed where the mutual information in reduced dimension is maximized. Then,
constant-modulus constrained approximations of unconstrained beamformer are
obtained by utilizing alternating minimization algorithms for fully connected
arrays and fixed subarrays. In addition, a dynamic subarray algorithm is
proposed where the connections between radio frequency (RF) chains and antennas
are changed with changing channel statistics. Convergence of the proposed
alternating minimization-based algorithms are provided along with their
complexity analysis. It is observed that additional complexity of proposed
algorithms is insignificant for the overall system design. Although most of the
interference is suppressed with the help of proposed constrained beamformers,
there may be some residual interference after the analog beamforming stage.
Therefore, linear minimum mean square error (LMMSE) type digital beamformers,
which take the residual interference in reduced dimension into account, are
proposed instead of zero-forcing (ZF) type. Simulation results verify the
superiority of the proposed interference-aware constrained design over existing
approaches in terms of beampattern, spectral efficiency, outage capacity and
channel estimation accuracy.",http://arxiv.org/abs/2103.12151v1
"YouTubing at Home: Media Sharing Behavior Change as Proxy for
  MobilityAround COVID-19 Lockdowns",2021-03-26T17:08:31Z,"Yelena Mejova, Nicolas Kourtellis","Compliance with public health measures, such as restrictions on movement and
socialization, is paramount in limiting the spread of diseases such as the
severe acute respiratory syndrome coronavirus 2 (also referred to as COVID-19).
Although large population datasets, such as phone-based mobility data, may
provide some glimpse into such compliance, it is often proprietary, and may not
be available for all locales. In this work, we examine the usefulness of video
sharing on social media as a proxy of the amount of time Internet users spend
at home. In particular, we focus on the number of people sharing YouTube videos
on Twitter before and during COVID-19 lockdown measures were imposed by 109
countries. We find that the media sharing behavior differs widely between
countries, in some having immediate response to the lockdown decrees - mostly
by increasing the sharing volume dramatically - while in others having a
substantial lag. We confirm that these insights correlate strongly with
mobility, as measured using phone data. Finally, we illustrate that both media
sharing and mobility behaviors change more drastically around mandated
lockdowns, and less so around more lax recommendations. We make the media
sharing volume data available to the research community for continued
monitoring of behavior change around public health measures.",http://arxiv.org/abs/2103.14601v1
"Are Multilevel functional models the next step in sports biomechanics
  and wearable technology? A case study of Knee Biomechanics patterns in
  typical training sessions of recreational runners",2021-03-29T15:43:09Z,"Marcos Matabuena, Sherveen Riazati, Nick Caplan, Phil Hayes","This paper illustrates how multilevel functional models can detect and
characterize biomechanical changes along different sport training sessions. Our
analysis focuses on the relevant cases to identify differences in knee
biomechanics in recreational runners during low and high-intensity exercise
sessions with the same energy expenditure by recording $20$ steps. To do so, we
review the existing literature of multilevel models, and then, we propose a new
hypothesis test to look at the changes between different levels of the
multilevel model as low and high-intensity training sessions. We also evaluate
the reliability of measures recorded in three-dimension knee angles from the
functional intra-class correlation coefficient (ICC) obtained from the
decomposition performed with the multilevel funcional model taking into account
$20$ measures recorded in each test. The results show that there are no
statistically significant differences between the two modes of exercise.
However, we have to be careful with the conclusions since, as we have shown,
human gait-patterns are very individual and heterogeneous between groups of
athletes, and other alternatives to the p-value may be more appropriate to
detect statistical differences in biomechanical changes in this context.",http://arxiv.org/abs/2103.15704v2
Globally Distributed Development during COVID-19,2021-03-31T16:02:32Z,"Clodagh NicCanna, Mohammad Abdur Razzak, John Noll, Sarah Beecham","Due to the global pandemic, in March 2020 we in academia and industry were
abruptly forced into working from home. Yet teaching never stopped, and neither
did developing software, fixing software, and expanding into new markets.
Demands for flexible ways of working, responding to new requirements, have
never been so high. How did we manage to continue working, when we had to
suddenly switch all communication to online and virtual forms of contact? In
this short paper we describe how Ocuco Ltd., a medium-sized organization
headquartered in Ireland, managed our software development teams--distributed
throughout Ireland, Europe, Asia and America during the COVID-19 pandemic. We
describe how we expanded, kept our customers happy, and our teams motivated. We
made changes, some large, such as providing emergency financial support; others
small, like implementing regular online social pizza evenings. Technology and
process changes were minor, an advantage of working in globally distributed
teams since 2016, when development activities were coordinated according to the
Scaled Agile Framework (SAFe). The results of implementing the changes were
satisfying; productivity went up, we gained new customers, and preliminary
results from our wellness survey indicate that everyone feels extremely
well-supported by management to achieve their goals. However, the anonymised
survey responses did show some developers' anxiety levels were slightly raised,
and many are working longer hours. Administering this survey is very
beneficial, as now we know, so we can act.",http://arxiv.org/abs/2103.17181v1
"A comparison of phase change materials in reconfigurable silicon
  photonic directional couplers",2021-06-02T14:09:56Z,"Ting Yu Teo, Milos Krbal, Jan Mistrik, Jan Prikryl, Li Lu, Robert Edward Simpson","The unique optical properties of phase change materials (PCMs) can be
exploited to develop efficient reconfigurable photonic devices. Here, we
design, model, and compare the performance of programmable 1X2 optical couplers
based on: Ge$_2$Sb$_2$Te$_5$, Ge$_2$Sb$_2$Se$_4$Te$_1$, Sb$_2$Se$_3$, and
Sb$_2$S$_3$ PCMs. Once programmed, these devices are passive, which can reduce
the overall energy consumed compared to thermo-optic or electro-optic
reconfigurable devices. Of all the PCMs studied, our ellipsometry refractive
index measurements show that Sb$_2$S$_3$ has the lowest absorption in the
telecommunications wavelength band. Moreover, Sb$_2$S$_3$-based couplers show
the best overall performance, with the lowest insertion losses in both the
amorphous and crystalline states. We show that by growth crystallization tuning
at least four different coupling ratios can be reliably programmed into the
Sb$_2$S$_3$ directional couplers. We used this effect to design a 2-bit
tuneable Sb$_2$S$_3$ directional coupler with a dynamic range close to 32 dB.
The bit-depth of the coupler appears to be limited by the crystallization
stochasticity.",http://arxiv.org/abs/2106.01169v2
Rectangular Flows for Manifold Learning,2021-06-02T18:30:39Z,"Anthony L. Caterini, Gabriel Loaiza-Ganem, Geoff Pleiss, John P. Cunningham","Normalizing flows are invertible neural networks with tractable
change-of-volume terms, which allow optimization of their parameters to be
efficiently performed via maximum likelihood. However, data of interest are
typically assumed to live in some (often unknown) low-dimensional manifold
embedded in a high-dimensional ambient space. The result is a modelling
mismatch since -- by construction -- the invertibility requirement implies
high-dimensional support of the learned distribution. Injective flows, mappings
from low- to high-dimensional spaces, aim to fix this discrepancy by learning
distributions on manifolds, but the resulting volume-change term becomes more
challenging to evaluate. Current approaches either avoid computing this term
entirely using various heuristics, or assume the manifold is known beforehand
and therefore are not widely applicable. Instead, we propose two methods to
tractably calculate the gradient of this term with respect to the parameters of
the model, relying on careful use of automatic differentiation and techniques
from numerical linear algebra. Both approaches perform end-to-end nonlinear
manifold learning and density estimation for data projected onto this manifold.
We study the trade-offs between our proposed methods, empirically verify that
we outperform approaches ignoring the volume-change term by more accurately
learning manifolds and the corresponding distributions on them, and show
promising results on out-of-distribution detection. Our code is available at
https://github.com/layer6ai-labs/rectangular-flows.",http://arxiv.org/abs/2106.01413v3
"Systematic Online Tuning of Multirotor UAVs for Accurate Trajectory
  Tracking Under Wind Disturbances and In-Flight Dynamics Changes",2021-06-07T09:40:23Z,"Abdulaziz Y. Alkayas, Mohamad Chehadeh, Abdulla Ayyad, Yahya Zweiri","The demand for accurate and fast trajectory tracking for multirotor Unmanned
Aerial Vehicles (UAVs) have grown recently due to advances in UAV avionics
technology and application domains. In many applications, the multirotor UAV is
required to accurately perform aggressive maneuvers in challenging scenarios
like the presence of external wind disturbances or in-flight payload changes.
In this paper, we propose a systematic controller tuning approach based on
identification results obtained by a recently developed Deep Neural Networks
with the Modified Relay Feedback Test (DNN-MRFT) algorithm. We formulate a
linear equivalent representation suitable for DNN-MRFT using feedback
linearization. This representation enables the analytical investigation of
different controller structures and tuning settings, and captures the
non-linearity trends of the system. With this approach, the trade-off between
performance and robustness in design was made possible which is convenient for
the design of controllers of UAVs operating in uncertain environments. We
demonstrate that our approach is adaptive and robust through a set of
experiments, where accurate trajectory tracking is maintained despite
significant changes to the UAV aerodynamic characteristics and the application
of wind disturbance. Due to the model-based system design, it was possible to
obtain low discrepancy between simulation and experimental results which is
beneficial for potential use of the proposed approach for real-time model-based
planning and fault detection tasks. We obtained RMSE of $3.59 \; cm$ when
tracking aggressive trajectories in the presence of strong wind, which is on
par with state-of-the-art.",http://arxiv.org/abs/2106.03459v2
"Changes in granulation scales over the solar cycle seen with SDO/HMI and
  Hinode/SOT",2021-06-07T12:35:36Z,"J. Ballot, T. Roudier, J. M. Malherbe, Z. Frank","The Sun is the only star where the superficial turbulent convection can be
observed at very high spatial resolution. The Solar Dynamics Observatory (SDO)
has continuously observed the full Sun from space with multi-wavelength filters
since July 2010. In particular, the Helioseismic and Magnetic Imager (HMI)
instrument takes high-cadence frames (45 seconds) of continuum intensity in
which solar granulation is visible. We aimed to follow the evolution of the
solar granules over an activity cycle and look for changes in their spatial
properties. We investigated the density of granules and their mean area derived
directly from the segmentation of deconvolved images from SDO/HMI. To perform
the segmentation, we define granules as convex elements of images. We measured
an approximately 2% variation in the density and the mean area of granules over
the cycle, the density of granules being greater at solar maximum with a
smaller granule mean area. The maximum density appears to be delayed by about
one year compared to classical activity indicators, such as the sunspot number.
We complemented this study with high-spatial-resolution observations obtained
with Hinode/SOTBFI (Solar Optical Telescope Broadband Filter Imager), which are
consistent with our results. The observed variations in solar granulation at
the disc centre reveal a direct insight into the change in the physical
properties that occur in the upper convective zone during a solar cycle. These
variations can be due to interactions between convection and magnetic fields,
either at the global scale or, locally, at the granulation scale.",http://arxiv.org/abs/2106.03556v1
"Deep Learning 3D Dose Prediction for Conventional Lung IMRT Using
  Consistent/Unbiased Automated Plans",2021-06-07T15:15:05Z,"Navdeep Dahiya, Gourav Jhanwar, Anthony Yezzi, Masoud Zarepisheh, Saad Nadeem","Deep learning (DL) 3D dose prediction has recently gained a lot of attention.
However, the variability of plan quality in the training dataset, generated
manually by planners with wide range of expertise, can dramatically effect the
quality of the final predictions. Moreover, any changes in the clinical
criteria requires a new set of manually generated plans by planners to build a
new prediction model. In this work, we instead use consistent plans generated
by our in-house automated planning system (named ``ECHO'') to train the DL
model. ECHO (expedited constrained hierarchical optimization) generates
consistent/unbiased plans by solving large-scale constrained optimization
problems sequentially. If the clinical criteria changes, a new training data
set can be easily generated offline using ECHO, with no or limited human
intervention, making the DL-based prediction model easily adaptable to the
changes in the clinical practice. We used 120 conventional lung patients (100
for training, 20 for testing) with different beam configurations and trained
our DL-model using manually-generated as well as automated ECHO plans. We
evaluated different inputs: (1) CT+(PTV/OAR)contours, and (2) CT+contours+beam
configurations, and different loss functions: (1) MAE (mean absolute error),
and (2) MAE+DVH (dose volume histograms). The quality of the predictions was
compared using different DVH metrics as well as dose-score and DVH-score,
recently introduced by the AAPM knowledge-based planning grand challenge. The
best results were obtained using automated ECHO plans and CT+contours+beam as
training inputs and MAE+DVH as loss function.",http://arxiv.org/abs/2106.03705v1
"Instantaneous equilibrium Transport for Brownian systems under
  time-dependent temperature and potential variations: Reversibility, Heat and
  work relations, and Fast Isentropic process",2021-06-08T08:49:34Z,"Yonggun Jun, Pik-Yin Lai","The theory of constructing instantaneous equilibrium (ieq) transition under
arbitrary time-dependent temperature and potential variation for a Brownian
particle is developed. It is shown that it is essential to consider the
underdamped dynamics for temperature-changing transitions. The ieq is
maintained by a time-dependent auxiliary position and momentum potential, which
can be calculated for given time-dependent transition protocols. Explicit
analytic results are derived for the work and heat statistics, energy, and
entropy changes for harmonic and non-harmonic trapping potential with arbitrary
time-dependent potential parameters and temperature protocols. Numerical
solutions of the corresponding Langevin dynamics are computed to confirm the
theoretical results. Although ieq transition of the reverse process is not the
time-reversal of the ieq transition of the forward process due to the
odd-parity of controlling parameters, their phase-space distribution functions
restore the time-reversal symmetry, and hence the energy and entropy changes of
the ieq of the reverse process are simply the negative of that of the forward
process. Furthermore, it is shown that it is possible to construct an ieq
transition that has zero entropy production at a finite transition rate, i.e.,
a fast ieq isentropic process, and is further demonstrated by explicit Langevin
dynamics simulations. Our theory provides fundamental building blocks for
designing controlled microscopic heat engine cycles. Implications for
constructing an efficient Brownian heat engine are also discussed.",http://arxiv.org/abs/2106.04184v2
"Vacuum instability in time-dependent electric fields. New example of
  exactly solvable case",2021-06-11T11:41:29Z,"A. I. Breev, S. P. Gavrilov, D. M. Gitman, A. A. Shishmarev","A new exactly solvable case in strong-field quantum electrodynamics with a
time-dependent external electric field is presented. The corresponding field is
given by an analytic function, which is asymmetric (in contrast to Sauter-like
electric field) with respect to the time instant, where it reaches its maximum
value, that is why we call it the analytic asymmetric electric field. We
managed to exactly solve the Dirac equation with such a field, which made it
possible to calculate characteristics of the corresponding vacuum instability
nonperturbatively. We construct the so-called in- and out-solutions and with
their help calculate mean differential and total numbers of created charged
particles, probability of the vacuum to remain a vacuum, vacuum mean values of
current density and energy-momentum tensor of the particles. We study the
vacuum instability in regimes of rapidly and slowly changing analytic
asymmetric electric field, and compare the obtained results with corresponding
ones obtained earlier for the case of the symmetric Sauter-like electric field.
We also compare exact results in the regime of slowly changing field with
corresponding results obtained within the slowly varying field approximation
recently proposed by two of the authors, thus demonstrating the effectiveness
of such an approximation.",http://arxiv.org/abs/2106.06322v4
"Hippocampus segmentation in magnetic resonance images of Alzheimer's
  patients using Deep machine learning",2021-06-12T11:00:29Z,"Hossein Yousefi-Banaem, Saber Malekzadeh","Background: Alzheimers disease is a progressive neurodegenerative disorder
and the main cause of dementia in aging. Hippocampus is prone to changes in the
early stages of Alzheimers disease. Detection and observation of the
hippocampus changes using magnetic resonance imaging (MRI) before the onset of
Alzheimers disease leads to the faster preventive and therapeutic measures.
Objective: The aim of this study was the segmentation of the hippocampus in
magnetic resonance (MR) images of Alzheimers patients using deep machine
learning method. Methods: U-Net architecture of convolutional neural network
was proposed to segment the hippocampus in the real MRI data. The MR images of
the 100 and 35 patients available in Alzheimers disease Neuroimaging Initiative
(ADNI) dataset, was used for the train and test of the model, respectively. The
performance of the proposed method was compared with manual segmentation by
measuring the similarity metrics. Results: The desired segmentation achieved
after 10 iterations. A Dice similarity coefficient (DSC) = 92.3%, sensitivity =
96.5%, positive predicted value (PPV) = 90.4%, and Intersection over Union
(IoU) value for the train 92.94 and test 92.93 sets were obtained which are
acceptable. Conclusion: The proposed approach is promising and can be extended
in the prognosis of Alzheimers disease by the prediction of the hippocampus
volume changes in the early stage of the disease.",http://arxiv.org/abs/2106.06743v2
"Heavy particle non-decoupling in flavor-changing gravitational
  interactions",2021-06-14T07:50:19Z,"Takeo Inami, Takahiro Kubota","The flavor-changing gravitational process d --> s + graviton, is evaluated at
the one-loop level in the standard electroweak theory with on-shell
renormalization. The results we present in the 't Hooft-Feynman gauge are valid
for on- and off-shell quarks and for all external and internal quark masses. We
show that there exist non-decoupling effects of the internal heavy top quark in
interactions with gravity. A naive argument taking account of the quark Yukawa
coupling suggests that the amplitude of the process d --> s + graviton in the
large top quark mass limit would possibly acquire an enhancement factor
$m_{t}^{2}/M_{W}^{2}$, where $m_{t}$ and $M_{W}$ are the top quark and the
W-boson masses, respectively. In practice this leading enhancement is absent in
the renormalized amplitude due to cancellation. Thus the non-decoupling of the
internal top quark takes place at the $O(1)$ level. The flavor-changing two-
and three-point functions are shown to satisfy the Ward-Takahashi identity,
which is used for a consistency-check of the aforementioned cancellation of the
$O(m_{t}^{2}/M_{W}^{2})$ terms. Among the $O(1)$ non-decoupling terms, we sort
out those that can be regarded as due to the effective Lagrangian in which
quark bilinear forms are coupled to the scalar curvature.",http://arxiv.org/abs/2106.07209v4
"Dataset of Propaganda Techniques of the State-Sponsored Information
  Operation of the People's Republic of China",2021-06-14T16:11:13Z,"Rong-Ching Chang, Chun-Ming Lai, Kai-Lai Chang, Chu-Hsing Lin","The digital media, identified as computational propaganda provides a pathway
for propaganda to expand its reach without limit. State-backed propaganda aims
to shape the audiences' cognition toward entities in favor of a certain
political party or authority. Furthermore, it has become part of modern
information warfare used in order to gain an advantage over opponents. Most of
the current studies focus on using machine learning, quantitative, and
qualitative methods to distinguish if a certain piece of information on social
media is propaganda. Mainly conducted on English content, but very little
research addresses Chinese Mandarin content. From propaganda detection, we want
to go one step further to provide more fine-grained information on propaganda
techniques that are applied. In this research, we aim to bridge the information
gap by providing a multi-labeled propaganda techniques dataset in Mandarin
based on a state-backed information operation dataset provided by Twitter. In
addition to presenting the dataset, we apply a multi-label text classification
using fine-tuned BERT. Potentially this could help future research in detecting
state-backed propaganda online especially in a cross-lingual context and cross
platforms identity consolidation.",http://arxiv.org/abs/2106.07544v1
"On A. D. Sakharov's hypothesis of cosmological transitions with changes
  in the signature of the metric",2021-06-17T12:02:34Z,T. P. Shestakova,"I discuss possible consequences of A. D. Sakharov's hypothesis of
cosmological transitions with changes in the signature of the metric, based on
the path integral approach. This hypothesis raises a number of mathematical and
philosophical questions. Mathematical questions concern the definition of the
path integral to include integration over spacetime regions with different
signatures of the metric. One possible way to describe the changes in the
signature is to admit time and space coordinates to be purely imaginary. It may
look like a generalization of what we have in the case of pseudo-Riemannian
manifolds with a non-trivial topology. The signature in these regions can be
fixed by special gauge conditions on components of the metric tensor. The
problem is what boundary conditions should be imposed on the boundaries of
these regions and how they should be taken into account in the definition of
the path integral. The philosophical question is what distinguishes the time
coordinate among other coordinates but the sign of the corresponding principal
value of the metric tensor. In particular, I try to speculate how the existence
of the regions with different signature can affect the evolution of the
Universe.",http://arxiv.org/abs/2106.09416v1
Cycles of paleomagnetic activity in the phanerozoic,2021-06-20T06:49:56Z,"A. Yu. Kurazhkovskii, N. A. Kurazhkovskaya, B. I. Klain","Quasi-periodic changes of the paleointensity and geomagnetic polarity in the
intervals of 170 Ma to the present time and of 550 Ma to the present time were
studied, respectively. It is revealed that the spectrum of the basic variations
in the paleointensity and of the duration of the polar intervals is discrete
and includes quasi-periodic oscillations with characteristic times of 15 Ma, 8
Ma, 5 Ma, and 3 Ma. The characteristic time of these quasi-periodic changes of
the geomagnetic field at the beginning and at the end of the Phanerozoic
differed by no more than 10%. The spectral density of quasi-periodic variations
of the geomagnetic field changed cyclically over geological time. The relation
between the behaviors of the amplitude of paleointensity variations, the
duration of the polar intervals, and their spectral density was shown.
Quasi-periodic variations of the paleointensity (geomagnetic activity) had a
relatively high spectral density in the interval of (150 - 40) Ma (in the
Cretaceous - Early Paleogene). In this interval, both the amplitude of
paleointensity variations and the duration of polar intervals increased. In the
intervals of (170 - 150) Ma and of 30 Ma to the present, a quasi-periodic
variation in the paleointensity practically did not detect against the
background of its noise variations. At the same time, the amplitude of the
paleointensity variations and duration of polar intervals decreased. An
alternation of time intervals in which the paleointensity variations acquired
either a quasi-periodic or noise character took place during the geomagnetic
history.",http://arxiv.org/abs/2106.10636v1
Pro or Anti? A Social Influence Model of Online Stance Flipping,2021-06-21T12:56:39Z,"Lynnette Hui Xian Ng, Kathleen Carley","Social influence characterizes the change of an individual's stances in a
complex social environment towards a topic. Two factors often govern the
influence of stances in an online social network: endogenous influences driven
by an individual's innate beliefs through the agent's past stances and
exogenous influences formed by social network influence between users. Both
endogenous and exogenous influences offer important cues to user
susceptibility, thereby enhancing the predictive performance on stance changes
or flipping. In this work, we propose a stance flipping prediction problem to
identify Twitter agents that are susceptible to stance flipping towards the
coronavirus vaccine (i.e., from pro-vaccine to anti-vaccine). Specifically, we
design a social influence model where each agent has some fixed innate stance
and a conviction of the stance that reflects the resistance to change; agents
influence each other through the social network structure.From data collected
between April 2020 to May 2021, our model achieves 86\% accuracy in predicting
agents that flip stances. Further analysis identifies that agents that flip
stances have significantly more neighbors engaging in collective expression of
the opposite stance, and 53.7% of the agents that flip stances are bots and bot
agents require lesser social influence to flip stances.",http://arxiv.org/abs/2106.11076v2
"Competing magnetic interactions and magnetocaloric effect in
  Ho$_5$Sn$_3$",2021-06-24T16:44:41Z,"Suman Mondal, Pushpendra Yadav, Anan Bari Sarkar, Prabir Dutta, Saurav Giri, Amit Agarwal, Subham Majumdar","The rare-earth intermetallic compound Ho$_5$Sn$_3$ demonstrates fascinating
magnetic properties which include temperature-driven multiple magnetic
transitions and field driven metamagnetism. We address the magnetic character
of this exciting compound through a combined experimental and theoretical
studies. Ho$_5$Sn$_3$ orders antiferromagnetically below $~28$ K, and shows
further spin reorientation transitions at 15 K and 12 K. We observe a sizable
amount of low-temperature magnetocaloric effect in Ho$_5$Sn$_3$ with a maximum
value of entropy change $\Delta S$ = -9.5 JKg$^{-1}$K$^{-1}$ for an applied
field of $H$ = 50 kOe at around 30 K. The field hysteresis is almost zero above
15 K where magneto-caloric effect is important. Interestingly, $\Delta S$ is
found to change its sign from positive to negative as the temperature is
increased above about 8 K, which can be linked to the multiple spin
reorientation transitions. The signature of the metamagnetism is visible in the
$\Delta S$ versus $H$ plot. The magnetic ground-state, obtained from the
density functional theory based calculation, is susceptible to the effective
Coulomb interaction ($U_{\rm eff}$) between electrons. Depending upon the value
of $U_{\rm eff}$, the ground-state can be ferromagnetic or antiferromagnetic.
The compound shows large relaxation (14\% change in magnetization in 60 min) in
the field cooled state with a logarithmic time variation, which may be
connected to the competing magnetic ground-states observed in our theoretical
calculations. The competing magnetic ground-states is also evident from the
small value of the paramagnetic Curie-Weiss temperature.",http://arxiv.org/abs/2106.13173v1
Sequential Recommendation with Graph Neural Networks,2021-06-27T12:57:31Z,"Jianxin Chang, Chen Gao, Yu Zheng, Yiqun Hui, Yanan Niu, Yang Song, Depeng Jin, Yong Li","Sequential recommendation aims to leverage users' historical behaviors to
predict their next interaction. Existing works have not yet addressed two main
challenges in sequential recommendation. First, user behaviors in their rich
historical sequences are often implicit and noisy preference signals, they
cannot sufficiently reflect users' actual preferences. In addition, users'
dynamic preferences often change rapidly over time, and hence it is difficult
to capture user patterns in their historical sequences. In this work, we
propose a graph neural network model called SURGE (short for SeqUential
Recommendation with Graph neural nEtworks) to address these two issues.
Specifically, SURGE integrates different types of preferences in long-term user
behaviors into clusters in the graph by re-constructing loose item sequences
into tight item-item interest graphs based on metric learning. This helps
explicitly distinguish users' core interests, by forming dense clusters in the
interest graph. Then, we perform cluster-aware and query-aware graph
convolutional propagation and graph pooling on the constructed graph. It
dynamically fuses and extracts users' current activated core interests from
noisy user behavior sequences. We conduct extensive experiments on both public
and proprietary industrial datasets. Experimental results demonstrate
significant performance gains of our proposed method compared to
state-of-the-art methods. Further studies on sequence length confirm that our
method can model long behavioral sequences effectively and efficiently.",http://arxiv.org/abs/2106.14226v2
"AniVis: Generating Animated Transitions Between Statistical Charts with
  a Tree Model",2021-06-27T19:17:51Z,"Wenchao Li, Yun Wang, He Huang, Weiwei Cui, Haidong Zhang, Huamin Qu, Dongmei Zhang","Animated transitions help viewers understand changes between related
visualizations. To clearly present the underlying relations between statistical
charts, animation authors need to have a high level of expertise and a
considerable amount of time to describe the relations with reasonable animation
stages. We present AniVis, an automated approach for generating animated
transitions to demonstrate the changes between two statistical charts. AniVis
models each statistical chart into a tree-based structure. Given an input chart
pair, the differences of data and visual properties of the chart pair are
formalized as tree edit operations. The edit operations can be mapped to atomic
transition units. Through this approach, the animated transition between two
charts can be expressed as a set of transition units. Then, we conduct a
formative study to understand people's preferences for animation sequences.
Based on the study, we propose a set of principles and a sequence composition
algorithm to compose the transition units into a meaningful animation sequence.
Finally, we synthesize these units together to deliver a smooth and intuitive
animated transition between charts. To test our approach, we present a
prototype system and its generated results to illustrate the usage of our
framework. We perform a comparative study to assess the transition sequence
derived from the tree model. We further collect qualitative feedback to
evaluate the effectiveness and usefulness of our method.",http://arxiv.org/abs/2106.14313v2
"Modularity in Reinforcement Learning via Algorithmic Independence in
  Credit Assignment",2021-06-28T21:29:13Z,"Michael Chang, Sidhant Kaushik, Sergey Levine, Thomas L. Griffiths","Many transfer problems require re-using previously optimal decisions for
solving new tasks, which suggests the need for learning algorithms that can
modify the mechanisms for choosing certain actions independently of those for
choosing others. However, there is currently no formalism nor theory for how to
achieve this kind of modular credit assignment. To answer this question, we
define modular credit assignment as a constraint on minimizing the algorithmic
mutual information among feedback signals for different decisions. We introduce
what we call the modularity criterion for testing whether a learning algorithm
satisfies this constraint by performing causal analysis on the algorithm
itself. We generalize the recently proposed societal decision-making framework
as a more granular formalism than the Markov decision process to prove that for
decision sequences that do not contain cycles, certain single-step temporal
difference action-value methods meet this criterion while all policy-gradient
methods do not. Empirical evidence suggests that such action-value methods are
more sample efficient than policy-gradient methods on transfer problems that
require only sparse changes to a sequence of previously optimal decisions.",http://arxiv.org/abs/2106.14993v3
"Streaming instability of multiple particle species II -- Numerical
  convergence with increasing particle number",2021-06-29T12:22:38Z,"Noemi Schaffer, Anders Johansen, Michiel Lambrechts","The streaming instability provides an efficient way of overcoming the growth
barriers in the initial stages of the planet formation process. Considering the
realistic case of a particle size distribution, the dynamics of the system is
altered compared to the outcome of single size models. In order to understand
the outcome of the multi-species streaming instability in detail, we perform a
large parameter study in terms of particle number, particle size distribution,
particle size range, initial metallicity and initial particle scale height. We
study vertically stratified systems and determine the metallicity threshold for
filament formation. We compare these with a system where the initial particle
distribution is unstratified and find that its evolution follows that of its
stratified counterpart. We find that change in particle number does not result
in significant variation in the efficiency and timing of filament formation. We
also see that there is no clear trend for how varying the size distribution in
combination with particle size range changes the outcome of the multi-species
streaming instability. Finally, we find that an initial metallicity of
$Z_{\rm{init}}=0.005$ and $Z_{\rm{init}}=0.01$ both result in similar critical
metallicity values for the start of filament formation. Our results show that
the inclusion of a particle size distribution into streaming instability
simulations, while changing the dynamics as compared to mono-disperse systems,
does not result in overall unfavorable conditions for solid growth. We
attribute the sub-dominant role of multiple species to the high-density
conditions in the midplane, conditions under which also linear stability
analysis predict little difference between single and multiple species.",http://arxiv.org/abs/2106.15302v1
"Interaction of Multiple Tensor Product Operators of the Same Type: an
  Introduction",2021-06-29T17:11:23Z,"Howard A. Blair, H Shelton Jacinto, Paul M. Alsing","Tensor product operators on finite dimensional Hilbert spaces are studied.
The focus is on bilinear tensor product operators. A tensor product operator on
a pair of Hilbert spaces is a maximally general bilinear operator into a target
Hilbert space. By 'maximally general' is meant every bilinear operator from the
same pair of spaces to any Hilbert space factors into the composition of the
tensor product operator with a uniquely determined linear mapping on the target
space. There are multiple distinct tensor product operators of the same type;
there is no ""the"" tensor product. Distinctly different tensor product operators
can be associated with different parts of a multipartite system without
difficulty. Separability of states, and locality of operators and observables
is tensor product operator dependent. The same state in the target state space
can be inseparable with respect to one tensor product operator but separable
with respect to another, and no tensor product operator is distinguished
relative to the others; the unitary operator used to construct a Bell state
from a pair of |0>'s being highly tensor product operator-dependent is a prime
example. The relationship between two tensor product operators of the same type
is given by composition with a unitary operator. There is an equivalence
between change of tensor product operator and change of basis in the target
space. Among the gains from change of tensor product operator is the
localization of some nonlocal operators as well as separability of inseparable
states. Examples are given.",http://arxiv.org/abs/2106.15576v1
NEUKONFIG: Reducing Edge Service Downtime When Repartitioning DNNs,2021-06-29T19:42:02Z,"Ayesha Abdul Majeed, Peter Kilpatrick, Ivor Spence, Blesson Varghese","Deep Neural Networks (DNNs) may be partitioned across the edge and the cloud
to improve the performance efficiency of inference. DNN partitions are
determined based on operational conditions such as network speed. When
operational conditions change DNNs will need to be repartitioned to maintain
the overall performance. However, repartitioning using existing approaches,
such as Pause and Resume, will incur a service downtime on the edge. This paper
presents the NEUKONFIG framework that identifies the service downtime incurred
when repartitioning DNNs and proposes approaches for reducing edge service
downtime. The proposed approaches are based on 'Dynamic Switching' in which,
when the network speed changes and given an existing edge-cloud pipeline, a new
edge-cloud pipeline is initialised with new DNN partitions. Incoming inference
requests are switched to the new pipeline for processing data. Two dynamic
switching scenarios are considered: when a second edge-cloud pipeline is always
running and when a second pipeline is only initialised when the network speed
changes. Experimental studies are carried out on a lab-based testbed to
demonstrate that Dynamic Switching reduces the downtime by at least an order of
magnitude when compared to a baseline using Pause and Resume that has a
downtime of 6 seconds. A trade-off in the edge service downtime and memory
required is noted. The Dynamic Switching approach that requires the same amount
of memory as the baseline reduces the edge service downtime to 0.6 seconds and
to less than 1 millisecond in the best case when twice the amount of memory as
the baseline is available.",http://arxiv.org/abs/2106.15689v1
"Thermal conductivity of intercalation, conversion, and alloying
  lithium-ion battery electrode materials as function of their state of charge",2021-06-30T13:10:14Z,"Jungwoo Shin, Sanghyeon Kim, Hoonkee Park, Ho Won Jang, David G. Cahill, Paul V. Braun","Upon insertion and extraction of lithium, materials important for
electrochemical energy storage can undergo changes in thermal conductivity
(${\Lambda}$) and elastic modulus ($\it M$). These changes are attributed to
evolution of the intrinsic thermal carrier lifetime and interatomic bonding
strength associated with structural transitions of electrode materials with
varying degrees of reversibility. Using in situ time-domain thermoreflectance
(TDTR) and picosecond acoustics, we systemically study $\Lambda$ and $\it M$ of
conversion, intercalation and alloying electrode materials during cycling. The
intercalation V$_{2}$O$_{5}$ and TiO$_{2}$ exhibit non-monotonic reversible
${\Lambda}$ and $\it M$ switching up to a factor of 1.8 (${\Lambda}$) and 1.5
($\it M$) as a function of lithium content. The conversion Fe$_{2}$O$_{3}$ and
NiO undergo irreversible decays in ${\Lambda}$ and $\it M$ upon the first
lithiation. The alloying Sb shows the largest and partially reversible order of
the magnitude switching in ${\Lambda}$ between the delithiated (18 W m$^{-1}$
K$^{-1}$) and lithiated states (<1 W m$^{-1}$ K$^{-1}$). The irreversible
${\Lambda}$ is attributed to structural degradation and pulverization resulting
from substantial volume changes during cycling. These findings provide new
understandings of the thermal and mechanical property evolution of electrode
materials during cycling of importance for battery design, and also point to
pathways for forming materials with thermally switchable properties.",http://arxiv.org/abs/2106.16040v2
"Low-Dose High-Resolution TOF-PET Using Ionization-activated Multi-State
  Low-Z Detector Media",2021-08-03T19:30:15Z,"Joao Francisco Shida, Eric Spieglan, Bernhard W. Adams, Evan Angelico, Kepler Domurat-Sousa, Andrey Elagin, Henry J. Frisch, Patrick La Riviere, Allison H. Squires","We propose PET scanners using low atomic number media that undergo a
persistent local change of state along the paths of the Compton recoil
electrons. Measurement of the individual scattering locations and angles,
deposited energies, and recoil electron directions allows using the kinematical
constraints of the 2-body Compton scattering process to perform a statistical
time-ordering of the scatterings, with a high probability of precisely
identifying where the gamma first interacted in the detector. In these cases
the Line-of-Response is measured with high resolution, determined by the
underlying physics processes and not the detector segmentation. There are
multiple such media that act through different mechanisms. As an example in
which the change of state is quantum-mechanical through a change in molecular
configuration, rather than thermodynamic, as in a bubble chamber, we present
simulations of a two-state photoswitchable organic dye, a `Switchillator', that
is activated to a fluorescent-capable state by the ionization of the recoil
electrons. The activated state is persistent, and can be optically excited
multiple times to image individual activated molecules. Energy resolution is
provided by counting the activated molecules. Location along the LOR is
implemented by large-area time-of-flight MCP-PMT photodetectors with single
photon time resolution in the tens of ps and sub-mm spatial resolution.
Simulations indicate a large reduction of dose.",http://arxiv.org/abs/2108.01715v1
"Luminosity dependence of the cyclotron line energy in 1A 0535+262
  observed by Insight-HXMT during 2020 giant outburst",2021-08-05T09:43:46Z,"L. D. Kong, S. Zhang, L. Ji, P. Reig, V. Doroshenko, A. Santangelo, R. Staubert, S. N. Zhang, R. Soria, Z. Chang, Y. P. Chen, P. J. Wang, L. Tao, J. L. Qu","We report on a detailed spectral analysis of the transient X-ray pulsar
1A~0535+262, which underwent the brightest giant outburst ever recorded for
this source from November to December 2020 with a peak luminosity of $1.2$
$\times10^{38}\ \rm erg\ s^{-1}$. Thanks to the unprecedented energy coverage
and high cadence observations provided by Insight-HXMT, we were able to find
for the first time evidence for a transition of the accretion regime. At high
luminosity, above the critical luminosity $6.7\times10^{37}$ erg s$^{-1}$, the
cyclotron absorption line energy anti-correlates with luminosity. Below the
critical luminosity, a positive correlation is observed. The 1A~0535+262
becomes, therefore, the second source after V~0332+53, which clearly shows an
anti-correlation above and transition between correlation and anti-correlation
around the critical luminosity. The evolution of both the observed CRSF line
energy and broadband X-ray continuum spectrum throughout the outburst exhibits
significant differences during the rising and fading phases: that is, for a
similar luminosity the spectral parameters take different values which results
in hysteresis patterns for several spectral parameters including the cyclotron
line energy. We argue that, similarly to V~0332+53, these changes might be
related to different geometry of the emission region in rising and declining
parts of the outburst, probably due to changes in the accretion disk structure
and its interaction with the magnetosphere of the neutron star.",http://arxiv.org/abs/2108.02485v2
OHPL: One-shot Hand-eye Policy Learner,2021-08-06T22:09:14Z,"Changjae Oh, Yik Lung Pang, Andrea Cavallaro","The control of a robot for manipulation tasks generally relies on object
detection and pose estimation. An attractive alternative is to learn control
policies directly from raw input data. However, this approach is time-consuming
and expensive since learning the policy requires many trials with robot actions
in the physical environment. To reduce the training cost, the policy can be
learned in simulation with a large set of synthetic images. The limit of this
approach is the domain gap between the simulation and the robot workspace. In
this paper, we propose to learn a policy for robot reaching movements from a
single image captured directly in the robot workspace from a camera placed on
the end-effector (a hand-eye camera). The idea behind the proposed policy
learner is that view changes seen from the hand-eye camera produced by actions
in the robot workspace are analogous to locating a region-of-interest in a
single image by performing sequential object localisation. This similar view
change enables training of object reaching policies using
reinforcement-learning-based sequential object localisation. To facilitate the
adaptation of the policy to view changes in the robot workspace, we further
present a dynamic filter that learns to bias an input state to remove
irrelevant information for an action decision. The proposed policy learner can
be used as a powerful representation for robotic tasks, and we validate it on
static and moving object reaching tasks.",http://arxiv.org/abs/2108.03318v1
"Understanding the roles of electronic effect in CO on Pt-Sn alloy
  surface via band structure measurements",2021-08-09T07:58:47Z,"Jongkeun Jung, Sungwoo Kang Laurent Nicolai, Jisook Hong, Jan Minár, Inkyung Song, Wonshik Kyung, Soohyun Cho, Beomseo Kim, Jonathan D. Denlinger, Francisco J. C. S. Aires, Eric Ehret, Philip N. Ross, Jihoon Shim, Slavomir Nemšák, Doyoung Noh, Seungwu Han, Changyoung Kim, Bongjin S. Mun","Using angle-resolved photoemission spectroscopy, we show the direct evidence
of charge transfer between adsorbed molecules and metal substrate, i.e.
chemisorption of CO on Pt(111) and Pt-Sn/Pt(111) 2x2 surfaces. The observed
band structure shows a unique signature of charge transfer as CO atoms are
adsorbed,revealing the roles of specific orbital characters participating in
the chemisorption process. As the coverage of CO increases, the degree of
charge transfer between CO and Pt shows clear difference to that of Pt-Sn. With
comparison to DFT calculation results, the observed distinct features in the
band structure are interpreted as backdonation bonding states of Pt molecular
orbital to the 2{\pi} orbital of CO. Furthermore, the change in the surface
charge concentration, measured from the Fermi surface area, shows Pt surface
has a larger charge concentration change than Pt-Sn surface upon CO adsorption.
The difference in the charge concentration change between Pt and Pt-Sn surfaces
reflects the degree of electronic effects during CO adsorption on Pt-Sn.",http://arxiv.org/abs/2108.03855v1
"Deep Joint Learning of Pathological Region Localization and Alzheimer's
  Disease Diagnosis",2021-08-10T10:06:54Z,"Changhyun Park, Heung-Il Suk","The identification of Alzheimer's disease (AD) and its early stages using
structural magnetic resonance imaging (MRI) has been attracting the attention
of researchers. Various data-driven approaches have been introduced to capture
subtle and local morphological changes of the brain accompanied by the disease
progression. One of the typical approaches for capturing subtle changes is
patch-level feature representation. However, the predetermined regions to
extract patches can limit classification performance by interrupting the
exploration of potential biomarkers. In addition, the existing patch-level
analyses have difficulty explaining their decision-making. To address these
problems, we propose the BrainBagNet with a position-based gate
(PG-BrainBagNet), a framework for jointly learning pathological region
localization and AD diagnosis in an end-to-end manner. In advance, as all scans
are aligned to a template in image processing, the position of brain images can
be represented through the 3D Cartesian space shared by the overall MRI scans.
The proposed method represents the patch-level response from whole-brain MRI
scans and discriminative brain-region from position information. Based on the
outcomes, the patch-level class evidence is calculated, and then the
image-level prediction is inferred by a transparent aggregation. The proposed
models were evaluated on the ADNI datasets. In five-fold cross-validation, the
classification performance of the proposed method outperformed that of the
state-of-the-art methods in both AD diagnosis (AD vs. normal control) and mild
cognitive impairment (MCI) conversion prediction (progressive MCI vs. stable
MCI) tasks. In addition, changes in the identified discriminant regions and
patch-level class evidence according to the patch size used for model training
are presented and analyzed.",http://arxiv.org/abs/2108.04555v1
"Large optical modulations during 2018 outburst of MAXI J1820+070 reveal
  evolution of warped accretion disc through X-ray state change",2021-08-11T21:11:44Z,"Jessymol K. Thomas, Philip A. Charles, David A. H. Buckley, Marissa M. Kotze, Jean-Pierre Lasota, Stephen B. Potter, James F. Steiner, John A. Paice","The black-hole X-ray transient MAXI J1820+07 (=ASSASN-18ey) discovered in
March 2018 was one of the optically brightest ever seen, which has resulted in
very detailed optical outburst light-curves being obtained. We combine them
here with X-ray and radio light-curves to show the major geometric changes the
source undergoes. We present a detailed temporal analysis that reveals the
presence of remarkably high amplitude (>0.5 mag) modulations, which evolve from
the superhump (16.87 h) period towards the presumed orbital (16.45 h) period.
These modulations appear ~87d after the outburst began, and follow the
Swift/BAT hard X-ray light-curve, which peaks 4 days before the radio flare and
jet ejection, when the source undergoes a rapid hard to soft state transition.
The optical modulation then moves closer to the orbital period, with a light
curve peak that drifts slowly in orbital phase from ~0.8 to ~0.3 during the
soft state. We propose that the unprecedentedly large amplitude modulation
requires a warp in the disc in order to provide a large enough radiating area,
and for the warp to be irradiation-driven. Its sudden turn-on implies a change
in the inner disc geometry that raises the hard X-ray emitting component to a
height where it can illuminate the warped outer disc regions.",http://arxiv.org/abs/2108.05447v2
Flow-Aware Platoon Formation of Connected Automated Vehicles,2021-08-12T04:45:26Z,"Soomin Woo, Alexander Skabardonis","Connected Automated Vehicles (CAVs) bring promise of increasing traffic
capacity and energy efficiency by forming platoons with short headways on the
road. However at low CAV penetration, the capacity gain will be small because
the CAVs that randomly enter the road will be sparsely distributed, diminishing
the probability of forming long platoons. Many researchers propose to solve
this issue by platoon organization strategies, where the CAVs search for other
CAVs on the road and change lanes if necessary to form longer platoons.
However, the current literature does not analyze a potential risk of platoon
organization in disrupting the flow and reducing the capacity by inducing more
lane changes. In this research, we use driving model of Cooperative Adaptive
Cruise Control (CACC) vehicles and human-driven vehicles that are validated
with field experiments and find that platoon organization can indeed drop the
capacity with more lane changes. But when the traffic demand is well below
capacity, platoon organization forms longer CAV platoons without reducing the
flow. Based on this finding, we develop the Flow-Aware platoon organization
strategy, where the CAVs perform platoon organization conditionally on the
local traffic state, i.e., a low flow and a high speed. We simulate the
Flow-Aware platoon organization on a realistic freeway network and show that
the CAVs successfully form longer platoons, while ensuring a maximal traffic
flow.",http://arxiv.org/abs/2108.05530v1
"Training for the Future: A Simple Gradient Interpolation Loss to
  Generalize Along Time",2021-08-15T11:20:10Z,"Anshul Nasery, Soumyadeep Thakur, Vihari Piratla, Abir De, Sunita Sarawagi","In several real world applications, machine learning models are deployed to
make predictions on data whose distribution changes gradually along time,
leading to a drift between the train and test distributions. Such models are
often re-trained on new data periodically, and they hence need to generalize to
data not too far into the future. In this context, there is much prior work on
enhancing temporal generalization, e.g. continuous transportation of past data,
kernel smoothed time-sensitive parameters and more recently, adversarial
learning of time-invariant features. However, these methods share several
limitations, e.g, poor scalability, training instability, and dependence on
unlabeled data from the future. Responding to the above limitations, we propose
a simple method that starts with a model with time-sensitive parameters but
regularizes its temporal complexity using a Gradient Interpolation (GI) loss.
GI allows the decision boundary to change along time and can still prevent
overfitting to the limited training time snapshots by allowing task-specific
control over changes along time. We compare our method to existing baselines on
multiple real-world datasets, which show that GI outperforms more complicated
generative and adversarial approaches on the one hand, and simpler gradient
regularization methods on the other.",http://arxiv.org/abs/2108.06721v2
Task-Sensitive Concept Drift Detector with Constraint Embedding,2021-08-16T09:10:52Z,"Andrea Castellani, Sebastian Schmitt, Barbara Hammer","Detecting drifts in data is essential for machine learning applications, as
changes in the statistics of processed data typically has a profound influence
on the performance of trained models. Most of the available drift detection
methods are either supervised and require access to the true labels during
inference time, or they are completely unsupervised and aim for changes in
distributions without taking label information into account. We propose a novel
task-sensitive semi-supervised drift detection scheme, which utilizes label
information while training the initial model, but takes into account that
supervised label information is no longer available when using the model during
inference. It utilizes a constrained low-dimensional embedding representation
of the input data. This way, it is best suited for the classification task. It
is able to detect real drift, where the drift affects the classification
performance, while it properly ignores virtual drift, where the classification
performance is not affected by the drift. In the proposed framework, the actual
method to detect a change in the statistics of incoming data samples can be
chosen freely. Experimental evaluation on nine benchmarks datasets, with
different types of drift, demonstrates that the proposed framework can reliably
detect drifts, and outperforms state-of-the-art unsupervised drift detection
approaches.",http://arxiv.org/abs/2108.06980v3
"Detection of nearly periodic spin period reversals in Vela X-1 on long
  time-scales: inkling of solar-like cycle in the donor star?",2021-08-16T14:05:37Z,"Amar Deo Chandra, Jayashree Roy, P. C. Agrawal, Manojendu Choudhury","We explore the long-term evolution of the spin period of the High Mass X-ray
Binary (HMXB) pulsar Vela X-1 over a period of 46 yr. Our analysis indicates
nearly periodic variations in the spin period of the pulsar on time-scales of
about 5.9 yr. There is suggestion of an overall spin-down behaviour of the
pulsar though it is noticed that the source appears to stay near its
equilibrium period 283.4 s since MJD 51000, with rather erratic
spin-up/spin-down episodes around this value. Our study suggests nearly cyclic
turnover in the spin behaviour of the pulsar from spin-up to spin-down regimes
on time-scales of about 17-19 yr. To our knowledge this is the first report of
periodic variation in the spin behaviour of a wind-fed accreting pulsar. We
also observe erratic episodes of spin-up and spin-down behaviour on relatively
shorter time-scales which is a well known archetype of this wind-fed X-ray
pulsar. We investigate whether nearly periodic long-term spin period changes in
the pulsar can be explained by using known mechanisms of torque reversals in
the accretion powered neutron stars. It appears that changes in the accretion
environment of the pulsar using current ideas can probably lead to long-term
spin period changes in this X-ray pulsar.",http://arxiv.org/abs/2108.07097v1
"Tailoring the band structure of twisted double bilayer graphene with
  pressure",2021-08-17T12:29:28Z,"Bálint Szentpéteri, Peter Rickhaus, Folkert K. de Vries, Albin Márffy, Bálint Fülöp, Endre Tóvári, Kenji Watanabe, Takashi Taniguchi, Andor Kormányos, Szabolcs Csonka, Péter Makk","Twisted two-dimensional structures open new possibilities in band structure
engineering. At magic twist angles, flat bands emerge, which give a new drive
to the field of strongly correlated physics. In twisted double bilayer graphene
dual gating allows changing the Fermi level and hence the electron density and
also allows tuning the interlayer potential, giving further control over band
gaps. Here, we demonstrate that by applying hydrostatic pressure, an additional
control of the band structure becomes possible due to the change of tunnel
couplings between the layers. We find that the flat bands and the gaps
separating them can be drastically changed by pressures up to 2 GPa, in good
agreement with our theoretical simulations. Furthermore, our measurements
suggest that in finite magnetic field due to pressure a topologically
non-trivial band gap opens at the charge neutrality point at zero displacement
field.",http://arxiv.org/abs/2108.07585v3
"Towards Deep and Efficient: A Deep Siamese Self-Attention Fully
  Efficient Convolutional Network for Change Detection in VHR Images",2021-08-18T14:02:38Z,"Hongruixuan Chen, Chen Wu, Bo Du","Recently, FCNs have attracted widespread attention in the CD field. In
pursuit of better CD performance, it has become a tendency to design deeper and
more complicated FCNs, which inevitably brings about huge numbers of parameters
and an unbearable computational burden. With the goal of designing a quite deep
architecture to obtain more precise CD results while simultaneously decreasing
parameter numbers to improve efficiency, in this work, we present a very deep
and efficient CD network, entitled EffCDNet. In EffCDNet, to reduce the
numerous parameters associated with deep architecture, an efficient convolution
consisting of depth-wise convolution and group convolution with a channel
shuffle mechanism is introduced to replace standard convolutional layers. In
terms of the specific network architecture, EffCDNet does not use mainstream
UNet-like architecture, but rather adopts the architecture with a very deep
encoder and a lightweight decoder. In the very deep encoder, two very deep
siamese streams stacked by efficient convolution first extract two highly
representative and informative feature maps from input image-pairs.
Subsequently, an efficient ASPP module is designed to capture multi-scale
change information. In the lightweight decoder, a recurrent criss-cross
self-attention (RCCA) module is applied to efficiently utilize non-local
similar feature representations to enhance discriminability for each pixel,
thus effectively separating the changed and unchanged regions. Moreover, to
tackle the optimization problem in confused pixels, two novel loss functions
based on information entropy are presented. On two challenging CD datasets, our
approach outperforms other SOTA FCN-based methods, with only benchmark-level
parameter numbers and quite low computational overhead.",http://arxiv.org/abs/2108.08157v1
"The changing dynamics of HIV/AIDS during the Covid-19 pandemic in the
  Rohingya refugee camps in Bangladesh a call for action",2021-08-22T11:30:59Z,"Muhammad Anwar Hossain, Iryna Zablotska-Manos","COVID-19 pandemic has affected each and every country's health service and
plunged refugees into the most desperate conditions. The plight of Rohingya
refugees is among the harshest. It has severely affected their existing HIV/STI
prevention and management services and further increased the risk of violence
and onward HIV transmission within the camps. In this commentary, we discuss
the context and the changing dynamics of HIV/AIDS during COVID-19 among the
Rohingya refugee community in Bangladesh. What we currently observe is the
worst crisis in the Rohingya refugee camps thus far. Firstly, because of being
displaced, Rohingya refugees have increased vulnerability to HIV, as well as to
STIs and other poor health outcomes. Secondly, for the same reason, they have
inadequate access to HIV testing treatment and care. Not only because of their
refugee status but also because of the poor capacity of the host country to
provide services. Thirdly, a host of complex economic, socio-cultural and
behavioural factors exacerbate their dire situation with access to HIV testing,
treatment and care. And finally, the advent of the COVID-19 pandemic has
changed priorities in all societies, including the refugee camps. In the
context of the unfolding COVID-19 crisis, more emphasis is placed on COVID-19
rather than other health issues, which exacerbates the dire situation with HIV
detection, management, and prevention among Rohingya refugees. Despite the
common crisis experienced by most countries around the world, the international
community has an obligation to work together to improve the life, livelihood,
and health of those who are most vulnerable. Rohingya refugees are among them.",http://arxiv.org/abs/2108.09690v1
"Welfare Effects of Labor Income Tax Changes on Married Couples: A
  Sufficient Statistics Approach",2021-08-23T07:32:19Z,Egor Malkov,"This paper develops a framework for assessing the welfare effects of labor
income tax changes on married couples. I build a static model of couples' labor
supply that features both intensive and extensive margins and derive a
tractable expression that delivers a transparent understanding of how labor
supply responses, policy parameters, and income distribution affect the
reform-induced welfare gains. Using this formula, I conduct a comparative
welfare analysis of four tax reforms implemented in the United States over the
last four decades, namely the Tax Reform Act of 1986, the Omnibus Budget
Reconciliation Act of 1993, the Economic Growth and Tax Relief Reconciliation
Act of 2001, and the Tax Cuts and Jobs Act of 2017. I find that these reforms
created welfare gains ranging from -0.16 to 0.62 percent of aggregate labor
income. A sizable part of the gains is generated by the labor force
participation responses of women. Despite three reforms resulted in aggregate
welfare gains, I show that each reform created both winners and losers.
Furthermore, I uncover two patterns in the relationship between welfare gains
and couples' labor income. In particular, the reforms of 1986 and 2017 display
a monotonically increasing relationship, while the other two reforms
demonstrate a U-shaped pattern. Finally, I characterize the bias in welfare
gains resulting from the assumption about a linear tax function. I consider a
reform that changes tax progressivity and show that the linearization bias is
given by the ratio between the tax progressivity parameter and the inverse
elasticity of taxable income. Quantitatively, it means that linearization
overestimates the welfare effects of the U.S. tax reforms by 3.6-18.1%.",http://arxiv.org/abs/2108.09981v2
"Manipulation and braiding of Weyl nodes using symmetry-constrained phase
  transitions",2021-08-23T18:00:04Z,"Siyu Chen, Adrien Bouhon, Robert-Jan Slager, Bartomeu Monserrat","Weyl semimetals are arguably the most paradigmatic form of a gapless
topological phase. While the stability of Weyl nodes, as quantified by their
topological charge, has been extensively investigated, recent interest has
shifted to the manipulation of the location of these Weyl nodes for non-Abelian
braiding. To accomplish this braiding it is necessary to drive significant Weyl
node motion using realistic experimental parameter changes. We show that a
family of phase transitions characterized by certain symmetry constraints
impose that the Weyl nodes have to reorganise by a large amount, shifting from
one high symmetry plane to another. Additionally, for a subset of pairs of
nodes with nontrivial Euler class topology, this reorganization can only occur
through a braiding process with adjacent nodes. As a result, the Weyl nodes are
forced to move a large distance across the Brillouin zone and to braid, all
driven by small temperature changes, a process we illustrate with
Cd$_2$Re$_2$O$_7$. Our work opens up routes to readily manipulate Weyl nodes
using only slight external parameter changes, paving the way for the practical
realization of reciprocal space braiding.",http://arxiv.org/abs/2108.10330v2
The Case for Task Sampling based Learning for Cluster Job Scheduling,2021-08-24T01:18:00Z,"Akshay Jajoo, Y. Charlie Hu, Xiaojun Lin, Nan Deng","The ability to accurately estimate job runtime properties allows a scheduler
to effectively schedule jobs. State-of-the-art online cluster job schedulers
use history-based learning, which uses past job execution information to
estimate the runtime properties of newly arrived jobs. However, with fast-paced
development in cluster technology (in both hardware and software) and changing
user inputs, job runtime properties can change over time, which lead to
inaccurate predictions. In this paper, we explore the potential and limitation
of real-time learning of job runtime properties, by proactively sampling and
scheduling a small fraction of the tasks of each job. Such a
task-sampling-based approach exploits the similarity among runtime properties
of the tasks of the same job and is inherently immune to changing job behavior.
Our study focuses on two key questions in comparing task-sampling-based
learning (learning in space) and history-based learning (learning in time): (1)
Can learning in space be more accurate than learning in time? (2) If so, can
delaying scheduling the remaining tasks of a job till the completion of sampled
tasks be more than compensated by the improved accuracy and result in improved
job performance? Our analytical and experimental analysis of 3 production
traces with different skew and job distribution shows that learning in space
can be substantially more accurate. Our simulation and testbed evaluation on
Azure of the two learning approaches anchored in a generic job scheduler using
3 production cluster job traces shows that despite its online overhead,
learning in space reduces the average Job Completion Time (JCT) by 1.28x,
1.56x, and 1.32x compared to the prior-art history-based predictor.",http://arxiv.org/abs/2108.10464v2
"Extracting Quantitative Dielectric Properties from Pump-Probe
  Spectroscopy",2021-08-24T09:41:22Z,"Arjun Ashoka, Ronnie R. Tamming, Aswathy V. Girija, Hope Bretscher, Sachin Dev Verma, Shang-Da Yang, Chih-Hsuan Lu, Justin M. Hodgkiss, David Ritchie, Chong Chen, Charles G. Smith, Christoph Schnedermann, Michael B. Price, Kai Chen, Akshay Rao","Optical pump-probe spectroscopy is a powerful tool for the study of
non-equilibrium electronic dynamics and finds wide applications across a range
of fields, from physics and chemistry to material science and biology. However,
a shortcoming of conventional pump-probe spectroscopy is that photoinduced
changes in transmission, reflection and scattering can simultaneously
contribute to the measured differential spectra, leading to ambiguities in
assigning the origin of spectral signatures and ruling out quantitative
interpretation of the spectra. Ideally, these methods would measure the
underlying dielectric function (or the complex refractive index) which would
then directly provide quantitative information on the transient excited state
dynamics free of these ambiguities. Here we present and test a model
independent route to transform differential transmission or reflection spectra,
measured via conventional optical pump-probe spectroscopy, to changes in the
quantitative transient dielectric function. We benchmark this method against
changes in the real refractive index measured using time-resolved Frequency
Domain Interferometry in prototypical inorganic and organic semiconductor
films. Our methodology can be applied to existing and future pump-probe data
sets, allowing for an unambiguous and quantitative characterisation of the
transient photoexcited spectra of materials. This in turn will accelerate the
adoption of pump-probe spectroscopy as a facile and robust materials
characterisation and screening tool.",http://arxiv.org/abs/2108.10605v1
"A perspective magnetic bed comprising Gd alloy multi-microwires for
  energy-efficient magnetic refrigeration",2021-08-25T19:31:00Z,"Hongxian Shen, Lin Luo, Sida Jiang, Jingshun Liu, Yanfen Liu, Yongjiang Huang, Lunyong Zhang, Jianfei Sun, Hillary Belliveau, Manh-Huong Phan","We have designed a new magnetic bed structure with desirable table-like
magnetocaloric effect (MCE) by using three kinds of soft ferromagnetic Gd-Al-Co
microwire arrays with different Curie temperatures ($T_C$). The $T_C$ interval
of these three wires is ~10 K and the designed new structure named Sample A.
This sample shows a smooth table-like magnetic entropy change ($\Delta S_M$) at
high applied field change ($\mu_0 \Delta H=5 T$) ranging from ~92 K to ~107 K.
The maximum entropy change ($-\Delta S_M^{\rm max}$) and refrigerant capacity
(RC) for Sample A at $\mu_0 \Delta H=5 T$ are calculated to be ~9.42
Jkg$^{-1}$K$^{-1}$ and ~676 Jkg$^{-1}$. The calculated curves of $-\Delta
S_M(T)$ and the corresponding experimental data match well with each other,
suggesting that the desirable magnetocaloric properties of the microwire arrays
can be designed. Simulation shows that the RC values of the designed systems
increase when increasing the interval of $T_C$. The table-like MCE and the
enhanced heat-transfer efficiency due to the enhanced surface areas of the
microwires make this newly designed magnetic bed very promising for use in
energy-efficient magnetic refrigerators.",http://arxiv.org/abs/2108.11446v1
"Effects of minor alloying on the mechanical properties of Al based
  metallic glasses",2021-08-26T20:38:28Z,"Vrishank Jambur, Chaiyapat Tangpatjaroen, Jianqi Xi, Jirameth Tarnsangpradit, Meng Gao, Howard Sheng, John Perepezko, Izabela Szlufarska","Minor alloying is widely used to control mechanical properties of metallic
glasses (MGs). The present understanding of how a small amount of alloying
element changes strength is that the additions lead to more efficient packing
of atoms and increased local topological order, which then increases the
barrier for shear transformations and the resistance to plastic deformation.
Here, we discover that minor alloying can improve the strength of MGs by
increasing the chemical bond strength alone and show that this strengthening is
distinct from changes in topological order. The results were obtained using
Al-Sm based MGs minor alloyed with transition metals (TMs). The addition of TMs
led to an increase in the hardness of the MGs which, however, could not be
explained based on changes in the topological ordering in the structure.
Instead we found that it was the strong bonding between TM and Al atoms which
led to a higher resistance to shear transformation that resulted in higher
strength and hardness, while the topology around the TM atoms had no influence
on their mechanical response. This finding demonstrates that the effects of
topology and chemistry on mechanical properties of MGs are independent of each
other and that they should be understood as separate, sometimes competing
mechanisms of strengthening. This understanding lays a foundation for design of
MGs with improved mechanical properties.",http://arxiv.org/abs/2108.12028v1
"Economic and environmental impacts of ballast water management on Small
  Island Developing States and Least Developed Countries",2021-08-30T15:31:36Z,"Zhaojun Wang, Amanda M. Countryman, James J. Corbett, Mandana Saebi","The Ballast Water Management Convention can decrease the introduction risk of
harmful aquatic organisms and pathogens, yet the Convention increases shipping
costs and causes subsequent economic impacts. This paper examines whether the
Convention generates disproportionate invasion risk reduction results and
economic impacts on Small Island Developing States (SIDS) and Least Developed
Countries (LDCs). Risk reduction is estimated with an invasion risk assessment
model based on a higher-order network, and the effects of the regulation on
national economies and trade are estimated with an integrated shipping cost and
computable general equilibrium modeling framework. Then we use the Lorenz curve
to examine if the regulation generates risk or economic inequality among
regions. Risk reduction ratios of all regions (except Singapore) are above 99%,
which proves the effectiveness of the Convention. The Gini coefficient of 0.66
shows the inequality in risk changes relative to income levels among regions,
but risk reductions across all nations vary without particularly high risks for
SIDS and LDCs than for large economies. Similarly, we reveal inequality in
economic impacts relative to income levels (the Gini coefficient is 0.58), but
there is no evidence that SIDS and LDCs are disproportionately impacted
compared to more developed regions. Most changes in GDP, real exports, and real
imports of studied regions are minor (smaller than 0.1%). However, there are
more noteworthy changes for select sectors and trade partners including Togo,
Bangladesh, and Dominican Republic, whose exports may decrease for textiles and
metal and chemicals. We conclude the Convention decreases biological invasion
risk and does not generate disproportionate negative impacts on SIDS and LDCs.",http://arxiv.org/abs/2108.13315v1
"On the Origins and Relevance of the Equal Transit Time Fallacy to
  Explain Lift",2021-10-02T00:06:58Z,Graham Wild,"Recently, aerodynamics syllabi have changed in high schools, pilot ground
training, and even undergraduate physics. In contrast, there has been no change
in the basic theory taught to aeronautical or aerospace engineers. What has
changed is technology, both experimentally and computationally. The internet
and social media have also empowered citizen science such that the deficiencies
in the legacy physics education around flight and lift are well known. The
long-standing equal transit time (ETT) theory to explain lift has been proven
false. If incorrect, why was it ever taught? Through a historical analysis of
relevant fluid and aerodynamics literature, this study attempts to explain why
ETT theory is part of our collectively lower-level cognitive understanding of
lift and flight. It was found that in 1744 D'Alembert himself assumed this to
be a feature of moving fluids, and while this initial intuition (ETT 1.0) was
incorrect, the property of ETT (ETT 2.0) was derived in 1752 when applying
Newton's laws of motion to fluids. This incorrect result was independently
confirmed in 1757 by Euler! The conclusion is that an over simplified treatment
of fluids predicts ETT, along with no lift and drag. This then leads to the
open question, can ETT be taught at an appropriately low level as an
explanation for lift?",http://arxiv.org/abs/2110.00690v1
A slim disc approach to external photoevaporation of discs,2021-10-04T18:00:02Z,"James E Owen, Noumahn Altaf","The photoevaporation of protoplanetary discs by nearby massive stars present
in their birth cluster plays a vital role in their evolution. Previous
modelling assumes that the disc behaves like a classical Keplerian accretion
disc out to a radius where the photoevaporative outflow is launched. There is
then an abrupt change in the angular velocity profile, and the outflow is
modelled by forcing the fluid parcels to conserve their specific angular
momenta. Instead, we model externally photoevaporating discs using the slim
disc formalism. The slim disc approach self consistently includes the advection
of radial and angular momentum as well as angular momentum redistribution by
internal viscous torques. Our resulting models produce a smooth transition from
a rotationally supported Keplerian disc to a photoevaporative driven outflow,
where this transition typically occurs over ~4-5 scale heights. The penetration
of UV photons predominately sets the radius of the transition and the
viscosity's strength plays a minor role. By studying the entrainment of dust
particles in the outflow, we find a rapid change in the dust size and surface
density distribution in the transition region due to the steep gas density
gradients present. This rapid change in the dust properties leaves a
potentially observable signature in the continuum spectral index of the disc at
mm wavelengths. Using the slim disc formalism in future evolutionary
calculations will reveal how both the gas and dust evolves in their outer
regions and the observable imprints of the external photoevaporation process.",http://arxiv.org/abs/2110.01630v1
"Design and Characterization of a 3D-printed Pneumatically-driven
  Bistable Valve with Tunable Characteristics",2021-10-04T23:25:10Z,"Sihan Wang, Liang He, Perla Maiolino","Although research studies in pneumatic soft robots develop rapidly, most
pneumatic actuators are still controlled by rigid valves and conventional
electronics. The existence of these rigid, electronic components sacrifices the
compliance and adaptability of soft robots.} Current electronics-free valve
designs based on soft materials are facing challenges in behaviour consistency,
design flexibility, and fabrication complexity. Taking advantages of soft
material 3D printing, this paper presents a new design of a bi-stable pneumatic
valve, which utilises two soft, pneumatically-driven, and
symmetrically-oriented conical shells with structural bistability to stabilise
and regulate the airflow. The critical pressure required to operate the valve
can be adjusted by changing the design features of the soft bi-stable
structure. Multi-material printing simplifies the valve fabrication, enhances
the flexibility in design feature optimisations, and improves the system
repeatability. In this work, both a theoretical model and physical experiments
are introduced to examine the relationships between the critical operating
pressure and the key design features. Results with valve characteristic tuning
via material stiffness changing show better effectiveness compared to the
change of geometry design features (demonstrated largest tunable critical
pressure range from 15.3 to 65.2 kPa and fastest response time $\leq$ 1.8 s.",http://arxiv.org/abs/2110.01743v1
"Distribution Mismatch Correction for Improved Robustness in Deep Neural
  Networks",2021-10-05T11:36:25Z,"Alexander Fuchs, Christian Knoll, Franz Pernkopf","Deep neural networks rely heavily on normalization methods to improve their
performance and learning behavior. Although normalization methods spurred the
development of increasingly deep and efficient architectures, they also
increase the vulnerability with respect to noise and input corruptions. In most
applications, however, noise is ubiquitous and diverse; this can often lead to
complete failure of machine learning systems as they fail to cope with
mismatches between the input distribution during training- and test-time. The
most common normalization method, batch normalization, reduces the distribution
shift during training but is agnostic to changes in the input distribution
during test time. This makes batch normalization prone to performance
degradation whenever noise is present during test-time. Sample-based
normalization methods can correct linear transformations of the activation
distribution but cannot mitigate changes in the distribution shape; this makes
the network vulnerable to distribution changes that cannot be reflected in the
normalization parameters. We propose an unsupervised non-parametric
distribution correction method that adapts the activation distribution of each
layer. This reduces the mismatch between the training and test-time
distribution by minimizing the 1-D Wasserstein distance. In our experiments, we
empirically show that the proposed method effectively reduces the impact of
intense image corruptions and thus improves the classification performance
without the need for retraining or fine-tuning the model.",http://arxiv.org/abs/2110.01955v1
"Runtime Interchange for Adaptive Re-use of Intelligent Cyber-Physical
  System Controllers",2021-09-24T01:08:25Z,"Hammond Pearce, Xin Yang, Srinivas Pinisetty, Partha S. Roop","Cyber-Physical Systems (CPSs) such as those found within autonomous vehicles
are increasingly adopting Artificial Neural Network (ANN)-based controllers. To
ensure the safety of these controllers, there is a spate of recent activity to
formally verify the ANN-based designs. There are two challenges with these
approaches: (1) The verification of such systems is difficult and time
consuming. (2) These verified controllers are not able to adapt to frequent
requirements changes, which are typical in situations like autonomous driving.
This raises the question: how can trained and verified controllers, which have
gone through expensive training and verification processes, be re-used to deal
with requirement changes? This paper addresses this challenge for the first
time by proposing a new framework that is capable of dealing with requirement
changes at runtime through a mechanism we term runtime interchange. Our
approach functions via a continual exchange and selection process of multiple
pre-verified controllers. It represents a key step on the way to
component-oriented engineering for intelligent designs, as it preserves the
behaviours of the original controllers while introducing additional
functionality. To demonstrate the efficacy of our approach we utilise an
existing autonomous driving case study as well as a set of smaller benchmarks.
These show that introduced overheads are extremely minimal and that the
approach is very scalable.",http://arxiv.org/abs/2110.01974v1
Haemodynamic analysis using multiphase flow dynamics in tubular lesions,2021-10-05T20:55:49Z,"Konstantinos G. Lyras, Jack Lee","Background and Objective: The role of red blood cell dynamics is emphasised
in certain cardiovascular diseases, and thus needs to be closely studied. A
multiphase model of blood flow allows the resolution of locally varying density
of red blood cells within a complex vessel geometrical domain, and haemodynamic
consequences of such build up. Methods: A novel computational fluid dynamics
solver for simulating multiphase flows is used for modelling blood flow using
level set for a sharp interface representation. Single-phase simulations and
reduced order models are used for pressure comparisons. The new solver is used
for numerically studying AHA type B lesions. The impact of hematocrit and
degree of stenosis on the haemodynamics of coronary arteries is investigated.
Results: The comparisons with single-phase flow simulations indicate
differences in pressure when considering red blood cell aggregation. Multiphase
simulations provide slightly lower pressure drop for the same stenosis severity
compared to the single-phase simulations. Secondary flow patterns and the
interactions between the two phases leads to the red blood cell aggregation at
the end of the diastole cycle, which significantly changes the red blood cell
distribution, the shear stresses and velocity in tubular lesions. Conclusions:
Neither pressure drop nor mean velocity are not strongly changed in the
multiphase modelling, but particle buildup significantly changes which is only
revealed by the multiphase approach.",http://arxiv.org/abs/2110.02356v1
8-bit Optimizers via Block-wise Quantization,2021-10-06T15:43:20Z,"Tim Dettmers, Mike Lewis, Sam Shleifer, Luke Zettlemoyer","Stateful optimizers maintain gradient statistics over time, e.g., the
exponentially smoothed sum (SGD with momentum) or squared sum (Adam) of past
gradient values. This state can be used to accelerate optimization compared to
plain stochastic gradient descent but uses memory that might otherwise be
allocated to model parameters, thereby limiting the maximum size of models
trained in practice. In this paper, we develop the first optimizers that use
8-bit statistics while maintaining the performance levels of using 32-bit
optimizer states. To overcome the resulting computational, quantization, and
stability challenges, we develop block-wise dynamic quantization. Block-wise
quantization divides input tensors into smaller blocks that are independently
quantized. Each block is processed in parallel across cores, yielding faster
optimization and high precision quantization. To maintain stability and
performance, we combine block-wise quantization with two additional changes:
(1) dynamic quantization, a form of non-linear optimization that is precise for
both large and small magnitude values, and (2) a stable embedding layer to
reduce gradient variance that comes from the highly non-uniform distribution of
input tokens in language models. As a result, our 8-bit optimizers maintain
32-bit performance with a small fraction of the memory footprint on a range of
tasks, including 1.5B parameter language modeling, GLUE finetuning, ImageNet
classification, WMT'14 machine translation, MoCo v2 contrastive ImageNet
pretraining+finetuning, and RoBERTa pretraining, without changes to the
original optimizer hyperparameters. We open-source our 8-bit optimizers as a
drop-in replacement that only requires a two-line code change.",http://arxiv.org/abs/2110.02861v2
Towards Continual Knowledge Learning of Language Models,2021-10-07T07:00:57Z,"Joel Jang, Seonghyeon Ye, Sohee Yang, Joongbo Shin, Janghoon Han, Gyeonghun Kim, Stanley Jungkyu Choi, Minjoon Seo","Large Language Models (LMs) are known to encode world knowledge in their
parameters as they pretrain on a vast amount of web corpus, which is often
utilized for performing knowledge-dependent downstream tasks such as question
answering, fact-checking, and open dialogue. In real-world scenarios, the world
knowledge stored in the LMs can quickly become outdated as the world changes,
but it is non-trivial to avoid catastrophic forgetting and reliably acquire new
knowledge while preserving invariant knowledge. To push the community towards
better maintenance of ever-changing LMs, we formulate a new continual learning
(CL) problem called Continual Knowledge Learning (CKL). We construct a new
benchmark and metric to quantify the retention of time-invariant world
knowledge, the update of outdated knowledge, and the acquisition of new
knowledge. We adopt applicable recent methods from literature to create several
strong baselines. Through extensive experiments, we find that CKL exhibits
unique challenges that are not addressed in previous CL setups, where parameter
expansion is necessary to reliably retain and learn knowledge simultaneously.
By highlighting the critical causes of knowledge forgetting, we show that CKL
is a challenging and important problem that helps us better understand and
train ever-changing LMs. The benchmark datasets, evaluation script, and
baseline code to reproduce our results are available at
https://github.com/joeljang/continual-knowledge-learning.",http://arxiv.org/abs/2110.03215v4
"Is the orbit of the exoplanet WASP-43b really decaying? TESS and MuSCAT2
  observations confirm no detection",2021-10-10T11:07:57Z,"Z. Garai, T. Pribulla, H. Parviainen, E. Pallé, A. Claret, L. Szigeti, V. J. S. Béjar, N. Casasayas-Barris, N. Crouzet, A. Fukui, G. Chen, K. Kawauchi, P. Klagyivik, S. Kurita, N. Kusakabe, J. P. de Leon, J. H. Livingston, R. Luque, M. Mori, F. Murgas, N. Narita, T. Nishiumi, M. Oshagh, Gy. M. Szabó, M. Tamura, Y. Terada, N. Watanabe","Up to now, WASP-12b is the only hot Jupiter confirmed to have a decaying
orbit. The case of WASP-43b is still under debate. Recent studies preferred or
ruled out the orbital decay scenario, but further precise transit timing
observations are needed to definitively confirm or refute the period change of
WASP-43b. This possibility is given by the Transiting Exoplanet Survey
Satellite (TESS) space telescope. In this work we used the available TESS data,
multi-color photometry data obtained with the Multicolor Simultaneous Camera
for studying Atmospheres of Transiting exoplanets 2 (MuSCAT2) and literature
data to calculate the period change rate of WASP-43b and to improve its
precision, and to refine the parameters of the WASP-43 planetary system. Based
on the observed-minus-calculated data of 129 mid-transit times in total,
covering a time baseline of about 10 years, we obtained an improved period
change rate of $\dot{P} = -0.6 \pm 1.2$ ms yr$^{-1}$ that is consistent with a
constant period well within $1\sigma$. We conclude that new TESS and MuSCAT2
observations confirm no detection of WASP-43b orbital decay.",http://arxiv.org/abs/2110.04761v1
"Asymmetry in flavour changing electromagnetic transitions of vector-like
  quarks",2021-10-11T17:59:53Z,Shyam Balaji,"Vector-like quarks have been of interest for a plethora of experimentally
motivated reasons and have come under increased investigation recently due to
their inclusion to the Standard Model (SM) appreciably improving global fits to
several flavour physics and precision electroweak measurements. The addition of
vector-like quark singlets breaks the unitarity of the
Cabibbo-Kobayashi-Maskawa (CKM) matrix and enables tree-level flavour changing
neutral (FCN) vertices. The resulting radiative flavour changing decays of
these particles through the electromagnetic transition dipole moment are a key
means to study their properties and search for them at experiments like the
Large Hadron Collider (LHC). Despite these radiative decays providing such a
clean experimental signature, an explicit analytical study of the branching
ratios and $CP$ violation resulting from these loop level processes has thus
far evaded attention. We provide the formulation for the decay rates and $CP$
asymmetry resulting from a combination of the imaginary components of the loop
integrals and complex phases in the quark mixing matrix. We then apply our
analytical results to study phenomenology of these states for several global
fits pertaining to vector-like isosinglets $t'$ and $b'$. We find that clean
collider signatures and polarisation observables can be generated for both $t'$
and $b'$.",http://arxiv.org/abs/2110.05473v2
Updating Street Maps using Changes Detected in Satellite Imagery,2021-10-13T02:50:26Z,"Favyen Bastani, Songtao He, Satvat Jagwani, Mohammad Alizadeh, Hari Balakrishnan, Sanjay Chawla, Sam Madden, Mohammad Amin Sadeghi","Accurately maintaining digital street maps is labor-intensive. To address
this challenge, much work has studied automatically processing geospatial data
sources such as GPS trajectories and satellite images to reduce the cost of
maintaining digital maps. An end-to-end map update system would first process
geospatial data sources to extract insights, and second leverage those insights
to update and improve the map. However, prior work largely focuses on the first
step of this pipeline: these map extraction methods infer road networks from
scratch given geospatial data sources (in effect creating entirely new maps),
but do not address the second step of leveraging this extracted information to
update the existing digital map data. In this paper, we first explain why
current map extraction techniques yield low accuracy when extended to update
existing maps. We then propose a novel method that leverages the progression of
satellite imagery over time to substantially improve accuracy. Our approach
first compares satellite images captured at different times to identify
portions of the physical road network that have visibly changed, and then
updates the existing map accordingly. We show that our change-based approach
reduces map update error rates four-fold.",http://arxiv.org/abs/2110.06456v1
"Sound and Complete Neural Network Repair with Minimality and Locality
  Guarantees",2021-10-14T19:40:40Z,"Feisi Fu, Wenchao Li","We present a novel methodology for repairing neural networks that use ReLU
activation functions. Unlike existing methods that rely on modifying the
weights of a neural network which can induce a global change in the function
space, our approach applies only a localized change in the function space while
still guaranteeing the removal of the buggy behavior. By leveraging the
piecewise linear nature of ReLU networks, our approach can efficiently
construct a patch network tailored to the linear region where the buggy input
resides, which when combined with the original network, provably corrects the
behavior on the buggy input. Our method is both sound and complete -- the
repaired network is guaranteed to fix the buggy input, and a patch is
guaranteed to be found for any buggy input. Moreover, our approach preserves
the continuous piecewise linear nature of ReLU networks, automatically
generalizes the repair to all the points including other undetected buggy
inputs inside the repair region, is minimal in terms of changes in the function
space, and guarantees that outputs on inputs away from the repair region are
unaltered. On several benchmarks, we show that our approach significantly
outperforms existing methods in terms of locality and limiting negative side
effects. Our code is available on GitHub:
https://github.com/BU-DEPEND-Lab/REASSURE.",http://arxiv.org/abs/2110.07682v3
"Effect of Dust Size on the Near-Infrared Spectra (1.0-5.0 $μ$m) of
  Brown Dwarf Atmospheres",2021-10-19T02:41:11Z,"Satoko Sorahana, Hiroshi Kobayashi, Kyoko K. Tanaka","In this study, we demonstrate the dependence of atmospheric dust size on the
near-infrared spectra of ten L dwarfs, and constrain the sizes of dust grains
in each L dwarf atmosphere. In previous studies, by comparing observed and
modeled spectra, it was suggested that the deviations of their spectral shapes
from theoretical prediction are general characteristics. Here, we focus on the
dust size in brown dwarf atmospheres to understand the observed spectra. We
confirm that changing the dust size changes the temperature-pressure structure
of the atmosphere, with the shape of the spectrum changing accordingly. At the
wavelength at which dust is the main absorber of radiation (the dust-dominated
regime), a large dust opacity combined with a medium grain size, e.g., 0.1
$\mu$m, results in a low photospheric temperature, and thus a small flux.
Conversely, for the wavelength at which gas absorption is dominant (the
gas-dominated regime), a large dust opacity modifies the temperature-pressure
structure, resulting in a high photospheric temperature, which corresponds to
large flux emissions. Taking into account the size effect, we compare the model
spectral fluxes in the wavelength range 1-5 $\mu$m with the observational ones
to constrain the main dust size in the atmosphere of each of the ten L dwarfs
observed with AKARI and SpeX or CGS4. Ultimately, we reveal that the observed
data are reproduced with higher fidelity by models based on a medium dust size
of 0.1-3.0 $\mu$m for six of these L dwarfs; therefore, we suggest that such
atmospheric dust sizes apply to the majority of L dwarfs.",http://arxiv.org/abs/2110.09700v1
Hosting Capacity Approach Implications,2021-10-20T13:16:37Z,"Narayan Bhusal, Andrija Sadikovic, Mohammed Ben-Idris","This paper revisits the generation hosting capacity (HC) calculation approach
to account for grid operational flexibility--the ability to reconfigure the
system safely. In essence, the generation hosting capacity is determined
against the set of limiting factors--voltage, thermal (conductor loading),
reverse flow (at the feeder head, station transformer, or substation), and
change in the voltage (due to sudden change in generation output)). Not that
long ago, California Investor-Owned Utilities (IOUs) added a new criterion that
does not allow reverse flow at the supervisory control and data acquisition
(SCADA) points that can change the system configuration, aiming to prevent the
potential transfer of reverse flow to an adjacent feeder. This new criterion
intended to capture operational constraints as part of hosting capacity-known
as hosting capacity with operational flexibility (OpFlex). This paper explores
the shortfalls of such an approach and proposes performing actual transfer
analysis when determining hosting capacity rather than implementing the OpFlex
approach. Furthermore, we discuss the need for transition to determining
hosting capacity profile (all intervals) rather than a flat line (one, worst
performing interval) hosting capacity. A hosting capacity profile would inform
the developers of interval-by-interval limits and opportunities, creating new
opportunities to reach higher penetration of DERs at a lower cost. With
technological and computational advancements, such an approach is neither out
of implementation reach nor that computationally expensive. In return, far more
DER can be interconnected once programmed not to violate certain generation
profiles as part of the interconnection requirement, and utilities would be
better informed of their actual operational flexibility, benefiting society
overall.",http://arxiv.org/abs/2110.10551v1
Flavor probes of axion-like particles,2021-10-20T18:00:03Z,"Martin Bauer, Matthias Neubert, Sophie Renner, Marvin Schnubel, Andrea Thamm","Axions and axion-like particles (ALPs) are well-motivated low-energy relics
of high-energy extensions of the Standard Model (SM). We investigate the
phenomenology of an ALP with flavor-changing couplings, and present a
comprehensive analysis of quark and lepton flavor-changing observables within a
general ALP effective field theory. Observables studied include rare meson
decays, flavor oscillations of neutral mesons, rare lepton decays, and dipole
moments. We derive bounds on the general ALP couplings as a function of its
mass, consistently taking into account the ALP lifetime and branching ratios.
We further calculate quark flavor-changing effects that are unavoidably induced
by running and matching between the new physics scale and the scale of the
measurements. This allows us to derive bounds on benchmark ALP models in which
only a single (flavorless or flavor-universal) ALP coupling to SM particles is
present at the new physics scale, and in this context we highlight the
complementarity and competitiveness of flavor bounds with constraints derived
from collider, beam dump and astrophysical measurements. We find that searches
for ALPs produced in meson decays provide some of the strongest constraints in
the MeV-GeV mass range, even for the most flavorless of ALP models. Likewise,
we discuss the interplay of flavor-conserving and flavor-violating couplings of
the ALP to leptons, finding that constraints from lepton flavor-violating
observables generally depend strongly on both. Additionally, we analyze whether
an ALP can provide an explanation for various experimental anomalies including
those observed in rare B-meson decays, measurements at the ATOMKI and KTeV
experiments, and in the anomalous magnetic moments of the muon and the
electron.",http://arxiv.org/abs/2110.10698v1
"Hydrodynamic effects on biofilms at the bio-interface using a
  microfluidic electrochemical cell: case study of Pseudomonas sp",2021-10-20T19:34:55Z,"Mirpouyan Zarabadi, François Paquet-Mercier, Steve J. Charette, Jesse Greener","The anchoring biofilm layer is expected to exhibit a different response to
environmental stresses than for portions in the bulk, due to the protection
from other strata and the proximity to the attachment surface. The effect of
hydrodynamic stress on surface-adhered biofilm layers was tested using a
specially designed microfluidic bio flow cell with an embedded three-electrode
detection system. In situ electrochemical impedance spectroscopy (EIS)
measurements of biocapacitance and bioresistance of Pseudomonas sp. biofilms
were conducted during the growth phase and under different shear flow
conditions with verification by other surface sensitive techniques.
Distinctive, but reversible changes to the amount of biofilm and its structure
at the attachment surface were observed during the application of elevated
shear stress. In contrast, regular microscopy revealed permanent distortion to
the biofilm bulk, in the form of streamers and ripples. Following the
application of extreme shear stresses, complete removal of significant portions
of biofilm outer layers occurred, but this did not change the measured quantity
of biofilm at the electrode attachment surface. The structure of the remaining
biofilm, however, appeared to be modified and susceptible to further changes
following application of shear stress directly to the unprotected biofilm
layers at the attachment surface.",http://arxiv.org/abs/2110.10743v1
"Logic, Philosophy and Physics: a critical commentary on the dilemma of
  categories",2021-09-16T11:44:10Z,Abhishek Majhi,"I provide a critical commentary regarding the attitude of the logician and
the philosopher towards the physicist and physics. The commentary is intended
to showcase how a general change in attitude towards making scientific
inquiries can be beneficial for science as a whole. However, such a change can
come at the cost of looking beyond the categories of the disciplines of logic,
philosophy and physics. It is through self-inquiry that such a change is
possible, along with the realization of the essence of the middle that is
otherwise excluded by choice. The logician, who generally holds a reverential
attitude towards the physicist, can then actively contribute to the betterment
of physics by improving the language through which the physicist expresses his
experience. The philosopher, who otherwise chooses to follow the advancement of
physics and gets stuck in the trap of sophistication of language, can then be
of guidance to the physicist on intellectual grounds by having the physicist's
experience himself. In course of this commentary, I provide a glimpse of how a
truthful conversion of verbal statements to physico-mathematical expressions
unravels the hitherto unrealized connection between Heisenberg uncertainty
relation and Cauchy's definition of derivative that is used in physics. The
commentary can be an essential reading if the reader is willing to look beyond
the categories of logic, philosophy and physics by being `nobody'.",http://arxiv.org/abs/2110.11230v1
"Evolution of accretion disc reflection spectra due to a Type I X-ray
  burst",2021-10-22T17:24:02Z,"J. Speicher, D. R. Ballantyne, P. C. Fragile","Irradiation of the accretion disc causes reflection signatures in the
observed X-ray spectrum, encoding important information about the disc
structure and density. A Type I X-ray burst will strongly irradiate the
accretion disc and alter its properties. Previous numerical simulations
predicted the evolution of the accretion disc due to an X-ray burst. Here, we
process time-averaged simulation data of six time intervals to track changes in
the reflection spectrum from the burst onset to just past its peak. We divide
the reflecting region of the disc within $r\lesssim50$ km into 6-7 radial zones
for every time interval and compute the reflection spectra for each zone. We
integrate these reflection spectra to obtain a total reflection spectrum per
time interval. The burst ionizes and heats the disc, which gradually weakens
all emission lines. Compton scattering and bremsstrahlung rates increase in the
disc during the burst rise, and the soft excess at $<$3 keV rises from
$\approx4$% to $\approx38$% of the total emission at the burst peak. A soft
excess is expected to be ubiquitous in the reflection spectra of X-ray bursts.
Structural disc changes such as inflation because of heating or drainage of the
inner disc due to Poynting-Robertson drag affect the strength of the soft
excess. Further studies on the dependence of the reflection spectrum
characteristics to changes in the accretion disc during an X-ray burst may lead
to probes of the disc geometry.",http://arxiv.org/abs/2110.11931v1
"Attend and Guide (AG-Net): A Keypoints-driven Attention-based Deep
  Network for Image Recognition",2021-10-23T09:43:36Z,"Asish Bera, Zachary Wharton, Yonghuai Liu, Nik Bessis, Ardhendu Behera","This paper presents a novel keypoints-based attention mechanism for visual
recognition in still images. Deep Convolutional Neural Networks (CNNs) for
recognizing images with distinctive classes have shown great success, but their
performance in discriminating fine-grained changes is not at the same level. We
address this by proposing an end-to-end CNN model, which learns meaningful
features linking fine-grained changes using our novel attention mechanism. It
captures the spatial structures in images by identifying semantic regions (SRs)
and their spatial distributions, and is proved to be the key to modelling
subtle changes in images. We automatically identify these SRs by grouping the
detected keypoints in a given image. The ``usefulness'' of these SRs for image
recognition is measured using our innovative attentional mechanism focusing on
parts of the image that are most relevant to a given task. This framework
applies to traditional and fine-grained image recognition tasks and does not
require manually annotated regions (e.g. bounding-box of body parts, objects,
etc.) for learning and prediction. Moreover, the proposed keypoints-driven
attention mechanism can be easily integrated into the existing CNN models. The
framework is evaluated on six diverse benchmark datasets. The model outperforms
the state-of-the-art approaches by a considerable margin using Distracted
Driver V1 (Acc: 3.39%), Distracted Driver V2 (Acc: 6.58%), Stanford-40 Actions
(mAP: 2.15%), People Playing Musical Instruments (mAP: 16.05%), Food-101 (Acc:
6.30%) and Caltech-256 (Acc: 2.59%) datasets.",http://arxiv.org/abs/2110.12183v1
"A Pipeline for Graph-Based Monitoring of the Changes in the Information
  Space of Russian Social Media during the Lockdown",2021-10-24T12:42:31Z,"V. Danilova, S. Popova, V. Karpova","With the COVID-19 outbreak and the subsequent lockdown, social media became a
vital communication tool. The sudden outburst of online activity influenced
information spread and consumption patterns. It increases the relevance of
studying the dynamics of social networks and developing data processing
pipelines that allow a comprehensive analysis of social media data in the
temporal dimension. This paper scopes the weekly dynamics of the information
space represented by Russian social media (Twitter and Livejournal) during a
critical period (massive COVID-19 outbreak and first governmental measures).
The approach is twofold: a) build the time series of topic similarity
indicators by identifying COVID-related topics in each week and measuring user
contribution to the topic space, and b) cluster user activity and display
user-topic relationships on graphs in a dashboard application. The paper
describes the development of the pipeline, explains the choices made and
provides a case study of the adaptation to virus control measures. The results
confirm that social processes and behaviour in response to pandemic-triggered
changes can be successfully traced in social media. Moreover, the adaptation
trends revealed by psychological and sociological studies are reflected in our
data and can be explored using the proposed method.",http://arxiv.org/abs/2110.13626v1
"Heterogeneous Effects of Software Patches in a Multiplayer Online Battle
  Arena Game",2021-10-27T17:59:22Z,"Yuzi He, Christopher Tran, Julie Jiang, Keith Burghardt, Emilio Ferrara, Elena Zheleva, Kristina Lerman","The popularity of online gaming has grown dramatically, driven in part by
streaming and the billion-dollar e-sports industry. Online games regularly
update their software to fix bugs, add functionality that improve the game's
look and feel, and change the game mechanics to keep the games fun and
challenging. An open question, however, is the impact of these changes on
player performance and game balance, as well as how players adapt to these
sudden changes. To address these questions, we use causal inference to measure
the impact of software patches to League of Legends, a popular team-based
multiplayer online game. We show that game patches have substantially different
impacts on players depending on their skill level and whether they take breaks
between games. We find that the gap between good and bad players increases
after a patch, despite efforts to make gameplay more equal. Moreover, longer
between-game breaks tend to improve player performance after patches. Overall,
our results highlight the utility of causal inference, and specifically
heterogeneous treatment effect estimation, as a tool to quantify the complex
mechanisms of game balance and its interplay with players' performance.",http://arxiv.org/abs/2110.14632v1
"Amplification of Primordial Perturbations from the Rise or Fall of the
  Inflaton",2021-10-27T18:00:00Z,"Keisuke Inomata, Evan McDonough, Wayne Hu","The next generation of cosmic microwave background, gravitational wave, and
large scale structure, experiments will provide an unprecedented opportunity to
probe the primordial power spectrum on small scales. An exciting possibility
for what lurks on small scales is a sharp rise in the primordial power
spectrum: This can lead to the formation of primordial black holes, providing a
dark matter candidate or the black holes observed by the LIGO-Virgo
collaboration. In this work we develop a mechanism for the amplification of the
small-scale primordial power spectrum, in the context of single-field inflation
with a step-like feature in the inflaton potential. Specifically, we consider
both the upward and the downward step in the potential. We also discuss the
possibility of the strong coupling between perturbations because the rapid
changes of the potential derivatives with the time-dependent field value,
caused by the step-like feature, could make the coupling stronger. As a result,
we find that the perturbations can remain weakly coupled yet sufficiently
enhanced if the step realizes the rapid changes of the potential derivatives in
some fraction of an e-fold, $\mathcal O(\mathcal P_{\mathcal R}^{1/2}) \lesssim
\Delta N < 1$, where $\mathcal P_\mathcal R$ is the power spectrum of the
curvature perturbation at that time. We also discuss the PBH formation rate
from the inflaton trapping at the local minimum, which can occur in the
potential with an upward step.",http://arxiv.org/abs/2110.14641v2
"Quark distribution inside a pion in many-flavor (2 + 1)-dimensional QCD
  using lattice computations: UV listens to IR",2021-01-06T19:00:17Z,Nikhil Karthik,"We study the changes in the short-distance quark structure of the
Nambu-Goldstone boson when the long-distance symmetry-breaking scales are
depleted controllably. We achieve this by studying the valence Parton
Distribution Function (PDF) of pion in 2+1 dimensional two-color QCD, with the
number $N$ of massless quarks as the tunable parameter that slides the theory
from being strongly broken for $N=0$ to the conformal window for $N>4$, where
the theory is gapped by the fixed finite volume. We perform our study
non-perturbatively using lattice simulations with $N=0,2,4,8$ flavors of nearly
massless two-component Wilson-Dirac sea quarks and employ the leading-twist
formalism (LaMET/SDF) to compute the PDF of pion at a fixed valence mass. We
find that the relative variations in the first few PDF moments are only mild
compared to the changes in decay constant, but the shape of the reconstructed
$x$-dependent PDF itself dramatically changes from being broad in the
scale-broken sector to being sharply peaked in the near-conformal region, best
reflected in PDF shape observables such as the cumulants.",http://arxiv.org/abs/2101.02224v3
"An Adaptive Multi-Agent Physical Layer Security Framework for Cognitive
  Cyber-Physical Systems",2021-01-07T09:26:29Z,"Mehmet Özgün Demir, Ozan Alp Topal, Ali Emre Pusane, Guido Dartmann, Gerd Ascheid, Güneş Karabulut Kurt","Being capable of sensing and behavioral adaptation in line with their
changing environments, cognitive cyber-physical systems (CCPSs) are the new
form of applications in future wireless networks. With the advancement of the
machine learning algorithms, the transmission scheme providing the best
performance can be utilized to sustain a reliable network of CCPS agents
equipped with self-decision mechanisms, where the interactions between each
agent are modeled in terms of service quality, security, and cost dimensions.
In this work, first, we provide network utility as a reliability metric, which
is a weighted sum of the individual utility values of the CCPS agents. The
individual utilities are calculated by mixing the quality of service (QoS),
security, and cost dimensions with the proportions determined by the
individualized user requirements. By changing the proportions, the CCPS network
can be tuned for different applications of next-generation wireless networks.
Then, we propose a secure transmission policy selection (STPS) mechanism that
maximizes the network utility by using the Markov-decision process (MDP). In
STPS, the CCPS network jointly selects the best performing physical layer
security policy and the parameters of the selected secure transmission policy
to adapt to the changing environmental effects. The proposed STPS is realized
by reinforcement learning (RL), considering its real-time decision mechanism
where agents can decide automatically the best utility providing policy in an
altering environment.",http://arxiv.org/abs/2101.02446v1
Bootstrapping Non-Stationary Stochastic Volatility,2021-01-10T15:04:28Z,"H. Peter Boswijk, Giuseppe Cavaliere, Anders Rahbek, Iliyan Georgiev","In this paper we investigate how the bootstrap can be applied to time series
regressions when the volatility of the innovations is random and
non-stationary. The volatility of many economic and financial time series
displays persistent changes and possible non-stationarity. However, the theory
of the bootstrap for such models has focused on deterministic changes of the
unconditional variance and little is known about the performance and the
validity of the bootstrap when the volatility is driven by a non-stationary
stochastic process. This includes near-integrated volatility processes as well
as near-integrated GARCH processes. This paper develops conditions for
bootstrap validity in time series regressions with non-stationary, stochastic
volatility. We show that in such cases the distribution of bootstrap statistics
(conditional on the data) is random in the limit. Consequently, the
conventional approaches to proving bootstrap validity, involving weak
convergence in probability of the bootstrap statistic, fail to deliver the
required results. Instead, we use the concept of `weak convergence in
distribution' to develop and establish novel conditions for validity of the
wild bootstrap, conditional on the volatility process. We apply our results to
several testing problems in the presence of non-stationary stochastic
volatility, including testing in a location model, testing for structural
change and testing for an autoregressive unit root. Sufficient conditions for
bootstrap validity include the absence of statistical leverage effects, i.e.,
correlation between the error process and its future conditional variance. The
results are illustrated using Monte Carlo simulations, which indicate that the
wild bootstrap leads to size control even in small samples.",http://arxiv.org/abs/2101.03562v1
Learn-n-Route: Learning implicit preferences for vehicle routing,2021-01-11T14:57:46Z,"Rocsildes Canoy, Víctor Bucarey, Jayanta Mandi, Tias Guns","We investigate a learning decision support system for vehicle routing, where
the routing engine learns implicit preferences that human planners have when
manually creating route plans (or routings). The goal is to use these learned
subjective preferences on top of the distance-based objective criterion in
vehicle routing systems. This is an alternative to the practice of
distinctively formulating a custom VRP for every company with its own routing
requirements. Instead, we assume the presence of past vehicle routing solutions
over similar sets of customers, and learn to make similar choices. The learning
approach is based on the concept of learning a Markov model, which corresponds
to a probabilistic transition matrix, rather than a deterministic distance
matrix. This nevertheless allows us to use existing arc routing VRP software in
creating the actual routings, and to optimize over both distances and
preferences at the same time. For the learning, we explore different schemes to
construct the probabilistic transition matrix that can co-evolve with changing
preferences over time. Our results on a use-case with a small transportation
company show that our method is able to generate results that are close to the
manually created solutions, without needing to characterize all constraints and
sub-objectives explicitly. Even in the case of changes in the customer sets,
our method is able to find solutions that are closer to the actual routings
than when using only distances, and hence, solutions that require fewer manual
changes when transformed into practical routings.",http://arxiv.org/abs/2101.03936v1
Comet 2P/Encke in apparition of 2017: II. Polarization and color,2021-01-11T21:10:25Z,"Nikolai Kiselev, Vera Rosenbush, Oleksandra Ivanova, Ludmilla Kolokolova, Dmitry Petrov, Valeriy Kleshchonok, Viktor Afanasiev, Olena Shubina","We present results of imaging polarimetry of comet 2P/Encke performed on
January 23, 2017 at the heliocentric (1.052 au) and geocentric (1.336 au)
distances and phase angle 46.8 deg, 46 days before perihelion. Observations
were made through the medium-band SED500 ({\lambda}5019/246 {\AA}) and
broadband r-sdss ({\lambda}6200/1200 {\AA}) filters with the multimode focal
reducer SCORPIO-2 at the 6-m BTA telescope of the Special Astrophysical
Observatory (Russia). Dust in comet 2P/Encke was mainly concentrated in the
near-nucleus region of the coma: the maximum dust/gas ratios were 1.5 and 2.9
in the SED500 and the r-sdss filters near the nucleus but dropped sharply to
~0.2 and ~1 at the distance ~2500 km, respectively. Then these ratios began to
increase at distances ~12000 km from the nucleus, the ratio was ~0.3 (SED500)
and ~1.3 (r-sdds). There were significant variations of polarization over the
coma, which correlated with the variations in the dust color and dust/gas
ratio. Changes in polarization and color across the 2P/Encke coma indicate
changes in physical properties of the dust particles with the distance from the
nucleus. Our Sh-matrix computer simulations of light scattering by Gaussian
particles allow us to suggest that the observed trends in color and
polarization are mainly result from changing particle size.",http://arxiv.org/abs/2101.04193v1
"Spectro-Timing Analysis of a highly variable narrow-line Seyfert 1
  galaxy NGC 4748 with AstroSat and XMM-Newton",2021-01-12T15:29:12Z,"Main Pal, Neeraj Kumari, Pankaj Kushwaha, K. P. Singh, Alok C. Gupta, Sachindra Naik, G. C. Dewangan, P. Tripathi, Rathin Adhikari, O. Adegoke, H. Nandan","We present a detailed timing and spectral study of an extremely variable
narrow-line Seyfert~1 galaxy NGC 4748 using observations in the year 2017 and
2014 performed with AstroSat and XMM-Newton, respectively. Both observations
show extremely variable soft and hard X-ray emission that are correlated with
each other. In the 2014 data set, the source retains its general behaviour of
""softer when brighter"" while the 2017 observation exhibits a ""harder when
brighter"" nature. Such changing behaviour is rare in AGNs and is usually
observed in the black hole binary systems. The ""harder when brighter"" is
confirmed with the anti-correlation between the photon index and the 0.3-10 keV
power-law flux. This suggests a possible change in the accretion mode from
standard to the advection-dominated flow. Additionally, both the observations
show soft X-ray excess below 2 keV over the power-law continuum. This excess
was fitted with a single or multiple blackbody component(s). The origin of soft
excess during the 2017 observation is likely due to the cool Comptonization as
the photon index changes with time. On the other hand, the broad iron line and
delayed UV emission during the 2014 observation strongly suggest that X-ray
illumination onto the accretion disk and reflection and reprocessing play a
significant role in this AGN.",http://arxiv.org/abs/2101.04546v1
"""How Was Your Weekend?"" Software Development Teams Working From Home
  During COVID-19",2021-01-14T21:47:42Z,"Courtney Miller, Paige Rodeghero, Margaret-Anne Storey, Denae Ford, Thomas Zimmermann","The mass shift to working at home during the COVID-19 pandemic radically
changed the way many software development teams collaborate and communicate. To
investigate how team culture and team productivity may also have been affected,
we conducted two surveys at a large software company. The first, an exploratory
survey during the early months of the pandemic with 2,265 developer responses,
revealed that many developers faced challenges reaching milestones and that
their team productivity had changed. We also found through qualitative analysis
that important team culture factors such as communication and social connection
had been affected. For example, the simple phrase ""How was your weekend?"" had
become a subtle way to show peer support.
  In our second survey, we conducted a quantitative analysis of the team
cultural factors that emerged from our first survey to understand the
prevalence of the reported changes. From 608 developer responses, we found that
74% of these respondents missed social interactions with colleagues and 51%
reported a decrease in their communication ease with colleagues. We used data
from the second survey to build a regression model to identify important team
culture factors for modeling team productivity. We found that the ability to
brainstorm with colleagues, difficulty communicating with colleagues, and
satisfaction with interactions from social activities are important factors
that are associated with how developers report their software development
team's productivity. Our findings inform how managers and leaders in large
software companies can support sustained team productivity during times of
crisis and beyond.",http://arxiv.org/abs/2101.05877v2
"Coarse Temporal Attention Network (CTA-Net) for Driver's Activity
  Recognition",2021-01-17T10:15:37Z,"Zachary Wharton, Ardhendu Behera, Yonghuai Liu, Nik Bessis","There is significant progress in recognizing traditional human activities
from videos focusing on highly distinctive actions involving discriminative
body movements, body-object and/or human-human interactions. Driver's
activities are different since they are executed by the same subject with
similar body parts movements, resulting in subtle changes. To address this, we
propose a novel framework by exploiting the spatiotemporal attention to model
the subtle changes. Our model is named Coarse Temporal Attention Network
(CTA-Net), in which coarse temporal branches are introduced in a trainable
glimpse network. The goal is to allow the glimpse to capture high-level
temporal relationships, such as 'during', 'before' and 'after' by focusing on a
specific part of a video. These branches also respect the topology of the
temporal dynamics in the video, ensuring that different branches learn
meaningful spatial and temporal changes. The model then uses an innovative
attention mechanism to generate high-level action specific contextual
information for activity recognition by exploring the hidden states of an LSTM.
The attention mechanism helps in learning to decide the importance of each
hidden state for the recognition task by weighing them when constructing the
representation of the video. Our approach is evaluated on four publicly
accessible datasets and significantly outperforms the state-of-the-art by a
considerable margin with only RGB video as input.",http://arxiv.org/abs/2101.06636v1
"DyLoc: Dynamic Localization for Massive MIMO Using Predictive Recurrent
  Neural Networks",2021-01-19T20:15:34Z,"Farzam Hejazi, Katarina Vuckovic, Nazanin Rahnavard","This paper presents a data-driven localization framework with high precision
in time-varying complex multipath environments, such as dense urban areas and
indoors, where GPS and model-based localization techniques come short. We
consider the angle-delay profile (ADP), a linear transformation of channel
state information (CSI), in massive MIMO systems and show that ADPs preserve
users' motion when stacked temporally. We discuss that given a static
environment, future frames of ADP time-series are predictable employing a video
frame prediction algorithm. We express that a deep convolutional neural network
(DCNN) can be employed to learn the background static scattering environment.
To detect foreground changes in the environment, corresponding to path blockage
or addition, we introduce an algorithm taking advantage of the trained DCNN.
Furthermore, we present DyLoc, a data-driven framework to recover distorted
ADPs due to foreground changes and to obtain precise location estimations. We
evaluate the performance of DyLoc in several dynamic scenarios employing
DeepMIMO dataset to generate geo-tagged CSI datasets for indoor and outdoor
environments. We show that previous DCNN-based techniques fail to perform with
desirable accuracy in dynamic environments, while DyLoc pursues localization
precisely. Moreover, simulations show that as the environment gets richer in
terms of the number of multipath, DyLoc gets more robust to foreground changes.",http://arxiv.org/abs/2101.07848v2
Influence Estimation for Generative Adversarial Networks,2021-01-20T23:55:54Z,"Naoyuki Terashita, Hiroki Ohashi, Yuichi Nonaka, Takashi Kanemaru","Identifying harmful instances, whose absence in a training dataset improves
model performance, is important for building better machine learning models.
Although previous studies have succeeded in estimating harmful instances under
supervised settings, they cannot be trivially extended to generative
adversarial networks (GANs). This is because previous approaches require that
(1) the absence of a training instance directly affects the loss value and that
(2) the change in the loss directly measures the harmfulness of the instance
for the performance of a model. In GAN training, however, neither of the
requirements is satisfied. This is because, (1) the generator's loss is not
directly affected by the training instances as they are not part of the
generator's training steps, and (2) the values of GAN's losses normally do not
capture the generative performance of a model. To this end, (1) we propose an
influence estimation method that uses the Jacobian of the gradient of the
generator's loss with respect to the discriminator's parameters (and vice
versa) to trace how the absence of an instance in the discriminator's training
affects the generator's parameters, and (2) we propose a novel evaluation
scheme, in which we assess harmfulness of each training instance on the basis
of how GAN evaluation metric (e.g., inception score) is expect to change due to
the removal of the instance. We experimentally verified that our influence
estimation method correctly inferred the changes in GAN evaluation metrics.
Further, we demonstrated that the removal of the identified harmful instances
effectively improved the model's generative performance with respect to various
GAN evaluation metrics.",http://arxiv.org/abs/2101.08367v3
Customer Price Sensitivities in Competitive Automobile Insurance Markets,2021-01-21T11:07:20Z,Robert Matthijs Verschuren,"Insurers are increasingly adopting more demand-based strategies to
incorporate the indirect effect of premium changes on their policyholders'
willingness to stay. However, since in practice both insurers' renewal premia
and customers' responses to these premia typically depend on the customer's
level of risk, it remains challenging in these strategies to determine how to
properly control for this confounding. We therefore consider a causal inference
approach in this paper to account for customers' price sensitivity and to
deduce optimal, multi-period profit maximizing premium renewal offers. More
specifically, we extend the discrete treatment framework of Guelman and
Guill\'en (2014) by Extreme Gradient Boosting, or XGBoost, and by multiple
imputation to better account for the uncertainty in the counterfactual
responses. We additionally introduce the continuous treatment framework with
XGBoost to the insurance literature to allow identification of the exact
optimal renewal offers and account for any competition in the market by
including competitor offers. The application of the two treatment frameworks to
a Dutch automobile insurance portfolio suggests that a policy's competitiveness
in the market is crucial for a customer's price sensitivity and that XGBoost is
more appropriate to describe this than the traditional logistic regression.
Moreover, an efficient frontier of both frameworks indicates that substantially
more profit can be gained on the portfolio than realized, also already with
less churn and in particular if we allow for continuous rate changes. A
multi-period renewal optimization confirms these findings and demonstrates that
the competitiveness enables temporal feedback of previous rate changes on
future demand.",http://arxiv.org/abs/2101.08551v2
E-commerce warehousing: learning a storage policy,2021-01-21T19:53:03Z,"Adrien Rimélé, Philippe Grangier, Michel Gamache, Michel Gendreau, Louis-Martin Rousseau","E-commerce with major online retailers is changing the way people consume.
The goal of increasing delivery speed while remaining cost-effective poses
significant new challenges for supply chains as they race to satisfy the
growing and fast-changing demand. In this paper, we consider a warehouse with a
Robotic Mobile Fulfillment System (RMFS), in which a fleet of robots stores and
retrieves shelves of items and brings them to human pickers. To adapt to
changing demand, uncertainty, and differentiated service (e.g., prime vs.
regular), one can dynamically modify the storage allocation of a shelf. The
objective is to define a dynamic storage policy to minimise the average cycle
time used by the robots to fulfil requests. We propose formulating this system
as a Partially Observable Markov Decision Process, and using a Deep Q-learning
agent from Reinforcement Learning, to learn an efficient real-time storage
policy that leverages repeated experiences and insightful forecasts using
simulations. Additionally, we develop a rollout strategy to enhance our method
by leveraging more information available at a given time step. Using
simulations to compare our method to traditional storage rules used in the
industry showed preliminary results up to 14\% better in terms of travelling
times.",http://arxiv.org/abs/2101.08828v1
"Enhancing the formation of ionic defects to study the ice Ih/XI
  transition with molecular dynamics simulations",2021-01-22T19:49:43Z,"Pablo M. Piaggi, Roberto Car","Ice Ih, the common form of ice in the biosphere, contains proton disorder.
Its proton-ordered counterpart, ice XI, is thermodynamically stable below 72 K.
However, even below this temperature the formation of ice XI is kinetically
hindered and experimentally it is obtained by doping ice with KOH. Doping
creates ionic defects that promote the migration of protons and the associated
change in proton configuration. In this article, we mimic the effect of doping
in molecular dynamics simulations using a bias potential that enhances the
formation of ionic defects. The recombination of the ions thus formed proceeds
through fast migration of the hydroxide and results in the jump of protons
along a hydrogen bond loop. This provides a physical and expedite way to change
the proton configuration, and to accelerate diffusion in proton configuration
space. A key ingredient of this approach is a machine learning potential
trained with density functional theory data and capable of modeling molecular
dissociation. We exemplify the usefulness of this idea by studying the
order-disorder transition using an appropriate order parameter to distinguish
the proton environments in ice Ih and XI. We calculate the changes in free
energy, enthalpy, and entropy associated with the transition. Our estimated
entropy agrees with experiment within the error bars of our calculation.",http://arxiv.org/abs/2101.09308v2
Relative vanishing theorems for $\mathbf{Q}$-schemes,2021-01-25T20:30:58Z,Takumi Murayama,"We prove the relative Grauert-Riemenschneider vanishing, Kawamata-Viehweg
vanishing, and Koll\'ar injectivity theorems for proper morphisms of schemes of
equal characteristic zero, solving conjectures of Boutot and Kawakita. Our
proof uses the Grothendieck limit theorem for sheaf cohomology and
Zariski-Riemann spaces. We also show these vanishing and injectivity theorems
hold for locally Moishezon (resp. projective) morphisms of quasi-excellent
algebraic spaces admitting dualizing complexes and semianalytic germs of
complex analytic spaces (resp. quasi-excellent formal schemes admitting
dualizing complexes, rigid analytic spaces, Berkovich spaces, and adic spaces
locally of weakly finite type over a field), all in equal characteristic zero.
  We give many applications of our vanishing results. For example, we extend
Boutot's theorem to all Noetherian $\mathbf{Q}$-algebras by showing that if $R
\to R'$ is a cyclically pure map of $\mathbf{Q}$-algebras and $R'$ is
pseudo-rational, then $R$ is pseudo-rational. This solves a conjecture of
Boutot and affirmatively answers a question of Schoutens. The proof of this
Boutot-type result uses a new characterization of pseudo-rationality and
rational singularities using Zariski-Riemann spaces. This characterization is
also used in the proofs of our vanishing and injectivity theorems and is of
independent interest.",http://arxiv.org/abs/2101.10397v5
"Towards low loss non-volatile phase change materials in mid index
  waveguides",2021-01-26T23:00:07Z,"Joaquin Faneca, Ioannis Zeimpekis, S. T. Ilie, Thalía Domínguez Bucio, Katarzyna Grabska, Daniel W. Hewak, Frederic Y. Gardes","Photonic integrated circuits currently use platform intrinsic thermo-optic
and electro-optic effects to implement dynamic functions such as switching,
modulation and other processing. Currently, there is a drive to implement field
programmable photonic circuits, a need which is only magnified by new
neuromorphic and quantum computing applications. The most promising
non-volatile photonic components employ phase change materials such as GST and
GSST, which had their origin in electronic memory. However, in the optical
domain, these compounds introduce significant losses potentially preventing a
large number of applications. Here, we evaluate the use of two newly introduced
low loss phase change materials, Sb2S3 and Sb2Se3, on a silicon nitride
photonic platform. We focus the study on Mach-Zehnder interferometers that
operate at the O and C bands to demonstrate the performance of the system. Our
measurements show an insertion loss below 0.04 dB/um for Sb2S3 and lower than
0.09 dB/um for Sb2Se3 cladded devices for both amorphous and crystalline
phases. The effective refractive index contrast for Sb2S3 on SiNx was measured
to be 0.05 at 1310 nm and 0.02 at 1550 nm, whereas for Sb2Se3, it was 0.03 at
1310 nm and 0.05 at 1550 nm highlighting the performance of the integrated
device.",http://arxiv.org/abs/2101.11127v1
Human Inference in Changing Environments With Temporal Structure,2021-01-27T00:31:46Z,"Arthur Prat-Carrabin, Robert C. Wilson, Jonathan D. Cohen, Rava Azeredo da Silveira","To make informed decisions in natural environments that change over time,
humans must update their beliefs as new observations are gathered. Studies
exploring human inference as a dynamical process that unfolds in time have
focused on situations in which the statistics of observations are
history-independent. Yet temporal structure is everywhere in nature, and yields
history-dependent observations. Do humans modify their inference processes
depending on the latent temporal statistics of their observations? We
investigate this question experimentally and theoretically using a change-point
inference task. We show that humans adapt their inference process to fine
aspects of the temporal structure in the statistics of stimuli. As such, humans
behave qualitatively in a Bayesian fashion, but, quantitatively, deviate away
from optimality. Perhaps more importantly, humans behave suboptimally in that
their responses are not deterministic, but variable. We show that this
variability itself is modulated by the temporal statistics of stimuli. To
elucidate the cognitive algorithm that yields this behavior, we investigate a
broad array of existing and new models that characterize different sources of
suboptimal deviations away from Bayesian inference. While models with 'output
noise' that corrupts the response-selection process are natural candidates,
human behavior is best described by sampling-based inference models, in which
the main ingredient is a compressed approximation of the posterior, represented
through a modest set of random samples and updated over time. This result comes
to complement a growing literature on sample-based representation and learning
in humans.",http://arxiv.org/abs/2101.11143v1
"Energy and mass dependencies for the characteristics of $p_T$ regions
  observed at LHC energies",2021-01-31T12:41:14Z,Mais Suleymanov,"The $p_T$ distributions of the $K^0$- and $\phi$ - mesons produced in the
$pp$ collisions at $\sqrt{s}=2.76 TeV$ have been analyzed by fitting them using
the exponential function. It was observed that the distributions contain
several $p_T$ regions similar to the cases with the charged particles, $\pi^0$-
and $\eta$- mesons produced in the same events. These regions could be
characterized using three variables: the length of the region $L^{c}_K $ and
free fitting parameters $a^{c}_K $ and $b^{c}_K $. It was observed that the
values of the parameters as a function of energy grouped around certain lines
and there are jump-like changes. These observations together with the effect of
existing the several $p_T$ regions can say on discrete energy dependencies for
the $L^{c}_K $ , $a^{c}_K $ and $b^{c}_K $. The lengths of the regions increase
with the mass of the particles. This increase gets stronger with energy. The
mass dependencies of the parameters $a^{c}_K $ and $b^{c}_K $ show a regime
change at a mass $\simeq 500 MeV/c^2$. According to the phenomenology of string
theory, these results could be explained by two processes occurring
simultaneously: string hadronization and string breaking. In the experiment we
can only measure the spectrum of the hadronized particles, since we cannot
access the spectrum of the strings themselves. The string breaking effect could
be a signal of string formations and the reason behind the observation of
several $p_T$ regions and the jump-like changes for the characteristics of the
regions.",http://arxiv.org/abs/2102.00440v1
"Optimal Sequential Detection of Signals with Unknown Appearance and
  Disappearance Points in Time",2021-02-02T04:58:57Z,"Alexander G. Tartakovsky, Nikita R. Berenkov, Alexei E. Kolessa, Igor V. Nikiforov","The paper addresses a sequential changepoint detection problem, assuming that
the duration of change may be finite and unknown. This problem is of importance
for many applications, e.g., for signal and image processing where signals
appear and disappear at unknown points in time or space. In contrast to the
conventional optimality criterion in quickest change detection that requires
minimization of the expected delay to detection for a given average run length
to a false alarm, we focus on a reliable maximin change detection criterion of
maximizing the minimal probability of detection in a given time (or space)
window for a given local maximal probability of false alarm in the prescribed
window. We show that the optimal detection procedure is a modified CUSUM
procedure. We then compare operating characteristics of this optimal procedure
with popular in engineering the Finite Moving Average (FMA) detection algorithm
and the ordinary CUSUM procedure using Monte Carlo simulations, which show that
typically the later algorithms have almost the same performance as the optimal
one. At the same time, the FMA procedure has a substantial advantage --
independence to the intensity of the signal, which is usually unknown. Finally,
the FMA algorithm is applied to detecting faint streaks of satellites in
optical images.",http://arxiv.org/abs/2102.01310v2
"Mimicry mechanism model of octopus epidermis pattern by inverse
  operation of Turing reaction model",2021-01-15T05:46:23Z,Takeshi Ishida,"Many cephalopods such as octopus and squid change their skin color
purposefully within a very short time. Furthermore, it is widely known that
some octopuses have the ability to change the color and unevenness of the skin
and to mimic the surroundings in short time. However, much research has not
been done on the entire mimicry mechanism in which the octopus recognizes the
surrounding landscape and changes the skin pattern. It seems that there is no
hypothetical model to explain the whole mimicry mechanism yet. In this study,
the mechanism of octopus skin pattern formation was assumed to be based on the
Turing model. Here, the pattern formation by the Turing model was realized by
the equivalent filter calculation model using the cellular automaton, instead
of directly solving the differential equations. It was shown that this model
can create various patterns with two feature parameters. Furthermore, for the
eyes recognition part where two features are extracted from the Turing pattern
image, our study proposed a method that can be calculated back with small
amount of calculation using the characteristics of the cellular Turing pattern
model. These two calculations can be expressed in the same mathematical frame
based on the cellular automaton model using the convolution filter. As a
result, it can be created a model which is capable of extracting features from
patterns and reconstructing patterns in a short time, the model is considered
to be a basic model for considering the mimicry mechanism of octopus. Also, in
terms of application to machine learning, it is considered that it shows the
possibility of leading to a model with a small amount of learning calculation.",http://arxiv.org/abs/2102.01512v2
"Stochastic kinetic treatment of protein aggregation and the effects of
  macromolecular crowding",2021-02-02T15:51:34Z,"John Bridstrup, John S Schreck, Jesse L Jorgenson, Jian-Min Yuan","Investigation of protein self-assembly processes is important for the
understanding of the growth processes of functional proteins as well as
disease-causing amyloids. Inside cells, intrinsic molecular fluctuations are so
high that they cast doubt on the validity of the deterministic rate equation
approach. Furthermore, the protein environments inside cells are often crowded
with other macromolecules, with volume fractions of the crowders as high as
40%. We study protein self-aggregation at the cellular level using Gillespie's
stochastic algorithm and investigate the effects of macromolecular crowding
using models built on scaled-particle and transition-state theories. The
stochastic kinetic method can be formulated to provide information on the
dominating aggregation mechanisms in a method called reaction frequency (or
propensity) analysis. This method reveals that the change of scaling laws
related to the lag time can be directly related to the change in the
frequencies of reaction mechanisms. Further examination of the time evolution
of the fibril mass and length quantities unveils that maximal fluctuations
occur in the periods of rapid fibril growth and the fluctuations of both
quantities can be sensitive functions of rate constants. The presence of
crowders often amplifies the roles of primary and secondary nucleation and
causes shifting in the relative importance of elongation, shrinking,
fragmentation and coagulation of linear aggregates. Comparison of the results
of stochastic simulations with those of rate equations gives us information on
the convergence relation between them and how the roles of reaction mechanisms
change as the system volume is varied.",http://arxiv.org/abs/2102.01569v1
"Introduction to Neural Transfer Learning with Transformers for Social
  Science Text Analysis",2021-02-03T15:41:20Z,Sandra Wankmüller,"Transformer-based models for transfer learning have the potential to achieve
high prediction accuracies on text-based supervised learning tasks with
relatively few training data instances. These models are thus likely to benefit
social scientists that seek to have as accurate as possible text-based measures
but only have limited resources for annotating training data. To enable social
scientists to leverage these potential benefits for their research, this paper
explains how these methods work, why they might be advantageous, and what their
limitations are. Additionally, three Transformer-based models for transfer
learning, BERT (Devlin et al. 2019), RoBERTa (Liu et al. 2019), and the
Longformer (Beltagy et al. 2020), are compared to conventional machine learning
algorithms on three applications. Across all evaluated tasks, textual styles,
and training data set sizes, the conventional models are consistently
outperformed by transfer learning with Transformers, thereby demonstrating the
benefits these models can bring to text-based social science research.",http://arxiv.org/abs/2102.02111v2
"The critical behavior of Hegselmann-Krause opinion model with smart
  agents",2021-02-04T02:58:32Z,"Yueying Zhu, Jian Jiang, Wei Li","The Hegselmann-Krause (HK) model allows one to characterize the continuous
change of agents' opinions with the bounded confidence threshold $\varepsilon$.
To consider the heterogeneity of agents in characteristics, we study the HK
model on homogeneous and heterogeneous networks by introducing a kind of smart
agent. Different from the averaging rule in opinion update of HK model, smart
agents will consider, in updating their opinions, the environmental influence
following the fact that an agent's behavior is often coupled with environmental
changes. The environment is characterized by a parameter that represents the
biased resource allocation between different cliques. We focus on the critical
behavior of the underlying system. A phase transition point separating a
complete consensus from the coexistence of different opinions is identified,
which occurs at a critical value $\varepsilon_c$ for the bounded confidence
threshold. We state analytically that $\varepsilon_c$ can take only one of two
possible values, depending on the behavior of the average degree $k_a$ of a
social graph, when agents are homogeneous in characteristics. Results also
suggest that the phase transition point weakly depends on the network structure
but is strongly correlated with the fraction of smart agents and the
environmental parameter. We finally establish the finite size scaling law that
stresses the role that the system size has in the underlying opinion dynamics.
Meanwhile, introducing smart agents does not change the functional dependence
between the time to reach a complete consensus and the system size. However, it
can drive a complete consensus to be reached faster, for homogeneous networks
that are far from the mean field limit.",http://arxiv.org/abs/2102.02385v1
"The challenges of changing teaching assistants' grading practices:
  Requiring students to show evidence of understanding",2021-02-15T01:37:02Z,"Emily Marshman, Ryan Sayer, Charles Henderson, Edit Yerushalmi, Chandralekha Singh","Teaching assistants (TAs) are often responsible for grading in introductory
physics courses at large research universities. Their grading practices can
shape students' approaches to problem solving and learning. Physics education
research recommends grading practices that encourage students to provide
evidence of understanding via explication of the problem-solving process.
However, TAs may not necessarily grade in a manner that encourages students to
provide evidence of understanding in their solutions. Within the context of a
semester-long TA professional development course, we investigated whether
encouraging TAs to use a grading rubric that appropriately weights the
problem-solving process and having them reflect upon the benefits of using such
a rubric prompts TAs to require evidence of understanding in student solutions.
We examined how the TAs graded realistic student solutions to introductory
physics problems before they were provided a rubric, whether TAs used the
rubric as intended, whether they were consistent in grading similar solutions,
and how TAs' grading criteria changed after discussing the benefits of a
well-designed rubric. We find that many TAs typically applied the rubric
consistently when grading similar student solutions but did not require
students to provide evidence of understanding. TAs' written responses, class
discussions, and individual interviews suggest that the instructional
activities involving the grading rubrics in this study were not sufficient to
change their grading practices. Interviews and class discussions suggest that
helping TAs value a rubric that appropriately weights the problem-solving
process may be challenging partly due to the TAs past educational experiences
and the departmental context.",http://arxiv.org/abs/2102.07295v1
"A Multiscale Graph Convolutional Network for Change Detection in
  Homogeneous and Heterogeneous Remote Sensing Images",2021-02-16T09:26:31Z,"Junzheng Wu, Biao Li, Yao Qin, Weiping Ni, Han Zhang, Yuli Sun","Change detection (CD) in remote sensing images has been an ever-expanding
area of research. To date, although many methods have been proposed using
various techniques, accurately identifying changes is still a great challenge,
especially in the high resolution or heterogeneous situations, due to the
difficulties in effectively modeling the features from ground objects with
different patterns. In this paper, a novel CD method based on the graph
convolutional network (GCN) and multiscale object-based technique is proposed
for both homogeneous and heterogeneous images. First, the object-wise high
level features are obtained through a pre-trained U-net and the multiscale
segmentations. Treating each parcel as a node, the graph representations can be
formed and then, fed into the proposed multiscale graph convolutional network
with each channel corresponding to one scale. The multiscale GCN propagates the
label information from a small number of labeled nodes to the other ones which
are unlabeled. Further, to comprehensively incorporate the information from the
output channels of multiscale GCN, a fusion strategy is designed using the
father-child relationships between scales. Extensive Experiments on optical,
SAR and heterogeneous optical/SAR data sets demonstrate that the proposed
method outperforms some state-of the-art methods in both qualitative and
quantitative evaluations. Besides, the Influences of some factors are also
discussed.",http://arxiv.org/abs/2102.08041v1
"Could you become more credible by being White? Assessing Impact of Race
  on Credibility with Deepfakes",2021-02-16T10:05:11Z,"Kurtis Haut, Caleb Wohn, Victor Antony, Aidan Goldfarb, Melissa Welsh, Dillanie Sumanthiran, Ji-ze Jang, Md. Rafayet Ali, Ehsan Hoque","Computer mediated conversations (e.g., videoconferencing) is now the new
mainstream media. How would credibility be impacted if one could change their
race on the fly in these environments? We propose an approach using Deepfakes
and a supporting GAN architecture to isolate visual features and alter racial
perception. We then crowd-sourced over 800 survey responses to measure how
credibility was influenced by changing the perceived race. We evaluate the
effect of showing a still image of a Black person versus a still image of a
White person using the same audio clip for each survey. We also test the effect
of showing either an original video or an altered video where the appearance of
the person in the original video is modified to appear more White. We measure
credibility as the percent of participant responses who believed the speaker
was telling the truth. We found that changing the race of a person in a static
image has negligible impact on credibility. However, the same manipulation of
race on a video increases credibility significantly (61\% to 73\% with p $<$
0.05). Furthermore, a VADER sentiment analysis over the free response survey
questions reveals that more positive sentiment is used to justify the
credibility of a White individual in a video.",http://arxiv.org/abs/2102.08054v1
"The influence of photo-induced processes and charge transfer on carbon
  and oxygen in the lower solar atmosphere",2021-02-18T11:48:36Z,"R. P. Dufresne, G. Del Zanna, N. R. Badnell","To predict line emission in the solar atmosphere requires models which are
fundamentally different depending on whether the emission is from the
chromosphere or the corona. At some point between the two regions, there must
be a change between the two modelling regimes. Recent extensions to the coronal
modelling for carbon and oxygen lines in the solar transition region have shown
improvements in the emission of singly- and doubly-charged ions, along with
Li-like ions. However, discrepancies still remain, particularly for
singly-charged ions and intercombination lines. The aim of this work is to
explore additional atomic processes that could further alter the charge state
distribution and the level populations within ions, in order to resolve some of
the discrepancies. To this end, excitation and ionisation caused by both the
radiation field and by atom-ion collisions have been included, along with
recombination through charge transfer. The modelling is carried out using
conditions which would be present in the quiet Sun, which allows an assessment
of the part atomic processes play in changing coronal modelling, separately
from dynamic and transient events taking place in the plasma. The effect the
processes have on the fractional ion populations are presented, as well as the
change in level populations brought about by the new excitation mechanisms.
Contribution functions of selected lines from low charge states are also shown,
to demonstrate the extent to which line emission in the lower atmosphere could
be affected by the new modelling.",http://arxiv.org/abs/2102.09278v1
Person Re-identification based on Robust Features in Open-world,2021-02-22T06:49:28Z,"Yaguan Qian, Anlin Sun","Deep learning technology promotes the rapid development of person
re-identifica-tion (re-ID). However, some challenges are still existing in the
open-world. First, the existing re-ID research usually assumes only one factor
variable (view, clothing, pedestrian pose, pedestrian occlusion, image
resolution, RGB/IR modality) changing, ignoring the complexity of multi-factor
variables in the open-world. Second, the existing re-ID methods are over depend
on clothing color and other apparent features of pedestrian, which are easily
disguised or changed. In addition, the lack of benchmark datasets containing
multi-factor variables is also hindering the practically application of re-ID
in the open-world. In this paper, we propose a low-cost and high-efficiency
method to solve shortcomings of the existing re-ID research, such as unreliable
feature selection, low efficiency of feature extraction, single research
variable, etc. Our approach based on pose estimation model improved by group
convolution to obtain the continuous key points of pedestrian, and utilize
dynamic time warping (DTW) to measure the similarity of features between
different pedestrians. At the same time, to verify the effectiveness of our
method, we provide a miniature dataset which is closer to the real world and
includes pedestrian changing clothes and cross-modality factor variables
fusion. Extensive experiments are conducted and the results show that our
method achieves Rank-1: 60.9%, Rank-5: 78.1%, and mAP: 49.2% on this dataset,
which exceeds most existing state-of-art re-ID models.",http://arxiv.org/abs/2102.10798v1
"Strapdown Inertial Navigation System Initial Alignment based on Group of
  Double Direct Spatial Isometries",2021-02-25T05:52:00Z,"Lubin Chang, Fangjun Qin, Jiangning Xu","The task of strapdown inertial navigation system (SINS) initial alignment is
to calculate the attitude transformation matrix from body frame to navigation
frame. In this paper, such attitude transformation matrix is divided into two
parts through introducing the initial inertially fixed navigation frame as
inertial frame. The attitude changes of the navigation frame corresponding to
the defined inertial frame can be exactly calculated with known velocity and
position provided by GNSS. The attitude from body frame to the defined inertial
frame is estimated based on the SINS mechanization in inertial frame. The
attitude, velocity and position in inertial frame are formulated together as
element of the group of double direct spatial isometries.It is proven that the
group state model in inertial frame satisfies a particular ""group affine""
property and the corresponding error model satisfies a ""log linear"" autonomous
differential equation on the Lie algebra. Based on such striking property, the
attitude from body frame to the defined inertial frame can be estimated based
on the linear error model with even extreme large misalignments. Two different
error state vectors are extracted based on right and left matrix
multiplications and the detailed linear state space models are derived based on
the right and left errors for SINS mechanization in inertial frame. With the
derived linear state space models, the explicit initial alignment procedures
have been presented. Extensive simulation and field tests indicate that the
initial alignment based on the left error model can perform quite well within a
wide range of initial attitude errors, although the used filter is still a type
of linear Kalman filter. This method is promising in practical products
abandoning the traditional coarse alignment stage.",http://arxiv.org/abs/2102.12697v1
"Investigating Design Anti-pattern and Design Pattern Mutations and Their
  Change- and Fault-proneness",2021-03-31T18:43:18Z,"Zeinab, Kermansaravi, Md Saidur Rahman, Foutse Khomh, Fehmi Jaafar, Yann-Gael Gueheneuc","During software evolution, inexperienced developers may introduce design
anti-patterns when they modify their software systems to fix bugs or to add new
functionalities based on changes in requirements. Developers may also use
design patterns to promote software quality or as a possible cure for some
design anti-patterns. Thus, design patterns and design anti-patterns are
introduced, removed, and mutated from one another by developers.
  Many studies investigated the evolution of design patterns and design
anti-patterns and their impact on software development. However, they
investigated design patterns or design anti-patterns in isolation and did not
consider their mutations and the impact of these mutations on software quality.
Therefore, we report our study of bidirectional mutations between design
patterns and design anti-patterns and the impacts of these mutations on
software change- and fault-proneness.
  We analyzed snapshots of seven Java software systems with diverse sizes,
evolution histories, and application domains. We built Markov models to capture
the probability of occurrences of the different design patterns and design
anti-patterns mutations. Results from our study show that (1) design patterns
and design anti-patterns mutate into other design patterns and/or design
anti-patterns. They also show that (2) some change types primarily trigger
mutations of design patterns and design anti-patterns (renaming and changes to
comments, declarations, and operators), and (3) some mutations of design
anti-patterns and design patterns are more faulty in specific contexts. These
results provide important insights into the evolution of design patterns and
design anti-patterns and its impact on the change- and fault-proneness of
software systems.",http://arxiv.org/abs/2104.00058v1
"Bayesian Functional Principal Components Analysis via Variational
  Message Passing",2021-04-01T17:42:15Z,"Tui H. Nolan, Jeff Goldsmith, David Ruppert","Functional principal components analysis is a popular tool for inference on
functional data. Standard approaches rely on an eigendecomposition of a
smoothed covariance surface in order to extract the orthonormal functions
representing the major modes of variation. This approach can be a
computationally intensive procedure, especially in the presence of large
datasets with irregular observations. In this article, we develop a Bayesian
approach, which aims to determine the Karhunen-Lo\`eve decomposition directly
without the need to smooth and estimate a covariance surface. More
specifically, we develop a variational Bayesian algorithm via message passing
over a factor graph, which is more commonly referred to as variational message
passing. Message passing algorithms are a powerful tool for compartmentalizing
the algebra and coding required for inference in hierarchical statistical
models. Recently, there has been much focus on formulating variational
inference algorithms in the message passing framework because it removes the
need for rederiving approximate posterior density functions if there is a
change to the model. Instead, model changes are handled by changing specific
computational units, known as fragments, within the factor graph. We extend the
notion of variational message passing to functional principal components
analysis. Indeed, this is the first article to address a functional data model
via variational message passing. Our approach introduces two new fragments that
are necessary for Bayesian functional principal components analysis. We present
the computational details, a set of simulations for assessing accuracy and
speed and an application to United States temperature data.",http://arxiv.org/abs/2104.00645v1
"Dimensional reduction of cavities with axial symmetry: A complete
  analysis of when an optical fiber is approximately one-dimensional",2021-04-01T19:47:34Z,"Daniel Grimmer, Richard Lopp, Eduardo Martín-Martínez","Intuition dictates that a very long, very thin cavity (e.g., a fiber optic
cable) could perhaps be modeled as an approximately one dimensional system. In
this paper we rigorously explore the validity of such intuition from the
perspective of a localized probe coupling to a quantum field inside a cavity
(e.g., an atom or an Unruh-DeWitt particle detector in a fiber optic cable). To
do so, we introduce the notion of subfield decomposition in which a $D+1$
dimensional quantum field in an axially-symmetric cavity can be reduced to an
infinite collection of uncoupled, massive $1+1$ dimensional fields. We show
that the ability to approximate a higher-dimensional scenario by a $1+1$
dimensional model is equivalent to making a certain change of the probe's shape
in the higher-dimensional space. The approximation is justified whenever this
change of shape is ""small enough"". In this light, we identify the dynamically
relevant norm by which the magnitude of these changes in probe shape ought to
be judged. Finally, we explore this approximation in particular setups
corresponding to quantum optics and superconducting circuits.",http://arxiv.org/abs/2104.00745v2
"Quick Line Outage Identification in Urban Distribution Grids via Smart
  Meters",2021-04-01T07:10:34Z,"Yizheng Liao, Yang Weng, Chin-woo Tan, Ram Rajagopal","The growing integration of distributed energy resources (DERs) in
distribution grids raises various reliability issues due to DER's uncertain and
complex behaviors. With a large-scale DER penetration in distribution grids,
traditional outage detection methods, which rely on customers report and smart
meters' last gasp signals, will have poor performance, because the renewable
generators and storages and the mesh structure in urban distribution grids can
continue supplying power after line outages. To address these challenges, we
propose a data-driven outage monitoring approach based on the stochastic time
series analysis with a theoretical guarantee. Specifically, we prove via power
flow analysis that the dependency of time-series voltage measurements exhibits
significant statistical changes after line outages. This makes the theory on
optimal change-point detection suitable to identify line outages. However,
existing change point detection methods require post-outage voltage
distribution, which is unknown in distribution systems. Therefore, we design a
maximum likelihood estimator to directly learn the distribution parameters from
voltage data. We prove that the estimated parameters-based detection also
achieves the optimal performance, making it extremely useful for fast
distribution grid outage identifications. Furthermore, since smart meters have
been widely installed in distribution grids and advanced infrastructure (e.g.,
PMU) has not widely been available, our approach only requires voltage
magnitude for quick outage identification. Simulation results show highly
accurate outage identification in eight distribution grids with 14
configurations with and without DERs using smart meter data.",http://arxiv.org/abs/2104.02056v1
On Adaptive Fairness in Software Systems,2021-04-06T10:44:28Z,"Ali Farahani, Liliana Pasquale, Amel Bennaceur, Thomas Welsh, Bashar Nuseibeh","Software systems are increasingly making decisions on behalf of humans,
raising concerns about the fairness of such decisions. Such concerns are
usually attributed to flaws in algorithmic design or biased data, but we argue
that they are often the result of a lack of explicit specification of fairness
requirements. However, such requirements are challenging to elicit, a problem
exacerbated by increasingly dynamic environments in which software systems
operate, as well as stakeholders' changing needs. Therefore, capturing all
fairness requirements during the production of software is challenging, and is
insufficient for addressing software changes post deployment. In this paper, we
propose adaptive fairness as a means for maintaining the satisfaction of
changing fairness requirements. We demonstrate how to combine
requirements-driven and resource-driven adaptation in order to address
variabilities in both fairness requirements and their associated resources.
Using models for fairness requirements, resources, and their relations, we show
how the approach can be used to provide systems owners and end-users with
capabilities that reflect adaptive fairness behaviours at runtime. We
demonstrate our approach using an example drawn from shopping experiences of
citizens. We conclude with a discussion of open research challenges in the
engineering of adaptive fairness in human-facing software systems.",http://arxiv.org/abs/2104.02414v2
"The Effects of Process Parameters on Melt-pool Oscillatory Behaviour in
  Gas Tungsten Arc Welding",2021-04-06T13:23:38Z,"Amin Ebrahimi, Chris R. Kleijn, Marcel J. M. Hermans, Ian M. Richardson","Internal flow behaviour and melt-pool surface oscillations during arc welding
are complex and not yet fully understood. In the present work, high-fidelity
numerical simulations are employed to describe the effects of welding position,
sulphur concentration (60-300 ppm) and travel speed (1.25-5 mm/s) on molten
metal flow dynamics in fully-penetrated melt-pools. A wavelet transform is
implemented to obtain time-resolved frequency spectra of the oscillation
signals, which overcomes the shortcomings of the Fourier transform in rendering
time resolution of the frequency spectra. Comparing the results of the present
numerical calculations with available analytical and experimental datasets, the
robustness of the proposed approach in predicting melt-pool oscillations is
demonstrated. The results reveal that changes in the surface morphology of the
pool resulting from a change in welding position alter the spatial distribution
of arc forces and power-density applied to the molten material, and in turn
affect flow patterns in the pool. Under similar welding conditions, changing
the sulphur concentration affects the Marangoni flow pattern, and increasing
the travel speed decreases the size of the pool and increases the offset
between top and bottom melt-pool surfaces, affecting the flow structures
(vortex formation) on the surface. Variations in the internal flow pattern
affect the evolution of melt-pool shape and its surface oscillations.",http://arxiv.org/abs/2104.02713v1
Shelling the m=1 amplituhedron,2021-04-06T21:18:10Z,"Steven N. Karp, John Machacek","The amplituhedron $\mathcal{A}_{n,k,m}$ was introduced by Arkani-Hamed and
Trnka (2014) in order to give a geometric basis for calculating scattering
amplitudes in planar $\mathcal{N}=4$ supersymmetric Yang-Mills theory. It is a
projection inside the Grassmannian $\text{Gr}_{k,k+m}$ of the totally
nonnegative part of $\text{Gr}_{k,n}$. Karp and Williams (2019) studied the
$m=1$ amplituhedron $\mathcal{A}_{n,k,1}$, giving a regular CW decomposition of
it. Its face poset $R_{n,l}$ (with $l := n-k-1$) consists of all projective
sign vectors of length $n$ with exactly $l$ sign changes. We show that
$R_{n,l}$ is EL-shellable, resolving a problem posed by Karp and Williams. This
gives a new proof that $\mathcal{A}_{n,k,1}$ is homeomorphic to a closed ball,
which was originally proved by Karp and Williams. We also give explicit
formulas for the $f$-vector and $h$-vector of $R_{n,l}$, and show that it is
rank-log-concave and strongly Sperner. Finally, we consider a related poset
$P_{n,l}$ introduced by Machacek (2019), consisting of all projective sign
vectors of length $n$ with at most $l$ sign changes. We show that it is
rank-log-concave, and conjecture that it is Sperner.",http://arxiv.org/abs/2104.02786v2
"Transition from physical to online shopping alternatives due to the
  COVID-19 pandemic",2021-03-25T16:27:17Z,"Claudia Andruetto, Elisa Bin, Yusak Susilo, Anna Pernestål","By using 530 responses from an online questionnaire, this study aims to
investigate the transition from physical to online shopping alternatives during
the first wave of the COVID-19 pandemic period at the individual level. The
focus areas of the study are Sweden and Italy, two European countries that
implemented contrasting prevention measures. This study analyses the impacts of
the pandemic to the shopping behaviour and identifies, among the respondents,
who have changed the behaviour the most, how respondents have adopted different
shopping strategies, what the main differences between Italian and Swedish
responses are and the influence of population density on the behavioural
change. Multivariate statistical analyses, including linear and binary logistic
regressions and multinomial logit models were used to analyse the dataset. The
results confirm the differences between Italy and Sweden in terms of social
distancing measures, social structures and technology readiness. Moreover, the
socio-demographic and household structures of the respondents were found
instrumental in influencing the amount and the direction of change in shopping
behaviour during the first wave of the pandemic period. The output of this
study highlights the impact that contrasting policies have on citizens, and
also the importance of having policies that are adaptable to different
situations.",http://arxiv.org/abs/2104.04061v2
"Temporal characterization of electron dynamics in attosecond XUV and
  infrared laser fields",2021-04-09T05:34:07Z,"L. Guo, Y. Jia, M. Q. Liu, X. Y. Jia, S. L. Hu, R. H. Lu, S. S. Han, J. Chen","We use a Wigner distribution-like function based on the strong field
approximation theory to obtain the time-energy distributions and the ionization
time distributions of electrons ionized by an XUV pulse alone and in the
presence of an infrared (IR) pulse. In the case of a single XUV pulse, although
the overall shape of the ionization time distribution resembles the
XUV-envelope, its detail shows dependence on the emission direction of the
electron and the carrier-envelope phase of the pulse, which mainly results from
the low-energy interference structure. It is further found that the electron
from the counter-rotating term plays an important role in the interference. In
the case of the two-color pulse, both the time-energy distributions and the
ionization time distributions change with varying IR field. Our analysis
demonstrates that the IR field not only modifies the final electron kinetic
energy but also changes the electron's emission time, which results from the
change of the electric field induced by the IR pulse. Moreover, the ionization
time distributions of the photoelectrons emitted from atoms with higher
ionization energy are also given, which show less impact of the IR field on the
electron dynamics.",http://arxiv.org/abs/2104.04198v1
"New Insights on Reducing Abrupt Representation Change in Online
  Continual Learning",2021-04-11T15:19:30Z,"Lucas Caccia, Rahaf Aljundi, Nader Asadi, Tinne Tuytelaars, Joelle Pineau, Eugene Belilovsky","In the online continual learning paradigm, agents must learn from a changing
distribution while respecting memory and compute constraints. Experience Replay
(ER), where a small subset of past data is stored and replayed alongside new
data, has emerged as a simple and effective learning strategy. In this work, we
focus on the change in representations of observed data that arises when
previously unobserved classes appear in the incoming data stream, and new
classes must be distinguished from previous ones. We shed new light on this
question by showing that applying ER causes the newly added classes'
representations to overlap significantly with the previous classes, leading to
highly disruptive parameter updates. Based on this empirical analysis, we
propose a new method which mitigates this issue by shielding the learned
representations from drastic adaptation to accommodate new classes. We show
that using an asymmetric update rule pushes new classes to adapt to the older
ones (rather than the reverse), which is more effective especially at task
boundaries, where much of the forgetting typically occurs. Empirical results
show significant gains over strong baselines on standard continual learning
benchmarks.",http://arxiv.org/abs/2104.05025v3
Shuffler: A Large Scale Data Management Tool for ML in Computer Vision,2021-04-11T22:27:28Z,"Evgeny Toropov, Paola A. Buitrago, Jose M. F. Moura","Datasets in the computer vision academic research community are primarily
static. Once a dataset is accepted as a benchmark for a computer vision task,
researchers working on this task will not alter it in order to make their
results reproducible. At the same time, when exploring new tasks and new
applications, datasets tend to be an ever changing entity. A practitioner may
combine existing public datasets, filter images or objects in them, change
annotations or add new ones to fit a task at hand, visualize sample images, or
perhaps output statistics in the form of text or plots. In fact, datasets
change as practitioners experiment with data as much as with algorithms, trying
to make the most out of machine learning models. Given that ML and deep
learning call for large volumes of data to produce satisfactory results, it is
no surprise that the resulting data and software management associated to
dealing with live datasets can be quite complex. As far as we know, there is no
flexible, publicly available instrument to facilitate manipulating image data
and their annotations throughout a ML pipeline. In this work, we present
Shuffler, an open source tool that makes it easy to manage large computer
vision datasets. It stores annotations in a relational, human-readable
database. Shuffler defines over 40 data handling operations with annotations
that are commonly useful in supervised learning applied to computer vision and
supports some of the most well-known computer vision datasets. Finally, it is
easily extensible, making the addition of new operations and datasets a task
that is fast and easy to accomplish.",http://arxiv.org/abs/2104.05125v1
"Breakdown of quantum-classical correspondence and dynamical generation
  of entanglement",2021-04-14T03:09:24Z,"Chushun Tian, Kun Yang","The {\it exchange} interaction arising from the particle indistinguishability
is of central importance to physics of many-particle quantum systems. Here we
study analytically the dynamical generation of quantum entanglement induced by
this interaction in an isolated system, namely, an ideal Fermi gas confined in
a chaotic cavity, which evolves unitarily from a non-Gaussian pure state. We
find that the breakdown of the quantum-classical correspondence of particle
motion, via dramatically changing the spatial structure of many-body
wavefunction, leads to profound changes of the entanglement structure.
Furthermore, for a class of initial states, such change leads to the approach
to thermal equilibrium everywhere in the cavity, with the well-known Ehrenfest
time in quantum chaos as the thermalization time. Specifically, the quantum
expectation values of various correlation functions at different spatial scales
are all determined by the Fermi-Dirac distribution. In addition, by using the
reduced density matrix (RDM) and the entanglement entropy (EE) as local probes,
we find that the gas inside a subsystem is at equilibrium with that outside,
and its thermal entropy is the EE, even though the whole system is in a pure
state. As a by-product of this work, we provide an analytical solution
supporting an important conjecture on thermalization, made and numerically
studied by Garrison and Grover in: Phys. Rev. X \textbf{8}, 021026 (2018), and
strengthen its statement.",http://arxiv.org/abs/2104.06605v1
"Temporal Adaptation of BERT and Performance on Downstream Document
  Classification: Insights from Social Media",2021-04-16T13:48:53Z,"Paul Röttger, Janet B. Pierrehumbert","Language use differs between domains and even within a domain, language use
changes over time. For pre-trained language models like BERT, domain adaptation
through continued pre-training has been shown to improve performance on
in-domain downstream tasks. In this article, we investigate whether temporal
adaptation can bring additional benefits. For this purpose, we introduce a
corpus of social media comments sampled over three years. It contains
unlabelled data for adaptation and evaluation on an upstream masked language
modelling task as well as labelled data for fine-tuning and evaluation on a
downstream document classification task. We find that temporality matters for
both tasks: temporal adaptation improves upstream and temporal fine-tuning
downstream task performance. Time-specific models generally perform better on
past than on future test sets, which matches evidence on the bursty usage of
topical words. However, adapting BERT to time and domain does not improve
performance on the downstream task over only adapting to domain. Token-level
analysis shows that temporal adaptation captures event-driven changes in
language use in the downstream task, but not those changes that are actually
relevant to task performance. Based on our findings, we discuss when temporal
adaptation may be more effective.",http://arxiv.org/abs/2104.08116v2
Editing Factual Knowledge in Language Models,2021-04-16T15:24:42Z,"Nicola De Cao, Wilker Aziz, Ivan Titov","The factual knowledge acquired during pre-training and stored in the
parameters of Language Models (LMs) can be useful in downstream tasks (e.g.,
question answering or textual inference). However, some facts can be
incorrectly induced or become obsolete over time. We present KnowledgeEditor, a
method which can be used to edit this knowledge and, thus, fix 'bugs' or
unexpected predictions without the need for expensive re-training or
fine-tuning. Besides being computationally efficient, KnowledgeEditordoes not
require any modifications in LM pre-training (e.g., the use of meta-learning).
In our approach, we train a hyper-network with constrained optimization to
modify a fact without affecting the rest of the knowledge; the trained
hyper-network is then used to predict the weight update at test time. We show
KnowledgeEditor's efficacy with two popular architectures and
knowledge-intensive tasks: i) a BERT model fine-tuned for fact-checking, and
ii) a sequence-to-sequence BART model for question answering. With our method,
changing a prediction on the specific wording of a query tends to result in a
consistent change in predictions also for its paraphrases. We show that this
can be further encouraged by exploiting (e.g., automatically-generated)
paraphrases during training. Interestingly, our hyper-network can be regarded
as a 'probe' revealing which components need to be changed to manipulate
factual knowledge; our analysis shows that the updates tend to be concentrated
on a small subset of components. Source code available at
https://github.com/nicola-decao/KnowledgeEditor",http://arxiv.org/abs/2104.08164v2
"TIE: A Framework for Embedding-based Incremental Temporal Knowledge
  Graph Completion",2021-04-17T01:40:46Z,"Jiapeng Wu, Yishi Xu, Yingxue Zhang, Chen Ma, Mark Coates, Jackie Chi Kit Cheung","Reasoning in a temporal knowledge graph (TKG) is a critical task for
information retrieval and semantic search. It is particularly challenging when
the TKG is updated frequently. The model has to adapt to changes in the TKG for
efficient training and inference while preserving its performance on historical
knowledge. Recent work approaches TKG completion (TKGC) by augmenting the
encoder-decoder framework with a time-aware encoding function. However, naively
fine-tuning the model at every time step using these methods does not address
the problems of 1) catastrophic forgetting, 2) the model's inability to
identify the change of facts (e.g., the change of the political affiliation and
end of a marriage), and 3) the lack of training efficiency. To address these
challenges, we present the Time-aware Incremental Embedding (TIE) framework,
which combines TKG representation learning, experience replay, and temporal
regularization. We introduce a set of metrics that characterizes the
intransigence of the model and propose a constraint that associates the deleted
facts with negative labels. Experimental results on Wikidata12k and YAGO11k
datasets demonstrate that the proposed TIE framework reduces training time by
about ten times and improves on the proposed metrics compared to vanilla
full-batch training. It comes without a significant loss in performance for any
traditional measures. Extensive ablation studies reveal performance trade-offs
among different evaluation metrics, which is essential for decision-making
around real-world TKG applications.",http://arxiv.org/abs/2104.08419v3
"Structure-dynamics relationships in cryogenically deformed bulk metallic
  glass",2021-04-19T13:31:15Z,"Florian Spieckermann, Daniel Şopu, Viktor Soprunyuk, Michael B. Kerber, Jozef Bednarčík, Alexander Schökel, Amir Rezvan, Sergey Ketov, Baran Sarac, Erhard Schafler, Jürgen Eckert","The atomistic mechanisms occurring during the processes of aging and
rejuvenation in glassy materials involve very small structural rearrangements
that are extremely difficult to capture experimentally. Here we use in-situ
X-ray diffraction to investigate the structural rearrangements during annealing
from 77 K up to the crystallization temperature in Cu44Zr44Al8Hf2Co2 bulk
metallic glass rejuvenated by high pressure torsion performed at cryogenic
temperatures and at room temperature. Using a measure of the configurational
entropy calculated from the X-ray pair correlation function, the structural
footprint of the deformation-induced rejuvenation in bulk metallic glass is
revealed. With synchrotron radiation, temperature and time resolutions
comparable to calorimetric experiments are possible. This opens hitherto
unavailable experimental possibilities allowing to unambiguously correlate
changes in atomic configuration and structure to calorimetrically observed
signals and can attribute those to changes of the dynamic and vibrational
relaxations ({\alpha}-, {\beta}- and {\gamma}-transition) in glassy materials.
The results suggest that the structural footprint of the {\beta}-transition is
related to entropic relaxation with characteristics of a first-order
transition. Dynamic mechanical analysis data shows that in the range of the
{\beta}-transition, non-reversible structural rearrangements are preferentially
activated. The low-temperature {\gamma}-transition is mostly triggering
reversible deformations and shows a change of slope in the entropic footprint
suggesting second-order characteristics.",http://arxiv.org/abs/2104.09292v2
"Transcriptome-wide prediction of prostate cancer gene expression from
  histopathology images using co-expression based convolutional neural networks",2021-04-19T13:50:25Z,"Philippe Weitz, Yinxi Wang, Kimmo Kartasalo, Lars Egevad, Johan Lindberg, Henrik Grönberg, Martin Eklund, Mattias Rantalainen","Molecular phenotyping by gene expression profiling is common in contemporary
cancer research and in molecular diagnostics. However, molecular profiling
remains costly and resource intense to implement, and is just starting to be
introduced into clinical diagnostics. Molecular changes, including genetic
alterations and gene expression changes, occuring in tumors cause morphological
changes in tissue, which can be observed on the microscopic level. The
relationship between morphological patterns and some of the molecular
phenotypes can be exploited to predict molecular phenotypes directly from
routine haematoxylin and eosin (H&E) stained whole slide images (WSIs) using
deep convolutional neural networks (CNNs). In this study, we propose a new,
computationally efficient approach for disease specific modelling of
relationships between morphology and gene expression, and we conducted the
first transcriptome-wide analysis in prostate cancer, using CNNs to predict
bulk RNA-sequencing estimates from WSIs of H&E stained tissue. The work is
based on the TCGA PRAD study and includes both WSIs and RNA-seq data for 370
patients. Out of 15586 protein coding and sufficiently frequently expressed
transcripts, 6618 had predicted expression significantly associated with
RNA-seq estimates (FDR-adjusted p-value < 1*10-4) in a cross-validation. 5419
(81.9%) of these were subsequently validated in a held-out test set. We also
demonstrate the ability to predict a prostate cancer specific cell cycle
progression score directly from WSIs. These findings suggest that contemporary
computer vision models offer an inexpensive and scalable solution for
prediction of gene expression phenotypes directly from WSIs, providing
opportunity for cost-effective large-scale research studies and molecular
diagnostics.",http://arxiv.org/abs/2104.09310v1
"Various magnetism of the compressed antiferromagnetic topological
  insulator EuSn2As2",2021-04-19T16:02:47Z,"Hualei Sun, Cuiqun Chen, Yusheng Hou, Yu Gong, Mengwu Huo, Lisi Li, Jia Yu, Wanping Cai, Naitian Liu, Ruqian Wu, Dao-Xin Yao, Meng Wang","We report a comprehensive high-pressure study on the antiferromagnetic
topological insulator EuSn2As2 up to 21.1 GPa through measurements of
synchrotron x-ray diffraction, electrical resistance, magnetic resistance, and
Hall transports combined with first-principles calculations. No evident trace
of a structural phase transition is detected. The Neel temperatures determined
from resistance are increased from 24 to 77 K under pressure, which is resulted
from the enhanced magnetic exchange couplings between Eu2+ ions yielded by our
first-principles calculations. The negative magnetoresistance of EuSn2As2
persists to higher temperatures accordantly. However, the enhancement of the
observed N\'eel temperatures deviates from the calculations obviously above
10.0 GPa. In addition, the magnitude of the magnetoresistance, the Hall
coefficients, and the charge carrier densities show abrupt changes between 6.9
to 10.0 GPa. The abrupt changes probably originate from a pressure induced
valence change of Eu ions from a divalent state to a divalent and trivalent
mixed state. Our results provide insights into variation of the magnetism of
EuSn2As2 and similar antiferromagnetic topological insulators under pressure.",http://arxiv.org/abs/2104.09412v1
"Void defect induced magnetism and structure change of carbon material-3,
  Polycyclic aromatic hydrocarbon",2021-04-20T03:52:35Z,"Norio Ota, Aigen Li, Laszlo Nemes","Void-defect induced magnetism of graphene molecule was recently reported in
our previous paper of this series study. This paper investigated the case of
hydrogenated graphene molecule, in chemical term, polycyclic aromatic
hydrocarbon (PAH). Molecular infrared spectrum obtained by density functional
theory was compared with astronomical observation. Void-defect on PAH caused
serious structure change. Typical example of C23H12 had two carbon pentagon
rings among hexagon networks. Stable spin state was non-magnetic singlet state.
This is contrary to pure carbon case of C23, which show magnetic triplet state.
It was discussed that Hydrogen played an important role to diminish magnetism
by creating an SP3-bond among SP2-networks. Such a structure change affected
molecular vibration and finally to photoemission spectrum in infrared region.
The dication-C23H12 showed featured bands at 3.2, 6.3, 7.7, 8.6, 11.2, and 12.7
micrometer. It was surprising that those calculated bands coincided well with
astronomically observed bands in many planetary nebulae. To confirm our study,
large size molecule of C53H18 was studied. Calculation reproduced again similar
astronomical bands. Also, small size molecule of C12H8 showed good coincidence
with the spectrum observed for young stars. This paper would be the first
report to indicate the specific PAH in space.",http://arxiv.org/abs/2104.09747v2
An Efficient Approach for Anomaly Detection in Traffic Videos,2021-04-20T04:43:18Z,"Keval Doshi, Yasin Yilmaz","Due to its relevance in intelligent transportation systems, anomaly detection
in traffic videos has recently received much interest. It remains a difficult
problem due to a variety of factors influencing the video quality of a
real-time traffic feed, such as temperature, perspective, lighting conditions,
and so on. Even though state-of-the-art methods perform well on the available
benchmark datasets, they need a large amount of external training data as well
as substantial computational resources. In this paper, we propose an efficient
approach for a video anomaly detection system which is capable of running at
the edge devices, e.g., on a roadside camera. The proposed approach comprises a
pre-processing module that detects changes in the scene and removes the
corrupted frames, a two-stage background modelling module and a two-stage
object detector. Finally, a backtracking anomaly detection algorithm computes a
similarity statistic and decides on the onset time of the anomaly. We also
propose a sequential change detection algorithm that can quickly adapt to a new
scene and detect changes in the similarity statistic. Experimental results on
the Track 4 test set of the 2021 AI City Challenge show the efficacy of the
proposed framework as we achieve an F1-score of 0.9157 along with 8.4027 root
mean square error (RMSE) and are ranked fourth in the competition.",http://arxiv.org/abs/2104.09758v1
"Electrically driven programmable phase-change meta-switch reaching 80%
  efficiency",2021-04-21T06:44:39Z,"Sajjad Abdollahramezani, Omid Hemmatyar, Mohammad Taghinejad, Hossein Taghinejad, Alex Krasnok, Ali A. Eftekhar, Christian Teichrib, Sanchit Deshmukh, Mostafa El-Sayed, Eric Pop, Matthias Wuttig, Andrea Alu, Wenshan Cai, Ali Adibi","Despite recent advances in active metaoptics, wide dynamic range combined
with high-speed reconfigurable solutions is still elusive. Phase-change
materials (PCMs) offer a compelling platform for metasurface optical elements,
owing to the large index contrast and fast yet stable phase transition
properties. Here, we experimentally demonstrate an in situ electrically-driven
reprogrammable metasurface by harnessing the unique properties of a
phase-change chalcogenide alloy, Ge$_{2}$Sb$_{2}$Te$_{5}$ (GST), in order to
realize fast, non-volatile, reversible, multilevel, and pronounced optical
modulation in the near-infrared spectral range. Co-optimized through a
multiphysics analysis, we integrate an efficient heterostructure resistive
microheater that indirectly heats and transforms the embedded GST film without
compromising the optical performance of the metasurface even after several
reversible phase transitions. A hybrid plasmonic-PCM meta-switch with a record
electrical modulation of the reflectance over eleven-fold (an absolute
reflectance contrast reaching 80%), unprecedented quasi-continuous spectral
tuning over 250 nm, and switching speed that can potentially reach a few kHz is
presented. Our work represents a significant step towards the development of
fully integrable dynamic metasurfaces and their potential for beamforming
applications.",http://arxiv.org/abs/2104.10381v2
"The visualisation of two-dimensional dose distribution on X-ray CT using
  radiochromic film",2021-04-22T00:27:55Z,"Nobuyoshi Tanki, Toshizo Katsuda, Masashi Sasaki, Rumi Gotanda, Tatsuhiro Gotanda, Shinya Imai, Yasuyuki Kawaji, Atsushi Noguchi","X-ray CT dose measurement has mainly been performed using an ionization
chamber dosimeter. Therefore, the dose distribution has not been sufficiently
studied. We investigated the importance of evaluating the two or
three-dimensional dose distributions for X-ray computed tomography (CT). To
confirm this purpose, we investigated the effects of phantom size and exposure
parameters on the phantom diameter. We performed 12 scans using XR-QA2 film and
cylindrical acrylic phantoms of two lengths. The tube current and slice
thicknesses were varied as exposure parameters. The dose distribution of the
primary and scattered radiation was visu-alised using ImageJ. The results were
evaluated using the profile curves, three-dimensional surface plots, and
subtrac-tion dose images. We observed changes in the dose distributions for
scans with and without phantoms. However, no significant differ-ence in the
dose distribution was observed with changes in the lengths of the phantom. To
visualise the dose distribution, three-dimensional surface plots and
subtraction images were found helpful. We must confirm that the dose
distribution does not change for phantoms with multiple diameters in future
studies. For using a clinical application, accurate quantitative assessment of
dose distribution requires improved accuracy of the calibration curve.",http://arxiv.org/abs/2104.10803v1
"Uncovering Phase Change Memory Energy Limits by Sub-Nanosecond Probing
  of Power Dissipation Dynamics",2021-04-23T11:40:23Z,"Keren Stern, Nicolás Wainstein, Yair Keller, Christopher M. Neumann, Eric Pop, Shahar Kvatinsky, Eilam Yalon","Phase change memory (PCM) is one of the leading candidates for neuromorphic
hardware and has recently matured as a storage class memory. Yet, energy and
power consumption remain key challenges for this technology because part of the
PCM device must be self-heated to its melting temperature during reset. Here,
we show that this reset energy can be reduced by nearly two orders of magnitude
by minimizing the pulse width. We utilize a high-speed measurement setup to
probe the energy consumption in PCM cells with varying pulse width (0.3 to 40
nanoseconds) and uncover the power dissipation dynamics. A key finding is that
the switching power (P) remains unchanged for pulses wider than a short thermal
time constant of the PCM ($\tau$$_t$$_h$ < 1 ns in 50 nm diameter device),
resulting in a decrease of energy (E=P$\tau$) as the pulse width $\tau$ is
reduced in that range. In other words, thermal confinement during short pulses
is achieved by limiting the heat diffusion time. Our improved programming
scheme reduces reset energy density below 0.1 nJ/$\mu$m$^2$, over an order of
magnitude lower than state-of-the-art PCM, potentially changing the roadmap of
future data storage technology and paving the way towards energy-efficient
neuromorphic hardware",http://arxiv.org/abs/2104.11545v2
Refraction of space-time wave packets: I. Theoretical principles,2021-04-27T04:13:51Z,"Murat Yessenov, Basanta Bhaduri, Ayman F. Abouraddy","Space-time (ST) wave packets are pulsed optical beams endowed with precise
spatio-temporal structure by virtue of which they exhibit unique and useful
characteristics, such as propagation invariance and tunable group velocity. We
study in detail here, and in two accompanying papers, the refraction of ST wave
packets at planar interfaces between non-dispersive, homogeneous, isotropic
dielectrics. We formulate a law of refraction that determines the change in the
ST wave-packet group velocity across such an interface as a consequence of a
newly identified optical refractive invariant that we call 'the spectral
curvature'. Because the spectral curvature vanishes in conventional optical
fields where the spatial and temporal degrees of freedom are separable, these
phenomena have not been observed to date. We derive the laws of refraction for
baseband, X-wave, and sideband ST wave packets that reveal fascinating
refractive phenomena, especially for the former class of wave packets. We
predict theoretically, and confirm experimentally in the accompanying papers,
refractive phenomena such as group-velocity invariance (ST wave packets whose
group velocity does not change across the interface), anomalous refraction
(group-velocity increase in higher-index media), group-velocity inversion
(change in the sign of the group velocity upon refraction but not its
magnitude), and the dependence of the group velocity of the refracted ST wave
packet on the angle of incidence.",http://arxiv.org/abs/2104.12965v1
"The sound speed and core of massive compact stars: A manifestation of
  hadron-quark duality",2021-04-28T15:12:32Z,"Yong-Liang Ma, Mannque Rho","When baryon-quark continuity is formulated in terms of a topology change
without invoking ""explicit "" QCD degrees of freedom at a density higher than
twice the nuclear matter density $n_0$ the core of massive compact stars can be
described in terms of fractionally charged particles, behaving neither like
pure baryons nor deconfined quarks. Hidden symmetries, both local gauge and
pseudo-conformal (or broken scale), lead to the pseudo-conformal (PC) sound
velocity $v_{pcs}^2/c^2\approx 1/3$ at $\gsim 3n_0$ in compact stars. We argue
these symmetries are ""emergent"" from strong nuclear correlations and conjecture
that they reflect hidden symmetries in QCD proper exposed by nuclear
correlations. We establish a possible link between the quenching of $g_A$ in
superallowed Gamow-Teller transitions in nuclei and the precocious onset at
$n\gsim 3n_0$ of the PC sound velocity predicted at the dilaton limit fixed
point. We propose that bringing in explicit quark degrees of freedom as is done
in terms of the ""quarkyonic"" and other hybrid hadron-quark structure and our
topology-change strategy represent the ""hadron-quark duality"" formulated in
terms of the Cheshire-Cat mechanism~\cite{CC} for the smooth cross-over between
hadrons and quarks. Confrontation with currently available experimental
observations is discussed to support this notion.",http://arxiv.org/abs/2104.13822v2
Pushing it out of the Way: Interactive Visual Navigation,2021-04-28T22:46:41Z,"Kuo-Hao Zeng, Luca Weihs, Ali Farhadi, Roozbeh Mottaghi","We have observed significant progress in visual navigation for embodied
agents. A common assumption in studying visual navigation is that the
environments are static; this is a limiting assumption. Intelligent navigation
may involve interacting with the environment beyond just moving
forward/backward and turning left/right. Sometimes, the best way to navigate is
to push something out of the way. In this paper, we study the problem of
interactive navigation where agents learn to change the environment to navigate
more efficiently to their goals. To this end, we introduce the Neural
Interaction Engine (NIE) to explicitly predict the change in the environment
caused by the agent's actions. By modeling the changes while planning, we find
that agents exhibit significant improvements in their navigational
capabilities. More specifically, we consider two downstream tasks in the
physics-enabled, visually rich, AI2-THOR environment: (1) reaching a target
while the path to the target is blocked (2) moving an object to a target
location by pushing it. For both tasks, agents equipped with an NIE
significantly outperform agents without the understanding of the effect of the
actions indicating the benefits of our approach.",http://arxiv.org/abs/2104.14040v2
"Machine-Learning Assisted Optimization Strategies for Phase Change
  Materials Embedded within Electronic Packages",2021-04-21T19:20:04Z,"Meghavin Bhatasana, Amy Marconnet","Leveraging the latent heat of phase change materials (PCMs) can reduce the
peak temperatures and transient variations in temperature in electronic
devices. But as the power levels increase, the thermal conduction pathway from
the heat source to the heat sink limits the effectiveness of these systems. In
this work, we evaluate embedding the PCM within the silicon device layer of an
electronic device to minimize the thermal resistance between the source and the
PCM to minimize this thermal resistance and enhance the thermal performance of
the device. The geometry and material properties of the embedded PCM regions
are optimized using a combination of parametric and machine learning
algorithms. For a fixed geometry, considering commercially available materials,
Solder 174 significantly outperforms other organic and metallic PCMs. Also with
a fixed geometry, the optimal melting points to minimize the peak temperature
is higher than the optimal melting point to minimize the amplitude of the
transient temperature oscillation, and both optima increase with increasing
heater power. Extending beyond conventional optimization strategies, genetic
algorithms and particle swarm optimization with and without neural network
surrogate models are used to enable optimization of many geometric and material
properties. For the test case evaluated, the optimized geometries and
properties are similar between all ML-assisted algorithms, but the
computational time depends on the technique. Ultimately, the optimized design
with embedded phase change materials reduces the maximum temperature rise by
19% and the fluctuations by up to 88% compared to devices without PCM.",http://arxiv.org/abs/2104.14433v1
"Predicting highly correlated hydride-ion diffusion in SrTiO$_3$ crystals
  based on the fragment kinetic Monte Carlo method with machine-learning
  potential",2021-05-02T08:06:48Z,Hiroya Nakata,"Oxyhydrides have drawn attention because of their fast ion conductivity and
strong reducing properties. Recently, hydride ion migration in
SrTiO$_{3-x}$H$_{x}$ oxyhydride crystals has been investigated, showing that
hydride ion migration is blocked by slow oxygen diffusion. In this study, we
investigate the hydride-ion migration mechanism using a kinetic Monte Carlo
approach to understanding the relationship between the hydride and oxygen ions.
The difficulties in applying the method to hydride and oxygen ion migration
involve complex changes in the ionic migration barrier, which shifts
dynamically depending on the characteristics of the surrounding hydride and
oxygen ions. We can predict these complex changes using a machine-learning
neural network model. The simulation can then be performed using this model to
predict the temperature-dependent ionic-migration behavior. We found that our
simulation results with respect to the activation barrier for hydride ion
diffusion accorded well with those obtained by experiment. We also found that
hydride ion migration is affected by slow oxygen diffusion and that oxygen
diffusion is accelerated by changes in the ionic migration barriers. The
parallel-processing efficiency of our proposed method was 84.92 \% for our
1,000-CPU implementation, suggesting that the approach should be widely
applicable to simulations of ionic migration in crystals at a reasonable
computational cost.",http://arxiv.org/abs/2105.00414v2
"Analysis of heat transfer and water flow with phase change in saturated
  porous media by bond-based peridynamics",2021-05-03T10:21:45Z,"Petr Nikolaev, Majid Sedighi, Andrey P Jivkov, Lee Margetts","A wide range of natural and industrial processes involve heat and mass
transport in porous media. In some important cases the transported substance
may undergo phase change, e.g. from liquid to solid and vice versa in the case
of freezing and thawing of soils. The predictive modelling of such phenomena
faces physical (multiple physical processes taking place) and mathematical
(evolving interface with step change of properties) challenges. In this work,
we develop and test a non-local approach based on bond-based peridynamics which
addresses the challenges successfully. Our formulation allows for predicting
the location of the interface between phases, and for calculating the
temperature and pressure distributions within the saturated porous medium under
the conditions of pressure driven water flow. The formulation is verified
against existing analytical solutions for 1D problems, as well as finite
element transient solutions for 2D problems. The agreement found by the
verification exercise demonstrates the accuracy of the proposed methodology.
The detailed coupled description of heat and hydraulic processes can be
considered as a critical step towards a thermo-hydro-mechanical model, which
will allow, for example, description of the hydrological behaviour of
permafrost soils and the frost heave phenomenon.",http://arxiv.org/abs/2105.00734v1
"A Two-Stage Coordinative Zonal Volt/VAR Control Scheme for Distribution
  Systems with High Inverter-based Resources",2021-05-04T10:39:14Z,"Asmaa Alrushoud, Ning Lu","This paper presents a two-stage zonal Volt/VAR control scheme for
coordinating inverter-based resources (IBR) with utility-owned voltage
regulators (VR) to regulate voltage in unbalanced 3-phase distribution systems.
First, correlations between nodal voltages are derived from nodal voltage
sensitivity studies. Then, the feeder is partitioned into non-overlapping,
weakly-coupled voltage control zones based on nodal voltage correlations. IBR
are used in the first stage to regulate voltage changes continuously and VR are
used in the second stage to regulate large voltage deviations. An online VR
voltage setpoint tuning strategy is developed to reduce excessive tap changes
and avoid large voltage fluctuations without retrofitting existing VR
controllers. In addition, the proposed algorithm uses real-time voltage
measurements only from the critical nodes (typically less than 4% of total
nodes) to reduce the sensing and communication needs. Actual distribution
feeder topologies and load and PV time-series data are used to verify the
performance of the algorithm. Because the method is a rule-based approach, it
runs extremely fast, requires fewer measurements, and requires no retrofit to
the existing VR control mechanisms. Simulation results show that the
performance of the proposed method in terms of voltage control results and
average numbers of VR tap changes are satisfactory.",http://arxiv.org/abs/2105.01405v1
"Correlated time variability of multi-component high velocity outflows in
  J162122.54+075808.4",2021-05-05T18:00:13Z,"P. Aromal, R. Srianand, P. Petitjean","We present a detailed analysis of time variability of two distinct C IV broad
absorption line (BAL) components seen in the spectrum of J162122.54+075808.4
($z_{em}$ = 2.1394) using observations from SDSS, NTT and SALT taken at seven
different epochs spanning about 15 years. The blue-BAL component (with an
ejection velocity, $v_{\rm e}\sim37,500$ kms$^{-1}$) is an emerging absorption
that shows equivalent width variations and kinematic shifts consistent with
acceleration. The red-BAL component ($v_{\rm e} \sim 15,400$ kms$^{-1}$) is a
three component absorption. One of the components is emerging and subsequently
disappearing. The two other components show kinematic shifts consistent with
acceleration coupled with equivalent width variability. Interestingly, we find
the kinematic shifts and equivalent width variability of the blue- and red-BAL
components to be correlated. While the C IV emission line flux varies by more
than 17% during our monitoring period, the available light-curves (covering
rest frame 1300-2300 angstrom do not show more than a 0.1 mag variability in
the continuum. This suggests that the variations in the ionizing flux are
larger than that of the near-UV flux. However, the correlated variability seen
between different BAL components cannot be explained solely by photoionization
models without structural changes. In the framework of disk wind models, any
changes in the radial profiles of density and/or velocity triggered either by
disk instabilities or by changes in the ionizing radiation can explain our
observations. High resolution spectroscopic monitoring of J1621+0758 is
important to understand the physical conditions of the absorbing gas and
thereby to constrain the parameters of disk-wind models.",http://arxiv.org/abs/2105.02249v1
"MIMII DUE: Sound Dataset for Malfunctioning Industrial Machine
  Investigation and Inspection with Domain Shifts due to Changes in Operational
  and Environmental Conditions",2021-05-06T14:18:24Z,"Ryo Tanabe, Harsh Purohit, Kota Dohi, Takashi Endo, Yuki Nikaido, Toshiki Nakamura, Yohei Kawaguchi","In this paper, we introduce MIMII DUE, a new dataset for malfunctioning
industrial machine investigation and inspection with domain shifts due to
changes in operational and environmental conditions. Conventional methods for
anomalous sound detection face practical challenges because the distribution of
features changes between the training and operational phases (called domain
shift) due to various real-world factors. To check the robustness against
domain shifts, we need a dataset that actually includes domain shifts, but such
a dataset does not exist so far. The new dataset we created consists of the
normal and abnormal operating sounds of five different types of industrial
machines under two different operational/environmental conditions (source
domain and target domain) independent of normal/abnormal, with domain shifts
occurring between the two domains. Experimental results showed significant
performance differences between the source and target domains, indicating that
the dataset contains the domain shifts. These findings demonstrate that the
dataset will be helpful for checking the robustness against domain shifts. The
dataset is a subset of the dataset for DCASE 2021 Challenge Task 2 and freely
available for download at https://zenodo.org/record/4740355",http://arxiv.org/abs/2105.02702v3
The dynamics of spatially confined oscillations,2021-05-05T18:00:01Z,"Till Stadtler, Pavel Kroupa, Manfred Schmid","The possible relation of the wave nature of particles to gravitation as an
emergent phenomenon is addressed. Hypothetical particles are considered as
spatially confined oscillations (SCOs) and are constructed through the
superposition of plane waves. The effect of a continuously changing refractive
index (speed of propagation field) on SCOs is calculated and the continuous
Ibn-Sahl--Snell law of refraction is derived. Refracted plane wave constituents
of SCOs in an inhomogeneous medium cause the oscillation as a whole to
accelerate as an entity. This acceleration is described by a geodesic equation,
in much the same way as in general relativity. The proper time of an SCO can be
defined via its oscillation frequency. The proper time and its change along the
trajectory are equivalent to a particle in general relativity as described by
the 0th component of its geodesic equation. An SCO in an inhomogeneous
refractive index field exhibits general relativistic properties based on basic
wave mechanics. Properties derived from direct calculations are length
contraction, gravitational red- and blueshift and Thomas precession. The
presented theory is an approximation for oscillations which are small compared
to changes in the refractive index field. SCOs in an inhomogeneous medium may
thus yield a naturally emerging particle-field interaction with general
relativistic properties and may allow a useful vantage point on the nature of
gravitation using classical-wave experiments.",http://arxiv.org/abs/2105.03230v1
"Systematic search for long-term transit duration changes in Kepler
  transiting planets",2021-05-10T12:55:31Z,"Sahar Shahaf, Tsevi Mazeh, Shay Zucker, Daniel Fabrycky","Holczer, Mazeh, and collaborators (HM+16) used the Kepler four-year
observations to derive a transit-timing catalog, identifying 260 Kepler objects
of interest (KOI) with significant transit timing variations (TTV). For KOIs
with high enough SNRs, HM+16 also derived the duration and depth of their
transits. In the present work, we use the duration measurements of HM+16 to
systematically study the duration changes of 561 KOIs and identify 15 KOIs with
a significant long-term linear change of transit durations and another 16 KOIs
with an intermediate significance. We show that the observed linear trend is
probably caused by a precession of the orbital plane of the transiting planet,
induced in most cases by another planet. The leading term of the precession
rate depends on the mass and relative inclination of the perturber, and the
period ratio between the two orbits, but not on the mass and period of the
transiting planet itself. Interestingly, our findings indicate that, as a
sample, the detected time derivatives of the durations get larger as a function
of the planetary orbital period, probably because short-period planetary
systems display small relative inclinations. The results might indicate that
short-period planets reside in relatively flattened planetary systems,
suggesting these systems experienced stronger dissipation either when formed or
when migrated to short orbits. This should be used as a possible clue for the
formation of such systems.",http://arxiv.org/abs/2105.04318v1
"A Unified Power-Setpoint Tracking Algorithm for Utility-Scale PV Systems
  with Power Reserves and Fast Frequency Response Capabilities",2021-05-11T19:53:51Z,"Victor Paduani, Hui Yu, Bei Xu, Ning Lu","This paper presents a fast power-setpoint tracking algorithm to enable
utility-scale photovoltaic (PV) systems to provide high quality grid services
such as power reserves and fast frequency response. The algorithm unites
maximum power-point estimation (MPPE) with flexible power-point tracking (FPPT)
control to improve the performance of both algorithms, achieving fast and
accurate PV power-setpoint tracking even under rapid solar irradiance changes.
The MPPE is developed using a real-time, nonlinear curve-fitting approach based
on the Levenberg-Marquardt algorithm. A modified adaptive FPPT based on the
Perturb and Observe technique is developed for the power-setpoint tracking. By
using MPPE to decouple the impact of irradiance changes on the measured PV
output power, we develop a fast convergence technique for tracking
power-reference changes within three FPPT iterations. Furthermore, to limit the
maximum output power ripple, a new design is introduced for the steady-state
voltage step size of the adaptive FPPT. The proposed algorithm is implemented
on a testbed consisting of a 500 kVA three-phase, single-stage, utility-scale
PV system on the OPAL-RT eMEGASIM platform. Results show that the proposed
method outperforms the state-of-the-art.",http://arxiv.org/abs/2105.05324v2
"Time- and Site-Resolved Kinetic NMR: Real-Time Monitoring of
  Off-Equilibrium Chemical Dynamics by 2D Spectrotemporal Correlations",2021-05-12T13:45:52Z,"Michael J. Jaroszewicz, Mengxiao Liu, Jihyun Kim, Guannan Zhang, Yaewon Kim, Christian Hilty, Lucio Frydman","Nuclear magnetic resonance (NMR) spectroscopy provides detailed information
pertaining to dynamic processes through line-shape changes, which have been
traditionally limited to equilibrium conditions. However, there is a wealth of
information to be gained by studying chemical reactions under off-equilibrium
conditions -- e.g., in states that arise upon mixing reactants that
subsequently undergo chemical changes -- and in monitoring the formation of
reaction products in real time. Herein, we propose and demonstrate a
time-resolved kinetic NMR experiment that combines rapid mixing techniques,
continuous flow, and single-scan spectroscopic imaging methods, leading in
unison to a new 2D spectro-temporal NMR correlation which provides high-quality
kinetic information of off-equilibrium dynamics. These kinetic 2D NMR spectra
possess a spectral dimension conveying with high resolution the individual
chemical sites, correlated with a time-independent, steady-state spatial axis
that delivers unique information concerning temporal changes along the chemical
reaction coordinate. A comprehensive description of the kinetic and
spectroscopic features associated to these spectro-temporal NMR analyses is
presented, factoring in the rapid-mixing, the flow and the spectroscopic NMR
imaging. An experimental demonstration of this method's novel aspects was
carried out using an enzymatically catalyzed reaction, leading to site- and
time-resolved kinetic NMR data that are in excellent agreement with control
experiments and literature values.",http://arxiv.org/abs/2105.05657v1
"Temporal changes of near-surface air temperature in Poland for 1781-2016
  and in Tbilisi (Georgia) for 1881-2016",2021-04-23T12:50:42Z,"R. Modzelewska, M. V. Alania, N. I. Kapanadze, E. I. Khelaia","Analyses of near-surface air temperature T in Poland for 1781-2016 and in
Tbilisi (Georgia) for 1881-2016 have been carried out. We show that the
centenary warming effect in Poland and in Tbilisi has almost the same
peculiarities. An average centenary warming effect deltaT = (1.08+/-0.29) C is
observed in Poland and in Tbilisi for 1881-2016. A warming effect is larger in
winter season (deltaT = ~1.15 C) than in other seasons (average warming effect
for these seasons deltaT = ~0.95 C). We show that a centenary warming is mainly
related to the change of solar activity (estimated by sunspot numbers (SSN) and
total solar irradiance (TSI)); particularly, a time interval about ~70 years
(1890-1960), when a correlation coefficients between 11 years smoothed SSN and
T, and TSI and T are high, r = 0.66+/-0.07 and r = 0.73+/-0.07 for Poland and r
= 0.82+/-0.05 and r = 0.90+/-0.05 for Tbilisi, respectively; in this period
solar activity contributes decisively in the global warming. We show that a
global warming effect equals zero based on the temperature T data in Poland for
period 1781-1880, when human activities were relatively less than in 1881-2016.
We recognize a few feeble ~20+/-3 years disturbances in the temperature changes
for period 1885-1980, most likely related with the fluctuations of solar
magnetic cycles. We distinguish the fluctuations of ~7-8 years in Poland's T
data, possibly connected with local effects of the North Atlantic Oscillation.",http://arxiv.org/abs/2105.06389v1
"Agree to Disagree: When Deep Learning Models With Identical
  Architectures Produce Distinct Explanations",2021-05-14T12:16:47Z,"Matthew Watson, Bashar Awwad Shiekh Hasan, Noura Al Moubayed","Deep Learning of neural networks has progressively become more prominent in
healthcare with models reaching, or even surpassing, expert accuracy levels.
However, these success stories are tainted by concerning reports on the lack of
model transparency and bias against some medical conditions or patients'
sub-groups. Explainable methods are considered the gateway to alleviate many of
these concerns. In this study we demonstrate that the generated explanations
are volatile to changes in model training that are perpendicular to the
classification task and model structure. This raises further questions about
trust in deep learning models for healthcare. Mainly, whether the models
capture underlying causal links in the data or just rely on spurious
correlations that are made visible via explanation methods. We demonstrate that
the output of explainability methods on deep neural networks can vary
significantly by changes of hyper-parameters, such as the random seed or how
the training set is shuffled. We introduce a measure of explanation consistency
which we use to highlight the identified problems on the MIMIC-CXR dataset. We
find explanations of identical models but with different training setups have a
low consistency: $\approx$ 33% on average. On the contrary, kernel methods are
robust against any orthogonal changes, with explanation consistency at 94%. We
conclude that current trends in model explanation are not sufficient to
mitigate the risks of deploying models in real life healthcare applications.",http://arxiv.org/abs/2105.06791v2
Algorithm-Agnostic Explainability for Unsupervised Clustering,2021-05-17T17:58:55Z,"Charles A. Ellis, Mohammad S. E. Sendi, Eloy P. T. Geenjaar, Sergey M. Plis, Robyn L. Miller, Vince D. Calhoun","Supervised machine learning explainability has developed rapidly in recent
years. However, clustering explainability has lagged behind. Here, we
demonstrate the first adaptation of model-agnostic explainability methods to
explain unsupervised clustering. We present two novel ""algorithm-agnostic""
explainability methods - global permutation percent change (G2PC) and local
perturbation percent change (L2PC) - that identify feature importance globally
to a clustering algorithm and locally to the clustering of individual samples.
The methods are (1) easy to implement and (2) broadly applicable across
clustering algorithms, which could make them highly impactful. We demonstrate
the utility of the methods for explaining five popular clustering methods on
low-dimensional synthetic datasets and on high-dimensional functional network
connectivity data extracted from a resting-state functional magnetic resonance
imaging dataset of 151 individuals with schizophrenia and 160 controls. Our
results are consistent with existing literature while also shedding new light
on how changes in brain connectivity may lead to schizophrenia symptoms. We
further compare the explanations from our methods to an interpretable
classifier and find them to be highly similar. Our proposed methods robustly
explain multiple clustering algorithms and could facilitate new insights into
many applications. We hope this study will greatly accelerate the development
of the field of clustering explainability.",http://arxiv.org/abs/2105.08053v2
"Non-contact Pain Recognition from Video Sequences with Remote
  Physiological Measurements Prediction",2021-05-18T20:47:45Z,"Ruijing Yang, Ziyu Guan, Zitong Yu, Xiaoyi Feng, Jinye Peng, Guoying Zhao","Automatic pain recognition is paramount for medical diagnosis and treatment.
The existing works fall into three categories: assessing facial appearance
changes, exploiting physiological cues, or fusing them in a multi-modal manner.
However, (1) appearance changes are easily affected by subjective factors which
impedes objective pain recognition. Besides, the appearance-based approaches
ignore long-range spatial-temporal dependencies that are important for modeling
expressions over time; (2) the physiological cues are obtained by attaching
sensors on human body, which is inconvenient and uncomfortable. In this paper,
we present a novel multi-task learning framework which encodes both appearance
changes and physiological cues in a non-contact manner for pain recognition.
The framework is able to capture both local and long-range dependencies via the
proposed attention mechanism for the learned appearance representations, which
are further enriched by temporally attended physiological cues (remote
photoplethysmography, rPPG) that are recovered from videos in the auxiliary
task. This framework is dubbed rPPG-enriched Spatio-Temporal Attention Network
(rSTAN) and allows us to establish the state-of-the-art performance of
non-contact pain recognition on publicly available pain databases. It
demonstrates that rPPG predictions can be used as an auxiliary task to
facilitate non-contact automatic pain recognition.",http://arxiv.org/abs/2105.08822v2
"Towards low gas consumption of muographic tracking detectors in field
  applications",2021-05-20T08:08:30Z,"Gábor Nyitrai, Gergő Hamar, Dezső Varga","Gaseous detectors are widely used in high energy physics, and are attractive
choices in tracking systems for cosmic muon imaging, also called muography.
Such detectors offer high resolution and high efficiency at reasonable cost for
large sizes, however, one of the drawbacks is that the gaseous detection medium
must be prevented from contamination by outside air or internal outgassing.
Standard systems work with a constant gas flow, leading to regular maintenance
in the form of gas cylinder changes, which can be an issue for remote field
applications. In this paper we discuss the practical possibilities to reduce
gas consumption of an outdoor gaseous tracker, where particularly the gas
density change from daily temperature cycling limits the input flow. Such
""breathing"" effect can be circumvented by well designed buffer volume, which
must prevent external air contamination. A realistic MWPC tracking test system
with 0.9 square meter area, total volume of 160 l, has been operated for 36
days with a flow of 3 l/day, confirming that the buffer volume, in this case a
50 m long and 10 l volume low diffusion tube, ensures sufficient gas quality.
The key effects governing the gas flow dynamics, including diffusion and gas
volume change, has been studied quantitatively, leading to practical design
prescriptions.",http://arxiv.org/abs/2105.09577v1
"Deep learning in physics: a study of dielectric quasi-cubic particles in
  a uniform electric field",2021-05-11T10:40:03Z,"Zhe Wang, Claude Guet","Solving physics problems for which we know the equations, boundary conditions
and symmetries can be done by deep learning. The constraints can be either
imposed as terms in a loss function or used to formulate a neural ansatz. In
the present case study, we calculate the induced field inside and outside a
dielectric cube placed in a uniform electric field, wherein the dielectric
mismatch at edges and corners of the cube makes accurate calculations
numerically challenging. The electric potential is expressed as an ansatz
incorporating neural networks with known leading order behaviors and symmetries
and the Laplace's equation is then solved with boundary conditions at the
dielectric interface by minimizing a loss function. The loss function ensures
that both Laplace's equation and boundary conditions are satisfied everywhere
inside a large solution domain. We study how the electric potential inside and
outside a quasi-cubic particle evolves through a sequence of shapes from a
sphere to a cube. The neural network being differentiable, it is
straightforward to calculate the electric field over the whole domain, the
induced surface charge distribution and the polarizability. The neural network
being retentive, one can efficiently follow how the field changes upon
particle's shape or dielectric constant by iterating from any previously
converged solution. The present work's objective is two-fold, first to show how
an a priori knowledge can be incorporated into neural networks to achieve
efficient learning and second to apply the method and study how the induced
field and polarizability change when a dielectric particle progressively
changes its shape from a sphere to a cube.",http://arxiv.org/abs/2105.09866v1
"Individual risk-aversion responses tune epidemics to critical
  transmissibility ($R=1$)",2021-05-21T21:05:38Z,"Susanna Manrubia, Damián H. Zanette","Changes in human behavior are increasingly recognized as a major determinant
of epidemic dynamics. Although collective activity can be modified through
imposed measures to control epidemic progression, spontaneous changes can also
arise as a result of uncoordinated individual responses to the perceived risk
of contagion. Here we introduce a stochastic epidemic model that implements
population responses driven by individual- and time-dependent risk-taking
propensity. The model reveals an emergent mechanism for the generation of
multiple infection waves of decreasing amplitude without the need to consider
external modulation of parameters. Successive waves tune the effective
reproduction number to its critical value $R=1$. This process is a consequence
of the interplay of the fractions of susceptible and infected population and
the average risk-taking propensity, as shown by a mean-field approach. The
proposed mechanism also shows how, under the threat of contagion, the
distribution of individual risk propensities evolves towards a well-defined
profile. Successive waves trigger selective sweeps of risk-taking propensity at
a pace determined by individual risk reaction rates. This kind of collective,
self-generated pressure, may therefore shape risk-aversion profiles associated
to epidemics in human groups. The final state is self-organized and generic,
independent of the parameter values. We conclude that uncoordinated changes in
human behavior can, by themselves, explain major qualitative and quantitative
features of the epidemic process, as the emergence of multiple waves and the
tendency to remain around $R=1$ observed worldwide after the first few waves of
COVID-19.",http://arxiv.org/abs/2105.10572v1
"Review on phase transformations, fracture, chemical reactions, and other
  structural changes in inelastic materials",2021-05-23T13:16:06Z,Valery I. Levitas,"Review of selected fundamental topics on the interaction between phase
transformations, fracture, and other structural changes in inelastic materials
is presented. It mostly focuses on the concepts developed in the author's group
over last three decades and numerous papers that affected us. It includes a
general thermodynamic and kinetic theories with sharp interfaces and within
phase field approach. Numerous analytical (even at large strains) and numerical
solutions illustrate the main features of the developed theories and their
application to the real phenomena. Coherent, semicoherent, and noncoherent
interfaces, as well as interfaces with decohesion and with intermediate liquid
(disordered) phase are discussed. Importance of the surface- and scale-induced
phenomena on interaction between phase transformation with fracture and
dislocations as well as inheritance of dislocations and plastic strains is
demonstrated. Some nontrivial phenomena, like solid-solid phase transformations
via intermediate (virtual) melt, virtual melting as a new mechanism of plastic
deformation and stress relaxation under high strain rate loading, and phase
transformations and chemical reactions induced by plastic shear under high
pressure are discussed and modeled.",http://arxiv.org/abs/2105.10932v2
Measuring Financial Advice: aligning client elicited and revealed risk,2021-05-25T12:55:03Z,"John R. J. Thompson, Longlong Feng, R. Mark Reesor, Chuck Grace, Adam Metzler","Financial advisors use questionnaires and discussions with clients to
determine a suitable portfolio of assets that will allow clients to reach their
investment objectives. Financial institutions assign risk ratings to each
security they offer, and those ratings are used to guide clients and advisors
to choose an investment portfolio risk that suits their stated risk tolerance.
This paper compares client Know Your Client (KYC) profile risk allocations to
their investment portfolio risk selections using a value-at-risk discrepancy
methodology. Value-at-risk is used to measure elicited and revealed risk to
show whether clients are over-risked or under-risked, changes in KYC risk lead
to changes in portfolio configuration, and cash flow affects a client's
portfolio risk. We demonstrate the effectiveness of value-at-risk at measuring
clients' elicited and revealed risk on a dataset provided by a private Canadian
financial dealership of over $50,000$ accounts for over $27,000$ clients and
$300$ advisors. By measuring both elicited and revealed risk using the same
measure, we can determine how well a client's portfolio aligns with their
stated goals. We believe that using value-at-risk to measure client risk
provides valuable insight to advisors to ensure that their practice is KYC
compliant, to better tailor their client portfolios to stated goals,
communicate advice to clients to either align their portfolios to stated goals
or refresh their goals, and to monitor changes to the clients' risk positions
across their practice.",http://arxiv.org/abs/2105.11892v1
On the Complexity of Weight-Dynamic Network Algorithms,2021-05-27T14:29:27Z,"Monika Henzinger, Ami Paz, Stefan Schmid","While operating communication networks adaptively may improve utilization and
performance, frequent adjustments also introduce an algorithmic challenge: the
re-optimization of traffic engineering solutions is time-consuming and may
limit the granularity at which a network can be adjusted. This paper is
motivated by question whether the reactivity of a network can be improved by
re-optimizing solutions dynamically rather than from scratch, especially if
inputs such as link weights do not change significantly. This paper explores to
what extent dynamic algorithms can be used to speed up fundamental tasks in
network operations. We specifically investigate optimizations related to
traffic engineering (namely shortest paths and maximum flow computations), but
also consider spanning tree and matching applications. While prior work on
dynamic graph algorithms focuses on link insertions and deletions, we are
interested in the practical problem of link weight changes. We revisit existing
upper bounds in the weight-dynamic model, and present several novel lower
bounds on the amortized runtime for recomputing solutions. In general, we find
that the potential performance gains depend on the application, and there are
also strict limitations on what can be achieved, even if link weights change
only slightly.",http://arxiv.org/abs/2105.13172v3
"How the University Portal Inspired Changes in the Academic Assessment
  Culture",2021-05-29T00:16:45Z,"Valerii Semenets, Svitlana Gryshko, Mariia Golovianko, Oleksandr Shevchenko, Liudmyla Titova, Olena Kaikova, Vagan Terziyan, Timo Tiihonen","Information retrieval (IR) is known facilitator of changes ongoing in human
society and vice versa. This is due to the fact that IR is a key component of
the digital ecosystems, where both information providers and information
consumers collaboratively address their problems with the use of technologies.
Organization and design of such ecosystems drives particular social impact for
all the players involved. In this paper, we study the impact made by a
particular IR ecosystem (semantic portal) used for management of academic
information resources and processes within the Ukrainian higher education. We
show how this portal is changing a collective mindset of the academic community
of its users. We argue that such impact becomes possible due to specific
organization of the ecosystem, where all the information resources, IR services
and related analytics (search, assessment, ranking, etc.) and IR users inhabit
the same semantic space under umbrella of the corresponding ontologies.
Personal values and preferences of the users configure on-the-fly the
corresponding IR analytics and enable personalized value-driven IR services,
making everyone feel involved into the organizational decision-making
processes. Four years of active use of this portal in university environment
has been reported and related impact is evaluated in this study.",http://arxiv.org/abs/2105.14154v1
"Phylogenetic Diversity Rankings in the Face of Extinctions: the
  Robustness of the Fair Proportion Index",2021-07-01T21:29:30Z,"Mareike Fischer, Andrew Francis, Kristina Wicke","Planning for the protection of species often involves difficult choices about
which species to prioritize, given constrained resources. One way of
prioritizing species is to consider their ""evolutionary distinctiveness"", i.e.
their relative evolutionary isolation on a phylogenetic tree. Several
evolutionary isolation metrics or phylogenetic diversity indices have been
introduced in the literature, among them the so-called Fair Proportion index
(also known as the ""evolutionary distinctiveness"" score). This index apportions
the total diversity of a tree among all leaves, thereby providing a simple
prioritization criterion for conservation.
  Here, we focus on the prioritization order obtained from the Fair Proportion
index and analyze the effects of species extinction on this ranking. More
precisely, we analyze the extent to which the ranking order may change when
some species go extinct and the Fair Proportion index is re-computed for the
remaining taxa. We show that for each phylogenetic tree, there are edge lengths
such that the extinction of one leaf per cherry completely reverses the
ranking. Moreover, we show that even if only the lowest ranked species goes
extinct, the ranking order may drastically change. We end by analyzing the
effects of these two extinction scenarios (extinction of the lowest ranked
species and extinction of one leaf per cherry) for a collection of empirical
and simulated trees. In both cases, we can observe significant changes in the
prioritization orders, highlighting the empirical relevance of our theoretical
findings.",http://arxiv.org/abs/2107.00748v1
"Advanced turning maneuver of a multi-legged robot using pitchfork
  bifurcation",2021-07-05T07:51:26Z,"Shinya Aoi, Ryoe Tomatsu, Yuki Yabuuchi, Daiki Morozumi, Kota Okamoto, Soichiro Fujiki, Kei Senda, Kazuo Tsuchiya","Legged robots have excellent terrestrial mobility for traversing diverse
environments and thus have the potential to be deployed in a wide variety of
scenarios. However, they are susceptible to falling and leg malfunction during
locomotion. Although the use of a large number of legs can overcome these
problems, it makes the body long and leads to many legs being constrained to
contact with the ground to support the long body, which impedes
maneuverability. To improve the locomotion maneuverability of such robots, the
present study focuses on dynamic instability, which induces rapid and large
movement changes, and uses a 12-legged robot with a flexible body axis. Our
previous work found that the straight walk of the robot becomes unstable
through Hopf bifurcation when the body axis flexibility is changed, which
induces body undulations. Furthermore, we developed a simple controller based
on the Hopf bifurcation and showed that the instability facilitates the turning
of the robot. In this study, we newly found that the straight walk becomes
unstable through pitchfork bifurcation when the body-axis flexibility is
changed in a way different from that in our previous work. In addition, the
pitchfork bifurcation induces a transition into a curved walk, whose curvature
can be controlled by the body-axis flexibility. We developed a simple
controller based on the pitchfork-bifurcation characteristics and demonstrated
that the robot can perform a turning maneuver superior to that with the
previous controller. This study provides a novel design principle for
maneuverable locomotion of many-legged robots using intrinsic dynamic
properties.",http://arxiv.org/abs/2107.01837v2
Detecting Concept Drift With Neural Network Model Uncertainty,2021-07-05T08:56:36Z,"Lucas Baier, Tim Schlör, Jakob Schöffer, Niklas Kühl","Deployed machine learning models are confronted with the problem of changing
data over time, a phenomenon also called concept drift. While existing
approaches of concept drift detection already show convincing results, they
require true labels as a prerequisite for successful drift detection.
Especially in many real-world application scenarios-like the ones covered in
this work-true labels are scarce, and their acquisition is expensive.
Therefore, we introduce a new algorithm for drift detection, Uncertainty Drift
Detection (UDD), which is able to detect drifts without access to true labels.
Our approach is based on the uncertainty estimates provided by a deep neural
network in combination with Monte Carlo Dropout. Structural changes over time
are detected by applying the ADWIN technique on the uncertainty estimates, and
detected drifts trigger a retraining of the prediction model. In contrast to
input data-based drift detection, our approach considers the effects of the
current input data on the properties of the prediction model rather than
detecting change on the input data only (which can lead to unnecessary
retrainings). We show that UDD outperforms other state-of-the-art strategies on
two synthetic as well as ten real-world data sets for both regression and
classification tasks.",http://arxiv.org/abs/2107.01873v2
A scheme for simulating multi-level phase change photonics materials,2021-07-05T13:52:39Z,"Yunzheng Wang, Jing Ning, Li Lu, Michel Bosman, Robert E. Simpson","Chalcogenide phase change materials (PCMs) have been extensively applied in
data storage, and they are now being proposed for high resolution displays,
holographic displays, reprogrammable photonics, and all-optical neural
networks. These wide-ranging applications all exploit the radical property
contrast between the PCMs different structural phases, extremely fast switching
speed, long-term stability, and low energy consumption. Designing PCM photonic
devices requires an accurate model to predict the response of the device during
phase transitions. Here, we describe an approach that accurately predicts the
microstructure and optical response of phase change materials during laser
induced heating. The framework couples the Gillespie Cellular Automata approach
for modelling phase transitions with effective medium theory and Fresnel
equations. The accuracy of the approach is verified by comparing the PCM
optical response and microstructure evolution with the results of nanosecond
laser switching experiments. We anticipate that this approach to simulating the
switching response of PCMs will become an important component for designing and
simulating programmable photonics devices. The method is particularly important
for predicting the multi-level optical response of PCMs, which is important for
all-optical neural networks and PCM-programmable perceptrons.",http://arxiv.org/abs/2107.02035v1
Edge-powered Assisted Driving For Connected Cars,2021-07-06T06:07:55Z,"Francesco Malandrino, Carla Fabiana Chiasserini, Gian Michele dell'Aera","Assisted driving for connected cars is one of the main applications that
5G-and-beyond networks shall support. In this work, we propose an assisted
driving system leveraging the synergy between connected vehicles and the edge
of the network infrastructure, in order to envision global traffic policies
that can effectively drive local decisions. Local decisions concern individual
vehicles, e.g., which vehicle should perform a lane-change manoeuvre and when;
global decisions, instead, involve whole traffic flows. Such decisions are made
at different time scales by different entities, which are integrated within an
edge-based architecture and can share information. In particular, we leverage a
queuing-based model and formulate an optimization problem to make global
decisions on traffic flows. To cope with the problem complexity, we then
develop an iterative, linear-time complexity algorithm called Bottleneck
Hunting (BH). We show the performance of our solution using a realistic
simulation framework, integrating a Python engine with ns-3 and SUMO, and
considering two relevant services, namely, lane change assistance and
navigation, in a real-world scenario. Results demonstrate that our solution
leads to a reduction of the vehicles' travel times by 66 in the case of lane
change assistance and by 20 for navigation, compared to traditional,
local-coordination approaches.",http://arxiv.org/abs/2107.02409v1
"From hidden-order to antiferromagnetism: electronic structure changes in
  Fe-doped URu$_{2}$Si$_{2}$",2021-07-08T14:26:45Z,"Emmanouil Frantzeskakis, Ji Dai, Cédric Bareille, Tobias C. Rödel, Monika Güttler, Sheng Ran, Noravee Kanchanavatee, Kevin Huang, Naveen Pouse, Christian T. Wolowiec, Emile D. L. Rienks, Pascal Lejay, Franck Fortuna, M. Brian Maple, Andrés F. Santander-Syro","In matter, any spontaneous symmetry breaking induces a phase transition
characterized by an order parameter, such as the magnetization vector in
ferromagnets, or a macroscopic many-electron wave-function in superconductors.
Phase transitions with unknown order parameter are rare but extremely
appealing, as they may lead to novel physics. An emblematic, and still
unsolved, example is the transition of the heavy fermion compound URu$_2$Si$_2$
(URS) into the so-called hidden-order (HO) phase when the temperature drops
below $T_0 = 17.5$K. Here we show that the interaction between the heavy
fermion and the conduction band states near the Fermi level has a key role in
the emergence of the HO phase. Using angle resolved photoemission spectroscopy,
we find that while the Fermi surfaces of the HO and of a neighboring
antiferromagnetic (AFM) phase of well-defined order parameter have the same
topography, they differ in the size of some, but not all, of their electron
pockets. Such a non-rigid change of the electronic structure indicates that a
change in the interaction strength between states near the Fermi level is a
crucial ingredient for the HO-to-AFM phase transition.",http://arxiv.org/abs/2107.03872v1
"Exploring Post COVID-19 Outbreak Intradaily Mobility Pattern Change in
  College Students: a GPS-focused Smartphone Sensing Study",2021-07-08T22:39:03Z,"Congyu Wu, Hagen Fritz, Cameron Craddock, Kerry Kinney, Darla Castelli, David M. Schnyer","With the outbreak of the COVID-19 pandemic in 2020, most colleges and
universities move to restrict campus activities, reduce indoor gatherings and
move instruction online. These changes required that students adapt and alter
their daily routines accordingly. To investigate patterns associated with these
behavioral changes, we collected smartphone sensing data using the Beiwe
platform from two groups of undergraduate students at a major North American
university, one from January to March of 2020 (74 participants), the other from
May to August (52 participants), to observe the differences in students' daily
life patterns before and after the start of the pandemic. In this paper, we
focus on the mobility patterns evidenced by GPS signal tracking from the
students' smartphones and report findings using several analytical methods
including principal component analysis, circadian rhythm analysis, and
predictive modeling of perceived sadness levels using mobility-based digital
metrics. Our findings suggest that compared to the pre-COVID group, students in
the mid-COVID group generally (1) registered a greater amount of midday
movement than movement in the morning (8-10am) and in the evening (7-9pm), as
opposed to the other way around; (2) exhibited significantly less intradaily
variability in their daily movement, and (3) had a significant lower
correlation between their mobility patterns and negative mood.",http://arxiv.org/abs/2107.04137v1
FedAdapt: Adaptive Offloading for IoT Devices in Federated Learning,2021-07-09T07:29:55Z,"Di Wu, Rehmat Ullah, Paul Harvey, Peter Kilpatrick, Ivor Spence, Blesson Varghese","Applying Federated Learning (FL) on Internet-of-Things devices is
necessitated by the large volumes of data they produce and growing concerns of
data privacy. However, there are three challenges that need to be addressed to
make FL efficient: (i) execution on devices with limited computational
capabilities, (ii) accounting for stragglers due to computational heterogeneity
of devices, and (iii) adaptation to the changing network bandwidths. This paper
presents FedAdapt, an adaptive offloading FL framework to mitigate the
aforementioned challenges. FedAdapt accelerates local training in
computationally constrained devices by leveraging layer offloading of deep
neural networks (DNNs) to servers. Further, FedAdapt adopts reinforcement
learning based optimization and clustering to adaptively identify which layers
of the DNN should be offloaded for each individual device on to a server to
tackle the challenges of computational heterogeneity and changing network
bandwidth. Experimental studies are carried out on a lab-based testbed and it
is demonstrated that by offloading a DNN from the device to the server FedAdapt
reduces the training time of a typical IoT device by over half compared to
classic FL. The training time of extreme stragglers and the overall training
time can be reduced by up to 57%. Furthermore, with changing network bandwidth,
FedAdapt is demonstrated to reduce the training time by up to 40% when compared
to classic FL, without sacrificing accuracy.",http://arxiv.org/abs/2107.04271v5
Cosmic Web-Halo Connection Between Twin Universes,2021-07-12T19:00:05Z,"Hou-Zun Chen, Xi Kang, Peng Wang, Noam I. Libeskind, Yu Luo","Both simulation and observational data have shown that the spin and shape of
dark matter halos are correlated with their nearby large-scale environment. As
structure formation on different scales is strongly coupled, it is trick to
disentangle the formation of halo with the large-scale environment, making it
difficult to infer which is the driving force for the correlation between halo
spin/shape with the large-scale structure. In this paper, we use N-body
simulation to produce twin Universes that share the same initial conditions on
small scales but different on large scales. This is achieved by changing the
random seeds for the phase of those k modes smaller than a given scale in the
initial conditions. In this way, we are able to disentangle the formation of
halo and large-scale structure, making it possible to investigate how halo spin
and shape correspond to the change of environment on large scales. We identify
matching halo pairs in the twin simulations as those sharing the maximum number
of identical particles within each other. Using these matched halo pairs, we
study the cross match of halo spin and their correlation with the large-scale
structure. It is found that when the large-scale environment changes
(eigenvector) between the twin simulations, the halo spin has to rotate
accordingly, although not significantly, to maintain the universal correlation
seen in each simulation. Our results suggest that the large-scale structure is
the main factor to drive the correlation between halo properties and their
environment.",http://arxiv.org/abs/2107.05689v1
"Anomalies in the temperature evolution of the Dirac states in a
  topological crystalline insulator SnTe",2021-07-14T09:00:27Z,"Ayanesh Maiti, Ram Prakash Pandeya, Bahadur Singh, Kartik K Iyer, A Thamizhavel, Kalobaran Maiti","Discovery of topologically protected surface states, believed to be immune to
weak disorder and thermal effects, opened up a new avenue to reveal exotic
fundamental science and advanced technology. While time-reversal symmetry plays
the key role in most such materials, the bulk crystalline symmetries such as
mirror symmetry preserve the topological properties of topological crystalline
insulators (TCIs). It is apparent that any structural change may alter the
topological properties of TCIs. To investigate this relatively unexplored
landscape, we study the temperature evolution of the Dirac fermion states in an
archetypical mirror-symmetry protected TCI, SnTe employing high-resolution
angle-resolved photoemission spectroscopy and density functional theory
studies. Experimental results reveal a perplexing scenario; the bulk bands
observed at 22 K move nearer to the Fermi level at 60 K and again shift back to
higher binding energies at 120 K. The slope of the surface Dirac bands at 22 K
becomes smaller at 60 K and changes back to a larger value at 120 K. Our
results from the first-principles calculations suggest that these anomalies can
be attributed to the evolution of the hybridization physics with complex
structural changes induced by temperature. In addition, we discover drastically
reduced intensity of the Dirac states at the Fermi level at high temperatures
may be due to complex evolution of anharmonicity, strain, etc. These results
address robustness of the topologically protected surface states due to thermal
effects and emphasize importance of covalency and anharmonicity in the
topological properties of such emerging quantum materials.",http://arxiv.org/abs/2107.06562v1
"Polarization and coherence in mean field games driven by private and
  social utility",2021-07-13T15:13:09Z,"Dai Pra Paolo, Sartori Elena, Tolotti Marco","We study a mean field game in continuous time over a finite horizon, T, where
the state of each agent is binary and where players base their strategic
decisions on two, possibly competing, factors: the willingness to align with
the majority (conformism) and the aspiration of sticking with the own type
(stubbornness). We also consider a quadratic cost related to the rate at which
a change in the state happens: changing opinion may be a costly operation.
Depending on the parameters of the model, the game may have more than one Nash
equilibrium, even though the corresponding N-player game does not. Moreover, it
exhibits a very rich phase diagram, where polarized/unpolarized,
coherent/incoherent equilibria may coexist, except for T small, where the
equilibrium is always unique. We fully describe such phase diagram in closed
form and provide a detailed numerical analysis of the N-player counterpart of
the mean field game. In this finite dimensional setting, the equilibrium
selected by the population of players is always coherent (favoring the
subpopulation whose type is aligned with the initial condition), but it does
not necessarily minimize the cost functional. Rather, it seems that, among the
coherent ones, the equilibrium prevailing is the one that most benefits the
underdog subpopulation forced to change opinion.",http://arxiv.org/abs/2107.06667v1
"A Multi-stage Stochastic Programming Model for Adaptive Biomass
  Processing Operation under Uncertainty",2021-07-16T18:51:31Z,"Berkay Gulcan, Yongjia Song, Sandra D. Eksioglu","Variations of physical and chemical characteristics of biomass reduce
equipment utilization and increase operational costs of biomass processing.
Biomass processing facilities use sensors to monitor the changes in biomass
characteristics. Integrating sensory data into the operational decisions in
biomass processing will increase its flexibility to the changing biomass
conditions. In this paper, we propose a multi-stage stochastic programming
model that minimizes the expected operational costs by identifying the initial
inventory level and creating an operational decision policy for equipment speed
settings. These policies take the sensory information data and the current
biomass inventory level as inputs to dynamically adjust inventory levels and
equipment settings according to the changes in the biomass' characteristics. We
ensure that a prescribed target reactor utilization is consistently achieved by
penalizing the violation of the target reactor feeding rate. A case study is
developed using real-world data collected at Idaho National Laboratory's
biomass processing facility. We show the value of multi-stage stochastic
programming from an extensive computational experiment. Our sensitivity
analysis indicates that updating the infeed rate of the system, the processing
speed of equipment, and bale sequencing based on the moisture level of biomass
improves the processing rate of the reactor and reduces operating costs.",http://arxiv.org/abs/2107.08078v1
The bluest changing-look QSO SDSS J224113-012108,2021-07-20T01:14:38Z,Zhang XueGuang,"In this manuscript, we report a new changing-look QSO (CLQSO) SDSS J2241 at
$z=0.059$. Based on the multi-epoch SDSS spectra from 2011 to 2017, the flux
ratio of broad H$\alpha$ to broad H$\beta$ has been changed from 7\ in 2011 to
2.7\ in 2017, leading SDSS J2241 with spectral index
$\alpha_\lambda\sim-5.21\pm0.02$ ($\lambda< 4000$\AA) in 2017 to be so-far the
bluest CLQSO. Based on the SDSS spectrum in 2011, the host galaxy contributions
with stellar velocity dispersion $\sim86{\rm km/s}$ can be well determined,
leading to the M-sigma relation expected central BH mass $\sim3\times10^6{\rm
M_\odot}$. However, through properties of the broad H$\alpha$, the virial BH
mass is $\sim10^8{\rm M_\odot}$, about two magnitudes larger than the mass
through the M-sigma relation. The different BH masses through different methods
indicate SDSS J2241 is one unique CLQSO. Meanwhile, the long-term photometric
light curve shows interesting variability properties, not expected by DRW
process commonly applied in AGN but probably connected to a central TDE.
Furthermore, based on continuum emission properties in 2017 with no dust
obscurations, only considering the moving dust clouds cannot be preferred to
explain the CLQSO SDSS J2241, because the expected intrinsic reddening
corrected continuum emissions were unreasonably higher than the unobscured
continuum emissions in 2017.",http://arxiv.org/abs/2107.09214v1
Identifying AGN host galaxies by Machine Learning with HSC+WISE,2021-07-20T18:00:01Z,"Yu-Yen Chang, Bau-Ching Hsieh, Wei-Hao Wang, Yen-Ting Lin, Chen-Fatt Lim, Yoshiki Toba, Yuxing Zhong, Siou-Yu Chang","We use machine learning techniques to investigate their performance in
classifying active galactic nuclei (AGNs), including X-ray selected AGNs
(XAGNs), infrared selected AGNs (IRAGNs), and radio selected AGNs (RAGNs).
Using known physical parameters in the Cosmic Evolution Survey (COSMOS) field,
we are able to well-established training samples in the region of Hyper
Suprime-Cam (HSC) survey. We compare several Python packages (e.g.,
scikit-learn, Keras, and XGBoost), and use XGBoost to identify AGNs and show
the performance (e.g., accuracy, precision, recall, F1 score, and AUROC). Our
results indicate that the performance is high for bright XAGN and IRAGN host
galaxies. The combination of the HSC (optical) information with the Wide-field
Infrared Survey Explorer (WISE) band-1 and WISE band-2 (near-infrared)
information perform well to identify AGN hosts. For both type-1 (broad-line)
XAGNs and type-1 (unobscured) IRAGNs, the performance is very good by using
optical to infrared information. These results can apply to the five-band data
from the wide regions of the HSC survey, and future all-sky surveys.",http://arxiv.org/abs/2107.09678v1
A Real Time Monitoring Approach for Bivariate Event Data,2021-07-26T05:51:51Z,"Inez Maria Zwetsloot, Tahir Mahmood, Funmilola Mary Taiwo, Zezhong Wang","Early detection of changes in the frequency of events is an important task,
in, for example, disease surveillance, monitoring of high-quality processes,
reliability monitoring and public health. In this article, we focus on
detecting changes in multivariate event data, by monitoring the
time-between-events (TBE). Existing multivariate TBE charts are limited in the
sense that, they only signal after an event occurred for each of the individual
processes. This results in delays (i.e., long time to signal), especially if it
is of interest to detect a change in one or a few of the processes. We propose
a bivariate TBE (BTBE) chart which is able to signal in real time. We derive
analytical expressions for the control limits and average time-to-signal
performance, conduct a performance evaluation and compare our chart to an
existing method. The findings showed that our method is a realistic approach to
monitor bivariate time-between-event data, and has better detection ability
than existing methods. A large benefit of our method is that it signals in
real-time and that due to the analytical expressions no simulation is needed.
The proposed method is implemented on a real-life dataset related to AIDS.",http://arxiv.org/abs/2107.11971v1
"Pressure-induced anomalies in the magnetic transitions of the exotic
  multiferroic material, Tb2BaNiO5",2021-07-27T11:06:12Z,"K. K. Iyer, Ram Kumar, S. Rayaprol, K. Maiti, E. V. Sampathkumaran","We have studied the influence of external pressure up to 1 GPa on the
magnetic transitions of the orthorhombic Haldane-spin chain compound Tb2BaNiO5
an exotic multiferroic material. This parent compound is known to undergo
N\'eel ordering at TN1= 63 K and another magnetic transition at TN2= 25K at
which ferroelectricity sets in, however, without any change in the magnetic
symmetry, but with only a sharp change in the canting angle of Tb 4f and Ni 3d
magnetic moments. There is a subtle difference in the antiferromagnetic state
above and below TN2, which is supported by the fact that there is a
metamagnetic transition below TN2only (for 5 K, at about 60 kOe). We report
here that, with the application of external pressure, there is an upward shift
of TN1, while TN2 shifts towards lower temperatures. It is interesting that the
two magnetic transitions in the same compound behave differently under pressure
and the opposite behavior at TN2 is attributed to local distortion leading to
ferroelectricity. The results are augmented by temperature dependent x-ray
diffraction and positive chemical pressure studies. The chemical pressure
caused by the isoelectronic doping at Ba site by Sr reduces both the transition
temperatures. Clearly, the external pressure favors antiferromagnetic coupling
(that is, leading to TN1 enhancement), whereas the chemical pressure reduces
TN1, suggesting important role of the changes in local hybridization induced by
doping on magnetism in this material.",http://arxiv.org/abs/2107.12729v1
The Robustness of Graph k-shell Structure under Adversarial Attacks,2021-07-29T13:51:17Z,"B. Zhou, Y. Q. Lv, Y. C. Mao, J. H. Wang, S. Q. Yu, Q. Xuan","The k-shell decomposition plays an important role in unveiling the structural
properties of a network, i.e., it is widely adopted to find the densest part of
a network across a broad range of scientific fields, including Internet,
biological networks, social networks, etc. However, there arises concern about
the robustness of the k-shell structure when networks suffer from adversarial
attacks. Here, we introduce and formalize the problem of the k-shell attack and
develop an efficient strategy to attack the k-shell structure by rewiring a
small number of links. To the best of our knowledge, it is the first time to
study the robustness of graph k-shell structure under adversarial attacks. In
particular, we propose a Simulated Annealing (SA) based k-shell attack method
and testify it on four real-world social networks. The extensive experiments
validate that the k-shell structure of a network is robust under random
perturbation, but it is quite vulnerable under adversarial attack, e.g., in
Dolphin and Throne networks, more than 40% nodes change their k-shell values
when only 10% links are changed based on our SA-based k-shell attack. Such
results suggest that a single structural feature could also be significantly
disturbed when only a small fraction of links are changed purposefully in a
network. Therefore, it could be an interesting topic to improve the robustness
of various network properties against adversarial attack in the future.",http://arxiv.org/abs/2107.13962v1
Tiny Machine Learning for Concept Drift,2021-07-30T17:02:04Z,"Simone Disabato, Manuel Roveri","Tiny Machine Learning (TML) is a new research area whose goal is to design
machine and deep learning techniques able to operate in Embedded Systems and
IoT units, hence satisfying the severe technological constraints on memory,
computation, and energy characterizing these pervasive devices. Interestingly,
the related literature mainly focused on reducing the computational and memory
demand of the inference phase of machine and deep learning models. At the same
time, the training is typically assumed to be carried out in Cloud or edge
computing systems (due to the larger memory and computational requirements).
This assumption results in TML solutions that might become obsolete when the
process generating the data is affected by concept drift (e.g., due to
periodicity or seasonality effect, faults or malfunctioning affecting sensors
or actuators, or changes in the users' behavior), a common situation in
real-world application scenarios. For the first time in the literature, this
paper introduces a Tiny Machine Learning for Concept Drift (TML-CD) solution
based on deep learning feature extractors and a k-nearest neighbors classifier
integrating a hybrid adaptation module able to deal with concept drift
affecting the data-generating process. This adaptation module continuously
updates (in a passive way) the knowledge base of TML-CD and, at the same time,
employs a Change Detection Test to inspect for changes (in an active way) to
quickly adapt to concept drift by removing the obsolete knowledge. Experimental
results on both image and audio benchmarks show the effectiveness of the
proposed solution, whilst the porting of TML-CD on three off-the-shelf
micro-controller units shows the feasibility of what is proposed in real-world
pervasive systems.",http://arxiv.org/abs/2107.14759v1
"A mechanistic model for the asymmetric torque-speed relationships of a
  bacterial flagellar motor",2021-09-04T08:16:18Z,"Biswajit Das, Hao Ge","A tiny bacterial flagellar motor rotates in both counter-clockwise (CCW) and
clockwise (CW) rotational directions. The most important measurable
characteristic of the flagellar motor is its torque versus angular speed
relationship in CCW or CW modes, which is found to be non-symmetrical with each
other, and still, such a phenomenon is not clearly understood.Here, we explain
this asymmetry through a mechanistic model based on the detailed torque
analysis for the rotation of the motor and the revolutionary as well as
spinning motion of the filament and bead. We find out that the asymmetry
results from the conformational changing of the hook due to rotational
switching, rather than any non-symmetric changes in the potential of mean force
generated by the stator-rotor interactions. In CCW mode, when the hook remains
bend and flexible, the revolution motion predominates and the restoring torque
in this motion, originated due to drag, governs the shape of the torque-speed
curve. However, in CW mode, spinning motion dominates as the hook becomes
straight and rigid, and the linear torque-speed relation arises due to the
restoring torque for the drag corresponding to this motion. Our study indicates
the significant role of the hook's conformational change upon the biological
functions of the motor and paves the way for further experimental exploration
on the structural origin of such asymmetry.",http://arxiv.org/abs/2109.01813v1
"The Emotional Roller Coaster of Responding to Requirements Changes in
  Software Engineering",2021-09-09T02:05:40Z,"Kashumi Madampe, Rashina Hoda, John Grundy","Background: A preliminary study we conducted showed that software
practitioners respond to requirements changes(RCs) with different emotions, and
that their emotions vary at stages of the RC handling life cycle, such as
receiving, developing, and delivering RCs. Objective: We wanted to study more
comprehensively how practitioners emotionally respond to RCs. Method: We
conducted a world-wide survey with the participation of 201 software
practitioners. In our survey, we used the Job-related Affective Well-being
Scale (JAWS) and open-ended questions to capture participants emotions when
handling RCs in their work and query about the different circumstances when
they feel these emotions. We used a combined approach of statistical analysis,
JAWS, and Socio-Technical Grounded Theory (STGT) for Data Analysis to analyse
our survey data. Findings: We identified (1) emotional responses to RCs, i.e.,
the most common emotions felt by practitioners when handling RCs; (2) different
stimuli -- such as the RC, the practitioner, team, manager, customer -- that
trigger these emotions through their own different characteristics; (3)emotion
dynamics, i.e., the changes in emotions during the project and RC handling life
cycles; (4) distinct events where particular emotions are triggered:project
milestones, and RC stages; (5) and time related matters that regulate the
emotion dynamics. Conclusion: Practitioners are not pleased with receiving RCs
all the time. Last minute RCs introduced closer to a deadline especially
violate emotional well-being of practitioners. We present some practical
recommendations for practitioners to follow, including a dual-purpose
emotion-centric decision guide to help decide when to introduce or accept an
RC, and some future key research directions.",http://arxiv.org/abs/2109.03993v1
"Effects of dust particles charged by inelastic collisions and by
  photoionization on Alfvén waves in a stellar wind",2021-09-13T20:58:12Z,"L. B. De Toni, R. Gaelzer","Using a kinetic description of a homogeneous magnetized dusty plasma with
Maxwellian distribution of electrons and protons and dust particles charged by
inelastic collisions and by photoionization, we analyse the dispersion relation
considering the case where waves and radiation propagate exactly parallel to
the ambient magnetic field. The investigation emphasizes the changes that the
photoionization process brings to the propagation and damping of the waves in a
stellar wind environment, since Alfv\'en waves are believed to play a
significant role in the heating and acceleration processes that take place in
the wind. The results show that, in the presence of dust with negative
equilibrium electrical charge, the Alfv\'en mode decouples into the whistler
and ion cyclotron modes for all values of wavenumber, but when dust particles
acquire neutral or positive values of electrical charge, these modes may couple
for certain values of wavenumber. It is also seen that the whistler and ion
cyclotron modes present null group velocity in a interval of small wavenumber,
and that the maximum value of wavenumber for which the waves are
non-propagating is reduced in the presence of the photoionization process. For
very small values of wavenumber, the damping rates of the modes could change
significantly from very small to very high values if the sign of the dust
electrical charge is changed.",http://arxiv.org/abs/2109.06320v1
Can Edge Probing Tasks Reveal Linguistic Knowledge in QA Models?,2021-09-15T06:16:12Z,"Sagnik Ray Choudhury, Nikita Bhutani, Isabelle Augenstein","There have been many efforts to try to understand what grammatical knowledge
(e.g., ability to understand the part of speech of a token) is encoded in large
pre-trained language models (LM). This is done through `Edge Probing' (EP)
tests: supervised classification tasks to predict the grammatical properties of
a span (whether it has a particular part of speech) using only the token
representations coming from the LM encoder. However, most NLP applications
fine-tune these LM encoders for specific tasks. Here, we ask: if an LM is
fine-tuned, does the encoding of linguistic information in it change, as
measured by EP tests? Specifically, we focus on the task of Question Answering
(QA) and conduct experiments on multiple datasets. We find that EP test results
do not change significantly when the fine-tuned model performs well or in
adversarial situations where the model is forced to learn wrong correlations.
From a similar finding, some recent papers conclude that fine-tuning does not
change linguistic knowledge in encoders but they do not provide an explanation.
We find that EP models themselves are susceptible to exploiting spurious
correlations in the EP datasets. When this dataset bias is corrected, we do see
an improvement in the EP test results as expected.",http://arxiv.org/abs/2109.07102v3
The impact of glitches on young pulsar rotational evolution,2021-09-15T22:58:12Z,"Marcus E. Lower, Simon Johnston, Liam Dunn, Ryan M. Shannon, Matthew Bailes, Shi Dai, Matthew Kerr, Richard N. Manchester, Andrew Melatos, Lucy S. Oswald, Aditya Parthasarathy, Charlotte Sobey, Patrick Weltevrede","We report on a timing programme of 74 young pulsars that have been observed
by the Parkes 64-m radio telescope over the past decade. Using modern Bayesian
timing techniques, we have measured the properties of 124 glitches in 52 of
these pulsars, of which 74 are new. We demonstrate that the glitch sample is
complete to fractional increases in spin-frequency greater than
$\Delta\nu^{90\%}_{g}/\nu \approx 8.1 \times 10^{-9}$. We measure values of the
braking index, $n$, in 33 pulsars. In most of these pulsars, their rotational
evolution is dominated by episodes of spin-down with $n > 10$, punctuated by
step changes in the spin-down rate at the time of a large glitch. The step
changes are such that, averaged over the glitches, the long-term $n$ is small.
We find a near one-to-one relationship between the inter-glitch value of $n$
and the change in spin-down of the previous glitch divided by the inter-glitch
time interval. We discuss the results in the context of a range of physical
models.",http://arxiv.org/abs/2109.07612v2
"Hadwiger number always upper bounds the chromatic number -- 1852-1943 --
  A far-reaching generalisation of Guthrie's postulate",2021-09-19T04:46:12Z,T Srinivasa Murthy,"In a simple graph $G$, we prove that the \textit{Hadwiger number}, $h(G)$, of
the given graph $G$ always upper bounds the \textit{chromatic number},
$\chi(G)$, of the given graph $G$, that is, $\chi(G) \leq h(G)$. This simply
stated problem is one of the fundamental questions in combinatorial
mathematics, which was made by Hugo Hadwiger in 1943. Consequently, it
independently verifies the most famous Four-Color Theorem: the case $h(G) = 4$
is equivalent to the Four-Color Theorem, that is, every planar graph is
$4$-colourable. In our novel approach, we use algebraic settings over a finite
field $\mathbb{Z}_p$. The algebraic setting, in essence, begins with the
complete graph with $h(G)$ vertices (which is a minor, $\mathcal{M}$, of the
given graph $G$) and iteratively extends to the simple graph $G$. This
conjecture has remained elusive, owing to a lack of understanding of the
interdependence, particularly the importance of Lemma 3.1, Lemma 3.2, Lemma
3.3, and Lemma 3.6 in Section 3.",http://arxiv.org/abs/2109.10240v5
"Early Lane Change Prediction for Automated Driving Systems Using
  Multi-Task Attention-based Convolutional Neural Networks",2021-09-22T13:59:27Z,"Sajjad Mozaffari, Eduardo Arnold, Mehrdad Dianati, Saber Fallah","Lane change (LC) is one of the safety-critical manoeuvres in highway driving
according to various road accident records. Thus, reliably predicting such
manoeuvre in advance is critical for the safe and comfortable operation of
automated driving systems. The majority of previous studies rely on detecting a
manoeuvre that has been already started, rather than predicting the manoeuvre
in advance. Furthermore, most of the previous works do not estimate the key
timings of the manoeuvre (e.g., crossing time), which can actually yield more
useful information for the decision making in the ego vehicle. To address these
shortcomings, this paper proposes a novel multi-task model to simultaneously
estimate the likelihood of LC manoeuvres and the time-to-lane-change (TTLC). In
both tasks, an attention-based convolutional neural network (CNN) is used as a
shared feature extractor from a bird's eye view representation of the driving
environment. The spatial attention used in the CNN model improves the feature
extraction process by focusing on the most relevant areas of the surrounding
environment. In addition, two novel curriculum learning schemes are employed to
train the proposed approach. The extensive evaluation and comparative analysis
of the proposed method in existing benchmark datasets show that the proposed
method outperforms state-of-the-art LC prediction models, particularly
considering long-term prediction performance.",http://arxiv.org/abs/2109.10742v2
"An Efficient and Scalable Collection of Fly-inspired Voting Units for
  Visual Place Recognition in Changing Environments",2021-09-22T19:01:20Z,"Bruno Arcanjo, Bruno Ferrarini, Michael Milford, Klaus D. McDonald-Maier, Shoaib Ehsan","State-of-the-art visual place recognition performance is currently being
achieved utilizing deep learning based approaches. Despite the recent efforts
in designing lightweight convolutional neural network based models, these can
still be too expensive for the most hardware restricted robot applications.
Low-overhead VPR techniques would not only enable platforms equipped with
low-end, cheap hardware but also reduce computation on more powerful systems,
allowing these resources to be allocated for other navigation tasks. In this
work, our goal is to provide an algorithm of extreme compactness and efficiency
while achieving state-of-the-art robustness to appearance changes and small
point-of-view variations. Our first contribution is DrosoNet, an exceptionally
compact model inspired by the odor processing abilities of the fruit fly,
Drosophyla melanogaster. Our second and main contribution is a voting mechanism
that leverages multiple small and efficient classifiers to achieve more robust
and consistent VPR compared to a single one. We use DrosoNet as the baseline
classifier for the voting mechanism and evaluate our models on five benchmark
datasets, assessing moderate to extreme appearance changes and small to
moderate viewpoint variations. We then compare the proposed algorithms to
state-of-the-art methods, both in terms of precision-recall AUC results and
computational efficiency.",http://arxiv.org/abs/2109.10986v1
"Intermediate spin state and the B1-B2 transition in ferropericlase at
  tera-Pascal pressures",2021-09-22T19:55:28Z,"Tianqi Wan, Yang Sun, Renata M. Wentzcovitch","Ferropericlase (fp), (Mg$_{1-x}$Fe$_x$)O, the second most abundant mineral in
the Earth's lower mantle, is expected to be an essential component of
super-Earths' mantles. Here we present an ab initio investigation of the
structure and magnetic ground state of fp up to $\sim$ 3 TPa with iron
concentrations (x$_{Fe}$) varying from 0.03 to 0.12. Calculations were
performed using LDA+U$_{sc}$ and PBE exchange-correlation functionals to
elucidate the pressure range for which the Hubbard U (U$_{sc}$) is required.
Similar to the end-members FeO and MgO, fp also undergoes a B1 to B2 phase
transition that should be essential for modeling the structure and dynamics of
super-Earths' mantles. This structural transition involves a simultaneous
change in magnetic state from a low spin (LS) B1 phase with iron total spin S=0
to an intermediate spin (IS) B2 phase with S=1. This is a rare form of
pressure/strain-induced magnetism produced by local cation coordination
changes. Phonon calculations confirm the dynamical stability of the iron B2-IS
state. Free energy calculations are then carried out including vibrational
effects and electronic and magnetic entropy contributions. The phase diagram is
then obtained for low concentration fp using a quasi-ideal solid solution
model. For x$_{Fe}$ > 0.12 this approach is no longer valid. At ultra-high
pressures, there is an IS to LS spin state change in Fe in the B2 phase, but
the transition pressure depends sensitively on thermal electronic excitations
and on x$_{Fe}$.",http://arxiv.org/abs/2109.11008v2
"Longitudinal change in language behaviour during protests: A case study
  of Euromaidan in Ukraine",2021-09-23T20:18:42Z,"Ivan Slobozhan, Tymofii Brik, Rajesh Sharma","In the last decade, online social media has become the primary platform for
protesters to organize and express their agenda in various parts of the world.
Nevertheless, scholars still debate whether online tools induce offline
protests or facilitate them. Unfortunately, studies of protests often lack
panel data and cannot address how particular users change their behaviour over
time in line with the protest agenda. To this end, we analyze a new dataset of
the Facebook page EuroMaydan that was explicitly created to facilitate the
protest in Ukraine from November 2013 to February 2014. Moreover, our analysis
follows this page even after the end of the protest till June 2014. In total,
the dataset includes 26,631 posts and 1,470,593 comments that were generated by
124,790 users during and after the protests. We use this panel data to test how
particular users switch between the two most popular languages of this page:
Ukrainian and Russian. Previous studies have puzzled with language behaviour
during the Ukrainian protest. Although researchers expected to see more
Ukrainian language due to national mobilization, studies discovered that
Ukrainian protesters frequently used Russian, especially after the end of the
protest. A hypothesis was suggested that protesters use language strategically
depending on circumstances (e.g., to maximize outreach). However, previous
studies relied on aggregated data and did not explore the within-subject
variation of language behaviour. Our study adds to this scholarship by adding a
longitudinal analysis of language behaviour. Considering the broader
contribution of this paper, we add to the literature on protests by validating
previous findings derived from surveys that activists change their behaviour to
reflect prior preferences and situational goals rather than modify their
preferences.",http://arxiv.org/abs/2109.11623v1
Modeling Dynamic Attributes for Next Basket Recommendation,2021-09-23T21:31:17Z,"Yongjun Chen, Jia Li, Chenghao Liu, Chenxi Li, Markus Anderle, Julian McAuley, Caiming Xiong","Traditional approaches to next item and next basket recommendation typically
extract users' interests based on their past interactions and associated static
contextual information (e.g. a user id or item category). However, extracted
interests can be inaccurate and become obsolete. Dynamic attributes, such as
user income changes, item price changes (etc.), change over time. Such dynamics
can intrinsically reflect the evolution of users' interests. We argue that
modeling such dynamic attributes can boost recommendation performance. However,
properly integrating them into user interest models is challenging since
attribute dynamics can be diverse such as time-interval aware, periodic
patterns (etc.), and they represent users' behaviors from different
perspectives, which can happen asynchronously with interactions. Besides
dynamic attributes, items in each basket contain complex interdependencies
which might be beneficial but nontrivial to effectively capture. To address
these challenges, we propose a novel Attentive network to model Dynamic
attributes (named AnDa). AnDa separately encodes dynamic attributes and basket
item sequences. We design a periodic aware encoder to allow the model to
capture various temporal patterns from dynamic attributes. To effectively learn
useful item relationships, intra-basket attention module is proposed.
Experimental results on three real-world datasets demonstrate that our method
consistently outperforms the state-of-the-art.",http://arxiv.org/abs/2109.11654v1
"Growth of Outward Propagating Fast-Magnetosonic/Whistler Waves in the
  Inner Heliosphere Observed by Parker Solar Probe",2021-09-27T02:34:14Z,"Jiansen He, Ying Wang, Xingyu Zhu, Die Duan, Daniel Verscharen, Guoqing Zhao","The solar wind in the inner heliosphere has been observed by Parker Solar
Probe (PSP) to exhibit abundant wave activities. The cyclotron wave modes in
the sense of ions or electrons are among the most crucial wave components.
However, their origin and evolution in the inner heliosphere close to the Sun
remain mysteries. Specifically, it remains unknown whether it is an emitted
signal from the solar atmosphere or an eigenmode growing locally in the
heliosphere due to plasma instability. To address and resolve this controversy,
we must investigate the key quantity of the energy change rate of the wave
mode. We develop a new technique to measure the energy change rate of plasma
waves, and apply this technique to the wave electromagnetic fields measured by
PSP. We provide the wave Poynting flux in the solar wind frame, identify the
wave nature to be the outward propagating fast-magnetosonic/whistler wave mode
instead of the sunward propagating waves. We provide the first evidence for
growth of the fast-magnetosonic/whistler wave mode in the inner heliosphere
based on the derived spectra of the real and imaginary parts of the wave
frequencies. The energy change rate rises and stays at a positive level in the
same wavenumber range as the bumps of the electromagnetic field power spectral
densities, clearly manifesting that the observed fast-magnetosonic/whistler
waves are locally growing to a large amplitude.",http://arxiv.org/abs/2109.12768v1
"Can You See Me Now? A Measurement Study of Zoom, Webex, and Meet",2021-09-27T15:00:18Z,"Hyunseok Chang, Matteo Varvello, Fang Hao, Sarit Mukherjee","Since the outbreak of the COVID-19 pandemic, videoconferencing has become the
default mode of communication in our daily lives at homes, workplaces and
schools, and it is likely to remain an important part of our lives in the
post-pandemic world. Despite its significance, there has not been any
systematic study characterizing the user-perceived performance of existing
videoconferencing systems other than anecdotal reports. In this paper, we
present a detailed measurement study that compares three major
videoconferencing systems: Zoom, Webex and Google Meet. Our study is based on
48 hours' worth of more than 700 videoconferencing sessions, which were created
with a mix of emulated videoconferencing clients deployed in the cloud, as well
as real mobile devices running from a residential network. We find that the
existing videoconferencing systems vary in terms of geographic scope, which in
turns determines streaming lag experienced by users. We also observe that
streaming rate can change under different conditions (e.g., number of users in
a session, mobile device status, etc), which affects user-perceived streaming
quality. Beyond these findings, our measurement methodology can enable
reproducible benchmark analysis for any types of comparative or longitudinal
study on available videoconferencing systems.",http://arxiv.org/abs/2109.13113v1
"The effects of random and seasonal environmental fluctuations on optimal
  harvesting and stocking",2021-09-27T16:30:25Z,"Alexandru Hening, Ky Q. Tran, Sergiu C. Ungureanu","We analyze the harvesting and stocking of a population that is affected by
random and seasonal environmental fluctuations. The main novelty comes from
having three layers of environmental fluctuations. The first layer is due to
the environment switching at random times between different environmental
states. This is similar to having sudden environmental changes or catastrophes.
The second layer is due to seasonal variation, where there is a significant
change in the dynamics between seasons. Finally, the third layer is due to the
constant presence of environmental stochasticity -- between the seasonal or
random regime switches, the species is affected by fluctuations which can be
modelled by white noise. This framework is more realistic because it can
capture both significant random and deterministic environmental shifts as well
as small and frequent fluctuations in abiotic factors. Our framework also
allows for the price or cost of harvesting to change deterministically and
stochastically, something that is more realistic from an economic point of
view.
  The combined effects of seasonal and random fluctuations make it impossible
to find the optimal harvesting-stocking strategy analytically. We get around
this roadblock by developing rigorous numerical approximations and proving that
they converge to the optimal harvesting-stocking strategy. We apply our methods
to multiple population models and explore how prices, or costs, and
environmental fluctuations influence the optimal harvesting-stocking strategy.
We show that in many situations the optimal way of harvesting and stocking is
not of threshold type.",http://arxiv.org/abs/2109.13169v2
Merger-induced galaxy transformations in the ARTEMIS simulations,2021-09-27T18:00:00Z,"Adam M. Dillamore, Vasily Belokurov, Andreea S. Font, Ian G. McCarthy","Using the ARTEMIS set of 45 high-resolution cosmological simulations, we
investigate a range of merger-induced dynamical transformations of Milky
Way-like galaxies. We first identify populations of accreted stars on highly
radial orbits, similar to the 'Gaia Sausage' in the Milky Way. We show that
$\approx1/3$ of the ARTEMIS galaxies contain a similar feature, and confirm
that they usually comprise stellar debris from the most massive accreted
satellite. Selecting 15 galaxies with discs at the present-day, we study their
changes around the times of the GS-like mergers. Dark matter haloes of many of
these exhibit global changes in shape and orientation, with almost half
becoming significantly more spherical when the mergers occur. Focusing on the
galaxies themselves, we find that 4/15 have stellar discs which experience
large changes in the orientation of their angular momentum (AM) axes, at rates
of up to $\sim60$ degrees Gyr$^{-1}$. By calculating the orbital angular
momentum axes of the satellites before they are accreted, we show that there is
a tendency for the disc's AM to become more aligned with this axis after the
merger. We also investigate the origin of in situ retrograde stars, analogous
to the 'Splash' in the Milky Way. Tracing them back to earlier snapshots, we
demonstrate that they were often disrupted onto their extreme orbits by
multiple early mergers. We also find that the total mass of these stars outside
the central regions positively correlates with the total accreted stellar mass.",http://arxiv.org/abs/2109.13244v2
Designing Counterfactual Generators using Deep Model Inversion,2021-09-29T08:40:50Z,"Jayaraman J. Thiagarajan, Vivek Narayanaswamy, Deepta Rajan, Jason Liang, Akshay Chaudhari, Andreas Spanias","Explanation techniques that synthesize small, interpretable changes to a
given image while producing desired changes in the model prediction have become
popular for introspecting black-box models. Commonly referred to as
counterfactuals, the synthesized explanations are required to contain
discernible changes (for easy interpretability) while also being realistic
(consistency to the data manifold). In this paper, we focus on the case where
we have access only to the trained deep classifier and not the actual training
data. While the problem of inverting deep models to synthesize images from the
training distribution has been explored, our goal is to develop a deep
inversion approach to generate counterfactual explanations for a given query
image. Despite their effectiveness in conditional image synthesis, we show that
existing deep inversion methods are insufficient for producing meaningful
counterfactuals. We propose DISC (Deep Inversion for Synthesizing
Counterfactuals) that improves upon deep inversion by utilizing (a) stronger
image priors, (b) incorporating a novel manifold consistency objective and (c)
adopting a progressive optimization strategy. We find that, in addition to
producing visually meaningful explanations, the counterfactuals from DISC are
effective at learning classifier decision boundaries and are robust to unknown
test-time corruptions.",http://arxiv.org/abs/2109.14274v2
Application-Platform Co-Design for Serverless Data Processing,2021-10-29T14:41:50Z,"Sebastian Werner, Stefan Tai","""Application-platform co-design"" refers to the phenomenon of new platforms
being created in response to changing application needs, followed by
application design and development changing due to the emergence (and the
specifics, limitations) of the new platforms, therefore creating, again, new
application and platform requirements. This continuous process of application
and platform (re-)design describes an engineering and management responsibility
to constantly evaluate any given platform for application fit and
platform-specific application design, and to consider a new or evolutionary
platform development project due to evolving and changing application needs.
  In this paper, we study this phenomenon in the context of serverless
computing and (big) data processing needs, and thus, for application-platform
co-design for serverless data processing (SDP). We present an analysis of the
state-of-the-art of function-as-a-service (FaaS) platforms, which reveals
several configuration, deployment, execution, and measurement differences
between popular platforms happening at-speed. These differences indicate
already ongoing platform (re-)design processes resulting in more specialized
serverless platforms and new, platform-specific challenges for application
design. We discuss data processing needs of applications using the serverless
model and present common initial (and undesirable) workaround solutions on the
application level, giving additional argument to the creation of new SDP
platforms. We present critical SDP requirements and possible new platform
augmentations, but identify the need for engineering methods and tooling to
better guide application-platform co-design. We argue to pay appropriate
attention to the phenomenon of continuous application-platform co-design to
better anticipate and to control future platform and application developments.",http://arxiv.org/abs/2111.00933v1
Anisotropic magnetocaloric effect of CrI$_{3}$: A theoretical study,2021-11-03T08:29:19Z,"Hung Ba Tran, Hiroyoshi Momida, Yu-ichiro Matsushita, Koun Shirai, Tamio Oguchi","CrI$_{3}$ is considered to be a promising candidate for spintronic devices
and data storage. We derived the Heisenberg Hamiltonian for CrI$_{3}$ from
density functional calculations using the Liechtenstein formula. Moreover, the
Monte--Carlo simulations with the Sucksmith--Thompson method were performed to
analyze the effect of magnetic anisotropy energy on the thermodynamic
properties. Our method successfully reproduced the negative sign of isothermal
magnetic entropy changes when a magnetic field was applied along the hard
plane. We found that the temperature dependence of the magnetocrystalline
anisotropy energy is not negligible at temperatures slightly above the Curie
temperature. We clarified that the origin of this phenomenon is attributed to
anisotropic magnetic susceptibility and magnetization anisotropy. The
difference between the entropy change of the easy axis and the hard plane is
proportional to the temperature dependence of the magnetic anisotropy energy,
implying that the anisotropic entropy term is the main source of the
temperature dependence of the free energy difference when magnetizing in a
specific direction other than the easy axis. We also investigated the magnetic
susceptibility that can be used for the characterization of the negative sign
of the entropy change in the case of a hard plane. The competition of
magnetocrystalline anisotropy energy and external magnetic field at low
temperature and low magnetic field region causes a high magnetic susceptibility
as the fluctuation of magnetization. Meanwhile, the anisotropy energy is
suppressed at a sufficient magnetic field applied along the hard axis, the
magnetization is fully rotated to the direction of the external magnetic field.",http://arxiv.org/abs/2111.02063v1
"Homoscatter: Towards efficient connectivity for ZigBee backscatter
  system",2021-11-03T11:14:13Z,"Zhaoyuan Xu, Wei Gong","Recent advances in backscatter open a promising direction for ultra-low power
communication. However, the state-of-art ZigBee backscatter system,
Interscatter, has several drawbacks to deploy. Its backscatter tag and exciting
source, Bluetooth, can hardly decode packets from other ZigBee nodes, which
left Interscatter one-way communication. Besides, it adopts instantaneous phase
change to modulate information, producing obvious sidelobes and interfering
devices working on neighboring channels severely. To address the problems
mentioned above, we introduce Homoscatter, a novel ZigBee backscatter system
that adopts specific ZigBee devices to generate a single tone and leverages
continuous phase change to modulate information, which eliminates spectral
leakage. It also does codeword translation on the packet header of exciting
packets, improving the utilization of ambient signal.
  The prototype of Homoscatter consists of a microchip radio, a backscatter
tag, and a commodity receiver. The evaluations show that the occupied bandwidth
of Homoscatter achieves 3x smaller than Interscatter. When the channel capacity
is 17.5 kbps, the continuous phase change modulation achieves 13 kbps with the
codeword translation on the excitation header. Based on the widely spread IoT
devices, Homoscatter is a practical way to build an efficient connection
between IoT devices.",http://arxiv.org/abs/2111.02140v2
Uniform bounds on symbolic powers in regular rings,2021-11-11T04:52:33Z,Takumi Murayama,"We prove a uniform bound on the growth of symbolic powers of arbitrary (not
necessarily radical) ideals in arbitrary (not necessarily excellent) regular
rings of all characteristics. This gives a complete answer to a question of
Hochster and Huneke. In equal characteristic, this result was proved by Ein,
Lazarsfeld, and Smith and by Hochster and Huneke. For radical ideals in
excellent regular rings of mixed characteristic, this result was proved by Ma
and Schwede. We also prove a generalization of these results involving products
of various symbolic powers and a uniform bound for regular local rings related
to a conjecture of Eisenbud and Mazur, which are completely new in mixed
characteristic. In equal characteristic, these results are due to Johnson and
to Hochster-Huneke, Takagi-Yoshida, and Johnson, respectively.",http://arxiv.org/abs/2111.06049v5
A Rule-Based Epidemiological Modelling Framework,2021-11-14T13:11:38Z,"David Alonso, Steffen Bauer, Markus Kirkilionis, Lisa Maria Kreusser, Luca Sbano","Motivated by chemical reaction rules, we introduce a rule-based
epidemiological framework for the systematic mathematical modelling of future
pandemics. Here we stress that we do not have a specific model in mind, but a
whole collection of models which can be transformed into each other, or
represent different aspects of a pandemic, and these aspects can change during
the course of the emergency, as happened during the Covid-19 pandemic. As
conditions for outbreaks in the modern world change on different time-scales,
some rapidly, epidemiology has few 'laws', besides perhaps the fundamental
infection process described by Kermack-McKendrick. Each single of our variety
of models, called framework, is based on a mathematical formulation that we
call a rule-based system. They have several advantages, for example that they
can be both interpreted stochastically and deterministically, without changing
the model structure. Rule-based systems should be easier to communicate to
non-specialists, when compared to differential equations. Due to their
combinatorial nature, the rule-based model framework we propose is ideal for
systematic mathematical modelling, systematic links to statistics, data
analysis in general and also machine learning leading to artificial
intelligence.",http://arxiv.org/abs/2111.07336v3
"Correlation between optical flux and polarization variations in Flat
  Spectrum Radio Quasars on diverse timescales",2021-11-16T06:08:56Z,"Ashwani Pandey, Bhoomika Rajput, C. S. Stalin","Study of the polarization behaviour in blazars is a powerful tool to discern
the role of magnetic field in the variable emission process in their
relativistic jets. We present here results of our systematic investigation on
the correlation between optical flux and polarization variations for eight
flat-spectrum radio quasars on various timescales using data from the Steward
Observatory that covers a period of $\sim$10 years. On long time scales
($\sim$several months), from a total of 79 observing cycles, in 34 observing
cycles, we found a significant positive correlation between optical flux and
optical polarization degree (PD), negative correlation in 3 cycles and no
correlation in 42 cycles. On short time scales ($\sim$few days), in 47 out of a
total of 55 epochs, we found a positive correlation between optical flux and
PD, while, on the remaining 8 epochs, an anti-correlation was detected between
the two quantities. Moreover, we noticed a significant positive correlation
between optical and $\gamma-$ray fluxes on 14 epochs and a negative correlation
between the two on one epoch. While the observed optical flux changes well fit
in the shock-in-jet model, the observed changes in PD are not explainable by
changes in the power-law spectral index of the relativistic electrons in the
jet. Instead, the observed varied correlations between optical flux and PD
could be due to multi-zone emission regions or the enhanced flux coinciding
with the emergence of a new emission knot with its magnetic field either
aligned or misaligned with the large scale magnetic field.",http://arxiv.org/abs/2111.08247v1
"Analysis of pedestrian stress level using GSR sensor in virtual
  immersive reality",2021-11-22T19:33:55Z,"Mahwish Mudassar, Arash Kalatian, Bilal Farooq","Level of emotional arousal of one's body changes in response to external
stimuli in an environment. Given the risks involved while crossing streets,
particularly at unsignalized mid-block crosswalks, one can expect a change in
the stress level of pedestrians. In this study, we investigate the levels and
changes in pedestrian stress, under different road crossing scenarios in
immersive virtual reality. To measure the stress level of pedestrians, we used
Galvanic Skin Response (GSR) sensors. To collect the required data for the
model, Virtual Immersive Reality Environment (VIRE) tool is used, which enables
us to measure participants' stress levels in a controlled environment. The
results suggested that the density of vehicles has a positive effect, meaning
as the density of vehicles increases, so does the stress level for pedestrians.
It was noted that younger pedestrians have a lower amount of stress when
crossing as compared to older pedestrians which have higher amounts of stress.
Geometric variables have an impact on the stress level of pedestrians. The
greater the number of lanes the greater the observed stress, which is due to
the crossing distance increasing, while the walking speed remains the same.",http://arxiv.org/abs/2111.11492v2
A bifurcation threshold for contact-induced language change,2021-11-23T18:21:12Z,Henri Kauhanen,"One proposed mechanism of language change concerns the role played by
second-language (L2) learners in situations of language contact. If
sufficiently many L2 speakers are present in a speech community in relation to
the number of first-language (L1) speakers, then those features which present a
difficulty in L2 acquisition may be prone to disappearing from the language.
This paper presents a mathematical account of such contact situations based on
a stochastic model of learning and nonlinear population dynamics. The
equilibria of a deterministic reduction of the model, describing a mixed
population of L1 and L2 speakers, are fully characterized. Whether or not the
language changes in response to the introduction of L2 learners turns out to
depend on three factors: the overall proportion of L2 learners in the
population, the strength of the difficulty speakers face in acquiring the
language as an L2, and the language-internal utilities of the competing
linguistic variants. These factors are related by a mathematical formula
describing a phase transition from retention of the L2-difficult feature to its
loss from both speaker populations. This supplies predictions that can be
tested against empirical data. Here, the model is evaluated with the help of
two case studies, morphological levelling in Afrikaans and the erosion of null
subjects in Afro-Peruvian Spanish; the model is found to be broadly in
agreement with the historical development in both cases.",http://arxiv.org/abs/2111.12061v2
Hanson-Wright Inequality for Random Tensors under Einstein Product,2021-11-23T21:54:55Z,Shih Yu Chang,"The Hanson-Wright inequality is an upper bound for tails of real quadratic
forms in independent subgaussian random variables. In this work, we extend the
Hanson-Wright inequality for the maximum eigenvalue of the quadratic sum of
random Hermitian tensors under Einstein product. We first prove Weyl inequality
for tensors under Einstein product and apply this fact to separate the
quadratic form of random Hermitian tensors into diagonal sum and coupling
(non-diagonal) sum parts. For the diagonal part, we can apply Bernstein
inequality to bound the tail probability of the maximum eigenvalue of the sum
of independent random Hermitian tensors directly. For coupling sum part, we
have to apply decoupling method first, i.e., decoupling inequality to bound
expressions with dependent random Hermitian tensors with independent random
Hermitian tensors, before applying Bernstein inequality again to bound the tail
probability of the maximum eigenvalue of the coupling sum of independent random
Hermitian tensors. Finally, the Hanson-Wright inequality for the maximum
eigenvalue of the quadratic sum of random Hermitian tensors under Einstein
product can be obtained by the combination of the bound from the diagonal sum
part and the bound from the coupling (non-diagonal) sum part. In Appendix of
this work, we also include the Hanson-Wright inequality under T-product tensor,
which can be derived by the same method of establishing the Hanson-Wright
inequality under Einstein product except changing the rule of tensors product
operation.",http://arxiv.org/abs/2111.12169v3
Model systematics in time domain tests of binary black hole evolution,2021-11-26T18:44:29Z,"Shilpa Kastha, Collin D. Capano, Julian Westerweck, Miriam Cabero, Badri Krishnan, Alex B. Nielsen","We perform several consistency tests between different phases of binary black
hole dynamics; the inspiral, the merger, and the ringdown on the gravitational
wave events GW150914 and GW170814. These tests are performed explicitly in the
time domain, without any spectral leakage between the different phases. We
compute posterior distributions on the mass and spin of the initial black holes
and the final black hole. We also compute the initial areas of the two
individual black holes and the final area from the parameters describing the
remnant black hole. This facilitates a test of Hawking's black hole area
theorem. We use different waveform models to quantify systematic waveform
uncertainties for the area increase law with the two events. We find that these
errors may lead to overstating the confidence with which the area theorem is
confirmed. For example, we find $>99\%$ agreement with the area theorem for
GW150914 if a damped sinusoid consisting of a single-mode is used at merger to
estimate the final area. This is because this model overestimates the final
mass. Including an overtone of the dominant mode decreases the confidence to
$\sim94\%$; using a full merger-ringdown model further decreases the confidence
to $\sim 85-90\%$. We find that comparing the measured change in the area to
the expected change in area yields a more robust test, as it also captures over
estimates in the change of area. We find good agreement with GR when applying
this test to GW150914 and GW170814.",http://arxiv.org/abs/2111.13664v1
Method of distinguishing between black holes and wormholes,2021-11-25T05:00:53Z,"Wei Hong, Jun Tao, Tong-Jie Zhang","Beginning with a brief review of the regular space-time with asymptotically
Minkowski core, we can consider two copies of the space-time connected through
a short-throat wormhole whose radius of mouth is equal to or larger than an
extremal regular black hole with asymptotically Minkowski core's event horizon
radius. If the wormhole is traversable and smooth, fluxes in these two
space-times will interact with and flow into each other. On the cosmological
scale, gravity is a candidate for the flux. As the gravitational field changes
in one space-time, the behaviours of stars around the wormhole will be affected
by the other space-time since we assume there exists enough exotic matter to
keep the wormhole open. The changes in a gravitational field can be quantized
through the gauge invariant perturbations. The variances in orbits of stars can
be reflected by changes in the kinematic shifts of photon frequencies. Then, we
use this to distinguish between the black hole and wormhole generated by the
same space-time line element, since black hole can not connect two space-times
and is unaffected by other space-time.",http://arxiv.org/abs/2111.14749v2
"Sequential Stochastic Control (Single or Multi-Agent) Problems Nearly
  Admit Change of Measures with Independent Measurements",2021-11-30T04:30:56Z,"Ian Hogeboom-Burr, Serdar Yüksel","Change of measures has been an effective method in stochastic control and
analysis; in continuous-time control this follows Girsanov's theorem applied to
both fully observed and partially observed models, in decentralized stochastic
control (or stochastic dynamic team theory) this is known as Witsenhausen's
static reduction, and in discrete-time classical stochastic control Borkar has
considered this method for partially observed Markov Decision processes
(POMDPs) generalizing Fleming and Pardoux's approach in continuous-time. This
method allows for equivalent optimal stochastic control or filtering in a new
probability space where the measurements form an independent exogenous process
in both discrete-time and continuous-time and the Radon-Nikodym derivative
(between the true measure and the reference measure formed via the independent
measurement process) is pushed to the cost or dynamics. However, for this to be
applicable, an absolute continuity condition is necessary. This raises the
following question: can we perturb any discrete-time sequential stochastic
control problem by adding some arbitrarily small additive (e.g. Gaussian or
otherwise) noise to the measurements to make the system measurements absolutely
continuous, so that a change-of-measure (or static reduction) can be applicable
with arbitrarily small error in the optimal cost? That is, are all sequential
stochastic (single-agent or decentralized multi-agent) problems $\epsilon$-away
from being static reducible as far as optimal cost is concerned, for any
$\epsilon > 0$? We show that this is possible when the cost function is bounded
and continuous in controllers' actions and the action spaces are convex. We
also note that the solution and the cost obtained for the perturbed system is
realizable (under a randomized policy) for the original model.",http://arxiv.org/abs/2111.15120v2
Sub-Seasonal Variation in Neptune's Mid-Infrared Emission,2021-11-30T19:00:11Z,"Michael T. Roman, Leigh N. Fletcher, Glenn S. Orton, Thomas K. Greathouse, Julianne I. Moses, Naomi Rowe-Gurney, Patrick G. J. Irwin, Arrate Antunano, James Sinclair, Yasumasa Kasaba, Takuya Fujiyoshi, Imke de Pater, Heidi B. Hammel","We present an analysis of all currently available ground-based imaging of
Neptune in the mid-infrared. Dating between 2003 and 2020, the images reveal
changes in Neptune's mid-infrared ($\sim 8-25\mu$m) emission over time in the
years surrounding Neptune's 2005 southern summer solstice. Images sensitive to
stratospheric ethane ($\sim12\mu$m), methane ($\sim8\mu$m), and CH$_3$D
($\sim9\mu$m) display significant sub-seasonal temporal variation on regional
and global scales. Comparison with H$_2$ S(1) hydrogen-quadrupole
($\sim17.035\mu$m) spectra suggests these changes are primarily related to
stratospheric temperature changes. The stratosphere appears to have cooled
between 2003 and 2009 across multiple filtered wavelengths, followed by a
dramatic warming of the south pole between 2018 and 2020. Conversely,
upper-tropospheric temperatures -- inferred from $\sim 17-25$-micron imaging --
appear invariant during this period, except for the south pole, which appeared
warmest between 2003 and 2006. We discuss the observed variability in the
context of seasonal forcing, tropospheric meteorology, and the solar cycle.
Collectively, these data provide the strongest evidence to date that processes
produce sub-seasonal variation on both global and regional scales in Neptune's
stratosphere.",http://arxiv.org/abs/2112.00033v2
PreViTS: Contrastive Pretraining with Video Tracking Supervision,2021-12-01T19:49:57Z,"Brian Chen, Ramprasaath R. Selvaraju, Shih-Fu Chang, Juan Carlos Niebles, Nikhil Naik","Videos are a rich source for self-supervised learning (SSL) of visual
representations due to the presence of natural temporal transformations of
objects. However, current methods typically randomly sample video clips for
learning, which results in an imperfect supervisory signal. In this work, we
propose PreViTS, an SSL framework that utilizes an unsupervised tracking signal
for selecting clips containing the same object, which helps better utilize
temporal transformations of objects. PreViTS further uses the tracking signal
to spatially constrain the frame regions to learn from and trains the model to
locate meaningful objects by providing supervision on Grad-CAM attention maps.
To evaluate our approach, we train a momentum contrastive (MoCo) encoder on
VGG-Sound and Kinetics-400 datasets with PreViTS. Training with PreViTS
outperforms representations learnt by contrastive strategy alone on video
downstream tasks, obtaining state-of-the-art performance on action
classification. PreViTS helps learn feature representations that are more
robust to changes in background and context, as seen by experiments on datasets
with background changes. Learning from large-scale videos with PreViTS could
lead to more accurate and robust visual feature representations.",http://arxiv.org/abs/2112.00804v2
Changepoint Analysis of Topic Proportions in Temporal Text Data,2021-11-29T17:20:51Z,"Avinandan Bose, Soumendu Sundar Mukherjee","Changepoint analysis deals with unsupervised detection and/or estimation of
time-points in time-series data, when the distribution generating the data
changes. In this article, we consider \emph{offline} changepoint detection in
the context of large scale textual data. We build a specialised temporal topic
model with provisions for changepoints in the distribution of topic
proportions. As full likelihood based inference in this model is
computationally intractable, we develop a computationally tractable approximate
inference procedure. More specifically, we use sample splitting to estimate
topic polytopes first and then apply a likelihood ratio statistic together with
a modified version of the wild binary segmentation algorithm of Fryzlewicz et
al. (2014). Our methodology facilitates automated detection of structural
changes in large corpora without the need of manual processing by domain
experts. As changepoints under our model correspond to changes in topic
structure, the estimated changepoints are often highly interpretable as marking
the surge or decline in popularity of a fashionable topic. We apply our
procedure on two large datasets: (i) a corpus of English literature from the
period 1800-1922 (Underwoodet al., 2015); (ii) abstracts from the High Energy
Physics arXiv repository (Clementet al., 2019). We obtain some historically
well-known changepoints and discover some new ones.",http://arxiv.org/abs/2112.00827v1
"Linking Solar Minimum, Space Weather, and Night Sky Brightness",2021-12-03T01:22:05Z,"Albert D. Grauer, Patricia A. Grauer","This paper presents time series observations and analysis of broadband night
sky airglow intensity 4 September 2018 through 30 April 2020. Data were
obtained at 5 sites spanning more than 8500 km during the historically deep
minimum of Solar Cycle 24 into the beginning of Solar Cycle 25. New time series
observations indicate previously unrecognized significant sources of broadband
night sky brightness variations, not involving corresponding changes in the
Sun's 10.7cm solar flux, occur during deep solar minimum. Even during a deep
solar minimum the natural night sky is rarely, if ever, constant in brightness.
Changes with time scales of minutes, hours, days, and months are observed.
Semiannual night sky brightness variations are coincident with changes in the
orientation of Earth's magnetic field relative to the interplanetary magnetic
field. Solar wind plasma streams from solar coronal holes arriving at Earth's
bow shock nose are coincident with major night sky brightness increase events.
Sites more than 8500 km along the Earth's surface experience nights in common
with either very bright or very faint night sky airglow emissions. The reason
for this observational fact remains an open question. It is plausible,
terrestrial night airglow and geomagnetic indices have similar responses to the
solar energy input into Earth's magnetosphere. Our empirical results contribute
to a quantitative basis for understanding and predicting broadband night sky
brightness variations. They are applicable in astronomical, planetary science,
space weather, light pollution, biological, and recreational studies.",http://arxiv.org/abs/2112.01664v1
The Three Hundred: Cluster Dynamical States and Relaxation Time Scale,2021-12-03T13:51:11Z,"Bowei Zhang, Weiguang Cui, Romeel Dave, Marco De Petris","Using the galaxy clusters from The Three Hundred Project, we define a new
parameter: $\lambda_{DS}$ to describe the dynamical state of clusters, which
assumes a double-Gaussian distribution in logarithm scale for our mass-complete
cluster sample at $z=0$ from the dark-matter-only (DMO) run. Therefore, the
threshold for distinguishing relaxed and unrelaxed clusters is naturally
determined by the crossing point of the double-Gaussian fitting which has a
value of $\lambda_{DS} = 3.424$. By applying $\lambda_{DS}$ with the same
parameters from the DMO run to the hydro-dynamically simulated clusters
(Gadget-X run and GIZMO-SIMBA run), we investigate the effect of baryons on the
cluster dynamical state. We find a weak baryon-model dependence for the
$\lambda_{DS}$ parameter. Finally, we study the evolution of $\lambda_{DS}$
along with clusters mass accretion history. We notice an upper limit of halo
mass change $\frac{\Delta M_{200}}{M_{200}} \sim 0.12$ that don't alter the
cluster dynamical state, i.e. from relaxed to unrelaxed. We define relaxation
period (from the most relaxed state to disturb and relaxed again) which
reflects how long the dynamical state of a cluster restores its relaxation
state, and propose a correlation between this relaxation period and the
strength of halo mass change $\frac{\Delta M_{200}}{M_{200}}$. With the
proposed fitting to such correlation, we verify the relaxation period can be
estimated from $\frac{\Delta M_{200}}{M_{200}}$ (including multi mass change
peaks) with considerably small error.",http://arxiv.org/abs/2112.01909v2
"Energy transfer mechanisms in adverse pressure gradient turbulent
  boundary layers",2021-12-06T12:50:15Z,"Taygun R. Gungor, Yvan Maciel, Ayse G. Gungor","The energy transfer mechanisms and structures playing a role in these
mechanisms in adverse-pressure-gradient (APG) turbulent boundary layers (TBLs)
with small and large velocity defects are investigated. We examine the
wall-normal and spectral distributions of energy, production and
pressure-strain in APG TBLs and compare these distributions with those in
canonical flows. It is found that the spectral distributions of production and
pressure-strain are not profoundly affected by an increase of the velocity
defect, although the energy spectra drastically change in the inner layer of
the large defect APG TBL. In the latter, the signature of the inner layer
streaks is absent from the energy spectra. However, the production and
pressure-strain spectra suggest that the near-wall cycle or another energy
transfer mechanism with similar spectral features still exist in large defect
TBLs. In the outer layer, energetic, production and pressure-strain structures
appear to change from wall-attached to wall-detached structures with increasing
velocity defect. Despite this, the 2D spectral distributions have similar
shapes and wavelength aspect ratios of the peaks in all these flows. These
observations suggest that outer layer energy transfer mechanisms may be the
same in wall-bounded flows, no matter if dynamically relevant structures are
attached or detached to the wall. Therefore, the conclusion is that the
mechanisms responsible for turbulence production and inter-component energy
transfer may remain the same within each layer in all these flows. It is the
intensity of these mechanisms within one layer that changes with velocity
defect, because of the local mean shear variation.",http://arxiv.org/abs/2112.02980v1
Understanding Distributed Tutorship in Online Language Tutoring,2021-12-07T05:19:35Z,"Meng Xia, Yankun Zhao, Mehmet Hamza Erol, Jihyeong Hong, Juho Kim","With the rise of the gig economy, online language tutoring platforms are
becoming increasingly popular. They provide temporary and flexible jobs for
native speakers as tutors and allow language learners to have one-on-one
speaking practices on demand. However, the lack of stable relationships hinders
tutors and learners from building long-term trust. ""Distributed tutorship"" --
temporally discontinuous learning experience with different tutors -- has been
underexplored yet has many implications for modern learning platforms. In this
paper, we analyzed tutorship sequences of 15,959 learners and found that around
40% of learners change to new tutors every session; 44% learners change to new
tutors while reverting to previous tutors sometimes; only 16% learners change
to new tutors and then fix on one tutor. We also found suggestive evidence that
higher distributedness -- higher diversity and lower continuity in tutorship --
is correlated to slower improvements in speaking performance scores with a
similar number of sessions. We further surveyed 519 and interviewed 40 learners
and found that more learners preferred fixed tutorship while some do not have
it due to various reasons. Finally, we conducted semi-structured interviews
with three tutors and one product manager to discuss the implications for
improving the continuity in learning under distributed tutorship.",http://arxiv.org/abs/2112.03500v4
"The activity of the dwarf nova RU Pegasi with rapidly changing outburst
  types",2021-12-07T10:37:07Z,Vojtech Simon,"RU Peg is a dwarf nova (DN) of the U Gem type. Our analysis of its long-term
optical activity uses the data from the AAVSO database. It concentrates on
investigating the properties of the individual outbursts and the time evolution
of the ensemble of these events. No significant irradiation of the disc by the
white dwarf was detected. In the interpretation, a variable steepness of the
rising branches of the individual outbursts shows that the start of outbursts
of RU Peg can occur at various distances from the disc centre without
remarkable changes of the outburst recurrence time $T_{\rm C}$. The disc
overflow of the inflowing mass stream, varying with time, could contribute to
the changes in the starting position of the heating front, hence the variations
of the outburst types. A typical length of $T_{\rm C}$ was 90 days. The
segments of the relatively stable length of $T_{\rm C}$ were accompanied by the
primarily little variable and small values of the fluence (the energy radiated
in the optical band in the individual outbursts). Jumps of $T_{\rm C}$,
accompanied by the big scatter of the fluences, sometimes replaced them. In the
interpretation, a combination of variations of $T_{\rm C}$ with the unstable
properties of the outbursts, including an unstable mass transfer rate between
the components, shows the influence of several mechanisms on the state of the
disc in various time segments.",http://arxiv.org/abs/2112.03620v1
Vision-Cloud Data Fusion for ADAS: A Lane Change Prediction Case Study,2021-12-07T23:42:21Z,"Yongkang Liu, Ziran Wang, Kyungtae Han, Zhenyu Shou, Prashant Tiwari, John H. L. Hansen","With the rapid development of intelligent vehicles and Advanced
Driver-Assistance Systems (ADAS), a new trend is that mixed levels of human
driver engagements will be involved in the transportation system. Therefore,
necessary visual guidance for drivers is vitally important under this situation
to prevent potential risks. To advance the development of visual guidance
systems, we introduce a novel vision-cloud data fusion methodology, integrating
camera image and Digital Twin information from the cloud to help intelligent
vehicles make better decisions. Target vehicle bounding box is drawn and
matched with the help of the object detector (running on the ego-vehicle) and
position information (received from the cloud). The best matching result, a
79.2% accuracy under 0.7 intersection over union threshold, is obtained with
depth images served as an additional feature source. A case study on lane
change prediction is conducted to show the effectiveness of the proposed data
fusion methodology. In the case study, a multi-layer perceptron algorithm is
proposed with modified lane change prediction approaches. Human-in-the-loop
simulation results obtained from the Unity game engine reveal that the proposed
model can improve highway driving performance significantly in terms of safety,
comfort, and environmental sustainability.",http://arxiv.org/abs/2112.04042v1
"Polarization-dependent magnetic properties of periodically driven
  $α$-RuCl$_{3}$",2021-12-09T04:06:05Z,"Naoya Arakawa, Kenji Yonemitsu","We study magnetic properties of a periodically driven Mott insulator with
strong spin-orbit coupling and show some properties characteristic of linearly
polarized light. We consider a $t_{2g}$-orbital Hubbard model driven by
circularly or linearly polarized light with strong spin-orbit coupling and
derive its effective Hamiltonian in the strong-interaction limit for a
high-frequency case. We show that linearly polarized light can change not only
the magnitudes and signs of the exchange interactions, but also their bond
anisotropy even without the bond-anisotropic hopping integrals. Because of this
property, the honeycomb-network spin system could be transformed into weakly
coupled zigzag or step spin chains for the light field polarized along the $b$-
or $a$-axis, respectively. Then, analyzing how the light fields affect several
magnetic states in a mean-field approximation, we show that linearly polarized
light can change the relative stability of the competing magnetic states,
whereas such a change is absent for circularly polarized light. We also analyze
the effects of both the bond anisotropy of nearest-neighbor hopping integrals
and a third-neighbor hopping integral on the magnetic states and show that the
results obtained in a simple model, in which the bond-averaged nearest-neighbor
hopping integrals are considered, remain qualitatively unchanged except for the
stability of zigzag states in the non-driven case and the degeneracy lifting of
the zigzag or stripy states.",http://arxiv.org/abs/2112.04690v1
"Adsorption-active polydisperse brush with tunable molecular mass
  distribution",2021-12-10T21:04:46Z,"Anna S. Ivanova, Alexey A. Polotsky, Alexander M. Skvortsov, Leonid I. Klushin, Friederike Schmid","Recently a novel class of responsive uncharged polymer brushes has been
proposed [Klushin et al, J. Chem. Phys. 154, 074904 (2021)] where the
brush-forming chains have an affinity to the substrate. For sufficiently strong
surface interactions, a fraction of chains condenses into a near-surface layer,
while the remaining ones form the outer brush with a reduced grafting density.
The dense layer and the more tenuous outer brush can be seen as coexisting
microphases. The effective grafting density of the outer brush is controlled by
the adsorption strength and can be changed reversibly as a response to changes
in environmental parameters.
  In this paper we use numerical self-consistent field calculations and
theoretical considerations to study this phenomenon in polydisperse brushes.
Our results reveal an unexpected effect: Although all chains are chemically
identical, shorter chains are adsorbed preferentially. Hence, with the increase
in the surface affinity parameter, a reduction in the surface grafting density
of the residual brush is accompanied by a change in the shape of its molecular
mass distribution. In particular, an originally bidisperse brush can be
effectively transformed into a nearly monodisperse one containing only the
longer chain fraction.",http://arxiv.org/abs/2112.05832v1
AI-Empowered Persuasive Video Generation: A Survey,2021-12-17T09:24:12Z,"Chang Liu, Han Yu","Promotional videos are rapidly becoming a popular medium for persuading
people to change their behaviours in many settings (e.g., online shopping,
social enterprise initiatives). Today, such videos are often produced by
professionals, which is a time-, labour- and cost-intensive undertaking. In
order to produce such contents to support a large applications (e.g.,
e-commerce), the field of artificial intelligence (AI)-empowered persuasive
video generation (AIPVG) has gained traction in recent years. This field is
interdisciplinary in nature, which makes it challenging for new researchers to
grasp. Currently, there is no comprehensive survey of AIPVG available. In this
paper, we bridge this gap by reviewing key AI techniques that can be utilized
to automatically generate persuasive videos. We offer a first-of-its-kind
taxonomy which divides AIPVG into three major steps: 1) visual material
understanding, which extracts information from the visual materials (VMs)
relevant to the target of promotion; 2) visual storyline generation, which
shortlists and arranges high-quality VMs into a sequence in order to compose a
storyline with persuasive power; and 3) post-production, which involves
background music generation and still image animation to enhance viewing
experience. We also introduce the evaluation metrics and datasets commonly
adopted in the field of AIPVG. We analyze the advantages and disadvantages of
the existing works belonging to the above-mentioned steps, and discuss
interesting potential future research directions.",http://arxiv.org/abs/2112.09401v1
Dynamics-aware Adversarial Attack of 3D Sparse Convolution Network,2021-12-17T10:53:35Z,"An Tao, Yueqi Duan, He Wang, Ziyi Wu, Pengliang Ji, Haowen Sun, Jie Zhou, Jiwen Lu","In this paper, we investigate the dynamics-aware adversarial attack problem
in deep neural networks. Most existing adversarial attack algorithms are
designed under a basic assumption -- the network architecture is fixed
throughout the attack process. However, this assumption does not hold for many
recently proposed networks, e.g. 3D sparse convolution network, which contains
input-dependent execution to improve computational efficiency. It results in a
serious issue of lagged gradient, making the learned attack at the current step
ineffective due to the architecture changes afterward. To address this issue,
we propose a Leaded Gradient Method (LGM) and show the significant effects of
the lagged gradient. More specifically, we re-formulate the gradients to be
aware of the potential dynamic changes of network architectures, so that the
learned attack better ""leads"" the next step than the dynamics-unaware methods
when network architecture changes dynamically. Extensive experiments on various
datasets show that our LGM achieves impressive performance on semantic
segmentation and classification. Compared with the dynamic-unaware methods, LGM
achieves about 20% lower mIoU averagely on the ScanNet and S3DIS datasets. LGM
also outperforms the recent point cloud attacks.",http://arxiv.org/abs/2112.09428v2
Tracing Accretion onto Herbig Ae/Be Stars Using the Brγ Line,2021-12-20T10:16:54Z,"Sierra L. Grant, Catherine C. Espaillat, Sean Brittain, Caleb Scott-Joseph, Nuria Calvet","Accretion plays an important role in protoplanetary disk evolution, and it is
thought that the accretion mechanism changes between low- and high-mass stars.
Here, we characterize accretion in intermediate-mass, pre-main-sequence Herbig
Ae/Be (HAeBe) stars to search for correlations between accretion and system
properties. We present new high-resolution, near-infrared spectra from the
Immersion GRating INfrared Spectrograph for 102 HAeBes and analyze the
accretion-tracing Br$\gamma$ line at 2.166 $\mu$m. We also include the samples
of Fairlamb et al. and Donehew & Brittain, for a total of 155 targets. We find
a positive correlation between the Br$\gamma$ and stellar luminosity, with a
change in the slope between the Herbig Aes and Herbig Bes. We use
$L_{Br\gamma}$ to determine the accretion luminosity and accretion rate. We
find that the accretion luminosity and rate depend on stellar mass and age;
however, the trend disappears when normalizing the accretion luminosity by the
stellar luminosity. We classify the objects into flared (Group I) or flat
(Group II) disks and find that there is no trend with accretion luminosity or
rate, indicating that the disk dust structure is not impacting accretion. We
test for Br$\gamma$ variability in objects that are common to our sample and
previous studies. We find that the Br$\gamma$ line equivalent width is largely
consistent between the literature observations and those that we present here,
except in a few cases where we may be seeing changes in the accretion rate.",http://arxiv.org/abs/2112.10428v2
Comments on the Aharonov-Bohm Effect,2021-12-21T13:09:07Z,"Kazuyasu Shigemoto, Kunihiko Uehara","In the original setting of the Aharonov-Bohm, the gauge invariant physical
longitudinal mode of the vector potential, which is written by the gauge
invariant physical current $(-e)\bar{\psi}{\boldsymbol \gamma} \psi$, gives the
desired contribution to the Aharonov-Bohm effect. While the scalar mode of the
vector potential, which changes under the gauge transformation so that it is
the unphysical mode, give no contribution to the Aharonov-Bohm effect. Then
Aharonov-Bohm effect really occurs by the physical longitudinal mode in the
original Aharonov-Bohm's setting. In the setting of Tonomura {\it et al.},
where the magnet is shielded with the superconducting material, not only the
magnetic field but also the longitudinal mode of the vector potential become
massive by the Meissner effect. Then not only the magnetic field but also the
physical longitudinal mode does not come out to the region where the electron
travels. In such setting, only the scalar mode of the vector potential exists
in the region where the electron travels, but there is no contribution to the
Aharonov-Bohm effect from that mode. Then, theoretically, the Aharonov-Bohm
effect does not occur in the Tonomura {\it et al.}'s setting. In the quantum
theory, the electron is treated as the wave, and the longitudinal mode give the
change of the phase, which gives the Aharonov-Bohm effect. In the classical
theory, the electron is treated as the particle, and the only existing
longitudinal mode gives the change of the angular momentum. For the particle,
there is no concept of the phase, so that there is no Aharonov-Bohm effect.",http://arxiv.org/abs/2112.11171v2
Dynamical impact of the Mekong River plume in the South China Sea,2021-12-21T14:27:14Z,"Xiyuan Zeng, Annalisa Bracco, Filippos Tagklis","Near the ocean surface, river plumes influence stratification, buoyancy and
transport of tracers, nutrients and pollutants. The extent to which river
plumes influence the overall circulation, however, is generally poorly
constrained. This work focuses on the South China Sea (SCS) and quantifies the
dynamical impacts of the Mekong River plume, which is bound to significantly
change in strength and seasonality in the next 20 years if the construction of
over hundred dams moves ahead as planned. The dynamic impact of the freshwater
fluxes on the SCS circulation are quantified by comparing submesoscale
permitting and mesoscale resolving simulations with and without riverine input
between 2011 and 2016. In the summer and early fall, when the Mekong discharge
is at its peak, the greater stratification causes a residual mesoscale
circulation through enhanced baroclinic instability. The residual circulation
is shaped as an eddy train of positive and negative vorticity. Submesoscale
fronts are responsible for transporting the freshwater offshore, shifting
eastward the development of the residual mesoscale circulation, and further
strengthening the residual eddy train in the submesoscale permitting case.
Overall, the northward transport near the surface is intensified in the
presence of riverine input. The significance of the mesoscale-induced and
submesoscale-induced transport associated with the river plume is especially
important in in the second half of the summer monsoon season, when primary
productivity has a secondary maximum. Circulation changes, and therefore
productivity changes, should be anticipated if human activities modify the
intensity and seasonality of the Mekong River plume.",http://arxiv.org/abs/2112.11252v1
Ab initio investigation of H-bond disordering in $δ$-AlOOH,2021-12-21T17:18:37Z,"Chenxing Luo, Koichiro Umemoto, Renata M. Wentzcovitch","$\delta$-AlOOH ($\delta$) is a high-pressure hydrous phase that participates
in the deep geological water cycle. At 0 GPa, $\delta$ has asymmetric hydrogen
bonds (H-bonds). Under pressure, it exhibits H-bond disordering, tunneling, and
finally, H-bond symmetrization at ~18 GPa. This study investigates these 300 K
pressure-induced state changes in $\delta$ with ab initio calculations. H-bond
disordering in $\delta$ was modeled using supercell multi-configuration
quasiharmonic calculations. We examine: (a) energy barriers for proton jumps,
(b) the pressure dependence of phonon frequencies, (c) 300 K compressibility,
(d) neutron diffraction pattern anomalies, and (e) compare ab initio bond
lengths with measured ones. Such thorough and systematic comparisons indicate
that: (a) proton ""disorder"" has a restricted meaning when applied to $\delta$.
Nevertheless, H-bonds are disordered between 0 and 8 GPa, and a gradual change
in H-bond configuration results in enhanced compressibility. (b) several
structural and vibrational anomalies at ~8 GPa are consistent with the
disappearance of a particular (HOC-12) H-bond configuration and its change into
another one (HOC-11*). (c) between 8-11 GPa, H-bond configuration (HOC-11*) is
generally ordered, at least in short- to mid-range scale. (d) between 11.5-18
GPa, H-bond lengths approach a critical value that impedes compression,
resulting in decreased compressibility. In this pressure range, especially
approaching H-bond symmetrization at ~18 GPa, anharmonicity and tunneling
should play an essential role in the proton dynamics. Further simulations
accounting for these effects are desirable to clarify the protons' state in
this pressure range.",http://arxiv.org/abs/2112.11369v4
"The differences between mass- and light-derived structural parameters
  over time for MaNGA Elliptical galaxies",2021-12-23T19:01:18Z,"H. Ibarra-Medel, V. Avila-Reese, I. Lacerna, A. Rodríguez-Puebla, J. A. Vázquez-Mata, H. M. Hernández-Toledo, S. F. Sánchez","We apply stellar population synthesis analysis to obtain spatially-resolved
archaeological inferences for a large sample of ""red and dead"" Elliptical
galaxies (Classical Ellipticals; CLEs) from the MaNGA/SDSS-IV DR15 survey. From
their 2D stellar light and mass maps, we explore the differences between the
radial mass and light distributions in the rest-frame bands $g,$ $r,$ and $i$
as functions of look-back time, $t_{\rm lb}$, or redshift, $z$. We characterize
these differences through the ratios between the following mass- and
light-derived global properties: sizes, concentrations, and effective surface
densities. We find that the mass-to-light ratios of these properties change
with $t_{\rm lb}$, more the more massive the galaxies are. The CLE galaxy
archaeological progenitors are, on average, less compact, concentrated, and
dense in light than in mass as $z$ decreases. However, at later times, when
also the evolution of the progenitors becomes passive at all radii, there is an
upturn in these trends and the differences between mass and light in
compactness/concentration decrease towards $z\sim 0$. The trends in the ratios
of mass to light sizes agree qualitatively with results from direct
observations in galaxy surveys at different redshifts. We discuss the caveats
and interpretations of our results, and speculate that the strong structural
evolution found in some previous studies for early-type galaxies could be
explained partially by photometric changes rather than by intrinsic structural
changes.",http://arxiv.org/abs/2112.12799v1
Stress-tailoring magnetic anisotropy of V$_2$O$_3$/Ni bilayers,2021-12-23T20:21:45Z,"Christian T. Wolowiec, Juan Gabriel Ramírez, Min-Han Lee, Nicolas M. Vargas, Ali C. Basaran, Pavel Salev, Ivan K. Schuller","We report on a temperature-driven reversible change of the in-plane magnetic
anisotropy of V$_2$O$_3$/Ni bilayers. This is caused by the rhombohedral to
monoclinic structural phase transition of V$_2$O$_3$ at $T_C$ = 160 K. The
in-plane magnetic anisotropy is uniaxial above $T_C$, but as the bilayer is
cooled through the structural phase transition, a secondary magnetic easy axis
emerges. Ferromagnetic resonance measurements show that this change in magnetic
anisotropy is reversible with temperature. We identify two structural
properties of the V$_2$O$_3$/Ni bilayers affecting the in-plane magnetic
anisotropy: (1) a growth-induced uniaxial magnetic anisotropy associated with
step-like terraces in the bilayer microstructure and (2) a low-temperature
strain-induced biaxial anisotropy associated with the V$_2$O$_3$ structural
phase transition. Magnetoresistance measurements corroborate the change in
magnetic anisotropy across the structural transition and suggest that the
negative magnetostriction of Ni leads to the emergence of a strain-induced
easy-axis. This shows that a temperature-dependent structural transition in
V$_2$O$_3$ may be used to tune the magnetic anisotropy in an adjacent
ferromagnetic thin film.",http://arxiv.org/abs/2112.12826v1
"Pressure induced emission enhancement and bandgap narrowing:
  experimental investigations and first principles theoretical simulations on a
  model halide perovskite",2021-12-24T15:25:38Z,"Debabrata Samanta, Sonu Pratap Chaudhary, Bishnupada Ghosh, Sayan Bhattacharyya, Gaurav Shukla, Goutam Dev Mukherjee","We report high-pressure photoluminescence, Raman scattering, and x-ray
diffraction measurements on a lead-free halide perovskite $Cs_3Sb_2Br_9$. At
about 3 GPa, an electronic transition manifests itself through a broad minimum
in linewidth, a maximum in the intensity of $E_g$, $A_{1g}$ Raman modes, and
the unusual change in the $c/a$ ratio of the trigonal lattice. The large
compressibility and observed Raman anomalies indicate to a soft material with
strong electron-phonon coupling. The observed below bandgap broadband emission
in the photoluminescence measurement indicates the recombination of
self-trapped excitons. The initial blueshift of the photoluminescence peak
reinforces itself to the redshift at around 3 GPa due to the change in the
electronic landscape. A first order trigonal to a monoclinic structural
transition is also seen at 8 GPa. The first-principles density functional
theory (DFT) calculations reveal that the electronic transition is associated
with direct-to-indirect bandgap transition due to changes in the hybridization
of $Sb-5s$ and $Br-4p$ orbitals near the Fermi level in the valence band. The
experimentally observed Raman modes are assigned to their symmetry using the
density functional perturbation theory. In addition, the DFT calculations
predict a 27.5\% reduction of the bandgap in the pressure range 0-8 GPa.",http://arxiv.org/abs/2112.13086v1
"Optimal shape of STIRAP pulses for large dissipation at the intermediate
  level",2021-12-27T11:52:06Z,"Dionisis Stefanatos, Emmanuel Paspalakis","We study the problem of maximizing population transfer efficiency in the
STIRAP system for the case where the dissipation rate of the intermediate state
is much higher than the maximum amplitude of the control fields. Under this
assumption, the original three-level system can be reduced to a couple of
equations involving the initial and target states only. We find the control
fields which maximize the population transfer to the target state for a given
duration $T$, without using any penalty involving the population of the lossy
intermediate state, but under the constraint that the sum of the intensities of
the pump and Stokes pulses is constant, so the total field has constant
amplitude and the only control parameter is the mixing angle of the two fields.
In the optimal solution the mixing angle changes in the bang-singular-bang
manner, where the initial and final bangs correspond to equal instantaneous
rotations, while the intermediate singular arc to a linear change with time. We
show that the optimal angle of the initial and final rotations is the unique
solution of a transcendental equation where duration $T$ appears as a
parameter, while the optimal slope of the intermediate linear change as well as
the optimal transfer efficiency are expressed as functions of this optimal
angle. The corresponding optimal solution recovers the counterintuitive
pulse-sequence, with nonzero pump and Stokes fields at the boundaries. We also
show with numerical simulations that, transfer efficiency values close to the
optimal derived using the approximate system, can also be obtained with the
original STIRAP system using dissipation rates comparable to the maximum
control amplitude.",http://arxiv.org/abs/2112.13620v1
"Economics of Innovation and Perceptions of Renewed Education and
  Curriculum Design in Bangladesh",2021-12-23T23:14:00Z,"Shifa Taslim Chowdhury, Mohammad Nur Nobi, Anm Moinul Islam","The creative Education system is one of the effective education systems in
many countries like Finland, Denmark, and South Korea. Bangladesh Government
has also launched the creative curriculum system in 2009 in both primary and
secondary levels, where changes have been made in educational contents and exam
question patterns. These changes in the previous curriculum aimed to avoid
memorization and less creativity and increase the students' level of
understanding and critical thinking. Though the Government has taken these
steps, the quality of the educational system in Bangladesh is still
deteriorating. Since the curriculum has been changed recently, this policy
issue got massive attention of the people because the problem of a substandard
education system has arisen. Many students have poor performances in
examinations, including entrance hall exams in universities and board
examinations. This deteriorating situation is mostly for leakage of question
paper, inadequate equipment and materials, and insufficient training. As a
result, the existing education system has failed to provide the standard level
of education. This research will discuss and find why this creative educational
system is getting impacted by these factors. It will be qualitative research. A
systematic questionnaire will interview different school teachers, parents,
experts, and students.",http://arxiv.org/abs/2112.13842v1
Control of dynamic systems with restrictions on input and output signals,2021-12-28T12:49:18Z,"Igor Furtat, Pavel Gushchin, Nguyen Ba Huy","The paper considers the generalization of the method proposed by I.B. Furtat,
P.A. Gushchin in ""Automation and Remote Control"", 2021, No. 4 for systems with
an arbitrary ratio of the number of input and output signals and with a
guarantee of their being in a given set. To solve the problem, two coordinate
changes are proposed. The first coordinate change reduces the output variable
of the system to a new variable which dimension does not exceed the control
dimension. The second coordinate change allows one to pass from a constrained
control problem to an unconstrained one. In order to illustrate the efficiency
of the method, the solution of two problems is considered. The first task is
state feedback control of linear systems, taking into account the constraints
on the control signal and phase variables. The second task is output feedback
control of linear systems with a restriction on output and control. In both
problems, checking the stability of the closed-loop system is formulated in
terms of the solvability of linear matrix inequalities. The obtained results
are accompanied by examples of modeling that illustrate the efficiency of the
proposed method.",http://arxiv.org/abs/2112.14123v2
Skin feature point tracking using deep feature encodings,2021-12-28T14:29:08Z,"Jose Ramon Chang, Torbjörn E. M. Nordling","Facial feature tracking is a key component of imaging ballistocardiography
(BCG) where accurate quantification of the displacement of facial keypoints is
needed for good heart rate estimation. Skin feature tracking enables
video-based quantification of motor degradation in Parkinson's disease.
Traditional computer vision algorithms include Scale Invariant Feature
Transform (SIFT), Speeded-Up Robust Features (SURF), and Lucas-Kanade method
(LK). These have long represented the state-of-the-art in efficiency and
accuracy but fail when common deformations, like affine local transformations
or illumination changes, are present.
  Over the past five years, deep convolutional neural networks have
outperformed traditional methods for most computer vision tasks. We propose a
pipeline for feature tracking, that applies a convolutional stacked autoencoder
to identify the most similar crop in an image to a reference crop containing
the feature of interest. The autoencoder learns to represent image crops into
deep feature encodings specific to the object category it is trained on.
  We train the autoencoder on facial images and validate its ability to track
skin features in general using manually labeled face and hand videos. The
tracking errors of distinctive skin features (moles) are so small that we
cannot exclude that they stem from the manual labelling based on a
$\chi^2$-test. With a mean error of 0.6-4.2 pixels, our method outperformed the
other methods in all but one scenario. More importantly, our method was the
only one to not diverge.
  We conclude that our method creates better feature descriptors for feature
tracking, feature matching, and image registration than the traditional
algorithms.",http://arxiv.org/abs/2112.14159v2
Can varying the gravitational constant alleviate the tensions ?,2021-12-28T15:02:15Z,"Ziad Sakr, Domenico Sapone","Constraints on the cosmological concordance model parameters from observables
at different redshifts are usually obtained using the locally measured value of
the gravitational constant $G_N$. Here we relax this assumption, by considering
$G$ as a free parameter, either constant over the redshift range or dynamical
but limited to differ from fiducial value only above a certain redshift. Using
CMB data and distance measurements from galaxy clustering BAO feature, we
constrain the cosmological parameters, along with $G$, through a MCMC bayesian
inference method. Furthermore, we investigate whether the tensions on the
matter fluctuation $\sigma_8$ and Hubble $H_0$ parameter could be alleviated by
this new variable. We used different parameterisations spanning from a constant
$G$ to a dynamical $G$. In all the cases investigated in this work we found no
mechanism that alleviates the tensions when both CMB and BAO data are used with
$\xi_{\mathrm{g}} = G / G_N$ constrained to 1.0$\pm0.04$ (resp. $\pm0.01$) in
the constant (resp. dynamical) case. Finally, we studied the cosmological
consequences of allowing a running of the spectral index, since the later is
sensitive to a change in $G$. For the two parameterisations adopted, we found
no significant changes to the previous conclusions.",http://arxiv.org/abs/2112.14173v2
Quantum tunneling in the presence of a topology-changing fermionic bath,2021-12-28T19:39:58Z,"Elis Roberts, Jan Behrends, Benjamin Béri","Coupling a quantum particle to a fermionic bath suppresses the particle's
amplitude to tunnel, even at zero temperature. While this effect can generally
be neglected for gapped baths -- a key feature for superconducting qubits -- ,
it is possible for the bath to be gapped near the potential minima between
which the particle tunnels, but different minima to correspond to different
bath topologies. This enforces the bath to undergo gap closing along the
tunneling path. In this work, we investigate quantum tunneling in the presence
of such a topology-changing fermionic bath. We develop a field theory for this
problem, linking the instantons describing tunneling in a bath of $d$ space
dimensions to topological boundary modes of systems in $d+1$ dimensions, thus
stepping a level higher in a dimensional hierarchy. We study in detail a $d=1$
example, inspired by planar Josephson junctions where the particle coordinate
is the superconducting phase whose value sets the electronic topology. We find
that the topology change suppresses tunneling by a factor scaling exponentially
with the system size. This translates to a correspondingly enhanced suppression
of the energy splitting for the lowest-lying states, despite these being linear
combinations of states near potential minima where the bath is gapped. Our
results help to estimate the influence of charging energy on topological phases
arising due to the Josephson effect and, conversely, to assess the potential
utility of such topological systems as superconducting qubits. For
moderate-sized baths, the incomplete suppression of tunneling opens the
prospects of quantum-mechanical superpositions of many-body states of different
topology, including superpositions of states with and without Majorana
fermions.",http://arxiv.org/abs/2112.14280v1
"Technology, Institution, and Regional Growth: Evidence from Mineral
  Mining Industry in Industrializing Japan",2021-12-29T11:47:08Z,Kota Ogasawara,"Coal extraction was an influential economic activity in interwar Japan.
Initially, coal mines employed both males and females as the workforce in the
pits. However, the innovation of labor-saving technologies and the renewal of
traditional extraction methodology induced institutional change. This was
manifested by the revision of labor regulations affecting female miners in the
early 1930s. This dramatically changed the mining workplace, making skilled
males the principal miners engaged in underground work. This paper investigates
the impact of coal mining on regional growth and assesses how the institutional
changes induced by the amended labor regulations affected its processes. By
linking the mines' location information with both registration and census-based
statistics, it was found that coal mines led to remarkable population growth.
Fertility rate increased following the implementation of labor regulations that
required female miners to leave the workforce and start families. The
regulations prohibited female miners from risky underground work. This
reduction in occupational hazard also improved early-life mortality via the
mortality selection mechanism in utero.",http://arxiv.org/abs/2112.14514v15
"Non-uniform magnetization profile in ferromagnetic heterostructures
  leading to topological Hall effect like signatures",2021-12-30T11:49:14Z,"Nandana Bhattacharya, S. Middey","Anomalous Hall effect (AHE), which arises when a current is passed through a
ferromagnetic material subjected to a perpendicular magnetic field, is
proportional to the magnetization of the sample.Additional hump-like features
in AHE are often attributed to the presence of non trivial spin textures
leading to topological Hall effect (THE). However, several recent reports have
emphasized in context of ferromagnetic SrRuO$_3$ based heterostructures that
the sample inhomogeneity can also result in THE-like features. In order to
investigate this issue in general for any ferromagnetic heterostructure, we
have considered a phenomenological model to calculate the changes in the shape
of hysteresis loop due to various interfacial effects. These changes in the
magnetization have been accounted for by considering that the interdomain
magnetic coupling parameter ($\alpha$) varies exponentially with the distance
from the interface along the growth direction of the heterostructure. In case
of symmetric interfaces on both sides of a ferromagnet, we have considered the
variation of $\alpha$ as a Gaussian function. We have found that the additional
AHE contribution due to the net change in magnetization in such cases are akin
to experimentally observed THE, even though we have not considered any
topological quantity explicitly in our model. Thus, we propose another
situation with nonuniform magnetization profile that may be used to explain
additional features in AHE, which might not necessarily be intrinsic THE.",http://arxiv.org/abs/2112.15020v1
"Power Under Multiplicity Project (PUMP): Estimating Power, Minimum
  Detectable Effect Size, and Sample Size When Adjusting for Multiple Outcomes
  in Multi-level Experiments",2021-12-31T02:50:42Z,"Kristen Hunter, Luke Miratrix, Kristin Porter","For randomized controlled trials (RCTs) with a single intervention being
measured on multiple outcomes, researchers often apply a multiple testing
procedure (such as Bonferroni or Benjamini-Hochberg) to adjust $p$-values. Such
an adjustment reduces the likelihood of spurious findings, but also changes the
statistical power, sometimes substantially, which reduces the probability of
detecting effects when they do exist. However, this consideration is frequently
ignored in typical power analyses, as existing tools do not easily accommodate
the use of multiple testing procedures. We introduce the PUMP R package as a
tool for analysts to estimate statistical power, minimum detectable effect
size, and sample size requirements for multi-level RCTs with multiple outcomes.
Multiple outcomes are accounted for in two ways. First, power estimates from
PUMP properly account for the adjustment in $p$-values from applying a multiple
testing procedure. Second, as researchers change their focus from one outcome
to multiple outcomes, different definitions of statistical power emerge. PUMP
allows researchers to consider a variety of definitions of power, as some may
be more appropriate for the goals of their study. The package estimates power
for frequentist multi-level mixed effects models, and supports a variety of
commonly-used RCT designs and models and multiple testing procedures. In
addition to the main functionality of estimating power, minimum detectable
effect size, and sample size requirements, the package allows the user to
easily explore sensitivity of these quantities to changes in underlying
assumptions.",http://arxiv.org/abs/2112.15273v3
T-Plots: A Novel Approach to Network Design,2021-12-09T11:17:34Z,Itamar Cohen,"It is accepted wisdom that changes in the traffic matrix entail capacity
over-provisioning, but there is no simple measure of just how much
over-provisioning can buy. In this Thesis, we aim to provide the network
designer with a simple view of the network robustness to traffic matrix
changes. We first present the Traffic Load Distribution Plots, or T-Plots, a
class of plots illustrating the percentage of traffic matrices that can be
serviced as a function of the capacity over-provisioning. For instance, from a
simple look at their T- Plots, network designers can guarantee that their
network services all admissible traffic matrices, or 99% of permutation traffic
matrices, or all traffic matrices with ingress/egress load at most half the
maximum. We further show that, unfortunately, in the general case plotting
T-Plots is #P-Complete, i.e., that it is impossible to plot a T-plot in a
polynomial time by the noon tools. However, we show that T-Plots can sometimes
be closely modeled as Gaussian, thus only using two values (mean and variance)
to quantify the robustness of a capacity allocation to traffic matrix changes.
We further utilize these Gaussian T-Plots to provide a more robust capacity
allocation. Finally, we demonstrate the benefits of using T-Plots by showing
results of extensive Monte Carlo simulations in a real backbone network. This
Thesis was submitted in 2007. Since then, the results that appeared in it were
applied in various networking environments. In this newer version, we revisit
the results 13 years later and explain their relevance to state-of-the-art
problems in network design.",http://arxiv.org/abs/2202.03157v1
Trace formulas for the modified Mathieu equation,2021-02-26T20:13:31Z,Leon A. Takhtajan,"For the radial and one-dimensional Schr\""{o}dinger operator $H$ with growing
potential $q(x)$ we outline a method of obtaining the trace identities - an
asymptotic expansion of the Fredholm determinant $\mathrm{det}_{F}(H-\lambda
I)$ as $\lambda\to-\infty$. As an illustrating example, we consider
Schr\""{o}dinger operator with the potential $q(x)=2\cosh 2x$, associated with
the modified Mathieu equation.",http://arxiv.org/abs/2103.00038v2
$d$-balanced squeezing function,2021-02-28T14:46:16Z,"Naveen Gupta, Sanjay Kumar Pant","We introduce the notion of squeezing function corresponding to $d$-balanced
domains motivated by the concept of generalized squeezing function given by
Rong and Yang. In this work we study some of its properties and its relation
with Fridman invariant.",http://arxiv.org/abs/2103.00526v2
Burkholder inequality by Bregman divergence,2021-03-10T22:02:16Z,"Krzysztof Bogdan, Mateusz Więcek",We prove Burkholder inequality using Bregman divergence.,http://arxiv.org/abs/2103.06358v3
"Piecewise linear processes with Poisson-modulated exponential switching
  times",2021-03-11T14:13:22Z,"Antonio Di Crescenzo, Barbara Martinucci, Nikita Ratanov","We consider the jump telegraph process when switching intensities depend on
external shocks also accompanying with jumps. The incomplete financial market
model based on this process is studied. The Esscher transform, which changes
only unobservable parameters, is considered in detail. The financial market
model based on this transform can price switching risks as well as jump risks
of the model.",http://arxiv.org/abs/2103.06680v2
"Curved holographic optical elements from a geometric view point:
  graphical visualization and parametric optimization",2021-03-15T13:26:35Z,"Tobias Graf, Dominik Hayd","We present numerical experiments regarding the diffraction characteristics
and their precompensation arising from changing the macroscopic geometry of a
flat HOE into a sphere segment. In particular, we discuss a parametric
optimization scheme using a grating vector field model which was previously
introduced in Ref. 1.",http://arxiv.org/abs/2103.08375v1
On a recolouring version of Hadwiger's conjecture,2021-03-19T08:33:45Z,"Marthe Bonamy, Marc Heinrich, Clément Legrand-Duchesne, Jonathan Narboni","We prove that for any $\varepsilon>0$, for any large enough $t$, there is a
graph $G$ that admits no $K_t$-minor but admits a
$(\frac32-\varepsilon)t$-colouring that is ""frozen"" with respect to Kempe
changes, i.e. any two colour classes induce a connected component. This
disproves three conjectures of Las Vergnas and Meyniel from 1981.",http://arxiv.org/abs/2103.10684v1
"An optical overview of blazars with LAMOST I: Hunting changing-look
  blazars and new redshift estimates",2021-03-19T15:34:52Z,"Harold A. Peña-Herazo, Francesco Massaro, Minfeng Gu, Alessandro Paggi, Marco Landoni, Raffaele D'Abrusco, Federica Ricci, Nicola Masetti, Vahram Chavushyan","The extragalactic $\gamma$-rays sky observed by Fermi-Large Area Telescope
(LAT) is dominated by blazars. In the fourth release of the Fermi-LAT Point
Source Catalog (4FGL), are sources showing a multifrequency behavior similar to
that of blazars but lacking an optical spectroscopic confirmation of their
nature known as Blazar Candidate of Uncertain type (BCUs). We aim at confirming
the blazar nature of BCUs and test if new optical spectroscopic observations
can reveal spectral features, allowing us to get a redshift estimate for known
BL Lac objects. We also aim to search for and discover changing-look blazars
(i.e., blazars that show a different classification at different epochs). We
carried out an extensive search for optical spectra available in the Large Sky
Area Multi-Object Fibre Spectroscopic Telescope (LAMOST) Data Release 5 (DR5)
archive. We selected sources out of the 4FGL catalog, the list of targets from
our follow-up spectroscopic campaign of unidentified or unassociated
$\gamma$-ray sources, and the multifrequency catalog of blazars: the
Roma-BZCAT. We selected a total of 392 spectra. We also compare some of the
LAMOST spectra with those available in the literature. We classified 20 BCUs
confirming their blazar-like nature. Then we obtained 15 new redshift estimates
for known blazars. We discovered 26 transitional (i.e., changing-look) blazars
that changed their classification. Finally, we were able to confirm the
blazar-like nature of six BL Lac candidates. All remaining sources analyzed
agree with previous classifications. BL Lac objects are certainly the most
elusive type of blazars in the $\gamma$-ray extragalactic sky.",http://arxiv.org/abs/2103.10861v1
Asymptotic syzygies of secant varieties of curves,2021-03-19T16:03:46Z,Gregory Taylor,"We prove that the minimal free resolution of the secant variety of a curve is
asymptotically pure. As a corollary, we show that the Betti numbers of converge
to a normal distribution.",http://arxiv.org/abs/2103.10879v2
Deciding Stability of Sheaves on Curves,2021-03-23T12:37:56Z,"Holger Brenner, Jonathan Steinbuch","We give an algorithm to determine whether a kernel sheaf over a smooth
projective curve over an algebraically closed field is semistable. The
algorithm uses symmetric powers to make destabilizing subbundles visible as
global sections.",http://arxiv.org/abs/2103.12493v2
"Jupiter's third largest and longest-lived oval: Color changes and
  dynamics",2021-03-24T13:14:26Z,"N. Barrado-Izagirre, J. Legarreta, A. Sánchez-Lavega, S. Pérez-Hoyos, R. Hueso, P. Iñurrigarro, J. F. Rojas, I. Mendikoa, I. Ordoñez-Etxeberria, the IOPW Team","The transition region between the North Equatorial Band (NEBn) and North
Tropical Zone (NTrZ) in Jupiter is home to convective storms, systems of
cyclones and anticyclones and atmospheric waves. A large anticyclone formed in
the year 2006 at planetographic latitude 19N and persists since then after a
complex dynamic history, being possibly the third longest-lived oval in the
planet after Jupiter's Great Red Spot and oval BA. This anticyclone has
experienced close interactions with other ovals, merging with another oval in
February 2013; it has also experienced color changes, from white to red
(September 2013). The oval survived the effects of the closely located North
Temperate Belt Disturbance, which occurred in October 2016 and fully covered
the oval, rendering it unobservable for a short time. When it became visible
again at its expected longitude from its previous longitudinal track, it
reappeared as a white large oval keeping this color and the same morphology
since 2017 at least until the onset of the new convective disturbance in
Jupiter's North Temperate Belt in August 2020. Here we describe the historic
evolution of the properties of this oval. We use JunoCam and Hubble Space
Telescope (HST) images to measure its size and its internal rotation. We also
used HST and PlanetCam-UPV/EHU multi-wavelength observations to characterize
its color changes and Junocam images to unveil its detailed structure. The
color and the altitude-opacity indices show that the oval is higher and has
redder clouds than its environment but has lower cloud tops than other large
ovals like the GRS, and it is less red than the GRS and oval BA. We show that
in spite of the dramatic environmental changes suffered by the oval during all
these years, its main characteristics are stable in time and therefore must be
related with the atmospheric dynamics below the observable cloud decks.",http://arxiv.org/abs/2103.13168v1
"Photoionisation Modelling of the X-ray Emission Line Regions within the
  Seyfert 2 AGN NGC 1068",2021-03-24T17:49:17Z,"S. Grafton-Waters, G. Branduardi-Raymont, M. Mehdipour, M. Page, S. Bianchi, E. Behar, M. Symeonidis","We investigate the photoionised X-ray emission line regions (ELRs) within the
Seyfert 2 galaxy NGC 1068, to determine if there are any characteristic changes
between observations taken fourteen years apart. We compare XMM-Newton
observations collected in 2000 and 2014, simultaneously fitting the reflection
grating spectrometer (RGS) and EPIC-pn spectra of each epoch, for the first
time, with the photoionisation model, PION, in SPEX. We find that four PION
components are required to fit the majority of the emission lines in the
spectra of NGC 1068, with $\log \xi=1-4$, $\log N_H>26 m^{-2}$, and
$v_{out}=-100$ to $-600 kms^{-1}$ for both epochs. Comparing the ionisation
state of the components shows almost no difference between the two epochs,
while there is an increase in the total column density. To estimate the
locations of these plasma regions from the central black hole we compare
distance methods, excluding the variability arguments as there is no spectral
change between observations. Although the methods are unable to constrain the
distances, the locations are consistent with the narrow line region, with the
possibility of the higher ionised component being part of the broad line
region, but we cannot conclude this for certain. In addition, we find evidence
for emission from collisionally ionised plasma, while previous analysis had
suggested that collisional plasma emission was unlikely. However, although PION
is unable to account for the FeXVII emission lines at 15 and 17 \AA, we do not
rule out that photoexcitation is a valid processes to produce these lines too.
NGC 1068 has not changed, both in terms of the observed spectra or from our
modelling, within the 14 year time period between observations. This suggests
that the ELRs are fairly static relative to the 14 year time frame between
observations, or there is no dramatic change in the black hole variability.",http://arxiv.org/abs/2103.13374v2
"Codes, Vertex Operators and Topological Modular Forms",2021-03-25T07:14:22Z,"Nora Ganter, Gerd Laures","We describe a new link between the theory of topological modular forms and
representations of vertex operator algebras obtained by certain lattices. The
construction is motivated by the arithmetic Whitehead tower of the orthogonal
groups. The tower discloses the role of codes in representation theory.",http://arxiv.org/abs/2103.13636v2
"Nodal solutions of fourth-order Kirchhoff equations with critical growth
  in $\mathbb{R}^N$",2021-03-25T20:13:08Z,"Hongling Pu, Shiqi Li, Sihua Liang, Dušan D. Repovš","We consider a class of fourth-order elliptic equations of Kirchhoff type with
critical growth in $\mathbb{R}^N$. By using constrained minimization in the
Nehari manifold, we establish sufficient conditions for the existence of nodal
(that is, sign-changing) solutions.",http://arxiv.org/abs/2103.14114v1
"Realizing arbitrary $d$-dimensional dynamics by renormalization of
  $C^d$-perturbations of identity",2021-03-29T11:59:16Z,"Bassam Fayad, Maria Saprykina","Any $C^d$ conservative map $f$ of the $d$-dimensional unit ball $\mathbb B^d$
can be realized by renormalized iteration of a $C^d$ perturbation of identity:
there exists a conservative diffeomorphism of $\mathbb B^d$, arbitrarily close
to identity in the $C^d$ topology, that has a periodic disc on which the return
dynamics after a $C^d$ change of coordinates is exactly $f$.",http://arxiv.org/abs/2103.15530v1
"Cloth-Changing Person Re-identification from A Single Image with Gait
  Prediction and Regularization",2021-03-29T12:10:50Z,"Xin Jin, Tianyu He, Kecheng Zheng, Zhiheng Yin, Xu Shen, Zhen Huang, Ruoyu Feng, Jianqiang Huang, Xian-Sheng Hua, Zhibo Chen","Cloth-Changing person re-identification (CC-ReID) aims at matching the same
person across different locations over a long-duration, e.g., over days, and
therefore inevitably meets challenge of changing clothing. In this paper, we
focus on handling well the CC-ReID problem under a more challenging setting,
i.e., just from a single image, which enables high-efficiency and latency-free
pedestrian identify for real-time surveillance applications. Specifically, we
introduce Gait recognition as an auxiliary task to drive the Image ReID model
to learn cloth-agnostic representations by leveraging personal unique and
cloth-independent gait information, we name this framework as GI-ReID. GI-ReID
adopts a two-stream architecture that consists of a image ReID-Stream and an
auxiliary gait recognition stream (Gait-Stream). The Gait-Stream, that is
discarded in the inference for high computational efficiency, acts as a
regulator to encourage the ReID-Stream to capture cloth-invariant biometric
motion features during the training. To get temporal continuous motion cues
from a single image, we design a Gait Sequence Prediction (GSP) module for
Gait-Stream to enrich gait information. Finally, a high-level semantics
consistency over two streams is enforced for effective knowledge
regularization. Experiments on multiple image-based Cloth-Changing ReID
benchmarks, e.g., LTCC, PRCC, Real28, and VC-Clothes, demonstrate that GI-ReID
performs favorably against the state-of-the-arts. Codes are available at
https://github.com/jinx-USTC/GI-ReID.",http://arxiv.org/abs/2103.15537v4
Towards proteinoid computers,2021-06-02T01:35:13Z,Andrew Adamatzky,"Proteinoids -- thermal proteins -- are produced by heating amino acids to
their melting point and initiation of polymerisation to produce polymeric
chains. Proteinoids swell in aqueous solution into hollow microspheres. The
proteinoid microspheres produce endogenous burst of electrical potential spikes
and change patterns of their electrical activity in response to illumination.
The microspheres can interconnect by pores and tubes and form networks with a
programmable growth. We speculate on how ensembles of the proteinoid
microspheres can be developed into unconventional computing devices.",http://arxiv.org/abs/2106.00883v1
Lieb type convexity for positive operator monotone decreasing functions,2021-06-02T11:56:41Z,"Hans Henrich Neumann, Makoto Yamashita","We prove Lieb type convexity and concavity results for trace functionals
associated with positive operator monotone (decreasing) functions and certain
monotone concave functions. This gives a partial generalization of Hiai's
recent work on trace functionals associated with power functions.",http://arxiv.org/abs/2106.01095v2
Introduction to Cluster Algebras. Chapter 7,2021-06-03T22:29:27Z,"Sergey Fomin, Lauren Williams, Andrei Zelevinsky","This is a preliminary draft of Chapter 7 of our forthcoming textbook
""Introduction to Cluster Algebras."" Chapters 1-3 have been posted as
arXiv:1608.05735. Chapters 4-5 have been posted as arXiv:1707.07190. Chapter 6
has been posted as arXiv:2008.09189.
  This installment contains:
  Chapter 7. Plabic graphs",http://arxiv.org/abs/2106.02160v2
Quasistatic limit of a dynamic viscoelastic model with memory,2021-06-07T12:13:41Z,"Gianni Dal Maso, Francesco Sapio","We study the behaviour of the solutions to a dynamic evolution problem for a
viscoelastic model with long memory, when the rate of change of the data tends
to zero. We prove that a suitably rescaled version of the solutions converges
to the solution of the corresponding stationary problem.",http://arxiv.org/abs/2106.03543v2
"Searching for changing-state AGNs in massive datasets -- I: applying
  deep learning and anomaly detection techniques to find AGNs with anomalous
  variability behaviours",2021-06-14T18:00:01Z,"P. Sánchez-Sáez, H. Lira, L. Martí, N. Sánchez-Pi, J. Arredondo, F. E. Bauer, A. Bayo, G. Cabrera-Vives, C. Donoso-Oliva, P. A. Estévez, S. Eyheramendy, F. Förster, L. Hernández-García, A. M. Muñoz Arancibia, M. Pérez-Carrasco, M. Sepúlveda, J. R. Vergara","The classic classification scheme for Active Galactic Nuclei (AGNs) was
recently challenged by the discovery of the so-called changing-state
(changing-look) AGNs (CSAGNs). The physical mechanism behind this phenomenon is
still a matter of open debate and the samples are too small and of
serendipitous nature to provide robust answers. In order to tackle this
problem, we need to design methods that are able to detect AGN right in the act
of changing-state. Here we present an anomaly detection (AD) technique designed
to identify AGN light curves with anomalous behaviors in massive datasets. The
main aim of this technique is to identify CSAGN at different stages of the
transition, but it can also be used for more general purposes, such as cleaning
massive datasets for AGN variability analyses. We used light curves from the
Zwicky Transient Facility data release 5 (ZTF DR5), containing a sample of
230,451 AGNs of different classes. The ZTF DR5 light curves were modeled with a
Variational Recurrent Autoencoder (VRAE) architecture, that allowed us to
obtain a set of attributes from the VRAE latent space that describes the
general behaviour of our sample. These attributes were then used as features
for an Isolation Forest (IF) algorithm, that is an anomaly detector for a ""one
class"" kind of problem. We used the VRAE reconstruction errors and the IF
anomaly score to select a sample of 8,809 anomalies. These anomalies are
dominated by bogus candidates, but we were able to identify 75 promising CSAGN
candidates.",http://arxiv.org/abs/2106.07660v2
"Role of surface termination in the metal-insulator transition of
  V$_2$O$_3$(0001) ultrathin films",2021-06-16T05:15:51Z,"Asish K. Kundu, Sukanta Barman, Krishnakumar S. R. Menon","Surface termination is known to play an important role in determining the
physical properties of materials. It is crucial to know how surface termination
affects the metal-insulator transition (MIT) of V$_2$O$_3$ films for both
fundamental understanding and its applications. By changing growth parameters,
we achieved a variety of surface terminations in V$_2$O$_3$ films that are
characterized by low energy electron diffraction (LEED) and photoemission
spectroscopy techniques. Depending upon the terminations, our results show MIT
can be partially or fully suppressed near the surface region due to the
different filling of the electrons at the surface and sub-surface layers and
change of screening length compared to the bulk. Across MIT, a strong
redistribution of spectral weight and its transfer from high-to-low binding
energy regime is observed in a wide-energy-scale. Our results show total
spectral weight in the low-energy regime is not conserved across MIT,
indicating a breakdown of `sum rules of spectral weight', a signature of a
strongly correlated system. Such change in spectral weight is possibly linked
to the change in hybridization, lattice volume ({\it i.e.,} effective carrier
density), and spin degree of freedom in the system that happens across MIT. We
find that MIT in this system is strongly correlation-driven where the
electron-electron interactions play a pivotal role. Moreover, our results
provide a better insight in understanding the electronic structure of strongly
correlated systems and highlight the importance of accounting surface effects
during interpretation of the physical property data mainly using surface
sensitive probes, such as surface resistivity.",http://arxiv.org/abs/2106.08555v1
"The spectrum and the Weyr characteristics of operator pencils and linear
  relations",2021-06-16T11:55:42Z,"Hannes Gernandt, Carsten Trunk","The relation between the spectra of operator pencils with unbounded
coefficients and of associated linear relations is investigated. It turns out
that various types of spectrum coincide and the same is true for the Weyr
characteristics. This characteristic describes how many independent Jordan
chains up to a certain length exist. Furthermore, the change of this
characteristic subject to one-dimensional perturbations is investigated.",http://arxiv.org/abs/2106.08726v1
Bernstein-Sato polynomials in commutative algebra,2021-06-16T14:45:26Z,"Josep Àlvarez Montaner, Jack Jeffries, Luis Núñez-Betancourt","This is an expository survey on the theory of Bernstein-Sato polynomials with
special emphasis in its recent developments and its importance in commutative
algebra.",http://arxiv.org/abs/2106.08830v3
On vanishing and torsion-freeness results for adjoint pairs,2021-06-22T15:54:08Z,Fanjun Meng,"We prove some vanishing and torsion-freeness results for higher direct images
of adjoint pairs satisfying relative abundance and nefness conditions. These
are applied to generic vanishing and weak positivity.",http://arxiv.org/abs/2106.11883v2
"Extended Graph 4-Manifolds, and Einstein Metrics",2021-06-24T19:04:39Z,Luca F. Di Cerbo,"We show that extended graph 4-manifolds (as defined by Frigerio-Lafont-Sisto
in [FLS15]) do not support Einstein metrics.",http://arxiv.org/abs/2106.13279v3
Anisotropic Shannon inequality,2021-06-27T10:08:27Z,"Marianna Chatzakou, Aidyn Kassymov, Michael Ruzhansky","In this note we prove the anisotropic version of the Shannon inequality. This
can be conveniently realised in the setting of Folland and Stein's homogeneous
groups. We give two proofs: one giving the best constant, and another one using
the Kubo-Ogawa-Suguro inequality.",http://arxiv.org/abs/2106.14182v2
The Eisenbud-Green-Harris Conjecture,2021-06-28T14:35:22Z,"Giulio Caviglia, Alessandro De Stefani, Enrico Sbarra","We survey most of the known results concerning the Eisenbud-Green-Harris
Conjecture. Our presentation includes new proofs of several theorems, as well
as a unified treatment of many results which are otherwise scattered in the
literature. We include a final section with some applications, and examples.",http://arxiv.org/abs/2106.14759v2
Few-Shot Domain Adaptation For End-to-End Communication,2021-08-02T13:18:40Z,"Jayaram Raghuram, Yijing Zeng, Dolores García Martí, Rafael Ruiz Ortiz, Somesh Jha, Joerg Widmer, Suman Banerjee","The problem of end-to-end learning of a communication system using an
autoencoder -- consisting of an encoder, channel, and decoder modeled using
neural networks -- has recently been shown to be an effective approach. A
challenge faced in the practical adoption of this learning approach is that
under changing channel conditions (e.g. a wireless link), it requires frequent
retraining of the autoencoder in order to maintain a low decoding error rate.
Since retraining is both time consuming and requires a large number of samples,
it becomes impractical when the channel distribution is changing quickly. We
propose to address this problem using a fast and sample-efficient (few-shot)
domain adaptation method that does not change the encoder and decoder networks.
Different from conventional training-time unsupervised or semi-supervised
domain adaptation, here we have a trained autoencoder from a source
distribution that we want to adapt (at test time) to a target distribution
using only a small labeled dataset, and no unlabeled data. We focus on a
generative channel model based on the Gaussian mixture density network (MDN),
and propose a regularized, parameter-efficient adaptation of the MDN using a
set of affine transformations. The learned affine transformations are then used
to design an optimal transformation at the decoder input to compensate for the
distribution shift, and effectively present to the decoder inputs close to the
source distribution. Experiments on many simulated distribution changes common
to the wireless setting, and a real mmWave FPGA testbed demonstrate the
effectiveness of our method at adaptation using very few target domain samples.
The code for our work can be found at:
https://github.com/jayaram-r/domain-adaptation-autoencoder.",http://arxiv.org/abs/2108.00874v3
"Practices of public procurement and the risk of corrupt behavior before
  and after the government transition in México",2021-08-04T01:34:50Z,"Andrea Falcón-Cortés, Andrés Aldana, Hernán Larralde","Corruption has a significant impact on economic growth, democracy, and
inequality. It has severe consequences at the human level are incalculable.
Public procurement, where public resources are used to purchase goods or
services from the private sector, are particularly susceptible to corrupt
practices. However, government turnover may bring significant changes in the
way public contracting is done, and thus, in the levels and types of corruption
involved in public procurement. In this respect, M\'exico lived a historical
government transition in 2018, with the new government promising a crackdown on
corruption. In this work, we analyze data from more than 1.5 million contracts
corresponding from 2013 to 2020, to study to what extent this change of
government affected the characteristics of public contracting, and we try to
determine whether these changes affect how corruption takes place. To do this,
we propose a statistical framework to compare the characteristics of the
contracting practices within each administration, separating the contracts in
different classes depending on whether or not they were made with companies
that have now been identified as being involved in corrupt practices. We find
that while the amount of resources spent with companies that turned out to be
corrupt has decreased substantially, many of the patterns followed to contract
these companies were maintained, and some of those in which changes did occur,
are suggestive of a larger risk of corruption.",http://arxiv.org/abs/2108.02653v3
Mechanical Properties of Wilberforce Pendulum,2021-08-06T15:54:04Z,S. Lee,"This paper shows the study of interesting mechanical properties of
Wilberforce pendulum. Analyzing qualitatively of the pendulum, it is able to
know how the phenomenon occurs. By setting of the quantitative model, equation
of the motion is derived. Considering the mass and moment of inertia of the
spring, the experiment was done by changing the moment of inertia as the main
parameter. The results were analyzed by defining oscillation ratio and
conversion factor.",http://arxiv.org/abs/2108.03183v1
Batched Thompson Sampling for Multi-Armed Bandits,2021-08-15T20:47:46Z,"Nikolai Karpov, Qin Zhang","We study Thompson Sampling algorithms for stochastic multi-armed bandits in
the batched setting, in which we want to minimize the regret over a sequence of
arm pulls using a small number of policy changes (or, batches). We propose two
algorithms and demonstrate their effectiveness by experiments on both synthetic
and real datasets. We also analyze the proposed algorithms from the theoretical
aspect and obtain almost tight regret-batches tradeoffs for the two-arm case.",http://arxiv.org/abs/2108.06812v1
On Construction of Hadamard Matrices,2021-08-18T13:18:53Z,"Shipra Kumari, Hrishikesh Mahato","In this article, a series of Hadamard matrix has been developed using some
block matrices with the help of skew Hadamard matrix. Basically an internal
structure of skew Hadamard matrix has been changed with some block matrices
using kronecker product. For some parameter, Hadamard matrices of order 4t
where t is an integer, has been found.",http://arxiv.org/abs/2108.08133v1
"The dual of the notions r-submodules, n-submodules, and J-submodules",2021-08-18T16:59:31Z,F. Farshadifar,"Let R be a commutative ring with identity and M be an R-module. The purpose
of this paper is to introduce and investigate the dual notions of r-submodules,
n-submodules, and J-submodules of M.",http://arxiv.org/abs/2108.08237v2
Lagrangian fibrations,2021-08-23T14:20:28Z,"Daniel Huybrechts, Mirko Mauri","We review the theory of Lagrangian fibrations of hyperk\""ahler manifolds as
initiated by Matsushita. We also discuss more recent work of Shen-Yin and
Harder-Li-Shen-Yin. Occasionally, we give alternative arguments and complement
the discussion by additional observations.",http://arxiv.org/abs/2108.10193v2
Identifying changing jets through their radio variability,2021-08-24T18:00:07Z,"I. Liodakis, T. Hovatta, M. F. Aller, H. D. Aller, M. A. Gurwell, A. Lähteenmäki, M. Tornikoski","Supermassive black holes launch highly relativistic jets with velocities
reaching Lorentz factors as high as $\Gamma>50$. How the jets accelerate to
such high velocities and where along the jet do they reach terminal velocity
are open questions that are tightly linked to their structure, launching and
dissipation mechanisms. Changes in the beaming factor along the jets could
potentially reveal jet acceleration, deceleration, or bending. We aim to (1)
quantify the relativistic effects in multiple radio frequencies and (2) study
possible jet velocity--viewing angle variations at parsec scales. We used the
state-of-the-art code Magnetron to model light curves from the University of
Michigan Radio Observatory and the Mets\""{a}hovi Radio Observatory's monitoring
programs in five frequencies covering about 25 years of observations in the
4.8-37~GHz range for 61 sources. We supplement our data set with high-frequency
radio observations in the 100-340~GHz range from ALMA, CARMA, and SMA. For each
frequency we estimate the Doppler factor which we use to quantify possible
changes in the relativistic effects along the jets. The majority of our sources
do not show any statistically significant difference in their Doppler factor
across frequencies. This is consistent with constant velocity in a conical jet,
as expected at parsec scales. However, our analysis reveals 17 sources where
relativistic beaming changes as a function of frequency. In the majority of
cases the Doppler factor increases towards lower frequencies. Only 1253-053
shows the opposite behavior. By exploring their jet properties we find that the
jet of 0420-014 is likely bent across the 4.8-340~GHz range. For 0212+735 the
jet is likely parabolic, and still accelerating in the 4.8-37~GHz range. We
discuss possible interpretations for the trends found in the remaining sources.",http://arxiv.org/abs/2108.10892v2
A zero-dimensional F-space that is not strongly zero-dimensional,2021-08-29T20:14:45Z,"Alan Dow, Klaas Pieter Hart","We present an example of a zero-dimensional $F$-space that is not strongly
zero-dimensional.",http://arxiv.org/abs/2108.12903v2
On localization for cubical higher Chow groups,2021-08-31T00:32:23Z,Jinhyun Park,"We give a purely cubical argument for the localization theorem for the
cubical version of higher Chow groups.",http://arxiv.org/abs/2108.13561v2
"Light kaonic atoms: from ""corrected"" to ""summed up"" Deser formula",2021-10-07T14:43:38Z,N. V. Shevchenko,"Accuracy of ""corrected Deser"" and ""summed up Deser"" formulas was checked for
the $K^- p$ and $K^- d$ systems. It was found that the last one is much more
accurate and should be used for connection the $1s$ level shift to the
corresponding scattering length.",http://arxiv.org/abs/2110.03505v2
Uniform Guarded Fragments,2021-10-07T23:00:50Z,Reijo Jaakkola,"In this paper we prove that the uniform one-dimensional guarded fragment,
which is a natural polyadic generalization of the guarded two-variable logic,
has the Craig interpolation property. We will also prove that the
satisfiability problem of uniform guarded fragment is NEXPTIME-complete.",http://arxiv.org/abs/2110.03821v2
Covering with Chang models over derived models,2021-10-12T14:28:53Z,Grigor Sargsyan,"We present a covering conjecture that we expect to be true below superstrong
cardinals. We then show that the conjecture is true in hod mice. This work is a
continuation of the work that started in Covering with Universally Baire
Functions Advances in Mathematics, and the main conjecture of the current paper
is a revision of the UB Covering Conjecture of the aforementioned paper.",http://arxiv.org/abs/2110.06031v1
"Addendum to ""Bounded Isometries and Homogeneous Quotients"", JGA 27
  (2017), 56--64",2021-10-16T22:15:17Z,Joseph A. Wolf,"An argument of Y. Nikonorov completes the proof of Theorem 2.5 in ""Bounded
Isometries and Homogeneous Quotients"", JGA 27 (2017), 56--64
[arXiv:1502.04276].",http://arxiv.org/abs/2110.08674v2
Hyperbolic Knots given by Positive Braids with at Least two Full Twists,2021-10-19T11:50:48Z,Thiago de Paiva,"We give some conditions on positive braids with at least two full twists that
ensure their closure is a hyperbolic knot, with applications to the geometric
classification of T-links, arising from dynamics, and twisted torus knots.",http://arxiv.org/abs/2110.09873v2
"Inverse energy cascade in self-gravitating collisionless dark matter
  flow and effects of halo shape",2021-10-26T17:41:38Z,"Zhijie, Xu","Halo-mediated mass and energy cascades are key to understand dark matter
flow. Both cascades origin from the mass exchange between halo and out-of-halo
sub-systems. Kinetic energy can be from the motion of halos and particle motion
in halos. Similarly, potential energy can be due to the inter- and intra-halo
interactions. Intra-halo virial equilibrium is established much faster than
inter-halo. Change of energy of entire system comes from virilization in halos.
At statistically steady state, continuous mass exchange is required to sustain
growth of total halo mass $M_h\propto a^{1/2}$ and energy $E\propto a^{3/2}$,
where $a$ is scale factor. Inverse cascade is identified for kinetic energy
that is transferred from the smallest scale to large mass scales. This is
sustained by the direct cascade of potential energy from large to small scale.
Both energies have a scale- and time-independent flux in propagation range that
is proportional to mass flux. Energy cascade is mostly facilitated by mass
cascade, which can be quantitatively described by mass accretion of typical
halos. Halo radial, angular momentum, and angular velocity are modelled and
inverse cascade is identified for the coherent radial and rotational motion in
halos. In turbulence, vortex stretching (shape changing) along its axis of spin
enables energy cascade from large to small length scales. However, change in
halo shape is not the dominant mechanism for energy cascade as the moment of
inertial gained from shape changing is less than 2 times. Large halos exhibit
preference for prolateness over oblateness and most halos have spin axis
perpendicular to major axis. Since mass cascade is local in mass space, halo
shape evolves continuously in mass space with halos formed by incrementally
inheriting structure from progenitor halos. A unique evolution path of halos is
found that gradually approaches sphere with increasing size.",http://arxiv.org/abs/2110.13885v2
"Singularity and Similarity Detection from Signals Using Wavelet
  Transform",2021-10-29T14:41:45Z,"Hua-Liang Wei, S. A. Billings","The wavelet transform and related techniques are used to analyze singular and
fractal signals. The normalized wavelet scalogram is introduced to detect
singularities including jumps, cusps and other sharply changing points. The
wavelet auto-covariance is applied to estimate the self-similarity exponent for
statistical self-affine signals.",http://arxiv.org/abs/2110.15825v1
Lower bound for Buchstaber invariants of real universal complexes,2021-01-04T14:02:59Z,Qifan Shen,"In this article, we prove that Buchstaber invariant of 4-dimensional real
universal complex is no less than 24 as a follow-up to the work of Ayzenberg
and Sun. Moreover, a lower bound for Buchstaber invariants of $n$-dimensional
real universal complexes is given as an improvement of result of Erokhovets.",http://arxiv.org/abs/2101.00988v2
"A Construction of Euclidean Invariant, Reflection Positive Measures on a
  Compactification of Distributions",2021-01-05T09:44:32Z,Tamer Tlas,"A simple construction is given of a class of Euclidean invariant, reflection
positive measures on a compactification of the space of distributions. An
unusual feature is that the regularizations used are not reflection positive.",http://arxiv.org/abs/2101.01427v2
"A work fluctuation theorem for a Brownian particle in a non confining
  potentia",2021-01-10T15:33:09Z,"Christoph Streißnig, Holger Kantz","Using the Feynman-Kac formula, a work fluctuation theorem for a Brownian
particle in a nonconfining potential, e.g., a potential well with finite depth,
is derived. The theorem yields aninequality that puts a lower bound on the
average work needed to change the potential in time.In comparison to the
Jarzynski equality, which holds for confining potentials, an additional
termdescribing a form of energy related to the never ending diffusive expansion
appears.",http://arxiv.org/abs/2101.03568v1
"Galaxy And Mass Assembly: Group and field galaxy morphologies in the
  star-formation rate - stellar mass plane",2021-01-11T10:36:04Z,"W. J. Pearson, L. Wang, S. Brough, B. W. Holwerda, A. M. Hopkins, J. Loveday","We study the environment in which a galaxy lies (i.e. field or group) and its
connection with the morphology of the galaxy. This is done by examining the
distribution of parametric and non-parametric statistics across the
star-formation rate (SFR) - stellar mass (M$_{\star}$) plane and studying how
these distributions change with the environment in the local universe
($z<0.15$).
  We determine the concentration (C), Gini, M$_{20}$, asymmetry, Gini-M$_{20}$
bulge statistic (GMB), 50\% light radius ($r_{50}$), total S\'{e}rsic index,
and bulge S\'{e}rsic index ($n_{Bulge}$) for galaxies from the Galaxy and Mass
Assembly (GAMA) survey using optical images from the Kilo Degree Survey. We
determine the galaxy environment using the GAMA group catalogue and split the
galaxies into field or group galaxies. The group galaxies are further divided
by the group halo mass (M$_{h}$) -
$11\leq\mathrm{log(M}_{h}/\mathrm{M}_\odot)<12$,
$12\leq\mathrm{log(M}_{h}/\mathrm{M}_\odot)<13$, and
$13\leq\mathrm{log(M}_{h}/\mathrm{M}_\odot)<14$ - and into central and
satellite galaxies. The galaxies in each of these samples are then placed onto
the SFR-M$_{\star}$ plane, and each parameter is used as a third dimension. We
fit the resulting distributions for each parameter in each sample using two
two-dimensional Gaussian distributions: one for star-forming galaxies and one
for quiescent galaxies. The coefficients of these Gaussian fits are then
compared between environments.
  Using C and $r_{50}$, we find that galaxies typically become larger as the
group mass increases. This change is greater for larger galaxies. There is no
indication that galaxies are typically more or less clumpy as the environment
changes. Using GMB and $n_{Bulge}$, we see that the star-forming galaxies do
not become more bulge or disk dominated as the group mass changes. Asymmetry
does not appear to be greatly influenced by environment.",http://arxiv.org/abs/2101.03804v1
"UFL Dual Spaces, a proposal",2021-01-13T15:55:51Z,David A. Ham,"This white paper highlights current limitations in the algebraic closure
Unified Form Language (UFL). UFL currently represents forms over finite element
spaces, however finite element problems naturally result in objects in the dual
to a finite element space, and operators mapping between primal and dual finite
element spaces. This document sketches the relevant mathematical areas and
proposes changes to the UFL language to support dual spaces as first class
types in UFL.",http://arxiv.org/abs/2101.05158v1
Structure Of Flavor Changing Goldstone Boson Interactions,2021-01-15T10:49:11Z,"Jin Sun, Yu Cheng, Xiao-Gang He","General flavor changing interactions for a Goldstone boson (GB) to fermions
due to a spontaneous global $U(1)_G$ symmetry breaking are discussed. This GB
may be the Axion, solving the strong QCD CP problem, if there is a QCD anomaly
for the $U(1)_G$ charge assignments for quarks. Or it may be the Majoron in
models from lepton number violation in producing seesaw Majorana neutrino
masses if the symmetry breaking scale is much higher than the electroweak
scale. It may also, in principle, play the roles of Axion and Majoron
simultaneously as far as providing solution for the strong CP problem and
generating a small Majorana neutrino masses are concerned. Great attentions
have been focused on flavor conserving GB interactions. Recently flavor
changing Axion and Majoron models have been studied in the hope to find new
physics from rare decays in the intensity frontier. In this work, we will
provide a systematic model building aspect study for a GB having flavor
changing neutral current (FCNC) interactions in both the quark and lepton
sectors, or separately in the quark, charged lepton and neutrino sectors with
sources of FCNC interactions identified in detail. We provide a general proof
of the equivalence of using physical GB components and GB broken generators for
calculating GB couplings to two gluons and two photons, and some issues related
to models having spontaneous CP violation are discussed. We will also provide
some details for obtaining FCNC GB interactions in several popular models, such
as the Type-I, -II, -III seesaw and Left-Right symmetric models, and point out
some special features in these models.",http://arxiv.org/abs/2101.06055v3
Integral morphisms and log blow-ups,2021-01-22T13:42:42Z,Fumiharu Kato,"This paper is a revision of the author's old preprint ""Exactness,
integrality, and log modifications"". We will prove that any quasi-compact
morphism of fs log schemes can be modified locally on the base to an integral
morphism by base change by fs log blow-ups.",http://arxiv.org/abs/2101.09104v1
Seshadri constants and K-stability of Fano manifolds,2021-01-22T17:56:55Z,"Hamid Abban, Ziquan Zhuang","We give a lower bound of the $\delta$-invariants of ample line bundles in
terms of Seshadri constants. As applications, we prove the uniform K-stability
of infinitely many families of Fano hypersurfaces of arbitrarily large index,
as well as the uniform K-stability of most families of smooth Fano threefolds
of Picard number one.",http://arxiv.org/abs/2101.09246v2
Almost orthogonal subsets of vector spaces over finite fields,2021-01-23T22:25:15Z,"Ali Mohammadi, Giorgis Petridis","We prove various results on the size and structure of subsets of vector
spaces over finite fields which, in some sense, have too many mutually
orthogonal pairs of vectors. In particular, we obtain sharp finite field
variants of a theorem of Rosenfeld and an almost version of a theorem of
Berlekamp.",http://arxiv.org/abs/2101.09597v2
Deformations of varieties of general type,2021-01-26T18:31:00Z,János Kollár,"We prove that small deformations of a projective variety of general type are
also projective varieties of general type, with the same plurigenera. Version
2: small changes in first half. Improved version of the second half is now a
separate preprint (Seshadri's criterion and openness of projectivity). Version
3: Footnote corrects citation on p.4.",http://arxiv.org/abs/2101.10986v3
"Modern Forcing Techniques related to Finite Support Iteration:
  Ultrapowers, templates, and submodels",2021-01-27T15:42:01Z,Joerg Brendle,"This is an expository paper about several sophisticated forcing techniques
closely related to standard finite support iterations of ccc partial orders. We
focus on the four topics of ultrapowers of forcing notions, iterations along
templates, Boolean ultrapowers of forcing notions, and restrictions of forcing
notions to elementary submodels.",http://arxiv.org/abs/2101.11494v2
Homogeneous varieties under split solvable algebraic groups,2021-01-29T07:50:43Z,Michel Brion,"We present a modern proof of a theorem of Rosenlicht, asserting that every
variety as in the title is isomorphic to a product of affine lines and
punctured affine lines.",http://arxiv.org/abs/2101.12452v2
Multi-Wavelength Photometry Derived from Monochromatic Kepler Data,2021-01-29T20:09:29Z,"Christina Hedges, Rodrigo Luger, Jessie Dotson, Daniel Foreman-Mackey, Geert Barentsen","The Kepler mission has provided a wealth of data, revealing new insights in
time-domain astronomy. However, Kepler's single band-pass has limited studies
to a single wavelength. In this work we build a data-driven, pixel-level model
for the Pixel Response Function (PRF) of Kepler targets, modeling the image
data from the spacecraft. Our model is sufficiently flexible to capture known
detector effects, such as non-linearity, intra-pixel sensitivity variations,
and focus change. In theory, the shape of the Kepler PRF should also be weakly
wavelength dependent, due to optical chromatic aberration and wavelength
dependent detector response functions. We are able to identify these predicted
shape changes to the PRF using the residuals between Kepler data and our model.
In this work, we show that these PRF changes correspond to wavelength
variability in Kepler targets using a small sample of eclipsing binaries. Using
our model, we demonstrate that pixel-level light curves of eclipsing binaries
show variable eclipse depths, ellipsoidal modulation and limb darkening. These
changes at the pixel level are consistent with multi-wavelength photometry. Our
work suggests each pixel in the Kepler data of a single target has a different
effective wavelength, ranging from $\approx$ 550-750 $nm$. In this proof of
concept, we demonstrate our model, and discuss possible use cases for the
wavelength dependent Pixel Response Function of Kepler. These use cases include
characterizing variable systems, and vetting exoplanet discoveries at the pixel
level. The chromatic PRF of Kepler is due to weak wavelength dependence in the
optical systems and detector of the telescope, and similar chromatic PRFs are
expected in other similar telescopes, notably the NASA TESS telescope.",http://arxiv.org/abs/2102.00044v1
"ALMA/NICER observations of GRS 1915+105 indicate a return to a hard
  state",2021-02-01T08:25:52Z,"Karri I. I. Koljonen, Talvikki Hovatta","GRS 1915+105 is a transient black hole X-ray binary consistently emitting
10-100% of the Eddington luminosity in the X-ray band during the last three
decades until mid-2018 when the source luminosity suddenly decreased by an
order of magnitude. This phase was followed by a change to a state with even
lower average X-ray fluxes never seen before during the outburst but presenting
renewed flaring activity at different wavelengths. Nevertheless, the mean
fluxes were still in decline. GRS 1915+105 has the longest orbital period known
among low-mass X-ray binaries, the largest accretion disk size, and therefore
the largest mass supply for accretion. The high inclination of the disk allows
the study of geometrical effects of the accretion flow such as changes in the
height-to-radius ratio or the effect of accretion disk winds on the intrinsic
emission that are expected during the outburst decay. In addition, the
transient jet is expected to change to a compact, self-absorbed, steady jet. We
conducted two full polarization Atacama Large Millimeter Array observations to
study the jet properties during the outburst decay by analyzing the spectral,
polarization, and intra-epoch variability for both observation epochs. In
addition, we analyzed nearly daily Neutron Star Interior Composition Explorer
pointing observations consisting of modeling X-ray power spectral densities,
spectral energy distributions, and lightcurves with a physically motivated
model to follow the changing accretion disk properties throughout the outburst
decay and relating them to the jet emission. We show that the X-ray and mm
spectral, timing, and polarization properties are consistent with those of a
typical decaying X-ray binary outburst and that GRS 1915+105 has descended into
the low-luminosity hard X-ray state.",http://arxiv.org/abs/2102.00693v2
The regularized free fall I -- Index computations,2021-02-02T18:56:42Z,"Urs Frauenfelder, Joa Weber","Main results are, firstly, a generalization of the Conley-Zehnder index from
ODEs to the delay equation at hand and, secondly, the equality of the Morse
index and the clockwise normalized Conley-Zehnder index.",http://arxiv.org/abs/2102.01688v2
"Deep learning-based attenuation correction in the image domain for
  myocardial perfusion SPECT imaging",2021-02-09T16:10:40Z,"Samaneh Mostafapour, Faeze Gholamiankhah, Sirvan Maroofpour, Mahdi Momennezhad, Mohsen Asadinezhad, Seyed Rasoul Zakavi, Hossein Arabi","Objective: In this work, we set out to investigate the accuracy of direct
attenuation correction (AC) in the image domain for the myocardial perfusion
SPECT imaging (MPI-SPECT) using two residual (ResNet) and UNet deep
convolutional neural networks. Methods: The MPI-SPECT 99mTc-sestamibi images of
99 participants were retrospectively examined. UNet and ResNet networks were
trained using SPECT non-attenuation corrected images as input and CT-based
attenuation corrected SPECT images (CT-AC) as reference. The Chang AC approach,
considering a uniform attenuation coefficient within the body contour, was also
implemented. Quantitative and clinical evaluation of the proposed methods were
performed considering SPECT CT-AC images of 19 subjects as reference using the
mean absolute error (MAE), structural similarity index (SSIM) metrics, as well
as relevant clinical indices such as perfusion deficit (TPD). Results: Overall,
the deep learning solution exhibited good agreement with the CT-based AC,
noticeably outperforming the Chang method. The ResNet and UNet models resulted
in the ME (count) of ${-6.99\pm16.72}$ and ${-4.41\pm11.8}$ and SSIM of
${0.99\pm0.04}$ and ${0.98\pm0.05}$, respectively. While the Change approach
led to ME and SSIM of ${25.52\pm33.98}$ and ${0.93\pm0.09}$, respectively.
Similarly, the clinical evaluation revealed a mean TPD of ${12.78\pm9.22}$ and
${12.57\pm8.93}$ for the ResNet and UNet models, respectively, compared to
${12.84\pm8.63}$ obtained from the reference SPECT CT-AC images. On the other
hand, the Chang approach led to a mean TPD of ${16.68\pm11.24}$. Conclusion: We
evaluated two deep convolutional neural networks to estimate SPECT-AC images
directly from the non-attenuation corrected images. The deep learning solutions
exhibited the promising potential to generate reliable attenuation corrected
SPECT images without the use of transmission scanning.",http://arxiv.org/abs/2102.04915v2
"Interfacial metric mechanics: stitching patterns of shape change in
  active sheets",2021-02-09T17:10:58Z,"Fan Feng, Daniel Duffy, Mark Warner, John S. Biggins","A flat sheet programmed with a planar pattern of spontaneous shape change
will morph into a curved surface. Such metric mechanics is seen in growing
biological sheets, and may be engineered in actuating soft matter sheets such
as phase-changing liquid crystal elastomers (LCEs), swelling gels and inflating
baromorphs. Here, we show how to combine multiple patterns in a sheet by
stitching regions of different shape changes together piecewise along
interfaces. This approach allows simple patterns to be used as building blocks,
and enables the design of multi-material or active/passive sheets. We give a
general condition for an interface to be geometrically compatible, and explore
its consequences for LCE/LCE, gel/gel, and active/passive interfaces. In
contraction/elongation systems such as LCEs, we find an infinite set of
compatible interfaces between any pair of patterns along which the metric is
discontinuous, and a finite number across which the metric is continuous. As an
example, we find all possible interfaces between pairs of LCE logarithmic
spiral patterns. In contrast, in isotropic systems such as swelling gels, only
a finite number of continuous interfaces are available, greatly limiting the
potential of stitching. In both continuous and discontinuous cases, we find the
stitched interfaces generically carry singular Gaussian curvature, leading to
intrinsically curved folds in the actuated surface. We give a general
expression for the distribution of this curvature, and a more specialized form
for interfaces in LCE patterns. The interfaces thus also have rich geometric
and mechanical properties in their own right.",http://arxiv.org/abs/2102.04955v5
Magnetically induced linear and nonreciprocal and tunable transparency,2021-02-14T08:53:21Z,A. H. Gevorgyan,"We report the discovery of a new effect, namely, the effect of magnetically
induced transparency. The effect is observed in a magnetically active helically
structured periodical medium. Changing the external magnetic field and
absorption, one can tune the frequency and the linewidth of the transparency
band.",http://arxiv.org/abs/2102.07105v2
Maximal estimates for averages over space curves,2021-02-14T15:23:43Z,"Hyerim Ko, Sanghyuk Lee, Sewook Oh","Let $M$ be the maximal operator associated to a smooth curve in $\mathbb R^3$
which has nonvanishing curvature and torsion. We prove that $M$ is bounded on
$L^p$ if and only if $p>3$.",http://arxiv.org/abs/2102.07175v2
The Disproof of the Riemann Hypothesis,2021-02-16T17:53:36Z,"C. Dumitrescu, M. Wolf","We show that there is a contradiction between the Riemann's Hypothesis and
some form of the theorem on the universality of the zeta function.",http://arxiv.org/abs/2102.08313v5
Correlation Based Principal Loading Analysis,2021-02-19T13:08:30Z,Jan O. Bauer,"Principal loading analysis is a dimension reduction method that discards
variables which have only a small distorting effect on the covariance matrix.
We complement principal loading analysis and propose to rather use a mix of
both, the correlation and covariance matrix instead. Further, we suggest to use
rescaled eigenvectors and provide updated algorithms for all proposed changes.",http://arxiv.org/abs/2102.09912v1
Potential benefits of delaying the second mRNA COVID-19 vaccine dose,2021-02-26T17:16:18Z,"Benjamin F. Maier, Angelique Burdinski, Annika H. Rose, Frank Schlosser, David Hinrichs, Cornelia Betsch, Lars Korn, Philipp Sprengholz, Michael Meyer-Hermann, Tanmay Mitra, Karl Lauterbach, Dirk Brockmann","Vaccination against COVID-19 with the recently approved mRNA vaccines
BNT162b2 (BioNTech/Pfizer) and mRNA-1273 (Moderna) is currently underway in a
large number of countries. However, high incidence rates and rapidly spreading
SARS-CoV-2 variants are concerning. In combination with acute supply deficits
in Europe in early 2021, the question arises of whether stretching the vaccine,
for instance by delaying the second dose, can make a significant contribution
to preventing deaths, despite associated risks such as lower vaccine efficacy,
the potential emergence of escape mutants, enhancement, waning immunity,
reduced social acceptance of off-label vaccination, and liability shifts. A
quantitative epidemiological assessment of risks and benefits of non-standard
vaccination protocols remains elusive. To clarify the situation and to provide
a quantitative epidemiological foundation we develop a stochastic
epidemiological model that integrates specific vaccine rollout protocols into a
risk-group structured infectious disease dynamical model. Using the situation
and conditions in Germany as a reference system, we show that delaying the
second vaccine dose is expected to prevent deaths in the four to five digit
range, should the incidence resurge. We show that this considerable public
health benefit relies on the fact that both mRNA vaccines provide substantial
protection against severe COVID-19 and death beginning 12 to 14 days after the
first dose. The benefits of protocol change are attenuated should vaccine
compliance decrease substantially. To quantify the impact of protocol change on
vaccination adherence we performed a large-scale online survey. We find that,
in Germany, changing vaccination protocols may lead to small reductions in
vaccination intention. In sum, we therefore expect the benefits of a strategy
change to remain substantial and stable.",http://arxiv.org/abs/2102.13600v1
"Ultrasonic monitoring of stress and cracks of the 1/3 scale mock-up of
  nuclear reactor concrete containment structure",2021-04-03T08:33:01Z,"Qi Xue, Eric Larose, Ludovic Moreau, Romain Thery, Odile Abraham, Jean-Marie Henault","To evaluate the stress level and damage of a reinforced concrete containment
wall and its reaction to pressure variations, we implemented successive
ultrasonic experiments on the exterior surface of the containment wall in the
gusset area for three consecutive years. During each experiment, the pressure
inside the containment wall increased gradually from 0 MPa to 0.43 MPa and then
decreased back to 0 Mpa.From the analysis of the ultrasonic coda waves obtained
in the multiple scattering regime, we performed Coda Wave Interferometry to
calculate the apparent velocity changes in the structure (denoted by $dV/V_a$)
and Coda Wave Decorrelation (DC) measurements to produce 3D cartographies of
stress and crack distribution. From three source-receiver pairs, located at the
top, middle and bottom of the experimental region, we observe that coda waves
dilate, shrink and remain almost unchanged, respectively. This corresponds to
the decreasing, increasing and invariant pressure inside the concrete. The
comparison of three years' results demonstrates that the variation of $dV/V_a$
and DC under the same pressure test increases through the years, which
indicates the progressive deterioration and aging of the concrete. From a large
collection of source-receiver pairs at different times, the spatial-temporal
variations of $dV/V_a$ and DC are then used to produce a map of the structural
velocity and scattering changes, respectively. We observe a decreasing velocity
on the top part and an increasing in the middle one, which is in line with the
$dV/V_a$ analysis. The reconstructed scattering changes (or structural changes)
highlight the active region during the inflation-deflation procedure,
corresponding to the opening and closing (and sometimes the development) of
cracks. The larger magnitude in 2019 than in 2017 indicates the increasing
damage in the concrete.",http://arxiv.org/abs/2104.01342v1
"FABRIC: A Framework for the Design and Evaluation of Collaborative
  Robots with Extended Human Adaptation",2021-04-05T15:52:38Z,"O. Can Görür, Benjamin Rosman, Fikret Sivrikaya, Sahin Albayrak","A limitation for collaborative robots (cobots) is their lack of ability to
adapt to human partners, who typically exhibit an immense diversity of
behaviors. We present an autonomous framework as a cobot's real-time
decision-making mechanism to anticipate a variety of human characteristics and
behaviors, including human errors, toward a personalized collaboration. Our
framework handles such behaviors in two levels: 1) short-term human behaviors
are adapted through our novel Anticipatory Partially Observable Markov Decision
Process (A-POMDP) models, covering a human's changing intent (motivation),
availability, and capability; 2) long-term changing human characteristics are
adapted by our novel Adaptive Bayesian Policy Selection (ABPS) mechanism that
selects a short-term decision model, e.g., an A-POMDP, according to an estimate
of a human's workplace characteristics, such as her expertise and collaboration
preferences. To design and evaluate our framework over a diversity of human
behaviors, we propose a pipeline where we first train and rigorously test the
framework in simulation over novel human models. Then, we deploy and evaluate
it on our novel physical experiment setup that induces cognitive load on humans
to observe their dynamic behaviors, including their mistakes, and their
changing characteristics such as their expertise. We conduct user studies and
show that our framework effectively collaborates non-stop for hours and adapts
to various changing human behaviors and characteristics in real-time. That
increases the efficiency and naturalness of the collaboration with a higher
perceived collaboration, positive teammate traits, and human trust. We believe
that such an extended human adaptation is key to the long-term use of cobots.",http://arxiv.org/abs/2104.01976v2
"Modulating Curie Temperature and Magnetic Anisotropy in Nanoscale
  Layered Cr_{2}Te_{3} Films: Implications for Room-Temperature Spintronics",2021-04-06T01:23:44Z,"In Hak Lee, Byoung Ki Choi, Hyuk Jin Kim, Min Jay Kim, Hu Young Jeong, Jong Hoon Lee, Seung-Young Park, Younghun Jo, Chanki Lee, Jun Woo Choi, Seong Won Cho, Suyuon Lee, Younghak Kim, Beom Hyun Kim, Kyeong Jun Lee, Jin Eun Heo, Seo Hyoung Chang, Fengping Li, Bheema Lingam Chittari, Jeil Jung, Young Jun Chang","Nanoscale layered ferromagnets have demonstrated fascinating two-dimensional
magnetism down to atomic layers, providing a peculiar playground of spin orders
for investigating fundamental physics and spintronic applications. However,
strategy for growing films with designed magnetic properties is not well
established yet. Herein, we present a versatile method to control the Curie
temperature (T_{C}) and magnetic anisotropy during growth of ultrathin
Cr_{2}Te_{3} films. We demonstrate increase of the TC from 165 K to 310 K in
sync with magnetic anisotropy switching from an out-of-plane orientation to an
in-plane one, respectively, via controlling the Te source flux during film
growth, leading to different c-lattice parameters while preserving the
stoichiometries and thicknesses of the films. We attributed this modulation of
magnetic anisotropy to the switching of the orbital magnetic moment, using
X-ray magnetic circular dichroism analysis. We also inferred that different
c-lattice constants might be responsible for the magnetic anisotropy change,
supported by theoretical calculations. These findings emphasize the potential
of ultrathin Cr_{2}Te_{3} films as candidates for developing room-temperature
spintronics applications and similar growth strategies could be applicable to
fabricate other nanoscale layered magnetic compounds.",http://arxiv.org/abs/2104.02224v1
On the Rajchman property for self-similar measures on $\mathbb{R}^{d}$,2021-04-08T17:56:35Z,Ariel Rapaport,"We establish a complete algebraic characterization of self-similar iterated
function systems $\Phi$ on $\mathbb{R}^{d}$, for which there exists a positive
probability vector $p$ so that the Fourier transform of the self-similar
measure corresponding to $\Phi$ and $p$ does not tend to $0$ at infinity.",http://arxiv.org/abs/2104.03955v2
Convexity of $λ$-hypersurfaces,2021-04-12T13:38:26Z,Tang-Kai Lee,"We prove that any $n$-dimensional closed mean convex $\lambda$-hypersurface
is convex if $\lambda\le 0.$ This generalizes Guang's work on $2$-dimensional
strictly mean convex $\lambda$-hypersurfaces. As a corollary, we obtain a gap
theorem for closed $\lambda$-hypersurfaces with $\lambda\le 0.$",http://arxiv.org/abs/2104.05464v2
"Exponential and strong ergodicity for one-dimensional symmetric stable
  jump diffusions",2021-04-16T07:50:20Z,Tao Wang,"We obtain explicit criteria for both exponential ergodicity and strong
ergodicity for one-dimensional time-changed symmetric stable processes with
$\alpha\in(1,2)$. Explicit lower bounds for ergodic convergence rates are
given.",http://arxiv.org/abs/2104.07947v5
"Quantizations and global hypoellipticity for pseudodifferential
  operators of infinite order in classes of ultradifferentiable functions",2021-04-19T10:42:42Z,Vicente Asensio,"We study the change of quantization for a class of global pseudodifferential
operators of infinite order in the setting of ultradifferentiable functions of
Beurling type. The composition of different quantizations as well as the
transpose of a quantization are also analysed, with applications to the Weyl
calculus. We also compare global $\omega$-hypoellipticity and global
$\omega$-regularity of these classes of pseudodifferential operators.",http://arxiv.org/abs/2104.09198v1
"Features of the Galactic Cosmic Ray Anisotropy in the Solar Cycle 24 and
  Solar Minima 23/24 and 24/25",2021-04-22T18:47:21Z,"R. Modzelewska, K. Iskra, W. Wozniak, M. Siluszyk, M. V. Alania","We study the role of drift effect in the temporal changes of the anisotropy
of galactic cosmic rays (GCRs) and the influence of the sector structure of the
heliospheric magnetic field on it. We analyze the GCRs anisotropy in the Solar
Cycle 24 and solar minimum 23_24 with negative polarity for the period of
2007-2009 and near minimum 24_25 with positive polarity in 2017-2018 using data
of global network of Neutron Monitors. We use the harmonic analyses method to
calculate the radial and tangential components of the anisotropy of GCRs for
different sectors (plus corresponds to the positive and minus to the negative
directions) of the heliospheric magnetic field. We compare the analysis of GCRs
anisotropy using different evaluations of the mean GCRs rigidity related to
Neutron Monitor observations. Then the radial and tangential components are
used for characterizing the GCRs modulation in the heliosphere. We show that in
the solar minimum 23_24 in 2007-2009 when negative, the drift effect is not
visibly evident in the changes of the radial component, i.e. the drift effect
is found to produce 4 % change in the radial component of the GCRs anisotropy
for 2007-2009. Hence the diffusion dominated model of GCRs transport is more
acceptable in 2007-2009. In turn, near the solar minimum 24_25 in 2017-2018
when positive, the drift effect is evidently visible and produce 40% change in
the radial component of the GCRs anisotropy for 2017-2018. So in the period of
2017-2018 diffusion model with noticeably manifested drift is acceptable. The
results of this work are in good agreement with the drift theory of GCRs
modulation, according to which during negative (positive) polarity cycles, a
drift stream of GCRs is directed toward (away from) the Sun, thus giving rise
to a 22-year cycle variation of the radial GCRs anisotropy.",http://arxiv.org/abs/2104.11277v1
The Ordered Join of Impartial Games,2021-04-27T12:19:28Z,"Mišo Gavrilović, Alexander Thumm","Inspired by the theory of poset games, we introduce a new compound of
impartial combinatorial games and provide a complete analysis in the spirit of
the Sprague-Grundy theory. Furthermore, we establish several substitution and
reduction principles for this compound and consider its computational aspects.",http://arxiv.org/abs/2104.13131v2
Estimation Radius Regression in PLIC-VOF Method for Droplet Evaporation,2021-04-27T09:59:06Z,"Jean Nahed, Joseph Dgheim","Naviers Stokes and energy equations of hydrocarbon liquid droplet in
evaporation in natural convection are solved numerically using PLIC VOF method.
Our new technique allows us to observe clearly the droplet radius regression in
each cell of the mesh. This regression is not affected by the changing of the
droplet shape and temperature.",http://arxiv.org/abs/2104.13375v1
"Ancient and present surface evolution processes in the Ash regionof
  comet 67P/Churyumov-Gerasimenko",2021-04-28T13:03:16Z,"A. Bouquety, L. Jorda, O. Groussin, A. Sejourné, S. Bouley, F. Costard","The Rosetta mission provided us with detailed data of the surface of the
nucleus of comet 67P/Churyumov-Gerasimenko.In order to better understand the
physical processes associated with the comet activity and the surface evolution
of its nucleus, we performed a detailed comparative morphometrical analysis of
two depressions located in the Ash region. To detect morphological temporal
changes, we compared pre- and post-perihelion high-resolution (pixel scale of
0.07-1.75 m) OSIRIS images of the two depressions. We quantified the changes
using the dynamic heights and the gravitational slopes calculated from the
Digital Terrain Model (DTM) of the studied area using the ArcGIS software
before and after perihelion. Our comparative morphometrical analysis allowed us
to detect and quantify the temporal changes that occurred in two depressions of
the Ash region during the last perihelion passage. We find that the two
depressions grew by several meters. The area of the smallest depression
(structure I) increased by 90+/-20%, with two preferential growths: one close
to the cliff associated with the apparition of new boulders at its foot, and a
second one on the opposite side of the cliff. The largest depression (structure
II) grew in all directions, increasing in area by 20+/-5%, and no new deposits
have been detected. We interpreted these two depression changes as being driven
by the sublimation of ices, which explains their global growth and which can
also trigger landslides. The deposits associated with depression II reveal a
stair-like topography, indicating that they have accumulated during several
successive landslides from different perihelion passages. Overall, these
observations bring additional evidence of complex active processes and
reshaping events occurring on short timescales, such as depression growth and
landslides, and on longer timescales, such as cliff retreat.",http://arxiv.org/abs/2104.13741v1
"A weakening Compton hump and soft X-ray excess detected in the Seyfert-1
  galaxy MCG-02-58-22",2021-04-29T19:28:04Z,"Sibasish Laha, Ritesh Ghosh","We have carried out an extensive X-ray spectral study of the bare Seyfert-1
galaxy MCG--02--58--22 to ascertain the nature of the X-ray reprocessing media,
using observations from Suzaku (2009) and simultaneous observations from
XMM-Newton and NuSTAR (2016) . The most significant results of our
investigation are: 1. The primary X-ray emission from the corona is constant in
these observations, both in terms of the power law slope ($\Gamma=1.80$) and
luminosity ($L_{2-10 \rm keV}= 2.55\times 10^{44} $ erg/s). 2. The soft excess
flux decreased by a factor of two in 2016, the Compton hump weakened/vanished
in 2016, and the narrow FeK$\alpha$ emission line became marginally broad
($\sigma=0.35\pm0.08$ keV) and its flux doubled in 2016. 3. From physical model
fits we find that the normalization of the narrow component of the FeK$\alpha$
line does not change in the two epochs, although the Compton hump vanishes in
the same time span. Since the primary X-ray continuum does not change, we
presume that any changes in the reprocessed emission must arise due to changes
in the reprocessing media. Our primary conclusions are: A. The vanishing of the
Compton hump in 2016 can probably be explained by a dynamic clumpy torus which
is infalling/outflowing, or by a polar torus wind. B. The torus in this AGN
possibly has two structures: an equatorial toroidal disk (producing the narrow
FeK$\alpha$ emission) and a polar component (producing the variable Compton
hump), C. The reduction of the soft-excess flux by half and increase in the
FeK$\alpha$ flux by a factor of two in the same period cannot be adequately
explained by ionized disk reflection model alone.",http://arxiv.org/abs/2104.14627v1
Distance and the Goeritz groups of bridge decompositions,2021-05-03T05:35:10Z,"Daiki Iguchi, Yuya Koda","We prove that if the distance of a bridge decomposition of a link with
respect to a Heegaard splitting of a $3$-manifold is at least $6$, then the
Goeritz group is a finite group.",http://arxiv.org/abs/2105.00631v2
"Functional equation of the $p$-adic $L$-function of Bianchi modular
  forms",2021-05-06T15:56:00Z,Luis Santiago Palacios,"Let $K$ be an imaginary quadratic field with class number 1, in this paper we
obtain the functional equation of the $p$-adic $L$-function of: (1) a small
slope $p$-stabilisation of a Bianchi modular form, and (2) a critical slope
$p$-stabilisation of a Base change Bianchi modular form that is
$\Sigma$-smooth. To treat case (2) we use $p$-adic families of Bianchi modular
forms.",http://arxiv.org/abs/2105.02770v1
Lecture notes on descriptional complexity and randomness,2021-05-10T23:15:28Z,Peter Gacs,"A didactical survey of the foundations of Algorithmic Information Theory.
These notes are short on motivation, history and background but introduce some
of the main techniques and concepts of the field.
  The ""manuscript"" has been evolving over the years. Please, look at ""Version
history"" below to see what has changed when.",http://arxiv.org/abs/2105.04704v1
"Ionizing photon production of Population III stars: effects of rotation,
  convection, and initial mass function",2021-05-14T15:38:47Z,"Laura J. Murphy, Jose H. Groh, Eoin Farrell, Georges Meynet, Sylvia Ekström, Sophie Tsiatsiou, Alexander Hackett, Sébastien Martinet","The first stars are thought to be one of the dominant sources of hydrogen
reionization in the early Universe, with their high luminosities and surface
temperatures expected to drive high ionizing photon production rates. In this
work, we take our Geneva stellar evolution models of zero-metallicity stars and
predict their production rates of photons capable to ionize H, He I and He II,
based on a blackbody approximation. We present analytical fits in the range
1.7-500 solar masses. We then explore the impact of stellar initial mass,
rotation, and convective overshooting for individual stars. We have found that
ionizing photon production rates increase with increasing initial mass. For the
rotational velocities considered we see changes of up to 25% to ionizing
photons produced. This varies with initial mass and ionizing photon species and
reflects changes to surface properties due to rotation. We have also found that
higher convective overshooting increases ionizing photon production by
approximately 20% for the change in overshooting considered here. For stellar
populations, we explore how the production of ionizing photons varies as a
function of the initial mass function (IMF) slope, and minimum and maximum
initial masses. For a fixed population mass we have found changes of the order
of 20-30% through varying the nature of the IMF. This work presents ionizing
photon production predictions for the most up to date Geneva stellar evolution
models of Population III stars, and provides insight into how key evolutionary
parameters impact the contribution of the first stars to reionization.",http://arxiv.org/abs/2105.06900v3
"Minimum-Delay Adaptation in Non-Stationary Reinforcement Learning via
  Online High-Confidence Change-Point Detection",2021-05-20T01:57:52Z,"Lucas N. Alegre, Ana L. C. Bazzan, Bruno C. da Silva","Non-stationary environments are challenging for reinforcement learning
algorithms. If the state transition and/or reward functions change based on
latent factors, the agent is effectively tasked with optimizing a behavior that
maximizes performance over a possibly infinite random sequence of Markov
Decision Processes (MDPs), each of which drawn from some unknown distribution.
We call each such MDP a context. Most related works make strong assumptions
such as knowledge about the distribution over contexts, the existence of
pre-training phases, or a priori knowledge about the number, sequence, or
boundaries between contexts. We introduce an algorithm that efficiently learns
policies in non-stationary environments. It analyzes a possibly infinite stream
of data and computes, in real-time, high-confidence change-point detection
statistics that reflect whether novel, specialized policies need to be created
and deployed to tackle novel contexts, or whether previously-optimized ones
might be reused. We show that (i) this algorithm minimizes the delay until
unforeseen changes to a context are detected, thereby allowing for rapid
responses; and (ii) it bounds the rate of false alarm, which is important in
order to minimize regret. Our method constructs a mixture model composed of a
(possibly infinite) ensemble of probabilistic dynamics predictors that model
the different modes of the distribution over underlying latent MDPs. We
evaluate our algorithm on high-dimensional continuous reinforcement learning
problems and show that it outperforms state-of-the-art (model-free and
model-based) RL algorithms, as well as state-of-the-art meta-learning methods
specially designed to deal with non-stationarity.",http://arxiv.org/abs/2105.09452v1
Retrieving Quality Factors for Reflection & Transmission Measurements,2021-05-31T04:07:43Z,"Juliang Li, P. Barry, C. Chang","This article presents pedagogical explanation of retrieving the resonance
parameters $Q_{L}$, $Q_{o}$ and $Q_{c}$ from both reflection and transmission
measurement of microwave resonator. Here $Q_{L}$ stands for the total or loaded
quality factor (Q), $Q_{o}$ is the internal Q and $Q_{c}$ is the coupling or
external Q. Matlab Code based on the methods is available for download for
direct calculation of the Qs.\cite{lighq}",http://arxiv.org/abs/2105.14692v1
Evidence for profile changes in PSR J1713+0747 using the uGMRT,2021-07-09T18:00:22Z,"Jaikhomba Singha, Mayuresh P Surnis, Bhal Chandra Joshi, Pratik Tarafdar, Prerna Rana, Abhimanyu Susobhanan, Raghav Girgaonkar, Neel Kolhe, Nikita Agarwal, Shantanu Desai, T Prabu, Adarsh Bathula, Subhajit Dandapat, Lankeswar Dey, Shinnosuke Hisano, Ryo Kato, Divyansh Kharbanda, Tomonosuke Kikunaga, Piyush Marmat, Sai Chaitanya Susarla, Manjari Bagchi, Neelam Dhanda Batra, Arpita Choudhury, A Gopakumar, Yashwant Gupta, M A Krishnakumar, Yogesh Maan, P K Manoharan, K Nobleson, Arul Pandian, Dhruv Pathak, Keitaro Takahashi","PSR J1713+0747 is one of the most precisely timed pulsars in the
international pulsar timing array experiment. This pulsar showed an abrupt
profile shape change between April 16, 2021 (MJD 59320) and April 17, 2021 (MJD
59321). In this paper, we report the results from multi-frequency observations
of this pulsar carried out with the upgraded Giant Metrewave Radio Telescope
(uGMRT) before and after the event. We demonstrate the profile change seen in
Band 5 (1260 MHz - 1460 MHz) and Band 3 (300 MHz - 500 MHz). The timing
analysis of this pulsar shows a disturbance accompanying this profile change
followed by a recovery with a timescale of $\sim 159$ days. Our data suggest
that a model with chromatic index as a free parameter is preferred over models
with combinations of achromaticity with DM bump or scattering bump. We
determine the frequency dependence to be $\sim\nu^{+1.34}$.",http://arxiv.org/abs/2107.04607v2
"On the Classification of Stable Solutions of some elliptic equations in
  half-space",2021-07-11T09:02:32Z,"Foued Mtiri, Abdelbaki Selmi, Cherif Zaidi","In this paper, we are concerned with stable solutions , possibly unbounded
and sign-changing, of some semi-linear elliptic problem with mixed nonlinear
boundary conditions. We establish the nonexistence of stable solutions, the
main methods used are the Pohozaev identity, monotonicity formula of solutions
together with a blowing down sequence.",http://arxiv.org/abs/2107.04999v1
Elementary amenability and almost finiteness,2021-07-12T09:15:07Z,"David Kerr, Petr Naryshkin","We show that every free continuous action of a countably infinite elementary
amenable group on a finite-dimensional compact metrizable space is almost
finite. As a consequence, the crossed products of minimal such actions are
$\mathcal{Z}$-stable and classified by their Elliott invariant.",http://arxiv.org/abs/2107.05273v2
Free-Text Keystroke Dynamics for User Authentication,2021-07-01T14:46:10Z,"Jianwei Li, Han-Chih Chang, Mark Stamp","In this research, we consider the problem of verifying user identity based on
keystroke dynamics obtained from free-text. We employ a novel feature
engineering method that generates image-like transition matrices. For this
image-like feature, a convolution neural network (CNN) with cutout achieves the
best results. A hybrid model consisting of a CNN and a recurrent neural network
(RNN) is also shown to outperform previous research in this field.",http://arxiv.org/abs/2107.07009v1
Exact inference from finite market data,2021-07-15T12:59:50Z,"Felix Kübler, Raghav Malhotra, Herakles Polemarchakis","We develop conditions under which individual choices and Walrasian
equilibrium prices and allocations can be exactly inferred from finite market
data. First, we consider market data that consist of individual demands as
prices and incomes change. Second, we show that finitely many observations of
individual endowments and associated Walrasian equilibrium prices, and only
prices, suffice to identify individual demands and, as a consequence,
equilibrium comparative statics.",http://arxiv.org/abs/2107.07294v1
"Cell mechanics and signalisation: SARS-CoV-2 hijacks membrane liquid
  crystals and cytoskeletal fractal topology",2021-07-15T17:44:39Z,"Christiane Binot, Jean-Francois Sadoc, Claude-Henri Chouard","We highlight changes to cell signalling under virus invasion (SARS-CoV-2),
involving disturbance of membranes and of nanodomains, modulated by the
cytoskeleton. Virus alters the mechanical properties of the membranes,
impairing mesophase structures mediated by the fractal architecture initiated
by actomyosin.",http://arxiv.org/abs/2107.07492v1
On Vizing's edge colouring question,2021-07-16T13:45:19Z,"Marthe Bonamy, Oscar Defrain, Tereza Klimošová, Aurélie Lagoutte, Jonathan Narboni","Soon after his 1964 seminal paper on edge colouring, Vizing asked the
following question: can an optimal edge colouring be reached from any given
proper edge colouring through a series of Kempe changes? We answer this
question in the affirmative for triangle-free graphs.",http://arxiv.org/abs/2107.07900v1
Some surfaces with canonical map of degree 4,2021-07-16T15:32:29Z,"Federico Fallucca, Roberto Pignatelli","In this short note we construct unbounded families of minimal surfaces of
general type with canonical map of degree 4 such that the limits of the slopes
assume countably many different values among 6+2/3 and 8.",http://arxiv.org/abs/2107.07966v3
"Design and Fabrication of a Microfluidic System with Nozzle/Diffuser
  Micropump and Viscosity",2021-07-17T17:07:37Z,Sumana Bhattacharjee,"Micropumps are one of the most important parts of a microfluidic system. In
particular, for biomedical applications such as Lab-on-Chip systems, micropumps
are used to transport and manipulate test fluids in a controlled manner. In
this work, a low-cost, structurally simple, piezoelectrically actuated
micropump was simulated and fabricated using poly-dimethylsiloxane (PDMS). The
channels in PDMS were fabricated using patterned SU-8 structures. The pump flow
rate was measured to be 9.49 uL/min, 14.06 uL/min, 20.87 uL/min for applied
voltages of 12 V, 14 V, 16 V respectively. Further, we report finite element
analysis (FEA) simulation to confirm the operation of the micropump and compare
favorably the experimentally obtained flowrate with the one predicted by
simulation. By taking these flow rates as a reference, the chamber pressure was
found to be 1.1 to 1.5 kPa from FEA simulations.
  Viscosity measurement has wide-ranging applications from the oil industry to
the pharmaceutical industry. This work provides an elaborate mathematical model
and study of measurement of viscosity in real-time using pressure sensors. For
a given flowrate, a change in liquid viscosity gives rise to a change in
pressure difference across a particular section of the pipe. Hence, by
recording the pressure change, viscosity can be calculated dynamically.
Mathematical modeling as well as finite element analysis (FEA) modeling has
been presented. A set of pressure sensors were placed at a fixed distance from
each other to get the real-time pressure change. Knowing the flow rate in the
channel, the viscosity has been calculated from the pressure difference. For
the finite element analysis, the pressure sensors were placed 60 mm away from
each other. A different ratio of the mixture of water and glycerol was used to
provide variable viscosity, which led to the variation in pressure-difference
values.",http://arxiv.org/abs/2107.08284v1
Stacky heights on elliptic curves in characteristic 3,2021-07-17T22:01:36Z,Aaron Landesman,"We show there are no stacky heights on the moduli stack of stable elliptic
curves in characteristic $3$ which induce the usual Faltings height, negatively
answering a question of Ellenberg, Satriano, and Zureick-Brown.",http://arxiv.org/abs/2107.08318v2
Instability of cumulation in converging cylindrical shock wave,2021-07-14T15:10:59Z,Sergey G. Chefranov,"The condition of linear instability for a converging cylindrical shock wave
in an arbitrary inviscid medium is obtained. The shape of resulting shock wave
front is not changed significantly, but the restriction of energy cumulation
can be caused by exponential grows of the medium rotation behind the front. The
correspondence with experimental and simulation data is considered.",http://arxiv.org/abs/2107.09201v2
Changes in Seasonal Upper Tropical Momentum Fluxes with Global Warming,2021-07-20T17:32:45Z,"Abu Bakar Siddiqui Thakur, Jai Sukhatme","The boreal summer tropical upper-tropospheric momentum budget involves a
balance between eddy and mean meridional fluxes. In winter, however, the eddy
flux itself acts to accelerate and decelerate the zonal flow in the Asian and
East Pacific regions, respectively. In a zonal mean sense, the residual of
these two is then balanced by the mean meridional flux. These features are
qualitatively captured by the CMIP6 suite of models in their control runs. With
warming, the CMIP6 ensemble shows that the flux budget changes in a
quantitative manner, in both the summer and winter seasons. Apart from the mean
meridional flux which is affected by the projected weakening of the Hadley
Cells, there are significant changes in eddy fluxes too. Notably, stationary
wave fluxes are affected in the Asian and East Pacific regions during the
summer and winter seasons, respectively. In the wintertime, extratropical wave
activity penetrating into the East Pacific almost shuts off due to a weakening
of the prevalent westerlies in the warming simulations. Whereas, in summer,
eddy fluxes in the Asian region are displaced upward and changes are observed
in the upper troposphere and lower stratosphere. Specifically, rotational flow
around the Asian summer anticyclone weakens in the upper troposphere while
strengthening in the lower stratosphere. Concomitantly, eddy flux convergence
over the equatorial Indian Ocean decreases in the former and increases (by a
larger amount) in the latter. In fact, strengthening of summertime tropical and
subtropical stationary waves in the lower stratosphere with warming is not
restricted to the Asian sector but is observed over all longitudes.
Effectively, the magnitude of all terms in the upper tropospheric momentum flux
budget decreases with warming, and an ensemble mean continues to yield a
marginally westward annual and zonal mean equatorial zonal flow.",http://arxiv.org/abs/2107.09646v1
"Local wellposedness for the free boundary incompressible Euler equations
  with interfaces that exhibit cusps and corners of nonconstant angle",2021-07-20T20:08:28Z,"Diego Córdoba, Alberto Enciso, Nastasia Grubic","We prove that free boundary incompressible Euler equations are locally well
posed in a class of solutions in which the interfaces can exhibit corners and
cusps. Contrary to what happens in all the previously known non-$C^1$ water
waves, the angle of these crests can change in time.",http://arxiv.org/abs/2107.09751v2
A Commentary on {\it The Knowledge Machine} by Michael Strevens,2021-07-24T20:27:00Z,Manuel Ortega-Rodríguez,"We offer a few comments derived from a careful reading of Michael Strevens'
book {\it The Knowledge Machine} (TKM), with an emphasis on extensions for
future work. We believe this book goes well beyond traditional accounts of
scientific change, and offers thus many insights into new research.",http://arxiv.org/abs/2107.11681v1
"No hyperbolic sets in J_\infty for infinitely renormalizable quadratic
  polynomials",2021-07-26T05:16:50Z,"Genadi Levin, Feliks Przytycki","Let f be an infinitely-renormalizable quadratic polynomial and J_\infty be
the intersection of forward orbits of ""small"" Julia sets of simple
renormalizations of f. We prove that J_\infty contains no hyperbolic sets.",http://arxiv.org/abs/2107.11962v2
Matrix Kloosterman sums,2021-09-02T07:57:29Z,"Márton Erdélyi, Árpád Tóth","We study a family of exponential sums that arises in the study of the
horocyclic flow on $\mathrm{GL}_n$. We prove an explicit version of general
purity and find optimal bounds for these sums.",http://arxiv.org/abs/2109.00762v4
"Cross-platform analysis of user comments in YouTube videos linked on
  Reddit conspiracy theory forum",2021-09-02T17:53:44Z,"Tomislav Duricic, Volker Seiser, Elisabeth Lex","We perform a cross-platform analysis in which we study how does linking
YouTube content on Reddit conspiracy forum impact language used in user
comments on YouTube. Our findings show a slight change in user language in that
it becomes more similar to language used on Reddit.",http://arxiv.org/abs/2109.01127v1
Existence of small ordered orthogonal arrays,2021-09-03T15:49:40Z,"Kai-Uwe Schmidt, Charlene Weiß","We show that there exist ordered orthogonal arrays, whose sizes deviate from
the Rao bound by a factor that is polynomial in the parameters of the ordered
orthogonal array. The proof is nonconstructive and based on a probabilistic
method due to Kuperberg, Lovett and Peled.",http://arxiv.org/abs/2109.01586v2
"Classification of irreducible $(\mathfrak{g},\mathfrak{k})$-modules
  associated to the ideals of minimal nilpotent orbits for simple Lie groups of
  type $A$",2021-09-08T04:53:54Z,Hiroyoshi Tamori,"We classify completely prime primitive ideals whose associated varieties are
the closure of the minimal nilpotent orbit of
$\mathfrak{g}=\mathfrak{sl}(n,\mathbb{C})$, and classify irreducible
$(\mathfrak{g},\mathfrak{k})$-modules which have those ideals as annihilators.
Moreover, we irreducibly decompose them as $\mathfrak{k}$-modules.",http://arxiv.org/abs/2109.03432v2
Quaternion matrix decomposition and its theoretical implications,2021-09-12T02:16:34Z,"Chang He, Bo Jiang, Xihua Zhu","This paper proposes a novel matrix rank-one decomposition for quaternion
Hermitian matrices, which admits a stronger property than the previous results
in (sturm2003cones,huang2007complex,ai2011new). The enhanced property can be
used to drive some improved results in joint numerical range,
$\mathcal{S}$-Procedure and quadratically constrained quadratic programming
(QCQP) in the quaternion domain, demonstrating the capability of our new
decomposition technique.",http://arxiv.org/abs/2109.05405v1
"Adapting the Tesseract Open-Source OCR Engine for Tamil and Sinhala
  Legacy Fonts and Creating a Parallel Corpus for Tamil-Sinhala-English",2021-09-13T13:26:30Z,"Charangan Vasantharajan, Laksika Tharmalingam, Uthayasanker Thayasivam","Most low-resource languages do not have the necessary resources to create
even a substantial monolingual corpus. These languages may often be found in
government proceedings but mainly in Portable Document Format (PDF) that
contains legacy fonts. Extracting text from these documents to create a
monolingual corpus is challenging due to legacy font usage and printer-friendly
encoding, which are not optimized for text extraction. Therefore, we propose a
simple, automatic, and novel idea that can scale for Tamil, Sinhala, English
languages, and many documents along with parallel corpora. Since Tamil and
Sinhala are Low-Resource Languages, we improved the performance of Tesseract by
employing LSTM-based training on more than 20 legacy fonts to recognize printed
characters in these languages. Especially, our model detects code-mixed text,
numbers, and special characters from the printed document. It is shown that
this approach can reduce the character-level error rate of Tesseract from 6.03
to 2.61 for Tamil (-3.42% relative change) and 7.61 to 4.74 for Sinhala (-2.87%
relative change), as well as the word-level error rate from 39.68 to 20.61 for
Tamil (-19.07% relative change) and 35.04 to 26.58 for Sinhala (-8.46% relative
change) on the test set. Also, our newly created parallel corpus consists of
185.4k, 168.9k, and 181.04k sentences and 2.11M, 2.22M, and 2.33M Words in
Tamil, Sinhala, and English respectively. This study shows that fine-tuning
Tesseract models on multiple new fonts help to understand the texts and
enhances the performance of the OCR. We made newly trained models and the
source code for fine-tuning Tesseract, freely available.",http://arxiv.org/abs/2109.05952v3
Moduli of genus one curves with two marked points as a weighted blow-up,2021-09-14T05:35:10Z,Giovanni Inchiostro,"We give an explicit description of $\overline{\mathcal{M}}_{1,2}$ as a
weighted blow-up of a weighted projective stack. We use this description to
compute the Brauer group of $\overline{\mathcal{M}}_{1,2;S}$ over any base
scheme $S$ where 6 is invertible, and the integral Chow rings of
$\overline{\mathcal{M}}_{1,2}$ and $\mathcal{M}_{1,2}$.",http://arxiv.org/abs/2109.06451v2
"The Enduring Effects of COVID-19 on Travel Behavior in the United
  States: A Panel Study on Observed and Expected Changes in Telecommuting, Mode
  Choice, Online Shopping and Air Travel",2021-09-16T13:56:49Z,"Mohammadjavad Javadinasr, Tassio B. Magassy, Ehsan Rahimi, Motahare, Mohammadi, Amir Davatgari, Abolfazl, Mohammadian, Deborah Salon, Matthew Wigginton Bhagat-Conway, Rishabh Singh Chauhan, Ram M. Pendyala, Sybil Derrible, Sara Khoeini","The explosive nature of Covid-19 transmission drastically altered the rhythm
of daily life by forcing billions of people to stay at their homes. A critical
challenge facing transportation planners is to identify the type and the extent
of changes in people's activity-travel behavior in the post-pandemic world. In
this study, we investigated the travel behavior evolution by analyzing a
longitudinal two-wave panel survey data conducted in the United States from
April 2020 to October 2020 (wave 1) and from November 2020 to May 2021(wave 2).
Encompassing nearly 3,000 respondents across different states, we explored
pandemic-induced changes and underlying reasons in four major categories of
telecommute/telemedicine, commute mode choice, online shopping, and air travel.
Upon concrete evidence, our findings substantiate significantly observed and
expected changes in habits and preferences. According to results, nearly half
of employees anticipate having the alternative to telecommute and among which
71% expect to work from home at least twice a week after the pandemic. In the
post-pandemic period, auto and transit commuters are expected to be 9% and 31%
less than pre-pandemic, respectively. A considerable rise in hybrid work and
grocery/non-grocery online shopping is expected. Moreover, 41% of pre-covid
business travelers expect to have fewer flights (after the pandemic) while only
8% anticipate more, compared to the pre-pandemic. Upon our analyses, we discuss
a spectrum of policy implications in all mentioned areas.",http://arxiv.org/abs/2109.07988v1
"Special holomorphic tensors on orthogonal modular varieties and
  applications to the Lang conjecture",2021-09-22T15:48:17Z,Shouhei Ma,"We introduce a method to construct special holomorphic tensors on orthogonal
modular varieties from scalar-valued modular forms, and give applications to
the Lang conjecture on the birational type of subvarieties of orthogonal
modular varieties.",http://arxiv.org/abs/2109.10801v2
"Hydrodynamic approach justified for low-temperature transport in
  Ioffe-Regel limit metal",2021-09-28T19:39:39Z,M. V. Cheremisin,"The highly disordered metals dropped into Ioffe-Regel transport regime at low
temperatures match unexpectedly the hydrodynamic criteria of the shortest
length scale entered the kinematic viscosity. Numerous hydrodynamic phenomena,
therefore, could be of reality in this case.",http://arxiv.org/abs/2109.14005v2
"Classification of homogeneous hypersurfaces in some noncompact symmetric
  spaces of rank two",2021-09-29T13:02:52Z,Ivan Solonenko,"We classify, up to isometric congruence, the homogeneous hypersurfaces in the
Riemannian symmetric spaces $\mathrm{SL}(3,\mathbb{H})/\mathrm{Sp}(3),
\hspace{1pt} \mathrm{SO}(5,\mathbb{C})/\mathrm{SO}(5),$ and
$\mathrm{Gr}^*(2,\mathbb{C}^{n+4}) =
\mathrm{SU}(n+2,2)/\mathrm{S}(\mathrm{U}(n+2)\mathrm{U}(2)), \, n \geqslant 1$.",http://arxiv.org/abs/2109.14399v2
Extended double covers of non-symmetric association schemes of class $2$,2021-09-30T02:26:13Z,"Takuya Ikuta, Akihiro Munemasa","In this paper, we give a method to construct non-symmetric association
schemes of class $3$ from non-symmetric association schemes of class $2$. This
construction is a non-symmetric analogue of the construction of Taylor graphs
as an antipodal double cover of a complete graph. We also mention how our
construction interact with doubling introduced by Pasechnik.",http://arxiv.org/abs/2109.14810v2
Developments since Kira 2.0,2021-11-01T15:51:02Z,"Fabian Lange, Philipp Maierhöfer, Johann Usovitsch","Last year we released version 2.0 of the Feynman integral reduction program
Kira. In this contribution we first report on changes and new features since
then and, secondly, on new features for upcoming releases.",http://arxiv.org/abs/2111.01045v1
Cubulating Small Cancellation Free Products,2021-11-06T19:47:13Z,"Kasia Jankiewicz, Daniel T. Wise","We give a simplified approach to the cubulation of small-cancellation
quotients of free products of cubulated groups. We construct fundamental groups
of compact nonpositively curved cube complexes that do not virtually split.",http://arxiv.org/abs/2111.03948v2
"Comment on ""Using an atom interferometer to infer gravitational
  entanglement generation''",2021-11-08T17:34:31Z,"Daniel Carney, Holger Muller, Jacob M. Taylor","Our paper arXiv:2101.11629 contains a technical error which changes some of
the conclusions. We thank Streltsov, Pedernales, and Plenio for bringing the
essence of this error to our attention. Here we explain the error, examine its
consequences, and suggest methods to overcome the resulting weakness in the
proposed experiment.",http://arxiv.org/abs/2111.04667v1
Small perturbations on means and quasi-means,2021-11-06T12:16:07Z,Attila Losonczi,"We start to investigate how small changes on the definition of ordinary means
affect their properties. Especially the property of being a mean. In that
direction we are looking for weakenings of the basic defining property of
means. Hence we introduce weaker notions in two directions. We investigate such
functions and provide many examples as well.",http://arxiv.org/abs/2111.04729v3
Singular Hermitian metrics with isolated singularities,2021-11-09T14:31:56Z,Takahiro Inayama,"In this paper, we study the coherence of a higher rank analogue of a
multiplier ideal sheaf. Key tools of the study are H\""ormander's $L^2$-estimate
and a singular version of a Demailly--Skoda type result.",http://arxiv.org/abs/2111.05172v2
Subelliptic operators on weighted Folland-Stein spaces,2021-11-10T09:48:39Z,Hung-Lin Chiu,"In this paper, we show that the sub-Laplacian of an asymptotically flat
pseudo-hermitian manifold defined on a suitable weighted Folland-Stein spaces
is an isomorphism. It turns out that the CR positive mass problem is resolved,
and hence CR Yamabe problem.",http://arxiv.org/abs/2111.05601v2
Automatically detecting data drift in machine learning classifiers,2021-11-10T12:34:14Z,"Samuel Ackerman, Orna Raz, Marcel Zalmanovici, Aviad Zlotnick","Classifiers and other statistics-based machine learning (ML) techniques
generalize, or learn, based on various statistical properties of the training
data. The assumption underlying statistical ML resulting in theoretical or
empirical performance guarantees is that the distribution of the training data
is representative of the production data distribution. This assumption often
breaks; for instance, statistical distributions of the data may change. We term
changes that affect ML performance `data drift' or `drift'.
  Many classification techniques compute a measure of confidence in their
results. This measure might not reflect the actual ML performance. A famous
example is the Panda picture that is correctly classified as such with a
confidence of about 60\%, but when noise is added it is incorrectly classified
as a Gibbon with a confidence of above 99\%. However, the work we report on
here suggests that a classifier's measure of confidence can be used for the
purpose of detecting data drift.
  We propose an approach based solely on classifier suggested labels and its
confidence in them, for alerting on data distribution or feature space changes
that are likely to cause data drift. Our approach identities degradation in
model performance and does not require labeling of data in production which is
often lacking or delayed. Our experiments with three different data sets and
classifiers demonstrate the effectiveness of this approach in detecting data
drift. This is especially encouraging as the classification itself may or may
not be correct and no model input data is required. We further explore the
statistical approach of sequential change-point tests to automatically
determine the amount of data needed in order to identify drift while
controlling the false positive rate (Type-1 error).",http://arxiv.org/abs/2111.05672v1
Deforming integrable models of AdS$_3$ strings,2021-11-14T21:23:16Z,Jacek Pawelczyk,"We discuss an integrable model of string on AdS$_3$xS$^3$xT$^4$ in a
thermodynamical bath. We show that scattering of the excitations above
equilibrium states has some novel features. Thermodynamics points to
interesting deformation of the original model for which we discuss finite size
effect through mirror TBA equations.",http://arxiv.org/abs/2111.07453v2
"Dependence of total kinetic energy of fission fragments on the
  excitation energy of fissioning systems",2021-11-16T07:56:52Z,"Kazuya Shimada, Chikako Ishizuka, Fedir A. Ivanyuk, Satoshi Chiba","We elucidated the reason why the average total kinetic energy (TKE) of
fission fragments decreases when the excitation energy of the fissioning
systems increases as indicated by experimental data for the neutron-induced
fission events. To explore this problem, we used a method based on the
four-dimensional Langevin equations we have developed. We have calculated the
TKE of fission fragments for fissioning systems $^{236}$U$^{*}$ and
$^{240}$Pu$^{*}$ excited above respective fission barriers, and compared the
results with experimental data for n + $^{235}$U and n + $^{239}$Pu reactions,
respectively. From the Langevin-model analysis, we have found that the shape of
the abundant heavy fragments changes from almost spherical for low excitation
domain to highly prolate shape for high excitation energy, while that of the
light fragments does not change noticeably. The change of the ""shape"" of the
heavy fragments causes an increase of a distance between the charge centers of
the nascent fragments just after scission as excitation energy increases.
Accordingly, the Coulomb repulsion between the two fragments decreases with an
increase of the excitation energy, which causes the decrease of the average
TKE. In this manner, we found that the change of the shape of the heavy
fragment as a function of the excitation energy is the key issue for the TKE of
fission fragments to decrease as the excitation energy of the fissioning nuclei
increases. In other words, washing out of the shell effects which affect the
shape of the heavy fragments is the key reason for the decreasing energy
dependence of the average TKE of the fission fragments.",http://arxiv.org/abs/2111.08278v1
Conjectures on the Kodaira dimension,2021-11-21T21:33:31Z,Mihnea Popa,"I propose a few increasingly stronger ""superadditivity"" conjectures regarding
the behavior of Kodaira dimension under morphisms of smooth quasi-projective
complex varieties.",http://arxiv.org/abs/2111.10900v3
Higher Algebraic Structures and General Field Theories,2021-11-17T12:58:21Z,Nils A. Baas,"In this paper we show how the hyperstructure concept leads to new algebraic
structures and general field theories.",http://arxiv.org/abs/2111.11205v4
A metric analogue of Hartogs' theorem,2021-11-23T17:35:11Z,"Hervé Gaussier, Andrew Zimmer","In this paper we prove a metric version of Hartogs' theorem where the
holomorphic function is replaced by a locally symmetric Hermitian metric. As an
application, we prove that if the Kobayashi metric on a strongly pseudoconvex
domain with $\mathcal{C}^2$ smooth boundary is a K\""ahler metric, then the
universal cover of the domain is the unit ball.",http://arxiv.org/abs/2111.12029v2
"Local X-ray Transform on Asymptotically Hyperbolic Manifolds via
  Projective Compactification",2021-11-26T17:47:28Z,"Nikolas Eptaminitakis, C. Robin Graham","We prove local injectivity near a boundary point for the geodesic X-ray
transform for an asymptotically hyperbolic metric even mod $O(\rho^5)$ in
dimensions three and higher.",http://arxiv.org/abs/2111.13631v2
Quantum computational advantage implies contextuality,2021-11-30T19:00:02Z,Farid Shahandeh,"We show that a separation between the class of all problems that can
efficiently be solved on a quantum computer and those solvable using
probabilistic classical algorithms in polynomial time implies the generalized
contextuality of quantum algorithms. Our result subsumes versions of
Gottesman-Knill theorem as special cases.",http://arxiv.org/abs/2112.00024v2
Rectifiability; a survey,2021-12-01T14:58:43Z,Pertti Mattila,"This is a survey on rectifiability. I discuss basic properties of rectifiable
sets, measures, currents and varifolds and their role in complex and harmonic
analysis, potential theory, calculus of variations, PDEs and some other topics.",http://arxiv.org/abs/2112.00540v3
Efficient Calling Conventions for Irregular Architectures,2021-12-02T16:35:41Z,Philipp K. Krause,"We empirically evaluated thousands of different C calling conventions for
irregular microcontroller architectures, and found potential for improvement
over the calling conventions previously used in the Small Device C Compiler
(SDCC). The improvements in code size and speed are substantial enough that
SDCC made changes to its default calling convention, breaking ABI
compatibility.",http://arxiv.org/abs/2112.01397v2
On the Gaussian surface area of spectrahedra,2021-12-02T18:04:27Z,"Srinivasan Arunachalam, Oded Regev, Penghui Yao","We show that for sufficiently large $n\geq 1$ and $d=C n^{3/4}$ for some
universal constant $C>0$, a random spectrahedron with matrices drawn from
Gaussian orthogonal ensemble has Gaussian surface area $\Theta(n^{1/8})$ with
high probability.",http://arxiv.org/abs/2112.01463v2
On equisingular approximation of plurisubharmonic functions,2021-12-04T12:27:32Z,"Jongbong An, Hoseob Seo","It is a natural question to ask which plurisubharmonic functions admit a
'nice' approximation in the sense of a decreasing equisingular approximation
with analytic singularities. For arbitrary toric plurisubharmonic functions, we
give a criterion for admitting a nice approximation with toric approximants.
Our results are motivated by a recent result of Guan for toric plurisubharmonic
functions of the diagonal type.",http://arxiv.org/abs/2112.02318v2
"The Pantheon+ Analysis: SuperCal-Fragilistic Cross Calibration,
  Retrained SALT2 Light Curve Model, and Calibration Systematic Uncertainty",2021-12-07T17:57:24Z,"Dillon Brout, Georgie Taylor, Dan Scolnic, Charlotte M. Wood, Benjamin M. Rose, Maria Vincenzi, Arianna Dwomoh, Christopher Lidman, Adam Riess, Noor Ali, Helen Qu, Mi Dai","We present here a re-calibration of the photometric systems used in the
Pantheon+ sample of Type Ia supernovae (SNe Ia) including those used for the
SH0ES distance-ladder measurement of H$_0$. We utilize the large and uniform
sky coverage of the public Pan-STARRS stellar photometry catalog to
cross-calibrate against tertiary standards released by individual SN Ia
surveys. The most significant updates over the `SuperCal' cross-calibration
used for the previous Pantheon and SH0ES analyses are: 1) expansion of the
number of photometric systems (now 25) and filters (now 105), 2) solving for
all filter offsets in all systems simultaneously in order to produce a
calibration uncertainty covariance matrix that can be used in
cosmological-model constraints, and 3) accounting for the change in the
fundamental flux calibration of the HST CALSPEC standards from previous
versions on the order of $1.5\%$ over a $\Delta \lambda$ of 4000~\AA. The
re-calibration of samples used for light-curve fitting has historically been
decoupled from the retraining of the light-curve model. Here, we are able to
retrain the SALT2 model using this new calibration and find the change in the
model coupled with the change to the calibration of the light-curves themselves
causes a net distance modulus change ($d\mu/dz$) of 0.04 mag over the redshift
range $0<z<1$. We introduce a new formalism to determine the systematic impact
on cosmological inference by propagating the covariance in fitted calibration
offsets through retraining simultaneously with light-curve fitting and find a
total calibration uncertainty impact of $\sigma_w=0.013$, which is roughly half
the size of the sample statistical uncertainty. Similarly, we find a systematic
SN calibration contribution to the SH0ES H$_0$ uncertainty is less than
0.2~km/s/Mpc, suggesting that SN Ia calibration cannot resolve the current
level of the `Hubble Tension'.",http://arxiv.org/abs/2112.03864v2
"GPU-accelerated image alignment for object detection in industrial
  applications",2021-12-10T14:43:24Z,"Trung-Son Le, Chyi-Yeu Lin","This research proposes a practical method for detecting featureless objects
by using image alignment approach with a robust similarity measure in
industrial applications. This similarity measure is robust against occlusion,
illumination changes and background clutter. The performance of the proposed
GPU (Graphics Processing Unit) accelerated algorithm is deemed successful in
experiments of comparison between both CPU and GPU implementations",http://arxiv.org/abs/2112.05576v1
Geometric energy transfer in two-component systems,2021-12-16T08:30:40Z,"Ryan Requist, Chen Li, E. K. U. Gross","Factoring a wave function into marginal and conditional factors partitions
the subsystem kinetic energy into two terms. The first depends solely on the
marginal wave function, through its gauge-covariant derivative, while the
second depends on the quantum metric of the conditional wave function over the
manifold of marginal variables. We derive an identity for the rate of change of
the second term.",http://arxiv.org/abs/2112.08694v1
"Large deviations principle for terminating multidimensional compound
  renewal processes with application to polymer pinning models",2021-12-17T17:27:35Z,"A. Logachov, A. Mogulskii, E. Prokopenko","Large deviations principle is obtained for terminating multidimensional
compound renewal processes. We also obtained the asymptotic of large deviations
for the case when a Gibbs change of the original probability measure takes
place. The random processes mentioned in the paper are widely used in polymer
pinning models.",http://arxiv.org/abs/2112.09640v1
Plasma dynamics in the flaring loop observed by RHESSI,2021-12-21T17:52:23Z,"T. Mrozek, R. Falewicz, S. Kolomanski, M. Litwicka","The thick-target model predicts that in flare foot points, we should observe
lowering of HXR sources' altitude with increasing energy. The foot point of HXR
sources result from the direct interaction of non-thermal electron beams with
plasma in the lower part of the solar atmosphere, where the density increases
rapidly. Therefore, we can estimate the plasma density distribution along the
non-thermal electron beam directly from the observations of the altitude-energy
relation obtained for the HXR foot point sources. The relation's shape is
density-dependent and is also determined by the power-law distribution of
non-thermal electrons. Additionally, during the impulsive phase these
parameters may change dramatically. Thus, the interpretation of observed HXR
foot point sources' altitudes is not straightforward and needs detailed
numerical modelling of the electron precipitation process. The numerical model
was calculated using the hydrodynamic 1D model with an application of the
Fokker-Planck formalism for non-thermal beam precipitation. HXR data from
RHESSI were used to trace chromospheric density changes during a non-thermal
emission burst, in detail. We have found that the amount of mass that
evaporated from the chromosphere is in good agreement with the ranges obtained
from hydrodynamical modelling of a flaring loop, and from an analysis of
observed emission measure in the loop top, and with specific scaling laws.
Consistency between the obtained values shows that HXR images may provide an
important constraint for models - a mass of plasma that evaporated due to a
non-thermal electron beam depositing energy in the chromosphere. High-energy,
non-thermal sources' (above 20 keV in this case) positions fit the column
density changes obtained from the hydrodynamical model perfectly. Density
changes seem to be less affected by the electrons' spectral index.",http://arxiv.org/abs/2112.11392v1
Gromov-Witten Theory of $A_n$ type quiver varieties and Seiberg Duality,2021-12-22T11:35:15Z,Yingchun Zhang,"Seiberg duality conjecture asserts that the Gromov-Witten theories (Gauged
Linear Sigma Models) of two quiver varieties related by quiver mutations are
equal via variable change. In this work, we prove this conjecture for $A_n$
type quiver varieties.",http://arxiv.org/abs/2112.11812v3
Arithmetic statistics for the Fine Selmer group in Iwasawa theory,2021-12-26T08:59:28Z,"Anwesh Ray, R. Sujatha","We study arithmetic statistics for Iwasawa invariants for fine Selmer groups
associated to elliptic curves.",http://arxiv.org/abs/2112.13335v2
Visual Place Representation and Recognition from Depth Images,2021-12-27T14:31:24Z,"Farah Ibelaiden, Slimane Larabi","This work proposes a new method for place recognition based on the scene
architecture. From depth video, we compute the 3D model and we derive and
describe geometrically the 2D map from which the scene descriptor is deduced to
constitute the core of the proposed algorithm. The obtained results show the
efficiency and the robustness of the propounded descriptor to scene appearance
changes and light variations.",http://arxiv.org/abs/2112.13707v1
Entanglement of Purification for Momentum Relaxed Superconductor,2021-12-28T11:18:49Z,"I-Hsi Chen, Po-Shuo Huang, Shang-Yu Wu","We reconstruct the information quantities in the holographic relaxed
superconductor system and discuss how these quantities behave under
non-symmetry configuration. We then combine the effect of the superconductor
and the momentum relaxation, and find out that the superconductor effect will
change how the momentum relaxation affect these information quantities.",http://arxiv.org/abs/2112.14092v1
How do exponential size solutions arise in semidefinite programming?,2021-02-26T20:32:10Z,"Gábor Pataki, Aleksandr Touzov","A striking pathology of semidefinite programs (SDPs) is illustrated by a
classical example of Khachiyan: feasible solutions in SDPs may need exponential
space even to write down. Such exponential size solutions are the main obstacle
to solve a long standing, fundamental open problem: can we decide feasibility
of SDPs in polynomial time?
  The consensus seems that SDPs with large size solutions are rare. However,
here we prove that they are actually quite common: a linear change of variables
transforms every strictly feasible SDP into a Khachiyan type SDP, in which the
leading variables are large. As to ``how large"", that depends on the
singularity degree of a dual problem. Further, we present some SDPs coming from
sum-of-squares proofs, in which large solutions appear naturally, without any
change of variables. We also partially answer the question: how do we represent
such large solutions in polynomial space?",http://arxiv.org/abs/2103.00041v2
"Repeated Games with Switching Costs: Stationary vs History Independent
  Strategies",2021-02-26T20:39:32Z,"Yevgeny Tsodikovich, Xavier Venel, Anna Zseleva","We study zero-sum repeated games where the minimizing player has to pay a
certain cost each time he changes his action. Our contribution is twofold.
First, we show that the value of the game exists in stationary strategies,
depending solely on the previous action of the minimizing player, not the
entire history. We provide a full characterization of the value and the optimal
strategies. The strategies exhibit a robustness property and typically do not
change with a small perturbation of the switching costs. Second, we consider a
case where the minimizing player is limited to playing simpler strategies that
are completely history-independent. Here too, we provide a full
characterization of the (minimax) value and the strategies for obtaining it.
Moreover, we present several bounds on the loss due to this limitation.",http://arxiv.org/abs/2103.00045v3
"Spatial control of extreme ultraviolet light with opto-optical phase
  modulation",2021-02-27T11:49:42Z,"Anna Olofsson, Emma Rose Simpson, Neven Ibrakovic, Samuel Bengtsson, Johan Mauritsson","Extreme-ultraviolet (XUV) light is notoriously difficult to control due to
its strong interaction cross-section with media. We demonstrate a method to
overcome this problem by using Opto-Optical Modulation guided by a geometrical
model to shape XUV light. A bell-shaped infrared light pulse is shown to
imprint a trace of its intensity profile onto the XUV light in the far-field,
such that a change in the intensity profile of the infrared pulse leads to a
change in the shape of the far-field XUV light. The geometrical model assists
the user in predicting the effect of a specific intensity profile of the
infrared pulse, thus enabling a deterministic process.",http://arxiv.org/abs/2103.00197v1
"Toward cubic symmetry for Ir$^{4+}$: structure and magnetism of
  antifluorite K$_2$IrBr$_6$",2021-02-27T12:59:01Z,"Nazir Khan, Danil Prishchenko, Mary H. Upton, Vladimir G. Mazurenko, Alexander A. Tsirlin","Crystal structure, electronic state of Ir$^{4+}$, and magnetic properties of
the antifluorite compound K$_2$IrBr$_6$ are studied using high-resolution
synchrotron x-ray diffraction, resonant inelastic x-ray scattering (RIXS),
thermodynamic and transport measurements, and ab initio calculations. The
crystal symmetry is reduced from cubic at room temperature to tetragonal below
170 K and eventually to monoclinic below 122 K. These changes are tracked by
the evolution of the non-cubic crystal-field splitting $\Delta$ measured by
RIXS. Non-monotonic changes in $\Delta$ are ascribed to the competing effects
of the tilt, rotation, and deformation of the IrBr$_6$ octahedra as well as
tetragonal strain on the electronic levels of Ir$^{4+}$. The N\'eel temperature
of $T_N=11.9$ K exceeds that of the isostructural K$_2$IrCl$_6$, and the
magnitude of frustration on the fcc spin lattice decreases. We argue that the
replacement of Cl by Br weakens electronic correlations and enhances magnetic
couplings.",http://arxiv.org/abs/2103.00206v2
Generalized Current-State Opacity With Dynamically Changing Secrets,2021-02-27T14:53:24Z,"Dan You, Shouguang Wang, Carla Seatzu","Opacity, an information-flow property related to the privacy and security of
a system, has been extensively studied in the context of discrete event
systems. Although various notions of opacity have been proposed, in all cases
the considered secret was constant. This work focuses on current-state opacity,
considering a scenario where the secret changes dynamically with the system
evolution. In other words, we propose the new notion of generalized
current-state opacity (GCSO), which is with respect to a dynamic-secret model
rather than a constant secret. Moreover, we provide a method to verify GCSO
based on the construction of the GCSO-verifier. Finally, a practical example is
given to illustrate the proposed notion and the method for its verification.",http://arxiv.org/abs/2103.00234v1
Proton irradiation effects on metal-YBCO interfaces,2021-02-27T23:09:11Z,"C. Acha, G. A. Sanca, M. Barella, M. Alurralde, F. Gomez Marlasca, H. Huhtinen, P. Paturi, F. Golmar, P. Levy","10 MeV proton-irradiation effects on a YBCO-based test structure were
analyzed by measuring its current-voltage (IV) characteristics for different
cumulated fluences. For fluences of up to $\sim$80$\cdot$10$^9$~p/cm$^2$ no
changes in the electrical behavior of the device were observed, while for a
fluence of $\sim$~300$\cdot$10$^9~$ p/cm$^2$ it becomes less conducting. A
detailed analysis of the room temperature IV characteristics based on the
$\gamma$ power exponent parameter [$\gamma=dLn(I)/dLn(V)$] allowed us to reveal
the main conduction mechanisms as well as to establish the equivalent circuit
model of the device. The changes produced in the electrical behavior, in
accordance with Monte Carlo TRIM simulations, suggest that the main effect
induced by protons is the displacement of oxygen atoms within the YBCO lattice,
particularly from oxygen-rich to oxygen-poor areas, where they become trapped.",http://arxiv.org/abs/2103.00350v1
"Topology change, emergent symmetries and compact star matter",2021-03-01T04:21:59Z,"Yong-Liang Ma, Mannque Rho","Topology effects have being extensively studied and confirmed in strongly
correlated condensed matter physics. In the large color number limit of QCD,
baryons can be regarded as topological objects -- skyrmions -- and the baryonic
matter can be regarded as a skyrmion matter. We review in this paper the
generalized effective field theory for dense compact-star matter constructed
with the robust inputs obtained from the skyrmion approach to dense nuclear
matter, relying to possible ``emergent"" scale and local flavor symmetries at
high density. All nuclear matter properties from the saturation density $n_0$
up to several times $n_0$ can be fairly well described. A uniquely novel -- and
unorthdox -- feature of this theory is the precocious appearance of the
pseudo-conformal sound velocity $v^2_{s}/c^2 \approx 1/3$, with the
non-vanishing trace of the energy momentum tensor of the system. The topology
change encoded in the density scaling of low energy constants is interpreted as
the quark-hadron continuity in the sense of Cheshire Cat Principle (CCP) at
density $\gsim 2n_0$ in accessing massive compact stars. We confront the
approach with the data from GW170817 and GW190425.",http://arxiv.org/abs/2103.00744v2
"TwoPhaseFlow: An OpenFOAM based framework for development of two phase
  flow solvers",2021-03-01T09:40:26Z,"Henning Scheufler, Johan Roenby","One of the prevailing challenges in Computational Fluid Dynamics is accurate
simulation of two-phase flows involving heat and mass transfer across the fluid
interface. This is currently an active field of research, which is to some
extend impaired by a lack of a common programming framework for implementing
and testing new models. Here we present a new OpenFOAM based open-source
framework allowing fast implementation and test of new phase change and surface
tension force models. Capitalizing on the runtime-selection mechanism in
OpenFOAM, the new models can easily be selected and compared to analytical
solutions and existing models. As a start, the framework includes the following
curvature calculation methods for surface tension: height function, parabolic
fit, and reconstructed distance function method. As for phase change, interface
heat resistance and direct heat flux models are available. These can be
combined with three solvers covering the range from isothermal, incompressible
flow to non-isothermal, compressible flow with conjugated heat transfer. By
design, addition of new models and solvers is straightforward and users are
invited to contribute their specific models, solvers, and validation cases to
the library.",http://arxiv.org/abs/2103.00870v1
Non-specular reflection by a planar resonant metasurface,2021-03-01T13:57:08Z,"Sergey L Prosvirnin, Vyacheslav V Khardikov, Kateryna L Domina, Olexandr A Maslovskiy, Ludmila A Kochetova, Vladimir V Yachin","An uncommon double-ray scenario of light resonant scattering by a periodic
metasurface is proposed to provide strong non-specular reflection. The
metasurface is constracted as an array of silicon nanodisks placed on thin
silica-on-metal substrate. A low-lossy non-specular resonant reflection for any
direction and any polarization of incident wave is revealed by a numerical
simulation of light scattering. The conditions for the implementation of an
autocollimation scheme of scattering and the observation of non-specular
reflected ray that does not lie in the incidence plane are worked out. It is
shown that the change of dielectric substrate thickness may be applied to set
the width of frequency band of non-specular reflection. The light intensity
related to the specular and non-specular reflected ray can be controlled by
changing the angle of incidence or by the polarization of incident wave.",http://arxiv.org/abs/2103.01010v2
Software Development with Scrum: A Bibliometric Analysis and Profile,2021-03-01T16:02:31Z,"Peter Kokol. Sašo Zagoranski, Marko Kokol","Introduction of the Scrum approach into software engineering has changed the
way software is being developed. The Scrum approach emphasizes the active
end-user involvement, embracing of change, and /iterative delivery of products.
Our study showed that Scrum has different variants or is used in combination
with different methods. Some tools not normally used in the conventional
software approaches, like gamification, content analysis and grounded theory
are also employed. However, Scrum like other software development approach
focuses on improvement of software process, software quality, business value,
performance, usability and efficiency and at the same time to reduce cost, risk
and uncertainty. Contrary to some conventional approaches it also strives to
boost soft factors like agility, trust, motivation, responsibility and
transparency. The bibliometric synthetic scoping study revealed seven main
research themes concerned with the Scrum research.",http://arxiv.org/abs/2103.01095v1
Non-invariance of the Brauer-Manin obstruction for surfaces,2021-03-02T14:51:50Z,Han Wu,"In this paper, we study the properties of weak approximation with
Brauer-Manin obstruction and the Hasse principle with Brauer-Manin obstruction
for surfaces with respect to field extensions of number fields. We assume a
conjecture of M. Stoll. For any nontrivial extension of number fields $L/K,$ we
construct two kinds of smooth, projective, and geometrically connected surfaces
defined over $K.$ For the surface of the first kind, it has a $K$-rational
point, and satisfies weak approximation with Brauer-Manin obstruction off
$\infty_K,$ while its base change by $L$ does not so off $\infty_L.$ For the
surface of the second kind, it is a counterexample to the Hasse principle
explained by the Brauer-Manin obstruction, while the failure of the Hasse
principle of its base change by $L$ cannot be so. We illustrate these
constructions with explicit unconditional examples.",http://arxiv.org/abs/2103.01784v3
"Can Program Synthesis be Used to Learn Merge Conflict Resolutions? An
  Empirical Analysis",2021-03-02T19:56:07Z,"Rangeet Pan, Vu Le, Nachiappan Nagappan, Sumit Gulwani, Shuvendu Lahiri, Mike Kaufman","Forking structure is widespread in the open-source repositories and that
causes a significant number of merge conflicts. In this paper, we study the
problem of textual merge conflicts from the perspective of Microsoft Edge, a
large, highly collaborative fork off the main Chromium branch with significant
merge conflicts. Broadly, this study is divided into two sections. First, we
empirically evaluate textual merge conflicts in Microsoft Edge and classify
them based on the type of files, location of conflicts in a file, and the size
of conflicts. We found that ~28% of the merge conflicts are 1-2 line changes,
and many resolutions have frequent patterns. Second, driven by these findings,
we explore Program Synthesis (for the first time) to learn patterns and resolve
structural merge conflicts. We propose a novel domain-specific language (DSL)
that captures many of the repetitive merge conflict resolution patterns and
learn resolution strategies as programs in this DSL from example resolutions.
We found that the learned strategies can resolve 11.4% of the conflicts (~41%
of 1-2 line changes) that arise in the C++ files with 93.2% accuracy.",http://arxiv.org/abs/2103.02004v1
"A Computational Design and Evaluation Tool for 3D Structures with Planar
  Surfaces",2021-03-03T01:15:21Z,"Chang Liu, Wenzhong Yan, Pehuen Moure, Cody Fan, Ankur Mehta","Three dimensional (3D) structures composed of planar surfaces can be build
out of accessible materials using easier fabrication technique with shorter
fabrication time. To better design 3D structures with planar surfaces,
realistic models are required to understand and evaluate mechanical behaviors.
Existing design tools are either effort-consuming (e.g. finite element
analysis) or bounded by assumptions (e.g. numerical solutions). In this
project, We have built a computational design tool that is (1) capable of
rapidly and inexpensively evaluating planar surfaces in 3D structures, with
sufficient computational efficiency and accuracy; (2) applicable to complex
boundary conditions and loading conditions, both isotropic materials and
orthotropic materials; and (3) suitable for rapid accommodation when design
parameters need to be adjusted. We demonstrate the efficiency and necessity of
this design tool by evaluating a glass table as well as a wood bookcase, and
iteratively designing an origami gripper to satisfy performance requirements.
This design tool gives non-expert users as well as engineers a simple and
effective modus operandi in structural design.",http://arxiv.org/abs/2103.02114v1
Real Time Vigilance Detection using Frontal EEG,2021-03-03T04:31:39Z,"Siddarth Ganesh, Ram Gurumoorthy","Vigilance of an operator is compromised in performing many monotonous
activities like workshop and manufacturing floor tasks, driving, night shift
workers, flying, and in general any activity which requires keen attention of
an individual over prolonged periods of time. Driver or operator fatigue in
these situations leads to drowsiness and lowered vigilance which is one of the
largest contributors to injuries and fatalities amongst road accidents or
workshop floor accidents. Having a vigilance monitoring system to detect drop
in vigilance in these situations becomes very important.
  This paper presents a system which uses non-invasively recorded Frontal EEG
from an easy-to-use commercially available Brain Computer Interface wearable
device to determine the vigilance state of an individual. The change in the
power spectrum in the Frontal Theta Band (4-8Hz) of an individual's brain wave
predicts the changes in the attention level of an individual - providing an
early detection and warning system. This method provides an accurate, yet cheap
and practical system for vigilance monitoring across different environments.",http://arxiv.org/abs/2103.02169v1
"On the Ricci curvature of homogeneous Finsler spaces with
  $(α,β)$-metrics",2021-03-03T05:37:13Z,"Sarita Rani, Gauree Shanker","The study of curvature properties of homogeneous Finsler spaces with
$(\alpha, \beta)$-metrics is one of the central problems in Riemann-Finsler
geometry. In this paper, we consider homogeneous Finsler spaces with square
metric and Randers change of square metric. First, we derive the explicit
formulae for Ricci curvature of homogeneous Finsler spaces with these metrics.
Next, we find a necessary and sufficient condition under which a homogeneous
Finsler space with either of these metrics is of vanishing $S$-curvature. The
formulae for Ricci curvature of homogeneous Finsler spaces with square metric
and Randers change of square metric having vanishing $S$-curvature are
established. Finally, we prove that the aforesaid spaces having vanishing
$S$-curvature and negative Ricci curvature must be Riemannian.",http://arxiv.org/abs/2103.02192v1
"Solution to the Riemann Hypothesis from geometric analysis of component
  series functions in the functional equation of zeta",2021-03-03T07:16:35Z,Jeet Kumar Gaur,"This paper presents a new approach towards the Riemann Hypothesis. On
iterative expansion of integration term in functional equation of the Riemann
zeta function we get sum of two series functions. At the `non-trivial' zeros of
zeta function, value of the series is zero. Thus, Riemann hypothesis is false
if that happens for an `s' off the line $\Re(s)=1/2$ ( the critical line). This
series has two components $f(s)$ and $f(1-s)$. For the hypothesis to be false
one component is additive inverse of the other. From geometric analysis of
spiral geometry representing the component series functions $f(s)$ and $f(1-s)$
on complex plane we find by contradiction that they cannot be each other's
additive inverse for any $s$, off the critical line. Thus, proving truth of the
hypothesis.",http://arxiv.org/abs/2103.02223v4
Tensor hierarchy algebra extensions of over-extended Kac--Moody algebras,2021-03-03T15:38:07Z,"Martin Cederwall, Jakob Palmkvist","Tensor hierarchy algebras are infinite-dimensional generalisations of
Cartan-type Lie superalgebras. They are not contragredient, exhibiting an
asymmetry between positive and negative levels. These superalgebras have been a
focus of attention due to the fundamental role they play for extended geometry.
In the present paper, we examine tensor hierarchy algebras which are
super-extensions of over-extended (often, hyperbolic) Kac--Moody algebras. They
contain novel algebraic structures. Of particular interest is the extension of
a over-extended algebra by its fundamental module, an extension that contains
and generalises the extension of an affine Kac--Moody algebra by a Virasoro
derivation $L_1$. A conjecture about the complete superalgebra is formulated,
relating it to the corresponding Borcherds superalgebra.",http://arxiv.org/abs/2103.02476v2
"Secure Software Development in the Era of Fluid Multi-party Open
  Software and Services",2021-03-04T21:01:03Z,"Ivan Pashchenko, Riccardo Scandariato, Antonino Sabetta, Fabio Massacci","Pushed by market forces, software development has become fast-paced. As a
consequence, modern development projects are assembled from 3rd-party
components. Security & privacy assurance techniques once designed for large,
controlled updates over months or years, must now cope with small, continuous
changes taking place within a week, and happening in sub-components that are
controlled by third-party developers one might not even know they existed. In
this paper, we aim to provide an overview of the current software security
approaches and evaluate their appropriateness in the face of the changed nature
in software development. Software security assurance could benefit by switching
from a process-based to an artefact-based approach. Further, security
evaluation might need to be more incremental, automated and decentralized. We
believe this can be achieved by supporting mechanisms for lightweight and
scalable screenings that are applicable to the entire population of software
components albeit there might be a price to pay.",http://arxiv.org/abs/2103.03331v1
Phase Separation of Polyelectrolytes: The Effect of Charge Regulation,2021-03-05T16:03:12Z,"Bin Zheng, Yael Avni, David Andelman, Rudolf Podgornik","Complex coacervation, known as the liquid-liquid phase separation of
solutions with oppositely charged polyelectrolytes, has attracted substantial
interest in recent years. We study the effect of the charge regulation (CR)
mechanism on the complex coacervation by including short-range interactions
between the charged sites on the polymer chains as well as an
association-dissociation energy parameter in the CR mechanism. We investigate
the phase diagrams of two CR models: (i) the hopping CR model (HCR) and (ii)
the asymmetric CR model (ACR). It is shown that during the phase separation
that the polymers in the condensed phase are more charged than those in the
dilute phase, in accordance with Le Chatelier's principle. In addition,
secondary CR effects also influence the change in the volume fraction of the
two phases. The latter can cause the charge difference between the two phases
to change nonmonotonically as a function of the CR parameters.",http://arxiv.org/abs/2103.03774v2
"ODIN: A Bit-Parallel Stochastic Arithmetic Based Accelerator for In-Situ
  Neural Network Processing in Phase Change RAM",2021-03-05T21:47:48Z,"Supreeth Mysore Shivanandamurthy, Ishan. G. Thakkar, Sayed Ahmad Salehi","Due to the very rapidly growing use of Artificial Neural Networks (ANNs) in
real-world applications related to machine learning and Artificial Intelligence
(AI), several hardware accelerator de-signs for ANNs have been proposed
recently. In this paper, we present a novel processing-in-memory (PIM) engine
called ODIN that employs hybrid binary-stochastic bit-parallel arithmetic
in-side phase change RAM (PCRAM) to enable a low-overhead in-situ acceleration
of all essential ANN functions such as multiply-accumulate (MAC), nonlinear
activation, and pooling. We mapped four ANN benchmark applications on ODIN to
compare its performance with a conventional processor-centric design and a
crossbar-based in-situ ANN accelerator from prior work. The results of our
analysis for the considered ANN topologies indicate that our ODIN accelerator
can be at least 5.8x faster and 23.2x more energy-efficient, and up to 90.8x
faster and 1554x more energy-efficient, compared to the crossbar-based in-situ
ANN accelerator from prior work.",http://arxiv.org/abs/2103.03953v1
Mode Structure of a Broadband High Gain Parametric Amplifier,2021-03-06T11:17:53Z,"Xin Chen, Jacob Zhang, Z. Y. Ou","High gain parametric amplifier with a single-pass pulsed pump is known to
generate broadband twin photon fields that are entangled in amplitude and phase
but have complicated spectral correlation. Fortunately, they can be decomposed
into independent temporal modes. But the common treatment of parametric
interaction Hamiltonian does not consider the issue of time ordering problem of
interaction Hamiltonian and thus leads to incorrect conclusion that the mode
structure and the temporal mode functions do not change as the gain increases.
In this paper, we use an approach that is usually employed for treating
nonlinear interferometers and avoids the time ordering issue. This allows us to
derive an evolution equation in differential-integral form. Numerical solutions
for high gain situation indicate a gain-dependent mode structure that has its
mode distributions changed and mode functions broadened as the gain increases.",http://arxiv.org/abs/2103.04099v1
"Terahertz Devices Using the Optical Activation of GeTe Phase Change
  Materials: Towards Fully Reconfigurable Functionalities",2021-03-07T16:32:54Z,"Maxime Pinaud, Georges Humbert, Sebastian Engelbrecht, Lionel Merlat, Bernd Fischer, Aurelian Crunteanu","We are demonstrating the optical control of a specific state of the germanium
telluride (GeTe) phase change material and its integration as control element
for realizing extremely efficient optically reconfigurable THz devices. The
excellent contrast of the material THz electrical properties in the two
dissimilar states were used for optical-induced fast modulation of THz
resonances of a hybrid metamaterial based of arrays of split ring resonator
metallic structures integrating GeTe patterns. We experimentally confirm for
the first time the feasibility to develop all dielectric (metal free)
GeTe-based THz polarizers presenting a broadband response, a high extinction
ratio when the GeTe is in the metal-like phase (up to 16.5 dB) and almost
transparent when the material is in the amorphous phase. The presented highly
functional approach based on non-volatile, optically controlled
multi-operational THz devices integrating PCMs, is extremely stimulating for
generating disruptive developments like field-programmable metasurfaces or
all-dielectric coding metamaterials with multifunctional capabilities for THz
waves manipulation.",http://arxiv.org/abs/2103.04395v2
Behavior-Driven Synthesis of Human Dynamics,2021-03-08T11:36:32Z,"Andreas Blattmann, Timo Milbich, Michael Dorkenwald, Björn Ommer","Generating and representing human behavior are of major importance for
various computer vision applications. Commonly, human video synthesis
represents behavior as sequences of postures while directly predicting their
likely progressions or merely changing the appearance of the depicted persons,
thus not being able to exercise control over their actual behavior during the
synthesis process. In contrast, controlled behavior synthesis and transfer
across individuals requires a deep understanding of body dynamics and calls for
a representation of behavior that is independent of appearance and also of
specific postures. In this work, we present a model for human behavior
synthesis which learns a dedicated representation of human dynamics independent
of postures. Using this representation, we are able to change the behavior of a
person depicted in an arbitrary posture, or to even directly transfer behavior
observed in a given video sequence. To this end, we propose a conditional
variational framework which explicitly disentangles posture from behavior. We
demonstrate the effectiveness of our approach on this novel task, evaluating
capturing, transferring, and sampling fine-grained, diverse behavior, both
quantitatively and qualitatively. Project page is available at
https://cutt.ly/5l7rXEp",http://arxiv.org/abs/2103.04677v2
"On Lipschitz approximations in second order Sobolev spaces and the
  change of variables formula",2021-03-08T12:53:38Z,"Paz Hashash, Alexander Ukhlov","In this paper we study approximations of functions of Sobolev spaces
$W^2_{p,\loc}(\Omega)$, $\Omega\subset\mathbb R^n$, by Lipschitz continuous
functions. We prove that if $f\in W^2_{p,\loc}(\Omega)$, $1\leq p<\infty$, then
there exists a sequence of closed sets $\{A_k\}_{k=1}^{\infty},A_k\subset
A_{k+1}\subset \Omega$, such that the restrictions $f \vert_{A_k}$ are
Lipschitz continuous functions and $\cp_p\left(S\right)=0$,
$S=\Omega\setminus\bigcup_{k=1}^{\infty}A_k$. Using these approximations we
prove the change of variables formula in the Lebesgue integral for mappings of
Sobolev spaces $W^2_{p,\loc}(\Omega;\mathbb R^n)$ with the Luzin
capacity-measure $N$-property.",http://arxiv.org/abs/2103.04720v3
"Near-infrared Brightening around the Periastron Passages of the
  Gamma-ray Binary PSR B1259$-$63 /LS 2883",2021-03-08T16:56:25Z,"A. Kawachi, Y. Moritani, A. T. Okazaki, H. Yoshida, K. Suzuki","The binary of the pulsar PSRB1259$-$63 and the Be star LS 2883 has been
observed at the 2010 and 2014 periastron passages in the near-infrared (NIR)
bands using the IRSF/SIRIUS and SIRPOL. The light curves in the J-,H-, and
Ks-bands are almost identical in these periastron passages. A flare starts no
later than 10 days before periastron and the maximum brightening of about 0.1
magnitude is observed 12--17 days after periastron. The rising part of the
light curve is steeper and reaches a peak slightly earlier in the Ks-band than
in the other bands, thus a characteristic track appears on the NIR
color-magnitude diagram. The time lag between the NIR light curves indicates
that the variation in the Be circumstellar disk first occurs in an outer
region. We propose that the initial rapid contraction followed by the gradual
expansion of the disk is evoked by the rapidly changing tidal torque around
periastron and the resultant change of the optically thick area causes the
observed NIR light curves.",http://arxiv.org/abs/2103.04895v1
Closed string deformations in open string field theory I: bosonic string,2021-03-08T17:31:47Z,"Carlo Maccaferri, Jakub Vošmera","This is the first of a series of three papers on open string field theories
based on Witten star product deformed with a gauge invariant open/closed
coupling. This deformation is a tree-level tadpole which destabilizes the
initial perturbative vacuum. We discuss the existence of vacuum-shift solutions
which cancel the tadpole and represent a new configuration where the initial
D-brane system has adapted to the change in the closed string background. As an
example we consider the bulk deformation which changes the compactification
radius and, to first order in the deformation, we reproduce the shift in the
mass of the open string KK modes from the new kinetic operator after the vacuum
shift. We also discuss the possibility of taming closed string degenerations
with the open string propagator in the simplest amplitude corresponding to two
closed strings off a disk.",http://arxiv.org/abs/2103.04919v2
The c-map as a functor on certain variations of Hodge structure,2021-03-08T20:34:32Z,"Mauro Mantegazza, Arpan Saha","We give a new manifestly natural presentation of the supergravity c-map. We
achieve this by giving a more explicit description of the correspondence
between projective special K\""ahler manifolds and variations of Hodge
structure, and by demonstrating that the twist construction of Swann, for a
certain kind of twist data, reduces to a quotient by a discrete group. We
combine these two ideas by showing that variations of Hodge structure give rise
to the aforementioned kind of twist data and by then applying the twist
realisation of the c-map due to Macia and Swann. This extends previous results
regarding the lifting of general isomorphisms along the undeformed c-map, and
of infinitesimal automorphisms along the deformed c-map. We show in fact that
general isomorphisms can be naturally lifted along the deformed c-map.",http://arxiv.org/abs/2103.05060v3
Fast and Efficient Bit-Level Precision Tuning,2021-03-09T06:12:41Z,"Assalé Adjé, Dorra Ben Khalifa, Matthieu Martel","In this article, we introduce a new technique for precision tuning. This
problem consists of finding the least data types for numerical values such that
the result of the computation satisfies some accuracy requirement. State of the
art techniques for precision tuning use a try and fail approach. They change
the data types of some variables of the program and evaluate the accuracy of
the result. Depending on what is obtained, they change more or less data types
and repeat the process. Our technique is radically different. Based on semantic
equations, we generate an Integer Linear Problem (ILP) from the program source
code. Basically, this is done by reasoning on the most significant bit and the
number of significant bits of the values which are integer quantities. The
integer solution to this problem, computed in polynomial time by a (real)
linear programming solver, gives the optimal data types at the bit level. A
finer set of semantic equations is also proposed which does not reduce directly
to an ILP problem. So we use policy iteration to find the solution. Both
techniques have been implemented and we show that our results encompass the
results of state of the art tools.",http://arxiv.org/abs/2103.05241v1
"Direct visualization of antiferroelectric switching dynamics via
  electrocaloric imaging",2021-03-09T11:43:21Z,"Pablo Vales-Castro, Miquel Vellvehi, Xavier Perpiñà, J. M. Caicedo, Xavier Jordà, Romain Faye, Krystian Roleder, Dariusz Kajewski, Amador Perez-Tomas, Emmanuel Defay, Gustau Catalan","The large electrocaloric coupling in PbZrO3 allows using high-speed infrared
imaging to visualize antiferroelectric switching dynamics via the associated
temperature change. We find that in ceramic samples of homogeneous temperature
and thickness, switching is nucleation-limited and fast, with devices
responding in the milisecond range. By introducing gradients of thickness,
however, it is possible to change the dynamics from nucleation-limited to
propagation-limited, whereby a single phase boundary sweeps across the sample
like a cold front, at a speed of c.a. 20 cm/s. Additionally, introducing
thermostatic temperature differences between two sides of the sample enables
the simultaneous generation of a negative electrocaloric effect on one side and
a positive one on the other, yielding a Janus-like electrocaloric response.",http://arxiv.org/abs/2103.05373v1
"Distributed Frequency Restoration and SoC Balancing Control for AC
  Microgrids",2021-03-09T17:33:08Z,"Chang Yu, Xiaoqing Lu, Jingang Lai, Li Chai","This paper develops an improved distributed finite-time control algorithm for
multiagent-based ac microgrids with battery energy storage systems (BESSs)
utilizing a low-width communication network. The proposed control algorithm can
simultaneously coordinate BESSs to eliminate any deviation from the nominal
frequency as well as solving the state of charge (SoC) balancing problem. The
stability of the proposed control algorithm is established using the Lyapunov
method and homogeneous approximation theory, which guarantees an accelerated
convergence within a settling time that does not dependent on initial
conditions. Based on this, to significantly reduce the communication burdens,
an event-triggered communication mechanism is designed which can also avoid
Zeno behavior. Then sufficient conditions on the event-triggered boundary are
derived to guarantee the stability and reliability of the whole system.
Practical local constraints are imposed to implement the control protocol, and
the theoretical results are applied to a test system consisting of five DGs and
five BESSs, which verifies the effectiveness of the proposed strategy.",http://arxiv.org/abs/2103.05576v1
Essential minimal volume of Einstein 4-manifolds,2021-03-09T19:01:12Z,Antoine Song,"The minimal volume of a closed manifold $M$ is the infimum of the volume of
$(M,g)$ over all metrics $g$ with sectional curvature between $-1$ and $1$. We
introduce a variant called the essential minimal volume,
$\mathrm{ess-Minvol}(M)$, which is the limit, as $\delta>0$ goes to $0$, of the
infimum of the volume of the $\delta$-thick part of $(M,g)$ over all metrics
$g$ with sectional curvature between $-1$ and $1$. We show that, for some
universal constant $C>0$, any closed Einstein 4-manifold $M$ with Euler
characteristic $e(M)$ satisfies $$C^{-1}e(M) \leq \mathrm{ess-Minvol}(M) \leq
Ce(M).$$ As a corollary, these inequalities are true for the essential minimal
volume of closed complex surfaces of nonnegative Kodaira dimension. We
conjecture that those linear bounds in fact hold for the minimal volume.",http://arxiv.org/abs/2103.05659v3
"Effects of confinement on the dynamics and correlation scales in active
  fluids",2021-03-10T20:36:04Z,"Yi Fan, Kun-Ta Wu, Ali Aghvami, Seth Fraden, Kenneth Breuer","We study the influence of solid boundaries on dynamics and structure of
active fluids as the height of the container, $z$, changes. Along the varying
dimension, the geometry systematically increases, therefore, the confinement
($z$) transits from ""strong confinement"", to ""intermediate confinement"" and to
""weak confinement"" (close to ""unconfined""). In horizontal dimensions ($x,y$),
the system remains ""unconfined"". Through tracking the tracers dispersed in the
active fluids in three dimensions we observed that activity level,
characterized by velocity fluctuations of flow tracers, increases as system
size increases. Concomitantly, the velocity-velocity temporal correlation
changes from weak correlation to strong positive correlation, indicating
""memory"" in active flows. We estimate the characteristic size of the flow
structure by integrating the velocity-velocity spatial correlation function.
The integral increases as confinement becomes weaker and saturates at
approximately 400 microns as the system becomes ""unconfined"". This saturation
indicates an intrinsic length scale which, along with the small-scale isotropy,
demonstrates the multi-scale nature of this kinesin-driven bundled microtubule
system.",http://arxiv.org/abs/2103.06334v1
"Have I been here before? Learning to Close the Loop with LiDAR Data in
  Graph-Based SLAM",2021-03-11T14:59:03Z,"Tim-Lukas Habich, Marvin Stuede, Mathieu Labbé, Svenja Spindeldreier","This work presents an extension of graph-based SLAM methods to exploit the
potential of 3D laser scans for loop detection. Every high-dimensional point
cloud is replaced by a compact global descriptor, whereby a trained detector
decides whether a loop exists. Searching for loops is performed locally in a
variable space to consider the odometry drift. Since closing a wrong loop has
fatal consequences, an extensive verification is performed before acceptance.
The proposed algorithm is implemented as an extension of the widely used
state-of-the-art library RTAB-Map, and several experiments show the
improvement: During SLAM with a mobile service robot in changing indoor and
outdoor campus environments, our approach improves RTAB-Map regarding total
number of closed loops. Especially in the presence of significant environmental
changes, which typically lead to failure, localization becomes possible by our
extension. Experiments with a car in traffic (KITTI benchmark) show the general
applicability of our approach. These results are comparable to the
state-of-the-art LiDAR method LOAM. The developed ROS package is freely
available.",http://arxiv.org/abs/2103.06713v2
"Intelligent behavior depends on the ecological niche: Scaling up AI to
  human-like intelligence in socio-cultural environments",2021-03-11T16:24:00Z,"Manfred Eppe, Pierre-Yves Oudeyer","This paper outlines a perspective on the future of AI, discussing directions
for machines models of human-like intelligence. We explain how developmental
and evolutionary theories of human cognition should further inform artificial
intelligence. We emphasize the role of ecological niches in sculpting
intelligent behavior, and in particular that human intelligence was
fundamentally shaped to adapt to a constantly changing socio-cultural
environment. We argue that a major limit of current work in AI is that it is
missing this perspective, both theoretically and experimentally. Finally, we
discuss the promising approach of developmental artificial intelligence,
modeling infant development through multi-scale interaction between
intrinsically motivated learning, embodiment and a fastly changing
socio-cultural environment. This paper takes the form of an interview of
Pierre-Yves Oudeyer by Mandred Eppe, organized within the context of a KI -
K{\""{u}}nstliche Intelligenz special issue in developmental robotics.",http://arxiv.org/abs/2103.06769v1
"Stochastic-HMDs: Adversarial Resilient Hardware Malware Detectors
  through Voltage Over-scaling",2021-03-11T20:18:40Z,"Md Shohidul Islam, Ihsen Alouani, Khaled N. Khasawneh","Machine learning-based hardware malware detectors (HMDs) offer a potential
game changing advantage in defending systems against malware. However, HMDs
suffer from adversarial attacks, can be effectively reverse-engineered and
subsequently be evaded, allowing malware to hide from detection. We address
this issue by proposing a novel HMDs (Stochastic-HMDs) through approximate
computing, which makes HMDs' inference computation-stochastic, thereby making
HMDs resilient against adversarial evasion attacks. Specifically, we propose to
leverage voltage overscaling to induce stochastic computation in the HMDs
model. We show that such a technique makes HMDs more resilient to both
black-box adversarial attack scenarios, i.e., reverse-engineering and
transferability. Our experimental results demonstrate that Stochastic-HMDs
offer effective defense against adversarial attacks along with by-product power
savings, without requiring any changes to the hardware/software nor to the
HMDs' model, i.e., no retraining or fine tuning is needed. Moreover, based on
recent results in probably approximately correct (PAC) learnability theory, we
show that Stochastic-HMDs are provably more difficult to reverse engineer.",http://arxiv.org/abs/2103.06936v1
Thousand to One: Semantic Prior Modeling for Conceptual Coding,2021-03-12T08:02:07Z,"Jianhui Chang, Zhenghui Zhao, Lingbo Yang, Chuanmin Jia, Jian Zhang, Siwei Ma","Conceptual coding has been an emerging research topic recently, which encodes
natural images into disentangled conceptual representations for compression.
However, the compression performance of the existing methods is still
sub-optimal due to the lack of comprehensive consideration of rate constraint
and reconstruction quality. To this end, we propose a novel end-to-end semantic
prior modeling-based conceptual coding scheme towards extremely low bitrate
image compression, which leverages semantic-wise deep representations as a
unified prior for entropy estimation and texture synthesis. Specifically, we
employ semantic segmentation maps as structural guidance for extracting deep
semantic prior, which provides fine-grained texture distribution modeling for
better detail construction and higher flexibility in subsequent high-level
vision tasks. Moreover, a cross-channel entropy model is proposed to further
exploit the inter-channel correlation of the spatially independent semantic
prior, leading to more accurate entropy estimation for rate-constrained
training. The proposed scheme achieves an ultra-high 1000x compression ratio,
while still enjoying high visual reconstruction quality and versatility towards
visual processing and analysis tasks.",http://arxiv.org/abs/2103.07131v2
Moiré-induced Vibrational Coupling in Double Walled Carbon Nanotubes,2021-03-12T15:09:33Z,"Georgy Gordeev, Sören Wasserroth, Han Li, Benjamin Flavel, Stephanie Reich","Moir\'e patterns are additional, long-range periodicities in twisted
crystalline bilayers. They are known to fundamentally change the electronic
states of the layers, but similar effects on their mechanical and vibrational
properties have not been discussed so far. Here we show that the Moir\'e
potential shifts the radial breathing mode in double walled carbon nanotubes
(DWCNTs). The change of frequency is expected to be proportional to the shift
in optical transition energies, which are induced by the Moir\'e patterns. To
verify our model we performed resonant Raman scattering on purified and sorted
semiconducting DWCNTs. We find that the radial breathing mode shifts up to 14
cm$^{-1}$ higher in energy followed by optical transitions energies
displacement up to 200 meV to lower energies, compared to the single-walled
tubes. We show how to identify the strong coupling condition in DWCNTs from
their phonon frequencies and construct a Kataura plot to aid their future
experimental assignment.",http://arxiv.org/abs/2103.07337v2
Distinguished categories and the Zilber-Pink conjecture,2021-03-12T17:35:00Z,"Fabrizio Barroero, Gabriel Andreas Dill","We propose an axiomatic approach towards studying unlikely intersections by
introducing the framework of distinguished categories. This includes
commutative algebraic groups and mixed Shimura varieties. It allows us to
define all basic concepts of the field and prove some fundamental facts about
them, e.g. the defect condition.
  In some categories that we call very distinguished, we are able to show some
implications between Zilber-Pink statements with respect to base change. This
yields unconditional results, i.e. the Zilber-Pink conjecture for a complex
curve in $\mathcal{A}_2$ that cannot be defined over $\bar{\mathbb{Q}}$, a
complex curve in the $g$-th fibered power of the Legendre family, and a complex
curve in the base change of a semiabelian variety over $\bar{\mathbb{Q}}$.",http://arxiv.org/abs/2103.07422v4
Quasi-static limit for the asymmetric simple exclusion,2021-03-14T20:02:48Z,"Anna De Masi, Stefano Marchesani, Stefano Olla, Lu Xu","We study the one-dimensional asymmetric simple exclusion process on the
lattice $\{1, \dots,N\}$ with creation/annihilation at the boundaries. The
boundary rates are time dependent and change on a slow time scale $N^{-a}$ with
$a>0$. We prove that at the time scale $N^{1+a}$ the system evolves
quasi-statically with a macroscopic density profile given by the entropy
solution of the stationary Burgers equation with boundary densities changing in
time, determined by the corresponding microscopic boundary rates. We consider
two different types of boundary rates: the ""Liggett boundaries"" that correspond
to the projection of the infinite dynamics, and the reversible boundaries, that
correspond to the contact with particle reservoirs in equilibrium. The proof is
based on the control of the Lax boundary entropy--entropy flux pairs and a
coupling argument.",http://arxiv.org/abs/2103.08019v5
Get Your Vitamin C! Robust Fact Verification with Contrastive Evidence,2021-03-15T17:05:13Z,"Tal Schuster, Adam Fisch, Regina Barzilay","Typical fact verification models use retrieved written evidence to verify
claims. Evidence sources, however, often change over time as more information
is gathered and revised. In order to adapt, models must be sensitive to subtle
differences in supporting evidence. We present VitaminC, a benchmark infused
with challenging cases that require fact verification models to discern and
adjust to slight factual changes. We collect over 100,000 Wikipedia revisions
that modify an underlying fact, and leverage these revisions, together with
additional synthetically constructed ones, to create a total of over 400,000
claim-evidence pairs. Unlike previous resources, the examples in VitaminC are
contrastive, i.e., they contain evidence pairs that are nearly identical in
language and content, with the exception that one supports a given claim while
the other does not. We show that training using this design increases
robustness -- improving accuracy by 10% on adversarial fact verification and 6%
on adversarial natural language inference (NLI). Moreover, the structure of
VitaminC leads us to define additional tasks for fact-checking resources:
tagging relevant words in the evidence for verifying the claim, identifying
factual revisions, and providing automatic edits via factually consistent text
generation.",http://arxiv.org/abs/2103.08541v1
Does Code Review Promote Conformance? A Study of OpenStack Patches,2021-03-15T09:05:05Z,"Panyawut Sri-iesaranusorn, Raula Gaikovina Kula, Takashi Ishio","Code Review plays a crucial role in software quality, by allowing reviewers
to discuss and critique any new patches before they can be successfully
integrated into the project code. Yet, it is unsure the extent to which coding
pattern changes (i.e., repetitive code) from when a patch is first submitted
and when the decision is made (i.e., during the review process). In this study,
we revisit coding patterns in code reviews, aiming to analyze whether or not
the coding pattern changes during the review process. Comparing prior submitted
patches, we measure differences in coding pattern between pre-review~(i.e.,
patch before the review) and post-review~(i.e., patch after a review) from
27,736 reviewed OpenStack patches. Results show that patches after review, tend
to conform to similar coding patterns of accepted patches, compared to when
they were first submitted. We also find that accepted patches do have similar
coding patterns to prior accepted patches. Our study reveals insights into the
review process, supporting the potential for automated tool support for
newcomers and lays the groundwork for work into understanding conformance and
how it makes for an efficient code review process.",http://arxiv.org/abs/2103.08595v1
Ternary Hashing,2021-03-16T16:20:54Z,"Chang Liu, Lixin Fan, Kam Woh Ng, Yilun Jin, Ce Ju, Tianyu Zhang, Chee Seng Chan, Qiang Yang","This paper proposes a novel ternary hash encoding for learning to hash
methods, which provides a principled more efficient coding scheme with
performances better than those of the state-of-the-art binary hashing
counterparts. Two kinds of axiomatic ternary logic, Kleene logic and
{\L}ukasiewicz logic are adopted to calculate the Ternary Hamming Distance
(THD) for both the learning/encoding and testing/querying phases. Our work
demonstrates that, with an efficient implementation of ternary logic on
standard binary machines, the proposed ternary hashing is compared favorably to
the binary hashing methods with consistent improvements of retrieval mean
average precision (mAP) ranging from 1\% to 5.9\% as shown in CIFAR10, NUS-WIDE
and ImageNet100 datasets.",http://arxiv.org/abs/2103.09173v2
Light confinement by local index tailoring in inhomogeneous dielectrics,2021-03-16T16:30:07Z,"I. Krešić, K. G. Makris, S. Rotter","The engineering of light confinement is a topic with a long history in optics
and with significant implications for the control of light-matter interaction.
In inhomogeneous and disordered media, however, multiple scattering prevents
the application of conventional approaches for the design of light fields with
desired properties. This is because any local change to such a medium typically
affects these fields in a non-local and complicated fashion. Here, we present a
theoretical methodology for tailoring an inhomogeneous one-dimensional (1D)
Hermitian dielectric index distribution, such that the intensity profile of an
incoming light field can be controlled purely locally, i.e., with little or no
influence on the field profile outside of a designated region of interest.
Strongly increasing or decreasing the light's intensity at arbitrary positions
inside the medium thereby becomes possible without, in fact, changing the
external reflectance or transmittance of the medium. These local modifications
of the medium can thus be made undetectable to unidirectional far field
measurements. We apply our approach to locally control the confinement of light
inside 1D materials with inhomogeneous continuous refractive index profiles and
extend it to multilayer films as well as to chains of coupled micro-resonators.",http://arxiv.org/abs/2103.09182v2
Learning Discriminative Prototypes with Dynamic Time Warping,2021-03-17T06:11:11Z,"Xiaobin Chang, Frederick Tung, Greg Mori","Dynamic Time Warping (DTW) is widely used for temporal data processing.
However, existing methods can neither learn the discriminative prototypes of
different classes nor exploit such prototypes for further analysis. We propose
Discriminative Prototype DTW (DP-DTW), a novel method to learn class-specific
discriminative prototypes for temporal recognition tasks. DP-DTW shows superior
performance compared to conventional DTWs on time series classification
benchmarks. Combined with end-to-end deep learning, DP-DTW can handle
challenging weakly supervised action segmentation problems and achieves state
of the art results on standard benchmarks. Moreover, detailed reasoning on the
input video is enabled by the learned action prototypes. Specifically, an
action-based video summarization can be obtained by aligning the input sequence
with action prototypes.",http://arxiv.org/abs/2103.09458v1
"Mathematical Modeling of Sediments in the Filter and Improvement of the
  Filter Construction",2021-03-17T07:57:28Z,Yuri Troshchiev,"The filters work in many areas of technology. There constructions are
different and substances under filtration are different. It is necessary in
some cases to take into account forming of sediments on the walls of the filter
since they can change properties of the filter or blind the filtering apertures
at all. I construct a mathematical model of sedimentation growth on the walls
of the porous filter in this article. Analytical investigation is present in
the article and numeric results too. There are formulas for dependencies of
concentration near the walls on inner concentration in liquid in the article.
Flow speed, calculated time of work, purification efficiency and other
parameters proved to be important factors. Differing of radiuses of apertures
from membrane to membrane can make contamination equal along the filter.
Numerical results show importance of preliminary calculation of the filter for
the purpose it will serve. Forming of calcic sediment is an investigated
example of chemical reaction.",http://arxiv.org/abs/2103.09492v2
"AndroidCompass: A Dataset of Android Compatibility Checks in Code
  Repositories",2021-03-17T13:11:14Z,"Sebastian Nielebock, Paul Blockhaus, Jacob Krüger, Frank Ortmeier","Many developers and organizations implement apps for Android, the most widely
used operating system for mobile devices. Common problems developers face are
the various hardware devices, customized Android variants, and frequent
updates, forcing them to implement workarounds for the different versions and
variants of Android APIs used in practice. In this paper, we contribute the
Android Compatibility checkS dataSet (AndroidCompass) that comprises changes to
compatibility checks developers use to enforce workarounds for specific Android
versions in their apps. We extracted 80,324 changes to compatibility checks
from 1,394 apps by analyzing the version histories of 2,399 projects from the
F-Droid catalog. With AndroidCompass, we aim to provide data on when and how
developers introduced or evolved workarounds to handle Android
incompatibilities. We hope that AndroidCompass fosters research to deal with
version incompatibilities, address potential design flaws, identify security
concerns, and help derive solutions for other developers, among others-helping
researchers to develop and evaluate novel techniques, and Android app as well
as operating-system developers in engineering their software.",http://arxiv.org/abs/2103.09620v1
"Demand for shared mobility to replace private mobility using connected
  and automated vehicles",2021-03-17T23:44:13Z,"Seyed Mehdi Meshkani, Shadi Djavadian, Bilal Farooq","We examine how introduction of Shared Connected and Automated vehicles
(SCAVs) as a new mobility mode could affect travel demand, welfare, as well as
traffic congestion in the network. To do so, we adapt an agent-based day-to-day
adjustment process and develop a central dispatching system, which is
implemented on an in-house traffic microsimulator. We consider a two-sided
market in which demand and SCAV fleet size change endogenously. For dispatching
SCAV fleet size, we take changing traffic conditions into account. There are
two available transport modes: private Connected Automated Vehicles (CAVs) and
SCAVs. The designed system is applied on downtown Toronto network using real
data. The results show that demand of SCAVs goes up by 43 per cent over seven
study days from 670 trips on the first day to 959 trips on the seventh day.
Whereas, there is a 10 per cent reduction in private CAV demand from 2807 trips
to 2518 trips during the same duration. Moreover, total travel time of the
network goes down by seven per cent indicating that traffic congestion was
reduced in the network.",http://arxiv.org/abs/2103.09951v1
"Measurement of critical current flow and connectivity in systems of
  joined square superconducting plates",2021-03-19T13:28:23Z,"F. Colauto, D. Carmo, A. M. H. de Andrade, A. A. M. Oliveira, W. A. Ortiz, Y. M. Galperin, T. H. Johansen","A method to measure the electrical connectivity between square
superconducting plates joined by weak link interfaces is presented. It is based
on observation of lines where the flow of critical current abruptly changes
direction due to the presence of weak links, and the confinement created by the
shape of the sample. The method is demonstrated using magneto-optical imaging
(MOI) of systems consisting of up to 2 X 2 plates joined to form a larger
square. Common features are found in the current flow patterns, which allow to
measure the electrical connectivity between the plates by observing an angle
between pairs of lines indicating where the current abruptly changes flow
direction, so-called discontinuity, or d-lines. The samples used in this study
are Nb films with weak links created by focused ion beam machining.",http://arxiv.org/abs/2103.10793v1
"IA Planner: Motion Planning Using Instantaneous Analysis for Autonomous
  Vehicle in the Dense Dynamic Scenarios on Highways",2021-03-19T17:10:50Z,"Xiaoyu Yang, Huiyun Li","In dense and dynamic scenarios, planning a safe and comfortable trajectory is
full of challenges when traffic participants are driving at high speed. The
classic graph search and sampling methods first perform path planning and then
configure the corresponding speed, which lacks a strategy to deal with the
high-speed obstacles. Decoupling optimization methods perform motion planning
in the S-L and S-T domains respectively. These methods require a large free
configuration space to plan the lane change trajectory. In dense dynamic
scenes, it is easy to cause the failure of trajectory planning and be cut in by
others, causing slow driving speed and bring safety hazards. We analyze the
collision relationship in the spatio-temporal domain, and propose an
instantaneous analysis model which only analyzes the collision relationship at
the same time. In the model, the collision-free constraints in 3D
spatio-temporal domain is projected to the 2D space domain to remove redundant
constraints and reduce computational complexity. Experimental results show that
our method can plan a safe and comfortable lane-changing trajectory in dense
dynamic scenarios. At the same time, it improves traffic efficiency and
increases ride comfort.",http://arxiv.org/abs/2103.10909v1
Paint by Word,2021-03-19T17:59:08Z,"Alex Andonian, Sabrina Osmany, Audrey Cui, YeonHwan Park, Ali Jahanian, Antonio Torralba, David Bau","We investigate the problem of zero-shot semantic image painting. Instead of
painting modifications into an image using only concrete colors or a finite set
of semantic concepts, we ask how to create semantic paint based on open
full-text descriptions: our goal is to be able to point to a location in a
synthesized image and apply an arbitrary new concept such as ""rustic"" or
""opulent"" or ""happy dog."" To do this, our method combines a state-of-the art
generative model of realistic images with a state-of-the-art text-image
semantic similarity network. We find that, to make large changes, it is
important to use non-gradient methods to explore latent space, and it is
important to relax the computations of the GAN to target changes to a specific
region. We conduct user studies to compare our methods to several baselines.",http://arxiv.org/abs/2103.10951v3
"Most Efficient Sensor Network Protocol for a Permanent Natural Disaster
  Monitoring System",2021-03-20T04:53:02Z,"Changmin Lee, Seong-Lyun Kim","To minimize enormous havoc from disasters, permanent environment monitoring
is necessarily required. Thus we propose a novel energy management protocol for
energy harvesting wireless sensor networks (EH-WSNs), named the adaptive sensor
node management protocol (ASMP). The proposed protocol makes system components
to systematically control their performance to conserve the energy. Through
this protocol, sensor nodes autonomously activate an additional energy
conservation algorithm. ASMP embeds three sampling algorithms. For the
optimized environment sampling, we proposed the adaptive sampling algorithm for
monitoring (ASA-m). ASA-m estimates the expected time period to occur
meaningful change. The meaningful change refers to the distance between two
target data for the monitoring QoS. Therefore, ASA-m merely gathers the data
the system demands. The continuous adaptive sampling algorithm (CASA) solves
the problem to be continuously decreasing energy despite of ASA-m. When the
monitored environment shows a linear trend property, the sensor node in CASA
rests a sampling process, and the server generates predicted data at the
estimated time slot. For guaranteeing the self-sustainability, ASMP uses the
recoverable adaptive sampling algorithm (RASA). RASA makes consumed energy
smaller than harvested energy by utilizing the predicted data. RASA recharges
the energy of the sensor node. Through this method, ASMP achieves both energy
conservation and service quality.",http://arxiv.org/abs/2103.11098v1
Twisting or untwisting graphene twisted nanoribbons without rotation,2021-03-21T00:51:15Z,Alexandre F. Fonseca,"The common sense regarding twisting or untwisting a ribbon is that it
requires the application of an external rotation to happen. However, at
nanoscale, the application of precise amounts of rotation on a nanoribbon is
not a trivial task. Here, the concept of an alternative method to add twist to
or remove twist from a twisted graphene nanoribbon (TGNR) without rotation is
presented. The method consists of suspending a TGNR on two separate substrates
and by changing only their distance, the total amount of twist of the TGNR is
shown to change. The possibility to fine-tuning the amount of twist of a TGNR
is also shown. The concept is demonstrated through fully atomistic molecular
dynamics simulations and numerical calculations of the topological parameters
twist and writhe of a TGNR. It is shown that the above process satisfies the
so-called linking number theorem of space curves. Besides being experimentally
feasible, this concept reveals a new kind of twist to writhe transition
phenomenon that is tension-free and does not require controlling neither the
nanoribbon end-to-end distance nor its critical twist density.",http://arxiv.org/abs/2103.11272v2
Online Convex Optimization with Continuous Switching Constraint,2021-03-21T11:43:35Z,"Guanghui Wang, Yuanyu Wan, Tianbao Yang, Lijun Zhang","In many sequential decision making applications, the change of decision would
bring an additional cost, such as the wear-and-tear cost associated with
changing server status. To control the switching cost, we introduce the problem
of online convex optimization with continuous switching constraint, where the
goal is to achieve a small regret given a budget on the \emph{overall}
switching cost. We first investigate the hardness of the problem, and provide a
lower bound of order $\Omega(\sqrt{T})$ when the switching cost budget
$S=\Omega(\sqrt{T})$, and $\Omega(\min\{\frac{T}{S},T\})$ when $S=O(\sqrt{T})$,
where $T$ is the time horizon. The essential idea is to carefully design an
adaptive adversary, who can adjust the loss function according to the
cumulative switching cost of the player incurred so far based on the orthogonal
technique. We then develop a simple gradient-based algorithm which enjoys the
minimax optimal regret bound. Finally, we show that, for strongly convex
functions, the regret bound can be improved to $O(\log T)$ for $S=\Omega(\log
T)$, and $O(\min\{T/\exp(S)+S,T\})$ for $S=O(\log T)$.",http://arxiv.org/abs/2103.11370v1
"NRQCD analysis of charmonium production with pion and proton beams at
  fixed-target energies",2021-03-22T08:32:35Z,"Chia-Yu Hsieh, Yu-Shiang Lian, Wen-Chen Chang, Jen-Chieh Peng, Stephane Platchkov, Takahiro Sawada","We present an analysis of hadroproduction of $J/\psi$ and $\psi(2S)$ at
fixed-target energies in the framework of non-relativistic QCD (NRQCD). Using
both pion- and proton-induced data, a new determination of the color-octet
long-distance matrix elements (LDMEs) is obtained. Compared with previous
results, the contributions from the $q \bar{q}$ and color-octet processes are
significantly enhanced, especially at lower energies. A good agreement between
the pion-induced $J/\psi$ production data and NRQCD calculations using the
newly obtained LDMEs is achieved. We find that the pion-induced charmonium
production data are sensitive to the gluon density of pions, and favor pion
PDFs with relatively large gluon contents at large $x$.",http://arxiv.org/abs/2103.11660v2
"Raven's Progressive Matrices Completion with Latent Gaussian Process
  Priors",2021-03-22T17:48:44Z,"Fan Shi, Bin Li, Xiangyang Xue","Abstract reasoning ability is fundamental to human intelligence. It enables
humans to uncover relations among abstract concepts and further deduce implicit
rules from the relations. As a well-known abstract visual reasoning task,
Raven's Progressive Matrices (RPM) are widely used in human IQ tests. Although
extensive research has been conducted on RPM solvers with machine intelligence,
few studies have considered further advancing the standard answer-selection
(classification) problem to a more challenging answer-painting (generating)
problem, which can verify whether the model has indeed understood the implicit
rules. In this paper we aim to solve the latter one by proposing a deep latent
variable model, in which multiple Gaussian processes are employed as priors of
latent variables to separately learn underlying abstract concepts from RPMs;
thus the proposed model is interpretable in terms of concept-specific latent
variables. The latent Gaussian process also provides an effective way of
extrapolation for answer painting based on the learned concept-changing rules.
We evaluate the proposed model on RPM-like datasets with multiple
continuously-changing visual concepts. Experimental results demonstrate that
our model requires only few training samples to paint high-quality answers,
generate novel RPM panels, and achieve interpretability through
concept-specific latent variables.",http://arxiv.org/abs/2103.12045v2
"Impulsive fire disturbance in a savanna model: Tree-grass coexistence
  states, multiple stable system states, and resilience",2021-03-22T18:54:45Z,"Alanna Hoyer-Leitzel, Sarah Iams","Savanna ecosystems are shaped by the frequency and intensity of regular
fires. We model savannas via an ordinary differential equation (ODE) encoding a
one-sided inhibitory Lotka-Volterra interaction between trees and grass. By
applying fire as a discrete disturbance, we create an impulsive dynamical
system that allows us to identify the impact of variation in fire frequency and
intensity. The model exhibits three different bistability regimes: between
savanna and grassland; two savanna states; and savanna and woodland. The
impulsive model reveals rich bifurcation structures in response to changes in
fire intensity and frequency -- structures that are largely invisible to
analogous ODE models with continuous fire. In addition, by using the amount of
grass as an example of a socially-valued function of the system state, we
examine the resilience of the social value to different disturbance regimes. We
find that large transitions (""tipping"") in the valued quantity can be triggered
by small changes in disturbance regime.",http://arxiv.org/abs/2103.12132v2
"Autonomous Flight through Cluttered Outdoor Environments Using a
  Memoryless Planner",2021-03-22T20:09:51Z,"Junseok Lee, Xiangyu Wu, Seung Jae Lee, Mark W. Mueller","This paper introduces a collision avoidance system for navigating a
multicopter in cluttered outdoor environments based on the recent memory-less
motion planner, rectangular pyramid partitioning using integrated depth sensors
(RAPPIDS). The RAPPIDS motion planner generates collision-free flight
trajectories at high speed with low computational cost using only the latest
depth image. In this work we extend it to improve the performance of the
planner by taking the following issues into account. (a) Changes in the dynamic
characteristics of the multicopter that occur during flight, such as changes in
motor input/output characteristics due to battery voltage drop. (b) The noise
of the flight sensor, which can cause unwanted control input components. (c)
Planner utility function which may not be suitable for the cluttered
environment. Therefore, in this paper we introduce solutions to each of the
above problems and propose a system for the successful operation of the RAPPIDS
planner in an outdoor cluttered flight environment. At the end of the paper, we
validate the proposed method's effectiveness by presenting the flight
experiment results in a forest environment. A video can be found at
www.youtube.com/channel/UCK-gErmvZlBODN5gQpNcpsg",http://arxiv.org/abs/2103.12156v1
Modeling Random Directions in 2D Simplex Data,2021-03-22T22:39:44Z,"Rayleigh Lei, XuanLong Nguyen","We propose models and algorithms for learning about random directions in
two-dimensional simplex data, and apply our methods to the study of income
level proportions and their changes over time in a geostatistical area. There
are several notable challenges in the analysis of simplex-valued data: the
measurements must respect the simplex constraint and the changes exhibit
spatiotemporal smoothness while allowing for possible heterogeneous behaviors.
To that end, we propose Bayesian models that rely on and expand upon building
blocks in circular and spatial statistics by exploiting suitable transformation
based on the polar coordinates for circular data. Our models also account for
spatial correlation across locations in the simplex and the heterogeneous
patterns via mixture modeling. We describe some properties of the models and
model fitting via MCMC techniques. Our models and methods are illustrated via a
thorough simulation study, and applied to an analysis of movements and trends
of income categories using the Home Mortgage Disclosure Act data.",http://arxiv.org/abs/2103.12214v2
"Fully-echoed Q-routing with Simulated Annealing Inference for Flying
  Adhoc Networks",2021-03-23T22:28:26Z,"Arnau Rovira-Sugranes, Fatemeh Afghah, Junsuo Qu, Abolfazl Razi","Current networking protocols deem inefficient in accommodating the two key
challenges of Unmanned Aerial Vehicle (UAV) networks, namely the network
connectivity loss and energy limitations. One approach to solve these issues is
using learning-based routing protocols to make close-to-optimal local decisions
by the network nodes, and Q-routing is a bold example of such protocols.
However, the performance of the current implementations of Q-routing algorithms
is not yet satisfactory, mainly due to the lack of adaptability to continued
topology changes. In this paper, we propose a full-echo Q-routing algorithm
with a self-adaptive learning rate that utilizes Simulated Annealing (SA)
optimization to control the exploration rate of the algorithm through the
temperature decline rate, which in turn is regulated by the experienced
variation rate of the Q-values. Our results show that our method adapts to the
network dynamicity without the need for manual re-initialization at transition
points (abrupt network topology changes). Our method exhibits a reduction in
the energy consumption ranging from 7% up to 82%, as well as a 2.6 fold gain in
successful packet delivery rate}, compared to the state of the art Q-routing
protocols",http://arxiv.org/abs/2103.12870v1
Dual Online Stein Variational Inference for Control and Dynamics,2021-03-23T23:26:09Z,"Lucas Barcelos, Alexander Lambert, Rafael Oliveira, Paulo Borges, Byron Boots, Fabio Ramos","Model predictive control (MPC) schemes have a proven track record for
delivering aggressive and robust performance in many challenging control tasks,
coping with nonlinear system dynamics, constraints, and observational noise.
Despite their success, these methods often rely on simple control
distributions, which can limit their performance in highly uncertain and
complex environments. MPC frameworks must be able to accommodate changing
distributions over system parameters, based on the most recent measurements. In
this paper, we devise an implicit variational inference algorithm able to
estimate distributions over model parameters and control inputs on-the-fly. The
method incorporates Stein Variational gradient descent to approximate the
target distributions as a collection of particles, and performs updates based
on a Bayesian formulation. This enables the approximation of complex
multi-modal posterior distributions, typically occurring in challenging and
realistic robot navigation tasks. We demonstrate our approach on both simulated
and real-world experiments requiring real-time execution in the face of
dynamically changing environments.",http://arxiv.org/abs/2103.12890v1
"A tale of two metrics: Polling and financial contributions as a measure
  of performance",2021-03-24T04:41:02Z,"Moeen Mostafavi, Maria Phillips, Yichen Jiang, Michael D. Porter, Paul Freedman","Campaign analysis is an integral part of American democracy and has many
complexities in its dynamics. Experts have long sought to understand these
dynamics and evaluate campaign performance using a variety of techniques. We
explore campaign financing and standing in the polls as two components of
campaign performance in the context of the 2020 Democratic primaries. We show
where these measures exhibit represent similar dynamics and where they differ.
We focus on identifying change points in the trend for all candidates using
joinpoint regression models. We find how these change points identify major
events such as failure or success in a debate. Joinpoint regression reveals who
the voters support when they stop supporting a specific candidate. This study
demonstrates the value of joinpoint regression in political campaign analysis
and it represents a crossover of this technique into the political domain
building a foundation for continued exploration and use of this method.",http://arxiv.org/abs/2103.12984v1
About a first order transformation of magnetite at 1 160 °C,2021-03-24T13:17:03Z,"Claude Carel, Pierre Vallet","In the literature on the w{\""u}stite/magnetite transformation, there are two
distinct values of the enthalpy and entropy terms of the equilibrium between
these two oxides. The formalism established previously for the calculation of
thermodynamic properties of w{\""u}stite is taken as well as the adjustment of
the boundary between the respective domains. A first-order transformation of
the magnetite is demonstrated at 1 433 K or 1 160{\textdegree}C where the
change in the reference enthalpy is -9 990 J.mole-1 at heating, with the
corresponding entropy change being-6.89 J.K-1. . mole-1. The approximate
determination of enthalpy vs temperature is made for both varieties of
magnetite. Two values of the molar heat content are deduced, with which a
direct experimental value can be compared.",http://arxiv.org/abs/2103.13170v1
Foreground color prediction through inverse compositing,2021-03-24T18:10:15Z,"Sebastian Lutz, Aljosa Smolic","In natural image matting, the goal is to estimate the opacity of the
foreground object in the image. This opacity controls the way the foreground
and background is blended in transparent regions. In recent years, advances in
deep learning have led to many natural image matting algorithms that have
achieved outstanding performance in a fully automatic manner. However, most of
these algorithms only predict the alpha matte from the image, which is not
sufficient to create high-quality compositions. Further, it is not possible to
manually interact with these algorithms in any way except by directly changing
their input or output. We propose a novel recurrent neural network that can be
used as a post-processing method to recover the foreground and background
colors of an image, given an initial alpha estimation. Our method outperforms
the state-of-the-art in color estimation for natural image matting and show
that the recurrent nature of our method allows users to easily change candidate
solutions that lead to superior color estimations.",http://arxiv.org/abs/2103.13423v1
3D Reasoning for Unsupervised Anomaly Detection in Pediatric WbMRI,2021-03-24T21:37:01Z,"Alex Chang, Vinith Suriyakumar, Abhishek Moturu, James Tu, Nipaporn Tewattanarat, Sayali Joshi, Andrea Doria, Anna Goldenberg","Modern deep unsupervised learning methods have shown great promise for
detecting diseases across a variety of medical imaging modalities. While
previous generative modeling approaches successfully perform anomaly detection
by learning the distribution of healthy 2D image slices, they process such
slices independently and ignore the fact that they are correlated, all being
sampled from a 3D volume. We show that incorporating the 3D context and
processing whole-body MRI volumes is beneficial to distinguishing anomalies
from their benign counterparts. In our work, we introduce a multi-channel
sliding window generative model to perform lesion detection in whole-body MRI
(wbMRI). Our experiments demonstrate that our proposed method significantly
outperforms processing individual images in isolation and our ablations clearly
show the importance of 3D reasoning. Moreover, our work also shows that it is
beneficial to include additional patient-specific features to further improve
anomaly detection in pediatric scans.",http://arxiv.org/abs/2103.13497v1
"Quality Gatekeepers: Investigating the Effects ofCode Review Bots on
  Pull Request Activities",2021-03-25T01:27:19Z,"Mairieli Wessel, Alexander Serebrenik, Igor Wiese, Igor Steinmacher, Marco A. Gerosa","Software bots have been facilitating several development activities in Open
Source Software (OSS) projects, including code review. However, these bots may
bring unexpected impacts to group dynamics, as frequently occurs with new
technology adoption. Understanding and anticipating such effects is important
for planning and management. To analyze these effects, we investigate how
several activity indicators change after the adoption of a code review bot. We
employed a regression discontinuity design on 1,194 software projects from
GitHub. We also interviewed 12 practitioners, including open-source maintainers
and contributors. Our results indicate that the adoption of code review bots
increases the number of monthly merged pull requests, decreases monthly
non-merged pull requests, and decreases communication among developers. From
the developers' perspective, these effects are explained by the transparency
and confidence the bot comments introduce, in addition to the changes in the
discussion focused on pull requests. Practitioners and maintainers may leverage
our results to understand, or even predict, bot effects on their projects.",http://arxiv.org/abs/2103.13547v2
SubSpectral Normalization for Neural Audio Data Processing,2021-03-25T05:55:48Z,"Simyung Chang, Hyoungwoo Park, Janghoon Cho, Hyunsin Park, Sungrack Yun, Kyuwoong Hwang","Convolutional Neural Networks are widely used in various machine learning
domains. In image processing, the features can be obtained by applying 2D
convolution to all spatial dimensions of the input. However, in the audio case,
frequency domain input like Mel-Spectrogram has different and unique
characteristics in the frequency dimension. Thus, there is a need for a method
that allows the 2D convolution layer to handle the frequency dimension
differently. In this work, we introduce SubSpectral Normalization (SSN), which
splits the input frequency dimension into several groups (sub-bands) and
performs a different normalization for each group. SSN also includes an affine
transformation that can be applied to each group. Our method removes the
inter-frequency deflection while the network learns a frequency-aware
characteristic. In the experiments with audio data, we observed that SSN can
efficiently improve the network's performance.",http://arxiv.org/abs/2103.13620v1
"Dark matter and dark radiation from evaporating Kerr primordial black
  holes",2021-03-24T11:36:46Z,Isabella Masina,"The mechanism of the generation of dark matter and dark radiation from the
evaporation of primordial black holes is very interesting. We consider the case
of Kerr black holes to generalize previous results obtained in the
Schwarzschild case. For dark matter, the results do not change dramatically and
the bounds on warm dark matter apply similarly: in particular, the Kerr case
cannot save the scenario of black hole domination for light dark matter. For
dark radiation, the expectations for $\Delta N_{eff}$ do not change
significantly with respect to the Schwarzschild case, but for an enhancement in
the case of spin 2 particles: in the massless case, however, the projected
experimental sensitivity would be reached only for extremal black holes.",http://arxiv.org/abs/2103.13825v1
Prediction of a supersolid phase in high-pressure deuterium,2021-03-25T17:02:16Z,"Chang Woo Myung, Barak Hirshberg, Michele Parrinello","Supersolid is a mysterious and puzzling state of matter whose possible
existence has stirred a vigorous debate among physicists for over 60 years. Its
elusive nature stems from the coexistence of two seemingly contradicting
properties, long-range order and superfluidity. We report computational
evidence of a supersolid phase of deuterium under high pressure ($p >800$ GPa)
and low temperature (T $<$ 1.0 K). In our simulations, that are based on
bosonic path integral molecular dynamics, we observe a highly concerted
exchange of atoms while the system preserves its crystalline order. The
exchange processes are favoured by the soft core interactions between deuterium
atoms that form a densely packed metallic solid. At the zero temperature limit,
Bose-Einstein condensation is observed as the permutation probability of $N$
deuterium atoms approaches $1/N$ with a finite superfluid fraction. Our study
provides concrete evidence for the existence of a supersolid phase in
high-pressure deuterium and could provide insights on the future investigation
of supersolid phases in real materials.",http://arxiv.org/abs/2103.13974v4
Andreev molecule in parallel InAs nanowires,2021-03-25T18:58:14Z,"Olivér Kürtössy, Zoltán Scherübl, Gergő Fülöp, István Endre Lukács, Thomas Kanne, Jesper Nygård, Péter Makk, Szabolcs Csonka","Coupling individual atoms via tunneling fundamentally changes the state of
matter: electrons bound to atomic cores become delocalized resulting in a
change from an insulating to a metallic state, as it is well known from the
canonical example of solids. A chain of atoms could lead to more exotic states
if the tunneling takes place via the superconducting vacuum and can induce
topologically protected excitations like Majorana or parafermions. Toward the
realization of such artificial chains, coupling a single atom to the
superconducting vacuum is well studied, but the hybridization of two sites via
the superconductor was not yet reported. The peculiar vacuum of the BCS
condensate opens the way to annihilate or generate two electrons from the bulk
resulting in a so-called Andreev molecular state. By employing parallel
nanowires with an Al superconductor shell, two artificial atoms were created at
a minimal distance with an epitaxial superconducting link between.
Hybridization via the BCS vacuum was observed between the two artificial atoms
for the first time, as a demonstration of an Andreev molecular state.",http://arxiv.org/abs/2103.14083v2
Multitype $Λ$-coalescents,2021-03-26T17:55:03Z,"Samuel G. G. Johnston, Andreas E. Kyprianou, Tim Rogers","Consider a multitype coalescent process in which each block has a colour in
$\{1,\ldots,d\}$. Individual blocks may change colour, and some number of
blocks of various colours may merge to form a new block of some colour. We show
that if the law of a multitype coalescent process is invariant under
permutations of blocks of the same colour, has consistent Markovian
projections, and has asychronous mergers, then it is a multitype
$\Lambda$-coalescent: a process in which single blocks may change colour, two
blocks of like colour may merge to form a single block of that colour, or large
mergers across various colours happen at rates governed by a $d$-tuple of
measures on the unit cube $[0,1]^d$. We go on to identify when such processes
come down from infinity. Our framework generalises Pitman's celebrated
classification theorem for singletype coalescent processes, and provides a
unifying setting for numerous examples that have appeared in the literature
including the seed-bank model, the island model and the coalescent structure of
continuous-state branching processes.",http://arxiv.org/abs/2103.14638v2
"Public-private research collaborations: longitudinal field-level
  analysis of determinants, frequency and impact",2021-03-27T09:35:22Z,"Giovanni Abramo, Francesca Apponi, Ciriaco Andrea D'Angelo","This study on public-private research collaboration measures the variation
over time of the propensity of academics to collaborate with colleagues from
private companies. It also investigates the change in weights of the main
drivers underlying the academics' propensity to collaborate, and whether the
type profile of the collaborating academics changes. To do this, the study
applies an inferential model on a dataset of professors working in Italian
universities in consecutive periods, 2010-2013 and 2014-2017. The results,
obtained at overall and field levels, support the formulation of policies aimed
at fostering public-private research collaborations, and should be taken into
account in post-assessment of their effectiveness.",http://arxiv.org/abs/2103.14857v1
"Inference of Random Effects for Linear Mixed-Effects Models with a Fixed
  Number of Clusters",2021-03-28T09:52:19Z,"Chih-Hao Chang, Hsin-Cheng Huang, Ching-Kang Ing","We consider a linear mixed-effects model with a clustered structure, where
the parameters are estimated using maximum likelihood (ML) based on possibly
unbalanced data. Inference with this model is typically done based on
asymptotic theory, assuming that the number of clusters tends to infinity with
the sample size. However, when the number of clusters is fixed, classical
asymptotic theory developed under a divergent number of clusters is no longer
valid and can lead to erroneous conclusions. In this paper, we establish the
asymptotic properties of the ML estimators of random-effects parameters under a
general setting, which can be applied to conduct valid statistical inference
with fixed numbers of clusters. Our asymptotic theorems allow both fixed
effects and random effects to be misspecified, and the dimensions of both
effects to go to infinity with the sample size.",http://arxiv.org/abs/2103.15095v1
"Extending Multi-Sense Word Embedding to Phrases and Sentences for
  Unsupervised Semantic Applications",2021-03-29T04:54:28Z,"Haw-Shiuan Chang, Amol Agrawal, Andrew McCallum","Most unsupervised NLP models represent each word with a single point or
single region in semantic space, while the existing multi-sense word embeddings
cannot represent longer word sequences like phrases or sentences. We propose a
novel embedding method for a text sequence (a phrase or a sentence) where each
sequence is represented by a distinct set of multi-mode codebook embeddings to
capture different semantic facets of its meaning. The codebook embeddings can
be viewed as the cluster centers which summarize the distribution of possibly
co-occurring words in a pre-trained word embedding space. We introduce an
end-to-end trainable neural model that directly predicts the set of cluster
centers from the input text sequence during test time. Our experiments show
that the per-sentence codebook embeddings significantly improve the
performances in unsupervised sentence similarity and extractive summarization
benchmarks. In phrase similarity experiments, we discover that the multi-facet
embeddings provide an interpretable semantic representation but do not
outperform the single-facet baseline.",http://arxiv.org/abs/2103.15330v2
Multi-facet Universal Schema,2021-03-29T05:10:10Z,"Rohan Paul, Haw-Shiuan Chang, Andrew McCallum","Universal schema (USchema) assumes that two sentence patterns that share the
same entity pairs are similar to each other. This assumption is widely adopted
for solving various types of relation extraction (RE) tasks. Nevertheless, each
sentence pattern could contain multiple facets, and not every facet is similar
to all the facets of another sentence pattern co-occurring with the same entity
pair. To address the violation of the USchema assumption, we propose
multi-facet universal schema that uses a neural model to represent each
sentence pattern as multiple facet embeddings and encourage one of these facet
embeddings to be close to that of another sentence pattern if they co-occur
with the same entity pair. In our experiments, we demonstrate that multi-facet
embeddings significantly outperform their single-facet embedding counterpart,
compositional universal schema (CUSchema) (Verga et al., 2016), in distantly
supervised relation extraction tasks. Moreover, we can also use multiple
embeddings to detect the entailment relation between two sentence patterns when
no manual label is available.",http://arxiv.org/abs/2103.15339v1
Dual-Parameterized Quantum Circuit GAN Model in High Energy Physics,2021-03-29T10:06:54Z,"Su Yeon Chang, Steven Herbert, Sofia Vallecorsa, Elías F. Combarro, Ross Duncan","Generative models, and Generative Adversarial Networks (GAN) in particular,
are being studied as possible alternatives to Monte Carlo simulations. It has
been proposed that, in certain circumstances, simulation using GANs can be
sped-up by using quantum GANs (qGANs). We present a new design of qGAN, the
dual-Parameterized Quantum Circuit(PQC) GAN, which consists of a classical
discriminator and two quantum generators which take the form of PQCs. The first
PQC learns a probability distribution over N-pixel images, while the second
generates normalized pixel intensities of an individual image for each PQC
input. With a view to HEP applications, we evaluated the dual-PQC architecture
on the task of imitating calorimeter outputs, translated into pixelated images.
The results demonstrate that the model can reproduce a fixed number of images
with a reduced size as well as their probability distribution and we anticipate
it should allow us to scale up to real calorimeter outputs.",http://arxiv.org/abs/2103.15470v1
Prototype-based Personalized Pruning,2021-03-25T05:49:42Z,"Jangho Kim, Simyung Chang, Sungrack Yun, Nojun Kwak","Nowadays, as edge devices such as smartphones become prevalent, there are
increasing demands for personalized services. However, traditional
personalization methods are not suitable for edge devices because retraining or
finetuning is needed with limited personal data. Also, a full model might be
too heavy for edge devices with limited resources. Unfortunately, model
compression methods which can handle the model complexity issue also require
the retraining phase. These multiple training phases generally need huge
computational cost during on-device learning which can be a burden to edge
devices. In this work, we propose a dynamic personalization method called
prototype-based personalized pruning (PPP). PPP considers both ends of
personalization and model efficiency. After training a network, PPP can easily
prune the network with a prototype representing the characteristics of personal
data and it performs well without retraining or finetuning. We verify the
usefulness of PPP on a couple of tasks in computer vision and Keyword spotting.",http://arxiv.org/abs/2103.15564v1
"Stability, electronic structure, and magnetic moment of Vanadium
  phthalocyanine grafted to the Au(111) surface",2021-03-29T14:17:33Z,"Manel Mabrouk, Jacek A. Majewski","The studies of electronic and magnetic properties of V-Pc molecule adsorbed
onto Au(111) surface are based on ab-initio calculations in the framework of
density functional theory. We compute adsorption energies, investigate
interaction mechanisms between constituents of the hybrid system consisting of
V-Pc molecule and Au surface, and determine geometry changes in the system,
particularly in the grafted molecule. We find out that the energetically most
stable configuration of the V-Pc/Au(111) occurs when V-Pc is grafted to the Au
surface's fcc site, which leads to the reduction of the point group symmetry of
the hybrid system in comparison to the free standing V-Pc molecule. Further,
our studies reveal that the electronic structure and magnetic properties of the
V-Pc change significantly after adsorption to the Au(111). Generally, these
studies shed light on physical mechanisms of the V-Pc adsorption to metallic
surfaces and open up new prospects for design of novel spintronic devices.",http://arxiv.org/abs/2103.15639v1
Self-Constructing Neural Networks Through Random Mutation,2021-03-29T15:27:38Z,Samuel Schmidgall,"The search for neural architecture is producing many of the most exciting
results in artificial intelligence. It has increasingly become apparent that
task-specific neural architecture plays a crucial role for effectively solving
problems. This paper presents a simple method for learning neural architecture
through random mutation. This method demonstrates 1) neural architecture may be
learned during the agent's lifetime, 2) neural architecture may be constructed
over a single lifetime without any initial connections or neurons, and 3)
architectural modifications enable rapid adaptation to dynamic and novel task
scenarios. Starting without any neurons or connections, this method constructs
a neural architecture capable of high-performance on several tasks. The
lifelong learning capabilities of this method are demonstrated in an
environment without episodic resets, even learning with constantly changing
morphology, limb disablement, and changing task goals all without losing
locomotion capabilities.",http://arxiv.org/abs/2103.15692v1
Classicality of the heat produced by quantum measurements,2021-03-29T16:43:43Z,M. Hamed Mohammady,"Quantum measurement is ultimately a physical process, resulting from an
interaction between the measured system and a measuring apparatus. Considering
the physical process of measurement within a thermodynamic context naturally
raises the following question: How can the work and heat be interpreted? In the
present paper we model the measurement process for an arbitrary discrete
observable as a measurement scheme. Here the system to be measured is first
unitarily coupled with an apparatus and subsequently the compound system is
objectified with respect to a pointer observable, thus producing definite
measurement outcomes. The work can therefore be interpreted as the change in
internal energy of the compound system due to the unitary coupling. By the
first law of thermodynamics, the heat is the subsequent change in internal
energy of this compound due to pointer objectification. We argue that the
apparatus serves as a stable record for the measurement outcomes only if the
pointer observable commutes with the Hamiltonian and show that such
commutativity implies that the uncertainty of heat will necessarily be
classical.",http://arxiv.org/abs/2103.15749v3
"TOUR: Dynamic Topic and Sentiment Analysis of User Reviews for Assisting
  App Release",2021-03-26T08:44:55Z,"Tianyi Yang, Cuiyun Gao, Jingya Zang, David Lo, Michael R. Lyu","App reviews deliver user opinions and emerging issues (e.g., new bugs) about
the app releases. Due to the dynamic nature of app reviews, topics and
sentiment of the reviews would change along with app release versions. Although
several studies have focused on summarizing user opinions by analyzing user
sentiment towards app features, no practical tool is released. The large
quantity of reviews and noise words also necessitates an automated tool for
monitoring user reviews. In this paper, we introduce TOUR for dynamic TOpic and
sentiment analysis of User Reviews. TOUR is able to (i) detect and summarize
emerging app issues over app versions, (ii) identify user sentiment towards app
features, and (iii) prioritize important user reviews for facilitating
developers' examination. The core techniques of TOUR include the online topic
modeling approach and sentiment prediction strategy. TOUR provides entries for
developers to customize the hyper-parameters and the results are presented in
an interactive way. We evaluate TOUR by conducting a developer survey that
involves 15 developers, and all of them confirm the practical usefulness of the
recommended feature changes by TOUR.",http://arxiv.org/abs/2103.15774v2
"Noise-resistant Deep Metric Learning with Ranking-based Instance
  Selection",2021-03-30T03:22:17Z,"Chang Liu, Han Yu, Boyang Li, Zhiqi Shen, Zhanning Gao, Peiran Ren, Xuansong Xie, Lizhen Cui, Chunyan Miao","The existence of noisy labels in real-world data negatively impacts the
performance of deep learning models. Although much research effort has been
devoted to improving robustness to noisy labels in classification tasks, the
problem of noisy labels in deep metric learning (DML) remains open. In this
paper, we propose a noise-resistant training technique for DML, which we name
Probabilistic Ranking-based Instance Selection with Memory (PRISM). PRISM
identifies noisy data in a minibatch using average similarity against image
features extracted by several previous versions of the neural network. These
features are stored in and retrieved from a memory bank. To alleviate the high
computational cost brought by the memory bank, we introduce an acceleration
method that replaces individual data points with the class centers. In
extensive comparisons with 12 existing approaches under both synthetic and
real-world label noise, PRISM demonstrates superior performance of up to 6.06%
in Precision@1.",http://arxiv.org/abs/2103.16047v2
"Wave based damage detection in solid structures using artificial neural
  networks",2021-03-30T13:31:50Z,"Frank Wuttke, Hao Lyu, Amir S. Sattari, Zarghaam H. Rizvi","The identification of structural damages takes a more and more important role
within the modern economy, where often the monitoring of an infrastructure is
the last approach to keep it under public use. Conventional monitoring methods
require specialized engineers and are mainly time consuming. This research
paper considers the ability of neural networks to recognize the initial or
alteration of structural properties based on the training processes. The
presented work here is based on Convolutional Neural Networks (CNN) for wave
field pattern recognition, or more specifically the wave field change
recognition. The CNN model is used to identify the change within propagating
wave fields after a crack initiation within the structure. The paper describes
the implemented method and the required training procedure to get a successful
crack detection accuracy, where the training data are based on the dynamic
lattice model. Although the training of the model is still time consuming, the
proposed new method has an enormous potential to become a new crack detection
or structural health monitoring approach within the conventional monitoring
methods.",http://arxiv.org/abs/2103.16339v1
"Design and Control of a Midair-Reconfigurable Quadcopter using
  Unactuated Hinges",2021-03-30T19:18:02Z,"Nathan Bucki, Jerry Tang, Mark W. Mueller","A novel quadcopter capable of changing shape mid-flight is presented,
allowing for operation in four configurations with the capability of sustained
hover in three. This is accomplished without requiring actuators beyond the
four motors typical of a quadcopter. Morphing is achieved through
freely-rotating hinges that allow the vehicle arms to fold downwards by either
reducing or reversing thrust forces. Constraints placed on the control inputs
of the vehicle prevent the arms from folding or unfolding unexpectedly. This
allows for the use of existing quadcopter controllers and trajectory generation
algorithms with only minimal added complexity. For our experimental vehicle at
hover, we find that these constraints result in a 36% reduction of the maximum
yaw torque the vehicle can produce, but do not result in a reduction of the
maximum thrust or roll and pitch torques. Experimental results show that, for a
typical maneuver, the added limits have a negligible effect on trajectory
tracking performance. Finally, the ability to change configurations is shown to
enable the vehicle to traverse small passages, perch on hanging wires, and
perform limited grasping tasks.",http://arxiv.org/abs/2103.16632v2
Anisotropic magnetotransport in LaAlO$_3$/SrTiO$_3$ nanostructures,2021-03-31T10:16:13Z,"M. S. Prasad, G. Schmidt","A number of recent studies indicate that the charge conduction of the
LaAlO$_3$/SrTiO$_3$ interface at low temperature is confined to filaments which
are linked to structural domain walls in the SrTiO$_3$ with drastic
consequences for example for the temperature dependence of local transport
properties. We demonstrate that as a consequences of this current carrying
filaments on the nano-scale the magnetotransport properties of the interface
are highly anisotropic. Our magnetoresistance measurements reveal that the
magnetoresistance in different nanostructures ($<500nm$) is random in magnitude
and sign, respectively. Warming up nanostructures above the structural phase
transition temperature (105K) results in the significant change in MR. Even a
sign change of the magnetoresistance is possible. The results suggest that
domain walls that are differently oriented with respect to the surface exhibit
different respective magnetoresistance and the total magnetoresistance is a
result of a random domain wall pattern formed during the structural phase
transition in the SrTiO$_3$ at cool down.",http://arxiv.org/abs/2103.16955v1
The Existential Threat of Future Exoplanet Discoveries,2021-03-31T13:50:11Z,Michael B. Lund,"The last 25 years have been revolutionary in astronomy, as the field of
exoplanets has gone from no known planets outside the Solar System to thousands
discovered over the last year few years. This represents a rapid increase not
just in known planets (often referred to as Mamajek's Law), but also in total
planetary mass. What has been heretofore unaddressed, however, is that this
rapid increase in planetary masses may have disastrous consequences for the
future of humanity. We look at how the number of planets, and more importantly,
the mass of these planets has changed in the past and how we can expect this to
change in the future. The answers to those questions, and how we respond to
them, will determine if humanity is able to survive beyond the next 230 years.",http://arxiv.org/abs/2103.17079v1
On the Origin of Species of Self-Supervised Learning,2021-03-31T15:09:36Z,"Samuel Albanie, Erika Lu, Joao F. Henriques","In the quiet backwaters of cs.CV, cs.LG and stat.ML, a cornucopia of new
learning systems is emerging from a primordial soup of mathematics-learning
systems with no need for external supervision. To date, little thought has been
given to how these self-supervised learners have sprung into being or the
principles that govern their continuing diversification. After a period of
deliberate study and dispassionate judgement during which each author set their
Zoom virtual background to a separate Galapagos island, we now entertain no
doubt that each of these learning machines are lineal descendants of some older
and generally extinct species. We make five contributions: (1) We gather and
catalogue row-major arrays of machine learning specimens, each exhibiting
heritable discriminative features; (2) We document a mutation mechanism by
which almost imperceptible changes are introduced to the genotype of new
systems, but their phenotype (birdsong in the form of tweets and vestigial
plumage such as press releases) communicates dramatic changes; (3) We propose a
unifying theory of self-supervised machine evolution and compare to other
unifying theories on standard unifying theory benchmarks, where we establish a
new (and unifying) state of the art; (4) We discuss the importance of digital
biodiversity, in light of the endearingly optimistic Paris Agreement.",http://arxiv.org/abs/2103.17143v1
Bit-Mixer: Mixed-precision networks with runtime bit-width selection,2021-03-31T17:58:47Z,"Adrian Bulat, Georgios Tzimiropoulos","Mixed-precision networks allow for a variable bit-width quantization for
every layer in the network. A major limitation of existing work is that the
bit-width for each layer must be predefined during training time. This allows
little flexibility if the characteristics of the device on which the network is
deployed change during runtime. In this work, we propose Bit-Mixer, the very
first method to train a meta-quantized network where during test time any layer
can change its bid-width without affecting at all the overall network's ability
for highly accurate inference. To this end, we make 2 key contributions: (a)
Transitional Batch-Norms, and (b) a 3-stage optimization process which is shown
capable of training such a network. We show that our method can result in mixed
precision networks that exhibit the desirable flexibility properties for
on-device deployment without compromising accuracy. Code will be made
available.",http://arxiv.org/abs/2103.17267v1
"Probabilistic Deep Learning with Probabilistic Neural Networks and Deep
  Probabilistic Models",2021-05-31T22:13:21Z,Daniel T. Chang,"Probabilistic deep learning is deep learning that accounts for uncertainty,
both model uncertainty and data uncertainty. It is based on the use of
probabilistic models and deep neural networks. We distinguish two approaches to
probabilistic deep learning: probabilistic neural networks and deep
probabilistic models. The former employs deep neural networks that utilize
probabilistic layers which can represent and process uncertainty; the latter
uses probabilistic models that incorporate deep neural network components which
capture complex non-linear stochastic relationships between the random
variables. We discuss some major examples of each approach including Bayesian
neural networks and mixture density networks (for probabilistic neural
networks), and variational autoencoders, deep Gaussian processes and deep mixed
effects models (for deep probabilistic models). TensorFlow Probability is a
library for probabilistic modeling and inference which can be used for both
approaches of probabilistic deep learning. We include its code examples for
illustration.",http://arxiv.org/abs/2106.00120v3
"Agent mental models and Bayesian rules as a tool to create opinion
  dynamics models",2021-06-01T03:10:31Z,Andre C. R. Martins,"Traditional models of opinion dynamics provide a simple approach to
understanding human behavior in basic social scenarios. However, when it comes
to issues such as polarization and extremism, we require a more nuanced
understanding of human biases and cognitive tendencies. In this paper, we
propose an approach to modeling opinion dynamics by integrating mental models
and assumptions of individuals agents using Bayesian-inspired methods. By
exploring the relationship between human rationality and Bayesian theory, we
demonstrate the efficacy of these methods in describing how opinions evolve.
Our analysis leverages the Continuous Opinions and Discrete Actions (CODA)
model, applying Bayesian-inspired rules to account for key human behaviors such
as confirmation bias, motivated reasoning, and our reluctance to change
opinions. Through this, we obtain update rules that offer deeper insights into
the dynamics of extreme opinions. Our work sheds light on the role of human
biases in shaping opinion dynamics and highlights the potential of
Bayesian-inspired modeling to provide more accurate predictions of real-world
scenarios.
  Keywords: Opinion dynamics, Bayesian methods, Cognition, CODA, Agent-based
models",http://arxiv.org/abs/2106.00199v2
"Optimizing travel routes using temporal networks constructed from GPS
  data",2021-06-01T09:02:03Z,"Tatsuro Mukai, Yuichi Ikeda","Because of the complexity of urban transportation networks and the temporal
changes in traffic conditions, it is difficult to assess real-time traffic
situations. However, the development of information terminals has made it
easier to obtain personal mobility information. In this study, we propose
methods for evaluating the mobility of people in a city using global
positioning system data. There are two main methods for evaluating movement.
One is to create a temporal network from real data and check the change in
travel time according to time zones or seasons. Temporal networks are difficult
to evaluate because of their time complexity, and in this study, we proposed an
evaluation method using the probability density function of travel time. The
other method is to define a time-dependent traveling salesman problem and find
an efficient traveling route by finding the shortest path. By creating a
time-dependent traveling salesman problem in an existing city and solving it, a
traveler can choose an efficient route by considering traffic conditions at
different times of the day. We used 2 months of data from Kyoto City to conduct
a traffic evaluation as a case study.",http://arxiv.org/abs/2106.00328v1
Dynamic perturbation spreading in networks,2021-06-01T12:02:35Z,"Malte Schröder, Xiaozhu Zhang, Justine Wolter, Marc Timme","Understanding how local perturbations induce the transient dynamics of a
network of coupled units is essential to control and operate such systems.
Often a perturbation initiated in one unit spreads to other units whose
dynamical state they transiently alter. The maximum state changes at those
units and the timings of these changes constitute key characteristics of such
transient response dynamics. However, even for linear dynamical systems it is
not possible to analytically determine time and amplitude of the maximal
response of a unit to a perturbation. Here, we propose to extract approximate
peak times and amplitudes from effective expectation values used to
characterize the typical time and magnitude of the response of a unit by
interpreting the system's response as a probability distribution over time. We
derive analytic estimators for the peak response based on these expectation
value measures in linearized systems operating close to a stable fixed point.
These estimators can be expressed in terms of the inverse of the system's
Jacobian. We obtain identical results with different approximations for the
response dynamics, indicating that these estimators become exact in the limit
of weak coupling. Furthermore, the results suggest that perturbations spread
ballistically in networks with diffusive coupling.",http://arxiv.org/abs/2106.00419v1
Fine-grained Finger Gesture Recognition Using WiFi Signals,2021-06-01T23:43:39Z,"Sheng Tan, Jie Yang","Gesture recognition has become increasingly important in human-computer
interaction and can support different applications such as smart home, VR, and
gaming. Traditional approaches usually rely on dedicated sensors that are worn
by the user or cameras that require line of sight. In this paper, we present
fine-grained finger gesture recognition by using commodity WiFi without
requiring user to wear any sensors. Our system takes advantages of the
fine-grained Channel State Information available from commodity WiFi devices
and the prevalence of WiFi network infrastructures. It senses and identifies
subtle movements of finger gestures by examining the unique patterns exhibited
in the detailed CSI. We devise environmental noise removal mechanism to
mitigate the effect of signal dynamic due to the environment changes. Moreover,
we propose to capture the intrinsic gesture behavior to deal with individual
diversity and gesture inconsistency. Lastly, we utilize multiple WiFi links and
larger bandwidth at 5GHz to achieve finger gesture recognition under multi-user
scenario. Our experimental evaluation in different environments demonstrates
that our system can achieve over 90% recognition accuracy and is robust to both
environment changes and individual diversity. Results also show that our system
can provide accurate gesture recognition under different scenarios.",http://arxiv.org/abs/2106.00857v1
"Towards Robust Classification Model by Counterfactual and Invariant Data
  Generation",2021-06-02T12:48:29Z,"Chun-Hao Chang, George Alexandru Adam, Anna Goldenberg","Despite the success of machine learning applications in science, industry,
and society in general, many approaches are known to be non-robust, often
relying on spurious correlations to make predictions. Spuriousness occurs when
some features correlate with labels but are not causal; relying on such
features prevents models from generalizing to unseen environments where such
correlations break. In this work, we focus on image classification and propose
two data generation processes to reduce spuriousness. Given human annotations
of the subset of the features responsible (causal) for the labels (e.g.
bounding boxes), we modify this causal set to generate a surrogate image that
no longer has the same label (i.e. a counterfactual image). We also alter
non-causal features to generate images still recognized as the original labels,
which helps to learn a model invariant to these features. In several
challenging datasets, our data generations outperform state-of-the-art methods
in accuracy when spurious correlations break, and increase the saliency focus
on causal features providing better explanations.",http://arxiv.org/abs/2106.01127v2
SIMLR: Machine Learning inside the SIR model for COVID-19 Forecasting,2021-06-03T04:22:43Z,"Roberto Vega, Leonardo Flores, Russell Greiner","Accurate forecasts of the number of newly infected people during an epidemic
are critical for making effective timely decisions. This paper addresses this
challenge using the SIMLR model, which incorporates machine learning (ML) into
the epidemiological SIR model. For each region, SIMLR tracks the changes in the
policies implemented at the government level, which it uses to estimate the
time-varying parameters of an SIR model for forecasting the number of new
infections 1- to 4-weeks in advance.It also forecasts the probability of
changes in those government policies at each of these future times, which is
essential for the longer-range forecasts. We applied SIMLR to data from regions
in Canada and in the United States,and show that its MAPE (mean average
percentage error) performance is as good as SOTA forecasting models, with the
added advantage of being an interpretable model. We expect that this approach
will be useful not only for forecasting COVID-19 infections, but also in
predicting the evolution of other infectious diseases.",http://arxiv.org/abs/2106.01590v1
"NODE-GAM: Neural Generalized Additive Model for Interpretable Deep
  Learning",2021-06-03T06:20:18Z,"Chun-Hao Chang, Rich Caruana, Anna Goldenberg","Deployment of machine learning models in real high-risk settings (e.g.
healthcare) often depends not only on the model's accuracy but also on its
fairness, robustness, and interpretability. Generalized Additive Models (GAMs)
are a class of interpretable models with a long history of use in these
high-risk domains, but they lack desirable features of deep learning such as
differentiability and scalability. In this work, we propose a neural GAM
(NODE-GAM) and neural GA$^2$M (NODE-GA$^2$M) that scale well and perform better
than other GAMs on large datasets, while remaining interpretable compared to
other ensemble and deep learning models. We demonstrate that our models find
interesting patterns in the data. Lastly, we show that we improve model
accuracy via self-supervised pre-training, an improvement that is not possible
for non-differentiable GAMs.",http://arxiv.org/abs/2106.01613v3
"Universal features of canonical phonon angular momentum without
  time-reversal symmetry",2021-06-03T10:18:01Z,"Hisayoshi Komiyama, Shuichi Murakami","It is known that phonons have angular momentum, and when the time-reversal
symmetry (TRS) is broken, the total phonon angular momentum in the whole system
becomes nonzero. In this paper, we propose that as an angular momentum of
phonons for a crystal without TRS, we need to consider the canonical angular
momentum, as opposed to the kinetic angular momentum in previous works. Next,
we show that the angular momentum of phonons without TRS exhibits universal
behaviors near the $\Gamma$ point. We focus on in-plane oscillations in
two-dimensional crystals as an example. By breaking the TRS, one of the
acoustic phonon branches at the $\Gamma$ point acquires a gap. We show that the
angular momentum of its acoustic phonon with a gap has a peak with the height
$\pm \hbar$ regardless of the details of the system. From this, we find that
this peak height changes discontinuously by changing the sign of the
TRS-breaking parameter.",http://arxiv.org/abs/2106.01731v2
Continual Learning in Deep Networks: an Analysis of the Last Layer,2021-06-03T13:41:29Z,"Timothée Lesort, Thomas George, Irina Rish","We study how different output layer parameterizations of a deep neural
network affects learning and forgetting in continual learning settings. The
following three effects can cause catastrophic forgetting in the output layer:
(1) weights modifications, (2) interference, and (3) projection drift. In this
paper, our goal is to provide more insights into how changing the output layer
parameterization may address (1) and (2). Some potential solutions to those
issues are proposed and evaluated here in several continual learning scenarios.
We show that the best-performing type of output layer depends on the data
distribution drifts and/or the amount of data available. In particular, in some
cases where a standard linear layer would fail, changing parameterization is
sufficient to achieve a significantly better performance, without introducing
any continual-learning algorithm but instead by using standard SGD to train a
model. Our analysis and results shed light on the dynamics of the output layer
in continual learning scenarios and suggest a way of selecting the best type of
output layer for a given scenario.",http://arxiv.org/abs/2106.01834v3
Primitive normalisers in quasipolynomial time,2021-06-03T14:31:55Z,"Mun See Chang, Colva M. Roney-Dougal","The normaliser problem has as input two subgroups $H$ and $K$ of the
symmetric group $S_n$, and asks for a generating set for $N_K(H)$: it is not
known to have a subexponential time solution. It is proved in [Roney-Dougal &
Siccha, 2020] that if $H$ is primitive then the normaliser problem can be
solved in quasipolynomial time. We show that for all subgroups $H$ and $K$ of
$S_n$, in quasipolynomial time we can decide whether $N_{S_n}(H)$ is primitive,
and if so compute $N_K(H)$. Hence we reduce the question of whether one can
solve the normaliser problem in quasipolynomial time to the case where the
normaliser is known not to be primitive.",http://arxiv.org/abs/2106.01886v1
Resonant Nonlinear Hall Effect in Two-Dimensional Electron Systems,2021-06-03T17:19:58Z,"Botsz Huang, Ali G. Moghaddam, Jorge I. Facio, Ching-Hao Chang","We study the Hall conductivity of a two-dimensional electron gas under an
inhomogeneous magnetic field $B(x)$. First, we prove using the quantum kinetic
theory that an odd magnetic field can lead to a purely nonlinear Hall response.
Second, considering a real-space magnetic dipole consisting of a sign-changing
magnetic field and based on numerical semiclassical dynamics, we unveil a
parametric resonance involving the cyclotron ratio and a characteristic width
of $B(x)$, which can greatly enhance the Hall response. Different from previous
mechanisms that rely on the bulk Berry curvature dipole, here, the effect
largely stems from boundary states associated with the real-space magnetic
dipole. Our findings pave a new way to engineer current rectification and
higher harmonic generation in two-dimensional materials having or not crystal
inversion symmetry.",http://arxiv.org/abs/2106.02001v2
Detecting and Adapting to Novelty in Games,2021-06-04T01:41:02Z,"Xiangyu Peng, Jonathan C. Balloch, Mark O. Riedl","Open-world novelty occurs when the rules of an environment can change
abruptly, such as when a game player encounters ""house rules"". To address
open-world novelty, game playing agents must be able to detect when novelty is
injected, and to quickly adapt to the new rules. We propose a model-based
reinforcement learning approach where game state and rules are represented as
knowledge graphs. The knowledge graph representation of the state and rules
allows novelty to be detected as changes in the knowledge graph, assists with
the training of deep reinforcement learners, and enables imagination-based
re-training where the agent uses the knowledge graph to perform look-ahead.",http://arxiv.org/abs/2106.02204v1
"An Energy-Based Interface Detection Method for Phase Change Processes in
  Nanoconfinements",2021-06-04T03:51:57Z,"Mustafa Ozsipahi, Yigit Akkus, Chinh Thanh Nguyen, Ali Beskok","An energy-based liquid-vapor interface detection method is presented using
molecular dynamics (MD) simulations of liquid menisci confined between two
parallel plates under equilibrium and evaporation/condensation conditions. This
method defines the liquid-vapor interface at the location where the kinetic
energy of the molecules first exceeds the total potential energy imposed by all
neighboring (liquid, vapor, and solid) atoms. This definition naturally adapts
to the location of the menisci relative to the walls and can properly model the
behavior of the liquid adsorbed layers. Unlike the density cutoff methods
frequently used in the literature that suffer from density layering effects,
this new method gives smooth and continuous liquid-vapor interfaces in
nanoconfinements. Surface tension values calculated from the equilibrium MD
simulations match the Young-Laplace equation better when using the radius of
curvatures calculated from this method. Overall, this energy-based liquid-vapor
interface detection method can be used in studies of nanoscale phase change
processes and other relevant applications.",http://arxiv.org/abs/2106.02238v1
The Failure of Galois Descent for p-Selmer Groups of Elliptic Curves,2021-06-04T13:46:36Z,Ross Paterson,"We show that if F is the rational numbers or a multiquadratic number field, p
is 2,3, or 5, and K/F is a Galois extension of degree a power of p, then for
elliptic curves E/Q ordered by height, the average dimension of the p-Selmer
groups of E/K is bounded. In particular, this provides a bound for the average
K-rank of elliptic curves E/Q for such K. Additionally, we give bounds for
certain representation-theoretic invariants of Mordell--Weil groups over Galois
extensions of such F.
  The central result is: for each finite Galois extension K/F of number fields
and prime number p, as E/Q varies, the difference in dimension between the
Galois fixed space in the p-Selmer group of E/K and the p-Selmer group of E/F
has bounded average.",http://arxiv.org/abs/2106.02486v2
Cohomological DT invariants from localization,2021-06-04T14:36:13Z,Pierre Descombes,"Given a quiver with potential associated to a toric Calabi-Yau threefold, the
numerical Donaldson-Thomas invariants for the moduli space of framed
representations can be computed by using toric localization, which reduces the
problem to the enumeration of molten crystals. We provide a refinement of this
localization procedure, which allows to compute motivic Donaldson-Thomas
invariants. Using this approach, we prove a universal formula which gives the
BPS invariants of any toric quiver, up to undetermined contributions which are
invariant under Poincar\'e duality. When the toric Calabi-Yau threefold has
compact divisors, these self-Poincar\'e dual contributions have a complicated
dependance on the stability parameters, but explicit computations suggest that
they drastically simplify for the self-stability condition (also called
attractor chamber). We conjecture a universal formula for the attractor
invariants, which applies to any toric Calabi-Yau singularity with compact
divisors.",http://arxiv.org/abs/2106.02518v2
Popular individuals process the world in particularly normative ways,2021-06-04T21:24:08Z,"Elisa C. Baek, Ryan Hyon, Karina López, Emily S. Finn, Mason A. Porter, Carolyn Parkinson","People differ in how they attend to, interpret, and respond to their
surroundings. Convergent processing of the world may be one factor that
contributes to social connections between individuals. We used neuroimaging and
network analysis to investigate whether the most central individuals in their
communities (as measured by in-degree centrality, a notion of popularity)
process the world in a particularly normative way. We found that more central
individuals had exceptionally similar neural responses to their peers and
especially to each other in brain regions that are associated with high-level
interpretations and social cognition (e.g., in the default-mode network),
whereas less-central individuals exhibited more idiosyncratic responses.
Self-reported enjoyment of and interest in stimuli followed a similar pattern,
but accounting for these data did not change our main results. These findings
suggest that highly-central individuals process the world in exceptionally
similar ways, whereas less-central individuals process the world in
idiosyncratic ways.",http://arxiv.org/abs/2106.02726v2
Anomalous Elasticity and Screening in Amorphous Solids,2021-06-06T07:11:48Z,"Anaël Lemaître, Chandana Mondal, Michael Moshe, Itamar Procaccia, Saikat Roy, Keren Screiber-Reém","Amorphous solids appear to react elastically to small external strains, but
in contrast to ideal elastic media, plastic responses abound immediately, at
any value of the strain. Such plastic responses are quasi-localized in nature,
with the ``cheapest"" one being a quadrupolar source. The existence of such
plastic responses results in {\em screened elasticity} in which strains and
stresses can either quantitatively or qualitatively differ from the un-screened
theory, depending on the specific screening mechanism. Here we offer a theory
of such screening effects by plastic quadrupoles, dipoles and monopoles,
explain their natural appearance, and point out the analogy to electrostatic
screening by electric charges and dipoles. For low density of quadrupoles the
effect is to normalize the elastic moduli without a qualitative change compared
to pure elasticity theory; for higher density of quadrupoles the screening
effects result in qualitative changes. Predictions for the spatial dependence
of displacement fields caused by local sources of strains are provided and
compared to numerical simulations. We find that anomalous elasticity is richer
than electrostatics in having a screening mode that does not appear in the
electrostatic analog",http://arxiv.org/abs/2106.03053v1
Tuning magnetic states in CrI$_3$ bilayers via Moiré patterns,2021-06-06T21:53:56Z,"A. M. León, E. A. Velásquez, F. Caro-Lopera, J. Mejía-López","Commensurable twisted bilayers can drastically change the magnetic properties
of chromium trihalide layered compounds, which opens novel opportunities for
tuning magnetic states through layer rotations. Here, we introduce a
mathematical approach to obtain moir\'e patterns in twisted hexagonal bilayers
by performing a certain commensurable rotation $\theta$ over one layer. To test
our approach, we apply it to find moir\'e structures with
$\theta=21.79^{\circ}$ and $32.20^{\circ}$ in the phases R$\bar{3}$ and C2/m of
CrI$_{3}$. For comparison purposes, we also consider a non-shifted CrI$_{3}$
structure. Electronic and magnetic properties of the so-obtained systems are
computed by \textit{Ab-Initio} methodologies. Results show the presence of
rotation-angle-dependent magnetic configurations and steep modifications of the
dispersion bands due to variations in the nearest and next nearest distances
among layers of Cr atoms. Modifications obtained from these commensurable
rotations are discussed on the basis of competition among different energy
contributions due to changes in the atomic arrangements.",http://arxiv.org/abs/2106.03258v2
Sub-trajectory Similarity Join with Obfuscation,2021-06-07T06:08:06Z,"Yanchuan Chang, Jianzhong Qi, Egemen Tanin, Xingjun Ma, Hanan Samet","User trajectory data is becoming increasingly accessible due to the
prevalence of GPS-equipped devices such as smartphones. Many existing studies
focus on querying trajectories that are similar to each other in their
entirety. We observe that trajectories partially similar to each other contain
useful information about users' travel patterns which should not be ignored.
Such partially similar trajectories are critical in applications such as
epidemic contact tracing. We thus propose to query trajectories that are within
a given distance range from each other for a given period of time. We formulate
this problem as a sub-trajectory similarity join query named as the STS-Join.
We further propose a distributed index structure and a query algorithm for
STS-Join, where users retain their raw location data and only send obfuscated
trajectories to a server for query processing. This helps preserve user
location privacy which is vital when dealing with such data. Theoretical
analysis and experiments on real data confirm the effectiveness and the
efficiency of our proposed index structure and query algorithm.",http://arxiv.org/abs/2106.03355v1
"Effect of Adaptive and Fixed Shared Steering Control on Distracted
  Driver Behavior",2021-06-07T06:39:15Z,"Zheng Wang, Satoshi Suga, Edric John Cruz Nacpil, Bo Yang, Kimihiko Nakano","Driver distraction is a well-known cause for traffic collisions worldwide.
Studies have indicated that shared steering control, which actively provides
haptic guidance torque on the steering wheel, effectively improves the
performance of distracted drivers. Recently, adaptive shared steering control
based on the physiological status of the driver has been developed, although
its effect on distracted driver behavior remains unclear. To this end, a
high-fidelity driving simulator experiment was conducted involving 18
participants performing double lane changes. The experimental conditions
comprised two driver states: attentive and distracted. Under each condition,
evaluations were performed on three types of haptic guidance: none (manual),
fixed authority, and adaptive authority based on feedback from the forearm
surface electromyography of the driver. Evaluation results indicated that, for
both attentive and distracted drivers, haptic guidance with adaptive authority
yielded lower driver workload and reduced lane departure risk than manual
driving and fixed authority. Moreover, there was a tendency for distracted
drivers to reduce grip strength on the steering wheel to follow the haptic
guidance with fixed authority, resulting in a relatively shorter double lane
change duration.",http://arxiv.org/abs/2106.03364v1
Commutative Lie Group VAE for Disentanglement Learning,2021-06-07T07:03:14Z,"Xinqi Zhu, Chang Xu, Dacheng Tao","We view disentanglement learning as discovering an underlying structure that
equivariantly reflects the factorized variations shown in data. Traditionally,
such a structure is fixed to be a vector space with data variations represented
by translations along individual latent dimensions. We argue this simple
structure is suboptimal since it requires the model to learn to discard the
properties (e.g. different scales of changes, different levels of abstractness)
of data variations, which is an extra work than equivariance learning. Instead,
we propose to encode the data variations with groups, a structure not only can
equivariantly represent variations, but can also be adaptively optimized to
preserve the properties of data variations. Considering it is hard to conduct
training on group structures, we focus on Lie groups and adopt a
parameterization using Lie algebra. Based on the parameterization, some
disentanglement learning constraints are naturally derived. A simple model
named Commutative Lie Group VAE is introduced to realize the group-based
disentanglement learning. Experiments show that our model can effectively learn
disentangled representations without supervision, and can achieve
state-of-the-art performance without extra constraints.",http://arxiv.org/abs/2106.03375v1
"The evolving usefulness of the Test-Negative Design in studying risk
  factors for COVID-19 due to changes in testing policy",2021-06-07T15:24:17Z,"Jan P Vandenbroucke, Elizabeth B Brickley, Christina M. J. E. Vandenbroucke-Grauls, Neil Pearce","This paper is a short extension of our previous paper [arXiv:2004.06033]
about the use of the Test-Negative design to study risk factors for COVID-19
[See: PubMed and ArXiv reference below] Reason for the extension is that the
conditions under which people refer themselves for testing have greatly
changed: originally, in most countries priority was given to people with
symptoms, but nowadays people without symptoms are also tested for different
reasons, e.g., during contact tracing, or to be allowed on an (international)
flight. Interestingly, this opens new possibilities to separately investigate
risk factors for infection and risk factors for becoming diseased. To use this
new situation to best effect, one has to think carefully about how to elucidate
the different reasons for testing and what analyses one might do with the
different groups.",http://arxiv.org/abs/2106.03713v1
Correcting Momentum in Temporal Difference Learning,2021-06-07T20:41:15Z,"Emmanuel Bengio, Joelle Pineau, Doina Precup","A common optimization tool used in deep reinforcement learning is momentum,
which consists in accumulating and discounting past gradients, reapplying them
at each iteration. We argue that, unlike in supervised learning, momentum in
Temporal Difference (TD) learning accumulates gradients that become doubly
stale: not only does the gradient of the loss change due to parameter updates,
the loss itself changes due to bootstrapping. We first show that this
phenomenon exists, and then propose a first-order correction term to momentum.
We show that this correction term improves sample efficiency in policy
evaluation by correcting target value drift. An important insight of this work
is that deep RL methods are not always best served by directly importing
techniques from the supervised setting.",http://arxiv.org/abs/2106.03955v1
Parameter Inference with Bifurcation Diagrams,2021-06-08T10:39:19Z,"Gregory Szep, Neil Dalchau, Attila Csikasz-Nagy","Estimation of parameters in differential equation models can be achieved by
applying learning algorithms to quantitative time-series data. However,
sometimes it is only possible to measure qualitative changes of a system in
response to a controlled condition. In dynamical systems theory, such change
points are known as bifurcations and lie on a function of the controlled
condition called the bifurcation diagram. In this work, we propose a
gradient-based approach for inferring the parameters of differential equations
that produce a user-specified bifurcation diagram. The cost function contains
an error term that is minimal when the model bifurcations match the specified
targets and a bifurcation measure which has gradients that push optimisers
towards bifurcating parameter regimes. The gradients can be computed without
the need to differentiate through the operations of the solver that was used to
compute the diagram. We demonstrate parameter inference with minimal models
which explore the space of saddle-node and pitchfork diagrams and the genetic
toggle switch from synthetic biology. Furthermore, the cost landscape allows us
to organise models in terms of topological and geometric equivalence.",http://arxiv.org/abs/2106.04243v3
Observation of mutual extinction and transparency in light scattering,2021-06-08T13:25:00Z,"Alfredo Rates, Ad Lagendijk, Ozan Akdemir, Allard P. Mosk, Willem L. Vos","Interference of scattered waves is fundamental for modern light-scattering
techniques, such as optical wavefront shaping. Recently, a new type of
wavefront shaping was introduced where the extinction is manipulated instead of
the scattered intensity. The underlying idea is that upon changing the phases
or the amplitudes of incident beams, the total extinction will change due to
interference described by the cross terms between different incident beams.
Here, we experimentally demonstrate the mutual extinction and transparency
effects in scattering media, in particular, a human hair and a silicon bar. To
this end, we send two light beams with a variable mutual angle on the sample.
Depending on the relative phase of the incident beams we observe either nearly
zero extinction, mutual transparency, or almost twice the single-beam
extinction, mutual extinction, in agreement with theory. We use an analytical
approximation for the scattering amplitude, starting from a completely opaque
object and we discuss the limitations of our approximation. We discuss the
applications of the mutual extinction and transparency effects in various
fields such as non-line-of-sight communications, microscopy, and biomedical
imaging.",http://arxiv.org/abs/2106.04318v2
Efficient Online Learning for Dynamic k-Clustering,2021-06-08T13:53:12Z,"Dimitris Fotakis, Georgios Piliouras, Stratis Skoulakis","We study dynamic clustering problems from the perspective of online learning.
We consider an online learning problem, called \textit{Dynamic $k$-Clustering},
in which $k$ centers are maintained in a metric space over time (centers may
change positions) such as a dynamically changing set of $r$ clients is served
in the best possible way. The connection cost at round $t$ is given by the
\textit{$p$-norm} of the vector consisting of the distance of each client to
its closest center at round $t$, for some $p\geq 1$ or $p = \infty$. We present
a \textit{$\Theta\left( \min(k,r) \right)$-regret} polynomial-time online
learning algorithm and show that, under some well-established computational
complexity conjectures, \textit{constant-regret} cannot be achieved in
polynomial-time. In addition to the efficient solution of Dynamic
$k$-Clustering, our work contributes to the long line of research on
combinatorial online learning.",http://arxiv.org/abs/2106.04336v1
"Dynamic Software Updates for Unmodified Browsers through Multi-Version
  Execution",2021-06-08T19:38:14Z,"Siddhanth Venkateshwaran, Ellen Kidane, Luís Pina","In this paper, we present the design, implementation, and evaluation of
SINATRA, which supports instantaneous browser updates that do not result in any
data loss through a novel Multi-Version eXecution (MVX) approach for JavaScript
programs. SINATRA works in pure JavaScript, does not require any browser
support, thus works on closed-source browsers, and requires trivial changes to
each target page, that can be automated. First, SINATRA captures all the
non-determinism available to a JavaScript program (e.g., event handlers
executed, expired timers, invocations of Math.random). Our evaluation shows
that SINATRA requires 5MB to store such events, and the memory grows at a
modest rate of 23.1KB/s as the user keeps interacting with each page. When an
update becomes available, SINATRA transfer the state by re-executing the same
set of non-deterministic events on the new browser. During this time, which can
be as long as 13 seconds, SINATRA uses MVX to allow the user to keep
interacting with the old browser. Finally, SINATRA changes the roles in 353ms,
and the user starts interacting with the new browser, effectively performing a
browser update with zero downtime and no loss of state.",http://arxiv.org/abs/2106.04655v1
CLCC: Contrastive Learning for Color Constancy,2021-06-09T11:16:31Z,"Yi-Chen Lo, Chia-Che Chang, Hsuan-Chao Chiu, Yu-Hao Huang, Chia-Ping Chen, Yu-Lin Chang, Kevin Jou","In this paper, we present CLCC, a novel contrastive learning framework for
color constancy. Contrastive learning has been applied for learning
high-quality visual representations for image classification. One key aspect to
yield useful representations for image classification is to design illuminant
invariant augmentations. However, the illuminant invariant assumption conflicts
with the nature of the color constancy task, which aims to estimate the
illuminant given a raw image. Therefore, we construct effective contrastive
pairs for learning better illuminant-dependent features via a novel raw-domain
color augmentation. On the NUS-8 dataset, our method provides $17.5\%$ relative
improvements over a strong baseline, reaching state-of-the-art performance
without increasing model complexity. Furthermore, our method achieves
competitive performance on the Gehler dataset with $3\times$ fewer parameters
compared to top-ranking deep learning methods. More importantly, we show that
our model is more robust to different scenes under close proximity of
illuminants, significantly reducing $28.7\%$ worst-case error in data-sparse
regions.",http://arxiv.org/abs/2106.04989v1
Traversable Wormholes in General Relativity,2021-06-09T12:47:20Z,"R. A. Konoplya, A. Zhidenko","In [J. Blazquez-Salcedo, C. Knoll, E. Radu, Phys. Rev. Lett. 126 (2021)
no.10, 101102] asymptotically flat traversable wormhole solutions were obtained
in the Einstein-Dirac-Maxwell theory without using phantom matter. The
normalizable numerical solutions found therein require a peculiar behavior at
the throat: the mirror symmetry relatively the throat leads to the
nonsmoothness of gravitational and matter fields. In particular, one must
postulate changing of the sign of the fermionic charge density at the throat,
requiring coexistence of particle and antiparticles without annihilation and
posing a membrane of matter at the throat with specific properties. Apparently
this kind of configuration could not exist in nature. We show that there are
wormhole solutions, which are asymmetric relative the throat and endowed by
smooth gravitational and matter fields, thereby being free from all the above
problems. This indicates that such wormhole configurations could also be
supported in a realistic scenario.",http://arxiv.org/abs/2106.05034v4
"Thermoelectric transport of type-I, II, and III massless Dirac fermions
  in two-dimensional lattice model",2021-06-10T00:07:16Z,"Tomonari Mizoguchi, Hiroyasu Matsuura, Masao Ogata","We study longitudinal electric and thermoelectric transport coefficients of
Dirac fermions on a simple lattice model where tuning of a single parameter
enables us to change the type of Dirac cones from type-I to type-II. We pay
particular attention to the behavior of the critical situation, i.e., the
type-III Dirac cone. We find that the transport coefficients of the type-III
Dirac fermions behave as the limiting case of neither the type-I nor type-II.
On the one hand, the qualitative behaviors of the type-III case are similar to
those of the type-I case. On the other hand, the transport coefficients do not
change monotonically upon increasing the tilting; namely, the largest
thermoelectric response is obtained not for the type-III case but for the
optimally tilted type-I case. For the optimal case, the sizable transport
coefficients are obtained; for example, the dimensionless figure of merit is
0.18.",http://arxiv.org/abs/2106.05435v2
"Multiplicative perturbation bounds for the Generalized block Cholesky
  downdating problem",2021-06-10T01:08:37Z,"Mahvish Samara, Aamir Farooq","The explicit expressions for the strong and the weak rigorous multiplicative
perturbation bounds for the Generalized block Cholesky downdating problem are
obtained. By bringing together the modified matrix-vector equation approach
with the method of Lyapunov majorant function and the Banach fixed point
theorem, we derived the strong rigorous multiplicative perturbation bounds. By
using the matrix-equation approach the weak rigorous multiplicative bounds are
presented. Numerical experiments are provided to illustrate the obtained
results.",http://arxiv.org/abs/2106.05444v2
"Convolutions and Self-Attention: Re-interpreting Relative Positions in
  Pre-trained Language Models",2021-06-10T05:11:35Z,"Tyler A. Chang, Yifan Xu, Weijian Xu, Zhuowen Tu","In this paper, we detail the relationship between convolutions and
self-attention in natural language tasks. We show that relative position
embeddings in self-attention layers are equivalent to recently-proposed dynamic
lightweight convolutions, and we consider multiple new ways of integrating
convolutions into Transformer self-attention. Specifically, we propose
composite attention, which unites previous relative position embedding methods
under a convolutional framework. We conduct experiments by training BERT with
composite attention, finding that convolutions consistently improve performance
on multiple downstream tasks, replacing absolute position embeddings. To inform
future work, we present results comparing lightweight convolutions, dynamic
convolutions, and depthwise-separable convolutions in language model
pre-training, considering multiple injection points for convolutions in
self-attention layers.",http://arxiv.org/abs/2106.05505v1
Integer programs with bounded subdeterminants and two nonzeros per row,2021-06-10T17:46:01Z,"Samuel Fiorini, Gwenaël Joret, Stefan Weltge, Yelena Yuditsky","We give a strongly polynomial-time algorithm for integer linear programs
defined by integer coefficient matrices whose subdeterminants are bounded by a
constant and that contain at most two nonzero entries in each row. The core of
our approach is the first polynomial-time algorithm for the weighted stable set
problem on graphs that do not contain more than $k$ vertex-disjoint odd cycles,
where $k$ is any constant. Previously, polynomial-time algorithms were only
known for $k=0$ (bipartite graphs) and for $k=1$.
  We observe that integer linear programs defined by coefficient matrices with
bounded subdeterminants and two nonzeros per column can be also solved in
strongly polynomial-time, using a reduction to $b$-matching.",http://arxiv.org/abs/2106.05947v4
CausalAdv: Adversarial Robustness through the Lens of Causality,2021-06-11T06:55:02Z,"Yonggang Zhang, Mingming Gong, Tongliang Liu, Gang Niu, Xinmei Tian, Bo Han, Bernhard Schölkopf, Kun Zhang","The adversarial vulnerability of deep neural networks has attracted
significant attention in machine learning. As causal reasoning has an instinct
for modelling distribution change, it is essential to incorporate causality
into analyzing this specific type of distribution change induced by adversarial
attacks. However, causal formulations of the intuition of adversarial attacks
and the development of robust DNNs are still lacking in the literature. To
bridge this gap, we construct a causal graph to model the generation process of
adversarial examples and define the adversarial distribution to formalize the
intuition of adversarial attacks. From the causal perspective, we study the
distinction between the natural and adversarial distribution and conclude that
the origin of adversarial vulnerability is the focus of models on spurious
correlations. Inspired by the causal understanding, we propose the Causal
inspired Adversarial distribution alignment method, CausalAdv, to eliminate the
difference between natural and adversarial distributions by considering
spurious correlations. Extensive experiments demonstrate the efficacy of the
proposed method. Our work is the first attempt towards using causality to
understand and mitigate the adversarial vulnerability.",http://arxiv.org/abs/2106.06196v2
"Measurement of onset of structural relaxation in melt-quenched phase
  change materials",2021-06-11T09:37:41Z,"Benedikt Kersting, Syed Ghazi Sarwat, Manuel Le Gallo, Kevin Brew, Sebastian Walfort, Nicole Saulnier, Martin Salinga, Abu Sebastian","Chalcogenide phase change materials enable non-volatile, low-latency
storage-class memory. They are also being explored for new forms of computing
such as neuromorphic and in-memory computing. A key challenge, however, is the
temporal drift in the electrical resistance of the amorphous states that encode
data. Drift, caused by the spontaneous structural relaxation of the newly
recreated melt-quenched amorphous phase, has consistently been observed to have
a logarithmic dependence in time. Here, we show that this observation is valid
only in a certain observable timescale. Using threshold-switching voltage as
the measured variable, based on temperature-dependent and short timescale
electrical characterization, we experimentally measure the onset of drift. This
additional feature of the structural relaxation dynamics serves as a new
benchmark to appraise the different classical models to explain drift.",http://arxiv.org/abs/2106.06270v1
Effective potentials induced by mixtures of patchy and hard co-solutes,2021-06-11T13:20:18Z,"Philip H. Handle, Emanuela Zaccarelli, Nicoletta Gnan","The addition of co-solutes to colloidal suspensions is often employed to
induce tunable depletion interactions. In this work we investigate effective
colloidal interactions arising from binary co-solute mixtures of hard spheres
and patchy particles. By changing the relative concentration of the two
species, we show that the resulting effective potential $V_\text{eff}$
continuously changes from the one obtained for a single-component hard sphere
co-solute to that mediated by the single-component patchy particle co-solute.
Interestingly, we find that, independently of the relative concentration of the
two components, the resulting $V_\text{eff}$ is additive, i.e., it is
well-described by the linear combination of the effective interactions mediated
by respective pure co-solutes. However, a breakdown of the additivity occurs
when the co-solute mixture is close to the onset of a demixing transition.
These results represent a step forward in understanding and predicting
colloidal behaviour in complex and crowded environments and for exploiting this
knowledge to design targeted colloidal superstructures.",http://arxiv.org/abs/2106.06371v1
"Sign-reversible valley-dependent Berry phase effects in 2D
  valley-half-semiconductors",2021-06-11T13:33:37Z,"Xiaodong Zhou, Run-Wu Zhang, Zeying Zhang, Wanxiang Feng, Yuriy Mokrousov, Yugui Yao","Manipulating valley-dependent Berry phase effects provides remarkable
opportunities for both fundamental research and practical applications. Here,
by referring to effective model analysis, we propose a general scheme for
realizing topological magneto-valley phase transitions. More importantly, by
using valley-half-semiconducting VSi2N4 as an outstanding example, we
investigate sign change of valley-dependent Berry phase effects which drive the
change-in-sign valley anomalous transport characteristics via external means
such as biaxial strain, electric field, and correlation effects. As a result,
this gives rise to quantized versions of valley anomalous transport phenomena.
Our findings not only uncover a general framework to control valley degree of
freedom, but also motivate further research in the direction of multifunctional
quantum devices in valleytronics and spintronics.",http://arxiv.org/abs/2106.06379v3
"A three Higgs doublet model with symmetry-suppressed flavour changing
  neutral currents",2021-06-11T14:34:12Z,"Dipankar Das, P. M. Ferreira, António P. Morais, Ian Padilla-Gay, Roman Pasechnik, J. Pedro Rodrigues","We construct a three-Higgs doublet model with a flavour non-universal ${\rm
U}(1)\times \mathbb{Z}_2$ symmetry. That symmetry induces suppressed
flavour-changing interactions mediated by neutral scalars. New scalars with
masses below the TeV scale can still successfully negotiate the constraints
arising from flavour data. Such a model can thus encourage direct searches for
extra Higgs bosons in the future collider experiments, and includes a
non-trivial flavour structure.",http://arxiv.org/abs/2106.06425v3
The X-Rays wind connection in PG 2112+059,2021-06-11T18:36:29Z,"C. Saez, W. N. Brandt, F. Bauer, G. Chartas, T. Misawa, F. Hamann, S. Gallagher","We study the connection between the X-ray and UV properties of the broad
absorption line (BAL) wind in the highly X-ray variable quasar PG 2112+059 by
comparing Chandra-ACIS data with contemporaneous UV HST/STIS spectra in three
different epochs. We observe a correlation whereby an increase in the
equivalent-widths (EWs) of the BALs is accompanied by a redder UV spectrum. The
growth in the BALs EWs is also accompanied by a significant dimming in soft
X-ray emission (<2 keV), consistent with increased absorption. Variations in
the hard X-ray emission (>2 keV) are only accompanied by minor spectral
variations of the UV-BALs and do not show significant changes in the EW of
BALs. These trends suggest a wind-shield scenario where the outflow inclination
with respect to the line of sight is decreasing and/or the wind mass is
increasing. These changes elevate the covering fraction and/or column densities
of the BALs and are likely accompanied by a nearly contemporaneous increase in
the column density of the shield.",http://arxiv.org/abs/2106.06567v2
"Effect of the metallicity on the capacitance of gold - aqueous sodium
  chloride interfaces",2021-06-14T08:39:10Z,"Alessandra Serva, Laura Scalfi, Benjamin Rotenberg, Mathieu Salanne","Electrochemistry experiments have established that the capacitance of
electrode-electrolyte interfaces is much larger for good metals such as gold
and platinum than for carbon-based materials. Despite the development of
elaborate electrode interaction potentials, to date molecular dynamics
simulations were not able to capture this effect. Here we show that changing
the width of the Gaussian charge distribution used to represent the atomic
charges in gold is an effective way to tune its metallicity. Larger Gaussian
widths lead to a capacitance of aqueous solutions (pure water and 1 molar NaCl)
in good agreement with recent ab initio molecular dynamics results. For pure
water, the increase in the capacitance is not accompanied with structural
changes, while in the presence of salt the Na$^+$ cations tend to adsorb
significantly on the surface. For a strongly metallic gold electrode, these
ions can even form inner sphere complexes on hollow sites of the surface.",http://arxiv.org/abs/2106.07232v1
Bounds of the spectral radius of the induced map on cohomology,2021-06-14T16:24:28Z,Sven Sandfeldt,"In this paper we study the relationship between Lyapunov exponents and the
induced map on cohomology for $C^{1}-$diffeomorphisms on compact manifolds. We
show that if the induced map on cohomology has spectral radius strictly larger
than 1, then the diffeomorphism has an invariant ergodic measure with at least
one positive Lyapunov exponent. Furthermore, if the diffeomorphism also
preserves a continuous volume form then it has an invariant ergodic measure
with at least one positive and one negative Lyapunov exponent, in agreement
with Shub's entropy conjecture. We also consider diffeomorphisms preserving a
measure equivalent to volume. In this case we show that if the Lyapunov metric
satisfies an integrability condition and the induced map on cohomology has
spectral radius strictly larger than 1, then the diffeomorphism has non-zero
Lyapunov exponents on a set of positive volume.",http://arxiv.org/abs/2106.07572v3
Dynamic Asymmetric Causality Tests with an Application,2021-06-14T17:17:30Z,Abdulnasser Hatemi-J,"Testing for causation, defined as the preceding impact of the past values of
one variable on the current value of another one when all other pertinent
information is accounted for, is increasingly utilized in empirical research of
the time-series data in different scientific disciplines. A relatively recent
extension of this approach has been allowing for potential asymmetric impacts
since it is harmonious with the way reality operates in many cases according to
Hatemi-J (2012). The current paper maintains that it is also important to
account for the potential change in the parameters when asymmetric causation
tests are conducted, as there exists a number of reasons for changing the
potential causal connection between variables across time. The current paper
extends therefore the static asymmetric causality tests by making them dynamic
via the usage of subsamples. An application is also provided consistent with
measurable definitions of economic or financial bad as well as good news and
their potential interaction across time.",http://arxiv.org/abs/2106.07612v2
Measuring time with stationary quantum clocks,2021-06-14T18:08:41Z,"Sergii Strelchuk, Mischa P. Woods","Time plays a fundamental role in our ability to make sense of the physical
laws in the world around us. The nature of time has puzzled people -- from the
ancient Greeks to the present day -- resulting in a long running debate between
philosophers and physicists alike to whether time needs change to exist (the
so-called relatival theory), or whether time flows regardless of change (the
so-called substantival theory). One way to decide between the two is to attempt
to measure the flow of time with a stationary clock, since if time were
substantival, the flow of time would manifest itself in the experiment. Alas,
conventional wisdom suggests that in order for a clock to function, it cannot
be a static object, thus rendering this experiment seemingly impossible. Here
we show, with the aid of counterfactual measurements, the surprising result
that a quantum clock can measure the passage of time even while being switched
off, thus lending constructive support for the substantival theory of time.",http://arxiv.org/abs/2106.07684v2
Deep Reinforcement Learning for Conservation Decisions,2021-06-15T16:32:48Z,"Marcus Lapeyrolerie, Melissa S. Chapman, Kari E. A. Norman, Carl Boettiger","Can machine learning help us make better decisions about a changing planet?
In this paper, we illustrate and discuss the potential of a promising corner of
machine learning known as _reinforcement learning_ (RL) to help tackle the most
challenging conservation decision problems. RL is uniquely well suited to
conservation and global change challenges for three reasons: (1) RL explicitly
focuses on designing an agent who _interacts_ with an environment which is
dynamic and uncertain, (2) RL approaches do not require massive amounts of
data, (3) RL approaches would utilize rather than replace existing models,
simulations, and the knowledge they contain. We provide a conceptual and
technical introduction to RL and its relevance to ecological and conservation
challenges, including examples of a problem in setting fisheries quotas and in
managing ecological tipping points. Four appendices with annotated code provide
a tangible introduction to researchers looking to adopt, evaluate, or extend
these approaches.",http://arxiv.org/abs/2106.08272v1
Linear-response magnetoresistance effects in chiral systems,2021-06-16T07:22:42Z,"Xu Yang, Bart J. van Wees","The chirality-induced spin selectivity (CISS) effect enables the detection of
chirality as electrical charge signals. It is often studied using a
two-terminal circuit geometry where a ferromagnet is connected to a chiral
component, and a change of electrical resistance is reported upon magnetization
reversal. This is however not expected in the linear response regime because of
compensating reciprocal processes, limiting the interpretation of experimental
results. Here we show that magnetoresistance effects can indeed appear even in
the linear response regime, either by changing the magnitude or the direction
of the magnetization or an applied magnetic field. We illustrate this in a
spin-valve device and in a chiral thin film as the CISS-induced Hanle
magnetoresistance (CHMR) effect. This effect helps to distinguish
spin-transport-related effects from other effects, and can thereby provide
further insight into the origin of CISS.",http://arxiv.org/abs/2106.08586v2
Velos: One-sided Paxos for RDMA applications,2021-06-16T10:28:31Z,"Rachid Guerraoui, Antoine Murat, Athanasios Xygkis","Modern data centers are becoming increasingly equipped with RDMA-capable
NICs. These devices enable distributed systems to rely on algorithms designed
for shared memory. RDMA allows consensus to terminate within a few microsecond
in failure-free scenarios, yet, RDMA-optimized algorithms still use expensive
two-sided operations in case of failure. In this work, we present a new
leader-based consensus algorithm that relies solely on one-sided RDMA verbs.
Our algorithm is based on Paxos, it decides in a single one-sided RDMA
operation in the common case, and changes leader also in a single one-sided
RDMA operation in case of failure. We implement our algorithm in the form of an
SMR system named Velos, and we evaluated our system against the
state-of-the-art competitor Mu. Compared to Mu, our solution adds a small
overhead of approximately 0.6 microseconds in failure-free executions and
shines during failover periods during which it is 13 times faster in changing
leader.",http://arxiv.org/abs/2106.08676v1
"Smoothing the Disentangled Latent Style Space for Unsupervised
  Image-to-Image Translation",2021-06-16T17:58:21Z,"Yahui Liu, Enver Sangineto, Yajing Chen, Linchao Bao, Haoxian Zhang, Nicu Sebe, Bruno Lepri, Wei Wang, Marco De Nadai","Image-to-Image (I2I) multi-domain translation models are usually evaluated
also using the quality of their semantic interpolation results. However,
state-of-the-art models frequently show abrupt changes in the image appearance
during interpolation, and usually perform poorly in interpolations across
domains. In this paper, we propose a new training protocol based on three
specific losses which help a translation network to learn a smooth and
disentangled latent style space in which: 1) Both intra- and inter-domain
interpolations correspond to gradual changes in the generated images and 2) The
content of the source image is better preserved during the translation.
Moreover, we propose a novel evaluation metric to properly measure the
smoothness of latent style space of I2I translation models. The proposed method
can be plugged into existing translation approaches, and our extensive
experiments on different datasets show that it can significantly boost the
quality of the generated images and the graduality of the interpolations.",http://arxiv.org/abs/2106.09016v1
"Fréchet derivatives of expected functionals of solutions to
  stochastic differential equations",2021-06-16T21:52:27Z,Han Cheng Lie,"In the analysis of stochastic dynamical systems described by stochastic
differential equations (SDEs), it is often of interest to analyse the
sensitivity of the expected value of a functional of the solution of the SDE
with respect to perturbations in the SDE parameters. In this paper, we consider
path functionals that depend on the solution of the SDE up to a stopping time.
We derive formulas for Fr\'{e}chet derivatives of the expected values of these
functionals with respect to bounded perturbations of the drift, using the
Cameron-Martin-Girsanov theorem for the change of measure. Using these
derivatives, we construct an example to show that the map that sends the change
of drift to the corresponding relative entropy is not in general convex. We
then analyse the existence and uniqueness of solutions to stochastic optimal
control problems defined on possibly random time intervals, as well as
gradient-based numerical methods for solving such problems.",http://arxiv.org/abs/2106.09149v1
"Recovery Guarantees for Time-varying Pairwise Comparison Matrices with
  Non-transitivity",2021-06-16T21:57:53Z,"Shuang Li, Michael B. Wakin","Pairwise comparison matrices have received substantial attention in a variety
of applications, especially in rank aggregation, the task of flattening items
into a one-dimensional (and thus transitive) ranking. However, non-transitive
preference cycles can arise in practice due to the fact that making a decision
often requires a complex evaluation of multiple factors. In some applications,
it may be important to identify and preserve information about the inherent
non-transitivity, either in the pairwise comparison data itself or in the
latent feature space. In this work, we develop structured models for
non-transitive pairwise comparison matrices that can be exploited to recover
such matrices from incomplete noisy data and thus allow the detection of
non-transitivity. Considering that individuals' tastes and items' latent
features may change over time, we formulate time-varying pairwise comparison
matrix recovery as a dynamic skew-symmetric matrix recovery problem by modeling
changes in the low-rank factors of the pairwise comparison matrix. We provide
theoretical guarantees for the recovery and numerically test the proposed
theory with both synthetic and real-world data.",http://arxiv.org/abs/2106.09151v1
Defying Gravity: The Economic Effects of Social Distancing,2021-06-17T10:27:46Z,"Alfredo D. Garcia, Christopher A. Hartwell, Martín Andrés Szybisz","The COVID-19 pandemic has forced changes in production and especially in
human interaction, with ""social distancing"" a standard prescription for slowing
transmission of the disease. This paper examines the economic effects of social
distancing at the aggregate level, weighing both the benefits and costs to
prolonged distancing. Specifically we fashion a model of economic recovery when
the productive capacity of factors of production is restricted by social
distancing, building a system of equations where output growth and social
distance changes are interdependent. The model attempts to show the complex
interactions between output levels and social distancing, developing cycle
paths for both variables. Ultimately, however, defying gravity via prolonged
social distancing shows that a lower growth path is inevitable as a result.",http://arxiv.org/abs/2106.09361v1
"Elicitation of Adaptive Requirements Using Creativity Triggers: A
  Controlled Experiment",2021-06-17T13:33:07Z,"Fabian Kneer, Erik Kamsties, Klaus Schmid","Adaptive systems react to changes in their environment by changing their
behavior. Identifying these needed adaptations is very difficult, but central
to requirements elicitation for adaptive systems. As the necessary or potential
adaptations are typically not obvious to the stakeholders, the problem is how
to effectively elicit adaptation-relevant information. One approach is to use
creativity techniques to support the systematic identification and elicitation
of adaptation requirements. In particular, here, we analyze a set of creativity
triggers defined for systematic exploration of potential adaptation
requirements. We compare these triggers with brainstorming as a baseline in a
controlled experiment with 85 master students. The results indicate that the
proposed triggers are suitable for the efficient elicitation of adaptive
requirements and that the 15 trigger questions produce significantly more
requirements fragments than solo brainstorming.",http://arxiv.org/abs/2106.09482v1
"DeepInsight: Interpretability Assisting Detection of Adversarial Samples
  on Graphs",2021-06-17T13:50:19Z,"Junhao Zhu, Yalu Shan, Jinhuan Wang, Shanqing Yu, Guanrong Chen, Qi Xuan","With the rapid development of artificial intelligence, a number of machine
learning algorithms, such as graph neural networks have been proposed to
facilitate network analysis or graph data mining. Although effective, recent
studies show that these advanced methods may suffer from adversarial attacks,
i.e., they may lose effectiveness when only a small fraction of links are
unexpectedly changed. This paper investigates three well-known adversarial
attack methods, i.e., Nettack, Meta Attack, and GradArgmax. It is found that
different attack methods have their specific attack preferences on changing the
target network structures. Such attack pattern are further verified by
experimental results on some real-world networks, revealing that generally the
top four most important network attributes on detecting adversarial samples
suffice to explain the preference of an attack method. Based on these findings,
the network attributes are utilized to design machine learning models for
adversarial sample detection and attack method recognition with outstanding
performance.",http://arxiv.org/abs/2106.09501v2
PAC Prediction Sets Under Covariate Shift,2021-06-17T23:28:42Z,"Sangdon Park, Edgar Dobriban, Insup Lee, Osbert Bastani","An important challenge facing modern machine learning is how to rigorously
quantify the uncertainty of model predictions. Conveying uncertainty is
especially important when there are changes to the underlying data distribution
that might invalidate the predictive model. Yet, most existing uncertainty
quantification algorithms break down in the presence of such shifts. We propose
a novel approach that addresses this challenge by constructing \emph{probably
approximately correct (PAC)} prediction sets in the presence of covariate
shift. Our approach focuses on the setting where there is a covariate shift
from the source distribution (where we have labeled training examples) to the
target distribution (for which we want to quantify uncertainty). Our algorithm
assumes given importance weights that encode how the probabilities of the
training examples change under the covariate shift. In practice, importance
weights typically need to be estimated; thus, we extend our algorithm to the
setting where we are given confidence intervals for the importance weights. We
demonstrate the effectiveness of our approach on covariate shifts based on
DomainNet and ImageNet. Our algorithm satisfies the PAC constraint, and gives
prediction sets with the smallest average normalized size among approaches that
always satisfy the PAC constraint.",http://arxiv.org/abs/2106.09848v2
World-GAN: a Generative Model for Minecraft Worlds,2021-06-18T14:45:39Z,"Maren Awiszus, Frederik Schubert, Bodo Rosenhahn","This work introduces World-GAN, the first method to perform data-driven
Procedural Content Generation via Machine Learning in Minecraft from a single
example. Based on a 3D Generative Adversarial Network (GAN) architecture, we
are able to create arbitrarily sized world snippets from a given sample. We
evaluate our approach on creations from the community as well as structures
generated with the Minecraft World Generator. Our method is motivated by the
dense representations used in Natural Language Processing (NLP) introduced with
word2vec [1]. The proposed block2vec representations make World-GAN independent
from the number of different blocks, which can vary a lot in Minecraft, and
enable the generation of larger levels. Finally, we demonstrate that changing
this new representation space allows us to change the generated style of an
already trained generator. World-GAN enables its users to generate Minecraft
worlds based on parts of their creations.",http://arxiv.org/abs/2106.10155v1
Circular orderability of 3-manifold groups,2021-06-20T18:10:58Z,"Idrissa Ba, Adam Clay","This paper initiates the study of circular orderability of $3$-manifold
groups, motivated by the L-space conjecture. We show that a compact, connected,
$\mathbb{P}^2$-irreducible $3$-manifold has a circularly orderable fundamental
group if and only if there exists a finite cyclic cover with left-orderable
fundamental group, which naturally leads to a ""circular orderability version""
of the L-space conjecture. We also show that the fundamental groups of almost
all graph manifolds are circularly orderable, and contrast the behaviour of
circularly orderability and left-orderability with respect to the operations of
Dehn surgery and taking cyclic branched covers.",http://arxiv.org/abs/2106.10736v2
"Quantum electrodynamics in anisotropic and tilted Dirac photonic
  lattices",2021-06-20T19:55:30Z,"J. Redondo-Yuste, M. Blanco de Paz, P. A. Huidobro, A. González-Tudela","One of the most striking predictions of quantum electrodynamics is that
vacuum fluctuations of the electromagnetic field can lead to spontaneous
emission of atoms as well as photon-mediated interactions among them. Since
these processes strongly depend on the nature of the photonic bath, a current
burgeoning field is the study of their modification in the presence of photons
with non-trivial energy dispersions, e.g., the ones confined in photonic
crystals. A remarkable example is the case of isotropic Dirac-photons, which
has been recently shown to lead to non-exponential spontaneous emission as well
as dissipation-less long-range emitter interactions. In this work, we show how
to further tune these processes by considering anisotropic Dirac cone
dispersions, which include tilted, semi-Dirac, and the recently discovered type
II and III Dirac points. In particular, we show how by changing the anisotropy
of the lattice one can change both the spatial shape of the interactions as
well as its coherent/incoherent nature. Finally, we discuss a possible
implementation where these energy dispersions can be engineered and interfaced
with quantum emitters based on subwavelength atomic arrays.",http://arxiv.org/abs/2106.10743v1
"Does Robustness Improve Fairness? Approaching Fairness with Word
  Substitution Robustness Methods for Text Classification",2021-06-21T03:20:44Z,"Yada Pruksachatkun, Satyapriya Krishna, Jwala Dhamala, Rahul Gupta, Kai-Wei Chang","Existing bias mitigation methods to reduce disparities in model outcomes
across cohorts have focused on data augmentation, debiasing model embeddings,
or adding fairness-based optimization objectives during training. Separately,
certified word substitution robustness methods have been developed to decrease
the impact of spurious features and synonym substitutions on model predictions.
While their end goals are different, they both aim to encourage models to make
the same prediction for certain changes in the input. In this paper, we
investigate the utility of certified word substitution robustness methods to
improve equality of odds and equality of opportunity on multiple text
classification tasks. We observe that certified robustness methods improve
fairness, and using both robustness and bias mitigation methods in training
results in an improvement in both fronts",http://arxiv.org/abs/2106.10826v1
On Limited-Memory Subsampling Strategies for Bandits,2021-06-21T09:11:22Z,"Dorian Baudry, Yoan Russac, Olivier Cappé","There has been a recent surge of interest in nonparametric bandit algorithms
based on subsampling. One drawback however of these approaches is the
additional complexity required by random subsampling and the storage of the
full history of rewards. Our first contribution is to show that a simple
deterministic subsampling rule, proposed in the recent work of Baudry et al.
(2020) under the name of ''last-block subsampling'', is asymptotically optimal
in one-parameter exponential families. In addition, we prove that these
guarantees also hold when limiting the algorithm memory to a polylogarithmic
function of the time horizon. These findings open up new perspectives, in
particular for non-stationary scenarios in which the arm distributions evolve
over time. We propose a variant of the algorithm in which only the most recent
observations are used for subsampling, achieving optimal regret guarantees
under the assumption of a known number of abrupt changes. Extensive numerical
simulations highlight the merits of this approach, particularly when the
changes are not only affecting the means of the rewards.",http://arxiv.org/abs/2106.10935v1
"An Exploratory Study on Architectural Knowledge in Issue Tracking
  Systems",2021-06-21T14:24:22Z,"Mohamed Soliman, Matthias Galster, Paris Avgeriou","Software developers use issue trackers (e.g. Jira) to manage defects, bugs,
tasks, change requests, etc. In this paper we explore (a) how architectural
knowledge concepts (e.g. architectural component behavior, contextual
constraints) are textually represented in issues (e.g. as adjectives), (b)
which architectural knowledge concepts commonly occur in issues, and (c) which
architectural knowledge concepts appear together. We analyzed issues in the
Jira issue trackers of three large Apache projects. To identify
``architecturally relevant'' issues, we linked issues to architecturally
relevant source code changes in the studied systems. We then developed a code
book by manually labeling a subset of issues. After reaching conceptual
saturation, we coded remaining issues. Our findings support
empirically-grounded search tools to identify architectural knowledge concepts
in issues for future reuse.",http://arxiv.org/abs/2106.11140v1
Automatic Plant Cover Estimation with Convolutional Neural Networks,2021-06-21T14:52:01Z,"Matthias Körschens, Paul Bodesheim, Christine Römermann, Solveig Franziska Bucher, Mirco Migliavacca, Josephine Ulrich, Joachim Denzler","Monitoring the responses of plants to environmental changes is essential for
plant biodiversity research. This, however, is currently still being done
manually by botanists in the field. This work is very laborious, and the data
obtained is, though following a standardized method to estimate plant coverage,
usually subjective and has a coarse temporal resolution. To remedy these
caveats, we investigate approaches using convolutional neural networks (CNNs)
to automatically extract the relevant data from images, focusing on plant
community composition and species coverages of 9 herbaceous plant species. To
this end, we investigate several standard CNN architectures and different
pretraining methods. We find that we outperform our previous approach at higher
image resolutions using a custom CNN with a mean absolute error of 5.16%. In
addition to these investigations, we also conduct an error analysis based on
the temporal aspect of the plant cover images. This analysis gives insight into
where problems for automatic approaches lie, like occlusion and likely
misclassifications caused by temporal changes.",http://arxiv.org/abs/2106.11154v3
Temporal Early Exits for Efficient Video Object Detection,2021-06-21T15:49:46Z,"Amin Sabet, Jonathon Hare, Bashir Al-Hashimi, Geoff V. Merrett","Transferring image-based object detectors to the domain of video remains
challenging under resource constraints. Previous efforts utilised optical flow
to allow unchanged features to be propagated, however, the overhead is
considerable when working with very slowly changing scenes from applications
such as surveillance. In this paper, we propose temporal early exits to reduce
the computational complexity of per-frame video object detection. Multiple
temporal early exit modules with low computational overhead are inserted at
early layers of the backbone network to identify the semantic differences
between consecutive frames. Full computation is only required if the frame is
identified as having a semantic change to previous frames; otherwise, detection
results from previous frames are reused. Experiments on CDnet show that our
method significantly reduces the computational complexity and execution of
per-frame video object detection up to $34 \times$ compared to existing methods
with an acceptable reduction of 2.2\% in mAP.",http://arxiv.org/abs/2106.11208v1
Bulk locality from the celestial amplitude,2021-06-22T17:44:27Z,"Chi-Ming Chang, Yu-tin Huang, Zi-Xun Huang, Wei Li","In this paper, we study the implications of bulk locality on the celestial
amplitude. In the context of the four-point amplitude, the fact that the bulk
S-matrix factorizes locally in poles of Mandelstam variables is reflected in
the imaginary part of the celestial amplitude. In particular, on the real axis
in the complex plane of the boost weight, the imaginary part of the celestial
amplitude can be given as a positive expansion on the Poincar\'e partial waves,
which are nothing but the projection of flat-space spinning polynomials onto
the celestial sphere. Furthermore, we derive the celestial dispersion relation,
which relates the imaginary part to the residue of the celestial amplitude for
negative even integer boost weight. The latter is precisely the projection of
low energy EFT coefficients onto the celestial sphere. We demonstrate these
properties explicitly on the open and closed string celestial amplitudes.
Finally, we give an explicit expansion of the Poincar\'e partial waves in terms
of 2D conformal partial waves.",http://arxiv.org/abs/2106.11948v2
Learning Under Delayed Feedback: Implicitly Adapting to Gradient Delays,2021-06-23T09:36:36Z,"Rotem Zamir Aviv, Ido Hakimi, Assaf Schuster, Kfir Y. Levy","We consider stochastic convex optimization problems, where several machines
act asynchronously in parallel while sharing a common memory. We propose a
robust training method for the constrained setting and derive non asymptotic
convergence guarantees that do not depend on prior knowledge of update delays,
objective smoothness, and gradient variance. Conversely, existing methods for
this setting crucially rely on this prior knowledge, which render them
unsuitable for essentially all shared-resources computational environments,
such as clouds and data centers. Concretely, existing approaches are unable to
accommodate changes in the delays which result from dynamic allocation of the
machines, while our method implicitly adapts to such changes.",http://arxiv.org/abs/2106.12261v1
Topology-preserving Scan-based Immersed Isogeometric Analysis,2021-06-23T12:35:41Z,"S. C. Divi, C. V. Verhoosel, F. Auricchio, A. Reali, E. H. van Brummelen","To exploit the advantageous properties of isogeometric analysis (IGA) in a
scan-based setting, it is important to extract a smooth geometric domain from
the scan data (e.g., voxel data). IGA-suitable domains can be constructed by
convoluting the grayscale data using B-splines. A negative side-effect of this
convolution technique is, however, that it can induce topological changes in
the process of smoothing when features with a size similar to that of the
voxels are encountered. This manuscript presents an enhanced B-spline-based
segmentation procedure using a refinement strategy based on truncated
hierarchical (TH)B-splines. A Fourier analysis is presented to explain the
effectiveness of local grayscale function refinement in repairing topological
anomalies. A moving-window-based topological anomaly detection algorithm is
proposed to identify regions in which the grayscale function refinements must
be performed. The criterion to identify topological anomalies is based on the
Euler characteristic, giving it the capability to distinguish between
topological and shape changes. The proposed topology-preserving THB-spline
image segmentation strategy is studied using a range of test cases. These tests
pertain to both the segmentation procedure itself, and its application in an
immersed IGA setting.",http://arxiv.org/abs/2106.12347v1
"TCEP: Transitions in Operator Placement to Adapt to Dynamic Network
  Environments",2021-06-23T14:31:39Z,"Manisha Luthra, Boris Koldehofe, Niels Danger, Pascal Weisenburger, Guido Salvaneschi, Ioannis Stavrakakis","Distributed Complex Event Processing (DCEP) is a commonly used paradigm to
detect and act on situational changes of many applications, including the
Internet of Things (IoT). DCEP achieves this using a simple specification of
analytical tasks on data streams called operators and their distributed
execution on a set of infrastructure. The adaptivity of DCEP to the dynamics of
IoT applications is essential and very challenging in the face of changing
demands concerning Quality of Service. In our previous work, we addressed this
issue by enabling transitions, which allow for the adaptive use of multiple
operator placement mechanisms. In this article, we extend the transition
methodology by optimizing the costs of transition and analyzing the behaviour
using multiple operator placement mechanisms. Furthermore, we provide an
extensive evaluation on the costs of transition imposed by operator migrations
and learning, as it can inflict overhead on the performance if operated
uncoordinatedly.",http://arxiv.org/abs/2106.12429v1
Discrete and metric divisorial gonality can be different,2021-06-23T17:52:45Z,"Josse van Dobben de Bruyn, Harry Smit, Marieke van der Wegen","This paper compares the divisorial gonality of a finite graph $G$ to the
divisorial gonality of the associated metric graph $\Gamma(G,\mathbb{1})$ with
unit lengths. We show that $\text{dgon}(\Gamma(G,\mathbb{1}))$ is equal to the
minimal divisorial gonality of all regular subdivisions of $G$, and we provide
a class of graphs for which this number is strictly smaller than the divisorial
gonality of $G$. This settles a conjecture of M. Baker in the negative.",http://arxiv.org/abs/2106.12568v2
"Label Disentanglement in Partition-based Extreme Multilabel
  Classification",2021-06-24T03:24:18Z,"Xuanqing Liu, Wei-Cheng Chang, Hsiang-Fu Yu, Cho-Jui Hsieh, Inderjit S. Dhillon","Partition-based methods are increasingly-used in extreme multi-label
classification (XMC) problems due to their scalability to large output spaces
(e.g., millions or more). However, existing methods partition the large label
space into mutually exclusive clusters, which is sub-optimal when labels have
multi-modality and rich semantics. For instance, the label ""Apple"" can be the
fruit or the brand name, which leads to the following research question: can we
disentangle these multi-modal labels with non-exclusive clustering tailored for
downstream XMC tasks? In this paper, we show that the label assignment problem
in partition-based XMC can be formulated as an optimization problem, with the
objective of maximizing precision rates. This leads to an efficient algorithm
to form flexible and overlapped label clusters, and a method that can
alternatively optimizes the cluster assignments and the model parameters for
partition-based XMC. Experimental results on synthetic and real datasets show
that our method can successfully disentangle multi-modal labels, leading to
state-of-the-art (SOTA) results on four XMC benchmarks.",http://arxiv.org/abs/2106.12751v1
Task-agnostic Continual Learning with Hybrid Probabilistic Models,2021-06-24T05:19:26Z,"Polina Kirichenko, Mehrdad Farajtabar, Dushyant Rao, Balaji Lakshminarayanan, Nir Levine, Ang Li, Huiyi Hu, Andrew Gordon Wilson, Razvan Pascanu","Learning new tasks continuously without forgetting on a constantly changing
data distribution is essential for real-world problems but extremely
challenging for modern deep learning. In this work we propose HCL, a Hybrid
generative-discriminative approach to Continual Learning for classification. We
model the distribution of each task and each class with a normalizing flow. The
flow is used to learn the data distribution, perform classification, identify
task changes, and avoid forgetting, all leveraging the invertibility and exact
likelihood which are uniquely enabled by the normalizing flow model. We use the
generative capabilities of the flow to avoid catastrophic forgetting through
generative replay and a novel functional regularization technique. For task
identification, we use state-of-the-art anomaly detection techniques based on
measuring the typicality of the model's statistics. We demonstrate the strong
performance of HCL on a range of continual learning benchmarks such as
split-MNIST, split-CIFAR, and SVHN-MNIST.",http://arxiv.org/abs/2106.12772v1
Modeling Magnetic Particle Imaging for Dynamic Tracer Distributions,2021-06-24T15:37:51Z,"Christina Brandt, Christiane Schmidt","Magnetic Particle Imaging (MPI) is a promising tracer-based, functional
medical imaging technique which measures the non-linear magnetization response
of magnetic nanoparticles to a dynamic magnetic field. For image
reconstruction, system matrices from time-consuming calibration scans are used
predominantly. Finding modeled forward operators for magnetic particle imaging,
which are able to compete with measured matrices in practice, is an ongoing
topic of research. The existing models for magnetic particle imaging are by
design not suitable for arbitrary dynamic tracer concentrations. Neither
modeled nor measured system matrices account for changes in the concentration
during a single scanning cycle. In this paper we present a new MPI forward
model for dynamic concentrations. A static model will be introduced briefly,
followed by the changes due to the dynamic behavior of the tracer
concentration. Furthermore, the relevance of this new extended model is
examined by investigating the influence of the extension and example
reconstructions with the new and the standard model.",http://arxiv.org/abs/2106.13102v2
DROID: Driver-centric Risk Object Identification,2021-06-24T17:27:32Z,"Chengxi Li, Stanley H. Chan, Yi-Ting Chen","Identification of high-risk driving situations is generally approached
through collision risk estimation or accident pattern recognition. In this
work, we approach the problem from the perspective of subjective risk. We
operationalize subjective risk assessment by predicting driver behavior changes
and identifying the cause of changes. To this end, we introduce a new task
called driver-centric risk object identification (DROID), which uses egocentric
video to identify object(s) influencing a driver's behavior, given only the
driver's response as the supervision signal. We formulate the task as a
cause-effect problem and present a novel two-stage DROID framework, taking
inspiration from models of situation awareness and causal inference. A subset
of data constructed from the Honda Research Institute Driving Dataset (HDD) is
used to evaluate DROID. We demonstrate state-of-the-art DROID performance, even
compared with strong baseline models using this dataset. Additionally, we
conduct extensive ablative studies to justify our design choices. Moreover, we
demonstrate the applicability of DROID for risk assessment.",http://arxiv.org/abs/2106.13201v3
Bayesian Neural Networks: Essentials,2021-06-22T13:54:17Z,Daniel T. Chang,"Bayesian neural networks utilize probabilistic layers that capture
uncertainty over weights and activations, and are trained using Bayesian
inference. Since these probabilistic layers are designed to be drop-in
replacement of their deterministic counter parts, Bayesian neural networks
provide a direct and natural way to extend conventional deep neural networks to
support probabilistic deep learning. However, it is nontrivial to understand,
design and train Bayesian neural networks due to their complexities. We discuss
the essentials of Bayesian neural networks including duality (deep neural
networks, probabilistic models), approximate Bayesian inference, Bayesian
priors, Bayesian posteriors, and deep variational learning. We use TensorFlow
Probability APIs and code examples for illustration. The main problem with
Bayesian neural networks is that the architecture of deep neural networks makes
it quite redundant, and costly, to account for uncertainty for a large number
of successive layers. Hybrid Bayesian neural networks, which use few
probabilistic layers judicially positioned in the networks, provide a practical
solution.",http://arxiv.org/abs/2106.13594v1
"An estimate for thermal diffusivity in highly irradiated tungsten using
  Molecular Dynamics simulation",2021-06-25T14:34:34Z,"Daniel R Mason, Abdallah Reza, Fredric Granberg, Felix Hofmann","The changing thermal conductivity of an irradiated material is among the
principal design considerations for any nuclear reactor, but at present few
models are capable of predicting these changes starting from an arbitrary
atomistic model. Here we present a simple model for computing the thermal
diffusivity of tungsten, based on the conductivity of the perfect crystal and
resistivity per Frenkel pair, and dividing a simulation into perfect and
athermal regions statistically. This is applied to highly irradiated
microstructures simulated with Molecular Dynamics. A comparison to experiment
shows that simulations closely track observed thermal diffusivity over a range
of doses from the dilute limit of a few Frenkel pairs to the high dose
saturation limit at 3 displacements per atom (dpa).",http://arxiv.org/abs/2106.13666v2
On Incorporating Inductive Biases into VAEs,2021-06-25T16:34:05Z,"Ning Miao, Emile Mathieu, N. Siddharth, Yee Whye Teh, Tom Rainforth","We explain why directly changing the prior can be a surprisingly ineffective
mechanism for incorporating inductive biases into VAEs, and introduce a simple
and effective alternative approach: Intermediary Latent Space VAEs(InteL-VAEs).
InteL-VAEs use an intermediary set of latent variables to control the
stochasticity of the encoding process, before mapping these in turn to the
latent representation using a parametric function that encapsulates our desired
inductive bias(es). This allows us to impose properties like sparsity or
clustering on learned representations, and incorporate human knowledge into the
generative model. Whereas changing the prior only indirectly encourages
behavior through regularizing the encoder, InteL-VAEs are able to directly
enforce desired characteristics. Moreover, they bypass the computation and
encoder design issues caused by non-Gaussian priors, while allowing for
additional flexibility through training of the parametric mapping function. We
show that these advantages, in turn, lead to both better generative models and
better representations being learned.",http://arxiv.org/abs/2106.13746v2
"Investigating behavior change indicators and cognitive measures in
  persuasive health games",2021-06-25T16:43:01Z,"S. Durga, S. Hallinan, M. Seif El-Nasr, M. Shiyko, C. Sceppa","Outcome-driven studies designed to evaluate potential effects of games and
apps designed to promote healthy eating and exercising remain limited either
targeting design or usability factors while omitting out health-based outcomes
altogether, or tend to be too narrowly focuses on behavioral outcomes within a
short periods of time thereby less likely to influence longitudinal factors
that can help sustain healthy habits. In this paper we argue for a unified
approach to tackle behavioral change through focusing on both health outcomes
and cognitive precursors, such as players' attitudes and behaviors around
healthy eating and exercising, motivation stage and knowledge and awareness
about nutrition or physical activity. Key findings from a 3-month long game
play study, with 47 female participants indicate that there are clear shifts in
players' perceptions about health and knowledge about eating. This paper
extends our current understandings about approaches for evaluating health games
and presents a unified approach to assess effectiveness of game-based health
interventions through combining health-based outcomes and shifts in players'
cognitive precursors.",http://arxiv.org/abs/2106.13753v1
A Case Study of LLVM-Based Analysis for Optimizing SIMD Code Generation,2021-06-27T22:38:16Z,"Joseph Huber, Weile Wei, Giorgis Georgakoudis, Johannes Doerfert, Oscar Hernandez","This paper presents a methodology for using LLVM-based tools to tune the
DCA++ (dynamical clusterapproximation) application that targets the new ARM
A64FX processor. The goal is to describethe changes required for the new
architecture and generate efficient single instruction/multiple data(SIMD)
instructions that target the new Scalable Vector Extension instruction set.
During manualtuning, the authors used the LLVM tools to improve code
parallelization by using OpenMP SIMD,refactored the code and applied
transformation that enabled SIMD optimizations, and ensured thatthe correct
libraries were used to achieve optimal performance. By applying these code
changes, codespeed was increased by 1.98X and 78 GFlops were achieved on the
A64FX processor. The authorsaim to automatize parts of the efforts in the
OpenMP Advisor tool, which is built on top of existingand newly introduced LLVM
tooling.",http://arxiv.org/abs/2106.14332v1
"Spatiotemporal differentiators generating optical vortices with
  transverse orbital angular momentum and detecting sharp change of pulse
  envelope",2021-06-28T06:54:44Z,"Junyi Huang, Jiahao Zhang, Tengfeng Zhu, Zhichao Ruan","As a new degree of freedom for optical manipulation, recently spatiotemporal
optical vortices (STOVs) carrying transverse orbital angular momentums have
been experimentally demonstrated with pulse shapers. Here a spatiotemporal
differentiator is proposed to generate STOVs with transverse orbital angular
momentum. In order to create phase singularity in the spatiotemporal domain,
the spatiotemporal differentiator is designed by breaking spatial mirror
symmetry. In contrast to pulse shapers, the device proposed here is a simple
one-dimensional periodic nanostructure and thus it is much more compact. For a
normal incident pulse, the differentiator generates a transmitted STOV pulse
with transverse orbital angular momentum. Furthermore, the interference of the
generated STOVs can be used to detect the sharp changes of pulse envelopes, in
both spatial and temporal dimensions.",http://arxiv.org/abs/2106.14420v3
"PQK: Model Compression via Pruning, Quantization, and Knowledge
  Distillation",2021-06-25T07:24:53Z,"Jangho Kim, Simyung Chang, Nojun Kwak","As edge devices become prevalent, deploying Deep Neural Networks (DNN) on
edge devices has become a critical issue. However, DNN requires a high
computational resource which is rarely available for edge devices. To handle
this, we propose a novel model compression method for the devices with limited
computational resources, called PQK consisting of pruning, quantization, and
knowledge distillation (KD) processes. Unlike traditional pruning and KD, PQK
makes use of unimportant weights pruned in the pruning process to make a
teacher network for training a better student network without pre-training the
teacher model. PQK has two phases. Phase 1 exploits iterative pruning and
quantization-aware training to make a lightweight and power-efficient model. In
phase 2, we make a teacher network by adding unimportant weights unused in
phase 1 to a pruned network. By using this teacher network, we train the pruned
network as a student network. In doing so, we do not need a pre-trained teacher
network for the KD framework because the teacher and the student networks
coexist within the same network. We apply our method to the recognition model
and verify the effectiveness of PQK on keyword spotting (KWS) and image
recognition.",http://arxiv.org/abs/2106.14681v1
"TQFT at work for IR-renormalons, resurgence and Lefschetz decomposition",2021-06-28T20:34:04Z,Mithat Ünsal,"We investigate the implications of coupling a topological quantum field
theory (TQFT) to Yang-Mills theory with $SU(N)$ gauge group in the context of
the IR-renormalon problem. Coupling a TQFT to QFT does not change the local
dynamics and perturbation theory, but it does change the bundle topology.
Crucially, the configurations with integer topological charge but fractional
action contribute to the path integral of the original theory. In the
semi-classical regime, these are critical points at infinity, called neutral
bions, and since ${\rm Arg}(g^2)=0$ is a Stokes line, their Lefschetz thimbles
are two-fold ambiguous. Therein, the ambiguity in the gluon condensate is
sourced by the neutral bions. The Fourier decomposition of multi-branched
observables at strong coupling is compatible with the saddle decomposition at
weak coupling. TQFT coupling and non-renormalization of $\theta$ angle impose
constraints and helps to identify IR-renormalon. In certain IR-CFTs, we prove
irrelevance of bions, and absence of IR-renormalons.",http://arxiv.org/abs/2106.14971v1
An Analysis of Speculative Type Confusion Vulnerabilities in the Wild,2021-06-29T17:41:34Z,"Ofek Kirzner, Adam Morrison","Spectre v1 attacks, which exploit conditional branch misprediction, are often
identified with attacks that bypass array bounds checking to leak data from a
victim's memory. Generally, however, Spectre v1 attacks can exploit any
conditional branch misprediction that makes the victim execute code
incorrectly. In this paper, we investigate speculative type confusion, a
Spectre v1 attack vector in which branch mispredictions make the victim execute
with variables holding values of the wrong type and thereby leak memory
content.
  We observe that speculative type confusion can be inadvertently introduced by
a compiler, making it extremely hard for programmers to reason about security
and manually apply Spectre mitigations. We thus set out to determine the extent
to which speculative type confusion affects the Linux kernel. Our analysis
finds exploitable and potentially-exploitable arbitrary memory disclosure
vulnerabilities. We also find many latent vulnerabilities, which could become
exploitable due to innocuous system changes, such as coding style changes.
  Our results suggest that Spectre mitigations which rely on
statically/manually identifying ""bad"" code patterns need to be rethought, and
more comprehensive mitigations are needed.",http://arxiv.org/abs/2106.15601v2
Monocular 3D Object Detection: An Extrinsic Parameter Free Approach,2021-06-30T03:35:51Z,"Yunsong Zhou, Yuan He, Hongzi Zhu, Cheng Wang, Hongyang Li, Qinhong Jiang","Monocular 3D object detection is an important task in autonomous driving. It
can be easily intractable where there exists ego-car pose change w.r.t. ground
plane. This is common due to the slight fluctuation of road smoothness and
slope. Due to the lack of insight in industrial application, existing methods
on open datasets neglect the camera pose information, which inevitably results
in the detector being susceptible to camera extrinsic parameters. The
perturbation of objects is very popular in most autonomous driving cases for
industrial products. To this end, we propose a novel method to capture camera
pose to formulate the detector free from extrinsic perturbation. Specifically,
the proposed framework predicts camera extrinsic parameters by detecting
vanishing point and horizon change. A converter is designed to rectify
perturbative features in the latent space. By doing so, our 3D detector works
independent of the extrinsic parameter variations and produces accurate results
in realistic cases, e.g., potholed and uneven roads, where almost all existing
monocular detectors fail to handle. Experiments demonstrate our method yields
the best performance compared with the other state-of-the-arts by a large
margin on both KITTI 3D and nuScenes datasets.",http://arxiv.org/abs/2106.15796v2
Matching of given sizes in hypergraphs,2021-06-30T13:56:51Z,"Yulin Chang, Huifen Ge, Jie Han, Guanghui Wang","For all integers $k,d$ such that $k \geq 3$ and $k/2\leq d \leq k-1$, let $n$
be a sufficiently large integer {\rm(}which may not be divisible by $k${\rm)}
and let $s\le \lfloor n/k\rfloor-1$. We show that if $H$ is a $k$-uniform
hypergraph on $n$ vertices with
$\delta_{d}(H)>\binom{n-d}{k-d}-\binom{n-d-s+1}{k-d}$, then $H$ contains a
matching of size $s$. This improves a recent result of Lu, Yu, and Yuan and
also answers a question of K\""uhn, Osthus, and Townsend. In many cases, our
result can be strengthened to $s\leq \lfloor n/k\rfloor$, which then covers the
entire possible range of $s$. On the other hand, there are examples showing
that the result does not hold for certain $n, k, d$ and $s= \lfloor
n/k\rfloor$.",http://arxiv.org/abs/2106.16068v2
The History of Speech Recognition to the Year 2030,2021-07-30T21:19:33Z,Awni Hannun,"The decade from 2010 to 2020 saw remarkable improvements in automatic speech
recognition. Many people now use speech recognition on a daily basis, for
example to perform voice search queries, send text messages, and interact with
voice assistants like Amazon Alexa and Siri by Apple. Before 2010 most people
rarely used speech recognition. Given the remarkable changes in the state of
speech recognition over the previous decade, what can we expect over the coming
decade? I attempt to forecast the state of speech recognition research and
applications by the year 2030. While the changes to general speech recognition
accuracy will not be as dramatic as in the previous decade, I suggest we have
an exciting decade of progress in speech technology ahead of us.",http://arxiv.org/abs/2108.00084v1
"Theory of the supercurrent diode effect in Rashba superconductors with
  arbitrary disorder",2021-07-31T10:40:39Z,"Stefan Ilić, F. Sebastian Bergeret","We calculate the non-reciprocal critical current and quantify the
supercurrent diode effect in Rashba superconductors with arbitrary disorder,
using the quasiclassical Eilenberger equation. The non-reciprocity is caused by
the helical superconducting state, which appears when both inversion and
time-reversal symmetries are broken. In the absence of disorder, we find a very
strong diode effect, with the non-reciprocity exceeding 40% at optimal
temperatures, magnetic fields and spin-orbit coupling. We establish that the
effect persists even in the presence of strong disorder. We show that the sign
of the diode effect changes as magnetic field and disorder are increased,
reflecting the changes in the nature of the helical state.",http://arxiv.org/abs/2108.00209v2
"Motion Planning for Variable Topology Trusses: Reconfiguration and
  Locomotion",2021-07-31T19:15:19Z,"Chao Liu, Sencheng Yu, Mark Yim","Truss robots are highly redundant parallel robotic systems that can be
applied in a variety of scenarios. The variable topology truss (VTT) is a class
of modular truss robots. As self-reconfigurable modular robots, a VTT is
composed of many edge modules that can be rearranged into various structures
depending on the task. These robots change their shape by not only controlling
joint positions as with fixed morphology robots, but also reconfiguring the
connectivity between truss members in order to change their topology. The
motion planning problem for VTT robots is difficult due to their varying
morphology, high dimensionality, the high likelihood for self-collision, and
complex motion constraints. In this paper, a new motion planning framework to
dramatically alter the structure of a VTT is presented. It can also be used to
solve locomotion tasks that are much more efficient compared with previous
work. Several test scenarios are used to show its effectiveness. Supplementary
materials are available at https://www.modlabupenn.org/vtt-motion-planning/.",http://arxiv.org/abs/2108.00309v2
Detecting two photons with one molecule,2021-08-01T17:15:11Z,"Saumya Biswas, S. J. van Enk","We apply input-output theory with quantum pulses [AH Kiilerich, K M\o lmer,
Phys. Rev. Lett. {\bf 123}, 123604 (2019)] to a model of a new type of
two-photon detector consisting of one molecule that can detect two photons
arriving sequentially in time. The underlying process is distinct from the
usual two-photon absorption process where two photons arriving simultaneously
and with frequencies adding up to the resonance frequency are absorbed by a
single molecule in one quantum jump. Our detector model includes a Hamiltonian
description of the amplification process necessary to convert the microscopic
change in the single molecule to a macroscopic signal.",http://arxiv.org/abs/2108.00498v4
Parametrizing the Ramsey theory of vector spaces I: Discrete spaces,2021-08-01T21:17:12Z,Iian B. Smythe,"We show that the Ramsey theory of block sequences in infinite-dimensional
discrete vector spaces can be parametrized by perfect sets. As special cases,
we prove combinatorial dichotomies for definable families of partitions and
linear transformations on those spaces. We also consider the extent to which
analogues of selective ultrafilters in this setting are preserved by Sacks
forcing.",http://arxiv.org/abs/2108.00544v2
"Detection of subtle cartilage and bone tissue degeneration in the equine
  joint using polarisation-sensitive optical coherence tomography",2021-08-01T21:36:03Z,"Matthew Goodwin, Marie Klufts, Joshua Workman, Ashvin Thambyah, Frédérique Vanholsbeeck","Objective: To explore the ability of polarisation-sensitive optical coherence
tomography (PS-OCT) to rapidly identify subtle signs of tissue degeneration in
the equine joint.
  Design: Polarisation-sensitive optical coherence tomography (PS-OCT) images
were systematically acquired in four locations along the medial and lateral
condyles of the third metacarpal bone in 5 equine specimens. Intensity and
retardation PS-OCT images, and anomalies observed therein, were then compared
and validated with high resolution images of the tissue sections obtained using
Differential Interference contrast (DIC) optical light microscopy.
  Results: The PS-OCT system was capable of imaging the entire equine
osteochondral unit, and allowed delineation of the three structurally
differentiated zones of the joint, that is, the articular cartilage matrix,
zone of calcified cartilage and underlying subchondral bone. Importantly,
PS-OCT imaging was able to detect underlying matrix and bone changes not
visible without dissection and/or microscopy.
  Conclusion: PS-OCT has substantial potential to detect, non-invasively,
sub-surface microstructural changes that are known to be associated with the
early stages of joint tissue degeneration.",http://arxiv.org/abs/2108.00547v1
Studying High-Mass Microquasars with HAWC,2021-08-02T02:03:12Z,"Chang Dong Rho, Ke Fang, Se Yeon Hwang, Youngwan Son","High-mass microquasars (HMMQs) are powerful particle accelerators, but their
mechanism of the high-energy emission is poorly understood. To date, only a
handful of these particle engines have ever been observed to emit gamma-ray
photons and are thus potential TeV gamma-ray emitters. In this work, we study
four HMMQs, namely, LS 5039, Cyg X-1, Cyg X-3, and SS 433 using the data from
the High Altitude Water Cherenkov (HAWC) observatory. We perform time dependent
analyses on each HMMQ to look for any periodic variations in their flux. We
produce light curves using the HAWC daily maps from which we generate
Lomb-Scargle periodograms. By analysing the significance of the periodogram
peaks, we assess whether or not HAWC is sensitive to orbitally modulating TeV
gamma-ray flux in the four HMMQs.",http://arxiv.org/abs/2108.00594v1
Improving Deep Learning for HAR with shallow LSTMs,2021-08-02T08:14:59Z,"Marius Bock, Alexander Hoelzemann, Michael Moeller, Kristof Van Laerhoven","Recent studies in Human Activity Recognition (HAR) have shown that Deep
Learning methods are able to outperform classical Machine Learning algorithms.
One popular Deep Learning architecture in HAR is the DeepConvLSTM. In this
paper we propose to alter the DeepConvLSTM architecture to employ a 1-layered
instead of a 2-layered LSTM. We validate our architecture change on 5 publicly
available HAR datasets by comparing the predictive performance with and without
the change employing varying hidden units within the LSTM layer(s). Results
show that across all datasets, our architecture consistently improves on the
original one: Recognition performance increases up to 11.7% for the F1-score,
and our architecture significantly decreases the amount of learnable
parameters. This improvement over DeepConvLSTM decreases training time by as
much as 48%. Our results stand in contrast to the belief that one needs at
least a 2-layered LSTM when dealing with sequential data. Based on our results
we argue that said claim might not be applicable to sensor-based HAR.",http://arxiv.org/abs/2108.00702v2
Electric-field control of the exchange interactions,2021-08-02T14:26:10Z,"S. Mankovsky, E. Simon, S. Polesya, A. Marmodoro, H. Ebert","The impact of an applied electric field on the exchange coupling parameters
has been investigated based on first-principles electronic structure
calculations by means of the KKR Green function method. The calculations have
been performed for a Fe film, free-standing and deposited on two different
substrates, having 1 monolayer (ML) thickness to minimize the effect of
screening of the electric field typical for metallic systems. By comparing the
results for the free-standing Fe ML with those for Fe on the various
substrates, we could analyze the origin of the field-induced change of the
exchange interactions. Compared to the free-standing Fe ML, in particular
rather pronounced changes have been found for the Fe/Pt(111) system due to the
localized electronic states at the Fe/Pt interface, which are strongly affected
by the electric field and which play an important role for the Fe-Fe exchange
interactions.",http://arxiv.org/abs/2108.00932v1
Neural Image Representations for Multi-Image Fusion and Layer Separation,2021-08-02T22:29:35Z,"Seonghyeon Nam, Marcus A. Brubaker, Michael S. Brown","We propose a framework for aligning and fusing multiple images into a single
view using neural image representations (NIRs), also known as implicit or
coordinate-based neural representations. Our framework targets burst images
that exhibit camera ego motion and potential changes in the scene. We describe
different strategies for alignment depending on the nature of the scene motion
-- namely, perspective planar (i.e., homography), optical flow with minimal
scene change, and optical flow with notable occlusion and disocclusion. With
the neural image representation, our framework effectively combines multiple
inputs into a single canonical view without the need for selecting one of the
images as a reference frame. We demonstrate how to use this multi-frame fusion
framework for various layer separation tasks. The code and results are
available at https://shnnam.github.io/research/nir.",http://arxiv.org/abs/2108.01199v4
"Changing Salty Food Preferences with Visual and Textual Explanations in
  a Search Interface",2021-08-03T11:58:05Z,"Arngeir Berge, Vegard Velle Sjøen, Alain D. Starke, Christoph Trattner","Salt is consumed at too high levels in the general population, causing high
blood pressure and related health problems. In this paper, we present results
of ongoing research that tries to reduce salt intake via technology and in
particular from an interface perspective. In detail, this paper features
results of a study that examines the extent to which visual and textual
explanations in a search interface can change salty food preferences. An online
user study with 200 participants demonstrates that this is possible in food
search results by accompanying recipes with a visual taste map that includes
salt-replacer herbs and spices in the calculation of salty taste.",http://arxiv.org/abs/2108.01427v1
Pandemic and disability: Challenges faced and role of technology,2021-08-03T20:42:20Z,"Monnie Parida, Dr Manjira Sinha","The pandemic has affected every facet of human life. Apart from individuals
psychological and mental health issues, the concern regarding mobility, access
and communication with high risk infection is a challenging situation. People
with disability are more likely vulnerable to infections. The new changes in
our social lifestyle (social distancing, limiting touch) can profoundly impact
the day today life of people with disability. In this paper, we will briefly
discuss the situation faced by individuals with disabilities, some known
remedies, and yet to be identified and curated technological remedies; the
impact due to transition of special education toward online mode. Tips and
tricks for better utilization of work from home concept by people with
disabilities. Accessibility must be universal, accommodating all and
encouraging inclusivity. As rightly said by Helen Keller, 'The only thing worse
than being blind is having sight but no vision'; subsequently, going by the
demand of the time, we should contribute toward the universal design approach
by supporting people with disabilities and commit to the changes required in
disability care to reduce the impact of pandemic. Keywords: Disabilities,
pandemic, corona virus, inclusive",http://arxiv.org/abs/2108.01743v2
Induced coactions along a homomorphism of locally compact quantum groups,2021-08-04T11:57:50Z,Kan Kitamura,"We consider induced coactions on C*-algebras along a homomorphism of locally
compact quantum groups which need not give a closed quantum subgroup. Our
approach generalizes the induced coactions constructed by Vaes, and also
includes certain fixed point algebras. We focus on the case when the
homomorphism satisfies a quantum analogue of properness. Induced coactions
along such a homomorphism still admit the natural formulations of various
properties known in the case of a closed quantum subgroup, such as
imprimitivity and adjointness with restriction. Also, we show a relationship of
induced coactions and restriction which is analogous to base change formula for
modules over algebras. As an application, we give an example that shows several
kinds of 1-categories of coactions with forgetful functors cannot recover the
original quantum group.",http://arxiv.org/abs/2108.01986v2
"Online unsupervised Learning for domain shift in COVID-19 CT scan
  datasets",2021-07-31T00:03:18Z,"Nicolas Ewen, Naimul Khan","Neural networks often require large amounts of expert annotated data to
train. When changes are made in the process of medical imaging, trained
networks may not perform as well, and obtaining large amounts of expert
annotations for each change in the imaging process can be time consuming and
expensive. Online unsupervised learning is a method that has been proposed to
deal with situations where there is a domain shift in incoming data, and a lack
of annotations. The aim of this study is to see whether online unsupervised
learning can help COVID-19 CT scan classification models adjust to slight
domain shifts, when there are no annotations available for the new data. A
total of six experiments are performed using three test datasets with differing
amounts of domain shift. These experiments compare the performance of the
online unsupervised learning strategy to a baseline, as well as comparing how
the strategy performs on different domain shifts. Code for online unsupervised
learning can be found at this link:
https://github.com/Mewtwo/online-unsupervised-learning",http://arxiv.org/abs/2108.02002v1
"Polarization switching of quasi-trapped modes and near field enhancement
  in bianisotropic all-dielectric metasurfaces",2021-08-04T17:47:31Z,"Andrey B. Evlyukhin, Maria Poleva, Alexey Prokhorov, Kseniia Baryshnikova, Andrey E. Miroshnichenko, Boris N. Chichkov","A general strategy for the realization of electric and magnetic quasi-trapped
modes located at the same spectral position is presented. This strategy's
application makes it possible to design metasurfaces allowing switching between
the electric and magnetic quasi-trapped modes by changing the polarization of
the incident light wave. The developed strategy is based on two stages: the
application of the dipole approximation for determining the conditions required
for the implementation of trapped modes and the creation of the energy channels
for their excitation by introducing a weak bianisotropy in nanoparticles. Since
excitation of trapped modes results in a concentration of electric and magnetic
energies in the metasurface plane, the polarization switching provides
possibilities to change and control the localization and distribution of
optical energy at the sub-wavelength scale. We demonstrate a practical method
for spectral tuning of quasi-trapped modes in metasurfaces composed of
nanoparticles with a pre-selected shape. As an example, the optical properties
of a metasurface composed of silicon triangular prisms are analyzed and
discussed.",http://arxiv.org/abs/2108.02195v1
"Measuring photoexcited electron and hole dynamics in ZnTe and modeling
  excited state core-valence effects in transient XUV reflection spectroscopy",2021-08-04T19:52:14Z,"Hanzhe Liu, Jonathan M. Michelsen, Isabel M. Klein, Scott K. Cushing","Transient XUV spectroscopy is growing in popularity for the measurement of
solar fuel and photovoltaic materials as it can separately measure electron and
hole energies for multiple elements at once. However, interpretation of
transient XUV measurements is complicated by changes in core-valence exciton
and angular momentum effects after photoexcitation. Here, we report the
photoexcited electron and hole dynamics for ZnTe, a promising material for CO2
reduction, following 400 nm excitation. We apply a newly developed, ab-initio
theoretical approach based on density functional theory and the Bethe-Salpeter
equation to accurately predict the excited state change in the measured
transient XUV spectra. Electrons excited to the conduction band are measured
with a thermalization rate of 70 $\pm$ 40 fs. Holes are excited with an average
excess energy of ~1 eV and thermalize in 1130 $\pm$ 150 fs. The theoretical
approach also allows an estimated assignment of inter- and intra-valley
relaxation pathways in k-space using the relative amplitudes of the
core-valence excitons.",http://arxiv.org/abs/2108.02262v1
"On the Robustness of Controlled Deep Reinforcement Learning for Slice
  Placement",2021-08-05T10:24:33Z,"Jose Jurandir Alves Esteves, Amina Boubendir, Fabrice Guillemin, Pierre Sens","The evaluation of the impact of using Machine Learning in the management of
softwarized networks is considered in multiple research works. Beyond that, we
propose to evaluate the robustness of online learning for optimal network slice
placement. A major assumption to this study is to consider that slice request
arrivals are non-stationary. In this context, we simulate unpredictable network
load variations and compare two Deep Reinforcement Learning (DRL) algorithms: a
pure DRL-based algorithm and a heuristically controlled DRL as a hybrid
DRL-heuristic algorithm, to assess the impact of these unpredictable changes of
traffic load on the algorithms performance. We conduct extensive simulations of
a large-scale operator infrastructure. The evaluation results show that the
proposed hybrid DRL-heuristic approach is more robust and reliable in case of
unpredictable network load changes than pure DRL as it reduces the performance
degradation. These results are follow-ups for a series of recent research we
have performed showing that the proposed hybrid DRL-heuristic approach is
efficient and more adapted to real network scenarios than pure DRL.",http://arxiv.org/abs/2108.02505v1
In-memory computing based on all-optically controlled memristor,2021-08-05T17:01:44Z,"Jing Yang, Lingxiang Hu, Liufeng Shen, Jingrui Wang, Peihong Cheng, Huanming Lu, Fei Zhuge, Zhizhen Ye","Artificial intelligence is widely used in everyday life. However, an
insufficient computing efficiency due to the so-called von Neumann bottleneck
cannot satisfy the demand for real-time processing of rapidly growing data.
Memristive in-memory computing is a promising candidate for highly efficient
data processing. However, performance of memristors varies significantly
because of microstructure change induced by electric-driven matter migration.
Here, we propose an all-optically controlled (AOC) memristor with a simple
Au/ZnO/Pt sandwich structure based on a purely electronic tuning mechanism of
memconductance. The memconductance can be reversibly tuned only by light
irradiation with different wavelengths. The device can be used to perform
in-memory computation such as nonvolatile neuromorphic computing and Boolean
logic functions. Moreover, no microstructure change is involved during the
operation of our AOC memristor which demonstrates superior operation stability.
Based on this and its structural simplicity, the device has attractive
application prospects for the next generation of computing systems.",http://arxiv.org/abs/2108.02739v1
"Local distinction, quadratic base change and automorphic induction for
  $\mathrm{GL_n}$",2021-08-06T09:25:28Z,Nadir Matringe,"Behind this sophisticated title hides an elementary exercise on Clifford
theory for index two subgroups and self-dual/conjugate-dual representations.
When applied to semi-simple representations of the Weil-Deligne group $W'_F$ of
a non Archimedean local field $F$, and further translated in terms of
representations of $\mathrm{GL_n}(F)$ via the local Langlands correspondence
when $F$ has characteristic zero, it yields various statements concerning the
behaviour of different types of distinction under quadratic base change and
automorphic induction. When $F$ has residual characteristic different from $2$,
combining of one of the simple results that we obtain with the tiviality of
conjugate-orthogonal root numbers (proved by Gan, Gross and Prasad), we recover
without using the LLC a result of Serre on the parity of the Artin conductor of
orthogonal representations of $W'_F$. On the other hand we discuss its parity
for symplectic representations using the LLC and the Prasad and Takloo-Bighash
conjecture.",http://arxiv.org/abs/2108.03017v3
Culling the herd of moments with penalized empirical likelihood,2021-08-07T07:03:41Z,"Jinyuan Chang, Zhentao Shi, Jia Zhang","Models defined by moment conditions are at the center of structural
econometric estimation, but economic theory is mostly agnostic about moment
selection. While a large pool of valid moments can potentially improve
estimation efficiency, in the meantime a few invalid ones may undermine
consistency. This paper investigates the empirical likelihood estimation of
these moment-defined models in high-dimensional settings. We propose a
penalized empirical likelihood (PEL) estimation and establish its oracle
property with consistent detection of invalid moments. The PEL estimator is
asymptotically normally distributed, and a projected PEL procedure further
eliminates its asymptotic bias and provides more accurate normal approximation
to the finite sample behavior. Simulation exercises demonstrate excellent
numerical performance of these methods in estimation and inference.",http://arxiv.org/abs/2108.03382v4
"Rotational and Reflectional Equivariant Convolutional Neural Network for
  data-limited applications: Multiphase Flow demonstration",2021-08-07T17:57:01Z,"Bhargav Sriram Siddani, S. Balachandar, Ruogu Fang","This article deals with approximating steady-state particle-resolved fluid
flow around a fixed particle of interest under the influence of randomly
distributed stationary particles in a dispersed multiphase setup using
Convolutional Neural Network (CNN). The considered problem involves rotational
symmetry about the mean velocity (streamwise) direction. Thus, this work
enforces this symmetry using $\mathbf{\textbf{SE(3)-equivariant}}$, special
Euclidean group of dimension 3, CNN architecture, which is translation and
three-dimensional rotation equivariant. This study mainly explores the
generalization capabilities and benefits of SE(3)-equivariant network. Accurate
synthetic flow fields for Reynolds number and particle volume fraction
combinations spanning over a range of [86.22, 172.96] and [0.11, 0.45]
respectively are produced with careful application of symmetry-aware
data-driven approach.",http://arxiv.org/abs/2108.03494v2
Are $\mathfrak a$ and $\mathfrak d$ your cup of tea? Revisited,2021-08-08T15:29:43Z,Saharon Shelah,"This is a revised version (of late 2020) of [Sh:700], which is
arXiv:math/0012170 .
  First point is noting that the proof of Theorem 4.3 in [Sh:700], which says
that the proof giving the consistency $ \mathfrak{b} = \mathfrak{d} =
\mathfrak{u} < \mathfrak{a} $ also gives $ \mathfrak{s} = \mathfrak{d} $. The
proof uses a measurable cardinal and a c.c.c. forcing so it gives large $
\mathfrak{d} $ and assumes a large cardinal.
  Second point is adding to the results of \S2,\S3 which say that (in \S3 with
no large cardinals) we can force $ {\aleph_1} < \mathfrak{b} = \mathfrak{d} <
\mathfrak{a}$. We like to have $ {\aleph_1} < \mathfrak{s} \le \mathfrak{b} =
\mathfrak{d} < \mathfrak{a} $. For this we allow in \S2,\S3 the sets $ K_t $ to
be uncountable; this requires non-essential changes. In particular, we replace
usually $ {\aleph_0}, {\aleph_1} $ by $ \sigma , \partial $. Naturally we can
deal with $ \mathfrak{i} $ and similar invariants.
  Third we proofread the work again. To get $ \mathfrak{s} $ we could have
retained the countability of the member of the $ I_t$-s but the parameters
would change with $ A \in I_t$, well for a cofinal set of them; but the present
seems simpler.
  We intend to continue in [Sh:F2009].",http://arxiv.org/abs/2108.03666v1
Sign Changes of Coefficients of Powers of the Infinite Borwein Product,2021-08-09T10:51:05Z,Liuquan Wang,"We denote by $c_t^{(m)}(n)$ the coefficient of $q^n$ in the series expansion
of $(q;q)_\infty^m(q^t;q^t)_\infty^{-m}$, which is the $m$-th power of the
infinite Borwein product. Let $t$ and $m$ be positive integers with $m(t-1)\leq
24$. We provide asymptotic formula for $c_t^{(m)}(n)$, and give
characterizations of $n$ for which $c_t^{(m)}(n)$ is positive, negative or
zero. We show that $c_t^{(m)}(n)$ is ultimately periodic in sign and conjecture
that this is still true for other positive integer values of $t$ and $m$.
Furthermore, we confirm this conjecture in the cases $(t,m)=(2,m),(p,1),(p,3)$
for arbitrary positive integer $m$ and prime $p$.",http://arxiv.org/abs/2108.03932v3
Designing order-disorder transformation in high-entropy ferritic steels,2021-08-09T15:14:13Z,"Singh, Prashant, Johnson, Duane D","Order-disorder transformations hold an essential place in chemically complex
high-entropy ferritic-steels (HEFSs) due to their critical technological
application. The chemical inhomogeneity arising from mixing of multi-principal
elements of varying chemistry can drive property altering changes at the atomic
scale, in particular short-range order. Using density-functional theory based
linear-response theory, we predict the effect of compositional tuning on the
order-disorder transformation in ferritic steels -focusing on Cr-Ni-Al-Ti-Fe
HEFSs. We show that Ti content in Cr-Ni-Al-Ti-Fe solid solutions can be tuned
to modify short-range order that changes the order-disorder path from BCC-B2
(Ti atomic-fraction = 0) to BCC-B2-L21 (Ti atomic-faction $>$ 0) consistent
with existing experiments. Our study suggests that tuning degree of SRO through
compositional variation can be used as an effective means to optimize phase
selection in technologically useful alloys.",http://arxiv.org/abs/2108.04110v1
"An Experimental Study of the Acoustic Field of a Single-Cell
  Piezoelectric Micromachined Ultrasound Transducer (PMUT)",2021-07-15T18:27:55Z,"Bibhas Nayak, Harshvardhan Gupta, Kaustav Roy, Anuj Ashok, Vijayendra Shastri, Rudra Pratap","Piezoelectric micromachined ultrasound transducers (PMUTs) have gained
popularity in the past decade as acoustic transmitters and receivers. As these
devices usually operate at resonance, they can deliver large output sound
pressures with very low power consumption. This paper explores the influence of
the transmitter's packaging on the radiated acoustic field in air. We run
simplified axisymmetric numerical models to observe the change in the acoustic
field and directivity with respect to the device's package dimensions. The
simulations demonstrate a notable change in the directivity of transmitter
based on the size of the baffle. Experimental measurements are carried out to
validate the simulations, which prove useful in designing packages for
transmitters to meet application specific requirements.",http://arxiv.org/abs/2108.04660v1
Accelerating Iterated Persistent Homology Computations with Warm Starts,2021-08-11T04:23:43Z,"Yuan Luo, Bradley J. Nelson","Persistent homology is a topological feature used in a variety of
applications such as generating features for data analysis and penalizing
optimization problems. We develop an approach to accelerate persistent homology
computations performed on many similar filtered topological spaces which is
based on updating associated matrix factorizations. Our approach improves the
update scheme of Cohen-Steiner, Edelsbrunner, and Morozov for permutations by
additionally handling addition and deletion of cells in a filtered topological
space and by processing changes in a single batch. We show that the complexity
of our scheme scales with the number of elementary changes to the filtration
which as a result is often less expensive than the full persistent homology
computation. Finally, we perform computational experiments demonstrating
practical speedups in several situations including feature generation and
optimization guided by persistent homology.",http://arxiv.org/abs/2108.05022v2
"Variable-Length Music Score Infilling via XLNet and Musically
  Specialized Positional Encoding",2021-08-11T07:07:21Z,"Chin-Jui Chang, Chun-Yi Lee, Yi-Hsuan Yang","This paper proposes a new self-attention based model for music score
infilling, i.e., to generate a polyphonic music sequence that fills in the gap
between given past and future contexts. While existing approaches can only fill
in a short segment with a fixed number of notes, or a fixed time span between
the past and future contexts, our model can infill a variable number of notes
(up to 128) for different time spans. We achieve so with three major technical
contributions. First, we adapt XLNet, an autoregressive model originally
proposed for unsupervised model pre-training, to music score infilling. Second,
we propose a new, musically specialized positional encoding called relative bar
encoding that better informs the model of notes' position within the past and
future context. Third, to capitalize relative bar encoding, we perform
look-ahead onset prediction to predict the onset of a note one time step before
predicting the other attributes of the note. We compare our proposed model with
two strong baselines and show that our model is superior in both objective and
subjective analyses.",http://arxiv.org/abs/2108.05064v1
"Minimax and pointwise sequential changepoint detection and
  identification for general stochastic models",2021-08-11T08:09:33Z,"Serguei Pergamenchtchikov, Alexander Tartakovsky, Valentin Spivak","This paper considers the problem of joint change detection and identification
assuming multiple composite postchange hypotheses. We propose a multihypothesis
changepoint detection-identification procedure that controls the probabilities
of false alarm and wrong identification. We show that the proposed procedure is
asymptotically minimax and pointwise optimal, minimizing moments of the
detection delay as probabilities of false alarm and wrong identification
approach zero. The asymptotic optimality properties hold for general stochastic
models with dependent observations. We illustrate general results for
detection-identification of changes in multistream Markov ergodic processes. We
consider several examples, including an application to rapid
detection-identification of COVID-19 in Italy. Our proposed sequential
algorithm allows much faster detection of COVID-19 than standard methods.",http://arxiv.org/abs/2108.05086v1
"Mounting Video Metadata on Transformer-based Language Model for
  Open-ended Video Question Answering",2021-08-11T11:11:43Z,"Donggeon Lee, Seongho Choi, Youwon Jang, Byoung-Tak Zhang","Video question answering has recently received a lot of attention from
multimodal video researchers. Most video question answering datasets are
usually in the form of multiple-choice. But, the model for the multiple-choice
task does not infer the answer. Rather it compares the answer candidates for
picking the correct answer. Furthermore, it makes it difficult to extend to
other tasks. In this paper, we challenge the existing multiple-choice video
question answering by changing it to open-ended video question answering. To
tackle open-ended question answering, we use the pretrained GPT2 model. The
model is fine-tuned with video inputs and subtitles. An ablation study is
performed by changing the existing DramaQA dataset to an open-ended question
answering, and it shows that performance can be improved using video metadata.",http://arxiv.org/abs/2108.05158v1
"Communicating extraterrestrial intelligence (CETI) interaction models
  based on the Drake Equation",2021-06-19T01:42:48Z,Reginald D. Smith,"The Drake Equation has proven fertile ground for speculation about the
abundance, or lack thereof, of communicating extraterrestrial intelligences
(CETIs) for decades. It has been augmented by subsequent authors to include
random variables in order to understand its probabilistic behavior. However, in
most cases, the emergence and lifetime of CETIs are assumed to be independent
of each other. In this paper, we will derive several expressions that can
demonstrate how CETIs may relate to each other in technological age as well as
how the dynamics of the concurrent CETI population change under basic models of
interaction, such as the Allee Effect. By defining interaction as the change in
the expected communication lifetime with respect to the density of CETI in a
region of space, we can use models and simulation to understand how the CETI
density can promote or inhibit the longevity and overall population of
interstellar technological civilizations.",http://arxiv.org/abs/2108.05215v3
Machine Learning Model Drift Detection Via Weak Data Slices,2021-08-11T16:55:34Z,"Samuel Ackerman, Parijat Dube, Eitan Farchi, Orna Raz, Marcel Zalmanovici","Detecting drift in performance of Machine Learning (ML) models is an
acknowledged challenge. For ML models to become an integral part of business
applications it is essential to detect when an ML model drifts away from
acceptable operation. However, it is often the case that actual labels are
difficult and expensive to get, for example, because they require expert
judgment. Therefore, there is a need for methods that detect likely degradation
in ML operation without labels. We propose a method that utilizes feature space
rules, called data slices, for drift detection. We provide experimental
indications that our method is likely to identify that the ML model will likely
change in performance, based on changes in the underlying data.",http://arxiv.org/abs/2108.05319v1
Optimal actuator design via Brunovsky's normal form,2021-08-12T09:50:02Z,"Borjan Geshkovski, Enrique Zuazua","In this paper, by using the Brunovsky normal form, we provide a reformulation
of the problem consisting in finding the actuator design which minimizes the
controllability cost for finite-dimensional linear systems with scalar
controls. Such systems may be seen as spatially discretized linear partial
differential equations with lumped controls. The change of coordinates induced
by Brunovsky's normal form allows us to remove the restriction of having to
work with diagonalizable system dynamics, and does not entail a randomization
procedure as done in past literature on diffusion equations or waves. Instead,
the optimization problem reduces to a minimization of the norm of the inverse
of a change of basis matrix, and allows for an easy deduction of existence of
solutions, and for a clearer picture of some of the problem's intrinsic
symmetries. Numerical experiments help to visualize these artifacts, indicate
further open problems, and also show a possible obstruction of using
gradient-based algorithms - this is alleviated by using an evolutionary
algorithm.",http://arxiv.org/abs/2108.05629v1
Angles in the SI: a detailed proposal for solving the problem,2021-08-10T09:44:48Z,Paul Quincey,"A recent Letter proposed changing the dimensionless status of the radian and
steradian within the SI, while allowing the continued use of the convention to
set the angle 1 radian equal to the number 1 within equations, providing this
is done explicitly. This would bring the advantages of a physics-based,
consistent, and logically-robust unit system, with unambiguous units for all
physical quantities, for the first time, while any upheaval to familiar
equations and routine practice would be minimised. More details of this
proposal are given here. The only notable changes for typical end-users would
be: improved units for the quantities torque, angular momentum and moment of
inertia; a statement of the convention accompanying some familiar equations;
and the use of different symbols for h-bar the action and h-bar the angular
momentum, a small step forward for quantum physics. Some features of the
proposal are already established practice for quantities involving the
steradian such as radiant intensity and radiance.",http://arxiv.org/abs/2108.05704v1
"An Optimal Transport Approach to Estimating Causal Effects via Nonlinear
  Difference-in-Differences",2021-08-12T17:08:32Z,"William Torous, Florian Gunsilius, Philippe Rigollet","We propose a nonlinear difference-in-differences method to estimate
multivariate counterfactual distributions in classical treatment and control
study designs with observational data. Our approach sheds a new light on
existing approaches like the changes-in-changes and the classical
semiparametric difference-in-differences estimator and generalizes them to
settings with multivariate heterogeneity in the outcomes. The main benefit of
this extension is that it allows for arbitrary dependence and heterogeneity in
the joint outcomes. We demonstrate its utility both on synthetic and real data.
In particular, we revisit the classical Card \& Krueger dataset, examining the
effect of a minimum wage increase on employment in fast food restaurants; a
reanalysis with our method reveals that restaurants tend to substitute
full-time with part-time labor after a minimum wage increase at a faster pace.
A previous version of this work was entitled ""An optimal transport approach to
causal inference.",http://arxiv.org/abs/2108.05858v2
"The SelectGen Challenge: Finding the Best Training Samples for Few-Shot
  Neural Text Generation",2021-08-14T21:20:35Z,"Ernie Chang, Xiaoyu Shen, Alex Marin, Vera Demberg","We propose a shared task on training instance selection for few-shot neural
text generation. Large-scale pretrained language models have led to dramatic
improvements in few-shot text generation. Nonetheless, almost all previous work
simply applies random sampling to select the few-shot training instances.
Little to no attention has been paid to the selection strategies and how they
would affect model performance. The study of the selection strategy can help us
to (1) make the most use of our annotation budget in downstream tasks and (2)
better benchmark few-shot text generative models. We welcome submissions that
present their selection strategies and the effects on the generation quality.",http://arxiv.org/abs/2108.06614v1
A Morphing Quadrotor that Can Optimize Morphology for Transportation,2021-08-15T15:26:48Z,"Chanyoung Kim, Hyungyu Lee, Myeongwoo Jeong, Hyun Myung","Multirotors can be effectively applied to various tasks, such as
transportation, investigation, exploration, and lifesaving, depending on the
type of payload. However, due to the nature of multirotors, the payload loaded
on the multirotor is limited in its position and weight, which presents a major
disadvantage when the multirotor is used in various fields. In this paper, we
propose a novel method that greatly improves the restrictions on payload
position and weight using a morphing quadrotor system. Our method can estimate
the drone's weight, center of gravity position, and inertia tensor in
real-time, which change depending on payload, and determine the optimal
morphology for efficient and stable flight. An adaptive control method that can
reflect the change in flight dynamics by payload and morphing is also
presented. Experiments were conducted to confirm that the proposed morphing
quadrotor improves the stability and efficiency in various situations of
transporting payloads compared with the conventional quadrotor systems.",http://arxiv.org/abs/2108.06759v1
"A fast direct solver for integral equations on locally refined boundary
  discretizations and its application to multiphase flow simulations",2021-08-16T16:18:54Z,"Yabin Zhang, Adrianna Gillman, Shravan Veerapaneni","In transient simulations of particulate Stokes flow, to accurately capture
the interaction between the constituent particles and the confining wall, the
discretization of the wall often needs to be locally refined in the region
approached by the particles. Consequently, standard fast direct solvers lose
their efficiency since the linear system changes at each time step. This
manuscript presents a new computational approach that avoids this issue by
pre-constructing a fast direct solver for the wall ahead of time, computing a
low-rank factorization to capture the changes due to the refinement, and
solving the problem on the refined discretization via a Woodbury formula.
Numerical results illustrate the efficiency of the solver in accelerating
particulate Stokes simulations.",http://arxiv.org/abs/2108.07205v2
"The infuence of compressive lattice deformations on the zone-center
  energy band properties of zincblende GaN and InN. Hybrid density functional
  results",2021-08-17T00:09:54Z,"Julián David Correa, Miguel Eduardo Mora-Ramos","We have investigated the effects of hydrostatic pressure and compressive
biaxial strain on the $\Gamma$-point energy states of GaN and InN with
zincblende crystal structure via first-principles DFT+HSE06 computation. To
correctly reproduce accepted experimental values of the energy band gap of both
compounds, the procedure includes modified exchange-correlation fractions in
the HSE hybrid functional, changing from the standard value $\alpha=0.25$ to
$\alpha=0.43$ (GaN) and $\alpha=0.40$ (InN). Within this environment, the work
reports on the variation of conduction and valence band edges as functions of
the lattice deformation. In addition, we present fitted expressions describing
the change in the band gap and the spin-orbit splitting energy due to unit cell
size modification. All these parameters are main input quantities in the
description of electronic and optical properties of InN/GaN-based
heterostructures.",http://arxiv.org/abs/2108.07381v1
"CARE: Coherent Actionable Recourse based on Sound Counterfactual
  Explanations",2021-08-18T15:26:59Z,"Peyman Rasouli, Ingrid Chieh Yu","Counterfactual explanation methods interpret the outputs of a machine
learning model in the form of ""what-if scenarios"" without compromising the
fidelity-interpretability trade-off. They explain how to obtain a desired
prediction from the model by recommending small changes to the input features,
aka recourse. We believe an actionable recourse should be created based on
sound counterfactual explanations originating from the distribution of the
ground-truth data and linked to the domain knowledge. Moreover, it needs to
preserve the coherency between changed/unchanged features while satisfying
user/domain-specified constraints. This paper introduces CARE, a modular
explanation framework that addresses the model- and user-level desiderata in a
consecutive and structured manner. We tackle the existing requirements by
proposing novel and efficient solutions that are formulated in a
multi-objective optimization framework. The designed framework enables
including arbitrary requirements and generating counterfactual explanations and
actionable recourse by choice. As a model-agnostic approach, CARE generates
multiple, diverse explanations for any black-box model in tabular
classification and regression settings. Several experiments on standard data
sets and black-box models demonstrate the effectiveness of our modular
framework and its superior performance compared to the baselines.",http://arxiv.org/abs/2108.08197v1
"Resilient and consistent multirobot cooperative localization with
  covariance intersection",2021-08-19T16:57:47Z,"Tsang-Kai Chang, Kenny Chen, Ankur Mehta","Cooperative localization is fundamental to autonomous multirobot systems, but
most algorithms couple inter-robot communication with observation, making these
algorithms susceptible to failures in both communication and observation steps.
To enhance the resilience of multirobot cooperative localization algorithms in
a distributed system, we use covariance intersection to formalize a
localization algorithm with an explicit communication update and ensure
estimation consistency at the same time. We investigate the covariance
boundedness criterion of our algorithm with respect to communication and
observation graphs, demonstrating provable localization performance under even
sparse communications topologies. We substantiate the resilience of our
algorithm as well as the boundedness analysis through experiments on simulated
and benchmark physical data against varying communications connectivity and
failure metrics. Especially when inter-robot communication is entirely blocked
or partially unavailable, we demonstrate that our method is less affected and
maintains desired performance compared to existing cooperative localization
algorithms.",http://arxiv.org/abs/2108.08789v1
"Controlled GAN-Based Creature Synthesis via a Challenging Game Art
  Dataset -- Addressing the Noise-Latent Trade-Off",2021-08-19T21:31:20Z,"Vaibhav Vavilala, David Forsyth","The state-of-the-art StyleGAN2 network supports powerful methods to create
and edit art, including generating random images, finding images ""like"" some
query, and modifying content or style. Further, recent advancements enable
training with small datasets. We apply these methods to synthesize card art, by
training on a novel Yu-Gi-Oh dataset. While noise inputs to StyleGAN2 are
essential for good synthesis, we find that coarse-scale noise interferes with
latent variables on this dataset because both control long-scale image effects.
We observe over-aggressive variation in art with changes in noise and weak
content control via latent variable edits. Here, we demonstrate that training a
modified StyleGAN2, where coarse-scale noise is suppressed, removes these
unwanted effects. We obtain a superior FID; changes in noise result in local
exploration of style; and identity control is markedly improved. These results
and analysis lead towards a GAN-assisted art synthesis tool for digital artists
of all skill levels, which can be used in film, games, or any creative industry
for artistic ideation.",http://arxiv.org/abs/2108.08922v2
"Stability condition on Calabi-Yau threefold of complete intersection of
  quadratic and quartic hypersurfaces",2021-08-19T22:28:50Z,Shengxuan Liu,"In this paper, we prove a Clifford type inequality for the curve
$X_{2,2,2,4}$, which is the intersection of a quartic and three general
quadratics in $\mathbb{P}^5$. We thus prove a stronger Bogomolov-Gieseker
inequality for characters of stable vector bundles and stable objects on
$X_{2,4}$. Applying the scheme proposed by Bayer, Bertram, Macr\`i, Stellari
and Toda, we can construct an open subset of Bridgeland stability conditions on
$X_{2,4}$.",http://arxiv.org/abs/2108.08934v3
"A fuzzy-rough uncertainty measure to discover bias encoded explicitly or
  implicitly in features of structured pattern classification datasets",2021-08-20T10:27:32Z,"Gonzalo Nápoles, Lisa Koutsoviti Koumeri","The need to measure bias encoded in tabular data that are used to solve
pattern recognition problems is widely recognized by academia, legislators and
enterprises alike. In previous work, we proposed a bias quantification measure,
called fuzzy-rough uncer-tainty, which relies on the fuzzy-rough set theory.
The intuition dictates that protected features should not change the
fuzzy-rough boundary regions of a decision class significantly. The extent to
which this happens is a proxy for bias expressed as uncertainty in
adecision-making context. Our measure's main advantage is that it does not
depend on any machine learning prediction model but adistance function. In this
paper, we extend our study by exploring the existence of bias encoded
implicitly in non-protected featuresas defined by the correlation between
protected and unprotected attributes. This analysis leads to four scenarios
that domain experts should evaluate before deciding how to tackle bias. In
addition, we conduct a sensitivity analysis to determine the fuzzy operatorsand
distance function that best capture change in the boundary regions.",http://arxiv.org/abs/2108.09098v2
"Overconvergent cohomology, $p$-adic $L$-functions and families for
  $\mathrm{GL}(2)$ over CM fields",2021-08-20T14:16:39Z,"Daniel Barrera Salazar, Chris Williams","The use of overconvergent cohomology in constructing $p$-adic $L$-functions,
initiated by Stevens and Pollack--Stevens in the setting of classical modular
forms, has now been established in a number of settings. The method is
compatible with constructions of eigenvarieties by Ash--Stevens, Urban and
Hansen, and is thus well-adapted to non-ordinary situations and variation in
$p$-adic families. In this note, we give an exposition of the ideas behind the
construction of $p$-adic $L$-functions via overconvergent cohomology.
Conditional on the non-abelian Leopoldt conjecture, we illustrate them by
constructing $p$-adic $L$-functions attached to families of base-change
automorphic representations for $\mathrm{GL}(2)$ over CM fields. As a
corollary, we prove a $p$-adic Artin formalism result for base-change $p$-adic
$L$-functions.",http://arxiv.org/abs/2108.09191v1
Detecting changes in the trend function of heteroscedastic time series,2021-08-20T14:57:06Z,Sara Kristin Schmidt,"We propose a new asymptotic test to assess the stationarity of a time series'
mean that is applicable in the presence of both heteroscedasticity and
short-range dependence. Our test statistic is composed of Gini's mean
difference of local sample means. To analyse its asymptotic behaviour, we
develop new limit theory for U-statistics of strongly mixing triangular arrays
under non-stationarity. Most importantly, we show asymptotic normality of the
test statistic under the hypothesis of a constant mean and prove the test's
consistency against a very general class of alternatives, including both smooth
and abrupt changes in the mean. We propose estimators for all parameters
involved, including an adapted subsampling estimator for the long run variance,
and show their consistency. Our procedure is practically evaluated in an
extensive simulation study and in two data examples.",http://arxiv.org/abs/2108.09206v1
"Tailored generation of quantum states in an entangled spinor
  interferometer to overcome detection noise",2021-08-20T17:09:46Z,"Q. Guan, G. W. Biedermann, A. Schwettmann, R. J. Lewis-Swan","We theoretically investigate how entangled atomic states generated via
spin-changing collisions in a spinor Bose-Einstein condensate can be designed
and controllably prepared for atom interferometry that is robust against common
technical issues, such as limited detector resolution. We use analytic and
numerical treatments of the spin-changing collision process to demonstrate that
triggering the entangling collisions with a small classical seed rather than
vacuum fluctuations leads to a more robust and superior sensitivity when
technical noise is accounted for, despite the generated atomic state ideally
featuring less metrologically useful entanglement. Our results are relevant for
understanding how entangled atomic states are best designed and generated for
use in quantum-enhanced matter-wave interferometry.",http://arxiv.org/abs/2108.09272v2
"First investigation of eclipsing binary KIC 9026766: analysis of light
  curve and periodic changes",2021-08-22T04:10:38Z,"Somaye Soomandar, Abbas Abedi","Abstract We investigate a short-period W UMa binary KIC 9026766 with an
orbital period of 0.2721278 days in the Kepler field of view. By using an
automated q-search for the folded light curve and producing a synthetic light
curve for this object based on the PHOEBE code, we calculate the fundamental
stellar parameters. We also analyze the O-C curve of the primary minima. The
orbital period changes can be attributed to the combination of an upward
quadratic function and light-travel time effect due to a possible third body
with a minimum mass of 0.029 solar mass and an orbital period of 972.5866 days.
The relative luminosity of the primary and secondary eclipses (Min I Min II) is
calculated. The periodogram of the residuals of the LTT effect, and Min I Min
II show peaks with the same period of 0.8566 days. The background effect of two
nearby stars on our target is the possible reason for this signal. By
considering the amplitudes and periods of the remaining signals in the OC curve
of minima, spot motion is possible.",http://arxiv.org/abs/2108.09629v1
Tunable single-mode laser on thin film lithium niobate,2021-08-22T14:42:54Z,"Xiangmin Liu, Xiongshuo Yan, Yi'an Liu, Hao Li, Yuping Chen, Xianfeng Chen","Erbium-doped lithium niobate on insulator (LNOI) laser plays an important
role in the complete photonic integrated circuits (PICs). Here, we demonstrate
an integrated tunable whisper galley single mode laser (WGSML) by making use of
a pair of coupled microdisk and microring on LNOI. A 974 nm single-mode pump
light can have an excellent resonance in the designed microdisk, which is
beneficial to the whisper gallery mode (WGM) laser generation. The WGSML at
1560.40 nm with a maximum 31.4 dB side mode suppression ratio (SMSR) has been
achieved. By regulating the temperature, WGSMLs output power increased and the
central wavelength can be changed from 1560.30 nm to 1560.40 nm. What's more,
1560.60 nm and 1565.00 nm WGSMLs have been achieved by changing the coupling
gap width between microdisk and microring. We can also use the electro-optic
effect of LNOI to obtain more accurate adjustable WGSMLs in further research.",http://arxiv.org/abs/2108.09740v2
Temporal Network Embedding via Tensor Factorization,2021-08-22T20:50:38Z,"Jing Ma, Qiuchen Zhang, Jian Lou, Li Xiong, Joyce C. Ho","Representation learning on static graph-structured data has shown a
significant impact on many real-world applications. However, less attention has
been paid to the evolving nature of temporal networks, in which the edges are
often changing over time. The embeddings of such temporal networks should
encode both graph-structured information and the temporally evolving pattern.
Existing approaches in learning temporally evolving network representations
fail to capture the temporal interdependence. In this paper, we propose Toffee,
a novel approach for temporal network representation learning based on tensor
decomposition. Our method exploits the tensor-tensor product operator to encode
the cross-time information, so that the periodic changes in the evolving
networks can be captured. Experimental results demonstrate that Toffee
outperforms existing methods on multiple real-world temporal networks in
generating effective embeddings for the link prediction tasks.",http://arxiv.org/abs/2108.09837v1
"Predicting Vehicles' Longitudinal Trajectories and Lane Changes on
  Highway On-Ramps",2021-08-23T20:38:37Z,"Nachuan Li, Riley Fischer, Wissam Kontar, Soyoung Ahn","Vehicles on highway on-ramps are one of the leading contributors to
congestion. In this paper, we propose a prediction framework that predicts the
longitudinal trajectories and lane changes (LCs) of vehicles on highway
on-ramps and tapers. Specifically, our framework adopts a combination of
prediction models that inputs a 4 seconds duration of a trajectory to output a
forecast of the longitudinal trajectories and LCs up to 15 seconds ahead.
Training and Validation based on next generation simulation (NGSIM) data show
that the prediction power of the developed model and its accuracy outperforms a
traditional long-short term memory (LSTM) model. Ultimately, the work presented
here can alleviate the congestion experienced on on-ramps, improve safety, and
guide effective traffic control strategies.",http://arxiv.org/abs/2108.10397v1
"A change of measure enhanced near exact Euler Maruyama scheme for the
  solution to nonlinear stochastic dynamical systems",2021-08-24T11:47:40Z,"Tapas Tripura, Mohammad Imran, Budhaditya Hazra, Souvik Chakraborty","The present study utilizes the Girsanov transformation based framework for
solving a nonlinear stochastic dynamical system in an efficient way in
comparison to other available approximate methods. In this approach, a
rejection sampling is formulated to evaluate the Radon-Nikodym derivative
arising from the change of measure due to Girsanov transformation. The
rejection sampling is applied on the Euler Maruyama approximated sample paths
which draw exact paths independent of the diffusion dynamics of the underlying
dynamical system. The efficacy of the proposed framework is ensured using more
accurate numerical as well as exact nonlinear methods. Finally, nonlinear
applied test problems are considered to confirm the theoretical results. The
test problems demonstrates that the proposed exact formulation of the
Euler-Maruyama provides an almost exact approximation to both the displacement
and velocity states of a second order non-linear dynamical system.",http://arxiv.org/abs/2108.10655v1
"Online Dictionary Learning Based Fault and Cyber Attack Detection for
  Power Systems",2021-08-24T23:17:58Z,"Gabriel Intriago, Yu Zhang","The emerging wide area monitoring systems (WAMS) have brought significant
improvements in electric grids' situational awareness. However, the newly
introduced system can potentially increase the risk of cyber-attacks, which may
be disguised as normal physical disturbances. This paper deals with the event
and intrusion detection problem by leveraging a stream data mining classifier
(Hoeffding adaptive tree) with semi-supervised learning techniques to
distinguish cyber-attacks from regular system perturbations accurately. First,
our proposed approach builds a dictionary by learning higher-level features
from unlabeled data. Then, the labeled data are represented as sparse linear
combinations of learned dictionary atoms. We capitalize on those sparse codes
to train the online classifier along with efficient change detectors. We
conduct numerical experiments with industrial control systems cyber-attack
datasets. We consider five different scenarios: short-circuit faults, line
maintenance, remote tripping command injection, relay setting change, as well
as false data injection. The data are generated based on a modified IEEE 9-bus
system. Simulation results show that our proposed approach outperforms the
state-of-the-art method.",http://arxiv.org/abs/2108.10990v1
Reachability of Nonlinear Systems with Unknown Dynamics,2021-08-25T04:50:31Z,"Taha Shafa, Melkior Ornik","Determining the reachable set for a given nonlinear control system is crucial
for system control and planning. However, computing such a set is impossible if
the system's dynamics are not fully known. This paper is motivated by a
scenario where a system suffers an adverse event mid-operation, resulting in a
substantial change to the system's dynamics, rendering them largely unknown.
Our objective is to conservatively approximate the system's reachable set
solely from its local dynamics at a single point and the bounds on the rate of
change of its dynamics. We translate this knowledge about the system dynamics
into an ordinary differential inclusion. We then derive a conservative
approximation of the velocities available to the system at every system state.
An inclusion using this approximation can be interpreted as a control system;
the trajectories of the derived control system are guaranteed to be
trajectories of the unknown system. To illustrate the practical implementation
and consequences of our work, we apply our algorithm to a simplified model of
an unmanned aerial vehicle.",http://arxiv.org/abs/2108.11045v1
"The rapidly oscillating Ap star gamma Equ: linear polarization as an
  enhanced pulsation diagnostic?",2021-08-25T14:53:01Z,"S. Hubrig, S. P. Jarvinen, I. Ilyin, K. G. Strassmeier, M. Schöller","We present the first short time scale observations of the roAp star gamma Equ
in linear polarized light obtained with the PEPSI polarimeter installed at the
LBT. These observations are used to search for pulsation variability in Stokes
Q and U line profiles belonging to different elements. The atmospheres of roAp
stars are significantly stratified with spectral lines of different elements
probing different atmospheric depths. roAp stars with strong magnetic fields,
such as gamma Equ with a magnetic field modulus of 4kG and a pulsation period
of 12.21min, are of special interest because the effect of the magnetic field
on the structure of their atmospheres can be studied with greatest detail and
accuracy. Our results show that we may detect changes in the transversal field
component in Fe I and rare-earth lines possessing large second-order Lande
factors. Such variability can be due to the impact of pulsation on the
transverse magnetic field, causing changes in the obliquity angles of the
magnetic force lines. Further studies of roAp stars in linear polarized light
and subsequent detailed modelling are necessary to improve our understanding of
the involved physics.",http://arxiv.org/abs/2108.11272v1
"A Unifying Theory of Thompson Sampling for Continuous Risk-Averse
  Bandits",2021-08-25T17:09:01Z,"Joel Q. L. Chang, Vincent Y. F. Tan","This paper unifies the design and the analysis of risk-averse Thompson
sampling algorithms for the multi-armed bandit problem for a class of risk
functionals $\rho$ that are continuous and dominant. We prove generalised
concentration bounds for these continuous and dominant risk functionals and
show that a wide class of popular risk functionals belong to this class. Using
our newly developed analytical toolkits, we analyse the algorithm $\rho$-MTS
(for multinomial distributions) and prove that they admit asymptotically
optimal regret bounds of risk-averse algorithms under CVaR, proportional
hazard, and other ubiquitous risk measures. More generally, we prove the
asymptotic optimality of $\rho$-MTS for Bernoulli distributions for a class of
risk measures known as empirical distribution performance measures (EDPMs);
this includes the well-known mean-variance. Numerical simulations show that the
regret bounds incurred by our algorithms are reasonably tight vis-\`a-vis
algorithm-independent lower bounds.",http://arxiv.org/abs/2108.11345v4
"Time-dependent treatment of cosmic-ray spectral steepening due to
  turbulence driving",2021-08-26T10:10:01Z,Martin Pohl,"Cosmic-ray acceleration at non-relativistic shocks relies on scattering by
turbulence that the cosmic rays drive upstream of the shock. We explore the
rate of energy transfer from cosmic rays to non-resonant Bell modes and the
spectral softening it implies. Accounting for the finite time available for
turbulence driving at supernova-remnant shocks yields a smaller spectral impact
than found earlier with steady-state considerations. Generally, for diffusion
scaling with the Bohm rate by a factor $\eta$, the change in spectral index is
at most $\eta$ divided by the Alfv\'enic Mach number of the thermal sub-shock.
For $M_\mathrm{A}\lesssim 50$ it is well below this limit. Only for very fast
shocks and very efficient cosmic-ray acceleration the change in spectral index
may reach $0.1$. For standard SNR parameters it is negligible. Independent
confirmation is derived by considering the synchrotron energy losses of
electrons: if intense nonthermal multi-keV emission is produced, the energy
loss, and hence the spectral steepening, is very small for hadronic cosmic rays
that produce TeV-band gamma-ray emission.",http://arxiv.org/abs/2108.11688v1
Rethinking Why Intermediate-Task Fine-Tuning Works,2021-08-26T10:34:37Z,"Ting-Yun Chang, Chi-Jen Lu","Supplementary Training on Intermediate Labeled-data Tasks (STILTs) is a
widely applied technique, which first fine-tunes the pretrained language models
on an intermediate task before on the target task of interest. While STILTs is
able to further improve the performance of pretrained language models, it is
still unclear why and when it works. Previous research shows that those
intermediate tasks involving complex inference, such as commonsense reasoning,
work especially well for RoBERTa. In this paper, we discover that the
improvement from an intermediate task could be orthogonal to it containing
reasoning or other complex skills -- a simple real-fake discrimination task
synthesized by GPT2 can benefit diverse target tasks. We conduct extensive
experiments to study the impact of different factors on STILTs. These findings
suggest rethinking the role of intermediate fine-tuning in the STILTs pipeline.",http://arxiv.org/abs/2108.11696v2
Orbital Occupancy and Hybridization in Strained SrVO$_3$ Epitaxial Films,2021-08-26T11:43:33Z,"Mathieu Mirjolet, Hari Babu Vasili, Adrian Valadkhani, José Santiso, Vladislav Borisov, Pierluigi Gargiani, Manuel Valvidares, Roser Valentí, Josep Fontcuberta","Oxygen packaging in transition metal oxides determines the metal-oxygen
hybridization and electronic occupation at metal orbitals. Strontium vanadate
(SrVO$_3$), having a single electron in a $3d$ orbital, is thought to be the
simplest example of strongly correlated metallic oxides. Here, we determine the
effects of epitaxial strain on the electronic properties of SrVO$_3$ thin
films, where the metal-oxide sublattice is corner-connected. Using x-ray
absorption and x-ray linear dichroism at the V $L_{2,3}$ and O $K$-edges, it is
observed that tensile or compressive epitaxial strain change the hierarchy of
orbitals within the $t_{2g}$ and $e_g$ manifolds. Data show a remarkable
$2p-3d$ hybridization, as well as a strain-induced reordering of the V
$3d$($t_{2g}$, $e_g$) orbitals. The latter is itself accompanied by a
consequent change of hybridization that modulates the hybrid $\pi^*$ and
$\sigma^*$ orbitals and the carrier population at the metal ions, challenging a
rigid band picture.",http://arxiv.org/abs/2108.11718v1
"NJOY+NCrystal: an open-source tool for creating thermal neutron
  scattering libraries",2021-08-26T12:33:57Z,"Kemal Ramic, Jose Ignacio Marquez Damian, Thomas Kittelmann, Douglas D. Di Julio, Davide Campi, Marco Bernasconi, Giuseppe Gorini, Valentina Santoro","In this work we present NJOY+NCrystal, a tool to generate thermal neutron
scattering libraries with support for coherent and incoherent elastic
components for crystalline solid materials. This tool, which is a customized
version of NJOY, was created by modifying the nuclear data processing program
NJOY to call the thermal scattering software library NCrystal, and includes a
proposed change in the ENDF-6 format to store both the coherent and incoherent
elastic components. Necessary changes to enable this format in NJOY, as well as
to sample it in the OpenMC Monte Carlo code, are detailed here. Examples of
materials that are coherent-dominant, incoherent-dominant, and mixed elastic
scatterers are presented, as well as the creation of novel libraries for
MgH$_2$ and MgD$_2$, that are under consideration as advanced neutron
reflectors in the HighNESS project at the European Spallation Source.
NJOY+NCrystal simplifies greatly the process to generate thermal scattering
libraries (TSL) and this is exemplified with 213 new and updated TSL
evaluations.",http://arxiv.org/abs/2108.11737v2
Non-unitary neutrino mixing in the NO$ν$A near detector data,2021-08-26T13:25:43Z,"Ushak Rahaman, Soebur Razzaque","The $\nu_\mu \to \nu_e$ oscillation probability over short baseline
($\lesssim 1$~km) would be negligible in case the mixing matrix for three
active neutrinos is unitary. However, in case of non-unitary mixing of three
neutrinos, this probability would be non-negligible due to the so-called ""zero
distance"" effect. Hence, the near detector of the accelerator experiments such
as NO$\nu$A can provide strong constraints on the parameters of the non-unitary
mixing with very large statistics. By analyzing the NO$\nu$A near detector data
we find that the non-unitary mixing does not improve fits to the $\nu_e$ or
$\nu_\mu$ events over the standard unitary mixing. This leads to constraints on
the non-unitary parameters: $\alpha_{00}>0.911$, $|\alpha_{10}|<0.020$ and
$\alpha_{11}>0.952$ at 90\% C.L. A combined analysis with the near and far
detector data does not change these constraints significantly.",http://arxiv.org/abs/2108.11783v2
Sketches for Time-Dependent Machine Learning,2021-08-26T17:24:56Z,"Jesus Antonanzas, Marta Arias, Albert Bifet","Time series data can be subject to changes in the underlying process that
generates them and, because of these changes, models built on old samples can
become obsolete or perform poorly. In this work, we present a way to
incorporate information about the current data distribution and its evolution
across time into machine learning algorithms. Our solution is based on
efficiently maintaining statistics, particularly the mean and the variance, of
data features at different time resolutions. These data summarisations can be
performed over the input attributes, in which case they can then be fed into
the model as additional input features, or over latent representations learned
by models, such as those of Recurrent Neural Networks. In classification tasks,
the proposed techniques can significantly outperform the prediction
capabilities of equivalent architectures with no feature / latent
summarisations. Furthermore, these modifications do not introduce notable
computational and memory overhead when properly adjusted.",http://arxiv.org/abs/2108.11923v1
Detecting Propaganda on the Sentence Level during the COVID-19 Pandemic,2021-07-31T06:40:17Z,"Rong-Ching Chang, Chu-Hsing Lin","The spread of misinformation, conspiracy, and questionable content and
information manipulation by foreign adversaries on social media has surged
along with the COVID-19 pandemic. Such malicious cyber-enabled actions may
cause increasing social polarization, health crises, and property loss. In this
paper, using fine-tuned contextualized embedding trained on Reddit, we tackle
the detection of the propaganda of such user accounts and their targeted issues
on Twitter during March 2020 when the COVID-19 epidemic became recognized as a
pandemic. Our result shows that the pro-China group appeared to be tweeting 35
to 115 times more than the neutral group. At the same time, neutral groups were
tweeting more positive-attitude content and voicing alarm for the COVID-19
situation. The pro-China group was also using more call-for-action words on
political issues not necessarily China-related.",http://arxiv.org/abs/2108.12269v1
"Quantum fluctuation in an inhomogeneous background and its influence on
  the phase transition in a finite volume system",2021-08-27T14:58:30Z,"Xiaogang Li, Song Shu, Jia-Rong Li","We have studied the grand potential and phase transitions of an inhomogeneous
finite volume spherical quark system. First the finite volume effects are
considered by applying the multiple reflection expansion method which is an
approximation for the density of states of the momentum in the grand potential
of the finite size system. Then, the density of states of momentum is further
modified by the thermal fluctuations in the thermal system with the
inhomogeneous field background. The modification of the density of states is
calculated by the scattering phase shift from the Dirac equation of quarks in
the inhomogeneous field background. By the numerical calculation we show how
the phase transition is changed by varying the configuration of the
inhomogeneous field background and find that the strong first order phase
transition could be weakened or even changed to a crossover as a result.",http://arxiv.org/abs/2108.12325v2
"Opinions are Made to be Changed: Temporally Adaptive Stance
  Classification",2021-08-27T19:47:31Z,"Rabab Alkhalifa, Elena Kochkina, Arkaitz Zubiaga","Given the rapidly evolving nature of social media and people's views, word
usage changes over time. Consequently, the performance of a classifier trained
on old textual data can drop dramatically when tested on newer data. While
research in stance classification has advanced in recent years, no effort has
been invested in making these classifiers have persistent performance over
time. To study this phenomenon we introduce two novel large-scale, longitudinal
stance datasets. We then evaluate the performance persistence of stance
classifiers over time and demonstrate how it decays as the temporal gap between
training and testing data increases. We propose a novel approach to mitigate
this performance drop, which is based on temporal adaptation of the word
embeddings used for training the stance classifier. This enables us to make use
of readily available unlabelled data from the current time period instead of
expensive annotation efforts. We propose and compare several approaches to
embedding adaptation and find that the Incremental Temporal Alignment (ITA)
model leads to the best results in reducing performance drop over time.",http://arxiv.org/abs/2108.12476v1
Mitigation of Diachronic Bias in Fake News Detection Dataset,2021-08-28T08:25:29Z,"Taichi Murayama, Shoko Wakamiya, Eiji Aramaki","Fake news causes significant damage to society.To deal with these fake news,
several studies on building detection models and arranging datasets have been
conducted. Most of the fake news datasets depend on a specific time period.
Consequently, the detection models trained on such a dataset have difficulty
detecting novel fake news generated by political changes and social changes;
they may possibly result in biased output from the input, including specific
person names and organizational names. We refer to this problem as
\textbf{Diachronic Bias} because it is caused by the creation date of news in
each dataset. In this study, we confirm the bias, especially proper nouns
including person names, from the deviation of phrase appearances in each
dataset. Based on these findings, we propose masking methods using Wikidata to
mitigate the influence of person names and validate whether they make fake news
detection models robust through experiments with in-domain and out-of-domain
data.",http://arxiv.org/abs/2108.12601v1
Multi-Channel Transformer Transducer for Speech Recognition,2021-08-30T01:50:51Z,"Feng-Ju Chang, Martin Radfar, Athanasios Mouchtaris, Maurizio Omologo","Multi-channel inputs offer several advantages over single-channel, to improve
the robustness of on-device speech recognition systems. Recent work on
multi-channel transformer, has proposed a way to incorporate such inputs into
end-to-end ASR for improved accuracy. However, this approach is characterized
by a high computational complexity, which prevents it from being deployed in
on-device systems. In this paper, we present a novel speech recognition model,
Multi-Channel Transformer Transducer (MCTT), which features end-to-end
multi-channel training, low computation cost, and low latency so that it is
suitable for streaming decoding in on-device speech recognition. In a far-field
in-house dataset, our MCTT outperforms stagewise multi-channel models with
transformer-transducer up to 6.01% relative WER improvement (WERR). In
addition, MCTT outperforms the multi-channel transformer up to 11.62% WERR, and
is 15.8 times faster in terms of inference speed. We further show that we can
improve the computational cost of MCTT by constraining the future and previous
context in attention computations.",http://arxiv.org/abs/2108.12953v1
Characterization and Topological Behavior of Homomorphism Tree-Shifts,2021-08-30T04:11:43Z,"Jung-Chao Ban, Chih-Hung Chang, Wen-Guei Hu, Guan-Yu Lai, Yu-Liang Wu","The purpose of this article is twofold. On one hand, we reveal the
equivalence of shift of finite type between a one-sided shift $X$ and its
associated hom tree-shift $\mathcal{T}_{X}$, as well as the equivalence in the
sofic shift. On the other hand, we investigate the interrelationship among the
comparable mixing properties on tree-shifts as those on multidimensional shift
spaces. They include irreducibility, topologically mixing, block gluing, and
strong irreducibility, all of which are defined in the spirit of classical
multidimensional shift, complete prefix code (CPC), and uniform CPC. In
summary, the mixing properties defined in all three manners coincide for
$\mathcal{T}_{X}$. Furthermore, an equivalence between irreducibility on
$\mathcal{T}_{A}$ and irreducibility on $X_A$ are seen, and so is one between
topologically mixing on $\mathcal{T}_{A}$ and mixing property on $X_A$, where
$X_A$ is the one-sided shift space induced by the matrix $A$ and $T_A$ is the
associated tree-shift. These equivalences are consistent with the mixing
properties on $X$ or $X_A$ when viewed as a degenerate tree-shift.",http://arxiv.org/abs/2108.12986v1
Modularity and Heavy-Tailed Degree Distributions,2021-08-30T18:06:18Z,Larry Wilson,"Identifying clusters of vertices in graphs continues to be an important
problem, and modularity continues to be used as a tool for solving the problem.
Modularity, which measures the quality of a division of the vertices into
clusters, explicitly treats vertices of different degrees differently, imposing
a larger penalty when high-degree vertices are put in the same cluster. We
claim that this unequal treatment negatively impacts the performance of
clustering algorithms based on modularity for graphs with heavy-tailed degree
distributions. We used the Greedy Modularity hill-climb to find clusters in
graphs with power-law degree distributions and observed that it performed
poorly clustering low-degree vertices. We propose a simple variant of
modularity that we call flat modularity. We found that, using the same
algorithm with the modified score instead, we improved the performance of the
clustering algorithm on low-degree vertices and the overall performance as
well. We believe that the small change -- from modularity to flat modularity --
could improve the output in the many real-world processes that rely on
modularity to measure the quality of a division into clusters with only a small
change, which is really a simplification, to the implementation.",http://arxiv.org/abs/2108.13450v2
A Hierarchical Stitching Algorithm for Coded Compressed Sensing,2021-08-31T11:24:44Z,"Yi-Jheng Lin, Chia-Ming Chang, Cheng-Shang Chang","Recently, a novel coded compressed sensing (CCS) approach was proposed in [1]
for dealing with the scalability problem for large sensing matrices in massive
machine-type communications. The approach is to divide the compressed sensing
(CS) problem into smaller CS sub-problems. However, such an approach requires
stitching the results from the sub-problems to recover the result in the
original CS problem. For this stitching problem, we propose a hierarchical
stitching algorithm that is easier to implement in hardware for parallelization
than the tree coding algorithm in [1]. For our algorithm, we also derive an
upper bound on the probability of recovery errors.",http://arxiv.org/abs/2108.13760v1
"More WiFi for Everyone: Increasing Spectral Efficiency in WiFi6 Networks
  using OBSS/PD Mechanism",2021-08-31T15:08:41Z,"Ali Karakoç, Mehmet Şükrü Kuran, H. Birkan Yilmaz","This study aims to enhance spatial reuse by using the new features of IEEE
802.11ax WLANs. Since the wireless medium is a shared medium and there may be
multiple basic service sets (BSS) in the same vicinity, BSSs may overlap, and
interference occurs. In this situation, BSSs cannot transmit simultaneously due
to the exposed node problem. The IEEE 802.11ax standard has a couple of
mechanisms to resolve these spectral efficiency problems. One of the most
effective mechanisms that address these problems is the overlapping BSS
preamble detection (OBSS/PD) mechanism. OBSS/PD mechanism uses the color
mechanism to distinguish OBSS signals. By using a signal threshold, the
mechanism can ignore some of the signals, which cause interference. In this
paper, we propose a rate-adaptive dynamic OBSS/PD threshold algorithm that
tracks the changes in transmission rate and dynamically adjusts the threshold
step by step considering the changes.",http://arxiv.org/abs/2108.13909v1
"A machine learning algorithm for direct detection of axion-like particle
  domain walls",2021-10-01T00:36:34Z,"Dongok Kim, Derek F. Jackson Kimball, Hector Masia-Roig, Joseph A. Smiga, Arne Wickenbrock, Dmitry Budker, Younggeun Kim, Yun Chang Shin, Yannis K. Semertzidis","The Global Network of Optical Magnetometers for Exotic physics searches
(GNOME) conducts an experimental search for certain forms of dark matter based
on their spatiotemporal signatures imprinted on a global array of synchronized
atomic magnetometers. The experiment described here looks for a gradient
coupling of axion-like particles (ALPs) with proton spins as a signature of
locally dense dark matter objects such as domain walls. In this work,
stochastic optimization with machine learning is proposed for use in a search
for ALP domain walls based on GNOME data. The validity and reliability of this
method were verified using binary classification. The projected sensitivity of
this new analysis method for ALP domain-wall crossing events is presented.",http://arxiv.org/abs/2110.00139v1
Collective Neutrino Flavor Instability Requires a Crossing,2021-10-01T03:40:48Z,Basudeb Dasgupta,"Neutrinos in supernovae, neutron stars, and in the early Universe may change
flavor collectively and unstably, due to neutrino-neutrino forward-scattering.
We prove that for collective instability to occur, the difference of momentum
distributions of two flavors must change sign, i.e., there is a zero crossing.
This necessary criterion, which unifies slow and fast instabilities, is valid
for Hamiltonian flavor-evolution of ultra-relativistic Standard Model neutrino
occupation matrices, including damping due to collisions in the relaxation
approximation. It provides a simple but rigorous condition for collective
flavor transformations that are believed to be important for stellar dynamics,
nucleosynthesis, and neutrino phenomenology.",http://arxiv.org/abs/2110.00192v2
Sums of divisors on arithmetic progressions,2021-10-01T07:08:06Z,Prapanpong Pongsriiam,"For each $s\in \mathbb R$ and $n\in \mathbb N$, let $\sigma_s(n) =
\sum_{d\mid n}d^s$. In this article, we give a comparison between
$\sigma_s(an+b)$ and $\sigma_s(cn+d)$ where $a$, $b$, $c$, $d$, $s$ are fixed,
the vectors $(a,b)$ and $(c,d)$ are linearly independent over $\mathbb Q$, and
$n$ runs over all positive integers. For example, if $|s|\leq 1$, $a, b, c,
d\in \mathbb N$ are fixed and satisfy certain natural conditions, then $$
\sigma_s(an+b) < \sigma_s(cn+d)\quad\text{ for all $n\leq M$} $$ where $M$ may
be arbitrarily large, but in fact $\sigma_s(an+b) - \sigma_s(cn+d)$ has
infinitely many sign changes. The results are entirely different when $|s|>1$,
where the following three cases may occur: \begin{itemize} \item[(i)]
$\sigma_s(an+b) < \sigma_s(cn+d)$ for all $n\in \mathbb N$; \item[(ii)]
$\sigma_s(an+b) < \sigma_s(cn+d)$ for all $n\leq M$ and $\sigma_s(an+b) >
\sigma_s(cn+d)$ for all $n\geq M+1$; \item[(iii)] $\sigma_s(an+b) -
\sigma_s(cn+d)$ has infinitely many sign changes. \end{itemize} We also give
several examples and propose some problems.",http://arxiv.org/abs/2110.00237v1
Rapid Quantum Squeezing by Jumping the Harmonic Oscillator Frequency,2021-10-01T08:18:29Z,"Mingjie Xin, Wui Seng Leong, Zilong Chen, Yu Wang, Shau-Yu Lan","Quantum sensing and quantum information processing use quantum advantages
such as squeezed states that encode a quantity of interest with higher
precision and generate quantum correlations to outperform classical methods. In
harmonic oscillators, the rate of generating squeezing is set by a quantum
speed limit. Therefore, the degree to which a quantum advantage can be used in
practice is limited by the time needed to create the state relative to the rate
of unavoidable decoherence. Alternatively, a sudden change of harmonic
oscillator's frequency projects a ground state into a squeezed state which can
circumvent the time constraint. Here, we create squeezed states of atomic
motion by sudden changes of the harmonic oscillation frequency of atoms in an
optical lattice. Building on this protocol, we demonstrate rapid quantum
amplification of a displacement operator that could be used for detecting
motion. Our results can speed up quantum gates and enable quantum sensing and
quantum information processing in noisy environments.",http://arxiv.org/abs/2110.00253v2
Batch size-invariance for policy optimization,2021-10-01T20:33:08Z,"Jacob Hilton, Karl Cobbe, John Schulman","We say an algorithm is batch size-invariant if changes to the batch size can
largely be compensated for by changes to other hyperparameters. Stochastic
gradient descent is well-known to have this property at small batch sizes, via
the learning rate. However, some policy optimization algorithms (such as PPO)
do not have this property, because of how they control the size of policy
updates. In this work we show how to make these algorithms batch
size-invariant. Our key insight is to decouple the proximal policy (used for
controlling policy updates) from the behavior policy (used for off-policy
corrections). Our experiments help explain why these algorithms work, and
additionally show how they can make more efficient use of stale data.",http://arxiv.org/abs/2110.00641v3
Joint Estimation of System Inertia and Load Relief,2021-10-02T01:00:22Z,"Julius Susanto, Alireza Fereidouni, Dean Sharafi","Modern power systems with high share of renewable generation are at the risk
of rapid changes in frequency and inertia resulting from contingencies. The
importance of an accurate assessment of system and load relief, as well as
frequency changes in the critical timescales is more pronounced in these power
systems. This knowledge serves as an insight which will guide the solutions
required for enhanced security and resilience. A novel procedure for
simultaneously assessing system inertia and load relief using a closed-form
system frequency response (SFR) model to fit measured disturbance data is
presented. Results of applying the proposed approach on generator contingencies
in the South West Interconnected System (SWIS) in Western Australia demonstrate
the validity of the method and indicate that it can overcome some of the
limitations observed in conventional inertia estimation methods based on the
linearised swing equation, such as the sliding window and polynomial fit
methods.",http://arxiv.org/abs/2110.00699v1
Weakly Durable High-Performance Transactions,2021-10-04T14:03:20Z,"Yun-Sheng Chang, Yu-Fang Chen, Hsiang-Shang Ko","Existing disk-based database systems largely fall into two categories -- they
either provide very high performance but few guarantees, or expose the
transaction abstraction satisfying the full ACID guarantees at the cost of
lower performance. In this paper, we present an alternative that achieves the
best of both worlds, namely good performance and transactional properties. Our
key observation is that, because of the frequent use of synchronization
primitives, systems with strong durability can hardly utilize the extremely
high parallelism granted by modern storage devices. Thus, we explore the notion
of weakly durable transactions, and discuss how to safely relax durability
without compromising other transactional properties. We present AciKV, a
transactional system whose design is centered around weak durability. AciKV
exposes to users the normal transactional interface, but what sets it apart
from others is a new ""persist"" primitive that decouples durability from commit.
AciKV is a middle ground between systems that perform fast atomic operations,
and ones that support transactions; this middle ground is useful as it provides
similar performance to the former, while prevents isolation and consistency
anomalies like the latter. Our evaluation using the YCSB benchmark shows that
AciKV, under workloads that involve write requests, exhibits more than two
orders of magnitude higher throughput than existing strongly durable systems.",http://arxiv.org/abs/2110.01465v1
Quantified Facial Expressiveness for Affective Behavior Analytics,2021-10-05T00:21:33Z,"Md Taufeeq Uddin, Shaun Canavan","The quantified measurement of facial expressiveness is crucial to analyze
human affective behavior at scale. Unfortunately, methods for expressiveness
quantification at the video frame-level are largely unexplored, unlike the
study of discrete expression. In this work, we propose an algorithm that
quantifies facial expressiveness using a bounded, continuous expressiveness
score using multimodal facial features, such as action units (AUs), landmarks,
head pose, and gaze. The proposed algorithm more heavily weights AUs with high
intensities and large temporal changes. The proposed algorithm can compute the
expressiveness in terms of discrete expression, and can be used to perform
tasks including facial behavior tracking and subjectivity quantification in
context. Our results on benchmark datasets show the proposed algorithm is
effective in terms of capturing temporal changes and expressiveness, measuring
subjective differences in context, and extracting useful insight.",http://arxiv.org/abs/2110.01758v2
"DistilHuBERT: Speech Representation Learning by Layer-wise Distillation
  of Hidden-unit BERT",2021-10-05T09:34:44Z,"Heng-Jui Chang, Shu-wen Yang, Hung-yi Lee","Self-supervised speech representation learning methods like wav2vec 2.0 and
Hidden-unit BERT (HuBERT) leverage unlabeled speech data for pre-training and
offer good representations for numerous speech processing tasks. Despite the
success of these methods, they require large memory and high pre-training
costs, making them inaccessible for researchers in academia and small
companies. Therefore, this paper introduces DistilHuBERT, a novel multi-task
learning framework to distill hidden representations from a HuBERT model
directly. This method reduces HuBERT's size by 75% and 73% faster while
retaining most performance in ten different tasks. Moreover, DistilHuBERT
required little training time and data, opening the possibilities of
pre-training personal and on-device SSL models for speech.",http://arxiv.org/abs/2110.01900v4
RapidAI4EO: A Corpus for Higher Spatial and Temporal Reasoning,2021-10-05T10:12:20Z,"Giovanni Marchisio, Patrick Helber, Benjamin Bischke, Timothy Davis, Caglar Senaras, Daniele Zanaga, Ruben Van De Kerchove, Annett Wania","Under the sponsorship of the European Union Horizon 2020 program, RapidAI4EO
will establish the foundations for the next generation of Copernicus Land
Monitoring Service (CLMS) products. The project aims to provide intensified
monitoring of Land Use (LU), Land Cover (LC), and LU change at a much higher
level of detail and temporal cadence than it is possible today. Focus is on
disentangling phenology from structural change and in providing critical
training data to drive advancement in the Copernicus community and ecosystem
well beyond the lifetime of this project. To this end we are creating the
densest spatiotemporal training sets ever by fusing open satellite data with
Planet imagery at as many as 500,000 patch locations over Europe and delivering
high resolution daily time series at all locations. We plan to open source
these datasets for the benefit of the entire remote sensing community.",http://arxiv.org/abs/2110.01919v1
"Axion emission from supernova with axion-pion-nucleon contact
  interaction",2021-10-05T12:13:10Z,"Kiwoon Choi, Hee Jung Kim, Hyeonseok Seong, Chang Sub Shin","We examine the axion emission from supernovae with a complete set of relevant
axion couplings including the axion-pion-nucleon contact interaction which was
ignored in the previous studies. Two processes are affected by the
axion-pion-nucleon contact interaction, $\pi^-+p \rightarrow n + a$ and
$n+p\rightarrow n+p+a$, and these processes can be the dominant source of
axions for some region in the axion parameter space or in astrophysical
conditions encountered inside supernovae. We find that the contact interaction
can enhance the axion emissivity of $\pi^-+p \rightarrow n + a$ by a factor of
$2-4$, while the effect on $n+p\rightarrow n+p+a$ is not significant. We also
discuss the relative importance of other pion-induced processes such as
$\pi^0+n\rightarrow n+a$ and $\pi^-+\pi^0\rightarrow \pi^-+a$.",http://arxiv.org/abs/2110.01972v2
"CNFET-based design of efficient ternary half adder and 1-trit multiplier
  circuits using dynamic logic",2021-10-05T11:26:06Z,"Farzin Mahboob-Sardroudi, Mehdi Habibi, Mohammad-Hossein Moaiyeri","This paper presents a ternary half adder and a 1-trit multiplier using carbon
nanotube transistors. The proposed circuits are designed using pass transistor
logic and dynamic logic. Ternary logic uses less connections than binary logic,
and less voltage changes are required for the same amount of data transmission.
Carbon nanotube transistors have advantages over MOSFETs, such as the same
mobility for electrons and holes, the ability to adjust the threshold voltage
by changing the nanotube diameter, and less leakage power. The proposed half
adder has lower power consumption, delay, and fewer transistors compared to
recent ternary half adders that use similar design methods. The proposed 1-trit
multiplier also has a lower delay than other designs. Moreover, these
advantages are achieved over a wide supply voltage range, operating
temperatures, and output loads. The design is also more robust to process
variations than the nearest design in terms of PDP.",http://arxiv.org/abs/2110.02223v1
Word Acquisition in Neural Language Models,2021-10-05T23:26:16Z,"Tyler A. Chang, Benjamin K. Bergen","We investigate how neural language models acquire individual words during
training, extracting learning curves and ages of acquisition for over 600 words
on the MacArthur-Bates Communicative Development Inventory (Fenson et al.,
2007). Drawing on studies of word acquisition in children, we evaluate multiple
predictors for words' ages of acquisition in LSTMs, BERT, and GPT-2. We find
that the effects of concreteness, word length, and lexical class are pointedly
different in children and language models, reinforcing the importance of
interaction and sensorimotor experience in child language acquisition. Language
models rely far more on word frequency than children, but like children, they
exhibit slower learning of words in longer utterances. Interestingly, models
follow consistent patterns during training for both unidirectional and
bidirectional models, and for both LSTM and Transformer architectures. Models
predict based on unigram token frequencies early in training, before
transitioning loosely to bigram probabilities, eventually converging on more
nuanced predictions. These results shed light on the role of distributional
learning mechanisms in children, while also providing insights for more
human-like language acquisition in language models.",http://arxiv.org/abs/2110.02406v1
Consistent Counterfactuals for Deep Models,2021-10-06T23:48:55Z,"Emily Black, Zifan Wang, Matt Fredrikson, Anupam Datta","Counterfactual examples are one of the most commonly-cited methods for
explaining the predictions of machine learning models in key areas such as
finance and medical diagnosis. Counterfactuals are often discussed under the
assumption that the model on which they will be used is static, but in
deployment models may be periodically retrained or fine-tuned. This paper
studies the consistency of model prediction on counterfactual examples in deep
networks under small changes to initial training conditions, such as weight
initialization and leave-one-out variations in data, as often occurs during
model deployment. We demonstrate experimentally that counterfactual examples
for deep models are often inconsistent across such small changes, and that
increasing the cost of the counterfactual, a stability-enhancing mitigation
suggested by prior work in the context of simpler models, is not a reliable
heuristic in deep networks. Rather, our analysis shows that a model's local
Lipschitz continuity around the counterfactual is key to its consistency across
related models. To this end, we propose Stable Neighbor Search as a way to
generate more consistent counterfactual explanations, and illustrate the
effectiveness of this approach on several benchmark datasets.",http://arxiv.org/abs/2110.03109v1
Gate-tunable magnetoresistance in six-septuple-layer MnBi$_2$Te$_4$,2021-10-07T03:36:49Z,"Yaoxin Li, Chang Liu, Yongchao Wang, Hao Li, Yang Wu, Jinsong Zhang, Yayu Wang","The recently discovered antiferromagnetic topological insulator
MnBi$_2$Te$_4$ hosts a variety of exotic topological quantum phases such as the
axion insulator and Chern insulator states. Here we report systematic gate
voltage dependent magneto transport studies in six septuple-layer
MnBi$_2$Te$_4$. In p-type carrier regime, we observe positive linear
magnetoresistance when MnBi$_2$Te$_4$ is polarized in the ferromagnetic state
by an out-of-plane magnetic field. Whereas in n-type regime, distinct negative
magnetoresistance behaviors are observed. The magnetoresistance in both regimes
is highly robust against temperature even up to the N\'eel temperature. Within
the antiferromagnetic state, the behavior of magnetoresistance exhibits a
transition from negative to positive as applying a gate voltage. The boundaries
between different magnetoresistance behaviors in the experimental phase diagram
can be explicitly characterized by the gate-voltage-independent magnetic fields
that denotes the processes of the spin-flop transition. The rich transport
phenomena demonstrate the intricate interplay between topology, magnetism and
dimensionality in MnBi$_2$Te$_4$.",http://arxiv.org/abs/2110.03164v1
"Extragradient Method: $O(1/K)$ Last-Iterate Convergence for Monotone
  Variational Inequalities and Connections With Cocoercivity",2021-10-08T17:16:12Z,"Eduard Gorbunov, Nicolas Loizou, Gauthier Gidel","Extragradient method (EG) (Korpelevich, 1976) is one of the most popular
methods for solving saddle point and variational inequalities problems (VIP).
Despite its long history and significant attention in the optimization
community, there remain important open questions about convergence of EG. In
this paper, we resolve one of such questions and derive the first last-iterate
$O(1/K)$ convergence rate for EG for monotone and Lipschitz VIP without any
additional assumptions on the operator unlike the only known result of this
type (Golowich et al., 2020) that relies on the Lipschitzness of the Jacobian
of the operator. The rate is given in terms of reducing the squared norm of the
operator. Moreover, we establish several results on the (non-)cocoercivity of
the update operators of EG, Optimistic Gradient Method, and Hamiltonian
Gradient Method, when the original operator is monotone and Lipschitz.",http://arxiv.org/abs/2110.04261v2
"A State Transfer Method That Adapts to Network Bandwidth Variations in
  Geographic State Machine Replication",2021-10-09T03:55:31Z,"Tairi Chiba, Ren Ohmura, Junya Nakamura","We present a new state transfer method for geographic State Machine
Replication (SMR) that dynamically allocates the state to be transferred among
replicas according to changes in communication bandwidths. SMR is a method that
improves fault tolerance by replicating a service to multiple replicas. When a
replica is newly added or is recovered from a failure, the other replicas
transfer the current state of the service to it. However, in geographic SMR,
the communication bandwidths of replicas are different and constantly changing.
Therefore, existing state transfer methods cannot fully utilize the available
bandwidth, and their state transfer time becomes long. To overcome this
problem, our method divides the state into multiple chunks and assigns them to
replicas based on each replica's bandwidth so that the broader a replica's
bandwidth is, the more chunks it transfers. The number of assigned chunks is
dynamically updated based on the currently estimated bandwidth. The performance
evaluation on Amazon EC2 shows that the proposed method reduces the state
transfer time by up to 47% compared with the existing one.",http://arxiv.org/abs/2110.04448v1
An Analysis of COVID-19 Knowledge Graph Construction and Applications,2021-10-10T23:58:57Z,"Dominic Flocco, Bryce Palmer-Toy, Ruixiao Wang, Hongyu Zhu, Rishi Sonthalia, Junyuan Lin, Andrea L. Bertozzi, P. Jeffrey Brantingham","The construction and application of knowledge graphs have seen a rapid
increase across many disciplines in recent years. Additionally, the problem of
uncovering relationships between developments in the COVID-19 pandemic and
social media behavior is of great interest to researchers hoping to curb the
spread of the disease. In this paper we present a knowledge graph constructed
from COVID-19 related tweets in the Los Angeles area, supplemented with federal
and state policy announcements and disease spread statistics. By incorporating
dates, topics, and events as entities, we construct a knowledge graph that
describes the connections between these useful information. We use natural
language processing and change point analysis to extract tweet-topic,
tweet-date, and event-date relations. Further analysis on the constructed
knowledge graph provides insight into how tweets reflect public sentiments
towards COVID-19 related topics and how changes in these sentiments correlate
with real-world events.",http://arxiv.org/abs/2110.04932v1
"LSC-GAN: Latent Style Code Modeling for Continuous Image-to-image
  Translation",2021-10-11T07:46:43Z,"Qiusheng Huang, Xueqi Hu, Li Sun, Qingli Li","Image-to-image (I2I) translation is usually carried out among discrete
domains. However, image domains, often corresponding to a physical value, are
usually continuous. In other words, images gradually change with the value, and
there exists no obvious gap between different domains. This paper intends to
build the model for I2I translation among continuous varying domains. We first
divide the whole domain coverage into discrete intervals, and explicitly model
the latent style code for the center of each interval. To deal with continuous
translation, we design the editing modules, changing the latent style code
along two directions. These editing modules help to constrain the codes for
domain centers during training, so that the model can better understand the
relation among them. To have diverse results, the latent style code is further
diversified with either the random noise or features from the reference image,
giving the individual style code to the decoder for label-based or
reference-based synthesis. Extensive experiments on age and viewing angle
translation show that the proposed method can achieve high-quality results, and
it is also flexible for users.",http://arxiv.org/abs/2110.05052v1
Tracy-Widom limit for free sum of random matrices,2021-10-11T10:44:39Z,"Hong Chang Ji, Jaewhi Park","We consider fluctuations of the largest eigenvalues of the random matrix
model $A+UBU^{*}$ where $A$ and $B$ are $N \times N$ deterministic Hermitian
(or symmetric) matrices and $U$ is a Haar-distributed unitary (or orthogonal)
matrix. We prove that the largest eigenvalue weakly converges to the
Tracy-Widom distribution, under mild assumptions on $A$ and $B$ to guarantee
that the density of states of the model decays as square root around the upper
edge. Our proof is based on the comparison of the Green function along the
Dyson Brownian motion starting from the matrix $A + UBU^{*}$ and ending at time
$N^{-1/3+\chi}$. As a byproduct of our proof, we also prove an optimal local
law for the Dyson Brownian motion up to the constant time scale.",http://arxiv.org/abs/2110.05147v3
Motivating Effort with Information about Future Rewards,2021-10-11T23:19:42Z,Chang Liu,"This paper studies the optimal mechanism to motivate effort in a dynamic
principal-agent model without transfers. An agent is engaged in a task with
uncertain future rewards and can shirk irreversibly at any time. The principal
knows the reward of the task and provides information to the agent over time in
order to motivate effort. We derive the optimal information policy in closed
form and thus identify two conditions, each of which guarantees that delayed
disclosure is valuable. First, if the principal is impatient compared to the
agent, she prefers the front-loaded effort schedule induced by delayed
disclosure. In a stationary environment, delayed disclosure is beneficial if
and only if the principal is less patient than the agent. Second, if the
environment makes the agent become pessimistic over time in absence of any
information disclosure, then providing delayed news can counteract this
downward trend in the agent's belief and encourage the agent to work longer.
Notably, the level of patience remains a crucial determinant of the optimal
policy structure.",http://arxiv.org/abs/2110.05643v3
"Compaction behaviour of various flax fabric structures during composite
  manufacturing: mechanical characterisation and microstructural analysis",2021-10-12T15:56:39Z,"R. Rayyaan, Z. Yousaf, W. R. Kennon, P. Potluri","Flax fibre reinforced composites are becoming popular in the automotive and
civil industries due to their environmentally friendly nature in terms of
production and recycling and for their good specific strength. Textile
structures undergo transverse compaction during composite manufacturing which
changes the fabric thickness and ultimately fibre volume fraction of
composites. Here, different flax fibre structures were investigated for
compaction behaviour during composite forming to study the thickness changes of
these fabrics under pressures between 1 and 10 bars. A range of composite
manufacturing processes including vacuum infusion, autoclave curing and resin
transfer moulding were utilised. These fabrics were studied in single and multi
layer states, in dry and wet states, under different loading cycles and in
different orientations of the fabric plies (00/00 and 00/900). Nesting of the
layers has been calculated for single plies and for multi-layer stacks of dry
fabrics. It was observed that under transverse compression, the structure of
the preform plays a vital role in determining the thickness of the preform. The
compressibility pattern of these various structures was also dissimilar for
single layer and multi-layer stack which was attributed to the different
nesting behaviours of these flax fibre structures.",http://arxiv.org/abs/2110.06110v1
Algebra of Data Reconciliation,2021-10-12T20:01:04Z,"Elod P. Csirmaz, Laszlo Csirmaz","With distributed computing and mobile applications becoming ever more
prevalent, synchronizing diverging replicas of the same data is a common
problem. Reconciliation -- bringing two replicas of the same data structure as
close as possible without overriding local changes -- is investigated in an
algebraic model. Our approach is to consider two sequences of simple commands
that describe the changes in the replicas compared to the original structure,
and then determine the maximal subsequences of each that can be propagated to
the other. The proposed command set is shown to be functionally complete, and
an update detection algorithm is presented which produces a command sequence
transforming the original data structure into the replica while traversing both
simultaneously. Syntactical characterization is provided in terms of a
rewriting system for semantically equivalent command sequences. Algebraic
properties of sequence pairs that are applicable to the same data structure are
investigated. Based on these results the reconciliation problem is shown to
have a unique maximal solution. In addition, syntactical properties of the
maximal solution allow for an efficient algorithm that produces it.",http://arxiv.org/abs/2110.06313v3
Time Masking for Temporal Language Models,2021-10-12T21:15:23Z,"Guy D. Rosin, Ido Guy, Kira Radinsky","Our world is constantly evolving, and so is the content on the web.
Consequently, our languages, often said to mirror the world, are dynamic in
nature. However, most current contextual language models are static and cannot
adapt to changes over time. In this work, we propose a temporal contextual
language model called TempoBERT, which uses time as an additional context of
texts. Our technique is based on modifying texts with temporal information and
performing time masking - specific masking for the supplementary time
information. We leverage our approach for the tasks of semantic change
detection and sentence time prediction, experimenting on diverse datasets in
terms of time, size, genre, and language. Our extensive evaluation shows that
both tasks benefit from exploiting time masking.",http://arxiv.org/abs/2110.06366v4
"Formation of ring-like structures in flared α-discs with
  X-ray/FUV photoevaporation",2021-10-13T09:25:09Z,"Juan C. Vallejo, Ana Inés Gómez de castro","Protoplanetary discs are complex dynamical systems where several processes
may lead to the formation of ring-like structures and planets. These discs are
flared following a profile where the vertical scale height increases with
radius. In this work, we investigate the role of this disc flaring geometry on
the formation of rings and holes. We combine a flattening law change with X-ray
and FUV photoevaporative winds. We have used a semi-analytical 1D viscous
{\alpha} approach, presenting the evolution of the disc mass and mass rate in a
grid of representative systems. Our results show that changing the profile of
the flared disc may favour the formation of ring-like features resembling those
observed in real systems at the proper evolutionary times, with proper disc
masses and accretion rate values. However, these features seem to be
short-lived and further enhancements are still needed for better matching all
the features seen in real systems.",http://arxiv.org/abs/2110.06594v1
"Technical Report: A Totally Asynchronous Algorithm for Tracking
  Solutions to Time-Varying Convex Optimization Problems",2021-10-13T13:25:02Z,"Gabriel Behrendt, Matthew Hale","This paper presents a decentralized algorithm for a team of agents to track
time-varying fixed points that are the solutions to time-varying convex
optimization problems. The algorithm is first-order, and it allows for total
asynchrony in the communications and computations of all agents, i.e., all such
operations can occur with arbitrary timing and arbitrary (finite) delays.
Convergence rates are computed in terms of the communications and computations
that agents execute, without specifying when they must occur. These rates apply
to convergence to the minimum of each individual objective function, as well as
agents' long-run behavior as their objective functions change. Then, to improve
the usage of limited communication and computation resources, we optimize the
timing of agents' operations relative to changes in their objective functions
to minimize total fixed point tracking error over time. Simulation results are
presented to illustrate these developments in practice and empirically assess
their robustness to uncertainties in agents' update laws.",http://arxiv.org/abs/2110.06705v1
Leveraging Automated Unit Tests for Unsupervised Code Translation,2021-10-13T15:08:43Z,"Baptiste Roziere, Jie M. Zhang, Francois Charton, Mark Harman, Gabriel Synnaeve, Guillaume Lample","With little to no parallel data available for programming languages,
unsupervised methods are well-suited to source code translation. However, the
majority of unsupervised machine translation approaches rely on
back-translation, a method developed in the context of natural language
translation and one that inherently involves training on noisy inputs.
Unfortunately, source code is highly sensitive to small changes; a single token
can result in compilation failures or erroneous programs, unlike natural
languages where small inaccuracies may not change the meaning of a sentence. To
address this issue, we propose to leverage an automated unit-testing system to
filter out invalid translations, thereby creating a fully tested parallel
corpus. We found that fine-tuning an unsupervised model with this filtered data
set significantly reduces the noise in the translations so-generated,
comfortably outperforming the state-of-the-art for all language pairs studied.
In particular, for Java $\to$ Python and Python $\to$ C++ we outperform the
best previous methods by more than 16% and 24% respectively, reducing the error
rate by more than 35%.",http://arxiv.org/abs/2110.06773v2
"Improving the Robustness to Variations of Objects and Instructions with
  a Neuro-Symbolic Approach for Interactive Instruction Following",2021-10-13T21:00:00Z,"Kazutoshi Shinoda, Yuki Takezawa, Masahiro Suzuki, Yusuke Iwasawa, Yutaka Matsuo","An interactive instruction following task has been proposed as a benchmark
for learning to map natural language instructions and first-person vision into
sequences of actions to interact with objects in 3D environments. We found that
an existing end-to-end neural model for this task tends to fail to interact
with objects of unseen attributes and follow various instructions. We assume
that this problem is caused by the high sensitivity of neural feature
extraction to small changes in vision and language inputs. To mitigate this
problem, we propose a neuro-symbolic approach that utilizes high-level symbolic
features, which are robust to small changes in raw inputs, as intermediate
representations. We verify the effectiveness of our model with the subtask
evaluation on the ALFRED benchmark. Our experiments show that our approach
significantly outperforms the end-to-end neural model by 9, 46, and 74 points
in the success rate on the ToggleObject, PickupObject, and SliceObject subtasks
in unseen environments respectively.",http://arxiv.org/abs/2110.07031v2
Data Incubation -- Synthesizing Missing Data for Handwriting Recognition,2021-10-13T21:28:18Z,"Jen-Hao Rick Chang, Martin Bresler, Youssouf Chherawala, Adrien Delaye, Thomas Deselaers, Ryan Dixon, Oncel Tuzel","In this paper, we demonstrate how a generative model can be used to build a
better recognizer through the control of content and style. We are building an
online handwriting recognizer from a modest amount of training samples. By
training our controllable handwriting synthesizer on the same data, we can
synthesize handwriting with previously underrepresented content (e.g., URLs and
email addresses) and style (e.g., cursive and slanted). Moreover, we propose a
framework to analyze a recognizer that is trained with a mixture of real and
synthetic training data. We use the framework to optimize data synthesis and
demonstrate significant improvement on handwriting recognition over a model
trained on real data only. Overall, we achieve a 66% reduction in Character
Error Rate.",http://arxiv.org/abs/2110.07040v1
Fast Hand Detection in Collaborative Learning Environments,2021-10-13T22:50:15Z,"Sravani Teeparthi, Venkatesh Jatla, Marios S. Pattichis, Sylvia Celedon Pattichis, Carlos LopezLeiva","Long-term object detection requires the integration of frame-based results
over several seconds. For non-deformable objects, long-term detection is often
addressed using object detection followed by video tracking. Unfortunately,
tracking is inapplicable to objects that undergo dramatic changes in appearance
from frame to frame. As a related example, we study hand detection over long
video recordings in collaborative learning environments. More specifically, we
develop long-term hand detection methods that can deal with partial occlusions
and dramatic changes in appearance.
  Our approach integrates object-detection, followed by time projections,
clustering, and small region removal to provide effective hand detection over
long videos. The hand detector achieved average precision (AP) of 72% at 0.5
intersection over union (IoU). The detection results were improved to 81% by
using our optimized approach for data augmentation. The method runs at 4.7x the
real-time with AP of 81% at 0.5 intersection over the union. Our method reduced
the number of false-positive hand detections by 80% by improving IoU ratios
from 0.2 to 0.5. The overall hand detection system runs at 4x real-time.",http://arxiv.org/abs/2110.07070v1
Nuisance-Label Supervision: Robustness Improvement by Free Labels,2021-10-14T02:07:00Z,"Xinyue Wei, Weichao Qiu, Yi Zhang, Zihao Xiao, Alan Yuille","In this paper, we present a Nuisance-label Supervision (NLS) module, which
can make models more robust to nuisance factor variations. Nuisance factors are
those irrelevant to a task, and an ideal model should be invariant to them. For
example, an activity recognition model should perform consistently regardless
of the change of clothes and background. But our experiments show existing
models are far from this capability. So we explicitly supervise a model with
nuisance labels to make extracted features less dependent on nuisance factors.
Although the values of nuisance factors are rarely annotated, we demonstrate
that besides existing annotations, nuisance labels can be acquired freely from
data augmentation and synthetic data. Experiments show consistent improvement
in robustness towards image corruption and appearance change in action
recognition.",http://arxiv.org/abs/2110.07118v1
"Combining CNNs With Transformer for Multimodal 3D MRI Brain Tumor
  Segmentation With Self-Supervised Pretraining",2021-10-15T08:03:27Z,"Mariia Dobko, Danylo-Ivan Kolinko, Ostap Viniavskyi, Yurii Yelisieiev","We apply an ensemble of modified TransBTS, nnU-Net, and a combination of both
for the segmentation task of the BraTS 2021 challenge. In fact, we change the
original architecture of the TransBTS model by adding Squeeze-and-Excitation
blocks, an increasing number of CNN layers, replacing positional encoding in
Transformer block with a learnable Multilayer Perceptron (MLP) embeddings,
which makes Transformer adjustable to any input size during inference. With
these modifications, we are able to largely improve TransBTS performance.
Inspired by a nnU-Net framework we decided to combine it with our modified
TransBTS by changing the architecture inside nnU-Net to our custom model. On
the Validation set of BraTS 2021, the ensemble of these approaches achieves
0.8496, 0.8698, 0.9256 Dice score and 15.72, 11.057, 3.374 HD95 for enhancing
tumor, tumor core, and whole tumor, correspondingly. Our code is publicly
available.",http://arxiv.org/abs/2110.07919v1
"Relation Preserving Triplet Mining for Stabilising the Triplet Loss in
  Re-identification Systems",2021-10-15T08:23:40Z,"Adhiraj Ghosh, Kuruparan Shanmugalingam, Wen-Yan Lin","Object appearances change dramatically with pose variations. This creates a
challenge for embedding schemes that seek to map instances with the same object
ID to locations that are as close as possible. This issue becomes significantly
heightened in complex computer vision tasks such as re-identification(reID). In
this paper, we suggest that these dramatic appearance changes are indications
that an object ID is composed of multiple natural groups, and it is
counterproductive to forcefully map instances from different groups to a common
location. This leads us to introduce Relation Preserving Triplet Mining (RPTM),
a feature-matching guided triplet mining scheme, that ensures that triplets
will respect the natural subgroupings within an object ID. We use this triplet
mining mechanism to establish a pose-aware, well-conditioned triplet loss by
implicitly enforcing view consistency. This allows a single network to be
trained with fixed parameters across datasets while providing state-of-the-art
results. Code is available at https://github.com/adhirajghosh/RPTM_reid.",http://arxiv.org/abs/2110.07933v2
Towards a Multi-Agent System Architecture for Supply Chain Management,2021-09-24T17:53:42Z,"Carlos R. Jaimez-González, Wulfrano A. Luna-Ramírez","Individual business processes have been changing since the Internet was
created, and they are now oriented towards a more distributed and collaborative
business model, in an e-commerce environment that adapts itself to the
competitive and changing market conditions. This paper presents a multi-agent
system architecture for supply chain management, which explores different
strategies and offers solutions in a distributed e-commerce environment. The
system is designed to support different types of interfaces, which allow
interoperating with other business models already developed. In order to show
how the entire multi-agent system is being developed, the implementation of a
collaborative agent is presented and explained.",http://arxiv.org/abs/2110.08125v1
A QP perspective on topology change in Poisson-Lie T-duality,2021-10-15T16:11:56Z,"Alex S. Arvanitakis, Chris D. A. Blair, Daniel C. Thompson","We describe topological T-duality and Poisson-Lie T-duality in terms of QP
(differential graded symplectic) manifolds and their canonical transformations.
Duality is mediated by a QP-manifold on doubled non-abelian ""correspondence""
space, from which we can perform mutually dual symplectic reductions, where
certain canonical transformations play a vital role. In the presence of
spectator coordinates, we show how the introduction of ""bibundle"" structure on
correspondence space realises changes in the global fibration structure under
Poisson-Lie duality. Our approach can be directly translated to the worldsheet
to derive dual string current algebras. Finally, the canonical transformations
appearing in our reduction procedure naturally suggest a Fourier-Mukai integral
transformation for Poisson-Lie T-duality.",http://arxiv.org/abs/2110.08179v2
"Exact Bias Correction for Linear Adjustment of Randomized Controlled
  Trials",2021-10-16T00:48:20Z,"Haoge Chang, Joel Middleton, P. M. Aronow","In an influential critique of empirical practice, Freedman (2008) showed that
the linear regression estimator was biased for the analysis of randomized
controlled trials under the randomization model. Under Freedman's assumptions,
we derive exact closed-form bias corrections for the linear regression
estimator with and without treatment-by-covariate interactions. We show that
the limiting distribution of the bias corrected estimator is identical to the
uncorrected estimator, implying that the asymptotic gains from adjustment can
be attained without introducing any risk of bias. Taken together with results
from Lin (2013), our results show that Freedman's theoretical arguments against
the use of regression adjustment can be completely resolved with minor
modifications to practice.",http://arxiv.org/abs/2110.08425v2
"Cellular resource allocation strategies for cell size and shape control
  in bacteria",2021-10-16T13:55:16Z,"Diana Serbanescu, Nikola Ojkic, Shiladitya Banerjee","Bacteria are highly adaptive microorganisms that thrive in a wide range of
growth conditions via changes in cell morphologies and macromolecular
composition. How bacterial morphologies are regulated in diverse environmental
conditions is a longstanding question. Regulation of cell size and shape
implies control mechanisms that couple the growth and division of bacteria to
their cellular environment and macromolecular composition. In the past decade,
simple quantitative laws have emerged that connect cell growth to proteomic
composition and the nutrient availability. However, the relationships between
cell size, shape and growth physiology remain challenging to disentangle and
unifying models are lacking. In this review, we focus on regulatory models of
cell size control that reveal the connections between bacterial cell morphology
and growth physiology. In particular, we discuss how changes in nutrient
conditions and translational perturbations regulate the cell size, growth rate
and proteome composition. Integrating quantitative models with experimental
data, we identify the physiological principles of bacterial size regulation,
and discuss the optimization strategies of cellular resource allocation for
size control.",http://arxiv.org/abs/2110.08575v1
"Self-Learned Kernel Low Rank Approach TO Accelerated High Resolution 3D
  Diffusion MRI",2021-10-16T17:30:07Z,"Abhijit Baul, Nian Wang, Choyi Zhang, Leslie Ying, Yuchou Chang, Ukash Nakarmi","Diffusion Magnetic Resonance Imaging (dMRI) is a promising method to analyze
the subtle changes in the tissue structure. However, the lengthy acquisition
time is a major limitation in the clinical application of dMRI. Different image
acquisition techniques such as parallel imaging, compressed sensing, has
shortened the prolonged acquisition time but creating high-resolution 3D dMRI
slices still requires a significant amount of time. In this study, we have
shown that high-resolution 3D dMRI can be reconstructed from the highly
undersampled k-space and q-space data using a Kernel LowRank method. Our
proposed method has outperformed the conventional CS methods in terms of both
image quality and diffusion maps constructed from the diffusion-weighted images",http://arxiv.org/abs/2110.08622v3
"Joint SCSP-LROM: A novel approach to detect Cerebrovascular Anomalies
  from EEG signals",2021-10-17T23:04:12Z,Debojyoti Seth,"It has always been a big challenge to identify subtle changes in
Electroencephalogram (EEG) signals. Minor differences often lead to vital
decisions, for example, which grade a certain tumour belong to or whether a
haemorrhage can result in benign blood clots or cancerous ones. In recent
studies on brain computer interfaces (BCIs), one of the biggest challenges is
recovering maximum information for realistic predictions. In order to choose
EEG channels with highest accuracy, a novel notion of including sparsity in a
modified common spatial pattern (CSP) algorithm is introduced here. Being
influenced by the existing concept of compressed sensing, an optimization model
is also developed alongside to recover the cosparse signal and retain maximum
information. The state-of-the-art Joint Sparsity Induced Modified Common
Spatial Pattern Algorithm and Low Rank Optimization Model (SCSP-LROM) developed
here is capable of identifying and describing tumours and lesions in great
detail at an overall accuracy of 96.3%.",http://arxiv.org/abs/2110.08942v2
Depth Profile of the Phase Transition of the FeRh Alloy in FeRh/BaTiO3,2021-10-18T12:21:29Z,"Attila Lengyel, Gábor Bazsó, Aleksandr I. Chumakov, Dénes L. Nagy, Gergő Hegedűs, Dimitrios Bessas, Zsolt E. Horváth, Norbert M. Nemes, Maria A. Gracheva, Edit Szilágyi, Szilárd Sajti, Dániel G. Merkel","We report on the depth dependence and technological limits of the phase
transition of the iron rhodium alloy as function of temperature, external
magnetic and electric fields in the FeRh/BaTiO3 multiferroic, determined by
grazing-incidence nuclear resonant scattering measurements. The change of
temperature induces a continuous and homogenous antiferromagnetic /
ferromagnetic phase transition through the entire FeRh layer, except in the
near substrate region. External magnetic field does not affect this mechanism,
but the application of electric field changes it fundamentally (via
piezoelectric strain): the phase transition of the alloy suddenly propagates
from the substrate up to a height, defined by the combination of temperature
and external magnetic field, as soon as the applied electric field reaches ~ 20
kV/m.",http://arxiv.org/abs/2110.09219v2
"Symmetric inseparability and number entanglement in charge conserving
  mixed states",2021-10-18T15:20:07Z,"Zhanyu Ma, Cheolhee Han, Yigal Meir, Eran Sela","We explore sufficient conditions for inseparability in mixed states with a
globally conserved charge, such as a particle number. We argue that even
separable states may contain entanglement in fixed charge sectors, as long as
the state can not be separated into charge conserving components. As a witness
of symmetric inseparability we study the number entanglement (NE), $\Delta
S_m$, defined as the entropy change due to a subsystem's charge measurement.
Whenever $\Delta S_m > 0$, there exist inseparable charge sectors, having
finite (logarithmic) negativity, even when the full state is either separable
or has vanishing negativity. We demonstrate that the NE is not only a witness
of symmetric inseparability, but also an entanglement monotone. Finally, we
study the scaling of $\Delta S_m$ in thermal 1D systems combining high
temperature expansion and conformal field theory.",http://arxiv.org/abs/2110.09388v3
"Numeraire-invariant quadratic hedging and mean--variance portfolio
  allocation",2021-10-18T15:45:35Z,"Aleš Černý, Christoph Czichowsky, Jan Kallsen","The paper investigates quadratic hedging in a semimartingale market that does
not necessarily contain a risk-free asset. An equivalence result for hedging
with and without numeraire change is established (Proposition 3.16). This
permits direct computation of the optimal strategy without choosing a reference
asset and/or performing a numeraire change (Theorem 4.1). New explicit
expressions for optimal strategies are obtained, featuring the use of oblique
projections that provide unified treatment of the case with and without a
risk-free asset (Theorem 4.3). The analysis yields a streamlined computation of
the efficient frontier for the pure investment problem in terms of three easily
interpreted processes (Equation~1.1). The main result advances our
understanding of the efficient frontier formation in the most general case
where a risk-free asset may not be present. Several illustrations of the
numeraire-invariant approach are given.",http://arxiv.org/abs/2110.09416v3
"Multicell Atomic Quantum Memory as a Hardware-Efficient Quantum Repeater
  Node",2021-10-18T19:32:36Z,"Chang Li, Sheng Zhang, Yukai Wu, Nan Jiang, Yunfei Pu, Luming Duan","For scalable quantum communication and networks, a key step is to realize a
quantum repeater node that can efficiently connect different segments of
atom-photon entanglement using quantum memories. We report a compact and
hardware-efficient realization of a quantum repeater node using a single atomic
ensemble for multicell quantum memories. Millisecond lifetime is achieved for
individual memory cells after suppressing the magnetic-field-induced
inhomogeneous broadening and the atomic-motion-induced spin-wave dephasing.
Based on these long-lived multicell memory cells, we achieve heralded
asynchronous entanglement generation in two quantum repeater segments one after
another and then an on-demand entanglement connection of these two repeater
segments. As another application of the multicell atomic quantum memory, we
further demonstrate storage and on-demand retrieval of heralded atomic
spin-wave qubits by implementing a random access quantum memory with individual
addressing capacity. This work provides a promising constituent for efficient
realization of quantum repeaters for large-scale quantum networks.",http://arxiv.org/abs/2110.09597v1
"Ultrafast generation and detection of propagating coherent acoustic
  phonon wave packets in ultra-thin iron pnictide films",2021-10-19T04:30:14Z,"D. Cheng, B. Song, J. H. Kang, C. Sundahl, L. Luo, J-M. Park, Y. G. Collantes, E. E. Hellstrom, M. Mootz, I. E. Perakis, C. B. Eom, J. Wang","We observe pronounced oscillations in differential reflectivity of 9 nm and
60 nm BaFe\textsubscript{2}As\textsubscript{2} (Ba-122) thin films using
ultrafast optical spectroscopy. Our studies show that the oscillations result
from propagating longitudinal acoustic (LA) phonon wave packets with strong
thickness and temperature dependence. Particularly, the experimentally measured
oscillation frequency approaches to 50 GHz for the ultra-thin film. Our
calculations show that Young's modulus of 9 nm thin film is nearly four times
as large as that of 60 nm thin film, consistent with the experiment. The
increase in Young's modulus as thickness decrease was attributed to the
decrease in parent Ba-122 tetragonality $c/a$ near the film-substrate interface
due to material-substrate mismatch effect. %Temperature dependence of LA phonon
mode frequency for 9 nm Ba-122 thin film is reported. The temperature-dependent
change in LA phonon frequency was attributed to the change in parent Ba-122
othorhombicity $(a-b)/(a+b)$.",http://arxiv.org/abs/2110.09728v1
"A Lightweight, High-Extension, Planar 3-Degree-of-Freedom Manipulator
  Using Pinched Bistable Tapes",2021-10-19T05:52:43Z,"O. Godson Osele, Allison M. Okamura, Brian H. Do","To facilitate sensing and physical interaction in remote and/or constrained
environments, high-extension, lightweight robot manipulators are easier to
transport and reach substantially further than traditional serial chain
manipulators. We propose a novel planar 3-degree-of-freedom manipulator that
achieves low weight and high extension through the use of a pair of spooling
bistable tapes, commonly used in self-retracting tape measures, which are
pinched together to form a reconfigurable revolute joint. The pinching action
flattens the tapes to produce a localized bending region, resulting in a
revolute joint that can change its orientation by cable tension and its
location on the tapes though friction-driven movement of the pinching
mechanism. We present the design, implementation, kinematic modeling, stiffness
behavior of the revolute joint, and quasi-static performance of this
manipulator. In particular, we demonstrate the ability of the manipulator to
reach specified targets in free space, reach a 2D target with various
orientations, and maintain an end-effector angle or stationary bending point
while changing the other. The long-term goal of this work is to integrate the
manipulator with an unmanned aerial vehicle to enable more capable aerial
manipulation.",http://arxiv.org/abs/2110.09751v2
Decoupling of Nucleation and Growth of ZnO nano-colloids in solution,2021-10-20T06:22:37Z,"Priyanka Sharma, P. B. Barman, Sanjiv Kumar Tiwari","In this paper, temporal growth and morphological evolution of ZnO
nano-colloids were studied by in-situ UV-Vis absorption spectroscopy and
Transmission Electron Microscopy (TEM) respectively. Nucleation of the
nanoparticles was observed to occur within 10 sec in the solution after mixing
the precursors and there was not any significant change in morphology observed
with an increase in growth time. The morphological change was found to depend
on interfacial energy curvature. Decoupling of nucleation and growth parameters
was observed in the case of the atomically unbalanced reaction while aging of
the nanoparticles was found in atomically balanced reaction respectively. The
growth of nano-particles was modeled using the Phase-field model (PFM) and
compared with the present in-situ growth process.",http://arxiv.org/abs/2110.10392v1
"Knowledge distillation from language model to acoustic model: a
  hierarchical multi-task learning approach",2021-10-20T08:42:10Z,"Mun-Hak Lee, Joon-Hyuk Chang","The remarkable performance of the pre-trained language model (LM) using
self-supervised learning has led to a major paradigm shift in the study of
natural language processing. In line with these changes, leveraging the
performance of speech recognition systems with massive deep learning-based LMs
is a major topic of speech recognition research. Among the various methods of
applying LMs to speech recognition systems, in this paper, we focus on a
cross-modal knowledge distillation method that transfers knowledge between two
types of deep neural networks with different modalities. We propose an acoustic
model structure with multiple auxiliary output layers for cross-modal
distillation and demonstrate that the proposed method effectively compensates
for the shortcomings of the existing label-interpolation-based distillation
method. In addition, we extend the proposed method to a hierarchical
distillation method using LMs trained in different units (senones, monophones,
and subwords) and reveal the effectiveness of the hierarchical distillation
method through an ablation study.",http://arxiv.org/abs/2110.10429v1
Temperature-biased double-loop Josephson flux transducer,2021-10-20T14:25:38Z,"Claudio Guarcello, Roberta Citro, Francesco Giazotto, Alessandro Braggio","We theoretically study the behavior of the critical current of a
thermally-biased tunnel Josephson junction with a particular design, in which
the electrodes of the junction are enclosed in two different superconducting
loops pierced by independent magnetic fluxes. In this setup, the
superconducting gaps can be modified independently through the magnetic fluxes
threading the loops. We investigate the response of the device as a function of
the magnetic fluxes, by changing the asymmetry parameter, i.e., the ratio
between the zero-temperature superconducting gaps
$\delta=\Delta_{10}/\Delta_{20}$, and the temperatures of the two rings. We
demonstrate a magnetically controllable step-like response of the critical
current, which emerges even in a symmetric junction, $\delta=1$. Finally, we
discuss the optimal working conditions and the high response of the critical
current to small changes in the magnetic flux, reporting good performances of
the transducer, with a high transfer function that depends on the operating
point and the quality of the junction.",http://arxiv.org/abs/2110.10585v3
"Geometry of radio pulsar signals: The origin of pulsation modes and
  nulling",2021-10-20T16:57:21Z,J. Dyks,"Radio pulsars exhibit an enormous diversity of single pulse behaviour that
involves sudden changes in pulsation mode and nulling occurring on timescales
of tens or hundreds of spin periods. The pulsations appear both chaotic and
quasi-regular, which has hampered their interpretation for decades. Here I show
that the pseudo-chaotic complexity of single pulses is caused by the viewing of
a relatively simple radio beam that has a sector structure traceable to the
magnetospheric charge distribution. The slow ExB drift of the sector beam, when
sampled by the line of sight, produces the classical drift-period-folded
patterns known from observations. The drifting azimuthal zones of the beam
produce the changes in pulsation modes and both the intermodal and sporadic
nulling at timescales of beating between the drift and the star spin. The
axially symmetric conal beams are thus a superficial geometric illusion, and
the standard carousel model of pulsar radio beams does not apply. The beam
suggests a particle flow structure that involves inward motions with possible
inward emission.",http://arxiv.org/abs/2110.10658v1
Vortex: Extending the RISC-V ISA for GPGPU and 3D-GraphicsResearch,2021-10-21T02:39:54Z,"Blaise Tine, Fares Elsabbagh, Krishna Yalamarthy, Hyesoon Kim","The importance of open-source hardware and software has been increasing.
However, despite GPUs being one of the more popular accelerators across various
applications, there is very little open-source GPU infrastructure in the public
domain. We argue that one of the reasons for the lack of open-source
infrastructure for GPUs is rooted in the complexity of their ISA and software
stacks.In this work, we first propose an ISA extension to RISC-V that supports
GPGPUs and graphics. The main goal of the ISA extension proposal is to minimize
the ISA changes so that the corresponding changes to the open-source ecosystem
are also minimal, which makes for a sustainable development ecosystem. To
demonstrate the feasibility of the minimally extended RISC-V ISA, we
implemented the complete software and hardware stacks of Vortex on FPGA. Vortex
is a PCIe-based soft GPU that supports OpenCL and OpenGL.Vortex can be used in
a variety of applications, including machine learning, graph analytics, and
graphics rendering. Vortex can scale up to 32 cores on an Altera Stratix 10
FPGA, delivering a peak performance of 25.6 GFlops at 200 Mhz.",http://arxiv.org/abs/2110.10857v1
Brownian motion in a growing population of ballistic particles,2021-10-21T17:48:16Z,"Nathaniel V. Mon Père, Pierre de Buyl, Sophie de Buyl","We investigate the motility of a growing population of cells in a idealized
setting: we consider a system of hard disks in which new particles are added
according to prescribed growth kinetics, thereby dynamically changing the
number density. As a result, the expected Brownian motion of the hard disks is
modified. We compute the density-dependent friction of the hard disks and
insert it in an effective Langevin equation to describe the system, assuming
that the inter-collision time is smaller than the timescale of the growth. We
find that the effective Langevin description captures the changes in motility
in agreement with the simulation results. Our framework can be extended to
other systems in which the transport coefficient varies with time.",http://arxiv.org/abs/2110.11315v2
"Optimal Allocation of Virtual Inertia Devices for Enhancing Frequency
  Stability in Low-Inertia PowerSystems",2021-10-21T21:54:18Z,"Mingjian Tuo, Xingpeng Li","As renewable resources gradually replace conventional generation based
synchronous machines, the dynamics of the modern grid changes significantly and
the system synchronous inertia decreases substantially. This transformation
poses severe challenges for power system stability; for instance, it may lead
to larger initial rate of change of frequency and increase frequency
excursions. However, new opportunities also arise as novelconverter control
techniques, so-called grid-forming strategies, show higher efficiency and
faster response than conventional synchronous generators. They mainly involve
virtual inertia (VI) emulation to mimic the behavior of synchronous machines.
In this study, a state-space model for the power system network is developed
with VI as a frequency regulation method. A reduced model based-norm algorithm
(RMHA) considering the Fiedler mode impact is proposed in this paper to
optimize the allocation of VI devices and improve power system frequency
stability. Finally, case studies conducted on the IEEE 24-bus system
demonstrate the efficacy of the proposed RMHA approach.",http://arxiv.org/abs/2110.11497v2
Ultralight scalar dark matter detection with ZAIGA,2021-10-22T03:05:00Z,"Wei Zhao, Xitong Mei, Dongfeng Gao, Jin Wang, Mingsheng Zhan","ZAIGA is a proposed underground long-baseline atom interferometer (AI)
facility, aiming for experimental research on gravitation and related problems.
In this paper, we study the possibility of detecting the ultralight scalar dark
matter (DM) with ZAIGA. According to a popular scalar DM model, the DM field
contains a background oscillation term and a local exponential fluctuation
term. In order to calculate the proposed constraints on DM coupling parameters,
we need to first compute the DM signals in ZAIGA. For the case of two AIs
vertically separated by 300 meters, the DM-induced differential phase consists
of three contributions, coming from the DM-induced changes in atomic internal
energy levels, atomic masses and the gravitational acceleration. For the case
of two AIs horizontally separated by several kilometers, the signal comes from
the DM-induced changes in atomic internal energy levels. With the current and
future technical parameters of ZAIGA, we then obtain the proposed constraints
on five DM coupling parameters. It turns out that our proposed constraints
could be several orders of magnitude better than the ones set by the MICROSCOPE
space mission.",http://arxiv.org/abs/2110.11564v2
Text Counterfactuals via Latent Optimization and Shapley-Guided Search,2021-10-22T05:04:40Z,"Quintin Pope, Xiaoli Z. Fern","We study the problem of generating counterfactual text for a classifier as a
means for understanding and debugging classification. Given a textual input and
a classification model, we aim to minimally alter the text to change the
model's prediction. White-box approaches have been successfully applied to
similar problems in vision where one can directly optimize the continuous
input. Optimization-based approaches become difficult in the language domain
due to the discrete nature of text. We bypass this issue by directly optimizing
in the latent space and leveraging a language model to generate candidate
modifications from optimized latent representations. We additionally use
Shapley values to estimate the combinatoric effect of multiple changes. We then
use these estimates to guide a beam search for the final counterfactual text.
We achieve favorable performance compared to recent white-box and black-box
baselines using human and automatic evaluations. Ablation studies show that
both latent optimization and the use of Shapley values improve success rate and
the quality of the generated counterfactuals.",http://arxiv.org/abs/2110.11589v1
Game Redesign in No-regret Game Playing,2021-10-18T02:28:02Z,"Yuzhe Ma, Young Wu, Xiaojin Zhu","We study the game redesign problem in which an external designer has the
ability to change the payoff function in each round, but incurs a design cost
for deviating from the original game. The players apply no-regret learning
algorithms to repeatedly play the changed games with limited feedback. The
goals of the designer are to (i) incentivize all players to take a specific
target action profile frequently; and (ii) incur small cumulative design cost.
We present game redesign algorithms with the guarantee that the target action
profile is played in T-o(T) rounds while incurring only o(T) cumulative design
cost. Game redesign describes both positive and negative applications: a
benevolent designer who incentivizes players to take a target action profile
with better social welfare compared to the solution of the original game, or a
malicious attacker whose target action profile benefits themselves but not the
players. Simulations on four classic games confirm the effectiveness of our
proposed redesign algorithms.",http://arxiv.org/abs/2110.11763v1
"A Layer-wise Adversarial-aware Quantization Optimization for Improving
  Robustness",2021-10-23T22:11:30Z,"Chang Song, Riya Ranjan, Hai Li","Neural networks are getting better accuracy with higher energy and
computational cost. After quantization, the cost can be greatly saved, and the
quantized models are more hardware friendly with acceptable accuracy loss. On
the other hand, recent research has found that neural networks are vulnerable
to adversarial attacks, and the robustness of a neural network model can only
be improved with defense methods, such as adversarial training. In this work,
we find that adversarially-trained neural networks are more vulnerable to
quantization loss than plain models. To minimize both the adversarial and the
quantization losses simultaneously and to make the quantized model robust, we
propose a layer-wise adversarial-aware quantization method, using the Lipschitz
constant to choose the best quantization parameter settings for a neural
network. We theoretically derive the losses and prove the consistency of our
metric selection. The experiment results show that our method can effectively
and efficiently improve the robustness of quantized adversarially-trained
neural networks.",http://arxiv.org/abs/2110.12308v1
Gradient-based Quadratic Multiform Separation,2021-10-25T14:45:52Z,Wen-Teng Chang,"Classification as a supervised learning concept is an important content in
machine learning. It aims at categorizing a set of data into classes. There are
several commonly-used classification methods nowadays such as k-nearest
neighbors, random forest, and support vector machine. Each of them has its own
pros and cons, and none of them is invincible for all kinds of problems. In
this thesis, we focus on Quadratic Multiform Separation (QMS), a classification
method recently proposed by Michael Fan et al. (2019). Its fresh concept, rich
mathematical structure, and innovative definition of loss function set it apart
from the existing classification methods. Inspired by QMS, we propose utilizing
a gradient-based optimization method, Adam, to obtain a classifier that
minimizes the QMS-specific loss function. In addition, we provide suggestions
regarding model tuning through explorations of the relationships between
hyperparameters and accuracies. Our empirical result shows that QMS performs as
good as most classification methods in terms of accuracy. Its superior
performance is almost comparable to those of gradient boosting algorithms that
win massive machine learning competitions.",http://arxiv.org/abs/2110.13006v2
"Homography-based Visual Servoing with Remote Center of Motion for
  Semi-autonomous Robotic Endoscope Manipulation",2021-10-25T20:08:10Z,"Martin Huber, John Bason Mitchell, Ross Henry, Sébastien Ourselin, Tom Vercauteren, Christos Bergeles","The dominant visual servoing approaches in Minimally Invasive Surgery (MIS)
follow single points or adapt the endoscope's field of view based on the
surgical tools' distance. These methods rely on point positions with respect to
the camera frame to infer a control policy. Deviating from the dominant
methods, we formulate a robotic controller that allows for image-based visual
servoing that requires neither explicit tool and camera positions nor any
explicit image depth information. The proposed method relies on
homography-based image registration, which changes the automation paradigm from
point-centric towards surgical-scene-centric approach. It simultaneously
respects a programmable Remote Center of Motion (RCM). Our approach allows a
surgeon to build a graph of desired views, from which, once built, views can be
manually selected and automatically servoed to irrespective of robot-patient
frame transformation changes. We evaluate our method on an abdominal phantom
and provide an open source ROS Moveit integration for use with any serial
manipulator.",http://arxiv.org/abs/2110.13245v1
Ferrers functions of arbitrary degree and order and related functions,2021-10-26T10:47:04Z,P. Malits,"Numerous novel integral and series representations for Ferrers functions of
the first kind (associated Legendre functions on the cut) of arbitrary degree
and order, various integral, series and differential relations connecting
Ferrers functions of different orders and degrees as well as a uniform
asymptotic expansion are derived in this article. Simple proofs of four
generating functions for Ferrers functions are given. Addition theorems for
Ferrers functions of the argument tanh(a+b) are proved by basing on generation
functions for three families of hypergeometric polynomials. Relations for
Gegenbauer polynomials and Ferrers associated Legendre functions (associated
Legendre polynomials) are obtained as special cases.",http://arxiv.org/abs/2110.13564v3
"Emotion recognition in talking-face videos using persistent entropy and
  neural networks",2021-10-26T11:08:56Z,"Eduardo Paluzo-Hidalgo, Guillermo Aguirre-Carrazana, Rocio Gonzalez-Diaz","The automatic recognition of a person's emotional state has become a very
active research field that involves scientists specialized in different areas
such as artificial intelligence, computer vision or psychology, among others.
Our main objective in this work is to develop a novel approach, using
persistent entropy and neural networks as main tools, to recognise and classify
emotions from talking-face videos. Specifically, we combine audio-signal and
image-sequence information to compute a topology signature(a 9-dimensional
vector) for each video. We prove that small changes in the video produce small
changes in the signature. These topological signatures are used to feed a
neural network to distinguish between the following emotions: neutral, calm,
happy, sad, angry, fearful, disgust, and surprised. The results reached are
promising and competitive, beating the performance reached in other
state-of-the-art works found in the literature.",http://arxiv.org/abs/2110.13571v1
"MEKF Ignoring Initial Conditions for Attitude Estimation Using Vector
  Observations",2021-10-26T12:58:33Z,Lubin Chang,"In this paper, the well-known multiplicative extended Kalman filter (MEKF) is
re-investigated for attitude estimation using vector observations. From the Lie
group theory, it is shown that the attitude estimation model is group affine
and its error state model should be trajectory-independent. Moreover, with such
trajectory-independent error state model, the linear Kalman filter is still
effective for large initialization errors. However, the measurement model of
the traditional MEKF is dependent on the attitude prediction, which is
therefore trajectory-dependent. This is also the main reason why the
performance of traditional MEKF is degraded for large initialization errors.
Through substitution of the attitude prediction related term with the vector
observation in body frame, a trajectory-independent measurement model is
derived for MEKF. Meanwhile, the MEKFs with reference attitude error definition
and with global state formulating on special Euclidean group have also been
studied, with main focus on derivation of the trajectory-independent
measurement models. Extensive Monte Carlo simulations and field test of
attitude estimation implementations demonstrate that the performance of MEKFs
can be much improved with trajectory-independent measurement models.",http://arxiv.org/abs/2110.13666v1
Dynamic Trace Estimation,2021-10-26T15:03:32Z,"Prathamesh Dharangutte, Christopher Musco","We study a dynamic version of the implicit trace estimation problem. Given
access to an oracle for computing matrix-vector multiplications with a
dynamically changing matrix A, our goal is to maintain an accurate
approximation to A's trace using as few multiplications as possible. We present
a practical algorithm for solving this problem and prove that, in a natural
setting, its complexity is quadratically better than the standard solution of
repeatedly applying Hutchinson's stochastic trace estimator. We also provide an
improved algorithm assuming slightly stronger assumptions on the dynamic matrix
A. We support our theory with empirical results, showing significant
computational improvements on three applications in machine learning and
network science: tracking moments of the Hessian spectral density during neural
network optimization, counting triangles, and estimating natural connectivity
in a dynamically changing graph.",http://arxiv.org/abs/2110.13752v1
"Finding the Best Partitioning Policy for Efficient Verification of
  Autonomous Systems at Runtime",2021-10-26T21:34:05Z,"Melika Dastranj, Mehran Alidoost Nia, Mehdi Kargahi","The autonomous systems need to decide how to react to the changes at runtime
efficiently. The ability to rigorously analyze the environment and the system
together is theoretically possible by the model-driven approaches; however, the
model size and timing limitations are two significant obstacles against such an
autonomous decision-making process. To tackle this issue, the incremental
approximation technique can be used to partition the model and only verify a
partition if it is affected by the change. This paper proposes a policy-based
analysis approach that finds the best partitioning policy among a set of
available policies based on two proposed metrics, namely Balancing and
Variation. The metrics quantitatively evaluate the generated components from
the incremental approximation scheme according to their size and frequency. We
investigate the validity of the approach both theoretically and experimentally
via a case study on energy harvesting systems. The results confirm the
effectiveness of the proposed approach.",http://arxiv.org/abs/2110.14040v1
Temporal Knowledge Distillation for On-device Audio Classification,2021-10-27T02:29:54Z,"Kwanghee Choi, Martin Kersner, Jacob Morton, Buru Chang","Improving the performance of on-device audio classification models remains a
challenge given the computational limits of the mobile environment. Many
studies leverage knowledge distillation to boost predictive performance by
transferring the knowledge from large models to on-device models. However, most
lack a mechanism to distill the essence of the temporal information, which is
crucial to audio classification tasks, or similar architecture is often
required. In this paper, we propose a new knowledge distillation method
designed to incorporate the temporal knowledge embedded in attention weights of
large transformer-based models into on-device models. Our distillation method
is applicable to various types of architectures, including the
non-attention-based architectures such as CNNs or RNNs, while retaining the
original network architecture during inference. Through extensive experiments
on both an audio event detection dataset and a noisy keyword spotting dataset,
we show that our proposed method improves the predictive performance across
diverse on-device architectures.",http://arxiv.org/abs/2110.14131v2
Angular-spectrum-dependent interference,2021-10-27T02:30:39Z,"Chen Yang, Zhi-Yuan Zhou, Yan Li, Shi-Kai Liu, Zheng Ge, Guang-Can Guo, Bao-Sen Shi","Optical interference is not only a fundamental phenomenon that has enabled
new theories of light to be derived but it has also been used in interferometry
for the measurement of small displacements, refractive index changes and
surface irregularities. In a two-beam interferometer, variations in the
interference fringes are used as a diagnostic for anything that causes the
optical path difference (OPD) to change; therefore, for a specified OPD,
greater variation in the fringes indicates better measurement sensitivity.
Here, we introduce and experimentally validate an interesting optical
interference phenomenon that uses photons with a structured frequency-angular
spectrum, which are generated from a spontaneous parametric down-conversion
process in a nonlinear crystal. This interference phenomenon is manifested as
interference fringes that vary much more rapidly with increasing OPD than the
corresponding fringes for equal-inclination interference; the phenomenon is
parameterised using an equivalent wavelength, which under our experimental
conditions is 29.38 nm or about 1/27 of the real wavelength. This phenomenon
not only enriches the knowledge with regard to optical interference but also
offers promise for applications in interferometry.",http://arxiv.org/abs/2110.14132v1
"Detection of Molecular Transitions with Nitrogen-Vacancy Centers and
  Electron-Spin Labels",2021-10-27T08:14:02Z,"C. Munuera-Javaloy, R. Puebla, B. D'Anjou, M. B. Plenio, J. Casanova","We present a protocol that detects molecular conformational changes with two
nitroxide electron-spin labels and a nitrogen-vacancy (NV) center in diamond.
More specifically, we demonstrate that the NV can detect energy shifts induced
by the coupling between electron-spin labels. The protocol relies on the
judicious application of microwave and radiofrequency pulses in a range of
parameters that ensures stable nitroxide resonances. Furthermore, we
demonstrate that our scheme is optimized by using nitroxides with distinct
nitrogen isotopes. We use detailed numerical simulations and Bayesian inference
techniques to demonstrate that our method enables the detection of
conformational changes under realistic conditions including strong NV dephasing
rates as a consequence of the diamond surface proximity and nitroxide
thermalization mechanisms. Finally, we show that random molecular tumbling can
be exploited to extract the inter-label distance.",http://arxiv.org/abs/2110.14255v2
"Magnetoconductivity of a metal with closed Fermi surface reconstructed
  by a biaxial density wave",2021-10-27T08:40:08Z,"A. M. Kadigrobov, B. Keran, D. Radić","We investigate quantum dynamics and kinetics of a 2D conductor with closed
Fermi surface reconstructed by a biaxial density wave, in which electrons move
along a two-dimensional periodic net of semiclassical trajectories coupled by
the magnetic breakdown tunnelling under a strong magnetic field. We derive a
quasi-particle dispersion law and magnetoconductivity tensor. The
quasi-particle spectrum is found to be the alternating series of
two-dimensional magnetic energy bands with gaps between them. The longitudinal
magnetoconductivity shows giant oscillations with change of magnetic field,
while the Hall coefficient changes sign and is absent in a wide range of the
magnetic fields in between. Preliminary estimations show that the suggested
magnetoconductivity mechanism may be the origin of such behaviour of the Hall
coefficient vs. magnetic field, as observed in experiments in materials with
analogous topology of the Fermi surface, such as the high-Tc superconducting
cuprates.",http://arxiv.org/abs/2110.14265v1
"Transfer learning with causal counterfactual reasoning in Decision
  Transformers",2021-10-27T11:23:27Z,"Ayman Boustati, Hana Chockler, Daniel C. McNamee","The ability to adapt to changes in environmental contingencies is an
important challenge in reinforcement learning. Indeed, transferring previously
acquired knowledge to environments with unseen structural properties can
greatly enhance the flexibility and efficiency by which novel optimal policies
may be constructed. In this work, we study the problem of transfer learning
under changes in the environment dynamics. In this study, we apply causal
reasoning in the offline reinforcement learning setting to transfer a learned
policy to new environments. Specifically, we use the Decision Transformer (DT)
architecture to distill a new policy on the new environment. The DT is trained
on data collected by performing policy rollouts on factual and counterfactual
simulations from the source environment. We show that this mechanism can
bootstrap a successful policy on the target environment while retaining most of
the reward.",http://arxiv.org/abs/2110.14355v1
"Learning where to learn: Gradient sparsity in meta and continual
  learning",2021-10-27T12:54:36Z,"Johannes von Oswald, Dominic Zhao, Seijin Kobayashi, Simon Schug, Massimo Caccia, Nicolas Zucchet, João Sacramento","Finding neural network weights that generalize well from small datasets is
difficult. A promising approach is to learn a weight initialization such that a
small number of weight changes results in low generalization error. We show
that this form of meta-learning can be improved by letting the learning
algorithm decide which weights to change, i.e., by learning where to learn. We
find that patterned sparsity emerges from this process, with the pattern of
sparsity varying on a problem-by-problem basis. This selective sparsity results
in better generalization and less interference in a range of few-shot and
continual learning problems. Moreover, we find that sparse learning also
emerges in a more expressive model where learning rates are meta-learned. Our
results shed light on an ongoing debate on whether meta-learning can discover
adaptable features and suggest that learning by sparse gradient descent is a
powerful inductive bias for meta-learning systems.",http://arxiv.org/abs/2110.14402v1
Time variation of the atmospheric neutrino flux at dark matter detectors,2021-10-27T19:20:54Z,"Yi Zhuang, Louis E. Strigari, Rafael F. Lang","The cosmic ray flux at the lowest energies, $\lesssim 10$ GeV, is modulated
by the solar cycle, inducing a time variation that is expected to carry over
into the atmospheric neutrino flux at these energies. Here we estimate this
time variation of the atmospheric neutrino flux at five prospective underground
locations for multi-tonne scale dark matter detectors (CJPL, Kamioka, LNGS,
SNOlab and SURF). We find that between solar minimum and solar maximum, the
normalization of the flux changes by $\sim 30\%$ at a high-latitude location
such as SURF, while it changes by a smaller amount, $\lesssim 10\%$, at LNGS. A
dark matter detector that runs for a period extending through solar cycles will
be most effective at identifying this time variation. This opens the
possibility to distinguish such neutrino-induced nuclear recoils from dark
matter-induced nuclear recoils, thus allowing for the possibility of using
timing information to break through the ""neutrino floor.""",http://arxiv.org/abs/2110.14723v1
Dynamic Review-based Recommenders,2021-10-27T20:17:47Z,"Kostadin Cvejoski, Ramses J. Sanchez, Christian Bauckhage, Cesar Ojeda","Just as user preferences change with time, item reviews also reflect those
same preference changes. In a nutshell, if one is to sequentially incorporate
review content knowledge into recommender systems, one is naturally led to
dynamical models of text. In the present work we leverage the known power of
reviews to enhance rating predictions in a way that (i) respects the causality
of review generation and (ii) includes, in a bidirectional fashion, the ability
of ratings to inform language review models and vice-versa, language
representations that help predict ratings end-to-end. Moreover, our
representations are time-interval aware and thus yield a continuous-time
representation of the dynamics. We provide experiments on real-world datasets
and show that our methodology is able to outperform several state-of-the-art
models. Source code for all models can be found at [1].",http://arxiv.org/abs/2110.14747v2
Extracting Expert's Goals by What-if Interpretable Modeling,2021-10-28T14:41:06Z,"Chun-Hao Chang, George Alexandru Adam, Rich Caruana, Anna Goldenberg","Although reinforcement learning (RL) has tremendous success in many fields,
applying RL to real-world settings such as healthcare is challenging when the
reward is hard to specify and no exploration is allowed. In this work, we focus
on recovering clinicians' rewards in treating patients. We incorporate the
what-if reasoning to explain the clinician's treatments based on their
potential future outcomes. We use generalized additive models (GAMs) - a class
of accurate, interpretable models - to recover the reward. In both simulation
and a real-world hospital dataset, we show our model outperforms baselines.
Finally, our model's explanations match several clinical guidelines when
treating patients while we found the commonly-used linear model often
contradicts them.",http://arxiv.org/abs/2110.15165v3
Passage of heavy quarks through the fluctuating hot QCD medium,2021-01-01T05:13:16Z,"Mohammad Yousuf Jamal, Bedangadas Mohanty","The change in the energy of the moving heavy (charm and bottom) quarks due to
field fluctuations present in the hot QCD medium has been studied. A finite
quark chemical potential has been considered while modeling the hot QCD medium
counting the fact that the upcoming experimental facilities such as Anti-proton
and Ion Research (FAIR) and Nuclotron-based Ion Collider fAcility (NICA) are
expected to operate at finite baryon density and moderate temperature. The
effective kinetic theory approach has been adopted where the collisions have
been incorporated using the well defined collisional kernel, known as
Bhatnagar-Gross-Krook (BGK). To incorporate the non-ideal equations of state
(EoSs) effects/ medium interaction effects, an extended effective fugacity
model has been adopted. The momentum dependence of the energy change due to
fluctuation for the charm and bottom quark has been investigated at different
values of collision frequency and chemical potential. The results are exciting
as the heavy quarks are found to gain energy due to fluctuations while moving
through the produced medium at finite chemical potential and collision
frequency.",http://arxiv.org/abs/2101.00164v2
Declarative Dashboard Generation,2021-01-01T17:26:44Z,"Alessandro Tundo, Chiara Castelnovo, Marco Mobilio, Oliviero Riganelli, Leonardo Mariani","Systems of systems are highly dynamic software systems that require flexible
monitoring solutions to be observed and controlled. Indeed, operators have to
frequently adapt the set of collected indicators according to changing
circumstances, to visualize the behavior of the monitored systems and timely
take actions, if needed. Unfortunately, dashboard systems are still quite
cumbersome to configure and adapt to a changing set of indicators that must be
visualized. This paper reports our initial effort towards the definition of an
automatic dashboard generation process that exploits metamodel layouts to
create a full dashboard from a set of indicators selected by operators.",http://arxiv.org/abs/2101.00274v1
Quotient Maps and Configuration Spaces of Hard Disks,2021-01-04T05:17:43Z,"O. B. Ericok, J. K. Mason","Hard disks systems are often considered as prototypes for simple fluids. In a
statistical mechanics context, the hard disk configuration space is generally
quotiented by the action of various symmetry groups. The changes in the
topological and geometric properties of the configuration spaces effected by
such quotient maps are studied for small numbers of disks on a square and
hexagonal torus. A metric is defined on the configuration space and the various
quotient spaces that respects the desired symmetries. This is used to construct
explicit triangulations of the configuration spaces as $\alpha$-complexes.
Critical points in a configuration space are associated with changes in the
topology as a function of disk radius, are conjectured to be related to the
configurational entropy of glassy systems, and could reveal the origins of
phase transitions in other systems. The number and topological and geometric
properties of the critical points are found to depend on the symmetries by
which the configuration space is quotiented.",http://arxiv.org/abs/2101.00780v2
GeCo: Quality Counterfactual Explanations in Real Time,2021-01-05T00:23:58Z,"Maximilian Schleich, Zixuan Geng, Yihong Zhang, Dan Suciu","Machine learning is increasingly applied in high-stakes decision making that
directly affect people's lives, and this leads to an increased demand for
systems to explain their decisions. Explanations often take the form of
counterfactuals, which consists of conveying to the end user what she/he needs
to change in order to improve the outcome. Computing counterfactual
explanations is challenging, because of the inherent tension between a rich
semantics of the domain, and the need for real time response. In this paper we
present GeCo, the first system that can compute plausible and feasible
counterfactual explanations in real time. At its core, GeCo relies on a genetic
algorithm, which is customized to favor searching counterfactual explanations
with the smallest number of changes. To achieve real-time performance, we
introduce two novel optimizations: $\Delta$-representation of candidate
counterfactuals, and partial evaluation of the classifier. We compare
empirically GeCo against five other systems described in the literature, and
show that it is the only system that can achieve both high quality explanations
and real time answers.",http://arxiv.org/abs/2101.01292v3
"Tunable Single-Ion Anisotropy in Spin-1 Models Realized with Ultracold
  Atoms",2021-01-05T02:05:24Z,"Woo Chang Chung, Julius de Hond, Jinggang Xiang, Enid Cruz-Colón, Wolfgang Ketterle","Mott insulator plateaus in optical lattices are a versatile platform to study
spin physics. Using sites occupied by two bosons with an internal degree of
freedom, we realize a uniaxial single-ion anisotropy term proportional to
$(S^z)^2$, which plays an important role in stabilizing magnetism for
low-dimensional magnetic materials. Here we explore non-equilibrium spin
dynamics and observe a resonant effect in the spin anisotropy as a function of
lattice depth when exchange coupling and on-site anisotropy are similar. Our
results are supported by many-body numerical simulations and are captured by
the analytical solution of a two-site model.",http://arxiv.org/abs/2101.01316v1
Collisions Between Ultracold Molecules and Atoms in a Magnetic Trap,2021-01-05T15:18:44Z,"S. Jurgilas, A. Chakraborty, C. J. H. Rich, L. Caldwell, H. J. Williams, N. J. Fitch, B. E. Sauer, Matthew D. Frye, Jeremy M. Hutson, M. R. Tarbutt","We prepare mixtures of ultracold CaF molecules and Rb atoms in a magnetic
trap and study their inelastic collisions. When the atoms are prepared in the
spin-stretched state and the molecules in the spin-stretched component of the
first rotationally excited state, they collide inelastically with a rate
coefficient of $k_2 = (6.6 \pm 1.5) \times 10^{-11}$ cm$^{3}$/s at temperatures
near 100~$\mu$K. We attribute this to rotation-changing collisions. When the
molecules are in the ground rotational state we see no inelastic loss and set
an upper bound on the spin relaxation rate coefficient of $k_2 < 5.8 \times
10^{-12}$ cm$^{3}$/s with 95% confidence. We compare these measurements to the
results of a single-channel loss model based on quantum defect theory. The
comparison suggests a short-range loss parameter close to unity for
rotationally excited molecules, but below 0.04 for molecules in the rotational
ground state.",http://arxiv.org/abs/2101.01580v2
"Label Augmentation via Time-based Knowledge Distillation for Financial
  Anomaly Detection",2021-01-05T18:24:13Z,"Hongda Shen, Eren Kursun","Detecting anomalies has become increasingly critical to the financial service
industry. Anomalous events are often indicative of illegal activities such as
fraud, identity theft, network intrusion, account takeover, and money
laundering. Financial anomaly detection use cases face serious challenges due
to the dynamic nature of the underlying patterns especially in adversarial
environments such as constantly changing fraud tactics. While retraining the
models with the new patterns is absolutely essential; keeping up with the rapid
changes introduces other challenges as it moves the model away from older
patterns or continuously grows the size of the training data. The resulting
data growth is hard to manage and it reduces the agility of the models'
response to the latest attacks. Due to the data size limitations and the need
to track the latest patterns, older time periods are often dropped in practice,
which in turn, causes vulnerabilities. In this study, we propose a label
augmentation approach to utilize the learning from older models to boost the
latest. Experimental results show that the proposed approach provides a
significant reduction in training time, while providing potential performance
improvement.",http://arxiv.org/abs/2101.01689v1
Reactive mixtures with the lattice Boltzmann model,2021-01-05T18:46:48Z,"N. Sawant, B. Dorschner, I. V. Karlin","A new lattice Boltzmann model for reactive ideal gas mixtures is presented.
The model is an extension to reactive flows of the recently proposed
multi-component lattice Boltzmann model for compressible ideal gas mixtures
with Stefan-Maxwell diffusion for species interaction. First, the kinetic model
for the Stefan--Maxwell diffusion is enhanced to accommodate a source term
accounting the change of the mixture composition due to chemical reaction.
Second, by including the heat of formation in the energy equation, the
thermodynamic consistency of the underlying compressible lattice Boltzmann
model for momentum and energy allows a realization of the energy and
temperature change due to chemical reactions. This obviates the need for ad-hoc
modelling with source terms for temperature or heat. Both parts remain
consistently coupled through mixture composition, momentum, pressure, energy
and enthalpy. The proposed model uses the standard three-dimensional lattices
and is validated with a set of benchmarks including laminar burning speed in
the hydrogen-air mixture and circular expanding premixed flame.",http://arxiv.org/abs/2101.01702v1
"User Ex Machina : Simulation as a Design Probe in Human-in-the-Loop Text
  Analytics",2021-01-06T19:44:11Z,"Anamaria Crisan, Michael Correll","Topic models are widely used analysis techniques for clustering documents and
surfacing thematic elements of text corpora. These models remain challenging to
optimize and often require a ""human-in-the-loop"" approach where domain experts
use their knowledge to steer and adjust. However, the fragility,
incompleteness, and opacity of these models means even minor changes could
induce large and potentially undesirable changes in resulting model. In this
paper we conduct a simulation-based analysis of human-centered interactions
with topic models, with the objective of measuring the sensitivity of topic
models to common classes of user actions. We find that user interactions have
impacts that differ in magnitude but often negatively affect the quality of the
resulting modelling in a way that can be difficult for the user to evaluate. We
suggest the incorporation of sensitivity and ""multiverse"" analyses to topic
model interfaces to surface and overcome these deficiencies.",http://arxiv.org/abs/2101.02244v1
"Monitoring of Railpad Long-term Condition in Turnouts Using Extreme
  Value Distributions",2021-01-07T14:45:49Z,"Pegah Barkhordari, Roberto Galeazzi, Mogens Blanke","The railpad is a key element in railway infrastructures that plays an
essential role in the train-track dynamics. Presence of worn or defective
railpads along railway track may lead to large wheel/rail interaction forces,
and a high rate of deterioration for track components. Despite the importance
of railpad, the track infrastructure managers use no inspection tool for
monitoring in-service railpads over time. In this paper, a novel data-driven
monitoring tool for long-term performance analysis of in-service railpads is
developed based on train-induced vibration data collected by a track-side
measurement system. The monitoring tool consists of a method for track
resonance frequencies estimation, a temperature-frequency model for describing
railpad behavior with respect to ambient temperature, and a generalized
likelihood ratio test based on the generalized extreme value distribution for
detecting changes in the railpad status over time. To evaluate the performance
of the proposed monitoring system, the status of railpads at four different
locations along a railway turnout is monitored over a period of 18 months. It
is shown that the monitoring system can successfully detect changes in railpad
properties over the considered period.",http://arxiv.org/abs/2101.02567v1
Motion Tomography via Occupation Kernels,2021-01-07T18:38:05Z,"Benjamin P. Russo, Rushikesh Kamalapurkar, Dongsik Chang, Joel A. Rosenfeld","The goal of motion tomography is to recover a description of a vector flow
field using information on the trajectory of a sensing unit. In this paper, we
develop a predictor corrector algorithm designed to recover vector flow fields
from trajectory data with the use of occupation kernels developed by Rosenfeld
et al.. Specifically, we use the occupation kernels as an adaptive basis; that
is, the trajectories defining our occupation kernels are iteratively updated to
improve the estimation on the next stage. Initial estimates are established,
then under mild assumptions, such as relatively straight trajectories,
convergence is proven using the Contraction Mapping Theorem. We then compare to
the established method by Chang et al. by defining a set of error metrics. We
found that for simulated data, which provides a ground truth, our method offers
a marked improvement and that for a real-world example we have similar results
to the established method.",http://arxiv.org/abs/2101.02677v2
Entropic bounds on information backflow,2021-01-07T19:00:30Z,"Nina Megier, Andrea Smirne, Bassano Vacchini","In the dynamics of open quantum systems, the backflow of information to the
reduced system under study has been suggested as the actual physical mechanism
inducing memory and thus leading to non-Markovian quantum dynamics. To this
aim, the trace-distance or Bures-distance revivals between distinct evolved
system states have been shown to be subordinated to the establishment of
system-environment correlations or changes in the environmental state. We show
that this interpretation can be substantiated also for a class of entropic
quantifiers. We exploit a suitably regularized version of Umegaki's quantum
relative entropy, known as telescopic relative entropy, that is tightly
connected to the quantum Jensen-Shannon divergence. In particular, we derive
general upper bounds on the telescopic relative entropy revivals conditioned
and determined by the formation of correlations and changes in the environment.
We illustrate our findings by means of examples, considering the
Jaynes-Cummings model and a two-qubit dynamics.",http://arxiv.org/abs/2101.02720v1
"Cumulants and factorial cumulants in the 3-dimensional Ising
  universality class",2021-01-08T01:54:32Z,"Xue Pan, Mingmei Xu, Yuanfang Wu","The high-order cumulants and factorial cumulants of conserved charges are
suggested to study the critical dynamics in heavy ion collisions. In this
paper, using parametric representation of the 3-dimensional Ising model, the
sign distribution on the phase diagram and temperature dependence of the
cumulants and factorial cumulants is studied and compared. In the vicinity of
the critical point, the cumulants and factorial cumulants can not be
distinguished. Far away from the critical point, sign changes occur in the
factorial cumulants comparing with the same order cumulants. The cause of these
sign changes is analysed. They may be used to measure the distance to the
critical point.",http://arxiv.org/abs/2101.02822v2
Optical-Cavity-Induced Current,2021-01-08T16:23:00Z,"Garret Moddel, Ayendra Weerakkody, David Doroski, Dylan Bartusiak","The formation of a submicron optical cavity on one side of a
metal-insulator-metal (MIM) tunneling device induces a measurable electrical
current between the two metal layers with no applied voltage. Reducing the
cavity thickness increases the measured current. Eight types of tests were
carried out to determine whether the output could be due to experimental
artifacts. All gave negative results, supporting the conclusion that the
observed electrical output is genuinely produced by the device. We interpret
the results as being due to the suppression of vacuum optical modes by the
optical cavity on one side of the MIM device, which upsets a balance in the
injection of electrons excited by zero-point fluctuations. This interpretation
is in accord with observed changes in electrical output as other device
parameters are varied. A feature of the MIM devices is their femtosecond-fast
transport and scattering times for hot charge carriers. The fast capture in
these devices is consistent with a model in which an energy {\Delta}E may be
accessed from zero-point fluctuations for a time {\Delta}t, following a
{\Delta}E{\Delta}t uncertainty-principle-like relation governing the process.",http://arxiv.org/abs/2101.03085v2
"Market Making with Stochastic Liquidity Demand: Simultaneous Order
  Arrival and Price Change Forecasts",2021-01-08T16:24:23Z,"Agostino Capponi, José E. Figueroa-López, Chuyi Yu","We provide an explicit characterization of the optimal market making strategy
in a discrete-time Limit Order Book (LOB). In our model, the number of filled
orders during each period depends linearly on the distance between the
fundamental price and the market maker's limit order quotes, with random slope
and intercept coefficients. The high-frequency market maker (HFM) incurs an
end-of-the-day liquidation cost resulting from linear price impact. The optimal
placement strategy incorporates in a novel and parsimonious way forecasts about
future changes in the asset's fundamental price. We show that the randomness in
the demand slope reduces the inventory management motive, and that a positive
correlation between demand slope and investors' reservation prices leads to
wider spreads. Our analysis reveals that the simultaneous arrival of buy and
sell market orders (i) reduces the shadow cost of inventory, (ii) leads the HFM
to reduce price pressures to execute larger flows, and (iii) introduces
patterns of nonlinearity in the intraday dynamics of bid and ask spreads. Our
empirical study shows that the market making strategy outperforms those which
ignores randomness in demand, simultaneous arrival of buy and sell market
orders, and local drift in the fundamental price.",http://arxiv.org/abs/2101.03086v1
Torsors in super-symmetry,2021-01-10T03:00:49Z,"Akira Masuoka, Takuya Oe, Yuta Takahashi","Torsors under affine groups are generalized in the super context by
super-torsors under affine super-groups. We investigate those super-torsors by
using Hopf-algebra language and techniques. It is explicitly shown, under
suitable assumptions, that every super-torsor arises from an ordinary torsor.
Especially, the objects with affinity restriction, or namely, the affine
super-torsors and the affine ordinary torsors are shown to be precisely in
one-to-one correspondence. The results play substantial roles in ongoing
construction of super-symmetric Picard-Vessiot theory.",http://arxiv.org/abs/2101.03461v5
"Equivalence between module categories over quiver Hecke algebras and
  Hernandez-Leclerc's categories in general types",2021-01-10T16:01:30Z,Katsuyuki Naoi,"We prove in full generality that the generalized quantum affine Schur-Weyl
duality functor, introduced by Kang-Kashiwara-Kim, gives an equivalence between
the category of finite-dimensional modules over a quiver Hecke algebra and a
certain full subcategory of finite-dimensional modules over a quantum affine
algebra which is a generalization of the Hernandez-Leclerc's category
$\mathcal{C}_Q$. This was previously proved in untwisted $ADE$ types by Fujita
using the geometry of quiver varieties, which is not applicable in general. Our
proof is purely algebraic, and so can be extended uniformly to general types.",http://arxiv.org/abs/2101.03573v3
"Non-volatile programmable silicon photonics using an ultralow loss
  Sb$_2$Se$_3$ phase change material",2021-01-10T20:20:06Z,"Matthew Delaney, Ioannis Zeimpekis, Han Du, Xingzhao Yan, Mehdi Banakar, David J. Thomson, Daniel W. Hewak, Otto L. Muskens","Adaptable, reconfigurable and programmable are key functionalities for the
next generation of silicon-based photonic processors, neural and quantum
networks. Phase change technology offers proven non-volatile electronic
programmability, however the materials used to date have shown prohibitively
high optical losses which are incompatible with integrated photonic platforms.
Here, we demonstrate the capability of the previously unexplored material
Sb$_2$Se$_3$ for ultralow-loss programmable silicon photonics. The favorable
combination of large refractive index contrast and ultralow losses seen in
Sb$_2$Se$_3$ facilitates an unprecedented optical phase control exceeding
10$\pi$ radians in a Mach-Zehnder interferometer. To demonstrate full control
over the flow of light, we introduce nanophotonic digital patterning as a
conceptually new approach at a footprint orders of magnitude smaller than state
of the art interferometer meshes. Our approach enables a wealth of
possibilities in high-density reconfiguration of optical functionalities on
silicon chip.",http://arxiv.org/abs/2101.03623v1
Active elastocapillarity in soft solids with negative surface tension,2021-01-11T16:28:30Z,"Jack Binysh, Thomas R. Wilks, Anton Souslov","Active solids consume energy to allow for actuation, shape change, and wave
propagation not possible in equilibrium. Whereas active interfaces have been
realized across many experimental systems, control of three-dimensional (3D)
bulk materials remains a challenge. Here, we develop continuum theory and
microscopic simulations that describe a 3D soft solid whose boundary
experiences active surface stresses. The competition between active boundary
and elastic bulk yields a broad range of previously unexplored phenomena, which
are demonstrations of so-called active elastocapillarity. In contrast to thin
shells and vesicles, we discover that bulk 3D elasticity controls snap-through
transitions between different anisotropic shapes. These transitions meet at a
critical point, allowing a universal classification via Landau theory. The
active surface modifies elastic wave propagation to allow zero, or even
negative, group velocities. These phenomena offer robust principles for
programming shape change and functionality into active solids, from robotic
metamaterials down to shape-shifting nanoparticles.",http://arxiv.org/abs/2101.04006v2
"Complexity analysis of Bayesian learning of high-dimensional DAG models
  and their equivalence classes",2021-01-11T18:27:59Z,"Quan Zhou, Hyunwoong Chang","Structure learning via MCMC sampling is known to be very challenging because
of the enormous search space and the existence of Markov equivalent DAGs.
Theoretical results on the mixing behavior are lacking. In this work, we prove
the rapid mixing of a random walk Metropolis-Hastings algorithm, which reveals
that the complexity of Bayesian learning of sparse equivalence classes grows
only polynomially in $n$ and $p$, under some high-dimensional assumptions. A
series of high-dimensional consistency results is obtained, including the
strong selection consistency of an empirical Bayes model for structure
learning. Our proof is based on two new results. First, we derive a general
mixing time bound on finite state spaces, which can be applied to local MCMC
schemes for other model selection problems. Second, we construct
high-probability search paths on the space of equivalence classes with node
degree constraints by proving a combinatorial property of DAG comparisons.
Simulation studies on the proposed MCMC sampler are conducted to illustrate the
main theoretical findings.",http://arxiv.org/abs/2101.04084v3
From Tinkering to Engineering: Measurements in Tensorflow Playground,2021-01-11T19:06:44Z,"Henrik Hoeiness, Axel Harstad, Gerald Friedland","In this article, we present an extension of the Tensorflow Playground, called
Tensorflow Meter (short TFMeter). TFMeter is an interactive neural network
architecting tool that allows the visual creation of different architectures of
neural networks. In addition to its ancestor, the playground, our tool shows
information-theoretic measurements while constructing, training, and testing
the network. As a result, each change results in a change in at least one of
the measurements, providing for a better engineering intuition of what
different architectures are able to learn. The measurements are derived from
various places in the literature. In this demo, we describe our web application
that is available online at http://tfmeter.icsi.berkeley.edu/ and argue that in
the same way that the original Playground is meant to build an intuition about
neural networks, our extension educates users on available measurements, which
we hope will ultimately improve experimental design and reproducibility in the
field.",http://arxiv.org/abs/2101.04141v1
"Challenges and approaches to time-series forecasting in data center
  telemetry: A Survey",2021-01-11T22:36:21Z,"Shruti Jadon, Jan Kanty Milczek, Ajit Patankar","Time-series forecasting has been an important research domain for so many
years. Its applications include ECG predictions, sales forecasting, weather
conditions, even COVID-19 spread predictions. These applications have motivated
many researchers to figure out an optimal forecasting approach, but the
modeling approach also changes as the application domain changes. This work has
focused on reviewing different forecasting approaches for telemetry data
predictions collected at data centers. Forecasting of telemetry data is a
critical feature of network and data center management products. However, there
are multiple options of forecasting approaches that range from a simple linear
statistical model to high capacity deep learning architectures. In this paper,
we attempted to summarize and evaluate the performance of well known time
series forecasting techniques. We hope that this evaluation provides a
comprehensive summary to innovate in forecasting approaches for telemetry data.",http://arxiv.org/abs/2101.04224v2
Droplet Splashing on Rough Surfaces,2021-01-13T14:31:47Z,"T. C. de Goede, K. G. de Bruin, N. Shahidzadeh, D. Bonn","When a droplet hits a surface fast enough, droplet splashing can occur:
smaller secondary droplets detach from the main droplet during impact. While
droplet splashing on smooth surfaces is by now well understood, the surface
roughness also affects at which impact velocity a droplet splashes. In this
study, the influence of the surface roughness on droplet splashing is
investigated. By changing the root mean square roughness of the impacted
surface, we show that the droplet splashing velocity is only affected when the
droplet roughness is large enough to disrupt the spreading droplet lamella and
change the droplet splashing mechanism from corona to prompt splashing.
Finally, using Weber and Ohnesorge number scaling models, we also show that the
measured splashing velocity for both water and ethanol on surfaces with
different roughness and water-ethanol mixtures collapse onto a single curve,
showing that the droplet splashing velocity on rough surfaces scales with the
Ohnesorge number defined with the surface roughness length scale.",http://arxiv.org/abs/2101.05096v1
"On singular Hilbert schemes of points: local structures and tautological
  sheaves",2021-01-13T17:58:49Z,Xiaowen Hu,"We show an intrinsic version of Thomason's fixed point theorem. Then we
determine the local structure of the Hilbert scheme of $\leq 7$ points in
$\mathbb{A}^3$. In particular, we show that in these cases the points with the
same extra dimension have the same singularity type. Using these results we
compute the equivariant Hilbert functions at the singularities and verify a
conjecture of Zhou on the Euler characteristics of tautological sheaves on
Hilbert schemes of points on $\mathbb{P}^3$ for $\leq 6$ points.",http://arxiv.org/abs/2101.05236v5
"Tunable quantum two-photon interference with reconfigurable metasurfaces
  using phase-change materials",2021-01-14T04:26:34Z,"Nooshin M. Estakhri, Theodore B. Norris","The ability of phase-change materials to reversibly and rapidly switch
between two stable phases has driven their use in a number of applications such
as data storage and optical modulators. Incorporating such materials into
metasurfaces enables new approaches to the control of optical fields. In this
article we present the design of novel switchable metasurfaces that enable the
control of the nonclassical two-photon quantum interference. These structures
require no static power consumption, operate at room temperature, and have high
switching speed. For the first adaptive metasurface presented in this article,
tunable nonclassical two-photon interference from -97.7% (anti-coalescence) to
75.48% (coalescence) is predicted. For the second adaptive geometry, the
quantum interference switches from -59.42% (anti-coalescence) to 86.09%
(coalescence) upon a thermally driven crystallographic phase transition. The
development of compact and rapidly controllable quantum devices is opening up
promising paths to brand-new quantum applications as well as the possibility of
improving free space quantum logic gates, linear-optics bell experiments, and
quantum phase estimation systems.",http://arxiv.org/abs/2101.05454v1
Integrative Learning for Population of Dynamic Networks with Covariates,2021-01-14T10:29:08Z,"Suprateek Kundu, Jin Ming, Joe Nocera, Keith M. McGregor","Although there is a rapidly growing literature on dynamic connectivity
methods, the primary focus has been on separate network estimation for each
individual, which fails to leverage common patterns of information. We propose
novel graph-theoretic approaches for estimating a population of dynamic
networks that are able to borrow information across multiple heterogeneous
samples in an unsupervised manner and guided by covariate information.
Specifically, we develop a Bayesian product mixture model that imposes
independent mixture priors at each time scan and uses covariates to model the
mixture weights, which results in time-varying clusters of samples designed to
pool information. The computation is carried out using an efficient
Expectation-Maximization algorithm. Extensive simulation studies illustrate
sharp gains in recovering the true dynamic network over existing dynamic
connectivity methods. An analysis of fMRI block task data with behavioral
interventions reveal sub-groups of individuals having similar dynamic
connectivity, and identifies intervention-related dynamic network changes that
are concentrated in biologically interpretable brain regions. In contrast,
existing dynamic connectivity approaches are able to detect minimal or no
changes in connectivity over time, which seems biologically unrealistic and
highlights the challenges resulting from the inability to systematically borrow
information across samples.",http://arxiv.org/abs/2101.05539v1
"Measuring the Impact of COVID-19 Induced Campus Closure on Student
  Self-Regulated Learning in Physics Online Learning Modules",2021-01-14T21:29:18Z,"Tom Zhang, Michelle Taub, Zhongzhou Chen","This paper examines the impact of COVID-19 induced campus closure on
university students' self-regulated learning behavior by analyzing click-stream
data collected from student interactions with 70 online learning modules in a
university physics course. To do so, we compared the trend of six types of
actions related to the three phases of self-regulated learning before and after
campus closures and between two semesters. We found that campus closure changed
students' planning and goal setting strategies for completing the assignments,
but didn't have a detectable impact on the outcome or the time of completion,
nor did it change students' self-reflection behavior. The results suggest that
most students still manage to complete assignments on time during the pandemic,
while the design of online learning modules might have provided the flexibility
and support for them to do so.",http://arxiv.org/abs/2101.05872v1
"Magnetized Rutherford scattering angle for electron-ion collision in
  plasma",2021-01-15T02:29:17Z,"Chang Jiang, Ding Li, Chao Dong","Rutherford scattering formula plays an important role in plasma classical
transport. It is urgent to need a magnetized Rutherford scattering formula
since the magnetic field increases significantly in different fusion areas
(e.g. tokamak magnetic field, self-generated magnetic field, and compressed
magnetic field). The electron-ion Coulomb collisions perpendicular to the
external magnetic field are studied in this paper. The scattering angle is
defined according to the electron trajectory and asymptotic line (without
magnetic field). A magnetized Rutherford scattering formula is obtained
analytically under the weak magnetic field approximation. It is found that the
scattering angle decreases as external magnetic field increases. It is easy to
find the scattering angle decreasing significantly as incident distance, and
incident velocity increasing. It is shown that the theoretical results agree
well with numerical calculation by checking the dependence of scattering angle
on external magnetic field.",http://arxiv.org/abs/2101.05943v1
"Interaction-Aware Behavior Planning for Autonomous Vehicles Validated
  with Real Traffic Data",2021-01-15T06:48:08Z,"Jinning Li, Liting Sun, Wei Zhan, Masayoshi Tomizuka","Autonomous vehicles (AVs) need to interact with other traffic participants
who can be either cooperative or aggressive, attentive or inattentive. Such
different characteristics can lead to quite different interactive behaviors.
Hence, to achieve safe and efficient autonomous driving, AVs need to be aware
of such uncertainties when they plan their own behaviors. In this paper, we
formulate such a behavior planning problem as a partially observable Markov
Decision Process (POMDP) where the cooperativeness of other traffic
participants is treated as an unobservable state. Under different
cooperativeness levels, we learn the human behavior models from real traffic
data via the principle of maximum likelihood. Based on that, the POMDP problem
is solved by Monte-Carlo Tree Search. We verify the proposed algorithm in both
simulations and real traffic data on a lane change scenario, and the results
show that the proposed algorithm can successfully finish the lane changes
without collisions.",http://arxiv.org/abs/2101.05985v1
"Optimal intervention strategies to mitigate the COVID-19 pandemic
  effects",2021-01-15T19:13:57Z,"Andreas Kasis, Stelios Timotheou, Nima Monshizadeh, Marios Polycarpou","Governments across the world are currently facing the task of selecting
suitable intervention strategies to cope with the effects of the COVID-19
pandemic. This is a highly challenging task, since harsh measures may result in
economic collapse while a relaxed strategy might lead to a high death toll.
Motivated by this, we consider the problem of forming intervention strategies
to mitigate the impact of the COVID-19 pandemic that optimize the trade-off
between the number of deceases and the socio-economic costs. We demonstrate
that the healthcare capacity and the testing rate highly affect the optimal
intervention strategies. Moreover, we propose an approach that enables
practical strategies, with a small number of policies and policy changes, that
are close to optimal. In particular, we provide tools to decide which policies
should be implemented and when should a government change to a different
policy. Finally, we consider how the presented results are affected by
uncertainty in the initial reproduction number and infection fatality rate and
demonstrate that parametric uncertainty has a more substantial effect when
stricter strategies are adopted.",http://arxiv.org/abs/2101.06282v1
Electro-Optic Lithium Niobate Metasurfaces,2021-01-16T17:53:04Z,"Bofeng Gao, Mengxin Ren, Wei Wu, Wei Cai, Jingjun Xu","Many applications of metasurfaces require an ability to dynamically change
their properties in time domain. Electrical tuning techniques are of particular
interest, since they pave a way to on-chip integration of metasurfaces with
optoelectronic devices. In this work, we propose and experimentally demonstrate
an electro-optic lithium niobate (EO-LN) metasurface that shows dynamic
modulations to phase retardation of transmitted light. Quasi-bound states in
the continuum (QBIC) are observed from our metasurface. And by applying
external electric voltages, the refractive index of the LN is changed by
Pockels EO nonlinearity, leading to efficient phase modulations to the
transmitted light around the QBIC wavelength. Our EO-LN metasurface opens up
new routes for potential applications in the field of displaying, pulse
shaping, and spatial light modulating.",http://arxiv.org/abs/2101.06491v1
Adaptive Change Point Monitoring for High-Dimensional Data,2021-01-18T02:10:28Z,"Teng Wu, Runmin Wang, Hao Yan, Xiaofeng Shao","In this paper, we propose a class of monitoring statistics for a mean shift
in a sequence of high-dimensional observations. Inspired by the recent
U-statistic based retrospective tests developed by Wang et al.(2019) and Zhang
et al.(2020), we advance the U-statistic based approach to the sequential
monitoring problem by developing a new adaptive monitoring procedure that can
detect both dense and sparse changes in real-time. Unlike Wang et al.(2019) and
Zhang et al.(2020), where self-normalization was used in their tests, we
instead introduce a class of estimators for $q$-norm of the covariance matrix
and prove their ratio consistency. To facilitate fast computation, we further
develop recursive algorithms to improve the computational efficiency of the
monitoring procedure. The advantage of the proposed methodology is demonstrated
via simulation studies and real data illustrations.",http://arxiv.org/abs/2101.06839v1
"Hierarchical Passive Beamforming for Reconfigurable Intelligent Surface
  Aided Communications",2021-01-18T08:17:52Z,"Chang Cai, Xiaojun Yuan, Wenjing Yan, Zhouyang Huang, Ying-Chang Liang, Wei Zhang","In reconfigurable intelligent surfaces (RISs) aided communications, the
existing passive beamforming (PB) design involves polynomial complexity in the
number of reflecting elements, and thus is difficult to implement due to a
massive number of reflecting elements. To overcome this difficulty, we propose
a reflection-angle-based cascaded channel model by adopting the generalized
Snell's law, in which the dimension of the variable space involved in
optimization is significantly reduced, resulting in a simplified hierarchical
passive beamforming (HPB) design. We develop an efficient two-stage HPB
algorithm, which exploits the angular domain property of the channel, to
maximize the achievable rate of the target user. Simulation results demonstrate
the appealing performance and low complexity of the proposed HPB design.",http://arxiv.org/abs/2101.06926v2
"Casimir-Polder Interaction of an Atom with a Cavity Wall Made of
  Phase-Change Material out of Thermal Equilibrium",2021-01-18T10:56:05Z,"G. L. Klimchitskaya, V. M. Mostepanenko","We consider the out-of-thermal-equilibrium Casimir-Polder interaction between
atoms of He$^*$, Na, Cs, and Rb and a cavity wall made of sapphire coated with
a vanadium dioxide film which undergoes the dielectric-to-metal phase
transition with increasing wall temperature. Numerical computations of the
Casimir-Polder force and its gradient as the functions of atom-wall separation
and wall temperature are made when the latter exceeds the temperature of the
environment. The obtained results are compared with those in experiment on
measuring the gradient of the Casimir-Polder force between $^{87}$Rb atoms and
a silica glass wall out of thermal equilibrium. It is shown that the use of
phase-change wall material increases significantly the force magnitude and
especially the force gradient, as opposed to the case of dielectric wall.",http://arxiv.org/abs/2101.06995v1
A note on broken dilatation symmetry in planar noncommutative theory,2021-01-18T13:49:46Z,"Partha Nandi, Sankarshan Sahu, Sayan Kumar Pal","A study of a riveting connection between noncommutativity and the anomalous
dilatation (scale) symmetry is presented for a generalized quantum Hall system
due to time dilatation transformations. On using the ""Peierls substitution""
scheme, it is shown that noncommutativity between spatial coordinates emerges
naturally at a large magnetic field limit. Thereafter, we derive a
path-integral action for the corresponding noncommutative quantum system and
discuss the equivalence between the considered noncommutative system and the
generalized Landau problem thus rendering an effective commmutative
description. By exploiting the path-integral method due to Fujikawa, we derive
an expression for the unintegrated scale or dilatation anomaly for the
generalized Landau system, wherein the anomalies are identified with Jacobian
factors arising from measure change under scale transformation and is
subsequently renormalised. In fact, we derive exact expressions of anomalous
Ward identities from which one may point out the existence of scale anomaly
which is a purely quantum effect induced from the noncommutative structure
between spatial coordinates.",http://arxiv.org/abs/2101.07076v3
"Impact of COVID-19 on IoT Adoption in Healthcare, Smart Homes, Smart
  Buildings, Smart Cities, Transportation and Industrial IoT",2021-01-15T17:14:27Z,"Muhammad Umair, Muhammad Aamir Cheema, Omer Cheema, Huan Li, Hua Lu","COVID-19 has disrupted normal life and has enforced a substantial change in
the policies, priorities and activities of individuals, organisations and
governments. These changes are proving to be a catalyst for technology and
innovation. In this paper, we discuss the pandemic's potential impact on the
adoption of the Internet of Things (IoT) in various broad sectors namely
healthcare, smart homes, smart buildings, smart cities, transportation and
industrial IoT. Our perspective and forecast of this impact on IoT adoption is
based on a thorough research literature review, a careful examination of
reports from leading consulting firms and interactions with several industry
experts. For each of these sectors, we also provide the details of notable IoT
initiatives taken in wake of COVID-19. We also highlight the challenges that
need to be addressed and important research directions that will facilitate
accelerated IoT adoption.",http://arxiv.org/abs/2101.07196v4
Disorder-induced topology in quench dynamics,2021-01-19T19:00:02Z,"Hsiu-Chuan Hsu, Pok-Man Chiu, Po-Yao Chang","We study the effect of strong disorder on topology and entanglement in quench
dynamics. Although disorder-induced topological phases have been well studied
in equilibrium, the disorder-induced topology in quench dynamics has not been
explored. In this work, we predict a disorder-induced topology of post-quench
states characterized by the quantized dynamical Chern number and the crossings
in the entanglement spectrum in $(1+1)$ dimensions. The dynamical Chern number
undergoes transitions from zero to unity, and back to zero when increasing the
disorder strength. The boundaries between different dynamical Chern numbers are
determined by delocalized critical points in the post-quench Hamiltonian with
the strong disorder. An experimental realization in quantum walks is discussed.",http://arxiv.org/abs/2101.07804v4
"LightSys: Lightweight and Efficient CI System for Improving Integration
  Speed of Software",2021-01-20T04:40:41Z,"Geunsik Lim, MyungJoo Ham, Jijoong Moon, Wook Song","The complexity and size increase of software has extended the delay for
developers as they wait for code analysis and code merge. With the larger and
more complex software, more developers nowadays are developing software with
large source code repositories. The tendency for software platforms to
immediately update software packages with feature updates and bug-fixes is a
significant obstacle. Continuous integration systems may help prevent software
flaws during the active development of software packages, even when they are
deployed and updated frequently. Herein, we present a portable and modular code
review automation system that inspects incoming code changes such as code
format and style, performance regression, static analysis, build and deployment
tests, and dynamic analysis before merging and changing code. The proposed
mechanisms are sufficiently lightweight to be hosted on a regular desktop
computer even for numerous developers. The resulting reduced costs allow
developers to apply the proposed mechanism to many source code repositories.
Experimental results demonstrate that the proposed mechanism drastically
reduces overheads and improves usability compared with conventional mechanisms:
execution time (6x faster), CPU usage (40% lower), memory consumption (1/180),
and no out-of-memory occurrence.",http://arxiv.org/abs/2101.07961v3
"Bridge the Vision Gap from Field to Command: A Deep Learning Network
  Enhancing Illumination and Details",2021-01-20T09:39:57Z,"Zhuqing Jiang, Chang Liu, Ya'nan Wang, Kai Li, Aidong Men, Haiying Wang, Haiyong Luo","With the goal of tuning up the brightness, low-light image enhancement enjoys
numerous applications, such as surveillance, remote sensing and computational
photography. Images captured under low-light conditions often suffer from poor
visibility and blur. Solely brightening the dark regions will inevitably
amplify the blur, thus may lead to detail loss. In this paper, we propose a
simple yet effective two-stream framework named NEID to tune up the brightness
and enhance the details simultaneously without introducing many computational
costs. Precisely, the proposed method consists of three parts: Light
Enhancement (LE), Detail Refinement (DR) and Feature Fusing (FF) module, which
can aggregate composite features oriented to multiple tasks based on channel
attention mechanism. Extensive experiments conducted on several benchmark
datasets demonstrate the efficacy of our method and its superiority over
state-of-the-art methods.",http://arxiv.org/abs/2101.08039v1
"Monitoring nonstationary processes based on recursive cointegration
  analysis and elastic weight consolidation",2021-01-21T12:49:18Z,"Jingxin Zhang, Donghua Zhou, Maoyin Chen","This paper considers the problem of nonstationary process monitoring under
frequently varying operating conditions. Traditional approaches generally
misidentify the normal dynamic deviations as faults and thus lead to high false
alarms. Besides, they generally consider single relatively steady operating
condition and suffer from the catastrophic forgetting issue when learning
successive operating conditions. In this paper, recursive cointegration
analysis (RCA) is first proposed to distinguish the real faults from normal
systems changes, where the model is updated once a new normal sample arrives
and can adapt to slow change of cointegration relationship. Based on the
long-term equilibrium information extracted by RCA, the remaining short-term
dynamic information is monitored by recursive principal component analysis
(RPCA). Thus a comprehensive monitoring framework is built. When the system
enters a new operating condition, the RCA-RPCA model is rebuilt to deal with
the new condition. Meanwhile, elastic weight consolidation (EWC) is employed to
settle the `catastrophic forgetting' issue inherent in RPCA, where significant
information of influential parameters is enhanced to avoid the abrupt
performance degradation for similar modes. The effectiveness of the proposed
method is illustrated by a practical industrial system.",http://arxiv.org/abs/2101.08579v1
"A Geospatial Functional Model For OCO-2 Data with Application on
  Imputation and Land Fraction Estimation",2021-01-23T05:09:33Z,"Xinyue Chang, Zhengyuan Zhu, Xiongtao Dai, Jonathan Hobbs","Data from NASA's Orbiting Carbon Observatory-2 (OCO-2) satellite is essential
to many carbon management strategies. A retrieval algorithm is used to estimate
CO2 concentration using the radiance data measured by OCO-2. However, due to
factors such as cloud cover and cosmic rays, the spatial coverage of the
retrieval algorithm is limited in some areas of critical importance for carbon
cycle science. Mixed land/water pixels along the coastline are also not used in
the retrieval processing due to the lack of valid ancillary variables including
land fraction. We propose an approach to model spatial spectral data to solve
these two problems by radiance imputation and land fraction estimation. The
spectral observations are modeled as spatially indexed functional data with
footprint-specific parameters and are reduced to much lower dimensions by
functional principal component analysis. The principal component scores are
modeled as random fields to account for the spatial dependence, and the missing
spectral observations are imputed by kriging the principal component scores.
The proposed method is shown to impute spectral radiance with high accuracy for
observations over the Pacific Ocean. An unmixing approach based on this model
provides much more accurate land fraction estimates in our validation study
along Greece coastlines.",http://arxiv.org/abs/2101.09418v1
"Personalization Paradox in Behavior Change Apps: Lessons from a Social
  Comparison-Based Personalized App for Physical Activity",2021-01-25T11:39:32Z,"Jichen Zhu, Diane H. Dallal, Robert C. Gray, Jennifer Villareale, Santiago Ontañón, Evan M. Forman, Danielle Arigo","Social comparison-based features are widely used in social computing apps.
However, most existing apps are not grounded in social comparison theories and
do not consider individual differences in social comparison preferences and
reactions. This paper is among the first to automatically personalize social
comparison targets. In the context of an m-health app for physical activity, we
use artificial intelligence (AI) techniques of multi-armed bandits. Results
from our user study (n=53) indicate that there is some evidence that motivation
can be increased using the AI-based personalization of social comparison. The
detected effects achieved small-to-moderate effect sizes, illustrating the
real-world implications of the intervention for enhancing motivation and
physical activity. In addition to design implications for social comparison
features in social apps, this paper identified the personalization paradox, the
conflict between user modeling and adaptation, as a key design challenge of
personalized applications for behavior change. Additionally, we propose
research directions to mitigate this Personalization Paradox.",http://arxiv.org/abs/2101.10020v2
"Full-duplex Reflective Beamsteering Metasurface Featuring Magnetless
  Nonreciprocal Amplification",2021-01-25T14:32:15Z,"Sajjad Taravati, George V. Eleftheriades","Nonreciprocal radiation refers to electromagnetic wave radiation in which a
structure provides different responses under the change of the direction of the
incident field. Modern wireless telecommunication systems demand versatile
apparatuses which are capable of full-duplex nonreciprocal wave processing and
amplification, especially in the reflective state. To realize such a unique,
extraordinary and versatile functionality, we propose an architecture in which
a chain of series cascaded radiating patches are integrated with nonreciprocal
phase shifters, providing an original and efficient apparatus for full-duplex
reflective beamsteering. Such an ultrathin reflective metasurface can provide
directive and diverse radiation beams, large wave amplification, steerable
beams by simply changing the bias of the gradient active nonmagnetic
nonreciprocal phase shifters, and is immune to undesired time harmonics. Having
accomplished all these functionalities in the reflective state, the metasurface
represents a conspicuous apparatus for efficient, controllable and programmable
wave engineering.",http://arxiv.org/abs/2101.10067v3
"Writers Gonna Wait: The Effectiveness of Notifications to Initiate
  Aversive Action in Writing Procrastination",2021-01-25T15:53:54Z,"Chatchai Wangwiwattana, Sunjoli Aggarwal, Eric C. Larson","This paper evaluates the use of notifications to reduce
aversive-task-procrastination by helping initiate action. Specifically, we
focus on aversion to graded writing tasks. We evaluate software designs
commonly used by behavior change applications, such as goal setting and action
support systems. We conduct a two-phase control trial experiment with 21
college students tasked to write two 3000-word writing assignments (14 students
fully completed the experiment). Participants use a customized text editor
designed to continuously collect writing behavior. The results from the study
reveal that notifications have minimal effect in encouraging users to get
started. They can also increase negative effects on participants. Other
techniques, such as eliminating distraction and showing simple writing
statistics, yield higher satisfaction among participants as they complete the
writing task. Furthermore, the incorporation of text mining decreases aversion
to the task and helps participants overcome writer's block. Finally, we discuss
lessons learned from our evaluation that help quantify the difficulty of
behavior change for writing procrastination, with emphasis on goals for the HCI
community.",http://arxiv.org/abs/2101.10191v1
Lensing of Dirac monopole in Berry's phase,2021-01-26T03:26:45Z,"Kazuo Fujikawa, Koichiro Umetsu","Berry's phase, which is associated with the slow cyclic motion with a finite
period, looks like a Dirac monopole when seen from far away but smoothly
changes to a dipole near the level crossing point in the parameter space in an
exactly solvable model. This topology change of Berry's phase is visualized as
a result of lensing effect; the monopole supposed to be located at the level
crossing point appears at the displaced point when the variables of the model
deviate from the precisely adiabatic movement. The effective magnetic field
generated by Berry's phase is determined by a simple geometrical consideration
of the magnetic flux coming from the displaced Dirac monopole.",http://arxiv.org/abs/2101.10541v3
Coulomb corrections to two-particle interaction in artificial traps,2021-01-26T21:59:30Z,Peng Guo,"In present work, we discuss the effect of Coulomb interaction to the dynamics
of two-particle system bound in various traps. The strategy of including
Coulomb interaction into the quantization condition of trapped system is
discussed in a general and non-perturbative manner. In most cases, Coulomb
corrections to quantization condition largely rely on numerical approach or
perturbation expansion. Only for some special cases, such as the spherical hard
wall trap, a closed-form of quantization condition with all orders of Coulomb
corrections can be obtained.",http://arxiv.org/abs/2101.11097v2
"Quantum Generative Adversarial Networks in a Continuous-Variable
  Architecture to Simulate High Energy Physics Detectors",2021-01-26T23:33:14Z,"Su Yeon Chang, Sofia Vallecorsa, Elías F. Combarro, Federico Carminati","Deep Neural Networks (DNNs) come into the limelight in High Energy Physics
(HEP) in order to manipulate the increasing amount of data encountered in the
next generation of accelerators. Recently, the HEP community has suggested
Generative Adversarial Networks (GANs) to replace traditional time-consuming
Geant4 simulations based on the Monte Carlo method. In parallel with advances
in deep learning, intriguing studies have been conducted in the last decade on
quantum computing, including the Quantum GAN model suggested by IBM. However,
this model is limited in learning a probability distribution over discrete
variables, while we initially aim to reproduce a distribution over continuous
variables in HEP. We introduce and analyze a new prototype of quantum GAN
(qGAN) employed in continuous-variable (CV) quantum computing, which encodes
quantum information in a continuous physical observable. Two CV qGAN models
with a quantum and a classical discriminator have been tested to reproduce
calorimeter outputs in a reduced size, and their advantages and limitations are
discussed.",http://arxiv.org/abs/2101.11132v1
"QCD effects in lepton angular distributions of Drell-Yan/$Z$ production
  and jet discrimination",2021-01-27T01:37:51Z,"Wen-Chen Chang, Randall Evan McClellan, Jen-Chieh Peng, Oleg Teryaev","We present a comparison of data of lepton angular distributions of
Drell-Yan/$Z$ production with the fixed-order pQCD calculations by which the
baseline of pQCD effects is illustrated. As for the $Z$ production, we predict
that $A_0$ and $A_2$ for $Z$ plus single gluon-jet events are very different
from that of $Z$ plus single quark-jet events, allowing a new experimental tool
for checking various algorithms which attempt to discriminate quark jets from
gluon jets. Using an intuitive geometric approach, we show that the violation
of the Lam-Tung relation, appearing at large transverse-momentum region, is
attributed to the presence of a non-coplanarity effect. This interpretation is
consistent with the appearance of violation beyond LO-QCD effect.",http://arxiv.org/abs/2101.11160v1
"The Ferroelectric Photo-Groundstate of SrTiO$_3$: Cavity Materials
  Engineering",2021-01-27T10:57:54Z,"Simone Latini, Dongbin Shin, Shunsuke A. Sato, Christian Schäfer, Umberto De Giovannini, Hannes Hübener, Angel Rubio","Optical cavities confine light on a small region in space which can result in
a strong coupling of light with materials inside the cavity. This gives rise to
new states where quantum fluctuations of light and matter can alter the
properties of the material altogether. Here we demonstrate, based on first
principles calculations, that such light-matter coupling induces a change of
the collective phase from quantum paraelectric to ferroelectric in the
SrTiO$_3$ groundstate, which has thus far only been achieved in
out-of-equilibrium strongly excited conditions[1, 2]. This is a
light-matter-hybrid groundstate which can only exist because of the coupling to
the vacuum fluctuations of light, a ""photo-groundstate"". The phase transition
is accompanied by changes in the crystal structure, showing that fundamental
groundstate properties of materials can be controlled via strong light-matter
coupling. Such a control of quantum states enables the tailoring of materials
properties or even the design of novel materials purely by exposing them to
confined light.",http://arxiv.org/abs/2101.11313v1
Dynamic formation of spherical voids crossing linear defects,2021-01-07T05:49:30Z,"Youcef A. Bioud, Maxime Rondeau, Abderraouf Boucherif, Gilles Patriarche, Dominique Drouin, Richard Arès","A predictive model for the evolution of porous Ge layer upon thermal
treatment is reported. We represent an idealized etched dislocation core as an
axially symmetric elongated hole and computed its dynamics during annealing.
Numerical simulations of the shape change of a completely spherical void via
surface diffusion have been performed. Simulations and experiments show
individual large spherical voids, aligned along the dislocation core. The
creation of voids could facilitate interactions between dislocations, enabling
the dislocation network to change its connectivity in a way that facilitates
the subsequent annihilation of dislocation segments. This confirms that
thermally activated processes such as state diffusion of porous materials
provide mechanisms whereby the defects are removed or arranged in
configurations of lower energy. This model is intended to be indicative, and
more detailed experimental characterization of process parameters such as
annealing temperature and time, and could estimate the annealing time for given
temperatures, or vice versa, with the right parameters.",http://arxiv.org/abs/2101.12012v1
"Influence of interaction softness in phase separation of active
  particles",2021-01-28T15:11:53Z,"Monika Sanoria, Raghunath Chelakkot, Amitabha Nandi","Using a minimal model of active Brownian discs, we study the effect of a
crucial parameter, namely the softness of the inter-particle repulsion, on
motility-induced phase separation. We show that an increase in particle
softness reduces the ability of the system to phase-separate and the system
exhibit a delayed transition. After phase separation, the system state
properties can be explained by a single relevant lengthscale, the effective
inter-particle distance. We estimate this lengthscale analytically and use it
to rescale the state properties at dense phase for systems with different
interaction softness. Using this lengthscale, we provide a scaling relation for
the time taken to phase separate which shows a high sensitivity to the
interaction softness.",http://arxiv.org/abs/2101.12055v2
"Nuclear binding energy predictions using neural networks: Application of
  the multilayer perceptron",2021-01-28T17:08:15Z,"Esra Yüksel, Derya Soydaner, Hüseyin Bahtiyar","In recent years, artificial neural networks and their applications for large
data sets have became a crucial part of scientific research. In this work, we
implement the Multilayer Perceptron (MLP), which is a class of feedforward
artificial neural network (ANN), to predict ground-state binding energies of
atomic nuclei. Two different MLP architectures with three and four hidden
layers are used to study their effects on the predictions. To train the MLP
architectures, two different inputs are used along with the latest atomic mass
table and changes in binding energy predictions are also analyzed in terms of
the changes in the input channel. It is seen that using appropriate MLP
architectures and putting more physical information in the input channels, MLP
can make fast and reliable predictions for binding energies of atomic nuclei,
which is also comparable to the microscopic energy density functionals.",http://arxiv.org/abs/2101.12117v2
lrsarith: a small fixed/hybrid arithmetic C library,2021-01-29T06:40:53Z,"David Avis, Charles Jordan","We describe lrsarith which is a small fixed precision and hybrid arithmetic C
library for integers and rationals that we developed for use in the lrslib
library for polyhedral computation. Using a generic set of operations, a
program can be compiled with either 64-bit or 128-bit (if available) fixed
precision, with an extended precision library such as GMP or the built-in MP
routines. A simple scheme checks for overflow and either terminates the program
or, in hybrid mode, changes to a higher precision arithmetic. Implementing
these arithmetics in lrslib resulted in only minimal changes to the original
code. We give computational results using lrs and mplrs, vertex/facet
enumeration codes in lrslib, using 64 and 128 bit fixed integer arithmetic with
and without overflow checking, GMP arithmetic, lrsarith hybrid arithmetic with
both GMP and MP, and FLINT hybrid arithmetic. We give a small self-contained
example C program using the lrsarith package in both fixed precision and hybrid
mode.",http://arxiv.org/abs/2101.12425v1
Learning User Preferences in Non-Stationary Environments,2021-01-29T10:26:16Z,"Wasim Huleihel, Soumyabrata Pal, Ofer Shayevitz","Recommendation systems often use online collaborative filtering (CF)
algorithms to identify items a given user likes over time, based on ratings
that this user and a large number of other users have provided in the past.
This problem has been studied extensively when users' preferences do not change
over time (static case); an assumption that is often violated in practical
settings. In this paper, we introduce a novel model for online non-stationary
recommendation systems which allows for temporal uncertainties in the users'
preferences. For this model, we propose a user-based CF algorithm, and provide
a theoretical analysis of its achievable reward. Compared to related
non-stationary multi-armed bandit literature, the main fundamental difficulty
in our model lies in the fact that variations in the preferences of a certain
user may affect the recommendations for other users severely. We also test our
algorithm over real-world datasets, showing its effectiveness in real-world
applications. One of the main surprising observations in our experiments is the
fact our algorithm outperforms other static algorithms even when preferences do
not change over time. This hints toward the general conclusion that in
practice, dynamic algorithms, such as the one we propose, might be beneficial
even in stationary environments.",http://arxiv.org/abs/2101.12506v1
"Aquanims: Area-Preserving Animated Transitions in Statistical Data
  Graphics based on a Hydraulic Metaphor",2021-01-29T10:35:42Z,Michael Aupetit,"We propose ""aquanims"" as new design metaphors for animated transitions that
preserve displayed areas during the transformation. Animated transitions are
used to facilitate understanding of graphical transformations between different
visualizations. Area is key information to preserve during filtering or
ordering transitions of area-based charts like bar charts, histograms,
treemaps, or mosaic plots. As liquids are incompressible fluids, we use a
hydraulic metaphor to convey the sense of area preservation during animated
transitions: in aquanims, graphical objects can change shape, position, color,
and even connectedness but not displayed area, as for a liquid contained in a
transparent vessel or transferred between such vessels communicating through
hidden pipes. We present various aquanims for product plots like bar charts and
histograms to accommodate changes in data, in the ordering of bars or in a
number of bins, and to provide animated tips. We also consider confusion
matrices visualized as fluctuation diagrams and mosaic plots, and show how
aquanims can be used to ease the understanding of different classification
errors of real data.",http://arxiv.org/abs/2101.12511v1
"Garland's Technique for Posets and High Dimensional Grassmannian
  Expanders",2021-01-29T15:02:37Z,"Tali Kaufman, Ran J. Tessler","Local to global machinery plays an important role in the study of simplicial
complexes, since the seminal work of Garland [G] to our days. In this work we
develop a local to global machinery for general posets. We show that the high
dimensional expansion notions and many recent expansion results have a
generalization to posets. Examples are fast convergence of high dimensional
random walks generalizing [KO,AL], an equivalence with a global random walk
definition, generalizing [DDFH] and a trickling down theorem, generalizing [O].
In particular, we show that some posets, such as the Grassmannian poset,
exhibit qualitatively stronger trickling down effect than simplicial complexes.
Using these methods, and the novel idea of Posetification, to Ramanujan
complexes [LSV1,LSV2], we construct a constant degree expanding Grassmannian
poset, and analyze its expansion. This it the first construction of such
object, whose existence was conjectured in [DDFH].",http://arxiv.org/abs/2101.12621v3
"Weil polynomials of abelian varieties over finite fields with many
  rational points",2021-01-29T16:11:57Z,"Elena Berardini, Alejandro J. Giangreco Maidana","We consider the finite set of isogeny classes of $g$-dimensional abelian
varieties defined over the finite field $\mathbb{F}_q$ with endomorphism
algebra being a field. We prove that the class within this set whose varieties
have maximal number of rational points is unique, for any prime even power $q$
big enough and verifying mild conditions. We describe its Weil polynomial and
we prove that the class is ordinary and cyclic outside the primes dividing an
integer that only depends on $g$. In dimension $3$, we prove that the class is
ordinary and cyclic and give explicitly its Weil polynomial, for any prime even
power $q$.",http://arxiv.org/abs/2101.12664v2
"Diminishing Domain Bias by Leveraging Domain Labels in Object Detection
  on UAVs",2021-01-29T16:42:52Z,"Benjamin Kiefer, Martin Messmer, Andreas Zell","Object detection from Unmanned Aerial Vehicles (UAVs) is of great importance
in many aerial vision-based applications. Despite the great success of generic
object detection methods, a significant performance drop is observed when
applied to images captured by UAVs. This is due to large variations in imaging
conditions, such as varying altitudes, dynamically changing viewing angles, and
different capture times. These variations lead to domain imbalances and, thus,
trained models suffering from domain bias. We demonstrate that domain knowledge
is a valuable source of information and thus propose domain-aware object
detectors by using freely accessible sensor data. By splitting the model into
cross-domain and domain-specific parts, substantial performance improvements
are achieved on multiple data sets across various models and metrics without
changing the architecture. In particular, we achieve a new state-of-the-art
performance on UAVDT for embedded real-time detectors. Furthermore, we create a
new airborne image data set by annotating 13,713 objects in 2,900 images
featuring precise altitude and viewing angle annotations.",http://arxiv.org/abs/2101.12677v2
"Causality theory of spacetimes with continuous Lorentzian metrics
  revisited",2021-01-29T18:25:52Z,Leonardo García-Heveling,"We consider the usual causal structure $(I^+,J^+)$ on a spacetime, and a
number of alternatives based on Minguzzi's $D^+$ and Sorkin and Woolgar's
$K^+$, in the case where the spacetime metric is continuous, but not
necessarily smooth. We compare the different causal structures based on three
key properties, namely the validity of the push-up lemma, the openness of
chronological futures, and the existence of limit causal curves. Recall that if
the spacetime metric is smooth, $(I^+,J^+)$ satisfies all three properties, but
that in the continuous case, the push-up lemma fails. Among the proposed
alternative causal structures, there is one that satisfies push-up and open
futures, and one that has open futures and limit curves. Furthermore, we show
that spacetimes with continuous metrics do not, in general, admit a causal
structure satisfying all three properties at once.",http://arxiv.org/abs/2101.12716v2
Elastic wave velocities in finitely pre-stretched soft fibers,2021-01-30T05:48:04Z,"Shiheng Zhao, Zheng Chang","Elastic wave velocity in a soft fiber that varies depending on material
constitution and axial stress level is an essential measure of mechanical
signals in many technical applications. In this work, based on the
small-on-large theory, we establish a model of linear elastic wave propagation
in a finitely pre-stretched soft fiber. The formulas of longitudinal (Primary,
P-) and transverse (Secondary, S-) wave velocities are provided and validated
by numerical simulations as well as by experimental data on spider silk. The
influences of material constitution, compressibility, and pre-stress on the
wave propagation are investigated. We found that with increasing pre-stress,
the variation of P-wave velocity highly relies on the concavity of the
stress-strain curve. In contrast, an increase of S-wave velocity exhibits
regardless of any constitutive model. For both P- and S-waves, the variation of
the velocities is more significant in a compressible fiber than that in a
nearly-incompressible one. Moreover, for minuscule pre-stress, we propose a
modified formula for S-wave velocity based on the Rayleigh beam theory, which
reveals the competition mechanism between ""string vibration"" and ""beam
vibration."" This may provide a reliable theoretical basis for precise
mechanical characterization of soft fibers and open a route for lightweight,
tunable wave manipulation devices.",http://arxiv.org/abs/2102.00156v1
"Deep Reinforcement Learning Aided Monte Carlo Tree Search for MIMO
  Detection",2021-01-30T07:29:04Z,"Tz-Wei Mo, Ronald Y. Chang, Te-Yi Kan","This paper proposes a novel multiple-input multiple-output (MIMO) symbol
detector that incorporates a deep reinforcement learning (DRL) agent into the
Monte Carlo tree search (MCTS) detection algorithm. We first describe how the
MCTS algorithm, used in many decision-making problems, is applied to the MIMO
detection problem. Then, we introduce a self-designed deep reinforcement
learning agent, consisting of a policy value network and a state value network,
which is trained to detect MIMO symbols. The outputs of the trained networks
are adopted into a modified MCTS detection algorithm to provide useful node
statistics and facilitate enhanced tree search process. The resulted scheme,
termed the DRL-MCTS detector, demonstrates significant improvements over the
original MCTS detection algorithm and exhibits favorable performance compared
to other existing linear and DNN-based detection methods under varying channel
conditions.",http://arxiv.org/abs/2102.00178v1
"Exploding paraxial beams, vortex beams, and cylindrical beams of light
  with finite power in linear media, and their enhanced longitudinal field",2021-01-30T16:37:05Z,Miguel A. Porras,"We present a set of paraxial light beams with cylindrical symmetry, smooth
and localized transversal profile carrying finite power, that develop intensity
singularities when they are focused in a linear medium, such as vacuum. They
include beams with orbital angular momentum and with radial polarization, in
which case they develop punctual phase and polarization singularities
surrounded by infinitely bright rings, along with singular longitudinal fields.
In practice, these effects are manifested in focal intensities and spot sizes,
vortex bright ring intensities and radii, and strengths of the longitudinal
field, that strongly change with the lens aperture radius. Continuous control
of these focal properties is thus exercised without changing the light incident
on the lens, with substantially the same collected power, and while maintaining
paraxial focusing conditions. As solutions of the Schr\""odinger equation, these
exploding beams have analogues in other areas of physics where this equation is
the fundamental dynamical model.",http://arxiv.org/abs/2102.00265v2
"Real-time Monitoring of Autonomous Vehicle's Time Gap Variations: A
  Bayesian Framework",2021-01-31T04:29:56Z,"Wissam Kontar, Soyoung Ahn","This paper proposes a novel monitoring methodology for car-following control
of automated vehicles that uses real-time measurements of spacing and velocity
obtained through vehicle sensors. This study focuses on monitoring the time
gap, a key parameter that dictates the desired following spacing of the
controlled vehicle. The goal is to monitor deviations in actual time gap from a
desired setting and detect when it deviates beyond a control limit. A random
coefficient modeling is developed to systematically capture the stochastic
distribution of the time gap and derive a closed-form Bayesian updating scheme
for real-time inference. A control chart is then adopted to systematically set
the control limits and inform when the time gap setting should be changed.
Simulation experiments are performed to demonstrate the effectiveness of the
proposes method for monitoring the time gap and alerting when the parameter
setting needs to be changed.",http://arxiv.org/abs/2102.00375v1
"MultiRocket: Multiple pooling operators and transformations for fast and
  effective time series classification",2021-01-31T14:04:10Z,"Chang Wei Tan, Angus Dempster, Christoph Bergmeir, Geoffrey I. Webb","We propose MultiRocket, a fast time series classification (TSC) algorithm
that achieves state-of-the-art performance with a tiny fraction of the time and
without the complex ensembling structure of many state-of-the-art methods.
MultiRocket improves on MiniRocket, one of the fastest TSC algorithms to date,
by adding multiple pooling operators and transformations to improve the
diversity of the features generated. In addition to processing the raw input
series, MultiRocket also applies first order differences to transform the
original series. Convolutions are applied to both representations, and four
pooling operators are applied to the convolution outputs. When benchmarked
using the University of California Riverside TSC benchmark datasets,
MultiRocket is significantly more accurate than MiniRocket, and competitive
with the best ranked current method in terms of accuracy, HIVE-COTE 2.0, while
being orders of magnitude faster.",http://arxiv.org/abs/2102.00457v4
"Enjoy Your Editing: Controllable GANs for Image Editing via Latent Space
  Navigation",2021-02-01T21:38:36Z,"Peiye Zhuang, Oluwasanmi Koyejo, Alexander G. Schwing","Controllable semantic image editing enables a user to change entire image
attributes with a few clicks, e.g., gradually making a summer scene look like
it was taken in winter. Classic approaches for this task use a Generative
Adversarial Net (GAN) to learn a latent space and suitable latent-space
transformations. However, current approaches often suffer from attribute edits
that are entangled, global image identity changes, and diminished
photo-realism. To address these concerns, we learn multiple attribute
transformations simultaneously, integrate attribute regression into the
training of transformation functions, and apply a content loss and an
adversarial loss that encourages the maintenance of image identity and
photo-realism. We propose quantitative evaluation strategies for measuring
controllable editing performance, unlike prior work, which primarily focuses on
qualitative evaluation. Our model permits better control for both single- and
multiple-attribute editing while preserving image identity and realism during
transformation. We provide empirical results for both natural and synthetic
images, highlighting that our model achieves state-of-the-art performance for
targeted image manipulation.",http://arxiv.org/abs/2102.01187v3
Drift Estimation with Graphical Models,2021-02-02T12:24:34Z,"Luigi Riso, Marco Guerzoni","This paper deals with the issue of concept drift in supervised machine
learn-ing. We make use of graphical models to elicit the visible structure of
the dataand we infer from there changes in the hidden context. Differently from
previous concept-drift detection methods, this application does not depend on
the supervised machine learning model in use for a specific target variable,
but it tries to assess the concept drift as independent characteristic of the
evolution of a dataset. Specifically, we investigate how a graphical model
evolves by looking at the creation of new links and the disappearing of
existing ones in different time periods. The paper suggests a method that
highlights the changes and eventually produce a metric to evaluate the
stability over time. The paper evaluate the method with real world data on the
Australian Electric market.",http://arxiv.org/abs/2102.01458v1
Fast Parametric Model Checking through Model Fragmentation,2021-02-02T13:52:52Z,"Xinwei Fang, Radu Calinescu, Simos Gerasimou, Faisal Alhwikem","Parametric model checking (PMC) computes algebraic formulae that express key
non-functional properties of a system (reliability, performance, etc.) as
rational functions of the system and environment parameters. In software
engineering, PMC formulae can be used during design, e.g., to analyse the
sensitivity of different system architectures to parametric variability, or to
find optimal system configurations. They can also be used at runtime, e.g., to
check if non-functional requirements are still satisfied after environmental
changes, or to select new configurations after such changes. However, current
PMC techniques do not scale well to systems with complex behaviour and more
than a few parameters. Our paper introduces a fast PMC (fPMC) approach that
overcomes this limitation, extending the applicability of PMC to a broader
class of systems than previously possible. To this end, fPMC partitions the
Markov models that PMC operates with into \emph{fragments} whose reachability
properties are analysed independently, and obtains PMC reachability formulae by
combining the results of these fragment analyses. To demonstrate the
effectiveness of fPMC, we show how our fPMC tool can analyse three systems
(taken from the research literature, and belonging to different application
domains) with which current PMC techniques and tools struggle.",http://arxiv.org/abs/2102.01490v1
Electrically Switchable Broadband Photonic Bound States in the Continuum,2021-02-02T18:54:02Z,"Andreas Henkel, Maik Meudt, Maximilian Buchmüller, Patrick Görrn","The question of how to continuously manipulate a photonic system between a
radiating state and a bound state is an important challenge in photonics, as
its solution promises broad technological relevance for optical sensors,
modulators, switches and displays. Existing approaches utilise the inherent
wave-nature of electromagnetic fields to their advantage, and are commonly
identified as bound states in the continuum (BICs), as they resemble singular
bound states embedded in a band of radiating states. Although quasi-BICs have
been demonstrated for numerous symmetric periodic photonic crystals, their
existence so far has been limited to narrow spectral ranges, and their
application in switches or modulators needs large changes of the refractive
index. Here, we show that the incidence of two guided symmetric substrate waves
of opposite phase onto a symmetric periodic film waveguide enables the
excitation of self-stabilising BICs which are electrically switchable in a
broad optical range, with small changes of the refractive index. An
experimental verification of the concept shows a switching contrast C=700 at a
wavelength of 532 nm and C=1000 at a wavelength of 632.8 nm.",http://arxiv.org/abs/2102.01686v1
"Recurrent Neural Network for MoonBoard Climbing Route Classification and
  Generation",2021-02-02T22:38:23Z,"Yi-Shiou Duh, Ray Chang","Classifying the difficulties of climbing routes and generating new routes are
both challenging. Existing machine learning models not only fail to accurately
predict a problem's difficulty, but they are also unable to generate reasonable
problems. In this work, we introduced ""BetaMove"", a new move preprocessing
pipeline we developed, in order to mimic a human climber's hand sequence. The
preprocessed move sequences were then used to train both a route generator and
a grade predictor. By preprocessing a MoonBoard problem into a proper move
sequence, the accuracy of our grade predictor reaches near human-level
performance, and our route generator produces new routes of much better quality
compared to previous work. We demonstrated that with BetaMove, we are able to
inject human insights into the machine learning problems, and this can be the
foundations for future transfer learning on climbing style classification
problems.",http://arxiv.org/abs/2102.01788v1
Betweenness centrality illuminates intermittent frictional dynamics,2021-02-03T03:12:43Z,"Omid Dorostkar, Karen E. Daniels, Dominik Strebel, Jan Carmeliet","Dense granular systems subjected to an imposed shear stress undergo
stick-slip dynamics with systematic patterns of dilation-compaction. During
each stick phase, as the frictional strength builds up, the granular system
dilates to accommodate shear strain, developing stronger force networks. During
each slip event, when the stored energy is released, particles experience large
rearrangements and the granular network can significantly change. Here, we use
numerical simulations of 3D, sheared frictional packings to show that the mean
betweenness centrality -- a property of network of interparticle connections --
follows consistent patterns during the stick-slip dynamics, showing sharp
spikes at each slip event. We identify the source of this behavior as arising
from the connectivity and contact arrangements of granular network during
dilation-compaction cycles, and find that a lower potential for connection
between particles leads to an increase of mean betweenness centrality in the
system. Furthermore, we show that at high confinements, few particles lose
contact during slip events, leading to a smaller change in granular
connectivity and betweenness centrality.",http://arxiv.org/abs/2102.01851v1
"Parallax estimation for push-frame satellite imagery: application to
  super-resolution and 3D surface modeling from Skysat products",2021-02-03T21:24:22Z,"Jérémy Anger, Thibaud Ehret, Gabriele Facciolo","Recent constellations of satellites, including the Skysat constellation, are
able to acquire bursts of images. This new acquisition mode allows for modern
image restoration techniques, including multi-frame super-resolution. As the
satellite moves during the acquisition of the burst, elevation changes in the
scene translate into noticeable parallax. This parallax hinders the results of
the restoration. To cope with this issue, we propose a novel parallax
estimation method. The method is composed of a linear Plane+Parallax
decomposition of the apparent motion and a multi-frame optical flow algorithm
that exploits all frames simultaneously. Using SkySat L1A images, we show that
the estimated per-pixel displacements are important for applying multi-frame
super-resolution on scenes containing elevation changes and that can also be
used to estimate a coarse 3D surface model.",http://arxiv.org/abs/2102.02301v1
"Covalency driven modulation of paramagnetism and development of lone
  pair ferroelectricity in multiferroic Pb$_3$TeMn$_3$P$_2$O$_{14}$",2021-02-04T07:01:02Z,"Rafikul Ali Saha, Anita Halder, Tanusri Saha-Dasgupta, Desheng Fu, Mitsuru Itoh, Sugata Ray","We have investigated the structural, magnetic and dielectric properties of
Pb-based langasite compound Pb$_3$TeMn$_3$P$_2$O$_{14}$ both experimentally and
theoretically in the light of metal-oxygen covalency, and the consequent
generation of multiferroicity. It is known that large covalency between Pb 6$p$
and O 2$p$ plays instrumental role behind stereochemical lone pair activity of
Pb. The same happens here but a subtle structural phase transition above room
temperature changes the degree of such lone pair activity and the system
becomes ferroelectric below 310 K. Interestingly, this structural change also
modulates the charge densities on different constituent atoms and consequently
the overall magnetic response of the system while maintaining global
paramagnetism behavior of the compound intact. This single origin of modulation
in polarity and paramagnetism inherently connects both the functionalities and
the system exhibits mutiferroicity at room temperature.",http://arxiv.org/abs/2102.02444v1
Semi-Supervised Action Recognition with Temporal Contrastive Learning,2021-02-04T17:28:35Z,"Ankit Singh, Omprakash Chakraborty, Ashutosh Varshney, Rameswar Panda, Rogerio Feris, Kate Saenko, Abir Das","Learning to recognize actions from only a handful of labeled videos is a
challenging problem due to the scarcity of tediously collected activity labels.
We approach this problem by learning a two-pathway temporal contrastive model
using unlabeled videos at two different speeds leveraging the fact that
changing video speed does not change an action. Specifically, we propose to
maximize the similarity between encoded representations of the same video at
two different speeds as well as minimize the similarity between different
videos played at different speeds. This way we use the rich supervisory
information in terms of `time' that is present in otherwise unsupervised pool
of videos. With this simple yet effective strategy of manipulating video
playback rates, we considerably outperform video extensions of sophisticated
state-of-the-art semi-supervised image recognition methods across multiple
diverse benchmark datasets and network architectures. Interestingly, our
proposed approach benefits from out-of-domain unlabeled videos showing
generalization and robustness. We also perform rigorous ablations and analysis
to validate our approach. Project page: https://cvir.github.io/TCL/.",http://arxiv.org/abs/2102.02751v2
Designing a Binary Clock using logic gates,2021-02-04T19:28:23Z,Jacob John,"Wristwatches have been a common fashion accessory addition for several
people. However, the concept of using a seven-segment digital display or
sometimes, even an analog indicator hasn't changed for a number of years. This
project aims to test and design a binary clock, also referred to as 32, 16, 8,
4, 2, 1 clock or even 8, 4, 2, 1 clock (due to their display configuration),
that could change this everlasting display for watches. Specifically, digital
logic and design engineers would find interest in this topic due to the
sophistication involved in reading-out the time. This project will do so using
by showing each decimal digit of sexagesimal time as a binary value. This
design will be primarily functioning on logic gates and would involve the use
of several basic components that include, but are not limited to, integrated
circuits (or ICs), Light-emitting diodes (LEDs), and resistors.",http://arxiv.org/abs/2102.02845v1
"An Interaction Neyman-Scott Point Process Model for Coronavirus
  Disease-19",2021-02-05T05:11:47Z,"J. Park, W. Chang, B. Choi","With rapid transmission, the coronavirus disease 2019 (COVID-19) has led to
over 2 million deaths worldwide, posing significant societal challenges.
Understanding the spatial patterns of patient visits and detecting the local
spreading events are crucial to controlling disease outbreaks. We analyze
highly detailed COVID-19 contact tracing data collected from Seoul, which
provides a unique opportunity to understand the mechanism of patient visit
occurrence. Analyzing contact tracing data is challenging because patient
visits show strong clustering patterns while clusters of events may have
complex interaction behavior. To account for such behaviors, we develop a novel
interaction Neyman-Scott process that regards the observed patient visit events
as offsprings generated from a parent spreading event. Inference for such
models is complicated since the likelihood involves intractable normalizing
functions. To address this issue, we embed an auxiliary variable algorithm into
our Markov chain Monte Carlo. We fit our model to several simulated and real
data examples under different outbreak scenarios and show that our method can
describe spatial patterns of patient visits well. We also provide visualization
tools that can inform public health interventions for infectious diseases such
as social distancing.",http://arxiv.org/abs/2102.02999v1
CF-GNNExplainer: Counterfactual Explanations for Graph Neural Networks,2021-02-05T17:58:14Z,"Ana Lucic, Maartje ter Hoeve, Gabriele Tolomei, Maarten de Rijke, Fabrizio Silvestri","Given the increasing promise of graph neural networks (GNNs) in real-world
applications, several methods have been developed for explaining their
predictions. Existing methods for interpreting predictions from GNNs have
primarily focused on generating subgraphs that are especially relevant for a
particular prediction. However, such methods are not counterfactual (CF) in
nature: given a prediction, we want to understand how the prediction can be
changed in order to achieve an alternative outcome. In this work, we propose a
method for generating CF explanations for GNNs: the minimal perturbation to the
input (graph) data such that the prediction changes. Using only edge deletions,
we find that our method, CF-GNNExplainer, can generate CF explanations for the
majority of instances across three widely used datasets for GNN explanations,
while removing less than 3 edges on average, with at least 94\% accuracy. This
indicates that CF-GNNExplainer primarily removes edges that are crucial for the
original predictions, resulting in minimal CF explanations.",http://arxiv.org/abs/2102.03322v4
Hydrogen Atom in the Cosmic Microwave Background,2021-02-06T02:48:44Z,Jose A. Magpantay,"The cosmic microwave background covers the entire universe, which suggests
the absence of ay closed system, except the universe itself. In this paper, I
consider the effect of the cosmic microwave background on the hydrogen atom,
which must be very small, otherwise, changes in energy levels would have been
measurable. But how small is small? This I compute by considering a system in
an environment or bath. I derived the bath's, (in this case the CMB) effect on
the hydrogen atom in the Feynman-Vernon approach to an open system. The effect
is small and quantified in terms of a correction to the hydrogen atom that
breaks time-reversal symmetry, as expected of memory effects. This is
significant. There are imperceptible changes in the state of the hydrogen atom,
which means that the pervasive CMB must have similar small effects on other
atoms, thus breaking time-reversal symmetry in all physical systems.",http://arxiv.org/abs/2102.03484v1
"Jointly Improving Language Understanding and Generation with
  Quality-Weighted Weak Supervision of Automatic Labeling",2021-02-06T10:06:15Z,"Ernie Chang, Vera Demberg, Alex Marin","Neural natural language generation (NLG) and understanding (NLU) models are
data-hungry and require massive amounts of annotated data to be competitive.
Recent frameworks address this bottleneck with generative models that
synthesize weak labels at scale, where a small amount of training labels are
expert-curated and the rest of the data is automatically annotated. We follow
that approach, by automatically constructing a large-scale weakly-labeled data
with a fine-tuned GPT-2, and employ a semi-supervised framework to jointly
train the NLG and NLU models. The proposed framework adapts the parameter
updates to the models according to the estimated label-quality. On both the E2E
and Weather benchmarks, we show that this weakly supervised training paradigm
is an effective approach under low resource scenarios and outperforming
benchmark systems on both datasets when 100% of training data is used.",http://arxiv.org/abs/2102.03551v1
"Study of $C$ parity violating and strangeness changing $J/ψ$
  ${\to}$ $PP$ weak decays",2021-02-06T13:09:13Z,"Yueling Yang, Junliang Lu, Mingfei Duan, Jinshu Huang, Junfeng Sun","The $J/{\psi}$ weak decays are rare but possible within the standard model of
elementary particles. Inspired by the potential prospects at the future
intensity frontier, the $C$ parity violating $J/{\psi}$ ${\to}$
${\pi}{\eta}^{({\prime})}$, ${\eta}{\eta}^{\prime}$ decays and the strangeness
changing $J/{\psi}$ ${\to}$ ${\pi}K$, $K{\eta}^{({\prime})}$ decays are studied
with the perturbative QCD approach. It is found that the $J/{\psi}$ ${\to}$
${\eta}{\eta}^{\prime}$ decays have relatively large branching ratios, about
the order of $10^{-11}$, which might be within the measurement capability and
sensitivity of the future STCF experiment.",http://arxiv.org/abs/2102.03580v3
Non-gaussianities for primordial black hole formation,2021-02-06T16:51:28Z,"Marco Taoso, Alfredo Urbano","We analyze primordial non-gaussianities in presence of an ultra-slow phase
during the inflationary dynamics, focusing on scenarios relevant for the
production of primordial black holes. We compute the three-point correlation
function of comoving curvature perturbations finding that non-gaussianities are
sizable, and predominantly local. In the context of threshold statistics, we
analyze their impact for the abundance of primordial black holes, and their
interplay with the non-gaussianities arising from the non-linear relation
between density and curvature perturbations. We find that non-gaussianities
significantly modify the estimate of the primordial black holes abundance
obtained with the gaussian approximation. However, we show that this effect can
be compensated by a small change, of a factor $2\div3$ at most, of the
amplitude of the primordial power spectrum of curvature perturbations. This is
obtained with a small tuning of the parameters of the inflationary model.",http://arxiv.org/abs/2102.03610v2
