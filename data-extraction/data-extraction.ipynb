{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def fetch_arxiv_papers_by_year(query=\"climate change\", year=2020, max_results=10):\n",
    "    \"\"\"\n",
    "    Fetches academic papers related to a query from arXiv that were submitted in a given year.\n",
    "\n",
    "    Parameters:\n",
    "    - query (str): The search term (e.g., \"climate change\").\n",
    "    - year (int): The year to filter papers by submission date.\n",
    "    - max_results (int): Maximum number of papers to retrieve for that year.\n",
    "\n",
    "    Returns:\n",
    "    - List of dictionaries containing Title, Published date, Authors, Abstract, and Link.\n",
    "    \"\"\"\n",
    "    base_url = \"http://export.arxiv.org/api/query\"\n",
    "\n",
    "    # Construct date range for the year: YYYY01010000 to YYYY12312359\n",
    "    date_from = f\"{year}01010000\"\n",
    "    date_to   = f\"{year}12312359\"\n",
    "    \n",
    "    # Construct the search query with the date range.\n",
    "    search_query = f\"all:{query} AND submittedDate:[{date_from} TO {date_to}]\"\n",
    "    \n",
    "    params = {\n",
    "        \"search_query\": search_query,\n",
    "        \"start\": 0,\n",
    "        \"max_results\": max_results,\n",
    "        \"sortBy\": \"relevance\",\n",
    "        \"sortOrder\": \"descending\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(base_url, params=params)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch data from arXiv for year {year}\")\n",
    "        return []\n",
    "    \n",
    "    root = ET.fromstring(response.text)\n",
    "    papers = []\n",
    "    \n",
    "    for entry in root.findall(\"{http://www.w3.org/2005/Atom}entry\"):\n",
    "        title = entry.find(\"{http://www.w3.org/2005/Atom}title\").text.strip()\n",
    "        abstract = entry.find(\"{http://www.w3.org/2005/Atom}summary\").text.strip()\n",
    "        link = entry.find(\"{http://www.w3.org/2005/Atom}id\").text.strip()\n",
    "        \n",
    "        # Get the published date\n",
    "        published = entry.find(\"{http://www.w3.org/2005/Atom}published\").text.strip() if entry.find(\"{http://www.w3.org/2005/Atom}published\") is not None else \"N/A\"\n",
    "        \n",
    "        # Aggregate authors (there can be multiple author tags)\n",
    "        authors = []\n",
    "        for author in entry.findall(\"{http://www.w3.org/2005/Atom}author\"):\n",
    "            name = author.find(\"{http://www.w3.org/2005/Atom}name\").text.strip()\n",
    "            authors.append(name)\n",
    "        authors_str = \", \".join(authors)\n",
    "        \n",
    "        papers.append({\n",
    "            \"Title\": title,\n",
    "            \"Published\": published,\n",
    "            \"Authors\": authors_str,\n",
    "            \"Abstract\": abstract,\n",
    "            \"Link\": link\n",
    "        })\n",
    "        \n",
    "    return papers\n",
    "\n",
    "def fetch_and_save_by_year(years, query=\"climate change\", max_results=10):\n",
    "    \"\"\"\n",
    "    For each year provided, fetch papers from arXiv and save the results\n",
    "    into a CSV file named \"climate_papers_{year}.csv\".\n",
    "    \n",
    "    Parameters:\n",
    "    - years (list of int): List of years to process.\n",
    "    - query (str): The search query for the papers.\n",
    "    - max_results (int): The maximum number of papers per year.\n",
    "    \"\"\"\n",
    "    for year in years:\n",
    "        print(f\"Fetching papers for {year}...\")\n",
    "        papers_data = fetch_arxiv_papers_by_year(query=query, year=year, max_results=max_results)\n",
    "        \n",
    "        if papers_data:\n",
    "            df = pd.DataFrame(papers_data)\n",
    "            filename = f\"climate_papers_{year}.csv\"\n",
    "            df.to_csv(filename, index=False)\n",
    "            print(f\"Data for {year} saved to {filename}\")\n",
    "        else:\n",
    "            print(f\"No data fetched for {year}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching papers for 2019...\n",
      "Data for 2019 saved to climate_papers_2019.csv\n",
      "Fetching papers for 2020...\n",
      "Data for 2020 saved to climate_papers_2020.csv\n",
      "Fetching papers for 2021...\n",
      "Data for 2021 saved to climate_papers_2021.csv\n"
     ]
    }
   ],
   "source": [
    "fetch_and_save_by_year(years=[2019, 2020, 2021], query=\"climate change\", max_results=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching papers for 2022...\n",
      "Data for 2022 saved to climate_papers_2022.csv\n",
      "Fetching papers for 2023...\n",
      "Data for 2023 saved to climate_papers_2023.csv\n",
      "Fetching papers for 2024...\n",
      "Data for 2024 saved to climate_papers_2024.csv\n",
      "Fetching papers for 2025...\n",
      "Data for 2025 saved to climate_papers_2025.csv\n"
     ]
    }
   ],
   "source": [
    "fetch_and_save_by_year(years=[2022, 2023, 2024, 2025], query=\"climate change\", max_results=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
