Title,Published,Authors,Abstract,Link
Climate Modeling and Bifurcation,2019-07-15T15:45:48Z,Mayer Humi,"Many papers and monographs were written about the modeling the Earth climate
and its variability. However there is still an obvious need for a module that
presents the fundamentals of climate modeling to students at the undergraduate
level. The present educational paper attempts to fill in this gap. To this end
we collect in this paper the relevant climate data and present a simple zero
and one dimensional models for the mean temperature of the Earth. These models
can exhibit bifurcations from the present Earth climate to an ice age or a
""Venus type of climate"". The models are accompanied by Matlab programs which
enable the user to change the models parameters and explore the impact that
these changes might have on their predictions on Earth climate.",http://arxiv.org/abs/1907.11067v2
The Physics of Climate Variability and Climate Change,2019-10-01T12:43:54Z,"Michael Ghil, Valerio Lucarini","The climate system is a forced, dissipative, nonlinear, complex and
heterogeneous system that is out of thermodynamic equilibrium. The system
exhibits natural variability on many scales of motion, in time as well as
space, and it is subject to various external forcings, natural as well as
anthropogenic. This paper reviews the observational evidence on climate
phenomena and the governing equations of planetary-scale flow, as well as
presenting the key concept of a hierarchy of models as used in the climate
sciences. Recent advances in the application of dynamical systems theory, on
the one hand, and of nonequilibrium statistical physics, on the other, are
brought together for the first time and shown to complement each other in
helping understand and predict the system's behavior. These complementary
points of view permit a self-consistent handling of subgrid-scale phenomena as
stochastic processes, as well as a unified handling of natural climate
variability and forced climate change, along with a treatment of the crucial
issues of climate sensitivity, response, and predictability.",http://arxiv.org/abs/1910.00583v2
"Learning Twitter User Sentiments on Climate Change with Limited Labeled
  Data",2019-04-15T21:51:21Z,"Allison Koenecke, Jordi Feliu-Fabà","While it is well-documented that climate change accepters and deniers have
become increasingly polarized in the United States over time, there has been no
large-scale examination of whether these individuals are prone to changing
their opinions as a result of natural external occurrences. On the
sub-population of Twitter users, we examine whether climate change sentiment
changes in response to five separate natural disasters occurring in the U.S. in
2018. We begin by showing that relevant tweets can be classified with over 75%
accuracy as either accepting or denying climate change when using our
methodology to compensate for limited labeled data; results are robust across
several machine learning models and yield geographic-level results in line with
prior research. We then apply RNNs to conduct a cohort-level analysis showing
that the 2018 hurricanes yielded a statistically significant increase in
average tweet sentiment affirming climate change. However, this effect does not
hold for the 2018 blizzard and wildfires studied, implying that Twitter users'
opinions on climate change are fairly ingrained on this subset of natural
disasters.",http://arxiv.org/abs/1904.07342v1
"Weathering Adaptation: Grid Infrastructure Planning in a Changing
  Climate",2019-12-05T23:31:17Z,"Anna M. Brockway, Laurel N. Dunn","Decisions related to electric power systems planning and operations rely on
assumptions and insights informed by historic weather data and records of past
performance. Evolving climate trends are, however, changing the energy use
patterns and operating conditions of grid assets, thus altering the nature and
severity of risks the system faces. Because grid assets remain in operation for
decades, planning for evolving risks will require incorporating climate
projections into grid infrastructure planning processes. The current work
traces a pathway for climate-aware decision-making in the electricity sector.
We evaluate the suitability of using existing climate models and data for
electricity planning and discuss their limitations. We review the interactions
between grid infrastructure and climate by synthesizing what is known about how
changing environmental operating conditions would impact infrastructure
utilization, constraints, and performance. We contextualize our findings by
presenting a case study of California, examining if and where climate data can
be integrated into infrastructure planning processes. The core contribution of
the work is a series of nine recommendations detailing advancements in climate
projections, grid modeling architecture, and disaster preparedness that would
be needed to ensure that infrastructure planning decisions are robust to
uncertainty and risks associated with evolving climate conditions.",http://arxiv.org/abs/1912.02920v1
"Beyond Forcing Scenarios: Predicting Climate Change through Response
  Operators in a Coupled General Circulation Model",2019-12-09T12:28:30Z,"Valerio Lembo, Valerio Lucarini, Francesco Ragone","Global Climate Models are key tools for predicting the future response of the
climate system to a variety of natural and anthropogenic forcings. Here we show
how to use statistical mechanics to construct operators able to flexibly
predict climate change for a variety of climatic variables of interest. We
perform our study on a fully coupled model - MPI-ESM v.1.2 - and for the first
time we prove the effectiveness of response theory in predicting future climate
response to CO$_2$ increase on a vast range of temporal scales, from
inter-annual to centennial, and for very diverse climatic quantities. We
investigate within a unified perspective the transient climate response and the
equilibrium climate sensitivity and assess the role of fast and slow processes.
The prediction of the ocean heat uptake highlights the very slow relaxation to
a newly established steady state. The change in the Atlantic Meridional
Overturning Circulation (AMOC) and of the Antarctic Circumpolar Current (ACC)
is accurately predicted. The AMOC strength is initially reduced and then
undergoes a slow and only partial recovery. The ACC strength initially
increases as a result of changes in the wind stress, then undergoes a slowdown,
followed by a recovery leading to a overshoot with respect to the initial
value. Finally, we are able to predict accurately the temperature change in the
Northern Atlantic.",http://arxiv.org/abs/1912.03996v2
"Visualizing the Consequences of Climate Change Using Cycle-Consistent
  Adversarial Networks",2019-05-02T15:34:53Z,"Victor Schmidt, Alexandra Luccioni, S. Karthik Mukkavilli, Narmada Balasooriya, Kris Sankaran, Jennifer Chayes, Yoshua Bengio","We present a project that aims to generate images that depict accurate,
vivid, and personalized outcomes of climate change using Cycle-Consistent
Adversarial Networks (CycleGANs). By training our CycleGAN model on street-view
images of houses before and after extreme weather events (e.g. floods, forest
fires, etc.), we learn a mapping that can then be applied to images of
locations that have not yet experienced these events. This visual
transformation is paired with climate model predictions to assess likelihood
and type of climate-related events in the long term (50 years) in order to
bring the future closer in the viewers mind. The eventual goal of our project
is to enable individuals to make more informed choices about their climate
future by creating a more visceral understanding of the effects of climate
change, while maintaining scientific credibility by drawing on climate model
projections.",http://arxiv.org/abs/1905.03709v1
"Learning Radiative Transfer Models for Climate Change Applications in
  Imaging Spectroscopy",2019-06-08T15:39:32Z,"Shubhankar Deshpande, Brian D. Bue, David R. Thompson, Vijay Natraj, Mario Parente","According to a recent investigation, an estimated 33-50% of the world's coral
reefs have undergone degradation, believed to be as a result of climate change.
A strong driver of climate change and the subsequent environmental impact are
greenhouse gases such as methane. However, the exact relation climate change
has to the environmental condition cannot be easily established. Remote sensing
methods are increasingly being used to quantify and draw connections between
rapidly changing climatic conditions and environmental impact. A crucial part
of this analysis is processing spectroscopy data using radiative transfer
models (RTMs) which is a computationally expensive process and limits their use
with high volume imaging spectrometers. This work presents an algorithm that
can efficiently emulate RTMs using neural networks leading to a multifold
speedup in processing time, and yielding multiple downstream benefits.",http://arxiv.org/abs/1906.03479v1
"Domino Effects in the Earth System -- The potential role of wanted
  tipping points",2019-11-12T16:25:23Z,"Marc Wiedermann, Ricarda Winkelmann, Jonathan F. Donges, Christina Eder, Jobst Heitzig, Alexia Katsanidou, E. Keith Smith","Vital parts of the climate system, such as the West Antarctic Ice Sheet, are
at risk even within the aspired aims of the Paris Agreement to limit global
temperature rise to 1.5 -- 2{\deg}C. These so-called natural tipping elements
are characterized by rapid qualitative shifts in their states once a critical
threshold, e.g., of global mean temperature, is transgressed. We argue that the
prevention of such unwanted tipping through effective climate policies may
critically depend on cascading Domino effects from (anticipated) climate
impacts to emission reductions via wanted social tipping in attitudes,
behaviors and policies. Specifically, the latter has recently been noted as a
key aspect in addressing contemporary global challenges, such as climate
change, via self-amplifying positive feedbacks similar to the processes
observable in climate tipping elements. Our discussion is supported with data
on commonly observed linkages between (subjective) climate change knowledge,
concern and consequential potential action and we argue that the presence of
such interrelations serves as a necessary condition for the possibility of
rapid climate action.",http://arxiv.org/abs/1911.10063v2
"The maximum likelihood climate change for global warming under the
  influence of greenhouse effect and Lévy noise",2019-09-06T15:44:40Z,"Yayun Zheng, Fang Yang, Jinqiao Duan, Xu Sun, Ling Fu, Jürgen Kurths","An abrupt climatic transition could be triggered by a single extreme event,
an $\alpha$-stable non-Gaussian L\'evy noise is regarded as a type of noise to
generate such extreme events. In contrast with the classic Gaussian noise, a
comprehensive approach of the most probable transition path for systems under
$\alpha$-stable L\'evy noise is still lacking. We develop here a probabilistic
framework, based on the nonlocal Fokker-Planck equation, to investigate the
maximum likelihood climate change for an energy balance system under the
influence of greenhouse effect and L\'evy fluctuations. We find that a period
of the cold climate state can be interrupted by a sharp shift to the warmer one
due to larger noise jumps, and the climate change for warming $1.5\rm ^oC$
under an enhanced greenhouse effect generates a step-like growth process. These
results provide important insights into the underlying mechanisms of abrupt
climate transitions triggered by a L\'evy process.",http://arxiv.org/abs/1909.08693v1
"Measuring Impact of Climate Change on Tree Species: analysis of JSDM on
  FIA data",2019-10-11T01:35:13Z,"Hyun Choi, Ali Sadeghian, Sergio Marconi, Ethan White, Daisy Zhe Wang","One of the first beings affected by changes in the climate are trees, one of
our most vital resources. In this study tree species interaction and the
response to climate in different ecological environments is observed by
applying a joint species distribution model to different ecological domains in
the United States. Joint species distribution models are useful to learn
inter-species relationships and species response to the environment. The
climates' impact on the tree species is measured through species abundance in
an area. We compare the model's performance across all ecological domains and
study the sensitivity of the climate variables. With the prediction of
abundances, tree species populations can be predicted in the future and measure
the impact of climate change on tree populations.",http://arxiv.org/abs/1910.04932v1
Recovering the parameters underlying the Lorenz-96 chaotic dynamics,2019-06-16T22:20:05Z,"Soukayna Mouatadid, Pierre Gentine, Wei Yu, Steve Easterbrook","Climate projections suffer from uncertain equilibrium climate sensitivity.
The reason behind this uncertainty is the resolution of global climate models,
which is too coarse to resolve key processes such as clouds and convection.
These processes are approximated using heuristics in a process called
parameterization. The selection of these parameters can be subjective, leading
to significant uncertainties in the way clouds are represented in global
climate models. Here, we explore three deep network algorithms to infer these
parameters in an objective and data-driven way. We compare the performance of a
fully-connected network, a one-dimensional and, a two-dimensional convolutional
networks to recover the underlying parameters of the Lorenz-96 model, a
non-linear dynamical system that has similar behavior to the climate system.",http://arxiv.org/abs/1906.06786v1
Climate Change and Social Sciences: a bibliometric analysis,2019-02-02T13:00:26Z,"Flavio C. D. Moraes, Ana Lia Leonel, Pedro H. C. Torres, Pedro R. Jacobi, Sandra Momm","The complexity of emergent wicked problems, such as climate change,
culminates in a reformulation of how we think about society and mobilize
scientists from various disciplines to seek solutions and perspectives on the
problem. From an epistemological point of view, it is essential to evaluate how
such topics can be developed inside the academic arena but, to do that, it is
necessary to perform complex analysis of the great number of recent academic
publications. In this work, we discuss how climate change has been addressed by
social sciences in practice. Can we observe the development of a new
epistemology by the emergence of the climate change debate? Are there
contributions in academic journals within the field of social sciences
addressing climate change? Which journals are these? Who are the authors? To
answer these questions, we developed an innovative method combining different
tools to search, filter, and analyze the impact of the academic production
related to climate change in social sciences in the most relevant journals.",http://arxiv.org/abs/1902.00712v3
Climate Change and Grain Production Fluctuations,2019-12-29T10:44:39Z,"Giuliano Vitali, Sergei Rogosin, Guido Baldoni","50 year-long time series from a Long Term Agronomic Experiment have been used
to to investigate the effects of climate change on yields of Wheat and Maize.
Trends and fluctuations, useful to estimate production forecasts and related
risks are compared to national ones, a classical regional climatic index as
Western Mediterranean Oscillation Index, and a global one given by Sun Spot
Number. Data, denoised by EMD and SSA, show how SSN oscillations slowing down
in the last decades, affects regional scale dynamics, where in the last two
decades a range of fluctuations (7-16 years) are also evident. Both signals
reflects on yield fluctuations of Wheat and Maize both a national and local
level.",http://arxiv.org/abs/2002.07039v1
"Modelling the climate and weather of a 2D Lagrangian-averaged
  Euler-Boussinesq equation with transport noise",2019-09-01T12:30:52Z,"Diego Alonso-Oran, Aythami Bethencourt de Leon, Darryl Holm, So Takao","The prediction of climate change and its impact on extreme weather events is
one of the great societal and intellectual challenges of our time. The first
part of the problem is to make the distinction between weather and climate. The
second part is to understand the dynamics of the fluctuations of the physical
variables. The third part is to predict how the variances of the fluctuations
are affected by statistical correlations in their fluctuating dynamics. This
paper investigates a framework called LA SALT which can meet all three parts of
the challenge for the problem of climate change. As a tractable example of this
framework, we consider the Euler--Boussinesq (EB) equations for an
incompressible stratified fluid flowing under gravity in a vertical plane with
no other external forcing. All three parts of the problem are solved for this
case. In fact, for this problem, the framework also delivers global
well-posedness of the dynamics of the physical variables and closed dynamical
equations for the moments of their fluctuations. Thus, in a well-posed
mathematical setting, the framework developed in this paper shows that the mean
field dynamics combines with an intricate array of correlations in the
fluctuation dynamics to drive the evolution of the mean statistics. The results
of the framework for 2D EB model analysis define its climate, as well as
climate change, weather dynamics, and change of weather statistics, all in the
context of a model system of SPDEs with unique global strong solutions.",http://arxiv.org/abs/1909.00388v1
"Stability of a planetary climate system with the biosphere competing for
  resources",2019-02-21T09:50:50Z,"Sergey A. Vakulenko, Ivan Sudakov, Sergei V. Petrovskii, Dmitry V. Lukichev","With the growing number of discovered exoplanets, the Gaia concept finds its
second wind. The Gaia concept defines that the biosphere of an inhabited planet
regulates a planetary climate through feedback loops such that the planet
remains habitable. Crunching 'Gaia' puzzle has been a focus of intense
empirical research. Much less attention has been paid to the mathematical
realization of this concept. In this paper, we consider the stability of a
planetary climate system with the dynamic biosphere by linking a conceptual
climate model to a generic population dynamics model with random parameters. We
first show that the dynamics of the corresponding coupled system possesses
multiple timescales and hence falls into the class of slow-fast dynamics. We
then investigate the properties of a general dynamical system to which our
model belongs and prove that the feedbacks from the biosphere dynamics cannot
break the system's stability as long as the biodiversity is sufficiently high.
That may explain why the climate is apparently stable over long time intervals.
Interestingly, our coupled climate-biosphere system can lose its stability if
biodiversity decreases; in this case, the evolution of the biosphere under the
effect of random factors can lead to a global climate change.",http://arxiv.org/abs/1902.07936v3
"Evaluating proxy influence in assimilated paleoclimate reconstructions
  -- Testing the exchangeability of two ensembles of spatial processes",2019-09-03T16:12:35Z,"Trevor Harris, Bo Li, Nathan Steiger, Jason Smerdon, Naveen Narisetty, Derek Tucker","Climate field reconstructions (CFR) attempt to estimate spatiotemporal fields
of climate variables in the past using climate proxies such as tree rings, ice
cores, and corals. Data Assimilation (DA) methods are a recent and promising
new means of deriving CFRs that optimally fuse climate proxies with climate
model output. Despite the growing application of DA-based CFRs, little is
understood about how much the assimilated proxies change the statistical
properties of the climate model data. To address this question, we propose a
robust and computationally efficient method, based on functional data depth, to
evaluate differences in the distributions of two spatiotemporal processes. We
apply our test to study global and regional proxy influence in DA-based CFRs by
comparing the background and analysis states, which are treated as two samples
of spatiotemporal fields. We find that the analysis states are significantly
altered from the climate-model-based background states due to the assimilation
of proxies. Moreover, the difference between the analysis and background states
increases with the number of proxies, even in regions far beyond proxy
collection sites. Our approach allows us to characterize the added value of
proxies, indicating where and when the analysis states are distinct from the
background states.",http://arxiv.org/abs/1909.01273v2
Embedding Climate Change Engagement in Astronomy Education and Research,2019-07-18T13:38:22Z,"Kathryn Williamson, Travis A. Rector, James Lowenthal","This White Paper is a call to action for astronomers to respond to climate
change with a large structural transition within our profession. Many
astronomers are deeply concerned about climate change and act upon it in their
personal and professional lives, and many organizations within astronomy have
incorporated incremental changes. We need a collective impact model to better
network and grow our efforts so that we can achieve results that are on the
scale appropriate to address climate change at the necessary level indicated by
scientific research; e.g., becoming carbon neutral by 2050. We need to
implement strategies within two primary drivers of our field: (1) Education and
Outreach, and (2) Research Practices and Infrastructure. (1) In the classroom
and through public talks, astronomers reach a large audience. Astronomy is
closely connected to the science of climate change, and it is arguably the most
important topic we include in our curriculum. Due to misinformation and
disinformation, climate change communication is different than for other areas
of science. We therefore need to expand our communication and implement
effective strategies, for which there is now a considerable body of research.
(2) On a per-person basis astronomers have an outsized carbon impact. There are
numerous ways we can reduce our footprint; e.g., in the design and operation of
telescope facilities and in the optimization and reduction of travel.
Fortunately, many of these solutions are win-win scenarios, e.g., increasing
the online presence of conferences will reduce the carbon footprint while
increasing participation, especially for astronomers working with fewer
financial resources. Astronomers have an obligation to act on climate change in
every way possible, and we need to do it now. In this White Paper, we outline a
plan for collective impact using a Networked Improvement Community (NIC)
approach.",http://arxiv.org/abs/1907.08043v1
"Response of Vertical Velocities in Extratropical Precipitation Extremes
  to Climate Change",2019-10-12T21:11:36Z,"Ziwei Li, Paul O'Gorman","Precipitation extremes intensify in most regions in climate-model
projections. Changes in vertical velocities contribute to the changes in
intensity of precipitation extremes but remain poorly understood. Here, we find
that mid-tropospheric vertical velocities in extratropical precipitation
extremes strengthen overall in simulations of 21st-century climate change. For
each extreme event, we solve the quasi-geostrophic omega equation to decompose
this strengthening into different physical contributions. We first consider a
dry decomposition in which latent heating is treated as an external forcing of
upward motion. Much of the positive contribution to upward motion from
increased latent heating is offset by negative contributions from increases in
dry static stability and changes in the horizontal length scale of vertical
velocities. However, taking changes in latent heating as given is a limitation
when the aim is to understand changes in precipitation, since latent heating
and precipitation are closely linked. Therefore, we also perform a moist
decomposition of the changes in vertical velocities in which latent heating is
represented through a moist static stability. In the moist decomposition,
changes in moist static stability play a key role and contributions from other
factors such as changes in the depth of the upward motion increase in
importance. While both dry and moist decompositions are self-consistent, the
moist dynamical perspective has greater potential to give insights into the
causes of the dynamical contributions to changes in precipitation extremes in
different regions.",http://arxiv.org/abs/1910.05644v2
"Achieving Conservation of Energy in Neural Network Emulators for Climate
  Modeling",2019-06-15T21:55:02Z,"Tom Beucler, Stephan Rasp, Michael Pritchard, Pierre Gentine","Artificial neural-networks have the potential to emulate cloud processes with
higher accuracy than the semi-empirical emulators currently used in climate
models. However, neural-network models do not intrinsically conserve energy and
mass, which is an obstacle to using them for long-term climate predictions.
Here, we propose two methods to enforce linear conservation laws in
neural-network emulators of physical models: Constraining (1) the loss function
or (2) the architecture of the network itself. Applied to the emulation of
explicitly-resolved cloud processes in a prototype multi-scale climate model,
we show that architecture constraints can enforce conservation laws to
satisfactory numerical precision, while all constraints help the neural-network
better generalize to conditions outside of its training set, such as global
warming.",http://arxiv.org/abs/1906.06622v1
Co-existing climate attractors in a coupled aquaplanet,2019-07-07T08:54:10Z,"Maura Brunetti, Jérôme Kasparian, Christian Vérard","The first step in exploring the properties of dynamical systems like the
Earth climate is to identify the different phase space regions where the
trajectories asymptotically evolve, called `attractors'. In a given system,
multiple attractors can co-exist under the effect of the same forcing. At the
boundaries of their basins of attraction, small changes produce large effects.
Therefore, they are key regions for understanding the system response to
perturbations. Here we prove the existence of up to five attractors in a
simplified climate system where the planet is entirely covered by the ocean
(aquaplanet). These attractors range from a snowball to a hot state without sea
ice, and their exact number depends on the details of the coupled
atmosphere-ocean-sea ice configuration. We characterise each attractor by
describing the associated climate feedbacks, by using the principal component
analysis, and by measuring quantities borrowed from the study of dynamical
systems, namely instantaneous dimension and persistence.",http://arxiv.org/abs/1907.03255v2
Predicting ice flow using machine learning,2019-10-20T07:56:18Z,"Yimeng Min, S. Karthik Mukkavilli, Yoshua Bengio","Though machine learning has achieved notable success in modeling sequential
and spatial data for speech recognition and in computer vision, applications to
remote sensing and climate science problems are seldom considered. In this
paper, we demonstrate techniques from unsupervised learning of future video
frame prediction, to increase the accuracy of ice flow tracking in
multi-spectral satellite images. As the volume of cryosphere data increases in
coming years, this is an interesting and important opportunity for machine
learning to address a global challenge for climate change, risk management from
floods, and conserving freshwater resources. Future frame prediction of ice
melt and tracking the optical flow of ice dynamics presents modeling
difficulties, due to uncertainties in global temperature increase, changing
precipitation patterns, occlusion from cloud cover, rapid melting and glacier
retreat due to black carbon aerosol deposition, from wildfires or human fossil
emissions. We show the adversarial learning method helps improve the accuracy
of tracking the optical flow of ice dynamics compared to existing methods in
climate science. We present a dataset, IceNet, to encourage machine learning
research and to help facilitate further applications in the areas of
cryospheric science and climate change.",http://arxiv.org/abs/1910.08922v1
"Impact of climate change on the cost-optimal mix of decentralised heat
  pump and gas boiler technologies in Europe",2019-07-09T10:12:47Z,"S. Kozarcanin, R. Hanna, I. Staffell, R. Gross, G. B. Andresen","Residential demands for space heating and hot water account for 31% of the
total European energy demand. Space heating is highly dependent on ambient
conditions and susceptible to climate change. We adopt a techno-economic
standpoint and assess the impact of climate change on decentralised heating
demand and the cost-optimal mix of heat pump and gas boiler technologies.
Temperature data with high spatial resolution from nine climate models
implementing three Representative Concentration Pathways from IPCC are used to
estimate climate induced changes in the European demand side for heating. The
demand side is modelled by the proxy of heating-degree days. The supply side is
modelled by using a screening curve approach to the economics of heat
generation. We find that space heating demand decreases by about 16%, 24% and
42% in low, intermediate and extreme global warming scenarios. When considering
historic weather data, we find a heterogeneous mix of technologies are
cost-optimal, depending on the heating load factor (number of full-load hours
per year). Increasing ambient temperatures toward the end-century improve the
economic performance of heat pumps in all concentration pathways. Cost optimal
technologies broadly correspond to heat markets and policies in Europe, with
some exceptions",http://arxiv.org/abs/1907.04067v4
"Combining interdependent climate model outputs in CMIP5: A spatial
  Bayesian approach",2019-12-31T20:50:31Z,"Huang Huang, Dorit Hammerling, Bo Li, Richard Smith","Projections of future climate change rely heavily on climate models, and
combining climate models through a multi-model ensemble is both more accurate
than a single climate model and valuable for uncertainty quantification.
However, Bayesian approaches to multi-model ensembles have been criticized for
making oversimplified assumptions about bias and variability, as well as
treating different models as statistically independent. This paper extends the
Bayesian hierarchical approach of Sansom et al. (2017) by explicitly accounting
for spatial variability and inter-model dependence. We propose a Bayesian
hierarchical model that accounts for bias between climate models and
observations, spatial and inter-model dependence, the emergent relationship
between historical and future periods, and natural variability. Extensive
simulations show that our model provides better estimates and uncertainty
quantification than the commonly used simple model mean. These results are
illustrated using data from the CMIP5 model archive. As examples, for Central
North America our projected mean temperature for 2070--2100 is about 0.8 K
lower than the simple model mean, while for East Asia it is about 0.5 K higher;
however, in both cases, the widths of the 90% credible intervals are of the
order 3--6 K, so the uncertainties overwhelm the relatively small differences
in projected mean temperatures.",http://arxiv.org/abs/2001.00074v2
"The Climates of Other Worlds: A Review of the Emerging Field of
  Exoplanet Climatology",2019-09-09T18:00:02Z,Aomawa L. Shields,"The discovery of planets orbiting stars other than the Sun has accelerated
over the past decade, and this trend will continue as new space- and
ground-based observatories employ next-generation instrumentation to search the
skies for habitable worlds. However, many factors and processes can affect
planetary habitability and must be understood to accurately determine a
planet's habitability potential. While climate models have long been used to
understand and predict climate and weather patterns on the Earth, a growing
community of researchers has begun to apply these models to extrasolar planets.
This work has provided a better understanding of how orbital, surface, and
atmospheric properties affect planetary climate and habitability; how these
climatic effects might change for different stellar and planetary environments;
and how the habitability and observational signatures of newly discovered
planets might be influenced by these climatic factors. This review summarizes
the origins and evolution of the burgeoning field of exoplanet climatology,
discusses recent work using a hierarchy of computer models to identify those
planets most capable of supporting life, and offers a glimpse into future
directions of this quickly evolving subfield of exoplanet science.",http://arxiv.org/abs/1909.04046v1
Impact of large scale climate oscillation on drought in West Africa,2019-01-29T07:42:35Z,"Samuel T. Ogunjo, Ibiyinka A. Fuwape, Christiana F. Olusegun","Drought poses a significant threat to the delicate economies in subsaharan
Africa. This study investigates the influence of large scale ocean oscillation
on drought in West Africa. Standardized Precipitation Index for the region was
computed using monthly precipitation data from the Climate Research Unit during
the period 1961 -1990. The impact of three ocean oscillation indices - Southern
Ocean Index (SOI), Pacific Decadal Oscillation (PDO) and North Atlantic
Oscillation (NAO) on drought over West Africa was investigated using linear
correlation, co-integration test, mutual information and nonlinear
synchronization methods. SOI showed predominantly positive correlation with
drought over the region while PDO and NAO showed negative correlation. This was
confirmed by the co-integration tests. The nonlinear test revealed more complex
relationship between the indices and drought. PDO has lesser influence or
contribute less to the drought in the coastal region compared to the Sahel
region of West Africa.",http://arxiv.org/abs/1901.10145v1
The impact of stochastic physics on climate sensitivity in EC-Earth,2019-05-16T09:26:24Z,"K. Strommen, P. A. G. Watson, T. N. Palmer","Stochastic schemes, designed to represent unresolved sub-grid scale
variability, are frequently used in short and medium-range weather forecasts,
where they are found to improve several aspects of the model. In recent years,
the impact of stochastic physics has also been found to be beneficial for the
model's long term climate. In this paper, we demonstrate for the first time
that the inclusion of a stochastic physics scheme can notably affect a model's
projection of global warming, as well as its historical climatological global
temperature. Specifically, we find that when including the 'stochastically
perturbed parametrisation tendencies' scheme (SPPT) in the fully coupled
climate model EC-Earth v3.1, the predicted level of global warming between 1850
and 2100 is reduced by 10% under an RCP8.5 forcing scenario. We link this
reduction in climate sensitivity to a change in the cloud feedbacks with SPPT.
In particular, the scheme appears to reduce the positive low cloud cover
feedback, and increase the negative cloud optical feedback. A key role is
played by a robust, rapid increase in cloud liquid water with SPPT, which we
speculate is due to the scheme's non-linear interaction with condensation.",http://arxiv.org/abs/1905.06613v1
Multivariate statistical modelling of future marine storms,2019-03-13T21:38:58Z,"Jue Lin-Ye, Manuel García-León, Vicente Gràcia, Maribel Ortego, Piero Lionello, Agustín Sanchez-Arcilla","Extreme events, such as wave-storms, need to be characterized for coastal
infrastructure design purposes. Such description should contain information on
both the univariate behaviour and the joint-dependence of storm-variables.
These two aspects have been here addressed through generalized Pareto
distributions and hierarchical Archimedean copulas. A non-stationary model has
been used to highlight the relationship between these extreme events and
non-stationary climate. It has been applied to a Representative Concentration
Pathway 8.5 Climate-Change scenario, for a fetch-limited environment (Catalan
Coast). In the non-stationary model, all considered variables decrease in time,
except for storm-duration at the northern part of the Catalan Coast. The joint
distribution of storm variables presents cyclical fluctuations, with a stronger
influence of climate dynamics than of climate itself.",http://arxiv.org/abs/1903.05727v1
"Probability Assessments of an Ice-Free Arctic: Comparing Statistical and
  Climate Model Projections",2019-12-23T12:52:04Z,"Francis X. Diebold, Glenn D. Rudebusch","The downward trend in the amount of Arctic sea ice has a wide range of
environmental and economic consequences including important effects on the pace
and intensity of global climate change. Based on several decades of satellite
data, we provide statistical forecasts of Arctic sea ice extent during the rest
of this century. The best fitting statistical model indicates that overall sea
ice coverage is declining at an increasing rate. By contrast, average
projections from the CMIP5 global climate models foresee a gradual slowing of
Arctic sea ice loss even in scenarios with high carbon emissions. Our
long-range statistical projections also deliver probability assessments of the
timing of an ice-free Arctic. These results indicate almost a 60 percent chance
of an effectively ice-free Arctic Ocean sometime during the 2030s -- much
earlier than the average projection from the global climate models.",http://arxiv.org/abs/1912.10774v4
"VARENN: Graphical representation of spatiotemporal data and application
  to climate studies",2019-07-23T07:23:01Z,"Takeshi Ise, Yurika Oba","Analyzing and utilizing spatiotemporal big data are essential for studies
concerning climate change. However, such data are not fully integrated into
climate models owing to limitations in statistical frameworks. Herein, we
employ VARENN (visually augmented representation of environment for neural
networks) to efficiently summarize monthly observations of climate data for
1901-2016 into 2-dimensional graphical images. Using red, green, and blue
channels of color images, three different variables are simultaneously
represented in a single image. For global datasets, models were trained via
convolutional neural networks. These models successfully classified rises and
falls in temperature and precipitation. Moreover, similarities between the
input and target variables were observed to have a significant effect on model
accuracy. The input variables had both seasonal and interannual variations,
whose importance was quantified for model efficacy. VARENN is thus an effective
method to summarize spatiotemporal data objectively and accurately.",http://arxiv.org/abs/1907.09725v1
"Peak Electricity Demand and Global Warming in the Industrial and
  Residential areas of Pune : An Extreme Value Approach",2019-08-22T19:17:34Z,"Ayush Maheshwari, Kamal Kumar Murari, T. Jayaraman","Industrial and residential activities respond distinctly to electricity
demand on temperature. Due to increasing temperature trend on account of global
warming, its impact on peak electricity demand is a proxy for effective
management of electricity infrastructure. Few studies explore the relationship
between electricity demand and temperature changes in industrial areas in India
mainly due to the limitation of data. The precise role of industrial and
residential activities response to the temperature is not explored in
sub-tropical humid climate of India. Here, we show the temperature sensitivity
of industrial and residential areas in the city of Pune, Maharashtra by keeping
other influencing variables on electricity demand as constant. The study seeks
to estimate the behaviour of peak electricity demand with the apparent
temperature (AT) using the Extreme Value Theory. Our analysis shows that
industrial activities are not much influenced by the temperature whereas
residential activities show around 1.5-2% change in average electricity demand
with 1 degree rise in AT. Further, we show that peak electricity demand in
residential areas, performed using stationary and non-stationary GEV models,
are significantly influenced by the rise in temperature. The study shows that
with the improvement in data collection, better planning for the future
development, accounting for the climate change effects, will enhance the
effectiveness of electricity distribution system. The study is limited to the
geographical area of Pune. However, the methods are useful in estimating the
peak power load attributed to climate change to other geographical regions
located in subtropical and humid climate.",http://arxiv.org/abs/1908.08570v1
Tackling Climate Change with Machine Learning,2019-06-10T17:51:47Z,"David Rolnick, Priya L. Donti, Lynn H. Kaack, Kelly Kochanski, Alexandre Lacoste, Kris Sankaran, Andrew Slavin Ross, Nikola Milojevic-Dupont, Natasha Jaques, Anna Waldman-Brown, Alexandra Luccioni, Tegan Maharaj, Evan D. Sherwin, S. Karthik Mukkavilli, Konrad P. Kording, Carla Gomes, Andrew Y. Ng, Demis Hassabis, John C. Platt, Felix Creutzig, Jennifer Chayes, Yoshua Bengio","Climate change is one of the greatest challenges facing humanity, and we, as
machine learning experts, may wonder how we can help. Here we describe how
machine learning can be a powerful tool in reducing greenhouse gas emissions
and helping society adapt to a changing climate. From smart grids to disaster
management, we identify high impact problems where existing gaps can be filled
by machine learning, in collaboration with other fields. Our recommendations
encompass exciting research questions as well as promising business
opportunities. We call on the machine learning community to join the global
effort against climate change.",http://arxiv.org/abs/1906.05433v2
"The effect of geographic sampling on evaluation of extreme precipitation
  in high resolution climate models",2019-11-12T19:11:29Z,"Mark D. Risser, Michael F. Wehner","Traditional approaches for comparing global climate models and observational
data products typically fail to account for the geographic location of the
underlying weather station data. For modern high-resolution models, this is an
oversight since there are likely grid cells where the physical output of a
climate model is compared with a statistically interpolated quantity instead of
actual measurements of the climate system. In this paper, we quantify the
impact of geographic sampling on the relative performance of high resolution
climate models' representation of precipitation extremes in Boreal winter (DJF)
over the contiguous United States (CONUS), comparing model output from five
early submissions to the HighResMIP subproject of the CMIP6 experiment. We find
that properly accounting for the geographic sampling of weather stations can
significantly change the assessment of model performance. Across the models
considered, failing to account for sampling impacts the different metrics
(extreme bias, spatial pattern correlation, and spatial variability) in
different ways (both increasing and decreasing). We argue that the geographic
sampling of weather stations should be accounted for in order to yield a more
straightforward and appropriate comparison between models and observational
data sets, particularly for high resolution models. While we focus on the CONUS
in this paper, our results have important implications for other global land
regions where the sampling problem is more severe.",http://arxiv.org/abs/1911.05103v2
Detecting anthropogenic cloud perturbations with deep learning,2019-11-29T11:22:48Z,"Duncan Watson-Parris, Samuel Sutherland, Matthew Christensen, Anthony Caterini, Dino Sejdinovic, Philip Stier","One of the most pressing questions in climate science is that of the effect
of anthropogenic aerosol on the Earth's energy balance. Aerosols provide the
`seeds' on which cloud droplets form, and changes in the amount of aerosol
available to a cloud can change its brightness and other physical properties
such as optical thickness and spatial extent. Clouds play a critical role in
moderating global temperatures and small perturbations can lead to significant
amounts of cooling or warming. Uncertainty in this effect is so large it is not
currently known if it is negligible, or provides a large enough cooling to
largely negate present-day warming by CO2. This work uses deep convolutional
neural networks to look for two particular perturbations in clouds due to
anthropogenic aerosol and assess their properties and prevalence, providing
valuable insights into their climatic effects.",http://arxiv.org/abs/1911.13061v1
A direct approach to detection and attribution of climate change,2019-10-08T11:41:52Z,"Eniko Székely, Sebastian Sippel, Reto Knutti, Guillaume Obozinski, Nicolai Meinshausen","We present here a novel statistical learning approach for detection and
attribution (D&A) of climate change. Traditional optimal D&A studies try to
directly model the observations from model simulations, but practically this is
challenging due to high-dimensionality. Dimension reduction techniques reduce
the dimensionality, typically using empirical orthogonal functions, but as
these techniques are unsupervised, the reduced space considered is somewhat
arbitrary. Here, we propose a supervised approach where we predict a given
external forcing, e.g., anthropogenic forcing, directly from the spatial
pattern of climate variables, and use the predicted forcing as a test statistic
for D&A. We want the prediction to work well even under changes in the
distribution of other external forcings, e.g., solar or volcanic forcings, and
therefore formulate the optimization problem from a distributional robustness
perspective.",http://arxiv.org/abs/1910.03346v1
"Establishing an Evaluation Metric to Quantify Climate Change Image
  Realism",2019-10-22T17:59:38Z,"Sharon Zhou, Alexandra Luccioni, Gautier Cosne, Michael S. Bernstein, Yoshua Bengio","With success on controlled tasks, generative models are being increasingly
applied to humanitarian applications [1,2]. In this paper, we focus on the
evaluation of a conditional generative model that illustrates the consequences
of climate change-induced flooding to encourage public interest and awareness
on the issue. Because metrics for comparing the realism of different modes in a
conditional generative model do not exist, we propose several automated and
human-based methods for evaluation. To do this, we adapt several existing
metrics, and assess the automated metrics against gold standard human
evaluation. We find that using Fr\'echet Inception Distance (FID) with
embeddings from an intermediary Inception-V3 layer that precedes the auxiliary
classifier produces results most correlated with human realism. While
insufficient alone to establish a human-correlated automatic evaluation metric,
we believe this work begins to bridge the gap between human and automated
generative evaluation procedures.",http://arxiv.org/abs/1910.10143v1
"Scenarios for Educational and Game Activities using Internet of Things
  Data",2019-06-20T18:26:12Z,"Chrysanthi Tziortzioti, Irene Mavrommati, Georgios Mylonas, Andrea Vitaletti, Ioannis Chatzigiannakis","Raising awareness among young people and changing their behavior and habits
concerning energy usage and the environment is key to achieving a sustainable
planet. The goal to address the global climate problem requires informing the
population on their roles in mitigation actions and adaptation of sustainable
behaviors. Addressing climate change and achieve ambitious energy and climate
targets requires a change in citizen behavior and consumption practices. IoT
sensing and related scenario and practices, which address school children via
discovery, gamification, and educational activities, are examined in this
paper. Use of seawater sensors in STEM education, that has not previously been
addressed, is included in these educational scenaria.",http://arxiv.org/abs/1906.09934v1
"Dynamic virtual ecosystems as a tool for detecting large-scale responses
  of biodiversity to environmental and land-use change",2019-11-27T16:24:16Z,"Claire L. Harris, Neil Brummitt, Christina A. Cobbold, Richard Reeve","Ecosystems are governed by dynamic processes such as competition for
resources, reproduction and dispersal. These shape their biodiversity and how
the system responds to change. Current approaches to modelling ecosystems,
especially plants, focus on either describing fine-scale processes for
individual species or broad-scale patterns for limited groups of plant
functional types.
  Digitisation of herbarium and other plant records has unlocked a wealth of
information that can be used to drive models of plant communities and make
predictions for their future under different scenarios of climate change. The
advent of increased computational capacity and fast, high level programming
languages allows for simulation of such landscapes at unprecedented scales.
  Here, we demonstrate a tool for Ecosystem Simulation through Integrated
Species Trait-Environment Modelling (EcoSISTEM), which models plant species
across multiple ecosystem sizes, from patches and small islands to regions and
entire continents. These simulated ecosystems support the ability to generate
many different types of habitat, as well as reproducing different disturbance
scenarios such as climate change, habitat loss and invasion. EcoSISTEM also
reproduces examples of real-world species distributions by integrating plant
occurrence records and global climate reconstructions to simulate plant species
throughout the continent of Africa for the past century.
  EcoSISTEM allows us to flexibly explore the dynamics of tens of thousands of
species interacting across a continent. The code parallelises efficiently
across multiple nodes on high performance computing platforms, and has been
scaled up to run on over 1000 cores. It allows us to study the impact of
changes to climate, resources and habitat and investigate real-life mechanisms
surrounding climate change and biodiversity loss.",http://arxiv.org/abs/1911.12257v3
Robustness of Gaian Feedbacks to Climate Perturbations,2019-06-03T22:45:40Z,"Olivia D. N. Alcabes, Stephanie Olson, Dorian S. Abbot","The Gaia hypothesis postulates that life regulates its environment to be
favorable for its own survival. Most planets experience numerous perturbations
throughout their lifetimes such as asteroid impacts, volcanism, and the
evolution of their host star's luminosity. For the Gaia hypothesis to be
viable, life must be able to keep the conditions of its host planet habitable,
even in the face of these challenges. ExoGaia, a model created to investigate
the Gaia hypothesis, has been previously used to demonstrate that a randomly
mutating biosphere is in some cases capable of maintaining planetary
habitability. However, those model scenarios assumed that all non-biological
planetary parameters were static, neglecting the inevitable perturbations that
real planets would experience. To see how life responds to climate
perturbations to its host planet, we created three climate perturbations in
ExoGaia: one rapid cooling of a planet and two heating events, one rapid and
one gradual. The planets on which Gaian feedbacks emerge without climate
perturbations are the same planets on which life is most likely to survive each
of our perturbation scenarios. Biospheres experiencing gradual changes to the
environment are able to survive changes of larger magnitude than those
experiencing rapid perturbations, and the magnitude of change matters more than
the sign. These findings suggest that if the Gaia hypothesis is correct, then
typical perturbations that a planet would experience may be unlikely to disrupt
Gaian systems.",http://arxiv.org/abs/1906.01112v2
"Population boundary across an environmental gradient: Effects of
  quenched disorder",2019-07-01T15:16:34Z,"R. Juhász, I. A. Kovács","Population boundary is a classic indicator of climatic response in ecology.
In addition to known challenges, the spatial and dynamical characteristics of
the boundary are not only affected by the spatial gradient in the environmental
factors, but also by local heterogeneities in the regional characteristics.
Here, we capture the effects of quenched heterogeneities on the ecological
boundary with the disordered contact process in one and two dimensions with a
linear spatial trend in the local control parameter. We apply the
strong-disorder renormalization group method to calculate the sites occupied
with an $O(1)$ probability in the stationary state, readily yielding the
population front's position as the outermost site locally as well as globally
for the entire boundary. We show that under a quasistatic change of the global
environment, mimicking climate change, the front advances intermittently: long
quiescent periods are interrupted by rare but long jumps. The characteristics
of this intermittent dynamics are found to obey universal scaling laws in terms
of the gradient, conjectured to be related to the correlation-length exponent
of the model. Our results suggest that current observations might misleadingly
show little to no climate response for an extended period of time, concealing
the long-term effects of climate change.",http://arxiv.org/abs/1907.00849v2
"A review of assessment methods for the urban environment and its energy
  sustainability to guarantee climate adaptation of future cities",2019-06-14T11:48:16Z,"Dasaraden Mauree, Emanuele Naboni, Silvia Coccolo, A. T. D. Perera, Vahid Nik, Jean-Louis Scartezzini","The current climate change is calling for drastic reduction of energy demand
as well as of greenhouse gases. Besides this, cities also need to adapt to face
the challenges related to climate change. Cities, with their complex urban
texture and fabric can be represented as a diverse ecosystem that do not have a
clear and defined boundary. Multiple tools that have been developed, in the
recent years, for assessment of urban climate, building energy demand, the
outdoor thermal comfort and the energy systems. In this review, we, however,
noted that these tools often address only one or two of these urban planning
aspects. There is however an intricate link between them. For instance, the
outdoor comfort assessment has showed that there is a strong link between
biometeorology and architecture and urban climate. Additionally, to address the
challenges of the energy transition, there will be a convergence of the energy
needs in the future with an energy nexus regrouping the energy demand of urban
areas. It is also highlighted that the uncertainty related to future climatic
data makes urban adaptation and mitigation strategies complex to implement and
to design given the lack of a comprehensive framework. We thus conclude by
suggesting the need for a holistic interface to take into account this
multi-dimensional problem. With the help of such a platform a positive loop in
urban design can be initiated leading to the development of low carbon cities
and/or with the use of blue and green infrastructure to have a positive impact
on the mitigation and adaptation strategies.",http://arxiv.org/abs/1906.06140v2
Using LSTMs for climate change assessment studies on droughts and floods,2019-11-10T14:50:48Z,"Frederik Kratzert, Daniel Klotz, Johannes Brandstetter, Pieter-Jan Hoedt, Grey Nearing, Sepp Hochreiter","Climate change affects occurrences of floods and droughts worldwide. However,
predicting climate impacts over individual watersheds is difficult, primarily
because accurate hydrological forecasts require models that are calibrated to
past data. In this work we present a large-scale LSTM-based modeling approach
that -- by training on large data sets -- learns a diversity of hydrological
behaviors. Previous work shows that this model is more accurate than current
state-of-the-art models, even when the LSTM-based approach operates
out-of-sample and the latter in-sample. In this work, we show how this model
can assess the sensitivity of the underlying systems with regard to extreme
(high and low) flows in individual watersheds over the continental US.",http://arxiv.org/abs/1911.03941v2
Towards Unsupervised Segmentation of Extreme Weather Events,2019-09-16T23:41:42Z,"Adam Rupe, Karthik Kashinath, Nalini Kumar, Victor Lee, Prabhat, James P. Crutchfield","Extreme weather is one of the main mechanisms through which climate change
will directly impact human society. Coping with such change as a global
community requires markedly improved understanding of how global warming drives
extreme weather events. While alternative climate scenarios can be simulated
using sophisticated models, identifying extreme weather events in these
simulations requires automation due to the vast amounts of complex
high-dimensional data produced. Atmospheric dynamics, and hydrodynamic flows
more generally, are highly structured and largely organize around a lower
dimensional skeleton of coherent structures. Indeed, extreme weather events are
a special case of more general hydrodynamic coherent structures. We present a
scalable physics-based representation learning method that decomposes
spatiotemporal systems into their structurally relevant components, which are
captured by latent variables known as local causal states. For complex fluid
flows we show our method is capable of capturing known coherent structures, and
with promising segmentation results on CAM5.1 water vapor data we outline the
path to extreme weather identification from unlabeled climate model simulation
data.",http://arxiv.org/abs/1909.07520v1
Stratospheric Aerosol Injection as a Deep Reinforcement Learning Problem,2019-05-17T16:36:00Z,"Christian Schroeder de Witt, Thomas Hornigold","As global greenhouse gas emissions continue to rise, the use of stratospheric
aerosol injection (SAI), a form of solar geoengineering, is increasingly
considered in order to artificially mitigate climate change effects. However,
initial research in simulation suggests that naive SAI can have catastrophic
regional consequences, which may induce serious geostrategic conflicts. Current
geo-engineering research treats SAI control in low-dimensional approximation
only. We suggest treating SAI as a high-dimensional control problem, with
policies trained according to a context-sensitive reward function within the
Deep Reinforcement Learning (DRL) paradigm. In order to facilitate training in
simulation, we suggest to emulate HadCM3, a widely used General Circulation
Model, using deep learning techniques. We believe this is the first application
of DRL to the climate sciences.",http://arxiv.org/abs/1905.07366v1
Separating an Outlier from a Change,2019-05-30T08:50:20Z,"Deniz Sargun, C. Emre Koksal","We study the change detection problem with an unknown post-change
distribution. Under this constraint, the unknown change in the distribution of
observations may occur in many ways without much structure on the observations,
whereas, before the change point, a false alarm (outlier) is highly structured,
following a particular sample path. We first characterize these likely events
for the deviation and propose a method to test the empirical distribution,
relative to the most likely way for it to occur as an outlier. We benchmark our
method with finite moving average (FMA) and generalized likelihood ratio tests
(GLRT) under 4 different performance criteria including the run time time
complexity. Finally, we apply our method on economic market indicators and
climate data. Our method successfully captures the regime shifts during times
of historical significance for the markets and identifies the current climate
change phenomenon to be a highly likely regime shift rather than a random
event.",http://arxiv.org/abs/1905.12915v4
"The atmospheric circulation and climate of terrestrial planets orbiting
  Sun-like and M-dwarf stars over a broad range of planetary parameters",2019-01-03T00:59:40Z,"Thaddeus D. Komacek, Dorian S. Abbot","The recent detections of temperate terrestrial planets orbiting nearby stars
and the promise of characterizing their atmospheres motivates a need to
understand how the diversity of possible planetary parameters affects the
climate of terrestrial planets. In this work, we investigate the atmospheric
circulation and climate of terrestrial exoplanets orbiting both Sun-like and
M-dwarf stars over a wide swath of possible planetary parameters, including the
planetary rotation period, surface pressure, incident stellar flux, surface
gravity, planetary radius, and cloud particle size. We do so using a general
circulation model (GCM) that includes non-grey radiative transfer and the
effects of clouds. The results from this suite of simulations generally show
qualitatively similar dependencies of circulation and climate on planetary
parameters as idealized GCMs, with quantitative differences due to the
inclusion of additional model physics. Notably, we find that the effective
cloud particle size is a key unknown parameter that can greatly affect the
climate of terrestrial exoplanets. We confirm a transition between low and high
dayside cloud coverage of synchronously rotating terrestrial planets with
increasing rotation period. We determine that this cloud transition is due to
eddy-driven convergence near the substellar point and should not be
parameterization-dependent. Finally, we compute full-phase light curves from
our simulations of planets orbiting M-dwarf stars, finding that changing
incident stellar flux and rotation period affect observable properties of
terrestrial exoplanets. Our GCM results can guide expectations for planetary
climate over the broad range of possible terrestrial exoplanets that will be
observed with future space telescopes.",http://arxiv.org/abs/1901.00567v3
On Climate Change and Photovoltaic Energy Production,2019-06-20T13:07:43Z,"Ian Marius Peters, Tonio Buonassisi","As the 21st century progresses, photovoltaic technology is becoming a major
provider of the worlds electricity, while effects of global climate change
unfold. This development begs the question: is climate change affecting the
energy production of solar cells? In this article, we attempt to answer this
question looking backward and forward. We start by analyzing recent trends for
global meteorological conditions and solar cell performance parameters,
covering the ten-year period between 20016 and 2015. We leverage a
field-verified performance model for two of the most well-established solar
cell technologies that also feature very different sensitivities to changing
operating conditions: silicon and cadmium telluride. We find that climate
change has already left its mark: ten years ago, silicon solar panels -- on
average -- generated 4 kWh per m2 more power than today. Correlating solar cell
performance ratio changes and changes in operating conditions, we find that
temperature globally is the leading factor for silicon (-0.52 pm 0.03% per K),
accounting for approx. 85% of the observed effect. Water related light
absorption in the atmosphere is most likely responsible for much of the
remaining contribution. To predict how future solar cell performance is
affected, we focus on the implications of raising temperatures. For the end of
the 21st century, we project that silicon PV panels globally will suffer
performance reductions of between 0.7% and 2.5% (8 to 30 kWh per kWp in North
America), depending on the global warming scenario. These reductions will
result in significant socioeconomic penalties, particularly in a world that
produces a significant portion of its electricity from PV panels, and
especially if additional effects of global warming, like accelerated panel
degradation and extreme weather are considered.",http://arxiv.org/abs/1908.00623v2
"Evaluation of the performance of Euro-CORDEX RCMs for assessing
  hydrological climate change impacts in Great Britain: a comparison of
  different spatial resolutions and quantile mapping bias correction methods",2019-07-21T22:09:29Z,"Ernesto Pasten-Zapata, Julie Jones, Helen Moggridge, Martin Widmann","Regional Climate Models (RCMs) are an essential tool for analysing regional
climate change impacts as they provide simulations with more small-scale
details and expected smaller errors than global climate models. There has been
much effort to increase the spatial resolution and simulation skill of RCMs,
yet the extent to which this improves the projection of hydrological change is
unclear. Here, we evaluate the skill of five reanalysis-driven Euro-CORDEX RCMs
in simulating precipitation and temperature, and as drivers of a hydrological
model to simulate river flow on four UK catchments covering different physical,
climatic and hydrological characteristics. We test whether high-resolution RCMs
provide added value, through analysis of two RCM resolutions, 50 km and 12.5
km, which are also bias-corrected employing the parametric quantile-mapping
(QM) method, using the normal distribution for temperature, and the Gamma (GQM)
and Double Gamma (DGQM) distributions for precipitation. In a small catchment
with complex topography, the 12.5 km RCMs outperform their 50 km version for
precipitation and temperature, but when used in combination with the
hydrological model, fail to capture the observed river flow distribution. In
the other (larger) catchments, only one high-resolution RCM consistently
outperforms its low-resolution version, implying that in general there is no
added value from using the high-resolution RCMs in those catchments. GQM
decreases most of the simulation biases, except for extreme precipitation and
high flows, which are further decreased by DGQM. Bias correction does not
improve the representation of daily temporal variability, but it does for
monthly variability, in particular when applying DGQM. Overall, an increase in
RCM resolution does not imply a better simulation of hydrology and
bias-correction represents an alternative to ease decision-making.",http://arxiv.org/abs/1907.09043v1
"Asymptotic analysis of internal relaxation-oscillations in a conceptual
  climate model",2019-02-09T18:34:37Z,Łukasz Płociniczak,"We construct a dynamical system based on the KCG (K\""all\'en, Crafoord, Ghil)
conceptual climate model which includes the ice-albedo and
precipitation-temperature feedbacks. Further, we classify the stability of
various critical points of the system and identify a parameter which change
generates a Hopf bifurcation. This gives rise to a stable limit cycle around a
physically interesting critical point. Moreover, it follows from the general
theory that the periodic orbit exhibits relaxation-oscillations which are a
characteristic feature of the Pleistocene ice-ages. We provide an asymptotic
analysis of their behaviour and derive a formula for the period along with
several estimates. They, in turn, are in a decent agreement with paleoclimatic
data and are independent of any parametrization used. Whence, our simple but
robust model shows that a climate may exhibit internal relaxation-oscillations
without any external forcing and for a wide range of parameters.",http://arxiv.org/abs/1902.03467v1
Anderson localization and extreme values in chaotic climate dynamics,2019-11-10T21:15:02Z,"John T. Bruun, Spiros N. Evangelou","This work is a generic advance in the study of delocalized (ergodic) to
localized (non-ergodic) wave propagation phenomena in the presence of disorder.
There is an urgent need to better understand the physics of extreme value
process in the context of contemporary climate change. For earth system climate
analysis General Circulation Model simulation sizes are rather small, 10 to 50
ensemble members due to computational burden while large ensembles are
intrinsic to the study of Anderson localization. We merge universal transport
approaches of Random Matrix Theory (RMT), described by the characteristic
polynomial of random matrices, with the geometrical universal extremal types
max stable limit law. A generic ensemble based random Hamiltonian approach
allows a physical proof of state transition properties for extreme value
processes. In this work Anderson localization is examined for the extreme tails
of the related probability densities. We show that the Generalized Extreme
Value (GEV) shape parameter $\xi$ is a diagnostic tool that accurately
distinguishes localized from delocalized systems and this property should hold
for all wave based transport phenomena.",http://arxiv.org/abs/1911.03998v1
How surfaces shape the climate of habitable exoplanets,2019-12-31T21:26:10Z,"Jack Madden, Lisa Kaltenegger","Large ground- and space-based telescopes will be able to observe Earth-like
planets in the near future. We explore how different planetary surfaces can
strongly influence the climate, atmospheric composition, and remotely
detectable spectra of terrestrial rocky exoplanets in the habitable zone
depending on the host star's incident irradiation spectrum for a range of
Sun-like host stars from F0V to K7V. We update a well-tested 1D
climate-photochemistry model to explore the changes of a planetary environment
for different surfaces for different host stars. Our results show that using a
wavelength-dependent surface albedo is critical for modeling potentially
habitable rocky exoplanets.",http://arxiv.org/abs/2001.00085v3
Stability Analysis of Interface Conditions for Ocean-Atmosphere Coupling,2019-09-03T02:08:47Z,"Hong Zhang, Zhengyu Liu, Emil Constantinescu, Robert Jacob","In this paper we analyze the stability of different coupling strategies for
multidomain PDEs that arise in general circulation models used in climate
simulations. We focus on fully coupled ocean-atmosphere models that are needed
to represent and understand the complicated interactions of these two systems,
becoming increasingly important in climate change assessment in recent years.
Numerical stability issues typically arise because of different time-stepping
strategies applied to the coupled PDE system. In particular, the contributing
factors include using large time steps, lack of accurate interface flux, and
singe-iteration coupling. We investigate the stability of the coupled
ocean-atmosphere models for various interface conditions such as the
Dirichlet-Neumann condition and the bulk interface condition, which is unique
to climate modeling. By analyzing a simplified model, we demonstrate how the
parameterization of the bulk condition and other numerical and physical
parameters affect the coupling stability.",http://arxiv.org/abs/1909.00916v2
Dynamic and Isotopic Evolution of Ice Reservoirs on Mars,2019-01-24T13:41:31Z,"Eran Vos, Oded Aharonson, Norbert Schorghofer","The layered polar caps of Mars have long been thought to be related to
variations in orbit and axial tilt. We dynamically link Mars's past climate
variations with the stratigraphy and isotopic composition of its ice by
modeling the exchange of H2O and HDO among three reservoirs. The model shows
that the interplay among equatorial, mid-latitude, and north-polar layered
deposits (NPLD) induces significant isotopic changes in the cap. The diffusive
properties of the sublimation lags and dust content in our model result in a
cap size consistent with current Mars. The layer thicknesses are mostly
controlled by obliquity variations, but the precession period of 50 kyr
dominates the variations in the isotopic composition during epochs of
relatively low and nearly constant obliquity such as at present. Isotopic
sampling of the top 100 meters may reveal climate oscillations unseen in the
layer thicknesses and would thus probe recent precession-driven climate cycles.",http://arxiv.org/abs/1901.08401v1
A free boundary problem for spreading under shifting climate,2019-08-12T08:03:14Z,"Yuanyang Hu, Xinan Hao, Xianfa Song, Yihong Du","In this paper we consider a free boundary problem which models the spreading
of an invasive species whose spreading is enhanced by the changing climate. We
assume that the climate is shifting with speed c and obtain a complete
classification of the long-time dynamical behaviour of the species. The model
is similar to that in [9] with a slight refinement in the free boundary
condition. While [9], like many works in the literature, investigates the case
that unfavourable environment is shifting into the favourable habitat of the
concerned species, here we examine the situation that the unfavourable habitat
of an invasive species is replaced by a favourable environment with a shifting
speed c. We show that a spreading-vanishing dichotomy holds, and there exists a
critical speed$c_0$ such that when spreading happens in the case $c < c_0$, the
spreading profile is determined by a semi-wave with forced speed c, but when $c
\geq c_0$, the spreading profile is determined by the usual semi-wave with
speed $c_0$.",http://arxiv.org/abs/1908.04041v1
The Arctic surface climate in CMIP6: status and developments since CMIP5,2019-12-25T12:26:13Z,"Richard Davy, Stephen Outten","Here we evaluate the sea ice, surface air temperature, and sea-level-pressure
from 31 of the models used in the Coupled Model Intercomparison Project Phase 6
(CMIP6) for their biases, trends, and variability, and compare them to the
CMIP5 ensemble and the ERA5 reanalysis for the period 1979 to 2004. The
principal purpose of this assessment is to provide an overview of the ability
of the CMIP6 ensemble to represent the Arctic climate, and to see how this has
changed since the last Phase of CMIP. Overall, we find a distinct improvement
in the representation of the sea ice volume, but also in the sea ice extent,
mostly linked to improvements in the seasonal cycle in the Barents Sea.
However, numerous model biases have persisted into CMIP6 including too-cold
conditions in the winter (4 K cold bias) and a negative trend in the day-to-day
variability over ice in winter. We find that under the low emission scenario,
SSP126, the Arctic climate is projected to stabilize by 2060 with a sea ice
extent of around 2.5 million km2 and a temperature 4.7 K warmer than the early
20th century average, compared to 1.7 K of warming globally.",http://arxiv.org/abs/1912.11654v1
"Integrated analysis of the urban water-electricity demand nexus in the
  Midwestern United States",2019-02-26T20:36:59Z,"Renee Obringer, Rohini Kumar, Roshanak Nateghi","Considering the interdependencies between water and electricity use is
critical for ensuring conservation measures are successful in lowering the net
water and electricity use in a city. This water-electricity demand nexus will
become even more important as cities continue to grow, causing water and
electricity utilities additional stress, especially given the likely impacts of
future global climatic and socioeconomic changes. Here, we propose a modeling
framework based in statistical learning theory for predicting the
climate-sensitive portion of the coupled water-electricity demand nexus. The
predictive models were built and tested on six Midwestern cities. The results
showed that water use was better predicted than electricity use, indicating
that water use is slightly more sensitive to climate than electricity use.
Additionally, the results demonstrated the importance of the variability in the
El Nino/Southern Oscillation index, which explained the majority of the
covariance in the water-electricity nexus. Our modeling results suggest that
stronger El Ninos lead to an overall increase in water and electricity use in
these cities. The integrated modeling framework presented here can be used to
characterize the climate-related sensitivity of the water-electricity demand
nexus, accounting for the coupled water and electricity use rather than
modeling them separately, as independent variables.",http://arxiv.org/abs/1902.10697v1
Cumulo: A Dataset for Learning Cloud Classes,2019-11-05T09:36:16Z,"Valentina Zantedeschi, Fabrizio Falasca, Alyson Douglas, Richard Strange, Matt J. Kusner, Duncan Watson-Parris","One of the greatest sources of uncertainty in future climate projections
comes from limitations in modelling clouds and in understanding how different
cloud types interact with the climate system. A key first step in reducing this
uncertainty is to accurately classify cloud types at high spatial and temporal
resolution. In this paper, we introduce Cumulo, a benchmark dataset for
training and evaluating global cloud classification models. It consists of one
year of 1km resolution MODIS hyperspectral imagery merged with pixel-width
'tracks' of CloudSat cloud labels. Bringing these complementary datasets
together is a crucial first step, enabling the Machine-Learning community to
develop innovative new techniques which could greatly benefit the Climate
community. To showcase Cumulo, we provide baseline performance analysis using
an invertible flow generative model (IResNet), which further allows us to
discover new sub-classes for a given cloud class by exploring the latent space.
To compare methods, we introduce a set of evaluation criteria, to identify
models that are not only accurate, but also physically-realistic. CUMULO can be
download from
https://www.dropbox.com/sh/i3s9q2v2jjyk2it/AACxXnXfMF5wuIqLXqH4NJOra?dl=0 .",http://arxiv.org/abs/1911.04227v3
"Applying machine learning to improve simulations of a chaotic dynamical
  system using empirical error correction",2019-04-24T16:17:46Z,Peter A. G. Watson,"Dynamical weather and climate prediction models underpin many studies of the
Earth system and hold the promise of being able to make robust projections of
future climate change based on physical laws. However, simulations from these
models still show many differences compared with observations. Machine learning
has been applied to solve certain prediction problems with great success, and
recently it's been proposed that this could replace the role of
physically-derived dynamical weather and climate models to give better quality
simulations. Here, instead, a framework using machine learning together with
physically-derived models is tested, in which it is learnt how to correct the
errors of the latter from timestep to timestep. This maintains the physical
understanding built into the models, whilst allowing performance improvements,
and also requires much simpler algorithms and less training data. This is
tested in the context of simulating the chaotic Lorenz '96 system, and it is
shown that the approach yields models that are stable and that give both
improved skill in initialised predictions and better long-term climate
statistics. Improvements in long-term statistics are smaller than for single
time-step tendencies, however, indicating that it would be valuable to develop
methods that target improvements on longer time scales. Future strategies for
the development of this approach and possible applications to making progress
on important scientific problems are discussed.",http://arxiv.org/abs/1904.10904v1
"New approach for stochastic downscaling and bias correction of daily
  mean temperatures to a high-resolution grid",2019-06-25T11:54:28Z,"Qifen Yuan, Thordis Thorarinsdottir, Stein Beldring, Wai Kwok Wong, Shaochun Huang, Chong-Yu Xu","In applications of climate information, coarse-resolution climate projections
commonly need to be downscaled to a finer grid. One challenge of this
requirement is the modeling of sub-grid variability and the spatial and
temporal dependence at the finer scale. Here, a post-processing procedure is
proposed for temperature projections that addresses this challenge. The
procedure employs statistical bias correction and stochastic downscaling in two
steps. In a first step, errors that are related to spatial and temporal
features of the first two moments of the temperature distribution at model
scale are identified and corrected. Secondly, residual space-time dependence at
the finer scale is analyzed using a statistical model, from which realizations
are generated and then combined with appropriate climate change signal to form
the downscaled projection fields. Using a high-resolution observational gridded
data product, the proposed approach is applied in a case study where
projections of two regional climate models from the EURO-CORDEX ensemble are
bias-corrected and downscaled to a 1x1 km grid in the Trondelag area of Norway.
A cross-validation study shows that the proposed procedure generates results
that better reflect the marginal distributional properties of the data product
and have better consistency in space and time than empirical quantile mapping.",http://arxiv.org/abs/1906.10464v1
"No experimental evidence for the significant anthropogenic climate
  change",2019-06-29T08:06:26Z,"Jyrki Kauppinen, Pekka Malmi","In this paper we will prove that GCM-models used in IPCC report AR5 fail to
calculate the influences of the low cloud cover changes on the global
temperature. That is why those models give a very small natural temperature
change leaving a very large change for the contribution of the green house
gases in the observed temperature. This is the reason why IPCC has to use a
very large sensitivity to compensate a too small natural component. Further
they have to leave out the strong negative feedback due to the clouds in order
to magnify the sensitivity. In addition, this paper proves that the changes in
the low cloud cover fraction practically control the global temperature.",http://arxiv.org/abs/1907.00165v1
"Causal inference for climate change events from satellite image time
  series using computer vision and deep learning",2019-10-25T02:16:15Z,Vikas Ramachandra,"We propose a method for causal inference using satellite image time series,
in order to determine the treatment effects of interventions which impact
climate change, such as deforestation. Simply put, the aim is to quantify the
'before versus after' effect of climate related human driven interventions,
such as urbanization; as well as natural disasters, such as hurricanes and
forest fires. As a concrete example, we focus on quantifying forest tree cover
change/ deforestation due to human led causes. The proposed method involves the
following steps. First, we uae computer vision and machine learning/deep
learning techniques to detect and quantify forest tree coverage levels over
time, at every time epoch. We then look at this time series to identify
changepoints. Next, we estimate the expected (forest tree cover) values using a
Bayesian structural causal model and projecting/forecasting the counterfactual.
This is compared to the values actually observed post intervention, and the
difference in the two values gives us the effect of the intervention (as
compared to the non intervention scenario, i.e. what would have possibly
happened without the intervention). As a specific use case, we analyze
deforestation levels before and after the hyperinflation event (intervention)
in Brazil (which ended in 1993-94), for the Amazon rainforest region, around
Rondonia, Brazil. For this deforestation use case, using our causal inference
framework can help causally attribute change/reduction in forest tree cover and
increasing deforestation rates due to human activities at various points in
time.",http://arxiv.org/abs/1910.11492v1
"Assessment of climate change effects on mountain ecosystems through a
  cross-site analysis in the Alps and Apennines",2019-10-29T19:50:39Z,"M. Rogora, L. Frate, M. L. Carranza, M. Freppaz, A. Stanisci, I. Bertani, R. Bottarin, A. Brambilla, R. Canullo, M. Carbognani, C. Cerrato, S. Chelli, E. Cremonese, M. Cutini, M. Di Musciano, B. Erschbamer, D. Godone, M. Iocchi, M. Isabellon, A. Magnani, L. Mazzola, U. Morra di Cella, H. Pauli, M. Petey, B. Petriccione, F. Porro, R. Psenner, G. Rossetti, A. Scotti, R. Sommaruga, U. Tappeiner, J. -P. Theurillat, M. Tomaselli, D. Viglietti, R. Viterbi, P. Vittoz, M. Winkler, G. Matteucci","Mountain ecosystems are sensitive indicators of climate change. Long-term
studies may be extremely useful in assessing the responses of high-elevation
ecosystems to climate change and other anthropogenic drivers. Mountain research
sites within the LTER (Long-Term Ecosystem Research) network are representative
of various types of ecosystems and span a wide bioclimatic and elevational
range. Here, we present a synthesis and a review of the main results from
long-term ecological studies in mountain ecosystems at 20 LTER sites in Italy,
Switzerland and Austria. We analyzed a set of key climate parameters, such as
temperature and snow cover duration, in relation to vascular species
composition, plant traits, abundance patterns, pedoclimate, nutrient dynamics
in soils and water, phenology and composition of freshwater biota. The overall
results highlight the rapid response of mountain ecosystems to climate change.
As temperatures increased, vegetation cover in alpine and subalpine summits
increased as well. Years with limited snow cover duration caused an increase in
soil temperature and microbial biomass during the growing season. Effects on
freshwater ecosystems were observed, in terms of increases in solutes,
decreases in nitrates and changes in plankton phenology and benthos
communities. This work highlights the importance of comparing and integrating
long-term ecological data collected in different ecosystems, for a more
comprehensive overview of the ecological effects of climate change.
Nevertheless, there is a need for i) adopting co-located monitoring site
networks to improve our ability to obtain sound results from cross-site
analysis, ii) carrying out further studies, with fine spatial and temporal
resolutions to improve understanding of responses to extreme events, and iii)
increasing comparability and standardizing protocols across networks to clarify
local from global patterns.",http://arxiv.org/abs/1910.13501v1
"The Effects of Gravity on the Climate and Circulation of a Terrestrial
  Planet",2019-01-31T15:24:32Z,"Stephen I. Thomson, Geoffrey K. Vallis","The climate and circulation of a terrestrial planet are governed by, among
other things, the distance to its host star, its size, rotation rate,
obliquity, atmospheric composition and gravity. Here we explore the effects of
the last of these, the Newtonian gravitational acceleration, on its atmosphere
and climate. We first demonstrate that if the atmosphere obeys the hydrostatic
primitive equations, which are a very good approximation for most terrestrial
atmospheres, and if the radiative forcing is unaltered, changes in gravity have
no effect at all on the circulation except for a vertical rescaling. That is to
say, the effects of gravity may be completely scaled away and the circulation
is unaltered. However, if the atmosphere contains a dilute condensible that is
radiatively active, such as water or methane, then an increase in gravity will
generally lead to a cooling of the planet because the total path length of the
condensible will be reduced as gravity increases, leading to a reduction in the
greenhouse effect. Furthermore, the specific humidity will decrease, leading to
changes in the moist adiabatic lapse rate, in the equator-to-pole heat
transport, and in the surface energy balance because of changes in the sensible
and latent fluxes. These effects are all demonstrated both by theoretical
arguments and by numerical simulations with moist and dry general circulation
models.",http://arxiv.org/abs/1901.11426v1
"Climate Change and Agriculture: Subsistence Farmers' Response to Extreme
  Heat",2019-02-25T11:40:42Z,"Fernando M. Aragón, Francisco Oteiza, Juan Pablo Rud","This paper examines how subsistence farmers respond to extreme heat. Using
micro-data from Peruvian households, we find that high temperatures reduce
agricultural productivity, increase area planted, and change crop mix. These
findings are consistent with farmers using input adjustments as a short-term
mechanism to attenuate the effect of extreme heat on output. This response
seems to complement other coping strategies, such as selling livestock, but
exacerbates the drop in yields, a standard measure of agricultural
productivity. Using our estimates, we show that accounting for land adjustments
is important to quantify damages associated with climate change.",http://arxiv.org/abs/1902.09204v2
"The systemic growth constants of climate change: From its origin in 1780
  to its major post-WWII acceleration",2019-11-08T15:36:56Z,Jessie Lydia Henshaw,"The recent discovery of long term growth constants in the accumulation of
atmospheric CO2, confirmed by two methods, enables analog methods for dating
the beginning of climate change at ~1780 and projecting its near term future.
Here we show that the preceding wavy variation in CO2 PPM abruptly shifts to
exponential, moving symmetrically around a growth constant of 1.48 %/yr until
WWII, and after a pause rises to hover about a higher constant growth constant
from 1960 on of 2.0 %/yr. Such long term steady states of global environmental
change suggest transitions between stable states of global self-organization. A
method of analog curve fitting to project the current steady state of
acceleration is tested, suggesting a 2040 earth temperature rise of 1.89 deg C
above the IPCC baseline. A very brief following discussion of what a systemic
growth constant for atmospheric CO2 implies and model strategies for responding
to it.",http://arxiv.org/abs/1911.04340v1
"Constraining the magnitude of climate extremes from time-varying
  instellation on a circumbinary terrestrial planet",2019-11-13T16:17:36Z,"Jacob Haqq-Misra, Eric T. Wolf, William F. Welsh, Ravi Kumar Kopparapu, Veselin Kostov, Stephen R. Kane","Planets that revolve around a binary pair of stars are known as circumbinary
planets. The orbital motion of the stars around their center of mass causes a
periodic variation in the total instellation incident upon a circumbinary
planet. This study uses both an analytic and numerical energy balance model to
calculate the extent to which this effect can drive changes in surface
temperature on circumbinary terrestrial planets. We show that the amplitude of
the temperature variation is largely constrained by the effective heat
capacity, which corresponds to the ocean-to-land ratio on the planet. Planets
with large ocean fractions should experience only modest warming and cooling of
only a few degrees, which suggests that habitability cannot be precluded for
such circumbinary planets. Planets with large land fractions that experience
extreme periodic forcing could be prone to changes in temperature of tens of
degrees or more, which could drive more extreme climate changes that inhibit
continuously habitable conditions.",http://arxiv.org/abs/1911.05577v1
Efficient Method for Updating IDF Curves to Future Climate Projections,2019-06-11T20:22:49Z,"Jonathan B. Butcher, Tan Zi","If climate stationarity is dead, how should engineering design standards be
modified to account for potential changes in extreme precipitation? Many
standards rely on precipitation intensity-duration-frequency (IDF) curves
provided in NOAA's Atlas 14. General Circulation Models (GCMs) predict
increases in average temperature throughout the US, but are less clear on
changes in precipitation. In many areas GCMs predict relatively small changes
in total precipitation volume, but also suggest increased magnitude of extreme
events as warmer air can hold more water. Unfortunately, GCMs have limited
skill in predicting individual storm events. This research developed an
efficient approach to solve this problem that replicates Atlas 14 methods,
which fit a generalized extreme value distribution to the annual maximum
series. GCM biases are addressed through equidistant quantile mapping, mapping
from a GCM's historical simulation to future predictions, then applying this
mapping from the fit to data used in Atlas 14. The approach is efficient
because it requires only the annual maxima, allowing rapid examination of
results across the range of GCM projections.",http://arxiv.org/abs/1906.04802v1
"Maize yield under a changing climate: The hidden role of vapor pressure
  deficit",2019-10-07T23:24:14Z,"Jennifer Hsiao, Abigail L. S. Swann, Soo-Hyung Kim","Temperatures over the next century are expected to rise to levels detrimental
to crop growth and yield. As the atmosphere warms without additional water
vapor input, vapor pressure deficit (VPD) increases as well. Increased
temperatures and accompanied elevated VPD levels can both lead to negative
impacts on crop yield. The independent importance of VPD, however, is often
neglected or conflated with that from temperature due to a tight correlation
between the two climate factors. We used a coupled process-based crop (MAIZSIM)
and soil (2DSOIL) model to gain a mechanistic understanding of the independent
roles temperature and VPD play in crop yield projections, as well as their
interactions with rising CO2 levels and changing precipitation patterns. We
found that by separating out the VPD effect from rising temperatures, VPD
increases had a greater negative impact on yield compared to that from warming.
The negative impact of these two factors varied with precipitation levels and
influenced yield through separate mechanisms. Warmer temperatures caused yield
loss mainly through shortening the growing season, while elevated VPD increased
water loss and triggered several water stress responses such as reduced
photosynthetic rates, lowered leaf area development, and shortened growing
season length. Elevated CO2 concentrations partially alleviated yield loss
under warming or increased VPD conditions through water savings, but the impact
level varied with precipitation levels and was most pronounced under drier
conditions. These results demonstrate the key role VPD plays in crop growth and
yield, displaying a magnitude of impact comparative to temperature and CO2. A
mechanistic understanding of the function of VPD and its relation with other
climate factors and management practices is critical to improving crop yield
projections under a changing climate.",http://arxiv.org/abs/1910.03129v1
"Non-stationarity in Esbjerg sea-level returnlevels: Applications in
  climate change adaptation",2019-11-10T08:11:00Z,"Peter Thejll, Peter Guttorp, Martin Drews, Torben Schmith, Thordis Thorarinsdottir, Jacob Woge Nielsen, Mads Hvid Ribergaard","Non-stationary time series modelling is applied to long tidal records from
Esbjerg, Denmark, and coupled to climate change projections for sea-level and
storminess, to produce projections of likely future sea-level maxima. The model
has several components: nonstationary models for mean sea-level, tides and
extremes of residuals of sea level above tide level. The extreme value model
(at least on an annual scale) has location-parameter dependent on mean sea
level. Using the methodology of Bolin et al. (2015)and Guttorp et al. (2014) we
calculate, using CMIP5 climate models, projections for mean sea level with
attendant uncertainty. We simulate annual maxima in two ways - one method uses
the empirically fitted non-stationary generalized extreme-value-distribution
(GEV) of 20th-century annual maxima projected forward based on msl-projections,
and the other has a stationary approach to extremes. We then consider return
levels and the increase in these from AD 2000 to AD 2100. We find that the
median of annual maxima with return period 100 years, taking into account all
the nonstationarities, in year 2100 is 6.5m above current mean sea level (start
of 21stC) levels",http://arxiv.org/abs/1911.03874v1
"Predicting Landscapes from Environmental Conditions Using Generative
  Networks",2019-09-23T11:24:52Z,"Christian Requena-Mesa, Markus Reichstein, Miguel Mahecha, Basil Kraft, Joachim Denzler","Landscapes are meaningful ecological units that strongly depend on the
environmental conditions. Such dependencies between landscapes and the
environment have been noted since the beginning of Earth sciences and cast into
conceptual models describing the interdependencies of climate, geology,
vegetation and geomorphology. Here, we ask whether landscapes, as seen from
space, can be statistically predicted from pertinent environmental conditions.
To this end we adapted a deep learning generative model in order to establish
the relationship between the environmental conditions and the view of
landscapes from the Sentinel-2 satellite. We trained a conditional generative
adversarial network to generate multispectral imagery given a set of climatic,
terrain and anthropogenic predictors. The generated imagery of the landscapes
share many characteristics with the real one. Results based on landscape patch
metrics, indicative of landscape composition and structure, show that the
proposed generative model creates landscapes that are more similar to the
targets than the baseline models while overall reflectance and vegetation cover
are predicted better. We demonstrate that for many purposes the generated
landscapes behave as real with immediate application for global change studies.
We envision the application of machine learning as a tool to forecast the
effects of climate change on the spatial features of landscapes, while we
assess its limitations and breaking points.",http://arxiv.org/abs/1909.10296v1
"Atmospheric Dynamics on Terrestrial Planets: The Seasonal Response to
  changes in Orbital, Rotational and Radiative Timescales",2019-06-13T15:16:44Z,"Ilai Guendelman, Yohai Kaspi","Thousands of exoplanets have been detected to date, and with future planned
missions this tally will increase. Understanding the climate dependence on the
planetary parameters is vital for the study of terrestrial exoplanet
habitability. Using an idealized general circulation model with a seasonal
cycle, we study the seasonal response of the surface temperature and Hadley
circulation to changes in the orbital, rotational and radiative timescales.
Analyzing the climate's seasonal response to variations in these timescales, we
find a regime transition between planets controlled by the annual mean
insolation to planets controlled by the seasonal variability depending on the
relation between the length of the orbital period, obliquity and radiative
timescale. Consequently, planets with obliquity greater than $54^{\circ}$ and
short orbital period will have a minimum surface temperature at the equator. We
also show that in specific configurations, mainly high atmospheric mass and
short orbital periods, high obliquity planets can still have an equable
climate. Based on the model results, we suggest an empirical power law for the
ascending and descending branches of the Hadley circulation and its strength.
These power laws show that the Hadley circulation becomes wider and stronger by
increasing the obliquity and orbital period or by decreasing the atmospheric
mass and rotation rate. Consistent with previous studies, we show that the
rotation rate plays an essential role in dictating the width of the Hadley
circulation.",http://arxiv.org/abs/1906.05748v1
"Forecasting the effect of heat stress index and climate change on cloud
  data center energy consumption",2019-11-09T16:17:15Z,Vikas Ramachandra,"In this paper, we estimate the effect of heat stress index (a measure which
takes into account rising temperatures as well as humidity) on data center
energy consumption. We use forecasting models to predict future energy use by
data centers, taking into account rising temperature scenarios. We compare
those estimates with baseline forecasted energy consumption (without heat
stress index or rising temperature correction) and present the result that
there is a sizeable and significant difference in the two forecasts. We show
that rising temperatures will cause a negative impact on data center energy
consumption, increasing it by about 8 percent, and conclude that data center
energy consumption analyses and forecasts must include the effects of heat
stress index and rising temperatures and other climate change related effects.",http://arxiv.org/abs/1911.03730v1
The Impact of Global Warming on Silicon PV Energy Yield in 2100,2019-06-13T14:30:07Z,"Ian Marius Peters, Tonio Buonassisi","While the installed photovoltaic capacity grows to a terawatt scale, effects
of global climate change unfold. The question arises, how a changing climate,
and especially raising temperatures, will affect the performance of PV
installations in the future. In this paper we present an estimate of the
reduction in energy yield for silicon PV installations due to global warming in
the year 2100. Using IPCC global warming scenarios and published temperature
coefficients for todays silicon PV panels, we project median reductions in
annual energy output of today's silicon solar panel of 15kWh per kWP, with
reductions up to 50kWh per kWP in some areas. Higher efficiency cells and
advanced cell and module architectures can significantly reduce these losses.
Cell concepts with higher voltage are particularly effective in reducing
temperature induced losses.",http://arxiv.org/abs/1908.00622v3
"A Deep Learning-based Framework for the Detection of Schools of Herring
  in Echograms",2019-10-18T01:12:46Z,"Alireza Rezvanifar, Tunai Porto Marques, Melissa Cote, Alexandra Branzan Albu, Alex Slonimer, Thomas Tolhurst, Kaan Ersahin, Todd Mudge, Stephane Gauthier","Tracking the abundance of underwater species is crucial for understanding the
effects of climate change on marine ecosystems. Biologists typically monitor
underwater sites with echosounders and visualize data as 2D images (echograms);
they interpret these data manually or semi-automatically, which is
time-consuming and prone to inconsistencies. This paper proposes a deep
learning framework for the automatic detection of schools of herring from
echograms. Experiments demonstrated that our approach outperforms a traditional
machine learning algorithm using hand-crafted features. Our framework could
easily be expanded to detect more species of interest to sustainable fisheries.",http://arxiv.org/abs/1910.08215v1
"Study of the impact of climate change on precipitation in Paris area
  using method based on iterative multiscale dynamic time warping (IMS-DTW)",2019-10-22T16:34:02Z,"Mohamed Djallel Dilmi, Laurent Barthès, Cécile Mallet, Aymeric Chazottes","Studying the impact of climate change on precipitation is constrained by
finding a way to evaluate the evolution of precipitation variability over time.
Classical approaches (feature-based) have shown their limitations for this
issue due to the intermittent and irregular nature of precipitation. In this
study, we present a novel variant of the Dynamic time warping method
quantifying the dissimilarity between two rainfall time series based on shapes
comparisons, for clustering annual time series recorded at daily scale. This
shape based approach considers the whole information (variability, trends and
intermittency). We further labeled each cluster using a feature-based approach.
While testing the proposed approach on the time series of Paris Montsouris, we
found that the precipitation variability increased over the years in Paris
area.",http://arxiv.org/abs/1910.10809v1
"Time Series Vector Autoregression Prediction of the Ecological Footprint
  based on Energy Parameters",2019-10-25T15:30:40Z,"Radmila Janković, Ivan Mihajlović, Alessia Amelio","Sustainability became the most important component of world development, as
countries worldwide fight the battle against the climate change. To understand
the effects of climate change, the ecological footprint, along with the
biocapacity should be observed. The big part of the ecological footprint, the
carbon footprint, is most directly associated with the energy, and specifically
fuel sources. This paper develops a time series vector autoregression
prediction model of the ecological footprint based on energy parameters. The
objective of the paper is to forecast the EF based solely on energy parameters
and determine the relationship between the energy and the EF. The dataset
included global yearly observations of the variables for the period 1971-2014.
Predictions were generated for every variable that was used in the model for
the period 2015-2024. The results indicate that the ecological footprint of
consumption will continue increasing, as well as the primary energy consumption
from different sources. However, the energy consumption from coal sources is
predicted to have a declining trend.",http://arxiv.org/abs/1910.11800v1
"Influence of a road on a population in an ecological niche facing
  climate change",2019-03-06T07:44:55Z,"Henri Berestycki, Romain Ducasse, Luca Rossi","We introduce a model designed to account for the influence of a line with
fast diffusion-such as a road or another transport network-on the dynamics of a
population in an ecological niche. This model consists of a system of coupled
reaction-diffusion equations set on domains with different dimensions (line /
plane). We first show that the presence of the line is always deleterious and
can even lead the population to extinction. Next, we consider the case where
the niche is subject to a displacement, representing the effect of a climate
change or of seasonal variation of resources. We find that in such case the
presence of the line with fast diffusion can help the population to persist. We
also study several qualitative properties of this system. The analysis is based
on a notion of generalized principal eigenvalue developed by the authors in
[5].",http://arxiv.org/abs/1903.02221v2
Optimal forest rotation under carbon pricing and forest damage risk,2019-11-30T21:50:14Z,Tommi Ekholm,"Forests will have two notable economic roles in the future: providing
renewable raw material and storing carbon to mitigate climate change. The
pricing of forest carbon leads to longer rotation times and consequently larger
carbon stocks, but also exposes landowners to a greater risk of forest damage.
This paper investigates optimal forest rotation under carbon pricing and forest
damage risk. I provide the optimality conditions for this problem and
illustrate the setting with numerical calculations representing boreal forests
under a range of carbon prices and damage probabilities. The relation between
damage probability and carbon price towards the optimal rotation length is
nearly linear, with carbon pricing having far greater impact. As such,
increasing forest carbon stocks by lengthening rotations is an economically
attractive method for climate change mitigation, despite the forest damage
risk. Carbon pricing also increases land expectation value and reduces the
economic risks of the landowner. The production possibility frontier under
optimal rotation suggests that significantly larger forests carbon stocks are
achievable, but imply lower harvests. However, forests' societally optimal role
between these two activities is not yet clear-cut; but rests on the future
development of relative prices between timber, carbon and other commodities
dependent on land-use.",http://arxiv.org/abs/1912.00269v1
Quantifying Urban Canopy Cover with Deep Convolutional Neural Networks,2019-12-03T17:14:53Z,"Bill Cai, Xiaojiang Li, Carlo Ratti","Urban canopy cover is important to mitigate the impact of climate change.
Yet, existing quantification of urban greenery is either manual and not
scalable, or use traditional computer vision methods that are inaccurate. We
train deep convolutional neural networks (DCNNs) on datasets used for
self-driving cars to estimate urban greenery instead, and find that our
semantic segmentation and direct end-to-end estimation method are more accurate
and scalable, reducing mean absolute error of estimating the Green View Index
(GVI) metric from 10.1% to 4.67%. With the revised DCNN methods, the Treepedia
project was able to scale and analyze canopy cover in 22 cities
internationally, sparking interest and action in public policy and research
fields.",http://arxiv.org/abs/1912.02109v1
"Enhancing Stratospheric Weather Analyses and Forecasts by Deploying
  Sensors from a Weather Balloon",2019-12-04T22:07:05Z,"Kiwan Maeng, Iskender Kushan, Brandon Lucia, Ashish Kapoor","The ability to analyze and forecast stratospheric weather conditions is
fundamental to addressing climate change. However, our capacity to collect data
in the stratosphere is limited by sparsely deployed weather balloons. We
propose a framework to collect stratospheric data by releasing a contrail of
tiny sensor devices as a weather balloon ascends. The key machine learning
challenges are determining when and how to deploy a finite collection of
sensors to produce a useful data set. We decide when to release sensors by
modeling the deviation of a forecast from actual stratospheric conditions as a
Gaussian process. We then implement a novel hardware system that is capable of
optimally releasing sensors from a rising weather balloon. We show that this
data engineering framework is effective through real weather balloon flights,
as well as simulations.",http://arxiv.org/abs/1912.02276v1
A Flexible Pipeline for Prediction of Tropical Cyclone Paths,2019-06-20T20:24:03Z,"Niccolò Dalmasso, Robin Dunn, Benjamin LeRoy, Chad Schafer","Hurricanes and, more generally, tropical cyclones (TCs) are rare, complex
natural phenomena of both scientific and public interest. The importance of
understanding TCs in a changing climate has increased as recent TCs have had
devastating impacts on human lives and communities. Moreover, good prediction
and understanding about the complex nature of TCs can mitigate some of these
human and property losses. Though TCs have been studied from many different
angles, more work is needed from a statistical approach of providing prediction
regions. The current state-of-the-art in TC prediction bands comes from the
National Hurricane Center of the National Oceanographic and Atmospheric
Administration (NOAA), whose proprietary model provides ""cones of uncertainty""
for TCs through an analysis of historical forecast errors.
  The contribution of this paper is twofold. We introduce a new pipeline that
encourages transparent and adaptable prediction band development by
streamlining cyclone track simulation and prediction band generation. We also
provide updates to existing models and novel statistical methodologies in both
areas of the pipeline, respectively.",http://arxiv.org/abs/1906.08832v1
Towards a Physically Motivated Planetary Accounting Framework,2019-07-24T15:55:58Z,"M. Barbosa, O. Bertolami, F. Francisco","In this work we present a physically motivated planetary Accounting Framework
for the Earth System. We show that the impact of the human activity in terms of
the Planetary Boundary variables can be accounted for in our Landau-Ginzburg
phase transition physical formulation. We then use the interaction between
climate change and ocean acidification mechanisms to exemplify the relation of
the concentration and flux of substances of the Planetary Boundaries variables,
as proposed by the accounting framework of Kate and Newman, with the underlying
thermodynamical transformation, quantifiable by the Landau-Ginzburg inspired
model. In this work we present a physically motivated planetary Accounting
Framework for the Earth System. We show that the impact of the human activity
in terms of the Planetary Boundary variables can be accounted for in our
Landau-Ginzburg phase transition physical formulation. We then use the
interaction between climate change and ocean acidification mechanisms to
exemplify the relation of the concentration and flux of substances of the
Planetary Boundaries variables, as proposed by the accounting framework of Kate
and Newman, with the underlying thermodynamical transformation, quantifiable by
the Landau-Ginzburg inspired model.",http://arxiv.org/abs/1907.10535v1
"Reconstruction of Past Human land-use from Pollen Data and Anthropogenic
  land-cover Changes Scenarios",2019-10-24T09:32:49Z,"Behnaz Pirzamanbein, Johan Lindström","Accurate maps of past land cover and human land-use are necessary when
studying the impact of anthropogenic land-cover changes on climate. Ideally the
maps of past land cover would be separated into naturally occurring vegetation
and human induced changes, allowing us to quantify the effect of human land-use
on past climate. Here we investigate the possibility of combining regional,
fossil pollen based, land-cover reconstructions with, population based,
estimates of past human land-use. By merging these two datasets and
interpolating the pollen based land-cover reconstructions we aim at obtaining
maps that provide both past natural land-cover and the anthropogenic land-cover
changes. We develop a Bayesian hierarchical model to handle the complex data,
using a latent Gaussian Markov random fields (GMRF) for the interpolation.
Estimation of the model is based on a block updated Markov chain Monte Carlo
(MCMC) algorithm. The sparse precision matrix of the GMRF together with an
adaptive Metropolis adjusted Langevin step allows for fast inference.
Uncertainties in the land-use predictions are computed from the MCMC posterior
samples. The model uses the pollen based observations to reconstruct three
composition of land cover; Coniferous forest, Broadleaved forest and
Unforested/Open land. The unforested land is then further decomposed into
natural and human induced openness by inclusion of the estimates of past human
land-use. The model is applied to five time periods - centred around 1900 CE,
1725 CE, 1425 CE, 1000 and, 4000 BCE over Europe. The results suggest pollen
based observations can be used to recover past human land-use by adjusting the
population based anthropogenic land-cover changes estimates.",http://arxiv.org/abs/1910.10993v1
"Estimating resilience of annual crop production systems: theory and
  limitations",2019-02-07T15:14:33Z,"Matteo Zampieri, Christof Weissteiner, Bruna Grizzetti, Andrea Toreti, Maurits van den Berg M., Frank Dentener","Agricultural production is affected by climate extremes, which are increasing
because of global warming. This motivates the need of a proper evaluation of
the agricultural production systems resilience to enhance food security, market
stability, and the general ability of society to cope with the effects of
climate change. Resilience is generally assessed through holistic approaches
involving a large number of indicators for the environmental, social and
economic factors that influence food availability, access and utilization.
Here, we investigate the problem of measuring resilience in a simplified
framework, focusing on the crop production component of the agricultural
system. For an idealized production system composed of a single crop, using the
original definition of resilience, we identify the best combination of the mean
and the variance of annual crop production data to estimate crop resilience
i.e. the crop resilience indicator. Through numerical experiments conducted
with a conceptual crop model, we show the general properties of this indicator
applied to production systems for different levels of adaptation to climate
variability and in case of increasing frequencies of extreme events. Finally,
we discuss the applicability of the proposed approach to real agricultural
production systems and the expected effects of crop diversity on the resilience
of crop production systems, following directly from the mathematical definition
of the crop resilience indicator.",http://arxiv.org/abs/1902.02677v1
Habitable Zone Boundaries for Circumbinary Planets,2019-11-08T01:59:18Z,"Wolf Cukier, Ravi kumar Kopparapu, Stephen R. Kane, William Welsh, Eric Wolf, Veselin Kostov, Jacob Haqq-Misra","We use a one-dimensional (1-D) cloud-free climate model to estimate habitable
zone (HZ) boundaries for terrestrial planets of masses 0.1 M$_{E}$ and 5
M$_{E}$ around circumbinary stars of various spectral type combinations.
Specifically, we consider binary systems with host spectral types F-F, F-G,
F-K, F-M, G-G, G-K, G-M, K-K, K-M and M-M. Scaling the background N2
atmospheric pressure with the radius of the planet, we find that the inner edge
of the HZ moves inwards towards the star for 5ME compared to 0.1ME planets for
all spectral types. This is because the water-vapor column depth is smaller for
larger planets and higher temperatures are needed before water vapor completely
dominates the outgoing longwave radiation. The outer edge of the HZ changes
little due to competing effects of the albedo and greenhouse effect. While
these results are broadly consistent with the trend of single star HZ results
for different mass planets, there are significant differences between single
star and binary star systems for the inner edge of the HZ. Interesting
combinations of stellar pairs from our 1-D model results can be used to explore
for in-depth climate studies with 3-D climate models. We identify a common HZ
stellar flux domain for all circumbinary spectral types",http://arxiv.org/abs/1911.02983v1
"LULC classification methodology based on simple Convolutional Neural
  Network to map complex urban forms at finer scale: Evidence from Mumbai",2019-09-21T05:00:29Z,"Deepank Verma, Arnab Jana","The satellite imagery classification task is fundamental to spatial knowledge
discovery. Several image classification methods are used to create standardized
Land use and Land cover (LULC) maps, which facilitate research on spatial and
ecological processes and human activities. Local Climate Zones (LCZ)
classification maps are an example of standardized maps which have been widely
used to demarcate the homogeneity in built and natural character in the cities.
The LCZ classification scheme is primarily focused on urban climate-related
research, in which 17 climate zones are mapped in a city area with the 100-150m
spatial resolution. Each zone exhibits physical properties related to urban
form and functions essential for thermal behavior studies. Extending this
widely adopted approach to create LULC maps at finer resolution using the LCZ
mapping scheme would benefit the allied domains of urban planning,
transportation, and water resources management. This study proposes a novel
solution to generate classification maps with a 10-band Sentinel-2B dataset and
Convolutional Neural Networks (CNN) at the 10m spatial resolution. The
classification benefits from CNNs property to preserve local structures in the
image datasets. The proposed CNN model outperforms traditional machine learning
models such as Artificial Neural Network, Random Forests, and Support Vector
Machines. The overall accuracy and kappa statistic of the CNN model trained on
14 urban and natural classes are 82 percent and 0.81, respectively. The study
also discusses the utility of the model for specialized remote sensing tasks
such as change detection, identification of slum settlements, and mapping
pervious/impervious layers in urban settlements with higher accuracy.",http://arxiv.org/abs/1909.09774v2
"How do Planetary Radius and Gravity Influence the Surface Climate of
  Earth-like Planets?",2019-10-15T01:56:34Z,"Huanzhou Yang, Jun Yang","About 4000 exoplanets have been confirmed since the year of 1992, and for
most of the planets, the main parameters that can be measured are planetary
radius and mass. Based on these two parameters, surface gravity can be
estimated. In this work, we investigate the effects of varying radius and
gravity on the climate of rapidly rotating terrestrial planets with assuming
they have an ocean and Earth-like atmospheres (N$_2$, CO$_2$, and H$_2$O).
Using a three-dimensional (3D) atmospheric general circulation model (GCM), we
find that varying radius mainly influences the equator-to-pole surface
temperature difference while varying gravity mainly influences the mean surface
temperature. For planets of larger radii, the meridional atmospheric energy
transport is weaker, which warms the tropics but cools high latitudes. For
planets of larger gravities, the surface is globally cooler due to the fact
that saturated vapor pressure depends on air temperature only and column water
vapor mass is approximately equal to saturated vapor pressure over gravity
multiplied by relative humidity. The relative humidity does not change much in
our experiments. Ice albedo and water vapor feedbacks act to further amplify
the effects of varying radius and gravity. These results suggest that radius
and gravity are important factors for planetary climate, although they are not
as critical as stellar flux, atmospheric composition and mass, and rotation
rate. Future simulations are required to know how large the radius and gravity
could influence the width of the habitable zone using 3D GCMs.",http://arxiv.org/abs/1910.06479v1
An Estimate of the Surface Pollution of the Arctic Sea Ice,2019-12-04T19:47:22Z,"A. Laubereau, H. Iglev","The Arctic sea ice represents an important energy reservoir for the climate
of the northern hemisphere. The shrinking of the polar ice in the past decades
decreases the stored energy and raises serious concerns about future climate
changes.[1-4] Model calculations of the present authors [5,6] suggest that half
of the global warming during the past fifty years is directly related to the
retreat of the sea ice, while the cause is not well understood, e.g. the role
of surface pollution [7-10]. We have analysed the reported annual melting and
freezing data of the northern sea ice in the years 1979 to 2018 [11] to gain
some insight. Two features can be deduced from our simple model: (i) recent
results [12,13] are confirmed that approximately 60 % of the loss of sea ice
stems from energy transport to the arctic region. (ii) We find evidence that
the remaining part of the ice retreat originates from an increasing surface
absorption of solar radiation, obviously due to the rising surface pollution of
the sea ice. While the phenomenon was previously considered by several authors
in a qualitative way, our analysis contributes semi-quantitative information on
the situation. We estimate that the relevant fall-out of light absorbing
aerosols onto the sea ice increased by 17 +/- 5 % during the past fifty years.
A deposition of additional 3 +/- 1 % of solar radiation in the melting region
results that accounts for the ice retreat. Recalling the important role of the
ice loss for the terrestrial climate,[3,5,9] the precipitation of air pollution
in the Arctic seems to be an important factor for the global warming.",http://arxiv.org/abs/1912.02226v1
"Near-resonance tidal evolution of the Earth-Moon system influenced by
  orbital-scale climate change",2019-07-22T03:47:45Z,"Nan Wang, Zhi-Guo He","We build a conceptual coupled model of the climate and tidal evolution of the
Earth-Moon system to find the influence of the former on the latter. An energy
balance model is applied to calculate steady-state temperature field from the
mean annual insolation as a function of varying astronomical parameters. A
harmonic oscillator model is applied to integrate the lunar orbit and Earth's
rotation with the tidal torque dependent on the dominant natural frequency of
ocean. An ocean geometry acts as a bridge between temperature and oceanic
frequency. On assumptions of a fixed hemispherical continent and an equatorial
circular lunar orbit, considering only the 41 kyr periodicity of Earth's
obliquity $\varepsilon$ and the $M_2$ tide, simulations are performed near
tidal resonance for $10^6$ yr. It is verified that the climate can influence
the tidal evolution via ocean. Compared with the tidal evolution with constant
$\varepsilon$, that with varying $\varepsilon$ is slowed down; the Earth-Moon
distance oscillates in phase with $\varepsilon$ before the resonance maximum
but exactly out of phase after that; the displacement of the oscillation is in
positive correlation with the difference between oceanic frequency and tidal
frequency.",http://arxiv.org/abs/1907.09121v2
"Order patterns, their variation and change points in financial time
  series and Brownian motion",2019-10-21T13:13:44Z,Christoph Bandt,"Order patterns and permutation entropy have become useful tools for studying
biomedical, geophysical or climate time series. Here we study day-to-day market
data, and Brownian motion which is a good model for their order patterns. A
crucial point is that for small lags (1 up to 6 days), pattern frequencies in
financial data remain essentially constant. The two most important order
parameters of a time series are turning rate and up-down balance. For change
points in EEG brain data, turning rate is excellent while for financial data,
up-down balance seems the best. The fit of Brownian motion with respect to
these parameters is tested, providing a new version of a forgotten test by
Bienaym'e.",http://arxiv.org/abs/1910.09978v1
On Changes of Global Wet-bulb Temperature and Snowfall Regimes,2019-05-19T17:09:45Z,"Sagar K. Tamang, Ardeshir M. Ebtehaj, Andreas F. Prein, Andrew J. Heymsfield","To properly interpret the observed shrinkage of the Earth's cryosphere it is
important to understand global changes of snowfall dominant regimes. To
document these changes, three different reanalysis products of wet-bulb
temperature together with observationally-based data sets are processed from
1979 to 2017. It is found that over the Northern Hemisphere (NH), the annual
mean wet-bulb temperature has increased at a rate of 0.34$^\circ$C per decade
(pd) over land and 0.35$^\circ$C pd over ocean, resulting in a reduction of the
annual mean potential areas of snowfall dominant regimes by 0.52/0.34 million
km$^2$pd over land/ocean. However, the changes in the Southern Hemisphere (SH)
are less conclusive and more uncertain. Among the K$\""o$ppen-Geiger climate
classes, the highest warming trend is observed over the NH polar climate
regimes. Over studied mountain regions, the Alps are warming at a faster rate
compared to the Rockies, Andes and High Mountain Asia (HMA). Due to such
warming, potential snowfall areas over the Alps is reducing at 3.64% pd
followed by Rockies at 2.81 and HMA at 1.85% pd. On average, these mountain
ranges have lost 0.02 million km$^2$pd of potential snowfall areas. The NH
potential snowfall areas is retracting towards the North pole over the Central
Asia and Europe at a rate of 0.45 and 0.7 degree pd. Furthermore, terrestrial
regions over the NH including the Great Plains in the United States, Canadian
provinces around the Hudson Bay, Central Siberian and Tibetan Plateaus, are
losing as much as 4% of the solid proportion of the annual precipitation amount
pd.",http://arxiv.org/abs/1905.07776v1
"New Astronomical, Meteorological and Geological Study of Pieve a Nievole
  (PT)",2019-10-08T16:26:43Z,"D. Tasselli, S. Ricci, P. Bianchi","In this paper we present an analysis of the geological, meteorological and
climatic data recorded in Pieve a Nievole (PT) over 24 years and using this
data for the establishment of the research structure called ""PAN.R.C. - Pieve a
Nievole Research Center"" and ""NGICS - New study of geological and Italian
city"". These data are compared to check local variations, long term trends and
correlation with maen annual temperature. The ultimate goal of this work is to
understand long term climatic changes in this geographic area. The analysis is
performed using a statistical approach and a particular care is used to
minimize any effect due to prejudices in case of lack of data.",http://arxiv.org/abs/1910.06101v1
Coupling Oceanic Observation Systems to Study Mesoscale Ocean Dynamics,2019-10-18T18:10:47Z,"Gautier Cosne, Guillaume Maze, Pierre Tandeo","Understanding local currents in the North Atlantic region of the ocean is a
key part of modelling heat transfer and global climate patterns. Satellites
provide a surface signature of the temperature of the ocean with a high
horizontal resolution while in situ autonomous probes supply high vertical
resolution, but horizontally sparse, knowledge of the ocean interior thermal
structure. The objective of this paper is to develop a methodology to combine
these complementary ocean observing systems measurements to obtain a
three-dimensional time series of ocean temperatures with high horizontal and
vertical resolution. Within an observation-driven framework, we investigate the
extent to which mesoscale ocean dynamics in the North Atlantic region may be
decomposed into a mixture of dynamical modes, characterized by different local
regressions between Sea Surface Temperature (SST), Sea Level Anomalies (SLA)
and Vertical Temperature fields. Ultimately we propose a Latent-class
regression method to improve prediction of vertical ocean temperature.",http://arxiv.org/abs/1910.08573v1
Water Preservation in Soan River Basin using Deep Learning Techniques,2019-06-26T05:26:31Z,"Sadaqat ur Rehman, Zhongliang Yang, Muhammad Shahid, Nan Wei, Yongfeng Huang, Muhammad Waqas, Shanshan Tu, Obaid ur Rehman","Water supplies are crucial for the development of living beings. However,
change in the hydrological process i.e. climate and land usage are the key
issues. Sustaining water level and accurate estimating for dynamic conditions
is a critical job for hydrologists, but predicting hydrological extremes is an
open issue. In this paper, we proposed two deep learning techniques and three
machine learning algorithms to predict stream flow, given the present climate
conditions. The results showed that the Recurrent Neural Network (RNN) or Long
Short-term Memory (LSTM), an artificial neural network based method, outperform
other conventional and machine-learning algorithms for predicting stream flow.
Furthermore, we analyzed that stream flow is directly affected by
precipitation, land usage, and temperature. These indexes are critical, which
can be used by hydrologists to identify the potential for stream flow. We make
the dataset publicly available (https://github.com/sadaqat007/Dataset) so that
others should be able to replicate and build upon the results published.",http://arxiv.org/abs/1906.10852v1
"Percolation theory suggests some general features in range margins
  across environmental gradients",2019-09-02T07:52:25Z,"R. Juhász, B. Oborny","The margins within the geographic range of species are often specific in
terms of ecological and evolutionary processes, and can strongly influence the
species' reaction to climate change. One of the frequently observed features at
range margins is fragmentation, caused internally by population dynamics or
externally by the limited availability of suitable habitat sites. We study both
causes, and describe the transition from a connected to a fragmented state
across space by means of a gradient metapopulation model. The main features of
our approach are the following. 1) Inhomogeneities can occur at two spatial
scales: there is a broad-scale gradient, which can be patterned by fine-scale
heterogeneities. The latter is implemented by dispersing a variable number of
small obstacles over the terrain, which can be penetrable or unpenetrable by
the spreading species. 2) We study the occupancy of this terrain in a
steady-state on two temporal scales: in snapshots and by long-term averages.
The simulations reveal some general scaling laws that are applicable in various
environments, independently of the mechanism of fragmentation. The edge of the
connected region (the hull) is a fractal with dimension 7/4. Its width and
length changes with the gradient according to universal scaling laws, that are
characteristic for percolation transitions. The results suggest that
percolation theory is a powerful tool for understanding the structure of range
margins in a broad variety of real-life scenarios, including those in which the
environmental gradient is combined with fine-scale heterogeneity. This provides
a new method for comparing the range margins of different species in various
geographic regions, and monitoring range shifts under climate change.",http://arxiv.org/abs/1909.00585v2
"Cosmic Noise Absorption During Solar Proton Events in WACCM-D and
  Riometer Observations",2019-01-21T11:26:18Z,"Erkka Heino, Pekka T. Verronen, Antti Kero, Niilo Kalakoski, Noora Partamies","Solar proton events (SPEs) cause large-scale ionization in the middle
atmosphere leading to ozone loss and changes in the energy budget of the middle
atmosphere. The accurate implementation of SPEs and other particle ionization
sources in climate models is necessary to understand the role of energetic
particle precipitation (EPP) in climate variability. We use riometer
observations from 16 riometer stations and the Whole Atmosphere Community
Climate Model with added D region ion chemistry (WACCM-D) to study the spatial
and temporal extent of cosmic noise absorption (CNA) during 62 solar proton
events from 2000 to 2005. We also present a correction method for the
non-linear response of observed CNA during intense absorption events. We find
that WACCM-D can reproduce the observed CNA well with some need for future
improvement and testing of the used EPP forcing. The average absolute
difference between the model and the observations is found to be less than 0.5
dB poleward of about $66^\circ$ geomagnetic latitude, and increasing with
decreasing latitude to about 1 dB equatorward of about $66^\circ$ geomagnetic
latitude. The differences are largest during twilight conditions where the
modeled changes in CNA are more abrupt compared to observations. An
overestimation of about $1^\circ$ to $3^\circ$ geomagnetic latitude in the
extent of the CNA is observed due to the fixed proton cutoff latitude in the
model. An unexplained underestimation of CNA by the model during sunlit
conditions is observed at stations within the polar cap during 18 of the
studied events.",http://arxiv.org/abs/1901.06884v1
"Seasonal variability in a 1600 year-long ice core chemical record, Pamir
  Mountains, Central Asia",2019-10-23T04:07:56Z,"Charles Rodda, Paul Mayewski, Andrei Kurbatov, Elena Aizen, Vladimir Aizen, Elena Korotkikh, Nozomu Takeuchi, Koji Fujita, Kenji Kawamura, Akane Tsushima","Targeted ultra-high resolution Laser Ablation Inductively Coupled Plasma Mass
Spectrometry (LA-ICP-MS) analysis of an ice core drilled in the Pamir Mountains
of Central Asia (CA) records changes in seasonal patterns of atmospheric
circulation and moisture delivery to CA over the past 1600 years. Fe, Ca, and
Mg signals in the LNC3 Pamir ice core reflect variable delivery of these
elements during the pre-Medieval Warm Period (pre-MWP), Medieval Warm Period
(MWP), and during the onset of the Little Ice Age (LIA) in CA. During the
pre-MWP, hiatuses between dust seasons are observed due to a lengthened
accumulation season, and dust delivery limited to a short period at the end of
the accumulation season when modern summer-style northerly airflow occurred.
During the MWP, dust delivery to CA decreased, though Fe-intensity in the core
indicates episodic northerly air incursion. By the onset of the LIA, dust
availability increased due to regional drying and strengthening winds, and
strong westerlies blocked meridional flow reducing Fe-rich dust input from the
north. CA has experienced recent warming, desiccation, weakening winds, and
glacier loss. Major climate circulation drivers (Westerlies, Icelandic Low,
Siberian High) continue to display LIA-style patterns, and annual temperatures
are approaching those of the MWP. While none of the preceding climate periods
in CA history can serve as an absolute wholesale proxy for conditions that are
likely to prevail in the near future continued Northern Hemisphere westerlies
weakening in a changing climate may enhance meridional flow and bring more
moisture into the Aral Sea catchment from the Arctic.",http://arxiv.org/abs/1910.10339v1
AI for Earth: Rainforest Conservation by Acoustic Surveillance,2019-08-20T03:50:57Z,"Yuan Liu, Zhongwei Cheng, Jie Liu, Bourhan Yassin, Zhe Nan, Jiebo Luo","Saving rainforests is a key to halting adverse climate changes. In this
paper, we introduce an innovative solution built on acoustic surveillance and
machine learning technologies to help rainforest conservation. In particular,
We propose new convolutional neural network (CNN) models for environmental
sound classification and achieved promising preliminary results on two
datasets, including a public audio dataset and our real rainforest sound
dataset. The proposed audio classification models can be easily extended in an
automated machine learning paradigm and integrated in cloud-based services for
real world deployment.",http://arxiv.org/abs/1908.07517v1
Machine Learning for AC Optimal Power Flow,2019-10-19T20:47:13Z,"Neel Guha, Zhecheng Wang, Matt Wytock, Arun Majumdar","We explore machine learning methods for AC Optimal Powerflow (ACOPF) - the
task of optimizing power generation in a transmission network according while
respecting physical and engineering constraints. We present two formulations of
ACOPF as a machine learning problem: 1) an end-to-end prediction task where we
directly predict the optimal generator settings, and 2) a constraint prediction
task where we predict the set of active constraints in the optimal solution. We
validate these approaches on two benchmark grids.",http://arxiv.org/abs/1910.08842v1
"Spatio-temporal crop classification of low-resolution satellite imagery
  with capsule layers and distributed attention",2019-04-23T03:05:31Z,John Brandt,"Land use classification of low resolution spatial imagery is one of the most
extensively researched fields in remote sensing. Despite significant
advancements in satellite technology, high resolution imagery lacks global
coverage and can be prohibitively expensive to procure for extended time
periods. Accurately classifying land use change without high resolution imagery
offers the potential to monitor vital aspects of global development agenda
including climate smart agriculture, drought resistant crops, and sustainable
land management. Utilizing a combination of capsule layers and long-short term
memory layers with distributed attention, the present paper achieves
state-of-the-art accuracy on temporal crop type classification at a 30x30m
resolution with Sentinel 2 imagery.",http://arxiv.org/abs/1904.10130v1
Model based functional clustering of varved lake sediments,2019-04-23T12:07:19Z,"Per Arnqvist, Sara Sjöstedt de Luna","In this paper we propose a model-based method for clustering subjects for
which functional data together with covariates are observed. The model allows
the covariance structures within the different clusters to be different. The
model thus extends a model proposed by James and Sugar (2003). We derive an EM
algorithm to estimate the parameters. The method is applied to annually
laminated (varved) sediment from lake Kassj\""on in northern Sweden, to infer on
past climate changes.",http://arxiv.org/abs/1904.10265v1
"Obliquity Evolution of Circumstellar Planets in Sun-like Stellar
  Binaries",2019-11-19T17:56:15Z,"Billy Quarles, Gongjie Li, Jack J. Lissauer","Changes in planetary obliquity, or axial tilt, influence the climates on
Earth-like planets. In the solar system, the Earth's obliquity is stabilized
due to interactions with our moon and the resulting {small amplitude variations
($\sim$2.4\degree)} are beneficial for advanced life. Most Sun-like stars have
at least one stellar companion and the habitability of circumstellar exoplanets
is shaped by their stellar companion. We show that a stellar companion can
dramatically change whether {Earth-like obliquity stability is} possible
through planetary orbital precession relative to the binary orbit or resonant
pumping of the obliquity through spin-orbit interactions. We present a new
formalism for the planetary spin precession that accounts for orbital
misalignments between the planet and binary. Using numerical modeling in
$\alpha$ Centauri AB we show: a stark contrast between the planetary obliquity
variations depending on the host star, planetary neighbors limit the possible
spin states for {Earth-like obliquity stability}, and the presence of a moon
can destabilize the obliquity, defying our Earth-based expectations. An
Earth-like rotator orbiting the primary star would experience {small} obliquity
variations for 87\%, 74\%, or 54\% of Solar type binaries, depending on the
mass of the primary (0.8, 1.0, or 1.2 M$_\odot$, respectively). Thus,
Earth-like planets likely experience much larger obliquity variations, with
more extreme climates, unless they are in specific states, such as orbiting
nearly planar with the binary and rotating retrograde (backwards) like Venus.",http://arxiv.org/abs/1911.08431v2
"EvaSylv: A user-friendly software to evaluate forestry scenarii
  including natural risk",2019-09-12T11:12:44Z,"Patrice Loisel, Guillerme Duvillié, Denis Barbeau, Brigitte Charnomordic","Forest management relies on the evaluation of silviculture practices. The
increase in natural risk due to climate change makes it necessary to consider
evaluation criteria that take natural risk into account. Risk integration in
existing software requires advanced programming skills.We propose a
user-friendly software to simulate even-aged and monospecific forest at the
stand level, in order to evaluate and optimize forest management. The software
gives the possibility to run management scenarii with or without considering
the impact of natural risk. The control variables are the dates and rates of
thinning and the cutting age.The risk model is based on a Poisson processus.
The Faustmann approach, including tree damage risk, is used to evaluate future
benefits, economic or ecosystem services. It relies on the calculation of
expected values, for which a dedicated mathematical development has been done.
The optimized criteria used to evaluate the various scenarii are the Faustmann
value and the Averaged yield value.We illustrate the approach and the software
on two case studies: economic optimization of a beech stand and carbon
sequestration optimization of a pine stand.Software interface makes it easy for
users to write their own (growth-tree damage-economic) models without advanced
programming skills. The possibility to run management scenarii with/without
considering the impact of natural risk may contribute improving silviculture
guidelines and adapting them to climate change. We propose future lines of
research and improvement.",http://arxiv.org/abs/1909.07288v1
Coupling Wind Farm with Nuclear Power Plant,2019-09-10T21:10:11Z,Mohamed Kareem Abdel Rahman AlAshery,"Climate change has been identified as one of the greatest challenges facing
nations, governments, businesses and citizens of the globe. The threats of
climate change demand an increase in the share of renewable energy from the
total of energy generation. Meanwhile, there are tremendous efforts to decrease
the reliance on fossil fuel energies which opens the venue for increasing the
usage of alternative resources such as nuclear energy. Many countries (e.g.
Egypt) are planning to meet increasing electricity demands by increasing both
renewable (especially wind energy) and nuclear energies contributions in
electricity generation. In the planning phase of siting both new Wind Farms
(WFs) and Nuclear Power Plants (NPPs), many benefits and challenges exist. An
important aspect taken into consideration during the NPP siting is the
existence of ultimate heat sink which is sea water in most cases. That is why
most NPPs are sited on sea coasts. On the other hand, during WF siting, the
main influential aspect is the existence of good wind resources. Many coastal
areas around the world fulfill this requirement for WF siting. Coupling both
NPPs and WFs in one site or nearby has many benefits and obstacles as well. In
this thesis, based on international experience and literature reviews, the
benefits and obstacles of this coupling/adjacency are studied and evaluated.
Various case studies are carried out to verify the coupling/adjacency concept.",http://arxiv.org/abs/1909.08963v1
"Facilitating on-line opinion dynamics by mining expressions of
  causation. The case of climate change debates on The Guardian",2019-12-03T09:20:41Z,"Tom Willaert, Sven Banisch, Paul Van Eecke, Katrien Beuls","News website comment sections are spaces where potentially conflicting
opinions and beliefs are voiced. Addressing questions of how to study such
cultural and societal conflicts through technological means, the present
article critically examines possibilities and limitations of machine-guided
exploration and potential facilitation of on-line opinion dynamics. These
investigations are guided by a discussion of an experimental observatory for
mining and analyzing opinions from climate change-related user comments on news
articles from the TheGuardian.com. This observatory combines causal mapping
methods with computational text analysis in order to mine beliefs and visualize
opinion landscapes based on expressions of causation. By (1) introducing
digital methods and open infrastructures for data exploration and analysis and
(2) engaging in debates about the implications of such methods and
infrastructures, notably in terms of the leap from opinion observation to
debate facilitation, the article aims to make a practical and theoretical
contribution to the study of opinion dynamics and conflict in new media
environments.",http://arxiv.org/abs/1912.01252v1
"Controlling the speed and trajectory of evolution with counterdiabatic
  driving",2019-12-08T21:17:41Z,"Shamreen Iram, Emily Dolson, Joshua Chiel, Julia Pelesko, Nikhil Krishnan, Özenç Güngör, Benjamin Kuznets-Speck, Sebastian Deffner, Efe Ilker, Jacob G. Scott, Michael Hinczewski","The pace and unpredictability of evolution are critically relevant in a
variety of modern challenges: combating drug resistance in pathogens and
cancer, understanding how species respond to environmental perturbations like
climate change, and developing artificial selection approaches for agriculture.
Great progress has been made in quantitative modeling of evolution using
fitness landscapes, allowing a degree of prediction for future evolutionary
histories. Yet fine-grained control of the speed and the distributions of these
trajectories remains elusive. We propose an approach to achieve this using
ideas originally developed in a completely different context: counterdiabatic
driving to control the behavior of quantum states for applications like quantum
computing and manipulating ultra-cold atoms. Implementing these ideas for the
first time in a biological context, we show how a set of external control
parameters (i.e. varying drug concentrations / types, temperature, nutrients)
can guide the probability distribution of genotypes in a population along a
specified path and time interval. This level of control, allowing empirical
optimization of evolutionary speed and trajectories, has myriad potential
applications, from enhancing adaptive therapies for diseases, to the
development of thermotolerant crops in preparation for climate change, to
accelerating bioengineering methods built on evolutionary models, like directed
evolution of biomolecules.",http://arxiv.org/abs/1912.03764v2
"Trade-offs between carbon stocks and biodiversity in European temperate
  forests",2019-02-28T08:50:11Z,"F. M. Sabatini, R. B. de Andrade, Y. Paillet, P. Odor, C. Bouget, T. Campagnaro, F. Gosselin, P. Janssen, W. Mattioli, J. Nascimbene, T. Sitzia, T. Kuemmerle, S. Burrascano","Policies to mitigate climate change and biodiversity loss often assume that
protecting carbon-rich forests provides co-benefits in terms of biodiversity,
due to the spatial congruence of carbon stocks and biodiversity at
biogeographic scales. However, it remains unclear whether this holds at the
scales relevant for management, with particularly large knowledge gaps for
temperate forests and for taxa other than trees. We built a comprehensive
dataset of Central European temperate forest structure and multi-taxonomic
diversity (beetles, birds, bryophytes, fungi, lichens, and plants) across 352
plots. We used Boosted Regression Trees to assess the relationship between
above-ground live carbon stocks and (a) taxon-specific richness, (b) a unified
multidiversity index. We used Threshold Indicator Taxa ANalysis to explore
individual species' responses to changing above-ground carbon stocks and to
detect change-points in species composition along the carbon-stock gradient.
Our results reveal an overall weak and highly variable relationship between
richness and carbon stock at the stand scale, both for individual taxonomic
groups and for multidiversity. Similarly, the proportion of win-win and
trade-off species (i.e. species favored or disadvantaged by increasing carbon
stock, respectively) varied substantially across taxa. Win-win species
gradually replaced trade-off species with increasing carbon, without clear
thresholds along the above-ground carbon gradient, suggesting that
community-level surrogates (e.g. richness) might fail to detect critical
changes in biodiversity. Collectively, our analyses highlight that leveraging
co-benefits between carbon and biodiversity in temperate forest may require
stand-scale management that prioritizes either biodiversity or carbon-in order
to maximize co-benefits at broader scales. Importantly, this contrasts with
tropical forests, where climate [...]",http://arxiv.org/abs/1902.10950v1
"Spatial variations in the Caspian Sea wave climate in 2002-2013 from
  satellite altimetry",2019-12-02T08:04:22Z,"Nadezhda Kudryavtseva, Kuanysh Kussembayeva, Zaure B. Rakisheva, Tarmo Soomere","The core properties of the wave climate and its changes in the Caspian Sea
are established in terms of the annual mean significant wave height and its
regional changes in 2002-2013 based on the outcome of the satellite altimetry
mission JASON-1. Remotely estimated wave heights are validated against
properties of the empirical distribution of instrumentally measured wave
heights in the southern Caspian Sea and monthly averages of visually observed
wave heights at three locations. A correction for systematic differences leads
to very good correspondence between monthly averaged in situ and satellite data
with a typical root mean square difference of 0.06 m. The average significant
wave height in the Caspian Sea is 0.5-0.7 m in the northern basin of the sea,
around 1.2 m in large parts of the central and southern basins and reaches up
to 1.8 m in the northern segment of the central basin. The basin-wide average
wave intensity varied insignificantly in the range of 1.02-1.14 m in 2002-2013.
These estimates overestimate the wave heights by about 30% because low wave
conditions are ignored. Substantial and statistically significant changes in
the wave height occurred in certain areas. The wave height decreased by 0.019
+- 0.007 m/yr in the eastern segment of the central basin and by 0.04 +- 0.04
m/yr in the western segment of the southern basin. These changes can be
explained by an increase in the frequency of westerly winds at the expence of
southerly winds. Both basin-wide and regional extreme wave heights exhibit
large interannual variations but do not show any significant trend. The
patterns of changes in mean and extreme wave height are different. The average
wave height has increased while the extreme wave height has decreased in the
eastern segment of the southern basin.",http://arxiv.org/abs/1912.00615v1
"So2Sat LCZ42: A Benchmark Dataset for Global Local Climate Zones
  Classification",2019-12-19T14:42:01Z,"Xiao Xiang Zhu, Jingliang Hu, Chunping Qiu, Yilei Shi, Jian Kang, Lichao Mou, Hossein Bagheri, Matthias Häberle, Yuansheng Hua, Rong Huang, Lloyd Hughes, Hao Li, Yao Sun, Guichen Zhang, Shiyao Han, Michael Schmitt, Yuanyuan Wang","Access to labeled reference data is one of the grand challenges in supervised
machine learning endeavors. This is especially true for an automated analysis
of remote sensing images on a global scale, which enables us to address global
challenges such as urbanization and climate change using state-of-the-art
machine learning techniques. To meet these pressing needs, especially in urban
research, we provide open access to a valuable benchmark dataset named ""So2Sat
LCZ42,"" which consists of local climate zone (LCZ) labels of about half a
million Sentinel-1 and Sentinel-2 image patches in 42 urban agglomerations
(plus 10 additional smaller areas) across the globe. This dataset was labeled
by 15 domain experts following a carefully designed labeling work flow and
evaluation process over a period of six months. As rarely done in other labeled
remote sensing dataset, we conducted rigorous quality assessment by domain
experts. The dataset achieved an overall confidence of 85%. We believe this LCZ
dataset is a first step towards an unbiased globallydistributed dataset for
urban growth monitoring using machine learning methods, because LCZ provide a
rather objective measure other than many other semantic land use and land cover
classifications. It provides measures of the morphology, compactness, and
height of urban areas, which are less dependent on human and culture. This
dataset can be accessed from http://doi.org/10.14459/2018mp1483140.",http://arxiv.org/abs/1912.12171v1
Eurasian Cooling Patterns in the CMIP5 Climate Models,2019-11-19T09:44:22Z,"Stephen Outten, Richard Davy, Linling Chen","The Arctic has warmed dramatically compared to the global average over the
last few decades. During this same period, there have been strong cooling
trends observed in the wintertime, near-surface air temperature over central
Eurasia, a phenomenon known as Eurasian cooling. Many studies have suggested
that the loss of sea ice, especially in the Barents and Kara Seas, is related
to the cooling over Eurasia, although this connection and its possible
mechanism is still a source of heated debate. Observations and reanalyses show
a clear pattern of co-variability between Arctic sea ice and Eurasian
wintertime temperatures. However, there is an open question regarding how
robustly this teleconnection pattern is reproduced in the current generation of
climate models.
  This study has examined Eurasian cooling in twenty models from the Coupled
Model Intercomparison Project Phase 5 (CMIP5), both in terms of temperature
trends and by using singular value decomposition to identify patterns of
co-variability between Arctic sea ice concentrations and near-surface
temperatures over Eurasia. These are compared to trends and patterns of
co-variability found in the ERA-Interim reanalysis. While most of the CMIP5
models have a robust pattern of co-variability that is similar to that found in
the reanalysis, many fail to reproduce the wintertime cooling that has been
observed. An examination of Arctic sea ice extent in the models suggests one
possible explanation is the inability of the models to accurately simulate the
wintertime sea ice changes over critical locations such as the Barents and Kara
Seas.",http://arxiv.org/abs/1911.08178v1
"High Resolution Forecasting of Heat Waves impacts on Leaf Area Index by
  Multiscale Multitemporal Deep Learning",2019-09-13T15:06:33Z,"Andrea Gobbi, Marco Cristoforetti, Giuseppe Jurman, Cesare Furlanello","Climate change impacts could cause progressive decrease of crop quality and
yield, up to harvest failures. In particular, heat waves and other climate
extremes can lead to localized food shortages and even threaten food security
of communities worldwide. In this study, we apply a deep learning architecture
for high resolution forecasting (300 m, 10 days) of the Leaf Area Index (LAI),
whose dynamics has been widely used to model the growth phase of crops and
impact of heat waves. LAI models can be computed at 0.1 degree spatial
resolution with an auto regressive component adjusted with weather conditions,
validated with remote sensing measurements. However model actionability is poor
in regions of varying terrain morphology at this scale (about 8 km at the Alps
latitude). Our deep learning model aims instead at forecasting LAI by training
multiscale multitemporal (MSMT) data from the Copernicus Global Land Service
(CGLS) project for all Europe at 300m resolution and medium-resolution
historical weather data. Further, the deep learning model inputs integrate
high-resolution land surface features, known to improve forecasts of
agricultural productivity. The historical weather data are then replaced with
forecast values to predict LAI values at 10 day horizon on Europe. We propose
the MSMT model to develop a high resolution crop-specific warning system for
mitigating damage due to heat waves and other extreme events.",http://arxiv.org/abs/1909.07786v1
"The effects of urbanization on the temperature over the
  Beijing-Tianjin-Hebei region under changing climate",2019-09-18T12:53:11Z,"Xinyi Ai, Yichuan Huang, Qizhen Dong, Kai Yang, Danhong Dong, Xichen Li","Urbanization has a large impact on human society. Besides, global warming has
become an increasingly popular topic since global warming will not only play a
significant role in human beings daily life but also have a huge impact on the
global climate. Under the background of global warming, the impacts of
urbanization may have differences, which is the topic this project mainly
discusses. In this study, the monthly air temperature data from 2
meteorological stations in Beijing under the different underlying surface:
urban and suburban for a period of 1960-2014 were analyzed. Besides, two years,
1993 and 2010, selected with the different circulation conditions have been
simulated by weather forecasting models. We conducted experiments using the
Weather Research and Forecasting (WRF) model to investigate the impacts of
urbanization under different circulation conditions on the summer temperature
over the Beijing-Tianjin-Hebei Region (BTHR). The results indicate that the
effect of urbanization under low-pressure system is greater than that under
high-pressure system. That is because the difference of total cloud cover
between the urban area and the suburban area is greater under low-pressure
system in 1993. This research will not only increase our understanding of the
effect of urbanization but also provide a scientific basis to enhance the
ability to prevent disasters and reduce damages under the global warming
background.",http://arxiv.org/abs/1909.08413v1
"Basin bifurcations, oscillatory instability and rate-induced thresholds
  for AMOC in a global oceanic box model",2019-01-29T05:30:57Z,"Hassan Alkhayuon, Peter Ashwin, Laura C Jackson, Courtney Quinn, Richard A Wood","The Atlantic Meridional Overturning Circulation (AMOC) transports substantial
amounts of heat into the North Atlantic sector, and hence is of very high
importance in regional climate projections. The AMOC has been observed to show
multi-stability across a range of models of different complexity. The simplest
models find a bifurcation associated with the AMOC `on' state losing stability
that is a saddle node. Here we study a physically derived global oceanic model
of Wood {\em et al} with five boxes, that is calibrated to runs of the FAMOUS
coupled atmosphere-ocean general circulation model. We find the loss of
stability of the `on' state is due to a subcritical Hopf for parameters from
both pre-industrial and doubled CO${}_2$ atmospheres. This loss of stability
via subcritical Hopf bifurcation has important consequences for the behaviour
of the basin of attraction close to bifurcation. We consider various
time-dependent profiles of freshwater forcing to the system, and find that
rate-induced thresholds for tipping can appear, even for perturbations that do
not cross the bifurcation. Understanding how such state transitions occur is
important in determining allowable safe climate change mitigation pathways to
avoid collapse of the AMOC.",http://arxiv.org/abs/1901.10111v2
"A New Line-By-Line General Circulation Model for Simulations of Diverse
  Planetary Atmospheres: Initial Validation and Application to the Exoplanet GJ
  1132b",2019-05-12T02:56:17Z,"Feng Ding, Robin D. Wordsworth","Exploring diverse planetary atmospheres requires modeling tools that are both
accurate and flexible. Here, we develop a three-dimensional general circulation
model (3D GCM) that for the first time uses a line-by-line approach to describe
the radiative transfer. We validate our GCM by comparing with published results
done by different 1D and 3D models. To demonstrate the versatility of the
model, we apply the GCM to the hot Earth-sized exoplanet GJ 1132b and study its
climate and circulation assuming an atmosphere dominated by abiotic oxygen
(O$_2$). Our simulations show that a minor CO$_2$ composition can change the
circulation pattern substantially, intensifying the equatorial superrotation in
particular. Computation of the phase-resolved spectroscopy indicates that the
vertical profile of the superrotating jet could be inferred in future
spectro-photometric observations by the phase shift of the hotspot in the
CO$_2$ principle absorption band centered at 667 cm$^{-1}$. We also show that
atmospheric mass could potentially be constrained by the phase amplitude in the
O$_2$ vibrational fundamental band for planets with O$_2$-rich atmospheres,
although further experimental and/or theoretical O$_2$-O$_2$ collision-induced
absorption data at high temperatures is needed to confirm this. More physical
schemes such as moist dynamics will be implemented in the GCM in the future so
that it can be used to tackle a wide variety of planetary climate problems.",http://arxiv.org/abs/1905.04635v1
Dynamics of Tipping Cascades on Complex Networks,2019-05-14T09:17:31Z,"Jonathan Krönke, Nico Wunderling, Ricarda Winkelmann, Arie Staal, Benedikt Stumpf, Obbe A. Tuinenburg, Jonathan F. Donges","Tipping points occur in diverse systems in various disciplines such as
ecology, climate science, economy or engineering. Tipping points are critical
thresholds in system parameters or state variables at which a tiny perturbation
can lead to a qualitative change of the system. Many systems with tipping
points can be modeled as networks of coupled multistable subsystems, e.g.
coupled patches of vegetation, connected lakes, interacting climate tipping
elements or multiscale infrastructure systems. In such networks, tipping events
in one subsystem are able to induce tipping cascades via domino effects. Here,
we investigate the effects of network topology on the occurrence of such
cascades. Numerical cascade simulations with a conceptual dynamical model for
tipping points are conducted on Erd\H{o}s-R\'enyi, Watts-Strogatz and
Barab\'asi-Albert networks. Additionally, we generate more realistic networks
using data from moisture-recycling simulations of the Amazon rainforest and
compare the results to those obtained for the model networks. We furthermore
use a directed configuration model and a stochastic block model which preserve
certain topological properties of the Amazon network to understand which of
these properties are responsible for its increased vulnerability. We find that
clustering and spatial organization increase the vulnerability of networks and
can lead to tipping of the whole network. These results could be useful to
evaluate which systems are vulnerable or robust due to their network topology
and might help to design or manage systems accordingly.",http://arxiv.org/abs/1905.05476v2
"Deep reinforcement learning in World-Earth system models to discover
  sustainable management strategies",2019-08-15T14:48:31Z,"Felix M. Strnad, Wolfram Barfuss, Jonathan F. Donges, Jobst Heitzig","Increasingly complex, non-linear World-Earth system models are used for
describing the dynamics of the biophysical Earth system and the socio-economic
and socio-cultural World of human societies and their interactions. Identifying
pathways towards a sustainable future in these models for informing policy
makers and the wider public, e.g. pathways leading to a robust mitigation of
dangerous anthropogenic climate change, is a challenging and widely
investigated task in the field of climate research and broader Earth system
science. This problem is particularly difficult when constraints on avoiding
transgressions of planetary boundaries and social foundations need to be taken
into account. In this work, we propose to combine recently developed machine
learning techniques, namely deep reinforcement learning (DRL), with classical
analysis of trajectories in the World-Earth system. Based on the concept of the
agent-environment interface, we develop an agent that is generally able to act
and learn in variable manageable environment models of the Earth system. We
demonstrate the potential of our framework by applying DRL algorithms to two
stylized World-Earth system models. Conceptually, we explore thereby the
feasibility of finding novel global governance policies leading into a safe and
just operating space constrained by certain planetary and socio-economic
boundaries. The artificially intelligent agent learns that the timing of a
specific mix of taxing carbon emissions and subsidies on renewables is of
crucial relevance for finding World-Earth system trajectories that are
sustainable on the long term.",http://arxiv.org/abs/1908.05567v1
"Impact of climatic, technical and economic uncertainties on the optimal
  design of a coupled fossil-free electricity, heating and cooling system in
  Europe",2019-10-08T08:56:59Z,"K. Zhu, M. Victoria, G. B. Andresen, M. Greiner","To limit the global temperature increase to 1.5 degrees Celsius, fossil-free
energy systems will be required eventually. To understand how such systems can
be designed, the current state-of-the-art is to apply techno-economical
optimisation modelling with high spatial and temporal resolution. This approach
relies on a number of climatic, technical and economic predictions that reach
multiple decades into the future. In this paper, we investigate how the design
of a fossil-free energy system for Europe is affected by changes in these
assumptions. In particular, the synergy among renewable generators,
power-to-heat converters, storage units, synthetic gas and transmission manage
to deliver an affordable net-zero emissions system. We find that levelised cost
of energy decreases due to heat savings, but not for global temperature
increases. In both cases, heat pumps become less favourable as surplus
electricity is more abundant for heating. Demand-side management through
buildings' thermal inertia could shape the heating demand, yet has modest
impact on the system configuration. Cost reductions of heat pumps impact
resistive heaters substantially, but not the opposite. Cheaper power-to-gas
could lower the need for thermal energy storage.",http://arxiv.org/abs/1910.03283v4
"Multiplicity of time scales in climate, matter, life, and economy",2019-07-01T09:21:09Z,"Bernhelm Booss-Bavnbek, Rasmus Kristoffer Pedersen, Ulf Rørbæk Pedersen","This topic review communicates working experiences regarding interaction of a
multiplicity of processes. Our experiences come from climate change modelling,
materials science, cell physiology and public health, and macroeconomic
modelling. We look at the astonishing advances of recent years in broad-band
temporal frequency sampling, multiscale modelling and fast large-scale
numerical simulation of complex systems, but also the continuing uncertainty of
many science-based results.
  We describe and analyse properties that depend on the time scale of the
measurement; structural instability; tipping points; thresholds; hysteresis;
feedback mechanisms with runaways or stabilizations or delays. We point to
grave disorientation in statistical sampling, the interpretation of
observations and the design of control when neglecting the presence or
emergence of multiple characteristic times.
  We explain what these working experiences can demonstrate for environmental
research.",http://arxiv.org/abs/1907.01902v2
"Convective dynamics and the response of precipitation extremes to
  warming in radiative-convective equilibrium",2019-09-04T16:59:47Z,"Tristan H. Abbott, Timothy W. Cronin, Tom Beucler","Tropical precipitation extremes are expected to strengthen with warming, but
quantitative estimates remain uncertain because of a poor understanding of
changes in convective dynamics. This uncertainty is addressed here by analyzing
idealized convection-permitting simulations of radiative-convective equilibrium
in long-channel geometry. Across a wide range of climates, the thermodynamic
contribution to changes in instantaneous precipitation extremes follows
near-surface moisture, and the dynamic contribution is positive and small, but
sensitive to domain size. The shapes of mass flux profiles associated with
precipitation extremes are determined by conditional sampling that favors
strong vertical motion at levels where the vertical saturation specific
humidity gradient is large, and mass flux profiles collapse to a common shape
across climates when plotted in a moisture-based vertical coordinate. The
collapse, robust to changes in microphysics and turbulence schemes, implies a
thermodynamic contribution that scales with near-surface moisture despite
substantial convergence aloft and allows the dynamic contribution to be defined
by the pressure velocity at a single level. Linking the simplified dynamic mode
to vertical velocities from entraining plume models reveals that the small
dynamic mode in channel simulations (<~2 %/K) is caused by opposing
height-dependences of vertical velocity and density, together with the
buffering influence of cloud-base buoyancies that vary little with surface
temperature. These results reinforce an emerging picture of the response of
extreme tropical precipitation rates to warming: a thermodynamic mode of about
7 %/K dominates, with a minor contribution from changes in dynamics.",http://arxiv.org/abs/1909.01941v4
"The Middle Pleistocene Transition by frequency locking and slow ramping
  of internal period",2019-01-06T10:02:21Z,"Karl H. M. Nyman, Peter D. Ditlevsen","The increase in glacial cycle length from approximately $41$ to on average
$100$ thousand years around $1$ million years ago, called the Middle
Pleistocene Transition (MPT), lacks a conclusive explanation. We describe a
dynamical mechanism which we call Ramping with Frequency Locking (RFL), that
explains the transition by an interaction between the internal period of a
self-sustained oscillator and forcing that contains periodic components. This
mechanism naturally explains the abrupt increase in cycle length from
approximately $40$ to $80$ thousand years observed in proxy data, unlike some
previously proposed mechanisms for the MPT. A rapid increase in durations can
be produced by a rapid change in an external parameter, but this assumes rather
than explains the abruptness. In contrast, models relying on frequency locking
can produce a rapid change in durations assuming only a slow change in an
external parameter. We propose a scheme for detecting RFL in complex,
computationally expensive models, and motivate the search for climate variables
that can gradually increase the internal period of the glacial cycles.",http://arxiv.org/abs/1901.01523v1
Optimal Investment to Enable Evolutionary Rescue,2019-02-23T18:48:29Z,"Jaime Ashander, Lisa C. Thompson, James N. Sanchirico, Marissa L. Baskett","'Evolutionary rescue' is the potential for evolution to enable population
persistence in a changing environment. Even with eventual rescue, evolutionary
time lags can cause the population size to temporarily fall below a threshold
susceptible to extinction. To reduce extinction risk given human-driven global
change, conservation management can enhance populations through actions such as
captive breeding. To quantify the optimal timing of, and indicators for
engaging in, investment in temporary enhancement to enable evolutionary rescue,
we construct a model of coupled demographic-genetic dynamics given a moving
optimum. We assume 'decelerating change', as might be relevant to climate
change, where the rate of environmental change initially exceeds a rate where
evolutionary rescue is possible, but eventually slows. We analyze the optimal
control path of an intervention to avoid the population size falling below a
threshold susceptible to extinction, minimizing costs. We find that the optimal
path of intervention initially increases as the population declines, then
declines and ceases when the population growth rate becomes positive, which
lags the stabilization in environmental change. In other words, the optimal
strategy involves increasing investment even in the face of a declining
population, and positive population growth could serve as a signal to end the
intervention. In addition, a greater carrying capacity relative to the initial
population size decreases the optimal intervention. Therefore, a one-time
action to increase carrying capacity, such as habitat restoration, can reduce
the amount and duration of longer-term investment in population enhancement,
even if the population is initially lower than and declining away from the new
carrying capacity.",http://arxiv.org/abs/1902.08827v1
Gain Stabilization of SiPMs with an Adaptive Power Supply,2019-02-17T13:40:16Z,"G. Eigen, J. Cvach, J. Kvasnicka, I. Polak, A. Træet, J. Zalieckas","The gain of silicon photomultipliers (SiPMs) increases with bias voltage and
decreases with temperature. To operate SiPMs at stable gain, the bias voltage
can be readjusted to compensate for temperature changes. We have tested this
concept with 30 SiPMs from three manufacturers (Hamamatsu, KETEK and CPTA)
operating in a climate chamber at CERN by varying temperatures between $1^\circ
\rm C$ and $48^\circ \rm C$. We built an adaptive power supply that uses a
linear dependence of the bias voltage on temperature. We stabilized four SiPMs
simultaneously with only one compensation parameter for the readjustment of the
bias voltage of four SiPMs. For all tested Hamamatsu and CPTA SiPMs we achieved
our goal of limiting gain changes to less than $\pm 0.5\%$ in the $20-30^\circ
C$ temperature range.",http://arxiv.org/abs/1902.06261v4
"Exponentially decaying modes and long-term prediction of sea ice
  concentration using Koopman Mode Decomposition",2019-11-04T19:01:35Z,"James Hogg, Maria Fonoberova, Igor Mezic","Sea ice cover in the Arctic and Antarctic is an important indicator of
changes in the climate, with important environmental, economic and security
consequences. The complexity of the spatio-temporal dynamics of sea ice makes
it difficult to assess the temporal nature of the changes - e.g. linear or
exponential - and their precise geographical loci. In this study, Koopman Mode
Decomposition (KMD) was applied to satellite data of sea ice concentration for
the northern and southern hemispheres to gain insight into the temporal and
spatial dynamics of the sea ice behavior and to predict future sea ice
behavior. We discover exponentially decaying spatial modes in both hemispheres
and discuss their precise spatial extent, and also perform precise geographic
predictions of sea ice concentration up to four years in the future. This
data-driven decomposition technique gives insight in spatial and temporal
dynamics not apparent in traditional linear approaches.",http://arxiv.org/abs/1911.01450v1
"Reinforcement Learning-Enabled Reliable Wireless Sensor Networks in
  Dynamic Underground Environments",2019-08-16T01:01:39Z,"Hongzhi Guo, Bincy Ben","Wireless underground sensor networks play an important role in underground
sensing such as climate-smart agriculture and underground infrastructure
monitoring. Existing works consider a static underground environment, which is
not practical since the dielectric parameters of soil change frequently due to
precipitation and harsh weather. This challenge cannot be ignored in real
implementation due to the drastic change of wireless underground channel. In
this paper, we study the effect of dynamic underground environment on wireless
communications for sensor networks. We use the real data collected by in-situ
sensors to train a Hidden Markov Model. Then, by using reinforcement learning,
we derive the optimal transmission policies for underground sensors to
efficiently use their energy and reduce the number of dropped and
unsuccessfully transmitted packets. Through simulations using real data, we
find that the developed algorithm can reduce the packet loss and transmit the
sensed data in a timely manner.",http://arxiv.org/abs/1908.05804v2
Endogenous Coalition Formation in Policy Debates,2019-03-25T13:03:14Z,"Philip Leifeld, Laurence Brandenberger","Political actors form coalitions around their joint normative beliefs in
order to influence the policy process on contentious issues such as climate
change or population ageing. Policy process theory maintains that learning
within and across coalitions is a central predictor of coalition formation and
policy change but has yet to explain how policy learning works. The present
article explains the formation and maintenance of coalitions by focusing on the
ways actors adopt policy beliefs from other actors in policy debates. A policy
debate is a complex social system in which temporal network dependence guides
how actors contribute ideological statements to the debate. Belief adoption
matters in three complementary ways: bonding, which exploits cues within
coalitions; bridging, which explores new beliefs outside one's perimeter in the
debate; and repulsion, which reinforces polarization between coalitions and
cements their belief systems. We formalize this theory of endogenous coalition
formation in policy debates and test it on a micro-level empirical dataset
using statistical network analysis and event history analysis.",http://arxiv.org/abs/1904.05327v2
A New Mathematical Framework for Atmospheric Blocking Events,2019-02-22T12:29:26Z,"Valerio Lucarini, Andrey Gritsun","We use a simple yet Earth-like atmospheric model to propose a new framework
for understanding the mathematics of blocking events. Analysing error growth
rates along a very long model trajectory, we show that blockings are associated
with conditions of anomalously high instability of the atmosphere.
Additionally, the lifetime of a blocking is positively correlated with the
intensity of such an anomaly, against intuition. In the case of Atlantic
blockings, predictability is especially reduced at the onset and decay of the
blocking, while a relative increase of predictability is found in the mature
phase, while the opposite holds for Pacific blockings, for which predictability
is lowest in the mature phase. We associate blockings to a specific class of
unstable periodic orbits (UPOs), natural modes of variability that cover the
attractor of the system. The UPOs differ substantially in terms of instability,
which explains the diversity of the atmosphere in terms predictability. The
UPOs associated to blockings are indeed anomalously unstable, which leads to
them being rarely visited. The onset of a blocking takes place when the
trajectory of the system hops into the neighbourhood of one of these special
UPOs. The decay takes place when the trajectory hops back to the neighbourhood
of usual, less unstable UPOs associated with zonal flow. This justifies the
classical Markov chains-based analysis of transitions between weather regimes.
The existence of UPOs differing in the dimensionality of their unstable
manifold indicates a very strong violation of hyperbolicity in the model, which
leads to a lack of structural stability. We propose that this is could be a
generic feature of atmospheric models and might be a fundamental cause behind
difficulties in representing blockings for the current climate and
uncertainties in predicting how their statistics will change as a result of
climate change.",http://arxiv.org/abs/1902.08464v3
"Statistical analysis and stochastic interest rate modelling for valuing
  the future with implications in climate change mitigation",2019-10-03T14:55:11Z,"Josep Perelló, Miquel Montero, Jaume Masoliver, J. Doyne Farmer, John Geanakoplos","High future discounting rates favor inaction on present expending while lower
rates advise for a more immediate political action. A possible approach to this
key issue in global economy is to take historical time series for nominal
interest rates and inflation, and to construct then real interest rates and
finally obtaining the resulting discount rate according to a specific
stochastic model. Extended periods of negative real interest rates, in which
inflation dominates over nominal rates, are commonly observed, occurring in
many epochs and in all countries. This feature leads us to choose a well-known
model in statistical physics, the Ornstein-Uhlenbeck model, as a basic
dynamical tool in which real interest rates randomly fluctuate and can become
negative, even if they tend to revert to a positive mean value. By covering 14
countries over hundreds of years we suggest different scenarios and include an
error analysis in order to consider the impact of statistical uncertainty in
our results. We find that only 4 of the countries have positive long-run
discount rates while the other ten countries have negative rates. Even if one
rejects the countries where hyperinflation has occurred, our results support
the need to consider low discounting rates. The results provided by these
fourteen countries significantly increase the priority of confronting global
actions such as climate change mitigation. We finally extend the analysis by
first allowing for fluctuations of the mean level in the Ornstein-Uhlenbeck
model and secondly by considering modified versions of the Feller and lognormal
models. In both cases, results remain basically unchanged thus demonstrating
the robustness of the results presented.",http://arxiv.org/abs/1910.01928v2
"Automatic Detection and Compression for Passive Acoustic Monitoring of
  the African Forest Elephant",2019-02-25T02:48:54Z,"Johan Bjorck, Brendan H. Rappazzo, Di Chen, Richard Bernstein, Peter H. Wrege, Carla P. Gomes","In this work, we consider applying machine learning to the analysis and
compression of audio signals in the context of monitoring elephants in
sub-Saharan Africa. Earth's biodiversity is increasingly under threat by
sources of anthropogenic change (e.g. resource extraction, land use change, and
climate change) and surveying animal populations is critical for developing
conservation strategies. However, manually monitoring tropical forests or deep
oceans is intractable. For species that communicate acoustically, researchers
have argued for placing audio recorders in the habitats as a cost-effective and
non-invasive method, a strategy known as passive acoustic monitoring (PAM). In
collaboration with conservation efforts, we construct a large labeled dataset
of passive acoustic recordings of the African Forest Elephant via
crowdsourcing, compromising thousands of hours of recordings in the wild. Using
state-of-the-art techniques in artificial intelligence we improve upon
previously proposed methods for passive acoustic monitoring for classification
and segmentation. In real-time detection of elephant calls, network bandwidth
quickly becomes a bottleneck and efficient ways to compress the data are
needed. Most audio compression schemes are aimed at human listeners and are
unsuitable for low-frequency elephant calls. To remedy this, we provide a novel
end-to-end differentiable method for compression of audio signals that can be
adapted to acoustic monitoring of any species and dramatically improves over
naive coding strategies.",http://arxiv.org/abs/1902.09069v1
"Modeling and simulation of heat source trajectories through phase-change
  materials",2019-09-19T09:28:27Z,Alexander Gary Zimmerman,"The modeling and simulation of heat source trajectories through phase-change
materials is a relevant problem both for space exploration and for terrestrial
climate research, among other fields. In space, the DLR and NASA are both
interested in exploring beneath the surfaces of icy moons, primarily Enceladus
and Europa, where conditions may alloy for extraterrestrial life. On Earth,
unique sub-glacial aquatic ecosystems offer potential for geo-biological
discoveries. Unfortunately, existing ice-drilling technology is dirty and
cumbersome.
  Melting probes are a clean and compact alternative technology which use
heaters to melt through the ice. A melting probe's trajectory can be controlled
with differential heating. Successful trajectory control requires advancements
not only in the modeling and simulation of the ambient dynamics, but also of
the probe's coupled rigid body dynamics. Fundamentally, the rigid body dynamics
can be modeled by the equations of motion; but this approach is prohibitively
complex.
  This work proposes an approach which exploits that the motion of the probe is
driven by contact with the evolving liquid-solid interface. From this
perspective, an energy minimization problem is formulated. The general
mathematical problem is formulated as two split operators, respectively for the
rigid body dynamics and the ambient dynamics. These operators are coupled with
feasibility constraints which ensure that the probe does not penetrate the
solid. Concrete examples are shown both for the energy minimization problem and
for the unsteady ambient dynamics. Finally, an algorithm is presented for the
temporal coupling of the split operators, which is implemented using Python and
C++. Example trajectories are shown, including the dynamic response of the
probe velocity to a rapid change in the heat flux.",http://arxiv.org/abs/1909.08882v1
"Towards the prediction of critical transitions in spatially extended
  populations with cubical homology",2019-12-02T19:00:05Z,"Laura S. Storch, Sarah L. Day","The prediction of critical transitions, such as extinction events, is vitally
important to preserving vulnerable populations in the face of a rapidly
changing climate and continuously increasing human resource usage. Predicting
such events in spatially distributed populations is challenging because of the
high dimensionality of the system and the complexity of the system dynamics.
Here, we reduce the dimensionality of the problem by quantifying spatial
patterns via Betti numbers ($\beta_0$ and $\beta_1$), which count particular
topological features in a topological space. Spatial patterns representing
regions occupied by the population are analyzed in a coupled patch population
model with Ricker map growth and nearest-neighbors dispersal on a
two-dimensional lattice. We illustrate how Betti numbers can be used to
characterize spatial patterns by type, which in turn may be used to track
spatiotemporal changes via Betti number time series and characterize asymptotic
dynamics of the model parameter space. En route to a global extinction event,
we find that the Betti number time series of a population exhibits
characteristic changes. We hope these preliminary results will be used to aide
in the prediction of critical transitions in spatially extended systems.
Additional applications of this technique include analysis of spatial data
(e.g., GIS) and model validation.",http://arxiv.org/abs/1912.01021v1
How on Earth: Flourishing in a Not-for-Profit World by 2050,2019-02-04T17:33:48Z,"Jennifer Hinton, Donnie Maclurcan","In this book, we outline a model of a non-capitalist market economy based on
not-for-profit forms of business. This work presents both a critique of the
current economic system and a vision of a more socially, economically, and
ecologically sustainable economy. The point of departure is the purpose and
profit-orientation embedded in the legal forms used by businesses (e.g.,
for-profit or not-for-profit) and the ramifications of this for global
sustainability challenges such as environmental pollution, resource use,
climate change, and economic inequality. We document the rapid rise of
not-for-profit forms of business in the global economy and offer a conceptual
framework and an analytical lens through which to view these relatively new
economic actors and their potential for transforming the economy. The book
explores how a market consisting of only or mostly not-for-profit forms of
business might lead to better financial circulation, economic equality, social
well-being, and environmental regeneration as compared to for-profit markets.",http://arxiv.org/abs/1902.01398v1
"Scaling properties of noise-induced switching in a bistable tunnel diode
  circuit",2019-02-23T01:02:32Z,"Stephen W. Teitsworth, Matthew E. Olson, Yuriy Bomze","Noise-induced switching between coexisting metastable states occurs in a wide
range of far-from-equilibrium systems including micro-mechanical oscillators,
epidemiological and climate change models, and nonlinear electronic transport
in tunneling structures such as semiconductor superlattices and tunnel diodes.
In the case of tunnel diode circuits, noise-induced switching behavior is
associated with negative differential resistance in the static current-voltage
characteristics and bistability, i.e., the existence of two macroscopic current
states for a given applied voltage. Noise effects are particularly strong near
the onset and offset of bistable current behavior, corresponding to bifurcation
points in the associated dynamical system. In this paper, we show that the
tunnel diode system provides an excellent experimental platform for the
precision measurement of scaling properties of mean switching times versus
applied voltage near bifurcation points. More specifically, experimental data
confirm that the mean switching time scales logarithmically as the 3/2 power of
voltage difference over an exceptionally wide range of time scales and noise
intensities.",http://arxiv.org/abs/1902.08711v1
AI Ethics for Systemic Issues: A Structural Approach,2019-11-08T12:31:49Z,"Agnes Schim van der Loeff, Iggy Bassi, Sachin Kapila, Jevgenij Gamper","The debate on AI ethics largely focuses on technical improvements and
stronger regulation to prevent accidents or misuse of AI, with solutions
relying on holding individual actors accountable for responsible AI
development. While useful and necessary, we argue that this ""agency"" approach
disregards more indirect and complex risks resulting from AI's interaction with
the socio-economic and political context. This paper calls for a ""structural""
approach to assessing AI's effects in order to understand and prevent such
systemic risks where no individual can be held accountable for the broader
negative impacts. This is particularly relevant for AI applied to systemic
issues such as climate change and food security which require political
solutions and global cooperation. To properly address the wide range of AI
risks and ensure 'AI for social good', agency-focused policies must be
complemented by policies informed by a structural approach.",http://arxiv.org/abs/1911.03216v1
"Resilience of Urban Transport Network-of-Networks under Intense Flood
  Hazards Exacerbated by Targeted Attacks",2019-11-15T01:21:46Z,"Nishant Yadav, Samrat Chatterjee, Auroop R. Ganguly","Natural hazards including floods can trigger catastrophic failures in
interdependent urban transport network-of-networks (NoNs). Population growth
has enhanced transportation demand while urbanization and climate change have
intensified urban floods. However, despite the clear need to develop actionable
insights for improving the resilience of critical urban lifelines, the theory
and methods remain underdeveloped. Furthermore, as infrastructure systems
become more intelligent, security experts point to the growing threat of
targeted cyber-physical attacks during natural hazards. Here we develop a
hypothesis-driven resilience framework for urban transport NoNs, which we
demonstrate on the London Rail Network (LRN). We find that topological
attributes designed for maximizing efficiency rather than robustness render the
network more vulnerable to compound natural-targeted threats including
cascading failures. Our results suggest that an organizing principle for
post-disruption recovery may be developed with network science principles. Our
findings and frameworks can generalize to urban lifelines and more generally to
real-world spatial networks.",http://arxiv.org/abs/1911.06440v2
"Leveraging Decentralized Artificial Intelligence to Enhance Resilience
  of Energy Networks",2019-11-18T15:13:48Z,"Ahmed Imteaj, M. Hadi Amini, Javad Mohammadi","This paper reintroduces the notion of resilience in the context of recent
issues originated from climate change triggered events including severe
hurricanes and wildfires. A recent example is PG&E's forced power outage to
contain wildfire risk which led to widespread power disruption. This paper
focuses on answering two questions: who is responsible for resilience? and how
to quantify the monetary value of resilience? To this end, we first provide
preliminary definitions of resilience for power systems. We then investigate
the role of natural hazards, especially wildfire, on power system resilience.
Finally, we will propose a decentralized strategy for a resilient management
system using distributed storage and demand response resources. Our proposed
high fidelity model provides utilities, operators, and policymakers with a
clearer picture for strategic decision making and preventive decisions.",http://arxiv.org/abs/1911.07690v1
"Energy Usage Reports: Environmental awareness as part of algorithmic
  accountability",2019-11-19T15:34:28Z,"Kadan Lottick, Silvia Susai, Sorelle A. Friedler, Jonathan P. Wilson","The carbon footprint of algorithms must be measured and transparently
reported so computer scientists can take an honest and active role in
environmental sustainability. In this paper, we take analyses usually applied
at the industrial level and make them accessible for individual computer
science researchers with an easy-to-use Python package. Localizing to the
energy mixture of the electrical power grid, we make the conversion from energy
usage to CO2 emissions, in addition to contextualizing these results with more
human-understandable benchmarks such as automobile miles driven. We also
include comparisons with energy mixtures employed in electrical grids around
the world. We propose including these automatically-generated Energy Usage
Reports as part of standard algorithmic accountability practices, and
demonstrate the use of these reports as part of model-choice in a machine
learning context.",http://arxiv.org/abs/1911.08354v2
"A Survey on the Role of Wireless Sensor Networks and IoT in Disaster
  Management",2019-09-23T13:11:11Z,"Ahsan Adeel, Mandar Gogate, Saadullah Farooq, Cosimo Ieracitano, Kia Dashtipour, Hadi Larijani, Amir Hussain","Extreme events and disasters resulting from climate change or other
ecological factors are difficult to predict and manage. Current limitations of
state-of-the-art approaches to disaster prediction and management could be
addressed by adopting new unorthodox risk assessment and management strategies.
The next generation Internet of Things (IoT), Wireless Sensor Networks (WSNs),
5G wireless communication, and big data analytics technologies are the key
enablers for future effective disaster management infrastructures. In this
chapter, we commissioned a survey on emerging wireless communication
technologies with potential for enhancing disaster prediction, monitoring, and
management systems. Challenges, opportunities, and future research trends are
highlighted to provide some insight on the potential future work for
researchers in this field.",http://arxiv.org/abs/1909.10353v1
"Assessing temporal complementarity between three variable energy sources
  by means of correlation and compromise programming",2019-04-30T21:58:31Z,"Fausto A. Canales, Jakub Jurasz, Alexandre Beluco, Alexander Kies","Renewable energies are deployed worldwide to mitigate climate change and push
power systems towards sustainability. However, the weather-dependent nature of
renewable energy sources often hinders their integration to national grids.
Combining different sources to profit from beneficial complementarity has often
been proposed as a partial solution to overcome these issues. This paper
introduces a novel method for quantifying total temporal energetic
complementarity between three different variable renewable sources, based on
well-known mathematical techniques: correlation coefficients and compromise
programming. It has the major advantage of allowing the simultaneous assessment
of partial and total complementarity. The method is employed to study the
complementarity of wind, solar and hydro resources on different temporal scales
in a region of Poland. Results show that timescale selection has a determinant
impact on the total temporal complementarity.",http://arxiv.org/abs/1905.00117v1
"Efficient Electrocatalytic Reduction of CO2 by Nitrogen-Doped Nanoporous
  Carbon-Carbon Nanotube Membranes - A Step Towards the Electrochemical CO2
  Refinery",2019-05-04T09:55:18Z,"Hong Wang, Jia Jia, Pengfei Song, Qiang Wang, Debao Li, Shixiong Min, Chenxi Qian, Lu Wang, Young Feng Li, Chun Ma, Tom Wu, Jiayin Yuan, Markus Antonietti, Geoffrey A. Ozin","The search for earth abundant, efficient and stable electrocatalysts that can
enable the chemical reduction of CO2 to value-added chemicals and fuels at an
industrially relevant scale, is a high priority for the development of a global
network of renewable energy conversion and storage systems that can
meaningfully impact greenhouse gas induced climate change. Here we introduce a
straightforward, low cost, scalable and technologically relevant method to
manufacture an all-carbon, electroactive, nitrogen-doped nanoporous
carbon-carbon nanotube composite membrane, dubbed ""HNCM-CNT"". The membrane is
demonstrated to function as a binder-free, high-performance electrode for the
electrocatalytic reduction of CO2 to formate. The Faradaic efficiency for the
production of formate is 81%. Furthermore, the robust structural and
electrochemical properties of the membrane endow it with excellent long-term
stability.",http://arxiv.org/abs/1905.01466v1
Weakly Labeling the Antarctic: The Penguin Colony Case,2019-05-08T20:03:18Z,"Hieu Le, Bento Gonçalves, Dimitris Samaras, Heather Lynch","Antarctic penguins are important ecological indicators -- especially in the
face of climate change. In this work, we present a deep learning based model
for semantic segmentation of Ad\'elie penguin colonies in high-resolution
satellite imagery. To train our segmentation models, we take advantage of the
Penguin Colony Dataset: a unique dataset with 2044 georeferenced cropped images
from 193 Ad\'elie penguin colonies in Antarctica. In the face of a scarcity of
pixel-level annotation masks, we propose a weakly-supervised framework to
effectively learn a segmentation model from weak labels. We use a
classification network to filter out data unsuitable for the segmentation
network. This segmentation network is trained with a specific loss function,
based on the average activation, to effectively learn from the data with the
weakly-annotated labels. Our experiments show that adding weakly-annotated
training examples significantly improves segmentation performance, increasing
the mean Intersection-over-Union from 42.3 to 60.0% on the Penguin Colony
Dataset.",http://arxiv.org/abs/1905.03313v2
"Atmospheric bistability and abrupt transitions to superrotation:
  wave-jet resonance and Hadley cell feedbacks",2019-05-29T13:03:59Z,"Corentin Herbert, Rodrigo Caballero, Freddy Bouchet","Strong eastward jets at the equator have been observed in many planetary
atmospheres and simulated in numerical models of varying complexity. However,
the nature of the transition from a conventional state of the general
circulation, with easterlies or weak westerlies in the tropics, to such a
superrotating state remains unclear. Is it abrupt or continuous? This question
may have far-reaching consequences, as it may provide a mechanism for abrupt
climate change in a planetary atmosphere, both through the loss of stability of
the conventional circulation and through potential noise-induced transitions in
the bistability range. We study two feedbacks which may lead to bistability
between a conventional and a superrotating state: the Hadley cell feedback and
a wave-jet resonance feedback. We delineate the regime of applicability of
these two mechanisms in a simple model of zonal acceleration budget at the
equator. Then, we show using numerical simulations of the axisymmetric
primitive equations that the wave-jet resonance feedback indeed leads to robust
bistability, while the bistability governed by the Hadley cell feedback,
although observed in our numerical simulations, is much more fragile in a
multilevel model.",http://arxiv.org/abs/1905.12401v1
"How the geometry of cities explains urban scaling laws and determines
  their exponents",2019-08-20T16:10:53Z,"Carlos Molinero, Stefan Thurner","Urban scaling laws relate socio-economic, behavioral, and physical variables
to the population size of cities and allow for a new paradigm of city planning,
and an understanding of urban resilience and economies. Independently of
culture and climate, almost all cities exhibit two fundamental scaling
exponents, one sub-linear and one super-linear that are related. Here we show
that based on fundamental fractal geometric relations of cities we derive both
exponents and their relation. Sub-linear scaling arises as the ratio of the
fractal dimensions of the road network and the distribution of the population
in 3D. Super-linear scaling emerges from human interactions that are
constrained by the city geometry. We demonstrate the validity of the framework
with data on 4750 European cities. We make several testable predictions,
including the relation of average height of cities with population size, and
that at a critical population size, growth changes from horizontal
densification to three-dimensional growth.",http://arxiv.org/abs/1908.07470v1
"Probabilistic Forecasting of the Arctic Sea Ice Edge with Contour
  Modeling",2019-08-25T19:20:47Z,"Hannah M. Director, Adrian E. Raftery, Cecilia M. Bitz","Sea ice, or frozen ocean water, freezes and melts every year in the Arctic.
Forecasts of where sea ice will be located weeks to months in advance have
become more important as the amount of sea ice declines due to climate change,
for maritime planning and other uses. Typical sea ice forecasts are made with
ensemble models, physics-based models of sea ice and the surrounding ocean and
atmosphere. This paper introduces Mixture Contour Forecasting, a method to
forecast sea ice probabilistically using a mixture of two distributions, one
based on post-processed output from ensembles and the other on observed sea ice
patterns in recent years. At short lead times, these forecasts are better
calibrated than unadjusted dynamic ensemble forecasts and other statistical
reference forecasts. To produce these forecasts, a statistical technique is
introduced that directly models the sea ice edge contour, the boundary around
the region that is ice-covered. Mixture Contour Forecasting and reference
methods are evaluated for monthly sea ice forecasts for 2008-2016 at lead times
ranging from 0.5-6.5 months using one of the European Centre for Medium-Range
Weather Forecasts ensembles.",http://arxiv.org/abs/1908.09377v3
When Nash Meets Stackelberg,2019-10-14T22:32:13Z,"Margarida Carvalho, Gabriele Dragotto, Felipe Feijoo, Andrea Lodi, Sriram Sankaranarayanan","This article introduces a class of $Nash$ games among $Stackelberg$ players
($NASPs$), namely, a class of simultaneous non-cooperative games where the
players solve sequential Stackelberg games. Specifically, each player solves a
Stackelberg game where a leader optimizes a (parametrized) linear objective
function subject to linear constraints while its followers solve convex
quadratic problems subject to the standard optimistic assumption. Although we
prove that deciding if a $NASP$ instance admits a Nash equilibrium is generally
a $\Sigma^2_p$-hard decision problem, we devise two exact and
computationally-efficient algorithms to compute and select Nash equilibria or
certify that no equilibrium exists. We apply $NASPs$ to model the hierarchical
interactions of international energy markets where climate-change aware
regulators oversee the operations of profit-driven energy producers. By
combining real-world data with our models, we find that Nash equilibria provide
informative, and often counterintuitive, managerial insights for market
regulators.",http://arxiv.org/abs/1910.06452v6
"Artificial intelligence for elections: the case of 2019 Argentina
  primary and presidential election",2019-10-24T15:32:31Z,"Zhenkun Zhou, Hernan A. Makse","We use a method based on machine learning, big-data analytics, and network
theory to process millions of messages posted in Twitter to predict election
outcomes. The model has achieved accurate results in the current Argentina
primary presidential election on August 11, 2019 by predicting the large
difference win of candidate Alberto Fernandez over president Mauricio Macri; a
result that none of the traditional pollsters in that country was able to
predict, and has led to a major bond market collapse. We apply the model to the
upcoming Argentina presidential election on October 27, 2019 yielding the
following results: Fernandez 47.5%, Macri 30.9% and third party 21.6%. Our
method improves over traditional polling methods which are based on direct
interactions with small number of individuals that are plagued by ever
declining response rates, currently falling in the low single digits. They
provide a reliable polling method that can be applied not only to predict
elections but to discover any trend in society, for instance, what people think
about climate change, politics or education.",http://arxiv.org/abs/1910.11227v1
"Decadal attribution of historic temperature and ocean heat content
  change to anthropogenic emissions",2019-10-30T03:49:10Z,"E. J. L. Larson, R. W. Portmann, S. Solomon, D. M. Murphy","We present an alternative method of calculating the historical effective
radiative forcing using the observed temperature record and a kernel based on
the CMIP5 temperature response. This estimate is the effective radiative
forcing time series that the average climate model would need to simulate the
observed global mean surface temperature anomalies. We further infer the
anthropogenic aerosols radiative forcing as a residual using the better-known
greenhouse gas radiative forcing. This allows an independent estimate of
anthropogenic aerosol radiative forcing, which suggests a cooling influence due
to aerosols in the early part of the 20th century. The temporal kernels are
also used to calculate decadal contributions from the dominant forcing agents
to present day temperature, ocean heat content, and thermosteric sea level
rise. The current global mean temperature anomaly is dominated by emissions in
the past two decades, while current ocean heat content is more strongly
affected by earlier decades.",http://arxiv.org/abs/1910.13651v1
"An extended transfer operator approach for time-consistent coherent set
  analysis",2019-03-12T16:56:01Z,"Benedict Lünsmann, Rahel Vortmeyer-Kley, Holger Kantz","Coherent oceanic mesoscale structures, especially the non-filamenting cores
of oceanic eddies, have gained a lot of attention in recent years. These
Lagrangian structures are considered to play a significant role in oceanic
transport processes which, in turn, impact marine life, weather and potentially
even the climate itself. Answering questions regarding these phenomena requires
robust tools for the detection and identification of these structures. In this
article, we use transfer operator ideas to develop a novel method for the
identification of weakly-mixing coherent volumes in oceanic velocity field data
sets. Unlike other methods, the approach focuses on maximizing consistency over
longer time periods. We employ a time-centralized transfer operator approach
with practical modifications to identify potential structures in predetermined
domains and couple adjacent time steps to decide how to conduct the final
partitioning. The analysis pipeline includes plausibility checks that give
further insights into the stability and coherence of the inferred structure.
The presented method is able to find changing masses of maximal coherence in
stationary and non-stationary toy models and yields good results when applied
to field data.",http://arxiv.org/abs/1903.05086v1
"Data Augmentation for Leaf Segmentation and Counting Tasks in Rosette
  Plants",2019-03-20T16:13:10Z,"Dmitry Kuznichov, Alon Zvirin, Yaron Honen, Ron Kimmel","Deep learning techniques involving image processing and data analysis are
constantly evolving. Many domains adapt these techniques for object
segmentation, instantiation and classification. Recently, agricultural
industries adopted those techniques in order to bring automation to farmers
around the globe. One analysis procedure required for automatic visual
inspection in this domain is leaf count and segmentation. Collecting labeled
data from field crops and greenhouses is a complicated task due to the large
variety of crops, growth seasons, climate changes, phenotype diversity, and
more, especially when specific learning tasks require a large amount of labeled
data for training. Data augmentation for training deep neural networks is well
established, examples include data synthesis, using generative semi-synthetic
models, and applying various kinds of transformations. In this paper we propose
a method that preserves the geometric structure of the data objects, thus
keeping the physical appearance of the data-set as close as possible to imaged
plants in real agricultural scenes. The proposed method provides state of the
art results when applied to the standard benchmark in the field, namely, the
ongoing Leaf Segmentation Challenge hosted by Computer Vision Problems in Plant
Phenotyping.",http://arxiv.org/abs/1903.08583v1
"Make Thunderbolts Less Frightening -- Predicting Extreme Weather Using
  Deep Learning",2019-12-03T10:17:48Z,"Christian Schön, Jens Dittrich","Forecasting severe weather conditions is still a very challenging and
computationally expensive task due to the enormous amount of data and the
complexity of the underlying physics. Machine learning approaches and
especially deep learning have however shown huge improvements in many research
areas dealing with large datasets in recent years. In this work, we tackle one
specific sub-problem of weather forecasting, namely the prediction of
thunderstorms and lightning. We propose the use of a convolutional neural
network architecture inspired by UNet++ and ResNet to predict thunderstorms as
a binary classification problem based on satellite images and lightnings
recorded in the past. We achieve a probability of detection of more than 94%
for lightnings within the next 15 minutes while at the same time minimizing the
false alarm ratio compared to previous approaches.",http://arxiv.org/abs/1912.01277v2
"Increasing performance of electric vehicles in ride-hailing services
  using deep reinforcement learning",2019-12-07T01:18:53Z,"Jacob F. Pettit, Ruben Glatt, Jonathan R. Donadee, Brenden K. Petersen","New forms of on-demand transportation such as ride-hailing and connected
autonomous vehicles are proliferating, yet are a challenging use case for
electric vehicles (EV). This paper explores the feasibility of using deep
reinforcement learning (DRL) to optimize a driving and charging policy for a
ride-hailing EV agent, with the goal of reducing costs and emissions while
increasing transportation service provided. We introduce a data-driven
simulation of a ride-hailing EV agent that provides transportation service and
charges energy at congested charging infrastructure. We then formulate a test
case for the sequential driving and charging decision making problem of the
agent and apply DRL to optimize the agent's decision making policy. We evaluate
the performance against hand-written policies and show that our agent learns to
act competitively without any prior knowledge.",http://arxiv.org/abs/1912.03408v1
"SolarNet: A Deep Learning Framework to Map Solar Power Plants In China
  From Satellite Imagery",2019-12-08T14:19:47Z,"Xin Hou, Biao Wang, Wanqi Hu, Lei Yin, Haishan Wu","Renewable energy such as solar power is critical to fight the ever more
serious climate change. China is the world leading installer of solar panel and
numerous solar power plants were built. In this paper, we proposed a deep
learning framework named SolarNet which is designed to perform semantic
segmentation on large scale satellite imagery data to detect solar farms.
SolarNet has successfully mapped 439 solar farms in China, covering near 2000
square kilometers, equivalent to the size of whole Shenzhen city or two and a
half of New York city. To the best of our knowledge, it is the first time that
we used deep learning to reveal the locations and sizes of solar farms in
China, which could provide insights for solar power companies, market analysts
and the government.",http://arxiv.org/abs/1912.03685v2
"Taking Ethics, Fairness, and Bias Seriously in Machine Learning for
  Disaster Risk Management",2019-12-10T20:37:45Z,"Robert Soden, Dennis Wagenaar, Dave Luo, Annegien Tijssen","This paper highlights an important, if under-examined, set of questions about
the deployment of machine learning technologies in the field of disaster risk
management (DRM). While emerging tools show promising capacity to support
scientific efforts to better understand and mitigate the threats posed by
disasters and climate change, our field must undertake a much more careful
assessment of the potential negative impacts that machine learning technologies
may create. We also argue that attention to these issues in the context of
machine learning affords the opportunity to have discussions about potential
ethics, bias, and fairness concerns within disaster data more broadly. In what
follows, we first describe some of the uses and potential benefits of
machine-learning technology in disaster risk management. We then draw on
research from other fields to speculate about potential negative impacts.
Finally, we outline a research agenda for how our disaster risk management can
begin to take these issues seriously and ensure that deployments of
machine-learning tools are conducted in a responsible and beneficial manner.",http://arxiv.org/abs/1912.05538v2
"Machine Learning-based Estimation of Forest Carbon Stocks to increase
  Transparency of Forest Preservation Efforts",2019-12-17T07:27:26Z,"Björn Lütjens, Lucas Liebenwein, Katharina Kramer","An increasing amount of companies and cities plan to become CO2-neutral,
which requires them to invest in renewable energies and carbon emission
offsetting solutions. One of the cheapest carbon offsetting solutions is
preventing deforestation in developing nations, a major contributor in global
greenhouse gas emissions. However, forest preservation projects historically
display an issue of trust and transparency, which drives companies to invest in
transparent, but expensive air carbon capture facilities. Preservation projects
could conduct accurate forest inventories (tree diameter, species, height etc.)
to transparently estimate the biomass and amount of stored carbon. However,
current rainforest inventories are too inaccurate, because they are often based
on a few expensive ground-based samples and/or low-resolution satellite
imagery. LiDAR-based solutions, used in US forests, are accurate, but
cost-prohibitive, and hardly-accessible in the Amazon rainforest. We propose
accurate and cheap forest inventory analyses through Deep Learning-based
processing of drone imagery. The more transparent estimation of stored carbon
will create higher transparency towards clients and thereby increase trust and
investment into forest preservation projects.",http://arxiv.org/abs/1912.07850v1
Deep learning predictions of sand dune migration,2019-12-13T01:17:42Z,"Kelly Kochanski, Divya Mohan, Jenna Horrall, Barry Rountree, Ghaleb Abdulla","A dry decade in the Navajo Nation has killed vegetation, dessicated soils,
and released once-stable sand into the wind. This sand now covers one-third of
the Nation's land, threatening roads, gardens and hundreds of homes. Many arid
regions have similar problems: global warming has increased dune movement
across farmland in Namibia and Angola, and the southwestern US. Current dune
models, unfortunately, do not scale well enough to provide useful forecasts for
the $\sim$5\% of land surfaces covered by mobile sand. We test the ability of
two deep learning algorithms, a GAN and a CNN, to model the motion of sand
dunes. The models are trained on simulated data from community-standard
cellular automaton model of sand dunes. Preliminary results show the GAN
producing reasonable forward predictions of dune migration at ten million times
the speed of the existing model.",http://arxiv.org/abs/1912.10798v1
Machine Learning for Precipitation Nowcasting from Radar Images,2019-12-11T22:46:54Z,"Shreya Agrawal, Luke Barrington, Carla Bromberg, John Burge, Cenk Gazen, Jason Hickey","High-resolution nowcasting is an essential tool needed for effective
adaptation to climate change, particularly for extreme weather. As Deep
Learning (DL) techniques have shown dramatic promise in many domains, including
the geosciences, we present an application of DL to the problem of
precipitation nowcasting, i.e., high-resolution (1 km x 1 km) short-term (1
hour) predictions of precipitation. We treat forecasting as an image-to-image
translation problem and leverage the power of the ubiquitous UNET convolutional
neural network. We find this performs favorably when compared to three commonly
used models: optical flow, persistence and NOAA's numerical one-hour HRRR
nowcasting prediction.",http://arxiv.org/abs/1912.12132v1
MEDEAS-World model calibration for the study of the energy transition,2019-06-04T14:21:24Z,"Gianluca Martelloni, Francesca Di Patti, Ilaria Perissi, Sara Falsini, Ugo Bardi","MEDEAS (Modelling the Energy Development under Environmental And
Socioeconomic constraint) World is a new global-aggregated
energy-economy-environmental model, which runs from 1995 to 2050. In this work,
we tested the MEDEAS world model to reproduce the IPCC (International Panel on
Climate Change) GHG (Green House Gases) emission pathways consistent with 2
{\deg}C Global Warming. We achieved parameter optimizations of the MEDEAS model
related to different scenarios until 2050. We chose to provide a sensitivity
analysis on the parameters that directly influence the emission curves focusing
on the annual growth of the RES (Renewable Energy Sources), GDP (Gross Domestic
Product) and annual population growth. From such an analysis, it has been
possible to infer the large impact of GDP on the emission scenarios.",http://arxiv.org/abs/1906.01997v3
"Circuitscape in Julia: High Performance Connectivity Modelling to
  Support Conservation Decisions",2019-06-08T23:46:47Z,"Ranjan Anantharaman, Kimberly Hall, Viral Shah, Alan Edelman","Connectivity across landscapes influences a wide range of
conservation-relevant ecological processes, including species movements, gene
flow, and the spread of wildfire, pests, and diseases. Recent improvements in
remote sensing data suggest great potential to advance connectivity models, but
computational constraints hinder these advances. To address this challenge, we
upgraded the widely-used Circuitscape connectivity package to the high
performance Julia programming language. Circuitscape.jl allows users to solve
problems faster via improved parallel processing and solvers, and supports
applications to larger problems (e.g., datasets with hundreds of millions of
cells). We document speed improvements of up to 1800\%. We also demonstrate
scaling of problem sizes up to 437 million grid cells. These improvements allow
modelers to work with higher resolution data, larger landscapes and perform
sensitivity analysis effortlessly. These improvements accelerate the pace of
innovation, helping modelers address pressing challenges like species range
shifts under climate change. Our collaboration between ecologists and computer
scientists has led to the use of connectivity models to inform conservation
decisions. Further, these next generation connectivity models will produce
results faster, facilitating stronger engagement with decision-makers.",http://arxiv.org/abs/1906.03542v1
"The Impact of Feature Causality on Normal Behaviour Models for
  SCADA-based Wind Turbine Fault Detection",2019-06-28T17:32:41Z,"Telmo Felgueira, Silvio Rodrigues, Christian S. Perone, Rui Castro","The cost of wind energy can be reduced by using SCADA data to detect faults
in wind turbine components. Normal behavior models are one of the main fault
detection approaches, but there is a lack of consensus in how different input
features affect the results. In this work, a new taxonomy based on the causal
relations between the input features and the target is presented. Based on this
taxonomy, the impact of different input feature configurations on the modelling
and fault detection performance is evaluated. To this end, a framework that
formulates the detection of faults as a classification problem is also
presented.",http://arxiv.org/abs/1906.12329v1
"Large presence of carbonic acid in CO$_2$-rich aqueous fluids under
  Earth's mantle conditions",2019-07-03T10:21:38Z,"Nore Stolte, Ding Pan","The chemistry of carbon in aqueous fluids at extreme pressure and temperature
conditions is of great importance to Earth's deep carbon cycle, which
substantially affects the carbon budget at Earth's surface and global climate
change. At ambient conditions, the concentration of carbonic acid in water is
negligible, so aqueous carbonic acid was simply ignored in previous geochemical
models. However, by applying extensive ab initio molecular dynamics simulations
at pressure and temperature conditions similar to those in Earth's upper
mantle, we found that carbonic acid can be the most abundant carbon species in
aqueous CO$_2$ solutions at ~10 GPa and 1000 K. The mole percent of carbonic
acid in total dissolved carbon species increases with increasing pressure along
an isotherm, while its mole percent decreases with increasing temperature along
an isobar. In CO$_2$-rich solutions, we found significant proton transfer
between carbonic acid molecules and bicarbonate ions, which may enhance the
conductivity of the solutions. The effects of pH buffering by carbonic acid may
play an important role in water-rock interactions in Earth's interior. Our
findings suggest that carbonic acid is an important carbon carrier in the deep
carbon cycle.",http://arxiv.org/abs/1907.01833v1
On the Evolution of U.S. Temperature Dynamics,2019-07-15T00:27:20Z,"Francis X. Diebold, Glenn D. Rudebusch","Climate change is a massive multidimensional shift. Temperature shifts, in
particular, have important implications for urbanization, agriculture, health,
productivity, and poverty, among other things. While much research has
documented rising mean temperature \emph{levels}, we also examine range-based
measures of daily temperature \emph{volatility}. Specifically, using data for
select U.S. cities over the past half-century, we compare the evolving time
series dynamics of the average temperature level, AVG, and the diurnal
temperature range, DTR (the difference between the daily maximum and minimum
temperatures). We characterize trend and seasonality in these two series using
linear models with time-varying coefficients. These straightforward yet
flexible approximations provide evidence of evolving DTR seasonality and stable
AVG seasonality.",http://arxiv.org/abs/1907.06303v3
Low-supervision urgency detection and transfer in short crisis messages,2019-07-15T20:43:53Z,"Mayank Kejriwal, Peilin Zhou","Humanitarian disasters have been on the rise in recent years due to the
effects of climate change and socio-political situations such as the refugee
crisis. Technology can be used to best mobilize resources such as food and
water in the event of a natural disaster, by semi-automatically flagging tweets
and short messages as indicating an urgent need. The problem is challenging not
just because of the sparseness of data in the immediate aftermath of a
disaster, but because of the varying characteristics of disasters in developing
countries (making it difficult to train just one system) and the noise and
quirks in social media. In this paper, we present a robust, low-supervision
social media urgency system that adapts to arbitrary crises by leveraging both
labeled and unlabeled data in an ensemble setting. The system is also able to
adapt to new crises where an unlabeled background corpus may not be available
yet by utilizing a simple and effective transfer learning methodology.
Experimentally, our transfer learning and low-supervision approaches are found
to outperform viable baselines with high significance on myriad disaster
datasets.",http://arxiv.org/abs/1907.06745v1
"Modeling and analysis of alternative distribution and Physical Internet
  schemes in urban area",2019-07-04T10:00:21Z,"Hao Jiang, Eric Ballot, Shenle Pan","Urban logistics is becoming more complicated and costlier due to new
challenges in recent years. Since the main problem lies on congestion, the
clean vehicle is not necessarily the most effective solution. There is thus a
need to redesign the logistics networks in the city. This paper proposes a
methodology to evaluate different distribution schemes in the city among which
we find the most efficient and sustainable one. External impacts are added to
the analysis of schemes, including accident, air pollution, climate change,
noise, and congestion. An optimization model based on an analytical model is
developed to optimize transportation means and distribution schemes. Results
based on Bordeaux city show that PI scheme improves the performances of
distribution.",http://arxiv.org/abs/1907.10593v1
Response and Sensitivity Using Markov Chains,2019-07-30T13:20:22Z,"Manuel Santos Gutiérrez, Valerio Lucarini","Dynamical systems are often subject to forcing or changes in their governing
parameters and it is of interest to study how this affects their statistical
properties. A prominent real-life example of this class of problems is the
investigation of climate response to perturbations. In this respect, it is
crucial to determine what the linear response of a system is to small
perturbations as a quantification of sensitivity. Alongside previous work, here
we use the transfer operator formalism to study the response and sensitivity of
a dynamical system undergoing perturbations. By projecting the transfer
operator onto a suitable finite dimensional vector space, one is able to obtain
matrix representations which determine finite Markov processes. Further, using
perturbation theory for Markov matrices, it is possible to determine the linear
and nonlinear response of the system given a prescribed forcing. Here, we
suggest a methodology which puts the scope on the evolution law of densities
(the Liouville/Fokker-Planck equation), allowing to effectively calculate the
sensitivity and response of two representative dynamical systems.",http://arxiv.org/abs/1907.12881v1
Astronomy in a Low-Carbon Future,2019-10-03T01:42:35Z,"Christopher D. Matzner, Nicolas B. Cowan, René Doyon, Vincent Hénault-Brunet, David Lafrenère, Martine Lokken, Peter G. Martin, Sharon Morsink, Magdalen Normandeau, Nathalie Ouellette, Mubdi Rahman, Joel Roediger, James Taylor, Rob Thacker, Marten van Kerkwijk","The global climate crisis poses new risks to humanity, and with them, new
challenges to the practices of professional astronomy. Avoiding the more
catastrophic consequences of global warming by more than 1.5 degrees requires
an immediate reduction of greenhouse gas emissions. According to the 2018
United Nations Intergovernmental Panel report, this will necessitate a 45%
reduction of emissions by 2030 and net-zero emissions by 2050. Efforts are
required at all levels, from the individual to the governmental, and every
discipline must find ways to achieve these goals. This will be especially
difficult for astronomy with its significant reliance on conference and
research travel, among other impacts. However, our long-range planning
exercises provide the means to coordinate our response on a variety of levels.
We have the opportunity to lead by example, rising to the challenge rather than
reacting to external constraints.
  We explore how astronomy can meet the challenge of a changing climate in
clear and responsible ways, such as how we set expectations (for ourselves, our
institutions, and our granting agencies) around scientific travel, the
organization of conferences, and the design of our infrastructure. We also
emphasize our role as reliable communicators of scientific information on a
problem that is both human and planetary in scale.",http://arxiv.org/abs/1910.01272v1
"Recruiting Hay to Find Needles: Recursive Incentives and Innovation in
  Social Networks",2019-12-14T20:41:01Z,"Erik P. Duhaime, Brittany M. Bond, Qi Yang, Patrick de Boer, Thomas W. Malone","Finding innovative solutions to complex problems is often about finding
people who have access to novel information and alternative viewpoints.
Research has found that most people are connected to each other through just a
few degrees of separation, but successful social search is often difficult
because it depends on people using their weak ties to make connections to
distant social networks. Recursive incentive schemes have shown promise for
social search by motivating people to use their weak ties to find distant
targets, such as specific people or even weather balloons placed at undisclosed
locations. Here, we report on a case study of a similar recursive incentive
scheme for finding innovative ideas. Specifically, we implemented a competition
to reward individuals(s) who helped refer Grand Prize winner(s) in MIT's
Climate CoLab, an open innovation platform for addressing global climate
change. Using data on over 78,000 CoLab members and over 36,000 people from
over 100 countries who engaged with the referral contest, we find that people
who are referred using this method are more likely than others to submit
proposals and to submit high quality proposals. Furthermore, we find suggestive
evidence that among the contributors referred via the contest, those who had
more than one degree of separation from a pre-existing CoLab member were more
likely to submit high quality proposals. Thus, the results from this case study
are consistent the theory that people from distant networks are more likely to
provide innovative solutions to complex problems. More broadly, the results
suggest that rewarding indirect intermediaries in addition to final finders may
promote effective social network recruitment.",http://arxiv.org/abs/1912.06922v1
"A Nested K-Nearest Prognostic Approach for Microwave Precipitation Phase
  Detection over Snow Cover",2019-02-25T19:24:45Z,"Zeinab Takbiri, Ardeshir Ebtehaj, Efi Foufoula-Georgiou, Pierre-Emmanuel Kirstetter, F. Joseph Turk","Monitoring changes of precipitation phase from space is important for
understanding the mass balance of Earth's cryosphere in a changing climate.
This paper examines a Bayesian nearest neighbor approach for prognostic
detection of precipitation and its phase using passive microwave observations
from the Global Precipitation Measurement (GPM) satellite. The method uses the
weighted Euclidean distance metric to search through an a priori database
populated with coincident GPM radiometer and radar observations as well as
ancillary snow-cover data. The algorithm performance is evaluated using data
from GPM official precipitation products, ground-based radars, and
high-fidelity simulations from the Weather Research and Forecasting model.
Using the presented approach, we demonstrate that the hit probability of
terrestrial precipitation detection can reach to 0.80, while the probability of
false alarm remains below 0.11. The algorithm demonstrates higher skill in
detecting snowfall than rainfall, on average by 10 percent. In particular, the
probability of precipitation detection and its solid phase increases by 11 and
8 percent, over dry snow cover, when compared to other surface types. The main
reason is found to be related to the ability of the algorithm in capturing the
signal of increased liquid water content in snowy clouds over radiometrically
cold snow-covered surfaces",http://arxiv.org/abs/1902.09578v1
"Power System Decarbonization: Impacts of Energy Storage Duration and
  Interannual Renewables Variability",2019-11-27T18:19:55Z,"Mehdi Jafari, Magnus Korpas, Audun Botterud","Decarbonization of the electricity sector is one of the major measures in
slowing down the pace of climate change. In this paper, we analyze the impacts
of energy storage systems (ESS) and interannual uncertainty of variable
renewable energy (VRE) on power system decarbonization in 2050. We perform
capacity expansion optimization based on technology cost projections and CO2
emission restrictions using 11 years of VRE and load data in Italy's power
system, with a particular focus on the role of ESS and its duration. We also
explore capacity expansion optimization based on multiple-year vs. single-year
data to quantify the impact of VRE interannual variability. Our results
indicate high renewables penetration even in the absence of decarbonization
policies. In the transition to zero carbon system, CCS plays a minor role due
to its carbon capture efficiency. ESS investments contribute to lower system
costs by replacing more expensive flexibility resources. However, longer ESS
durations have lower marginal value per added kWh ESS. Interannual variability
of VRE substantially changes the system's configuration and energy cost.
Decision-making based on single-year data substantially increases the systems'
operational costs in other years. In contrast, optimizing over multiple years
provides a more robust and cost effective generation expansion strategy.",http://arxiv.org/abs/1911.12331v1
"Late 19th-Century Navigational Uncertainties and Their Influence on Sea
  Surface Temperature Estimates",2019-10-10T20:40:06Z,"Chenguang Dai, Duo Chan, Peter Huybers, Natesh Pillai","Accurate estimates of historical changes in sea surface temperatures (SSTs)
and their uncertainties are important for documenting and understanding
historical changes in climate. A source of uncertainty that has not previously
been quantified in historical SST estimates stems from position errors. A
Bayesian inference framework is proposed for quantifying errors in reported
positions and their implications on SST estimates. The analysis framework is
applied to data from the International Comprehensive Ocean-Atmosphere Data Set
(ICOADS3.0) in 1885, a time when astronomical and chronometer estimation of
position was common, but predating the use of radio signals. Focus is upon a
subset of 943 ship tracks from ICOADS3.0 that report their position every two
hours to a precision of 0.01{\deg} longitude and latitude. These data are
interpreted as positions determined by dead reckoning that are periodically
updated by celestial correction techniques. The posterior medians of
uncertainties in celestial correction are 33.1 km (0.30{\deg} on the equator)
in longitude and 24.4 km (0.22{\deg}) in latitude, respectively. The posterior
medians of two-hourly dead reckoning uncertainties are 19.2% for ship speed and
13.2{\deg} for ship heading, leading to random position uncertainties with
median 0.18{\deg} (20 km on the equator) in longitude and 0.15{\deg} (17 km) in
latitude. Reported ship tracks also contain systematic position uncertainties
relating to precursor dead-reckoning positions not being updated after
obtaining celestial position estimates, indicating that more accurate positions
can be provided for SST observations. Finally, we translate position errors
into SST uncertainties by sampling an ensemble of SSTs from the Multi-scale
Ultra-high resolution Sea Surface Temperature (MURSST) data set.",http://arxiv.org/abs/1910.04843v2
"EspressoDB: A scientific database for managing high-performance
  computing workflow",2019-12-08T00:09:33Z,"Chia Cheng Chang, Christopher Körber, André Walker-Loud","Leadership computing facilities around the world support cutting-edge
scientific research across a broad spectrum of disciplines including
understanding climate change, combating opioid addiction, or simulating the
decay of a neutron. While the increase in computational power has allowed
scientists to better evaluate the underlying model, the size of these
computational projects have grown to a point where a framework is desired to
facilitate managing the workflow. A typical scientific computing workflow
includes: Defining all input parameters for every step of the computation;
Defining dependencies of computational tasks; Storing some of the output data;
Post-processing these data files; Performing data analysis on output.
EspressoDB is a programmatic object-relational data management framework
implemented in Python and based on the Django web framework. EspressoDB was
developed to streamline data management workflows, centralize and guarantee
data integrity, while providing domain flexibility and ease of use. The
framework provided by EspressoDB aims to support the ever increasing complexity
of workflows of scientific computing at leadership computing facilities, with
the goal of reducing the amount of human time required to manage the jobs, thus
giving scientists more time to focus on science.",http://arxiv.org/abs/1912.03580v2
"Quantitative evaluation of regulatory policies for reducing
  deforestation using the bent-cable regression model",2019-06-22T02:00:24Z,"Megan C Evans, Grace Chiu, Philip Gibbons, Andrew K Macintosh","Reducing and redressing the effects of deforestation is a complex public
policy challenge, and evaluating the efficacy of such policy efforts is crucial
for policy learning and adaptation. Deforestation in high-income nations can
contribute substantially to global forest loss, despite the presence of strong
institutions and high policy capacity. In Queensland, Australia, over 5 million
hectares of native forest has been lost since 1988. Successive regulatory
policies have aimed to reduce deforestation in Queensland, though debate exists
over their effect given the influence of other drivers of forest loss. Using a
hierarchical Bayesian statistical framework, we combine satellite imagery of
forest loss with macroeconomic, land tenure, biophysical and climatic variables
to collectively model deforestation for 50 local government areas (LGAs) across
Queensland. We apply the spatially explicit bent-cable regression model to
detect trend change that may signal a regulatory policy effect. We find that
annual % growth in GDP was the only clear driver of LGA-specific deforestation
after adjusting for other covariate effects. Our model shows strong evidence of
spatial contagion in deforestation across Queensland, and this effect is
influenced by the dominant land tenure type within each LGA. We find our model
exhibits a ""bend"" mostly between 2000 and 2007, consistent with expectations,
but the signal is not particularly strong due extreme variation in
deforestation trends between and within LGAs. Our results demonstrate that the
bent-cable model is a promising technique for detecting system changes in
response to policy interventions, but future work should be conducted at a
national scale to provide more data points, and incorporate more LGA-specific
data to improve model goodness-of-fit.",http://arxiv.org/abs/1906.09365v1
"Spatial sensitivity analysis for urban land use prediction with
  physics-constrained conditional generative adversarial networks",2019-07-22T19:32:43Z,"Adrian Albert, Jasleen Kaur, Emanuele Strano, Marta Gonzalez","Accurately forecasting urban development and its environmental and climate
impacts critically depends on realistic models of the spatial structure of the
built environment, and of its dependence on key factors such as population and
economic development. Scenario simulation and sensitivity analysis, i.e.,
predicting how changes in underlying factors at a given location affect
urbanization outcomes at other locations, is currently not achievable at a
large scale with traditional urban growth models, which are either too
simplistic, or depend on detailed locally-collected socioeconomic data that is
not available in most places. Here we develop a framework to estimate, purely
from globally-available remote-sensing data and without parametric assumptions,
the spatial sensitivity of the (\textit{static}) rate of change of urban sprawl
to key macroeconomic development indicators. We formulate this spatial
regression problem as an image-to-image translation task using conditional
generative adversarial networks (GANs), where the gradients necessary for
comparative static analysis are provided by the backpropagation algorithm used
to train the model. This framework allows to naturally incorporate physical
constraints, e.g., the inability to build over water bodies. To validate the
spatial structure of model-generated built environment distributions, we use
spatial statistics commonly used in urban form analysis. We apply our method to
a novel dataset comprising of layers on the built environment, nightlighs
measurements (a proxy for economic development and energy use), and population
density for the world's most populous 15,000 cities.",http://arxiv.org/abs/1907.09543v1
Time delay effects in the control of synchronous electricity grids,2019-07-31T08:56:11Z,"Philipp C. Böttcher, Andreas Otto, Stefan Kettemann, Carsten Agert","The expansion of inverter-connected generation facilities (i.e. wind and
photovoltaics) and the removal of conventional power plants is necessary to
mitigate the impacts of climate change. Whereas conventional generation with
large rotating generator masses provides stabilizing inertia,
inverter-connected generation does not. Since the underlying power system and
the control mechanisms that keep it close to a desired reference state, were
not designed for such a low inertia system, this might make the system
vulnerable to disturbances. In this paper, we will investigate whether the
currently used control mechanisms are able to keep a low inertia system stable
and how this is effected by the time delay between a frequency deviation and
the onset of the control action. We integrate the control mechanisms used in
continental Europe into a model of coupled oscillators which resembles the
second order Kuramoto model. This model is then used to investigate how the
interplay of changing inertia, network topology and delayed control effects the
stability of the interconnected power system. To identify regions in parameter
space that make stable grid operation possible, the linearized system is
analyzed to create the system's stability chart. We show that lower and
distributed inertia could have a beneficial effect on the stability of the
desired synchronous state.",http://arxiv.org/abs/1907.13370v2
"Meridional Structure and Future Changes of Tropopause Height and
  Temperature",2019-02-21T19:47:51Z,"Shineng Hu, Geoffrey K. Vallis","We use a simple, semi-analytic, column model to better understand the
meridional structure of the tropopause height and the future changes in its
height and temperature associated with global warming. The model allows us to
separate the effects of tropospheric lapse rate (TLR), optical depth, outgoing
longwave radiation (OLR) and stratospheric cooling on the tropopause height.
When applied locally at each latitudinal band the model predicts the overall
meridional structure of the tropopause height, with a tropical tropopause
substantially higher than that in higher latitudes and a sharp transition at
the edge of the extratropics. The large optical depth of the tropics, due
mainly to the large water vapour path (WVP), is the dominant tropospheric
effect producing the higher tropical tropopause, whereas the larger tropical
lapse rate acts to lower the tropopause height. The dynamical cooling induced
by the stratospheric circulation further lifts the thermal tropopause in the
tropics resulting in it being significantly cooler and higher than in mid- and
high latitudes. The model quantifies the causes of the tropopause height
increase with global warming that is robustly found in climate integrations
from the fifth Coupled Model Intercomparison Project (CMIP5). The large spread
in the increase rate of tropopause height in the CMIP5 models is captured by
the simple model, which attributes the dominant contributions to changes in WVP
and TLR, with changes in CO2 concentration and OLR having much smaller effects.
The CMIP5 models also show a small but robust increase in the tropopause
temperature in low latitudes, with a much smaller increase in higher latitudes.
We suggest that the tropical increase may in part be caused by non-grey effects
in the radiative transfer associated with the higher levels of water vapour in
the tropics, with near constant tropopause temperatures predicted otherwise.",http://arxiv.org/abs/1902.08230v1
"A lifestyle-based model of household neighbourhood location and
  individual travel mode choice behaviours",2019-02-06T00:41:08Z,"Ali Ardeshiri, Akshay Vij","Issues such as urban sprawl, congestion, oil dependence, climate change and
public health, are prompting urban and transportation planners to turn to land
use and urban design to rein in automobile use. One of the implicit beliefs in
this effort is that the right land-use policies will, in fact, help to reduce
automobile use and increase the use of alternative modes of transportation.
Thus, planners and transport engineers are increasingly viewing land use
policies and lifestyle patterns as a way to manage transportation demand. While
a substantial body of work has looked at the relationship between the built
environment and travel behaviour, as well as the influence of lifestyles and
lifestyle-related decisions on using different travel modes and activity
behaviours, limited work has been done in capturing these effects
simultaneously and also in exploring the effect of intra-household interaction
on individual attitudes and beliefs towards travel and activity behavior, and
their subsequent influence on lifestyles and modality styles. Therefore, for
this study we proposed a framework that captures the concurrent influence of
lifestyles and modality styles on both household-level decisions, such as
neighbourhood location, and individual-level decisions, such as travel mode
choices using a hierarchical Latent Class Choice Model.",http://arxiv.org/abs/1902.01986v2
"A new dynamical core of the Global Environmental Multiscale (GEM) model
  with a height-based terrain-following vertical coordinate",2019-02-07T18:04:40Z,"Syed Zahid Husain, Claude Girard, Abdessamad Qaddouri, Andre Plante","A new dynamical core of Environment and Climate Change Canada's Global
Environmental Multiscale (GEM) atmospheric model is presented. Unlike the
existing log-hydrostatic-pressure-type terrain-following vertical coordinate,
the proposed core adopts a height-based approach. The move to a height-based
vertical coordinate is motivated by its potential for improving model stability
over steep terrain, which is expected to become more prevalent with the
increasing demand for very high resolution forecasting systems. A dynamical
core with height-based vertical coordinate generally requires an iterative
solution approach. In addition to a three-dimensional iterative solver, a
simplified approach has been devised allowing the use of a direct solver for
the new dynamical core that separates a three-dimensional elliptic boundary
value problem into a set of two-dimensional independent Helmholtz problems. The
new dynamical core is evaluated using numerical experiments that include
two-dimensional nonhydrostatic theoretical cases as well as 25-km resolution
global forecasts. For a wide range of horizontal grid resolutions---from a few
meters to up to 25 km---the results from the direct solution approach is found
to be equivalent to the iterative approach for the new dynamical core.
Furthermore, results from the numerical experiments confirm that the new
height-based dynamical core leads to results that are equivalent to the
existing pressure-based core.",http://arxiv.org/abs/1902.03958v1
"Hazard assessment of potential storm tide inundation at Southeast China
  coast",2019-02-17T03:41:50Z,"Bingchuan Nie, Qingyong Wuxi, Jiachun Li, Feng Xu","Hazard assessment of storm tide is addressed for Southeast China coast in
this study. In particular, we pay attention to the scarcely discussed issue of
storm tide inundation. The main procedures of hazard assessment are: 1)
non-stationary tropical cyclone intensification (TCI) and sea level rise (SLR)
for the study area are analyzed based on the long-term historical database; 2)
four typical scenarios of storm tide are examined using the surge-tide-wave
coupled hydrodynamic model; 3) the potential inundated regions are identified
on the GIS platform. The distributions of water elevation show that high water
elevation tends to occur in the bays and around the estuaries. Without
considering the impacts of TCI and SLR, the maximal water elevations caused by
the typhoon wind of 100-year recurrence period can reach as high as 6.06 m,
5.82 m and 5.67 m around Aojiang, Feiyunjiang and Oujiang river estuaries,
respectively. In this circumstance, about 533 km2 area is under the threat of
storm tide inundation. TCI and SLR due to climate change can further
deteriorate the situation and enhance the risk of inundation there. The maximal
water elevations at the aforementioned three estuaries considering the
potential non-stationary TCI and SLR in 2100s can be as high as 7.02m, 6.67 m,
6.44m, respectively. The corresponding potential inundation area expands by 50%
compared with the situation without considering TCI and SLR. In addition, the
remotely sensed maps and inundation durations of the hardest hit regions are
provided as well.",http://arxiv.org/abs/1902.06198v1
Improved Representation of Ocean Heat Content in Energy Balance Models,2019-02-27T23:43:23Z,"Balasubramanya T. Nadiga, Nathan M. Urban","Anomaly-diffusing energy balance models (AD-EBM) are routinely employed to
analyze and emulate the warming response of both observed and simulated Earth
systems. We demonstrate a deficiency in common multi-layer as well as
continuous-diffusion AD-EBM variants: They are unable to, simultaneously,
properly represent surface warming and the vertical distribution of heat
uptake. We show that this inability is due to the diffusion approximation. On
the other hand, it is well understood that transport of water from the surface
mixed layer into the ocean interior is achieved, in large part, by the process
of ventilation---a process associated with outcropping isopycnals. We,
therefore, start from a configuration of outcropping isopycnals and demonstrate
how an AD-EBM can be modified to include the effect of ventilation on ocean
uptake of anomalous radiative forcing. The resulting EBM is able to
successfully represent both surface warming and the vertical distribution of
heat uptake, and indeed, a simple four layer model suffices. The simplicity of
the models notwithstanding, the analysis presented and the necessity of the
modification highlight the role played by processes related to the down-welling
branch of global ocean circulation in shaping the vertical distribution of
ocean heat uptake.",http://arxiv.org/abs/1902.10836v1
"Estimating animal utilization distributions from multiple data types: a
  joint spatio-temporal point process framework",2019-10-31T23:43:16Z,"Joe Watson, Ruth Joy, Dominic Tollit, Sheila J Thornton, Marie Auger-Méthé","Models of the spatial distribution of animals provide useful tools to help
ecologists quantify species-environment relationships, and they are
increasingly being used to help determine the impacts of climate and habitat
changes on species. While high-quality survey-style data with known effort are
sometimes available, often researchers have multiple datasets of varying
quality and type. In particular, collections of sightings made by citizen
scientists are becoming increasingly common, with no information typically
provided on their observer effort. Many standard modelling approaches ignore
observer effort completely, which can severely bias estimates of an animal's
distribution. Combining sightings data from observers who followed different
protocols is challenging. Any differences in observer skill, spatial effort,
and the detectability of the animals across space all need to be accounted for.
To achieve this, we build upon the recent advancements made in integrative
species distribution models and present a novel marked spatio-temporal point
process framework for estimating the utilization distribution (UD) of the
individuals of a highly mobile species. We show that in certain settings, we
can also use the framework to combine the UDs from the sampled individuals to
estimate the species' distribution. We combine the empirical results from a
simulation study with the implications outlined in a causal directed acyclic
graph to identify the necessary assumptions required for our framework to
control for observer effort when it is unknown. We then apply our framework to
combine multiple datasets collected on the endangered Southern Resident Killer
Whales, to estimate their monthly effort-corrected space-use.",http://arxiv.org/abs/1911.00151v2
"ElecSim: Monte-Carlo Open-Source Agent-Based Model to Inform Policy for
  Long-Term Electricity Planning",2019-10-22T10:55:46Z,"Alexander J. M. Kell, Matthew Forshaw, A. Stephen McGough","Due to the threat of climate change, a transition from a fossil-fuel based
system to one based on zero-carbon is required. However, this is not as simple
as instantaneously closing down all fossil fuel energy generation and replacing
them with renewable sources -- careful decisions need to be taken to ensure
rapid but stable progress. To aid decision makers, we present a new tool,
ElecSim, which is an open-sourced agent-based modelling framework used to
examine the effect of policy on long-term investment decisions in electricity
generation. ElecSim allows non-experts to rapidly prototype new ideas.
  Different techniques to model long-term electricity decisions are reviewed
and used to motivate why agent-based models will become an important strategic
tool for policy. We motivate why an open-source toolkit is required for
long-term electricity planning.
  Actual electricity prices are compared with our model and we demonstrate that
the use of a Monte-Carlo simulation in the system improves performance by
$52.5\%$. Further, using ElecSim we demonstrate the effect of a carbon tax to
encourage a low-carbon electricity supply. We show how a {\pounds}40 ($\$50$)
per tonne of CO2 emitted would lead to 70% renewable electricity by 2050.",http://arxiv.org/abs/1911.01203v1
"Hierarchical Bayesian Model for Probabilistic Analysis of Electric
  Vehicle Battery Degradation",2019-11-04T18:43:33Z,"Mehdi Jafari, Laura E. Brown, Lucia Gauchia","This paper proposes a hierarchical Bayesian model for probabilistic
estimation of the electric vehicle battery capacity fade. Since the battery
aging factors such as temperature, current, and state of charge are not fixed,
and they change in different times, locations and by the different users,
deterministic models with constant parameters cannot accurately evaluate the
battery capacity fade. Therefore, a probabilistic presentation of the capacity
fade including uncertainties of the measurements or observations of the
variables can be a proper solution. We have developed a hierarchical Bayesian
Network model for the electric vehicle battery capacity fade considering
multiple external variables. The mathematical expression of the model is
extracted based on Bayes theorem, the probability distributions for all
variables and their dependencies are carefully chosen where the Metropolis
Hastings Markov Chain Monte Carlo sampling method is applied to generate the
posterior distributions. The model is trained with 85 percent of experimental
data to obtain its unseen parameters and tested with other 15 percent of data
to prove its accuracy. Also, three case studies for different drivers,
different grid services frequencies, and different climates are explored to
show model flexibility with different input data. The developed model needs
training data for parameter tuning in different conditions. However, after
training, it has more than 95 percent precision in estimating the battery
capacity fade percentage.",http://arxiv.org/abs/1911.01399v1
"Smoke Sky -- Exploring New Frontiers of Unmanned Aerial Systems for
  Wildland Fire Science and Applications",2019-11-12T20:37:19Z,"E. Natasha Stavros, Ali Agha, Allen Sirota, Marco Quadrelli, Kamak Ebadi, Kyongsik Yun","Wildfire has had increasing impacts on society as the climate changes and the
wildland urban interface grows. As such, there is a demand for innovative
solutions to help manage fire. Managing wildfire can include proactive fire
management such as prescribed burning within constrained areas or advancements
for reactive fire management (e.g., fire suppression). Because of the growing
societal impact, the JPL BlueSky program sought to assess the current state of
fire management and technology and determine areas with high return on
investment. To accomplish this, we met with the national interagency Unmanned
Aerial System (UAS) Advisory Group (UASAG) and with leading technology transfer
experts for fire science and management applications. We provide an overview of
the current state as well as an analysis of the impact, maturity and
feasibility of integrating different technologies that can be developed by JPL.
Based on the findings, the highest return on investment technologies for fire
management are first to develop single micro-aerial vehicle (MAV) autonomy,
autonomous sensing over fire, and the associated data and information system
for active fire local environment mapping. Once this is completed for a single
MAV, expanding the work to include many in a swarm would require further
investment of distributed MAV autonomy and MAV swarm mechanics, but could
greatly expand the breadth of application over large fires. Important to
investing in these technologies will be in developing collaborations with the
key influencers and champions for using UAS technology in fire management.",http://arxiv.org/abs/1911.08288v1
"On the Side Effects of Automation in IoT: Complacency and Comfort vs.
  Relapse and Distrust",2019-06-18T13:12:00Z,"D. Casado-Mansilla, P. Garaizar, A. Irizar-Arrieta, D. López-de-Ipiña","Automation through IoT brings with it a whole new set of philosophical and
ethical implications that we barely began to address. However, it is widely
considered by many scholars as the panacea to overcoming the majority of
societal issues. The case of energy efficiency as an action for tackling
climate change is not different: demand-response proposals or occupancy-driven
energy management systems crowd the current research agenda on energy
efficiency. However, there are still very few studies that have reported the
effects of automation in the mid or long term beyond energy reduction (e.g.
emotional feelings derived to interact with automation, complacency to the
devices or perceived value of the automation throughout the time). In this
workshop article, we report scientific evidence of a study conducted in ten
workplaces during more than one year where we found that automating some
electronic devices of common use (i.e. moving away or preventing subjects from
the control of these devices) in favour of comfort and energy efficiency, is
associated with a reduction of the users' confidence in science and technology
as a mean to solve all environmental current problems and reduce the
willingness of people to act in favor of the environment.",http://arxiv.org/abs/1911.08657v1
"An integrodifference model for vegetation patterns in semi-arid
  environments with seasonality",2019-11-25T15:07:49Z,"Lukas Eigentler, Jonathan A. Sherratt","Vegetation patterns are a characteristic feature of semi-deserts occurring on
all continents except Antarctica. In some semi-arid regions, the climate is
characterised by seasonality, which yields a synchronisation of seed dispersal
with the dry season or the beginning of the wet season. We reformulate the
Klausmeier model, a reaction-advection-diffusion system that describes the
plant-water dynamics in semi-arid environments, as an integrodifference model
to account for the temporal separation of plant growth processes during the wet
season and seed dispersal processes during the dry season. The model further
accounts for nonlocal processes involved in the dispersal of seeds. Our
analysis focusses on the onset of spatial patterns. The Klausmeier partial
differential equations (PDE) model is linked to the integrodifference model in
an appropriate limit, which yields a control parameter for the temporal
separation of seed dispersal events. We find that the conditions for pattern
onset in the integrodifference model are equivalent to those for the continuous
PDE model and hence independent of the time between seed dispersal events. We
thus conclude that in the context of seed dispersal, a PDE model provides a
sufficiently accurate description, even if the environment is seasonal. This
emphasises the validity of results that have previously been obtained for the
PDE model. Further, we numerically investigate the effects of changes to seed
dispersal behaviour on the onset of patterns. We find that long-range seed
dispersal inhibits the formation of spatial patterns and that the seed
dispersal kernel's decay at infinity is a significant regulator of patterning.",http://arxiv.org/abs/1911.10964v2
"Optimising reactive disease management using spatially explicit models
  at the landscape scale",2019-11-27T13:14:24Z,"Frédéric Fabre, Jérôme Coville, Nik J. Cunniffe","Increasing rates of global trade and travel, as well as changing climatic
patterns, have led to more frequent outbreaks of plant disease epidemics
worldwide. Mathematical modelling is a key tool in predicting where and how
these new threats will spread, as well as in assessing how damaging they might
be. Models can also be used to inform disease management, providing a rational
methodology for comparing the performance of possible control strategies
against one another. For emerging epidemics, in which new pathogens or pathogen
strains are actively spreading into new regions, the spatial component of
spread becomes particularly important, both to make predictions and to optimise
disease control. In this chapter we illustrate how the spatial spread of
emerging plant diseases can be modelled at the landscape scale via spatially
explicit compartmental models. Our particular focus is on the crucial role of
the dispersal kernel-which parameterises the probability of pathogen spread
from an infected host to susceptible hosts at any given distance-in determining
outcomes of epidemics. We add disease management to our model by testing
performance of a simple ''one off'' form of reactive disease control, in which
sites within a particular distance of locations detected to contain infection
are removed in a single round of disease management. We use this simplified
model to show how ostensibly arcane decisions made by the modeller-most notably
whether or not the underpinning disease model allows for stochasticity (i.e.
randomness)-can greatly impact on disease management recommendations. Our
chapter is accompanied by example code in the programming language R available
via an online repository, allowing the reader to run the models we present for
him/herself.",http://arxiv.org/abs/1911.12131v1
"Demand Forecasting in the Presence of Systematic Events: Cases in
  Capturing Sales Promotions",2019-09-06T05:17:32Z,"Mahdi Abolghasemi, Ali Eshragh, Jason Hurley, Behnam Fahimnia","Reliable demand forecasts are critical for the effective supply chain
management. Several endogenous and exogenous variables can influence the
dynamics of demand, and hence a single statistical model that only consists of
historical sales data is often insufficient to produce accurate forecasts. In
practice, the forecasts generated by baseline statistical models are often
judgmentally adjusted by forecasters to incorporate factors and information
that are not incorporated in the baseline models. There are however systematic
events whose effect can be effectively quantified and modeled to help minimize
human intervention in adjusting the baseline forecasts. In this paper, we
develop and test a novel regime-switching approach to quantify systematic
information/events and objectively incorporate them into the baseline
statistical model. Our simple yet practical and effective model can help limit
forecast adjustments to only focus on the impact of less systematic events such
as sudden climate change or dynamic market activities. The proposed model and
approach is validated empirically using sales and promotional data from two
Australian companies. Discussions focus on a thorough analysis of the
forecasting and benchmarking results. Our analysis indicates that the proposed
model can successfully improve the forecast accuracy when compared to the
current industry practice which heavily relies on human judgment to factor in
all types of information/events.",http://arxiv.org/abs/1909.02716v1
"Ship resistance when operating in floating ice floes: a combined CFD&DEM
  approach",2019-09-22T14:41:59Z,"Luofeng Huang, Jukka Tuhkuri, Bojan Igrec, Minghao Li, Dimitris Stagonas, Alessandro Toffoli, Philip Cardiff, Giles Thomas","Whilst climate change is transforming the Arctic into a navigable ocean where
small ice floes are floating on the sea surface, the effect of such ice
conditions on ship performance has yet to be understood. The present work
combines a set of numerical methods to simulate the ship-wave-ice interaction
in such ice conditions. Particularly, Computational Fluid Dynamics is applied
to provide fluid solutions for the floes and it is incorporated with the
Discrete Element Method to govern ice motions and account for ship-ice/ice-ice
collisions, by which, the proposed approach innovatively includes wave effects
in the interaction. In addition, this work introduces two algorithms that can
implement computational models with natural ice-floe fields, which takes
randomness into consideration thus achieving high-fidelity modelling of the
problem. Following validation against experiments, the model is shown accurate
in predicting the ice-floe resistance of a ship, and then a series of
simulations are performed to investigate how the resistance is influenced by
ship speed, ice concentration, ice thickness and floe diameter. This paper
presents a useful approach that can provide power estimates for Arctic shipping
and has the potential to facilitate other polar engineering purposes.",http://arxiv.org/abs/1909.10018v1
The Snowball Stratosphere,2019-09-27T14:41:26Z,"R. J. Graham, Tiffany Shaw, Dorian Abbot","According to the Snowball Earth hypothesis, Earth has experienced periods of
low-latitude glaciation in its deep past. Prior studies have used general
circulation models (GCMs) to examine the effects such an extreme climate state
might have on the structure and dynamics of Earth's troposphere, but the
behavior of the stratosphere has not been studied in detail. Understanding the
snowball stratosphere is important for developing an accurate account of the
Earth's radiative and chemical properties during these episodes. Here we
conduct the first analysis of the stratospheric circulation of the Snowball
Earth using ECHAM6 general circulation model simulations. In order to
understand the factors contributing to the stratospheric circulation, we extend
the Statistical Transformed Eulerian Mean framework. We find that the
stratosphere during a snowball with prescribed modern ozone levels exhibits a
weaker meridional overturning circulation, reduced wave activity, stronger
zonal jets, and is extremely cold relative to modern conditions. Notably, the
snowball stratosphere displays no sudden stratospheric warmings. Without ozone,
the stratosphere displays slightly weaker circulation, a complete lack of polar
vortex, and even colder temperatures. We also explicitly quantify for the first
time the cross-tropopause mass exchange rate and stratospheric mixing
efficiency during the snowball and show that our values do not change the
constraints on CO$_2$ inferred from geochemical proxies during the Marinoan
glaciation ($\sim$635 Ma), unless the O$_2$ concentration during the snowball
was orders of magnitude less than the CO$_2$ concentration.",http://arxiv.org/abs/1909.12717v1
"Robotic Tankette for Intelligent BioEnergy Agriculture: Design,
  Development and Field Tests",2019-01-03T14:20:44Z,"Marco F. S. Xaud, Antonio C. Leite, Evelyn S. Barbosa, Henrique D. Faria, Gabriel S. M. Loureiro, Pål J. From","In recent years, the use of robots in agriculture has been increasing mainly
due to the high demand of productivity, precision and efficiency, which follow
the climate change effects and world population growth. Unlike conventional
agriculture, sugarcane farms are usually regions with dense vegetation,
gigantic areas, and subjected to extreme weather conditions, such as intense
heat, moisture and rain. TIBA - Tankette for Intelligent BioEnergy Agriculture
- is the first result of an R&D project which strives to develop an autonomous
mobile robotic system for carrying out a number of agricultural tasks in
sugarcane fields. The proposed concept consists of a semi-autonomous, low-cost,
dust and waterproof tankette-type vehicle, capable of infiltrating dense
vegetation in plantation tunnels and carry several sensing systems, in order to
perform mapping of hard-to-access areas and collecting samples. This paper
presents an overview of the robot mechanical design, the embedded electronics
and software architecture, and the construction of a first prototype.
Preliminary results obtained in field tests validate the proposed conceptual
design and bring about several challenges and potential applications for robot
autonomous navigation, as well as to build a new prototype with additional
functionality.",http://arxiv.org/abs/1901.00761v1
Towards a Live Anonymous Question Queue To Address Student Apprehension,2019-01-04T11:35:19Z,"Lloyd Montgomery, Guy Evans, Francis Harrison, Daniela Damian","In today's university climate many first and second year classes have over a
hundred students. Large classrooms make some students apprehensive about asking
questions. An anonymous method of submitting questions to an instructor would
allow students to ask their questions without feeling apprehensive. In this
paper we propose a Live Anonymous Question Queue (LAQQ), a system that
facilitates anonymous question submissions in real time to mitigate student
apprehension, increase student participation, and provide real-time feedback to
the instructor. To study the necessary features of an LAQQ, we conducted a
study of a system, namely Google Moderator, which best approached our concept
of an LAQQ. We deployed Google moderator in large lectures and studied its
support of a number of features that we envisioned for an LAQQ. Through our
class observations, interviews with instructors, and surveys with the students,
our results suggest that an LAQQ system must provide support for: notification
of question submission to provide awareness for the instructor, and context for
questions to allow an instructor to easily answer a question. Additionally our
results suggest that an LAQQ system must be accessible and usable on multiple
platforms. Finally our results suggest that in order to be successful in the
classroom an LAQQ system must be fully adopted by the instructor and the
classroom organizational structure must change to accommodate the use of the
LAQQ.",http://arxiv.org/abs/1901.01061v1
"An Open Source, Versatile, Affordable Waves in Ice Instrument for
  Scientific Measurements in the Polar Regions",2019-01-08T17:11:05Z,"Jean Rabault, Graig Sutherland, Olav Gundersen, Atle Jensen, Aleksey Marchenko, Øyvind Breivik","Sea ice is a major feature of the polar environments. Recent changes in the
climate and extent of the sea ice, together with increased economic activity
and research interest in these regions, are driving factors for new
measurements of sea ice dynamics. Waves in ice are important as they
participate in the coupling between the open ocean and the ice-covered regions.
Measurements are challenging to perform due to remoteness and harsh
environmental conditions. While progress has been made in observing wave
propagtion in sea ice using remote methods, these are still relatively new
measurements and would benefit from more in situ data for validation. In this
article, we present an open source instrument that was developed for performing
such measurements. The versatile design includes an ultra-low power unit, a
microcontroller-based logger, a small microcomputer for on-board data
processing, and an Iridium modem for satellite communications. Virtually any
sensor can be used with this design. In the present case, we use an Inertial
Motion Unit to record wave motion. High quality results were obtained, which
opens new possibilities for in situ measurements in the polar regions. Our
instrument can be easily customized to fit many in situ measurement tasks, and
we hope that our work will provide a framework for future developments of a
variety of such open source instruments.",http://arxiv.org/abs/1901.02410v4
Impact of pressure dissipation on fluid injection into layered aquifers,2019-01-11T15:52:16Z,"Luke T. Jenkins, Martino Foschi, Christopher W. MacMinn","Carbon dioxide (CO2) capture and subsurface storage is one method for
reducing anthropogenic CO2 emissions to mitigate climate change. It is well
known that large-scale fluid injection into the subsurface leads to a buildup
in pressure that gradually spreads and dissipates through lateral and vertical
migration of water. This dissipation can have an important feedback on the
shape of the CO2 plume during injection, and the impact of vertical pressure
dissipation, in particular, remains poorly understood. Here, we investigate the
impact of lateral and vertical pressure dissipation on the injection of CO2
into a layered aquifer system. We develop a compressible, two-phase model that
couples pressure dissipation to the propagation of a CO2 gravity current. We
show that our vertically integrated, sharp-interface model is capable of
efficiently and accurately capturing water migration in a layered aquifer
system with an arbitrary number of aquifers. We identify two limiting cases ---
`no leakage' and `strong leakage' --- in which we derive analytical expressions
for the water pressure field for the corresponding single-phase injection
problem. We demonstrate that pressure dissipation acts to suppress the
formation of an advancing CO2 tongue during injection, resulting in a plume
with a reduced lateral extent. The properties of the seals and the number of
aquifers determine the strength of pressure dissipation and subsequent coupling
with the CO2 plume. The impact of pressure dissipation on the shape of the CO2
plume is likely to be important for storage efficiency and security.",http://arxiv.org/abs/1901.03623v2
Virtual-to-Real-World Transfer Learning for Robots on Wilderness Trails,2019-01-17T03:11:58Z,"Michael L. Iuzzolino, Michael E. Walker, Daniel Szafir","Robots hold promise in many scenarios involving outdoor use, such as
search-and-rescue, wildlife management, and collecting data to improve
environment, climate, and weather forecasting. However, autonomous navigation
of outdoor trails remains a challenging problem. Recent work has sought to
address this issue using deep learning. Although this approach has achieved
state-of-the-art results, the deep learning paradigm may be limited due to a
reliance on large amounts of annotated training data. Collecting and curating
training datasets may not be feasible or practical in many situations,
especially as trail conditions may change due to seasonal weather variations,
storms, and natural erosion. In this paper, we explore an approach to address
this issue through virtual-to-real-world transfer learning using a variety of
deep learning models trained to classify the direction of a trail in an image.
Our approach utilizes synthetic data gathered from virtual environments for
model training, bypassing the need to collect a large amount of real images of
the outdoors. We validate our approach in three main ways. First, we
demonstrate that our models achieve classification accuracies upwards of 95% on
our synthetic data set. Next, we utilize our classification models in the
control system of a simulated robot to demonstrate feasibility. Finally, we
evaluate our models on real-world trail data and demonstrate the potential of
virtual-to-real-world transfer learning.",http://arxiv.org/abs/1901.05599v1
"S-Type and P-Type Habitability in Stellar Binary Systems: A
  Comprehensive Approach III. Results for Mars, Earth, and super-Earth Planets",2019-01-31T02:03:13Z,"Zhaopeng Wang, Manfred Cuntz","In Paper I and II, a comprehensive approach was utilized for the calculation
of S-type and P-type habitable regions in stellar binary systems for both
circular and elliptical orbits of the binary components. It considered a joint
constraint including orbital stability and a habitable region for a possible
system planet through the stellar radiative energy fluxes (""radiative habitable
zone""; RHZ). Specifically, the stellar S-type and P-type RHZs are calculated
based on the solution of a fourth order polynomial. However, in concurrent
developments, mostly during 2013 and 2014, important improvements have been
made in the computation of stellar habitable zones for single stars based on
updated climate models given by R. K. Kopparapu and collaborators. These models
entail considerable changes for the inner and outer limits of the stellar
habitable zones. Moreover, regarding the habitability limit given by the
runaway greenhouse effect, notable disparities were identified between Earth,
Mars, and super-Earth planets due to differences in their atmospheric models,
thus affecting their potential for habitability. It is the aim of this study to
compute S-type and P-type habitable regions of binaries in response to the
updated planetary models. Moreover, our study will also consider improved
relationships between effective temperatures, radii, and masses for
low-luminosity stars.",http://arxiv.org/abs/1901.11171v1
"Identification of synoptic weather types over Taiwan area with multiple
  classifiers",2019-05-21T16:29:27Z,"Shih-Hao Su, Jung-Lien Chu, Ting-Shuo Yo, Lee-Yaw Lin","In this study, a novel machine learning approach was used to classify three
types of synoptic weather events in Taiwan area from 2001 to 2010. We used
reanalysis data with three machine learning algorithms to recognize weather
systems and evaluated their performance. Overall, the classifiers successfully
identified 52-83% of weather events (hit rate), which is higher than the
performance of traditional objective methods. The results showed that the
machine learning approach gave low false alarm rate in general, while the
support vector machine (SVM) with more principal components of reanalysis data
had higher hit rate on all tested weather events. The sensitivity tests of grid
data resolution indicated that the differences between the high- and
low-resolution datasets are limited, which implied that the proposed method can
achieve reasonable performance in weather forecasting with minimal resources.
By identifying daily weather systems in historical reanalysis data, this method
can be used to study long-term weather changes, to monitor climatological-scale
variations, and to provide a better estimate of climate projections.
Furthermore, this method can also serve as an alternative to model output
statistics and potentially be used for synoptic weather forecasting.",http://arxiv.org/abs/1905.08736v1
"CloudSat-inferred vertical structure of precipitation over the Antarctic
  continent",2019-08-01T15:30:24Z,"Florentin Lemonnier, Jean-Baptiste Madeleine, Chantal Claud, Cyril Palerme, Christophe Genthon, Tristan L'Ecuyer, Norman B. Wood","Current global warming is causing significant changes in snowfall in polar
regions, directly impacting the mass balance of the ice caps. The only water
supply in Antarctica, precipitation, is poorly estimated from surface
measurements. The onboard cloud-profiling radar of the CloudSat satellite
provided the first real opportunity to estimate precipitation at continental
scale. Based on CloudSat observations, we propose to explore the vertical
structure of precipitation in Antarctica over the 2007-2010 period. A first
division of this dataset following a topographical approach (continent versus
peripheral regions, with a 2250m topographical criterion) shows a high
precipitation rate (275mm/yr at 1200meters above ground level) with low
relative seasonal variation (+/-11%) over the peripheral areas. Over the
plateau, the precipitation rate is low (34mm/yr at 1200m.a.g.l.) with a much
larger relative seasonal variation (+/-143%). A second study that follows a
geographical division highlights the average vertical structure of
precipitation and temperature depending on the regions and their interactions
with topography. In particular, over ice-shelves, we see a strong dependence of
the distribution of precipitation on the sea-ice coverage. Finally, the
relationship between precipitation and temperature is analyzed and compared
with a simple analytical relationship. This study highlights that precipitation
is largely dependent on the advection of air masses along the topographic
slopes with an average vertical wind of 0.02m/s. This provides new diagnostics
to evaluate climate models with a three-dimensional approach of the atmospheric
structure of precipitation.",http://arxiv.org/abs/1908.00457v2
Venus: Key to understanding the evolution of terrestrial planets,2019-08-07T13:48:13Z,"Colin Frank Wilson, Thomas Widemann","As we become aware of Earth's changing climate, and as we discover
terrestrial planets in other solar systems, we gain ever more reasons to study
the Earth's nearest neighbour and closest sibling, the only Earth-sized planet
besides our own that can be reached by our spacecraft. For the scientific and
programmatic reasons outlined in this document, Venus is a compelling target
for exploration. The science themes important for Venus research - comparative
planetology and planetary evolution - are common to all of planetary and
exoplanetary science. Many of the payloads required - radar and atmospheric
remote sensing, in situ mass spectrometers - are common to mission proposals
for many other solar system targets, as are mission technologies like high rate
deep-space telecommunications technologies. Venus-specific technology
developments meriting special attention include high-temperature systems and
balloons. Venus is an excellent proving ground for fundamental understanding of
geophysical processes of terrestrial planets; an excellent proving ground for
techniques of analysis of exoplanets; an indispensable part of our quest to
understand the evolution of Earthlike planets. For all these reasons, Venus
will be an ever more compelling theme in the coming decades, and we therefore
recommend its inclusion in the Voyage 2050 plan. We recommend that ESA aim to
have launched at least two M-class Venus missions by 2050, including the
EnVision M5 geophysics orbiter, and an in situ element such as a cloud-level
balloon; or an L-class mission combining these elements.",http://arxiv.org/abs/1908.04269v1
Gas injection and leakage in layered aquifers,2019-08-21T23:08:35Z,"Luke T. Jenkins, Martino Foschi, Christopher W. MacMinn","Carbon dioxide (CO2) injection into saline aquifers is one method of
mitigating anthropogenic climate change. To ensure secure storage of this CO2,
it is important to understand the interaction of CO2 injection and migration
with geological layering. For example, seismic monitoring at the Sleipner pilot
project suggests that the injected CO2 is ponding against, and leaking across,
a series of thin, intermediate seals. Here, we develop a gravity-current model
for weakly compressible, two-phase fluid migration in a system of layered
aquifers. Our model includes vertical leakage of both water and gas across
seals, where the latter is subject to a capillary entry threshold. We
demonstrate that the buildup of capillary pressure is very sensitive to the
conductivity and connectivity of water films in the gas region. We identify two
associated limiting cases, where gas obstructs water flow either completely or
not at all. We then explore the parameters that govern gas leakage and the
resulting fluid distributions---demonstrating that this problem involves a
complex interplay between pressure dissipation, capillary pressure buildup, and
fluid migration. We show that decreasing the relative permeability of water in
the gas region can initiate gas leakage or significantly increase the amount of
gas leakage. Finally, we apply our model to rock properties expected for
Sleipner and show that CO2 injection may build up sufficient capillary pressure
to invade the seals---suggesting that, contrary to conventional wisdom, CO2 may
be able to leak across the intermediate seals at Sleipner in the absence of a
focused conduit.",http://arxiv.org/abs/1908.08137v1
"Surrogate Optimization of Deep Neural Networks for Groundwater
  Predictions",2019-08-28T21:18:35Z,"Juliane Mueller, Jangho Park, Reetik Sahu, Charuleka Varadharajan, Bhavna Arora, Boris Faybishenko, Deborah Agarwal","Sustainable management of groundwater resources under changing climatic
conditions require an application of reliable and accurate predictions of
groundwater levels. Mechanistic multi-scale, multi-physics simulation models
are often too hard to use for this purpose, especially for groundwater managers
who do not have access to the complex compute resources and data. Therefore, we
analyzed the applicability and performance of four modern deep learning
computational models for predictions of groundwater levels. We compare three
methods for optimizing the models' hyperparameters, including two surrogate
model-based algorithms and a random sampling method. The models were tested
using predictions of the groundwater level in Butte County, California, USA,
taking into account the temporal variability of streamflow, precipitation, and
ambient temperature. Our numerical study shows that the optimization of the
hyperparameters can lead to reasonably accurate performance of all models (root
mean squared errors of groundwater predictions of 2 meters or less), but the
''simplest'' network, namely a multilayer perceptron (MLP) performs overall
better for learning and predicting groundwater data than the more advanced long
short-term memory or convolutional neural networks in terms of prediction
accuracy and time-to-solution, making the MLP a suitable candidate for
groundwater prediction.",http://arxiv.org/abs/1908.10947v3
"Potential Effects of Atmospheric Collapse on Martian Heat Flow and
  Application to the InSight Measurements",2019-10-10T12:42:35Z,"Nicholas Attree, Narissa Patel, Axel Hagermann, Matthias Grott, Tilman Spohn, Matthew Siegler","Heat flow is an important constraint on planetary formation and evolution. It
has been suggested that Martian obliquity cycles might cause periodic collapses
in atmospheric pressure, leading to corresponding decreases in regolith thermal
conductivity (which is controlled by gas in the pore spaces). Geothermal heat
would then build up in the subsurface, potentially affecting present-day heat
flow - and thus the measurements made by a heat-flow probe such as the InSight
HP$^{3}$ instrument. To gauge the order of magnitude of this effect, we model
the diffusion of a putative heat pulse caused by thermal conductivity changes
with a simple numerical scheme and compare it to the heat-flow perturbations
caused by other effects. We find that an atmospheric collapse to 300 Pa in the
last 40 kyr would lead to a present-day heat flow that is up to $2-8\%$ larger
than the average geothermal background. Considering the InSight mission with
expected $5-15\%$ error bars on the HP$^{3}$ measurement, this perturbation
would only be significant in the best-case scenario of full instrument
deployment, completed measurement campaign, and a well-modelled surface
configuration. The prospects for detecting long-term climate perturbations via
spacecraft heat-flow experiments remain challenging.",http://arxiv.org/abs/1910.04520v1
Machine Learning for Generalizable Prediction of Flood Susceptibility,2019-10-15T04:31:39Z,"Chelsea Sidrane, Dylan J Fitzpatrick, Andrew Annex, Diane O'Donoghue, Yarin Gal, Piotr Biliński","Flooding is a destructive and dangerous hazard and climate change appears to
be increasing the frequency of catastrophic flooding events around the world.
Physics-based flood models are costly to calibrate and are rarely generalizable
across different river basins, as model outputs are sensitive to site-specific
parameters and human-regulated infrastructure. In contrast, statistical models
implicitly account for such factors through the data on which they are trained.
Such models trained primarily from remotely-sensed Earth observation data could
reduce the need for extensive in-situ measurements. In this work, we develop
generalizable, multi-basin models of river flooding susceptibility using
geographically-distributed data from the USGS stream gauge network. Machine
learning models are trained in a supervised framework to predict two measures
of flood susceptibility from a mix of river basin attributes, impervious
surface cover information derived from satellite imagery, and historical
records of rainfall and stream height. We report prediction performance of
multiple models using precision-recall curves, and compare with performance of
naive baselines. This work on multi-basin flood prediction represents a step in
the direction of making flood prediction accessible to all at-risk communities.",http://arxiv.org/abs/1910.06521v1
"Coalition-structured governance improves cooperation to provide public
  goods",2019-10-24T02:13:43Z,"Vítor V. Vasconcelos, Phillip M. Hannam, Simon A. Levin, Jorge M. Pacheco","While the benefits of common and public goods are shared, they tend to be
scarce when contributions are provided voluntarily. Failure to cooperate in the
provision or preservation of these goods is fundamental to sustainability
challenges, ranging from local fisheries to global climate change. In the real
world, such cooperative dilemmas occur in multiple interactions with complex
strategic interests and frequently without full information. We argue that
voluntary cooperation enabled across multiple coalitions (akin to
polycentricity) not only facilitates greater generation of non-excludable
public goods, but may also allow evolution toward a more cooperative, stable,
and inclusive approach to governance. Contrary to any previous study, we show
that these merits of multi-coalition governance are far more general than the
singular examples occurring in the literature, and are robust under diverse
conditions of excludability, congestability of the non-excludable public good,
and arbitrary shapes of the return-to-contribution function. We first confirm
the intuition that a single coalition without enforcement and with players
pursuing their self-interest without knowledge of returns to contribution is
prone to cooperative failure. Next, we demonstrate that the same pessimistic
model but with a multi-coalition structure of governance experiences relatively
higher cooperation by enabling recognition of marginal gains of cooperation in
the game at stake. In the absence of enforcement, public-goods regimes that
evolve through a proliferation of voluntary cooperative forums can maintain and
increase cooperation more successfully than singular, inclusive regimes.",http://arxiv.org/abs/1910.11337v1
The Prosumer Economy -- Being Like a Forest,2019-03-16T12:56:19Z,Uygar Ozesmi,"Planetary life support systems are collapsing due to climate change and the
biodiversity crisis. The root cause is the existing consumer economy, coupled
with profit maximisation based on ecological and social externalities. Trends
can be reversed, civilisation may be saved by transforming the profit
maximising consumer economy into an ecologically and socially just economy,
which we call the prosumer economy. Prosumer economy is a macro scale circular
economy with minimum negative or positive ecological and social impact, an
ecosystem of producers and prosumers, who have synergistic and circular
relationships with deepened circular supply chains, networks, where leakage of
wealth out of the system is minimised. In a prosumer economy there is no waste,
no lasting negative impacts on the ecology and no social exploitation. The
prosumer economy is like a lake or a forest, an economic ecosystem that is
productive and supportive of the planet. We are already planting this forest
through Good4Trust.org, started in Turkey. Good4Trust is a community platform
bringing together ecologically and socially just producers and prosumers.
Prosumers come together around a basic ethical tenet the golden rule and share
on the platform their good deeds. The relationship are already deepening and
circularity is forming to create a prosumer economy. The platforms software to
structure the economy is open source, and is available to be licenced to start
Good4Trust anywhere on the planet. Complexity theory tells us that if enough
agents in a given system adopt simple rules which they all follow, the system
may shift. The shift from a consumer economy to a prosumer economy has already
started, the future is either ecologically and socially just or bust.",http://arxiv.org/abs/1903.07615v1
Quantile Diffusions for Risk Analysis,2019-12-23T14:27:51Z,"Holly Brannelly, Andrea Macrina, Gareth W. Peters","We develop a novel approach for the construction of quantile processes
governing the stochastic dynamics of quantiles in continuous time. Two classes
of quantile diffusions are identified: the first, which we largely focus on,
features a dynamic random quantile level and allows for direct interpretation
of the resulting quantile process characteristics such as location, scale,
skewness and kurtosis, in terms of the model parameters. The second type are
function-valued quantile diffusions and are driven by stochastic parameter
processes, which determine the entire quantile function at each point in time.
By the proposed innovative and simple -- yet powerful -- construction method,
quantile processes are obtained by transforming the marginals of a diffusion
process under a composite map consisting of a distribution and a quantile
function. Such maps, analogous to rank transmutation maps, produce the
marginals of the resulting quantile process. We discuss the relationship and
differences between our approach and existing methods and characterisations of
quantile processes in discrete and continuous time. As an example of an
application of quantile diffusions, we show how probability measure
distortions, a form of dynamic tilting, can be induced. Though particularly
useful in financial mathematics and actuarial science, examples of which are
given in this work, measure distortions feature prominently across multiple
research areas. For instance, dynamic distributional approximations
(statistics), non-parametric and asymptotic analysis (mathematical statistics),
dynamic risk measures (econometrics), behavioural economics, decision making
(operations research), signal processing (information theory), and not least in
general risk theory including applications thereof, for example in the context
of climate change.",http://arxiv.org/abs/1912.10866v3
Effects of Radius and Gravity on the Inner Edge of the Habitable Zone,2019-04-28T07:02:00Z,"Huanzhou Yang, Thaddeus D. Komacek, Dorian S. Abbot","A rigorous definition of the habitable zone and its dependence on planetary
properties is part of the search for habitable exoplanets. In this work, we use
the general circulation model ExoCAM to determine how the inner edge of the
habitable zone of tidally locked planets orbiting M dwarf stars depends on
planetary radius, surface gravity, and surface pressure. We find that the inner
edge of the habitable zone for more massive planets occurs at higher stellar
irradiation, as found in previous one-dimensional simulations. We also
determine the relative effects of varying planetary radius and surface gravity.
Increasing the planetary radius leads to a lower planetary albedo and warmer
climate, pushing the inner edge of the habitable zone to lower stellar
irradiation. This results from a change in circulation regime that leads to the
disruption of the thick, reflective cloud deck around the substellar point.
Increasing gravity increases the outgoing longwave radiation, which moves the
inner edge of the habitable zone to higher stellar irradiation. This is because
the column mass of water vapor decreases with increasing gravity, leading to a
reduction in the greenhouse effect. The effect of gravity on the outgoing
longwave radiation is stronger than the effect of radius on the planetary
albedo, so that increasing gravity and radius together causes the inner edge of
the habitable zone to move to higher stellar irradiation. Our results show that
the inner edge of the habitable zone for more massive terrestrial planets
occurs at a larger stellar irradiation.",http://arxiv.org/abs/1904.12267v1
A ruin model with a resampled environment,2019-06-07T06:05:56Z,"Corina Constantinescu, Guusje Delsing, Michel Mandjes, Leonardo Rojas Nandayapa","This paper considers a Cram\'er-Lundberg risk setting, where the components
of the underlying model change over time. These components could be thought of
as the claim arrival rate, the claim-size distribution, and the premium rate,
but we allow the more general setting of the cumulative claim process being
modelled as a spectrally positive L\'evy process. We provide an intuitively
appealing mechanism to create such parameter uncertainty: at Poisson epochs we
resample the model components from a finite number of $d$ settings. It results
in a setup that is particularly suited to describe situations in which the risk
reserve dynamics are affected by external processes (such as the state of the
economy, political developments, weather or climate conditions, and policy
regulations). We extend the classical Cram\'er-Lundberg approximation
(asymptotically characterizing the all-time ruin probability in a light-tailed
setting) to this more general setup. In addition, for the situation that the
driving L\'evy processes are sums of Brownian motions and compound Poisson
processes, we find an explicit uniform bound on the ruin probability, which can
be viewed as an extension of Lundberg's inequality; importantly, here it is not
required that the L\'evy processes be spectrally one-sided. In passing we
propose an importance-sampling algorithm facilitating efficient estimation, and
prove it has bounded relative error. In a series of numerical experiments we
assess the accuracy of the asymptotics and bounds, and illustrate that
neglecting the resampling can lead to substantial underestimation of the risk.",http://arxiv.org/abs/1906.02911v1
"Data-driven prediction of a multi-scale Lorenz 96 chaotic system using
  deep learning methods: Reservoir computing, ANN, and RNN-LSTM",2019-06-20T20:16:53Z,"Ashesh Chattopadhyay, Pedram Hassanzadeh, Devika Subramanian","In this paper, the performance of three deep learning methods for predicting
short-term evolution and for reproducing the long-term statistics of a
multi-scale spatio-temporal Lorenz 96 system is examined. The methods are: echo
state network (a type of reservoir computing, RC-ESN), deep feed-forward
artificial neural network (ANN), and recurrent neural network with long
short-term memory (RNN-LSTM). This Lorenz 96 system has three tiers of
nonlinearly interacting variables representing slow/large-scale ($X$),
intermediate ($Y$), and fast/small-scale ($Z$) processes. For training or
testing, only $X$ is available; $Y$ and $Z$ are never known or used. We show
that RC-ESN substantially outperforms ANN and RNN-LSTM for short-term
prediction, e.g., accurately forecasting the chaotic trajectories for hundreds
of numerical solver's time steps, equivalent to several Lyapunov timescales.
The RNN-LSTM and ANN show some prediction skills as well; RNN-LSTM bests ANN.
Furthermore, even after losing the trajectory, data predicted by RC-ESN and
RNN-LSTM have probability density functions (PDFs) that closely match the true
PDF, even at the tails. The PDF of the data predicted using ANN, however,
deviates from the true PDF. Implications, caveats, and applications to
data-driven and data-assisted surrogate modeling of complex nonlinear dynamical
systems such as weather/climate are discussed.",http://arxiv.org/abs/1906.08829v3
Super-Resolution of PROBA-V Images Using Convolutional Neural Networks,2019-07-03T09:53:05Z,"Marcus Märtens, Dario Izzo, Andrej Krzic, Daniël Cox","ESA's PROBA-V Earth observation satellite enables us to monitor our planet at
a large scale, studying the interaction between vegetation and climate and
provides guidance for important decisions on our common global future. However,
the interval at which high resolution images are recorded spans over several
days, in contrast to the availability of lower resolution images which is often
daily. We collect an extensive dataset of both, high and low resolution images
taken by PROBA-V instruments during monthly periods to investigate Multi Image
Super-resolution, a technique to merge several low resolution images to one
image of higher quality. We propose a convolutional neural network that is able
to cope with changes in illumination, cloud coverage and landscape features
which are challenges introduced by the fact that the different images are taken
over successive satellite passages over the same region. Given a bicubic
upscaling of low resolution images taken under optimal conditions, we find the
Peak Signal to Noise Ratio of the reconstructed image of the network to be
higher for a large majority of different scenes. This shows that applied
machine learning has the potential to enhance large amounts of previously
collected earth observation data during multiple satellite passes.",http://arxiv.org/abs/1907.01821v1
Geochemistry constrains global hydrology on Early Mars,2019-07-18T17:15:20Z,"Edwin S. Kite, Mohit Melwani Daswani","Ancient hydrology is recorded by sedimentary rocks on Mars. The most
voluminous sedimentary rocks that formed during Mars' Hesperian period are
sulfate-rich rocks, explored by the $Opportunity$ rover from 2004-2012 and soon
to be investigated by the $Curiosity$ rover at Gale crater. A leading
hypothesis for the origin of these sulfates is that the cations were derived
from evaporation of deep-sourced groundwater, as part of a global circulation
of groundwater. Global groundwater circulation would imply sustained warm
Earthlike conditions on Early Mars. Global circulation of groundwater including
infiltration of water initially in equilibrium with Mars' CO$_2$ atmosphere
implies subsurface formation of carbonate. We find that the CO$_2$
sequestration implied by the global groundwater hypothesis for the origin of
sulfate-rich rocks on Mars is 30-5000 bars if the $Opportunity$ data are
representative of Hesperian sulfate-rich rocks, which is so large that (even
accounting for volcanic outgassing) it would bury the atmosphere. This
disfavors the hypothesis that the cations for Mars' Hesperian sulfates were
derived from upwelling of deep sourced groundwater. If, instead, Hesperian
sulfate-rich rocks are approximated as pure Mg-sulfate (no Fe), then the CO$_2$
sequestration is 0.3-400 bars. The low end of this range is consistent with the
hypothesis that the cations for Mars' Hesperian sulfates were derived from
upwelling of deep sourced groundwater. In both cases, carbon sequestration by
global groundwater circulation actively works to terminate surface
habitability, rather than being a passive marker of warm Earthlike conditions.
$Curiosity$ will soon be in a position to discriminate between these two
hypotheses. Our work links Mars sulfate cation composition, carbon isotopes,
and climate change.",http://arxiv.org/abs/1907.08166v1
"A Simple Sinuosity-Based Method using GPS data to Support Mitigation
  Policies for Public Buses GHG Emissions",2019-07-22T14:23:08Z,"William Wills, Joao Meirelles, Vivien Green Baptista, Gabriel Cury, Pablo Cerdeira","It is clear by now that climate change mitigation relies on our capacity to
guide urban systems towards a low-carbon phase and that the urban
transportation sector plays a major role in this transition. It is estimated
that around 30% of total CO2 emissions worldwide come from the urban
transportation sector. Regardless of its importance, detailed estimations of
transport-related emissions in cities are still rare to find, hindering our
capacity to understand and reduce them. This work aims to develop a replicable
and fast method for GHG estimation from GPS (Global Positioning System) data
and to introduce a simple sinuosity-based algorithm for such. We applied the
method for 1 year of GPS data in the city of Rio de Janeiro. Our results were
compared to top-down estimations from fuel consumption and proved to be valid
after a simple data filling process. Our GPS-based approach allowed for much
finer spatial and temporal descriptions of emissions and we further showed
possible policy insights that can be extracted from the estimated emissions
based on the proposed method.",http://arxiv.org/abs/1907.09335v2
"An Implementation of a Non-monotonic Logic in an Embedded Computer for a
  Motor-glider",2019-07-31T04:48:56Z,"José Luis Vilchis Medina, Pierre Siegel, Vincent Risch, Andrei Doncescu","In this article we present an implementation of non-monotonic reasoning in an
embedded system. As a part of an autonomous motor-glider, it simulates piloting
decisions of an airplane. A real pilot must take care not only about the
information arising from the cockpit (airspeed, altitude, variometer,
compass...) but also from outside the cabin. Throughout a flight, a pilot is
constantly in communication with the control tower to follow orders, because
there is an airspace regulation to respect. In addition, if the control tower
sends orders while the pilot has an emergency, he may have to violate these
orders and airspace regulations to solve his problem (e.g. emergency landing).
On the other hand, climate changes constantly (wind, snow, hail..) and can
affect the sensors. All these cases easily lead to contradictions. Switching to
reasoning under uncertainty, a pilot must make decisions to carry out a flight.
The objective of this implementation is to validate a non-monotonic model which
allows to solve the question of incomplete and contradictory information. We
formalize the problem using default logic, a non-monotonic logic which allows
to find fixed-points in the face of contradictions. For the implementation, the
Prolog language is used in an embedded computer running at 1 GHz single core
with 512 Mb of RAM and 0.8 watts of energy consumption.",http://arxiv.org/abs/1907.13305v2
Quantifying the Influence of Jupiter on the Earth's Orbital Cycles,2019-10-31T04:29:29Z,"Jonathan Horner, Pam Vervoort, Stephen R. Kane, Alma Y. Ceja, David Waltham, James Gilmore, Sandra Kirtland Turner","A wealth of Earth-sized exoplanets will be discovered in the coming years,
proving a large pool of candidates from which the targets for the search for
life beyond the Solar system will be chosen. The target selection process will
require the leveraging of all available information in order to maximise the
robustness of the target list and make the most productive use of follow-up
resources. Here, we present the results of a suite of $n$-body simulations that
demonstrate the degree to which the orbital architecture of the Solar system
impacts the variability of Earth's orbital elements. By varying the orbit of
Jupiter and keeping the initial orbits of the other planets constant, we
demonstrate how subtle changes in Solar system architecture could alter the
Earth's orbital evolution -- a key factor in the Milankovitch cycles that alter
the amount and distribution of solar insolation, thereby driving periodic
climate change on our planet. The amplitudes and frequencies of Earth's modern
orbital cycles fall in the middle of the range seen in our runs for all
parameters considered -- neither unusually fast nor slow, nor large nor small.
This finding runs counter to the `Rare Earth' hypothesis, which suggests that
conditions on Earth are so unusual that life elsewhere is essentially
impossible. Our results highlight how dynamical simulations of newly discovered
exoplanetary systems could be used as an additional means to assess the
potential targets of biosignature searches, and thereby help focus the search
for life to the most promising targets.",http://arxiv.org/abs/1910.14250v2
"Wave measurements from ship mounted sensors in the Arctic marginal ice
  zone",2019-11-18T13:30:49Z,"Trygve K. Løken, Jean Rabault, Atle Jensen, Graig Sutherland, Kai H. Christensen, Malte Müller","Increased research interest and economic activity in the Arctic raise the
need for new observations of sea ice dynamics. Remote sensing as well as
mathematical and numerical models of wave propagation in sea ice would benefit
from more in situ data for validation. This study presents wave measurements in
the marginal ice zone (MIZ) obtained from ship mounted sensors. The system
combines altimeter readings from the ship bow with ship motion correction data
to provide estimated single point ocean surface elevation. Significant wave
height and mean wave period, as well as one-dimensional wave spectra are
derived from the combined measurements. The results are compared with
integrated parameters from a spectral wave model over a period of eight days in
the open ocean, and with spectra and integrated parameters derived from motion
detecting instruments placed on ice floes inside the MIZ. Mean absolute errors
of the integrated parameters are in the range 15.0-18.9% when comparing with
the spectral wave model and 1.0-9.6% when comparing with valid motion detecting
instruments. The spatial wave damping coefficient is estimated by looking at
the change in spectral wave amplitude found at discrete frequency values as the
ship was moving along the longitudinal direction of the MIZ within time
intervals where the wave field is found to be approximately constant in time.
As expected from theory, high frequency waves are effectively dampened by the
presence of sea ice. The observed wave attenuation rates compare favourably
with a two-layer dissipation model. Our methodology can be regarded as a simple
and reliable way to collect more waves-in-ice data as it can be easily added to
any ship participating to ice expeditions, at little extra cost.",http://arxiv.org/abs/1911.07612v2
"Earth system modeling with endogenous and dynamic human societies: the
  copan:CORE open World-Earth modeling framework",2019-09-30T13:50:15Z,"Jonathan F. Donges, Jobst Heitzig, Wolfram Barfuss, Marc Wiedermann, Johannes A. Kassel, Tim Kittel, Jakob J. Kolb, Till Kolster, Finn Müller-Hansen, Ilona M. Otto, Kilian B. Zimmerer, Wolfgang Lucht","Analysis of Earth system dynamics in the Anthropocene requires to explicitly
take into account the increasing magnitude of processes operating in human
societies, their cultures, economies and technosphere and their growing
feedback entanglement with those in the physical, chemical and biological
systems of the planet. However, current state-of-the-art Earth System Models do
not represent dynamic human societies and their feedback interactions with the
biogeophysical Earth system and macroeconomic Integrated Assessment Models
typically do so only with limited scope. This paper (i) proposes design
principles for constructing World-Earth Models (WEM) for Earth system analysis
of the Anthropocene, i.e., models of social (World) - ecological (Earth)
co-evolution on up to planetary scales, and (ii) presents the copan:CORE open
simulation modeling framework for developing, composing and analyzing such WEMs
based on the proposed principles. The framework provides a modular structure to
flexibly construct and study WEMs. These can contain biophysical (e.g. carbon
cycle dynamics), socio-metabolic/economic (e.g. economic growth) and
socio-cultural processes (e.g. voting on climate policies or changing social
norms) and their feedback interactions, and are based on elementary entity
types, e.g., grid cells and social systems. Thereby, copan:CORE enables the
epistemic flexibility needed for contributions towards Earth system analysis of
the Anthropocene given the large diversity of competing theories and
methodologies used for describing socio-metabolic/economic and socio-cultural
processes in the Earth system by various fields and schools of thought. To
illustrate the capabilities of the framework, we present an exemplary and
highly stylized WEM implemented in copan:CORE that illustrates how endogenizing
socio-cultural processes and feedbacks could fundamentally change macroscopic
model outcomes.",http://arxiv.org/abs/1909.13697v1
"Where does active travel fit within local community narratives of
  mobility space and place?",2019-05-07T16:25:12Z,"Alec Biehl, Ying Chen, Karla Sanabria-Veaz, David Uttal, Amanda Stathopoulos","Encouraging sustainable mobility patterns is at the forefront of policymaking
at all scales of governance as the collective consciousness surrounding climate
change continues to expand. Not every community, however, possesses the
necessary economic or socio-cultural capital to encourage modal shifts away
from private motorized vehicles towards active modes. The current literature on
`soft' policy emphasizes the importance of tailoring behavior change campaigns
to individual or geographic context. Yet, there is a lack of insight and
appropriate tools to promote active mobility and overcome transport
disadvantage from the local community perspective. The current study
investigates the promotion of walking and cycling adoption using a series of
focus groups with local residents in two geographic communities, namely
Chicago's (1) Humboldt Park neighborhood and (2) suburb of Evanston. The
research approach combines traditional qualitative discourse analysis with
quantitative text-mining tools, namely topic modeling and sentiment analysis.
The analysis uncovers the local mobility culture, embedded norms and values
associated with acceptance of active travel modes in different communities. We
observe that underserved populations within diverse communities view active
mobility simultaneously as a necessity and as a symbol of privilege that is
sometimes at odds with the local culture. The mixed methods approach to
analyzing community member discourses is translated into policy findings that
are either tailored to local context or broadly applicable to curbing
automobile dominance. Overall, residents of both Humboldt Park and Evanston
envision a society in which multimodalism replaces car-centrism, but
differences in the local physical and social environments would and should
influence the manner in which overarching policy objectives are met.",http://arxiv.org/abs/1905.02674v1
"Modelling the impact of deep-water crustacean trawl fishery in the
  marine ecosystem off Portuguese Southwestern and South Coasts: I) the trophic
  web and trophic flows",2019-03-27T14:48:25Z,"Maria Angeles Torres, Paulo Fonseca, Karim Erzini, Teresa Cerveira Borges, Aida Campos, Margarida Castro, Jorge Santos, Maria Esmeralda Costa, Ana Marcalo, Nuno Oliveira, Jose Vingada","The concentration of the population in coastal regions, in addition to the
direct human use, is leading to an accelerated process of change and
deterioration of the marine ecosystems. Human activities such as fishing
together with environmental drivers (e.g. climate change) are triggering major
threats to marine biodiversity, and impact directly the services they provide.
In the South and Southwest coasts of Portugal, the deep-water crustacean trawl
fishery is not exemption. This fishery is recognized to have large effects on a
number of species while generating high rates of unwanted catches. However,
taking into account an ecosystem-based perspective, the fishing impacts along
the food web accounting for biological interactions between and among species
caught remains poorly understood. These impacts are particularly troubling and
are a cause of concern given the cascading effects that might arise. Facing the
main policies and legislative instruments for the restoration and conservation
of the marine environment, times are calling for implementing ecosystem-based
approaches to fisheries management. To this end, we use a food web modelling
(Ecopath with Ecosim) approach to assess the fishing impacts of this particular
fishery on the marine ecosystem of southern and southwestern Portugal. In
particular, we describe the food web structure and functioning, identify the
main keystone species and/or groups, quantify the major trophic and energy
flows, and ultimately assess the impact of fishing on the target species but
also on the ecosystem by means of ecological and ecosystem-based indicators.
Finally, we examine limitations and weaknesses of the model for potential
improvements and future research directions.",http://arxiv.org/abs/1903.11458v1
"A comparison of remotely-sensed and inventory datasets for burned area
  in Mediterranean Europe",2019-06-14T10:50:02Z,"Marco Turco, Sixto Herrera, Etienne Tourigny, Emilio Chuvieco, Antonello Provenzale","Quantitative estimate of observational uncertainty is an essential ingredient
to correctly interpret changes in climatic and environmental variables such as
wildfires. In this work we compare four state-of-the-art satellite fire
products with the gridded, ground-based EFFIS dataset for Mediterranean Europe
and analyse their statistical differences. The data are compared for spatial
and temporal similarities at different aggregations to identify a spatial scale
at which most of the observations provide equivalent results. The results of
the analysis indicate that the datasets show high temporal correlation with
each other (0.5/0.6) when aggregating the data at resolution of at least
1.0{\deg} or at NUTS3 level. However, burned area estimates vary widely between
datasets. Filtering out satellite fires located on urban and crop land cover
classes greatly improves the agreement with EFFIS data. Finally, in spite of
the differences found in the area estimates, the spatial pattern is similar for
all the datasets, with spatial correlation increasing as the resolution
decreases. Also, the general reasonable agreement between satellite products
builds confidence in using these datasets and in particular the most-recent
developed dataset, FireCCI51, shows the best agreement with EFFIS overall. As a
result, the main conclusion of the study is that users should carefully
consider the limitations of the satellite fire estimates currently available,
as their uncertainties cannot be neglected in the overall uncertainty
estimate/cascade that should accompany global or regional change studies and
that removing fires on human-dominated land areas is key to analyze forest
fires estimation from satellite products.",http://arxiv.org/abs/1906.06121v1
"A Reliability-Oriented Cost Optimisation Method for Capacity Planning of
  a Multi-Carrier Micro-Grid: A Case Study of Stewart Island, New Zealand",2019-06-23T03:06:49Z,"Soheil Mohseni, Alan C. Brent, Daniel Burmester","Nearly all types of energy systems (such as power systems, natural gas supply
systems, fuel supply systems, and so forth) are going through a major
transition from centralised, top-down structures to distributed, clean energy
approaches in order to address the concerns regarding climate change, air
quality, depletion of natural resources, and energy security, whilst also
enabling the supply of energy to communities in line with the goals of
sustainable development. Accordingly, the establishment of the concept of
sustainable, decentralised, multi-carrier energy systems, together with the
declining costs of renewable energy technologies, has proposed changes in the
energy industry towards the development of integrated energy systems.
Notwithstanding the potential benefits, the optimal capacity planning of these
systems with multiple energy carriers (such as electricity, heat, hydrogen, and
biogas) is exceedingly complex due to the concurrent goals and interrelated
constraints that must be satisfied, as well as the heavily context-dependent
nature of such schemes. This paper puts forward an innovative optimal capacity
planning method for a cutting-edge, stand-alone multiple energy carrier
micro-grid (MECM) serving the electricity, hot water, and transportation fuel
demands of remote communities. The proposed MECM system is equipped with wind
turbines, a hydrogen sub-system (including an electrolyser, a hydrogen
reservoir, and a fuel cell), a hybrid super-capacitor/battery energy storage
system, a hot water storage tank, a heat exchanger, an inline electric heater,
a hydrogen refuelling station, and some power converters. A numerical case
study for the optimal capacity planning of the suggested MECM configuration, to
be realised on Stewart Island, New Zealand, is presented to evaluate the
effectiveness of the proposed optimisation method.",http://arxiv.org/abs/1906.09544v1
"Thermo-compositional diabatic convection in the atmospheres of brown
  dwarfs and in Earth's atmosphere and oceans",2019-02-10T07:53:41Z,"P. Tremblin, T. Padioleau, M. Phillips, G. Chabrier, I. Baraffe, S. Fromang, E. Audit, H. Bloch, A. J. Burgasser, B. Drummond, M. Gonzalez, P. Kestener, S. Kokh, P. -O. Lagage, M. Stauffert","By generalizing the theory of convection to any type of thermal and
compositional source terms (diabatic processes), we show that thermohaline
convection in Earth oceans, fingering convection in stellar atmospheres, and
moist convection in Earth atmosphere are deriving from the same general
diabatic convective instability. We show also that ""radiative convection""
triggered by CO/CH4 transition with radiative transfer in the atmospheres of
brown dwarfs is analog to moist and thermohaline convection. We derive a
generalization of the mixing length theory to include the effect of source
terms in 1D codes. We show that CO/CH4 radiative convection could significantly
reduce the temperature gradient in the atmospheres of brown dwarfs similarly to
moist convection in Earth atmosphere thus possibly explaining the reddening in
brown-dwarf spectra. By using idealized two-dimensional hydrodynamic
simulations in the Ledoux unstable regime, we show that compositional source
terms can indeed provoke a reduction of the temperature gradient. The L/T
transition could be explained by a bifurcation between the adiabatic and
diabatic convective transports and could be seen as a giant cooling crisis: an
analog of the boiling crisis in liquid/steam-water convective flows. This
mechanism with other chemical transitions could be present in many giant and
earth-like exoplanets. The study of the impact of different parameters
(effective temperature, compositional changes) on CO/CH4 radiative convection
and the analogy with Earth moist and thermohaline convection is opening the
possibility to use brown dwarfs to better understand some aspects of the
physics at play in the climate of our own planet.",http://arxiv.org/abs/1902.03553v1
"Revised mass-radius relationships for water-rich rocky planets more
  irradiated than the runaway greenhouse limit",2019-11-20T13:15:07Z,"Martin Turbet, Emeline Bolmont, David Ehrenreich, Pierre Gratier, Jérémy Leconte, Franck Selsis, Nathan Hara, Christophe Lovis","Mass-radius relationships for water-rich rocky planets are usually calculated
assuming most water is present in condensed (either liquid or solid) form.
Planet density estimates are then compared to these mass-radius relationships,
even when these planets are more irradiated than the runaway greenhouse
irradiation limit (around 1.1~times the insolation at Earth for planets
orbiting a Sun-like star), for which water has been shown to be unstable in
condensed form and would instead form a thick H2O-dominated atmosphere. Here we
use the LMD Generic numerical climate model to derive new mass-radius
relationships appropriate for water-rich rocky planets that are more irradiated
than the runaway greenhouse irradiation limit, meaning planets endowed with a
steam, water-dominated atmosphere. For a given water-to-rock mass ratio, these
new mass-radius relationships lead to planet bulk densities much lower than
calculated when water is assumed to be in condensed form. In other words, using
traditional mass-radius relationships for planets that are more irradiated than
the runaway greenhouse irradiation limit tends to dramatically overestimate --
possibly by several orders of magnitude -- their bulk water content. In
particular, this result applies to TRAPPIST-1 b, c, and d, which can
accommodate a water mass fraction of at most 2, 0.3 and 0.08 %, respectively,
assuming planetary core with a terrestrial composition. In addition, we show
that significant changes of mass-radius relationships (between planets less and
more irradiated than the runaway greenhouse limit) can be used to remove bulk
composition degeneracies in multiplanetary systems such as TRAPPIST-1. Finally,
we provide an empirical formula for the H2O steam atmosphere thickness which
can be used to construct mass-radius relationships for any water-rich, rocky
planet more irradiated than the runaway greenhouse irradiation threshold.",http://arxiv.org/abs/1911.08878v3
"Metered reagent injection into microfluidic continuous flow sampling for
  conductimetric ocean dissolved inorganic carbon sensing",2019-09-04T14:44:10Z,"Mark Tweedie, Antonin Macquart, Joao Almeida, Brian Ward, Paul Maguire","Continuous and autonomous measurement of total dissolved inorganic carbon
(TCO2) in the oceans is critical for modelling important climate change factors
such as ocean uptake of atmospheric CO2 and ocean acidification. Miniaturised
chemical analysis systems are therefore required which are small enough for
integration into the existing Argo ocean float network for long-term unattended
depth profiling of dissolved CO2 with the accuracy of laboratory bench
analysers. A microfluidic conductivity-based approach offers the potential for
such miniaturisation. Reagent payload for >3 yr operation is a critical
parameter. The precise injection of acid into sample, liberating CO2 from
seawater, is addressed here. Laser etched microfluidic snake channel
restrictors and asymmetric Y meters were fabricated to adjust the metering
ratio between seawater and acid simulants. Laser etching conditions were varied
to create a range of channel dimensions down to ~75 microns. Channel flow
versus pressure measurements were used to determine hydrodynamic resistances
which were compared with finite element simulations using a range of
cross-section profiles and areas. Microfluidic metering circuits were
constructed from variable resistance snake channels and dimensionally symmetric
or asymmetric Y-junctions. Sample to acid volume ratios (meter ratio) up to
100:1 have been achieved with 300 microns wide snake channel for lengths > 1m.
At the highest pattern resolution, this would require a footprint of > 600 mm2
(6 x10-4 m2). Circuits based solely on asymmetric Y-junctions gave meter ratios
up to 16:1 with a footprint cost of < 40 mm2 and precision values of ~0.2%.
Further design and fabrication refinements will be required to ensure the
structural and dimensional integrity of such small channels in future
integration of metering units into full TCO2 analysis microfluidic circuits.",http://arxiv.org/abs/1909.01845v1
"Effects of green revolution led agricultural expansion on net ecosystem
  service values in India",2019-09-24T07:30:54Z,"Srikanta Sannigrahi, Suman Chakraborti, Pawan Kumar Joshi, Saskia Keesstra, P. S. Roy, Paul. C. Sutton, Urs Kreuter, Saikat Kumar Paul, Somnath Sen, Sandeep Bhatt, Shahid Rahmat, Shouvik Jha, Qi Zhang, Laishram Kanta Singh","Ecosystem Services are a bundle of natural processes and functions that are
essential for human well-being, subsistence, and livelihood. The expansion of
cultivation and cropland, which is the backbone of the Indian economy, is one
of the main drivers of rapid Land Use Land Cover changes in India. To assess
the impact of the Green Revolution led agrarian expansion on the total
ecosystem service values, we first estimated the ESVs from 1985 to 2005 for
eight ecoregions in India using several value transfer approaches. Five
explanatory factors such as Total Crop Area, Crop Production, Crop Yield, Net
Irrigated Area, and Cropping Intensity representing the cropping scenarios in
the country were used in constructing local Geographical Weighted Regression
model to explore the cumulative and individual effects on ESVs. A Multi-Layer
Perceptron based Artificial Neural Network algorithm was employed to estimate
the normalized importance of these explanatory factors. During the observation
periods, cropland, forestland, and water bodies have contributed the most and
form a significant proportion of ESVs, followed by grassland, mangrove,
wetland, and urban builtup. In all three years, among the nine ESs, the highest
ESV accounts for water regulation, followed by soil formation and soilwater
retention, biodiversity maintenance, waste treatment, climate regulation, and
gas regulation. Among the five explanatory factors, TCA, NIA, CP showed a
strong positive association with ESVs, while the CI exhibited a negative
association. The study reveals a strong association between GR led agricultural
expansion and ESVs in India.",http://arxiv.org/abs/1909.10742v2
"Wind, wave and current interactions appear key for quantifying
  cross-shelf transport and carbon export; new knowledge and the potential of
  SKIM to enable monitoring",2019-05-21T15:04:21Z,"Jamie D. Shutler, Thomas Holding, Clement Ubelmann, Lucile Gaultier, Fabrice Collard, Fabrice Ardhuin, Bertrand Chapron, Marie-Helene Rio, Craig Donlon","The highly heterogeneous and biologically active continental shelf-seas are
important components of the oceanic carbon sink. Carbon rich water from
shelf-seas is exported at depth to the open ocean, a process known as the
continental shelf pump, with open-ocean surface water moving (transported) onto
the shelf driving the export at depth. Existing methods to study shelf-wide
exchange focus on the wind or geostrophic currents, often ignoring their
combined effect, spatial heterogeniety or any other ageostrophic components.
Here we investigate the influence that wind, wave and current interactions can
have on surface transport and carbon export across continental shelves. Using a
21 year global re-analysis dataset we confirm that geostrophic and wind driven
Ekman processes are important for the transport of water onto shelf seas; but
the dominance of each is location and season dependent. A global wave model
re-analysis shows that one type of ageostrophic flow, Stokes drift due to
waves, can also be significant. A regional case study using two submesocale
model simulations identifies that up to 100% of the cross-shelf surface flow in
European seas can be due to ageostrophic components. Using these results and
grouping shelf-seas based on their observed carbon accumulation rates shows
that differences in rates are consistent with imbalances between the processes
driving atmosphere-ocean exchange at the surface and those driving carbon
export at depth. Therefore expected future changes in wind and wave climate
support the need to monitor cross-shelf transport and the size of the
continental shelf-sea carbon pump. The results presented show that the Sea
Surface Kinematics Multiscale monitoring satellite mission (SKIM), will be
capable of providing measurements of the total cross-shelf current, which are
now needed to enable routine monitoring of the global continental shelf-sea
carbon pump.",http://arxiv.org/abs/1905.08687v1
How much of the Solar System should we leave as Wilderness?,2019-05-24T19:35:45Z,"Martin Elvis, Tony Milligan","""How much of the Solar System should we reserve as wilderness, off-limits to
human development?"" We argue that, as a matter of policy, development should be
limited to one eighth, with the remainder set aside. We argue that adopting a
""1/8 principle"" is far less restrictive, overall, than it might seem. One
eighth of the iron in the asteroid belt is more than a million times greater
than all of the Earth's estimated iron reserves and may suffice for centuries.
A limit of some sort is needed because of the problems associated with
exponential growth. Humans are poor at estimating the pace of such growth, so
the limitations of a resource are hard to recognize before the final three
doubling times which take utilization successively from 1/8 to 1/4 to 1/2, and
then to the point of exhaustion. Population growth and climate change are
instances of unchecked exponential growth. Each places strains upon ouru
available resources. Each is a problem we would like to control but attempts to
do so at this comparatively late stage have not been encouraging. Our limited
ability to see ahead suggests that we should set ourselves a 'tripwire' that
gives us at least 3 doubling times as leeway, i.e. when 1/8 of Solar System
resources are close to being exploited. At a 3.5 percent growth rate for the
space economy, comparable to that of the iron use from the beginning of the
Industrial Revolution until now, the 1/8 point would be reached after 400
years. At that point the 20 year doubling time of a 3.5 percent growth rate
means that only 60 years would remain to transition the economic system to new
""steady state"" conditions. The rationale for adopting the 1/8 principle now is
that it may be far easier to implement in principle restrictions at an early
stage, rather than later, when vested and competing interests have come into
existence.",http://arxiv.org/abs/1905.13681v1
"Planetary-scale variations in winds and UV brightness at the Venusian
  cloud top: Periodicity and temporal evolution",2019-08-22T06:48:03Z,"Masataka Imai, Toru Kouyama, Yukihiro Takahashi, Atsushi Yamazaki, Shigeto Watanabe, Manabu Yamada, Takeshi Imamura, Takehiko Satoh, Masato Nakamura, Shin-ya Murakami, Kazunori Ogohara, Takeshi Horinouchi","Planetary-scale waves at the Venusian cloud-top cause periodic variations in
both winds and ultraviolet (UV) brightness. While the wave candidates are the
4-day Kelvin wave and 5-day Rossby wave with zonal wavenumber 1, their temporal
evolutions are poorly understood. Here we conducted a time series analysis of
the 365-nm brightness and cloud-tracking wind variations, obtained by the UV
Imager onboard the Japanese Venus Climate Orbiter Akatsuki from June to October
2017, revealing a dramatic evolution of planetary-scale waves and corresponding
changes in planetary-scale UV features. We identified a prominent 5-day
periodicity in both the winds and brightness variations, whose phase velocities
were slower than the dayside mean zonal winds (or the super-rotation) by >35 m
s$^{-1}$. The reconstructed planetary-scale vortices were nearly equatorially
symmetric and centered at ~35{\deg} latitude in both hemispheres, which
indicated that they were part of a Rossby wave. The amplitude of winds
variation associated with the observed Rossby wave packet were amplified
gradually over ~20 days and attenuated over ~50 days. Following the formation
of the Rossby wave vortices, brightness variation emerges to form rippling
white cloud belts in the 45{\deg}-60{\deg} latitudes of both hemispheres.
~3.8-day periodic signals were observed in the zonal wind and brightness
variations in the equatorial region before the Rossby wave amplification.
Although the amplitude and significance of the 3.8-day mode were relatively low
in the observation season, this feature is consistent with a Kelvin wave, which
may be the cause of the dark clusters in the equatorial region.",http://arxiv.org/abs/1908.08220v2
"Generative stochastic modeling of strongly nonlinear flows with
  non-Gaussian statistics",2019-08-20T20:10:41Z,"Hassan Arbabi, Themistoklis Sapsis","Strongly nonlinear flows, which commonly arise in geophysical and engineering
turbulence, are characterized by persistent and intermittent energy transfer
between various spatial and temporal scales. These systems are difficult to
model and analyze due to combination of high dimensionality and uncertainty,
and there has been much interest in obtaining reduced models, in the form of
stochastic closures, that can replicate their non-Gaussian statistics in many
dimensions. Here, we propose a data-driven framework to model stationary
chaotic dynamical systems through nonlinear transformations and a set of
decoupled stochastic differential equations (SDEs). Specifically, we use
optimal transport to find a transformation from the distribution of time-series
data to a multiplicative reference probability measure such as the standard
normal distribution. Then we find the set of decoupled SDEs that admit the
reference measure as the invariant measure, and also closely match the spectrum
of the transformed data. As such, this framework represents the chaotic time
series as the evolution of a stochastic system observed through the lens of a
nonlinear map. We demonstrate the application of this framework in Lorenz-96
system, a 10-dimensional model of high-Reynolds cavity flow, and reanalysis
climate data. These examples show that SDE models generated by this framework
can reproduce the non-Gaussian statistics of systems with moderate dimensions
(e.g. 10 and more), and predict super-Gaussian tails that are not readily
available from little training data. These findings suggest that this class of
models provide an efficient hypothesis space for learning strongly nonlinear
flows from small amounts of data.",http://arxiv.org/abs/1908.08941v5
"An Enterprise Control Methodology for the Techno-Economic Assessment of
  the Energy Water Nexus",2019-08-27T21:19:58Z,"Steffi O. Muhanji, Amro M. Farid","In recent years, the energy-water nexus literature has recognized that the
electricity and water infrastructure that enable the production, distribution,
and consumption of these two commodities is fundamentally intertwined. Electric
power is used to produce, treat, distribute, and recycle water while water is
used to generate and consume electricity. In the meantime, significant
attention has been given to renewable energy integration within the context of
global climate change. While these two issues may seem unrelated, their
resolution is potentially synergistic in that renewable energy technologies not
only present low CO2 emissions but also low water-intensities. Furthermore,
because water is readily stored, it has the potential to act as a flexible
energy resource on both the supply and the demand-side of the electricity grid.
Despite these synergies, the renewable energy integration and energy-water
nexus literature have yet to methodologically converge to systematically
address potential synergies. This paper advances an enterprise control
methodology as a means of assessing the techno-economic performance of the
energy water nexus. The enterprise control methodology has been developed in
recent years to advance the methodological state of the art of renewable energy
integration studies and used recently to carry out a full-scale study for the
Independent System Operator (ISO) New England system. The methodology
quantifies day-ahead and real-time energy market production costs, dispatched
energy mixes, required operating reserves, levels of curtailment, and grid
imbalances. This energy-water nexus methodological extension now includes
flexible water-energy resources within the grid's energy resource portfolio and
quantifies the amounts of water withdrawn and consumed. The simulation
methodology is demonstrated on a modified version of the RTS-96 (RTS-GMLC) test
case.",http://arxiv.org/abs/1908.10469v1
"Unveiling dynamic changes in the diurnal microclimate of a Buxus
  sempervirens with non-intrusive imaging of flow field, leaf temperature, and
  plant microstructure",2019-03-06T10:10:38Z,"Lento Manickathan, Thijs Defraeye, Stephan Carl, Henning Richter, Jonas Allegrini, Dominique Derome, Jan Carmeliet","Plant response is not only dependent on the atmospheric evaporative demand
due to the combined effects of wind speed, air temperature, humidity, and solar
radiation, but is also dependent on the water transport within the
leaf-xylem-root system. Therefore, a detailed understanding of such dynamics is
key to the development of appropriate mitigation strategies and numerical
models. In this study, we unveil the diurnal dynamics of the microclimate of a
Buxus sempervirens plant using multiple high-resolution non-intrusive imaging
techniques. The wake flow field is measured using stereoscopic particle image
velocimetry, the spatiotemporal leaf temperature history is obtained using
infrared thermography, and additionally, the plant porosity is obtained using
X-ray tomography. We find that the wake velocity statistics is not directly
linked with the distribution of the porosity but depends mainly on the geometry
of the plant foliage which generates the shear flow. The interaction between
the shear regions and the upstream boundary layer profile is seen to have a
dominant effect on the wake turbulent kinetic energy distribution. Furthermore,
the leaf area density distribution has a direct impact on the short-wave
radiative heat flux absorption inside the foliage where 50% of the radiation is
absorbed in the top 20% of the foliage. This localized radiation absorption
results in a high local leaf and air temperature. Furthermore, a comparison of
the diurnal variation of leaf temperature and the net plant transpiration rate
enabled us to quantify the diurnal hysteresis resulting from the stomatal
response lag. The day of this plant is seen to comprise of four stages of
climatic conditions: no-cooling, high-cooling, equilibrium, and
decaying-cooling stages.",http://arxiv.org/abs/1903.02283v1
The habitability of stagnant-lid Earths around dwarf stars,2019-03-18T08:33:26Z,"Mareike Godolt, Nicola Tosi, Barbara Stracke, J. Lee Grenfell, Thomas Ruedas, Tilman Spohn, Heike Rauer","The habitability of a planet depends on various factors, such as delivery of
water during the formation, the co-evolution of the interior and the
atmosphere, as well as the stellar irradiation which changes in time. Since an
unknown number of rocky exoplanets may operate in a one-plate convective
regime, i.e., without plate tectonics, we aim at understanding under which
conditions planets in such a stagnant-lid regime may support habitable surface
conditions. Understanding the interaction of the planetary interior and
outgassing of volatiles with the atmosphere in combination with the evolution
of the host star is crucial to determine the potential habitability. M-dwarf
stars in particular possess a high-luminosity pre-main sequence phase which
endangers the habitability of planets around them via water loss. We therefore
explore the potential of secondary outgassing from the planetary interior to
rebuild a water reservoir allowing for habitability at a later stage. We
compute the boundaries of the habitable zone around M, K, G, and F-dwarf stars
using a 1D cloud-free radiative-convective climate model accounting for the
outgassing history of CO2 and H2O from an interior evolution and outgassing
model for different interior compositions and stellar luminosity evolutions.
The outer edge of the habitable zone strongly depends on the amount of CO2
outgassed from the interior, while the inner edge is mainly determined via the
stellar irradiation, as soon as a sufficiently large water reservoir has been
outgassed. A build-up of a secondary water reservoir for planets around M-dwarf
stars is possible even after severe water loss during the high luminosity
pre-main sequence phase as long as some water has been retained within the
mantle. Earth-like stagnant-lid planets allow for habitable surface conditions
within a continuous habitable zone that is dependent on interior composition.",http://arxiv.org/abs/1903.07298v1
"Insights On Streamflow Predictability Across Scales Using Horizontal
  Visibility Graph Based Networks",2019-12-06T21:09:49Z,"Ganesh R. Ghimire, Navid Jadidoleslam, Witold F. Krajewski, Anastasios A. Tsonis","Streamflow is a dynamical process that integrates water movement in space and
time within basin boundaries. The authors characterize the dynamics associated
with streamflow time series data from about seventy-one U.S. Geological Survey
(USGS) stream-gauge stations in the state of Iowa. They employ a novel approach
called visibility graph (VG). It uses the concept of mapping time series into
complex networks to investigate the time evolutionary behavior of dynamical
system. The authors focus on a simple variant of VG algorithm called horizontal
visibility graph (HVG). The tracking of dynamics and hence, the predictability
of streamflow processes, are carried out by extracting two key pieces of
information called characteristic exponent, {\lambda} of degree distribution
and global clustering coefficient, GC pertaining to HVG derived network. The
authors use these two measures to identify whether streamflow process has its
origin in random or chaotic processes. They show that the characterization of
streamflow dynamics is sensitive to data attributes. Through a systematic and
comprehensive analysis, the authors illustrate that streamflow dynamics
characterization is sensitive to the normalization, and the time-scale of
streamflow time-series. At daily scale, streamflow at all stations used in the
analysis, reveals randomness with strong spatial scale (basin size) dependence.
This has implications for predictability of streamflow and floods. The authors
demonstrate that dynamics transition through potentially chaotic to randomly
correlated process as the averaging time-scale increases. Finally, the temporal
trends of {\lambda} and GC are statistically significant at about 40% of the
total number of stations analyzed. Attributing this trend to factors such as
changing climate or land use requires further research.",http://arxiv.org/abs/1912.03343v1
The imperative to reduce carbon emissions in astronomy,2019-12-12T08:50:42Z,"Adam R. H. Stevens, Sabine Bellstedt, Pascal J. Elahi, Michael T. Murphy","For astronomers to make a significant contribution to the reduction of
climate change-inducing greenhouse gas emissions, we first must quantify our
sources of emissions and review the most effective approaches for reducing
them. Here we estimate that Australian astronomers' total greenhouse gas
emissions from their regular work activities are $\gtrsim$25 ktCO$_2$-e/yr
(equivalent kilotonnes of carbon dioxide per year). This can be broken into
$\sim$15 ktCO$_2$-e/yr from supercomputer usage, $\sim$4.2 ktCO$_2$-e/yr from
flights (where individuals' flight emissions correlate with seniority), $>$3.3
ktCO$_2$-e/yr from the operation of observatories, and 2.6$\pm$0.4
ktCO$_2$-e/yr from powering office buildings. Split across faculty scientists,
postdoctoral researchers, and PhD students, this averages to $\gtrsim$37
tCO$_2$-e/yr per astronomer, over 40% more than what the average Australian
non-dependant emits in total, equivalent to $\sim$5$\times$ the global average.
To combat these environmentally unsustainable practices, we suggest astronomers
should strongly preference use of supercomputers, observatories, and office
spaces that are predominantly powered by renewable energy sources. Where
facilities that we currently use do not meet this requirement, their funders
should be lobbied to invest in renewables, such as solar or wind farms. Air
travel should also be reduced wherever possible, replaced primarily by video
conferencing, which should also promote inclusivity.",http://arxiv.org/abs/1912.05834v3
"Consequences of glacial cycles for magmatism and carbon transport at
  mid-ocean ridges",2019-04-05T16:45:40Z,"Nestor G. Cerpa, David W. Rees Jones, Richard F. Katz","Magmatism and volcanism transfer carbon from the solid Earth into the climate
system. This transfer may be modulated by the glacial/interglacial cycling of
water between oceans and continental ice sheets, which alters the surface
loading of the solid Earth. The consequent volcanic-carbon fluctuations have
been proposed as a pacing mechanism for Pleistocene glacial cycles. This
mechanism is dependant on the amplitude and lag of the mid-ocean ridge response
to sea-level changes. Here we develop and analyse a new model for that
response, eliminating some questionable assumptions made in previous work. Our
model calculates the carbon flux, accounting for the thermodynamic effect of
mantle carbon: reduction of the solidus temperature and a deeper onset of
melting. We analyse models forced by idealised, periodic sea level and conclude
that fluctuations in melting rate are the prime control on magma and carbon
flux. We also discuss a model forced by a reconstruction of eustatic sea level
over the past 800 kyr. It indicates that peak-to-trough variations of magma and
carbon flux are up to about 20% and 10% of the mean flux, respectively. Peaks
in mid-ocean ridge emissions lag peaks in sea-level forcing by less than about
20 kyr and the lag could well be shorter. The amplitude and lag are sensitive
to the rate of melt segregation. The lag is much shorter than the time it takes
for melt to travel vertically across the melting region.",http://arxiv.org/abs/1904.03154v2
"Machine Vision for Natural Gas Methane Emissions Detection Using an
  Infrared Camera",2019-04-01T05:38:59Z,"Jingfan Wang, Lyne P. Tchapmi, Arvind P. Ravikumara, Mike McGuire, Clay S. Bell, Daniel Zimmerle, Silvio Savarese, Adam R. Brandt","It is crucial to reduce natural gas methane emissions, which can potentially
offset the climate benefits of replacing coal with gas. Optical gas imaging
(OGI) is a widely-used method to detect methane leaks, but is labor-intensive
and cannot provide leak detection results without operators' judgment. In this
paper, we develop a computer vision approach to OGI-based leak detection using
convolutional neural networks (CNN) trained on methane leak images to enable
automatic detection. First, we collect ~1 M frames of labeled video of methane
leaks from different leaking equipment for building CNN model, covering a wide
range of leak sizes (5.3-2051.6 gCH4/h) and imaging distances (4.6-15.6 m).
Second, we examine different background subtraction methods to extract the
methane plume in the foreground. Third, we then test three CNN model variants,
collectively called GasNet, to detect plumes in videos taken at other pieces of
leaking equipment. We assess the ability of GasNet to perform leak detection by
comparing it to a baseline method that uses optical-flow based change detection
algorithm. We explore the sensitivity of results to the CNN structure, with a
moderate-complexity variant performing best across distances. We find that the
detection accuracy can reach as high as 99%, the overall detection accuracy can
exceed 95% for a case across all leak sizes and imaging distances. Binary
detection accuracy exceeds 97% for large leaks (~710 gCH4/h) imaged closely
(~5-7 m). At closer imaging distances (~5-10 m), CNN-based models have greater
than 94% accuracy across all leak sizes. At farthest distances (~13-16 m),
performance degrades rapidly, but it can achieve above 95% accuracy to detect
large leaks (>950 gCH4/h). The GasNet-based computer vision approach could be
deployed in OGI surveys to allow automatic vigilance of methane leak detection
with high detection accuracy in the real world.",http://arxiv.org/abs/1904.08500v1
ArcticNet: A Deep Learning Solution to Classify Arctic Wetlands,2019-06-01T02:40:47Z,"Ziyu Jiang, Kate Von Ness, Julie Loisel, Zhangyang Wang","Arctic environments are rapidly changing under the warming climate. Of
particular interest are wetlands, a type of ecosystem that constitutes the most
effective terrestrial long-term carbon store. As permafrost thaws, the carbon
that was locked in these wetland soils for millennia becomes available for
aerobic and anaerobic decomposition, which releases CO2 and CH4, respectively,
back to the atmosphere.As CO2 and CH4 are potent greenhouse gases, this
transfer of carbon from the land to the atmosphere further contributes to
global warming, thereby increasing the rate of permafrost degradation in a
positive feedback loop. Therefore, monitoring Arctic wetland health and
dynamics is a key scientific task that is also of importance for policy.
However, the identification and delineation of these important wetland
ecosystems, remain incomplete and often inaccurate. Mapping the extent of
Arctic wetlands remains a challenge for the scientific community. Conventional,
coarser remote sensing methods are inadequate at distinguishing the diverse and
micro-topographically complex non-vascular vegetation that characterize Arctic
wetlands, presenting the need for better identification methods. To tackle this
challenging problem, we constructed and annotated the first-of-its-kind Arctic
Wetland Dataset (AWD). Based on that, we present ArcticNet, a deep neural
network that exploits the multi-spectral, high-resolution imagery captured from
nanosatellites (Planet Dove CubeSats) with additional DEM from the ArcticDEM
project, to semantically label a Arctic study area into six types, in which
three Arctic wetland functional types are included. We present multi-fold
efforts to handle the arising challenges, including class imbalance, and the
choice of fusion strategies. Preliminary results endorse the high promise of
ArcticNet, achieving 93.12% in labelling a hold-out set of regions in our
Arctic study area.",http://arxiv.org/abs/1906.00133v1
"Estimation of common change point and isolation of changed panels after
  sequential detection",2019-07-03T18:46:43Z,Yanhong Wu,"Quick detection of common changes is critical in sequential monitoring of
multi-stream data where a common change is referred as a change that only
occurs in a portion of panels. After a common change is detected by using a
combined CUSUM-SR procedure, we first study the joint distribution for values
of the CUSUM process and the estimated delay detection time for the unchanged
panels. The BH method by using the asymptotic exponential property for the
CUSUM process is developed to isolate the changed panels with the control on
FDR. The common change point is then estimated based on the isolated changed
panels. Simulation results show that the proposed method can also control the
FNR by properly selecting FDR.",http://arxiv.org/abs/1907.02097v1
The meaning of a program change is a change to the program's meaning,2019-08-02T15:01:07Z,Roly Perera,"Programming is the activity of modifying a program in order to bring about
specific changes in its behaviour. Yet programming language theory almost
exclusively focuses on the meaning of programs. We motivate a ""change-oriented""
viewpoint from which the meaning of a program change is a change to the
program's meaning.",http://arxiv.org/abs/1908.00898v1
Which principal components are most sensitive to distributional changes?,2019-05-15T17:50:22Z,Martin Tveten,"PCA is often used in anomaly detection and statistical process control tasks.
For bivariate data, we prove that the minor projection (the least varying
projection) of the PCA-rotated data is the most sensitive to distributional
changes, where sensitivity is defined by the Hellinger distance between
distributions before and after a change. In particular, this is almost always
the case if only one parameter of the bivariate normal distribution changes,
i.e., the change is sparse. Simulations indicate that the minor projections are
the most sensitive for a large range of changes and pre-change settings in
higher dimensions as well. This motivates using the minor projections for
detecting sparse distributional changes in high-dimensional data.",http://arxiv.org/abs/1905.06318v1
Region crossing change on surfaces,2019-08-19T15:01:50Z,"Jiawei Cheng, Zhiyun Cheng, Jinwen Xu, Jieyao Zheng","Region crossing change is a local operation on link diagrams. The behavior of
region crossing change on $S^2$ is well understood. In this paper, we study the
behavior of (modified) region crossing change on higher genus surfaces.",http://arxiv.org/abs/1908.06864v1
Privately detecting changes in unknown distributions,2019-10-03T07:05:59Z,"Rachel Cummings, Sara Krehbiel, Yuliia Lut, Wanrong Zhang","The change-point detection problem seeks to identify distributional changes
in streams of data. Increasingly, tools for change-point detection are applied
in settings where data may be highly sensitive and formal privacy guarantees
are required, such as identifying disease outbreaks based on hospital records,
or IoT devices detecting activity within a home. Differential privacy has
emerged as a powerful technique for enabling data analysis while preventing
information leakage about individuals. Much of the prior work on change-point
detection---including the only private algorithms for this problem---requires
complete knowledge of the pre-change and post-change distributions. However,
this assumption is not realistic for many practical applications of interest.
This work develops differentially private algorithms for solving the
change-point problem when the data distributions are unknown. Additionally, the
data may be sampled from distributions that change smoothly over time, rather
than fixed pre-change and post-change distributions. We apply our algorithms to
detect changes in the linear trends of such data streams. Finally, we also
provide experimental results to empirically validate the performance of our
algorithms.",http://arxiv.org/abs/1910.01327v2
Robust Change Captioning,2019-01-08T21:29:42Z,"Dong Huk Park, Trevor Darrell, Anna Rohrbach","Describing what has changed in a scene can be useful to a user, but only if
generated text focuses on what is semantically relevant. It is thus important
to distinguish distractors (e.g. a viewpoint change) from relevant changes
(e.g. an object has moved). We present a novel Dual Dynamic Attention Model
(DUDA) to perform robust Change Captioning. Our model learns to distinguish
distractors from semantic changes, localize the changes via Dual Attention over
""before"" and ""after"" images, and accurately describe them in natural language
via Dynamic Speaker, by adaptively focusing on the necessary visual inputs
(e.g. ""before"" or ""after"" image). To study the problem in depth, we collect a
CLEVR-Change dataset, built off the CLEVR engine, with 5 types of scene
changes. We benchmark a number of baselines on our dataset, and systematically
study different change types and robustness to distractors. We show the
superiority of our DUDA model in terms of both change captioning and
localization. We also show that our approach is general, obtaining
state-of-the-art results on the recent realistic Spot-the-Diff dataset which
has no distractors.",http://arxiv.org/abs/1901.02527v2
"Detected changes in precipitation extremes at their native scales
  derived from in situ measurements",2019-02-15T19:53:43Z,"Mark D. Risser, Christopher J. Paciorek, Travis A. O'Brien, Michael F. Wehner, William D. Collins","The gridding of daily accumulated precipitation -- especially extremes --
from ground-based station observations is problematic due to the fractal nature
of precipitation, and therefore estimates of long period return values and
their changes based on such gridded daily data sets are generally
underestimated. In this paper, we characterize high-resolution changes in
observed extreme precipitation from 1950 to 2017 for the contiguous United
States (CONUS) based on in situ measurements only. Our analysis utilizes
spatial statistical methods that allow us to derive gridded estimates that do
not smooth extreme daily measurements and are consistent with statistics from
the original station data while increasing the resulting signal to noise ratio.
Furthermore, we use a robust statistical technique to identify significant
pointwise changes in the climatology of extreme precipitation while carefully
controlling the rate of false positives. We present and discuss seasonal
changes in the statistics of extreme precipitation: the largest and most
spatially-coherent pointwise changes are in fall (SON), with approximately 33%
of CONUS exhibiting significant changes (in an absolute sense). Other seasons
display very few meaningful pointwise changes (in either a relative or absolute
sense), illustrating the difficulty in detecting pointwise changes in extreme
precipitation based on in situ measurements. While our main result involves
seasonal changes, we also present and discuss annual changes in the statistics
of extreme precipitation. In this paper we only seek to detect changes over
time and leave attribution of the underlying causes of these changes for future
work.",http://arxiv.org/abs/1902.05977v3
Change Actions: Models of Generalised Differentiation,2019-02-14T16:00:23Z,"Mario Alvarez-Picallo, C. -H. Luke Ong","Cai et al. have recently proposed change structures as a semantic framework
for incremental computation. We generalise change structures to arbitrary
cartesian categories and propose the notion of change action model as a
categorical model for (higher-order) generalised differentiation. Change action
models naturally arise from many geometric and computational settings, such as
(generalised) cartesian differential categories, group models of discrete
calculus, and Kleene algebra of regular expressions. We show how to build
canonical change action models on arbitrary cartesian categories, reminiscent
of the F\`aa di Bruno construction.",http://arxiv.org/abs/1902.05465v3
Robust change point tests by bounded transformations,2019-05-15T14:14:12Z,"Alexander Dürre, Roland Fried","Classical moment based change point tests like the cusum test are very
powerful in case of Gaussian time series with one change point but behave
poorly under heavy tailed distributions and corrupted data. A new class of
robust change point tests based on cusum statistics of robustly transformed
observations is proposed. This framework is quite flexible, depending on the
used transformation one can detect for instance changes in the mean, scale or
dependence of a possibly multivariate time series. Simulations indicate that
this approach is very powerful in detecting changes in the marginal variance of
ARCH processes and outperforms existing proposals for detecting structural
breaks in the dependence structure of heavy tailed multivariate time series.",http://arxiv.org/abs/1905.06201v1
Semantic Change and Semantic Stability: Variation is Key,2019-06-13T15:40:50Z,Claire Bowern,"I survey some recent approaches to studying change in the lexicon,
particularly change in meaning across phylogenies. I briefly sketch an
evolutionary approach to language change and point out some issues in recent
approaches to studying semantic change that rely on temporally stratified word
embeddings. I draw illustrations from lexical cognate models in Pama-Nyungan to
identify meaning classes most appropriate for lexical phylogenetic inference,
particularly highlighting the importance of variation in studying change over
time.",http://arxiv.org/abs/1906.05760v1
Gamma factors of level zero supercuspidal representations,2019-03-27T15:45:32Z,Chang Yang,"We give an explicit formula for the twisted gamma factor for a pair of
irreducible supercuspidal representations of level zero. We also obtain an
explicit formula for the unramified base change of level zero supercuspidal
representations.",http://arxiv.org/abs/1903.11497v1
Inference of Dynamic Graph Changes for Functional Connectome,2019-05-24T01:44:10Z,"Dingjue Ji, Junwei Lu, Yiliang Zhang, Hongyu Zhao, Siyuan Gao","Dynamic functional connectivity is an effective measure for the brain's
responses to continuous stimuli. We propose an inferential method to detect the
dynamic changes of brain networks based on time-varying graphical models.
Whereas most existing methods focus on testing the existence of change points,
the dynamics in the brain network offer more signals in many neuroscience
studies. We propose a novel method to conduct hypothesis testing on changes in
dynamic brain networks. We introduce a bootstrap statistic to approximate the
supreme of the high-dimensional empirical processes over dynamically changing
edges. Our simulations show that this framework can capture the change points
with changed connectivity. Finally, we apply our method to a brain imaging
dataset under a natural audio-video stimulus and illustrate that we are able to
detect temporal changes in brain networks. The functions of the identified
regions are consistent with specific emotional annotations, which are closely
associated with changes inferred by our method.",http://arxiv.org/abs/1905.09993v2
"Analyzing the Context of Bug-Fixing Changes in the OpenStack Cloud
  Computing Platform",2019-08-29T15:33:00Z,"Domenico Cotroneo, Luigi De Simone, Antonio Ken Iannillo, Roberto Natella, Stefano Rosiello, Nematollah Bidokhti","Many research areas in software engineering, such as mutation testing,
automatic repair, fault localization, and fault injection, rely on empirical
knowledge about recurring bug-fixing code changes. Previous studies in this
field focus on what has been changed due to bug-fixes, such as in terms of code
edit actions. However, such studies did not consider where the bug-fix change
was made (i.e., the context of the change), but knowing about the context can
potentially narrow the search space for many software engineering techniques
(e.g., by focusing mutation only on specific parts of the software).
Furthermore, most previous work on bug-fixing changes focused on C and Java
projects, but there is little empirical evidence about Python software.
Therefore, in this paper we perform a thorough empirical analysis of bug-fixing
changes in three OpenStack projects, focusing on both the what and the where of
the changes. We observed that all the recurring change patterns are not
oblivious with respect to the surrounding code, but tend to occur in specific
code contexts.",http://arxiv.org/abs/1908.11297v1
"How Do Code Changes Evolve in Different Platforms? A Mining-based
  Investigation",2019-10-24T21:36:52Z,"Markos Viggiato, Johnatan Oliveira, Eduardo Figueiredo, Pooyan Jamshidi, Christian Kästner","Code changes are performed differently in the mobile and non-mobile
platforms. Prior work has investigated the differences in specific platforms.
However, we still lack a deeper understanding of how code changes evolve across
different software platforms. In this paper, we present a study aiming at
investigating the frequency of changes and how source code, build and test
changes co-evolve in mobile and non-mobile platforms. We developed regression
models to explain which factors influence the frequency of changes and applied
the Apriori algorithm to find types of changes that frequently co-occur. Our
findings show that non-mobile repositories have a higher number of commits per
month and our regression models suggest that being mobile significantly impacts
on the number of commits in a negative direction when controlling for confound
factors, such as code size. We also found that developers do not usually change
source code files together with build or test files. We argue that our results
can provide valuable information for developers on how changes are performed in
different platforms so that practices adopted in successful software systems
can be followed.",http://arxiv.org/abs/1910.11433v1
Region crossing change on spatial theta-curves,2019-10-27T05:08:57Z,"Ayaka Shimizu, Rinno Takahashi","A region crossing change at a region of a spatial-graph diagram is a
transformation changing every crossing on the boundary of the region. In this
paper, it is shown that every spatial graph consisting of theta-curves can be
unknotted by region crossing changes.",http://arxiv.org/abs/1910.12183v1
"Optimal nonparametric multivariate change point detection and
  localization",2019-10-29T14:27:40Z,"Oscar Hernan Madrid Padilla, Yi Yu, Daren Wang, Alessandro Rinaldo","We study the multivariate nonparametric change point detection problem, where
the data are a sequence of independent $p$-dimensional random vectors whose
distributions are piecewise-constant with Lipschitz densities changing at
unknown times, called change points. We quantify the size of the distributional
change at any change point with the supremum norm of the difference between the
corresponding densities. We are concerned with the localization task of
estimating the positions of the change points. In our analysis, we allow for
the model parameters to vary with the total number of time points, including
the minimal spacing between consecutive change points and the magnitude of the
smallest distributional change. We provide information-theoretic lower bounds
on both the localization rate and the minimal signal-to-noise ratio required to
guarantee consistent localization. We formulate a novel algorithm based on
kernel density estimation that nearly achieves the minimax lower bound, save
possibly for logarithm factors. We have provided extensive numerical evidence
to support our theoretical findings.",http://arxiv.org/abs/1910.13289v3
Change Detection with the Kernel Cumulative Sum Algorithm,2019-03-05T04:30:17Z,"Thomas Flynn, Shinjae Yoo","Online change detection involves monitoring a stream of data for changes in
the statistical properties of incoming observations. A good change detector
will detect any changes shortly after they occur, while raising few false
alarms. Although there are algorithms with confirmed optimality properties for
this task, they rely on the exact specifications of the relevant probability
distributions and this limits their practicality. In this work we describe a
kernel-based variant of the Cumulative Sum (CUSUM) change detection algorithm
that can detect changes under less restrictive assumptions. Instead of using
the likelihood ratio, which is a parametric quantity, the Kernel CUSUM (KCUSUM)
algorithm compares incoming data with samples from a reference distribution
using a statistic based on the Maximum Mean Discrepancy (MMD) non-parametric
testing framework. The KCUSUM algorithm is applicable in settings where there
is a large amount of background data available and it is desirable to detect a
change away from this background setting. Exploiting the random-walk structure
of the test statistic, we derive bounds on the performance of the algorithm,
including the expected delay and the average time to false alarm.",http://arxiv.org/abs/1903.01661v2
"Unsupervised Change Detection in Multi-temporal VHR Images Based on Deep
  Kernel PCA Convolutional Mapping Network",2019-12-18T14:20:11Z,"Chen Wu, Hongruixuan Chen, Bo Do, Liangpei Zhang","With the development of Earth observation technology, very-high-resolution
(VHR) image has become an important data source of change detection. Nowadays,
deep learning methods have achieved conspicuous performance in the change
detection of VHR images. Nonetheless, most of the existing change detection
models based on deep learning require annotated training samples. In this
paper, a novel unsupervised model called kernel principal component analysis
(KPCA) convolution is proposed for extracting representative features from
multi-temporal VHR images. Based on the KPCA convolution, an unsupervised deep
siamese KPCA convolutional mapping network (KPCA-MNet) is designed for binary
and multi-class change detection. In the KPCA-MNet, the high-level
spatial-spectral feature maps are extracted by a deep siamese network
consisting of weight-shared PCA convolution layers. Then, the change
information in the feature difference map is mapped into a 2-D polar domain.
Finally, the change detection results are generated by threshold segmentation
and clustering algorithms. All procedures of KPCA-MNet does not require labeled
data. The theoretical analysis and experimental results demonstrate the
validity, robustness, and potential of the proposed method in two binary change
detection data sets and one multi-class change detection data set.",http://arxiv.org/abs/1912.08628v1
Curvature-dimension conditions for diffusions under time change,2019-07-12T14:21:26Z,"Bang-Xian Han, Karl-Theodor Sturm","We derive precise transformation formulas for synthetic lower Ricci bounds
under time change. More precisely, for local Dirichlet forms we study how the
curvature-dimension condition in the sense of Bakry-Emery will transform under
time change. Similarly, for metric measure spaces we study how the
curvature-dimension condition in the sense of Lott-Sturm-Villani will transform
under time change.",http://arxiv.org/abs/1907.05761v1
Quickest Change Detection in the Presence of a Nuisance Change,2019-02-09T17:59:26Z,"Tze Siong Lau, Wee Peng Tay","In the quickest change detection problem in which both nuisance and critical
changes may occur, the objective is to detect the critical change as quickly as
possible without raising an alarm when either there is no change or a nuisance
change has occurred. A window-limited sequential change detection procedure
based on the generalized likelihood ratio test statistic is proposed. A
recursive update scheme for the proposed test statistic is developed and is
shown to be asymptotically optimal under mild technical conditions. In the
scenario where the post-change distribution belongs to a parametrized family, a
generalized stopping time and a lower bound on its average run length are
derived. The proposed stopping rule is compared with the FMA stopping time and
the naive 2-stage procedure that detects the nuisance or critical change using
separate CuSum stopping procedures for the nuisance and critical changes.
Simulations demonstrate that the proposed rule outperforms the FMA stopping
time and the 2-stage procedure, and experiments on a real dataset on bearing
failure verify the performance of the proposed stopping time.",http://arxiv.org/abs/1902.03460v5
Rectangles in latin squares,2019-02-13T17:40:56Z,I. I. Deriyenko,"To get another from a given latin square, we have to change at least 4
entries. We show how to find these entries and how to change them.",http://arxiv.org/abs/1902.05656v1
Detecting multiple generalized change-points by isolating single ones,2019-01-30T14:36:45Z,"Andreas Anastasiou, Piotr Fryzlewicz","We introduce a new approach, called Isolate-Detect (ID), for the consistent
estimation of the number and location of multiple generalized change-points in
noisy data sequences. Examples of signal changes that ID can deal with are
changes in the mean of a piecewise-constant signal and changes, continuous or
not, in the linear trend. The number of change-points can increase with the
sample size. Our method is based on an isolation technique, which prevents the
consideration of intervals that contain more than one change-point. This
isolation enhances ID's accuracy as it allows for detection in the presence of
frequent changes of possibly small magnitudes. In ID, model selection is
carried out via thresholding, or an information criterion, or SDLL, or a hybrid
involving the former two. The hybrid model selection leads to a general method
with very good practical performance and minimal parameter choice. In the
scenarios tested, ID is at least as accurate as the state-of-the-art methods;
most of the times it outperforms them. ID is implemented in the R packages
IDetect and breakfast, available from CRAN.",http://arxiv.org/abs/1901.10852v2
Regions In a Linked Dataset For Change Detection,2019-05-19T00:01:05Z,Anuj Singh,"Linked Datasets (LDs) are constantly evolving and the applications using a
Linked Dataset (LD) may face several issues such as outdated data or broken
interlinks due to evolution of the dataset. To overcome these issues, the
detection of changes in LDs during their evolution has proven crucial. As LDs
evolve frequently, the change detection during the evolution should also be
done at frequent intervals. However, due to limitation of available
computational resources such as capacity to fetch data from LD and time to
detect changes, the frequent change detection may not be possible with existing
change detection techniques. This research proposes to explore the notion of
prioritization of regions (subsets) in LDs for change detection with the aim of
achieving optimal accuracy and efficient use of available computational
resources. This will facilitate the detection of changes in an evolving LD at
frequent intervals and will allow the applications to update their data closest
to real-time data.",http://arxiv.org/abs/1905.07663v1
"Confirmatory Bayesian Online Change Point Detection in the Covariance
  Structure of Gaussian Processes",2019-05-30T16:52:42Z,"Jiyeon Han, Kyowoon Lee, Anh Tong, Jaesik Choi","In the analysis of sequential data, the detection of abrupt changes is
important in predicting future changes. In this paper, we propose statistical
hypothesis tests for detecting covariance structure changes in locally smooth
time series modeled by Gaussian Processes (GPs). We provide theoretically
justified thresholds for the tests, and use them to improve Bayesian Online
Change Point Detection (BOCPD) by confirming statistically significant changes
and non-changes. Our Confirmatory BOCPD (CBOCPD) algorithm finds multiple
structural breaks in GPs even when hyperparameters are not tuned precisely. We
also provide conditions under which CBOCPD provides the lower prediction error
compared to BOCPD. Experimental results on synthetic and real-world datasets
show that our new tests correctly detect changes in the covariance structure in
GPs. The proposed algorithm also outperforms existing methods for the
prediction of nonstationarity in terms of both regression error and log
likelihood.",http://arxiv.org/abs/1905.13168v2
"Online Detection of Sparse Changes in High-Dimensional Data Streams
  Using Tailored Projections",2019-08-06T09:06:45Z,"Martin Tveten, Ingrid K. Glad","When applying principal component analysis (PCA) for dimension reduction, the
most varying projections are usually used in order to retain most of the
information. For the purpose of anomaly and change detection, however, the
least varying projections are often the most important ones. In this article,
we present a novel method that automatically tailors the choice of projections
to monitor for sparse changes in the mean and/or covariance matrix of
high-dimensional data. A subset of the least varying projections is almost
always selected based on a criteria of the projection's sensitivity to changes.
  Our focus is on online/sequential change detection, where the aim is to
detect changes as quickly as possible, while controlling false alarms at a
specified level. A combination of tailored PCA and a generalized log-likelihood
monitoring procedure displays high efficiency in detecting even very sparse
changes in the mean, variance and correlation. We demonstrate on real data that
tailored PCA monitoring is efficient for sparse change detection also when the
data streams are highly auto-correlated and non-normal. Notably, error control
is achieved without a large validation set, which is needed in most existing
methods.",http://arxiv.org/abs/1908.02029v1
Changes in the solar rotation over two solar cycles,2019-08-14T18:00:09Z,"Sarbani Basu, H. M. Antia","We use helioseismic data from ground and space-based instruments to analyze
how solar rotation has changed since the beginning of solar Cycle 23 with
emphasis on studying the differences between Cycles 23 and 24. We find that the
nature of solar rotation is indeed different for the two cycles. While the
changes in the latitudinally independent component follows solar-cycle indices,
some of the other components have a more complicated behavior. There is a
substantial change in the behavior of the solar zonal flows and their spatial
gradients too. While the zonal flows are in general weaker in Cycle 24 than
those in Cycle 23, there are clear signs of the emergence of Cycle 25. We have
also investigated the properties of the solar tachocline, in particular, its
position, width, and the change (or jump) in the rotation rate across it. We
find significant temporal variation in the change of the rotation rate across
the tachocline. We also find that the changes in solar Cycle 24 were very
different from those of Cycle 23. We do not find any statistically significant
change in the position or the width of the tachocline.",http://arxiv.org/abs/1908.05282v1
"Bivariate change point detection: joint detection of changes in
  expectation and variance",2019-04-02T10:30:33Z,Michael Messer,"A method for change point detection is proposed. We consider a univariate
sequence of independent random variables with piecewise constant expectation
and variance, apart from which the distribution may vary periodically. We aim
to detect change points in both expectation and variance. For that, we propose
a statistical test for the null hypothesis of no change points and an algorithm
for change point detection. Both are based on a bivariate moving sum approach
that jointly evaluates the mean and the empirical variance. The joint
consideration helps improve inference as compared to separate univariate
approaches. We infer on the strength and the type of changes with confidence.
Nonparametric methodology supports the analysis of diverse data. Additionally,
a multi-scale approach addresses complex patterns in change points and effects.
We demonstrate the performance through theoretical results and simulation
studies. A companion R-package jcp (available on CRAN) is discussed.",http://arxiv.org/abs/1904.01320v3
"Cycle-Consistent Adversarial Networks for Realistic Pervasive Change
  Generation in Remote Sensing Imagery",2019-11-28T06:03:18Z,"Christopher X. Ren, Amanda Ziemann, Alice M. S. Durieux, James Theiler","This paper introduces a new method of generating realistic pervasive changes
in the context of evaluating the effectiveness of change detection algorithms
in controlled settings. The method, a cycle-consistent adversarial network
(CycleGAN), requires low quantities of training data to generate realistic
changes. Here we show an application of CycleGAN in creating realistic
snow-covered scenes of multispectral Sentinel-2 imagery, and demonstrate how
these images can be used as a test bed for anomalous change detection
algorithms.",http://arxiv.org/abs/1911.12546v3
Generating Timelines by Modeling Semantic Change,2019-09-21T21:57:38Z,"Guy D. Rosin, Kira Radinsky","Though languages can evolve slowly, they can also react strongly to dramatic
world events. By studying the connection between words and events, it is
possible to identify which events change our vocabulary and in what way. In
this work, we tackle the task of creating timelines - records of historical
""turning points"", represented by either words or events, to understand the
dynamics of a target word. Our approach identifies these points by leveraging
both static and time-varying word embeddings to measure the influence of words
and events. In addition to quantifying changes, we show how our technique can
help isolate semantic changes. Our qualitative and quantitative evaluations
show that we are able to capture this semantic change and event influence.",http://arxiv.org/abs/1909.09907v1
Triangulation Graph and Color Changing Channel,2019-01-10T06:55:15Z,Rundong Gan,"Triangulation graph staining is sufficient for planar graph staining. This
article will focus on triangulation and the nature of the color change channel
of the staining tool. By construction, the four colors of the vertex are
converted into three colors of the side, and two colors of the triangle.
Thereby the equivalent dyeing scheme is combined. The color change channel
utilizes the transferability of edge dyeing to reflect the integrity of the
triangulation graph. According to the nature of the color change channel, two
constraints are obtained, so that the color change can be followed regularly.
Eventually, a breakthrough was made in the structure of the reduced d(v)=5,
which proves the reducible of this structure. This negates the existence of the
smallest counterexample.",http://arxiv.org/abs/1901.09008v1
Time-changed Stochastic Control Problem and its Maximum Principle Theory,2019-05-28T16:30:27Z,"Erkan Nane, Yinan Ni","This paper studies a time-changed stochastic control problem, where the
underlying stochastic process is a L\'evy noise time-changed by an inverse
subordinator. We establish a maximum principle theory for the time-changed
stochastic control problem. We also prove the existence and uniqueness of the
corresponding time-changed backward stochastic differential equation involved
in the stochastic control problem. Some examples are provided for illustration.",http://arxiv.org/abs/1905.11921v1
"On the Informativeness of Measurements in Shiryaev's Bayesian Quickest
  Change Detection",2019-03-08T04:49:03Z,"Jason J. Ford, Jasmin James, Timothy L. Molloy","This paper provides the first description of a weak practical
super-martingale phenomenon that can emerge in the test statistic in Shiryaev's
Bayesian quickest change detection (QCD) problem. We establish that this
super-martingale phenomenon can emerge under a condition on the relative
entropy between pre and post change densities when the measurements are
insufficiently informative to overcome the change time's geometric prior. We
illustrate this super-martingale phenomenon in a simple Bayesian QCD problem
which highlights the unsuitability of Shiryaev's test statistic for detecting
subtle change events.",http://arxiv.org/abs/1903.03283v2
Adaptive Variance for Changing Sparse-Reward Environments,2019-03-15T00:40:59Z,"Xingyu Lin, Pengsheng Guo, Carlos Florensa, David Held","Robots that are trained to perform a task in a fixed environment often fail
when facing unexpected changes to the environment due to a lack of exploration.
We propose a principled way to adapt the policy for better exploration in
changing sparse-reward environments. Unlike previous works which explicitly
model environmental changes, we analyze the relationship between the value
function and the optimal exploration for a Gaussian-parameterized policy and
show that our theory leads to an effective strategy for adjusting the variance
of the policy, enabling fast adapt to changes in a variety of sparse-reward
environments.",http://arxiv.org/abs/1903.06309v2
"A Wind of Change: Detecting and Evaluating Lexical Semantic Change
  across Times and Domains",2019-06-07T09:19:47Z,"Dominik Schlechtweg, Anna Hätty, Marco del Tredici, Sabine Schulte im Walde","We perform an interdisciplinary large-scale evaluation for detecting lexical
semantic divergences in a diachronic and in a synchronic task: semantic sense
changes across time, and semantic sense changes across domains. Our work
addresses the superficialness and lack of comparison in assessing models of
diachronic lexical change, by bringing together and extending benchmark models
on a common state-of-the-art evaluation task. In addition, we demonstrate that
the same evaluation task and modelling approaches can successfully be utilised
for the synchronic detection of domain-specific sense divergences in the field
of term extraction.",http://arxiv.org/abs/1906.02979v1
Fréchet Change Point Detection,2019-11-26T22:20:39Z,"Paromita Dubey, Hans-Georg Müller","We propose a method to infer the presence and location of change-points in
the distribution of a sequence of independent data taking values in a general
metric space, where change-points are viewed as locations at which the
distribution of the data sequence changes abruptly in terms of either its
Fr\'echet mean or Fr\'echet variance or both. The proposed method is based on
comparisons of Fr\'echet variances before and after putative change-point
locations and does not require a tuning parameter except for the specification
of cut-off intervals near the endpoints where change-points are assumed not to
occur. Our results include theoretical guarantees for consistency of the test
under contiguous alternatives when a change-point exists and also for
consistency of the estimated location of the change-point if it exists, where
under the null hypothesis of no change-point the limit distribution of the
proposed scan function is the square of a standardized Brownian Bridge. These
consistency results are applicable for a broad class of metric spaces under
mild entropy conditions. Examples include the space of univariate probability
distributions and the space of graph Laplacians for networks. Simulation
studies demonstrate the effectiveness of the proposed methods, both for
inferring the presence of a change-point and estimating its location. We also
develop theory that justifies bootstrap-based inference and illustrate the new
approach with sequences of maternal fertility distributions and communication
networks.",http://arxiv.org/abs/1911.11864v2
"Learning and Suggesting Source Code Changes from Version History: A
  Systematic Review",2019-09-09T00:31:26Z,"Leandro Ungari Cayres, Bruno Santos de Lima, Rogério Eduardo Garcia","Context: Software systems are in continuous evolution through source code
changes to fixing bugs, adding new functionalities and improving the internal
architecture. All these practices are recorded in the version history, which
can be reused as an advantage in the development process. Objective: This paper
aims to investigate approaches and techniques related to the learning of source
code changes, since the change identification step, learning, and reuse in
recommending strategies. Method: We conducted a systematic review related to
primary studies about source code changes. The search approach identified 2410
studies, up to and including 2012, which resulted in a final set of 39 selected
papers. We grouped the studies according to each established research question.
This review investigates how source code changes, which were performed in the
past of software, can support the improvement of the software project. Results:
The majority of approaches and techniques have used repetitiveness behavior of
source code changes to identify structural or metrics patterns in software
repositories, trough the evaluation of sequences of versions. To extract the
structural patterns, the approaches have used programming-by-example techniques
to differencing source code changes. In quality metrics analysis, the studies
have applied mainly complexity and object-oriented metrics. Conclusion: The
main implication of this review is that source code changes as examples, to
support the improvement of coding practice during the development process, in
which we presented some relevant strategies to guide each step, since
identifying until the suggesting of source code changes.",http://arxiv.org/abs/1909.03571v3
"Curved surface geometry-induced topological change of an excitable
  planar wave",2019-05-08T06:15:49Z,"Kazuya Horibe, Ken-ichi Hironaka, Katsuyoshi Matsushita, Koichi Fujimoto","On the curved surfaces of living and nonliving materials, planar excitable
waves frequently exhibit directional change and subsequently undergo a
topological change; that is, a series of wave dynamics from fusion,
annihilation to splitting. Theoretical studies have shown that excitable planar
stable waves change their topology significantly depending on the initial
conditions on flat surfaces, whereas the directional-change of the waves occurs
based on the geometry of curved surfaces. However, it is not clear if the
geometry of curved surfaces induces this topological change. In this study, we
first show the curved surface geometry-induced topological changes in a planar
stable wave by numerically solving an excitable reaction-diffusion equation on
a bell-shaped surface. We determined two necessary conditions for inducing
topological change: the characteristic length of the curved surface (i.e.,
height of the bell-shaped structure) should be larger than the width of the
wave and than a threshold independent of the wave width. As for the geometrical
mechanism of the latter, we found that a bifurcation of the globally minimum
geodesics (i.e. minimal paths) on the curved surface leads to the topological
change. These conditions imply that wave topology changes can be predicted on
the basis of curved surfaces, whose structure is larger than the wave width.",http://arxiv.org/abs/1905.02927v1
"Change Detection in Noisy Dynamic Networks: A Spectral Embedding
  Approach",2019-10-05T18:02:18Z,"Isuru Udayangani Hewapathirana, Dominic Lee, Elena Moltchanova, Jeanette McLeod","Change detection in dynamic networks is an important problem in many areas,
such as fraud detection, cyber intrusion detection and health care monitoring.
It is a challenging problem because it involves a time sequence of graphs, each
of which is usually very large and sparse with heterogeneous vertex degrees,
resulting in a complex, high dimensional mathematical object. Spectral
embedding methods provide an effective way to transform a graph to a lower
dimensional latent Euclidean space that preserves the underlying structure of
the network. Although change detection methods that use spectral embedding are
available, they do not address sparsity and degree heterogeneity that usually
occur in noisy real-world graphs and a majority of these methods focus on
changes in the behaviour of the overall network.
  In this paper, we adapt previously developed techniques in spectral graph
theory and propose a novel concept of applying Procrustes techniques to
embedded points for vertices in a graph to detect changes in entity behaviour.
Our spectral embedding approach not only addresses sparsity and degree
heterogeneity issues, but also obtains an estimate of the appropriate embedding
dimension. We call this method CDP (change detection using Procrustes
analysis). We demonstrate the performance of CDP through extensive simulation
experiments and a real-world application. CDP successfully detects various
types of vertex-based changes including (i) changes in vertex degree, (ii)
changes in community membership of vertices, and (iii) unusual increase or
decrease in edge weight between vertices. The change detection performance of
CDP is compared with two other baseline methods that employ alternative
spectral embedding approaches. In both cases, CDP generally shows superior
performance.",http://arxiv.org/abs/1910.02301v1
"Change Detection in Multi-temporal VHR Images Based on Deep Siamese
  Multi-scale Convolutional Networks",2019-06-27T07:53:41Z,"Hongruixuan Chen, Chen Wu, Bo Du, Liangpei Zhang","Very-high-resolution (VHR) images can provide abundant ground details and
spatial geometric information. Change detection in multi-temporal VHR images
plays a significant role in urban expansion and area internal change analysis.
Nevertheless, traditional change detection methods can neither take full
advantage of spatial context information nor cope with the complex internal
heterogeneity of VHR images. In this paper, a powerful feature extraction model
entitled multi-scale feature convolution unit (MFCU) is adopted for change
detection in multi-temporal VHR images. MFCU can extract multi-scale
spatial-spectral features in the same layer. Based on the unit two novel deep
siamese convolutional neural networks, called as deep siamese multi-scale
convolutional network (DSMS-CN) and deep siamese multi-scale fully
convolutional network (DSMS-FCN), are designed for unsupervised and supervised
change detection, respectively. For unsupervised change detection, an automatic
pre-classification is implemented to obtain reliable training samples, then
DSMS-CN fits the statistical distribution of changed and unchanged areas from
selected training samples through MFCU modules and deep siamese architecture.
For supervised change detection, the end-to-end deep fully convolutional
network DSMS-FCN is trained in any size of multi-temporal VHR images, and
directly outputs the binary change map. In addition, for the purpose of solving
the inaccurate localization problem, the fully connected conditional random
field (FC-CRF) is combined with DSMS-FCN to refine the results. The
experimental results with challenging data sets confirm that the two proposed
architectures perform better than the state-of-the-art methods.",http://arxiv.org/abs/1906.11479v2
Fault-Diagnosing SLAM for Varying Scale Change Detection,2019-09-16T08:52:45Z,"Sugimoto Takuma, Yamaguchi Kousuke, Tanaka Kanji","In this paper, we present a new fault diagnosis (FD) -based approach for
detection of imagery changes that can detect significant changes as
inconsistencies between different sub-modules (e.g., self-localizaiton) of
visual SLAM. Unlike classical change detection approaches such as pairwise
image comparison (PC) and anomaly detection (AD), neither the memorization of
each map image nor the maintenance of up-to-date place-specific anomaly
detectors are required in this FD approach. A significant challenge that is
encountered when incorporating different SLAM sub-modules into FD involves
dealing with the varying scales of objects that have changed (e.g., the
appearance of small dangerous obstacles on the floor). To address this issue,
we reconsider the bag-of-words (BoW) image representation, by exploiting its
recent advances in terms of self-localization and change detection. As a key
advantage, BoW image representation can be reorganized into any different
scaling by simply cropping the original BoW image. Furthermore, we propose to
combine different self-localization modules with strong and weak BoW features
with different discriminativity, and to treat inconsistency between strong and
weak self-localization as an indicator of change. The efficacy of the proposed
approach for FD with/without AD and/or PC was experimentally validated.",http://arxiv.org/abs/1909.09592v1
"Semantic Change and Emerging Tropes In a Large Corpus of New High German
  Poetry",2019-09-26T14:18:09Z,"Thomas Haider, Steffen Eger","Due to its semantic succinctness and novelty of expression, poetry is a great
test bed for semantic change analysis. However, so far there is a scarcity of
large diachronic corpora. Here, we provide a large corpus of German poetry
which consists of about 75k poems with more than 11 million tokens, with poems
ranging from the 16th to early 20th century. We then track semantic change in
this corpus by investigating the rise of tropes (`love is magic') over time and
detecting change points of meaning, which we find to occur particularly within
the German Romantic period. Additionally, through self-similarity, we
reconstruct literary periods and find evidence that the law of linear semantic
change also applies to poetry.",http://arxiv.org/abs/1909.12136v1
Change Detection and Notification of Webpages: A Survey,2019-01-09T10:20:40Z,"Vijini Mallawaarachchi, Lakmal Meegahapola, Roshan Alwis, Eranga Nimalarathna, Dulani Meedeniya, Sampath Jayarathna","Majority of the currently available webpages are dynamic in nature and are
changing frequently. New content gets added to webpages and existing content
gets updated or deleted. Hence, people find it useful to be alert for changes
in webpages which contain information valuable to them. In the current context,
keeping track of these webpages and getting alerts about different changes have
become significantly challenging. Change Detection and Notification (CDN)
systems were introduced to automate this monitoring process and notify users
when changes occur in webpages. This survey classifies and analyzes different
aspects of CDN systems and different techniques used for each aspect.
Furthermore, the survey highlights the current challenges and areas of
improvement present within the field of research.",http://arxiv.org/abs/1901.02660v4
Predictive Indexing,2019-01-21T20:16:47Z,"Joy Arulraj, Ran Xian, Lin Ma, Andrew Pavlo","There has been considerable research on automated index tuning in database
management systems (DBMSs). But the majority of these solutions tune the index
configuration by retrospectively making computationally expensive physical
design changes all at once. Such changes degrade the DBMS's performance during
the process, and have reduced utility during subsequent query processing due to
the delay between a workload shift and the associated change. A better approach
is to generate small changes that tune the physical design over time, forecast
the utility of these changes, and apply them ahead of time to maximize their
impact.
  This paper presents predictive indexing that continuously improves a
database's physical design using lightweight physical design changes. It uses a
machine learning model to forecast the utility of these changes, and
continuously refines the index configuration of the database to handle evolving
workloads. We introduce a lightweight hybrid scan operator with which a DBMS
can make use of partially-built indexes for query processing. Our evaluation
shows that predictive indexing improves the throughput of a DBMS by 3.5--5.2x
compared to other state-of-the-art indexing approaches. We demonstrate that
predictive indexing works seamlessly with other lightweight automated physical
design tuning methods.",http://arxiv.org/abs/1901.07064v1
"Modeling the Dynamics of User Preferences for Sequence-Aware
  Recommendation Using Hidden Markov Models",2019-05-14T19:56:57Z,"Farzad Eskandanian, Bamshad Mobasher","In a variety of online settings involving interaction with end-users it is
critical for the systems to adapt to changes in user preferences. User
preferences on items tend to change over time due to a variety of factors such
as change in context, the task being performed, or other short-term or
long-term external factors. Recommender systems need to be able to capture
these dynamics in user preferences in order to remain tuned to the most current
interests of users. In this work we present a recommendation framework which
takes into account the dynamics of user preferences. We propose an approach
based on Hidden Markov Models (HMM) to identify change-points in the sequence
of user interactions which reflect significant changes in preference according
to the sequential behavior of all the users in the data. The proposed framework
leverages the identified change points to generate recommendations using a
sequence-aware non-negative matrix factorization model. We empirically
demonstrate the effectiveness of the HMM-based change detection method as
compared to standard baseline methods. Additionally, we evaluate the
performance of the proposed recommendation method and show that it compares
favorably to state-of-the-art sequence-aware recommendation models.",http://arxiv.org/abs/1905.06863v1
Change-point detection in dynamic networks via graphon estimation,2019-08-05T19:50:20Z,"Zifeng Zhao, Li Chen, Lizhen Lin","We propose a general approach for change-point detection in dynamic networks.
The proposed method is model-free and covers a wide range of dynamic networks.
The key idea behind our approach is to effectively utilize the network
structure in designing change-point detection algorithms. This is done via an
initial step of graphon estimation, where we propose a modified neighborhood
smoothing~(MNBS) algorithm for estimating the link probability matrices of a
dynamic network. Based on the initial graphon estimation, we then develop a
screening and thresholding algorithm for multiple change-point detection in
dynamic networks. The convergence rate and consistency for the change-point
detection procedure are derived as well as those for MNBS. When the number of
nodes is large~(e.g., exceeds the number of temporal points), our approach
yields a faster convergence rate in detecting change-points comparing with an
algorithm that simply employs averaged information of the dynamic network
across time. Numerical experiments demonstrate robust performance of the
proposed algorithm for change-point detection under various types of dynamic
networks, and superior performance over existing methods is observed. A real
data example is provided to illustrate the effectiveness and practical impact
of the procedure.",http://arxiv.org/abs/1908.01823v1
"Building change detection based on multi-scale filtering and grid
  partition",2019-08-22T01:38:47Z,"Qi Bi, Kun Qin, Han Zhang, Wenjun Han, Zhili Li, Kai Xu","Building change detection is of great significance in high resolution remote
sensing applications. Multi-index learning, one of the state-of-the-art
building change detection methods, still has drawbacks like incapability to
find change types directly and heavy computation consumption of MBI. In this
paper, a two-stage building change detection method is proposed to address
these problems. In the first stage, a multi-scale filtering building index
(MFBI) is calculated to detect building areas in each temporal with fast speed
and moderate accuracy. In the second stage, images and the corresponding
building maps are partitioned into grids. In each grid, the ratio of building
areas in time T2 and time T1 is calculated. Each grid is classified into one of
the three change patterns, i.e., significantly increase, significantly decrease
and approximately unchanged. Exhaustive experiments indicate that the proposed
method can detect building change types directly and outperform the current
multi-index learning method.",http://arxiv.org/abs/1908.08164v1
"Harnessing the power of Topological Data Analysis to detect change
  points in time series",2019-10-28T19:52:23Z,"Umar Islambekov, Monisha Yuvaraj, Yulia R. Gel","We introduce a novel geometry-oriented methodology, based on the emerging
tools of topological data analysis, into the change point detection framework.
The key rationale is that change points are likely to be associated with
changes in geometry behind the data generating process. While the applications
of topological data analysis to change point detection are potentially very
broad, in this paper we primarily focus on integrating topological concepts
with the existing nonparametric methods for change point detection. In
particular, the proposed new geometry-oriented approach aims to enhance
detection accuracy of distributional regime shift locations. Our simulation
studies suggest that integration of topological data analysis with some
existing algorithms for change point detection leads to consistently more
accurate detection results. We illustrate our new methodology in application to
the two closely related environmental time series datasets -ice phenology of
the Lake Baikal and the North Atlantic Oscillation indices, in a research query
for a possible association between their estimated regime shift locations.",http://arxiv.org/abs/1910.12939v1
"The standard coder: a machine learning approach to measuring the effort
  required to produce source code change",2019-03-06T15:05:06Z,"Ian Wright, Albert Ziegler","We apply machine learning to version control data to measure the quantity of
effort required to produce source code changes. We construct a model of a
`standard coder' trained from examples of code changes produced by actual
software developers together with the labor time they supplied. The effort of a
code change is then defined as the labor hours supplied by the standard coder
to produce that change. We therefore reduce heterogeneous, structured code
changes to a scalar measure of effort derived from large quantities of
empirical data on the coding behavior of software developers. The standard
coder replaces traditional metrics, such as lines-of-code or function point
analysis, and yields new insights into what code changes require more or less
effort.",http://arxiv.org/abs/1903.02436v1
A new class of change point test statistics of Rényi type,2019-04-03T21:56:25Z,"Lajos Horváth, Curtis Miller, Gregory Rice","A new class of change point test statistics is proposed that utilizes a
weighting and trimming scheme for the cumulative sum (CUSUM) process inspired
by R\'enyi (1953). A thorough asymptotic analysis and simulations both
demonstrate that this new class of statistics possess superior power compared
to traditional change point statistics based on the CUSUM process when the
change point is near the beginning or end of the sample. Generalizations of
these ""R\'enyi"" statistics are also developed to test for changes in the
parameters in linear and non-linear regression models, and in generalized
method of moments estimation. In these contexts we applied the proposed
statistics, as well as several others, to test for changes in the coefficients
of Fama-French factor models. We observed that the R\'enyi statistic was the
most effective in terms of retrospectively detecting change points that occur
near the endpoints of the sample.",http://arxiv.org/abs/1904.02250v1
"Moving Object Detection under Discontinuous Change in Illumination Using
  Tensor Low-Rank and Invariant Sparse Decomposition",2019-04-05T17:49:37Z,"Moein Shakeri, Hong Zhang","Although low-rank and sparse decomposition based methods have been
successfully applied to the problem of moving object detection using structured
sparsity-inducing norms, they are still vulnerable to significant illumination
changes that arise in certain applications. We are interested in moving object
detection in applications involving time-lapse image sequences for which
current methods mistakenly group moving objects and illumination changes into
foreground. Our method relies on the multilinear (tensor) data low-rank and
sparse decomposition framework to address the weaknesses of existing methods.
The key to our proposed method is to create first a set of prior maps that can
characterize the changes in the image sequence due to illumination. We show
that they can be detected by a k-support norm. To deal with concurrent, two
types of changes, we employ two regularization terms, one for detecting moving
objects and the other for accounting for illumination changes, in the tensor
low-rank and sparse decomposition formulation. Through comprehensive
experiments using challenging datasets, we show that our method demonstrates a
remarkable ability to detect moving objects under discontinuous change in
illumination, and outperforms the state-of-the-art solutions to this
challenging problem.",http://arxiv.org/abs/1904.03175v2
State-domain Change Point Detection for Nonlinear Time Series Regression,2019-04-24T21:31:12Z,"Yan Cui, Jun Yang, Zhou Zhou","Change point detection in time series has attracted substantial interest, but
most of the existing results have been focused on detecting change points in
the time domain. This paper considers the situation where nonlinear time series
have potential change points in the state domain. We apply a density-weighted
anti-symmetric kernel function to the state domain and therefore propose a
nonparametric procedure to test the existence of change points. When the
existence of change points is affirmative, we further introduce an algorithm to
estimate the number of change points together with their locations. Theoretical
results of the proposed detection and estimation procedures are given and a
real dataset is used to illustrate our methods.",http://arxiv.org/abs/1904.11075v4
"Asymptotically Optimal Change Point Detection for Composite Hypothesis
  in State Space Models",2019-06-08T08:21:51Z,Cheng-Der Fuh,"This paper investigates change point detection in state space models, in
which the pre-change distribution $f^{\theta_0}$ is given, while the poster
distribution $f^{\theta}$ after change is unknown. The problem is to raise an
alarm as soon as possible after the distribution changes from $f^{\theta_0}$ to
$f^{\theta}$, under a restriction on the false alarms. We investigate
theoretical properties of a weighted Shiryayev-Roberts-Pollak (SRP) change
point detection rule in state space models. By making use of a Markov chain
representation for the likelihood function, exponential embedding of the
induced Markovian transition operator, nonlinear Markov renewal theory, and
sequential hypothesis testing theory for Markov random walks, we show that the
weighted SRP procedure is second-order asymptotically optimal. To this end, we
derive an asymptotic approximation for the expected stopping time of such a
stopping scheme when the change time $\omega = 1$. To illustrate our method we
apply the results to two types of state space models: general state Markov
chains and linear state space models.",http://arxiv.org/abs/1906.03416v1
"Imbalanced Learning-based Automatic SAR Images Change Detection by
  Morphologically Supervised PCA-Net",2019-06-19T05:34:50Z,"Rongfang Wang, Jie Zhang, Jia-Wei Chen, Licheng Jiao, Mi Wang","Change detection is a quite challenging task due to the imbalance between
unchanged and changed class. In addition, the traditional difference map
generated by log-ratio is subject to the speckle, which will reduce the
accuracy. In this letter, an imbalanced learning-based change detection is
proposed based on PCA network (PCA-Net), where a supervised PCA-Net is designed
to obtain the robust features directly from given multitemporal SAR images
instead of a difference map. Furthermore, to tackle with the imbalance between
changed and unchanged classes, we propose a morphologically supervised learning
method, where the knowledge in the pixels near the boundary between two classes
are exploited to guide network training. Finally, our proposed PCA-Net can be
trained by the datasets with available reference maps and applied to a new
dataset, which is quite practical in change detection projects. Our proposed
method is verified on five sets of multiple temporal SAR images. It is
demonstrated from the experiment results that with the knowledge in training
samples from the boundary, the learned features benefit for change detection
and make the proposed method outperforms than supervised methods trained by
randomly drawing samples.",http://arxiv.org/abs/1906.07923v1
Invariant Diffs,2019-11-18T22:39:38Z,"Ashwin Kallingal Joshy, Wei Le","Software development is inherently incremental. Nowadays, many software
companies adopt an agile process and a shorter release cycle, where software
needs to be delivered faster with quality assurances. On the other hand, the
majority of existing program analysis tools still target single versions of
programs and are slow and inflexible to handle changes. In the popular version
control systems such as git, the program changes are still presented using
source code diffs. It is hard to understand what program conditions are changed
and which source code lines cause them. In this paper, we propose to compute
""invariant diffs"" to specify changes. Similar to source diffs that report
common code and code churns, we define version invariants to represent program
conditions that are common across versions, and invariant churns to show the
changes of program conditions between versions. We designed a static
demand-driven, path-sensitive analysis to compute and compare invariants for
multiple versions of programs using multiversion control flow graphs. We report
invariant diffs at the matched program points where comparing invariants are
meaningful. Importantly, our analysis correlates source diffs with invariant
diffs to explain what source code changes lead to the property changes. We
implemented our algorithms in a tool called $H_2$ and performed experiments on
104 versions of programs. Our results show that we are able to compute
invariant diffs correctly within reasonable amount of time. The version
invariants can capture the common properties of program versions even
constructed by different persons, and the invariant churns can specify the
semantics of changes such as how a patch changed a buggy condition to a correct
condition.",http://arxiv.org/abs/1911.07988v2
Optimal nonparametric change point detection and localization,2019-05-24T03:34:23Z,"Oscar Hernan Madrid Padilla, Yi Yu, Daren Wang, Alessandro Rinaldo","We study change point detection and localization for univariate data in fully
nonparametric settings in which, at each time point, we acquire an i.i.d.
sample from an unknown distribution. We quantify the magnitude of the
distributional changes at the change points using the Kolmogorov--Smirnov
distance. We allow all the relevant parameters -- the minimal spacing between
two consecutive change points, the minimal magnitude of the changes in the
Kolmogorov--Smirnov distance, and the number of sample points collected at each
time point -- to change with the length of time series. We generalize the
renowned binary segmentation (e.g. Scott and Knott, 1974) algorithm and its
variant, the wild binary segmentation of Fryzlewicz (2014), both originally
designed for univariate mean change point detection problems, to our
nonparametric settings and exhibit rates of consistency for both of them. In
particular, we prove that the procedure based on wild binary segmentation is
nearly minimax rate-optimal. We further demonstrate a phase transition in the
space of model parameters that separates parameter combinations for which
consistent localization is possible from the ones for which this task is
statistical unfeasible. Finally, we provide extensive numerical experiments to
support our theory. R code is available at https://github.com/hernanmp/NWBS.",http://arxiv.org/abs/1905.10019v1
Simple unity among the fundamental equations of science,2019-03-29T07:56:40Z,Steven A. Frank,"The Price equation describes the change in populations. Change concerns some
value, such as biological fitness, information or physical work. The Price
equation reveals universal aspects for the nature of change, independently of
the meaning ascribed to values. By understanding those universal aspects, we
can see more clearly why fundamental mathematical results in different
disciplines often share a common form. We can also interpret more clearly the
meaning of key results within each discipline. For example, the mathematics of
natural selection in biology has a form closely related to information theory
and physical entropy. Does that mean that natural selection is about
information or entropy? Or do natural selection, information and entropy arise
as interpretations of a common underlying abstraction? The Price equation
suggests the latter. The Price equation achieves its abstract generality by
partitioning change into two terms. The first term naturally associates with
the direct forces that cause change. The second term naturally associates with
the changing frame of reference. In the Price equation's canonical form, total
change remains zero because the conservation of total probability requires that
all probabilities invariantly sum to one. Much of the shared common form for
the mathematics of different disciplines may arise from that seemingly trivial
invariance of total probability, which leads to the partitioning of total
change into equal and opposite components of the direct forces and the changing
frame of reference.",http://arxiv.org/abs/1904.00825v2
"Detection and estimation of parameters in high dimensional multiple
  change point regression models via $\ell_1/\ell_0$ regularization and
  discrete optimization",2019-06-11T05:15:24Z,"Abhishek Kaul, Venkata K Jandhyala, Stergios B Fotopoulos","Binary segmentation, which is sequential in nature is thus far the most
widely used method for identifying multiple change points in statistical
models. Here we propose a top down methodology called arbitrary segmentation
that proceeds in a conceptually reverse manner. We begin with an arbitrary
superset of the parametric space of the change points, and locate unknown
change points by suitably filtering this space down. Critically, we reframe the
problem as that of variable selection in the change point parameters, this
enables the filtering down process to be achieved in a single step with the aid
of an $\ell_0$ regularization, thus avoiding the sequentiality of binary
segmentation. We study this method under a high dimensional multiple change
point linear regression model and show that rates convergence of the error in
the regression and change point estimates are near optimal. We propose a
simulated annealing (SA) approach to implement a key finite state space
discrete optimization that arises in our method. Theoretical results are
numerically supported via simulations. The proposed method is shown to possess
the ability to agnostically detect the `no change' scenario. Furthermore, its
computational complexity is of order $O(Np^2)$+SA, where SA is the cost of a SA
optimization on a $N$(no. of change points) dimensional grid. Thus, the
proposed methodology is significantly more computationally efficient than
existing approaches. Finally, our theoretical results are obtained under weaker
model conditions than those assumed in the current literature.",http://arxiv.org/abs/1906.04396v1
"Statistically and Computationally Efficient Change Point Localization in
  Regression Settings",2019-06-26T22:21:56Z,"Daren Wang, Zifeng Zhao, Kevin Lin, Rebecca Willett","Detecting when the underlying distribution changes for the observed time
series is a fundamental problem arising in a broad spectrum of applications. In
this paper, we study multiple change-point localization in the high-dimensional
regression setting, which is particularly challenging as no direct observations
of the parameter of interest is available. Specifically, we assume we observe
$\{ x_t, y_t\}_{t=1}^n$ where $ \{ x_t\}_{t=1}^n $ are $p$-dimensional
covariates, $\{y_t\}_{t=1}^n$ are the univariate responses satisfying
$\mathbb{E}(y_t) = x_t^\top \beta_t^* \text{ for } 1\le t \le n $ and
$\{\beta_t^*\}_{t=1}^n $ are the unobserved regression coefficients that change
over time in a piecewise constant manner. We propose a novel projection-based
algorithm, Variance Projected Wild Binary Segmentation~(VPWBS), which
transforms the original (difficult) problem of change-point detection in
$p$-dimensional regression to a simpler problem of change-point detection in
mean of a one-dimensional time series. VPWBS is shown to achieve sharp
localization rate $O_p(1/n)$ up to a log factor, a significant improvement from
the best rate $O_p(1/\sqrt{n})$ known in the existing literature for multiple
change-point localization in high-dimensional regression. Extensive numerical
experiments are conducted to demonstrate the robust and favorable performance
of VPWBS over two state-of-the-art algorithms, especially when the size of
change in the regression coefficients $\{\beta_t^*\}_{t=1}^n $ is small.",http://arxiv.org/abs/1906.11364v3
"Identifying Dehn Functions of Bestvina--Brady Groups From Their Defining
  Graphs",2019-11-01T20:50:26Z,Yu-Chan Chang,"Let $\Gamma$ be a finite simplicial graph such that the flag complex on
$\Gamma$ is a $2$-dimensional triangulated disk. We show that with some
assumptions, the Dehn function of the associated Bestvina--Brady group is
either quadratic, cubic, or quartic. Furthermore, we can identify the Dehn
function from the defining graph $\Gamma$.",http://arxiv.org/abs/1911.00588v2
Spectral algebras and non-commutative Hodge-to-de Rham degeneration,2019-06-22T23:01:44Z,"D. Kaledin, A. Konovalov, K. Magidson","We revisit the non-commutative Hodge-to-de Rham Degeneration Theorem of the
first author, and present its proof in a somewhat streamlined and improved form
that explicitly uses spectral algebraic geometry. We also try to explain why
topology is essential to the proof.",http://arxiv.org/abs/1906.09518v2
Node Alertness-Detecting changes in rapidly evolving graphs,2019-07-02T12:11:24Z,"Mirco A. Mannucci, Deborah Tylor","In this article we describe a new approach for detecting changes in rapidly
evolving large-scale graphs. The key notion involved is local alertness: nodes
monitor change within their neighborhoods at each time step. Here we propose a
financial local alertness application for cointegrated stock pairs",http://arxiv.org/abs/1907.11623v1
"A hybridized discontinuous Galerkin method for Poisson-type problems
  with sign-changing coefficients",2019-11-05T18:24:18Z,"Jeonghun J. Lee, Sander Rhebergen","In this paper, we present a hybridized discontinuous Galerkin (HDG) method
for Poisson-type problems with sign-changing coefficients. We introduce a
sign-changing stabilization parameter that results in a stable HDG method
independent of domain geometry and the ratio of the negative and positive
coefficients. Since the Poisson-type problem with sign-changing coefficients is
not elliptic, standard techniques with a duality argument to analyze the HDG
method cannot be applied. Hence, we present a novel error analysis exploiting
the stabilized saddle-point problem structure of the HDG method. Numerical
experiments in two dimensions and for varying polynomial degree verify our
theoretical results.",http://arxiv.org/abs/1911.01984v2
A Three-Feature Model to Predict Colour Change Blindness,2019-08-25T23:20:18Z,"Steven Le Moan, Marius Pedersen","Change blindness is a striking shortcoming of our visual system which is
exploited in the popular ""Spot the difference"" game. It makes us unable to
notice large visual changes happening right before our eyes and illustrates the
fact that we see much less than we think we do. We introduce a fully automated
model to predict colour change blindness in cartoon images based on two
low-level image features and observer experience. Using linear regression with
only three parameters, the predictions of the proposed model correlate
significantly with measured detection times. We also demonstrate the efficacy
of the model to classify stimuli in terms of difficulty.",http://arxiv.org/abs/1909.04147v1
Detecting Changes in Hidden Markov Models,2019-01-24T14:41:14Z,George V. Moustakides,"We consider the problem of sequential detection of a change in the
statistical behavior of a hidden Markov model. By adopting a worst-case
analysis with respect to the time of change and by taking into account the data
that can be accessed by the change-imposing mechanism we offer alternative
formulations of the problem. For each formulation we derive the optimum
Shewhart test that maximizes the worst-case detection probability while
guaranteeing infrequent false alarms.",http://arxiv.org/abs/1901.08434v2
"Convergence of U-Processes in Hölder Spaces with Application to Robust
  Detection of a Changed Segment",2019-08-27T18:36:30Z,"Alfredas Račkauskas, Martin Wendler","To detect a changed segment (so called epidemic changes) in a time series,
variants of the CUSUM statistic are frequently used. However, they are
sensitive to outliers in the data and do not perform well for heavy tailed
data, especially when short segments get a high weight in the test statistic.
We will present a robust test statistic for epidemic changes based on the
Wilcoxon statistic. To study their asymptotic behavior, we prove functional
limit theorems for U-processes in H\""older spaces. We also study the finite
sample behavior via simulations and apply the statistic to a real data example.",http://arxiv.org/abs/1908.10401v2
"Using Artificial Intelligence to Recapture Norms: Did #metoo change
  gender norms in Sweden?",2019-03-02T12:12:45Z,Sara Moricz,"Norms are challenging to define and measure, but this paper takes advantage
of text data and the recent development in machine learning to create an
encompassing measure of norms. An LSTM neural network is trained to detect
gendered language. The network functions as a tool to create a measure on how
gender norms changes in relation to the Metoo movement on Swedish Twitter. This
paper shows that gender norms on average are less salient half a year after the
date of the first appearance of the hashtag #Metoo. Previous literature
suggests that gender norms change over generations, but the current result
suggests that norms can change in the short run.",http://arxiv.org/abs/1903.00690v1
"Change Point Detection in the Mean of High-Dimensional Time Series Data
  under Dependence",2019-03-17T00:06:18Z,"Jun Li, Minya Xu, Ping-Shou Zhong, Lingjun Li","High-dimensional time series are characterized by a large number of
measurements and complex dependence, and often involve abrupt change points. We
propose a new procedure to detect change points in the mean of high-dimensional
time series data. The proposed procedure incorporates spatial and temporal
dependence of data and is able to test and estimate the change point occurred
on the boundary of time series. We study its asymptotic properties under mild
conditions. Simulation studies demonstrate its robust performance through the
comparison with other existing methods. Our procedure is applied to an fMRI
dataset.",http://arxiv.org/abs/1903.07006v1
"Feature Augmentation Improves Anomalous Change Detection for Human
  Activity Identification in Synthetic Aperture Radar Imagery",2019-12-07T17:54:18Z,"Hannah J. Murphy, Christopher X. Ren, Matthew T. Calef","Anomalous change detection (ACD) methods separate common, uninteresting
changes from rare, significant changes in co-registered images collected at
different points in time. In this paper we evaluate methods to improve the
performance of ACD in detecting human activity in SAR imagery using outdoor
music festivals as a target. Our results show that the low dimensionality of
SAR data leads to poor performance of ACD when compared to simpler methods such
as image differencing, but augmenting the dimensionality of our input feature
space by incorporating local spatial information leads to enhanced performance.",http://arxiv.org/abs/1912.03539v2
"The Systems Approach to Change and the Agile Software Development
  Context",2019-04-04T10:40:40Z,Lucas Gren,"There is a diversity of models explaining organizational culture and how
these complex aspects can be addressed in connection to organizational change
efforts. This workshop paper claims that models already exist for dealing with
the cultural change that an agile transition is in the software engineering
context. Instead of realizing this again through agile success stories, and
thus reinventing the wheel, it is argued that the research in the software
engineering field should build on these models instead and investigate how/if
they differ. Practitioners already work as the change agents described in other
fields and they should get recognition through the presence and integration of
these models in the software engineering process research.",http://arxiv.org/abs/1904.02465v1
"Time-Out: Temporal Referencing for Robust Modeling of Lexical Semantic
  Change",2019-06-04T19:19:46Z,"Haim Dubossarsky, Simon Hengchen, Nina Tahmasebi, Dominik Schlechtweg","State-of-the-art models of lexical semantic change detection suffer from
noise stemming from vector space alignment. We have empirically tested the
Temporal Referencing method for lexical semantic change and show that, by
avoiding alignment, it is less affected by this noise. We show that, trained on
a diachronic corpus, the skip-gram with negative sampling architecture with
temporal referencing outperforms alignment models on a synthetic task as well
as a manual testset. We introduce a principled way to simulate lexical semantic
change and systematically control for possible biases.",http://arxiv.org/abs/1906.01688v1
"Genetic Random Weight Change Algorithm for the Learning of Multilayer
  Neural Networks",2019-06-05T09:08:58Z,"Mohammad Ibraim Sarker, Yali Nie, Hong Yongki, Hyongsuk Kim","A new method to improve the performance of Random weight change (RWC)
algorithm based on a simple genetic algorithm, namely, Genetic random weight
change (GRWC) is proposed. It is to find the optimal values of global minima
via learning. In contrast to Random Weight Change (RWC), GRWC contains an
effective optimization procedure which are good at exploring a large and
complex space in an intellectual strategies influenced by the GA/RWC synergy.
By implementing our simple GA in RWC we achieve an astounding accuracy of
finding global minima.",http://arxiv.org/abs/1906.01892v1
Alteration of helical vortex core without change in flow topology,2019-06-14T20:25:55Z,"Clara M. Velte, Valery L. Okulov, Martin O. L. Hansen","The abrupt expansion of the slender vortex core with changes in flow topology
is commonly known as vortex breakdown. We present new experimental observations
of an alteration of the helical vortex core in wall bounded turbulent flow with
abrupt growth in core size, but without change in flow topology. The helical
symmetry as such is preserved, though the characteristic parameters of helical
symmetry of the vortex core transfer from a smooth linear variation to a
different trend under the influence of a non-uniform pressure gradient, causing
an increase in helical pitch without changing its sign.",http://arxiv.org/abs/1906.06391v1
Time-changed \levy processes and option pricing: a critical comment,2019-06-29T05:29:57Z,"Hasan Fallahgoul, Kihun Nam","Carr and Wu (2004), henceforth CW, developed a framework that encompasses
almost all of the continuous-time models proposed in the option pricing
literature. Their framework hinges on the stopping time property of the time
changes. By analyzing the measurability of the time changes with respect to the
underlying filtration, we show that all models CW proposed for the time changes
fail to satisfy this assumption.",http://arxiv.org/abs/1907.00149v1
"Optimal Sequential Tests for Monitoring Changes in the Distribution of
  Finite Observation Sequences",2019-07-31T11:23:40Z,"Dong Han, Fugee Tsung, Jinguo Xian","This article develops a method to construct the optimal sequential test for
monitoring the changes in the distribution of finite observation sequences with
a general dependence structure. This method allows us to prove that different
optimal sequential tests can be constructed for different performance measures
of detection delay times. We also provide a formula to calculate the value of
the generalized out-of-control average run length for every optimal sequential
test. Moreover, we show that there is an equivalent optimal control limit which
does not depend on the test statistic directly when the post-change conditional
densities (probabilities) of the observation sequences do not depend on the
change time.",http://arxiv.org/abs/1907.13421v1
"Investigating conformation changes and network formation of mucin in
  joints functioning in human locomotion",2019-11-21T10:17:44Z,"Natalia Kruszewska, Piotr Bełdowski, Krzysztof Domino, Kanika D Lambert","Many different processes take place to facilitate lubrication of the joints
functioning in human locomotion system. The main purpose of this is to avoid
destroying the articular cartilage. Viscoelastic properties of the joints
system are very sensitive on both temperature and concentration changes because
of the change in conformation presented in the system proteins and protein
network formation. We are searching for an answer to the question on how
changes in temperature and concentration influence the conformational entropy
of mucin protein which is a part of one of the key components, lubricin, which
is believed to be responsible for gel formation inside synovial fluid. We are
using molecular dynamic technique to obtain the information about dihedral
(phi, psi) angles of the mucin during protein self - assembly by means of the
computer simulation with a time duration up to 50 ns, parameterized by six
temperatures ranged between 300 - 315 K, and six concentrations 10.68 - 267.1
g/L. The results show that between c3 and c4 (160 g/L and 214 g/L) a transition
exists where crowding begins affecting the dynamics of protein network
formation. In such a concentration ranges mucin has a chance to change the
frictional properties of the system. Simultaneously there were no significant
changes in conformations of the mucins molecules even after they created
networks. The temperature changes also did not affect much of mucins
conformations but it introduced slightly modifications in dihedral angles and
after some critical value T=306 K it changed conformational entropy trend from
decreasing to raising.",http://arxiv.org/abs/1911.09383v1
On ultrametric $1$-median selection,2019-09-05T13:34:45Z,Ching-Lueh Chang,"Consider the problem of finding a point in an ultrametric space with the
minimum average distance to all points. We give this problem a Monte Carlo
$O((\log^2(1/\epsilon))/\epsilon^3)$-time $(1+\epsilon)$-approximation
algorithm for all $\epsilon>0$.",http://arxiv.org/abs/1909.02400v1
"Tracing the AGN/X-ray Binary Analogy with Light Curves of Individual
  Changing-Look AGN",2019-09-10T18:00:03Z,"John J. Ruan, Scott F. Anderson, Michael Eracleous, Paul J. Green, Daryl Haggard, Chelsea L. MacLeod, Jessie C. Runnoe, Malgosia A. Sobolewska","Physical models of X-ray binary outbursts can aid in understanding the origin
of 'changing-look' active galactic nuclei (AGN), if we can establish that these
two black hole accretion phenomena are analogous. Previously, studies of the
correlation between the UV-to-X-ray spectral index alpha_OX and Eddington ratio
using single-epoch observations of changing-look AGN samples have revealed
possible similarities to the spectral evolution of outbursting X-ray binaries.
However, direct comparisons using multi-epoch UV/X-ray light curves of
individual changing-look AGN undergoing dramatic changes in Eddington ratio
have been scarce. Here, we use published Swift UV/X-ray light curves of two
changing-look AGN (NGC 2617 and ZTF18aajupnt) to examine the evolution of their
alpha_OX values during outburst. We show that the combination of these two
changing-look AGN can trace out the predicted spectral evolution from X-ray
binary outbursts, including the inversion in the evolution of alpha_OX as a
function of Eddington ratio. We suggest that the spectral softening that is
observed to occur below a critical Eddington ratio in both AGN and X-ray
binaries is due to reprocessing of Comptonized X-ray emission by the accretion
disk, based on the X-ray to UV reverberation lags previously observed in NGC
2617. Our results suggest that the physical processes causing the changing-look
AGN phenomenon are similar to those in X-ray binary outbursts.",http://arxiv.org/abs/1909.04676v2
Structural Change Analysis of Active Cryptocurrency Market,2019-09-24T02:02:24Z,"C. Y. Tan, Y. B. Koh, K. H. Ng, K. H. Ng",Structural Change Analysis of Active Cryptocurrency Market,http://arxiv.org/abs/1909.10679v1
Change Detection with Sparse Signals using Quantum Designs,2019-01-24T11:16:34Z,"Aditi Jain, Pradeep Sarvepalli, Srikrishna Bhashyam, Arun Pachai Kannu","We consider the change detection problem where the pre-change observation
vectors are purely noise and the post-change observation vectors are
noise-corrupted compressive measurements of sparse signals with a common
support, measured using a sensing matrix. In general, post-change distribution
of the observations depends on parameters such as the support and variances of
the sparse signal. When these parameters are unknown, we propose two
approaches. In the first approach, we approximate the post-change pdf based on
the known parameters such as mutual coherence of the sensing matrix and bounds
on the signal variances. In the second approach, we parameterize the
post-change pdf with an unknown parameter and try to adaptively estimate this
parameter using a stochastic gradient descent method. In both these approaches,
we employ CUSUM algorithm with various decision statistics such as the energy
of the observations, correlation values with columns of the sensing matrix and
the maximum value of such correlations. We study the performance of these
approaches and offer insights on the relevance of different decision statistics
in different SNR regimes. We also address the problem of designing sensing
matrices with small coherence by using designs from quantum information theory.
One such design, called SIC POVM, also has an additional structure which allows
exact computation of the post-change pdfs of some decision statistics even when
the support set of the sparse signal is unknown. We apply our detection
algorithms with SIC POVM based sequences to a massive random access problem and
show their superior performance over conventional Gold codes.",http://arxiv.org/abs/1901.08352v1
"Magnifier: A Compositional Analysis Approach for Autonomous Traffic
  Control",2019-04-20T06:48:33Z,"Maryam Bagheri, Marjan Sirjani, Ehsan Khamespanah, Christel Baier, Ali Movaghar","Autonomous traffic control systems are large-scale systems with critical
goals. Due to the dynamic nature of the surrounding world of these systems,
assuring the satisfaction of their properties at runtime and in the presence of
a change is important. A prominent approach to assure the correct behavior of
these systems is verification at runtime, which has strict time and memory
limitations. To tackle these limitations, we propose Magnifier, an iterative,
incremental, and compositional verification approach that operates on a
component-based model. The Magnifier idea is zooming on the component affected
by a change, verifying the correctness of properties of interest of the system
after adapting the component to the change, and then zooming out and tracing
the change if it propagates. If the change propagates, all components affected
by the change are adapted and are composed to form a new component. Magnifier
repeats the same process for the new component. This iterative process
terminates whenever the propagation of the change stops. In Magnifier, we use
the Coordinated Adaptive Actor model (CoodAA) of traffic control systems. We
present a formal semantics for CoodAA as a network of Timed Input-Output
Automata (TIOAs). The change does not propagate if TIOAs of the adapted
component and its environment are compatible. We implement our approach in
Ptolemy II. The results of our experiments indicate that the proposed approach
improves the verification time and the memory consumption compared to a
non-compositional approach.",http://arxiv.org/abs/1905.06732v3
"Reversible Electrochemical Phase Change in Monolayer to Bulk MoTe2 by
  Ionic Liquid Gating",2019-05-29T21:39:27Z,"Dante Zakhidov, Daniel A. Rehn, Evan J. Reed, Alberto Salleo","Transition metal dichalcogenides (TMDs) exist in various crystal structures
with semiconducting, semi-metallic, and metallic properties. The dynamic
control of these phases is of immediate interest for next generation
electronics such as phase change memories. Of the binary Mo and W-based TMDs,
MoTe2 is attractive for electronic applications because it has the lowest
energy difference (40 meV) between the semiconducting (2H) and semi-metallic
(1T') phases, allowing for MoTe2 phase change by electrostatic doping. Here we
report phase change between the 2H and 1T' polymorphs of MoTe2 in thicknesses
ranging from the monolayer case to effective bulk (73nm) using an ionic liquid
electrolyte at room temperature and in air. We find consistent evidence of a
partially reversible 2H-1T' transition using in-situ Raman spectroscopy where
the phase change occurs in the top-most layers of the MoTe2 flake. We find a
thickness-dependent transition voltage where higher voltages are necessary to
drive the phase change for thicker flakes. We also show evidence of
electrochemical activity during the gating process by observation of Te metal
deposition. This finding suggests the formation of Te vacancies which have been
reported to lower the energy difference between the 2H and 1T' phase,
potentially aiding the phase change process. Our discovery that the phase
change can be achieved on the surface layer of bulk materials reveals that this
electrochemical mechanism does not require isolation of a single layer and the
effect may be more broadly applicable than previously thought.",http://arxiv.org/abs/1905.12746v1
"Rarely-switching linear bandits: optimization of causal effects for the
  real world",2019-05-30T15:52:51Z,"Benjamin Lansdell, Sofia Triantafillou, Konrad Kording","Excessively changing policies in many real world scenarios is difficult,
unethical, or expensive. After all, doctor guidelines, tax codes, and price
lists can only be reprinted so often. We may thus want to only change a policy
when it is probable that the change is beneficial. In cases that a policy is a
threshold on contextual variables we can estimate treatment effects for
populations lying at the threshold. This allows for a schedule of incremental
policy updates that let us optimize a policy while making few detrimental
changes. Using this idea, and the theory of linear contextual bandits, we
present a conservative policy updating procedure which updates a deterministic
policy only when justified. We extend the theory of linear bandits to this
rarely-switching case, proving that such procedures share the same regret, up
to constant scaling, as the common LinUCB algorithm. However the algorithm
makes far fewer changes to its policy and, of those changes, fewer are
detrimental. We provide simulations and an analysis of an infant health
well-being causal inference dataset, showing the algorithm efficiently learns a
good policy with few changes. Our approach allows efficiently solving problems
where changes are to be avoided, with potential applications in medicine,
economics and beyond.",http://arxiv.org/abs/1905.13121v2
"Adjoining only the things you want: a survey of Strong Chang's
  Conjecture and related topics",2019-08-14T20:18:45Z,Sean Cox,"We survey some old and new results on strong variants of Chang's Conjecture
and related topics.",http://arxiv.org/abs/1908.05334v3
When very slow is too fast -- collapse of a predator-prey system,2019-08-15T12:18:46Z,"Anna Vanselow, Sebastian Wieczorek, Ulrike Feudel","Critical transitions or regime shifts are sudden and unexpected changes in
the state of an ecosystem, that are usually associated with dangerous levels of
environmental change. However, recent studies show that critical transitions
can also be triggered by dangerous rates of environmental change. In contrast
to classical regime shifts, such rate-induced critical transitions do not
involve any obvious loss of stability, or a bifurcation, and thus cannot be
explained by the linear stability analysis. In this work, we demonstrate that
the well-known Rosenzweig-MacArthur predator-prey model can undergo a
rate-induced critical transition in response to a continuous decline in the
habitat quality, resulting in a collapse of the predator and prey populations.
Rather surprisingly, the collapse occurs even if the environmental change is
slower than the slowest process in the model. To explain this counterintuitive
phenomenon, we combine methods from geometric singular perturbation theory with
the concept of a moving equilibrium, and study critical rates of environmental
change with dependence on the initial state and the system parameters.
Moreover, for a fixed rate of environmental change, we determine the set of
initial states that undergo a rate-induced population collapse. Our results
suggest that ecosystems may be more sensitive to how fast environmental
conditions change than previously assumed. In particular, unexpected critical
transitions with dramatic ecological consequences can be triggered by
environmental changes that (i) do not exceed any dangerous levels, and (ii) are
slower than the natural timescales of the ecosystem. This poses an interesting
research question whether regime shifts observed in the natural world are
predominantly rate-induced or bifurcation-induced.",http://arxiv.org/abs/1908.05507v1
Some algorithms for the mean curvature flow under topological changes,2019-08-26T14:00:35Z,"Arthur Bousquet, Yukun Li, Guanqian Wang","This paper considers and proposes some algorithms to compute the mean
curvature flow under topological changes. Instead of solving the fully
nonlinear partial differential equations based on the level set approach, we
propose some minimization algorithms based on the phase field approach. It is
well known that zero-level set of the Allen-Cahn equation approaches the mean
curvature flow before the onset of the topological changes; however, there are
few papers systematically studying the evolution of the mean curvature flow
under the topological changes. There are three main contributions of this
paper. First, in order to consider various random initial conditions, we design
several benchmark problems with topological changes, and we find different
patterns of the evolutions of the solutions can be obtained if the interaction
length (width of the interface) is slightly changed, which is different from
the problems without topological changes. Second, we propose an energy
penalized minimization algorithm which works very well for these benchmark
problems, and thus furthermore, for the problems with random initial
conditions. Third, we propose a multilevel minimization algorithm. This
algorithm is shown to be more tolerant of the unsatisfying initial guess when
there are and there are no topological changes in the evolutions of the
solutions.",http://arxiv.org/abs/1908.09690v2
The first high-redshift changing-look quasars,2019-12-11T13:52:33Z,"Nicholas P. Ross, Matthew J. Graham, Giorgio Calderone, K. E. Saavik Ford, Barry McKernan, Daniel Stern","We report on three redshift $z>2$ quasars with dramatic changes in their C IV
emission lines, the first sample of changing-look quasars (CLQs) at high
redshift. This is also the first time the changing-look behaviour has been seen
in a high-ionisation emission line. SDSS J1205+3422, J1638+2827, and J2228+2201
show interesting behaviour in their observed optical light curves, and
subsequent spectroscopy shows significant changes in the C IV broad emission
line, with both line collapse and emergence being displayed on rest-frame
timescales of $\sim$240-1640 days. These are rapid changes, especially when
considering virial black hole mass estimates of $M_{\rm BH} > 10^{9} M_{\odot}$
for all three quasars. Continuum and emission line measurements from the three
quasars show changes in the continuum-equivalent width plane with the CLQs seen
to be on the edge of the full population distribution, and showing indications
of an intrinsic Baldwin effect. We put these observations in context with
recent state-change models, and note that even in their observed low-state, the
C IV CLQs are generally above $\sim$5\% in Eddington luminosity.",http://arxiv.org/abs/1912.05310v1
"A robust bootstrap change point test for high-dimensional location
  parameter",2019-04-06T06:16:01Z,"Mengjia Yu, Xiaohui Chen","We consider the problem of change point detection for high-dimensional
distributions in a location family when the dimension can be much larger than
the sample size. In change point analysis, the widely used cumulative sum
(CUSUM) statistics are sensitive to outliers and heavy-tailed distributions. In
this paper, we propose a robust, tuning-free (i.e., fully data-dependent), and
easy-to-implement change point test that enjoys strong theoretical guarantees.
To achieve the robust purpose in a nonparametric setting, we formulate the
change point detection in the multivariate $U$-statistics framework with
anti-symmetric and nonlinear kernels. Specifically, the within-sample noise is
canceled out by anti-symmetry of the kernel, while the signal distortion under
certain nonlinear kernels can be controlled such that the between-sample change
point signal is magnitude preserving. A (half) jackknife multiplier bootstrap
(JMB) tailored to the change point detection setting is proposed to calibrate
the distribution of our $\ell^{\infty}$-norm aggregated test statistic. Subject
to mild moment conditions on kernels, we derive the uniform rates of
convergence for the JMB to approximate the sampling distribution of the test
statistic, and analyze its size and power properties. Extensions to multiple
change point testing and estimation are discussed with illustration from
numerical studies.",http://arxiv.org/abs/1904.03372v3
"A Composite Likelihood-based Approach for Change-point Detection in
  Spatio-temporal Processes",2019-04-12T17:43:06Z,"Zifeng Zhao, Ting Fung Ma, Wai Leong Ng, Chun Yip Yau","This paper develops a unified and computationally efficient method for
change-point estimation along the time dimension in a non-stationary
spatio-temporal process. By modeling a non-stationary spatio-temporal process
as a piecewise stationary spatio-temporal process, we consider simultaneous
estimation of the number and locations of change-points, and model parameters
in each segment. A composite likelihood-based criterion is developed for
change-point and parameters estimation. Under the framework of increasing
domain asymptotics, theoretical results including consistency and distribution
of the estimators are derived under mild conditions. In contrast to classical
results in fixed dimensional time series that the localization error of
change-point estimator is $O_{p}(1)$, exact recovery of true change-points can
be achieved in the spatio-temporal setting. More surprisingly, the consistency
of change-point estimation can be achieved without any penalty term in the
criterion function. In addition, we further establish consistency of the number
and locations of the change-point estimator under the infill asymptotics
framework where the time domain is increasing while the spatial sampling domain
is fixed. A computationally efficient pruned dynamic programming algorithm is
developed for the challenging criterion optimization problem. Extensive
simulation studies and an application to U.S. precipitation data are provided
to demonstrate the effectiveness and practicality of the proposed method.",http://arxiv.org/abs/1904.06340v3
The change of variable formula for the Riemann integral,2019-04-14T14:22:19Z,Alberto Torchinsky,"This note concerns the general formulation by Preiss and Uher of Kestelman's
influential result pertaining the change of variable, or substitution, formula
for the Riemann integral.",http://arxiv.org/abs/1904.07446v1
The change of variable formula for Riemann-Stieltjes integrals,2019-04-14T14:27:36Z,Alberto Torchinsky,"We consider general formulations of the change of variable formula for the
Riemann-Stieltjes integral, including the case when the substitution is not
invertible.",http://arxiv.org/abs/1904.07447v1
"On the semisimple orbits of restricted Cartan type Lie algebras $W, S$
  and $H$",2019-06-12T12:20:08Z,"Hao Chang, Ke Ou","In this short note, we give a description of semisimple orbits in the
restricted Cartan type Lie algebras $W, S, H$.",http://arxiv.org/abs/1906.05080v2
Lepton (non-) unversality in (flavor changing) neutral current B decays,2019-07-03T02:56:13Z,Rodrigo Alonso,"The following proceedings contain a theory perspective on the flavor changing
neutral current anomalies reported by LHCb on the ratios $B\to K^{(*)}
\mu\mu/B\to K^{(*)} ee$",http://arxiv.org/abs/1907.01716v1
"Analyses of 'change scores' do not estimate causal effects in
  observational data",2019-07-05T10:42:38Z,"Peter W. G. Tennant, Kellyn F. Arnold, George T. H. Ellison, Mark S. Gilthorpe","Background: In longitudinal data, it is common to create 'change scores' by
subtracting measurements taken at baseline from those taken at follow-up, and
then to analyse the resulting 'change' as the outcome variable. In
observational data, this approach can produce misleading causal effect
estimates. The present article uses directed acyclic graphs (DAGs) and simple
simulations to provide an accessible explanation of why change scores do not
estimate causal effects in observational data.
  Methods: Data were simulated to match three general scenarios where the
variable representing measurements of the outcome at baseline was a 1)
competing exposure, 2) confounder, or 3) mediator for the total causal effect
of the exposure on the variable representing measurements of the outcome at
follow-up. Regression coefficients were compared between change-score analyses
and DAG-informed analyses.
  Results: Change-score analyses do not provide meaningful causal effect
estimates unless the variable representing measurements of the outcome at
baseline is a competing exposure, as in a randomised experiment. Where such
variables (i.e. baseline measurements of the outcome) are confounders or
mediators, the conclusions drawn from analyses of change scores diverge
(potentially substantially) from those of DAG-informed analyses.
  Conclusions: Future observational studies that seek causal effect estimates
should avoid analysing change scores and adopt alternative analytical
strategies.",http://arxiv.org/abs/1907.02764v1
ShapeBots: Shape-changing Swarm Robots,2019-09-08T02:34:59Z,"Ryo Suzuki, Clement Zheng, Yasuaki Kakehi, Tom Yeh, Ellen Yi-Luen Do, Mark D. Gross, Daniel Leithinger","We introduce shape-changing swarm robots. A swarm of self-transformable
robots can both individually and collectively change their configuration to
display information, actuate objects, act as tangible controllers, visualize
data, and provide physical affordances. ShapeBots is a concept prototype of
shape-changing swarm robots. Each robot can change its shape by leveraging
small linear actuators that are thin (2.5 cm) and highly extendable (up to
20cm) in both horizontal and vertical directions. The modular design of each
actuator enables various shapes and geometries of self-transformation. We
illustrate potential application scenarios and discuss how this type of
interface opens up possibilities for the future of ubiquitous and distributed
shape-changing interfaces.",http://arxiv.org/abs/1909.03372v1
Compound Sequential Change-point Detection in Parallel Data Streams,2019-09-12T18:48:21Z,"Yunxiao Chen, Xiaoou Li","We consider sequential change-point detection in parallel data streams, where
each stream has its own change point. Once a change is detected in a data
stream, this stream is deactivated permanently. The goal is to maximize the
normal operation of the pre-change streams, while controlling the proportion of
post-change streams among the active streams at all time points. Taking a
Bayesian formulation, we develop a compound decision framework for this
problem. A procedure is proposed that is uniformly optimal among all sequential
procedures which control the expected proportion of postchange streams at all
time points. We also investigate the asymptotic behavior of the proposed method
when the number of data streams grows large. Numerical examples are provided to
illustrate the use and performance of the proposed method.",http://arxiv.org/abs/1909.05903v2
"Building Change Detection for Remote Sensing Images Using a Dual Task
  Constrained Deep Siamese Convolutional Network Model",2019-09-17T11:34:19Z,"Yi Liu, Chao Pang, Zongqian Zhan, Xiaomeng Zhang, Xue Yang","In recent years, building change detection methods have made great progress
by introducing deep learning, but they still suffer from the problem of the
extracted features not being discriminative enough, resulting in incomplete
regions and irregular boundaries. To tackle this problem, we propose a dual
task constrained deep Siamese convolutional network (DTCDSCN) model, which
contains three sub-networks: a change detection network and two semantic
segmentation networks. DTCDSCN can accomplish both change detection and
semantic segmentation at the same time, which can help to learn more
discriminative object-level features and obtain a complete change detection
map. Furthermore, we introduce a dual attention module (DAM) to exploit the
interdependencies between channels and spatial positions, which improves the
feature representation. We also improve the focal loss function to suppress the
sample imbalance problem. The experimental results obtained with the WHU
building dataset show that the proposed method is effective for building change
detection and achieves a state-of-the-art performance in terms of four metrics:
precision, recall, F1-score, and intersection over union.",http://arxiv.org/abs/1909.07726v1
"Is change the only constant? Profile change perspective on
  #LokSabhaElections2019",2019-09-22T14:17:50Z,"Kumari Neha, Shashank Srikanth, Sonali Singhal, Shwetanshu Singh, Arun Balaji Buduru, Ponnurangam Kumaraguru","Users on Twitter are identified with the help of their profile attributes
that consists of username, display name, profile image, to name a few. The
profile attributes that users adopt can reflect their interests, belief, or
thematic inclinations. Literature has proposed the implications and
significance of profile attribute change for a random population of users.
However, the use of profile attribute for endorsements and to start a movement
have been under-explored. In this work, we consider #LokSabhaElections2019 as a
movement and perform a large-scale study of the profile of users who actively
made changes to profile attributes centered around #LokSabhaElections2019. We
collect the profile metadata for 49.4M users for a period of 2 months from
April 5, 2019 to June 5, 2019 amid #LokSabhaElections2019. We investigate how
the profile changes vary for the influential leaders and their followers over
the social movement. We further differentiate the organic and inorganic ways to
show the political inclination from the prism of profile changes. We report how
the addition of election campaign related keywords lead to spread of behavior
contagion and further investigate it with respect to ""Chowkidar Movement"" in
detail.",http://arxiv.org/abs/1909.10012v1
Kernel Change-point Detection with Auxiliary Deep Generative Models,2019-01-18T04:06:58Z,"Wei-Cheng Chang, Chun-Liang Li, Yiming Yang, Barnabás Póczos","Detecting the emergence of abrupt property changes in time series is a
challenging problem. Kernel two-sample test has been studied for this task
which makes fewer assumptions on the distributions than traditional parametric
approaches. However, selecting kernels is non-trivial in practice. Although
kernel selection for two-sample test has been studied, the insufficient samples
in change point detection problem hinder the success of those developed kernel
selection algorithms. In this paper, we propose KL-CPD, a novel kernel learning
framework for time series CPD that optimizes a lower bound of test power via an
auxiliary generative model. With deep kernel parameterization, KL-CPD endows
kernel two-sample test with the data-driven kernel to detect different types of
change-points in real-world applications. The proposed approach significantly
outperformed other state-of-the-art methods in our comparative evaluation of
benchmark datasets and simulation studies.",http://arxiv.org/abs/1901.06077v1
"Correcting the measured values of the rate of change of the spin and
  orbital periods of rotation powered pulsars",2019-05-02T16:43:19Z,"Dhruv Pathak, Manjari Bagchi","For rotation powered pulsars, the rate of change of the spin period is
expected to be positive. On the other hand, for a clean binary system (where
gravity is the only force acting on the pulsar) the rate of change of the
orbital period is expected to be negative. There are, however, some pulsars
with the measurements of the rate of change of the spin period as negative
quantities. Likewise, there are some pulsars with positive measurements of the
rate of change of the orbital period. We investigate these cases by eliminating
the external dynamical effects. We also look at those cases where at first, the
measured values possess the correct sign, but on subtracting the dynamical
effects, the sign changes. We use `GalDynPsr' package to perform these tasks.
Moreover, we investigate possible reasons for such anomalies.",http://arxiv.org/abs/1905.01159v1
"On the Behaviour of Differential Evolution for Problems with Dynamic
  Linear Constraints",2019-02-27T03:46:14Z,"Maryam Hasani-Shoreh, María-Yaneli Ameca-Alducin, Wilson Blaikie, Frank Neumann, Marc Schoenauer","Evolutionary algorithms have been widely applied for solving dynamic
constrained optimization problems (DCOPs) as a common area of research in
evolutionary optimization. Current benchmarks proposed for testing these
problems in the continuous spaces are either not scalable in problem dimension
or the settings for the environmental changes are not flexible. Moreover, they
mainly focus on non-linear environmental changes on the objective function.
While the dynamism in some real-world problems exists in the constraints and
can be emulated with linear constraint changes. The purpose of this paper is to
introduce a framework which produces benchmarks in which a dynamic environment
is created with simple changes in linear constraints (rotation and translation
of constraint's hyperplane). Our proposed framework creates dynamic benchmarks
that are flexible in terms of number of changes, dimension of the problem and
can be applied to test any objective function. Different constraint handling
techniques will then be used to compare with our benchmark. The results reveal
that with these changes set, there was an observable effect on the performance
of the constraint handling techniques.",http://arxiv.org/abs/1905.04099v3
Compliance Change Tracking in Business Process Services,2019-08-20T06:49:06Z,"Srikanth G Tamilselvam, Ankush Gupta, Arvind Agarwal","Regulatory compliance is an organization's adherence to laws, regulations,
guidelines and specifications relevant to its business. Compliance officers
responsible for maintaining adherence constantly struggle to keep up with the
large amount of changes in regulatory requirements. Keeping up with the changes
entail two main tasks: fetching the regulatory announcements that actually
contain changes of interest, and incorporating those changes in the business
process. In this paper we focus on the first task, and present a Compliance
Change Tracking System, that gathers regulatory announcements from government
sites, news sites, email subscriptions; classifies their importance i.e
Actionability through a hierarchical classifier, and business process
applicability through a multi-class classifier. For these classifiers, we
experiment with several approaches such as vanilla classification methods (e.g.
Naive Bayes, logistic regression etc.), hierarchical classification methods,
rule based approach, hybrid approach with various preprocessing and feature
selection methods; and show that despite the richness of other models, a simple
hierarchical classification with bag-of-words features works the best for
Actionability classifier and multi-class logistic regression works the best for
Applicability classifier. The system has been deployed in global delivery
centers, and has received positive feedback from payroll compliance officers.",http://arxiv.org/abs/1908.07190v1
An Improved Historical Embedding without Alignment,2019-10-19T03:32:16Z,"Xiaofei Xu, Ke Deng, Fei Hu, Li Li","Many words have evolved in meaning as a result of cultural and social change.
Understanding such changes is crucial for modelling language and cultural
evolution. Low-dimensional embedding methods have shown promise in detecting
words' meaning change by encoding them into dense vectors. However, when
exploring semantic change of words over time, these methods require the
alignment of word embeddings across different time periods. This process is
computationally expensive, prohibitively time consuming and suffering from
contextual variability. In this paper, we propose a new and scalable method for
encoding words from different time periods into one dense vector space. This
can greatly improve performance when it comes to identifying words that have
changed in meaning over time. We evaluated our method on dataset from Google
Books N-gram. Our method outperformed three other popular methods in terms of
the number of words correctly identified to have changed in meaning.
Additionally, we provide an intuitive visualization of the semantic evolution
of some words extracted by our method",http://arxiv.org/abs/1910.08692v1
"Indigenous use of stellar scintillation to predict weather and seasonal
  change",2019-03-04T03:44:22Z,"Duane W. Hamacher, John Barsa, Segar Passi, Alo Tapim","Indigenous peoples across the world observe the motions and positions of
stars to develop seasonal calendars. Additionally, changing properties of
stars, such as their brightness and colour, are also used for predicting
weather. Combining archival studies with ethnographic fieldwork in Australia's
Torres Strait, we explore the various ways Indigenous peoples utilise stellar
scintillation (twinkling) as an indicator for predicting weather and seasonal
change, discussing the scientific underpinnings of this knowledge. By observing
subtle changes in the ways the stars twinkle, Meriam people gauge changing
trade winds, approaching wet weather, and temperature changes. We then explore
how the Northern Dene of Arctic North America utilise stellar scintillation to
forecast weather.",http://arxiv.org/abs/1903.01060v1
Utility maximisation and time-change,2019-12-06T16:09:46Z,"Giulia Di Nunno, Hannes Haferkorn, Asma Khedher, Michèle Vanmaele","We consider the problem of maximising expected utility from terminal wealth
in a semimartingale setting, where the semimartingale is written as a sum of a
time-changed Brownian motion and a finite variation process. To solve this
problem, we consider an initial enlargement of filtration and we derive change
of variable formulas for stochastic integrals w.r.t. a time-changed Brownian
motion. The change of variable formulas allow us to shift the problem to a
maximisation problem under the enlarged filtration for models driven by a
Brownian motion and a finite variation process. The latter could be solved by
using martingale methods. Then applying again the change of variable formula,
we derive the optimal strategy for the original problem for a power utility
under certain assumptions on the finite variation process of the
semimartingale.",http://arxiv.org/abs/1912.03202v2
"Multiple Change Point Detection and Validation in Autoregressive Time
  Series Data",2019-12-17T01:16:48Z,"Lijing Ma, Andrew Grant, Georgy Sofronov","It is quite common that the structure of a time series changes abruptly.
Identifying these change points and describing the model structure in the
segments between these change points is of interest. In this paper, time series
data is modelled assuming each segment is an autoregressive time series with
possibly different autoregressive parameters. This is achieved using two main
steps. The first step is to use a likelihood ratio scan based estimation
technique to identify these potential change points to segment the time series.
Once these potential change points are identified, modified parametric spectral
discrimination tests are used to validate the proposed segments. A numerical
study is conducted to demonstrate the performance of the proposed method across
various scenarios and compared against other contemporary techniques.",http://arxiv.org/abs/1912.07775v1
"Multidimensional molecular changes-environment interaction analysis for
  disease outcomes",2019-12-18T03:54:47Z,"Yaqing Xu, Mengyun Wu, Shuangge Ma","For the outcomes and phenotypes of complex diseases, multiple types of
molecular (genetic, genomic, epigenetic, etc.) changes, environmental risk
factors, and their interactions have been found to have important
contributions. In each of the existing studies, only the interactions between
one type of molecular changes and environmental risk factors have been
analyzed. In recent biomedical studies, multidimensional profiling, under which
data on multiple types of molecular changes is collected on the same subjects,
is becoming popular. A myriad of recent studies have shown that collectively
analyzing multiple types of molecular changes is not only biologically sensible
but also leads to improved estimation and prediction. In this study, we conduct
M-E interaction analysis, with M standing for multidimensional molecular
changes and E standing for environmental risk factors, which can accommodate
multiple types of molecular measurements and sufficiently account for their
overlapping information (attributable to regulations) as well as independent
information. The proposed approach is based on the penalization technique, has
a solid statistical ground, and can be effectively realized. Extensive
simulation shows that it outperforms multiple closely relevant alternatives. In
the analysis of TCGA (The Cancer Genome Atlas) data on lung adenocarcinoma and
cutaneous melanoma, sensible findings with superior stability and prediction
are made.",http://arxiv.org/abs/1912.08370v1
Quantifying the Trendiness of Trends,2019-12-26T12:05:03Z,"Andreas Kryger Jensen, Claus Thorn Ekstrøm","News media often report that the trend of some public health outcome has
changed. These statements are frequently based on longitudinal data, and the
change in trend is typically found to have occurred at the most recent data
collection time point - if no change had occurred the story is less likely to
be reported. Such claims may potentially influence public health decisions on a
national level.
  We propose two measures for quantifying the trendiness of trends. Assuming
that reality evolves in continuous time we define what constitutes a trend and
a change in trend, and introduce a probabilistic Trend Direction Index. This
index has the interpretation of the probability that a latent characteristic
has changed monotonicity at any given time conditional on observed data. We
also define an index of Expected Trend Instability quantifying the expected
number of changes in trend on an interval.
  Using a latent Gaussian Process model we show how the Trend Direction Index
and the Expected Trend Instability can be estimated in a Bayesian framework and
use the methods to analyze the proportion of smokers in Denmark during the last
20 years, and the development of new COVID-19 cases in Italy from February 24th
onwards.",http://arxiv.org/abs/1912.11848v2
"A formulation of the relaxation phenomenon for lane changing dynamics in
  an arbitrary car following model",2019-04-17T17:52:18Z,"Ronan Keane, H. Oliver Gao","Lane changing dynamics are an important part of traffic microsimulation and
are vital for modeling weaving sections and merge bottlenecks. However, there
is often much more emphasis placed on car following and gap acceptance models,
whereas lane changing dynamics such as tactical, cooperation, and relaxation
models receive comparatively little attention. This paper develops a general
relaxation model which can be applied to an arbitrary parametric or
nonparametric microsimulation model. The relaxation model modifies car
following dynamics after a lane change, when vehicles can be far from
equilibrium. Relaxation prevents car following models from reacting too
strongly to the changes in space headway caused by lane changing, leading to
more accurate and realistic simulated trajectories. We also show that
relaxation is necessary for correctly simulating traffic breakdown with
realistic values of capacity drop.",http://arxiv.org/abs/1904.08395v3
"SkyMapper SEDs of nearby galaxies: quenching and bursting probed by a
  change index for star formation",2019-04-18T07:24:38Z,"Christian Wolf, Jacob Golding, Christopher A. Onken, Li Shao","The wish list of astronomers includes a tool that reveals quenching of star
formation in galaxies directly as it proceeds. Here, we present a
proof-of-concept for a new quenching-and-bursting diagnostic, a ""change index""
for star formation, that requires only photometric data, provided they include
filters such as the violet $uv$ bands used by SkyMapper. The index responds
mostly to changes in star-formation rate on a timescale of 20 to 500 Myr and is
nearly insensitive to dust extinction. It works effectively to distances of 100
to 150 Mpc. We explore its application to eight example galaxies in SkyMapper
DR2, including known E+A and Seyfert-1 galaxies. Owing to the degeneracies
inherent in broad-band photometry, the change index can only be a qualitative
indicator of changes in star-formation rate. But once the SkyMapper Southern
Survey is complete, the change index will be available for every spatial
resolution element of every galaxy in the Southern sky within its working
distance range.",http://arxiv.org/abs/1904.08612v1
"Change Point Estimation in Panel Data with Temporal and Cross-sectional
  Dependence",2019-04-25T00:03:07Z,"Monika Bhattacharjee, Moulinath Banerjee, George Michailidis","We study the problem of detecting a common change point in large panel data
based on a mean shift model, wherein the errors exhibit both temporal and
cross-sectional dependence. A least squares based procedure is used to estimate
the location of the change point. Further, we establish the convergence rate
and obtain the asymptotic distribution of the least squares estimator. The form
of the distribution is determined by the behavior of the norm difference of the
means before and after the change point. Since the behavior of this norm
difference is, a priori, unknown to the practitioner, we also develop a novel
data driven adaptive procedure that provides valid confidence intervals for the
common change point, without requiring any such knowledge. Numerical work based
on synthetic data illustrates the performance of the estimator in finite
samples under different settings of temporal and cross-sectional dependence,
sample size and number of panels. Finally, we examine an application to
financial stock data and discuss the identified change points.",http://arxiv.org/abs/1904.11101v1
"Discovering Common Change-Point Patterns in Functional Connectivity
  Across Subjects",2019-04-26T19:34:52Z,"Mengyu Dai, Zhengwu Zhang, Anuj Srivastava","This paper studies change-points in human brain functional connectivity (FC)
and seeks patterns that are common across multiple subjects under identical
external stimulus. FC relates to the similarity of fMRI responses across
different brain regions when the brain is simply resting or performing a task.
While the dynamic nature of FC is well accepted, this paper develops a formal
statistical test for finding {\it change-points} in times series associated
with FC. It represents short-term connectivity by a symmetric positive-definite
matrix, and uses a Riemannian metric on this space to develop a graphical
method for detecting change-points in a time series of such matrices. It also
provides a graphical representation of estimated FC for stationary subintervals
in between the detected change-points. Furthermore, it uses a temporal
alignment of the test statistic, viewed as a real-valued function over time, to
remove inter-subject variability and to discover common change-point patterns
across subjects. This method is illustrated using data from Human Connectome
Project (HCP) database for multiple subjects and tasks.",http://arxiv.org/abs/1904.12023v1
Online Graph-Based Change-Point Detection for High Dimensional Data,2019-06-07T10:40:45Z,"Yang-Wen Sun, Katerina Papagiannouli, Vladmir Spokoiny","Online change-point detection (OCPD) is important for application in various
areas such as finance, biology, and the Internet of Things (IoT). However, OCPD
faces major challenges due to high-dimensionality, and it is still rarely
studied in literature. In this paper, we propose a novel, online, graph-based,
change-point detection algorithm to detect change of distribution in low- to
high-dimensional data. We introduce a similarity measure, which is derived from
the graph-spanning ratio, to test statistically if a change occurs. Through
numerical study using artificial online datasets, our data-driven approach
demonstrates high detection power for high-dimensional data, while the false
alarm rate (type I error) is controlled at a nominal significant level. In
particular, our graph-spanning approach has desirable power with small and
multiple scanning window, which allows timely detection of change-point in the
online setting.",http://arxiv.org/abs/1906.03001v1
Recursive Style Breach Detection with Multifaceted Ensemble Learning,2019-06-17T09:33:30Z,"Daniel Kopev, Dimitrina Zlatkova, Kristiyan Mitov, Atanas Atanasov, Momchil Hardalov, Ivan Koychev, Preslav Nakov","We present a supervised approach for style change detection, which aims at
predicting whether there are changes in the style in a given text document, as
well as at finding the exact positions where such changes occur. In particular,
we combine a TF.IDF representation of the document with features specifically
engineered for the task, and we make predictions via an ensemble of diverse
classifiers including SVM, Random Forest, AdaBoost, MLP, and LightGBM. Whenever
the model detects that style change is present, we apply it recursively,
looking to find the specific positions of the change. Our approach powered the
winning system for the PAN@CLEF 2018 task on Style Change Detection.",http://arxiv.org/abs/1906.06917v1
"Alternating Pruned Dynamic Programming for Multiple Epidemic
  Change-Point Estimation",2019-07-16T02:30:10Z,"Zifeng Zhao, Chun Yip Yau","In this paper, we study the problem of multiple change-point detection for a
univariate sequence under the epidemic setting, where the behavior of the
sequence alternates between a common normal state and different epidemic
states. This is a non-trivial generalization of the classical (single) epidemic
change-point testing problem. To explicitly incorporate the alternating
structure of the problem, we propose a novel model selection based approach for
simultaneous inference on both change-points and alternating states. Using the
same spirit as profile likelihood, we develop a two-stage alternating pruned
dynamic programming algorithm, which conducts efficient and exact optimization
of the model selection criteria and has $O(n^2)$ as the worst case
computational cost. As demonstrated by extensive numerical experiments,
compared to classical general-purpose multiple change-point detection
procedures, the proposed method improves accuracy for both change-point
estimation and model parameter estimation. We further show promising
applications of the proposed algorithm to multiple testing with locally
clustered signals, and demonstrate its advantages over existing methods in
large scale multiple testing, in DNA copy number variation detection, and in
oceanographic study.",http://arxiv.org/abs/1907.06810v3
Factor Analysis for High-Dimensional Time Series with Change Point,2019-07-22T18:43:16Z,"Xialu Liu, Ting Zhang","We consider change-point latent factor models for high-dimensional time
series, where a structural break may exist in the underlying factor structure.
In particular, we propose consistent estimators for factor loading spaces
before and after the change point, and the problem of estimating the
change-point location is also considered. Compared with existing results on
change-point factor analysis of high-dimensional time series, a distinguished
feature of the current paper is that our results allow strong cross-sectional
dependence in the noise process. To accommodate the unknown degree of
cross-sectional dependence strength, we propose to use self-normalization to
pivotalize the change-point test statistic. Numerical experiments including a
Monte Carlo simulation study and a real data application are presented to
illustrate the proposed methods.",http://arxiv.org/abs/1907.09522v1
Phase-Change Control of Interlayer Exchange Coupling,2019-07-25T01:15:54Z,"Xiaofei Fan, Guodong Wei, Xiaoyang Lin, Xinhe Wang, Zhizhong Si, Xueying Zhang, Qiming Shao, Stephane Mangin, Eric Fullerton, Lei Jiang, Weisheng Zhao","Changing the interlayer exchange coupling between magnetic layers in-situ is
a key issue of spintronics, as it allows for the optimization of properties
that are desirable for applications, including magnetic sensing and memory. In
this paper, we utilize the phase change material VO2 as a spacer layer to
regulate the interlayer exchange coupling between ferromagnetic layers with
perpendicular magnetic anisotropy. The successful growth of ultra-thin (several
nanometres) VO2 films is realized by sputtering at room temperature, which
further enables the fabrication of [Pt/Co]2/VO2/[Co/Pt]2 multilayers with
distinct interfaces. Such a magnetic multilayer exhibits an evolution from
antiferromagnetic coupling to ferromagnetic coupling as the VO2 undergoes a
phase change. The underlying mechanism originates from the change in the
electronic structure of the spacer layer from an insulating to a metallic
state. As a demonstration of phase change spintronics, this work may reveal the
great potential of material innovations for next-generation spintronics.",http://arxiv.org/abs/1907.10784v2
VEDAR: Accountable Behavioural Change Detection,2019-02-04T09:59:10Z,"Amit Kumar, Tanya Ahuja, Rajesh Kumar Madabhattula, Murali Kante, Srinivasa Rao Aravilli","With exponential increase in the availability oftelemetry / streaming /
real-time data, understanding contextualbehavior changes is a vital
functionality in order to deliverunrivalled customer experience and build high
performance andhigh availability systems. Real-time behavior change
detectionfinds a use case in number of domains such as social networks,network
traffic monitoring, ad exchange metrics etc. In streamingdata, behavior change
is an implausible observation that does notfit in with the distribution of rest
of the data. A timely and preciserevelation of such behavior changes can give
us substantialinformation about the system in critical situations which can bea
driving factor for vital decisions. Detecting behavior changes instreaming
fashion is a difficult task as the system needs to processhigh speed real-time
data and continuously learn from data alongwith detecting anomalies in a single
pass of data. In this paperwe introduce a novel algorithm called Accountable
BehaviorChange Detection (VEDAR) which can detect and elucidate thebehavior
changes in real-time and operates in a fashion similarto human perception. We
have bench marked our algorithmon open source anomaly detection datasets. We
have benchmarked our algorithm by comparing its performance on opensource
anomaly datasets against industry standard algorithmslike Numenta HTM and
Twitter AdVec (SH-ESD). Our algorithmoutperforms above mentioned algorithms for
behaviour changedetection, efficacy is given in section V.",http://arxiv.org/abs/1902.06663v1
"An Approach and Benchmark to Detect Behavioral Changes of Commits in
  Continuous Integration",2019-02-22T13:19:36Z,"Benjamin Danglot, Martin Monperrus, Walter Rudametkin, Benoit Baudry","When a developer pushes a change to an application's codebase, a good
practice is to have a test case specifying this behavioral change. Thanks to
continuous integration (CI), the test is run on subsequent commits to check
that they do no introduce a regression for that behavior. In this paper, we
propose an approach that detects behavioral changes in commits. As input, it
takes a program, its test suite, and a commit. Its output is a set of test
methods that capture the behavioral difference between the pre-commit and
post-commit versions of the program. We call our approach DCI (Detecting
behavioral changes in CI). It works by generating variations of the existing
test cases through (i) assertion amplification and (ii) a search-based
exploration of the input space. We evaluate our approach on a curated set of 60
commits from 6 open source Java projects. To our knowledge, this is the first
ever curated dataset of real-world behavioral changes. Our evaluation shows
that DCI is able to generate test methods that detect behavioral changes. Our
approach is fully automated and can be integrated into current development
processes. The main limitations are that it targets unit tests and works on a
relatively small fraction of commits. More specifically, DCI works on commits
that have a unit test that already executes the modified code. In practice,
from our benchmark projects, we found 15.29% of commits to meet the conditions
required by DCI.",http://arxiv.org/abs/1902.08482v3
"Change point localization in dependent dynamic nonparametric random dot
  product graphs",2019-11-18T09:18:02Z,"Oscar Hernan Madrid Padilla, Yi Yu, Carey E. Priebe","In this paper, we study the offline change point localization problem in a
sequence of dependent nonparametric random dot product graphs. To be specific,
assume that at every time point, a network is generated from a nonparametric
random dot product graph model \citep[see e.g.][]{athreya2017statistical},
where the latent positions are generated from unknown underlying distributions.
The underlying distributions are piecewise constant in time and change at
unknown locations, called change points. Most importantly, we allow for
dependence among networks generated between two consecutive change points. This
setting incorporates edge-dependence within networks and temporal dependence
between networks, which is the most flexible setting in the published
literature.
  To accomplish the task of consistently localizing change points, we propose a
novel change point detection algorithm, consisting of two steps. First, we
estimate the latent positions of the random dot product model, our theoretical
result being a refined version of the state-of-the-art results, allowing the
dimension of the latent positions to diverge. Subsequently, we construct a
nonparametric version of the CUSUM statistic \citep[e.g.][]{Page1954,
padilla2019optimal} that allows for temporal dependence. Consistent
localization is proved theoretically and supported by extensive numerical
experiments, which illustrate state-of-the-art performance. We also provide in
depth discussion of possible extensions to give more understanding and
insights.",http://arxiv.org/abs/1911.07494v3
Towards Predicting the Impact of Software Changes on Building Activities,2019-01-22T01:35:30Z,"Michele Tufano, Hitesh Sajnani, Kim Herzig","The pervasive adoption of Continuous Integration practices -- both in
industry and open source projects -- has led software building to become a
daily activity for thousands of developers around the world. Companies such as
Microsoft have invested in in-house infrastructures with the goal of optimizing
the build process. CloudBuild, a distributed and caching build service
developed internally by Microsoft, runs the build process in parallel in the
cloud and relies on caching to accelerate builds. This allows for agile
development and rapid delivery of software even several times a day. However,
moving towards faster builds requires not only improvements on the
infrastructure side, but also attention to developers' changes in the software.
Surely, architectural decisions and software changes, such as addition of
dependencies, can lead to significant build time increase. Yet, estimating the
impact of such changes on build time can be challenging when dealing with
complex, distributed, and cached build systems. In this paper, we envision a
predictive model able to preemptively alert developers on the extent to which
their software changes may impact future building activities. In particular, we
describe an approach that analyzes the developer's change and predicts (i)
whether it impacts (any of) the Longest Critical Path; (ii) may lead to build
time increase and its delta; and (iii) the percentage of future builds that
might be affected by such change.",http://arxiv.org/abs/1901.07142v2
Multiple criteria decision-making for lane-change model,2019-10-22T17:58:39Z,"Ao Li, Liting Sun, Wei Zhan, Masayoshi Tomizuka","Simulation has long been an essential part of testing autonomous driving
systems, but only recently has simulation been useful for building and training
self-driving vehicles. Vehicle behavioural models are necessary to simulate the
interactions between robot cars. This paper proposed a new method to formalize
the lane-changing model in urban driving scenarios. We define human incentives
from different perspectives, speed incentive, route change incentive, comfort
incentive and courtesy incentive etc. We applied a decision-theoretical tool,
called Multi-Criteria Decision Making (MCDM) to take these incentive policies
into account. The strategy of combination is according to different driving
style which varies for each driving. Thus a lane-changing decision selection
algorithm is proposed. Not only our method allows for varying the motivation of
lane-changing from the purely egoistic desire to a more courtesy concern, but
also they can mimic drivers' state, inattentive or concentrate, which
influences their driving Behaviour. We define some cost functions and calibrate
the parameters with different scenarios of traffic data. Distinguishing driving
styles are used to aggregate decision-makers' assessments about various
criteria weightings to obtain the action drivers desire most. Our result
demonstrates the proposed method can produce varied lane-changing behaviour.
Unlike other lane-changing models based on artificial intelligence methods, our
model has more flexible controllability.",http://arxiv.org/abs/1910.10142v1
GASC: Genre-Aware Semantic Change for Ancient Greek,2019-03-13T17:32:51Z,"Valerio Perrone, Marco Palma, Simon Hengchen, Alessandro Vatri, Jim Q. Smith, Barbara McGillivray","Word meaning changes over time, depending on linguistic and extra-linguistic
factors. Associating a word's correct meaning in its historical context is a
central challenge in diachronic research, and is relevant to a range of NLP
tasks, including information retrieval and semantic search in historical texts.
Bayesian models for semantic change have emerged as a powerful tool to address
this challenge, providing explicit and interpretable representations of
semantic change phenomena. However, while corpora typically come with rich
metadata, existing models are limited by their inability to exploit contextual
information (such as text genre) beyond the document time-stamp. This is
particularly critical in the case of ancient languages, where lack of data and
long diachronic span make it harder to draw a clear distinction between
polysemy (the fact that a word has several senses) and semantic change (the
process of acquiring, losing, or changing senses), and current systems perform
poorly on these languages. We develop GASC, a dynamic semantic change model
that leverages categorical metadata about the texts' genre to boost inference
and uncover the evolution of meanings in Ancient Greek corpora. In a new
evaluation framework, our model achieves improved predictive performance
compared to the state of the art.",http://arxiv.org/abs/1903.05587v2
"Early Prediction for Merged vs Abandoned Code Changes in Modern Code
  Reviews",2019-12-07T04:38:48Z,"Md. Khairul Islam, Toufique Ahmed, Rifat Shahriyar, Anindya Iqbal, Gias Uddin","The modern code review process is an integral part of the current software
development practice. Considerable effort is given here to inspect code
changes, find defects, suggest an improvement, and address the suggestions of
the reviewers. In a code review process, usually, several iterations take place
where an author submits code changes and a reviewer gives feedback until is
happy to accept the change. In around 12% cases, the changes are abandoned,
eventually wasting all the efforts. In this research, our objective is to
design a tool that can predict whether a code change would be merged or
abandoned at an early stage to reduce the waste of efforts of all stakeholders
(e.g., program author, reviewer, project management, etc.) involved. The
real-world demand for such a tool was formally identified by a study by Fan et
al. [1]. We have mined 146,612 code changes from the code reviews of three
large and popular open-source software and trained and tested a suite of
supervised machine learning classifiers, both shallow and deep learning based.
We consider a total of 25 features in each code change during the training and
testing of the models. The best performing model named PredCR (Predicting Code
Review), a LightGBM-based classifier achieves around 85% AUC score on average
and relatively improves the state-of-the-art [1] by 14-23%. In our empirical
study on the 146,612 code changes from the three software projects, we find
that (1) The new features like reviewer dimensions that are introduced in
PredCR are the most informative. (2) Compared to the baseline, PredCR is more
effective towards reducing bias against new developers. (3) PredCR uses
historical data in the code review repository and as such the performance of
PredCR improves as a software system evolves with new and more data.",http://arxiv.org/abs/1912.03437v2
"Blue, white, and red ocean planets - Simulations of orbital variations
  in flux and polarization colors",2019-04-18T17:57:10Z,"Victor J. H. Trees, Daphne M. Stam","An exoplanet's habitability will depend strongly on the presence of liquid
water. Flux and/or polarization measurements of starlight that is reflected by
exoplanets could help to identify exo-oceans. We investigate which broadband
spectral features in flux and polarization phase functions of reflected
starlight uniquely identify exo-oceans. We compute total fluxes F and polarized
fluxes Q of starlight reflected by cloud-free and (partly) cloudy exoplanets,
for wavelengths from 350 to 865 nm. The ocean surface has waves composed of
Fresnel reflecting wave facets and whitecaps, and scattering within the water
body is included. Total flux F, polarized flux Q, and degree of polarization P
of ocean planets change color from blue, through white, to red at phase angles
alpha ranging from 134-108 deg for F, and from 123-157 deg for Q, with cloud
coverage fraction fc increasing from 0.0 to 1.0 for F, and to 0.98 for Q. The
color change in P only occurs for fc ranging from 0.03-0.98, with the color
crossing angle alpha ranging from 88-161 deg. The total flux F of a cloudy,
zero surface albedo planet can also change color, and for fc=0.0, an ocean
planet's F will not change color for surface pressures ps > 8 bars. Polarized
flux Q of a zero surface albedo planet does not change color for any fc. The
color change of P of starlight reflected by an exoplanet, from blue, through
white, to red with increasing alpha above 88 deg, appears to identify a
(partly) cloudy exo-ocean. The color change of polarized flux Q with increasing
alpha above 123 deg appears to uniquely identify an exo-ocean, independent of
surface pressure or cloud fraction. At the color changing phase angle, the
angular distance between a star and its planet is much larger than at the phase
angle where the glint appears in reflected light. The color change in
polarization thus offers better prospects for detecting exo-oceans.",http://arxiv.org/abs/1904.08922v2
Bayesian Online Prediction of Change Points,2019-02-12T18:01:35Z,"Diego Agudelo-España, Sebastian Gomez-Gonzalez, Stefan Bauer, Bernhard Schölkopf, Jan Peters","Online detection of instantaneous changes in the generative process of a data
sequence generally focuses on retrospective inference of such change points
without considering their future occurrences. We extend the Bayesian Online
Change Point Detection algorithm to also infer the number of time steps until
the next change point (i.e., the residual time). This enables to handle
observation models which depend on the total segment duration, which is useful
to model data sequences with temporal scaling. The resulting inference
algorithm for segment detection can be deployed in an online fashion, and we
illustrate applications to synthetic and to two medical real-world data sets.",http://arxiv.org/abs/1902.04524v2
"X-Ray Spectral Variability of Ultraluminous X-Ray Sources in
  Extragalactic Globular Clusters",2019-02-13T19:00:00Z,"Kristen C. Dage, Stephen E. Zepf, Mark B. Peacock, Arash Bahramian, Omid Noroozi, Arunav Kundu, Thomas J. Maccarone","A number of ultraluminous X-ray sources (ULXs) are physically associated with
extragalactic globular clusters (GCs). We undertake a systematic X-ray analysis
of eight of the brightest of these sources. We fit the spectra of the GC ULXs
to single power law and single disk models. We find that the data never require
that any of the sources change between a disk and a power law across successive
observations. The GC ULXs best fit by a single disk show a bimodal
distribution: they either have temperatures well below 0.5 keV, or variable
temperatures ranging above 0.5 keV up to 2~keV. The GC ULXs with low kT have
significant changes in luminosity but show little or no change in kT. By
contrast, the sources with higher kT either change in both kT and $L_X$
together, or show no significant change in either parameter. Notably, the X-ray
characteristics may be related to the optical properties of these ULXs, with
the two lowest kT sources showing optical emission lines.",http://arxiv.org/abs/1902.05073v2
"A One-Class Support Vector Machine Calibration Method for Time Series
  Change Point Detection",2019-02-18T00:34:58Z,"Baihong Jin, Yuxin Chen, Dan Li, Kameshwar Poolla, Alberto Sangiovanni-Vincentelli","It is important to identify the change point of a system's health status,
which usually signifies an incipient fault under development. The One-Class
Support Vector Machine (OC-SVM) is a popular machine learning model for anomaly
detection and hence could be used for identifying change points; however, it is
sometimes difficult to obtain a good OC-SVM model that can be used on sensor
measurement time series to identify the change points in system health status.
In this paper, we propose a novel approach for calibrating OC-SVM models. The
approach uses a heuristic search method to find a good set of input data and
hyperparameters that yield a well-performing model. Our results on the C-MAPSS
dataset demonstrate that OC-SVM can also achieve satisfactory accuracy in
detecting change point in time series with fewer training data, compared to
state-of-the-art deep learning approaches. In our case study, the OC-SVM
calibrated by the proposed model is shown to be useful especially in scenarios
with limited amount of training data.",http://arxiv.org/abs/1902.06361v1
"On computation of optimal strategies in oligopolistic markets respecting
  the cost of change",2019-11-05T14:57:43Z,"Jiří V. Outrata, Jan Valdman","The paper deals with a class of parametrized equilibrium problems, where the
objectives of the players do possess nonsmooth terms. The respective Nash
equilibria can be characterized via a parameter-dependent variational
inequality of the second kind, whose Lipschitzian stability is thoroughly
investigated. This theory is then applied to evolution of a oligopolistic
market in which the firms adopt their production strategies to changing input
costs, while each change of the production is associated with some ""costs of
change"". We examine both the Cournot-Nash equilibria as well as the two-level
case, when one firm decides to take over the role of the Leader (Stackelberg
equilibrium). The impact of costs of change is illustrated by academic
examples.",http://arxiv.org/abs/1911.01841v1
Change-point Analysis in Financial Networks,2019-11-14T05:54:33Z,"Sayantan Banerjee, Kousik Guhathakurta","A major impact of globalization has been the information flow across the
financial markets rendering them vulnerable to financial contagion. Research
has focused on network analysis techniques to understand the extent and nature
of such information flow. It is now an established fact that a stock market
crash in one country can have a serious impact on other markets across the
globe. It follows that such crashes or critical regimes will affect the network
dynamics of the global financial markets. In this paper, we use sequential
change point detection in dynamic networks to detect changes in the network
characteristics of thirteen stock markets across the globe. Our method helps us
to detect changes in network behavior across all known stock market crashes
during the period of study. In most of the cases, we can detect a change in the
network characteristics prior to crash. Our work thus opens the possibility of
using this technique to create a warning bell for critical regimes in financial
markets.",http://arxiv.org/abs/1911.05952v1
"Correcting for Model Changes in Statistical Postprocessing -- An
  approach based on Response Theory",2019-11-14T19:54:42Z,"Jonathan Demaeyer, Stéphane Vannitsem","For most statistical postprocessing schemes used to correct weather
forecasts, changes to the forecast model induce a considerable reforecasting
effort. We present a new approach based on response theory to cope with slight
model changes. In this framework, the model change is seen as a perturbation of
the original forecast model. The response theory allows us then to evaluate the
variation induced on the parameters involved in the statistical postprocessing,
provided that the magnitude of this perturbation is not too large. This
approach is studied in the context of simple Ornstein-Uhlenbeck models, and
then on a more realistic, yet simple, quasi-geostrophic model. The analytical
results for the former case help to pose the problem, while the application to
the latter provide a proof-of-concept and assesses the potential performances
of response theory in a chaotic system. In both cases, the parameters of the
statistical postprocessing used - an Error-in-Variables Model Output Statistics
(EVMOS) - are appropriately corrected when facing a model change. The potential
application in an operational environment is also discussed.",http://arxiv.org/abs/1911.06361v3
"Estimation of dynamic networks for high-dimensional nonstationary time
  series",2019-11-14T21:11:42Z,"Mengyu Xu, Xiaohui Chen, Wei Biao Wu","This paper is concerned with the estimation of time-varying networks for
high-dimensional nonstationary time series. Two types of dynamic behaviors are
considered: structural breaks (i.e., abrupt change points) and smooth changes.
To simultaneously handle these two types of time-varying features, a two-step
approach is proposed: multiple change point locations are first identified
based on comparing the difference between the localized averages on sample
covariance matrices, and then graph supports are recovered based on a
kernelized time-varying constrained $L_1$-minimization for inverse matrix
estimation (CLIME) estimator on each segment. We derive the rates of
convergence for estimating the change points and precision matrices under mild
moment and dependence conditions. In particular, we show that this two-step
approach is consistent in estimating the change points and the piecewise smooth
precision matrix function, under certain high-dimensional scaling limit. The
method is applied to the analysis of network structure of the S\&P 500 index
between 2003 and 2008.",http://arxiv.org/abs/1911.06385v4
"Online Change-Point Detection in High-Dimensional Covariance Structure
  with Application to Dynamic Networks",2019-11-18T16:53:53Z,"Lingjun Li, Jun Li","In this paper, we develop an online change-point detection procedure in the
covariance structure of high-dimensional data. A new stopping rule is proposed
to terminate the process as early as possible when a change in covariance
structure occurs. The stopping rule allows temporal dependence and can be
applied to non-Gaussian data. An explicit expression for the average run length
(ARL) is derived, so that the level of threshold in the stopping rule can be
easily obtained with no need to run time-consuming Monte Carlo simulations. We
also establish an upper bound for the expected detection delay (EDD), the
expression of which demonstrates the impact of data dependence and magnitude of
change in the covariance structure. Simulation studies are provided to confirm
accuracy of the theoretical results. The practical usefulness of the proposed
procedure is illustrated by detecting the change of brain's covariance network
in a resting-state fMRI dataset.",http://arxiv.org/abs/1911.07762v2
Land Cover Change Detection via Semantic Segmentation,2019-11-28T23:54:36Z,"Renee Su, Rong Chen","This paper presents a change detection method that identifies land cover
changes from aerial imagery, using semantic segmentation, a machine learning
approach. We present a land cover classification training pipeline with Deeplab
v3+, state-of-the-art semantic segmentation technology, including data
preparation, model training for seven land cover types, and model exporting
modules. In the land cover change detection system, the inputs are images
retrieved from Google Earth at the same location but from different times. The
system then predicts semantic segmentation results on these images using the
trained model and calculates the land cover class percentage for each input
image. We see an improvement in the accuracy of the land cover semantic
segmentation model, with a mean IoU of 0.756 compared to 0.433, as reported in
the DeepGlobe land cover classification challenge. The land cover change
detection system that leverages the state-of-the-art semantic segmentation
technology is proposed and can be used for deforestation analysis, land
management, and urban planning.",http://arxiv.org/abs/1911.12903v1
"U-net super-neural segmentation and similarity calculation to realize
  vegetation change assessment in satellite imagery",2019-09-10T11:13:55Z,"Chunxue Wu, Bobo Ju, Naixue Xiong, Guisong Yang, Yan Wu, Hongming Yang, Jiaying Huang, Zhiyong Xu","Vegetation is the natural linkage connecting soil, atmosphere and water. It
can represent the change of land cover to a certain extent and serve as an
indicator for global change research. Methods for measuring coverage can be
divided into two types: surface measurement and remote sensing. Because
vegetation cover has significant spatial and temporal differentiation
characteristics, remote sensing has become an important technical means to
estimate vegetation coverage. This paper firstly uses U-net to perform remote
sensing image semantic segmentation training, then uses the result of semantic
segmentation, and then uses the integral progressive method to calculate the
forestland change rate, and finally realizes automated valuation of woodland
change rate.",http://arxiv.org/abs/1909.04410v1
Direct and Indirect Effects based on Changes-in-Changes,2019-09-11T11:32:54Z,"Martin Huber, Mark Schelker, Anthony Strittmatter","We propose a novel approach for causal mediation analysis based on
changes-in-changes assumptions restricting unobserved heterogeneity over time.
This allows disentangling the causal effect of a binary treatment on a
continuous outcome into an indirect effect operating through a binary
intermediate variable (called mediator) and a direct effect running via other
causal mechanisms. We identify average and quantile direct and indirect effects
for various subgroups under the condition that the outcome is monotonic in the
unobserved heterogeneity and that the distribution of the latter does not
change over time conditional on the treatment and the mediator. We also provide
a simulation study and an empirical application to the Jobs II programme.",http://arxiv.org/abs/1909.04981v3
A model for phonetic changes driven by social interactions,2019-09-28T21:41:36Z,"A. Chacoma, N. Almeira, J. I. Perotti, O. V. Billoni","We propose a stochastic model to study phonetic changes as an evolutionary
process driven by social interactions between two groups of individuals with
different phonological systems. Particularly, we focus on the changes in the
place of articulation, inspired by the drift /\textphi/$\rightarrow$/h/
observed in some words of Latin root in the Castilian language. In the model,
each agent is characterized by a variable of three states, representing the
place of articulation used during speech production. In this frame, we propose
stochastic rules of interactions among agents which lead to phonetic imitation
and consequently to changes in the articulation place. Based on this, we
mathematically formalize the model as a problem of population dynamics, derive
the equations of evolution in the mean field approximation, and study the
emergence of three non--trivial global states, which can be linked to the
pattern of phonetic changes observed in the language of Castile and in other
Romance languages.",http://arxiv.org/abs/1909.13157v2
"Morse index and bifurcation for figure-eight choreographies of the equal
  mass three-body problem",2019-01-01T08:28:59Z,"Hiroshi Fukuda, Toshiaki Fujiwara, Hiroshi Ozaki","We report on the Morse index and periodic solutions bifurcating from the
figure-eight choreography for the equal mass three-body problem under
homogeneous potential $-1/r^a$ for $a \ge 0$, and under Lennard-Jones (LJ) type
potential $1/r^{12}-1/r^6$, where $r$ is a distance between bodies. It is shown
that the Morse index changes at a bifurcation point and all solutions
bifurcating are approximated by variational functions responsible for the
change of the Morse index. Inversely we observed %numerically bifurcation
occurs at every point where the Morse index changes for the figure-eight
choreography under $-1/r^a$, and for $\alpha$ solution under LJ type potential,
where $\alpha$ solution is a figure-eight choreography tending to that under
$-1/r^6$ for infinitely large period. Thus, to our numerical studies, change of
the Morse index is not only necessary but also sufficient condition for
bifurcation for these choreographies. Further we observed that the change of
the Morse index is equal to the number of bifurcated solutions regarding
solutions with congruent orbits as the same solution.",http://arxiv.org/abs/1901.00115v2
Change-point Detection by the Quantile LASSO Method,2019-01-15T07:32:06Z,"Gabriela Ciuperca, Matúš Maciak","A simultaneous change-point detection and estimation in a piece-wise constant
model is a common task in modern statistics. If, in addition, the whole
estimation can be performed automatically, in just one single step without
going through any hypothesis tests for non-identifiable models, or unwieldy
classical a-posterior methods, it becomes an interesting, but also challenging
idea. In this paper we introduce the estimation method based on the quantile
LASSO approach. Unlike standard LASSO approaches, our method does not rely on
typical assumptions usually required for the model errors, such as sub-Gaussian
or Normal distribution. The proposed quantile LASSO method can effectively
handle heavy-tailed random error distributions, and, in general, it offers a
more complex view of the data as one can obtain any conditional quantile of the
target distribution, not just the conditional mean. It is proved that under
some reasonable assumptions the number of change-points is not underestimated
with probability tenting to one, and, in addition, when the number of
change-points is estimated correctly, the change-point estimates provided by
the quantile LASSO are consistent. Numerical simulations are used to
demonstrate these results and to illustrate the empirical performance robust
favor of the proposed quantile LASSO method.",http://arxiv.org/abs/1901.04691v1
Change Point Detection for Compositional Multivariate Data,2019-01-11T08:10:41Z,"Prabuchandran K. J., Nitin Singh, Pankaj Dayama, Vinayaka Pandit","Change point detection algorithms have numerous applications in fields of
scientific and economic importance. We consider the problem of change point
detection on compositional multivariate data (each sample is a probability mass
function), which is a practically important sub-class of general multivariate
data. While the problem of change-point detection is well studied in univariate
setting, and there are few viable implementations for a general multivariate
data, the existing methods do not perform well on compositional data. In this
paper, we propose a parametric approach for change point detection in
compositional data. Moreover, using simple transformations on data, we extend
our approach to handle any general multivariate data. Experimentally, we show
that our method performs significantly better on compositional data and is
competitive on general data compared to the available state of the art
implementations.",http://arxiv.org/abs/1901.04935v1
"Evolution of electronic states and emergence of superconductivity in the
  polar semiconductor GeTe by doping valence-skipping In",2019-01-25T04:53:41Z,"M. Kriener, M. Sakano, M. Kamitani, M. S. Bahramy, R. Yukawa, K. Horiba, H. Kumigashira, K. Ishizaka, Y. Tokura, Y. Taguchi","GeTe is a chemically simple IV-VI semiconductor which bears a rich plethora
of different physical properties induced by doping and external stimuli. These
include, among others, ferromagnetism, ferroelectricity, phase-change memory
functionality, and comparably large thermoelectric figure of merits. Here we
report a superconductor - semiconductor - superconductor transition controlled
by finely-tuned In doping. Our results moreover show the existence of a
critical doping concentration around $x = 0.12$ in Ge$_{1-x}$In$_{x}$Te, where
various properties take either an extremum or change their characters: The
structure changes from polarly-rhombohedral to cubic, the resistivity sharply
increases by orders of magnitude, the type of charge carriers changes from
holes to electrons, and the density of states diminishes at the dawn of an
emerging superconducting phase. By core-level photoemission spectroscopy we
find indications of a change in the In-valence state from In$^{3+}$ to
In$^{1+}$ with increasing $x$, suggesting that this system is a new promising
playground to probe valence fluctuations and their possible impact on
superconductivity.",http://arxiv.org/abs/1901.08739v1
"Health Behavior Change in HCI: Trends, Patterns, and Opportunities",2019-01-29T18:55:06Z,"Yunlong Wang, Ahmed Fadhil, Harald Reiterer","Unhealthy lifestyles could cause many chronic diseases, which bring patients
and their families much burden. Research has shown the potential of digital
technologies for supporting health behavior change to help us prevent these
chronic diseases. The HCI community has contributed to the research on health
behavior change for more than a decade. In this paper, we aim to explore the
research trends and patterns of health behavior change in HCI. Our systematic
review showed that physical activity drew much more attention than other
behaviors. Most of the participants in the reviewed studies were adults, while
children and the elderly were much less addressed. Also, we found there is a
lack of standardized approaches to evaluating the user experience of
interventions for health behavior change in HCI. Based on the reviewed studies,
we provide suggestions and research opportunities on six topics, e.g., game
integration, social support, and relevant AI application.",http://arxiv.org/abs/1901.10449v1
"On the Coordinate Change to the First-Order Spline Kernel for
  Regularized Impulse Response Estimation",2019-01-30T14:08:40Z,"Yusuke Fujimoto, Tianchi Chen","The so-called tuned-correlated kernel (sometimes also called the first-order
stable spline kernel) is one of the most widely used kernels for the
regularized impulse response estimation. This kernel can be derived by applying
an exponential decay function as a coordinate change to the first-order spline
kernel. This paper focuses on this coordinate change and derives new kernels by
investigating other coordinate changes induced by stable and strictly proper
transfer functions. It is shown that the corresponding kernels inherit
properties from these coordinate changes and the first-order spline kernel. In
particular, they have the maximum entropy property and moreover, the inverse of
their Gram matrices has sparse structure. In addition, the spectral analysis of
some special kernels are provided. Finally, a numerical example is given to
show the efficacy of the proposed kernel.",http://arxiv.org/abs/1901.10835v1
"Next-Paradigm Programming Languages: What Will They Look Like and What
  Changes Will They Bring?",2019-05-01T17:37:08Z,Yannis Smaragdakis,"The dream of programming language design is to bring about
orders-of-magnitude productivity improvements in software development tasks.
Designers can endlessly debate on how this dream can be realized and on how
close we are to its realization. Instead, I would like to focus on a question
with an answer that can be, surprisingly, clearer: what will be the common
principles behind next-paradigm, high-productivity programming languages, and
how will they change everyday program development? Based on my decade-plus
experience of heavy-duty development in declarative languages, I speculate that
certain tenets of high-productivity languages are inevitable. These include,
for instance, enormous variations in performance (including automatic
transformations that change the asymptotic complexity of algorithms); a radical
change in a programmer's workflow, elevating testing from a near-menial task to
an act of deep understanding; a change in the need for formal proofs; and more.",http://arxiv.org/abs/1905.00402v1
"Interactive Trajectory Adaptation through Force-guided Bayesian
  Optimization",2019-08-20T10:28:51Z,Leonel Rozo,"Flexible manufacturing processes demand robots to easily adapt to changes in
the environment and interact with humans. In such dynamic scenarios, robotic
tasks may be programmed through learning-from-demonstration approaches, where a
nominal plan of the task is learned by the robot. However, the learned plan may
need to be adapted in order to fulfill additional requirements or overcome
unexpected environment changes. When the required adaptation occurs at the
end-effector trajectory level, a human operator may want to intuitively show
the robot the desired changes by physically interacting with it. In this
scenario, the robot needs to understand the human intended changes from noisy
haptic data, quickly adapt accordingly and execute the nominal task plan when
no further adaptation is needed. This paper addresses the aforementioned
challenges by leveraging LfD and Bayesian optimization to endow the robot with
data-efficient adaptation capabilities. Our approach exploits the sensed
interaction forces to guide the robot adaptation, and speeds up the
optimization process by defining local search spaces extracted from the learned
task model. We show how our framework quickly adapts the learned
spatial-temporal patterns of the task, leading to deformed trajectory
distributions that are consistent with the nominal plan and the changes
introduced by the human.",http://arxiv.org/abs/1908.07263v1
RelGAN: Multi-Domain Image-to-Image Translation via Relative Attributes,2019-08-20T10:54:34Z,"Po-Wei Wu, Yu-Jing Lin, Che-Han Chang, Edward Y. Chang, Shih-Wei Liao","Multi-domain image-to-image translation has gained increasing attention
recently. Previous methods take an image and some target attributes as inputs
and generate an output image with the desired attributes. However, such methods
have two limitations. First, these methods assume binary-valued attributes and
thus cannot yield satisfactory results for fine-grained control. Second, these
methods require specifying the entire set of target attributes, even if most of
the attributes would not be changed. To address these limitations, we propose
RelGAN, a new method for multi-domain image-to-image translation. The key idea
is to use relative attributes, which describes the desired change on selected
attributes. Our method is capable of modifying images by changing particular
attributes of interest in a continuous manner while preserving the other
attributes. Experimental results demonstrate both the quantitative and
qualitative effectiveness of our method on the tasks of facial attribute
transfer and interpolation.",http://arxiv.org/abs/1908.07269v1
Do Energy-oriented Changes Hinder Maintainability?,2019-08-22T12:21:08Z,"Luis Cruz, Rui Abreu, John Grundy, Li Li, Xin Xia","Energy efficiency is a crucial quality requirement for mobile applications.
However, improving energy efficiency is far from trivial as developers lack the
knowledge and tools to aid in this activity. In this paper we study the impact
of changes to improve energy efficiency on the maintainability of Android
applications. Using a dataset containing 539 energy efficiency-oriented
commits, we measure maintainability -- as computed by the Software Improvement
Group's web-based source code analysis service Better Code Hub (BCH) -- before
and after energy efficiency-related code changes. Results show that in general
improving energy efficiency comes with a significant decrease in
maintainability. This is particularly evident in code changes to accommodate
the Power Save Mode and Wakelock Addition energy patterns. In addition, we
perform manual analysis to assess how real examples of energy-oriented changes
affect maintainability. Our results help mobile app developers to 1) avoid
common maintainability issues when improving the energy efficiency of their
apps; and 2) adopt development processes to build maintainable and
energy-efficient code. We also support researchers by identifying challenges in
mobile app development that still need to be addressed.",http://arxiv.org/abs/1908.08332v1
"Generator Contingency Modeling in Electric Energy Markets: Derivation of
  Prices via Duality Theory",2019-10-05T20:12:21Z,"N. G. Singhal, J. Kwon, K. W. Hedman","Traditional electric energy markets do not explicitly model generator
contingencies. To improve the representation of resources and to enhance the
modeling of uncertainty, existing markets are moving in the direction of
including generator contingencies and remedial action schemes within market
auction models explicitly. This research contributes to the market design realm
by providing detailed analysis of impending changes, it provides insightful
guidance in understanding the market implications, and it provides
recommendations on necessary changes to ensure a fair and transparent market
structure. A primal (and the corresponding dual) formulation that accounts for
the proposed changes to the auction model is provided to enable a theoretical
analysis of the anticipated changes including the effect on market prices,
settlements, and revenues. The derivation of the prices and the dual
formulation are based on leveraging duality theory from linear optimization
theory. A comparison to existing market structures is also included. The
primary impact of the proposed changes includes the addition of a new
congestion component within the traditional locational marginal price, which
reflects the influence of congestion during the post-contingency states for the
modeled critical generator contingencies.",http://arxiv.org/abs/1910.02323v1
"Change Point Detection for Nonparametric Regression under Strongly
  Mixing Process",2019-10-31T09:33:52Z,"Q. Yang, Y. Li, Y. Zhang","In this article, we consider the estimation of the structural change point in
the nonparametric model with dependent observations. We introduce a
maximum-CUSUM-estimation procedure, where the CUSUM statistic is constructed
based on the sum-of-squares aggregation of the difference of the two
Nadaraya-Watson estimates using the observations before and after a specific
time point. Under some mild conditions, we prove that the statistic tends to
zero almost surely if there is no change, and is larger than a threshold
asymptotically almost surely otherwise, which helps us to obtain a
threshold-detection strategy. Furthermore, we demonstrate the strong
consistency of the change point estimator. In the simulation, we discuss the
selection of the bandwidth and the threshold used in the estimation, and show
the robustness of our method in the long-memory scenario. We implement our
method to the data of Nasdaq 100 index and find that the relation between the
realized volatility and the return exhibits several structural changes in
2007-2009.",http://arxiv.org/abs/1910.14330v2
"Determining the Optimal Phase-Change Material via High-Throughput
  Calculations",2019-03-04T14:49:38Z,"Nicholas A. Pike, Amina Matt, Ole M. Løvvik","The discovery and optimization of phase-change and shape memory alloys remain
a tedious and expensive process. Here a simple computational method is proposed
to determine the ideal phase-change material for a given alloy composed of
three elements. Using first-principles calculations, within a high-throughput
framework, the ideal composition of a phase-change material between any two
assumed phases can be determined. This ideal composition minimizes the
interface strain during the structural transformation. Then one can target this
ideal composition experimentally to produce compounds with low mechanical
failure rates for a potentially wide variety of applications. Here we will
provide evidence of the effectiveness of our calculations for a well-known
phase-change material in which we predict the ideal composition and compare it
to experimental results.",http://arxiv.org/abs/1903.01286v1
Quantifying Gait Changes Using Microsoft Kinect and Sample Entropy,2019-03-05T00:16:23Z,"Behnam Malmir, Shing I Chang, Malgorzata Rys, Dylan Darter","This study describes a method to quantify potential gait changes in human
subjects. Microsoft Kinect devices were used to provide and track coordinates
of fifteen different joints of a subject over time. Three male subjects walk a
10-foot path multiple times with and without motion-restricting devices. Their
walking patterns were recorded via two Kinect devices through frontal and
sagittal planes. A modified sample entropy (SE) value was computed to quantify
the variability of the time series for each joint. The SE values with and
without motion-restricting devices were used to compare the changes in each
joint. The preliminary results of the experiments show that the proposed
quantification method can detect differences in walking patterns with and
without motion-restricting devices. The proposed method has the potential to be
applied to track personal progress in physical therapy sessions.",http://arxiv.org/abs/1903.01601v1
"Heterogeneous Impact of the Minimum Wage: Implications for Changes in
  Between- and Within-group Inequality",2019-03-10T05:28:15Z,"Tatsushi Oka, Ken Yamada","Workers who earn at or below the minimum wage in the United States are mostly
either less educated, young, or female. Little is known, however, concerning
the extent to which the minimum wage influences wage differentials among
workers with different observed characteristics and among workers with the same
observed characteristics. This paper shows that changes in the real value of
the minimum wage over recent decades have affected the relationship of hourly
wages with education, experience, and gender. The results suggest that changes
in the real value of the minimum wage account in part for the patterns of
changes in education, experience, and gender wage differentials and mostly for
the patterns of changes in within-group wage differentials among female workers
with lower levels of experience.",http://arxiv.org/abs/1903.03925v2
"Strong approximation of stochastic differential equations driven by a
  time-changed Brownian motion with time-space-dependent coefficients",2019-03-20T19:16:30Z,"Sixian Jin, Kei Kobayashi","The rate of strong convergence is investigated for an approximation scheme
for a class of stochastic differential equations driven by a time-changed
Brownian motion, where the random time changes $(E_t)_{t\ge 0}$ considered
include the inverses of stable and tempered stable subordinators as well as
their mixtures. Unlike those in the work of Jum and Kobayashi (2016), the
coefficients of the stochastic differential equations discussed in this paper
depend on the regular time variable $t$ rather than the time change $E_t$. This
alteration makes it difficult to apply the method used in that paper. To
overcome this difficulty, we utilize a Gronwall-type inequality involving a
stochastic driver to control the moment of the error process. Moreover, in
order to guarantee that an ultimately derived error bound is finite, we
establish a useful criterion for the existence of exponential moments of powers
of the random time change.",http://arxiv.org/abs/1903.08706v2
"The role of physiological complexity changes in resting-state EEG in
  clinical effectiveness of rTMS and tDCS in treatments of resistant depression",2019-03-25T23:06:22Z,Milena Cukic,"The present literature about possible mechanisms behind the effectivity of
noninvasive electromagnetic stimulation in major depressive disorder (MDD) is
not very rich. Despite extensive research in applications for clinical
practice, the exact effects are yet not clear. We are comparing our previous
results about the complexity changes induced by repetitive Transcranial
Magnetic Stimulation (rTMS), and transcranial direct current stimulation (tDCS)
which are known to modulate neural dynamics. Also, we are reviewing different
biomarkers of complexity changes connected to depression, and how they change
with the stimulation. TDCS is low-intensity TES, known to have polarity
specific effects (neuromodulatory effects), and rTMS is inducing an electric
field in the tissue circumstantially via Faraday's law. Both nonlinear
modalities of electromagnetic stimulation may affect the levels of
physiological complexity in the brain. We also compare the changes of
complexity in electroencephalogram (EEG) and electrocardiogram (ECG), as
potential future predictors of therapy outcome.",http://arxiv.org/abs/1903.10626v1
"Testing and Estimating Change-Points in the Covariance Matrix of a
  High-Dimensional Time Series",2019-12-10T13:28:05Z,Ansgar Steland,"This paper studies methods for testing and estimating change-points in the
covariance structure of a high-dimensional linear time series. The assumed
framework allows for a large class of multivariate linear processes (including
vector autoregressive moving average (VARMA) models) of growing dimension and
spiked covariance models. The approach uses bilinear forms of the centered or
non-centered sample variance-covariance matrix. Change-point testing and
estimation are based on maximally selected weighted cumulated sum (CUSUM)
statistics. Large sample approximations under a change-point regime are
provided including a multivariate CUSUM transform of increasing dimension. For
the unknown asymptotic variance and covariance parameters associated to (pairs
of) CUSUM statistics we propose consistent estimators. Based on weak laws of
large numbers for their sequential versions, we also consider stopped sample
estimation where observations until the estimated change-point are used. Finite
sample properties of the procedures are investigated by simulations and their
application is illustrated by analyzing a real data set from environmetrics.",http://arxiv.org/abs/1912.04677v2
Forecasting significant stock price changes using neural networks,2019-11-21T11:48:48Z,Firuz Kamalov,"Stock price prediction is a rich research topic that has attracted interest
from various areas of science. The recent success of machine learning in speech
and image recognition has prompted researchers to apply these methods to asset
price prediction. The majority of literature has been devoted to predicting
either the actual asset price or the direction of price movement. In this
paper, we study a hitherto little explored question of predicting significant
changes in stock price based on previous changes using machine learning
algorithms. We are particularly interested in the performance of neural network
classifiers in the given context. To this end, we construct and test three
neural network models including multi-layer perceptron, convolutional net, and
long short term memory net. As benchmark models we use random forest and
relative strength index methods. The models are tested using 10-year daily
stock price data of four major US public companies. Test results show that
predicting significant changes in stock price can be accomplished with a high
degree of accuracy. In particular, we obtain substantially better results than
similar studies that forecast the direction of price change.",http://arxiv.org/abs/1912.08791v1
"TESS observations of the asynchronous polar CD Ind: mapping the changing
  accretion geometry",2019-04-05T09:17:38Z,"Pasi Hakala, Gavin Ramsay, Stephen B. Potter, Andrew Beardmore, David A. H. Buckley, Graham Wynn","We present the results of near continuous TESS optical observations of the
asynchronous polar CD Ind (RX J2115-5840). The 27.9 d long light curve, with 2
min resolution, reveals remarkable changes in the magnetic accretion geometry
of the system over the 7.3 d beat period. We have modelled the changes in the
optical spin period pulse shape using a cyclotron emission mapping technique.
The resulting cyclotron emission maps of the magnetic white dwarf reveal how
the accretion geometry changes from single to two pole accretion and back over
the beat cycle. Finally, we present the results from particle based numerical
magnetic accretion simulations, that agree with our interpretation of the
changing accretion scenario.",http://arxiv.org/abs/1904.02949v1
"A Bayesian Theory of Change Detection in Statistically Periodic Random
  Processes",2019-04-06T20:57:19Z,"Taposh Banerjee, Prudhvi Gurram, Gene Whipps","A new class of stochastic processes called independent and periodically
identically distributed (i.p.i.d.) processes is defined to capture periodically
varying statistical behavior. A novel Bayesian theory is developed for
detecting a change in the distribution of an i.p.i.d. process. It is shown that
the Bayesian change point problem can be expressed as a problem of optimal
control of a Markov decision process (MDP) with periodic transition and cost
structures. Optimal control theory is developed for periodic MDPs for
discounted and undiscounted total cost criteria. A fixed-point equation is
obtained that is satisfied by the optimal cost function. It is shown that the
optimal policy for the MDP is nonstationary but periodic in nature. A value
iteration algorithm is obtained to compute the optimal cost function. The
results from the MDP theory are then applied to detect changes in i.p.i.d.
processes. It is shown that while the optimal change point algorithm is a
stopping rule based on a periodic sequence of thresholds, a single-threshold
policy is asymptotically optimal, as the probability of false alarm goes to
zero. Numerical results are provided to demonstrate that the asymptotically
optimal policy is not strictly optimal.",http://arxiv.org/abs/1904.03530v1
Empirical Study of Phased Model of Software Change,2019-04-11T16:52:34Z,"Leon A. Wilson, Yoann Senin, Yibin Wang, Václav Rajlich","Software change is the basic task of software evolution and maintenance.
Phased Model for Software Change (PMSC) is a process model for software changes
that localize in the code. It consists of several phases that cover both
program comprehension and code modifications. This paper presents an empirical
study of an enactment of PMSC, enhanced by the use of tool JRipples. The
subjects are graduate students with varying degree of programming experience.
The empirical findings demonstrate that programmers with knowledge of PMSC and
supported by JRipples perform perfective software changes in unfamiliar
software in significantly less time (about half time) than unaided programmers.
Substantial time improvements were witnessed in both code comprehension and
implementation efforts.",http://arxiv.org/abs/1904.05842v1
"Glassy dynamics of a model of bacterial cytoplasm with metabolic
  activities",2019-04-19T02:36:08Z,"Norihiro Oyama, Takeshi Kawasaki, Hideyuki Mizuno, Atsushi Ikeda","Recent experiments have revealed that cytoplasms become glassy when their
metabolism is suppressed, while they maintain fluidity in a living state. The
mechanism of this active fluidization is not clear, especially for bacterial
cytoplasms, since they lack traditional motor proteins, which can cause
directed motions. We introduce a model of bacterial cytoplasm focusing on the
impact of conformational change in proteins due to metabolism. In the model,
proteins are treated as particles under thermal agitation, and conformation
changes are treated as changes in particle volume. Simulations revealed that a
small change in volume fluidizes the glassy state, accompanied by a change in
fragility, as observed experimentally.",http://arxiv.org/abs/1904.09052v1
Nonradiative to Superscattering Switch with Phase-Change Materials,2019-04-25T16:37:56Z,"Sergey Lepeshov, Alex Krasnok, Andrea Alù","Phase-change materials (PCMs) can switch between different crystalline states
as a function of an external bias, offering a pronounced change of their
dielectric function. In order to take full advantage of these features for
active photonics and information storage, stand-alone PCMs are not sufficient,
since the phase transition requires strong pump fields. Here, we explore hybrid
metal-semiconductor core-shell nanoantennas loaded with PCMs, enabling a
drastic switch in scattering features as the load changes its phase. Large
scattering, beyond the limits of small resonant particles, is achieved by
spectrally matching different Mie resonances, while scattering cancellation and
cloaking is achieved with out-of-phase electric dipole oscillations in the PCM
shell and Ag core. We show that tuning the PCM crystallinity we can largely
vary total (~15 times) and forward (~100 times) scattering. Remarkably, a
substantial reconfiguration of the scattering pattern from Kerker (zero
backward) to antiKerker (almost zero forward) regimes with little change (~5%)
in crystallinity is predicted, which makes this structure promising
low-intensity nonlinear photonics.",http://arxiv.org/abs/1904.11442v1
Online Causal Structure Learning in the Presence of Latent Variables,2019-04-30T13:49:43Z,"Durdane Kocacoban, James Cussens","We present two online causal structure learning algorithms which can track
changes in a causal structure and process data in a dynamic real-time manner.
Standard causal structure learning algorithms assume that causal structure does
not change during the data collection process, but in real-world scenarios, it
does often change. Therefore, it is inappropriate to handle such changes with
existing batch-learning approaches, and instead, a structure should be learned
in an online manner. The online causal structure learning algorithms we present
here can revise correlation values without reprocessing the entire dataset and
use an existing model to avoid relearning the causal links in the prior model,
which still fit data. Proposed algorithms are tested on synthetic and
real-world datasets, the latter being a seasonally adjusted commodity price
index dataset for the U.S. The online causal structure learning algorithms
outperformed standard FCI by a large margin in learning the changed causal
structure correctly and efficiently when latent variables were present.",http://arxiv.org/abs/1904.13247v2
Lifelong Learning with a Changing Action Set,2019-06-05T00:59:25Z,"Yash Chandak, Georgios Theocharous, Chris Nota, Philip S. Thomas","In many real-world sequential decision making problems, the number of
available actions (decisions) can vary over time. While problems like
catastrophic forgetting, changing transition dynamics, changing rewards
functions, etc. have been well-studied in the lifelong learning literature, the
setting where the action set changes remains unaddressed. In this paper, we
present an algorithm that autonomously adapts to an action set whose size
changes over time. To tackle this open problem, we break it into two problems
that can be solved iteratively: inferring the underlying, unknown, structure in
the space of actions and optimizing a policy that leverages this structure. We
demonstrate the efficiency of this approach on large-scale real-world lifelong
learning problems.",http://arxiv.org/abs/1906.01770v3
"Continuous Control for Automated Lane Change Behavior Based on Deep
  Deterministic Policy Gradient Algorithm",2019-06-05T19:40:20Z,"Pin Wang, Hanhan Li, Ching-Yao Chan","Lane change is a challenging task which requires delicate actions to ensure
safety and comfort. Some recent studies have attempted to solve the lane-change
control problem with Reinforcement Learning (RL), yet the action is confined to
discrete action space. To overcome this limitation, we formulate the lane
change behavior with continuous action in a model-free dynamic driving
environment based on Deep Deterministic Policy Gradient (DDPG). The reward
function, which is critical for learning the optimal policy, is defined by
control values, position deviation status, and maneuvering time to provide the
RL agent informative signals. The RL agent is trained from scratch without
resorting to any prior knowledge of the environment and vehicle dynamics since
they are not easy to obtain. Seven models under different hyperparameter
settings are compared. A video showing the learning progress of the driving
behavior is available. It demonstrates the RL vehicle agent initially runs out
of road boundary frequently, but eventually has managed to smoothly and stably
change to the target lane with a success rate of 100% under diverse driving
situations in simulation.",http://arxiv.org/abs/1906.02275v1
Nonlowness independent from frequent mind changes,2019-06-14T19:54:06Z,Liling Ko,"It was recently shown that the computably enumerable (c.e.) degrees that
embed the critical triple (Downey, Greenberg, Weber 2007) and the M3 lattice
structure (Downey, Greenberg 2015) are exactly those that change their minds
sufficiently often. Therefore the embeddability strength of a c.e. degree has
much to do with the degree's mind change frequency. Nonlowness is another
common measure of degree strength, with nonlow degrees expected to compute more
degrees than low ones. We ask if nonlowness and frequent mind changes are
independent measures of strength. Downey and Greenberg (2015) claimed this to
be true without proof, so we present one here. We prove the claim by building
low and nonlow c.e. sets with an arbitrary number of mind changes. We base our
proof on our direct construction of a nonlow low2 array computable set. Such
sets were always known to exist, but also never constructed directly in any
publication.",http://arxiv.org/abs/1906.06381v1
Evolving the Hearthstone Meta,2019-07-02T20:32:08Z,"Fernando de Mesentier Silva, Rodrigo Canaan, Scott Lee, Matthew C. Fontaine, Julian Togelius, Amy K. Hoover","Balancing an ever growing strategic game of high complexity, such as
Hearthstone is a complex task. The target of making strategies diverse and
customizable results in a delicate intricate system. Tuning over 2000 cards to
generate the desired outcome without disrupting the existing environment
becomes a laborious challenge. In this paper, we discuss the impacts that
changes to existing cards can have on strategy in Hearthstone. By analyzing the
win rate on match-ups across different decks, being played by different
strategies, we propose to compare their performance before and after changes
are made to improve or worsen different cards. Then, using an evolutionary
algorithm, we search for a combination of changes to the card attributes that
cause the decks to approach equal, 50% win rates. We then expand our
evolutionary algorithm to a multi-objective solution to search for this result,
while making the minimum amount of changes, and as a consequence disruption, to
the existing cards. Lastly, we propose and evaluate metrics to serve as
heuristics with which to decide which cards to target with balance changes.",http://arxiv.org/abs/1907.01623v1
"A Conformance Checking-based Approach for Drift Detection in Business
  Processes",2019-07-09T16:24:33Z,"Víctor Gallego-Fontenla, Juan C. Vidal, Manuel Lama","Real life business processes change over time, in both planned and unexpected
ways. The detection of these changes is crucial for organizations to ensure
that the expected and the real behavior are as similar as possible. These
changes over time are called concept drift and its detection is a big challenge
in process mining since the inherent complexity of the data makes difficult
distinguishing between a change and an anomalous execution. In this paper, we
present C2D2 (Conformance Checking-based Drift Detection), a new approach to
detect sudden control-flow changes in the process models from event traces.
C2D2 combines discovery techniques with conformance checking methods to perform
an offline detection. Our approach has been validated with a synthetic
benchmarking dataset formed by 68 logs, showing an improvement in the accuracy
while maintaining a minimum delay in the drift detection.",http://arxiv.org/abs/1907.04276v1
"Effects of changing population or density on urban carbon dioxide
  emissions",2019-07-19T11:00:47Z,"Haroldo V. Ribeiro, Diego Rybski, Jürgen P. Kropp","The question of whether urbanization contributes to increasing carbon dioxide
emissions has been mainly investigated via scaling relationships with
population or population density. However, these approaches overlook the
correlations between population and area, and ignore possible interactions
between these quantities. Here, we propose a generalized framework that
simultaneously considers the effects of population and area along with possible
interactions between these urban metrics. Our results significantly improve the
description of emissions and reveal the coupled role between population and
density on emissions. These models show that variations in emissions associated
with proportionate changes in population or density may not only depend on the
magnitude of these changes but also on the initial values of these quantities.
For US areas, the larger the city, the higher is the impact of changing its
population or density on its emissions; but population changes always have a
greater effect on emissions than population density.",http://arxiv.org/abs/1907.08623v1
"Optimal Sequential Tests for Detection of Changes under Finite measure
  space for Finite Sequences of Networks",2019-11-15T10:04:36Z,"Lei Qiao, Dong Han","This paper considers the change-point problem for finite sequences of
networks. To avoid the difficulty of computing the normalization coefficient,
such as in Exponential random graphical models (ERGMs) and Markov networks, we
construct a finite measure space with measure ratio statistics. A new
performance measure of detection delay is proposed to detect the changes in
distribution of the network. And an optimal sequential test is proposed under
the performance measure. The good performance of the optimal sequential test is
illustrated numerically on ERGMs and Erdos-R\'{e}nyi network sequences.",http://arxiv.org/abs/1911.06545v2
Detecting structural breaks in eigensystems of functional time series,2019-11-18T12:20:47Z,"Holger Dette, Tim Kutta","Detecting structural changes in functional data is a prominent topic in
statistical literature. However not all trends in the data are important in
applications, but only those of large enough influence. In this paper we
address the problem of identifying relevant changes in the eigenfunctions and
eigenvalues of covariance kernels of $L^2[0,1]$-valued time series. By
self-normalization techniques we derive pivotal, asymptotically consistent
tests for relevant changes in these characteristics of the second order
structure and investigate their finite sample properties in a simulation study.
The applicability of our approach is demonstrated analyzing German annual
temperature data.",http://arxiv.org/abs/1911.07580v1
A Conditional Perspective for Iterated Belief Contraction,2019-11-20T11:23:17Z,"Kai Sauerwald, Gabriele Kern-Isberner, Christoph Beierle","According to Boutillier, Darwiche, Pearl and others, principles for iterated
revision can be characterised in terms of changing beliefs about conditionals.
For iterated contraction a similar formulation is not known. This is especially
because for iterated belief change the connection between revision and
contraction via the Levi and Harper identity is not straightforward, and
therefore, characterisation results do not transfer easily between iterated
revision and contraction. In this article, we develop an axiomatisation of
iterated contraction in terms of changing conditional beliefs. We prove that
the new set of postulates conforms semantically to the class of operators like
the ones given by Konieczny and Pino P\'erez for iterated contraction.",http://arxiv.org/abs/1911.08833v1
"Consistency of Binary Segmentation For Multiple Change-Points Estimation
  With Functional Data",2019-12-31T22:06:03Z,"Gregory Rice, Chi Zhang","For sequentially observed functional data exhibiting multiple change points
in the mean function, we establish consistency results for the estimated number
and locations of the change points based on the norm of the functional CUSUM
process and standard binary segmentation. In addition to extending similar
results in Venkatraman (1992) and Fryzlewicz (2014) for scalar data to the
general Hilbert space setting, our main results are established without
assuming the Gaussianity of the data, and under general linear process
conditions on the model errors.",http://arxiv.org/abs/2001.00093v1
"Element-wise estimation error of a total variation regularized estimator
  for change point detection",2019-01-03T21:06:15Z,Teng Zhang,"This work studies the total variation regularized $\ell_2$ estimator (fused
lasso) in the setting of a change point detection problem. Compared with
existing works that focus on the sum of squared estimation errors, we give
bound on the element-wise estimation error. Our bound is nearly optimal in the
sense that the sum of squared error matches the best existing result, up to a
logarithmic factor. This analysis of the element-wise estimation error allows a
screening method that can approximately detect all the change points. We also
generalize this method to the muitivariate setting, i.e., to the problem of
group fused lasso.",http://arxiv.org/abs/1901.00914v1
Nonmonotonic band gap evolution in bent phosphorene nanosheets,2019-01-15T05:12:33Z,"Vojtech Vlcek, Eran Rabani, Roi Baer, Daniel Neuhauser","Nonmonotonic bending-induced changes of fundamental band gaps and
quasiparticle energies are observed for realistic nanoscale phosphorene
nanosheets. Calculations using stochastic many-body perturbation theory (sGW)
show that even slight curvature causes significant changes in the electronic
properties. For small bending radii (< 4 nm) the band-gap changes from direct
to indirect. The response of phosphorene to deformation is strongly anisotropic
(different for zig-zag vs. armchair bending) due to an interplay of exchange
and correlation effects. Overall, our results show that fundamental band gaps
of phosphorene sheets can be manipulated by as much as 0.7 eV depending on the
bending direction.",http://arxiv.org/abs/1901.04665v1
"Supplementary Notes: Segment Parameter Labelling in MCMC Change
  Detection",2019-01-16T13:47:19Z,Alireza Ahrabian,"This work addresses the problem of segmentation in time series data with
respect to a statistical parameter of interest in Bayesian models. It is common
to assume that the parameters are distinct within each segment. As such, many
Bayesian change point detection models do not exploit the segment parameter
patterns, which can improve performance. This work proposes a Bayesian change
point detection algorithm that makes use of repetition in segment parameters,
by introducing segment class labels that utilise a Dirichlet process prior.",http://arxiv.org/abs/1901.05452v1
"Experimental Observation of Invariance of Spectral Degree of Coherence
  with Change in Bandwidth of Light",2019-01-18T03:51:31Z,"Bhaskar Kanseri, Hem Chandra Kandpal","An experimental study is conducted to show the effect of the change in
bandwidth of light on the spectral degree of coherence at a pair of points in
the cross-section of a beam. For this purpose a polychromatic source and a
monochromator with variable entrance and exit slits were used to produce a
variable bandwidth source. The classic Youngs interferometer was used to
produce an interference pattern. The spectral measurements of the visibility of
the interference fringes show that the spectral degree of coherence remains
unaffected by the change in the frequency pass-band of the light.",http://arxiv.org/abs/1901.06076v1
Agol's theorem on hyperbolic cubulations,2019-05-15T14:11:17Z,Sam Shepherd,"Agol proved that hyperbolic cubulated groups are virtually special. The aim
of these notes is to make the proof accessible to a wider audience; we retain
the underlying ideas and constructions of Agol, but substantially change or add
to many parts of the argument to give a more transparent and detailed account.",http://arxiv.org/abs/1905.06199v2
KG-GAN: Knowledge-Guided Generative Adversarial Networks,2019-05-29T07:55:46Z,"Che-Han Chang, Chun-Hsien Yu, Szu-Ying Chen, Edward Y. Chang","Can generative adversarial networks (GANs) generate roses of various colors
given only roses of red petals as input? The answer is negative, since GANs'
discriminator would reject all roses of unseen petal colors. In this study, we
propose knowledge-guided GAN (KG-GAN) to fuse domain knowledge with the GAN
framework. KG-GAN trains two generators; one learns from data whereas the other
learns from knowledge with a constraint function. Experimental results
demonstrate the effectiveness of KG-GAN in generating unseen flower categories
from seen categories given textual descriptions of the unseen ones.",http://arxiv.org/abs/1905.12261v2
"A robust approach for testing parameter change in Poisson autoregressive
  models",2019-08-29T22:13:27Z,"Jiwon Kang, Junmo Song","Parameter change test has been an important issue in time series analysis.
The problem has also been actively explored in the field of integer-valued time
series, but the testing in the presence of outliers has not yet been
extensively investigated. This study considers the problem of testing for
parameter change in Poisson autoregressive models particularly when
observations are contaminated by outliers. To lessen the impact of outliers on
testing procedure, we propose a test based on the density power divergence,
which is introduced by Basu et al. (Biometrika, 1998), and derive its limiting
null distribution. Monte Carlo simulation results demonstrate validity and
strong robustness of the proposed test.",http://arxiv.org/abs/1908.11466v1
Variation of shear moduli across superconducting phase transitions,2019-10-07T18:28:24Z,"Dimitri Labat, Panagiotis Kotetes, Brian M. Andersen, Indranil Paul","We study how shear moduli of a correlated metal change across superconducting
phase transitions. Using a microscopic theory we explain why for most classes
of superconductors this change is small. The Fe-based and the A15 systems are
notable exceptions where the change is boosted by five orders of magnitude. We
show that this boost is a consequence of enhanced nematic correlation. The
theory explains the unusual temperature dependence of the orthorhombic shear
and the back-bending of the nematic transition line in the superconducting
phase of the Fe-based systems.",http://arxiv.org/abs/1910.02996v1
In Search for Linear Relations in Sentence Embedding Spaces,2019-10-08T13:06:01Z,"Petra Barančíková, Ondřej Bojar","We present an introductory investigation into continuous-space vector
representations of sentences. We acquire pairs of very similar sentences
differing only by a small alterations (such as change of a noun, adding an
adjective, noun or punctuation) from datasets for natural language inference
using a simple pattern method. We look into how such a small change within the
sentence text affects its representation in the continuous space and how such
alterations are reflected by some of the popular sentence embedding models. We
found that vector differences of some embeddings actually reflect small changes
within a sentence.",http://arxiv.org/abs/1910.03375v1
Distributed Change Detection in Streaming Graph Signals,2019-10-15T06:58:57Z,"André Ferrari, Cédric Richard, Louis Verduci","Detecting abrupt changes in streaming graph signals is relevant in a variety
of applications ranging from energy and water supplies, to environmental
monitoring. In this paper, we address this problem when anomalies activate
localized groups of nodes in a network. We introduce an online change-point
detection algorithm, which is fully distributed across nodes to monitor
large-scale dynamic networks. We analyze the detection statistics for
controlling the probability of a global type 1 error. Finally we illustrate the
detection and localization performance with simulated data.",http://arxiv.org/abs/1910.06561v1
"Commutativity of the Haagerup tensor product and base change for
  operator modules",2019-10-25T14:52:25Z,Tyrone Crisp,"By computing the completely bounded norm of the flip map on the Haagerup
tensor product $C_0 Y_1\otimes_{C_0 X} C_0 Y_2$ associated to a pair of
continuous mappings of locally compact Hausdorff spaces $Y_1\rightarrow
X\leftarrow Y_2$, we establish a simple characterisation of the Beck-Chevalley
condition for base change of operator modules over commutative $C^*$-algebras,
and a descent theorem for continuous fields of Hilbert spaces.",http://arxiv.org/abs/1910.11774v4
Change of drift in one-dimensional diffusions,2019-10-25T19:16:08Z,"Sascha Desmettre, Gunther Leobacher, L. C. G. Rogers","It is generally understood that a given one-dimensional diffusion may be
transformed by Cameron-Martin-Girsanov measure change into another
one-dimensional diffusion with the same volatility but a different drift. But
to achieve this we have to know that the change-of-measure local martingale
that we write down is a true martingale; we provide a complete characterization
of when this happens. This is then used to discuss absence of arbitrage in a
generalized Heston model including the case where the Feller condition for the
volatility process is violated.",http://arxiv.org/abs/1910.11904v4
A Global Diffeomorphism Theorem for Fréchet spaces,2019-03-12T19:20:04Z,Kaveh Eftekharinasab,"We give sufficient conditions for a $ C^1_c $-local diffeomorphism between
Fr\'{e}chet spaces to be a global one. We extend the Clarke's theory of
generalized gradients to the more general setting of Fr\'{e}chet spaces. As a
consequence, we define the Chang Palais-Smale condition for Lipschitz functions
and show that a function which is bounded below and satisfies the Chang
Palais-Smale condition at all levels is coercive. We prove a version of the
mountain pass theorem for Lipschitz maps in the Fr\'{e}chet setting and show
that along with the Chang Palais-Smale condition we can obtain a global
diffeomorphism theorem.",http://arxiv.org/abs/1903.05162v2
A strong Markov process time-changed by an inverse killed subordinator,2019-12-06T02:00:44Z,"Huiyan Zhao, Siyan xu","In this paper, we consider a type of time-changed Markov process, where the
time-change is an inverse killed subordinator. This can be seen as an extension
of Chen (Chen, Z., Time fractional equations and probabilistic representation,
Chaos Solitons and Fractals, 168-174, 2017). As a result, it constructs a
one-to-one correspondence between general Bernstein functions (with infinite
L\'{e}vy measure) and a class of generalized time-fractional partial
differential equations.",http://arxiv.org/abs/1912.02948v1
"Interdependent Infrastructure System Risk and Resilience to Natural
  Hazards",2019-04-11T15:18:27Z,"Benjamin Rachunok, Roshanak Nateghi","Complex, interdependent systems are necessary to the delivery of goods and
services critical to societal function. Here we demonstrate how interdependent
systems respond to disruptions. Specifically, we change the spatial arrangement
of a disruption in infrastructure and show that -- while controlling for the
size -- changes in the spatial pattern of a disruption induce significant
changes in the way interdependent systems fail and recover. This work
demonstrates the potential to improve characterizations of hazard disruption to
infrastructure by incorporating additional information about the impact of
disruptions on interdependent systems.",http://arxiv.org/abs/1904.05763v1
Nonparametric volatility change detection,2019-06-07T10:08:23Z,"Maria Mohr, Natalie Neumeyer","We consider a nonparametric heteroscedastic time series regression model and
suggest testing procedures to detect changes in the conditional variance
function. The tests are based on a sequential marked empirical process and thus
combine classical CUSUM tests with marked empirical process approaches known
from goodness-of-fit testing. The tests are consistent against general
alternatives of a change in the conditional variance function, a feature that
classical CUSUM tests are lacking. We derive a simple limiting distribution and
in the case of univariate covariates even obtain asymptotically
distribution-free tests. We demonstrate the good performance of the tests in a
simulation study and consider exchange rate data as a real data application.",http://arxiv.org/abs/1906.02996v1
Dynamic time series clustering via volatility change-points,2019-06-25T08:18:58Z,Nick Whiteley,"This note outlines a method for clustering time series based on a statistical
model in which volatility shifts at unobserved change-points. The model
accommodates some classical stylized features of returns and its relation to
GARCH is discussed. Clustering is performed using a probability metric
evaluated between posterior distributions of the most recent change-point
associated with each series. This implies series are grouped together at a
given time if there is evidence the most recent shifts in their respective
volatilities were coincident or closely timed. The clustering method is
dynamic, in that groupings may be updated in an online manner as data arrive.
Numerical results are given analyzing daily returns of constituents of the S&P
500.",http://arxiv.org/abs/1906.10372v1
"Determination of spin relaxation time and spin diffusion length by
  oscillation of spin pumping signal",2019-07-10T11:59:06Z,"Junji Fujimoto, Mamoru Matsuo","We theoretically investigate a manipulation method of nonequilibrium spin
accumulation in the paramagnetic normal metal of a spin pumping system, by
using the spin precession motion combined with the spin diffusion transport. We
demonstrate based on the Bloch-Torrey equation that the direction of the
nonequilibrium spin accumulation is changed by applying an additional external
magnetic field, and consequently, the inverse spin Hall voltage in an adjacent
paramagnetic heavy metal changes its sign. We find that the spin relaxation
time and the spin diffusion length are simultaneously determined by changing
the magnitude of the external magnetic field and the thickness of the normal
metal in a commonly-used spin pumping system.",http://arxiv.org/abs/1907.04639v1
"Semi-implicit Euler-Maruyama method for non-linear time-changed
  stochastic differential equations",2019-07-26T07:24:14Z,"Chang-Song Deng, Wei Liu","The semi-implicit Euler-Maruyama (EM) method is investigated to approximate a
class of time-changed stochastic differential equations, whose drift
coefficient can grow super-linearly and diffusion coefficient obeys the global
Lipschitz condition. The strong convergence of the semi-implicit EM is proved
and the convergence rate is discussed. When the Bernstein function of the
inverse subordinator (time-change) is regularly varying at zero, we establish
the mean square polynomial stability of the underlying equations. In addition,
the numerical method is proved to be able to preserve such an asymptotic
property. Numerical simulations are presented to demonstrate the theoretical
results.",http://arxiv.org/abs/1907.11408v1
"On the length scale dependence of DNA conformational change under local
  perturbation",2019-11-12T07:40:23Z,"Soumyadip Banerjee, Kushal Shah, Shaunak Sen","Conformational change of a DNA molecule is frequently observed in multiple
biological processes and has been modelled using a chain of strongly coupled
oscillators with a nonlinear bistable potential. While the mechanism and
properties of conformational change in the model have been investigated and
several reduced order models developed, the conformational dynamics as a
function of the length of the oscillator chain is relatively less clear. To
address this, we used a modified Lindstedt-Poincare method and numerical
computations. We calculate a perturbation expansion of the frequency of the
model's nonzero modes, finding that approximating these modes with their
unperturbed dynamics, as in a previous reduced order model, may not hold when
the length of the DNA model increases. We investigate the conformational change
to local perturbation in models of varying lengths, finding that for chosen
input and parameters, there are two regions of DNA length in the model, first
where the minimum energy required to undergo the conformational change
increases with DNA length; and second, where it is almost independent of the
length of the DNA model. We analyze the conformational change in these models
by adding randomness to the local perturbation, finding that the tendency of
the system to remain in a stable conformation against random perturbation
decreases with an increase in the DNA length. These results should help to
understand the role of the length of a DNA molecule in influencing its
conformational dynamics.",http://arxiv.org/abs/1911.04711v2
Localizing Changes in High-Dimensional Vector Autoregressive Processes,2019-09-12T15:07:32Z,"Daren Wang, Yi Yu, Alessandro Rinaldo, Rebecca Willett","Autoregressive models capture stochastic processes in which past realizations
determine the generative distribution of new data; they arise naturally in a
variety of industrial, biomedical, and financial settings. A key challenge when
working with such data is to determine when the underlying generative model has
changed, as this can offer insights into distinct operating regimes of the
underlying system. This paper describes a novel dynamic programming approach to
localizing changes in high-dimensional autoregressive processes and associated
error rates that improve upon the prior state of the art. When the model
parameters are piecewise constant over time and the corresponding process is
piecewise stable, the proposed dynamic programming algorithm consistently
localizes change points even as the dimensionality, the sparsity of the
coefficient matrices, the temporal spacing between two consecutive change
points, and the magnitude of the difference of two consecutive coefficient
matrices are allowed to vary with the sample size. Furthermore, the accuracy of
initial, coarse change point localization estimates can be boosted via a
computationally-efficient refinement algorithm that provably improves the
localization error rate. Finally, a comprehensive simulation experiments and a
real data analysis are provided to show the numerical superiority of our
proposed methods.",http://arxiv.org/abs/1909.06359v2
"Inference on the change point with the jump size near the boundary of
  the region of detectability in high dimensional time series models",2019-09-17T21:08:15Z,"Abhishek Kaul, Venkata K Jandhyala, Stergios B Fotopoulos","We develop a projected least squares estimator for the change point parameter
in a high dimensional time series model with a potential change point.
Importantly we work under the setup where the jump size may be near the
boundary of the region of detectability. The proposed methodology yields an
optimal rate of convergence despite high dimensionality of the assumed model
and a potentially diminishing jump size. The limiting distribution of this
estimate is derived, thereby allowing construction of a confidence interval for
the location of the change point. A secondary near optimal estimate is proposed
which is required for the implementation of the optimal projected least squares
estimate. The prestep estimation procedure is designed to also agnostically
detect the case where no change point exists, thereby removing the need to
pretest for the existence of a change point for the implementation of the
inference methodology. Our results are presented under a general positive
definite spatial dependence setup, assuming no special structure on this
dependence. The proposed methodology is designed to be highly scalable, and
applicable to very large data. Theoretical results regarding detection and
estimation consistency and the limiting distribution are numerically supported
via monte carlo simulations.",http://arxiv.org/abs/1909.08101v1
Online Semi-Supervised Concept Drift Detection with Density Estimation,2019-09-25T01:47:28Z,"Chang How Tan, Vincent CS Lee, Mahsa Salehi","Concept drift is formally defined as the change in joint distribution of a
set of input variables X and a target variable y. The two types of drift that
are extensively studied are real drift and virtual drift where the former is
the change in posterior probabilities p(y|X) while the latter is the change in
distribution of X without affecting the posterior probabilities. Many
approaches on concept drift detection either assume full availability of data
labels, y or handle only the virtual drift. In a streaming environment, the
assumption of full availability of data labels, y is questioned. On the other
hand, approaches that deal with virtual drift failed to address real drift.
Rather than improving the state-of-the-art methods, this paper presents a
semi-supervised framework to deal with the challenges above. The objective of
the proposed framework is to learn from streaming environment with limited data
labels, y and detect real drift concurrently. This paper proposes a novel
concept drift detection method utilizing the densities of posterior
probabilities in partially labeled streaming environments. Experimental results
on both synthetic and realworld datasets show that our proposed semi-supervised
framework enables the detection of concept drift in such environment while
achieving comparable prediction performance to the state-of-the-art methods.",http://arxiv.org/abs/1909.11251v2
"Tangled String for Multi-Scale Explanation of Contextual Shifts in Stock
  Market",2019-01-28T00:18:34Z,"Yukio Ohsawa, Teruaki Hayashi, Takaaki Yoshino","The original research question here is given by marketers in general, i.e.,
how to explain the changes in the desired timescale of the market. Tangled
String, a sequence visualization tool based on the metaphor where contexts in a
sequence are compared to tangled pills in a string, is here extended and
diverted to detecting stocks that trigger changes in the market and to
explaining the scenario of contextual shifts in the market. Here, the
sequential data on the stocks of top 10 weekly increase rates in the First
Section of the Tokyo Stock Exchange for 12 years are visualized by Tangled
String. The changing in the prices of stocks is a mixture of various timescales
and can be explained in the time-scale set as desired by using TS. Also, it is
found that the change points found by TS coincided by high precision with the
real changes in each stock price. As TS has been created from the data-driven
innovation platform called Innovators Marketplace on Data Jackets and is
extended to satisfy data users, this paper is as evidence of the contribution
of the market of data to data-driven innovations.",http://arxiv.org/abs/1901.09469v1
A new PIR-based method for real-time tracking,2019-01-30T07:59:16Z,"Tianye Yang, Xuefeng Liu, Shaojie Tang, Jianwei Niu, Peng Guo","Pyroelectric infrared (PIR) sensors are considered to be promising devices
for device-free localization due to its advantages of low cost, less intrusive,
and the immunity from multi-path fading. However, most of the existing
PIR-based localization systems only utilize the binary information of PIR
sensors and therefore require a large number of PIR sensors and a careful
deployment. A few works directly map the raw data of PIR sensors to one's
location using machine learning approaches. However, these approaches require
to collect abundant training data and suffer from environmental change. In this
paper, we propose a PIR-based device-free localization approach based on the
raw data of PIR sensors. The key of this approach is to extract a new type of
location information called as the azimuth change. The extraction of the
azimuth change relies on the physical properties of PIR sensors. Therefore, no
abundant training data are needed and the system is robust to environmental
change. Through experiments, we demonstrated that a device-free localization
system incorporating the information of azimuth change outperforms the
state-of-the-art approaches in terms of higher location accuracy. In addition,
the information of the azimuth change can be easily integrated with other
PIR-based localization systems to improve their localization accuracy.",http://arxiv.org/abs/1901.10700v2
"Understanding extreme quasar optical variability with CRTS: II.
  Changing-state quasars",2019-05-06T21:07:49Z,"Matthew J. Graham, Nicholas P. Ross, Daniel Stern, rew J. Drake, Barry McKernan, K. E. Saavik Ford, S. G. Djorgovski, Ashish Mahabal, Eilat Glikman, Steve Larson, Eric Christensen","We present the results of a systematic search for quasars in the Catalina
Real-time Transient Survey exhibiting both strong photometric and spectroscopic
variability over a decadal baseline. We identify 73 sources with specific
patterns of optical and mid-IR photometric behavior and a defined spectroscopic
change. These ""Changing-State"" quasars (CSQs) form a higher luminosity sample
to complement existing sets of ""Changing-Look"" AGN and quasars in the
literature. The CSQs (by selection) exhibit larger photometric variability than
the CLQs. The spectroscopic variability is marginally stronger in the CSQs than
CLQs as defined by the change in H$\beta$/[OIII] ratio. We find 36 sources with
declining H$\beta$ flux, 37 sources with increasing H$\beta$ flux and discover
seven sources with $z > 0.8$, further extending the redshift arm. Our CSQ
sample compares to the literature CLQ objects in similar distributions of
H$\beta$ flux ratios and differential Eddington ratios between high (bright)
and low (dim) states. Taken as a whole, we find that this population of extreme
varying quasars is associated with changes in the Eddington ratio and the
timescales imply cooling/heating fronts propagating through the disk.",http://arxiv.org/abs/1905.02262v1
"Monitoring dynamic networks: a simulation-based strategy for comparing
  monitoring methods and a comparative study",2019-05-24T15:57:49Z,"Lisha Yu, Inez M. Zwetsloot, Nathaniel T. Stevens, James D. Wilson, Kwok Leung Tsui","Recently there has been a lot of interest in monitoring and identifying
changes in dynamic networks, which has led to the development of a variety of
monitoring methods. Unfortunately, these methods have not been systematically
compared; moreover, new methods are often designed for a specialized use case.
In light of this, we propose the use of simulation to compare the performance
of network monitoring methods over a variety of dynamic network changes. Using
our family of simulated dynamic networks, we compare the performance of several
state-of-the-art social network monitoring methods in the literature. We
compare their performance over a variety of types of change; we consider both
increases in communication levels, node propensity change as well as changes in
community structure. We show that there does not exist one method that is
uniformly superior to the others; the best method depends on the context and
the type of change one wishes to detect. As such, we conclude that a variety of
methods is needed for network monitoring and that it is important to understand
in which scenarios a given method is appropriate.",http://arxiv.org/abs/1905.10302v1
"Changes in long-term properties of the Danube river level and flow
  induced by damming",2019-05-30T16:09:49Z,"Djordje Stratimirovic, Ilija Batas-Bjelic, Vladimir Djurdjevic, Suzana Blesic","In this paper we assessed changes in scaling properties of the river Danube
level and flow data, associated with building of Djerdap/Iron Gates
hydrological power plants positioned on the border of Romania and Serbia. We
used detrended fluctuation analysis (DFA), wavelet transform spectral analysis
(WTS) and wavelet-based modulus maxima method (WTMM) to investigate time series
of river levels and river flows recorded at hydrological stations in the
vicinity of dams and in the area of up to 480 km upstream from dams, and time
series of simulated NOAA-CIRES 20th Century Global Reanalysis precipitation
records for the Djerdap/Iron Gates region. By comparing river dynamics during
the periods before and after construction of dams, we were able to register
changes in scaling that are different for recordings from upstream and from
downstream (from dams) areas. We found that damming caused appearance of
human-made or enhancement of natural cycles in the small time scales region,
which largely influenced the change in temporal scaling in downstream recording
stations. We additionally found disappearance or decline in the amplitude of
large-time-scale cycles as a result of damming, that changed the dynamics of
upstream data. The most prominent finding of our paper is a demonstration of a
complete or partial loss of annual cycles in the upstream stations' data that
we found to extend as far as 220 km from dams. We discussed probable sources of
such found changes in scaling, aiming to provide explanations that could be of
use in future environmental assessments.",http://arxiv.org/abs/1905.13144v2
"Market Dynamics: On Directional Information Derived From (Time,
  Execution Price, Shares Traded) Transaction Sequences",2019-03-27T16:29:04Z,Vladislav Gennadievich Malyshkin,"A new approach to obtaining market--directional information, based on a
non-stationary solution to the dynamic equation ""future price tends to the
value that maximizes the number of shares traded per unit time"" [1] is
presented. In our previous work[2], we established that it is the share
execution flow ($I=dV/dt$) and not the share trading volume ($V$) that is the
driving force of the market, and that asset prices are much more sensitive to
the execution flow $I$ (the dynamic impact) than to the traded volume $V$ (the
regular impact). In this paper, an important advancement is achieved: we define
the ""scalp-price"" ${\cal P}$ as the sum of only those price moves that are
relevant to market dynamics; the criterion of relevance is a high $I$. Thus,
only ""follow the market"" (and not ""little bounce"") events are included in
${\cal P}$. Changes in the scalp-price defined this way indicate a market trend
change - not a bear market rally or a bull market sell-off; the approach can be
further extended to non-local price change. The software calculating the
scalp--price given market observations triples (time, execution price, shares
traded) is available from the authors.",http://arxiv.org/abs/1903.11530v2
"ATOM: Commit Message Generation Based on Abstract Syntax Tree and Hybrid
  Ranking",2019-12-06T04:32:57Z,"Shangqing Liu, Cuiyun Gao, Sen Chen, Lun Yiu Nie, Yang Liu","Commit messages record code changes (e.g., feature modifications and bug
repairs) in natural language, and are useful for program comprehension. Due to
the frequent updates of software and time cost, developers are generally
unmotivated to write commit messages for code changes. Therefore, automating
the message writing process is necessitated. Previous studies on commit message
generation have been benefited from generation models or retrieval models, but
the code structure of changed code, i.e., AST, which can be important for
capturing code semantics, has not been explicitly involved. Moreover, although
generation models have the advantages of synthesizing commit messages for new
code changes, they are not easy to bridge the semantic gap between code and
natural languages which could be mitigated by retrieval models. In this paper,
we propose a novel commit message generation model, named ATOM, which
explicitly incorporates the abstract syntax tree for representing code changes
and integrates both retrieved and generated messages through hybrid ranking.
Specifically, the hybrid ranking module can prioritize the most accurate
message from both retrieved and generated messages regarding one code change.
We evaluate the proposed model ATOM on our dataset crawled from 56 popular Java
repositories. Experimental results demonstrate that ATOM increases the
state-of-the-art models by 30.72% in terms of BLEU-4 (an accuracy measure that
is widely used to evaluate text generation systems). Qualitative analysis also
demonstrates the effectiveness of ATOM in generating accurate code commit
messages.",http://arxiv.org/abs/1912.02972v2
Long Secondary Periods in luminous red giant variables,2019-12-21T10:55:03Z,"Masaki Takayama, Yoshifusa Ita","The origin of long secondary periods (LSPs) in red giant variables is
unknown. We investigate whether stellar pulsations in red giants can explain
the properties of the LSP variability. VIJHKs light curves obtained by OGLE and
the IRSF/SIRIUS survey in the Small Magellanic Cloud are examined. The sample
of oxygen-rich LSP stars show evidence of a phase lag between the light curves
of optical and near- IR band. The change in radius contributes the bolometric
change roughly half as much as the change in temperature, implying that the
change in effective temperature plays an important role in the luminosity
change associated with the LSPs. We have created numerical models based on the
spherical harmonics to calculate the light amplitudes of dipole mode
variability and have found that the models can roughly reproduce the amplitude
- amplitude relations (e.g. ($\Delta I$, $\Delta H$)). The LSP variability can
be reproduced by the dipole mode oscillations with temperature amplitude of
$\lesssim$ 100 K and $\lesssim$ 150 K for oxygen-rich stars and most carbon
stars, respectively. Radial pulsation models are also examined and can
reproduce the observed colour change of the LSPs. However, there is still an
inconsistency in length between the LSP and periods of radial fundamental mode.
On the other hand, theoretical PL relations of the dipole mode corresponding to
so-called oscillatory convective mode were roughly consistent with observation.
Hence our result suggests that the observations can be consistent with stellar
pulsations corresponding to oscillatory convective modes.",http://arxiv.org/abs/1912.10244v1
"Impact of requirements volatility on software architecture: How do
  software teams keep up with ever-changing requirements?",2019-04-17T10:19:02Z,"Sandun Dasanayake, Sanja Aaramaa, Jouni Markkula, Markku Oivo","Requirements volatility is a major issue in software development, causing
problems such as higher defect density, project delays and cost overruns.
Software architecture that guides the overall vision of software product, is
one of the areas that is greatly affected by requirements volatility. Since
critical architecture decisions are made based on the requirements at hand,
changes in requirements can result signifiant changes in architecture. With the
wide adoption of agile software development, software architectures are
designed to accommodate possible future changes. However, the changes has to be
carefully managed as unnecessary and excessive changes can bring negative
consequences. An exploratory case study was conducted to study the impact of
requirements volatility on software architecture. Fifteen semi-structured,
thematic interviews were conducted in a European software company. The research
revealed poor communication, information distortion, and external dependencies
as the main factors that cause requirement volatility and inadequate
architecture documentation, inability to trace design rationale, and increased
complexity as the main implications of requirements volatility on software
architecture. Insights from software teams' awareness of the requirement
volatility, factors contribute to it, and possible ways to mitigate its
implications will be utilized to improve the management of requirement
volatility during software architecting process.",http://arxiv.org/abs/1904.08164v1
Probing the top quark flavor-changing couplings at CEPC,2019-06-11T13:22:50Z,"Liaoshan Shi, Cen Zhang","We propose to study the flavor properties of the top quark at the future
Circular Electron Positron Collider (CEPC) in China. We systematically consider
the full set of 56 real parameters that characterize the flavor-changing
neutral interactions of the top quark, which can be tested at CEPC in the
single top production channel. Compared with the current bounds from the LEP2
data and the projected limits at the high-luminosity LHC, we find that CEPC
could improve the limits of the four-fermion flavor-changing coefficients by
one to two orders of magnitude, and would also provide similar sensitivity for
the two-fermion flavor-changing coefficients. Overall, CEPC could explore a
large fraction of currently allowed parameter space that will not be covered by
the LHC upgrade. We show that the $c$-jet tagging capacity at CEPC could
further improve its sensitivity to top-charm flavor-changing couplings. If a
signal is observed, the kinematic distribution as well as the $c$-jet tagging
could be exploited to pinpoint the various flavor-changing couplings, providing
valuable information about the flavor properties of the top quark.",http://arxiv.org/abs/1906.04573v3
An Integrated Image Filter for Enhancing Change Detection Results,2019-07-02T11:32:35Z,"Dawei Li, Siyuan Yan, Xin Cai, Yan Cao, Sifan Wang","Change detection is a fundamental task in computer vision. Despite
significant advances have been made, most of the change detection methods fail
to work well in challenging scenes due to ubiquitous noise and interferences.
Nowadays, post-processing methods (e.g. MRF, and CRF) aiming to enhance the
binary change detection results still fall short of the requirements on
universality for distinctive scenes, applicability for different types of
detection methods, accuracy, and real-time performance. Inspired by the nature
of image filtering, which separates noise from pixel observations and recovers
the real structure of patches, we consider utilizing image filters to enhance
the detection masks. In this paper, we present an integrated filter which
comprises a weighted local guided image filter and a weighted spatiotemporal
tree filter. The spatiotemporal tree filter leverages the global spatiotemporal
information of adjacent video frames and meanwhile the guided filter carries
out local window filtering of pixels, for enhancing the coarse change detection
masks. The main contributions are three: (i) the proposed filter can make full
use of the information of the same object in consecutive frames to improve its
current detection mask by computations on a spatiotemporal minimum spanning
tree; (ii) the integrated filter possesses both advantages of local filtering
and global filtering; it not only has good edge-preserving property but also
can handle heavily textured and colorful foreground regions; and (iii) Unlike
some popular enhancement methods (MRF, and CRF) that require either a priori
background probabilities or a posteriori foreground probabilities for every
pixel to improve the coarse detection masks, our method is a versatile
enhancement filter that can be applied after many different types of change
detection methods, and is particularly suitable for video sequences.",http://arxiv.org/abs/1907.01301v1
An aberration criterion for conditional models,2019-11-02T13:51:52Z,Ming-Chung Chang,"Conditional models with one pair of conditional and conditioned factors in
Mukerjee et al. (2017) are extended to two pairs in this paper. The extension
includes the parametrization, effect hierarchy, sufficient conditions for
universal optimality, aberration, complementary set theory and the strategy for
finding minimum aberration designs. A catalog of 16-run minimum aberration
designs under conditional models is provided. For five to twelve factors, all
16-run minimum aberration designs under conditional models are also minimum
aberration under traditional models.",http://arxiv.org/abs/1911.00717v1
Optimal Estimation of Change in a Population of Parameters,2019-11-28T07:43:03Z,"Ramya Korlakai Vinayak, Weihao Kong, Sham M. Kakade","Paired estimation of change in parameters of interest over a population plays
a central role in several application domains including those in the social
sciences, epidemiology, medicine and biology. In these domains, the size of the
population under study is often very large, however, the number of observations
available per individual in the population is very small (\emph{sparse
observations}) which makes the problem challenging. Consider the setting with
$N$ independent individuals, each with unknown parameters $(p_i, q_i)$ drawn
from some unknown distribution on $[0, 1]^2$. We observe $X_i \sim
\text{Bin}(t, p_i)$ before an event and $Y_i \sim \text{Bin}(t, q_i)$ after the
event. Provided these paired observations, $\{(X_i, Y_i) \}_{i=1}^N$, our goal
is to accurately estimate the \emph{distribution of the change in parameters},
$\delta_i := q_i - p_i$, over the population and properties of interest like
the \emph{$\ell_1$-magnitude of the change} with sparse observations ($t\ll
N$). We provide \emph{information theoretic lower bounds} on the error in
estimating the distribution of change and the $\ell_1$-magnitude of change.
Furthermore, we show that the following two step procedure achieves the optimal
error bounds: first, estimate the full joint distribution of the paired
parameters using the maximum likelihood estimator (MLE) and then estimate the
distribution of change and the $\ell_1$-magnitude of change using the joint
MLE. Notably, and perhaps surprisingly, these error bounds are of the same
order as the minimax optimal error bounds for learning the \emph{full} joint
distribution itself (in Wasserstein-1 distance); in other words, estimating the
magnitude of the change of parameters over the population is, in a minimax
sense, as difficult as estimating the full joint distribution itself.",http://arxiv.org/abs/1911.12568v1
"The common attribute shared by defects, surfaces, and nanostructures:
  the BOLS-NEP notion",2019-12-09T08:50:51Z,Chang Q Sun,"Atomic undercoordination fascinates defects, surfaces, and nanostructures in
electronic binding energy, lattice oscillation frequency, elasticity and
plasticity (IHPR), thermal stability, photon emisibility, reactivity,
dielectrics, super-hydrophobicity, spin-resolved topological edge and monolayer
high-TC superconductivity, etc., through local bond contraction, quantum
entrapment and polarization.",http://arxiv.org/abs/2001.02044v1
Multifield phonon spectrometrics of structured liquid and solid crystals,2019-12-15T08:45:48Z,Chang Q Sun,"Atomic undercoordination, charge injection, mechanical and thermal activation
mediate the properties of a material intrinsically by bond relaxation from one
equilibrium to another while the phonon spectrometrics probes the
ever-unexpected information of the binding energy density, atomic cohesive
energy, single bond force constant, crystal elastic modulus, Debye temperature
and the abundance-length-stiffness transition of bonds under perturbation.",http://arxiv.org/abs/2001.02052v1
A note on the Brauer group and the Brauer-Manin set of a product,2019-09-14T04:40:58Z,Chang Lv,"We generalize the results of Skorobogatov and Zarhin considering the
commutativity of Brauer groups (and Brauer-Manin sets) with taking product of
two varieties, by relaxing the condition that varieties are projective.",http://arxiv.org/abs/1909.06531v3
"Observation of long-term changes in the effective refractive index of
  light",2019-01-15T19:43:58Z,Adrian Melissinos,"During the LIGO S5 run (April 2006 to June 2007) preliminary data from the H1
interferometer recorded long-term changes in the effective refractive index of
light over a 14 month period. These are due to the presence of external gravity
gradients along the arms of the interferometer. After accounting for the effect
of the tides, an unexpected twice-annual modulation was observed.",http://arxiv.org/abs/1901.08442v1
On the existence of minimal models for log canonical pairs,2019-05-14T13:10:19Z,"Vladimir Lazić, Nikolaos Tsakanikas","We show that minimal models of log canonical pairs exist, assuming the
existence of minimal models of smooth varieties.",http://arxiv.org/abs/1905.05576v3
"Effect of shapes of activation functions on predictability in the echo
  state network",2019-05-22T10:07:06Z,"Hanten Chang, Shinji Nakaoka, Hiroyasu Ando","We investigate prediction accuracy for time series of Echo state networks
with respect to several kinds of activation functions. As a result, we found
that some kinds of activation functions with an appropriate nonlinearity show
high performance compared to the conventional sigmoid function.",http://arxiv.org/abs/1905.09419v1
Continuous time integration for changing type systems,2019-08-02T07:37:42Z,Sebastian Franz,"We consider variational time integration using continuous Galerkin Petrov
methods applied to evolutionary systems of changing type. We prove
optimal-order convergence of the error in a cGP-like norm and conclude the
paper with some numerical examples and conclusions.",http://arxiv.org/abs/1908.00728v3
"Second order estimates for complex Hessian equations on Hermitian
  manifolds",2019-08-09T19:06:03Z,"Weisong Dong, Chang Li","We derive second order estimates for $\chi$-plurisubharmonic solutions of
complex Hessian equations with right hand sides depending on gradients on
compact Hermitian manifolds.",http://arxiv.org/abs/1908.03599v2
Risk-neutral option pricing under GARCH intensity model,2019-08-15T03:40:48Z,Kyungsub Lee,"The risk-neutral option pricing method under GARCH intensity model is
examined. The GARCH intensity model incorporates the characteristics of
financial return series such as volatility clustering, leverage effect and
conditional asymmetry. The GARCH intensity option pricing model has flexibility
in changing the volatility according to the probability measure change.",http://arxiv.org/abs/1908.05405v1
Base Change Along the Frobenius Endomorphism and the Gorenstein Property,2019-10-27T18:09:59Z,Pinches Dirnfeld,"Let $R$ be a local ring of positive characteristic and $X$ a complex with
nonzero finitely generated homology and finite injective dimension. We prove
that if derived base change of $X$ via the Frobenius (or more generally, via a
contracting) endomorphism has finite injective dimension then $R$ is
Gorenstein.",http://arxiv.org/abs/1910.12315v2
"Caution, DOI! Bibliographic detective story in the era of digitalization",2019-03-08T11:02:54Z,Victor Kozyakin,"An example of inconsistencies in information provided by popular
bibliographic services is described and the reasons for these inconsistencies
are discussed.",http://arxiv.org/abs/1903.03366v3
Comparing $n$-dice fixing the sum of the faces,2019-11-25T20:33:54Z,Rémi Molinier,"These notes describe some results on dice comparisons when changing the
numbers on the faces while the sum of all the face stay the same.",http://arxiv.org/abs/1912.04031v3
"The Complexity of the Classification Problems of Finite-Dimensional
  Continua",2019-04-21T17:40:05Z,"Cheng Chang, Su Gao","We consider the homeomorphic classification of finite-dimensional continua as
well as several related equivalence relations. We show that, when $n \geq 2$,
the classification problem of $n$-dimensional continua is strictly more complex
than the isomorphism problem of countable graphs. We also obtain results that
compare the relative complexity of various equivalence relations.",http://arxiv.org/abs/1904.09634v1
"Least energy sign-changing solution of fractional $p$-Laplacian problems
  involving singularities",2019-06-05T18:07:24Z,"Sekhar Ghosh, Kamel Saoudi, Mouna Kratou, Debajyoti Choudhuri","In this paper we study the existence of a least energy sign-changing solution
to a nonlocal elliptic PDE involving singularity by using the Nehari manifold
method, the constraint variational method and Brouwer degree theory.",http://arxiv.org/abs/1906.02225v1
Stability in graded rings associated with commutative augmented rings,2019-07-10T08:58:25Z,Shan Chang,"Let $A$ be a commutative augmented ring and $I$ be its augmentation ideal.
This paper shows that the sequence $\{I^n/I^{n+1}\}$ becomes stationary up to
isomorphism. The result yields stability in the associated graded ring of $A$
along $I$.",http://arxiv.org/abs/1907.04579v2
Time-changed fractional Ornstein-Uhlenbeck process,2019-07-10T17:51:44Z,"Giacomo Ascione, Yuliya Mishura, Enrica Pirozzi","We define a time-changed fractional Ornstein-Uhlenbeck process by composing a
fractional Ornstein-Uhlenbeck process with the inverse of a subordinator.
Properties of the moments of such process are investigated and the existence of
the density is shown. We also provide a generalized Fokker-Planck equation for
the density of the process.",http://arxiv.org/abs/1907.04847v2
Isometries of combinatorial Banach spaces,2019-07-16T02:42:26Z,"C. Brech, V. Ferenczi, A. Tcaciuc","We prove that every isometry between two combinatorial spaces is determined
by a permutation of the canonical unit basis combined with a change of signs.
As a consequence, we show that in the case of Schreier spaces, all the
isometries are given by a change of signs of the elements of the basis. Our
results hold for both the real and the complex cases.",http://arxiv.org/abs/1907.06815v2
"Equilibrium trapping of cold atoms using dipole and radiative forces in
  an optical trap",2019-02-01T10:09:32Z,"Taro Mashimo, Masashi Abe, Satoshi Tojo","We report on highly effective trapping of cold atoms by a new method for a
stable single optical trap in the near-optical resonant regime. An optical trap
with the near-optical resonance condition consists of not only the dipole but
also the radiative forces, while a trap using a far-off resonance dominates
only the dipole force. We estimate a near-optical resonant trap for ultracold
rubidium atoms in the range between -0.373 and -2.23 THz from the resonance.
The time dependence of the trapped atoms indicates some difference of the
stable center-of-mass positions in the near-optical resonant trap, and also
indicates that the differences are caused by the change of the equilibrium
condition of the optical dipole and radiative forces. A stable position depends
only on laser detuning due to the change in the radiative force; however, the
position is ineffective against the change in the laser intensity, which
results in a change in the radiative force.",http://arxiv.org/abs/1902.00258v1
Long Term Trends in Atmospheric Pressure and its Variance,2019-02-04T17:00:02Z,"T. A. Howells, J. I. Katz","We use the Global Historical Climatology Network--daily database to calculate
trends in sea-level atmospheric pressures, their variance and the variance of
their day-to-day differences in nine regions of the world. Changes in pressure
reflect the addition of water vapor to the warming atmosphere and changes in
circulation patterns. Pressure gradients drive fronts and storm systems, and
pressure differences, a meteorological parameter distinct from temperature and
precipitation, are a proxy for storminess. In eight of nine regions the mean
sea level pressure decreased at a rate significant at the $2\sigma$ (95\%
confidence) level if correlations between stations are small, but this nominal
assumption is uncertain. We find lower bounds on the characteristic time scale
of change of the sea level pressure variance and its differences between
consecutive days. Depending on assumptions about the uncertainties of the mean
values of trends averaged over many ($> 1000$ in some regions) stations, these
lower bounds on the time scales of change of the variances range from $\sim
100$ to several thousand years. Trends in the variance of day-to-day pressure
differences are negative and nominally significant in six of nine regions.
Nominally significant trends in the pressure variances themselves are positive
in three regions and negative in one.",http://arxiv.org/abs/1902.01307v1
"Cannings models, population size changes and multiple-merger coalescents",2019-02-06T13:14:36Z,Fabian Freund,"Multiple-merger coalescents, e.g. $\Lambda$-$n$-coalescents, have been
proposed as models of the genealogy of $n$ sampled individuals for a range of
populations whose genealogical structures are not captured well by Kingman's
$n$-coalescent. $\Lambda$-$n$-coalescents can be seen as the limit process of
the discrete genealogies of Cannings models with fixed population size, when
time is rescaled and population size $N\to\infty$. As established for Kingman's
$n$-coalescent, moderate population size fluctuations in the discrete
population model should be reflected by a time-change of the limit coalescent.
For $\Lambda$-$n$-coalescents, this has been explicitly shown for only a
limited subclass of $\Lambda$-$n$-coalescents and exponentially growing
populations. This article gives a general construction of time-changed
$\Lambda$-$n$-coalescents as limits of specific Cannings models with rather
arbitrary time changes.",http://arxiv.org/abs/1902.02155v2
"The List is the Process: Reliable Pre-Integration Tracking of Commits on
  Mailing Lists",2019-02-08T15:27:24Z,"Ralf Ramsauer, Daniel Lohmann, Wolfgang Mauerer","A considerable corpus of research on software evolution focuses on mining
changes in software repositories, but omits their pre-integration history.
  We present a novel method for tracking this otherwise invisible evolution of
software changes on mailing lists by connecting all early revisions of changes
to their final version in repositories. Since artefact modifications on mailing
lists are communicated by updates to fragments (i.e., patches) only,
identifying semantically similar changes is a non-trivial task that our
approach solves in a language-independent way. We evaluate our method on
high-profile open source software (OSS) projects like the Linux kernel, and
validate its high accuracy using an elaborately created ground truth.
  Our approach can be used to quantify properties of OSS development processes,
which is an essential requirement for using OSS in reliable or safety-critical
industrial products, where certifiability and conformance to processes are
crucial. The high accuracy of our technique allows, to the best of our
knowledge, for the first time to quantitatively determine if an open
development process effectively aligns with given formal process requirements.",http://arxiv.org/abs/1902.03147v1
Iterated Belief Base Revision: A Dynamic Epistemic Logic Approach,2019-02-17T00:14:26Z,"Marlo Souza, Álvaro Moreira, Renata Vieira","AGM's belief revision is one of the main paradigms in the study of belief
change operations. In this context, belief bases (prioritised bases) have been
largely used to specify the agent's belief state - whether representing the
agent's `explicit beliefs' or as a computational model for her belief state.
While the connection of iterated AGM-like operations and their encoding in
dynamic epistemic logics have been studied before, few works considered how
well-known postulates from iterated belief revision theory can be characterised
by means of belief bases and their counterpart in a dynamic epistemic logic.
This work investigates how priority graphs, a syntactic representation of
preference relations deeply connected to prioritised bases, can be used to
characterise belief change operators, focusing on well-known postulates of
Iterated Belief Change. We provide syntactic representations of belief change
operators in a dynamic context, as well as new negative results regarding the
possibility of representing an iterated belief revision operation using
transformations on priority graphs.",http://arxiv.org/abs/1902.06178v1
A Bayesian binary algorithm for RMS-based acoustic signal segmentation,2019-02-17T19:59:36Z,"Paulo Hubert, Rebecca Killick, Alexandra Chung, Linilson Padovese","Changepoint analysis (also known as segmentation analysis) aims at analyzing
an ordered, one-dimensional vector, in order to find locations where some
characteristic of the data changes. Many models and algorithms have been
studied under this theme, including models for changes in mean and / or
variance, changes in linear regression parameters, etc. In this work, we are
interested in an algorithm for the segmentation of long duration acoustic
signals; the segmentation is based on the change of the RMS power of the
signal. We investigate a Bayesian model with two possible parameterizations,
and propose a binary algorithm in two versions, using non-informative or
informative priors. We apply our algorithm to the segmentation of annotated
acoustic signals from the Alcatrazes marine preservation park in Brazil.",http://arxiv.org/abs/1902.06315v2
Changing measurable into small accessible cardinals,2019-02-19T05:32:15Z,Mohammad Golshani,"We give a detailed proof of the properties of the usual Prikry type forcing
notion for turning a measurable cardinal into $\aleph_\omega$.",http://arxiv.org/abs/1902.06904v1
"Ternary Representation of Stochastic Change and the Origin of Entropy
  and Its Fluctuations",2019-02-25T07:05:10Z,"Hong Qian, Yu-Chen Cheng, Lowell F. Thompson","A change in a stochastic system has three representations: Probabilistic,
statistical, and informational: (i) is based on random variable
$u(\omega)\to\tilde{u}(\omega)$; this induces (ii) the probability
distributions $F_u(x)\to F_{\tilde{u}}(x)$, $x\in\mathbb{R}^n$; and (iii) a
change in the probability measure $\mathbb{P}\to\tilde{\mathbb{P}}$ under the
same observable $u(\omega)$. In the informational representation a change is
quantified by the Radon-Nikodym derivative $\ln\left( \frac{ d
\tilde{\mathbb{P}}}{ d\mathbb{P}}(\omega)\right)=-\ln\left(\frac{ d F_u}{ d
F_{\tilde{u}}}(x)\right)$ when $x=u(\omega)$. Substituting a random variable
into its own density function creates a fluctuating entropy whose expectation
has been given by Shannon. Informational representation of a deterministic
transformation on $\mathbb{R}^n$ reveals entropic and energetic terms, and the
notions of configurational entropy of Boltzmann and Gibbs, and potential of
mean force of Kirkwood. Mutual information arises for correlated $u(\omega)$
and $\tilde{u}(\omega)$; and a nonequilibrium thermodynamic entropy balance
equation is identified.",http://arxiv.org/abs/1902.09536v1
"Gait Change Detection Using Parameters Generated from Microsoft Kinect
  Coordinates",2019-02-27T00:49:31Z,"Behnam Malmir, Shing I Chang","This paper describes a method to convert Microsoft Kinect coordinates into
gait parameters in order to detect a person's gait change. The proposed method
can help quantify the progress of physical therapy. Microsoft Kinect, a popular
platform for video games, was used to generate 25 joints to form a human
skeleton, and then the proposed method converted the coordinates of selected
Kinect joints into gait parameters such as spine tilt, hip tilt, and shoulder
tilt, which were tracked over time. Sample entropy measure was then applied to
quantify the variability of each gait parameter. Male and female subjects
walked a three-meter path multiple times in initial experiments, and their
walking patterns were recorded via the proposed Kinect device through the
frontal plane. Time series of the gait parameters were generated for subjects
with and without knee braces. Sample entropy was used to transform these time
series into numerical values for comparison of these two conditions.",http://arxiv.org/abs/1902.10283v1
3D tissue reconstruction with Kinect to evaluate neck lymphedema,2019-11-02T08:37:14Z,"Gerrit Brugman, Beril Sirmacek","Lymphedema is a condition of localized tissue swelling caused by a damaged
lymphatic system. Therapy to these tissues is applied manually. Some of the
methods are lymph drainage, compression therapy or bandaging. However, the
therapy methods are still insufficiently evaluated. Especially, because of not
having a reliable method to measure the change of such a soft and flexible
tissue. In this research, our goal has been providing a 3d computer vision
based method to measure the changes of the neck tissues. To do so, we used
Kinect as a depth sensor and built our algorithms for the point cloud data
acquired from this sensor. The resulting 3D models of the patient necks are
used for comparing the models in time and measuring the volumetric changes
accurately. Our discussions with the medical doctors validate that, when used
in practice this approach would be able to give better indication on which
therapy method is helping and how the tissue is changing in time.",http://arxiv.org/abs/1911.00678v1
"Sign-Changing Points of Solutions of Homogeneous Sturm-Liouville
  Equations with Measure-Valued Coefficients",2019-11-06T02:09:39Z,"Ahmed Ghatasheh, Rudi Weikard","In this paper we investigate sign-changing points of nontrivial real-valued
solutions of homogeneous Sturm-Liouville differential equations of the form
$-d(du/d\alpha)+ud\beta=0$, where $d\alpha$ is a positive Borel measure
supported everywhere on $(a,b)$ and $d\beta$ is a locally finite real Borel
measure on $(a,b)$. Since solutions for such equations are functions of locally
bounded variation, sign-changing points are the natural generalization of
zeros. We prove that sign-changing points for each nontrivial real-valued
solution are isolated in $(a,b)$. We also prove a Sturm-type separation theorem
for two nontrivial linearly independent solutions, and conclude the paper by
proving a Sturm-type comparison theorem for two differential equations with
distinct potentials.",http://arxiv.org/abs/1911.02164v1
Improving Robustness of Task Oriented Dialog Systems,2019-11-12T21:34:15Z,"Arash Einolghozati, Sonal Gupta, Mrinal Mohit, Rushin Shah","Task oriented language understanding in dialog systems is often modeled using
intents (task of a query) and slots (parameters for that task). Intent
detection and slot tagging are, in turn, modeled using sentence classification
and word tagging techniques respectively. Similar to adversarial attack
problems with computer vision models discussed in existing literature, these
intent-slot tagging models are often over-sensitive to small variations in
input -- predicting different and often incorrect labels when small changes are
made to a query, thus reducing their accuracy and reliability. However,
evaluating a model's robustness to these changes is harder for language since
words are discrete and an automated change (e.g. adding `noise') to a query
sometimes changes the meaning and thus labels of a query. In this paper, we
first describe how to create an adversarial test set to measure the robustness
of these models. Furthermore, we introduce and adapt adversarial training
methods as well as data augmentation using back-translation to mitigate these
issues. Our experiments show that both techniques improve the robustness of the
system substantially and can be combined to yield the best results.",http://arxiv.org/abs/1911.05153v1
Online detection of cascading change-points,2019-10-28T19:19:42Z,"Rui Zhang, Yao Xie, Rui Yao, Feng Qiu","We propose an online detection procedure for cascading failures in the
network from sequential data, which can be modeled as multiple correlated
change-points happening during a short period. We consider a temporal diffusion
network model to capture the temporal dynamic structure of multiple
change-points and develop a sequential Shewhart procedure based on the
generalized likelihood ratio statistics based on the diffusion network model
assuming unknown post-change distribution parameters. We also tackle the
computational complexity posed by the unknown propagation. Numerical
experiments demonstrate the good performance for detecting cascade failures.",http://arxiv.org/abs/1911.05610v4
"First-order magnetic phase-transition of mobile electrons in monolayer
  MoS$_2$",2019-11-22T20:20:55Z,"Jonas Gaël Roch, Dmitry Miserev, Guillaume Froehlicher, Nadine Leisgang, Lukas Sponfeldner, Kenji Watanabe, Takashi Taniguchi, Jelena Klinovaja, Daniel Loss, Richard John Warburton","Evidence is presented for a first-order magnetic phase transition in a gated
two-dimensional semiconductor, monolayer-MoS$_2$. The phase boundary separates
a spin-polarised (ferromagnetic) phase at low electron density and a
paramagnetic phase at high electron density. Abrupt changes in the optical
response signal an abrupt change in the magnetism. The magnetic order is
thereby controlled via the voltage applied to the gate electrode of the device.
Accompanying the change in magnetism is a large change in the electron
effective mass.",http://arxiv.org/abs/1911.10238v1
Field choice problem in persistent homology,2019-11-26T05:45:14Z,"Ippei Obayashi, Michio Yoshiwaki","This paper tackles the problem of coefficient field choice in persistent
homology. When we compute a persistence diagram, we need to select a
coefficient field before computation. We should understand the dependency of
the diagram on the coefficient field to facilitate computation and
interpretation of the diagram. We clarify that the dependency is strongly
related to the torsion of $\mathbb{Z}$ relative homology in the filtration. We
show the sufficient and necessary conditions of the independence of coefficient
field choice. An efficient algorithm is proposed to verify the independence. In
a numerical experiment with the algorithm, a persistence diagram rarely changes
even when the coefficient field changes if we consider a filtration in
$\mathbb{R}^3$. The experiment suggests that, in practical terms, changes in
the field coefficient will not change persistence diagrams when the data are in
$\mathbb{R}^3$.",http://arxiv.org/abs/1911.11350v3
AI and Medicine,2019-12-05T21:58:18Z,Mihai Nadin,"Which part of medicine, if any, can and should be entrusted to AI, now or at
some moment in the future? That both medicine and AI will continue to change
goes without saying.",http://arxiv.org/abs/2001.00641v1
"AU Pegasi revisited: period evolution and orbital elements of a peculiar
  Type II Cepheid",2019-09-03T15:37:43Z,"Géza Csörnyei, László Szabados","New analysis on the period changes of Type II Cepheid AU Peg is presented.
The available recent photometric measurements were collected and analysed with
various methods. The period has been found to be constant for certain time
intervals, although increasing in overall, in contrast with the previous
expectations, which suggested the period change to reverse. Superimposed on
overall period change, a formerly unknown periodic behaviour has been found in
the $O-C$ diagram of AU Peg, which cannot be matched to the radial velocity
variations. Since the Cepheid is a member of a binary system, it is probable
that the unusual period change is in connection with the companion's tidal
force. The orbital elements of the binary system involving AU Peg have been
also revised.",http://arxiv.org/abs/1909.01255v1
"Morphology and magnetic properties of nanocomposite magnetic multilayers
  {[(Co$_{40}$Fe$_{40}$B$_{20}$)$_{34}$(SiO$_2$)$_{66}$]/[C]}$_{47}$",2019-09-08T10:10:27Z,"V. Ukleev, E. Dyadkina, A. Vorobiev, O. V. Gerashchenko, L. Caron, A. V. Sitnikov, Yu. E. Kalinin, S. V. Grigoriev","We report on the investigation of morphology, magnetic and conductive
properties of the mutilayered nanostructures
[(Co$_{40}$Fe$_{40}$B$_{20}$)$_{34}$(SiO$_2$)$_{66}$]/[C]$_{47}$ consisting of
the contacting magnetic (Co$_{40}$Fe$_{40}$B$_{20}$)$_{34}$(SiO$_2$)$_{66}$
nanocomposite and amorphous semiconductor carbon C layers. It is shown by
Grazing-Incidence Small-Angle X-ray Scattering method that the ordering and the
size of nanoparticles in the magnetic layers do not change profoundly with
increasing of carbon layer thickness. Meanwhile, the electrical conductance and
the magnetic properties are significantly varied: resistance of the samples
changes by four orders of magnitude and superparamagnetic blocking temperature
changes from 15 K to 7 K with the increment of carbon layer thickness $h_c$
from 0.4 nm to 1.8 nm. We assume that the formation of the homogeneous
semiconductor interlayer leads to modification of the metal-insulator growth
process that drives the changes in the magnetic and conductive properties.",http://arxiv.org/abs/1909.03420v1
Estimating change points in nonparametric time series regression models,2019-09-16T13:16:14Z,"Maria Mohr, Leonie Selk","In this paper we consider a regression model that allows for time series
covariates as well as heteroscedasticity with a regression function that is
modelled nonparametrically. We assume that the regression function changes at
some unknown time $\lfloor ns_0\rfloor$, $s_0\in(0,1)$, and our aim is to
estimate the (rescaled) change point $s_0$. The considered estimator is based
on a Kolmogorov-Smirnov functional of the marked empirical process of
residuals. We show consistency of the estimator and prove a rate of convergence
of $O_P(n^{-1})$ which in this case is clearly optimal as there are only $n$
points in the sequence. Additionally we investigate the case of lagged
dependent covariates, that is, autoregression models with a change in the
nonparametric (auto-) regression function and give a consistency result. The
method of proof also allows for different kinds of functionals such that
Cram\'er-von Mises type estimators can be considered similarly. The approach
extends existing literature by allowing nonparametric models, time series data
as well as heteroscedasticity. Finite sample simulations indicate the good
performance of our estimator in regression as well as autoregression models and
a real data example shows its applicability in practise.",http://arxiv.org/abs/1909.07178v1
Charged lepton flavour change and Non-Standard neutrino Interactions,2019-09-16T18:00:59Z,"Sacha Davidson, Martin Gorbahn","Non-Standard neutrino Interactions (NSI) are vector contact interactions
involving two neutrinos and two first generation fermions, which can affect
neutrino propagation in matter. SU(2) gauge invariance suggests that NSI should
be accompanied by more observable charged lepton contact interactions. However,
these can be avoided at tree level in various ways. We focus on lepton
flavour-changing NSI, suppose they are generated by New Physics heavier than
$m_W$ that does not induce (charged) Lepton Flavour Violation (LFV) at tree
level, and show that LFV is generated at one loop in most cases. The current
constraints on charged Lepton Flavour Violation therefore suggest that mu <--->
e flavour-changing NSI are unobservable and tau <---> l flavour-changing NSI
are an order of magnitude weaker than the weak interactions. This conclusion
can be avoided if the heavy New Physics conspires to cancel the one-loop LFV,
or if NSI are generated by light New Physics to which our analysis does not
apply.",http://arxiv.org/abs/1909.07406v2
"Spin-Orbit-Torque Field-Effect Transistor (SOTFET): Proposal for a New
  Magnetoelectric Memory",2019-09-17T22:46:55Z,"Xiang Li, Phillip Dang, Joseph Casamento, Zexuan Zhang, Olalekan Afuye, Antonio B. Mei, Alyssa B. Apsel, Darrell G. Schlom, Debdeep Jena, Daniel C. Ralph, Huili Grace Xing","Spin-based memories are attractive for their non-volatility and high
durability but provide modest resistance changes, whereas semiconductor logic
transistors are capable of large resistance changes, but lack memory function
with high durability. The recent availability of multiferroic materials
provides an opportunity to directly couple the change in spin states of a
magnetic memory to a charge change in a semiconductor transistor. In this work,
we propose and analyze the spin-orbit torque field-effect transistor (SOTFET),
a device with the potential to significantly boost the energy efficiency of
spin-based memories, and to simultaneously offer a palette of new
functionalities.",http://arxiv.org/abs/1909.08133v3
Polynomial 3-mixing for smooth time-changes of horocycle flows,2019-09-19T04:30:53Z,"Adam Kanigowski, Davide Ravotti","Let $(h_t)_{t\in \mathbb{R}}$ be the horocycle flow acting on
$(M,\mu)=(\Gamma \backslash \text{SL}(2,\mathbb{R}),\mu)$, where $\Gamma$ is a
co-compact lattice in $\text{SL}(2,\mathbb{R})$ and $\mu$ is the homogeneous
probability measure locally given by the Haar measure on
$\text{SL}(2,\mathbb{R})$. Let $\tau\in W^6(M)$ be a strictly positive function
and let $\mu^{\tau}$ be the measure equivalent to $\mu$ with density $\tau$. We
consider the time changed flow $(h_t^\tau)_{t\in \mathbb{R}}$ and we show that
there exists $\gamma=\gamma(M,\tau)>0$ and a constant $C>0$ such that for any $
f_0, f_1, f_2\in W^6(M)$ and for all $0=t_0<t_1<t_2$, we have $$\ \left|\int_M
\prod_{i=0}^{2} f_i\circ h^\tau_{t_i} d \mu^\tau -\prod_{i=0}^{2}\int_M f_i d
\mu^\tau \right|\leq C \left(\prod_{i=0}^{2} \|f_i\|_6\right) \left(\min_{0\leq
i<j\leq 2} |t_i-t_j|\right)^{-\gamma}.$$ With the same techniques, we establish
polynomial mixing of all orders under the additional assumption of $\tau$ being
fully supported on the discrete series.",http://arxiv.org/abs/1909.08799v2
Stock Prices Prediction using Deep Learning Models,2019-09-25T11:38:25Z,"Jialin Liu, Fei Chao, Yu-Chen Lin, Chih-Min Lin","Financial markets have a vital role in the development of modern society.
They allow the deployment of economic resources. Changes in stock prices
reflect changes in the market. In this study, we focus on predicting stock
prices by deep learning model. This is a challenge task, because there is much
noise and uncertainty in information that is related to stock prices. So this
work uses sparse autoencoders with one-dimension (1-D) residual convolutional
networks which is a deep learning model, to de-noise the data. Long-short term
memory (LSTM) is then used to predict the stock price. The prices, indices and
macroeconomic variables in past are the features used to predict the next day's
price. Experiment results show that 1-D residual convolutional networks can
de-noise data and extract deep features better than a model that combines
wavelet transforms (WT) and stacked autoencoders (SAEs). In addition, we
compare the performances of model with two different forecast targets of stock
price: absolute stock price and price rate of change. The results show that
predicting stock price through price rate of change is better than predicting
absolute prices directly.",http://arxiv.org/abs/1909.12227v1
"Modeling and Quantifying the Impact of Wind Power Penetration on Power
  System Coherency",2019-01-07T23:07:01Z,"Sayak Mukherjee, Aranya Chakrabortty, Saman Babaei","This paper presents a mathematical analysis of how wind generation impacts
the coherency property of power systems. Coherency arises from time-scale
separation in the dynamics of synchronous generators, where generator states
inside a coherent area synchronize over a fast time-scale due to stronger
coupling, while the areas themselves synchronize over a slower time-scale due
to weaker coupling. This time-scale separation is reflected in the form of a
spectral separation in the weighted Laplacian matrix describing the swing
dynamics of the generators. However, when wind farms with doubly-fed induction
generators (DFIG) are integrated in the system then this Laplacian matrix
changes based on both the level of wind penetration and the location of the
wind farms. The modified Laplacian changes the effective slow eigenspace of the
generators. Depending on penetration level, this change may result in changing
the identities of the coherent areas. We develop a theoretical framework to
quantify this modification, and validate our results with numerical simulations
of the IEEE 68-bus system with one and multiple wind farms. We compare our
model based results on clustering with results using measurement-based
principal component analysis to substantiate our derivations.",http://arxiv.org/abs/1901.02098v1
"Nonparametric Multiple Change Point Detection for Non-Stationary Times
  Series",2019-01-10T06:48:43Z,"Zixiang Guan, Gemai Chen","This article considers a nonparametric method for detecting change points in
non-stationary time series. The proposed method will divide the time series
into several segments so that between two adjacent segments, the normalized
spectral density functions are different. The theory is based on the assumption
that within each segment, time series is a linear process, which means that our
method works not only for classic time series models, e.g., causal and
invertible ARMA process, but also preserves good performance for non-invertible
moving average process. We show that our estimations for change points are
consistent. Also, a Bayesian information criterion is applied to estimate the
member of change points consistently. Simulation results as well as empirical
results will be presented.",http://arxiv.org/abs/1901.03036v3
A Hybrid HMM Approach for the Dynamics of DNA Methylation,2019-01-18T14:55:08Z,"Charalampos Kyriakopoulos, Pascal Giehr, Alexander Lück, Jörn Walter, Verena Wolf","The understanding of mechanisms that control epigenetic changes is an
important research area in modern functional biology. Epigenetic modifications
such as DNA methylation are in general very stable over many cell divisions.
DNA methylation can however be subject to specific and fast changes over a
short time scale even in non-dividing (i.e. not-replicating) cells. Such
dynamic DNA methylation changes are caused by a combination of active
demethylation and de novo methylation processes which have not been
investigated in integrated models. Here we present a hybrid (hidden) Markov
model to describe the cycle of methylation and demethylation over (short) time
scales. Our hybrid model decribes several molecular events either happening at
deterministic points (i.e. describing mechanisms that occur only during cell
division) and other events occurring at random time points. We test our model
on mouse embryonic stem cells using time-resolved data. We predict methylation
changes and estimate the efficiencies of the different modification steps
related to DNA methylation and demethylation.",http://arxiv.org/abs/1901.06286v1
"Modeling the Biological Pathology Continuum with HSIC-regularized
  Wasserstein Auto-encoders",2019-01-20T03:40:55Z,"Denny Wu, Hirofumi Kobayashi, Charles Ding, Lei Cheng, Keisuke Goda Marzyeh Ghassemi","A crucial challenge in image-based modeling of biomedical data is to identify
trends and features that separate normality and pathology. In many cases, the
morphology of the imaged object exhibits continuous change as it deviates from
normality, and thus a generative model can be trained to model this
morphological continuum. Moreover, given side information that correlates to
certain trend in morphological change, a latent variable model can be
regularized such that its latent representation reflects this side information.
In this work, we use the Wasserstein Auto-encoder to model this pathology
continuum, and apply the Hilbert-Schmitt Independence Criterion (HSIC) to
enforce dependency between certain latent features and the provided side
information. We experimentally show that the model can provide disentangled and
interpretable latent representations and also generate a continuum of
morphological changes that corresponds to change in the side information.",http://arxiv.org/abs/1901.06618v1
Flavor changing in the flipped trinification,2019-01-23T15:59:19Z,"D. N. Dinh, D. T. Huong, N. T. Duy, N. T. Nhuan, L. D. Thien, Phung Van Dong","The flipped trinification, a framework for unifying the 3-3-1 and left-right
symmetries, has recently been proposed in order to solve profound questions,
the weak parity violation and the number of families, besides the implication
for neutrino mass generation and dark matter stability. In this work, we argue
that this gauge-completion naturally provides flavor-changing neutral currents
in both quark and lepton sectors. The quark flavor changing happens at the
tree-level due to the nonuniversal couplings of $Z'_{L,R}$, while the lepton
flavor changing $l\rightarrow l'\gamma$ starts from the one loop level
contributed significantly by the new charged currents of $Y_{L,R}$, which
couple ordinary to exotic leptons. These effects disappear in the minimal
left-right model, but are present in the framework characterizing a flipped
trinification symmetry.",http://arxiv.org/abs/1901.07969v1
"Deep Learning for Multi-Scale Changepoint Detection in Multivariate Time
  Series",2019-05-16T17:17:55Z,"Zahra Ebrahimzadeh, Min Zheng, Selcuk Karakas, Samantha Kleinberg","Many real-world time series, such as in health, have changepoints where the
system's structure or parameters change. Since changepoints can indicate
critical events such as onset of illness, it is highly important to detect
them. However, existing methods for changepoint detection (CPD) often require
user-specified models and cannot recognize changes that occur gradually or at
multiple time-scales. To address both, we show how CPD can be treated as a
supervised learning problem, and propose a new deep neural network architecture
to efficiently identify both abrupt and gradual changes at multiple timescales
from multivariate data. Our proposed pyramid recurrent neural network (PRN)
provides scale-invariance using wavelets and pyramid analysis techniques from
multi-scale signal processing. Through experiments on synthetic and real-world
datasets, we show that PRN can detect abrupt and gradual changes with higher
accuracy than the state of the art and can extrapolate to detect changepoints
at novel scales not seen in training.",http://arxiv.org/abs/1905.06913v1
"Distinguished representations, Shintani base change and a finite field
  analogue of a conjecture of Prasad",2019-05-29T04:08:52Z,Chang Yang,"Let $E/F$ be a quadratic extension of fields, and $G$ a connected quasi-split
reductive group over $F$. Let $G^{op}$ be the opposition group obtained by
twisting $G$ by the duality involution considered by Prasad. Assume that the
field $F$ is finite. Let $\pi$ be an irreducible generic representation of
$G(E)$. When $\pi$ is a Shintani base change lift of some representation of
$G^{op}(F)$, we give an explicit nonzero $G(F)$-invariant vector in terms of
the Whittaker vector of $\pi$. This shows particularly that $\pi$ is
$G(F)$-distinguished.
  When the field $F$ is $p$-adic, the paper also proves that the duality
involution takes an irreducible admissible generic representation of $G(F)$ to
its contragredient. As a special case of this result, all generic
representations of $G_2,\ F_4$ or $E_8$ are self-dual.",http://arxiv.org/abs/1905.12205v3
"Crystalline droplets with emergent topological color-charge in many-body
  systems with sign-changing interactions",2019-05-30T17:57:09Z,"P. Karpov, F. Piazza","We introduce a novel type of self-bound droplet which carries an emergent
color charge. We consider a system of particles hopping on a lattice and
interacting via a commensurately sign-changing potential which is attractive at
a short range. The droplet formation is heralded by spontaneous crystallization
into topologically distinct domains. This endows each droplet with an emergent
color charge governing their mutual interactions: attractive for equal colors
and repulsive otherwise. The number of allowed colors is fixed only by the
discrete spatial symmetries of the sign-changing part of the interaction
potential. With increasing interaction range, the droplets become progressively
more mobile, with their color charge still being energetically protected,
allowing for nontrivial viscous dynamics of the interacting droplet plasmas
formed during cooling. Sign-changing potentials with a short-range attraction
appear quite naturally for light-mediated interactions and we concretely
propose a realization in state-of-the-art experiments with cold atoms in a
multimode optical cavity.",http://arxiv.org/abs/1905.13217v2
"Scalable Place Recognition Under Appearance Change for Autonomous
  Driving",2019-08-01T02:04:27Z,"Anh-Dzung Doan, Yasir Latif, Tat-Jun Chin, Yu Liu, Thanh-Toan Do, Ian Reid","A major challenge in place recognition for autonomous driving is to be robust
against appearance changes due to short-term (e.g., weather, lighting) and
long-term (seasons, vegetation growth, etc.) environmental variations. A
promising solution is to continuously accumulate images to maintain an adequate
sample of the conditions and incorporate new changes into the place recognition
decision. However, this demands a place recognition technique that is scalable
on an ever growing dataset. To this end, we propose a novel place recognition
technique that can be efficiently retrained and compressed, such that the
recognition of new queries can exploit all available data (including recent
changes) without suffering from visible growth in computational cost.
Underpinning our method is a novel temporal image matching technique based on
Hidden Markov Models. Our experiments show that, compared to state-of-the-art
techniques, our method has much greater potential for large-scale place
recognition for autonomous driving.",http://arxiv.org/abs/1908.00178v1
Derivation of non-classical stochastic price dynamics equations,2019-08-03T01:28:09Z,"Carey Caginalp, Gunduz Caginalp","We analyze the relative price change of assets starting from basic
supply/demand considerations subject to arbitrary motivations. The resulting
stochastic differential equation has coefficients that are functions of supply
and demand. We derive these rigorously. The variance in the relative price
change is then also dependent on the supply and demand, and is closely
connected to the expected return. An important consequence for risk assessment
and options pricing is the implication that variance is highest when the
magnitude of price change is greatest, and lowest near market extrema. This
occurs even if supply and demand are not dependent on price trend. The
stochastic equation differs from the standard equation in mathematical finance
in which the expected return and variance are decoupled. The methodology has
implications for the basic framework for risk assessment, suggesting that
volatility should be measured in the context of regimes of price change. The
model we propose shows how investors are often misled by the apparent calm of
markets near a market peak. Risk assessment methods utilizing volatility can be
improved using this formulation.",http://arxiv.org/abs/1908.01103v2
"Gordian complexes of knots and virtual knots given by region crossing
  changes and arc shift moves",2019-08-15T00:50:03Z,"Amrendra Gill, Madeti Prabhakar, Andrei Vesnin","Gordian complex of knots was defined by Hirasawa and Uchida as the simplicial
complex whose vertices are knot isotopy classes in $\mathbb{S}^3$. Later
Horiuchi and Ohyama defined Gordian complex of virtual knots using $v$-move and
forbidden moves. In this paper we discuss Gordian complex of knots by region
crossing change and Gordian complex of virtual knots by arc shift move. Arc
shift move is a local move in the virtual knot diagram which results in
reversing orientation locally between two consecutive crossings. We show the
existence of an arbitrarily high dimensional simplex in both the Gordian
complexes, i.e., by region crossing change and by the arc shift move. For any
given knot (respectively, virtual knot) diagram we construct an infinite family
of knots (respectively, virtual knots) such that any two distinct members of
the family have distance one by region crossing change (respectively, arc shift
move). We show that that the constructed virtual knots have the same affine
index polynomial.",http://arxiv.org/abs/1908.05382v1
"Fine-Grained Segmentation Networks: Self-Supervised Segmentation for
  Improved Long-Term Visual Localization",2019-08-18T07:13:26Z,"Måns Larsson, Erik Stenborg, Carl Toft, Lars Hammarstrand, Torsten Sattler, Fredrik Kahl","Long-term visual localization is the problem of estimating the camera pose of
a given query image in a scene whose appearance changes over time. It is an
important problem in practice, for example, encountered in autonomous driving.
In order to gain robustness to such changes, long-term localization approaches
often use segmantic segmentations as an invariant scene representation, as the
semantic meaning of each scene part should not be affected by seasonal and
other changes. However, these representations are typically not very
discriminative due to the limited number of available classes. In this paper,
we propose a new neural network, the Fine-Grained Segmentation Network (FGSN),
that can be used to provide image segmentations with a larger number of labels
and can be trained in a self-supervised fashion. In addition, we show how FGSNs
can be trained to output consistent labels across seasonal changes. We
demonstrate through extensive experiments that integrating the fine-grained
segmentations produced by our FGSNs into existing localization algorithms leads
to substantial improvements in localization performance.",http://arxiv.org/abs/1908.06387v1
"Lexical Features Are More Vulnerable, Syntactic Features Have More
  Predictive Power",2019-09-30T19:34:45Z,"Jekaterina Novikova, Aparna Balagopalan, Ksenia Shkaruta, Frank Rudzicz","Understanding the vulnerability of linguistic features extracted from noisy
text is important for both developing better health text classification models
and for interpreting vulnerabilities of natural language models. In this paper,
we investigate how generic language characteristics, such as syntax or the
lexicon, are impacted by artificial text alterations. The vulnerability of
features is analysed from two perspectives: (1) the level of feature value
change, and (2) the level of change of feature predictive power as a result of
text modifications. We show that lexical features are more sensitive to text
modifications than syntactic ones. However, we also demonstrate that these
smaller changes of syntactic features have a stronger influence on
classification performance downstream, compared to the impact of changes to
lexical features. Results are validated across three datasets representing
different text-classification tasks, with different levels of lexical and
syntactic complexity of both conversational and written language.",http://arxiv.org/abs/1910.00065v1
An introduction to flexible methods for policy evaluation,2019-10-01T19:59:51Z,Martin Huber,"This chapter covers different approaches to policy evaluation for assessing
the causal effect of a treatment or intervention on an outcome of interest. As
an introduction to causal inference, the discussion starts with the
experimental evaluation of a randomized treatment. It then reviews evaluation
methods based on selection on observables (assuming a quasi-random treatment
given observed covariates), instrumental variables (inducing a quasi-random
shift in the treatment), difference-in-differences and changes-in-changes
(exploiting changes in outcomes over time), as well as regression
discontinuities and kinks (using changes in the treatment assignment at some
threshold of a running variable). The chapter discusses methods particularly
suited for data with many observations for a flexible (i.e. semi- or
nonparametric) modeling of treatment effects, and/or many (i.e. high
dimensional) observed covariates by applying machine learning to select and
control for covariates in a data-driven way. This is not only useful for
tackling confounding by controlling for instance for factors jointly affecting
the treatment and the outcome, but also for learning effect heterogeneities
across subgroups defined upon observable covariates and optimally targeting
those groups for which the treatment is most effective.",http://arxiv.org/abs/1910.00641v1
"Concept Drift Detection and Adaptation with Weak Supervision on
  Streaming Unlabeled Data",2019-10-02T16:33:51Z,Abhijit Suprem,"Concept drift in learning and classification occurs when the statistical
properties of either the data features or target change over time; evidence of
drift has appeared in search data, medical research, malware, web data, and
video. Drift adaptation has not yet been addressed in high dimensional, noisy,
low-context data such as streaming text, video, or images due to the unique
challenges these domains present. We present a two-fold approach to deal with
concept drift in these domains: a density-based clustering approach to deal
with virtual concept drift (change in statistical properties of features) and a
weak-supervision step to deal with real concept drift (change in statistical
properties of target). Our density-based clustering avoids problems posed by
the curse of dimensionality to create an evolving 'map' of the live data space,
thereby addressing virtual drift in features. Our weak-supervision step
leverages high-confidence labels (oracle or heuristic labels) to generate
weighted training sets to generalize and update existing deep learners to adapt
to changing decision boundaries (real drift) and create new deep learners for
unseen regions of the data space. Our results show that our two-fold approach
performs well with >90% precision in 2018, four years after initial deployment
in 2014, without any human intervention.",http://arxiv.org/abs/1910.01064v1
"Two New ""Turn-off"" Changing-look Active Galactic nuclei and Implication
  on ""Partially Obscured"" AGNs",2019-10-06T07:38:31Z,"J. Wang, D. W. Xu, Y. Wang, J. B. Zhang, J. Zheng, J. Y. Wei","We here report a spectroscopic identification of two new changing-look AGNs
(CL-AGNs): SDSS\,J104705.16+544405.8 and SDSS\,J120447.91+170256.8 both with a
""turn-off"" type transition from type 1 to type 1.8/1.9. The identification is
arrived by a follow-up spectroscopic observation of the five changing-look AGN
(CL-AGN) candidates that are extracted from the sample recently released in
Macleod et al. The candidates are extract by the authors from the Sloan Digit
Sky Survey Data Release 7 spectroscopically confirmed quasars with large
amplitude variability. By compiling a sample of 26 previously identified
CL-AGNs, we confirm the claim in Macleod et al. that CL-AGNs tend to be biased
against low Eddington ratio, and identify an overlap between the CL-AGNs at
their dim state and the so-called intermediate-type AGNs. The overlap implies
that there two populations of the intermediate-type AGNs with different
origins. One is due to the torus orientation effect, and the another the
intrinsic change of the accretion rate of the central supermassive blackholes.",http://arxiv.org/abs/1910.02392v1
"Force Field Generalization and the Internal Representation of Motor
  Learning",2019-10-07T21:07:32Z,"Alireza Rezazadeh, Max Berniker","When learning a new motor behavior, e.g. reaching in a force field, the
nervous system builds an internal representation. Examining how subsequent
reaches in unpracticed directions generalize reveals this representation.
Though it is the subject of frequent studies, it is not known how this
representation changes across training directions, or how changes in reach
direction and the corresponding changes in limb impedance, influence
measurements of it. We ran a force field adaptation experiment using eight
groups of subjects each trained on one of eight standard directions and then
tested for generalization in the remaining seven directions. Generalization in
all directions was local and asymmetric, providing limited and unequal transfer
to the left and right side of the trained target. These asymmetries were not
consistent in either magnitude or direction even after correcting for changes
in limb impedance, at odds with previous explanations. Relying on a standard
model for generalization the inferred representations inconsistently shifted to
one side or the other of their respective training direction. A second model
that accounted for limb impedance and variations in baseline trajectories
explained more data and the inferred representations were centered on their
respective training directions. Our results highlight the influence of limb
mechanics and impedance on psychophysical measurements and their
interpretations for motor learning.",http://arxiv.org/abs/1910.03087v1
Free Expansion of Yukawa Gas in the Constant Plasma Background,2019-10-14T18:18:55Z,"Manish K. Shukla, K. Avinash","We discuss the irreversible free expansion phenomenon for Yukawa gas and
obtain the corresponding change in temperature of the gas. In our expansion
scheme, the system is not allowed to exchange heat with surroundings during
free expansion, therefore, present expansion scheme refers to adiabatic free
expansion. Using first principle classical Molecular Dynamics (MD) simulation
with reflecting boundary conditions, we show that the Yukawa gases exhibits
heating effect during the process of adiabatic free expansion. We also obtain
the scaling for change in temperature and establish that the change in
temperature is directly proportional to the change in number density of gas.
The scaling for temperature is also obtained analytically taking the mean field
limit of thermodynamic model proposed by Avinash. The simulation results are
consistent with the analytical results.",http://arxiv.org/abs/1910.06364v1
"Detecting Urban Changes with Recurrent Neural Networks from
  Multitemporal Sentinel-2 Data",2019-10-17T09:15:43Z,"Maria Papadomanolaki, Sagar Verma, Maria Vakalopoulou, Siddharth Gupta, Konstantinos Karantzalos","\begin{abstract} The advent of multitemporal high resolution data, like the
Copernicus Sentinel-2, has enhanced significantly the potential of monitoring
the earth's surface and environmental dynamics. In this paper, we present a
novel deep learning framework for urban change detection which combines
state-of-the-art fully convolutional networks (similar to U-Net) for feature
representation and powerful recurrent networks (such as LSTMs) for temporal
modeling. We report our results on the recently publicly available bi-temporal
Onera Satellite Change Detection (OSCD) Sentinel-2 dataset, enhancing the
temporal information with additional images of the same region on different
dates. Moreover, we evaluate the performance of the recurrent networks as well
as the use of the additional dates on the unseen test-set using an ensemble
cross-validation strategy. All the developed models during the validation phase
have scored an overall accuracy of more than 95%, while the use of LSTMs and
further temporal information, boost the F1 rate of the change class by an
additional 1.5%.",http://arxiv.org/abs/1910.07778v1
"Learning the piece-wise constant graph structure of a varying Ising
  model",2019-10-18T17:20:37Z,"Batiste Le Bars, Pierre Humbert, Argyris Kalogeratos, Nicolas Vayatis","This work focuses on the estimation of multiple change-points in a
time-varying Ising model that evolves piece-wise constantly. The aim is to
identify both the moments at which significant changes occur in the Ising
model, as well as the underlying graph structures. For this purpose, we propose
to estimate the neighborhood of each node by maximizing a penalized version of
its conditional log-likelihood. The objective of the penalization is twofold:
it imposes sparsity in the learned graphs and, thanks to a fused-type penalty,
it also enforces them to evolve piece-wise constantly. Using few assumptions,
we provide two change-points consistency theorems. Those are the first in the
context of unknown number of change-points detection in time-varying Ising
model. Finally, experimental results on several synthetic datasets and a
real-world dataset demonstrate the performance of our method.",http://arxiv.org/abs/1910.08512v2
Processing Large Datasets of Fined Grained Source Code Changes,2019-10-20T06:27:25Z,"Stanislav Levin, Amiram Yehudai","In the era of Big Code, when researchers seek to study an increasingly large
number of repositories to support their findings, the data processing stage may
require manipulating millions and more of records.
  In this work we focus on studies involving fine-grained AST level source code
changes. We present how we extended the CodeDistillery source code mining
framework with data manipulation capabilities, aimed to alleviate the
processing of large datasets of fine grained source code changes. The
capabilities we have introduced allow researchers to highly automate their
repository mining process and streamline the data acquisition and processing
phases. These capabilities have been successfully used to conduct a number of
studies, in the course of which dozens of millions of fine-grained source code
changes have been processed.",http://arxiv.org/abs/1910.08908v1
Spectral CUSUM for Online Network Structure Change Detection,2019-10-20T23:47:33Z,"Minghe Zhang, Liyan Xie, Yao Xie","Detecting abrupt changes in the community structure of a network from noisy
observations is a fundamental problem in statistics and machine learning. This
paper presents an online change detection algorithm called Spectral-CUSUM to
detect unknown network structure changes through a generalized likelihood ratio
statistic. We characterize the average run length (ARL) and the expected
detection delay (EDD) of the Spectral-CUSUM procedure and prove its asymptotic
optimality. Finally, we demonstrate the good performance of the Spectral-CUSUM
procedure and compare it with several baseline methods using simulations and
real data examples on seismic event detection using sensor network data.",http://arxiv.org/abs/1910.09083v8
Stability of Graph Neural Networks to Relative Perturbations,2019-10-21T21:03:38Z,"Fernando Gama, Joan Bruna, Alejandro Ribeiro","Graph neural networks (GNNs), consisting of a cascade of layers applying a
graph convolution followed by a pointwise nonlinearity, have become a powerful
architecture to process signals supported on graphs. Graph convolutions (and
thus, GNNs), rely heavily on knowledge of the graph for operation. However, in
many practical cases the GSO is not known and needs to be estimated, or might
change from training time to testing time. In this paper, we are set to study
the effect that a change in the underlying graph topology that supports the
signal has on the output of a GNN. We prove that graph convolutions with
integral Lipschitz filters lead to GNNs whose output change is bounded by the
size of the relative change in the topology. Furthermore, we leverage this
result to show that the main reason for the success of GNNs is that they are
stable architectures capable of discriminating features on high eigenvalues,
which is a feat that cannot be achieved by linear graph filters (which are
either stable or discriminative, but cannot be both). Finally, we comment on
the use of this result to train GNNs with increased stability and run
experiments on movie recommendation systems.",http://arxiv.org/abs/1910.09655v1
Broad Neural Network for Change Detection in Aerial Images,2019-02-28T22:16:56Z,"Shailesh Shrivastava, Alakh Aggarwal, Pratik Chattopadhyay","A change detection system takes as input two images of a region captured at
two different times, and predicts which pixels in the region have undergone
change over the time period. Since pixel-based analysis can be erroneous due to
noise, illumination difference and other factors, contextual information is
usually used to determine the class of a pixel (changed or not). This
contextual information is taken into account by considering a pixel of the
difference image along with its neighborhood. With the help of ground truth
information, the labeled patterns are generated. Finally, Broad Learning
classifier is used to get prediction about the class of each pixel. Results
show that Broad Learning can classify the data set with a significantly higher
F-Score than that of Multilayer Perceptron. Performance comparison has also
been made with other popular classifiers, namely Multilayer Perceptron and
Random Forest.",http://arxiv.org/abs/1903.00087v2
"Detecting changes in the covariance structure of functional time series
  with application to fMRI data",2019-03-01T13:32:06Z,"Christina Stoehr, John A D Aston, Claudia Kirch","Functional magnetic resonance imaging (fMRI) data provides information
concerning activity in the brain and in particular the interactions between
brain regions. Resting state fMRI data is widely used for inferring
connectivities in the brain which are not due to external factors. As such
analyzes strongly rely on stationarity, change point procedures can be applied
in order to detect possible deviations from this crucial assumption. In this
paper, we model fMRI data as functional time series and develop tools for the
detection of deviations from covariance stationarity via change point
alternatives. We propose a nonparametric procedure which is based on dimension
reduction techniques. However, as the projection of the functional time series
on a finite and rather low-dimensional subspace involves the risk of missing
changes which are orthogonal to the projection space, we also consider two test
statistics which take the full functional structure into account. The proposed
methods are compared in a simulation study and applied to more than 100 resting
state fMRI data sets.",http://arxiv.org/abs/1903.00288v1
"Change-point detection for multivariate and non-Euclidean data with
  local dependency",2019-03-05T00:12:29Z,Hao Chen,"In a sequence of multivariate observations or non-Euclidean data objects,
such as networks, local dependence is common and could lead to false
change-point discoveries. We propose a new way of permutation -- circular block
permutation with a random starting point -- to address this problem. This
permutation scheme is studied on a non-parametric change-point detection
framework based on a similarity graph constructed on the observations, leading
to a general framework for change-point detection for data with local
dependency. Simulation studies show that this new framework retains the same
level of power when there is no local dependency, while it controls type I
error correctly for sequences with and without local dependency. We also derive
an analytic p-value approximation under this new framework. The approximation
works well for sequences with length in hundreds and above, making this
approach fast-applicable for long data sequences.",http://arxiv.org/abs/1903.01598v1
Nonparametric Change Point Detection in Regression,2019-03-06T20:34:05Z,Valeriy Avanesov,"This paper considers the prominent problem of change-point detection in
regression. The study suggests a novel testing procedure featuring a fully
data-driven calibration scheme. The method is essentially a black box,
requiring no tuning from the practitioner. The approach is investigated from
both theoretical and practical points of view. The theoretical study
demonstrates proper control of first-type error rate under $H_0$ and power
approaching $1$ under $H_1$. The experiments conducted on synthetic data fully
support the theoretical claims. In conclusion, the method is applied to
financial data, where it detects sensible change-points. Techniques for
change-point localization are also suggested and investigated.",http://arxiv.org/abs/1903.02603v3
CHANG-ES: XVIII---The CHANG-ES Survey and Selected Results,2019-03-26T17:42:45Z,"Judith Irwin, Ancor Damas-Segovia, Marita Krause, Arpad Miskolczi, Jiangtao Li, Yelena Stein, Jayanne English, Richard Henriksen, Rainer Beck, Theresa Wiegert, Ralf-Juergen Dettmar","The CHANG-ES (Continuum Halos in Nearby Galaxies) survey of 35 nearby edge-on
galaxies is revealing new and sometimes unexpected and startling results in
their radio continuum emission. The observations were in wide bandwidths
centered at 1.6 and 6.0 GHz. Unique to this survey is full polarization data
showing magnetic field structures in unprecedented detail, resolution and
sensitivity for such a large sample. A wide range of new results are reported
here, some never before seen in any galaxy. We see circular polarization and
variability in active galactic nuclei (AGNs), in-disk discrete features,
disk-halo structures sometimes only seen in polarization, and broad-scale halos
with reversing magnetic fields, among others. This paper summarizes some of the
CHANG-ES results seen thus far. Released images can be found at
https://www.queensu.ca/changes.",http://arxiv.org/abs/1903.11042v1
On Change of Variable Formulas for non-anticipative functionals,2019-03-27T17:34:10Z,"Michael Mania, Revaz Tevzadze","For non-anticipative functionals, differentiable in Chitashvili's sense, the
It\^o formula for cadlag semimartingales is proved. Relations between different
notions of functional derivatives are established.",http://arxiv.org/abs/1903.11571v1
"On the potential of BFAST for monitoring burned areas using
  multi-temporal Landsat-7 images",2019-12-03T17:42:47Z,"Inder Tecuapetla-Gómez, Gabriela Villamil-Cortez, María Isabel Cruz-López","In this paper, we propose a semi-automatic approach to map burned areas and
assess burn severity that does not require prior knowledge of the fire date.
First, we apply BFAST to NDVI time series and estimate statistically abrupt
changes in NDVI trends. These estimated changes are then used as plausible fire
dates to calculate dNBR following a typical pre-post fire assessment. In
addition to its statistical guarantees, this method depends only on a tuning
parameter (the bandwidth of the test statistic for changes). This method was
applied to Landsat-7 images taken over La Primavera Flora and Fauna Protection
Area, in Jalisco, Mexico, from 2003 to 2016. We evaluated BFAST's ability to
estimate vegetation changes based on time series with significant observation
gaps. We discussed burn severity maps associated with massive wildfires (2005
and 2012) and another with smaller dimensions (2008) that might have been
excluded from official records. We validated our 2012 burned area map against a
high resolution burned area map obtained from RapidEye images; in zones with
moderate data quality, the overall accuracy of our map is 92%.",http://arxiv.org/abs/1912.01543v2
"On the contribution of work or heat in exchanged energy via interaction
  in open bipartite quantum systems",2019-12-04T13:52:46Z,"B. Ahmadi, S. Salimi, A. S. Khorashad","In this paper, unambiguous redefinitions of heat and work are presented for
quantum thermodynamic systems. We will use genuine reasoning based on which
Clausius originally defined work and heat in establishing thermodynamics. The
change in the energy which is accompanied by a change in the entropy is
identified as heat, while any change in the energy which does not lead to a
change in the entropy is known as work. It will be seen that quantum coherence
does not allow all the energy exchanged between two quantum systems to be only
of the heat form. Several examples will also be discussed. Finally, it will be
shown that these refined definitions will strongly affect the entropy
production of quantum thermodynamic processes giving new insight into the
irreversibility of quantum processes.",http://arxiv.org/abs/1912.01983v8
"Resistance Drift in Ge2Sb2Te5 Phase Change Memory Line Cells at Low
  Temperatures and Its Response to Photoexcitation",2019-12-10T03:46:29Z,"Raihan Sayeed Khan, Faruk Dirisaglik, Ali Gokirmak, Helena Silva","Resistance drift in phase change materials is characterized in amorphous
phase change memory line-cells from 300 K to 125 K range and is observed to
follow the previously reported power-law behavior with drift coefficients in
the 0.07 to 0.11 range in dark. While these drift coefficients measured in dark
are similar to commonly observed drift coefficients (~0.1) at and above room
temperature, measurements under light show a significantly lower drift
coefficient (0.05 under illumination versus 0.09 in dark at 150K). Periodic
on/off switching of light shows sudden decrease/increase of resistance,
attributed to photo-excited carriers, followed by a very slow response (~30
minutes at 150 K) attributed to contribution of charge traps. Continuation of
the resistance drift at low temperatures and the observed photo-response
suggest that resistance drift in amorphous phase change materials is
predominantly an electronic process.",http://arxiv.org/abs/1912.04480v2
Comments on the stability of the KPV state,2019-12-10T11:14:03Z,Nam Nguyen,"Using the blackfold approach, we study the classical stability of the KPV
(Kachru-Pearson-Verlinde) state of anti-D3 branes at the tip of the
Klebanov-Strassler throat. With regards to generic long-wavelength deformations
considered, we found no instabilities. We comment on the relation of our
results to existing results on the stability of the KPV state.",http://arxiv.org/abs/1912.04646v3
Sequential change point tests based on U-statistics,2019-12-18T13:12:08Z,"Claudia Kirch, Christina Stoehr","We propose a general framework of sequential testing procedures based on
$U$-statistics which contains as an example a sequential CUSUM test based on
differences in mean but also includes a robust sequential Wilcoxon change point
procedure. Within this framework, we consider several monitoring schemes that
take different observations into account to make a decision at a given time
point. Unlike the originally proposed scheme that takes all observations of the
monitoring period into account, we also consider a modified moving-sum-version
as well as a version of a Page-monitoring scheme. The latter behave almost as
good for early changes while being advantageous for later changes. For all
proposed procedures we provide the limit distribution under the null hypothesis
which yields the threshold to control the asymptotic type-I-error. Furthermore,
we show that the proposed tests have asymptotic power one. In a simulation
study we compare the performance of the sequential procedures via their
empirical size, power and detection delay, which is further illustrated by
means of a temperature data set.",http://arxiv.org/abs/1912.08580v1
Bringing Belief Base Change into Dynamic Epistemic Logic,2019-12-22T19:21:05Z,"Marlo Souza, Álvaro Moreira","AGM's belief revision is one of the main paradigms in the study of belief
change operations. In this context, belief bases (prioritised bases) have been
primarily used to specify the agent's belief state. While the connection of
iterated AGM-like operations and their encoding in dynamic epistemic logics
have been studied before, few works considered how well-known postulates from
iterated belief revision theory can be characterised by means of belief bases
and their counterpart in dynamic epistemic logic. Particularly, it has been
shown that some postulates can be characterised through transformations in
priority graphs, while others may not be represented that way. This work
investigates changes in the semantics of Dynamic Preference Logic that give
rise to an appropriate syntactic representation for its models that allow us to
represent and reason about iterated belief base change in this logic.",http://arxiv.org/abs/1912.10515v1
A Bi-Level Cooperative Driving Strategy Allowing Lane Changes,2019-12-24T19:12:21Z,"Huile Xu, Yi Zhang, Christos G. Cassandras, Li Li, Shuo Feng","This paper studies the cooperative driving of connected and automated
vehicles (CAVs) at conflict areas (e.g., non-signalized intersections and
ramping regions). Due to safety concerns, most existing studies prohibit lane
change since this may cause lateral collisions when coordination is not
appropriately performed. However, in many traffic scenarios (e.g., work zones),
vehicles must change lanes. To solve this problem, we categorize the potential
collision into two kinds and thus establish a bi-level planning problem. The
right-of-way of vehicles for the critical conflict zone is considered in the
upper-level, and the right-of-way of vehicles during lane changes is then
resolved in the lower-level. The solutions of the upper-level problem are
represented in tree space, and a near-optimal solution is searched for by
combining Monte Carlo Tree Search (MCTS) with some heuristic rules within a
very short planning time. The proposed strategy is suitable for not only the
shortest delay objective but also other objectives (e.g., energy-saving and
passenger comfort). Numerical examples show that the proposed strategy leads to
good traffic performance in real-time.",http://arxiv.org/abs/1912.11495v1
"3DFR: A Swift 3D Feature Reductionist Framework for Scene Independent
  Change Detection",2019-12-26T16:05:43Z,"Murari Mandal, Vansh Dhar, Abhishek Mishra, Santosh Kumar Vipparthi","In this paper we propose an end-to-end swift 3D feature reductionist
framework (3DFR) for scene independent change detection. The 3DFR framework
consists of three feature streams: a swift 3D feature reductionist stream
(AvFeat), a contemporary feature stream (ConFeat) and a temporal median feature
map. These multilateral foreground/background features are further refined
through an encoder-decoder network. As a result, the proposed framework not
only detects temporal changes but also learns high-level appearance features.
Thus, it incorporates the object semantics for effective change detection.
Furthermore, the proposed framework is validated through a scene independent
evaluation scheme in order to demonstrate the robustness and generalization
capability of the network. The performance of the proposed method is evaluated
on the benchmark CDnet 2014 dataset. The experimental results show that the
proposed 3DFR network outperforms the state-of-the-art approaches.",http://arxiv.org/abs/1912.11891v1
Optimal control of batch processes via a deterministic Q-learning method,2019-04-07T14:02:53Z,"Abdelrahman ElMezain, Mohamed Saleh, Jie Zhang, Ahmed Soliman, Seif Fateen","Dynamic optimization of nonlinear chemical systems -- such as batch reactors
-- should be applied online, and the suitable control taken should be according
to the current state of the system rather than the current time instant. The
recent state of the art methods applies the control based on the current time
instant only. This is not suitable for most cases, as it is not robust to
possible changes in the system. This paper proposes a Deterministic Q-Learning
method to conduct robust online optimization of batch reactors. In this paper,
the Q-Learning method is applied on simple batch reactor models; and in order
to show the effectiveness of the proposed method the results are compared to
other dynamic optimization methods. The main advantage of the Q-learning method
or the proposed method is that it can accommodate unplanned changes during the
process via changing the control action; i.e. the main advantage of the
proposed method that it can overcome sudden changes during the reaction. In
general, we try to maximize the final product obtained or meet certain
specifications of the products (e.g. minimize side products).",http://arxiv.org/abs/1904.03654v2
Minimum Spanning Trees in Weakly Dynamic Graphs,2019-04-10T08:50:16Z,"Moustafa Nakechbandi, Jean-Yves Colin, Hervé Mathieu","In this paper, we study weakly dynamic undirected graphs, that can be used to
represent some logistic networks. The goal is to deliver all the delivery
points in the network. The network exists in a mostly stable environment,
except for a few edges known to be non-stable. The weight of each of these
non-stable edges may change at any time (bascule or lift bridge, elevator,
traffic congestion...). All other edges have stable weights that never change.
This problem can be now considered as a Minimum Spanning Tree (MST) problem on
a dynamic graph. We propose an efficient polynomial algorithm that computes in
advance alternative MSTs for all possible configurations. No additional
computation is then needed after any change in the problem because the MSTs are
already known in all cases. We use these results to compute critical values for
the non-stable weights and to pre-compute best paths. When the non-stable
weights change, the appropriate MST may then directly and immediately be used
without any recomputation.",http://arxiv.org/abs/1904.05066v1
"Conductance distribution in 1D systems: dependence on the Fermi level
  and the ideal leads",2019-04-05T08:58:08Z,I. M. Suslov,"The correct definition of the conductance of finite systems implies a
connection to the system of the massive ideal leads. Influence of the latter on
the properties of the system appears to be rather essential and is studied
below on the simplest example of the 1D case. In the log-normal regime this
influence is reduced to the change of the absolute scale of conductance, but
generally changes the whole distribution function. Under the change of the
system length L, its resistance may undergo the periodic or aperiodic
oscillations. Variation of the Fermi level induces qualitative changes in the
conductance distribution, resembling the smoothed Anderson transition.",http://arxiv.org/abs/1904.06407v1
"Mobility profiles and calendars for food security and livelihoods
  analysis",2019-04-17T22:41:14Z,"Pedro J. Zufiria, David Pastor-Escuredo, Luis Ubeda Medina, Miguel A. Hernandez Medina, Iker Barriales Valbuena, Alfredo J. Morales, Wilfred Nkwambi, John Quinn, Paula Hidalgo Sanchis, Miguel Luengo-Oroz","Social vulnerability is defined as the capacity of individuals and social
groups to respond to any external stress placed on their livelihoods and
wellbeing. Mobility and migrations are relevant when assessing vulnerability
since the movements of a population reflect on their livelihoods, coping
strategies and social safety nets. Although in general migration
characterization is complex and open to controversy, changes in mobility
patterns for vulnerable population groups are likely to indicate a change in
livelihoods or coping strategies. These changes can also indicate that the
population groups may be exposed to new shocks; hence, monitoring of changes in
mobility patterns can be a powerful early warning mechanism.",http://arxiv.org/abs/1904.08525v1
"Progressive amorphization of GeSbTe phase-change material under electron
  beam irradiation",2019-04-24T01:50:59Z,"Ting-Ting Jiang, Jiang-Jing Wang, Lu Lu, Chuan-Sheng Ma, Dan-Li Zhang, Feng Rao, Chun-Lin Jia, Wei Zhang","Fast and reversible phase transitions in chalcogenide phase-change materials
(PCMs), in particular, Ge-Sb-Te compounds, are not only of fundamental
interests, but also make PCMs based random access memory (PRAM) a leading
candidate for non-volatile memory and neuromorphic computing devices. To RESET
the memory cell, crystalline Ge-Sb-Te has to undergo phase transitions firstly
to a liquid state and then to an amorphous state, corresponding to an abrupt
change in electrical resistance. In this work, we demonstrate a progressive
amorphization process in GeSb2Te4 thin films under electron beam irradiation on
transmission electron microscope (TEM). Melting is shown to be completely
absent by the in situ TEM experiments. The progressive amorphization process
resembles closely the cumulative crystallization process that accompanies a
continuous change in electrical resistance. Our work suggests that if
displacement forces can be implemented properly, it should be possible to
emulate symmetric neuronal dynamics by using PCMs.",http://arxiv.org/abs/1904.10601v2
Linking Long- and Short-Term Emission Variability in Pulsars,2019-04-24T18:07:13Z,"Paul Brook, Aris Karastergiou, Simon Johnston","It is now known that the emission from radio pulsars can vary over a wide
range of timescales, from fractions of seconds to decades. However, it is not
yet known if long- and short-term emission variability are caused by the same
physical processes. It has been observed that long-term emission variability is
often correlated with rotational changes in the pulsar. We do not yet know if
the same is true of short-term emission variability, as the rotational changes
involved cannot be directly measured over such short timescales. To remedy
this, we propose a continuous pulsar monitoring technique that permits the
statistical detection of any rotational changes in nulling and mode-changing
pulsars with certain properties. Using a simulation, we explore the range of
pulsar properties over which such an experiment would be possible.",http://arxiv.org/abs/1904.10989v2
"Change detection in SAR time-series based on the coefficient of
  variation",2019-04-25T13:48:14Z,"Elise Colin Koeniguer, Jean-Marie Nicolas","This paper discusses change detection in SAR time-series. Firstly, several
statistical properties of the coefficient of variation highlight its pertinence
for change detection. Then several criteria are proposed. The coefficient of
variation is suggested to detect any kind of change.
  Then other criteria based on ratios of coefficients of variations are
proposed to detect long events such as construction test sites, or point-event
such as vehicles.
  These detection methods are evaluated first on theoretical statistical
simulations to determine the scenarios where they can deliver the best results.
Then detection performance is assessed on real data for different types of
scenes and sensors (Sentinel-1, UAVSAR). In particular, a quantitative
evaluation is performed with a comparison of our solutions with
state-of-the-art methods.",http://arxiv.org/abs/1904.11335v2
Detecting Syntactic Change Using a Neural Part-of-Speech Tagger,2019-06-04T18:04:14Z,"William Merrill, Gigi Felice Stark, Robert Frank","We train a diachronic long short-term memory (LSTM) part-of-speech tagger on
a large corpus of American English from the 19th, 20th, and 21st centuries. We
analyze the tagger's ability to implicitly learn temporal structure between
years, and the extent to which this knowledge can be transferred to date new
sentences. The learned year embeddings show a strong linear correlation between
their first principal component and time. We show that temporal information
encoded in the model can be used to predict novel sentences' years of
composition relatively well. Comparisons to a feedforward baseline suggest that
the temporal change learned by the LSTM is syntactic rather than purely
lexical. Thus, our results suggest that our tagger is implicitly learning to
model syntactic change in American English over the course of the 19th, 20th,
and early 21st centuries.",http://arxiv.org/abs/1906.01661v2
Detecting linear trend changes in data sequences,2019-06-05T11:00:54Z,"Hyeyoung Maeng, Piotr Fryzlewicz","We propose TrendSegment, a methodology for detecting multiple change-points
corresponding to linear trend changes in one dimensional data. A core
ingredient of TrendSegment is a new Tail-Greedy Unbalanced Wavelet transform: a
conditionally orthonormal, bottom-up transformation of the data through an
adaptively constructed unbalanced wavelet basis, which results in a sparse
representation of the data. Due to its bottom-up nature, this multiscale
decomposition focuses on local features in its early stages and on global
features next which enables the detection of both long and short linear trend
segments at once. To reduce the computational complexity, the proposed method
merges multiple regions in a single pass over the data. We show the consistency
of the estimated number and locations of change-points. The practicality of our
approach is demonstrated through simulations and two real data examples,
involving Iceland temperature data and sea ice extent of the Arctic and the
Antarctic. Our methodology is implemented in the R package trendsegmentR,
available from CRAN.",http://arxiv.org/abs/1906.01939v3
"Geometric evolution as a source of discontinuous behavior in soft
  condensed matter",2019-06-10T15:28:33Z,"James E. McClure, Steffen Berg, Ryan T. Armstrong","Geometric evolution represents a fundamental aspect of many physical
phenomena. In this paper we consider the geometric evolution of structures that
undergo topological changes. Topological changes occur when the shape of an
object evolves such that it either breaks apart or converges back into itself
to form a loop. Changes to the topology of an object are fundamentally discrete
events. We consider how discontinuities arise during geometric evolution
processes by characterizing the possible topological events and analyzing the
associated source terms based on evolution equations for geometric invariants.
We show that the discrete nature of a topological change leads to discontinuous
source terms that propagate to physical variables.",http://arxiv.org/abs/1906.04073v1
Swelling thermodynamics and phase transitions of polymer gels,2019-06-12T04:32:55Z,"Michael S. Dimitriyev, Ya-Wen Chang, Paul M. Goldbart, Alberto Fernández-Nieves","We present a pedagogical review of the swelling thermodynamics and phase
transitions of polymer gels. In particular, we discuss how features of the
volume phase transition of the gel's osmotic equilibrium is analogous to other
transitions described by mean-field models of binary mixtures, and the failure
of this analogy at the critical point due to shear rigidity. We then consider
the phase transition at fixed volume, a relatively unexplored paradigm for
polymer gels that results in a phase-separated equilibrium consisting of
coexisting solvent-rich and solvent-poor regions of gel. Again, the gel's shear
rigidity is found to have a profound effect on the phase transition, here
resulting in macroscopic shape change at constant volume of the sample,
exemplified by the tunable buckling of toroidal samples of polymer gel. By
drawing analogies with extreme mechanics, where large shape changes are
achieved via mechanical instabilities, we formulate the notion of extreme
thermodynamics, where large shape changes are achieved via thermodynamic
instabilities, i.e. phase transitions.",http://arxiv.org/abs/1906.04935v1
"Large Fermi Surface Expansion through Anisotropic c-f Mixing in the
  Semimetallic Kondo Lattice System CeBi",2019-06-18T06:39:00Z,"Peng Li, Zhongzheng Wu, Fan Wu, Chunyu Guo, Yi Liu, Haijiang Liu, Zhe Sun, Ming Shi, Fanny Rodolakis, Jessica L McChesney, Chao Cao, Frank Steglich, Huiqiu Yuan, Yang Liu","Using angle-resolved photoemission spectroscopy (ARPES) and resonant ARPES,
we report evidence of strong anisotropic conduction-f electron mixing (c-f
mixing) in CeBi by observing a largely expanded Ce-5d pocket at low
temperature, with no change in the Bi-6p bands. The Fermi surface (FS)
expansion is accompanied by a pronounced spectral weight transfer from the
local 4f 0 peak of Ce (corresponding to Ce3+) to the itinerant conduction bands
near the Fermi level. Careful analysis suggests that the observed large FS
change (with a volume expansion of the electron pocket up to 40%) can most
naturally be explained by a small valence change (~ 1%) of Ce, which coexists
with a very weak Kondo screening. Our work therefore provides evidence for a FS
change driven by real charge fluctuations deep in the Kondo limit, which is
made possible by the low carrier density.",http://arxiv.org/abs/1906.07402v1
"Robust test for dispersion parameter change in discretely observed
  diffusion processes",2019-06-28T13:28:07Z,Junmo Song,"This paper deals with the problem of testing for dispersion parameter change
in discretely observed diffusion processes when the observations are
contaminated by outliers. To lessen the impact of outliers, we first calculate
residuals using a robust estimate and then propose a trimmed-residual based
CUSUM test. The proposed test is shown to converge weakly to a function of the
Brownian bridge under the null hypothesis of no parameter change. We conduct
simulations to evaluate performances of the proposed test in the presence of
outliers. Numerical results confirm that the proposed test posses a strong
robust property against outliers. In real data analysis, we fit the
Ornstein-Uhlenbeck process to KOSPI200 volatility index data and locate some
change points that are not detected by a naive CUSUM test.",http://arxiv.org/abs/1906.12208v1
Parametrically Amplified Low-Power MEMS Capacitive Humidity Sensor,2019-07-08T22:35:04Z,"Rugved Likhite, Aishwaryadev Banerjee, Apratim Majumder, Hanseup Kim and, Carlos H. Mastrangelo","We present the design, fabrication, and response of a polymer-based Laterally
Amplified Chemo-Mechanical (LACM) humidity sensor based on mechanical
leveraging and parametric amplification. The device consists of a sense
cantilever asymmetrically patterned with a polymer and flanked by two
stationary electrodes on the sides. When exposed to a humidity change, the
polymer swells after absorbing the analyte and causes the central cantilever to
bend laterally towards one side, causing a change in the measured capacitance.
The device features an intrinsic gain due to parametric amplification resulting
in an enhanced signal-to-noise ratio (SNR). 11-fold magnification in sensor
response was observed via voltage biasing of the side electrodes without the
use of conventional electronic amplifiers. The sensor showed a repeatable and
recoverable capacitance change of 11% when exposed to a change in relative
humidity from 25-85%. The dynamic characterization of the device also revealed
a response time ~1s and demonstrated a competitive response with respect to a
commercially available reference chip.",http://arxiv.org/abs/1907.03898v1
"Variable Planck's constant and scaling properties of states on Weyl
  algebra",2019-07-19T18:44:07Z,"Piotr Ługiewicz, Lech Jakóbczyk, Andrzej Frydryszak","We consider the possible quantum effect for infinite systems produced by
variations of the Planck's constant. Using the algebraic formulation of quantum
theory we study behaviour of states $\omega$ defined as positive, normalized
functionals on the canonical commutation relations algebra (CCR-algebra) under
the changes of the defining relations of the CCR. These defining relations of
the multiplication in the CCR-algebra depend explicitly on the value of the
Planck's constant. We analyse to what extend changes of the $\hbar$ preserve
the original state space (this gives restrictions on the admissible changes of
the Plank's constant) and what properties have original quantum states $\omega$
as states on the new algebra. We answer such questions for the quasi-free
states. We show that any universally invariant state can be interpreted as a
convex combination of Fock states with different values of Planck's constant.
The second important class of states we study are the KMS-states, here the
rescaling alters in a nontrivial way the relevant dynamics. We also show that
it is possible to go beyond the limits restricting the changes of the $\hbar$,
but then one has to restrict the CCR-algebra to a subalgebra.",http://arxiv.org/abs/1907.08644v1
"Using Word Embeddings to Examine Gender Bias in Dutch Newspapers,
  1950-1990",2019-07-21T06:58:22Z,Melvin Wevers,"Contemporary debates on filter bubbles and polarization in public and social
media raise the question to what extent news media of the past exhibited
biases. This paper specifically examines bias related to gender in six Dutch
national newspapers between 1950 and 1990. We measure bias related to gender by
comparing local changes in word embedding models trained on newspapers with
divergent ideological backgrounds. We demonstrate clear differences in gender
bias and changes within and between newspapers over time. In relation to themes
such as sexuality and leisure, we see the bias moving toward women, whereas,
generally, the bias shifts in the direction of men, despite growing female
employment number and feminist movements. Even though Dutch society became less
stratified ideologically (depillarization), we found an increasing divergence
in gender bias between religious and social-democratic on the one hand and
liberal newspapers on the other. Methodologically, this paper illustrates how
word embeddings can be used to examine historical language change. Future work
will investigate how fine-tuning deep contextualized embedding models, such as
ELMO, might be used for similar tasks with greater contextual information.",http://arxiv.org/abs/1907.08922v1
"U-GAT-IT: Unsupervised Generative Attentional Networks with Adaptive
  Layer-Instance Normalization for Image-to-Image Translation",2019-07-25T04:17:25Z,"Junho Kim, Minjae Kim, Hyeonwoo Kang, Kwanghee Lee","We propose a novel method for unsupervised image-to-image translation, which
incorporates a new attention module and a new learnable normalization function
in an end-to-end manner. The attention module guides our model to focus on more
important regions distinguishing between source and target domains based on the
attention map obtained by the auxiliary classifier. Unlike previous
attention-based method which cannot handle the geometric changes between
domains, our model can translate both images requiring holistic changes and
images requiring large shape changes. Moreover, our new AdaLIN (Adaptive
Layer-Instance Normalization) function helps our attention-guided model to
flexibly control the amount of change in shape and texture by learned
parameters depending on datasets. Experimental results show the superiority of
the proposed method compared to the existing state-of-the-art models with a
fixed network architecture and hyper-parameters. Our code and datasets are
available at https://github.com/taki0112/UGATIT or
https://github.com/znxlwm/UGATIT-pytorch.",http://arxiv.org/abs/1907.10830v4
Wave Enhancement through Optimization of Boundary Conditions,2019-07-25T16:19:08Z,"Habib Ammari, Oscar Bruno, Kthim Imeri, Nilima Nigam","It is well known that changing boundary conditions for the Laplacian from
Dirichlet to Neumann can result in significant changes to the associated
eigenmodes, while keeping the eigenvalues close. We present a new and efficient
approach for optimizing the transmission signal between two points in a cavity
at a given frequency, by changing boundary conditions. The proposed approach
makes use of recent results on the monotonicity of the eigenvalues of the mixed
boundary value problem and on the sensitivity of the Green s function to small
changes in the boundary conditions. The switching of the boundary condition
from Dirichlet to Neumann can be performed through the use of the recently
modeled concept of metasurfaces which are comprised of coupled pairs of
Helmholtz resonators. A variety of numerical experiments are presented to show
the applicability and the accuracy of the proposed new methodology.",http://arxiv.org/abs/1907.11170v1
Killer Technologies: the destructive creation in the technical change,2019-07-29T13:14:27Z,Mario Coccia,"Killer technology is a radical innovation, based on new products and/or
processes, that with high technical and/or economic performance destroys the
usage value of established techniques previously sold and used. Killer
technology is a new concept in economics of innovation that may be useful for
bringing a new perspective to explain and generalize the behavior and
characteristics of innovations that generate a destructive creation for
sustaining technical change. To explore the behavior of killer technologies, a
simple model is proposed to analyze and predict how killer technologies destroy
and substitute established technologies. Empirical evidence of this theoretical
framework is based on historical data on the evolution of some example
technologies. Theoretical framework and empirical evidence hint at general
properties of the behavior of killer technologies to explain corporate,
industrial, economic and social change and to support best practices for
technology management of firms and innovation policy of nations. Overall, then,
the proposed theoretical framework can lay a foundation for the development of
more sophisticated concepts to explain the behavior of vital technologies that
generate technological and industrial change in society.",http://arxiv.org/abs/1907.12406v1
On Learning Meaningful Code Changes via Neural Machine Translation,2019-01-25T22:12:39Z,"Michele Tufano, Jevgenija Pantiuchina, Cody Watson, Gabriele Bavota, Denys Poshyvanyk","Recent years have seen the rise of Deep Learning (DL) techniques applied to
source code. Researchers have exploited DL to automate several development and
maintenance tasks, such as writing commit messages, generating comments and
detecting vulnerabilities among others. One of the long lasting dreams of
applying DL to source code is the possibility to automate non-trivial coding
activities. While some steps in this direction have been taken (e.g., learning
how to fix bugs), there is still a glaring lack of empirical evidence on the
types of code changes that can be learned and automatically applied by DL. Our
goal is to make this first important step by quantitatively and qualitatively
investigating the ability of a Neural Machine Translation (NMT) model to learn
how to automatically apply code changes implemented by developers during pull
requests. We train and experiment with the NMT model on a set of 236k pairs of
code components before and after the implementation of the changes provided in
the pull requests. We show that, when applied in a narrow enough context (i.e.,
small/medium-sized pairs of methods before/after the pull request changes), NMT
can automatically replicate the changes implemented by developers during pull
requests in up to 36% of the cases. Moreover, our qualitative analysis shows
that the model is capable of learning and replicating a wide variety of
meaningful code changes, especially refactorings and bug-fixing activities. Our
results pave the way for novel research in the area of DL on code, such as the
automatic learning and applications of refactoring.",http://arxiv.org/abs/1901.09102v1
"The Effects of the Problem Hamiltonian Parameters on the Minimum
  Spectral Gap in Adiabatic Quantum Optimization",2019-10-07T18:12:11Z,Vicky Choi,"We study the relation between the Ising problem Hamiltonian parameters and
the minimum spectral gap (min-gap) of the system Hamiltonian in the Ising-based
quantum annealer. The main argument we use in this paper to assess the
performance of a QA algorithm is the presence or absence of an anti-crossing
during quantum evolution. For this purpose, we introduce a new parametrization
definition of the anti-crossing. Using the Maximum-weighted Independent Set
(MIS) problem in which there are flexible parameters (energy penalties J
between pairs of edges) in an Ising formulation as the model problem, we
construct examples to show that by changing the value of J, we can change the
quantum evolution from one that has an anti-crossing (that results in an
exponential small min-gap) to one that does not have, or the other way around,
and thus drastically change (increase or decrease) the min-gap. However, we
also show that by changing the value of $J$ alone, one can not avoid the
anti-crossing. We recall a polynomial reduction from an Ising problem to an MIS
problem to show that the flexibility of changing parameters without changing
the problem to be solved can be applied to any Ising problem. As an example, we
show that by such a reduction alone, it is possible to remove the anti-crossing
and thus increase the min-gap. Our anti-crossing definition is necessarily
scaling invariant as scaling the problem Hamiltonian does not change the nature
(i.e. presence or absence) of an anti-crossing. As a side note, we show exactly
how the min-gap is scaled if we scale the problem Hamiltonian by a constant
factor.",http://arxiv.org/abs/1910.02985v2
"Causal Discovery from Heterogeneous/Nonstationary Data with Independent
  Changes",2019-03-05T05:07:13Z,"Biwei Huang, Kun Zhang, Jiji Zhang, Joseph Ramsey, Ruben Sanchez-Romero, Clark Glymour, Bernhard Schölkopf","It is commonplace to encounter heterogeneous or nonstationary data, of which
the underlying generating process changes across domains or over time. Such a
distribution shift feature presents both challenges and opportunities for
causal discovery. In this paper, we develop a framework for causal discovery
from such data, called Constraint-based causal Discovery from
heterogeneous/NOnstationary Data (CD-NOD), to find causal skeleton and
directions and estimate the properties of mechanism changes. First, we propose
an enhanced constraint-based procedure to detect variables whose local
mechanisms change and recover the skeleton of the causal structure over
observed variables. Second, we present a method to determine causal
orientations by making use of independent changes in the data distribution
implied by the underlying causal model, benefiting from information carried by
changing distributions. After learning the causal structure, next, we
investigate how to efficiently estimate the ""driving force"" of the
nonstationarity of a causal mechanism. That is, we aim to extract from data a
low-dimensional representation of changes. The proposed methods are
nonparametric, with no hard restrictions on data distributions and causal
mechanisms, and do not rely on window segmentation. Furthermore, we find that
data heterogeneity benefits causal structure identification even with
particular types of confounders. Finally, we show the connection between
heterogeneity/nonstationarity and soft intervention in causal discovery.
Experimental results on various synthetic and real-world data sets (task-fMRI
and stock market data) are presented to demonstrate the efficacy of the
proposed methods.",http://arxiv.org/abs/1903.01672v5
Gemini Imaging of the Host Galaxies of Changing-Look Quasars,2019-03-19T17:31:26Z,"Paul J. L. Charlton, John J. Ruan, Daryl Haggard, Scott F. Anderson, Michael Eracleous, Chelsea L. Macleod, Jessie C. Runnoe","Changing-look quasars are a newly-discovered class of luminous active
galactic nuclei that undergo rapid ($\lesssim$10 year) transitions between Type
1 and Type 1.9/2, with an associated change in their continuum emission. We
characterize the host galaxies of four faded changing-look quasars using
broadband optical imaging. We use \textit{gri} images obtained with the Gemini
Multi Object Spectrograph (GMOS) on Gemini North to characterize the surface
brightness profiles of the quasar hosts and search for [O III]
$\lambda4959,\lambda5007$ emission from spatially extended regions, or
voorwerpjes, with the goal of using them to examine past luminosity history.
Although we do not detect, voorwerpjes surrounding the four quasar host
galaxies, we take advantage of the dim nuclear emission to characterize the
colors and morphologies of the host galaxies. Three of the four galaxies show
morphological evidence of merger activity or tidal features in their residuals.
The three galaxies which are not highly distorted are fit with a single
S\'ersic profile to characterize their overall surface brightness profiles. The
single-S\'ersic fits give intermediate S\'ersic indices between the $n=1$ of
disk galaxies and the $n=4$ of ellipticals. On a color-magnitude diagram, our
changing-look quasar host galaxies reside in the blue cloud, with other AGN
host galaxies and star-forming galaxies. On a color-S\'ersic index diagram the
changing-look quasar hosts reside with other AGN hosts in the ""green valley"".
Our analysis suggests that the hosts of changing-look quasars are predominantly
disrupted or merging galaxies that resemble AGN hosts, rather than inactive
galaxies.",http://arxiv.org/abs/1903.08122v2
"Feature-wise change detection and robust indoor positioning using
  RANSAC-like approach",2019-12-18T12:46:04Z,Caifa Zhou,"Fingerprinting-based positioning, one of the promising indoor positioning
solutions, has been broadly explored owing to the pervasiveness of sensor-rich
mobile devices, the prosperity of opportunistically measurable
location-relevant signals and the progress of data-driven algorithms. One
critical challenge is to controland improve the quality of the reference
fingerprint map (RFM), which is built at the offline stage and applied for
online positioning. The key concept concerningthe quality control of the RFM is
updating the RFM according to the newly measured data. Though varies methods
have been proposed for adapting the RFM, they approach the problem by
introducing extra-positioning schemes (e.g. PDR orUGV) and directly adjust the
RFM without distinguishing whether critical changes have occurred. This paper
aims at proposing an extra-positioning-free solution by making full use of the
redundancy of measurable features. Loosely inspired by random sampling
consensus (RANSAC), arbitrarily sampled subset of features from the online
measurement are used for generating multi-resamples, which areused for
estimating the intermediate locations. In the way of resampling, it can
mitigate the impact of the changed features on positioning and enables to
retrieve accurate location estimation. The users location is robustly computed
by identifying the candidate locations from these intermediate ones using
modified Jaccardindex (MJI) and the feature-wise change belief is calculated
according to the world model of the RFM and the estimated variability of
features. In order to validate our proposed approach, two levels of
experimental analysis have been carried out. On the simulated dataset, the
average change detection accuracy is about 90%. Meanwhile, the improvement of
positioning accuracy within 2 m is about 20% by dropping out the features that
are detected as changed when performing positioning comparing to that of using
all measured features for location estimation. On the long-term collected
dataset, the average change detection accuracy is about 85%.",http://arxiv.org/abs/1912.09301v1
"A Surveillance Infrastructure for Malaria Analytics: Provisioning Data
  Access and Preservation of Interoperability",2019-02-05T19:19:10Z,"Mohammad Sadnan Al Manir, Jon Haël Brenas, Christopher JO Baker, Arash Shaban-Nejad","We propose the Semantics, Interoperability, and Evolution for Malaria
Analytics (SIEMA) platform for use in malaria surveillance based on semantic
data federation. Using this approach, it is possible to access distributed
data, extend and preserve interoperability between multiple dynamic distributed
malaria sources, and facilitate detection of system changes that can interrupt
mission-critical global surveillance activities. We used Semantic Automated
Discovery and Integration (SADI) Semantic Web Services to enable data access
and improve interoperability, and the graphical user interface-enabled semantic
query engine HYDRA to implement the target queries typical of malaria programs.
We implemented a custom algorithm to detect changes to community-developed
terminologies, data sources, and services that are core to SIEMA. This
algorithm reports to a dashboard. Valet SADI is used to mitigate the impact of
changes by rebuilding affected services. We developed a prototype surveillance
and change management platform from a combination of third-party tools,
community-developed terminologies, and custom algorithms. We illustrated a
methodology and core infrastructure to facilitate interoperable access to
distributed data sources using SADI Semantic Web services. This degree of
access makes it possible to implement complex queries needed by our user
community with minimal technical skill. We implemented a dashboard that reports
on terminology changes that can render the services inactive, jeopardizing
system interoperability. Using this information, end users can control and
reactively rebuild services to preserve interoperability and minimize service
downtime.",http://arxiv.org/abs/1902.01877v1
"Long-term optical spectral monitoring of a changing-look AGN NGC 3516 I:
  Continuum and broad-line flux variability",2019-02-28T00:35:31Z,"A. I. Shapovalova, L. C. Popovic, V. L. Afanasiev, D. Ilic, A. Kovacevic, A. N. Burenkov, V. H. Chavushyan, S. Marceta-Mandic, O. Spiridonova, J. R. Valdes, N. G. Bochkarev, V. Patino-Alvarez, L. Carrasco, V. E. Zhdanova","Here we present the long-term optical spectral monitoring of a changing-look
active galactic nuclei (AGN) NGC 3516 that covers 22 years (from 1996 to 2018).
We explore a variability in the broad lines and continuum, finding that the
continuum is changing by more than a factor of 2, while the broad lines are
varying by more than a factor of 10. The minimum of activity is observed in
2014, when the broad lines almost disappeared. We confirm that NGC 3516 is a
changing-look AGN, and the absorption seen in the UV and X-ray may indicate
that there is an obscuring region which is responsible for this.
  The line profiles are also changing. The mean profiles of the broad Halpha
and Hbeta lines show shoulder-like structure in the wings, and enhanced peak,
that may indicate a complex BLR. The rms-profiles of both lines seem to have
the same shape and width of around 4200 km/s, indicating practically the same
kinematics in the Halpha and Hbeta emitting regions.
  Measured time-lags between the continuum and Halpha and Hbeta broad-line
variability are ~15 and 17 days, respectively, that in combination with the
broad lines width allows us to estimate the NGC 3516 central black hole mass.
We find that the black hole mass is 4.73+-1.40 x 10^7M_sun which is in
agreement with previous estimates.",http://arxiv.org/abs/1902.10845v1
"Application of a bipolar nanopore as a sensor: rectification as an
  additional device function",2019-11-05T20:54:18Z,"Eszter Mádai, Mónika Valiskó, Dezső Boda","We model and simulate a nanopore sensor that selectively binds analyte ions.
This binding leads to the modulation of the local concentrations of the ions of
the background electrolyte (KCl), and, thus, to the modulation of the ionic
current flowing through the pore. The nanopore's wall carries a bipolar charge
pattern with a larger positive buffer region determining the anions as the main
charge carriers and the smaller negative binding region containing binding
sites. This charge pattern proved to be an appropriate one as shown by a
previous comparative study of varying charge patterns (M\'adai et al.\
\textit{J. Mol. Liq.}, 2019, \textbf{283}, 391--398.). Binding of the positive
analyte ions attracts more anions in the pore thus increasing the current. The
asymmetric nature of the pore results in an additional device function,
rectification. Our model, therefore, is a dual response device. Using a reduced
model of the nanopore studied by a hybrid computer simulation method (Local
Equilibrium Monte Carlo coupled to the Nernst-Planck equation) we show that we
can create a sensor whose underlying mechanisms are based on the changes of the
local electric field as a response to changing thermodynamic conditions. The
change of the electric field results in changes in the local ionic
concentrations (depletion zones), and, thus, changes in ionic currents.",http://arxiv.org/abs/1911.02083v1
"Vision-Based Lane-Changing Behavior Detection Using Deep Residual Neural
  Network",2019-11-08T22:28:53Z,"Zhensong Wei, Chao Wang, Peng Hao, Matthew Barth","Accurate lane localization and lane change detection are crucial in advanced
driver assistance systems and autonomous driving systems for safer and more
efficient trajectory planning. Conventional localization devices such as Global
Positioning System only provide road-level resolution for car navigation, which
is incompetent to assist in lane-level decision making. The state of art
technique for lane localization is to use Light Detection and Ranging sensors
to correct the global localization error and achieve centimeter-level accuracy,
but the real-time implementation and popularization for LiDAR is still limited
by its computational burden and current cost. As a cost-effective alternative,
vision-based lane change detection has been highly regarded for affordable
autonomous vehicles to support lane-level localization. A deep learning-based
computer vision system is developed to detect the lane change behavior using
the images captured by a front-view camera mounted on the vehicle and data from
the inertial measurement unit for highway driving. Testing results on
real-world driving data have shown that the proposed method is robust with
real-time working ability and could achieve around 87% lane change detection
accuracy. Compared to the average human reaction to visual stimuli, the
proposed computer vision system works 9 times faster, which makes it capable of
helping make life-saving decisions in time.",http://arxiv.org/abs/1911.03565v1
A Code Injection Method for Rapid Docker Image Building,2019-11-18T06:04:12Z,"Yujing Wang, Qinyang Bao","Docker images are composed of multiple layers, each of which contains a set
of instructions, and an archive of files. Layers allow Docker to separate a
large build task into smaller ones, such that when a part of the program is
changed, only the corresponding layer needs to be changed. Yet the current
implementation has major inefficiencies that make the rebuilding of an image
unnecessarily slow when changes in bottom layers are required: uneven content
distribution amongst layers, the need to rebuild an entire layer during update,
and the rebuild fall-throughs in many cases. In this paper, we propose a code
injection method that overcomes these inefficiencies by targeting only the
changed layer and then bypassing the layer's content checksum. This process is
developed specifically for an interpreted language such as Python, where
changes can be detected explicitly via text diff tools and run as-is without
compilation. We then demonstrate that this method can accelerate the rebuild
time, effectively reducing the O(n) where n = size of layer rebuild time to
O(1). Whereas for compiled languages, literal code injection cannot guarantee
integrity in compiled machine code. Expanding on the same code injection
principle, multi-layer targeted code injection will be addressed in a future
discussion.",http://arxiv.org/abs/1911.07444v3
"Wind-Induced Changes to Surface Gravity Wave Shape in Deep to
  Intermediate Water",2019-11-18T19:08:23Z,"Thomas Zdyrski, Falk Feddersen","Wave shape (i.e. skewness or asymmetry) plays an important role in beach
morphology evolution, remote sensing, and ship safety. Wind's influence on
ocean waves has been extensively studied theoretically in the context of
growth, but most theories are phase averaged and cannot predict wave shape.
Most laboratory and numerical studies similarly focus on wave growth. A few
laboratory experiments have demonstrated that wind can change wave shape, and
two-phase numerical simulations have also noted wind-induced wave shape
changes. However, wind's effect on wave shape is poorly understood, and no
theory for it exists. For weakly nonlinear waves, wave shape parameters are the
phase of the harmonic relative to the primary frequency (or harmonic phase HP,
zero for a Stokes wave) and relative amplitude of the harmonic to the primary.
Here, surface pressure profiles (denoted Jeffreys, Miles, and Generalized
Miles) are prescribed based on wind-wave generation theories. Theoretical
solutions are derived for quasi-periodic progressive waves and the wind-induced
changes to HP, relative harmonic amplitude, as well as already known phase
speed changes and growth rates. The wave shape parameters depend upon the
chosen surface pressure profile, pressure magnitude and phase relative to the
wave profile, and the nondimensional depth. Wave asymmetry is linked to the
nondimensional growth rate. Atmospheric large eddy simulations constrain
pressure profile parameters. HP predictions are qualitatively consistent with
laboratory observations. This theory, together with the observables of HP and
relative harmonic amplitude, can provide insight into the actual wave surface
pressure profile.",http://arxiv.org/abs/1911.07879v2
"The role of annealing in determining the yielding behavior of glasses
  under cyclic shear deformation",2019-11-29T05:40:33Z,"Himangsu Bhaumik, Giuseppe Foffi, Srikanth Sastry","Yielding behavior in amorphous solids has been investigated in computer
simulations employing uniform and cyclic shear deformation. Recent results
characterise yielding as a discontinuous transition, with the degree of
annealing of glasses being a significant parameter. Under uniform shear,
discontinuous changes in stresses at yielding occur in the high annealing
regime, separated from the poor annealing regime in which yielding is gradual.
In cyclic shear simulations, relatively poorly annealed glasses become
progressively better annealed as the yielding point is approached, with a
relatively modest but clear discontinuous change at yielding. To understand
better the role of annealing on yielding characteristics, we perform athermal
quasistaic cyclic shear simulations of glasses prepared with a wide range of
annealing in two qualitatively different systems -- a model of silica (a
network glass), and an atomic binary mixture glass. Two strikingly different
regimes of behavior emerge: Energies of poorly annealed samples evolve towards
a unique threshold energy as the strain amplitude increases, before yielding
takes place. Well annealed samples, in contrast, show no significant energy
change with strain amplitude till they yield, accompanied by discontinuous
energy changes that increase with the degree of annealing. Significantly, the
threshold energy for both systems correspond to dynamical crossover
temperatures associated with changes in the character of the energy landscape
sampled by glass forming liquids. Uniform shear simulations support the
recently discussed scenario of a random critical point separating ductile and
brittle yielding, which our results now associate with dynamical crossover
temperatures in the corresponding liquids.",http://arxiv.org/abs/1911.12957v1
"Learning and Planning for Time-Varying MDPs Using Maximum Likelihood
  Estimation",2019-11-29T07:02:14Z,"Melkior Ornik, Ufuk Topcu","This paper proposes a formal approach to online learning and planning for
agents operating in a priori unknown, time-varying environments. The proposed
method computes the maximally likely model of the environment, given the
observations about the environment made by an agent earlier in the system run
and assuming knowledge of a bound on the maximal rate of change of system
dynamics. Such an approach generalizes the estimation method commonly used in
learning algorithms for unknown Markov decision processes with time-invariant
transition probabilities, but is also able to quickly and correctly identify
the system dynamics following a change. Based on the proposed method, we
generalize the exploration bonuses used in learning for time-invariant Markov
decision processes by introducing a notion of uncertainty in a learned
time-varying model, and develop a control policy for time-varying Markov
decision processes based on the exploitation and exploration trade-off. We
demonstrate the proposed methods on four numerical examples: a patrolling task
with a change in system dynamics, a two-state MDP with periodically changing
outcomes of actions, a wind flow estimation task, and a multi-armed bandit
problem with periodically changing probabilities of different rewards.",http://arxiv.org/abs/1911.12976v2
"ST-GRAT: A Novel Spatio-temporal Graph Attention Network for Accurately
  Forecasting Dynamically Changing Road Speed",2019-11-29T16:32:51Z,"Cheonbok Park, Chunggi Lee, Hyojin Bahng, Yunwon Tae, Kihwan Kim, Seungmin Jin, Sungahn Ko, Jaegul Choo","Predicting road traffic speed is a challenging task due to different types of
roads, abrupt speed change and spatial dependencies between roads; it requires
the modeling of dynamically changing spatial dependencies among roads and
temporal patterns over long input sequences. This paper proposes a novel
spatio-temporal graph attention (ST-GRAT) that effectively captures the
spatio-temporal dynamics in road networks. The novel aspects of our approach
mainly include spatial attention, temporal attention, and spatial sentinel
vectors. The spatial attention takes the graph structure information (e.g.,
distance between roads) and dynamically adjusts spatial correlation based on
road states. The temporal attention is responsible for capturing traffic speed
changes, and the sentinel vectors allow the model to retrieve new features from
spatially correlated nodes or preserve existing features. The experimental
results show that ST-GRAT outperforms existing models, especially in difficult
conditions where traffic speeds rapidly change (e.g., rush hours). We
additionally provide a qualitative study to analyze when and where ST-GRAT
tended to make accurate predictions during rush-hour times.",http://arxiv.org/abs/1911.13181v2
Unsupervised Image Regression for Heterogeneous Change Detection,2019-09-07T12:26:11Z,"Luigi T. Luppino, Filippo M. Bianchi, Gabriele Moser, Stian N. Anfinsen","Change detection in heterogeneous multitemporal satellite images is an
emerging and challenging topic in remote sensing. In particular, one of the
main challenges is to tackle the problem in an unsupervised manner. In this
paper we propose an unsupervised framework for bitemporal heterogeneous change
detection based on the comparison of affinity matrices and image regression.
First, our method quantifies the similarity of affinity matrices computed from
co-located image patches in the two images. This is done to automatically
identify pixels that are likely to be unchanged. With the identified pixels as
pseudo-training data, we learn a transformation to map the first image to the
domain of the other image, and vice versa. Four regression methods are selected
to carry out the transformation: Gaussian process regression, support vector
regression, random forest regression, and a recently proposed kernel regression
method called homogeneous pixel transformation. To evaluate the potentials and
limitations of our framework, and also the benefits and disadvantages of each
regression method, we perform experiments on two real data sets. The results
indicate that the comparison of the affinity matrices can already be considered
a change detection method by itself. However, image regression is shown to
improve the results obtained by the previous step alone and produces accurate
change detection maps despite of the heterogeneity of the multitemporal input
data. Notably, the random forest regression approach excels by achieving
similar accuracy as the other methods, but with a significantly lower
computational cost and with fast and robust tuning of hyperparameters.",http://arxiv.org/abs/1909.05948v1
Efficient Representation Learning Using Random Walks for Dynamic Graphs,2019-01-05T00:35:43Z,"Hooman Peiro Sajjad, Andrew Docherty, Yuriy Tyshetskiy","An important part of many machine learning workflows on graphs is vertex
representation learning, i.e., learning a low-dimensional vector representation
for each vertex in the graph. Recently, several powerful techniques for
unsupervised representation learning have been demonstrated to give the
state-of-the-art performance in downstream tasks such as vertex classification
and edge prediction. These techniques rely on random walks performed on the
graph in order to capture its structural properties. These structural
properties are then encoded in the vector representation space.
  However, most contemporary representation learning methods only apply to
static graphs while real-world graphs are often dynamic and change over time.
Static representation learning methods are not able to update the vector
representations when the graph changes; therefore, they must re-generate the
vector representations on an updated static snapshot of the graph regardless of
the extent of the change in the graph. In this work, we propose computationally
efficient algorithms for vertex representation learning that extend random walk
based methods to dynamic graphs. The computation complexity of our algorithms
depends upon the extent and rate of changes (the number of edges changed per
update) and on the density of the graph. We empirically evaluate our algorithms
on real world datasets for downstream machine learning tasks of multi-class and
multi-label vertex classification. The results show that our algorithms can
achieve competitive results to the state-of-the-art methods while being
computationally efficient.",http://arxiv.org/abs/1901.01346v2
"Demonstration of a strain-mediated magnetoelectric write and read unit
  in a Co60Fe20B20/ Pb(Mg1/3Nb2/3)0.7Ti0.3O3 heterostructure",2019-01-05T05:10:17Z,"Tingting Shen, Vaibhav Ostwal, Kerem Y. Camsari, Joerg Appenzeller","Taking advantage of the Magnetoelectric (ME) and its inverse effect, this
article demonstrates strain-mediated magnetoelectric write and read operations
simultaneously in Co60Fe20B20/ Pb(Mg1/3Nb2/3)0.7Ti0.3O3 heterostructures
without using any symmetry breaking magnetic field at room temperature. By
applying an external DC-voltage across a (011)-cut PMN-PT substrate, the
ferroelectric polarization is re-oriented, which results in an anisotropic
in-plane strain that transfers to the CoFeB thin film and changes its magnetic
anisotropy Hk. The change in Hk in-turn results in a 90o rotation of the
magnetic easy axis for sufficiently high voltages. Simultaneously, the inverse
effect is employed to read changes of the magnetic properties. Because the
Piezoelectric (PE)/FerroMagnetic (FM) system is fully coupled, the change of
magnetization in FM induces an elastic stress in the PE layer, which generates
a piezoelectric potential in the system that can be used to readout the
magnetic state of the FM layer. Our experimental results are in excellent
qualitative agreement with a recently proposed, experimentally benchmarked
equivalent circuit model that considers how magnetic properties are
electrically controlled in such ME/PE heterostructure and how a back-voltage is
generated due to changing magnetic properties in a self-consistent model.",http://arxiv.org/abs/1901.01368v1
"Cyber Security Awareness Campaigns: Why do they fail to change
  behaviour?",2019-01-09T10:45:57Z,"Maria Bada, Angela M. Sasse, Jason R. C. Nurse","The present paper focuses on Cyber Security Awareness Campaigns, and aims to
identify key factors regarding security which may lead them to failing to
appropriately change people's behaviour. Past and current efforts to improve
information-security practices and promote a sustainable society have not had
the desired impact. It is important therefore to critically reflect on the
challenges involved in improving information-security behaviours for citizens,
consumers and employees. In particular, our work considers these challenges
from a Psychology perspective, as we believe that understanding how people
perceive risks is critical to creating effective awareness campaigns. Changing
behaviour requires more than providing information about risks and reactive
behaviours - firstly, people must be able to understand and apply the advice,
and secondly, they must be motivated and willing to do so - and the latter
requires changes to attitudes and intentions. These antecedents of behaviour
change are identified in several psychological models of behaviour. We review
the suitability of persuasion techniques, including the widely used 'fear
appeals'. From this range of literature, we extract essential components for an
awareness campaign as well as factors which can lead to a campaign's success or
failure. Finally, we present examples of existing awareness campaigns in
different cultures (the UK and Africa) and reflect on these.",http://arxiv.org/abs/1901.02672v1
"Phenomenal magneto-elastoresistance of WTe$_{2}$: strain engineering of
  electronic and quantum transport properties",2019-01-15T23:50:40Z,"Na Hyun Jo, Lin-Lin Wang, Peter P. Orth, Sergey L. Bud'ko, Paul C. Canfield","Elastoresistance describes the relative change of a material's resistance
when strained. It has two major contributions: strain induced geometric and
electronic changes. If the geometric factor dominates, like in ordinary metals
such as copper, the elastoresistance is positive and rather small, i.e.
typically of order 1. In a few materials, however, changes in electronic
structure dominate, which gives rise to larger and even negative values, such
as (-11) for Bi. Here, we report that the transition metal dichalcogenide
(TMDC) WTe$_{2}$ is a member of the second group, exhibiting a large and
non-monotonic elastoresistance that is about (-20) near 100 K and changes sign
at low temperatures. We discover that an applied magnetic field has a dramatic
effect on the elastoresistance in WTe$_{2}$: in the quantum regime at low
temperatures, it leads to quantum oscillations of the elastoresistance, that
ranges between (-80) to 120 within a field range of only half a Tesla. In the
semiclassical regime at intermediate temperatures, we find that the
elastoresistance rapidly increases and changes sign in a magnetic field. We
provide a semi-quantitative understanding of our experimental results using a
combination of first-principle and analytical low-energy model calculations.
Understanding bulk properties of TMDCs under uniaxial strain is an important
stepping stone toward strain engineering of 2D TMDCs.",http://arxiv.org/abs/1901.05090v1
"Room Temperature Electrocaloric Effect in Layered Ferroelectric CuInP2S6
  for Solid State Refrigeration",2019-01-20T03:13:28Z,"Mengwei Si, Atanu K. Saha, Pai-Ying Liao, Shengjie Gao, Sabine M. Neumayer, Jie Jian, Jingkai Qin, Nina Balke, Haiyan Wang, Petro Maksymovych, Wenzhuo Wu, Sumeet K. Gupta, Peide D. Ye","A material with reversible temperature change capability under an external
electric field, known as the electrocaloric effect (ECE), has long been
considered as a promising solid-state cooling solution. However, electrocaloric
(EC) performance of EC materials generally is not sufficiently high for real
cooling applications. As a result, exploring EC materials with high performance
is of great interest and importance. Here, we report on the ECE of
ferroelectric materials with van der Waals layered structure (CuInP2S6 or CIPS
in this work in particular). Over 60% polarization charge change is observed
within a temperature change of only 10 K at Curie temperature. Large adiabatic
temperature change (|{\Delta}T|) of 3.3 K, isothermal entropy change
(|{\Delta}S|) of 5.8 J kg-1 K-1 at |{\Delta}E|=142.0 kV cm-1 at 315 K (above
and near room temperature) are achieved, with a large EC strength
(|{\Delta}T|/|{\Delta}E|) of 29.5 mK cm kV-1. The ECE of CIPS is also
investigated theoretically by numerical simulation and a further EC performance
projection is provided.",http://arxiv.org/abs/1901.06616v2
The threshold age of Keyfitz' entropy,2019-01-23T15:48:35Z,"José Manuel Aburto, Jesús-Adrián Alvarez, Francisco Villavicencio, James W. Vaupel","BACKGROUND Indicators of relative inequality of lifespans are important
because they capture the dimensionless shape of aging. They are markers of
inequality at the population level and express the uncertainty at the time of
death at the individual level. In particular, Keyfitz' entropy $\bar{H}$
represents the elasticity of life expectancy to a change in mortality and it
has been used as an indicator of lifespan variation. However, it is unknown how
this measure changes over time and whether a threshold age exists, as it does
for other lifespan variation indicators.
  RESULTS The time derivative of $\bar{H}$ can be decomposed into changes in
life disparity $e^\dagger$ and life expectancy at birth $e_o$. Likewise,
changes over time in $\bar{H}$ are a weighted average of age-specific rates of
mortality improvements. These weights reflect the sensitivity of $\bar{H}$ and
show how mortality improvements can increase (or decrease) the relative
inequality of lifespans. Further, we prove that $\bar{H}$, as well as
$e^\dagger$, in the case that mortality is reduced in every age, has a
threshold age below which saving lives reduces entropy, whereas improvements
above that age increase entropy.
  CONTRIBUTION We give a formal expression for changes over time of $\bar{H}$
and provide a formal proof of the threshold age that separates reductions and
increases in lifespan inequality from age-specific mortality improvements.",http://arxiv.org/abs/1901.07963v1
A Meta-Transfer Objective for Learning to Disentangle Causal Mechanisms,2019-01-30T15:47:12Z,"Yoshua Bengio, Tristan Deleu, Nasim Rahaman, Rosemary Ke, Sébastien Lachapelle, Olexa Bilaniuk, Anirudh Goyal, Christopher Pal","We propose to meta-learn causal structures based on how fast a learner adapts
to new distributions arising from sparse distributional changes, e.g. due to
interventions, actions of agents and other sources of non-stationarities. We
show that under this assumption, the correct causal structural choices lead to
faster adaptation to modified distributions because the changes are
concentrated in one or just a few mechanisms when the learned knowledge is
modularized appropriately. This leads to sparse expected gradients and a lower
effective number of degrees of freedom needing to be relearned while adapting
to the change. It motivates using the speed of adaptation to a modified
distribution as a meta-learning objective. We demonstrate how this can be used
to determine the cause-effect relationship between two observed variables. The
distributional changes do not need to correspond to standard interventions
(clamping a variable), and the learner has no direct knowledge of these
interventions. We show that causal structures can be parameterized via
continuous variables and learned end-to-end. We then explore how these ideas
could be used to also learn an encoder that would map low-level observed
variables to unobserved causal variables leading to faster adaptation
out-of-distribution, learning a representation space where one can satisfy the
assumptions of independent mechanisms and of small and sparse changes in these
mechanisms due to actions and non-stationarities.",http://arxiv.org/abs/1901.10912v2
"GETNET: A General End-to-end Two-dimensional CNN Framework for
  Hyperspectral Image Change Detection",2019-05-05T11:36:53Z,"Qi Wang, Zhenghang Yuan, Qian Du, Xuelong Li","Change detection (CD) is an important application of remote sensing, which
provides timely change information about large-scale Earth surface. With the
emergence of hyperspectral imagery, CD technology has been greatly promoted, as
hyperspectral data with the highspectral resolution are capable of detecting
finer changes than using the traditional multispectral imagery. Nevertheless,
the high dimension of hyperspectral data makes it difficult to implement
traditional CD algorithms. Besides, endmember abundance information at subpixel
level is often not fully utilized. In order to better handle high dimension
problem and explore abundance information, this paper presents a General
End-to-end Two-dimensional CNN (GETNET) framework for hyperspectral image
change detection (HSI-CD). The main contributions of this work are threefold:
1) Mixed-affinity matrix that integrates subpixel representation is introduced
to mine more cross-channel gradient features and fuse multi-source information;
2) 2-D CNN is designed to learn the discriminative features effectively from
multi-source data at a higher level and enhance the generalization ability of
the proposed CD algorithm; 3) A new HSI-CD data set is designed for the
objective comparison of different methods. Experimental results on real
hyperspectral data sets demonstrate the proposed method outperforms most of the
state-of-the-arts.",http://arxiv.org/abs/1905.01662v1
"Effect of E-cigarette Use and Social Network on Smoking Behavior Change:
  An agent-based model of E-cigarette and Cigarette Interaction",2019-05-03T01:27:37Z,"Yang Qin, Rojiemiahd Edjoc, Nathaniel D Osgood","Despite a general reduction in smoking in many areas of the developed world,
it remains one of the biggest public health threats. As an alternative to
tobacco, the use of electronic cigarettes (ECig) has been increased
dramatically over the last decade. ECig use is hypothesized to impact smoking
behavior through several pathways, not only as a means of quitting cigarettes
and lowering risk of relapse, but also as both an alternative nicotine delivery
device to cigarettes, as a visible use of nicotine that can lead to imitative
behavior in the form of smoking, and as a gateway nicotine delivery technology
that can build high levels of nicotine tolerance and pave the way for
initiation of smoking. Evidence regarding the effect of ECig use on smoking
behavior change remains inconclusive. To address these challenges, we built an
agent-based model (ABM) of smoking and ECig use to examine the effects of ECig
use on smoking behavior change. The impact of social network (SN) on the
initiation of smoking and ECig use were also explored. Findings from the
simulation suggest that the use of ECig generates substantially lower
prevalence of current smoker (PCS), which demonstrates the potential for
reducing smoking and lowering the risk of relapse. The effects of
proximity-based influences within SN increases the prevalence of current ECig
user (PCEU). The model also suggests the importance of improved understanding
of drivers in cessation and relapse in ECig use, in light of findings that such
aspects of behavior change may notably influence smoking behavior change and
burden.",http://arxiv.org/abs/1905.03611v1
Reinforcement Learning in Non-Stationary Environments,2019-05-10T07:05:27Z,"Sindhu Padakandla, Prabuchandran K. J, Shalabh Bhatnagar","Reinforcement learning (RL) methods learn optimal decisions in the presence
of a stationary environment. However, the stationary assumption on the
environment is very restrictive. In many real world problems like traffic
signal control, robotic applications, one often encounters situations with
non-stationary environments and in these scenarios, RL methods yield
sub-optimal decisions. In this paper, we thus consider the problem of
developing RL methods that obtain optimal decisions in a non-stationary
environment. The goal of this problem is to maximize the long-term discounted
reward achieved when the underlying model of the environment changes over time.
To achieve this, we first adapt a change point algorithm to detect change in
the statistics of the environment and then develop an RL algorithm that
maximizes the long-run reward accrued. We illustrate that our change point
method detects change in the model of the environment effectively and thus
facilitates the RL algorithm in maximizing the long-run reward. We further
validate the effectiveness of the proposed solution on non-stationary random
Markov decision processes, a sensor energy management problem and a traffic
signal control problem.",http://arxiv.org/abs/1905.03970v4
Improving Change Prediction Models with Code Smell-Related Information,2019-05-26T21:44:29Z,"Gemma Catolino, Fabio Palomba, Francesca Arcelli Fontana, Andrea De Lucia, Andy Zaidman, Filomena Ferrucci","Code smells represent sub-optimal implementation choices applied by
developers when evolving software systems. The negative impact of code smells
has been widely investigated in the past: besides developers' productivity and
ability to comprehend source code, researchers empirically showed that the
presence of code smells heavily impacts the change-proneness of the affected
classes. On the basis of these findings, in this paper we conjecture that code
smell-related information can be effectively exploited to improve the
performance of change prediction models, ie models having as goal that of
indicating to developers which classes are more likely to change in the future,
so that they may apply preventive maintenance actions. Specifically, we exploit
the so-called intensity index - a previously defined metric that captures the
severity of a code smell - and evaluate its contribution when added as
additional feature in the context of three state of the art change prediction
models based on product, process, and developer-based features. We also compare
the performance achieved by the proposed model with the one of an alternative
technique that considers the previously defined antipattern metrics, namely a
set of indicators computed considering the history of code smells in files. Our
results report that (i) the prediction performance of the intensity-including
models is statistically better than that of the baselines and (ii) the
intensity is a more powerful metric with respect to the alternative
smell-related ones.",http://arxiv.org/abs/1905.10889v1
Quantum state change in light of changes in valuational entropies,2019-08-08T00:38:37Z,Arkady Bolotin,"In the statement ""The vector is an element of the closed linear subspace of
the Hilbert space H"", the predicate ""... is an element of ..."" might be not
only determined, that is, either true or false (depending on whether set
membership is applicable or inapplicable to the specified vector and subspace)
but also undetermined, that is, neither true nor false. To evaluate the
vagueness of set membership among arbitrary vectors and closed linear subspaces
of H, the notion of the entropy of the predicate ""... is an element of ..."" is
introduced in the present paper. Since each closed linear subspace in H
uniquely represents the atomic proposition P about a quantum system, the
entropy of this predicate can also be considered as the valuational entropy
that measures the uncertainty about the assignment of truth values to the
proposition P. As it is demonstrated in the paper, in the Hilbert space H of
the dimension greater than or equal to 2, there always exists a nonempty set S
of the closed linear subspaces in H, such that the entropy of the predicate
""... is an element of ..."" on the given vector of H and all the subspaces of S
cannot be zero. This implies the existence of two different processes of the
pure quantum state change: the process which yields no changes in the
valuational entropies of the propositions (corresponding to the deterministic
and reversible evolution) and the process which brings forth changes in the
valuational entropies (corresponding to the gain or loss of information in a
quantum measurement).",http://arxiv.org/abs/1908.02887v1
"Some SonarQube Issues have a Significant but SmallEffect on Faults and
  Changes. A large-scale empirical study",2019-08-30T08:21:57Z,"Valentina Lenarduzzi, Nyyti Saarimäki, Davide Taibi","Context. Companies commonly invest effort to remove technical issues believed
to impact software qualities, such as removing anti-patterns or coding styles
violations. Objective. Our aim is to analyze the diffuseness of Technical Debt
(TD) items in software systems and to assess their impact on code changes and
fault-proneness, considering also the type of TD items and their severity.
Method. We conducted a case study among 33 Java projects from the Apache
Software Foundation (ASF) repository. We analyzed 726 commits containing 27K
faults and 12M changes. The projects violated 173 SonarQube rules generating
more than 95K TD items in more than 200K classes. Results. Clean classes
(classes not affected by TD items) are less change-prone than dirty ones, but
the difference between the groups is small. Clean classes are slightly more
change-prone than classes affected by TD items of type Code Smell or Security
Vulnerability. As for fault-proneness, there is no difference between clean and
dirty classes. Moreover, we found a lot of incongruities in the type and
severity level assigned by SonarQube. Conclusions. Our result can be useful for
practitioners to understand which TD items they should refactor and for
researchers to bridge the missing gaps. They can also support companies and
tool vendors in identifying TD items as accurately as possible.",http://arxiv.org/abs/1908.11590v1
"Seasonal payoff variations and the evolution of cooperation in social
  dilemmas",2019-08-30T15:55:12Z,"Attila Szolnoki, Matjaz Perc","Varying environmental conditions affect relations between interacting
individuals in social dilemmas, thus affecting also the evolution of
cooperation. Oftentimes these environmental variations are seasonal and can
therefore be mathematically described as periodic changes. Accordingly, we here
study how periodic shifts between different manifestations of social dilemmas
affect cooperation. We observe a non-trivial interplay between the inherent
spatiotemporal dynamics that characterizes the spreading of cooperation in a
particular social dilemma type and the frequency of payoff changes. In
particular, we show that periodic changes between two available games with
global ordering best be fast, while periodic changes between global and local
ordering games best be slow for cooperation to thrive. We also show that the
frequency of periodic changes between two local ordering social dilemmas is
irrelevant, because then the process is fast and simply the average cooperation
level of the two is returned. The structure of the interaction network plays an
important role too in that lattices promote local ordering, whilst random
graphs hinder the formation of compact cooperative clusters. Conversely, for
local ordering the regular structure of the interaction network is only
marginally relevant as role-separating checkerboard patterns do not rely on
long-range order.",http://arxiv.org/abs/1908.11805v1
Evolutionary dimension reduction in phenotypic space,2019-10-03T04:20:06Z,"Takuya U. Sato, Kunihiko Kaneko","In general, cellular phenotypes, as measured by concentrations of cellular
components, involve large degrees of freedom. However, recent measurement has
demonstrated that phenotypic changes resulting from adaptation and evolution in
response to environmental changes are effectively restricted to a
low-dimensional subspace. Thus, uncovering the origin and nature of such a
drastic dimension reduction is crucial to understanding the general
characteristics of biological adaptation and evolution. Herein, we first
formulated the dimension reduction in terms of dynamical systems theory:
considering the steady growth state of cells, the reduction is represented by
the separation of a few large singular values of the inverse Jacobian matrix
around a fixed point. We then examined this dimension reduction by numerical
evolution of cells consisting of thousands of chemicals whose concentrations
determine phenotype. As a result of the evolution, phenotypic changes due to
mutations and external perturbations were found to be mainly restricted to a
one-dimensional subspace. One singular value of the inverse Jacobian matrix at
a fixed point of concentrations was significantly larger than the others. The
major phenotypic changes due to mutations and external perturbations occur
along the corresponding left-singular vector, which leads to phenotypic
constraint, and fitness dominantly changes in the same direction. Once such
phenotypic constraint is acquired, phenotypic evolution to a novel environment
takes advantage of this restricted phenotypic direction. This results in the
convergence of phenotypic pathways across genetically different strains, as is
experimentally observed, while accelerating further evolution.",http://arxiv.org/abs/1910.01297v2
"Automating Data Monitoring: Detecting Structural Breaks in Time Series
  Data Using Bayesian Minimum Description Length",2019-10-04T04:03:02Z,"Yingbo Li, Robert Cezeaux, Di Yu","In modern business modeling and analytics, data monitoring plays a critical
role. Nowadays, sophisticated models often rely on hundreds or even thousands
of input variables. Over time, structural changes such as abrupt level shifts
or trend slope changes may occur among some of these variables, likely due to
changes in economy or government policies. As a part of data monitoring, it is
important to identify these changepoints, in terms of which variables exhibit
such changes, and what time locations do the changepoints occur. Being alerted
about the changepoints can help modelers decide if models need modification or
rebuilds, while ignoring them may increase risks of model degrading. Simple
process control rules often flag too many false alarms because regular seasonal
fluctuations or steady upward or downward trends usually trigger alerts. To
reduce potential false alarms, we create a novel statistical method based on
the Bayesian Minimum Description Length (BMDL) framework to perform multiple
change-point detection. Our method is capable of detecting all structural
breaks occurred in the past, and automatically handling data with or without
seasonality and/or autocorrelation. It is implemented with computation
algorithms such as Markov chain Monte Carlo (MCMC), and can be applied to all
variables in parallel. As an explainable anomaly detection tool, our
changepoint detection method not only triggers alerts, but provides useful
information about the structural breaks, such as the times of changepoints, and
estimation of mean levels and linear slopes before and after the changepoints.
This makes future business analysis and evaluation on the structural breaks
easier.",http://arxiv.org/abs/1910.01793v1
"Exploring the Role of Common Model of Cognition in Designing Adaptive
  Coaching Interactions for Health Behavior Change",2019-10-17T06:18:37Z,Shiwali Mohan,"Our research aims to develop intelligent collaborative agents that are
human-aware - they can model, learn, and reason about their human partner's
physiological, cognitive, and affective states. In this paper, we study how
adaptive coaching interactions can be designed to help people develop
sustainable healthy behaviors. We leverage the common model of cognition - CMC
[26] - as a framework for unifying several behavior change theories that are
known to be useful in human-human coaching. We motivate a set of interactive
system desiderata based on the CMC-based view of behavior change. Then, we
propose PARCoach - an interactive system that addresses the desiderata.
PARCoach helps a trainee pick a relevant health goal, set an implementation
intention, and track their behavior. During this process, the trainee
identifies a specific goal-directed behavior as well as the situational context
in which they will perform it. PARCcoach uses this information to send
notifications to the trainee, reminding them of their chosen behavior and the
context. We report the results from a 4-week deployment with 60 participants.
Our results support the CMC-based view of behavior change and demonstrate that
the desiderata for proposed interactive system design is useful in producing
behavior change.",http://arxiv.org/abs/1910.07728v3
"Two-stage data segmentation permitting multiscale change points, heavy
  tails and dependence",2019-10-28T08:02:16Z,"Haeran Cho, Claudia Kirch","The segmentation of a time series into piecewise stationary segments, a.k.a.
multiple change point analysis, is an important problem both in time series
analysis and signal processing. In the presence of multiscale change points
with both large jumps over short intervals and small changes over long
stationary intervals, multiscale methods achieve good adaptivity in their
localisation but at the same time, require the removal of false positives and
duplicate estimators via a model selection step. In this paper, we propose a
localised application of Schwarz information criterion which, as a generic
methodology, is applicable with any multiscale candidate generating procedure
fulfilling mild assumptions. We establish the theoretical consistency of the
proposed localised pruning method in estimating the number and locations of
multiple change points under general assumptions permitting heavy tails and
dependence. Further, we show that combined with a MOSUM-based candidate
generating procedure, it attains minimax optimality in terms of detection lower
bound and localisation for i.i.d. sub-Gaussian errors. A careful comparison
with the existing methods by means of (a) theoretical properties such as
generality, optimality and algorithmic complexity, (b) performance on simulated
datasets and run time, as well as (c) performance on real data applications,
confirm the overall competitiveness of the proposed methodology.",http://arxiv.org/abs/1910.12486v3
"Constant light element abundances suggest that the extended P1 in NGC
  2808 is not a consequence of CNO-cycle nucleosynthesis",2019-03-08T19:00:01Z,"I. Cabrera-Ziri, C. Lardo, A. Mucciarelli","Recent photometric results have identified a new population among globular
cluster stars. This population, referred to as the ``extended P1'', has been
suggested to be the manifestation of a new abundance pattern where the initial
mass fraction of He changes among cluster stars that share the same CNO values.
The current paradigm for the formation of the multiple stellar populations in
globular clusters assumes that variations in He are the product of chemical
``enrichment'' by the ashes of the CNO-cycle (which changes He and other
elements like C, N and O simultaneously). We obtained MIKE@Magellan spectra of
six giant stars in NGC 2808, a cluster with one of the strongest examples of
the extended P1 population. We provide the first complete characterization of
the light elements abundances for the stars along a significant range of the
extended P1 photometric group. The stars from our sample appear to be
homogeneous in C, N, O, Na, Mg and Al. The lack of a significant change in
these products of the CNO-cycle, suggest that unlike the rest of the
populations identified to date, the photometric changes responsible for the
extended P1 feature are a consequence of an alternative mechanism. Our
measurements, are consistent with the interpretations where the changes of the
He mass fraction among these stars could be consequence of p-p chain
nucleosynthesis (which could increase the He in stars without affecting heavier
elements). Having said that, direct measurements of He are necessary to
conclude if variations of this element are present among extended P1 stars.",http://arxiv.org/abs/1903.03621v1
"Pay to change lanes: A cooperative lane-changing strategy for
  connected/automated driving",2019-03-11T21:48:54Z,"DianChao Lin, Li Li, Saif Eddin Jabari","This paper proposes a cooperative lane changing strategy using a transferable
utility games framework. This allows vehicles to engage in transactions where
gaps in traffic are created in exchange for monetary compensation. The proposed
approach is best suited to discretionary lane change maneuvers. We formulate
gains in travel time, referred to as time differences, that result from
achieving higher speeds. These time differences, coupled with value of time,
are used to formulate a utility function, where utility is transferable. We
also allow for games between connected vehicles that do not involve transfer of
utility. We apply Nash bargaining theory to solve the latter. A cellular
automaton is developed and utilized to perform simulation experiments that
explore the impact of such transactions on traffic conditions (travel-time
savings, resulting speed-density relations and shock wave formation) and the
benefit to vehicles. The results show that lane changing with transferable
utility between drivers can help achieve win-win results, improve both
individual and social benefits without resulting in any adverse effects on
traffic characteristics in general and, in fact, result in slight improvement
at traffic densities outside of free-flow and (bumper-to-bumper) jammed
traffic.",http://arxiv.org/abs/1903.04620v2
"On Evaluation of Adversarial Perturbations for Sequence-to-Sequence
  Models",2019-03-15T16:04:11Z,"Paul Michel, Xian Li, Graham Neubig, Juan Miguel Pino","Adversarial examples --- perturbations to the input of a model that elicit
large changes in the output --- have been shown to be an effective way of
assessing the robustness of sequence-to-sequence (seq2seq) models. However,
these perturbations only indicate weaknesses in the model if they do not change
the input so significantly that it legitimately results in changes in the
expected output. This fact has largely been ignored in the evaluations of the
growing body of related literature. Using the example of untargeted attacks on
machine translation (MT), we propose a new evaluation framework for adversarial
attacks on seq2seq models that takes the semantic equivalence of the pre- and
post-perturbation input into account. Using this framework, we demonstrate that
existing methods may not preserve meaning in general, breaking the
aforementioned assumption that source side perturbations should not result in
changes in the expected output. We further use this framework to demonstrate
that adding additional constraints on attacks allows for adversarial
perturbations that are more meaning-preserving, but nonetheless largely change
the output sequence. Finally, we show that performing untargeted adversarial
training with meaning-preserving attacks is beneficial to the model in terms of
adversarial robustness, without hurting test performance. A toolkit
implementing our evaluation framework is released at
https://github.com/pmichel31415/teapot-nlp.",http://arxiv.org/abs/1903.06620v2
"Real-time data-driven detection of the rock type alteration during a
  directional drilling",2019-03-27T14:04:32Z,"Evgenya Romanenkova, Alexey Zaytsev, Nikita Klyuchnikov, Arseniy Gruzdev, Ksenia Antipova, Leyla Ismailova, Evgeny Burnaev, Artyom Semenikhin, Vitaliy Koryabkin, Igor Simon, Dmitry Koroteev","During the directional drilling, a bit may sometimes go to a nonproductive
rock layer due to the gap about 20m between the bit and high-fidelity rock type
sensors. The only way to detect the lithotype changes in time is the usage of
Measurements While Drilling (MWD) data. However, there are no general
mathematical modeling approaches that both well reconstruct the rock type based
on MWD data and correspond to specifics of the oil and gas industry. In this
article, we present a data-driven procedure that utilizes MWD data for quick
detection of changes in rock type. We propose the approach that combines
traditional machine learning based on the solution of the rock type
classification problem with change detection procedures rarely used before in
the Oil\&Gas industry. The data come from a newly developed oilfield in the
north of western Siberia. The results suggest that we can detect a significant
part of changes in rock type reducing the change detection delay from $20$ to
$1.8$ meters and the number of false-positive alarms from $43$ to $6$ per well.",http://arxiv.org/abs/1903.11436v2
"A Longitudinal Study of Static Analysis Warning Evolution and the
  Effects of PMD on Software Quality in Apache Open Source Projects",2019-12-02T16:37:10Z,"Alexander Trautsch, Steffen Herbold, Jens Grabowski","Automated static analysis tools (ASATs) have become a major part of the
software development workflow. Acting on the generated warnings, i.e., changing
the code indicated in the warning, should be part of, at latest, the code
review phase. Despite this being a best practice in software development, there
is still a lack of empirical research regarding the usage of ASATs in the wild.
In this work, we want to study ASAT warning trends in software via the example
of PMD as an ASAT and its usage in open source projects. We analyzed the commit
history of 54 projects (with 112,266 commits in total), taking into account 193
PMD rules and 61 PMD releases. We investigate trends of ASAT warnings over up
to 17 years for the selected study subjects regarding changes of warning types,
short and long term impact of ASAT use, and changes in warning severities. We
found that large global changes in ASAT warnings are mostly due to coding style
changes regarding braces and naming conventions. We also found that,
surprisingly, the influence of the presence of PMD in the build process of the
project on warning removal trends for the number of warnings per lines of code
is small and not statistically significant. Regardless, if we consider defect
density as a proxy for external quality, we see a positive effect if PMD is
present in the build configuration of our study subjects.",http://arxiv.org/abs/1912.02179v3
"Microscopyc description of the Photothermal increase of temperature for
  metallic nanoparticles excited with short-laser pulses",2019-04-03T17:14:34Z,"M. Rodríguez-Matus, C. Garcia-Segundo, Jean-Parick Connerade","The pulsed photothermal phenomenon due to optically absorbed energy, result
from non-radiative decay mechanisms, which in nature, these imply the temporal
change in the local free energy and thus a temporary change in the local
temperature. At the nanoscale, this is a prediction broadly described in terms
of macroscopic variables. Here we introduce a formalism based on the
Jarzynski's physical statistics description, for interpreting the equilibrium
free energy difference between two configurations of a metallic nanoparticle.
In this way, within a finite-time span, we describe the temporal increase of
the local free energy and thus of the local temperature arising from
temporarily bringing the sample far from thermal equilibrium. The result is an
expression for which one can get the photothermally induced change of
temperature for a metallic nanoparticle. For practical purposes, we limited the
study to Au nanoparticles. The study is made as function of the particle size
and the optical properties for wavelengths spanning the optical range. The
assessment indicates that, for nanoparticles with radii shorter than 40 nm, the
temperature change is strongly dependent on particle size and on the
illumination wavelength. While, for near 40 nm particle radii, the current
description and the known formalism, based on macroscopic variables, predict
the very same temperature change. At the closing we discuss additional possible
thermodynamic consequences associated to the scale considerations.",http://arxiv.org/abs/1904.02109v1
Polarization of changing-look quasars,2019-04-08T09:40:24Z,"D. Hutsemékers, B. Agís González, F. Marin, D. Sluse, C. Ramos Almeida, J. -A. Acosta Pulido","If the disappearance of the broad emission lines observed in changing-look
quasars originates from the obscuration of the quasar core by dusty clouds
moving in the torus, high linear optical polarization would be expected in
those objects. We then measured the rest-frame UV-blue linear polarization of a
sample of 13 changing-look quasars, 7 of them being in a type 1.9-2 state. For
all quasars but one the polarization degree is lower than 1%. This suggests
that the disappearance of the broad emission lines cannot be attributed to dust
obscuration, and supports the scenario in which changes of look are caused by a
change in the rate of accretion onto the supermassive black hole. Such low
polarization degrees also indicate that these quasars are seen under
inclinations close to the system axis. One type 1.9-2 quasar in our sample
shows a high polarization degree of 6.8%. While this polarization could be
ascribed to obscuration by a moving dusty cloud, we argue that this is unlikely
given the very long time needed for a cloud from the torus to eclipse the broad
emission line region of that object. We propose that the high polarization is
due to the echo of a past bright phase seen in polar-scattered light. This
interpretation raises the possibility that broad emission lines observed in the
polarized light of some type 2 active galactic nuclei can be echoes of past
type 1 phases and not evidence of hidden broad emission line regions.",http://arxiv.org/abs/1904.03914v1
"Region homogeneity in the Logarithmic Image Processing framework:
  application to region growing algorithms",2019-04-17T12:34:28Z,"Guillaume Noyel, Michel Jourlin","In order to create an image segmentation method robust to lighting changes,
two novel homogeneity criteria of an image region were studied. Both were
defined using the Logarithmic Image Processing (LIP) framework whose laws model
lighting changes. The first criterion estimates the LIP-additive homogeneity
and is based on the LIP-additive law. It is theoretically insensitive to
lighting changes caused by variations of the camera exposure-time or source
intensity. The second, the LIP-multiplicative homogeneity criterion, is based
on the LIP-multiplicative law and is insensitive to changes due to variations
of the object thickness or opacity. Each criterion is then applied in Revol and
Jourlin's (1997) region growing method which is based on the homogeneity of an
image region. The region growing method becomes therefore robust to the
lighting changes specific to each criterion. Experiments on simulated and on
real images presenting lighting variations prove the robustness of the criteria
to those variations. Compared to a state-of the art method based on the image
component-tree, ours is more robust. These results open the way to numerous
applications where the lighting is uncontrolled or partially controlled.",http://arxiv.org/abs/1904.12597v1
"Epistasis between cultural traits drives paradigm shifts in cultural
  evolution",2019-04-29T22:06:09Z,"Ignacio Pascual, Jacobo Aguirre, Susanna Manrubia, José A. Cuesta","Every now and then the cultural paradigm of a society changes. Human history
can be regarded as a sequence of long periods of cultural stasis punctuated by
paradigm shifts that transform culture upside-down over the turn of a few
generations. We propose here a population dynamics model devised to analyse
paradigm shifts. In this model individuals are defined by a vector of cultural
traits that can change mainly through imitation of other individuals' traits.
The novelty of the model is that cultural traits may interact reinforcing or
hindering each other. Imitation is then biased by the 'cultural fitness'
landscape thus defined. Our main result is that abrupt paradigm shifts occur,
as a response to weak changes in the landscape, only when cultural traits do
interact---whereas adaptation is smooth if there is no interaction. Borrowing
the genetic term, this interaction is called 'cultural epistasis'. The result
is robust to the way that epistasis is implemented, to whether imitation is
biased by homophily, or to changes in other model parameters. Finally, a
relevant consequence of this dynamics is the irreversible nature of paradigm
shifts: the old paradigm cannot be restored even if the external changes are
undone. Our model puts the phenomenon of paradigm shifts in cultural evolution
in the same category as catastrophic shifts in ecology or phase transitions in
physics.",http://arxiv.org/abs/1904.12972v1
"Signal detection using biphotons and potential application in axion-like
  particle search",2019-07-24T22:19:59Z,"Phuong Hoang Le, Binh Xuan Cao","This paper presents a new optical system for detecting light signals
associated with the change in incoming photon number. The system employs
quantum correlation of photon pairs created via spontaneous parametric
down-conversion (SPDC). The signal, if present, will perturb the flux of the
incident photon stream. The perturbed photon stream is first projected through
a birefringent crystal where SPDC occurs, converting a single high-energy
photon into a pair of low energy photons. The photons in each pair eventually
arrive at separate detectors. By examining the biphoton correlation using the
probability distribution of the photons at the detectors, which varies
depending on the displacement of the main pump photon stream and the change in
the number of photons, the small optical displacement of the photon stream and
its variance can be determined. The change in incident photon number, in other
words, the presence of light signal does not influence the average of the
measured optical displacement values. Nevertheless, the change in optical
displacement measurement variance when the number of incident photons has
changed detects the light signal. This optical setup enables the detection of
light signals with low noise and remarkably high precision and sensitivity
using quantum correlation. The proposed technique has potential application for
axion-like particle search in experimental high energy physics.",http://arxiv.org/abs/1907.10757v2
"Elastic stiffness tensors of Zr-$x$Nb alloy in presence of defects: A
  molecular dynamics study",2019-07-27T21:02:32Z,"Mohammad-Reza Basaadat, Mahmoud Payami","In a nuclear reactor, the Zr-$x$Nb alloy, which is used as a structural
material in the core region, is irradiated by energetic particles that cause
the atoms to be displaced from their lattice sites and giving rise to crystal
defects. The local changes in the atomic arrangements lead to local
deformations of the solid and thereby changes of its local mechanical
properties. Understanding the mechanisms behind this evolution in the core
region of a reactor, and its monitoring or controlling is a critical task in
nuclear industry. In this work, using extensive molecular dynamics simulations,
we have studied the effects of radiation damage on the local mechanical
properties of Zr-$x$Nb alloy. In the first step, the effect of Nb-concentration
on the mechanical stability of homogeneous Zr-$x$Nb alloy is investigated. In
the second step, we have studied the local changes of the elastic constants due
to local changes of the microstructure. These local changes include presence
and accumulation of vacancies in the form of dislocation loops or voids,
accumulation of Nb atoms in the form of clusters of different morphologies.
This study covers both cases of $T=0^\circ$K and finite temperatures up to
$T=600^\circ$K.",http://arxiv.org/abs/1907.11977v2
"MUSE observations of a changing-look AGN I: The re-appearance of the
  broad emission lines",2019-03-20T18:55:35Z,"S. I. Raimundo, M. Vestergaard, J. Y. Koay, D. Lawther, V. Casasola, B. M. Peterson","Optical changing-look Active Galactic Nuclei (AGN) are a class of sources
that change type within a short timescale of years or decades. This change is
characterised by the appearance or disappearance of broad emission lines, often
associated with dramatic AGN continuum flux changes that are orders of
magnitude larger than those expected from typical AGN variability. In this work
we study for the first time the host galaxy of a changing-look AGN, Mrk 590,
using high spatial resolution optical and near-infrared observations. We
discover that after ~ 10 yr absence, the optical broad emission lines of Mrk
590 have reappeared. The AGN optical continuum flux however, is still ~ 10
times lower than that observed during the most luminous state in the 1990s. The
host galaxy shows a 4.5 kpc radius star-forming ring with knots of ionised and
cold molecular gas emission. Extended ionised and warm molecular gas emission
are detected in the nucleus, indicating that there is a reservoir of gas as
close as 60 pc from the black hole. We observe a nuclear gas spiral between
radii r ~ 0.5 - 2 kpc, which has been suggested as a dynamical mechanism able
to drive the necessary gas to fuel AGN. We also discover blue-shifted and high
velocity dispersion [O III] emission out to a radius of 1 kpc, tracing a
nuclear gas outflow. The gas dynamics in Mrk 590 suggest a complex balance
between gas inflow and outflow in the nucleus of the galaxy.",http://arxiv.org/abs/1903.08696v2
"Sudden and Steady Orbital Period Changes Across the Classical Nova
  Eruptions of DQ Her and BT Mon",2019-12-12T19:25:31Z,Bradley E. Schaefer,"I report two new measures of the sudden change in the orbital period ($P$)
across the nova eruption ($\Delta$P) and the steady period change in quiescence
($\dot{P}$) for classical novae (CNe) DQ Her and BT Mon. The fractional changes
($\Delta$P/P) in parts-per-million (ppm) are $-$4.46$\pm$0.03 for DQ Her and
+39.6$\pm$0.5 for BT Mon. For BT Mon, the $\Delta$P/P value is not large enough
(i.e., $>$1580 ppm) to allow for Hibernation in this system. The {\it negative}
$\Delta$P/P for DQ Her is a confident counterexample of the Hibernation model
for the evolution of cataclysmic variables. Further, published models of period
changes by nova eruptions do not allow for such a negative value, so some
additional mechanism is required, with this perhaps being due to asymmetric
ejection of material. My program has also measured the first long-term
$\dot{P}$ for CNe, with 0.00$\pm$0.02 for DQ Her and $-$2.3$\pm$0.1 for BT Mon,
all with units of $10^{-11}$ days/cycle. These can be directly compared to the
predictions of the Magnetic Braking model, where the long-term average
$\dot{P}$ is a single universal function of $P$. The predicted values are
-0.027 for DQ Her and -0.33 for BT Mon. For both novae, the measured $\dot{P}$
is significantly far from the predictions for Magnetic Braking. Further, the
observed $\Delta$P for BT Mon imposes an additional {\it positive} period
change of +0.60$\times$10$^{-11}$ days/cycle when averaged over the eruption
cycle, so this system actually has a long-term {\it rise} in $P$.",http://arxiv.org/abs/1912.06169v1
CORE: Automating Review Recommendation for Code Changes,2019-12-20T06:14:18Z,"JingKai Siow, Cuiyun Gao, Lingling Fan, Sen Chen, Yang Liu","Code review is a common process that is used by developers, in which a
reviewer provides useful comments or points out defects in the submitted source
code changes via pull request. Code review has been widely used for both
industry and open-source projects due to its capacity in early defect
identification, project maintenance, and code improvement. With rapid updates
on project developments, code review becomes a non-trivial and labor-intensive
task for reviewers. Thus, an automated code review engine can be beneficial and
useful for project development in practice. Although there exist prior studies
on automating the code review process by adopting static analysis tools or deep
learning techniques, they often require external sources such as partial or
full source code for accurate review suggestion. In this paper, we aim at
automating the code review process only based on code changes and the
corresponding reviews but with better performance. The hinge of accurate code
review suggestion is to learn good representations for both code changes and
reviews. To achieve this with limited source, we design a multi-level embedding
(i.e., word embedding and character embedding) approach to represent the
semantics provided by code changes and reviews. The embeddings are then well
trained through a proposed attentional deep learning model, as a whole named
CORE. We evaluate the effectiveness of CORE on code changes and reviews
collected from 19 popular Java projects hosted on Github. Experimental results
show that our model CORE can achieve significantly better performance than the
state-of-the-art model (DeepMem), with an increase of 131.03% in terms of
Recall@10 and 150.69% in terms of Mean Reciprocal Rank. Qualitative general
word analysis among project developers also demonstrates the performance of
CORE in automating code review.",http://arxiv.org/abs/1912.09652v1
"Automatic detection of lesion load change in Multiple Sclerosis using
  convolutional neural networks with segmentation confidence",2019-04-05T12:59:58Z,"Richard McKinley, Lorenz Grunder, Rik Wepfer, Fabian Aschwanden, Tim Fischer, Christoph Friedli, Raphaela Muri, Christian Rummel, Rajeev Verma, Christian Weisstanner, Mauricio Reyes, Anke Salmen, Andrew Chan, Roland Wiest, Franca Wagner","The detection of new or enlarged white-matter lesions in multiple sclerosis
is a vital task in the monitoring of patients undergoing disease-modifying
treatment for multiple sclerosis. However, the definition of 'new or enlarged'
is not fixed, and it is known that lesion-counting is highly subjective, with
high degree of inter- and intra-rater variability. Automated methods for lesion
quantification hold the potential to make the detection of new and enlarged
lesions consistent and repeatable. However, the majority of lesion segmentation
algorithms are not evaluated for their ability to separate progressive from
stable patients, despite this being a pressing clinical use-case. In this paper
we show that change in volumetric measurements of lesion load alone is not a
good method for performing this separation, even for highly performing
segmentation methods. Instead, we propose a method for identifying lesion
changes of high certainty, and establish on a dataset of longitudinal multiple
sclerosis cases that this method is able to separate progressive from stable
timepoints with a very high level of discrimination (AUC = 0.99), while changes
in lesion volume are much less able to perform this separation (AUC = 0.71).
Validation of the method on a second external dataset confirms that the method
is able to generalize beyond the setting in which it was trained, achieving an
accuracy of 83% in separating stable and progressive timepoints. Both lesion
volume and count have previously been shown to be strong predictors of disease
course across a population. However, we demonstrate that for individual
patients, changes in these measures are not an adequate means of establishing
no evidence of disease activity. Meanwhile, directly detecting tissue which
changes, with high confidence, from non-lesion to lesion is a feasible
methodology for identifying radiologically active patients.",http://arxiv.org/abs/1904.03041v1
Monopole Antimonopole Instability in Non-Hermitian Coupled Waveguides,2019-02-06T10:50:36Z,"Rosie Hayward, Fabio Biancalana","A non-Hermitian coupled waveguide system with periodically varying
parameters, in which the Berry curvature is analogous to a hyperbolic magnetic
monopole or antimonopole, is investigated. It is shown to have a purely
imaginary Berry connection, and is consequently influenced by a geometric
multiplier. It is possible for this multiplier to induce net gain or loss in
the system, corresponding to the existence of the antimonopole or monopole in
parameter space, respectively. For the right choice of parameters, the system
will display an apparent non-adiabatic change in behaviour, which implies a
switch between the dominant eigenstate in the waveguides, leading to a change
in parameter space analogous to a charge reversal of the hyperbolic magnetic
monopole.",http://arxiv.org/abs/1902.02106v1
Entire nodal solutions to the critical Lane-Emden system,2019-02-06T13:02:53Z,"Mónica Clapp, Alberto Saldaña","We establish the existence of finitely many sign-changing solutions to the
Lane-Emden system $$-\Delta u=|v|^{q-2}v,\quad -\Delta v=|u|^{p-2}u \quad
\text{ in }\mathbb{R}^N, \ \ N\geq 4,$$ where the exponents $p$ and $q$ lie on
the critical hyperbola $\frac{1}{p}+\frac{1}{q}=\frac{N-2}{N}$. These solutions
are nonradial and arise as limit profiles of symmetric sign-changing minimizing
sequences for a critical higher-order problem in a bounded domain.",http://arxiv.org/abs/1902.02150v2
Higher Steenrod squares for Khovanov homology,2019-02-07T20:52:13Z,Federico Cantero Morán,"We describe stable cup-i products on the cochain complex with $F^2$
coefficients of any augmented semi-simplicial object in the Burnside category.
An example of such an object is the Khovanov functor of Lawson, Lipshitz and
Sarkar. Thus we obtain explicit formulas for cohomology operations on the
Khovanov homology of any link.",http://arxiv.org/abs/1902.02839v3
"Electromagnetic self-force of a point charge from the rate of change of
  the momentum of its retarded self-field",2019-02-12T16:46:46Z,"V. Hnizdo, G. Vaman","The self-force of a point charge moving on a rectilinear trajectory is
obtained, with no need of any explicit removal of infinities, as the negative
of the time rate of change of the momentum of its retarded self-field.",http://arxiv.org/abs/1902.04488v3
Probabilistic Generative Deep Learning for Molecular Design,2019-02-11T19:21:08Z,Daniel T. Chang,"Probabilistic generative deep learning for molecular design involves the
discovery and design of new molecules and analysis of their structure,
properties and activities by probabilistic generative models using the deep
learning approach. It leverages the existing huge databases and publications of
experimental results, and quantum-mechanical calculations, to learn and explore
molecular structure, properties and activities. We discuss the major components
of probabilistic generative deep learning for molecular design, which include
molecular structure, molecular representations, deep generative models,
molecular latent representations and latent space, molecular structure-property
and structure-activity relationships, molecular similarity and molecular
design. We highlight significant recent work using or applicable to this new
approach.",http://arxiv.org/abs/1902.05148v1
Seven Myths in Machine Learning Research,2019-02-18T20:38:14Z,"Oscar Chang, Hod Lipson","We present seven myths commonly believed to be true in machine learning
research, circa Feb 2019. This is an archival copy of the blog post at
https://crazyoscarchang.github.io/2019/02/16/seven-myths-in-machine-learning-research/
  Myth 1: TensorFlow is a Tensor manipulation library
  Myth 2: Image datasets are representative of real images found in the wild
  Myth 3: Machine Learning researchers do not use the test set for validation
  Myth 4: Every datapoint is used in training a neural network
  Myth 5: We need (batch) normalization to train very deep residual networks
  Myth 6: Attention $>$ Convolution
  Myth 7: Saliency maps are robust ways to interpret neural networks",http://arxiv.org/abs/1902.06789v2
"First-order perturbation theory for material changes in the surrounding
  of open optical resonators",2019-02-21T16:18:59Z,"Steffen Both, Thomas Weiss","The single-mode approximation of the resonant state expansion has proven to
give accurate first-order approximations of resonance shifts and linewidth
changes when modifying the material properties inside open optical resonators.
Here, we extend this first-order perturbation theory to modifications of the
material properties in the surrounding medium. As a side product of our
derivations, we retrieve the already known analytical normalization condition
for resonant states. We apply our theory to two example systems: A metallic
nanosphere and a one-dimensional photonic crystal slab.",http://arxiv.org/abs/1902.08120v1
"Cross helicity sign reversals in the dissipative scales of
  magnetohydrodynamic turbulence",2019-02-21T20:34:32Z,"V. Titov, R. Stepanov, N. Yokoi, M. Verma, R. Samtaney","We perform direct numerical simulations of magnetohydrodynamic (MHD)
turbulence with kinetic energy and cross helicity injections at large scales.
We observe that the cross helicity changes sign as we go from large and
intermediate scales to small scales. In addition, the magnetic reconnections
are strongest at the regions where the cross helicity changes sign and becomes
smallest in magnitude. Thus, our simulations provide an important window to
explore the regions of magnetic reconnections in nonlinear MHD.",http://arxiv.org/abs/1902.08253v1
Condition-Invariant Multi-View Place Recognition,2019-02-25T18:56:55Z,"Jose M. Facil, Daniel Olid, Luis Montesano, Javier Civera","Visual place recognition is particularly challenging when places suffer
changes in its appearance. Such changes are indeed common, e.g., due to
weather, night/day or seasons. In this paper we leverage on recent research
using deep networks, and explore how they can be improved by exploiting the
temporal sequence information. Specifically, we propose 3 different
alternatives (Descriptor Grouping, Fusion and Recurrent Descriptors) for deep
networks to use several frames of a sequence. We show that our approaches
produce more compact and best performing descriptors than single- and
multi-view baselines in the literature in two public databases.",http://arxiv.org/abs/1902.09516v1
Functoriality of Moduli Spaces of Global $\mathbb G$-Shtukas,2019-02-27T15:51:55Z,Paul Breutmann,"Moduli spaces of global $\mathbb G$-shtukas play a crucial role in the
Langlands program for function fields. We analyze their functoriality
properties following a change of the curve and a change of the group scheme
$\mathbb G$ under various aspects. In particular, we prove two finiteness
results which are of interest in the study of stratifications of these moduli
spaces and which potentially allow the formulation of an analog of the
Andr\'{e}-Oort conjecture for global $\mathbb G$-shtukas.",http://arxiv.org/abs/1902.10602v1
"Finite Boundary Regularity for Conformally Compact Einstein Manifolds of
  Dimension 4",2019-11-05T15:45:51Z,Xiaoshang Jin,"We prove that a $4-$dimensional $C^2$ conformally compact Einstein manifold
with H\""older continuous scalar curvature and with $C^{m,\alpha}$ boundary
metric has a $C^{m,\alpha}$ compactification. We also study the regularity of
the new structure and the new defining function. This is a supplementary proof
of Anderson's work and an improvement of Helliwell's result in dimension 4.",http://arxiv.org/abs/1911.01885v3
"Eddington-inspired Born-Infeld Gravity with Varying Cosmological
  Constant",2019-11-12T14:39:01Z,"Haomin Rao, Dehao Zhao","In this paper we modify the EiBI model to realize a varying cosmological
constant which is determined by matter distribution. We find that the Newton's
constant is also variable and its change is related to the change of
cosmological constant. And then we study its cosmological behavior. We find
that the early universe will have different behaviors if we take different
forms of pending functions. And we can avoid singularity in early universe just
like the original EiBI model.",http://arxiv.org/abs/1911.04896v1
Enhanced Voice Post Processing Using Voice Decoder Guidance Indicators,2019-11-13T15:48:27Z,"Phani Kumar Nyshadham, D R Shivakumar, Peter Kroon, Shmulik Markovich-Golan","Voice enhancement and voice coding are imperative and important functions in
a voice-communication system. However, both functions are commonly treated
independently, even though both utilize similar features of the underlying
signals. Our proposal is to leverage information from one function to the
benefit of the other. Specifically, our proposed changes are focused on changes
to the voice enhancement at the downlink side and utilizing information of the
voice decoding. Preliminary results show that such an approach results in
improved quality. Additionally, suggestions are provided on future extensions
of the proposed concept.",http://arxiv.org/abs/1911.05560v1
Virtual cycles of stable (quasi)-maps with fields,2019-11-22T03:14:15Z,"Qile Chen, Felix Janda, Rachel Webb","We generalize the results of Chang-Li, Kim-Oh and Chang-Li on the moduli of
$p$-fields to the setting of (quasi-)maps to complete intersections in
arbitrary smooth Deligne-Mumford stacks with projective coarse moduli. In
particular, we show that the virtual cycle of stable (quasi-)maps to a complete
intersection can be recovered by the cosection localized virtual cycle of the
moduli of $p$-fields of the ambient space.",http://arxiv.org/abs/1911.09825v2
Small-Instanton Transitions in F-theory,2019-11-28T19:50:32Z,"Stephen Angus, Kang-Sin Choi","We study the phase transition between G-instantons and D3-branes. A
G-instanton is a classical solution to the self-dual equation of the M/F-theory
four-form field strength G in the complex fourfold. This phase transition is
dual to that between small instantons and 5-branes in the heterotic string.
Using G as a background gauge flux, we may dynamically control the gauge
symmetry breaking, connect between different vacua of F-theory and understand
D3-branes in terms of group-theoretical quantities. We also discuss the
resulting chirality change and preservation of anomaly freedom.",http://arxiv.org/abs/1911.12846v2
"Magnetic orders induced by RKKY interaction in Tsai-type
  quasicrystalline approximant Au-Al-Gd",2019-11-29T05:06:23Z,"Haruka Miyazaki, Takanori Sugimoto, Katsuhiro Morita, Takami Tohyama","Recent experimental study on Tsai-type quasicrystalline approximant Au-Al-Gd
has revealed the presence of magnetic orders and phase transitions with
changing the Au/Al concentration. Motivated by the experiment, we theoretically
investigate whether a successive change of magnetic orders occurs in a minimal
magnetic model including the RKKY interaction only. We find that the model
induces multifarious magnetic orders depending on the Fermi wavenumber and
gives a good starting point for understanding the experimental observation. In
addition, we predict the presence of an undiscovered novel magnetic order
called cuboc order at large Fermi wavenumber region.",http://arxiv.org/abs/1911.12952v1
Vidange d'un réservoir,2019-11-25T15:49:13Z,"Thomas Gibaud, Alain Gibaud","We show in this article that depending on the flow conditions the same fluid
can be considered as a perfect fluid or on the contrary as viscous fluid. These
properties are addressed by emptying a tank. we show that we pass from one
regime to another by just changing the length of the outlet tube of the tank is
drained. This change of regime takes place in accordance with a criterion
defined in the theoretical part.",http://arxiv.org/abs/1911.13221v1
Automatically Inferring Gender Associations from Language,2019-08-30T23:27:06Z,"Serina Chang, Kathleen McKeown","In this paper, we pose the question: do people talk about women and men in
different ways? We introduce two datasets and a novel integration of approaches
for automatically inferring gender associations from language, discovering
coherent word clusters, and labeling the clusters for the semantic concepts
they represent. The datasets allow us to compare how people write about women
and men in two different settings - one set draws from celebrity news and the
other from student reviews of computer science professors. We demonstrate that
there are large-scale differences in the ways that people talk about women and
men and that these differences vary across domains. Human evaluations show that
our methods significantly outperform strong baselines.",http://arxiv.org/abs/1909.00091v1
About Fibonacci trees III: multiple Fibonacci trees,2019-09-04T15:41:20Z,Maurice Margenstern,"In this third paper, we revisit the question to which extent the properties
of the trees associated to the tilings $\{p,4\}$ of the hyperbolic plane are
still true if we consider a finitely generated tree by the same rules but
rooted at a black node? What happens if, considering the same distinction
between black and white nodes but changing the place of the black son in the
rules. What happens if we change the representation of the numbers by another
set of digits?
  We tackle all of these questions in the paper. The present paper is an
extension of the previous papers arXiv:1904.12135 and arXiv:1907.04677.",http://arxiv.org/abs/1909.01893v1
"Studying the variability of the X-ray spectral parameters of
  high-redshift GRBs' afterglows",2019-09-04T15:56:28Z,"Istvan I. Racz, Agnes J. Hortobagyi","The Swift satellite has observed more than a thousand GRBs with X-ray data.
Almost a third of them have redshift measurement, too. Here we start to
investigate the X-ray spectral fitting of the data considering the low energy
part where the N(H) absorption happens. Based on the available more accurate
input data we examined the robustness of previous fittings and tested how
sensitive the changes of the starting parameters are. We studied the change of
the intrinsic hydrogen column density during the outburst for a few events. No
significant variability of N(H) column density was identified.",http://arxiv.org/abs/1909.01905v1
Number of Sign Changes: Segment of AR(1),2019-09-05T17:53:31Z,Steven Finch,"Let $X_{t}$ denote a stationary first-order autoregressive process. Consider
$n$ contiguous observations (in time $t$) of the series (e.g., $X_{1}, ...,
X_{n}$). Let its mean be zero and its lag-one serial correlation be $\rho$,
which satisfies $|\rho| < 1$. Rice (1945) proved that $(n-1) \arccos(\rho)/\pi$
is the expected number of sign changes. A corresponding formula for
higher-order moments was proposed by Nyberg, Lizana & Ambj\""ornsson (2018),
based on an independent interval approximation. We focus on the variance only,
for small $n$, and see a promising fit between theory and model.",http://arxiv.org/abs/1909.02556v1
"An extended Speculation Game for the recovery of Hurst exponent of
  financial time series",2019-09-06T13:34:33Z,"Kei Katahira, Yu Chen","The speculation game is an agent-based toy model to investigate the dynamics
of the financial market. Our model has achieved the reproduction of 10 of the
well-known stylized facts for financial time series. However, there is also a
divergence from the behavior of real market. The market price of the model
tends to be anti-persistent to the initial price, resulting in the quite small
value of Hurst exponent of price change. To overcome this problem, we extend
the speculation game by introducing a perturbative part to the price change
with the consideration of other effects besides pure speculative behaviors.",http://arxiv.org/abs/1909.02899v1
"On integer values of the generating functions for sequences given by the
  Pell's equations",2019-09-07T16:00:54Z,Yuji Tsuno,"D. S. Hong and P. Pongsriiam have provided a necessary and sufficient
condition for the generating function for Fibonacci numbers (resp. the Lucas
numbers) to be an integer value, for rational numbers. In other words, their
results relate to the integer values of the generating functions of the
sequences obtained from the integer solutions of Pell's equation
$5x^{2}-y^{2}=\pm4$. If we change this Pell's equation to another type of
Pell's equation, how will their results change? This is a natural and
interesting problem. In this paper, we show that a result similar to theirs is
obtained for the generating functions for sequences given by Pell's equation
$x^{2}-my^{2}=\pm1 \ (m\text{ is a non-square natural number})$.",http://arxiv.org/abs/1909.03294v2
Impact of electron solvation on ice structures at the molecular scale,2019-09-09T13:22:11Z,"Cord Bertram, Philipp Auburger, Michel Bockstedte, Julia Stähler, Uwe Bovensiepen, Karina Morgenstern","We determine the impact of electron solvation on D$_2$O structures adsorbed
on Cu(111) with low temperature scanning tunneling microscopy, two-photon
photoemission, and ab initio theory. UV photons generating solvated electrons
lead not only to transient, but also to permanent structural changes through
the rearrangement of individual molecules. The persistent changes occur near
sites with a high density of dangling OH groups that facilitate electron
solvation. We conclude that energy dissipation during solvation triggers
permanent molecular rearrangement via vibrational excitation.",http://arxiv.org/abs/1909.03844v2
Higgs Mechanism and Debye Screening in the Generalized Electrodynamics,2019-09-10T20:20:12Z,"C. A. Bonin, G. B. de Gracia, A. A. Nogueira, B. M. Pimentel","In this work we study the Higgs mechanism and the Debye shielding for the
Bopp-Podolsky theory of electrodynamics. We find that not only the massless
sector of the Podolsky theory acquires a mass in both these phenomena, but also
that its massive sector has its mass changed. Furthermore, we find a
mathematical analogy in the way these masses change between these two
mechanisms. Besides exploring the behaviour of the screened potentials, we find
a temperature for which the presence of the generalized gauge field may be
experimentally detected.",http://arxiv.org/abs/1909.04731v1
Visualizing Trends of Key Roles in News Articles,2019-09-12T04:21:41Z,"Chen Xia, Haoxiang Zhang, Jacob Moghtader, Allen Wu, Kai-Wei Chang","There are tons of news articles generated every day reflecting the activities
of key roles such as people, organizations and political parties. Analyzing
these key roles allows us to understand the trends in news. In this paper, we
present a demonstration system that visualizes the trend of key roles in news
articles based on natural language processing techniques. Specifically, we
apply a semantic role labeler and the dynamic word embedding technique to
understand relationships between key roles in the news across different time
periods and visualize the trends of key role and news topics change over time.",http://arxiv.org/abs/1909.05449v1
"Infinitely many sign-changing solutions of a critical fractional
  equation",2019-09-12T13:43:08Z,"Emerson Abreu, Ezequiel Barbosa, Joel Cruz Ramirez","In this paper, we obtain nonexistence results of positive solutions, and also
the existence of an unbounded sequence of solutions that changing sign for some
critical problems involving conformally invariant operators on the standard
unit sphere, and the fractional Laplacian operator in the Euclidean space. Our
arguments are based on a reduction of the initial problem in the Euclidean
space to an equivalent problem on the standard unit sphere and vice versa, what
together to blow up arguments, a variant of Pohozaev's type identity, a
refinement of regularity results for this type operators, and finally, by
exploiting the symmetries of the sphere.",http://arxiv.org/abs/1909.05650v2
PredatorHP Attacks Interval-Sized Regions,2019-09-16T12:33:16Z,"Michal Kotoun, Petr Peringer, Veronika Šoková, Tomáš Vojnar","This paper describes shortly the basic principles of the PredatorHP (Predator
Hunting Party) shape analyzer and presents its recent improvements. One of the
most visible changes is the way PredatorHP handles interval-sized memory
regions, which is particularly useful for dealing with arrays whose size is not
fixed in advance. Further, the paper characterizes PredatorHP's participation
in SV-COMP 2019, pointing out its strengths and weakness and the way they were
influenced by the latest changes in the tool.",http://arxiv.org/abs/1909.07152v1
A Tractable Logic for Molecular Biology,2019-09-18T07:03:29Z,"Adrien Husson, Jean Krivine","We introduce a logic for knowledge representation and reasoning on
protein-protein interactions. Modulo a theory, formulas describe protein
structures and dynamic changes. They can be composed in order to add or remove
static and dynamic observations. A second-order circumscription operator then
enables nonmonotonic reasoning on the changes implied by a formula. We
introduce deduction rules that produce formulas which are, up to equivalence,
in a first-order fragment with decidable satisfiability and validity.
Importantly, the rules can produce circumscribed formulas.",http://arxiv.org/abs/1909.08236v1
Agility is responsiveness to change: An essential definition,2019-09-22T20:05:39Z,"Lucas Gren, Per Lenberg","There is some ambiguity of what agile means in both research and practice.
Authors have suggested a diversity of different definitions, through which it
is difficult to interpret what agile really is. The concept, however, exists in
its implementation through agile practices. In this vision paper, we argue that
adopting an agile approach boils down to being more responsive to change. To
support this claim, we relate agile principles, practices, the agile manifesto,
and our own experiences to this core definition. We envision that agile
transformations would be, and are, much easier using this definition and
contextualizing its implications.",http://arxiv.org/abs/1909.10082v2
"Design of Globally Exponentially Convergent Continuous Observers for
  Velocity Bias and State for Systems on Real Matrix Groups",2019-09-23T06:26:10Z,Dong Eui Chang,"We propose globally exponentially convergent continuous observers for
invariant kinematic systems on finite-dimensional matrix Lie groups. Such an
observer estimates, from measurements of landmarks, vectors and biased
velocity, both the system state and the unknown constant bias in velocity
measurement, where the state belongs to the state-space Lie group and the
velocity to the Lie algebra of the Lie group. The main technique is to embed a
given system defined on a matrix Lie group into Euclidean space and build
observers in the Euclidean space. The theory is illustrated with the special
Euclidean group in three dimensions.",http://arxiv.org/abs/1909.10179v1
Superposition of time-changed Poisson processes and their hitting times,2019-09-29T06:45:28Z,"A. Maheshwari, E. Orsingher, A. S. Sengar","The Poisson process of order $i$ is a weighted sum of independent Poisson
processes and is used to model the flow of clients in different services. In
the paper below we study some extensions of this process, for different forms
of the weights and also with the time-changed versions, with Bern\v stein
subordinator playing the role of time. We focus on the analysis of hitting
times of these processes obtaining sometimes explicit distributions. Since all
the processes examined display a similar structure with multiple upward jumps
sometimes they can skip all states with positive probability even on infinitely
long time span.",http://arxiv.org/abs/1909.13213v1
"Risk Neutral Reformulation Approach to Risk Averse Stochastic
  Programming",2019-01-04T20:30:56Z,"Rui Peng Liu, Alexander Shapiro","The aim of this paper is to show that in some cases risk averse multistage
stochastic programming problems can be reformulated in a form of risk neutral
setting. This is achieved by a change of the reference probability measure
making ``bad"" (extreme) scenarios more frequent. As a numerical example we
demonstrate advantages of such change-of-measure approach applied to the
Brazilian Interconnected Power System operation planning problem.",http://arxiv.org/abs/1901.01302v4
"The direct test of the absence of the ""quantum vampire's"" shadow with
  use of thermal light",2019-01-10T10:50:29Z,"K. G. Katamadze, E. V. Kovlakov, G. V. Avosopiants, S. P. Kulik","Counterintuitive nature of quantum physics leads to a number of paradoxes.
One of them is a ""quantum vampire"" effect [1] consisting in the fact, that
photon annihilation in a part of a large beam doesn't change the shape of the
beam profile (i. e., doesn't cast a shadow), but may change the total beam
intensity. Previously this effect was demonstrated just in a simplified
double-mode regime [1,2]. In the current paper the direct test of shadow
absence after the photon annihilation has been performed with use of thermal
state of light at the input.",http://arxiv.org/abs/1901.03093v1
Sharp Sobolev trace inequalities for higher order derivatives,2019-01-13T07:35:25Z,Qiaohua Yang,"Motivated by a recent work of Ache and Chang concerning the sharp Sobolev
trace inequality and Lebedev-Milin inequalities of order four on the Euclidean
unit ball, we derive such inequalities on the Euclidean unit ball for higher
order derivatives. By using, among other things, the scattering theory on
hyperbolic spaces and the generalized Poisson kernel, we obtain the explicit
formulas of extremal functions of such inequations. Moreover, we also derive
the sharp trace Sobolev inequalities on half spaces for higher order
derivatives. Finally, we compute the explicit formulas of adapted metric,
introduced by Case and Chang, on the Euclidean unit ball, which is of
independent interest.",http://arxiv.org/abs/1901.03945v1
Change of Variables with Local Time on Surfaces for Jump Processes,2019-01-13T19:10:42Z,Daniel Wilson,"The `local time on curves' formula of Peskir provides a stochastic change of
variables formula for a function whose derivatives may be discontinuous over a
time-dependent curve, a setting which occurs often in applications in optimal
control and beyond. This formula was further extended to higher dimensions and
to include processes with jumps under conditions which may be hard to verify in
practice. We build upon the work of Du Toit in weakening the required
conditions by allowing semimartingales with jumps. In addition, under vanishing
of the sectional first derivative (the so-called `smooth fit' condition), we
show that the classical It\^o formula still holds under general conditions.",http://arxiv.org/abs/1901.04039v1
"Tetrahedral entropy captures non-monotonicity of electrical conductivity
  in aqueous monatomic ions",2019-01-19T22:02:46Z,"Puja Banerjee, Biman Bagchi","The intriguing relationship between entropy and diffusion is a subject of
much current interest. However, the experimentally observed unusual
non-monotonic dependence of limiting ionic conductivity on inverse ion size is
neither described by the Adam-Gibbs entropy crisis theory nor by the Rosenfeld
entropy scaling. This failure is obvious because throughout the size variation
the bulk entropy of the solvent remains the same, or undergoes infinitesimal
change. We show that it is the entropy experienced by the tagged ion that needs
to be calculated. This entropy can be quantified, at least partly, by the
change in the tetrahedral ordering of water molecules in the hydration layer of
the ions which exhibits a nonmonotonic size dependence.",http://arxiv.org/abs/1901.06592v1
Online Adaptive Principal Component Analysis and Its extensions,2019-01-23T02:06:51Z,"Jianjun Yuan, Andrew Lamperski","We propose algorithms for online principal component analysis (PCA) and
variance minimization for adaptive settings. Previous literature has focused on
upper bounding the static adversarial regret, whose comparator is the optimal
fixed action in hindsight. However, static regret is not an appropriate metric
when the underlying environment is changing. Instead, we adopt the adaptive
regret metric from the previous literature and propose online adaptive
algorithms for PCA and variance minimization, that have sub-linear adaptive
regret guarantees. We demonstrate both theoretically and experimentally that
the proposed algorithms can adapt to the changing environments.",http://arxiv.org/abs/1901.07687v3
"Taming boundary condition changing operator anomalies with the tachyon
  vacuum",2019-01-23T18:38:58Z,"Theodore Erler, Carlo Maccaferri, Ruggero Noris","Motivated by the appearance of associativity anomalies in the context of
superstring field theory, we give a generalized solution built from boundary
condition changing operators which can be associated to a generic tachyon
vacuum in the $KBc$ subalgebra of the Okawa form. We articulate sufficient
conditions on the choice of tachyon vacuum to ensure that ambiguous products do
not appear in the equations of motion.",http://arxiv.org/abs/1901.08038v3
"Multi-stream Network With Temporal Attention For Environmental Sound
  Classification",2019-01-24T19:02:17Z,"Xinyu Li, Venkata Chebiyyam, Katrin Kirchhoff","Environmental sound classification systems often do not perform robustly
across different sound classification tasks and audio signals of varying
temporal structures. We introduce a multi-stream convolutional neural network
with temporal attention that addresses these problems. The network relies on
three input streams consisting of raw audio and spectral features and utilizes
a temporal attention function computed from energy changes over time. Training
and classification utilizes decision fusion and data augmentation techniques
that incorporate uncertainty. We evaluate this network on three commonly used
data sets for environmental sound and audio scene classification and achieve
new state-of-the-art performance without any changes in network architecture or
front-end preprocessing, thus demonstrating better generalizability.",http://arxiv.org/abs/1901.08608v1
"Investigation of the Mode-Switching Phenomenon in Pulsar B0329+54
  Through Polarimetric Analysis",2019-01-24T22:52:45Z,"Casey Brinkman, Dipanjan Mitra, Joanna Rankin","The phenomenon of profile mode switching in pulsars, where the stable average
pulse profile changes to another stable state on the timescale of a pulsar's
period, remains poorly understood. We sought to understand how pulsars undergo
profile mode switching through a comparative analysis of the polarization and
geometry of the two different profile modes of PSR B0329+54. The polarization
behavior and fitted parameters of the rotation-vector model remain constant
between modes, and the emission height remains constant as well. These
similarities lend support to a model of pair production in the surface plasma
that would cause a change in the available electrons and therefore the
differential emission intensity.",http://arxiv.org/abs/1901.08677v1
A simple INDIUM TIN OXIDE/glass DRA,2019-01-27T09:22:38Z,"Vivek Parimi, Chia Hao Ku, Abhirup Datta, Sajal Biring, Somaditya Sen","A novel Dielectric Resonator Antenna, simply made of INDIUM TIN OXIDE coated
glass slides placed on a microstrip transmission line, for communication
applications is presented. Changes in the bandwidth and gain of the antenna are
observed by modifying the dimensions of the INDIUM TIN OXIDE coated glass
slides. Changes in gain, directivity and reflection coefficient are observed. A
parametric study is conducted on the size of the DRA to understand the effect
on bandwidth, reflection coefficient and gain.",http://arxiv.org/abs/1901.09340v1
"Manipulation of magnetization in Pd(100) ultrathin films with quantum
  well structure using modification of Schottky barrier potentials",2019-01-28T01:34:15Z,"Hidetake Tanabe, Shunsuke Sakuragi, Tetsuya Sato","The magnetization of Pd(100) ultrathin films that show ferromagnetism due to
quantum well states was manipulated by changing the quantum well state with an
applied bias voltage. The voltage dependence of the magnetic moment of
Pd/SrTiO$_{3-x}$/Ti/Au intrinsically depends on the Pd film thickness. The
induced change in the magnetic moment is due to the modulation of the phase
shift at the interface between the Pd thin film and the semiconductor
SrTiO$_{3-x}$ substrate.",http://arxiv.org/abs/1901.09481v1
Leveraging Outdoor Webcams for Local Descriptor Learning,2019-01-28T16:28:52Z,"Milan Pultar, Dmytro Mishkin, Jiří Matas","We present AMOS Patches, a large set of image cut-outs, intended primarily
for the robustification of trainable local feature descriptors to illumination
and appearance changes. Images contributing to AMOS Patches originate from the
AMOS dataset of recordings from a large set of outdoor webcams.
  The semiautomatic method used to generate AMOS Patches is described. It
includes camera selection, viewpoint clustering and patch selection. For
training, we provide both the registered full source images as well as the
patches.
  A new descriptor, trained on the AMOS Patches and 6Brown datasets, is
introduced. It achieves state-of-the-art in matching under illumination changes
on standard benchmarks.",http://arxiv.org/abs/1901.09780v2
"Random Time Change and Related Evolution Equations: Time Asymptotic
  Behavior",2019-01-21T10:45:50Z,"Anatoly N. Kochubei, Yuri Kondratiev, José L. da Silva","In this paper we investigate the long time behavior of solutions to
fractional in time evolution equations which appear as results of random time
changes in Markov processes. We consider inverse subordinators as random times
and use the subordination principle for the solutions to forward Kolmogorov
equations. The class of subordinators for which asymptotic analysis may be
realized is described.",http://arxiv.org/abs/1901.10015v2
On symmetric equivalence of symmetric union diagrams,2019-01-29T13:23:32Z,"Carlo Collari, Paolo Lisca","Eisermann and Lamm introduced a notion of symmetric equivalence among
symmetric union diagrams and studied it using a refined form of the Jones
polynomial. We introduced invariants of symmetric equivalence via refined
versions of topological spin models and provided a partial answer to a question
left open by Eisermann and Lamm. In this paper we adopt a new approach to the
symmetric equivalence problem and give a complete answer to the original
question left open by Eisermann and Lamm.",http://arxiv.org/abs/1901.10270v3
"On the behavior of modules of $m$-integrable derivations in the sense of
  Hasse-Schmidt under base change",2019-05-05T15:30:22Z,María de la Paz Tirado Hernández,"We study the behavior of modules of $m$-integrable derivations of a
commutative finitely generated algebra in the sense of Hasse-Schmidt under base
change. We focus on the case of separable ring extensions over a field of
positive characteristic and on the case where the extension is a polynomial
ring in an arbitrary number of variables.",http://arxiv.org/abs/1905.01704v1
The Uniqueness of Hypergravity,2019-05-08T18:00:04Z,Rakibur Rahman,"We show that consistent interactions of a spin-2 and a higher-spin Majorana
fermion gauge fields in 3D flat space lead uniquely to Aragone-Deser
hypergravity or its generalization. Our analysis employs the BRST-cohomological
techniques, and works in the metric-like formulation under the assumptions of
locality, parity and Poincar\'e invariance. Local hypersymmetry shows up as the
unique consistent deformation of the gauge transformations. An extension of the
theory with fermion flavors does not change these features, while a
cosmological deformation becomes obstructed in the absence of other degrees of
freedom and/or non-locality.",http://arxiv.org/abs/1905.04109v2
"Holographic Dual of Conformal Field Theories with Very Special
  $T\bar{J}$ Deformations",2019-05-14T02:23:45Z,Yu Nakayama,"Very special $T\bar{J}$ deformations of a conformal field theory are
irrelevant deformations that break the Lorentz symmetry but preserve the
twisted Lorentz symmetry. We construct a holographic description of very
special $T\bar{J}$ deformations. We give a holographic recipe to study the
double trace as well as single trace deformations. The former is obtained from
the change of the boundary condition while the latter is obtained from the
change of the supergravity background.",http://arxiv.org/abs/1905.05353v1
"Photonic realization of the deformed Dirac equation via the segmented
  graphene nanoribbons under inhomogeneous strain",2019-05-15T06:49:55Z,"M. R. Setare, P. Majari, C. Noh, Sh. Dehdashti","Starting from an engineered periodic optical structure formed by waveguide
arrays comprised of two interleaved lattices, we simulate a deformed Dirac
equation. We show that the system also simulate graphene nano ribbons under
strain. This optical analogue allows us to study the phenomenon of
Zitterbewegung for the modified Dirac equation. Our results show that the
amplitude of Zitterbewegung oscillations changes as the deformation parameter
is changed.",http://arxiv.org/abs/1905.05972v1
Gravitational wave emission from the CMB and other thermal fields,2019-05-16T18:40:31Z,"Petar Simidzija, Achim Kempf, Eduardo Martin-Martinez","We calculate the gravitational wave power density emitted by quantum thermal
sources. As particular cases, we calculate the emission of gravitational waves
from the cosmic microwave background and from stellar sources. We study how
treating gravity classically affects the prediction of the thermal emission. We
find that the predicted emitted gravitational wave radiation does not exhibit
an ultraviolet divergence, even if gravity is treated classically, as long as
the fields describing the thermal source are quantum mechanical.",http://arxiv.org/abs/1905.06988v2
Decrement Operators in Belief Change,2019-05-20T21:09:55Z,"Kai Sauerwald, Christoph Beierle","While research on iterated revision is predominant in the field of iterated
belief change, the class of iterated contraction operators received more
attention in recent years. In this article, we examine a non-prioritized
generalisation of iterated contraction. In particular, the class of weak
decrement operators is introduced, which are operators that by multiple steps
achieve the same as a contraction. Inspired by Darwiche and Pearl's work on
iterated revision the subclass of decrement operators is defined. For both,
decrement and weak decrement operators, postulates are presented and for each
of them a representation theorem in the framework of total preorders is given.
Furthermore, we present two sub-types of decrement operators.",http://arxiv.org/abs/1905.08347v2
Spacelike deformations: Higher-helicity fields from scalar fields,2019-05-21T15:53:11Z,"Vincenzo Morinelli, Karl-Henning Rehren","In contrast to Hamiltonian perturbation theory which changes the time
evolution, ""spacelike deformations"" proceed by changing the translations
(momentum operators). The free Maxwell theory is only the first member of an
infinite family of spacelike deformations of the complex massless Klein-Gordon
quantum field into fields of higher helicity. A similar but simpler instance of
spacelike deformation allows to increase the mass of scalar fields.",http://arxiv.org/abs/1905.08714v2
"Gold nanorod induced enhanced efficiency in luminescent solar
  concentrator device",2019-05-23T12:05:04Z,"Puspendu Barik, Jaydeep Kumar Basu","We have observed significant changes in the edge emission of a luminescent
solar concentrator device (LSC) consist of core shell Cd1-xZnxSe1-ySy quantum
dots (QDs), and a monolayer of gold nanorods (GNRs) on the surface of LSC
device. The observed changes show a nonlinear growth when another LSC of same
thickness casted on the top of GNRs layer. The mechanism of plasmon-enhanced PL
is mainly associated with the surface plasmon excitation which were found to be
imprinted into the corresponding PL characteristics collected from the edge and
back side of LSCs. The findings point to so far not recognized any application
potentials of plasmonic LSC device.",http://arxiv.org/abs/1905.09606v1
Generalized Vaidya solutions in bimetric gravity,2019-05-23T18:00:01Z,"Marcus Högås, Mikica Kocic, Francesco Torsello, Edvard Mörtsell","In general relativity, the endpoint of spherically symmetric gravitational
collapse is a Schwarzschild--[(A)dS] black hole. In bimetric gravity, it has
been speculated that a static end state must also be Schwarzschild--[(A)dS]. To
this end, we present a set of exact solutions, including collapsing massless
dust particles. For these, the speculation is confirmed.",http://arxiv.org/abs/1905.09832v2
"Normal completions of toric varieties over rank one valuation rings and
  completions of $Γ$-admissible fans",2019-07-31T19:52:20Z,Netanel Friedenberg,"We show that any normal toric variety over a rank one valuation ring admits
an equivariant open embedding in a normal toric variety which is proper over
the valuation ring, after a base-change by a finite extension of valuation
rings. If the value group $\Gamma$ is discrete or divisible then no base-change
is needed. We give explicit examples which show that existing methods do not
produce such normal equivariant completions. Our approach is combinatorial and
proceeds by showing that $\Gamma$-admissible fans admit $\Gamma$-admissible
completions. In order to show this we prove a combinatorial analog of
noetherian reduction which we believe will be of independent interest.",http://arxiv.org/abs/1908.00064v1
"Non-Hermitian spectral changes in the scattering of partially coherent
  radiation by periodic structures",2019-08-01T22:17:33Z,"Paulo A. Brandão, S. B. Cavalcanti","The physical aspects of partially coherent radiation interacting with
deterministic non-Hermitian periodic materials remain largely unexplored in the
statistical optics literature. Here, we consider the scattering of partially
coherent radiation by a deterministic periodic medium, symmetric under the
simultaneous transformations of parity inversion and time reversal, that is, a
parity-time (PT)-symmetric periodic medium. Taking into account light
fluctuations, one is able to describe the spectrum changes on propagation and
the influence of the coherence-driven angular divergence effect. The far-field
spectral density profile is found to depend crucially on the loss/gain
properties of the material, giving rise to unexpected and contrasting spectral
diffraction profiles when compared to the Hermitian ones.",http://arxiv.org/abs/1908.00645v1
"Improving Generalization in Coreference Resolution via Adversarial
  Training",2019-08-13T16:39:48Z,"Sanjay Subramanian, Dan Roth","In order for coreference resolution systems to be useful in practice, they
must be able to generalize to new text. In this work, we demonstrate that the
performance of the state-of-the-art system decreases when the names of PER and
GPE named entities in the CoNLL dataset are changed to names that do not occur
in the training set. We use the technique of adversarial gradient-based
training to retrain the state-of-the-art system and demonstrate that the
retrained system achieves higher performance on the CoNLL dataset (both with
and without the change of named entities) and the GAP dataset.",http://arxiv.org/abs/1908.04728v1
A Review of Changepoint Detection Models,2019-08-20T02:58:49Z,"Yixiao Li, Gloria Lin, Thomas Lau, Ruochen Zeng","The objective of the change-point detection is to discover the abrupt
property changes lying behind the time-series data. In this paper, we firstly
summarize the definition and in-depth implication of the changepoint detection.
The next stage is to elaborate traditional and some alternative model-based
changepoint detection algorithms. Finally, we try to go a bit further in the
theory and look into future research directions.",http://arxiv.org/abs/1908.07136v1
Artificial Spin Ice Phase-Change Memory Resistors,2019-08-21T18:13:36Z,"Francesco Caravelli, Gia-Wei Chern, Cristiano Nisoli","We study the implications of the anisotropic magnetic resistance on permalloy
nanowires, and in particular on the property of the resistance depending on the
type of lattice. We discuss how the internal spin configuration of artificial
spin ice nanowires can affect their effective resistive state, and which
mechanisms can introduce a current-dependent effect dynamic resistive state. We
discuss a spin-induced thermal phase-change mechanism, and an athermal
domain-wall spin inversion. In both cases we observe memory behavior
reminiscent of a memristor, with an I-V hysteretic pinched behavior.",http://arxiv.org/abs/1908.08073v1
Random growth on a Ramanujan graph,2019-08-26T10:03:47Z,"Janko Boehm, Michael Joswig, Lars Kastner, Andrew Newman","The behavior of a certain random growth process is analyzed on arbitrary
regular and non-regular graphs. Our argument is based on the Expander Mixing
Lemma, which entails that the results are strongest for Ramanujan graphs, which
asymptotically maximize the spectral gap. Further, we consider
Erd\H{o}s--R\'enyi random graphs and compare our theoretical results with
computational experiments on flip graphs of point configurations. The latter is
relevant for enumerating triangulations.",http://arxiv.org/abs/1908.09575v2
Automated Fashion Size Normalization,2019-08-27T01:43:43Z,"Eddie S. J. Du, Chang Liu, David H. Wayne","The ability to accurately predict the fit of fashion items and recommend the
correct size is key to reducing merchandise returns in e-commerce. A critical
prerequisite of fit prediction is size normalization, the mapping of product
sizes across brands to a common space in which sizes can be compared. At
present, size normalization is usually a time-consuming manual process. We
propose a method to automate size normalization through the use of salesdata.
The size mappings generated from our automated approaches are comparable to
human-generated mappings.",http://arxiv.org/abs/1908.09980v1
An Auto-ML Framework Based on GBDT for Lifelong Learning,2019-08-29T03:30:11Z,"Jinlong Chai, Jiangeng Chang, Yakun Zhao, Honggang Liu","Automatic Machine Learning (Auto-ML) has attracted more and more attention in
recent years, our work is to solve the problem of data drift, which means that
the distribution of data will gradually change with the acquisition process,
resulting in a worse performance of the auto-ML model. We construct our model
based on GBDT, Incremental learning and full learning are used to handle with
drift problem. Experiments show that our method performs well on the five data
sets. Which shows that our method can effectively solve the problem of data
drift and has robust performance.",http://arxiv.org/abs/1908.11033v1
"Model Predictive Tracking Control for Invariant Systems on Matrix Lie
  Groups via Stable Embedding into Euclidean Spaces",2019-10-13T02:39:40Z,"Dong Eui Chang, Karmvir Singh Phogat, Jongeun Choi","For controller design for systems on manifolds embedded in Euclidean space,
it is convenient to utilize a theory that requires a single global coordinate
system on the ambient Euclidean space rather than multiple local charts on the
manifold or coordinate-free tools from differential geometry. In this article,
we apply such a theory to design model predictive tracking controllers for
systems whose dynamics evolve on manifolds and illustrate its efficacy with the
fully actuated rigid body attitude control system.",http://arxiv.org/abs/1910.05669v1
DTC ultrafilters on groups,2019-10-16T17:47:36Z,"Jan Pachl, Juris Steprāns","We say that an ultrafilter on an infinite group $G$ is DTC if it determines
the topological centre of the semigroup $\beta G$. We prove that DTC
ultrafilters do not exist for virtually BFC groups, and do exist for the
countable groups that are not virtually FC. In particular, an infinite finitely
generated group is virtually abelian if and only if it does not admit a DTC
ultrafilter.",http://arxiv.org/abs/1910.07505v3
Autonomous exploration for navigating in non-stationary CMPs,2019-10-18T14:40:26Z,"Pratik Gajane, Ronald Ortner, Peter Auer, Csaba Szepesvari","We consider a setting in which the objective is to learn to navigate in a
controlled Markov process (CMP) where transition probabilities may abruptly
change. For this setting, we propose a performance measure called exploration
steps which counts the time steps at which the learner lacks sufficient
knowledge to navigate its environment efficiently. We devise a learning
meta-algorithm, MNM and prove an upper bound on the exploration steps in terms
of the number of changes.",http://arxiv.org/abs/1910.08446v1
Estimating a Large Covariance Matrix in Time-varying Factor Models,2019-10-26T00:08:24Z,Jaeheon Jung,"This paper deals with the time-varying high dimensional covariance matrix
estimation. We propose two covariance matrix estimators corresponding with a
time-varying approximate factor model and a time-varying approximate
characteristic-based factor model, respectively. The models allow the factor
loadings, factor covariance matrix, and error covariance matrix to change
smoothly over time. We study the rate of convergence of each estimator. Our
simulation and empirical study indicate that time-varying covariance matrix
estimators generally perform better than time-invariant covariance matrix
estimators. Also, if characteristics are available that genuinely explain true
loadings, the characteristics can be used to estimate loadings more precisely
in finite samples; their helpfulness increases when loadings rapidly change.",http://arxiv.org/abs/1910.11965v1
Decidability of irreducible tree shifts of finite type,2019-10-30T13:31:49Z,"Jung-Chao Ban, Chih-Hung Chang, Nai-Zhu Huang, Yu-Liang Wu","We reveal an algorithm for determining the complete prefix code
irreducibility (CPC-irreducibility) of dyadic trees labeled by a finite
alphabet. By introducing an extended directed graph representation of tree
shift of finite type (TSFT), we show that the CPC-irreducibility of TSFTs is
related to the connectivity of its graph representation, which is a similar
result to one-dimensional shifts of finite type.",http://arxiv.org/abs/1910.13846v1
Sign changes in the prime number theorem,2019-10-31T01:22:44Z,"Thomas Morrill, Dave Platt, Tim Trudgian","Let $V(T)$ denote the number of sign changes in $\psi(x) - x$ for $x\in[1,
T]$. We show that $\liminf_{\;T\rightarrow\infty} V(T)/\log T \geq
\gamma_{1}/\pi + 1.867\cdot 10^{-30}$, where $\gamma_{1} = 14.13\ldots$ denotes
the ordinate of the lowest-lying non-trivial zero of the Riemann zeta-function.
This improves on a long-standing result by Kaczorowski.",http://arxiv.org/abs/1910.14203v3
Notes on Chow rings of G/B and BG,2019-10-31T15:42:08Z,Nobuaki Yagita,"Let $G$ be a compact Lie group and $T$ its maximal torus. The composition of
maps $ H^*(BG)\to H^*(BT) \to H^*(G/T)$ is zero for positive degree, while it
is far from exact. We change $H^*(G/T)$ by Chow ring $CH^*(X)$ for $X$ some
twisted form of $G/T$, and change $H^*(BG)$ by $CH^*(BG)$. Then we see that it
becomes near to exact but still not exact, in general. We also see that the
difference for exactness relates to the generalized Rost motive in $X$.",http://arxiv.org/abs/1910.14541v1
Magnetospheric Switching in PSR B1828-11,2019-03-04T22:43:05Z,"I. H. Stairs, A. G. Lyne, M. Kramer, B. W. Stappers, J. van Leeuwen, A. Tung, R. N Manchester, G. B. Hobbs, D. R. Lorimer, A. Melatos","PSR B1828-11 is a young pulsar once thought to be undergoing free precession
and recently found instead to be switching magnetospheric states in tandem with
spin-down changes. Here we show the two extreme states of the mode-changing
found for this pulsar and comment briefly on its interpretation.",http://arxiv.org/abs/1903.01574v1
"Regularity properties of free multiplicative convolution on the positive
  line",2019-03-06T11:32:44Z,Hong Chang Ji,"Given two nondegenerate Borel probability measures $\mu$ and $\nu$ on
$\mathbb{R}_{+}=[0,\infty)$, we prove that their free multiplicative
convolution $\mu\boxtimes\nu$ has zero singular continuous part and its
absolutely continuous part has a density bounded by $x^{-1}$. When $\mu$ and
$\nu$ are compactly supported Jacobi measures on $(0,\infty)$ having power law
behavior with exponents in $(-1,1)$, we prove that $\mu\boxtimes\nu$ is another
Jacobi measure whose density has square root decay at the edges of its support.",http://arxiv.org/abs/1903.02326v2
"Infinitely many solutions for a Schrodinger equation with sign-changing
  potential and nonlinear term",2019-03-07T15:59:00Z,"Long-Jiang Gu, Huan-Song Zhou","We propose a new variational approach to finding multiple critical points for
strongly indefinite problems without assuming the weak upper semicontinuity on
the variational functionals. By this approach, we obtain the existence of
infinitely many geometrically distinct solutions for a stationary periodic
Schr\""odinger equation, in which the linear part is strongly indefinite and the
nonlinear term is allowed to change sign in general ways.",http://arxiv.org/abs/1903.03012v3
Let's Play Mahjong!,2019-03-08T05:43:21Z,"Sanjiang Li, Xueqing Yan","Mahjong is a very popular tile-based game commonly played by four players.
Each player begins with a hand of 13 tiles and, in turn, players draw and
discard (i.e., change) tiles until they complete a legal hand using a 14th
tile. In this paper, we initiate a mathematical and AI study of the Mahjong
game and try to answer two fundamental questions: how bad is a hand of 14
tiles? and which tile should I discard? We define and characterise the notion
of deficiency and present an optimal policy to discard a tile in order to
increase the chance of completing a legal hand within $k$ tile changes for each
$k\geq 1$.",http://arxiv.org/abs/1903.03294v1
Analysis of the use of smart cards on the urban railway,2019-03-09T18:56:00Z,"Dmitry Namiot, Oleg Pokusaev, Vasily Kupriyanovsky","The article analyzes the patterns of use of railway stations in the Moscow
region. The basis for the analysis is the data of smart cards on the entrances
and exits of passengers. The technical tool is time series similarity analysis.
As a result, the work identifies the main patterns of user behavior on the use
of railway stations (railway transport). The results of the work were used in
the design of new lines of urban railways. Obviously, the use patterns reflect
the current state of the transport system and the urban environment.
Accordingly, the recorded changes in usage patterns can serve as indicators and
metrics for changes in the urban environment.",http://arxiv.org/abs/1903.03851v1
Coulomb branch of a multiloop quiver gauge theory,2019-03-14T05:53:17Z,"Michael Finkelberg, Evgeny Goncharov","We compute the Coulomb branch of a multiloop quiver gauge theory for the
quiver with a single vertex, $r$ loops, one-dimensional framing, and $\dim
V=2$. We identify it with a Slodowy slice in the nilpotent cone of the
symplectic Lie algebra of rank $r$. Hence it possesses a symplectic resolution
with $2r$ fixed points with respect to a Hamiltonian torus action. We also
idenfity its flavor deformation with a base change of the full Slodowy slice.",http://arxiv.org/abs/1903.05822v2
"Investigating the Impacts of Stochastic Load Fluctuation on Dynamic
  Voltage Stability Margin Using Bifurcation Theory",2019-03-18T15:21:32Z,"Georgia Pierrou, Xiaozhe Wang","This paper studies the impacts of stochastic load fluctuations, namely the
fluctuation intensity and the changing speed of load power, on the size of the
voltage stability margin. To this end, Stochastic Differential-Algebraic
Equations (SDAEs) are used to model the stochastic load variation; bifurcation
analysis is carried out to explain the influence of stochasticity. Numerical
study and Monte Carlo simulations on the IEEE 14-bus system demonstrate that a
larger fluctuation intensity or a slower load power changing speed may lead to
a smaller voltage stability margin. Particularly, this work may represent the
first attempt to reveal the influence of the time evolution property of the
driving parameters on the voltage stability margin in power systems.",http://arxiv.org/abs/1903.07502v1
A Pattern for the Flavor Dependence of the Quark-Gluon Interaction,2019-03-19T03:23:12Z,"Muyang Chen, Lei Chang","A flavor dependent kernel is constructed based on the rainbow-ladder
truncation of the Dyson-Schwinger and Bethe-Salpeter equation approach of
Quantum Chromodynamics. The quark-antiquark interaction is composed of a flavor
dependent infrared part and a flavor independent ultraviolet part. Our model
gives a successful and unified description of the light, heavy and heavy-light
ground pseudoscalar and vector mesons. For the first time, our model shows that
the infrared enhanced quark-antiquark interaction is stronger and wider for the
lighter quark.",http://arxiv.org/abs/1903.07808v3
Bayesian Estimation Based Parameter Estimation for Composite Load,2019-03-22T02:55:31Z,"Chang Fu, Zhe Yu, Di Shi, Haifeng Li, Caisheng Wang, Zhiwei Wang, Jie Li","Accurate identification of parameters of load models is essential in power
system computations, including simulation, prediction, and stability and
reliability analysis. Conventional point estimation based composite load
modeling approaches suffer from disturbances and noises and provide limited
information of the system dynamics. In this work, a statistic (Bayesian
Estimation) based distribution estimation approach is proposed for both static
(ZIP) and dynamic (Induction Motor) load modeling. When dealing with multiple
parameters, Gibbs sampling method is employed. In each iteration, the proposal
samples each parameter while keeps others fixed. The proposed method provides a
distribution estimation of load models coefficients and is robust to
measurement errors.",http://arxiv.org/abs/1903.10695v1
Geometry for evolving topographies of light-responsive plastic sheets,2019-03-27T13:13:03Z,Mark Warner,"Recently, topography change by illumination of pre-stretched, flat sheets
covered in ink of optical density varying in-plane has been demonstrated by
Mailen\textit{ et al}, Smart Materials and Structures, 2019. They reduce an
analysis of the problem to one of metric change in the sheets in the thin
limit, that is, to a question of geometry. We present the explicit form of the
contraction field needed to produce the bowls these authors were interested in,
using a method that can also yield the contraction field for more general
desired, circularly-symmetric topography development. We give as examples the
fields required for developing paraboloids and catenoids.",http://arxiv.org/abs/1903.11407v1
"Second order asymptotics for Krein indefinite multipliers with
  multiplicity two",2019-03-29T09:01:29Z,"Yinshan Chang, Jingzhi Yan","We consider linear Hamiltonian equations in $\mathbb{R}^{4}$ of the following
type \begin{equation}
  \frac{\mathrm{d}\gamma}{\mathrm{d}t}(t)=J_{4}A(t)\gamma(t),
\gamma(0)\in\operatorname{Sp}(4,\mathbb{R}), \end{equation} where
$J=J_{4}\overset{\text{def}}{=}\begin{bmatrix}0 &
\operatorname{Id}_2\\-\operatorname{Id}_2 & 0\end{bmatrix}$ and $A:t\mapsto
A(t)$ is a $C^1$-continuous curve in the space of $4\times 4$ real matrices
which are symmetric. We obtain second order asymptotics for the eigenvalues
bifurcated from non-real Krein indefinite eigenvalues with multiplicity two.",http://arxiv.org/abs/1903.12403v1
"A Changing Dichotomy: The Conception of the ""Macroscopic"" and
  ""Microscopic"" Worlds in the History of Physics",2019-12-02T16:42:08Z,Zhixin Wang,"This short essay traces the conceptual history of micro- and macroscopicity
in the context of physical science. By focusing on three distinct episodes
spanning five centuries, we show the scientific and philosophical meanings of
this antonym pair, despite never being far from ""the small"" and ""the large,""
have been evolving as the frontier of science advances. We analyze the
intellectual and material impetus for these movements, and conclude that this
conceptual history reflects the changing interaction between the natural world
and humankind.",http://arxiv.org/abs/1912.00914v2
"Second-order effects of the magnetic vector potential in the
  Aharonov-Bohm experiment",2019-12-04T18:47:37Z,Keith J. Kasunic,"Recent experiments with the Aharonov-Bohm geometry have shown that, in
addition to an electron-interference fringe shift, there is also a lateral
displacement of the electron diffraction envelope. In this paper, we derive a
displacement force based on a second-order expansion of the magnetic vector
potential. The analysis illustrates the conservation of canonical angular
momentum, where the mechanical angular momentum and field angular momentum sum
to a constant of the motion; the azimuthal force required to change the
mechanical momentum is thus supplied by changes in field momentum associated
with the second-order vector potential term. Our results are consistent with
all known Aharonov-Bohm experiments, including interference fringe shifts,
lateral displacement forces, and the absence of longitudinal forces.",http://arxiv.org/abs/1912.02169v1
Warped Input Gaussian Processes for Time Series Forecasting,2019-12-05T12:11:54Z,David Tolpin,"We introduce a Gaussian process-based model for handling of non-stationarity.
The warping is achieved non-parametrically, through imposing a prior on the
relative change of distance between subsequent observation inputs. The model
allows the use of general gradient optimization algorithms for training and
incurs only a small computational overhead on training and prediction. The
model finds its applications in forecasting in non-stationary time series with
either gradually varying volatility, presence of change points, or a
combination thereof. We evaluate the model on synthetic and real-world time
series data comparing against both baseline and known state-of-the-art
approaches and show that the model exhibits state-of-the-art forecasting
performance at a lower implementation and computation cost.",http://arxiv.org/abs/1912.02527v1
Strong necessary conditions and Cauchy problem,2019-11-30T11:12:36Z,Łukasz T. Stȩpień,"Some exact solutions of boundary or initial conditions formulated for
Bogomolny equations (derived by using the strong necessary conditions and
associated with some ordinary equation and some partial differential
equations), have been found. Besides, a degeneracy of the hamiltonian for the
restricted baby Skyrme model has been established.",http://arxiv.org/abs/1912.02609v2
A Note on Norine's Antipodal-Colouring Conjecture,2019-12-16T17:10:04Z,Vojtěch Dvořák,"Norine's antipodal-colouring conjecture, in a form given by Feder and Subi,
asserts that whenever the edges of the discrete cube are 2-coloured there must
exist a path between two opposite vertices along which there is at most one
colour change. The best bound to date was that there must exist such a path
with at most $n/2$ colour changes. Our aim in this note is to improve this
upper bound to $(\frac{3}{8}+o(1))n$.",http://arxiv.org/abs/1912.07504v1
"Random time-change with inverses of multivariate subordinators:
  governing equations and fractional dynamics",2019-12-19T17:58:54Z,"Luisa Beghin, Claudio Macci, Costantino Ricciuti","It is well-known that compositions of Markov processes with inverse
subordinators are governed by integro-differential equations of generalized
fractional type. This kind of processes are of wide interest in statistical
physics as they are connected to anomalous diffusions. In this paper we
consider a generalization; more precisely we mean componentwise compositions of
$\mathbb{R}^d$-valued Markov processes with the components of an independent
multivariate inverse subordinator. As a possible application, we present a
model of anomalous diffusion in anisotropic medium, which is obtained as a weak
limit of suitable continuous-time random walks.",http://arxiv.org/abs/1912.09432v2
Towards Symbolic Factual Change in DEL,2019-12-23T10:26:34Z,Malvin Gattinger,"We extend symbolic model checking for Dynamic Epistemic Logic (DEL) with
factual change. Our transformers provide a compact representation of action
models with pre- and postconditions, for both S5 and the general case. The
method can be implemented using binary decision diagrams and we expect it to
improve model checking performance. As an example we give a symbolic
representation of the Sally-Anne false belief task.",http://arxiv.org/abs/1912.10717v1
"Generalized low rank approximation to the symmetric positive
  semidefinite matrix",2019-12-20T12:18:04Z,"Haixia Chang, Chunmei Li, Qionghui Huang","In this paper, we investigate the generalized low rank approximation to the
symmetric positive semidefinite matrix in the Frobenius norm: $$\underset{
rank(X)\leq k}{\min} \sum^m_{i=1}\left \Vert A_i - B_i XB_i^T \right
\Vert^2_F,$$ where $X$ is an unknown symmetric positive semidefinite matrix and
$k$ is a positive integer. We firstly use the property of a symmetric positive
semidefinite matrix $X=YY^T$, $Y$ with order $n\times k$, to convert the
generalized low rank approximation into unconstraint generalized optimization
problem. Then we apply the nonlinear conjugate gradient method to solve the
generalized optimization problem. We give a numerical example to illustrate the
numerical algorithm is feasible.",http://arxiv.org/abs/1912.10856v1
"Tracking the polarisation state of light via Hong-Ou-Mandel
  interferometry",2019-12-27T13:20:23Z,"Natapon Harnchaiwat, Feng Zhu, Niclas Westerberg, Erik Gauger, Jonathan Leach","We provide a statistically robust and accurate framework to measure and track
the polarisation state of light employing Hong-Ou-Mandel interference. This is
achieved by combining the concepts of maximum likelihood estimation and Fisher
information applied to photon detection events. Such an approach ensures that
the Cram\'er-Rao bound is saturated and changes to the polarisation state are
established in an optimal manner. Using this method, we show that changes in
the linear polarisation state can be measured with 0.6 arcminute precision
(0.01 degrees).",http://arxiv.org/abs/1912.12087v1
"Third components with elliptical orbits in the eclipsing binaries: EQ
  Tau, IR Cas, IV Cas, RY Aqr & RZ Com",2019-12-29T11:48:50Z,D. E. Tvardovskyi,"This research is our forth article related to the topic of cyclic O-C
changes, third components as the physical process that cause these changes and
elliptical orbits of the third components. Here five more eclipsing binary
stars were investigated: EQ Tau, IR Cas, IV Cas, RY Aqr and RZ Com. All of them
have cyclic O-C curve with superposition of parabolic trend. We computed the
mass transfer rate, minima possible mass of the third component and their
errors for each of the researched stars.",http://arxiv.org/abs/1912.12639v1
One-loop CHY-Integrand of Bi-adjoint Scalar Theory,2019-12-30T15:17:30Z,"Bo Feng, Chang Hu","In this paper, the one-loop CHY-integrands of bi-adjoint scalar theory has
been reinvestigated. Differing from previous constructions, we have explicitly
removed contributions from tadpole and massless bubbles when taking the forward
limit of corresponding tree-level amplitudes. The way to remove those singular
contributions is to exploit the idea of 'picking poles', which is to multiply a
special cross ratio factor with the role of isolating terms having a particular
pole structure.",http://arxiv.org/abs/1912.12960v2
Singular Yamabe and Obata Problems,2019-12-30T23:10:06Z,"A. Rod Gover, Andrew Waldron","A conformal geometry determines a distinguished, potentially singular,
variant of the usual Yamabe problem, where the conformal factor can change
sign. When a smooth solution does change sign, its zero locus is a smoothly
embedded separating hypersurface that, in dimension three, is necessarily a
Willmore energy minimiser or, in higher dimensions, satisfies a conformally
invariant analog of the Willmore equation. In any case the zero locus is
critical for a conformal functional that generalises the total Q-curvature by
including extrinsic data. These observations lead to some interesting global
problems that include natural singular variants of a classical problem solved
by Obata.",http://arxiv.org/abs/1912.13114v1
Excited $B_{c}$ States via Continuum QCD,2019-03-31T12:49:14Z,"Lei Chang, Muyang Chen, Yu-xin Liu","We study the most recently observed excited $B_{c}$ states with the
Dyson-Schwinger equation and the Bethe-Salpeter equation approach of continuum
QCD. The obtained $M_{B^+_{c}(2S)}=6.813(16)\text{GeV}$,
$M_{B^{*+}_{c}(2S)}=6.841(18)\text{GeV}$ and the mass splitting
$M_{B_c^+(2S)}-M^{\text{rec}}_{B_c^{*+}(2S)} \approx 0.039 \text{GeV}$ agree
with the observations very well. Moreover we predict the leptonic decay
constant $f_{B^+_{c}(2S)}=-0.165(10)\text{GeV}$,
$f_{B^{*+}_{c}(2S)}=-0.161(7)\text{GeV}$ respectively.",http://arxiv.org/abs/1904.00399v1
Belousov-Zhabotinsky liquid marbles in robot control,2019-03-25T12:34:57Z,"Michail-Antisthenis Tsompanas, Claire Fullarton, Andrew Adamatzky","We show how to control the movement of a wheeled robot using on-board liquid
marbles made of Belousov-Zhabotinsky solution droplets coated with polyethylene
powder. Two stainless steel, iridium coated electrodes were inserted in a
marble and the electrical potential recorded was used to control the robot's
motor. We stimulated the marble with a laser beam. It responded to the
stimulation by pronounced changes in the electrical potential output. The
electrical output was detected by robot. The robot was changing its trajectory
in response to the stimulation. The results open new horizons for applications
for oscillatory chemical reactions in robotics.",http://arxiv.org/abs/1904.01520v1
"Sign-changing bubble-tower solutions to fractional semilinear elliptic
  problems",2019-04-04T18:24:14Z,"Gabriele Cora, Alessandro Iacopetti","We study the asymptotic and qualitative properties of least energy radial
sign-changing solutions to fractional semilinear elliptic problems of the form
\[ \begin{cases} (-\Delta)^s u = |u|^{2^*_s-2-\varepsilon}u &\text{in } B_R, \\
u = 0 &\text{in }\mathbb{R}^n \setminus B_R, \end{cases} \] where $s \in
(0,1)$, $(-\Delta)^s$ is the s-Laplacian, $B_R$ is a ball of $\mathbb{R}^n$,
$2^*_s := \frac{2n}{n-2s}$ is the critical Sobolev exponent and $\varepsilon>0$
is a small parameter. We prove that such solutions have the limit profile of a
""tower of bubbles"", as $ \varepsilon \to 0^+$, i.e. the positive and negative
parts concentrate at the same point with different concentration speeds.
Moreover, we provide information about the nodal set of these solutions.",http://arxiv.org/abs/1904.02738v1
"The first Hochschild (co)homology when adding arrows to a bound quiver
  algebra",2019-04-07T01:48:49Z,"Claude Cibils, Marcelo Lanzilotta, Eduardo N. Marcos, Sibylle Schroll, Andrea Solotar","We provide a formula for the change of the dimension of the first
Hoch\-schild cohomology vector space of bound quiver algebras when adding new
arrows. For this purpose we show that there exists a short exact sequence which
relates the first cohomology vector spaces of the algebras to the first
relative cohomology. Moreover, we show that the first Hochschild homologies are
isomorphic when adding new arrows.",http://arxiv.org/abs/1904.03565v2
"Wall-crossings and a categorification of $K$-theory stable bases of the
  Springer resolution",2019-04-07T23:14:46Z,"Changjian Su, Gufang Zhao, Changlong Zhong","We compare the $K$-theory stable bases of the Springer resolution associated
to different affine Weyl alcoves. We prove that (up to relabelling) the change
of alcoves operators are given by the Demazure-Lusztig operators in the affine
Hecke algebra. We then show that these bases are categorified by the Verma
modules of the Lie algebra, under the localization of Lie algebras in positive
characteristic of Bezrukavnikov, Mirkovi\'c, and Rumynin. As an application, we
prove that the wall-crossing matrices of the $K$-theory stable bases coincide
with the monodromy matrices of the quantum cohomology of the Springer
resolution.",http://arxiv.org/abs/1904.03769v2
What makes a complex a virtual resolution?,2019-04-12T00:48:55Z,Michael C. Loper,"Virtual resolutions are homological representations of finitely generated
$\text{Pic}(X)$-graded modules over the Cox ring of a smooth projective toric
variety. In this paper, we identify two algebraic conditions that characterize
when a chain complex of graded free modules over the Cox ring is a virtual
resolution. We then turn our attention to the saturation of Fitting ideals by
the irrelevant ideal of the Cox ring and prove some results that mirror the
classical theory of Fitting ideals for Noetherian rings.",http://arxiv.org/abs/1904.05994v2
"Chaotic Quantum Behaved Particle Swarm Optimization for Multiobjective
  Optimization in Habitability Studies",2019-04-19T19:13:36Z,"Arun John, Anish Murthy","In this paper, based on the Quantum-behaved Particle Swarm Optimization
algorithm, we evolve the algorithm to optimize a multiobjective optimization
problem, namely the Cobb Douglas Habitability function which is based on CES
production functions in Economics. We also propose some changes to the
Quantum-behaved Particle Swarm Optimization algorithm to mitigate the problem
of the algorithm prematurely converging and show the results of the proposed
changes to the Quantum-behaved Particle Swarm Optimization.",http://arxiv.org/abs/1904.09975v2
"Enhancing keV high harmonic signals generated by long-wave infrared
  lasers",2019-04-23T10:14:47Z,Zenghu Chang,"It is demonstrated by single-atom simulations that X-ray signals in the 3.4
to 4 keV region from an 8 micron laser driven high harmonic generation can be
increased by more than two orders of magnitude when a single-cycle pulse
centered at 800 nm is added. The ionization probability of a helium atom by the
two-pulse field is set to 4.56x10^-5, which is needed for balancing the index
of refraction of free electrons with that of neutral helium atoms to achieve
phase matching.",http://arxiv.org/abs/1904.10233v1
Descartes' rule of signs and moduli of roots,2019-04-24T08:38:10Z,Vladimir Petrov Kostov,"A hyperbolic polynomial (HP) is a real univariate polynomial with all roots
real. By Descartes' rule of signs a HP with all coefficients nonvanishing has
exactly $c$ positive and exactly $p$ negative roots counted with multiplicity,
where $c$ and $p$ are the numbers of sign changes and sign preservations in the
sequence of its coefficients. For $c=1$ and $2$, we discuss the question: When
the moduli of all the roots of a HP are arranged in the increasing order on the
real half-line, at which positions can be the moduli of its positive roots
depending on the positions of the sign changes in the sequence of coefficients?",http://arxiv.org/abs/1904.10694v1
"Non-volatile silicon photonic memory with more than 4-bit per cell
  capability",2019-04-29T14:26:47Z,"Xuan Li, Nathan Youngblood, C. David Wright, Wolfram H. P. Pernice, Harish Bhaskaran","We present the first demonstration of an integrated photonic phase-change
memory using GeSbTe-225 on silicon-on-insulator and demonstrate reliable
multilevel operation with a single programming pulse. We also compare our
results on silicon with previous demonstrations on silicon nitride. Crucially,
achieving this on silicon enables tighter integration of traditional
electronics with photonic memories in future, making phase-change photonic
memory a viable and integrable technology.",http://arxiv.org/abs/1904.12740v1
On idempotents of a class of commutative rings,2019-04-29T20:09:20Z,"Fernanda D. de Melo Hernández, César A. Hernández Melo, Horacio Tapia-Recillas","In the present work, a procedure for determining idempotents of a commutative
ring having a sequence of ideals with certain properties is presented. As an
application of this procedure, idempotent elements of various commutative rings
are determined. Several examples are included illustrating the main results.",http://arxiv.org/abs/1904.12932v2
"Formation of structure for gas-liquid, non-equilibrium polymer media",2019-06-11T18:28:16Z,"T. V. Savenkova, M. A. Taleisnik, A. R. Karimov, T. V. Gerasimov, A. M. Bulygin, S. A. Terekhov","This paper examines the mechanisms of destruction and synthesis for
macromolecules, which may be propelled by external acoustic fields in the flows
of polymeric liquids containing a large number of gas bubbles. The dynamics of
these bubbles is assumed to govern by changing the flow geometry and exciting
sound oscillations in the flow. Mechanically-induced kinetic changes in
macromolecules (destruction and synthesis of polymer chains) will occur when
the bubbles collapse.",http://arxiv.org/abs/1906.04764v1
Do Delta Baryons Play a Role in Neutron Stars?,2019-06-13T02:26:24Z,"T. F. Motta, A. W. Thomas, P. A. M. Guichon","The presence of exotic hadrons, such as hyperons and $\Delta$ isobars, in the
dense nuclear matter in their cores has been shown to produce important changes
in the properties of neutron stars. Within the quark-meson coupling model, we
show that the many-body forces generated by the change in the internal quark
structure of the baryons in the strong scalar mean fields generated in dense
nuclear matter prohibit the appearance of $\Delta$ isobars.",http://arxiv.org/abs/1906.05459v1
Comparative Analysis of Switching Dynamics in Different Memristor Models,2019-06-13T13:00:03Z,"Santosh Parajuli, Ram Kaji Budhathoki","Memristor, memory resistor, is an emerging technology for computational
memory. Number of different memristor models are available based on the
physical experiments. To use memristor as a computational memory element, one
should know how the internal state modulates in time when driven by current or
voltage. In this paper, we examine three widely used models and make a
comparison of how internal state in these models changes with respect to input
current or voltage. In Strukov model, internal state changes linearly with the
input current. However, the linearity of internal state modulation in Yang
model can be controlled. On the other hand, Pickett model shows non linear
variation in internal state with the input current.",http://arxiv.org/abs/1906.05643v1
Beyond the Isotropic Lifshitz Endpoint,2019-06-17T16:24:26Z,Tom T. S. Chang,"The puzzle of the disappearance of isotropic Lifshitz points in condensed
matter physics is explained from the point of view of the Wilsonian
renormalization group. In analogy to the commensurate ideas of metamagnetic
phase transitions, we describe the physics of thermodynamic states beyond an
isotropic Lifshitz endpoint. Such phenomenon may be understood in terms of a
statistically isotropic environment of coexisting multi-incommensurate
helicoidal states. In addition to the magnetic and condensed matter
discussions, we consider also an interesting example in the context of
dynamical evolution.",http://arxiv.org/abs/1906.07557v1
Cooperative Lane Changing via Deep Reinforcement Learning,2019-06-20T14:31:48Z,"Guan Wang, Jianming Hu, Zhiheng Li, Li Li","In this paper, we study how to learn an appropriate lane changing strategy
for autonomous vehicles by using deep reinforcement learning. We show that the
reward of the system should consider the overall traffic efficiency instead of
the travel efficiency of an individual vehicle. In summary, cooperation leads
to a more harmonic and efficient traffic system rather than competition",http://arxiv.org/abs/1906.08662v1
"Self-Oscillating Capacitive Wireless Power Transfer with Robust
  Operation",2019-06-21T21:43:23Z,"Fu Liu, Bhakti Chowkwale, Sergei A. Tretyakov","We show that a capacitive wireless power transfer device can be designed as a
self-oscillating circuit using operational amplifiers. As the load and the
capacitive wireless channels are part of the feedback circuit of the
oscillator, the wireless power transfer can self-adjust to the optimal
condition under the change of the load resistance and the transfer distance. We
have theoretically analyzed and experimentally demonstrated the proposed
design. The results show that the operation is robust against changes of
various parameters, including the load resistance.",http://arxiv.org/abs/1906.09339v1
Colored Unlinking,2019-06-29T18:22:38Z,"Natalie DuBois, Chris Eufemia, Jeff Johannes, Jenna Zomback","In links with two components there are three different types of crossings:
self-crossings in the first component, self crossings in the second component,
and crossings between components. In this paper we examine the minimum number
of crossing changes needed to unlink without changing the crossings between
components. We restrict our attention to unlinking two component links with
linking number zero and both components unknotted. We provide data for links
with no more than ten crossings and general results about asymmetry of
unlinking between components.",http://arxiv.org/abs/1907.00251v2
Fields of definition of K3 surfaces with complex multiplication,2019-07-02T13:07:36Z,Domenico Valloni,"Let $X/ \mathbb{C}$ be a K3 surface with complex multiplication by the ring
of integers of a CM field $E$. We show that $X$ can always be defined over an
Abelian extension $K/E$ explicitly determined by the discriminant form of the
lattice $\mathrm{NS}(X)$. We then construct a model of $X$ over $K$ via
Galois-descent and we study some of its basic properties, in particular we
determine its Galois representation explicitly. Finally, we apply our results
to give upper and lower bounds for a minimal field of definition for $X$ in
terms of the class number of $E$ and the discriminant of $\mathrm{NS}(X)$.",http://arxiv.org/abs/1907.01336v2
An Online Topic Modeling Framework with Topics Automatically Labeled,2019-06-22T02:42:44Z,"Fenglei Jin, Cuiyun Gao, Michael R. Lyu","In this paper, we propose a novel online topic tracking framework, named
IEDL, for tracking the topic changes related to deep learning techniques on
Stack Exchange and automatically interpreting each identified topic. The
proposed framework combines the prior topic distributions in a time window
during inferring the topics in current time slice, and introduces a new ranking
scheme to select most representative phrases and sentences for the inferred
topics in each time slice. Experiments on 7,076 Stack Exchange posts show the
effectiveness of IEDL in tracking topic changes and labeling topics.",http://arxiv.org/abs/1907.01638v1
Stabilization Time in Minority Processes,2019-07-03T20:55:47Z,"Pál András Papp, Roger Wattenhofer","We analyze the stabilization time of minority processes in graphs. A minority
process is a dynamically changing coloring, where each node repeatedly changes
its color to the color which is least frequent in its neighborhood. First, we
present a simple $\Omega(n^2)$ stabilization time lower bound in the sequential
adversarial model. Our main contribution is a graph construction which proves a
${\Omega}(n^{2-\epsilon})$ stabilization time lower bound for any $\epsilon>0$.
This lower bound holds even if the order of nodes is chosen benevolently, not
only in the sequential model, but also in any reasonable concurrent model of
the process.",http://arxiv.org/abs/1907.02131v1
Geometric moves relate geometric triangulations,2019-07-04T05:38:33Z,"Tejas Kalelkar, Advait Phanse","A geometric triangulation of a Riemannian manifold is a triangulation where
the interior of each simplex is totally geodesic. Bistellar moves are local
changes to the triangulation which are higher dimensional versions of the flip
operation of triangulations in a plane. We show that geometric triangulations
of a compact hyperbolic, spherical or Euclidean manifold are connected by
geometric bistellar moves (possibly adding or removing vertices), after taking
sufficiently many derived subdivisions. For dimensions 2 and 3, we show that
geometric triangulations of such manifolds are directly related by geometric
bistellar moves (without having to take derived subdivision).",http://arxiv.org/abs/1907.02643v3
"On the first Hochschild cohomology of cocommutative Hopf algebras of
  finite representation type",2019-07-09T11:42:49Z,Hao Chang,"Let $\mathscr{B}_0(\mathcal{G})\subseteq k\mathcal{G}$ be the principal block
algebra of the group algebra $k\mathcal{G}$ of an infinitesimal group scheme
$\mathcal{G}$ over an algebraically closed field $k$ of characteristic ${\rm
char}(k)=:p\geq 3$. We calculate the restricted Lie algebra structure of the
first Hochschild cohomology $\mathcal{L}:={\rm
H}^1(\mathscr{B}_0(\mathcal{G}),\mathscr{B}_0(\mathcal{G}))$ whenever
$\mathscr{B}_0(\mathcal{G})$ has finite representation type. As a consequence,
we prove that the complexity of the trivial $\mathcal{G}$-module $k$ coincides
with the maximal toral rank of $\mathcal{L}$.",http://arxiv.org/abs/1907.04093v1
On the mathematics and physics of Mixed Spin P-Fields,2019-07-14T01:00:00Z,"Huai-Liang Chang, Jun Li, Wei-Ping Li, Chiu-Chu Melissa Liu","We outline various developments of affine and general Landau Ginzburg models
in physics. We then describe the A-twisting and coupling to gravity in terms of
Algebraic Geometry. We describe constructions of various path integral measures
(virtual fundamental class) using the algebro-geometric technique of cosection
localization, culminating in the theory of ``Mixed Spin P (MSP) fields""
developed by the authors.",http://arxiv.org/abs/1907.06152v1
Fractional Immigration-Death Processes,2019-07-17T15:37:36Z,"Giacomo Ascione, Nikolai Leonenko, Enrica Pirozzi","In this paper we study explicit strong solutions for two
difference-differential fractional equations, defined via the generator of an
immigration-death process, by using spectral methods. Moreover, we give a
stochastic representation of the solutions of such difference-differential
equations by means of a stable time-changed immigration-death process and we
use this stochastic representation to show boundedness and then uniqueness of
these strong solutions. Finally, we study the limit distribution of the
time-changed process.",http://arxiv.org/abs/1907.07588v1
Insertion algorithm for inverting the signature of a path,2019-07-19T09:26:37Z,"Jiawei Chang, Terry Lyons","In this article we introduce the insertion method for reconstructing the path
from its signature, i.e. inverting the signature of a path. For this purpose,
we prove that a converging upper bound exists for the difference between the
inserted n-th term and the (n+1)-th term of the normalised signature of a
smooth path, and we also show that there exists a constant lower bound for a
subsequence of the terms in the normalised signature of a piecewise linear
path. We demonstrate our results with numerical examples.",http://arxiv.org/abs/1907.08423v1
Learning dynamic word embeddings with drift regularisation,2019-07-22T07:44:09Z,"Syrielle Montariol, Alexandre Allauzen","Word usage, meaning and connotation change throughout time. Diachronic word
embeddings are used to grasp these changes in an unsupervised way. In this
paper, we use variants of the Dynamic Bernoulli Embeddings model to learn
dynamic word embeddings, in order to identify notable properties of the model.
The comparison is made on the New York Times Annotated Corpus in English and a
set of articles from the French newspaper Le Monde covering the same period.
This allows us to define a pipeline to analyse the evolution of words use
across two languages.",http://arxiv.org/abs/1907.09169v1
Detecting Stable Communities in Link Streams at Multiple Temporal Scales,2019-07-24T13:58:07Z,"Souaad Boudebza, Remy Cazabet, Omar Nouali, Faical Azouaou","Link streams model interactions over time in a wide range of fields. Under
this model, the challenge is to mine efficiently both temporal and topological
structures. Community detection and change point detection are one of the most
powerful tools to analyze such evolving interactions. In this paper, we build
on both to detect stable community structures by identifying change points
within meaningful communities. Unlike existing dynamic community detection
algorithms, the proposed method is able to discover stable communities
efficiently at multiple temporal scales. We test the effectiveness of our
method on synthetic networks, and on high-resolution time-varying networks of
contacts drawn from real social networks.",http://arxiv.org/abs/1907.10453v1
SlideVaR: a risk measure with variable risk attitudes,2019-07-27T06:44:30Z,Wentao Hu,"To find a trade-off between profitability and prudence, financial
practitioners need to choose appropriate risk measures. Two key points are:
Firstly, investors' risk attitudes under uncertainty conditions should be an
important reference for risk measures. Secondly, risk attitudes are not
absolute. For different market performance, investors have different risk
attitudes. We proposed a new risk measure named SlideVaR which sufficiently
reflects the different subjective attitudes of investors and the impact of
market changes on investors' attitudes. We proposed the concept of risk-tail
region and risk-tail sub-additivity and proved that SlideVaR satisfies several
important mathematical properties. Moreover, SlideVaR has a simple and
intuitive form of expression for practical application. Several simulate and
empirical computations show that SlideVaR has obvious advantages in markets
where the state changes frequently.",http://arxiv.org/abs/1907.11855v1
Polarization of the Cosmic Infrared Background Fluctuations,2019-07-28T14:12:50Z,"Chang Feng, Gilbert Holder","The cosmic infrared background (CIB) is slightly polarized. Polarization
directions of individual galaxies could be aligned with tidal fields around
galaxies, resulting in nonzero CIB polarization. We use a linear intrinsic
alignment model to theoretically predict angular correlations of the CIB
polarization fluctuations and find that electriclike and curl-like ($B$-mode)
polarization modes are equally generated with power four orders of magnitude
less than its intensity. The CIB $B$-mode signal is negligible and not a
concerning foreground for the inflationary $B$-mode searches at nominal
frequencies for cosmic microwave background measurements, but could be detected
at submillimetre wavelengths by future space missions.",http://arxiv.org/abs/1907.12085v1
"Quadrupolar ordering and exotic magnetocaloric effect in RB4 (R = Dy,
  Ho)",2019-02-07T11:37:42Z,"M. S. Song, K. K. Cho, B. Y. Kang, S. B. Lee, B. K. Cho","The interplay of charge, spin, orbital and lattice degrees of freedom has
recently received great interest due to its potential to improve the
magnetocaloric effect (MCE) for the purpose of magnetic cooling applications.
Here we propose a new mechanism for a giant inverse MCE in rare-earth
tetraborides, especially for Ho1-xDyxB4 (x = 0.0, 0.5, and 1.0). For x = 0.0,
0.5, and 1.0, the maximum entropy changes of the giant inverse MCE are found to
be 22.7 J/kgK, 19.6 J/kgK, and 19.0 J/kgK with critical fields of 25 kOe, 40
kOe, and 50 kOe, respectively. It is remarkable that such a giant MCE is
realized, even when applying a low magnetic field, which enables a field-tuned
entropy change and brings about a significant advantage for several
applications. For all compounds, we have systematically studied how the entropy
changes as a function of the field and temperature and investigated their
correlation with consecutive double transitions, i.e., the magnetic dipolar
order at T = TN and the quadrupolar order at T = TQ (TQ < TN). We found that
the maximum entropy change occurs at T = TQ and the critical field associated
with the meta-magnetic transition, which is in good agreement with the
experimental data. Thus, we elucidate that this unique behaviour is attributed
to the strong coupling between magnetic dipoles and quadrupoles in the presence
of strong spin-orbit coupling and geometric frustration. Our work offers new
insights into both the academic interest of multipolar degrees of freedom in
magnetic materials and the discovery of giant MCE with various applications for
magnetic cooling systems.",http://arxiv.org/abs/1902.02576v1
A remark on Pinney's equation,2019-02-07T17:29:08Z,Philip Korman,"We show that Pinney's equation [2] with a constant coefficient can be reduced
to its linear part by a simple change of variables. Also, Pinney's original
solution is simplified slightly.",http://arxiv.org/abs/1902.02739v1
"Look No Deeper: Recognizing Places from Opposing Viewpoints under
  Varying Scene Appearance using Single-View Depth Estimation",2019-02-20T02:43:02Z,"Sourav Garg, Madhu Babu V, Thanuja Dharmasiri, Stephen Hausler, Niko Suenderhauf, Swagat Kumar, Tom Drummond, Michael Milford","Visual place recognition (VPR) - the act of recognizing a familiar visual
place - becomes difficult when there is extreme environmental appearance change
or viewpoint change. Particularly challenging is the scenario where both
phenomena occur simultaneously, such as when returning for the first time along
a road at night that was previously traversed during the day in the opposite
direction. While such problems can be solved with panoramic sensors, humans
solve this problem regularly with limited field of view vision and without
needing to constantly turn around. In this paper, we present a new depth- and
temporal-aware visual place recognition system that solves the opposing
viewpoint, extreme appearance-change visual place recognition problem. Our
system performs sequence-to-single matching by extracting depth-filtered
keypoints using a state-of-the-art depth estimation pipeline, constructing a
keypoint sequence over multiple frames from the reference dataset, and
comparing those keypoints to those in a single query image. We evaluate the
system on a challenging benchmark dataset and show that it consistently
outperforms state-of-the-art techniques. We also develop a range of diagnostic
simulation experiments that characterize the contribution of depth-filtered
keypoint sequences with respect to key domain parameters including degree of
appearance change and camera motion.",http://arxiv.org/abs/1902.07381v1
Graded change of ring,2019-02-22T18:54:43Z,Fred Rohrer,"We investigate scalar restriction, scalar extension, and scalar coextension
functors for graded modules, including their interplay with coarsening
functors, graded tensor products, and graded Hom functors. This leads to
several characterisations of epimorphisms of graded rings.",http://arxiv.org/abs/1902.08611v1
"Fitting stochastic epidemic models to gene genealogies using linear
  noise approximation",2019-02-24T02:24:16Z,"Mingwei Tang, Gytis Dudas, Trevor Bedford, Vladimir N. Minin","Phylodynamics is a set of population genetics tools that aim at
reconstructing demographic history of a population based on molecular sequences
of individuals sampled from the population of interest. One important task in
phylodynamics is to estimate changes in (effective) population size. When
applied to infectious disease sequences such estimation of population size
trajectories can provide information about changes in the number of infections.
To model changes in the number of infected individuals, current phylodynamic
methods use non-parametric approaches, parametric approaches, and stochastic
modeling in conjunction with likelihood-free Bayesian methods. The first class
of methods yields results that are hard-to-interpret epidemiologically. The
second class of methods provides estimates of important epidemiological
parameters, such as infection and removal/recovery rates, but ignores variation
in the dynamics of infectious disease spread. The third class of methods is the
most advantageous statistically, but relies on computationally intensive
particle filtering techniques that limits its applications. We propose a
Bayesian model that combines phylodynamic inference and stochastic epidemic
models, and achieves computational tractability by using a linear noise
approximation (LNA) --- a technique that allows us to approximate probability
densities of stochastic epidemic model trajectories. LNA opens the door for
using modern Markov chain Monte Carlo tools to approximate the joint posterior
distribution of the disease transmission parameters and of high dimensional
vectors describing unobserved changes in the stochastic epidemic model
compartment sizes (e.g., numbers of infectious and susceptible individuals). We
apply our estimation technique to Ebola genealogies estimated using viral
genetic data from the 2014 epidemic in Sierra Leone and Liberia.",http://arxiv.org/abs/1902.08877v1
Shear-induced electrical changes in the base of thin layer-cloud,2019-11-01T14:42:58Z,"R Giles Harrison, Graeme Marlton, Karen L Aplin, Keri Nicoll","Charging of upper and lower horizontal boundaries of extensive layer clouds
results from current flow in the global electric circuit. Layer-cloud charge
accumulation has previously been considered a solely electrostatic phenomenon,
but it does not occur in isolation from meteorological processes, which can
transport charge. Thin layer clouds provide special circumstances for
investigating this dynamical charge transport, as disruption at the cloud-top
may reach the cloud base, observable from the surface. Here, a thin (~300 m)
persistent layer-cloud with base at 300 m and strong wind shear at cloud-top
was observed to generate strongly correlated fluctuations in cloud base height,
optical thickness and surface electric Potential Gradient (PG) beneath. PG
changes are identified to precede the cloud base fluctuations by 2 minutes,
consistent with shear-induced cloud-top electrical changes followed by cloud
base changes. These observations demonstrate, for the first time, dynamically
driven modification of charge within a layer-cloud. Even in weakly charged
layer-clouds, redistribution of charge will modify local electric fields within
the cloud and the collisional behaviour of interacting charged cloud droplets.
Local field intensification may also explain previously observed electrostatic
discharges in warm clouds.",http://arxiv.org/abs/1911.00410v1
"The effect of our local motion on the Sandage-Loeb test of the cosmic
  expansion",2019-11-04T19:50:57Z,"Takuya Inoue, Eiichiro Komatsu, Wako Aoki, Takeshi Chiba, Toru Misawa, Tomonori Usuda","Redshifts of an astronomical body measured at multiple epochs (e.g.,
separated by 10 years) are different due to the cosmic expansion. This
so-called Sandage-Loeb test offers a direct measurement of the expansion rate
of the Universe. However, acceleration in the motion of Solar System with
respect to the cosmic microwave background also changes redshifts measured at
multiple epochs. If not accounted for, it yields a biased cosmological
inference. To address this, we calculate the acceleration of Solar System with
respect to the Local Group of galaxies to quantify the change in the measured
redshift due to local motion. Our study is motivated by the recent
determination of the mass of Large Magellanic Cloud (LMC), which indicates a
significant fraction of the Milky Way mass. We find that the acceleration
towards the Galactic Center dominates, which gives a redshift change of 7 cm/s
in 10 years, while the accelerations due to LMC and M31 cannot be ignored
depending on lines of sight. We create all-sky maps of the expected change in
redshift and the corresponding uncertainty, which can be used to correct for
this effect.",http://arxiv.org/abs/1911.01467v1
Response Prediction for Low-Regret Agents,2019-11-05T19:51:18Z,"Saeed Alaei, Ashwinkumar Badanidiyuru, Mohammad Mahdian, Sadra Yazdanbod","Companies like Google and Microsoft run billions of auctions every day to
sell advertising opportunities. Any change to the rules of these auctions can
have a tremendous effect on the revenue of the company and the welfare of the
advertisers and the users. Therefore, any change requires careful evaluation of
its potential impacts. Currently, such impacts are often evaluated by running
simulations or small controlled experiments. This, however, misses the
important factor that the advertisers respond to changes. Our goal is to build
a theoretical framework for predicting the actions of an agent (the advertiser)
that is optimizing her actions in an uncertain environment. We model this
problem using a variant of the multi-armed bandit setting where playing an arm
is costly. The cost of each arm changes over time and is publicly observable.
The value of playing an arm is drawn stochastically from a static distribution
and is observed by the agent and not by us. We, however, observe the actions of
the agent. Our main result is that assuming the agent is playing a strategy
with a regret of at most $f(T)$ within the first $T$ rounds, we can learn to
play the multi-armed bandits game (without observing the rewards) in such a way
that the regret of our selected actions is at most $O(k^4(f(T)+1)\log(T))$,
where $k$ is the number of arms.",http://arxiv.org/abs/1911.02056v1
Positive Strong Amalgamation,2019-11-06T15:18:45Z,Mohammed Belkasmi,"We present the notions of positively complete theory and general forms of
amalgamation in the framework of positive logic. We explore the fundamental
properties of positively complete theories and study the behaviour of companion
theories by a change of constants in the language. Moreover, we present a
general form of amalgamation and discuss some forms of strong amalgamation.",http://arxiv.org/abs/1911.06109v1
"Electric dipole moment of the neutron in Two Higgs Doublet Models with
  flavor changing",2019-11-12T19:17:04Z,Jan O. Eeg,"I consider contributions to the neutron electric dipole moment within Two
Higgs Doublet Models which allow for small flavor changing neutral Higgs
couplings. In a previous paper, I considered flavor changing interactions for
the Standard Model Higgs boson to first order in the flavor changing coupling.
In that paper I found that the obtained value of the neutron electric dipole
moment were below the present experimental limit, given previous restrictions
on such couplings. Because this was an effective theory, the result depended on
an ultraviolet cut off $\Lambda$, parametrized as $ln(\Lambda^2)$. In the
present paper I demonstrate that, when going to Two Higgs Doublet Models, the
result stays the same as in the previous paper, up to $M_{SM}^2/M_H^2$
corrections, where $M_{SM}$ is the mass of the top-quark or the $W$-boson.
$M_H$ is the mass of the heavy neutral scalar Higgs-boson $H$ which is much
heavier than the light neutral Higgs boson $h$ with mass $M_h$. In the limit
$M_H^2 \gg M_h^2$, the $ln(\Lambda^2)$ behaviour in the previous paper is
replaced by $ln(\widetilde{M_H}^2)$, where $\widetilde{M_H}$ is of order $M_H$.
I also explain how some divergences due to exchange of the pseudoscalar Higgs
$A$ are cancelled by similar contributions from the scalar heavy Higgs $H$, and
that these contributions, and finite contributions from $A$-exchange, are
suppressed.",http://arxiv.org/abs/1911.07291v4
Differential subalgebras and norm-controlled inversion,2019-11-20T03:12:14Z,"Chang Eon Shin, Qiyu Sun","In this paper, we consider the norm-controlled inversion for differential
$*$-subalgebras of a symmetric $*$-algebra with common identity and involution.",http://arxiv.org/abs/1911.08679v1
"ApproxNet: Content and Contention-Aware Video Analytics System for
  Embedded Clients",2019-08-28T19:29:41Z,"Ran Xu, Rakesh Kumar, Pengcheng Wang, Peter Bai, Ganga Meghanath, Somali Chaterji, Subrata Mitra, Saurabh Bagchi","Videos take a lot of time to transport over the network, hence running
analytics on the live video on embedded or mobile devices has become an
important system driver. Considering that such devices, e.g., surveillance
cameras or AR/VR gadgets, are resource constrained, creating lightweight deep
neural networks (DNNs) for embedded devices is crucial. None of the current
approximation techniques for object classification DNNs can adapt to changing
runtime conditions, e.g., changes in resource availability on the device, the
content characteristics, or requirements from the user. In this paper, we
introduce ApproxNet, a video object classification system for embedded or
mobile clients. It enables novel dynamic approximation techniques to achieve
desired inference latency and accuracy trade-off under changing runtime
conditions. It achieves this by enabling two approximation knobs within a
single DNN model, rather than creating and maintaining an ensemble of models
(e.g., MCDNN [MobiSys-16]. We show that ApproxNet can adapt seamlessly at
runtime to these changes, provides low and stable latency for the image and
video frame classification problems, and show the improvement in accuracy and
latency over ResNet [CVPR-16], MCDNN [MobiSys-16], MobileNets [Google-17],
NestDNN [MobiCom-18], and MSDNet [ICLR-18].",http://arxiv.org/abs/1909.02068v5
"Harnack Inequalities for Functional SDEs Driven by Subordinate Brownian
  Motions",2019-09-07T09:18:00Z,"Chang-Song Deng, Xing Huang","Using coupling by change of measure and an approximation technique, Wang's
Harnack inequalities are established for a class of functional SDEs driven by
subordinate Brownian motions. The results cover the corresponding ones in the
case without delay.",http://arxiv.org/abs/1909.03224v1
"Follow the Leader: Documents on the Leading Edge of Semantic Change Get
  More Citations",2019-09-09T22:43:02Z,"Sandeep Soni, Kristina Lerman, Jacob Eisenstein","Diachronic word embeddings -- vector representations of words over time --
offer remarkable insights into the evolution of language and provide a tool for
quantifying sociocultural change from text documents. Prior work has used such
embeddings to identify shifts in the meaning of individual words. However,
simply knowing that a word has changed in meaning is insufficient to identify
the instances of word usage that convey the historical or the newer meaning. In
this paper, we link diachronic word embeddings to documents, by situating those
documents as leaders or laggards with respect to ongoing semantic changes.
Specifically, we propose a novel method to quantify the degree of semantic
progressiveness in each word usage, and then show how these usages can be
aggregated to obtain scores for each document. We analyze two large collections
of documents, representing legal opinions and scientific articles. Documents
that are scored as semantically progressive receive a larger number of
citations, indicating that they are especially influential. Our work thus
provides a new technique for identifying lexical semantic leaders and
demonstrates a new link between progressive use of language and influence in a
citation network.",http://arxiv.org/abs/1909.04189v2
Topological theory of physical fields,2019-09-11T03:10:42Z,"Amir Jafari, Ethan Vishniac","We study the topology associated with physical vector and scalar fields. A
mathematical object, e.g., a ball, can be continuously deformed, without
tearing or gluing, to make other topologically equivalent objects, e.g., a cube
or a solid disk. If tearing or gluing get involved, i.e., the deformation is
not continuous anymore, the initial topology will consequently change giving
rise to a topologically distinct object, e.g., a torus. This simple concept in
general topology may be employed in the study of physical systems described by
fields. Instead of continuously deforming objects, we can take a continuously
evolving field, with an appropriately defined topology, such that the topology
remains unchanged in time unless the system undergoes an important physical
change, e.g., a transition to a different energy state. For instance, a sudden
change in the magnetic topology in an energetically relaxing plasma, a process
called reconnection, strongly affects the dynamics, e.g., it is involved in
launching solar flares and generating large scale magnetic fields in
astrophysical objects. In this topological formalism, the magnetic topology in
a plasma can spontaneously change due to the presence of dissipative terms in
the induction equation which break its time symmetry. We define a topology for
the vector field $\bf F$ in the phase space $(\bf x, F)$. As for scalar fields
represented by a perfect fluid, e.g., the inhomogeneous inflaton or Higgs
fields, the fluid velocity $\bf u$ defines the corresponding topology. The
vector field topology in its corresponding phase space $(\bf x, F)$ will be
preserved in time if certain conditions including time reversal invariance are
satisfied by the field and its governing differential equation.",http://arxiv.org/abs/1909.04836v3
"A new concept of technology with systemic-purposeful perpsective:
  theory, examples and empirical application",2019-09-11T08:18:37Z,Mario Coccia,"Although definitions of technology exist to explain the patterns of
technological innovations, there is no general definition that explain the role
of technology for humans and other animal species in environment. The goal of
this study is to suggest a new concept of technology with a systemic-purposeful
perspective for technology analysis. Technology here is a complex system of
artifact, made and_or used by living systems, that is composed of more than one
entity or sub-system and a relationship that holds between each entity and at
least one other entity in the system, selected considering practical, technical
and_or economic characteristics to satisfy needs, achieve goals and_or solve
problems of users for purposes of adaptation and_or survival in environment.
Technology T changes current modes of cognition and action to enable makers
and_or users to take advantage of important opportunities or to cope with
consequential environmental threats. Technology, as a complex system, is formed
by different elements given by incremental and radical innovations.
Technological change generates the progress from a system T1 to T2, T3, etc.
driven by changes of technological trajectories and technological paradigms.
Several examples illustrate here these concepts and a simple model with a
preliminary empirical analysis shows how to operationalize the suggested
definition of technology. Overall, then, the role of adaptation (i.e.
reproductive advantage) can be explained as a main driver of technology use for
adopters to take advantage of important opportunities or to cope with
environmental threats. This study begins the process of clarifying and
generalizing, as far as possible, the concept of technology with a new
perspective that it can lay a foundation for the development of more
sophisticated concepts and theories to explain technological and economic
change in environment.",http://arxiv.org/abs/1909.05689v1
V2: Fast Detection of Configuration Drift in Python,2019-09-13T14:25:06Z,"Eric Horton, Chris Parnin","Code snippets are prevalent, but are hard to reuse because they often lack an
accompanying environment configuration. Most are not actively maintained,
allowing for drift between the most recent possible configuration and the code
snippet as the snippet becomes out-of-date over time. Recent work has
identified the problem of validating and detecting out-of-date code snippets as
the most important consideration for code reuse. However, determining if a
snippet is correct, but simply out-of-date, is a non-trivial task. In the best
case, breaking changes are well documented, allowing developers to manually
determine when a code snippet contains an out-of-date API usage. In the worst
case, determining if and when a breaking change was made requires an exhaustive
search through previous dependency versions.
  We present V2, a strategy for determining if a code snippet is out-of-date by
detecting discrete instances of configuration drift, where the snippet uses an
API which has since undergone a breaking change. Each instance of configuration
drift is classified by a failure encountered during validation and a
configuration patch, consisting of dependency version changes, which fixes the
underlying fault. V2 uses feedback-directed search to explore the possible
configuration space for a code snippet, reducing the number of potential
environment configurations that need to be validated. When run on a corpus of
public Python snippets from prior research, V2 identifies 248 instances of
configuration drift.",http://arxiv.org/abs/1909.06251v1
Plasmonic elastic capsules as colorimetric reversible pH-microsensors,2019-09-16T13:57:32Z,"C. A. S. Burel, A. Teolis, A. Alsayed, C. B. Murray, B. Donnio, R. Dreyfus","There is a crucial need for effective and easily dispersible colloidal
microsensors able to detect local pH changes before irreversible damages caused
by demineralization, corrosion, or biofilms occur. One class of such
microsensors is based on molecular dyes encapsulated or dispersed either in
polymer matrices or in liquid systems exhibiting different colors upon pH
variations. They are efficient but often rely on sophisticated and costly
syntheses, and present significant risks of leakage and photobleaching damages,
which is detrimental for mainstream applications. Another approach consists in
exploiting the distance-dependent plasmonic properties of metallic
nanoparticles. Still, assembling nanoparticles into dispersible colloidal
pH-sensitive sensors remains a challenge. Here, we show how to combine
optically active plasmonic gold nanoparticles and pH-responsive thin shells
into ""plasmocapsules"". Upon pH change, plasmocapsules swell or shrink.
Concomitantly, the distance between the gold nanoparticles embedded in the
polymeric matrix varies, resulting in an unambiguous color change. Billions of
micron-size sensors can thus be easily fabricated. They are non-intrusive,
reusable, and sense local pH changes. Each plasmocapsule is an independent
reversible microsensor over a large pH range. Finally, we demonstrate their
potential use for the detection of bacterial growth, thus proving that
plasmocapsules are a new class of sensing materials.",http://arxiv.org/abs/1909.07204v2
"Complex hybridization physics and evidence of structural anomaly to be a
  bulk property in an exotic Fe-based compound, CaFe2As2",2019-09-23T16:37:21Z,"Ram Prakash Pandeya, Arindam Pramanik, Anup Pradhan Sakhya, A. Thamizhavel, Kalobaran Maiti","Surface of quantum materials often exhibits significantly different behavior
than the bulk due to changed topologies and symmetry protections. The
outstanding problem is to find out if the exoticity of a material is linked to
the changed topology at the surface or it is a bulk property. Hard x-ray
photoemission spectroscopy (HAXPES) is a significantly bulk sensitive technique
(escape depth of valence electrons is about 40 \AA\ for 6 keV photon energy)
and the probing depth can be tuned by changing the electron emission angle.
Therefore, HAXPES is often used to reveal the surface-bulk differences in a
material. Here, we show that the delineation of surface-bulk differences in the
valence band spectral functions using this method is highly non-trivial due to
the complexity arising from linear dichroic effect in addition to the change in
surface sensitivity. We show that core level spectra can be used to reveal the
surface-bulk differences in the electronic structure. The Ca 2p spectra exhibit
evidence of significant hybridization with the conduction electrons revealing
their importance in the electronic properties of the system as also found for
the charge reservoir layers in cuprate superconductors. The Fe 2p core level
spectra as a function of bulk sensitivity and temperature reveals an unusual
scenario; while the surface electronic structure corroborates well with the
observed phase transitions of the system, the bulk spectra exhibit signature of
additional structural phases providing a rare evidence of structural anomaly to
be a bulk property.",http://arxiv.org/abs/1909.10463v1
"Fast Feedback Control over Multi-hop Wireless Networks with Mode Changes
  and Stability Guarantees",2019-09-19T19:22:09Z,"Dominik Baumann, Fabian Mager, Romain Jacob, Lothar Thiele, Marco Zimmerling, Sebastian Trimpe","Closing feedback loops fast and over long distances is key to emerging
cyber-physical applications; for example, robot motion control and swarm
coordination require update intervals of tens of milliseconds. Low-power
wireless communication technology is preferred for its low cost, small form
factor, and flexibility, especially if the devices support multi-hop
communication. Thus far, however, feedback control over multi-hop low-power
wireless networks has only been demonstrated for update intervals on the order
of seconds. To fill this gap, this paper presents a wireless embedded system
that supports dynamic mode changes and tames imperfections impairing control
performance (e.g., jitter and message loss), and a control design that exploits
the essential properties of this system to provably guarantee closed-loop
stability for physical processes with linear time-invariant dynamics in the
presence of mode changes. Using experiments on a cyber-physical testbed with 20
wireless devices and multiple cart-pole systems, we are the first to
demonstrate and evaluate feedback control and coordination with mode changes
over multi-hop networks for update intervals of 20 to 50 milliseconds.",http://arxiv.org/abs/1909.10873v1
"Clustering Strategies of Cooperative Adaptive Cruise Control: Impacts on
  Human-driven Vehicles",2019-09-29T05:41:50Z,"Zijia Zhong, Mark Nejad, Earl E. Lee, Joyoung Lee","As a promising application of connected and automated vehicles (CAVs),
Cooperative Adaptive Cruise Control (CACC) is expected to be deployed on the
public road in the near term. Thus far the majority of the CACC studies have
been focusing on the overall network performance with limited insight on the
potential impact of CAVs on human-driven vehicles (HVs). This paper aims to
quantify the influence of CAVs on HVs by studying the high-resolution vehicle
trajectory data that is obtained from microscopic simulation. Two clustering
strategies for CACC are implemented: an ad hoc coordination one and a local
coordination one. Results show that the local coordination outperforms the ad
hoc coordination across all tested market penetration rates (MPRs) in terms of
network throughput and productivity. The greatest performance difference
between the two strategies is observed at 30% and 40% MPR for throughput and
productivity, respectively. However, the distributions of the hard braking
observations (as a potential safety impact) for HVs change significantly under
local coordination strategy. Regardless of the clustering strategy, CAVs
increase the average lane change frequency for HVs. 30% MPR is the break-even
point for local coordination, after which the average lane change frequency
decreases from the peak 5.42 to 5.38. Such inverse relationship to MPR is not
found in the ah hoc case and the average lane change frequency reaches the
highest 5.48 at 40% MPR.",http://arxiv.org/abs/1909.13204v1
"Bayesian Longitudinal Causal Inference in the Analysis of the Public
  Health Impact of Pollutant Emissions",2019-01-03T20:26:36Z,"Chanmin Kim, Corwin M Zigler, Michael J Daniels, Christine Choirat, Jason A Roy","Pollutant emissions from coal-burning power plants have been deemed to
adversely impact ambient air quality and public health conditions. Despite the
noticeable reduction in emissions and the improvement of air quality since the
Clean Air Act (CAA) became the law, the public-health benefits from changes in
emissions have not been widely evaluated yet. In terms of the chain of
accountability (HEI Accountability Working Group, 2003), the link between
pollutant emissions from the power plants (SO2) and public health conditions
(respiratory diseases) accounting for changes in ambient air quality (PM2.5) is
unknown. We provide the first assessment of the longitudinal effect of specific
pollutant emission (SO2) on public health outcomes that is mediated through
changes in the ambient air quality. It is of particular interest to examine the
extent to which the effect that is mediated through changes in local ambient
air quality differs from year to year. In this paper, we propose a Bayesian
approach to estimate novel causal estimands: time-varying mediation effects in
the presence of mediators and responses measured every year. We replace the
commonly invoked sequential ignorability assumption with a new set of
assumptions which are sufficient to identify the distributions of the natural
indirect and direct effects in this setting.",http://arxiv.org/abs/1901.00908v1
"Evaluation of central corneal thickness in keratoconus and normal
  corneas during air puff indentation",2019-01-07T12:32:13Z,"Dan Lin, Lei Tian, Chenglang Yuan, Wenxiu Shi, Like Wang, Yongjin Zhou","Purpose: This study aimed to investigate the actual changes of central
corneal thickness (CCT) in keratoconus and normal corneas during air puff
indentation, by using corneal visualization Scheimpflug technology (Corvis ST).
Methods: A total of 32 keratoconic eyes and 46 normal eyes were included in
this study. Three parameters of CCTinitial, CCTfinal and CCTpeak were selected
to represent the CCT at initial time, final time and highest corneal concavity,
respectively, during air puff indentation. Wilcoxon signed rank test (paired
sample test) was used to assess the differences between these 3 parameters in
both keratoconus and normal groups. Univariate linear regression analysis was
performed to determine the effect of CCTinitial on CCTpeak and CCTfinal, as
well as the impact of air puff force on CCT in each group. Receiver operating
characteristic (ROC) curves were constructed to evaluate the discriminative
ability of the 3 parameters. Results: The results demonstrated that CCTpeak and
CCTfinal were significantly decreased (p<0.01) compared to CCTinitial in both
keratoconus and normal groups. Regression analysis indicated a significant
positive correlation between CCTpeak and CCTinitial in normal cornea group
(R2=0.337, p<0.01), but not in keratoconus group (R2=0.029, p=0.187). Likewise,
regression models of air puff force and CCT revealed the different patterns of
CCT changes between keratoconus and normal cornea groups. Furthermore, ROC
curves showed that CCTpeak exhibited the greatest AUC (area under ROC curve) of
0.940, with accuracy, sensitivity and specificity of 94.9%, 87.5% and 100%,
respectively. Conclusions: CCT may change during air puff indentation, and is
significantly different between keratoconus and normal cornea groups. The
changing pattern is useful for the diagnosis of keratoconus, and lays the
foundation for corneal biomechanics.",http://arxiv.org/abs/1901.01772v1
Face changing companion of the redback millisecond pulsar PSR J1048+2339,2019-01-07T17:59:20Z,"Yee Xuan Yap, K. L. Li, A. K. H. Kong, J. Takata, J. Lee, C. Y. Hui","We present optical observations of the redback millisecond pulsar PSR
J1048+2339, which is a 4.66 ms radio pulsar in a compact binary with an orbital
period of six hours. We obtained high-quality light curves of PSR J1048+2339
with the Lulin 1 m Telescope. The system shows two distinct six-hour orbital
modulations, in which an ellipsoidal modulation changes into a sinusoidal-like
profile in less than 14 days. In addition to the change, the brightness of the
companion increased by one magnitude, suggesting that the latter type of
modulation is caused by the pulsar wind heating of the companion and that the
heating became dominant in the system. While the changes are not unexpected,
such a timescale is the shortest among similar systems. We performed modeling
analysis to extract the properties of the system. We obtained a derived pulsar
mass of 2.1 M$_{\odot }$ and a companion star mass of 0.4 M$_{\odot }$ for the
system. The irradiation power increased by a factor of 6 during which the
pulsar wind heating dominates. We also report on the two archival Chandra X-ray
observations and discuss several possibilities that might cause the varying
heating on the companion.",http://arxiv.org/abs/1901.01948v1
"Merging cold front and AGN feedback in the peculiar galaxy cluster Abell
  2626",2019-01-11T11:09:17Z,"Sonali K. Kadam, Satish S. Sonkamble, Pramod K. Pawar, Madhav K. Patil","This paper presents the analysis of a combined 134 ks {\it Chandra} data of a
peculiar galaxy cluster Abell 2626. This study confirms the earlier detection
of the east cavity at $\sim$13 kpc and reports detection of a new cavity at
$\sim$39 kpc on the west of the X-ray peak. The average mechanical power
injected by the AGN outburst ${\rm P_{cav} \sim 6.6 \times 10^{44}\, erg\,
s^{-1}}$ is $\sim$29 times more than required to compensate the cooling
luminosity ${\rm L_{cool} = 2.30 \pm 0.02 \times 10^{43} {\rm~erg\ s}^{-1}}$.
The edges in the SB on the west and south-west at $\sim$36 kpc and 33 kpc,
respectively, have the gas compressions of 1.57$\pm$0.08 and 2.06$\pm$0.44 and
are spatially associated with the arcs in the temperature and metallicity maps
due to the merging cold fronts. The systematic study of the nuclear sources
exhibited dramatic changes over the span of ten years. The NE source that
emitted mostly in the soft band in the past disappeared in the recent
observations. Instead, an excess emission was seen at $2.2""$ on its west and
required an unrealistic line of sight velocity of $\sim$ $675\times{}c$ if is
due to its movement. The count rate analysis and spectral analysis exhibited a
change in the state of the SW source from a soft state to the hard due to the
change in the mass accretion rate. No such spectral change was noticed for the
NE source.",http://arxiv.org/abs/1901.03550v1
Parameter Estimation in Abruptly Changing Dynamic Environments,2019-01-15T06:44:44Z,"Hugo Lewi Hammer, Anis Yazidi","Many real-life dynamical systems change abruptly followed by almost
stationary periods. In this paper, we consider streams of data with such abrupt
behavior and investigate the problem of tracking their statistical properties
in an online manner.
  We devise a tracking procedure where an estimator that is suitable for a
stationary environment is combined together with an event detection method such
that the estimator rapidly can jump to a more suitable value if an event is
detected. Combining an estimation procedure with detection procedure is
commonly known idea in the literature. However, our contribution lies in
building the detection procedure based on the difference between the stationary
estimator and a Stochastic Learning Weak Estimator (SLWE). The SLWE estimator
is known to be the state-of-the art approach to tracking properties of
non-stationary environments and thus should be a better choice to detect
changes in abruptly changing environments than the far more common sliding
window based approaches. To the best of our knowledge, the event detection
procedure suggested by Ross et al. (2012) is the only procedure in the
literature taking advantage of the powerful tracking properties of the SLWE
estimator. The procedure in Ross et al. is however quite complex and not well
founded theoretically compared to the procedures in this paper. In this paper,
we focus on estimation procedure for the binomial and multinomial
distributions, but our approach can be easily generalized to cover other
distributions as well.
  Extensive simulation results based on both synthetic and real-life data
related to news classification demonstrate that our estimation procedure is
easy to tune and performs well.",http://arxiv.org/abs/1901.04678v1
"Investigation of the time evolution of entanglement and trace distance
  in an atom-cavity system described with random walk and non-random walk
  states",2019-01-15T17:49:42Z,"M. Mohammadi, S. Jami","An atom-cavity system consists of an atom or group of atoms inside a cavity.
When an atom in cavity is stimulated by a laser pump, it is affected by the
atom-field interaction shows the quasi-random walk behavior. This can change
the entanglement and trace distance of system. In this work, the change
entanglement and trace distance of system in two different cases namely the
random walk and non-random walk is considered. The descriptive system is a
two-level atom in the electrodynamics cavity based on the Jaynes-Cummings
model, which is stimulated by two longitudinal and transverse laser pumps. The
results show that the consideration of the random walk case for the atom
changes in the amount of entanglement can be seen as the phenomenon of sudden
death and birth of entanglement. It results in its rate of changes to be
increased. In contrast to the non-random walk case, this rate is increased and
decreased more quickly compared to the random walk case. The maximum amount of
entanglement in each case is the same, but the minimum in random walk case is
less than that of non-random walk case.",http://arxiv.org/abs/1901.04952v1
Blazar jet evolution revealed by multi-epoch broadband radio polarimetry,2019-01-23T19:00:01Z,"C. S. Anderson, S. P. O'Sullivan, G. H. Heald, T. Hodgson, A. Pasetto, B. M. Gaensler","We investigate the previously proposed possibility that multi-epoch broadband
polarimetry could act as a complement or limited proxy for VLBI observations of
blazars, in that the number of polarised emission components in the jet, and
some of their properties and those of the foreground environment, might be
inferred from the object's time-varying 1D Faraday depth spectrum (FDS) alone.
We report on a pilot-scale experiment designed to establish the basic
plausibility and utility of this idea. We analyse temporal changes in the
complex polarisation spectra of nine spatially unresolved (at arcsecond scales)
blazars in two epochs separated by $\sim$5 years, using data taken with the
Australia Telescope Compact Array. The data allow for precise modelling, and we
demonstrate that all objects in our sample show changes in their polarisation
spectrum that cannot be accounted for by uncertainties in calibration or
observational effects. By associating polarised emission components across
epochs, we infer changes in their number, intrinsic fractional polarisation,
intrinsic polarisation angle, rotation measure, and depolarisation
characteristics. We attribute these changes to evolution in the structure of
the blazar jets, most likely located at distances of up to tens of parsecs from
the central active galactic nuclei. Our results suggest that continued work in
this area is warranted; in particular, it will be important to determine the
frequency ranges and temporal cadence most useful for scientifically exploiting
the effects.",http://arxiv.org/abs/1901.08066v1
Critical speeding up as an early warning signal of regime switching,2019-01-23T19:07:58Z,"Mathew Titus, Zach Gelbaum, James Watson","The use of critical slowing down as an early warning indicator for regime
switching in observations from stochastic environments and noisy dynamical
models has been widely studied and implemented in recent years. Some systems,
however, have been shown to avoid critical slowing down prior to a transition
between equilibria, e.g. (Ditlevsen and Johnsen, 2010). Possible explanations
include non-smooth potential driving the dynamic (Hastings and Wysham, 2010) or
large perturbations driving the system out of the initial basin of attraction.
In this paper we discuss a phenomenon analogous to critical slowing down, where
a slow parameter change leads to a high likelihood of a regime shift and
creates signature warning signs in the statistics of the process's sample
paths. In short, if a basin of attraction is compressed under a parameter
change then the potential well steepens, leading to a drop in the time series'
variance and autocorrelation; precisely the opposite warning signs exhibited by
critical slowing down. This effect, which we call `critical speeding up,' is
demonstrated using a simple ecological model exhibiting an Allee effect. The
fact that both dropping and rising variance / autocorrelation can indicate
imminent state change should underline the need for reliable modeling of any
empirical system where one desires to forecast regime change.",http://arxiv.org/abs/1901.08084v1
"The effects of imitation dynamics on vaccination behaviours in
  SIR-network model",2019-05-01T06:00:16Z,"Sheryl L. Chang, Mahendra Piraveenan, Mikhail Prokopenko","We present a series of SIR-network models, extended with a game-theoretic
treatment of imitation dynamics which result from regular population mobility
across residential and work areas and the ensuing interactions. Each considered
SIR-network model captures a class of vaccination behaviours influenced by
epidemic characteristics, interaction topology, and imitation dynamics. Our
focus is the eventual vaccination coverage, produced under voluntary
vaccination schemes, in response to these varying factors. Using the next
generation matrix method, we analytically derive and compare expressions for
the basic reproduction number $R_0$ for the proposed SIR-network models.
Furthermore, we simulate the epidemic dynamics over time for the considered
models, and show that if individuals are sufficiently responsive towards the
changes in the disease prevalence, then the more expansive travelling patterns
encourage convergence to the endemic, mixed equilibria. On the contrary, if
individuals are insensitive to changes in the disease prevalence, we find that
they tend to remain unvaccinated in all the studied models. Our results concur
with earlier studies in showing that residents from highly connected
residential areas are more likely to get vaccinated. We also show that the
existence of the individuals committed to receiving vaccination reduces $R_0$
and delays the disease prevalence, and thus is essential to containing
epidemics.",http://arxiv.org/abs/1905.00734v3
"Erratum to ""On the Non-vanishing of the Central Value of the
  Rankin-Selberg L-functions""",2019-05-07T15:42:01Z,"David Ginzburg, Dihua Jiang, Baiying Liu, Stephen Rallis",We complete the proof of Proposition 5.3 of [GJR04].,http://arxiv.org/abs/1905.02644v2
"Probing charge carrier movement in organic semiconductor thin films via
  nanowire conductance spectroscopy",2019-05-17T05:05:14Z,"M. V. Klymenko, J. A. Vaitkus, J. H. Cole","Understanding the movement of charge within organic semiconducting films is
crucial for applications in photo-voltaics and flexible electronics. We study
the sensitivity of the electrical conductance of a silicon nanowire to changes
of charge states within an organic semiconductor physisorbed on the surface of
the nanowire. Elastic scattering caused by motion of charge carriers near the
nanowire modifies the mean-free path for backscattering of electrons
propagating within it, which we have mathematically expressed in terms of the
causal Green's functions. The scattering potential has been computed using a
combination of the polarizable continuum model and density functional theory
with the range-separated exchange-correlation functional for organic molecules
and the semi-empirical tight-binding model for silicon. As an example, the
sensitivity to charge state changes in tetracene is computed as a function of
operating temperature and geometrical parameters of a nanowire. For a single
molecule, ultra-thin silicon nanowires with characteristic sizes of the
cross-section below 2 nm produce a detectable conductance change at room
temperature. For larger nanowires the sensitivity is reduced, however the
conductance change grows with the number of charged molecules: with sub-4 nm
nanowires being sensitive enough to detect several tens of charge carriers. We
propose using noise spectroscopy to access the temporal evolution of the charge
states. Information regarding the spatial distribution of charge carries in
organic thin films can be obtained using a grid of nanowire resistors and
electric impedance tomography.",http://arxiv.org/abs/1905.07115v1
"Remarks on intersection numbers and integrable hierarchies. I.
  Quasi-triviality",2019-05-20T13:39:17Z,"Boris Dubrovin, Di Yang","Explicit expression for quasi-triviality of scalar non-linear PDE is under
consideration.",http://arxiv.org/abs/1905.08106v2
"Inference for Change Points in High Dimensional Data via
  Self-Normalization",2019-05-21T05:30:11Z,"Runmin Wang, Changbo Zhu, Stanislav Volgushev, Xiaofeng Shao","This article considers change point testing and estimation for a sequence of
high-dimensional data. In the case of testing for a mean shift for
high-dimensional independent data, we propose a new test which is based on
$U$-statistic in Chen and Qin (2010) and utilizes the self-normalization
principle [Shao (2010), Shao and Zhang (2010)]. Our test targets dense
alternatives in the high-dimensional setting and involves no tuning parameters.
To extend to change point testing for high-dimensional time series, we
introduce a trimming parameter and formulate a self-normalized test statistic
with trimming to accommodate the weak temporal dependence. On the theory front,
we derive the limiting distributions of self-normalized test statistics under
both the null and alternatives for both independent and dependent
high-dimensional data. At the core of our asymptotic theory, we obtain weak
convergence of a sequential U-statistic based process for high-dimensional
independent data, and weak convergence of sequential trimmed U-statistic based
processes for high-dimensional linear processes, both of which are of
independent interests. Additionally, we illustrate how our tests can be used in
combination with wild binary segmentation to estimate the number and location
of multiple change points. Numerical simulations demonstrate the
competitiveness of our proposed testing and estimation procedures in comparison
with several existing methods in the literature.",http://arxiv.org/abs/1905.08446v2
Switching 2D Magnetic States via Pressure Tuning of Layer Stacking,2019-05-26T19:14:50Z,"Tiancheng Song, Zaiyao Fei, Matthew Yankowitz, Zhong Lin, Qianni Jiang, Kyle Hwangbo, Qi Zhang, Bosong Sun, Takashi Taniguchi, Kenji Watanabe, Michael A. McGuire, David Graf, Ting Cao, Jiun-Haw Chu, David H. Cobden, Cory R. Dean, Di Xiao, Xiaodong Xu","The physical properties of two-dimensional van der Waals (2D vdW) crystals
depend sensitively on the interlayer coupling, which is intimately connected to
the stacking arrangement and the interlayer spacing. For example, simply
changing the twist angle between graphene layers can induce a variety of
correlated electronic phases, which can be controlled further in a continuous
manner by applying hydrostatic pressure to decrease the interlayer spacing. In
the recently discovered 2D magnets, theory suggests that the interlayer
exchange coupling strongly depends on layer separation, while the stacking
arrangement can even change the sign of the magnetic exchange, thus drastically
modifying the ground state. Here, we demonstrate pressure tuning of magnetic
order in the 2D magnet CrI3. We probe the magnetic states using tunneling and
scanning magnetic circular dichroism microscopy measurements. We find that the
interlayer magnetic coupling can be more than doubled by hydrostatic pressure.
In bilayer CrI3, pressure induces a transition from layered antiferromagnetic
to ferromagnetic phases. In trilayer CrI3, pressure can create coexisting
domains of three phases, one ferromagnetic and two distinct antiferromagnetic.
The observed changes in magnetic order can be explained by changes in the
stacking arrangement. Such coupling between stacking order and magnetism
provides ample opportunities for designer magnetic phases and functionalities.",http://arxiv.org/abs/1905.10860v1
Power laws in code repositories: A skeptical approach,2019-05-27T08:48:42Z,"Bartolomé Ortiz, J. J. Merelo-Guervós","Software development as done using modern methodologies and source control
management systems, has been often established as an example of
self-organization, with code growing and evolving organically, through
activities that do not stem from entralized power, leader or directives. The
main challenge in proving these claims is that self organization cannot be
detected through direct observation, but through measurements on the system,
looking for hints such as the existence of power laws over some features, such
as the size of changes over time. The problem we intend to tackle in this paper
is to establish a methodology for checking, for a chosen set of repositories we
had already measured in the past, if the claims about power laws actually hold
from a precise mathematical point of view, since, although shown as pervasive
in the software engineering literature (and others), power laws are more
elusive than they might seem at first sight. For that reason, in this paper we
present a statistically accurate set of tests that will help us decide, from
the way repositories are changing, if they are really distributed by a power
law, which could indicate us the existence of a state reached via
self-organization, or actually, how accurately a power law fits the observed
distribution of the size of changes of commits in git repositories of 16 open
source repositories. We revisit one of the most representative papers of these
observations to reevaluate its results and compare them with the current status
of the repositories analyzed in it, trying to elucidate if there has been any
change in the possible presence, or not, of a power law.",http://arxiv.org/abs/1905.11044v1
Cerberus: A Multi-headed Derenderer,2019-05-28T17:00:03Z,"Boyang Deng, Simon Kornblith, Geoffrey Hinton","To generalize to novel visual scenes with new viewpoints and new object
poses, a visual system needs representations of the shapes of the parts of an
object that are invariant to changes in viewpoint or pose. 3D graphics
representations disentangle visual factors such as viewpoints and lighting from
object structure in a natural way. It is possible to learn to invert the
process that converts 3D graphics representations into 2D images, provided the
3D graphics representations are available as labels. When only the unlabeled
images are available, however, learning to derender is much harder. We consider
a simple model which is just a set of free floating parts. Each part has its
own relation to the camera and its own triangular mesh which can be deformed to
model the shape of the part. At test time, a neural network looks at a single
image and extracts the shapes of the parts and their relations to the camera.
Each part can be viewed as one head of a multi-headed derenderer. During
training, the extracted parts are used as input to a differentiable 3D renderer
and the reconstruction error is backpropagated to train the neural net. We make
the learning task easier by encouraging the deformations of the part meshes to
be invariant to changes in viewpoint and invariant to the changes in the
relative positions of the parts that occur when the pose of an articulated body
changes. Cerberus, our multi-headed derenderer, outperforms previous methods
for extracting 3D parts from single images without part annotations, and it
does quite well at extracting natural parts of human figures.",http://arxiv.org/abs/1905.11940v1
Finsler metrics on surfaces admitting three projective vector fields,2019-08-07T16:07:29Z,Julius Lang,"We show that in dimension 2 every Finsler metric with at least 3-dimensional
Lie algebra of projective vector fields is locally projectively equivalent to a
Randers metric. We give a short list of such Finsler metrics which is complete
up to coordinate change and projective equivalence.",http://arxiv.org/abs/1908.02696v1
"MoS$_{2}$ pixel arrays for real-time photoluminescence imaging of redox
  molecules",2019-08-09T14:15:24Z,"M. F. Reynolds, M. H. D. Guimaraes, H. Gao, K. Kang, A. J. Cortese, D. C. Ralph, J. Park, P. L. McEuen","Measuring the behavior of redox-active molecules in space and time is crucial
for better understanding of chemical and biological systems and for the
development of new technologies. Optical schemes are non-invasive, scalable and
can be applied to many different systems, but usually have a slow response
compared to electrical detection methods. Furthermore, many fluorescent
molecules for redox detection degrade in brightness over long exposure times.
Here we show that the photoluminescence of pixel arrays of an atomically thin
two-dimensional (2D) material, a monolayer of MoS$_{2}$, can image spatial and
temporal changes in redox molecule concentration in real time. Because of the
strong dependence of MoS$_{2}$ photoluminescence on doping and sensitivity to
surface changes characteristic of 2D materials, changes in the local chemical
potential significantly modulate the photoluminescence of MoS$_{2}$, with a
sensitivity of 0.9 mV/$\sqrt{Hz}$ on a 5 $\mu$m by 5 $\mu$m pixel,
corresponding to better than parts-per-hundred changes in redox molecule
concentration down to nanomolar concentrations at 100 ms frame rates. The
real-time imaging of electrochemical potentials with a fast response time
provides a new strategy for visualizing chemical reactions and biomolecules
with a 2D material screen.",http://arxiv.org/abs/1908.03471v1
"Spiking Neural Networks and Online Learning: An Overview and
  Perspectives",2019-07-23T09:18:28Z,"Jesus L. Lobo, Javier Del Ser, Albert Bifet, Nikola Kasabov","Applications that generate huge amounts of data in the form of fast streams
are becoming increasingly prevalent, being therefore necessary to learn in an
online manner. These conditions usually impose memory and processing time
restrictions, and they often turn into evolving environments where a change may
affect the input data distribution. Such a change causes that predictive models
trained over these stream data become obsolete and do not adapt suitably to new
distributions. Specially in these non-stationary scenarios, there is a pressing
need for new algorithms that adapt to these changes as fast as possible, while
maintaining good performance scores. Unfortunately, most off-the-shelf
classification models need to be retrained if they are used in changing
environments, and fail to scale properly. Spiking Neural Networks have revealed
themselves as one of the most successful approaches to model the behavior and
learning potential of the brain, and exploit them to undertake practical online
learning tasks. Besides, some specific flavors of Spiking Neural Networks can
overcome the necessity of retraining after a drift occurs. This work intends to
merge both fields by serving as a comprehensive overview, motivating further
developments that embrace Spiking Neural Networks for online learning
scenarios, and being a friendly entry point for non-experts.",http://arxiv.org/abs/1908.08019v1
"Ice-rule made manifold: phase transitions, topological defects and
  manifold restoration in two-dimensional artificial spin systems",2019-08-23T17:03:05Z,"Gavin M. Macauley, Gary W. Paterson, Yue Li, Rair Macêdo, Stephen McVitie, Robert L. Stamps","Artificial spin ices are arrays of correlated nano-scale magnetic islands
that prove an excellent playground in which to study the role of topology in
critical phenomena. Here, we investigate a continuum of spin ice geometries,
parameterised by rotation of the islands. In doing so, we morph from the
classic square ice to the recently studied pinwheel geometry, with the rotation
angle acting as a proxy for controlling inter-island interactions. We
experimentally observe a change in ground state magnetic order from
antiferromagnetic to ferromagnetic across this class of geometries using
Lorentz transmission electron microscopy on thermally annealed cobalt arrays.
The change in ordering leads to an apparent change in the nature of the defects
supported: from one-dimensional strings in the antiferromagnetic phase to
two-dimensional vortex-like structures in the ferromagnetic one, consistent
with the scaling predicted by the Kibble-Zurek mechanism. Our results show how
magnetic order in artificial spin ices can be tuned by changes in geometry so
that a truly frustrated ice-rule phase is possible in two-dimensional systems.
Furthermore, we demonstrate this system as a testbed to investigate
out-of-equilibrium dynamics across phases.",http://arxiv.org/abs/1908.08903v1
"Explainable Video Action Reasoning via Prior Knowledge and State
  Transitions",2019-08-28T13:04:28Z,"Tao Zhuo, Zhiyong Cheng, Peng Zhang, Yongkang Wong, Mohan Kankanhalli","Human action analysis and understanding in videos is an important and
challenging task. Although substantial progress has been made in past years,
the explainability of existing methods is still limited. In this work, we
propose a novel action reasoning framework that uses prior knowledge to explain
semantic-level observations of video state changes. Our method takes advantage
of both classical reasoning and modern deep learning approaches. Specifically,
prior knowledge is defined as the information of a target video domain,
including a set of objects, attributes and relationships in the target video
domain, as well as relevant actions defined by the temporal attribute and
relationship changes (i.e. state transitions). Given a video sequence, we first
generate a scene graph on each frame to represent concerned objects, attributes
and relationships. Then those scene graphs are linked by tracking objects
across frames to form a spatio-temporal graph (also called video graph), which
represents semantic-level video states. Finally, by sequentially examining each
state transition in the video graph, our method can detect and explain how
those actions are executed with prior knowledge, just like the logical manner
of thinking by humans. Compared to previous works, the action reasoning results
of our method can be explained by both logical rules and semantic-level
observations of video content changes. Besides, the proposed method can be used
to detect multiple concurrent actions with detailed information, such as who
(particular objects), when (time), where (object locations) and how (what kind
of changes). Experiments on a re-annotated dataset CAD-120 show the
effectiveness of our method.",http://arxiv.org/abs/1908.10700v1
"ActivFORMS: A Formally-Founded Model-Based Approach to Engineer
  Self-Adaptive Systems",2019-08-29T12:33:50Z,"Danny Weyns, M. Usman Iftikhar","Self-adaptation equips a computing system with a feedback loop that enables
it dealing with change caused by uncertainties during operation, such as
changing availability of resources and fluctuating workloads. To ensure that
the system complies with the adaptation goals, recent research suggests the use
of formal techniques at runtime. Yet, existing approaches have three
limitations that affect their practical applicability: (i) they ignore
correctness of the behavior of the feedback loop, (ii) they rely on exhaustive
verification at runtime to select adaptation options to realize the adaptation
goals, which is time and resource demanding, and (iii) they provide limited or
no support for changing adaptation goals at runtime. To tackle these
shortcomings, we present ActivFORMS (Active FORmal Models for Self-adaptation).
ActivFORMS contributes an end-to-end approach for engineering self-adaptive
systems, spanning four main stages of the life cycle of a feedback loop:
design, deployment, runtime adaptation, and evolution. We also present
ActivFORMS-ta, a tool-supported instance of ActivFORMS that leverages timed
automata models and statistical model checking at runtime. We validate the
research results using an IoT application for building security monitoring that
is deployed in Leuven. The experimental results demonstrate that ActivFORMS
supports correctness of the behavior of the feedback loop, achieves the
adaptation goals in an efficient way, and supports changing adaptation goals at
runtime.",http://arxiv.org/abs/1908.11179v3
"On non-commutative formal deformations of coherent sheaves on an
  algebraic variety",2019-08-29T23:50:35Z,Yujiro Kawamata,"We review the theory of non-commutative deformations of sheaves and describe
a versal deformation by using an A-infinity algebra and the change of
differentials of an injective resolution. We give some explicit non-trivial
examples.",http://arxiv.org/abs/1908.11483v2
"Tissue evolution: Mechanical interplay of adhesion, pressure, and
  heterogeneity",2019-10-08T08:03:03Z,"Tobias Büscher, Nirmalendu Ganai, Gerhard Gompper, Jens Elgeti","The evolution of various competing cell types in tissues, and the resulting
persistent tissue population, is studied numerically and analytically in a
particle-based model of active tissues. Mutations change the properties of
cells in various ways, including their mechanical properties. Each mutation
results in an advantage or disadvantage to grow in the competition between
different cell types. While changes in signaling processes and biochemistry
play an important role, we focus on changes in the mechanical properties by
studying the result of variation of growth force and adhesive
cross-interactions between cell types. For independent mutations of growth
force and adhesion strength, the tissue evolves towards cell types with high
growth force and low internal adhesion strength, as both increase the
homeostatic pressure. Motivated by biological evidence, we postulate a coupling
between both parameters, such that an increased growth force comes at the cost
of a higher internal adhesion strength or vice versa. This tradeoff controls
the evolution of the tissue, ranging from unidirectional evolution to very
heterogeneous and dynamic populations. The special case of two competing cell
types reveals three distinct parameter regimes: Two in which one cell type
outcompetes the other, and one in which both cell types coexist in a highly
mixed state. Interestingly, a single mutated cell alone suffices to reach the
mixed state, while a finite mutation rate affects the results only weakly.
Finally, the coupling between changes in growth force and adhesion strength
reveals a mechanical explanation for the evolution towards intra-tumor
heterogeneity, in which multiple species coexist even under a constant
evolutianary pressure.",http://arxiv.org/abs/1910.03263v1
Dynamic Brain Functional Networks Guided By Anatomical Knowledge,2019-10-07T21:48:27Z,"Suprateek Kundu, Jin Ming, Jennifer Stevens","Recently, the potential of dynamic brain networks as a neuroimaging
biomarkers for mental illnesses is being increasingly recognized. However,
there are several unmet challenges in developing such biomarkers, including the
need for methods to model rapidly changing network states. In one of the first
such efforts, we develop a novel approach for computing dynamic brain
functional connectivity (FC), that is guided by brain structural connectivity
(SC) computed from diffusion tensor imaging (DTI) data. The proposed approach
involving dynamic Gaussian graphical models decomposes the time course into
non-overlapping state phases determined by change points, each having a
distinct network. We develop an optimization algorithm to implement the method
such that the estimation of both the change points and the state-phase specific
networks are fully data driven and unsupervised, and guided by SC information.
The approach is scalable to large dimensions and extensive simulations
illustrate its clear advantages over existing methods in terms of network
estimation accuracy and detecting dynamic network changes. An application of
the method to a posttraumatic stress disorder (PTSD) study reveals important
dynamic resting state connections in regions of the brain previously implicated
in PTSD. We also illustrate that the dynamic networks computed under the
proposed method are able to better predict psychological resilience among
trauma exposed individuals compared to existing dynamic and stationary
connectivity approaches, which highlights its potential as a neuroimaging
biomarker.",http://arxiv.org/abs/1910.03577v1
"Autonomous Driving using Safe Reinforcement Learning by Incorporating a
  Regret-based Human Lane-Changing Decision Model",2019-10-10T18:33:42Z,"Dong Chen, Longsheng Jiang, Yue Wang, Zhaojian Li","It is expected that many human drivers will still prefer to drive themselves
even if the self-driving technologies are ready. Therefore, human-driven
vehicles and autonomous vehicles (AVs) will coexist in a mixed traffic for a
long time. To enable AVs to safely and efficiently maneuver in this mixed
traffic, it is critical that the AVs can understand how humans cope with risks
and make driving-related decisions. On the other hand, the driving environment
is highly dynamic and ever-changing, and it is thus difficult to enumerate all
the scenarios and hard-code the controllers. To face up these challenges, in
this work, we incorporate a human decision-making model in reinforcement
learning to control AVs for safe and efficient operations. Specifically, we
adapt regret theory to describe a human driver's lane-changing behavior, and
fit the personalized models to individual drivers for predicting their
lane-changing decisions. The predicted decisions are incorporated in the safety
constraints for reinforcement learning in training and in implementation. We
then use an extended version of double deep Q-network (DDQN) to train our AV
controller within the safety set. By doing so, the amount of collisions in
training is reduced to zero, while the training accuracy is not impinged.",http://arxiv.org/abs/1910.04803v1
Smoothly bounded domains covering compact manifolds,2019-10-11T16:29:01Z,Andrew Zimmer,"We show that if a bounded domain in complex Euclidean space with
$\mathcal{C}^{1,1}$ boundary covers a compact manifold, then the domain is
biholomorphic to the unit ball.",http://arxiv.org/abs/1910.05288v2
A Simple Proof of Voisin's Theorem for Canonical Curves of Even Genus,2019-10-14T15:17:51Z,Michael Kemeny,"We give a simple proof of Voisin's Theorem for general canonical curves of
even genus. This completely determines the terms of the minimal free resolution
of the coordinate ring of such curves.",http://arxiv.org/abs/1910.06200v2
"Hidden Unit Specialization in Layered Neural Networks: ReLU vs.
  Sigmoidal Activation",2019-10-16T17:06:00Z,"Elisa Oostwal, Michiel Straat, Michael Biehl","We study layered neural networks of rectified linear units (ReLU) in a
modelling framework for stochastic training processes. The comparison with
sigmoidal activation functions is in the center of interest. We compute typical
learning curves for shallow networks with K hidden units in matching student
teacher scenarios. The systems exhibit sudden changes of the generalization
performance via the process of hidden unit specialization at critical sizes of
the training set. Surprisingly, our results show that the training behavior of
ReLU networks is qualitatively different from that of networks with sigmoidal
activations. In networks with K >= 3 sigmoidal hidden units, the transition is
discontinuous: Specialized network configurations co-exist and compete with
states of poor performance even for very large training sets. On the contrary,
the use of ReLU activations results in continuous transitions for all K: For
large enough training sets, two competing, differently specialized states
display similar generalization abilities, which coincide exactly for large
networks in the limit K to infinity.",http://arxiv.org/abs/1910.07476v2
"Worst-Case Polylog Incremental SPQR-trees: Embeddings, Planarity, and
  Triconnectivity",2019-10-20T16:00:27Z,"Jacob Holm, Eva Rotenberg","We show that every labelled planar graph $G$ can be assigned a canonical
embedding $\phi(G)$, such that for any planar $G'$ that differs from $G$ by the
insertion or deletion of one edge, the number of local changes to the
combinatorial embedding needed to get from $\phi(G)$ to $\phi(G')$ is $O(\log
n)$.
  In contrast, there exist embedded graphs where $\Omega(n)$ changes are
necessary to accommodate one inserted edge. We provide a matching lower bound
of $\Omega(\log n)$ local changes, and although our upper bound is worst-case,
our lower bound hold in the amortized case as well.
  Our proof is based on BC trees and SPQR trees, and we develop
\emph{pre-split} variants of these for general graphs, based on a novel biased
heavy-path decomposition, where the structural changes corresponding to edge
insertions and deletions in the underlying graph consist of at most $O(\log n)$
basic operations of a particularly simple form.
  As a secondary result, we show how to maintain the pre-split trees under edge
insertions in the underlying graph deterministically in worst case $O(\log^3
n)$ time. Using this, we obtain deterministic data structures for incremental
planarity testing, incremental planar embedding, and incremental
triconnectivity, that each have worst case $O(\log^3 n)$ update and query time,
answering an open question by La Poutr\'e and Westbrook from 1998.",http://arxiv.org/abs/1910.09005v1
Tight finite-key security for twin-field quantum key distribution,2019-10-24T20:11:01Z,"Guillermo Currás-Lorenzo, Alvaro Navarrete, Koji Azuma, Go Kato, Marcos Curty, Mohsen Razavi","Quantum key distribution (QKD) offers a reliable solution to communication
problems that require long-term data security. For its widespread use, however,
the rate and reach of QKD systems must be improved. Twin-field (TF) QKD is a
step forward toward this direction, with early demonstrations suggesting it can
beat the current rate-versus-distance records. A recently introduced variant of
TF-QKD is particularly suited for experimental implementation, and has been
shown to offer a higher key rate than other variants in the asymptotic regime
where users exchange an infinite number of signals. Here, we extend the
security of this protocol to the finite-key regime, showing that it can
overcome the fundamental bounds on point-to-point QKD with around $10^{10}$
transmitted signals. Within distance regimes of interest, our analysis offers
higher key rates than those of alternative variants. Moreover, some of the
techniques we develop are applicable to the finite-key analysis of other QKD
protocols.",http://arxiv.org/abs/1910.11407v4
Construction of the Supersymmetric Path Integral: A Survey,2019-10-29T00:41:16Z,Matthias Ludewig,"This is a survey based on joint work with Florian Hanisch and Batu G\""uneysu
reporting on a rigorous construction of the supersymmetric path integral
associated to compact spin manifolds.",http://arxiv.org/abs/1910.13019v2
User Review-Based Change File Localization for Mobile Applications,2019-03-03T12:45:46Z,"Yu Zhou, Yanqi Su, Taolue Chen, Zhiqiu Huang, Harald Gall, Sebastiano Panichella","In the current mobile app development, novel and emerging DevOps practices
(e.g., Continuous Delivery, Integration, and user feedback analysis) and tools
are becoming more widespread. For instance, the integration of user feedback
(provided in the form of user reviews) in the software release cycle represents
a valuable asset for the maintenance and evolution of mobile apps. To fully
make use of these assets, it is highly desirable for developers to establish
semantic links between the user reviews and the software artefacts to be
changed (e.g., source code and documentation), and thus to localize the
potential files to change for addressing the user feedback. In this paper, we
propose RISING (Review Integration via claSsification, clusterIng, and
linkiNG), an automated approach to support the continuous integration of user
feedback via classification, clustering, and linking of user reviews. RISING
leverages domain-specific constraint information and semi-supervised learning
to group user reviews into multiple fine-grained clusters concerning similar
users' requests. Then, by combining the textual information from both commit
messages and source code, it automatically localizes potential change files to
accommodate the users' requests. Our empirical studies demonstrate that the
proposed approach outperforms the state-of-the-art baseline work in terms of
clustering and localization accuracy, and thus produces more reliable results.",http://arxiv.org/abs/1903.00894v3
Critical behavior and magnetocaloric effect in VI$_3$,2019-03-12T15:15:25Z,"Yu Liu, Milinda Abeykoon, C. Petrovic","Layered van der Waals ferromagnets are promising candidates for designing new
spintronic devices. Here we investigated the critical properties and
magnetocaloric effect connected with ferromagnetic transition in layered van
der Waals VI$_3$ single crystals. The critical exponents $\beta = 0.244(5)$
with a critical temperature $T_c = 50.10(2)$ K and $\gamma = 1.028(12)$ with
$T_c = 49.97(5)$ K are obtained from the modified Arrott plot, whereas $\delta
= 5.24(2)$ is obtained from a critical isotherm analysis at $T_c = 50$ K. The
magnetic entropy change $-\Delta S_M(T,H)$ features a maximum at $T_c$, i.e.,
$-\Delta S_M^{max} \sim$ 2.64 (2.27) J kg$^{-1}$ K$^{-1}$ with out-of-plane
(in-plane) field change of 5 T. This is consistent with $-\Delta S_M^{max}$
$\sim$ 2.80 J kg$^{-1}$ K$^{-1}$ deduced from heat capacity and the
corresponding adiabatic temperature change $\Delta T_{ad}$ $\sim$ 0.96 K with
out-of-plane field change of 5 T. The critical analysis suggests that the
ferromagnetic phase transition in VI$_3$ is situated close to a three- to
two-dimensional critical point. The rescaled $\Delta S_M(T,H)$ curves collapse
onto a universal curve, confirming a second-order type of the magnetic
transition and reliability of the obtained critical exponents.",http://arxiv.org/abs/1903.05477v3
An Updated Duet Model for Passage Re-ranking,2019-03-18T18:44:07Z,"Bhaskar Mitra, Nick Craswell","We propose several small modifications to Duet---a deep neural ranking
model---and evaluate the updated model on the MS MARCO passage ranking task. We
report significant improvements from the proposed changes based on an ablation
study.",http://arxiv.org/abs/1903.07666v1
"Covariate-dependent control limits for the detection of abnormal price
  changes in scanner data",2019-12-04T07:27:37Z,"Youngrae Kim, Sangkyun Kim, Johan Lim, Sungim Lee, Won Son, Heejin Hwang","Currently, large-scale sales data for consumer goods, called scanner data,
are obtained by scanning the bar codes of individual products at the points of
sale of retail outlets. Many national statistical offices use scanner data to
build consumer price statistics. In this process, as in other statistical
procedures, the detection of abnormal transactions in sales prices is an
important step in the analysis. Popular methods for conducting such outlier
detection are the quartile method, the Hidiroglou-Berthelot method, the
resistant fences method, and the Tukey algorithm. These methods are based
solely on information about price changes and not on any of the other
covariates (e.g., sales volume or types of retail shops) that are also
available from scanner data. In this paper, we propose a new method to detect
abnormal price changes that takes into account an additional covariate, namely,
sales volume. We assume that the variance of the log of the price change is a
smooth function of the sales volume and estimate the function from previously
observed data. We numerically show the advantages of the new method over
existing methods. We also apply the methods to real scanner data collected at
weekly intervals by the Korean Chamber of Commerce and Industry between 2013
and 2014 and compare their performance.",http://arxiv.org/abs/1912.01832v2
"Control of ecological outcomes through deliberate parameter changes in a
  model of the gut microbiome",2019-12-07T02:04:40Z,"Zipeng Wang, Eric W. Jones, Joshua M. Mueller, Jean M. Carlson","The generalized Lotka-Volterra (gLV) equations are a mathematical proxy for
ecological dynamics. We focus on a gLV model of the gut microbiome, in which
the evolution of the gut microbial state is determined in part by pairwise
inter-species interaction parameters that encode environmentally-mediated
resource competition between microbes. We develop an in silico method that
controls the steady-state outcome of the system by adjusting these interaction
parameters. This approach is confined to a bistable region of the gLV model.
The two steady states of interest are idealized as either a ""healthy"" or
""diseased"" steady state of the gut microbiome. In this method, a dimensionality
reduction technique called steady-state reduction (SSR) is first used to
generate a two-dimensional (2D) gLV model that approximates the
high-dimensional dynamics on the 2D subspace spanned by the two steady states.
Then a bifurcation analysis of the 2D model analytically determines parameter
modifications that drive a disease-prone initial condition to the healthy
steady state. This parameter modification of the reduced 2D model guides
parameter modifications of the original high-dimensional model, resulting in a
change of steady-state outcome in the high-dimensional model. This control
method, called SPARC (SSR-guided parameter change), bypasses the computational
challenge of directly determining parameter modifications in the original
high-dimensional system. SPARC could guide the development of indirect
bacteriotherapies, which seek to change microbial compositions by deliberately
modifying gut environmental variables such as gut acidity or macronutrient
availability.",http://arxiv.org/abs/1912.03412v2
"A short proof on the transition matrix from the Specht basis to the
  Kazhdan-Lusztig basis",2019-12-09T01:27:00Z,Mee Seong Im,"We provide a short proof on the change-of-basis coefficients from the Specht
basis to the Kazhdan-Lusztig basis, using Kazhdan-Lusztig theory for parabolic
Hecke algebra.",http://arxiv.org/abs/1912.03809v1
Evidence for changing-look AGNs is caused by change of accretion mode,2019-12-09T11:19:03Z,"Hao liu, Qingwen Wu, Bing Lyu, Zhen Yan","The discovery of changing-look active galactic nuclei (CL AGNs), with
appearance and disappearance of broad emission lines and/or with strong
variation of line-of-sight column density within a few years, challenges the
AGN unification model. We explore the physical mechanisms based on the X-ray
spectral evolution for a sample of 15 CL AGNs. We find that the X-ray photon
index, $\Gamma$, and Eddington-scaled X-ray luminosity, $L_{\rm 2-10
keV}/L_{\rm Edd}$, follow negative and positive correlations when $L_{\rm 2-10
keV}/L_{\rm Edd}$ is lower and higher than a critical value of $\sim 10^{-3}$.
This different X-ray spectral evolution is roughly consistent with the
prediction of the accretion-mode transition (e.g., clumpy cold gas or cold disk
to advection dominated accretion flow, or vice visa). With quasi-simultaneous
X-ray and optical spectrum observations within one year, we find that the CL
AGNs observed with and without broad emission lines stay in the positive and
negative part of the $\Gamma-L_{\rm 2-10 keV}/L_{\rm Edd}$ correlation
respectively. Our result suggest that the change of the accretion mode may be
the physical reason for the CL AGNs.",http://arxiv.org/abs/1912.03972v1
Roles for Computing in Social Change,2019-12-10T18:46:42Z,"Rediet Abebe, Solon Barocas, Jon Kleinberg, Karen Levy, Manish Raghavan, David G. Robinson","A recent normative turn in computer science has brought concerns about
fairness, bias, and accountability to the core of the field. Yet recent
scholarship has warned that much of this technical work treats problematic
features of the status quo as fixed, and fails to address deeper patterns of
injustice and inequality. While acknowledging these critiques, we posit that
computational research has valuable roles to play in addressing social problems
-- roles whose value can be recognized even from a perspective that aspires
toward fundamental social change. In this paper, we articulate four such roles,
through an analysis that considers the opportunities as well as the significant
risks inherent in such work. Computing research can serve as a diagnostic,
helping us to understand and measure social problems with precision and
clarity. As a formalizer, computing shapes how social problems are explicitly
defined --- changing how those problems, and possible responses to them, are
understood. Computing serves as rebuttal when it illuminates the boundaries of
what is possible through technical means. And computing acts as synecdoche when
it makes long-standing social problems newly salient in the public eye. We
offer these paths forward as modalities that leverage the particular strengths
of computational work in the service of social change, without overclaiming
computing's capacity to solve social problems on its own.",http://arxiv.org/abs/1912.04883v4
"Analysis of Cardiovascular Changes Caused by Epileptic Seizures in Human
  Photoplethysmogram Signal",2019-12-11T02:04:29Z,"Seyede Mahya Safavi, Ninaz Valisharifabad, Robert Sabino, Hsinchung Chen, Ali HeydariGorji, Demi Tran, Jack Lin, Beth Lopour, Pai H. Chou","Objectives: This study examines human Photoplethysmogram (PPG) along with
Electrocardiogram (ECG) signals to study cardiac autonomic imbalance in
epileptic seizures. The significance and the prevalence of changes in PPG
morphological parameters have been investigated to find common patterns among
subjects. Alterations in cardiovascular parameters measured by PPG/ECG signals
are used to train a neural network based on LSTM for automatic seizure
detection. Methods: Electroencephalogram (EEG), ECG, and PPG signals from 12
different subjects ( 8 males;4 females;age 34.3$\pm$ 13.8) were recorded
including 57 seizures and 101 hours of inter-ictal data. 12 PPG features
significantly changing due to epileptic seizures were extracted and normalized
based on a proposed z-score metric. 7 feature are heart rate variability
related and 5 features hemodynamic related. Results: A consistent pattern of
ictal change was observed for all the features across the subjects/seziures.
The proposed seizure detector is subject independent and works for both
nocturnal and diurnal seizures. With an average of 0.52 false alarms per hour,
positive predictive value of $43\%$ and sensitivity of $92\%$, the new proposed
hemodynamic based seizure detector shows improvement over the the heart rate
variability based detector. Conclusion: The cardiac autonomic imbalance due to
seizure manifests itself in variations of peripheral hemodynamics measured by
PPG signal, suggesting vasoconstriction in limbs. These variations can be used
on a consumer seizure detecting devices with optical sensors for seizure
detection. Significance: The stereotyped pattern is common among all the
subjects which can help understand the mechanism of cardiac autonomic imbalance
induced by epileptic seizures.",http://arxiv.org/abs/1912.05083v1
Assessing Practitioner Beliefs about Software Defect Prediction,2019-12-20T20:40:27Z,"N. C. Shrikanth, Tim Menzies","Just because software developers say they believe in ""X"", that does not
necessarily mean that ""X"" is true. As shown here, there exist numerous beliefs
listed in the recent Software Engineering literature which are only supported
by small portions of the available data. Hence we ask what is the source of
this disconnect between beliefs and evidence?. To answer this question we look
for evidence for ten beliefs within 300,000+ changes seen in dozens of
open-source projects. Some of those beliefs had strong support across all the
projects; specifically, ""A commit that involves more added and removed lines is
more bug-prone"" and ""Files with fewer lines contributed by their owners (who
contribute most changes) are bug-prone"". Most of the widely-held beliefs
studied are only sporadically supported in the data; i.e. large effects can
appear in project data and then disappear in subsequent releases. Such sporadic
support explains why developers believe things that were relevant to their
prior work, but not necessarily their current work. Our conclusion will be that
we need to change the nature of the debate with Software Engineering.
Specifically, while it is important to report the effects that hold right now,
it is also important to report on what effects change over time.",http://arxiv.org/abs/1912.10093v3
Homeorhesis in Waddington's Landscape by Epigenetic Feedback Regulation,2019-12-27T05:28:39Z,"Yuuki Matsushita, Kunihiko Kaneko","In multicellular organisms, cells differentiate into several distinct types
during early development. Determination of each cellular state, along with the
ratio of each cell type, as well as the developmental course during cell
differentiation are highly regulated processes that are robust to noise and
environmental perturbations throughout development. Waddington metaphorically
depicted this robustness as the epigenetic landscape in which the robustness of
each cellular state is represented by each valley in the landscape. This
robustness is now conceptualized as an approach toward an attractor in a
gene-expression dynamical system. However, there is still an incomplete
understanding of the origin of landscape change, which is accompanied by
branching of valleys that corresponds to the differentiation process. Recent
progress in developmental biology has unveiled the molecular processes involved
in epigenetic modification, which will be a key to understanding the nature of
slow landscape change. Nevertheless, the contribution of the interplay between
gene expression and epigenetic modification to robust landscape changes, known
as homeorhesis, remains elusive. Here, we introduce a theoretical model that
combines epigenetic modification with gene expression dynamics driven by a
regulatory network. In this model, epigenetic modification changes the
feasibility of expression, i.e., the threshold for expression dynamics, and a
slow positive-feedback process from expression to the threshold level is
introduced. Under such epigenetic feedback, several fixed-point attractors with
distinct expression patterns are generated hierarchically shaping the
epigenetic landscape with successive branching of valleys. This theory provides
a quantitative framework for explaining homeorhesis in development as
postulated by Waddington, based on dynamical-system theory with slow feedback
reinforcement.",http://arxiv.org/abs/1912.11994v1
"Multi-contact Phase Change Toggle Logic Device Utilizing Thermal
  Crosstalk",2019-03-29T15:23:48Z,"Raihan Sayeed Khan, Nadim H. Kanan, Jake Scoggin, Helena Silva, Ali Gokirmak","Phase change memory (PCM) is an emerging high speed, high density, high
endurance, and scalable non-volatile memory technology which utilizes the large
resistivity contrast between the amorphous and crystalline phases of
chalcogenide materials such as Ge2Sb2Te5 (GST). In addition to being used as a
standalone memory, there has been a growing interest in integration of PCM
devices on top of the CMOS layer for computation in memory and neuromorphic
computing. The large CMOS overhead for memory controllers is a limiting factor
for this purpose. Transferring functionality like routing, multiplexing, and
logic to the memory layer can substantially reduce the CMOS overhead, making it
possible to integrate 100s of GB of PCM storage on top of a conventional CPU.
In this work, we present computational analysis of a phase change device
concept that can perform toggle operations. The toggle functionality is
achieved using two physical mechanisms: (i) isolation of different read
contacts due to amorphization between different write contact pairs, and (ii)
thermal cross-talk between a molten region and a previously amorphized region.
Phase-change devices with six contacts can be implemented as toggle flip-flops,
multiplexer, or demultiplexer when interfaced with CMOS transistors. Here, we
demonstrate the operation of the device as a toggle flip-flop with 5
transistors, requiring ~50% of the footprint compared to conventional CMOS
alternatives, with the added advantage of non-volatility.",http://arxiv.org/abs/1904.00836v1
HomebrewedDB: RGB-D Dataset for 6D Pose Estimation of 3D Objects,2019-04-05T17:16:09Z,"Roman Kaskman, Sergey Zakharov, Ivan Shugurov, Slobodan Ilic","Among the most important prerequisites for creating and evaluating 6D object
pose detectors are datasets with labeled 6D poses. With the advent of deep
learning, demand for such datasets is growing continuously. Despite the fact
that some of exist, they are scarce and typically have restricted setups, such
as a single object per sequence, or they focus on specific object types, such
as textureless industrial parts. Besides, two significant components are often
ignored: training using only available 3D models instead of real data and
scalability, i.e. training one method to detect all objects rather than
training one detector per object. Other challenges, such as occlusions,
changing light conditions and changes in object appearance, as well precisely
defined benchmarks are either not present or are scattered among different
datasets. In this paper we present a dataset for 6D pose estimation that covers
the above-mentioned challenges, mainly targeting training from 3D models (both
textured and textureless), scalability, occlusions, and changes in light
conditions and object appearance. The dataset features 33 objects (17 toy, 8
household and 8 industry-relevant objects) over 13 scenes of various
difficulty. We also present a set of benchmarks to test various desired
detector properties, particularly focusing on scalability with respect to the
number of objects and resistance to changing light conditions, occlusions and
clutter. We also set a baseline for the presented benchmarks using a
state-of-the-art DPOD detector. Considering the difficulty of making such
datasets, we plan to release the code allowing other researchers to extend this
dataset or make their own datasets in the future.",http://arxiv.org/abs/1904.03167v2
"Thermoelectric and optical probes for a Fermi surface topology change in
  noncentrosymmetric metals",2019-04-09T13:29:55Z,"Sonu Verma, Tutul Biswas, Tarun Kanti Ghosh","Noncentrosymmetric metals such as Li$_2$(Pd$_{1-x}$Pt$_x$)$_3$B have
different Fermi surface topology below and above the band touching point where
spin-degeneracy is not lifted by the spin-orbit coupling. We investigate
thermoelectric and optical response as probes for this Fermi surface topology
change. We show that the chemical potential displays a dimensional crossover
from a three-dimensional to one-dimensional characteristics as the descending
Fermi energy crosses the band touching point. This dimensional crossover is due
to the existence of different Fermi surface topology above and below the band
touching point. We obtain an exact expression of relaxation time due to
short-range scatterer by solving Boltzmann transport equations
self-consistently. The thermoelctric power and figure of merit are
significantly enhanced as the Fermi energy goes below the band touching point
owing to the underlying one-dimensional-like nature of noncentrosymmteric bulk
metals. The value of thermoelectric figure of merit goes beyond two as the
Fermi energy approaches to the van Hove singularity for lower spin-orbit
coupling. Similarly, the studies of the zero-frequency and finite-frequency
optical conductivities in the zero-momentum limit reflect the nature of
topological change of the Fermi surface. The Hall coefficient and optical
absorption width exhibit distinct signatures in response to the changes in
Fermi surface topology.",http://arxiv.org/abs/1904.04656v2
"An Extended Game-Theoretic Model for Aggregate Lane Choice Behavior of
  Vehicles at Traffic Diverges with a Bifurcating Lane",2019-04-17T16:52:59Z,"Ruolin Li, Negar Mehr, Roberto Horowitz","Road network junctions, such as merges and diverges, often act as bottlenecks
that initiate and exacerbate congestion. More complex junction configurations
lead to more complex driver behaviors, resulting in aggregate congestion
patterns that are more difficult to predict and mitigate. In this paper, we
discuss diverge configurations where vehicles on some lanes can enter only one
of the downstream roads, but vehicles on other lanes can enter one of several
downstream roads. Counterintuitively, these bifurcating lanes, rather than
relieving congestion (by acting as a versatile resource that can serve either
downstream road as the demand changes), often cause enormous congestion due to
lane changing. We develop an aggregate lane--changing model for this situation
that is expressive enough to model drivers' choices and the resultant
congestion, but simple enough to easily analyze. We use a game-theoretic
framework to model the aggregate lane choice behavior of selfish vehicles as a
Wardrop equilibrium (an aggregate type of Nash equilibrium). We then establish
the existence and uniqueness of this equilibrium. We explain how our model can
be easily calibrated using simulation data or real data, and we present results
showing that our model successfully predicts the aggregate behavior that
emerges from widely-used behavioral lane-changing models. Our model's
expressiveness, ease of calibration, and accuracy may make it a useful tool for
mitigating congestion at these complex diverges.",http://arxiv.org/abs/1904.08358v1
The evolution of polarization in the legislative branch of government,2019-04-20T23:54:51Z,"Xiaoyan Lu, Jianxi Gao, Boleslaw K. Szymanski","The polarization of political opinions among members of the U.S. legislative
chambers measured by their voting records is greater today than it was thirty
years ago. Previous research efforts to find causes of such increase have
suggested diverse contributors, like growth of online media, echo chamber
effects, media biases, or disinformation propagation. Yet, we lack theoretic
tools to understand, quantify, and predict the emergence of high political
polarization among voters and their legislators. Here, we analyze millions of
roll-call votes cast in the U.S. Congress over the past six decades. Our
analysis reveals the critical change of polarization patterns that started at
the end of 1980's. In earlier decades, polarization within each Congress tended
to decrease with time. In contrast, in the recent decades, the polarization has
been likely to grow within each term. To shed light on the reasons for this
change, we introduce here a formal model for competitive dynamics to quantify
the evolution of polarization patterns in the legislative branch of the U.S.
government. Our model represents dynamics of polarization, enabling us to
successfully predict the direction of polarization changes in 28 out of 30 U.S.
Congresses elected in the past six decades. From the evolution of polarization
level as measured by the Rice index, our model extracts a hidden parameter -
polarization utility which determines the convergence point of the polarization
evolution. The increase in the polarization utility implied by the model
strongly correlates with two current trends: growing polarization of voters and
increasing influence of election campaign funders. Two largest peaks of the
model's polarization utility correlate with significant political or
legislative changes happening at the same time.",http://arxiv.org/abs/1904.10317v1
"The algebraic dimension of compact complex threefolds with vanishing
  second Betti numbers",2019-04-25T07:04:32Z,"Frederic Campana, Jean-Pierre Demailly, Thomas Peternell","Small changes in sections 4 and 5, results not affected",http://arxiv.org/abs/1904.11179v2
"Photoacoustic monitoring of blood oxygenation during neurosurgical
  interventions",2019-04-26T12:47:43Z,"Thomas Kirchner, Janek Gröhl, Niklas Holzwarth, Mildred A. Herrera, Tim Adler, Adrián Hernández-Aguilera, Edgar Santos, Lena Maier-Hein","Multispectral photoacoustic (PA) imaging is a prime modality to monitor
hemodynamics and changes in blood oxygenation (sO2). Although sO2 changes can
be an indicator of brain activity both in normal and in pathological
conditions, PA imaging of the brain has mainly focused on small animal models
with lissencephalic brains. Therefore, the purpose of this work was to
investigate the usefulness of multispectral PA imaging in assessing sO2 in a
gyrencephalic brain. To this end, we continuously imaged a porcine brain as
part of an open neurosurgical intervention with a handheld PA and ultrasonic
(US) imaging system in vivo. Throughout the experiment, we varied respiratory
oxygen and continuously measured arterial blood gases. The arterial blood
oxygenation (SaO2) values derived by the blood gas analyzer were used as a
reference to compare the performance of linear spectral unmixing algorithms in
this scenario. According to our experiment, PA imaging can be used to monitor
sO2 in the porcine cerebral cortex. While linear spectral unmixing algorithms
are well-suited for detecting changes in oxygenation, there are limits with
respect to the accurate quantification of sO2, especially in depth. Overall, we
conclude that multispectral PA imaging can potentially be a valuable tool for
change detection of sO2 in the cerebral cortex of a gyrencephalic brain. The
spectral unmixing algorithms investigated in this work will be made publicly
available as part of the open-source software platform Medical Imaging
Interaction Toolkit (MITK).",http://arxiv.org/abs/1904.11809v1
Photo Switching of Protein Dynamical Collectivity,2019-06-03T15:50:18Z,"M. Xu, D. K. George, R. Jimenez, A. G. Markelz","We examine changes in the picosecond structural dynamics with irreversible
photobleaching of red fluorescent proteins mCherry, mOrange2 and TagRFP-T.
Measurements of the protein dynamical transition using terahertz time-domain
spectroscopy show in all cases an increase in the turn-on temperature in the
bleached state. The result is surprising given that there is little change in
the protein surface, and thus the solvent dynamics held responsible for the
transition should not change. A spectral analysis of the measurements guided by
quasiharmonic calculations of the protein absorbance reveals that indeed the
solvent dynamical turn-on temperature is independent of the thermal stability
and photostate however the protein dynamical turn-on temperature shifts to
higher temperatures. This is the first demonstration of switching the protein
dynamical turn-on temperature with protein functional state. The observed shift
in protein dynamical turn-on temperature relative to the solvent indicates an
increase in the required mobile waters necessary for the protein picosecond
motions: that is these motions are more collective. Melting-point measurements
reveal that the photobleached state is more thermally stable and structural
analysis of related RFPs shows that there is an increase in internal water
channels as well as a more uniform atomic root mean squared displacement. These
observations are consistent with previous suggestions that water channels form
with extended light excitation providing O2 access to the chromophore and
subsequent fluorescence loss. We report that these same channels increase
internal coupling enhancing thermal stability and collectivity of the
picosecond protein motions. The terahertz spectroscopic characterization of the
protein and solvent dynamical onsets can be applied generally to measure
changes in collectivity of protein motions.",http://arxiv.org/abs/1906.00893v1
Metrics Towards Measuring Cyber Agility,2019-06-12T21:50:45Z,"Jose David Mireles, Eric Ficke, Jin-Hee Cho, Patrick Hurley, Shouhuai Xu","In cyberspace, evolutionary strategies are commonly used by both attackers
and defenders. For example, an attacker's strategy often changes over the
course of time, as new vulnerabilities are discovered and/or mitigated.
Similarly, a defender's strategy changes over time. These changes may or may
not be in direct response to a change in the opponent's strategy. In any case,
it is important to have a set of quantitative metrics to characterize and
understand the effectiveness of attackers' and defenders' evolutionary
strategies, which reflect their {\em cyber agility}. Despite its clear
importance, few systematic metrics have been developed to quantify the cyber
agility of attackers and defenders. In this paper, we propose the first metric
framework for measuring cyber agility in terms of the effectiveness of the
dynamic evolution of cyber attacks and defenses. The proposed framework is
generic and applicable to transform any relevant, quantitative, and/or
conventional static security metrics (e.g., false positives and false
negatives) into dynamic metrics to capture dynamics of system behaviors. In
order to validate the usefulness of the proposed framework, we conduct case
studies on measuring the evolution of cyber attacks and defenses using two
real-world datasets. We discuss the limitations of the current work and
identify future research directions.",http://arxiv.org/abs/1906.05395v1
"Reputation Systems -- Fair allocation of points to the editors in the
  collaborative community",2019-06-18T02:01:46Z,Shubhendra Pal Singhal,"In this paper we are trying to determine a scheme for the fair allocation of
points to the contributors of the collaborative community. The major problem of
fair allocation of points among the contributors is that we have to analyze the
improvement in the versions of an article. Lets say there is a contribution of
major change in content which is relevant vs the contribution of adding a
single comma. Every contributor cannot be given the same points in such a case.
There are many ways which can be used like number of changes in a new version.
That might seem relevant but it becomes irrelevant in terms of correct content
contribution and other significant changes. There is no AI system too which can
detect such a change and award the points accordingly. So this problem of
allocation of points to the contributors is presented by an algorithm with a
theoretical proof. It relies on the interactive interaction of the users in the
system which is trivial in case of big system design economies.",http://arxiv.org/abs/1906.07339v2
"CHANG-ES XVII: H-alpha Imaging of Nearby Edge-on Galaxies, New SFRs, and
  an Extreme Star Formation Region -- Data Release 2",2019-06-18T18:45:12Z,"Carlos J. Vargas, Rene Walterbos, Richard Rand, Jeroen Stil, Marita Krause, Jiang-Tao Li, Judith Irwin, Ralf-Jurgen Dettmar","We present new narrow-band H-alpha imaging for 24 nearby edge-on galaxies in
the CHANG-ES survey. We use the images in conjunction with WISE 22 micron
imaging of the sample to estimate improved star formation rates (SFRs) using
the updated recipe from Vargas et al. (2018). We explore correlations between
the updated star formation properties and radio continuum scale heights, scale
lengths, and diameters, measured in Krause et al. (2018). We find a newly
discovered correlation between SFR and radio scale height that did not exist
using mid-IR only SFR calibrations. This implies that a mid-IR extinction
correction should be applied to SFR calibrations when used in edge-on galaxies,
due to attenuation by dust. The updated SFR values also show newly discovered
correlations with radio scale length and radio diameter, implying that the
previously-measured relationship between radio scale height and radio diameter
originates from star formation within the disk. We also identify a region of
star formation located at extreme distance from the disk of NGC 4157, possibly
ionized by a single O5.5 V star. This region is spatially coincident with an
XUV disk feature, as traced by GALEX NUV imaging. We theorize that the star
formation feature arose due to gravitational instability within gas from an
accretion event. New H-alpha images from this work can be found at the CHANG-ES
data release web site, https://www.queensu.ca/changes.",http://arxiv.org/abs/1906.07763v1
"Quantifying the Total Effect of Edge Interventions in Discrete
  Multistate Networks",2019-06-22T15:49:23Z,"David Murrugarra, Elena Dimitrova","Developing efficient computational methods to assess the impact of external
interventions on the dynamics of a network model is an important problem in
systems biology. This paper focuses on quantifying the global changes that
result from the application of an intervention to produce a desired effect,
which we define as the total effect of the intervention. The type of
mathematical models that we will consider are discrete dynamical systems which
include the widely used Boolean networks and their generalizations. The
potential interventions can be represented by a set of nodes and edges that can
be manipulated to produce a desired effect on the system. We use a class of
regulatory rules called nested canalizing functions that frequently appear in
published models and were inspired by the concept of canalization in
evolutionary biology. In this paper, we provide a polynomial normal form based
on the canalizing properties of regulatory functions. Using this polynomial
normal form, we give a set of formulas for counting the maximum number of
transitions that will change in the state space upon an edge deletion in the
wiring diagram. These formulas rely on the canalizing structure of the target
function since the number of changed transitions depends on the canalizing
layer that includes the input to be deleted. We also present computations on
random networks to compare the exact number of changes with the upper bounds
provided by our formulas. Finally, we provide statistics on the sharpness of
these upper bounds in random networks.",http://arxiv.org/abs/1906.09465v4
"The Sloan Digital Sky Survey Reverberation Mapping Project: Accretion
  and Broad Emission Line Physics from a Hypervariable Quasar",2019-06-24T18:00:03Z,"Jason Dexter, Shuo Xin, Yue Shen, C. J. Grier, Teng Liu, Suvi Gezari, Ian D. McGreer, W. N. Brandt, P. B. Hall, Keith Horne, Torben Simm, Andrea Merloni, Paul J. Green, M. Vivek, Jonathan R. Trump, Yasaman Homayouni, B. M. Peterson, Donald P. Schneider, K. Kinemuchi, Kaike Pan, Dmitry Bizyaev","We analyze extensive spectroscopic and photometric data of the hypervariable
quasar SDSS J131424+530527 (RMID 017) at z=0.456, an optical ""changing look""
quasar from the Sloan Digital Sky Survey Reverberation Mapping project that
increased in optical luminosity by a factor of 10 between 2014 and 2017. The
observed broad emission lines all respond in luminosity and width to the
changing optical continuum, as expected for photoionization in a stratified,
virialized broad emission line region. The luminosity changes therefore result
from intrinsic changes in accretion power rather than variable obscuration. The
variability is continuous and apparently stochastic, disfavoring an origin as a
discrete event such as a tidal disruption flare or microlensing event. It is
coordinated on day timescales with blue leading red, consistent with
reprocessing powering the entire optical SED. We show that this process cannot
work in a standard thin disk geometry on energetic grounds, and would instead
require a large covering factor reprocessor. Disk instability models could
potentially also explain the data, provided that the instability sets in near
the inner radius of a geometrically thick accretion disk.",http://arxiv.org/abs/1906.10138v1
"Detection of small changes in medical and random-dot images comparing
  self-organizing map performance to human detection",2019-06-26T16:42:19Z,"John Wandeto, Henry Nyongesa, Yves Remond, Birgitta Dresp-Langley","Radiologists use time series of medical images to monitor the progression of
a patient condition. They compare information gleaned from sequences of images
to gain insight on progression or remission of the lesions, thus evaluating the
progress of a patient condition or response to therapy. Visual methods of
determining differences between one series of images to another can be
subjective or fail to detect very small differences. We propose the use of
quantization errors obtained from Self Organizing Maps for image content
analysis. We tested this technique with MRI images to which we progressively
added synthetic lesions. We have used a global approach that considers changes
on the entire image as opposed to changes in segmented lesion regions only. We
claim that this approach does not suffer from the limitations imposed by
segmentation, which may compromise the results. Results show quantization
errors increased with the increase in lesions on the images. The results are
also consistent with previous studies using alternative approaches. We then
compared the detectability ability of our method to that of human novice
observers having to detect very small local differences in random-dot images.
The quantization errors of the SOM outputs compared with correct positive
rates, after subtraction of false positive rates (guess rates), increased
noticeably and consistently with small increases in local dot size that were
not detectable by humans. We conclude that our method detects very small
changes in complex images and suggest that it could be implemented to assist
human operators in image based decision making.",http://arxiv.org/abs/1906.11675v1
Fundamental groups and path lifting for algebraic varieties,2019-06-27T17:49:07Z,János Kollár,"We study 3 basic questions about fundamental groups of algebraic varieties.
For a morphism, is being surjective on $\pi_1$ preserved by base change? What
is the connection between openness in the Zariski and in the Euclidean
topologies? Which morphisms have the path lifting property?",http://arxiv.org/abs/1906.11816v1
On Sinha's note on perfect numbers,2019-06-28T12:54:44Z,Tomohiro Yamada,"We shall show that there is no odd perfect number of the form $2^n+1$ or
$n^n+1$.",http://arxiv.org/abs/1906.12184v2
"Sequential online prediction in the presence of outliers and change
  points: an instant temporal structure learning approach",2019-07-15T09:05:05Z,"Bin Liu, Yu Qi, Ke-Jia Chen","In this paper, we consider sequential online prediction (SOP) for streaming
data in the presence of outliers and change points. We propose an INstant
TEmporal structure Learning (INTEL) algorithm to address this problem. Our
INTEL algorithm is developed based on a full consideration of the duality
between online prediction and anomaly detection. We first employ a mixture of
weighted Gaussian process models (WGPs) to cover the expected possible temporal
structures of the data. Then, based on the rich modeling capacity of this WGP
mixture, we develop an efficient technique to instantly learn (capture) the
temporal structure of the data that follows a regime shift. This instant
learning is achieved only by adjusting one hyper-parameter value of the mixture
model. A weighted generalization of the product of experts (POE) model is used
for fusing predictions yielded from multiple GP models. An outlier is declared
once a real observation seriously deviates from the fused prediction. If a
certain number of outliers are consecutively declared, then a change point is
declared. Extensive experiments are performed using a diverse of real datasets.
Results show that the proposed algorithm is significantly better than benchmark
methods for SOP in the presence of outliers and change points.",http://arxiv.org/abs/1907.06377v2
"Slowing-down reduction and Possible Reversal Trend of Tropospheric NO2
  over China during 2016 to 2019",2019-07-15T14:40:09Z,"Rui Li, Haixu Bo, Yu Wang","Atmospheric nitrogen dioxide (NO2) over China at national level has been kept
reducing since 2011 as seen from both satellite observations, ground-based
measurements and bottom-up emission inventory (Liu et al., 2016; Irie et al.,
2016; Krotkov et al., 2016; Foy et al., 2016; Liu et al 2017). These studies
used data before 2015-2016. After 2016, however, a significant slowing-down of
the reduction trend and/or even a reversal trend were found in numerous
provinces, particularly in those with heavy NO2 level, based on satellite
observations. Error analysis on satellite data excluded cloud contamination,
instrument anomalies from the main reasons of this change. Ground-based
measurements show strong positive correlations with satellite observations and
similar patterns of year-to-year changes of NO2 in 2018 and 2019 winter time.
The temporal variations of Satellite NO2 over China are believed largely
determined by surface emission from power plant and transportation. The reason
for the recent change from emission perspective cannot be traced down since the
national emission inventory was not updated since 2015. We therefore call on
immediate attentions from both scientist community and policy makers to this
phenomenon. Further efforts should be made to understand the reasons causing
this change and to make associated air pollution controlling actions.",http://arxiv.org/abs/1907.06525v1
"Sign change of polarization rotation under either time or space
  inversion in magnetoelectric YbAl3(BO3)4",2019-07-16T09:07:30Z,"A. M. Kuzmenko, V. Dziom, A. Shuvaev, A. Pimenov, D. Szaller, A. A. Mukhin, V. Yu. Ivanov, A. Pimenov","Materials with optical activity can rotate the polarization plane of
transmitted light. The most typical example is the natural optical activity,
which has the symmetry property of changing sign after space inversion but
being invariant to time inversion. Faraday rotation exhibits the opposite: it
is invariant to space inversion but changes sign after time reversal. Here, we
demonstrate that in a magnetoelectric material, another type of polarization
rotation is possible. This effect is investigated in magnetoelectric
YbAl3(BO3)4 under the viewpoint of time and space inversion symmetry arguments.
We observe the sign change of the rotation sense under either time or space
reversal. This investigation proves that the polarization rotation in
YbAl3(BO3)4 must be classified as gyrotropic birefringence, which has been
discussed within the idea of time-reversal breaking in underdoped cuprates. The
diagonal terms in the magnetoelectric susceptibility are responsible for the
observed signal of gyrotropic birefringence. Further analysis of the
experimental spectra reveals a substantial contribution of the natural optical
activity to the polarization rotation. We also demonstrate that the observed
activity originates from the magnetoelectric susceptibility.",http://arxiv.org/abs/1907.06899v1
"Global Well-posedness for the Primitive Equations Coupled to Nonlinear
  Moisture Dynamics with Phase Changes",2019-07-25T17:00:55Z,"Sabine Hittmeir, Rupert Klein, Jinkai Li, Edriss S. Titi","In this work we study the global solvability of the primitive equations for
the atmosphere coupled to moisture dynamics with phase changes for warm clouds,
where water is present in the form of water vapor and in the liquid state as
cloud water and rain water. This moisture model contains closures for the phase
changes condensation and evaporation, as well as the processes of
autoconversion of cloud water into rainwater and the collection of cloud water
by the falling rain droplets. It has been used by Klein and Majda in \cite{KM}
and corresponds to a basic form of the bulk microphysics closure in the spirit
of Kessler \cite{Ke} and Grabowski and Smolarkiewicz \cite{GS}. The moisture
balances are strongly coupled to the thermodynamic equation via the latent heat
associated to the phase changes. In \cite{HKLT} we assumed the velocity field
to be given and proved rigorously the global existence and uniqueness of
uniformly bounded solutions of the moisture balances coupled to the
thermodynamic equation. In this paper we present the solvability of a full
moist atmospheric flow model, where the moisture model is coupled to the
primitive equations of atmospherical dynamics governing the velocity field. For
the derivation of a priori estimates for the velocity field we thereby use the
ideas of Cao and Titi \cite{CT}, who succeeded in proving the global
solvability of the primitive equations.",http://arxiv.org/abs/1907.11199v2
Prediction of Highway Lane Changes Based on Prototype Trajectories,2019-07-25T17:18:53Z,"David Augustin, Marius Hofmann, Ulrich Konigorski","The vision of automated driving is to increase both road safety and
efficiency, while offering passengers a convenient travel experience. This
requires that autonomous systems correctly estimate the current traffic scene
and its likely evolution. In highway scenarios early recognition of cut-in
maneuvers is essential for risk-aware maneuver planning. In this paper, a
statistical approach is proposed, which advantageously utilizes a set of
prototypical lane change trajectories to realize both early maneuver detection
and uncertainty-aware trajectory prediction for traffic participants.
Generation of prototype trajectories from real traffic data is accomplished by
Agglomerative Hierarchical Clustering. During clustering, the alignment of the
cluster prototypes to each other is optimized and the cohesion of the resulting
prototype is limited when two clusters merge. In the prediction stage, the
similarity of observed vehicle motion and typical lane change patterns in the
data base is evaluated to construct a set of significant features for maneuver
classification via Boosted Decision Trees. The future trajectory is predicted
combining typical lane change realizations in a mixture model. B-splines based
trajectory adaptations guarantee continuity during transition from actually
observed to predicted vehicle states. Quantitative evaluation results
demonstrate the proposed concept's improved performance for both maneuver and
trajectory prediction compared to a previously implemented reference approach.",http://arxiv.org/abs/1907.11208v1
Discriminability Tests for Visualization Effectiveness and Scalability,2019-07-26T01:57:36Z,"Rafael Veras, Christopher Collins","The scalability of a particular visualization approach is limited by the
ability for people to discern differences between plots made with different
datasets. Ideally, when the data changes, the visualization changes in
perceptible ways. This relation breaks down when there is a mismatch between
the encoding and the character of the dataset being viewed. Unfortunately,
visualizations are often designed and evaluated without fully exploring how
they will respond to a wide variety of datasets. We explore the use of an image
similarity measure, the Multi-Scale Structural Similarity Index (MS-SSIM), for
testing the discriminability of a data visualization across a variety of
datasets. MS-SSIM is able to capture the similarity of two visualizations
across multiple scales, including low level granular changes and high level
patterns. Significant data changes that are not captured by the MS-SSIM
indicate visualizations of low discriminability and effectiveness. The
measure's utility is demonstrated with two empirical studies. In the first, we
compare human similarity judgments and MS-SSIM scores for a collection of
scatterplots. In the second, we compute the discriminability values for a set
of basic visualizations and compare them with empirical measurements of
effectiveness. In both cases, the analyses show that the computational measure
is able to approximate empirical results. Our approach can be used to rank
competing encodings on their discriminability and to aid in selecting
visualizations for a particular type of data distribution.",http://arxiv.org/abs/1907.11358v1
Ice Model Calibration Using Semi-continuous Spatial Data,2019-07-31T15:30:36Z,"Won Chang, Bledar A. Konomi, Georgios Karagiannis, Yawen Guan, Murali Haran","Rapid changes in Earth's cryosphere caused by human activity can lead to
significant environmental impacts. Computer models provide a useful tool for
understanding the behavior and projecting the future of Arctic and Antarctic
ice sheets. However, these models are typically subject to large parametric
uncertainties due to poorly constrained model input parameters that govern the
behavior of simulated ice sheets. Computer model calibration provides a formal
statistical framework to infer parameters using observational data, and to
quantify the uncertainty in projections due to the uncertainty in these
parameters. Calibration of ice sheet models is often challenging because the
relevant model output and observational data take the form of semi-continuous
spatial data, with a point mass at zero and a right-skewed continuous
distribution for positive values. Current calibration approaches cannot handle
such data. Here we introduce a hierarchical latent variable model that handles
binary spatial patterns and positive continuous spatial patterns as separate
components. To overcome challenges due to high-dimensionality we use
likelihood-based generalized principal component analysis to impose
low-dimensional structures on the latent variables for spatial dependence. We
apply our methodology to calibrate a physical model for the Antarctic ice sheet
and demonstrate that we can overcome the aforementioned modeling and
computational challenges. As a result of our calibration, we obtain improved
future ice-volume change projections.",http://arxiv.org/abs/1907.13554v1
Monatomic phase change memory,2019-02-01T09:57:43Z,"Martin Salinga, Benedikt Kersting, Ider Ronneberger, Vara Prasad Jonnalagadda, Xuan Thang Vu, Manuel Le Gallo, Iason Giannopoulos, Oana Cojocaru-Mirédin, Riccardo Mazzarello, Abu Sebastian","Phase change memory has been developed into a mature technology capable of
storing information in a fast and non-volatile way, with potential for
neuromorphic computing applications. However, its future impact in electronics
depends crucially on how the materials at the core of this technology adapt to
the requirements arising from continued scaling towards higher device
densities. A common strategy to finetune the properties of phase change memory
materials, reaching reasonable thermal stability in optical data storage,
relies on mixing precise amounts of different dopants, resulting often in
quaternary or even more complicated compounds. Here we show how the simplest
material imaginable, a single element (in this case, antimony), can become a
valid alternative when confined in extremely small volumes. This compositional
simplification eliminates problems related to unwanted deviations from the
optimized stoichiometry in the switching volume, which become increasingly
pressing when devices are aggressively miniaturized. Removing compositional
optimization issues may allow one to capitalize on nanosize effects in
information storage.",http://arxiv.org/abs/1902.00254v1
Stabilization Time in Weighted Minority Processes,2019-02-04T14:46:05Z,"Pál András Papp, Roger Wattenhofer","A minority process in a weighted graph is a dynamically changing coloring.
Each node repeatedly changes its color in order to minimize the sum of weighted
conflicts with its neighbors. We study the number of steps until such a process
stabilizes. Our main contribution is an exponential lower bound on
stabilization time. We first present a construction showing this bound in the
adversarial sequential model, and then we show how to extend the construction
to establish the same bound in the benevolent sequential model, as well as in
any reasonable concurrent model. Furthermore, we show that the stabilization
time of our construction remains exponential even for very strict switching
conditions, namely, if a node only changes color when almost all (i.e., any
specific fraction) of its neighbors have the same color. Our lower bound works
in a wide range of settings, both for node-weighted and edge-weighted graphs,
or if we restrict minority processes to the class of sparse graphs.",http://arxiv.org/abs/1902.01228v1
"Passive radiative ""thermostat"" enabled by phase-change photonic
  nanostructures",2019-02-04T18:17:59Z,"Wilton J. M. Kort-Kamp, Shobhita Kramadhati, Abul K. Azad, Matthew T. Reiten, Diego A. R. Dalvit","A thermostat senses the temperature of a physical system and switches heating
or cooling devices on or off, regulating the flow of heat to maintain the
system's temperature near a desired setpoint. Taking advantage of recent
advances in radiative heat transfer technologies, here we propose a passive
radiative ""thermostat"" based on phase-change photonic nanostructures for
thermal regulation at room temperature. By self-adjusting their visible to
mid-IR absorptivity and emissivity responses depending on the ambient
temperature, the proposed devices use the sky to passively cool or heat during
day-time using the phase-change transition temperature as the setpoint, while
at night-time temperature is maintained at or below ambient. We simulate the
performance of a passive nanophotonic thermostat design based on vanadium
dioxide thin films, showing daytime passive cooling (heating) with respect to
ambient in hot (cold) days, maintaining an equilibrium temperature
approximately locked within the phase transition region. Passive radiative
thermostats can potentially enable novel thermal management technologies, e.g.
to moderate diurnal temperature in regions with extreme annual thermal swings.",http://arxiv.org/abs/1902.01354v1
"Efficient Change-Point Detection for Tackling Piecewise-Stationary
  Bandits",2019-02-05T07:37:48Z,"Lilian Besson, Emilie Kaufmann, Odalric-Ambrym Maillard, Julien Seznec","We introduce GLR-klUCB, a novel algorithm for the piecewise iid
non-stationary bandit problem with bounded rewards. This algorithm combines an
efficient bandit algorithm, kl-UCB, with an efficient, parameter-free,
changepoint detector, the Bernoulli Generalized Likelihood Ratio Test, for
which we provide new theoretical guarantees of independent interest. Unlike
previous non-stationary bandit algorithms using a change-point detector,
GLR-klUCB does not need to be calibrated based on prior knowledge on the arms'
means. We prove that this algorithm can attain a $O(\sqrt{TA
\Upsilon_T\log(T)})$ regret in $T$ rounds on some ""easy"" instances, where A is
the number of arms and $\Upsilon_T$ the number of change-points, without prior
knowledge of $\Upsilon_T$. In contrast with recently proposed algorithms that
are agnostic to $\Upsilon_T$, we perform a numerical study showing that
GLR-klUCB is also very efficient in practice, beyond easy instances.",http://arxiv.org/abs/1902.01575v2
"Dipolar Switching of Charge-Injection Barriers at
  Electrode/Semiconductor Interfaces as a Mechanism for Water-Induced
  Instabilities of Organic Devices",2019-02-05T11:03:34Z,Ryo Nouchi,"An electrode contact-related mechanism for the operational instability of
organic electronic devices is proposed and confirmed via observation of a
water-induced change in charge-injection barrier eights at the
electrode/organic-semiconductor interfaces. Water molecules in air penetrate
into the organic crystal via diffusion, and an external electric field orients
the electric dipole of the water molecules at the electrode surfaces, leading
to dipolar switching of the charge-injection barrier height. As a result of the
switching, current-voltage curves of two-terminal Au-rubrene-Au devices change
from symmetric to asymmetric, showing diode-like rectification and reversible
switching of the diode polarity. The device shows the highest current switching
ratio of 267 for the switching voltage of 3 V, corresponding to an electrode
work function change of >144 meV. The mechanism proposed herein will be
important especially for short-channel organic devices, which are indispensable
for applications such as organic integrated circuits.",http://arxiv.org/abs/1902.01640v2
"Discovering bursts revisited: guaranteed optimization of the model
  parameters",2019-02-05T15:00:23Z,Nikolaj Tatti,"One of the classic data mining tasks is to discover bursts, time intervals,
where events occur at abnormally high rate. In this paper we revisit
Kleinberg's seminal work, where bursts are discovered by using exponential
distribution with a varying rate parameter: the regions where it is more
advantageous to set the rate higher are deemed bursty. The model depends on two
parameters, the initial rate and the change rate. The initial rate, that is,
the rate that is used when there are no burstiness was set to the average rate
over the whole sequence. The change rate is provided by the user.
  We argue that these choices are suboptimal: it leads to worse likelihood, and
may lead to missing some existing bursts. We propose an alternative problem
setting, where the model parameters are selected by optimizing the likelihood
of the model. While this tweak is trivial from the problem definition point of
view, this changes the optimization problem greatly. To solve the problem in
practice, we propose efficient ($1 + \epsilon$) approximation schemes. Finally,
we demonstrate empirically that with this setting we are able to discover
bursts that would have otherwise be undetected.",http://arxiv.org/abs/1902.01727v1
How Different Are Different diff Algorithms in Git?,2019-02-07T04:16:49Z,"Yusuf Sulistyo Nugroho, Hideaki Hata, Kenichi Matsumoto","Automatic identification of the differences between two versions of a file is
a common and basic task in several applications of mining code repositories.
Git, a version control system, has a diff utility and users can select
algorithms of diff from the default algorithm Myers to the advanced Histogram
algorithm. From our systematic mapping, we identified three popular
applications of diff in recent studies. On the impact on code churn metrics in
14 Java projects, we obtained different values in 1.7% to 8.2% commits based on
the different diff algorithms. Regarding bug-introducing change identification,
we found 6.0% and 13.3% in the identified bug-fix commits had different results
of bug-introducing changes from 10 Java projects. For patch application, we
found that the Histogram is more suitable than Myers for providing the changes
of code, from our manual analysis. Thus, we strongly recommend using the
Histogram algorithm when mining Git repositories to consider differences in
source code.",http://arxiv.org/abs/1902.02467v4
"WdW-patches in AdS$_{3}$ and complexity change under conformal
  transformations II",2019-02-18T10:36:09Z,Mario Flory,"We study the null-boundaries of Wheeler-de Witt (WdW) patches in three
dimensional Poincare-AdS, when the selected boundary timeslice is an arbitrary
(non-constant) function, presenting some useful analytic statements about them.
Special attention will be given to the piecewise smooth nature of the
null-boundaries, due to the emergence of caustics and null-null joint curves.
This is then applied, in the spirit of our previous paper arXiv:1806.08376, to
the problem of how complexity of the CFT$_2$ groundstate changes under a small
local conformal transformation according to the action (CA) proposal. In stark
contrast to the volume (CV) proposal, where this change is only proportional to
the second order in the infinitesimal expansion parameter $\sigma$, we show
that in the CA case we obtain terms of order $\sigma$ and even
$\sigma\log(\sigma)$. This has strong implications for the possible
field-theory duals of the CA proposal, ruling out an entire class of them.",http://arxiv.org/abs/1902.06499v2
"Spatial And Temporal Changes Of The Geomagnetic Field: Insights From
  Forward And Inverse Core Field Models",2019-02-21T15:28:44Z,Nicolas Gillet,"Observational constraints on geomagnetic field changes from interannual to
millenial periods are reviewed, and the current resolution of field models
(covering archeological to satellite eras) is discussed. With the perspective
of data assimilation, emphasis is put on uncertainties entaching Gauss
coefficients, and on the statistical properties of ground-based records. These
latter potentially call for leaving behind the notion of geomagnetic jerks. The
accuracy at which we recover interannual changes also requires considering with
caution the apparent periodicity seen in the secular acceleration from
satellite data. I then address the interpretation of recorded magnetic
fluctuations in terms of core dynamics, highlighting the need for models that
allow (or pre-suppose) a magnetic energy orders of magnitudes larger than the
kinetic energy at large length-scales, a target for future numerical
simulations of the geodynamo. I finally recall the first attempts at
implementing geomagnetic data assimilation algorithms.",http://arxiv.org/abs/1902.08098v1
An IDEA: An Ingestion Framework for Data Enrichment in AsterixDB,2019-02-21T21:23:05Z,"Xikui Wang, Michael J. Carey","Big Data today is being generated at an unprecedented rate from various
sources such as sensors, applications, and devices, and it often needs to be
enriched based on other reference information to support complex analytical
queries. Depending on the use case, the enrichment operations can be compiled
code, declarative queries, or machine learning models with different
complexities. For enrichments that will be frequently used in the future, it
can be advantageous to push their computation into the ingestion pipeline so
that they can be stored (and queried) together with the data. In some cases,
the referenced information may change over time, so the ingestion pipeline
should be able to adapt to such changes to guarantee the currency and/or
correctness of the enrichment results.
  In this paper, we present a new data ingestion framework that supports data
ingestion at scale, enrichments requiring complex operations, and adaptiveness
to reference data changes. We explain how this framework has been built on top
of Apache AsterixDB and investigate its performance at scale under various
workloads.",http://arxiv.org/abs/1902.08271v5
"Absorption cross-section spectroscopy of single strong coupling system
  between plasmon and molecular exciton resonance using single silver
  nanoparticle dimer generating surface enhanced resonant Raman scattering",2019-02-23T03:20:21Z,"Tamitake Itoh, Yuko S. Yamamoto, Takayuki Okamoto","This study investigated spectral changes in the absorption cross-sections of
single strong coupling systems composed of single silver nanoparticle dimers
and a few dye molecules during the quenching of surface-enhanced resonant Raman
scattering (SERRS). The absorption cross-section was obtained by subtracting
the scattering cross-section from an extinction cross-section. The spectral
changes in these cross-sections were evaluated using a classical hybridization
model composed of a plasmon and a molecular exciton including a molecular
multi-level property. The changes in the scattering and extinction
cross-sections exhibit blue-shifts in their peak energy and increased peak
intensities, respectively, during SERRS quenching. These properties are
effectively reproduced in the model by decreasing the coupling energy. In
particular, the peaks in the scattering and extinction cross-sections appear as
peaks or dips in the absorption cross-sections depending on the degree of
scattering loss, which reflects the dimer sizes. These results are useful for
optimizing photophysical and photochemical effects mediated by the electronic
excited states of strong coupling systems.",http://arxiv.org/abs/1902.08724v1
"Sign change in the anomalous Hall effect and strong transport effects in
  a 2D massive Dirac metal due to spin-charge correlated disorder",2019-02-25T20:50:17Z,"Aydin Cem Keser, Roberto Raimondi, Dimitrie Culcer","The anomalous Hall effect (AHE) is highly sensitive to disorder in the
metallic phase. Here we show that statistical correlations between the charge
and spin disorder sectors strongly affect both the longitudinal conductivity
and the sign/magnitude of AHE. Correlations between mass and charge disorder
can be absorbed into an effective mass. In general, random gauge fields are
also present due to e.g. in-plane component of magnetization in topological
insulator, causing an anisotropy in conductivity. As the correlation between
the charge and gauge-mass components increases, so does the AHE, achieving its
universal value, and even exceed it, although the system is an impure metal.
The AHE can change sign when the anti-correlations reverse the effective mass,
a possible mechanism behind the sign change seen in recent experiments.",http://arxiv.org/abs/1902.09605v2
"Three Different Ways Synchronization Can Cause Contagion in Financial
  Markets",2019-02-27T21:55:34Z,"Naji Massad, Jørgen Vitting Andersen","We introduce tools to capture the dynamics of three different pathways, in
which the synchronization of human decision-making could lead to turbulent
periods and contagion phenomena in financial markets. The first pathway is
caused when stock market indices, seen as a set of coupled integrate-and-fire
oscillators, synchronize in frequency. The integrate-and-fire dynamics happens
due to change blindness, a trait in human decision-making where people have the
tendency to ignore small changes, but take action when a large change happens.
The second pathway happens due to feedback mechanisms between market
performance and the use of certain (decoupled) trading strategies. The third
pathway occurs through the effects of communication and its impact on human
decision-making. A model is introduced in which financial market performance
has an impact on decision-making through communication between people.
Conversely, the sentiment created via communication has an impact on financial
market performance. The methodologies used are: agent based modeling, models of
integrate-and-fire oscillators, and communication models of human
decision-making",http://arxiv.org/abs/1902.10800v1
Metric Learning for Dynamic Text Classification,2019-11-04T04:27:29Z,"Jeremy Wohlwend, Ethan R. Elenberg, Samuel Altschul, Shawn Henry, Tao Lei","Traditional text classifiers are limited to predicting over a fixed set of
labels. However, in many real-world applications the label set is frequently
changing. For example, in intent classification, new intents may be added over
time while others are removed. We propose to address the problem of dynamic
text classification by replacing the traditional, fixed-size output layer with
a learned, semantically meaningful metric space. Here the distances between
textual inputs are optimized to perform nearest-neighbor classification across
overlapping label sets. Changing the label set does not involve removing
parameters, but rather simply adding or removing support points in the metric
space. Then the learned metric can be fine-tuned with only a few additional
training examples. We demonstrate that this simple strategy is robust to
changes in the label space. Furthermore, our results show that learning a
non-Euclidean metric can improve performance in the low data regime, suggesting
that further work on metric spaces may benefit low-resource research.",http://arxiv.org/abs/1911.01026v1
Yield-stress anomaly in equiatomic ZrNbTiVHf high-entropy alloys,2019-11-05T15:48:19Z,"T. Lienig, C. Thomas, M. Feuerbacher","We have carried out plastic deformation experiments on single-phase samples
of the body centered ZrNbTiVHf high-entropy alloy between room temperature and
1150 K. The experiments were carried out on polycrystalline samples with two
different grain sizes, in compression at a true constant strain rate of 10-4
1/s. Incremental tests such as stress-relaxation tests, strain-rate changes and
temperature changes were carried out in order to determine thermodynamic
activation parameters of the plastic deformation process. The material displays
a yield-stress anomaly in the temperature range between about 500 and 800 K,
where the yield stress increases with increasing temperature. In the same
temperature range, we find an extremely low strain-rate dependence of the flow
stress, which is reflected in almost constant flow-stress values in
stress-relaxations and strain-rate changes. At temperatures below 400 and above
800 K we find regular plastic deformation behavior with a linear temperature
dependence of the yield stress of about -1.1 MPa/K, an activation volume of
around 1.8 nm3 and 0.2 nm3 at low and high stresses, respectively, and an
activation enthalpy of 2.7 eV in the high-temperature range.",http://arxiv.org/abs/1911.01887v1
Sculpting vesicles with active particles: Less is more,2019-11-06T13:44:37Z,"Hanumantha Rao Vutukuri, Masoud Hoore, Clara Abaurrea-Velasco, Lennard van Buren, Alessandro Dutto, Thorsten Auth, Dmitry A. Fedosov, Gerhard Gompper, Jan Vermant","Biological cells are able to generate intricate structures and respond to
external stimuli, sculpting their membrane from within. Simplified biomimetic
systems can aid in understanding the principles which govern these shape
changes and elucidate the response of the cell membrane under strong
deformations. Here, a combined experimental and simulation approach is used to
identify the conditions under which different non-equilibrium shapes and
distinct active shape fluctuations can be obtained by enclosing self-propelled
particles in giant vesicles. Interestingly, the most pronounced shape changes
are observed at relatively low particle loadings, starting with the formation
of tether-like protrusions to highly branched, dendritic structures. At high
volume fractions, globally deformed vesicle shapes are observed. The obtained
state diagram of vesicles sculpted by active particles predicts the conditions
under which local internal forces can generate dramatic cell shape changes,
such as branched structures in neurons.",http://arxiv.org/abs/1911.02381v1
"Effects of Electron Correlations and Chemical Pressures on
  Superconductivity of $β^{\prime\prime}$-type Organic Compounds",2019-11-11T23:21:29Z,"S. Imajo, H. Akutsu, A. Akutsu-Sato, A. L. Morritt, L. Martin, Y. Nakazawa","We investigate low-temperature electronic states of the series of organic
conductors $\beta^{\prime\prime}$-(BEDT-TTF)$_4$[(H$_3$O)M(C$_2$O$_4$)$_3$]G,
where BEDT-TTF is bis(ethylenedithio)tetrathiafulvalene, and M and G represent
trivalent metal ions and guest organic molecules, respectively. Our structural
analyses reveal that the replacement of M and G give rise to systematic change
in the cell parameters, especially in the $b$-axis length, which has positive
correlation with the superconducting transition temperature $T_{\rm c}$.
Analyses of temperature and magnetic field dependences of the electrical
resistance including the Shubnikov-de Haas oscillations elucidates that the
variation of charge disproportionation, effective mass and the number of
itinerant carriers, can be systematically explained by the change of the
$b$-axis length. The changes of the transfer integrals induced by
stretching/compressing the $b$-axis are confirmed by the band calculation. We
discuss that electron correlations in quarter-filled electronic bands lead to
charge disproportionation and the possibility of a novel pairing mechanism of
superconductivity mediated by charge degrees of freedom.",http://arxiv.org/abs/1911.04599v1
Object-Centric Task and Motion Planning in Dynamic Environments,2019-11-12T05:28:03Z,"Toki Migimatsu, Jeannette Bohg","We address the problem of applying Task and Motion Planning (TAMP) in real
world environments. TAMP combines symbolic and geometric reasoning to produce
sequential manipulation plans, typically specified as joint-space trajectories,
which are valid only as long as the environment is static and perception and
control are highly accurate. In case of any changes in the environment, slow
re-planning is required. We propose a TAMP algorithm that optimizes over
Cartesian frames defined relative to target objects. The resulting plan then
remains valid even if the objects are moving and can be executed by reactive
controllers that adapt to these changes in real time. We apply our TAMP
framework to a torque-controlled robot in a pick and place setting and
demonstrate its ability to adapt to changing environments, inaccurate
perception, and imprecise control, both in simulation and the real world.",http://arxiv.org/abs/1911.04679v3
"Dipole oscillations of fermionic superfluids along the BEC-BCS crossover
  in disordered potentials",2019-11-13T17:16:51Z,"Benjamin Nagler, Kevin Jägering, Ameneh Sheikhan, Sian Barbosa, Jennifer Koch, Sebastian Eggert, Imke Schneider, Artur Widera","We investigate dipole oscillations of ultracold Fermi gases along the BEC-BCS
crossover through disordered potentials. We observe a disorder-induced damping
of oscillations as well as a change of the fundamental Kohn-mode frequency. The
measurement results are compared to numerical density matrix renormalization
group calculations as well as to a three-dimensional simulation of
non-interacting fermions. Experimentally, we find a disorder-dependent damping,
which grows approximately with the second power of the disorder strength.
Moreover, we observe experimentally a change of oscillation frequency which
deviates from the expected behavior of a damped harmonic oscillator on a
percent level. While this behavior is qualitatively expected from the
theoretical models used, quantitatively the experimental observations show a
significantly stronger effect than predicted by theory. Furthermore, while the
frequency shift seems to scale differently with interaction strength in the BEC
versus BCS regime, the damping coefficient apparently decreases with the
strength of interaction, but not with the sign, which changes for BEC and BCS
type Fermi gases. This is surprising, as the dominant damping mechanisms are
expected to be different in the two regimes.",http://arxiv.org/abs/1911.05638v1
Attosecond timing of electron emission from a molecular shape resonance,2019-11-19T09:54:02Z,"S. Nandi, E. Plésiat, S. Zhong, A. Palacios, D. Busto, M. Isinger, L. Neoričić, C. L. Arnold, R. J. Squibb, R. Feifel, P. Decleva, A. L'Huillier, F. Martín, M. Gisselbrecht","Shape resonances in physics and chemistry arise from the spatial confinement
of a particle by a potential barrier. In molecular photoionization, these
barriers prevent the electron from escaping instantaneously, so that nuclei may
move and modify the potential, thereby affecting the ionization process. By
using an attosecond two-color interferometric approach in combination with high
spectral resolution, we have captured the changes induced by the nuclear motion
on the centrifugal barrier that sustains the well-known shape resonance in
valence-ionized N$_2$. We show that despite the nuclear motion altering the
bond length by only $2\%$, which leads to tiny changes in the potential
barrier, the corresponding change in the ionization time can be as large as
$200$ attoseconds. This result poses limits to the concept of instantaneous
electronic transitions in molecules, which is at the basis of the Franck-Condon
principle of molecular spectroscopy.",http://arxiv.org/abs/1911.08181v2
"High dimensional entanglement between a photon and a multiplexed atomic
  quantum memory",2019-11-25T07:47:41Z,"Chang Li, Yukai Wu, Wei Chang, Sheng Zhang, Yunfei Pu, Nan Jiang, Luming Duan","Multiplexed quantum memories and high-dimensional entanglement can improve
the performance of quantum repeaters by promoting the entanglement generation
rate and the quantum communication channel capacity. Here, we experimentally
generate a high-dimensional entangled state between a photon and a collective
spin wave excitation stored in the multiplexed atomic quantum memory. We verify
the entanglement dimension by the quantum witness and the entanglement of
formation. Then we use the high-dimensional entangled state to test the
violation of the Bell-type inequality. Our work provides an effective method to
generate multidimensional entanglement between the flying photonic pulses and
the atomic quantum interface.",http://arxiv.org/abs/1911.10746v1
"Hybrid phase-change lattice Boltzmann simulation of the bubble
  nucleation and different boiling regimes of conjugate boiling heat transfer",2019-11-25T07:48:05Z,"Wandong Zhao, Jianhan Liang, Mingbo Sun, Xiaodong Cai, Peibo Li","Pool boiling characteristics in two computational domains with and without
considering conjugate heat transfer (CHT) were numerically simulated by an
improved hybrid pseudopotential phase-change lattice Boltzmann method (LBM).
The effects of constant temperature boundary condition (BC) with nucleate spots
and fluctuant temperature on the boiling process were investigated in detail.
It was found that for the computational domain without CHT, the treatment of
constant temperature BC with nucleate spots is quite easier to produce film
boiling than the temperature BC with small fluctuation. However, the results
would be the opposite for the case with CHT. The entire boiling curve from the
onset of nucleate boiling to fully developed film boiling was presented using
the computational domain considering CHT and constant temperature BC with
nucleate spots. The simulated critical heat flux showed an excellent agreement
with the existing analytical solutions. Hence, the current hybrid phase-change
LBM was quantitatively verified. The highly fluctuant heat flux occurred in the
CHF and transition boiling as well as the transverse movement of the bubbles
had been observed. Furthermore, the thermal responses inside the heater and
heat transfer mechanism in different boiling patterns were also comprehensively
studied.",http://arxiv.org/abs/1911.10747v1
"Characterization of Age-related Microstructural Changes in Locus
  Coeruleus and Substantia Nigra Pars Compacta",2019-11-26T04:34:50Z,"Jason Langley, Sana Hussain, Justino J. Flores, Ilana J. Bennett, Xiaoping Hu","Locus coeruleus (LC) and substantia nigra pars compacta (SNpc) degrade with
normal aging, but not much is known regarding how these changes manifest in MRI
images, or whether these markers predict aspects of cognition. Here, we use
high-resolution diffusion-weighted MRI to investigate microstructural and
compositional changes in LC and SNpc in young and aged cohorts, as well as
their relationship with cognition. In LC, the older cohort exhibited a
significant reduction in mean and radial diffusivity, but a significant
increase in fractional anisotropy compared to the young cohort. We observed a
significant correlation between the decrease in LC mean and radial
diffusivities with delayed recall. This observation suggests that LC is
involved in retaining cognitive abilities. In addition, we observed that iron
deposition in SNpc occurs early in life and continues during normal aging.
Since neuronal loss occurs in both LC and SNpc in Parkinson's disease, but
occurs only in the LC in Alzheimer's disease, our results may lead to early
stage imaging biomarkers for these diseases.",http://arxiv.org/abs/1911.11336v1
"Adversarial Deep Reinforcement Learning based Adaptive Moving Target
  Defense",2019-11-27T06:13:20Z,"Taha Eghtesad, Yevgeniy Vorobeychik, Aron Laszka","Moving target defense (MTD) is a proactive defense approach that aims to
thwart attacks by continuously changing the attack surface of a system (e.g.,
changing host or network configurations), thereby increasing the adversary's
uncertainty and attack cost. To maximize the impact of MTD, a defender must
strategically choose when and what changes to make, taking into account both
the characteristics of its system as well as the adversary's observed
activities. Finding an optimal strategy for MTD presents a significant
challenge, especially when facing a resourceful and determined adversary who
may respond to the defender's actions. In this paper, we propose a multi-agent
partially-observable Markov Decision Process model of MTD and formulate a
two-player general-sum game between the adversary and the defender. Based on an
established model of adaptive MTD, we propose a multi-agent reinforcement
learning framework based on the double oracle algorithm to solve the game. In
the experiments, we show the effectiveness of our framework in finding optimal
policies.",http://arxiv.org/abs/1911.11972v2
"PhIT-Net: Photo-consistent Image Transform for Robust Illumination
  Invariant Matching",2019-11-28T10:55:55Z,"Damian Kaliroff, Guy Gilboa","We propose a new and completely data-driven approach for generating a
photo-consistent image transform. We show that simple classical algorithms
which operate in the transform domain become extremely resilient to
illumination changes. This considerably improves matching accuracy,
outperforming the use of state-of-the-art invariant representations as well as
new matching methods based on deep features. The transform is obtained by
training a neural network with a specialized triplet loss, designed to
emphasize actual scene changes while attenuating illumination changes. The
transform yields an illumination invariant representation, structured as an
image map, which is highly flexible and can be easily used for various tasks.",http://arxiv.org/abs/1911.12641v4
"Non-Commutative space: boon or bane for quantum engines and
  refrigerators",2019-11-28T16:02:28Z,Pritam Chattopadhyay,"Various quantum systems are considered as the working substance for the
analysis of quantum heat cycles and quantum refrigerators. The ongoing
technological challenge is how efficiently can a heat engine convert thermal
energy to mechanical work. The seminal work of Carnot has proposed a
fundamental upper limit-the Carnot limit on the efficiency of the heat engine.
However, the heat engines can be operated beyond the fundamental upper limit by
exploiting non-equilibrium reservoirs. Here, the change in the space structure
introduces the non-equilibrium effect. So, a question arises whether a change
in the space structure can provide any boost for the quantum engines and
refrigerators. The efficiency of the heat cycle and the coefficient of
performance (COP) of the refrigerator cycles in the non-commutative space are
analyzed here. The efficiency of the quantum heat engines gets a boost with the
change in the space structure than the traditional quantum heat engine but the
effectiveness of the non-commutative parameter is less for the efficiency
compared to the COP of the refrigerator. There is a steep boost for the
coefficient of performance of the refrigerator cycles for the non-commutative
space harmonic oscillator compared to the harmonic oscillator.",http://arxiv.org/abs/1911.12766v2
"Improving Dynamic Range of Speckle Correlation based Optical Lever by
  spatial multiplexing",2019-08-30T13:30:20Z,"Vijayakumar Anand, Shanti Bhattacharya, Joseph Rosen","Speckle correlation based optical levers SC OptLev possess attractive
characteristics suitable for sensing small changes in the angular orientations
of surfaces. In this study, we propose and demonstrate a spatial multiplexing
technique for improving the dynamic range of SC OptLev. When the surface is in
its initial position, a synthetic speckle intensity pattern, larger than the
area of the image sensor is created by transversely shifting the image sensor
and recording different sections of a larger speckle pattern. Then, the
acquired images are stitched together by a computer program into one relatively
large synthetic speckle pattern. Following the calibration stage, the synthetic
speckle intensity pattern is used to sense changes in the surfaces angular
orientation. The surface is monitored in realtime by recording part of the
speckle pattern which lies within the sensor area. Next, the recorded speckle
pattern is a cross correlated with the synthetic speckle pattern in the
computer. The resulting shift of the correlation peak indicates the angular
orientations of the reflective surface under test. This spatial multiplexing
technique enables sensing changes in the angular orientation of the surface
beyond the limit imposed by the physical size of the image sensor.",http://arxiv.org/abs/1909.02095v1
Quantum Communication between Multiplexed Atomic Quantum Memories,2019-09-05T02:20:16Z,"Chang Li, Nan Jiang, Yukai Wu, Wei Chang, Yunfei Pu, Sheng Zhang, Luming Duan","The use of multiplexed atomic quantum memories (MAQM) can significantly
enhance the efficiency to establish entanglement in a quantum network. In the
previous experiments, individual elements of a quantum network, such as the
generation, storage and transmission of quantum entanglement have been
demonstrated separately. Here we report an experiment to show the compatibility
of these basic operations. Specifically, we generate photon-atom entanglement
in a $6\times 5$ MAQM, convert the spin wave to time-bin photonic excitation
after a controllable storage time, and then store and retrieve the photon in a
second MAQM for another controllable storage time. The preservation of quantum
information in this process is verified by measuring the state fidelity. We
also show that our scheme supports quantum systems with higher dimension than a
qubit.",http://arxiv.org/abs/1909.02185v2
Photo-Motile Structures,2019-09-05T21:42:27Z,"Kevin Korner, Basile Audoly, Kaushik Bhattacharya","Actuation remains a signifcant challenge in soft robotics. Actuation by light
has important advantages: objects can be actuated from a distance, distinct
frequencies can be used to actuate and control distinct modes with minimal
interference and signifcant power can be transmitted over long distances
through corrosion-free, lightweight fiber optic cables. Photo-chemical
processes that directly convert photons to configurational changes are
particularly attractive for actuation. Various researchers have demonstrated
light-induced actuation with liquid crystal elastomers combined with azobenzene
photochromes. We present a simple modeling framework and a series of examples
that studies actuation by light. Of particular interest is the generation of
cyclic or periodic motion under steady illumination. We show that this emerges
as a result of a coupling between light absorption and deformation. As the
structure absorbs light and deforms, the conditions of illumination change, and
this in turn changes the nature of further deformation. This coupling can be
exploited in either closed structures or with structural instabilities to
generate cyclic motion.",http://arxiv.org/abs/1909.02643v1
"Walking for short distances and turning in lower-limb amputees: a study
  in low-cost prosthesis users",2019-09-06T22:25:46Z,"Nidhi Seethapathi, Anil Kumar Jain, Manoj Srinivasan","Preferred walking speed is a widely-used performance measure for people with
mobility issues, but is usually measured in straight line walking for fixed
distances or durations. However, daily walking involves walking for bouts of
different distances and walking with turning. Here, we studied walking for
short distances and walking in circles in unilateral lower-limb amputees
wearing an above or below-knee passive prosthesis, specifically, a Jaipur foot
prosthesis. Analogous to earlier results in non-amputees, we found that their
preferred walking speeds are lower for short distances and lower for circles of
smaller radii. Using inverse optimization, we estimated the cost of changing
speeds and turning such that the observed preferred walking speeds in our
experiments minimizes the total energy cost. The inferred costs of changing
speeds and turning were much larger than for non-amputees. These findings could
inform prosthesis design and rehabilitation therapy to better assist changing
speeds and turning tasks in amputee walking. Further, measuring the preferred
speed for a range of distances and radii is a more robust subject-specific
measure of walking performance.",http://arxiv.org/abs/1909.03139v3
Measuring global mean sea level changes with surface drifting buoys,2019-09-07T13:57:15Z,Shane Elipot,"Combining ocean model data and in-situ Lagrangian data, I show that an array
of surface drifting buoys tracked by a Global Navigation Satellite System
(GNSS), such as the Global Drifter Program, could provide estimates of global
mean sea level (GMSL) and its changes, including linear decadal trends. For a
sustained array of 1250 globally distributed buoys with a standardized design,
I demonstrate that GMSL decadal linear trend estimates with an uncertainty less
than 0.3 mm yr$^{-1}$ could be achieved with GNSS daily random error of 1.6 m
or less in the vertical direction. This demonstration assumes that controlled
vertical position measurements could be acquired from drifting buoys, which is
yet to be demonstrated. Development and implementation of such measurements
could ultimately provide an independent and resilient observational system to
infer natural and anthropogenic sea level changes, augmenting the on-going tide
gauge and satellites records.",http://arxiv.org/abs/1909.03269v2
High-density electron doping of SmNiO$_3$ from first principles,2019-09-08T10:44:21Z,"Michele Kotiuga, Karin M. Rabe","Recent experimental work has realized a new insulating state of samarium
nickelate (SmNiO$_3$), accessible in a reversible manner via high-density
electron doping. To elucidate this behavior, we use the first-principles
density functional theory (DFT) + U method to study the effect of added
electrons on the crystal and electronic structure of SmNiO$_3$. First, we track
the changes in the crystal and electronic structure with added electrons
compensated by a uniform positive background charge at concentrations of
$\frac{1}{4}$, $\frac{1}{2}$, $\frac{3}{4}$, and 1 electrons per Ni. The change
in electron concentration does not rigidly shift the Fermi energy; rather, the
added electrons localize on NiO$_6$ octahedra causing an on-site Mott
transition and a change in the density of states resulting in a large gap
between the occupied and unoccupied Ni $e_g$ orbitals at full doping. This
evolution of the density of states is essentially unchanged when the added
electrons are introduced by doping with interstitial H or Li ions.",http://arxiv.org/abs/1909.03425v2
"Dispersion Interaction between Two Hydrogen Atoms in a Static Electric
  Field",2019-09-08T17:31:19Z,"G. Fiscelli, L. Rizzuto, R. Passante","We consider the dispersion interaction between two ground-state hydrogen
atoms, interacting with the quantum electromagnetic field in the vacuum state,
in the presence of an external static electric field, both in the nonretarded
and in the retarded Casimir-Polder regime. We show that the presence of the
external field strongly modifies the dispersion interaction between the atoms,
changing its space dependence. Moreover, we find that, for specific geometrical
configurations of the two atoms with respect to the external field and/or the
relative orientation of the fields acting on the two atoms, it is possible to
change the character of the dispersion force, turning it from attractive to
repulsive, or even make it vanishing. This new finding clearly shows the
possibility to control and tailor interatomic dispersion interactions through
external actions. By a numerical estimate of the field-modified interaction, we
show that at typical interatomic distances the change of the interaction's
strength can match or even outmatch the unperturbed interaction; this can be
obtained for values of the external field that can be currently achieved in the
laboratory, and sufficiently weak to be taken into account perturbatively.",http://arxiv.org/abs/1909.03517v2
Electrical Control of Large Rashba Effect in Oxide Heterostructures,2019-09-09T09:46:34Z,"Yan Song, Dong Zhang, Ben Xu, Kai Chang, Ce-Wen Nan","Large Rashba effect efficiently tuned by an external electric field is highly
desired for spintronic devices. Using first-principles calculations, we
demonstrate that large Rashba splitting is locked at conduction band minimum in
ferroelectric Bi(Sc/Y/La/Al/Ga/In)O3/PbTiO3 heterostructures where the position
of Fermi level is precisely controlled via its stoichiometry. Fully reversible
Rashba spin texture and drastic change of Rashba splitting strength with
ferroelectric polarization switching are realized in the symmetric and
asymmetric heterostructures, respectively. By artificially tuning the local
ferroelectric displacement and the orbital hybridization, the synergetic effect
of local potential gradient and orbital overlap on the dramatic change of
splitting strength is confirmed. These results improve the feasibility of
utilizing Rashba spin-orbit coupling in spintronic devices.",http://arxiv.org/abs/1909.03727v1
"Existence and multiplicity for an elliptic problem with critical growth
  in the gradient and sign-changing coefficients",2019-09-11T10:31:08Z,"Colette De Coster, Antonio J. Fernández","Let $\Omega \subset \mathbb{R}^N$, $N \geq 2$, be a smooth bounded domain. We
consider the boundary value problem \begin{equation}
\label{Plambda-Abstract-ch3} \tag{$P_{\lambda}$} -\Delta u = c_{\lambda}(x) u +
\mu |\nabla u|^2 + h(x)\,, \quad u \in H_0^1(\Omega) \cap L^{\infty}(\Omega)\,,
\end{equation} where $c_{\lambda}$ and $h$ belong to $L^q(\Omega)$ for some $q
> N/2$, $\mu$ belongs to $\mathbb{R} \setminus \{0\}$ and we write
$c_{\lambda}$ under the form $c_{\lambda}:= \lambda c_{+} - c_{-}$ with $c_{+}
\gneqq 0$, $c_{-} \geq 0$, $c_{+} c_{-} \equiv 0$ and $\lambda \in \mathbb{R}$.
Here $c_{\lambda}$ and $h$ are both allowed to change sign. As a first main
result we give a necessary and sufficient condition which guarantees the
existence of a unique solution to \eqref{Plambda-Abstract-ch3} when $\lambda
\leq 0$. Then, assuming that $(P_0)$ has a solution, we prove existence and
multiplicity results for $\lambda > 0$. Our proofs rely on a suitable change of
variable of type $v = F(u)$ and the combination of variational methods with
lower and upper solution techniques.",http://arxiv.org/abs/1909.04962v1
Feedback Learning for Improving the Robustness of Neural Networks,2019-09-12T03:50:28Z,"Chang Song, Zuoguan Wang, Hai Li","Recent research studies revealed that neural networks are vulnerable to
adversarial attacks. State-of-the-art defensive techniques add various
adversarial examples in training to improve models' adversarial robustness.
However, these methods are not universal and can't defend unknown or
non-adversarial evasion attacks. In this paper, we analyze the model robustness
in the decision space. A feedback learning method is then proposed, to
understand how well a model learns and to facilitate the retraining process of
remedying the defects. The evaluations according to a set of distance-based
criteria show that our method can significantly improve models' accuracy and
robustness against different types of evasion attacks. Moreover, we observe the
existence of inter-class inequality and propose to compensate it by changing
the proportions of examples generated in different classes.",http://arxiv.org/abs/1909.05443v1
"Cooperation-Aware Lane Change Maneuver in Dense Traffic based on Model
  Predictive Control with Recurrent Neural Network",2019-09-09T18:01:36Z,"Sangjae Bae, Dhruv Saxena, Alireza Nakhaei, Chiho Choi, Kikuo Fujimura, Scott Moura","This paper presents a real-time lane change control framework of autonomous
driving in dense traffic, which exploits cooperative behaviors of other
drivers. This paper focuses on heavy traffic where vehicles cannot change lanes
without cooperating with other drivers. In this case, classical robust controls
may not apply since there is no safe area to merge to without interacting with
the other drivers. That said, modeling complex and interactive human behaviors
is highly non-trivial from the perspective of control engineers. We propose a
mathematical control framework based on Model Predictive Control (MPC)
encompassing a state-of-the-art Recurrent Neural network (RNN) architecture. In
particular, RNN predicts interactive motions of other drivers in response to
potential actions of the autonomous vehicle, which are then systematically
evaluated in safety constraints. We also propose a real-time heuristic
algorithm to find locally optimal control inputs. Finally, quantitative and
qualitative analysis on simulation studies are presented to illustrate the
benefits of the proposed framework.",http://arxiv.org/abs/1909.05665v2
"Temperature and field evolution of site-dependent magnetism in
  $ε$-Fe$_2$O$_3$ nanoparticles",2019-09-12T15:47:19Z,"Richard Jones, Rachel Nickel, Palash K. Manna, J. Hilman, Johan van Lierop","8~nm epsilon-Fe2O3 nanoparticles exhibit a spin reorientation transition that
begins at 150 K which is a hallmark of this unique iron-oxide polymorph. We
find that the change from the high to low temperature magnetic structures has
been suppressed by ~50 K. At the spin reorientation temperature, a change of
the field-dependent response of the tetrahedral sites in intermediate field
strengths (0.25 - 1.5 T) indicates that a collective tetrahedral distortion
occurs to which the octahedral sites adjust, altering the magnetic anisotropy.
An abrupt step in the hyperfine parameters' temperature dependencies,
especially at 125 K for the hyperfine field associated with the Fe4 tetrahedral
sites, suggests strongly a change in the superexchange pathways are responsible
for the spin reorientation.",http://arxiv.org/abs/1909.05763v1
"Confidence Tubes for Curves on SO(3) and Identification of
  Subject-Specific Gait Change after Kneeling",2019-09-14T11:47:33Z,"Fabian J. E. Telschow, Michael R. Pierrynowski, Stephan F. Huckemann","In order to identify changes of gait patterns, e.g. due to prolonged
occupational kneeling, which is believed to be major risk factor, among others,
for the development of knee osteoarthritis, we develop confidence tubes for
curves following a Gaussian perturbation model on SO(3). These are based on an
application of the Gaussian kinematic formula to a process of Hotelling
statistics and we approximate them by a computible version, for which we show
convergence. Simulations endorse our method, which in application to gait
curves from eight volunteers undergoing kneeling tasks, identifies phases of
the gait cycle that have changed due to kneeling tasks. We find that after
kneeling, deviation from normal gait is stronger, in particular for older aged
male volunteers. Notably our method adjusts for different walking speeds and
marker replacement at different visits.",http://arxiv.org/abs/1909.06583v1
"OpenMPR: Recognize Places Using Multimodal Data for People with Visual
  Impairments",2019-09-15T12:58:53Z,"Ruiqi Cheng, Kaiwei Wang, Jian Bai, Zhijie Xu","Place recognition plays a crucial role in navigational assistance, and is
also a challenging issue of assistive technology. The place recognition is
prone to erroneous localization owing to various changes between database and
query images. Aiming at the wearable assistive device for visually impaired
people, we propose an open-sourced place recognition algorithm OpenMPR, which
utilizes the multimodal data to address the challenging issues of place
recognition. Compared with conventional place recognition, the proposed OpenMPR
not only leverages multiple effective descriptors, but also assigns different
weights to those descriptors in image matching. Incorporating GNSS data into
the algorithm, the cone-based sequence searching is used for robust place
recognition. The experiments illustrate that the proposed algorithm manages to
solve the place recognition issue in the real-world scenarios and surpass the
state-of-the-art algorithms in terms of assistive navigation performance. On
the real-world testing dataset, the online OpenMPR achieves 88.7% precision at
100% recall without illumination changes, and achieves 57.8% precision at 99.3%
recall with illumination changes. The OpenMPR is available at
https://github.com/chengricky/OpenMultiPR.",http://arxiv.org/abs/1909.06795v1
Various Characterizations of Throttling Numbers,2019-09-17T17:37:37Z,"Joshua Carlson, Juergen Kritschgau","Zero forcing can be described as a combinatorial game on a graph that uses a
color change rule in which vertices change white vertices to blue. The
throttling number of a graph minimizes the sum of the number of vertices
initially colored blue and the number of time steps required to color the
entire graph. Positive semidefinite (PSD) zero forcing is a commonly studied
variant of standard zero forcing that alters the color change rule. This paper
introduces a method for extending a graph using a PSD zero forcing process.
Using this extension method, graphs with PSD throttling number at most $t$ are
characterized as specific minors of the Cartesian product of complete graphs
and trees. A similar characterization is obtained for the minor monotone floor
of PSD zero forcing. Finally, the set of connected graphs on $n$ vertices with
throttling number at least $n-k$ is characterized by forbidding a finite family
of induced subgraphs. These forbidden subgraphs are constructed for standard
throttling.",http://arxiv.org/abs/1909.07952v3
"Study of interference effects in the search for flavour-changing neutral
  current interactions involving the top quark and a photon or a $Z$ boson at
  the LHC",2019-09-18T13:37:30Z,"Maura Barros, Nuno Filipe Castro, Johannes Erdmann, Gregor Geßner, Kevin Kröninger, Salvatore La Cagnina, Ana Peixoto","Flavour-changing neutral-current interactions of the top quark can be
searched for in top-quark pair production with one top quark decaying to an
up-type quark and a neutral boson, and they can be searched for in the single
production of a top quark in association with such a boson. Both processes
interfere if an additional up-type quark is produced in the case of single
production. The impact of these interference effects on searches for
flavour-changing neutral currents at the LHC is studied for the case where the
neutral boson is a photon or a $Z$ boson. Interference effects are found to be
smaller than variations of the renormalisation and factorisation scales.",http://arxiv.org/abs/1909.08443v2
"Observation of flux qubit states with the help of a superconducting
  differential double contour interferometer",2019-09-13T16:52:54Z,A. V. Nikulov,"The quantum states of flux qubit is suggested to observe with the help of a
new device, the superconducting differential double contour interferometer
(DDCI). The flux qubit and the superconducting quantum interference device
(DC-SQUID) are connected in the DDCI through the phase of the wave function
rather than through magnetic flux. The critical current of DC-SQUID should
change to the maximum value at the change of the flux qubit state thanks to
this phase coupling. A large jump in the critical current and voltage enables
to observe continuously the change in time the state of the flux qubit. This
observation can have fundamental importance for the investigation of the
superposition of macroscopic quantum states.",http://arxiv.org/abs/1909.09460v1
Giant magnetocaloric effect in Co2FeAl Heusler alloy nanoparticles,2019-09-23T07:58:42Z,"Aquil Ahmad, Srimanta Mitra, S. K. Srivastava, A. K. Das","A giant magnetocaloric effect across the ferromagnetic (FM) to paramagnetic
(PM) phase transition was observed in chemically synthesized Co2FeAl Heusler
alloy nanoparticles with a mean diameter of 16 nm. In our previous report, we
have observed a significant enhancement in its saturation magnetization (Ms)
and Curie temperature (Tc) as compared with the bulk counterpart. Motivated
from those results, here, we aim to explore its magnetocaloric properties near
the Tc. The magnetic entropy change shows a positive anomaly at 1252 K.
Magnetic entropy change increases linearly with the magnetic field, and a large
value of ~15 J/Kg-K is detected under a moderate field of 14 kOe. It leads to a
net relative cooling power of 89 J/Kg for the magnetic field change of 14 kOe.
To confirm the nature of magnetic phase transition, a detailed study of its
magnetization is performed. The Arrott plot and nature of the universal curve
conclude that FM to PM phase transition in the present system is of
second-order.",http://arxiv.org/abs/1909.10201v4
"Comparison of structure making/breaking properties of alkali metal ions
  Na+, K+ and Cs+ in water",2019-09-23T10:15:06Z,"Sudakshina Roy, Barnana Pal","The alkali metal ions in aqueous electrolyte solutions have strong influence
on the surrounding network structure of water formed through hydrogen bonds.
The extent of ionic perturbation to the structure of water depends on the
nature of individual ions and the solute concentration. Experimental techniques
like Neutron diffraction, X-ray diffraction, Raman spectroscopy, isotopic
substitution study, viscosity measurements and related theoretical or
simulation studies are used to understand the characteristics features of the
structural changes in these solutions. Recent ultrasonic studies on aqueous
solutions of NaCl, KCl and CsCl show anomalous changes in the variation of
velocity (v) with increase in concentration (c) from very dilute to saturation
limit. The experimental observations and theoretical or simulation studies
available in the literature are considered to make a comparative study on the
structure making/breaking properties of Na+, K+ and Cs+ ions in water and
consequent effect in ultrasonic velocity change.",http://arxiv.org/abs/1909.10262v1
Alternative route towards the change of metric signature,2019-09-24T01:04:40Z,Fan Zhang,"Beginning with Hartle and Hawking's no-boundary proposal, it has long been
known that the pathology of a big bang singularity can be suppressed if a
transition into Riemannian (Euclidean) metric signature (the usual singularity
theorems become invalid in this region) occurs when we track back along cosmic
time. A vital component of this type of models, that needs to be clarified, is
the set of junction conditions at the boundary between the two signature
regimes. In the traditional approach, the signature change occurs in the
temporal sector through a switch of sign in the lapse-squared function.
Motivated by more straightforward connections with the big bang cosmology, we
explore here an alternative whereby the spatial metric eigenvalues change sign
instead, so that the Riemannian side is purely timelike. We investigate the
junction conditions required in this case.",http://arxiv.org/abs/1909.10669v1
"Limiting absorption principle and well-posedness for the time-harmonic
  Maxwell equations with anisotropic sign-changing coefficients",2019-09-24T08:04:12Z,"Hoai Minh Nguyen, Swarnendu Sil","We study the limiting absorption principle and the well-posedness of Maxwell
equations with anisotropic sign-changing coefficients in the time-harmonic
domain. The starting point of the analysis is to obtain Cauchy problems
associated with two Maxwell systems using a change of variables. We then derive
a priori estimates for these Cauchy problems using two different approaches.
The Fourier approach involves the complementing conditions for the Cauchy
problems associated with two elliptic equations, which were studied in a
general setting by Agmon, Douglis, and Nirenberg. The variational approach
explores the variational structure of the Cauchy problems of the Maxwell
equations. As a result, we obtain general conditions on the coefficients for
which the limiting absorption principle and the well-posedness hold. Moreover,
these {\it new} conditions are of a local character and easy to check. Our work
is motivated by and provides general sufficient criteria for the stability of
electromagnetic fields in the context of negative-index metamaterials.",http://arxiv.org/abs/1909.10752v1
Josephson junctions of Weyl and multi-Weyl semimetals,2019-09-26T18:00:08Z,"Kirill Kulikov, Debabrata Sinha, Yu. M. Shukrinov, K. Sengupta","We study a Josephson junction involving a Weyl and a multi-Weyl semimetal
separated by a barrier region of width $d$ created by putting a gate voltage
$U_0$ over the Weyl semimetal. The topological winding number of such a
junction changes across the barrier. We show that $I_c R_N$ for such junctions,
where $I_c$ is the critical current and $R_N$ the normal state resistance, in
the thin barrier limit, has a universal value independent of the barrier
potential. We provide an analytical expression of the Andreev bound states and
use it to demonstrate that the universal value of $I_c R_N$ is a consequence of
change in topological winding number across the junction. We also study AC
Josephson effect in such a junction in the presence of an external microwave
radiation, chart out its current-voltage characteristics, and show that the
change in the winding number across the junction shapes the properties of its
Shapiro steps. We discuss the effect of increasing barrier thickness $d$ on the
above-mentioned properties and chart out experiments which may test our theory.",http://arxiv.org/abs/1909.12308v2
Rethinking Text Attribute Transfer: A Lexical Analysis,2019-09-26T18:59:53Z,"Yao Fu, Hao Zhou, Jiaze Chen, Lei Li","Text attribute transfer is modifying certain linguistic attributes (e.g.
sentiment, style, authorship, etc.) of a sentence and transforming them from
one type to another. In this paper, we aim to analyze and interpret what is
changed during the transfer process. We start from the observation that in many
existing models and datasets, certain words within a sentence play important
roles in determining the sentence attribute class. These words are referred to
as \textit{the Pivot Words}. Based on these pivot words, we propose a lexical
analysis framework, \textit{the Pivot Analysis}, to quantitatively analyze the
effects of these words in text attribute classification and transfer. We apply
this framework to existing datasets and models and show that: (1) the pivot
words are strong features for the classification of sentence attributes; (2) to
change the attribute of a sentence, many datasets only requires to change
certain pivot words; (3) consequently, many transfer models only perform the
lexical-level modification, while leaving higher-level sentence structures
unchanged. Our work provides an in-depth understanding of linguistic attribute
transfer and further identifies the future requirements and challenges of this
task\footnote{Our code can be found at
https://github.com/FranxYao/pivot_analysis}.",http://arxiv.org/abs/1909.12335v1
"Photoionization model for streamer propagation mode change in simulation
  model for streamers in dielectric liquids",2019-09-27T14:04:14Z,"I Madshaven, OL Hestad, M Unge, O Hjortstam, PO Åstrand","Radiation is important for the propagation of streamers in dielectric
liquids. Photoionization is a possibility, but the effect is difficult to
differentiate from other contributions. In this work, we model radiation from
the streamer head, causing photoionization when absorbed in the liquid. We find
that photoionization is local in space ({\mu}m-scale). The radiation absorption
cross section is modeled considering that the ionization potential (IP) is
dependent on the electric field. The result is a steep increase in the
ionization rate when the electric field reduces the IP below the energy of the
first electronically excited state, which is interpreted as a possible
mechanism for changing from slow to fast streamers. By combining a simulation
model for slow streamers based on the avalanche mechanism with a change to fast
mode based on a photoionization threshold for the electric field, we
demonstrate how the conductivity of the streamer channel can be important for
switching between slow and fast streamer propagation modes.",http://arxiv.org/abs/1909.12694v2
"Long-Term Robot Navigation in Indoor Environments Estimating Patterns in
  Traversability Changes",2019-09-27T15:08:01Z,"Lorenzo Nardi, Cyrill Stachniss","Nowadays, mobile robots are deployed in many indoor environments, such as
offices or hospitals. These environments are subject to changes in the
traversability that often happen by following repeating patterns. In this
paper, we investigate the problem of navigating in such environments over
extended periods of time by capturing these patterns and exploiting this
knowledge to make informed decisions. Our approach incrementally estimates a
model of the traversability changes from robot's observations and uses a
probabilistic graphical model to make predictions at currently unobserved
locations. In the belief space defined by the predictions, we plan paths that
trade off the risk to encounter obstacles and the information gain of visiting
unknown locations. We implemented our approach and tested it in different
indoor environments. The experiments suggest that in the long run, our approach
leads to navigation along shorter paths compared to following a greedy shortest
path policy.",http://arxiv.org/abs/1909.12733v1
"Likelihood-based approach to discriminate mixtures of network models
  that vary in time",2019-09-29T10:47:04Z,"Naomi A. Arnold, Raul J. Mondragon, Richard G. Clegg","Discriminating between competing explanatory models as to which is more
likely responsible for the growth of a network is a problem of fundamental
importance for network science. The rules governing this growth are attributed
to mechanisms such as preferential attachment and triangle closure, with a
wealth of explanatory models based on these. These models are deliberately
simple, commonly with the network growing according to a constant mechanism for
its lifetime, to allow for analytical results. We use a likelihood-based
framework on artificial data where the network model changes at a known point
in time and demonstrate that we can recover the change point from analysis of
the network. We then use real datasets and demonstrate how our framework can
show the changing importance of network growth mechanisms over time.",http://arxiv.org/abs/1909.13253v2
"ProtRank: Bypassing the imputation of missing values in differential
  expression analysis of proteomic data",2019-09-30T13:05:31Z,"Matus Medo, Daniel M. Aebersold, Michaela Medova","Data from discovery proteomic and phosphoproteomic experiments typically
include missing values that correspond to proteins that have not been
identified in the analyzed sample. Replacing the missing values with random
numbers, a process known as ""imputation"", avoids apparent infinite fold-change
values. However, the procedure comes at a cost: Imputing a large number of
missing values has the potential to significantly impact the results of the
subsequent differential expression analysis. We propose a method that
identifies differentially expressed proteins by ranking their observed changes
with respect to the changes observed for other proteins. Missing values are
taken into account by this method directly, without the need to impute them. We
illustrate the performance of the new method on two distinct datasets and show
that it is robust to missing values and, at the same time, provides results
that are otherwise similar to those obtained with edgeR which is a state-of-art
differential expression analysis method. The new method for the differential
expression analysis of proteomic data is available as an easy to use Python
package.",http://arxiv.org/abs/1909.13667v1
Anisotropic magnetic entropy change in Cr$_2$X$_2$Te$_6$ (X = Si and Ge),2019-01-09T18:58:01Z,"Yu Liu, C. Petrovic","Intrinsic, two-dimensional (2D) ferromagnetic semiconductors are an important
class of materials for spintronics applications. Cr$_2$X$_2$Te$_6$ (X = Si and
Ge) semiconductors show 2D Ising-like ferromagnetism, which is preserved in
few-layer devices. The maximum magnetic entropy change associated with the
critical properties around the ferromagnetic transition for Cr$_2$Si$_2$Te$_6$
$-\Delta S_M^{max} \sim$ 5.05 J kg$^{-1}$ K$^{-1}$ is much larger than $-\Delta
S_M^{max} \sim$ 2.64 J kg$^{-1}$ K$^{-1}$ for Cr$_2$Ge$_2$Te$_6$ with an
out-of-plane field change of 5 T. The rescaled $-\Delta S_M(T,H)$ curves
collapse onto a universal curve independent of temperature and field for both
materials. This indicates similar critical behavior and 2D Ising magnetism,
confirming the magnetocrystalline anisotropy that could preserve the long-range
ferromagnetism in few-layers of Cr$_2$X$_2$Te$_6$.",http://arxiv.org/abs/1901.02876v1
"Weak Cosmic Censorship with Pressure and Volume in Charged Anti-de
  Sitter Black Hole under Charged Scalar Field",2019-01-17T02:20:52Z,Bogeun Gwak,"We investigate the weak cosmic censorship conjecture in charged anti-de
Sitter black holes with thermodynamic pressure and volume by the scattering of
the charged scalar field in four and higher dimensions. We assume that the
internal energy and electric charge of the black hole changes infinitesimally
according to the energy and charge fluxes of the scalar field. Then, found to
be an isobaric process, the changes in the black hole can be well reproduced to
the first law of thermodynamics, although we find that the second law of
thermodynamics is violated in extremal and near-extremal black holes.
Nevertheless, the weak cosmic censorship conjecture remains valid, because the
extremality of a black hole is invariant despite changes in internal energy and
electric charge.",http://arxiv.org/abs/1901.05589v1
"Possible pressure-induced topological quantum phase transition in the
  nodal line semimetal ZrSiS",2019-01-21T19:02:06Z,"D. VanGennep, T. A. Paul, C. W. Yerger, S. T. Weir, Y. K. Vohra, J. J. Hamlin","ZrSiS has recently gained attention due to its unusual electronic properties:
nearly perfect electron-hole compensation, large, anisotropic
magneto-resistance, multiple Dirac nodes near the Fermi level, and an extremely
large range of linear dispersion of up to 2 eV. We have carried out a series of
high pressure electrical resistivity measurements on single crystals of ZrSiS.
Shubnikov-de Haas measurements show two distinct oscillation frequencies. For
the smaller orbit, we observe a change in the phase of 0.5, which occurs
between 0.16 - 0.5 GPa. This change in phase is accompanied by an abrupt
decrease of the cross-sectional area of this Fermi surface. We attribute this
change in phase to a possible topological quantum phase transition. The phase
of the larger orbit exhibits a Berry phase of pi and remains roughly constant
up to 2.3 GPa. Resistivity measurements to higher pressures show no evidence
for pressure-induced superconductivity to at least 20 GPa.",http://arxiv.org/abs/1901.07043v1
Spatial Modeling of Trends in Crime over Time in Philadelphia,2019-01-23T20:10:59Z,"Cecilia Balocchi, Shane T. Jensen","Understanding the relationship between change in crime over time and the
geography of urban areas is an important problem for urban planning. Accurate
estimation of changing crime rates throughout a city would aid law enforcement
as well as enable studies of the association between crime and the built
environment. Bayesian modeling is a promising direction since areal data
require principled sharing of information to address spatial autocorrelation
between proximal neighborhoods. We develop several Bayesian approaches to
spatial sharing of information between neighborhoods while modeling trends in
crime counts over time. We apply our methodology to estimate changes in crime
throughout Philadelphia over the 2006-15 period, while also incorporating
spatially-varying economic and demographic predictors. We find that the local
shrinkage imposed by a conditional autoregressive model has substantial
benefits in terms of out-of-sample predictive accuracy of crime. We also
explore the possibility of spatial discontinuities between neighborhoods that
could represent natural barriers or aspects of the built environment.",http://arxiv.org/abs/1901.08117v2
Asynchronous Multi-Sensor Change-Point Detection for Seismic Tremors,2019-01-24T02:03:34Z,"Liyan Xie, Yao Xie, George V. Moustakides","We consider the sequential change-point detection for asynchronous
multi-sensors, where each sensor observe a signal (due to change-point) at
different times. We propose an asynchronous Subspace-CUSUM procedure based on
jointly estimating the unknown signal waveform and the unknown relative delays
between the sensors. Using the estimated delays, we can align signals and use
the subspace to combine the multiple sensor observations. We derive the optimal
drift parameter for the proposed procedure, and characterize the relationship
between the expected detection delay, average run length (of false alarms), and
the energy of the time-varying signal. We demonstrate the good performance of
the proposed procedure using simulation and real data. We also demonstrate that
the proposed procedure outperforms the well-known `one-shot procedure' in
detecting weak and asynchronous signals.",http://arxiv.org/abs/1901.08196v1
"Consistent nonparametric change point detection combining CUSUM and
  marked empirical processes",2019-01-24T16:39:23Z,"Maria Mohr, Natalie Neumeyer","A weakly dependent time series regression model with multivariate covariates
and univariate observations is considered, for which we develop a procedure to
detect whether the nonparametric conditional mean function is stable in time
against change point alternatives. Our proposal is based on a modified CUSUM
type test procedure, which uses a sequential marked empirical process of
residuals. We show weak convergence of the considered process to a centered
Gaussian process under the null hypothesis of no change in the mean function
and a stationarity assumption. This requires some sophisticated arguments for
sequential empirical processes of weakly dependent variables. As a consequence
we obtain convergence of Kolmogorov-Smirnov and Cram\'er-von Mises type test
statistics. The proposed procedure acquires a very simple limiting distribution
and nice consistency properties, features from which related tests are lacking.
We moreover suggest a bootstrap version of the procedure and discuss its
applicability in the case of unstable variances.",http://arxiv.org/abs/1901.08491v1
"Stopping Active Learning based on Predicted Change of F Measure for Text
  Classification",2019-01-26T00:01:27Z,"Michael Altschuler, Michael Bloodgood","During active learning, an effective stopping method allows users to limit
the number of annotations, which is cost effective. In this paper, a new
stopping method called Predicted Change of F Measure will be introduced that
attempts to provide the users an estimate of how much performance of the model
is changing at each iteration. This stopping method can be applied with any
base learner. This method is useful for reducing the data annotation bottleneck
encountered when building text classification systems.",http://arxiv.org/abs/1901.09118v2
"Chern insulator in a ferromagnetic two-dimensional electron system with
  Dresselhaus spin-orbit coupling",2019-01-28T07:33:40Z,"Rui-An Chang, Ching-Ray Chang","We propose a Chern insulator in a two-dimensional electron system with
Dresselhaus spin-orbit coupling, ferromagnetism, and spin-dependent effective
mass. The analytically-obtained topological phase diagrams show the topological
phase transitions induced by tuning the magnetization orientation with the
Chern number varying between $1,0,-1$. The magnetization orientation tuning
shown here is a more practical way of triggering the topological phase
transitions than manipulating the exchange coupling that is no longer tunable
after the fabrication of the system. The analytic results are confirmed by the
band structure and transport calculations, showing the feasibility of this
theoretical proposal. With the advanced and mature semiconductor engineering
today, this Chern insulator is very possible to be experimentally realized and
also promising to topological spintronics.",http://arxiv.org/abs/1901.09536v3
"Change-point detection in a linear model by adaptive fused quantile
  method",2019-01-28T11:25:58Z,"Gabriela Ciuperca, Matus Maciak","A novel approach to quantile estimation in multivariate linear regression
models with change-points is proposed: the change-point detection and the model
estimation are both performed automatically, by adopting either the quantile
fused penalty or the adaptive version of the quantile fused penalty. These two
methods combine the idea of the check function used for the quantile estimation
and the $L_1$ penalization principle known from the signal processing and,
unlike some standard approaches, the presented methods go beyond typical
assumptions usually required for the model errors, such as sub-Gaussian or
Normal distribution. They can effectively handle heavy-tailed random error
distributions, and, in general, they offer a more complex view on the data as
one can obtain any conditional quantile of the target distribution, not just
the conditional mean. The consistency of detection is proved and proper
convergence rates for the parameter estimates are derived. The empirical
performance is investigated via an extensive comparative simulation study and
practical utilization is demonstrated using a real data example.",http://arxiv.org/abs/1901.09607v2
Sensing electrons during an adiabatic coherent transport passage,2019-01-29T00:50:56Z,"Oded Zilberberg, Alessandro Romito","We study the detection of electrons undergoing coherent transfer via
adiabatic passage (CTAP) in a triple quantum-dot system with a quantum
point-contact sensing the change of the middle dot. In the ideal scenario, the
protocol amounts to perfect change transfer between the external dots with
vanishing occupation of the central dot at all times, rendering the measurement
and its backaction moot. Nevertheless, even with minor corrections to the
protocol, a small population builds up in the central dot. We study the
measurement backaction by a Bayesian formalism simulation of an instantaneous
detection at the time of maximal occupancy of the dot. We show that the
interplay between the measurement backaction and the non-adiabatic dynamics
induce a change of the success probability of the protocol, which
quantitatively agrees with a continuous detection treatment. We introduce a
correlated measurement signal to certify the non-occupancy of the central dot
for a successful CTAP protocol, which, in the weak measurement limit, confirms
a vanishing occupation of the central dot. Our proposed correlated-signal
purports that proper experimental method by which to confirm CTAP.",http://arxiv.org/abs/1901.10057v1
Point-Particle Catalysis,2019-04-30T21:03:57Z,"P. Hayman, C. P. Burgess","We use the point-particle effective field theory (PPEFT) framework to
describe particle-conversion mediated by a flavour-changing coupling to a
point-particle. We do this for a toy model of two non-relativistic scalars
coupled to the same point-particle, on which there is a flavour-violating
coupling. It is found that the point-particle couplings all must be
renormalized with respect to a radial cut-off near the origin, and it is an
invariant of the flow of the flavour-changing coupling that is directly related
to particle-changing cross-sections. At the same time, we find an interesting
dependence of those cross-sections on the ratio k_out/k_in of the outgoing and
incoming momenta, which can lead to a 1/k_in enhancement in certain regimes. We
further connect this model to the case of a single-particle non-self-adjoint
(absorptive) PPEFT, as well as to a PPEFT of a single particle coupled to a
two-state nucleus. These results could be relevant for future calculations of
any more complicated reactions, such as nucleus-induced electron-muon
conversions, monopole catalysis of baryon number violation, as well as nuclear
transfer reactions.",http://arxiv.org/abs/1905.00103v1
"Investigating Robustness and Interpretability of Link Prediction via
  Adversarial Modifications",2019-05-02T03:30:17Z,"Pouya Pezeshkpour, Yifan Tian, Sameer Singh","Representing entities and relations in an embedding space is a well-studied
approach for machine learning on relational data. Existing approaches, however,
primarily focus on improving accuracy and overlook other aspects such as
robustness and interpretability. In this paper, we propose adversarial
modifications for link prediction models: identifying the fact to add into or
remove from the knowledge graph that changes the prediction for a target fact
after the model is retrained. Using these single modifications of the graph, we
identify the most influential fact for a predicted link and evaluate the
sensitivity of the model to the addition of fake facts. We introduce an
efficient approach to estimate the effect of such modifications by
approximating the change in the embeddings when the knowledge graph changes. To
avoid the combinatorial search over all possible facts, we train a network to
decode embeddings to their corresponding graph components, allowing the use of
gradient-based optimization to identify the adversarial modification. We use
these techniques to evaluate the robustness of link prediction models (by
measuring sensitivity to additional facts), study interpretability through the
facts most responsible for predictions (by identifying the most influential
neighbors), and detect incorrect facts in the knowledge base.",http://arxiv.org/abs/1905.00563v1
"Controlling Fano resonance using the Geometrical Phase of light in
  spatially tailored waveguided plasmonic crystals",2019-05-05T09:05:53Z,"Subir K. Ray, Ankit K. Singh, Ajmal, Shubham Chandel, Partha Mitra, Nirmalya Ghosh","Fano resonance exhibiting an asymmetric spectral line shape is a universal
phenomenon observed in diverse physical systems. Here we experimentally
establish a direct link between the spectral asymmetry parameter and a
physically realizable phase factor of interference between a continuum and a
discrete mode that leads to Fano resonance. Using a specially designed
metamaterial, namely waveguided plasmonic crystal with a spatially varying
orientation axis of plasmonic grating, we demonstrate control on the spectral
asymmetry of the Fano resonance through changes in the geometric phase of
polarized light. In this scenario, the changes in the geometric phase for input
left, and right circular polarized light arises due to varying orientation
angle of the grating axis. The systematic changes in the geometric phase and
the resulting q-parameter of Fano resonance is interpreted by an appropriate
theoretical model connecting the two physical entities. The demonstrated
control over the spectral line shape of Fano resonance achieved by tailoring
geometric phase may open up novel routes for polarization-based photonic
applications.",http://arxiv.org/abs/1905.01636v1
Dynamic wake modulation induced by utility-scale wind turbine operation,2019-05-07T19:12:17Z,"Aliza Abraham, Jiarong Hong","Understanding wind turbine wake mixing and recovery is critical for improving
the power generation and structural stability of downwind turbines in a wind
farm. In the field, where incoming flow and turbine operation are constantly
changing, wake recovery can be significantly influenced by dynamic wake
modulation, which has not yet been explored. Here we present the first
investigation of dynamic wake modulation in the near wake of a utility-scale
turbine and quantify its relationship with changing conditions. This
investigation is enabled using novel super-large-scale flow visualization with
natural snowfall, providing unprecedented spatiotemporal resolution to resolve
instantaneous changes of the wake envelope. These measurements reveal the
significant influence of dynamic wake modulation on wake recovery. Further, our
study uncovers the direct connection of dynamic wake modulation with
operational parameters readily available to the turbine, paving the way for
more precise wake prediction and control under field conditions for wind farm
optimization.",http://arxiv.org/abs/1905.02775v1
Orbitally defined field-induced electronic state in a Kondo lattice,2019-05-08T01:28:05Z,"G. G. Lesseux, H. Sakai, T. Hattori, Y. Tokunaga, S. Kambe, P. L. Kuhns, A. P. Reyes, J. D. Thompson, P. G. Pagliuso, R. R. Urbano","CeRhIn$_{5}$ is a Kondo-lattice prototype in which a magnetic field
B$\bf{^{\ast}\simeq}$ 30 T induces an abrupt Fermi-surface (FS) reconstruction
and pronounced in-plane electrical transport anisotropy all within its
antiferromagnetic state. Though the antiferromagnetic order at zero field is
well-understood, the origin of an emergent state at B$^{\ast}$ remains unknown
due to challenges inherent to probing states microscopically at high fields.
Here, we report low-temperature Nuclear Magnetic Resonance (NMR) measurements
revealing a discontinuous decrease in the $^{115}$In formal Knight shift,
without changes in crystal or magnetic structures, of CeRhIn$_{5}$ at fields
spanning B$^{\ast}$. We show that the emergent state above B$^{\ast}$ results
from a change in Ce's 4f orbitals that arises from field-induced evolution of
crystal-electric field (CEF) energy levels. This change in orbital character
enhances hybridisation between the 4f and the conduction electrons (c.e.) that
leads ultimately to an itinerant quantum-critical point at B$\bf{_{c0} \simeq}$
50 T.",http://arxiv.org/abs/1905.02861v2
"Miniature Multi-Level Optical Memristive Switch Using Phase Change
  Material",2019-05-08T15:45:39Z,"Hanyu Zhang, Linjie Zhou, Liangjun Lu, Jian Xu, Ningning Wang, Hao Hu, B. M. A. Rahman, Zhiping Zhou, Jianping Chen","The optical memristive switches are electrically activated optical switches
that can memorize the current state. They can be used as optical latching
switches in which the switching state is changed only by applying an electrical
Write/Erase pulse and maintained without external power supply. We demonstrate
an optical memristive switch based on a silicon MMI structure covered with
nanoscale-size Ge2Sb2Te5 (GST) material on top. The phase change of GST is
triggered by resistive heating of the silicon layer beneath GST with an
electrical pulse. Experimental results reveal that the optical transmissivity
can be tuned in a controllable and repeatable manner with the maximum
transmission contrast exceeding 20 dB. Partial crystallization of GST is
obtained by controlling the width and amplitude of the electric pulses.
Crucially, we also demonstrate that both Erase and Write operations, to and
from any intermediate level, are possible with accurate control of the
electrical pulses. Our work marks a significant step forward towards realizing
photonic memristive switches without static power consumption, which are highly
demanded in high-density large-scale integrated photonics.",http://arxiv.org/abs/1905.03163v1
"Helicity-Changing Brillouin Light Scattering by Magnons in a
  Ferromagnetic Crystal",2019-05-10T09:04:47Z,"R. Hisatomi, A. Noguchi, R. Yamazaki, Y. Nakata, A. Gloppe, Y. Nakamura, K. Usami","Brillouin light scattering in ferromagnetic materials usually involves one
magnon and two photons and their total angular momentum is conserved. Here, we
experimentally demonstrate the presence of a helicity-changing two-magnon
Brillouin light scattering in a ferromagetic crystal, which can be viewed as a
four-wave mixing process involving two magnons and two photons. Moreover, we
observe an unconventional helicity-changing one-magnon Brillouin light
scattering, which apparently infringes the conservation law of the angular
momentum. We show that the crystal angular momentum intervenes to compensate
the missing angular momentum in the latter scattering process.",http://arxiv.org/abs/1905.04018v5
Unusual charge exchange by swift heavy ions at solid surfaces,2019-05-10T18:19:21Z,"Tapan Nandi, Prashant Sharma, Pravin Kumar","We have employed x-ray spectroscopy to probe the charge changing process only
in the bulk of the foil when swift heavy ions pass through it. In contrast, the
electromagnetic methods take into account integral effect of the charge
changing process in the bulk as well as the charge exchange phenomenon at the
surface of the foil. Thus, the difference between the mean charge states so
measured from the two methods disentangles the charge exchange phenomenon at
the surface from the charge changing process in the bulk and, provides
opportunities to refine the understanding of ion-surface interactions. Very
surprisingly, up to tens of electrons per event participate in the charge
exchange phenomenon during swift heavy ion-surface interactions. This finding
has been validated with a series of experiments using several ions (z = 22-35)
in the energy range of 1.5-3.0 MeV/u and also verified theoretically with
Fermi-gas model. Interestingly, such unusual charge exchange phenomenon could
play significant role in x-ray emission of many astrophysical environments,
infrared emission bands from range of environments in galaxies, accelerator
physics, ion energy losses in solids, heavy ion cancer treatments, inner shell
ionization by heavy ions, and surface modifications in nano scale.",http://arxiv.org/abs/1905.04328v1
"Graphical Models in Meshed Distribution Grids: Topology estimation,
  change detection and limitations",2019-05-16T06:22:50Z,"Deepjyoti Deka, Saurav Talukdar, Michael Chertkov, Murti Salapaka","Graphical models are a succinct way to represent the structure in probability
distributions. This article analyzes the graphical model of nodal voltages in
non-radial power distribution grids. Using algebraic and structural properties
of graphical models, algorithms exactly determining topology and detecting line
changes for distribution grids are presented along with their theoretical
limitations. We show that if distribution grids have cycles/loops of size
greater than three, then nodal voltages are sufficient for efficient topology
estimation without additional assumptions on system parameters. In contrast,
line failure or change detection using nodal voltages does not require any
structural assumption. Under noisy measurements, we provide the first
non-trivial bounds on the maximum noise that the system can tolerate for
asymptotically correct topology recovery. The performance of the designed
algorithms is validated with nonlinear AC power flow samples generated by
Matpower on test grids, including scenarios with injection correlations and
system noise.",http://arxiv.org/abs/1905.06550v2
Majorization bounds for Ritz values of self-adjoint matrices,2019-05-16T19:09:08Z,"Pedro Massey, Demetrio Stojanoff, Sebastian Zarate","A priori, a posteriori, and mixed type upper bounds for the absolute change
in Ritz values of self-adjoint matrices in terms of submajorization relations
are obtained. Some of our results prove recent conjectures by Knyazev,
Argentati, and Zhu, which extend several known results for one dimensional
subspaces to arbitrary subspaces. In addition, we improve Nakatsukasa's version
of the $\tan \Theta$ theorem of Davis and Kahan. As a consequence, we obtain
new quadratic a posteriori bounds for the absolute change in Ritz values.",http://arxiv.org/abs/1905.06998v2
"Procedural Synthesis of Remote Sensing Images for Robust Change
  Detection with Neural Networks",2019-05-20T05:24:33Z,"Maria Kolos, Anton Marin, Alexey Artemov, Evgeny Burnaev","Data-driven methods such as convolutional neural networks (CNNs) are known to
deliver state-of-the-art performance on image recognition tasks when the
training data are abundant. However, in some instances, such as change
detection in remote sensing images, annotated data cannot be obtained in
sufficient quantities. In this work, we propose a simple and efficient method
for creating realistic targeted synthetic datasets in the remote sensing
domain, leveraging the opportunities offered by game development engines. We
provide a description of the pipeline for procedural geometry generation and
rendering as well as an evaluation of the efficiency of produced datasets in a
change detection scenario. Our evaluations demonstrate that our pipeline helps
to improve the performance and convergence of deep learning models when the
amount of real-world data is severely limited.",http://arxiv.org/abs/1905.07877v1
Automated shapeshifting for function recovery in damaged robots,2019-05-22T17:50:40Z,"Sam Kriegman, Stephanie Walker, Dylan Shah, Michael Levin, Rebecca Kramer-Bottiglio, Josh Bongard","A robot's mechanical parts routinely wear out from normal functioning and can
be lost to injury. For autonomous robots operating in isolated or hostile
environments, repair from a human operator is often not possible. Thus, much
work has sought to automate damage recovery in robots. However, every case
reported in the literature to date has accepted the damaged mechanical
structure as fixed, and focused on learning new ways to control it. Here we
show for the first time a robot that automatically recovers from unexpected
damage by deforming its resting mechanical structure without changing its
control policy. We found that, especially in the case of ""deep insult"", such as
removal of all four of the robot's legs, the damaged machine evolves shape
changes that not only recover the original level of function (locomotion) as
before, but can in fact surpass the original level of performance (speed). This
suggests that shape change, instead of control readaptation, may be a better
method to recover function after damage in some cases.",http://arxiv.org/abs/1905.09264v1
Deep density ratio estimation for change point detection,2019-05-23T19:04:56Z,"Haidar Khan, Lara Marcuse, Bülent Yener","In this work, we propose new objective functions to train deep neural network
based density ratio estimators and apply it to a change point detection
problem. Existing methods use linear combinations of kernels to approximate the
density ratio function by solving a convex constrained minimization problem.
Approximating the density ratio function using a deep neural network requires
defining a suitable objective function to optimize. We formulate and compare
objective functions that can be minimized using gradient descent and show that
the network can effectively learn to approximate the density ratio function.
Using our deep density ratio estimation objective function results in better
performance on a seizure detection task than other (kernel and neural network
based) density ratio estimation methods and other window-based change point
detection algorithms. We also show that the method can still support other
neural network architectures, such as convolutional networks.",http://arxiv.org/abs/1905.09876v1
Continual Reinforcement Learning in 3D Non-stationary Environments,2019-05-24T09:38:42Z,"Vincenzo Lomonaco, Karan Desai, Eugenio Culurciello, Davide Maltoni","High-dimensional always-changing environments constitute a hard challenge for
current reinforcement learning techniques. Artificial agents, nowadays, are
often trained off-line in very static and controlled conditions in simulation
such that training observations can be thought as sampled i.i.d. from the
entire observations space. However, in real world settings, the environment is
often non-stationary and subject to unpredictable, frequent changes. In this
paper we propose and openly release CRLMaze, a new benchmark for learning
continually through reinforcement in a complex 3D non-stationary task based on
ViZDoom and subject to several environmental changes. Then, we introduce an
end-to-end model-free continual reinforcement learning strategy showing
competitive results with respect to four different baselines and not requiring
any access to additional supervised signals, previously encountered
environmental conditions or observations.",http://arxiv.org/abs/1905.10112v2
Enhancing Adversarial Defense by k-Winners-Take-All,2019-05-25T03:36:40Z,"Chang Xiao, Peilin Zhong, Changxi Zheng","We propose a simple change to existing neural network structures for better
defending against gradient-based adversarial attacks. Instead of using popular
activation functions (such as ReLU), we advocate the use of k-Winners-Take-All
(k-WTA) activation, a C0 discontinuous function that purposely invalidates the
neural network model's gradient at densely distributed input data points. The
proposed k-WTA activation can be readily used in nearly all existing networks
and training methods with no significant overhead. Our proposal is
theoretically rationalized. We analyze why the discontinuities in k-WTA
networks can largely prevent gradient-based search of adversarial examples and
why they at the same time remain innocuous to the network training. This
understanding is also empirically backed. We test k-WTA activation on various
network structures optimized by a training method, be it adversarial training
or not. In all cases, the robustness of k-WTA networks outperforms that of
traditional networks under white-box attacks.",http://arxiv.org/abs/1905.10510v3
Large Scale Markov Decision Processes with Changing Rewards,2019-05-25T18:26:49Z,"Adrian Rivera Cardoso, He Wang, Huan Xu","We consider Markov Decision Processes (MDPs) where the rewards are unknown
and may change in an adversarial manner. We provide an algorithm that achieves
state-of-the-art regret bound of $O( \sqrt{\tau (\ln|S|+\ln|A|)T}\ln(T))$,
where $S$ is the state space, $A$ is the action space, $\tau$ is the mixing
time of the MDP, and $T$ is the number of periods. The algorithm's
computational complexity is polynomial in $|S|$ and $|A|$ per period. We then
consider a setting often encountered in practice, where the state space of the
MDP is too large to allow for exact solutions. By approximating the
state-action occupancy measures with a linear architecture of dimension
$d\ll|S|$, we propose a modified algorithm with computational complexity
polynomial in $d$. We also prove a regret bound for this modified algorithm,
which to the best of our knowledge this is the first $\tilde{O}(\sqrt{T})$
regret bound for large scale MDPs with changing rewards.",http://arxiv.org/abs/1905.10649v1
Mixing for Smooth Time-Changes of General Nilflows,2019-05-28T06:28:57Z,"Artur Avila, Giovanni Forni, Davide Ravotti, Corinna Ulcigrai","We consider completely irrational nilflows on any nilmanifold of step at
least $2$. We show that there exists a dense set of smooth time-changes such
that any time-change in this class which is not measurably trivial gives rise
to a mixing nilflow. This in particular reproves and generalizes to any nilflow
(of step at least $2$) the main result proved in [AFU] for the special class of
Heisenberg (step $2$) nilflows, and later generalized in [Rav2] to a class of
nilflows of arbitrary step which are isomorphic to suspensions of
higher-dimensional linear toral skew-shifts.",http://arxiv.org/abs/1905.11628v2
"Effect of palladium on the microstructure and grain boundary complexions
  in SiC",2019-05-21T04:34:38Z,"David J. Navarro-Solis, Felix Cancino-Trejo, Eddie Lopez-Honorato","One of the main challenges in the study of TRISO (Tristructural Isotropic)
coated fuel particles is the understanding of the diffusion of fission products
through SiC. Among the elements produced inside the uranium kernel, it has been
suggested that Pd might enhance the diffusion of other fission products. In
this work we have studied the interaction between Pd and SiC. We have observed
that as Pd diffuses it can change the chemical composition and microstructure
of SiC. Electron Backscattered Diffraction (EBSD) analysis showed that Pd
increased the amount of high angle grain boundaries from 47 to 59%.
Furthermore, we have observed that as Pd diffused, it changed the composition
of SiC by leaving a trail of excess carbon at the grain boundary. This change
in localized chemical composition and microstructure suggests a grain boundary
complexion transition induced by Pd and a new way in which Pd can lead to
faster diffusion routes for other fission products.",http://arxiv.org/abs/1905.12157v1
"Automatic Realistic Music Video Generation from Segments of Youtube
  Videos",2019-05-29T06:57:09Z,"Sarah Gross, Xingxing Wei, Jun Zhu","A Music Video (MV) is a video aiming at visually illustrating or extending
the meaning of its background music. This paper proposes a novel method to
automatically generate, from an input music track, a music video made of
segments of Youtube music videos which would fit this music. The system
analyzes the input music to find its genre (pop, rock, ...) and finds segmented
MVs with the same genre in the database. Then, a K-Means clustering is done to
group video segments by color histogram, meaning segments of MVs having the
same global distribution of colors. A few clusters are randomly selected, then
are assembled around music boundaries, which are moments where a significant
change in the music occurs (for instance, transitioning from verse to chorus).
This way, when the music changes, the video color mood changes as well. This
work aims at generating high-quality realistic MVs, which could be mistaken for
man-made MVs. By asking users to identify, in a batch of music videos
containing professional MVs, amateur-made MVs and generated MVs by our
algorithm, we show that our algorithm gives satisfying results, as 45% of
generated videos are mistaken for professional MVs and 21.6% are mistaken for
amateur-made MVs. More information can be found in the project website:
http://ml.cs.tsinghua.edu.cn/~sarah/",http://arxiv.org/abs/1905.12245v1
"G2R Bound: A Generalization Bound for Supervised Learning from
  GAN-Synthetic Data",2019-05-29T10:22:49Z,"Fu-Chieh Chang, Hao-Jen Wang, Chun-Nan Chou, Edward Y. Chang","Performing supervised learning from the data synthesized by using Generative
Adversarial Networks (GANs), dubbed GAN-synthetic data, has two important
applications. First, GANs may generate more labeled training data, which may
help improve classification accuracy. Second, in scenarios where real data
cannot be released outside certain premises for privacy and/or security
reasons, using GAN- synthetic data to conduct training is a plausible
alternative. This paper proposes a generalization bound to guarantee the
generalization capability of a classifier learning from GAN-synthetic data.
This generalization bound helps developers gauge the generalization gap between
learning from synthetic data and testing on real data, and can therefore
provide the clues to improve the generalization capability.",http://arxiv.org/abs/1905.12313v1
"Cascading Non-Stationary Bandits: Online Learning to Rank in the
  Non-Stationary Cascade Model",2019-05-29T12:18:51Z,"Chang Li, Maarten de Rijke","Non-stationarity appears in many online applications such as web search and
advertising. In this paper, we study the online learning to rank problem in a
non-stationary environment where user preferences change abruptly at an unknown
moment in time. We consider the problem of identifying the K most attractive
items and propose cascading non-stationary bandits, an online learning variant
of the cascading model, where a user browses a ranked list from top to bottom
and clicks on the first attractive item. We propose two algorithms for solving
this non-stationary problem: CascadeDUCB and CascadeSWUCB. We analyze their
performance and derive gap-dependent upper bounds on the n-step regret of these
algorithms. We also establish a lower bound on the regret for cascading
non-stationary bandits and show that both algorithms match the lower bound up
to a logarithmic factor. Finally, we evaluate their performance on a real-world
web search click dataset.",http://arxiv.org/abs/1905.12370v3
"Reusability and Transferability of Macro Actions for Reinforcement
  Learning",2019-08-05T05:59:40Z,"Yi-Hsiang Chang, Kuan-Yu Chang, Henry Kuo, Chun-Yi Lee","Conventional reinforcement learning (RL) typically determines an appropriate
primitive action at each timestep. However, by using a proper macro action,
defined as a sequence of primitive actions, an agent is able to bypass
intermediate states to a farther state and facilitate its learning procedure.
The problem we would like to investigate is what associated beneficial
properties that macro actions may possess. In this paper, we unveil the
properties of reusability and transferability of macro actions. The first
property, reusability, means that a macro action generated along with one RL
method can be reused by another RL method for training, while the second one,
transferability, means that a macro action can be utilized for training agents
in similar environments with different reward settings. In our experiments, we
first generate macro actions along with RL methods. We then provide a set of
analyses to reveal the properties of reusability and transferability of the
generated macro actions.",http://arxiv.org/abs/1908.01478v3
Ab Antiquo: Neural Proto-language Reconstruction,2019-08-07T08:03:08Z,"Carlo Meloni, Shauli Ravfogel, Yoav Goldberg","Historical linguists have identified regularities in the process of historic
sound change. The comparative method utilizes those regularities to reconstruct
proto-words based on observed forms in daughter languages. Can this process be
efficiently automated? We address the task of proto-word reconstruction, in
which the model is exposed to cognates in contemporary daughter languages, and
has to predict the proto word in the ancestor language. We provide a novel
dataset for this task, encompassing over 8,000 comparative entries, and show
that neural sequence models outperform conventional methods applied to this
task so far. Error analysis reveals variability in the ability of neural model
to capture different phonological changes, correlating with the complexity of
the changes. Analysis of learned embeddings reveals the models learn
phonologically meaningful generalizations, corresponding to well-attested
phonological shifts documented by historical linguistics.",http://arxiv.org/abs/1908.02477v3
"Leibniz Equivalence, Newton Equivalence, and Substantivalism",2019-08-12T18:29:28Z,Oliver Davis Johns,"Active diffeomorphisms map a differentiable manifold to itself. They
transform manifold points and objects without changing the system of local
coordinates used to represent those objects. What has been called Leibniz
Equivalence is the assertion that, although active diffeomorphisms do change
manifold objects, they do not change what is called the ""physical situation""
being modeled by those objects. This paper introduces the contrasting idea of
Newton Equivalence, which asserts that the different values of manifold objects
produced by active diffeomorphisms do model different physical situations. But
due to the assumption of general covariance, these different physical
situations are all equally possible. They represent physically different
situations all of which could happen. This paper compares these two
interpretations of active diffeomorphisms, and comments on their importance in
the substantivalism debate.",http://arxiv.org/abs/1908.04326v1
"Temperature Effects in the thermal conductivity of aligned amorphous
  Polyethylene -- A molecular Dynamics study",2019-08-12T19:14:19Z,"Rajmohan Muthaiah, Jivtesh Garg","We analyze, through molecular dynamics simulations, the temperature
dependence of the thermal conductivity (k) of chain-oriented amorphous
polyethylene (PE). We find that at increasing levels of orientation, the
temperature corresponding to a peak k progressively decreases. Un-oriented PE
exhibits the peak k at 350 K, while aligned PE under an applied strain of 400%
shows a maximum at 100 K. This transition of peak k to lower temperatures with
increasing alignment is explained in terms of a crossover from disorder to
anharmonicity dominated phonon transport in aligned polymers. Evidence for this
crossover is achieved by manipulating the disorder in the polymer structure and
studying the resulting change in temperature corresponding to peak k. Disorder
is modified through a change in the dihedral parameters of the potential
function, allowing a change in the relative fraction of trans and gauche
transformations. The results shed light on the underlying thermal transport
processes in aligned polymers and hold importance for low temperature
applications of polymer materials in thermal management technologies.",http://arxiv.org/abs/1908.04341v1
"Unsupervised Behavior Change Detection in Multidimensional Data Streams
  for Maritime Traffic Monitoring",2019-08-14T12:53:20Z,"Lucas May Petry, Amilcar Soares, Vania Bogorny, Stan Matwin","The worldwide growth of maritime traffic and the development of the Automatic
Identification System (AIS) has led to advances in monitoring systems for
preventing vessel accidents and detecting illegal activities. In this work, we
describe research gaps and challenges in machine learning for vessel behavior
change and event detection, considering several constraints imposed by
real-time data streams and the maritime monitoring domain. As a starting point,
we investigate how unsupervised and semi-supervised change detection methods
may be employed for identifying shifts in vessel behavior, aiming to detect and
label unusual events.",http://arxiv.org/abs/1908.05103v1
Magnetic Entropy in a Non-Collinear Weak Ferromagnetic YCrO3,2019-08-18T14:58:36Z,"Brajesh Tiwari, Ambesh Dixit, M. S. Ramachandra Rao","We carried out temperature and field dependent magnetic measurements to
understand the evolution of magnetic non-collinearity near antiferromagnetic
phase in conjunction with the evolution of magnetic entropy near phase
transition. We observed the maximum change in entropy just before magnetic
ordering of Cr3+ in YCrO3 with the maximum change in magnetic entropy of -0.38
Jkg-1K-1 at 8 Tesla external field. The data is linear in higher fields 3 T - 8
T , whereas it showed deviations in the lower field region. The maximum entropy
change fits well with mean field approximation at higher fields, while the
observed deviation in lower field substantiates the onset of weak
ferromagnetism in YCrO3.",http://arxiv.org/abs/1908.06454v1
"Tracking Behavioral Patterns among Students in an Online Educational
  System",2019-08-21T13:36:26Z,"Stephan Lorenzen, Niklas Hjuler, Stephen Alstrup","Analysis of log data generated by online educational systems is an essential
task to better the educational systems and increase our understanding of how
students learn. In this study we investigate previously unseen data from Clio
Online, the largest provider of digital learning content for primary schools in
Denmark. We consider data for 14,810 students with 3 million sessions in the
period 2015-2017. We analyze student activity in periods of one week. By using
non-negative matrix factorization techniques, we obtain soft clusterings,
revealing dependencies among time of day, subject, activity type, activity
complexity (measured by Bloom's taxonomy), and performance. Furthermore, our
method allows for tracking behavioral changes of individual students over time,
as well as general behavioral changes in the educational system. Based on the
results, we give suggestions for behavioral changes, in order to optimize the
learning experience and improve performance.",http://arxiv.org/abs/1908.08937v1
Changepoint in Linear Relations,2019-08-28T10:27:48Z,Michal Pešta,"Linear relations, containing measurement errors in input and output data, are
considered. Parameters of these so-called errors-in-variables models can change
at some unknown moment. The aim is to test whether such an unknown change has
occurred or not. For instance, detecting a change in trend for a randomly
spaced time series is a special case of the investigated framework. The
designed changepoint tests are shown to be consistent and involve neither
nuisance parameters nor tuning constants, which makes the testing procedures
effortlessly applicable. A changepoint estimator is also introduced and its
consistency is proved. A boundary issue is avoided, meaning that the
changepoint can be detected when being close to the extremities of the
observation regime. As a theoretical basis for the developed methods, a weak
invariance principle for the smallest singular value of the data matrix is
provided, assuming weakly dependent and non-stationary errors. The results are
presented in a simulation study, which demonstrates computational efficiency of
the techniques. The completely data-driven tests are illustrated through a
calibration problem, however, the methodology can be applied to other areas
such as clinical measurements, dietary assessment, computational psychometrics,
or environmental toxicology as manifested in the paper.",http://arxiv.org/abs/1908.10628v2
On a class of weighted p-Laplace equation with singular nonlinearity,2019-08-29T14:13:37Z,"P. Garain, T. Mukherjee","This article deals with the existence of the following quasilinear degenerate
singular elliptic equation \begin{equation*} (P_\la)\left\{ \begin{split}
  -\text{div}(w(x)|\nabla u|^{p-2}\nabla u) &= g_{\la}(u),\;u>0\; \text{in}\;
\Om,
  u&=0 \; \text{on}\; \partial \Om, \end{split}\right. \end{equation*} where $
\Om \subset \mb R^n$ is a smooth bounded domain, $n\geq 3$, $\la>0$, $p>1$ and
$w$ is a Muckenhoupt weight. Using variational techniques, for $g_{\la}(u)= \la
f(u)u^{-q}$ and certain assumptions on $f$, we show existence of a solution to
$(P_\la)$ for each $\la>0$. Moreover when $g_{\la}(u)= \la u^{-q}+ u^{r}$ we
establish existence of atleast two solutions to $(P_\la)$ in a suitable range
of the parameter $\la$. Here we assume $q\in (0,1)$ and $r \in (p-1,p^*_s-1)$.",http://arxiv.org/abs/1908.11247v2
Thermal Conductivity and Magnetic Phase Diagram of CuB2O4,2019-10-01T02:37:39Z,"T. Kawamata, N. Sugawara, S. M. Haidar, T. Adachi, T. Noji, K. Kudo, N. Kobayashi, Y. Fujii, H. Kikuchi, M. Chiba, G. A. Petrakovskii, M. A. Popov, L. N. Bezmaternykh, Y. Koike","We have measured temperature and magnetic field dependences of the thermal
conductivity along the c-axis, kc, and that along the [110] direction, k110, of
CuB2O4 single crystals in zero field and magnetic fields along the c-axis and
along the [110] direction. It has been found that the thermal conductivity is
nearly isotropic and very large in zero field and that the thermal conductivity
due to phonons is dominant in CuB2O4. The temperature and field dependences of
kc and k110 have markedly changed at phase boundaries in the magnetic phase
diagram, which has been understood to be due to the change of the mean free
path of phonons caused by the change of the phonon-spin scattering rate at the
phase boundaries. It has been concluded that thermal conductivity measurements
are very effective for detecting magnetic phase boundaries.",http://arxiv.org/abs/1910.00179v1
"The energy budget and figure of Earth during recovery from the
  Moon-forming giant impact",2019-10-01T19:00:17Z,"Simon J. Lock, Sarah T. Stewart, Matija Ćuk","Quantifying the energy budget of Earth in the first few million years
following the Moon-forming giant impact is vital to understanding Earth's
initial thermal state and the dynamics of lunar tidal evolution. After the
impact, the body was substantially vaporized and rotating rapidly, very
different from the planet we know today. The subsequent evolution of Earth's
energy budget, as the body cooled and angular momentum was transferred during
lunar tidal recession, has not been accurately calculated with all relevant
energy components included. Here, we use giant impact simulations and planetary
structure models to calculate the energy budget at stages in Earth's evolution.
We show that the figure and internal structure of Earth changed substantially
during its post-impact evolution and that changes in kinetic, potential, and
internal energy were all significant. These changes have important implications
for the dynamics of tidal recession and the thermal structure of early Earth.",http://arxiv.org/abs/1910.00619v1
Magnetic exchange interactions in SrMnO$_3$,2019-10-03T16:21:07Z,"Xiangzhou Zhu, Alexander Edström, Claude Ederer","We calculate Heisenberg-type magnetic exchange interactions for SrMnO$_3$
under isotropic volume expansion using an approach that is based on total
energy variations due to infinitesimal spin rotations around a given reference
state. Our total energy calculations using density functional theory (DFT)
indicate a transition from antiferromagnetic to ferromagnetic coupling for
increasing interatomic distances, corresponding to a sign change of the nearest
neighbor exchange interaction. This sign change cannot easily be understood
from a standard superexchange mechanism. Furthermore, the exchange interaction
strongly depends on the corresponding reference state. This ""non-Heisenberg""
behavior increases with increasing volume and is also confirmed through
non-collinear DFT calculations. An orbital- and energy-resolved decomposition
of the exchange coupling suggests that an increased partial occupancy of $e_g$
orbitals near the Fermi level is crucial both for the sign change and the
non-Heisenberg behavior of the nearest neighbor interaction. Furthermore, even
though both $e_g$ and $t_{2g}$ contributions to the exchange interactions decay
exponentially for large inter-atomic distances, the $e_g$ contribution remains
surprisingly strong over relatively large distances along the crystal axes.",http://arxiv.org/abs/1910.01574v1
"A Likely Inclination Dependence in the Non-linear Variability of Quasi
  Periodic Oscillations from Black Hole Binaries",2019-10-03T19:04:55Z,"Arur. K, Maccarone. T. J","We present a systematic analysis of the effects of orbital inclination angle
on the non-linear variability properties of type-B and type-C QPOs from black
hole binaries. We use the bicoherence, a measure of phase coupling at different
Fourier frequencies for our analysis. We find that there is a likely
inclination dependent change in the non-linear properties of type-C QPOs as the
source transitions from a hard intermediate state to a soft intermediate state.
High inclination (edge-on) sources show a change from a `web' to a `cross'
pattern, while the low inclination (face-on) sources show a change from a `web'
to a `hypotenuse' pattern. We present a scenario of a moderate increase in the
optical depth of the Comptonising region as a possible explanation of these
effects. The bicoherence of type-B QPOs do not exhibit any measurable
inclination dependence.",http://arxiv.org/abs/1910.01687v1
"On the Cost-Optimality Trade-off for Service Function Chain
  Reconfiguration",2019-10-04T11:46:12Z,"Kyoomars Alizadeh Noghani, Andreas Kassler, Javid Taheri","Optimal placement of Virtual Network Functions (VNFs) in virtualized data
centers enhances the overall performance of Service Function Chains (SFCs) and
decreases the operational costs for mobile network operators. Maintaining an
optimal placement of VNFs under changing load requires a dynamic
reconfiguration that includes adding or removing VNF instances, changing the
resource allocation of VNFs, and re-routing corresponding service flows.
However, such reconfiguration may lead to notable service disruptions and
impose additional overhead on the VNF infrastructure, especially when
reconfiguration entails state or VNF migration. On the other hand, not changing
the existing placement may lead to high operational costs. In this paper, we
investigate the trade-off between the reconfiguration of SFCs and the
optimality of the resulting placement and service flow (re)routing. We model
different reconfiguration costs related to the migration of stateful VNFs and
solve a joint optimization problem that aims to minimize both the total cost of
the VNF placement and the reconfiguration cost necessary for repairing a
suboptimal placement. Numerical results show that a small number of
reconfiguration operations can significantly reduce the operational cost of the
VNF infrastructure; however, too much reconfiguration may not pay off should
heavy costs be involved.",http://arxiv.org/abs/1910.01881v1
"Deterministic and random attractors for a wave equation with sign
  changing damping",2019-10-06T12:00:37Z,"Qingquan Chang, Dandan Li, Chunyou Sun, Sergey Zelik","The paper gives a detailed study of long-time dynamics generated by weakly
damped wave equations in bounded 3D domains where the damping exponent depends
explicitly on time and may change sign. It is shown that in the case when the
non-linearity is superlinear, the considered equation remains dissipative if
the weighted mean value of the dissipation rate remains positive and that the
conditions of this type are not sufficient in the linear case. Two principally
different cases are considered. In the case when this mean is uniform (which
corresponds to deterministic dissipation rates), it is shown that the
considered system possesses smooth uniform attractors as well as non-autonomous
exponential attractors. In the case where the mean is not uniform (which
corresponds to the random dissipation rate, for instance, when this dissipation
rate is generated by the Bernoulli process), the tempered random attractor is
constructed. In contrast to the usual situation, this random attractor is
expected to have infinite Hausdorff and fractal dimension. The simplified model
example which demonstrates infinite-dimensionality of the random attractor is
also presented.",http://arxiv.org/abs/1910.02430v1
Resilience of the Rank of Random Matrices,2019-10-08T18:10:32Z,"Asaf Ferber, Kyle Luh, Gweneth McKinley","Let $M$ be an $n \times m$ matrix of independent Rademacher ($\pm 1$) random
variables. It is well known that if $n \leq m$, then $M$ is of full rank with
high probability. We show that this property is resilient to adversarial
changes to $M$. More precisely, if $m \geq n + n^{1-\varepsilon/6}$, then even
after changing the sign of $(1-\varepsilon)m/2$ entries, $M$ is still of full
rank with high probability. Note that this is asymptotically best possible as
one can easily make any two rows proportional with at most $m/2$ changes.
Moreover, this theorem gives an asymptotic solution to a slightly weakened
version of a conjecture made by Van Vu.",http://arxiv.org/abs/1910.03619v1
Testing for a Change in Mean After Changepoint Detection,2019-10-09T22:58:38Z,"Sean Jewell, Paul Fearnhead, Daniela Witten","While many methods are available to detect structural changes in a time
series, few procedures are available to quantify the uncertainty of these
estimates post-detection. In this work, we fill this gap by proposing a new
framework to test the null hypothesis that there is no change in mean around an
estimated changepoint. We further show that it is possible to efficiently carry
out this framework in the case of changepoints estimated by binary segmentation
and its variants, $\ell_{0}$ segmentation, or the fused lasso. Our setup allows
us to condition on much less information than existing approaches, which yields
higher powered tests. We apply our proposals in a simulation study and on a
dataset of chromosomal guanine-cytosine content. These approaches are freely
available in the R package ChangepointInference at
https://jewellsean.github.io/changepoint-inference/.",http://arxiv.org/abs/1910.04291v3
"Radial thermal rectification in the concentric silicon ring from
  ballistic to diffusive regime",2019-10-10T07:45:06Z,"Chuang Zhang, Songze Chen, Zhaoli Guo","The radial thermal rectification in the concentric silicon ring from
ballistic to diffusive regime is investigated based on the phonon Boltzmann
transport equation. In the ballistic and diffusive limits, the analytical
solutions prove that there is no thermal rectification. In the
ballistic-diffusive regime, the heat flux prefers to flow from the inner
boundary to the outer boundary. Furthermore, as the characteristic length (the
distance between two circular boundaries) increases from tens of nanometers to
tens of microns, the thermal rectification ratio enhances first and then fades
away gradually. It attributes to that as the direction of the temperature
gradient changes, the average phonon mean free path changes. The difference of
the average phonon mean free path finally leads to the change of the heat flux
or thermal conductivity. As the temperature decreases, the maximum thermal
rectification ratio decreases. In addition, as the radius ratio between the
inner and outer boundary increases, the thermal rectification ratio decreases
for a given characteristic length.",http://arxiv.org/abs/1910.04412v1
Defensive Escort Teams via Multi-Agent Deep Reinforcement Learning,2019-10-09T15:57:49Z,"Arpit Garg, Yazied A. Hasan, Adam Yañez, Lydia Tapia","Coordinated defensive escorts can aid a navigating payload by positioning
themselves in order to maintain the safety of the payload from obstacles. In
this paper, we present a novel, end-to-end solution for coordinating an escort
team for protecting high-value payloads. Our solution employs deep
reinforcement learning (RL) in order to train a team of escorts to maintain
payload safety while navigating alongside the payload. This is done in a
distributed fashion, relying only on limited range positional information of
other escorts, the payload, and the obstacles. When compared to a state-of-art
algorithm for obstacle avoidance, our solution with a single escort increases
navigation success up to 31%. Additionally, escort teams increase success rate
by up to 75% percent over escorts in static formations. We also show that this
learned solution is general to several adaptations in the scenario including: a
changing number of escorts in the team, changing obstacle density, and changes
in payload conformation. Video: https://youtu.be/SoYesKti4VA.",http://arxiv.org/abs/1910.04537v1
"Combined molecular dynamics and quantum trajectories simulation of
  laser-driven, collisional systems",2019-10-10T20:07:37Z,"G. M. Gorman, T. K. Langin, M. K. Warrens, D. Vrinceanu, T. C. Killian","We introduce a combined molecular dynamics (MD) and quantum trajectories (QT)
code to simulate the effects of near-resonant optical fields on state-vector
evolution and particle motion in a collisional system. In contrast to
collisionless systems, in which the quantum dynamics of multi-level,
laser-driven particles with spontaneous emission can be described with the
optical Bloch equations (OBEs), particle velocities in sufficiently collisional
systems change on timescales comparable to those of the laser-induced,
quantum-state dynamics. These transient velocity changes can cause the
time-averaged velocity dependence of the quantum state to differ from the OBE
solution. We use this multiscale code to describe laser-cooling in a strontium
ultracold neutral plasma. Important phenomena described by the simulation
include suppression of electromagnetically induced transparencies through rapid
velocity changing collisions and thermalization between cooled and un-cooled
directions for anisotropic laser cooling.",http://arxiv.org/abs/1910.04837v1
Topology change of levels sets in Morse theory,2019-10-11T16:39:51Z,"Andreas Knauf, Nikolay Martynchuk","Classical Morse theory proceeds by considering sublevel sets $f^{-1}(-\infty,
a]$ of a Morse function $f: M \to R$, where $M$ is a smooth finite-dimensional
manifold. In this paper, we study the topology of the level sets $f^{-1}(a)$
and give conditions under which the topology of $f^{-1}(a)$ changes when
passing a critical value. We show that for a general class of functions, which
includes all exhaustive Morse function, the topology of a regular level
$f^{-1}(a)$ always changes when passing a single critical point, unless the
index of the critical point is half the dimension of the manifold $M$. When $f$
is a natural Hamiltonian on a cotangent bundle, we obtain more precise results
in terms of the topology of the configuration space. (Counter-)examples and
applications to celestial mechanics are also discussed.",http://arxiv.org/abs/1910.05294v1
"Appearance of hinge states in second-order topological insulators via
  the cutting procedure",2019-10-14T06:55:42Z,"Yutaro Tanaka, Ryo Takahashi, Shuichi Murakami","In recent years, second-order topological insulators have been proposed as a
new class of topological insulators. Second-order topological insulators are
materials with gapped bulk and surfaces, but with topologically protected
gapless states at the intersection of two surfaces. These gapless states are
called hinge states. In this paper, we give a general proof that any insulators
with inversion symmetry and gapped surface in class A always have hinge states
when the $\mathbb{Z}_{4}$ topological index $\mu_{1}$ is $\mu_{1}=2$. We
consider a three-dimensional insulator whose boundary conditions along two
directions change by changing the hopping amplitudes across the boundaries. We
study behaviors of gapless states through continuously changing boundary
conditions along the two directions, and reveal that the behaviors of gapless
states result from the $\mathbb{Z}_{4}$ strong topological index. From this
discussion, we show that gapless states inevitably appear at the hinge of a
three-dimensional insulator with gapped surfaces when the strong topological
index is $\mathbb{Z}_{4}=2$ and the weak topological indices are
$\nu_{1}=\nu_{2}=\nu_{3}=0$.",http://arxiv.org/abs/1910.05938v3
"Implicit Context-aware Learning and Discovery for Streaming Data
  Analytics",2019-10-18T14:30:27Z,"Kin Gwn Lore, Kishore K. Reddy","The performance of machine learning model can be further improved if
contextual cues are provided as input along with base features that are
directly related to an inference task. In offline learning, one can inspect
historical training data to identify contextual clusters either through feature
clustering, or hand-crafting additional features to describe a context. While
offline training enjoys the privilege of learning reliable models based on
already-defined contextual features, online training for streaming data may be
more challenging -- the data is streamed through time, and the underlying
context during a data generation process may change. Furthermore, the problem
is exacerbated when the number of possible context is not known. In this study,
we propose an online-learning algorithm involving the use of a neural
network-based autoencoder to identify contextual changes during training, then
compares the currently-inferred context to a knowledge base of learned contexts
as training advances. Results show that classifier-training benefits from the
automatically discovered contexts which demonstrates quicker learning
convergence during contextual changes compared to current methods.",http://arxiv.org/abs/1910.08438v1
Continual Learning for Infinite Hierarchical Change-Point Detection,2019-10-22T16:30:14Z,"Pablo Moreno-Muñoz, David Ramírez, Antonio Artés-Rodríguez","Change-point detection (CPD) aims to locate abrupt transitions in the
generative model of a sequence of observations. When Bayesian methods are
considered, the standard practice is to infer the posterior distribution of the
change-point locations. However, for complex models (high-dimensional or
heterogeneous), it is not possible to perform reliable detection. To circumvent
this problem, we propose to use a hierarchical model, which yields observations
that belong to a lower-dimensional manifold. Concretely, we consider a
latent-class model with an unbounded number of categories, which is based on
the chinese-restaurant process (CRP). For this model we derive a continual
learning mechanism that is based on the sequential construction of the CRP and
the expectation-maximization (EM) algorithm with a stochastic maximization
step. Our results show that the proposed method is able to recursively infer
the number of underlying latent classes and perform CPD in a reliable manner.",http://arxiv.org/abs/1910.10087v1
SalGaze: Personalizing Gaze Estimation Using Visual Saliency,2019-10-23T15:11:08Z,"Zhuoqing Chang, Matias Di Martino, Qiang Qiu, Steven Espinosa, Guillermo Sapiro","Traditional gaze estimation methods typically require explicit user
calibration to achieve high accuracy. This process is cumbersome and
recalibration is often required when there are changes in factors such as
illumination and pose. To address this challenge, we introduce SalGaze, a
framework that utilizes saliency information in the visual content to
transparently adapt the gaze estimation algorithm to the user without explicit
user calibration. We design an algorithm to transform a saliency map into a
differentiable loss map that can be used for the optimization of CNN-based
models. SalGaze is also able to greatly augment standard point calibration data
with implicit video saliency calibration data using a unified framework. We
show accuracy improvements over 24% using our technique on existing methods.",http://arxiv.org/abs/1910.10603v1
"Descriptive Dimensionality and Its Characterization of MDL-based
  Learning and Change Detection",2019-10-25T05:55:25Z,Kenji Yamanishi,"This paper introduces a new notion of dimensionality of probabilistic models
from an information-theoretic view point. We call it the ""descriptive
dimension""(Ddim). We show that Ddim coincides with the number of independent
parameters for the parametric class, and can further be extended to real-valued
dimensionality when a number of models are mixed. The paper then derives the
rate of convergence of the MDL (Minimum Description Length) learning algorithm
which outputs a normalized maximum likelihood (NML) distribution with model of
the shortest NML codelength. The paper proves that the rate is governed by
Ddim. The paper also derives error probabilities of the MDL-based test for
multiple model change detection. It proves that they are also governed by Ddim.
Through the analysis, we demonstrate that Ddim is an intrinsic quantity which
characterizes the performance of the MDL-based learning and change detection.",http://arxiv.org/abs/1910.11540v1
Continuity and Semileptonic $B_{(s)}\rightarrow D_{(s)}$ Form Factors,2019-10-29T00:58:59Z,Andrew Kobach,"Small changes in the masses of massive external scattering states should
correspond to small changes in the non-perturbative parameterization of form
factors in quantum field theory, as long as the relevant energy range is not
near strong deformations. Here, the definition of ``small'' is investigated and
applied to $SU(3)$ breaking in semileptonic $B_{(s)}\rightarrow D_{(s)}$
transitions. When unitarity and analyticity are imposed, the differences in the
form factors for semileptonic $B\rightarrow D$ versus $B_s\rightarrow D_s$
decays are found to be within $\mathcal{O}(1\%)$ over the entire kinematic
range, not just at zero recoil, which is consistent with results from lattice
calculations and differs from the expectation using HQET alone.",http://arxiv.org/abs/1910.13024v3
Flip motion of solitary wave in an Ising-type Vicsek model,2019-10-29T08:20:20Z,"Hidetsugu Sakaguchi, Kazuya Ishibashi","An Ising-type Vicsek model is proposed for collective motion and sudden
direction change in a population of self-propelled particles. Particles move on
a linear lattice with velocity +1 or -1 in the one-dimensional model. The
probability of the velocity of a particle at the next step is determined by the
number difference of the right- and left- moving particles at the present
lattice site and its nearest-neighboring sites. A solitary wave appears also in
our model similarly to previous models. In some parameter range, the moving
direction of the solitary wave sometimes changes rather suddenly, which is like
the sudden change of moving direction of a flock of birds. We study the average
reversal time of traveling direction numerically and compare the results with a
mean-field theory. The one-dimensional model is generalized to a
two-dimensional model. Flip motion of a bandlike soliton is observed in the
two-dimensional model.",http://arxiv.org/abs/1910.13130v1
"Belief revision and 3-valued logics: Characterization of 19,683 belief
  change operators",2019-10-30T21:10:39Z,"Nerio Borges, Ramón Pino Pérez","In most classical models of belief change, epistemic states are represented
by theories (AGM) or formulas (Katsuno-Mendelzon) and the new pieces of
information by formulas. The Representation Theorem for revision operators says
that operators are represented by total preorders. This important
representation is exploited by Darwiche and Pearl to shift the notion of
epistemic state to a more abstract one, where the paradigm of epistemic state
is indeed that of a total preorder over interpretations. In this work, we
introduce a 3-valued logic where the formulas can be identified with a
generalisation of total preorders of three levels: a ranking function mapping
interpretations into the truth values. Then we analyse some sort of changes in
this kind of structures and give syntactical characterizations of them.",http://arxiv.org/abs/1910.14138v1
"Reliability Analysis of Systems Subject To Mutually Dependent Competing
  Failure Processes With Changing Degradation Rate",2019-02-28T21:36:28Z,"Nooshin Yousefi, David W. Coit","In this paper, a new reliability model has been developed for a single system
degrading stochastically which experiences soft and hard failure. Soft failure
occurs when the physical deterioration level of the system is greater than a
predefined failure threshold, and hard failure occurs when the instantaneous
stress caused by a shock process is greater than a critical threshold. It is
considered that the degradation and shock process are mutually dependent. In
fact, each arriving shock accelerates the degradation process by adding abrupt
additional damages to the degradation path and changing the degradation rate
according to specific magnitude; also, the cumulative degradation changes the
occurrence intensity of shock process. A gamma process is used as a stochastic
process to model the degradation path. A realistic numerical example is
presented to illustrate the proposed reliability.",http://arxiv.org/abs/1903.00076v1
"Zinc Electrode Shape-Change in Secondary Air Batteries: A 2D Modeling
  Approach",2019-03-01T15:59:04Z,"Tobias Schmitt, Tobias Arlt, Ingo Manke, Arnulf Latz, Birger Horstmann","Zinc-air batteries offer large specific energy densities, while relying on
abundant and non-toxic materials. In this paper, we present the first
multi-dimensional simulations of zinc-air batteries. We refine our existing
theory-based model of secondary zinc-air systems. The model comprises
thermodynamically consistent multi-species transport in alkaline electrolytes,
formation and dissolution of metallic zinc and passivating zinc oxide, as well
as multi-phase coexistence in gas diffusion electrodes. For the first time, we
simulate zinc shape-change during battery cycling by modeling convection of
zinc solids. We validate our model with in-situ tomography of commercial button
cells. Two-dimensional volume-averaged simulations of cell voltage and zinc
electrode morphology during discharge agree with these measurements. Thus, we
can study how electrolyte carbonation limits shelf-life and how zinc
shape-change limits cycle-life. The charging current is found to be the major
contributor to cycle-life limitations. Finally, we optimize initial anode
structure and charge-discharge protocols for improved performance and
cycle-ability.",http://arxiv.org/abs/1903.00382v1
"Engineering Thermal and Electrical Interface Properties of Phase Change
  Memory with Monolayer MoS2",2019-03-02T01:53:19Z,"Christopher M. Neumann, Kye L. Okabe, Eilam Yalon, Ryan W. Grady, H. -S. Philip Wong, Eric Pop","Phase change memory (PCM) is an emerging data storage technology, however its
programming is thermal in nature and typically not energy-efficient. Here we
reduce the switching power of PCM through the combined approaches of
filamentary contacts and thermal confinement. The filamentary contact is formed
through an oxidized TiN layer on the bottom electrode, and thermal confinement
is achieved using a monolayer semiconductor interface, three-atom thick MoS2.
The former reduces the switching volume of the phase change material and yields
a 70% reduction in reset current versus typical 150 nm diameter mushroom cells.
The enhanced thermal confinement achieved with the ultra-thin (~6 {\AA}) MoS2
yields an additional 30% reduction in switching current and power. We also use
detailed simulations to show that further tailoring the electrical and thermal
interfaces of such PCM cells toward their fundamental limits could lead up to a
six-fold benefit in power efficiency.",http://arxiv.org/abs/1903.00602v1
Measuring timing properties of PSR B0540-69,2019-03-04T07:46:08Z,"Minjun Kim, Hongjun An","We report on the timing properties of the `Crab twin' pulsar PSR~B0540$-$69
measured with X-ray data taken with the Swift telescope over a period of
1100\,days. The braking index of the pulsar was estimated to be $n =
0.03\pm0.013$ in a previous study performed in 2015 with 500-day Swift data.
This small value of $n$ is unusual for pulsars, and a comparison to old
measurements of $n\approx2.1$ for the same target determined $\sim$10 years ago
suggests a dramatic change in the braking index. To confirm the small value and
large change of $n$, we used 1100-day Swift observations including the data
used for measuring $n=0.03$. In this study we found that the braking index of
PSR~B0540$-$69 is $n=0.163\pm0.001$, somewhat larger than $0.03$. Since the
measured value of $n$ is still much smaller than $2.1$, we can confirm the
dramatic change in the braking index for this pulsar.",http://arxiv.org/abs/1903.01107v2
Attention-based Lane Change Prediction,2019-03-04T13:56:25Z,"Oliver Scheel, Naveen Shankar Nagaraja, Loren Schwarz, Nassir Navab, Federico Tombari","Lane change prediction of surrounding vehicles is a key building block of
path planning. The focus has been on increasing the accuracy of prediction by
posing it purely as a function estimation problem at the cost of model
understandability. However, the efficacy of any lane change prediction model
can be improved when both corner and failure cases are humanly understandable.
We propose an attention-based recurrent model to tackle both understandability
and prediction quality. We also propose metrics which reflect the discomfort
felt by the driver. We show encouraging results on a publicly available dataset
and proprietary fleet data.",http://arxiv.org/abs/1903.01246v2
"Random Walks on Dynamic Graphs: Mixing Times, HittingTimes, and Return
  Probabilities",2019-03-04T16:31:56Z,"Thomas Sauerwald, Luca Zanetti","We establish and generalise several bounds for various random walk quantities
including the mixing time and the maximum hitting time. Unlike previous
analyses, our derivations are based on rather intuitive notions of local
expansion properties which allows us to capture the progress the random walk
makes through $t$-step probabilities.
  We apply our framework to dynamically changing graphs, where the set of
vertices is fixed while the set of edges changes in each round. For random
walks on dynamic connected graphs for which the stationary distribution does
not change over time, we show that their behaviour is in a certain sense
similar to static graphs. For example, we show that the mixing and hitting
times of any sequence of $d$-regular connected graphs is $O(n^2)$, generalising
a well-known result for static graphs. We also provide refined bounds depending
on the isoperimetric dimension of the graph, matching again known results for
static graphs. Finally, we investigate properties of random walks on dynamic
graphs that are not always connected: we relate their convergence to
stationarity to the spectral properties of an average of transition matrices
and provide some examples that demonstrate strong discrepancies between static
and dynamic graphs.",http://arxiv.org/abs/1903.01342v1
Mode switching and oscillations in PSR B1828-11,2019-03-04T22:43:02Z,"I. H. Stairs, A. G. Lyne, M. Kramer, B. W. Stappers, J. van Leeuwen, A. Tung, R. N Manchester, G. B. Hobbs, D. R. Lorimer, A. Melatos","The young pulsar PSR B1828-11 has long been known to show correlated shape
and spin-down changes with timescales of roughly 500 and 250 days, perhaps
associated with large-scale magnetospheric switching. Here we present
multi-hour observations with the Parkes and Green Bank Telescopes at multiple
phases across the roughly 500-day cycle and show that the pulsar undergoes
mode-changing between two stable, extreme profile states. The fraction of time
spent in each profile state naturally accounts for the observed overall ""shape
parameter"" (defined to be 0 for wide profiles and 1 for narrow ones); this and
the variable rate of the mode transitions are directly related to the spin-down
changes. We observe that the mode transition rate could plausibly function as
an additional parameter governing the chaotic behaviour in this object which
was proposed earlier by Seymour and Lorimer. Free precession is not needed to
account for the variations.",http://arxiv.org/abs/1903.01573v1
"Detection of excited state absorption cross-section of porphyrin through
  cw and femto-second laser pump-probe technique",2019-03-05T09:18:59Z,"A. Srinivasa Rao, Alok Sharan, N Venkatramaiah, R Venkatesan","We report on direct detection of excited states absorption cross-section
using dual wavelength pump-probe technique. Also, we experimentally demonstrate
using porphyrin composite molecules (porphyrin derivatives such as
5,10,15,20-meso-tetrakis phenyl porphyrin (H2TPP), 5,10,15,20 -
meso-tetrakis(4-hydroxyphenyl) porphyrin (H2TPP(OH)4)). The cw laser at 761 nm
wavelength is used as a pump to maintain excited state population. Changes in
the population of excited states lead to the change in transmission are
monitored using femto-second probe pulses of 130 fs width and repeated at a
1kHz rate with central wavelength around 800 nm. Transmittance changes due to
excited state population are modeled using rate equation approach. The effect
of the absorption on the transmitted pulse shape has been discussed as a
function of fluence. Obtained excited state absorption cross-sections of H2TPP
and H2TPP(OH)4 doped boric acid glass (BAG) films are 4.9X10-18 cm2 and
1.2X10-17 cm2 respectively.",http://arxiv.org/abs/1903.01740v1
"Comment to Impact of Daylight Saving Time on circadian timing system: An
  expert statement",2019-02-11T19:38:13Z,Jose Maria Martin-Olalla,"1000 words comment on a paper published in the European Journal of Internal
Medicine by a panel of experts. My point is authors address the magnitude of
the change (one hour) but fail to consider in any way its seasonal features.
DST is not a random change of an hour but an specific change on specific dates
and in a specific direction ---spring forward, fall back---. DST is the way
many contemporary societies handles the seasonality. The way many contemporary
societies turn a nonseasonal clock (the mechanical clock) into a seasonal
clock.",http://arxiv.org/abs/1903.01908v2
Design of A Two-point Steering Path Planner Using Geometric Control,2019-03-06T17:09:47Z,Yunlong Huang,"For lateral vehicle dynamics, planning trajectories for lane-keeping and
lane-change can be generalized as a path planning task to stabilize a vehicle
onto a target lane, which is a fundamental element in nowadays autonomous
driving systems. On the other hand, two-point steering for lane-change and
lane-keeping has been investigated by researchers from psychology as a
sensorimotor mechanism of human drivers. In the first part of this paper, using
knowledge of geometric control, we will first design a path planner which
satisfies five design objectives: generalization for different vehicle models,
convergence to the target lane, optimality, safety in lane-change maneuver and
low computational complexity. Later, based on this path planner, a two-point
steering path planner will be proposed and it will be proved rigorously that
this two-point steering path planner possesses the advantage--steering radius
of the planned trajectory is smaller than the intrinsic radius of reference
line of the target lane. This advantage is also described as ""corner-cutting""
in driving. The smaller driving radius of the trajectory will result in higher
vehicle speed along the winding roads and more comfortness for the passengers.",http://arxiv.org/abs/1903.02552v3
Nonlocal Spin Transport as a Probe of Viscous Magnon Fluids,2019-03-07T09:44:07Z,"Camilo Ulloa, A. Tomadin, J. Shan, M. Polini, B. J. van Wees, R. A. Duine","Magnons in ferromagnets behave as a viscous fluid over a length scale, the
momentum-relaxation length, below which momentum-conserving scattering
processes dominate. We show theoretically that in this hydrodynamic regime
viscous effects lead to a sign change in the magnon chemical potential, which
can be detected as a sign change in the nonlocal resistance measured in spin
transport experiments. This sign change is observable when the
injector-detector distance becomes comparable to the momentum-relaxation
length. Taking into account momentum- and spin-relaxation processes, we
consider the quasiconservation laws for momentum and spin in a magnon fluid.
The resulting equations are solved for nonlocal spin transport devices in which
spin is injected and detected via metallic leads. Because of the finite
viscosity we also find a backflow of magnons close to the injector lead. Our
work shows that nonlocal magnon spin transport devices are an attractive
platform to develop and study magnon-fluid dynamics.",http://arxiv.org/abs/1903.02790v2
Attitude Observer on SO(3) with Time-Varying Reference Directions,2019-03-09T16:43:54Z,"Kanishke Gamagedara, Taeyoung Lee, Dong Eui Chang","This paper introduces an advanced Lyapunov stability analysis for an attitude
observer that has been developed on the special orthogonal group. In
particular, when the attitude observer is constructed based on multiple
direction measurements toward known reference points, a local exponential
stability has been established by linearization, under the assumption that
those reference points are fixed in the inertial frame. Several modifications
have been proposed to deal with reference directions changing over time. Here,
we present an alternative Lyapunov analysis to show that the attitude observer
still exhibits exponential stability for time-varying reference directions,
under the assumption that the observer gain is sufficiently large relative to
the rate of change of the reference directions. These are illustrated by a
numerical example, followed by experimental results with visual marker
detection in an indoor space.",http://arxiv.org/abs/1903.03826v1
"Neutron Diffraction Studies on Temperature Driven Crystallographic
  Anisotropy in FeVO4 Multiferroic: Evidence of Strong Magnetostructural
  Correlations",2019-03-12T13:46:32Z,"Ajay Tiwari, Sagarmal Kumawat, Sudhindra Rayaprol, Ambesh Dixit","We used temperature-dependent neutron diffraction measurements on FeVO4 to
understand the temperature driven anisotropy and observed that the maximum
change for a and b lattice parameters in conjunction with a large contraction
in angle \beta\ as a function of temperature. The least changes are observed
for the c lattice parameter and in \gamma\ angle. From these structural
parameters, it can be said that, FeVO4 exhibits large structural anisotropy
with lowering temperature. The large change in lattice parameters in magnetic
phases i.e. below 22 K explains the strong magnetostructural coupling in FeVO4.",http://arxiv.org/abs/1903.04913v1
A Framework for On-line Learning of Underwater Vehicles Dynamic Models,2019-03-13T08:33:46Z,"Bilal Wehbe, Marc Hildebrandt, Frank Kirchner","Learning the dynamics of robots from data can help achieve more accurate
tracking controllers, or aid their navigation algorithms. However, when the
actual dynamics of the robots change due to external conditions, on-line
adaptation of their models is required to maintain high fidelity performance.
In this work, a framework for on-line learning of robot dynamics is developed
to adapt to such changes. The proposed framework employs an incremental support
vector regression method to learn the model sequentially from data streams. In
combination with the incremental learning, strategies for including and
forgetting data are developed to obtain better generalization over the whole
state space. The framework is tested in simulation and real experimental
scenarios demonstrating its adaptation capabilities to changes in the robot's
dynamics.",http://arxiv.org/abs/1903.05355v1
A Cross-Season Correspondence Dataset for Robust Semantic Segmentation,2019-03-16T13:01:23Z,"Måns Larsson, Erik Stenborg, Lars Hammarstrand, Torsten Sattler, Mark Pollefeys, Fredrik Kahl","In this paper, we present a method to utilize 2D-2D point matches between
images taken during different image conditions to train a convolutional neural
network for semantic segmentation. Enforcing label consistency across the
matches makes the final segmentation algorithm robust to seasonal changes. We
describe how these 2D-2D matches can be generated with little human interaction
by geometrically matching points from 3D models built from images. Two
cross-season correspondence datasets are created providing 2D-2D matches across
seasonal changes as well as from day to night. The datasets are made publicly
available to facilitate further research. We show that adding the
correspondences as extra supervision during training improves the segmentation
performance of the convolutional neural network, making it more robust to
seasonal changes and weather conditions.",http://arxiv.org/abs/1903.06916v2
Spatiotemporal Feature Learning for Event-Based Vision,2019-03-16T13:52:30Z,"Rohan Ghosh, Anupam Gupta, Siyi Tang, Alcimar Soares, Nitish Thakor","Unlike conventional frame-based sensors, event-based visual sensors output
information through spikes at a high temporal resolution. By only encoding
changes in pixel intensity, they showcase a low-power consuming, low-latency
approach to visual information sensing. To use this information for higher
sensory tasks like object recognition and tracking, an essential simplification
step is the extraction and learning of features. An ideal feature descriptor
must be robust to changes involving (i) local transformations and (ii)
re-appearances of a local event pattern. To that end, we propose a novel
spatiotemporal feature representation learning algorithm based on slow feature
analysis (SFA). Using SFA, smoothly changing linear projections are learnt
which are robust to local visual transformations. In order to determine if the
features can learn to be invariant to various visual transformations, feature
point tracking tasks are used for evaluation. Extensive experiments across two
datasets demonstrate the adaptability of the spatiotemporal feature learner to
translation, scaling and rotational transformations of the feature points. More
importantly, we find that the obtained feature representations are able to
exploit the high temporal resolution of such event-based cameras in generating
better feature tracks.",http://arxiv.org/abs/1903.06923v1
Appearance-Based Gaze Estimation Using Dilated-Convolutions,2019-03-18T08:29:32Z,"Zhaokang Chen, Bertram E. Shi","Appearance-based gaze estimation has attracted more and more attention
because of its wide range of applications. The use of deep convolutional neural
networks has improved the accuracy significantly. In order to improve the
estimation accuracy further, we focus on extracting better features from eye
images. Relatively large changes in gaze angles may result in relatively small
changes in eye appearance. We argue that current architectures for gaze
estimation may not be able to capture such small changes, as they apply
multiple pooling layers or other downsampling layers so that the spatial
resolution of the high-level layers is reduced significantly. To evaluate
whether the use of features extracted at high resolution can benefit gaze
estimation, we adopt dilated-convolutions to extract high-level features
without reducing spatial resolution. In cross-subject experiments on the
Columbia Gaze dataset for eye contact detection and the MPIIGaze dataset for 3D
gaze vector regression, the resulting Dilated-Nets achieve significant (up to
20.8%) gains when compared to similar networks without dilated-convolutions.
Our proposed Dilated-Net achieves state-of-the-art results on both the Columbia
Gaze and the MPIIGaze datasets.",http://arxiv.org/abs/1903.07296v1
Spin Dynamics of CPMG sequence in time-dependent magnetic fields,2019-03-19T14:07:46Z,"Martin D. Hürlimann, Shin Utsuzawa, Chang-Yu Hou","We analyze the effects of time dependent magnetic and RF fields on the spin
dynamics of the Carr-Purcell-Meiboom-Gill (CPMG) sequence. The analysis is
based on the decomposition of the magnetization into the eigenmodes of the
propagator of a single refocusing cycle. For sufficiently slow changes in the
external fields, the magnetization follows the changing eigenmodes
adiabatically. This results in echo amplitudes that show regular modulations
with time. Faster field changes can induce transitions between the eigenmodes.
Such non-adiabatic behavior occurs preferentially at particular offsets of the
Larmor frequency from the RF frequency where the eigenmodes become nearly
degenerate. We introduce the instantaneous adiabaticity parameter ${\cal A}(t)$
that accurately predicts the crossover from the adiabatic to the non-adiabatic
regime and allows the classification of field fluctuations. ${\cal A}(t)$ is
determined solely by the properties of a single refocusing cycle under static
conditions and the instantaneous value of the field offset and its temporal
derivative. The analytical results are compared with numerical simulations.",http://arxiv.org/abs/1903.08006v1
Anomalous Ground State in Fe$_{1-x}$Ni$_{x}$ Invar alloys,2019-03-19T19:14:18Z,S. S. Acharya,"This paper reports high resolution X-ray photoelectron spectroscopy (XPS)
studies on Fe$_{1-x}$Ni$_x$ (x=0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.9) alloys down
to 10 K temperature. Core levels and Auger transitions of the alloys except the
invar alloy (x=0.4) exhibit no observable temperature induced changes. The
invar alloy exhibits changes in the core levels below 20 K temperature that
strongly depend on the core level. Such core level dependent changes with
temperature were attributed to the precipitation of spin glass like phase below
20 K only in the invar alloy. Ni L$_3$M$_{45}$M$_{45}$ Auger transition also
supported such precipitation below 20 K.",http://arxiv.org/abs/1903.08221v3
"Concordance, crossing changes, and knots in homology spheres",2019-03-21T20:21:11Z,Christopher W. Davis,"Any knot in $S^3$ may be reduced to a slice knot by crossing changes. Indeed,
this slice knot can be taken to be the unknot. In this paper we study the
question of when the same holds for knots in homology spheres. We show that a
knot in a homology sphere is nullhomotopic in a smooth homology ball if and
only if that knot is smoothly concordant to a knot which is homotopic to a
smoothly slice knot. As a consequence, we prove that the equivalence relation
on knots in homology spheres given by cobounding immersed annuli in a homology
cobordism is generated by concordance in homology cobordisms together with
homotopy in a homology sphere.",http://arxiv.org/abs/1903.09225v2
Axonal Conduction Velocity Impacts Neuronal Network Oscillations,2019-03-22T18:38:12Z,"Vladimir A. Ivanov, Ioannis E. Polykretis, Konstantinos P. Michmizos","Increasing experimental evidence suggests that axonal action potential
conduction velocity is a highly adaptive parameter in the adult central nervous
system. Yet, the effects of this newfound plasticity on global brain dynamics
is poorly understood. In this work, we analyzed oscillations in biologically
plausible neuronal networks with different conduction velocity distributions.
Changes of 1-2 (ms) in network mean signal transmission time resulted in
substantial network oscillation frequency changes ranging in 0-120 (Hz). Our
results suggest that changes in axonal conduction velocity may significantly
affect both the frequency and synchrony of brain rhythms, which have well
established connections to learning, memory, and other cognitive processes.",http://arxiv.org/abs/1903.09671v1
"Temporal changes in stimulus perception improve bio-inspired source
  seeking",2019-03-25T12:53:18Z,"A. Pequeño-Zurro, D. Shaikh, I. Rañó","Braitenberg vehicles are well known qualitative models of sensor driven
animal source seeking (biological taxes) that locally navigate a stimulus
function. These models ultimately depend on the perceived stimulus values,
while there is biological evidence that animals also use the temporal changes
in the stimulus as information source for taxis behaviour. The time evolution
of the stimulus values depends on the agent's (animal or robot) velocity, while
simultaneously the velocity is typically the variable to control. This circular
dependency appears, for instance, when using optical flow to control the motion
of a robot, and it is solved by fixing the forward speed while controlling only
the steering rate. This paper presents a new mathematical model of a
bio-inspired source seeking controller that includes the rate of change of the
stimulus in the velocity control mechanism. The above mentioned circular
dependency results in a closed-loop model represented by a set of
differential-algebraic equations (DAEs), which can be converted to non-linear
ordinary differential equations (ODEs) under some assumptions. Theoretical
results of the model analysis show that including a term dependent on the
temporal evolution of the stimulus improves the behaviour of the closed-loop
system compared to simply using the stimulus values. We illustrate the
theoretical results through a set of simulations.",http://arxiv.org/abs/1903.10279v1
"Dynamic Multi Objective Particle Swarm Optimization based on a New
  Environment Change Detection Strategy",2019-03-25T10:05:28Z,"Ahlem Aboud, Raja Fdhila, Adel M. Alimi","The dynamic of real-world optimization problems raises new challenges to the
traditional particle swarm optimization (PSO). Responding to these challenges,
the dynamic optimization has received considerable attention over the past
decade. This paper introduces a new dynamic multi-objective optimization based
particle swarm optimization (Dynamic-MOPSO).The main idea of this paper is to
solve such dynamic problem based on a new environment change detection strategy
using the advantage of the particle swarm optimization. In this way, our
approach has been developed not just to obtain the optimal solution, but also
to have a capability to detect the environment changes. Thereby, DynamicMOPSO
ensures the balance between the exploration and the exploitation in dynamic
research space. Our approach is tested through the most popularized dynamic
benchmark's functions to evaluate its performance as a good method.",http://arxiv.org/abs/1903.10681v1
"Colossal barocaloric effects near room temperature in plastic crystals
  of neopentylglycol",2019-03-28T14:37:06Z,"Pol Lloveras, Araceli Aznar, María Barrio, Philippe Negrier, Catalin Popescu, Antoni Planes, Lluís Mañosa, Enric Stern-Taulats, Alex Avramenko, Neil D. Mathur, Xavier Moya, Josep-Lluís Tamarit","There is currently great interest in replacing the harmful volatile
hydrofluorocarbon fluids used in refrigeration and air-conditioning with solid
materials that display magnetocaloric, electrocaloric or mechanocaloric
effects. However, the field-driven thermal changes in all of these caloric
materials fall short with respect to their fluid counterparts. Here we show
that plastic crystals of neopentylglycol (CH3)2C(CH2OH)2 display
unprecedentedly large pressure-driven thermal changes near room temperature due
to molecular reconfiguration, and that these changes are comparable with those
exploited commercially in hydrofluorocarbons. Our discovery of colossal
barocaloric effects in a plastic crystal should bring barocaloric materials to
the forefront of research and development in order to achieve safe
environmentally friendly cooling without compromising performance.",http://arxiv.org/abs/1903.12010v1
"Spectral Unmixing: A Derivation of the Extended Linear Mixing Model from
  the Hapke Model",2019-03-28T16:11:50Z,"Lucas Drumetz, Jocelyn Chanussot, Christian Jutten","In hyperspectral imaging, spectral unmixing aims at decomposing the image
into a set of reference spectral signatures corresponding to the materials
present in the observed scene and their relative proportions in every pixel.
While a linear mixing model was used for a long time, the complex nature of the
physical mixing processes, led to shift the community's attention towards
nonlinear models and algorithms accounting for the variability of the
endmembers. Such intra class variations are due to local changes in the
physico-chemical composition of the materials, and to illumination changes. In
the physical remote sensing community, a popular model accounting for
illumination variability is the radiative transfer model proposed by Hapke. It
is however too complex to be directly used in hyperspectral unmixing in a
tractable way. Instead, the Extended Linear Mixing Model (ELMM) allows to
easily unmix hyperspectral data accounting for changing illumination
conditions. In this letter, we show that the ELMM can be obtained from the
Hapke model by successive simplifiying physical assumptions, thus theoretically
confirming its relevance to handle illumination induced variability in the
unmixing problem.",http://arxiv.org/abs/1903.12089v2
Quantum gravity on a torus,2019-11-30T17:12:19Z,Jakub Gizbert-Studnicki,"Causal Dynamical Triangulations (CDT) is a non-perturbative lattice approach
to quantum gravity where one assumes space-time foliation into spatial
hyper-surfaces of fixed topology. Most of the CDT results were obtained for the
spatial topology of the 3-sphere. It was shown that CDT has rich phase
structure, including the semiclassical phase consistent with Einstein's general
relativity. Some of the phase transitions were found to be second (or higher)
order which makes a possibility of taking continuum limit viable. Here we
present new results of changing the spatial topology to that of the 3-torus. We
argue that the topology change does not change the phase structure nor the
order of the phase transitions. Therefore CDT results seem to be universal
independent of the topology chosen.",http://arxiv.org/abs/1912.00240v1
Multi-Agent Deep Reinforcement Learning with Adaptive Policies,2019-11-28T07:23:37Z,"Yixiang Wang, Feng Wu","We propose a novel approach to address one aspect of the non-stationarity
problem in multi-agent reinforcement learning (RL), where the other agents may
alter their policies due to environment changes during execution. This violates
the Markov assumption that governs most single-agent RL methods and is one of
the key challenges in multi-agent RL. To tackle this, we propose to train
multiple policies for each agent and postpone the selection of the best policy
at execution time. Specifically, we model the environment non-stationarity with
a finite set of scenarios and train policies fitting each scenario. In addition
to multiple policies, each agent also learns a policy predictor to determine
which policy is the best with its local information. By doing so, each agent is
able to adapt its policy when the environment changes and consequentially the
other agents alter their policies during execution. We empirically evaluated
our method on a variety of common benchmark problems proposed for multi-agent
deep RL in the literature. Our experimental results show that the agents
trained by our algorithm have better adaptiveness in changing environments and
outperform the state-of-the-art methods in all the tested environments.",http://arxiv.org/abs/1912.00949v1
Proving Data-Poisoning Robustness in Decision Trees,2019-12-02T18:20:54Z,"Samuel Drews, Aws Albarghouthi, Loris D'Antoni","Machine learning models are brittle, and small changes in the training data
can result in different predictions. We study the problem of proving that a
prediction is robust to data poisoning, where an attacker can inject a number
of malicious elements into the training set to influence the learned model. We
target decision-tree models, a popular and simple class of machine learning
models that underlies many complex learning techniques. We present a sound
verification technique based on abstract interpretation and implement it in a
tool called Antidote. Antidote abstractly trains decision trees for an
intractably large space of possible poisoned datasets. Due to the soundness of
our abstraction, Antidote can produce proofs that, for a given input, the
corresponding prediction would not have changed had the training set been
tampered with or not. We demonstrate the effectiveness of Antidote on a number
of popular datasets.",http://arxiv.org/abs/1912.00981v2
Periodic mode changing in PSR J1048-5832,2019-12-03T02:46:00Z,"W. M. Yan, R. N. Manchester, N. Wang, Z. G. Wen, J. P. Yuan, K. J. Lee, J. L. Chen","By analysing the data acquired from the Parkes 64-m radio telescope at 1369
MHz, we report on the phase-stationary non-drift amplitude modulation observed
in PSR J1048-5832. The high-sensitivity observations revealed that the central
and trailing components of the pulse profile of this pulsar switch between a
strong mode and a weak mode periodically. However, the leading component
remains unchanged. Polarization properties of the strong and weak modes are
investigated. Considering the similarity to mode changing, we argue that the
periodic amplitude modulation in PSR J1048$-$5832 is periodic mode changing.
The fluctuation spectral analysis showed that the modulation period is very
short (~2.1 s or 17 P1), where P1 is the rotation period of the pulsar. We find
that this periodic amplitude modulation is hard to explain by existing models
that account for the periodic phenomena in pulsars like subpulse drifting.",http://arxiv.org/abs/1912.01165v1
Adaptive Online Planning for Continual Lifelong Learning,2019-12-03T04:29:01Z,"Kevin Lu, Igor Mordatch, Pieter Abbeel","We study learning control in an online reset-free lifelong learning scenario,
where mistakes can compound catastrophically into the future and the underlying
dynamics of the environment may change. Traditional model-free policy learning
methods have achieved successes in difficult tasks due to their broad
flexibility, but struggle in this setting, as they can activate failure modes
early in their lifetimes which are difficult to recover from and face
performance degradation as dynamics change. On the other hand, model-based
planning methods learn and adapt quickly, but require prohibitive levels of
computational resources. We present a new algorithm, Adaptive Online Planning
(AOP), that achieves strong performance in this setting by combining
model-based planning with model-free learning. By approximating the uncertainty
of the model-free components and the planner performance, AOP is able to call
upon more extensive planning only when necessary, leading to reduced
computation times, while still gracefully adapting behaviors in the face of
unpredictable changes in the world -- even when traditional RL fails.",http://arxiv.org/abs/1912.01188v2
"Entropy-Based Formulation of Thermodynamics in Arbitrary Quantum
  Evolution",2019-12-04T12:57:51Z,"S. Alipour, A. T. Rezakhani, A. Chenu, A. del Campo, T. Ala-Nissila","Given the evolution of an arbitrary open quantum system, we formulate a
general and unambiguous method to separate the internal energy change of the
system into an entropy-related contribution and a part causing no entropy
change, identified as heat and work, respectively. We also demonstrate that
heat and work admit geometric and dynamical descriptions by developing a
universal dynamical equation for the given trajectory of the system. The
dissipative and coherent parts of this equation contribute exclusively to heat
and work, where the specific role of a work contribution from a counterdiabatic
drive is underlined. Next we define an expression for the irreversible entropy
production of the system which does not have explicit dependence on the
properties of the ambient environment; rather, it depends on a set of the
system's observables excluding its Hamiltonian and is independent of internal
energy change. We illustrate our results with three examples.",http://arxiv.org/abs/1912.01939v4
"Charge density wave sliding driven by an interplay of conventional and
  Hall voltages in NbSe$_3$ microbridges",2019-12-04T16:06:40Z,"A. V. Frolov, A. P. Orlov, A. A. Sinchenko, P. Monceau","Collective charge-density wave (CDW) transport was measured under a high
magnetic field in NbSe$_3$ microbridges which have been cut transversely and at
an angle to the chains' direction. We give evidences that the CDW sliding is
driven by the Hall voltage generated by the inter-chain current of normal
carriers. We have discovered a re-entrance effect of the Hall-driven sliding
above a crossover temperature at which the Hall constant has been known to
change sign. For the narrow channel, cut at 45$^\circ$ relative to the chain
axis, we observed an evolution from the Hall-driven sliding at low
temperatures, to the conventional sliding at higher temperatures, which
corroborates with falling of the Hall constant. In this course, the nonlinear
contribution to the conductivity coming from the collective sliding changes
sign. The quantization of Shapiro-steps, generated presumably by a coherent
sequence of phase slips, indicates that their governing changes from the
applied voltage to the current.",http://arxiv.org/abs/1912.02075v1
Chromatin Structure Changes in Human Disease: A Mini Review,2019-12-06T06:25:03Z,Yuriy Shckorbatov,"There are many experimental data indicating the correlations of the changes
in high level of organization of chromatin in human cells and changes in the
state of the whole organism related to disease, state of tiredness or aging. In
our previous work: arXiv.org-2018 (1812.00186) we analyzed the publications on
the topic up to 2017. In this work we focused on works upon the problem of
connection of the state of chromatin with human diseases published in
2018-2019. In the modern literature the most attention is paid to problem of
chromatin transformations in different forms of cancer, Alzheimer'r disease,
and hereditary diseases. Summing up, the tendency of scientific research of
noncommunicable diseases is shifting towards investigation of aspects of
nuclear regulation of disease origin, connected with conformation of chromatin.",http://arxiv.org/abs/1912.02991v1
Dark matter filtering-out effect during a first-order phase transition,2019-12-09T18:24:49Z,"Dongjin Chway, Tae Hyun Jung, Chang Sub Shin","If the mass of dark matter is generated from a cosmological phase transition
involving the nucleation of bubbles, the corresponding bubble walls can filter
out dark matter particles during the phase transition. Only particles with
sufficient momentum to overcome their mass inside the bubbles can pass through
the walls. As a result, the dark matter number density after the phase
transition has a suppression factor $\exp(-M_\chi/2\tilde \gamma T)$, where
$M_\chi$ is the dark matter mass, and $\tilde \gamma$ and $T$ are the Lorentz
factor and temperature of the incoming fluid in the bubble wall rest frame,
respectively. Under certain assumptions, we show that the filtering-out process
can naturally provide a large suppression consistent with the observed dark
matter density for a wide range of dark matter masses up to the Planck scale.
Since the first-order phase transition is the decisive ingredient in our
mechanism, a new connection is made between heavy dark matter scenarios and
gravitational wave observations.",http://arxiv.org/abs/1912.04238v2
"Emergence and spectral-weight transfer of electronic states in the
  Hubbard ladder",2019-12-11T02:00:33Z,Masanori Kohno,"The number of electronic bands is usually considered invariant regardless of
the electron density in a band picture. However, in interacting systems, the
spectral-weight distribution generally changes depending on the electron
density, and electronic states can even emerge or disappear as the electron
density changes. Here, to clarify how electronic states emerge and become
dominant as the electron density changes, the spectral function of the Hubbard
ladder with strong repulsion and strong intrarung hopping is studied using the
non-Abelian dynamical density-matrix renormalization-group method. A mode
emerging in the low-electron-density limit gains spectral weight as the
electron density increases and governs the dimer Mott physics at
quarter-filling. In contrast, the antibonding band, which is dominant in the
low-electron-density regime, loses spectral weight and disappears at the Mott
transition at half-filling, exhibiting the momentum-shifted magnetic dispersion
relation in the small-doping limit. This paper identifies the origin of the
electronic states responsible for the Mott transition and brings a new
perspective to electronic bands by revealing the overall nature of electronic
states over a wide energy and electron-density regime.",http://arxiv.org/abs/1912.05080v2
Ionization energy of atoms in photonic crystals,2019-12-11T14:18:33Z,"Renat Kh. Gainutdinov, Adel I. Garifullin, Marat A. Khamadeev, Myakzyum Kh. Salakhov","The periodic changes in physical and chemical properties of the chemical
elements is caused by the periodic change of the ionization energies. The
ionization energy of each element is constant and this manifests itself in the
periodic table. However, we show that the ionization energies can be
dramatically changed, when atoms are placed in a photonic crystal consisting of
materials with a highly tunable refractive index and voids. The tunability of
these materials gives rise to the tunability of the ionization energies over a
wide range. This allows one to come beyond the limitations put on by the
periodic table on physical and chemical processes, and can open up new horizons
in synthesizing exceptional chemical compounds that could be used in
pharmaceutical and other medical-related activities.",http://arxiv.org/abs/1912.05336v1
"What it Thinks is Important is Important: Robustness Transfers through
  Input Gradients",2019-12-11T23:51:37Z,"Alvin Chan, Yi Tay, Yew-Soon Ong","Adversarial perturbations are imperceptible changes to input pixels that can
change the prediction of deep learning models. Learned weights of models robust
to such perturbations are previously found to be transferable across different
tasks but this applies only if the model architecture for the source and target
tasks is the same. Input gradients characterize how small changes at each input
pixel affect the model output. Using only natural images, we show here that
training a student model's input gradients to match those of a robust teacher
model can gain robustness close to a strong baseline that is robustly trained
from scratch. Through experiments in MNIST, CIFAR-10, CIFAR-100 and
Tiny-ImageNet, we show that our proposed method, input gradient adversarial
matching, can transfer robustness across different tasks and even across
different model architectures. This demonstrates that directly targeting the
semantics of input gradients is a feasible way towards adversarial robustness.",http://arxiv.org/abs/1912.05699v3
"Hybrid Bound States in Continuum for Enhanced Sensing and Light
  Manipulation",2019-12-12T10:06:51Z,"Maik Meudt, Chakan Bogiadzi, Kevin Wrobel, Patrick Görrn","Light can be influenced by permittivity changes in optical resonators,
enabling optical sensors, modulators and optical switches. It is
straightforward that a high relative change of intensity per change of
permittivity, labelled as figure of merit FOM*, is sought. This FOM* is
proportional to the product of quality factor Q and sensitivity S of the
resonator. In known resonators, an increase of Q is always accompanied by a
decrease of S leaving FOM* constant. Hybridization of resonators has always
been reported to lead to an averaging of their performance, only.
  Here, we theoretically show that light diffracted by bound states in
continuum (BICs) breaks that rule. Its FOM* is strongly increased by
hybridization, thus outperforming both purely dielectric or plasmonic BICs. We
suggest a symmetric waveguide geometry for realising topologically protected
hybrid BICs, develop a polymer based fabrication technology and show first
experimental evidence of hybrid BICs.",http://arxiv.org/abs/1912.05858v1
Data-driven Identification of Occupant Thermostat-Behavior Dynamics,2019-12-13T20:57:25Z,"Michael B. Kane, Kunind Sharma","Building occupant behavior drives significant differences in building energy
use, even in automated buildings. Users' distrust in the automation causes them
to override settings. This results in responses that fail to satisfy both the
occupants' and/or the building automation's objectives. The transition toward
grid-interactive efficient buildings will make this evermore important as
complex building control systems optimize not only for comfort, but also
changing electricity costs. This paper presents a data-driven approach to study
thermal comfort behavior dynamics which are not captured by standard
steady-state comfort models such as predicted mean vote.
  The proposed model captures the time it takes for a user to override a
thermostat setpoint change as a function of the manual setpoint change
magnitude. The model was trained with the ecobee Donate Your Data dataset of 5
min. resolution data from 27,764 smart thermostats and occupancy sensors. The
resulting population-level model shows that, on average, a 2{\deg}F override
will occur after ~30 mins. and an 8{\deg}F override will occur in only ~15
mins., indicating the magnitude of discomfort as a key driver to the swiftness
of an override. Such models could improve demand response programs through
personalized controls.",http://arxiv.org/abs/1912.06705v1
"Continuously Tunable Acoustic Metasurface with Rotatable Anisotropic
  Three-component Resonators",2019-12-16T01:13:57Z,"Pan Li, Yunfan Chang, Qiujiao Du, Zhihong Xu, Meiyu Liu, Pai Peng","We propose a tunable acoustic metasurface consisting of identical units. And
units are rotatable anisotropic three-component resonators, which can induce
the non-degenerate dipolar resonance, causing an evident phase change in low
frequencies. Compared with the monopole resonance widely used in Helmholtz
resonators, the polarization direction of the dipole resonance is a new degree
of freedom for phase manipulation. The proposed metasurface is constructed by
identical units that made with real (not rigid) materials. And the phase
profile can continuously change by rotating the anisotropic resonators. We
present a wide-angle and broad-band acoustic focusing by the metasurface under
a water background.",http://arxiv.org/abs/1912.07149v1
"All-optical continuous tuning of phase-change plasmonic metasurfaces for
  multispectral thermal imaging",2019-12-17T15:38:29Z,"Matthew N. Julian, Calum Williams, Stephen Borg, Scott Bartram, Hyun Jung Kim","Actively tunable, narrowband spectral filtering across arbitrary optical
wavebands is highly desirable in a plethora of applications, from chemical
sensing, hyperspectral imaging to infrared astronomy. Yet, the ability to
actively reconfigure the optical properties of a solid-state narrowband filter
remains elusive. Existing solutions require either moving parts, have slow
response times or provide limited spectral coverage. Here, we demonstrate a
continuously tunable, spectrally-agnostic, all-solid-state, narrowband
phase-change metasurface filter based on a GeSbTe (GST)-embedded plasmonic
nanohole array. The passband of the presented tunable filter is ~74 nm with
~70% transmittance and operates across 3 - 5 $\mu$m; the thermal imaging
waveband. Continuous, reconfigurable tuning is achieved by exploiting
intermediate GST phases via optical switching with a single nanosecond laser
pulse and material stability is verified through multiple switching cycles. We
further demonstrate multispectral thermal imaging in the mid-wave infrared
using our phase-change metasurfaces. Our results pave the way for highly
functional, reduced power, compact hyperspectral imaging systems and optical
filters.",http://arxiv.org/abs/1912.08086v1
Adaptive Scheduling for Efficient Execution of Dynamic Stream Workflows,2019-12-18T05:59:57Z,"Mutaz Barika, Saurabh Garg, Rajiv Ranjan","Stream workflow application such as online anomaly detection or online
traffic monitoring, integrates multiple streaming big data applications into
data analysis pipeline. This application can be highly dynamic in nature, where
the data velocity may change at runtime and therefore the resources should be
managed overtime. To manage these changes, the orchestration of this
application requires a dynamic execution environment and dynamic scheduling
technique. For the former requirement, Multicloud environment is a visible
solution to cope with the dynamic aspects of this workflow application. While
for the latter requirement, dynamic scheduling technique not only need to
adhere to end user's requirements in terms of data processing and deadline for
decision making, and data stream sources location constraints, but also adjust
provisioning and scheduling plan at runtime to cope with dynamic variations of
stream data rates. Therefore, we propose a two-phase adaptive scheduling
technique to efficiently schedule dynamic workflow application in Multicloud
environment that can respond to changes in the velocity of data at runtime. The
experimental results showed that the proposed technique is close to the lower
bound and effective for different experiment scenarios.",http://arxiv.org/abs/1912.08397v1
"Acoustic and Optical Properties of a Fast Spinning Dielectric
  Nanoparticle",2019-12-18T11:40:08Z,"Daniel Hümmer, René Lampert, Katja Kustura, Patrick Maurer, Carlos Gonzalez-Ballestero, Oriol Romero-Isart","Nanoparticles levitated in vacuum can be set to spin at ultimate frequencies,
limited only by the tensile strength of the material. At such high frequencies,
drastic changes to the dynamics of solid-state quantum excitations are to be
expected. Here, we theoretically describe the interaction between acoustic
phonons and the rotation of a nanoparticle around its own axis, and model how
the acoustic and optical properties of the nanoparticle change when it rotates
at a fixed frequency. As an example, we analytically predict the scaling of the
shape, the acoustic eigenmode spectrum, the permittivity, and the
polarizability of a spinning dielectric nanosphere. We find that the changes to
these properties at frequencies of a few gigahertz achieved in current
experiments should be measurable with presents technology. Our work aims at
exploring solid-state quantum excitations in mesoscopic matter under extreme
rotation, a regime that is now becoming accessible with the advent of precision
control over highly isolated levitated nanoparticles.",http://arxiv.org/abs/1912.08537v2
Isospectral flows related to Frobenius-Stickelberger-Thiele polynomials,2019-12-27T08:11:39Z,"Xiang-Ke Chang, Xing-Biao Hu, Jacek Szmigielski, Alexei Zhedanov","The isospectral deformations of the Frobenius-Stickelberger-Thiele (FST)
polynomials introduced in [32](Spiridonov et al. Commun. Math. Phys.
272:139--165, 2007 ) are studied. For a specific choice of the deformation of
the spectral measure, one is led to an integrable lattice (FST lattice), which
is indeed an isospectral flow connected with a generalized eigenvalue problem.
In the second part of the paper the spectral problem used previously in the
study of the modified Camassa-Holm (mCH) peakon lattice is interpreted in terms
of the FST polynomials together with the associated FST polynomials, resulting
in a map from the mCH peakon lattice to a negative flow of the finite FST
lattice. Furthermore, it is pointed out that the degenerate case of the finite
FST lattice unexpectedly maps to the interlacing peakon ODE system associated
with the two-component mCH equation studied in [17](Chang et al. Adv. Math.
299:1--35, 2016).",http://arxiv.org/abs/1912.12019v1
Real World Longitudinal iOS App Usage Study at Scale,2019-12-28T21:42:09Z,"Dohyun Kim, Joshua Gluck, Malcolm Hall, Yuvraj Agarwal","Given the importance of understanding the interaction between mobile devices
and their users, app usage patterns have been studied in various contexts.
However, prior work has not fully investigated longitudinal changes to app
usage behavior. In this paper, we present a longitudinal, large-scale study of
mobile app usage based on a dataset collected from 162,006 iPhones and iPads
over 4 years. We explore multiple dimensions of app usage pattern proving
useful insights on how app usage changes over time. Our key findings include
(i) app usage pattern changes over time both at the individual app level and
the app category level (i.e. proportion of time a user spends using an app),
(ii) users keep a small set of apps frequently launched (90% of iPhone users
launch roughly 14-18 apps weekly), (iii) a small number of apps remain popular
while some specific kinds of apps (e.g. Games) have a shorter life cycle
compared to other apps of different categories. Finally, we discuss our
findings and their implications, for example, a short-term study as an attempt
to understand the general needs of mobile devices may not achieve useful
results for the long term.",http://arxiv.org/abs/1912.12526v1
"Scholarly journal publishing in transition: from restricted to open
  access",2019-12-29T13:29:59Z,Bo-Christer Björk,"While the business models used in most segments of the media industry have
been profoundly changed by the Internet surprisingly little has been changed in
the publishing of scholarly peer reviewed journals. Electronic delivery has
become the norm, but the same publishers as before are dominating the market,
selling content to subscribers. This article asks the question why Open Access
(OA) to the output of mainly publicly funded research hasn't yet become the
mainstream business model. OA implies a reversal of business logic from readers
paying for content to authors paying fro dissemination via universa free
access. The current situation is analyzed using Porter's five forces model. The
analysis demonstrates a lack of competitive pressure in this industry, leading
to so high profit levels of the leading publishers that they have yet to feel a
strong need to change the way they operate.",http://arxiv.org/abs/1912.12646v1
"Lane Change Decision-making through Deep Reinforcement Learning with
  Rule-based Constraints",2019-03-30T15:16:39Z,"Junjie Wang, Qichao Zhang, Dongbin Zhao, Yaran Chen","Autonomous driving decision-making is a great challenge due to the complexity
and uncertainty of the traffic environment. Combined with the rule-based
constraints, a Deep Q-Network (DQN) based method is applied for autonomous
driving lane change decision-making task in this study. Through the combination
of high-level lateral decision-making and low-level rule-based trajectory
modification, a safe and efficient lane change behavior can be achieved. With
the setting of our state representation and reward function, the trained agent
is able to take appropriate actions in a real-world-like simulator. The
generated policy is evaluated on the simulator for 10 times, and the results
demonstrate that the proposed rule-based DQN method outperforms the rule-based
approach and the DQN method.",http://arxiv.org/abs/1904.00231v2
Enhancement of Energy-Based Swing-Up Controller via Entropy Search,2019-04-02T04:56:09Z,"Chang Sik Lee, Dong Eui Chang","An energy based approach for stabilizing a mechanical system has offered a
simple yet powerful control scheme. However, since it does not impose such
strong constraints on parameter space of the controller, finding appropriate
parameter values for an optimal controller is known to be hard. This paper
intends to generate an optimal energy-based controller for swinging up a rotary
inverted pendulum, also known as the Furuta pendulum, by applying the Bayesian
optimization called Entropy Search. Simulations and experiments show that the
optimal controller has an improved performance compared to a nominal controller
for various initial conditions.",http://arxiv.org/abs/1904.01214v2
Adaptive Sequential Machine Learning,2019-04-04T20:03:46Z,"Craig Wilson, Yuheng Bu, Venugopal Veeravalli","A framework previously introduced in [3] for solving a sequence of stochastic
optimization problems with bounded changes in the minimizers is extended and
applied to machine learning problems such as regression and classification. The
stochastic optimization problems arising in these machine learning problems is
solved using algorithms such as stochastic gradient descent (SGD). A method
based on estimates of the change in the minimizers and properties of the
optimization algorithm is introduced for adaptively selecting the number of
samples at each time step to ensure that the excess risk, i.e., the expected
gap between the loss achieved by the approximate minimizer produced by the
optimization algorithm and the exact minimizer, does not exceed a target level.
A bound is developed to show that the estimate of the change in the minimizers
is non-trivial provided that the excess risk is small enough. Extensions
relevant to the machine learning setting are considered, including a cost-based
approach to select the number of samples with a cost budget over a fixed
horizon, and an approach to applying cross-validation for model selection.
Finally, experiments with synthetic and real data are used to validate the
algorithms.",http://arxiv.org/abs/1904.02773v1
Anisotropic magnetocaloric effect in Fe$_{3-x}$GeTe$_2$,2019-04-08T07:31:42Z,"Yu Liu, Jun Li, Jing Tao, Yimei Zhu, C. Petrovic","We present a comprehensive study on anisotropic magnetocaloric porperties of
the van der Waals weak-itinerant ferromagnet Fe$_{3-x}$GeTe$_2$ that features
gate-tunable room-temperature ferromagnetism in few-layer device. Intrinsic
magnetocrystalline anisotropy is observed to be temperature-dependent and most
likely favors the long-range magnetic order in thin Fe$_{3-x}$GeTe$_2$ crsytal.
The magnetic entropy change $-\Delta S_M$ also reveals an anisotropic
characteristic between $H // ab$ and $H // c$, which could be well scaled into
a universal curve. The peak value $-\Delta S_M^{max}$ of 1.20 J kg$^{-1}$
K$^{-1}$ and the corresponding adiabatic temperature change $\Delta T_{ad}$ of
0.66 K are deduced from heat capacity with out-of-plane field change of 5 T. By
fitting of the field-dependent parameters of $-\Delta S_M^{max}$ and the
relative cooling power RCP, it gives $-\Delta S_M^{max} \propto H^n$ with $n =
0.603(6)$ and $RCP \propto H^m$ with $m = 1.20(1)$ when $H // c$. Given the
high and tunable $T_c$, Fe$_{3-x}$GeTe$_2$ crystals are of interest for
fabricating the heterostructure-based spintronics device.",http://arxiv.org/abs/1904.03873v2
"Minimax-Optimal Algorithms for Detecting Changes in Statistically
  Periodic Random Processes",2019-04-06T21:06:23Z,"Taposh Banerjee, Prudhvi Gurram, Gene Whipps","Theory and algorithms are developed for detecting changes in the distribution
of statistically periodic random processes. The statistical periodicity is
modeled using independent and periodically identically distributed processes, a
new class of stochastic processes proposed by us. An algorithm is developed
that is minimax asymptotically optimal as the false alarm rate goes to zero.
Algorithms are also developed for the cases when the post-change distribution
is not known or when there are multiple streams of observations. The modeling
is inspired by real datasets encountered in cyber-physical systems, biology,
and medicine. The developed algorithms are applied to sequences of Instagram
counts collected around a 5K run in New York City to detect the run.",http://arxiv.org/abs/1904.04239v2
"Cusum tests for changes in the Hurst exponent and volatility of
  fractional Brownian motion",2019-04-09T09:20:33Z,Markus Bibinger,"In this letter, we construct cusum change-point tests for the Hurst exponent
and the volatility of a discretely observed fractional Brownian motion. As a
statistical application of the functional Breuer-Major theorems by B\'egyn
(2007) and Nourdin and Nualart (2019), we show under infill asymptotics
consistency of the tests and weak convergence to the Kolmogorov-Smirnov law
under the no-change hypothesis. The test is feasible and pivotal in the sense
that it is based on a statistic and critical values which do not require
knowledge of any parameter values. Consistent estimation of the break date
under the alternative hypothesis is established. We demonstrate the
finite-sample properties in simulations and a data example.",http://arxiv.org/abs/1904.04556v2
Generation & Evaluation of Adversarial Examples for Malware Obfuscation,2019-04-09T17:27:58Z,"Daniel Park, Haidar Khan, Bülent Yener","There has been an increased interest in the application of convolutional
neural networks for image based malware classification, but the susceptibility
of neural networks to adversarial examples allows malicious actors to evade
classifiers. Adversarial examples are usually generated by adding small
perturbations to the input that are unrecognizable to humans, but the same
approach is not effective with malware. In general, these perturbations cause
changes in the byte sequences that change the initial functionality or result
in un-executable binaries. We present a generative model for executable
adversarial malware examples using obfuscation that achieves a high
misclassification rate, up to 100% and 98% in white-box and black-box settings
respectively, and demonstrates transferability. We further evaluate the
effectiveness of the proposed method by reporting insignificant change in the
evasion rate of our adversarial examples against popular defense strategies.",http://arxiv.org/abs/1904.04802v3
Environmental Changes and the Dynamics of Musical Identity,2019-04-09T23:50:42Z,"Samuel F. Way, Santiago Gil, Ian Anderson, Aaron Clauset","Musical tastes reflect our unique values and experiences, our relationships
with others, and the places where we live. But as each of these things changes,
do our tastes also change to reflect the present, or remain fixed, reflecting
our past? Here, we investigate how where a person lives shapes their musical
preferences, using geographic relocation to construct quasi-natural experiments
that measure short- and long-term effects. Analyzing comprehensive data on over
16 million users on Spotify, we show that relocation within the United States
has only a small impact on individuals' tastes, which remain more similar to
those of their past environments. We then show that the age gap between a
person and the music they consume indicates that adolescence, and likely their
environment during these years, shapes their lifelong musical tastes. Our
results demonstrate the robustness of individuals' musical identity, and shed
new light on the development of preferences.",http://arxiv.org/abs/1904.04948v1
Stochastic Comparative Statics in Markov Decision Processes,2019-04-10T23:56:03Z,Bar Light,"In multi-period stochastic optimization problems, the future optimal decision
is a random variable whose distribution depends on the parameters of the
optimization problem. We analyze how the expected value of this random variable
changes as a function of the dynamic optimization parameters in the context of
Markov decision processes. We call this analysis \emph{stochastic comparative
statics}. We derive both \emph{comparative statics} results and
\emph{stochastic comparative statics} results showing how the current and
future optimal decisions change in response to changes in the single-period
payoff function, the discount factor, the initial state of the system, and the
transition probability function. We apply our results to various models from
the economics and operations research literature, including investment theory,
dynamic pricing models, controlled random walks, and comparisons of stationary
distributions.",http://arxiv.org/abs/1904.05481v2
ACE: Adapting to Changing Environments for Semantic Segmentation,2019-04-12T15:15:15Z,"Zuxuan Wu, Xin Wang, Joseph E. Gonzalez, Tom Goldstein, Larry S. Davis","Deep neural networks exhibit exceptional accuracy when they are trained and
tested on the same data distributions. However, neural classifiers are often
extremely brittle when confronted with domain shift---changes in the input
distribution that occur over time. We present ACE, a framework for semantic
segmentation that dynamically adapts to changing environments over the time. By
aligning the distribution of labeled training data from the original source
domain with the distribution of incoming data in a shifted domain, ACE
synthesizes labeled training data for environments as it sees them. This
stylized data is then used to update a segmentation model so that it performs
well in new environments. To avoid forgetting knowledge from past environments,
we introduce a memory that stores feature statistics from previously seen
domains. These statistics can be used to replay images in any of the previously
observed domains, thus preventing catastrophic forgetting. In addition to
standard batch training using stochastic gradient decent (SGD), we also
experiment with fast adaptation methods based on adaptive meta-learning.
Extensive experiments are conducted on two datasets from SYNTHIA, the results
demonstrate the effectiveness of the proposed approach when adapting to a
number of tasks.",http://arxiv.org/abs/1904.06268v1
"A Negotiation-based Right-of-way Assignment Strategy to Ensure Traffic
  Safety and Efficiency in Lane Change",2019-04-13T07:38:54Z,"Can Zhao, Zhiheng Li, Li Li, Xiao Wang, Fei-Yue Wang, Xiangbin Wu","It is widely acknowledged that verifying the safety of autonomous driving
strategies requires a substantial body of simulation testing and road testing.
In recent years, the formal safety methods represented by
Responsibility-Sensitive Safety (RSS) have encouraged low-cost autonomous
driving safety research, benefitting from its accurate assessment of safety and
clear division of responsibilities. However, how to maintain traffic efficiency
while ensuring safety remains a challenge. To address this problem, this paper
proposes a formulized negotiation-based lane-changing strategy that makes a
trade-off between safety and efficiency. Both theoretical analysis and
numerical experimental results shows that compared to RSS, our strategy can
noticeably improve the success rate of changing lanes on the premise of safety.",http://arxiv.org/abs/1904.06500v4
Localizing Discriminative Visual Landmarks for Place Recognition,2019-04-14T06:05:54Z,"Zhe Xin, Yinghao Cai, Tao Lu, Xiaoxia Xing, Shaojun Cai, Jixiang Zhang, Yiping Yang, Yanqing Wang","We address the problem of visual place recognition with perceptual changes.
The fundamental problem of visual place recognition is generating robust image
representations which are not only insensitive to environmental changes but
also distinguishable to different places. Taking advantage of the feature
extraction ability of Convolutional Neural Networks (CNNs), we further
investigate how to localize discriminative visual landmarks that positively
contribute to the similarity measurement, such as buildings and vegetations. In
particular, a Landmark Localization Network (LLN) is designed to indicate which
regions of an image are used for discrimination. Detailed experiments are
conducted on open source datasets with varied appearance and viewpoint changes.
The proposed approach achieves superior performance against state-of-the-art
methods.",http://arxiv.org/abs/1904.06635v1
Mechanism of the Changing Look phenomenon in Active Galactic Nuclei,2019-04-14T22:00:03Z,"Marzena Śniegowska, Bożena Czerny","Changing-look phenomenon observed now in a growing number of active galaxies
challenges our understanding of the accretion process close to a black hole. We
propose a simple explanation for periodic outbursts in sources operating at a
few per cent of the Eddington limit. The mechanism is based on two relatively
well understood phenomena: radiation pressure instability and formation of the
inner optically thin Advection-Dominated Accretion Flow. The limit cycle
behaviour takes place in a relatively narrow transition zone between the
standard disk and optically thin flow. Large changes in the cold disk are due
to the irradiation by the hot flow with accretion rate strongly varying during
the cycle. The model gives quantitative predictions and works well for multiple
outbursts of NGC 1566.",http://arxiv.org/abs/1904.06767v2
"Efficient Motion Planning for Automated Lane Change based on Imitation
  Learning and Mixed-Integer Optimization",2019-04-18T13:47:17Z,"Chenyang Xi, Tianyu Shi, Yuankai Wu, Lijun Sun","Intelligent motion planning is one of the core components in automated
vehicles, which has received extensive interests. Traditional motion planning
methods suffer from several drawbacks in terms of optimality, efficiency and
generalization capability. Sampling based methods cannot guarantee the
optimality of the generated trajectories. Whereas the optimization-based
methods are not able to perform motion planning in real-time, and limited by
the simplified formalization. In this work, we propose a learning-based
approach to handle those shortcomings. Mixed Integer Quadratic Problem based
optimization (MIQP) is used to generate the optimal lane-change trajectories
which served as the training dataset for learning-based action generation
algorithms. A hierarchical supervised learning model is devised to make the
fast lane-change decision. Numerous experiments have been conducted to evaluate
the optimality, efficiency, and generalization capability of the proposed
approach. The experimental results indicate that the proposed model outperforms
several commonly used motion planning baselines.",http://arxiv.org/abs/1904.08784v4
"Strain-Induced Reversible Manipulation of Orbital Magnetic Moments in
  Ni/Cu Multilayers on Ferroelectric BaTiO3",2019-04-22T05:01:10Z,"Jun Okabayashi, Yoshio Miura, Tomoyasu Taniyama","Controlling magnetic anisotropy by orbital magnetic moments related to
interfacial strains has considerable potential for the development of future
devices using spins and orbitals. For the fundamental physics, the relationship
between strain and orbital magnetic moment is still unknown, because there are
few tools to probe changes of orbital magnetic moment. In this study, we
developed an electric-field- (E)-induced X-ray magnetic circular dichroism
(EXMCD) technique to apply E to a ferroelectric BaTiO3 substrate. We reversibly
tuned the interfacial lattice constants of Ni/Cu multilayers on BaTiO3 using
this technique. As the domain structures in BaTiO3 are modulated by E, EXMCD
measurements reveal that the changes in the magnetic anisotropy of Ni/Cu films
are induced through the modulation of orbital magnetic moments in Ni with
magneto-elastic contributions. The strained Ni layer that induces the
perpendicular magnetic anisotropy without E is released at E = 8 kV/cm, and
in-plane magnetization also occurs. We observed that EXMCD measurements
clarified the origin of the reversible changes in perpendicular magnetic
anisotropy and established the relationship between macroscopic inverse
magnetostriction effects and microscopic orbital moment anisotropy.",http://arxiv.org/abs/1904.09719v1
"ICT Capital-Skill Complementarity and Wage Inequality: Evidence from
  OECD Countries",2019-04-22T13:25:45Z,"Hiroya Taniguchi, Ken Yamada","Although wage inequality has evolved in advanced countries over recent
decades, it remains unknown the extent to which changes in wage inequality and
their differences across countries are attributable to specific capital and
labor quantities. We examine this issue by estimating a sector-level production
function extended to allow for capital-skill complementarity and factor-biased
technological change using cross-country and cross-industry panel data. Our
results indicate that most of the changes in the skill premium are attributable
to the relative quantities of ICT equipment, skilled labor, and unskilled labor
in the goods and service sectors of the majority of advanced countries.",http://arxiv.org/abs/1904.09857v5
"Health Behaviour Change Techniques in Diabetes Management Applications:
  A Systematic Review",2019-04-22T14:03:03Z,"Ahmed Fadhil, Yunlong Wang","The rapid growth in mobile healthcare technology could significantly help
control chronic diseases, such as diabetes. This paper presents a systematic
review to characterise type 1 & type 2 diabetes management applications
available in Apple's iTunes store. We investigated ""Health & Fitness"" and
""Medical"" apps following a two-step filtering process (Selection and Analysis
phases). We firstly investigated the apps compliance to the persuasive system
design (PSD) model. We then characterised the behaviour change techniques
(BCTs) of top-ranked apps for diabetes management. Finally, we checked the apps
regarding the stages of disease continuum. The findings revealed apps
incorporation some PSD principles based on their configuration and behaviour
change techniques. Most apps miss the element of BCT and focus on measuring
exercise and caloric intake. Few apps consider managing specific diabetes type,
which raises doubts about the effectiveness of those apps in providing
sustainable diabetes management. Moreover, people may need multiple apps to
initiate and maintain a healthy behaviour.",http://arxiv.org/abs/1904.09884v1
"Autonomous Voltage Control for Grid Operation Using Deep Reinforcement
  Learning",2019-04-24T01:34:04Z,"Ruisheng Diao, Zhiwei Wang, Di Shi, Qianyun Chang, Jiajun Duan, Xiaohu Zhang","Modern power grids are experiencing grand challenges caused by the stochastic
and dynamic nature of growing renewable energy and demand response. Traditional
theoretical assumptions and operational rules may be violated, which are
difficult to be adapted by existing control systems due to the lack of
computational power and accurate grid models for use in real time, leading to
growing concerns in the secure and economic operation of the power grid.
Existing operational control actions are typically determined offline, which
are less optimized. This paper presents a novel paradigm, Grid Mind, for
autonomous grid operational controls using deep reinforcement learning. The
proposed AI agent for voltage control can learn its control policy through
interactions with massive offline simulations, and adapts its behavior to new
changes including not only load/generation variations but also topological
changes. A properly trained agent is tested on the IEEE 14-bus system with tens
of thousands of scenarios, and promising performance is demonstrated in
applying autonomous voltage controls for secure grid operation.",http://arxiv.org/abs/1904.10597v1
"Presenting Static Friction Sensation at Stick-slip Transition using
  Pseudo-haptic Effect",2019-04-26T05:32:40Z,"Yusuke Ujitoko, Yuki Ban, Koichi Hirota","Previous studies have aimed at creating a simple hardware implementation of
surface friction display. In this study, we propose a new method for presenting
static frictional sensation using the pseudo-haptic effect as a first attempt,
which is the simplest implementation of presenting static friction sensation.
We focus on the stick-slip phenomenon while users explore surfaces with an
input device, such as a stylus. During the stick phase, we present users with
pseudo-haptic feedback that represents static friction on the surface. In our
method, users watch a virtual contact point become stuck at the contact point
on screen while users freely move the input device. We hypothesize that the
perceived probability and intensity of static friction sensation can be
controlled by changing the static friction coefficient as a visual parameter.
User studies were conducted, and results show the threshold value over which
users felt the pseudo-haptic static friction sensation at 90% probability. The
results also show that the perceived intensity of the sensation changed with
respect to the static friction coefficient. The maximum intensity change was
23%. These results confirm the hypothesis and show that our method is a
promising option for presenting static friction sensation.",http://arxiv.org/abs/1904.11676v1
Phase-change silicon as an ultrafast active photonic platform,2019-04-26T06:41:49Z,"Letian Wang, Matthew Eliceiri, Yang Deng, Yoonsoo Rho, Wan Shou, Heng Pan, Jie Yao, Costas P. Grigoropoulos","Phase change material (PCM) features distinct optical or electronic
properties between amorphous and crystalline states. Recently, it starts to
play a key role in the emerging photonic applications like optoelectronic
display, dynamic wavefront control, on-chip photonic memory and computation.
However, current PCMs do not refract effectively at visible wavelengths and
suffer from deformation and decomposition, limiting the repeatability and vast
visible wavelength applications. Silicon as the fundamental material for
electronics and photonics, has never been considered as phase change material,
due to its ultrafast crystallization kinetics. Here we show the striking fact
that nanoscale silicon domains can be reversibly crystallized and amorphized
under nanosecond laser pulses. For a typical disk resonator, it also provides a
25% non-volatile modulation at nanosecond time scale. We further show
proof-of-concept experiments that such attributes could enable ultra-high
resolution dielectric color display and dynamic visible wavefront control.",http://arxiv.org/abs/1904.11691v1
"First Observed Metal-like to Insulator Transition in the vacant 3d
  orbital Quantum Spin Liquid Tb$_2$Ti$_2$O$_7$",2019-04-29T07:50:34Z,"B. Santhosh Kumar, C. Venkateswaran","We report the observation of metal-like to insulator transition (MTI) in the
3dpyrochlore oxide Tb2Ti2O7 at 603 K due to the interaction of empty 3d
orbitals of Ti4+ with O2- ions, evidenced by the transition in resistivity.
Magnetisation, specific heat capacity and differential scanning calorimetry
support the MTI, and the transition is of second order. An appreciable change
in magnetisation with temperature, without any magnetic phase transition, is a
behaviour typical in this family of compounds which is seldom observed in empty
d orbital pyrochlores. The possible mechanism that supports the MTI in Tb2Ti2O7
is discussed. Subsequently, a broad change in magnetisation from 696 K is also
seen. Thermogravimetric analysis confirms the observed MTI (603 K) and the
broad change in magnetisation (696 K)are not due to oxygen vacancy",http://arxiv.org/abs/1904.12478v6
"A first-principles study on the lattice thermal conductivity of
  irradiated glassy states of the Ge$_2$Sb$_2$Te$_5$ phase-change memory
  material",2019-06-03T14:45:32Z,"Felix C. Mocanu, Konstantinos Konstantinou, Stephen R. Elliott","An analysis of thermal transients from non-equilibrium ab initio
molecular-dynamics simulations can be used to calculate the thermal
conductivity of materials with a short phonon mean-free path. We adapt the
approach-to-equilibrium methodology to the three-dimensional case of a
simulation that consists of a cubic core region at higher temperature
approaching thermal equilibrium with a thermostatted boundary. This leads to
estimates of the lattice thermal conductivity for the glassy state of the
phase-change memory material, Ge$_2$Sb$_2$Te$_5$, which are close to previously
reported experimental measurements. Self-atom irradiation of the material,
modelled using thermal spikes and stochastic-boundary conditions, results in
glassy models with a significant reduction of the lattice thermal conductivity
compared to the pristine glassy structure. This approach may prove to be useful
in technological applications, e.g. for the suppression of thermal cross-talk
in phase-change memory and data-storage devices.",http://arxiv.org/abs/1906.00846v2
"Theory of Single Photon Detection by a Photoreceptive Molecule and a
  Quantum Coherent Spin Center",2019-06-05T03:14:18Z,"N. J. Harmon, M. E. Flatté","The long spin coherence times in ambient conditions of color centers in
solids, such as nitrogen-vacancy (NV$^{-}$) centers in diamond, make these
systems attractive candidates for quantum sensing. Quantum sensing provides
remarkable sensitivity at room temperature to very small external
perturbations, including magnetic fields, electric fields, and temperature
changes. A photoreceptive molecule, such as those involved in vision, changes
its charge state or conformation in response to the absorption of a single
photon. We show the resulting change in local electric field modifies the
properties of a nearby quantum coherent spin center in a detectable fashion.
Using the formalism of positive operator values measurements (POVMs), we
analyze the photo-excited electric dipole field and, by extension, the arrival
of a photon based on a measured readout, using a fluorescence cycle, from the
spin center. We determine the jitter time of photon arrival and the probability
of measurement errors. We predict that configuring multiple independent spin
sensors around the photoreceptive molecule would dramatically suppresses the
measurement error.",http://arxiv.org/abs/1906.01800v1
"Theory of Josephson Current on a Magnetically Doped Topological
  Insulator",2019-06-05T10:53:25Z,"Tsubasa Toki, Sho Nakosai, Yukio Tanaka, Yuki Kawaguchi","Proximity induced superconducting states in the surface of magnetically doped
topological insulators can host chiral Majorana modes. We consider a Josephson
junction in that system with changing the chemical potential, which drives a
topological phase transition in the induced superconducting states as well as a
metal-insulator transition in the surface states. The local density of states
and the Josephson current are analytically calculated by McMillan's Green's
function method in terms of the Andreev reflection coefficient. We show that
although the magnitude of the Josephson current is greatly enhanced when the
surface state changes from insulating to metallic, its temperature dependence
drastically changes at the topological phase transition point, reflecting the
appearance of the chiral Majorana modes",http://arxiv.org/abs/1906.01934v1
Measuring the compositionality of noun-noun compounds over time,2019-06-06T13:12:35Z,"Prajit Dhar, Janis Pagel, Lonneke van der Plas","We present work in progress on the temporal progression of compositionality
in noun-noun compounds. Previous work has proposed computational methods for
determining the compositionality of compounds. These methods try to
automatically determine how transparent the meaning of the compound as a whole
is with respect to the meaning of its parts. We hypothesize that such a
property might change over time. We use the time-stamped Google Books corpus
for our diachronic investigations, and first examine whether the vector-based
semantic spaces extracted from this corpus are able to predict compositionality
ratings, despite their inherent limitations. We find that using temporal
information helps predicting the ratings, although correlation with the ratings
is lower than reported for other corpora. Finally, we show changes in
compositionality over time for a selection of compounds.",http://arxiv.org/abs/1906.02563v2
Control of surface states of planar metamaterial based on moire effect,2019-06-06T14:59:15Z,"Sergey Yu. Polevoy, Sergey I. Tarapov","The possibility of continuous tuning of the spectral properties of two types
of planar metamaterials based on the moire effect by changing their geometric
parameters is demonstrated both experimentally and numerically. It is shown
that for a one-dimensional moire metamaterial obtained by superposition of two
microstrip photonic crystals with close periods, the position of the stop band
in the spectrum can be controlled by changing these periods. For the
two-dimensional moire metamaterial formed by two identical periodic crossed
structures with hexagonal symmetry, the ability to control the frequency of the
surface state mode by changing the crossing angle of these structures relative
to each other has been experimentally and numerically shown. It is numerically
demonstrated that if the moire metamaterial is irradiated by the horn antenna,
a surface wave propagating in the metamaterial plane appears in all directions
beginning from its intersection point with the axis of the incident wave beam.
From the application point of view, moire metamaterials of this type can be
considered as promising prototype of microwave filters, whose spectral
properties can be continuously and smoothly mechanically rearranged.",http://arxiv.org/abs/1906.02624v1
A new approach for open-end sequential change point monitoring,2019-06-03T13:56:13Z,"Josua Gösmann, Tobias Kley, Holger Dette","We propose a new sequential monitoring scheme for changes in the parameters
of a multivariate time series. In contrast to procedures proposed in the
literature which compare an estimator from the training sample with an
estimator calculated from the remaining data, we suggest to divide the sample
at each time point after the training sample. Estimators from the sample before
and after all separation points are then continuously compared calculating a
maximum of norms of their differences. For open-end scenarios our approach
yields an asymptotic level $\alpha$ procedure, which is consistent under the
alternative of a change in the parameter. By means of a simulation study it is
demonstrated that the new method outperforms the commonly used procedures with
respect to power and the feasibility of our approach is illustrated by
analyzing two data examples.",http://arxiv.org/abs/1906.03225v4
"Demo Abstract: Fast Feedback Control and Coordination with Mode Changes
  for Wireless Cyber-Physical Systems",2019-06-13T09:04:51Z,"Fabian Mager, Dominik Baumann, Romain Jacob, Lothar Thiele, Sebastian Trimpe, Marco Zimmerling","This abstract describes the first public demonstration of feedback control
and coordination of multiple physical systems over a dynamic multi-hop
low-power wireless network with update intervals of tens of milliseconds. Our
running system can dynamically change between different sets of application
tasks (e.g., sensing, actuation, control) executing on the spatially
distributed embedded devices, while closed-loop stability is provably
guaranteed even across those so-called mode changes. Moreover, any subset of
the devices can move freely, which does not affect closed-loop stability and
control performance as long as the wireless network remains connected.",http://arxiv.org/abs/1906.05554v1
"Flavor changing Flavon decay $φ\to tc$ ($φ=H_F,\,A_F$) at the High
  Luminosity Large Hadron Collider",2019-06-18T21:41:13Z,"M. A. Arroyo-Ureña, A. Fernández-Téllez, G. Tavares-Velasco","We present a study of the flavor changing decays $\phi\to tc$
($\phi=H_F,\,A_F$) of the $CP$-even and $CP$-odd scalar flavons at the large
hadron collider and its next stage, the high-luminosity large hadron collider.
The theoretical framework is an extension of the standard model that
incorporates an extra complex singlet and invokes the Froggatt-Nielsen
mechanism with an Abelian flavor symmetry. The projected exclusion and
discovery regions in terms of the model parameters are reported. We find that
$A_F$ could be detected at the LHC by considering a reasonable scenario of the
model parameter space. As far as $H_F$ is concerned, we also found promising
results that could be verified experimentally at the high-luminosity LHC.",http://arxiv.org/abs/1906.07821v2
MediaPipe: A Framework for Building Perception Pipelines,2019-06-14T05:49:22Z,"Camillo Lugaresi, Jiuqiang Tang, Hadon Nash, Chris McClanahan, Esha Uboweja, Michael Hays, Fan Zhang, Chuo-Ling Chang, Ming Guang Yong, Juhyun Lee, Wan-Teh Chang, Wei Hua, Manfred Georg, Matthias Grundmann","Building applications that perceive the world around them is challenging. A
developer needs to (a) select and develop corresponding machine learning
algorithms and models, (b) build a series of prototypes and demos, (c) balance
resource consumption against the quality of the solutions, and finally (d)
identify and mitigate problematic cases. The MediaPipe framework addresses all
of these challenges. A developer can use MediaPipe to build prototypes by
combining existing perception components, to advance them to polished
cross-platform applications and measure system performance and resource
consumption on target platforms. We show that these features enable a developer
to focus on the algorithm or model development and use MediaPipe as an
environment for iteratively improving their application with results
reproducible across different devices and platforms. MediaPipe will be
open-sourced at https://github.com/google/mediapipe.",http://arxiv.org/abs/1906.08172v1
"Field Dependent Conductivity and Threshold Switching in Amorphous
  Chalcogenides -- Modeling and Simulations of Ovonic Threshold Switches and
  Phase Change Memory Devices",2019-06-21T20:52:22Z,"Jake Scoggin, Helena Silva, Ali Gokirmak","We model electrical conductivity in metastable amorphous $Ge_{2}Sb_{2}Te_{5}$
using independent contributions from temperature and electric field to simulate
phase change memory devices and Ovonic threshold switches. 3D, 2D-rotational,
and 2D finite element simulations of pillar cells capture threshold switching
and show filamentary conduction in the on-state. The model can be tuned to
capture switching fields from ~5 to 40 MV/m at room temperature using the
temperature dependent electrical conductivity measured for metastable amorphous
GST; lower and higher fields are obtainable using different temperature
dependent electrical conductivities. We use a 2D fixed out-of-plane-depth
simulation to simulate an Ovonic threshold switch in series with a
$Ge_{2}Sb_{2}Te_{5}$ phase change memory cell to emulate a crossbar memory
element. The simulation reproduces the pre-switching current and voltage
characteristics found experimentally for the switch + memory cell, isolated
switch, and isolated memory cell.",http://arxiv.org/abs/1906.09316v1
"Observation of drastic electronic structure change in one-dimensional
  moiré crystals",2019-06-22T10:07:34Z,"Sihan Zhao, Pilkyung Moon, Yuhei Miyauchi, Kazunari Matsuda, Mikito Koshino, Ryo Kitaura","We report the first experimental observation of strong coupling effect in
one-dimensional moir\'e crystals. We study one-dimensional double-wall carbon
nanotubes (DWCNTs) in which van der Waals-coupled two single nanotubes form
one-dimensional moir\'e superlattice. We experimentally combine Rayleigh
scattering spectroscopy and electron beam diffraction on the same individual
DWCNTs to probe the optical transitions of structure-identified DWCNTs in the
visible spectral range. Among more than 30 structure-identified DWCNTs
examined, we experimentally observed and identified a drastic change of optical
transition spectrum in DWCNT with chirality (12,11)@(17,16). The origin of the
marked change is attributed to the strong intertube coupling effect in a
moir\'e superlattice formed by two nearly-armchair nanotubes. Our numerical
simulation is consistent to these experimental findings.",http://arxiv.org/abs/1906.09421v2
"Light-induced optical switching in an asymmetric metal-dielectric
  microcavity with phase-change material",2019-06-23T19:58:28Z,"R. Thomas, A. A. Chabanov, I. Vitebskiy, T. Kottos","We propose an infrared power switch based on an asymmetric high-Q microcavity
incorporating a metallic nanolayer in close proximity to a layer made of a
phase-change material (PCM). The microcavity is designed so that when the PCM
layer is in the low-temperature phase, the metallic nanolayer coincides with a
nodal plane of the resonant electric field component, to allow a high resonant
transmittance. As the light intensity exceeds a certain threshold,
light-induced heating of the PCM layer triggers the phase transition
accompanied by an abrupt change in its refractive index in the vicinity of the
transition temperature. The latter results in a shift of the nodal plane away
from the metallic nanolayer, rendering the entire microcavity highly reflective
over a broad frequency range. The nearly binary nature of the PCM refractive
index allows for the low-intensity resonant transmission over a broad range of
ambient temperatures below the transition point.",http://arxiv.org/abs/1906.09640v1
Time-evolving psychological processes over repeated decisions,2019-06-26T04:12:50Z,"David Gunawan, Guy E. Hawkins, Robert Kohn, Minh-Ngoc Tran, Scott D. Brown","Many psychological experiments have subjects repeat a task to gain the
statistical precision required to test quantitative theories of psychological
performance. In such experiments, time-on-task can have sizable effects on
performance, changing the psychological processes under investigation. Most
research has either ignored these changes, treating the underlying process as
static, or sacrificed some psychological content of the models for statistical
simplicity. We use particle Markov chain Monte-Carlo methods to study
psychologically plausible time-varying changes in model parameters. Using data
from three highly-cited experiments we find strong evidence in favor of a
hidden Markov switching process as an explanation of time-varying effects. This
embodies the psychological assumption of ""regime switching"", with subjects
alternating between different cognitive states representing different modes of
decision-making. The switching model explains key long- and short-term dynamic
effects in the data. The central idea of our approach can be applied quite
generally to quantitative psychological theories, beyond the models and data
sets that we investigate.",http://arxiv.org/abs/1906.10838v3
"Dual Adaptivity: A Universal Algorithm for Minimizing the Adaptive
  Regret of Convex Functions",2019-06-26T05:23:26Z,"Lijun Zhang, Guanghui Wang, Wei-Wei Tu, Zhi-Hua Zhou","To deal with changing environments, a new performance measure -- adaptive
regret, defined as the maximum static regret over any interval, was proposed in
online learning. Under the setting of online convex optimization, several
algorithms have been successfully developed to minimize the adaptive regret.
However, existing algorithms lack universality in the sense that they can only
handle one type of convex functions and need apriori knowledge of parameters.
By contrast, there exist universal algorithms, such as MetaGrad, that attain
optimal static regret for multiple types of convex functions simultaneously.
Along this line of research, this paper presents the first universal algorithm
for minimizing the adaptive regret of convex functions. Specifically, we borrow
the idea of maintaining multiple learning rates in MetaGrad to handle the
uncertainty of functions, and utilize the technique of sleeping experts to
capture changing environments. In this way, our algorithm automatically adapts
to the property of functions (convex, exponentially concave, or strongly
convex), as well as the nature of environments (stationary or changing). As a
by product, it also allows the type of functions to switch between rounds.",http://arxiv.org/abs/1906.10851v2
Tuning environmental timescales to evolve and maintain generalists,2019-06-27T19:22:53Z,"Vedant Sachdeva, Kabir Husain, Jiming Sheng, Shenshen Wang, Arvind Murugan","Natural environments can present diverse challenges, but some genotypes
remain fit across many environments. Such `generalists' can be hard to evolve,
out-competed by specialists fitter in any particular environment. Here,
inspired by the search for broadly-neutralising antibodies during B-cell
affinity maturation, we demonstrate that environmental changes on an
intermediate timescale can reliably evolve generalists, even when faster or
slower environmental changes are unable to do so. We find that changing
environments on timescales comparable to evolutionary transients in a
population enhances the rate of evolving generalists from specialists, without
enhancing the reverse process. The yield of generalists is further increased in
more complex dynamic environments, such as a `chirp' of increasing frequency.
Our work offers design principles for how non-equilibrium fitness `seascapes'
can dynamically funnel populations to genotypes unobtainable in static
environments.",http://arxiv.org/abs/1906.11924v1
Studying the Impact of Mood on Identifying Smartphone Users,2019-06-27T20:55:16Z,"Khadija Zanna, Sayde King, Tempestt Neal, Shaun Canavan","This paper explores the identification of smartphone users when certain
samples collected while the subject felt happy, upset or stressed were absent
or present. We employ data from 19 subjects using the StudentLife dataset, a
dataset collected by researchers at Dartmouth College that was originally
collected to correlate behaviors characterized by smartphone usage patterns
with changes in stress and academic performance. Although many previous works
on behavioral biometrics have implied that mood is a source of intra-person
variation which may impact biometric performance, our results contradict this
assumption. Our findings show that performance worsens when removing samples
that were generated when subjects may be happy, upset, or stressed. Thus, there
is no indication that mood negatively impacts performance. However, we do find
that changes existing in smartphone usage patterns may correlate with mood,
including changes in locking, audio, location, calling, homescreen, and e-mail
habits. Thus, we show that while mood is a source of intra-person variation, it
may be an inaccurate assumption that biometric systems (particularly, mobile
biometrics) are likely influenced by mood.",http://arxiv.org/abs/1906.11960v1
"Test for parameter change in the presence of outliers: the density power
  divergence based approach",2019-06-28T13:39:56Z,"Junmo Song, Jiwon Kang","This study considers the problem of testing for a parameter change in the
presence of outliers. For this, we propose a robust test using the objective
function of minimum density power divergence estimator (MDPDE) by Basu et al.
(Biometrika, 1998), and then derive its limiting null distribution. Our test
procedure can be naturally extended to any parametric model to which MDPDE can
be applied. To illustrate this, we apply our test procedure to GARCH models. We
demonstrate the validity and robustness of the proposed test through a
simulation study. In a real data application to the Hang Seng index, our test
locates some change-points that are not detected by the previous tests such as
the score test and the residual-based CUSUM test.",http://arxiv.org/abs/1907.00004v3
"Generative Guiding Block: Synthesizing Realistic Looking Variants
  Capable of Even Large Change Demands",2019-07-02T06:24:21Z,"Minho Park, Hak Gu Kim, Yong Man Ro","Realistic image synthesis is to generate an image that is perceptually
indistinguishable from an actual image. Generating realistic looking images
with large variations (e.g., large spatial deformations and large pose change),
however, is very challenging. Handing large variations as well as preserving
appearance needs to be taken into account in the realistic looking image
generation. In this paper, we propose a novel realistic looking image synthesis
method, especially in large change demands. To do that, we devise generative
guiding blocks. The proposed generative guiding block includes realistic
appearance preserving discriminator and naturalistic variation transforming
discriminator. By taking the proposed generative guiding blocks into generative
model, the latent features at the layer of generative model are enhanced to
synthesize both realistic looking- and target variation- image. With
qualitative and quantitative evaluation in experiments, we demonstrated the
effectiveness of the proposed generative guiding blocks, compared to the
state-of-the-arts.",http://arxiv.org/abs/1907.01187v1
Adapting Stable Matchings to Evolving Preferences,2019-07-02T13:57:10Z,"Robert Bredereck, Jiehua Chen, Dušan Knop, Junjie Luo, Rolf Niedermeier","Adaptivity to changing environments and constraints is key to success in
modern society. We address this by proposing ""incrementalized versions"" of
Stable Marriage and Stable Roommates. That is, we try to answer the following
question: for both problems, what is the computational cost of adapting an
existing stable matching after some of the preferences of the agents have
changed. While doing so, we also model the constraint that the new stable
matching shall be not too different from the old one. After formalizing these
incremental versions, we provide a fairly comprehensive picture of the
computational complexity landscape of Incremental Stable Marriage and
Incremental Stable Roommates. To this end, we exploit the parameters ""degree of
change"" both in the input (difference between old and new preference profile)
and in the output (difference between old and new stable matching). We obtain
both hardness and tractability results, in particular showing a fixed-parameter
tractability result with respect to the parameter ""distance between old and new
stable matching"".",http://arxiv.org/abs/1907.01375v2
"Dynamics of the magnetoelastic phase transition and adiabatic
  temperature change in Mn1.3Fe0.7P0.5Si0.55",2019-07-04T09:55:58Z,"M. Fries, T. Gottschall, F. Scheibel, L. Pfeuffer, K. P. Skokov, I. Skourski, M. Acet, M. Farle, J. Wosnitza, O. Gutfleisch","The adiabatic temperature change DTad of a Mn1.3Fe0.7P0.5Si0.55 Fe2P-type
alloy was measured under different magnetic field-sweep rates from 0.93 Ts-1 to
2870 Ts-1. We find a field-sweep-rate independent magnetocaloric effect due to
a partial alignment of magnetic moments in the paramagnetic region overlapping
with the magnetocaloric effect of the first-order phase transition.
Additionally, the first-order phase transition is not completed even in fields
up to 20 T leading to a non-saturating behavior of DTad. Measurements in
different pulsed fields reveal that the first-order phase transition cannot
follow the fast field changes as previously assumed, resulting in a distinct
field-dependent hysteresis in DTad.",http://arxiv.org/abs/1907.02307v1
"Giant enhancement of Piezo-resistance in ballistic graphene due to
  transverse electric fields",2019-07-05T15:30:55Z,"Abhinaba Sinha, Abhishek Sharma, Ashwin Tulapurkar, V Ramgopal Rao, Bhaskaran Muralidharan","We investigate the longitudinal and transverse piezoresistance effect in
suspended graphene in the ballistic regime. Utilizing parametrized tight
binding Hamiltonian from ab initio calculations along with Landauer quantum
transport formalism, we devise a methodology to evaluate the piezoresistance
effect in 2D materials especially in graphene. We evaluate the longitudinal and
transverse gauge factor of graphene along armchair and zigzag directions in the
linear elastic limit ($0\%$-$10\%$). The longitudinal and transverse gauge
factors are identical along armchair and zigzag directions. Our model predicts
a significant variation ($\approx 1000\% $ change) in transverse gauge factor
compared to longitudinal gauge factor along with sign inversion. The calculated
value of longitudinal gauge factor is $\approx 0.3$ whereas the transverse
gauge factor is $\approx -3.3$. We rationalize our prediction using deformation
of Dirac cone and change in separation between transverse modes due to
longitudinal and transverse strain, leading to an inverse change in gauge
factor. The results obtained herein may serve as a template for high strain
piezoresistance effect of graphene in nano electromechanical systems.",http://arxiv.org/abs/1907.02896v1
"Modeling Symmetric Positive Definite Matrices with An Application to
  Functional Brain Connectivity",2019-07-08T02:28:39Z,"Zhenhua Lin, Dehan Kong, Qiang Sun","In neuroscience, functional brain connectivity describes the connectivity
between brain regions that share functional properties. Neuroscientists often
characterize it by a time series of covariance matrices between functional
measurements of distributed neuron areas. An effective statistical model for
functional connectivity and its changes over time is critical for better
understanding the mechanisms of brain and various neurological diseases. To
this end, we propose a matrix-log mean model with an additive heterogeneous
noise for modeling random symmetric positive definite matrices that lie in a
Riemannian manifold. The heterogeneity of error terms is introduced
specifically to capture the curved nature of the manifold. We then propose to
use the local scan statistics to detect change patterns in the functional
connectivity. Theoretically, we show that our procedure can recover all change
points consistently. Simulation studies and an application to the Human
Connectome Project lend further support to the proposed methodology.",http://arxiv.org/abs/1907.03385v1
"Change point detection for graphical models in the presence of missing
  values",2019-07-11T17:50:47Z,"Malte Londschien, Solt Kovács, Peter Bühlmann","We propose estimation methods for change points in high-dimensional
covariance structures with an emphasis on challenging scenarios with missing
values. We advocate three imputation like methods and investigate their
implications on common losses used for change point detection. We also discuss
how model selection methods have to be adapted to the setting of incomplete
data. The methods are compared in a simulation study and applied to a time
series from an environmental monitoring system. An implementation of our
proposals within the R-package hdcd is available via the Supplementary
materials.",http://arxiv.org/abs/1907.05409v2
"X-Ray spectral evolution of PSR~J2032+4127 during the 2017 periastron
  passage",2019-07-12T11:50:48Z,"Partha Sarathi Pal, P. H. Thomas Tam, Yudong Cui, Kwan Lok Li, Albert K. H. Kong, Can Gungor","We report X-ray data analysis results obtained from Chandra, XMM-Newton,
NuSTAR and Swift observations of PSR J2032+4127 taken before, during, and after
the periastron on 2017 November 13. We found the first clear evidence of a
change in the X-ray spectral index over the passage period, thanks to a broad
and sensitive spectral coverage by XMM-Newton and NuSTAR. We analysed the joint
XMM-Newton and NuSTAR observation epochs with power-law and broken power-law
model. We have obtained change in spectral parameters before and after the
periastron passage for both models. The spectra get softened after the passage.
The evolution of the spectral index and break energy before and after the
periastron may indicate a change in the physical state of shock-accelerated
electrons.",http://arxiv.org/abs/1907.05685v2
Molecular structure elucidation with charge-state control,2019-07-13T15:49:46Z,"Shadi Fatayer, Florian Albrecht, Yunlong Zhang, Darius Urbonas, Diego Peña, Nikolaj Moll, Leo Gross","The charge state of a molecule governs its physicochemical properties, such
as conformation, reactivity and aromaticity, with implications for on-surface
synthesis, catalysis, photo conversion and applications in molecular
electronics. On insulating, multilayer NaCl films we control the charge state
of organic molecules and resolve their structures in neutral, cationic, anionic
and dianionic states by atomic force microscopy, obtaining atomic resolution
and bond-order discrimination using CO functionalized tips. We detect changes
in conformation, adsorption geometry and bond-order relations for azobenzene,
tetracyanoquinodimethane and pentacene in multiple charge states. Moreover, for
porphine we investigate the charge-state-dependent change of aromaticity and
conjugation pathway in the macrocycle. This work opens the way to studying
chemical-structural changes of individual molecules for a wide range of charge
states.",http://arxiv.org/abs/1907.06100v2
Noise Removal of FTIR Hyperspectral Images via MMSE,2019-07-16T04:44:18Z,"Chang Sik Lee, Hyeong Geun Yu, Dong Jo Park, Dong Eui Chang, Hyunwoo Nam, Byeong Hwang Park","Fourier transform infrared (FTIR) hyperspectral imaging systems are deployed
in various fields where spectral information is exploited. Chemical warfare
agent (CWA) detection is one of such fields and it requires a fast and accurate
process from the measurement to the visualization of detection results,
including noise removal. A general concern of existing noise removal algorithms
is a trade-off between time and performance. This paper suggests a minimum mean
square error (MMSE) approach as an efficient noise removal algorithm for FTIR
hyperspectral images. The experimental result shows that the MMSE estimator
spends less time to achieve comparable performance to the existing algorithms.",http://arxiv.org/abs/1907.06834v3
"Optimizing method for Neural Network based on Genetic Random Weight
  Change Learning Algorithm",2019-06-05T09:12:22Z,"Mohammad Ibrahim Sarker, Zubaer Ibna Mannan, Hyongsuk Kim","Random weight change (RWC) algorithm is extremely component and robust for
the hardware implementation of neural networks. RWC and Genetic algorithm (GA)
are well known methodologies used for optimizing and learning the neural
network (NN). Individually, each of these two algorithms has its strength and
weakness along with separate objectives. However, recently, researchers combine
these two algorithms for better learning and optimization of NN. In this paper,
we proposed a methodology by combining the RWC and GA, namely Genetic Random
Weight Change (GRWC), as well as demonstrate a seminal way to reduce the
complexity of the neural network by removing weak weights of GRWC. In contrast
to RWC and GA, GRWC contains an effective optimization procedure which is
worthy at exploring a large and complex space in intellectual strategies
influenced by the GA/RWC synergy. The learning behavior of the proposed
algorithm was tested on MNIST dataset and it was able to prove its performance.",http://arxiv.org/abs/1907.07254v1
