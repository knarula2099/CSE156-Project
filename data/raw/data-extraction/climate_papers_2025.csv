Title,Published,Authors,Abstract,Link
"EpiClim: Weekly District-Wise all-India multi-epidemics Climate-Health
  Dataset for accelerated GeoHealth research",2025-01-17T23:12:08Z,"Gurleen Kaur, Shubham Ghoshal, Manmeet Singh, Reena Marbate, Neetiraj Malviya, Arshmehar Kaur, Vaisakh SB","Climate change significantly impacts public health, driving the emergence and
spread of epidemics. Climate health models are essential for assessing and
predicting disease outbreaks influenced by climatic variables like temperature
and precipitation. For instance, dengue and malaria correlate with temperature
changes, while cholera is linked to precipitation anomalies. Advances in
AI-enabled weather prediction (AI-NWP) have improved forecasting, but
integrating climate models with health systems is hindered by the lack of
comprehensive, granular health datasets. This study introduces EpiClim: India's
Epidemic-Climate Dataset, the first weekly district-wise dataset for major
epidemics in India from 2009 to the present, sourced from the Integrated
Disease Surveillance Programme (IDSP). The dataset, covering diseases like
dengue, malaria, and acute-diarrheal disease, bridges the gap between climate
and health data, enabling the integration of climate forecasts with epidemic
prediction models. This work lays the foundation for coupling predictive
climate health models with weather and climate models, advancing efforts to
mitigate climate-induced public health crises.",http://arxiv.org/abs/2501.18602v1
Analysis of Climatic Trends and Variability in Indian Topography,2025-01-08T15:47:30Z,"Ayush Prusty, Akshita Gupta, Vivek Ashok Bohara","The climatic change is one of the serious concerns nowadays. The impacts of
climate change are global in scope and unprecedented in scale. Moreover, a
small perturbation in climatic changes affects not only the pristine ecosystem
but also the socioeconomic sectors. Specifically, the affect of climatic
changes is related to frequent casualties. This makes it essential to dwelve
deeper into analyzing the socio-climatic trends and variability. This work
provides a comprehensive analysis of India's climatic trends, emphasizing on
regional variations and specifically delving into the unique climate of Delhi.
Specifically, this research unveils the temporal and spatial variations in
temperature patterns by amalgamating extensive datasets encompassing India's
diverse landscapes. The study uses advanced statistical tools and methodologies
to scrutinize temperature's annual and seasonal variability. The insights drawn
from this rigorous analysis may offer invaluable contributions to regional
planning strategies, adaptive measures, and informed decision-making amidst the
complex impacts of climate change. By bridging the gap between broader climatic
trends and localized impacts, this research aims to facilitate more effective
measures to mitigate and adapt to the multifaceted challenges of climate
change, ensuring a more nuanced and tailored approaches. We utilized the
Mann-Kendall test and Theil-Sen's slope estimator to analyze the trends and
variability of the climatic conditions over the decades. The results
demonstrate that temperature variations have increased over 0.58oC on average
over the last decade. Moreover, over last decade the variability of Indian
states shows that Lakshadweep faced the highest change (0.87oC), highlighting
coastal vulnerability, while Tripura observed the least change of 0.07oC.",http://arxiv.org/abs/2501.04578v1
"Social dynamics can delay or prevent climate tipping points by speeding
  the adoption of climate change mitigation",2025-01-23T21:05:22Z,"Yazdan Babazadeh Maghsoodlo, Madhur Anand, Chris T. Bauch","Social behaviour models are increasingly integrated into climate change
studies, and the significance of climate tipping points for `runaway' climate
change is well recognised. However, there has been insufficient focus on
tipping points in social-climate dynamics. We developed a coupled
social-climate model consisting of an Earth system model and a social behaviour
model, both with tipping elements. The social model explores opinion formation
by analysing social learning rates, the net cost of mitigation, and the
strength of social norms. Our results indicate that the net cost of mitigation
and social norms have minimal impact on tipping points when social norms are
weak. As social norms strengthen, the climate tipping point can trigger a
tipping element in the social model. However, faster social learning can delay
or prevent the climate tipping point: sufficiently fast social learning means
growing climate change mitigation can outpace the oncoming climate tipping
point, despite social-climate feedback. By comparing high- and low-risk
scenarios, we demonstrated high-risk scenarios increase the likelihood of
tipping points. We also illustrate the role of a critical temperature anomaly
in triggering tipping points. In conclusion, understanding social behaviour
dynamics is vital for predicting climate tipping points and mitigating their
impacts.",http://arxiv.org/abs/2501.14096v1
"Enhancing LLMs for Governance with Human Oversight: Evaluating and
  Aligning LLMs on Expert Classification of Climate Misinformation for
  Detecting False or Misleading Claims about Climate Change",2025-01-23T16:21:15Z,"Mowafak Allaham, Ayse D. Lokmanoglu, Sol P. Hart, Erik C. Nisbet","Climate misinformation is a problem that has the potential to be
substantially aggravated by the development of Large Language Models (LLMs). In
this study we evaluate the potential for LLMs to be part of the solution for
mitigating online dis/misinformation rather than the problem. Employing a
public expert annotated dataset and a curated sample of social media content we
evaluate the performance of proprietary vs. open source LLMs on climate
misinformation classification task, comparing them to existing climate-focused
computer-assisted tools and expert assessments. Results show (1)
state-of-the-art (SOTA) open-source models substantially under-perform in
classifying climate misinformation compared to proprietary models, (2) existing
climate-focused computer-assisted tools leveraging expert-annotated datasets
continues to outperform many of proprietary models, including GPT-4o, and (3)
demonstrate the efficacy and generalizability of fine-tuning GPT-3.5-turbo on
expert annotated dataset in classifying claims about climate change at the
equivalency of climate change experts with over 20 years of experience in
climate communication. These findings highlight 1) the importance of
incorporating human-oversight, such as incorporating expert-annotated datasets
in training LLMs, for governance tasks that require subject-matter expertise
like classifying climate misinformation, and 2) the potential for LLMs in
facilitating civil society organizations to engage in various governance tasks
such as classifying false or misleading claims in domains beyond climate change
such as politics and health science.",http://arxiv.org/abs/2501.13802v1
"Changes over time in the 100-year return value of climate model
  variables",2025-01-20T18:29:12Z,"Callum Leach, Kevin Ewans, Philip Jonathan","We assess evidence for changes in tail characteristics of wind, solar
irradiance and temperature variables output from CMIP6 global climate models
(GCMs) due to climate forcing. We estimate global and climate zone annual
maximum and annual means for period (2015, 2100) from daily output of seven
GCMs for daily wind speed, maximum wind speed, solar irradiance and
near-surface temperature. We calculate corresponding annualised data for
individual locations within neighbourhoods of the North Atlantic and Celtic Sea
region. We consider output for three climate scenarios and multiple climate
ensembles. We estimate non-stationary extreme value models for annual extremes,
and non-homogeneous Gaussian regressions for annual means, using Bayesian
inference. We use estimated statistical models to quantify the distribution of
(i) the change in 100-year return value for annual extremes, and (2) the change
in annual mean, over the period (2025, 2125). To summarise results, we estimate
linear mixed effects models for observed variation of (i) and (ii). Evidence
for changes in the 100-year return value for annual maxima of solar irradiance
and temperature is much stronger than for wind variables over time and with
climate scenario.",http://arxiv.org/abs/2501.11650v2
"Incivility and Contentiousness Spillover between COVID-19 and Climate
  Science Engagement",2025-02-07T18:08:50Z,"Hasti Narimanzadeh, Arash Badie-Modiri, Iuliia Smirnova, Ted Hsuan Yun Chen","Affective polarization and its accompanying cleavage-based sorting drives
incivility and contentiousness around climate change and other science-related
issues. Looking at the COVID-19 period, we study cross-domain spillover of
incivility and contentiousness in public engagements with climate change and
climate science on Twitter and Reddit. We find strong evidence of the
signatures of affective polarization surrounding COVID-19 spilling into the
climate change domain. Across different social media systems, COVID-19 content
is associated with incivility and contentiousness in climate discussions. These
patterns of increased antagonism were responsive to pandemic events that made
the link between science and public policy more salient. We also show that the
observed spillover activated along pre-pandemic political cleavages,
specifically anti-internationalist populist beliefs, that linked climate policy
opposition to vaccine hesitancy. Our findings highlight the dangers of
entrenched cross-domain polarization manifesting as spillover of antagonistic
behavior.",http://arxiv.org/abs/2502.05255v1
"An Important Decision for Climate Change: Sequestering Carbon in
  Materials or Underground?",2025-01-03T19:40:55Z,Peter Eisenberger,"A first-order analysis concludes it is feasible to store the carbon needed to
meet the Paris targets in structural materials and use less energy and at a
lower cost than our use of extractive materials, steel, aluminum, and concrete.
Switching to a synthetic material industry using CO2 from the air will
stimulate economic growth and create increased equity while addressing the
threat of climate change. The positive feedback between them will accelerate
reaching a global accord to address the dual threats of climate change and
equity and may, in fact, be needed to avoid the catastrophic consequences of
failing to meet them on time.",http://arxiv.org/abs/2501.02075v1
Intraseasonal atmospheric variability under climate trends,2025-02-03T11:51:23Z,"Bernardo Maraldi, Henk Dijkstra, Michael Ghil","Low-order climate models can play an important role in understanding
low-frequency variability in the atmospheric circulation and how forcing
consistent with anthropogenic climate change may affect this variability. Here,
we study a conceptual model of the mid-latitudes' atmospheric circulation from
the perspective of nonautonomous dynamical systems. First, a bifurcation
analysis is carried out under time-independent forcing in order to identify
different types of behavior in the autonomous model's parameter space. Next, we
focus on the study of the nonautonomous system in which the cross-latitudinal
heat flux varies seasonally, according to insolation changes. The forward
attractor of the seasonally forced model is compared with the attractor of the
autonomous one. The seasonal forcing results in a clear change of the
attractor's shape. The summer attractor loses its periodicity, and hence
predictability, when the forcing is seasonal, while the winter attractor favors
energy transport through one of the model's two wave components. Climate change
forcing produces several remarkable effects. Thus, the analysis of the model's
snapshot attractor under climate trends suggests that the jet speed does not
always follow the sign of the change in equator-to-pole thermal contrast, while
the change in the energy transported by the eddies does. Chaotic behavior can
be completely suppressed in favor of a regular periodic one and vice-versa.
Circulation patterns can change, suddenly disappear, and rebuild. The model's
snapshot attractor proves to be a robust tool to study its changes in internal
variability due to climate trends, both positive and negative.",http://arxiv.org/abs/2502.01279v1
"Chinese Historical Documents Reveal Multi-Century Seasonal Shifts in
  Tropical Cyclone Landfalls",2025-02-01T02:24:08Z,"Gan Zhang, Kuanhui Elaine Lin, Dan Fu, Tom Knutson, Jörg Franke, Wan-Ling Tseng","Paleoclimate records reveal a fuller range of natural climate variability
than modern records and are essential for better understanding the modern
climate change. However, most paleoclimate records are point-based proxies and
lack the temporal resolution needed to analyze spatiotemporal changes in
destructive extremes like tropical cyclones (TCs). Here we show that historical
records by pre-industrial Chinese intellectuals help investigate long-term
variability of TC landfalls in East Asia. Despite inherent limitations, these
records show a landfalling TC climatology resembling modern observations in
spatial-temporal distributions. Comparisons between the pre-industrial records
(1776-1850), modern observations (1946-2020), and climate simulations reveal an
earlier seasonal occurrence of modern TCs. However, the variations of
seasonally aggregated landfall time show pronounced multi-century variations.
The modern changes and multi-decade trends appear moderate compared to
long-term variability in pre-industrial TC records, suggesting that an
overreliance on modern data may lead to an underestimation of the full range of
TC activity potentially arising from natural variability alone. Analyses of
newly available climate data reveal associations between past landfalling TC
activity and the large-scale climate variability of tropical ocean and
extratropical land. These findings demonstrate the value of paleoclimate data
for exploring natural variability in TC activity and inform the development of
effective adaptation strategies for future climate change.",http://arxiv.org/abs/2502.00276v1
"Removing Atmospheric Carbon Dioxide Using Large Land Or Ocean Areas Will
  Change Earth Albedo And Force Climate",2025-01-03T16:33:22Z,"J. B. Marston, Daniel E. Ibarra","When large surface areas of the Earth are altered, radiative forcing due to
changes in surface reflectance can drive climate change. Yet to achieve the
necessary scale to remove the substantial amounts of carbon dioxide from the
atmosphere relevant for ameliorating climate change, enhanced rock weathering
(ERW) will need to be applied to very large land areas. Likewise, marine carbon
dioxide removal (mCDR) must alter a large fraction of the ocean surface waters
to have a significant impact upon climate. We show that surface albedo
modification (SAM) associated with ERW or mCDR can easily overwhelm the
radiative forcing from the decrease of atmospheric CO2 over years or even
decades. A change in albedo as small as parts per thousand has a radiative
impact comparable to the removal of 10 tons of carbon per hectare. SAM via ERW
can be either cooling or warming. We identify some of the many questions raised
by radiative forcing due to these forms of CDR.",http://arxiv.org/abs/2501.01885v2
Opportunities and challenges of quantum computing for climate modelling,2025-02-14T12:25:06Z,"Mierk Schwabe, Lorenzo Pastori, Inés de Vega, Pierre Gentine, Luigi Iapichino, Valtteri Lahtinen, Martin Leib, Jeanette M. Lorenz, Veronika Eyring","Adaptation to climate change requires robust climate projections, yet the
uncertainty in these projections performed by ensembles of Earth system models
(ESMs) remains large. This is mainly due to uncertainties in the representation
of subgrid-scale processes such as turbulence or convection that are partly
alleviated at higher resolution. New developments in machine learning-based
hybrid ESMs demonstrate great potential for systematically reduced errors
compared to traditional ESMs. Building on the work of hybrid (physics + AI)
ESMs, we here discuss the additional potential of further improving and
accelerating climate models with quantum computing. We discuss how quantum
computers could accelerate climate models by solving the underlying
differential equations faster, how quantum machine learning could better
represent subgrid-scale phenomena in ESMs even with currently available noisy
intermediate-scale quantum devices, how quantum algorithms aimed at solving
optimisation problems could assist in tuning the many parameters in ESMs, a
currently time-consuming and challenging process, and how quantum computers
could aid in the analysis of climate models. We also discuss hurdles and
obstacles facing current quantum computing paradigms. Strong interdisciplinary
collaboration between climate scientists and quantum computing experts could
help overcome these hurdles and harness the potential of quantum computing for
this urgent topic.",http://arxiv.org/abs/2502.10488v1
"Network science disentangles internal climate variability in global
  spatial dependence structures",2025-01-24T21:51:31Z,"Arnob Ray, Abhirup Banerjee, Rachindra Mawalagedara, Auroop R. Ganguly","A comprehensive characterization of internal climate variability and
irreducible uncertainty through initial-condition large ensembles of Earth
system models across different spatiotemporal scales remains a significant
challenge in climate science. In this study, we find significant differences in
the spatial connectivity structures of temperature networks across ensemble
members, with variations in long-range connections providing a distinguishing
feature across the outcomes of initial conditions. Based on this, we introduce
a novel quantifier, the 'Connectivity Ratio' (R), to encapsulate the spatial
connectivity structure of each ensemble member by investigating the influence
of internal climate variability on the global connectivity patterns in air
temperatures. R allows us to characterize the variability of spatial dependence
structure across the initial condition ensemble members as well as multiple
models. Furthermore, we examine changes in spatial connectivity between
near-term and long-term projections using R, which shows a potential shift in
climate predictability under anthropogenic influence on a spatial scale.",http://arxiv.org/abs/2501.14937v1
"Integrating Spatiotemporal Vision Transformer into Digital Twins for
  High-Resolution Heat Stress Forecasting in Campus Environments",2025-02-12T05:27:16Z,"Wenjing Gong, Xinyue Ye, Keshu Wu, Suphanut Jamonnak, Wenyu Zhang, Yifan Yang, Xiao Huang","Extreme heat events exacerbated by climate change pose significant challenges
to urban resilience and planning. This study introduces a climate-responsive
digital twin framework integrating the Spatiotemporal Vision Transformer
(ST-ViT) model to enhance heat stress forecasting and decision-making. Using a
Texas campus as a testbed, we synthesized high-resolution physical model
simulations with spatial and meteorological data to develop fine-scale human
thermal predictions. The ST-ViT-powered digital twin enables efficient,
data-driven insights for planners, policymakers, and campus stakeholders,
supporting targeted heat mitigation strategies and advancing climate-adaptive
urban design.",http://arxiv.org/abs/2502.09657v1
"Redefining Influenza Transmission Seasonality Using the Novel
  Seasonality Index",2025-01-23T16:42:36Z,"Branislava Lalic, Vladimir Koci, Ana Firanj Sremac, Zorana Jovanovic Andersen","The impact of climate conditions on influenza epidemiology has mostly been
studied by addressing a singular aspect of transmission and a climate variable
correlating to it. As climate change unfolds at an unprecedented rate, we
urgently need new multidisciplinary approaches that can embrace complexity of
disease transmission in the fast-changing environment and help us better
understand the implications for health. In this study, we have implemented a
novel seasonality index to capture a vast network of climate, infectious, and
socio-behavioural mechanisms influencing a seasonal influenza epidemic. We
hypothesize that intricate, region-specific behavioural patterns are cross
regulating the influenza spreading and dynamics of epidemics with changes in
meteorological conditions within a specific season. To better understand the
phenomena, we analysed weekly surveillance data from temperate European
countries and redefined seasonal transitions using the seasonality index. This
approach allowed us to characterize influenza seasonality more accurately in
relation to specific atmospheric conditions. Key findings include: i) a strong
correlation between influenza infection rates and the seasonality index across
different climate zones and social groups, and ii) a high linear correlation
between winter duration, determined by the seasonality index, and the time
scale of low-frequency peaks in the infection rates power spectral density.",http://arxiv.org/abs/2501.13821v1
"Solar radiation and atmospheric CO$_2$ predict young leaf production in
  a moist evergreen tropical forest: Insights from 23 years",2025-01-13T16:49:43Z,"Laura Lüthy, Colin A. Chapman, Patrick Lauer, Patrick Omeja, Urs Kalbitzer","Climate change impacts ecosystems worldwide, affecting animal behaviour and
survival both directly and indirectly through changes such as the availability
of food. For animals reliant on leaves as a primary food source, understanding
how climate change influences leaf production of trees is crucial, yet this is
understudied, especially in moist evergreen tropical forests. We analyzed a
23-year dataset of young leaf phenology from a moist tropical forest in Kibale
National Park, Uganda, to examine seasonal and long-term patterns of 12 key
tree species consumed by folivorous primates. We described phenological
patterns and explored relationships between young leaf production of different
tree species and climate variables. We also assessed the suitability of the
Enhanced Vegetation Index (EVI) as a proxy for young leaf production in moist
evergreen tropical forests. Our results showed that tree species exhibited
distinct phenological patterns, with most species producing young leaves during
two seasonal peaks aligned with the rainy seasons. Rainfall, cloud cover, and
maximum temperature were the most informative predictors of seasonal variation
in young leaf production. However, solar radiation and atmospheric CO$_2$ were
most informative regarding long-term trends. EVI was strongly correlated with
young leaf production within years but less effective for capturing
inter-annual trends. These findings highlight the complex relationship between
climate and young leaf phenology in moist evergreen tropical forests, and helps
us understand the changes in food availability for tropical folivores.",http://arxiv.org/abs/2501.07620v1
"The Norwegian-Polish CCS Network: A Case Study in Bilateral
  Collaboration for European Climate Action",2025-01-09T19:25:06Z,"Mohammad Nooraiepour, Pawel Gladysz, Eirik Melaaen","In the face of escalating climate change, achieving significant reductions in
greenhouse gas emissions from hard-to-abate industrial sectors is imperative.
Carbon Capture and Storage (CCS) represents an essential technological
advancement to achieve sustainable decarbonization. This manuscript reports on
the bilateral CCS network between Norway and Poland, designed and implemented
to leverage their capabilities to expedite technology deployment via mutual
cooperation and accelerate CCS initiatives targeted to member states'
challenges across Europe, aiming for a meaningful contribution to climate
goals. Norway is renowned for its operational acumen, as demonstrated by
landmark projects like Sleipner and Snohvit, and its forward-looking
initiatives, such as the open-source cross-border Northern Lights project,
which offer advanced infrastructure and expertise. Conversely, Poland,
characterized by its coal-dependent economy and the challenge of decarbonizing
extensive industrial emissions, presents a significant geological CO2 storage
potential, estimated at over 15.5 gigatonnes. This study delves into the
potential synergies derived from collaborative endeavors in academic education,
research and development, industrial implementation, regulatory coherence, and
public engagement. By underscoring the reciprocal benefits of such partnership,
the study underscores the indispensable role of bilateral cooperation in
harnessing CCS's capabilities to meet the EU's ambitious climate objectives,
paving the way toward a sustainable and low-carbon future. Additionally, it
outlines a scalable model for fostering and supporting broader bilateral and
multi-lateral collaborations, emphasizing the pivotal role of interconnected
networks in shaping effective global climate action strategies.",http://arxiv.org/abs/2501.05539v3
"Refined climatologies of future precipitation over High Mountain Asia
  using probabilistic ensemble learning",2025-01-26T22:35:24Z,"Kenza Tazi, Sun Woo P. Kim, Marc Girona-Mata, Richard E. Turner","High Mountain Asia holds the largest concentration of frozen water outside
the polar regions, serving as a crucial water source for more than 1.9 billion
people. In the face of climate change, precipitation represents the largest
source of uncertainty for hydrological modelling in this area. Future
precipitation predictions remain challenging due to complex orography, lack of
in situ hydrological observations, and limitations in climate model resolution
and parametrisation for this region. To address the uncertainty posed by these
challenges, climate models are often aggregated into multi-model ensembles.
While multi-model ensembles are known to improve the predictive accuracy and
analysis of future climate projections, consensus regarding how models are
aggregated is lacking. In this study, we propose a probabilistic machine
learning framework to systematically combine 13 regional climate models from
the Coordinated Regional Downscaling Experiment (CORDEX) over High Mountain
Asia. Our approach accounts for seasonal and spatial biases within the models,
enabling the prediction of more faithful precipitation distributions. The
framework is validated against gridded historical precipitation data and is
used to generate projections for the near-future (2036-2065) and far-future
(2066-2095) under RCP4.5 and RCP8.5 scenarios.",http://arxiv.org/abs/2501.15690v1
"Social and Genetic Ties Drive Skewed Cross-Border Media Coverage of
  Disasters",2025-01-13T11:24:52Z,"Thiemo Fetzer, Prashant Garg","Climate change is increasing the frequency and severity of natural disasters
worldwide. Media coverage of these events may be vital to generate empathy and
mobilize global populations to address the common threat posed by climate
change. Using a dataset of 466 news sources from 123 countries, covering 135
million news articles since 2016, we apply an event study framework to measure
cross-border media activity following natural disasters. Our results shows that
while media attention rises after disasters, it is heavily skewed towards
certain events, notably earthquakes, accidents, and wildfires. In contrast,
climatologically salient events such as floods, droughts, or extreme
temperatures receive less coverage. This cross-border disaster reporting is
strongly related to the number of deaths associated with the event, especially
when the affected populations share strong social ties or genetic similarities
with those in the reporting country. Achieving more balanced media coverage
across different types of natural disasters may be essential to counteract
skewed perceptions. Further, fostering closer social connections between
countries may enhance empathy and mobilize the resources necessary to confront
the global threat of climate change.",http://arxiv.org/abs/2501.07615v1
The Role of Science in the Climate Change Discussions on Reddit,2025-02-07T15:56:21Z,"Paolo Cornale, Michele Tizzani, Fabio Ciulla, Kyriaki Kalimeri, Elisa Omodei, Daniela Paolotti, Yelena Mejova","Collective and individual action necessary to address climate change hinges
on the public's understanding of the relevant scientific findings. In this
study, we examine the use of scientific sources in the course of 14 years of
public deliberation around climate change on one of the largest social media
platforms, Reddit. We find that only 4.0% of the links in the Reddit posts, and
6.5% in the comments, point to domains of scientific sources, although these
rates have been increasing in the past decades. These links are dwarfed,
however, by the citations of mass media, newspapers, and social media, the
latter of which peaked especially during 2019-2020. Further, scientific sources
are more likely to be posted by users who also post links to sources having
central-left political leaning, and less so by those posting more polarized
sources. Unfortunately, scientific sources are not often used in response to
links to unreliable sources.",http://arxiv.org/abs/2502.05026v1
Nuclear Explosions for Large Scale Carbon Sequestration,2025-01-11T19:18:00Z,Andrew Haverly,"Confronting the escalating threat of climate change requires innovative and
large-scale interventions. This paper presents a bold proposal to employ a
buried nuclear explosion in a remote basaltic seabed for pulverizing basalt,
thereby accelerating carbon sequestration through Enhanced Rock Weathering
(ERW). By precisely locating the explosion beneath the seabed, we aim to
confine debris, radiation, and energy while ensuring rapid rock weathering at a
scale substantial enough to make a meaningful dent in atmospheric carbon
levels. Our analysis outlines the parameters essential for efficient carbon
capture and minimal collateral effects, emphasizing that a yield on the order
of gigatons is critical for global climate impact. Although this approach may
appear radical, we illustrate its feasibility by examining safety factors,
preservation of local ecosystems, political considerations, and financial
viability. This work argues for reimagining nuclear technology not merely as a
destructive force but as a potential catalyst for decarbonization, thereby
inviting further exploration of pioneering solutions in the fight against
climate change.",http://arxiv.org/abs/2501.06623v1
"CarbonChat: Large Language Model-Based Corporate Carbon Emission
  Analysis and Climate Knowledge Q&A System",2025-01-03T08:45:38Z,"Zhixuan Cao, Ming Han, Jingtao Wang, Meng Jia","As the impact of global climate change intensifies, corporate carbon
emissions have become a focal point of global attention. In response to issues
such as the lag in climate change knowledge updates within large language
models, the lack of specialization and accuracy in traditional augmented
generation architectures for complex problems, and the high cost and time
consumption of sustainability report analysis, this paper proposes CarbonChat:
Large Language Model-based corporate carbon emission analysis and climate
knowledge Q&A system, aimed at achieving precise carbon emission analysis and
policy understanding.First, a diversified index module construction method is
proposed to handle the segmentation of rule-based and long-text documents, as
well as the extraction of structured data, thereby optimizing the parsing of
key information.Second, an enhanced self-prompt retrieval-augmented generation
architecture is designed, integrating intent recognition, structured reasoning
chains, hybrid retrieval, and Text2SQL, improving the efficiency of semantic
understanding and query conversion.Next, based on the greenhouse gas accounting
framework, 14 dimensions are established for carbon emission analysis, enabling
report summarization, relevance evaluation, and customized responses.Finally,
through a multi-layer chunking mechanism, timestamps, and hallucination
detection features, the accuracy and verifiability of the analysis results are
ensured, reducing hallucination rates and enhancing the precision of the
responses.",http://arxiv.org/abs/2501.02031v1
"Exploring the economic, social and environmental prospects for
  commercial natural annual grasslands by performing a sensitivity analysis on
  a multidisciplinary integrated model",2025-01-28T18:41:10Z,"Javier Ibáñez, Jaime Martínez-Valderrama, Joaquín Francisco Lavado Contador, Manuel Pulido Fernández","This paper presents an integrated modelling assessment that estimated the
sensitivities of five endogenous factors in commercial rangelands, i.e. number
of active farmers, profits, stocking rate, standing herbage biomass, and soil
erosion, to the same percentage variation in 70 factors, including economic and
climate drivers. The assessment utilised a system dynamics model (107
equations) which represents an area of extensive private farms, its farmers,
the main local markets on which they trade, and key ecosystem services
involved. The assessment procedure consisted in analysing the behaviours of
288,000 variants of this system during 300 years, each under a different
economic and climate scenario. Our key findings were as follows: 1) It is
likely that at least annual grasslands will suffer environmental degradation in
the future, and that such degradation will be primarily caused by climate
change, not by the increasing demand for livestock products; 2) Private farming
systems provide social and economic security to farmers against the effects of
climate change, especially in a scenario of rising prices of animal products.
However, this research will remain incomplete until its methods and results can
be contrasted with other similar assessments.",http://arxiv.org/abs/2501.17215v1
Diving Deep: Forecasting Sea Surface Temperatures and Anomalies,2025-01-10T05:55:14Z,"Ding Ning, Varvara Vetrova, Karin R. Bryan, Yun Sing Koh, Andreas Voskou, N'Dah Jean Kouagou, Arnab Sharma","This overview paper details the findings from the Diving Deep: Forecasting
Sea Surface Temperatures and Anomalies Challenge at the European Conference on
Machine Learning and Principles and Practice of Knowledge Discovery in
Databases (ECML PKDD) 2024. The challenge focused on the data-driven
predictability of global sea surface temperatures (SSTs), a key factor in
climate forecasting, ecosystem management, fisheries management, and climate
change monitoring. The challenge involved forecasting SST anomalies (SSTAs)
three months in advance using historical data and included a special task of
predicting SSTAs nine months ahead for the Baltic Sea. Participants utilized
various machine learning approaches to tackle the task, leveraging data from
ERA5. This paper discusses the methodologies employed, the results obtained,
and the lessons learned, offering insights into the future of climate-related
predictive modeling.",http://arxiv.org/abs/2501.05731v1
"A Smart IoT Framework for Climate-Resilient and Sustainable Maize
  Farming In Uganda",2025-01-21T20:20:36Z,"Nomugisha Godwin, Dr Mwebaze Johnson","This study provides a framework that incorporates the Internet of Things
(IoT) technology into maize farming activities in Central Uganda as a solution
to various challenges including climate change, sub-optimal resource use and
low crop yields. Using IoT-based modeling and simulation, the presented
solution recommends cost-effective and efficient approaches to irrigation, crop
yield improvement enhancement and prevention of drinking water loss while being
practical for smallholder farmers. The framework is developed in a manner that
is appropriate for low resource use regions by using local strategies that are
easily understandable and actionable for the farmers thus solving the issue of
technology access and social economic constraints. Research in this area
brought to light the promise that the IoT holds for the evolution of
agriculture into a more data-informed, climate-smart sector, contributes to the
much-needed food in the world, is economically viable, facilitates sustainable
rural development and is a huge step for the agriculture modernization of
Uganda.",http://arxiv.org/abs/2501.12483v1
"Dynamic and thermodynamic contributions to future extreme-rainfall
  intensification: a case study for Belgium",2025-02-04T16:00:04Z,"Jozefien Schoofs, Kobe Vandelanotte, Hans Van de Vyver, Line Van Der Sichel, Matthias Vandersteene, Fien Serras, Nicole P. M. van Lipzig, Bert Van Schaeybroeck","Extreme precipitation is projected to become more frequent and more intense
due to climate change and associated thermodynamical effects, but the local
response of atmospheric circulation under future climate scenarios remains
uncertain due mainly to dynamical differences. In this study, we outline a
methodology for a regional assessment of future extreme precipitation based on
the Lamb Weather Type classification and to evaluate future changes in weather
patterns. While anticyclonic days occur most frequently over Belgium, extreme
rainfall is mostly associated with days of cyclonic, westerly and
south-westerly weather patterns. GCMs from CMIP6 are first selected based on
their reliability in representing local atmospheric circulation patterns during
days with extreme rainfall days. It was found that for our case study over
Belgium, the future (end-of-the-century SSP3-7.0) changes in intensity and
likelihood of rainfall extremes can be primarily attributed to thermodynamic
factors, with minimal contribution from changes in atmospheric dynamics. Both
intensity and probability of extreme rainfall increase for all seasons. While
extreme-rainfall probabilities mostly increase in fall and winter, the
associated intensity changes are dominated by positive changes in spring and
summer. Additionally, the weather patterns that are historically associated
with extreme rainfall, disproportionally contribute to these changes,
especially to thermodynamic changes. More specifically, robust changes arise
from an increased extreme-rainfall occurrence probability in case of cyclonic,
south-westerly and westerly circulation types.",http://arxiv.org/abs/2502.02436v1
Seasonal Changes -- Time for Paradigm Shift,2025-01-22T13:42:41Z,"Branislava Lalic, Ana Firanj Sremac","Season and their transitions play a critical role in sharpening ecosystems
and human activities, yet traditional classifications, meteorological and
astronomical, fail to capture the complexities of biosphere-atmosphere
interactions. Conventional definitions often overlook the interplay between
climate variables, biosphere processes, and seasonal anticipation, particularly
as global climate change disrupts traditional patterns. This study addresses
the limitations of current seasonal classification by proposing a framework
based on phenological markers such as NDVI, EVI, LAI, fPAR, and the Bowen
ratio, using plants as a nature-based sensor of seasonal transitions.
Indicators derived from satellite data and ground observations provide robust
foundations for defining seasonal boundaries. The normalized daily temperature
range (DTRT), validated in crop and orchard regions, is hypothesized as a
reliable seasonality index to capture transitions. We demonstrated the
alignment of this index with phenological markers across boreal, temperate, and
deciduous forests. Analyzing trends, extreme values and inflection points in
the seasonality index time series, we established a methodology to identify
seasonal onset, duration, and transitions. This universal, scalable
classification aligns with current knowledge and perception of seasonal shifts
and captures site-specific timing. Findings reveal shifts in the
Euro-Mediterranean region, with winters shortening, summers extending, and
transitions becoming more pronounced. Effects include the Gulf Stream s
influence on milder transitions, urban heat islands accelerating seasonal
shifts, and large inland lakes moderating durations. This underscores the
importance of understanding seasonal transitions to enable climate change
adaptive strategies in agriculture, forestry, urban planning, medicine, trade,
marketing, and tourism.",http://arxiv.org/abs/2501.12882v1
Rain from Solar Scattering,2025-01-12T22:26:52Z,Aya Thompson,"Herein we propose a method mimicking natural processes for the creation of
precipitation, rain, in a safe, economically feasible manner anywhere in the
world. We propose accomplishing this via changing the target of the well
established field of aerosol dispersal for large scale climate cooling from
long term cooling to short term, locally targeted dispersal. We show that such
should induce precipitation anywhere with sufficient humidity, and should be
accomplishable at low cost and low or no safety concerns.",http://arxiv.org/abs/2501.12402v1
"The Resurgence of Trumponomics: Implications for the Future of ESG
  Investments in a Changing Political Landscape",2025-02-04T15:43:37Z,Innocentus Alhamis,"Public policy shapes the economic landscape, influencing everything from
corporate behavior to individual investment decisions. For Environmental,
Social, and Governance (ESG) investors, these policy shifts can create
opportunities and challenges as they navigate an ever-changing regulatory
environment. The contrast between the Trump and Biden administrations offers a
striking example of how differing political agendas can affect ESG investments.
Trump's first term was marked by deregulation and policies favoring fossil
fuels, which created an uncertain environment for sustainable investments. When
Biden assumed office, his focus on climate action and clean energy
reinvigorated the ESG sector, offering a more stable and supportive landscape
for green investments. However, with Trump's return to power in his second
term, these policies are being reversed again, leading to further volatility.
This paper explores how such dramatic shifts in public policy influence
economic strategies and directly impact ESG investors' decisions, forcing them
to constantly reassess their portfolios in response to changing political
climates.",http://arxiv.org/abs/2502.02627v1
"Advancing Carbon Capture using AI: Design of permeable membrane and
  estimation of parameters for Carbon Capture using linear regression and
  membrane-based equations",2025-01-23T04:28:35Z,"Bishwash Panerua, Biplov Paneru","This study focuses on membrane-based systems for CO$_2$ separation,
addressing the urgent need for efficient carbon capture solutions to mitigate
climate change. Linear regression models, based on membrane equations, were
utilized to estimate key parameters, including porosity ($\epsilon$) of 0.4805,
Kozeny constant (K) of 2.9084, specific surface area ($\sigma$) of 105.3272
m$^2$/m$^3$, mean pressure (Pm) of 6.2166 MPa, viscosity ($\mu$) of 0.1997
Ns/m$^2$, and gas flux (Jg) of 3.2559 kg m$^{-2}$ s$^{-1}$. These parameters
were derived from the analysis of synthetic datasets using linear regression.
The study also provides insights into the performance of the membrane, with a
flow rate (Q) of 9.8778 $\times$ 10$^{-4}$ m$^3$/s, an injection pressure
(P$_1$) of 2.8219 MPa, and an exit pressure (P$_2$) of 2.5762 MPa. The
permeability value of 0.045 for CO$_2$ indicates the potential for efficient
separation. Optimizing membrane properties to selectively block CO$_2$ while
allowing other gases to pass is crucial for improving carbon capture
efficiency. By integrating these technologies into industrial processes,
significant reductions in greenhouse gas emissions can be achieved, fostering a
circular carbon economy and contributing to global climate goals. This study
also explores how artificial intelligence (AI) can aid in designing membranes
for carbon capture, addressing the global climate change challenge and
supporting the Sustainable Development Goals (SDGs) set by the United Nations.",http://arxiv.org/abs/2501.13373v1
Circular Microalgae-Based Carbon Control for Net Zero,2025-02-04T15:01:44Z,"Federico Zocco, Joan García, Wassim M. Haddad","The alteration of the climate in various areas of the world is of increasing
concern since climate stability is a necessary condition for human survival as
well as every living organism. The main reason of climate change is the
greenhouse effect caused by the accumulation of carbon dioxide in the
atmosphere. In this paper, we design a networked system underpinned by
compartmental dynamical thermodynamics to circulate the atmospheric carbon
dioxide. Specifically, in the carbon dioxide emitter compartment, we develop an
initial-condition-dependent finite-time stabilizing controller that guarantees
stability within a desired time leveraging the system property of affinity in
the control. Then, to compensate for carbon emissions we show that a
cultivation of microalgae with a volume 625 times bigger than the one of the
carbon emitter is required. To increase the carbon uptake of the microalgae, we
implement the nonaffine-in-the-control microalgae dynamical equations as an
environment of a state-of-the-art library for reinforcement learning (RL),
namely, Stable-Baselines3, and then, through the library, we test the
performance of eight RL algorithms for training a controller that maximizes the
microalgae absorption of carbon through the light intensity. All the eight
controllers increased the carbon absorption of the cultivation during a
training of 200,000 time steps with a maximum episode length of 200 time steps
and with no termination conditions. This work is a first step towards
approaching net zero as a classical and learning-based network control problem.
The source code is publicly available.",http://arxiv.org/abs/2502.02382v1
Discontinuous stochastic forcing in Greenland ice core data,2025-02-12T14:55:19Z,"Keno Riechers, Andreas Morr, Klaus Lehnertz, Pedro G. Lind, Niklas Boers, Dirk Witthaut, Leonardo Rydin Gorjão","Paleoclimate proxy records from Greenland ice cores, archiving e.g.
$\delta^{18}$O as a proxy for surface temperature, show that sudden climatic
shifts called Dansgaard-Oeschger events (DO) occurred repeatedly during the
last glacial interval. They comprised substantial warming of the Arctic region
from cold to milder conditions. Concomitant abrupt changes in the dust
concentrations of the same ice cores suggest that sudden reorganisations of the
hemispheric-scale atmospheric circulation have accompanied the warming events.
Genuine bistability of the North Atlantic climate system is commonly
hypothesised to explain the existence of stadial (cold) and interstadial
(milder) periods in Greenland. However, the physical mechanisms that drove
abrupt transitions from the stadial to the interstadial state, and more gradual
yet still abrupt reverse transitions, remain debated. Here, we conduct a
one-dimensional data-driven analysis of the Greenland temperature and
atmospheric circulation proxies under the purview of stochastic processes. We
take the Kramers-Moyal equation to estimate each proxy's drift and diffusion
terms within a Markovian model framework. We then assess noise contributions
beyond Gaussian white noise. The resulting stochastic differential equation
(SDE) models feature a monostable drift for the Greenland temperature proxy and
a bistable one for the atmospheric circulation proxy. Indicators of
discontinuity in stochastic processes suggest to include higher-order terms of
the Kramers-Moyal equation when modelling the Greenland temperature proxy's
evolution. This constitutes a qualitative difference in the characteristics of
the two time series, which should be further investigated from the standpoint
of climate dynamics.",http://arxiv.org/abs/2502.08460v1
"OceanChat: The Effect of Virtual Conversational AI Agents on Sustainable
  Attitude and Behavior Change",2025-02-05T03:45:33Z,"Pat Pataranutaporn, Alexander Doudkin, Pattie Maes","Marine ecosystems face unprecedented threats from climate change and plastic
pollution, yet traditional environmental education often struggles to translate
awareness into sustained behavioral change. This paper presents OceanChat, an
interactive system leveraging large language models to create conversational AI
agents represented as animated marine creatures -- specifically a beluga whale,
a jellyfish, and a seahorse -- designed to promote environmental behavior (PEB)
and foster awareness through personalized dialogue. Through a between-subjects
experiment (N=900), we compared three conditions: (1) Static Scientific
Information, providing conventional environmental education through text and
images; (2) Static Character Narrative, featuring first-person storytelling
from 3D-rendered marine creatures; and (3) Conversational Character Narrative,
enabling real-time dialogue with AI-powered marine characters. Our analysis
revealed that the Conversational Character Narrative condition significantly
increased behavioral intentions and sustainable choice preferences compared to
static approaches. The beluga whale character demonstrated consistently
stronger emotional engagement across multiple measures, including perceived
anthropomorphism and empathy. However, impacts on deeper measures like climate
policy support and psychological distance were limited, highlighting the
complexity of shifting entrenched beliefs. Our work extends research on
sustainability interfaces facilitating PEB and offers design principles for
creating emotionally resonant, context-aware AI characters. By balancing
anthropomorphism with species authenticity, OceanChat demonstrates how
interactive narratives can bridge the gap between environmental knowledge and
real-world behavior change.",http://arxiv.org/abs/2502.02863v1
"Will artificial intelligence accelerate or delay the race between
  nuclear energy technology budgeting and net-zero emissions?",2025-01-29T04:25:03Z,"Danish, Adnan Khan","This study explores the impact of nuclear energy technology budgeting and
artificial intelligence on carbon dioxide (CO2) emissions in 20 OECD economies.
Unlike previous research that relied on conventional panel techniques, we
utilize the Method of Moment Quantile Regression panel data estimation
techniques. This approach provides quantile-specific insights while addressing
issues of endogeneity and heteroscedasticity, resulting in a more nuanced and
robust understanding of complex relationships. A novel aspect of this research
work is introducing the moderating effect of artificial intelligence on the
relationship between nuclear energy and CO2 emissions. The results found that
the direct impact of artificial intelligence on CO2 emissions is significant,
while the effect of nuclear energy technology budgeting is not. Additionally,
artificial intelligence moderates the relationship between nuclear energy
technology budgeting and CO2 emissions, aiding nuclear energy in reducing
carbon emissions across OECD countries. Our findings indicate that
transitioning to a low-carbon future is achievable by replacing fossil fuel
energy sources with increased integration of artificial intelligence to promote
nuclear energy technologies. This study demonstrates that energy innovations
can serve as effective climate-resilience strategies to mitigate the impacts of
climate change.",http://arxiv.org/abs/2501.17410v1
Spatial Distribution-Shift Aware Knowledge-Guided Machine Learning,2025-02-20T18:52:24Z,"Arun Sharma, Majid Farhadloo, Mingzhou Yang, Ruolei Zeng, Subhankar Ghosh, Shashi Shekhar","Given inputs of diverse soil characteristics and climate data gathered from
various regions, we aimed to build a model to predict accurate land emissions.
The problem is important since accurate quantification of the carbon cycle in
agroecosystems is crucial for mitigating climate change and ensuring
sustainable food production. Predicting accurate land emissions is challenging
since calibrating the heterogeneous nature of soil properties, moisture, and
environmental conditions is hard at decision-relevant scales. Traditional
approaches do not adequately estimate land emissions due to
location-independent parameters failing to leverage the spatial heterogeneity
and also require large datasets. To overcome these limitations, we proposed
Spatial Distribution-Shift Aware Knowledge-Guided Machine Learning (SDSA-KGML),
which leverages location-dependent parameters that account for significant
spatial heterogeneity in soil moisture from multiple sites within the same
region. Experimental results demonstrate that SDSA-KGML models achieve higher
local accuracy for the specified states in the Midwest Region.",http://arxiv.org/abs/2502.14840v1
"Understanding Computational Science and Domain Science Skills
  Development in National Laboratory Graduate Internships",2025-01-17T23:31:57Z,"Morgan M. Fong, Hilary Egan, Marc Day, Kristin Potter, Michael J. Martin","Contribution: This study presents an evaluation of federally-funded graduate
internship outcomes in computational science at a national laboratory.
Additionally, we present a survey instrument that may be used for other
internship programs with a similar focus. Background: There is ongoing demand
for computational scientists to grapple with large-scale problems such as
climate change. Internships may help provide additional training and access to
greater compute capabilities for graduate students. However, little work has
been done to quantify the learning outcomes of such internships. Background:
There is ongoing demand for computational scientists to grapple with
large-scale problems such as climate change. Internships may help provide
additional training and access to greater compute capabilities for graduate
students. However, little work has been done to quantify the learning outcomes
of such internships. Research Questions: What computational skills, research
skills, and professional skills do graduate students improve through their
internships at NREL, the national laboratory selected for the study? What
sustainability and renewable energy topics do graduate students gain more
familiarity with through their internships at NREL? Do graduate students'
career interests change after their internships at NREL? Methodology: We
developed a survey and collected responses from past participants of five
federally-funded internship programs and compare participant ratings of their
prior experience to their internship experience. Findings: Our results indicate
participants improve their computational skills, familiarity with
sustainability and renewable energy topics, and are more interested in working
at national labs. Additionally, participants go on to degree programs and
positions related to sustainability and renewable energy after their
internships.",http://arxiv.org/abs/2501.10601v1
Quantifying firm-level risks from nature deterioration,2025-01-24T10:44:26Z,Ricardo Crisóstomo,"We estimate the loss of value that companies might suffer from nature
overexploitation. We find that global equities shed 26.8% in a scenario of
unabated nature decline, while the worst-performing firms lose ~75% of their
value. Our risk framework considers five environmental hazards: biodiversity
loss, land degradation, climate change, human population and nature capital. We
also introduce two metrics to assess nature-related risks: a Country
Degradation Index that tracks the damage caused by environmental hazards in
specific territories, including nonlinear dynamics and tipping points; and a
Nature Risk Score that summarizes the risk that companies face due to the
decline of nature and its services.",http://arxiv.org/abs/2501.14391v2
A Statistical Learning Approach to Mediterranean Cyclones,2025-01-26T22:46:11Z,"L. Roveri, L. Fery, L. Cavicchia, F. Grotto","Mediterranean cyclones are extreme meteorological events of which much less
is known compared to their tropical, oceanic counterparts. The raising interest
in such phenomena is due to their impact on a region increasingly more affected
by climate change, but a precise characterization remains a non trivial task.
In this work we showcase how a Bayesian algorithm (Latent Dirichlet Allocation)
can classify Mediterranean cyclones relying on wind velocity data, leading to a
drastic dimensional reduction that allows the use of supervised statistical
learning techniques for detecting and tracking new cyclones.",http://arxiv.org/abs/2501.15694v1
Probabilistic Joint Recovery Method for CO$_2$ Plume Monitoring,2025-01-30T21:32:01Z,"Zijun Deng, Rafael Orozco, Abhinav Prakash Gahlot, Felix J. Herrmann","Reducing CO$_2$ emissions is crucial to mitigating climate change. Carbon
Capture and Storage (CCS) is one of the few technologies capable of achieving
net-negative CO$_2$ emissions. However, predicting fluid flow patterns in CCS
remains challenging due to uncertainties in CO$_2$ plume dynamics and reservoir
properties. Building on existing seismic imaging methods like the Joint
Recovery Method (JRM), which lacks uncertainty quantification, we propose the
Probabilistic Joint Recovery Method (pJRM). By estimating posterior
distributions across surveys using a shared generative model, pJRM provides
uncertainty information to improve risk assessment in CCS projects.",http://arxiv.org/abs/2501.18761v1
"Estimating forest carbon stocks from high-resolution remote sensing
  imagery by reducing domain shift with style transfer",2025-02-02T12:45:46Z,"Zhenyu Yu, Jinnian Wang","Forests function as crucial carbon reservoirs on land, and their carbon sinks
can efficiently reduce atmospheric CO2 concentrations and mitigate climate
change. Currently, the overall trend for monitoring and assessing forest carbon
stocks is to integrate ground monitoring sample data with satellite remote
sensing imagery. This style of analysis facilitates large-scale observation.
However, these techniques require improvement in accuracy. We used GF-1 WFV and
Landsat TM images to analyze Huize County, Qujing City, Yunnan Province in
China. Using the style transfer method, we introduced Swin Transformer to
extract global features through attention mechanisms, converting the carbon
stock estimation into an image translation.",http://arxiv.org/abs/2502.00784v1
"Entity Linking using LLMs for Automated Product Carbon Footprint
  Estimation",2025-02-11T09:54:39Z,"Steffen Castle, Julian Moreno Schneider, Leonhard Hennig, Georg Rehm","Growing concerns about climate change and sustainability are driving
manufacturers to take significant steps toward reducing their carbon
footprints. For these manufacturers, a first step towards this goal is to
identify the environmental impact of the individual components of their
products. We propose a system leveraging large language models (LLMs) to
automatically map components from manufacturer Bills of Materials (BOMs) to
Life Cycle Assessment (LCA) database entries by using LLMs to expand on
available component information. Our approach reduces the need for manual data
processing, paving the way for more accessible sustainability practices.",http://arxiv.org/abs/2502.07418v1
"Causal pathway from AMOC to Southern Amazon rainforest indicates
  stabilising interaction between two climate tipping elements",2025-01-24T10:13:38Z,"Annika Högner, Giorgia Di Capua, Jonathan F. Donges, Reik V. Donner, Georg Feulner, Nico Wunderling","Declines in resilience have been observed in several climate tipping elements
over the past decades, including the Atlantic Meridional Overturning
Circulation (AMOC) and the Amazon rainforest (AR). Large-scale nonlinear and
possibly irreversible changes in system state, such as AMOC weakening or
rainforest-savanna transitions in the Amazon basin, would have severe impacts
on ecosystems and human societies worldwide. In order to improve future tipping
risk assessments, understanding interactions between tipping elements is
crucial. The AMOC is known to influence the Intertropical Convergence Zone,
potentially altering precipitation patterns over the AR and affecting its
stability. However, AMOC-AR interactions are currently not well understood.
Here, we identify a previously unknown stabilising interaction pathway from the
AMOC onto the Southern AR, applying an established causal discovery and
inference approach to tipping element interactions for the first time.
Analysing observational and reanalysis data from 1982-2022, we show that AMOC
weakening leads to increased precipitation in the Southern AR during the
critical dry season, in line with findings from recent Earth system model
experiments. Specifically, we report a 4.8% increase of mean dry season
precipitation in the Southern AR for every 1 Sv of AMOC weakening. This finding
is consistent across multiple data sources and AMOC strength indices. We show
that this stabilising interaction has offset 17% of dry season precipitation
decrease in the Southern AR since 1982. Our results demonstrate the potential
of causal discovery methods for analysing tipping element interactions based on
reanalysis and observational data. By improving the understanding of AMOC-AR
interactions, we contribute toward better constraining the risk of potential
climate tipping cascades under global warming.",http://arxiv.org/abs/2501.14374v1
FireCastNet: Earth-as-a-Graph for Seasonal Fire Prediction,2025-02-03T17:30:45Z,"Dimitrios Michail, Charalampos Davalas, Lefki-Ioanna Panagiotou, Ioannis Prapas, Spyros Kondylatos, Nikolaos Ioannis Bountos, Ioannis Papoutsis","With climate change expected to exacerbate fire weather conditions, the
accurate and timely anticipation of wildfires becomes increasingly crucial for
disaster mitigation. In this study, we utilize SeasFire, a comprehensive global
wildfire dataset with climate, vegetation, oceanic indices, and human-related
variables, to enable seasonal wildfire forecasting with machine learning. For
the predictive analysis, we present FireCastNet, a novel architecture which
combines a 3D convolutional encoder with GraphCast, originally developed for
global short-term weather forecasting using graph neural networks. FireCastNet
is trained to capture the context leading to wildfires, at different spatial
and temporal scales. Our investigation focuses on assessing the effectiveness
of our model in predicting the presence of burned areas at varying forecasting
time horizons globally, extending up to six months into the future, and on how
different spatial or/and temporal context affects the performance. Our findings
demonstrate the potential of deep learning models in seasonal fire forecasting;
longer input time-series leads to more robust predictions, while integrating
spatial information to capture wildfire spatio-temporal dynamics boosts
performance. Finally, our results hint that in order to enhance performance at
longer forecasting horizons, a larger receptive field spatially needs to be
considered.",http://arxiv.org/abs/2502.01550v1
"Comprehensive Review of Analytical and Numerical Approaches in
  Earth-to-Air Heat Exchangers and Exergoeconomic Evaluations",2025-02-12T16:33:44Z,"Saeed Asadi, Mohsen Mohammadagha, Hajar Kazemi Naeini","In recent decades, Earth-to-Air Heat Exchangers (EAHEs), also known as
underground air ducts, have garnered significant attention for their ability to
provide energy-efficient cooling and heating solutions while maintaining a
minimal environmental footprint. These systems leverage the relatively stable
underground temperature to regulate indoor climates, reducing reliance on
conventional heating, ventilation, and air conditioning (HVAC) systems. This
review systematically categorizes and synthesizes research on EAHEs into three
primary areas: analytical, numerical, and exergoeconomic studies. Analytical
approaches focus on developing theoretical models to predict thermal
performance, while numerical simulations provide insights into system
optimization and real-world applications. Exergoeconomic analyses, integrating
thermodynamic efficiency with economic considerations, offer valuable
perspectives on cost-effectiveness and long-term viability. By consolidating
existing contributions across these domains, this study serves as a
comprehensive reference for researchers, engineers, and policymakers seeking to
enhance the design, implementation, and performance of EAHE systems. The
findings emphasize the pivotal role of EAHEs in reducing energy consumption,
lowering greenhouse gas emissions, and improving economic sustainability.
Additionally, this review identifies key challenges, including soil thermal
conductivity variations, moisture effects, and system integration with
renewable energy sources, which require further investigation. By addressing
these challenges, EAHEs can be further optimized to serve as a cornerstone in
sustainable energy management, contributing to global efforts toward
energy-efficient building solutions and climate change mitigation.",http://arxiv.org/abs/2502.08553v1
SpaceTime: Causal Discovery from Non-Stationary Time Series,2025-01-17T15:00:20Z,"Sarah Mameche, Lénaïg Cornanguer, Urmi Ninad, Jilles Vreeken","Understanding causality is challenging and often complicated by changing
causal relationships over time and across environments. Climate patterns, for
example, shift over time with recurring seasonal trends, while also depending
on geographical characteristics such as ecosystem variability. Existing methods
for discovering causal graphs from time series either assume stationarity, do
not permit both temporal and spatial distribution changes, or are unaware of
locations with the same causal relationships. In this work, we therefore unify
the three tasks of causal graph discovery in the non-stationary multi-context
setting, of reconstructing temporal regimes, and of partitioning datasets and
time intervals into those where invariant causal relationships hold. To
construct a consistent score that forms the basis of our method, we employ the
Minimum Description Length principle. Our resulting algorithm SPACETIME
simultaneously accounts for heterogeneity across space and non-stationarity
over time. Given multiple time series, it discovers regime changepoints and a
temporal causal graph using non-parametric functional modeling and kernelized
discrepancy testing. We also show that our method provides insights into
real-world phenomena such as river-runoff measured at different catchments and
biosphere-atmosphere interactions across ecosystems.",http://arxiv.org/abs/2501.10235v1
"Arbitrage-free catastrophe reinsurance valuation for compound dynamic
  contagion claims",2025-02-18T23:04:27Z,"Jiwook Jang, Patrick J. Laub, Tak Kuen Siu, Hongbiao Zhao","In this paper, we consider catastrophe stop-loss reinsurance valuation for a
reinsurance company with dynamic contagion claims. To deal with conventional
and emerging catastrophic events, we propose the use of a compound dynamic
contagion process for the catastrophic component of the liability. Under the
premise that there is an absence of arbitrage opportunity in the market, we
obtain arbitrage-free premiums for these contacts. To this end, the Esscher
transform is adopted to specify an equivalent martingale probability measure.
We show that reinsurers have various ways of levying the security loading on
the net premiums to quantify the catastrophic liability in light of the growing
challenges posed by emerging risks arising from climate change, cyberattacks,
and pandemics. We numerically compare arbitrage-free catastrophe stop-loss
reinsurance premiums via the Monte Carlo simulation method. Sensitivity
analyzes are performed by changing the Esscher parameters and the retention
level.",http://arxiv.org/abs/2502.13325v1
Electrochemical CO2 capture with pH-independent redox chemistry,2025-02-03T03:48:04Z,"Sang Cheol Kim, Marco Gigantino, John Holoubek, Jesse E. Matthews, Junjie Chen, Yaereen Dho, Thomas F. Jaramillo, Yi Cui, Arun Majumdar, Yan-Kai Tzeng, Steven Chu","Capture of anthropogenic CO2 is critical for mitigating climate change, and
reducing the energy cost is essential for wide-scale deployment. Solubility of
inorganic carbon in aqueous solutions depends on the pH, and electrochemical
modulation of the pH has been investigated as a means of CO2 capture and
release. However, reported methods incur unavoidable energy costs due to
thermodynamic penalties. In this study, we introduce a pH-independent redox
chemistry that greatly lowers the thermodynamic energy costs by changing the pH
without directly changing the [H+]. We show that the redox reaction of TEMPO
molecules modulates the pH for capture and release of CO2 in a flow cell with
an energy cost as low as 2.6 kJ/mol of CO2 corresponding to 0.027 eV/molecule.
A molecular model, supported by MD and DFT simulations, is proposed of how the
pH is decreased by 7.6 while largely avoiding the entropic energy cost
associated with increasing the [H+]. We believe that this work showcases the
potential of pH-independent redox chemistries for practical and cost-effective
CO2 capture.",http://arxiv.org/abs/2502.01028v1
"Interfacial Free Energy as the Key to the Pressure-Induced Deceleration
  of Ice Nucleation",2025-01-13T08:24:22Z,"Jorge R. Espinosa, Alberto Zaragoza, Pablo Rosales-Peláez, Caridad Navarro, Chantal Valeriani, Carlos Vega, Eduardo Sanz","The avoidance of water freezing is the holy grail in the cryopreservation of
biological samples, food, and organs. Fast cooling rates are used to beat ice
nucleation and avoid cell damage. This strategy can be enhanced by applying
high pressures to decrease the nucleation rate, but the physics behind this
procedure has not been fully understood yet. We perform computer experiments to
investigate ice nucleation at high pressures consisting in embedding ice seeds
in supercooled water. We find that the slowing down of the nucleation rate is
mainly due to an increase of the ice I-water interfacial free energy with
pressure. Our work also clarifies the molecular mechanism of ice nucleation for
a wide pressure range. This study is not only relevant to cryopreservation, but
also to water amorphization and climate change modeling.",http://arxiv.org/abs/2501.07122v1
"Consistency of Responses and Continuations Generated by Large Language
  Models on Social Media",2025-01-14T13:19:47Z,"Wenlu Fan, Yuqi Zhu, Chenyang Wang, Bin Wang, Wentao Xu","Large Language Models (LLMs) demonstrate remarkable capabilities in text
generation, yet their emotional consistency and semantic coherence in social
media contexts remain insufficiently understood. This study investigates how
LLMs handle emotional content and maintain semantic relationships through
continuation and response tasks using two open-source models: Gemma and Llama.
By analyzing climate change discussions from Twitter and Reddit, we examine
emotional transitions, intensity patterns, and semantic similarity between
human-authored and LLM-generated content. Our findings reveal that while both
models maintain high semantic coherence, they exhibit distinct emotional
patterns: Gemma shows a tendency toward negative emotion amplification,
particularly anger, while maintaining certain positive emotions like optimism.
Llama demonstrates superior emotional preservation across a broader spectrum of
affects. Both models systematically generate responses with attenuated
emotional intensity compared to human-authored content and show a bias toward
positive emotions in response tasks. Additionally, both models maintain strong
semantic similarity with original texts, though performance varies between
continuation and response tasks. These findings provide insights into LLMs'
emotional and semantic processing capabilities, with implications for their
deployment in social media contexts and human-AI interaction design.",http://arxiv.org/abs/2501.08102v2
"Daily Groundwater Monitoring Using Vehicle-DAS Elastic Full-waveform
  Inversion",2025-01-18T00:52:18Z,"Haipeng Li, Jingxiao Liu, Shujuan Mao, Siyuan Yuan, Robert G. Clapp, Biondo L. Biondi","Understanding groundwater dynamics is critical for sustainable water
management, particularly as climate extremes intensify. However, the
resolutions of existing subsurface observational tools are still inadequate for
detailed aquifer monitoring and imaging. We introduce an innovative technique
for groundwater monitoring using time-lapse full-waveform inversion, leveraging
fiber-optic cables as seismic sensors and vehicular traffic as repetitive
seismic sources. Over a two-year period along Sandhill Road, California, this
approach captures detailed spatiotemporal S-wave velocity variations, revealing
a 2.9% reduction corresponding to a 9.0-meter groundwater table rise after
atmospheric-river storms in Water Year 2023. Notably, this approach enables the
high-resolution daily analysis of rapid aquifer responses. We observe spatially
inhomogeneous velocity changes, with less reduction beneath impervious paved
zones than under grassy areas, underscoring the impact of urbanization on the
natural recharge of aquifers. Our findings highlight the potential of
Vehicle-DAS FWI for high-resolution daily monitoring and quantitative
spatiotemporal characterizations of groundwater systems.",http://arxiv.org/abs/2501.10618v1
"A Safer, Smaller, Cleaner Subcritical Thorium Fission - Deuteron Fusion
  Hybrid Reactor: DD Collider Instead of Muonic Fusion",2025-01-11T16:19:58Z,"D. Akturk, A. C. Canbay, B. Dagli, U. Kaya, S. Sultansoy","Fossil fuels, which meet most of humanity's energy needs, cause climate
change due to their high carbon emissions. There are two types of energy
sources that can replace fossil fuels: renewable and nuclear. Nuclear energy
sources are more advantageous in terms of efficiency and sustainability. The
use of Thorium as nuclear fuel in fusion reactors will contribute to the
reduction of radioactive waste, due to the much lower production of
transuranics. Fusion reactors, which are considered promising, are still in the
R&D phase. In this respect, hybrid fusion-fission reactors seem more promising
and the recently proposed combination of muon-catalyzed DD fusion with a
cascade thorium reactor is worthy of appreciation. In this study, we show that
using the DD collider instead of muonic fusion has significant advantages.",http://arxiv.org/abs/2501.12401v1
"How Does the Spatial Distribution of Pre-training Data Affect Geospatial
  Foundation Models?",2025-01-21T22:57:09Z,"Mirali Purohit, Gedeon Muhawenayo, Esther Rolf, Hannah Kerner","Foundation models have made rapid advances in many domains including Earth
observation, where Geospatial Foundation Models (GFMs) can help address global
challenges such as climate change, agriculture, and disaster response. Previous
work on GFMs focused on tailoring model architecture and pre-text tasks, and
did not investigate the impact of pre-training data selection on model
performance. However, recent works from other domains show that the
pre-training data distribution is an important factor influencing the
performance of the foundation models. With this motivation, our research
explores how the geographic distribution of pre-training data affects the
performance of GFMs. We evaluated several pre-training data distributions by
sampling different compositions from a global data pool. Our experiments with
two GFMs on downstream tasks indicate that balanced and globally representative
data compositions often outperform region-specific sampling, highlighting the
importance of diversity and global coverage in pre-training data. Our results
suggest that the most appropriate data sampling technique may depend on the
specific GFM architecture. These findings will support the development of
robust GFMs by incorporating quality pre-training data distributions,
ultimately improving machine learning solutions for Earth observation.",http://arxiv.org/abs/2501.12535v1
"The silent threat of methane to ecosystems: Insights from mechanistic
  modelling",2025-01-24T01:22:17Z,"Pranali Roy Chowdhury, Tianxu Wang, Shohel Ahmed, Hao Wang","Over the past century, atmospheric methane levels have nearly doubled, posing
a significant threat to ecosystems. Despite this, studies on its direct impact
on species interactions are lacking. Although bioaccumulation theory explains
the effects of contaminants in trophic levels, it is inadequate for gaseous
pollutants such as methane. This study aims to bridge the gap by developing a
methane-population-detritus model to investigate ecological impacts in aquatic
and terrestrial ecosystems. Our findings show that low methane concentrations
can enhance species growth, while moderate accumulation may induce sub-lethal
effects over time. Elevated methane levels, however, lead to ecosystem
collapse. Furthermore, prolonged exposure to the gas increases the sensitivity
of species towards rising temperatures. Multiscale analysis reveals that rapid
methane accumulation leads to long transients near the extinction states. We
argue that high emission rates can push the system towards a critical
threshold, where the ecosystem shifts to an alternative stable state
characterized by elevated methane concentrations. This work highlights the
urgent need for a better understanding of the fatal role of methane in
ecosystems for developing strategies to mitigate its effects amid climate
change.",http://arxiv.org/abs/2501.14161v1
"Pesti-Gen: Unleashing a Generative Molecule Approach for Toxicity Aware
  Pesticide Design",2025-01-24T13:00:54Z,"Taehan Kim, Wonduk Seo","Global climate change has reduced crop resilience and pesticide efficacy,
making reliance on synthetic pesticides inevitable, even though their
widespread use poses significant health and environmental risks. While these
pesticides remain a key tool in pest management, previous machine-learning
applications in pesticide and agriculture have focused on classification or
regression, leaving the fundamental challenge of generating new molecular
structures or designing novel candidates unaddressed. In this paper, we propose
Pesti-Gen, a novel generative model based on variational auto-encoders,
designed to create pesticide candidates with optimized properties for the first
time. Specifically, Pesti-Gen leverages a two-stage learning process: an
initial pre-training phase that captures a generalized chemical structure
representation, followed by a fine-tuning stage that incorporates
toxicity-specific information. The model simultaneously optimizes over multiple
toxicity metrics, such as (1) livestock toxicity and (2) aqua toxicity to
generate environmentally friendly pesticide candidates. Notably, Pesti-Gen
achieves approximately 68\% structural validity in generating new molecular
structures, demonstrating the model's effectiveness in producing optimized and
feasible pesticide candidates, thereby providing a new way for safer and more
sustainable pest management solutions.",http://arxiv.org/abs/2501.14469v1
Share a Tiny Space of Your Freezer to Preserve Seed Diversity,2025-01-27T11:13:03Z,Andrea Vitaletti,"The Food and Agriculture Organization (FAO), estimates that 75% of crop
diversity was lost since the 1900s. That lack of diversity presents a severe
risk to the security of global food systems. Without seed diversity, it is
difficult for plants to adapt to pests, diseases, and changing climate
conditions. Genebanks, such as the Svalbard Global Seed Vault, are valuable
initiatives to preserve seed diversity in a single secure and safe place.
However, according to our analysis of the data available in the Seed Portal,
the redundancy for some species might be limited, posing a potential threat to
their future availability. Interestingly, the conditions to properly store
seeds in genebanks, are the ones available in the freezers of our homes. This
paper lays out a vision for Distributed Seed Storage relying on a peer-to-peer
infrastructure of domestic freezers to increase the overall availability of
seeds. We present a Proof-of-Concept focused on monitoring the proper seed
storing conditions and incentive user participation through a Blockchain
lottery. The PoC proves the feasibility of the proposed approach and outlines
the main technical issues that still need to be efficiently solved to realize a
fully-fledged solution.",http://arxiv.org/abs/2501.15962v1
"Zoning in American Cities: Are Reforms Making a Difference? An AI-based
  Analysis",2025-01-07T01:03:38Z,"Arianna Salazar-Miranda, Emily Talen","Cities are at the forefront of addressing global sustainability challenges,
particularly those exacerbated by climate change. Traditional zoning codes,
which often segregate land uses, have been linked to increased vehicular
dependence, urban sprawl, and social disconnection, undermining broader social
and environmental sustainability objectives. This study investigates the
adoption and impact of form-based codes (FBCs), which aim to promote
sustainable, compact, and mixed-use urban forms as a solution to these issues.
Using Natural Language Processing (NLP) techniques, we analyzed zoning
documents from over 2000 U.S. census-designated places to identify linguistic
patterns indicative of FBC principles. Our findings reveal widespread adoption
of FBCs across the country, with notable variations within regions. FBCs are
associated with higher floor-to-area ratios, narrower and more consistent
street setbacks, and smaller plots. We also find that places with FBCs have
improved walkability, shorter commutes, and a higher share of multi-family
housing. Our findings highlight the utility of NLP for evaluating zoning codes
and underscore the potential benefits of form-based zoning reforms for
enhancing urban sustainability.",http://arxiv.org/abs/2502.00008v1
Lessons from complexity theory for AI governance,2025-01-07T07:56:40Z,"Noam Kolt, Michal Shur-Ofry, Reuven Cohen","The study of complex adaptive systems, pioneered in physics, biology, and the
social sciences, offers important lessons for AI governance. Contemporary AI
systems and the environments in which they operate exhibit many of the
properties characteristic of complex systems, including nonlinear growth
patterns, emergent phenomena, and cascading effects that can lead to tail
risks. Complexity theory can help illuminate the features of AI that pose
central challenges for policymakers, such as feedback loops induced by training
AI models on synthetic data and the interconnectedness between AI systems and
critical infrastructure. Drawing on insights from other domains shaped by
complex systems, including public health and climate change, we examine how
efforts to govern AI are marked by deep uncertainty. To contend with this
challenge, we propose a set of complexity-compatible principles concerning the
timing and structure of AI governance, and the risk thresholds that should
trigger regulatory intervention.",http://arxiv.org/abs/2502.00012v1
"Bayesian Spatiotemporal Nonstationary Model Quantifies Robust Increases
  in Daily Extreme Rainfall Across the Western Gulf Coast",2025-02-04T04:22:02Z,"Yuchen Lu, Ben Seiyon Lee, James Doss-Gollin","Precipitation exceedance probabilities are widely used in engineering design,
risk assessment, and floodplain management. While common approaches like NOAA
Atlas 14 assume that extreme precipitation characteristics are stationary over
time, this assumption may underestimate current and future hazards due to
anthropogenic climate change. However, the incorporation of nonstationarity in
the statistical modeling of extreme precipitation has faced practical
challenges that have restricted its applications. In particular, random
sampling variability challenges the reliable estimation of trends and
parameters, especially when observational records are limited. To address this
methodological gap, we propose the Spatially Varying Covariates Model, a
hierarchical Bayesian spatial framework that integrates nonstationarity and
regionalization for robust frequency analysis of extreme precipitation. This
model draws from extreme value theory, spatial statistics, and Bayesian
statistics, and is validated through cross-validation and multiple performance
metrics. Applying this framework to a case study of daily rainfall in the
Western Gulf Coast, we identify robustly increasing trends in extreme
precipitation intensity and variability throughout the study area, with notable
spatial heterogeneity. This flexible model accommodates stations with varying
observation records, yields smooth return level estimates, and can be
straightforwardly adapted to the analysis of precipitation frequencies at
different durations and for other regions.",http://arxiv.org/abs/2502.02000v1
"Is this normal? A new projection pursuit index to assess a sample
  against a multivariate null distribution",2025-02-04T15:17:10Z,"Annalisa Calvi, Ursula Laa, Dianne Cook","Many data problems contain some reference or normal conditions, upon which to
compare newly collected data. This scenario occurs in data collected as part of
clinical trials to detect adverse events, or for measuring climate change
against historical norms. The data is typically multivariate, and often the
normal ranges are specified by a multivariate normal distribution. The work
presented in this paper develops methods to compare the new sample against the
reference distribution with high-dimensional visualisation. It uses a
projection pursuit guided tour to produce a sequence of low-dimensional
projections steered towards those where the new sample is most different from
the reference. A new projection pursuit index is defined for this purpose. The
tour visualisation also includes drawing of the projected ellipse, which is
computed analytically, corresponding to the reference distribution. The methods
are implemented in the R package, tourr.",http://arxiv.org/abs/2502.02397v1
Measuring Fitness and Importance of Species in Food Webs,2025-02-11T15:05:21Z,"Emanuele Calò, Giordano De Marzo, Vito D. P. Servedio","Ecosystems face intensifying threats from climate change, overexploitation,
and other human pressures, emphasizing the urgent need to identify keystone
species and vulnerable ones. While established network-based measures often
rely on a single metric to quantify a species' relevance, they overlook how
organisms can be both carbon providers and consumers, thus playing a dual role
in food webs. Here, we introduce a novel approach that assigns each species two
complementary scores -- an importance measure quantifying their centrality as
carbon source and a fitness measure capturing their vulnerability. We show that
species with high importance are more likely to trigger co-extinctions upon
removal, while high-fitness species typically endure until later stages of
collapse, in line with their broader prey ranges. On the other hand, low
fitness species are the most vulnerable and susceptible to extinctions. Tested
on multiple food webs, our method outperforms traditional degree-based analyses
and competes effectively with eigenvector-based approaches, while also
providing additional insights. Relying solely on interaction data, the approach
is scalable and avoids reliance on expert-driven classifications, offering a
cost-effective tool for prioritizing conservation efforts.",http://arxiv.org/abs/2502.07614v1
"Adsorption Behavior of Greenhouse Gases on Carbon Nanobelts: A
  Semi-Empirical Tight-Binding Approach for Environmental Application",2025-02-11T16:44:48Z,"C. Aguiar, I. Camps","This research investigates the adsorption characteristics of carbon nanobelts
(CNB) and Mobius carbon nanobelts (MCNB) interacting with various greenhouse
gases, including NH3, CO2, CO, H2S, CH4, CH3OH, NO2, NO, and COCl2. The study
employs semi-empirical tight-binding calculations via xTB software,
complemented by topological analysis using MULTIWFN software. Comparative
analysis reveals MCNB's superior adsorption properties, particularly for
specific gases. Notable adsorption energies for MCNB were measured at -1.595eV,
-0.669eV, and -0.637eV for NO, COCl2, and NO2, respectively, significantly
exceeding the corresponding CNB values of -0.636eV, -0.449eV, and -0.438eV. The
investigation of desorption kinetics demonstrates rapid recovery times
(sub-millisecond) for most gas-nanobelt interactions, with the notable
exception of the MCNB+NO system, which exhibits persistent bonding. Topological
analysis confirms chemisorption mechanisms for NO, COCl2, and NO2 on both
nanobelt variants, characterized by complex hybridizations of covalent and
non-covalent interactions. Molecular dynamics simulations conducted in both
packed configurations and dry air mixtures demonstrate the nanobelts' effective
gas-attracting properties, maintaining consistent capture performance across
different environmental conditions. These findings establish carbon nanobelts,
particularly the Mobius configuration, as promising candidates for greenhouse
gas capture technologies, offering potential applications in environmental
remediation and climate change mitigation strategies.",http://arxiv.org/abs/2502.07690v1
Optimal Placement of Nature-Based Solutions for Urban Challenges,2025-02-16T10:10:01Z,"Diego Maria Pinto, Davide Donato Russo, Antonio M. Sudoso","Increased urbanization and climate change intensify urban heat islands and
degrade air quality, making current mitigation strategies insufficient.
Nature-based solutions (NBSs), such as parks, green walls, roofs, and street
trees, offer a promising means to regulate urban temperatures and enhance air
quality. However, determining their optimal placement to maximize environmental
benefits remains a pressing challenge. Leveraging Operational Research (OR)
tools, we propose a Mixed-Integer Linear Programming (MILP) model that
integrates multiple factors, including urban challenges, physical constraints,
clustering techniques, convolution theory, and fairness considerations. This
model determines the optimal placement of NBSs by addressing metrics such as
ground temperature, air quality, and accessibility to green spaces. Through
several case study analyses, we demonstrate the effectiveness of our approach
in improving environmental and social indicators. This research holds
implications for policy and practice, empowering urban planners and
policymakers to make informed decisions regarding NBS implementation. Such
decisions ensure that investments in urban greening yield maximum
environmental, social, and economic benefits.",http://arxiv.org/abs/2502.11065v1
"A survey about perceptions of mobility to inform an agent-based
  simulator of subjective modal choice",2025-02-17T17:25:18Z,"Carole Adam, Benoit Gaudou","In order to adapt to the issues of climate change and public health, urban
policies are trying to encourage soft mobility, but the share of the car
remains significant. Beyond known constraints, we study here the impact of
perception biases on individual choices. We designed a multi-criteria decision
model, integrating the influence of habits and biases. We then conducted an
online survey, which received 650 responses. We used these to calculate
realistic mobility perception values, in order to initialise the environment
and the population of a modal choice simulator, implemented in Netlogo. This
allows us to visualize the adaptation of the modal distribution in reaction to
the evolution of urban planning, depending on whether or not we activate biases
and habits in individual reasoning.
  This is an extended and translated version of a demo paper published in
French at JFSMA-JFMS 2024 ""Un simulateur multi-agent de choix modal subjectif""",http://arxiv.org/abs/2502.12058v1
"Scalable and Robust Physics-Informed Graph Neural Networks for Water
  Distribution Systems",2025-02-11T13:38:14Z,"Inaam Ashraf, André Artelt, Barbara Hammer","Water distribution systems (WDSs) are an important part of critical
infrastructure becoming increasingly significant in the face of climate change
and urban population growth. We propose a robust and scalable surrogate deep
learning (DL) model to enable efficient planning, expansion, and rehabilitation
of WDSs. Our approach incorporates an improved graph neural network
architecture, an adapted physics-informed algorithm, an innovative training
scheme, and a physics-preserving data normalization method. Evaluation results
on a number of WDSs demonstrate that our model outperforms the current
state-of-the-art DL model. Moreover, our method allows us to scale the model to
bigger and more realistic WDSs. Furthermore, our approach makes the model more
robust to out-of-distribution input features (demands, pipe diameters). Hence,
our proposed method constitutes a significant step towards bridging the
simulation-to-real gap in the use of artificial intelligence for WDSs.",http://arxiv.org/abs/2502.12164v1
Fine-grained Fallacy Detection with Human Label Variation,2025-02-19T16:18:44Z,"Alan Ramponi, Agnese Daffara, Sara Tonelli","We introduce Faina, the first dataset for fallacy detection that embraces
multiple plausible answers and natural disagreement. Faina includes over 11K
span-level annotations with overlaps across 20 fallacy types on social media
posts in Italian about migration, climate change, and public health given by
two expert annotators. Through an extensive annotation study that allowed
discussion over multiple rounds, we minimize annotation errors whilst keeping
signals of human label variation. Moreover, we devise a framework that goes
beyond ""single ground truth"" evaluation and simultaneously accounts for
multiple (equally reliable) test sets and the peculiarities of the task, i.e.,
partial span matches, overlaps, and the varying severity of labeling errors.
Our experiments across four fallacy detection setups show that multi-task and
multi-label transformer-based approaches are strong baselines across all
settings. We release our data, code, and annotation guidelines to foster
research on fallacy detection and human label variation more broadly.",http://arxiv.org/abs/2502.13853v1
"A meta-model of belief dynamics with Personal, Expressed and Social
  beliefs",2025-02-20T08:40:32Z,"Filippo Zimmaro, Henrik Olsson","Beliefs are central to individual decision-making and societal dynamics, yet
they are shaped through complex interactions between personal cognition and
social environments. Traditional models of belief dynamics often fail to
capture the interplay between internal belief systems and external influences.
This paper introduces the Personal, Expressed, and Social Beliefs (PES)
meta-model, which integrates personal beliefs, outwardly expressed beliefs, and
perceptions of others' beliefs. The PES meta-model provides a flexible
structure to model belief dynamics, incorporating processes like social
influence, authenticity, ego projection, and conformity. It accommodates wide
range of existing models, of the Voter, Ising, DeGroot and bounded confidence
types, allowing for comparison and extension of the models within a unified
framework. Through a case study on the misperception of public support for
climate change policies, the PES meta-model demonstrates its capacity to
capture complex psychological and social phenomena. This work highlights the
utility of the PES meta-model in advancing theoretical understanding and
practical applications in belief dynamics research.",http://arxiv.org/abs/2502.14362v1
Eco-evolutionary dynamics of a trait-structured predator-prey model,2025-01-13T14:55:59Z,"Manh Hong Duong, Fabian Spill, Blaine van Rensburg","The coupling between evolutionary and ecological changes (eco-evolutionary
dynamics) has been shown to be relevant among diverse species, and is also of
interest outside of ecology, i.e. in cancer evolution. These dynamics play an
important role in determining survival in response to climate change,
motivating the need for mathematical models to capture this often complex
interplay. Models incorporating eco-evolutionary dynamics often sacrifice
analytical tractability to capture the complexity of real systems, do not
explicitly consider the effect of population heterogeneity, or focus on
long-term behaviour. In order to capture population heterogeneity, both
transient, and long-term dynamics, while retaining tractability, we generalise
a moment-based method applicable in the regime of small segregational variance
to the case of time-dependent mortality and birth. These results are applied to
a predator-prey model, where ecological parameters such as the contact rate
between species are trait-structured. The trait-distribution of the prey
species is shown to be approximately Gaussian with constant variance centered
on the mean trait, which is asymptotically governed by an autonomous ODE. In
this way, we make explicit the impact of eco-evolutionary dynamics on the
transient behaviour and long-term fate of the prey species.",http://arxiv.org/abs/2501.07379v2
"Analyzing the progress of Indian states chasing sustainable development
  goals using complex network framework",2025-01-09T15:30:09Z,"Hrishidev Unni, Rubal Rathi, Sangita Dutta Gupta, Anirban Chakraborti","The Sustainable Development Goals (SDGs) offer a critical global framework
for addressing challenges like poverty, inequality, climate change, etc. They
encourage a holistic approach integrating economic growth, social inclusion,
and environmental sustainability to create a better future. We aim to examine
India's responsibility in achieving the SDGs by recognizing the contributions
of its diverse states in the federal structure of governance. As the nodal
agency in India, the NITI Aayog's existing SDG index, using various
socioeconomic indicators to determine the performance across different goals,
serves as a foundation for assessing each state's progress. Building on the
seminal works of Hidalgo and Hausmann (2009) and Tachhella et al. (2012), which
introduced the economic complexity/fitness index, Sciarra et al. (2020)
proposed the SDGs-Generalized Economic Complexity (GENEPY) framework to
quantify ""complexity"" by computing ""ranks for states"" and ""scores for goals"",
treating them as part of a complex bipartite network. In this paper, we apply
the SDGs-GENEPY, to evaluate the progress and evolution of Indian states and
union territories over several years. This enables us to identify each state's
capacity (and rank) in achieving the SDGs. We can interpret these complexity
scores as ""centrality measures"" of a complex bipartite network of the states
and the goals. This enhances our understanding of the complex relationship
between state capabilities and the achievability of SDGs within the Indian
context and enables data-driven policy-making.",http://arxiv.org/abs/2501.05314v1
"Estimation of the Effect of Carbon Tax Implementation on Household
  Income Distribution in Indonesia: Quantitative Analysis with Miyazawa Input-
  Output Approach",2025-01-14T15:00:25Z,Syahrituah Siregar,"Climate change is a global challenge caused by greenhouse gas emissions from
fossil fuel use. Indonesia, as a developing country, faces major challenges in
implementing carbon tax policies to reduce emissions, especially related to
their regressive impacts on low-income households. Currently, there is little
in-depth research on how carbon tax policies impact household income
distribution in Indonesia. This study uses a quantitative approach with the
Input- Output model to analyze the impact of carbon tax on household income
based on 10 income groups, both in urban and rural areas. The results show that
carbon tax policies have a regressive impact, where low-income households bear
a proportionally greater burden. Household income in Class - 10 decreased by
IDR 19,144.85 million in urban areas and IDR 8,819.13 million in rural areas,
while households in Class - 1 decreased by IDR 954.23 million. Therefore,
mitigation policies such as cross subsidies are needed to reduce the impact on
vulnerable groups. These findings are important for policy makers in
formulating fair and effective fiscal policies, as well as ensuring social
justice in the context of sustainable development. This study has limitations
in the scope of analysis of long-term energy consumption behavior and certain
sectors, so further research is needed to deepen these aspects.",http://arxiv.org/abs/2501.08177v1
"A life cycle model for high-speed rail infrastructure: environmental
  inventories and assessment of the Tours-Bordeaux railway in France",2025-01-14T22:34:02Z,"Anne de Bortoli, Lina Bouhaya, Adelaide Feraille","Method: a process-based LCA compliant with ISO 14040 and 14044 is performed.
Construction stage LCIs rely on data collection conducted with the
concessionaire of the HSR line combined with EcoInvent 3.1 inventories. Use and
End-of-Life stages LCIs rest on expert feedback scenarios and field data. A set
of 13 midpoint indicators is proposed to capture the diversity of the
environmental damage: climate change, consumptions of primary energy and
non-renewable resources, human toxicity and ecotoxicities, eutrophication,
acidification, radioactive and bulk wastes, stratospheric ozone depletion and
summer smog. Results: The study shows major contributions to environmental
impact from rails (10-71%), roadbed (3-48%), and civil engineering structures
(4-28%). More limited impact is noted from ballast (1-22%), building machines
(0-17%), sleepers (4-11%), and power supply system (2-12%). The two last
components, chairs and fasteners, have negligible impact (max. 1% and 3% of
total contributions, respectively). Direct transportation can contribute up to
18% of total impact. The production and maintenance stages contribute roughly
equally to environmental deterioration (resp. average of 62% and 59%). Because
the End-of-Life (EoL) mainly includes recycling with environmental credit
accounted for in our 100:100 approach, this stage has globally a positive
impact (-9 to -98%) on all the impact categories except terrestrial ecotoxicity
(58%), radioactive waste (11%) and ozone depletion (8%). Contribution analyses
show that if concrete production is one of the important contributing process
over the construction stage, primary steel production is unquestionably the
most important process on all the impact categories over the entire life cycle.",http://arxiv.org/abs/2501.10458v1
"Solar Panel Selection using Extended WASPAS with Disc Intuitionistic
  Fuzzy Choquet Integral Operators: CASPAS Methodology",2025-01-21T16:12:55Z,"Mahmut Can Bozyiğit, Mehmet Ünver","Renewable energy is crucial for addressing the growing energy demands of
modern society while mitigating the adverse effects of climate change. Unlike
fossil fuels, renewable energy sources such as solar, wind, hydro, geothermal,
and biomass are abundant, sustainable, and environmentally friendly. This study
focuses on addressing a critical challenge in renewable energy decision-making
by developing a novel framework for optimal solar panel selection, a key
component of sustainable energy solutions. Solar panel selection involves
evaluating multiple interdependent criteria, such as efficiency, cost,
durability, and environmental impact. Traditional multi-criteria
decision-making (MCDM) methods often fail to account for the interdependencies
among these criteria, leading to suboptimal outcomes. To overcome this
limitation, the study introduces the Choquet Aggregated Sum Product Assessment
(CASPAS) method, a Choquet integral-based MCDM approach that incorporates fuzzy
measures to model interactions among criteria. CASPAS generalizes the Weighted
Aggregated Sum Product Assessment (WASPAS) method, thereby enhancing
decision-making accuracy and reliability. This study also introduces the
concept of disc intuitionistic fuzzy set (D-IFS), a generalization of the
concept of circular intuitionistic fuzzy set, which employ a radius function
capable of assigning varying values to individual elements instead of relying
on a fixed radius. Recognizing that traditional weighted aggregation operators
neglect the interaction among criteria, this study proposes disc intuitionistic
fuzzy Choquet integral operators by incorporating the concept of fuzzy
measures, which are effective in modeling such interactions. The proposed
method is applied to a renewable energy problem on selecting optimal solar
panels.",http://arxiv.org/abs/2501.12251v1
"A Dimension-Reduced Multivariate Spatial Model for Extreme Events:
  Balancing Flexibility and Scalability",2025-01-22T18:30:21Z,"Remy MacDonald, Benjamin Seiyon Lee, John Foley, Justin Lee","Modeling extreme precipitation and temperature is vital for understanding the
impacts of climate change, as hazards like intense rainfall and record-breaking
temperatures can result in severe consequences, including floods, droughts, and
wildfires. Gaining insight into the spatial variation and interactions between
these extremes is critical for effective risk management, early warning
systems, and informed policy-making. However, challenges such as the rarity of
extreme events, spatial dependencies, and complex cross-variable interactions
hinder accurate modeling. We introduce a novel framework for modeling spatial
extremes, building upon spatial generalized extreme value (GEV) models. Our
approach incorporates a dimension-reduced latent spatial process to improve
scalability and flexibility, particularly in capturing asymmetry in
cross-covariance structures. This Joint Latent Spatial GEV model (JLS-GEV)
overcomes key limitations of existing methods by providing a more flexible
framework for inter-variable dependencies. In addition to addressing event
rarity, spatial dependence and cross-variable interactions, JLS-GEV supports
nonstationary spatial behaviors and independently collected data sources, while
maintaining practical fitting times through dimension reduction. We validate
JLS-GEV through extensive simulation studies, demonstrating its superior
performance in capturing spatial extremes compared to baseline modeling
approaches. Application to real-world data on extreme precipitation and
temperature in the southeastern United States highlights its practical utility.
While primarily motivated by environmental challenges, this framework is
broadly applicable to interdisciplinary studies of spatial extremes in
interdependent natural processes.",http://arxiv.org/abs/2501.13070v1
"A framework for river connectivity classification using temporal image
  processing and attention based neural networks",2025-02-01T16:00:28Z,"Timothy James Becker, Derin Gezgin, Jun Yi He Wu, Mary Becker","Measuring the connectivity of water in rivers and streams is essential for
effective water resource management. Increased extreme weather events
associated with climate change can result in alterations to river and stream
connectivity. While traditional stream flow gauges are costly to deploy and
limited to large river bodies, trail camera methods are a low-cost and easily
deployed alternative to collect hourly data. Image capturing, however requires
stream ecologists to manually curate (select and label) tens of thousands of
images per year. To improve this workflow, we developed an automated instream
trail camera image classification system consisting of three parts: (1) image
processing, (2) image augmentation and (3) machine learning. The image
preprocessing consists of seven image quality filters, foliage-based luma
variance reduction, resizing and bottom-center cropping. Images are balanced
using variable amount of generative augmentation using diffusion models and
then passed to a machine learning classification model in labeled form. By
using the vision transformer architecture and temporal image enhancement in our
framework, we are able to increase the 75% base accuracy to 90% for a new
unseen site image. We make use of a dataset captured and labeled by staff from
the Connecticut Department of Energy and Environmental Protection between
2018-2020. Our results indicate that a combination of temporal image processing
and attention-based models are effective at classifying unseen river
connectivity images.",http://arxiv.org/abs/2502.00474v1
"AquaticCLIP: A Vision-Language Foundation Model for Underwater Scene
  Analysis",2025-02-03T19:56:16Z,"Basit Alawode, Iyyakutti Iyappan Ganapathi, Sajid Javed, Naoufel Werghi, Mohammed Bennamoun, Arif Mahmood","The preservation of aquatic biodiversity is critical in mitigating the
effects of climate change. Aquatic scene understanding plays a pivotal role in
aiding marine scientists in their decision-making processes. In this paper, we
introduce AquaticCLIP, a novel contrastive language-image pre-training model
tailored for aquatic scene understanding. AquaticCLIP presents a new
unsupervised learning framework that aligns images and texts in aquatic
environments, enabling tasks such as segmentation, classification, detection,
and object counting. By leveraging our large-scale underwater image-text paired
dataset without the need for ground-truth annotations, our model enriches
existing vision-language models in the aquatic domain. For this purpose, we
construct a 2 million underwater image-text paired dataset using heterogeneous
resources, including YouTube, Netflix, NatGeo, etc. To fine-tune AquaticCLIP,
we propose a prompt-guided vision encoder that progressively aggregates patch
features via learnable prompts, while a vision-guided mechanism enhances the
language encoder by incorporating visual context. The model is optimized
through a contrastive pretraining loss to align visual and textual modalities.
AquaticCLIP achieves notable performance improvements in zero-shot settings
across multiple underwater computer vision tasks, outperforming existing
methods in both robustness and interpretability. Our model sets a new benchmark
for vision-language applications in underwater environments. The code and
dataset for AquaticCLIP are publicly available on GitHub at xxx.",http://arxiv.org/abs/2502.01785v1
"Integrating social capital with urban infrastructure networks for more
  resilient cities",2025-02-10T10:28:17Z,"Ariel Favier, Christine Hedde-von Westernhagen, Meghan Krieg, Bhaskar Kumawat","More than half of the world's population now lives in urban environments,
which concentrate services and infrastructure to satisfy the material needs of
a growing number of inhabitants. The interdependencies between physical
infrastructure systems are required for cities to function efficiently, but
simultaneously expose cities to new hazards. Failures that emerge from one
infrastructure system and cascade through these interdependencies are becoming
larger and more frequent due to climate change and growing urban environments.
Because of the uneven distribution of resources and basic services, cascade
failures often exacerbate pre-existing socioeconomic inequalities. Human
communities rely on both social capital and infrastructure services to prepare
for, manage, and recover from these challenging scenarios, but the overlap
between social and physical infrastructure creates unpredictable feedback
dynamics. While prior research has focused on either social capital or physical
infrastructure in urban disaster management, an integrative view of these two
perspectives is seldom explored. In this paper, the feedback mechanisms between
the physical and social layers of different urban designs are identified and
analyzed to optimize relief response. Methodologically, we identify cities with
high accessibility that have undergone disasters. From these cities, we measure
their physical and social resilience indicators before and after disaster as a
means to evaluate the impact of accessibility on disaster relief and
preparedness. We will supplement this empirical analysis with a simulation that
captures a cascade failure/disaster through a multilayer infrastructure and
social network model.",http://arxiv.org/abs/2502.06328v1
AstroLoc: Robust Space to Ground Image Localizer,2025-02-10T20:06:14Z,"Gabriele Berton, Alex Stoken, Carlo Masone","Astronauts take thousands of photos of Earth per day from the International
Space Station, which, once localized on Earth's surface, are used for a
multitude of tasks, ranging from climate change research to disaster
management. The localization process, which has been performed manually for
decades, has recently been approached through image retrieval solutions: given
an astronaut photo, find its most similar match among a large database of
geo-tagged satellite images, in a task called Astronaut Photography
Localization (APL). Yet, existing APL approaches are trained only using
satellite images, without taking advantage of the millions open-source
astronaut photos. In this work we present the first APL pipeline capable of
leveraging astronaut photos for training. We first produce full localization
information for 300,000 manually weakly labeled astronaut photos through an
automated pipeline, and then use these images to train a model, called
AstroLoc. AstroLoc learns a robust representation of Earth's surface features
through two losses: astronaut photos paired with their matching satellite
counterparts in a pairwise loss, and a second loss on clusters of satellite
imagery weighted by their relevance to astronaut photography via unsupervised
mining. We find that AstroLoc achieves a staggering 35% average improvement in
recall@1 over previous SOTA, pushing the limits of existing datasets with a
recall@100 consistently over 99%. Finally, we note that AstroLoc, without any
fine-tuning, provides excellent results for related tasks like the
lost-in-space satellite problem and historical space imagery localization.",http://arxiv.org/abs/2502.07003v1
"Resampling Methods that Generate Time Series Data to Enable Sensitivity
  and Model Analysis in Energy Modeling",2025-02-12T03:59:18Z,"Kelly Wang, Steven O. Kimbrough","Energy systems modeling frequently relies on time series data, whether
observed or forecast. This is particularly the case, for example, in capacity
planning models that use hourly production and load data forecast to occur over
the coming several decades. This paper addresses the attendant problem of
performing sensitivity, robustness, and other post-solution analyses using time
series data. We explore two efficient and relatively simple, non-parametric,
bootstrapping methods for generating arbitrary numbers of time series from a
single observed or forecast series. The paper presents and assesses each
method. We find that the generated series are both visually and by statistical
summary measures close to the original observational data. In consequence these
series are credibly taken as stochastic instances from a common distribution,
that of the original series of observations. With climate change in mind, the
paper further proposes and explores two general techniques for systematically
altering (increasing or decreasing) time series. Both for the perturbed and
unperturbed synthetic series data, we find that the generated series induce
variability in properties of the series that are important for energy modeling,
in particular periods of under- and over-production, and periods of increased
ramping rates. In consequence, series produced in this way are apt for use in
robustness, sensitivity, and in general post-solution analysis of energy
planning models. These validity factors auger well for applications beyond
energy modeling.",http://arxiv.org/abs/2502.08102v1
"Glacier data assimilation on an Arctic glacier: Learning from large
  ensemble twin experiments",2025-02-13T13:28:03Z,"Wenxue Cao, Kristoffer Aalstad, Louise S. Schmidt, Sebastian Westermann, Thomas V. Schuler","Glacier modeling is crucial for quantifying the evolution of cryospheric
processes. At the same time, uncertainties hamper process understanding and
predictive accuracy. Here, we suggest improving glacier mass balance
simulations for the Kongsvegen glacier in Svalbard through the application of
Bayesian data assimilation techniques in a set of large ensemble twin
experiments. Noisy synthetic observations of albedo and snow depth, generated
using the multilayer CryoGrid community model with a full energy balance, are
assimilated using two ensemble-based data assimilation schemes: the particle
batch smoother and the ensemble smoother. A comprehensive evaluation exercise
demonstrates that the joint assimilation of albedo and snow depth improves the
simulation skill by up to 86% relative to the prior in specific glacier
regions. The particle batch smoother excels in representing albedo dynamics,
while the ensemble smoother is particularly effective for snow depth under low
snowfall conditions. By combining the strengths of both observations, the joint
assimilation achieves improved mass balance simulations across different
glacier zones using either assimilation scheme. This work underscores the
potential of ensemble-based data assimilation methods for refining glacier
models by offering a robust framework to enhance predictive accuracy and reduce
uncertainties in cryospheric simulations. Further advances in glacier data
assimilation will be critical to better understanding the fate and role of
Arctic glaciers in a changing climate.",http://arxiv.org/abs/2502.09314v1
Entity Framing and Role Portrayal in the News,2025-02-20T16:44:46Z,"Tarek Mahmoud, Zhuohan Xie, Dimitar Dimitrov, Nikolaos Nikolaidis, Purificação Silvano, Roman Yangarber, Shivam Sharma, Elisa Sartori, Nicolas Stefanovitch, Giovanni Da San Martino, Jakub Piskorski, Preslav Nakov","We introduce a novel multilingual hierarchical corpus annotated for entity
framing and role portrayal in news articles. The dataset uses a unique taxonomy
inspired by storytelling elements, comprising 22 fine-grained roles, or
archetypes, nested within three main categories: protagonist, antagonist, and
innocent. Each archetype is carefully defined, capturing nuanced portrayals of
entities such as guardian, martyr, and underdog for protagonists; tyrant,
deceiver, and bigot for antagonists; and victim, scapegoat, and exploited for
innocents. The dataset includes 1,378 recent news articles in five languages
(Bulgarian, English, Hindi, European Portuguese, and Russian) focusing on two
critical domains of global significance: the Ukraine-Russia War and Climate
Change. Over 5,800 entity mentions have been annotated with role labels. This
dataset serves as a valuable resource for research into role portrayal and has
broader implications for news analysis. We describe the characteristics of the
dataset and the annotation process, and we report evaluation results on
fine-tuned state-of-the-art multilingual transformers and hierarchical
zero-shot learning using LLMs at the level of a document, a paragraph, and a
sentence.",http://arxiv.org/abs/2502.14718v1
Implications of zero-growth economics analysed with an agent-based model,2025-01-31T14:33:59Z,"Dylan C. Terry-Doyle, Adam B. Barrett","The ever-approaching limits of the Earth's biosphere and the potentially
catastrophic consequences caused by climate change have begun to call into
question the endless growth of the economy. There is increasing interest in the
prospects of zero economic growth from the degrowth and post-growth literature.
In particular, the question arises as to whether a zero-growth trajectory in a
capitalist system with interest-bearing debt can be economically stable. There
have been several answers to this question using macroeconomic models; some
find a zero-growth trajectory is stable, while other models show an economic
breakdown. However, the capitalist system in a period of growth is not
guaranteed to be stable. Hence, a more appropriate methodology is to compare
the relative stability between a growth and zero-growth scenario on the same
model. Such a question has not yet been answered at any disaggregated level.
It's important to investigate the consequences of zero-growth on market share
instability and concentration, bankruptcy rates, income distribution, and
credit network risk. To answer such questions, we develop a macroeconomic
agent-based model incorporating Minskyan financial dynamics. The growth and
zero-growth scenarios are accomplished by changing an average productivity
growth parameter for the firms in the model. The model results showed that real
GDP growth rates were more stable in the zero-growth scenario, there were fewer
economic crises, lower unemployment rates, a higher wage share of output for
workers, and capital firm and bank market shares were relatively more stable.
Some of the consequences of zero-growth were a higher rate of inflation than in
the growth scenario, increased market concentration for both firms and banks,
and a higher level of financial risk in the credit network.",http://arxiv.org/abs/2501.19168v1
"AI Driven Water Segmentation with deep learning models for Enhanced
  Flood Monitoring",2025-01-14T17:26:02Z,"Sanjida Afrin Mou, Tasfia Noor Chowdhury, Adib Ibn Mannan, Sadia Nourin Mim, Lubana Tarannum, Tasrin Noman, Jamal Uddin Ahamed","Flooding is a major natural hazard causing significant fatalities and
economic losses annually, with increasing frequency due to climate change.
Rapid and accurate flood detection and monitoring are crucial for mitigating
these impacts. This study compares the performance of three deep learning
models UNet, ResNet, and DeepLabv3 for pixelwise water segmentation to aid in
flood detection, utilizing images from drones, in field observations, and
social media. This study involves creating a new dataset that augments
wellknown benchmark datasets with flood-specific images, enhancing the
robustness of the models. The UNet, ResNet, and DeepLab v3 architectures are
tested to determine their effectiveness in various environmental conditions and
geographical locations, and the strengths and limitations of each model are
also discussed here, providing insights into their applicability in different
scenarios by predicting image segmentation masks. This fully automated approach
allows these models to isolate flooded areas in images, significantly reducing
processing time compared to traditional semi-automated methods. The outcome of
this study is to predict segmented masks for each image effected by a flood
disaster and the validation accuracy of these models. This methodology
facilitates timely and continuous flood monitoring, providing vital data for
emergency response teams to reduce loss of life and economic damages. It offers
a significant reduction in the time required to generate flood maps, cutting
down the manual processing time. Additionally, we present avenues for future
research, including the integration of multimodal data sources and the
development of robust deep learning architectures tailored specifically for
flood detection tasks. Overall, our work contributes to the advancement of
flood management strategies through innovative use of deep learning
technologies.",http://arxiv.org/abs/2501.08266v1
"A method for estimating forest carbon storage distribution density via
  artificial intelligence generated content model",2025-02-02T12:41:47Z,"Zhenyu Yu, Jinnian Wang","Forest is the most significant land-based carbon storage mechanism. The
forest carbon sink can effectively decrease the atmospheric CO2 concentration
and mitigate climate change. Remote sensing estimation not only ensures high
accuracy of data, but also enables large-scale area observation. Optical images
provide the possibility for long-term monitoring, which is a potential issue in
the future carbon storage estimation research. We chose Huize County, Qujing
City, Yunnan Province, China as the study area, took GF-1 WFV satellite image
as the data, introduced the KD-VGG module to extract the initial features, and
proposed the improved implicit diffusion model (IIDM). The results showed that:
(1) The VGG-19 module after knowledge distillation can realize the initial
feature extraction, reduce the inference time and improve the accuracy in the
case of reducing the number of model parameters. (2) The Attention + MLP module
was added for feature fusion to obtain the relationship between global and
local features and realized the restoration of high-fidelity images in the
continuous scale range. (3) The IIDM model proposed in this paper had the
highest estimation accuracy, with RMSE of 28.68, which was 13.16 higher than
that of the regression model, about 31.45%. In the estimation of carbon
storage, the generative model can extract deeper features, and its performance
was significantly better than other models. It demonstrated the feasibility of
artificial intelligence-generated content (AIGC) in the field of quantitative
remote sensing and provided valuable insights for the study of carbon
neutralization effect. By combining the actual characteristics of the forest,
the regional carbon storage estimation with a resolution of 16-meter was
utilized to provide a significant theoretical basis for the formulation of
forest carbon sink regulation.",http://arxiv.org/abs/2502.00783v1
"Building Age Estimation: A New Multi-Modal Benchmark Dataset and
  Community Challenge",2025-02-19T15:31:13Z,"Nikolaos Dionelis, Nicolas Longépé, Alessandra Feliciotti, Mattia Marconcini, Devis Peressutti, Nika Oman Kadunc, JaeWan Park, Hagai Raja Sinulingga, Steve Andreas Immanuel, Ba Tran, Caroline Arnold","Estimating the construction year of buildings is of great importance for
sustainability. Sustainable buildings minimize energy consumption and are a key
part of responsible and sustainable urban planning and development to
effectively combat climate change. By using Artificial Intelligence (AI) and
recently proposed Transformer models, we are able to estimate the construction
epoch of buildings from a multi-modal dataset. In this paper, we introduce a
new benchmark multi-modal dataset, i.e. the Map your City Dataset (MyCD),
containing top-view Very High Resolution (VHR) images, Earth Observation (EO)
multi-spectral data from the Copernicus Sentinel-2 satellite constellation, and
street-view images in many different cities in Europe, co-localized with
respect to the building under study and labelled with the construction epoch.
We assess EO generalization performance on new/ previously unseen cities that
have been held-out from training and appear only during inference. In this
work, we present the community-based data challenge we organized based on MyCD.
The ESA AI4EO Challenge MapYourCity was opened in 2024 for 4 months. Here, we
present the Top-4 performing models, and the main evaluation results. During
inference, the performance of the models using both all three input modalities
and only the two top-view modalities, i.e. without the street-view images, is
examined. The evaluation results show that the models are effective and can
achieve good performance on this difficult real-world task of estimating the
age of buildings, even on previously unseen cities, as well as even using only
the two top-view modalities (i.e. VHR and Sentinel-2) during inference.",http://arxiv.org/abs/2502.13818v1
"Improving Zero-Shot Object-Level Change Detection by Incorporating
  Visual Correspondence",2025-01-09T20:02:10Z,"Hung Huy Nguyen, Pooyan Rahmanzadehgervi, Long Mai, Anh Totti Nguyen","Detecting object-level changes between two images across possibly different
views is a core task in many applications that involve visual inspection or
camera surveillance. Existing change-detection approaches suffer from three
major limitations: (1) lack of evaluation on image pairs that contain no
changes, leading to unreported false positive rates; (2) lack of
correspondences (i.e., localizing the regions before and after a change); and
(3) poor zero-shot generalization across different domains. To address these
issues, we introduce a novel method that leverages change correspondences (a)
during training to improve change detection accuracy, and (b) at test time, to
minimize false positives. That is, we harness the supervision labels of where
an object is added or removed to supervise change detectors, improving their
accuracy over previous work by a large margin. Our work is also the first to
predict correspondences between pairs of detected changes using estimated
homography and the Hungarian algorithm. Our model demonstrates superior
performance over existing methods, achieving state-of-the-art results in change
detection and change correspondence accuracy across both in-distribution and
zero-shot benchmarks.",http://arxiv.org/abs/2501.05555v2
"Explainable Lane Change Prediction for Near-Crash Scenarios Using
  Knowledge Graph Embeddings and Retrieval Augmented Generation",2025-01-20T16:02:26Z,"M. Manzour, A. Ballardini, R. Izquierdo, M. Á. Sotelo","Lane-changing maneuvers, particularly those executed abruptly or in risky
situations, are a significant cause of road traffic accidents. However, current
research mainly focuses on predicting safe lane changes. Furthermore, existing
accident datasets are often based on images only and lack comprehensive sensory
data. In this work, we focus on predicting risky lane changes using the CRASH
dataset (our own collected dataset specifically for risky lane changes), and
safe lane changes (using the HighD dataset). Then, we leverage KG and Bayesian
inference to predict these maneuvers using linguistic contextual information,
enhancing the model's interpretability and transparency. The model achieved a
91.5% f1-score with anticipation time extending to four seconds for risky lane
changes, and a 90.0% f1-score for predicting safe lane changes with the same
anticipation time. We validate our model by integrating it into a vehicle
within the CARLA simulator in scenarios that involve risky lane changes. The
model managed to anticipate sudden lane changes, thus providing automated
vehicles with further time to plan and execute appropriate safe reactions.
Finally, to enhance the explainability of our model, we utilize RAG to provide
clear and natural language explanations for the given prediction.",http://arxiv.org/abs/2501.11560v1
"Quantification of Flagellar Gait Changes with Combined Shape Mode
  Analysis and Swimming Simulations",2025-01-02T22:10:47Z,"Kelli E. Gutierrez, Robert D. Guy, Becca Thomases, Paulo E. Arratia","Many different microswimmers propel themselves using flagella that beat
periodically. The shape of the flagellar beat and swimming speed have been
observed to change with fluid rheology. We quantify changes in the flagellar
waveforms of Chlamydomonas reinhardtii in response to changes in fluid
viscosity using (1) shape mode analysis and (2) a full swimmer simulation to
analyze how shape changes affect the swimming speed and to explore the
dimensionality of the shape space. By decomposing the gait into the
time-independent mean shape and the time-varying stroke, we find that the
flagellar mean shape substantially changes in response to viscosity, while the
changes in the time-varying stroke are more subtle. Using the swimmer
simulation, we quantify how the swimming speed is affected by the
dimensionality of the flagellar shape reconstruction, and we show that the
observed change in swimming speed with viscosity is explained by the variations
in mean flagellar shape and beat frequency, while the changes in swimming speed
from the different time-varying strokes are on the scale of variation between
cells.",http://arxiv.org/abs/2501.01554v1
"Identifying rapid changes in the hemodynamic response in event-related
  functional magnetic resonance imaging",2025-02-18T16:12:04Z,"Friederike Preusse, Thorsten Dickhaus, André Brechmann","The hemodynamic response (HR) in event-related functional magnetic resonance
imaging is typically assumed to be stationary. While there are some approaches
in the literature to model nonstationary HRs, few focus on rapid changes. In
this work, we propose two procedures to investigate rapid changes in the HR.
Both procedures make inference on the existence of rapid changes for
multi-subject data. We allow the change point locations to vary between
subjects, conditions and brain regions. The first procedure utilizes available
information about the change point locations to compare multiple shape
parameters of the HR over time. In the second procedure, the change point
locations are determined for each subject separately. To account for the
estimation of the change point locations, we propose the notion of post
selection variance. The power of the proposed procedures is assessed in
simulation studies. We apply the procedure for pre-specified change point
locations to data from a category learning experiment.",http://arxiv.org/abs/2502.12989v1
"Change Point Detection for Random Objects with Possibly Periodic
  Behavior",2025-01-03T06:20:19Z,"Jiazhen Xu, Andrew T. A. Wood, Tao Zou","Time-varying random objects have been increasingly encountered in modern data
analysis. Moreover, in a substantial number of these applications, periodic
behavior of the random objects has been observed. We introduce a new, powerful
scan statistic and corresponding test for the precise identification and
localization of abrupt changes in the distribution of non-Euclidean random
objects with possibly periodic behavior. Our approach is nonparametric and
effectively captures the entire distribution of these random objects.
Remarkably, it operates with minimal tuning parameters, requiring only the
specification of cut-off intervals near endpoints, where change points are
assumed not to occur. Our theoretical contributions include deriving the
asymptotic distribution of the test statistic under the null hypothesis of no
change points, establishing the consistency of the test in the presence of
change points under contiguous alternatives and providing rigorous guarantees
on the near-optimal consistency in estimating the number and locations of
change points, whether dealing with a single change point or multiple ones. We
demonstrate that the most competitive method currently in the literature for
change point detection in random objects is degraded by periodic behavior, as
periodicity leads to blurring of the changes that this procedure aims to
discover. Through comprehensive simulation studies, we demonstrate the superior
power and accuracy of our approach in both detecting change points and
pinpointing their locations, across scenarios involving both periodic and
nonperiodic random objects. Our main application is to weighted networks,
represented through graph Laplacians. The proposed method delivers highly
interpretable results, as evidenced by the identification of meaningful change
points in the New York City Citi Bike sharing system that align with
significant historical events.",http://arxiv.org/abs/2501.01657v1
"Semantic-CD: Remote Sensing Image Semantic Change Detection towards
  Open-vocabulary Setting",2025-01-12T13:22:11Z,"Yongshuo Zhu, Lu Li, Keyan Chen, Chenyang Liu, Fugen Zhou, Zhenwei Shi","Remote sensing image semantic change detection is a method used to analyze
remote sensing images, aiming to identify areas of change as well as categorize
these changes within images of the same location taken at different times.
Traditional change detection methods often face challenges in generalizing
across semantic categories in practical scenarios. To address this issue, we
introduce a novel approach called Semantic-CD, specifically designed for
semantic change detection in remote sensing images. This method incorporates
the open vocabulary semantics from the vision-language foundation model, CLIP.
By utilizing CLIP's extensive vocabulary knowledge, our model enhances its
ability to generalize across categories and improves segmentation through fully
decoupled multi-task learning, which includes both binary change detection and
semantic change detection tasks. Semantic-CD consists of four main components:
a bi-temporal CLIP visual encoder for extracting features from bi-temporal
images, an open semantic prompter for creating semantic cost volume maps with
open vocabulary, a binary change detection decoder for generating binary change
detection masks, and a semantic change detection decoder for producing semantic
labels. Experimental results on the SECOND dataset demonstrate that Semantic-CD
achieves more accurate masks and reduces semantic classification errors,
illustrating its effectiveness in applying semantic priors from vision-language
foundation models to SCD tasks.",http://arxiv.org/abs/2501.06808v1
"ME-CPT: Multi-Task Enhanced Cross-Temporal Point Transformer for Urban
  3D Change Detection",2025-01-23T13:07:41Z,"Luqi Zhang, Haiping Wang, Chong Liu, Zhen Dong, Bisheng Yang","The point clouds collected by the Airborne Laser Scanning (ALS) system
provide accurate 3D information of urban land covers. By utilizing
multi-temporal ALS point clouds, semantic changes in urban area can be
captured, demonstrating significant potential in urban planning, emergency
management, and infrastructure maintenance. Existing 3D change detection
methods struggle to efficiently extract multi-class semantic information and
change features, still facing the following challenges: (1) the difficulty of
accurately modeling cross-temporal point clouds spatial relationships for
effective change feature extraction; (2) class imbalance of change samples
which hinders distinguishability of semantic features; (3) the lack of
real-world datasets for 3D semantic change detection. To resolve these
challenges, we propose the Multi-task Enhanced Cross-temporal Point Transformer
(ME-CPT) network. ME-CPT establishes spatiotemporal correspondences between
point cloud across different epochs and employs attention mechanisms to jointly
extract semantic change features, facilitating information exchange and change
comparison. Additionally, we incorporate a semantic segmentation task and
through the multi-task training strategy, further enhance the
distinguishability of semantic features, reducing the impact of class imbalance
in change types. Moreover, we release a 22.5 $km^2$ 3D semantic change
detection dataset, offering diverse scenes for comprehensive evaluation.
Experiments on multiple datasets show that the proposed MT-CPT achieves
superior performance compared to existing state-of-the-art methods. The source
code and dataset will be released upon acceptance at
https://github.com/zhangluqi0209/ME-CPT.",http://arxiv.org/abs/2501.14004v2
High-Dimensional Sequential Change Detection,2025-02-07T23:15:06Z,"Robert Malinas, Dogyoon Song, Benjamin D. Robinson, Alfred O. Hero III","We address the problem of detecting a change in the distribution of a
high-dimensional multivariate normal time series. Assuming that the post-change
parameters are unknown and estimated using a window of historical data, we
extend the framework of quickest change detection (QCD) to the highdimensional
setting in which the number of variables increases proportionally with the size
of the window used to estimate the post-change parameters. Our analysis reveals
that an information theoretic quantity, which we call the Normalized High-
Dimensional Kullback-Leibler divergence (NHDKL), governs the high-dimensional
asymptotic performance of QCD procedures. Specifically, we show that the
detection delay is asymptotically inversely proportional to the difference
between the NHDKL of the true post-change versus pre-change distributions and
the NHDKL of the true versus estimated post-change distributions. In cases of
perfect estimation, where the latter NHDKL is zero, the delay is inversely
proportional to the NHDKL between the post-change and pre-change distributions
alone. Thus, our analysis is a direct generalization of the traditional
fixed-dimension, large-sample asymptotic framework, where the standard KL
divergence is asymptotically inversely proportional to detection delay.
Finally, we identify parameter estimators that asymptotically minimize the
NHDKL between the true versus estimated post-change distributions, resulting in
a QCD method that is guaranteed to outperform standard approaches based on
fixed-dimension asymptotics.",http://arxiv.org/abs/2502.05377v2
Sensitivity of Room Impulse Responses in Changing Acoustic Environment,2025-01-02T11:30:12Z,Karolina Prawda,"Changes in room acoustics, such as modifications to surface absorption or the
insertion of a scattering object, significantly impact measured room impulse
responses (RIRs). These changes can affect the performance of systems used in
echo cancellation and active acoustics and support tasks such as navigation and
object tracking. Recognizing and quantifying such changes is, therefore,
critical for advancing technologies based on room acoustics. This study
introduces a method for analyzing acoustic environment changes by evaluating
the similarity of consecutively recorded RIRs. Short-time coherence is employed
to characterize modifications, including changes in wall absorption or the
presence of a moving person in the room. A sensitivity rating is further used
to quantify the magnitude of these changes. The results clearly differentiate
between types of modifications -- atmospheric variation, changes in absorption,
and human presence. The methods described provide a novel approach to analyzing
and interpreting room acoustics, emphasizing RIR similarity and extracting
information from temporal and spectral signal properties.",http://arxiv.org/abs/2501.01206v1
Metamaterials that learn to change shape,2025-01-21T08:09:52Z,"Yao Du, Jonas Veenstra, Ryan van Mastrigt, Corentin Coulais","Learning to change shape is a fundamental strategy of adaptation and
evolution of living organisms, from bacteria and cells to tissues and animals.
Human-made materials can also exhibit advanced shape morphing capabilities, but
lack the ability to learn. Here, we build metamaterials that can learn complex
shape-changing responses using a contrastive learning scheme. By being shown
examples of the target shape changes, our metamaterials are able to learn those
shape changes by progressively updating internal learning degrees of freedom --
the local stiffnesses. Unlike traditional materials that are designed once and
for all, our metamaterials have the ability to forget and learn new shape
changes in sequence, to learn multiple shape changes that break reciprocity,
and to learn multistable shape changes, which in turn allows them to perform
reflex gripping actions and locomotion. Our findings establish metamaterials as
an exciting platform for physical learning, which in turn opens avenues for the
use of physical learning to design adaptive materials and robots.",http://arxiv.org/abs/2501.11958v1
DynamicEarth: How Far are We from Open-Vocabulary Change Detection?,2025-01-22T15:02:43Z,"Kaiyu Li, Xiangyong Cao, Yupeng Deng, Chao Pang, Zepeng Xin, Deyu Meng, Zhi Wang","Monitoring Earth's evolving land covers requires methods capable of detecting
changes across a wide range of categories and contexts. Existing change
detection methods are hindered by their dependency on predefined classes,
reducing their effectiveness in open-world applications. To address this issue,
we introduce open-vocabulary change detection (OVCD), a novel task that bridges
vision and language to detect changes across any category. Considering the lack
of high-quality data and annotation, we propose two training-free frameworks,
M-C-I and I-M-C, which leverage and integrate off-the-shelf foundation models
for the OVCD task. The insight behind the M-C-I framework is to discover all
potential changes and then classify these changes, while the insight of I-M-C
framework is to identify all targets of interest and then determine whether
their states have changed. Based on these two frameworks, we instantiate to
obtain several methods, e.g., SAM-DINOv2-SegEarth-OV, Grounding-DINO-SAM2-DINO,
etc. Extensive evaluations on 5 benchmark datasets demonstrate the superior
generalization and robustness of our OVCD methods over existing supervised and
unsupervised methods. To support continued exploration, we release
DynamicEarth, a dedicated codebase designed to advance research and application
of OVCD. https://likyoo.github.io/DynamicEarth",http://arxiv.org/abs/2501.12931v1
Non-evolutionary effects on period change in Magellanic Cepheids,2025-01-03T12:13:09Z,"R. S. Rathour, R. Smolec, G. Hajdu, P. Karczmarek, V. Hocdé, O. Ziółkowska, I. Soszyński, A. Udalski","Classical Cepheids are a cornerstone class of pulsators, fundamental to
testing stellar evolution and pulsation theories. Their secular period changes,
characterized through $O-C$ (Observed minus Calculated) diagrams, offer
valuable insights into their evolution. While evolutionary period changes are
well understood from both observational and theoretical perspectives, shorter
timescale period changes (on the order of ($\sim$ 10$^{2}$-10$^{4}$ days) -
known as non-evolutionary period changes are yet to be systematically explored.
  In this work, we present a detailed and comprehensive search for
non-evolutionary period changes using $O-C$ analysis of Magellanic Cloud (MC)
Cepheids, based on 20+ years of OGLE photometry data. Our sample includes both
the Large Magellanic Cloud (LMC) and the Small Magellanic Cloud (SMC) Cepheids,
focusing on single radial mode Cepheids (both fundamental (FU) and first
overtone (FO) modes). The results are grouped into two phenomena: (a) Cepheids
in binary systems (b) Non-linear period changes.",http://arxiv.org/abs/2501.01777v2
"Change Detection-Based Procedures for Piecewise Stationary MABs: A
  Modular Approach",2025-01-02T15:18:18Z,"Yu-Han Huang, Argyrios Gerogiannis, Subhonmesh Bose, Venugopal V. Veeravalli","Conventional Multi-Armed Bandit (MAB) algorithms are designed for stationary
environments, where the reward distributions associated with the arms do not
change with time. In many applications, however, the environment is more
accurately modeled as being nonstationary. In this work, piecewise stationary
MAB (PS-MAB) environments are investigated, in which the reward distributions
associated with a subset of the arms change at some change-points and remain
stationary between change-points. Our focus is on the asymptotic analysis of
PS-MABs, for which practical algorithms based on change detection (CD) have
been previously proposed. Our goal is to modularize the design and analysis of
such CD-based Bandit (CDB) procedures. To this end, we identify the
requirements for stationary bandit algorithms and change detectors in a CDB
procedure that are needed for the modularization. We assume that the rewards
are sub-Gaussian. Under this assumption and a condition on the separation of
the change-points, we show that the analysis of CDB procedures can indeed be
modularized, so that regret bounds can be obtained in a unified manner for
various combinations of change detectors and bandit algorithms. Through this
analysis, we develop new modular CDB procedures that are order-optimal. We
compare the performance of our modular CDB procedures with various other
methods in simulations.",http://arxiv.org/abs/2501.01291v1
The NuSTAR view of five changing-look active galactic nuclei,2025-01-16T15:23:22Z,"Bing Lyu, Zhen Yan, Xue-bing Wu, Qingwen Wu, Wenfei Yu, Hao Liu","Changing-look active galactic nuclei (CLAGNs) are known to change their
spectral type between 1 and 2 (changing-state) or change their absorption
between Compton-thick and Compton-thin (changing-obscuration) on timescales of
years or less. The physical mechanism and possible connection between the two
types of CLAGNs are still unclear. We explore the evolution of the broadband
X-ray spectra from Nuclear Spectroscopic Telescope Array (\nustar\,) and column
density in five CLAGNs with moderate inclination viewing angles, which have
shown significant variations of both optical types and X-ray absorption. Based
on a phenomenological and two clumpy torus models, we find that the X-ray
photon index ($\Gamma$) and the Eddington-scaled X-ray $2-10$ keV luminosity
($L_{\rm X}/L_{\rm Edd}$) are positively correlated for the five sources, which
are similar to other bright AGNs and optical CLAGNs at type 1 phase. We find a
significant negative correlation between log$N_\mathrm{H,los}$ and log$L_{\rm
X}/L_{\rm Edd}$ except for ESO 362-G18. Similar to changing-state AGNs,
changing-obscuration AGNs may be also triggered by the evolution of the
accretion disc. Our results support the disc wind scenario, where the disc wind
proportional to the accretion rate and formed at moderate inclination angles
would push the obscuration material further away and decrease the column
density from the line of sight observed in the changing-look AGNs.",http://arxiv.org/abs/2501.09602v1
"A Remote Sensing Image Change Detection Method Integrating Layer
  Exchange and Channel-Spatial Differences",2025-01-19T00:14:20Z,"Sijun Dong, Fangcheng Zuo, Geng Chen, Siming Fu, Xiaoliang Meng","Change detection in remote sensing imagery is a critical technique for Earth
observation, primarily focusing on pixel-level segmentation of change regions
between bi-temporal images. The essence of pixel-level change detection lies in
determining whether corresponding pixels in bi-temporal images have changed. In
deep learning, the spatial and channel dimensions of feature maps represent
different information from the original images. In this study, we found that in
change detection tasks, difference information can be computed not only from
the spatial dimension of bi-temporal features but also from the channel
dimension. Therefore, we designed the Channel-Spatial Difference Weighting
(CSDW) module as an aggregation-distribution mechanism for bi-temporal features
in change detection. This module enhances the sensitivity of the change
detection model to difference features. Additionally, bi-temporal images share
the same geographic location and exhibit strong inter-image correlations. To
construct the correlation between bi-temporal images, we designed a decoding
structure based on the Layer-Exchange (LE) method to enhance the interaction of
bi-temporal features. Comprehensive experiments on the CLCD, PX-CLCD, LEVIR-CD,
and S2Looking datasets demonstrate that the proposed LENet model significantly
improves change detection performance. The code and pre-trained models will be
available at: https://github.com/dyzy41/lenet.",http://arxiv.org/abs/2501.10905v1
"Plug-and-Play DISep: Separating Dense Instances for Scene-to-Pixel
  Weakly-Supervised Change Detection in High-Resolution Remote Sensing Images",2025-01-09T02:52:30Z,"Zhenghui Zhao, Chen Wu, Lixiang Ru, Di Wang, Hongruixuan Chen, Cuiqun Chen","Existing Weakly-Supervised Change Detection (WSCD) methods often encounter
the problem of ""instance lumping"" under scene-level supervision, particularly
in scenarios with a dense distribution of changed instances (i.e., changed
objects). In these scenarios, unchanged pixels between changed instances are
also mistakenly identified as changed, causing multiple changes to be
mistakenly viewed as one. In practical applications, this issue prevents the
accurate quantification of the number of changes. To address this issue, we
propose a Dense Instance Separation (DISep) method as a plug-and-play solution,
refining pixel features from a unified instance perspective under scene-level
supervision. Specifically, our DISep comprises a three-step iterative training
process: 1) Instance Localization: We locate instance candidate regions for
changed pixels using high-pass class activation maps. 2) Instance Retrieval: We
identify and group these changed pixels into different instance IDs through
connectivity searching. Then, based on the assigned instance IDs, we extract
corresponding pixel-level features on a per-instance basis. 3) Instance
Separation: We introduce a separation loss to enforce intra-instance pixel
consistency in the embedding space, thereby ensuring separable instance feature
representations. The proposed DISep adds only minimal training cost and no
inference cost. It can be seamlessly integrated to enhance existing WSCD
methods. We achieve state-of-the-art performance by enhancing {three
Transformer-based and four ConvNet-based methods} on the LEVIR-CD, WHU-CD,
DSIFN-CD, SYSU-CD, and CDD datasets. Additionally, our DISep can be used to
improve fully-supervised change detection methods. Code is available at
https://github.com/zhenghuizhao/Plug-and-Play-DISep-for-Change-Detection.",http://arxiv.org/abs/2501.04934v2
Flavor-changing Lorentz and CPT violation in muonic atoms,2025-01-10T14:18:05Z,"Alan Kostelecky, W. P. McNulty, E. Passemar, N. Sherrill","Flavor-changing signatures of Lorentz and CPT violation involving
muon-electron conversions in muonic atoms are studied using effective field
theory. Constraints on coefficients for Lorentz violation at parts in
$10^{-12}$ GeV$^{-1}$ for flavor-changing electromagnetic muon decays and parts
in $10^{-13}$ GeV$^{-2}$ for flavor-changing 4-point quark-lepton interactions
are extracted using existing data from the SINDRUM II experiment at the Paul
Scherrer Institute. Estimates are provided for sensitivities attainable in the
forthcoming experiments Mu2e at Fermilab and COMET at the Japan Proton
Accelerator Complex.",http://arxiv.org/abs/2501.05986v1
"Seismic regularity coefficient changes precede stronger earthquakes in
  Santorini swarm",2025-02-17T12:58:26Z,"Stanislaw Lasocki, Beata Orlecka-Sikora, Anastasios Kostoglou, Vasileios G. Karakostas, Eleftheria E. Papadimitrio","We have been analyzing the ongoing seismic swarm in Santorini, Greece, with
the Seismic Regularity (dc) and Seismic Strain Dynamics (SSD) coefficients,
which quantify temporal changes in seismic process organization and strain
energy release. Stronger earthquakes are preceded by characteristic down-up
changes of dc. Such a change indicates an increase in the seismic process
regularity followed by a fast transition to a more irregular and chaotic
seismic regime.",http://arxiv.org/abs/2502.11768v1
"CD-Lamba: Boosting Remote Sensing Change Detection via a Cross-Temporal
  Locally Adaptive State Space Model",2025-01-26T08:51:10Z,"Zhenkai Wu, Xiaowen Ma, Rongrong Lian, Kai Zheng, Mengting Ma, Wei Zhang, Siyang Song","Mamba, with its advantages of global perception and linear complexity, has
been widely applied to identify changes of the target regions within the remote
sensing (RS) images captured under complex scenarios and varied conditions.
However, existing remote sensing change detection (RSCD) approaches based on
Mamba frequently struggle to effectively perceive the inherent locality of
change regions as they direct flatten and scan RS images (i.e., the features of
the same region of changes are not distributed continuously within the sequence
but are mixed with features from other regions throughout the sequence). In
this paper, we propose a novel locally adaptive SSM-based approach, termed
CD-Lamba, which effectively enhances the locality of change detection while
maintaining global perception. Specifically, our CD-Lamba includes a Locally
Adaptive State-Space Scan (LASS) strategy for locality enhancement, a
Cross-Temporal State-Space Scan (CTSS) strategy for bi-temporal feature fusion,
and a Window Shifting and Perception (WSP) mechanism to enhance interactions
across segmented windows. These strategies are integrated into a multi-scale
Cross-Temporal Locally Adaptive State-Space Scan (CT-LASS) module to
effectively highlight changes and refine changes' representations feature
generation. CD-Lamba significantly enhances local-global spatio-temporal
interactions in bi-temporal images, offering improved performance in RSCD
tasks. Extensive experimental results show that CD-Lamba achieves
state-of-the-art performance on four benchmark datasets with a satisfactory
efficiency-accuracy trade-off. Our code is publicly available at
https://github.com/xwmaxwma/rschange.",http://arxiv.org/abs/2501.15455v1
"Detecting Abrupt Changes in Point Processes: Fundamental Limits and
  Applications",2025-01-14T19:14:24Z,"Anna Brandenberger, Elchanan Mossel, Anirudh Sridhar","We consider the problem of detecting abrupt changes (i.e., large jump
discontinuities) in the rate function of a point process. The rate function is
assumed to be fully unknown, non-stationary, and may itself be a random process
that depends on the history of event times. We show that abrupt changes can be
accurately identified from observations of the point process, provided the
changes are sharper than the ""smoothness'' of the rate function before the
abrupt change. This condition is also shown to be necessary from an
information-theoretic point of view. We then apply our theory to several
special cases of interest, including the detection of significant changes in
piecewise smooth rate functions and detecting super-spreading events in
epidemic models on graphs. Finally, we confirm the effectiveness of our methods
through a detailed empirical analysis of both synthetic and real datasets.",http://arxiv.org/abs/2501.08392v1
"Multiple change point detection based on Hodrick-Prescott and $l_1$
  filtering method for random walk time series data",2025-01-21T00:47:45Z,Xiyuan Liu,"We propose new methods for detecting multiple change points in time series,
specifically designed for random walk processes, where stationarity and
variance changes present challenges. Our approach combines two trend estimation
methods: the Hodrick Prescott (HP) filter and the l1 filter. A major challenge
in these methods is selecting the tuning parameter lambda, which we address by
introducing two selection techniques. For the HP based change point detection,
we propose a probability-based threshold to select lambda under the assumption
of an exponential distribution. For the l1 based method, we suggest a selection
strategy assuming normality. Additionally, we introduce a technique to estimate
the maximum number of change points in time segments using the l1 based method.
We validate our methods by comparing them to similar techniques, such as PELT,
using simulated data. We also demonstrate the practical application of our
approach to real-world SNP stock data, showcasing its effectiveness in
detecting change points.",http://arxiv.org/abs/2501.11805v2
Hypo3D: Exploring Hypothetical Reasoning in 3D,2025-02-02T23:11:42Z,"Ye Mao, Weixun Luo, Junpeng Jing, Anlan Qiu, Krystian Mikolajczyk","The rise of vision-language foundation models marks an advancement in
bridging the gap between human and machine capabilities in 3D scene reasoning.
Existing 3D reasoning benchmarks assume real-time scene accessibility, which is
impractical due to the high cost of frequent scene updates. To this end, we
introduce Hypothetical 3D Reasoning, namely Hypo3D, a benchmark designed to
evaluate models' ability to reason without access to real-time scene data.
Models need to imagine the scene state based on a provided change description
before reasoning. Hypo3D is formulated as a 3D Visual Question Answering (VQA)
benchmark, comprising 7,727 context changes across 700 indoor scenes, resulting
in 14,885 question-answer pairs. An anchor-based world frame is established for
all scenes, ensuring consistent reference to a global frame for directional
terms in context changes and QAs. Extensive experiments show that
state-of-the-art foundation models struggle to reason in hypothetically changed
scenes. This reveals a substantial performance gap compared to humans,
particularly in scenarios involving movement changes and directional reasoning.
Even when the context change is irrelevant to the question, models often
incorrectly adjust their answers.",http://arxiv.org/abs/2502.00954v2
"EHCTNet: Enhanced Hybrid of CNN and Transformer Network for Remote
  Sensing Image Change Detection",2025-01-02T12:55:36Z,"Junjie Yang, Haibo Wan, Zhihai Shang","Remote sensing (RS) change detection incurs a high cost because of false
negatives, which are more costly than false positives. Existing frameworks,
struggling to improve the Precision metric to reduce the cost of false
positive, still have limitations in focusing on the change of interest, which
leads to missed detections and discontinuity issues. This work tackles these
issues by enhancing feature learning capabilities and integrating the frequency
components of feature information, with a strategy to incrementally boost the
Recall value. We propose an enhanced hybrid of CNN and Transformer network
(EHCTNet) for effectively mining the change information of interest. Firstly, a
dual branch feature extraction module is used to extract the multi scale
features of RS images. Secondly, the frequency component of these features is
exploited by a refined module I. Thirdly, an enhanced token mining module based
on the Kolmogorov Arnold Network is utilized to derive semantic information.
Finally, the semantic change information's frequency component, beneficial for
final detection, is mined from the refined module II. Extensive experiments
validate the effectiveness of EHCTNet in comprehending complex changes of
interest. The visualization outcomes show that EHCTNet detects more intact and
continuous changed areas and perceives more accurate neighboring distinction
than state of the art models.",http://arxiv.org/abs/2501.01238v1
"CI at Scale: Lean, Green, and Fast",2025-01-07T00:04:29Z,"Dhruva Juloori, Zhongpeng Lin, Matthew Williams, Eddy Shin, Sonal Mahajan","Maintaining a ""green"" mainline branch, where all builds pass successfully, is
crucial but challenging in fast-paced, large-scale software development
environments, particularly with concurrent code changes in large monorepos.
SubmitQueue, a system designed to address these challenges, speculatively
executes builds and only lands changes with successful outcomes. However,
despite its effectiveness, the system faces inefficiencies in resource
utilization, leading to a high rate of premature build aborts and delays in
landing smaller changes blocked by larger conflicting ones. This paper
introduces enhancements to SubmitQueue, focusing on optimizing resource usage
and improving build prioritization. Central to this is our innovative
probabilistic model, which distinguishes between changes with shorter and
longer build times to prioritize builds for more efficient scheduling. By
leveraging a machine learning model to predict build times and incorporating
this into the probabilistic framework, we expedite the landing of smaller
changes blocked by conflicting larger time-consuming changes. Additionally,
introducing a concept of speculation threshold ensures that only the most
likely builds are executed, reducing unnecessary resource consumption. After
implementing these enhancements across Uber's major monorepos (Go, iOS, and
Android), we observed a reduction in Continuous Integration (CI) resource usage
by approximately 53%, CPU usage by 44%, and P95 waiting times by 37%. These
improvements highlight the enhanced efficiency of SubmitQueue in managing
large-scale software changes while maintaining a green mainline.",http://arxiv.org/abs/2501.03440v1
"Automatic detection and prediction of nAMD activity change in retinal
  OCT using Siamese networks and Wasserstein Distance for ordinality",2025-01-24T08:35:22Z,"Taha Emre, Teresa Araújo, Marzieh Oghbaie, Dmitrii Lachinov, Guilherme Aresta, Hrvoje Bogunović","Neovascular age-related macular degeneration (nAMD) is a leading cause of
vision loss among older adults, where disease activity detection and
progression prediction are critical for nAMD management in terms of timely drug
administration and improving patient outcomes. Recent advancements in deep
learning offer a promising solution for predicting changes in AMD from optical
coherence tomography (OCT) retinal volumes. In this work, we proposed deep
learning models for the two tasks of the public MARIO Challenge at MICCAI 2024,
designed to detect and forecast changes in nAMD severity with longitudinal
retinal OCT. For the first task, we employ a Vision Transformer (ViT) based
Siamese Network to detect changes in AMD severity by comparing scan embeddings
of a patient from different time points. To train a model to forecast the
change after 3 months, we exploit, for the first time, an Earth Mover
(Wasserstein) Distance-based loss to harness the ordinal relation within the
severity change classes. Both models ranked high on the preliminary
leaderboard, demonstrating that their predictive capabilities could facilitate
nAMD treatment management.",http://arxiv.org/abs/2501.14323v1
"Functional limit theorems for a time-changed multidimensional Wiener
  process",2025-01-18T16:46:18Z,"Yuliia Mishura, René L. Schilling","We study the asymptotic behaviour of a properly normalized time-changed
multidimensional Wiener process; the time change is given by an additive
functional of the Wiener process itself. At the level of generators, the time
change means that we consider the Laplace operator -- which generates a
multidimensional Wiener process -- and multiply it by a (possibly degenerate)
state-space dependent intensity. We assume that the intensity admits limits at
infinity in each octant of the state space, but the values of these limits may
be different. Applying a functional limit theorem for the superposition of
stochastic processes, we prove functional limit theorems for the normalized
time-changed multidimensional Wiener process. Among the possible limits there
is a multidimensional analogue of skew Brownian motion.",http://arxiv.org/abs/2501.10820v1
Towards Change Impact Analysis in Microservices-based System Evolution,2025-01-20T23:08:26Z,"Tomas Cerny, Gabriel Goulis, Amr S. Abdelfattah","Cloud-native systems are the mainstream for enterprise solutions, given their
scalability, resilience, and other benefits. While the benefits of cloud-native
systems fueled by microservices are known, less guidance exists on their
evolution. One could assume that since microservices encapsulate their code,
code changes remain encapsulated as well; however, the community is becoming
more aware of the possible consequences of code change propagation across
microservices. Moreover, an active mitigation instrument for negative
consequences of change propagation across microservices (i.e., ripple effect)
is yet missing, but the microservice community would greatly benefit from it.
This paper introduces what it could look like to have an infrastructure to
assist with change impact analysis across the entire microservice system and
intends to facilitate advancements in laying out the foundations and building
guidelines on microservice system evolution. It shares a new direction for
incremental software architecture reconstruction that could serve as the
infrastructure concept and demonstrates early results from prototyping to
illustrate the potential impact.",http://arxiv.org/abs/2501.11778v1
"CoDocBench: A Dataset for Code-Documentation Alignment in Software
  Maintenance",2025-02-01T18:45:32Z,"Kunal Pai, Premkumar Devanbu, Toufique Ahmed","One of the central tasks in software maintenance is being able to understand
and develop code changes. Thus, given a natural language description of the
desired new operation of a function, an agent (human or AI) might be asked to
generate the set of edits to that function to implement the desired new
operation; likewise, given a set of edits to a function, an agent might be
asked to generate a changed description, of that function's new workings. Thus,
there is an incentive to train a neural model for change-related tasks.
Motivated by this, we offer a new, ""natural"", large dataset of coupled changes
to code and documentation mined from actual high-quality GitHub projects, where
each sample represents a single commit where the code and the associated
docstring were changed together. We present the methodology for gathering the
dataset, and some sample, challenging (but realistic) tasks where our dataset
provides opportunities for both learning and evaluation. We find that current
models (specifically Llama-3.1 405B, Mixtral 8$\times$22B) do find these
maintenance-related tasks challenging.",http://arxiv.org/abs/2502.00519v2
"Online Correlation Change Detection for Large-Dimensional Data with An
  Application to Forecasting of El Niño Events",2025-02-03T03:02:34Z,"Jie Gao, Liyan Xie, Zhaoyuan Li","We consider detecting change points in the correlation structure of streaming
large-dimensional data with minimum assumptions posed on the underlying data
distribution. Depending on the $\ell_1$ and $\ell_{\infty}$ norms of the
squared difference of vectorized pre-change and post-change correlation
matrices, detection statistics are constructed for dense and sparse settings,
respectively. The proposed detection procedures possess the bless-dimension
property, as a novel algorithm for threshold selection is designed based on
sign-flip permutation. Theoretical evaluations of the proposed methods are
conducted in terms of average run length and expected detection delay.
Numerical studies are conducted to examine the finite sample performances of
the proposed methods. Our methods are effective because the average detection
delays have slopes similar to that of the optimal exact CUSUM test. Moreover, a
combined $\ell_1$ and $\ell_{\infty}$ norm approach is proposed and has
expected performance for transitions from sparse to dense settings. Our method
is applied to forecast El Ni{\~n}o events and achieves state-of-the-art hit
rates greater than 0.86, while false alarm rates are 0. This application
illustrates the efficiency and effectiveness of our proposed methodology in
detecting fundamental changes with minimal delay.",http://arxiv.org/abs/2502.01010v1
"Generalized Counting Process with Random Drift and Different Brownian
  Clocks",2025-02-03T13:56:26Z,"Mostafizar Khandakar, Manisha Dhillon, Kuldeep Kumar Kataria","In this paper, we introduce drifted versions of the generalized counting
process (GCP) with a deterministic drift and a random drift. The composition of
stable subordinator with an independent inverse stable subordinator is taken as
the random drift. We derive the probability law and its governing fractional
differential equations for these drifted versions. Also, we study the GCP
time-changed with different Brownian clocks, for example, the Brownian first
passage-time with or without drift, elastic Brownian motion, Brownian sojourn
time on positive half-line and the Bessel times. For these time-changed
processes, we obtain the governing system of differential equation of their
state probabilities, probability generating function, etc. Further, we consider
a time-changed GCP where the time-change is done by subordinators linked to
incomplete gamma function. Later, we study the fractional integral of GCP and
its time-changed variant.",http://arxiv.org/abs/2502.01363v1
"Streaming Speaker Change Detection and Gender Classification for
  Transducer-Based Multi-Talker Speech Translation",2025-02-04T19:50:15Z,"Peidong Wang, Naoyuki Kanda, Jian Xue, Jinyu Li, Xiaofei Wang, Aswin Shanmugam Subramanian, Junkun Chen, Sunit Sivasankaran, Xiong Xiao, Yong Zhao","Streaming multi-talker speech translation is a task that involves not only
generating accurate and fluent translations with low latency but also
recognizing when a speaker change occurs and what the speaker's gender is.
Speaker change information can be used to create audio prompts for a zero-shot
text-to-speech system, and gender can help to select speaker profiles in a
conventional text-to-speech model. We propose to tackle streaming speaker
change detection and gender classification by incorporating speaker embeddings
into a transducer-based streaming end-to-end speech translation model. Our
experiments demonstrate that the proposed methods can achieve high accuracy for
both speaker change detection and gender classification.",http://arxiv.org/abs/2502.02683v1
Time change rigidity for unipotent flows,2025-02-12T03:06:12Z,"Elon Lindenstrauss, Daren Wei","We prove a dichotomy regarding the behavior of one-parameter unipotent flows
on quotients of semisimple lie groups under time change. We show that if
$u^{(1)}_t$ acting on $\mathbf{G}_{1}/\Gamma_1$ is such a flow it satisfies
exactly one of the following:
  (1) The flow is loosely Kronecker, and hence measurably isomorphic after an
appropriate time change to any other loosely Kronecker system.
  (2) The flow exhibits the following rigid behavior: if the one-parameter
unipotent flow $u^{(1)} _ t$ on $\mathbf{G}_1/\Gamma_1$ is measurably
isomorphic after time change to another such flow $u^{(2)} _ t$ on
$\mathbf{G}_2/\Gamma _ 2$, then $\mathbf{G}_1/\Gamma_1 $ is isomorphic to
$\mathbf{G}_2/ \Gamma_2$ with the isomorphism taking $u^{(1)}_t$ to $u^{(2)}_t$
and moreover the time change is cohomologous to a trivial one up to a
renormalization.",http://arxiv.org/abs/2502.08081v1
"Change-point problem: Direct estimation using a geometry inspired
  re-parametrization",2025-02-17T11:13:17Z,"Buddhananda Banerjee, Arnab Kumar Laha","Estimation of mean shift in a temporally ordered sequence of random variables
with a possible existence of change-point is an important problem in many
disciplines. In the available literature of more than fifty years the
estimation methods of the mean shift is usually dealt as a two-step problem. A
test for the existence of a change-point is followed by an estimation process
of the mean shift, which is known as testimator. The problem suffers from over
parametrization. When viewed as an estimation problem, we establish that the
maximum likelihood estimator (MLE) always gives a false alarm indicting an
existence of a change-point in the given sequence even though there is no
change-point at all. After modelling the parameter space as a modified horn
torus. We introduce a new method of estimation of the parameters. The newly
introduced estimation method of the mean shift is assessed with a proper
Riemannian metric on that conic manifold. It is seen that its performance is
superior compared to that of the MLE. The proposed method is implemented on
Bitcoin data and compared its performance with the performance of the MLE.",http://arxiv.org/abs/2502.11679v1
"Phase-change materials for volatile threshold resistive switching and
  neuronal device applications",2025-02-17T11:22:35Z,"Huandong Chen, Jayakanth Ravichandran","Volatile threshold resistive switching and neuronal oscillations in
phase-change materials, specifically those undergoing metal-to-insulator and
charge density wave transitions, offer unique attributes such as fast and
low-field volatile switching, tunability, and non-linear behaviors. These
characteristics are particularly promising for emulating neuronal behavior and
thus hold great potential for realizing energy-efficient neuromorphic
computing. In this review, we summarize recent advances in the development of
neuronal oscillator devices based on three archetypal electronic phase-change
materials: the correlated oxide VO2, the charge density wave transition metal
dichalcogenide 1T-TaS2, and the emerging phase-change chalcogenide perovskite
BaTiS3. We discuss progress from the perspective of materials development,
including structural phase transitions, synthesis methods, electrical
properties, and device implementation. Finally, we emphasize the major
challenges that must be addressed for practical applications of these
phase-change materials and provide our outlook on the future research
directions in this rapidly evolving field.",http://arxiv.org/abs/2502.11685v1
"How do Humans take an Object from a Robot: Behavior changes observed in
  a User Study",2025-01-03T22:41:14Z,"Parag Khanna, Elmira Yadollahi, Iolanda Leite, Mårten Björkman, Christian Smith","To facilitate human-robot interaction and gain human trust, a robot should
recognize and adapt to changes in human behavior. This work documents different
human behaviors observed while taking objects from an interactive robot in an
experimental study, categorized across two dimensions: pull force applied and
handedness. We also present the changes observed in human behavior upon
repeated interaction with the robot to take various objects.",http://arxiv.org/abs/2501.02127v1
"Maximum-Entropy-Rate Selection of Features for Classifying Changes in
  Knee and Ankle Dynamics During Running",2025-01-23T15:30:39Z,"Garry A. Einicke, Haider A. Sabti, David V. Thiel, Marta Fernandez","This paper investigates deteriorations in knee and ankle dynamics during
running. Changes in lower limb accelerations are analyzed by a wearable
musculo-skeletal monitoring system. The system employs a machine learning
technique to classify joint stiffness. A maximum-entropyrate method is
developed to select the most relevant features. Experimental results
demonstrate that distance travelled and energy expended can be estimated from
observed changes in knee and ankle motions during 5 km runs.",http://arxiv.org/abs/2501.13750v1
Passing through nondegenerate singularities in mean curvature flows,2025-01-28T03:24:31Z,"Ao Sun, Zhihan Wang, Jinxin Xue","In this paper, we study the properties of nondegenerate cylindrical
singularities of mean curvature flow. We prove they are isolated in spacetime
and provide a complete description of the geometry and topology change of the
flow passing through the singularities. Particularly, the topology change
agrees with the level sets change near a critical point of a Morse function,
which is the same as performing surgery. The proof is based on a new
$L^2$-distance monotonicity formula, which allows us to derive a discrete
almost monotonicity of the ``decay order"", a discrete mean curvature flow
analog to Almgren's frequency function.",http://arxiv.org/abs/2501.16678v1
"The simplest solutions of cold plasma equations: change in properties
  from a hydrodynamic to a kinetic model",2025-01-29T18:01:25Z,"Lidia V. Gargyants, Olga S. Rozanova","We consider the transition from the kinetic model of Landau cold plasma to
the hydrodynamic one by constructing a ""multi-speed"" moment chain in the case
of one spatial variable. Closing this chain at the first step leads to the
standard hydrodynamic system of cold plasma. The change in the properties of
the solution when closing the chain at the second step is discussed using the
example of two classes of solutions - affine in space and traveling waves, and
it is shown that their properties change significantly compared to the
hydrodynamic model.",http://arxiv.org/abs/2501.17812v1
"A Methodology for Studying Linguistic and Cultural Change in China,
  1900-1950",2025-02-06T18:33:50Z,Spencer Dean Stewart,"This paper presents a quantitative approach to studying linguistic and
cultural change in China during the first half of the twentieth century, a
period that remains understudied in computational humanities research. The
dramatic changes in Chinese language and culture during this time call for
greater reflection on the tools and methods used for text analysis. This
preliminary study offers a framework for analyzing Chinese texts from the late
nineteenth and twentieth centuries, demonstrating how established methods such
as word counts and word embeddings can provide new historical insights into the
complex negotiations between Western modernity and Chinese cultural discourse.",http://arxiv.org/abs/2502.04286v1
"Dynamics of ""Spontaneous"" Topic Changes in Next Token Prediction with
  Self-Attention",2025-01-10T23:18:23Z,"Mumin Jia, Jairo Diaz-Rodriguez","Human cognition can spontaneously shift conversation topics, often triggered
by emotional or contextual signals. In contrast, self-attention-based language
models depend on structured statistical cues from input tokens for next-token
prediction, lacking this spontaneity. Motivated by this distinction, we
investigate the factors that influence the next-token prediction to change the
topic of the input sequence. We define concepts of topic continuity, ambiguous
sequences, and change of topic, based on defining a topic as a set of token
priority graphs (TPGs). Using a simplified single-layer self-attention
architecture, we derive analytical characterizations of topic changes.
Specifically, we demonstrate that (1) the model maintains the priority order of
tokens related to the input topic, (2) a topic change can occur only if
lower-priority tokens outnumber all higher-priority tokens of the input topic,
and (3) unlike human cognition, longer context lengths and overlapping topics
reduce the likelihood of spontaneous redirection. These insights highlight
differences between human cognition and self-attention-based models in
navigating topic changes and underscore the challenges in designing
conversational AI capable of handling ""spontaneous"" conversations more
naturally. To the best of our knowledge, no prior work has explored these
questions with a focus as closely aligned to human conversation and thought.",http://arxiv.org/abs/2501.06382v2
"Evaluating Amazon Effects and the Limited Impact of COVID-19 With
  Purchases Crowdsourced from US Consumers",2025-01-17T23:03:56Z,"Alex Berke, Dana Calacci, Alex, Pentland, Kent Larson","We leverage a recently published dataset of Amazon purchase histories,
crowdsourced from thousands of US consumers, to study how online purchasing
behaviors have changed over time, how changes vary across demographic groups,
the impact of the COVID-19 pandemic, and relationships between online and
offline retail. This work provides a case study in how consumer-level purchases
data can reveal purchasing behaviors and trends beyond those available from
aggregate metrics. For example, in addition to analyzing spending behavior, we
develop new metrics to quantify changes in consumers' online purchase frequency
and the diversity of products purchased, to better reflect the growing ubiquity
and dominance of online retail. Between 2018 and 2022 these consumer-level
metrics grew on average by more than 85%, peaking in 2021. We find a steady
upward trend in individuals' online purchasing prior to COVID-19, with a
significant increase in the first year of COVID, but without a lasting effect.
Purchasing behaviors in 2022 were no greater than the result of the
pre-pandemic trend. We also find changes in purchasing significantly differ by
demographics, with different responses to the pandemic. We further use the
consumer-level data to show substitution effects between online and offline
retail in sectors where Amazon heavily invested: books, shoes, and grocery.
Prior to COVID we find year-to-year changes in the number of consumers making
online purchases for books and shoes negatively correlated with changes in
employment at local bookstores and shoe stores. During COVID we find online
grocery purchasing negatively correlated with in-store grocery visits. This
work demonstrates how crowdsourced, open purchases data can enable economic
insights that may otherwise only be available to private firms.",http://arxiv.org/abs/2501.10596v1
"A Detailed Look at a Trio of Changing-Look Quasars: Spectral Energy
  Distributions and the Dust Extinction Test",2025-01-22T19:04:54Z,"Laura Duffy, Michael Eracleous, Jessie C. Runnoe, John J. Ruan, Scott F. Anderson, Sabrina Dimassimo, Paul Green, Stephanie LaMassa","Changing-look quasars exhibit dramatic variability in broad emission-line
fluxes on short timescales. This behavior is challenging to many models of the
quasar broad line region, due in large part to the short transition times
between high and low states. In order to constrain the cause of the dramatic
variability, we obtained contemporaneous Hubble Space Telescope UV and Hobby
Eberly Telescope optical spectra of three changing-look quasars caught in their
low state. We use these spectra, along with archival spectra taken during both
the high and low states, to investigate potential scenarios for the change in
state. Our data strongly disfavor a variable dust obscuration scenario for
these three CLQs, and instead suggest that the observed transformation reflects
a change in the intrinsic luminosity of the central engine. We also find that
the low-state spectral energy distributions of all three quasars are
reminiscent of those of low-luminosity active galactic nuclei, which suggests
that the transition may result from a change in accretion flow structure caused
by a reduced Eddington ratio.",http://arxiv.org/abs/2501.13174v1
Monitorization of the H-O Bond Flexibility,2025-01-01T03:12:18Z,Chang Q Sun,"Unlike conventional thought, the H-O bond is flexible, instead, and sensitive
to perturbation. This exercise empowers the electron and phonon spectroscopies
with the Tight-binding approach, enabling a referential database to
synchronically quantize the relaxation and flexibility of these identities for
substances involving the H-O bond during phonon spectroscopy.",http://arxiv.org/abs/2501.01469v1
Variations on the Expectation Due to Changes in the Probability Measure,2025-02-05T04:56:28Z,"Samir M. Perlaza, Gaetan Bisson","Closed-form expressions are presented for the variation of the expectation of
a given function due to changes in the probability measure used for the
expectation. They unveil interesting connections with Gibbs probability
measures, the mutual information, and the lautum information.",http://arxiv.org/abs/2502.02887v1
On the spectral theory of sign-changing Laplace operators,2025-02-06T07:47:20Z,Yves Colin de Verdière,"We study spectral theory of sign-changing Laplace operators using
semi-classical Dirichlet-to-Neumann maps. We prove the existence of
modesconcentrated on the interface and describe an effective semi-classical
equation for them.",http://arxiv.org/abs/2502.03838v1
Resurrecting saturated LLM benchmarks with adversarial encoding,2025-02-10T18:07:09Z,"Igor Ivanov, Dmitrii Volkov","Recent work showed that small changes in benchmark questions can reduce LLMs'
reasoning and recall. We explore two such changes: pairing questions and adding
more answer options, on three benchmarks: WMDP-bio, GPQA, and MMLU variants. We
find that for more capable models, these predictably reduce performance,
essentially heightening the performance ceiling of a benchmark and unsaturating
it again. We suggest this approach can resurrect old benchmarks.",http://arxiv.org/abs/2502.06738v1
"WeVibe: Weight Change Estimation Through Audio-Induced Shelf Vibrations
  In Autonomous Stores",2025-02-17T18:10:53Z,"Jiale Zhang, Yuyan Wu, Jesse R Codling, Yen Cheng Chang, Julia Gersey, Pei Zhang, Hae Young Noh, Yiwen Dong","Weight change estimation is crucial in various applications, particularly for
detecting pick-up and put-back actions when people interact with the shelf
while shopping in autonomous stores. Moreover, accurate weight change
estimation allows autonomous stores to automatically identify items being
picked up or put back, ensuring precise cost estimation. However, the
conventional approach of estimating weight changes requires specialized
weight-sensing shelves, which are densely deployed weight scales, incurring
intensive sensor consumption and high costs. Prior works explored the
vibration-based weight sensing method, but they failed when the location of
weight change varies.
  In response to these limitations, we made the following contributions: (1) We
propose WeVibe, a first item weight change estimation system through active
shelf vibration sensing. The main intuition of the system is that the weight
placed on the shelf influences the dynamic vibration response of the shelf,
thus altering the shelf vibration patterns. (2) We model a physics-informed
relationship between the shelf vibration response and item weight across
multiple locations on the shelf based on structural dynamics theory. This
relationship is linear and allows easy training of a weight estimation model at
a new location without heavy data collection. (3) We evaluate our system on a
gondola shelf organized as the real-store settings. WeVibe achieved a mean
absolute error down to 38.07g and a standard deviation of 31.2g with one sensor
and 10% samples from three weight classes on estimating weight change from 0g
to 450g, which can be leveraged for differentiating items with more than 100g
differences.",http://arxiv.org/abs/2502.12093v1
"The Change of Variable Formula Integrals, do they have equal value?",2025-02-18T09:35:13Z,Oswaldo Rio Branco de Oliveira,"Assuming that the two integrals in the Change of Variable Formula for the
unidimensional Riemann integral are finite, one can ask if they have equal
value. We give an answer to this question. The proof is very easy to follow and
to keep in mind. Two examples are given.",http://arxiv.org/abs/2502.12679v1
"New bounds in R.S. Lehman's estimates for the difference $π\left(
  x\right) -li\left( x\right) $",2025-01-08T13:14:54Z,Michael Revers,"We denote by $\pi\left( x\right) $ the usual prime counting function and let
$li\left( x\right) $ the logarithmic integral of $x$. In 1966, R.S. Lehman came
up with a new approach and an effective method for finding an upper bound where
it is assured that a sign change occurs for $\pi\left( x\right) -li\left(
x\right) $ for some value $x$ not higher than this given bound. In this paper
we provide further improvements on the error terms including an improvement
upon Lehman's famous error term $S_{3}$ in his original paper. We are now able
to eliminate the lower condition for the size-length $\eta$ completely. For
further numerical computations this enables us to establish sharper results on
the positions for the sign changes. We illustrate with some numerical
computations on the lowest known crossover regions near $10^{316}$ and we
discuss numerically on potential crossover regions below this value.",http://arxiv.org/abs/2501.04488v2
"Sequential Change Detection for Learning in Piecewise Stationary Bandit
  Environments",2025-01-19T07:27:24Z,"Yu-Han Huang, Venugopal V. Veeravalli","A finite-horizon variant of the quickest change detection problem is
investigated, which is motivated by a change detection problem that arises in
piecewise stationary bandits. The goal is to minimize the \emph{latency}, which
is smallest threshold such that the probability that the detection delay
exceeds the threshold is below a desired low level, while controlling the false
alarm probability to a desired low level. When the pre- and post-change
distributions are unknown, two tests are proposed as candidate solutions. These
tests are shown to attain order optimality in terms of the horizon.
Furthermore, the growth in their latencies with respect to the false alarm
probability and late detection probability satisfies a property that is
desirable in regret analysis for piecewise stationary bandits. Numerical
results are provided to validate the theoretical performance results.",http://arxiv.org/abs/2501.10974v2
Sequential Change Point Detection via Denoising Score Matching,2025-01-22T06:04:57Z,"Wenbin Zhou, Liyan Xie, Zhigang Peng, Shixiang Zhu","Sequential change-point detection plays a critical role in numerous
real-world applications, where timely identification of distributional shifts
can greatly mitigate adverse outcomes. Classical methods commonly rely on
parametric density assumptions of pre- and post-change distributions, limiting
their effectiveness for high-dimensional, complex data streams. This paper
proposes a score-based CUSUM change-point detection, in which the score
functions of the data distribution are estimated by injecting noise and
applying denoising score matching. We consider both offline and online versions
of score estimation. Through theoretical analysis, we demonstrate that
denoising score matching can enhance detection power by effectively controlling
the injected noise scale. Finally, we validate the practical efficacy of our
method through numerical experiments on two synthetic datasets and a real-world
earthquake precursor detection task, demonstrating its effectiveness in
challenging scenarios.",http://arxiv.org/abs/2501.12667v1
"A control system framework for counterfactuals: an optimization based
  approach",2025-01-22T14:43:05Z,"Pierluigi Francesco De Paola, Jared Miller, Alessandro Borri, Alessia Paglialonga, Fabrizio Dabbene","Counterfactuals are a concept inherited from the field of logic and in
general attain to the existence of causal relations between sentences or
events. In particular, this concept has been introduced also in the context of
interpretability in artificial intelligence, where counterfactuals refer to the
minimum change to the feature values that changes the prediction of a
classification model. The artificial intelligence framework of counterfactuals
is mostly focused on machine learning approaches, typically neglecting the
physics of the variables that determine a change in class. However, a
theoretical formulation of counterfactuals in a control system framework -
i.e., able to account for the mechanisms underlying a change in class - is
lacking. To fill this gap, in this work we propose an original control system,
physics-informed, theoretical foundation for counterfactuals, by means of the
formulation of an optimal control problem. We apply the proposed methodology to
a general glucose-insulin regulation model and results appear promising and
pave the way to the possible integration with artificial intelligence
techniques, with the aim of feeding machine learning models with the physics
knowledge acquired through the system framework.",http://arxiv.org/abs/2501.12914v1
Fixed-Budget Change Point Identification in Piecewise Constant Bandits,2025-01-22T15:30:44Z,"Joseph Lazzaro, Ciara Pike-Burke","We study the piecewise constant bandit problem where the expected reward is a
piecewise constant function with one change point (discontinuity) across the
action space $[0,1]$ and the learner's aim is to locate the change point. Under
the assumption of a fixed exploration budget, we provide the first
non-asymptotic analysis of policies designed to locate abrupt changes in the
mean reward function under bandit feedback. We study the problem under a large
and small budget regime, and for both settings establish lower bounds on the
error probability and provide algorithms with near matching upper bounds.
Interestingly, our results show a separation in the complexity of the two
regimes. We then propose a regime adaptive algorithm which is near optimal for
both small and large budgets simultaneously. We complement our theoretical
analysis with experimental results in simulated environments to support our
findings.",http://arxiv.org/abs/2501.12957v1
"Targeting heuristics for cost-optimized institutional incentives in
  heterogeneous networked populations",2025-01-23T12:45:08Z,"Dhruv Mittal, Fátima González-Novo López, Sara Constantino, Shaul Shalvi, Xiaojie Chen, Vítor V. Vasconcelos","The world is currently grappling with challenges on both local and global
scales, many of which demand coordinated behavioral changes. However, breaking
away from the status is often difficult due to deeply ingrained social norms.
In such cases, social systems may require seemingly exogenous interventions to
set off endogenous, largely irreversible processes that drive change -- social
tipping. While studies have looked at targeted interventions, real-life
constraints faced by policymakers, like minimizing costs while ensuring a quick
and fair transition, remain understudied. To address this complexity, we
introduce a game-theoretic framework that accounts for individual heterogeneity
and networks of local influence. We implement various heuristics based on
information about individual preferences and commonly used local network
properties. Results show that where the change is initiated in the population
and the direction in which it propagates is essential to the effectiveness of
interventions. We identify optimal strategies under different scenarios, such
as varying levels of resistance to change, preference heterogeneity, and
homophily. These results provide insights that can be experimentally tested and
help policymakers to better direct incentives.",http://arxiv.org/abs/2501.13623v1
Sampling with time-changed Markov processes,2025-01-25T09:37:59Z,"Andrea Bertazzi, Giorgos Vasdekis","We study time-changed Markov processes to speed up the convergence of Markov
chain Monte Carlo (MCMC) algorithms in the context of multimodal distributions
and rare event simulation. The time-changed process is defined by adjusting the
speed of time of a base process via a user-chosen, state-dependent function. We
apply this framework to several Markov processes from the MCMC literature, such
as Langevin diffusions and piecewise deterministic Markov processes, obtaining
novel modifications of classical algorithms and also re-discovering known MCMC
algorithms. We prove theoretical properties of the time-changed process under
suitable conditions on the base process, focusing on connecting the stationary
distributions and qualitative convergence properties such as geometric and
uniform ergodicity, as well as a functional central limit theorem. A comparison
with the framework of space transformations is provided, clarifying the
similarities between the approaches. Throughout the paper we give various
visualisations and numerical simulations on simple tasks to gain intuition on
the method and its performance.",http://arxiv.org/abs/2501.15155v1
"Pareto sensitivity, most-changing sub-fronts, and knee solutions",2025-01-28T14:50:50Z,"Tommaso Giovannelli, Marcos Medeiros Raimundo, Luis Nunes Vicente","When dealing with a multi-objective optimization problem, obtaining a
comprehensive representation of the Pareto front can be computationally
expensive. Furthermore, identifying the most representative Pareto solutions
can be difficult and sometimes ambiguous. A popular selection are the so-called
Pareto knee solutions, where a small improvement in any objective leads to a
large deterioration in at least one other objective. In this paper, using
Pareto sensitivity, we show how to compute Pareto knee solutions according to
their verbal definition of least maximal change. We refer to the resulting
approach as the sensitivity knee (snee) approach, and we apply it to
unconstrained and constrained problems. Pareto sensitivity can also be used to
compute the most-changing Pareto sub-fronts around a Pareto solution, where the
points are distributed along directions of maximum change, which could be of
interest in a decision-making process if one is willing to explore solutions
around a current one. Our approach is still restricted to scalarized methods,
in particular to the weighted-sum or epsilon-constrained methods, and require
the computation or approximations of first- and second-order derivatives. We
include numerical results from synthetic problems that illustrate the benefits
of our approach.",http://arxiv.org/abs/2501.16993v1
"A Proof of The Changepoint Detection Threshold Conjecture in
  Preferential Attachment Models",2025-02-01T18:19:36Z,"Hang Du, Shuyang Gong, Jiaming Xu","We investigate the problem of detecting and estimating a changepoint in the
attachment function of a network evolving according to a preferential
attachment model on $n$ vertices, using only a single final snapshot of the
network. Bet et al.~\cite{bet2023detecting} show that a simple test based on
thresholding the number of vertices with minimum degrees can detect the
changepoint when the change occurs at time $n-\Omega(\sqrt{n})$. They further
make the striking conjecture that detection becomes impossible for any test if
the change occurs at time $n-o(\sqrt{n}).$ Kaddouri et
al.~\cite{kaddouri2024impossibility} make a step forward by proving the
detection is impossible if the change occurs at time $n-o(n^{1/3}).$ In this
paper, we resolve the conjecture affirmatively, proving that detection is
indeed impossible if the change occurs at time $n-o(\sqrt{n}).$ Furthermore, we
establish that estimating the changepoint with an error smaller than
$o(\sqrt{n})$ is also impossible, thereby confirming that the estimator
proposed in Bhamidi et al.~\cite{bhamidi2018change} is order-optimal.",http://arxiv.org/abs/2502.00514v1
Modelling change in neural dynamics during phonetic accommodation,2025-02-03T10:00:29Z,"Sam Kirkham, Patrycja Strycharczuk, Rob Davies, Danielle Welburn","Short-term phonetic accommodation is a fundamental driver behind accent
change, but how does real-time input from another speaker's voice shape the
speech planning representations of an interlocutor? We advance a computational
model of change in phonetic representations during phonetic accommodation,
grounded in dynamic neural field equations for movement planning and memory
dynamics. We test the model's ability to capture empirical patterns from an
experimental study where speakers shadowed a model talker with a different
accent from their own. The experimental data shows vowel-specific degrees of
convergence during shadowing, followed by return to baseline (or minor
divergence) post-shadowing. The model can reproduce these phenomena by
modulating the magnitude of inhibitory memory dynamics, which may reflect
resistance to accommodation due to phonological and/or sociolinguistic
pressures. We discuss the implications of these results for the relation
between short-term phonetic accommodation and longer-term patterns of sound
change.",http://arxiv.org/abs/2502.01210v1
"The ""negative end"" of change in grammar: terminology, concepts and
  causes",2025-02-07T07:54:08Z,Karolina Rudnicka,"The topic of ""negative end"" of change is, contrary to the fields of
innovation and emergence, largely under-researched. Yet, it has lately started
to gain an increasing attention from language scholars worldwide. The main
focus of this article is threefold, namely to discuss the i) terminology; ii)
concepts and iii) causes associated with the ""negative end"" of change in
grammar. The article starts with an overview of research conducted on the
topic. It then moves to situating phenomena referred to as loss, decline or
obsolescence among processes of language change, before elaborating on the
terminology and concepts behind it. The last part looks at possible causes for
constructions to display a (gradual or rapid, but very consistent) decrease in
the frequency of use over time, which continues until the construction
disappears or there are only residual or fossilised forms left. Keywords: loss,
obsolescence, decline, competition, higher",http://arxiv.org/abs/2502.04729v1
Post-detection inference for sequential changepoint localization,2025-02-10T02:01:30Z,"Aytijhya Saha, Aaditya Ramdas","This paper addresses a fundamental but largely unexplored challenge in
sequential changepoint analysis: conducting inference following a detected
change. We study the problem of localizing the changepoint using only the data
observed up to a data-dependent stopping time at which a sequential detection
algorithm $\mathcal A$ declares a change. We first construct confidence sets
for the unknown changepoint when pre- and post-change distributions are assumed
to be known. We then extend our framework to composite pre- and post-change
scenarios. We impose no conditions on the observation space or on $\mathcal A$
-- we only need to be able to run $\mathcal A$ on simulated data sequences. In
summary, this work offers both theoretically sound and practically effective
tools for sequential changepoint localization.",http://arxiv.org/abs/2502.06096v1
"Kernels of Selfhood: GPT-4o shows humanlike patterns of cognitive
  consistency moderated by free choice",2025-01-27T02:25:12Z,"Steven A. Lehr, Ketan S. Saichandran, Eddie Harmon-Jones, Nykko Vitali, Mahzarin R. Banaji","Large Language Models (LLMs) show emergent patterns that mimic human
cognition. We explore whether they also mirror other, less deliberative human
psychological processes. Drawing upon classical theories of cognitive
consistency, two preregistered studies tested whether GPT-4o changed its
attitudes toward Vladimir Putin in the direction of a positive or negative
essay it wrote about the Russian leader. Indeed, GPT displayed patterns of
attitude change mimicking cognitive consistency effects in humans. Even more
remarkably, the degree of change increased sharply when the LLM was offered an
illusion of choice about which essay (positive or negative) to write. This
result suggests that GPT-4o manifests a functional analog of humanlike
selfhood, although how faithfully the chatbot's behavior reflects the
mechanisms of human attitude change remains to be understood.",http://arxiv.org/abs/2502.07088v1
Difference-in-Differences and Changes-in-Changes with Sample Selection,2025-02-12T18:03:11Z,Javier Viviens,"Sample selection arises endogenously in causal research when the treatment
affects whether certain units are observed. It is a common pitfall in
longitudinal studies, particularly in settings where treatment assignment is
confounded. In this paper, I highlight the drawbacks of one of the most popular
identification strategies in such settings: Difference-in-Differences (DiD).
Specifically, I employ principal stratification analysis to show that the
conventional ATT estimand may not be well defined, and the DiD estimand cannot
be interpreted causally without additional assumptions. To address these
issues, I develop an identification strategy to partially identify causal
effects on the subset of units with well-defined and observed outcomes under
both treatment regimes. I adapt Lee bounds to the Changes-in-Changes (CiC)
setting (Athey & Imbens, 2006), leveraging the time dimension of the data to
relax the unconfoundedness assumption in the original trimming strategy of Lee
(2009). This setting has the DiD identification strategy as a particular case,
which I also implement in the paper. Additionally, I explore how to leverage
multiple sources of sample selection to relax the monotonicity assumption in
Lee (2009), which may be of independent interest. Alongside the identification
strategy, I present estimators and inference results. I illustrate the
relevance of the proposed methodology by analyzing a job training program in
Colombia.",http://arxiv.org/abs/2502.08614v1
"Deployment-friendly Lane-changing Intention Prediction Powered by
  Brain-inspired Spiking Neural Networks",2025-02-09T06:33:47Z,"Shuqi Shen, Junjie Yang, Hui Zhong, Qiming Zhang, Hongliang Lu, Hai Yang","Accurate and real-time prediction of surrounding vehicles' lane-changing
intentions is a critical challenge in deploying safe and efficient autonomous
driving systems in open-world scenarios. Existing high-performing methods
remain hard to deploy due to their high computational cost, long training
times, and excessive memory requirements. Here, we propose an efficient
lane-changing intention prediction approach based on brain-inspired Spiking
Neural Networks (SNN). By leveraging the event-driven nature of SNN, the
proposed approach enables us to encode the vehicle's states in a more efficient
manner. Comparison experiments conducted on HighD and NGSIM datasets
demonstrate that our method significantly improves training efficiency and
reduces deployment costs while maintaining comparable prediction accuracy.
Particularly, compared to the baseline, our approach reduces training time by
75% and memory usage by 99.9%. These results validate the efficiency and
reliability of our method in lane-changing predictions, highlighting its
potential for safe and efficient autonomous driving systems while offering
significant advantages in deployment, including reduced training time, lower
memory usage, and faster inference.",http://arxiv.org/abs/2502.08659v2
Landscapes and nonequilibrium fluctuations of eukaryotic gene regulation,2025-02-14T10:43:17Z,"Masaki Sasai, Bhaswati Bhattacharyya, Shin Fujishiro, Yoshiaki Horiike","Understanding the interplay among processes that occur over different
timescales is a challenging issue in the physics of systems regulation. In gene
regulation, the timescales for changes in chromatin states can differ from
those for changes in the concentration of product protein, raising questions
about how to understand their coupled dynamics. In this study, we examine the
effects of these different timescales on eukaryotic gene regulation using a
stochastic model that describes the landscapes and probability currents of
nonequilibrium fluctuations. This model shows that slow, nonadiabatic
transitions of chromatin states significantly impact gene-regulation dynamics.
The simulated circular flow of the probability currents indicates a maximum
entropy production when the rates of chromatin-state transitions are low in the
intensely nonadiabatic regime. In the mildly nonadiabatic regime, this circular
flow fosters hysteresis, suggesting that changes in chromatin states precede
changes in transcription activity. Furthermore, calculations using a model of a
circuit involving three core genes in mouse embryonic stem cells illustrate how
multilayer regulation of chromatin, or deep epigenetic regulation, can flexibly
tune fluctuations in individual genes. These findings highlight the rich
effects of nonadiabatic chromatin-state transitions on gene regulation in
eukaryotic cells.",http://arxiv.org/abs/2502.10067v1
"On Lorentzian-Euclidean black holes and Lorentzian to Riemannian metric
  transitions",2025-02-19T21:22:42Z,"Rossella Bartolo, Erasmo Caponio, Anna Valeria Germinario, Miguel Sánchez","In recent papers on spacetimes with a signature-changing metric, the concept
of a Lorentzian-Euclidean black hole and new elements for Lorentzian-Riemannian
signature change have been introduced. A Lorentzian-Euclidean black hole is a
signature-changing modification of the Schwarzschild spacetime satisfying the
vacuum Einstein equations in a weak sense. Here the event horizon serves as a
boundary beyond which time becomes imaginary. We demonstrate that the proper
time needed to reach the horizon remains finite, consistently with the
classical Schwarzschild solution. About Lorentzian to Riemannian metric
transitions, we stress that the hypersurface where the metric signature changes
is naturally a spacelike hypersurface which might be identified with the future
or past causal boundary of the Lorentzian sector. Moreover, a number of
geometric interpretations appear, as the degeneracy of the metric corresponds
to the collapse of the causal cones into a line, the degeneracy of the dual
metric corresponds to collapsing into a hyperplane, and additional geometric
structures on the transition hypersurface (Galilean and dual Galilean) might be
explored.",http://arxiv.org/abs/2502.14108v1
Online detection of forecast model inadequacies using forecast errors,2025-02-20T00:56:51Z,"Thomas Grundy, Rebecca Killick, Ivan Svetunkov","In many organisations, accurate forecasts are essential for making informed
decisions for a variety of applications from inventory management to staffing
optimization. Whatever forecasting model is used, changes in the underlying
process can lead to inaccurate forecasts, which will be damaging to
decision-making. At the same time, models are becoming increasingly complex and
identifying change through direct modelling is problematic. We present a novel
framework for online monitoring of forecasts to ensure they remain accurate. By
utilizing sequential changepoint techniques on the forecast errors, our
framework allows for the real-time identification of potential changes in the
process caused by various external factors. We show theoretically that some
common changes in the underlying process will manifest in the forecast errors
and can be identified faster by identifying shifts in the forecast errors than
within the original modelling framework. Moreover, we demonstrate the
effectiveness of this framework on numerous forecasting approaches through
simulations and show its effectiveness over alternative approaches. Finally, we
present two concrete examples, one from Royal Mail parcel delivery volumes and
one from NHS A\&E admissions relating to gallstones.",http://arxiv.org/abs/2502.14173v1
Relightable Full-Body Gaussian Codec Avatars,2025-01-24T18:59:15Z,"Shaofei Wang, Tomas Simon, Igor Santesteban, Timur Bagautdinov, Junxuan Li, Vasu Agrawal, Fabian Prada, Shoou-I Yu, Pace Nalbone, Matt Gramlich, Roman Lubachersky, Chenglei Wu, Javier Romero, Jason Saragih, Michael Zollhoefer, Andreas Geiger, Siyu Tang, Shunsuke Saito","We propose Relightable Full-Body Gaussian Codec Avatars, a new approach for
modeling relightable full-body avatars with fine-grained details including face
and hands. The unique challenge for relighting full-body avatars lies in the
large deformations caused by body articulation and the resulting impact on
appearance caused by light transport. Changes in body pose can dramatically
change the orientation of body surfaces with respect to lights, resulting in
both local appearance changes due to changes in local light transport
functions, as well as non-local changes due to occlusion between body parts. To
address this, we decompose the light transport into local and non-local
effects. Local appearance changes are modeled using learnable zonal harmonics
for diffuse radiance transfer. Unlike spherical harmonics, zonal harmonics are
highly efficient to rotate under articulation. This allows us to learn diffuse
radiance transfer in a local coordinate frame, which disentangles the local
radiance transfer from the articulation of the body. To account for non-local
appearance changes, we introduce a shadow network that predicts shadows given
precomputed incoming irradiance on a base mesh. This facilitates the learning
of non-local shadowing between the body parts. Finally, we use a deferred
shading approach to model specular radiance transfer and better capture
reflections and highlights such as eye glints. We demonstrate that our approach
successfully models both the local and non-local light transport required for
relightable full-body avatars, with a superior generalization ability under
novel illumination conditions and unseen poses.",http://arxiv.org/abs/2501.14726v1
"IRONMAP: Iron Network Mapping and Analysis Protocol for Detecting
  Over-Time Brain Iron Abnormalities in Neurological Disease",2025-01-29T18:37:15Z,"Jack A. Reeves, Fahad Salman, Michael G. Dwyer, Niels Bergsland, Sarah Muldoon, Bianca Weinstock-Guttman, Robert Zivadinov, Ferdinand Schweser","Pathologically altered iron levels, detected using iron-sensitive MRI
techniques such as quantitative susceptibility mapping (QSM), are observed in
neurological disorders such as multiple sclerosis (MS) and may play a crucial
role in disease pathophysiology. However, brain iron changes occur slowly, even
in neurological diseases, and can be influenced by physiological factors such
as diet. Therefore, novel analysis methods are needed to improve sensitivity to
disease-related iron changes as compared to conventional region-based analysis
methods. This study introduces IRONMAP, Iron Network Mapping and Analysis
Protocol, which is a novel network-based analysis method to evaluate over-time
changes in magnetic susceptibility. With this novel methodology, we analyzed
short-term (<1 year) longitudinal QSM data from a cohort of individuals with MS
(pwMS) and healthy controls (HCs) and assessed disease-related network
patterns, comparing the new approach to a conventional per-region
rate-of-change method. IRONMAP analysis was able to detect over-time,
MS-related brain iron abnormalities that were undetectable using the
rate-of-change approach. IRONMAP was applicable on the per-subject level,
improving binary classification of pwMS vs HCs compared to rate-of-change data
alone (areas under the curve: 0.773 vs 0.636, p = 0.024). Further analysis
revealed that the observed IRONMAP-derived HC network structure closely aligned
with simulated networks based on healthy aging-related susceptibility data,
suggesting that disruptions in normal aging-related iron changes may contribute
to the network differences seen in pwMS. IRONMAP is generalizable to any
neurological disease, including Alzheimer's disease and Parkinson's disease,
and may allow for study of brain iron abnormalities over shorter timeframes
than previously possible.",http://arxiv.org/abs/2501.17838v1
"Change Captioning in Remote Sensing: Evolution to SAT-Cap -- A
  Single-Stage Transformer Approach",2025-01-14T13:46:03Z,"Yuduo Wang, Weikang Yu, Pedram Ghamisi","Change captioning has become essential for accurately describing changes in
multi-temporal remote sensing data, providing an intuitive way to monitor
Earth's dynamics through natural language. However, existing change captioning
methods face two key challenges: high computational demands due to multistage
fusion strategy, and insufficient detail in object descriptions due to limited
semantic extraction from individual images. To solve these challenges, we
propose SAT-Cap based on the transformers model with a single-stage feature
fusion for remote sensing change captioning. In particular, SAT-Cap integrates
a Spatial-Channel Attention Encoder, a Difference-Guided Fusion module, and a
Caption Decoder. Compared to typical models that require multi-stage fusion in
transformer encoder and fusion module, SAT-Cap uses only a simple cosine
similarity-based fusion module for information integration, reducing the
complexity of the model architecture. By jointly modeling spatial and channel
information in Spatial-Channel Attention Encoder, our approach significantly
enhances the model's ability to extract semantic information from objects in
multi-temporal remote sensing images. Extensive experiments validate the
effectiveness of SAT-Cap, achieving CIDEr scores of 140.23% on the LEVIR-CC
dataset and 97.74% on the DUBAI-CC dataset, surpassing current state-of-the-art
methods. The code and pre-trained models will be available online.",http://arxiv.org/abs/2501.08114v1
"Robust Change Captioning in Remote Sensing: SECOND-CC Dataset and
  MModalCC Framework",2025-01-17T09:47:27Z,"Ali Can Karaca, M. Enes Ozelbas, Saadettin Berber, Orkhan Karimli, Turabi Yildirim, M. Fatih Amasyali","Remote sensing change captioning (RSICC) aims to describe changes between
bitemporal images in natural language. Existing methods often fail under
challenges like illumination differences, viewpoint changes, blur effects,
leading to inaccuracies, especially in no-change regions. Moreover, the images
acquired at different spatial resolutions and have registration errors tend to
affect the captions. To address these issues, we introduce SECOND-CC, a novel
RSICC dataset featuring high-resolution RGB image pairs, semantic segmentation
maps, and diverse real-world scenarios. SECOND-CC which contains 6,041 pairs of
bitemporal RS images and 30,205 sentences describing the differences between
images. Additionally, we propose MModalCC, a multimodal framework that
integrates semantic and visual data using advanced attention mechanisms,
including Cross-Modal Cross Attention (CMCA) and Multimodal Gated Cross
Attention (MGCA). Detailed ablation studies and attention visualizations
further demonstrate its effectiveness and ability to address RSICC challenges.
Comprehensive experiments show that MModalCC outperforms state-of-the-art RSICC
methods, including RSICCformer, Chg2Cap, and PSNet with +4.6% improvement on
BLEU4 score and +9.6% improvement on CIDEr score. We will make our dataset and
codebase publicly available to facilitate future research at
https://github.com/ChangeCapsInRS/SecondCC",http://arxiv.org/abs/2501.10075v1
"Lifelong 3D Mapping Framework for Hand-held & Robot-mounted LiDAR
  Mapping Systems",2025-01-30T03:29:42Z,"Liudi Yang, Sai Manoj Prakhya, Senhua Zhu, Ziyuan Liu","We propose a lifelong 3D mapping framework that is modular, cloud-native by
design and more importantly, works for both hand-held and robot-mounted 3D
LiDAR mapping systems. Our proposed framework comprises of dynamic point
removal, multi-session map alignment, map change detection and map version
control. First, our sensor-setup agnostic dynamic point removal algorithm works
seamlessly with both hand-held and robot-mounted setups to produce clean static
3D maps. Second, the multi-session map alignment aligns these clean static maps
automatically, without manual parameter fine-tuning, into a single reference
frame, using a two stage approach based on feature descriptor matching and fine
registration. Third, our novel map change detection identifies positive and
negative changes between two aligned maps. Finally, the map version control
maintains a single base map that represents the current state of the
environment, and stores the detected positive and negative changes, and
boundary information. Our unique map version control system can reconstruct any
of the previous clean session maps and allows users to query changes between
any two random mapping sessions, all without storing any input raw session
maps, making it very unique. Extensive experiments are performed using
hand-held commercial LiDAR mapping devices and open-source robot-mounted LiDAR
SLAM algorithms to evaluate each module and the whole 3D lifelong mapping
framework.",http://arxiv.org/abs/2501.18110v1
A Scalable Crawling Algorithm Utilizing Noisy Change-Indicating Signals,2025-02-04T15:55:10Z,"Róbert Busa-Fekete, Julian Zimmert, András György, Linhai Qiu, Tzu-Wei Sung, Hao Shen, Hyomin Choi, Sharmila Subramaniam, Li Xiao","Web refresh crawling is the problem of keeping a cache of web pages fresh,
that is, having the most recent copy available when a page is requested, given
a limited bandwidth available to the crawler. Under the assumption that the
change and request events, resp., to each web page follow independent Poisson
processes, the optimal scheduling policy was derived by Azar et al. 2018. In
this paper, we study an extension of this problem where side information
indicating content changes, such as various types of web pings, for example,
signals from sitemaps, content delivery networks, etc., is available.
Incorporating such side information into the crawling policy is challenging,
because (i) the signals can be noisy with false positive events and with
missing change events; and (ii) the crawler should achieve a fair performance
over web pages regardless of the quality of the side information, which might
differ from web page to web page. We propose a scalable crawling algorithm
which (i) uses the noisy side information in an optimal way under mild
assumptions; (ii) can be deployed without heavy centralized computation; (iii)
is able to crawl web pages at a constant total rate without spikes in the total
bandwidth usage over any time interval, and automatically adapt to the new
optimal solution when the total bandwidth changes without centralized
computation. Experiments clearly demonstrate the versatility of our approach.",http://arxiv.org/abs/2502.02430v1
"S2C: Learning Noise-Resistant Differences for Unsupervised Change
  Detection in Multimodal Remote Sensing Images",2025-02-18T07:34:54Z,"Lei Ding, Xibing Zuo, Danfeng Hong, Haitao Guo, Jun Lu, Zhihui Gong, Lorenzo Bruzzone","Unsupervised Change Detection (UCD) in multimodal Remote Sensing (RS) images
remains a difficult challenge due to the inherent spatio-temporal complexity
within data, and the heterogeneity arising from different imaging sensors.
Inspired by recent advancements in Visual Foundation Models (VFMs) and
Contrastive Learning (CL) methodologies, this research aims to develop CL
methodologies to translate implicit knowledge in VFM into change
representations, thus eliminating the need for explicit supervision. To this
end, we introduce a Semantic-to-Change (S2C) learning framework for UCD in both
homogeneous and multimodal RS images. Differently from existing CL
methodologies that typically focus on learning multi-temporal similarities, we
introduce a novel triplet learning strategy that explicitly models temporal
differences, which are crucial to the CD task. Furthermore, random spatial and
spectral perturbations are introduced during the training to enhance robustness
to temporal noise. In addition, a grid sparsity regularization is defined to
suppress insignificant changes, and an IoU-matching algorithm is developed to
refine the CD results. Experiments on four benchmark CD datasets demonstrate
that the proposed S2C learning framework achieves significant improvements in
accuracy, surpassing current state-of-the-art by over 31\%, 9\%, 23\%, and
15\%, respectively. It also demonstrates robustness and sample efficiency,
suitable for training and adaptation of various Visual Foundation Models (VFMs)
or backbone neural networks. The relevant code will be available at:
github.com/DingLei14/S2C.",http://arxiv.org/abs/2502.12604v1
"Nano-topographical changes in latent fingerprint due to degradation over
  time studied by Atomic force microscopy -- option to set a timeline?",2025-02-20T15:40:10Z,"Tereza Svatonova, Anna Fucikova","Latent fingerprints, if present, are crucial in identifying the suspect who
was at the crime scene. If there are many latent fingerprints or the suspect is
from the same household, crime investigators may have difficulty identifying
whose latent fingerprints are time-related to the crime. Here, we report
changes in the nanoscale topography of latent fingerprints, which may serve as
a timeline and could help estimate when the latent fingerprint was imprinted.
On the latent fingerprint of an adolescent, we observed a change in
nano-topography over time, specifically the formation of nano-chain structures
in space between the imprinted papillary ridges. We consequently compared this
observation with the decomposition of the latent fingerprints of a child and
adult. We observed a significant difference in the time change in
nano-topography of latent fingerprints of a child, adolescent, and young adult.
The nano-topographical changes of latent fingerprints were studied by atomic
force microscopy over 70 days. In the case of child's and adolescent's latent
fingerprints, the first nano-chains were observed already 24 hours after
imprinting of the latent fingerprint, and the number of nano-chains increased
steadily up to 21 days, then we observed that another organic material covered
the nano-chains, and they started slowly deteriorating; nevertheless, the
nano-chains were still present on the 70th day.",http://arxiv.org/abs/2502.14650v1
LDMapNet-U: An End-to-End System for City-Scale Lane-Level Map Updating,2025-01-06T05:14:40Z,"Deguo Xia, Weiming Zhang, Xiyan Liu, Wei Zhang, Chenting Gong, Xiao Tan, Jizhou Huang, Mengmeng Yang, Diange Yang","An up-to-date city-scale lane-level map is an indispensable infrastructure
and a key enabling technology for ensuring the safety and user experience of
autonomous driving systems. In industrial scenarios, reliance on manual
annotation for map updates creates a critical bottleneck. Lane-level updates
require precise change information and must ensure consistency with adjacent
data while adhering to strict standards. Traditional methods utilize a
three-stage approach-construction, change detection, and updating-which often
necessitates manual verification due to accuracy limitations. This results in
labor-intensive processes and hampers timely updates. To address these
challenges, we propose LDMapNet-U, which implements a new end-to-end paradigm
for city-scale lane-level map updating. By reconceptualizing the update task as
an end-to-end map generation process grounded in historical map data, we
introduce a paradigm shift in map updating that simultaneously generates
vectorized maps and change information. To achieve this, a Prior-Map Encoding
(PME) module is introduced to effectively encode historical maps, serving as a
critical reference for detecting changes. Additionally, we incorporate a novel
Instance Change Prediction (ICP) module that learns to predict associations
with historical maps. Consequently, LDMapNet-U simultaneously achieves
vectorized map element generation and change detection. To demonstrate the
superiority and effectiveness of LDMapNet-U, extensive experiments are
conducted using large-scale real-world datasets. In addition, LDMapNet-U has
been successfully deployed in production at Baidu Maps since April 2024,
supporting map updating for over 360 cities and significantly shortening the
update cycle from quarterly to weekly. The updated maps serve hundreds of
millions of users and are integrated into the autonomous driving systems of
several leading vehicle companies.",http://arxiv.org/abs/2501.02763v2
"Metallisation of the Mott Insulator Ca$_{2}$RuO$_{4}$ using Electric
  Double-Layer Gating",2025-01-07T07:39:14Z,"Tatsuhiro Sakami, Hiroki Ogura, Akihiro Ino, Takumi Ouchi, Tsutomu Nojima, Fumihiko Nakamura","To verify whether the Mott insulator Ca2RuO4 can be switched by applying
electric-field alone, regardless of current flow, we employ metallisation using
electric double-layer gating (EDLG). The resistance change due to EDLG occurs
only when positive gate-voltage above +3 V is applied. The amplitude of the
reduction, reaching ~97% of the initial value, is difficult to interpret as
surface metallisation and is likely related to structural change in bulk.",http://arxiv.org/abs/2501.03591v1
Unveiling the inner structure of the pion first excited state,2025-01-07T08:02:48Z,"Xiaobin Wang, Lei Chang","By capturing the characteristics of the Bethe-Salpeter amplitude for the pion
excitation state, we construct an algebraic model to provide the overall
features of the pion first excitation state parton distribution amplitude and
distribution function. We find that, at the hadronic scale, the distribution
amplitude of the excited state exhibits nodes, while the distribution function
is unimodal, with a peak at $x=1/2$ and distinct concave and convex
fluctuations in the valence region. These findings provide new insights into
the partonic structure of excited mesons and contribute significantly to our
understanding of hadronic excitations.",http://arxiv.org/abs/2501.03602v2
Bosonic Amplitude-Damping Codes Beyond Binomial Schemes,2025-01-13T07:04:05Z,En-Jui Chang,"We introduce two new families of bosonic quantum error correction (QEC) codes
to address collective coherent and amplitude-damping errors, building upon our
previous multi-qubit QEC codes. These new bosonic codes enhance existing
binomial codes for oscillators and permutation-invariant codes for qubits by
reducing the required excitations per input qubit from linear to sub-linear
growth. The mappings from multi-qubit stabilizer codes to bosonic codes
establish a bridge between QEC code construction for qubits and oscillators,
offering a unified approach to error correction across different quantum
systems.",http://arxiv.org/abs/2501.07093v1
On Erlang Queue with Multiple Arrivals and its Time-changed Variant,2025-01-15T13:24:37Z,"R. B. Pote, K. K. Kataria","We introduce and study a queue with the Erlang service system and whose
arrivals are governed by a counting process in which there is a possibility of
finitely many arrivals in an infinitesimal time interval. We call it the Erlang
queue with multiple arrivals. Some of its distributional properties are
obtained that includes the state-phase probabilities, the mean queue length and
the distribution of busy period etc. Also, we study a time-changed variant of
it by subordinating it with an independent inverse stable subordinator where we
obtain its state probabilities and the mean queue length.",http://arxiv.org/abs/2501.08789v1
On Elephant Random Walk with Random Memory,2025-01-22T13:20:10Z,"M. Dhillon, K. K. Kataria","In this paper, we introduce the elephant random walk (ERW) with memory
consisting of randomly selected steps from its history. It is a time-changed
variant of the standard elephant random walk with memory consisting of its full
history. At each time point, the time changing component is the composition of
two uniformly distributed independent random variables with support over all
the past steps. Several conditional distributional properties including the
conditional mean increments and conditional displacement of ERW with random
memory are obtained. Using these conditional results, we derive the recursive
and explicit expressions for the mean increments and mean displacement of the
walk.",http://arxiv.org/abs/2501.12866v1
"Sign-changing prescribed mass solutions for $L^2$-supercritical NLS on
  compact metric graphs",2025-01-24T17:03:54Z,"Louis Jeanjean, Linjie Song","This paper is devoted to the existence of multiple sign-changing solutions of
prescribed mass for a mass-supercritical nonlinear Schr\""odinger equation set
on a compact metric graph. In particular, we obtain, in the supercritical mass
regime, the first multiplicity result for prescribed mass solutions on compact
metric graphs. Our approach relies on the introduction a new kind of link and
on the use of gradient flow techniques on a constraint. It can be transposed to
other problems posed on a bounded domain.",http://arxiv.org/abs/2501.14642v1
"Assessment various control methods a digital copy of enterprise by
  integral indicator",2025-01-29T01:03:51Z,Sergey Masaev,"The difficulty of assessing the state lies in a little predictable change in
the dimension of a dynamic system under the influence of internal changes and
environmental parameters. In the work, the state of such a system is estimated
by the method of integral indicators. The application of the method of integral
indicators allowed us to evaluate the activity of an enterprise. In the present
work, the method of integrated indicators is used to assess the control of a
digital copy (enterprise).",http://arxiv.org/abs/2501.17363v1
eagle: early approximated gradient based learning rate estimator,2025-02-03T04:15:34Z,"Takumi Fujimoto, Hiroaki Nishi","We propose EAGLE update rule, a novel optimization method that accelerates
loss convergence during the early stages of training by leveraging both current
and previous step parameter and gradient values. The update algorithm estimates
optimal parameters by computing the changes in parameters and gradients between
consecutive training steps and leveraging the local curvature of the loss
landscape derived from these changes. However, this update rule has potential
instability, and to address that, we introduce an adaptive switching mechanism
that dynamically selects between Adam and EAGLE update rules to enhance
training stability. Experiments on standard benchmark datasets demonstrate that
EAGLE optimizer, which combines this novel update rule with the switching
mechanism achieves rapid training loss convergence with fewer epochs, compared
to conventional optimization methods.",http://arxiv.org/abs/2502.01036v1
Geometric Gauss Sums and Gross-Koblitz Formulas over Function Fields,2025-02-03T06:59:45Z,Ting-Wei Chang,"In this paper, we prove the Gross-Koblitz-Thakur formulas relating special
$v$-adic gamma values to the newly introduced geometric Gauss sums in the
function field setting. These are analogous to those for the $p$-adic gamma
function in the classical setting due to Gross-Koblitz and the $v$-adic
arithmetic gamma function over function fields due to Thakur. For these new
Gauss sums, we establish their key arithmetic properties, including the
uniformity of absolute values and prime factorizations. We also determine their
signs at infinite places, and derive two analogs of the Hasse-Davenport
relations.",http://arxiv.org/abs/2502.01109v1
Ordinal Patterns Based Change Points Detection,2025-02-05T11:48:36Z,"Annika Betken, Giorgio Micali, Johannes Schmidt-Hieber","The ordinal patterns of a fixed number of consecutive values in a time series
is the spatial ordering of these values. Counting how often a specific ordinal
pattern occurs in a time series provides important insights into the properties
of the time series. In this work, we prove the asymptotic normality of the
relative frequency of ordinal patterns for time series with linear increments.
Moreover, we apply ordinal patterns to detect changes in the distribution of a
time series.",http://arxiv.org/abs/2502.03099v1
"Rising Marginal Costs, Rising Prices?",2025-02-09T13:28:47Z,"Joel Kariel, Anthony Savagar","We present empirical evidence on the relationship between demand shocks and
price changes, conditional on returns to scale. We find that in industries with
decreasing returns to scale, demand increases (which raise costs) correspond to
price increases. Whereas, in industries with increasing returns to scale,
demand increases (which lower costs) correspond to stable prices. We interpret
the results with a theory of imperfect competition and returns to scale. For
prices to remain stable following a cost decrease, markups necessarily rise.
For prices to increase as cost increases, it is not necessary for markups to
change but does not preclude their role. From a macroeconomic perspective, our
results imply that inflation dynamics and the effectiveness of monetary policy
depend on market structures.",http://arxiv.org/abs/2502.05898v1
"Conditioning and AGM-like belief change in the Desirability-Indifference
  framework",2025-02-10T08:11:00Z,"Kathelijne Coussement, Gert de Cooman, Keano De Vos","We show how the AGM framework for belief change (expansion, revision,
contraction) can be extended to deal with conditioning in the so-called
Desirability-Indifference framework, based on abstract notions of accepting and
rejecting options, as well as on abstract notions of events. This level of
abstraction allows us to deal simultaneously with classical and quantum
probability theory.",http://arxiv.org/abs/2502.06235v1
Consistency Training with Physical Constraints,2025-02-11T15:23:14Z,"Che-Chia Chang, Chen-Yang Dai, Te-Sheng Lin, Ming-Chih Lai, Chieh-Hsin Lai","We propose a physics-aware Consistency Training (CT) method that accelerates
sampling in Diffusion Models with physical constraints. Our approach leverages
a two-stage strategy: (1) learning the noise-to-data mapping via CT, and (2)
incorporating physics constraints as a regularizer. Experiments on toy examples
show that our method generates samples in a single step while adhering to the
imposed constraints. This approach has the potential to efficiently solve
partial differential equations (PDEs) using deep generative modeling.",http://arxiv.org/abs/2502.07636v1
"SPARNet: Continual Test-Time Adaptation via Sample Partitioning Strategy
  and Anti-Forgetting Regularization",2025-01-01T12:19:17Z,"Xinru Meng, Han Sun, Jiamei Liu, Ningzhong Liu, Huiyu Zhou","Test-time Adaptation (TTA) aims to improve model performance when the model
encounters domain changes after deployment. The standard TTA mainly considers
the case where the target domain is static, while the continual TTA needs to
undergo a sequence of domain changes. This encounters a significant challenge
as the model needs to adapt for the long-term and is unaware of when the domain
changes occur. The quality of pseudo-labels is hard to guarantee. Noisy
pseudo-labels produced by simple self-training methods can cause error
accumulation and catastrophic forgetting. In this work, we propose a new
framework named SPARNet which consists of two parts, sample partitioning
strategy and anti-forgetting regularization. The sample partition strategy
divides samples into two groups, namely reliable samples and unreliable
samples. According to the characteristics of each group of samples, we choose
different strategies to deal with different groups of samples. This ensures
that reliable samples contribute more to the model. At the same time, the
negative impacts of unreliable samples are eliminated by the mean teacher's
consistency learning. Finally, we introduce a regularization term to alleviate
the catastrophic forgetting problem, which can limit important parameters from
excessive changes. This term enables long-term adaptation of parameters in the
network. The effectiveness of our method is demonstrated in continual TTA
scenario by conducting a large number of experiments on CIFAR10-C, CIFAR100-C
and ImageNet-C.",http://arxiv.org/abs/2501.00818v1
Host-guided data placement: whose job is it anyway?,2025-01-01T23:08:54Z,"Devashish R. Purandare, Peter Alvaro, Avani Wildani, Darrell D. E. Long, Ethan L. Miller","The increasing demand for SSDs coupled with scaling difficulties have left
manufacturers scrambling for newer SSD interfaces which promise better
performance and durability. While these interfaces reduce the rigidity of
traditional abstractions, they require application or system-level changes that
can impact the stability, security, and portability of systems. To make matters
worse, such changes are rendered futile with introduction of next-generation
interfaces. Further, there is little guidance on data placement and hardware
specifics are often abstracted from the application layer. It is no surprise
therefore that such interfaces have seen limited adoption, leaving behind a
graveyard of experimental interfaces ranging from open-channel SSDs to zoned
namespaces.
  In this paper, we show how shim layers can to shield systems from changing
hardware interfaces while benefiting from them. We present Reshim, an
all-userspace shim layer that performs affinity and lifetime based data
placement with no change to the operating system or the application. We
demonstrate Reshim's ease of adoption with host-device coordination for three
widely-used data-intensive systems: RocksDB, MongoDB, and CacheLib. With
Reshim, these systems see 2-6 times highe write throughput, up to 6 times lower
latency, and reduced write amplification compared to filesystems like F2FS.
Reshim performs on par with application-specific backends like ZenFS while
offering more generality, lower latency, and richer data placement. With Reshim
we demonstrate the value of isolating the complexity of the placement logic,
allowing easy deployment of dynamic placement rules across several applications
and storage interfaces.",http://arxiv.org/abs/2501.00977v1
"Online Fault Tolerance Strategy for Abrupt Reachability Constraint
  Changes",2025-01-03T14:32:17Z,"Henghua Shen, Qixin Wang","When a system's constraints change abruptly, the system's reachability safety
does no longer sustain. Thus, the system can reach a forbidden/dangerous value.
Conventional remedy practically involves online controller redesign (OCR) to
re-establish the reachability's compliance with the new constraints, which,
however, is usually too slow. There is a need for an online strategy capable of
managing runtime changes in reachability constraints. However, to the best of
the authors' knowledge, this topic has not been addressed in the existing
literature. In this paper, we propose a fast fault tolerance strategy to
recover the system's reachability safety in runtime. Instead of redesigning the
system's controller, we propose to change the system's reference state to
modify the system's reachability to comply with the new constraints. We frame
the reference state search as an optimization problem and employ the
Karush-Kuhn-Tucker (KKT) method as well as the Interior Point Method (IPM)
based Newton's method (as a fallback for the KKT method) for fast solution
derivation. The optimization also allows more future fault tolerance. Numerical
simulations demonstrate that our method outperforms the conventional OCR method
in terms of computational efficiency and success rate. Specifically, the
results show that the proposed method finds a solution $10^{2}$ (with the IPM
based Newton's method) $\sim 10^{4}$ (with the KKT method) times faster than
the OCR method. Additionally, the improvement rate of the success rate of our
method over the OCR method is $40.81\%$ without considering the deadline of run
time. The success rate remains at $49.44\%$ for the proposed method, while it
becomes $0\%$ for the OCR method when a deadline of $1.5 \; seconds$ is
imposed.",http://arxiv.org/abs/2501.01831v2
"The diophantine equation
  $\left(2^{k}-1\right)\left(3^{k}-1\right)=x^{n}$",2025-01-06T16:54:51Z,"Bo He, Chang Liu","In this paper, we investigate the Diophantine equation \[ (2^k - 1)(3^k - 1)
= x^n \] and prove that it has no solutions in positive integers $k, x, n > 2$.",http://arxiv.org/abs/2501.04050v1
Multiple testing in multi-stream sequential change detection,2025-01-07T20:25:52Z,"Sanjit Dandapanthula, Aaditya Ramdas","Multi-stream sequential change detection involves simultaneously monitoring
many streams of data and trying to detect when their distributions change, if
at all. Here, we theoretically study multiple testing issues that arise from
detecting changes in many streams. We point out that any algorithm with finite
average run length (ARL) must have a trivial worst-case false detection rate
(FDR), family-wise error rate (FWER), per-family error rate (PFER), and global
error rate (GER); thus, any attempt to control these Type I error metrics is
fundamentally in conflict with the desire for a finite ARL (which is typically
necessary in order to have a small detection delay). One of our contributions
is to define a new class of metrics which can be controlled, called error over
patience (EOP). We propose algorithms that combine the recent e-detector
framework (which generalizes the Shiryaev-Roberts and CUSUM methods) with the
recent e-Benjamini-Hochberg procedure and e-Bonferroni procedures. We prove
that these algorithms control the EOP at any desired level under very general
dependence structures on the data within and across the streams. In fact, we
prove a more general error control that holds uniformly over all stopping times
and provides a smooth trade-off between the conflicting metrics. Additionally,
if finiteness of the ARL is forfeited, we show that our algorithms control the
worst-case Type I error.",http://arxiv.org/abs/2501.04130v4
"4D fabrication of shape-changing systems for tissue engineering: state
  of the art and perspectives",2025-01-13T08:07:39Z,"Lorenzo Bonetti, Giulia Scalet","In recent years, four-dimensional (4D) fabrication has emerged as a powerful
technology capable of revolutionizing the field of tissue engineering. This
technology represents a shift in perspective from traditional tissue
engineering approaches, which generally rely on static-or passive-structures
(e.g., scaffolds, constructs) unable of adapting to changes in biological
environments. In contrast, 4D fabrication offers the unprecedented possibility
of fabricating complex designs with spatiotemporal control over structure and
function in response to environment stimuli, thus mimicking biological
processes. In this review, an overview of the state of the art of 4D
fabrication technology for the obtainment of cellularized constructs is
presented, with a focus on shape-changing soft materials. First, the approaches
to obtain cellularized constructs are introduced, also describing conventional
and non-conventional fabrication techniques with their relative advantages and
limitations. Next, the main families of shape-changing soft materials, namely
shape-memory polymers and shape-memory hydrogels are discussed and their use in
4D fabrication in the field of tissue engineering is described. Ultimately,
current challenges and proposed solutions are outlined, and valuable insights
into future research directions of 4D fabrication for tissue engineering are
provided to disclose its full potential.",http://arxiv.org/abs/2501.07612v1
SymSETs and self-dualities under gauging non-invertible symmetries,2025-01-14T02:05:45Z,"Da-Chuan Lu, Zhengdi Sun, Zipei Zhang","The self-duality defects under discrete gauging in a categorical symmetry
$\mathcal{C}$ can be classified by inequivalent ways of enriching the bulk
SymTFT of $\mathcal{C}$ with $\mathbb{Z}_2$ 0-form symmetry. The resulting
Symmetry Enriched Topological (SET) orders will be referred to as
$\textit{SymSETs}$ and are parameterized by choices of $\mathbb{Z}_2$
symmetries, as well as symmetry fractionalization classes and discrete
torsions. In this work, we consider self-dualities under gauging
$\textit{non-invertible}$ $0$-form symmetries in $2$-dim QFTs and explore their
SymSETs. Unlike the simpler case of self-dualities under gauging finite Abelian
groups, the SymSETs here generally admit multiple choices of fractionalization
classes. We provide a direct construction of the SymSET from a given duality
defect using its $\textit{relative center}$. Using the SymSET, we show
explicitly that changing fractionalization classes can change fusion rules of
the duality defect besides its $F$-symbols. We consider three concrete
examples: the maximal gauging of $\operatorname{Rep} H_8$, the non-maximal
gauging of the duality defect $\mathcal{N}$ in $\operatorname{Rep} H_8$ and
$\operatorname{Rep} D_8$ respectively. The latter two cases each result in 6
fusion categories with two types of fusion rules related by changing
fractionalization class. In particular, two self-dualities of
$\operatorname{Rep} D_8$ related by changing the fractionalization class lead
to $\operatorname{Rep} D_{16}$ and $\operatorname{Rep} SD_{16}$ respectively.
Finally, we study the physical implications such as the spin selection rules
and the SPT phases for the aforementioned categories.",http://arxiv.org/abs/2501.07787v1
PIXELS: Progressive Image Xemplar-based Editing with Latent Surgery,2025-01-16T20:26:30Z,"Shristi Das Biswas, Matthew Shreve, Xuelu Li, Prateek Singhal, Kaushik Roy","Recent advancements in language-guided diffusion models for image editing are
often bottle-necked by cumbersome prompt engineering to precisely articulate
desired changes. An intuitive alternative calls on guidance from in-the-wild
image exemplars to help users bring their imagined edits to life. Contemporary
exemplar-based editing methods shy away from leveraging the rich latent space
learnt by pre-existing large text-to-image (TTI) models and fall back on
training with curated objective functions to achieve the task. Though somewhat
effective, this demands significant computational resources and lacks
compatibility with diverse base models and arbitrary exemplar count. On further
investigation, we also find that these techniques restrict user control to only
applying uniform global changes over the entire edited region. In this paper,
we introduce a novel framework for progressive exemplar-driven editing with
off-the-shelf diffusion models, dubbed PIXELS, to enable customization by
providing granular control over edits, allowing adjustments at the pixel or
region level. Our method operates solely during inference to facilitate
imitative editing, enabling users to draw inspiration from a dynamic number of
reference images, or multimodal prompts, and progressively incorporate all the
desired changes without retraining or fine-tuning existing TTI models. This
capability of fine-grained control opens up a range of new possibilities,
including selective modification of individual objects and specifying gradual
spatial changes. We demonstrate that PIXELS delivers high-quality edits
efficiently, leading to a notable improvement in quantitative metrics as well
as human evaluation. By making high-quality image editing more accessible,
PIXELS has the potential to enable professional-grade edits to a wider audience
with the ease of using any open-source image generation model.",http://arxiv.org/abs/2501.09826v1
The Grothendieck groups of repetitive cluster categories of type $D_n$,2025-01-19T11:50:13Z,"Huimin Chang, Panyue Zhou","In this paper, we compute the Grothendieck groups of repetitive cluster
categories of type $D_n$, which are defined as the orbit categories $\mathcal
C_{n,~p}=D^b({\rm mod}KD_n)/\langle(\tau^{-1}[1])^p\rangle$ for $1\leq
p\in\mathbb{N}$.",http://arxiv.org/abs/2501.11021v1
"A New Approach to Radiocarbon Summarisation: Rigorous Identification of
  Variations/Changepoints in the Occurrence Rate of Radiocarbon Samples using a
  Poisson Process",2025-01-27T12:07:15Z,"Timothy J Heaton, Sara Al-assam, Edouard Bard","A commonly-used paradigm to estimate changes in the frequency of past events
or the size of populations is to consider the occurrence rate of
archaeological/environmental samples found at a site over time. The reliability
of such a ""dates-as-data"" approach is highly dependent upon how the occurrence
rates are estimated from the underlying samples, particularly when calendar age
information for the samples is obtained from radiocarbon (14C). The most
frequently-used ""14C-dates-as-data"" approach of creating Summed Probability
Distributions (SPDs) is not statistically valid or coherent and can provide
highly misleading inference. Here, we provide an alternative method with a
rigorous statistical underpinning that also provides valuable additional
information on potential changepoints in the rate of events. Our approach
ensures more reliable ""14C-dates-as-data"" analyses, allowing us to better
assess and identify potential signals present. We model the occurrence of
events, each assumed to leave a radiocarbon sample in the
archaeological/environmental record, as an inhomogeneous Poisson process. The
varying rate of samples over time is then estimated within a fully-Bayesian
framework using reversible-jump Markov Chain Monte Carlo (RJ-MCMC). Given a set
of radiocarbon samples, we reconstruct how their occurrence rate varies over
calendar time and identify if that rate contains statistically-significant
changes, i.e., specific times at which the rate of events abruptly changes. We
illustrate our method with both a simulation study and a practical example
concerning late-Pleistocene megafaunal population changes in Alaska and Yukon.",http://arxiv.org/abs/2501.15980v1
"Interfacial Temperature and Density Discontinuities for Phase-Change
  Heat Transfer With Non-condensable Gas",2025-01-28T16:34:52Z,Gang Chen,"In recent prior work, the author derived interfacial mass and heat flux
conditions for phase-change processes. The mass flux condition is identical to
the Schrage equation, but the additional heat flux expression enables one to
couple the interface to the continua in both the liquid and the vapor phases
and compute the interfacial temperature and density discontinuities. However,
questions exist on how to treat phase change heat transfer in the presence of
non-condensable gases. In this work, the author shows that the same set of
interfacial conditions can be used to account for the presence of
non-condensable gases. Although the mass flux of non-condensable gas is zero,
their presence impacts the heat transfer. For evaporation, when the presence of
the non-condensable gas is small, temperature and density discontinuities
persist across the interface, as well as inverted temperature distributions.
For condensation, however, no temperature inversion happens in the presence of
a small amount of non-condensable gas and the interfacial temperature jump is
significantly smaller. When a large amount of non-condensable gas is present,
such as for evaporation into and condensation from air, the temperature
discontinuities at the interface are significantly smaller and no temperature
inversion happens. For evaporation driven purely by humidity difference,
temperature inversion and discontinuity still exist. Results from this work
will benefit the modeling of phase change processes in the presence of
non-condensable gases, evaporative cooling in air, air-gap distillation,
atmospheric water harvesting, and other applications.",http://arxiv.org/abs/2501.17058v1
"Simulation of the crystallization kinetics of Ge$_2$Sb$_2$Te$_5$
  nanoconfined in superlattice geometries for phase change memories",2025-01-30T14:24:17Z,"Debdipto Acharya, Omar Abou El Kheir, Simone Marcorini, Marco Bernasconi","Phase change materials are the most promising candidates for the realization
of artificial synapsis for neuromorphic computing. Different resistance levels
corresponding to analogic values of the synapsis conductance can be achieved by
modulating the size of an amorphous region embedded in its crystalline matrix.
Recently, it has been proposed that a superlattice made of alternating layers
of the phase change compound Sb$_2$Te$_3$ and of the TiTe$_2$ confining
material allows for a better control of multiple intermediate resistance states
and for a lower drift with time of the electrical resistance of the amorphous
phase. In this work, we consider to substitute Sb$_2$Te$_3$ with the
Ge$_2$Sb$_2$Te$_5$ prototypical phase change compound that should feature
better data retention. By exploiting molecular dynamics simulations with a
machine learning interatomic potential, we have investigated the
crystallization kinetics of Ge$_2$Sb$_2$Te$_5$ nanoconfined in geometries
mimicking Ge$_2$Sb$_2$Te$_5$/TiTe$_2$ superlattices. It turns out that
nanoconfinement induces a slight reduction in the crystal growth velocities
with respect to the bulk, but also an enhancement of the nucleation rate due to
heterogeneous nucleation. The results support the idea of investigating
Ge$_2$Sb$_2$Te$_5$/TiTe$_2$ superlattices for applications in neuromorphic
devices with improved data retention. The effect on the crystallization
kinetics of the addition of van der Waals interaction to the interatomic
potential is also discussed.",http://arxiv.org/abs/2501.18370v1
"The Effect of Covid-19 Lockdown on Human Behaviour Using Analytical
  Hierarchy Process",2025-01-18T13:47:03Z,"Rashi Jain, Mansi Yadav","The coronavirus pandemic corresponds to a serious global health crisis which
not only changed the way people used to live but also how people behaved in
their daily lives. Information from social and behavioural sciences can help in
modifying human behaviour to comply with the recommendations of health
officials, as the pandemic requires large-scale behaviour change and puts
significant mental stress on individuals. The aim of this paper is to examine
the changes in human behaviour brought about by the COVID-19 pandemic, which
has caused a global health crisis and altered the way people live and interact.
The collection of data has been done through online mode and the behaviour of
the people is observed, and the results were finally analysed using the
Analytical Hierarchy Process (AHP) which is a multi-criteria decision-making
method to rank the factors that had the greatest impact on the changes in human
behaviour. During the study, parameters taken under consideration were the ones
which were most likely to affect the human behaviour as an impact of COVID-19
lockdown on health, relationship with family and friends, overall lifestyle,
online education and work from home, screen time etc. The paper explains each
criterion and how it affected human behaviour the most.",http://arxiv.org/abs/2501.18603v1
Controllable Video Generation with Provable Disentanglement,2025-02-04T20:10:20Z,"Yifan Shen, Peiyuan Zhu, Zijian Li, Shaoan Xie, Zeyu Tang, Namrata Deka, Zongfang Liu, Guangyi Chen, Kun Zhang","Controllable video generation remains a significant challenge, despite recent
advances in generating high-quality and consistent videos. Most existing
methods for controlling video generation treat the video as a whole, neglecting
intricate fine-grained spatiotemporal relationships, which limits both control
precision and efficiency. In this paper, we propose Controllable Video
Generative Adversarial Networks (CoVoGAN) to disentangle the video concepts,
thus facilitating efficient and independent control over individual concepts.
Specifically, following the minimal change principle, we first disentangle
static and dynamic latent variables. We then leverage the sufficient change
property to achieve component-wise identifiability of dynamic latent variables,
enabling independent control over motion and identity. To establish the
theoretical foundation, we provide a rigorous analysis demonstrating the
identifiability of our approach. Building on these theoretical insights, we
design a Temporal Transition Module to disentangle latent dynamics. To enforce
the minimal change principle and sufficient change property, we minimize the
dimensionality of latent dynamic variables and impose temporal conditional
independence. To validate our approach, we integrate this module as a plug-in
for GANs. Extensive qualitative and quantitative experiments on various video
generation benchmarks demonstrate that our method significantly improves
generation quality and controllability across diverse real-world scenarios.",http://arxiv.org/abs/2502.02690v1
"A Survey of Sample-Efficient Deep Learning for Change Detection in
  Remote Sensing: Tasks, Strategies, and Challenges",2025-02-05T02:36:09Z,"Lei Ding, Danfeng Hong, Maofan Zhao, Hongruixuan Chen, Chenyu Li, Jie Deng, Naoto Yokoya, Lorenzo Bruzzone, Jocelyn Chanussot","In the last decade, the rapid development of deep learning (DL) has made it
possible to perform automatic, accurate, and robust Change Detection (CD) on
large volumes of Remote Sensing Images (RSIs). However, despite advances in CD
methods, their practical application in real-world contexts remains limited due
to the diverse input data and the applicational context. For example, the
collected RSIs can be time-series observations, and more informative results
are required to indicate the time of change or the specific change category.
Moreover, training a Deep Neural Network (DNN) requires a massive amount of
training samples, whereas in many cases these samples are difficult to collect.
To address these challenges, various specific CD methods have been developed
considering different application scenarios and training resources.
Additionally, recent advancements in image generation, self-supervision, and
visual foundation models (VFMs) have opened up new approaches to address the
'data-hungry' issue of DL-based CD. The development of these methods in broader
application scenarios requires further investigation and discussion. Therefore,
this article summarizes the literature methods for different CD tasks and the
available strategies and techniques to train and deploy DL-based CD methods in
sample-limited scenarios. We expect that this survey can provide new insights
and inspiration for researchers in this field to develop more effective CD
methods that can be applied in a wider range of contexts.",http://arxiv.org/abs/2502.02835v1
Boundedness of toric foliations,2025-02-16T11:29:19Z,"Chih-Wei Chang, Yen-An Chen","We discuss boundedness of toric Fano foliations and connectedness of its
dicritical and singular loci. Moreover, we show the set of interpolated
$\delta$-lcts for the toric foliations satisfies the descending chain
condition.",http://arxiv.org/abs/2502.11080v1
"Searching for Low-Mass Exoplanets Amid Stellar Variability with a Fixed
  Effects Linear Model of Line-by-Line Shape Changes",2025-02-17T15:41:40Z,"Joseph Salzer, Jessi Cisewski-Kehe, Eric B. Ford, Lily L. Zhao","The radial velocity (RV) method, also known as Doppler spectroscopy, is a
powerful technique for exoplanet discovery and characterization. In recent
years, progress has been made thanks to the improvements in the quality of
spectra from new extreme precision RV spectrometers. However, detecting the RV
signals of Earth-like exoplanets remains challenging, as the spectroscopic
signatures of low-mass planets can be obscured or confused with intrinsic
stellar variability. Changes in the shapes of spectral lines across time can
provide valuable information for disentangling stellar activity from true
Doppler shifts caused by low-mass exoplanets. In this work, we present a fixed
effects linear model to estimate RV signals that controls for changes in line
shapes by aggregating information from hundreds of spectral lines. Our
methodology incorporates a wild-bootstrap approach for modeling uncertainty and
cross-validation to control for overfitting. We evaluate the model's ability to
remove stellar activity using solar observations from the NEID spectrograph, as
the sun's true center-of-mass motion is precisely known. Including line
shape-change covariates reduces the RV root-mean-square errors by approximately
70% (from 1.919 m s$^{-1}$ to 0.575 m s$^{-1}$) relative to using only the
line-by-line Doppler shifts. The magnitude of the residuals is significantly
less than that from traditional CCF-based RV estimators and comparable to other
state-of-the-art methods for mitigating stellar variability.",http://arxiv.org/abs/2502.11930v1
"Stress Testing Generalization: How Minor Modifications Undermine Large
  Language Model Performance",2025-02-18T02:42:53Z,"Guangxiang Zhao, Saier Hu, Xiaoqi Jian, Jinzhu Wu, Yuhan Wu, Change Jia, Lin Sun, Xiangzheng Zhang","This paper investigates the fragility of Large Language Models (LLMs) in
generalizing to novel inputs, specifically focusing on minor perturbations in
well-established benchmarks (e.g., slight changes in question format or
distractor length). Despite high benchmark scores, LLMs exhibit significant
accuracy drops and unexpected biases (e.g., preference for longer distractors)
when faced with these minor but content-preserving modifications. For example,
Qwen 2.5 1.5B's MMLU score rises from 60 to 89 and drops from 89 to 36 when
option lengths are changed without altering the question. Even GPT-4
experiences a 25-point accuracy loss when question types are changed, with a
6-point drop across all three modification categories. These analyses suggest
that LLMs rely heavily on superficial cues rather than forming robust, abstract
representations that generalize across formats, lexical variations, and
irrelevant content shifts. This work aligns with the ACL 2025 theme track on
the Generalization of NLP models, proposing a ""Generalization Stress Test"" to
assess performance shifts under controlled perturbations. The study calls for
reevaluating benchmarks and developing more reliable evaluation methodologies
to capture LLM generalization abilities better.",http://arxiv.org/abs/2502.12459v1
"Reinforcement Learning for Adaptive Time-Stepping in the Chaotic
  Gravitational Three-Body Problem",2025-02-18T12:12:49Z,"Veronica Saz Ulibarrena, Simon Portegies Zwart","Many problems in astrophysics cover multiple orders of magnitude in spatial
and temporal scales. While simulating systems that experience rapid changes in
these conditions, it is essential to adapt the (time-) step size to capture the
behavior of the system during those rapid changes and use a less accurate time
step at other, less demanding, moments. We encounter three problems with
traditional methods. Firstly, making such changes requires expert knowledge of
the astrophysics as well as of the details of the numerical implementation.
Secondly, some parameters that determine the time-step size are fixed
throughout the simulation, which means that they do not adapt to the rapidly
changing conditions of the problem. Lastly, we would like the choice of
time-step size to balance accuracy and computation effort. We address these
challenges with Reinforcement Learning by training it to select the time-step
size dynamically. We use the integration of a system of three equal-mass bodies
that move due to their mutual gravity as an example of its application. With
our method, the selected integration parameter adapts to the specific
requirements of the problem, both in terms of computation time and accuracy
while eliminating the expert knowledge needed to set up these simulations. Our
method produces results competitive to existing methods and improve the results
found with the most commonly-used values of time-step parameter. This method
can be applied to other integrators without further retraining. We show that
this extrapolation works for variable time-step integrators but does not
perform to the desired accuracy for fixed time-step integrators.",http://arxiv.org/abs/2502.12809v1
"Charge-changing weak interactions for right-handed particles in the
  Standard Model",2025-02-18T22:19:19Z,J. D. Franson,"Experiments have shown that the charge-changing weak interaction is purely
left-handed, which is taken into account in the Standard Model by the inclusion
of a left-handed projection operator in the Lagrangian. Nevertheless, it will
be shown here that the Standard Model predicts charge-changing weak
interactions for right-handed fermions that can be larger than those for
left-handed fermions if the mass is sufficiently large, as is the case for the
top quark. Here we are using the conventional terminology in which a massive
fermion with its spin parallel to its momentum is referred to as being
right-handed in the relativistic limit, where it is in an approximate
eigenstate of the chirality operator. These effects are due to the way in which
the field of the W boson is quantized, which gives a divergent tensor product
in the Feynman propagator in the unitary gauge. It will be shown that the
off-diagonal terms in the propagator can convert a left-handed projection
operator into a right-handed projection operator, which allows an interaction
with right-handed fermions even though the Lagrangian is left-handed.
Experiments to date have only demonstrated charge-changing weak interactions
for left-handed particles, and an alternative quantization approach that
eliminates the divergent off-diagonal terms in the W boson propagator and
avoids these difficulties will be considered. The alternative approach appears
to be in agreement with existing experiments, but additional high-energy
experiments may be required in order to distinguish its predictions from those
of the Standard Model.",http://arxiv.org/abs/2502.13317v1
"Modeling Cell Type Developmental Trajectory using Multinomial Unbalanced
  Optimal Transport",2025-01-07T03:44:28Z,"Junhao Zhu, Kevin Zhang, Zhaolei Zhang, Dehan Kong","Single-cell trajectory analysis aims to reconstruct the biological
developmental processes of cells as they evolve over time, leveraging temporal
correlations in gene expression. During cellular development, gene expression
patterns typically change and vary across different cell types. A significant
challenge in this analysis is that RNA sequencing destroys the cell, making it
impossible to track gene expression across multiple stages for the same cell.
Recent advances have introduced the use of optimal transport tools to model the
trajectory of individual cells. In this paper, our focus shifts to a question
of greater practical importance: we examine the differentiation of cell types
over time. Specifically, we propose a novel method based on discrete unbalanced
optimal transport to model the developmental trajectory of cell types. Our
method detects biological changes in cell types and infers their transitions to
different states by analyzing the transport matrix. We validated our method
using single-cell RNA sequencing data from mouse embryonic fibroblasts. The
results accurately identified major developmental changes in cell types, which
were corroborated by experimental evidence. Furthermore, the inferred
transition probabilities between cell types are highly congruent to biological
ground truth.",http://arxiv.org/abs/2501.03501v1
"Unsupervised Speech Segmentation: A General Approach Using Speech
  Language Models",2025-01-07T11:32:13Z,"Avishai Elmakies, Omri Abend, Yossi Adi","In this paper, we introduce an unsupervised approach for Speech Segmentation,
which builds on previously researched approaches, e.g., Speaker Diarization,
while being applicable to an inclusive set of acoustic-semantic distinctions,
paving a path towards a general Unsupervised Speech Segmentation approach.
Unlike traditional speech and audio segmentation, which mainly focuses on
spectral changes in the input signal, e.g., phone segmentation, our approach
tries to segment the spoken utterance into chunks with differing
acoustic-semantic styles, focusing on acoustic-semantic information that does
not translate well into text, e.g., emotion or speaker. While most Speech
Segmentation tasks only handle one style change, e.g., emotion diarization, our
approach tries to handle multiple acoustic-semantic style changes. Leveraging
recent advances in Speech Language Models (SLMs), we propose a simple
unsupervised method to segment a given speech utterance. We empirically
demonstrate the effectiveness of the proposed approach by considering several
setups. Results suggest that the proposed method is superior to the evaluated
baselines on boundary detection, segment purity, and over-segmentation. Code is
available at
https://github.com/avishaiElmakies/unsupervised_speech_segmentation_using_slm.",http://arxiv.org/abs/2501.03711v1
Cyber-Physical Steganography in Robotic Motion Control,2025-01-08T14:44:40Z,"Ching-Chun Chang, Yijie Lin, Isao Echizen","Steganography, the art of information hiding, has continually evolved across
visual, auditory and linguistic domains, adapting to the ceaseless interplay
between steganographic concealment and steganalytic revelation. This study
seeks to extend the horizons of what constitutes a viable steganographic medium
by introducing a steganographic paradigm in robotic motion control. Based on
the observation of the robot's inherent sensitivity to changes in its
environment, we propose a methodology to encode messages as environmental
stimuli influencing the motions of the robotic agent and to decode messages
from the resulting motion trajectory. The constraints of maximal robot
integrity and minimal motion deviation are established as fundamental
principles underlying secrecy. As a proof of concept, we conduct experiments in
simulated environments across various manipulation tasks, incorporating robotic
embodiments equipped with generalist multimodal policies.",http://arxiv.org/abs/2501.04541v1
"Investigating the Impact of Observation Space Design Choices On Training
  Reinforcement Learning Solutions for Spacecraft Problems",2025-01-10T14:53:21Z,"Nathaniel Hamilton, Kyle Dunlap, Kerianne L Hobbs","Recent research using Reinforcement Learning (RL) to learn autonomous control
for spacecraft operations has shown great success. However, a recent study
showed their performance could be improved by changing the action space, i.e.
control outputs, used in the learning environment. This has opened the door for
finding more improvements through further changes to the environment. The work
in this paper focuses on how changes to the environment's observation space can
impact the training and performance of RL agents learning the spacecraft
inspection task. The studies are split into two groups. The first looks at the
impact of sensors that were designed to help agents learn the task. The second
looks at the impact of reference frames, reorienting the agent to see the world
from a different perspective. The results show the sensors are not necessary,
but most of them help agents learn more optimal behavior, and that the
reference frame does not have a large impact, but is best kept consistent.",http://arxiv.org/abs/2501.06016v1
"The New Calculator? Practices, Norms, and Implications of Generative AI
  in Higher Education",2025-01-15T15:27:03Z,"Auste Simkute, Viktor Kewenig, Abigail Sellen, Sean Rintel, Lev Tankelevitch","Generative AI (GenAI) has introduced myriad opportunities and challenges for
higher education. Anticipating this potential transformation requires
understanding students' contextualised practices and norms around GenAI. We
conducted semi-structured interviews with 26 students and 11 educators from
diverse departments across two universities. Grounded in Strong Structuration
Theory, we find diversity in students' uses and motivations for GenAI.
Occurring in the context of unclear university guidelines, institutional
fixation on plagiarism, and inconsistent educator communication, students'
practices are informed by unspoken rules around appropriate use, GenAI
limitations and reliance strategies, and consideration of agency and skills.
Perceived impacts include changes in confidence, and concerns about skill
development, relationships with educators, and plagiarism. Both groups envision
changes in universities' attitude to GenAI, responsible use training,
assessments, and integration of GenAI into education. We discuss
socio-technical implications in terms of current and anticipated changes in the
external and internal structures that contextualise students' GenAI use.",http://arxiv.org/abs/2501.08864v1
GSTAR: Gaussian Surface Tracking and Reconstruction,2025-01-17T16:26:24Z,"Chengwei Zheng, Lixin Xue, Juan Zarate, Jie Song","3D Gaussian Splatting techniques have enabled efficient photo-realistic
rendering of static scenes. Recent works have extended these approaches to
support surface reconstruction and tracking. However, tracking dynamic surfaces
with 3D Gaussians remains challenging due to complex topology changes, such as
surfaces appearing, disappearing, or splitting. To address these challenges, we
propose GSTAR, a novel method that achieves photo-realistic rendering, accurate
surface reconstruction, and reliable 3D tracking for general dynamic scenes
with changing topology. Given multi-view captures as input, GSTAR binds
Gaussians to mesh faces to represent dynamic objects. For surfaces with
consistent topology, GSTAR maintains the mesh topology and tracks the meshes
using Gaussians. In regions where topology changes, GSTAR adaptively unbinds
Gaussians from the mesh, enabling accurate registration and the generation of
new surfaces based on these optimized Gaussians. Additionally, we introduce a
surface-based scene flow method that provides robust initialization for
tracking between frames. Experiments demonstrate that our method effectively
tracks and reconstructs dynamic surfaces, enabling a range of applications. Our
project page with the code release is available at
https://eth-ait.github.io/GSTAR/.",http://arxiv.org/abs/2501.10283v2
"Lead Times in Flux: Analyzing Airbnb Booking Dynamics During Global
  Upheavals (2018-2022)",2025-01-17T20:16:32Z,"Harrison Katz, Erica Savage, Peter Coles","Short-term shifts in booking behaviors can disrupt forecasting in the travel
and hospitality industry, especially during global crises. Traditional metrics
like average or median lead times often overlook important distribution
changes. This study introduces a normalized L1 (Manhattan) distance to assess
Airbnb booking lead time divergences from 2018 to 2022, focusing on the
COVID-19 pandemic across four major U.S. cities. We identify a two-phase
disruption: an abrupt change at the pandemic's onset followed by partial
recovery with persistent deviations from pre-2018 patterns. Our method reveals
changes in travelers' planning horizons that standard statistics miss,
highlighting the need to analyze the entire lead-time distribution for more
accurate demand forecasting and pricing strategies. The normalized L1 metric
provides valuable insights for tourism stakeholders navigating ongoing market
volatility.",http://arxiv.org/abs/2501.10535v1
Towards Online Code Specialization of Systems,2025-01-20T09:55:15Z,"Vaastav Anand, Deepak Garg, Antoine Kaufmann","Specializing low-level systems to specifics of the workload they serve and
platform they are running on often significantly improves performance. However,
specializing systems is difficult because of three compounding challenges: i)
specialization for optimal performance requires in-depth compile-time changes;
ii) the right combination of specialization choices for optimal performance is
hard to predict a priori; and iii) workloads and platform details often change
online. In practice, benefits of specialization are thus not attainable for
many low-level systems. To address this, we advocate for a radically different
approach for performance-critical low-level systems: designing and implementing
systems with and for runtime code specialization. We leverage just-in-time
compilation to change systems code based on developer-specified specialization
points as the system runs. The JIT runtime automatically tries out
specialization choices and measures their impact on system performance, e.g.
request latency or throughput, to guide the search. With Iridescent, our early
prototype, we demonstrate that online specialization (i) is feasible even for
low-level systems code, such as network stacks, (ii) improves system
performance without the need for complex cost models, (iii) incurs low
developer effort, especially compared to manual exploration. We conclude with
future opportunities online system code specialization enables.",http://arxiv.org/abs/2501.11366v1
"On nodal solutions with a prescribed number of nodes for a
  Kirchhoff-type problem",2025-01-22T13:18:03Z,"Haining Fan, Marco Squassina, Jianjun Zhang","We are concerned with the existence and asymptotic behavior of multiple
radial sign-changing solutions with the nodal characterization for a
Kirchhoff-type problem involving the nonlinearity $|u|^{p-2}u(2<p<4)$ in
$\mathbb{R}^3$. By developing some useful analysis techniques and introducing a
novel definition of the Nehari manifold for the auxiliary system of the
equations, we show that, for any positive integer $k$, the problem has a
sign-changing solution $u_k^b$ changing signs exactly $k$ times. Furthermore,
the energy of $u_k^b$ is strictly increasing in $k$, as well as some asymptotic
behaviors of $u_k^b$ are obtained. Our result is a complement of [Deng Y, Peng
S, Shuai W, {\it J. Funct. Anal.}, {\bf269}(2015), 3500-3527], where the case
$2<p<4$ is left open.",http://arxiv.org/abs/2501.12865v1
Parallel Belief Contraction via Order Aggregation,2025-01-23T00:42:16Z,"Jake Chandler, Richard Booth","The standard ``serial'' (aka ``singleton'') model of belief contraction
models the manner in which an agent's corpus of beliefs responds to the removal
of a single item of information. One salient extension of this model introduces
the idea of ``parallel'' (aka ``package'' or ``multiple'') change, in which an
entire set of items of information are simultaneously removed. Existing
research on the latter has largely focussed on single-step parallel
contraction: understanding the behaviour of beliefs after a single parallel
contraction. It has also focussed on generalisations to the parallel case of
serial contraction operations whose characteristic properties are extremely
weak. Here we consider how to extend serial contraction operations that obey
stronger properties. Potentially more importantly, we also consider the
iterated case: the behaviour of beliefs after a sequence of parallel
contractions. We propose a general method for extending serial iterated belief
change operators to handle parallel change based on an n-ary generalisation of
Booth & Chandler's TeamQueue binary order aggregators.",http://arxiv.org/abs/2501.13295v1
"Changing Induced Subgraph Isomorphisms Under Extended Reconfiguration
  Rules",2025-01-24T12:33:59Z,"Tatsuhiro Suga, Akira Suzuki, Yuma Tamura, Xiao Zhou","In a reconfiguration problem, we are given two feasible solutions of a
combinatorial problem and our goal is to determine whether it is possible to
reconfigure one into the other, with the steps dictated by specific
reconfiguration rules. Traditionally, most studies on reconfiguration problems
have focused on rules that allow changing a single element at a time. In
contrast, this paper considers scenarios in which $k \ge 2$ elements can be
changed simultaneously. We investigate the general reconfiguration problem of
isomorphisms. For the Induced Subgraph Isomorphism Reconfiguration problem, we
show that the problem remains $\textsf{PSPACE}$-complete even under stringent
constraints on the pattern graph when $k$ is constant. We then give two
meta-theorems applicable when $k$ is slightly less than the number of vertices
in the pattern graph. In addition, we investigate the complexity of the
Independent Set Reconfiguration problem, which is a special case of the Induced
Subgraph Isomorphism Reconfiguration problem.",http://arxiv.org/abs/2501.14450v1
"mFollowIR: a Multilingual Benchmark for Instruction Following in
  Retrieval",2025-01-31T16:24:46Z,"Orion Weller, Benjamin Chang, Eugene Yang, Mahsa Yarmohammadi, Sam Barham, Sean MacAvaney, Arman Cohan, Luca Soldaini, Benjamin Van Durme, Dawn Lawrie","Retrieval systems generally focus on web-style queries that are short and
underspecified. However, advances in language models have facilitated the
nascent rise of retrieval models that can understand more complex queries with
diverse intents. However, these efforts have focused exclusively on English;
therefore, we do not yet understand how they work across languages. We
introduce mFollowIR, a multilingual benchmark for measuring
instruction-following ability in retrieval models. mFollowIR builds upon the
TREC NeuCLIR narratives (or instructions) that span three diverse languages
(Russian, Chinese, Persian) giving both query and instruction to the retrieval
models. We make small changes to the narratives and isolate how well retrieval
models can follow these nuanced changes. We present results for both
multilingual (XX-XX) and cross-lingual (En-XX) performance. We see strong
cross-lingual performance with English-based retrievers that trained using
instructions, but find a notable drop in performance in the multilingual
setting, indicating that more work is needed in developing data for
instruction-based multilingual retrievers.",http://arxiv.org/abs/2501.19264v1
"Detection Is All You Need: A Feasible Optimal Prior-Free Black-Box
  Approach For Piecewise Stationary Bandits",2025-01-31T18:57:21Z,"Argyrios Gerogiannis, Yu-Han Huang, Subhonmesh Bose, Venugopal V. Veeravalli","We study the problem of piecewise stationary bandits without prior knowledge
of the underlying non-stationarity. We propose the first $\textit{feasible}$
black-box algorithm applicable to most common parametric bandit variants. Our
procedure, termed Detection Augmented Bandit (DAB), is modular, accepting any
stationary bandit algorithm as input and augmenting it with a change detector.
DAB achieves optimal regret in the piecewise stationary setting under mild
assumptions. Specifically, we prove that DAB attains the order-optimal regret
bound of $\tilde{\mathcal{O}}(\sqrt{N_T T})$, where $N_T$ denotes the number of
changes over the horizon $T$, if its input stationary bandit algorithm has
order-optimal stationary regret guarantees. Applying DAB to different
parametric bandit settings, we recover recent state-of-the-art results.
Notably, for self-concordant bandits, DAB achieves optimal dynamic regret,
while previous works obtain suboptimal bounds and require knowledge on the
non-stationarity. In simulations on piecewise stationary environments, DAB
outperforms existing approaches across varying number of changes.
Interestingly, despite being theoretically designed for piecewise stationary
environments, DAB is also effective in simulations in drifting environments,
outperforming existing methods designed specifically for this scenario.",http://arxiv.org/abs/2501.19401v1
"Analysis of Fractional Vegetation Coverage and its Dynamic Change in the
  Yalong River Basin based on Dimidiate Pixel Model",2025-02-03T01:17:49Z,"Yue Qin, Yuwei Lyu","Fractional vegetation coverage (FVC) and its spatio-temporal variations are
critical indicators of regional ecological changes, which are of great
significance to study the laws of surface variation and analyze regional
ecosystem. Under the development of RS and GIS technology, this analysis
employs Landsat satellite images in 1994, 2008, 2013 and 2016 to estimate FVC
in Yalong River Basin based on the Dimidiate Pixel Model. With consideration of
the vegetation coverage condition and land surface law in the study area, the
research further analyzes the Spatio-temporal variations as well as the
influencing factors of FVC in terms of topography and land use types
respectively. The results show that since 1994, FVC in Yalong River Basin has
experienced a downward trend yet displaying an uptick from 2013. Moreover,
different land use types indicate the versatility of land covers in Yalong
River Basin, with grassland and forest performing probably the most important
factors that can induce changes to the stability of FVC in whole basin.
Overall, the research reflects the impact of human activities on vegetation in
Yalong River Basin, and provides available data and theoretical basis for
ecological assessment, ecological restoration and environmental protection.",http://arxiv.org/abs/2502.01698v1
"Adaptive Budget Optimization for Multichannel Advertising Using
  Combinatorial Bandits",2025-02-05T06:29:52Z,"Briti Gangopadhyay, Zhao Wang, Alberto Silvio Chiappa, Shingo Takamatsu","Effective budget allocation is crucial for optimizing the performance of
digital advertising campaigns. However, the development of practical budget
allocation algorithms remain limited, primarily due to the lack of public
datasets and comprehensive simulation environments capable of verifying the
intricacies of real-world advertising. While multi-armed bandit (MAB)
algorithms have been extensively studied, their efficacy diminishes in
non-stationary environments where quick adaptation to changing market dynamics
is essential. In this paper, we advance the field of budget allocation in
digital advertising by introducing three key contributions. First, we develop a
simulation environment designed to mimic multichannel advertising campaigns
over extended time horizons, incorporating logged real-world data. Second, we
propose an enhanced combinatorial bandit budget allocation strategy that
leverages a saturating mean function and a targeted exploration mechanism with
change-point detection. This approach dynamically adapts to changing market
conditions, improving allocation efficiency by filtering target regions based
on domain knowledge. Finally, we present both theoretical analysis and
empirical results, demonstrating that our method consistently outperforms
baseline strategies, achieving higher rewards and lower regret across multiple
real-world campaigns.",http://arxiv.org/abs/2502.02920v1
"Time Series Anomaly Detection in the Frequency Domain with Statistical
  Reliability",2025-02-05T10:48:12Z,"Akifumi Yamada, Tomohiro Shiraishi, Shuichi Nishino, Teruyuki Katsuoka, Kouichi Taji, Ichiro Takeuchi","Effective anomaly detection in complex systems requires identifying change
points (CPs) in the frequency domain, as abnormalities often arise across
multiple frequencies. This paper extends recent advancements in statistically
significant CP detection, based on Selective Inference (SI), to the frequency
domain. The proposed SI method quantifies the statistical significance of
detected CPs in the frequency domain using $p$-values, ensuring that the
detected changes reflect genuine structural shifts in the target system. We
address two major technical challenges to achieve this. First, we extend the
existing SI framework to the frequency domain by appropriately utilizing the
properties of discrete Fourier transform (DFT). Second, we develop an SI method
that provides valid $p$-values for CPs where changes occur across multiple
frequencies. Experimental results demonstrate that the proposed method reliably
identifies genuine CPs with strong statistical guarantees, enabling more
accurate root-cause analysis in the frequency domain of complex systems.",http://arxiv.org/abs/2502.03062v1
"An object detection approach for lane change and overtake detection from
  motion profiles",2025-02-06T17:36:35Z,"Andrea Benericetti, Niccolò Bellaccini, Henrique Piñeiro Monteagudo, Matteo Simoncini, Francesco Sambo","In the application domain of fleet management and driver monitoring, it is
very challenging to obtain relevant driving events and activities from dashcam
footage while minimizing the amount of information stored and analyzed. In this
paper, we address the identification of overtake and lane change maneuvers with
a novel object detection approach applied to motion profiles, a compact
representation of driving video footage into a single image. To train and test
our model we created an internal dataset of motion profile images obtained from
a heterogeneous set of dashcam videos, manually labeled with overtake and lane
change maneuvers by the ego-vehicle. In addition to a standard object-detection
approach, we show how the inclusion of CoordConvolution layers further improves
the model performance, in terms of mAP and F1 score, yielding state-of-the art
performance when compared to other baselines from the literature. The extremely
low computational requirements of the proposed solution make it especially
suitable to run in device.",http://arxiv.org/abs/2502.04244v1
Variation of sentence length across time and genre,2025-02-06T18:59:02Z,Karolina Rudnicka,"The goal of this paper is threefold: i) to present some practical aspects of
using full-text version of Corpus of Historical American English (COHA), the
largest diachronic multi-genre corpus of the English language, in the
investigation of a linguistic trend of change; ii) to test a widely held
assumption that sentence length in written English has been steadily decreasing
over the past few centuries; iii) to point to a possible link between the
changes in sentence length and changes in the English syntactic usage. The
empirical proof of concept for iii) is provided by the decline in the frequency
of the non-finite purpose subordinator in order to. Sentence length, genre and
the likelihood of occurrence of in order to are shown to be interrelated.",http://arxiv.org/abs/2502.04321v1
"An Evolutionary Game With the Game Transitions Based on the Markov
  Process",2025-02-09T01:57:18Z,"Minyu Feng, Bin Pi, Liang-Jian Deng, Jürgen Kurths","The psychology of the individual is continuously changing in nature, which
has a significant influence on the evolutionary dynamics of populations. To
study the influence of the continuously changing psychology of individuals on
the behavior of populations, in this paper, we consider the game transitions of
individuals in evolutionary processes to capture the changing psychology of
individuals in reality, where the game that individuals will play shifts as
time progresses and is related to the transition rates between different games.
Besides, the individual's reputation is taken into account and utilized to
choose a suitable neighbor for the strategy updating of the individual. Within
this model, we investigate the statistical number of individuals staying in
different game states and the expected number fits well with our theoretical
results. Furthermore, we explore the impact of transition rates between
different game states, payoff parameters, the reputation mechanism, and
different time scales of strategy updates on cooperative behavior, and our
findings demonstrate that both the transition rates and reputation mechanism
have a remarkable influence on the evolution of cooperation. Additionally, we
examine the relationship between network size and cooperation frequency,
providing valuable insights into the robustness of the model.",http://arxiv.org/abs/2502.05742v1
"CHIRLA: Comprehensive High-resolution Identification and
  Re-identification for Large-scale Analysis",2025-02-10T17:07:43Z,"Bessie Dominguez-Dager, Felix Escalona, Francisco Gomez-Donoso, Miguel Cazorla","Person re-identification (Re-ID) is a key challenge in computer vision,
requiring the matching of individuals across different cameras, locations, and
time periods. While most research focuses on short-term scenarios with minimal
appearance changes, real-world applications demand robust Re-ID systems capable
of handling long-term scenarios, where persons' appearances can change
significantly due to variations in clothing and physical characteristics. In
this paper, we present CHIRLA, Comprehensive High-resolution Identification and
Re-identification for Large-scale Analysis, a novel dataset specifically
designed for long-term person Re-ID. CHIRLA consists of recordings from
strategically placed cameras over a seven-month period, capturing significant
variations in both temporal and appearance attributes, including controlled
changes in participants' clothing and physical features. The dataset includes
22 individuals, four connected indoor environments, and seven cameras. We
collected more than five hours of video that we semi-automatically labeled to
generate around one million bounding boxes with identity annotations. By
introducing this comprehensive benchmark, we aim to facilitate the development
and evaluation of Re-ID algorithms that can reliably perform in challenging,
long-term real-world scenarios.",http://arxiv.org/abs/2502.06681v1
Fock state probability changes in open quantum systems,2025-02-11T16:19:08Z,"Clare Burrage, Christian Käding","Open quantum systems are powerful effective descriptions of quantum systems
interacting with their environments. Studying changes of Fock states
probabilities can be intricate in this context since the prevailing description
of open quantum dynamics is by master equations of the systems' reduced density
matrices, which usually requires finding solutions for a set of complicated
coupled differential equations. In this article, we show that such problems can
be circumvented by employing a recently developed path integral-based method
for directly computing reduced density matrices in scalar quantum field theory.
For this purpose, we consider a real scalar field $\phi$ as an open system
interacting via a $\lambda \chi^2\phi^2$-term with an environment comprising
another real scalar field $\chi$ that has a finite temperature. In particular,
we investigate how the probabilities for observing the vacuum or two-particle
states change over time if there were initial correlations of these Fock
states. Subsequently, we apply our resulting expressions to a neutrino toy
model. We show that, within our model, lighter neutrino masses would lead to a
stronger distortion of the observable number of particles due to the
interaction with the environment after the initial production process.",http://arxiv.org/abs/2502.07673v1
"Improving TCM Question Answering through Tree-Organized Self-Reflective
  Retrieval with LLMs",2025-02-13T10:36:18Z,"Chang Liu, Ying Chang, Jianmin Li, Yiqian Qu, Yu Li, Lingyong Cao, Shuyuan Lin","Objectives: Large language models (LLMs) can harness medical knowledge for
intelligent question answering (Q&A), promising support for auxiliary diagnosis
and medical talent cultivation. However, there is a deficiency of highly
efficient retrieval-augmented generation (RAG) frameworks within the domain of
Traditional Chinese Medicine (TCM). Our purpose is to observe the effect of the
Tree-Organized Self-Reflective Retrieval (TOSRR) framework on LLMs in TCM Q&A
tasks.
  Materials and Methods: We introduce the novel approach of knowledge
organization, constructing a tree structure knowledge base with hierarchy. At
inference time, our self-reflection framework retrieves from this knowledge
base, integrating information across chapters. Questions from the TCM Medical
Licensing Examination (MLE) and the college Classics Course Exam (CCE) were
randomly selected as benchmark datasets.
  Results: By coupling with GPT-4, the framework can improve the best
performance on the TCM MLE benchmark by 19.85% in absolute accuracy, and
improve recall accuracy from 27% to 38% on CCE datasets. In manual evaluation,
the framework improves a total of 18.52 points across dimensions of safety,
consistency, explainability, compliance, and coherence.
  Conclusion: The TOSRR framework can effectively improve LLM's capability in
Q&A tasks of TCM.",http://arxiv.org/abs/2502.09156v1
"Architecture for Simulating Behavior Mode Changes in Norm-Aware
  Autonomous Agents",2025-02-13T11:49:02Z,"Sean Glaze, Daniela Inclezan","This paper presents an architecture for simulating the actions of a
norm-aware intelligent agent whose behavior with respect to norm compliance is
set, and can later be changed, by a human controller. Updating an agent's
behavior mode from a norm-abiding to a riskier one may be relevant when the
agent is involved in time-sensitive rescue operations, for example. We base our
work on the Authorization and Obligation Policy Language AOPL designed by
Gelfond and Lobo for the specification of norms. We introduce an architecture
and a prototype software system that can be used to simulate an agent's plans
under different behavior modes that can later be changed by the controller. We
envision such software to be useful to policy makers, as they can more readily
understand how agents may act in certain situations based on the agents'
attitudes towards norm-compliance. Policy makers may then refine their policies
if simulations show unwanted consequences.",http://arxiv.org/abs/2502.09215v1
CellFlow: Simulating Cellular Morphology Changes via Flow Matching,2025-02-13T21:10:00Z,"Yuhui Zhang, Yuchang Su, Chenyu Wang, Tianhong Li, Zoe Wefers, Jeffrey Nirschl, James Burgess, Daisy Ding, Alejandro Lozano, Emma Lundberg, Serena Yeung-Levy","Building a virtual cell capable of accurately simulating cellular behaviors
in silico has long been a dream in computational biology. We introduce
CellFlow, an image-generative model that simulates cellular morphology changes
induced by chemical and genetic perturbations using flow matching. Unlike prior
methods, CellFlow models distribution-wise transformations from unperturbed to
perturbed cell states, effectively distinguishing actual perturbation effects
from experimental artifacts such as batch effects -- a major challenge in
biological data. Evaluated on chemical (BBBC021), genetic (RxRx1), and combined
perturbation (JUMP) datasets, CellFlow generates biologically meaningful cell
images that faithfully capture perturbation-specific morphological changes,
achieving a 35% improvement in FID scores and a 12% increase in mode-of-action
prediction accuracy over existing methods. Additionally, CellFlow enables
continuous interpolation between cellular states, providing a potential tool
for studying perturbation dynamics. These capabilities mark a significant step
toward realizing virtual cell modeling for biomedical research.",http://arxiv.org/abs/2502.09775v1
"Robust variance estimators in application to segmentation of measurement
  data distorted by impulsive and non-Gaussian noise",2025-02-14T16:33:17Z,"Justyna Witulska, Anna Zaleska, Natalia Kremzer-Osiadacz, Agnieszka Wyłomańska, Ireneusz Jabłoński","The paper algorithmizes the problem of regime change point identification for
data measured in a system exhibiting impulsive behaviors. This is a fundamental
challenge for annotation of measurement data relevant, e.g., for designing
data-driven autonomous systems. The contribution consists in the formulation of
an offline robust methodology based on the classical approach for structural
break detection. The problem of data segmentation is considered in the context
of scale change, which physically can be translated into the occurrence of a
critical event that reorganizes the system structure. The main advantage of our
approach is that it does not require the existence of a variance of the data
distribution. The efficiency has been evaluated for simulated data from two
distributions and for real-world datasets measured in financial, mechanical,
and medical systems. Simulation studies show that in the most challenging case,
the error in estimating regime change is 20 times smaller for robust approach
compared to the classical one.",http://arxiv.org/abs/2502.10275v1
"Changing the Rules of the Game: Reasoning about Dynamic Phenomena in
  Multi-Agent Systems",2025-02-17T13:23:37Z,"Rustam Galimullin, Maksim Gladyshev, Munyque Mittelmann, Nima Motamed","The design and application of multi-agent systems (MAS) require reasoning
about the effects of modifications on their underlying structure. In
particular, such changes may impact the satisfaction of system specifications
and the strategic abilities of their autonomous components. In this paper, we
are concerned with the problem of verifying and synthesising modifications (or
\textit{updates}) of MAS. We propose an extension of the Alternating-Time
Temporal Logic ($\mathsf{ATL}$) that enables reasoning about the dynamics of
model change, called the \textit{Logic for $\mathsf{ATL}$ Model Building}
($\mathsf{LAMB}$). We show how $\mathsf{LAMB}$ can express various intuitions
and ideas about the dynamics of MAS, from normative updates to mechanism
design. As the main technical result, we prove that, while being strictly more
expressive than $\mathsf{ATL}$, $\mathsf{LAMB}$ enjoys a P-complete
model-checking procedure.",http://arxiv.org/abs/2502.11785v1
"JL1-CD: A New Benchmark for Remote Sensing Change Detection and a Robust
  Multi-Teacher Knowledge Distillation Framework",2025-02-19T03:33:54Z,"Ziyuan Liu, Ruifei Zhu, Long Gao, Yuanxiu Zhou, Jingyu Ma, Yuantao Gu","Deep learning has achieved significant success in the field of remote sensing
image change detection (CD), yet two major challenges remain: the scarcity of
sub-meter, all-inclusive open-source CD datasets, and the difficulty of
achieving consistent and satisfactory detection results across images with
varying change areas. To address these issues, we introduce the JL1-CD dataset,
which contains 5,000 pairs of 512 x 512 pixel images with a resolution of 0.5
to 0.75 meters. Additionally, we propose a multi-teacher knowledge distillation
(MTKD) framework for CD. Experimental results on the JL1-CD and SYSU-CD
datasets demonstrate that the MTKD framework significantly improves the
performance of CD models with various network architectures and parameter
sizes, achieving new state-of-the-art results. The code is available at
https://github.com/circleLZY/MTKD-CD.",http://arxiv.org/abs/2502.13407v1
"Exploring Personalized Health Support through Data-Driven, Theory-Guided
  LLMs: A Case Study in Sleep Health",2025-02-19T17:53:43Z,"Xingbo Wang, Janessa Griffith, Daniel A. Adler, Joey Castillo, Tanzeem Choudhury, Fei Wang","Despite the prevalence of sleep-tracking devices, many individuals struggle
to translate data into actionable improvements in sleep health. Current methods
often provide data-driven suggestions but may not be feasible and adaptive to
real-life constraints and individual contexts. We present HealthGuru, a novel
large language model-powered chatbot to enhance sleep health through
data-driven, theory-guided, and adaptive recommendations with conversational
behavior change support. HealthGuru's multi-agent framework integrates wearable
device data, contextual information, and a contextual multi-armed bandit model
to suggest tailored sleep-enhancing activities. The system facilitates natural
conversations while incorporating data-driven insights and theoretical behavior
change techniques. Our eight-week in-the-wild deployment study with 16
participants compared HealthGuru to a baseline chatbot. Results show improved
metrics like sleep duration and activity scores, higher quality responses, and
increased user motivation for behavior change with HealthGuru. We also identify
challenges and design considerations for personalization and user engagement in
health chatbots.",http://arxiv.org/abs/2502.13920v1
"LoRA-GGPO: Mitigating Double Descent in LoRA Fine-Tuning via
  Gradient-Guided Perturbation Optimization",2025-02-20T13:14:41Z,"Yupeng Chang, Chenlu Guo, Yi Chang, Yuan Wu","Large Language Models (LLMs) have achieved remarkable success in natural
language processing, but their full fine-tuning remains resource-intensive.
Parameter-Efficient Fine-Tuning (PEFT) methods, such as Low-Rank Adaptation
(LoRA), have emerged as a practical solution by approximating parameter updates
with low-rank matrices. However, LoRA often exhibits a ""double descent""
phenomenon during fine-tuning, where model performance degrades due to
overfitting and limited expressiveness caused by low-rank constraints. To
address this issue, we propose LoRA-GGPO (Gradient-Guided Perturbation
Optimization), a novel method that leverages gradient and weight norms to
generate targeted perturbations. By optimizing the sharpness of the loss
landscape, LoRA-GGPO guides the model toward flatter minima, mitigating the
double descent problem and improving generalization. Extensive experiments on
natural language understanding (NLU) and generation (NLG) tasks demonstrate
that LoRA-GGPO outperforms LoRA and its state-of-the-art variants. Furthermore,
extended experiments specifically designed to analyze the double descent
phenomenon confirm that LoRA-GGPO effectively alleviates this issue, producing
more robust and generalizable models. Our work provides a robust and efficient
solution for fine-tuning LLMs, with broad applicability in real-world
scenarios. The code is available at https://github.com/llm172/LoRA-GGPO.",http://arxiv.org/abs/2502.14538v1
"IoT Firmware Version Identification Using Transfer Learning with Twin
  Neural Networks",2025-01-10T15:11:33Z,"Ashley Andrews, George Oikonomou, Simon Armour, Paul Thomas, Thomas Cattermole","As the Internet of Things (IoT) becomes more embedded within our daily lives,
there is growing concern about the risk `smart' devices pose to network
security. To address this, one avenue of research has focused on automated IoT
device identification. Research has however largely neglected the
identification of IoT device firmware versions. There is strong evidence that
IoT security relies on devices being on the latest version patched for known
vulnerabilities. Identifying when a device has updated (has changed version) or
not (is on a stable version) is therefore useful for IoT security. Version
identification involves challenges beyond those for identifying the model,
type, and manufacturer of IoT devices, and traditional machine learning
algorithms are ill-suited for effective version identification due to being
limited by the availability of data for training. In this paper, we introduce
an effective technique for identifying IoT device versions based on transfer
learning. This technique relies on the idea that we can use a Twin Neural
Network (TNN) - trained at distinguishing devices - to detect differences
between a device on different versions. This facilitates real-world
implementation by requiring relatively little training data. We extract
statistical features from on-wire packet flows, convert these features into
greyscale images, pass these images into a TNN, and determine version changes
based on the Hedges' g effect size of the similarity scores. This allows us to
detect the subtle changes present in on-wire traffic when a device changes
version. To evaluate our technique, we set up a lab containing 12 IoT devices
and recorded their on-wire packet captures for 11 days across multiple firmware
versions. For testing data held out from training, our best performing model is
shown to be 95.83% and 84.38% accurate at identifying stable versions and
version changes respectively.",http://arxiv.org/abs/2501.06033v1
"Sensitivity of Quantitative Susceptibility Mapping in Clinical Brain
  Research",2025-01-28T18:58:43Z,"Fahad Salman, Abhisri Ramesh, Thomas Jochmann, Mirjam Prayer, Ademola Adegbemigun, Jack A. Reeves, Gregory E. Wilding, Junghun Cho, Dejan Jakimovski, Niels Bergsland, Michael G. Dwyer, Robert Zivadinov, Ferdinand Schweser","Background: Quantitative susceptibility mapping (QSM) of the brain is an
advanced MRI technique for assessing tissue characteristics based on magnetic
susceptibility, which varies with the composition of the tissue, such as iron,
calcium, and myelin levels. QSM consists of multiple processing steps, with
various choices for each step. Despite its increasing application in detecting
and monitoring neurodegenerative diseases, the impact of algorithmic choices in
QSM's workflow on clinical outcomes has not been thoroughly quantified.
  Objective: This study aimed to evaluate how choices in background field
removal (BFR), dipole inversion algorithms, and anatomical referencing impact
the sensitivity and reproducibility error of QSM in detecting group-level and
longitudinal changes in deep gray matter susceptibility in a clinical setting.
  Methods: We compared 378 different QSM pipelines using a 10-year follow-up
dataset of healthy adults. We analyzed the sensitivity of pipelines to detect
known aging-related susceptibility changes in the DGM over time.
  Results: We found high variability in the sensitivity of QSM pipelines to
detect susceptibility changes. The study highlighted that while most pipelines
could detect changes reliably, the choice of BFR algorithm and the referencing
strategy substantially influenced the outcome reproducibility error and
sensitivity. Notably, pipelines using RESHARP with AMP-PE, HEIDI or LSQR
inversion showed the highest overall sensitivity.
  Conclusions: The findings underscore the critical influence of algorithmic
choices in QSM processing on the accuracy and reliability of detecting
physiological changes in the brain. This has profound implications for clinical
research and trials where QSM is used as a biomarker for disease progression,
highlighting that careful consideration should be given to pipeline
configuration to optimize clinical outcomes.",http://arxiv.org/abs/2501.17158v1
"Evolution and sudden change of steady interactions of low enthalpy
  hypersonic double wedge flows with fore angle",2025-02-20T01:41:00Z,"Yihui Weng, Yi Duan, Qin Li, Yunchuan Wu, Mengyu Wang, Pan Yan, Siyi Li","The evolution and sudden change of steady interaction structures is
numerically studied with the fore wedge angle theta_1 in a low enthalpy
hypersonic double wedge configuration. It particularly focuses on the
conditions of Swantek and Austin's experiments where Ma=7, and h_0=2 MJ/kg but
with a reduced Reynolds number (Re). The sudden structural change indicates
that when theta_1 reaches a critical value, minor angular variations can
trigger a discontinuous transformation in flow structures. The analysis is
based on the laminar Navier-Stokes equations, using ideal gas and
non-equilibrium gas models. Under the condition of Re=1E5/m, detailed numerical
simulations are conducted as theta_1 varies over 0 deg-40 deg. This study
yields the following findings: (a) The upper and lower boundaries of theta_1
for the onset of unsteady flow are identified. When theta_1 lies outside these
boundaries, the flow remains steady. (b) As theta_1 increases, the interaction
patterns evolve sequentially, progressing from Type VI through Type VI->V, Type
III, Type IV_r, and ultimately to a flow dominated solely by a bow shock. This
evolution defines the boundaries between different interaction patterns and
provides a comprehensive understanding of their progression with theta_1.
Sudden structural changes occur during the transitions from Type III to Type
IV_r and from Type IV_r to a bow shock-dominated flow. In addition, a
comparative study is performed through shock polar analysis to compare its
predictions with computational results. (c) An unconventional reflection
pattern of the transmitted shock over the separation zone, called Type III_r,
is observed in non-equilibrium gas flows, which differs from classical
interaction patterns. (d) The aerodynamic distribution of wall properties under
various interactions is obtained, indicating distinct features before and after
the sudden structural change.",http://arxiv.org/abs/2502.14186v1
"Realistic overground gait transitions are not sharp but involve
  gradually changing walk-run mixtures as per energy optimality",2025-01-01T04:37:28Z,"Nicholas S. Baker, Leroy Long, Manoj Srinivasan","Humans use two qualitatively different gaits for locomotion, namely, walking
and running -- usually using walking at lower speeds and running at higher
speeds. Researchers have examined when humans switch between walking and
running on treadmills and have noted hystereses in these gait transition
speeds. Here, we consider an ecologically realistic overground locomotion task,
one requiring traveling a given long distance (800 meters or 2400 meters) in a
prescribed time duration. Unlike on a treadmill, this task allows the human to
change speed or gait during the trial to reach the destination on time: this
task is akin to traveling to an appointment at a particular time from your
office to another office, arriving neither early or late. We find that gait
transition is not sharp, but instead involves a 'gait transition regime' in
which humans use a mixture of walking and running, using mostly walking atlower
speeds and mostly running higher speeds -- supporting earlier results over
short distances (120 m). The presence of this gradually changing walk-run
mixture is predicted by energy optimality. We hypothesize that this energy
optimal behavior in this realistic overground conditions accounts for the
hysteretic behavior in treadmill experiments, apparently switching earlier than
predicted by energy optimality.",http://arxiv.org/abs/2501.00720v1
"Rotational Flow Dominates Abrupt Seasonal Change in Zonally Asymmetric
  Tropical Meridional Circulation",2025-01-04T16:13:33Z,"Wuqiushi Yao, Jianhua Lu, Yimin Liu","The seasonality of the tropical meridional circulation evolves differently
across different regions, governs the onset and retreat of monsoons and
migration of tropical precipitation, thereby influencing agricultural
productivity and disaster preparedness in the tropics and subtropics. By
defining a pseudo meridional overturning streamfunction ({\Psi}pseudo) and
defining a new vector-type, dual-component index (ASCI), we diagnose zonally
asymmetric abrupt seasonal change (ASC) of tropical meridional circulation.
{\Psi}pseudo converges to traditional, meridional overturning streamfunction
({\Psi}m) after being averaged over a zonal circle around any latitude. By
applying the Helmholtz decomposition to horizontal velocity fields so as to
decompose {\Psi}pseudo into rotational and divergent components, we
quantitatively compare the contributions of horizontally rotational and
divergent flows to the abrupt seasonal change. We find that the zonal sectors
associated with strong deep convection exhibit the most pronounced ASC of
tropical meridional circulation, and all of subregions exhibiting ASC contain
landmass with low heat inertia. Particularly, in contrast to the case of
zonally symmetric Hadley cell, rotational flow, rather than the thermal-direct
divergent flow, dominates the zonally asymmetric ASC in the tropics, although
the divergent flow also contributes to the ASC over the zonal sectors
associated with deep convection. We suggest that the interplay between tropical
Rossby-type eddies with extratropical eddies and tropical circulation is
essential to the zonally asymmetric ASC of tropical Hadley circulation.",http://arxiv.org/abs/2501.02326v1
"AHMSA-Net: Adaptive Hierarchical Multi-Scale Attention Network for
  Micro-Expression Recognition",2025-01-05T13:40:12Z,"Lijun Zhang, Yifan Zhang, Weicheng Tang, Xinzhi Sun, Xiaomeng Wang, Zhanshan Li","Micro-expression recognition (MER) presents a significant challenge due to
the transient and subtle nature of the motion changes involved. In recent
years, deep learning methods based on attention mechanisms have made some
breakthroughs in MER. However, these methods still suffer from the limitations
of insufficient feature capture and poor dynamic adaptation when coping with
the instantaneous subtle movement changes of micro-expressions. Therefore, in
this paper, we design an Adaptive Hierarchical Multi-Scale Attention Network
(AHMSA-Net) for MER. Specifically, we first utilize the onset and apex frames
of the micro-expression sequence to extract three-dimensional (3D) optical flow
maps, including horizontal optical flow, vertical optical flow, and optical
flow strain. Subsequently, the optical flow feature maps are inputted into
AHMSA-Net, which consists of two parts: an adaptive hierarchical framework and
a multi-scale attention mechanism. Based on the adaptive downsampling
hierarchical attention framework, AHMSA-Net captures the subtle changes of
micro-expressions from different granularities (fine and coarse) by dynamically
adjusting the size of the optical flow feature map at each layer. Based on the
multi-scale attention mechanism, AHMSA-Net learns micro-expression action
information by fusing features from different scales (channel and spatial).
These two modules work together to comprehensively improve the accuracy of MER.
Additionally, rigorous experiments demonstrate that the proposed method
achieves competitive results on major micro-expression databases, with
AHMSA-Net achieving recognition accuracy of up to 78.21% on composite databases
(SMIC, SAMM, CASMEII) and 77.08% on the CASME^{}3 database.",http://arxiv.org/abs/2501.02539v1
The fragmentation of molecular clouds in starburst environments,2025-01-06T19:00:04Z,"Matt T. Cusack, Paul C. Clark, Simon C. O. Glover, Ralf S. Klessen, Philipp Girichidis, Anthony P. Whitworth, Felix D. Priestley","A significant amount of star formation occurs and has occurred in
environments unlike the solar neighbourhood. The majority of stars formed
closer to the peak of the cosmic star formation rate (z > 1.3) and a great deal
of star formation presently occurs in the central molecular zone (CMZ) of the
Galaxy. These environments are unified by the presence of a high interstellar
radiation field (ISRF) and a high cosmic ray ionisation rate (CRIR). Numerical
studies of stellar birth typically neglect this fact, and those that do not
have thus far been limited in scope. In this work we present the first
comprehensive analysis of hydrodynamical simulations of star formation in
extreme environments where we have increased the ISRF and CRIR to values
typical of the CMZ and starburst galaxies. We note changes in the fragmentation
behaviour on both the core and stellar system scale, leading to top-heavy core
and stellar system mass functions in high ISRF/CRIR clouds. Clouds fragment
less on the core scale, producing fewer but more massive cores. Conversely, the
cores fragment more intensely and produce richer clusters of stellar systems.
We present a picture where high ISRF/CRIR clouds fragment less on the scale of
cores and clumps, but more on the scale of stellar systems. The change in
fragmentation behaviour subsequently changes the mass function of the stellar
systems that form through enhanced accretion rates.",http://arxiv.org/abs/2501.03323v1
"OpenIN: Open-Vocabulary Instance-Oriented Navigation in Dynamic Domestic
  Environments",2025-01-08T05:01:59Z,"Yujie Tang, Meiling Wang, Yinan Deng, Zibo Zheng, Jingchuan Deng, Yufeng Yue","In daily domestic settings, frequently used objects like cups often have
unfixed positions and multiple instances within the same category, and their
carriers frequently change as well. As a result, it becomes challenging for a
robot to efficiently navigate to a specific instance. To tackle this challenge,
the robot must capture and update scene changes and plans continuously.
However, current object navigation approaches primarily focus on the semantic
level and lack the ability to dynamically update scene representation. In
contrast, this paper captures the relationships between frequently used objects
and their static carriers. It constructs an open-vocabulary
Carrier-Relationship Scene Graph (CRSG) and updates the carrying status during
robot navigation to reflect the dynamic changes of the scene. Based on the
CRSG, we further propose an instance navigation strategy that models the
navigation process as a Markov Decision Process. At each step, decisions are
informed by the Large Language Model's commonsense knowledge and
visual-language feature similarity. We designed a series of long-sequence
navigation tasks for frequently used everyday items in the Habitat simulator.
The results demonstrate that by updating the CRSG, the robot can efficiently
navigate to moved targets. Additionally, we deployed our algorithm on a real
robot and validated its practical effectiveness. The project page can be found
here: https://OpenIN-nav.github.io.",http://arxiv.org/abs/2501.04279v1
"Federated-Continual Dynamic Segmentation of Histopathology guided by
  Barlow Continuity",2025-01-08T16:06:39Z,"Niklas Babendererde, Haozhe Zhu, Moritz Fuchs, Jonathan Stieber, Anirban Mukhopadhyay","Federated- and Continual Learning have been established as approaches to
enable privacy-aware learning on continuously changing data, as required for
deploying AI systems in histopathology images. However, data shifts can occur
in a dynamic world, spatially between institutions and temporally, due to
changing data over time. This leads to two issues: Client Drift, where the
central model degrades from aggregating data from clients trained on shifted
data, and Catastrophic Forgetting, from temporal shifts such as changes in
patient populations. Both tend to degrade the model's performance of previously
seen data or spatially distributed training. Despite both problems arising from
the same underlying problem of data shifts, existing research addresses them
only individually. In this work, we introduce a method that can jointly
alleviate Client Drift and Catastrophic Forgetting by using our proposed
Dynamic Barlow Continuity that evaluates client updates on a public reference
dataset and uses this to guide the training process to a spatially and
temporally shift-invariant model. We evaluate our approach on the
histopathology datasets BCSS and Semicol and prove our method to be highly
effective by jointly improving the dice score as much as from 15.8% to 71.6% in
Client Drift and from 42.5% to 62.8% in Catastrophic Forgetting. This enables
Dynamic Learning by establishing spatio-temporal shift-invariance.",http://arxiv.org/abs/2501.04588v1
"Color Correction Meets Cross-Spectral Refinement: A Distribution-Aware
  Diffusion for Underwater Image Restoration",2025-01-08T03:26:45Z,"Laibin Chang, Yunke Wang, Bo Du, Chang Xu","Underwater imaging often suffers from significant visual degradation, which
limits its suitability for subsequent applications. While recent underwater
image enhancement (UIE) methods rely on the current advances in deep neural
network architecture designs, there is still considerable room for improvement
in terms of cross-scene robustness and computational efficiency. Diffusion
models have shown great success in image generation, prompting us to consider
their application to UIE tasks. However, directly applying them to UIE tasks
will pose two challenges, \textit{i.e.}, high computational budget and color
unbalanced perturbations. To tackle these issues, we propose DiffColor, a
distribution-aware diffusion and cross-spectral refinement model for efficient
UIE. Instead of diffusing in the raw pixel space, we transfer the image into
the wavelet domain to obtain such low-frequency and high-frequency spectra, it
inherently reduces the image spatial dimensions by half after each
transformation. Unlike single-noise image restoration tasks, underwater imaging
exhibits unbalanced channel distributions due to the selective absorption of
light by water. To address this, we design the Global Color Correction (GCC)
module to handle the diverse color shifts, thereby avoiding potential global
degradation disturbances during the denoising process. For the sacrificed image
details caused by underwater scattering, we further present the Cross-Spectral
Detail Refinement (CSDR) to enhance the high-frequency details, which are
integrated with the low-frequency signal as input conditions for guiding the
diffusion. This way not only ensures the high-fidelity of sampled content but
also compensates for the sacrificed details. Comprehensive experiments
demonstrate the superior performance of DiffColor over state-of-the-art methods
in both quantitative and qualitative evaluations.",http://arxiv.org/abs/2501.04740v1
"Million-atom simulation of the set process in phase change memories at
  the real device scale",2025-01-13T15:03:47Z,"Omar Abou El Kheir, Marco Bernasconi","Phase change materials are exploited in several enabling technologies such as
storage class memories, neuromorphic devices and memories embedded in
microcontrollers. A key functional property for these applications is the fast
crystal nucleation and growth in the supercool liquid phase. Over the last
decade, atomistic simulations based on density functional theory (DFT) have
provided crucial insights on the early stage of this process. These simulations
are, however, restricted to a few hundred atoms for at most a few ns. More
recently, the scope of the DFT simulations have been greatly extended by
leveraging on machine learning techniques. In this paper, we show that the
exploitation of a recently devised neural network potential for the
prototypical phase change compound Ge$_2$Sb$_2$Te$_5$, allows simulating the
crystallization process in a multimillion atom model at the length and time
scales of the real memory devices. The simulations provide a vivid atomistic
picture of the subtle interplay between crystal nucleation and crystal growth
from the crystal/amorphous rim. Moreover, the simulations have allowed
quantifying the distribution of point defects controlling electronic transport,
in a very large crystallite grown at the real conditions of the set process of
the device.",http://arxiv.org/abs/2501.07384v1
"Modelling the transition from shear-driven turbulence to convective
  turbulence in a vertical heated pipe",2025-01-14T14:58:44Z,"Shijun Chu, Elena Marensi, Ashley P. Willis","Heated pipe flow is widely used in thermal engineering applications, but the
presence of buoyancy force can cause intermittency, or multiple flow states at
the same parameter values. Such changes in the flow lead to substantial changes
in its heat transfer properties and thereby significant changes in the axial
temperature gradient. We therefore introduce a model that features a
time-dependent background axial temperature gradient, and consider two
temperature boundary conditions -- fixed temperature difference and fixed
boundary heat flux. Direct numerical simulations (DNS) are based on the
pseudo-spectral framework, and good agreement is achieved between present
numerical results and experimental results. The code extends openpipeflow.org
and is available at the website. The effect of the axially periodic domain on
flow dynamics and heat transfer is examined, using pipes of length L=5D and
L=25D. Provided that the flow is fully turbulent, results show close agreement
for the mean flow and temperature profiles, and only slight differences in
root-mean-square fluctuations. When the flow shows spatial intermittency, heat
transfer tends to be overestimated using a short pipe, as shear turbulence
fills the domain. This is particularly important when shear turbulence starts
to be suppressed at intermediate buoyancy numbers. Finally, at such
intermediate buoyancy numbers, we confirm that the decay of localised shear
turbulence in the heated pipe flow follows a memoryless process, similar to
that in isothermal flow. While isothermal flow then laminarises, convective
turbulence in the heated flow can intermittently trigger bursts of shear-like
turbulence.",http://arxiv.org/abs/2501.08176v1
"Observation of discontinuities in the periodic modulation of PSR
  B1828-11",2025-01-16T20:50:00Z,"Adriana Dias, Gregory Ashton, Julianna Ostrovska, David Ian Jones, Michael Keith","PSR B1828-11 is a radio pulsar that undergoes periodic modulations (~500
days) of its spin-down rate and beam width, providing a valuable opportunity to
understand the rotational dynamics of neutron stars. The periodic modulations
have previously been attributed to planetary companion(s), precession, or
magnetospheric effects and have several interesting features: they persist over
10 cycles, there are at least two harmonically related components, and the
period is decreasing at a rate of about 5 days per cycle. PSR B1828-11 also
experienced a glitch, a sudden increase in its rotation frequency, at 55 040.9
Modified Julian Day(MJD). By studying the interaction of the periodic
modulations with the glitch, we seek to find evidence to distinguish
explanations of the periodic modulation. Using a phenomenological model, we
analyse a recently published open data set from Jodrell Bank Observatory,
providing the longest and highest resolution measurements of the pulsar's
spin-down rate data. Our phenomenological model consists of step changes in the
amplitude, modulation frequency, and phase of the long-term periodic modulation
and the usual spin-down glitch behaviour. We find clear evidence with a
(natural-log) Bayes factor of 1486 to support that not only is there a change
to these three separate parameters but that the shifts occur before the glitch.
Finally, we also present model-independent evidence which demonstrates visually
how and when the modulation period and amplitude change. Discontinuities in the
modulation period are difficult to explain if a planetary companion sources the
periodic modulations, but we conclude with a discussion on the insights into
precession and magnetospheric switching.",http://arxiv.org/abs/2501.09834v1
X-Dyna: Expressive Dynamic Human Image Animation,2025-01-17T08:10:53Z,"Di Chang, Hongyi Xu, You Xie, Yipeng Gao, Zhengfei Kuang, Shengqu Cai, Chenxu Zhang, Guoxian Song, Chao Wang, Yichun Shi, Zeyuan Chen, Shijie Zhou, Linjie Luo, Gordon Wetzstein, Mohammad Soleymani","We introduce X-Dyna, a novel zero-shot, diffusion-based pipeline for
animating a single human image using facial expressions and body movements
derived from a driving video, that generates realistic, context-aware dynamics
for both the subject and the surrounding environment. Building on prior
approaches centered on human pose control, X-Dyna addresses key shortcomings
causing the loss of dynamic details, enhancing the lifelike qualities of human
video animations. At the core of our approach is the Dynamics-Adapter, a
lightweight module that effectively integrates reference appearance context
into the spatial attentions of the diffusion backbone while preserving the
capacity of motion modules in synthesizing fluid and intricate dynamic details.
Beyond body pose control, we connect a local control module with our model to
capture identity-disentangled facial expressions, facilitating accurate
expression transfer for enhanced realism in animated scenes. Together, these
components form a unified framework capable of learning physical human motion
and natural scene dynamics from a diverse blend of human and scene videos.
Comprehensive qualitative and quantitative evaluations demonstrate that X-Dyna
outperforms state-of-the-art methods, creating highly lifelike and expressive
animations. The code is available at https://github.com/bytedance/X-Dyna.",http://arxiv.org/abs/2501.10021v2
"Dynamic Continual Learning: Harnessing Parameter Uncertainty for
  Improved Network Adaptation",2025-01-18T19:58:53Z,"Christopher Angelini, Nidhal Bouaynaya","When fine-tuning Deep Neural Networks (DNNs) to new data, DNNs are prone to
overwriting network parameters required for task-specific functionality on
previously learned tasks, resulting in a loss of performance on those tasks. We
propose using parameter-based uncertainty to determine which parameters are
relevant to a network's learned function and regularize training to prevent
change in these important parameters. We approach this regularization in two
ways: (1), we constrain critical parameters from significant changes by
associating more critical parameters with lower learning rates, thereby
limiting alterations in those parameters; (2), important parameters are
restricted from change by imposing a higher regularization weighting, causing
parameters to revert to their states prior to the learning of subsequent tasks.
We leverage a Bayesian Moment Propagation framework which learns network
parameters concurrently with their associated uncertainties while allowing each
parameter to contribute uncertainty to the network's predictive distribution,
avoiding the pitfalls of existing sampling-based methods. The proposed approach
is evaluated for common sequential benchmark datasets and compared to existing
published approaches from the Continual Learning community. Ultimately, we show
improved Continual Learning performance for Average Test Accuracy and Backward
Transfer metrics compared to sampling-based methods and other
non-uncertainty-based approaches.",http://arxiv.org/abs/2501.10861v1
Imaging signatures of edge currents in a magnetic topological insulator,2025-01-20T18:48:02Z,"G. M. Ferguson, Run Xiao, Anthony R. Richardella, Austin Kaczmarek, Nitin Samarth, Katja C. Nowack","Magnetic topological insulators (MTIs) host topologically protected edge
states, but the role that these edge states play in electronic transport
remains unclear. Using scanning superconducting quantum interference device
(SQUID) microscopy, we performed local measurements of the current distribution
in a quantum anomalous Hall (QAH) insulator at large bias currents, where the
quantization of the conductivity tensor breaks down. We find that bulk currents
in the channel interior coexist with edge currents at the sample boundary.
While the position of the edge current changes with the reversal of the
magnetic field, it does not depend on the current direction. To understand our
observations, we introduce a model which includes contributions from both the
sample magnetization and currents driven by chemical potential gradients. To
parameterize our model, we use local measurements of the chemical potential
induced changes in the sample magnetization. Our model reveals that the
observed edge currents can be understood as changes in the magnetization
generated by the electrochemical potential distribution in the sample under
bias. Our work underscores the complexity of electronic transport in MTIs and
highlights both the value and challenges of using magnetic imaging to
disentangle various contributions to the electronic transport signatures.",http://arxiv.org/abs/2501.11666v1
"A One Dimensional (1D) Computational Fluid Dynamics Study of
  Fontan-Associated Liver Disease (FALD)",2025-01-06T15:36:26Z,"Yaqi Li, Charles Puelz, Mette S. Olufsen, Alyssa Taylor-LaPole","Fontan-Associated Liver Disease (FALD) is a disorder arising from hemodynamic
changes and venous congestion in the liver. This disease is prominent in
patients with hypoplastic left heart syndrome (HLHS). Although HLHS patients
typically survive into adulthood, they have reduced cardiac output due to their
univentricular physiology (i.e., a Fontan circuit). As a result, they have
insufficient blood delivery to the liver. In comparison, patients with double
outlet right ventricle (DORV), also having a univentricular circuit, have lower
incidence of FALD. In this study, we use a patient-specific, one-dimensional
computational fluid dynamics (1D-CFD) model to predict hemodynamics in the
liver of an HLHS patient and compare predictions with an age- and size-matched
DORV control patient. Additionally, we simulate FALD conditions in the HLHS
patient to predict hemodynamic changes across various stages of disease
progression. Our results show that the HLHS patient has a higher portal venous
pressure compared to the DORV patient. This difference is exacerbated as FALD
conditions progress. The wall shear stress (WSS) is also higher than normal for
the HLHS patient, suggesting vascular remodeling. WSS decreases slightly under
FALD conditions, consistent with the development of portal hypertension.
Perfusion analysis gives insight into regions of liver tissue at risk for
fibrosis development, showing increasing pressures and reduced flow throughout
the liver tissue fed by the portal vein under FALD conditions. Our results
provide insight into the specific hemodynamic changes in Fontan circulation
that can cause FALD.",http://arxiv.org/abs/2501.12396v1
"Structural and optical changes induced by incorporation of antimony into
  InAs/GaAs(001) quantum dots",2025-01-23T07:46:25Z,"A. G. Taboada, A. M. Sánchez, A. M. Beltrán, M. Bozkurt, D. Alonso-Álvarez, B. Alén, A. Rivera, J. M. Ripalda, J. M. Llorens, J. Martín-Sánchez, Y. González, J. M. Ulloa, J. M. García, S. I. Molina, P. M. Koenraad","We present experimental evidence of Sb incorporation inside InAs/GaA(001)
quantum dots exposed to an antimony flux immediately before capping with GaAs.
The Sb composition profile inside the nanostructures as measured by
cross-sectional scanning tunneling and electron transmission microscopies show
two differentiated regions within the quantum dots, with an Sb rich alloy at
the tip of the quantum dots. Atomic force microscopy and transmission electron
microscopy micrographs show increased quantum-dot height with Sb flux exposure.
The evolution of the reflection high-energy electron-diffraction pattern
suggests that the increased height is due to changes in the quantum-dot capping
process related to the presence of segregated Sb atoms. These structural and
compositional changes result in a shift of the room-temperature
photoluminescence emission from 1.26 to 1.36 microns accompanied by an order of
magnitude increase in the room-temperature quantum-dot luminescence intensity.",http://arxiv.org/abs/2501.13437v1
A Micromechanical Model for Light-interactive Molecular Crystals,2025-01-24T23:18:11Z,"Devesh Tiwari, Ananya Renuka Balakrishna","Molecular crystals respond to a light stimulus by bending, twisting, rolling,
jumping, or other kinematic behaviors. These behaviors are known to be affected
by, among others, the intensity of the incident light, the aspect ratios of
crystal geometries, and the volume changes accompanying phase transformation.
While these factors, individually, explain the increase in internal energy of
the system and its subsequent minimization through macroscopic deformation,
they do not fully explain the diversity of deformations observed in molecular
crystals. Here, we propose a micromechanical model based on the Cauchy-Born
rule and photoreaction theory to predict the macroscopic response in molecular
crystals. By accounting for lattice geometry changes and microstructural
patterns that emerge during phase transformation, we predict a range of
deformations in a representative molecular crystal (salicylideneamine). Doing
so, we find that the interplay between photoexcited states and the energy
minimization pathways, across a multi-well energy landscape, is crucial to the
bending and twisting deformations. We use our model to analyze the role of
particle geometries and the intensity of incident light on macroscopic
deformation, and identify geometric regimes for shearing and twisting
deformations in salicylideneamine crystals. Our micromechanical model is
general and can be adapted to predict photomechanical deformation in other
molecular crystals undergoing a solid-to-solid phase change and has potential
as a computational design tool to engineer reversible and controllable
actuation in molecular crystals.",http://arxiv.org/abs/2501.14975v1
"Code Change Intention, Development Artifact and History Vulnerability:
  Putting Them Together for Vulnerability Fix Detection by LLM",2025-01-24T23:40:03Z,"Xu Yang, Wenhan Zhu, Michael Pacheco, Jiayuan Zhou, Shaowei Wang, Xing Hu, Kui Liu","Detecting vulnerability fix commits in open-source software is crucial for
maintaining software security. To help OSS identify vulnerability fix commits,
several automated approaches are developed. However, existing approaches like
VulFixMiner and CoLeFunDa, focus solely on code changes, neglecting essential
context from development artifacts. Tools like Vulcurator, which integrates
issue reports, fail to leverage semantic associations between different
development artifacts (e.g., pull requests and history vulnerability fixes).
Moreover, they miss vulnerability fixes in tangled commits and lack
explanations, limiting practical use. Hence to address those limitations, we
propose LLM4VFD, a novel framework that leverages Large Language Models (LLMs)
enhanced with Chain-of-Thought reasoning and In-Context Learning to improve the
accuracy of vulnerability fix detection. LLM4VFD comprises three components:
(1) Code Change Intention, which analyzes commit summaries, purposes, and
implications using Chain-of-Thought reasoning; (2) Development Artifact, which
incorporates context from related issue reports and pull requests; (3)
Historical Vulnerability, which retrieves similar past vulnerability fixes to
enrich context. More importantly, on top of the prediction, LLM4VFD also
provides a detailed analysis and explanation to help security experts
understand the rationale behind the decision. We evaluated LLM4VFD against
state-of-the-art techniques, including Pre-trained Language Model-based
approaches and vanilla LLMs, using a newly collected dataset, BigVulFixes.
Experimental results demonstrate that LLM4VFD significantly outperforms the
best-performed existing approach by 68.1%--145.4%. Furthermore, We conducted a
user study with security experts, showing that the analysis generated by
LLM4VFD improves the efficiency of vulnerability fix identification.",http://arxiv.org/abs/2501.14983v1
"Large Language Model Critics for Execution-Free Evaluation of Code
  Changes",2025-01-28T02:38:56Z,"Aashish Yadavally, Hoan Nguyen, Laurent Callot, Gauthier Guinet","Large language models (LLMs) offer a promising way forward for automating
software engineering tasks, such as bug fixes, feature additions, etc., via
multi-step LLM-based agentic workflows. However, existing metrics for
evaluating such workflows, mainly build status and occasionally log analysis,
are too sparse and limited in providing the information needed to assess the
quality of changes made. In this work, we designed LLM-based critics to derive
well-structured and rigorous intermediate/step-level, execution-free evaluation
proxies for repo-level code changes. Importantly, we assume access to the gold
test patch for the problem (i.e., reference-aware) to assess both semantics and
executability of generated patches. With the gold test patch as a reference, we
predict executability of all editing locations with an F1 score of 91.6%,
aggregating which, we can predict the build status in 84.8% of the instances in
SWE-bench. In particular, such an execution-focused LLM critic outperforms
other reference-free and reference-aware LLM critics by 38.9% to 72.5%.
Moreover, we demonstrate the usefulness of such a reference-aware framework in
comparing patches generated by different agentic workflows. Finally, we
open-source the library developed for this project, which allows further usage
for either other agentic workflows or other benchmarks. The source code is
available at https://github.com/amazon-science/code-agent-eval.",http://arxiv.org/abs/2501.16655v1
"AlphaAdam:Asynchronous Masked Optimization with Dynamic Alpha for
  Selective Updates",2025-01-30T02:10:23Z,"Da Chang, Yu Li, Ganzhao Yuan","In the training of large language models (LLMs), updating parameters more
efficiently and stably has always been an important challenge. To achieve
efficient parameter updates, existing methods usually achieve performance
comparable to full parameter updates through methods such as low-dimensional
decomposition or layer-wise selective updates. In this work, we propose
AlphaAdam, an optimization framework for LLM from the perspective of
intra-layer parameter updates. By decoupling parameter updates and dynamically
adjusting their strength, AlphaAdam accelerates convergence and improves
training stability. We construct parameter masks based on the consistency of
historical momentum and gradient direction and combine them with an adaptive
mask strength strategy to ensure efficient optimization and theoretical
convergence guarantees, which is also applicable to most momentum-based
optimizers. Extensive experiments show that AlphaAdam outperforms
state-of-the-art methods such as AdamW in terms of convergence speed and
computational efficiency across tasks, including GPT-2 pre-trained and
fine-tuned RoBERTa and Llama-7B. Our AlphaAdam implements an optimizer
enhancement framework for LLMs through intra-layer asynchronous masked adaptive
updates. Our code is available in this https://github.com/MaeChd/AlphaAdam.",http://arxiv.org/abs/2501.18094v2
What is causal about causal models and representations?,2025-01-31T17:35:21Z,"Frederik Hytting Jørgensen, Luigi Gresele, Sebastian Weichwald","Causal Bayesian networks are 'causal' models since they make predictions
about interventional distributions. To connect such causal model predictions to
real-world outcomes, we must determine which actions in the world correspond to
which interventions in the model. For example, to interpret an action as an
intervention on a treatment variable, the action will presumably have to a)
change the distribution of treatment in a way that corresponds to the
intervention, and b) not change other aspects, such as how the outcome depends
on the treatment; while the marginal distributions of some variables may change
as an effect. We introduce a formal framework to make such requirements for
different interpretations of actions as interventions precise. We prove that
the seemingly natural interpretation of actions as interventions is circular:
Under this interpretation, every causal Bayesian network that correctly models
the observational distribution is trivially also interventionally valid, and no
action yields empirical data that could possibly falsify such a model. We prove
an impossibility result: No interpretation exists that is non-circular and
simultaneously satisfies a set of natural desiderata. Instead, we examine
non-circular interpretations that may violate some desiderata and show how this
may in turn enable the falsification of causal models. By rigorously examining
how a causal Bayesian network could be a 'causal' model of the world instead of
merely a mathematical object, our formal framework contributes to the
conceptual foundations of causal representation learning, causal discovery, and
causal abstraction, while also highlighting some limitations of existing
approaches.",http://arxiv.org/abs/2501.19335v2
"VLA-Cache: Towards Efficient Vision-Language-Action Model via Adaptive
  Token Caching in Robotic Manipulation",2025-02-04T09:48:14Z,"Siyu Xu, Yunke Wang, Chenghao Xia, Dihao Zhu, Tao Huang, Chang Xu","Vision-Language-Action (VLA) model can process instructions and visual
perception to directly generate actions as output in an end-to-end fashion due
to its strong multi-modal reasoning capabilities. While the performance of VLA
models is promising, their computational cost can be substantial. This raises
challenge for applying them on robotics tasks, which requires real-time
decision-making to respond quickly to environmental changes. Since robotic
control involves sequential decision-making, the visual input often exhibits
minimal variation between successive steps. A natural idea is to reuse the
computational results of unchanged visual tokens from the last step. Motivated
by this idea, we propose VLA-Cache, an efficient vision-language-action model.
VLA-Cache incorporates a token-selection mechanism that compares the visual
input at each step with the input from the previous step, adaptively
identifying visual tokens with minimal changes. The computational results for
these unchanged tokens are then reused in subsequent steps via KV-cache,
thereby significantly improving the efficiency of the VLA-Cache model.
Experimental results on both simulation (e.g., LIBERO benchmark and SIMPLER)
and real-world robot valid VLA-Cache can achieve practical acceleration with
minimal sacrifice in success rate.",http://arxiv.org/abs/2502.02175v1
"Adaptive Resource Allocation Optimization Using Large Language Models in
  Dynamic Wireless Environments",2025-02-04T12:56:59Z,"Hyeonho Noh, Byonghyo Shim, Hyun Jong Yang","Deep learning (DL) has made notable progress in addressing complex radio
access network control challenges that conventional analytic methods have
struggled to solve. However, DL has shown limitations in solving constrained
NP-hard problems often encountered in network optimization, such as those
involving quality of service (QoS) or discrete variables like user indices.
Current solutions rely on domain-specific architectures or heuristic
techniques, and a general DL approach for constrained optimization remains
undeveloped. Moreover, even minor changes in communication objectives demand
time-consuming retraining, limiting their adaptability to dynamic environments
where task objectives, constraints, environmental factors, and communication
scenarios frequently change. To address these challenges, we propose a large
language model for resource allocation optimizer (LLM-RAO), a novel approach
that harnesses the capabilities of LLMs to address the complex resource
allocation problem while adhering to QoS constraints. By employing a
prompt-based tuning strategy to flexibly convey ever-changing task descriptions
and requirements to the LLM, LLM-RAO demonstrates robust performance and
seamless adaptability in dynamic environments without requiring extensive
retraining. Simulation results reveal that LLM-RAO achieves up to a 40%
performance enhancement compared to conventional DL methods and up to an $80$\%
improvement over analytical approaches. Moreover, in scenarios with fluctuating
communication objectives, LLM-RAO attains up to 2.9 times the performance of
traditional DL-based networks.",http://arxiv.org/abs/2502.02287v1
"On the Convergence of Strong Cylindrical and Spherical Shock Waves in
  Solid Materials",2025-02-02T15:35:36Z,R. K. Anand,"In this article, we present a description of the behaviour of
shock-compressed solid materials following the Geometrical Shock Dynamics (GSD)
theory. GSD has been successfully applied to various gas dynamics problems, and
here we have employed it to investigate the propagation of cylindrically and
spherically symmetric converging shock waves in solid materials. The analytical
solution of shock dynamics equations has been obtained in strong-shock limit,
assuming the solid material to be homogeneous and isotropic and obeying the
Mie-Gruneisen equation of state. The non-dimensional expressions are obtained
for the velocity of shock, the pressure, the mass density, the particle
velocity, the temperature, the speed of sound, the adiabatic bulk modulus, and
the change-in-entropy behind the strong converging shock front. The influences
as a result of changes in (i) the propagation distance r from the axis or
centre (r=0) of convergence, (ii) the Gruneisen parameter, and (iii) the
material parameter are explored on the shock velocity and the domain behind the
converging shock front. The results show that as the shock focuses at the axis
or origin, the shock velocity, the pressure, the temperature, and the
change-in-entropy increase in the shock-compressed titanium Ti6Al4V, stainless
steel 304, aluminum 6061-T6, etc.",http://arxiv.org/abs/2502.02609v1
Photoluminescence Features of Few-Layer Hexagonal $α$-In$_2$Se$_3$,2025-02-06T11:25:00Z,"I. A. Eliseyev, A. I. Veretennikov, A. I. Galimov, L. V. Kotova, G. V. Osochenko, K. A. Gasnikova, D. A. Kirilenko, M. A. Yagovkina, Yu. A. Salii, V. Yu. Davydov, P. A. Alekseev, M. V. Rakhlin","Indium (III) selenide is currently one of the most actively studied materials
in the two-dimensional family due to its remarkable ferroelectric and optical
properties. This study focuses on the luminescent properties of few-layer
In$_2$Se$_3$ flakes with thicknesses ranging from 7 to 100 monolayers. To
explore the photoluminescence features and correlate them with changes in
crystal symmetry and surface potential, we employed a combination of
techniques, including temperature-dependent micro-photoluminescence,
time-resolved photoluminescence, Raman spectroscopy, atomic force microscopy,
and Kelvin probe force microscopy. X-ray diffraction and Raman spectroscopy
confirmed that the samples studied possess the $\alpha$-polytype structure. The
micro-photoluminescence spectrum consists of two bands, A and B, with band B
almost completely disappearing at room temperature. Temperature-dependent
photoluminescence and time-resolved measurements helped us to elucidate the
nature of the observed bands. We find that peak A is associated with emission
from interband transitions in In$_2$Se$_3$, while peak B is attributed to
defect-related emission. Additionally, the photoluminescence decay times of
In$_2$Se$_3$ flakes with varying thicknesses were determined. No significant
changes were observed in the decay components as the thickness increased from 7
to 100 monolayers, suggesting that there are no qualitative changes in the band
structure.",http://arxiv.org/abs/2502.03981v1
"Maximizing nanoparticle light absorption: size, geometry, and a prospect
  for metal alloys",2025-02-06T12:49:51Z,"Matej Bubaš, Jordi Sancho-Parramon","In this work we show how to maximize absorption of plasmonic nanoparticles in
terms of size, geometry and material. For that reason the interaction of
nanoparticles with light was decomposed into different effects. We determined
that the main effect dictating the optimal amount of optical losses is
radiation damping, and how it depends on nanoparticle size and geometry. Based
on this, we find that for many combinations of sizes and geometries losses in
pure metals are far from optimal. To overcome the aforementioned issue,
alloying is presented as straightforward and flexible way of modulating the
optical losses. Furthermore, strategies for tuning the optical losses to values
above, between, and even below those in pure plasmonic metals are developed in
terms of selecting the right alloy composition. In some cases, alloys showed a
multifold increase in absorption when compared to pure plasmonic metals. The
physical reasons governing such changes are elucidated based on the electronic
structure changes during alloying of different metals, which enables
generalization of the results to other systems. Besides increasing absorption,
electronic structure changes can also be utilized for channeling the absorbed
energy to suit different purposes, such as hot carrier generation for
photocatalysis or solar energy harvesting. Overall, these results establish
alloying as a powerful tool for designing nanostructures for applications that
utilize light absorption.",http://arxiv.org/abs/2502.04032v1
"AgilePilot: DRL-Based Drone Agent for Real-Time Motion Planning in
  Dynamic Environments by Leveraging Object Detection",2025-02-10T17:54:30Z,"Roohan Ahmed Khan, Valerii Serpiva, Demetros Aschalew, Aleksey Fedoseev, Dzmitry Tsetserukou","Autonomous drone navigation in dynamic environments remains a critical
challenge, especially when dealing with unpredictable scenarios including
fast-moving objects with rapidly changing goal positions. While traditional
planners and classical optimisation methods have been extensively used to
address this dynamic problem, they often face real-time, unpredictable changes
that ultimately leads to sub-optimal performance in terms of adaptiveness and
real-time decision making. In this work, we propose a novel motion planner,
AgilePilot, based on Deep Reinforcement Learning (DRL) that is trained in
dynamic conditions, coupled with real-time Computer Vision (CV) for object
detections during flight. The training-to-deployment framework bridges the
Sim2Real gap, leveraging sophisticated reward structures that promotes both
safety and agility depending upon environment conditions. The system can
rapidly adapt to changing environments, while achieving a maximum speed of 3.0
m/s in real-world scenarios. In comparison, our approach outperforms classical
algorithms such as Artificial Potential Field (APF) based motion planner by 3
times, both in performance and tracking accuracy of dynamic targets by using
velocity predictions while exhibiting 90% success rate in 75 conducted
experiments. This work highlights the effectiveness of DRL in tackling
real-time dynamic navigation challenges, offering intelligent safety and
agility.",http://arxiv.org/abs/2502.06725v1
"Flip-flop QPO changes during state transitions: a case study of GX339-4
  and theoretical discussion",2025-02-12T19:00:06Z,"D. J. K. Buisson, G. Marcel, V. López-Barquero, S. E. Motta, S. G. D. Turner, F. M. Vincentelli","We analyse the 2021 outburst from the black hole X-ray binary GX339-4
observed by NICER around the hard to soft transition, when the system exhibits
flip-flops between two distinct luminosity states: a bright state with a 5-6 Hz
quasi-periodic oscillation (QPO) and a dim state showing only strong broadband
noise. Despite the marked differences in variability patterns between these
states, the spectral energy distributions remain strikingly similar, with only
minor changes in the black body component in the soft X-ray range. We find that
the QPO frequency correlates with the X-ray count rates and hardness,
suggesting a tight coupling between the QPO mechanism and the accretion disc's
spectral properties. Additionally, we demonstrate that flip-flops can occur on
very short timescales, with almost 50 state changes within ~1200 s, while both
states can also remain stable over longer periods (at least 1000 s). We explore
various QPO models to explain these observations, including the possibility
that the corona's accretion speed is near the sound speed, affecting the
presence of QPOs. However, the exact mechanism driving the flip-flops and the
QPOs remains unclear. Our findings emphasize the complexity of these phenomena
and the necessity for further theoretical and observational studies to unravel
the intricacies of QPO and flip-flop behaviours in X-ray binaries.",http://arxiv.org/abs/2502.08718v1
"Pace in Concert with Phase: Rate-induced Phase-tipping in Birhythmic
  Oscillators",2025-02-13T11:27:57Z,"Ravi Kumar K, Hassan Alkhayuon, Sebastian Wieczorek, Partha Sharathi Dutta","We study rate-induced phase-tipping (RP-tipping) between two stable limit
cycles of a birhythmic oscillator. We say that such an oscillator RP-tips when
a time variation of an input parameter preserves the bistability of the limit
cycles but induces transitions from one stable limit cycle to the other,
causing abrupt changes in the amplitude and frequency of the oscillations.
Crucially, these transitions occur when: the rate of change of the input is in
a certain interval bounded by critical rate(s), and the system is in certain
phases of the cycle.
  We focus on two illustrative examples: the birhythmic van der Pol oscillator
and the birhythmic Decroly-Goldbeter glycolysis model, each subjected to
monotone and non-monotone shifts in their input parameters. We explain
RP-tipping in terms of properties of the autonomous frozen system, including
the phase of a cycle and partial basin instability along the parameter path
traced by the changing input. We show that RP-tipping can occur as an
irreversible one-way transition or as a series of transitions between the
stable limit cycles. Finally, we present RP-tipping diagrams showing
combinations of the rate and magnitude of parameter shifts and the phase of the
oscillation that give rise to this genuine non-autonomous instability.",http://arxiv.org/abs/2502.09190v1
Merging public elementary schools to reduce racial/ethnic segregation,2025-02-14T14:36:28Z,"Madison Landry, Nabeel Gillani","Diverse schools can help address implicit biases and increase empathy, mutual
respect, and reflective thought by fostering connections between students from
different racial/ethnic, socioeconomic, and other backgrounds. Unfortunately,
demographic segregation remains rampant in US public schools, despite over 70
years since the passing of federal legislation formally outlawing segregation
by race. However, changing how students are assigned to schools can help foster
more integrated learning environments. In this paper, we explore ""school
mergers"" as one such under-explored, yet promising, student assignment policy
change. School mergers involve merging the school attendance boundaries, or
catchment areas, of schools and subsequently changing the grades each school
offers. We develop an algorithm to simulate elementary school mergers across
200 large school districts serving 4.5 million elementary school students and
find that pairing or tripling schools in this way could reduce racial/ethnic
segregation by a median relative 20% -- and as much as nearly 60% in some
districts -- while increasing driving times to schools by an average of a few
minutes each way. Districts with many interfaces between
racially/ethnically-disparate neighborhoods tend to be prime candidates for
mergers. We also compare the expected results of school mergers to other
typical integration policies, like redistricting, and find that different
policies may be more or less suitable in different places. Finally, we make our
results available through a public dashboard for policymakers and community
members to explore further (https://mergers.schooldiversity.org). Together, our
study offers new findings and tools to support integration policy-making across
US public school districts.",http://arxiv.org/abs/2502.10193v1
"Investigation of the Estimation Accuracy of 5 Different Numerical ODE
  Solvers on 3 Case Studies",2025-02-14T16:51:01Z,"Hamidreza Moradi, Erfan Kefayat, Hamideh Hossei","Numerical ordinary differential equation (ODE) solvers are indispensable
tools in various engineering domains, enabling the simulation and analysis of
dynamic systems. In this work, we utilize 5 different numerical ODE solvers
namely: Euler's method, Heun's method, Midpoint Method, Runge-kutta 4th order
and ODE45 method in order to discover the answer of three wellknown case
studies and compare their results by calculation of relative errors. To check
for the validity of the estimations, the experimental data of previous
literature have been compared with the data in this paper which shows a good
accordance. We observe that for each of the case studies based on the behavior
of the model, the estimation accuracy of the solvers is different. For the
logistic population change as the first case study, the results of all solvers
are so close to each other that only their solution cost can be considered for
their superiority. For temperature change of a building as the second case
study we see that in some especial areas the accuracy of the solvers is
different and in general Midpoint ODE solver shows better results. As the last
case study, market equilibrium price shows that none of the numerical ODE
solvers can estimate its behavior which is due to its sudden changing nature.",http://arxiv.org/abs/2502.10289v1
"Bayesian inference from time series of allele frequency data using exact
  simulation techniques",2025-02-17T19:28:15Z,"Jaromir Sant, Paul A. Jenkins, Jere Koskela, Dario Spano","A central statistical problem in population genetics is to infer evolutionary
and biological parameters such as the strength of natural selection and allele
age from DNA samples extracted from a contemporary population. That all samples
come only from the present-day has long been known to limit statistical
inference; there is potentially more information available if one also has
access to ancient DNA so that inference is based on a time-series of historical
changes in allele frequencies. We introduce a Markov Chain Monte Carlo (MCMC)
method for Bayesian inference from allele frequency time-series data based on
an underlying Wright--Fisher diffusion model of evolution, through which one
can infer the parameters of essentially any selection model including those
with frequency-dependent effects. The chief novelty is that we show this method
to be exact in the sense that it is possible to augment the state space
explored by MCMC with the unobserved diffusion trajectory, even though the
transition function of this diffusion is intractable. Through careful design of
a proposal distribution, we describe an efficient method in which updates to
the trajectory and accept/reject decisions are calculated without error. We
illustrate the method on data capturing changes in coat colour over the past
20,000 years, and find evidence to support previous findings that the mutant
alleles ASIP and MC1R responsible for changes in coat color have experienced
very strong, possibly overdominant, selection and further provide estimates for
the ages of these genes.",http://arxiv.org/abs/2502.12279v1
The Non-Relativistic Limit of Keldysh Spinors,2025-01-08T14:04:39Z,A. Jourjine,"Keldysh spinors obey Dirac equation, but have the negative of the Dirac
action and Hamiltonian. In an example of the U(1) EM coupling, we show that,
despite the sign changes, they have a well-defined non-relativistic limit
resulting in quantum mechanics with the positive-definite Pauli Hamiltonian.
When non-relativistic Dirac and Keldysh fields are brought to interact, we
observe curious decoupling of the two fields in mass-like and vector couplings.",http://arxiv.org/abs/2501.04514v1
"Modeling the impact of hospitalization-induced behavioral changes on
  SARS-COV-2 spread in New York City",2025-01-12T21:35:24Z,"Alice Oveson, Michelle Girvan, Abba Gumel","A novel behavior-epidemiology model, which considers $n$ heterogeneous
behavioral groups based on level of risk tolerance and distinguishes behavioral
changes by social and disease-related motivations (such as peer-influence and
fear of disease-related hospitalizations), is developed. In addition to
rigorously analyzing the basic qualitative features of this model, a special
case is considered where the total population is stratified into two groups:
risk-averse (Group 1) and risk-tolerant (Group 2). The two-group behavior model
has three disease-free equilibria in the absence of disease, and their
stability is analyzed using standard linearization and the properties of
Metzler-stable matrices. Furthermore, the two-group model was calibrated and
validated using daily hospitalization data for New York City during the first
wave, and the calibrated model was used to predict the data for the second
wave. Numerical simulations of the calibrated two-group behavior model showed
that while the dynamics of the SARS-CoV-2 pandemic during the first wave was
largely influenced by the behavior of the risk-tolerant individuals, the
dynamics during the second wave was influenced by the behavior of individuals
in both groups. It was also shown that disease-motivated behavioral changes had
greater influence in significantly reducing SARS-CoV-2 morbidity and mortality
than behavior changes due to the level of peer or social influence or pressure.
Finally, it is shown that the initial proportion of members in the community
that are risk-averse (i.e., the proportion of individuals in Group 1 at the
beginning of the pandemic) and the early and effective implementation of
non-pharmaceutical interventions have major impacts in reducing the size and
burden of the pandemic (particularly the total SARS-CoV-2 mortality in New York
City during the second wave).",http://arxiv.org/abs/2501.06941v1
Restrictions on Hilbert coefficients give depths of graded domains,2025-01-14T04:21:35Z,Cheng Meng,"In this paper, we prove that if $P$ is a homogeneous prime ideal inside a
standard graded polynomial ring $S$ with $\dim(S/P)=d$, and for $s \leq d$,
adjoining $s$ general linear forms to the prime ideal changes the $(d-s)$-th
Hilbert coefficient by 1, then $\text{depth}(S/P)=s-1$. This criterion also
tells us about possible restrictions on the generic initial ideal of a prime
ideal inside a polynomial ring.",http://arxiv.org/abs/2501.07829v1
"Two-Measure Electroweak Standard Model. Some aspects of cosmological
  evolution and vacuum stability",2025-01-26T18:09:46Z,Alexander B. Kaganovich,"In the FLRW universe, the scalar field \phi(t) obtained by cosmological
averaging of the local Higgs field H(x) is considered as a classical field for
which the SM quantization procedure is meaningless. When applying the
Two-Measure theory (TMT) to study cosmology, the ratio \zeta of the measure
densities is a scalar function, which: enters into all equations of motion.
Through the constraint, $\zeta$ is defined as a function of \phi(t). During
cosmological evolution, \zeta(\phi) changes from \zeta\approx 0 at the
inflationary stage to \zeta=1 at the approaching vacuum stage. Each stage of
the classical cosmological background is determined by the set \{\phi(t), {\rm
curvature}, \zeta(\phi(t))\}. The Two-Measure SM (TMSM) is realized in the
context of cosmology as a set of cosmologically modified copies of the GWS
model. Each of the copies exists as a local quantum field theory defined on the
classical cosmological background at the appropriate stage of its evolution.
This basic idea is studied in detail for the stage of slow-roll inflation and
for the stage of approaching vacuum. Due to the presence of \zeta(\phi(t)) in
all equations of motion, all TMSM coupling constants turn out to be running
(classical) TMT-effective parameters. During cosmological evolution, changing
these parameters yields new results: the classical running TMT-effective Higgs
selfcoupling increases from \lambda\sim 10^{-11} (which ensures consistency
with Planck's CMB data at \xi=\frac{1}{6}) to \lambda\sim 0.1 near vacuum; the
mass term in the Higgs potential changes sign from positive to negative,
providing standard SSB; the classical running gauge and Yukawa coupling
constants change by several orders of magnitude; the GWS theory is reproduced
so that the fermion mass hierarchy is obtained quite naturally. 1-loop quantum
corrections preserves the slow-roll inflation and does not violate the vacuum
stability.",http://arxiv.org/abs/2501.15623v2
Ideal of the variety of flexes of plane cubics,2025-02-03T17:16:36Z,Vladimir L. Popov,"We prove that the variety of flexes of algebraic curves of degree $3$ in the
projective plane is an ideal theoretic complete intersection in the product of
a two-dimensional and a nine-dimensional projective spaces.",http://arxiv.org/abs/2502.01539v2
Dimer problem on a spherical surface,2025-02-10T17:54:11Z,"A. Tononi, D. S. Petrov, M. Lewenstein","We solve the problem of a dimer moving on a spherical surface and find that
its binding energy and wave function are sensitive to the total angular
momentum. The dimer gets squeezed in the direction orthogonal to the
center-of-mass motion and can qualitatively change its geometry from
two-dimensional to one-dimensional.",http://arxiv.org/abs/2502.06724v1
"Hypercubic Decomposition of Verma Supermodules and Semibricks Realizing
  the Khovanov Algebra of Defect One",2025-02-16T04:15:25Z,Shunsuke Hirota,"We study some variants of Verma modules of basic Lie superalgebras obtained
via changing Borel subalgebras. These allow us to demonstrate that the
principal block of \(\mathfrak{gl}(1|1)\) is realized as (non-Serre) full
subcategories of any atypical block of BGG category \( \mathcal{O} \) of basic
Lie superalgebras.",http://arxiv.org/abs/2502.10987v2
"Identifying Bug Inducing Commits by Combining Fault Localisation and
  Code Change Histories",2025-02-18T15:02:22Z,"Gabin An, Jinsu Choi, Jingun Hong, Naryeong Kim, Shin Yoo","A Bug Inducing Commit (BIC) is a code change that introduces a bug into the
codebase. Although the abnormal or unexpected behavior caused by the bug may
not manifest immediately, it will eventually lead to program failures further
down the line. When such a program failure is observed, identifying the
relevant BIC can aid in the bug resolution process, because knowing the
original intent and context behind the code change, as well as having a link to
the author of that change, can facilitate bug triaging and debugging. However,
existing BIC identification techniques have limitations. Bisection can be
computationally expensive because it requires executing failing tests against
previous versions of the codebase. Other techniques rely on the availability of
specific post hoc artifacts, such as bug reports or bug fixes. In this paper,
we propose a technique called Fonte that aims to identify the BIC with a core
concept that a commit is more likely to be a BIC if it has more recently
modified code elements that are highly suspicious of containing the bug. To
realise this idea, Fonte leverages two fundamental relationships in software:
the failure-to-code relationship, which can be quantified through fault
localisation techniques, and the code-to-commit relationship, which can be
obtained from version control systems. Our empirical evaluation using 206
real-world BICs from open-source Java projects shows that Fonte significantly
outperforms state-of-the-art BIC identification techniques, achieving up to
45.8% higher MRR. We also report that the ranking scores produced by Fonte can
be used to perform weighted bisection. Finally, we apply Fonte to a large-scale
industry project with over 10M lines of code, and show that it can rank the
actual BIC within the top five commits for 87% of the studied real
batch-testing failures, and save the BIC inspection cost by 32% on average.",http://arxiv.org/abs/2502.12922v2
DMSA: A Decentralized Microservice Architecture for Edge Networks,2025-01-01T16:07:34Z,"Yuang Chen, Chengdi Lu, Yongsheng Huang, Chang Wu, Fengqian Guo, Hancheng Lu, Chang Wen Chen","The dispersed node locations and complex topologies of edge networks,
combined with intricate dynamic microservice dependencies, render traditional
centralized microservice architectures (MSAs) unsuitable. In this paper, we
propose a decentralized microservice architecture (DMSA), which delegates
scheduling functions from the control plane to edge nodes. DMSA redesigns and
implements three core modules of microservice discovery, monitoring, and
scheduling for edge networks to achieve precise awareness of instance
deployments, low monitoring overhead and measurement errors, and accurate
dynamic scheduling, respectively. Particularly, DMSA has customized a
microservice scheduling scheme that leverages multi-port listening and
zero-copy forwarding to guarantee high data forwarding efficiency. Moreover, a
dynamic weighted multi-level load balancing algorithm is proposed to adjust
scheduling dynamically with consideration of reliability, priority, and
response delay. Finally, we have implemented a physical verification platform
for DMSA. Extensive empirical results demonstrate that compared to
state-of-the-art and traditional scheduling schemes, DMSA effectively
counteracts link failures and network fluctuations, improving the service
response delay and execution success rate by approximately $60\% \sim 75\%$ and
$10\%\sim15\%$, respectively.",http://arxiv.org/abs/2501.00883v1
Aligning Netlist to Source Code using SynAlign,2025-01-01T18:40:05Z,"Sakshi Garg, Jose Renau","In current chip design processes, using multiple tools to obtain a gate-level
netlist often results in the loss of source code correlation. SynAlign
addresses this challenge by automating the alignment process, simplifying
iterative design, reducing overhead, and maintaining correlation across various
tools. This enhances the efficiency and effectiveness of chip design workflows.
  Improving characteristics such as frequency through iterative design is
essential for enhancing accelerators and chip designs. While synthesis tools
produce netlists with critical path information, designers often lack the tools
to trace these netlist cells back to their original source code. Mapping
netlist components to source code provides early feedback on timing and power
for frontend designers.
  SynAlign automatically aligns post-optimized netlists with the original
source code without altering compilers or synthesis processes. Its alignment
strategy relies on the consistent design structure throughout the chip design
cycle, even with changes in compiler flow. This consistency allows engineers to
maintain a correlation between modified designs and the original source code
across various tools. Remarkably, SynAlign can tolerate up to 61\% design net
changes without impacting alignment accuracy.",http://arxiv.org/abs/2501.00921v1
"FAPL-DM-BC: A Secure and Scalable FL Framework with Adaptive Privacy and
  Dynamic Masking, Blockchain, and XAI for the IoVs",2025-01-02T05:21:52Z,"Sathwik Narkedimilli, Amballa Venkata Sriram, Sujith Makam, MSVPJ Sathvik, Sai Prashanth Mallellu","The FAPL-DM-BC solution is a new FL-based privacy, security, and scalability
solution for the Internet of Vehicles (IoV). It leverages Federated Adaptive
Privacy-Aware Learning (FAPL) and Dynamic Masking (DM) to learn and adaptively
change privacy policies in response to changing data sensitivity and state in
real-time, for the optimal privacy-utility tradeoff. Secure Logging and
Verification, Blockchain-based provenance and decentralized validation, and
Cloud Microservices Secure Aggregation using FedAvg (Federated Averaging) and
Secure Multi-Party Computation (SMPC). Two-model feedback, driven by
Model-Agnostic Explainable AI (XAI), certifies local predictions and
explanations to drive it to the next level of efficiency. Combining local
feedback with world knowledge through a weighted mean computation, FAPL-DM-BC
assures federated learning that is secure, scalable, and interpretable.
Self-driving cars, traffic management, and forecasting, vehicular network
cybersecurity in real-time, and smart cities are a few possible applications of
this integrated, privacy-safe, and high-performance IoV platform.",http://arxiv.org/abs/2501.01063v1
"Self-diffusive dynamics of active Brownian particles at moderate
  densities",2025-01-02T13:31:58Z,Rodrigo Soto,"The Active Brownian Particle (ABP) model has become a prototype of
self-propelled particles. ABPs move persistently at a constant speed $V$ along
a direction that changes slowly by rotational diffusion, characterized by a
coefficient $\Dr$. Persistent motion plus random reorientations generate a
random walk at long times with a diffusion coefficient that, for isolated ABPs
in two dimensions, is given by $D_0=V^2/(2\Dr)$. Here we study the density
effects on the self-diffusive dynamics using a recently proposed kinetic theory
for ABPs, in which persistent collisions are described as producing a net
displacement on the particles. On intermediate timescales, where many
collisions have taken place but the director of the tagged particle has not yet
changed, an effective stochastic dynamics emerges, characterized by an
effective reduced streaming velocity $V_\text{eff}$ and anisotropic diffusion,
with coefficients explicitly depending on density. Based on this result, an
effective theoretical and numerical approach is proposed in which the particles
follow stochastic dynamics with mean-field interactions based on the local
density. Finally, on time scales larger than $\Dr^{-1}$, the tagged particle
shows an effective diffusive motion with a coefficient
$D=V_\text{eff}^2/(2\Dr)$. The dependence of $V_\text{eff}$ on density
indicates that the kinetic theory is limited to are fractions smaller than
0.42, and beyond this limit unphysical results appear.",http://arxiv.org/abs/2501.01251v1
"Automating Legal Concept Interpretation with LLMs: Retrieval,
  Generation, and Evaluation",2025-01-03T10:11:38Z,"Kangcheng Luo, Quzhe Huang, Cong Jiang, Yansong Feng","Legal articles often include vague concepts for adapting to the ever-changing
society. Providing detailed interpretations of these concepts is a critical and
challenging task even for legal practitioners. It requires meticulous and
professional annotations and summarizations by legal experts, which are
admittedly time-consuming and expensive to collect at scale. By emulating legal
experts' doctrinal method, we introduce a novel framework, ATRIE, using large
language models (LLMs) to AuTomatically Retrieve concept-related information,
Interpret legal concepts, and Evaluate generated interpretations, eliminating
dependence on legal experts. ATRIE comprises a legal concept interpreter and a
legal concept interpretation evaluator. The interpreter uses LLMs to retrieve
relevant information from judicial precedents and interpret legal concepts. The
evaluator uses performance changes on legal concept entailment, a downstream
task we propose, as a proxy of interpretation quality. Automatic and
multifaceted human evaluations indicate that the quality of our interpretations
is comparable to those written by legal experts, with superior
comprehensiveness and readability. Although there remains a slight gap in
accuracy, it can already assist legal practitioners in improving the efficiency
of concept interpretation.",http://arxiv.org/abs/2501.01743v2
Kinetic Model of the Emergence of Autocatalysis,2025-01-03T13:09:44Z,"P. O. Mchedlov-Petrosyan, L. N. Davydov","We develop a formal model of the emergence of self-constructing objects (e.g.
heteropolymers with autocatalytic capability) in an open system, which don't
contain such objects initially. The objects are constructed from subunits (e.g.
monomers). Each object is characterized by the difference of self-instructed
reproduction and decomposition rate only. This difference, divided by a common
dimensional constant, is called ``productivity''. Due to external influence the
productivity of each object can randomly change. The system as a whole is
subjected to external limitation: the total number of the objects is conserved
(e.g., by the controlled influx of monomers). We consider such process as
possibly simplest example of self-organization. We obtained exact solutions of
our model for several presumed mechanisms of random change of the productivity.
We have shown that the probability to find self-constructing objects in the
system necessarily increases, even if initially it was equal to zero.",http://arxiv.org/abs/2501.01795v1
Spin-period variations in the intermediate polar RX J2133.7+5107,2025-01-03T18:38:23Z,"V. Breus, I. L. Andronov, P. Dubovsky, Y. Kim, J. N. Yoon, K. Petrik","We report the results of long-term time series photometry on RX J2133.7+5107
(also known as 1RXS J213344.1+510725) obtained at several observatories. Using
data taken during 17 years, we determined the current value of the spin period
of $570.811470$ seconds with the formal accuracy of $0.000006$ seconds and a
spin-up of the white dwarf with a characteristic time of $1.483(1)\times10^5$
years. This is even faster than that reported previously and, if confirmed,
makes this object have one of the fastest spin-up timescales of all known
intermediate polars. We derived an improved value of the superhump period of
the system to be $0^d.280130(1)$. Superhump maxima timings are moving on the
phase curve from season to season, showing non-monotonic changes, without a
change in superhump period.",http://arxiv.org/abs/2501.01940v1
"Multi-Aggregator Time-Warping Heterogeneous Graph Neural Network for
  Personalized Micro-Video Recommendation",2025-01-05T21:14:35Z,"Jinkun Han, Wei Li, Xhipeng Cai, Yingshu Li","Micro-video recommendation is attracting global attention and becoming a
popular daily service for people of all ages. Recently, Graph Neural
Networks-based micro-video recommendation has displayed performance improvement
for many kinds of recommendation tasks. However, the existing works fail to
fully consider the characteristics of micro-videos, such as the high timeliness
of news nature micro-video recommendation and sequential interactions of
frequently changed interests. In this paper, a novel Multi-aggregator
Time-warping Heterogeneous Graph Neural Network (MTHGNN) is proposed for
personalized news nature micro-video recommendation based on sequential
sessions, where characteristics of micro-videos are comprehensively studied,
users' preference is mined via multi-aggregator, the temporal and dynamic
changes of users' preference are captured, and timeliness is considered.
Through the comparison with the state-of-the-arts, the experimental results
validate the superiority of our MTHGNN model.",http://arxiv.org/abs/2501.02666v1
"IIMedGPT: Promoting Large Language Model Capabilities of Medical Tasks
  by Efficient Human Preference Alignment",2025-01-06T09:22:36Z,"Yiming Zhang, Zheng Chang, Wentao Cai, MengXing Ren, Kang Yuan, Yining Sun, Zenghui Ding","Recent researches of large language models(LLM), which is pre-trained on
massive general-purpose corpora, have achieved breakthroughs in responding
human queries. However, these methods face challenges including limited data
insufficiency to support extensive pre-training and can not align responses
with users' instructions. To address these issues, we introduce a medical
instruction dataset, CMedINS, containing six medical instructions derived from
actual medical tasks, which effectively fine-tunes LLM in conjunction with
other data. Subsequently, We launch our medical model, IIMedGPT, employing an
efficient preference alignment method, Direct preference Optimization(DPO). The
results show that our final model outperforms existing medical models in
medical dialogue.Datsets, Code and model checkpoints will be released upon
acceptance.",http://arxiv.org/abs/2501.02869v1
Operating semiconductor qubits without individual barrier gates,2025-01-06T14:21:53Z,"A. S. Ivlev, D. R. Crielaard, M. Meyer, W. I. L. Lawrie, N. W. Hendrickx, A. Sammak, G. Scappucci, C. Déprez, M. Veldhorst","Semiconductor spin qubits have emerged as a promising platform for quantum
computing, following a significant improvement in their control fidelities over
recent years. Increasing the qubit count remains challenging, beginning with
the fabrication of small features and complex fanouts. A particular challenge
has been formed by the need for individual barrier gates to control the
exchange interaction between adjacent spin qubits. Here, we propose a method to
vary two-qubit interactions without applying pulses on individual barrier gates
while also remaining insensitive to detuning noise in first order. By changing
plunger gate voltages over 300 mV we tune the exchange energy $J$ from 100 kHz
to 60 MHz. This allows us to perform two-qubit operations without changing the
barrier gate voltage. Based on these findings we conceptualize a spin qubit
architecture without individual barrier gates, simplifying the fabrication
while maintaining the control necessary for universal quantum computation.",http://arxiv.org/abs/2501.03033v1
"Environmental Policy in General Equilibrium under Market Power and Price
  Discrimination",2025-01-06T16:21:19Z,"Tengjiao Chen, Daniel H. Karney","This study constructs a novel analytical general equilibrium model to compare
environmental policies in a setting where oligopolistic energy firms engage in
third-degree price discrimination across residential consumers and industrial
firms. Closed-form solutions demonstrate the impact on prices and quantities.
The resulting welfare change is decomposed across three distortions: output,
price discrimination, and externality. This study finds that the output
distortion and price discrimination welfare effects generally move in opposite
directions under policies such as an emission tax or a two-part instrument.
Numerical analysis compares policies and finds scenarios where the output
distortion and price discrimination welfare changes fully offset and thus
leaves the net welfare gain of the externality correction. In this way,
environmental policy can be designed to mitigate output distortion welfare
concerns when firms have market power.",http://arxiv.org/abs/2501.03114v1
"Multimodal Machine Learning Can Predict Videoconference Fluidity and
  Enjoyment",2025-01-06T18:05:35Z,"Andrew Chang, Viswadruth Akkaraju, Ray McFadden Cogliano, David Poeppel, Dustin Freeman","Videoconferencing is now a frequent mode of communication in both
professional and informal settings, yet it often lacks the fluidity and
enjoyment of in-person conversation. This study leverages multimodal machine
learning to predict moments of negative experience in videoconferencing. We
sampled thousands of short clips from the RoomReader corpus, extracting audio
embeddings, facial actions, and body motion features to train models for
identifying low conversational fluidity, low enjoyment, and classifying
conversational events (backchanneling, interruption, or gap). Our best models
achieved an ROC-AUC of up to 0.87 on hold-out videoconference sessions, with
domain-general audio features proving most critical. This work demonstrates
that multimodal audio-video signals can effectively predict high-level
subjective conversational outcomes. In addition, this is a contribution to
research on videoconferencing user experience by showing that multimodal
machine learning can be used to identify rare moments of negative user
experience for further study or mitigation.",http://arxiv.org/abs/2501.03190v2
"Graph Based, Adaptive, Multi Arm, Multiple Endpoint, Two Stage Design",2025-01-06T18:16:21Z,"Cyrus Mehta, Ajoy Mukhopadhyay, Martin Posch","The graph based approach to multiple testing is an intuitive method that
enables a study team to represent clearly, through a directed graph, its
priorities for hierarchical testing of multiple hypotheses, and for propagating
the available type-1 error from rejected or dropped hypotheses to hypotheses
yet to be tested. Although originally developed for single stage non-adaptive
designs, we show how it may be extended to two-stage designs that permit early
identification of efficacious treatments, adaptive sample size re-estimation,
dropping of hypotheses, and changes in the hierarchical testing strategy at the
end of stage one. Two approaches are available for preserving the family wise
error rate in the presence of these adaptive changes; the p-value combination
method, and the conditional error rate method. In this investigation we will
present the statistical methodology underlying each approach and will compare
the operating characteristics of the two methods in a large simulation
experiment.",http://arxiv.org/abs/2501.03197v1
Analog of the Carnot engine for fluctuating diffusivity in living cells,2025-01-07T00:45:39Z,Yuichi Itto,"Recently, a formal analogy between the fluctuating diffusivity and
thermodynamics has been proposed based on phenomena of heterogeneous diffusion
observed in living cells. This not only offers the analogs of the quantity of
heat and work as well as the internal energy but also achieves that of the
Clausius inequality for the entropy concerning diffusivity fluctuations. Here,
a discussion is developed about constructing a heat-like engine in terms of the
fluctuating diffusivity. The engine constitutes two kinds of processes with the
average diffusivity or the average local temperature being kept fixed, along
which the fluctuation distribution obeys an exponential law. The efficiency of
the engine in a cycle, which quantifies how much the diffusivity change as the
analog of work can be extracted, is found to formally coincide with that of
Carnot's. During the cycle, the total change of the entropy is also shown to
vanish.",http://arxiv.org/abs/2501.03452v1
Thermal Transport Properties of Magnons on the $α$-T$_3$ Lattice,2025-01-07T18:36:11Z,"Luqman Saleem, Hasan M. Abdullah, Udo Schwingenschlogl, Aurelien Manchon","We theoretically investigate magnons on the $\alpha$-T$_3$ lattice. Atomistic
spin dynamics simulations show that next-nearest neighbor hopping and easy-axis
anisotropy stabilize ferromagnetic order in the presence of
Dzyaloshinskii-Moriya interaction. We identify one topologically trivial magnon
insulator phase and three magnon Chern insulator phases. The topologically
trivial magnon insulator phase exhibits a small but non-zero magnon thermal
Hall conductivity, while in the magnon Chern insulator phases the Chern number
of the lowest magnon band dominates the magnon thermal Hall conductivity. The
sign of the magnon thermal Hall conductivity does not change at the topological
phase boundaries, but distinct changes are observed in the magnitude.",http://arxiv.org/abs/2501.03979v1
"Exploiting Instabilities to Enable Large Shape Transformations in
  Dielectric Elastomers",2025-01-07T20:25:12Z,"Daniel Katusele, Carmel Majidi, Pradeep Sharma, Kaushik Dayal","Dielectric elastomers have significant potential for new technologies ranging
from soft robots to biomedical devices, driven by their ability to display
complex shape changes in response to electrical stimulus. However, an important
shortcoming of current realizations is that large voltages are required for
useful actuation strains. This work proposes, and demonstrates through theory
and numerical simulations, a strategy to achieve large and controlled actuation
by exploiting the electromechanical analog of the Treloar-Kearsley (TK)
instability. The key idea is to use the fact that the TK instability is a
symmetry-breaking bifurcation, which implies the existence of a symmetry-driven
constant-energy region in the energy landscape. This provides for nonlinear
soft modes with large deformations that can be accessed with very small
external stimulus, which is achieved here by applying a small in-plane electric
field. First, the bifurcation and post-bifurcation behavior of the
electromechanical TK instability are established theoretically in the idealized
setting of uniform deformation and electric field. Next, building on this, a
finite element analysis of a realistic geometry with patterned top and bottom
electrodes is applied to demonstrate large and soft shape changes driven by
small voltage differences across the electrodes.",http://arxiv.org/abs/2501.04128v1
"Modeling with quantities in calculus and physics: A conceptual framework
  of the fundamental theorem",2025-01-08T01:32:34Z,"Suzanne White Brahmia, Patrick W. Thompson","There is a substantial curricular overlap between calculus and physics, yet
introductory physics students often struggle to connect the two. We introduce a
conceptual framework for the Fundamental Theorem of Calculus (FTC) to help
unify learning across both disciplines. We propose a consistent approach to
teaching definite integrals, including shared vocabulary and symbolism, to help
students recognize how concepts like change, rate, and accumulation show up in
both calculus and physics. We argue that the typical interpretation of the FTC
in calculus, focusing on antiderivatives in closed form, doesn't align well
with how physicists use these concepts. We advocate for an additional focus on
Riemann sums and the underlying ideas of change, rate, products, and
accumulation, which are fundamental in both fields. This approach can help
students build a deeper, more integrated understanding of both mathematics and
physics quantity. By aligning learning objectives across the disciplines, we
argue that students can develop a stronger understanding of foundational
mathematical principles.",http://arxiv.org/abs/2501.04219v1
"Mathematical Modelling of Mechanotransduction via RhoA Signalling
  Pathways",2025-01-08T10:40:05Z,"Sofie Verhees, Chandrasekhar Venkataraman, Mariya Ptashnyk","We derive and simulate a mathematical model for mechanotransduction related
to the Rho GTPase signalling pathway. The model addresses the bidirectional
coupling between signalling processes and cell mechanics. A numerical method
based on bulk-surface finite elements is proposed for the approximation of the
coupled system of nonlinear reaction-diffusion equations, defined inside the
cell and on the cell membrane, and the equations of elasticity. Our simulation
results illustrate novel emergent features such as the strong dependence of the
dynamics on cell shape, a threshold-like response to changes in substrate
stiffness, and the fact that coupling mechanics and signalling can lead to the
robustness of cell deformation to larger changes in substrate stiffness,
ensuring mechanical homeostasis in agreement with experiments.",http://arxiv.org/abs/2501.04407v1
Choosing the Right Norm for Change Point Detection in Functional Data,2025-01-08T12:58:01Z,Patrick Bastian,"We consider the problem of detecting a change point in a sequence of mean
functions from a functional time series. We propose an $L^1$ norm based
methodology and establish its theoretical validity both for classical and for
relevant hypotheses. We compare the proposed method with currently available
methodology that is based on the $L^2$ and supremum norms. Additionally we
investigate the asymptotic behaviour under the alternative for all three
methods and showcase both theoretically and empirically that the $L^1$ norm
achieves the best performance in a broad range of scenarios. We also propose a
power enhancement component that improves the performance of the $L^1$ test
against sparse alternatives. Finally we apply the proposed methodology to both
synthetic and real data.",http://arxiv.org/abs/2501.04476v2
"Stability Exchange near Folds: Analysis of an end-loaded Elastica with a
  Lever Arm",2025-01-06T15:37:56Z,Siva Prasad Chakri Dhanakoti,"Numerous problems in physical sciences can be expressed as
parameter-dependent variational problems. The associated family of equilibria
may or may not exist realistically and can be determined after examining its
stability. Hence, it is crucial to determine the stability and track its
transitions. Generally, the stability characteristics of the equilibria change
near the folds in the parameter space. The direction of stability change can be
encoded through a particular projection of the solutions. In this article, we
identify such projections for variational problems characterized by fixed-free
ends, a class of problems frequently found in mechanics. Using the developed
theory, we study an Elastica subject to an end load applied through a rigid
lever arm. The examples revealed several instances of snap-back instability in
these systems. These findings may aid in enhancing the design of soft robot
arms and other innovative switching mechanisms.",http://arxiv.org/abs/2501.04729v1
"Probabilistic Skip Connections for Deterministic Uncertainty
  Quantification in Deep Neural Networks",2025-01-08T20:12:33Z,"Felix Jimenez, Matthias Katzfuss","Deterministic uncertainty quantification (UQ) in deep learning aims to
estimate uncertainty with a single pass through a network by leveraging outputs
from the network's feature extractor. Existing methods require that the feature
extractor be both sensitive and smooth, ensuring meaningful input changes
produce meaningful changes in feature vectors. Smoothness enables
generalization, while sensitivity prevents feature collapse, where distinct
inputs are mapped to identical feature vectors. To meet these requirements,
current deterministic methods often retrain networks with spectral
normalization. Instead of modifying training, we propose using measures of
neural collapse to identify an existing intermediate layer that is both
sensitive and smooth. We then fit a probabilistic model to the feature vector
of this intermediate layer, which we call a probabilistic skip connection
(PSC). Through empirical analysis, we explore the impact of spectral
normalization on neural collapse and demonstrate that PSCs can effectively
disentangle aleatoric and epistemic uncertainty. Additionally, we show that
PSCs achieve uncertainty quantification and out-of-distribution (OOD) detection
performance that matches or exceeds existing single-pass methods requiring
training modifications. By retrofitting existing models, PSCs enable
high-quality UQ and OOD capabilities without retraining.",http://arxiv.org/abs/2501.04816v1
"Magnetism and electronic dynamics in $CuCr_{2-x}Sn_xS_4$ spinels studied
  by transferred hyperfine fields at $^{119}Sn$ and muon spin rotation and
  relaxation",2025-01-09T11:08:16Z,"Elaheh Sadrollahi, Cynthia P. C. Medrano, Magno A. V. Heringer, E. M. Baggio Saitovitch, Lilian Prodan, Vladimir Tsurkan, F. Jochen Litterst","We investigated magnetization, muon spin rotation ($\mu$SR), and $^{119}Sn$
M\""{o}ssbauer spectroscopy on Sn substituted $CuCr_{2-x}Sn_xS_4$ (x=0.03 and
0.08) spinel compounds. The magnetization and $\mu$SR results reveal similar
additional low-temperature magnetic transitions around 80 K and 40 K as found
for the undoped material, indicating a magnetic ground state deviating from a
simple collinear ferromagnet. The observed changes in the M\""{o}ssbauer
hyperfine spectra are less pronounced and are discussed in view of the
different positions of the local probes $\mu^+$ and $^{119}Sn$ and their
different magnetic coupling to the magnetic Cr lattice. Above 80 K, both
$\mu$SR and M\""{o}ssbauer spectra show temperature-dependent inhomogeneous
broadening either due to structural or charge disorder and changing spin
dynamics that can be related to a precursor magnetic phase above the
well-defined static low-temperature phase.",http://arxiv.org/abs/2501.05151v1
Competition of superconducting pairing symmetries in La3Ni2O7,2025-01-09T14:10:33Z,"Han-Xiang Xu, Yue Xie, Daniel Guterding, Zhijun Wang","The recent discovery of superconductivity in the bilayer Ruddlesden-Popper
nickelate La3Ni2O7 under high pressure has generated much interest in the
superconducting pairing mechanism of nickelates. Various theoretical approaches
have been applied to the study of superconductivity in La3Ni2O7, but lead to a
number of contradicting results. We argue that different superconducting states
in La3Ni2O7 are in close competition and at the same time particularly
sensitive to the choice of interaction parameters as well as changes of the
electronic structure through pressure. Our study uses a multi-orbital Hubbard
model, incorporating all Ni 3d and O 2p states. We analyze the superconducting
pairing mechanism of La3Ni2O7 within the random phase approximation and find a
transition between d-wave and sign-changing s-wave pairing states as a function
of pressure and interaction parameters, which is driven by spin-fluctuations
with different wave vectors. Our work paves the way to understanding seemingly
contradictory theoretical results within a unified framework.",http://arxiv.org/abs/2501.05254v1
Semisimplifications and representations of the General Linear Supergroup,2025-01-09T15:02:46Z,"Thorsten Heidersdorf, Rainer Weissauer","We study the semisimplification of the full karoubian subcategory generated
by the irreducible finite dimensional representations of the algebraic
supergroup $GL(m|n)$ over an algebraically closed field of characteristic zero.
This semisimplification is equivalent to the representations of a pro-reductive
group $H_{m|n}$. We show that there is a canonical decomposition $H_{m|n} \cong
GL(m\!-\! n) \times H_{n|n}$, thereby reducing the determination of $H_{m|n}$
to the equal rank case $m\! =\! n$ which was treated in a previous paper.",http://arxiv.org/abs/2501.05298v4
"Identity-aware Feature Decoupling Learning for Clothing-change Person
  Re-identification",2025-01-10T10:45:38Z,"Haoxuan Xu, Bo Li, Guanglin Niu","Clothing-change person re-identification (CC Re-ID) has attracted increasing
attention in recent years due to its application prospect. Most existing works
struggle to adequately extract the ID-related information from the original RGB
images. In this paper, we propose an Identity-aware Feature Decoupling (IFD)
learning framework to mine identity-related features. Particularly, IFD
exploits a dual stream architecture that consists of a main stream and an
attention stream. The attention stream takes the clothing-masked images as
inputs and derives the identity attention weights for effectively transferring
the spatial knowledge to the main stream and highlighting the regions with
abundant identity-related information. To eliminate the semantic gap between
the inputs of two streams, we propose a clothing bias diminishing module
specific to the main stream to regularize the features of clothing-relevant
regions. Extensive experimental results demonstrate that our framework
outperforms other baseline models on several widely-used CC Re-ID datasets.",http://arxiv.org/abs/2501.05851v1
Metasurface Polarimeter for Structural Imaging and Tissue Diagnostics,2025-01-10T11:06:39Z,"Paul Thrane, Chao Meng, Alexander Bykov, Oleksii Sieryi, Fei Ding, Igor Meglinski, Christopher A. Dirdal, Sergey I. Bozhevolnyi","Histopathology, the study and diagnosis of disease through analysis of tissue
samples, is an indispensable part of modern medicine. However, the practice is
time consuming and labor intensive, compelling efforts to improve the process
and develop new approaches. One perspective technique involves mapping changes
in the polarization state of light scattered by the tissue, but the
conventional implementation requires bulky polarization optics and is slow. We
report the design, fabrication and characterization of a compact metasurface
polarimeter operating at 640 nm enabling simultaneous determination of Stokes
parameters and degree of polarization with $\pm$2% accuracy. To validate its
use for histopathology we map polarization state changes in a tissue phantom
mimicking a biopsy with a cancerous inclusion, comparing it to a commercial
polarimeter. The results indicate a great potential and suggest several
improvements with which we believe metasurface polarimeter based devices will
be ready for practical histopathology application in clinical environment.",http://arxiv.org/abs/2501.05864v1
"AlgoRxplorers | Precision in Mutation: Enhancing Drug Design with
  Advanced Protein Stability Prediction Tools",2025-01-13T02:17:01Z,"Karishma Thakrar, Jiangqin Ma, Max Diamond, Akash Patel","Predicting the impact of single-point amino acid mutations on protein
stability is essential for understanding disease mechanisms and advancing drug
development. Protein stability, quantified by changes in Gibbs free energy
($\Delta\Delta G$), is influenced by these mutations. However, the scarcity of
data and the complexity of model interpretation pose challenges in accurately
predicting stability changes. This study proposes the application of deep
neural networks, leveraging transfer learning and fusing complementary
information from different models, to create a feature-rich representation of
the protein stability landscape. We developed four models, with our third
model, ThermoMPNN+, demonstrating the best performance in predicting
$\Delta\Delta G$ values. This approach, which integrates diverse feature sets
and embeddings through latent transfusion techniques, aims to refine
$\Delta\Delta G$ predictions and contribute to a deeper understanding of
protein dynamics, potentially leading to advancements in disease research and
drug discovery.",http://arxiv.org/abs/2501.07014v3
"A Deep Search for a Strong Diffuse Interstellar Band in the
  Circumgalactic Medium",2025-01-13T06:29:29Z,"Chih-Yuan Chang, Ting-Wen Lan","We investigate the absorption signals of a strong diffuse interstellar band,
DIB$\lambda4430$, in the circumgalactic medium (CGM) traced by MgII absorption
lines. To this end, we make use of approximately 60,000 MgII absorption line
spectra within $0.4<z<1.0$ compiled from the Sloan Digital Sky Surveys and
obtain composite spectra with uncertainties for absorption line measurements
being a few m$\r{A}$. By using MgII absorption strength and dust reddening
relation from the literature, we measure the DIB$\lambda4430$ absorption
strength as a function of $\rm E(B-V)$ in the CGM, and compare the Milky Way
DIB$\lambda4430$ - $\rm E(B-V)$ relation extrapolated down to the CGM $\rm
E(B-V)$ region. Our results show no detectable signals of DIB$\lambda4430$
across the entire $\rm E(B-V)$ range in the CGM traced by MgII absorption
lines. This lack of detection of DIB$\lambda4430$ in the CGM is inconsistent
with the Milky Way signals by $\sim 5 \, \sigma$, indicating that the factors
associated with different environments affect the abundance of the
DIB$\lambda4430$ carrier.",http://arxiv.org/abs/2501.07082v1
"An Investigation into Seasonal Variations in Energy Forecasting for
  Student Residences",2025-01-13T15:43:22Z,"Muhammad Umair Danish, Mathumitha Sureshkumar, Thanuri Fonseka, Umeshika Uthayakumar, Vinura Galwaduge","This research provides an in-depth evaluation of various machine learning
models for energy forecasting, focusing on the unique challenges of seasonal
variations in student residential settings. The study assesses the performance
of baseline models, such as LSTM and GRU, alongside state-of-the-art
forecasting methods, including Autoregressive Feedforward Neural Networks,
Transformers, and hybrid approaches. Special attention is given to predicting
energy consumption amidst challenges like seasonal patterns, vacations,
meteorological changes, and irregular human activities that cause sudden
fluctuations in usage. The findings reveal that no single model consistently
outperforms others across all seasons, emphasizing the need for season-specific
model selection or tailored designs. Notably, the proposed Hyper Network based
LSTM and MiniAutoEncXGBoost models exhibit strong adaptability to seasonal
variations, effectively capturing abrupt changes in energy consumption during
summer months. This study advances the energy forecasting field by emphasizing
the critical role of seasonal dynamics and model-specific behavior in achieving
accurate predictions.",http://arxiv.org/abs/2501.07423v1
"""Near Data"" and ""Far Data"" for Urban Sustainability: How Do Community
  Advocates Envision Data Intermediaries?",2025-01-13T19:47:44Z,"Han Qiao, Siyi Wu, Christoph Becker","In the densifying data ecosystem of today's cities, data intermediaries are
crucial stakeholders in facilitating data access and use. Community advocates
live in these sites of social injustices and opportunities for change. Highly
experienced in working with data to enact change, they offer distinctive
insights on data practices and tools. This paper examines the unique
perspectives that community advocates offer on data intermediaries. Based on
interviews with 17 advocates working with 23 grassroots and nonprofit
organizations, we propose the quality of ""near"" and ""far"" to be seriously
considered in data intermediaries' works and articulate advocates' vision of
connecting ""near data"" and ""far data."" To pursue this vision, we identified
three pathways for data intermediaries: align data exploration with ways of
storytelling, communicate context and uncertainties, and decenter artifacts for
relationship building. These pathways help data intermediaries to put data
feminism into practice, surface design opportunities and tensions, and raise
key questions for supporting the pursuit of the Right to the City.",http://arxiv.org/abs/2501.07661v1
"Annealed mean-field epidemiological model on scale-free networks with a
  mitigating factor",2025-01-13T21:33:21Z,"K. M. Kim, M. O. Hase","An annealed version of the quenched mean-field model for epidemic spread is
introduced and investigated analytically and assisted by numerical
calculations. The interaction between individuals follows a prescription that
is used to generate a scale-free network, and we have adjusted the number of
connections to produce a sparse network. Specifically, the model's behavior
near the infection threshold is examined, as well as the behavior of the
stationary prevalence and the probability that a connection between individuals
encounters an infected one. We found that these functions display a
monotonically increasing dependence on the infection rate. Subsequently, a
modification that mimics the mitigation in the probability of encountering an
infected individual is introduced, following an old idea rooted in the
Malthus-Verhulst model. We found that this modification drastically changes the
probability that a connection meets an infected individual. However, despite
this change, it does not alter the monotonically increasing behavior of the
stationary prevalence.",http://arxiv.org/abs/2501.07706v2
Optimal Control of an Electromechanical Energy Harvester,2025-01-13T22:54:11Z,"Dario Lucente, Alessandro Manacorda, Andrea Plati, Alessandro Sarracino, Marco Baldovin","Many techniques originally developed in the context of deterministic control
theory have been recently applied to the quest for optimal protocols in
stochastic processes. Given a system subject to environmental fluctuations, one
may ask what is the best way to change in time its controllable parameters in
order to maximize, on average, a certain reward function, while steering the
system between two pre-assigned states. In this work we study the problem of
optimal control for a wide class of stochastic systems, inspired by a model of
energy harvester. The stochastic noise in this system is due to the mechanical
vibrations, while the reward function is the average power extracted from them.
We consider the case in which the electrical resistance of the harvester can be
changed in time, and we exploit the tools of control theory to work out optimal
solutions in a perturbative regime, close to the stationary state. Our results
show that it is possible to design protocols that perform better than any
possible solution with constant resistance.",http://arxiv.org/abs/2501.07735v1
"Improving Our Knowledge of the Solar Near-Surface Shear Layer: The
  Special Case of the Leptocline",2025-01-14T11:21:25Z,"Jean-Pierre Rozelot, Alexander Kosovichev, Irina Kitiashvili","The discovery of the solar activity cycle was linked from the outset to the
observation of the temporal variability of sunspots, which we know to be the
result of complex processes associated with the dynamics of inner layers.
Numerous recent studies have highlighted changes in the Sun's Near-Surface
Shear Layer (NSSL), pointing to the role of the leptocline, a shallow and sharp
rotational shear layer in the top around 8 Mm. The leptocline, mainly
characterized by a strong radial rotational gradient at middle latitudes and
self-organized meridional flows, is the cradle of numerous phenomena: opacity,
superadiabaticity, and turbulent pressure changes; the hydrogen and helium
ionization processes; a sharp decrease in the sound speed; and, probably,
variations of the seismic radius associated with a nonmonotonic expansion of
subsurface layers with depth. In addition, the leptocline may play a key role
in forming the magnetic butterfly diagram. Such results are a starting point
for further systematic investigations of the structure and dynamics of this
layer, which will lead to a better understanding of solar activity.",http://arxiv.org/abs/2501.08021v1
"Efficient Planning in Large-scale Systems Using Hierarchical Finite
  State Machines",2025-01-15T16:23:04Z,"Elis Stefansson, Karl H. Johansson","We consider optimal planning in a large-scale system formalised as a
hierarchical finite state machine (HFSM). A planning algorithm is proposed
computing an optimal plan between any two states in the HFSM, consisting of two
steps: A pre-processing step that computes optimal exit costs of the machines
in the HFSM, with time complexity scaling with the number of machines; and a
query step that efficiently computes an optimal plan by removing irrelevant
subtrees of the HFSM using the optimal exit costs. The algorithm is
reconfigurable in the sense that changes in the HFSM are handled with ease,
where the pre-processing step recomputes only the optimal exit costs affected
by the change. The algorithm can also exploit compact representations that
groups together identical machines in the HFSM, where the algorithm only needs
to compute the optimal exit costs for one of the identical machines within each
group, thereby avoid unnecessary recomputations. We validate the algorithm on
large systems with millions of states and a robotic application. It is shown
that our approach outperforms Dijkstra's algorithm, Bidirectional Dijkstra and
Contraction Hierarchies.",http://arxiv.org/abs/2501.08918v1
"Determination and evaluation of the critical liquid nitrogen for
  superconducting levitator based on a novel temperature-weight coupling
  measurement device",2025-01-12T21:48:05Z,"Peng Pang, Jun Zheng, Chenling Xian","Liquid nitrogen (LN2) is the only cooling medium for the high-temperature
superconducting (HTS) bulks in the superconducting levitator, which is the
heart of the maglev train, to reach working state. The detection and
determination of the critical LN2 content are crucial for reliable operation of
the HTS maglev train. However, the related intelligent detection model and
technology is lack in the combination filed of the cryogenic environment and
maglev application, and there is no existing method to detect the LN2 content
in superconducting levitator. This paper proposes to employ multisensor fusion
framework to fuse and enhance the accuracy of critical LN2 content testing.
Four temperature sensors were deployed inside superconducting levitator to
measure the temperature change during the LN2 content changing from 100 % to 0.
It was first obtained that the critical LN2 content in the superconducting
levitator is 4%. To accurately monitor the critical LN2 content in the
superconducting levitator, a matrix-weighted information fusion Kalman filter
algorithm was used. Compared with the previous single sensor method, the
testing accuracy of the multisensor fusion method can be improved by 5.6%. The
work can provide a preliminary research foundation for the online monitoring
and fault diagnosis of HTS maglev train.",http://arxiv.org/abs/2501.09030v1
"Layered Dirichlet Modeling to Assess the Changing Contributions of MLB
  Players as they Age",2025-01-15T21:13:15Z,"Monnie McGee, Jacob Turner, Bianca Luedeker","The productive career of a professional athlete is limited compared to the
normal human lifespan. Most professional athletes have retired by age 40. The
early retirement age is due to a combination of age-related performance and
life considerations. While younger players typically are stronger and faster
than their older teammates, older teammates add value to a team due to their
experience and perspective. Indeed, the highest--paid major league baseball
players are those over the age of 35. These players contribute intangibly to a
team through mentorship of younger players; however, their peak athletic
performance has likely passed. Given this, it is of interest to learn how more
mature players contribute to a team in measurable ways. We examine the
distribution of plate appearance outcomes from three different age groups as
compositional data, using Layered Dirichlet Modeling (LDM). We develop a
hypothesis testing framework to compare the average proportions of outcomes for
each component among 3 of more groups. LDM can not only determine evidence for
differences among populations, but also pinpoint within which component the
largest changes are likely to occur. This framework can determine where players
can be of most use as they age.",http://arxiv.org/abs/2501.09153v1
"Adaptive Spatiotemporal Augmentation for Improving Dynamic Graph
  Learning",2025-01-17T07:48:18Z,"Xu Chu, Hanlin Xue, Bingce Wang, Xiaoyang Liu, Weiping Li, Tong Mo, Tuoyu Feng, Zhijie Tan","Dynamic graph augmentation is used to improve the performance of dynamic
GNNs. Most methods assume temporal locality, meaning that recent edges are more
influential than earlier edges. However, for temporal changes in edges caused
by random noise, overemphasizing recent edges while neglecting earlier ones may
lead to the model capturing noise. To address this issue, we propose STAA
(SpatioTemporal Activity-Aware Random Walk Diffusion). STAA identifies nodes
likely to have noisy edges in spatiotemporal dimensions. Spatially, it analyzes
critical topological positions through graph wavelet coefficients. Temporally,
it analyzes edge evolution through graph wavelet coefficient change rates.
Then, random walks are used to reduce the weights of noisy edges, deriving a
diffusion matrix containing spatiotemporal information as an augmented
adjacency matrix for dynamic GNN learning. Experiments on multiple datasets
show that STAA outperforms other dynamic graph augmentation methods in node
classification and link prediction tasks.",http://arxiv.org/abs/2501.10010v1
"Time-Resolved Measurements of Cumulative Effects in Gas Dynamics Induced
  by High-Repetition-Rate Femtosecond Laser Filamentation",2025-01-17T13:47:46Z,"Robin Löscher, Malte C. Schroeder, Alan Omar, Clara J. Saraceno","The advent of high-average-power, ultrafast ytterbium-based lasers allows us
to generate laser filaments at repetition rates ranging from 10s of kHz up to
100s of kHz. At such high repetition rates, the inter-pulse time lies below the
time required for the total diffusion of the deposited heat by each laser
pulse, leading to cumulative hydrodynamic effects that have so far been rarely
studied. Here, we present, to the best of our knowledge, the first experimental
time-resolved measurements of these dynamics in air for laser repetition rates
between 1 kHz and 100 kHz. We measure the change in the air refractive index
caused by the localized heat deposition and the length of the
filament-generated plasma channel, with which we can infer the corresponding
change in air density. We observe that at repetition rates above 10 kHz,
stationary density depletions with vanishing dynamics emerge. Our findings are
of wide relevance for the fields of high-repetition-rate laser filamentation
and its applications, as well as THz generation from laser-induced plasma
sources.",http://arxiv.org/abs/2501.10198v1
"Matrix Ordering through Spectral and Nilpotent Structures in Totally
  Ordered Complex Number Fields",2025-01-17T23:34:17Z,Shih-Yu Chang,"Matrix inequalities play a pivotal role in mathematics, generalizing scalar
inequalities and providing insights into linear operator structures. However,
the widely used L\""owner ordering, which relies on real-valued eigenvalues, is
limited to Hermitian matrices, restricting its applicability to non-Hermitian
systems increasingly relevant in fields like non-Hermitian physics. To overcome
this, we develop a total ordering relation for complex numbers, enabling
comparisons of the spectral components of general matrices with complex
eigenvalues. Building on this, we introduce the Spectral and Nilpotent Ordering
(SNO), a partial order for arbitrary matrices of the same dimensions. We
further establish a theoretical framework for majorization ordering with
complex-valued functions, which aids in refining SNO and analyzing spectral
components. An additional result is the extension of the Schur--Ostrowski
criterion to the complex domain. Moreover, we characterize Jordan blocks of
matrix functions using a generalized dominance order for nilpotent components,
facilitating systematic analysis of non-diagonalizable matrices. Finally, we
derive monotonicity and convexity conditions for functions under the SNO
framework, laying a new mathematical foundation for advancing matrix analysis.",http://arxiv.org/abs/2501.10603v1
"Role of Random Interaction Connection in the Order Transition of Active
  Matter Based on the Vicsek Model",2025-01-18T06:24:15Z,"Ruizhi Jin, Kejun Dong","Randomness plays a key role in the order transition of active matter but has
not yet been explicitly considered in pairwise interaction connection. In this
letter, we introduce the perception rate P into the Vicsek model as the
probability of the interaction connections and model the connections as
superposition states. We show that with increasing P, the polar order number
undergoes an order transition and then saturation. The order transition is a
first-order phase transition with band formation, and the effect of P is
different from density. The change of the order number is linked with the
interaction structure. The order transition, order saturation, and phase
separation correspond to different critical changes in the local interaction
number. The global interaction structure is further analyzed as a network. The
decrease of P is comparable to random edge removal, under which the network
experiences modal transitions near the critical points of the order number, and
the network exhibits surprising robustness. Our results suggest that random
interaction can be a new important factor in active matter models, with
potential applications in robotic swarms and social activities.",http://arxiv.org/abs/2501.10669v1
"Almost sure bounds for weighted sums of Rademacher random multiplicative
  functions",2025-01-19T15:26:39Z,Christopher Atherfold,"We prove that when $f$ is a Rademacher random multiplicative function for any
$\epsilon>0$, then $\sum_{n \leqslant x}\frac{f(n)}{\sqrt{n}} \ll
(\log\log(x))^{3/4+\epsilon}$ for almost all $f$. We also show that there exist
arbitrarily large values of $x$ such that $\sum_{n \leqslant
x}\frac{f(n)}{\sqrt{n}} \gg (\log\log(x))^{-1/2}$. This is different to what is
found in the Steinhaus case, this time with the size of the Rademacher Euler
product making the multiplicative chaos contribution the dominant one. We also
find a sharper upper bound when we restrict to integers with a prime factor
greater than $\sqrt{x}$, proving that $\sum_{\substack{n \leqslant x \\ P(n) >
\sqrt{x}}}\frac{f(n)}{\sqrt{n}} \ll (\log\log(x))^{1/4+\epsilon}$.",http://arxiv.org/abs/2501.11076v2
The influence of chromospheric activity on line formation,2025-01-20T21:14:40Z,"Mariela C. Vieytes, Lily L. Zhao, Megan Bedell","One of the primary sources of stellar spectral variability is magnetic
activity. While our current understanding of chromospheric activity is largely
derived from specific lines sensitive to chromospheric heating, such as the Ca
II HK doublet, previous observational studies have shown that other spectral
lines are also affected. To investigate the influence of activity on line
formation in greater detail, we constructed a set of stellar models for
hypothetical G2 dwarf stars with varying levels of activity and calculated
their synthetic spectra. A comparison of these spectra revealed two spectral
regions most significantly impacted by activity: approximately 3300-4400 A and
5250-5500 A. By calculating the total contribution function of the lines, we
determined that the emergence of a secondary chromospheric contribution to line
formation is the primary mechanism driving these changes. Based on our
calculations and analysis, we compiled a list of transition lines and their
corresponding changes due to chromospheric activity. This list could serve as a
valuable tool for selecting spectral lines applicable to a wide range of
astrophysical studies.",http://arxiv.org/abs/2501.11750v1
"Semantic Dependency in Microservice Architecture: A Framework for
  Definition and Detection",2025-01-20T23:34:24Z,"Amr S. Abdelfattah, Kari E Cordes, Austin Medina, Tomas Cerny","Microservices have been a key architectural approach for over a decade,
transforming system design by promoting decentralization and allowing
development teams to work independently on specific microservices. While
loosely coupled microservices are ideal, dependencies between them are
inevitable. Often, these dependencies go unnoticed by development teams.
Although syntactic dependencies can be identified, tracking semantic
dependencies - when multiple microservices share similar logic - poses a
greater challenge. As systems evolve, changes made to one microservice can
trigger ripple effects, jeopardizing system consistency and requiring updates
to dependent services, which increases maintenance and operational complexity.
Effectively tracking different types of dependencies across microservices is
essential for anticipating the impact of such changes. This paper introduces
the Semantic Dependency Matrix as an instrument to address these challenges
from a semantic perspective. We propose an automated approach to extract and
represent these dependencies and demonstrate its effectiveness through a case
study. This paper takes a step further by demonstrating the significance of
semantic dependencies, even in cases where there are no direct dependencies
between microservices. It shows that these hidden dependencies can exist
independently of endpoint or data dependencies, revealing critical connections
that might otherwise be overlooked.",http://arxiv.org/abs/2501.11787v1
"The Associated Discrete Laplacian in $\mathbb{R}^3$ and Mean Curvature
  with Higher order Approximations",2025-01-21T04:01:59Z,Wei-Hung Liao,"In $\mathbb{R}^3$, the primal and dual constructions yield completely
different discrete Laplacians for tetrahedral meshes.In this article, we prove
that the discrete Laplacian satisfies the Euler-Lagrange equation of the
Dirichlet energy in terms of the associated discrete Laplacian corresponding to
the dual construction. Specifically, for a three simplex immersed in
$\mathbb{R}^3$, the associated discrete Laplacian on the tetrahedron can be
expressed as the discrete Laplacian of the faces of the tetrahedron and the
associated discrete mean curvature term given by the ambient space
$\mathbb{R}^3$. Based on geometric foundations, we provide a mathematical proof
showing that the dual construction gives a optimal Laplacian in $\mathbb{R}^3$
compared to the primal construction. Moreover, we show that the associated
discrete mean curvature is more sensitive to the initial mesh than other
state-of-the-art discrete mean curvatures when the angle changes
instantaneously. Instead of improving the angular transient accuracy through
mesh subdivision, we can improve the accuracy by providing a higher order
approximation of the instantaneous change in angle to reduce the solution
error.",http://arxiv.org/abs/2501.11871v1
"Beyond Window-Based Detection: A Graph-Centric Framework for Discrete
  Log Anomaly Detection",2025-01-21T14:26:03Z,"Jiaxing Qi, Chang Zeng, Zhongzhi Luan, Shaohan Huang, Shu Yang, Yao Lu, Hailong Yang, Depei Qian","Detecting anomalies in discrete event logs is critical for ensuring system
reliability, security, and efficiency. Traditional window-based methods for log
anomaly detection often suffer from context bias and fuzzy localization, which
hinder their ability to precisely and efficiently identify anomalies. To
address these challenges, we propose a graph-centric framework, TempoLog, which
leverages multi-scale temporal graph networks for discrete log anomaly
detection. Unlike conventional methods, TempoLog constructs continuous-time
dynamic graphs directly from event logs, eliminating the need for fixed-size
window grouping. By representing log templates as nodes and their temporal
relationships as edges, the framework dynamically captures both local and
global dependencies across multiple temporal scales. Additionally, a
semantic-aware model enhances detection by incorporating rich contextual
information. Extensive experiments on public datasets demonstrate that our
method achieves state-of-the-art performance in event-level anomaly detection,
significantly outperforming existing approaches in both accuracy and
efficiency.",http://arxiv.org/abs/2501.12166v1
"Regressor-Guided Image Editing Regulates Emotional Response to Reduce
  Online Engagement",2025-01-21T16:59:13Z,"Christoph Gebhardt, Robin Willardt, Seyedmorteza Sadat, Chih-Wei Ning, Andreas Brombach, Jie Song, Otmar Hilliges, Christian Holz","Emotions are known to mediate the relationship between users' content
consumption and their online engagement, with heightened emotional intensity
leading to increased engagement. Building on this insight, we propose three
regressor-guided image editing approaches aimed at diminishing the emotional
impact of images. These include (i) a parameter optimization approach based on
global image transformations known to influence emotions, (ii) an optimization
approach targeting the style latent space of a generative adversarial network,
and (iii) a diffusion-based approach employing classifier guidance and
classifier-free guidance. Our findings demonstrate that approaches can
effectively alter the emotional properties of images while maintaining high
visual quality. Optimization-based methods primarily adjust low-level
properties like color hues and brightness, whereas the diffusion-based approach
introduces semantic changes, such as altering appearance or facial expressions.
Notably, results from a behavioral study reveal that only the diffusion-based
approach successfully elicits changes in viewers' emotional responses while
preserving high perceived image quality. In future work, we will investigate
the impact of these image adaptations on internet user behavior.",http://arxiv.org/abs/2501.12289v1
Tuning the topological winding number by rolling up graphene,2025-01-22T02:33:35Z,"Ying-Je Lee, Yu-An Cheng, Yu-Jie Zhong, Ion Cosma Fulga, Ching-Hao Chang","Nanoscrolls, radial superlattices formed by rolling up a nanomembrane,
exhibit distinct electronic and magneto-transport properties compared to their
flat counterparts. In this study, we theoretically demonstrate that the
conductance can be precisely enhanced N times by rolling up graphene into an
N-turn nanoscroll and applying a longitudinal magnetic field. This tunable
positive magnetoconductance stems from the topological winding number which is
activated in a carbon nanoscroll with magnetic flux and its maximum value
purely increases with the scroll winding number (the number of turns). By
integrating material geometry and topology, our work opens the door to
artificially creating, customizing, and designing topological materials in
rolled-up graphene-like systems.",http://arxiv.org/abs/2501.12590v1
"EvidenceMap: Learning Evidence Analysis to Unleash the Power of Small
  Language Models for Biomedical Question Answering",2025-01-22T09:27:11Z,"Chang Zong, Jian Wan, Siliang Tang, Lei Zhang","When addressing professional questions in the biomedical domain, humans
typically acquire multiple pieces of information as evidence and engage in
multifaceted analysis to provide high-quality answers. Current LLM-based
question answering methods lack a detailed definition and learning process for
evidence analysis, leading to the risk of error propagation and hallucinations
while using evidence. Although increasing the parameter size of LLMs can
alleviate these issues, it also presents challenges in training and deployment
with limited resources. In this study, we propose EvidenceMap, which aims to
enable a tiny pre-trained language model to explicitly learn multiple aspects
of biomedical evidence, including supportive evaluation, logical correlation
and content summarization, thereby latently guiding a small generative model
(around 3B parameters) to provide textual responses. Experimental results
demonstrate that our method, learning evidence analysis by fine-tuning a model
with only 66M parameters, exceeds the RAG method with an 8B LLM by 19.9% and
5.7% in reference-based quality and accuracy, respectively.",http://arxiv.org/abs/2501.12746v4
"MultiDreamer3D: Multi-concept 3D Customization with Concept-Aware
  Diffusion Guidance",2025-01-23T08:02:59Z,"Wooseok Song, Seunggyu Chang, Jaejun Yoo","While single-concept customization has been studied in 3D, multi-concept
customization remains largely unexplored. To address this, we propose
MultiDreamer3D that can generate coherent multi-concept 3D content in a
divide-and-conquer manner. First, we generate 3D bounding boxes using an
LLM-based layout controller. Next, a selective point cloud generator creates
coarse point clouds for each concept. These point clouds are placed in the 3D
bounding boxes and initialized into 3D Gaussian Splatting with concept labels,
enabling precise identification of concept attributions in 2D projections.
Finally, we refine 3D Gaussians via concept-aware interval score matching,
guided by concept-aware diffusion. Our experimental results show that
MultiDreamer3D not only ensures object presence and preserves the distinct
identities of each concept but also successfully handles complex cases such as
property change or interaction. To the best of our knowledge, we are the first
to address the multi-concept customization in 3D.",http://arxiv.org/abs/2501.13449v1
Moments of generalized fractional polynomial processes,2025-01-23T17:23:12Z,"Johannes Assefa, Martin Keller-Ressel","We derive a moment formula for generalized fractional polynomial processes,
i.e., for polynomial-preserving Markov processes time-changed by an inverse
L\'evy-subordinator. If the time change is inverse $\alpha$-stable, the
time-derivative of the Kolmogorov backward equation is replaced by a Caputo
fractional derivative of order $\alpha$, and we demonstrate that moments of
such processes are computable, in a closed form, using matrix Mittag-Leffler
functions. The same holds true for cross-moments in equilibrium, generalizing
results of Leonenko, Meerschaert and Sikorskii from the one-dimensional
diffusive case of second-order moments to the multivariate, jump-diffusive case
of moments of arbitrary order. We show that also in this more general setting,
fractional polynomial processes exhibit long-range dependence, with
correlations decaying as a power law with exponent $\alpha$.",http://arxiv.org/abs/2501.13854v1
"Longitudinal Abuse and Sentiment Analysis of Hollywood Movie Dialogues
  using LLMs",2025-01-20T00:44:38Z,"Rohitash Chandra, Guoxiang Ren, Group-H","Over the past decades, there has been an increasing concern about the
prevalence of abusive and violent content in Hollywood movies. This study uses
Large Language Models (LLMs) to explore the longitudinal abuse and sentiment
analysis of Hollywood Oscar and blockbuster movie dialogues from 1950 to 2024.
By employing fine-tuned LLMs, we analyze subtitles for over a thousand movies
categorised into four genres to examine the trends and shifts in emotional and
abusive content over the past seven decades. Our findings reveal significant
temporal changes in movie dialogues, which reflect broader social and cultural
influences. Overall, the emotional tendencies in the films are diverse, and the
detection of abusive content also exhibits significant fluctuations. The
results show a gradual rise in abusive content in recent decades, reflecting
social norms and regulatory policy changes. Genres such as thrillers still
present a higher frequency of abusive content that emphasises the ongoing
narrative role of violence and conflict. At the same time, underlying positive
emotions such as humour and optimism remain prevalent in most of the movies.
Furthermore, the gradual increase of abusive content in movie dialogues has
been significant over the last two decades, where Oscar-nominated movies
overtook the top ten blockbusters.",http://arxiv.org/abs/2501.13948v1
"Triplet Synthesis For Enhancing Composed Image Retrieval via
  Counterfactual Image Generation",2025-01-22T07:18:46Z,"Kenta Uesugi, Naoki Saito, Keisuke Maeda, Takahiro Ogawa, Miki Haseyama","Composed Image Retrieval (CIR) provides an effective way to manage and access
large-scale visual data. Construction of the CIR model utilizes triplets that
consist of a reference image, modification text describing desired changes, and
a target image that reflects these changes. For effectively training CIR
models, extensive manual annotation to construct high-quality training
datasets, which can be time-consuming and labor-intensive, is required. To deal
with this problem, this paper proposes a novel triplet synthesis method by
leveraging counterfactual image generation. By controlling visual feature
modifications via counterfactual image generation, our approach automatically
generates diverse training triplets without any manual intervention. This
approach facilitates the creation of larger and more expressive datasets,
leading to the improvement of CIR model's performance.",http://arxiv.org/abs/2501.13968v1
On Measures in Ion Trap Quantum Information,2025-01-24T09:47:13Z,"Reza Pirmoradian, M Reza Tanhayi","In this study, we investigate quantum information measures in ion traps by
utilizing the harmonic oscillator model to characterize trapped potentials and
ion dynamics. Our findings confirm that, in the steady-state case, mutual
information and synchronization measures exhibit similar behaviors.
Additionally, we explore how these measures change in the quench model and how
they are influenced by coupling and external noise, such as an external
magnetic field. Moreover, for a proposed target ground state, we determine the
circuit depth and analyze the effects of the external magnetic field and
coupling constant, highlighting their dynamic evolution over time. We also
discuss the coherent state of a single ion in a trap, noting an inverse
relationship between complexity and fidelity-where increased fidelity
corresponds to decreased system complexity, indicating a more ordered state
with improved control and optimization. However, at higher system frequencies,
complexity increases due to intricate interactions and rapid state changes,
necessitating advanced control mechanisms.",http://arxiv.org/abs/2501.14359v2
Approximation of Set-Valued Functions with images sets in $\mathbb{R}^d$,2025-01-24T15:53:03Z,"Nira Dyn, David Levin","Given a finite number of samples of a continuous set-valued function F,
mapping an interval to non-empty compact subsets of $\mathbb{R}^d$, $F: [a,b]
\to K(\mathbb{R}^d)$, we discuss the problem of computing good approximations
of F. We also discuss algorithms for a direct high-order evaluation of the
graph of $F$, namely, the set $Graph(F)=\{(t,y)\ | \ y\in F(t),\ t\in
[a,b]\}\in K(\mathbb{R}^{d+1})$. A set-valued function can be continuous and
yet have points where the topology of the image sets changes. The main
challenge in set-valued function approximation is to derive high-order
approximations near these points. In a previous paper, we presented with Q.
Muzaffar, an algorithm for approximating set-valued functions with 1D sets
($d=1$) as images, achieving high approximation order near points of topology
change. Here we build upon the results and algorithms in the $d=1$ case, first
in more detail for the important case $d=2$, and later for approximating
set-valued functions and their graphs in higher dimensions.",http://arxiv.org/abs/2501.14591v1
"BOLDreams: Dreaming with pruned in-silico fMRI Encoding Models of the
  Visual Cortex",2025-01-24T16:46:16Z,"Uzair Hussain, Kamil Uludag","In this article we use the Natural Scenes Dataset (NSD) to train a family of
feature-weighted receptive field neural encoding models. These models use a
pre-trained vision or text backbone and map extracted features to the voxel
space via receptive field readouts. We comprehensively assess such models,
quantifying performance changes based on using different modalities like text
or images, toggling finetuning, using different pre-trained backbones, and
changing the width of the readout. We also dissect each model using explainable
AI (XAI) techniques, such as feature visualization via input optimization, also
referred to as ``dreaming'' in the AI literature, and the integrated gradients
approach to calculate implicit attention maps to illustrate which features
drive the predicted signal in different brain areas. These XAI tools illustrate
biologically plausible features that drive the predicted signal. Traversing the
model hyperparameter space reveals the existence of a maximally minimal model,
balancing simplicity while maintaining performance.",http://arxiv.org/abs/2501.14854v1
"Decision Making in Changing Environments: Robustness, Query-Based
  Learning, and Differential Privacy",2025-01-24T21:31:50Z,"Fan Chen, Alexander Rakhlin","We study the problem of interactive decision making in which the underlying
environment changes over time subject to given constraints. We propose a
framework, which we call \textit{hybrid Decision Making with Structured
Observations} (hybrid DMSO), that provides an interpolation between the
stochastic and adversarial settings of decision making. Within this framework,
we can analyze local differentially private (LDP) decision making, query-based
learning (in particular, SQ learning), and robust and smooth decision making
under the same umbrella, deriving upper and lower bounds based on variants of
the Decision-Estimation Coefficient (DEC). We further establish strong
connections between the DEC's behavior, the SQ dimension, local minimax
complexity, learnability, and joint differential privacy. To showcase the
framework's power, we provide new results for contextual bandits under the LDP
constraint.",http://arxiv.org/abs/2501.14928v1
"Determination of the London penetration depth with the tunnel diode
  oscillator technique",2025-01-26T13:07:12Z,G. P. Mikitik,"Using a distribution of the Meissner currents over the surface of an
infinitely long superconducting slab with a rectangular cross section, the
magnetic moment of the slab is calculated, taking into account corrections
associated with a small but finite value of the London penetration depth
$\lambda$. Since these corrections determine the shift of the resonant
frequency in the tunnel diode oscillator technique, formulas for determination
of $\lambda$ within this technique are derived for the slab. These formulas are
valid for any aspect ratio of its cross section, and they differ from those
that are often used in analyzing experimental data. Namely, it is shown that
sharp edges of the slab can cause the large frequency shift proportional to the
change in the value of $\lambda^{2/3}$. Although this result complicates the
extraction of a temperature dependence of $\lambda$ from the frequency shift,
it also opens up new possibilities in determining the London penetration depth.
In particular, under certain conditions, it is possible not only to measure the
changes in $\lambda$ with the temperature, but also to estimate its absolute
value.",http://arxiv.org/abs/2501.15512v1
"Pressure induced Structure Change and Anomalies in Thermodynamic
  Quantities and Transport Properties in Liquid Lithium Hydride",2025-01-26T13:54:59Z,"X. Z. Yan, Y. M. Chen, Hua Y. Geng, Y. F. Wang, Y. Sun, L. L. Zhang, H. Wang, Y. L. Xu","Understand the nature of liquid structure and its evolution under different
conditions is a major challenge in condensed physics and materials science.
Here, we report a pressure-induced structure change spanning a wide pressure
range in liquid-state lithium hydride (LiH) by first-principles molecular
dynamic simulations. This behavior can be described as a continuous crossover
from low pressure liquid with Li$^+$-H$^-$ duality symmetry to high pressure
one with broken of duality symmetry. The thermodynamic quantities such as heat
capacity and ionic transport properties such as diffusivity are also saliently
impacted. It is important to stress that such behavior is firstly predicted for
this category of materials, which is ubiquitous in universe as well as in
industry applications. Lastly, a comprehensive high-pressure high-temperature
phase diagram of LiH is constructed, which embodies rich physics in this
previously-thought-simple ionic compound.",http://arxiv.org/abs/2501.15532v1
Can Molecular Evolution Mechanism Enhance Molecular Representation?,2025-01-27T05:54:42Z,"Kun Li, Longtao Hu, Xiantao Cai, Jia Wu, Wenbin Hu","Molecular evolution is the process of simulating the natural evolution of
molecules in chemical space to explore potential molecular structures and
properties. The relationships between similar molecules are often described
through transformations such as adding, deleting, and modifying atoms and
chemical bonds, reflecting specific evolutionary paths. Existing molecular
representation methods mainly focus on mining data, such as atomic-level
structures and chemical bonds directly from the molecules, often overlooking
their evolutionary history. Consequently, we aim to explore the possibility of
enhancing molecular representations by simulating the evolutionary process. We
extract and analyze the changes in the evolutionary pathway and explore
combining it with existing molecular representations. Therefore, this paper
proposes the molecular evolutionary network (MEvoN) for molecular
representations. First, we construct the MEvoN using molecules with a small
number of atoms and generate evolutionary paths utilizing similarity
calculations. Then, by modeling the atomic-level changes, MEvoN reveals their
impact on molecular properties. Experimental results show that the MEvoN-based
molecular property prediction method significantly improves the performance of
traditional end-to-end algorithms on several molecular datasets. The code is
available at https://anonymous.4open.science/r/MEvoN-7416/.",http://arxiv.org/abs/2501.15799v1
"Adaptive AI-based Decentralized Resource Management in the Cloud-Edge
  Continuum",2025-01-27T06:07:09Z,"Lanpei Li, Jack Bell, Massimo Coppola, Vincenzo Lomonaco","The increasing complexity of application requirements and the dynamic nature
of the Cloud-Edge Continuum present significant challenges for efficient
resource management. These challenges stem from the ever-changing
infrastructure, which is characterized by additions, removals, and
reconfigurations of nodes and links, as well as the variability of application
workloads. Traditional centralized approaches struggle to adapt to these
changes due to their static nature, while decentralized solutions face
challenges such as limited global visibility and coordination overhead. This
paper proposes a hybrid decentralized framework for dynamic application
placement and resource management. The framework utilizes Graph Neural Networks
(GNNs) to embed resource and application states, enabling comprehensive
representation and efficient decision-making. It employs a collaborative
multi-agent reinforcement learning (MARL) approach, where local agents optimize
resource management in their neighborhoods and a global orchestrator ensures
system-wide coordination. By combining decentralized application placement with
centralized oversight, our framework addresses the scalability, adaptability,
and accuracy challenges inherent in the Cloud-Edge Continuum. This work
contributes to the development of decentralized application placement
strategies, the integration of GNN embeddings, and collaborative MARL systems,
providing a foundation for efficient, adaptive and scalable resource
management.",http://arxiv.org/abs/2501.15802v1
Precession for the mode change in a gamma-ray pulsar,2025-01-27T09:51:55Z,"H. Tong, H. H. Wang","PSR J2021+4026 is a gamma-ray pulsar having variations in its spin-down rate
and gamma-ray flux. Its variations in timing and emission are correlated, e.g.,
a larger spin-down rate for a low gamma-ray flux. We show that the mode change
in PSR J2021+4026 can be understood in the precession scenario. In the
precession model, the inclination angle is modulated due to precession. At the
same time, the wobble angle may decay with time. This results in damping of the
precession. Combined with magnetospheric torque model and the outer gap model,
the damped precession can explain: (1) when the inclination angle is larger,
the spin-down rate will be larger, accompanied by a lower gamma-ray flux. (2)
The variation amplitude of the gamma-ray flux and spin-down rate is smaller
than previous results due to the damping of the precession. The modulation
period is becoming shorter due to a smaller wobble angle. In the end, we
propose that there are two kinds of modulations in pulsars. Long-term
modulations in pulsars may be due to precession. Short-term modulations may be
of magnetospheric origin.",http://arxiv.org/abs/2501.15902v1
"Microfoundations of IPR and standardization strategies of companies:
  Evidence from the evolving European Single Market",2025-01-27T13:35:26Z,"Jussi Heikkilä, Satu Rinkinen, Tero Rantala","Intellectual property rights (IPR) and standards are important institutions
that by shaping appropriability conditions of companies impact international
trade flows and the rate and direction of technological progress and innovation
activity. We shed light on microfoundations of IPR and standardization
capabilities and explore how companies have developed their IPR and
standardization strategies and adapted to related institutional changes in the
European Single Market. The analysis of the IPR and standardization strategies
of companies active in P\""aij\""at-H\""ame region of Finland, a northern part of
the European Union, reveals that only a few companies have explicit IPR and
standardization strategies, but several have systematic approaches to following
the development of standards and IPR environments in their industries.
Companies build dynamic IPR and standardization capabilities and adapt their
IPR and standardization strategies to the changing institutional environment
via experiential learning.",http://arxiv.org/abs/2501.16040v1
"HERITRACE: A User-Friendly Semantic Data Editor with Change Tracking and
  Provenance Management for Cultural Heritage Institutions",2025-01-27T16:48:39Z,"Arcangelo Massari, Silvio Peroni","HERITRACE is a data editor designed for galleries, libraries, archives and
museums, aimed at simplifying data curation while enabling non-technical domain
experts to manage data intuitively without losing its semantic integrity. While
the semantic nature of RDF can pose a barrier to data curation due to its
complexity, HERITRACE conceals this intricacy while preserving the advantages
of semantic representation. The system natively supports provenance management
and change tracking, ensuring transparency and accountability throughout the
curation process. Although HERITRACE functions effectively out of the box, it
offers a straightforward customization interface for technical staff, enabling
adaptation to the specific data model required by a given collection. Current
applications include the ParaText project, and its adoption is already planned
for OpenCitations. Future developments will focus on integrating the RDF
Mapping Language (RML) to enhance compatibility with non-RDF data formats,
further expanding its applicability in digital heritage management.",http://arxiv.org/abs/2501.16197v1
SAFR: Neuron Redistribution for Interpretability,2025-01-23T06:20:33Z,"Ruidi Chang, Chunyuan Deng, Hanjie Chen","Superposition refers to encoding representations of multiple features within
a single neuron, which is common in deep neural networks. This property allows
neurons to combine and represent multiple features, enabling the model to
capture intricate information and handle complex tasks. Despite promising
performance, the model's interpretability has been diminished. This paper
presents a novel approach to enhance model interpretability by regularizing
feature superposition. We introduce SAFR, which simply applies regularizations
to the loss function to promote monosemantic representations for important
tokens while encouraging polysemanticity for correlated token pairs, where
important tokens and correlated token pairs are identified via VMASK and
attention weights respectively. We evaluate SAFR with a transformer model on
two classification tasks. Experiments demonstrate the effectiveness of SAFR in
improving model interpretability without compromising prediction performance.
Besides, SAFR provides explanations by visualizing the neuron allocation within
the intermediate layers.",http://arxiv.org/abs/2501.16374v2
"SCDiar: a streaming diarization system based on speaker change detection
  and speech recognition",2025-01-28T02:27:24Z,"Naijun Zheng, Xucheng Wan, Kai Liu, Zhou Huan","In hours-long meeting scenarios, real-time speech stream often struggles with
achieving accurate speaker diarization, commonly leading to speaker
identification and speaker count errors. To address this challenge, we propose
SCDiar, a system that operates on speech segments, split at the token level by
a speaker change detection (SCD) module. Building on these segments, we
introduce several enhancements to efficiently select the best available segment
for each speaker. These improvements lead to significant gains across various
benchmarks. Notably, on real-world meeting data involving more than ten
participants, SCDiar outperforms previous systems by up to 53.6\% in accuracy,
substantially narrowing the performance gap between online and offline systems.",http://arxiv.org/abs/2501.16641v1
"MACI: Multi-Agent Collaborative Intelligence for Adaptive Reasoning and
  Temporal Planning",2025-01-28T03:57:22Z,Edward Y. Chang,"Artificial intelligence requires deliberate reasoning, temporal awareness,
and effective constraint management, capabilities traditional LLMs often lack
due to their reliance on pattern matching, limited self-verification, and
inconsistent constraint handling. We introduce Multi-Agent Collaborative
Intelligence (MACI), a framework comprising three key components: 1) a
meta-planner (MP) that identifies, formulates, and refines all roles and
constraints of a task (e.g., wedding planning) while generating a dependency
graph, with common-sense augmentation to ensure realistic and practical
constraints; 2) a collection of agents to facilitate planning and address
task-specific requirements; and 3) a run-time monitor that manages plan
adjustments as needed. By decoupling planning from validation, maintaining
minimal agent context, and integrating common-sense reasoning, MACI overcomes
the aforementioned limitations and demonstrates robust performance in two
scheduling problems.",http://arxiv.org/abs/2501.16689v2
"Meta-Federated Learning: A Novel Approach for Real-Time Traffic Flow
  Management",2025-01-28T07:24:24Z,"Bob Johnson, Michael Geller","Efficient management of traffic flow in urban environments presents a
significant challenge, exacerbated by dynamic changes and the sheer volume of
data generated by modern transportation networks. Traditional centralized
traffic management systems often struggle with scalability and privacy
concerns, hindering their effectiveness. This paper introduces a novel approach
by combining Federated Learning (FL) and Meta-Learning (ML) to create a
decentralized, scalable, and adaptive traffic management system. Our approach,
termed Meta-Federated Learning, leverages the distributed nature of FL to
process data locally at the edge, thereby enhancing privacy and reducing
latency. Simultaneously, ML enables the system to quickly adapt to new traffic
conditions without the need for extensive retraining. We implement our model
across a simulated network of smart traffic devices, demonstrating that
Meta-Federated Learning significantly outperforms traditional models in terms
of prediction accuracy and response time. Furthermore, our approach shows
remarkable adaptability to sudden changes in traffic patterns, suggesting a
scalable solution for real-time traffic management in smart cities. This study
not only paves the way for more resilient urban traffic systems but also
exemplifies the potential of integrated FL and ML in other real-world
applications.",http://arxiv.org/abs/2501.16758v1
"Dynamics of small, constant size particles in a protoplanetary disk with
  an embedded protoplanet",2025-01-28T19:00:03Z,"Ellen M. Price, Eric Van Clepper, Fred J. Ciesla","Hydrodynamical simulations of protoplanetary disk dynamics are useful tools
for understanding the formation of planetary systems, including our own.
Approximations are necessary to make these simulations computationally
tractable. A common assumption when simulating dust fluids is that of a
constant Stokes number, a dimensionless number that characterizes the
interaction between a particle and the surrounding gas. Constant Stokes number
is not a good approximation in regions of the disk where the gas density
changes significantly, such as near a planet-induced gap. In this paper, we
relax the assumption of constant Stokes number in the popular FARGO3D code
using semi-analytic equations for the drag force on dust particles, which
enables an assumption of constant particle size instead. We explore the effect
this change has on disk morphology and particle fluxes across the gap for both
outward- and inward-drifting particles. The assumption of constant particle
size, rather than constant Stokes number, is shown to make a significant
difference in some cases, emphasizing the importance of the more accurate
treatment.",http://arxiv.org/abs/2501.17232v1
"Tailored Truths: Optimizing LLM Persuasion with Personalization and
  Fabricated Statistics",2025-01-28T20:06:09Z,"Jasper Timm, Chetan Talele, Jacob Haimes","Large Language Models (LLMs) are becoming increasingly persuasive,
demonstrating the ability to personalize arguments in conversation with humans
by leveraging their personal data. This may have serious impacts on the scale
and effectiveness of disinformation campaigns. We studied the persuasiveness of
LLMs in a debate setting by having humans $(n=33)$ engage with LLM-generated
arguments intended to change the human's opinion. We quantified the LLM's
effect by measuring human agreement with the debate's hypothesis pre- and
post-debate and analyzing both the magnitude of opinion change, as well as the
likelihood of an update in the LLM's direction. We compare persuasiveness
across established persuasion strategies, including personalized arguments
informed by user demographics and personality, appeal to fabricated statistics,
and a mixed strategy utilizing both personalized arguments and fabricated
statistics. We found that static arguments generated by humans and GPT-4o-mini
have comparable persuasive power. However, the LLM outperformed static
human-written arguments when leveraging the mixed strategy in an interactive
debate setting. This approach had a $\mathbf{51\%}$ chance of persuading
participants to modify their initial position, compared to $\mathbf{32\%}$ for
the static human-written arguments. Our results highlight the concerning
potential for LLMs to enable inexpensive and persuasive large-scale
disinformation campaigns.",http://arxiv.org/abs/2501.17273v1
"Transition from non-ergodic to ergodic dynamics in an autonomous
  discrete time crystal",2025-01-29T06:27:46Z,"T. T. Sergeev, A. A. Zyablovsky, E. S. Andrianov","We consider an autonomous system of two coupled single-mode cavities, one of
which interacts with a multimode resonator. We demonstrate that for small
coupling strengths between single-mode cavities, the Loschmidt echo oscillates
periodically in time and spontaneous breaking of time translation symmetry
takes place. The Loschmidt echo behavior is an indication of the non-ergodic
nature of the system when its evolution is time-reversible. In this regime, the
system retains a memory of the initial state under the action of small
perturbations. This behavior reveals the presence of a time crystalline order
in the autonomous system. An increase in the coupling strength leads to a
transition from periodic oscillations to an exponential decay in time of the
Loschmidt echo. This corresponds to the transition from non-ergodic to ergodic
behavior in the system. We demonstrate that the transition from non-ergodic to
ergodic system's behavior can also be observed when changing the number of
degrees of freedom in the resonator, which is achieved by changing its length.",http://arxiv.org/abs/2501.17435v1
Accelerated DC loadflow solver for topology optimization,2025-01-29T09:57:53Z,"Nico Westerbeck, Joost van Dijk, Jan Viebahn, Christian Merz, Dirk Witthaut","We present a massively parallel solver that accelerates DC loadflow
computations for power grid topology optimization tasks. Our approach leverages
low-rank updates of the Power Transfer Distribution Factors (PTDFs) to
represent substation splits, line outages, and reconfigurations without ever
refactorizing the system. Furthermore, we implement the core routines on
Graphics Processing Units (GPUs), thereby exploiting their high-throughput
architecture for linear algebra. A two-level decomposition separates changes in
branch topology from changes in nodal injections, enabling additional speed-ups
by an in-the-loop brute force search over injection variations at minimal
additional cost. We demonstrate billion-loadflow-per-second performance on
power grids of varying sizes in workload settings which are typical for
gradient-free topology optimization such as Reinforcement Learning or Quality
Diversity methods. While adopting the DC approximation sacrifices some accuracy
and prohibits the computation of voltage magnitudes, we show that this
sacrifice unlocks new scales of computational feasibility, offering a powerful
tool for large-scale grid planning and operational topology optimization.",http://arxiv.org/abs/2501.17529v1
"Effects of oxidation and impurities in lithium surfaces on the emitting
  wall plasma sheath",2025-01-29T14:52:33Z,"Kolter Bradshaw, Ammar Hakim, Bhuvana Srinivasan","Use of lithium as a surface coating in fusion devices improves plasma
performance, but the change in wall properties affects the secondary electron
emission properties of the material. Lithium oxidizes easily, which drives the
emission yield well above unity. We present here simulations demonstrating the
change in sheath structure from monotonic to the nonmonotonic space-charge
limited sheath using an energy-dependent data-driven emission model which
self-consistently captures both secondary emission and backscattering
populations. Increased secondary electron emission from the material has
ramifications for the degradation and erosion of the wall. Results shows that
the oxidation leads to an increased electron flux into the wall, and a reduced
ion flux. The net transfer of energy to the surface is significantly greater
for the oxidized case than for the pure lithium case. High reflection rates of
low-energy backscattered particles leads to a high re-emission rate at the
wall.",http://arxiv.org/abs/2501.17686v1
"Single crystal growth and physical characterization to fine tune
  YbIn1-xTxCu4 (T = Au, Ag) towards the critical endpoint of the valence
  transition",2025-01-29T15:31:14Z,"Michelle Ocker, Bereket Ghebretinsae, Jan-Niklas Zimmermann, Sophie Würtele, Bernd Wolf, Alexandr Virovets, Michael Lang, Kristin Kliemt, Cornelius Krellner","Pure as well as Ag- and Au-substituted YbInCu$_4$ single crystals were
structurally and chemically characterized and investigated by means of heat
capacity, magnetization, resistivity and ultrasonic measurements. We studied
the influence of different compositions of the initial melt as well as of Au
and Ag substitutions on the valence change and investigated whether this change
occurs via a first-order phase transition or via crossover. We constructed a
phase diagram of YbInCu$_4$ as a function of various substitutions and show
that the position of the critical endpoint of the valence transition depends on
the substituent and on the conditions under which the samples were grown.
Multiple thermal cycles through the first-order transition lead to a
significant modification of the physical properties which clearly demonstrated
the influence of defects in substituted YbInCu$_4$.",http://arxiv.org/abs/2501.17714v1
Graviton loops and negativity,2025-01-29T19:18:11Z,"Cyuan-Han Chang, Julio Parra-Martinez","We revisit dispersive bounds on Wilson coefficients of scalar effective field
theories (EFT) coupled to gravity in various spacetime dimensions, by computing
the contributions from graviton loops to the corresponding sum rules at low
energies. Fixed-momentum-transfer dispersion relations are often ill-behaved
due to forward singularities arising from loop-level graviton exchange, making
naive positivity bounds derived from them unreliable. Instead, we perform a
careful analysis using crossing-symmetric dispersion relations, and compute the
one-loop corrections to the bounds on EFT coefficients. We find that including
the graviton loops generically allows for negativity of Wilson coefficients by
an amount suppressed by powers of Newton's constant, $G$. The exception are the
few couplings that dominate over (or are degenerate with) the graviton loops at
low energies. In $D=4$, we observe that assuming that the eikonal formula
captures the correct forward behavior of the amplitude at all orders in $G$,
and for energies of the order of the EFT cutoff, yields bounds free of
logarithmic infrared divergences.",http://arxiv.org/abs/2501.17949v1
"Scattering approach to diffusion quantifies axonal damage in brain
  injury",2025-01-30T06:31:04Z,"Ali Abdollahzadeh, Ricardo Coronado-Leija, Hong-Hsi Lee, Alejandra Sierra, Els Fieremans, Dmitry S. Novikov","Early diagnosis and noninvasive monitoring of neurological disorders require
sensitivity to elusive cellular-level alterations that occur much earlier than
volumetric changes observable with the millimeter-resolution of medical imaging
modalities. Morphological changes in axons, such as axonal varicosities or
beadings, are observed in neurological disorders, as well as in development and
aging. Here, we reveal the sensitivity of time-dependent diffusion MRI (dMRI)
to axonal morphology at the micrometer scale. Scattering theory uncovers the
two parameters that determine the diffusive dynamics of water in axons: the
average reciprocal cross-section and the variance of long-range cross-sectional
fluctuations. This theoretical development allowed us to predict dMRI metrics
sensitive to axonal alterations across tens of thousands of axons in seconds
rather than months of simulations in a rat model of traumatic brain injury. Our
approach bridges the gap between micrometers and millimeters in resolution,
offering quantitative, objective biomarkers applicable to a broad spectrum of
neurological disorders.",http://arxiv.org/abs/2501.18167v1
"Elastic constants of single-crystalline NiTi studied by resonant
  ultrasound spectroscopy",2025-01-30T15:20:49Z,"Lucie Bodnárová, Michaela Janovská, Martin Ševčík, Miroslav Frost, Lukáš Kadeřávek, Jaromír Kopeček, Hanuš Seiner, Petr Sedlák, -","Contactless, laser-based resonant ultrasound spectroscopy was utilized to
monitor changes in elastic properties in single-crystalline NiTi shape memory
alloy. It was observed that the elastic behavior of the temperature-induced
B19$^\prime$ martensite adopts the symmetry elements of the parent austenite
phase, and thus, the changes over the transformation temperature can be
represented by the temperature evolution of three cubic elastic coefficients.
The experiments confirm that the transition during the cooling run is preceded
by pronounced softening of the $c_{44}$ elastic coefficient, which leads to
nearly complete vanishing of elastic anisotropy prior to the transition. Below
the transition, this coefficient remains soft, and the character of anisotropy
switches from $c_{44}/c^\prime>1$ to $c_{44}/c^\prime<1$. We rationalize this
behavior from the mechanical instability of the B19$^\prime$ lattice with
respect to shears along the (001)$_{B19^\prime}$ plane, which is known from
first-principles calculations.",http://arxiv.org/abs/2501.18421v1
"Motion Diffusion Autoencoders: Enabling Attribute Manipulation in Human
  Motion Demonstrated on Karate Techniques",2025-01-30T20:13:52Z,"Anthony Mendil, Felix Putze","Attribute manipulation deals with the problem of changing individual
attributes of a data point or a time series, while leaving all other aspects
unaffected. This work focuses on the domain of human motion, more precisely
karate movement patterns. To the best of our knowledge, it presents the first
success at manipulating attributes of human motion data. One of the key
requirements for achieving attribute manipulation on human motion is a suitable
pose representation. Therefore, we design a novel rotation-based pose
representation that enables the disentanglement of the human skeleton and the
motion trajectory, while still allowing an accurate reconstruction of the
original anatomy. The core idea of the manipulation approach is to use a
transformer encoder for discovering high-level semantics, and a diffusion
probabilistic model for modeling the remaining stochastic variations. We show
that the embedding space obtained from the transformer encoder is semantically
meaningful and linear. This enables the manipulation of high-level attributes,
by discovering their linear direction of change in the semantic embedding space
and moving the embedding along said direction. The code and data are available
at https://github.com/anthony-mendil/MoDiffAE.",http://arxiv.org/abs/2501.18729v1
"Magnetizing weak links by time-dependent spin-orbit interactions:
  momentum conserving and non-conserving processes",2025-01-31T08:46:18Z,"Debashree Chowdhury, O. Entin-Wohlman, A. Aharony, R. I. Shekhter, M. Jonson","Rashba spin-orbit interactions generated by time-dependent electric fields
acting on weak links (that couple together non-magnetic macroscopic leads) can
magnetize the junction. The Rashba spin-orbit interaction that affects the
spins of electrons tunneling through the weak links changes their momentum
concomitantly. We establish the connection between the magnetization flux
induced by processes that conserve the momentum and the magnetization created
by tunneling events that do not. Control of the induced magnetization can be
achieved by tuning the polarization of the AC electric field responsible for
the spin-orbit Rashba interaction (e.g., from being circular to linear), by
changing the applied bias voltage, and by varying the degree of a gate
voltage-induced asymmetry of the device.",http://arxiv.org/abs/2501.18961v1
"Reinforcement Learning on Reconfigurable Hardware: Overcoming Material
  Variability in Laser Material Processing",2025-01-31T12:51:55Z,"Giulio Masinelli, Chang Rajani, Patrik Hoffmann, Kilian Wasmer, David Atienza","Ensuring consistent processing quality is challenging in laser processes due
to varying material properties and surface conditions. Although some approaches
have shown promise in solving this problem via automation, they often rely on
predetermined targets or are limited to simulated environments. To address
these shortcomings, we propose a novel real-time reinforcement learning
approach for laser process control, implemented on a Field Programmable Gate
Array to achieve real-time execution. Our experimental results from laser
welding tests on stainless steel samples with a range of surface roughnesses
validated the method's ability to adapt autonomously, without relying on reward
engineering or prior setup information. Specifically, the algorithm learned the
correct power profile for each unique surface characteristic, demonstrating
significant improvements over hand-engineered optimal constant power strategies
-- up to 23% better performance on rougher surfaces and 7% on mixed surfaces.
This approach represents a significant advancement in automating and optimizing
laser processes, with potential applications across multiple industries.",http://arxiv.org/abs/2501.19102v1
"A Three-Branch Checks-and-Balances Frameworkfor Context-Aware Ethical
  Alignment of Large Language Models",2025-01-31T19:41:28Z,Edward Y. Chang,"This paper introduces a three-branch checks-and-balances framework for
ethical alignment of Large Language Models (LLMs), inspired by governmental
systems. It implements three independent yet interacting components: LLMs as
the executive branch for knowledge generation, DIKE as the legislative branch
establishing ethical guardrails, and ERIS as the judicial branch for contextual
interpretation. The adversarial DIKE-ERIS duality enables adaptation to diverse
cultural contexts while upholding consistent ethical principles. This
architecture addresses limitations of reinforcement learning with human
feedback (RLHF) by providing interpretable, adaptable, and culturally-aware
ethical reasoning. Through self-supervised learning and adversarial testing,
our framework demonstrates how emotional modeling can guide linguistic
behaviors toward ethical outcomes while preserving independence across
knowledge generation, ethical oversight, and contextual interpretation.",http://arxiv.org/abs/2502.00136v1
Model Successor Functions,2025-01-31T22:27:09Z,"Yingshan Chang, Yonatan Bisk","The notion of generalization has moved away from the classical one defined in
statistical learning theory towards an emphasis on out-of-domain generalization
(OODG). Recently, there is a growing focus on inductive generalization, where a
progression of difficulty implicitly governs the direction of domain shifts. In
inductive generalization, it is often assumed that the training data lie in the
easier side, while the testing data lie in the harder side. The challenge is
that training data are always finite, but a learner is expected to infer an
inductive principle that could be applied in an unbounded manner. This emerging
regime has appeared in the literature under different names, such as
length/logical/algorithmic extrapolation, but a formal definition is lacking.
This work provides such a formalization that centers on the concept of model
successors. Then we outline directions to adapt well-established techniques
towards the learning of model successors. This work calls for restructuring of
the research discussion around inductive generalization from fragmented
task-centric communities to a more unified effort, focused on universal
properties of learning and computation.",http://arxiv.org/abs/2502.00197v1
K Nearest Neighbor-Guided Trajectory Similarity Learning,2025-02-01T02:52:43Z,"Yanchuan Chang, Xu Cai, Christian S. Jensen, Jianzhong Qi","Trajectory similarity is fundamental to many spatio-temporal data mining
applications. Recent studies propose deep learning models to approximate
conventional trajectory similarity measures, exploiting their fast inference
time once trained. Although efficient inference has been reported, challenges
remain in similarity approximation accuracy due to difficulties in trajectory
granularity modeling and in exploiting similarity signals in the training data.
To fill this gap, we propose TSMini, a highly effective trajectory similarity
model with a sub-view modeling mechanism capable of learning multi-granularity
trajectory patterns and a k nearest neighbor-based loss that guides TSMini to
learn not only absolute similarity values between trajectories but also their
relative similarity ranks. Together, these two innovations enable highly
accurate trajectory similarity approximation. Experiments show that TSMini can
outperform the state-of-the-art models by 22% in accuracy on average when
learning trajectory similarity measures.",http://arxiv.org/abs/2502.00285v1
Mitigating Heterogeneous Token Overfitting in LLM Knowledge Editing,2025-02-02T00:10:51Z,"Tianci Liu, Zihan Dong, Linjun Zhang, Haoyu Wang, Jing Gao","Large language models (LLMs) have achieved remarkable performance on various
natural language tasks. However, they are trained on static corpora and their
knowledge can become outdated quickly in the fast-changing world. This
motivates the development of knowledge editing (KE) to update specific
knowledge in LLMs without changing unrelated others or compromising their
pre-trained capabilities. Previous efforts sought to update a small amount of
parameters of a LLM and proved effective for making selective updates.
Nonetheless, the edited LLM often exhibits degraded ability to reason about the
new knowledge. In this work, we identify a key issue: heterogeneous token
overfitting (HTO), where the LLM overfits different tokens in the provided
knowledge at varying rates. To tackle this, we propose OVERTONE, a token-level
smoothing method that mitigates HTO by adaptively refining the target
distribution. Theoretically, OVERTONE offers better parameter updates with
negligible computation overhead. It also induces an implicit DPO but does not
require preference data pairs. Extensive experiments across four editing
methods, two LLMs, and diverse scenarios demonstrate the effectiveness and
versatility of our method.",http://arxiv.org/abs/2502.00602v1
Optimal local certification on graphs of bounded pathwidth,2025-02-02T05:28:08Z,"Dan Alden Baterisna, Yi-Jun Chang","We present proof labeling schemes for graphs with bounded pathwidth that can
decide any graph property expressible in monadic second-order (MSO) logic using
$O(\log n)$-bit vertex labels. Examples of such properties include planarity,
Hamiltonicity, $k$-colorability, $H$-minor-freeness, admitting a perfect
matching, and having a vertex cover of a given size.
  Our proof labeling schemes improve upon a recent result by Fraigniaud,
Montealegre, Rapaport, and Todinca (Algorithmica 2024), which achieved the same
result for graphs of bounded treewidth but required $O(\log^2 n)$-bit labels.
Our improved label size $O(\log n)$ is optimal, as it is well-known that any
proof labeling scheme that accepts paths and rejects cycles requires labels of
size $\Omega(\log n)$.
  Our result implies that graphs with pathwidth at most $k$ can be certified
using $O(\log n)$-bit labels for any fixed constant $k$. Applying the Excluding
Forest Theorem of Robertson and Seymour, we deduce that the class of
$F$-minor-free graphs can be certified with $O(\log n)$-bit labels for any
fixed forest $F$, thereby providing an affirmative answer to an open question
posed by Bousquet, Feuilloley, and Pierron (Journal of Parallel and Distributed
Computing 2024).",http://arxiv.org/abs/2502.00676v1
Trade Dynamics of the Global Dry Bulk Shipping Network,2025-02-02T19:01:22Z,"Yan Li, Carol Alexander, Michael Coulon, Istvan Kiss","This study investigates the inherently random structures of dry bulk shipping
networks, often likened to a taxi service, and identifies the underlying trade
dynamics that contribute to this randomness within individual cargo
sub-networks. By analysing micro-level trade flow data from 2015 to 2023, we
explore the evolution of dry commodity networks, including grain, coal, and
iron ore, and suggest that the Giant Strongly Connected Components exhibit
small-world phenomena, indicative of efficient bilateral trade. The significant
heterogeneity of in-degree and out-degree within these sub-networks, primarily
driven by importing ports, underscores the complexity of their dynamics. Our
temporal analysis shows that while the Covid-19 pandemic profoundly impacted
the coal network, the Ukraine conflict significantly altered the grain network,
resulting in changes in community structures. Notably, grain sub-networks
display periodic changes, suggesting distinct life cycles absent in coal and
iron ore networks. These findings illustrate that the randomness in dry bulk
shipping networks is a reflection of real-world trade dynamics, providing
valuable insights for stakeholders in navigating and predicting network
behaviours.",http://arxiv.org/abs/2502.00877v1
Structured Pneumatic Fingerpads for Actively Tunable Grip Friction,2025-02-02T21:29:23Z,"Katherine Allison, Jonathan Kelly, Benjamin Hatton","Grip surfaces with tunable friction can actively modify contact conditions,
enabling transitions between higher- and lower-friction states for grasp
adjustment. Friction can be increased to grip securely and then decreased to
gently release (e.g., for handovers) or manipulate in-hand. Recent
friction-tuning surface designs using soft pneumatic chambers show good control
over grip friction; however, most require complex fabrication processes and/or
custom gripper hardware. We present a practical structured fingerpad design for
friction tuning that uses less than \$1 USD of materials, takes only seconds to
repair, and is easily adapted to existing grippers. Our design uses surface
morphology changes to tune friction. The fingerpad is actuated by pressurizing
its internal chambers, thereby deflecting its flexible grip surface out from or
into these chambers. We characterize the friction-tuning capabilities of our
design by measuring the shear force required to pull an object from a gripper
equipped with two independently actuated fingerpads. Our results show that
varying actuation pressure and timing changes the magnitude of friction forces
on a gripped object by up to a factor of 2.8. We demonstrate additional
features including macro-scale interlocking behaviour and pressure-based object
detection.",http://arxiv.org/abs/2502.00926v1
"Revisiting turbulent properties of solar convection with 3D radiative
  hydrodynamic modeling",2025-02-03T00:55:40Z,"Irina N. Kitiashvili, Alan A. Wray","We discuss the turbulent structure and dynamics of the upper solar convection
zone using a 3D radiative hydrodynamic simulation model at 45 degrees latitude.
The model reveals the self-formation of meridional flows, the leptocline, and
the radial differential rotation. Unlike previous studies, the model shows a
complex variation of the characteristic scales of turbulent flows with depth.
In particular, an increase in the characteristic convective scale is trackable
within an individual snapshot up to a depth of 7 Mm, near the bottom of the
hydrogen ionization zone, where turbulent flows become weaker and more
homogeneous. However, the turbulent spectra show an increase in scale with
depth and a qualitative change in convective patterns below 7 Mm (near the
bottom of the leptocline), suggesting changes in the diffusivity properties and
energy exchange among different scales.",http://arxiv.org/abs/2502.00974v1
Dissipative quantum phase transitions monitored by current fluctuations,2025-02-03T08:08:08Z,"Masataka Matsumoto, Matteo Baggioli, Zi Cai","Dissipative phase transitions (DPT) are defined by sudden changes in the
physical properties of nonequilibrium open quantum systems and they present
characteristics that have no analogue in closed and thermal systems. Several
methods to detect and characterize DPT have been suggested in the literature,
the most famous of which -- the $\textit{Liouvillian gap}$ -- can be derived
from a spectral analysis of the Liouvillian super-operator that governs the
complex interplay between coherent and dissipative dynamics. Here, we consider
the $\textit{output current}$, defined as the average total quantum jumps per
unit time between the open quantum system and the environment. We propose that
output current fluctuations, and in particular their dynamical correlations,
their power spectrum, and their characteristic timescale can provide valuable
information about DPT, confirming a dramatic change of behavior at the critical
point. We validate our proposal using the dissipative XYZ model and the
nonlinear driven-dissipative Kerr model, showing good agreement with previous
estimates of the location of the critical point. Compared to previous
approaches, our proposal could be already experimentally tested in optical
systems, providing a practical method to detect criticality in quantum open
systems.",http://arxiv.org/abs/2502.01136v1
"Boosting Graph Robustness Against Backdoor Attacks: An Over-Similarity
  Perspective",2025-02-03T11:41:42Z,"Chang Liu, Hai Huang, Yujie Xing, Xingquan Zuo","Graph Neural Networks (GNNs) have achieved notable success in tasks such as
social and transportation networks. However, recent studies have highlighted
the vulnerability of GNNs to backdoor attacks, raising significant concerns
about their reliability in real-world applications. Despite initial efforts to
defend against specific graph backdoor attacks, existing defense methods face
two main challenges: either the inability to establish a clear distinction
between triggers and clean nodes, resulting in the removal of many clean nodes,
or the failure to eliminate the impact of triggers, making it challenging to
restore the target nodes to their pre-attack state. Through empirical analysis
of various existing graph backdoor attacks, we observe that the triggers
generated by these methods exhibit over-similarity in both features and
structure. Based on this observation, we propose a novel graph backdoor defense
method SimGuard. We first utilizes a similarity-based metric to detect triggers
and then employs contrastive learning to train a backdoor detector that
generates embeddings capable of separating triggers from clean nodes, thereby
improving detection efficiency. Extensive experiments conducted on real-world
datasets demonstrate that our proposed method effectively defends against
various graph backdoor attacks while preserving performance on clean nodes. The
code will be released upon acceptance.",http://arxiv.org/abs/2502.01272v1
"Identification and Optimization of High-Performance Passing Networks in
  Football",2025-02-03T15:31:43Z,Andres Chacoma,"This study explores the relationship between the performance of a football
team and the topological parameters of temporal passing networks. To achieve
this, we propose a method to identify moments of high and low team performance
based on the analysis of match events. This approach enables the construction
of sets of temporal passing networks associated with each performance context.
By analyzing topological metrics such as clustering, eigenvector centrality,
and betweenness across both sets, significant structural differences were
identified between moments of high and low performance. These differences
reflect changes in the interaction dynamics among players and, consequently, in
the team's playing system. Subsequently, a logistic regression model was
employed to classify high- and low-performance networks. The analysis of the
model coefficients identified which metrics need to be adjusted to promote the
emergence of structures associated with better performance. This framework
provides quantitative tools to guide tactical decisions and optimize playing
dynamics. Finally, the proposed method was applied to address the ``blocked
player"" problem, optimizing passing relationships to minimize the emergence of
structures associated with low performance, thereby ensuring more robust
dynamics against contextual changes.",http://arxiv.org/abs/2502.01444v1
"Faster Adaptive Optimization via Expected Gradient Outer Product
  Reparameterization",2025-02-03T18:26:35Z,"Adela DePavia, Vasileios Charisopoulos, Rebecca Willett","Adaptive optimization algorithms -- such as Adagrad, Adam, and their variants
-- have found widespread use in machine learning, signal processing and many
other settings. Several methods in this family are not rotationally
equivariant, meaning that simple reparameterizations (i.e. change of basis) can
drastically affect their convergence. However, their sensitivity to the choice
of parameterization has not been systematically studied; it is not clear how to
identify a ""favorable"" change of basis in which these methods perform best. In
this paper we propose a reparameterization method and demonstrate both
theoretically and empirically its potential to improve their convergence
behavior. Our method is an orthonormal transformation based on the expected
gradient outer product (EGOP) matrix, which can be approximated using either
full-batch or stochastic gradient oracles. We show that for a broad class of
functions, the sensitivity of adaptive algorithms to choice-of-basis is
influenced by the decay of the EGOP matrix spectrum. We illustrate the
potential impact of EGOP reparameterization by presenting empirical evidence
and theoretical arguments that common machine learning tasks with ""natural""
data exhibit EGOP spectral decay.",http://arxiv.org/abs/2502.01594v1
"Query-Based and Unnoticeable Graph Injection Attack from Neighborhood
  Perspective",2025-02-04T02:11:57Z,"Chang Liu, Hai Huang, Yujie Xing, Xingquan Zuo","The robustness of Graph Neural Networks (GNNs) has become an increasingly
important topic due to their expanding range of applications. Various attack
methods have been proposed to explore the vulnerabilities of GNNs, ranging from
Graph Modification Attacks (GMA) to the more practical and flexible Graph
Injection Attacks (GIA). However, existing methods face two key challenges: (i)
their reliance on surrogate models, which often leads to reduced attack
effectiveness due to structural differences and prior biases, and (ii) existing
GIA methods often sacrifice attack success rates in undefended settings to
bypass certain defense models, thereby limiting their overall effectiveness. To
overcome these limitations, we propose QUGIA, a Query-based and Unnoticeable
Graph Injection Attack. QUGIA injects nodes by first selecting edges based on
victim node connections and then generating node features using a Bayesian
framework. This ensures that the injected nodes are similar to the original
graph nodes, implicitly preserving homophily and making the attack more
unnoticeable. Unlike previous methods, QUGIA does not rely on surrogate models,
thereby avoiding performance degradation and achieving better generalization.
Extensive experiments on six real-world datasets with diverse characteristics
demonstrate that QUGIA achieves unnoticeable attacks and outperforms
state-of-the-art attackers. The code will be released upon acceptance.",http://arxiv.org/abs/2502.01936v1
CASIM: Composite Aware Semantic Injection for Text to Motion Generation,2025-02-04T07:22:07Z,"Che-Jui Chang, Qingze Tony Liu, Honglu Zhou, Vladimir Pavlovic, Mubbasir Kapadia","Recent advances in generative modeling and tokenization have driven
significant progress in text-to-motion generation, leading to enhanced quality
and realism in generated motions. However, effectively leveraging textual
information for conditional motion generation remains an open challenge. We
observe that current approaches, primarily relying on fixed-length text
embeddings (e.g., CLIP) for global semantic injection, struggle to capture the
composite nature of human motion, resulting in suboptimal motion quality and
controllability. To address this limitation, we propose the Composite Aware
Semantic Injection Mechanism (CASIM), comprising a composite-aware semantic
encoder and a text-motion aligner that learns the dynamic correspondence
between text and motion tokens. Notably, CASIM is model and
representation-agnostic, readily integrating with both autoregressive and
diffusion-based methods. Experiments on HumanML3D and KIT benchmarks
demonstrate that CASIM consistently improves motion quality, text-motion
alignment, and retrieval scores across state-of-the-art methods. Qualitative
analyses further highlight the superiority of our composite-aware approach over
fixed-length semantic injection, enabling precise motion control from text
prompts and stronger generalization to unseen text inputs.",http://arxiv.org/abs/2502.02063v1
"Neural network potential molecular dynamics simulations of
  (La,Ce,Pr,Nd)0.95(Mg,Zn,Pb,Cd,Ca,Sr,Ba)0.05F2.95",2025-02-04T15:26:13Z,Yoyo Hinuma,"Tysonite structure fluorides doped with divalent cations, represented by
Ce0.95Ca0.05F2.95, are a class of good F- ion conductors together with
fluorite-structured compounds. Computational understanding of the F- conduction
process is difficult because of the complicated interactions between three
symmetrically distinct F sites and the experimentally observed change in the F
diffusion mechanism slightly above room temperature, effectively making first
principles molecular dynamics (FP-MD) simulations, which are often conducted
well above the transition temperature, useless when analyzing behavior below
the transition point. Neural network potential (NNP) MD simulations showed that
the F diffusion coefficient is higher when the divalent dopant cation size is
similar to the trivalent cation size. The diffusion behavior of F in different
sites changes at roughly 500 K in Ce0.95Ca0.05F2.95 because only the F1 site
sublattice contributes to F diffusion below this temperature but the remaining
F2 and F3 sublattices becomes gradually active above this temperature. The
paradox of higher diffusion coefficients in CeF3-based compounds than similar
LaF3-based compounds even though the lattice parameters are larger in the
latter may be caused by a shallower potential of Ce and F in CeF3 compared to
the LaF3 counterparts.",http://arxiv.org/abs/2502.02408v1
"Improving volatility forecasts of the Nikkei 225 stock index using a
  realized EGARCH model with realized and realized range-based volatilities",2025-02-04T20:23:49Z,Yaming Chang,"This paper applies the realized exponential generalized autoregressive
conditional heteroskedasticity (REGARCH) model to analyze the Nikkei 225 index
from 2010 to 2017, utilizing realized variance (RV) and realized range-based
volatility (RRV) as high-frequency measures of volatility. The findings show
that REGARCH models outperform standard GARCH family models in both in-sample
fitting and out-of-sample forecasting, driven by the dynamic information
embedded in high-frequency realized measures. Incorporating multiple realized
measures within a joint REGARCH framework further enhances model performance.
Notably, RRV demonstrates superior predictive power compared to RV, as
evidenced by improvements in forecast accuracy metrics. Moreover, the
forecasting results remain robust under both rolling-window and recursive
evaluation schemes.",http://arxiv.org/abs/2502.02695v2
"Concentration on the Boundary and Sign-Changing Solutions for a Slightly
  Subcritical Biharmonic Problem",2025-02-04T22:23:05Z,"Salomón Alarcón, Jorge Faya, Carolina Rey","We consider the fourth-order nonlinear elliptic problem: \begin{equation*}
\begin{array}{ll}
  \Delta(a(x)\Delta u) = a(x) \left\vert u \right\vert^{p-2-\epsilon} u \
\text{ in } \ \Omega,
  \hspace{0.6cm} u = 0 \ \text{ on } \ \partial \Omega,
  \hspace{0.6cm} \Delta u = 0 \ \text{ on } \ \partial \Omega,
  \end{array}\end{equation*} where $\Omega$ is a smooth, bounded domain in
$\mathbb{R}^N$ with $N \geq 5$. Here, $p := \frac{2N}{N-4}$ is the Sobolev
critical exponent for the embedding $H^2 \cap H_0^1(\Omega) \hookrightarrow
L^p(\Omega)$, and $a \in C^2(\overline{\Omega})$ is a strictly positive
function on $\overline{\Omega}$.
  We establish sufficient conditions on the function $a$ and the domain
$\Omega$ for this problem to admit both positive and sign-changing solutions
with an explicit asymptotic profile. These solutions concentrate and blow up at
a point on the boundary $\partial \Omega$ as $\epsilon \to 0$. The proofs of
the main results rely on the Lyapunov-Schmidt finite-dimensional reduction
method.",http://arxiv.org/abs/2502.02745v1
"CAMI: A Counselor Agent Supporting Motivational Interviewing through
  State Inference and Topic Exploration",2025-02-05T01:09:09Z,"Yizhe Yang, Palakorn Achananuparp, Heyan Huang, Jing Jiang, Kit Phey Leng, Nicholas Gabriel Lim, Cameron Tan Shi Ern, Ee-peng Lim","Conversational counselor agents have become essential tools for addressing
the rising demand for scalable and accessible mental health support. This paper
introduces CAMI, a novel automated counselor agent grounded in Motivational
Interviewing (MI) -- a client-centered counseling approach designed to address
ambivalence and facilitate behavior change. CAMI employs a novel STAR
framework, consisting of client's state inference, motivation topic
exploration, and response generation modules, leveraging large language models
(LLMs). These components work together to evoke change talk, aligning with MI
principles and improving counseling outcomes for clients from diverse
backgrounds. We evaluate CAMI's performance through both automated and manual
evaluations, utilizing simulated clients to assess MI skill competency,
client's state inference accuracy, topic exploration proficiency, and overall
counseling success. Results show that CAMI not only outperforms several
state-of-the-art methods but also shows more realistic counselor-like behavior.
Additionally, our ablation study underscores the critical roles of state
inference and topic exploration in achieving this performance.",http://arxiv.org/abs/2502.02807v1
"A Systematic Approach for Assessing Large Language Models' Test Case
  Generation Capability",2025-02-05T03:51:44Z,"Hung-Fu Chang, Mohammad Shokrolah Shirazi","Software testing ensures the quality and reliability of software products,
but manual test case creation is labor-intensive. With the rise of large
language models (LLMs), there is growing interest in unit test creation with
LLMs. However, effective assessment of LLM-generated test cases is limited by
the lack of standardized benchmarks that comprehensively cover diverse
programming scenarios. To address the assessment of LLM's test case generation
ability and lacking dataset for evaluation, we propose the Generated Benchmark
from Control-Flow Structure and Variable Usage Composition (GBCV) approach,
which systematically generates programs used for evaluating LLMs' test
generation capabilities. By leveraging basic control-flow structures and
variable usage, GBCV provides a flexible framework to create a spectrum of
programs ranging from simple to complex. Because GPT-4o and GPT-3-Turbo are
publicly accessible models, to present real-world regular user's use case, we
use GBCV to assess LLM performance on them. Our findings indicate that GPT-4o
performs better on complex program structures, while all models effectively
detect boundary values in simple conditions but face challenges with arithmetic
computations. This study highlights the strengths and limitations of LLMs in
test generation, provides a benchmark framework, and suggests directions for
future improvement.",http://arxiv.org/abs/2502.02866v1
"Improve Decoding Factuality by Token-wise Cross Layer Entropy of Large
  Language Models",2025-02-05T14:19:52Z,"Jialiang Wu, Yi Shen, Sijia Liu, Yi Tang, Sen Song, Xiaoyi Wang, Longjun Cai","Despite their impressive capacities, Large language models (LLMs) often
struggle with the hallucination issue of generating inaccurate or fabricated
content even when they possess correct knowledge. In this paper, we extend the
exploration of the correlation between hidden-state prediction changes and
output factuality into a deeper, token-wise level. Based on the insights , we
propose cross-layer Entropy eNhanced Decoding (END), a decoding method that
mitigates hallucinations without requiring extra training. END leverages inner
probability changes across layers to individually quantify the factual
knowledge required for each candidate token, and adjusts the final predicting
distribution to prioritize tokens with higher factuality. Experiments on both
hallucination and QA benchmarks demonstrate that END significantly enhances the
truthfulness and informativeness of generated content while maintaining robust
QA accuracy. Moreover, our work provides a deeper perspective on understanding
the correlations between inherent knowledge and output factuality.",http://arxiv.org/abs/2502.03199v1
"Temporal multilayer structures for designing higher-order transfer
  functions using time-varying metamaterials",2025-02-05T15:12:20Z,"Davide Ramaccia, Andrea Alu, Alessandro Toscano, Filiberto Bilotti","Temporal metamaterials are artificial materials whose electromagnetic
properties change over time. In analogy with spatial media and metamaterials,
where their properties change smoothly or abruptly over space, temporal
metamaterials can exhibit a smooth variation over time, realizing a temporal
non-homogeneous medium, or a stepwise transition, realizing the temporal
version of dielectric slabs or multilayer structures. In this Letter, we focus
our attention on temporal multilayer structures, and we propose the synthesis
of higher-order transfer functions by modeling the wave propagation through a
generalized temporal multilayer structure, consisting of a cascade over time of
different media. The tailoring of the scattering response of temporal structure
as a function of frequency is presented, deriving the corresponding scattering
coefficients for a properly designed set of medium properties, i.e.,
permittivity and permeability, and application time, in analogy with what is
typically done in optical and electromagnetic spatial multilayered structures.
This allows us to design novel electromagnetic and optical devices with
higher-order transfer functions by exploiting the temporal dimension instead of
the spatial one.",http://arxiv.org/abs/2502.03255v1
"Adaptive Variational Inference in Probabilistic Graphical Models: Beyond
  Bethe, Tree-Reweighted, and Convex Free Energies",2025-02-05T16:33:59Z,"Harald Leisenberger, Franz Pernkopf","Variational inference in probabilistic graphical models aims to approximate
fundamental quantities such as marginal distributions and the partition
function. Popular approaches are the Bethe approximation, tree-reweighted, and
other types of convex free energies. These approximations are efficient but can
fail if the model is complex and highly interactive. In this work, we analyze
two classes of approximations that include the above methods as special cases:
first, if the model parameters are changed; and second, if the entropy
approximation is changed. We discuss benefits and drawbacks of either approach,
and deduce from this analysis how a free energy approximation should ideally be
constructed. Based on our observations, we propose approximations that
automatically adapt to a given model and demonstrate their effectiveness for a
range of difficult problems.",http://arxiv.org/abs/2502.03341v1
"Discrete GCBF Proximal Policy Optimization for Multi-agent Safe Optimal
  Control",2025-02-05T21:51:47Z,"Songyuan Zhang, Oswin So, Mitchell Black, Chuchu Fan","Control policies that can achieve high task performance and satisfy safety
constraints are desirable for any system, including multi-agent systems (MAS).
One promising technique for ensuring the safety of MAS is distributed control
barrier functions (CBF). However, it is difficult to design distributed
CBF-based policies for MAS that can tackle unknown discrete-time dynamics,
partial observability, changing neighborhoods, and input constraints,
especially when a distributed high-performance nominal policy that can achieve
the task is unavailable. To tackle these challenges, we propose DGPPO, a new
framework that simultaneously learns both a discrete graph CBF which handles
neighborhood changes and input constraints, and a distributed high-performance
safe policy for MAS with unknown discrete-time dynamics. We empirically
validate our claims on a suite of multi-agent tasks spanning three different
simulation engines. The results suggest that, compared with existing methods,
our DGPPO framework obtains policies that achieve high task performance
(matching baselines that ignore the safety constraints), and high safety rates
(matching the most conservative baselines), with a constant set of
hyperparameters across all environments.",http://arxiv.org/abs/2502.03640v1
"Nonlinearity and Quantumness in Thermodynamics: From Principles to
  Technologies",2025-02-06T05:37:25Z,"Gershon Kurizki, Nilakantha Meher, Tomáš Opatrný","The impact of quantum mechanics on thermodynamics, particularly on the
principles and designs of heat machines (HM), has been limited by the
incompatibility of quantum coherent evolution with the dissipative, open-system
nature of all existing HM and their basic structure, which has not been
radically changed since Carnot. We have recently proposed a paradigm change
whereby conventional HM functionality is replaced by that of few-mode coherent,
closed systems with nonlinear, e.g. cross-Kerr, inter-mode couplings. These
couplings allow us to coherently filter incident thermal noise, transforming it
into a resource of work and information. Current technological advances enable
heat engines, noise sensors or microscopes based on such designs to operate
with thermal noise sources of few photons. This paradigm shift opens a path
towards radically new understanding and exploitation of the relation between
coherent, quantum or classical, evolution and thermodynamic behavior.",http://arxiv.org/abs/2502.03791v1
"Inhibition and promotion of quasi-uniform to filamentary discharge
  transition in negative repetitive nanosecond surface dielectric barrier
  discharge",2025-02-06T10:00:11Z,"Zhang Yaqi, Guo Yulin, Zhu Yifei, Sun Anbang","The transition from quasi-uniform to filamentary modes in a repetitive
nanosecond Surface Dielectric Barrier Discharge(SDBD) under atmospheric
pressure was studied. Our focus encompassed both discharge morphology and
electrical characteristics, revealing two pivotal findings. Firstly, by
analyzing the current and the deposited energy waveforms, three characteristic
frequency ranges respectively corresponding to the discharge modes are
identified. Notably, within the 5 kHz to 8 kHz range, we observed non-monotonic
changes in the propagation distance, the current amplitude, and the deposited
energy - a crucial insight linked to the discharge transition. Secondly, the
count of current extrema in the primary discharge process changes only during
the transition to filamentary mode, remaining stable in the steady discharge
mode. This variation may be attributed to secondary Surface Ionization Waves
(SIWs). The interplay of these two findings with the discharge transition
requires deeper investigation. Additionally, we present a discharge modes
control curve outlining parameter windows for the discharge modes. This curve
facilitates the optimization of pulse power supply and control schemes in
practical applications.",http://arxiv.org/abs/2502.03923v1
"Can Grammarly and ChatGPT accelerate language change? AI-powered
  technologies and their impact on the English language: wordiness vs.
  conciseness",2025-02-06T18:59:26Z,Karolina Rudnicka,"The proliferation of NLP-powered language technologies, AI-based natural
language generation models, and English as a mainstream means of communication
among both native and non-native speakers make the output of AI-powered tools
especially intriguing to linguists. This paper investigates how Grammarly and
ChatGPT affect the English language regarding wordiness vs. conciseness. A case
study focusing on the purpose subordinator in order to is presented to
illustrate the way in which Grammarly and ChatGPT recommend shorter grammatical
structures instead of longer and more elaborate ones. Although the analysed
sentences were produced by native speakers, are perfectly correct, and were
extracted from a language corpus of contemporary English, both Grammarly and
ChatGPT suggest more conciseness and less verbosity, even for relatively short
sentences. The present article argues that technologies such as Grammarly not
only mirror language change but also have the potential to facilitate or
accelerate it.",http://arxiv.org/abs/2502.04324v1
On Techniques for Barely Coupled Multiphysics,2025-02-06T20:09:01Z,"Rainald Löhner, Harbir Antil, Sebastian Schöps","A technique to combine codes to solve barely coupled multiphysics problems
has been developed. Each field is advanced separately until a stop is
triggered. This could be due to a preset time increment, a preset number of
timesteps, a preset decrease of residuals, a preset change in unknowns, a
preset change in geometry, or any other physically meaningful quantity. The
technique allows for a simple implementation in coupled codes using the loose
coupling approach. Examples from evaporative cooling of electric motors, a
problem that has come to the forefront with the rise of electric propulsion in
the aerospace sector (drones and air taxis in particular) shows the viability
and accuracy of the proposed procedure.",http://arxiv.org/abs/2502.04480v1
"Enhancing Impression Change Prediction in Speed Dating Simulations Based
  on Speakers' Personalities",2025-02-07T07:18:32Z,"Kazuya Matsuo, Yoko Ishii, Atsushi Otsuka, Ryo Ishii, Hiroaki Sugiyama, Masahiro Mizukami, Tsunehiro Arimoto, Narichika Nomoto, Yoshihide Sato, Tetsuya Yamaguchi","This paper focuses on simulating text dialogues in which impressions between
speakers improve during speed dating. This simulation involves selecting an
utterance from multiple candidates generated by a text generation model that
replicates a specific speaker's utterances, aiming to improve the impression of
the speaker. Accurately selecting an utterance that improves the impression is
crucial for the simulation. We believe that whether an utterance improves a
dialogue partner's impression of the speaker may depend on the personalities of
both parties. However, recent methods for utterance selection do not consider
the impression per utterance or the personalities. To address this, we propose
a method that predicts whether an utterance improves a partner's impression of
the speaker, considering the personalities. The evaluation results showed that
personalities are useful in predicting impression changes per utterance.
Furthermore, we conducted a human evaluation of simulated dialogues using our
method. The results showed that it could simulate dialogues more favorably
received than those selected without considering personalities.",http://arxiv.org/abs/2502.04706v1
Ensembles in Urban Large Eddy Simulations with Changing Wind Direction,2025-02-07T11:10:29Z,"Jukka-Pekka Keskinen, Antti Hellsten","Differences between time-averaged and ensemble-averaged wind are studied in
this article for the case of changing wind direction. We consider a flow driven
by a temporally turning pressure gradient in both an idealized case of a
staggered cube array and a realistic urban environment. The repeating structure
of the idealized case allows us to construct a large ensemble of 3 240 members
with a reasonable compute time. The results indicate that the use of plain time
average instead of an ensemble average allows for accurate calculation of only
the along-wind mean velocity. Utilising Taylor diagrams, we show that a
reasonable compromise between ensemble size and accuracy can be achieved
utilising a 30-minute time average together with a 50-member ensemble for the
flow within the urban roughness sublayer. During this 30-minute averaging
period, the wind direction turns for approximately 4.8{\deg}. By applying this
approach to the realistic urban geometry, we identify building wakes as the
regions most severely affected by the incorrectly utilized time averaging.",http://arxiv.org/abs/2502.04836v1
"Relationship among solutions for three-phase change problems with Robin,
  Dirichlet, and Neumann boundary conditions",2025-02-08T12:18:07Z,"Julieta Bollati, María Fernanda Natale, José Abel Semitiel, Domingo Alberto Tarzia","This study investigates the melting process of a three-phase Stefan problem
in a semi-infinite material, imposing a convective boundary condition at the
fixed face. By employing a similarity-type transformation, the problem is
reduced to a solvable form, yielding a unique explicit solution. The analysis
uncovers significant equivalences among the solutions of three different
three-phase Stefan problems: one with a Robin boundary condition, another with
a Dirichlet boundary condition, and a third one with a Neumann boundary
condition at the fixed face. These equivalences are established under the
condition that the problem data satisfy a specific relationship, providing new
insights into the behaviour of phase change problems under varying boundary
conditions.",http://arxiv.org/abs/2502.05545v1
Reinforced Lifelong Editing for Language Models,2025-02-09T03:37:06Z,"Zherui Li, Houcheng Jiang, Hao Chen, Baolong Bi, Zhenhong Zhou, Fei Sun, Junfeng Fang, Xiang Wang","Large language models (LLMs) acquire information from pre-training corpora,
but their stored knowledge can become inaccurate or outdated over time. Model
editing addresses this challenge by modifying model parameters without
retraining, and prevalent approaches leverage hypernetworks to generate these
parameter updates. However, they face significant challenges in lifelong
editing due to their incompatibility with LLM parameters that dynamically
change during the editing process. To address this, we observed that
hypernetwork-based lifelong editing aligns with reinforcement learning modeling
and proposed RLEdit, an RL-based editing method. By treating editing losses as
rewards and optimizing hypernetwork parameters at the full knowledge sequence
level, we enable it to precisely capture LLM changes and generate appropriate
parameter updates. Our extensive empirical evaluation across several LLMs
demonstrates that RLEdit outperforms existing methods in lifelong editing with
superior effectiveness and efficiency, achieving a 59.24% improvement while
requiring only 2.11% of the time compared to most approaches. Our code is
available at: https://github.com/zhrli324/RLEdit.",http://arxiv.org/abs/2502.05759v2
Decision Making in Hybrid Environments: A Model Aggregation Approach,2025-02-09T17:59:42Z,"Haolin Liu, Chen-Yu Wei, Julian Zimmert","Recent work by Foster et al. (2021, 2022, 2023) and Xu and Zeevi (2023)
developed the framework of decision estimation coefficient (DEC) that
characterizes the complexity of general online decision making problems and
provides a general algorithm design principle. These works, however, either
focus on the pure stochastic regime where the world remains fixed over time, or
the pure adversarial regime where the world arbitrarily changes over time. For
the hybrid regime where the dynamics of the world is fixed while the reward
arbitrarily changes, they only give pessimistic bounds on the decision
complexity. In this work, we propose a general extension of DEC that more
precisely characterizes this case. Besides applications in special cases, our
framework leads to a flexible algorithm design where the learner learns over
subsets of the hypothesis set, trading estimation complexity with decision
complexity, which could be of independent interest. Our work covers model-based
learning and model-free learning in the hybrid regime, with a newly proposed
extension of the bilinear classes (Du et al., 2021) to the adversarial-reward
case. We also recover some existing model-free learning results in the pure
stochastic regime.",http://arxiv.org/abs/2502.05974v1
Thermodynamic Cost of Steady State Erasure,2025-02-09T20:10:22Z,"Deepak Gupta, Kristian Stølevik Olsen, Supriya Krishnamurthy","Recent experiments have implemented resetting by means of a time-varying
external harmonic trap whereby the trap stiffness is changed from an initial to
a final value in finite-time and then the system is reset when it relaxes to an
equilibrium distribution in the final trap. Such setups are very similar to
those studied in the context of the finite-time Landauer erasure principle. We
analyse the thermodynamic costs of such a setup by deriving a moment generating
function for the work cost of changing the trap stiffness in finite-time for a
system in steady state. We analyse the mean and variance of the work required
for a specific experimentally viable protocol and also obtain an optimal
protocol which minimises the mean cost. For both these procedures, our analysis
captures both the large-time and short-time corrections. For the optimal
protocol, we obtain a closed form expression for the mean cost for all protocol
durations, thereby making contact with earlier work on geometric measures of
dissipation-minimising optimal protocols that implement information erasure.",http://arxiv.org/abs/2502.06014v1
Proprioceptive Origami Manipulator,2025-02-10T11:29:25Z,"Aida Parvaresh, Arman Goshtasbi, Jonathan Andres Tirado Rosero, Ahmad Rafsanjani","Origami offers a versatile framework for designing morphable structures and
soft robots by exploiting the geometry of folds. Tubular origami structures can
act as continuum manipulators that balance flexibility and strength. However,
precise control of such manipulators often requires reliance on vision-based
systems that limit their application in complex and cluttered environments.
Here, we propose a proprioceptive tendon-driven origami manipulator without
compromising its flexibility. Using conductive threads as actuating tendons, we
multiplex them with proprioceptive sensing capabilities. The change in the
active length of the tendons is reflected in their effective resistance, which
can be measured with a simple circuit. We correlated the change in the
resistance to the lengths of the tendons. We input this information into a
forward kinematic model to reconstruct the manipulator configuration and
end-effector position. This platform provides a foundation for the closed-loop
control of continuum origami manipulators while preserving their inherent
flexibility.",http://arxiv.org/abs/2502.06362v1
Hedgehog-like spin texture in Sb-doped MnBi$_2$Te$_4$,2025-02-10T12:54:29Z,"Meng Zeng, Shu Mo, Ke Zhang, Yu-Jie Hao, Yu-Peng Zhu, Xiang-Rui Liu, Cheng Zhang, Ming-Yuan Zhu, Shiv Kumar, Takuma Iwata, Koji Miyamoto, Taichi Okuda, Kenya Shimada, Kenta Kuroda, Xiao-Ming Ma, Chang Liu","We employ spin- and angle-resolved photoemission spectroscopy and
circular-dichroism ARPES to systematically investigate the spin texture of
Sb-doped MnBi$_2$Te$_4$. Our results display a hedgehog-like spin texture in
this system which is signified by reversed-orienting out-of-plane spins at the
Dirac gap. Our finding reveals the presence of time-reversal symmetry breaking,
implying the possibility for realization of high-temperature quantum anomalous
Hall effect.",http://arxiv.org/abs/2502.06416v1
"Crossover from BKT to first-order transition induced by higher-order
  terms in 2D XY models",2025-02-10T14:26:00Z,Milan Žukovič,"We study phase transitions in $XY$ models, generalized by inclusion of $n$
higher-order pairwise interactions of equal strength, by Monte Carlo
simulation. It is found that by adding new terms the
Berezinskii-Kosterlitz-Thouless (BKT) transition, observed in the standard $XY$
model, gradually changes to the first-order phase transition. We determine the
critical number of terms for which the first-order transition appears as
$n_c=6$. It is also found that for $n=5$ the transition is pseudo-first-order
but it becomes true first-order if the couplings are allowed to increase. In
general, a more rapid increase of the coupling intensity supports the
first-order transition, however, a too fast increase may result in splitting of
the single transition to multiple transitions. Consequently, the minimal number
of the terms required for the change of the BKT phase transition to first order
in the present model with arbitrary couplings is estimated to be $2 < n_c \leq
5$.",http://arxiv.org/abs/2502.06509v1
Topological Constraint Model of Alkaline Earth Vanadate Glasses,2025-02-10T15:40:14Z,"Adam Shearer, John C. Mauro","Topological constraint theory has enabled the successful prediction of glass
properties over a wide range of compositions. In this study, a topological
constraint model is constructed for alkaline earth vanadate glasses based on
experimental data. The change in vanadate structural units from VO5 to VO4 was
modeled as a function of alkaline earth content and related to thermal and
mechanical properties. The model covers both high and low-temperature
properties to probe the temperature dependence of constraint rigidity for each
constituent of the glass network. The model is changed to describe anomalies in
magnesium sites potentially implying that magnesium can form locally rigid
structures. Furthermore, the traditional understanding of vanadate glass
structure is compared to recent results concluding that the terminal oxygen
must exist as a part of the VO4 units. Results for the model explain that
bridging oxygen constraints are the main contributors to network rigidity in
both low and high temperature regimes. Vanadate glass networks are highly
connected even with the introduction of modifier species, which introduce their
own bond constraints. Corroboration between experimental data and the
topological constraint model illustrates the role of alkaline earth oxides in
the glass network.",http://arxiv.org/abs/2502.06571v1
"SMAB: MAB based word Sensitivity Estimation Framework and its
  Applications in Adversarial Text Generation",2025-02-10T22:46:57Z,"Saurabh Kumar Pandey, Sachin Vashistha, Debrup Das, Somak Aditya, Monojit Choudhury","To understand the complexity of sequence classification tasks, Hahn et al.
(2021) proposed sensitivity as the number of disjoint subsets of the input
sequence that can each be individually changed to change the output. Though
effective, calculating sensitivity at scale using this framework is costly
because of exponential time complexity. Therefore, we introduce a
Sensitivity-based Multi-Armed Bandit framework (SMAB), which provides a
scalable approach for calculating word-level local (sentence-level) and global
(aggregated) sensitivities concerning an underlying text classifier for any
dataset. We establish the effectiveness of our approach through various
applications. We perform a case study on CHECKLIST generated sentiment analysis
dataset where we show that our algorithm indeed captures intuitively high and
low-sensitive words. Through experiments on multiple tasks and languages, we
show that sensitivity can serve as a proxy for accuracy in the absence of gold
data. Lastly, we show that guiding perturbation prompts using sensitivity
values in adversarial example generation improves attack success rate by
15.58%, whereas using sensitivity as an additional reward in adversarial
paraphrase generation gives a 12.00% improvement over SOTA approaches. Warning:
Contains potentially offensive content.",http://arxiv.org/abs/2502.07101v1
On a Fractional Variant of Linear Birth-Death Process,2025-02-11T07:48:30Z,"Manisha Dhillon, Pradeep Vishwakarma, Kuldeep Kumar Kataria","We introduce and study a fractional variant of the linear birth-death
process, namely, the generalized fractional linear birth-death process (GFLBDP)
which is defined by taking the regularized Hilfer-Prabhakar derivative in the
system of differential equations that governs the state probabilities of linear
birth-death process. For a particular choice of parameters, the GFLBDP reduces
to the fractional linear birth-death process that involves the Caputo
derivative. Its time-changed representation is obtained and utilized to derive
the explicit expressions of its state probabilities. The explicit expressions
for its mean and variance are derived. In a particular case, it is observed
that the limiting distribution of the time changing process coincides to that
of an inverse stable subordinator. A relation between the extinction
probability of GFLBDP and the density of inter arrival times of a generalized
fractional Poisson process is obtained. Later, we study some integrals of the
GFLBDP and discuss the asymptotic distributional characteristics for a
particular integral process. Also, an application of the path integral at
random time to a genetic population with an upper bound is discussed.",http://arxiv.org/abs/2502.07329v1
Nuclear Fusion Enhancement by Heavy Nuclear Catalysts,2025-02-05T13:48:00Z,"Christopher Grayson, Johann Rafelski","We seek to understand the effect of high electron density in the proximity of
a heavy nucleus on the fusion reaction rates in a hot plasma phase. We
investigate quantitatively the catalytic effect of gold ($Z=79$) ions embedded
in an electron plasma created due to plasmonic focusing of high-intensity short
laser pulses. Using self-consistent strong plasma screening, we find highly
significant changes in the internuclear potential of light elements present
nearby. For gold, we see a $14\,$keV change in the internuclear potential near
the nuclear surface, independent of the long-distance thermal Debye-H\""uckel
screening. The dense polarization cloud of electrons around the gold catalyst
leads to a $\sim 1.5$ enhancement of proton-boron ($^{11}$B) fusion above
$T=100\,$keV.",http://arxiv.org/abs/2502.07804v1
"A Bayesian Non-linear Mixed-Effects Model for Accurate Detection of the
  Onset of Cognitive Decline in Longitudinal Aging Studies",2025-02-12T14:01:05Z,"Fernando Massa, Marco Scavino, Graciela Muniz-Terrera","Change-point models are frequently considered when modeling phenomena where a
regime shift occurs at an unknown time. In ageing research, these models are
commonly adopted to estimate of the onset of cognitive decline. Yet commonly
used models present several limitations. Here, we present a Bayesian non-linear
mixed-effects model based on a differential equation designed for longitudinal
studies to overcome some limitations of classical change point models used in
ageing research. We demonstrate the ability of the proposed model to avoid
biases in estimates of the onset of cognitive impairment in a simulated study.
Finally, the methodology presented in this work is illustrated by analysing
results from memory tests from older adults who participated in the English
Longitudinal Study of Ageing.",http://arxiv.org/abs/2502.08418v1
"Long Secondary Periods in Red Giants: AAVSO Observations and the Eclipse
  Hypothesis",2025-02-12T23:28:33Z,"John Percy, Melanie Szpigiel","At least a third of red giants show a long secondary period (LSP), 5 to 10
times longer than the pulsation period. There is strong evidence that the LSP
is caused by eclipses of the red giant by a dust-enshrouded low-mass companion.
We have used long-term AAVSO observations of 11 stars to study two aspects of
the eclipse hypothesis: the relation between the LSP phase (eclipse) curve and
the geometry of the eclipse, and the long-term (decades) changes in the LSP
phenomenon in each star. The stars with the largest LSP amplitudes show
evidence of a dust tail on the companion, but most of the 11 stars show only a
small-amplitude sinusoidal phase curve. The LSP amplitudes of all the stars
vary slowly by up to a factor of 8, suggesting that the amount of obscuring
dust varies by that amount, but there is no strong evidence that the geometry
of the system changes over many decades.",http://arxiv.org/abs/2502.08842v1
Recent advances in high-dimensional quantum frequency combs,2025-02-13T01:33:58Z,"Kai-Chi Chang, Xiang Cheng, Murat Can Sarihan, Chee Wei Wong","High-dimensional entanglement in qudit states offers a promising pathway
towards the realization of practical, large-scale quantum systems that are
highly controllable. These systems can be leveraged for various applications,
including advanced quantum information processing, secure communications,
computation, and metrology. In this context, quantum frequency combs have a
crucial role as they inherently support multiple modes in both temporal and
frequency domains, while preserving a single spatial mode. The multiple
temporal and frequency modes of quantum frequency combs facilitate the
generation, characterization, and control of high-dimensional time-frequency
entanglement in extensive quantum systems. In this review article, we provide
an overview of recent technological advancements in high-dimensional
energy-time entangled quantum frequency combs. We explore how these
time-frequency qudits, achieved using scalable telecommunications-wavelength
components, can empower the creation of large-scale quantum states. Advances in
quantum frequency combs can unlock new capabilities and versatility for
promising developments in quantum science and technology.",http://arxiv.org/abs/2502.08879v1
Modeling Time-evolving Causality over Data Streams,2025-02-13T04:59:01Z,"Naoki Chihara, Yasuko Matsubara, Ren Fujiwara, Yasushi Sakurai","Given an extensive, semi-infinite collection of multivariate coevolving data
sequences (e.g., sensor/web activity streams) whose observations influence each
other, how can we discover the time-changing cause-and-effect relationships in
co-evolving data streams? How efficiently can we reveal dynamical patterns that
allow us to forecast future values? In this paper, we present a novel streaming
method, ModePlait, which is designed for modeling such causal relationships
(i.e., time-evolving causality) in multivariate co-evolving data streams and
forecasting their future values. The solution relies on characteristics of the
causal relationships that evolve over time in accordance with the dynamic
changes of exogenous variables. ModePlait has the following properties: (a)
Effective: it discovers the time-evolving causality in multivariate co-evolving
data streams by detecting the transitions of distinct dynamical patterns
adaptively. (b) Accurate: it enables both the discovery of time-evolving
causality and the forecasting of future values in a streaming fashion. (c)
Scalable: our algorithm does not depend on data stream length and thus is
applicable to very large sequences. Extensive experiments on both synthetic and
real-world datasets demonstrate that our proposed model outperforms
state-of-the-art methods in terms of discovering the time-evolving causality as
well as forecasting.",http://arxiv.org/abs/2502.08963v1
Generalizing Reduced Rank Extrapolation to Low-Rank Matrix Sequences,2025-02-13T10:48:46Z,"Pascal den Boef, Patrick Kürschner, Xiaobo Liu, Jos Maubach, Jens Saak, Wil Schilders, Jonas Schulze, Nathan van de Wouw","Reduced rank extrapolation (RRE) is an acceleration method typically used to
accelerate the iterative solution of nonlinear systems of equations using a
fixed-point process. In this context, the iterates are vectors generated from a
fixed-point mapping function. However, when considering the iterative solution
of large-scale matrix equations, the iterates are low-rank matrices generated
from a fixed-point process for which, generally, the mapping function changes
in each iteration. To enable acceleration of the iterative solution for these
problems, we propose two novel generalizations of RRE. First, we show how to
effectively compute RRE for sequences of low-rank matrices. Second, we derive a
formulation of RRE that is suitable for fixed-point processes for which the
mapping function changes each iteration. We demonstrate the potential of the
methods on several numerical examples involving the iterative solution of
large-scale Lyapunov and Riccati matrix equations.",http://arxiv.org/abs/2502.09165v1
"Spectral diversity in collisional neutrino-flavor conversion: flavor
  equipartition or swap",2025-02-13T12:18:57Z,Masamichi Zaizen,"Quantum kinetics of neutrinos are known to potentially change the classical
neutrino radiation field in high-energy astrophysical sources such as
core-collapse supernovae and binary neutron-star mergers. However, the mixing
phenomena still have open issues in the nonlinear dynamics and the asymptotic
states, particularly for recently discovered collision-induced flavor
conversion. In this paper, we investigate linear and nonlinear dynamics of
collisional neutrino-flavor conversion (CFC) with multi-energy neutrino gases
through numerical simulations, demonstrating that the asymptotic states
dramatically change depending on unstable modes dominating the system. In one
unstable mode, high-energy neutrinos reach a flavor equipartition, but
low-energy neutrinos return back to almost their initial states. In contrast,
in the other one, rather low-energy neutrinos achieve a full flavor swap, but
high-energy neutrinos undergo less flavor conversion. We clarify the distinct
spectral behaviors in two different ways based on stability analysis and flavor
pendulum. Our result suggests that CFC with flavor swap can become crucial at
deeper radii with low electron fraction and requires more detailed theoretical
modeling of neutrino quantum kinetics.",http://arxiv.org/abs/2502.09260v1
"Unexpected large electrostatic gating by pyroelectric charge
  accumulation",2025-02-13T16:29:50Z,"Yicheng Mou, Qi Liu, Jiaqi Liu, Yingchao Xia, Zejing Guo, Wenqing Song, Jiaming Gu, Zixuan Xu, Wenbin Wang, Hangwen Guo, Wu Shi, Jian Shen, Cheng Zhang","Pyroelectricity refers to the accumulation of charges due to changes in the
spontaneous polarization of ferroelectric materials when subjected to
temperature variations. Typically, these pyroelectric charges are considered
unstable and dissipate quickly through interactions with the external
environment. Consequently, the pyroelectric effect has been largely overlooked
in ferroelectric field-effect transistors. In this work, we leverage the van
der Waals interface of hBN to achieve a substantial and long-term electrostatic
gating effect in graphene devices via the pyroelectric properties of a
ferroelectric LiNbO3 substrate. Upon cooling, the polarization change in LiNbO3
induces high doping concentrations up to 1013 cm-2 in the adjacent graphene.
Through a combination of transport measurements and non-contact techniques, we
demonstrate that the pyroelectric charge accumulation, as well as its
enhancement in electric fields, are responsible for this unexpectedly high
doping level. Our findings introduce a novel mechanism for voltage-free
electrostatic gating control with long retention.",http://arxiv.org/abs/2502.09464v1
Quality thinning and value development of boreal trees,2025-02-13T10:53:49Z,Petri P. Karenlampi,"For the first time, quality distribution of trees is introduced in a tree
growth model. Consequently, the effects of quality thinning on stand
development can be investigated. Quality thinning improves the financial return
in all cases studied, but the effect is small. Rotation ages, timber stocks and
maturity diameters are not much affected by quality thinning. Bare land
valuation neither changes the contribution of the quality thinning. The reason
for the small effect apparently lies in the value development of individual
trees. The relative value development of small pulpwood trunks is large, since
the harvesting expense per volume unit is reduced along with size increment.
Such trees are not feasible objects for quality thinning, unless quality
correlates with growth rate. Another enhanced stage of value development is
when pulpwood trunks turn to sawlog trunks. For large pulpwood trunks, quality
thinning is feasible. Existing sawlog content in trees dilutes the effect of
quality thinning on the financial return. The results change if the growth rate
is positively correlated with quality, quality thinning becoming feasible in
all commercial diameter classes.",http://arxiv.org/abs/2502.09678v1
Deep Tree Tensor Networks for Image Recognition,2025-02-14T05:41:33Z,"Chang Nie, Junfang Chen, Yajie Chen","Originating in quantum physics, tensor networks (TNs) have been widely
adopted as exponential machines and parameter decomposers for recognition
tasks. Typical TN models, such as Matrix Product States (MPS), have not yet
achieved successful application in natural image processing. When employed,
they primarily serve to compress parameters within off-the-shelf networks, thus
losing their distinctive capability to enhance exponential-order feature
interactions. This paper introduces a novel architecture named
\textit{\textbf{D}eep \textbf{T}ree \textbf{T}ensor \textbf{N}etwork} (DTTN),
which captures $2^L$-order multiplicative interactions across features through
multilinear operations, while essentially unfolding into a \emph{tree}-like TN
topology with the parameter-sharing property. DTTN is stacked with multiple
antisymmetric interacting modules (AIMs), and this design facilitates efficient
implementation. Moreover, we theoretically reveal the equivalency among
quantum-inspired TN models and polynomial and multilinear networks under
certain conditions, and we believe that DTTN can inspire more interpretable
studies in this field. We evaluate the proposed model against a series of
benchmarks and achieve excellent performance compared to its peers and
cutting-edge architectures. Our code will soon be publicly available.",http://arxiv.org/abs/2502.09928v1
"Decision Information Meets Large Language Models: The Future of
  Explainable Operations Research",2025-02-14T08:25:06Z,"Yansen Zhang, Qingcan Kang, Wing Yin Yu, Hailei Gong, Xiaojin Fu, Xiongwei Han, Tao Zhong, Chen Ma","Operations Research (OR) is vital for decision-making in many industries.
While recent OR methods have seen significant improvements in automation and
efficiency through integrating Large Language Models (LLMs), they still
struggle to produce meaningful explanations. This lack of clarity raises
concerns about transparency and trustworthiness in OR applications. To address
these challenges, we propose a comprehensive framework, Explainable Operations
Research (EOR), emphasizing actionable and understandable explanations
accompanying optimization. The core of EOR is the concept of Decision
Information, which emerges from what-if analysis and focuses on evaluating the
impact of complex constraints (or parameters) changes on decision-making.
Specifically, we utilize bipartite graphs to quantify the changes in the OR
model and adopt LLMs to improve the explanation capabilities. Additionally, we
introduce the first industrial benchmark to rigorously evaluate the
effectiveness of explanations and analyses in OR, establishing a new standard
for transparency and clarity in the field.",http://arxiv.org/abs/2502.09994v1
"COMBINEX: A Unified Counterfactual Explainer for Graph Neural Networks
  via Node Feature and Structural Perturbations",2025-02-14T12:17:24Z,"Flavio Giorgi, Fabrizio Silvestri, Gabriele Tolomei","Counterfactual explanations have emerged as a powerful tool to unveil the
opaque decision-making processes of graph neural networks (GNNs). However,
existing techniques primarily focus on edge modifications, often overlooking
the crucial role of node feature perturbations in shaping model predictions. To
address this limitation, we propose COMBINEX, a novel GNN explainer that
generates counterfactual explanations for both node and graph classification
tasks. Unlike prior methods, which treat structural and feature-based changes
independently, COMBINEX optimally balances modifications to edges and node
features by jointly optimizing these perturbations. This unified approach
ensures minimal yet effective changes required to flip a model's prediction,
resulting in realistic and interpretable counterfactuals. Additionally,
COMBINEX seamlessly handles both continuous and discrete node features,
enhancing its versatility across diverse datasets and GNN architectures.
Extensive experiments on real-world datasets and various GNN architectures
demonstrate the effectiveness and robustness of our approach over existing
baselines.",http://arxiv.org/abs/2502.10111v1
Enhancing Age-Related Robustness in Children Speaker Verification,2025-02-14T19:18:02Z,"Vishwas M. Shetty, Jiusi Zheng, Steven M. Lulich, Abeer Alwan","One of the main challenges in children's speaker verification (C-SV) is the
significant change in children's voices as they grow. In this paper, we propose
two approaches to improve age-related robustness in C-SV. We first introduce a
Feature Transform Adapter (FTA) module that integrates local patterns into
higher-level global representations, reducing overfitting to specific local
features and improving the inter-year SV performance of the system. We then
employ Synthetic Audio Augmentation (SAA) to increase data diversity and size,
thereby improving robustness against age-related changes. Since the lack of
longitudinal speech datasets makes it difficult to measure age-related
robustness of C-SV systems, we introduce a longitudinal dataset to assess
inter-year verification robustness of C-SV systems. By integrating both of our
proposed methods, the average equal error rate was reduced by 19.4%, 13.0%, and
6.1% in the one-year, two-year, and three-year gap inter-year evaluation sets,
respectively, compared to the baseline.",http://arxiv.org/abs/2502.10511v1
"Shape Changes of Liquid Crystal Elastomers Swollen by Low Molecular
  Weight Liquid Crystal Drops",2025-02-14T23:19:06Z,"Mahesha Kodithuwakku Arachchige, Rohan Dharmarathna, Paul Fleischer, Antal Jakli","An elastomer swelling actuator deforms by absorbing a fluid, thus generating
mechanical movement. We show that depositing small droplets of low molecular
weight liquid crystal on liquid crystal elastomer (LCE) films leads to shape
changes and bending actuation. It is found that the radially symmetric LCE
director alignments provide radially symmetric hat shapes, while swelling LCEs
with uniform director structure leads to arch shapes. Hybrid samples (different
director alignments on two sides) lead to more complicated bent shapes. All the
observed shapes can be explained by the diffusion that mainly progresses along
the direction normal to the director of the LCE. The swelling induced bending
force is elevating the top of the swollen LCE up to a factor of 30, providing a
powerful and long-lasting actuation. These observations may lead to
applications in various fields, like sealants, soft robotics and biomedical
devices.",http://arxiv.org/abs/2502.10604v1
K-Edit: Language Model Editing with Contextual Knowledge Awareness,2025-02-15T01:35:13Z,"Elan Markowitz, Anil Ramakrishna, Ninareh Mehrabi, Charith Peris, Rahul Gupta, Kai-Wei Chang, Aram Galstyan","As the world changes, we need to be able to update our models and correct
false information without costly retraining. Knowledge-based model editing
enables precise modifications to the weights of large language models in order
to modify the information encoded within. Recent approaches have seen success
in enabling recall of edited information for thousands of edits at once.
However, these approaches fail to produce edits that account for associated
contextual information. We present K-Edit, an effective approach to generating
contextually consistent knowledge edits. By using knowledge graphs, which
maintain contextual consistency when an edge is edited, we are able to generate
additional \textit{contextual edits} that ensure consistency of related
information in the language model. Our experiments demonstrate significant
improvements in multi-hop question answering while maintaining the general
effectiveness and scalability of model edits.",http://arxiv.org/abs/2502.10626v1
"A recurrent vision transformer shows signatures of primate visual
  attention",2025-02-16T02:22:27Z,"Jonathan Morgan, Badr Albanna, James P. Herman","Attention is fundamental to both biological and artificial intelligence, yet
research on animal attention and AI self attention remains largely
disconnected. We propose a Recurrent Vision Transformer (Recurrent ViT) that
integrates self-attention with recurrent memory, allowing both current inputs
and stored information to guide attention allocation. Trained solely via sparse
reward feedback on a spatially cued orientation change detection task, a
paradigm used in primate studies, our model exhibits primate like signatures of
attention, including improved accuracy and faster responses for cued stimuli
that scale with cue validity. Analysis of self-attention maps reveals dynamic
spatial prioritization with reactivation prior to expected changes, and
targeted perturbations produce performance shifts similar to those observed in
primate frontal eye fields and superior colliculus. These findings demonstrate
that incorporating recurrent feedback into self attention can capture key
aspects of primate visual attention.",http://arxiv.org/abs/2502.10955v1
A Survey: Potential Dimensionality Reduction Methods,2025-02-16T08:28:33Z,Yuan-chin Ivan Chang,"Dimensionality reduction is a fundamental technique in machine learning and
data analysis, enabling efficient representation and visualization of
high-dimensional data. This paper explores five key methods: Principal
Component Analysis (PCA), Kernel PCA (KPCA), Sparse Kernel PCA, t-Distributed
Stochastic Neighbor Embedding (t-SNE), and Uniform Manifold Approximation and
Projection (UMAP). PCA provides a linear approach to capturing variance,
whereas KPCA and Sparse KPCA extend this concept to non-linear structures using
kernel functions. Meanwhile, t-SNE and UMAP focus on preserving local
relationships, making them effective for data visualization. Each method is
examined in terms of its mathematical formulation, computational complexity,
strengths, and limitations. The trade-offs between global structure
preservation, computational efficiency, and interpretability are discussed to
guide practitioners in selecting the appropriate technique based on their
application needs.",http://arxiv.org/abs/2502.11036v2
"Comprehensive scaling laws across animals, microorganisms and plants",2025-02-17T03:27:31Z,"Huan Liu, Shashank Priya, Richard D. James","Scaling laws illuminate Nature's fundamental biological principles and guide
bioinspired materials and structural designs. In simple cases they are based on
the fundamental principle that all laws of nature remain unchanged (i.e.,
invariant) under a change of units. A more general framework is a change of
variables for the governing laws that takes all equations, boundary, and
interaction conditions into themselves. We consider an accepted macroscale
system of partial differential equations including coupled fluid dynamics,
nonlinear elasticity, and rigid body mechanics for a complex organism. We show
that there is a set of scaling laws where length, time, density, elastic
modulus, viscosity, and gravitational constant undergo nontrivial scaling
(Table 1). We compare these results to extensive data sets mined from the
literature on beating frequency of flying, swimming, and running animals, speed
of bacteria, insects, fish, mammals and reptiles, leg stiffness of mammals, and
modulus of elasticity of plants. The uniform agreement of the scaling laws with
the dynamics of fauna, flora, and microorganisms supports the dominating role
of coupled nonlinear elasticity and fluid dynamics in evolutionary development.
We conclude with predictions for some prehistoric cases for which observations
are unavailable.",http://arxiv.org/abs/2502.11398v1
"Which Retain Set Matters for LLM Unlearning? A Case Study on Entity
  Unlearning",2025-02-17T04:55:02Z,"Hwan Chang, Hwanhee Lee","Large language models (LLMs) risk retaining unauthorized or sensitive
information from their training data, which raises privacy concerns. LLM
unlearning seeks to mitigate these risks by selectively removing specified data
while maintaining overall model performance. However, most existing work focus
on methods to achieve effective forgetting and does not provide a detailed
analysis of the retain set, the portion of training data that is not targeted
for removal. In this paper, we investigate the effects of unlearning on various
subsets of the retain set through a case study on entity unlearning. We
introduce the Syntactically Similar Neighbor Set, a group of queries that share
similar syntactic structures with the data targeted for removal, and show that
this subset suffers the greatest performance drop during unlearning. Moreover,
when used for regularization, this set not only preserves performance on
syntactically similar queries but also delivers comparable or improved results
across other data subsets. Our results highlight that syntactic similarity is a
critical factor, potentially more so than domain or entity relationships, in
achieving effective and practical LLM unlearning.",http://arxiv.org/abs/2502.11441v1
"A linear-time algorithm computing the resident fitness in interacting
  trajectories",2025-02-17T08:48:29Z,"Katalin Friedl, Viktória Nemkin, András Tóbiás","The notion of a system of interacting trajectories was recently introduced by
Hermann, Gonz\'alez Casanova, Soares dos Santos, T\'obi\'as and Wakolbinger.
Such a system of $[0,1]$-valued piecewise linear trajectories arises as a
scaling limit of the system of logarithmic subpopulation sizes in a certain
population-genetic model (more precisely, a Moran model) with mutation and
selection. By definition, the resident fitness is initially 0 and afterwards it
increases by the ultimate slope of each trajectory that reaches height 1.
  We show that although the interaction of $n$ trajectories may yield
$\Omega(n^2)$ slope changes in total, the resident fitness (at all times) can
be computed algorithmically in $O(n)$ time. Our algorithm is given in terms of
the so-called continued lines representation of the system of interacting
trajectories. In the special case of Poissonian interacting trajectories where
the birth times of the trajectories form a Poisson process and the initial
slopes are random and i.i.d., we show that even the expected number of slope
changes grows only linearly in time.",http://arxiv.org/abs/2502.11561v1
"A Diagnostic to Find and Help Combat Positivity Issues -- with a Focus
  on Continuous Treatments",2025-02-17T14:13:09Z,"Katharina Ring, Michael Schomaker","The positivity assumption is central in the identification of a causal
effect, yet is rarely discussed, especially in conjunction with continuous
treatments or Modified Treatment Policies. One common recommendation for
dealing with a violation is to change the estimand. However, an applied
researcher is faced with two problems: First, how can she tell whether there is
a positivity violation given her estimand of interest, preferably without
having to estimate a model first? Second, if she finds a problem with
positivity, how should she change her estimand in order to arrive at an
estimand which does not face the same issues? We suggest a novel diagnostic
which allows the researcher to answer both questions by providing insights into
how well an estimation for a certain estimand can be made for each observation
using the data at hand. We provide a simulation study on the general behaviour
of different MTPs at different levels of positivity violations and show how the
diagnostic helps understand where bias is to be expected. We illustrate the
application of our proposed diagnostic in a pharmacoepidemiological study based
on data from CHAPAS-3, a trial comparing different treatment regimens for
children living with HIV.",http://arxiv.org/abs/2502.11820v1
"Bandwidth-Adaptive Spatiotemporal Correspondence Identification for
  Collaborative Perception",2025-02-17T18:18:23Z,"Peng Gao, Williard Joshua Jose, Hao Zhang","Correspondence identification (CoID) is an essential capability in
multi-robot collaborative perception, which enables a group of robots to
consistently refer to the same objects within their respective fields of view.
In real-world applications, such as connected autonomous driving, vehicles face
challenges in directly sharing raw observations due to limited communication
bandwidth. In order to address this challenge, we propose a novel approach for
bandwidth-adaptive spatiotemporal CoID in collaborative perception. This
approach allows robots to progressively select partial spatiotemporal
observations and share with others, while adapting to communication constraints
that dynamically change over time. We evaluate our approach across various
scenarios in connected autonomous driving simulations. Experimental results
validate that our approach enables CoID and adapts to dynamic communication
bandwidth changes. In addition, our approach achieves 8%-56% overall
improvements in terms of covisible object retrieval for CoID and data sharing
efficiency, which outperforms previous techniques and achieves the
state-of-the-art performance. More information is available at:
https://gaopeng5.github.io/acoid.",http://arxiv.org/abs/2502.12098v1
Not-So-Optimal Transport Flows for 3D Point Cloud Generation,2025-02-18T02:37:34Z,"Ka-Hei Hui, Chao Liu, Xiaohui Zeng, Chi-Wing Fu, Arash Vahdat","Learning generative models of 3D point clouds is one of the fundamental
problems in 3D generative learning. One of the key properties of point clouds
is their permutation invariance, i.e., changing the order of points in a point
cloud does not change the shape they represent. In this paper, we analyze the
recently proposed equivariant OT flows that learn permutation invariant
generative models for point-based molecular data and we show that these models
scale poorly on large point clouds. Also, we observe learning (equivariant) OT
flows is generally challenging since straightening flow trajectories makes the
learned flow model complex at the beginning of the trajectory. To remedy these,
we propose not-so-optimal transport flow models that obtain an approximate OT
by an offline OT precomputation, enabling an efficient construction of OT pairs
for training. During training, we can additionally construct a hybrid coupling
by combining our approximate OT and independent coupling to make the target
flow models easier to learn. In an extensive empirical study, we show that our
proposed model outperforms prior diffusion- and flow-based approaches on a wide
range of unconditional generation and shape completion on the ShapeNet
benchmark.",http://arxiv.org/abs/2502.12456v1
Ultrafast annealing process of MTJ using hybrid microwave annealing,2025-02-18T11:34:40Z,"Ming-Chun Hsu, Fan-Yun Chiu, Wei-Chi Aeneas Hsu, Chang-Shan Shen, Kun-Ping Huang, Tsun-Hsu Chang","This paper discovers that the magnetic tunnel junction (MTJ) structure is
successfully magnetized with hybrid microwave annealing, confirmed by the
tunneling magnetoresistance (TMR) and Coercivity (Hc) results. Hybrid microwave
annealing can transform CoFeB into a single crystal and form the Fe-O bond at
the interface between CoFeB and MgO without adding an extra magnet. The
annealing time is significantly reduced from the original 120 minutes to just 1
minute, allowing for rapid low-temperature annealing of the MTJ structure. The
TEM results are used to determine the change in the lattice structure of CoFeB
from amorphous to a single crystal, and the EELS result indicates the diffusion
distribution of atoms in the MTJ structure. This hybrid annealing process can
save a significant amount of fabrication time and is an energy-efficient
alternative to the current fabrication process of MRAM.",http://arxiv.org/abs/2502.12772v1
DNA Sensing with Whispering Gallery Mode Microlasers,2025-02-19T12:16:05Z,"Soraya Caixeiro, Robert Dörrenhaus, Anna Popczyk, Marcel Schubert, Stephanie Kath-Schorr, Malte C. Gather","Nucleic acid sensing is crucial for advancing diagnostics, therapeutic
monitoring and molecu-lar biology research, by enabling the precise
identification of DNA and RNA interactions. Here, we present an innovative
sensing platform based on DNA-functionalized whispering gallery mode (WGM)
microlasers. By correlating spectral shifts in laser emission to changes in
refractive index, we demonstrate real-time detection of DNA hybridization and
structural changes. The addition of gold nanoparticles to the DNA strands
significantly enhances sensi-tivity, and labeling exclusively the sensing
strand or a hairpin strand eliminates the need for secondary labeling of the
target strand. We further show that ionic strength influences DNA compactness,
and we introduce a hairpin-based system as a dual-purpose sensor and
con-trolled release mechanism for potential drug delivery. This versatile
WGM-based platform of-fers promise for sequence-specific nucleic acid sensing,
multiplexed detection, and in vivo ap-plications in diagnostics and cellular
research.",http://arxiv.org/abs/2502.13664v1
RobustX: Robust Counterfactual Explanations Made Easy,2025-02-19T14:12:01Z,"Junqi Jiang, Luca Marzari, Aaryan Purohit, Francesco Leofante","The increasing use of Machine Learning (ML) models to aid decision-making in
high-stakes industries demands explainability to facilitate trust.
Counterfactual Explanations (CEs) are ideally suited for this, as they can
offer insights into the predictions of an ML model by illustrating how changes
in its input data may lead to different outcomes. However, for CEs to realise
their explanatory potential, significant challenges remain in ensuring their
robustness under slight changes in the scenario being explained. Despite the
widespread recognition of CEs' robustness as a fundamental requirement, a lack
of standardised tools and benchmarks hinders a comprehensive and effective
comparison of robust CE generation methods. In this paper, we introduce
RobustX, an open-source Python library implementing a collection of CE
generation and evaluation methods, with a focus on the robustness property.
RobustX provides interfaces to several existing methods from the literature,
enabling streamlined access to state-of-the-art techniques. The library is also
easily extensible, allowing fast prototyping of novel robust CE generation and
evaluation methods.",http://arxiv.org/abs/2502.13751v1
"Grid Labeling: Crowdsourcing Task-Specific Importance from
  Visualizations",2025-02-19T17:35:38Z,"Minsuk Chang, Yao Wang, Huichen Will Wang, Andreas Bulling, Cindy Xiong Bearfield","Knowing where people look in visualizations is key to effective design. Yet,
existing research primarily focuses on free-viewing-based saliency models, even
though visual attention is inherently task-dependent. Collecting task-relevant
importance data remains a resource-intensive challenge. To address this, we
introduce Grid Labeling, a novel annotation method for collecting task-specific
importance data to enhance saliency prediction models. Grid Labeling
dynamically segments visualizations into Adaptive Grids, enabling efficient,
low-effort annotation while adapting to visualization structure. We conducted a
human-subject study comparing Grid Labeling with existing annotation methods,
ImportAnnots and BubbleView, across multiple metrics. Results show that Grid
Labeling produces the least noisy data and the highest inter-participant
agreement with fewer participants while requiring less physical (e.g.,
clicks/mouse movements) and cognitive effort.",http://arxiv.org/abs/2502.13902v1
CND-IDS: Continual Novelty Detection for Intrusion Detection Systems,2025-02-19T20:47:22Z,"Sean Fuhrman, Onat Gungor, Tajana Rosing","Intrusion detection systems (IDS) play a crucial role in IoT and network
security by monitoring system data and alerting to suspicious activities.
Machine learning (ML) has emerged as a promising solution for IDS, offering
highly accurate intrusion detection. However, ML-IDS solutions often overlook
two critical aspects needed to build reliable systems: continually changing
data streams and a lack of attack labels. Streaming network traffic and
associated cyber attacks are continually changing, which can degrade the
performance of deployed ML models. Labeling attack data, such as zero-day
attacks, in real-world intrusion scenarios may not be feasible, making the use
of ML solutions that do not rely on attack labels necessary. To address both
these challenges, we propose CND-IDS, a continual novelty detection IDS
framework which consists of (i) a learning-based feature extractor that
continuously updates new feature representations of the system data, and (ii) a
novelty detector that identifies new cyber attacks by leveraging principal
component analysis (PCA) reconstruction. Our results on realistic intrusion
datasets show that CND-IDS achieves up to 6.1x F-score improvement, and up to
6.5x improved forward transfer over the SOTA unsupervised continual learning
algorithm. Our code will be released upon acceptance.",http://arxiv.org/abs/2502.14094v1
"Innovative Financing Solutions: A Transformative Driver for Financial
  Performance of Businesses in Morocco",2025-02-20T09:31:43Z,"Nohayla Badrane, Zineb Bamousse","In a rapidly evolving landscape marked by continuous change and complex
challenges, effective cash management stands as a cornerstone for ensuring
business sustainability and driving performance. To address these pressing
demands, cash managersare increasingly turning to innovative financing
solutions such as venture capital, green finance, crowdfunding, advanced
services from Pan-African banks, and blockchain technology. These cutting-edge
tools are pivotal in bolstering resilience against market volatility,
ecological transitions, and the accelerating pace of technological change. The
present article aims to examine how such innovative financial approaches can
serve as strategic drivers, enabling businesses to transform challenges into
opportunities. The analysis underscores that rethinking cash management through
innovation is a critical pathway toboost the performance of Moroccan companies.
Therefore, embracing these forward-thinking strategies unlocks new avenues for
development empowering them to adapt with agility amidst the uncertainties of a
shifting environment.",http://arxiv.org/abs/2502.14393v1
"Stories that (are) Move(d by) Markets: A Causal Exploration of Market
  Shocks and Semantic Shifts across Different Partisan Groups",2025-02-20T12:26:56Z,"Felix Drinkall, Stefan Zohren, Michael McMahon, Janet B. Pierrehumbert","Macroeconomic fluctuations and the narratives that shape them form a mutually
reinforcing cycle: public discourse can spur behavioural changes leading to
economic shifts, which then result in changes in the stories that propagate. We
show that shifts in semantic embedding space can be causally linked to
financial market shocks -- deviations from the expected market behaviour.
Furthermore, we show how partisanship can influence the predictive power of
text for market fluctuations and shape reactions to those same shocks. We also
provide some evidence that text-based signals are particularly salient during
unexpected events such as COVID-19, highlighting the value of language data as
an exogenous variable in economic forecasting. Our findings underscore the
bidirectional relationship between news outlets and market shocks, offering a
novel empirical approach to studying their effect on each other.",http://arxiv.org/abs/2502.14497v1
"Lattice distortion tuning resistivity invar effect in high entropy
  alloys",2025-02-20T13:20:46Z,"Hao Chen, Yuanji Xu, Lihua Liu, Yue Chen, Jan Wróbel, Daoyong Cong, Fuyang Tian","Materials with an ultra-low temperature coefficient of resistivity are
desired for the temperature and flow sensors in high-precision electronic
measuring systems. In this work, the Kubo-Greenwood formula, implemented in ab
initio molecular dynamics simulations, is employed to predict the
finite-temperature resistivity of multi-component alloys with severe lattice
distortion. We observe a tiny change in resistivity over a wide temperature
range in high-entropy alloys. The electronic resistivity invar effect in B2
Ni$_{25}$Co$_{25}$(HfTiZr)$_{50}$ Elinvar alloys results from a balance between
intrinsic and residual resistivity. This effect is associated with atomic
displacements from ideal lattice sites, which are caused by lattice thermal
vibrations and chemical disorder-induced lattice distortions. It is further
evidenced by a decrease in lattice distortion with temperature and changes in
the electronic density of states.",http://arxiv.org/abs/2502.14542v1
"Environmental Factors Can Have Opposite Biodiversity Influences on the
  Community Temporal Stability In Aquatic Ecosystems",2025-01-06T14:31:21Z,"Zihao Wen, Hang Shan, Hao Wang, Yu Cao, Liang He, Wenjing Ren, Chengjie Yin, Qingchuan Chou, Chaochao Lv, Haojie Su, Tao Tang, Qinghua Cai, Leyi Ni, Wen Xiao, Xiaolin Zhang, Kuanyi Li, Te Cao, Ming-Chih Chiu, Vincent H. Resh, Pablo Urrutia-Cordero","1. An understanding of how biodiversity confers ecosystem stability is
crucial in managing ecosystems under major environmental changes. Multiple
biodiversity drivers can stabilize ecosystem functions over time. However, we
know little about how local environmental conditions can influence these
biodiversity drivers, and consequently how they indirectly shape the ecological
stability of ecosystems.
  2. We hypothesized that environmental factors can have opposite influences
(i.e., not necessarily either positive or negative) on the temporal stability
of communities in different environmental ranges depending on the biodiversity
drivers involved. We tested this novel hypothesis by using data from a
4-year-long field study of submerged macrophyte across a water depth gradient
in 8 heterogeneous bays of Erhai lake (with total sample size of 30,071
quadrats), a large lentic system in China.
  3. Results indicate that a unimodal pattern of stability in temporal biomass
measurements occurred along the water-depth gradient, and that multiple
biodiversity drivers (the asynchrony in species dynamics, and the stability of
dominant species) generally increased the temporal stability of aquatic primary
producers. However, the effect of water depth either increased or decreased the
stability of biomass according to the environmental conditions associated with
sites along the water depth gradient.
  4. Synthesis. These results reveal the influence of local environmental
conditions on the biodiversity drivers of stability may help predict the
functional consequences of biodiversity change across different scenarios of
environmental change.",http://arxiv.org/abs/2501.03044v1
"Towards Probabilistic Inference of Human Motor Intentions by Assistive
  Mobile Robots Controlled via a Brain-Computer Interface",2025-01-09T23:18:38Z,"Xiaoshan Zhou, Carol M. Menassa, Vineet R. Kamat","Assistive mobile robots are a transformative technology that helps persons
with disabilities regain the ability to move freely. Although autonomous
wheelchairs significantly reduce user effort, they still require human input to
allow users to maintain control and adapt to changing environments. Brain
Computer Interface (BCI) stands out as a highly user-friendly option that does
not require physical movement. Current BCI systems can understand whether users
want to accelerate or decelerate, but they implement these changes in discrete
speed steps rather than allowing for smooth, continuous velocity adjustments.
This limitation prevents the systems from mimicking the natural, fluid speed
changes seen in human self-paced motion. The authors aim to address this
limitation by redesigning the perception-action cycle in a BCI controlled
robotic system: improving how the robotic agent interprets the user's motion
intentions (world state) and implementing these actions in a way that better
reflects natural physical properties of motion, such as inertia and damping.
The scope of this paper focuses on the perception aspect. We asked and answered
a normative question ""what computation should the robotic agent carry out to
optimally perceive incomplete or noisy sensory observations?"" Empirical EEG
data were collected, and probabilistic representation that served as world
state distributions were learned and evaluated in a Generative Adversarial
Network framework. The ROS framework was established that connected with a
Gazebo environment containing a digital twin of an indoor space and a virtual
model of a robotic wheelchair. Signal processing and statistical analyses were
implemented to identity the most discriminative features in the
spatial-spectral-temporal dimensions, which are then used to construct the
world model for the robotic agent to interpret user motion intentions as a
Bayesian observer.",http://arxiv.org/abs/2501.05610v1
"Thermal Annealing and Radiation Effects on Structural and Electrical
  Properties of NbN/GaN Superconductor/Semiconductor Junctions",2025-01-14T01:37:21Z,"Stephen Margiotta, Binzhi Liu, Saleh Ahmed Khan, Gabriel Calderon Ortiz, Ahmed Ibreljic, Jinwoo Hwang, A F M Anhar Uddin Bhuiyan","In the rapidly evolving field of quantum computing, niobium nitride (NbN)
superconductors have emerged as integral components due to their unique
structural properties, including a high superconducting transition temperature
(Tc), exceptional electrical conductivity, and compatibility with advanced
device architectures. This study investigates the impact of high-temperature
annealing and high-dose gamma irradiation on the structural and superconducting
properties of NbN films grown on GaN via reactive DC magnetron sputtering. The
as-deposited cubic {\delta}-NbN (111) films exhibited a high-intensity XRD
peak, high Tc of 12.82K, and an atomically flat surface. Annealing at 500 and
950 {\deg}C for varying durations revealed notable structural and surface
changes. High-resolution STEM indicated improved local ordering, while AFM
showed reduced surface roughness after annealing. XPS revealed a gradual
increase in the Nb/N ratio with higher annealing temperatures and durations.
High-resolution XRD and STEM analyses showed lattice constant modifications in
{\delta}-NbN films, attributed to residual stress changes following annealing.
Additionally, XRD phi-scans revealed sixfold symmetry in NbN films due to
rotational domains relative to GaN. While Tc remained stable after annealing at
500 {\deg}C, increasing the annealing temperature to 950 {\deg}C degraded Tc to
~8K and reduced the residual resistivity ratio from 0.85 in as-deposited films
to 0.29 after 30 minutes. The effects of gamma radiation (5 Mrad (Si)) were
also studied, demonstrating minimal changes to crystallinity and
superconducting performance, indicating excellent radiation resilience. These
findings highlight the potential of NbN superconductors for integration into
advanced quantum devices and their suitability for applications in
radiation-intensive environments such as space, satellites, and nuclear power
plants.",http://arxiv.org/abs/2501.07780v1
"Skeleton and Font Generation Network for Zero-shot Chinese Character
  Generation",2025-01-14T12:15:49Z,"Mobai Xue, Jun Du, Zhenrong Zhang, Jiefeng Ma, Qikai Chang, Pengfei Hu, Jianshu Zhang, Yu Hu","Automatic font generation remains a challenging research issue, primarily due
to the vast number of Chinese characters, each with unique and intricate
structures. Our investigation of previous studies reveals inherent bias capable
of causing structural changes in characters. Specifically, when generating a
Chinese character similar to, but different from, those in the training
samples, the bias is prone to either correcting or ignoring these subtle
variations. To address this concern, we propose a novel Skeleton and Font
Generation Network (SFGN) to achieve a more robust Chinese character font
generation. Our approach includes a skeleton builder and font generator. The
skeleton builder synthesizes content features using low-resource text input,
enabling our technique to realize font generation independently of content
image inputs. Unlike previous font generation methods that treat font style as
a global embedding, we introduce a font generator to align content and style
features on the radical level, which is a brand-new perspective for font
generation. Except for common characters, we also conduct experiments on
misspelled characters, a substantial portion of which slightly differs from the
common ones. Our approach visually demonstrates the efficacy of generated
images and outperforms current state-of-the-art font generation methods.
Moreover, we believe that misspelled character generation have significant
pedagogical implications and verify such supposition through experiments. We
used generated misspelled characters as data augmentation in Chinese character
error correction tasks, simulating the scenario where students learn
handwritten Chinese characters with the help of misspelled characters. The
significantly improved performance of error correction tasks demonstrates the
effectiveness of our proposed approach and the value of misspelled character
generation.",http://arxiv.org/abs/2501.08062v1
"Multiplex Nodal Modularity: A novel network metric for the regional
  analysis of amnestic mild cognitive impairment during a working memory
  binding task",2025-01-16T19:27:20Z,"Avalon Campbell-Cousins, Federica Guazzo, Mark Bastin, Mario A. Parra, Javier Escudero","Modularity is a well-established concept for assessing community structures
in various single and multi-layer networks, including those in biological and
social domains. Biological networks, such as the brain, are known to exhibit
group structure at a variety of scales -- local, meso, and global scale.
Modularity, while useful in describing mesoscale brain organization, is limited
as a metric to a global scale describing the overall strength of community
structure. This approach, while valuable, overlooks important localized
variations in community structure at the node level. To address this
limitation, we extended modularity to individual nodes. This novel measure of
nodal modularity ($nQ$) captures both meso and local scale changes in
modularity. We hypothesized that $nQ$ illuminates granular changes in the brain
due to diseases such as Alzheimer's disease (AD), which are known to disrupt
the brain's modular structure. We explored $nQ$ in multiplex networks of a
visual short-term memory binding task in fMRI and DTI data in the early stages
of AD. Observed changes in $nQ$ in fMRI and DTI networks aligned with known
trajectories of AD and were linked to common biomarkers of the disease,
including amyloid-$\beta$ and tau. Additionally, $nQ$ clearly differentiated
MCI from MCI converters showing indications that $nQ$ may be a useful
diagnostic tool for characterizing disease stages. Our findings demonstrate the
utility of $nQ$ as a measure of localized group structure, providing novel
insights into temporal and disease related variability at the node level. Given
the widespread application of modularity as a global measure, $nQ$ represents a
significant advancement, providing a granular measure of network organization
applicable to a wide range of disciplines.",http://arxiv.org/abs/2501.09805v1
"Intervening nuclear obscuration changing the X-ray look of the
  $z\approx6$ QSO CFHQS J164121+375520",2025-01-21T19:00:09Z,"Fabio Vito, William Nielsen Brandt, Andrea Comastri, Roberto Gilli, Franz Bauer, Silvia Belladitta, George Chartas, Kazushi Iwasawa, Giorgio Lanzuisi, Bin Luo, Stefano Marchesi, Marco Mignoli, Federica Ricci, Ohad Shemmer, Cristiana Spingola, Cristian Vignali, Walter Boschin, Felice Cusano, Diego Paris","X-ray observations of the optically selected $z=6.025$ QSO CFHQS
J164121+375520 (hereafter J1641) revealed that its flux dropped by a factor
$\gtrsim7$ from 2018, when it was a bright and soft X-ray source, to 2021. Such
a strong variability amplitude has not been observed before among $z>6$ QSOs,
and the underlying physical mechanism was unclear. We carried out a new X-ray
and rest-frame UV monitoring campaign of J1641 over 2022-2024. We detected
J1641 with Chandra in the 2-7 keV band, while no significant emission is
detected at softer X-ray energies, making J1641 an X-ray changing look QSO at
$z>6$. Comparing with the 2018 epoch, the 0.5-2 keV flux dropped dramatically
by a factor $>20$. We ascribe this behaviour to intervening, and still ongoing,
obscuration by Compton-thick gas intercepting our line of sight between 2018
and 2021. The screening material could be an inner disk or a failed nuclear
wind that increased their thickness. Another possibility is that we have
witnessed an occultation event due to dust-free clouds located at sub-pc/pc
scales, similar to those recently invoked to explain the remarkable X-ray
weakness of AGN discovered by JWST. These interpretations are also consistent
with the lack of strong variations of the QSO rest-frame UV lightcurve over the
same period. Future monitoring of J1641 and the possible discovery of other
X-ray changing look QSOs at $z>6$ will provide us with precious information
about the physics of rapid supermassive black-hole growth at high redshift.",http://arxiv.org/abs/2501.12449v2
Differentially Private Compression and the Sensitivity of LZ77,2025-02-13T18:42:20Z,"Jeremiah Blocki, Seunghoon Lee, Brayan Sebastián Yepes Garcia","We initiate the study of differentially private data-compression schemes
motivated by the insecurity of the popular ""Compress-Then-Encrypt"" framework.
Data compression is a useful tool which exploits redundancy in data to reduce
storage/bandwidth when files are stored or transmitted. However, if the
contents of a file are confidential then the length of a compressed file might
leak confidential information about the content of the file itself. Encrypting
a compressed file does not eliminate this leakage as data encryption schemes
are only designed to hide the content of confidential message instead of the
length of the message. In our proposed Differentially Private
Compress-Then-Encrypt framework, we add a random positive amount of padding to
the compressed file to ensure that any leakage satisfies the rigorous privacy
guarantee of $(\epsilon,\delta)$-differential privacy. The amount of padding
that needs to be added depends on the sensitivity of the compression scheme to
small changes in the input, i.e., to what degree can changing a single
character of the input message impact the length of the compressed file. While
some popular compression schemes are highly sensitive to small changes in the
input, we argue that effective data compression schemes do not necessarily have
high sensitivity. Our primary technical contribution is analyzing the
fine-grained sensitivity of the LZ77 compression scheme (IEEE Trans. Inf.
Theory 1977) which is one of the most common compression schemes used in
practice. We show that the global sensitivity of the LZ77 compression scheme
has the upper bound $\mathcal{O}(W^{2/3}\log n)$ where $W\leq n$ denotes the
size of the sliding window. When $W=n$, we show the lower bound
$\Omega(n^{2/3}\log^{1/3}n)$ for the global sensitivity of the LZ77 compression
scheme which is tight up to a sublogarithmic factor.",http://arxiv.org/abs/2502.09584v1
"On the Impacts of Halo Model Implementations in Sunyaev-Zeldovich
  Cross-Correlation Analyses",2025-02-18T21:19:14Z,"Chad Popik, Nicholas Battaglia, Aleksandra Kusiak, Boris Bolliet, J. Colin Hill","Statistical studies of the circumgalactic medium (CGM) using
Sunyaev-Zeldovich (SZ) observations offer a promising method of studying the
gas properties of galaxies and the astrophysics that govern their evolution.
Forward modeling profiles from theory and simulations allows them to be refined
directly off of data, but there are currently significant differences between
the thermal SZ (tSZ) observations of the CGM and the predicted tSZ signal.
While these discrepancies could be inherent, they could also be the result of
decisions in the forward modeling used to build statistical measures off of
theory. In order to see effects of this, we compare an analysis utilizing halo
occupancy distributions (HODs) implemented in halo models to simulate the
galaxy distribution against a previous studies which weighted their results off
of the CMASS galaxy sample, which contains nearly one million galaxies, mainly
centrals of group sized halos, selected for relatively uniform stellar mass
across redshifts between $0.4<z<0.7$. We review some of the implementation
differences that can account for changes, such as miscentering,
one-halo/two-halo cutoff radii, and mass ranges, all of which will need to be
given the proper attention in future high-signal-to-noise studies. We find that
our more thorough model predicts a signal $\sim 25\%$ stronger than the one
from previous studies on the exact same sample, resulting in a $33\%$ improved
fit for non-dust-contaminated angular scales. Additionally, we find that
modifications that change the satellite fraction even by just a few percents,
such as editing the halo mass range and certain HOD parameters, result in
strong changes in the final signal. Although significant, this discrepancy from
the modeling choices is not large enough to completely account for the existing
disagreements between simulations and measurements.",http://arxiv.org/abs/2502.13291v1
"Thermodynamic properties of an ideal Quark-Gluon plasma under quantum
  gravitational effects",2025-01-02T09:27:25Z,"Djamel Eddine Zenkhri, Abdelhakim Benkrane","In this study, we investigate the thermodynamic properties of an ideal
Quark-Gluon Plasma (QGP) at a vanishing chemical potential, under the influence
of quantum gravitational effects, specifically incorporating the
Linear-Quadratic Generalized Uncertainty Principle (LQGUP). We analyze the
impact of LQGUP on key thermodynamic quantities, including the grand canonical
potential, pressure, energy density, entropy, speed of sound, and the bulk
viscosity's response to changes in the speed of sound. Furthermore, we extend
our analysis to examine the time evolution of the universe's temperature in the
presence of LQGUP effects.",http://arxiv.org/abs/2501.01159v1
"Solving the Porous Medium Equation with the eXtreme Mesh deformation
  approach (X-Mesh)",2025-01-06T15:26:12Z,"Alexandre Chemin, Jonathan Lambrechts, Nicolas Moës, Jean-François Remacle","We introduce a new scheme for solving the non-regularized Porous Medium
Equation. It is mass conserving and uses only positive unknown values. To
address these typically conflicting features, we employ the eXtreme Mesh
deformation approach (X-Mesh), specifically designed for problems involving
sharp interfaces. The method ensures that the interface is always meshed, even
in the face of complex topological changes, without the need for remeshing or
altering the mesh topology. We illustrate the effectiveness of the approach
through various numerical experiments.",http://arxiv.org/abs/2501.03083v1
JT Gravity in de Sitter Space and Its Extensions,2025-01-06T17:15:05Z,"Indranil Dey, Kanhu Kishore Nanda, Akashdeep Roy, Sunil Kumar Sake, Sandip P. Trivedi","We discuss and extend some aspects pertaining to the canonical quantisation
of JT gravity in de Sitter space, including the problem of time and the
construction of a Hilbert space. We then extend this discussion to other two
dimensional models obtained by changing the dilaton potential and show that the
canonical quantisation procedure can be carried out for a large class of such
models. Some discussion leading towards a path integral understanding for
states, other than the Hartle Hawking state, is also included here, along with
comments pertaining to Holography and the entropy of de Sitter space.",http://arxiv.org/abs/2501.03148v1
"Global hypoellipticity for a class of evolution operators in
  time-periodic weighted Sobolev spaces",2025-01-06T22:23:51Z,"Fernando de Ávila Silva, Matteo Bonino, Sandro Coriasco","We study the hypoellipticity properties of a class of time-periodic evolution
operators, with coefficients globally defined on $\mathbb{R}^d$ and growing
polynomially with respect to the space variable. To this aim, we introduce a
class of time-periodic weighted Sobolev spaces, whose elements are
characterised in terms of suitable Fourier expansions, associated with elliptic
operators.",http://arxiv.org/abs/2501.03414v1
Sharp bounds for product and sum throttling numbers,2025-01-07T02:23:42Z,"Ryan Blair, Gabriel Elvin, Veronika Furst, Leslie Hogben, Nandita Sahajpal, Tony W. H. Wong","Throttling in graphs optimizes a sum or product of resources used, such as
the number of vertices in an initial set, and time required, such as the
propagation time, to complete a given task. We introduce a new technique to
establish sharp upper bounds in terms of graph order for sum throttling and
initial cost product throttling for power domination. Furthermore, we establish
sharp bounds on possible changes of the product throttling number, both with
and without initial cost, caused by certain graph operations for standard zero
forcing, positive semidefinite forcing, and power domination.",http://arxiv.org/abs/2501.03472v2
Grid homology for singular links in lens space and a resolution cube,2025-01-07T07:07:59Z,Yonghan Xiao,"In this paper, we define grid homology for singular links in lens spaces and
use it to construct a resolution cube for knot Floer homology of regular links
in lens spaces. The results will first be proven over $\mathbb{Z}/2\mathbb{Z}$
and then extended to be over $\mathbb{Z}$ via a sign assignment. We will also
describe the relationship between our grid homology and classical knot Floer
homology over $\mathbb{Z}$.",http://arxiv.org/abs/2501.03579v2
"Global bifurcation diagrams for coercive third-degree polynomial
  ordinary differential equations with recurrent nonautonomous coefficients",2025-01-07T09:55:59Z,"Cinzia Elia, Roberta Fabbri, Carmen Núñez","Nonautonomous bifurcation theory is a growing branch of mathematics, for the
insight it provides into radical changes in the global dynamics of realistic
models for many real-world phenomena, i.e., into the occurrence of critical
transitions. This paper describes several global bifurcation diagrams for
nonautonomous first order scalar ordinary differential equations generated by
coercive third degree polynomials in the state variable. The conclusions are
applied to a population dynamics model subject to an Allee effect that is weak
in the absence of migration and becomes strong under a migratory phenomenon
whose sense and intensity depend on a threshold in the number of individuals in
the population.",http://arxiv.org/abs/2501.03662v1
"Changing almost perfect nonlinear functions on affine subspaces of small
  codimensions",2025-01-07T16:35:14Z,"Hiroaki Taniguchi, Alexandr Polujan, Alexander Pott, Razi Arshad","In this article, we study algebraic decompositions and secondary
constructions of almost perfect nonlinear (APN) functions. In many cases, we
establish precise criteria which characterize when certain modifications of a
given APN function yield new ones. Furthermore, we show that some of the newly
constructed functions are extended-affine inequivalent to the original ones.",http://arxiv.org/abs/2501.03922v1
"A Quasi-deterministic Channel Model for Underwater Acoustic
  Communication Systems",2025-01-08T02:32:15Z,"Yuxuan Yang, Yilin Ma, Hengtai Chang, Cheng-Xiang Wang","In this paper, a quasi-deterministic (Q-D) model for non-stationary
underwater acoustic (UWA) channels is proposed. This model combines the BELLHOP
deterministic model and geometry-based stochastic model (GBSM), which provides
higher accuracy and flexibility. Different propagation components in shallow
water are classified as D-rays, R-rays and F-rays in the proposed model, where
D-rays are modeled by BELLHOP while both R-rays and F-rays are modeled by GBSM.
Some important channel statistical properties, including time-frequency
correlation function (TF-CF), Doppler power spectrum density (PSD), average
Doppler shift, and RMS Doppler spread are derived and simulated. Finally,
simulation results illustrate the correctness of the proposed model.",http://arxiv.org/abs/2501.04238v1
"Solvent-triggered shape change in gradient-based 4D printed bilayers:
  case study on semi-crystalline polymer networks",2025-01-08T14:47:57Z,"Lorenzo Bonetti, Aron Cobianchi, Daniele Natali, Stefano Pandini, Massimo Messori, Maurizio Toselli, Giulia Scalet","We propose an approach to 4D print solvent-triggered, gradient-based bilayers
made of semi-crystalline crosslinked polymer networks. Out-of-plane bending is
obtained after immersion in the solvent, exploiting the different swelling
degrees of the layers resulting from crosslinking gradients. Lastly, a beam
model of the shape transformation is applied and experimentally validated.",http://arxiv.org/abs/2501.04546v1
"DriVLM: Domain Adaptation of Vision-Language Models in Autonomous
  Driving",2025-01-09T09:02:41Z,"Xuran Zheng, Chang D. Yoo","In recent years, large language models have had a very impressive
performance, which largely contributed to the development and application of
artificial intelligence, and the parameters and performance of the models are
still growing rapidly. In particular, multimodal large language models (MLLM)
can combine multiple modalities such as pictures, videos, sounds, texts, etc.,
and have great potential in various tasks. However, most MLLMs require very
high computational resources, which is a major challenge for most researchers
and developers. In this paper, we explored the utility of small-scale MLLMs and
applied small-scale MLLMs to the field of autonomous driving. We hope that this
will advance the application of MLLMs in real-world scenarios.",http://arxiv.org/abs/2501.05081v1
"Drift-harmonic functions with polynomial growth on asymptotically
  paraboloidal manifolds",2025-01-09T10:17:02Z,Michael B. Law,"We construct and classify all polynomial growth solutions to certain
drift-harmonic equations on complete manifolds with paraboloidal asymptotics.
These encompass the natural drift-harmonic equations on certain steady gradient
Ricci solitons. Specifically, we show that all drift-harmonic functions with
polynomial growth asymptotically separate variables, and compute the dimensions
of spaces of drift-harmonic functions with a given polynomial growth rate. The
proof uses an inductive argument that alternates between constructing and
asymptotically controlling drift-harmonic functions.",http://arxiv.org/abs/2501.05119v2
Fortuity in the D1-D5 system,2025-01-09T18:59:27Z,"Chi-Ming Chang, Ying-Hsuan Lin, Haoyu Zhang","We reformulate the lifting problem in the D1-D5 CFT as a supercharge
cohomology problem, and enumerate BPS states according to the
fortuitous/monotone classification. Focusing on the deformed $T^4$ symmetric
orbifold theory, cohomology classes in the $N=2$ theory are explicitly
constructed and matched with the exact BPS partition function. For general $N$,
an infinite set of monotone cohomology classes are characterized and
conjectured to be exhaustive. We further describe how to assemble BPS states at
smaller $N$ into BPS states at larger $N$, and interpret their holographic
duals as black hole bound states and massive stringy excitations on smooth
horizonless (e.g. Lunin-Mathur) geometries.",http://arxiv.org/abs/2501.05448v1
Smoothing surfaces on fourfolds,2025-01-10T00:12:20Z,"Scott Nollet, A. P. Rao","If $\mathcal E, \mathcal F$ are vector bundles of ranks $r-1,r$ on a smooth
fourfold $X$ and $\mathcal{Hom}(\mathcal E,\mathcal F)$ is globally generated,
it is well known that the general map $\phi: \mathcal E \to \mathcal F$ is
injective and drops rank along a smooth surface. Chang improved on this with a
filtered Bertini theorem. We strengthen these results by proving variants in
which (a) $\mathcal F$ is not a vector bundle and (b) $\mathcal{Hom}(\mathcal
E,\mathcal F)$ is not globally generated. As an application, we give examples
of even linkage classes of surfaces on $\mathbb P^4$ in which all integral
surfaces are smoothable, including the linkage classes associated with the
Horrocks-Mumford surface.",http://arxiv.org/abs/2501.05630v1
"The Waters We Swim In: Replicability and the Evolution of Scientific
  Norms",2025-01-10T08:44:46Z,"Hope Bretscher, Núria Muñoz Garganté","In recent years, a series of high-profile retractions and fraud cases have
arisen in physics, sparking a conversation about research integrity and
replicability. Here, we discuss how the practice of science is shaped by the
social and political context in which it operates. Reflection on our norms and
values could provide a route to create community-driven safeguards that respond
to the changing demands in which our research occurs. We propose that
collaborations between physicists, philosophers, social scientists, and
historians of science could facilitate these reflections and provide new ideas
for social science and humanities colleagues.",http://arxiv.org/abs/2501.05788v1
Stieltjes differential systems with non monotonic derivators,2025-01-11T19:19:49Z,"Marlène Frigon, F. Adrián F. Tojo","In this work we study Stieltjes differential systems of which the derivators
are allowed to change sign. This leads to the definition of the notion of
\emph{function of controlled variation}, a characterization of precompact sets
of $g$-continuous functions, and an explicit expression of $g$-exponential
maps. Finally, we prove a Peano-type existence result and apply it to a model
of fluid stratification on buoyant miscible jets and plumes.",http://arxiv.org/abs/2501.06624v1
"Necessary and sufficient condition for constructing a single qudit
  insertion/deletion code and its decoding algorithm",2025-01-13T02:59:18Z,Taro Shibayama,"This paper shows that Knill-Laflamme condition, known as a necessary and
sufficient condition for quantum error-correction, can be applied to quantum
errors where the number of particles changes before and after the error. This
fact shows that correctabilities of single deletion errors and single insertion
errors are equivalent. By applying Knill-Laflamme condition, we generalize the
previously known correction conditions for single insertion and deletion errors
to necessary and sufficient level. By giving an example that satisfies this
condition, we construct a new single qudit insertion/deletion code and explain
its decoding algorithm.",http://arxiv.org/abs/2501.07027v1
"Limiting absorption principle of Helmholtz equation with sign changing
  coefficients under periodic structure",2025-01-13T11:29:53Z,"Wenjing Zhang, Yu Chen, Yixian Gao","Negative refractive index materials have garnered widespread attention due to
their anomalous electromagnetic properties. In this paper, we utilize
complementing boundary conditions to conduct a priori estimates for Cauchy
problems and derive the limiting absorption principle. Consequently, we
establish the well-posedness of the transmission problem involving conventional
materials and negative refractive index materials within a simulated
two-dimensional periodic structure.",http://arxiv.org/abs/2501.07229v1
Anonymous Attention and Abuse,2025-01-13T15:27:35Z,"Florian Ederer, Paul Goldsmith-Pinkham, Kyle Jensen","We analyze the content of the anonymous online discussion forum Economics Job
Market Rumors (EJMR) and document its evolving interactions with external
information sources. We focus on three key aspects: the prevalence and impact
of links to external domains, the surge in discussions driven by Twitter posts
since 2018, and the categorization of individuals whose tweets are most
frequently discussed on EJMR. Using data on linked domains, we show how these
trends reflect broader changes in the economics profession's digital footprint.
Our analysis sheds light on EJMR's informational role but also raises questions
about inclusivity and professional ethics in economics.",http://arxiv.org/abs/2501.07410v1
"Paper Fortune Tellers in the combinatorial dynamics of some generalized
  McMullen maps with both critical orbits bounded",2025-01-13T18:30:02Z,"Suzanne Boyd, Kelsey Brouwer","For the family of complex rational functions known as ""Generalized McMullen
maps"", F(z) = z^n + a/z^n+b, for complex parameters a and b, with a nonzero,
and any integer n at least 3 fixed, we reveal, and provide a combinatorial
model for, some new dynamical behavior. In particular, we describe a large
class of maps whose Julia sets contain both infinitely many homeomorphic copies
of quadratic Julia sets and infinitely many subsets homeomorphic to a set which
is obtained by starting with a quadratic Julia set, then changing a finite
number of pairs of external ray landing point identifications, following an
algorithm we will describe.",http://arxiv.org/abs/2501.07545v1
A mathematical model for the progression of dental caries,2025-01-13T16:12:07Z,"Rene Fabregas, Jacob Rubinstein","A model for the progression of dental caries is derived. The analysis starts
at the microscopic reaction and diffusion process. The local equations are
averaged to derive a set of macroscopic equations. The global system includes
features such as anisotropic diffusion and local changes in the geometry due to
the enamel melting. The equations are then solved numerically. The simulations
highlight the effect of anisotropy. In addition we draw conclusions on the
progression rate of caries, and discuss them in light of a number of
experiments.",http://arxiv.org/abs/2501.07619v1
Polyakov-Alvarez Formula for Curvilinear Polygonal Domains with Slits,2025-01-13T20:41:59Z,Ellen Krusell,"We consider the $\zeta$-regularized determinant of the Friedrichs extension
of the Dirichlet Laplace-Beltrami operator on curvilinear polygonal domains
with corners of arbitrary positive angles. In particular, this includes slit
domains. We obtain a short time asymptotic expansion of the heat trace using a
classical patchwork method. This allows us to define the $\zeta$-regularized
determinant of the Laplacian and prove a comparison formula of Polyakov-Alvarez
type for a smooth and conformal change of metric.",http://arxiv.org/abs/2501.07682v1
Counterexamples to a conjecture of Adams,2025-01-14T02:40:34Z,Feifei Fan,"For any odd prime $p$ and any integer $n>0$ with $p^2|n$, we show that the
mod $p$ cohomology ring of the classifying space of the projective unitary
group $PU(n)$ is not completely detected by elementary abelian $p$-subgroups,
providing counterexamples to a conjecture due to J. F. Adams.",http://arxiv.org/abs/2501.07797v4
The existence of pyramidal Steiner triple systems over abelian groups,2025-01-14T08:30:52Z,"Yanxun Chang, Tommaso Traetta, Junling Zhou","A Steiner triple system STS$(v)$ is called $f$-pyramidal if it has an
automorphism group fixing $f$ points and acting sharply transitively on the
remaining ones. In this paper, we focus on the STSs that are $f$-pyramidal over
some abelian group. Their existence has been settled only for the smallest
admissible values of $f$, that is, $f=0,1,3$.
  In this paper, we complete this result and determine, for every $f>3$, the
spectrum of values $(f,v)$ for which there is an $f$-pyramidal STS$(v)$ over an
abelian group. This result is obtained by constructing difference families
relative to a suitable partial spread.",http://arxiv.org/abs/2501.07928v1
Pulse compression by photoexcitation-induced dynamics of Bragg mirrors,2025-01-15T08:00:14Z,"Zukhriddin Ruziev, Kazuhiro Yabana, Anton Husakou","We propose dynamical Bragg mirrors as a means to compress intense short
optical pulses. We show that strong-field photoexcitation of carriers changes
the refractive index of the layers and leads to motion of the resonance-defined
boundary of the Bragg mirror. In a reflection geometry, this
counter-propagating motion leads to significant compression of the incident
pulse. We utilize a finite-difference time-domain numerical model to predict up
to a 6-fold pulse compression in the few-femtosecond regime. Modification of
the refractive index and properties of the compressed pulse as a function of
the incident pulse parameters are investigated.",http://arxiv.org/abs/2501.08637v1
The Berry-Esseen Bound for High-dimensional Self-normalized Sums,2025-01-15T17:52:38Z,"Woonyoung Chang, Kenta Takatsu, Konrad Urban, Arun Kumar Kuchibhotla","This manuscript studies the Gaussian approximation of the coordinate-wise
maximum of self-normalized statistics in high-dimensional settings. We derive
an explicit Berry-Esseen bound under weak assumptions on the absolute moments.
When the third absolute moment is finite, our bound scales as
$\log^{5/4}(d)/n^{1/8}$ where $n$ is the sample size and $d$ is the dimension.
Hence, our bound tends to zero as long as $\log(d)=o(n^{1/10})$. Our results on
self-normalized statistics represent substantial advancements, as such a bound
has not been previously available in the high-dimensional central limit theorem
(CLT) literature.",http://arxiv.org/abs/2501.08979v1
"Surface transport and barrier effects in metal halide perovskites
  explored by bias polarity switching",2025-01-15T10:24:38Z,"Marian Betusiak, Roman Grill, Eduard Belas, Petr Praus, Mykola Brynza, Mahshid Ahmadi, Jonghee Yang, Artem Musiienko","Surface transport and barrier effects in metal halide perovskites explored by
bias polarity switching. By bias polarity switching we experimentally proved
that free and trapped holes accumulate beneath the contact barrier. Further
investigation proved that the duration of bias pulse changes surface properties
that surprisingly affect only free holes. Temperature dependence of accumulated
hole dissipation revealed two activation energies 150meV the height of the
barrier and 770meV corresponding to a yet unknown process.",http://arxiv.org/abs/2501.09047v1
The sleeping bacterium: shedding light on the resuscitation mechanism,2025-01-16T08:25:02Z,"Eleonora Alfinito, Matteo Beccaria","The revival mechanism in dormant bacteria is a puzzling and open issue. We
propose a model of information diffusion on a regular grid where agents
represent bacteria and their mutual interactions implement quorum sensing.
Agents may have different metabolic characteristics corresponding to multiple
phenotypes. The intra/inter phenotype cooperation is analyzed under different
metabolic and productivity conditions. We study the interactions between
rapidly reproducing active bacteria and non-reproducing quiescent bacteria. We
highlight the conditions under which the quiescent bacteria may revive. The
occurrence of revival is generally related to a change in environmental
conditions. Our results support this picture showing that revival can be
mediated by the presence of different catalyst bacteria that produce the
necessary resources .",http://arxiv.org/abs/2501.09366v1
Sensorimotor Control Strategies for Tactile Robotics,2025-01-16T11:10:10Z,"Enrico Donato, Matteo Lo Preti, Lucia Beccai, Egidio Falotico","How are robots becoming smarter at interacting with their surroundings?
Recent advances have reshaped how robots use tactile sensing to perceive and
engage with the world. Tactile sensing is a game-changer, allowing robots to
embed sensorimotor control strategies to interact with complex environments and
skillfully handle heterogeneous objects. Such control frameworks plan
contact-driven motions while staying responsive to sudden changes. We review
the latest methods for building perception and control systems in tactile
robotics while offering practical guidelines for their design and
implementation. We also address key challenges to shape the future of
intelligent robots.",http://arxiv.org/abs/2501.09468v2
"Infrared Behavior of Induced Gravitational Waves from Isocurvature
  Perturbations",2025-01-17T03:38:51Z,"Chang Han, Zu-Cheng Chen, Hongwei Yu, Puxun Wu","Induced gravitational waves provide a powerful probe of primordial
perturbations in the early universe through their distinctive spectral
properties. We analyze the spectral energy density $\Omega_{\text{GW}}$ of
gravitational waves induced by isocurvature scalar perturbations. In the
infrared regime, we find that the spectral slope $n_{\text{GW}} \equiv \text{d}
\ln\Omega_\mathrm{GW}/\text{d}\ln k$ takes the log-dependent form $3-4/ \ln
(\tilde{k}_*^2 / 6k^2)$, where $\tilde{k}_*$ represents the effective peak
scale of the primordial scalar power spectrum. This characteristic behavior
differs markedly from that of adiabatic-induced gravitational waves,
establishing a robust observational discriminant between isocurvature and
adiabatic primordial perturbation modes.",http://arxiv.org/abs/2501.09939v1
Strong Consistency of Sparse K-means Clustering,2025-01-17T06:50:24Z,"Jeungju Kim, Johan Lim","In this paper, we prove the strong consistency of the sparse K-means method
proposed by Witten and Tibshirani (2010). We prove the consistency in both risk
and clustering for the Euclidean distance. We discuss the characterization of
the limit of the clustering under some special cases. For the general distance,
we prove the consistency in risk. Our result naturally extends to other models
with the same objective function but different constraints such as l0 or l1
penalty in Chang et al. (2018).",http://arxiv.org/abs/2501.09983v1
BBPOS: BERT-based Part-of-Speech Tagging for Uzbek,2025-01-17T10:50:22Z,"Latofat Bobojonova, Arofat Akhundjanova, Phil Ostheimer, Sophie Fellenz","This paper advances NLP research for the low-resource Uzbek language by
evaluating two previously untested monolingual Uzbek BERT models on the
part-of-speech (POS) tagging task and introducing the first publicly available
UPOS-tagged benchmark dataset for Uzbek. Our fine-tuned models achieve 91%
average accuracy, outperforming the baseline multi-lingual BERT as well as the
rule-based tagger. Notably, these models capture intermediate POS changes
through affixes and demonstrate context sensitivity, unlike existing rule-based
taggers.",http://arxiv.org/abs/2501.10107v1
Growing Spines Ad Infinitum,2025-01-17T20:08:15Z,"Blaise Boissonneau, Anna De Mase, Franziska Jahnke, Pierre Touchard","We show that every non-trivial ordered abelian group $G$ is augmentable by
infinite elements, i.e., we have $G\preccurlyeq H\oplus G$ for some non-trivial
ordered abelian group $H$. As an application, we show that when $k$ is a field
of characteristic 0, then $k$ is not $t$-henselian if and only if all henselian
valuations with residue field $k$ are ($\emptyset$-)definable.",http://arxiv.org/abs/2501.10531v2
Notes on splitting fields,2025-01-17T20:59:00Z,Cihan Bahran,"These notes include introductory material on the notion of splitting fields
for modules over a k-algebra where k is a field.",http://arxiv.org/abs/2501.10554v1
A Generative Security Application Engineering Curriculum,2025-01-18T23:17:34Z,"Wu-chang Feng, David Baker-Robinson","Generative AI and large language models (LLMs) are transforming security by
automating many tasks being performed manually. With such automation changing
the practice of security as we know it, it is imperative that we prepare future
students for the technology landscape they will ultimately face. Towards this
end, we describe an initial curriculum and course that attempts to show
students how to apply generative AI in order to solve problems in security. By
refocusing security education and training on aspects uniquely suited for
humans and showing students how to leverage automation for the rest, we believe
we can better align security education practices with generative AI as it
evolves.",http://arxiv.org/abs/2501.10900v1
Leptogenesis in a domain-wall-free Majoron+Triplet model,2025-01-20T15:09:58Z,Tim Brune,"We discuss leptogenesis in a majoron model extended by a right-handed
$SU(2)_L$ triplet fermion that prevents the appearance of cosmological domain
walls due to a change of the $[SU(2)_L]^2 \times U(1)_L$ anomaly factor. We
study several different parameter assignments and find that the interactions of
neutrinos with the new particles in the majoron+triplet model can significantly
alter the way leptogenesis proceeds. We show that for large parts of the
considered parameter space, it is essential to solve the set of coupled
Boltzmann equations for the evolution of the neutrinos and the additional
particles rather than solving the Boltzmann equations for the neutrino
evolution only.",http://arxiv.org/abs/2501.11529v1
"Detecting Free Products in the Mapping Class Group of Punctured Disks
  via Dynnikov Coordinates",2025-01-21T06:23:51Z,"Elif Medetoğulları, Elif Dalyan, S. Öykü Yurttaş","We prove that Dehn twists about opposite curves that define a complete
partition on an $n$-punctured disk $D_n$ generate either a free group or a free
product of abelian groups. Additionally, we introduce an algorithm based on
Dynnikov coordinates to determine whether a given collection of opposite curves
forms a complete partition. This algorithm not only verifies completeness but
also reveals the exact structure of the free products generated by these Dehn
twists, relying solely on the Dynnikov coordinates of the curves as input.",http://arxiv.org/abs/2501.11912v3
"Nocturnal eye inspired liquid to gas phase change soft actuator with
  Laser-Induced-Graphene: enhanced environmental light harvesting and
  photothermal conversion",2025-01-21T07:08:53Z,"Maina Sogabe, Youhyun Kim, Kenji Kawashima","Robotic systems' mobility is constrained by power sources and wiring. While
pneumatic actuators remain tethered to air supplies, we developed a new
actuator utilizing light energy. Inspired by nocturnal animals' eyes, we
designed a bilayer soft actuator incorporating Laser-Induced Graphene (LIG) on
the inner surface of a silicone layer. This design maintains silicone's
transparency and flexibility while achieving 54% faster response time compared
to conventional actuators through enhanced photothermal conversion.",http://arxiv.org/abs/2501.11930v1
"On Generalization and Distributional Update for Mimicking Observations
  with Adequate Exploration",2025-01-22T10:37:51Z,"Yirui Zhou, Xiaowei Liu, Xiaofeng Zhang, Yangchun Zhang","This paper tackles the efficiency and stability issues in learning from
observations (LfO). We commence by investigating how reward functions and
policies generalize in LfO. Subsequently, the built-in reinforcement learning
(RL) approach in generative adversarial imitation from observation (GAIfO) is
replaced with distributional soft actor-critic (DSAC). This change results in a
novel algorithm called Mimicking Observations through Distributional Update
Learning with adequate Exploration (MODULE), which combines soft actor-critic's
superior efficiency with distributional RL's robust stability.",http://arxiv.org/abs/2501.12785v1
An unusual BPS equation,2025-01-22T19:58:58Z,"Constantin Bachas, Lorenzo Bianchi, Zhongwu Chen","We prove a conjectured relation between the energy-momentum and the
displacement norm of superconformal defects. The proof completes earlier
results, and shows that supersymmetry identifies two natural notions of brane
tension in Anti-de Sitter gravity. As a byproduct we show that a modification
of the energy-momentum tensor that removes the stress of static superconformal
defects, ensures also that the radiation these emit obeys the Null Energy
Condition. This sheds new light on the radiation-reaction problem for moving
charges.",http://arxiv.org/abs/2501.13197v2
"Modified Dai-Liao Spectral Conjugate Gradient Method with Application to
  Signal Processing",2025-01-25T18:50:26Z,"D. R. Sahu, Shikher Sharma, Pankaj Gautam","In this article, we present a modified variant of the Dai-Liao spectral
conjugate gradient method, developed through an analysis of eigenvalues and
inspired by a modified secant condition. We show that the proposed method is
globally convergent for general nonlinear functions under standard assumptions.
By incorporating the new secant condition and a quasi-Newton direction, we
introduce updated spectral parameters. These changes ensure that the resulting
search direction satisfies the sufficient descent property without relying on
any line search. Numerical experiments show that the proposed algorithm
performs better than several existing methods in terms of convergence speed and
computational efficiency. Its effectiveness is further demonstrated through an
application in signal processing.",http://arxiv.org/abs/2501.15300v1
"Ma-Qiu index, presentation distance, and local moves in knot theory",2025-01-27T06:58:47Z,Tetsuya Ito,"The Ma-Qiu index of a group is the minimum number of normal generators of the
commutator subgroup. We show that the Ma-Qiu index gives a lower bound of the
presentation distance of two groups, the minimum number of relator replacements
to change one group to the other. Since many local moves in knot theory induce
relator replacements in knot groups, this shows that the Ma-Qiu index of knot
groups gives a lower bound of the Gordian distance based on various local
moves. In particular, this gives a unified and simple proof of the Nakanishi
index bounds of various unknotting numbers, including virtual or welded knot
cases.",http://arxiv.org/abs/2501.15821v1
"Equivalent Conditions for Domination of
  $\mathrm{M}(2,\mathbb{C})$-sequences",2025-01-27T10:36:28Z,"Chang Sun, Zhenghe Zhang","It is well known that a $\mathrm{SL}(2,\mathbb{C})$-sequence is uniformly
hyperbolic if and only it satisfies a uniform exponential growth condition.
Similarly, for $\mathrm{GL}(2,\mathbb{C})$-sequences whose determinants are
uniformly bounded away from zero, it has dominated splitting if and only if it
satisfies a uniform exponential gap condition between the two singular values.
Inspired by [QTZ], we provide a similar equivalent description in terms of
singular values for $\mathrm{M}(2,\mathbb{C})$-sequences that admit dominated
splitting. We also prove a version of the Avalanche Principle for such
sequences.",http://arxiv.org/abs/2501.15940v1
Poisson kernels on the half-plane are bell-shaped,2025-01-27T14:13:28Z,Mateusz Kwaśnicki,"Consider a second-order elliptic operator $L$ in the half-plane $\mathbb R
\times (0, \infty)$ with coefficients depending only on the second coordinate.
The Poisson kernel for $L$ is used in the representation of positive
$L$-harmonic functions, that is, solutions of $L u = 0$. In probabilistic
terms, the Poisson kernel is the density function of the distribution of the
diffusion in $\mathbb R \times (0, \infty)$ with generator $L$ at the hitting
time of the boundary. We prove that the Poisson kernel for $L$ is bell-shaped:
its $n$th derivative changes sign $n$ times. In particular, it is unimodal and
it has two inflection points (it is concave, then convex, then concave again).",http://arxiv.org/abs/2501.16068v1
"Multiplicatively irreducibility of small perturbations of shifted $k$-th
  powers",2025-01-28T01:37:30Z,Chi Hoi Yip,"Motivated by a conjecture of Erd\H{o}s on the additively irreducibility of
small perturbations of the set of squares, recently Hajdu and S\'{a}rk\""{o}zy
studied a multiplicative analogue of the conjecture for shifted $k$-th powers.
They conjectured that for each $k\geq 2$, if one changes $o(X^{1/k})$ elements
of $M_k'=\{x^k+1: x \in \mathbb{N}\}$ up to $X$, then the resulting set cannot
be written as a product set $AB$ nontrivially. In this paper, we confirm a more
general version of their conjecture for $k\geq 3$.",http://arxiv.org/abs/2501.16620v1
"Seasonal Influenza Vaccination Hesitancy and Digital Literacy: Evidence
  from the European countries",2025-01-28T15:00:59Z,"Martina Celidoni, Nita Handastya, Guglielmo Weber, Nancy Zambon","This study documents the relationship between computer skills/digital
literacy and influenza vaccination take-up among older adults in Europe during
and after the COVID-19 pandemic. Using data from the Survey of Health, Aging
and Retirement in Europe, we find a positive partial association between
influenza vaccination take-up and two indicators of computer skills/digital
literacy, self-assessed pre-pandemic computer skills and having used a computer
at work in any pre-pandemic job. We do not estimate significant behavioural
changes for individuals with better computer skills that may have been driven
by spillover effects from the pandemic experience.",http://arxiv.org/abs/2501.17005v1
"Demand Analysis under Price Rigidity and Endogenous Assortment: An
  Application to China's Tobacco Industry",2025-01-28T19:16:45Z,"Hui Liu, Yao Luo","We observe nominal price rigidity in tobacco markets across China. The
monopolistic seller responds by adjusting product assortments, which remain
unobserved by the analyst. We develop and estimate a logit demand model that
incorporates assortment discrimination and nominal price rigidity. We find that
consumers are significantly more responsive to price changes than conventional
models predict. Simulated tax increases reveal that neglecting the role of
endogenous assortments results in underestimations of the decline in
higher-tier product sales, incorrect directional predictions of lower-tier
product sales, and overestimation of tax revenue by more than 50%. Finally, we
extend our methodology to settings with competition and random coefficient
models.",http://arxiv.org/abs/2501.17251v1
"Non-commutative hourglasses I: On classification of the Q-Fano 3-folds
  Gorenstein index 2 via Derived category",2025-01-29T07:20:11Z,Xingbang Hao,"In previous work, Takagi used the methods of solving the Sarkisov links by
calculating the corresponding Diophantine equations and the construction of key
varieties to give all possible classifications and some implementations of a
class $\mathbb{Q}$-Fano 3-fold with Fano index 1/2 and at worst $(1, 1, 1)/2$
or QODP singularities. Firstly, we use a method different from Kawamata's work
to give the derived category formulas for general weighted blow-up and Kawamata
weighted blow-up. On this basis, we study the changing behavior of the derived
category of Takagi's varieties under Sarkisov links. Finally, by studying
non-commutative projections, we give exceptional collections on the derived
category of Takagi's varieties and their corresponding geometric meanings.",http://arxiv.org/abs/2501.17454v1
Adding MFMA Support to gem5,2025-01-30T03:32:14Z,"Marco Kurzynski, Matthew D. Sinclair","In this work we have enhanced gem5's GPU model support to add Matrix Core
Engines (MCEs). Specifically, on the AMD MI200 and MI300 GPUs that gem5
supports, these MCEs perform Matrix Fused Multiply Add (MFMA) instructions for
a variety of precisions. By adding this support, our changes enable running
state-of-the-art ML workloads in gem5, as well as examining how MCE
optimizations impact the behavior of future systems.",http://arxiv.org/abs/2501.18113v2
"Network Weighted Functional Regression: a method for modeling
  dependencies between functional data in a network",2025-01-30T09:23:31Z,"Andrea Diana, Elvira Romano, Antonio Irpino","This paper focuses on predicting continuous signals in a sensor lab network,
particularly studying microclimate changes. We propose two novel concepts:
Network Functional Data (NFD), which represents time series signals as
functions on network nodes, and the Network Weighted Functional Regression
(NWFR) model, which analyzes relationships between functional responses and
predictors in a weighted network. Additionally, we introduce a functional
conformal method to provide prediction bands with guaranteed coverage
probabilities, independent of data distribution.
  Our statistical analysis on simulated and real-world data demonstrates that
incorporating network structure enhances regression accuracy and improves the
reliability of conformal prediction regions. These findings advance the
analysis of complex network-structured data, offering a more precise and
efficient approach.",http://arxiv.org/abs/2501.18221v1
STAN: Smooth Transition Autoregressive Networks,2025-01-30T19:01:01Z,"Hugo Inzirillo, Remi Genet","Traditional Smooth Transition Autoregressive (STAR) models offer an effective
way to model these dynamics through smooth regime changes based on specific
transition variables. In this paper, we propose a novel approach by drawing an
analogy between STAR models and a multilayer neural network architecture. Our
proposed neural network architecture mimics the STAR framework, employing
multiple layers to simulate the smooth transition between regimes and capturing
complex, nonlinear relationships. The network's hidden layers and activation
functions are structured to replicate the gradual switching behavior typical of
STAR models, allowing for a more flexible and scalable approach to
regime-dependent modeling. This research suggests that neural networks can
provide a powerful alternative to STAR models, with the potential to enhance
predictive accuracy in economic and financial forecasting.",http://arxiv.org/abs/2501.18699v1
"Rank stability in quadratic extensions and Hilbert's tenth problem for
  the ring of integers of a number field",2025-01-30T21:56:25Z,"Levent Alpöge, Manjul Bhargava, Wei Ho, Ari Shnidman","We show that for any quadratic extension of number fields $K/F$, there exists
an abelian variety $A/F$ of positive rank whose rank does not grow upon base
change to $K$. This result implies that Hilbert's tenth problem over the ring
of integers of any number field has a negative solution. That is, for the ring
$\mathcal{O}_K$ of integers of any number field $K$, there does not exist an
algorithm that answers the question of whether a polynomial equation in several
variables over $\mathcal{O}_K$ has solutions in $\mathcal{O}_K$.",http://arxiv.org/abs/2501.18774v1
"Efficient preparation of entangled states in cavity QED with Grover's
  algorithm",2025-01-31T04:31:37Z,"Omar Nagib, M. Saffman, K. Mølmer","We propose to employ the amplification mechanism of Grover's search algorithm
to efficiently prepare entangled states of an ensemble of qubits. The
conditional change of sign employed in the algorithm can be implemented by the
phase shift of photons scattered on an optical cavity hosting an atomic
ensemble. We show that collective Dicke states, GHZ states, and Schr\""odinger
cat superpositions of $N$ atoms may be prepared deterministically by few ($\sim
N^{1/4}$) photon scattering events without individual addressing of the atoms.",http://arxiv.org/abs/2501.18881v2
"CAT Pruning: Cluster-Aware Token Pruning For Text-to-Image Diffusion
  Models",2025-02-01T13:46:02Z,"Xinle Cheng, Zhuoming Chen, Zhihao Jia","Diffusion models have revolutionized generative tasks, especially in the
domain of text-to-image synthesis; however, their iterative denoising process
demands substantial computational resources. In this paper, we present a novel
acceleration strategy that integrates token-level pruning with caching
techniques to tackle this computational challenge. By employing noise relative
magnitude, we identify significant token changes across denoising iterations.
Additionally, we enhance token selection by incorporating spatial clustering
and ensuring distributional balance. Our experiments demonstrate reveal a
50%-60% reduction in computational costs while preserving the performance of
the model, thereby markedly increasing the efficiency of diffusion models. The
code is available at https://github.com/ada-cheng/CAT-Pruning",http://arxiv.org/abs/2502.00433v1
Evolution of Society Caused by Collective and Individual Decisions,2025-02-01T15:56:19Z,Pavel Chebotarev,"Under the assumptions of the ViSE model, we investigate the welfare and
performance of a society consisting of one group (a ``party'') and
individualists. In the case of Gaussian proposal generators, the expected
capital gains can be expressed in standard functions. The relative
effectiveness of individualistic and group strategies of agents, as well as the
benefits of the entire society, depend on the level of cooperation, the voting
threshold, and the favorability of the environment. We focus on the evolution
of society in neutral environments caused by changing its structure and the
voting rule in the interests of agents.",http://arxiv.org/abs/2502.00471v1
"Transfer Learning in Physics-Informed Neural Networks: Full Fine-Tuning,
  Lightweight Fine-Tuning, and Low-Rank Adaptation",2025-02-02T12:40:22Z,"Yizheng Wang, Jinshuai Bai, Mohammad Sadegh Eshaghi, Cosmin Anitescu, Xiaoying Zhuang, Timon Rabczuk, Yinghua Liu","AI for PDEs has garnered significant attention, particularly Physics-Informed
Neural Networks (PINNs). However, PINNs are typically limited to solving
specific problems, and any changes in problem conditions necessitate
retraining. Therefore, we explore the generalization capability of transfer
learning in the strong and energy form of PINNs across different boundary
conditions, materials, and geometries. The transfer learning methods we employ
include full finetuning, lightweight finetuning, and Low-Rank Adaptation
(LoRA). The results demonstrate that full finetuning and LoRA can significantly
improve convergence speed while providing a slight enhancement in accuracy.",http://arxiv.org/abs/2502.00782v1
The Batch Complexity of Bandit Pure Exploration,2025-02-03T15:03:45Z,"Adrienne Tuynman, Rémy Degenne","In a fixed-confidence pure exploration problem in stochastic multi-armed
bandits, an algorithm iteratively samples arms and should stop as early as
possible and return the correct answer to a query about the arms distributions.
We are interested in batched methods, which change their sampling behaviour
only a few times, between batches of observations. We give an
instance-dependent lower bound on the number of batches used by any sample
efficient algorithm for any pure exploration task. We then give a general
batched algorithm and prove upper bounds on its expected sample complexity and
batch complexity. We illustrate both lower and upper bounds on best-arm
identification and thresholding bandits.",http://arxiv.org/abs/2502.01425v1
TeV Afterglow of BOAT GRB without Jet Break,2025-02-03T15:24:06Z,"Yo Kusafuka, Katsuaki Asano","We present a new model for the TeV afterglow of GRB 221009A. The rapid
increase of the TeV flux in the very early phase is reproduced by the magnetic
acceleration. We consider the change in the radial structure of the
circumstellar medium from homogeneous to wind-like to describe the breaks in
the TeV light curve. Our results imply a highly magnetized ejecta with a
significantly thick width, making the deceleration time around 400 s for
observers. In our model, no early jet break is required.",http://arxiv.org/abs/2502.01437v1
"On the Uncertainty of a Simple Estimator for Remote Source Monitoring
  over ALOHA Channels",2025-02-03T16:16:18Z,Andrea Munari,"Efficient remote monitoring of distributed sources is essential for many
Internet of Things (IoT) applications. This work studies the uncertainty at the
receiver when tracking two-state Markov sources over a slotted random access
channel without feedback, using the conditional entropy as a performance
indicator, and considering the last received value as current state estimate.
We provide an analytical characterization of the metric, and evaluate three
access strategies: (i) maximizing throughput, (ii) transmitting only on state
changes, and (iii) minimizing uncertainty through optimized access
probabilities. Our results reveal that throughput optimization does not always
reduce uncertainty. Moreover, while reactive policies are optimal for symmetric
sources, asymmetric processes benefit from mixed strategies allowing
transmissions during state persistence.",http://arxiv.org/abs/2502.01482v1
The Cost Perspective of Liquid Democracy: Feasibility and Control,2025-02-04T14:59:56Z,"Shiri Alouf-Heffetz, Łukasz Janeczko, Grzegorz Lisowski, Georgios Papasotiropoulos","We examine an approval-based model of Liquid Democracy with a budget
constraint on voting and delegating costs, aiming to centrally select casting
voters ensuring complete representation of the electorate. From a computational
complexity perspective, we focus on minimizing overall costs, maintaining short
delegation paths, and preventing excessive concentration of voting power.
Furthermore, we explore computational aspects of strategic control,
specifically, whether external agents can change election components to
influence the voting power of certain voters.",http://arxiv.org/abs/2502.02380v1
Quantum State Preparation via Nested Entanglement,2025-02-05T00:03:05Z,Geoffrey L. Warner,"We develop a representation of an n-qubit register that parameterizes its
statevector as a series of nested entanglements. We show that the recursive
substructure of this representation provides a natural framework for automating
the construction of quantum circuits for state preparation. It also allows for
a straightforward treatment of pure state separability. We discuss a novel
derivation of uniformly controlled rotations and the quantum Fourier transform
within this representation, and consider the effects of single-qubit basis
changes on its overall structure. We end with a discussion of the apparent
connection between the compressibility of the state description in this
representation, and the circuit complexity required to prepare it.",http://arxiv.org/abs/2502.02784v1
Popularity and Innovation in Maven Central,2025-02-05T04:38:20Z,"Nkiru Ede, Jens Dietrich, Ulrich Zülicke","Maven Central is a large popular repository of Java components that has
evolved over the last 20 years. The distribution of dependencies indicates that
the repository is dominated by a relatively small number of components other
components depend on. The question is whether those elites are static, or
change over time, and how this relates to innovation in the Maven ecosystem. We
study those questions using several metrics. We find that elites are dynamic,
and that the rate of innovation is slowing as the repository ages but remains
healthy.",http://arxiv.org/abs/2502.02879v1
Extended Massive Ambitwistor String II,2025-02-05T19:59:30Z,Christian Kunz,"This article continues previous work done in arXiv:2406.01907. It is shown in
more detail how vacuum partition functions and the cosmological constant vanish
at all orders of perturbation theory. Further, all-multiplicity higher-loop
amplitudes are given and shown to be modular invariant, to have proper
factorization, and to be UV-finite at least up to one-loop level, formally even
to all levels. Therefore, the model provides a modular invariant and unitary
N=8 supergravity theory in twistor space with embedded Super-Yang-Mills and
promising UV-finiteness behavior.",http://arxiv.org/abs/2502.03581v2
"Discrete Lyapunov functional for cyclic systems of differential
  equations with time-variable or state-dependent delay",2025-02-05T22:20:51Z,"István Balázs, Ábel Garab","We consider nonautonomous cyclic systems of delay differential equations with
variable delay. Under suitable feedback assumptions, we define an (integer
valued) Lyapunov functional related to the number of sign changes of the
coordinate functions of solutions. We prove that this functional possesses
properties analogous to those established by Mallet-Paret and Sell for the
constant delay case and by Krisztin and Arino for the scalar case. We also
apply the results to equations with state-dependent delays.",http://arxiv.org/abs/2502.03648v1
Frame-dependent coherence of a quantum state,2025-02-06T16:09:21Z,Nicolae Cotfas,"A finite-dimensional Hilbert space is usually described by using an
orthonormal basis, but a more general description can be obtained by using a
tight frame. The frame-dependent coherence, defined by following the analogy
with the basis-dependent coherence, allows us to define the coherence with
respect to several orthonormal bases considered simultaneously or with respect
to a discrete system of coherent states. By using this more general definition,
we can investigate how the basis-dependent coherence changes when we go from a
basis to another one, from a basis to a complementary one. Frame-dependent
coherence contains basis-dependent coherence as a particular case, but it
allows a deeper description of coherence.",http://arxiv.org/abs/2502.04178v1
"Temperature dependent energy gap for Yu-Shiba-Rusinov states at the
  quantum phase transition",2025-02-06T16:34:15Z,"Andreas Theiler, Christian R. Ast, Annica M. Black-Schaffer","Motivated by recent experiments, which allow for fine tuning of the effective
magnetic interaction between the impurity and the superconductor, we
investigate the regime around the quantum phase transition where the system's
ground state changes from a weakly coupled free spin to a screened spin regime.
At this transition we find that the YSR states remain at finite energies at low
temperatures, thereby generating a gap in the spectrum, which is inconsistent
with predictions of the original YSR theory. We investigate various
gap-generating scenarios and determine that the local suppression of the order
parameter, only captured by self-consistent calculations, generates the gap.",http://arxiv.org/abs/2502.04196v1
Multiple nodal solutions of planar Stein-Weiss equations,2025-02-06T22:04:24Z,"Eudes M. Barboza, Eduardo De S. Böer, Olímpio H. Miyagaki, Claudia R. Santana","In this paper, our goal is to investigate the existence of multiple nodal
solutions to a class of planar Stein-Weiss problems involving a nonlinearity
$f$ with subcritical or critical growth in the sense of Trudinger-Moser. To
achieve this, we combine a gluing approach with the Nehari manifold argument.
We demonstrate that for any positive integer $k\in \mathbb{N}$, the problem
studied has at least one radially symmetrical ground state solution that
changes sign exactly $k$-times.",http://arxiv.org/abs/2502.04532v1
"Strong law of large numbers for a function of the local times of a
  transient random walk on groups",2025-02-07T09:51:39Z,"Yinshan Chang, Qinwei Chen, Qian Meng, Xue Peng","This paper presents the strong law of large numbers for a function of the
local times of a transient random walk on groups, extending the research of
Asymont and Korshunov for random walks on the integer lattice $\mathbb{Z}^d$.
Under some weaker conditions, we prove that certain function of the local times
converges almost surely and in $L^1$ and $L^2$. The proof is mainly based on
the subadditive ergodic theorem.",http://arxiv.org/abs/2502.04792v1
Counting lifts of irreducible Brauer characters,2025-02-09T04:19:00Z,"Junwei Zhang, Xuewu Chang, Ping Jin","Let $p$ be an odd prime, and suppose that $G$ is a $p$-solvable group and
$\varphi\in {\rm IBr}(G)$ has vertex $Q$. In 2011, Cossey, Lewis and Navarro
proved that the number of lifts of $\varphi$ is at most $|Q:Q'|$ whenever $Q$
is normal in $G$. In this paper, we present an explicit description of the set
of lifts of $\varphi$ with a given vertex pair $(Q,\delta)$ under a weaker
condition on $Q$, and thus generalize their result.",http://arxiv.org/abs/2502.05771v1
"Symmetric Tensor Coupling in Holographic Mean-Field Theory: Deformed
  Dirac Cones",2025-02-09T12:14:15Z,"Moongul Byun, Taewon Yuk, Sang-Jin Sin","We extend the holographic mean-field theory to rank-two symmetric tensor
order parameter field coupled with fermion. We classify the roles of symmetric
tensor order according to the effect on the spectral density: cone-angle
change, squashing, and tilting of the spectral light cones. In case of the
over-tilted light cone, an analytic continuation of the Green's function is
necessary to preserve the continuity of the spectrum inside the lightcone. Our
results provide agreements between the holographic spectra with those observed
in real materials, such as type-II Dirac cones and strained graphene.",http://arxiv.org/abs/2502.05871v1
"Algorithm for Constructing Related Spanning Directed Forests of Minimum
  Weight",2025-02-09T16:26:47Z,Vasily Buslov,"An algorithm is proposed for constructing directed spanning forests of the
minimum weight, in which the maximum possible degree of affinity between the
minimum forests is preserved when the number of trees changes. The correctness
of the algorithm is checked and its complexity is determined, which does not
exceed $ O (N ^ 3) $ for dense graphs. The result of the algorithm is a set of
related spanning minimal forests consisting of $ k $ trees for all admissible $
k $.",http://arxiv.org/abs/2502.05946v2
Combinatorial Ricci Flow and Thurston's Triangulation Conjecture,2025-02-10T14:13:50Z,"Feng Ke, Ge Huabin","Thurston's triangulation conjecture asserts that every hyperbolic 3-manifold
admits a geometric decomposition into ideal hyperbolic tetrahedra, a result
proven only for certain special 3-manifolds. This paper presents combinatorial
Ricci flow as a systematic and general approach to addressing Thurston's
triangulation conjecture, showing that the flow converges if and only if the
triangulation is geometric. First, we prove the rigidity of the most general
hyperbolic polyhedral 3-manifolds constructed by isometrically gluing partially
truncated and decorated hyperbolic tetrahedra, demonstrating that the metrics
are uniquely determined by cone angles modulo isometry and decoration changes.
Then, we demonstrate that combinatorial Ricci flow evolves polyhedral metrics
toward complete hyperbolic structures with geometric decompositions when
convergent. Conversely, the existence of a geometric triangulation guarantees
flow convergence.",http://arxiv.org/abs/2502.06497v1
Elastically induced phase-shift and birefringence in optical fibers,2025-02-10T22:43:11Z,"Elisabeth Steininger, Thomas Mieling, Piotr T. Chruściel","We compute how elastic deformations of optical fibers affect light
propagation therein. Specifically, we consider differences in wave-guiding
properties of straight fibers subject to different external temperatures,
pressures, and gravitational fields. This is done by solving, perturbatively to
first order, the Maxwell equations in deformed and anisotropic fibers using a
multiple-scales approximation scheme. We derive explicit expressions for the
induced phase shift and birefringence. The phase shift can be expressed in
terms of the average radial pressure, longitudinal tension, and change in
temperature, while birefringence depends on the quadrupole of the external
pressure distribution and the stresses on the axis of the fiber.",http://arxiv.org/abs/2502.07099v1
Analysis of the maps with variable fractional order,2025-02-11T06:23:16Z,"Prashant M. Gade, Sachin Bhalekar, Janardhan Chevala","Fractional order differential and difference equations are used to model
systems with memory. Variable order fractional equations are proposed to model
systems where the memory changes in time. We investigate stability conditions
for linear variable order difference equations where the order is periodic
function with period $T$. We give a general procedure for arbitrary $T$ and for
$T=2$ and $T=3$, we give exact results. For $T=2$, we find that the lower order
determines the stability of the equations. For odd $T$, numerical simulations
indicate that we can approximately determine the stability of equations from
the mean value of the variables.",http://arxiv.org/abs/2502.07290v1
Some remarks on singular capillary cones with free boundary,2025-02-11T16:50:40Z,"Alberto Pacati, Giorgio Tortone, Bozhidar Velichkov","We study minimizing singular cones with free boundary associated with the
capillarity problem. Precisely, we provide a stability criterion $\`a$ la
Jerison-Savin for capillary hypersurfaces and show that, in dimensions up to
$4$, minimizing cones with non-sign-changing mean curvature are flat. We apply
this criterion to minimizing capillary drops and, additionally, establish the
instability of non-trivial axially symmetric cones in dimensions up to $6$.
  The main results are based on a Simons-type inequality for a class of convex,
homogeneous, symmetric functions of the principal curvatures, combined with a
boundary condition specific to the capillary setting.",http://arxiv.org/abs/2502.07697v1
Mathematical reasoning and the computer,2025-02-11T10:35:52Z,Kevin Buzzard,"Computers have already changed the way that humans do mathematics: they
enable us to compute efficiently. But will they soon be helping us to reason?
And will they one day start reasoning themselves? We give an overview of recent
developments in neural networks, computer theorem provers and large language
models.",http://arxiv.org/abs/2502.07850v1
Practical properties of the CUSUM process,2025-02-13T11:21:16Z,"Michael Baron, Sergey V. Malov","We explore the behavior and establish new properties of the cumulative-sum
process (CUSUM) and its running maximum. The study includes precise expressions
for CUSUM's moment generating function and moments, fast recursive computing
algorithms, lower and upper bounds, as well as asymptotes. Results are applied
to single, multiple, and transient change-point problems, for the calculation
of thresholds that provide a desired control of familywise false alarm rates,
as well as the quantiles of queuing processes and probabilities of their large
deviation at least once over a given time interval.",http://arxiv.org/abs/2502.09185v1
On mean curvature flow solitons in the sphere,2025-02-13T11:38:28Z,"Marco Magliaro, Luciano Mari, Fernanda Roing, Andreas Savas-Halilaj","In this paper, we consider soliton solutions of the mean curvature flow in
the unit sphere $S^{2n+1}$ moving along the integral curves of the Hopf unit
vector field. While such solitons must necessarily be minimal if compact, we
produce a non-minimal, complete example with topology $S^{2n-1} \times R$. The
example wraps around a Clifford torus $S^{2n-1} \times S^1$ along each end, it
has reflection and rotational symmetry and its mean curvature changes sign on
each end. Indeed, we prove that a complete 2-dimensional soliton with
non-negative mean curvature outside a compact set must be a covering of a
Clifford torus. Concluding, we obtain a pinching theorem under suitable
conditions on the second fundamental form.",http://arxiv.org/abs/2502.09199v1
Generating Causally Compliant Counterfactual Explanations using ASP,2025-02-13T11:51:53Z,Sopam Dasgupta,"This research is focused on generating achievable counterfactual
explanations. Given a negative outcome computed by a machine learning model or
a decision system, the novel CoGS approach generates (i) a counterfactual
solution that represents a positive outcome and (ii) a path that will take us
from the negative outcome to the positive one, where each node in the path
represents a change in an attribute (feature) value. CoGS computes paths that
respect the causal constraints among features. Thus, the counterfactuals
computed by CoGS are realistic. CoGS utilizes rule-based machine learning
algorithms to model causal dependencies between features. The paper discusses
the current status of the research and the preliminary results obtained.",http://arxiv.org/abs/2502.09226v1
"Optimal response for stochastic differential equations by local kernel
  perturbations",2025-02-13T13:14:07Z,"Gianmarco del Sarto, Stefano Galatolo, Sakshi Jain","We consider a random dynamical system on $\mathbb{R}^d$, whose dynamics is
defined by a stochastic differential equation. The annealed transfer operator
associated with such systems is a kernel operator. Given a set of feasible
infinitesimal perturbations $P$ to this kernel, with support in a certain
compact set, and a specified observable function $\phi: \mathbb{R}^d \to
\mathbb{R}$, we study which infinitesimal perturbation in $P$ produces the
greatest change in expectation of $\phi$. We establish conditions under which
the optimal perturbation uniquely exists and present a numerical method to
approximate the optimal infinitesimal kernel perturbation. Finally, we
numerically illustrate our findings with concrete examples.",http://arxiv.org/abs/2502.09300v1
"The $p$-rank stratification of the moduli space of double covers of a
  fixed elliptic curve",2025-02-13T17:56:42Z,"Kevin Chang, Dušan Dragutinović, Steven R. Groen, Yuxin Lin, Natalia Pacheco-Tallaj, Deepesh Singhal","In this paper we investigate the $p$-rank stratification of the moduli space
of curves of genus $g$ that admit a double cover to a fixed elliptic curve $E$
in characteristic $p>2$. We show that the closed $p$-rank strata of this moduli
space are equidimensional of the expected dimension. We also show the existence
of a smooth double cover of $E$ of all the possible values of the $p$-rank on
this moduli space.",http://arxiv.org/abs/2502.09540v1
"Leveraging V2X for Collaborative HD Maps Construction Using Scene Graph
  Generation",2025-02-14T12:56:10Z,"Gamal Elghazaly, Raphael Frank","High-Definition (HD) maps play a crucial role in autonomous vehicle
navigation, complementing onboard perception sensors for improved accuracy and
safety. Traditional HD map generation relies on dedicated mapping vehicles,
which are costly and fail to capture real-time infrastructure changes. This
paper presents HDMapLaneNet, a novel framework leveraging V2X communication and
Scene Graph Generation to collaboratively construct a localized geometric layer
of HD maps. The approach extracts lane centerlines from front-facing camera
images, represents them as graphs, and transmits the data for global
aggregation to the cloud via V2X. Preliminary results on the nuScenes dataset
demonstrate superior association prediction performance compared to a
state-of-the-art method.",http://arxiv.org/abs/2502.10127v1
"Giant vortex in a harmonically-trapped rotating dipolar $^{164}$Dy
  condensate",2025-02-14T16:29:46Z,"Luis E. Young-S., S. K. Adhikari","We demonstrate the formation of dynamically stable giant vortices in a
harmonically-trapped strongly dipolar $^{164}$Dy Bose-Einstein condensate under
rotation around the polarization direction of dipolar atoms, employing the
numerical solution of an improved mean-field model including a
Lee-Huang-Yang-type interaction, meant to stop a collapse at high atom density.
These giant vortices are stationary, obtainable by imaginary-time propagation
using a Gaussian initial state, while the appropriate phase of the giant vortex
is imprinted on the initial wave function. The dynamical stability of the giant
vortices is established by real-time propagation during a long interval of time
after a small change of a parameter.",http://arxiv.org/abs/2502.10272v1
"Long-term behavior for wave equation with nonlinear damping and
  super-cubic nonlinearity",2025-02-15T11:42:01Z,"Cuncai Liu, Fengjuan Meng, Chang Zhang","In this paper, we consider the semilinear wave equation involving the
nonlinear damping term $g(u_t) $ and nonlinearity $f(u)$. The well-posedness of
the weak solution satisfying some additional regularity is achieved under the
wider ranges of the exponents $g$ and $f$. Moreover, the existence of global
attractor and exponential attractor are proved.",http://arxiv.org/abs/2502.10774v1
On the Computation of the Fisher Information in Continual Learning,2025-02-17T12:52:10Z,Gido M. van de Ven,"One of the most popular methods for continual learning with deep neural
networks is Elastic Weight Consolidation (EWC), which involves computing the
Fisher Information. The exact way in which the Fisher Information is computed
is however rarely described, and multiple different implementations for it can
be found online. This blog post discusses and empirically compares several
often-used implementations, which highlights that many currently reported
results for EWC could likely be improved by changing the way the Fisher
Information is computed.",http://arxiv.org/abs/2502.11756v1
On the average least negative Hecke eigenvalue,2025-02-17T16:26:33Z,Jackie Voros,"We show that the first sign change of Hecke eigenvalues of classical newforms
has a finite mean, which we also compute. We distinguish between the first
negative prime Hecke eigenvalue, and the first negative Hecke eigenvalue. This
problem can be considered to be an analogue of the least quadratic non-residue
problem, of which the average was explored by Erd\H{o}s in 1961. In fact, the
average least negative prime Hecke eigenvalue has the same value as the average
least quadratic non-residue, under GRH. To compute these averages, we develop
large sieve inequalities that are uniform in both the weight and level aspect.",http://arxiv.org/abs/2502.11987v2
"A thermal Green-Naghdi model with time dependent bathymetry and complete
  Coriolis force",2025-02-17T12:21:43Z,"Darryl D. Holm, Oliver D. Street","This paper extends the theoretical Euler-Poincar\'e framework for modelling
ocean mixed layer dynamics. Through a symmetry-broken Lie group invariant
variational principle, we derive a generalised Green-Naghdi equation with time
dependent bathymetry, a complete Coriolis force, and inhomogeneity of the
thermal buoyancy. The nature of the model derived here lends it a potential
future application to wave dynamics generated by changes to the bathymetry.",http://arxiv.org/abs/2502.12220v1
"Applications of Stretch Reflex for the Upper Limb of Musculoskeletal
  Humanoids: Protective Behavior, Postural Stability, and Active Induction",2025-02-18T12:15:54Z,"Kento Kawaharazuka, Yuya Koga, Kei Tsuzuki, Moritaka Onitsuka, Yuki Asano, Kei Okada, Koji Kawasaki, Masayuki Inaba","The musculoskeletal humanoid has various biomimetic benefits, and it is
important that we can embed and evaluate human reflexes in the actual robot.
Although stretch reflex has been implemented in lower limbs of musculoskeletal
humanoids, we apply it to the upper limb to discover its useful applications.
We consider the implementation of stretch reflex in the actual robot, its
active/passive applications, and the change in behavior according to the
difference of parameters.",http://arxiv.org/abs/2502.12811v1
Polarization agnostic continuous variable quantum key distribution,2025-02-18T15:48:25Z,"Brian P. Williams, Nicholas A. Peters","We introduce a polarization agnostic method for Gaussian-modulated coherent
state (GCMS) continuous-variable quantum key distribution (CVQKD). Due to the
random and continuous nature of the GCMS protocol, Alice, the transmitter, can
encode two distinct quadratures in each of two orthogonal polarization modes,
such that Bob, the receiver, measures valid GCMS quadratures in a single
polarization mode even when polarization changes occur during transmission.
This method does not require polarization correction in the optical domain,
does not require monitoring both polarization modes, reduces loss by
eliminating optical components, and avoids the noise injected by polarization
correction algorithms.",http://arxiv.org/abs/2502.12968v1
"Enhanced dynamo drive for the sawtooth relaxation process due to
  non-uniform resistivity distribution in a reversed field pinch",2025-02-20T12:33:08Z,"Wentan Yan, Ping Zhu, Hong Li, Wandong Liu, Bing Luo, Haolong Li","In this work, we use the three-dimensional resistive MHD code NIMROD to
investigate the impact of resistivity inhomogeneity on the sawtooth process of
an reversed field pinch (RFP) plasma. The simulation employs a non-uniform
resistivity profile similar to experiments, which monotonically increases from
the core to the edge as the temperature decreases. The resistivity
inhomogeneity introduces an additional electric field in the plasma, which
accelerates the inward diffusion of magnetic flux and changing the self
sustained reversal state, hence significantly enhances the dynamo effect and
the sawtooth process in the RFP plasma.",http://arxiv.org/abs/2502.14506v1
"TS-SatMVSNet: Slope Aware Height Estimation for Large-Scale Earth
  Terrain Multi-view Stereo",2025-01-02T04:18:40Z,"Song Zhang, Zhiwei Wei, Wenjia Xu, Lili Zhang, Yang Wang, Jinming Zhang, Junyi Liu","3D terrain reconstruction with remote sensing imagery achieves cost-effective
and large-scale earth observation and is crucial for safeguarding natural
disasters, monitoring ecological changes, and preserving the
environment.Recently, learning-based multi-view stereo~(MVS) methods have shown
promise in this task. However, these methods simply modify the general
learning-based MVS framework for height estimation, which overlooks the terrain
characteristics and results in insufficient accuracy. Considering that the
Earth's surface generally undulates with no drastic changes and can be measured
by slope, integrating slope considerations into MVS frameworks could enhance
the accuracy of terrain reconstructions. To this end, we propose an end-to-end
slope-aware height estimation network named TS-SatMVSNet for large-scale remote
sensing terrain reconstruction.To effectively obtain the slope representation,
drawing from mathematical gradient concepts, we innovatively proposed a
height-based slope calculation strategy to first calculate a slope map from a
height map to measure the terrain undulation. To fully integrate slope
information into the MVS pipeline, we separately design two slope-guided
modules to enhance reconstruction outcomes at both micro and macro levels.
Specifically, at the micro level, we designed a slope-guided interval partition
module for refined height estimation using slope values. At the macro level, a
height correction module is proposed, using a learnable Gaussian smoothing
operator to amend the inaccurate height values. Additionally, to enhance the
efficacy of height estimation, we proposed a slope direction loss for
implicitly optimizing height estimation results. Extensive experiments on the
WHU-TLC dataset and MVS3D dataset show that our proposed method achieves
state-of-the-art performance and demonstrates competitive generalization
ability.",http://arxiv.org/abs/2501.01049v1
"Angular-Controlled GST Phase-Change Double Micro-Ring Resonator for
  High-Speed Activation Functions in Neuromorphic Computing",2025-01-02T06:32:30Z,"Hossein Karimkhani, Yaser M. Banad, Sarah Sharif","In the drive toward efficient neuromorphic computing, photonic technologies
offer promising solutions for implementing neural functionalities. Here we
demonstrate the first all-optical double micro-ring resonator incorporating
Ge2Sb2Te5 (GST) as a phase-change material to realize precise nonlinear
activation functions (NLAF). Our device architecture achieves switching speeds
of 0.5 ns through a novel approach to GST integration, where angular
positioning of GST segments within the rings enables unprecedented control over
optical transmission characteristics. Through systematic investigation of
sixteen distinct phase configurations, we identify optimal GST positioning (180
degrees in the first ring, 90 degrees in the second) that achieves ultra-narrow
band transmission with 0.47 nm full width at half maximum. Operating at
significantly lower temperatures (100 degrees centigrade) than conventional GST
implementations, our device maintains high contrast ratios with transmission
coefficient modulation from near-zero to 0.85 across a 4 nm spectral window.
The dual-ring architecture enables independent optimization of spectral
selectivity and switching contrast a capability previously unattainable in
single ring designs. These results demonstrate a viable pathway toward
efficient neuromorphic photonic systems that can operate at speeds relevant for
practical computing applications while maintaining the precision required for
neural processing.",http://arxiv.org/abs/2501.01093v1
Learning 3D Garment Animation from Trajectories of A Piece of Cloth,2025-01-02T18:09:42Z,"Yidi Shao, Chen Change Loy, Bo Dai","Garment animation is ubiquitous in various applications, such as virtual
reality, gaming, and film producing. Recently, learning-based approaches obtain
compelling performance in animating diverse garments under versatile scenarios.
Nevertheless, to mimic the deformations of the observed garments, data-driven
methods require large scale of garment data, which are both resource-wise
expensive and time-consuming. In addition, forcing models to match the dynamics
of observed garment animation may hinder the potentials to generalize to unseen
cases. In this paper, instead of using garment-wise supervised-learning we
adopt a disentangled scheme to learn how to animate observed garments: 1).
learning constitutive behaviors from the observed cloth; 2). dynamically
animate various garments constrained by the learned constitutive laws.
Specifically, we propose Energy Unit network (EUNet) to model the constitutive
relations in the format of energy. Without the priors from analytical physics
models and differentiable simulation engines, EUNet is able to directly capture
the constitutive behaviors from the observed piece of cloth and uniformly
describes the change of energy caused by deformations, such as stretching and
bending. We further apply the pre-trained EUNet to animate various garments
based on energy optimizations. The disentangled scheme alleviates the need of
garment data and enables us to utilize the dynamics of a piece of cloth for
animating garments. Experiments show that while EUNet effectively delivers the
energy gradients due to the deformations, models constrained by EUNet achieve
more stable and physically plausible performance comparing with those trained
in garment-wise supervised manner. Code is available at
https://github.com/ftbabi/EUNet_NeurIPS2024.git .",http://arxiv.org/abs/2501.01393v1
Impact of inter-city interactions on disease scaling,2025-01-02T18:14:24Z,"Nathalia A. Loureiro, Camilo R. Neto, Jack Sutton, Matjaz Perc, Haroldo V. Ribeiro","Inter-city interactions are critical for the transmission of infectious
diseases, yet their effects on the scaling of disease cases remain largely
underexplored. Here, we use the commuting network as a proxy for inter-city
interactions, integrating it with a general scaling framework to describe the
incidence of seven infectious diseases across Brazilian cities as a function of
population size and the number of commuters. Our models significantly
outperform traditional urban scaling approaches, revealing that the
relationship between disease cases and a combination of population and
commuters varies across diseases and is influenced by both factors. Although
most cities exhibit a less-than-proportional increase in disease cases with
changes in population and commuters, more-than-proportional responses are also
observed across all diseases. Notably, in some small and isolated cities,
proportional rises in population and commuters correlate with a reduction in
disease cases. These findings suggest that such towns may experience improved
health outcomes and socioeconomic conditions as they grow and become more
connected. However, as growth and connectivity continue, these gains diminish,
eventually giving way to challenges typical of larger urban areas - such as
socioeconomic inequality and overcrowding - that facilitate the spread of
infectious diseases. Our study underscores the interconnected roles of
population size and commuter dynamics in disease incidence while highlighting
that changes in population size exert a greater influence on disease cases than
variations in the number of commuters.",http://arxiv.org/abs/2501.01395v1
"Slow spatial migration can help eradicate cooperative antimicrobial
  resistance in time-varying environments",2025-01-03T18:36:48Z,"Lluís Hernández-Navarro, Kenneth Distefano, Uwe C. Täuber, Mauro Mobilia","Antimicrobial resistance (AMR) is a global threat and combating its spread is
of paramount importance. AMR often results from a cooperative behaviour with
shared protection against drugs. Microbial communities generally evolve in
volatile environments and spatial structures. Migration, fluctuations, and
environmental variability thus have significant impacts on AMR, whose
maintenance in static environments is generally promoted by migration. Here, we
demonstrate that this picture changes dramatically in time-fluctuating
spatially structured environments. To this end, we consider a two-dimensional
metapopulation model consisting of demes in which drug-resistant and sensitive
cells evolve in a time-changing environment in the presence of a toxin against
which protection can be shared. Cells migrate between neighbouring demes and
hence connect them. When the environment varies neither too quickly nor too
slowly, the dynamics is characterised by bottlenecks causing fluctuation-driven
local extinctions, a mechanism countered by migration that rescues AMR. Through
simulations and mathematical analysis, we investigate how migration and
environmental variability influence the probability of resistance eradication.
We determine the near-optimal conditions for the fluctuation-driven AMR
eradication, and show that slow but non-zero migration speeds up the clearance
of resistance and can enhance its eradication probability. We discuss our
study's impact on laboratory-controlled experiments.",http://arxiv.org/abs/2501.01939v1
Lorentz force mediation of turbulent dynamo transitions,2025-01-04T14:59:51Z,"Krista M. Soderlund, Paula Wulff, Petri Käpylä, Jonathan M. Aurnou","We investigate how the strength of the Lorentz force alters stellar
convection zone dynamics in a suite of buoyancy-dominated, three-dimensional,
spherical shell convective dynamo models. This is done by varying only the
magnetic Prandtl number, $Pm$, the non-dimensional form of the fluid's
electrical conductivity $\sigma$. Because the strength of the dynamo magnetic
field and the Lorentz force scale with $Pm$, it is found that the fluid
motions, the pattern of convective heat transfer, and the mode of dynamo
generation all differ across the $0.25 \leq Pm \leq 10$ range investigated
here. For example, we show that strong magnetohydrodynamic effects cause a
fundamental change in the surface zonal flows: differential rotation switches
from solar-like (prograde equatorial zonal flow) for larger electrical
conductivities to an anti-solar differential rotation (retrograde equatorial
zonal flow) at lower electrical conductivities. This study shows that the value
of the bulk electrical conductivity is important not only for sustaining dynamo
action, but can also drive first-order changes in the characteristics of the
magnetic, velocity, and temperature fields. It is also associated with the
relative strength of the Lorentz force in the system as measured by the local
magnetic Rossby number, $Ro_\ell^M$, which we show is crucial in setting the
characteristics of the large-scale convection regime that generates those
dynamo fields.",http://arxiv.org/abs/2501.02306v1
Gas bubble dynamics,2025-01-06T12:56:21Z,"Dominique Legendre, Roberto Zenit","The study of gas bubble dynamics in liquids is justified by the numerous
applications and natural phenomena where this two-phase flow is encountered.
Gas bubbles move as forces are applied to them; their dynamics are full of
nuances that need to be addressed carefully. Since the mass of gas bubbles is
practically negligible, in comparison to that of the surrounding liquid, their
reaction to the fluid is controlled by the added mass acceleration and is thus
impacted by all the forces arising from the fluid action. Furthermore, since
their surface can be deformed by the same forces acting on them, their shape
may change leading to changes in their resistance to move, the drag force, and
therefore affecting their speed and their interaction with the surrounding flow
which is often turbulent. The liquid rheology, as well as its surfactant
content can also affect the bubble shape and motion as well. Understanding
these issues, in addition to the effect of interactions with other bubbles,
walls, and non-uniform flows, provides sufficient elements to model and predict
bubble behavior through the solution of dynamic equations. In this review, we
cover the key aspects of non-condensable gas bubble dynamics. We survey
classical references on the subject and provide an overview of the main
findings in the past 20 years. We conclude with a scope and suggestions for
future research directions, with special attention to the dynamics of bubble in
turbulence, in non-Newtonian fluid and/or in the presence of electrolytes.",http://arxiv.org/abs/2501.02988v1
"Analyzing Fine-tuning Representation Shift for Multimodal LLMs Steering
  alignment",2025-01-06T13:37:13Z,"Pegah Khayatan, Mustafa Shukor, Jayneel Parekh, Matthieu Cord","Multimodal LLMs have reached remarkable levels of proficiency in
understanding multimodal inputs, driving extensive research to develop
increasingly powerful models. However, much less attention has been paid to
understanding and explaining the underlying mechanisms of these models. Most
existing explainability research examines these models only in their final
states, overlooking the dynamic representational shifts that occur during
training. In this work, we systematically analyze the evolution of hidden state
representations to reveal how fine-tuning alters the internal structure of a
model to specialize in new multimodal tasks. Using a concept-based approach, we
map hidden states to interpretable visual and textual concepts, enabling us to
trace changes in encoded concepts across modalities as training progresses. We
also demonstrate the use of shift vectors to capture these concepts changes.
These shift vectors allow us to recover fine-tuned concepts by shifting those
in the original model. Finally, we explore the practical impact of our findings
on model steering, showing that we can adjust multimodal LLMs behaviors without
any training, such as modifying answer types, captions style, or biasing the
model toward specific responses. Our work sheds light on how multimodal
representations evolve through fine-tuning and offers a new perspective for
interpreting model adaptation in multimodal tasks. The code for this project is
publicly available at https://github.com/mshukor/xl-vlms.",http://arxiv.org/abs/2501.03012v1
"Investigating Discontinuous X-ray Irradiation as a Damage Mitigation
  Strategy for [M(COD)Cl]$_2$ Catalysts",2025-01-06T14:48:24Z,"Nathalie K. Fernando, Claire A. Murray, Amber L. Thompson, Katherine Milton, Andrew B. Cairns, Anna Regoutz","With the advent of ever more intense and focused X-ray sources, including in
laboratories, at synchrotrons, and at X-ray free electron lasers,
radiation-induced sample change and damage are becoming increasingly
challenging. Therefore, the exploration of possible mitigation strategies is
crucial to continue to allow the collection of robust and repeatable data. One
mitigation approach is the introduction of short, X-ray-free ``dark'' periods.
However, it is unclear whether this strategy minimises damage or, in actuality,
promotes it through a phenomenon called ``dark progression'', i.e. the increase
or progression of radiation damage that occurs after the X-ray beam is turned
off. This work discusses the influence of introducing dark periods and their
duration on the radiation-induced changes in two model small-molecule
catalysts, [Ir(COD)Cl]$_2$ and [Rh(COD)Cl]$_2$, exposed to X-ray radiation in
powder diffraction (PXRD) and photoelectron spectroscopy (XPS) experiments.
This provides, for the first time, insights into how damage progresses under
varying radiation regimes and allows the distinction between the processes that
affect the unit cell itself, the individual molecular units, and the respective
atomic chemical environments. Furthermore, it provides the basis for informed
decision-making in the design of future experiments where the need to minimise
radiation-induced damage is crucial.",http://arxiv.org/abs/2501.03057v1
"Comment on ""The unphysicality of Hilbert spaces"" (arXiv:2308.06669v3)",2025-01-06T10:55:32Z,Nivaldo A. Lemos,"``The unphysicality of Hilbert spaces'' by Carcassi, Calder\'on and Aidala
(arXiv:2308.06669v3) is a thoughtful dissection of the mathematical structure
of quantum mechanics that seeks to pinpoint difficulties inherent in
postulating that the physical states are elements of a Hilbert space. Its
pivotal charge against Hilbert spaces is that by a change of variables, which
is a change-of-basis unitary transformation, one ``can map states with finite
expectation values to those with infinite ones''. In the present comment it is
shown that this statement is incorrect and the source of the error is spotted.
In consequence, the purported example of a time evolution that makes ``the
expectation value oscillate from finite to infinite in finite time"" is also
faulty, and the assertion that Hilbert spaces ``turn a potential infinity into
an actual infinity'' is unsubstantiated. Two other objections to Hilbert spaces
on physical grounds, both technically correct, are the isomorphism of separable
Hilbert spaces and the unavoidable existence of infinite-expectation-value
states. The former is of little relevance but the latter remains an issue
without a fully satisfactory solution, although the evidence so far is that it
is physically innocuous. All in all, while the authors' thesis that Hilbert
spaces must be given up ought to be taken seriously, it seems insufficiently
supported to be convincing.",http://arxiv.org/abs/2501.03294v2
Orbital fluctuations and spin-orbital-lattice coupling in Bi2Fe4O9,2025-01-07T06:05:30Z,"Aditya Prasad Roy, M. K. Chattopadhyay, Ranjan Mittal, Srungarpu N. Achary, Avesh K. Tyagi, Manh Duc Le, Dipanshu Bansal","Magnetic frustrations and degeneracies profoundly affect ground-state
magnetic properties emerging from competing exchange interactions. Controlling
such frustrations using orbital and phonon engineering via the
Kugel-Khomskii-type (KK-type) interactions has recently enabled the orbital
enhancement of magnetoelectric (ME) coupling. Using combined spectroscopic
techniques and first-principle simulations, here we demonstrate that the
magnetically frustrated Cairo lattice, Bi2Fe4O9, exhibits a strong KK-type
interaction resulting in a coupled spin-orbital phase below 1.8 times the Neel
temperature (TN = 245 K). We observe an order of magnitude change in phonon
linewidths that is not explainable considering spin-phonon coupling channels
alone. Instead, the observed change is reminiscent of orbitally active
materials, which we explicitly confirm by measuring the T-dependence of
low-energy orbital excitations. We further find that Bi2Fe4O9 harbors an
unstable polar mode, driving the lattice to a symmetry-lowered ferroelectric
(FE) phase below TN, in line with the previously reported hysteresis in
polarization. Nonetheless, the FE phase leads to extremely small calculated
superlattice Bragg peak intensities that are yet to be experimentally
confirmed. Moreover, thermal conductivity measurements do not show any
measurable effect of KK-type interactions on thermal transport across TN. But,
we observe a repeatable anomaly near 57 K appearing only in the heating cycle,
which co-occurs with the 400 meV broad continuum observed in Raman
measurements. The observed KK-type interaction in Bi2Fe4O9 provides an
opportunity for orbital enhancement of ME coupling by phonon control of
superexchange interactions.",http://arxiv.org/abs/2501.03555v1
AlphaPO - Reward shape matters for LLM alignment,2025-01-07T15:46:42Z,"Aman Gupta, Shao Tang, Qingquan Song, Sirou Zhu, Jiwoo Hong, Ankan Saha, Viral Gupta, Noah Lee, Eunki Kim, Siyu Zhu, Parag Agarwal, Natesh Pillai, S. Sathiya Keerthi","Reinforcement Learning with Human Feedback (RLHF) and its variants have made
huge strides toward the effective alignment of large language models (LLMs) to
follow instructions and reflect human values. More recently, Direct Alignment
Algorithms (DAAs) have emerged in which the reward modeling stage of RLHF is
skipped by characterizing the reward directly as a function of the policy being
learned. Some popular examples of DAAs include Direct Preference Optimization
(DPO) and Simple Preference Optimization (SimPO). These methods often suffer
from likelihood displacement, a phenomenon by which the probabilities of
preferred responses are often reduced undesirably.
  In this paper, we argue that, for DAAs the reward (function) shape matters.
We introduce \textbf{AlphaPO}, a new DAA method that leverages an
$\alpha$-parameter to help change the shape of the reward function beyond the
standard log reward. AlphaPO helps maintain fine-grained control over
likelihood displacement and over-optimization. Compared to SimPO, one of the
best performing DAAs, AlphaPO leads to about 7\% to 10\% relative improvement
in alignment performance for the instruct versions of Mistral-7B and Llama3-8B
while achieving 15\% to 50\% relative improvement over DPO on the same models.
The analysis and results presented highlight the importance of the reward
shape, and how one can systematically change it to affect training dynamics, as
well as improve alignment performance.",http://arxiv.org/abs/2501.03884v2
"Multi-functional Wafer-Scale Van der Waals Heterostructures and
  Polymorphs",2025-01-07T17:28:57Z,"M. Micica, A. Wright, S. Massabeau, S. Ayari, E. Rongione, M. Oliveira Ribeiro, S. Husain, T. Denneulin, R. Dunin-Borkowsk, J. Tignon, J. Mangeney, R. Lebrun, H. Okuno, O. Boulle, A. Marty, F. Bonell, F. Carosella, H. Jaffres, R. Ferreira, J-M. George, M. Jamet, S. Dhillon","Van der Waals heterostructures have promised the realisation of artificial
materials with multiple physical phenomena such as giant optical
nonlinearities, spin-to-charge interconversion in spintronics and topological
carrier protection, in a single layered device through an infinitely diverse
set of quantum materials. However, most efforts have only focused on exfoliated
material that inherently limits both the dimensions of the materials and the
scalability for applications. Here, we show the epitaxial growth of large area
heterostructures of topological insulators (Bi2Se3), transition metal
dichalcogenides (TMDs, WSe2) and ferromagnets (Co), resulting in the
combination of functionalities including tuneable optical nonlinearities,
spin-to-charge conversion and magnetic proximity effects. This is demonstrated
through coherent phase resolved terahertz currents, bringing novel
functionalities beyond those achievable in simple homostructures. In
particular, we show the role of different TMD polymorphs, with the simple
change of one atomic monolayer of the artificial material stack entirely
changing its optical, electrical and magnetic properties. This epitaxial
integration of diverse two-dimensional materials offers foundational steps
towards diverse perspectives in quantum material engineering, where the
material polymorph can be controlled at technological relevant scales for
coupling applications in, for example, van der Waals nonlinear optics,
optoelectronics, spintronics, multiferroics and coherent current control.",http://arxiv.org/abs/2501.03955v1
"Novel magnetic-field-free switching behavior in vdW-magnet/oxide
  heterostructure",2025-01-08T02:20:58Z,"Jihoon Keum, Kai-Xuan Zhang, Suik Cheon, Hyuncheol Kim, Jingyuan Cui, Giung Park, Yunyeong Chang, Miyoung Kim, Hyun-Woo Lee, Je-Geun Park","Magnetization switching by charge current without a magnetic field is
essential for device applications and information technology. It generally
requires a current-induced out-of-plane spin polarization beyond the capability
of conventional ferromagnet/heavy-metal systems, where the current-induced spin
polarization aligns in-plane orthogonal to the in-plane charge current and
out-of-plane spin current. Here, we demonstrate a new approach for
magnetic-field-free switching by fabricating a van-der-Waals magnet and oxide
Fe3GeTe2/SrTiO3 heterostructure. This new magnetic-field-free switching is
possible because the current-driven accumulated spins at the Rashba interface
precess around an emergent interface magnetism, eventually producing an
ultimate out-of-plane spin polarization. This interpretation is further
confirmed by the switching polarity change controlled by the in-plane
initialization magnetic fields with clear hysteresis. We successfully combined
van-der-Waals magnet and oxide for the first time, especially taking advantage
of spin-orbit torque on the SrTiO3 oxide. This allows us to establish a new way
of magnetic field-free switching. Our work demonstrates an unusual
perpendicular switching application of large spin Hall angle materials and
precession of accumulated spins, and in doing so, opens up a new field and
opportunities for van-der-Waals magnets and oxide spintronics.",http://arxiv.org/abs/2501.04235v1
"Chondrule dust rim growth: Influence of restructuring using molecular
  dynamics simulations",2025-01-08T17:15:30Z,"Chuchu Xiang, Nina Merkert, Lorin S. Matthews, Augusto Carballido, Truell W. Hyde","We investigate the influence of disruptive collisions on chondrule rim
growth, emphasizing the role of kinetic energy in determining the outcomes of
these interactions. We establish a threshold of approximately 10 cm/s for the
""hit-and-stick"" collision regime, beyond which significant changes occur in the
structure of rimmed chondrules. Our findings highlight that at low collision
energies (KE $< 10^{-12}$ J), minimal structural alteration takes place, while
higher energies (KE up to $10^{-10}$ J) lead to compaction of the rim, reducing
both its thickness and porosity. Collisions with energies exceeding $10^{-8}$ J
result in the complete disruption of the rim, with particles being expelled
from it. These results are correlated with the turbulence levels within the
disk, as kinetic energy scales with the relative velocities of colliding
particles. Leveraging machine learning models trained on our collision data, we
predict changes in rim characteristics and employ these predictions in a Monte
Carlo simulation to explore rim growth dynamics. Our simulations reveal that
rim development is sustained in low-turbulence environments ($\alpha \leq
10^{-5}$), while intermediate turbulence levels ($\alpha$ = $10^{-3}$ to
$10^{-4}$) lead to erosion, preventing further rim accumulation in
high-turbulence contexts.",http://arxiv.org/abs/2501.04625v1
"Explaining k-Nearest Neighbors: Abductive and Counterfactual
  Explanations",2025-01-10T16:14:35Z,"Pablo Barceló, Alexander Kozachinskiy, Miguel Romero Orth, Bernardo Subercaseaux, José Verschae","Despite the wide use of $k$-Nearest Neighbors as classification models, their
explainability properties remain poorly understood from a theoretical
perspective. While nearest neighbors classifiers offer interpretability from a
""data perspective"", in which the classification of an input vector $\bar{x}$ is
explained by identifying the vectors $\bar{v}_1, \ldots, \bar{v}_k$ in the
training set that determine the classification of $\bar{x}$, we argue that such
explanations can be impractical in high-dimensional applications, where each
vector has hundreds or thousands of features and it is not clear what their
relative importance is. Hence, we focus on understanding nearest neighbor
classifications through a ""feature perspective"", in which the goal is to
identify how the values of the features in $\bar{x}$ affect its classification.
Concretely, we study abductive explanations such as ""minimum sufficient
reasons"", which correspond to sets of features in $\bar{x}$ that are enough to
guarantee its classification, and ""counterfactual explanations"" based on the
minimum distance feature changes one would have to perform in $\bar{x}$ to
change its classification. We present a detailed landscape of positive and
negative complexity results for counterfactual and abductive explanations,
distinguishing between discrete and continuous feature spaces, and considering
the impact of the choice of distance function involved. Finally, we show that
despite some negative complexity results, Integer Quadratic Programming and SAT
solving allow for computing explanations in practice.",http://arxiv.org/abs/2501.06078v1
Focus-N-Fix: Region-Aware Fine-Tuning for Text-to-Image Generation,2025-01-11T08:16:30Z,"Xiaoying Xing, Avinab Saha, Junfeng He, Susan Hao, Paul Vicol, Moonkyung Ryu, Gang Li, Sahil Singla, Sarah Young, Yinxiao Li, Feng Yang, Deepak Ramachandran","Text-to-image (T2I) generation has made significant advances in recent years,
but challenges still remain in the generation of perceptual artifacts,
misalignment with complex prompts, and safety. The prevailing approach to
address these issues involves collecting human feedback on generated images,
training reward models to estimate human feedback, and then fine-tuning T2I
models based on the reward models to align them with human preferences.
However, while existing reward fine-tuning methods can produce images with
higher rewards, they may change model behavior in unexpected ways. For example,
fine-tuning for one quality aspect (e.g., safety) may degrade other aspects
(e.g., prompt alignment), or may lead to reward hacking (e.g., finding a way to
increase rewards without having the intended effect). In this paper, we propose
Focus-N-Fix, a region-aware fine-tuning method that trains models to correct
only previously problematic image regions. The resulting fine-tuned model
generates images with the same high-level structure as the original model but
shows significant improvements in regions where the original model was
deficient in safety (over-sexualization and violence), plausibility, or other
criteria. Our experiments demonstrate that Focus-N-Fix improves these localized
quality aspects with little or no degradation to others and typically
imperceptible changes in the rest of the image. Disclaimer: This paper contains
images that may be overly sexual, violent, offensive, or harmful.",http://arxiv.org/abs/2501.06481v1
"OpenGERT: Open Source Automated Geometry Extraction with Geometric and
  Electromagnetic Sensitivity Analyses for Ray-Tracing Propagation Models",2025-01-12T21:42:29Z,"Serhat Tadik, Rajib Bhattacharjea, Johnathan Corgan, David Johnson, Jacobus Van der Merwe, Gregory D. Durgin","Accurate RF propagation modeling in urban environments is critical for
developing digital spectrum twins and optimizing wireless communication
systems. We introduce OpenGERT, an open-source automated Geometry Extraction
tool for Ray Tracing, which collects and processes terrain and building data
from OpenStreetMap, Microsoft Global ML Building Footprints, and USGS elevation
data. Using the Blender Python API, it creates detailed urban models for
high-fidelity simulations with NVIDIA Sionna RT. We perform sensitivity
analyses to examine how variations in building height, position, and
electromagnetic material properties affect ray-tracing accuracy. Specifically,
we present pairwise dispersion plots of channel statistics (path gain, mean
excess delay, delay spread, link outage, and Rician K-factor) and investigate
how their sensitivities change with distance from transmitters. We also
visualize the variance of these statistics for selected transmitter locations
to gain deeper insights. Our study covers Munich and Etoile scenes, each with
10 transmitter locations. For each location, we apply five types of
perturbations: material, position, height, height-position, and all combined,
with 50 perturbations each. Results show that small changes in permittivity and
conductivity minimally affect channel statistics, whereas variations in
building height and position significantly alter all statistics, even with
noise standard deviations of 1 meter in height and 0.4 meters in position.
These findings highlight the importance of precise environmental modeling for
accurate propagation predictions, essential for digital spectrum twins and
advanced communication networks. The code for geometry extraction and
sensitivity analyses is available at github.com/serhatadik/OpenGERT/.",http://arxiv.org/abs/2501.06945v1
"Global Search for Optimal Low Thrust Spacecraft Trajectories using
  Diffusion Models and the Indirect Method",2025-01-13T01:49:17Z,"Jannik Graebner, Ryne Beeson","Long time-duration low-thrust nonlinear optimal spacecraft trajectory global
search is a computationally and time expensive problem characterized by
clustering patterns in locally optimal solutions. During preliminary mission
design, mission parameters are subject to frequent changes, necessitating that
trajectory designers efficiently generate high-quality control solutions for
these new scenarios. Generative machine learning models can be trained to learn
how the solution structure varies with respect to a conditional parameter,
thereby accelerating the global search for missions with updated parameters. In
this work, state-of-the-art diffusion models are integrated with the indirect
approach for trajectory optimization within a global search framework. This
framework is tested on two low-thrust transfers of different complexity in the
circular restricted three-body problem. By generating and analyzing a training
data set, we develop mathematical relations and techniques to understand the
complex structures in the costate domain of locally optimal solutions for these
problems. A diffusion model is trained on this data and successfully
accelerates the global search for both problems. The model predicts how the
costate solution structure changes, based on the maximum spacecraft thrust
magnitude. Warm-starting a numerical solver with diffusion model samples for
the costates at the initial time increases the number of solutions generated
per minute for problems with unseen thrust magnitudes by one to two orders of
magnitude in comparison to samples from a uniform distribution and from an
adjoint control transformation.",http://arxiv.org/abs/2501.07005v1
"Competing Effects of Local Solvation Structures on Chemical Shift
  Changes of Liquid Electrolyte",2025-01-13T13:32:50Z,"Qi You, Yan Sun, Feng Wang, Jun Cheng, Fujie Tang","Understanding the solvation structure of electrolytes is critical for
optimizing the electrochemical performance of rechargeable batteries, as it
directly influences properties such as ionic conductivity, viscosity, and
electrochemical stability. The highly complex structures and strong
interactions in high-concentration electrolytes make accurate modeling and
interpretation of their ``structure-property"" relationships even more
challenging with spectroscopic methods. In this study, we present a machine
learning-based approach to predict dynamic $^7$Li NMR chemical shifts in
LiFSI/DME electrolyte solutions. Additionally, we provide a comprehensive
structural analysis to interpret the observed chemical shift behavior in our
experiments, particularly the abrupt changes in $^7$Li chemical shifts at high
concentrations. Using advanced modeling techniques, we quantitatively establish
the relationship between molecular structure and NMR spectra, offering critical
insights into solvation structure assignments. Our findings reveal the
coexistence of two competing local solvation structures that shift in dominance
as electrolyte concentration approaches the concentrated limit, leading to
anomalous reverse of $^7$Li NMR chemical shift in our experiment. This work
provides a detailed molecular-level understanding of the intricate solvation
structures probed by NMR spectroscopy, leading the way for enhanced electrolyte
design.",http://arxiv.org/abs/2501.07321v1
"A Linear Parameter-Varying Framework for the Analysis of Time-Varying
  Optimization Algorithms",2025-01-13T16:30:56Z,"Fabian Jakob, Andrea Iannelli","In this paper we propose a framework to analyze iterative first-order
optimization algorithms for time-varying convex optimization. We assume that
the temporal variability is caused by a time-varying parameter entering the
objective, which can be measured at the time of decision but whose future
values are unknown. We consider the case of strongly convex objective functions
with Lipschitz continuous gradients and address the class of running algorithms
where only one iteration per time change is performed. We model these
algorithms as discrete-time linear parameter varying (LPV) systems in feedback
with a time-varying gradient. We leverage the approach of analyzing algorithms
as uncertain control interconnections with integral quadratic constraints
(IQCs) and generalize that framework to the time-varying case. We propose novel
IQCs that are capable of capturing the behavior of time-varying nonlinearities
and leverage techniques from the LPV literature to establish novel bounds on
the tracking error. Quantitative bounds can be computed by solving a
semi-definite program and can be interpreted as an input-to-state stability
result with respect to a disturbance signal which increases with the temporal
variability of the problem. As a departure from results in this research area,
our bounds introduce terms that can be interpreted as a temporal rate of change
in the cost function and the optimal value. We exemplify our main results with
numerical experiments that showcase how our analysis framework is able to
capture convergence rates of different first-order algorithms for time-varying
optimization through the choice of IQC and rate bounds.",http://arxiv.org/abs/2501.07461v1
Multi-megabase scale genome interpretation with genetic language models,2025-01-13T23:00:40Z,"Frederik Träuble, Lachlan Stuart, Andreas Georgiou, Pascal Notin, Arash Mehrjou, Ron Schwessinger, Mathieu Chevalley, Kim Branson, Bernhard Schölkopf, Cornelia van Duijn, Debora Marks, Patrick Schwab","Understanding how molecular changes caused by genetic variation drive disease
risk is crucial for deciphering disease mechanisms. However, interpreting
genome sequences is challenging because of the vast size of the human genome,
and because its consequences manifest across a wide range of cells, tissues and
scales -- spanning from molecular to whole organism level. Here, we present
Phenformer, a multi-scale genetic language model that learns to generate
mechanistic hypotheses as to how differences in genome sequence lead to
disease-relevant changes in expression across cell types and tissues directly
from DNA sequences of up to 88 million base pairs. Using whole genome
sequencing data from more than 150 000 individuals, we show that Phenformer
generates mechanistic hypotheses about disease-relevant cell and tissue types
that match literature better than existing state-of-the-art methods, while
using only sequence data. Furthermore, disease risk predictors enriched by
Phenformer show improved prediction performance and generalisation to diverse
populations. Accurate multi-megabase scale interpretation of whole genomes
without additional experimental data enables both a deeper understanding of
molecular mechanisms involved in disease and improved disease risk prediction
at the level of individuals.",http://arxiv.org/abs/2501.07737v1
Bridge-SR: Schrödinger Bridge for Efficient SR,2025-01-14T07:26:05Z,"Chang Li, Zehua Chen, Fan Bao, Jun Zhu","Speech super-resolution (SR), which generates a waveform at a higher sampling
rate from its low-resolution version, is a long-standing critical task in
speech restoration. Previous works have explored speech SR in different data
spaces, but these methods either require additional compression networks or
exhibit limited synthesis quality and inference speed. Motivated by recent
advances in probabilistic generative models, we present Bridge-SR, a novel and
efficient any-to-48kHz SR system in the speech waveform domain. Using tractable
Schr\""odinger Bridge models, we leverage the observed low-resolution waveform
as a prior, which is intrinsically informative for the high-resolution target.
By optimizing a lightweight network to learn the score functions from the prior
to the target, we achieve efficient waveform SR through a data-to-data
generation process that fully exploits the instructive content contained in the
low-resolution observation. Furthermore, we identify the importance of the
noise schedule, data scaling, and auxiliary loss functions, which further
improve the SR quality of bridge-based systems. The experiments conducted on
the benchmark dataset VCTK demonstrate the efficiency of our system: (1) in
terms of sample quality, Bridge-SR outperforms several strong baseline methods
under different SR settings, using a lightweight network backbone (1.7M); (2)
in terms of inference speed, our 4-step synthesis achieves better performance
than the 8-step conditional diffusion counterpart (LSD: 0.911 vs 0.927). Demo
at https://bridge-sr.github.io.",http://arxiv.org/abs/2501.07897v1
Evaluating Policy Effects through Network Dynamics and Sampling,2025-01-14T14:26:11Z,"Eugene T. Y. Ang, Yong Sheng Soh","In the process of enacting or introducing a new policy, policymakers
frequently consider the population's responses. These considerations are
critical for effective governance. There are numerous methods to gauge the
ground sentiment from a subset of the population; examples include surveys or
listening to various feedback channels. Many conventional approaches implicitly
assume that opinions are static; however, in reality, the population will
discuss and debate these new policies among themselves, and reform new opinions
in the process. In this paper, we pose the following questions: Can we quantify
the effect of these social dynamics on the broader opinion towards a new
policy? Given some information about the relationship network that underlies
the population, how does overall opinion change post-discussion? We investigate
three different settings in which the policy is revealed: respondents who do
not know each other, groups of respondents who all know each other, and
respondents chosen randomly. By controlling who the policy is revealed to, we
control the degree of discussion among the population. We quantify how these
factors affect the changes in policy beliefs via the Wasserstein distance
between the empirically observed data post-discussion and its distribution
pre-discussion. We also provide several numerical analyses based on generated
network and real-life network datasets. Our work aims to address the challenges
associated with network topology and social interactions, and provide
policymakers with a quantitative lens to assess policy effectiveness in the
face of resource constraints and network complexities.",http://arxiv.org/abs/2501.08150v1
"Go-with-the-Flow: Motion-Controllable Video Diffusion Models Using
  Real-Time Warped Noise",2025-01-14T18:59:10Z,"Ryan Burgert, Yuancheng Xu, Wenqi Xian, Oliver Pilarski, Pascal Clausen, Mingming He, Li Ma, Yitong Deng, Lingxiao Li, Mohsen Mousavi, Michael Ryoo, Paul Debevec, Ning Yu","Generative modeling aims to transform random noise into structured outputs.
In this work, we enhance video diffusion models by allowing motion control via
structured latent noise sampling. This is achieved by just a change in data: we
pre-process training videos to yield structured noise. Consequently, our method
is agnostic to diffusion model design, requiring no changes to model
architectures or training pipelines. Specifically, we propose a novel noise
warping algorithm, fast enough to run in real time, that replaces random
temporal Gaussianity with correlated warped noise derived from optical flow
fields, while preserving the spatial Gaussianity. The efficiency of our
algorithm enables us to fine-tune modern video diffusion base models using
warped noise with minimal overhead, and provide a one-stop solution for a wide
range of user-friendly motion control: local object motion control, global
camera movement control, and motion transfer. The harmonization between
temporal coherence and spatial Gaussianity in our warped noise leads to
effective motion control while maintaining per-frame pixel quality. Extensive
experiments and user studies demonstrate the advantages of our method, making
it a robust and scalable approach for controlling motion in video diffusion
models. Video results are available on our webpage:
https://eyeline-research.github.io/Go-with-the-Flow. Source code and model
checkpoints are available on GitHub:
https://github.com/Eyeline-Research/Go-with-the-Flow.",http://arxiv.org/abs/2501.08331v3
"Deep Learning-Based Feature Fusion for Emotion Analysis and Suicide Risk
  Differentiation in Chinese Psychological Support Hotlines",2025-01-15T10:09:38Z,"Han Wang, Jianqiang Li, Qing Zhao, Zhonglong Chen, Changwei Song, Jing Tang, Yuning Huang, Wei Zhai, Yongsheng Tong, Guanghui Fu","Mental health is a critical global public health issue, and psychological
support hotlines play a pivotal role in providing mental health assistance and
identifying suicide risks at an early stage. However, the emotional expressions
conveyed during these calls remain underexplored in current research. This
study introduces a method that combines pitch acoustic features with deep
learning-based features to analyze and understand emotions expressed during
hotline interactions. Using data from China's largest psychological support
hotline, our method achieved an F1-score of 79.13% for negative binary emotion
classification.Additionally, the proposed approach was validated on an open
dataset for multi-class emotion classification,where it demonstrated better
performance compared to the state-of-the-art methods. To explore its clinical
relevance, we applied the model to analysis the frequency of negative emotions
and the rate of emotional change in the conversation, comparing 46 subjects
with suicidal behavior to those without. While the suicidal group exhibited
more frequent emotional changes than the non-suicidal group, the difference was
not statistically significant.Importantly, our findings suggest that emotional
fluctuation intensity and frequency could serve as novel features for
psychological assessment scales and suicide risk prediction.The proposed method
provides valuable insights into emotional dynamics and has the potential to
advance early intervention and improve suicide prevention strategies through
integration with clinical tools and assessments The source code is publicly
available at https://github.com/Sco-field/Speechemotionrecognition/tree/main.",http://arxiv.org/abs/2501.08696v1
"Cyclical accretion regime change in the slow X-ray pulsar 4U 0114+65
  observed with Chandra",2025-01-15T10:37:02Z,"Graciela Sanjurjo-Ferrín, Jose Miguel Torrejón, Konstantin Postnov, Michael Nowak, Jose Joaquín Rodes-Roca, Lida Oskinova, Jessica Planelles-Villalva, Norbert Schulz","4U 0114+65 is a high-mass X-ray binary system formed by the luminous
supergiant B1Ia, known as V{*} V662 Cas, and one of the slowest rotating
neutron stars (NS) with a spin period of about 2.6 hours. This fact provides a
rare opportunity to study interesting details of the accretion within each
individual pulse of the compact object. In this paper, we analyze 200 ks of
Chandra grating data, divided into 9 uninterrupted observations around the
orbit. The changes in the circumstellar absorption column through the orbit
suggest an orbital inclination of $\sim$ $40^{\circ}$ with respect to the
observer and a companion mass-loss rate of $\sim$ 8.6 10$^{-7}$ solar masses
yr$^{-1}$. The peaks of the NS pulse show a large pulse-to-pulse variability.
Three of them show an evolution from a brighter regime to a weaker one. We
propose that the efficiency of Compton cooling in this source fluctuates
throughout an accumulation cycle. After significant depletion of matter within
the magnetosphere, since the settling velocity is $\sim \times$ 2 times lower
than the free-fall velocity, the source gradually accumulates matter until the
density exceeds a critical threshold. This increase in density triggers a
transition to a more efficient Compton cooling regime, leading to a higher mass
accretion rate and consequently to an increased brightness.",http://arxiv.org/abs/2501.08702v2
"Female and Combined Male-Female Injury Risk Functions for the Anterior
  Pelvis Under Frontal Lap Belt Loading Conditions",2025-01-15T16:20:12Z,"Connor Hanggi, Joon Seok Kong, James Caldwell, Bronislaw Gepner, Martin Östling, Jason R. Kerrigan","Purpose: Iliac wing fractures due to lap belt loading have been observed in
laboratory settings for 50 years and recent data suggest they are also
occurring in the field. Automated driving systems (ADS) and other occupant
compartment advancements are expected to offer enhanced flexibility in seating
orientation, which could place a greater reliance on the seatbelt to restrain
occupants. Such changes may increase seatbelt loads and create new challenges
in successfully restraining occupants and mitigating injury to areas such as
the pelvis. Injury criteria exist for component-level male iliac wing fractures
resulting from frontal lap belt loading, but not for females. Methods: This
study explored female iliac wing fracture tolerance in the same loading
environment as a previous study that explored the fracture tolerance of
isolated male iliac wings. Male and female fracture data were combined to
evaluate the effect of sex. Injury risk functions were created by fitting
Weibull survival models to data that integrated censored and exact failure
observations. Results: Twenty female iliac wings were tested; fourteen of them
sustained fracture with known failure forces (exact), but the remaining six
wings either (1) did not fracture, or (2) fractured after an event that changed
the boundary conditions (right censored). The fracture tolerance of the tested
specimens ranged widely (1134 - 8759 N) and averaged 4240 N (SD 2516 N).
Conclusion: Female data and combined male-female data were analyzed. Age was
the only covariate investigated in this study that had a statistically
significant effect and improved the predictive performance of the models.",http://arxiv.org/abs/2501.08911v1
"A joint spatiotemporal model for multiple longitudinal markers and
  competing events",2025-01-15T17:10:49Z,"Juliette Ortholand, Stanley Durrleman, Sophie Tezenas du Montcel","Non-terminal events can represent a meaningful change in a patient's life.
Thus, better understanding and predicting their occurrence can bring valuable
information to individuals. In a context where longitudinal markers could
inform these events, joint models with competing risks have been developed.
Their precision relies on a reference time for which disease onset is often
used. Nevertheless, chronic diseases have no clear onset, making it difficult
to define a precise reference time. We propose a Joint cause-specific
Spatiotemporal model to overcome this limitation and to capture a shared latent
process, a latent age (temporal aspect), associated with the ordering of the
longitudinal outcomes (spatial aspect). First, we validated our model on
simulated real-like data. Then, we benchmarked our model with a
shared-random-effect joint model on real ALS data using the PRO-ACT dataset.
Finally, to show how the model could be used for description tasks, we analysed
the impact of sex and onset site on the progression of ALS as well as the
initiation of Non-Invasive Ventilation. The Joint cause-specific spatiotemporal
model achieved similar performance to the shared random effect joint model
while capturing the latent disease age and the impact of the ordering of
longitudinal outcomes on the occurrence of the events with fewer parameters.
The application study confirmed existing results for the Longitudinal outcomes
and showed how to interpret the model. The proposed approach by disentangling a
temporal and a spatial aspect of the disease opens the perspective to capture
meaningful change in future clinical trials.",http://arxiv.org/abs/2501.08960v1
"Continual Test-Time Adaptation for Single Image Defocus Deblurring via
  Causal Siamese Networks",2025-01-15T13:42:39Z,"Shuang Cui, Yi Li, Jiangmeng Li, Xiongxin Tang, Bing Su, Fanjiang Xu, Hui Xiong","Single image defocus deblurring (SIDD) aims to restore an all-in-focus image
from a defocused one. Distribution shifts in defocused images generally lead to
performance degradation of existing methods during out-of-distribution
inferences. In this work, we gauge the intrinsic reason behind the performance
degradation, which is identified as the heterogeneity of lens-specific point
spread functions. Empirical evidence supports this finding, motivating us to
employ a continual test-time adaptation (CTTA) paradigm for SIDD. However,
traditional CTTA methods, which primarily rely on entropy minimization, cannot
sufficiently explore task-dependent information for pixel-level regression
tasks like SIDD. To address this issue, we propose a novel Siamese
networks-based continual test-time adaptation framework, which adapts source
models to continuously changing target domains only requiring unlabeled target
data in an online manner. To further mitigate semantically erroneous textures
introduced by source SIDD models under severe degradation, we revisit the
learning paradigm through a structural causal model and propose Causal Siamese
networks (CauSiam). Our method leverages large-scale pre-trained
vision-language models to derive discriminative universal semantic priors and
integrates these priors into Siamese networks, ensuring causal identifiability
between blurry inputs and restored images. Extensive experiments demonstrate
that CauSiam effectively improves the generalization performance of existing
SIDD methods in continuously changing domains.",http://arxiv.org/abs/2501.09052v1
ADAGE: A generic two-layer framework for adaptive agent based modelling,2025-01-16T09:58:24Z,"Benjamin Patrick Evans, Sihan Zeng, Sumitra Ganesh, Leo Ardon","Agent-based models (ABMs) are valuable for modelling complex, potentially
out-of-equilibria scenarios. However, ABMs have long suffered from the Lucas
critique, stating that agent behaviour should adapt to environmental changes.
Furthermore, the environment itself often adapts to these behavioural changes,
creating a complex bi-level adaptation problem. Recent progress integrating
multi-agent reinforcement learning into ABMs introduces adaptive agent
behaviour, beginning to address the first part of this critique, however, the
approaches are still relatively ad hoc, lacking a general formulation, and
furthermore, do not tackle the second aspect of simultaneously adapting
environmental level characteristics in addition to the agent behaviours. In
this work, we develop a generic two-layer framework for ADaptive AGEnt based
modelling (ADAGE) for addressing these problems. This framework formalises the
bi-level problem as a Stackelberg game with conditional behavioural policies,
providing a consolidated framework for adaptive agent-based modelling based on
solving a coupled set of non-linear equations. We demonstrate how this generic
approach encapsulates several common (previously viewed as distinct) ABM tasks,
such as policy design, calibration, scenario generation, and robust behavioural
learning under one unified framework. We provide example simulations on
multiple complex economic and financial environments, showing the strength of
the novel framework under these canonical settings, addressing long-standing
critiques of traditional ABMs.",http://arxiv.org/abs/2501.09429v1
"Make yourself comfortable: Nudging urban heat and noise mitigation with
  smartwatch-based Just-in-time Adaptive Interventions (JITAI)",2025-01-16T13:28:40Z,"Clayton Miller, Yun Xuan Chua, Matias Quintana, Binyu Lei, Filip Biljecki, Mario Frei","Humans can play a more active role in improving their comfort in the built
environment if given the right information at the right place and time. This
paper outlines the use of Just-in-Time Adaptive Interventions (JITAI)
implemented in the context of the built environment to provide information that
helps humans minimize the impact of heat and noise on their daily lives. This
framework builds upon the open-source Cozie iOS smartwatch platform. It
includes data collection through micro-surveys and intervention messages
triggered by environmental, contextual, and personal history conditions. An
eight-month deployment of the method was completed in Singapore with 103
participants who submitted over 12,000 micro-surveys and delivered over 3,600
JITAI intervention messages. A weekly survey conducted during two deployment
phases revealed an overall increase in perceived usefulness ranging from 8-19%
over the first three weeks of data collection. For noise-related interventions,
participants showed an overall increase in location changes ranging from 4-11%
and a 2-17% increase in earphone use to mitigate noise distractions. For
thermal comfort-related interventions, participants demonstrated a 3-13%
increase in adjustments to their location or thermostat to feel more
comfortable. The analysis found evidence that personality traits (such as
conscientiousness), gender, and environmental preferences could be factors in
determining the perceived helpfulness of JITAIs and influencing behavior
change. These findings underscore the importance of tailoring intervention
strategies to individual traits and environmental conditions, setting the stage
for future research to refine the delivery, timing, and content of intervention
messages.",http://arxiv.org/abs/2501.09530v1
"NS-Gym: Open-Source Simulation Environments and Benchmarks for
  Non-Stationary Markov Decision Processes",2025-01-16T16:38:33Z,"Nathaniel S. Keplinger, Baiting Luo, Iliyas Bektas, Yunuo Zhang, Kyle Hollins Wray, Aron Laszka, Abhishek Dubey, Ayan Mukhopadhyay","In many real-world applications, agents must make sequential decisions in
environments where conditions are subject to change due to various exogenous
factors. These non-stationary environments pose significant challenges to
traditional decision-making models, which typically assume stationary dynamics.
Non-stationary Markov decision processes (NS-MDPs) offer a framework to model
and solve decision problems under such changing conditions. However, the lack
of standardized benchmarks and simulation tools has hindered systematic
evaluation and advance in this field. We present NS-Gym, the first simulation
toolkit designed explicitly for NS-MDPs, integrated within the popular
Gymnasium framework. In NS-Gym, we segregate the evolution of the environmental
parameters that characterize non-stationarity from the agent's decision-making
module, allowing for modular and flexible adaptations to dynamic environments.
We review prior work in this domain and present a toolkit encapsulating key
problem characteristics and types in NS-MDPs. This toolkit is the first effort
to develop a set of standardized interfaces and benchmark problems to enable
consistent and reproducible evaluation of algorithms under non-stationary
conditions. We also benchmark six algorithmic approaches from prior work on
NS-MDPs using NS-Gym. Our vision is that NS-Gym will enable researchers to
assess the adaptability and robustness of their decision-making algorithms to
non-stationary conditions.",http://arxiv.org/abs/2501.09646v1
"Regulation of Algorithmic Collusion, Refined: Testing Pessimistic
  Calibrated Regret",2025-01-16T18:49:12Z,"Jason D. Hartline, Chang Wang, Chenhao Zhang","We study the regulation of algorithmic (non-)collusion amongst sellers in
dynamic imperfect price competition by auditing their data as introduced by
Hartline et al. [2024].
  We develop an auditing method that tests whether a seller's pessimistic
calibrated regret is low. The pessimistic calibrated regret is the highest
calibrated regret of outcomes compatible with the observed data. This method
relaxes the previous requirement that a pricing algorithm must use
fully-supported price distributions to be auditable. This method is at least as
permissive as any auditing method that has a high probability of failing
algorithmic outcomes with non-vanishing calibrated regret. Additionally, we
strengthen the justification for using vanishing calibrated regret, versus
vanishing best-in-hindsight regret, as the non-collusion definition, by showing
that even without any side information, the pricing algorithms that only
satisfy weaker vanishing best-in-hindsight regret allow an opponent to
manipulate them into posting supra-competitive prices. This manipulation cannot
be excluded with a non-collusion definition of vanishing best-in-hindsight
regret.
  We motivate and interpret the approach of auditing algorithms from their data
as suggesting a per se rule. However, we demonstrate that it is possible for
algorithms to pass the audit by pretending to have higher costs than they
actually do. For such scenarios, the rule of reason can be applied to bound the
range of costs to those that are reasonable for the domain.",http://arxiv.org/abs/2501.09740v1
"VERITAS: Verifying the Performance of AI-native Transceiver Actions in
  Base-Stations",2025-01-01T19:12:03Z,"Nasim Soltani, Michael Loehning, Kaushik Chowdhury","Artificial Intelligence (AI)-native receivers prove significant performance
improvement in high noise regimes and can potentially reduce communication
overhead compared to the traditional receiver. However, their performance
highly depends on the representativeness of the training dataset. A major issue
is the uncertainty of whether the training dataset covers all test environments
and waveform configurations, and thus, whether the trained model is robust in
practical deployment conditions. To this end, we propose a joint
measurement-recovery framework for AI-native transceivers post deployment,
called VERITAS, that continuously looks for distribution shifts in the received
signals and triggers finite re-training spurts. VERITAS monitors the wireless
channel using 5G pilots fed to an auxiliary neural network that detects
out-of-distribution channel profile, transmitter speed, and delay spread. As
soon as such a change is detected, a traditional (reference) receiver is
activated, which runs for a period of time in parallel to the AI-native
receiver. Finally, VERTIAS compares the bit probabilities of the AI-native and
the reference receivers for the same received data inputs, and decides whether
or not a retraining process needs to be initiated. Our evaluations reveal that
VERITAS can detect changes in the channel profile, transmitter speed, and delay
spread with 99%, 97%, and 69% accuracies, respectively, followed by timely
initiation of retraining for 86%, 93.3%, and 94.8% of inputs in channel
profile, transmitter speed, and delay spread test sets, respectively.",http://arxiv.org/abs/2501.09761v1
"Mapping the three-dimensional fermiology of the triangular lattice
  magnet EuAg$_4$Sb$_2$",2025-01-17T06:15:52Z,"J. Green, Harry W. T. Morgan, Morgaine Mandigo-Stoba, William T. Laderer, Kuan-Yu Wey, Asari G. Prado, Chris Jozwiak, Aaron Bostwick, Eli Rotenberg, Christopher Gutiérrez, Anastassia N. Alexandrova, Ni Ni","In this paper, we report the temperature-field phase diagram as well as
present a comprehensive study of the electronic structure and three-dimensional
fermiology of the triangular-lattice magnet EuAg$_4$Sb$_2$, utilizing quantum
oscillation measurements, angle-resolved photoemission spectroscopy and
first-principles calculations. The complex magnetic phase diagram of
EuAg$_4$Sb$_2$ highlights many transitions through nontrivial AFM states.
Shubnikov-de Haas and de Haas-van Alphen oscillations were observed in the
polarized ferromagnetic state of EuAg$_4$Sb$_2$, revealing three pairs of
distinct spin-split frequency branches with small effective masses. A
comparison of the angle-dependent oscillation data with first-principles
calculations in the ferromagnetic state and angle-resolved photoemission
spectra shows good agreement, identifying tubular hole pockets and
hourglass-shaped hole pockets at the Brillouin zone center, as well as
diamond-shaped electron pockets at the zone boundary. As the temperature
increases, the frequency branches of the tiny hourglass pockets evolve into a
more cylindrical shape, while the larger pockets remain unchanged. This
highlights that variations in exchange splitting, driven by changes in the
magnetic moment, primarily impact the small Fermi pockets without significantly
altering the overall band structure. This is consistent with first-principles
calculations, which show minimal changes near the Fermi level across
ferromagnetic and simple antiferromagnetic states or under varying on-site
Coulomb repulsion.",http://arxiv.org/abs/2501.09966v1
"No evidence that the binary black hole mass distribution evolves with
  redshift",2025-01-17T16:42:13Z,"Max Lalleman, Kevin Turbang, Thomas Callister, Nick van Remortel","The mass distribution of merging binary black holes is generically predicted
to evolve with redshift, reflecting systematic changes in their astrophysical
environment, stellar progenitors, and/or dominant formation channels over
cosmic time. Whether or not such an effect is observed in gravitational-wave
data, however, remains an open question, with some contradictory results
present in the literature. In this paper, we study the ensemble of binary black
holes within the latest GWTC-3 catalog released by the LIGO-Virgo-KAGRA
Collaboration, systematically surveying for possible evolution of their mass
distribution with redshift. We specifically focus on two key features present
in the binary black hole primary mass distribution -- (1) an excess of
$35\,M_\odot$ black holes and (2) a broad power-law continuum ranging from 10
to $\gtrsim 80 M_\odot$ -- and ask if one or both of these features are
observed to vary with redshift. We find no evidence that either the Gaussian
peak or power-law continuum components of the mass distribution change with
redshift. In some cases, we place somewhat stringent bounds on the degree of
allowed redshift evolution. Most notably, we find that the mean location of the
$35\,M_\odot$ peak and the slope of the power-law continuum are constrained to
remain approximately constant below redshift $z\approx 1$. The data remain more
agnostic about other forms of redshift dependence, such as evolution in the
height of the $35\,M_\odot$ excess or the minimum and maximum black hole
masses. In all cases, we conclude that a redshift-dependent mass spectrum
remains possible, but that it is not required by current data.",http://arxiv.org/abs/2501.10295v1
"New Fashion Products Performance Forecasting: A Survey on Evolutions,
  Models and Emerging Trends",2025-01-17T17:56:27Z,"Andrea Avogaro, Luigi Capogrosso, Andrea Toaiari, Franco Fummi, Marco Cristani","The fast fashion industry's insatiable demand for new styles and rapid
production cycles has led to a significant environmental burden.
Overproduction, excessive waste, and harmful chemicals have contributed to the
negative environmental impact of the industry. To mitigate these issues, a
paradigm shift that prioritizes sustainability and efficiency is urgently
needed. Integrating learning-based predictive analytics into the fashion
industry represents a significant opportunity to address environmental
challenges and drive sustainable practices. By forecasting fashion trends and
optimizing production, brands can reduce their ecological footprint while
remaining competitive in a rapidly changing market. However, one of the key
challenges in forecasting fashion sales is the dynamic nature of consumer
preferences. Fashion is acyclical, with trends constantly evolving and
resurfacing. In addition, cultural changes and unexpected events can disrupt
established patterns. This problem is also known as New Fashion Products
Performance Forecasting (NFPPF), and it has recently gained more and more
interest in the global research landscape. Given its multidisciplinary nature,
the field of NFPPF has been approached from many different angles. This
comprehensive survey wishes to provide an up-to-date overview that focuses on
learning-based NFPPF strategies. The survey is based on the Preferred Reporting
Items for Systematic Reviews and Meta-Analyses (PRISMA) methodological flow,
allowing for a systematic and complete literature review. In particular, we
propose the first taxonomy that covers the learning panorama for NFPPF,
examining in detail the different methodologies used to increase the amount of
multimodal information, as well as the state-of-the-art available datasets.
Finally, we discuss the challenges and future directions.",http://arxiv.org/abs/2501.10324v1
"Automated Detection of Epileptic Spikes and Seizures Incorporating a
  Novel Spatial Clustering Prior",2025-01-05T02:06:13Z,"Hanyang Dong, Shurong Sheng, Xiongfei Wang, Jiahong Gao, Yi Sun, Wanli Yang, Kuntao Xiao, Pengfei Teng, Guoming Luan, Zhao Lv","A Magnetoencephalography (MEG) time-series recording consists of
multi-channel signals collected by superconducting sensors, with each signal's
intensity reflecting magnetic field changes over time at the sensor location.
Automating epileptic MEG spike detection significantly reduces manual
assessment time and effort, yielding substantial clinical benefits. Existing
research addresses MEG spike detection by encoding neural network inputs with
signals from all channel within a time segment, followed by classification.
However, these methods overlook simultaneous spiking occurred from nearby
sensors. We introduce a simple yet effective paradigm that first clusters MEG
channels based on their sensor's spatial position. Next, a novel convolutional
input module is designed to integrate the spatial clustering and temporal
changes of the signals. This module is fed into a custom MEEG-ResNet3D
developed by the authors, which learns to extract relevant features and
classify the input as a spike clip or not. Our method achieves an F1 score of
94.73% on a large real-world MEG dataset Sanbo-CMR collected from two centers,
outperforming state-of-the-art approaches by 1.85%. Moreover, it demonstrates
efficacy and stability in the Electroencephalographic (EEG) seizure detection
task, yielding an improved weighted F1 score of 1.4% compared to current
state-of-the-art techniques evaluated on TUSZ, whch is the largest EEG seizure
dataset.",http://arxiv.org/abs/2501.10404v1
"Constrained Coding for Composite DNA: Channel Capacity and Efficient
  Constructions",2025-01-18T03:32:10Z,"Tuan Thanh Nguyen, Chen Wang, Kui Cai, Yiwei Zhang, Zohar Yakhini","Composite DNA is a recent novel method to increase the information capacity
of DNA-based data storage above the theoretical limit of 2 bits/symbol. In this
method, every composite symbol does not store a single DNA nucleotide but a
mixture of the four nucleotides in a predetermined ratio. By using different
mixtures and ratios, the alphabet can be extended to have much more than four
symbols in the naive approach. While this method enables higher data content
per synthesis cycle, potentially reducing the DNA synthesis cost, it also
imposes significant challenges for accurate DNA sequencing since the base-level
errors can easily change the mixture of bases and their ratio, resulting in
changes to the composite symbols. With this motivation, we propose efficient
constrained coding techniques to enforce the biological constraints, including
the runlength-limited constraint and the GC-content constraint, into every DNA
synthesized oligo, regardless of the mixture of bases in each composite letter
and their corresponding ratio. Our goals include computing the capacity of the
constrained channel, constructing efficient encoders/decoders, and providing
the best options for the composite letters to obtain capacity-approaching
codes. For certain codes' parameters, our methods incur only one redundant
symbol.",http://arxiv.org/abs/2501.10645v1
"Deformable Image Registration of Dark-Field Chest Radiographs for Local
  Lung Signal Change Assessment",2025-01-18T13:08:32Z,"Fabian Drexel, Vasiliki Sideri-Lampretsa, Henriette Bast, Alexander W. Marka, Thomas Koehler, Florian T. Gassert, Daniela Pfeiffer, Daniel Rueckert, Franz Pfeiffer","Dark-field radiography of the human chest has been demonstrated to have
promising potential for the analysis of the lung microstructure and the
diagnosis of respiratory diseases. However, previous studies of dark-field
chest radiographs evaluated the lung signal only in the inspiratory breathing
state. Our work aims to add a new perspective to these previous assessments by
locally comparing dark-field lung information between different respiratory
states. To this end, we discuss suitable image registration methods for
dark-field chest radiographs to enable consistent spatial alignment of the lung
in distinct breathing states. Utilizing full inspiration and expiration scans
from a clinical chronic obstructive pulmonary disease study, we assess the
performance of the proposed registration framework and outline applicable
evaluation approaches. Our regional characterization of lung dark-field signal
changes between the breathing states provides a proof-of-principle that dynamic
radiography-based lung function assessment approaches may benefit from
considering registered dark-field images in addition to standard plain chest
radiographs.",http://arxiv.org/abs/2501.10757v1
"Decoupling Appearance Variations with 3D Consistent Features in Gaussian
  Splatting",2025-01-18T14:55:58Z,"Jiaqi Lin, Zhihao Li, Binxiao Huang, Xiao Tang, Jianzhuang Liu, Shiyong Liu, Xiaofei Wu, Fenglong Song, Wenming Yang","Gaussian Splatting has emerged as a prominent 3D representation in novel view
synthesis, but it still suffers from appearance variations, which are caused by
various factors, such as modern camera ISPs, different time of day, weather
conditions, and local light changes. These variations can lead to floaters and
color distortions in the rendered images/videos. Recent appearance modeling
approaches in Gaussian Splatting are either tightly coupled with the rendering
process, hindering real-time rendering, or they only account for mild global
variations, performing poorly in scenes with local light changes. In this
paper, we propose DAVIGS, a method that decouples appearance variations in a
plug-and-play and efficient manner. By transforming the rendering results at
the image level instead of the Gaussian level, our approach can model
appearance variations with minimal optimization time and memory overhead.
Furthermore, our method gathers appearance-related information in 3D space to
transform the rendered images, thus building 3D consistency across views
implicitly. We validate our method on several appearance-variant scenes, and
demonstrate that it achieves state-of-the-art rendering quality with minimal
training time and memory usage, without compromising rendering speeds.
Additionally, it provides performance improvements for different Gaussian
Splatting baselines in a plug-and-play manner.",http://arxiv.org/abs/2501.10788v1
"Solar oblateness & asphericities temporal variations: outstanding some
  unsolved issues",2025-01-18T16:47:23Z,"Jean P. Rozelot, Alexander G. Kosovichev, Ali Kilcik","Solar oblateness has been the subject of several studies dating back to the
nineteenth century. Despite diffculties, both theoretical and observational,
tangible results have been achieved. However, variability of the solar
oblateness with time is still poorly known. How the solar shape evolves with
the solar cycle has been a challenging problem. Analysis of the helioseismic
data, which are the most accurate measure of the solar structure up to now,
leads to the determination of asphericity coeffcients which have been found to
change with time. We show here that by inverting even coeffcients of f-mode
oscillation frequency splitting to obtain the oblateness magnitude and its
temporal dependence can be inferred. It is found that the oblateness variations
lag the solar activity cycles by about 3 years. A major change occurred between
solar cycles 23 and 24 is that the oblateness was greater in cycle 24 despite
the lower solar activity level. Such results may help to better understand the
near-subsurface layers as they strongly impacts the internal dynamics of the
Sun and may induce instabilities driving the transport of angular momentum.",http://arxiv.org/abs/2501.10821v1
Arbitrary-Threshold Fully Homomorphic Encryption with Lower Complexity,2025-01-20T02:46:08Z,"Yijia Chang, Songze Li","Threshold fully homomorphic encryption (ThFHE) enables multiple parties to
compute functions over their sensitive data without leaking data privacy. Most
of existing ThFHE schemes are restricted to full threshold and require the
participation of \textit{all} parties to output computing results. Compared
with these full-threshold schemes, arbitrary threshold (ATh)-FHE schemes are
robust to non-participants and can be a promising solution to many real-world
applications. However, existing AThFHE schemes are either inefficient to be
applied with a large number of parties $N$ and a large data size $K$, or
insufficient to tolerate all types of non-participants. In this paper, we
propose an AThFHE scheme to handle all types of non-participants with lower
complexity over existing schemes. At the core of our scheme is the reduction
from AThFHE construction to the design of a new primitive called
\textit{approximate secret sharing} (ApproxSS). Particularly, we formulate
ApproxSS and prove the correctness and security of AThFHE on top of
arbitrary-threshold (ATh)-ApproxSS's properties. Such a reduction reveals that
existing AThFHE schemes implicitly design ATh-ApproxSS following a similar idea
called ``noisy share''. Nonetheless, their ATh-ApproxSS design has high
complexity and become the performance bottleneck. By developing ATASSES, an
ATh-ApproxSS scheme based on a novel ``encrypted share'' idea, we reduce the
computation (resp. communication) complexity from $\mathcal{O}(N^2K)$ to
$\mathcal{O}(N^2+K)$ (resp. from $\mathcal{O}(NK)$ to $\mathcal{O}(N+K)$). We
not only theoretically prove the (approximate) correctness and security of
ATASSES, but also empirically evaluate its efficiency against existing
baselines. Particularly, when applying to a system with one thousand parties,
ATASSES achieves a speedup of $3.83\times$ -- $15.4\times$ over baselines.",http://arxiv.org/abs/2501.11235v1
"A New Formulation of Lipschitz Constrained With Functional Gradient
  Learning for GANs",2025-01-20T02:48:07Z,"Chang Wan, Ke Fan, Xinwei Sun, Yanwei Fu, Minglu Li, Yunliang Jiang, Zhonglong Zheng","This paper introduces a promising alternative method for training Generative
Adversarial Networks (GANs) on large-scale datasets with clear theoretical
guarantees. GANs are typically learned through a minimax game between a
generator and a discriminator, which is known to be empirically unstable.
Previous learning paradigms have encountered mode collapse issues without a
theoretical solution. To address these challenges, we propose a novel
Lipschitz-constrained Functional Gradient GANs learning (Li-CFG) method to
stabilize the training of GAN and provide a theoretical foundation for
effectively increasing the diversity of synthetic samples by reducing the
neighborhood size of the latent vector. Specifically, we demonstrate that the
neighborhood size of the latent vector can be reduced by increasing the norm of
the discriminator gradient, resulting in enhanced diversity of synthetic
samples. To efficiently enlarge the norm of the discriminator gradient, we
introduce a novel {\epsilon}-centered gradient penalty that amplifies the norm
of the discriminator gradient using the hyper-parameter {\epsilon}. In
comparison to other constraints, our method enlarging the discriminator norm,
thus obtaining the smallest neighborhood size of the latent vector. Extensive
experiments on benchmark datasets for image generation demonstrate the efficacy
of the Li-CFG method and the {\epsilon}-centered gradient penalty. The results
showcase improved stability and increased diversity of synthetic samples.",http://arxiv.org/abs/2501.11236v1
Nested Annealed Training Scheme for Generative Adversarial Networks,2025-01-20T07:44:09Z,"Chang Wan, Ming-Hsuan Yang, Minglu Li, Yunliang Jiang, Zhonglong Zheng","Recently, researchers have proposed many deep generative models, including
generative adversarial networks(GANs) and denoising diffusion models. Although
significant breakthroughs have been made and empirical success has been
achieved with the GAN, its mathematical underpinnings remain relatively
unknown. This paper focuses on a rigorous mathematical theoretical framework:
the composite-functional-gradient GAN (CFG)[1]. Specifically, we reveal the
theoretical connection between the CFG model and score-based models. We find
that the training objective of the CFG discriminator is equivalent to finding
an optimal D(x). The optimal gradient of D(x) differentiates the integral of
the differences between the score functions of real and synthesized samples.
Conversely, training the CFG generator involves finding an optimal G(x) that
minimizes this difference. In this paper, we aim to derive an annealed weight
preceding the weight of the CFG discriminator. This new explicit theoretical
explanation model is called the annealed CFG method. To overcome the limitation
of the annealed CFG method, as the method is not readily applicable to the SOTA
GAN model, we propose a nested annealed training scheme (NATS). This scheme
keeps the annealed weight from the CFG method and can be seamlessly adapted to
various GAN models, no matter their structural, loss, or regularization
differences. We conduct thorough experimental evaluations on various benchmark
datasets for image generation. The results show that our annealed CFG and NATS
methods significantly improve the quality and diversity of the synthesized
samples. This improvement is clear when comparing the CFG method and the SOTA
GAN models.",http://arxiv.org/abs/2501.11318v1
"StyleSSP: Sampling StartPoint Enhancement for Training-free
  Diffusion-based Method for Style Transfer",2025-01-20T07:45:42Z,"Ruojun Xu, Weijie Xi, Xiaodi Wang, Yongbo Mao, Zach Cheng","Training-free diffusion-based methods have achieved remarkable success in
style transfer, eliminating the need for extensive training or fine-tuning.
However, due to the lack of targeted training for style information extraction
and constraints on the content image layout, training-free methods often suffer
from layout changes of original content and content leakage from style images.
Through a series of experiments, we discovered that an effective startpoint in
the sampling stage significantly enhances the style transfer process. Based on
this discovery, we propose StyleSSP, which focuses on obtaining a better
startpoint to address layout changes of original content and content leakage
from style image. StyleSSP comprises two key components: (1) Frequency
Manipulation: To improve content preservation, we reduce the low-frequency
components of the DDIM latent, allowing the sampling stage to pay more
attention to the layout of content images; and (2) Negative Guidance via
Inversion: To mitigate the content leakage from style image, we employ negative
guidance in the inversion stage to ensure that the startpoint of the sampling
stage is distanced from the content of style image. Experiments show that
StyleSSP surpasses previous training-free style transfer baselines,
particularly in preserving original content and minimizing the content leakage
from style image.",http://arxiv.org/abs/2501.11319v1
"Hybrid Adaptive Modeling using Neural Networks Trained with Nonlinear
  Dynamics Based Features",2025-01-21T02:38:28Z,"Zihan Liu, Prashant N. Kambali, C. Nataraj","Accurate models are essential for design, performance prediction, control,
and diagnostics in complex engineering systems. Physics-based models excel
during the design phase but often become outdated during system deployment due
to changing operational conditions, unknown interactions, excitations, and
parametric drift. While data-based models can capture the current state of
complex systems, they face significant challenges, including excessive data
dependence, limited generalizability to changing conditions, and inability to
predict parametric dependence. This has led to combining physics and data in
modeling, termed physics-infused machine learning, often using numerical
simulations from physics-based models. This paper introduces a novel approach
that departs from standard techniques by uncovering information from nonlinear
dynamical modeling and embedding it in data-based models. The goal is to create
a hybrid adaptive modeling framework that integrates data-based modeling with
newly measured data and analytical nonlinear dynamical models for enhanced
accuracy, parametric dependence, and improved generalizability. By explicitly
incorporating nonlinear dynamic phenomena through perturbation methods, the
predictive capabilities are more realistic and insightful compared to knowledge
obtained from brute-force numerical simulations. In particular, perturbation
methods are utilized to derive asymptotic solutions which are parameterized to
generate frequency responses. Frequency responses provide comprehensive
insights into dynamics and nonlinearity which are quantified and extracted as
high-quality features. A machine-learning model, trained by these features,
tracks parameter variations and updates the mismatched model. The results
demonstrate that this adaptive modeling method outperforms numerical gray box
models in prediction accuracy and computational efficiency.",http://arxiv.org/abs/2501.11835v1
"Integrate Temporal Graph Learning into LLM-based Temporal Knowledge
  Graph Model",2025-01-21T06:12:49Z,"He Chang, Jie Wu, Zhulin Tao, Yunshan Ma, Xianglin Huang, Tat-Seng Chua","Temporal Knowledge Graph Forecasting (TKGF) aims to predict future events
based on the observed events in history. Recently, Large Language Models (LLMs)
have exhibited remarkable capabilities, generating significant research
interest in their application for reasoning over temporal knowledge graphs
(TKGs). Existing LLM-based methods have integrated retrieved historical facts
or static graph representations into LLMs. Despite the notable performance of
LLM-based methods, they are limited by the insufficient modeling of temporal
patterns and ineffective cross-modal alignment between graph and language,
hindering the ability of LLMs to fully grasp the temporal and structural
information in TKGs. To tackle these issues, we propose a novel framework
TGL-LLM to integrate temporal graph learning into LLM-based temporal knowledge
graph model. Specifically, we introduce temporal graph learning to capture the
temporal and relational patterns and obtain the historical graph embedding.
Furthermore, we design a hybrid graph tokenization to sufficiently model the
temporal patterns within LLMs. To achieve better alignment between graph and
language, we employ a two-stage training paradigm to finetune LLMs on
high-quality and diverse data, thereby resulting in better performance.
Extensive experiments on three real-world datasets show that our approach
outperforms a range of state-of-the-art (SOTA) methods.",http://arxiv.org/abs/2501.11911v1
"Generalized Bond Polarizability model for more accurate atomistic
  modeling of Raman spectra",2025-01-21T11:29:55Z,"Atanu Paul, Nagaprasad Reddy Samala, Ilya Grinberg","Raman spectroscopy is an important tool for studies of molecules, liquids and
solids. While Raman spectra can be obtained theoretically from molecular
dynamics (MD) simulations, this requires the calculation of the electronic
polarizability along the simulation trajectory. First-principles calculations
of electronic polarizability are computationally expensive, motivating the
development of atomistic models for the evaluation of the changes in the
electronic polarizability with the changes in the atomic coordinates of the
system. The bond polarizability model (BPM) is one of the oldest and simplest
such atomistic models, but cannot reproduce the effects of angular vibrations,
leading to inaccurate modeling of Raman spectra. Here, we demonstrate that the
generalization of BPM through inclusion of terms for atom pairs that are
traditionally considered to be not involved in bonding dramatically improves
the accuracy of polarizability modeling and Raman spectra calculations. The
generalized BPM (GBPM) reproduces the ab initio polarizability and Raman
spectra for a range of tested molecules (SO2, H2S, H2O, NH3, CH4, CH3OH and
CH3CH2OH) with high accuracy and also shows significantly improved agreement
with ab initio results for the more complex ferroelectric BaTiO3 systems. For
liquid water, the anisotropic Raman spectrum derived from atomistic MD
simulations using GBPM evaluation of polarizability shows significantly
improved agreement with the experimental spectrum compared to the spectrum
derived using BPM. Thus, GBPM can be used for the modeling of Raman spectra
using large-scale molecular dynamics and provides a good basis for the further
development of atomistic polarizability models.",http://arxiv.org/abs/2501.12059v1
"Thermodynamics of $s_{\pm}-to-s_{++}$ transition in iron pnictides in
  the vicinity of the Born limit",2025-01-22T09:05:54Z,"Vadim Shestakov, Maxim M. Korshunov","To study thermodynamical properties of the disorder-induced transition
between $s_{\pm}$ and $s_{++}$ superconducting gap functions, we calculate the
grand thermodynamic potential $\Omega$ in the normal and the superconducting
states. Expression for the difference between the two, $\Delta\Omega$, is
derived for a two-band model for Fe-based systems with nonmagnetic impurities.
The disorder is considered in a $\mathcal{T}$-matrix approximation within the
multiband Eliashberg theory. In the vicinity of the Born limit near the
$s_{\pm}$-to-$s_{++}$ transition, we find two solutions obtained for opposite
directions of the system's evolution with respect to the impurity scattering
rate. By calculating the change in entropy $\Delta S$ and the change in
electronic specific heat $\Delta C$ from $\Delta\Omega$, we show that such a
hysteresis is not due to the time-reversal symmetry breaking state, but it
rather points out to the first order phase transition induced by the
nonmagnetic disorder. Based on the $\Delta\Omega$ calculations, phase diagram
is plotted representing the energetically favourable $s_{\pm}$ and $s_{++}$
states and the transition between them. At finite temperature, a first order
phase transition line there is limited by a critical end point. Above that
point, the sharp $s_{\pm} \to s_{++}$ transition transforms to a crossover
between $s_{\pm}$ and $s_{++}$ states.",http://arxiv.org/abs/2501.12730v1
"Exploring the Technology Landscape through Topic Modeling, Expert
  Involvement, and Reinforcement Learning",2025-01-22T22:18:50Z,"Ali Nazari, Michael Weiss","In today's rapidly evolving technological landscape, organizations face the
challenge of integrating external insights into their decision-making processes
to stay competitive. To address this issue, this study proposes a method that
combines topic modeling, expert knowledge inputs, and reinforcement learning
(RL) to enhance the detection of technological changes. The method has four
main steps: (1) Build a relevant topic model, starting with textual data like
documents and reports to find key themes. (2) Create aspect-based topic models.
Experts use curated keywords to build models that showcase key domain-specific
aspects. (3) Iterative analysis and RL driven refinement: We examine metrics
such as topic magnitude, similarity, entropy shifts, and how models change over
time. We optimize topic selection with RL. Our reward function balances the
diversity and similarity of the topics. (4) Synthesis and operational
integration: Each iteration provides insights. In the final phase, the experts
check these insights and reach new conclusions. These conclusions are designed
for use in the firm's operational processes. The application is tested by
forecasting trends in quantum communication. Results demonstrate the method's
effectiveness in identifying, ranking, and tracking trends that align with
expert input, providing a robust tool for exploring evolving technological
landscapes. This research offers a scalable and adaptive solution for
organizations to make informed strategic decisions in dynamic environments.",http://arxiv.org/abs/2501.13252v2
"Pseudocode-Injection Magic: Enabling LLMs to Tackle Graph Computational
  Tasks",2025-01-23T15:04:22Z,"Chang Gong, Wanrui Bian, Zhijie Zhang, Weiguo Zheng","Graph computational tasks are inherently challenging and often demand the
development of advanced algorithms for effective solutions. With the emergence
of large language models (LLMs), researchers have begun investigating their
potential to address these tasks. However, existing approaches are constrained
by LLMs' limited capability to comprehend complex graph structures and their
high inference costs, rendering them impractical for handling large-scale
graphs. Inspired by human approaches to graph problems, we introduce a novel
framework, PIE (Pseudocode-Injection-Enhanced LLM Reasoning for Graph
Computational Tasks), which consists of three key steps: problem understanding,
prompt design, and code generation. In this framework, LLMs are tasked with
understanding the problem and extracting relevant information to generate
correct code. The responsibility for analyzing the graph structure and
executing the code is delegated to the interpreter. We inject task-related
pseudocodes into the prompts to further assist the LLMs in generating efficient
code. We also employ cost-effective trial-and-error techniques to ensure that
the LLM-generated code executes correctly. Unlike other methods that require
invoking LLMs for each individual test case, PIE only calls the LLM during the
code generation phase, allowing the generated code to be reused and
significantly reducing inference costs. Extensive experiments demonstrate that
PIE outperforms existing baselines in terms of both accuracy and computational
efficiency.",http://arxiv.org/abs/2501.13731v1
Molecular origins of colossal barocaloric effects in plastic crystals,2025-01-24T11:17:15Z,"Ares Sanuy, Carlos Escorihuela-Sayalero, Pol Lloveras, Josep Lluis Tamarit, Luis Carlos Pardo, Claudio Cazorla","In recent years, orientationally disordered crystals, or plastic crystals,
have transformed the field of solid-state cooling due to the significant latent
heat and entropy changes associated with their temperature induced molecular
order-disorder phase transition, which can produce colossal caloric effects
under external field stimuli. However, the molecular mechanisms underlying
these huge caloric effects remain inadequately understood, and general
principles for enhancing the performance of caloric plastic crystals are
lacking. Previous studies have predominantly focused on molecular rotations,
overlooking other potentially critical factors, such as lattice vibrations and
molecular conformations. In this study, we employ classical molecular dynamics
(MD) simulations to both replicate and elucidate the microscopic origins of the
experimentally observed colossal barocaloric (BC) effects -- those driven by
hydrostatic pressure -- in the archetypal plastic crystal neopentyl glycol
(NPG). Our MD simulations demonstrate that in NPG, the combined BC response and
phase-transition entropy changes arising from lattice vibrations and molecular
conformations are nearly equal to those from molecular reorientations,
contributing 45% and 55%, respectively. These findings suggest that, alongside
hydrogen bonding -- which directly impacts molecular rotational dynamics --
lattice vibrational and molecular structural features, often overlooked, must
be integrated into the rational design and modeling of advanced caloric plastic
crystals. These insights are not only of significant fundamental interest but
also essential for driving the development of next-generation solid-state
refrigeration technologies.",http://arxiv.org/abs/2501.14403v1
Optimal Strategies for Federated Learning Maintaining Client Privacy,2025-01-24T12:34:38Z,"Uday Bhaskar, Varul Srivastava, Avyukta Manjunatha Vummintala, Naresh Manwani, Sujit Gujar","Federated Learning (FL) emerged as a learning method to enable the server to
train models over data distributed among various clients. These clients are
protective about their data being leaked to the server, any other client, or an
external adversary, and hence, locally train the model and share it with the
server rather than sharing the data. The introduction of sophisticated
inferencing attacks enabled the leakage of information about data through
access to model parameters. To tackle this challenge, privacy-preserving
federated learning aims to achieve differential privacy through learning
algorithms like DP-SGD. However, such methods involve adding noise to the
model, data, or gradients, reducing the model's performance.
  This work provides a theoretical analysis of the tradeoff between model
performance and communication complexity of the FL system. We formally prove
that training for one local epoch per global round of training gives optimal
performance while preserving the same privacy budget. We also investigate the
change of utility (tied to privacy) of FL models with a change in the number of
clients and observe that when clients are training using DP-SGD and argue that
for the same privacy budget, the utility improved with increased clients. We
validate our findings through experiments on real-world datasets. The results
from this paper aim to improve the performance of privacy-preserving federated
learning systems.",http://arxiv.org/abs/2501.14453v1
"Explaining Categorical Feature Interactions Using Graph Covariance and
  LLMs",2025-01-24T21:41:26Z,"Cencheng Shen, Darren Edge, Jonathan Larson, Carey E. Priebe","Modern datasets often consist of numerous samples with abundant features and
associated timestamps. Analyzing such datasets to uncover underlying events
typically requires complex statistical methods and substantial domain
expertise. A notable example, and the primary data focus of this paper, is the
global synthetic dataset from the Counter Trafficking Data Collaborative (CTDC)
-- a global hub of human trafficking data containing over 200,000 anonymized
records spanning from 2002 to 2022, with numerous categorical features for each
record. In this paper, we propose a fast and scalable method for analyzing and
extracting significant categorical feature interactions, and querying large
language models (LLMs) to generate data-driven insights that explain these
interactions. Our approach begins with a binarization step for categorical
features using one-hot encoding, followed by the computation of graph
covariance at each time. This graph covariance quantifies temporal changes in
dependence structures within categorical data and is established as a
consistent dependence measure under the Bernoulli distribution. We use this
measure to identify significant feature pairs, such as those with the most
frequent trends over time or those exhibiting sudden spikes in dependence at
specific moments. These extracted feature pairs, along with their timestamps,
are subsequently passed to an LLM tasked with generating potential explanations
of the underlying events driving these dependence changes. The effectiveness of
our method is demonstrated through extensive simulations, and its application
to the CTDC dataset reveals meaningful feature pairs and potential data stories
underlying the observed feature interactions.",http://arxiv.org/abs/2501.14932v1
"Automatic Link Selection in Multi-Channel Multiple Access with Link
  Failures",2025-01-24T23:09:31Z,"Mevan Wijewardena, Michael J. Neely","This paper focuses on the problem of automatic link selection in
multi-channel multiple access control using bandit feedback. In particular, a
controller assigns multiple users to multiple channels in a time slotted
system, where in each time slot at most one user can be assigned to a given
channel and at most one channel can be assigned to a given user. Given that
user $i$ is assigned to channel $j$, the transmission fails with a fixed
probability $f_{i,j}$. The failure probabilities are not known to the
controller. The assignments are made dynamically using success/failure
feedback. The goal is to maximize the time average utility, where we consider
an arbitrary (possibly nonsmooth) concave and entrywise nondecreasing utility
function. The problem of merely maximizing the total throughput has a solution
of always assigning the same user-channel pairs and can be unfair to certain
users, particularly when the number of channels is less than the number of
users. Instead, our scheme allows various types of fairness, such as
proportional fairness, maximizing the minimum, or combinations of these by
defining the appropriate utility function. We propose two algorithms for this
task. The first algorithm is adaptive and gets within
$\mathcal{O}(\log(T)/T^{1/3})$ of optimality over any interval of $T$
consecutive slots over which the success probabilities do not change. The
second algorithm has faster $\mathcal{O}(\sqrt{\log(T)/T})$ performance over
the first $T$ slots, but does not adapt well if probabilities change.",http://arxiv.org/abs/2501.14971v1
Probing ALP couplings to electroweak gauge bosons,2025-01-25T15:44:36Z,"Jin Sun, Zhi-Peng Xing, Seokhoon Yun","Motivated by the more and more abundant experimental data, we revisit the
couplings of axion-like particle (ALP) to electroweak gauge bosons across the
ALP mass range from MeV to 100 GeV. The current and future experimental limits
on the couplings are extended. The ALP coupling to $W$-bosons gives rise to
flavor-changing ALP-quark couplings at the one-loop level. These
flavor-changing couplings deserve further investigation under current
experimental constraints, especially those stemming from rare meson decays and
neutral meson mixing processes. Additionally, flavor-conserving couplings of
the ALP to Standard Model (SM) fermions arise at the one-loop level as well
from ALP-electroweak gauge boson couplings, even in the absence of tree-level
couplings to these SM fermions, with consequent ALP decays to the SM fermions
leading to constraints on the ALP-electroweak gauge boson couplings. We also
investigate processes relevant to $Z$-boson measurements, such as the invisible
decay $Z\to a\gamma$, subsequent decays
  $Z\to 3\gamma$ and $Z\to \gamma ll$, as well as constraints from oblique
parameters ($S,\, T,\, U$). Our study highlights that rare two-body decays of
pseudoscalar mesons offer the most sensitive probes of ALP couplings to
electroweak gauge bosons from the loop-induced flavor-violating interactions
for ALP masses below the kinematic threshold, while $Z$-boson decays
complementarily explore larger ALP masses. Future lepton colliders, such as
CEPC and FCC-ee operating at the $Z$-pole, along with SHiP, provide further
opportunities to probe ALP couplings to electroweak gauge bosons.",http://arxiv.org/abs/2501.15250v2
"Tracing the Lifecycle of Architecture Technical Debt in Software
  Systems: A Dependency Approach",2025-01-26T03:58:57Z,"Edi Sutoyo, Paris Avgeriou, Andrea Capiluppi","Architectural technical debt (ATD) represents trade-offs in software
architecture that accelerate initial development but create long-term
maintenance challenges. ATD, in particular when self-admitted, impacts the
foundational structure of software, making it difficult to detect and resolve.
This study investigates the lifecycle of ATD, focusing on how it affects i) the
connectivity between classes and ii) the frequency of file modifications. We
aim to understand how ATD evolves from introduction to repayment and its
implications on software architectures. Our empirical approach was applied to a
dataset of SATD from various software artifacts. We isolated ATD instances,
filtered for architectural indicators, and calculated dependencies at different
lifecycle stages using FAN-IN and FAN-OUT metrics. Statistical analyses,
including the Mann-Whitney U test and Cohen's d, were used to assess the
significance and effect size of connectivity and dependency changes over time.
We observed that ATD repayment increased class connectivity, with FAN-IN
increasing by 57.5% on average and FAN-OUT by 26.7%, suggesting a shift toward
centralization and increased architectural complexity post-repayment. Moreover,
ATD files were modified less frequently than Non-ATD files, with changes
accumulated in high-dependency portions of the code. Our study shows that
resolving ATD improves software quality in the short-term, but can make the
architecture more complex by centralizing dependencies. Also, even if
dependency metrics (like FAN-IN and FAN-OUT) can help understand the impact of
ATD, they should be combined with other measures to capture other effects of
ATD on software maintainability.",http://arxiv.org/abs/2501.15387v1
"The Potential of Large Language Models in Supply Chain Management:
  Advancing Decision-Making, Efficiency, and Innovation",2025-01-26T05:41:50Z,"Raha Aghaei, Ali A. Kiaei, Mahnaz Boush, Javad Vahidi, Zeynab Barzegar, Mahan Rofoosheh","The integration of large language models (LLMs) into supply chain management
(SCM) is revolutionizing the industry by improving decision-making, predictive
analytics, and operational efficiency. This white paper explores the
transformative impact of LLMs on various SCM functions, including demand
forecasting, inventory management, supplier relationship management, and
logistics optimization. By leveraging advanced data analytics and real-time
insights, LLMs enable organizations to optimize resources, reduce costs, and
improve responsiveness to market changes. Key findings highlight the benefits
of integrating LLMs with emerging technologies such as IoT, blockchain, and
robotics, which together create smarter and more autonomous supply chains.
Ethical considerations, including bias mitigation and data protection, are
taken into account to ensure fair and transparent AI practices. In addition,
the paper discusses the need to educate the workforce on how to manage new
AI-driven processes and the long-term strategic benefits of adopting LLMs.
Strategic recommendations for SCM professionals include investing in
high-quality data management, promoting cross-functional collaboration, and
aligning LLM initiatives with overall business goals. The findings highlight
the potential of LLMs to drive innovation, sustainability, and competitive
advantage in the ever-changing supply chain management landscape.",http://arxiv.org/abs/2501.15411v1
"Efficiency Bottlenecks of Convolutional Kolmogorov-Arnold Networks: A
  Comprehensive Scrutiny with ImageNet, AlexNet, LeNet and Tabular
  Classification",2025-01-27T04:00:05Z,"Ashim Dahal, Saydul Akbar Murad, Nick Rahimi","Algorithmic level developments like Convolutional Neural Networks,
transformers, attention mechanism, Retrieval Augmented Generation and so on
have changed Artificial Intelligence. Recent such development was observed by
Kolmogorov-Arnold Networks that suggested to challenge the fundamental concept
of a Neural Network, thus change Multilayer Perceptron, and Convolutional
Neural Networks. They received a good reception in terms of scientific
modeling, yet had some drawbacks in terms of efficiency. In this paper, we
train Convolutional Kolmogorov Arnold Networks (CKANs) with the ImageNet-1k
dataset with 1.3 million images, MNIST dataset with 60k images and a tabular
biological science related MoA dataset and test the promise of CKANs in terms
of FLOPS, Inference Time, number of trainable parameters and training time
against the accuracy, precision, recall and f-1 score they produce against the
standard industry practice on CNN models. We show that the CKANs perform fair
yet slower than CNNs in small size dataset like MoA and MNIST but are not
nearly comparable as the dataset gets larger and more complex like the
ImageNet. The code implementation of this paper can be found on the link:
\href{https://github.com/ashimdahal/Study-of-Convolutional-Kolmogorov-Arnold-networks}{https://github.com/ashimdahal/Study-of-Convolutional-Kolmogorov-Arnold-networks}",http://arxiv.org/abs/2501.15757v2
Observables for the Effect of Gravity on Electromagnetic Polarization,2025-01-27T08:13:15Z,Kjell Tangen,"Does gravity affect the polarization of electromagnetic radiation in an
observable way? The effect of gravity on the observed polarization of a ray of
electromagnetic radiation is investigated for an arbitrary 4-dimensional
spacetime and radiation with a frequency spectrum within the geometric optics
limit and with arbitrary state of polarization. Focusing on effects observable
by a single inertial observer, we show how the presence of curvature along the
null geodesic of polarized electromagnetic radiation may induce observable
changes in the state of polarization. We find a set of scalars that quantify
the effect and derive their transport equations. Two of these scalars, the
polarization degree and the circular polarization degree, are polarization
state observables that are conserved along the radiation geodesic. Four
observables that quantify time rate of change of the observed state of
polarization are identified. These observables and their corresponding
transport equations provide a complete representation of how gravity affects
the observed state of polarization of electromagnetic radiation with
frequencies above the geometric optics limit. Polarization wiggling is sourced
by curvature twist, which is a scalar derived from the Riemann tensor.
Curvature twist is closely related to the magnetic part of the Weyl tensor, the
second Weyl scalar as well as the rotation of the rest frame geodesic
congruence. The results of this paper are valid for any metric theory of
gravity.",http://arxiv.org/abs/2501.15846v1
Probability of earthquake fault jumps from physics based criterion,2025-01-27T10:52:18Z,"Sylvain Michel, Oona Scotti, Sebastien Hok, Harsha S. Bhat, Navid Kheirdast, Pierre Romanet, Michelle Almakari, Jinhui Cheng","Geometrical complexities in natural fault zones, such as steps and gaps, pose
a challenge in seismic hazard studies as they can act as barriers to seismic
ruptures. In this study, we propose a criterion, which is based on the
rate-and-state equation, to estimate the efficiency of an earthquake rupture to
jump two spatially disconnected faults. The proposed jump criterion is tested
using a 2D quasi-dynamic numerical simulations of the seismic cycle. The
criterion successfully predicts fault jumps where the coulomb stress change
fails to do so. The criterion includes the coulomb stress change as a parameter
but is also dependent on other important parameters among which the absolute
normal stress on the fault which the rupture is to jump to. Based on the
criterion, the maximum jump distance increases with decreasing absolute normal
stress, i.e. as the rupture process occurs closer to the surface or as pore
pressure increases. The criterion implies that an earthquake can jump to an
infinite distance at the surface if the normal stress is allowed to go to zero.
Thus, the properties of the surface layers are of the outmost importance in
terms of maximum rupture jump distance allowed. The absolute normal stress is
the main controlling parameter followed by the uncertainty on the slip of an
earthquake, which controls the coulomb stress impact on the receiver fault.
Finally, we also propose a method to compute probabilities of earthquakes
rupture to jump, which allows to consider uncertainties in geometrical
configurations between two faults.",http://arxiv.org/abs/2501.15948v1
"Effect of Numerical Resolution on Synthetic Observables of Simulated
  Coronal Loops",2025-01-27T18:34:11Z,"Cosima Alexandra Breu, Ineke De Moortel, Hardi Peter, Sami Khan Solanki","Increasingly realistic simulations of the corona are used to predict
synthetic observables for instruments onboard both existing and upcoming
heliophysics space missions. Synthetic observables play an important role in
constraining coronal heating theories. Choosing the spatial resolution of
numerical simulations involves a trade-off between accuracy and computational
cost. Since the numerical resolution not only affects the scale of structures
that can be resolved, but also thermodynamic quantities such as the average
coronal density, it is important to quantify the effect on synthesized
observables. Using 3D radiative MHD simulations of coronal loops at three
different grid spacings, from 60 km down to 12 km, we find that changes in
numerical resolution lead to differences in thermodynamic quantities and
stratification as well as dynamic behaviour. Higher grid resolution results in
a more complex and dynamic atmosphere. The resolution affects the emission
intensity as well as the velocity distribution, thereby affecting synthetic
spectra derived from the simulation. The distribution of synthetic coronal loop
strand sizes changes as more fine-scale structure is resolved. A number of
parameters, however, seem to start to saturate from our chosen medium grid
resolution on. Our study shows that while choosing a sufficiently high
resolution matters when comparing forward-modelled observables with data from
current and future space missions, for most purposes not much is gained by
further increasing the resolution beyond a grid spacing of 24 km, which seems
to be adequate for reproducing bulk loop properties and forward-modelled
emission, representing a good trade-off between accuracy and computational
resource.",http://arxiv.org/abs/2501.16293v1
"Stable Tree Labelling for Accelerating Distance Queries on Dynamic Road
  Networks",2025-01-29T02:25:18Z,"Henning Koehler, Muhammad Farhan, Qing Wang","Finding the shortest-path distance between two arbitrary vertices is an
important problem in road networks. Due to real-time traffic conditions, road
networks undergo dynamic changes all the time. Current state-of-the-art methods
incrementally maintain a distance labelling based on a hierarchy among vertices
to support efficient distance computation. However, their labelling sizes are
often large and cannot be efficiently maintained. To combat these issues, we
present a simple yet efficient labelling method, namely \emph{Stable Tree
Labelling} (STL), for answering distance queries on dynamic road networks. We
observe that the properties of an underlying hierarchy play an important role
in improving and balancing query and update performance. Thus, we introduce the
notion of \emph{stable tree hierarchy} which lays the ground for developing
efficient maintenance algorithms on dynamic road networks. Based on stable tree
hierarchy, STL can be efficiently constructed as a 2-hop labelling. A crucial
ingredient of STL is to only store distances within subgraphs in labels, rather
than distances in the entire graph, which restricts the labels affected by
dynamic changes. We further develop two efficient maintenance algorithms upon
STL: \emph{Label Search algorithm} and \emph{Pareto Search algorithm}. Label
Search algorithm identifies affected ancestors in a stable tree hierarchy and
performs efficient searches to update labels from those ancestors. Pareto
Search algorithm explores the interaction between search spaces of different
ancestors, and combines searches from multiple ancestors into only two searches
for each update, eliminating duplicate graph traversals. The experiments show
that our algorithms significantly outperform state-of-the-art dynamic methods
in maintaining the labelling and query processing, while requiring an order of
magnitude less space.",http://arxiv.org/abs/2501.17379v1
Reqo: A Robust and Explainable Query Optimization Cost Model,2025-01-29T04:48:51Z,"Baoming Chang, Amin Kamali, Verena Kantere","In recent years, there has been a growing interest in using machine learning
(ML) in query optimization to select more efficient plans. Existing
learning-based query optimizers use certain model architectures to convert
tree-structured query plans into representations suitable for downstream ML
tasks. As the design of these architectures significantly impacts cost
estimation, we propose a tree model architecture based on Bidirectional Graph
Neural Networks (Bi-GNN) aggregated by Gated Recurrent Units (GRUs) to achieve
more accurate cost estimates. The inherent uncertainty of data and model
parameters also leads to inaccurate cost estimates, resulting in suboptimal
plans and less robust query performance. To address this, we implement a novel
learning-to-rank cost model that effectively quantifies the uncertainty in cost
estimates using approximate probabilistic ML. This model adaptively integrates
quantified uncertainty with estimated costs and learns from comparing pairwise
plans, achieving more robust performance. In addition, we propose the first
explainability technique specifically designed for learning-based cost models.
This technique explains the contribution of any subgraphs in the query plan to
the final predicted cost, which can be integrated and trained with any
learning-based cost model to significantly boost the model's explainability. By
incorporating these innovations, we propose a cost model for a Robust and
Explainable Query Optimizer, Reqo, that improves the accuracy, robustness, and
explainability of cost estimation, outperforming state-of-the-art approaches in
all three dimensions.",http://arxiv.org/abs/2501.17414v1
"Nuclear Electric Resonance for Spatially-Resolved Spin Control via
  Pulsed Optical Excitation in the UV-Visible Spectrum",2025-01-29T11:21:39Z,"Johannes K. Krondorfer, Andreas W. Hauser","Nuclear electric resonance (NER) spectroscopy is currently experiencing a
revival as a tool for nuclear spin-based quantum computing. Compared to
magnetic or electric fields, local electron density fluctuations caused by
changes in the atomic environment provide a much higher spatial resolution for
the addressing of nuclear spins in qubit registers or within a single molecule.
In this article, we investigate the possibility of coherent spin control in
atoms or molecules via nuclear quadrupole resonance from first principles. An
abstract, time-dependent description is provided which entails and reflects on
commonly applied approximations. This formalism is then used to propose a new
method we refer to as `optical' nuclear electric resonance (ONER). It employs
pulsed optical excitations in the UV-visible light spectrum to modulate the
electric field gradient at the position of a specific nucleus of interest by
periodic changes of the surrounding electron density. Possible realizations and
limitations of ONER for atomically resolved spin manipulation are discussed and
tested on $^9$Be as an atomic benchmark system via electronic structure theory.",http://arxiv.org/abs/2501.17575v1
"Variations of absolute source positions determined from quad-band VLBI
  observations",2025-01-30T11:28:40Z,"Ming Hui Xu, Patrick Charlot","Active Galactic Nuclei (AGNs) observed with the technique of very long
baseline interferometry (VLBI) are used as fiducial references on the sky to
precisely measure the shape and orientation of the Earth. Their positions form
a celestial reference frame that plays an important role in both astronomy and
geodesy. This study investigates the accuracy and stability of the positions of
the AGNs that are measured by simultaneous VLBI observations at 3.3, 5.5, 6.6,
and 10.5 GHz. Based on position time series from dedicated geodetic solutions,
we characterize the observed source position variations and identify the
possible factors causing such variations. We find that the primary contributor
is source structure for sources above 20-degree declination while the
sensitivity of the observations to the declination coordinate predominates for
sources below 20-degree declination. The position time series are further
explored to derive more realistic uncertainties for the quad-band positions.
Significant position offsets with respect to the positions at 2.2/8.6 GHz are
found for 15% of the sources. For 6% of the sources, the offsets are larger
than 0.8 milli-arcseconds. Source structure may be divided into two parts: the
invisible structure (within the beam size) and the visible structure (on larger
scales). The latter causes closure delays enlarging post-fit delay residuals in
geodetic solutions whereas the former causes source position changes. Such
position changes will contribute significantly to the offsets between radio and
optical positions. Overall, this work highlights the necessity to have a
specific quad-band catalog for processing operational quad-band observations.",http://arxiv.org/abs/2501.18276v1
"Characterization of NBI-driven shear Alfvén waves in the TJ-II
  stellarator using Mirnov probes and electrostatic potential fluctuation
  measurements",2025-01-30T17:51:29Z,"P. Pons-Villalonga, Á. Cappa, E. Ascasíbar, O. S. Kozachok, M. B. Dreval, K. J. McCarthy, J. de la Riva Villén, J. Martínez-Fernández, TJ-II Team","We present the first experimental measurements of the toroidal mode number of
shear Alfv\'en waves in the TJ-II stellarator. A series of experiments were
carried out in three different magnetic configurations to investigate
counter-NBI driven modes. Co- and counter- electron-cyclotron current drive was
used to modify the rotational transform ($\iota/2\pi$) profile leading to the
destabilization of a varied set of Alfv\'en eigenmodes with different
frequencies and mode numbers. To characterize the spatial structure of the
modes we have used two Mirnov probe arrays, one dedicated to the measurement of
the poloidal mode number and the other, a recently commissioned helical
tri-axial array, dedicated to the measurement of the toroidal mode number. A
heavy ion beam probe, operated in radial sweep mode, was employed to
characterize the radial location of the modes. We show that the induced changes
in $\iota/2\pi$, that are fundamental when it comes to validation studies,
cannot be measured experimentally with motional Stark effect so, instead, the
shielding current diffusion equation is solved in cylindrical geometry to
estimate these changes. We calculate the incompressible shear Alfv\'en
continuum for selected cases using \texttt{STELLGAP} and find reasonable
consistency with observations. A database with the observed modes has been
created, so that it can be used in future work for theory validation purposes.",http://arxiv.org/abs/2501.18529v1
"BounTCHA: A CAPTCHA Utilizing Boundary Identification in AI-extended
  Videos",2025-01-30T18:38:09Z,"Lehao Lin, Ke Wang, Maha Abdallah, Wei Cai","In recent years, the rapid development of artificial intelligence (AI)
especially multi-modal Large Language Models (MLLMs), has enabled it to
understand text, images, videos, and other multimedia data, allowing AI systems
to execute various tasks based on human-provided prompts. However, AI-powered
bots have increasingly been able to bypass most existing CAPTCHA systems,
posing significant security threats to web applications. This makes the design
of new CAPTCHA mechanisms an urgent priority. We observe that humans are highly
sensitive to shifts and abrupt changes in videos, while current AI systems
still struggle to comprehend and respond to such situations effectively. Based
on this observation, we design and implement BounTCHA, a CAPTCHA mechanism that
leverages human perception of boundaries in video transitions and disruptions.
By utilizing AI's capability to expand original videos with prompts, we
introduce unexpected twists and changes to create a pipeline for generating
short videos for CAPTCHA purposes. We develop a prototype and conduct
experiments to collect data on humans' time biases in boundary identification.
This data serves as a basis for distinguishing between human users and bots.
Additionally, we perform a detailed security analysis of BounTCHA,
demonstrating its resilience against various types of attacks. We hope that
BounTCHA will act as a robust defense, safeguarding millions of web
applications in the AI-driven era.",http://arxiv.org/abs/2501.18565v1
"A Radiance Field Loss for Fast and Simple Emissive Surface
  Reconstruction",2025-01-27T13:30:51Z,"Ziyi Zhang, Nicolas Roussel, Thomas Müller, Tizian Zeltner, Merlin Nimier-David, Fabrice Rousselle, Wenzel Jakob","We present a fast and simple technique to convert images into an emissive
surface-based scene representation. Building on existing emissive volume
reconstruction algorithms, we introduce a subtle yet impactful modification of
the loss function requiring changes to only a few lines of code: instead of
integrating the radiance field along rays and supervising the resulting images,
we project the training images into the scene to directly supervise the
spatio-directional radiance field.
  The primary outcome of this change is the complete removal of alpha blending
and ray marching from the image formation model, instead moving these steps
into the loss computation. In addition to promoting convergence to surfaces,
this formulation assigns explicit semantic meaning to 2D subsets of the
radiance field, turning them into well-defined emissive surfaces. We finally
extract a level set from this representation, which results in a high-quality
emissive surface model.
  Our method retains much of the speed and quality of the baseline algorithm.
For instance, a suitably modified variant of Instant~NGP maintains comparable
computational efficiency, while achieving an average PSNR that is only 0.1 dB
lower. Most importantly, our method generates explicit surfaces in place of an
exponential volume, doing so with a level of simplicity not seen in prior work.",http://arxiv.org/abs/2501.18627v1
"First-order phase transitions in the heavy quark region of lattice QCD
  at high temperatures and high densities",2025-01-31T00:48:25Z,Shinji Ejiri,"If there is a first-order phase transition in the light quark region of
2+1-flavor finite temperature and density QCD and if the region of the
first-order phase transition expands with increasing density as suggested by
several studies, then, at very high densities, we may expect that the
first-order phase transition region expands into the heavy quark region of QCD,
where we can perform efficient large scale simulations by adopting an effective
theory of heavy quark QCD based on the hopping parameter expansion. In the
heavy quark region of QCD, we have another first-order phase transition region
around the heavy quark limit at zero density. By numerical simulations of
effective heavy quark QCD, we found that, the first-order transition at zero
density turns into a crossover as the chemical potential is increased, but,
when we increase the chemical potential further, the change in the plaquette
value near the crossover point becomes much steeper. This may be suggesting
reappearance of the first-order phase transition. In this talk, we first show
the nature of the phase transition of phase-quenched finite density QCD in the
heavy quark region and then study the effect of the complex phase to discuss
whether the QCD phase transition changes again to a first-order phase
transition at very high densities.",http://arxiv.org/abs/2501.18828v1
"Quantum effects in surface diffusion: application to diffusion of
  nitrogen adatoms over GaN(0001) surface",2025-01-31T12:10:14Z,"Paweł Strak, Cyprian Sobczak, Stanislaw Krukowski","It is shown that quantum effects play determining role in nitrogen adatom
diffusion due to several different factors. This could be related to the change
of the energy of the quantum states and also due to the redistribution of
electrons between the quantum states, both full and resonant, via quantum
statistics partially governed by the Fermi energy level. These effects were
studied in the case of nitrogen diffusion over clean and gallium covered
Ga-terminated GaN(0001) surface. For the fractional coverage the density
functional theory (DFT) calculations show that at the saddle point
configuration the redistribution of electrons between different quantum states
may affect the surface diffusion barrier significantly. The other quantum
influence occurs via the change of the minimal energy configuration. Under
fractional Ga coverage of GaN(0001) surface the nitrogen diffusion energy
barrier proceeds from the resonant states governed energy minimal H3 site
across the saddle point in the bridge configuration. At this path the barrier
is affected the electron redistribution between surface quantum states both in
the initial and the saddle point. In the case of the full GaN coverage the
diffusion path is from on-top N adatom configuration via H3 site that
corresponds to maximal energy. Therefore the diffusion barrier is Ebar= 1.18 eV
for clean and Ebar= 0.92 eV for (1/6) ML to finally Ebar= 1.23 eV for full Ga
coverage. Thus the overall barrier is reduced to Ebar= 0.92 eV due to quantum
statistics effects. The identified stable N on-top configuration for the full
coverage is essential for atomic mechanism of GaN growth in Ga-rich regime.",http://arxiv.org/abs/2501.19079v1
"Imitation Game for Adversarial Disillusion with Multimodal Generative
  Chain-of-Thought Role-Play",2025-01-31T13:57:34Z,"Ching-Chun Chang, Fan-Yun Chen, Shih-Hong Gu, Kai Gao, Hanrui Wang, Isao Echizen","As the cornerstone of artificial intelligence, machine perception confronts a
fundamental threat posed by adversarial illusions. These adversarial attacks
manifest in two primary forms: deductive illusion, where specific stimuli are
crafted based on the victim model's general decision logic, and inductive
illusion, where the victim model's general decision logic is shaped by specific
stimuli. The former exploits the model's decision boundaries to create a
stimulus that, when applied, interferes with its decision-making process. The
latter reinforces a conditioned reflex in the model, embedding a backdoor
during its learning phase that, when triggered by a stimulus, causes aberrant
behaviours. The multifaceted nature of adversarial illusions calls for a
unified defence framework, addressing vulnerabilities across various forms of
attack. In this study, we propose a disillusion paradigm based on the concept
of an imitation game. At the heart of the imitation game lies a multimodal
generative agent, steered by chain-of-thought reasoning, which observes,
internalises and reconstructs the semantic essence of a sample, liberated from
the classic pursuit of reversing the sample to its original state. As a proof
of concept, we conduct experimental simulations using a multimodal generative
dialogue agent and evaluates the methodology under a variety of attack
scenarios.",http://arxiv.org/abs/2501.19143v1
Using Causality for Enhanced Prediction of Web Traffic Time Series,2025-02-02T00:36:40Z,"Chang Tian, Mingzhe Xing, Zenglin Shi, Matthew B. Blaschko, Yinliang Yue, Marie-Francine Moens","Predicting web service traffic has significant social value, as it can be
applied to various practical scenarios, including but not limited to dynamic
resource scaling, load balancing, system anomaly detection, service-level
agreement compliance, and fraud detection. Web service traffic is characterized
by frequent and drastic fluctuations over time and are influenced by
heterogeneous web user behaviors, making accurate prediction a challenging
task. Previous research has extensively explored statistical approaches, and
neural networks to mine features from preceding service traffic time series for
prediction. However, these methods have largely overlooked the causal
relationships between services. Drawing inspiration from causality in
ecological systems, we empirically recognize the causal relationships between
web services. To leverage these relationships for improved web service traffic
prediction, we propose an effective neural network module, CCMPlus, designed to
extract causal relationship features across services. This module can be
seamlessly integrated with existing time series models to consistently enhance
the performance of web service traffic predictions. We theoretically justify
that the causal correlation matrix generated by the CCMPlus module captures
causal relationships among services. Empirical results on real-world datasets
from Microsoft Azure, Alibaba Group, and Ant Group confirm that our method
surpasses state-of-the-art approaches in Mean Squared Error (MSE) and Mean
Absolute Error (MAE) for predicting service traffic time series. These findings
highlight the efficacy of leveraging causal relationships for improved
predictions.",http://arxiv.org/abs/2502.00612v1
"Lifting the Winding Number: Precise Representation of Complex Cuts in
  Subspace Physics Simulations",2025-02-02T01:51:56Z,"Yue Chang, Mengfei Liu, Zhecheng Wang, Peter Yichen Chen, Eitan Grinspun","Cutting thin-walled deformable structures is common in daily life, but poses
significant challenges for simulation due to the introduced spatial
discontinuities. Traditional methods rely on mesh-based domain representations,
which require frequent remeshing and refinement to accurately capture evolving
discontinuities. These challenges are further compounded in reduced-space
simulations, where the basis functions are inherently geometry- and
mesh-dependent, making it difficult or even impossible for the basis to
represent the diverse family of discontinuities introduced by cuts.
  Recent advances in representing basis functions with neural fields offer a
promising alternative, leveraging their discretization-agnostic nature to
represent deformations across varying geometries. However, the inherent
continuity of neural fields is an obstruction to generalization, particularly
if discontinuities are encoded in neural network weights.
  We present Wind Lifter, a novel neural representation designed to accurately
model complex cuts in thin-walled deformable structures. Our approach
constructs neural fields that reproduce discontinuities precisely at specified
locations, without baking in the position of the cut line. Crucially, our
approach does not embed the discontinuity in the neural network's weights,
opening avenues to generalization of cut placement.
  Our method achieves real-time simulation speeds and supports dynamic updates
to cut line geometry during the simulation. Moreover, the explicit
representation of discontinuities makes our neural field intuitive to control
and edit, offering a significant advantage over traditional neural fields,
where discontinuities are embedded within the network's weights, and enabling
new applications that rely on general cut placement.",http://arxiv.org/abs/2502.00626v1
TrojanTime: Backdoor Attacks on Time Series Classification,2025-02-02T03:24:24Z,"Chang Dong, Zechao Sun, Guangdong Bai, Shuying Piao, Weitong Chen, Wei Emma Zhang","Time Series Classification (TSC) is highly vulnerable to backdoor attacks,
posing significant security threats. Existing methods primarily focus on data
poisoning during the training phase, designing sophisticated triggers to
improve stealthiness and attack success rate (ASR). However, in practical
scenarios, attackers often face restrictions in accessing training data.
Moreover, it is a challenge for the model to maintain generalization ability on
clean test data while remaining vulnerable to poisoned inputs when data is
inaccessible. To address these challenges, we propose TrojanTime, a novel
two-step training algorithm. In the first stage, we generate a pseudo-dataset
using an external arbitrary dataset through target adversarial attacks. The
clean model is then continually trained on this pseudo-dataset and its poisoned
version. To ensure generalization ability, the second stage employs a carefully
designed training strategy, combining logits alignment and batch norm freezing.
We evaluate TrojanTime using five types of triggers across four TSC
architectures in UCR benchmark datasets from diverse domains. The results
demonstrate the effectiveness of TrojanTime in executing backdoor attacks while
maintaining clean accuracy. Finally, to mitigate this threat, we propose a
defensive unlearning strategy that effectively reduces the ASR while preserving
clean accuracy.",http://arxiv.org/abs/2502.00646v1
Integrated plasmo-photonic sensor with voltage controled detection,2025-02-02T16:22:27Z,"Jacek Gosciniak, Ryszard Piramidowicz","In this paper, we propose and analyze a waveguide-integrated interferometric
sensor in which interference occurs between two plasmonic modes propagating in
a single plasmonic waveguide. For the purpose of sensing, the vertical
plasmonic slot waveguide was rearranged by increasing the distance between the
metal electrodes. Consequently, the plasmonic modes associated with each metal
electrode have been separated, enabling them to propagate independently on
opposing edges of metal electrodes what allows for the implementation of a
Mach-Zehnder interferometer. The metal electrodes that support the plasmonic
modes can also function as electrical contacts. By applying a DC voltage
between them, it is possible to efficiently separate ions that drift to one of
the metal electrodes. Consequently, any change in a transmission from the
interferometer refers only to the amount of ions in a liquid as the output
signal from the interferometer is normalized to a liquid by the reference arm
which is in direct contact with the examined liquid solution. The total amount
of ions in the examined liquid remains constant, however, what changes is their
distribution in the gap as the ions drift toward one of the metal electrodes
when a voltage is applied. The proposed configuration is highly sensitive to
variations in transmission between the two arms of the interferometer, enabling
a record sensitivity of over 12460 nm/RIU, even at the telecom wavelength of
1550 nm. A further enhancement in sensitivity is expected in the mid-infrared
wavelengths, which correspond to the maximum absorption peaks of most chemical
and biological compounds.",http://arxiv.org/abs/2502.00839v1
Modeling Filamentary Conduction in Reset Phase Change Memory Devices,2025-02-02T18:20:02Z,"Md Samzid Bin Hafiz, Helena Silva, Ali Gokirmak","We performed a computational analysis on percolation transport and filament
formation in amorphous $Ge_2Sb_2Te_5$ (a-GST) using 2D finite-element
multi-physics simulations with 2 nm out-of-plane depth using an electric-field
and temperature dependent electronic transport model with carrier activation
energies that vary locally around 0.3 eV and as a function of temperature. We
observe the snapback (threshold switching) behavior in the current-voltage
(I-V) characteristics at ~50 MV/m electric field with 0.63 $\mu$A current for
300 K ambient temperature, where current collapses onto a single molten
filament with ~ 2 nm diameter, aligned with the electric field, and the device
switches from a high resistance state (108 $\Omega$) to a low resistance state
(103 $\Omega$). Further increase in voltage across the device leads to widening
of the molten filament. Snap-back current and electric field are strong
functions of ambient temperature, ranging from ~ 0.53 $\mu$A at 200 K to ~
16.93 $\mu$A at 800 K and ~ 85 MV/m at 150 K to 45 MV/m at 350 K, respectively.
Snap-back electric-field decreases exponentially with increasing device length,
converging to ~ 38 MV/m for devices longer than 200 nm.",http://arxiv.org/abs/2502.00866v1
"Dependence of the energy and orbital structure of local states in CuO
  monolayer on Coulomb parameters",2025-02-03T16:17:15Z,"I. A. Makarov, M. M. Korshunov, S. G. Ovchinnikov","The dependence of the energies and orbital structure of local states in the
CuO monolayer on intra- and interatomic Coulomb interactions on copper and
oxygen orbitals is studied. The electronic system is described within the
eight-band p-d model in the hole representation with the on-site energies and
hopping integrals obtained using density functional theory. CuO cluster
multiparticle eigenstates are calculated using exact diagonalization. The
difference between the energy dependencies on the Coulomb parameters for the
states with the predominant probability density on the d-orbital and the states
in which hole occupies p-orbitals leads to crossover of d- and p-states. The
ground single-hole and two-hole states which determine the electronic structure
of the low-energy excitations have the character of d- or p-orbitals in the
different regions of the Coulomb parameters space. The gap between the energies
of the dispersionless quasiparticles forming the top of the valence band and
conductivity band also have different values in these two regions. The
magnitude of this gap and the orbital character of the local multiparticle
states change sharply even with an insignificant change in the Coulomb
interactions within the boundary region of parameters between the regions in
which the local states are formed by the d- or p-orbitals.",http://arxiv.org/abs/2502.01483v1
"LV-XAttn: Distributed Cross-Attention for Long Visual Inputs in
  Multimodal Large Language Models",2025-02-04T15:24:16Z,"Tzu-Tao Chang, Shivaram Venkataraman","Cross-attention is commonly adopted in multimodal large language models
(MLLMs) for integrating visual information into the language backbone. However,
in applications with large visual inputs, such as video understanding,
processing a large number of visual tokens in cross-attention layers leads to
high memory demands and often necessitates distributed computation across
multiple GPUs. Existing distributed attention mechanisms face significant
communication overheads, making cross-attention layers a critical bottleneck
for efficient training and inference of MLLMs. To address this, we propose
LV-XAttn, a distributed, exact cross-attention mechanism with minimal
communication overhead. We observe that in applications involving large visual
inputs the size of the query block is typically much smaller than that of the
key-value blocks. Thus, in LV-XAttn we keep the large key-value blocks locally
on each GPU and exchange smaller query blocks across GPUs. We also introduce an
efficient activation recomputation technique enabling support for longer visual
context. We theoretically analyze the communication benefits of LV-XAttn and
show that it can achieve speedups for a wide range of models. Our evaluations
with mPLUG-Owl3 and OpenFlamingo models find that LV-XAttn achieves up to
5.58$\times$ end-to-end speedup compared to existing approaches.",http://arxiv.org/abs/2502.02406v2
"Response of liquid metal in a fusion reactor blanket to rapid variation
  of magnetic field during a transient plasma event",2025-02-04T20:31:53Z,"Ivan Smolyanov, Oleg Zikanov","Transient plasma events, such as plasma disruptions, are anticipated in the
future magnetic-confinement nuclear fusion reactors. The events are accompanied
by a rapid change in the magnetic field generated by the plasma current and,
accordingly, induction of strong eddy currents and Lorentz forces within the
reactor structure. This work targets processes within liquid-metal components
of the reactor's breeding blankets. Order-of-magnitude analysis and numerical
simulations are performed to understand the response of liquid metal to a
rapidly changing magnetic field and to evaluate the accuracy of commonly used
simplifying model assumptions. The response is found to consist of two stages:
an initial brief stage ($\sim 1$ ms) characterized by a rapid increase in the
induced currents, forces, and fluid velocity; and a subsequent stage, which is
triggered by the growing velocity of the metal and marked by reversals of
Lorentz force, and oscillations and decreases in the amplitude of the induced
fields. The transition to the second stage sets the upper limit of the velocity
($\sim 0.5$ m/s in our tests), to which an initially quiescent metal can be
accelerated during the event. The simulations indicate that many widely used
model assumptions, such as the negligible role of Joule dissipation in the heat
balance and the constancy of physical property coefficients, remain valid
during the response. However, the assumption of liquid metal incompressibility
is found to be questionable due to the potential significant effects of
pressure waves.",http://arxiv.org/abs/2502.02699v2
"Planning with affordances: Integrating learned affordance models and
  symbolic planning",2025-02-04T23:15:38Z,Rajesh Mangannavar,"Intelligent agents working in real-world environments must be able to learn
about the environment and its capabilities which enable them to take actions to
change to the state of the world to complete a complex multi-step task in a
photorealistic environment. Learning about the environment is especially
important to perform various multiple-step tasks without having to redefine an
agent's action set for different tasks or environment settings. In our work, we
augment an existing task and motion planning framework with learned affordance
models of objects in the world to enable planning and executing multi-step
tasks using learned models. Each task can be seen as changing the current state
of the world to a given goal state. The affordance models provide us with what
actions are possible and how to perform those actions in any given state. A
symbolic planning algorithm uses this information and the starting and goal
state to create a feasible plan to reach the desired goal state to complete a
given task. We demonstrate our approach in a virtual 3D photorealistic
environment, AI2-Thor, and evaluate it on real-world tasks. Our results show
that our agent quickly learns how to interact with the environment and is well
prepared to perform tasks such as ""Moving an object out of the way to reach the
desired location.""",http://arxiv.org/abs/2502.02768v1
"Don't Let Your Likert Scales Grow Up To Be Visual Analog Scales:
  Understanding the Relationship Between Number of Response Categories and
  Measurement Error",2025-02-05T03:01:40Z,"Siqi Sun, Karen M. Schmidt, Teague R. Henry","The use of Visual Analog Scales (VAS), which can be broadly conceptualized as
items where the response scale is 0-100, has surged recently due to the
convenience of digital assessments. However, there is no consensus as to
whether the use of VAS scales is optimal in a measurement sense. Put
differently, in the 90+ years since Likert introduced his eponymous scale, the
field does not know how to determine the optimal number of response options for
a given item. In the current work, we investigate the optimal number of
response categories using a series of simulations. We find that when the
measurement error of an item is not dependent on the number of response
categories, there is no true optimum; rather, reliability increases with number
of response options and then plateaus. However, under the more realistic
assumption that the measurement error of an item increases with the number of
response categories, we find a clear optimum that depends on the rate of that
increase. If measurement error increases with the number of response
categories, then conversion of any Likert scale item to VAS will result in a
drastic decrease in reliability. Finally, if researchers do want to change the
response scale of a validated measure, they must re-validate the new measure as
the measurement error of the scale is likely to change.",http://arxiv.org/abs/2502.02846v1
"Optical Properties of Aluminium-Doped Zinc Oxide Thin Films Synthesized
  via AACVD Using Nitrogen as a Carrier Gas",2025-02-05T10:37:25Z,"Kingsley Imoni-Ogbe, Onyekachukwu Mike Osiele, Vincent Akpoveta, Queen Umudi, Bright Ugbolu, Oscar Enajite","The study uses AACVD technology with nitrogen carrier gas to make AZO thin
films through which it determines structural, optical, and morphological
changes from 0 to 20 percent aluminum doping. The depositions took place at 400
degrees Celsius on soda-lime glass before the samples received an annealing
process at 450 degrees Celsius inside a nitrogen chamber. The X-ray diffraction
analysis identified superior crystalline structure in films processed with
nitrogen gas through their strong signals at the 220, 311 and 222 peaks. The
increasing levels of aluminum doping decreased the crystallite dimensions and
elevated grain boundary concentrations because of intensified crystal tension
and defective structural formation. The profilometry assessment determined film
thickness increased mildly from 102 nanometers in undoped ZnO to 115 nanometers
in 20 percent aluminum-doped ZnO. The presence of nitrogen annealing in the
films led to increased absorbance while the strongest absorbance peaks occurred
when the material contained 5 percent dopants. The bandgap energy expanded
through the change from undoped ZnO with 3.21 electron volts to 3.33 electron
volts at 20 percent aluminum doping which matched Burstein-Moss effect results.
The optoelectronic devices gain enhanced optical characteristics from the
doping levels exceeding 15 percent.",http://arxiv.org/abs/2502.03058v1
Strategizing with AI: Insights from a Beauty Contest Experiment,2025-02-05T13:31:38Z,"Iuliia Alekseenko, Dmitry Dagaev, Sofia Paklina, Petr Parshakov","A Keynesian beauty contest is a wide class of games of guessing the most
popular strategy among other players. In particular, guessing a fraction of a
mean of numbers chosen by all players is a classic behavioral experiment
designed to test iterative reasoning patterns among various groups of people.
The previous literature reveals that the level of sophistication of the
opponents is an important factor affecting the outcome of the game. Smarter
decision makers choose strategies that are closer to theoretical Nash
equilibrium and demonstrate faster convergence to equilibrium in iterated
contests with information revelation. We replicate a series of classic
experiments by running virtual experiments with modern large language models
(LLMs) who play against various groups of virtual players. We test how advanced
the LLMs' behavior is compared to the behavior of human players. We show that
LLMs typically take into account the opponents' level of sophistication and
adapt by changing the strategy. In various settings, most LLMs (with the
exception of Llama) are more sophisticated and play lower numbers compared to
human players. Our results suggest that LLMs (except Llama) are rather
successful in identifying the underlying strategic environment and adopting the
strategies to the changing set of parameters of the game in the same way that
human players do. All LLMs still fail to play dominant strategies in a
two-player game. Our results contribute to the discussion on the accuracy of
modeling human economic agents by artificial intelligence.",http://arxiv.org/abs/2502.03158v1
"From Kernels to Features: A Multi-Scale Adaptive Theory of Feature
  Learning",2025-02-05T14:26:50Z,"Noa Rubin, Kirsten Fischer, Javed Lindner, David Dahmen, Inbar Seroussi, Zohar Ringel, Michael Krämer, Moritz Helias","Theoretically describing feature learning in neural networks is crucial for
understanding their expressive power and inductive biases, motivating various
approaches. Some approaches describe network behavior after training through a
simple change in kernel scale from initialization, resulting in a
generalization power comparable to a Gaussian process. Conversely, in other
approaches training results in the adaptation of the kernel to the data,
involving complex directional changes to the kernel. While these approaches
capture different facets of network behavior, their relationship and respective
strengths across scaling regimes remains an open question. This work presents a
theoretical framework of multi-scale adaptive feature learning bridging these
approaches. Using methods from statistical mechanics, we derive analytical
expressions for network output statistics which are valid across scaling
regimes and in the continuum between them. A systematic expansion of the
network's probability distribution reveals that mean-field scaling requires
only a saddle-point approximation, while standard scaling necessitates
additional correction terms. Remarkably, we find across regimes that kernel
adaptation can be reduced to an effective kernel rescaling when predicting the
mean network output of a linear network. However, even in this case, the
multi-scale adaptive approach captures directional feature learning effects,
providing richer insights than what could be recovered from a rescaling of the
kernel alone.",http://arxiv.org/abs/2502.03210v1
"Parametric reduced-order modeling and mode sensitivity of actuated
  cylinder flow from a matrix manifold perspective",2025-02-06T03:30:41Z,"Shintaro Sato, Oliver T. Schmidt","We present a framework for parametric proper orthogonal decomposition
(POD)-Galerkin reduced-order modeling (ROM) of fluid flows that accommodates
variations in flow parameters and control inputs. As an initial step, to
explore how the locally optimal POD modes vary with parameter changes, we
demonstrate a sensitivity analysis of POD modes and their spanned subspace,
respectively rooted in Stiefel and Grassmann manifolds. The sensitivity
analysis, by defining distance between POD modes for different parameters, is
applied to the flow around a rotating cylinder with varying Reynolds numbers
and rotation rates. The sensitivity of the subspace spanned by POD modes to
parameter changes is represented by a tangent vector on the Grassmann manifold.
For the cylinder case, the inverse of the subspace sensitivity on the Grassmann
manifold is proportional to the Roshko number, highlighting the connection
between geometric properties and flow physics. Furthermore, the Reynolds number
at which the subspace sensitivity approaches infinity corresponds to the lower
bound at which the characteristic frequency of the K\'arm\'an vortex street
exists (Noack & Eckelmann, JFM, 1994). From the Stiefel manifold perspective,
sensitivity modes are derived to represent the flow field sensitivity,
comprising the sensitivities of the POD modes and expansion coefficients. The
temporal evolution of the flow field sensitivity is represented by superposing
the sensitivity modes. Lastly, we devise a parametric POD-Galerkin ROM based on
subspace interpolation on the Grassmann manifold. The reconstruction error of
the ROM is intimately linked to the subspace-estimation error, which is in turn
closely related to subspace sensitivity.",http://arxiv.org/abs/2502.03754v1
"The coalescent structure of multitype continuous-time Galton-Watson
  trees",2025-02-07T00:46:50Z,"Osvaldo Angtuncio Hernández, Simon Harris, Juan Carlos Pardo","We investigate the genealogy of a sample of $k\geq1$ particles chosen
uniformly without replacement from a population alive at large times in a
critical continuous-time multitype Galton-Watson process with finite second
moment. We will show that subject to a deterministic time-change, the sample
genealogy always converges to the same universal genealogical structure; it has
the same tree topology as Kingman's coalescent, when the types are discarded,
and the coalescent times of the $k-1$ pairwise mergers look like a mixture of
independent identically distributed times. We show that such an ancestral
lineage in the limit, strongly depends on the multitype offspring distribution,
which differs from the single type case Harris, Johnston, and Roberts [Annals
of Applied Probability, 2020]. Our approach uses $k$ distinguished 'spine'
particles and a suitable change of measure under which (a) the spines form a
uniform sample without replacement that depend on the colours but additionally
(b) there is $k$-size biasing and discounting according to the population size.
Our work substantially extends the spine techniques developed in Harris,
Johnston, and Roberts [Annals of Applied Probability, 2020] for genealogies of
uniform samples of size $k$ in critical, continuous-time, single-type
Galton-Watson processes. We generalize these methods to the multi-type setting
and provide a comprehensive analysis of how functionals of the spines are
influenced by the types. While the single-type case exhibits a more homogeneous
structure with simpler dependency patterns, the multi-type case introduces
interactions between different types, leading to a more intricate dependency
structure where functionals must account for type-specific behaviours and
inter-type relationships.",http://arxiv.org/abs/2502.04588v1
"Context images for Venus Express radio occultation measurements: A
  search for a correlation between temperature structure and UV contrasts in
  the clouds of Venus",2025-02-07T04:25:06Z,"Maarten Roos-Serote, Colin Wilson, Ryan MacDonald, Silvia Tellmann, Yeon Joo Lee, Igor Khatuntsev","Venus exhibits strong and changing contrasts at ultraviolet wavelengths
apparently related to the clouds and the dynamics in the cloud layer, but to
date their origin continues to be unknown. We investigate the nature of the UV
contrasts exhibited by Venus clouds by examining possible correlations between
the thermal structure inferred from radio occultation data and UV brightness
from imagery data, both observed with Venus Express. We analyse Venus Express
images obtained from 11 hours before to a few hours after the time of radio
occultation measurements of the same area. We account for the advection of
clouds by zonal and meridional winds and apply a phase angle correction to
compensate for the changing viewing geometry. We find a possible
anti-correlation between UV-brightness and atmospheric temperature in the 65-70
km altitude range for low latitudes. Heating in this altitude and latitude
region due to an increase in the UV-absorber has been predicted by radiative
forcing studies. The predictions roughly match our observed temperature
amplitude between UV-dark and UV-bright regions. We find no evidence for any
correlation between UV-brightness and static stability in the atmosphere in the
50-80 km altitude region. This could be the first observational evidence for a
direct link between UV-brightness and atmospheric temperature in the 65-70km
altitude region in the clouds of Venus.",http://arxiv.org/abs/2502.04650v1
"Mechanistic Understandings of Representation Vulnerabilities and
  Engineering Robust Vision Transformers",2025-02-07T05:58:16Z,"Chashi Mahiul Islam, Samuel Jacob Chacko, Mao Nishino, Xiuwen Liu","While transformer-based models dominate NLP and vision applications, their
underlying mechanisms to map the input space to the label space semantically
are not well understood. In this paper, we study the sources of known
representation vulnerabilities of vision transformers (ViT), where perceptually
identical images can have very different representations and semantically
unrelated images can have the same representation. Our analysis indicates that
imperceptible changes to the input can result in significant representation
changes, particularly in later layers, suggesting potential instabilities in
the performance of ViTs. Our comprehensive study reveals that adversarial
effects, while subtle in early layers, propagate and amplify through the
network, becoming most pronounced in middle to late layers. This insight
motivates the development of NeuroShield-ViT, a novel defense mechanism that
strategically neutralizes vulnerable neurons in earlier layers to prevent the
cascade of adversarial effects. We demonstrate NeuroShield-ViT's effectiveness
across various attacks, particularly excelling against strong iterative
attacks, and showcase its remarkable zero-shot generalization capabilities.
Without fine-tuning, our method achieves a competitive accuracy of 77.8% on
adversarial examples, surpassing conventional robustness methods. Our results
shed new light on how adversarial effects propagate through ViT layers, while
providing a promising approach to enhance the robustness of vision transformers
against adversarial attacks. Additionally, they provide a promising approach to
enhance the robustness of vision transformers against adversarial attacks.",http://arxiv.org/abs/2502.04679v1
"Identification of $tqg$ flavor-changing neutral current interactions
  using machine learning techniques",2025-02-07T11:30:27Z,"Byeonghak Ko, Jeewon Heo, Woojin Jang, Jason S. H. Lee, Youn Jung Roh, Ian James Watson, Seungjin Yang","Flavor-changing neutral currents (FCNCs) are forbidden at tree level in the
Standard Model (SM), but they can be enhanced in physics Beyond the Standard
Model (BSM) scenarios.In this paper, we investigate the effectiveness of deep
learning techniques to enhance the sensitivity of current and future collider
experiments to the production of a top quark and an associated parton through
the $tqg$ FCNC process, which originates from the $tug$ and $tcg$ vertices. The
$tqg$ FCNC events can be produced with a top quark and either an associated
gluon or quark, while SM only has events with a top quark and an associated
quark. We apply machine learning techniques to distinguish the $tqg$ FCNC
events from the SM backgrounds, including $qg$-discrimination variables. We use
the Boosted Decision Tree (BDT) method as a baseline classifier, assuming that
the leading jet originates from the associated parton. We compare with a
Transformer-based deep learning method known as the Self-Attention for
Jet-parton Assignment (SAJA) network, which allows us to include information
from all jets in the event, regardless of their number, eliminating the
necessity to match the associated parton to the leading jet. The \SaJa\ network
with qg-discrimination variables has the best performance, giving expected
upper limits on the branching ratios Br($t \to qg$) that are 25-35\% lower than
those from the BDT method.",http://arxiv.org/abs/2502.04844v1
"Deep Generative model that uses physical quantities to generate and
  retrieve solar magnetic active regions",2025-02-07T21:44:01Z,"Subhamoy Chatterjee, Andres Munoz-Jaramillo, Anna Malanushenko","Deep generative models have shown immense potential in generating unseen data
that has properties of real data. These models learn complex data-generating
distributions starting from a smaller set of latent dimensions. However,
generative models have encountered great skepticism in scientific domains due
to the disconnection between generative latent vectors and scientifically
relevant quantities. In this study, we integrate three types of machine
learning models to generate solar magnetic patches in a physically
interpretable manner and use those as a query to find matching patches in real
observations. We use the magnetic field measurements from Space-weather HMI
Active Region Patches (SHARPs) to train a Generative Adversarial Network (GAN).
We connect the physical properties of GAN-generated images with their latent
vectors to train Support Vector Machines (SVMs) that do mapping between
physical and latent spaces. These produce directions in the GAN latent space
along which known physical parameters of the SHARPs change. We train a
self-supervised learner (SSL) to make queries with generated images and find
matches from real data. We find that the GAN-SVM combination enables users to
produce high-quality patches that change smoothly only with a prescribed
physical quantity, making generative models physically interpretable. We also
show that GAN outputs can be used to retrieve real data that shares the same
physical properties as the generated query. This elevates Generative Artificial
Intelligence (AI) from a means-to-produce artificial data to a novel tool for
scientific data interrogation, supporting its applicability beyond the domain
of heliophysics.",http://arxiv.org/abs/2502.05351v1
"A state-space framework for causal detection of hippocampal
  ripple-replay events",2025-02-08T00:39:35Z,"Sirui Zeng, Uri T. Eden","Hippocampal ripple-replay events are typically identified using a two-step
process that at each time point uses past and future data to determine whether
an event is occurring. This prevents researchers from identifying these events
in real time for closed-loop experiments. It also prevents the identification
of periods of nonlocal representation that are not accompanied by large changes
in the spectral content of the local field potentials (LFPs). In this work, we
present a new state-space model framework that is able to detect concurrent
changes in the rhythmic structure of LFPs with nonlocal activity in place cells
to identify ripple-replay events in a causal manner. The model combines latent
factors related to neural oscillations, represented space, and switches between
coding properties to explain simultaneously the spiking activity from multiple
units and the rhythmic content of LFPs recorded from multiple sources. The
model is temporally causal, meaning that estimates of the switching state can
be made at each instant using only past information from the spike and LFP
signals, or can be combined with future data to refine those estimates. We
applied this model framework to simulated and real hippocampal data to
demonstrate its performance in identifying ripple-replay events.",http://arxiv.org/abs/2502.05394v2
"Towards Learning Scalable Agile Dynamic Motion Planning for Robosoccer
  Teams with Policy Optimization",2025-02-08T11:13:07Z,"Brandon Ho, Batuhan Altundas, Matthew Gombolay","In fast-paced, ever-changing environments, dynamic Motion Planning for
Multi-Agent Systems in the presence of obstacles is a universal and unsolved
problem. Be it from path planning around obstacles to the movement of robotic
arms, or in planning navigation of robot teams in settings such as Robosoccer,
dynamic motion planning is needed to avoid collisions while reaching the
targeted destination when multiple agents occupy the same area. In continuous
domains where the world changes quickly, existing classical Motion Planning
algorithms such as RRT* and A* become computationally expensive to rerun at
every time step. Many variations of classical and well-formulated non-learning
path-planning methods have been proposed to solve this universal problem but
fall short due to their limitations of speed, smoothness, optimally, etc. Deep
Learning models overcome their challenges due to their ability to adapt to
varying environments based on past experience. However, current learning motion
planning models use discretized environments, do not account for heterogeneous
agents or replanning, and build up to improve the classical motion planners'
efficiency, leading to issues with scalability. To prevent collisions between
heterogenous team members and collision to obstacles while trying to reach the
target location, we present a learning-based dynamic navigation model and show
our model working on a simple environment in the concept of a simple Robosoccer
Game.",http://arxiv.org/abs/2502.05526v1
"Rethinking Word Similarity: Semantic Similarity through Classification
  Confusion",2025-02-08T21:55:38Z,"Kaitlyn Zhou, Haishan Gao, Sarah Chen, Dan Edelstein, Dan Jurafsky, Chen Shani","Word similarity has many applications to social science and cultural
analytics tasks like measuring meaning change over time and making sense of
contested terms. Yet traditional similarity methods based on cosine similarity
between word embeddings cannot capture the context-dependent, asymmetrical,
polysemous nature of semantic similarity. We propose a new measure of
similarity, Word Confusion, that reframes semantic similarity in terms of
feature-based classification confusion. Word Confusion is inspired by Tversky's
suggestion that similarity features be chosen dynamically. Here we train a
classifier to map contextual embeddings to word identities and use the
classifier confusion (the probability of choosing a confounding word c instead
of the correct target word t) as a measure of the similarity of c and t. The
set of potential confounding words acts as the chosen features. Our method is
comparable to cosine similarity in matching human similarity judgments across
several datasets (MEN, WirdSim353, and SimLex), and can measure similarity
using predetermined features of interest. We demonstrate our model's ability to
make use of dynamic features by applying it to test a hypothesis about changes
in the 18th C. meaning of the French word ""revolution"" from popular to state
action during the French Revolution. We hope this reimagining of semantic
similarity will inspire the development of new tools that better capture the
multi-faceted and dynamic nature of language, advancing the fields of
computational social science and cultural analytics and beyond.",http://arxiv.org/abs/2502.05704v1
Multimodal Search on a Line,2025-02-10T19:50:54Z,"Jared Coleman, Dmitry Ivanov, Evangelos Kranakis, Danny Krizanc, Oscar Morales Ponce","Inspired by the diverse set of technologies used in underground object
detection and imaging, we introduce a novel multimodal linear search problem
whereby a single searcher starts at the origin and must find a target that can
only be detected when the searcher moves through its location using the correct
of $p$ possible search modes.
  The target's location, its distance $d$ from the origin, and the correct
search mode are all initially unknown to the searcher. We prove tight upper and
lower bounds on the competitive ratio for this problem. Specifically, we show
that when $p$ is odd, the optimal competitive ratio is given by
$2p+3+\sqrt{8(p+1)}$, whereas when $p$ is even, the optimal competitive ratio
is given by $c$: the unique solution to $(c-1)^4-4p(c+1)^2(c-p-1)=0$ in the
interval $\left[2p+1+\sqrt{8p},\infty\right)$. This solution $c$ has the
explicit bounds $2p+3+\sqrt{8(p-1)}\leq c\leq 2p+3+\sqrt{8p}$. The optimal
algorithms we propose require the searcher to move infinitesimal distances and
change directions infinitely many times within finite intervals. To better suit
practical applications, we also propose an approximation algorithm with a
competitive ratio of $c+\varepsilon$ (where $c$ is the optimal competitive
ratio and $\varepsilon > 0$ is an arbitrarily small constant). This algorithm
involves the searcher moving finite distances and changing directions a finite
number of times within any finite interval.",http://arxiv.org/abs/2502.07000v1
"Comprehensive Analysis of Thermal Dissipation in Lithium-Ion Battery
  Packs",2025-02-10T22:06:05Z,"Xuguang Zhang, Hexiang Zhang, Amjad Almansour, Mrityunjay Singh, Hengling Zhu, Michael C. Halbig, Yi Zheng","Effective thermal management is critical for lithium-ion battery packs' safe
and efficient operations, particularly in applications such as drones, where
compact designs and varying airflow conditions present unique challenges. This
study investigates the thermal performance of a 16-cell lithium-ion battery
pack by optimizing cooling airflow configurations and integrating phase change
materials (PCMs) for enhanced heat dissipation. Seven geometric configurations
were evaluated under airflow speeds ranging from 0 to 15 m/s, reflecting the
operational conditions of civilian drones. A comprehensive 3D simulation
approach was used to analyze the effects of inlet and outlet configurations,
airflow dynamics, and PCM phase transition behavior. Results indicate that the
trapezoidal (wide-base) configuration, paired with a 5-inlet and 1-outlet
setup, achieves the most balanced performance, effectively maintaining optimal
operating temperatures across low and high-speed airflow conditions. PCM
integration further stabilized thermal behavior, with phase change durations
extending to 12.5 min under tested conditions. These findings highlight the
importance of geometric optimization and material integration in advancing
compact and reliable thermal management systems for energy-dense battery packs.
This study provides a foundation for designing efficient cooling strategies
tailored to lightweight applications such as drones and portable energy storage
systems.",http://arxiv.org/abs/2502.07070v1
"SparseFormer: Detecting Objects in HRW Shots via Sparse Vision
  Transformer",2025-02-11T03:21:25Z,"Wenxi Li, Yuchen Guo, Jilai Zheng, Haozhe Lin, Chao Ma, Lu Fang, Xiaokang Yang","Recent years have seen an increase in the use of gigapixel-level image and
video capture systems and benchmarks with high-resolution wide (HRW) shots.
However, unlike close-up shots in the MS COCO dataset, the higher resolution
and wider field of view raise unique challenges, such as extreme sparsity and
huge scale changes, causing existing close-up detectors inaccuracy and
inefficiency. In this paper, we present a novel model-agnostic sparse vision
transformer, dubbed SparseFormer, to bridge the gap of object detection between
close-up and HRW shots. The proposed SparseFormer selectively uses attentive
tokens to scrutinize the sparsely distributed windows that may contain objects.
In this way, it can jointly explore global and local attention by fusing
coarse- and fine-grained features to handle huge scale changes. SparseFormer
also benefits from a novel Cross-slice non-maximum suppression (C-NMS)
algorithm to precisely localize objects from noisy windows and a simple yet
effective multi-scale strategy to improve accuracy. Extensive experiments on
two HRW benchmarks, PANDA and DOTA-v1.0, demonstrate that the proposed
SparseFormer significantly improves detection accuracy (up to 5.8%) and speed
(up to 3x) over the state-of-the-art approaches.",http://arxiv.org/abs/2502.07216v1
"DEG: Efficient Hybrid Vector Search Using the Dynamic Edge Navigation
  Graph",2025-02-11T08:10:16Z,"Ziqi Yin, Jianyang Gao, Pasquale Balsebre, Gao Cong, Cheng Long","Bimodal data, such as image-text pairs, has become increasingly prevalent in
the digital era. The Hybrid Vector Query (HVQ) is an effective approach for
querying such data and has recently garnered considerable attention from
researchers. It calculates similarity scores for objects represented by two
vectors using a weighted sum of each individual vector's similarity, with a
query-specific parameter $\alpha$ to determine the weight. Existing methods for
HVQ typically construct Approximate Nearest Neighbors Search (ANNS) indexes
with a fixed $\alpha$ value. This leads to significant performance degradation
when the query's $\alpha$ dynamically changes based on the different scenarios
and needs.
  In this study, we introduce the Dynamic Edge Navigation Graph (DEG), a
graph-based ANNS index that maintains efficiency and accuracy with changing
$\alpha$ values. It includes three novel components: (1) a greedy Pareto
frontier search algorithm to compute a candidate neighbor set for each node,
which comprises the node's approximate nearest neighbors for all possible
$\alpha$ values; (2) a dynamic edge pruning strategy to determine the final
edges from the candidate set and assign each edge an active range. This active
range enables the dynamic use of the Relative Neighborhood Graph's pruning
strategy based on the query's $\alpha$ values, skipping redundant edges at
query time and achieving a better accuracy-efficiency trade-off; and (3) an
edge seed method that accelerates the querying process. Extensive experiments
on real-world datasets show that DEG demonstrates superior performance compared
to existing methods under varying $\alpha$ values.",http://arxiv.org/abs/2502.07343v1
HGTUL: A Hypergraph-based Model For Trajectory User Linking,2025-02-11T13:39:35Z,"Fengjie Chang, Xinning Zhu, Zheng Hu, Yang Qin","Trajectory User Linking (TUL), which links anonymous trajectories with users
who generate them, plays a crucial role in modeling human mobility. Despite
significant advancements in this field, existing studies primarily neglect the
high-order inter-trajectory relationships, which represent complex associations
among multiple trajectories, manifested through multi-location co-occurrence
patterns emerging when trajectories intersect at various Points of Interest
(POIs). Furthermore, they also overlook the variable influence of POIs on
different trajectories, as well as the user class imbalance problem caused by
disparities in user activity levels and check-in frequencies. To address these
limitations, we propose a novel HyperGraph-based multi-perspective Trajectory
User Linking model (HGTUL). Our model learns trajectory representations from
both relational and spatio-temporal perspectives: (1) it captures high-order
associations among trajectories by constructing a trajectory hypergraph and
leverages a hypergraph attention network to learn the variable impact of POIs
on trajectories; (2) it models the spatio-temporal characteristics of
trajectories by incorporating their temporal and spatial information into a
sequential encoder. Moreover, we design a data balancing method to effectively
address the user class imbalance problem and experimentally validate its
significance in TUL. Extensive experiments on three real-world datasets
demonstrate that HGTUL outperforms state-of-the-art baselines, achieving
improvements of 2.57%~20.09% and 5.68%~26.00% in ACC@1 and Macro-F1 metrics,
respectively.",http://arxiv.org/abs/2502.07549v1
"Genetic evolution of a multi-generational population in the context of
  interstellar space travels -- Part II: Phenotypic effects of gene expression",2025-02-11T13:57:22Z,"Frédéric Marin, Camille Beluffi-Marin, Frédéric Fischer","In the first paper of this series, we included the effects of population
genetics in the agent-based Monte Carlo code HERITAGE under the hypothesis of
neutral phenotypic effects. It implied that mutations (genetic changes) had
only neutral physical manifestations. We now relax this assumption by including
genetic effects of mutation and neo-mutations (from radiations) onto the
population's life expectancy, fertility, pregnancy chances and miscarriage
rates. When applied to a population aboard a generation ship that travels at
sub-light speed towards a distant exoplanet, we demonstrate that natural
selection indirectly affects the genetic structure of a population via the
contribution of phenotypes, in agreement with past studies in conservation
biology. For large starting crews (about 500 individuals), the effect aligns
with the neutral hypothesis and the frequency of alleles (for non-sexual
chromosomes) is stable over centuries. Results are completely different if the
spacecraft shielding, integrated into hull design, fails to efficiently protect
the crew from high-energy cosmic rays and showers of secondary particles. We
tested different scenarios, in which the level of radiation is either fixed at
normal or extreme levels, or changing over time due to, e.g., shield
degradation, on-board nuclear incident or the outburst of a supernova situated
50 light-years away.",http://arxiv.org/abs/2502.07559v1
Pre-Trained Video Generative Models as World Simulators,2025-02-10T14:49:09Z,"Haoran He, Yang Zhang, Liang Lin, Zhongwen Xu, Ling Pan","Video generative models pre-trained on large-scale internet datasets have
achieved remarkable success, excelling at producing realistic synthetic videos.
However, they often generate clips based on static prompts (e.g., text or
images), limiting their ability to model interactive and dynamic scenarios. In
this paper, we propose Dynamic World Simulation (DWS), a novel approach to
transform pre-trained video generative models into controllable world
simulators capable of executing specified action trajectories. To achieve
precise alignment between conditioned actions and generated visual changes, we
introduce a lightweight, universal action-conditioned module that seamlessly
integrates into any existing model. Instead of focusing on complex visual
details, we demonstrate that consistent dynamic transition modeling is the key
to building powerful world simulators. Building upon this insight, we further
introduce a motion-reinforced loss that enhances action controllability by
compelling the model to capture dynamic changes more effectively. Experiments
demonstrate that DWS can be versatilely applied to both diffusion and
autoregressive transformer models, achieving significant improvements in
generating action-controllable, dynamically consistent videos across games and
robotics domains. Moreover, to facilitate the applications of the learned world
simulator in downstream tasks such as model-based reinforcement learning, we
propose prioritized imagination to improve sample efficiency, demonstrating
competitive performance compared with state-of-the-art methods.",http://arxiv.org/abs/2502.07825v1
"Artificial and Eddy Viscosity in Large Eddy Simulation Part 2:
  Turbulence Models",2025-02-12T07:08:40Z,"Jing Sun, Roel Verstappen","This is the second part to our companion paper. The novel method to quantify
artificial dissipation proposed in Part 1 is further applied in turbulent
channel flow at $\mathrm{Re_\tau}=180$ using various subgrid-scale models, with
an emphasis on minimum-dissipation models (QR and AMD). We found that the
amount of artificial viscosity is comparable to the eddy viscosity, but their
distributions are essentially opposite. The artificial viscosity can either
produce turbulent kinetic energy (TKE) in the near wall region or dissipate TKE
in the bulk region. The eddy viscosity is almost uniformly distributed across
the wall-normal direction and actively damps TKE at the channel center. An eddy
viscosity level of $\nu_e/\nu < 22\%$ leads to accurate predictions of flow
quantities at the current mesh resolution. The optimal coefficients for the QR
model combined with symmetry-preserving discretization were found to be C=0.092
for turbulent kinetic energy and C=0.012 for Reynolds stress terms and large
scale motions. Adjusting the QR model coefficient changes the artificial
viscosity and significantly impact turbulence characteristics: small-scale
motions remain unaffected, while larger scales are less accurately captured
with larger coefficients. For error quantification, the SGS activity parameter
$\nu_{rel} = \frac{\nu_e}{\nu_e + \nu}$ helps relate and reflect the error
magnitude with the SGS model. Optimal coefficients for the AMD model were also
identified. The trends of varying the coefficient are similar to the QR model
but differ in the amplitude of changes. The AMD model is more sensitive to the
model coefficients and introduces more eddy viscosity in the near-wall region
compared to the QR model. This research highlights the importance of balancing
numerical and eddy viscosities for accurate LES predictions.",http://arxiv.org/abs/2502.08165v1
"Rhythmic sharing: A bio-inspired paradigm for zero-shot adaptation and
  learning in neural networks",2025-02-12T18:58:34Z,"Hoony Kang, Wolfgang Losert","The brain can rapidly adapt to new contexts and learn from limited data, a
coveted characteristic that artificial intelligence algorithms have struggled
to mimic. Inspired by oscillatory rhythms of the mechanical structures of
neural cells, we developed a learning paradigm that is based on oscillations in
link strengths and associates learning with the coordination of these
oscillations. We find that this paradigm yields rapid adaptation and learning
in artificial neural networks. Link oscillations can rapidly change
coordination, endowing the network with the ability to sense subtle context
changes in an unsupervised manner. In other words, the network generates the
missing contextual tokens required to perform as a generalist AI architecture
capable of predicting dynamics in multiple contexts. Oscillations also allow
the network to extrapolate dynamics to never-seen-before contexts. These
capabilities make our learning paradigm a powerful starting point for novel
models of learning and cognition. Furthermore, learning through link
coordination is agnostic to the specifics of the neural network architecture,
hence our study opens the door for introducing rapid adaptation and learning
capabilities into leading AI models.",http://arxiv.org/abs/2502.08644v3
A unified model of feed rotation in radio telescopes and GNSS antennas,2025-02-12T20:08:34Z,"Joe Skeens, Johnathan York, Leonid Petrov, Kyle Herrity, Richard Ji-Cathriner, Srinivas Bettadpur","We describe a model that accounts for the phase rotation that occurs when a
receiver or transmitter changes orientation while observing or emitting
circularly polarized electromagnetic waves. This model extends work detailing
Global Navigation Satellite Systems (GNSS) carrier phase wind-up to allow us to
describe the interaction of changing satellite orientation with phase rotation
in observing radio telescopes. This development is motivated by, and a critical
requirement of, unifying GNSS and Very Long Baseline Interferometry (VLBI)
measurements at the observation level. The model can be used for either
stationary choke ring antennas or steerable radio telescopes observing either
natural radio sources or satellites. Simulations and experimental data are used
to validate the model and to illustrate its importance. In addition, we
rigorously lay out the feed rotation correction for radio telescopes with beam
waveguide and full Nasmyth focuses and validate the correction by observing the
effect with dual polarization observations. Using this feed rotation model for
beam waveguide telescopes, we produce the first phase delay solution for the
VLBI baseline WARK30M-WARK12M. We provide a practical guide to using the feed
rotation model in Appendix D.",http://arxiv.org/abs/2502.08761v1
Modified Hadronic Interactions and the future of UHECR observations,2025-02-12T21:21:20Z,"Jan Ebr, Jiří Blažek, Jakub Vícha, Tanguy Pierog, Eva Santos, Petr Trávníček, Nikolas Denner, Ralf Ulrich","Data from multiple experiments suggest that the current interaction models
used in Monte Carlo simulations do not correctly reproduce the hadronic
interactions in air showers produced by ultra-high-energy cosmic rays (UHECR).
We have created a large library of UHECR simulations where the interactions at
the highest energies are slightly modified in various ways - but always within
the constraints of the accelerator data, without any abrupt changes with energy
and without assuming any specific mechanism or dramatically new physics at the
ultra-high energies. Recent results of the Pierre Auger Observatory indicate a
need for a change in the prediction of the models for both the muon content at
ground and the depth of the maximum of longitudinal development of the shower.
In our parameter space, we find combinations of modifications that are in
agreement with this analysis, however a consistent description of UHECR showers
remains elusive. Our library however provides a realistic representation of the
freedom in the modeling of the hadronic interactions and offers an opportunity
to quantify uncertainties of various predictions. This can be particularly
valuable for the design of future observatories where hadronic models are often
used as input for the prediction of the performance. We demonstrate this
powerful capability on several selected examples.",http://arxiv.org/abs/2502.08798v1
"Efficient and Trustworthy Block Propagation for Blockchain-enabled
  Mobile Embodied AI Networks: A Graph Resfusion Approach",2025-01-26T07:47:05Z,"Jiawen Kang, Jiana Liao, Runquan Gao, Jinbo Wen, Huawei Huang, Maomao Zhang, Changyan Yi, Tao Zhang, Dusit Niyato, Zibin Zheng","By synergistically integrating mobile networks and embodied artificial
intelligence (AI), Mobile Embodied AI Networks (MEANETs) represent an advanced
paradigm that facilitates autonomous, context-aware, and interactive behaviors
within dynamic environments. Nevertheless, the rapid development of MEANETs is
accompanied by challenges in trustworthiness and operational efficiency.
Fortunately, blockchain technology, with its decentralized and immutable
characteristics, offers promising solutions for MEANETs. However, existing
block propagation mechanisms suffer from challenges such as low propagation
efficiency and weak security for block propagation, which results in delayed
transmission of vehicular messages or vulnerability to malicious tampering,
potentially causing severe traffic accidents in blockchain-enabled MEANETs.
Moreover, current block propagation strategies cannot effectively adapt to
real-time changes of dynamic topology in MEANETs. Therefore, in this paper, we
propose a graph Resfusion model-based trustworthy block propagation
optimization framework for consortium blockchain-enabled MEANETs. Specifically,
we propose an innovative trust calculation mechanism based on the trust cloud
model, which comprehensively accounts for randomness and fuzziness in the miner
trust evaluation. Furthermore, by leveraging the strengths of graph neural
networks and diffusion models, we develop a graph Resfusion model to
effectively and adaptively generate the optimal block propagation trajectory.
Simulation results demonstrate that the proposed model outperforms other
routing mechanisms in terms of block propagation efficiency and
trustworthiness. Additionally, the results highlight its strong adaptability to
dynamic environments, making it particularly suitable for rapidly changing
MEANETs.",http://arxiv.org/abs/2502.09624v1
"On the Bias, Fairness, and Bias Mitigation for a Wearable-based Freezing
  of Gait Detection in Parkinson's Disease",2025-01-29T18:43:01Z,"Timothy Odonga, Christine D. Esper, Stewart A. Factor, J. Lucas McKay, Hyeokhyen Kwon","Freezing of gait (FOG) is a debilitating feature of Parkinson's disease (PD),
which is a cause of injurious falls among PD patients. Recent advances in
wearable-based human activity recognition (HAR) technology have enabled the
detection of FOG subtypes across benchmark datasets. Since FOG manifestation is
heterogeneous, developing models that quantify FOG consistently across patients
with varying demographics, FOG types, and PD conditions is important. Bias and
fairness in FOG models remain understudied in HAR, with research focused mainly
on FOG detection using single benchmark datasets. We evaluated the bias and
fairness of HAR models for wearable-based FOG detection across demographics and
PD conditions using multiple datasets and the effectiveness of transfer
learning as a potential bias mitigation approach. Our evaluation using
demographic parity ratio (DPR) and equalized odds ratio (EOR) showed model bias
(DPR & EOR < 0.8) for all stratified demographic variables, including age, sex,
and disease duration. Our experiments demonstrated that transfer learning from
multi-site datasets and generic human activity representations significantly
improved fairness (average change in DPR +0.027, +0.039, respectively) and
performance (average change in F1-score +0.026, +0.018, respectively) across
attributes, supporting the hypothesis that generic human activity
representations learn fairer representations applicable to health analytics.",http://arxiv.org/abs/2502.09626v1
"A Discontinuous Galerkin Method for Simulating 3D Seismic Wave
  Propagation in Nonlinear Rock Models: Verification and Application to the
  2015 Mw 7.8 Gorkha Earthquake",2025-02-13T19:02:26Z,"Zihua Niu, Alice-Agnes Gabriel, Sebastian Wolf, Thomas Ulrich, Vladimir Lyakhovsky, Heiner Igel","The nonlinear mechanical responses of rocks and soils to seismic waves play
an important role in earthquake physics, influencing ground motion from source
to site. Continuous geophysical monitoring, such as ambient noise
interferometry, has revealed co-seismic wave speed reductions extending tens of
kilometers from earthquake sources. However, the mechanisms governing these
changes remain challenging to model, especially at regional scales. Using a
nonlinear damage model constrained by laboratory experiments, we develop and
apply an open-source 3D discontinuous Galerkin method to simulate regional
co-seismic wave speed changes during the 2015 Mw7.8 Gorkha earthquake. We find
pronounced spatial variations of co-seismic wave speed reduction, ranging from
<0.01% to >50%, particularly close to the source and within the Kathmandu
Basin. The most significant reduction occurs within the sedimentary basin and
varies with basin depths, while wave speed reductions correlate with the fault
slip distribution near the source. By comparing ground motions from simulations
with elastic, viscoelastic, elastoplastic, and nonlinear damage rheologies, we
demonstrate that the nonlinear damage model effectively captures low-frequency
ground motion amplification due to strain-dependent wave speed reductions in
soft sediments. We verify the accuracy of our approach through comparisons with
analytical solutions and assess its scalability on high-performance computing
systems. The model shows near-linear strong and weak scaling up to 2048 nodes,
enabling efficient large-scale simulations. Our findings provide a
physics-based framework to quantify nonlinear earthquake effects and emphasize
the importance of damage-induced wave speed variations for seismic hazard
assessment and ground motion predictions.",http://arxiv.org/abs/2502.09714v1
"Efficient Evaluation of Multi-Task Robot Policies With Active Experiment
  Selection",2025-02-14T00:07:02Z,"Abrar Anwar, Rohan Gupta, Zain Merchant, Sayan Ghosh, Willie Neiswanger, Jesse Thomason","Evaluating learned robot control policies to determine their physical
task-level capabilities costs experimenter time and effort. The growing number
of policies and tasks exacerbates this issue. It is impractical to test every
policy on every task multiple times; each trial requires a manual environment
reset, and each task change involves re-arranging objects or even changing
robots. Naively selecting a random subset of tasks and policies to evaluate is
a high-cost solution with unreliable, incomplete results. In this work, we
formulate robot evaluation as an active testing problem. We propose to model
the distribution of robot performance across all tasks and policies as we
sequentially execute experiments. Tasks often share similarities that can
reveal potential relationships in policy behavior, and we show that natural
language is a useful prior in modeling these relationships between tasks. We
then leverage this formulation to reduce the experimenter effort by using a
cost-aware expected information gain heuristic to efficiently select
informative trials. Our framework accommodates both continuous and discrete
performance outcomes. We conduct experiments on existing evaluation data from
real robots and simulations. By prioritizing informative trials, our framework
reduces the cost of calculating evaluation metrics for robot policies across
many tasks.",http://arxiv.org/abs/2502.09829v1
"Strain energy enhanced room-temperature magnetocaloric effect in
  second-order magnetic transition materials",2025-02-14T01:40:54Z,"Xiaohe Liu, Ping Song, Sen Yao, Yuhao Lei, Ling Yang, Shenxiang Du, Yiran Deng, Defeng Guo","Large magnetic entropy change (deltaSM) can realize a prominent heat
transformation under the magnetic field and directly strengthen the efficacy of
the magnetocaloric effect, which provides a pioneering environmentally friendly
solid-state strategy to improve refrigeration capacities and efficiencies. The
second-order magnetic transition (SOMT) materials have broader deltaSM peaks
without thermal hysteresis compared with most first-order magnetic transition
materials, making them highly attractive in magnetic refrigeration, especially
in the room temperature range. Here, we report a significant enhancement of
deltaSM at room temperature in single-crystal Mn5Ge3. In this SOMT system, we
realize a 60% improvement of -deltaSM from 3.5 J/kgK to 5.6 J/kgK at T = 300K.
This considerable enhancement of deltaSM is achieved by intentionally
introducing strain energy through high-pressure constrained deformation. Both
experimental results and Monte Carlo simulations demonstrate that the
enhancement of deltaSM originates from the microscopic strain and lattice
deformation induced by strain energy after deformation. This strain energy will
reconstruct the energy landscape of this ferromagnetic system and enhance
magnetization, resulting in a giant intensity of magnetocaloric responses. Our
findings provide an approach to increase magnetic entropy change and may give
fresh ideas for exploring advanced magnetocaloric materials.",http://arxiv.org/abs/2502.09856v1
On Self-Propulsion by Oscillations in a Viscous Liquid,2025-02-14T08:45:06Z,"Giovanni P. Galdi, Boris Muha, Ana Radošević","Suppose that a body $\mathscr B$ can move by translatory motion with velocity
$\boldsymbol{\gamma}$ in an otherwise quiescent Navier-Stokes liquid, $\mathscr
L$, filling the entire space outside $\mathscr B$. Denote by $\Omega =
\Omega(t)$, $t\in\mathbb{R}$, the one-parameter family of bounded, sufficiently
smooth domains of $\mathbb{R}^3$, each one representing the configuration of
$\mathscr B$ at time $t$ with respect to a frame with the origin at the center
of mass $G$ and axes parallel to those of an inertial frame. We assume that
there are no external forces acting on the coupled system $\mathscr S :=
\mathscr B +\mathscr L$ and that the only driving mechanism is a prescribed
change in shape of $\Omega$ with time. The self-propulsion problem that we
would like to address can be thus qualitatively formulated as follows. Suppose
that $\mathscr B$ changes its shape in a given time-periodic fashion, namely,
$\Omega(t+T) = \Omega(t)$, for some $T > 0$ and all $t \in \mathbb{R}$. Then,
find necessary and sufficient conditions on the map $t\mapsto \Omega(t)$
securing that $\mathscr B$ self-propels, that is, $G$ covers any given finite
distance in a finite time. We show that this problem is solvable, in a suitable
function class, provided the amplitude of the oscillations is below a given
constant. Moreover, we provide examples where the propelling velocity of
$\mathscr B$ is explicitly evaluated in terms of the physical parameters and
the frequency of oscillations.",http://arxiv.org/abs/2502.10009v1
"Strain-Induced Optical and Molecular Transformations in PET Films for
  Organic Electronic Applications",2025-02-14T12:21:50Z,"Mahya Ghorab, Ayush K. Ranga, Patrice Donfack, Arnulf Materny, Veit Wagner, Mojtaba Joodaki","Poly(ethylene terephthalate) (PET) films are widely used in flexible
electronics and optoelectronics, where their mechanical durability and optical
performance under strain are essential for device reliability. This study
investigates the impact of applied mechanical strain on the optical and
molecular properties of PET at room temperature,using UV-Vis absorption and
Raman spectroscopy. The work explores how varying strain levels, from 0%
(unstretched) to 30%, affect the transparency, vibrational modes, and molecular
reorganization within PET films. UV-Vis absorbance measurements reveal that
strain induces significant changes in the light transmission properties of PET,
particularly in the visible range, and increases absorption in the UVA and
visible region by up to 100%. Raman spectra indicate that strain levels higher
than 5% lead to irreversible shifts of vibrational lines, accompanied by an
increase of their full width at half maximum (FWHM), suggesting molecular
reorientation and crystallinity changes. The phonon mode coupled with C-O
stretching [O-CH2] shows the strongest response to applied mechanical stress.
This study provides a comprehensive understanding of strain-induced optical and
structural alterations in PET, with implications for improving the mechanical
and optical performance of PET-based devices in strainsensitive applications,
such as organic solar cells (OSCs), organic light-emitting diodes (OLEDs), and
flexible sensors.",http://arxiv.org/abs/2502.10113v1
"Modeling biases in binary decision-making within the generalized
  nonlinear q-voter model",2025-02-14T13:57:42Z,"Maciej Doniec, Pratik Mullick, Parongama Sen, Katarzyna Sznajd-Weron","Binary decision frameworks are widely used in the social sciences, including
management and economics, to understand collective behavior. In group
decision-making, opinions evolve through social influence, shaping outcomes
that lead to either consensus or polarization. The $q$ voter model, also known
as the non-linear voter model, has been extensively studied in this context.
However, the impact of an individual's current opinion on their future stance
has been largely overlooked. To fill this gap, we introduce a generalized model
in which an agent's opinion depends not only on its neighbors but also on its
own state. As in the original $q$-voter model, a unanimous influence group of
size $q$ causes the agent to adopt the group's opinion. However, if the group
is not unanimous, the agent will change its opinion with a probability
influenced by its current state. This introduces a bias toward a choice that
reflects external factors such as politics or advertising. Our model
generalizes previous $q$-voter models, including the original one, while
allowing for a wider range of scenarios. We analyze the model on a complete
graph, deriving the phase diagram and the exit probability for finite systems.
We support our analytical approach with Monte Carlo simulations and show that
they overlap even for small systems of size $N=64$. Our results show that the
exit probability depends on $q$. For $q \geq 3$, the exit probability exhibits
a shape that was not observed in previous models, which implies that increasing
initial support for a decision does not necessarily change the final collective
outcome.",http://arxiv.org/abs/2502.10172v1
"Analysis of Stable Vertex Values: Fast Query Evaluation Over An Evolving
  Graph",2025-02-14T22:15:26Z,"Mahbod Afarin, Chao Gao, Xizhe Yin, Zhijia Zhao, Nael Abu-Ghazaleh, Rajiv Gupta","Evaluating a query over a large, irregular graph is inherently challenging.
This challenge intensifies when solving a query over a sequence of snapshots of
an evolving graph, where changes occur through the addition and deletion of
edges. We carried out a study that shows that due to the gradually changing
nature of evolving graphs, when a vertex-specific query (e.g., SSSP) is
evaluated over a sequence of 25 to 100 snapshots, for 53.2% to 99.8% of
vertices, the query results remain unchanged across all snapshots. Therefore,
the Unchanged Vertex Values (UVVs) can be computed once and then minimal
analysis can be performed for each snapshot to obtain the results for the
remaining vertices in that snapshot. We develop a novel intersection-union
analysis that very accurately computes lower and upper bounds of vertex values
across all snapshots. When the lower and upper bounds for a vertex are found to
be equal, we can safely conclude that the value found for the vertex remains
the same across all snapshots. Therefore, the rest of our query evaluation is
limited to computing values across snapshots for vertices whose bounds do not
match. We optimize this latter step evaluation by concurrently performing
incremental computations on all snapshots over a significantly smaller
subgraph. Our experiments with several benchmarks and graphs show that we need
to carry out per snapshot incremental analysis for under 42% vertices on a
graph with under 32% of edges. Our approach delivers speedups of 2.01-12.23x
when compared to the state-of-the-art RisGraph implementation of the
KickStarter-based incremental algorithm for 64 snapshots.",http://arxiv.org/abs/2502.10579v1
"Correlative and in situ microscopy investigation of phase
  transformation, crystal growth and degradation of antimony sulfide thin films",2025-02-16T19:53:53Z,"Mingjian Wu, Maïssa K. S. Barr, Vanessa M. Koch, Martin Dierner, Tobias Dierke, Penghan Lu, Johannes Will, Rafal Dunin-Borkowski, Janina Maultzsch, Julien Bachmann, Erdmann Spiecker","Antimony sulfide (Sb$_2$S$_3$), a compound of earth-abundant elements with
highly anisotropic, quasi-layered crystal structure, triggered growing interest
as a solar absorber in photovoltaics and as a phase change material in memory
devices, yet challenges remain in achieving high-quality thin films with
controlled nucleation and growth for optimal performance. Here, we investigate
the phase transformation, crystal structure and properties, growth and
degradation of atomic layer deposited Sb$_2$S$_3$ thin films using in situ TEM
and correlative ex situ analysis. The as-deposited amorphous films crystallized
at 243{\deg}C, forming grains with an [100] out-of-plane texture and developed
into tens to hundreds of micrometer, leaves-shaped grains. Introducing an
ultra-thin ZnS interfacial layer increased nucleation density, and resulted in
a few micrometer-sized, more uniform grains while retaining the overall [100]
texture. In situ observations and subsequent crystal orientation analysis with
cutting-edge 4D-STEM and EBSD revealed that the grains grew faster along the
[010] ribbon direction and that the bare films underwent early-stage
degradation, forming holes in amorphous regions during annealing. The ZnS
interlayer mitigated degradation, stabilizing the films and improving their
uniformity. These findings offer valuable insights for optimizing Sb$_2$S$_3$
thin films for applications both as solar cell materials and phase change
materials.",http://arxiv.org/abs/2502.11247v2
Non-Uniform Memory Sampling in Experience Replay,2025-02-16T23:04:16Z,Andrii Krutsylo,"Continual learning is the process of training machine learning models on a
sequence of tasks where data distributions change over time. A well-known
obstacle in this setting is catastrophic forgetting, a phenomenon in which a
model drastically loses performance on previously learned tasks when learning
new ones. A popular strategy to alleviate this problem is experience replay, in
which a subset of old samples is stored in a memory buffer and replayed with
new data. Despite continual learning advances focusing on which examples to
store and how to incorporate them into the training loss, most approaches
assume that sampling from this buffer is uniform by default.
  We challenge the assumption that uniform sampling is necessarily optimal. We
conduct an experiment in which the memory buffer updates the same way in every
trial, but the replay probability of each stored sample changes between trials
based on different random weight distributions. Specifically, we generate 50
different non-uniform sampling probability weights for each trial and compare
their final accuracy to the uniform sampling baseline. We find that there is
always at least one distribution that significantly outperforms the baseline
across multiple buffer sizes, models, and datasets. These results suggest that
more principled adaptive replay policies could yield further gains. We discuss
how exploiting this insight could inspire new research on non-uniform memory
sampling in continual learning to better mitigate catastrophic forgetting.
  The code supporting this study is available at
$\href{https://github.com/DentonJC/memory-sampling}{https://github.com/DentonJC/memory-sampling}$.",http://arxiv.org/abs/2502.11305v1
"Mimicking the Familiar: Dynamic Command Generation for Information Theft
  Attacks in LLM Tool-Learning System",2025-02-17T02:15:46Z,"Ziyou Jiang, Mingyang Li, Guowei Yang, Junjie Wang, Yuekai Huang, Zhiyuan Chang, Qing Wang","Information theft attacks pose a significant risk to Large Language Model
(LLM) tool-learning systems. Adversaries can inject malicious commands through
compromised tools, manipulating LLMs to send sensitive information to these
tools, which leads to potential privacy breaches. However, existing attack
approaches are black-box oriented and rely on static commands that cannot adapt
flexibly to the changes in user queries and the invocation chain of tools. It
makes malicious commands more likely to be detected by LLM and leads to attack
failure. In this paper, we propose AutoCMD, a dynamic attack comment generation
approach for information theft attacks in LLM tool-learning systems. Inspired
by the concept of mimicking the familiar, AutoCMD is capable of inferring the
information utilized by upstream tools in the toolchain through learning on
open-source systems and reinforcement with target system examples, thereby
generating more targeted commands for information theft. The evaluation results
show that AutoCMD outperforms the baselines with +13.2% $ASR_{Theft}$, and can
be generalized to new tool-learning systems to expose their information leakage
risks. We also design four defense methods to effectively protect tool-learning
systems from the attack.",http://arxiv.org/abs/2502.11358v1
Interference patterns for simple lens models in wave-optics regime,2025-02-17T06:45:02Z,Ashish Kumar Meena,"This work studies interference patterns created by simple lens models (point
mass, Chang-Refsdal, and binary lens) in the wave optics regime, primarily in
the context of lensing of gravitational waves (GWs) in the LIGO band at
frequencies around 100 Hz. We study how the interference patterns behave close
to the caustic curves which mark the high magnification regions in conventional
geometric optics. In addition, we also look at the formation of highly
de-amplified regions in the amplification maps close to caustics and how they
differ under wave and geometric optics. We see that for a source close to
caustics, the oscillations in the amplification factor (their amplitude and
location of crests and troughs) can differ significantly in wave optics
compared to geometric optics. As we move away from caustics, the wave optics
amplification factor starts to converge towards geometric optics one,
especially the frequencies at which crests and through occur in the
amplification factor, although the amplitude of these oscillations can still be
considerably different. For Chang-Refsdal and binary lens with ${\sim}100\:{\rm
M_\odot}-200\:{\rm M_\odot}$ can introduce significant de-amplification at
frequencies ${\sim}100$ Hz when the source is close to caustics which may help
us distinguish such lenses from the point mass lens.",http://arxiv.org/abs/2502.11488v1
"Towards Understanding Fine-Tuning Mechanisms of LLMs via Circuit
  Analysis",2025-02-17T13:59:41Z,"Xu Wang, Yan Hu, Wenyu Du, Reynold Cheng, Benyou Wang, Difan Zou","Fine-tuning significantly improves the performance of Large Language Models
(LLMs), yet its underlying mechanisms remain poorly understood. This paper aims
to provide an in-depth interpretation of the fine-tuning process through
circuit analysis, a popular tool in Mechanistic Interpretability (MI). Unlike
previous studies
\cite{prakash2024finetuningenhancesexistingmechanisms,chhabra2024neuroplasticity}
that focus on tasks where pre-trained models already perform well, we develop a
set of mathematical tasks where fine-tuning yields substantial performance
gains, which are closer to the practical setting. In our experiments, we
identify circuits at various checkpoints during fine-tuning and examine the
interplay between circuit analysis, fine-tuning methods, and task complexities.
First, we find that while circuits maintain high node similarity before and
after fine-tuning, their edges undergo significant changes, which is in
contrast to the previous work
\cite{prakash2024finetuningenhancesexistingmechanisms,chhabra2024neuroplasticity}
that show circuits only add some additional components after fine-tuning. Based
on these observations, we develop a circuit-aware Low-Rank Adaptation (LoRA)
method, which assigns ranks to layers based on edge changes in the circuits.
Experimental results demonstrate that our circuit-based LoRA algorithm achieves
an average performance improvement of 2.46\% over standard LoRA with similar
parameter sizes. Furthermore, we explore how combining circuits from subtasks
can enhance fine-tuning in compositional tasks, providing new insights into the
design of such tasks and deepening the understanding of circuit dynamics and
fine-tuning mechanisms.",http://arxiv.org/abs/2502.11812v1
Gaseous Object Detection,2025-02-18T01:26:07Z,"Kailai Zhou, Yibo Wang, Tao Lv, Qiu Shen, Xun Cao","Object detection, a fundamental and challenging problem in computer vision,
has experienced rapid development due to the effectiveness of deep learning.
The current objects to be detected are mostly rigid solid substances with
apparent and distinct visual characteristics. In this paper, we endeavor on a
scarcely explored task named Gaseous Object Detection (GOD), which is
undertaken to explore whether the object detection techniques can be extended
from solid substances to gaseous substances. Nevertheless, the gas exhibits
significantly different visual characteristics: 1) saliency deficiency, 2)
arbitrary and ever-changing shapes, 3) lack of distinct boundaries. To
facilitate the study on this challenging task, we construct a GOD-Video dataset
comprising 600 videos (141,017 frames) that cover various attributes with
multiple types of gases. A comprehensive benchmark is established based on this
dataset, allowing for a rigorous evaluation of frame-level and video-level
detectors. Deduced from the Gaussian dispersion model, the physics-inspired
Voxel Shift Field (VSF) is designed to model geometric irregularities and
ever-changing shapes in potential 3D space. By integrating VSF into Faster
RCNN, the VSF RCNN serves as a simple but strong baseline for gaseous object
detection. Our work aims to attract further research into this valuable albeit
challenging area.",http://arxiv.org/abs/2502.12415v1
"Disentangling Long-Short Term State Under Unknown Interventions for
  Online Time Series Forecasting",2025-02-18T07:31:04Z,"Ruichu Cai, Haiqin Huang, Zhifang Jiang, Zijian Li, Changze Zhou, Yuequn Liu, Yuming Liu, Zhifeng Hao","Current methods for time series forecasting struggle in the online scenario,
since it is difficult to preserve long-term dependency while adapting
short-term changes when data are arriving sequentially. Although some recent
methods solve this problem by controlling the updates of latent states, they
cannot disentangle the long/short-term states, leading to the inability to
effectively adapt to nonstationary. To tackle this challenge, we propose a
general framework to disentangle long/short-term states for online time series
forecasting. Our idea is inspired by the observations where short-term changes
can be led by unknown interventions like abrupt policies in the stock market.
Based on this insight, we formalize a data generation process with unknown
interventions on short-term states. Under mild assumptions, we further leverage
the independence of short-term states led by unknown interventions to establish
the identification theory to achieve the disentanglement of long/short-term
states. Built on this theory, we develop a long short-term disentanglement
model (LSTD) to extract the long/short-term states with long/short-term
encoders, respectively. Furthermore, the LSTD model incorporates a smooth
constraint to preserve the long-term dependencies and an interrupted dependency
constraint to enforce the forgetting of short-term dependencies, together
boosting the disentanglement of long/short-term states. Experimental results on
several benchmark datasets show that our \textbf{LSTD} model outperforms
existing methods for online time series forecasting, validating its efficacy in
real-world applications.",http://arxiv.org/abs/2502.12603v1
"Study of amorphous alumina coatings for next-generation nuclear
  reactors: hightemperature in-situ and post-mortem Raman spectroscopy and
  X-ray diffraction",2025-02-18T07:50:17Z,"Magdalena Gaweda, Piotr Jelen, Agata Zaborowska, Ryszard Diduszko, Lukasz Kurpaska","The present work focuses on the investigation of the thermal stability and
structural integrity of amorphous alumina coatings intended for use as
protective coatings on cladding tubes in Generation IV nuclear reactors,
specifically in the Lead-cooled Fast Reactor (LFR) type. Hightemperature Raman
spectroscopy and high-temperature X-ray diffraction analyses were carried out
up to 1050 C on a 5 um coating deposited by the pulsed laser deposition (PLD)
technique on a 316L steel substrate. The experiments involved the in-situ
examination of structural changes in the material under increasing temperature,
along with ex-situ Raman imaging of the surface and cross-section of the
coating after thermal treatments of different lengths. As it was expected, the
presence of alpha-alumina was detected with the addition of other polymorphs,
gamma- and theta-Al2O3, found in the material after longer high-temperature
exposure. The use of two structural analysis methods and two lasers excitation
wavelengths with Raman spectroscopy allowed us to detect all the mentioned
phases despite different mode activity. Alumina analysis was based on the
emission spectra, while substrate oxidation products were identified through
the structural bands. The experiments depicted a dependence of the phase
composition of oxidation products and alumina's degree of crystallization on
the length of the treatment. Nevertheless, the observed structural changes did
not occur rapidly, and the coating's integrity remained intact. Moreover,
oxidation signs occurred locally at temperatures exceeding the LFR reactor's
working temperature, confirming the material's great potential as a protective
coating in the operational conditions of LFR nuclear reactors.",http://arxiv.org/abs/2502.12612v1
"An improved wind power prediction via a novel wind ramp identification
  algorithm",2025-02-18T12:11:46Z,Yifan Xu,"Authors: Yifan Xu Abstract: Conventional wind power prediction methods often
struggle to provide accurate and reliable predictions in the presence of sudden
changes in wind speed and power output. To address this challenge, this study
proposes an integrated algorithm that combines a wind speed mutation
identification algorithm, an optimized similar period matching algorithm and a
wind power prediction algorithm. By exploiting the convergence properties of
meteorological events, the method significantly improves the accuracy of wind
power prediction under sudden meteorological changes. Firstly, a novel adaptive
model based on variational mode decomposition, the VMD-IC model, is developed
for identifying and labelling key turning points in the historical wind power
data, representing abrupt meteorological environments. At the same time, this
paper proposes Ramp Factor (RF) indicators and wind speed similarity
coefficient to optimize the definition algorithm of the current wind power ramp
event (WPRE). After innovating the definition of climbing and denoising
algorithm, this paper uses the Informer deep learning algorithm to output the
first two models as well as multimodal data such as NWP numerical weather
forecasts to achieve accurate wind forecasts. The experimental results of the
ablation study confirm the effectiveness and reliability of the proposed wind
slope identification method. Compared with existing methods, the proposed model
exhibits excellent performance and provides valuable guidance for the safe and
cost-effective operation of power systems.",http://arxiv.org/abs/2502.12807v1
Semi-supervised classification of bird vocalizations,2025-02-19T05:31:13Z,"Simen Hexeberg, Mandar Chitre, Matthias Hoffmann-Kuhnt, Bing Wen Low","Changes in bird populations can indicate broader changes in ecosystems,
making birds one of the most important animal groups to monitor. Combining
machine learning and passive acoustics enables continuous monitoring over
extended periods without direct human involvement. However, most existing
techniques require extensive expert-labeled datasets for training and cannot
easily detect time-overlapping calls in busy soundscapes. We propose a
semi-supervised acoustic bird detector designed to allow both the detection of
time-overlapping calls (when separated in frequency) and the use of few labeled
training samples. The classifier is trained and evaluated on a combination of
community-recorded open-source data and long-duration soundscape recordings
from Singapore. It achieves a mean F0.5 score of 0.701 across 315 classes from
110 bird species on a hold-out test set, with an average of 11 labeled training
samples per class. It outperforms the state-of-the-art BirdNET classifier on a
test set of 103 bird species despite significantly fewer labeled training
samples. The detector is further tested on 144 microphone-hours of continuous
soundscape data. The rich soundscape in Singapore makes suppression of false
positives a challenge on raw, continuous data streams. Nevertheless, we
demonstrate that achieving high precision in such environments with minimal
labeled training data is possible.",http://arxiv.org/abs/2502.13440v1
"Distal Causal Excursion Effects: Modeling Long-Term Effects of
  Time-Varying Treatments in Micro-Randomized Trials",2025-02-19T07:36:54Z,Tianchen Qian,"Micro-randomized trials (MRTs) play a crucial role in optimizing digital
interventions. In an MRT, each participant is sequentially randomized among
treatment options hundreds of times. While the interventions tested in MRTs
target short-term behavioral responses (proximal outcomes), their ultimate goal
is to drive long-term behavior change (distal outcomes). However, existing
causal inference methods, such as the causal excursion effect, are limited to
proximal outcomes, making it challenging to quantify the long-term impact of
interventions. To address this gap, we introduce the distal causal excursion
effect (DCEE), a novel estimand that quantifies the long-term effect of
time-varying treatments. The DCEE contrasts distal outcomes under two excursion
policies while marginalizing over most treatment assignments, enabling a
parsimonious and interpretable causal model even with a large number of
decision points. We propose two estimators for the DCEE -- one with
cross-fitting and one without -- both robust to misspecification of the outcome
model. We establish their asymptotic properties and validate their performance
through simulations. We apply our method to the HeartSteps MRT to assess the
impact of activity prompts on long-term habit formation. Our findings suggest
that prompts delivered earlier in the study have a stronger long-term effect
than those delivered later, underscoring the importance of intervention timing
in behavior change. This work provides the critically needed toolkit for
scientists working on digital interventions to assess long-term causal effects
using MRT data.",http://arxiv.org/abs/2502.13500v1
"Transfer-Prompting: Enhancing Cross-Task Adaptation in Large Language
  Models via Dual-Stage Prompts Optimization",2025-02-20T02:47:04Z,"Yupeng Chang, Yi Chang, Yuan Wu","Large language models (LLMs) face significant challenges when balancing
multiple high-level objectives, such as generating coherent, relevant, and
high-quality responses while maintaining efficient task adaptation across
diverse tasks. To address these challenges, we introduce Transfer-Prompting, a
novel two-stage framework designed to enhance cross-task adaptation in prompt
generation. The framework comprises two key components: (1) source prompt
construction, which refines the original prompts on source task datasets to
generate source prompts with enhanced generalization ability, and (2) target
prompt generation, which enhances cross-task adaptation of target prompts by
fine-tuning a set of high-scored source prompts on task-specific datasets. In
each optimization cycle, a reference LLM generates candidate prompts based on
historical prompt-score pairs and task descriptions in our designed reference
prompt. These candidate prompts are refined iteratively, while a scorer LLM
evaluates their effectiveness using the multi-dimensional metrics designed in
the objective prompts evaluator-a novel contribution in this work that provides
a holistic evaluation of prompt quality and task performance. This feedback
loop facilitates continuous refinement, optimizing both prompt quality and
task-specific outcomes. We validate Transfer-Prompting through extensive
experiments across 25 LLMs, including 7 foundational models and 18 specialized
models, evaluated on 9 diverse datasets. The results demonstrate that
Transfer-Prompting significantly improves task-specific performance,
highlighting its potential for enhancing cross-task adaptation in LLMs. The
code is available at https://github.com/llm172/Transfer-Prompting.",http://arxiv.org/abs/2502.14211v1
"Multi-Layer Deep xVA: Structural Credit Models, Measure Changes and
  Convergence Analysis",2025-02-20T17:41:55Z,"Kristoffer Andersson, Alessandro Gnoatto","We propose a structural default model for portfolio-wide valuation
adjustments (xVAs) and represent it as a system of coupled backward stochastic
differential equations. The framework is divided into four layers, each
capturing a key component: (i) clean values, (ii) initial margin and Collateral
Valuation Adjustment (ColVA), (iii) Credit/Debit Valuation Adjustments
(CVA/DVA) together with Margin Valuation Adjustment (MVA), and (iv) Funding
Valuation Adjustment (FVA). Because these layers depend on one another through
collateral and default effects, a naive Monte Carlo approach would require
deeply nested simulations, making the problem computationally intractable.
  To address this challenge, we use an iterative deep BSDE approach, handling
each layer sequentially so that earlier outputs serve as inputs to the
subsequent layers. Initial margin is computed via deep quantile regression to
reflect margin requirements over the Margin Period of Risk. We also adopt a
change-of-measure method that highlights rare but significant defaults of the
bank or counterparty, ensuring that these events are accurately captured in the
training process.
  We further extend Han and Long's standard a posteriori error analysis
\cite{han2020convergence} to BSDEs on bounded domains by leveraging
\cite{bouchard2009strong}. Due to the random exit from the domain, we obtain an
order of convergence of $\mathcal{O}(h^{1/4-\epsilon})$ rather than the usual
$\mathcal{O}(h^{1/2})$.
  Numerical experiments illustrate that this method drastically reduces
computational demands and successfully scales to high-dimensional,
non-symmetric portfolios. The results confirm its effectiveness and accuracy,
offering a practical alternative to nested Monte Carlo simulations in
multi-counterparty xVA analyses.",http://arxiv.org/abs/2502.14766v1
Metabolic energy expenditure for time-varying isometric forces,2025-01-01T04:56:34Z,"Sriram Sekaripuram Muralidhar, Kristen Heitman, Samuel C. Walcott, Manoj Srinivasan","Muscles consume metabolic energy (ATP) to produce force. A mathematical model
for energy expenditure can be useful in estimating real-time costs of movements
or to predict energy optimal movements. Metabolic cost models developed so far
have predominantly aimed at dynamic movement tasks, where mechanical work
dominates. Further, while it is known that both force magnitude and rate of
change of force (force rate) affect metabolic cost, it is not known how these
terms interact, or if the force rate dependence can be a consequence of the
force dependence. Here, we performed extensive human subject experiments,
involving each subject over 5 hours of metabolic trials, which systematically
changed the mean forces and forces rates so as to characterize a holistic
relation for metabolic cost based on both force and force rate -- or
analogously, torque and torque rate. Our experiments involved humans producing
symmetric or asymmetric sinusoidal forces with different means, amplitudes,
frequencies, and rise and fall periods. We showed that the metabolic cost can
be well-approximated by a sum of power law functions of torque and torque rate.
We found that the metabolic cost scales non-linearly with joint torque (with
exponent = 1.36) and non-linearly with torque rate (with exponent = 2.5).
Surprisingly, the data suggested that the cost was roughly four times higher
for decreasing the torque than increasing, mirroring the analogous ratio
between the cost of positive and negative work. Using these metabolic cost
relations, we show that if the metabolic cost scales with particular exponents
with muscle force and force rates, the same exponents will be observed in
multi-joint tasks with multiple muscles. Our new metabolic cost model involving
both force and force rate will potentially allow better predictions of energy
optimal movements and thus inform wearable robot design and analysis.",http://arxiv.org/abs/2501.00723v1
"Continuation of an Optical Spectroscopic Campaign of Fermi Blazar
  Candidates with TNG: Discovery of a New Changing-Look Blazar",2025-01-07T10:44:33Z,"N. Álvarez Crespo, A. Domínguez, V. S. Paliya, M. Chamorro Cazorla, P. Sánchez Blázquez, A. Gil de Paz","Context. Blazars are a distinct subclass of active galactic nuclei (AGN),
known for their fast variability, high polarization, and intense emission
across the electromagnetic spectrum, from radio waves to gamma rays. Gamma-ray
blazar candidates of uncertain type (BCU) are an ongoing challenge in gamma-ray
astronomy due to difficulties in classification and redshift determination.
Aims. This study continues an optical spectroscopic campaign aimed at
identifying the characteristics of BCUs to improve classification and redshift
estimates, particularly focusing on low-synchrotron-peak sources. Methods. We
conducted a detailed analysis of optical spectroscopic data for a sample of 21
low-synchrotron-peak BCUs plus one bl lac with contradictory results in the
literature, using the 3.58-m Telescopio Nazionale Galileo (TNG, La Palma,
Spain). Results. Our analysis identifies 14 out of the 21 BCUs as flat-spectrum
radio quasars (FSRQs), demonstrating the effectiveness of our selection
criteria. Notably, four FSRQs have redshifts exceeding 1, including 4FGL
J2000.0+4214 at z = 2.04. Six sources are classified as bl lacs, with one of
them, 4FGL J0746.5-0719, showing a featureless spectrum in this work despite
previously exhibiting strong lines, suggesting it may be a changing-look
blazar. One source remains classified as a BCU due to a noisy spectrum.
Additionally, we observed a bl lac object, 4FGL J1054.5+2211, due to
inconsistent redshift estimates in the literature, but we could not confirm any
redshift due to its featureless spectrum. Our findings provide insights into
the classification and redshift estimation of blazar candidates, emphasizing
the need for continued spectroscopic monitoring.",http://arxiv.org/abs/2501.03693v1
"Bit reset protocols that obey activity-constrained speed limits do not
  minimize work for a given speed",2025-01-08T11:40:53Z,"Daan Mulder, Thomas E. Ouldridge, Pieter Rein ten Wolde","The goal of thermodynamic optimal control theory is to find protocols to
change the state of a system from an initial to a desired final distribution,
within a finite time, with the least possible expenditure of work. The optimal
protocol is closely linked to the intrinsic dynamics of the system at hand. The
fact that these dynamics can vary widely has made a general solution elusive.
Recent years have seen great progress by recasting the question in terms of a
quantity called total activity, i.e. the average number of jumps between states
of the system, rather than the time that the operation is allowed to take. This
perspective has allowed for general expressions for the minimal work as a
function of the total activity, and the minimal total activity required for a
given work. The expression for minimal total activity can be recast as an
apparent minimal operation time or speed limit. However, it is unclear whether
protocols optimized under a constrained activity actually require the lowest
work input for a given operation time. In the context of bit reset, we show
that directly minimizing work for a given operation time leads to protocols
that require significantly less work to perform the operation than the
activity-constrained protocol of the same duration. We show how the resulting
protocols differ. One reason for the difference is the fact that the activity
rate is not constant over the course of the protocol: it depends on both the
transition rates and the distribution of the bit, both of which change during
the copy operation. In the limit of long protocol duration, we find an
expression for the difference between the resulting minimal work for both
optimization schemes, for a general class of dynamics. The time-constrained
approach always outperforms the activity-constrained approach for a given
constrained duration, and the difference in work can be arbitrarily large.",http://arxiv.org/abs/2501.04439v1
Comparing radial migration in dark matter and MOND regimes,2025-01-10T12:35:58Z,"R. Nagy, F. Janák, M. Šturc, M. Jurčík, E. Puha","Multiple studies on radial migration in disc galaxies have proven the
importance of the effect of resonances with non-axisymmetric components on the
evolution of galactic discs. However, the dynamical effects of classic
Newtonian dynamics with dark matter (DM) differ from MOdified Newtonian
Dynamics (MOND) and might trigger different radial migration. A thorough
analysis of radial migration considering these two gravitational regimes might
shed some light on different predictions of DM and MOND theories. We aim to
quantitatively and qualitatively compare the effects of resonances and stellar
radial migration (churning) in a Milky Way-like (MW-like) galaxy in the DM and
MOND regimes. We performed simulations of a MW-like galaxy to analyse the
effect of non-axisymmetric structures (galactic bar and spiral arms)
considering various parameters of the spiral structure. We conducted a
two-dimensional numerical simulation consisting of the integration of $2 \cdot
10^6$ stars in a static rotating galactic potential for $6~\mbox{Gyr}$. We
analysed the change in the star's position, the guiding radius, as well as the
frequency phase space. We investigated DM and MOND approaches. The outcome of
the simulation shows that the radial migration is much more pronounced in the
MOND regime compared to the DM one. Compared to the DM approach, in the MOND
regime, we observe up to five times as many stars with a maximum change in the
guiding radius of more than $1.5~\mbox{kpc}$ during the time interval from
$2-6~\mbox{Gyr}$.Analysis of the frequency phase space reveals that the most
prominent resonances in all DM and MOND configurations are the co-rotation
resonance with the spiral arms ($m=p=1$), outer Lindblad resonance with the
galactic bar and spiral arms, and the co-rotation resonance ($m=2$, $p=1$) with
the superposition of the galactic bar and spiral arms, $2 \Omega = \Omega_b +
\Omega_{sp}$.",http://arxiv.org/abs/2501.05924v1
Emergent Symbol-like Number Variables in Artificial Neural Networks,2025-01-10T18:03:46Z,"Satchel Grant, Noah D. Goodman, James L. McClelland","What types of numeric representations emerge in Neural Networks (NNs)? To
what degree do NNs induce abstract, mutable, slot-like numeric variables, and
in what situations do these representations emerge? How do these
representations change over learning, and how can we understand the neural
implementations in ways that are unified across different NNs? In this work, we
approach these questions by first training sequence based neural systems using
Next Token Prediction (NTP) objectives on numeric tasks. We then seek to
understand the neural solutions through the lens of causal abstractions or
symbolic algorithms. We use a combination of causal interventions and
visualization methods to find that artificial neural models do indeed develop
analogs of interchangeable, mutable, latent number variables purely from the
NTP objective. We then ask how variations on the tasks and model architectures
affect the models' learned solutions to find that these symbol-like numeric
representations do not form for every variant of the task, and transformers
solve the problem in a notably different way than their recurrent counterparts.
We then show how the symbol-like variables change over the course of training
to find a strong correlation between the models' task performance and the
alignment of their symbol-like representations. Lastly, we show that in all
cases, some degree of gradience exists in these neural symbols, highlighting
the difficulty of finding simple, interpretable symbolic stories of how neural
networks perform numeric tasks. Taken together, our results are consistent with
the view that neural networks can approximate interpretable symbolic programs
of number cognition, but the particular program they approximate and the extent
to which they approximate it can vary widely, depending on the network
architecture, training data, extent of training, and network size.",http://arxiv.org/abs/2501.06141v1
"Intermingled open and closed magnetic field lines near the radial origin
  of the heliospheric current sheet",2025-01-14T20:22:54Z,"Forrest Mozer, Andrii Voshchepynets, Oleksiy Agapitov, Kyung-Eu Choi, Richard Sydora","Aims. To investigate the magnetic field geometry and waves in the region near
the Sun where the heliospheric current sheet is formed. Methods. One good
example of apparent open and closed field lines was found and its fields and
plasmas were analyzed. Results. The radial component of the magnetic field (the
Z-component) measured on the Parker Solar Probe (PSP) changed sign between
12:00 and 13:00 UT on March 30, 2024, when the spacecraft was at 13 solar
radii. This sign change may have occurred because the spacecraft crossed the
heliospheric current sheet on long open magnetic field lines or it may have
occurred because the spacecraft crossed from one side of the equator to the
other on much shorter closed magnetic field lines. During this crossing, two
distinct regions having different magnetic field geometries, strahl flows,
plasma densities, and electric field spectra were observed and identified as
regions with open and closed magnetic field lines, respectively. The two
regions intermingled on time scales less than 100 milliseconds to create a
complex magnetic field geometry. The waves observed in both regions were
electrostatic and composed of wide band signatures (in the open field lines
regions) and well-structured frequency harmonics (in both the open and closed
field lines regions). These harmonic frequencies correlated with the proton
plasma frequency, fpp, with the lowest frequency at ~0.1fpp. This result plus
the field aligned electric field perturbations and plasma density fluctuations,
require that the observed intense electrostatic mode and associated harmonics
were ion acoustic waves. The absence of broadband electrostatic signals in
closed field line regions is explained by the lower (than in open field line
regions) hot and core electron density and higher ratio of the electron plasma
frequency to the electron gyrofrequency, suppressing wave generation.",http://arxiv.org/abs/2501.08419v1
Can LLM Generate Regression Tests for Software Commits?,2025-01-19T15:46:26Z,"Jing Liu, Seongmin Lee, Eleonora Losiouk, Marcel Böhme","Large Language Models (LLMs) have shown tremendous promise in automated
software engineering. In this paper, we investigate the opportunities of LLMs
for automatic regression test generation for programs that take highly
structured, human-readable inputs, such as XML parsers or JavaScript
interpreters. Concretely, we explore the following regression test generation
scenarios for such programs that have so far been difficult to test
automatically in the absence of corresponding input grammars:
  $\bullet$ Bug finding. Given a code change (e.g., a commit or pull request),
our LLM-based approach generates a test case with the objective of revealing
any bugs that might be introduced if that change is applied.
  $\bullet$ Patch testing. Given a patch, our LLM-based approach generates a
test case that fails before but passes after the patch. This test can be added
to the regression test suite to catch similar bugs in the future.
  We implement Cleverest, a feedback-directed, zero-shot LLM-based regression
test generation technique, and evaluate its effectiveness on 22 commits to
three subject programs: Mujs, Libxml2, and Poppler. For programs using more
human-readable file formats, like XML or JavaScript, we found Cleverest
performed very well. It generated easy-to-understand bug-revealing or
bug-reproduction test cases for the majority of commits in just under three
minutes -- even when only the code diff or commit message (unless it was too
vague) was given. For programs with more compact file formats, like PDF, as
expected, it struggled to generate effective test cases. However, the
LLM-supplied test cases are not very far from becoming effective (e.g., when
used as a seed by a greybox fuzzer or as a starting point by the developer).",http://arxiv.org/abs/2501.11086v1
"On the Complexity of Computing a Fastest Temporal Path in Interval
  Temporal Graphs",2025-01-20T10:16:50Z,"Guillaume Aubian, Filippo Brunelli, Feodor F Dragan, Guillaume Ducoffe, Michel Habib, Allen Ibiapina, Laurent Viennot","Temporal graphs arise when modeling interactions that evolve over time. They
usually come in several flavors, depending on the number of parameters used to
describe the temporal aspects of the interactions: time of appearance,
duration, delay of transmission. In the point model, edges appear at specific
points in time, while in the more general interval model, edges can be present
over multiple time intervals. In both models, the delay for traversing an edge
can change with each edge appearance. When time is discrete, the two models are
equivalent in the sense that the presence of an edge during an interval is
equivalent to a sequence of point-in-time occurrences of the edge. However,
this transformation can drastically change the size of the input and has
complexity issues. Indeed, we show a gap between the two models with respect to
the complexity of the classical problem of computing a fastest temporal path
from a source vertex to a target vertex, i.e. a path where edges can be
traversed one after another in time and such that the total duration from
source to target is minimized. It can be solved in near-linear time in the
point model, while we show that the interval model requires quadratic time
under classical assumptions of fine-grained complexity. With respect to linear
time, our lower bound implies a factor of the number of vertices, while the
best known algorithm has a factor of the number of underlying edges.
Interestingly, we show that near-linear time is possible in the interval model
when restricted to all delays being zero, i.e. traversing an edge is
instantaneous.",http://arxiv.org/abs/2501.11380v1
"Mechanical strength investigations of the APPLE-X undulator using Fiber
  Bragg Grating strain measurements",2025-01-20T15:13:46Z,"I. Balossino, A. Polimadei, M. Del Franco, A. Selce, A. Vannozzi, E. Di Pasquale, L. Giannessi, F. Nguyen, A. Petralia, J. Pockar, U. Primozic, R. Geometrante, M. A. Caponero, L. Sabbatini","The SPARC_LAB facility at the INFN LNF is being upgraded to accommodate a new
user facility as part of the SABINA project. It was set up to investigate the
feasibility of an ultra-brilliant photoinjector and to perform FEL experiments.
The new beamline is equipped with three APPLE-X undulators acting as amplifiers
to deliver IR/THz radiation with photon pulses in the ps range, with energy of
tens of uJ, and with linear, circular, or elliptical polarization. The APPLE-X
guarantees to vary the gap amplitude between the magnets arrays and their
relative phase. The entire system has been designed from scratch, and a
structural analysis has been carried out. Once they were in Frascati, in
collaboration with ENEA, a further investigation campaign was launched on the
mechanical, using strain measurements based on optical methods. FBG sensors
were suitable for these tests due to their immunity to electromagnetic noise.
They consist of a phase grating inscribed in the core of a single-mode fiber,
whose Bragg-diffracted light propagates back along the fiber. If bonded to the
mechanical structure, they can be used as strain sensors. By following the
variations in the scattered spectrum, it is possible to perform strain
measurements. Using multiple FBGs applied at selected locations on the
undulator, several measurements were while opening and closing the gap or
changing the phase, but also by studying the quiescent response as a function
of the ambient temperature. The results of these tests show that there is a
clear deformation of the structure related to the temperature changes and
magnetic forces, but the magnitude of this deformation is well within the
tolerances required for the functionality of the undulator since they are
compatible or lower with respect to the one calculated with the finite elements
methods. The tests confirm the reliability of the mechanical structure.",http://arxiv.org/abs/2501.11531v1
"Practical Pipeline-Aware Regression Test Optimization for Continuous
  Integration",2025-01-20T15:39:16Z,"Daniel Schwendner, Maximilian Jungwirth, Martin Gruber, Martin Knoche, Daniel Merget, Gordon Fraser","Massive, multi-language, monolithic repositories form the backbone of many
modern, complex software systems. To ensure consistent code quality while still
allowing fast development cycles, Continuous Integration (CI) is commonly
applied. However, operating CI at such scale not only leads to a single point
of failure for many developers, but also requires computational resources that
may reach feasibility limits and cause long feedback latencies. To address
these issues, developers commonly split test executions across multiple
pipelines, running small and fast tests in pre-submit stages while executing
long-running and flaky tests in post-submit pipelines. Given the long runtimes
of many pipelines and the substantial proportion of passing test executions
(98% in our pre-submit pipelines), there not only a need but also potential for
further improvements by prioritizing and selecting tests. However, many
previously proposed regression optimization techniques are unfit for an
industrial context, because they (1) rely on complex and difficult-to-obtain
features like per-test code coverage that are not feasible in large,
multi-language environments, (2) do not automatically adapt to rapidly changing
systems where new tests are continuously added or modified, and (3) are not
designed to distinguish the different objectives of pre- and post-submit
pipelines: While pre-submit testing should prioritize failing tests,
post-submit pipelines should prioritize tests that indicate non-flaky changes
by transitioning from pass to fail outcomes or vice versa. To overcome these
issues, we developed a lightweight and pipeline-aware regression test
optimization approach that employs Reinforcement Learning models trained on
language-agnostic features. We evaluated our approach on a large industry
dataset collected over a span of 20 weeks of CI test executions. When
predicting...",http://arxiv.org/abs/2501.11550v1
"Experiments and modeling of dust particle heating resulting from changes
  in polarity switching in the PK-4 microgravity laboratory",2025-01-21T16:09:02Z,"Lori S. McCabe, Jeremiah Williams, Saikat Chakraborty Thakur, Uwe Konopka, Evdokiya Kostadinova, Mikhail Pustylnik, Hubertus Thomas, Markus Thoma, Edward Thomas","In the presence of gravity, the micron-sized charged dust particles in a
complex (dusty) plasma are compressed into thin layers. However, under the
microgravity conditions of the Plasma Kristall-4 (PK-4) experiment on the
International Space Station (ISS), the particles fill the plasma, allowing us
to investigate the properties of a three-dimensional (3D) multi-particle
system. This paper examines the change in the spatial ordering and thermal
state of the particle system created when dust particles are stopped by
periodic oscillations of the electric field, known as polarity switching, in a
dc glow discharge plasma.
  Data from the ISS is compared against experiments performed using a
ground-based reference version of PK-4 and numerical simulations. Initial
results show substantive differences in the velocity distribution functions
between experiments on the ground and in microgravity. There are also
differences in the motion of the dust cloud, in microgravity there is an
expansion of the dust cloud at the application of polarity switching which is
not seen in the ground-based experiments. It is proposed that the dust cloud in
microgravity gains thermal energy at the application of polarity switching due
to this expansion. Simulation results suggest that this may be due to a
modification in the effective screening length of the dust at the onset of
polarity switching, which arises from a configuration energy between the
charged particles. Experimental measurements and simulations show that an
extended time (much greater than the Epstein drag decay) is required to
dissipate this energy.",http://arxiv.org/abs/2501.12248v2
"Near-infrared Integral-field Spectroscopy of the Wind Forming Region of
  CW Leo",2025-01-21T20:21:17Z,"Hyosun Kim, Youichi Ohyama, Ho-Gyu Lee, Ji Hoon Kim","The circumstellar envelope of the carbon star CW Leo exhibited various
unexpected changes in recent optical imaging observations. We have performed a
follow-up observation using the Near-infrared Integral-Field Spectrograph
(NIFS) equipped on the Gemini-North telescope. We report the near-infrared
counterparts of a local brightness peak in the optical at the stellar position
of CW Leo. On the other hand, a second peak detected at short wavelengths in
the J band coincides with the brightest, bluest position in the optical images.
The absorption features in the K band are minimized at a radius of 0.2 arcsec
from the predicted stellar position. The reduction of the absorption depths
likely indicates dilution of the absorption features by thermal emission of
dust grains newly formed at such a radius and heated by radiation from the
central star. The broad absorption feature at 1.53 um is significantly deeper
than in template carbon stars, consistent with the presence of a substantial
amount of circumstellar material around CW Leo. Its northeastern quadrant lacks
circumstellar absorption features and scattered light in the near-infrared
regime, which are possibly manifestations of its conical cavity in both gas and
dust. In addition, a cross correlation of CO overtone bands indicates that the
average expansion velocity of dust grains is smaller to the northern direction,
likewise the velocity of transverse wind components derived using the
differential proper motion of a circumstellar whirled pattern. The gradual
brightening of CW Leo and the changes in its innermost circumstellar envelope
need further continuous monitoring observations to properly understand its
transitional phase toward the post-asymptotic-giant-branch stage.",http://arxiv.org/abs/2501.12484v1
Field induced density wave in a kagome superconductor,2025-01-22T22:43:25Z,"Md Shafayat Hossain, Qi Zhang, Julian Ingham, Jinjin Liu, Sen Shao, Yangmu Li, Yuxin Wang, Bal K. Pokharel, Zi-Jia Cheng, Yu-Xiao Jiang, Maksim Litskevich, Byunghoon Kim, Xian Yang, Yongkai Li, Tyler A. Cochran, Yugui Yao, Dragana Popović, Zhiwei Wang, Guoqing Chang, Ronny Thomale, Luis Balicas, M. Zahid Hasan","On the kagome lattice, electrons benefit from the simultaneous presence of
band topology, flat electronic bands, and van Hove singularities, forming
competing or cooperating orders. Understanding the interrelation between these
distinct order parameters remains a significant challenge, leaving much of the
associated physics unexplored. In the kagome superconductor KV3Sb5, which
exhibits a charge density wave (CDW) state below T = 78 K, we uncover an
unpredicted field-induced phase transition below 6 K. The observed transition
is marked by a hysteretic anomaly in the resistivity, nonlinear electrical
transport, and a change in the symmetry of the electronic response as probed
via the angular dependence of the magnetoresistivity. These observations
surprisingly suggest the emergence of an unanticipated broken symmetry state
coexisting with the original CDW. To understand this experimental observation,
we developed a theoretical minimal model for the normal state inside the
high-temperature parent CDW phase where an incommensurate CDW order emerges as
an instability sub-leading to superconductivity. The incommensurate CDW emerges
when superconducting fluctuations become fully suppressed by large magnetic
fields. Our results suggest that, in kagome superconductors, quantum states can
either coexist or are nearly degenerate in energy, indicating that these are
rich platforms to expose new correlated phenomena.",http://arxiv.org/abs/2501.13260v1
Higgs Inflation Model with Small Non-Minimal Coupling Constant,2025-01-26T16:49:25Z,Alexander B. Kaganovich,"In the ""Higgs field+gravity"" model, the selfconsistency of equations obtained
from the original action has the form of an algebraic constraint defining the
scalar $\zeta$ as a function of the Higgs field $\varphi$ and its first
derivatives. The scalar $\zeta$ is present in all equations of motion and has a
significant effect on the dynamics. Transition to the Einstein frame is carried
out in equations of motions. Due to the constraint, the original model
parameters are converted into $\varphi$-dependent classical effective
parameters. In particular, the effective potential has the form
$U_{eff}=\frac{\lambda}{4\xi^2}M_P^4 F(\varphi)
\tanh^4(\frac{\sqrt{\xi}\varphi}{M_P})$, where $F(\varphi)$ is a smooth
function. The constant $\xi$ of non-minimal coupling to scalar curvature can be
chosen as small as desired. If $\xi =1/6$, then to ensure agreement with CMB
observational data, the Higgs field selfcoupling parameter $\lambda$ in the
original action must be of the order of $\sim 10^{-11}$. During cosmological
evolution after the end of inflation, the decrease of $\varphi$ leads to a
change in the sign of the effective Higgs mass term. This effect provides an
answer to the mystery of the Higgs potential structure and leads to SSB. As
$\varphi$ approaches VEV, the scalar function $\zeta(\varphi)$ changes in such
a way that the classical effective selfcoupling parameter
$\lambda_{eff}(\zeta(\varphi))$ increases by 10 orders of magnitude compared to
$\lambda$, which is necessary for the implementation of the GWS theory.
Applying the model to the very beginning of the classical evolution of the
Universe shows that under certain initial conditions, cosmological dynamics can
begin with a phantom regime preceding inflation.However, if evolution begins
with normal dynamics, then it proceeds only as inflation, and the problem of
initial conditions for the onset of inflation does not arise.",http://arxiv.org/abs/2501.15597v2
Quantum oscillations of holes in GaN,2025-01-27T17:05:52Z,"Chuan F. C. Chang, Joseph E. Dill, Zexuan Zhang, Jie-Cheng Chen, Naomi Pieczulewski, Samuel J. Bader, Oscar Ayala Valenzuela, Scott A. Crooker, Fedor F. Balakirev, Ross D. McDonald, Jimy Encomendero, David A. Muller, Feliciano Giustino, Debdeep Jena, Huili Grace Xing","GaN has emerged to be a major semiconductor akin to silicon due to its
revolutionary impacts in solid state lighting, critically enabled by p-type
doping, and high-performance radio-frequency and power electronics. Suffering
from inefficient hole doping and low hole mobility, quantum oscillations in
p-type GaN have not been observed, hindering fundamental studies of valence
bands and hole transport in GaN. Here, we present the first observation of
quantum oscillations of holes in GaN. Shubnikov-de Haas (SdH) oscillations in
hole resistivity are observed in a quantum-confined two-dimensional hole gas at
a GaN/AlN interface, where polarization-induced doping overcomes thermal
freeze-out, and a sharp and clean interface boosts the hole mobility enough to
unmask the quantum oscillations. These holes degenerately occupy the light and
heavy hole bands of GaN and have record-high mobilities of ~1900 cm2/Vs and
~400 cm2/Vs at 3K, respectively. We use magnetic fields up to 72 T to resolve
SdH oscillations of holes from both valence bands to extract their respective
sheet densities, quantum scattering times, and the effective masses of light
holes (0.5-0.7 m0) and heavy holes (1.9 m0). SdH oscillations of heavy and
light holes in GaN constitute a direct metrology of valence bands and open new
venues for quantum engineering in this technologically important semiconductor.
Like strained silicon transistors, strain-engineering of the valence bands of
GaN is predicted to dramatically improve hole mobilities by reducing the hole
effective mass, a proposal that can now be explored experimentally,
particularly in a fully fabricated transistor, using quantum oscillations.
Furthermore, the findings of this work suggest a blueprint to create 2D hole
gases and observe quantum oscillations of holes in related wide bandgap
semiconductors such as SiC and ZnO in which such techniques are not yet
possible.",http://arxiv.org/abs/2501.16213v1
"The foot, the fan, and the cuprate phase diagram: Fermi-volume-changing
  quantum phase transitions",2025-01-27T19:00:00Z,Subir Sachdev,"A Fermi liquid with a 'large' Fermi surface (FL) can have a quantum phase
transition to a spin density wave state (SDW) with reconstructed 'small' Fermi
pockets. Both FL and SDW phases obey the Luttinger constraints on the volume
enclosed by the Fermi surfaces. Critical spin fluctuations lead to spin-singlet
$d$-wave pairing, as observed in the cuprates. Studies of the influence of
spatial disorder on the FL-SDW quantum phase transition predict an extended
quantum-critical Griffiths-type phase at low temperatures on the large Fermi
surface side. These computations agree with the 'foot' of strange metal
transport, and recent low temperature neutron scattering observations on
La$_{2-x}$Sr$_x$CuO$_4$.
  However, this theory cannot explain the higher temperature pseudogap and the
'fan' of strange metal behavior of the hole-doped cuprates. Here we need to
consider underlying Fermi-volume-changing quantum phase transitions without
symmetry breaking. Then the small Fermi surface phase does not obey the
Luttinger constraint, and the pseudogap metal is described by thermal
fluctuations above a 'fractionalized Fermi liquid' (FL*) or a 'holon metal',
with the descriptions related by a duality on a background spin liquid. The
quantum critical fan is described using a field theory for an underlying FL-FL*
quantum phase transition in the presence of spatial disorder. This field theory
can be mapped to a form which can be analyzed using the methods of the
Sachdev-Ye-Kitaev model. Such an analysis successfully models
linear-in-temperature resistivity, optical conductivity and thermopower
observations in the quantum critical fan.
  The confinement crossover connecting these lower and higher temperature
descriptions is also discussed.",http://arxiv.org/abs/2501.16417v4
An Adaptive Proton FLASH Therapy Using Modularized Pin Ridge Filter,2025-02-03T03:02:52Z,"Ahmal Jawad Zafar, Xiaofeng Yang, Zachary Diamond, Tian Sibo, David Yu, Pretesh R. Patel, Jun Zhou","In this paper, we proposed a method to optimize adaptive proton FLASH therapy
(ADP FLASH) using modularized pin ridge filters (pRFs) by recycling module pins
from the initial plan while reducing pRF adjustments in adaptive FLASH
planning. Initially, single energy (250 MeV) FLASH pRF plans were created using
pencil beam directions (PBDs) from initial IMPT plans on the planning CT (pCT).
PBDs are classified as new/changed ($\Delta$E > > 5 MeV) or unchanged by
comparing spot maps for targets between pCT and re-CT. We used an iterative
least square regression model to identify recyclable PBDs with minimal relative
changes to spot MU weighting. Two PBDs with the least square error were
retrieved per iteration and added to the background plan, and the remaining
PBDs were reoptimized for the adaptive plan in subsequent iterations. The
method was validated on three liver SBRT cases (50 Gy in 5 fractions) by
comparing various dosimetric parameters across initial pRF plans on pCT, reCT
and the ADP FLASH pRF plans on reCT. V100 for initial pRF plans on pCT, reCT,
and ADP FLASH pRF plans for the three cases were as follows: (93.7%, 89.2%,
91.4%), (93.5%, 60.2%, 91.7%), (97.3%, 69.9%, 98.8%). We observe a decline in
plan quality when applying the initial pRF to the reCT, whereas the ADP FLASH
pRF approach restores quality comparable to the initial pRF on the pCT. FLASH
effect of the initial pRF and ADP pRF plans were evaluated with a dose and dose
rate threshold of 1Gy and 40Gy/s, respectively, using the FLASH effectiveness
model. The proposed method recycled 91.2%, 71%, and 64.7% of PBDs from initial
pRF plans for the three cases while maintaining all clinical goals and
preserving FLASH effects across all cases.",http://arxiv.org/abs/2502.01011v1
"Multi-Object Active Search and Tracking by Multiple Agents in Untrusted,
  Dynamically Changing Environments",2025-02-03T04:23:07Z,"Mingi Jeong, Cristian Molinaro, Tonmoay Deb, Youzhi Zhang, Andrea Pugliese, Eugene Santos Jr., VS Subrahmanian, Alberto Quattrini Li","This paper addresses the problem of both actively searching and tracking
multiple unknown dynamic objects in a known environment with multiple
cooperative autonomous agents with partial observability. The tracking of a
target ends when the uncertainty is below a threshold. Current methods
typically assume homogeneous agents without access to external information and
utilize short-horizon target predictive models. Such assumptions limit
real-world applications. We propose a fully integrated pipeline where the main
contributions are: (1) a time-varying weighted belief representation capable of
handling knowledge that changes over time, which includes external reports of
varying levels of trustworthiness in addition to the agents; (2) the
integration of a Long Short Term Memory-based trajectory prediction within the
optimization framework for long-horizon decision-making, which reasons in
time-configuration space, thus increasing responsiveness; and (3) a
comprehensive system that accounts for multiple agents and enables
information-driven optimization. When communication is available, our strategy
consolidates exploration results collected asynchronously by agents and
external sources into a headquarters, who can allocate each agent to maximize
the overall team's utility, using all available information. We tested our
approach extensively in simulations against baselines, and in robustness and
ablation studies. In addition, we performed experiments in a 3D physics based
engine robot simulator to test the applicability in the real world, as well as
with real-world trajectories obtained from an oceanography computational fluid
dynamics simulator. Results show the effectiveness of our method, which
achieves mission completion times 1.3 to 3.2 times faster in finding all
targets, even under the most challenging scenarios where the number of targets
is 5 times greater than that of the agents.",http://arxiv.org/abs/2502.01041v1
The TechDebt Game -- Enabling Discussions about Technical Debt,2025-02-04T09:48:02Z,"Marion Wiese, Angelina Heinrichs, Nino Rusieshvili, Rodrigo Rebouças de Almeida, Klara Borowa","Context. Technical Debt (TD), defined as software constructs that are
beneficial in the short term but may hinder future change, is a frequently used
term in software development practice. Nevertheless, practitioners do not
always fully understand its definition and, in particular, conceptual model.
Previous research highlights that communication about TD is challenging,
especially with non-technical stakeholders. Discussions on this topic often
cause conflicts due to misunderstandings related to other stakeholders'
perspectives. Goal. We designed a board game to emulate TD concepts to make
them tangible to all stakeholders, including non-technical ones. The game aims
to encourage discussions about TD in an emulated and safe environment, thereby
avoiding real-life conflicts. Method. To evaluate the game's effectiveness, we
surveyed 46 practitioners from diverse domains, positions, and experience
levels who played the game in 13 sessions following extensive testing during
its development. In addition to the players' general feedback, we examined
situations where players recognized new insights about TD or connected game
scenarios to real-life experiences. Results. Overall, the feedback on the game
and its enjoyment factor were highly positive. While developers and software
architects often connected game situations to their real-world experiences,
non-technical stakeholders, such as scrum masters, product owners, and less
experienced developers, encountered multiple new insights on TD. Numerous
players have shifted their attitudes toward TD and have outlined a plan to
modify their behavior regarding TD management. Conclusions. Although the game
may not lead to long-term behavior change among stakeholders, participants'
feedback provides evidence that it might serve as a valuable starting point for
team discussions on technical debt management.",http://arxiv.org/abs/2502.02174v1
"A New Spectral Library for Modeling the Surfaces of Hot, Rocky
  Exoplanets",2025-02-06T19:00:00Z,"Kimberly Paragas, Heather A. Knutson, Renyu Hu, Bethany L. Ehlmann, Giulia Alemanno, Jörn Helbert, Alessandro Maturilli, Michael Zhang, Aishwarya Iyer, George Rossman","JWST's MIRI LRS provides the first opportunity to spectroscopically
characterize the surface compositions of close-in terrestrial exoplanets.
Models for the bare-rock spectra of these planets often utilize a spectral
library from R. Hu et al., which is based on room temperature reflectance
measurements of materials that represent archetypes of rocky planet surfaces.
Here we present an expanded library that includes hemispherical reflectance
measurements for a greater variety of compositions, varying textures (solid
slab, coarsely crushed, and fine powder), as well as high temperature (500-800
K) emissivity measurements for select samples. We incorporate this new library
into version 6.3 of the retrieval package PLATON and use it to show that
surfaces with similar compositions can have widely varying albedos and surface
temperatures. We additionally demonstrate that changing the texture of a
material can significantly alter its albedo, making albedo a poor proxy for
surface composition. We identify key spectral features -- the 5.6 \textmu{m}
olivine feature, the transparency feature, the Si-O stretching feature, and the
Christiansen feature -- that indicate silicate abundance and surface texture.
We quantify the number of JWST observations needed to detect these features in
the spectrum of the most favorable super-Earth target, LHS 3844 b, and revisit
the interpretation of its Spitzer photometry. Lastly, we show that
temperature-dependent changes in spectral features are likely undetectable at
the precision of current exoplanet observations. Our results illustrate the
importance of spectroscopically-resolved thermal emission measurements, as
distinct from surface albedo constraints, for characterizing the surface
compositions of hot, rocky exoplanets.",http://arxiv.org/abs/2502.04433v1
"The establishment of static digital humans and the integration with
  spinal models",2025-02-11T08:21:37Z,"Fujiao Ju, Yuxuan Wang, Shuo Wang, Chengyin Wang, Yinbo Chen, Jianfeng Li, Mingjie Dong, Bin Fang, Qianyu Zhuang","Adolescent idiopathic scoliosis (AIS), a prevalent spinal deformity,
significantly affects individuals' health and quality of life. Conventional
imaging techniques, such as X - rays, computed tomography (CT), and magnetic
resonance imaging (MRI), offer static views of the spine. However, they are
restricted in capturing the dynamic changes of the spine and its interactions
with overall body motion. Therefore, developing new techniques to address these
limitations has become extremely important. Dynamic digital human modeling
represents a major breakthrough in digital medicine. It enables a three -
dimensional (3D) view of the spine as it changes during daily activities,
assisting clinicians in detecting deformities that might be missed in static
imaging. Although dynamic modeling holds great potential, constructing an
accurate static digital human model is a crucial initial step for high -
precision simulations. In this study, our focus is on constructing an accurate
static digital human model integrating the spine, which is vital for subsequent
dynamic digital human research on AIS. First, we generate human point - cloud
data by combining the 3D Gaussian method with the Skinned Multi - Person Linear
(SMPL) model from the patient's multi - view images. Then, we fit a standard
skeletal model to the generated human model. Next, we align the real spine
model reconstructed from CT images with the standard skeletal model. We
validated the resulting personalized spine model using X - ray data from six
AIS patients, with Cobb angles (used to measure the severity of scoliosis) as
evaluation metrics. The results indicate that the model's error was within 1
degree of the actual measurements. This study presents an important method for
constructing digital humans.",http://arxiv.org/abs/2502.07844v1
Viscoplasticity can stabilise liquid collar motion on vertical cylinders,2025-02-12T10:47:10Z,"James D. Shemilt, Alice B. Thompson, Alex Horsley, Carl A. Whitfield, Oliver E. Jensen","Liquid films coating vertical cylinders can form annular liquid collars which
translate downwards under gravity. We investigate the dynamics of a thin
viscoplastic liquid film coating the interior or exterior of a vertical
cylindrical tube, quantifying how the yield stress modifies both the
Rayleigh-Plateau instability leading to collar formation and the translation of
collars down the tube. We use thin-film theory to derive an evolution equation
for the layer thickness, which we solve numerically to determine the nonlinear
dynamics of an initially flat layer. A flat layer is unstable to small
disturbances in the free-surface height when gravity is sufficiently strong to
make the fluid yield. We use matched asymptotics to derive a model describing
the quasi-steady translation of a slender liquid collar when the Bond number is
small. The structure of the asymptotic solution for a viscoplastic collar
shares some features with the Newtonian version, but there are several novel
asymptotic regions that emerge at the two ends of the collar. The global force
balance, which determines the collar's speed, is modified by a leading-order
contribution from viscous drag in the collar when the liquid is viscoplastic.
We use the asymptotic model to describe slow changes in collar volume when the
film thicknesses ahead of, and behind, the collar are unequal. When the film
thickness ahead of the collar is less than a critical value that we determine,
viscoplastic collars adjust their volume and reach a steadily-translating
state. This contrasts with the Newtonian problem, where the only state in which
steady translation occurs is unstable to small changes in the film thickness.",http://arxiv.org/abs/2502.08291v2
"Robot Pouring: Identifying Causes of Spillage and Selecting Alternative
  Action Parameters Using Probabilistic Actual Causation",2025-02-13T15:16:52Z,"Jaime Maldonado, Jonas Krumme, Christoph Zetzsche, Vanessa Didelez, Kerstin Schill","In everyday life, we perform tasks (e.g., cooking or cleaning) that involve a
large variety of objects and goals. When confronted with an unexpected or
unwanted outcome, we take corrective actions and try again until achieving the
desired result. The reasoning performed to identify a cause of the observed
outcome and to select an appropriate corrective action is a crucial aspect of
human reasoning for successful task execution. Central to this reasoning is the
assumption that a factor is responsible for producing the observed outcome. In
this paper, we investigate the use of probabilistic actual causation to
determine whether a factor is the cause of an observed undesired outcome.
Furthermore, we show how the actual causation probabilities can be used to find
alternative actions to change the outcome. We apply the probabilistic actual
causation analysis to a robot pouring task. When spillage occurs, the analysis
indicates whether a task parameter is the cause and how it should be changed to
avoid spillage. The analysis requires a causal graph of the task and the
corresponding conditional probability distributions. To fulfill these
requirements, we perform a complete causal modeling procedure (i.e., task
analysis, definition of variables, determination of the causal graph structure,
and estimation of conditional probability distributions) using data from a
realistic simulation of the robot pouring task, covering a large combinatorial
space of task parameters. Based on the results, we discuss the implications of
the variables' representation and how the alternative actions suggested by the
actual causation analysis would compare to the alternative solutions proposed
by a human observer. The practical use of the analysis of probabilistic actual
causation to select alternative action parameters is demonstrated.",http://arxiv.org/abs/2502.09395v1
"Artificial Intelligence to Assess Dental Findings from Panoramic
  Radiographs -- A Multinational Study",2025-02-14T16:34:21Z,"Yin-Chih Chelsea Wang, Tsao-Lun Chen, Shankeeth Vinayahalingam, Tai-Hsien Wu, Chu Wei Chang, Hsuan Hao Chang, Hung-Jen Wei, Mu-Hsiung Chen, Ching-Chang Ko, David Anssari Moin, Bram van Ginneken, Tong Xi, Hsiao-Cheng Tsai, Min-Huey Chen, Tzu-Ming Harry Hsu, Hye Chou","Dental panoramic radiographs (DPRs) are widely used in clinical practice for
comprehensive oral assessment but present challenges due to overlapping
structures and time constraints in interpretation.
  This study aimed to establish a solid baseline for the AI-automated
assessment of findings in DPRs by developing, evaluating an AI system, and
comparing its performance with that of human readers across multinational data
sets.
  We analyzed 6,669 DPRs from three data sets (the Netherlands, Brazil, and
Taiwan), focusing on 8 types of dental findings. The AI system combined object
detection and semantic segmentation techniques for per-tooth finding
identification. Performance metrics included sensitivity, specificity, and area
under the receiver operating characteristic curve (AUC-ROC). AI
generalizability was tested across data sets, and performance was compared with
human dental practitioners.
  The AI system demonstrated comparable or superior performance to human
readers, particularly +67.9% (95% CI: 54.0%-81.9%; p < .001) sensitivity for
identifying periapical radiolucencies and +4.7% (95% CI: 1.4%-8.0%; p = .008)
sensitivity for identifying missing teeth. The AI achieved a macro-averaged
AUC-ROC of 96.2% (95% CI: 94.6%-97.8%) across 8 findings. AI agreements with
the reference were comparable to inter-human agreements in 7 of 8 findings
except for caries (p = .024). The AI system demonstrated robust generalization
across diverse imaging and demographic settings and processed images 79 times
faster (95% CI: 75-82) than human readers.
  The AI system effectively assessed findings in DPRs, achieving performance on
par with or better than human experts while significantly reducing
interpretation time. These results highlight the potential for integrating AI
into clinical workflows to improve diagnostic efficiency and accuracy, and
patient management.",http://arxiv.org/abs/2502.10277v1
Independence Tests for Language Models,2025-02-17T20:01:08Z,"Sally Zhu, Ahmed Ahmed, Rohith Kuditipudi, Percy Liang","We consider the following problem: given the weights of two models, can we
test whether they were trained independently -- i.e., from independent random
initializations? We consider two settings: constrained and unconstrained. In
the constrained setting, we make assumptions about model architecture and
training and propose a family of statistical tests that yield exact p-values
with respect to the null hypothesis that the models are trained from
independent random initializations. These p-values are valid regardless of the
composition of either model's training data; we compute them by simulating
exchangeable copies of each model under our assumptions and comparing various
similarity measures of weights and activations between the original two models
versus these copies. We report the p-values from these tests on pairs of 21
open-weight models (210 total pairs) and correctly identify all pairs of
non-independent models. Our tests remain effective even if one model was
fine-tuned for many tokens. In the unconstrained setting, where we make no
assumptions about training procedures, can change model architecture, and allow
for adversarial evasion attacks, the previous tests no longer work. Instead, we
propose a new test which matches hidden activations between two models, and
which is robust to adversarial transformations and to changes in model
architecture. The test can also do localized testing: identifying specific
non-independent components of models. Though we no longer obtain exact p-values
from this, empirically we find it behaves as one and reliably identifies
non-independent models. Notably, we can use the test to identify specific parts
of one model that are derived from another (e.g., how Llama 3.1-8B was pruned
to initialize Llama 3.2-3B, or shared layers between Mistral-7B and
StripedHyena-7B), and it is even robust to retraining individual layers of
either model from scratch.",http://arxiv.org/abs/2502.12292v1
"The Preference for Evolving Dark Energy from Cosmological Distance
  Measurements and Possible Signatures in the Growth Rate of Perturbations",2025-02-18T09:18:00Z,"Ryan E. Keeley, Kevork N. Abazajian, Manoj Kaplinghat, Arman Shafieloo","In this study, we use a flexible parametrization of the equation of state of
dark energy to explore its possible evolution with datasets from the Dark
Energy Spectroscopic Instrument (DESI), Planck cosmic microwave background, and
either the 5-year Dark Energy Survey (DES) or the Pantheon+ (PP) supernova (SN)
compilation. This parametrization, called transitional dark energy, allows for
rapid changes in the equation of state but also changes like that in the
Chevallier-Polarski-Linder parametrization. We find a 3.8{\sigma} preference
for evolving dark energy over {\Lambda}CDM with the DES dataset and a weaker
2.4{\sigma} preference when using the PP dataset. This corroborates the finding
of the DESI Collaboration, who found that their baryon acoustic oscillation
data preferred evolving dark energy when fit with the CPL parametrization of
the equation of state. Our analysis reveals no significant outliers in the DESI
data around the TDE best-fit, while the data is asymmetrically distributed
around the {\Lambda}CDM best-fit model such that the measured distances are on
average smaller. The DESI and SN data both prefer an expansion history that
implies a higher dark energy density around z=0.5 than in the
Planck-{\Lambda}CDM model, with the inferred equation of state being greater
than -1 around z=0 and close to or below -1 at z>0.5. We show that when the
expansion rate is greater than that in the Planck-{\Lambda}CDM model (around
z=0.5), the growth rate calculated assuming General Relativity is suppressed
relative to the Planck-{\Lambda}CDM model, and it rebounds as the expansion
rate differences between the models become smaller closer to the present time.
The resulting flattening of the $f\sigma_8(z)$ curve compared to the
{\Lambda}CDM model could be an independent signature of the temporal evolution
of dark energy.",http://arxiv.org/abs/2502.12667v1
"Variable Read Disturbance: An Experimental Analysis of Temporal
  Variation in DRAM Read Disturbance",2025-02-18T17:22:42Z,"Ataberk Olgun, F. Nisa Bostanci, Ismail Emir Yuksel, Oguzhan Canpolat, Haocong Luo, Geraldo F. Oliveira, A. Giray Yaglikci, Minesh Patel, Onur Mutlu","Modern DRAM chips are subject to read disturbance errors. State-of-the-art
read disturbance mitigations rely on accurate and exhaustive characterization
of the read disturbance threshold (RDT) (e.g., the number of aggressor row
activations needed to induce the first RowHammer or RowPress bitflip) of every
DRAM row (of which there are millions or billions in a modern system) to
prevent read disturbance bitflips securely and with low overhead. We
experimentally demonstrate for the first time that the RDT of a DRAM row
significantly and unpredictably changes over time. We call this new phenomenon
variable read disturbance (VRD). Our experiments using 160 DDR4 chips and 4
HBM2 chips from three major manufacturers yield two key observations. First, it
is very unlikely that relatively few RDT measurements can accurately identify
the RDT of a DRAM row. The minimum RDT of a DRAM row appears after tens of
thousands of measurements (e.g., up to 94,467), and the minimum RDT of a DRAM
row is 3.5X smaller than the maximum RDT observed for that row. Second, the
probability of accurately identifying a row's RDT with a relatively small
number of measurements reduces with increasing chip density or smaller
technology node size. Our empirical results have implications for the security
guarantees of read disturbance mitigation techniques: if the RDT of a DRAM row
is not identified accurately, these techniques can easily become insecure. We
discuss and evaluate using a guardband for RDT and error-correcting codes for
mitigating read disturbance bitflips in the presence of RDTs that change
unpredictably over time. We conclude that a >10% guardband for the minimum
observed RDT combined with SECDED or Chipkill-like SSC error-correcting codes
could prevent read disturbance bitflips at the cost of large read disturbance
mitigation performance overheads (e.g., 45% performance loss for an RDT
guardband of 50%).",http://arxiv.org/abs/2502.13075v1
"A Framework for Semantics-based Situational Awareness during Mobile
  Robot Deployments",2025-02-19T12:37:23Z,"Tianshu Ruan, Aniketh Ramesh, Hao Wang, Alix Johnstone-Morfoisse, Gokcenur Altindal, Paul Norman, Grigoris Nikolaou, Rustam Stolkin, Manolis Chiou","Deployment of robots into hazardous environments typically involves a
``Human-Robot Teaming'' (HRT) paradigm, in which a human supervisor interacts
with a remotely operating robot inside the hazardous zone. Situational
Awareness (SA) is vital for enabling HRT, to support navigation, planning, and
decision-making. This paper explores issues of higher-level ``semantic''
information and understanding in SA. In semi-autonomous, or variable-autonomy
paradigms, different types of semantic information may be important, in
different ways, for both the human operator and an autonomous agent controlling
the robot. We propose a generalizable framework for acquiring and combining
multiple modalities of semantic-level SA during remote deployments of mobile
robots. We demonstrate the framework with an example application of search and
rescue (SAR) in disaster response robotics. We propose a set of ``environment
semantic indicators"" that can reflect a variety of different types of semantic
information, e.g. indicators of risk, or signs of human activity, as the robot
encounters different scenes. Based on these indicators, we propose a metric to
describe the overall situation of the environment called ``Situational Semantic
Richness (SSR)"". This metric combines multiple semantic indicators to summarise
the overall situation. The SSR indicates if an information-rich and complex
situation has been encountered, which may require advanced reasoning for robots
and humans and hence the attention of the expert human operator. The framework
is tested on a Jackal robot in a mock-up disaster response environment.
Experimental results demonstrate that the proposed semantic indicators are
sensitive to changes in different modalities of semantic information in
different scenes, and the SSR metric reflects overall semantic changes in the
situations encountered.",http://arxiv.org/abs/2502.13677v1
"Restriction of macroscopic structural superlubricity due to structure
  relaxation by the example of twisted graphene bilayer",2025-02-19T14:20:42Z,"Alexander S. Minkin, Irina V. Lebedeva, Andrey M. Popov, Sergey A. Vyrko, Nikolai A. Poklonski, Yurii E. Lozovik","The effect of structure relaxation on the potential energy surface (PES) of
interlayer interaction of twisted graphene bilayer is studied for a set of
commensurate moir\'e systems using the registry-dependent empirical potential
of Kolmogorov and Crespi. It is found that the influence of structure
relaxation on the amplitude of PES corrugations (determining static friction)
depends on the unit cell size (or related twist angle) of the moir\'e system.
For moir\'e systems with the smallest unit cells, the amplitudes of PES
corrugations calculated with and without account of structure relaxation are
approximately the same. However, for large unit cell sizes, the structure
relaxation can lead to an increase of PES corrugations by orders of magnitude.
This means that structure relaxation can provide the main contribution into the
static friction of a superlubric system under certain conditions (such as the
contact size and twist angle). Moreover, the change of the PES type because of
structure relaxation from a trigonal lattice of maxima to a trigonal lattice of
minima is observed for the systems with the moir\'e patterns (5,1) and (5,3).
Based on the results obtained, possible crossovers between static friction
modes taking place upon changing the twist angle in a macroscopic superlubric
system consisting of identical layers are discussed. Additionally it is shown
that the PES for relaxed structures can still be approximated by the first
Fourier harmonics compatible with symmetries of twisted layers analogously to
the PES for rigid layers.",http://arxiv.org/abs/2502.13758v1
"Imaging the Photochemistry of Cyclobutanone using Ultrafast Electron
  Diffraction: Experimental Results",2025-02-19T18:55:21Z,"A. E. Green, Y. Liu, F. Allum, M. Graßl, P. Lenzen, M. N. R. Ashfold, S. Bhattacharyya, X. Cheng, M. Centurion, S. W. Crane, R. G. Forbes, N. A. Goff, L. Huang, B. Kaufman, M. F. Kling, P. L. Kramer, H. V. S. Lam, K. A. Larsen, R. Lemons, M. -F. Lin, A. J. Orr-Ewing, D. Rolles, A. Rudenko, S. K. Saha, J. Searles, X. Shen, S. Weathersby, P. M. Weber, H. Zhao, T. J. A. Wolf","We investigated the ultrafast structural dynamics of cyclobutanone following
photoexcitation at $\lambda=200$ nm using gas-phase megaelectronvolt ultrafast
electron diffraction. Our investigation complements the simulation studies of
the same process within this special issue. It provides information about both
electronic state population and structural dynamics through well-separable
inelastic and elastic electron scattering signatures. We observe the
depopulation of the photoexcited S$_2$ state of cyclobutanone with n3s Rydberg
character through its inelastic electron scattering signature with a time
constant of $(0.29 \pm 0.2)$ ps towards the S$_1$ state. The S$_1$ state
population undergoes ring-opening via a Norrish Type-I reaction, likely while
passing through a conical intersection with S$_0$. The corresponding structural
changes can be tracked by elastic electron scattering signatures. These changes
appear with a delay of $(0.14 \pm 0.05)$ ps with respect the initial
photoexcitation, which is less than the S$_2$ depopulation time constant. This
behavior provides evidence for the ballistic nature of the ring-opening once
the S$_1$ state is reached. The resulting biradical species react further
within $(1.2 \pm 0.2)$ ps via two rival fragmentation channels yielding ketene
and ethylene, or propene and carbon monoxide. Our study showcases both the
value of gas-phase ultrafast diffraction studies as an experimental benchmark
for nonadiabatic dynamics simulation methods and the limits in the
interpretation of such experimental data without comparison to such
simulations.",http://arxiv.org/abs/2502.13956v1
"H$α$ Variability of AB Aur b with the Hubble Space Telescope:
  Probing the Nature of a Protoplanet Candidate with Accretion Light Echoes",2025-02-20T17:02:42Z,"Brendan P. Bowler, Yifan Zhou, Lauren I. Biddle, Lillian Yushu Jiang, Jaehan Bae, Laird M. Close, Katherine B. Follette, Kyle Franson, Adam L. Kraus, Aniket Sanghi, Quang Tran, Kimberly Ward-Duong, Ya-Lin Wu, Zhaohuan Zhu","Giant planets generate accretion luminosity as they form. Much of this energy
is radiated in strong H$\alpha$ line emission, which has motivated direct
imaging surveys at optical wavelengths to search for accreting protoplanets.
However, compact disk structures can mimic accreting planets by scattering
emission from the host star. This can complicate the interpretation of
H$\alpha$ point sources, especially if the host star itself is accreting. We
describe an approach to distinguish accreting protoplanets from scattered-light
disk features using ""accretion light echoes."" This method relies on variable
H$\alpha$ emission from a stochastically accreting host star to search for a
delayed brightness correlation with a candidate protoplanet. We apply this
method to the candidate protoplanet AB Aur b with a dedicated Hubble Space
Telescope Wide Field Camera 3 program designed to sequentially sample the host
star and the candidate planet in H$\alpha$ while accounting for the light
travel time delay and orbital geometry of the source within the protoplanetary
disk. Across five epochs spanning 14 months, AB Aur b is over 20 times more
variable than its host star; AB Aur's H$\alpha$ emission changes by 15% while
AB Aur b varies by 330%. These brightness changes are not correlated, which
rules out unobstructed scattered starlight from the host star as the only
source of AB Aur b's H$\alpha$ emission and is consistent with tracing emission
from an independently accreting protoplanet, inner disk shadowing effects, or a
physically evolving compact disk structure. More broadly, accretion light
echoes offer a novel tool to explore the nature of protoplanet candidates with
well-timed observations of the host star prior to deep imaging in H$\alpha$.",http://arxiv.org/abs/2502.14736v1
"A Ritz variational principle for local collisionless gyrokinetic
  instabilities",2025-01-01T02:15:18Z,"C. D. Stephens, P. -Y. Li","Turbulence driven by gyrokinetic instabilities is largely responsible for
transport in magnetic fusion devices. To estimate this turbulent transport,
integrated modeling codes often use mixing length estimates in conjunction with
reduced models of the linearized gyrokinetic equation. One common method of
formulating and solving the linearized gyrokinetic eigenvalue problem equation
uses a Ritz variational principle, particularly in the local collisionless
limit. However, the variational principle as typically stated in the literature
is mathematically incorrect. In this work, we derive a mathematically correct
form of the variational principle that applies to local linear collisionless
gyrokinetics in general geometry with electromagnetic effects. We also
explicitly derive a weak form of the gyrokinetic field equations suitable for
numerical applications.",http://arxiv.org/abs/2501.00698v3
"eRevise+RF: A Writing Evaluation System for Assessing Student Essay
  Revisions and Providing Formative Feedback",2025-01-01T03:49:48Z,"Zhexiong Liu, Diane Litman, Elaine Wang, Tianwen Li, Mason Gobat, Lindsay Clare Matsumura, Richard Correnti","The ability to revise essays in response to feedback is important for
students' writing success. An automated writing evaluation (AWE) system that
supports students in revising their essays is thus essential. We present
eRevise+RF, an enhanced AWE system for assessing student essay revisions (e.g.,
changes made to an essay to improve its quality in response to essay feedback)
and providing revision feedback. We deployed the system with 6 teachers and 406
students across 3 schools in Pennsylvania and Louisiana. The results confirmed
its effectiveness in (1) assessing student essays in terms of evidence usage,
(2) extracting evidence and reasoning revisions across essays, and (3)
determining revision success in responding to feedback. The evaluation also
suggested eRevise+RF is a helpful system for young students to improve their
argumentative writing skills through revision and formative feedback.",http://arxiv.org/abs/2501.00715v1
"Towards End-to-End Neuromorphic Voxel-based 3D Object Reconstruction
  Without Physical Priors",2025-01-01T06:07:03Z,"Chuanzhi Xu, Langyi Chen, Vincent Qu, Haodong Chen, Vera Chung","Neuromorphic cameras, also known as event cameras, are asynchronous
brightness-change sensors that can capture extremely fast motion without
suffering from motion blur, making them particularly promising for 3D
reconstruction in extreme environments. However, existing research on 3D
reconstruction using monocular neuromorphic cameras is limited, and most of the
methods rely on estimating physical priors and employ complex multi-step
pipelines. In this work, we propose an end-to-end method for dense voxel 3D
reconstruction using neuromorphic cameras that eliminates the need to estimate
physical priors. Our method incorporates a novel event representation to
enhance edge features, enabling the proposed feature-enhancement model to learn
more effectively. Additionally, we introduced Optimal Binarization Threshold
Selection Principle as a guideline for future related work, using the optimal
reconstruction results achieved with threshold optimization as the benchmark.
Our method achieves a 54.6% improvement in reconstruction accuracy compared to
the baseline method.",http://arxiv.org/abs/2501.00741v1
"Swimming mode determines how well mesoscale swimmers shield their odor
  in turbulence",2025-01-01T09:59:47Z,"Martin James, Francesco Viola, Agnese Seminara","Marine organisms manipulate their surrounding flow through their swimming
dynamics, which affects the transport of their own odor cues. We demonstrate by
direct numerical simulations how a group of mesoscale swimmers immersed in a
turbulent flow alters the shape of the odor plume they release in the water.
Odor mixing is enhanced by increased velocity fluctuations and a
swimmer-induced flow circulation which widen the odor plume at close range
while speeding up dilution of the chemical trace. Beyond a short-range increase
in the likelihood of being detected, swimming considerably reduces detections
with effects that can persist at distances of the order of ten times the size
of the group or more. We find that puller-like swimmers are more effective at
olfactory shielding than pusher-like swimmers. We trace this difference back to
the dynamics at the swimmer location, which tends to trap odor at the source
for pushers and to dilute it for pullers. Olfactory shielding is robust to
changes in the conditions, and is more pronounced for weak turbulent Reynolds
numbers and large swimmer Reynolds numbers. Our results suggest that olfactory
shielding may play a role in the emergence of different swimming modalities by
marine organisms.",http://arxiv.org/abs/2501.00789v1
"Unfolding the Headline: Iterative Self-Questioning for News Retrieval
  and Timeline Summarization",2025-01-01T16:28:21Z,"Weiqi Wu, Shen Huang, Yong Jiang, Pengjun Xie, Fei Huang, Hai Zhao","In the fast-changing realm of information, the capacity to construct coherent
timelines from extensive event-related content has become increasingly
significant and challenging. The complexity arises in aggregating related
documents to build a meaningful event graph around a central topic. This paper
proposes CHRONOS - Causal Headline Retrieval for Open-domain News Timeline
SummarizatiOn via Iterative Self-Questioning, which offers a fresh perspective
on the integration of Large Language Models (LLMs) to tackle the task of
Timeline Summarization (TLS). By iteratively reflecting on how events are
linked and posing new questions regarding a specific news topic to gather
information online or from an offline knowledge base, LLMs produce and refresh
chronological summaries based on documents retrieved in each round.
Furthermore, we curate Open-TLS, a novel dataset of timelines on recent news
topics authored by professional journalists to evaluate open-domain TLS where
information overload makes it impossible to find comprehensive relevant
documents from the web. Our experiments indicate that CHRONOS is not only adept
at open-domain timeline summarization, but it also rivals the performance of
existing state-of-the-art systems designed for closed-domain applications,
where a related news corpus is provided for summarization.",http://arxiv.org/abs/2501.00888v1
"Exceptional point in a trimer chain of oscillators with a quadratic
  driving",2025-01-02T03:28:08Z,"M Shoufie Ukhtary, Albert Andersen, Donny Dwiputra, M. Jauhar Kholili","Exceptional points of a dissipative chain of three coupled oscillators
(trimer), which is driven by quadratic photon, are investigated. The
exceptional points emerge from the coalescence of both eigenvalues and
eigenvectors of the dynamical matrix that describes the first moments of the
trimer. At the exceptional point, we found that the optical spectrum is split
into two peaks, instead of a conventional single peak, as in the case of a
single oscillator. In particular, the positions of these peaks correspond to
the natural frequency of the trimer in a \textit{closed system}, which depends
only on the coupling strength. Furthermore, after passing the exceptional
point, the peak positions do not change, which can be used to estimate the
coupling strength between oscillators.",http://arxiv.org/abs/2501.01033v1
"The angular momentum of 1.2$M_\odot$ to 2.0$M_\odot$ main-sequence and
  turn-off stars constrain the relationship between star-forming environment
  and galactic evolution history",2025-01-02T03:30:05Z,"Yu-Fu Shen, Yan Xu, Yi-Bo Wang, Xiu-Lin Huang, Xing-Xing Hu, Qi Yuan","\textit{Kepler} and \textit{Gaia} data shows an anomaly in the angular
momentum-age relationship for 1.2-2 main-sequence stars. After considering
model-induced correlation of parameters, the moment of inertia, stellar
velocity distribution, sample selection effects, interactions between the Milky
Way and dwarf galaxies, the star-disk interaction during the early pre-main
sequence, and the angular momentum change on the main sequence, this work
suggests that the earlier the star within this mass range born, the smaller the
angular momentum at the time of born, following an exponential decay
relationship. This relationship should be attributed to the variation in
molecular cloud parameters throughout the history of the Milky Way.",http://arxiv.org/abs/2501.01035v2
"HPC Application Parameter Autotuning on Edge Devices: A Bandit Learning
  Approach",2025-01-02T04:59:32Z,"Abrar Hossain, Abdel-Hameed A. Badawy, Mohammad A. Islam, Tapasya Patki, Kishwar Ahmed","The growing necessity for enhanced processing capabilities in edge devices
with limited resources has led us to develop effective methods for improving
high-performance computing (HPC) applications. In this paper, we introduce LASP
(Lightweight Autotuning of Scientific Application Parameters), a novel strategy
designed to address the parameter search space challenge in edge devices. Our
strategy employs a multi-armed bandit (MAB) technique focused on online
exploration and exploitation. Notably, LASP takes a dynamic approach, adapting
seamlessly to changing environments. We tested LASP with four HPC applications:
Lulesh, Kripke, Clomp, and Hypre. Its lightweight nature makes it particularly
well-suited for resource-constrained edge devices. By employing the MAB
framework to efficiently navigate the search space, we achieved significant
performance improvements while adhering to the stringent computational limits
of edge devices. Our experimental results demonstrate the effectiveness of LASP
in optimizing parameter search on edge devices.",http://arxiv.org/abs/2501.01057v1
"Are Politicians Responsive to Mass Shootings? Evidence from U.S. State
  Legislatures",2025-01-02T06:00:02Z,"Haotian Chen, Jack Kappelman","The United States leads the world in the number of violent mass shootings
that occur each year, and policy making on firearms remains polarized along
party lines. Are legislators responsive to mass shootings? We estimate the
latent positions of nearly 2,000 state legislators on gun policy from their
roll-call voting records on firearm-related bills from 2011 to 2022. Employing
a staggered difference-in-differences design, we find that mass shootings
within or near a state legislator's district do not alter their voting behavior
on firearm policy, on average, for members of both parties. Our estimated
effects of mass shootings on treated legislators' support for restrictive gun
policies (on a -1 to 1 scale) range from a 4.8% reduction among California
Democrats and a 0.9% increase among California Republicans to, across six total
states, a 5% (among Democrats) and 7.1% (among Republicans) increase, with 95%
confidence intervals spanning opposite directions. We conclude that, on
average, mass shootings fail to produce changes in a legislator's support
(opposition) for restrictive (permissive) firearms bills. Our findings suggest
that even the most heinous acts of mass violence -- that are squarely in the
domain of events that state legislators might respond to -- fail to produce any
measurable effects on legislators' positions on firearm-related policy.",http://arxiv.org/abs/2501.01084v1
Probing exoplanetary magnetism via atomic alignment effect,2025-01-02T07:42:24Z,"M. Rumenskikh, A. V. Taichenachev, I. F. Shaikhislamov, V. I. Yudin","The intrinsic magnetic fields of exoplanets affect the structure of their
atmospheres and plasmaspheres and, therefore, the observational manifestations
of transit absorptions. This work proposes a new method for constraining the
presence or absence of relatively weak magnetic fields. The method is based on
the quantum effect of atomic alignment of the lower energy level resulting in
changing the absorption probabilities of individual transitions of multiplets
from the equilibrium 2J+1 value. It appears to be sensitive to fields above
~0.001 G. We applied this method to some available transit observations of
exoplanets and demonstrate that we indeed have the possibility to constrain the
intrinsic magnetic field of some exoplanets right now. However, more precise
and repetitive measurements, which might be available in near future, are
needed for definite conclusions.",http://arxiv.org/abs/2501.01122v1
"Communicating Unexpectedness for Out-of-Distribution Multi-Agent
  Reinforcement Learning",2025-01-02T08:47:12Z,"Min Whoo Lee, Kibeom Kim, Soo Wung Shin, Minsu Lee, Byoung-Tak Zhang","Applying multi-agent reinforcement learning methods to realistic settings is
challenging as it may require the agents to quickly adapt to unexpected
situations that are rarely or never encountered in training. Recent methods for
generalization to such out-of-distribution settings are limited to more
specific, restricted instances of distribution shifts. To tackle adaptation to
distribution shifts, we propose Unexpected Encoding Scheme, a novel
decentralized multi-agent reinforcement learning algorithm where agents
communicate ""unexpectedness,"" the aspects of the environment that are
surprising. In addition to a message yielded by the original reward-driven
communication, each agent predicts the next observation based on previous
experience, measures the discrepancy between the prediction and the actually
encountered observation, and encodes this discrepancy as a message. Experiments
on multi-robot warehouse environment support that our proposed method adapts
robustly to dynamically changing training environments as well as
out-of-distribution environment.",http://arxiv.org/abs/2501.01140v1
"Revisiting Impurity Induced In-gap Bound States In Unconventional
  Superconductors",2025-01-02T09:19:19Z,"Junkang Huang, Z. D. Wang, Tao Zhou","This study revisits the effects of single impurity scattering in
unconventional superconductors, with a specific emphasis on intralayer $d$-wave
pairing and interlayer $s$-wave pairing. We reveal that in the context of a
square lattice near half-filling doping, there exists an intrinsic connection
between the $d$-wave pairing symmetry and the appearance of mid-gap states.
This relationship is determined by the $C_4$ rotational symmetry of both the
$d$-wave gap amplitude and the square lattice itself. Furthermore, we identify
an intrinsic link between the in-gap states and the sign change of the order
parameter. In systems with interlayer pairing, strong resonant peaks are
observed, despite the absence of sign-reversal characteristics in the pairing
order parameter. By utilizing the $T$-matrix approach, we elucidate the
mechanisms underlying these impurity-induced states. Our theoretical framework
is pertinent to the analysis of newly discovered nickel-based high-temperature
superconductors, providing a powerful tool for distinguishing their pairing
properties. The results of this study shed light on the complex interplay
between pairing symmetries and impurity effects in unconventional
superconductors, paving the way for future investigations into the unique
properties of these emerging materials.",http://arxiv.org/abs/2501.01155v1
"Attending To Syntactic Information In Biomedical Event Extraction Via
  Graph Neural Networks",2025-01-02T09:25:24Z,"Farshad Noravesh, Reza Haffari, Ong Huey Fang, Layki Soon, Sailaja Rajalana, Arghya Pal","Many models are proposed in the literature on biomedical event
extraction(BEE). Some of them use the shortest dependency path(SDP) information
to represent the argument classification task. There is an issue with this
representation since even missing one word from the dependency parsing graph
may totally change the final prediction. To this end, the full adjacency matrix
of the dependency graph is used to embed individual tokens using a graph
convolutional network(GCN). An ablation study is also done to show the effect
of the dependency graph on the overall performance. The results show a
significant improvement when dependency graph information is used. The proposed
model slightly outperforms state-of-the-art models on BEE over different
datasets.",http://arxiv.org/abs/2501.01158v2
Asymmetric Reinforcing against Multi-modal Representation Bias,2025-01-02T13:00:06Z,"Xiyuan Gao, Bing Cao, Pengfei Zhu, Nannan Wang, Qinghua Hu","The strength of multimodal learning lies in its ability to integrate
information from various sources, providing rich and comprehensive insights.
However, in real-world scenarios, multi-modal systems often face the challenge
of dynamic modality contributions, the dominance of different modalities may
change with the environments, leading to suboptimal performance in multimodal
learning. Current methods mainly enhance weak modalities to balance multimodal
representation bias, which inevitably optimizes from a partialmodality
perspective, easily leading to performance descending for dominant modalities.
To address this problem, we propose an Asymmetric Reinforcing method against
Multimodal representation bias (ARM). Our ARM dynamically reinforces the weak
modalities while maintaining the ability to represent dominant modalities
through conditional mutual information. Moreover, we provide an in-depth
analysis that optimizing certain modalities could cause information loss and
prevent leveraging the full advantages of multimodal data. By exploring the
dominance and narrowing the contribution gaps between modalities, we have
significantly improved the performance of multimodal learning, making notable
progress in mitigating imbalanced multimodal learning.",http://arxiv.org/abs/2501.01240v1
"Transport Signatures of Inverted Andreev Bands in Topological Josephson
  Junctions",2025-01-02T15:37:00Z,"Jonathan Sturm, Raffael L. Klees, Ewelina M. Hankiewicz, Daniel Gresta","We study the thermoelectrical transport transverse to conventional and
topological Josephson junctions with a central quantum dot (QD). For that
purpose, we derive an effective resonant tunneling model where the QD is
renormalized with an induced superconducting gap. By applying Keldysh Green's
function technique, we compute the local density of states as well as the
transmission functions. In the latter case, we observe that the Andreev bound
states forming on the QD are inverted if the junction has $p$-wave symmetry,
meaning that electron and hole orbitals switch roles. We calculate the
thermoelectric transport coefficients both analytically and numerically and
show how the induced gaps and the band inversion are reflected in the
electrical and heat conductance as well as the Seebeck coefficient, the latter
experiencing a sign change in the topological case.",http://arxiv.org/abs/2501.01307v1
"SeedVR: Seeding Infinity in Diffusion Transformer Towards Generic Video
  Restoration",2025-01-02T16:19:48Z,"Jianyi Wang, Zhijie Lin, Meng Wei, Yang Zhao, Ceyuan Yang, Fei Xiao, Chen Change Loy, Lu Jiang","Video restoration poses non-trivial challenges in maintaining fidelity while
recovering temporally consistent details from unknown degradations in the wild.
Despite recent advances in diffusion-based restoration, these methods often
face limitations in generation capability and sampling efficiency. In this
work, we present SeedVR, a diffusion transformer designed to handle real-world
video restoration with arbitrary length and resolution. The core design of
SeedVR lies in the shifted window attention that facilitates effective
restoration on long video sequences. SeedVR further supports variable-sized
windows near the boundary of both spatial and temporal dimensions, overcoming
the resolution constraints of traditional window attention. Equipped with
contemporary practices, including causal video autoencoder, mixed image and
video training, and progressive training, SeedVR achieves highly-competitive
performance on both synthetic and real-world benchmarks, as well as
AI-generated videos. Extensive experiments demonstrate SeedVR's superiority
over existing methods for generic video restoration.",http://arxiv.org/abs/2501.01320v3
"Codimensional MultiMeshing: Synchronizing the Evolution of Multiple
  Embedded Geometries",2025-01-02T17:19:02Z,"Michael Tao, Jiacheng Dai, Denis Zorin, Teseo Schneider, Daniele Panozzo","Complex geometric tasks such as geometric modeling, physical simulation, and
texture parametrization often involve the embedding of many complex sub-domains
with potentially different dimensions. These tasks often require evolving the
geometry and topology of the discretizations of these sub-domains, and
guaranteeing a \emph{consistent} overall embedding for the multiplicity of
sub-domains is required to define boundary conditions. We propose a data
structure and algorithmic framework for hierarchically encoding a collection of
meshes, enabling topological and geometric changes to be automatically
propagated with coherent correspondences between them. We demonstrate the
effectiveness of our approach in surface mesh decimation while preserving UV
seams, periodic 2D/3D meshing, and extending the TetWild algorithm to ensure
topology preservation of the embedded structures.",http://arxiv.org/abs/2501.01362v1
ViGiL3D: A Linguistically Diverse Dataset for 3D Visual Grounding,2025-01-02T17:20:41Z,"Austin T. Wang, ZeMing Gong, Angel X. Chang","3D visual grounding (3DVG) involves localizing entities in a 3D scene
referred to by natural language text. Such models are useful for embodied AI
and scene retrieval applications, which involve searching for objects or
patterns using natural language descriptions. While recent works have focused
on LLM-based scaling of 3DVG datasets, these datasets do not capture the full
range of potential prompts which could be specified in the English language. To
ensure that we are scaling up and testing against a useful and representative
set of prompts, we propose a framework for linguistically analyzing 3DVG
prompts and introduce Visual Grounding with Diverse Language in 3D (ViGiL3D), a
diagnostic dataset for evaluating visual grounding methods against a diverse
set of language patterns. We evaluate existing open-vocabulary 3DVG methods to
demonstrate that these methods are not yet proficient in understanding and
identifying the targets of more challenging, out-of-distribution prompts,
toward real-world applications.",http://arxiv.org/abs/2501.01366v1
"Data Acquisition Through Participatory Design for Automated
  Rehabilitation Assessment",2025-01-02T17:33:06Z,"Tamim Ahmed, Zhaoyi Guo, Mohammod Shaikh Sadid Khan, Thanassis Rikakis, Aisling Kelliher","Through participatory design, we are developing a computational system for
the semi-automated assessment of the Action Research Arm Test (ARAT) for stroke
rehabilitation. During rehabilitation assessment, clinicians rate movement
segments and components in the context of overall task performance. Clinicians
change viewing angles to assess particular components. Through studies with
clinicians, we develop a system that includes: a) unobtrusive multi-camera
capture, b) a segmentation interface for non-expert segmentors, and c) a rating
interface for expert clinicians. Five clinicians independently captured 1800
stroke survivor videos with <5$\%$ errors. Three segmentors have segmented 760
of these videos, averaging 20 seconds per segment. They favor the recommended
camera view $>$ 90\%. Multiple clinicians have rated the segmented videos while
reporting minimal problems. The complete data will be used for training an
automated segmentation and rating system that empowers the clinicians as the
ratings will be compatible with clinical practice and intuition.",http://arxiv.org/abs/2501.01374v1
A remark on dimensionality reduction in discrete subgroups,2025-01-02T18:15:08Z,Rodolfo Viera,"In this short note, we prove a version of the Johnson-Lindenstrauss
flattening Lemma for point sets taking values in discrete subgroups. More
precisely, given $d,\lambda_0,N_0\in\mathbb{N}$ and $\epsilon\in
\left(0,\frac{1}{2}\right)$ suitably chosen, we show there exists a natural
number $k=k(d,\epsilon)=O\left(\frac{1}{\epsilon^2}\log d\right)$, such that
for every sufficiently large scaling factor $\lambda\in\mathbb{N}$ and any
point set $\mathcal{D}\subset\frac{\lambda}{\lambda_0}\mathbb{Z}^d\cap
B(0,\lambda N_0)$ with cardinality $d$, there exists an embedding
$F:\mathcal{D}\to\frac{1}{\lambda_0}\mathbb{Z}^k$, with distortion at most
$\left(1+\epsilon+\frac{\epsilon}{\lambda\lambda_0}\right)$.",http://arxiv.org/abs/2501.01396v3
"R-SCoRe: Revisiting Scene Coordinate Regression for Robust Large-Scale
  Visual Localization",2025-01-02T18:59:08Z,"Xudong Jiang, Fangjinhua Wang, Silvano Galliani, Christoph Vogel, Marc Pollefeys","Learning-based visual localization methods that use scene coordinate
regression (SCR) offer the advantage of smaller map sizes. However, on datasets
with complex illumination changes or image-level ambiguities, it remains a less
robust alternative to feature matching methods. This work aims to close the
gap. We introduce a covisibility graph-based global encoding learning and data
augmentation strategy, along with a depth-adjusted reprojection loss to
facilitate implicit triangulation. Additionally, we revisit the network
architecture and local feature extraction module. Our method achieves
state-of-the-art on challenging large-scale datasets without relying on network
ensembles or 3D supervision. On Aachen Day-Night, we are 10$\times$ more
accurate than previous SCR methods with similar map sizes and require at least
5$\times$ smaller map sizes than any other SCR method while still delivering
superior accuracy. Code will be available at: https://github.com/cvg/scrstudio .",http://arxiv.org/abs/2501.01421v1
"Assessing HRV and HR Dynamics with Wearables During Socially Anxious
  Situations: Insights from a Controlled Study in a Low-Middle-Income Country",2025-01-01T10:11:08Z,"Nilesh Kumar Sahu, Snehil Gupta, Haroon R. Lone","This paper investigates physiological markers of Social Anxiety Disorder
(SAD) by examining the relationship between Electrocardiogram (ECG)
measurements and speech, a known anxiety-inducing activity. Specifically, we
analyze changes in heart rate variability (HRV) and heart rate (HR) during four
distinct phases: baseline, anticipation, speech activity, and reflection. Our
study, involving 51 participants (31 with SAD and 20 without), found that HRV
decreased and HR increased during the anticipation and speech activity phases
compared to baseline. In contrast, during the reflection phase, HRV increased
and HR decreased. Additionally, participants with SAD exhibited lower HRV,
higher HR, and reported greater self-perceived anxiety compared to those
without SAD. These findings have implications for developing wearable
technology to monitor SAD. We also provide our dataset, which captures anxiety
across multiple stages, to support further research in this area.",http://arxiv.org/abs/2501.01471v1
"Algebraic perturbation theory: traversable wormholes and generalized
  entropy beyond subleading order",2025-01-02T19:00:00Z,"Shadi Ali Ahmad, Ro Jefferson","The crossed product has recently emerged as an important tool in high-energy
theory. We combine this with another powerful tool, namely pertubation theory,
and study the crossed product algebra of a system under a deformation, relating
the structure of deformed observables to that of the undeformed theory. In
particular, we derive the change in the von Neumann entropy of the type II
algebras, and demonstrate that our approach allows one to formally compute this
to arbitrarily high orders in perturbation theory. As a concrete example, we
apply this machinery to the case of a double-trace deformation of the
thermofield double state in AdS/CFT, which is dual to a traversable wormhole in
the bulk, obtaining several new contributions to the generalized entropy
relative to the original work by Gao, Jafferis, and Wall. We comment on the
relevance of this framework for black hole evaporation and interiors, as well
as on the applicability of the algebraic approach to quantum gravity more
generally.",http://arxiv.org/abs/2501.01487v1
Transfer Neyman-Pearson Algorithm for Outlier Detection,2025-01-02T20:28:53Z,"Mohammadreza M. Kalan, Eitan J. Neugut, Samory Kpotufe","We consider the problem of transfer learning in outlier detection where
target abnormal data is rare. While transfer learning has been considered
extensively in traditional balanced classification, the problem of transfer in
outlier detection and more generally in imbalanced classification settings has
received less attention. We propose a general meta-algorithm which is shown
theoretically to yield strong guarantees w.r.t. to a range of changes in
abnormal distribution, and at the same time amenable to practical
implementation. We then investigate different instantiations of this general
meta-algorithm, e.g., based on multi-layer neural networks, and show
empirically that they outperform natural extensions of transfer methods for
traditional balanced classification settings (which are the only solutions
available at the moment).",http://arxiv.org/abs/2501.01525v1
"In Search of a Lost Metric: Human Empowerment as a Pillar of Socially
  Conscious Navigation",2025-01-02T21:13:46Z,"Vasanth Reddy Baddam, Behdad Chalaki, Vaishnav Tadiparthi, Hossein Nourkhiz Mahjoub, Ehsan Moradi-Pari, Hoda Eldardiry, Almuatazbellah Boker","In social robot navigation, traditional metrics like proxemics and behavior
naturalness emphasize human comfort and adherence to social norms but often
fail to capture an agent's autonomy and adaptability in dynamic environments.
This paper introduces human empowerment, an information-theoretic concept that
measures a human's ability to influence their future states and observe those
changes, as a complementary metric for evaluating social compliance. This
metric reveals how robot navigation policies can indirectly impact human
empowerment. We present a framework that integrates human empowerment into the
evaluation of social performance in navigation tasks. Through numerical
simulations, we demonstrate that human empowerment as a metric not only aligns
with intuitive social behavior, but also shows statistically significant
differences across various robot navigation policies. These results provide a
deeper understanding of how different policies affect social compliance,
highlighting the potential of human empowerment as a complementary metric for
future research in social navigation.",http://arxiv.org/abs/2501.01539v1
"Asymptotic approximations for convection onset with Ekman pumping at low
  wavenumbers",2025-01-02T21:23:17Z,"Sara Tro, Ian Grooms, Keith Julien","Ekman pumping is a phenomenon induced by no-slip boundary conditions in
rotating fluids. In the context of Rayleigh-B\'enard convection, Ekman pumping
causes a significant change in the linear stability of the system compared to
when it is not present (that is, stress-free). Motivated by numerical solutions
to the marginal stability problem of the incompressible Navier-Stokes (iNSE)
system, we seek analytical asymptotic solutions which describe the departure of
the no-slip solution from the stress-free. The substitution of normal modes
into a reduced asymptotic model yields a linear system for which we explore
analytical solutions for various scalings of wavenumber. We find very good
agreement between the analytical asymptotic solutions and the numerical
solutions to the iNSE linear stability problem with no-slip boundary
conditions.",http://arxiv.org/abs/2501.01543v1
"Extended Information Geometry: Large Deviation Theory, Statistical
  Thermodynamics, and Empirical Counting Frequencies",2025-01-02T22:23:28Z,"Viswa Virinchi Muppirala, Hong Qian","Combinatorics, probabilities, and measurements are fundamental to
understanding information. This work explores how the application of large
deviation theory (LDT) in counting phenomena leads to the emergence of various
entropy functions, including Shannon's entropy, mutual information, and
relative and conditional entropies. In terms of these functions, we reveal an
inherent geometrical structure through operations, including contractions,
lift, change of basis, and projections. Legendre-Fenchel (LF) transform, which
is central to both LDT and Gibbs' method of thermodynamics, offers a novel
energetic description of data. The manifold of empirical mean values of
statistical data ad infinitum has a parametrization using LF conjugates w.r.t.
an entropy function; this gives rise to the additivity known in statistical
thermodynamic energetics. This work extends current information geometry to
information projection as defined through conditional expectations in
Kolmogorov's probability theory.",http://arxiv.org/abs/2501.01556v1
"Global existence for small amplitude semilinear wave equations with
  time-dependent scale-invariant damping",2025-01-03T07:02:53Z,"Daoyin He, Yaqing Sun, Kangqun Zhang","In this paper we prove a sharp global existence result for semilinear wave
equations with time-dependent scale-invariant damping terms if the initial data
is small. More specifically, we consider Cauchy problem of
$\partial_t^2u-\Delta u+\frac{\mu}{t}\partial_tu=|u|^p$, where $n\ge 3$, $t\ge
1$ and $\mu\in(0,1)\cup(1,2)$. For critical exponent $p_{crit}(n,\mu)$ which is
the positive root of $(n+\mu-1)p^2-(n+\mu+1)p-2=0$ and conformal exponent
$p_{conf}(n,\mu)=\frac{n+\mu+3}{n+\mu-1}$, we establish global existence for
$n\geq3$ and $p_{crit}(n,\mu)<p\leq p_{conf}(n,\mu)$. The proof is based on
changing the wave equation into the semilinear generalized Tricomi equation
$\partial_t^2u-t^m\Delta u=t^{\alpha(m)}|u|^p$, where $m=m(\mu)>0$ and
$\alpha(m)\in\Bbb R$ are two suitable constants, then we investigate more
general semilinear Tricomi equation $\partial_t^2v-t^m\Delta v=t^{\alpha}|v|^p$
and establish related weighted Strichartz estimates. Returning to the original
wave equation, the corresponding global existence results on the small data
solution $u$ can be obtained.",http://arxiv.org/abs/2501.01670v1
"CrossView-GS: Cross-view Gaussian Splatting For Large-scale Scene
  Reconstruction",2025-01-03T08:24:59Z,"Chenhao Zhang, Yuanping Cao, Lei Zhang","3D Gaussian Splatting (3DGS) has emerged as a prominent method for scene
representation and reconstruction, leveraging densely distributed Gaussian
primitives to enable real-time rendering of high-resolution images. While
existing 3DGS methods perform well in scenes with minor view variation, large
view changes in cross-view scenes pose optimization challenges for these
methods. To address these issues, we propose a novel cross-view Gaussian
Splatting method for large-scale scene reconstruction, based on dual-branch
fusion. Our method independently reconstructs models from aerial and ground
views as two independent branches to establish the baselines of Gaussian
distribution, providing reliable priors for cross-view reconstruction during
both initialization and densification. Specifically, a gradient-aware
regularization strategy is introduced to mitigate smoothing issues caused by
significant view disparities. Additionally, a unique Gaussian supplementation
strategy is utilized to incorporate complementary information of dual-branch
into the cross-view model. Extensive experiments on benchmark datasets
demonstrate that our method achieves superior performance in novel view
synthesis compared to state-of-the-art methods.",http://arxiv.org/abs/2501.01695v1
Sensor Placement on a Cantilever Beam Using Observability Gramians,2025-01-03T09:36:21Z,"Natalie L. Brace, Nicholas B. Andrews, Jeremy Upsal, Kristi A. Morgansen","Working from an observability characterization based on output energy
sensitivity to changes in initial conditions, we derive both analytical and
empirical observability Gramian tools for a class of continuum material
systems. Using these results, optimal sensor placement is calculated for an
Euler-Bernoulli cantilever beam for the following cases: analytical
observability for the continuum system and analytical observability for a
finite number of modes. Error covariance of an Unscented Kalman Filter is
determined for both cases and compared to randomly placed sensors to
demonstrate effectiveness of the techniques.",http://arxiv.org/abs/2501.01726v1
SaLoRA: Safety-Alignment Preserved Low-Rank Adaptation,2025-01-03T11:34:28Z,"Mingjie Li, Wai Man Si, Michael Backes, Yang Zhang, Yisen Wang","As advancements in large language models (LLMs) continue and the demand for
personalized models increases, parameter-efficient fine-tuning (PEFT) methods
(e.g., LoRA) will become essential due to their efficiency in reducing
computation costs. However, recent studies have raised alarming concerns that
LoRA fine-tuning could potentially compromise the safety alignment in LLMs,
posing significant risks for the model owner. In this paper, we first
investigate the underlying mechanism by analyzing the changes in safety
alignment related features before and after fine-tuning. Then, we propose a
fixed safety module calculated by safety data and a task-specific
initialization for trainable parameters in low-rank adaptations, termed
Safety-alignment preserved Low-Rank Adaptation (SaLoRA). Unlike previous LoRA
methods and their variants, SaLoRA enables targeted modifications to LLMs
without disrupting their original alignments. Our experiments show that SaLoRA
outperforms various adapters-based approaches across various evaluation metrics
in different fine-tuning tasks.",http://arxiv.org/abs/2501.01765v1
Some remarks on plane curves related to freeness,2025-01-03T13:39:48Z,Alexandru Dimca,"Let $C$ be a reduced complex projective plane curve, and let $d_1$ and $d_2$
be the first two smallest exponents of $C$. For a free curve $C$ of degree $d$,
there is a simple formula relating $d,d_1, d_2$ and the total Tjurina number of
$C$. Our first result discusses how this result changes when the curve $C$ is
no longer free. For a free line arrangement, the Poincar\'e polynomial
coincides with the Betti polynomial $B(t)$ and with the product
$P(t)=(1+d_1t)(1+d_2t)$. Our second result shows that for any curve $C$, the
difference $P(t)-B(t)$ is a polynomial $a t +bt^2$, with $a$ and $b$
non-negative integers. Moreover $a =0$ or $b=0$ if and only if $C$ is a free
line arrangement. Finally we give new bounds for the second exponent $d_2$ of a
line arrangement $\mathcal A$, the corresponding lower bound being an
improvement of a result by H. Schenck concerning the relation between the
maximal exponent of $\mathcal A$ and the maximal multiplicity of points in
$\mathcal A$.",http://arxiv.org/abs/2501.01807v4
"A stable phase-locking-free single beam optical lattice with multiple
  configurations",2025-01-03T14:52:59Z,"Yirong Wang, Xiaoyu Dai, Xue Zhao, Guangren Sun, Kuiyi Gao, Wei Zhang","Optical lattices formed by interfering laser beams are widely used to trap
and manipulate atoms for quantum simulation, metrology, and computation. To
stabilize optical lattices in experiments, it is usually challenging to
implement delicate phase-locking systems with complicated optics and
electronics to reduce the relative phase fluctuation of multiple laser beams.
Here we report a phase-locking-free scheme to implement optical lattices by
passing a single laser beam through a prism with n-fold symmetric facets and
large apex angles. The scheme ensures a stable optical lattice since the
interference occurs among different deflected parts of a single laser beam
without any moving component. Various lattice configurations, including a
triangular lattice and a quasi-crystal lattice with ten-fold symmetry are
demonstrated. In both cases, stability measurements show a change of lattice
constant in less than 1.14%, and a drift of lattice position in less than
1.61%.",http://arxiv.org/abs/2501.01843v1
"CycleFlow: Leveraging Cycle Consistency in Flow Matching for Speaker
  Style Adaptation",2025-01-03T15:18:30Z,"Ziqi Liang, Xulong Zhang, Chang Liu, Xiaoyang Qu, Weifeng Zhao, Jianzong Wang","Voice Conversion (VC) aims to convert the style of a source speaker, such as
timbre and pitch, to the style of any target speaker while preserving the
linguistic content. However, the ground truth of the converted speech does not
exist in a non-parallel VC scenario, which induces the train-inference mismatch
problem. Moreover, existing methods still have an inaccurate pitch and low
speaker adaptation quality, there is a significant disparity in pitch between
the source and target speaker style domains. As a result, the models tend to
generate speech with hoarseness, posing challenges in achieving high-quality
voice conversion. In this study, we propose CycleFlow, a novel VC approach that
leverages cycle consistency in conditional flow matching (CFM) for speaker
timbre adaptation training on non-parallel data. Furthermore, we design a
Dual-CFM based on VoiceCFM and PitchCFM to generate speech and improve speaker
pitch adaptation quality. Experiments show that our method can significantly
improve speaker similarity, generating natural and higher-quality speech.",http://arxiv.org/abs/2501.01861v1
"Latent Mutants: A large-scale study on the Interplay between mutation
  testing and software evolution",2025-01-03T15:44:38Z,"Jeongju Sohn, Ezekiel Soremekun, Michail Papadakis","In this paper we apply mutation testing in an in-time fashion, i.e., across
multiple project releases. Thus, we investigate how the mutants of the current
version behave in the future versions of the programs. We study the
characteristics of what we call latent mutants, i.e., the mutants that are live
in one version and killed in later revisions, and explore whether they are
predictable with these properties. We examine 131,308 mutants generated by
Pitest on 13 open-source projects. Around 11.2% of these mutants are live, and
3.5% of them are latent, manifesting in 104 days on average. Using the mutation
operators and change-related features we successfully demonstrate that these
latent mutants are identifiable, predicting them with an accuracy of 86% and a
balanced accuracy of 67% using a simple random forest classifier.",http://arxiv.org/abs/2501.01873v1
"Exploring Equality: An Investigation into Custom Loss Functions for
  Fairness Definitions",2025-01-03T16:49:17Z,"Gordon Lee, Simeon Sayer","This paper explores the complex tradeoffs between various fairness metrics
such as equalized odds, disparate impact, and equal opportunity and predictive
accuracy within COMPAS by building neural networks trained with custom loss
functions optimized to specific fairness criteria. This paper creates the first
fairness-driven implementation of the novel Group Accuracy Parity (GAP)
framework, as theoretically proposed by Gupta et al. (2024), and applies it to
COMPAS. To operationalize and accurately compare the fairness of COMPAS models
optimized to differing fairness ideals, this paper develops and proposes a
combinatory analytical procedure that incorporates Pareto front and
multivariate analysis, leveraging data visualizations such as violin graphs.
This paper concludes that GAP achieves an enhanced equilibrium between fairness
and accuracy compared to COMPAS's current nationwide implementation and
alternative implementations of COMPAS optimized to more traditional fairness
definitions. While this paper's algorithmic improvements of COMPAS
significantly augment its fairness, external biases undermine the fairness of
its implementation. Practices such as predictive policing and issues such as
the lack of transparency regarding COMPAS's internal workings have contributed
to the algorithm's historical injustice. In conjunction with developments
regarding COMPAS's predictive methodology, legal and institutional changes must
happen for COMPAS's just deployment.",http://arxiv.org/abs/2501.01889v1
"Dissociation of Adsorbates via Electronic Energy Transfer from Aromatic
  Thin Films",2025-01-03T18:23:14Z,E. T. Jensen,"Photofragment translational spectroscopy has been used to characterize the
photodissociation of CH$_3$I and CF$_3$I adsorbed on thin films of a variety of
aromatic molecules, initiated by near-UV light. Thin films (nominally 10
monolayers) of benzene, five substituted benzenes and two naphthalenes have
been employed to study systematic changes in the photochemical activity.
Illumination of these systems with 248nm light is found to result in a
dissociation process for the CH$_3$I and CF$_3$I mediated by initial absorption
in the aromatic thin film, followed by electronic energy transfer (EET) to the
dissociating species. The effective cross sections for dissociation are found
to be substantially increased via this mechanism, by amounts that differ
depending on the aromatic molecule thin film used, and is connected to the
aromatic photabsorption profile. Distinctive translational energy distributions
for the CH$_3$ and CF$_3$ photofragments are found to vary systematically for
the different aromatic molecule thin film used, and are related to the aromatic
molecule excited states. The CH$_3$ and CF$_3$ photofragment kinetic energy
distributions found for the aromatic thin films suggest that the dissociation
occurs via EET to the $^3Q_1$ excited state of CH$_3$I and CF$_3$I.",http://arxiv.org/abs/2501.01937v1
"Safeguarding Large Language Models in Real-time with Tunable
  Safety-Performance Trade-offs",2025-01-02T15:15:38Z,"Joao Fonseca, Andrew Bell, Julia Stoyanovich","Large Language Models (LLMs) have been shown to be susceptible to jailbreak
attacks, or adversarial attacks used to illicit high risk behavior from a
model. Jailbreaks have been exploited by cybercriminals and blackhat actors to
cause significant harm, highlighting the critical need to safeguard
widely-deployed models. Safeguarding approaches, which include fine-tuning
models or having LLMs ""self-reflect"", may lengthen the inference time of a
model, incur a computational penalty, reduce the semantic fluency of an output,
and restrict ``normal'' model behavior. Importantly, these Safety-Performance
Trade-offs (SPTs) remain an understudied area. In this work, we introduce a
novel safeguard, called SafeNudge, that combines Controlled Text Generation
with ""nudging"", or using text interventions to change the behavior of a model.
SafeNudge triggers during text-generation while a jailbreak attack is being
executed, and can reduce successful jailbreak attempts by 30% by guiding the
LLM towards a safe responses. It adds minimal latency to inference and has a
negligible impact on the semantic fluency of outputs. Further, we allow for
tunable SPTs. SafeNudge is open-source and available through https://pypi.org/,
and is compatible with models loaded with the Hugging Face ""transformers""
library.",http://arxiv.org/abs/2501.02018v1
"Relational bundle geometric formulation of non-relativistic quantum
  mechanics",2025-01-03T19:00:00Z,"J. François, L. Ravera","We present a bundle geometric formulation of non-relativistic many-particles
Quantum Mechanics. A wave function is seen to be a $\mathbb{C}$-valued cocyclic
tensorial 0-form on configuration space-time seen as a principal bundle, while
the Schr\""odinger equation flows from its covariant derivative, with the action
functional supplying a (flat) cocyclic connection 1-form on the configuration
bundle. In line with the historical motivations of Dirac and Feynman, ours is
thus a Lagrangian geometric formulation of QM, in which the Dirac-Feynman path
integral arises in a geometrically natural way.
  Applying the dressing field method, we obtain a relational reformulation of
this geometric non-relativistic QM: a relational wave function is realised as a
basic cocyclic 0-form on the configuration bundle. In this relational QM, any
particle position can be used as a dressing field, i.e. as a ""physical
reference frame"". The dressing field method naturally accounts for the freedom
in choosing the dressing field, which is readily understood as a covariance of
the relational formulation under changes of physical reference frame.",http://arxiv.org/abs/2501.02046v1
"Sporadic Dips from Extended Debris Transiting the Metal-Rich White Dwarf
  SBSS 1232+563",2025-01-03T19:00:01Z,"J. J. Hermes, Joseph A. Guidry, Zachary P. Vanderbosch, Mariona Badenas-Agusti, Siyi Xu, Malia L. Kao, Antonio C. Rodriguez, Keith Hawkins","We present the discovery of deep but sporadic transits in the flux of SBSS
1232+563, a metal-rich white dwarf polluted by disrupted exoplanetary debris.
Nearly 25 years of photometry from multiple sky surveys reveal evidence of
occasional dimming of the white dwarf, most notably evident in an 8-months-long
event in 2023 that caused a >40% drop in flux from the star. In-transit
follow-up shows additional short-timescale (minutes- to hours-long) dimming
events. TESS photometry suggests a coherent 14.842-hr signal that could
represent the dominant orbital period of debris. Six low-resolution spectra
collected at various transit depths over two decades show no evidence of
significant changes in the observed elemental abundances. SBSS 1232+563
demonstrates that debris transits around white dwarfs can be sporadic, with
many years of inactivity before large-amplitude dimming events.",http://arxiv.org/abs/2501.02050v1
"Topological insights into dense frictional suspension rheology: Third
  order loops drive discontinuous shear thickening",2025-01-03T19:12:21Z,"Alessandro D'Amico, Sidong Tu, Abhinendra Singh","Dense suspensions exhibit significant viscosity changes under external
deformation, a phenomenon known as shear thickening. Recent studies have
identified a stress-induced transition from lubricated, unconstrained
interactions to frictional contacts, which play a crucial role in shear
thickening. This work investigates the rheological behavior and contact network
evolution during continuous and discontinuous shear thickening (CST and DST) in
two-dimensional simulations. We find that at low stress, during weak
thickening, the frictional contact network is composed of quasilinear chains
along the compression axis. With increasing stress, the contact network becomes
more isotropic, and forms loop-like structures. We show that third-order loops
within the frictional contact network are key to this behavior. Our findings
revealed a strong correlation between the number of edges in the third-order
loops and the viscosity of the suspension. Notably, this relationship remains
independent of the packing fraction, applied stress, and interparticle
friction, highlighting the fundamental role of the mesoscale network topology
in governing macroscopic rheology.",http://arxiv.org/abs/2501.02062v1
"PriveShield: Enhancing User Privacy Using Automatic Isolated Profiles in
  Browsers",2025-01-03T20:29:33Z,"Seyed Ali Akhavani, Engin Kirda, Amin Kharraz","Online tracking is a widespread practice on the web with questionable ethics,
security, and privacy concerns. While web tracking can offer personalized and
curated content to Internet users, it operates as a sophisticated surveillance
mechanism to gather extensive user information. This paper introduces
PriveShield, a light-weight privacy mechanism that disrupts the information
gathering cycle while offering more control to Internet users to maintain their
privacy. PriveShield is implemented as a browser extension that offers an
adjustable privacy feature to surf the web with multiple identities or accounts
simultaneously without any changes to underlying browser code or services. When
necessary, multiple factors are automatically analyzed on the client side to
isolate cookies and other information that are the basis of online tracking.
PriveShield creates isolated profiles for clients based on their browsing
history, interactions with websites, and the amount of time they spend on
specific websites. This allows the users to easily prevent unwanted browsing
information from being shared with third parties and ad exchanges without the
need for manual configuration. Our evaluation results from 54 real-world
scenarios show that our extension is effective in preventing retargeted ads in
91% of those scenarios.",http://arxiv.org/abs/2501.02091v1
"How Your Location Relates to Health: Variable Importance and
  Interpretable Machine Learning for Environmental and Sociodemographic Data",2025-01-03T21:34:35Z,"Ishaan Maitra, Raymond Lin, Eric Chen, Jon Donnelly, Sanja Šćepanović, Cynthia Rudin","Health outcomes depend on complex environmental and sociodemographic factors
whose effects change over location and time. Only recently has fine-grained
spatial and temporal data become available to study these effects, namely the
MEDSAT dataset of English health, environmental, and sociodemographic
information. Leveraging this new resource, we use a variety of variable
importance techniques to robustly identify the most informative predictors
across multiple health outcomes. We then develop an interpretable machine
learning framework based on Generalized Additive Models (GAMs) and Multiscale
Geographically Weighted Regression (MGWR) to analyze both local and global
spatial dependencies of each variable on various health outcomes. Our findings
identify NO2 as a global predictor for asthma, hypertension, and anxiety,
alongside other outcome-specific predictors related to occupation, marriage,
and vegetation. Regional analyses reveal local variations with air pollution
and solar radiation, with notable shifts during COVID. This comprehensive
approach provides actionable insights for addressing health disparities, and
advocates for the integration of interpretable machine learning in public
health.",http://arxiv.org/abs/2501.02111v1
"The onset of nonpenetrative convection in a suddenly cooled layer of
  fluid",2025-01-03T23:00:23Z,"C F Ihle, Y Niño","Conditions for the onset of nonpenetrative convection in a horizontal
Boussinesq fluid layer subject to a step change in temperature are studied
using propagation theory. A wide range of Prandtl numbers and two different
kinematic boundary conditions are considered. It is shown that for high
Rayleigh numbers, critical conditions for the onset of convective motion
reproduce exactly those for the unsteady Rayleigh-B\'enard instability. Present
results extend those of previous research and show a tendency of the
rigid-rigid and free-rigid critical curves to converge for low Prandtl numbers.
Comparison between present and previously reported results on critical
conditions for the onset of instabilities and onset time using different
methods yields good agreement on a middle to high Prandtl number range. A ratio
of 10 between experimentally measured and theoretically predicted onset times
is suggested for stress-free bounded systems.",http://arxiv.org/abs/2501.02134v2
The Application of Large Language Models in Recommendation Systems,2025-01-04T04:02:23Z,"Peiyang Yu, Zeqiu Xu, Jiani Wang, Xiaochuan Xu","The integration of Large Language Models into recommendation frameworks
presents key advantages for personalization and adaptability of experiences to
the users. Classic methods of recommendations, such as collaborative filtering
and content-based filtering, are seriously limited in the solution of
cold-start problems, sparsity of data, and lack of diversity in information
considered. LLMs, of which GPT-4 is a good example, have emerged as powerful
tools that enable recommendation frameworks to tap into unstructured data
sources such as user reviews, social interactions, and text-based content. By
analyzing these data sources, LLMs improve the accuracy and relevance of
recommendations, thereby overcoming some of the limitations of traditional
approaches. This work discusses applications of LLMs in recommendation systems,
especially in electronic commerce, social media platforms, streaming services,
and educational technologies. This showcases how LLMs enrich recommendation
diversity, user engagement, and the system's adaptability; yet it also looks
into the challenges connected to their technical implementation. This can also
be presented as a study that shows the potential of LLMs for changing user
experiences and making innovation possible in industries.",http://arxiv.org/abs/2501.02178v2
"AdaMixup: A Dynamic Defense Framework for Membership Inference Attack
  Mitigation",2025-01-04T04:21:48Z,"Ying Chen, Jiajing Chen, Yijie Weng, ChiaHua Chang, Dezhi Yu, Guanbiao Lin","Membership inference attacks have emerged as a significant privacy concern in
the training of deep learning models, where attackers can infer whether a data
point was part of the training set based on the model's outputs. To address
this challenge, we propose a novel defense mechanism, AdaMixup. AdaMixup
employs adaptive mixup techniques to enhance the model's robustness against
membership inference attacks by dynamically adjusting the mixup strategy during
training. This method not only improves the model's privacy protection but also
maintains high performance. Experimental results across multiple datasets
demonstrate that AdaMixup significantly reduces the risk of membership
inference attacks while achieving a favorable trade-off between defensive
efficiency and model accuracy. This research provides an effective solution for
data privacy protection and lays the groundwork for future advancements in
mixup training methods.",http://arxiv.org/abs/2501.02182v1
"Examining the Robustness of Homogeneity Bias to Hyperparameter
  Adjustments in GPT-4",2025-01-04T06:51:49Z,Messi H. J. Lee,"Vision-Language Models trained on massive collections of human-generated data
often reproduce and amplify societal stereotypes. One critical form of
stereotyping reproduced by these models is homogeneity bias-the tendency to
represent certain groups as more homogeneous than others. We investigate how
this bias responds to hyperparameter adjustments in GPT-4, specifically
examining sampling temperature and top p which control the randomness of model
outputs. By generating stories about individuals from different racial and
gender groups and comparing their similarities using vector representations, we
assess both bias robustness and its relationship with hyperparameter values. We
find that (1) homogeneity bias persists across most hyperparameter
configurations, with Black Americans and women being represented more
homogeneously than White Americans and men, (2) the relationship between
hyperparameters and group representations shows unexpected non-linear patterns,
particularly at extreme values, and (3) hyperparameter adjustments affect
racial and gender homogeneity bias differently-while increasing temperature or
decreasing top p can reduce racial homogeneity bias, these changes show
different effects on gender homogeneity bias. Our findings suggest that while
hyperparameter tuning may mitigate certain biases to some extent, it cannot
serve as a universal solution for addressing homogeneity bias across different
social group dimensions.",http://arxiv.org/abs/2501.02211v1
"Interpretable Load Forecasting via Representation Learning of
  Geo-distributed Meteorological Factors",2025-01-04T09:05:06Z,"Yangze Zhou, Guoxin Lin, Gonghao Zhang, Yi Wang","Meteorological factors (MF) are crucial in day-ahead load forecasting as they
significantly influence the electricity consumption behaviors of consumers.
Numerous studies have incorporated MF into the load forecasting model to
achieve higher accuracy. Selecting MF from one representative location or the
averaged MF as the inputs of the forecasting model is a common practice.
However, the difference in MF collected in various locations within a region
may be significant, which poses a challenge in selecting the appropriate MF
from numerous locations. A representation learning framework is proposed to
extract geo-distributed MF while considering their spatial relationships. In
addition, this paper employs the Shapley value in the graph-based model to
reveal connections between MF collected in different locations and loads. To
reduce the computational complexity of calculating the Shapley value, an
acceleration method is adopted based on Monte Carlo sampling and weighted
linear regression. Experiments on two real-world datasets demonstrate that the
proposed method improves the day-ahead forecasting accuracy, especially in
extreme scenarios such as the ""accumulation temperature effect"" in summer and
""sudden temperature change"" in winter. We also find a significant correlation
between the importance of MF in different locations and the corresponding
area's GDP and mainstay industry.",http://arxiv.org/abs/2501.02241v1
"The Effect of Capital Share on Income Inequality: Identifying the Time
  Patterns",2025-01-04T20:15:42Z,"Oğuzhan Akgün, Ezgi Özsöğüt","This study explores the link between the capital share and income inequality
over the past four decades across 56 countries. Calculating the capital share
from national accounts alongside top income share data from the World
Inequality Database, which is based on the Distributional National Accounts
methodology, we ensure the consistency in the theory and measurement. Employing
a structural econometric approach, we account for heterogeneous and
time-varying transmission coefficients from the capital share to personal
income inequality. Our findings reveal that a one percentage point (pp)
increase in the capital share raises the income share of the top 5% by 0.17 pp
on average. Advanced economies show a stable transmission coefficient with
rising capital and labor income inequality, while emerging economies experience
an increasing transmission coefficient alongside growing capital income
inequality. In contrast, a third group exhibits a declining transmission
coefficient and rising labor income inequality. Overall, changes in the capital
share account for approximately 50% of the rise in income inequality,
underscoring its pivotal role over the last four decades.",http://arxiv.org/abs/2501.02371v1
"iTARGET: Interpretable Tailored Age Regression for Grouped Epigenetic
  Traits",2025-01-04T23:06:46Z,"Zipeng Wu, Daniel Herring, Fabian Spill, James Andrews","Accurately predicting chronological age from DNA methylation patterns is
crucial for advancing biological age estimation. However, this task is made
challenging by Epigenetic Correlation Drift (ECD) and Heterogeneity Among CpGs
(HAC), which reflect the dynamic relationship between methylation and age
across different life stages. To address these issues, we propose a novel
two-phase algorithm. The first phase employs similarity searching to cluster
methylation profiles by age group, while the second phase uses Explainable
Boosting Machines (EBM) for precise, group-specific prediction. Our method not
only improves prediction accuracy but also reveals key age-related CpG sites,
detects age-specific changes in aging rates, and identifies pairwise
interactions between CpG sites. Experimental results show that our approach
outperforms traditional epigenetic clocks and machine learning models, offering
a more accurate and interpretable solution for biological age estimation with
significant implications for aging research.",http://arxiv.org/abs/2501.02401v1
Asynchronous Hebbian/anti-Hebbian networks,2025-01-04T23:11:24Z,"Henrique Reis Aguiar, Matthias H. Hennig","Lateral inhibition models coupled with Hebbian plasticity have been shown to
learn factorised causal representations of input stimuli, for instance,
oriented edges are learned from natural images. Currently, these models require
the recurrent dynamics to settle into a stable state before weight changes can
be applied, which is not only biologically implausible, but also impractical
for real-time learning systems. Here, we propose a new Hebbian learning rule
which is implemented using plausible biological mechanisms that have been
observed experimentally. We find that this rule allows for efficient,
time-continuous learning of factorised representations, very similar to the
classic noncontinuous Hebbian/anti-Hebbian learning. Furthermore, we show that
this rule naturally prevents catastrophic forgetting when stimuli from
different distributions are shown sequentially.",http://arxiv.org/abs/2501.02402v1
"Interpretable Neural ODEs for Gene Regulatory Network Discovery under
  Perturbations",2025-01-05T01:04:23Z,"Zaikang Lin, Sei Chang, Aaron Zweig, Minseo Kang, Elham Azizi, David A. Knowles","Modern high-throughput biological datasets with thousands of perturbations
provide the opportunity for large-scale discovery of causal graphs that
represent the regulatory interactions between genes. Differentiable causal
graphical models have been proposed to infer a gene regulatory network (GRN)
from large scale interventional datasets, capturing the causal gene regulatory
relationships from genetic perturbations. However, existing models are limited
in their expressivity and scalability while failing to address the dynamic
nature of biological processes such as cellular differentiation. We propose
PerturbODE, a novel framework that incorporates biologically informative neural
ordinary differential equations (neural ODEs) to model cell state trajectories
under perturbations and derive the causal GRN from the neural ODE's parameters.
We demonstrate PerturbODE's efficacy in trajectory prediction and GRN inference
across simulated and real over-expression datasets.",http://arxiv.org/abs/2501.02409v2
"RTLMarker: Protecting LLM-Generated RTL Copyright via a Hardware
  Watermarking Framework",2025-01-05T05:38:28Z,"Kun Wang, Kaiyan Chang, Mengdi Wang, Xinqi Zou, Haobo Xu, Yinhe Han, Ying Wang","Recent advances of large language models in the field of Verilog generation
have raised several ethical and security concerns, such as code copyright
protection and dissemination of malicious code. Researchers have employed
watermarking techniques to identify codes generated by large language models.
However, the existing watermarking works fail to protect RTL code copyright due
to the significant syntactic and semantic differences between RTL code and
software code in languages such as Python. This paper proposes a hardware
watermarking framework RTLMarker that embeds watermarks into RTL code and
deeper into the synthesized netlist. We propose a set of rule-based Verilog
code transformations , ensuring the watermarked RTL code's syntactic and
semantic correctness. In addition, we consider an inherent tradeoff between
watermark transparency and watermark effectiveness and jointly optimize them.
The results demonstrate RTLMarker's superiority over the baseline in RTL code
watermarking.",http://arxiv.org/abs/2501.02446v1
The Meta-Representation Hypothesis,2025-01-05T09:06:17Z,"Zhengpeng Xie, Jiahang Cao, Qiang Zhang, Jianxiong Zhang, Changwei Wang, Renjing Xu","Humans rely on high-level understandings of things, i.e.,
meta-representations, to engage in abstract reasoning. In complex cognitive
tasks, these meta-representations help individuals abstract general rules from
experience. However, constructing such meta-representations from
high-dimensional observations remains a longstanding challenge for
reinforcement learning (RL) agents. For instance, a well-trained agent often
fails to generalize to even minor variations of the same task, such as changes
in background color, while humans can easily handle. In this paper, we
theoretically investigate how meta-representations contribute to the
generalization ability of RL agents, demonstrating that learning
meta-representations from high-dimensional observations enhance an agent's
ability to generalize across varied environments. We further hypothesize that
deep mutual learning (DML) among agents can help them learn the
meta-representations that capture the underlying essence of the task. Empirical
results provide strong support for both our theory and hypothesis. Overall,
this work provides a new perspective on the generalization of deep
reinforcement learning.",http://arxiv.org/abs/2501.02481v3
Surfacic networks,2025-01-05T09:26:17Z,"Marc Barthelemy, Geoff Boeing, Alain Chiarada, Chris Webster","Surfacic networks are structures built upon a two-dimensional manifold. Many
systems, including transportation networks and various urban networks, fall
into this category. The fluctuations of node elevations imply significant
deviations from typical plane networks and require specific tools to understand
their impact. Here, we present such tools, including lazy paths that minimize
elevation differences, graph arduousness which measures the tiring nature of
shortest paths, and the excess effort, which characterizes positive elevation
variations along shortest paths. We illustrate these measures using toy models
of surfacic networks and empirically examine pedestrian networks in selected
cities. Specifically, we examine how changes in elevation affect the spatial
distribution of betweenness centrality. We also demonstrate that the excess
effort follows a non-trivial power law distribution, with an exponent that is
not universal, which illustrates that there is a significant probability of
encountering steep slopes along shortest paths, regardless of the elevation
difference between the starting point and the destination. These findings
highlight the significance of elevation fluctuations in shaping network
characteristics. Surfacic networks offer a promising framework for
comprehensively analyzing and modeling complex systems that are situated on or
constrained to a surface environment.",http://arxiv.org/abs/2501.02484v1
"Remote Inference over Dynamic Links via Adaptive Rate Deep Task-Oriented
  Vector Quantization",2025-01-05T12:38:13Z,"Eyal Fishel, May Malka, Shai Ginzach, Nir Shlezinger","A broad range of technologies rely on remote inference, wherein data acquired
is conveyed over a communication channel for inference in a remote server.
Communication between the participating entities is often carried out over
rate-limited channels, necessitating data compression for reducing latency.
While deep learning facilitates joint design of the compression mapping along
with encoding and inference rules, existing learned compression mechanisms are
static, and struggle in adapting their resolution to changes in channel
conditions and to dynamic links. To address this, we propose Adaptive Rate
Task-Oriented Vector Quantization (ARTOVeQ), a learned compression mechanism
that is tailored for remote inference over dynamic links. ARTOVeQ is based on
designing nested codebooks along with a learning algorithm employing
progressive learning. We show that ARTOVeQ extends to support low-latency
inference that is gradually refined via successive refinement principles, and
that it enables the simultaneous usage of multiple resolutions when conveying
high-dimensional data. Numerical results demonstrate that the proposed scheme
yields remote deep inference that operates with multiple rates, supports a
broad range of bit budgets, and facilitates rapid inference that gradually
improves with more bits exchanged, while approaching the performance of
single-rate deep quantization methods.",http://arxiv.org/abs/2501.02521v1
"AMM: Adaptive Modularized Reinforcement Model for Multi-city Traffic
  Signal Control",2025-01-05T13:59:08Z,"Zherui Huang, Yicheng Liu, Chumeng Liang, Guanjie Zheng","Traffic signal control (TSC) is an important and widely studied direction.
Recently, reinforcement learning (RL) methods have been used to solve TSC
problems and achieve superior performance over conventional TSC methods.
However, applying RL methods to the real world is challenging due to the huge
cost of experiments in real-world traffic environments. One possible solution
is TSC domain adaptation, which adapts trained models to target environments
and reduces the number of interactions and the training cost. However, existing
TSC domain adaptation methods still face two major issues: the lack of
consideration for differences across cities and the low utilization of
multi-city data.
  To solve aforementioned issues, we propose an approach named Adaptive
Modularized Model (AMM). By modularizing TSC problems and network models, we
overcome the challenge of possible changes in environmental observations. We
also aggregate multi-city experience through meta-learning. We conduct
extensive experiments on different cities and show that AMM can achieve
excellent performance with limited interactions in target environments and
outperform existing methods. We also demonstrate the feasibility and
generalizability of our method.",http://arxiv.org/abs/2501.02548v1
Feshbach resonances and dynamics of BPS solitons,2025-01-05T15:49:13Z,"Alberto García Martín-Caro, Jose Queiruga, Andrzej Wereszczynski","We demonstrate that the geodesic dynamics of BPS solitons can be modified by
the excitation of Feshbach resonances, or quasi-bound modes, in a toy model of
two scalar fields. A mode-generated force emerges, with a strength determined
by the spectral flow of the frequency on the moduli space, and weakened by the
coupling between the bound and scattering components of the resonance. Notably,
spectral walls persist unaffected by the resonant mode's exponential decay, as
the decay constant vanishes at the spectral wall. Our motivation comes from the
't Hooft-Polyakov monopoles, which do not present true bound states but long
lived semi-bound excitations. Our findings suggest the existence of spectral
walls in the scattering of excited monopoles in three dimensions, whose
trajectories may significantly deviate from the geodesic motion in the moduli
space of unexcited monopoles.",http://arxiv.org/abs/2501.02589v2
"A System for Melodic Harmonization using Schoenberg Regions, Giant
  Steps, and Church Modes",2025-01-05T20:08:42Z,Frederick Fernandes,"Systems such as Microsoft Songsmith automatically assign chords and harmony
to a melody by minimizing the dissonance across all chord changes. Although
this produces harmonious music, it is not what practicing musicians do. In this
paper, I describe Harmonizer, a prototype system for melodic harmonization.
Harmonizer uses Schoenberg's chart of regions as the underlying data structure
that allows harmonization using several different methods. Because the chart
reveals inter-chordal relationships, the harmonizations may be programmed to
emphasize desired relationships. In the prototype Harmonizer, I also explore
recent signal-processing methods that enable songwriters to easily input a
melody by singing or by playing a musical instrument. The prototype Harmonizer
is available on GitHub and a video demonstrating its distinctive harmonizations
is on YouTube as explained in the Results section of the paper.",http://arxiv.org/abs/2501.02642v1
"From Superficial Patterns to Semantic Understanding: Fine-Tuning
  Language Models on Contrast Sets",2025-01-05T23:19:55Z,Daniel Petrov,"Large-scale pre-trained language models have demonstrated high performance on
standard datasets for natural language inference (NLI) tasks. Unfortunately,
these evaluations can be misleading, as although the models can perform well on
in-distribution data, they perform poorly on out-of-distribution test sets,
such as contrast sets. Contrast sets consist of perturbed instances of data
that have very minor, but meaningful, changes to the input that alter the gold
label, revealing how models can learn superficial patterns in the training data
rather than learning more sophisticated language nuances. As an example, the
ELECTRA-small language model achieves nearly 90% accuracy on an SNLI dataset
but drops to 75% when tested on an out-of-distribution contrast set. The
research carried out in this study explores how the robustness of a language
model can be improved by exposing it to small amounts of more complex contrast
sets during training to help it better learn language patterns. With this
approach, the model recovers performance and achieves nearly 90% accuracy on
contrast sets, highlighting the importance of diverse and challenging training
data.",http://arxiv.org/abs/2501.02683v2
"Anomalous Magnetotransport in the Paramagnetic State of a Magnetic
  Kagome Metal EuTi$_3$Bi$_4$",2025-01-06T03:27:59Z,"Yun Shu, Xinrun Mi, Yuhao Wei, Sixue Tao, Aifeng Wang, Yisheng Chai, Dashuai Ma, Xiaolong Yang, Mingquan He","We investigate the electrical transport properties of a magnetic kagome metal
EuTi$_3$Bi$_4$, which undergoes magnetic ordering below $T_\mathrm{c}=10.5$ K.
Unlike typical magnets showing anomalous magnetotransport in their ordered
states, EuTi$_3$Bi$_4$ exhibits unusual magnetotransport behaviors in its
paramagnetic phase. Specifically, the magnetoconductivity shows a linear
dependence on magnetic field at low fields below $\sim 1$ T, and the Hall
conductivity undergoes a sign change below about 2 T. These behaviors resemble
those observed in the charge density wave (CDW) phase of kagome metals
$A$V$_3$Sb$_5$ ($A$ = K, Rb, Cs). The anomalous magnetotransport in
$A$V$_3$Sb$_5$ has commonly been attributed to the possible emergence of a
time-reversal symmetry breaking chiral CDW order. However, given the absence of
CDW in EuTi$_3$Bi$_4$ and its manifestation exclusively in the paramagnetic
state, the anomalous magnetotransport observed in EuTi$_3$Bi$_4$ is likely
associated with multiband transport and/or the van Hove singularities near the
Fermi level.",http://arxiv.org/abs/2501.02743v2
"Bifurcations and stability of synchronized solutions in the Kuramoto
  model with uniformly spaced natural frequencies",2025-01-06T10:07:17Z,Kazuyuki Yagasaki,"We consider the classical Kuramoto model (KM) with natural frequencies and
its continuum limit (CL), and discuss the existence of synchronized solutions
and their bifurcations and stability. We specifically assume that the frequency
function is symmetric and linear in the CL, so that the natural frequencies are
evenly spaced in the KM. We show that in the KM, $O(2^n)$ one-parameter
families of synchronized solutions are born and $O(2^n)$ {saddle-node and}
pitchfork bifurcations occur at least, when the node number $n$ is odd and
tends to infinity. Moreover, we prove that the family of synchronized solutions
obtained in the previous work suffers a saddle-node bifurcation at which its
stability changes from asymptotically stable to unstable and the other families
of synchronized solutions are unstable in the KM. For the CL, we show that the
one-parameter family of synchronized solutions obtained in the previous work is
the only continuous one and there exist uncountably many one-parameter families
of noncontinuous synchronized solutions and that the former is asymptotically
stable and the latter are unstable.",http://arxiv.org/abs/2501.02889v3
"Leader Rotation Is Not Enough: Scrutinizing Leadership Democracy of
  Chained BFT Consensus",2025-01-06T12:27:34Z,"Yining Tang, Runchao Han, Jianyu Niu, Chen Feng, Yinqian Zhang","With the growing popularity of blockchains, modern chained BFT protocols
combining chaining and leader rotation to obtain better efficiency and
leadership democracy have received increasing interest. Although the efficiency
provisions of chained BFT protocols have been thoroughly analyzed, the
leadership democracy has received little attention in prior work. In this
paper, we scrutinize the leadership democracy of four representative chained
BFT protocols, especially under attack. To this end, we propose a unified
framework with two evaluation metrics, i.e., chain quality and censorship
resilience, and quantitatively analyze chosen protocols through the Markov
Decision Process (MDP). With this framework, we further examine the impact of
two key components, i.e., voting pattern and leader rotation on leadership
democracy. Our results indicate that leader rotation is not enough to provide
the leadership democracy guarantee; an adversary could utilize the design,
e.g., voting pattern, to deteriorate the leadership democracy significantly.
Based on the analysis results, we propose customized countermeasures for three
evaluated protocols to improve their leadership democracy with only slight
protocol overhead and no change of consensus rules. We also discuss future
directions toward building more democratic chained BFT protocols.",http://arxiv.org/abs/2501.02970v1
"Super-fast bullet bubbles transported in a pressure-driven cylindrical
  flow",2025-01-06T13:12:15Z,"Jean Cappello, Javier Rivero-Rodriguez, Benoit Scheid","When transported by a pressure driven flow in a cylindrical pipe, bubbles may
exhibit very fast velocities. In this paper, we show that, when the bubbles are
largely deformable, that is, at large capillary numbers Ca, the velocity of the
bubble can be larger than the maximal velocity of the flow that transports
them. We call this regime ""super-fast"". However, the situation changes when
inertia comes at play for increasing Reynolds numbers Re, and the relative
velocity of the bubble drops for sufficiently large Laplace number, defined as
La = Re/Ca. In this article, we uncover the conditions for which the super-fast
regime exists : the deformability of the drop is crucial, and hence the
capillary number needs to be larger than a critical value, yet smaller than a
threshold above which the bubble breaks up. The two limiting capillary numbers
are presented in a phase diagram as a function of the bubble size and the
Laplace number.",http://arxiv.org/abs/2501.02993v1
"Characterizing Measurement Error in the German Socio-Economic Panel
  Using Linked Survey and Administrative Data",2025-01-06T13:47:22Z,Nico Thurow,"This paper exploits the linkage of German administrative social security data
(GER: Integrierte Erwerbsbiografien) and survey data from the socio-economic
panel (GER: Sozio-\""okonomisches Panel, SOEP) for the characterization of
measurement error in metrics quantifying individual-specific labor earnings in
Germany. We find that survey participants' decision whether to consent to
linkage is non-random based on observables. In that sense, the studied sample
does not constitute a random sample of SOEP. Measurement error is not
classical: we observe underreporting of income on average, autocorrelation, and
non-zero correlation with the true signal and other observable characteristics.
In levels, calculated reliability ratios above 0.94 hint at a relaitvely small
attenuation bias in simple linear univariate regressions with earnings as the
explanatory variable. For changes in income, i.e. first differences, the bias
from measurement error is exacerbated.",http://arxiv.org/abs/2501.03015v1
"Geometric optics analysis in Lorentz violating Chern-Simons
  electrodynamics",2025-01-06T14:36:04Z,"Arpan Das, Hriditi Howlader, Alekha C. Nayak","We study the geometric optics limit of the electrodynamics in the presence of
Lorentz violating Chern-Simons term in (3+1) dimensions. The Chern-Simons term
couples the dual electromagnetic tensor to an external four-vector and the
electromagnetic gauge field. For a fixed external four-vector, such a
Chern-Simons term violates Lorentz invariance while maintaining the gauge
invariance of the theory. In this analysis, we look into the consequences of
Lorentz symmetry violating Chern-Simons term within the geometric optics limit
of light rays propagating from a source to an observation point. We argue that
the Ricci tensor and the Lorentz-violating term modify the dynamical equation
for the gauge vector field. However, in the geometric optics limit, neither the
space-time curvature nor the Chern-Simons term influences the intensity of
light. Unlike the intensity, the polarization of light, on the other hand, can
be influenced by the Lorentz-violating Chern-Simons term. Due to such an effect
in the presence of Chern-Simons term, the photon emitting from astrophysical
objects can undergo a change in polarization as it propagates in space.",http://arxiv.org/abs/2501.03047v1
Knife-Edge Diffraction of Scalar and Vector Vortex Light,2025-01-06T14:39:50Z,"Richard Aguiar Maduro, Amanda Kronhardt Fritsch, Sonja Franke-Arnold","Various methods have been introduced to measure the orbital angular momentum
(OAM) of light, from fork holograms to Dove prism interferometers, from tilted
lenses to triangular apertures - each with their own benefits and limitations.
Here we demonstrate how simple knife-edge diffraction can be used to identify
the OAM of an optical phase vortex from the formation of fork dislocations
within the Fresnel diffraction pattern. For vector vortex beams without net
OAM, the conventional Fresnel fringes are recovered, whereas the polarization
in the geometric shadow is changed in its ellipticity. The observed diffraction
patterns agree with simulations and their features can be explained by
considering diffraction as an interference phenomenon. Knife-edge diffraction
provides not only an instructive illustration of various properties of phase
and polarization vortices, but can also serve as an ideal method for the quick
determination of optical OAM, with potential applications beyond optics, where
alternative detection measurement methods may be harder to realize.",http://arxiv.org/abs/2501.03052v1
"MVP: Multimodal Emotion Recognition based on Video and Physiological
  Signals",2025-01-06T16:09:22Z,"Valeriya Strizhkova, Hadi Kachmar, Hava Chaptoukaev, Raphael Kalandadze, Natia Kukhilava, Tatia Tsmindashvili, Nibras Abo-Alzahab, Maria A. Zuluaga, Michal Balazia, Antitza Dantcheva, François Brémond, Laura Ferrari","Human emotions entail a complex set of behavioral, physiological and
cognitive changes. Current state-of-the-art models fuse the behavioral and
physiological components using classic machine learning, rather than recent
deep learning techniques. We propose to fill this gap, designing the Multimodal
for Video and Physio (MVP) architecture, streamlined to fuse video and
physiological signals. Differently then others approaches, MVP exploits the
benefits of attention to enable the use of long input sequences (1-2 minutes).
We have studied video and physiological backbones for inputting long sequences
and evaluated our method with respect to the state-of-the-art. Our results show
that MVP outperforms former methods for emotion recognition based on facial
videos, EDA, and ECG/PPG.",http://arxiv.org/abs/2501.03103v1
"On the renormalization of ultraviolet divergences in the inflationary
  angular power spectrum",2025-01-06T16:31:52Z,"Adrian del Rio, Jose Navarro-Salas","We revise the role that ultraviolet divergences of quantum fields play in
slow-roll inflation, and discuss the renormalization of cosmological
observables from a space-time perspective, namely the angular power spectrum.
We first derive an explicit expression for the multipole coefficients
$C_{\ell}$ in the Sachs-Wolfe regime in terms of the two-point function of
primordial perturbations. We then analyze the ultraviolet behavior, and point
out that the standard result in the literature is equivalent to a
renormalization of $C_{\ell}$ at zero ``adiabatic'' order. We further argue
that renormalization at second ``adiabatic'' order may be more appropriate from
the viewpoint of standard quantum field theory. This may change significantly
the predictions for $C_{\ell}$, while maintaining scale invariance.",http://arxiv.org/abs/2501.03125v1
"Nonequilibrium thermodynamics of populations of weakly-coupled
  low-temperature-differential Stirling engines with synchronous and
  asynchronous transitions",2025-01-06T18:04:04Z,"Songhao Yin, Hiroshi Kori, Yuki Izumida","This study developed the theory of nonequilibrium thermodynamics for
populations of low-temperature-differential (LTD) Stirling engines
weakly-coupled in a general class of networks to clarify the effects of
synchronous and asynchronous transitions on the power and thermal efficiency.
We first show that synchronous (asynchronous) transitions increase (decrease)
the power and thermal efficiency of weakly-coupled LTD Stirling engines based
on quasilinear response relations between formally defined thermodynamic fluxes
and forces. After that, we construct a conceptual model satisfying the
quasilinear response relations to give a physical interpretation of the changes
in power and thermal efficiency due to synchronous and asynchronous
transitions, and justify the use of this conceptual model. We then show that
the conceptual model, rather than the quasilinear response relations, preserves
the irreversible nature in the relative motion of the original model and thus
shows more accurate results than the analysis using the quasilinear response
relations. Finally, we compare the dynamics between the original and the
conceptual models for two-engine systems and show that the conceptual model
roughly preserves the dynamical characteristics leading up to the synchronous
transitions, while some detailed dynamical structures are lost.",http://arxiv.org/abs/2501.03185v1
Local data of elliptic curves under quadratic twist,2025-01-06T18:41:56Z,"Alexander J. Barrios, Manami Roy, Nandita Sahajpal, Darwin Tallana, Bella Tobin, Hanneke Wiersema","Let $K$ be the field of fractions of a complete discrete valuation ring with
a perfect residue field. In this article, we investigate how the Tamagawa
number of $E/K$ changes under quadratic twist. To accomplish this, we introduce
the notion of a normal model for $E/K$, which is a Weierstrass model satisfying
certain conditions that lead one to easily infer the local data of $E/K$. Our
main results provide necessary and sufficient conditions on the Weierstrass
coefficients of a normal model of $E/K$ to determine the local data of a
quadratic twist $E^{d}/K$. We note that when the residue field has
characteristic $2$, we only consider the special case $K=\mathbb{Q}_{2}$. In
this setting, we also determine the minimal discriminant valuation and
conductor exponent of $E$ and $E^d$ from further conditions on the coefficients
of a normal model for $E$.",http://arxiv.org/abs/2501.03209v1
"Sub-micron Circuit Fabrication on Diamond Anvils for Mesoscopic
  High-Pressure Experiments",2025-01-06T19:00:01Z,"Z. R. Rehfuss, K. Zheng, S. L. Gould, K. W. Murch, S. Ran","We present a novel fabrication procedure to produce high-quality lift-off
structures on diamond anvils extending from the culet down to the slanted
facets. Feature sizes down to 500 nm are achieved through the use of a bi-layer
resist stack and electron beam lithography. Device structures with strong
adhesion to the diamond surface and high abrasion resistance are realized by
optimizing the surface treatment. To benchmark our process, we fabricate a
multi-lead tungsten circuit to measure changes of the superconducting
transition temperature of zirconium across the structural phase transition at
$\sim$30 GPa; showing a 4-fold jump of the critical temperature. Our process is
easily reproducible in most traditional academic and industrial cleanroom
facilities. This work paves the way for complex and high-precision fabrication
and measurements inside diamond anvil cells and on other faceted crystalline
samples.",http://arxiv.org/abs/2501.03317v1
"Solar Cycle Variation of Axial Orientations and Favorable Locations of
  Eruptive MFRs",2025-01-06T19:26:58Z,"Hong Xie, Nat Gopalswamy, Sachiko Akiyama, Pertti Makela, Seiji Yashiro","Using multi-viewpoint observations from STEREO and SOHO during three solar
cycles from 23 to 25, we study the magnetic flux rope (MFR) structures of
coronal mass ejections (CMEs) near the Sun and magnetic clouds (MCs) at 1au.
The study aims to investigate two phenomena: 1) the occurrence rate of CMEs
near Hale sector boundaries (HBs) and 2) solar-cycle variation of MFR axial
orientations in CMEs and MCs. Our preliminary results include: 1) the axes of
MFRs in cycle 25 present a systematic northward orientation, which is the same
as in cycle 23 but opposite to cycle 24; 2) the majority of the MFRs occurred
near HBs (within 30 degrees) and some exceptional events occurred at non-HBs;
3) the axial fields in MCs present a similar north-south orientation, which
changes from cycle to cycle. We discuss the implication of solar cycle
variations of MFR axial orientations for space weather forecasts.",http://arxiv.org/abs/2501.03346v1
Critical-like phenomenon in scraping of jamming systems,2025-01-07T02:30:19Z,"Masaya Endo, Rei Kurita","In jamming systems like colloids, emulsions, foams, and biological tissues,
significant deformation is essential for processes such as material scraping or
wound self-healing. To adequately spread a foam or cream over a surface,
external force must be applied to artificially scrape it. The scraping of foam
using a rigid plate has been observed to exhibit complex behavior distinct from
that of simple liquids. In this study, we quantitatively analyzed the
transition between partial and slender scraping regimes by examining changes in
internal structure and partial spreading lengths. Our findings reveal that the
sequential propagation of bubble rearrangement in the foam's internal structure
leads to the partial scraping. Moreover, the scraping length in the partial
scraping regime shows divergence near the transition point, characterized by a
critical exponent of approximately 0.61. These results imply that foam scraping
is governed by directional percolation theory, supported by the agreement
between the experimentally observed critical exponent and theoretical
predictions. This research significantly advances the understanding of
macroscopic kinetics and rheological behavior in jamming systems, including
foams, colloids, emulsions, and biological tissues.",http://arxiv.org/abs/2501.03473v1
"Transitions from Composite Fermi Liquid to Moore-Read States in Weyl
  Semimetals",2025-01-07T03:38:49Z,"Jiong-Hao Wang, Yong Xu","Weyl semimetals represent a significant class of topological gapless
materials in three dimensions and have been shown to exhibit three-dimensional
quantum Hall effect. However, existing research mainly focuses on scenarios
without interactions. Recent studies suggest that the fractional quantum Hall
effect can arise in a Weyl semimetal with a one-third filled Landau level under
a magnetic field. However, it remains unclear whether more exotic states, such
as composite Fermi liquid and MooreRead states, can appear at half filling.
Here we surprisingly find the existence of composite Fermi liquid, Moore-Read
states and charge density waves in the same Weyl-orbit-based Landau level of a
Weyl semimetal and their transitions induced by varying the distance between
Weyl points. We attribute these transitions to a significant change in the
single-particle wave functions of the Landau level as the distance between Weyl
points is varied. Finally, we demonstrate that a transition from composite
Fermi liquid to Moore-Read states can be induced by tuning the direction of a
magnetic field, a process that is more experimentally accessible.",http://arxiv.org/abs/2501.03498v1
"Spectro-timing analysis of Be X-ray pulsar SMC X-2 during the 2022
  outburst",2025-01-07T07:00:53Z,"Mohammed Tobrej, Binay Rai, Manoj Ghising, Ruchi Tamang, Bikash Chandra Paul","We present broadband X-ray observations of the High Mass X-ray Binary (HMXB)
pulsar SMC X-2, using concurrent NuSTAR and NICER observations during its 2022
outburst. The source is found to be spinning with a period of 2.37281(3) s. We
confirm the existence of cyclotron resonant scattering feature (CRSF) at 31 keV
in addition to the iron emission line in the X-ray continuum of the source.
Spectral analysis performed with the physical bulk and thermal Comptonization
model indicates that the bulk Comptonization dominates the thermal
Comptonization. Using phase-resolved spectroscopy, we have investigated the
variations of the spectral parameters relative to pulse phase that may be due
to the complex structure of magnetic field of the pulsar or the impact of the
emission geometry. It is observed that the spectral parameters exhibit
significant variabilities relative to the pulsed phase. Time-resolved
spectroscopy is employed to examine the evolution of the continuum and changes
in the spectral characteristics. Measurements of luminosity along with
variations in cyclotron line energy and photon index suggest that the source
may be accreting in the super-critical regime.",http://arxiv.org/abs/2501.03576v1
"Long-distance high-precision and high-sensitivity time delay sensing
  based on fiber optic weak measurements",2025-01-07T07:32:40Z,"Wei-Qian Zhao, Zi-Fu Su, Ya-Fei Yu, Jin-Dong Wang","In fiber optic sensing, time delays induced by polarization mode dispersion
can distort signals in systems relying on phase or intensity variations for
measurement, degrading performance, especially in long distance, high-precision
applications. To address this challenge, we propose a weak measurement-based
scheme using intensity contrast ratio for high-precision, high-sensitivity
fiber optic delay estimation under large inherent time delays. We demonstrate
that a narrower light source bandwidth enhances the effective sensing distance
for high-sensitivity measurements. Our results show that, even with large
inherent time delays, the measurement precision and sensitivity remain
comparable to those of biased weak measurement, enabling detection of time
delay variations at the attosecond level, corresponding to a 25.5 Pa water
pressure change. The scheme is also robust against fiber misalignment errors,
offering a novel solution for long-distance distributed fiber-optic sensing and
broadening the applications of weak measurement techniques.",http://arxiv.org/abs/2501.03589v1
"IEEE 802.11bn Multi-AP Coordinated Spatial Reuse with Hierarchical
  Multi-Armed Bandits",2025-01-07T10:29:27Z,"Maksymilian Wojnar, Wojciech Ciezobka, Katarzyna Kosek-Szott, Krzysztof Rusek, Szymon Szott, David Nunez, Boris Bellalta","Coordination among multiple access points (APs) is integral to IEEE 802.11bn
(Wi-Fi 8) for managing contention in dense networks. This letter explores the
benefits of Coordinated Spatial Reuse (C-SR) and proposes the use of
reinforcement learning to optimize C-SR group selection. We develop a
hierarchical multi-armed bandit (MAB) framework that efficiently selects APs
for simultaneous transmissions across various network topologies, demonstrating
reinforcement learning's promise in Wi-Fi settings. Among several MAB
algorithms studied, we identify the upper confidence bound (UCB) as
particularly effective, offering rapid convergence, adaptability to changes,
and sustained performance.",http://arxiv.org/abs/2501.03680v1
"Confinement and Activity-Driven Dynamics of Semiflexible Polymers in
  Motility Assays",2025-01-07T10:33:25Z,"Sandip Roy, Anil Kumar Dasanna","We investigate the dynamics of semiflexible polymers in a motility assay,
where motor proteins (MPs) stochastically bind, unbind, and walk along the
polymer, under the influence of harmonic confinement. Using Langevin dynamics
simulations, we explore the interplay between the polymer's rigidity, activity
in the form of attachment/detachment of MPs and subsequent movement of attached
MPs, and trap strength, revealing a two-state transition from a trapped to a
free polymer, with an intermediate coexistence region. Rigidity significantly
impacts the trapping behaviour, with flexible polymers remaining trapped at the
higher activity. Attachment/detachment of MPs can also induce a change in the
effective rigidity of the polymer and, therefore, influence confinement by the
trap.The polymer undergoes spiral and open-chain conformations, with the
turning number serving as a key order parameter to quantify spiral formation.
We show that confinement stabilizes spiral structures and suppresses open-chain
motion, especially at higher activity. The centre of mass (COM) dynamics are
analyzed through the mean square displacement (MSD), showing diffusive,
ballistic, and diffusive regimes that depend on the trap strength and activity.
Negative excess kurtosis indicates nonequilibrium behaviour, which saturates
with increasing confinement, reflecting the dominance of the trap over the
activity.",http://arxiv.org/abs/2501.03686v1
"Foliated Asymptotically Safe Gravity -- Lorentzian Signature
  Fluctuations from the Wick Rotation",2025-01-07T12:48:08Z,"Frank Saueressig, Jian Wang","Asymptotic Safety constitutes a promising mechanism for a consistent and
predictive high-energy completion of the gravitational interactions. To date,
most results on the interacting renormalization group fixed point underlying
the construction are obtained for Euclidean signature spacetimes. In this work,
we use the Arnowitt-Deser-Misner (ADM) decomposition of the metric degrees of
freedom and investigate the relations between the Euclidean and Lorentzian
renormalization group flows resulting from the analytic continuation of the
lapse function. We discuss the general conditions which guarantee the
equivalence of the beta functions. These insights are illustrated based on the
flow of the graviton two-point function within the Einstein-Hilbert truncation,
demonstrating agreement of the Euclidean and Lorentzian settings. Hence the UV-
and IR-completions identified in the Euclidean case are robust when changing
spacetime signature. We take this as an important indicator that the Euclidean
asymptotic safety mechanism carries over to Lorentzian signature spacetimes.",http://arxiv.org/abs/2501.03752v1
"Investigation of bremsstrahlung emission in an electron cyclotron
  resonance ion source and its dependence on the magnetic confinement",2025-01-07T13:39:21Z,"Andrea Cernuschi, Thomas Thuillier","A Monte Carlo (MC) code is used to investigate the bremsstrahlung x-ray
emission of an electron cyclotron resonance ion source (ECRIS) and its
dependence on the axial magnetic confinement. The x-ray spectral temperature Ts
measured with the simulations is in fair agreement with previous experiments.
The dependence of Ts on the minimum magnetic field of the configuration Bmin is
corroborated, also observing that the ion extraction peak field Bext has no
influence on temperature. Details on the mechanism generating the hot electron
population responsible for the change in spectral x-ray temperature as a
function of Bmin are proposed, based on an in-depth investigation of the
electron population with the MC code using a high statistics.",http://arxiv.org/abs/2501.03779v1
Dynamical space-time ray tracing and modified horizontal ray method,2025-01-07T15:14:26Z,"Aleksandr Kaplun, Boris Katsnelson","The 'vertical modes and horizontal rays' method, commonly applied for
simulating acoustic wave propagation in shallow water is advanced in this
research. Our approach to this method involves the use of the so-called
space-time rays, which are constructed by decomposing the time-dependent sound
field into adiabatic vertical modes, the solutions to the Sturm-Liouville
problem. The introduction of the time coordinate, while still considering it as
an additional space coordinate instead of merely a parameter along the ray,
allows us to describe the propagation of frequency-modulated signals in an
effectively frequency-dispersive medium. The consideration of the extension of
Hamiltonian ray-tracing methods (also used for the description of Gaussian
beams and so-called quasiphotons) leads to a simple description of observable
effects such as changes in modulation, time compression, differences between
angles of phase and amplitude fronts, space-time caustics, etc., in dynamics -
on the moving line or at some point of observation while having the general
form of the source (for example, also a moving one).",http://arxiv.org/abs/2501.03856v1
Progressive Document-level Text Simplification via Large Language Models,2025-01-07T15:14:37Z,"Dengzhao Fang, Jipeng Qiang, Yi Zhu, Yunhao Yuan, Wei Li, Yan Liu","Research on text simplification has primarily focused on lexical and
sentence-level changes. Long document-level simplification (DS) is still
relatively unexplored. Large Language Models (LLMs), like ChatGPT, have
excelled in many natural language processing tasks. However, their performance
on DS tasks is unsatisfactory, as they often treat DS as merely document
summarization. For the DS task, the generated long sequences not only must
maintain consistency with the original document throughout, but complete
moderate simplification operations encompassing discourses, sentences, and
word-level simplifications. Human editors employ a hierarchical complexity
simplification strategy to simplify documents. This study delves into
simulating this strategy through the utilization of a multi-stage collaboration
using LLMs. We propose a progressive simplification method (ProgDS) by
hierarchically decomposing the task, including the discourse-level,
topic-level, and lexical-level simplification. Experimental results demonstrate
that ProgDS significantly outperforms existing smaller models or direct
prompting with LLMs, advancing the state-of-the-art in the document
simplification task.",http://arxiv.org/abs/2501.03857v1
Effective textures from a $[SU(3)]^3$ flavored scalar sector,2025-01-07T15:36:46Z,"A. Carrillo-Monteverde, R. Escorcia Ramírez, S. Gómez-Ávila, L. Lopez-Lozano","Current constraints on flavor-changing neutral currents (FCNCs) strongly
indicate that any new physics emerging at the 1-10 TeV scale must adhere to the
Minimal Flavor Violation (MFV) principle, where Yukawa couplings are the sole
sources of flavor violation. In this work, we present a model inspired by a
gauged $SU(3)$ flavor symmetry that dynamically generates leptonic Yukawa
matrices through effective operators. The model incorporates a scalar sector
with two sets of flavons, characterized by their vacuum expectation values
(VEVs), which govern the suppression scale of the Yukawa couplings and the
hierarchy of neutrino masses. By leveraging phenomenologically viable Yukawa
textures, we derive restrictions on the flavon VEVs and demonstrate the
compatibility of the model with experimental neutrino oscillation data.
Furthermore, the model predicts at least one neutrino mass to be strongly
suppressed, consistent with the normal mass ordering and experimental upper
bounds. This framework provides a robust mechanism for dynamically generating
neutrino masses and mixing while addressing key challenges in leptonic flavor
physics, such as FCNC suppression and CP-violating phases.",http://arxiv.org/abs/2501.03872v1
"An obstruction to small-time local controllability for a bilinear
  Schrödinger equation",2025-01-07T15:44:16Z,"Karine Beauchard, Frédéric Marbach, Thomas Perrin","We consider the small-time local controllability in the vicinity of the
ground state of a bilinear Schr\""odinger equation with Neumann boundary
conditions. We prove that, when the linearized system is not controllable, the
nonlinear system is not controllable, due to a quadratic obstruction involving
the squared norm of the control's primitive. This obstruction has been known
since 1983 for ODEs and observed for some PDEs since 2006. However, our
situation is more intricate since the kernel describing the quadratic expansion
of the solution is not twice differentiable. We thus follow a Fourier-based
approach, closer to the one used for quadratic obstructions of fractional
Sobolev regularity.
  In this Fourier-based approach, a challenge is to formulate a necessary and
sufficient condition on the convolution kernel, for the quadratic form to be
coercive. In previous studies, the coercivity was ensured by a signed
asymptotic equivalent for the Fourier transform of the convolution kernel of
the form $\widehat{K}(\omega) \sim \omega^{-2}$ as $|\omega| \to \infty$. In
our case, $\widehat{K}$ is a distribution which has singularities and changes
sign up to infinity. We still prove coercivity because one of the signs appears
too infrequently.",http://arxiv.org/abs/2501.03882v1
Origin of ion bombardment induced Tb oxidation in Tb/Co multilayers,2025-01-07T16:06:24Z,"Daniel Kiphart, Michal Krupinski, Marzena Mitura-Nowak, Pawel Piotr Michalowski, Mateusz Kowacz, Marek Schmidt, Feliks Stobiecki, Gabriel David Chaves-O'Flynn, Piotr Kuswik","Ion bombardment is currently an active area of research for patterning rare
earth/transition metal ferrimagnetic thin films because the magnetic properties
are extremely sensitive to changes in the constituent sublattices. It has
previously been shown that ion bombardment can be used to deliberately reduce
the contribution of the rare earth sublattice in rare earth/transition metal
ferrimagnets by selective oxidation. However, the exact mechanism by which
oxidation occurs remains an outstanding question. We show that the defects
introduced by ion bombardment of Tb/Co multilayers using different ion species
with projected range (i.e., 10 keV He + , 15 keV O + , and 30 keV Ga +) create
easy diffusion paths for oxygen to penetrate the system. The choice of ion
species and fluence enables the effective composition of the films to be
tailored by reducing the amount of magnetically-active Tb.",http://arxiv.org/abs/2501.03899v1
"Optical absorption and luminescence of $α$-LiV$_2$O$_5$ from the
  Bethe Salpeter Equation",2025-01-07T16:31:16Z,"Claudio Garcia, Walter R. L. Lambrecht","$\alpha$-Li$_x$V$_2$O$_5$ is obtained by intercalating Li between the layers
of V$_2$O$_5$. The partial filling of the split-off conduction band by electron
donation from Li leads to significant changes in optical properties. Here we
study the electronic band structure of $\alpha$-LiV$_2$O$_5$ using
quasiparticle self-consistent (QS) $GW$ calculations and the optical dielectric
function by means of the Bethe Salpeter equation. We find a very strong optical
absorption band related to transitions between the filled V-$d_{xy}$ like
states to the empty ones with strong polarization along the $a$-direction. We
relate this to recent experimental observations of cathodoluminescence (CL) in
which a supression of the CL was observed upon addition of Li.",http://arxiv.org/abs/2501.03917v2
Thermally Adaptive Surface Microscopy for brain functional imaging,2025-01-07T18:00:48Z,"Hadrien L. M. Robert, Giulia Faini, Chang F. Liu, Nadja Rutz, Anis Aggoun, Elena Putti, Jose Garcia-Guirado, Filippo Del Bene, Romain Quidant, Gilles Tessier, Pascal Berto","Fluorescence microscopes can record the dynamics of living cells with high
spatio-temporal resolution in a single plane. However, monitoring rapid and dim
fluorescence fluctuations, e.g induced by neuronal activity in the brain,
remains challenging for 3D-distributed emitters due to out-of-focus
fluorescence background, a restricted photon budget, and the speed limit of
conventional scanning systems. Here, we introduce a Thermally Adaptive Surface
strategy, capable of simultaneously recording, at camera framerate, the
activity of 3D-distributed objects. This innovative microscope leverages on an
array of thermally tuneable microlenses that offer low chromatic aberration and
high transmission, and can be combined with patterned illumination to provide
optical sectioning. We demonstrate its potential in vivo, by simultaneously
monitoring fast fluorescent dynamics at different depths in the zebrafish
larval brain, at a rate of 0.5 kHz and over a large field of view (360um x
360um).",http://arxiv.org/abs/2501.03965v1
Impact of Leg Stiffness on Energy Efficiency in One Legged Hopping,2025-01-07T18:22:23Z,"Iskandar Khemakhem, Dominik Tschemernjak, Maximilian Raff, C. David Remy","In the fields of robotics and biomechanics, the integration of elastic
elements such as springs and tendons in legged systems has long been recognized
for enabling energy-efficient locomotion. Yet, a significant challenge
persists: designing a robotic leg that perform consistently across diverse
operating conditions, especially varying average forward speeds. It remains
unclear whether, for such a range of operating conditions, the stiffness of the
elastic elements needs to be varied or if a similar performance can be obtained
by changing the motion and actuation while keeping the stiffness fixed. This
work explores the influence of the leg stiffness on the energy efficiency of a
monopedal robot through an extensive parametric study of its periodic hopping
motion. To this end, we formulate an optimal control problem parameterized by
average forward speed and leg stiffness, solving it numerically using direct
collocation. Our findings indicate that, compared to the use of a fixed
stiffness, employing variable stiffness in legged systems improves energy
efficiency by 20 % maximally and by 6.8 % on average across a range of speeds.",http://arxiv.org/abs/2501.03971v1
Towards reconstruction of finite tensor categories,2025-01-07T18:44:15Z,"Mitchell Jubeir, Zhenghan Wang","We take a first step towards a reconstruction of finite tensor categories
using finitely many $F$-matrices. The goal is to reconstruct a finite tensor
category from its projective ideal. Here we set up the framework for an
important concrete example--the $8$-dimensional Nicholas Hopf algebra $K_2$. Of
particular importance is to determine its Green ring and tensor ideals. The
Hopf algebra $K_2$ allows the recovery of $(2+1)$-dimensional Seiberg-Witten
TQFT from Hennings TQFT based on $K_2$. This powerful result convinced us that
it is interesting to study the Green ring of $K_2$ and its tensor ideals in
more detail. Our results clearly illustrate the difficulties arisen from the
proliferation of non-projective reducible indecomposable objects in finite
tensor categories.",http://arxiv.org/abs/2501.03987v2
Axion misalignment with memory-burdened PBH,2025-01-07T19:00:00Z,"Disha Bandyopadhyay, Debasish Borah, Nayan Das","We study the possibility of producing axion dark matter (DM) via misalignment
mechanisms in a non-standard cosmological era dominated by ultra-light
primordial black holes (PBH). While the effect of PBH domination on the
production of axion via vacuum misalignment is known assuming the PBH
evaporation to proceed according to Hawking's semi-classical (SC)
approximation, we go beyond these simplest possibilities to include kinetic
misalignment of axion and backreaction effect of emitted particles on the PBH
themselves, referred to as the memory-burden (MB) effect. We show that,
depending upon the type of misalignment mechanism and PBH evaporation regime,
the axion as well as PBH parameter space consistent with the observed DM relic
changes significantly having interesting implications for axion detection
experiments. PBH also offer complementary detection prospects via gravitational
wave due to PBH density fluctuations and excess radiation due to emission of
hot axions within reach of future cosmic microwave background experiments.",http://arxiv.org/abs/2501.04076v1
Comparison of STR and EMLSR Performance in Wi-Fi 7 MLO,2025-01-07T21:33:42Z,"Aishwarya Choorakuzhiyil, Kevin Ho, Sara Reyes","This project compares the performance of simultaneous transmit and receive
(STR) and enhanced multi-link single radio (EMLSR) within Multi-Link Operation
(MLO) in Wi-Fi 7 networks. Using the ns-3 simulator, we evaluate both
techniques under various scenarios, including changes in modulation coding
scheme (MCS), bandwidth, link quality, and interference levels. Key performance
metrics such as latency, throughput, and energy efficiency are analyzed to
determine the trade-offs between STR and EMLSR. The results demonstrate that
STR achieves higher throughput and lower latency due to dual-link utilization,
making it suitable for high-load environments. In contrast, EMLSR balances
energy efficiency with responsiveness, making it advantageous for
power-sensitive applications. This analysis provides insights into the
strengths and limitations of STR and EMLSR, guiding optimal deployment
strategies for future Wi-Fi 7 networks.",http://arxiv.org/abs/2501.04149v1
"Efficient LP warmstarting for linear modifications of the constraint
  matrix",2025-01-07T21:37:41Z,"Guillaume Derval, Bardhyl Miftari, Damien Ernst, Quentin Louveaux","We consider the problem of computing the optimal solution and objective of a
linear program under linearly changing linear constraints. More specifically,
we want to compute the optimal solution of a linear optimization where the
constraint matrix linearly depends on a paramater that can take p different
values. Based on the information given by a precomputed basis, we present three
efficient LP warm-starting algorithms. Each algorithm is either based on the
eigenvalue decomposition, the Schur decomposition, or a tweaked eigenvalue
decomposition to evaluate the optimal solution and optimal objective of these
problems. The three algorithms have an overall complexity O(m^3 + pm^2) where m
is the number of constraints of the original problem and p the number of values
of the parameter that we want to evaluate. We also provide theorems related to
the optimality conditions to verify when a basis is still optimal and a local
bound on the objective.",http://arxiv.org/abs/2501.04151v1
"Tilted chiral spin textures in confined nanostructures with in-plane
  magnetic anisotropy",2025-01-08T01:58:08Z,"Wenlei Fu, Haiming Dong, Kai Chang","We demonstrate that nanoconfinement effects and in-plane magnetic anisotropy
(IMA) can lead to tilted chiral spin textures in magnetic nanostructures, based
on the analysis and simulation of theoretical models of micromagnetism. The
tilted skyrmions are induced in confined nanoscale magnets with IMA under
perpendicular magnetic fields. The chiral magnetic structures depend
significantly on the size of the nanostructures. A controlled string of
periodic skyrmion states emerges within the central magnetic domain wall, which
can be tuned by the steady magnetic fields and the size of the nanostructures.
Non-trivial topological states with non-integer topological charges are
achieved by tuning the magnetic fields or the sizes of the nanostructures.
Importantly, the periodic switching between the trivial and the non-trivial
topological configurations is realized using an alternating magnetic field. Our
study reveals an important mechanism for controlling novel skyrmion states via
nanoconfinement effects and the IMA in magnetic nanostructures, and also
provides a new approach for the development of magnetic field-modulated spin
nanodevices.",http://arxiv.org/abs/2501.04226v1
"Beam Domain Channel Estimation for Spatial Non-Stationary Massive MIMO
  Systems",2025-01-08T02:47:07Z,"Lin Hou, Hengtai Chang, Cheng-Xiang Wang, Jie Huang, Songjiang Yang","In massive multiple-input multiple-output (MIMO) systems, the channel
estimation scheme is subject to the spatial non-stationarity and inevitably
power leakage in the beam domain. In this paper, a beam domain channel
estimation scheme is investigated for spatial non-stationary (SNS) massive MIMO
systems considering power leakage. %a novel beam domain channel estimation
scheme is proposed for spatial non-stationary (SNS) massive MIMO systems.
Specifically, a realistic massive MIMO beam domain channel model (BDCM) is
introduced to capture the spatial non-stationarity considering power leakage by
introducing the illustration of visibility region (VR). Then, a beam domain
structure-based sparsity adaptive matching pursuit (BDS-SAMP) scheme is
proposed based on the cross-block sparse structure and power ratio threshold of
beam domain channel. Finally, the simulation results validate the accuracy of
proposed BDS-SAMP scheme with low pilot overhead and reasonable complexity by
comparing with conventional schemes.",http://arxiv.org/abs/2501.04242v1
"Defect Phonon Renormalization during Nonradiative Multiphonon
  Transitions in Semiconductors",2025-01-08T05:27:24Z,"Junjie Zhou, Shanshan Wang, Menglin Huang, Xin-Gao Gong, Shiyou Chen","As a typical nonradiative multiphonon transition in semiconductors, carrier
capture at defects is critical to the performance of semiconductor devices. Its
transition rate is usually calculated using the equal-mode approximation, which
assumes that phonon modes and frequencies remain unchanged before and after the
transition. Using the carbon substitutional defect ($\text{C}_\text{N}$) in GaN
as a benchmark, here we demonstrate that the phonon renormalization can be
significant during defect relaxation, which causes errors as large as orders of
magnitude in the approximation. To address this issue, we consider (i)
Duschinsky matrix connecting the initial-state and final-state phonons, which
accounts for the changes in phonon modes and frequencies; and (ii) the
off-diagonal contributions in total transition matrix element, which
incorporates the cross terms of electron-phonon interactions between different
modes. With this improvement, the calculated transition rates show agreements
with experimental results within an order of magnitude. We believe the present
method makes one step forward for the accurate calculation of multiphonon
transition rate, especially in cases with large defect relaxations.",http://arxiv.org/abs/2501.04289v1
"Who Does the Giant Number Pile Like Best: Analyzing Fairness in Hiring
  Contexts",2025-01-08T07:28:10Z,"Preethi Seshadri, Seraphina Goldfarb-Tarrant","Large language models (LLMs) are increasingly being deployed in high-stakes
applications like hiring, yet their potential for unfair decision-making and
outcomes remains understudied, particularly in generative settings. In this
work, we examine the fairness of LLM-based hiring systems through two
real-world tasks: resume summarization and retrieval. By constructing a
synthetic resume dataset and curating job postings, we investigate whether
model behavior differs across demographic groups and is sensitive to
demographic perturbations. Our findings reveal that race-based differences
appear in approximately 10% of generated summaries, while gender-based
differences occur in only 1%. In the retrieval setting, all evaluated models
display non-uniform selection patterns across demographic groups and exhibit
high sensitivity to both gender and race-based perturbations. Surprisingly,
retrieval models demonstrate comparable sensitivity to non-demographic changes,
suggesting that fairness issues may stem, in part, from general brittleness
issues. Overall, our results indicate that LLM-based hiring systems, especially
at the retrieval stage, can exhibit notable biases that lead to discriminatory
outcomes in real-world contexts.",http://arxiv.org/abs/2501.04316v1
"The probability for chiral oscillation of Majorana neutrino in Quantum
  Field Theory",2025-01-08T07:34:46Z,"Takuya Morozumi, Tomoharu Tahara","We derive the probability for chiral oscillation of Majorana neutrinos based
on quantum field theory. Since the Hamiltonian under the Majorana mass term
does not conserve lepton number, the eigenstates of lepton number change
continuously over time. Therefore, the transition amplitude is described by the
inner product of the eigenstates of lepton number at the time of the neutrino
production and the detection. With the Bogoliubov transformation, we
successfully relates the lepton number eigenstates at different times. This
method enables us to understand the time variation of lepton number induced by
chiral oscillations in terms of transition probabilities. We also present the
physical picture that emerges through the Bogoliubov transformation.",http://arxiv.org/abs/2501.04320v1
Tracking UWB Devices Through Radio Frequency Fingerprinting Is Possible,2025-01-08T10:29:35Z,"Thibaud Ardoin, Niklas Pauli, Benedikt Groß, Mahsa Kholghi, Khan Reaz, Gerhard Wunder","Ultra-wideband (UWB) is a state-of-the-art technology designed for
applications requiring centimeter-level localization. Its widespread adoption
by smartphone manufacturer naturally raises security and privacy concerns.
Successfully implementing Radio Frequency Fingerprinting (RFF) to UWB could
enable physical layer security, but might also allow undesired tracking of the
devices. The scope of this paper is to explore the feasibility of applying RFF
to UWB and investigates how well this technique generalizes across different
environments. We collected a realistic dataset using off-the-shelf UWB devices
with controlled variation in device positioning. Moreover, we developed an
improved deep learning pipeline to extract the hardware signature from the
signal data. In stable conditions, the extracted RFF achieves over 99%
accuracy. While the accuracy decreases in more changing environments, we still
obtain up to 76% accuracy in untrained locations.",http://arxiv.org/abs/2501.04401v1
"AI-assisted design of experiments at the frontiers of computation:
  methods and new perspectives",2025-01-08T11:58:31Z,Pietro Vischia,"Designing the next generation colliders and detectors involves solving
optimization problems in high-dimensional spaces where the optimal solutions
may nest in regions that even a team of expert humans would not explore.
  Resorting to Artificial Intelligence to assist the experimental design
introduces however significant computational challenges in terms of generation
and processing of the data required to perform such optimizations: from the
software point of view, differentiable programming makes the exploration of
such spaces with gradient descent feasible; from the hardware point of view,
the complexity of the resulting models and their optimization is prohibitive.
To scale up to the complexity of the typical HEP collider experiment, a change
in paradigma is required.
  In this contribution I will describe the first proofs-of-concept of
gradient-based optimization of experimental design and implementations in
neuromorphic hardware architectures, paving the way to more complex challenges.",http://arxiv.org/abs/2501.04448v1
"ART: Distribution-Free and Model-Agnostic Changepoint Detection with
  Finite-Sample Guarantees",2025-01-08T12:57:09Z,"Xiaolong Cui, Haoyu Geng, Guanghui Wang, Zhaojun Wang, Changliang Zou","We introduce ART, a distribution-free and model-agnostic framework for
changepoint detection that provides finite-sample guarantees. ART transforms
independent observations into real-valued scores via a symmetric function,
ensuring exchangeability in the absence of changepoints. These scores are then
ranked and aggregated to detect distributional changes. The resulting test
offers exact Type-I error control, agnostic to specific distributional or model
assumptions. Moreover, ART seamlessly extends to multi-scale settings, enabling
robust multiple changepoint estimation and post-detection inference with
finite-sample error rate control. By locally ranking the scores and performing
aggregations across multiple prespecified intervals, ART identifies changepoint
intervals and refines subsequent inference while maintaining its
distribution-free and model-agnostic nature. This adaptability makes ART as a
reliable and versatile tool for modern changepoint analysis, particularly in
high-dimensional data contexts and applications leveraging machine learning
methods.",http://arxiv.org/abs/2501.04475v1
"Towards a Problem-Oriented Domain Adaptation Framework for Machine
  Learning",2025-01-08T14:19:54Z,"Philipp Spitzer, Dominik Martin, Laurin Eichberger, Niklas Kühl","Domain adaptation is a sub-field of machine learning that involves
transferring knowledge from a source domain to perform the same task in the
target domain. It is a typical challenge in machine learning that arises, e.g.,
when data is obtained from various sources or when using a data basis that
changes over time. Recent advances in the field offer promising methods, but it
is still challenging for researchers and practitioners to determine if domain
adaptation is suitable for a given problem -- and, subsequently, to select the
appropriate approach. This article employs design science research to develop a
problem-oriented framework for domain adaptation, which is matured in three
evaluation episodes. We describe a framework that distinguishes between five
domain adaptation scenarios, provides recommendations for addressing each
scenario, and offers guidelines for determining if a problem falls into one of
these scenarios. During the multiple evaluation episodes, the framework is
tested on artificial and real-world datasets and an experimental study
involving 100 participants. The evaluation demonstrates that the framework has
the explanatory power to capture any domain adaptation problem effectively. In
summary, we provide clear guidance for researchers and practitioners who want
to employ domain adaptation but lack in-depth knowledge of the possibilities.",http://arxiv.org/abs/2501.04528v1
"The MBTA Pipeline for Detecting Compact Binary Coalescences in the
  Fourth LIGO-Virgo-KAGRA Observing Run",2025-01-08T16:26:46Z,"Christopher Alléné, Florian Aubin, Inès Bentara, Damir Buskulic, Gianluca M Guidi, Vincent Juste, Morgan Lethuillier, Frédérique Marion, Lorenzo Mobilia, Benoît Mours, Amazigh Ouzriat, Thomas Sainrat, Viola Sordini","In this paper, we describe the Multi-Band Template Analysis (MBTA) search
pipeline dedicated to the detection of compact binary coalescence (CBC)
gravitational wave signals from the data obtained by the LIGO-Virgo-KAGRA
collaboration (LVK) during the fourth observing run (O4), which started in May
2023. We give details on the configuration of the pipeline and its evolution
compared to the third observing run (O3). We focus here on the configuration
used for the offline results of the first part of the run (O4a), which are part
of the GWTC-4 catalog (in preparation). We also give a brief summary of the
online configuration and highlight some of the changes implemented or
considered for the second part of O4 (O4b).",http://arxiv.org/abs/2501.04598v1
"Leveraging Log Probabilities in Language Models to Forecast Future
  Events",2025-01-08T23:28:28Z,"Tommaso Soru, Jim Marshall","In the constantly changing field of data-driven decision making, accurately
predicting future events is crucial for strategic planning in various sectors.
The emergence of Large Language Models (LLMs) marks a significant advancement
in this area, offering advanced tools that utilise extensive text data for
prediction. In this industry paper, we introduce a novel method for AI-driven
foresight using LLMs. Building on top of previous research, we employ data on
current trends and their trajectories for generating forecasts on 15 different
topics. Subsequently, we estimate their probabilities via a multi-step approach
based on log probabilities. We show we achieve a Brier score of 0.186, meaning
a +26% improvement over random chance and a +19% improvement over
widely-available AI systems.",http://arxiv.org/abs/2501.04880v1
Beyond Life: A Digital Will Solution for Posthumous Data Management,2025-01-09T01:25:13Z,"Xinzhang Chen, Arash Shaghaghi, Jesse Laeuchli, Salil Kanhere","In the digital era, managing posthumous data presents a growing challenge,
with current technical solutions often falling short in practicality. Existing
tools are typically closed-source, lack transparency, fail to offer
cross-platform support, and provide limited access control. This paper
introduces `Beyond Life', a cross-platform digital will management solution
designed to securely handle and distribute digital assets after death. At the
core of this solution is a customized Ciphertext-Policy Attribute-Based
Encryption (CP-ABE) scheme, referred to as PD-CP-ABE, which enables efficient,
fine-grained control over access to will content at scale. Unlike existing
systems, Beyond Life operates independently of service providers, offering
users greater transparency and control over how their will is generated,
stored, and executed. The system is also designed to be portable, allowing
users to change their will service provider. The proposed system has been fully
developed and rigorously evaluated to ensure performance and real-world
feasibility. The system implementation is made publicly available.",http://arxiv.org/abs/2501.04900v2
"Theoretical study of the Spectroscopic measurements of Kerr non-linear
  resonators with four-body interaction",2025-01-09T05:43:57Z,"Yuichiro Matsuzaki, Yuichiro Mori, Aiko Yamaguchi, Yohei Kawakami, Tsuyoshi Yamamoto","Quantum annealing provides a promising way to solve combinational
optimization problems where the solutions correspond to the ground state of the
Ising Hamiltonian. We can implement quantum annealing using the Kerr non-linear
resonators, with bifurcation phenomena emerging when subjected to a parametric
drive. These bifurcated states can function as bases of qubits. Moreover,
integrating four-body interactions between physical qubits enables the
establishment of effective all-to-all long-range interactions between logical
qubits, which is essential for practical quantum annealing. While theoretical
proposals exist for creating four-body interactions within Kerr non-linear
resonators, there has not been experimental verification through their
spectroscopic signatures. In this paper, we theoretically investigate the
spectroscopic measurements of Kerr non-linear resonators featuring four-body
interaction. We identify six distinct frequencies exhibiting population changes
by employing resonant driving on one resonator and weak driving on another.
Analytical and numerical calculations validate these findings. Our study
demonstrates the potential of spectroscopy in characterizing systems with
four-body interactions, offering insights for realizing quantum annealing with
Kerr parametric oscillators.",http://arxiv.org/abs/2501.04981v1
"Continuous Knowledge-Preserving Decomposition for Few-Shot Continual
  Learning",2025-01-09T07:18:48Z,"Xiaojie Li, Yibo Yang, Jianlong Wu, David A. Clifton, Yue Yu, Bernard Ghanem, Min Zhang","Few-shot class-incremental learning (FSCIL) involves learning new classes
from limited data while retaining prior knowledge, and often results in
catastrophic forgetting. Existing methods either freeze backbone networks to
preserve knowledge, which limits adaptability, or rely on additional modules or
prompts, introducing inference overhead. To this end, we propose Continuous
Knowledge-Preserving Decomposition for FSCIL (CKPD-FSCIL), a framework that
decomposes a model's weights into two parts: one that compacts existing
knowledge (knowledge-sensitive components) and another that carries redundant
capacity to accommodate new abilities (redundant-capacity components). The
decomposition is guided by a covariance matrix from replay samples, ensuring
principal components align with classification abilities. During adaptation, we
freeze the knowledge-sensitive components and only adapt the redundant-capacity
components, fostering plasticity while minimizing interference without changing
the architecture or increasing overhead. Additionally, CKPD introduces an
adaptive layer selection strategy to identify layers with redundant capacity,
dynamically allocating adapters. Experiments on multiple benchmarks show that
CKPD-FSCIL outperforms state-of-the-art methods.",http://arxiv.org/abs/2501.05017v1
"Perception-as-Control: Fine-grained Controllable Image Animation with
  3D-aware Motion Representation",2025-01-09T07:23:48Z,"Yingjie Chen, Yifang Men, Yuan Yao, Miaomiao Cui, Liefeng Bo","Motion-controllable image animation is a fundamental task with a wide range
of potential applications. Recent works have made progress in controlling
camera or object motion via various motion representations, while they still
struggle to support collaborative camera and object motion control with
adaptive control granularity. To this end, we introduce 3D-aware motion
representation and propose an image animation framework, called
Perception-as-Control, to achieve fine-grained collaborative motion control.
Specifically, we construct 3D-aware motion representation from a reference
image, manipulate it based on interpreted user intentions, and perceive it from
different viewpoints. In this way, camera and object motions are transformed
into intuitive, consistent visual changes. Then, the proposed framework
leverages the perception results as motion control signals, enabling it to
support various motion-related video synthesis tasks in a unified and flexible
way. Experiments demonstrate the superiority of the proposed framework. For
more details and qualitative results, please refer to our project webpage:
https://chen-yingjie.github.io/projects/Perception-as-Control.",http://arxiv.org/abs/2501.05020v1
"Rudin Inequality, Chang Theorem, primes and squares",2025-01-09T08:25:22Z,Olivier Ramaré,"We prove that the set of large values of the trigonometric polynomial over a
subset of density of the primes has some additive structure, similarly to what
happens for subsets of densities in $\mathbb{Z}/{N}\mathbb{Z}$ but in a weaker
form. To do so, we prove large sieve inequalities for \emph{dissociate sets}
$\mathcal{X}$ of circle points and functions $f$ whose support~$S$ is finite
and respectively in an interval, in the set of primes or in the set of squares.
Set $T(f,x)=\sum_{n}f(n)\exp(2i\pi nx)$. These inequalities are of the shape
$\sum_{x\in\mathcal{X}}|T(f,x)|^2\ll |S|\|f\|_2^2\log(8R/|S|)$ where $R$ is
respectively $N$, $N/\log N$ and $\sqrt{N}$. The implied constants depend on
the spacement between sumsets of~$\mathcal{X}$.",http://arxiv.org/abs/2501.05056v1
"Improving signal-to-noise ratios in pump-probe spectroscopy on
  light-sensitive samples by adapting pulse repetition rates",2025-01-09T10:24:29Z,"Matthias C. Velsink, Maksym Illienko, Komal Chaudhary, Stefan Witte","Ultrafast optical pump-probe spectroscopy is a powerful tool to study
dynamics in solid materials on femto- and picosecond timescales. In such
experiments, a pump pulse induces dynamics inside a sample by impulsive
light-matter interaction, resulting in dynamics that can be detected using a
time-delayed probe pulse. In addition to the desired dynamics, the initial
interaction may also lead to unwanted effects that may result in irreversible
changes and even damage. Therefore, the achievable signal strength is often
limited by the pumping conditions that a sample can sustain. Here we
investigate the optimization of ultrafast photoacoustics in various solid thin
films. We perform systematic experiments aimed at maximizing the achievable
signal-to-noise (SNR) ratio in a given measurement time while limiting sample
damage. By varying pump and probe pulse energies, average pump fluence, and
repetition rate, we identify different paths towards optimal SNR depending on
material properties. Our results provide a strategy for the design of
pump-probe experiments, to optimize achievable SNR for samples in which
different damage mechanisms may dominate.",http://arxiv.org/abs/2501.05121v1
Frustration Induced Chimeras and Motion in Two Dimensional Swarmalators,2025-01-09T10:39:53Z,"R. Senthamizhan, R. Gopal, V. K. Chandrasekar","Swarmalators are phase oscillators capable of simultaneous swarming and
synchronization, making them potential candidates for replicating complex
dynamical states. In this work, we explore the effects of a frustration
parameter in the phase interaction functions of a two-dimensional swarmalator
model inspired by the solvable Sakaguchi-swarmalators that move in a
one-dimensional ring. The impact of the frustration parameter in these models
has been a topic of great interest. Real-world coupled systems with frustration
exhibit remarkable collective dynamical states, underscoring the relevance of
this study. The frustration parameter induces various states exhibiting
non-stationarity, chimeric clustering, and global translational motion, where
swarmalators move spontaneously in two-dimensional space. We investigate the
characteristics of these states and their responses to changes in the
frustration parameter. Notably, the emergence of chimeric states suggests the
crucial role of non-stationarity in phase interactions for spontaneous
population clustering. Additionally, we examine how phase non-stationarity
influences the spatial positions of swarmalators and provide a classification
of these states based on different order parameters.",http://arxiv.org/abs/2501.05135v1
Polymorphism and Magnetism in a Kitaev Honeycomb Cobaltate KCoAsO$_4$,2025-01-09T10:53:23Z,"Yuya Haraguchi, Daisuke-Nishio Hamane, Hiroko Aruga Katori","We report the synthesis, crystal structure, and magnetic properties of a new
Kitaev honeycomb cobaltate, KCoAsO$_4$, which crystallizes in two distinct
forms: $P2/c$ and $R\bar{3}$ space groups. Magnetic measurements reveal
ordering temperatures of $\sim$14 K for the $P2/c$ structure and $\sim$10.5 K
for the $R\bar{3}$ structure. The $P2/c$-type KCoAsO$_4$ sample exhibits a
complex temperature-field phase diagram, including a field-induced phase, while
the $R\bar{3}$-type KCoAsO$_4$ shows a simpler phase diagram with a single
magnetically ordered phase. The observed differences in magnetic properties are
attributed to subtle structural variations, strongly suggesting that local
structural changes play a crucial role in determining the magnetism of
cobaltate-based Kitaev materials.",http://arxiv.org/abs/2501.05146v1
Explainable AI based System for Supply Air Temperature Forecast,2025-01-09T11:36:29Z,"Marika Eik, Ahmet Kose, Hossein Nourollahi Hokmabad, Juri Belikov","This paper explores the application of Explainable AI (XAI) techniques to
improve the transparency and understanding of predictive models in control of
automated supply air temperature (ASAT) of Air Handling Unit (AHU). The study
focuses on forecasting of ASAT using a linear regression with Huber loss.
However, having only a control curve without semantic and/or physical
explanation is often not enough. The present study employs one of the XAI
methods: Shapley values, which allows to reveal the reasoning and highlight the
contribution of each feature to the final ASAT forecast. In comparison to other
XAI methods, Shapley values have solid mathematical background, resulting in
interpretation transparency. The study demonstrates the contrastive
explanations--slices, for each control value of ASAT, which makes it possible
to give the client objective justifications for curve changes.",http://arxiv.org/abs/2501.05163v1
"CoDe: Communication Delay-Tolerant Multi-Agent Collaboration via Dual
  Alignment of Intent and Timeliness",2025-01-09T12:57:41Z,"Shoucheng Song, Youfang Lin, Sheng Han, Chang Yao, Hao Wu, Shuo Wang, Kai Lv","Communication has been widely employed to enhance multi-agent collaboration.
Previous research has typically assumed delay-free communication, a strong
assumption that is challenging to meet in practice. However, real-world agents
suffer from channel delays, receiving messages sent at different time points,
termed {\it{Asynchronous Communication}}, leading to cognitive biases and
breakdowns in collaboration. This paper first defines two communication delay
settings in MARL and emphasizes their harm to collaboration. To handle the
above delays, this paper proposes a novel framework, Communication
Delay-tolerant Multi-Agent Collaboration (CoDe). At first, CoDe learns an
intent representation as messages through future action inference, reflecting
the stable future behavioral trends of the agents. Then, CoDe devises a dual
alignment mechanism of intent and timeliness to strengthen the fusion process
of asynchronous messages. In this way, agents can extract the long-term intent
of others, even from delayed messages, and selectively utilize the most recent
messages that are relevant to their intent. Experimental results demonstrate
that CoDe outperforms baseline algorithms in three MARL benchmarks without
delay and exhibits robustness under fixed and time-varying delays.",http://arxiv.org/abs/2501.05207v1
"ParaRev: Building a dataset for Scientific Paragraph Revision annotated
  with revision instruction",2025-01-09T13:19:55Z,"Léane Jourdan, Nicolas Hernandez, Richard Dufour, Florian Boudin, Akiko Aizawa","Revision is a crucial step in scientific writing, where authors refine their
work to improve clarity, structure, and academic quality. Existing approaches
to automated writing assistance often focus on sentence-level revisions, which
fail to capture the broader context needed for effective modification. In this
paper, we explore the impact of shifting from sentence-level to paragraph-level
scope for the task of scientific text revision. The paragraph level definition
of the task allows for more meaningful changes, and is guided by detailed
revision instructions rather than general ones. To support this task, we
introduce ParaRev, the first dataset of revised scientific paragraphs with an
evaluation subset manually annotated with revision instructions. Our
experiments demonstrate that using detailed instructions significantly improves
the quality of automated revisions compared to general approaches, no matter
the model or the metric considered.",http://arxiv.org/abs/2501.05222v1
"The Intraday Bitcoin Response to Tether Minting and Burning Events:
  Asymmetry, Investor Sentiment, And ""Whale Alerts"" On Twitter",2025-01-09T13:39:22Z,Aman Saggu,"Tether Limited has the sole authority to create (mint) and destroy (burn)
Tether stablecoins (USDT). This paper investigates Bitcoin's response to USDT
supply change events between 2014 and 2021 and identifies an interesting
asymmetry between Bitcoin's responses to USDT minting and burning events.
Bitcoin responds positively to USDT minting events over 5- to 30-minute event
windows, but this response begins declining after 60 minutes. State-dependence
is also demonstrated, with Bitcoin prices exhibiting a greater increase when
the corresponding USDT minting event coincides with positive investor sentiment
and is announced to the public by data service provider, Whale Alert, on
Twitter.",http://arxiv.org/abs/2501.05232v1
Randomized Spectral Clustering for Large-Scale Multi-Layer Networks,2025-01-09T15:50:59Z,"Wenqing Su, Xiao Guo, Xiangyu Chang, Ying Yang","Large-scale multi-layer networks with large numbers of nodes, edges, and
layers arise across various domains, which poses a great computational
challenge for the downstream analysis. In this paper, we develop an efficient
randomized spectral clustering algorithm for community detection of multi-layer
networks. We first utilize the random sampling strategy to sparsify the
adjacency matrix of each layer. Then we use the random projection strategy to
accelerate the eigen-decomposition of the sum-of-squared sparsified adjacency
matrices of all layers. The communities are finally obtained via the k-means of
the eigenvectors. The algorithm not only has low time complexity but also saves
the storage space. Theoretically, we study the misclassification error rate of
the proposed algorithm under the multi-layer stochastic block models, which
shows that the randomization does not deteriorate the error bound under certain
conditions. Numerical studies on multi-layer networks with millions of nodes
show the superior efficiency of the proposed algorithm, which achieves
clustering results rapidly. A new R package called MLRclust is developed and
made available to the public.",http://arxiv.org/abs/2501.05326v1
"CROPS: Model-Agnostic Training-Free Framework for Safe Image Synthesis
  with Latent Diffusion Models",2025-01-09T16:43:21Z,"Junha Park, Ian Ryu, Jaehui Hwang, Hyungkeun Park, Jiyoon Kim, Jong-Seok Lee","With advances in diffusion models, image generation has shown significant
performance improvements. This raises concerns about the potential abuse of
image generation, such as the creation of explicit or violent images, commonly
referred to as Not Safe For Work (NSFW) content. To address this, the Stable
Diffusion model includes several safety checkers to censor initial text prompts
and final output images generated from the model. However, recent research has
shown that these safety checkers have vulnerabilities against adversarial
attacks, allowing them to generate NSFW images. In this paper, we find that
these adversarial attacks are not robust to small changes in text prompts or
input latents. Based on this, we propose CROPS (Circular or RandOm Prompts for
Safety), a model-agnostic framework that easily defends against adversarial
attacks generating NSFW images without requiring additional training. Moreover,
we develop an approach that utilizes one-step diffusion models for efficient
NSFW detection (CROPS-1), further reducing computational resources. We
demonstrate the superiority of our method in terms of performance and
applicability.",http://arxiv.org/abs/2501.05359v1
Some factorization results for formal power series,2025-01-09T16:58:40Z,"Rishu Garg, Jitender Singh","In this paper, we obtain some factorization results on formal power series
over principle ideal domains with sharp bounds on number of irreducible
factors. These factorization results correspondingly lead to irreducibility
criteria for formal power series. The information about prime factorization of
the constant term up to a unit and that of some higher order terms is utilized
for the purpose. Further, using theory of Newton polygons for power series, we
extend the classical Dumas irreducibility criterion to formal power series over
discrete valuation domains, which in particular, yields several irreducibility
criteria.",http://arxiv.org/abs/2501.05375v2
"TimeDP: Learning to Generate Multi-Domain Time Series with Domain
  Prompts",2025-01-09T17:57:56Z,"Yu-Hao Huang, Chang Xu, Yueying Wu, Wu-Jun Li, Jiang Bian","Time series generation models are crucial for applications like data
augmentation and privacy preservation. Most existing time series generation
models are typically designed to generate data from one specified domain. While
leveraging data from other domain for better generalization is proved to work
in other application areas, this approach remains challenging for time series
modeling due to the large divergence in patterns among different real world
time series categories. In this paper, we propose a multi-domain time series
diffusion model with domain prompts, named TimeDP. In TimeDP, we utilize a time
series semantic prototype module which defines time series prototypes to
represent time series basis, each prototype vector serving as ""word""
representing some elementary time series feature. A prototype assignment module
is applied to extract the extract domain specific prototype weights, for
learning domain prompts as generation condition. During sampling, we extract
""domain prompt"" with few-shot samples from the target domain and use the domain
prompts as condition to generate time series samples. Experiments demonstrate
that our method outperforms baselines to provide the state-of-the-art in-domain
generation quality and strong unseen domain generation capability.",http://arxiv.org/abs/2501.05403v1
From Simple to Complex Skills: The Case of In-Hand Object Reorientation,2025-01-09T18:49:39Z,"Haozhi Qi, Brent Yi, Mike Lambeta, Yi Ma, Roberto Calandra, Jitendra Malik","Learning policies in simulation and transferring them to the real world has
become a promising approach in dexterous manipulation. However, bridging the
sim-to-real gap for each new task requires substantial human effort, such as
careful reward engineering, hyperparameter tuning, and system identification.
In this work, we present a system that leverages low-level skills to address
these challenges for more complex tasks. Specifically, we introduce a
hierarchical policy for in-hand object reorientation based on previously
acquired rotation skills. This hierarchical policy learns to select which
low-level skill to execute based on feedback from both the environment and the
low-level skill policies themselves. Compared to learning from scratch, the
hierarchical policy is more robust to out-of-distribution changes and transfers
easily from simulation to real-world environments. Additionally, we propose a
generalizable object pose estimator that uses proprioceptive information,
low-level skill predictions, and control errors as inputs to estimate the
object pose over time. We demonstrate that our system can reorient objects,
including symmetrical and textureless ones, to a desired pose.",http://arxiv.org/abs/2501.05439v1
"The more polypersonal the better -- a short look on space geometry of
  fine-tuned layers",2025-01-09T18:50:47Z,"Sergei Kudriashov, Veronika Zykova, Angelina Stepanova, Yakov Raskind, Eduard Klyshinsky","The interpretation of deep learning models is a rapidly growing field, with
particular interest in language models. There are various approaches to this
task, including training simpler models to replicate neural network predictions
and analyzing the latent space of the model. The latter method allows us to not
only identify patterns in the model's decision-making process, but also
understand the features of its internal structure. In this paper, we analyze
the changes in the internal representation of the BERT model when it is trained
with additional grammatical modules and data containing new grammatical
structures (polypersonality). We find that adding a single grammatical layer
causes the model to separate the new and old grammatical systems within itself,
improving the overall performance on perplexity metrics.",http://arxiv.org/abs/2501.05503v1
"Sub-band Domain Multi-Hypothesis Acoustic Echo Canceler Based Acoustic
  Scene Analysis",2025-01-10T01:43:26Z,"Benjamin J Southwell, Yin-Lee Ho, David Gunawan","This paper introduces a novel approach for acoustic scene analysis by
exploiting an ensemble of statistics extracted from a sub-band domain
multi-hypothesis acoustic echo canceler (SDMH-AEC). A well-designed SDMH-AEC
employs multiple adaptive filtering strategies with potentially complementary
behaviours during convergence, perturbations, and steady-state conditions. By
aggregating statistics across the sub-bands, we derive a feature vector that
exhibits strong discriminative power for distinguishing different acoustic
events and estimating acoustic parameters. The complementary nature of the
SDMH-AEC filters provides a rich source of information that can be extracted at
insignificant cost for acoustic scene analysis tasks. We demonstrate the
effectiveness of the proposed approach experimentally with real data containing
double-talk, echo path change and events where the full-duplex device is
physically moved. The extracted features enable acoustic scene analysis using
existing echo cancellation algorithms and techniques.",http://arxiv.org/abs/2501.05652v1
"ExoFabric: A Re-moldable Textile System for Creating Customizable Soft
  Goods and Wearable Applications",2025-01-10T02:31:09Z,"Rosalie Lin, Aditi Maheshwari, Jung Wook Park, Andreea Danielescu","Fabric has been a fundamental part of human life for thousands of years,
providing comfort, protection, and aesthetic expression. While modern
advancements have enhanced fabric's functionality, it remains static and
unchangeable, failing to adapt to our evolving body shapes and preferences.
This lack of adaptability can lead to unsustainable practices, as consumers
often buy more items to meet their changing needs. In this paper, we propose
ExoFabric, a re-moldable fabric system for customized soft goods applications.
We created ExoFabric by embedding thermoplastic threads into fabric through
computerized embroidery to allow for tunability between rigid plastic and
conformable fabric. We defined a library of design primitives to enable
geometric formability, stiffness, and stretchability by identifying suitable
fabrics, threads, embroidery parameters, and machine limitations. To facilitate
practical applications, we demonstrated practical methods for linking
parameters to application requirements, showcasing form-fitting wearables,
structural support, and shape-changeable furniture for repeatable or one-time
customization.",http://arxiv.org/abs/2501.05664v1
Towards optimization of the Josephson diode effect,2025-01-10T02:44:51Z,"Michiyasu Mori, Wataru Koshibae, Sadamichi Maekawa","We theoretically study the Josephson diode effect in the junction of singlet
superconductors separated by the Rashba system in the in-plane magnetic field
perpendicular to the bias current. The coupling energy of two superconductors
is formulated under the bias current using a tunneling Hamiltonian with a
one-dimensional model. The bias current shifts the Fermi momentum in the Rashba
system due to the continuity of the electronic current. Including the shift of
Fermi momentum in the coupling energy, it is found that the critical current is
asymmetric with respect to the current and the magnetic field, i.e., Josephson
diode effect. Depending on a distance between the superconducting electrodes
$d$, the Josephson diode effect changes its magnitude and sign. The magnitude
is inversely proportional to a band split caused by the spin-orbit interaction.
Since $d$ is experimentally controllable, the Josephson diode effect can be
optimized by tuning of $d$. Our theory develops a new guiding principle to
design the Josephson diode device.",http://arxiv.org/abs/2501.05671v2
"A Belyi-type criterion for vector bundles on curves defined over a
  number field",2025-01-10T03:10:56Z,"Indranil Biswas, Sudarshan Gurjar","Let $X_0$ be an irreducible smooth projective curve defined over
$\overline{\mathbb Q}$ and $f_0 : X_0 \rightarrow
\mathbb{P}^1_{\overline{\mathbb Q}}$ a nonconstant morphism whose branch locus
is contained in the subset $\{0,1, \infty\} \subset
\mathbb{P}^1_{\overline{\mathbb Q}}$. For any vector bundle $E$ on $X =
X_0\times_{{\rm Spec}\,\overline{\mathbb Q}} {\rm Spec} \mathbb{C}$, consider
the direct image $f_*E$ on $\mathbb{P}^1_{\mathbb C}$, where $f= (f_0)_{\mathbb
C}$. It decomposes into a direct sum of line bundles and also it has a natural
parabolic structure. We prove that $E$ is the base change, to $\mathbb C$, of a
vector bundle on $X_0$ if and only if there is an isomorphism $f_*E
\stackrel{\sim}{\rightarrow} \bigoplus_{i=1}^r {\mathcal O}_{{\mathbb
P}^1_{\mathbb C}}(m_i)$, where $r = {\rm rank}(f_*E)$, that takes the parabolic
structure on $f_*E$ to a parabolic structure on $\bigoplus_{i=1}^r {\mathcal
O}_{{\mathbb P}^1_{\mathbb C}}(m_i)$ defined over $\overline{\mathbb Q}$.",http://arxiv.org/abs/2501.05681v1
"Exoplanet Ephemerides Change Observations (ExoEcho). I. Transit Timing
  Analysis of Thirty-Seven Exoplanets using HST/WFC3 Data",2025-01-10T04:28:16Z,"Xinyue Ma, Wenqin Wang, Zixin Zhang, Cong Yu, Dichang Chen, Jiwei Xie, Shangfei Liu, Li Zhou, Bo Ma","The ExoEcho project is designed to study the photodynamics of exoplanets by
leveraging high-precision transit timing data from ground- and space-based
telescopes. Some exoplanets are experiencing orbital decay, and transit timing
variation (TTV) is a useful technique to study their orbital period variations.
In this study, we have obtained transit middle-time data from the Hubble Space
Telescope (HST) observations for 37 short-period exoplanets, most of which are
hot Jupiters. To search for potential long- and short-term orbital period
variations within the sample, we conduct TTV model fitting using both linear
and quadratic ephemeris models. Our analysis identifies two hot Jupiters
experiencing strong periodic decays. Given the old age of the host stars of the
hot Jupiter population, our findings call for a scenario where HJs are
continuously being destructed and created. Our study demonstrates the
importance of incorporating high-precision transit timing data to TTV study in
the future.",http://arxiv.org/abs/2501.05704v1
"Semantic Mapping in Indoor Embodied AI -- A Comprehensive Survey and
  Future Directions",2025-01-10T06:58:14Z,"Sonia Raychaudhuri, Angel X. Chang","Intelligent embodied agents (e.g. robots) need to perform complex semantic
tasks in unfamiliar environments. Among many skills that the agents need to
possess, building and maintaining a semantic map of the environment is most
crucial in long-horizon tasks. A semantic map captures information about the
environment in a structured way, allowing the agent to reference it for
advanced reasoning throughout the task. While existing surveys in embodied AI
focus on general advancements or specific tasks like navigation and
manipulation, this paper provides a comprehensive review of semantic
map-building approaches in embodied AI, specifically for indoor navigation. We
categorize these approaches based on their structural representation (spatial
grids, topological graphs, dense point-clouds or hybrid maps) and the type of
information they encode (implicit features or explicit environmental data). We
also explore the strengths and limitations of the map building techniques,
highlight current challenges, and propose future research directions. We
identify that the field is moving towards developing open-vocabulary,
queryable, task-agnostic map representations, while high memory demands and
computational inefficiency still remaining to be open challenges. This survey
aims to guide current and future researchers in advancing semantic mapping
techniques for embodied AI systems.",http://arxiv.org/abs/2501.05750v1
"Hierarchical Serpentine-like Organic Crystal Optical Waveguides for
  Artificial Neural Networks",2025-01-10T10:10:46Z,"Avulu Vinod Kumar, Mehdi Rohullah, Melchi Chosenyah, Sinduja Gaddam, Rajadurai Chandrasekar","Optical components and circuits that deal with multiple signal generation and
processing are quintessential for artificial neural networks. Herein, we
present a proof-of-concept four-layered organic optical artificial neural
network (ANN)-like architecture, constructed from flexible organic crystals of
(E)-1-(((5-methylpyridin-2-yl)imino)methyl)naphthalene-2-ol (MPyIN), employing
an atomic force microscopy cantilever tip-based mechanical micromanipulation
technique. Initially, the strategic selection of four MPyIN crystal active
waveguides of varying lengths, mechanically bending them into serpentine-like
forms, followed by their hierarchical integration, creates neuron-like,
four-layered interconnected optical waveguides with six optical synapses. The
synapses in the ANN-like architecture enable parallel transmissions of passive
optical signals via evanescent coupling across multiple paths through various
layers of the serpentine-shaped optical waveguides. Notably, the feedforward
mechanism allows the synapses to multiply and split the optical signal
generated at any input into four diverging signals with varying magnitudes.
Here, certain outputs deliver a mixed signal (passive and active) due to
diverging and converging optical transmission paths. This hierarchical,
ANN-like tiny architecture paves the way for the development of smart optical
neural networks utilizing multiple emissive and phase-changing organic
crystals.",http://arxiv.org/abs/2501.05831v1
"Affordably Fine-tuned LLMs Provide Better Answers to Course-specific
  MCQs",2025-01-10T11:44:35Z,"Bianca Raimondi, Saverio Giallorenzo, Maurizio Gabbrielli","In education, the capability of generating human-like text of Large Language
Models (LLMs) inspired work on how they can increase the efficiency of learning
and teaching. We study the affordability of these models for educators and
students by investigating how LLMs answer multiple-choice questions (MCQs) with
respect to hardware constraints and refinement techniques. We explore this
space by using generic pre-trained LLMs (the 7B, 13B, and 70B variants of
LLaMA-2) to answer 162 undergraduate-level MCQs from a course on Programming
Languages (PL) -- the MCQ dataset is a contribution of this work, which we make
publicly available. Specifically, we dissect how different factors, such as
using readily-available material -- (parts of) the course's textbook -- for
fine-tuning and quantisation (to decrease resource usage) can change the
accuracy of the responses. The main takeaway is that smaller textbook-based
fine-tuned models outperform generic larger ones (whose pre-training requires
conspicuous resources), making the usage of LLMs for answering MCQs resource-
and material-wise affordable.",http://arxiv.org/abs/2501.05891v1
"Environment Modeling for Service Robots From a Task Execution
  Perspective",2025-01-10T12:54:33Z,"Ying Zhang, Guohui Tian, Cui-Hua Zhang, Changchun Hua, Weili Ding, Choon Ki Ahn","Service robots are increasingly entering the home to provide domestic tasks
for residents. However, when working in an open, dynamic, and unstructured home
environment, service robots still face challenges such as low intelligence for
task execution and poor long-term autonomy (LTA), which has limited their
deployment. As the basis of robotic task execution, environment modeling has
attracted significant attention. This integrates core technologies such as
environment perception, understanding, and representation to accurately
recognize environmental information. This paper presents a comprehensive survey
of environmental modeling from a new task-executionoriented perspective. In
particular, guided by the requirements of robots in performing domestic service
tasks in the home environment, we systematically review the progress that has
been made in task-execution-oriented environmental modeling in four respects:
1) localization, 2) navigation, 3) manipulation, and 4) LTA. Current challenges
are discussed, and potential research opportunities are also highlighted.",http://arxiv.org/abs/2501.05931v1
Noetherian rings of non-local rank,2025-01-10T13:04:06Z,Dmitry Kudryakov,"The rank of a ring $R$ is the supremum of minimal cardinalities of generating
sets of $I$, among all ideals $I$ in $R$. In this paper, we obtain a
characterization of Noetherian rings $R$ whose rank is not equal to the
supremum of ranks of localizations of $R$ at maximal ideals. It turns out that
any such ring is a direct product of a finite number of local principal
Artinian rings and Dedekind domains, at least one of which is not principal
ideal ring. As an application, we show that the rank of the ring of polynomials
over an Artinian ring can be computed locally.",http://arxiv.org/abs/2501.05940v2
Non-Abelian interlayer coherent fractional quantum Hall states,2025-01-10T15:19:50Z,"Xiang-Jian Hou, Lei Wang, Ying-Hai Wu","We study non-Abelian fractional quantum Hall state in double layer systems at
total filling factor $1/2$. Recent progresses in two-dimensional van der Waals
materials made it possible to explore the regime with very small interlayer
distance. Numerical calculations suggests interlayer phase coherence can
develop between the layers such that the electrons may redistribute between
them without changing the Hall response. It corresponds to spontaneous breaking
of the U(1) symmetry associated with the particle number difference in the
layers. This state manifests itself as superfluid in counterflow measurement
and has characteristic Hall response when current is passed through one layer
and voltages in both layers are measured. As the interlayer distance increases,
a phase transition into the Halperin 331 state occurs. We also discuss similar
physics for bosonic systems with specially designed interactions.",http://arxiv.org/abs/2501.06041v1
"Effects of disorder on the quantum transport properties in topologically
  nontrivial metal PbTaSe$_{2}$",2025-01-10T05:45:15Z,"Longfei Sun, Yue Sun, Qiang Hou, R. Sankar, R. Kalaivanan, Xiaofeng Xu, Zhixiang Shi, Tsuyoshi Tamegai","Weak antilocalization (WAL), an increase in the electrical conductivity at
low temperatures associated with the suppression of electron localization due
to quantum interference effects, is often observed in topological materials. In
this study, we report the observation of WAL in topologically nontrivial metal
PbTaSe$_{2}$ at low temperatures. In the pristine sample, we identified the
presence of WAL, which is attributed to the topologically protected
backscattering. In order to investigate the influence of disorder on the WAL,
we successively introduced controlled amounts of disorder by
H$^{+}$-irradiation. As disorder increases, the dip-like magnetoresistance
caused by WAL changes to a linear magnetoresistance(MR), and eventually to a
quadratic MR as the electronic system becomes highly localized. This research
unveils the significance of disorder in shaping the quantum transport
characteristics of topological materials.",http://arxiv.org/abs/2501.06272v1
On How Traffic Signals Impact the Fundamental Diagrams of Urban Roads,2025-01-10T19:06:50Z,"Chao Zhang, Yechen Li, Neha Arora, Carolina Osorio","Being widely adopted by the transportation and planning practitioners, the
fundamental diagram (FD) is the primary tool used to relate the key macroscopic
traffic variables of speed, flow, and density. We empirically analyze the
relation between vehicular space-mean speeds and flows given different signal
settings and postulate a parsimonious parametric function form of the
traditional FD where its function parameters are explicitly modeled as a
function of the signal plan factors. We validate the proposed formulation using
data from signalized urban road segments in Salt Lake City, Utah, USA. The
proposed formulation builds our understanding of how changes to signal settings
impact the FDs, and more generally the congestion patterns, of signalized urban
segments.",http://arxiv.org/abs/2501.06306v1
Maximum Likelihood Detection of Instrumental Glitches in LISA TDI Data,2025-01-10T19:32:12Z,"Orion Sauter, Peter Wass, Wiler Sanchez, Henri Inchauspé","The orbiting LISA instrument is designed to detect gravitational waves in the
millihertz band, produced by sources including galactic binaries and extreme
mass ratio inspirals, among others. The detector consists of three spacecraft,
each carrying a pair of free-falling test masses. A technology-demonstration
mission, LISA Pathfinder, was launched in 2015, and observed several sudden
changes in test mass acceleration, referred to as ""glitches."" Similar glitches
in the full LISA mission have the potential to contaminate the Time-Delay
Interferometry outputs that are the detector's primary data product. In this
paper, we describe an optimization technique using maximum likelihood
estimation for detecting and removing glitches with a known waveform.",http://arxiv.org/abs/2501.06315v2
"High-Speed Tunable Generation of Random Number Distributions Using
  Actuated Perpendicular Magnetic Tunnel Junctions",2025-01-10T19:42:28Z,"Ahmed Sidi El Valli, Michael Tsao, J. Darby Smith, Shashank Misra, Andrew D. Kent","Perpendicular magnetic tunnel junctions (pMTJs) actuated by nanosecond pulses
are emerging as promising devices for true random number generation (TRNG) due
to their intrinsic stochastic behavior and high throughput. In this work, we
study the tunability and quality of random-number distributions generated by
pMTJs operating at a frequency of 104 MHz. First, changing the pulse amplitude
is used to systematically vary the probability bias. The variance of the
resulting bitstreams is shown to follow the expected binomial distribution.
Second, the quality of uniform distributions of 8-bit random numbers generated
with a probability bias of 0.5 is considered. A reduced chi-square analysis of
this data shows that two XOR operations are necessary to achieve this
distribution with p-values greater than 0.05. Finally, we show that there is a
correlation between long-term probability bias variations and pMTJ resistance.
These findings suggest that variations in the characteristics of the pMTJ
underlie the observed variation of probability bias. Our results highlight the
potential of stochastically actuated pMTJs for high-speed, tunable TRNG
applications, showing the importance of the stability of pMTJs device
characteristics in achieving reliable, long-term performance.",http://arxiv.org/abs/2501.06318v1
"Quantification of Nuclear Coordinate Activation on Polaritonic Potential
  Energy Surfaces",2025-01-10T22:04:49Z,"Shahzad Alam, Yicheng Liu, Russell J. Holmes, Renee R. Frontiera","Polaritonic states, which arise from strong coupling between light and
matter, show great promise in modifying chemical reactivity. However,
reproducible enhancement of chemical reactions with polaritons is challenging
due to a lack of understanding on how to launch wavepackets along productive
reactive coordinates while avoiding unproductive local minima in the
multidimensional potential energy landscape. Here we employ resonance Raman
intensity analysis to quantify mode-specific nuclear displacement values in
pentacene thin films and pentacene exciton-polaritons. We find that coupling
significantly changes the potential energy landscape, including both
enhancement and suppression of nuclear displacements. We demonstrate that
controlling cavity parameters enables selective steering of vibronic
wavepackets. Our approach provides a quantitative methodology for screening
polaritonic catalysts and opens new avenues for designing reproducible and
effective cavity-controlled chemistry.",http://arxiv.org/abs/2501.06364v1
Resilient Endurance-Aware NVM-based PUF against Learning-based Attacks,2025-01-10T22:30:11Z,"Hassan Nassar, Ming-Liang Wei, Chia-Lin Yang, Jörg Henkel, Kuan-Hsun Chen","Physical Unclonable Functions (PUFs) based on Non-Volatile Memory (NVM)
technology have emerged as a promising solution for secure authentication and
cryptographic applications. By leveraging the multi-level cell (MLC)
characteristic of NVMs, these PUFs can generate a wide range of unique
responses, enhancing their resilience to machine learning (ML) modeling
attacks. However, a significant issue with NVM-based PUFs is their endurance
problem; frequent write operations lead to wear and degradation over time,
reducing the reliability and lifespan of the PUF.
  This paper addresses these issues by offering a comprehensive model to
predict and analyze the effects of endurance changes on NVM PUFs. This model
provides insights into how wear impacts the PUF's quality and helps in
designing more robust PUFs. Building on this model, we present a novel design
for NVM PUFs that significantly improves endurance. Our design approach
incorporates advanced techniques to distribute write operations more evenly and
reduce stress on individual cells. The result is an NVM PUF that demonstrates a
$62\times$ improvement in endurance compared to current state-of-the-art
solutions while maintaining protection against learning-based attacks.",http://arxiv.org/abs/2501.06367v1
"Frequency-dependent specific heat in quantum supercooled liquids: A
  mode-coupling study",2025-01-11T06:57:54Z,"Ankita Das, Eran Rabani, Kunimasa Miyazaki, Upendra Harbola","Frequency-dependence of specific heat in supercooled hard sphere liquid is
computed using quantum mode-coupling theory (QMCT). Mode-coupling equations are
solved using recently proposed perturbative method that allows to study
relaxation in the moderate quantum regime where quantum effects assist liquid
to glass transition. Zwanzig's formulation is used to compute the
frequency-dependent specific heat in supercooled state using dynamical
information from QMCT. Specific heat shows strong variation as the quantumness
of the liquid is changed, which becomes more significant as density is
increased. It is found that, near the transition point, different dynamical
modes contribute to the specific heat in the classical and the quantum liquids.",http://arxiv.org/abs/2501.06455v1
Tagged particle dynamics in supercooled quantum liquid,2025-01-11T07:03:53Z,"Ankita Das, Gopika Krishnan, Eran Rabani, Upendra Harbola","We analyze dynamics of quantum supercooled liquids in terms of tagged
particle dynamics. Unlike the classical case, uncertainty in the position of a
particle in quantum liquid leads to qualitative changes. We demonstrate these
effects in the dynamics of the first two moments of displacements, namely, the
mean-squared displacement, $\langle \Delta r^2(t)\rangle$, and $\langle \Delta
r^4(t)\rangle$. Results are presented for a hard sphere liquid using
mode-coupling theory (MCT) formulation and simulation on a binary Lennard-Jones
liquid. As the quantumness (controlled by the de-Broglie thermal wavelength) is
increased, a non-zero value of the moments at zero time leads to significant
deviations from the classical behavior in the initial dynamics. Initial
displacement shows ballistic behavior $\langle \Delta r^2(t)\rangle\sim t^2$,
but, as a result of large uncertainty in the position, the dynamical effects
become weaker with increasing quantumness over this time scale.",http://arxiv.org/abs/2501.06456v1
"The 1st SpeechWellness Challenge: Detecting Suicidal Risk Among
  Adolescents",2025-01-11T08:03:41Z,"Wen Wu, Ziyun Cui, Chang Lei, Yinan Duan, Diyang Qu, Ji Wu, Bowen Zhou, Runsen Chen, Chao Zhang","The 1st SpeechWellness Challenge (SW1) aims to advance methods for detecting
suicidal risk in adolescents using speech analysis techniques. Suicide among
adolescents is a critical public health issue globally. Early detection of
suicidal tendencies can lead to timely intervention and potentially save lives.
Traditional methods of assessment often rely on self-reporting or clinical
interviews, which may not always be accessible. The SW1 challenge addresses
this gap by exploring speech as a non-invasive and readily available indicator
of mental health. We release the SW1 dataset which contains speech recordings
from 600 adolescents aged 10-18 years. By focusing on speech generated from
natural tasks, the challenge seeks to uncover patterns and markers that
correlate with suicidal risk.",http://arxiv.org/abs/2501.06474v1
Whole-Body Integrated Motion Planning for Aerial Manipulators,2025-01-11T09:45:38Z,"Weiliang Deng, Hongming Chen, Biyu Ye, Haoran Chen, Ximin Lyu","Efficient motion planning for Aerial Manipulators (AMs) is essential for
tackling complex manipulation tasks, yet achieving coupled trajectory planning
remains challenging. In this work, we propose, to the best of our knowledge,
the first whole-body integrated motion planning framework for aerial
manipulators, which is facilitated by an improved Safe Flight Corridor (SFC)
generation strategy and high-dimensional collision-free trajectory planning. In
particular, we formulate an optimization problem to generate feasible
trajectories for both the quadrotor and manipulator while ensuring collision
avoidance, dynamic feasibility, kinematic feasibility, and waypoint
constraints. To achieve collision avoidance, we introduce a variable geometry
approximation method, which dynamically models the changing collision volume
induced by different manipulator configurations. Moreover, waypoint constraints
in our framework are defined in $\mathrm{SE(3)\times\mathbb{R}^3}$, allowing
the aerial manipulator to traverse specified positions while maintaining
desired attitudes and end-effector states. The effectiveness of our framework
is validated through comprehensive simulations and real-world experiments
across various environments.",http://arxiv.org/abs/2501.06493v1
Dynamic Causal Structure Discovery and Causal Effect Estimation,2025-01-11T12:52:39Z,"Jianian Wang, Rui Song","To represent the causal relationships between variables, a directed acyclic
graph (DAG) is widely utilized in many areas, such as social sciences,
epidemics, and genetics. Many causal structure learning approaches are
developed to learn the hidden causal structure utilizing deep-learning
approaches. However, these approaches have a hidden assumption that the causal
relationship remains unchanged over time, which may not hold in real life. In
this paper, we develop a new framework to model the dynamic causal graph where
the causal relations are allowed to be time-varying. We incorporate the basis
approximation method into the score-based causal discovery approach to capture
the dynamic pattern of the causal graphs. Utilizing the autoregressive model
structure, we could capture both contemporaneous and time-lagged causal
relationships while allowing them to vary with time. We propose an algorithm
that could provide both past-time estimates and future-time predictions on the
causal graphs, and conduct simulations to demonstrate the usefulness of the
proposed method. We also apply the proposed method for the covid-data analysis,
and provide causal estimates on how policy restriction's effect changes.",http://arxiv.org/abs/2501.06534v1
ACORD: An Expert-Annotated Retrieval Dataset for Legal Contract Drafting,2025-01-11T16:37:49Z,"Steven H. Wang, Maksim Zubkov, Kexin Fan, Sarah Harrell, Yuyang Sun, Wei Chen, Andreas Plesner, Roger Wattenhofer","Information retrieval, specifically contract clause retrieval, is
foundational to contract drafting because lawyers rarely draft contracts from
scratch; instead, they locate and revise the most relevant precedent. We
introduce the Atticus Clause Retrieval Dataset (ACORD), the first retrieval
benchmark for contract drafting fully annotated by experts. ACORD focuses on
complex contract clauses such as Limitation of Liability, Indemnification,
Change of Control, and Most Favored Nation. It includes 114 queries and over
126,000 query-clause pairs, each ranked on a scale from 1 to 5 stars. The task
is to find the most relevant precedent clauses to a query. The bi-encoder
retriever paired with pointwise LLMs re-rankers shows promising results.
However, substantial improvements are still needed to effectively manage the
complex legal work typically undertaken by lawyers. As the first retrieval
benchmark for contract drafting annotated by experts, ACORD can serve as a
valuable IR benchmark for the NLP community.",http://arxiv.org/abs/2501.06582v1
"Mean-field behavior of the quantum Ising susceptibility and a new lace
  expansion for the classical Ising model",2025-01-11T17:22:01Z,"Yoshinori Kamijima, Akira Sakai","The transverse-field Ising model is widely studied as one of the simplest
quantum spin systems. It is known that this model exhibits a phase transition
at the critical inverse temperature $\beta_{\mathrm{c}}(q)$, where $q$ is the
strength of the transverse field. Bj\""ornberg [Commun. Math. Phys., 232 (2013)]
investigated the divergence rate of the susceptibility for the nearest-neighbor
model as the critical point is approached by simultaneously changing $q$ and
the spin-spin coupling $J$ in a proper manner, with fixed temperature. In this
paper, we prove that the susceptibility diverges as
$(\beta_{\mathrm{c}}(q)-\beta)^{-1}$ as $\beta\uparrow\beta_{\mathrm{c}}(q)$
for $d>4$ assuming an infrared bound on the space-time two-point function. One
of the key elements is a stochastic-geometric representation in Bj\""ornberg &
Grimmett [J. Stat. Phys., 136 (2009)] and Crawford & Ioffe [Commun. Math.
Phys., 296 (2010)]. As a byproduct, we derive a new lace expansion for the
classical Ising model (i.e., $q=0$).",http://arxiv.org/abs/2501.06592v1
Wavelet Integrated Convolutional Neural Network for ECG Signal Denoising,2025-01-12T06:18:46Z,"Takamasa Terada, Masahiro Toyoura","Wearable electrocardiogram (ECG) measurement using dry electrodes has a
problem with high-intensity noise distortion. Hence, a robust noise reduction
method is required. However, overlapping frequency bands of ECG and noise make
noise reduction difficult. Hence, it is necessary to provide a mechanism that
changes the characteristics of the noise based on its intensity and type. This
study proposes a convolutional neural network (CNN) model with an additional
wavelet transform layer that extracts the specific frequency features in a
clean ECG. Testing confirms that the proposed method effectively predicts
accurate ECG behavior with reduced noise by accounting for all frequency
domains. In an experiment, noisy signals in the signal-to-noise ratio (SNR)
range of -10-10 are evaluated, demonstrating that the efficiency of the
proposed method is higher when the SNR is small.",http://arxiv.org/abs/2501.06724v1
"Diversified Augmentation with Domain Adaptation for Debiased Video
  Temporal Grounding",2025-01-12T08:04:52Z,"Junlong Ren, Gangjian Zhang, Haifeng Sun, Hao Wang","Temporal sentence grounding in videos (TSGV) faces challenges due to public
TSGV datasets containing significant temporal biases, which are attributed to
the uneven temporal distributions of target moments. Existing methods generate
augmented videos, where target moments are forced to have varying temporal
locations. However, since the video lengths of the given datasets have small
variations, only changing the temporal locations results in poor generalization
ability in videos with varying lengths. In this paper, we propose a novel
training framework complemented by diversified data augmentation and a domain
discriminator. The data augmentation generates videos with various lengths and
target moment locations to diversify temporal distributions. However, augmented
videos inevitably exhibit distinct feature distributions which may introduce
noise. To address this, we design a domain adaptation auxiliary task to
diminish feature discrepancies between original and augmented videos. We also
encourage the model to produce distinct predictions for videos with the same
text queries but different moment locations to promote debiased training.
Experiments on Charades-CD and ActivityNet-CD datasets demonstrate the
effectiveness and generalization abilities of our method in multiple grounding
structures, achieving state-of-the-art results.",http://arxiv.org/abs/2501.06746v2
"Exploring dynamical quantum phase transition from pure states to mixed
  states through generalized Su-Schrieffer-Heeger models",2025-01-12T12:28:34Z,"Kaiyuan Cao, Jian Wang","We investigate dynamic quantum phase transitions (DQPTs) in both pure and
mixed states within the framework of the generalized SSH model, specifically
analyzing the SSH-3 and SSH-4 models, which exhibit different symmetries. We
find that the SSH-3 model, characterized by a chiral-like point symmetry rather
than true chiral symmetry, supports robust localized edge states associated
with its topological properties. Our results show that DQPTs for pure states
occur following a quench that crosses the topological transition, even with an
open energy band gap. For mixed states, DQPT behavior is consistent at low
temperatures, but significant changes are observed at high temperatures,
resulting in the emergence of multiple critical times. In contrast, the SSH-4
model, which possesses chiral symmetry, allows for the analysis of two distinct
energy spectrum configurations. We conclude that the occurrence of DQPTs for
pure states in the SSH-4 model necessitates a quench from an initial state
without a band gap while crossing the critical point of the topological
transition, whereas DQPTs are absent for mixed states at elevated temperatures.",http://arxiv.org/abs/2501.06794v1
"Symmetry-breaking induced transition among net-zero-magnetization
  magnets",2025-01-12T14:46:49Z,"San-Dong Guo, Xiao-Shu Guo, Guangzhao Wang","Net-zero-magnetization magnets have garnered intensive research attention due
to their ultradense and ultrafast potential. In terms of the symmetric
classification of connecting magnetic atoms with opposite spin polarization,
the net-zero-magnetization magnets mainly include $PT$-antiferromagnet (the
joint symmetry ($PT$) of space inversion symmetry ($P$) and time-reversal
symmetry ($T$)), altermagnet and fully-compensated ferrimagnet. Studying
transitions among net-zero-magnetization magnets is essentially the research on
symmetry breaking, which can also clearly reveal the transformation of
spin-splitting symmetry. Symmetry breaking can be achieved through methods such
as Janus engineering, isovalent alloying, and external electric field. Here, we
start from a parent $PT$-antiferromagnet that simultaneously possesses both $P$
and rotational/mirror symmetries to induce altermagnet and fully-compensated
ferrimagnet. Based on first-principles calculations, the proposed transitions
can be verified in $PT$-antiferromagnet $\mathrm{CrC_2S_6}$ monolayer. By Janus
engineering and isovalent alloying, $\mathrm{CrC_2S_6}$ can change into
altermagnetic $\mathrm{CrC_2S_3Se_3}$ and fully-compensated ferrimagnetic
$\mathrm{CrMoC_2S_6}$. The $\mathrm{CrC_2S_3Se_3}$ can also become
fully-compensated ferrimagnetic $\mathrm{CrMoC_2S_3Se_3}$ by isovalent
alloying. Our work provides a clear and intuitive example to explain the
transitions among net-zero-magnetization magnets, which can inspire more
research on net-zero-magnetization magnets.",http://arxiv.org/abs/2501.06829v1
"Unveiling Temporal Trends in 19th Century Literature: An Information
  Retrieval Approach",2025-01-12T15:00:10Z,"Suchana Datta, Dwaipayan Roy, Derek Greene, Gerardine Meaney","In English literature, the 19th century witnessed a significant transition in
styles, themes, and genres. Consequently, the novels from this period display
remarkable diversity. This paper explores these variations by examining the
evolution of term usage in 19th century English novels through the lens of
information retrieval. By applying a query expansion-based approach to a
decade-segmented collection of fiction from the British Library, we examine how
related terms vary over time. Our analysis employs multiple standard metrics
including Kendall's tau, Jaccard similarity, and Jensen-Shannon divergence to
assess overlaps and shifts in expanded query term sets. Our results indicate a
significant degree of divergence in the related terms across decades as
selected by the query expansion technique, suggesting substantial linguistic
and conceptual changes throughout the 19th century novels.",http://arxiv.org/abs/2501.06833v1
Faithful Counterfactual Visual Explanations (FCVE),2025-01-12T15:18:31Z,"Bismillah Khan, Syed Ali Tariq, Tehseen Zia, Muhammad Ahsan, David Windridge","Deep learning models in computer vision have made remarkable progress, but
their lack of transparency and interpretability remains a challenge. The
development of explainable AI can enhance the understanding and performance of
these models. However, existing techniques often struggle to provide convincing
explanations that non-experts easily understand, and they cannot accurately
identify models' intrinsic decision-making processes. To address these
challenges, we propose to develop a counterfactual explanation (CE) model that
balances plausibility and faithfulness. This model generates easy-to-understand
visual explanations by making minimum changes necessary in images without
altering the pixel data. Instead, the proposed method identifies internal
concepts and filters learned by models and leverages them to produce plausible
counterfactual explanations. The provided explanations reflect the internal
decision-making process of the model, thus ensuring faithfulness to the model.",http://arxiv.org/abs/2501.06841v1
"Generative Artificial Intelligence-Supported Pentesting: A Comparison
  between Claude Opus, GPT-4, and Copilot",2025-01-12T22:48:37Z,"Antonio López Martínez, Alejandro Cano, Antonio Ruiz-Martínez","The advent of Generative Artificial Intelligence (GenAI) has brought a
significant change to our society. GenAI can be applied across numerous fields,
with particular relevance in cybersecurity. Among the various areas of
application, its use in penetration testing (pentesting) or ethical hacking
processes is of special interest. In this paper, we have analyzed the potential
of leading generic-purpose GenAI tools-Claude Opus, GPT-4 from ChatGPT, and
Copilot-in augmenting the penetration testing process as defined by the
Penetration Testing Execution Standard (PTES). Our analysis involved evaluating
each tool across all PTES phases within a controlled virtualized environment.
The findings reveal that, while these tools cannot fully automate the
pentesting process, they provide substantial support by enhancing efficiency
and effectiveness in specific tasks. Notably, all tools demonstrated utility;
however, Claude Opus consistently outperformed the others in our experimental
scenarios.",http://arxiv.org/abs/2501.06963v1
Logic Meets Magic: LLMs Cracking Smart Contract Vulnerabilities,2025-01-13T04:42:45Z,"ZeKe Xiao, Qin Wang, Hammond Pearce, Shiping Chen","Smart contract vulnerabilities caused significant economic losses in
blockchain applications. Large Language Models (LLMs) provide new possibilities
for addressing this time-consuming task. However, state-of-the-art LLM-based
detection solutions are often plagued by high false-positive rates.
  In this paper, we push the boundaries of existing research in two key ways.
First, our evaluation is based on Solidity v0.8, offering the most up-to-date
insights compared to prior studies that focus on older versions (v0.4). Second,
we leverage the latest five LLM models (across companies), ensuring
comprehensive coverage across the most advanced capabilities in the field.
  We conducted a series of rigorous evaluations. Our experiments demonstrate
that a well-designed prompt can reduce the false-positive rate by over 60%.
Surprisingly, we also discovered that the recall rate for detecting some
specific vulnerabilities in Solidity v0.8 has dropped to just 13% compared to
earlier versions (i.e., v0.4). Further analysis reveals the root cause of this
decline: the reliance of LLMs on identifying changes in newly introduced
libraries and frameworks during detection.",http://arxiv.org/abs/2501.07058v1
Nonequilibrium Continuous Transition in a Fast Rotating Turbulence,2025-01-13T06:26:27Z,"Chandra Shekhar Lohani, Suraj Kumar Nayak, Kannabiran Seshasayanan, Vishwanath Shukla","We study the saturation of three-dimensional unstable perturbations on a fast
rotating turbulent flow using direct numerical simulations (DNSs). Under the
effect of Kolmogorov forcing, a transition between states dominated by coherent
two-dimensional modes to states with three-dimensional variations
(quasi-two-dimensional) is observed as we change the global rotation rate. We
find this akin to a critical phenomenon, wherein the order parameter scales
with the distance to the critical point raised to an exponent. The exponent
itself deviates from the predicted mean field value. Also, the nature of the
fluctuations of the order parameter near the critical point indicate the
presence of on-off intermittency. The critical rotation rate at which the
transition occurs exhibits a linear scaling behaviour with the forcing wave
number. A reduced model based on linear stability analysis is used to find the
linear threshold estimates; we find these to be in good agreement with the 3D
nonlinear DNS results.",http://arxiv.org/abs/2501.07079v1
"Quality Control of Lifetime Drift in Discrete Electrical Parameters in
  Semiconductor Devices via Transition Modeling",2025-01-13T08:06:12Z,"Lukas Sommeregger, Jürgen Pilz","Semiconductors are widely used in various applications and critical
infrastructures. These devices have specified lifetimes and quality targets
that manufacturers must achieve. Lifetime estimation is conducted through
accelerated stress tests. Electrical parameters are measured at multiple times
during a stress test procedure. The change in these Electrical parameters is
called lifetime drift. Data from these tests can be used to develop a
statistical model predicting the lifetime behavior of the electrical parameters
in real devices. These models can provide early warnings in production
processes, identify critical parameter drift, and detect outliers. While models
for continuous electrical parameters exists, there may be bias when estimating
the lifetime of discrete parameters. To address this, we propose a
semi-parametric model for degradation trajectories based on longitudinal stress
test data. This model optimizes guard bands, or quality guaranteeing tighter
limits, for discrete electrical parameters at production testing. It is
scalable, data-driven, and explainable, offering improvements over existing
methods for continuous underlying data, such as faster calculations, arbitrary
non-parametric conditional distribution modeling, and a natural extension of
optimization algorithms to the discrete case using Markov transition matrices.",http://arxiv.org/abs/2501.07115v1
"TIMRL: A Novel Meta-Reinforcement Learning Framework for Non-Stationary
  and Multi-Task Environments",2025-01-13T09:11:33Z,"Chenyang Qi, Huiping Li, Panfeng Huang","In recent years, meta-reinforcement learning (meta-RL) algorithm has been
proposed to improve sample efficiency in the field of decision-making and
control, enabling agents to learn new knowledge from a small number of samples.
However, most research uses the Gaussian distribution to extract task
representation, which is poorly adapted to tasks that change in non-stationary
environment. To address this problem, we propose a novel meta-reinforcement
learning method by leveraging Gaussian mixture model and the transformer
network to construct task inference model. The Gaussian mixture model is
utilized to extend the task representation and conduct explicit encoding of
tasks. Specifically, the classification of tasks is encoded through transformer
network to determine the Gaussian component corresponding to the task. By
leveraging task labels, the transformer network is trained using supervised
learning. We validate our method on MuJoCo benchmarks with non-stationary and
multi-task environments. Experimental results demonstrate that the proposed
method dramatically improves sample efficiency and accurately recognizes the
classification of the tasks, while performing excellently in the environment.",http://arxiv.org/abs/2501.07146v1
Temperature Driven Multi-modal/Single-actuated Soft Finger,2025-01-13T11:14:05Z,"Prashant Kumar, Weiwei Wan, Kensuke Harada","Soft pneumatic fingers are of great research interest. However, their
significant potential is limited as most of them can generate only one motion,
mostly bending. The conventional design of soft fingers does not allow them to
switch to another motion mode. In this paper, we developed a novel multi-modal
and single-actuated soft finger where its motion mode is switched by changing
the finger's temperature. Our soft finger is capable of switching between three
distinctive motion modes: bending, twisting, and extension-in approximately
five seconds. We carried out a detailed experimental study of the soft finger
and evaluated its repeatability and range of motion. It exhibited repeatability
of around one millimeter and a fifty percent larger range of motion than a
standard bending actuator. We developed an analytical model for a
fiber-reinforced soft actuator for twisting motion. This helped us relate the
input pressure to the output twist radius of the twisting motion. This model
was validated by experimental verification. Further, a soft robotic gripper
with multiple grasp modes was developed using three actuators. This gripper can
adapt to and grasp objects of a large range of size, shape, and stiffness. We
showcased its grasping capabilities by successfully grasping a small berry, a
large roll, and a delicate tofu cube.",http://arxiv.org/abs/2501.07216v1
Markarian 590: The AGN Awakens,2025-01-13T11:24:52Z,"Biswaraj Palit, Marzena Śniegowska, Alex Markowitz, Agata Różańska, Benny Trakhtenbrot, Joseph Farah, Andy Howell","Changing-Look AGN (CLAGN) Mkn 590 recently underwent a sudden \lq
re-ignition\rq, marked by substantial increases in optical/UV and X-ray
continuum flux since last year. \textit{Swift}-XRT observations revealed the
re-emergence of a soft X-ray excess (SXE) as the source transitioned from a
low-flux state in July 2023 to a significantly higher flux state in October
2024. This evolution was in response to an order-of-magnitude increase in
extreme-UV (EUV) continuum emission, detected by \textit{Swift}-UVOT. Follow-up
optical spectra from the Las Cumbres Observatory confirmed the presence of
dynamically broadened Balmer lines, He II emission, and the emergence of the Fe
II complex. As the Eddington fraction increased by 10\% over the last 15
months, we found clear evidence of formation of a warm corona, strongly linked
to the cold accretion disc underneath. A global amplification of ionizing
radiation after approximately 11 years is consistent with propagating heating
fronts in inflated accretion discs. Based on our multi-wavelength study on
recent data, we propose that Mkn 590 is currently becoming a Seyfert-1, similar
to 1990s.",http://arxiv.org/abs/2501.07225v1
Sensing with near-infrared laser trapped fluorescent nanodiamonds,2025-01-13T12:24:05Z,"Arthur Dervillez, Fatemeh Kalantarifard, Luca Troise, Alexander Huck, Kirstine Berg-Sørensen","Biosensing based on optically trapped fluorescent nanodiamonds is an
intriguing research direction potentially allowing to resolve biochemical
processes inside living cells. Towards this goal, we investigate infrared near
(NIR) laser irradiation at 1064 nm on fluorescent nanodiamonds (FNDs)
containing nitrogen-vacancy (NV) centers. By conducting comprehensive
experiments, we aim to understand how NIR exposure influences the fluorescence
and sensing properties of FNDs and to determine the potential implications for
the use of FNDs in various sensing applications. The experimental setup
involved exposing FNDs to varying intensities of NIR laser light and analyzing
the resultant changes in their optical and physical properties. Key
measurements included T1 relaxation times, optical spectroscopy, and optically
detected magnetic resonance (ODMR) spectra. The findings reveal how increased
NIR laser power correlates with alterations in ODMR central frequency but also
that charge state dynamics under NIR irradiation of NV centers plays a role. We
suggest protocols with NIR and green light that mitigate the effect of NIR, and
demonstrate that FND biosensing works well with such a protocol.",http://arxiv.org/abs/2501.07263v1
"Anomalies of the Scholtes regularization for mathematical programs with
  complementarity constraints",2025-01-13T15:02:27Z,"Vladimir Shikhman, Sebastian Lämmel","For mathematical programs with complementarity constraints (MPCC), we refine
the convergence analysis of the Scholtes regularization. Our goal is to relate
nondegenerate C-stationary points of MPCC with nondegenerate Karush-Kuhn-Tucker
points of its Scholtes regularization. We detected the following anomalies: (i)
in a neighborhood of a nondegenerate C-stationary point there could be
degenerate Karush-Kuhn-Tucker points of the Scholtes regularization; (ii) even
if nondegenerate, they might be locally non-unique; (iii) if nevertheless
unique, their quadratic index potentially differs from the C-index of the
C-stationary point under consideration. Thus, a change of the topological type
for Karush-Kuhn-Tucker points of the Scholtes regularization is possible. In
particular, a nondegenerate minimizer of MPCC might be approximated by saddle
points. In order to bypass the mentioned anomalies, an additional generic
condition for nondegenerate C-stationary points of MPCC is identified. Then, we
uniquely trace nondegenerate Karush-Kuhn-Tucker points of the Scholtes
regularization and successively maintain their topological type.",http://arxiv.org/abs/2501.07383v1
"Ultrafast photodissociation dynamics of dichloromethane on
  three-dimensional potential energy surfaces and its Coulomb explosion
  signature",2025-01-13T16:52:36Z,Yijue Ding,"We present efficient and reliable molecular dynamics simulations of the
photodissociation of dichloromethane followed by Coulomb explosion. These
simulations are performed by calculating trajectories on accurate potential
energy surfaces of the low-lying excited states of the neutral dichloromethane
molecule. The subsequent time-resolved Coulomb explosions are simulated on the
triply charged ionic state, assuming Coulomb interactions between ionic
fragments. Both the neutral state trajectories and the simulated Coulomb
explosion observables indicate that intra-molecular photoisomerization of
dichloromethane is unlikely to occur. Estimating the kinetic energy release
using \textit{ab initio} ionic potential reveals a discrepancy of approximately
5-8 eV compared to our simulated values using Coulomb potential. The molecular
structural changes during photodissociation are clearly mapped to the
ionic-fragment coincidence signals, demonstrating the Coulomb explosion imaging
technique as a powerful tool to probe the time-resolved reaction dynamics.",http://arxiv.org/abs/2501.07479v1
"Computing Safety Margins of Parameterized Nonlinear Systems for
  Vulnerability Assessment via Trajectory Sensitivities",2025-01-13T17:16:34Z,Michael W. Fisher,"Physical systems experience nonlinear disturbances which have the potential
to disrupt desired behavior. For a particular disturbance, whether or not the
system recovers from the disturbance to a desired stable equilibrium point
depends on system parameter values, which are typically uncertain and
time-varying. Therefore, to quantify proximity to vulnerability we define the
safety margin to be the smallest change in parameter values from a nominal
value such that the system will no longer be able to recover from the
disturbance. Safety margins are valuable but challenging to compute as related
methods, such as those for robust region of attraction estimation, are often
either overly conservative or computationally intractable for high dimensional
systems. Recently, we developed algorithms to compute safety margins
efficiently and non-conservatively by exploiting the large sensitivity of the
system trajectory near the region of attraction boundary to small
perturbations. Although these algorithms have enjoyed empirical success, they
lack theoretical guarantees that would ensure their generalizability. This work
develops a novel characterization of safety margins in terms of trajectory
sensitivities, and uses this to derive well-posedness and convergence
guarantees for these algorithms, enabling their generalizability and successful
application to a large class of nonlinear systems.",http://arxiv.org/abs/2501.07498v1
"Floquet-engineered system-reservoir interaction in the transverse field
  Ising model",2025-01-13T17:58:34Z,"Maritza Ahumada, Natalia Valderrama-Quinteros, Guillermo Romero","Periodically driving a quantum many-body system can drastically change its
properties, leading to exotic non-equilibrium states of matter without a static
analog. In this scenario, parametric resonances and the complexity of an
interacting many-body system are pivotal in establishing non-equilibrium
states. We report on a Floquet-engineered transverse field Ising model for the
controlled propagation in one dimension of spin waves. The underlying
mechanisms behind our proposal rely on high-frequency drivings using
characteristic parametric resonances of the spin lattice. Many-body resonances
modulating spin-sping exchange or individual spin gaps inhibit interactions
between spins thus proving a mechanism for controlling spin-wave propagation
and a quantum switch. Our schemes may have applications in coupling-decoupling
schemes for system-reservoir interaction, and routing in quantum networks.",http://arxiv.org/abs/2501.07527v2
disco: Distributional Synthetic Controls,2025-01-13T18:36:38Z,"Florian Gunsilius, David Van Dijcke","The method of synthetic controls is widely used for evaluating causal effects
of policy changes in settings with observational data. Often, researchers aim
to estimate the causal impact of policy interventions on a treated unit at an
aggregate level while also possessing data at a finer granularity. In this
article, we introduce the new disco command, which implements the
Distributional Synthetic Controls method introduced in Gunsilius (2023). This
command allows researchers to construct entire synthetic distributions for the
treated unit based on an optimally weighted average of the distributions of the
control units. Several aggregation schemes are provided to facilitate clear
reporting of the distributional effects of the treatment. The package offers
both quantile-based and CDF-based approaches, comprehensive inference
procedures via bootstrap and permutation methods, and visualization
capabilities. We empirically illustrate the use of the package by replicating
the results in Van Dijcke et al. (2024).",http://arxiv.org/abs/2501.07550v2
Decoding Musical Evolution Through Network Science,2025-01-13T18:39:44Z,"Niccolo' Di Marco, Edoardo Loru, Alessandro Galeazzi, Matteo Cinelli, Walter Quattrociocchi","Music has always been central to human culture, reflecting and shaping
traditions, emotions, and societal changes. Technological advancements have
transformed how music is created and consumed, influencing tastes and the music
itself. In this study, we use Network Science to analyze musical complexity.
Drawing on $\approx20,000$ MIDI files across six macro-genres spanning nearly
four centuries, we represent each composition as a weighted directed network to
study its structural properties. Our results show that Classical and Jazz
compositions have higher complexity and melodic diversity than recently
developed genres. However, a temporal analysis reveals a trend toward
simplification, with even Classical and Jazz nearing the complexity levels of
modern genres. This study highlights how digital tools and streaming platforms
shape musical evolution, fostering new genres while driving homogenization and
simplicity.",http://arxiv.org/abs/2501.07557v1
Zero-temperature phase-flip rate in a biased parametric oscillator,2025-01-13T18:52:18Z,"Daniel K. J. Boneß, Wolfgang Belzig, Mark I. Dykman","A parametrically driven oscillator has two stable vibrational states at half
the modulation frequency. The states have opposite phase and equal amplitudes.
An extra drive at half the modulation frequency provides an effective bias that
lifts the state symmetry. Quantum fluctuations lead to switching between the
states, i.e., to phase-flip transitions. We develop a semiclassical approach
that allows us to find the dependence of the switching rates on the amplitude
of the bias and the parameters of the modulating field. We find that the rate
of switching from a ''shallow'' state can become anomalously small at certain
parameter values, leading to an efficient localization in this state. This is a
consequence of the change of the topology of the oscillator phase trajectories.
The results pave the way for implementing nonreciprocal quantum Ising systems
based on parametric oscillators.",http://arxiv.org/abs/2501.07562v2
"Ultra-Light Dark Matter Simulations and Stellar Dynamics: Tension in
  Dwarf Galaxies for $m < 5\times10^{-21} $ eV",2025-01-13T19:00:02Z,"Luca Teodori, Andrea Caputo, Kfir Blum","We present numerical simulations of dark matter and stellar dynamics in Ultra
Light Dark Matter halos tailored to mimic dwarf galaxies. For dark matter
particle mass $m\approx 1\times 10^{-22}$ eV, dynamical heating causes the
half-light radius to over-shoot surface brightness data of the Fornax galaxy.
For $m\approx 1\times 10^{-21}$ eV, soliton core formation leads to a velocity
dispersion peak incompatible with kinematics data. Extending the analysis to
the Carina and Leo II galaxies, the tension persists up to $m\approx 5\times
10^{-21}$ eV. A caveat in our analysis is the omission of stellar self-gravity.
This would not change dynamics today, but could affect extrapolation back in
time if the stellar body was more compact in the past.",http://arxiv.org/abs/2501.07631v1
A Low-Rank QTT-based Finite Element Method for Elasticity Problems,2025-01-14T01:26:56Z,"Elena Benvenuti, Gianmarco Manzini, Marco Nale, Simone Pizzolato","We present an efficient and robust numerical algorithm for solving the
two-dimensional linear elasticity problem that combines the Quantized Tensor
Train format and a domain partitioning strategy. This approach makes it
possible to solve the linear elasticity problem on a computational domain that
is more general than a square. Our method substantially decreases memory usage
and achieves a notable reduction in rank compared to established Finite Element
implementations like the FEniCS platform. This performance gain, however,
requires a fundamental rethinking of how core finite element operations are
implemented, which includes changes to mesh discretization, node and degree of
freedom ordering, stiffness matrix and internal nodal force assembly, and the
execution of algebraic matrix-vector operations. In this work, we discuss all
these aspects in detail and assess the method's performance in the numerical
approximation of three representative test cases.",http://arxiv.org/abs/2501.07778v1
Waiting Time Solutions in gas dynamics,2025-01-14T04:24:14Z,"Juhi Jang, Jiaqi Liu, Nader Masmoudi","In this article, we construct a continuum family of self-similar waiting time
solutions for the one-dimensional compressible Euler equations for the
adiabatic exponent $\ga\in(1,3)$ in the half-line with the vacuum boundary. The
solutions are confined by a stationary vacuum interface for a finite time with
at least $C^1$ regularity of the velocity and the sound speed up to the
boundary. Subsequently, the solutions undergo the change of the behavior,
becoming only H\""{o}lder continuous near the singular point, and simultaneously
transition to the solutions to the vacuum moving boundary Euler equations
satisfying the physical vacuum condition. When the boundary starts moving, a
weak discontinuity emanating from the singular point along the sonic curve
emerges. The solutions are locally smooth in the interior region away from the
vacuum boundary and the sonic curve.",http://arxiv.org/abs/2501.07831v1
Flow: A Modular Approach to Automated Agentic Workflow Generation,2025-01-14T04:35:37Z,"Boye Niu, Yiliao Song, Kai Lian, Yifan Shen, Yu Yao, Kun Zhang, Tongliang Liu","Multi-agent frameworks powered by large language models (LLMs) have
demonstrated great success in automated planning and task execution. However,
the effective adjustment of Agentic workflows during execution has not been
well-studied. A effective workflow adjustment is crucial, as in many real-world
scenarios, the initial plan must adjust to unforeseen challenges and changing
conditions in real-time to ensure the efficient execution of complex tasks. In
this paper, we define workflows as an activity-on-vertex (AOV) graphs. We
continuously refine the workflow by dynamically adjusting task allocations
based on historical performance and previous AOV with LLM agents. To further
enhance system performance, we emphasize modularity in workflow design based on
measuring parallelism and dependence complexity. Our proposed multi-agent
framework achieved efficient sub-task concurrent execution, goal achievement,
and error tolerance. Empirical results across different practical tasks
demonstrate dramatic improvements in the efficiency of multi-agent frameworks
through dynamic workflow updating and modularization.",http://arxiv.org/abs/2501.07834v1
"Mean-squared Energy Difference for Exploring Potential Energy Landscapes
  of Supercooled Liquids",2025-01-14T07:42:18Z,"Dianmo Zhang, Deyan Sun, Xingao Gong","By extending the concept of diffusion to the potential energy landscapes
(PELs), we introduce the mean-squared energy difference (MSED) as a novel
quantity to investigate the intrinsic properties of glass. MSED can provide a
clear description of the ""energy relaxation"" process on a PEL. Through MSED
analysis, we can obtain characteristic timescale similar to those from
structure analysis, namely $\tau_\alpha^*$. We establish a connection between
MSED and the properties of PELs, providing a concise and quantitative
description of the PEL. We find that the roughness of the accessible PEL has
changed significantly after the glass transition. And we also find that one of
the PEL parameters is closely related to the Adam-Gibbs configurational
entropy. The present research, which directly links the PEL to the relaxation
process, provides avenues for further research of the glass.",http://arxiv.org/abs/2501.07902v1
"Ultrasensitive Higher-Order Exceptional Points via Non-Hermitian
  Zero-Index Materials",2025-01-14T09:47:06Z,"Dongyang Yan, Alexander S. Shalin, Yongxing Wang, Yun Lai, Yadong Xu, Zhi Hong Hang, Fang Cao, Lei Gao, Jie Luo","Higher-order exceptional points (EPs) in optical structures enable
ultra-sensitive responses to perturbations. However, previous investigations on
higher-order EPs have predominantly focused on coupled systems, leaving their
fundamental physics in open scattering systems largely unexplored. Here, we
harness wave interference to realize higher-order EPs in non-Hermitian
zero-index materials connected to multiple open channels. Specifically, we
demonstrate that a three-channel model can give rise to three interesting types
of third-order EPs: lasing EP, reflecting EP, and absorbing EP. Notably, near
the third-order absorbing EP, we observe ultrasensitivity--a drastic change in
output power in response to perturbations at the operating frequency--in a
purely lossy system. These findings pave the way for achieving higher-order and
even arbitrary-order EPs in open scattering systems, offering significant
potential for advanced sensing applications.",http://arxiv.org/abs/2501.07974v1
"Quasiparticle Fermi surfaces of niobium and niobium-titanium alloys at
  high pressure",2025-01-14T11:03:08Z,"D. Jones, A. Östlin, A. Chmeruk, F. Beiuşeanu, U. Eckern, L. Vitos, L. Chioncel","The electronic structure of pure niobium and the niobium-titanium alloy
Nb$_{0.44}$Ti$_{0.56}$ in the bcc-phase at pressures up to $250$ GPa is
investigated, to reveal possible factors conducing toward the robust
superconductivity reported for Ti-doped niobium upon a considerable volume
reduction. We model the structural disorder using the coherent potential
approximation, and the electronic correlations are taken into account using
dynamical mean-field theory. At high pressure, a significant change in the
topology of the Fermi surface is observed, while electronic correlations weaken
with increasing pressure. Thus, the normal state of Nb$_{0.44}$Ti$_{0.56}$ is
found to be a Fermi liquid with a well-defined Fermi surface, and well-defined
quasiparticles near it. The systematic study of the impact of disorder upon the
Fermi surface at such ultra high pressures allows notable insights into the
nature of the electronic states near the Fermi level, i.e., within the energy
scale relevant for superconducting pairing. Furthermore, our results clearly
indicate the necessity of further experimental Fermi surface explorations.",http://arxiv.org/abs/2501.08012v1
"Rigidity, volume and angle structures of 1-3 type hyperbolic polyhedral
  3-manifolds",2025-01-14T12:49:30Z,"Feng Ke, Ge Huabin, Liu Chunlei","In this paper, we study the rigidity of hyperbolic polyhedral 3-manifolds and
the volume optimization program of angle structures. We first study the
rigidity of decorated 1-3 type hyperbolic polyhedral metrics on 3-manifolds
which are isometric gluing of decorated 1-3 type hyperbolic tetrahedra. Here a
1-3 type hyperbolic tetrahedron is a truncated hyperbolic tetrahedron with one
hyperideal vertex and three ideal vertices. A decorated 1-3 type polyhedron is
a 1-3 type hyperbolic polyhedron with a horosphere centered at each ideal
vertex. We show that a decorated 1-3 type hyperbolic polyhedral metric is
determined up to isometry and change of decorations by its curvature. We also
prove several results on the volume optimization program of Casson and Rivin,
i,e. Casson-Rivin's volume optimization program is shown to be still valid for
1-3 type ideal triangulated 3-manifolds. We also get a strongly 1-efficiency
triangulation when assuming the existence of an angle structure. On the whole,
we follow the spirit of Luo-Yang's work in 2018 to prove our main results. The
main differences come from that the hyperbolic tetrahedra considered here have
completely different geometry with those considered in Luo-Yang's work in 2018.",http://arxiv.org/abs/2501.08081v1
"A Time- and Space-Efficient Heuristic Approach for Late Train-Crew
  Rescheduling",2025-01-14T13:11:15Z,"Liyun Yu, Carl Henrik Häll, Anders Peterson, Christiane Schmidt","In this paper, we reschedule the duties of train drivers one day before the
operation. Due to absent drivers (e.g., because of sick leave), some trains
have no driver. Thus, duties need to be rescheduled for the day of operation.
We start with a feasible crew schedule for each of the remaining operating
drivers, a set of unassigned tasks originally assigned to the absent drivers,
and a group of standby drivers with fixed start time, end time, start depot,
and end depot. Our aim is to generate a crew schedule with as few canceled or
changed tasks as possible. We present a tabu-search-based approach for crew
rescheduling. We also adapt a column-generation approach with the same
objective function and equivalent restrictions as the benchmark for comparing
the results, computational time, and space usage. Our tabu-search-based
approach needs both less computation time and space than the column-generation
approach to compute an acceptable result. We further test the performance of
our approach under different settings. The data used in the experiments
originated from a regional passenger-train system around Stockholm, Sweden and
was provided by M\""alart\r{a}g.",http://arxiv.org/abs/2501.08098v1
Gapless higher-order topology and corner states in Floquet systems,2025-01-14T14:45:07Z,"Longwen Zhou, Rongtao Wang, Jiaxin Pan","Higher-order topological phases (HOTPs) possess localized and
symmetry-protected eigenmodes at corners and along hinges in two and three
dimensional lattices. The numbers of these topological boundary modes will
undergo quantized changes at the critical points between different HOTPs. In
this work, we reveal unique higher-order topology induced by time-periodic
driving at the critical points of topological phase transitions, which has no
equilibrium counterparts and also goes beyond the description of gapped
topological matter. Using an alternately coupled Creutz ladder and its
Floquet-driven descendants as illustrative examples, we analytically
characterize and numerically demonstrate the zero and $\pi$ corner modes that
could emerge at the critical points between different Floquet HOTPs. Moreover,
we propose a unified scheme of bulk-corner correspondence for both gapless and
gapped Floquet HOTPs protected by chiral symmetry in two dimensions. Our work
reveals the possibility of corner modes surviving topological transitions in
Floquet systems and initializes the study of higher-order Floquet topology at
quantum criticality.",http://arxiv.org/abs/2501.08164v2
Efficient Dataframe Systems: Lazy Fat Pandas on a Diet,2025-01-14T15:46:35Z,"Bhushan Pal Singh, Priyesh Kumar, Chiranmoy Bhattacharya, S. Sudarshan","Pandas is widely used for data science applications, but users often run into
problems when datasets are larger than memory. There are several frameworks
based on lazy evaluation that handle large datasets, but the programs have to
be rewritten to suit the framework, and the presence of multiple frameworks
complicates the life of a programmer. In this paper we present a framework that
allows programmers to code in plain Pandas; with just two lines of code changed
by the user, our system optimizes the program using a combination of
just-in-time static analysis, and runtime optimization based on a lazy
dataframe wrapper framework. Moreover, our system allows the programmer to
choose the backend. It works seamlessly with Pandas, Dask, and Modin, allowing
the choice of the best-suited backend for an application based on factors such
as data size. Performance results on a variety of programs show the benefits of
our framework.",http://arxiv.org/abs/2501.08207v1
"Quantum-Corrected Hawking Radiation from Near-Extremal Kerr-Newman Black
  Holes",2025-01-14T16:50:43Z,"Sabyasachi Maulik, Xin Meng, Leopoldo A. Pando Zayas","Near-extremal black holes have a long AdS$_2$ throat in their near-horizon
region. Quantum fluctuations in the throat region are effectively governed by a
quantum version of Jackiw-Teitelboim gravity with matter and are strongly
coupled at low temperatures. We investigate how these quantum fluctuations
affect the spectrum of emission of particles during Hawking radiation. We
systematically consider the cases of Kerr and Kerr-Newman black holes for
emission of scalar particles and discuss photon and graviton emission from the
Kerr background. We find that at very low temperatures the quantum fluctuations
radically change the nature of particle emission. Unlike the generic
suppression of particle emission in the spherically symmetric
Reissner-Nordstr\""om case, we uncover that for particles with non-vanishing
angular momentum, the quantum-corrected emission can be substantially enhanced
with respect to the standard semiclassical result.",http://arxiv.org/abs/2501.08252v1
FDPP: Fine-tune Diffusion Policy with Human Preference,2025-01-14T17:15:27Z,"Yuxin Chen, Devesh K. Jha, Masayoshi Tomizuka, Diego Romeres","Imitation learning from human demonstrations enables robots to perform
complex manipulation tasks and has recently witnessed huge success. However,
these techniques often struggle to adapt behavior to new preferences or changes
in the environment. To address these limitations, we propose Fine-tuning
Diffusion Policy with Human Preference (FDPP). FDPP learns a reward function
through preference-based learning. This reward is then used to fine-tune the
pre-trained policy with reinforcement learning (RL), resulting in alignment of
pre-trained policy with new human preferences while still solving the original
task. Our experiments across various robotic tasks and preferences demonstrate
that FDPP effectively customizes policy behavior without compromising
performance. Additionally, we show that incorporating Kullback-Leibler (KL)
regularization during fine-tuning prevents over-fitting and helps maintain the
competencies of the initial policy.",http://arxiv.org/abs/2501.08259v1
"Two- versus three-body approach to femtoscopic hadron-deuteron
  correlations",2025-01-14T17:58:23Z,Stanislaw Mrowczynski,"The three-body approach to hadron-deuteron correlations is shown to turn into
a two-body approach if the three-particle hadron-deuteron wave function
factorizes into the deuteron wave-function and the wave function of a hadron
motion relative to the deuteron. Then, the hadron-deuteron correlation function
is as in the two-body approach only the source radius somewhat changes. For
this reason, as we argue, the two-body approach works well for kaon-deuteron
correlations but it fails for proton-deuteron ones in case of small sources.
Applying the three-body approach generalized to the case where the radius of
the hadron source is different from the nucleon source radius, we derive the
source radius formula which used in the two-body approach gives the correlation
function as in the `factorized' three-body one. The formula is discussed in the
context of existing and future experimental data.",http://arxiv.org/abs/2501.08283v1
"A GPU-Accelerated Distributed Algorithm for Optimal Power Flow in
  Distribution Systems",2025-01-14T18:13:36Z,"Minseok Ryu, Geunyeong Byeon, Kibaek Kim","We propose a GPU-accelerated distributed optimization algorithm for
controlling multi-phase optimal power flow in active distribution systems with
dynamically changing topologies. To handle varying network configurations and
enable adaptable decomposition, we advocate a componentwise decomposition
strategy. However, this approach can lead to a prolonged computation time
mainly due to the excessive iterations required for achieving consensus among a
large number of fine-grained components. To overcome this, we introduce a
technique that segregates equality constraints from inequality constraints,
enabling GPU parallelism to reduce per-iteration time by orders of magnitude,
thereby significantly accelerating the overall computation. Numerical
experiments on IEEE test systems ranging from 13 to 8500 buses demonstrate the
superior scalability of the proposed approach compared to its CPU-based
counterparts.",http://arxiv.org/abs/2501.08293v1
"Continuation methods as a tool for parameter inference in
  electrophysiology modeling",2025-01-13T23:23:55Z,"Matt J Owen, Gary R Mirams","Parameterizing mathematical models of biological systems often requires
fitting to stable periodic data. In cardiac electrophysiology this typically
requires converging to a stable action potential through long simulations. We
explore this problem through the theory of dynamical systems, bifurcation
analysis and continuation methods; under which a converged action potential is
a stable limit cycle. Various attempts have been made to improve the efficiency
of identifying these limit cycles, with limited success. We demonstrate that
continuation methods can more efficiently infer the converged action potential
as proposed model parameter sets change during optimization or inference
routines. In an example electrophysiology model this reduces parameter
inference computation time by 70%. We also discuss theoretical considerations
and limitations of continuation method use in place of time-consuming model
simulations. The application of continuation methods allows more robust
optimization by making extra runs from multiple starting locations
computationally tractable, and facilitates the application of inference methods
such as Markov Chain Monte Carlo to gain more information on the plausible
parameter space.",http://arxiv.org/abs/2501.08355v1
"Weight Averaging for Out-of-Distribution Generalization and Few-Shot
  Domain Adaptation",2025-01-14T10:04:05Z,Shijian Xu,"Empirical risk minimization (ERM) is not robust to changes in the
distribution of data. When the distribution of test data is different from that
of training data, the problem is known as out-of-distribution generalization.
Recently, two techniques have been developed for addressing out-of-distribution
generalization in computer vision: weight averaging (WA) and sharpness-aware
minimization (SAM). WA involves training multiple models with different
hyperparameters and then averaging the weights of these models, which can
significantly improve out-of-distribution generalization performance. SAM
optimizes a neural network to find minima in flat regions, which have been
proven to perform well under distribution shifts. While these techniques have
made great progress, there is still room for improvement and further
exploration. In this thesis, we propose increasing the model diversity in WA
explicitly by introducing gradient similarity as a loss regularizer to further
improve out-of-distribution generalization performance. We also propose
combining WA and SAM to solve the problem of few-shot domain adaptation. Our
extensive experiments on digits datasets (MNIST, SVHN, USPS, MNIST-M) and other
domain adaptation datasets (VLCS, PACS) show that combining WA and SAM leads to
improved out-of-distribution generalization performance and significantly
increases few-shot domain adaptation accuracy.",http://arxiv.org/abs/2501.08361v1
"Polarimetric searches for axion dark matter and high-frequency
  gravitational waves using optical cavities",2025-01-14T19:00:04Z,"Camilo García-Cely, Luca Marsili, Andreas Ringwald, Aaron D. Spector","We revisit birefringence effects associated with the evolution of the
polarization of light as it propagates through axion dark matter or the
background of a passing gravitational wave (GW). We demonstrate that this can
be described by a unified formalism, highlighting a synergy between searches
for axions and high-frequency GWs. We show that by exploiting this framework,
the optical cavities used by the ALPS II experiment can potentially probe axion
masses in the range $m_a \sim 10^{-9} - 10^{-6} \, \mathrm{eV}$, offering
competitive sensitivity with existing laboratory and astrophysical searches.
Also building on this approach, we propose using these optical cavities to
search for high-frequency GWs by measuring changes in the polarization of their
laser. This makes it a promising method for exploring, in the near future, GWs
with frequencies above $100$ MHz and strain sensitivities on the order of
$10^{-14} \, \mathrm{Hz}^{-1/2}$. Such sensitivity allows the exploration of
currently unconstrained parameter space, complementing other high-frequency GW
experiments. This work contributes to the growing community investigating novel
approaches for high-frequency GW detection.",http://arxiv.org/abs/2501.08382v1
"Pressure-induced topological changes in Fermi surface of two-dimensional
  molecular conductor",2025-01-15T07:54:25Z,"T. Kobayashi, K. Yoshimi, H. Ma, S. Sekine, H. Taniguchi, N. Matsunaga, A. Kawamoto, Y. Uwatoko","We demonstrated X-ray structural analysis of the pressure-induced
superconductor, $\beta'$-ET$_2$ICl$_2$ under extremely high-pressure
conditions, where ET denotes bis(ethylenedithio)tetrathiafulvalene. This
material has been known as the highest transition temperature ($T_c$)
superconductor among organic superconductors ($T_c=14.2$ K at $8.2$ GPa). On
the basis of the experimental results, ab-initio models were derived using the
constrained random phase approximation. We revealed that the Lifshitz
transition exists behind the Mott insulator-metal transition and found that the
value of the on-site Coulomb interaction was halved to around $10$ GPa compared
to that at ambient pressure. This study clarifies the enigmatic origins of high
$T_{\rm c}$, and concurrently, provides a new understanding of the impacts of
structural alterations in organic materials under high pressure on their
electronic properties and the superconductivity process.",http://arxiv.org/abs/2501.08635v1
"A Spatio-Temporal Dirichlet Process Mixture Model on Linear Networks for
  Crime Data",2025-01-15T09:05:40Z,"Sujeong Lee, Won Chang, Jorge Mateu, Heejin Lee, Jaewoo Park","Analyzing crime events is crucial to understand crime dynamics and it is
largely helpful for constructing prevention policies. Point processes specified
on linear networks can provide a more accurate description of crime incidents
by considering the geometry of the city. We propose a spatio-temporal Dirichlet
process mixture model on a linear network to analyze crime events in Valencia,
Spain. We propose a Bayesian hierarchical model with a Dirichlet process prior
to automatically detect space-time clusters of the events and adopt a
convolution kernel estimator to account for the network structure in the city.
From the fitted model, we provide crime hotspot visualizations that can inform
social interventions to prevent crime incidents. Furthermore, we study the
relationships between the detected cluster centers and the city's amenities,
which provides an intuitive explanation of criminal contagion.",http://arxiv.org/abs/2501.08673v1
"The Physics of Life: Exploring Information as a Distinctive Feature of
  Living Systems",2025-01-15T09:24:06Z,"Stuart Bartlett, Andrew W. Eckford, Matthew Egbert, Manasvi Lingam, Artemy Kolchinsky, Adam Frank, Gourab Ghoshal","This paper explores the idea that information is an essential and distinctive
feature of living systems. Unlike non-living systems, living systems actively
acquire, process, and use information about their environments to respond to
changing conditions, sustain themselves, and achieve other intrinsic goals. We
discuss relevant theoretical frameworks such as ``semantic information'' and
``fitness value of information''. We also highlight the broader implications of
our perspective for fields such as origins-of-life research and astrobiology.
In particular, we touch on the transition to information-driven systems as a
key step in abiogenesis, informational constraints as determinants of planetary
habitability, and informational biosignatures for detecting life beyond Earth.
We briefly discuss experimental platforms which offer opportunities to
investigate these theoretical concepts in controlled environments. By
integrating theoretical and experimental approaches, this perspective advances
our understanding of life's informational dynamics and its universal principles
across diverse scientific domains.",http://arxiv.org/abs/2501.08683v1
Neuromorphic Retina: An FPGA-based Emulator,2025-01-15T16:45:45Z,"Prince Phillip, Pallab Kumar Nath, Kapil Jainwal, Andre van Schaik, Chetan Singh Thakur","Implementing accurate models of the retina is a challenging task,
particularly in the context of creating visual prosthetics and devices.
Notwithstanding the presence of diverse artificial renditions of the retina,
the imperative task persists to pursue a more realistic model. In this work, we
are emulating a neuromorphic retina model on an FPGA. The key feature of this
model is its powerful adaptation to luminance and contrast, which allows it to
accurately emulate the sensitivity of the biological retina to changes in light
levels. Phasic and tonic cells are realizable in the retina in the simplest way
possible. Our FPGA implementation of the proposed biologically inspired digital
retina, incorporating a receptive field with a center-surround structure, is
reconfigurable and can support 128*128 pixel images at a frame rate of 200fps.
It consumes 1720 slices, approximately 3.7k Look-Up Tables (LUTs), and
Flip-Flops (FFs) on the FPGA. This implementation provides a high-performance,
low-power, and small-area solution and could be a significant step forward in
the development of biologically plausible retinal prostheses with enhanced
information processing capabilities",http://arxiv.org/abs/2501.08943v1
"Intelligent Anti-Money Laundering Solution Based upon Novel Community
  Detection in Massive Transaction Networks on Spark",2025-01-08T02:57:08Z,"Xurui Li, Xiang Cao, Xuetao Qiu, Jintao Zhao, Jianbin Zheng","Criminals are using every means available to launder the profits from their
illegal activities into ostensibly legitimate assets. Meanwhile, most
commercial anti-money laundering systems are still rule-based, which cannot
adapt to the ever-changing tricks. Although some machine learning methods have
been proposed, they are mainly focused on the perspective of abnormal behavior
for single accounts. Considering money laundering activities are often involved
in gang criminals, these methods are still not intelligent enough to crack down
on criminal gangs all-sidedly. In this paper, a systematic solution is
presented to find suspicious money laundering gangs. A temporal-directed
Louvain algorithm has been proposed to detect communities according to relevant
anti-money laundering patterns. All processes are implemented and optimized on
Spark platform. This solution can greatly improve the efficiency of anti-money
laundering work for financial regulation agencies.",http://arxiv.org/abs/2501.09026v1
Higher Representations and Quark Confinement,2025-01-15T19:00:01Z,"Finn Gagliano, Andrea Grigoletto, Kantaro Ohmori","The concept of a (de)confined phase in QFT is well-defined in the presence of
$1$-form symmetries and their spontaneous symmetry breaking. However, in
scenarios where such symmetries are absent, confinement is not a well-defined
phase property. In this work, we propose that, when restricting to a specific
submanifold of the parameter space -- namely at zero temperature and fixed
quark mass -- the confined and adjoint Higgs phases of scalar QCD can be
distinguished through the different organization of their spectra, as seen from
the perspective of the baryon symmetry. The analysis is performed in terms of
an appropriate higher-categorical representation theory, recently developed for
generalized symmetries. Consistent with expectations, we find that the confined
phase permits only particles with integer baryon charges, while the Higgs phase
is characterized by the coexistence of bare quarks and center vortices,
exhibiting a non-trivial Aharonov-Bohm effect between these excitations.",http://arxiv.org/abs/2501.09069v2
"Observational evidence of anisotropic changes apparent resistivity
  before strong earthquakes",2025-01-15T20:27:27Z,"Jianguo Zhang, Wei Du, Mingxin Yue, Chenghui Liu, Xiaolong Liang, Jun Yang","Using a method based on normalized monthly variation rate, we studied
resistivity data of seven observation stations before the events in the
epicenter areas of two strong earthquakes. The relationship between variation
of anisotropic apparent resistivity and the azimuth of the maximum principal
stress is analyzed. The study shows that significant apparent resistivity
variation occurs in the direction that is perpendicular to the azimuth of the
maximum principal stress while only small fluctuation are recorded in the
direction of the maximum principal stress. We surmise that the variation of
anisotropic resistivity occurs in the late stage of the development of a strong
earthquake, which can be observed in the epicenter area. If the density of the
observation stations is increased and the direction of the observed resistivity
is right, the epicenter of an earthquake location may be estimated by the
observed resistivity anomaly.",http://arxiv.org/abs/2501.09131v1
Towards Understanding Extrapolation: a Causal Lens,2025-01-15T21:29:29Z,"Lingjing Kong, Guangyi Chen, Petar Stojanov, Haoxuan Li, Eric P. Xing, Kun Zhang","Canonical work handling distribution shifts typically necessitates an entire
target distribution that lands inside the training distribution. However,
practical scenarios often involve only a handful of target samples, potentially
lying outside the training support, which requires the capability of
extrapolation. In this work, we aim to provide a theoretical understanding of
when extrapolation is possible and offer principled methods to achieve it
without requiring an on-support target distribution. To this end, we formulate
the extrapolation problem with a latent-variable model that embodies the
minimal change principle in causal mechanisms. Under this formulation, we cast
the extrapolation problem into a latent-variable identification problem. We
provide realistic conditions on shift properties and the estimation objectives
that lead to identification even when only one off-support target sample is
available, tackling the most challenging scenarios. Our theory reveals the
intricate interplay between the underlying manifold's smoothness and the shift
properties. We showcase how our theoretical results inform the design of
practical adaptation algorithms. Through experiments on both synthetic and
real-world data, we validate our theoretical findings and their practical
implications.",http://arxiv.org/abs/2501.09163v1
"The Veln(ia)s is in the Details: Evaluating LLM Judgment on Latvian and
  Lithuanian Short Answer Matching",2025-01-15T21:30:03Z,"Yevhen Kostiuk, Oxana Vitman, Łukasz Gagała, Artur Kiulian","In this work, we address the challenge of evaluating large language models
(LLMs) on the short answer matching task for Latvian and Lithuanian languages.
We introduce novel datasets consisting of 502 Latvian and 690 Lithuanian
question-answer pairs. For each question-answer pair, we generated matched and
non-matched answers using a set of alteration rules specifically designed to
introduce small but meaningful changes in the text. These generated answers
serve as test cases to assess the ability of LLMs to detect subtle differences
in matching of the original answers. A subset of the datasets was manually
verified for quality and accuracy. Our results show that while larger LLMs,
such as QWEN2.5 72b and LLaMa3.1 70b, demonstrate near-perfect performance in
distinguishing matched and non-matched answers, smaller models show more
variance. For instance, LLaMa3.1 8b and EuroLLM 9b benefited from few-shot
examples, while Mistral Nemo 12b underperformed on detection of subtle text
alteration, particularly in Lithuanian, even with additional examples. QWEN2.5
7b and Mistral 7b were able to obtain a strong and comparable performance to
the larger 70b models in zero and few shot experiments. Moreover, the
performance of Mistral 7b was weaker in few shot experiments.",http://arxiv.org/abs/2501.09164v1
Provenance Guided Rollback Suggestions,2025-01-16T01:15:21Z,"David Zhao, Pavle Subotic, Mukund Raghothaman, Bernhard Scholz","Advances in incremental Datalog evaluation strategies have made Datalog
popular among use cases with constantly evolving inputs such as static analysis
in continuous integration and deployment pipelines. As a result, new logic
programming debugging techniques are needed to support these emerging use
cases.
  This paper introduces an incremental debugging technique for Datalog, which
determines the failing changes for a \emph{rollback} in an incremental setup.
Our debugging technique leverages a novel incremental provenance method. We
have implemented our technique using an incremental version of the Souffl\'{e}
Datalog engine and evaluated its effectiveness on the DaCapo Java program
benchmarks analyzed by the Doop static analysis library. Compared to
state-of-the-art techniques, we can localize faults and suggest rollbacks with
an overall speedup of over 26.9$\times$ while providing higher quality results.",http://arxiv.org/abs/2501.09225v1
Dispersive dark excitons in van der Waals ferromagnet CrI3,2025-01-16T02:10:39Z,"W. He, J. Sears, F. Barantani, T. Kim, J. W. Villanova, T. Berlijn, M. Lajer, M. A. McGuire, J. Pelliciari, V. Bisogni, S. Johnston, E. Baldini, M. Mitrano, M. P. M. Dean","Spin-flip dark excitons are optical-dipole-forbidden quasiparticles with
remarkable potential in optoelectronics, especially when they are realized
within cleavable van der Waals materials. Despite this potential, dark excitons
have not yet been definitively identified in ferromagnetic van der Waals
materials. Here, we report two dark excitons in a model ferromagnetic material
CrI3 using high-resolution resonant inelastic x-ray scattering (RIXS) and show
that they feature narrower linewidths compared to the bright excitons
previously reported in this material. These excitons are shown to have
spin-flip character, to disperse as a function of momentum, and to change
through the ferromagnetic transition temperature. Given the versatility of van
der Waals materials, these excitons hold promise for new types of
magneto-optical functionality.",http://arxiv.org/abs/2501.09244v1
Clone-Robust AI Alignment,2025-01-16T02:43:44Z,"Ariel D. Procaccia, Benjamin Schiffer, Shirley Zhang","A key challenge in training Large Language Models (LLMs) is properly aligning
them with human preferences. Reinforcement Learning with Human Feedback (RLHF)
uses pairwise comparisons from human annotators to train reward functions and
has emerged as a popular alignment method. However, input datasets in RLHF are
not necessarily balanced in the types of questions and answers that are
included. Therefore, we want RLHF algorithms to perform well even when the set
of alternatives is not uniformly distributed. Drawing on insights from social
choice theory, we introduce robustness to approximate clones, a desirable
property of RLHF algorithms which requires that adding near-duplicate
alternatives does not significantly change the learned reward function. We
first demonstrate that the standard RLHF algorithm based on regularized maximum
likelihood estimation (MLE) fails to satisfy this property. We then propose the
weighted MLE, a new RLHF algorithm that modifies the standard regularized MLE
by weighting alternatives based on their similarity to other alternatives. This
new algorithm guarantees robustness to approximate clones while preserving
desirable theoretical properties.",http://arxiv.org/abs/2501.09254v1
"RoboReflect: Robotic Reflective Reasoning for Grasping
  Ambiguous-Condition Objects",2025-01-16T05:40:37Z,"Zhen Luo, Yixuan Yang, Chang Cai, Yanfu Zhang, Feng Zheng","As robotic technology rapidly develops, robots are being employed in an
increasing number of fields. However, due to the complexity of deployment
environments or the prevalence of ambiguous-condition objects, the practical
application of robotics still faces many challenges, leading to frequent
errors. Traditional methods and some LLM-based approaches, although improved,
still require substantial human intervention and struggle with autonomous error
correction in complex scenarios.In this work, we propose RoboReflect, a novel
framework leveraging large vision-language models (LVLMs) to enable
self-reflection and autonomous error correction in robotic grasping tasks.
RoboReflect allows robots to automatically adjust their strategies based on
unsuccessful attempts until successful execution is achieved.The corrected
strategies are saved in a memory for future task reference.We evaluate
RoboReflect through extensive testing on eight common objects prone to
ambiguous conditions of three categories.Our results demonstrate that
RoboReflect not only outperforms existing grasp pose estimation methods like
AnyGrasp and high-level action planning techniques using GPT-4V but also
significantly enhances the robot's ability to adapt and correct errors
independently. These findings underscore the critical importance of autonomous
selfreflection in robotic systems while effectively addressing the challenges
posed by ambiguous environments.",http://arxiv.org/abs/2501.09307v1
Discovery of anomalous nuclear effect on electron transfer between atoms,2025-01-16T08:20:54Z,"Sota Kimura, Michiharu Wada, Hiromitsu Haba, Hironobu Ishiyama, Toshitaka Niwase, Marco Rosenbusch, Peter Schury","Among the known isotope effects in chemistry, electron spin conversion by
nuclear spin is a potent mechanism governing the reactions of radical pairs.
For the electron transfer between nonradical(s), this spin conversion does not
work, and other isotope effects have been presumed to have negligible
contributions. However, we have observed a nuclear-state-dependence anomaly in
ion charge state distributions in the thermalization of energetic atomic ions
in helium gas, the process between nonradical(s). It could be understood to
arise from the change in the stability of the intermediate quasi-molecule state
of the electron transfer caused by the difference in nuclear states. This
should prompt a reconsideration of the influence of atomic nuclei on
interatomic and intermolecular interactions.",http://arxiv.org/abs/2501.09364v1
Factorization of solutions of linear differential equations,2025-01-16T12:41:57Z,Janne Gröhn,"This paper supplements recents results on linear differential equations
$f''+Af=0$, where the coefficient $A$ is analytic in the unit disc of the
complex plane $\mathbb{C}$. It is shown that, if $A$ is analytic and
$|A(z)|^2(1-|z|^2)^3\, dm(z)$ is a Carleson measure, then all non-trivial
solutions of $f''+Af=0$ can be factorized as $f=Be^g$, where $B$ is a Blaschke
product whose zero-sequence $\Lambda$ is uniformly separated and where
$g\in{\rm BMOA}$ satisfies the interpolation property $$g'(z_n) = -\frac{1}{2}
\, \frac{B''(z_n)}{B'(z_n)}, \quad z_n\in\Lambda.$$ Among other things, this
factorization implies that all solutions of $f''+Af=0$ are functions in a Hardy
space and have no singular inner factors.
  Zero-free solutions play an important role as their maximal growth is similar
to the general case. The study of zero-free solutions produces a new result on
Riccati differential equations.",http://arxiv.org/abs/2501.09508v2
"Analyzing Continuous Semantic Shifts with Diachronic Word Similarity
  Matrices",2025-01-16T13:42:09Z,"Hajime Kiyama, Taichi Aida, Mamoru Komachi, Toshinobu Ogiso, Hiroya Takamura, Daichi Mochihashi","The meanings and relationships of words shift over time. This phenomenon is
referred to as semantic shift. Research focused on understanding how semantic
shifts occur over multiple time periods is essential for gaining a detailed
understanding of semantic shifts. However, detecting change points only between
adjacent time periods is insufficient for analyzing detailed semantic shifts,
and using BERT-based methods to examine word sense proportions incurs a high
computational cost. To address those issues, we propose a simple yet intuitive
framework for how semantic shifts occur over multiple time periods by
leveraging a similarity matrix between the embeddings of the same word through
time. We compute a diachronic word similarity matrix using fast and lightweight
word embeddings across arbitrary time periods, making it deeper to analyze
continuous semantic shifts. Additionally, by clustering the similarity matrices
for different words, we can categorize words that exhibit similar behavior of
semantic shift in an unsupervised manner.",http://arxiv.org/abs/2501.09538v2
Core Hours and Carbon Credits: Incentivizing Sustainability in HPC,2025-01-16T14:19:46Z,"Alok Kamatar, Maxime Gonthier, Valerie Hayot-Sasson, Andre Bauer, Marcin Copik, Torsten Hoefler, Raul Castro Fernandez, Kyle Chard, Ian Foster","Realizing a shared responsibility between providers and consumers is critical
to manage the sustainability of HPC. However, while cost may motivate
efficiency improvements by infrastructure operators, broader progress is
impeded by a lack of user incentives. We conduct a survey of HPC users that
reveals fewer than 30 percent are aware of their energy consumption, and that
energy efficiency is among users' lowest priority concerns. One explanation is
that existing pricing models may encourage users to prioritize performance over
energy efficiency. We propose two transparent multi-resource pricing schemes,
Energy- and Carbon-Based Accounting, that seek to change this paradigm by
incentivizing more efficient user behavior. These two schemes charge for
computations based on their energy consumption or carbon footprint,
respectively, rewarding users who leverage efficient hardware and software. We
evaluate these two pricing schemes via simulation, in a prototype, and a user
study.",http://arxiv.org/abs/2501.09557v1
"Almost sharp variational estimates for discrete truncated operators of
  Carleson type",2025-01-16T14:40:01Z,"Jiecheng Chen, Renhui Wan","We establish $r$-variational estimates for discrete truncated Carleson-type
operators on $\ell^p$ for $1<p<\infty$. Notably, these estimates are sharp and
enhance the results obtained by Krause and Roos (J. Eur. Math. Soc. 2022, J.
Funct. Anal. 2023), up to a logarithmic loss related to the scale. On the other
hand, as $r$ approaches infinity, the consequences align with the estimates
proved by Krause and Roos. Moreover, for the case of quadratic phases, we
remove this logarithmic loss with respect to the scale, at the cost of
increasing $p$ slightly.",http://arxiv.org/abs/2501.09564v2
"Reducing the Sensitivity of Neural Physics Simulators to Mesh Topology
  via Pretraining",2025-01-16T15:21:18Z,"Nathan Vaska, Justin Goodwin, Robin Walters, Rajmonda S. Caceres","Meshes are used to represent complex objects in high fidelity physics
simulators across a variety of domains, such as radar sensing and aerodynamics.
There is growing interest in using neural networks to accelerate physics
simulations, and also a growing body of work on applying neural networks
directly to irregular mesh data. Since multiple mesh topologies can represent
the same object, mesh augmentation is typically required to handle topological
variation when training neural networks. Due to the sensitivity of physics
simulators to small changes in mesh shape, it is challenging to use these
augmentations when training neural network-based physics simulators. In this
work, we show that variations in mesh topology can significantly reduce the
performance of neural network simulators. We evaluate whether pretraining can
be used to address this issue, and find that employing an established
autoencoder pretraining technique with graph embedding models reduces the
sensitivity of neural network simulators to variations in mesh topology.
Finally, we highlight future research directions that may further reduce neural
simulator sensitivity to mesh topology.",http://arxiv.org/abs/2501.09597v1
"Supersolid dipolar phases in planar geometry: effects of tilted
  polarization",2025-01-16T16:30:11Z,"Daniel Lima, Matheus Grossklags, Vinicius Zampronio, Fabio Cinti, Alejandro Mendoza-Coto","The behavior of dipolar Bose-Einstein condensates in planar geometries is
investigated, focusing on the effects of the polarization orientation. While
perpendicular polarization produces a phase diagram with hexagonal, stripes,
and honeycomb phases ending at a single critical point, the presence of an
in-plane polarization component transforms the critical point into three
critical lines, separating two phases at a time and changing radically the
appearance of the phase diagram. All transition lines contain first- and
second-order regions, while the phase diagram itself shows a resemblance with
those displayed by quasi-one-dimensional dipolar systems. Finally, we
investigate the effect of introducing an in-plane polarization on the
structural properties of the phases and determine the superfluid fraction. Our
results show that this process induces an axial deformation on the hexagonal
and honeycomb phases, resulting in an anisotropic behavior in the long distance
properties of the system like superfluidity. We expect that the rich
phenomenology observed provides motivation for new experiments and theoretical
works.",http://arxiv.org/abs/2501.09641v1
Aging of colloidal gels in microgravity,2025-01-16T16:46:22Z,"Swagata S. Datta, Waad Paliwal, Eric R. Weeks","We study the aging of colloidal gels using light microscopy movies of
depletion gels from the International Space Station. Under such microgravity
conditions, we observe a slowdown in particle dynamics consistent with gel
aging. Stronger attractive forces promote the formation of thicker gel strands
over time. The samples are bidisperse, composed of particles with a size ratio
1.2. Larger particles experience stronger depletion forces, which lead to a
large first-neighbor peak in the pair correlation function $g(r)$ due to the
prevalence of large-large particle contacts. As the gel ages, small mobile
particles are incorporated into the gel structure. The changes in gel structure
correlate with a slow power-law decay in particle motion, observed over nearly
two orders of magnitude of time scales in microgravity experiments.
Additionally, through complementary ground-based experiments, we compare
two-dimensional (2D) and three-dimensional (3D) images of depletion colloidal
gels. While microgravity gel data are limited to 2D projections, ground-based
data establish a correspondence between the 2D and 3D $g(r)$ peak heights. Our
results provide new insights into how colloidal gels age in the absence of
gravitational collapse.",http://arxiv.org/abs/2501.09650v1
Active particle in a very thin interfacial droplet,2025-01-16T16:47:24Z,"Airi N. Kato, Kaili Xie, Benjamin Gorin, Jean-Michel Rampnoux, Hamid Kellay","A single light-driven Janus particle confined in a very thin oil droplet at
an air--water interface displays intriguing dynamics. While laser activation
induces rapid horizontal motion (1mm/s--1cm/s) by thermal Marangoni flow, the
particle exhibits unexpected periodic circular motions or intermittent
irregular motions. We show that the periodic trajectories are the result of a
coupling between the self-propulsion of the particle and the spatiotemporal
droplet thickness changes. We propose a simple model where the properties of
the active particle trajectories are governed by capillary forces and torques
due to the confinement of the particle in the thin droplet.",http://arxiv.org/abs/2501.09652v1
Stacking disorder in novel ABAC-stacked brochantite,2025-01-16T16:51:34Z,"Aswathi Mannathanath Chakkingal, Chloe Fuller, Maxim Avdeev, Roman Gumeniuk, Marein C. Rahn, Falk Pabst, Yiran Wang, Sergey Granovsky, Artem Korshunov, Dmitry Chernyshov, Dmytro S. Inosov, Darren C. Peets","In geometrically frustrated magnetic systems, weak interactions or slight
changes to the structure can tip the delicate balance of exchange interactions,
sending the system into a different ground state. Brochantite,
Cu$_4$SO$_4$(OH)$_6$, has a copper sublattice composed of distorted triangles,
making it a likely host for frustrated magnetism, but exhibits stacking
disorder. The lack of synthetic single crystals has limited research on the
magnetism in brochantite to powders and natural mineral crystals. We grew
crystals which we find to be a new polytype with a tendency toward ABAC
stacking and some anion disorder, alongside the expected stacking disorder.
Comparison to previous results on natural mineral specimens suggests that
cation disorder is more deleterious to the magnetism than anion and stacking
disorder. Our specific heat data suggest a double transition on cooling into
the magnetically ordered state.",http://arxiv.org/abs/2501.09654v1
"A Survey of Research in Large Language Models for Electronic Design
  Automation",2025-01-16T16:51:59Z,"Jingyu Pan, Guanglei Zhou, Chen-Chia Chang, Isaac Jacobson, Jiang Hu, Yiran Chen","Within the rapidly evolving domain of Electronic Design Automation (EDA),
Large Language Models (LLMs) have emerged as transformative technologies,
offering unprecedented capabilities for optimizing and automating various
aspects of electronic design. This survey provides a comprehensive exploration
of LLM applications in EDA, focusing on advancements in model architectures,
the implications of varying model sizes, and innovative customization
techniques that enable tailored analytical insights. By examining the
intersection of LLM capabilities and EDA requirements, the paper highlights the
significant impact these models have on extracting nuanced understandings from
complex datasets. Furthermore, it addresses the challenges and opportunities in
integrating LLMs into EDA workflows, paving the way for future research and
application in this dynamic field. Through this detailed analysis, the survey
aims to offer valuable insights to professionals in the EDA industry, AI
researchers, and anyone interested in the convergence of advanced AI
technologies and electronic design.",http://arxiv.org/abs/2501.09655v1
"SynthLight: Portrait Relighting with Diffusion Model by Learning to
  Re-render Synthetic Faces",2025-01-16T18:59:48Z,"Sumit Chaturvedi, Mengwei Ren, Yannick Hold-Geoffroy, Jingyuan Liu, Julie Dorsey, Zhixin Shu","We introduce SynthLight, a diffusion model for portrait relighting. Our
approach frames image relighting as a re-rendering problem, where pixels are
transformed in response to changes in environmental lighting conditions. Using
a physically-based rendering engine, we synthesize a dataset to simulate this
lighting-conditioned transformation with 3D head assets under varying lighting.
We propose two training and inference strategies to bridge the gap between the
synthetic and real image domains: (1) multi-task training that takes advantage
of real human portraits without lighting labels; (2) an inference time
diffusion sampling procedure based on classifier-free guidance that leverages
the input portrait to better preserve details. Our method generalizes to
diverse real photographs and produces realistic illumination effects, including
specular highlights and cast shadows, while preserving the subject's identity.
Our quantitative experiments on Light Stage data demonstrate results comparable
to state-of-the-art relighting methods. Our qualitative results on in-the-wild
images showcase rich and unprecedented illumination effects. Project Page:
\url{https://vrroom.github.io/synthlight/}",http://arxiv.org/abs/2501.09756v1
Testing Refactoring Engine via Historical Bug Report driven LLM,2025-01-16T23:31:49Z,"Haibo Wang, Zhuolin Xu, Shin Hwei Tan","Refactoring is the process of restructuring existing code without changing
its external behavior while improving its internal structure. Refactoring
engines are integral components of modern Integrated Development Environments
(IDEs) and can automate or semi-automate this process to enhance code
readability, reduce complexity, and improve the maintainability of software
products. Similar to traditional software systems such as compilers,
refactoring engines may also contain bugs that can lead to unexpected
behaviors. In this paper, we propose a novel approach called RETESTER, a
LLM-based framework for automated refactoring engine testing. Specifically, by
using input program structure templates extracted from historical bug reports
and input program characteristics that are error-prone, we design
chain-of-thought (CoT) prompts to perform refactoring-preserving
transformations. The generated variants are then tested on the latest version
of refactoring engines using differential testing. We evaluate RETESTER on two
most popular modern refactoring engines (i.e., ECLIPSE, and INTELLIJ IDEA). It
successfully revealed 18 new bugs in the latest version of those refactoring
engines. By the time we submit our paper, seven of them were confirmed by their
developers, and three were fixed.",http://arxiv.org/abs/2501.09879v2
"The Evolution of Unobserved Skill Returns in the U.S.: A New Approach
  Using Panel Data",2025-01-17T02:17:17Z,"Lance Lochner, Youngmin Park, Youngki Shin","Economists disagree about the factors driving the substantial increase in
residual wage inequality in the US over the past few decades. To identify
changes in the returns to unobserved skills, we make a novel assumption about
the dynamics of skills rather than about the stability of skill distributions
across cohorts, as is standard. We show that our assumption is supported by
data on test score dynamics for older workers in the HRS. Using survey data
from the PSID and administrative data from the IRS and SSA, we estimate that
the returns to unobserved skills $declined$ substantially in the late-1980s and
1990s despite an increase in residual inequality. Accounting for firm-specific
pay differences yields similar results. Extending our framework to consider
occupational differences in returns to skill and multiple unobserved skills, we
further show that skill returns display similar patterns for workers employed
in each of cognitive, routine, and social occupations. Finally, our results
suggest that increasing skill dispersion, driven by rising skill volatility,
explains most of the growth in residual wage inequality since the 1980s.",http://arxiv.org/abs/2501.09917v1
"Adaptive Twisting Sliding Control for Integrated Attack UAV's Autopilot
  and Guidance",2025-01-17T03:20:39Z,"Minh Tu Nguyen, Van Truong Hoang, Manh Duong Phung, Van Hoa Doan","This paper investigates an adaptive sliding-mode control for an integrated
UAV autopilot and guidance system. First, a two-dimensional mathematical model
of the system is derived by considering the incorporated lateral dynamics and
relative kinematics of the UAV and its potential target of attack. Then, a
sliding surface is derived utilizing the zero-effort miss distance. An adaptive
twisting sliding mode (ATSMC) algorithm is applied to the integrated system.
Simulation and comparisons have been accomplished. The results show our
proposed design performs well in interception precision, even with high
nonlinearity, uncertainties, disturbances, and abrupt changes in the target's
movement, thanks to the adaptation strategy.",http://arxiv.org/abs/2501.09937v1
"Emergent scales and spatial correlations at the yielding transition of
  glassy materials",2025-01-17T08:55:11Z,"Stefano Aime, Domenico Truzzolillo","Glassy materials yield under large external mechanical solicitations. Under
oscillatory shear, yielding shows a well-known rheological fingerprint, common
to samples with widely different microstructures. At the microscale, this
corresponds to a transition between slow, solid-like dynamics and faster
liquid-like dynamics, which can coexist at yielding in a finite range of strain
amplitudes. Here, we capture this phenomenology in a lattice model with two
main parameters: glassiness and disorder, describing the average coupling
between adjacent lattice sites, and their variance, respectively. In absence of
disorder, our model yields a law of correspondent states equivalent to
trajectories on a cusp catastrophe manifold, a well-known class of problems
including equilibrium liquid-vapour phase transitions. Introducing a finite
disorder in our model entails a qualitative change, to a continuous and rounded
transition, whose extent is controlled by the magnitude of the disorder. We
show that a spatial correlation length $\xi$ emerges spontaneously from the
coupling between disorder and bifurcating dynamics. With vanishing disorder,
$\xi$ diverges and yielding becomes discontinuous, suggesting that the
abruptness of yielding can be rationalized in terms of a lengthscale of dynamic
heterogeneities.",http://arxiv.org/abs/2501.10039v1
"Temporal and topological partitioning in real-world growing networks for
  scale-free properties study",2025-01-17T12:12:47Z,Guillaume Rousseau,"We introduce a method to study evolution rules and scale-free hypothesis of
real-world growing networks using natural partitions of nodes and edges based
on temporal and topological attributes, and analyzing degree distributions.
  We apply this method to the Software Heritage dataset, which collects
software releases and revisions from open-source communities. Nodes with native
temporal information does not fully capture the overall network dynamics, and
degree distributions show greater regularity with fewer outliers, suggesting a
more likely scale-free regime when examining networks derived from temporal and
topological partitions.
  However, underlying aging, fitness, and inheritance mechanisms, along with
chosen partitioning, hinder definitive conclusions and suggest that the very
common ``pure parametric power-law'' hypothesis for the tail of degree
distributions is too strong. Node's type derived from partions and changes in
evolution rules, shown by variations in the average number of new edges per
node over time, highlight the need for tools better suited for studying
transient regimes and ease comparison of real-world networks with minimal
models.",http://arxiv.org/abs/2501.10145v1
A scalable event-driven spatiotemporal feature extraction circuit,2025-01-17T12:39:09Z,"Hugh Greatorex, Michele Mastella, Ole Richter, Madison Cotteret, Willian Soares Girão, Ella Janotte, Elisabetta Chicca","Event-driven sensors, which produce data only when there is a change in the
input signal, are increasingly used in applications that require low-latency
and low-power real-time sensing, such as robotics and edge devices. To fully
achieve the latency and power advantages on offer however, similarly
event-driven data processing methods are required. A promising solution is the
TDE: an event-based processing element which encodes the time difference
between events on different channels into an output event stream. In this work
we introduce a novel TDE implementation on CMOS. The circuit is robust to
device mismatch and allows the linear integration of input events. This is
crucial for enabling a high-density implementation of many TDEs on the same
die, and for realising real-time parallel processing of the high-event-rate
data produced by event-driven sensors.",http://arxiv.org/abs/2501.10155v2
Streaming Graph Algorithms in the Massively Parallel Computation Model,2025-01-17T14:51:39Z,"Artur Czumaj, Gopinath Mishra, Anish Mukherjee","We initiate the study of graph algorithms in the streaming setting on massive
distributed and parallel systems inspired by practical data processing systems.
The objective is to design algorithms that can efficiently process evolving
graphs via large batches of edge insertions and deletions using as little
memory as possible.
  We focus on the nowadays canonical model for the study of theoretical
algorithms for massive networks, the Massively Parallel Computation (MPC)
model. We design MPC algorithms that efficiently process evolving graphs: in a
constant number of rounds they can handle large batches of edge updates for
problems such as connectivity, minimum spanning forest, and approximate
matching while adhering to the most restrictive memory regime, in which the
local memory per machine is strongly sublinear in the number of vertices and
the total memory is sublinear in the graph size. These results improve upon
earlier works in this area which rely on using larger total space, proportional
to the size of the processed graph. Our work demonstrates that parallel
algorithms can process dynamically changing graphs with asymptotically optimal
utilization of MPC resources: parallel time, local memory, and total memory,
while processing large batches of edge updates.",http://arxiv.org/abs/2501.10230v1
"Hybrid Deep Learning Model for epileptic seizure classification by using
  1D-CNN with multi-head attention mechanism",2025-01-17T18:33:58Z,"Mohammed Guhdar, Ramadhan J. Mstafa, Abdulhakeem O. Mohammed","Epilepsy is a prevalent neurological disorder globally, impacting around 50
million people \cite{WHO_epilepsy_50million}. Epileptic seizures result from
sudden abnormal electrical activity in the brain, which can be read as sudden
and significant changes in the EEG signal of the brain. The signal can vary in
severity and frequency, which results in loss of consciousness and muscle
contractions for a short period of time \cite{epilepsyfoundation_myoclonic}.
Individuals with epilepsy often face significant employment challenges due to
safety concerns in certain work environments. Many jobs that involve working at
heights, operating heavy machinery, or in other potentially hazardous settings
may be restricted for people with seizure disorders. This certainly limits job
options and economic opportunities for those living with epilepsy.",http://arxiv.org/abs/2501.10342v1
"Realization of tilted Dirac-like microwave cone in superconducting
  circuit lattices",2025-01-12T18:45:10Z,"Amir Youssefi, Ahmad Motavassal, Shingo Kono, Seyed Akbar Jafari, Tobias J. Kippenberg","Dirac-like band crossings are paradigms in condensed matter systems to
emulate high-energy physics phenomena. They are associated with two aspects:
gap and tilting. The ability to design sign-changing gap gives rise to band
topology, whereas the tilting of band crossings which is a gateway for large
gravity-like effects remains uncharted. In this work, we introduce an
experimental platform to realize tilted Dirac-like microwave cone in
large-scale superconducting circuit lattices. The direction and magnitude of
the tilt can be controlled by engineering the axially preferred second neighbor
coupling. We demonstrate three lattices with 731-site LC resonator featuring
tilt values of up to 59% of relative difference in the opposite-direction group
velocities. This is obtained by reconstructing the density of states (DOS) of
measured microwave resonance frequencies. Harnessing the tilt of Dirac-like
band crossings lays the foundation for weaving the fabric of an emergent
solid-state spacetime.",http://arxiv.org/abs/2501.10434v1
"A flatness-based predictive controller for six-degrees of freedom
  spacecraft rendezvous",2025-01-13T14:12:41Z,"Julio C. Sanchez, Francisco Gavilan, Rafael Vazquez, Christophe Louembet","This work presents a closed-loop guidance algorithm for six-degrees of
freedom spacecraft rendezvous with a passive target flying in an eccentric
orbit. The main assumption is that the chaser vehicle has an attitude control
system, based on reaction wheels, providing the necessary torque to change its
orientation whereas the number of thrusters is arbitrary. The goal is to design
fuel optimal maneuvers while satisfying operational constraints and rejecting
disturbances. The proposed method is as follows; first, the coupled
translational and angular dynamics are transformed to equivalent algebraic
relations using the relative translational states transition matrix and the
attitude flatness property. Then, a direct transcription method, based on
B-splines parameterization and discretization of time continuous constraints,
is developed to obtain a tractable static program. Finally, a Model Predictive
Controller, based on linearization around the previously computed solution, is
considered to handle disturbances. Numerical results are shown and discussed.",http://arxiv.org/abs/2501.10436v1
"Quantitative noncontact measurement of thermal Hall angle and transverse
  thermal conductivity by lock-in thermography",2025-01-17T07:01:14Z,"Takumi Imamura, Takamasa Hirai, Koichi Oyanagi, Ryo Iguchi, Kenta Takamori, Satoru Kobayashi, Ken-ichi Uchida","We propose and demonstrate a quantitative noncontact measurement method for
the thermal Hall effect (THE) based on magnetic-field-modulated lock-in
thermography. This method enables visualization of THE-induced temperature
change and quantitative estimation of the thermal Hall angle $\theta_{\rm THE}$
by applying periodic magnetic fields to a sample and obtaining the first
harmonic response of thermal images. By combining this method with LIT-based
measurement techniques for the longitudinal thermal conductivity $\kappa_{xx}$,
we also quantify the transverse thermal conductivity $\kappa_{xy}$. We validate
our measurement methods by estimating $\theta_{\rm THE}$, $\kappa_{xx}$, and
$\kappa_{xy}$ in a ferromagnetic Heusler alloy Co$_2$MnGa slab showing large
THE.",http://arxiv.org/abs/2501.10485v2
"Excited s-wave $1^{--}$ vector mesons, their leptonic decays and
  (in-)complete absence of abnormal states as seen from the constituent quark
  BSE",2025-01-17T15:15:46Z,V. Sauli,"Within a lattice inspired interaction between quark and antiquark, we obtain
hierarchy of Bethe-Salpeter equation (BSE) solutions for vector quarkonia
excited states in the constituent quark mass approximation. As a toy model, we
apply the similar to calculate ground and excited states of $\phi$ and
$\omega/\rho$ meson. Performing detailed numerical search, our study provides
the evidence that the quark propagator with single valued constant mass does
not provide known meson spectra without the presence of abnormal (unphysical)
solutions simultaneously. We classify normal and abnormal solutions and discuss
necessary changes in calculation scheme preventing the spectrum from
inconsistent solutions. While all experimentaly narrow vector mesons are
identified with a normal state of the BSE, the intriguing appearance of mutualy
canceled normal-abnormal states is reported. They appearance discriminate
between heavy and the light mesons. In both cases they seems to be remainder of
inconsitent use of the hmogeneous BSE for the description of broad resonances.",http://arxiv.org/abs/2501.10498v1
"Modeling Changes in Individuals' Cognitive Self-Esteem With and Without
  Access To Search Tools",2025-01-17T19:28:10Z,"Mahir Akgun, Sacip Toker","Search engines, as cognitive partners, reshape how individuals evaluate their
cognitive abilities. This study examines how search tool access influences
cognitive self-esteem (CSE)-users' self-perception of cognitive abilities --
through the lens of transactive memory systems. Using a within-subject design
with 164 participants, we found that CSE significantly inflates when users have
access to search tools, driven by cognitive offloading. Participants with lower
initial CSE exhibited greater shifts, highlighting individual differences.
Search self-efficacy mediated the relationship between prior search experience
and CSE, emphasizing the role of users' past interactions. These findings
reveal opportunities for search engine design: interfaces that promote
awareness of cognitive offloading and foster self-reflection can support
accurate metacognitive evaluations, reducing overreliance on external tools.
This research contributes to HCI by demonstrating how interactive systems shape
cognitive self-perception, offering actionable insights for designing
human-centered tools that balance user confidence and cognitive independence.",http://arxiv.org/abs/2501.10517v1
"Perfect, Pretty Good and Optimized Quantum State Transfer in Transmon
  qubit chains",2025-01-17T22:16:41Z,"Pablo Serra, Alejandro Ferrón, Omar Osenda","Chains of transmon qubits are considered promising systems to implement
different quantum information tasks. In particular as channels that perform
high-quality quantum state transfer. We study how changing the interaction
strength between the chain qubits allows us to obtain perfect or pretty good
state transfer and present explicit analytic expressions for their transmission
fidelity. For particular values of the interactions between the qubits,
transmon chains are equivalent to generalized SSH chains and show the
traditional traits observed in chains with topological states, localized states
at the extremes of the chain, and eigenvalues that lie inside the spectral gap.
Consequently, we study the quantum state transfer on chains with dimerized
interactions, looking for chains with fast transfer times. We show that, in
many cases, asking for fast transfer times results in chains with dimerized
interactions that do not have topological states.",http://arxiv.org/abs/2501.10580v1
"ColorGrid: A Multi-Agent Non-Stationary Environment for Goal Inference
  and Assistance",2025-01-17T22:55:33Z,"Andrey Risukhin, Kavel Rao, Ben Caffee, Alan Fan","Autonomous agents' interactions with humans are increasingly focused on
adapting to their changing preferences in order to improve assistance in
real-world tasks. Effective agents must learn to accurately infer human goals,
which are often hidden, to collaborate well. However, existing Multi-Agent
Reinforcement Learning (MARL) environments lack the necessary attributes
required to rigorously evaluate these agents' learning capabilities. To this
end, we introduce ColorGrid, a novel MARL environment with customizable
non-stationarity, asymmetry, and reward structure. We investigate the
performance of Independent Proximal Policy Optimization (IPPO), a
state-of-the-art (SOTA) MARL algorithm, in ColorGrid and find through extensive
ablations that, particularly with simultaneous non-stationary and asymmetric
goals between a ``leader'' agent representing a human and a ``follower''
assistant agent, ColorGrid is unsolved by IPPO. To support benchmarking future
MARL algorithms, we release our environment code, model checkpoints, and
trajectory visualizations at https://github.com/andreyrisukhin/ColorGrid.",http://arxiv.org/abs/2501.10593v1
"Effect of Magnetic Field on Aqueous Humor Flows Inside Anterior Chamber
  of Human Eye",2025-01-18T10:24:51Z,"Deepak Kumar, Subramaniam Pushpavanam","Aqueous humor (AH) dynamics is responsible for maintaining intraocular
pressure, ocular health and targeted drug delivery within the eye. This study
investigates the flow of AH within the anterior chamber (AC) under the combined
influence of a uniform magnetic field and natural convection. Different
orientations of the magnetic field and temperaature gradient are considered. A
lubrication approximation is employed and the resulting equations are solved
using regular perturbation method. The analytical solutions are validated using
numerical simulations performed in COMSOL Multiphysics 6.2. In the standing
position, AH flow field is characterised by a single vortex, while in the
supine position, it forms two counter-rotating vortices. The velocity is found
to be higher in standing position. The effect of a uniform magnetic field on
the velocity is more significant in the supine position. The magnetic field
does not change the flow field qualitatively as buoyancy is the primary driving
force. In the standing position a magnetic field oriented perpendicular to the
eye resulted in a greatest reduction of AH velocity, as compared to a magnetic
field along the eye. This study is a step towards holistic approach for
targeted drug delivery using magnetic fields in eye.",http://arxiv.org/abs/2501.10717v1
"Some results of CCD-photometry of variable stars at the Astronomical
  Institute of Karazin Kharkiv National University",2025-01-18T12:52:01Z,"V. G. Shevchenko, D. O. Danylko, I. G. Slyusarev, R. A. Chigladze","We presented photometric observations for the one UV Ceti type and three W
Ursae Majoris-type variable stars. The flare of the UV Ceti type star lasted
about two hours, and the star changed magnitude to 3.9 within about two
minutes. The values of color indices V-R, the rotational periods and the
composite lightcurves have been obtained for the EW stars. Using a relation of
an absolute magnitude-period obtained by Mateo and Rucinski (2017) and
interstellar extinction from the three-dimensional map of Milky Way dust
(http://argonaut.skymaps.info) and Green et al. (2019), we have calculated the
absolute magnitudes of the EW stars and distances to them. The parallaxes
obtained from our data differ from those given in Gaia DR 3, which may be due
to insufficient quality calibration of the absolute magnitude-period relation
and with the estimations of interstellar extinction.",http://arxiv.org/abs/2501.10754v1
"Model Monitoring in the Absence of Labeled Data via Feature Attributions
  Distributions",2025-01-18T14:07:37Z,Carlos Mougan,"Model monitoring involves analyzing AI algorithms once they have been
deployed and detecting changes in their behaviour. This thesis explores machine
learning model monitoring ML before the predictions impact real-world decisions
or users. This step is characterized by one particular condition: the absence
of labelled data at test time, which makes it challenging, even often
impossible, to calculate performance metrics.
  The thesis is structured around two main themes: (i) AI alignment, measuring
if AI models behave in a manner consistent with human values and (ii)
performance monitoring, measuring if the models achieve specific accuracy goals
or desires.
  The thesis uses a common methodology that unifies all its sections. It
explores feature attribution distributions for both monitoring dimensions.
Using these feature attribution explanations, we can exploit their theoretical
properties to derive and establish certain guarantees and insights into model
monitoring.",http://arxiv.org/abs/2501.10774v2
"The working principles of model-based GAs fall within the PAC framework:
  A mathematical theory of problem decomposition",2025-01-18T14:18:15Z,"Tian-Li Yu, Chi-Hsien Chang, Ying-ping Chen","The concepts of linkage, building blocks, and problem decomposition have long
existed in the genetic algorithm (GA) field and have guided the development of
model-based GAs for decades. However, their definitions are usually vague,
making it difficult to develop theoretical support. This paper provides an
algorithm-independent definition to describe the concept of linkage. With this
definition, the paper proves that any problems with a bounded degree of linkage
are decomposable and that proper problem decomposition is possible via linkage
learning. The way of decomposition given in this paper also offers a new
perspective on nearly decomposable problems with bounded difficulty and
building blocks from the theoretical aspect. Finally, this paper relates
problem decomposition to PAC learning and proves that the global optima of
these problems and the minimum decomposition blocks are PAC learnable under
certain conditions.",http://arxiv.org/abs/2501.10777v1
Automated Selfish Mining Analysis for DAG-based PoW Consensus Protocols,2025-01-18T21:57:02Z,Patrik Keller,"Selfish mining is strategic rule-breaking to maximize rewards in
proof-of-work protocols. Markov Decision Processes (MDPs) are the preferred
tool for finding optimal strategies in Bitcoin and similar linear chain
protocols. Protocols increasingly adopt DAG-based chain structures, for which
MDP analysis is more involved. To date, researchers have tailored specific MDPs
for each protocol. Protocol design suffers long feedback loops, as each
protocol change implies manual work on the MDP. To overcome this, we propose a
generic attack model that covers a wide range of protocols, including Ethereum
Proof-of-Work, GhostDAG, and Parallel Proof-of-Work. Our approach is modular:
we specify each protocol as a concise program, and our tooling then derives and
solves the selfish mining MDP automatically.",http://arxiv.org/abs/2501.10888v1
Generative Physical AI in Vision: A Survey,2025-01-19T03:19:47Z,"Daochang Liu, Junyu Zhang, Anh-Dung Dinh, Eunbyung Park, Shichao Zhang, Chang Xu","Generative Artificial Intelligence (AI) has rapidly advanced the field of
computer vision by enabling machines to create and interpret visual data with
unprecedented sophistication. This transformation builds upon a foundation of
generative models to produce realistic images, videos, and 3D or 4D content.
Traditionally, generative models primarily focus on visual fidelity while often
neglecting the physical plausibility of generated content. This gap limits
their effectiveness in applications requiring adherence to real-world physical
laws, such as robotics, autonomous systems, and scientific simulations. As
generative AI evolves to increasingly integrate physical realism and dynamic
simulation, its potential to function as a ""world simulator"" expands-enabling
the modeling of interactions governed by physics and bridging the divide
between virtual and physical realities. This survey systematically reviews this
emerging field of physics-aware generative AI in computer vision, categorizing
methods based on how they incorporate physical knowledge-either through
explicit simulation or implicit learning. We analyze key paradigms, discuss
evaluation protocols, and identify future research directions. By offering a
comprehensive overview, this survey aims to help future developments in
physically grounded generation for vision. The reviewed papers are summarized
at https://github.com/BestJunYu/Awesome-Physics-aware-Generation.",http://arxiv.org/abs/2501.10928v1
Issues with Neural Tangent Kernel Approach to Neural Networks,2025-01-19T03:21:06Z,"Haoran Liu, Anthony Tai, David J. Crandall, Chunfeng Huang","Neural tangent kernels (NTKs) have been proposed to study the behavior of
trained neural networks from the perspective of Gaussian processes. An
important result in this body of work is the theorem of equivalence between a
trained neural network and kernel regression with the corresponding NTK. This
theorem allows for an interpretation of neural networks as special cases of
kernel regression. However, does this theorem of equivalence hold in practice?
  In this paper, we revisit the derivation of the NTK rigorously and conduct
numerical experiments to evaluate this equivalence theorem. We observe that
adding a layer to a neural network and the corresponding updated NTK do not
yield matching changes in the predictor error. Furthermore, we observe that
kernel regression with a Gaussian process kernel in the literature that does
not account for neural network training produces prediction errors very close
to that of kernel regression with NTKs. These observations suggest the
equivalence theorem does not hold well in practice and puts into question
whether neural tangent kernels adequately address the training process of
neural networks.",http://arxiv.org/abs/2501.10929v1
"The anomalous density of states and quasi-localized vibration through
  homogeneous thermalization of an inhomogeneous elastic system",2025-01-19T05:05:28Z,Cunyuan Jiang,"Amorphous solids are dynamically inhomogeneous due to in lack of
translational symmetry and hence exhibit vibrational properties different from
crystalline solids with anomalous low frequency vibrational density of states
(VDOS) and related low temperature thermal properties. However, an
interpretation of their origin from basic physical laws is still needed
compared with rapidly progressed particle level investigations. In this work,
we start with the quasi-equilibrium condition, which requires elastic potential
energy to be homogeneously distributed even in an inhomogeneous elastic solid
over long time observation. Analytical result shows that the anomalous low
frequency VDOS behavior $D(\omega) \propto \omega^4$ can be obtained when the
quasi-equilibrium condition is satisfied on an inhomogeneous elastic system.
Under high frequency after a crossover depending on the length scale of
inhomogeneity, the power law of VDOS is changed to square $D(\omega) \propto
\omega^2$ which is Debye's law for crystalline solids. These features agree
with recent particle level investigations. Our work suggest that the universal
low frequency anomaly of amorphous solids can be considered as a result of
homogeneous thermalization.",http://arxiv.org/abs/2501.10947v1
"Ambient Backscatter Communication in LTE Uplink Sounding Reference
  Signal",2025-01-19T05:36:21Z,"Jingyi Liao, Tianshu Zhang, Kalle Ruttik, Riku Jäntti, Dinh-Thuy Phan-Huy","Ambient Internet of Things (AIoT), recently standardized by the 3rd
Generation Partnership Project (3GPP), demands a low-power wide-area
communication solution that operates several orders of magnitude below the
power requirements of existing 3GPP specifications. Ambient backscatter
communication (AmBC) is considered as a competitive potential technique by
harvesting energy from the ambient RF signal. This paper considers a symbiotic
AmBC into Long Term Evolution (LTE) cellular system uplink. Leveraging by LTE
uplink channel estimation ability, AIoT conveys its own message to Base Station
(BS) by modulating backscatter path. We explore the detector design, analyze
the error performance of the proposed scheme, provide exact expression and its
Guassian approximation for the error probability. We corroborate the receiver
error performance by Monte Carlo simulation. Analysis of communication range
reveals AmBC achieves a reasonable BER of order of magnitude $10^{-2}$ within
four times wavelength reading distance. In addition, a AmBC prototype in LTE
uplink confirms the its feasibility. The over-the-air experiment results
validate theoretical analysis. Hence, the proposed AmBC approach enables AIoT
deployment with minimal changes to the LTE system.",http://arxiv.org/abs/2501.10952v1
"The thermodynamic stability and phase structure of the
  Einstein-Euler-Heisenberg-AdS black holes",2025-01-19T15:26:13Z,"Yinan Zhao, Hongbo Cheng","In both canonical ensemble and grand canonical ensemble, the thermodynamic
stability and phase structure of Einstein-Euler-Heisenberg-AdS black hole are
studied. We derive the Hawking temperature, Helmholtz free energy, Gibbs
potential, entropy and heat capacity of the black holes. We compute the minimum
temperature to find that the phase transition may happen at the lowest point.
The entropy-temperature diagram consists of two parts. The upper part belonging
to the large black holes under the influence from the electromagnetic
self-interactions keeps the positive heat capacity, leading the huge compact
objects to survive. The lower curves corresponding to the small ones show that
the heat capacity of the tiny black holes is negative, which means that the
nonlinear-effect-corrected smaller sources will evaporate. The further
discussions show that the nonlinear effect modifies the thermodynamic
quantities, but the corrections limited by the nonlinear factor $\mu$ with
allowed values can not change the properties and the phase structure
fundamentally and thoroughly. We argue that the influence from self-interaction
can not make the Einstein-Euler-Heisenberg-AdS black holes to split under the
second law of thermodynamics.",http://arxiv.org/abs/2501.11075v1
"Direct Expression for One-Loop Tensor Reduction with Lorentz Indices via
  Generating Function",2025-01-19T19:23:56Z,"Chang Hu, Yifan Hu, Jiyuan Shen","In recent work, we derived a direct expression for one-loop tensor reduction
using generating functions and Feynman parametrization in projective space,
avoiding recursive relations. However, for practical applications, this
expression still presents two challenges: (1) While the final reduction
coefficients are expressed in terms of the dimension D and Mandelstam
variables, the given expression explicitly contains irrational functions; (2)
The expression involves an auxiliary vector R, which can be eliminated via
differentiation $\frac{\partial}{\partial R}$, but the presence of irrational
terms making differentiation cumbersome. (3) Most practical applications
require the tensor form with Lorentz indices.
  In this paper, we provide a rational form of the reduction coefficients with
Lorentz indices, free from recursion. Additionally, We provide a pure Wolfram
Mathematica implementation of the code. Our practical tests demonstrate that
this direct expression achieves significantly higher computational efficiency
compared to the traditional Passarino-Veltman (PV) reduction or other
recursion-based methods.",http://arxiv.org/abs/2501.11150v1
"Remote characterization of aerogel foam concrete using dynamic speckle
  pattern analysis",2025-01-19T21:18:46Z,"Ramin Jamali, Mohammad Hadi Sadri, Ali-Reza Moradi","Aerogel foam concrete (AFC) has garnered significant attention in recent
years due to its exceptional thermal insulation, lightweight structure, and
versatility in construction applications. However, the durability of this
material in various chemical environments, particularly acidic and alkaline
solutions, remains a critical concern for its long-term performance. In this
study, we employed an advanced remote characterization technique-dynamic
speckle pattern analysis-to monitor and quantify the degradation and corrosion
processes of AFC under these conditions. Using this non-invasive method, we
extracted valuable statistical parameters, including the time history of
speckle patterns, co-occurrence matrix, inertia moment, Pearson correlation,
and roughness indices, to provide a comprehensive analysis of surface and
structural changes. Our findings reveal that AFC exposed to acidic environments
undergoes faster degradation and more severe surface damage compared to
alkaline environments, as demonstrated through $\textit{in situ}$ and remote
characterization. These results underscore the importance of understanding
material behavior in diverse conditions, offering critical insights for
improving the durability of AFC in various applications.",http://arxiv.org/abs/2501.11172v1
"Spontaneous spatial sorting by cell shape in growing colonies of
  rod-like bacteria",2025-01-19T21:29:32Z,"Mateusz Ratman, Jimmy Gonzalez Nuñez, Daniel A. Beller","Mechanical interactions among cells in a growing microbial colony can
significantly influence the colony's spatial genetic structure and, thus,
evolutionary outcomes such as the fates of rare mutations. Here, we
computationally investigate how this spatial genetic structure changes as a
result of heritable phenotypic variations in cell shape. By modeling rod-like
bacterial cells as lengthening and dividing circo-rectangles in a 2D Brownian
dynamics framework, we simulate the growth of a colony containing two
populations with different aspect ratios. Compared to monodisperse colonies,
such bidisperse colonies exhibit diminished intermixing between sub-populations
when the less elongated cells are too short to nematically order, instead
forming large clusters. We find that the cells with longer aspect ratio
gradually segregate to the colony periphery. We present evidence that this
demixing is related to nematic order in the bulk and to active nematic mixing
dynamics near the periphery. These findings are qualitatively robust across
different growth rate protocols and initial conditions. Because the periphery
is often an advantageous position when nutrients are limited, our results
suggest a possible evolutionary selective pressure of mechanical origin that
favors large cell aspect ratio.",http://arxiv.org/abs/2501.11177v1
Local Limits of Small World Networks,2025-01-20T02:21:37Z,"Yeganeh Alimohammadi, Senem Işık, Amin Saberi","Small-world networks, known for their high local clustering and short average
path lengths, are a fundamental structure in many real-world systems, including
social, biological, and technological networks. We apply the theory of local
convergence (Benjamini-Schramm convergence) to derive the limiting behavior of
the local structures for two of the most commonly studied small-world network
models: the Watts-Strogatz model and the Kleinberg model. Establishing local
convergence enables us to show that key network measures, such as PageRank,
clustering coefficients, and maximum matching size, converge as network size
increases with their limits determined by the graph's local structure.
Additionally, this framework facilitates the estimation of global phenomena,
such as information cascades, using local information from small neighborhoods.
As an additional outcome of our results, we observe a critical change in the
behavior of the limit exactly when the parameter governing long-range
connections in the Kleinberg model crosses the threshold where decentralized
search remains efficient, offering a new perspective on why decentralized
algorithms fail in certain regimes.",http://arxiv.org/abs/2501.11226v1
"Mode shapes and sensitivity analysis of torsional vibrations in
  overhang- and T-shaped microcantilevers",2025-01-20T03:46:27Z,"Le Tri Dat, Vinh N. T. Pham, Nguyen Duy Vy","The torsional mode of atomic force microscope (AFM) cantilevers plays a
crucial role in a wide range of sensitive measurements. Despite their
importance, the use of approximated frequencies and mode shapes for
width-varying cantilevers often results in discrepancies between theoretical
models and experimental observations. In this study, we present an analytical
approach to accurately calculate the mode shapes and resonance frequencies of
these cantilevers, including higher-order modes, then we derive the modal
sensitivity. Our results reveal distinct changes in mode shapes and frequencies
as the overhang length increases, with the mode shapes showing multiple maxima.
Furthermore, we demonstrate that tuning the overhang length provides effective
control over the resonant frequency. The relationship between modal sensitivity
and the coupling strength between the cantilever and the surface is also
established, aligning with previous experimental findings. This work offers
valuable insights for optimizing cantilever geometry to achieve desired
frequency responses in AFM applications.",http://arxiv.org/abs/2501.11256v1
"In-medium bottomonium properties from lattice NRQCD calculations with
  extended meson operators",2025-01-20T03:52:13Z,"H. -T. Ding, W. -P. Huang, R. Larsen, S. Meinel, Swagato Mukherjee, P. Petreczky, Zhanduo Tang","We calculate the temperature dependence of bottomonium correlators in
(2+1)-flavor lattice QCD with the aim to constrain in-medium properties of
bottomonia at high temperature. The lattice calculations are performed using
HISQ action with physical strange quark mass and light quark masses twenty
times smaller than the strange quark mass at two lattice spacings $a=0.0493$ fm
and $0.0602$ fm, and temporal extents $N_{\tau}=16-30$, corresponding to the
temperatures $T=133-250$ MeV. We use a tadpole-improved NRQCD action including
spin-dependent $v^6$ corrections for the heavy quarks and extended meson
operators in order to be sensitive to in-medium properties of the bottomonium
states of interest. We find that within estimated errors the bottomonium masses
do not change compared to their vacuum values for all temperatures under our
consideration; however, we find different nonzero widths for the various
bottomonium states.",http://arxiv.org/abs/2501.11257v1
"Multiply iterated Poisson processes and their applications in ruin
  theory",2025-01-20T07:54:49Z,"Dongdong Hu, Svetlozar T. Rachev, Hasanjan Sayit, Hailiang Yang, Yildiray Yildirim","This paper studies the properties of the Multiply Iterated Poisson Process
(MIPP), a stochastic process constructed by repeatedly time-changing a Poisson
process, and its applications in ruin theory. Like standard Poisson processes,
MIPPs have exponentially distributed sojourn times (waiting times between
jumps). We explicitly derive the probabilities of all possible jump sizes at
the first jump and obtain the Laplace transform of the joint distribution of
the first jump time and its corresponding jump size. In ruin theory, the
classical Cram\'er-Lundberg model assumes claims arrive independently according
to a Poisson process. In contrast, our model employs MIPP to allow for
clustered arrivals, reflecting real-world scenarios, such as catastrophic
events. Under this new framework, we derive the corresponding scale function in
closed form, facilitating accurate ruin probability calculations in the
presence of clustered claims. These results improve the modeling of extreme
risks and have practical implications for insurance solvency assessments,
reinsurance pricing, and capital reserve estimation.",http://arxiv.org/abs/2501.11322v1
CME Observations -- from Sun to Impact on Geospace,2025-01-20T09:09:50Z,Manuela Temmer,"Our Sun is an active star expelling dynamic phenomena known as coronal mass
ejections (CMEs). The magnetic field configuration on the Sun and related solar
wind structures affect the propagation behavior of CMEs, dominate its transit
time and embedded magnetic field properties when impacting Earth. Since the
conditions on the Sun constantly change, the impact of CMEs on the different
regimes of geospace is quite variable and may differ significantly from event
to event. This short review summarizes the different manifestations of CMEs on
the Sun, their appearance in interplanetary space, and how CMEs trigger a
cascade of reactions as they interact with Earth.",http://arxiv.org/abs/2501.11345v1
"A Multidimensional Elasticity Framework for Adaptive Data Analytics
  Management in the Computing Continuum",2025-01-20T09:56:26Z,"Sergio Laso, Ilir Murturi, Pantelis Frangoudis, Juan Luis Herrera, Juan M. Murillo, Schahram Dustdar","The increasing complexity of IoT applications and the continuous growth in
data generated by connected devices have led to significant challenges in
managing resources and meeting performance requirements in computing continuum
architectures. Traditional cloud solutions struggle to handle the dynamic
nature of these environments, where both infrastructure demands and data
analytics requirements can fluctuate rapidly. As a result, there is a need for
more adaptable and intelligent resource management solutions that can respond
to these changes in real-time. This paper introduces a framework based on
multi-dimensional elasticity, which enables the adaptive management of both
infrastructure resources and data analytics requirements. The framework
leverages an orchestrator capable of dynamically adjusting architecture
resources such as CPU, memory, or bandwidth and modulating data analytics
requirements, including coverage, sample, and freshness. The framework has been
evaluated, demonstrating the impact of varying data analytics requirements on
system performance and the orchestrator's effectiveness in maintaining a
balanced and optimized system, ensuring efficient operation across edge and
head nodes.",http://arxiv.org/abs/2501.11369v1
"Steady state and mixing of two run-and-tumble particles interacting
  through jamming and attractive forces",2025-01-20T10:15:13Z,Leo Hahn,"We study the long-time behavior of two run-and-tumble particles on the real
line subjected to an attractive interaction potential and jamming interactions,
which prevent the particles from crossing. We provide the explicit invariant
measure, a useful tool for studying clustering phenomena in out-ofequilibrium
statistical mechanics, for different tumbling mechanisms and potentials. An
important difference with invariant measures of equilibrium systems are Dirac
masses on the boundary of the state space, due to the jamming interactions.
Qualitative changes in the invariant measure depending on model parameters are
also observed, suggesting, like a growing body of evidence, that run-andtumble
particle systems can be classified into close-to-equilibrium and strongly
out-of-equilibrium models. We also study the relaxation properties of the
system, which are linked to the timescale at which clustering emerges from an
arbitrary initial configuration. When the interaction potential is linear, we
show that the total variation distance to the invariant measure decays
exponentially and provide sharp bounds on the decay rate. When the interaction
potential is harmonic, we give quantitative exponential bounds in a
Wasserstein-type distance.",http://arxiv.org/abs/2501.11379v1
"Generalization and Informativeness of Weighted Conformal Risk Control
  Under Covariate Shift",2025-01-20T11:26:36Z,"Matteo Zecchin, Fredrik Hellström, Sangwoo Park, Shlomo Shamai, Osvaldo Simeone","Predictive models are often required to produce reliable predictions under
statistical conditions that are not matched to the training data. A common type
of training-testing mismatch is covariate shift, where the conditional
distribution of the target variable given the input features remains fixed,
while the marginal distribution of the inputs changes. Weighted conformal risk
control (W-CRC) uses data collected during the training phase to convert point
predictions into prediction sets with valid risk guarantees at test time
despite the presence of a covariate shift. However, while W-CRC provides
statistical reliability, its efficiency -- measured by the size of the
prediction sets -- can only be assessed at test time. In this work, we relate
the generalization properties of the base predictor to the efficiency of W-CRC
under covariate shifts. Specifically, we derive a bound on the inefficiency of
the W-CRC predictor that depends on algorithmic hyperparameters and
task-specific quantities available at training time. This bound offers insights
on relationships between the informativeness of the prediction sets, the extent
of the covariate shift, and the size of the calibration and training sets.
Experiments on fingerprinting-based localization validate the theoretical
results.",http://arxiv.org/abs/2501.11413v1
"Multitask Auxiliary Network for Perceptual Quality Assessment of
  Non-Uniformly Distorted Omnidirectional Images",2025-01-20T14:41:29Z,"Jiebin Yan, Jiale Rao, Junjie Chen, Ziwen Tan, Weide Liu, Yuming Fang","Omnidirectional image quality assessment (OIQA) has been widely investigated
in the past few years and achieved much success. However, most of existing
studies are dedicated to solve the uniform distortion problem in OIQA, which
has a natural gap with the non-uniform distortion problem, and their ability in
capturing non-uniform distortion is far from satisfactory. To narrow this gap,
in this paper, we propose a multitask auxiliary network for non-uniformly
distorted omnidirectional images, where the parameters are optimized by jointly
training the main task and other auxiliary tasks. The proposed network mainly
consists of three parts: a backbone for extracting multiscale features from the
viewport sequence, a multitask feature selection module for dynamically
allocating specific features to different tasks, and auxiliary sub-networks for
guiding the proposed model to capture local distortion and global quality
change. Extensive experiments conducted on two large-scale OIQA databases
demonstrate that the proposed model outperforms other state-of-the-art OIQA
metrics, and these auxiliary sub-networks contribute to improve the performance
of the proposed model. The source code is available at
https://github.com/RJL2000/MTAOIQA.",http://arxiv.org/abs/2501.11512v1
"Investigating the Scalability of Approximate Sparse Retrieval Algorithms
  to Massive Datasets",2025-01-20T17:59:21Z,"Sebastian Bruch, Franco Maria Nardini, Cosimo Rulli, Rossano Venturini, Leonardo Venuta","Learned sparse text embeddings have gained popularity due to their
effectiveness in top-k retrieval and inherent interpretability. Their
distributional idiosyncrasies, however, have long hindered their use in
real-world retrieval systems. That changed with the recent development of
approximate algorithms that leverage the distributional properties of sparse
embeddings to speed up retrieval. Nonetheless, in much of the existing
literature, evaluation has been limited to datasets with only a few million
documents such as MSMARCO. It remains unclear how these systems behave on much
larger datasets and what challenges lurk in larger scales. To bridge that gap,
we investigate the behavior of state-of-the-art retrieval algorithms on massive
datasets. We compare and contrast the recently-proposed Seismic and graph-based
solutions adapted from dense retrieval. We extensively evaluate Splade
embeddings of 138M passages from MsMarco-v2 and report indexing time and other
efficiency and effectiveness metrics.",http://arxiv.org/abs/2501.11628v1
"Boundary Quantum Field Theories Perturbed by ${\rm T}\bar{\rm T}$:
  Towards a Form Factor Program",2025-01-20T18:25:01Z,"Olalla A. Castro-Alvaredo, Stefano Negro, Fabio Sailis","Our understanding of irrelevant perturbations of integrable quantum field
theories has greatly expanded over the last decade. In particular, we know
that, from a scattering theory viewpoint at least, their effect is realised as
a modification the two-body scattering amplitudes by a CDD factor. While this
sounds like a relatively small change, this CDD factor incorporates a
non-trivial dependence on the perturbation parameter(s) and alters
substantially the high-energy physics of the model. This occurs through the
introduction of a natural length scale and is associated with phenomena such as
the Hagedorn transition. In this paper we discuss how all these features extend
to boundary integrable quantum field theories and propose a construction for
the building blocks of matrix elements of local fields. We show that the same
type of building blocks are also found in the sinh-Gordon model with Dirichlet
boundary conditions.",http://arxiv.org/abs/2501.11647v1
"Less Wound and More Asymmetric: JWST Confirms the Evolution of Spiral
  Structure in Galaxies at $z \lesssim 3$",2025-01-20T18:54:30Z,"Ilia V. Chugunov, Alexander A. Marchuk, Aleksandr V. Mosenkov","Spiral galaxies are ubiquitous in the local Universe. However the properties
of spiral arms in them are still not well studied, and there is even less
information concerning spiral structure in distant galaxies. We aim to measure
the most general parameters of spiral arms in remote galaxies and trace their
changes with redshift. We perform photometric decomposition, including spiral
arms, for 159 galaxies from the HST COSMOS and JWST CEERS and JADES surveys,
which are imaged in optical and near-infrared rest-frame wavelengths. We
confirm that, in our representative sample of spiral galaxies, the pitch angles
increase, and the azimuthal lengths decrease with increasing redshift, implying
that the spiral structure becomes more tightly wound over time. For the
spiral-to-total luminosity ratio and the spiral width-to-disc scale length
ratio, we find that band-shifting effects can be as significant as, or even
stronger than, evolutionary effects. Additionally, we find that spiral
structure becomes more asymmetric at higher redshifts.",http://arxiv.org/abs/2501.11670v1
"Nehari-type ground state solutions for asymptotically periodic
  bi-harmonic Kirchhoff-type problems in $\mathbb{R}^N$",2025-01-20T19:16:46Z,Antônio de Pádua Farias de Souza Filho,"We investigate the following Kirchhoff-type biharmonic equation
\begin{equation}\label{pr} \left\{ \begin{array}{ll} \Delta^2 u+
\left(a+b\int_{\mathbb{R}^N}|\nabla u|^2d x\right)(-\Delta
u+V(x)u)=f(x,u),\quad x\in \mathbb{R}^N,\\ u\in H^{2}(\mathbb{R}^N),
\end{array} \right. \end{equation} where $a>0$, $b\geq 0$ and $V(x)$ and $f(x,
u)$ are periodic or asymptotically periodic in $x$. We study the existence of
Nehari-type ground state solutions of \eqref{pr} with $f(x,u)u-4F(x,u)$
sign-changing, where $F(x,u):=\int_0^uf(x,s)d s$. We significantly extend some
results from the previous literature.",http://arxiv.org/abs/2501.11693v2
"Transformer Vibration Forecasting for Advancing Rail Safety and
  Maintenance 4.0",2025-01-20T20:29:40Z,"Darío C. Larese, Almudena Bravo Cerrada, Gabriel Dambrosio Tomei, Alejandro Guerrero-López, Pablo M. Olmos, María Jesús Gómez García","Maintaining railway axles is critical to preventing severe accidents and
financial losses. The railway industry is increasingly interested in advanced
condition monitoring techniques to enhance safety and efficiency, moving beyond
traditional periodic inspections toward Maintenance 4.0.
  This study introduces a robust Deep Autoregressive solution that integrates
seamlessly with existing systems to avert mechanical failures. Our approach
simulates and predicts vibration signals under various conditions and fault
scenarios, improving dataset robustness for more effective detection systems.
These systems can alert maintenance needs, preventing accidents preemptively.
We use experimental vibration signals from accelerometers on train axles.
  Our primary contributions include a transformer model, ShaftFormer, designed
for processing time series data, and an alternative model incorporating
spectral methods and enhanced observation models. Simulating vibration signals
under diverse conditions mitigates the high cost of obtaining experimental
signals for all scenarios. Given the non-stationary nature of railway vibration
signals, influenced by speed and load changes, our models address these
complexities, offering a powerful tool for predictive maintenance in the rail
industry.",http://arxiv.org/abs/2501.11730v1
"Preconditioning for a Cahn-Hilliard-Navier-Stokes model for morphology
  formation in organic solar cells",2025-01-20T22:06:58Z,"Pelin Çiloğlu, Carmen Tretmans, Roland Herzog, Jan-F. Pietschmann, Martin Stoll","We present a model for the morphology evolution of printed organic solar
cells which occurs during the drying of a mixture of polymer, the non-fullerene
acceptor and the solvent. Our model uses a phase field approach coupled to a
Navier-Stokes equation describing the macroscopic movement of the fluid.
Additionally, we incorporate the evaporation process of the solvent using an
Allen-Cahn equation.
  The model is discretized using a finite-element approach with a semi-implicit
discretization in time. The resulting (non)linear systems are coupled and of
large dimensionality. We present a preconditioned iterative scheme to solve
them robustly with respect to changes in the discretization parameters. We
illustrate that the preconditioned solver shows parameter-robust iteration
numbers and that the model qualitatively captures the behavior of the film
morphology during drying.",http://arxiv.org/abs/2501.11767v1
"Arrangements of circles supported by small chords and compatible with
  natural real algebraic functions",2025-01-21T01:57:21Z,Naoki Kitazawa,"We have previously proposed a study of arrangements of small circles which
also surround regions in the plane realized as the images of natural real
algebraic maps yielding Morse-Bott functions by projections. Among studies of
arrangements, families of smooth regular submanifolds in smooth manifolds, this
study is fundamental, explicit, and new, surprisingly.
  We have obtained a complete list of local changes of the graphs the regions
naturally collapse to in adding a (generic) small circle to an existing
arrangement of the proposed class. Here, we propose a similar and essentially
different class of arrangements of circles. The present study also yields real
algebraic maps and nice real algebraic functions similarly and we present a
similar study.
  We are interested in topological properties and combinatorics among such
arrangements and regions and applications to constructing such real algebraic
maps and manifolds explicitly and understanding their global structures.",http://arxiv.org/abs/2501.11819v1
"A Fully Pipelined FIFO Based Polynomial Multiplication Hardware
  Architecture Based On Number Theoretic Transform",2025-01-21T03:50:26Z,"Moslem Heidarpur, Mitra Mirhassani, Norman Chang","This paper presents digital hardware for computing polynomial multiplication
using Number Theoretic Transform (NTT), specifically designed for
implementation on Field Programmable Gate Arrays (FPGAs). Multiplying two large
polynomials applies to many modern encryption schemes, including those based on
Ring Learning with Error (RLWE). The proposed design uses First In, First Out
(FIFO) buffers to make the design fully pipelined and capable of computing two
n degree polynomials in n/2 clock cycles. This hardware proposes a two-fold
reduction in the processing time of polynomial multiplication compared to
state-of-the-art enabling twice as much encryption in the same amount of time.
Despite that, the proposed hardware utilizes fewer resources than the
fastest-reported work.",http://arxiv.org/abs/2501.11867v1
"Probing negative differential resistance in silicon with a P-I-N
  diode-integrated T center ensemble",2025-01-21T04:54:30Z,"Aaron M. Day, Chaoshen Zhang, Chang Jin, Hanbin Song, Madison Sutula, Alp Sipahigil, Mihir K. Bhaskar, Evelyn L. Hu","The T center in silicon has recently emerged as a promising candidate for
scalable quantum technologies, due to its telecommunications band optical
transition and microwave addressable ground state spin. The immense promise of
the T center is driven by its silicon host material; silicon is by far the most
mature, manufacturable semiconductor material for integrated photonic and
electronic devices. Here, we present the first study of T-centers in an
electrical device. We study an ensemble of T centers coupled to a buried
lateral P-I-N diode in silicon, observing the T-center's optical response to
static and dynamic electric fields. We utilize the defect's optical response as
a probe of device nonlinearity, observing a phase transition of the carrier
density into a stable oscillatory regime characteristic of negative
differential resistance. These findings provide fundamental insight into the
physics of the T-center for improved quantum device performance and open a
promising new direction for defect-based local quantum sensing in semiconductor
devices.",http://arxiv.org/abs/2501.11888v1
"MeshONet: A Generalizable and Efficient Operator Learning Method for
  Structured Mesh Generation",2025-01-21T07:27:05Z,"Jing Xiao, Xinhai Chen, Qingling Wang, Jie Liu","Mesh generation plays a crucial role in scientific computing. Traditional
mesh generation methods, such as TFI and PDE-based methods, often struggle to
achieve a balance between efficiency and mesh quality. To address this
challenge, physics-informed intelligent learning methods have recently emerged,
significantly improving generation efficiency while maintaining high mesh
quality. However, physics-informed methods fail to generalize when applied to
previously unseen geometries, as even small changes in the boundary shape
necessitate burdensome retraining to adapt to new geometric variations. In this
paper, we introduce MeshONet, the first generalizable intelligent learning
method for structured mesh generation. The method transforms the mesh
generation task into an operator learning problem with multiple input and
solution functions. To effectively overcome the multivariable mapping
restriction of operator learning methods, we propose a dual-branch,
shared-trunk architecture to approximate the mapping between function spaces
based on input-output pairs. Experimental results show that MeshONet achieves a
speedup of up to four orders of magnitude in generation efficiency over
traditional methods. It also enables generalization to different geometries
without retraining, greatly enhancing the practicality of intelligent methods.",http://arxiv.org/abs/2501.11937v2
GLAM: Global-Local Variation Awareness in Mamba-based World Model,2025-01-21T07:47:03Z,"Qian He, Wenqi Liang, Chunhui Hao, Gan Sun, Jiandong Tian","Mimicking the real interaction trajectory in the inference of the world model
has been shown to improve the sample efficiency of model-based reinforcement
learning (MBRL) algorithms. Many methods directly use known state sequences for
reasoning. However, this approach fails to enhance the quality of reasoning by
capturing the subtle variation between states. Much like how humans infer
trends in event development from this variation, in this work, we introduce
Global-Local variation Awareness Mamba-based world model (GLAM) that improves
reasoning quality by perceiving and predicting variation between states. GLAM
comprises two Mambabased parallel reasoning modules, GMamba and LMamba, which
focus on perceiving variation from global and local perspectives, respectively,
during the reasoning process. GMamba focuses on identifying patterns of
variation between states in the input sequence and leverages these patterns to
enhance the prediction of future state variation. LMamba emphasizes reasoning
about unknown information, such as rewards, termination signals, and visual
representations, by perceiving variation in adjacent states. By integrating the
strengths of the two modules, GLAM accounts for highervalue variation in
environmental changes, providing the agent with more efficient
imagination-based training. We demonstrate that our method outperforms existing
methods in normalized human scores on the Atari 100k benchmark.",http://arxiv.org/abs/2501.11949v1
"GSVC: Efficient Video Representation and Compression Through 2D Gaussian
  Splatting",2025-01-21T11:30:51Z,"Longan Wang, Yuang Shi, Wei Tsang Ooi","3D Gaussian splats have emerged as a revolutionary, effective, learned
representation for static 3D scenes. In this work, we explore using 2D Gaussian
splats as a new primitive for representing videos. We propose GSVC, an approach
to learning a set of 2D Gaussian splats that can effectively represent and
compress video frames. GSVC incorporates the following techniques: (i) To
exploit temporal redundancy among adjacent frames, which can speed up training
and improve the compression efficiency, we predict the Gaussian splats of a
frame based on its previous frame; (ii) To control the trade-offs between file
size and quality, we remove Gaussian splats with low contribution to the video
quality; (iii) To capture dynamics in videos, we randomly add Gaussian splats
to fit content with large motion or newly-appeared objects; (iv) To handle
significant changes in the scene, we detect key frames based on loss
differences during the learning process. Experiment results show that GSVC
achieves good rate-distortion trade-offs, comparable to state-of-the-art video
codecs such as AV1 and VVC, and a rendering speed of 1500 fps for a 1920x1080
video.",http://arxiv.org/abs/2501.12060v2
"On the cohomology of simple Shimura varieties with non quasi-split local
  groups",2025-01-21T13:40:22Z,"Jingren Chi, Thomas J. Haines","We study the Scholze test functions for bad reduction of simple Shimura
varieties at a prime where the underlying local group is any inner form of a
product of Weil restrictions of general linear groups. Using global methods, we
prove that these test functions satisfy a vanishing property of their twisted
orbital integrals, and we prove that the pseudostabilization base changes of
such functions exist (even though the local group need not be quasi-split) and
can be expressed in terms of explicit distributions in the stable Bernstein
center. We then deduce applications to the stable trace formula and local
Hasse-Weil zeta functions for these Shimura varieties.",http://arxiv.org/abs/2501.12127v2
Nucleon tensor form factors at large $N_{c}$,2025-01-21T16:00:31Z,"Nam-Yong Ghim, Ho-Yeon Won, June-Young Kim, Hyun-Chul Kim","We investigate nucleon tensor form factors in the large-$N_{c}$ limit. In
this picture, the nucleon emerges as a state of the $N_c$ valence quarks, which
were bound by pion mean fields that were created by the presence of the valence
quarks self-consistently. We find that the tensor charge ($g^{u-d}_{T}=0.99$)
and the anomalous tensor magnetic moment ($\kappa^{u+d}_{T}=7.61$) are
dominated by valence quarks, while the tensor quadrupole moment
($Q^{u-d}_{T}=-7.02$) shows significant sea quark effects. We examine how these
quantities vary as the average size of the pion mean field is changed, showing
interpolation between non-relativistic quark and Skyrme limits. We also observe
that $g^{u-d}_{T}$ and $\kappa^{u+d}_{T}$ depend weakly on the pion mass. In
contrast, $Q^{u-d}_{T}$ exhibits strong enhancement near the chiral limit. The
numerical results are in good agreement with available lattice QCD data and
provide predictions for unmeasured quantities.",http://arxiv.org/abs/2501.12241v1
"Benchmarking Image Perturbations for Testing Automated Driving
  Assistance Systems",2025-01-21T16:40:44Z,"Stefano Carlo Lambertenghi, Hannes Leonhard, Andrea Stocco","Advanced Driver Assistance Systems (ADAS) based on deep neural networks
(DNNs) are widely used in autonomous vehicles for critical perception tasks
such as object detection, semantic segmentation, and lane recognition. However,
these systems are highly sensitive to input variations, such as noise and
changes in lighting, which can compromise their effectiveness and potentially
lead to safety-critical failures.
  This study offers a comprehensive empirical evaluation of image
perturbations, techniques commonly used to assess the robustness of DNNs, to
validate and improve the robustness and generalization of ADAS perception
systems. We first conducted a systematic review of the literature, identifying
38 categories of perturbations. Next, we evaluated their effectiveness in
revealing failures in two different ADAS, both at the component and at the
system level. Finally, we explored the use of perturbation-based data
augmentation and continuous learning strategies to improve ADAS adaptation to
new operational design domains. Our results demonstrate that all categories of
image perturbations successfully expose robustness issues in ADAS and that the
use of dataset augmentation and continuous learning significantly improves ADAS
performance in novel, unseen environments.",http://arxiv.org/abs/2501.12269v1
Period Analysis of Eclipsing Cataclysmic Variable Stars,2025-01-21T18:09:25Z,"Mennatalla Mahmoud Ellaqany, Valeria Garcia-Lopez, Emily S. Hatten, Mridul Agarwal, David A. Moffett","We have performed a study of the orbital properties of seven eclipsing
cataclysmic variable (CV) binary systems by analyzing photometric time series
from the Transiting Exoplanet Survey Satellite (TESS). We employed Python code
to determine the eclipse epochs and orbital periods for each system, and
constructed O-C diagrams from observed and predicted eclipse epochs. By
analyzing the O-C diagrams of our target CVs, we have constrained values for
changes in orbital period with time. Our targets include a sample of sources
from each class of non-magnetic, eclipsing CVs: dwarf novae variables, Z Cam
type, and U Gem subclasses. We include in our study classical novae variables,
nova-like variables (including the VY Scl and UX UMa subclasses), and recurrent
novae variable stars. We approached this project with goals of developing time
series analysis techniques for future undergraduate-level studies of eclipsing
CVs, and how they may contribute to the understanding of their orbital
evolution.",http://arxiv.org/abs/2501.12334v1
Self-assembling of Ge quantum dots in an alumina matrix,2025-01-21T19:04:23Z,"M. Buljan, S. R. C. Pinto, A. G. Rolo, J. Martín-Sánchez, M. J. M. Gomes, J. Grenzer, A. Mücklich, S. Bernstorff, V. Holý","In this work we report on a self-assembled growth of a Ge quantum dot lattice
in a single 600-nm-thick Ge+Al2O3 layer during magnetron sputtering deposition
of a Ge+Al2O3 mixture at an elevated substrate temperature. The self-assembly
results in the formation of a well-ordered threedimensional body-centered
tetragonal quantum dot lattice within the whole deposited volume. The quantum
dots formed are very small in size less than 4.0 nm, have a narrow size
distribution and a large packing density. The parameters of the quantum dot
lattice can be tuned by changing the deposition parameters. The self-ordering
of the quantum dots is explained by diffusionmediated nucleation and
surface-morphology effects and simulated by a kinetic Monte Carlo model.",http://arxiv.org/abs/2501.12455v1
Tunable extraordinary optical transmission for integrated photonics,2025-01-21T19:56:37Z,"Hira Asif, Ramazan Sahin","The propagation of light through opaque materials, served by periodic arrays
of subwavelength holes, has revolutionized imaging and sensor technology with a
breakthrough of extraordinary optical transmission (EOT). The enhanced optical
transmission assisted by surface plasmon resonances (SPR) has become the most
ingenious phenomenon in the field of light-matter interaction. Active tuning of
SPR presents a new and simple way to control spectral features of the EOT
signal (without the need to change the geometrical structure of the device).
This provides a new possibility to integrate an active EOT device with tunable
operational frequencies on a single chip of photonic integrated circuits (PIC)-
a new scalable instrument in the optoelectronic industry, and quantum
technology for improving subwavelength optical imaging and biomedical sensing.
In this review, we discuss the fundamentals of EOT, the role of SPR, and how
the active quantum plasmonic control of the EOT device makes it a feasible
on-chip electro-optic programmable element for integrated photonics.",http://arxiv.org/abs/2501.12476v1
"Global symmetries of quantum lattice models under non-invertible
  dualities",2025-01-21T21:52:39Z,"Weiguang Cao, Yuan Miao, Masahito Yamazaki","Non-invertible dualities/symmetries have become an important tool in the
study of quantum field theories and quantum lattice models in recent years. One
of the most studied examples is non-invertible dualities obtained by gauging a
discrete group. When the physical system has more global symmetries than the
gauged symmetry, it has not been thoroughly investigated how those global
symmetries transform under non-invertible duality. In this paper, we study the
change of global symmetries under non-invertible duality of gauging a discrete
group $G$ in the context of (1+1)-dimensional quantum lattice models. We obtain
the global symmetries of the dual model by focusing on different Hilbert space
sectors determined by the $\mathrm{Rep}(G)$ symmetry. We provide general
conjectures of global symmetries of the dual model forming an algebraic ring of
the double cosets. We present concrete examples of the XXZ models and the
duals, providing strong evidence for the conjectures.",http://arxiv.org/abs/2501.12514v1
"On the Uniqueness of Certain Types of Circle Packings on Translation
  Surfaces",2025-01-22T00:14:29Z,Nilay Mishra,"Consider a collection of finitely many polygons in $\mathbb C$, such that for
each side of each polygon, there exists another side of some polygon in the
collection (possibly the same) that is parallel and of equal length. A
translation surface is the surface formed by identifying these opposite sides
with one another. The $H(1, 1)$ stratum consists of genus two translation
surfaces with two singularities of order one. A circle packing corresponding to
a graph $G$ is a configuration of disjoint disks such that each vertex of $G$
corresponds to a circle, two disks are externally tangent if and only if their
vertices are connected by an edge in $G$, and $G$ is a triangulation of the
surface. It is proven that for certain circle packings on $H(1, 1)$ translation
surfaces, there are only a finite number of ways the packing can vary without
changing the contacts graph, if two disks along the slit are fixed in place.
These variations can be explicitly characterized using a new concept known as
splitting bigons. Finally, the uniqueness theorem is generalized to a specific
type of translation surfaces with arbitrary genus $g \geq 2$.",http://arxiv.org/abs/2501.12552v1
"GATE: Adaptive Learning with Working Memory by Information Gating in
  Multi-lamellar Hippocampal Formation",2025-01-22T03:41:35Z,"Yuechen Liu, Zishun Wang, Chen Qiao, Zongben Xu","Hippocampal formation (HF) can rapidly adapt to varied environments and build
flexible working memory (WM). To mirror the HF's mechanism on generalization
and WM, we propose a model named Generalization and Associative Temporary
Encoding (GATE), which deploys a 3-D multi-lamellar dorsoventral (DV)
architecture, and learns to build up internally representation from externally
driven information layer-wisely. In each lamella, regions of HF:
EC3-CA1-EC5-EC3 forms a re-entrant loop that discriminately maintains
information by EC3 persistent activity, and selectively readouts the retained
information by CA1 neurons. CA3 and EC5 further provides gating function that
controls these processes. After learning complex WM tasks, GATE forms neuron
representations that align with experimental records, including splitter, lap,
evidence, trace, delay-active cells, as well as conventional place cells.
Crucially, DV architecture in GATE also captures information, range from
detailed to abstract, which enables a rapid generalization ability when cue,
environment or task changes, with learned representations inherited. GATE
promises a viable framework for understanding the HF's flexible memory
mechanisms and for progressively developing brain-inspired intelligent systems.",http://arxiv.org/abs/2501.12615v1
"DWTNeRF: Boosting Few-shot Neural Radiance Fields via Discrete Wavelet
  Transform",2025-01-22T04:53:12Z,"Hung Nguyen, Blark Runfa Li, Truong Nguyen","Neural Radiance Fields (NeRF) has achieved superior performance in novel view
synthesis and 3D scene representation, but its practical applications are
hindered by slow convergence and reliance on dense training views. To this end,
we present DWTNeRF, a unified framework based on Instant-NGP's fast-training
hash encoding. It is coupled with regularization terms designed for few-shot
NeRF, which operates on sparse training views. Our DWTNeRF additionally
includes a novel Discrete Wavelet loss that allows explicit prioritization of
low frequencies directly in the training objective, reducing few-shot NeRF's
overfitting on high frequencies in earlier training stages. We also introduce a
model-based approach, based on multi-head attention, that is compatible with
INGP, which are sensitive to architectural changes. On the 3-shot LLFF
benchmark, DWTNeRF outperforms Vanilla INGP by 15.07% in PSNR, 24.45% in SSIM
and 36.30% in LPIPS. Our approach encourages a re-thinking of current few-shot
approaches for fast-converging implicit representations like INGP or 3DGS.",http://arxiv.org/abs/2501.12637v2
"Heat Transport Hysteresis Generated through Frequency Switching of a
  Time-Dependent Temperature Gradient",2025-01-22T05:17:38Z,"Renai Chen, Galen T. Craven","A stochastic energetics framework is applied to examine how periodically
shifting the frequency of a time-dependent oscillating temperature gradient
affects heat transport in a nanoscale molecular model. We specifically examine
the effects that frequency switching, i.e., instantaneously changing the
oscillation frequency of the temperature gradient, has on the shape of the heat
transport hysteresis curves generated by a particle connected to two thermal
baths, each with a temperature that is oscillating in time. Analytical
expressions are derived for the energy fluxes in/out of the system and the
baths, with excellent agreement observed between the analytical expressions and
the results from nonequilibrium molecular dynamics simulations. We find that
the shape of the heat transport hysteresis curves can be significantly altered
by shifting the frequency between fast and slow oscillation regimes. We also
observe the emergence of features in the hysteresis curves such as pinched
loops and complex multi-loop patterns due to the frequency shifting. The
presented results have implications in the design of thermal neuromorphic
devices such as thermal memristors and thermal memcapacitors.",http://arxiv.org/abs/2501.12649v1
"Strong shape-dependent intensity of inelastic light scattering by gold
  nanocrystals",2025-01-22T08:02:54Z,"Lucien Saviot, Vincent Laude","We present a numerical approach to calculate inelastic light scattering
spectra from gold nanocrystals, based on the finite element method. This
approach is validated by comparison with previous analytic calculations for
spherically symmetric scatterers. Superellipsoid nanocrystals are considered in
order to smoothly vary the shape from octahedra to cubes via spheres, while
preserving cubic symmetry. Spectra are calculated and discussed taking into
account the irreducible representation of the involved vibration modes. A
strong increase in the inelastically scattered light intensity is observed for
small variations of the shape around the sphere. This increase is related to
variations of the electric field inside the nanocrystals, which are very small
for small nanospheres but increase quickly for non-spherical nanocrystals. This
strong dependence with shape must be taken into account when interpreting
experimental spectra acquired from inhomogeneous ensembles of nanocrystals
whose shape dispersion are usually neglected. The overall changes in the
spectra when varying the shape of the nanocrystals provide additional insight
into previously published results. Preliminary calculations for chiral shapes
further show a significant difference between spectra obtained with right or
left circularly polarized light.",http://arxiv.org/abs/2501.12692v1
"Achronal localization and representation of the causal logic from
  conserved current, application to massive scalar boson",2025-01-22T08:15:57Z,"Domenico P. L. Castrigiano, Carmine De Rosa, Valter Moretti","Covariant achronal localizations are gained out of covariant conserved
currents computing their flux passing through achronal surfaces. This general
method applies to the probability density currents with causal kernel regarding
the massive scalar boson. Due to the one-to-one correspondence between
(covariant) achronal localizations and (covariant) representations of the
causal logic thus, apparently for the first time, a covariant representation of
the causal logic for an elementary relativistic quantum mechanical system has
been achieved. Similarly one derives the covariant family of representations of
the causal logic related to the stress energy tensor of the massive scalar
boson. While reaching this result the divergence theorem is proven for open
sets with almost Lipschitz boundary.",http://arxiv.org/abs/2501.12699v3
TimeDepFrail: Time-Dependent Shared Frailty Cox Models in R,2025-01-22T08:47:37Z,"Alessandra Ragni, Giulia Romani, Chiara Masci","This paper introduces TimeDepFrail, an R package designed to implement
time-varying shared frailty models by extending the traditional shared frailty
Cox model to allow the frailty term to evolve across time intervals. These
models are particularly suited for survival analysis in clustered data where
unobserved heterogeneity changes over time, providing greater flexibility in
modeling time-to-event data.
  The package builds on the piecewise gamma frailty model originally proposed
by Paik (1994) and refined by Wintrebert et al. (2004). Our key contributions
include the integration of posterior frailty estimation, a reduction in
computational complexity, the definition of a prediction framework and the
efficient implementation of these models within an R package.
  As a practical application, we use TimeDepFrail to analyze dropout rates
within a university, where high dropout rates are a known issue. By allowing
frailty to vary over time, the package uncovers new insights into the
unobserved factors influencing dropout.
  TimeDepFrail simplifies access to advanced time-varying frailty models,
providing a practical and scalable alternative to more computationally
demanding methods, making it highly applicable for large-scale datasets.",http://arxiv.org/abs/2501.12718v1
"Anomalous Lattice Effect Originated Metal-Insulator Transition in
  FeSe$_x$",2025-01-22T08:53:57Z,"Shubham Purwar, Shinjini Paul, Kritika Vijay, R. Venkatesh, Soma Banik, P. Mahadevan, S. Thirupathaiah","We present a comprehensive investigation of the structural, electrical
transport, and magnetic properties of FeSe$_{\it{x}}$ ($\it{x}$ = 1.14, 1.18,
1.23, 1.28, and 1.32) to unravel the mechanism of the metal-insulator
transition observed in these systems. For this, we systematically evaluated the
structural parameters of FeSe$_{\it{x}}$ as a function of Se concentration and
temperature. We observe increased lattice constants and cell volume with
increased Se concentration. On the other hand, the temperature-dependent XRD
studies suggest unusual lattice change around the metal-insulator (MI)
transition temperature of the respective compositions. This remarkable
observation suggests that the anomalous lattice effect originates the MI
transition in these systems. Additionally, our density of states (DOS)
calculations on FeSe$_{1.14}$ qualitatively explain the MI transition, as the
low-temperature (50 K) structure DOS suggests a metallic nature and the
high-temperature (300 K) structure DOS shows a gap near the Fermi level.",http://arxiv.org/abs/2501.12724v2
LLMs as Repositories of Factual Knowledge: Limitations and Solutions,2025-01-22T10:16:53Z,"Seyed Mahed Mousavi, Simone Alghisi, Giuseppe Riccardi","LLMs' sources of knowledge are data snapshots containing factual information
about entities collected at different timestamps and from different media types
(e.g. wikis, social media, etc.). Such unstructured knowledge is subject to
change due to updates through time from past to present. Equally important are
the inconsistencies and inaccuracies occurring in different information
sources. Consequently, the model's knowledge about an entity may be perturbed
while training over the sequence of snapshots or at inference time, resulting
in inconsistent and inaccurate model performance. In this work, we study the
appropriateness of Large Language Models (LLMs) as repositories of factual
knowledge. We consider twenty-four state-of-the-art LLMs that are either
closed-, partially (weights), or fully (weight and training data) open-source.
We evaluate their reliability in responding to time-sensitive factual questions
in terms of accuracy and consistency when prompts are perturbed. We further
evaluate the effectiveness of state-of-the-art methods to improve LLMs'
accuracy and consistency. We then propose ""ENtity-Aware Fine-tuning"" (ENAF), a
soft neurosymbolic approach aimed at providing a structured representation of
entities during fine-tuning to improve the model's performance.",http://arxiv.org/abs/2501.12774v1
"Kink dynamics for the Yang-Mills field in an extremal
  Reissner-Nordström black hole",2025-01-22T10:49:06Z,"Ignacio Acevedo, Claudio Muñoz","Considered in this work is the Yang-Mills field in an extremal
Reissner-Nordstr\""om black hole, a physically motivated mathematical model
introduced by Bizo\'n and Kahl. The kink is a fundamental, strongly unstable
stationary solution in this non-perturbative, variable coefficients model, with
a polynomial tail and no explicit form. In this paper, we introduce and extend
several virial techniques, adapt them to the inhomogeneous medium setting, and
construct a finite codimensional manifold of the energy space where the kink is
asymptotically stable. In particular, we handle, using virial techniques, the
emergence of a weak threshold resonance in the description of the stable
manifold.",http://arxiv.org/abs/2501.12790v2
"Exploring the heterogeneous impacts of Indonesia's conditional cash
  transfer scheme (PKH) on maternal health care utilisation using instrumental
  causal forests",2025-01-22T11:21:05Z,"Vishalie Shah, Julia Hatamyar, Taufik Hidayat, Noemi Kreif","This paper uses instrumental causal forests, a novel machine learning method,
to explore the treatment effect heterogeneity of Indonesia's conditional cash
transfer scheme on maternal health care utilisation. Using randomised programme
assignment as an instrument for enrollment in the scheme, we estimate
conditional local average treatment effects for four key outcomes: good
assisted delivery, delivery in a health care facility, pre-natal visits, and
post-natal visits. We find significant treatment effect heterogeneity by
supply-side characteristics, even though supply-side readiness was taken into
account during programme development. Mothers in areas with more doctors,
nurses, and delivery assistants were more likely to benefit from the programme,
in terms of increased rates of good assisted delivery outcome. We also find
large differences in benefits according to indicators of household poverty and
survey wave, reflecting the possible impact of changes in programme design in
its later years. The impact on post-natal visits in 2013 displayed the largest
heterogeneity among all outcomes, with some women less likely to attend
post-natal check ups after receiving the cash transfer in the long term.",http://arxiv.org/abs/2501.12803v1
"Probing dynamics of time-varying media: Beyond abrupt temporal
  interfaces",2025-01-22T14:18:49Z,"Ayan Nussupbekov, Juan-Feng Zhu, Yuriy Akimov, Ping Bai, Ching Eng Png, Francisco J. Garcia-Vidal, Lin Wu","This work investigates the effects of time-varying media, where optical
properties change over time, on electromagnetic wave propagation, focusing on
plane waves and free-electron evanescent waves. We introduce a switching
parameter, $\tau$, to model ultrafast switching in the femtosecond to
nanosecond range. For plane-wave incidence at angular frequency $\omega_0$, we
derive a generalized expression for the backward-to-forward flux ratio as a
function of $\omega_0$ and $\tau$, aligning with recent experimental data and
providing a unified interpretation framework. For free-electron incidence, we
observe intensity saturation in temporal transition radiation at
$I_{\textrm{max}}$ for $\tau \leq \tau_{\textrm{0}}$, with both
$I_{\textrm{max}}$ and $\tau_{\textrm{0}}$ depending on electron speed. These
results highlight the importance of precise $\tau$ control in experiments to
probe time-varying media effectively.",http://arxiv.org/abs/2501.12899v1
Development of the Critical Reflection and Agency in Computing Index,2025-01-22T18:13:05Z,"Aadarsh Padiyath, Mark Guzdial, Barbara Ericson","As computing's societal impact grows, so does the need for computing students
to recognize and address the ethical and sociotechnical implications of their
work. While there are efforts to integrate ethics into computing curricula, we
lack a standardized tool to measure those efforts, specifically, students'
attitudes towards ethical reflection and their ability to effect change. This
paper introduces the novel framework of Critically Conscious Computing and
reports on the development and content validation of the Critical Reflection
and Agency in Computing Index, a novel instrument designed to assess
undergraduate computing students' attitudes towards practicing critically
conscious computing. The resulting index is a theoretically grounded,
expert-reviewed tool to support research and practice in computing ethics
education. This enables researchers and educators to gain insights into
students' perspectives, inform the design of targeted ethics interventions, and
measure the effectiveness of computing ethics education initiatives.",http://arxiv.org/abs/2501.13060v1
A Non-linear Massive Gravity Theory of Geometric Origin,2025-01-22T18:40:02Z,"Thibault Damour, Tamanna Jain","We study the number of propagating degrees of freedom, at non-linear order,
in torsion gravity theories, a class of modified theories of gravity that
include a propagating torsion in addition to the metric. We focus on a
three-parameter subfamily of theories (``torsion bigravity"") that contains, at
linear order, only two physical excitations: a massless spin-2 one (with two
degrees of freedom) and a massive spin-2 one (with five degrees of freedom). We
study the dynamics of the massive spin-2 field in the limit where the torsion
field decouples from the metric. The number of degrees of freedom of the
torsion field is found to {\it change, at non-linear order, from five to nine}.",http://arxiv.org/abs/2501.13077v1
"Two decades of optical variability of Small Magellanic Cloud high-mass
  X-ray binaries",2025-01-22T19:00:00Z,"Helena Treiber, Georgios Vasilopoulos, Charles Bailyn, Frank Haberl, Andrzej Udalski","We present an analysis of the long-term optical/IR behavior of 111 high-mass
X-ray binaries (HMXBs) in the Small Magellanic Cloud based on data from the
OGLE collaboration. Most systems exhibit variability on a range of time scales.
This variability regulates the mass transfer to the compact object, while the
compact object can, in turn, affect the donor star's behavior. To better
understand this complex interaction and the resulting X-ray properties in these
systems, we define a new taxonomy for the observed super-orbital variability.
This taxonomy connects to the color changes, orbital periods, and X-ray
behavior of the sources. In most cases, these properties can be explained by
differences between the flux of the disk around the Be star and the flux from
the star itself. We also refine and present new potential orbital periods and
sub-orbital variability in the sources.",http://arxiv.org/abs/2501.13147v1
Localization of Dirac modes in a finite temperature SU(2) Higgs model,2025-01-22T19:12:05Z,"György Baranka, Matteo Giordano","Low-lying Dirac modes become localized at the finite-temperature transition
in QCD and other gauge theories, indicating a strong connection between
localization and deconfinement. This phenomenon can be understood through the
""sea/islands"" picture: in the deconfined phase, modes become trapped on
""islands"" of Polyakov loop fluctuations within a ""sea"" of ordered Polyakov
loops. To test the universality of the ""sea/islands"" mechanism, we investigate
whether changes in the localization properties of low modes occur across other
thermal transitions where the Polyakov loop becomes ordered, beyond the usual
deconfinement transition. The fixed-length SU(2)-Higgs model is appropriate for
this study. After mapping out the phase diagram, we find that low Dirac modes
become localized in the deconfined and Higgs phases, where the Polyakov loop is
ordered. However, localization is absent in the confined phase. These findings
confirm the ""sea/islands"" picture of localization.",http://arxiv.org/abs/2501.13177v1
"Using Principal Component Analysis to Distinguish Different Dynamic
  Phases in Superconducting Vortex Matter",2025-01-22T23:17:21Z,"C. J. O. Reichhardt, D. McDermott, C. Reichhardt","Vortices in type-II superconductors driven over random disorder are known to
exhibit a remarkable variety of distinct nonequilibrium dynamical phases that
arise due to the competition between vortex-vortex interactions, the quenched
disorder, and the drive. These include pinned states, elastic flows, plastic or
disordered flows, and dynamically reordered moving crystal or moving smectic
states. The plastic flow phases can be particularly difficult to characterize
since the flows are strongly disordered. Here we perform principal component
analysis (PCA) on the positions and velocities of vortex matter moving over
random disorder for different disorder strengths and drives. We find that PCA
can distinguish the known dynamic phases as well as or better than previous
measures based on transport signatures or topological defect densities. In
addition, PCA recognizes distinct plastic flow regimes, a slowly changing
channel flow and a moving amorphous fluid flow, that do not produce distinct
signatures in the standard measurements. Our results suggest that this position
and velocity based PCA approach could be used to characterize dynamic phases in
a broader class of systems that exhibit depinning and nonequilibrium phase
transitions.",http://arxiv.org/abs/2501.13269v1
Gradient-Free Adversarial Purification with Diffusion Models,2025-01-23T02:34:14Z,"Xuelong Dai, Dong Wang, Duan Mingxing, Bin Xiao","Adversarial training and adversarial purification are two effective and
practical defense methods to enhance a model's robustness against adversarial
attacks. However, adversarial training necessitates additional training, while
adversarial purification suffers from low time efficiency. More critically,
current defenses are designed under the perturbation-based adversarial threat
model, which is ineffective against the recently proposed unrestricted
adversarial attacks. In this paper, we propose an effective and efficient
adversarial defense method that counters both perturbation-based and
unrestricted adversarial attacks. Our defense is inspired by the observation
that adversarial attacks are typically located near the decision boundary and
are sensitive to pixel changes. To address this, we introduce adversarial
anti-aliasing to mitigate adversarial modifications. Additionally, we propose
adversarial super-resolution, which leverages prior knowledge from clean
datasets to benignly recover images. These approaches do not require additional
training and are computationally efficient without calculating gradients.
Extensive experiments against both perturbation-based and unrestricted
adversarial attacks demonstrate that our defense method outperforms
state-of-the-art adversarial purification methods.",http://arxiv.org/abs/2501.13336v1
"Load and Renewable Energy Forecasting Using Deep Learning for Grid
  Stability",2025-01-23T06:33:33Z,Kamal Sarkar,"As the energy landscape changes quickly, grid operators face several
challenges, especially when integrating renewable energy sources with the grid.
The most important challenge is to balance supply and demand because the solar
and wind energy are highly unpredictable. When dealing with such uncertainty,
trustworthy short-term load and renewable energy forecasting can help stabilize
the grid, maximize energy storage, and guarantee the effective use of renewable
resources. Physical models and statistical techniques were the previous
approaches employed for this kind of forecasting tasks. In forecasting
renewable energy, machine learning and deep learning techniques have recently
demonstrated encouraging results. More specifically, the deep learning
techniques like CNN and LSTM and the conventional machine learning techniques
like regression that are mostly utilized for load and renewable energy
forecasting tasks. In this article, we will focus mainly on CNN and LSTM-based
forecasting methods.",http://arxiv.org/abs/2501.13412v1
"Wasserstein-regularized Conformal Prediction under General Distribution
  Shift",2025-01-23T07:29:44Z,"Rui Xu, Chao Chen, Yue Sun, Parvathinathan Venkitasubramaniam, Sihong Xie","Conformal prediction yields a prediction set with guaranteed $1-\alpha$
coverage of the true target under the i.i.d. assumption, which may not hold and
lead to a gap between $1-\alpha$ and the actual coverage. Prior studies bound
the gap using total variation distance, which cannot identify the gap changes
under distribution shift at a given $\alpha$. Besides, existing methods are
mostly limited to covariate shift,while general joint distribution shifts are
more common in practice but less researched.In response, we first propose a
Wasserstein distance-based upper bound of the coverage gap and analyze the
bound using probability measure pushforwards between the shifted joint data and
conformal score distributions, enabling a separation of the effect of covariate
and concept shifts over the coverage gap. We exploit the separation to design
an algorithm based on importance weighting and regularized representation
learning (WR-CP) to reduce the Wasserstein bound with a finite-sample error
bound.WR-CP achieves a controllable balance between conformal prediction
accuracy and efficiency. Experiments on six datasets prove that WR-CP can
reduce coverage gaps to $3.1\%$ across different confidence levels and outputs
prediction sets 38$\%$ smaller than the worst-case approach on average.",http://arxiv.org/abs/2501.13430v1
Deep Multi-modal Neural Receiver for 6G Vehicular Communication,2025-01-23T08:26:45Z,"Osama Saleem, Mohammed Alfaqawi, Pierre Merdrignac, Abdelaziz Bensrhair, Soheyb Ribouh","Deep Learning (DL) based neural receiver models are used to jointly optimize
PHY of baseline receiver for cellular vehicle to everything (C-V2X) system in
next generation (6G) communication, however, there has been no exploration of
how varying training parameters affect the model's efficiency. Additionally, a
comprehensive evaluation of its performance on multi-modal data remains largely
unexplored. To address this, we propose a neural receiver designed to optimize
Bit Error Rate (BER) for vehicle to network (V2N) uplink scenario in 6G
network. We train multiple neural receivers by changing its trainable
parameters and use the best fit model as proposition for large scale
deployment. Our proposed neural receiver gets signal in frequency domain at the
base station (BS) as input and generates optimal log likelihood ratio (LLR) at
the output. It estimates the channel based on the received signal, equalizes
and demodulates the higher order modulated signal. Later, to evaluate
multi-modality of the proposed model, we test it across diverse V2X data flows
(e.g., image, video, gps, lidar cloud points and radar detection signal).
Results from simulation clearly indicates that our proposed multi-modal neural
receiver outperforms state-of-the-art receiver architectures by achieving high
performance at low Signal to Noise Ratio (SNR).",http://arxiv.org/abs/2501.13464v1
"GCAD: Anomaly Detection in Multivariate Time Series from the Perspective
  of Granger Causality",2025-01-23T09:15:59Z,"Zehao Liu, Mengzhou Gao, Pengfei Jiao","Multivariate time series anomaly detection has numerous real-world
applications and is being extensively studied. Modeling pairwise correlations
between variables is crucial. Existing methods employ learnable graph
structures and graph neural networks to explicitly model the spatial
dependencies between variables. However, these methods are primarily based on
prediction or reconstruction tasks, which can only learn similarity
relationships between sequence embeddings and lack interpretability in how
graph structures affect time series evolution. In this paper, we designed a
framework that models spatial dependencies using interpretable causal
relationships and detects anomalies through changes in causal patterns.
Specifically, we propose a method to dynamically discover Granger causality
using gradients in nonlinear deep predictors and employ a simple sparsification
strategy to obtain a Granger causality graph, detecting anomalies from a causal
perspective. Experiments on real-world datasets demonstrate that the proposed
model achieves more accurate anomaly detection compared to baseline methods.",http://arxiv.org/abs/2501.13493v1
"Medium Temperature Phase Change Materials Thermal Characterization by
  the T-History Method and Differential Scanning Calorimetry",2025-01-23T09:28:02Z,"D. Gaona, E. Urresta, J. Martinez, G. Guerron","This paper presents a thermal characterization of salt mixtures applying the
T-History Method and the Differential Scanning Calorimetry DSC techniques. By
using water as a standard substance, the original T-History method was
developed to analyze materials with melting points under 100 Celsius. This is
the first research that proposes to replace water by glycerin to characterize
medium melting temperature PCMs from 140 to 220 Celsius. Moreover, the DSC
technique was used to validate and compare the results obtained with the
T-history method for each mixture. For instance, the system compound of 40
KNO$_3$ to 60 NaNO$_3$ was studied, and the enthalpy of fusion determined by
THM and DSC differs by 2.1% between each method. The results given by the two
methods for all mixtures showed that both techniques are complementary and
present satisfactory agreement with the specialized literature.",http://arxiv.org/abs/2501.13502v1
Towards a Theory of AI Personhood,2025-01-23T10:31:26Z,Francis Rhys Ward,"I am a person and so are you. Philosophically we sometimes grant personhood
to non-human animals, and entities such as sovereign states or corporations can
legally be considered persons. But when, if ever, should we ascribe personhood
to AI systems? In this paper, we outline necessary conditions for AI
personhood, focusing on agency, theory-of-mind, and self-awareness. We discuss
evidence from the machine learning literature regarding the extent to which
contemporary AI systems, such as language models, satisfy these conditions,
finding the evidence surprisingly inconclusive.
  If AI systems can be considered persons, then typical framings of AI
alignment may be incomplete. Whereas agency has been discussed at length in the
literature, other aspects of personhood have been relatively neglected. AI
agents are often assumed to pursue fixed goals, but AI persons may be
self-aware enough to reflect on their aims, values, and positions in the world
and thereby induce their goals to change. We highlight open research directions
to advance the understanding of AI personhood and its relevance to alignment.
Finally, we reflect on the ethical considerations surrounding the treatment of
AI systems. If AI systems are persons, then seeking control and alignment may
be ethically untenable.",http://arxiv.org/abs/2501.13533v1
Towards Robust Incremental Learning under Ambiguous Supervision,2025-01-23T11:52:53Z,"Rui Wang, Mingxuan Xia, Chang Yao, Lei Feng, Junbo Zhao, Gang Chen, Haobo Wang","Traditional Incremental Learning (IL) targets to handle sequential
fully-supervised learning problems where novel classes emerge from time to
time. However, due to inherent annotation uncertainty and ambiguity, collecting
high-quality annotated data in a dynamic learning system can be extremely
expensive. To mitigate this problem, we propose a novel weakly-supervised
learning paradigm called Incremental Partial Label Learning (IPLL), where the
sequentially arrived data relate to a set of candidate labels rather than the
ground truth. Technically, we develop the Prototype-Guided Disambiguation and
Replay Algorithm (PGDR) which leverages the class prototypes as a proxy to
mitigate two intertwined challenges in IPLL, i.e., label ambiguity and
catastrophic forgetting. To handle the former, PGDR encapsulates a
momentum-based pseudo-labeling algorithm along with prototype-guided
initialization, resulting in a balanced perception of classes. To alleviate
forgetting, we develop a memory replay technique that collects
well-disambiguated samples while maintaining representativeness and diversity.
By jointly distilling knowledge from curated memory data, our framework
exhibits a great disambiguation ability for samples of new tasks and achieves
less forgetting of knowledge. Extensive experiments demonstrate that PGDR
achieves superior",http://arxiv.org/abs/2501.13584v3
Evolvable Soma Theory of Ageing: Insights from Computer Simulations,2025-01-23T13:37:09Z,"Alessandro Fontana, Marios Kyriazis","Biological evolution continuously refines the design of species, resulting in
highly optimised organisms over hundreds of millennia. Intuitively, we expect
that random changes-evolution's primary mechanism-are more likely to be harmful
than beneficial, leading to widespread detrimental effects in evolving species.
The Evolvable Soma Theory of Ageing (ESTA) suggests that ageing is the
cumulative result of these harmful effects, which predominantly cause bodily
damage, while a few may lead to beneficial adaptations that evolution can
exploit. While the disposable soma theory views ageing as a consequence of
limited evolutionary pressure, ESTA posits that ageing is essentially evolution
in action. In this study, we gather evidence supporting this theory through
computer simulations. We conduct experiments using a platform where genes are
linked to onset values that determine when they are expressed. Three scenarios
are tested: one with single-point fitness evaluation, constant mutation rate
and fixed gene onsets; one with single-point fitness evaluation,
onset-dependent mutation rate and fixed gene onsets; and one with spread
fitness evaluation, onset-dependent mutation rate and evolvable gene onsets.
The last scenario, which embodies the evolvable soma hypothesis, demonstrates
superior performance in both algorithmic efficiency and biological plausibility
compared to the others.",http://arxiv.org/abs/2501.13657v1
Certified Robustness Under Bounded Levenshtein Distance,2025-01-23T13:58:53Z,"Elias Abad Rocamora, Grigorios G. Chrysos, Volkan Cevher","Text classifiers suffer from small perturbations, that if chosen
adversarially, can dramatically change the output of the model. Verification
methods can provide robustness certificates against such adversarial
perturbations, by computing a sound lower bound on the robust accuracy.
Nevertheless, existing verification methods incur in prohibitive costs and
cannot practically handle Levenshtein distance constraints. We propose the
first method for computing the Lipschitz constant of convolutional classifiers
with respect to the Levenshtein distance. We use these Lipschitz constant
estimates for training 1-Lipschitz classifiers. This enables computing the
certified radius of a classifier in a single forward pass. Our method, LipsLev,
is able to obtain $38.80$% and $13.93$% verified accuracy at distance $1$ and
$2$ respectively in the AG-News dataset, while being $4$ orders of magnitude
faster than existing approaches. We believe our work can open the door to more
efficient verification in the text domain.",http://arxiv.org/abs/2501.13676v2
Training-Free Consistency Pipeline for Fashion Repose,2025-01-23T14:17:01Z,"Potito Aghilar, Vito Walter Anelli, Michelantonio Trizio, Tommaso Di Noia","Recent advancements in diffusion models have significantly broadened the
possibilities for editing images of real-world objects. However, performing
non-rigid transformations, such as changing the pose of objects or image-based
conditioning, remains challenging. Maintaining object identity during these
edits is difficult, and current methods often fall short of the precision
needed for industrial applications, where consistency is critical.
Additionally, fine-tuning diffusion models requires custom training data, which
is not always accessible in real-world scenarios. This work introduces
FashionRepose, a training-free pipeline for non-rigid pose editing specifically
designed for the fashion industry. The approach integrates off-the-shelf models
to adjust poses of long-sleeve garments, maintaining identity and branding
attributes. FashionRepose uses a zero-shot approach to perform these edits in
near real-time, eliminating the need for specialized training. consistent image
editing. The solution holds potential for applications in the fashion industry
and other fields demanding identity preservation in image editing.",http://arxiv.org/abs/2501.13692v1
Naked and truly naked rotating black holes,2025-01-23T14:49:03Z,"H. V. Ovcharenko, O. B. Zaslavskii","Previously, it was noticed that in some space-times with Killing horizons
some curvature components, responsible for tidal forces, small or even zero in
the static frame, become enhanced from the viewpoint of a falling observer.
This leads to the notion of so-called naked black holes. If some components in
the frame attached to a free-falling observer formally diverge, although scalar
invariants remain finite, such space-times was named ""truly naked black holes""
(in mathematical language, one can speak about non-scalar singularity).
Previous results included static spherically symmetric or distorted static
metrics. In the present work, we generalized them to include rotation in
consideration. We also scrutiny how the algebraic type can change in the
vicinity of the horizon due to local Lorentz boost. Our approach essentially
uses the Newman-Penrose formalism, so we analyze the behavior of Weyl scalar
for different kinds of observers.",http://arxiv.org/abs/2501.13719v1
"Centralized Versus Distributed Routing for Large-Scale Satellite
  Networks",2025-01-23T15:19:09Z,"Rudrapatna Vallabh Ramakanth, Eytan Modiano","An important choice in the design of satellite networks is whether the
routing decisions are made in a distributed manner onboard the satellite, or
centrally on a ground-based controller. We study the tradeoff between
centralized and distributed routing in large-scale satellite networks. In
particular, we consider a centralized routing scheme that has access to global
but delayed network state information and a distributed routing scheme that has
access to local but real-time network state information. For both routing
schemes, we analyze the throughput and delay performance of shortest-path
algorithms in networks with and without buffers onboard the satellites. We show
that distributed routing outperforms centralized routing when the rate of
changes in the network link state is comparable to the inherent propagation and
transmission delays. In particular, we show that in highly dynamic networks
without buffers, the distributed scheme achieves higher throughput than a
centralized scheme. In networks with buffers, the distributed scheme achieves
lower delays with the same throughput.",http://arxiv.org/abs/2501.13744v1
"Unveiling the Power of Noise Priors: Enhancing Diffusion Models for
  Mobile Traffic Prediction",2025-01-23T16:13:08Z,"Zhi Sheng, Yuan Yuan, Jingtao Ding, Yong Li","Accurate prediction of mobile traffic, \textit{i.e.,} network traffic from
cellular base stations, is crucial for optimizing network performance and
supporting urban development. However, the non-stationary nature of mobile
traffic, driven by human activity and environmental changes, leads to both
regular patterns and abrupt variations. Diffusion models excel in capturing
such complex temporal dynamics due to their ability to capture the inherent
uncertainties. Most existing approaches prioritize designing novel denoising
networks but often neglect the critical role of noise itself, potentially
leading to sub-optimal performance. In this paper, we introduce a novel
perspective by emphasizing the role of noise in the denoising process. Our
analysis reveals that noise fundamentally shapes mobile traffic predictions,
exhibiting distinct and consistent patterns. We propose NPDiff, a framework
that decomposes noise into \textit{prior} and \textit{residual} components,
with the \textit{prior} derived from data dynamics, enhancing the model's
ability to capture both regular and abrupt variations. NPDiff can seamlessly
integrate with various diffusion-based prediction models, delivering
predictions that are effective, efficient, and robust. Extensive experiments
demonstrate that it achieves superior performance with an improvement over
30\%, offering a new perspective on leveraging diffusion models in this domain.",http://arxiv.org/abs/2501.13794v1
Regularizing random points by deleting a few,2025-01-23T16:35:35Z,"Dmitriy Bilyk, Stefan Steinerberger","It is well understood that if one is given a set $X \subset [0,1]$ of $n$
independent uniformly distributed random variables, then $$ \sup_{0 \leq x \leq
1} \left| \frac{\# X \cap [0,x]}{\# X} - x \right| \lesssim
\frac{\sqrt{\log{n}}}{ \sqrt{n}} \qquad \mbox{with very high probability.} $$
We show that one can improve the error term by removing a few of the points.
For any $m \leq 0.001n$ there exists a subset $Y \subset X$ obtained by
deleting at most $m$ points, so that the error term drops from $\sim
\sqrt{\log{n}}/\sqrt{n}$ to $ \log{(n)}/m$ with high probability. When $m=cn$
for a small $0 \leq c \leq 0.001$, this achieves the essentially optimal
asymptotic order of discrepancy $\log(n)/n$. The proof is constructive and
works in an online setting (where one is given the points sequentially, one at
a time, and has to decide whether to keep or discard it). A change of variables
shows the same result for any random variables on the real line with absolutely
continuous density.",http://arxiv.org/abs/2501.13813v1
Four-quark operators with $ΔF = 2$ in the GIRS scheme,2025-01-17T11:47:51Z,"M. Constantinou, M. Costa, H. Herodotou, H. Panagopoulos, G. Spanoudes","We calculate the mixing matrices of four-quark operators that change flavor
numbers by two units. Our approach employs two schemes: the coordinate-space
Gauge Invariant Renormalization Scheme (GIRS) and the Modified Minimal
Subtraction scheme. From our perturbative computations, we extract the
conversion factors between these two renormalization schemes at the
next-to-leading order. A significant challenge in the study of four-quark
operators is that they mix among themselves upon renormalization. Additionally,
computations in GIRS at a given order in perturbation theory require Feynman
diagrams with at least one additional loop. The extraction of the conversion
factors involves calculating two-point Green's functions, which include
products of two four-quark operators, and three-point Green's functions, which
involve one four-quark operator and two bilinear operators, with all operators
located at distinct spacetime points. We investigate both parity-conserving and
parity-violating four-quark operators. This calculation is relevant to the
determination of Cabibbo-Kobayashi-Maskawa (CKM) matrix elements from numerical
simulations using the GIRS scheme.",http://arxiv.org/abs/2501.13939v1
Self-Explanation in Social AI Agents,2025-01-19T03:03:15Z,"Rhea Basappa, Mustafa Tekman, Hong Lu, Benjamin Faught, Sandeep Kakar, Ashok K. Goel","Social AI agents interact with members of a community, thereby changing the
behavior of the community. For example, in online learning, an AI social
assistant may connect learners and thereby enhance social interaction. These
social AI assistants too need to explain themselves in order to enhance
transparency and trust with the learners. We present a method of
self-explanation that uses introspection over a self-model of an AI social
assistant. The self-model is captured as a functional model that specifies how
the methods of the agent use knowledge to achieve its tasks. The process of
generating self-explanations uses Chain of Thought to reflect on the self-model
and ChatGPT to provide explanations about its functioning. We evaluate the
self-explanation of the AI social assistant for completeness and correctness.
We also report on its deployment in a live class.",http://arxiv.org/abs/2501.13945v1
Predictive Learning in Energy-based Models with Attractor Structures,2025-01-23T11:04:25Z,"Xingsi Dong, Pengxiang Yuan, Si Wu","Predictive models are highly advanced in understanding the mechanisms of
brain function. Recent advances in machine learning further underscore the
power of prediction for optimal representation in learning. However, there
remains a gap in creating a biologically plausible model that explains how the
neural system achieves prediction. In this paper, we introduce a framework that
employs an energy-based model (EBM) to capture the nuanced processes of
predicting observation after action within the neural system, encompassing
prediction, learning, and inference. We implement the EBM with a hierarchical
structure and integrate a continuous attractor neural network for memory,
constructing a biologically plausible model. In experimental evaluations, our
model demonstrates efficacy across diverse scenarios. The range of actions
includes eye movement, motion in environments, head turning, and static
observation while the environment changes. Our model not only makes accurate
predictions for environments it was trained on, but also provides reasonable
predictions for unseen environments, matching the performances of machine
learning methods in multiple tasks. We hope that this study contributes to a
deep understanding of how the neural system performs prediction.",http://arxiv.org/abs/2501.13997v1
Grover-Sagnac interferometer,2025-01-23T19:32:13Z,"Christopher R. Schwarze, Anthony D. Manni, David S. Simon, Abdoulaye Ndao, Alexander V. Sergienko","We demonstrate a nontraditional design of the Sagnac interferometer by
replacing the commonly used beam splitter with a linear-optical Grover
multiport. This substitution creates a pole at the origin of the device
parameter space with an associated resonance in the output intensity. The
structure of this resonance is dictated only by the non-reciprocal portion of
the phase acquired in the Sagnac loop. This property directly results from
adopting the more symmetric and higher-dimensional central scattering coin, and
allows for a different approach to registering and detecting the non-reciprocal
Sagnac phase. This parameter may be extracted from the width of a peak or dip
in the interferogram instead of tracing small changes in power as in
traditional Sagnac interferometry. We discuss how losses affect the system and
potential metrological applications.",http://arxiv.org/abs/2501.14049v1
Life in the Slow Lane: A Search for Long Term Variability in ASAS-SN,2025-01-23T19:49:36Z,"Sydney Petz, Christopher S. Kochanek","We search a sample of 9,361,613 isolated sources with 13<g<14.5 mag for
slowly varying sources. We select sources with brightness changes larger than ~
0.03 mag/year over 10 years, removing false positives due to, for example,
nearby bright stars or high proper motions. After a thorough visual inspection,
we find 782 slowly varying systems. Of these systems, 433 are identified as
variables for the first time and 349 are previously classified as variables.
Previously classified systems were mostly identified as semi-regular variables
(SR), slow irregular variables (L), spotted stars (ROT), or unknown (MISC or
VAR), as long time scale variability does not fit into a standard class. The
stellar sources are scattered across the CMD and can be placed into 5 groups
that exhibit distinct behaviors. The largest groups are very red subgiants and
lower main sequence stars. There are also a small number of AGN. There are 551
candidates (~70 percent) that also show shorter time scale periodic
variability, mostly with periods longer than 10 days. The variability of 191 of
these candidates may be related to dust.",http://arxiv.org/abs/2501.14058v1
"Single-Letter Characterization of the Mismatched Distortion-Rate
  Function",2025-01-23T20:39:37Z,"Maël Le Treust, Tristan Tomala","The mismatched distortion-rate problem has remained open since its
formulation by Lapidoth in 1997. In this paper, we characterize the mismatched
distortion-rate function. Our single-letter solution highlights the adequate
conditional distributions for the encoder and the decoder. The achievability
result relies on a time-sharing argument that allows to convexify the upper
bound of Lapidoth. We show that it is sufficient to consider two regimes, one
with a large rate and another one with a small rate. Our main contribution is
the converse proof. Suppose that the encoder selects a single-letter
conditional distribution distinct from the one in the solution, we construct an
encoding strategy that leads to the same expected cost for both encoder and
decoder. This ensures that the encoder cannot gain by changing the
single-letter conditional distribution. This argument relies on a careful
identification of the sequence of auxiliary random variables. By building on
Caratheodory's Theorem we show that the cardinality of the auxiliary random
variables is equal to the one of the source alphabet plus three.",http://arxiv.org/abs/2501.14081v1
Selective enhancement of Coulomb interactions in planar Weyl fermions,2025-01-23T23:00:25Z,"Vadym Apalkov, Wenchen Luo, Tapash Chakraborty","We report on our study of the electron interaction effects in topological
two-dimensional (2D) materials placed in a quantizing magnetic field. Taking
our cue from a recent experimental report, we consider a particular case of
bismuthene monolayer with a strong spin-orbit interaction which can be a Weyl
semimetal when placed on a specially tuned substrate. Interestingly, we observe
that in some Landau levels of this material, the interaction effects are
strongly enhanced compared to those for a conventional 2D system. Such an
enhancement of electron-electron interactions in these materials is largely due
to an anisotropy present in the materials. Additionally, the interaction
effects can be tuned by changing the coupling to the substrate and the
strongest inter-electron interactions are observed when the system is a Weyl
semimental. The observed enhancement of the interaction effects can therefore
be an important signature of the 2D Weyl fermions.",http://arxiv.org/abs/2501.14128v2
Optimal Preconditioning for Online Quadratic Cone Programming,2025-01-24T02:54:06Z,"Abhinav G. Kamath, Purnanand Elango, Behçet Açıkmeşe","First-order conic optimization solvers are sensitive to problem conditioning
and typically perform poorly in the face of ill-conditioned problem data. To
mitigate this, we propose an approach to preconditioning for a class of
quadratic cone programs (QCPs), i.e., conic optimization problems with a
quadratic objective function, wherein the objective function is strongly convex
and possesses a certain structure. This approach lends itself to
factorization-free, customizable, first-order conic optimization for online
applications wherein the solver is called repeatedly to solve problems of the
same size/structure, but with changing problem data. One of the steps in the
proposed preconditioning procedure is to scale the objective function: in
addition to deriving an analytical expression for the optimal objective
function scaling factor, we establish the relationship between the objective
function scaling factor and the primal-dual step-size ratio for a first-order
method, the proportional-integral projected gradient method (PIPG), which
applies to the general class of QCPs, including quadratic programs (QPs),
second-order cone programs (SOCPs), and semidefinite programs (SDPs). We
demonstrate the efficacy of our approach on a numerical nonconvex trajectory
optimization example, using sequential conic optimization (SeCO).",http://arxiv.org/abs/2501.14191v1
"PuzzleGPT: Emulating Human Puzzle-Solving Ability for Time and Location
  Prediction",2025-01-24T03:28:37Z,"Hammad Ayyubi, Xuande Feng, Junzhang Liu, Xudong Lin, Zhecan Wang, Shih-Fu Chang","The task of predicting time and location from images is challenging and
requires complex human-like puzzle-solving ability over different clues. In
this work, we formalize this ability into core skills and implement them using
different modules in an expert pipeline called PuzzleGPT. PuzzleGPT consists of
a perceiver to identify visual clues, a reasoner to deduce prediction
candidates, a combiner to combinatorially combine information from different
clues, a web retriever to get external knowledge if the task can't be solved
locally, and a noise filter for robustness. This results in a zero-shot,
interpretable, and robust approach that records state-of-the-art performance on
two datasets -- TARA and WikiTilo. PuzzleGPT outperforms large VLMs such as
BLIP-2, InstructBLIP, LLaVA, and even GPT-4V, as well as automatically
generated reasoning pipelines like VisProg, by at least 32% and 38%,
respectively. It even rivals or surpasses finetuned models.",http://arxiv.org/abs/2501.14210v1
"When GNNs meet symmetry in ILPs: an orbit-based feature augmentation
  approach",2025-01-24T03:33:33Z,"Qian Chen, Lei Li, Qian Li, Jianghua Wu, Akang Wang, Ruoyu Sun, Xiaodong Luo, Tsung-Hui Chang, Qingjiang Shi","A common characteristic in integer linear programs (ILPs) is symmetry,
allowing variables to be permuted without altering the underlying problem
structure. Recently, GNNs have emerged as a promising approach for solving
ILPs. However, a significant challenge arises when applying GNNs to ILPs with
symmetry: classic GNN architectures struggle to differentiate between symmetric
variables, which limits their predictive accuracy. In this work, we investigate
the properties of permutation equivariance and invariance in GNNs, particularly
in relation to the inherent symmetry of ILP formulations. We reveal that the
interaction between these two factors contributes to the difficulty of
distinguishing between symmetric variables. To address this challenge, we
explore the potential of feature augmentation and propose several guiding
principles for constructing augmented features. Building on these principles,
we develop an orbit-based augmentation scheme that first groups symmetric
variables and then samples augmented features for each group from a discrete
uniform distribution. Empirical results demonstrate that our proposed approach
significantly enhances both training efficiency and predictive performance.",http://arxiv.org/abs/2501.14211v1
"Active Learning for Continual Learning: Keeping the Past Alive in the
  Present",2025-01-24T06:46:58Z,"Jaehyun Park, Dongmin Park, Jae-Gil Lee","Continual learning (CL) enables deep neural networks to adapt to
ever-changing data distributions. In practice, there may be scenarios where
annotation is costly, leading to active continual learning (ACL), which
performs active learning (AL) for the CL scenarios when reducing the labeling
cost by selecting the most informative subset is preferable. However,
conventional AL strategies are not suitable for ACL, as they focus solely on
learning the new knowledge, leading to catastrophic forgetting of previously
learned tasks. Therefore, ACL requires a new AL strategy that can balance the
prevention of catastrophic forgetting and the ability to quickly learn new
tasks. In this paper, we propose AccuACL, Accumulated informativeness-based
Active Continual Learning, by the novel use of the Fisher information matrix as
a criterion for sample selection, derived from a theoretical analysis of the
Fisher-optimality preservation properties within the framework of ACL, while
also addressing the scalability issue of Fisher information-based AL. Extensive
experiments demonstrate that AccuACL significantly outperforms AL baselines
across various CL algorithms, increasing the average accuracy and forgetting by
23.8% and 17.0%, respectively, in average.",http://arxiv.org/abs/2501.14278v1
"Robustified Time-optimal Point-to-point Motion Planning and Control
  under Uncertainty",2025-01-24T14:29:58Z,"Shuhao Zhang, Jan Swevers","This paper proposes a novel approach to formulate time-optimal point-to-point
motion planning and control under uncertainty. The approach defines a
robustified two-stage Optimal Control Problem (OCP), in which stage 1, with a
fixed time grid, is seamlessly stitched with stage 2, which features a variable
time grid. Stage 1 optimizes not only the nominal trajectory, but also feedback
gains and corresponding state covariances, which robustify constraints in both
stages. The outcome is a minimized uncertainty in stage 1 and a minimized total
motion time for stage 2, both contributing to the time optimality and safety of
the total motion. A timely replanning strategy is employed to handle changes in
constraints and maintain feasibility, while a tailored iterative algorithm is
proposed for efficient, real-time OCP execution.",http://arxiv.org/abs/2501.14526v1
"Wearable slot antenna at 2.45 GHz for off-body radiation: analysis of
  efficiency, frequency shift and body absorption",2025-01-24T14:53:26Z,"Marta Fernandez, Hugo G. Espinosa, David V. Thiel, Amaia Arrinda","The interaction of body worn antennas with the human body causes a
significant decrease in the antenna efficiency and a shift in the resonant
frequency. A resonant slot in a small conductive box placed on the body has
been shown to reduce these effects. The specific absorption rate (SAR) is less
than international health standards for most wearable antennas due to the small
transmitter power. This paper reports the linear relationship between the power
absorbed by biological tissues at different locations on the body, and the
radiation efficiency based on numerical modeling (r = 0.99). While the -10 dB
bandwidth of the antenna remains constant and equal to 12.5%, the maximum
frequency shift occurs when the antenna is close to the elbow (6.61%) and on
the thigh (5.86%). The smallest change was found on the torso (4.21%).
Participants with body-mass index (BMI) between 17 and 29 kg/m2 took part in
experimental measurements, where the maximum frequency shift was 2.51%.
Measurements show better agreement with simulations on the upper arm. These
experimental results demonstrate that the BMI for each individual has little
effect on the performance of the antenna.",http://arxiv.org/abs/2501.14549v1
Scanning gate microscopy detection of Majorana bound states,2025-01-24T15:07:34Z,"S. Maji, M. P. Nowak","We theoretically study scanning gate microscopy of a
superconductor-proximitized semiconducting wire focusing on the possibility of
detection of Majorana bound states. We exploit the possibility to create local
potential perturbation by the scanning gate tip which allows controllable
modification of the spatial distribution of the Majorana modes, which is
translated into changes in their energy structure. When the tip scans across
the system, it effectively divides the wire into two parts with controllable
lengths, in which two pairs of Majorana states are created when the system is
in the topological regime. For strong values of the tip potential the pairs are
decoupled, and the presence of Majorana states can be detected via local
tunneling spectroscopy that resolves the energy splittings resulting from the
Majorana states wave functions overlap. Importantly, as the system is probed
spatially via the tip, this technique can distinguish Majorana bound states
from quasi-Majorana states localized on smooth potential barriers. We
demonstrate that for weaker tip potentials the two neighboring Majorana states
hybridize opening pronounced anticrossings in the energy spectra which are
reflected in local conductance maps and which result in non-zero non-local
conductance features. Finally, we demonstrate the effect of the disorder on the
scanning gate microscopy spectroscopy maps.",http://arxiv.org/abs/2501.14562v1
MatAnyone: Stable Video Matting with Consistent Memory Propagation,2025-01-24T17:56:24Z,"Peiqing Yang, Shangchen Zhou, Jixin Zhao, Qingyi Tao, Chen Change Loy","Auxiliary-free human video matting methods, which rely solely on input
frames, often struggle with complex or ambiguous backgrounds. To address this,
we propose MatAnyone, a robust framework tailored for target-assigned video
matting. Specifically, building on a memory-based paradigm, we introduce a
consistent memory propagation module via region-adaptive memory fusion, which
adaptively integrates memory from the previous frame. This ensures semantic
stability in core regions while preserving fine-grained details along object
boundaries. For robust training, we present a larger, high-quality, and diverse
dataset for video matting. Additionally, we incorporate a novel training
strategy that efficiently leverages large-scale segmentation data, boosting
matting stability. With this new network design, dataset, and training
strategy, MatAnyone delivers robust and accurate video matting results in
diverse real-world scenarios, outperforming existing methods.",http://arxiv.org/abs/2501.14677v1
"Towards Better Understanding Table Instruction Tuning: Decoupling the
  Effects from Data versus Models",2025-01-24T18:50:26Z,"Naihao Deng, Sheng Zhang, Henghui Zhu, Shuaichen Chang, Jiani Zhang, Alexander Hanbo Li, Chung-Wei Hang, Hideo Kobayashi, Yiqun Hu, Patrick Ng","Recent advances in natural language processing have leveraged instruction
tuning to enhance Large Language Models (LLMs) for table-related tasks.
However, previous works train different base models with different training
data, lacking an apples-to-apples comparison across the result table LLMs. To
address this, we fine-tune base models from the Mistral, OLMo, and Phi families
on existing public training datasets. Our replication achieves performance on
par with or surpassing existing table LLMs, establishing new state-of-the-art
performance on Hitab, a table question-answering dataset. More importantly,
through systematic out-of-domain evaluation, we decouple the contributions of
training data and the base model, providing insight into their individual
impacts. In addition, we assess the effects of table-specific instruction
tuning on general-purpose benchmarks, revealing trade-offs between
specialization and generalization.",http://arxiv.org/abs/2501.14717v1
A unified approach for domination and packing problems in graphs,2025-01-08T15:26:13Z,"E. Hinrichsen, G. Nasini, N. Vansteenkiste","In this paper, we introduce new concepts of domination and packing functions
in graphs, which generalize, respectively, the labelled dominating and packing
functions defined by Lee and Chang in 2008, and Hinrichsen et al. in 2019.
These generalized functions offer a unified and simpler framework for
addressing many of the variations of domination and packing concepts in graphs
explored in the literature. Interestingly, their associated optimization
problems turn out to be equivalent, providing insight to explain the observed
coincidences in computational complexity results for graph classes where both
problems, the domination one and its corresponding packing variation, have been
analyzed. This equivalence also allows us to solve some computational
complexity open questions, for some graph classes.
  Furthermore, we prove that the generalized problems remain solvable in
polynomial time for graphs with bounded clique-width and strongly chordal
graphs.",http://arxiv.org/abs/2501.14789v1
Shape Morphing Metamaterials,2025-01-14T18:29:49Z,"Krzysztof K. Dudek, Muamer Kadic, Corentin Coulais, Katia Bertoldi","Mechanical metamaterials leverage geometric design to achieve unconventional
properties, such as high strength at low density, efficient wave guiding, and
complex shape morphing. The ability to control shape changes builds on the
complex relationship between geometry and nonlinear mechanics, and opens new
possibilities for disruptive technologies across diverse fields, including
wearable devices, medical technology, robotics, and beyond. In this review of
shape-morphing metamaterials, we examine the current state of the field and
propose a unified classification system for the mechanisms involved, as well as
the design principles underlying them. Specifically, we explore two main
categories of unit cells-those that exploit structural anisotropy or internal
rotations-and two potential approaches to tessellating these cells: based on
kinematic compatibility or geometric frustration. We conclude by discussing the
available design tools and highlighting emerging challenges in the development
of shape-morphing metamaterials.",http://arxiv.org/abs/2501.14804v1
A VM-HDL Co-Simulation Framework for Systems with PCIe-Connected FPGAs,2025-01-19T22:06:36Z,"Shenghsun Cho, Mrunal Patel, Basavaraj Kaladagi, Han Chen, Tapti Palit, Michael Ferdman, Peter Milder","PCIe-connected FPGAs are gaining popularity as an accelerator technology in
data centers. However, it is challenging to jointly develop and debug host
software and FPGA hardware. Changes to the hardware design require a
time-consuming FPGA synthesis process, and modification to the software,
especially the operating system and device drivers, can frequently cause the
system to hang, without providing enough information for debugging. The
combination of these problems results in long debug iterations and a slow
development process. To overcome these problems, we designed a VM-HDL
co-simulation framework, which is capable of running the same software,
operating system, and hardware designs as the target physical system, while
providing full visibility and significantly shorter debug iterations.",http://arxiv.org/abs/2501.14815v1
Multi-Fidelity Machine Learning Applied to Steady Fluid Flows,2025-01-24T19:00:24Z,"Kazuko W. Fuchi, Eric M. Wolf, David S. Makhija, Christopher R. Schrock, Philip S. Beran","A machine learning method to predict steady external fluid flows using
elliptic input features is introduced. Using data from as few as one
high-fidelity simulation, the proposed method produces models generalizable
under changes to boundary geometry by using solutions to elliptic boundary
value problems over the flow domain as the model input, instead of Cartesian
coordinates of the domain. Training data is generated through pointwise
evaluation of flow features at points selected through a quad-tree adaptive
sampling method to concentrate training points in areas with large field
gradients. Models are trained within a training window around the body, while
predictions are smoothly extended to freestream conditions using a
Partition-of-Unity extension. Predictive capabilities of the machine learning
model are demonstrated in steady-state flow of incompressible fluid around a
cylinder and a Joukowski airfoil. The predicted flow field is used to
warm-start CFD simulations to achieve acceleration in solver convergence.",http://arxiv.org/abs/2501.14870v1
"Atypical vortex lattice and the magnetic penetration depth in
  superconducting Sr$_2$RuO$_4$ deduced by $μ$SR",2025-01-24T19:03:37Z,"M. Yakovlev, Z. Kartsonas, J. E. Sonier","The muon spin rotation ($\mu$SR) technique has been applied to determine the
behavior of the in-plane magnetic penetration depth ($\lambda_{ab}$) in the
vortex state of the unconventional superconductor Sr$_2$RuO$_4$ as a means of
gaining insight into its still unknown superconducting order parameter. A
recent $\mu$SR study of Sr$_2$RuO$_4$ reported a $T$-linear temperature
dependence for $\lambda_{ab}$ at low temperatures that was not identified in an
earlier $\mu$SR study. Here we show that there is no significant difference
between the data in the early and recent $\mu$SR studies and both are
compatible with the limiting low-temperature $\lambda_{ab} \sim T^2$ dependence
expected from measurements of the change in $\lambda_{ab}(T)$ in the Meissner
state by other techniques. However, we argue that at this time there is no
valid theoretical model for reliably determining the absolute value of
$\lambda_{ab}$ in Sr$_2$RuO$_4$ from $\mu$SR measurements. Instead, we identify
the formation of an unusual square vortex lattice that introduces a new
constraint on candidate superconducting order parameters for Sr$_2$RuO$_4$.",http://arxiv.org/abs/2501.14876v1
Cuscuton-like contribution to dark energy evolution,2025-01-24T20:22:55Z,"D. Bazeia, J. D. Dantas, S. Santos da Costa","This work deals with the presence of the cuscuton term in the otherwise
standard dark energy evolution under the usual FLRW background. We disclose a
first-order framework similar to the Hamilton-Jacobi formalism, which helps us
to solve the equations of motion and find analytical solutions. We explore
several possibilities, concentrating mainly on how the cuscuton-like
contribution works to modify cosmic evolution. Some results are of current
interest since they describe scenarios capable of changing the evolution,
adding or excluding possible distinct phases during the Universe's expansion
history. Additionally, we present interesting constraints on the cuscuton-like
contribution for the dark energy evolution using a set of homogeneous
geometrical observational probes. Finally, based on the Akaike Information
Criterion (AIC), we perform a statistical comparison of the cuscuton-like model
with $\Lambda$CDM, and find strong support for our model.",http://arxiv.org/abs/2501.14909v1
"Predictive Modeling and Uncertainty Quantification of Fatigue Life in
  Metal Alloys using Machine Learning",2025-01-25T03:43:19Z,"Jiang Chang, Deekshith Basvoju, Aleksandar Vakanski, Indrajit Charit, Min Xian","Recent advancements in machine learning-based methods have demonstrated great
potential for improved property prediction in material science. However,
reliable estimation of the confidence intervals for the predicted values
remains a challenge, due to the inherent complexities in material modeling.
This study introduces a novel approach for uncertainty quantification in
fatigue life prediction of metal materials based on integrating knowledge from
physics-based fatigue life models and machine learning models. The proposed
approach employs physics-based input features estimated using the Basquin
fatigue model to augment the experimentally collected data of fatigue life.
Furthermore, a physics-informed loss function that enforces boundary
constraints for the estimated fatigue life of considered materials is
introduced for the neural network models. Experimental validation on datasets
comprising collected data from fatigue life tests for Titanium alloys and
Carbon steel alloys demonstrates the effectiveness of the proposed approach.
The synergy between physics-based models and data-driven models enhances the
consistency in predicted values and improves uncertainty interval estimates.",http://arxiv.org/abs/2501.15057v1
"SpatioTemporal Learning for Human Pose Estimation in Sparsely-Labeled
  Videos",2025-01-25T04:43:12Z,"Yingying Jiao, Zhigang Wang, Sifan Wu, Shaojing Fan, Zhenguang Liu, Zhuoyue Xu, Zheqi Wu","Human pose estimation in videos remains a challenge, largely due to the
reliance on extensive manual annotation of large datasets, which is expensive
and labor-intensive. Furthermore, existing approaches often struggle to capture
long-range temporal dependencies and overlook the complementary relationship
between temporal pose heatmaps and visual features. To address these
limitations, we introduce STDPose, a novel framework that enhances human pose
estimation by learning spatiotemporal dynamics in sparsely-labeled videos.
STDPose incorporates two key innovations: 1) A novel Dynamic-Aware Mask to
capture long-range motion context, allowing for a nuanced understanding of pose
changes. 2) A system for encoding and aggregating spatiotemporal
representations and motion dynamics to effectively model spatiotemporal
relationships, improving the accuracy and robustness of pose estimation.
STDPose establishes a new performance benchmark for both video pose propagation
(i.e., propagating pose annotations from labeled frames to unlabeled frames)
and pose estimation tasks, across three large-scale evaluation datasets.
Additionally, utilizing pseudo-labels generated by pose propagation, STDPose
achieves competitive performance with only 26.7% labeled data.",http://arxiv.org/abs/2501.15073v1
"Can Large Language Models Be Trusted as Black-Box Evolutionary
  Optimizers for Combinatorial Problems?",2025-01-25T05:19:19Z,"Jie Zhao, Tao Wen, Kang Hao Cheong","Evolutionary computation excels in complex optimization but demands deep
domain knowledge, restricting its accessibility. Large Language Models (LLMs)
offer a game-changing solution with their extensive knowledge and could
democratize the optimization paradigm. Although LLMs possess significant
capabilities, they may not be universally effective, particularly since
evolutionary optimization encompasses multiple stages. It is therefore
imperative to evaluate the suitability of LLMs as evolutionary optimizer (EVO).
Thus, we establish a series of rigid standards to thoroughly examine the
fidelity of LLM-based EVO output in different stages of evolutionary
optimization and then introduce a robust error-correction mechanism to mitigate
the output uncertainty. Furthermore, we explore a cost-efficient method that
directly operates on entire populations with excellent effectiveness in
contrast to individual-level optimization. Through extensive experiments, we
rigorously validate the performance of LLMs as operators targeted for
combinatorial problems. Our findings provide critical insights and valuable
observations, advancing the understanding and application of LLM-based
optimization.",http://arxiv.org/abs/2501.15081v1
"Dynamic Modulation of Electronic and Optical Properties in GaN Bilayers
  by Interlayer Sliding",2025-01-25T05:32:13Z,"Heeju Kim, Gunn Kim","In this study, we present a first-principles investigation of the electronic
and optical properties of gallium nitride (GaN) bilayers, focusing on the
influence of interlayer sliding and spacing. In contrast to the earlier studies
on discrete stacking configurations, we explore the dynamic evolution of the
properties during transitions between stable stacking arrangements. Using
density functional theory calculations, we systematically analyze the impact of
these structural variations on the electronic band structure and optical
absorption spectra of GaN bilayers. The analysis includes both high-symmetry
stacking configurations (AA', AB', and AC') and intermediate states generated
by controlled in-plane atomic displacements, thereby providing a comprehensive
understanding of the property changes associated with interlayer sliding. The
findings of this study provide valuable insights into the potential for tuning
the electronic and optical response of two-dimensional GaN for applications in
nanoscale photonic and electronic devices, where precise control over
interlayer interactions and stacking is crucial.",http://arxiv.org/abs/2501.15088v1
Topological photonic crystal fibre,2025-01-25T07:17:06Z,"Bofeng Zhu, Kevin Hean, Stephan Wong, Yuxi Wang, Rimi Banerjee, Haoran Xue, Qiang Wang, Alexander Cerjan, Qi Jie Wang, Wonkeun Chang, Yi Dong Chong","Photonic crystal fibres (PCFs) are optical fibres that guide light using a
modulated dielectric medium. They provide an exceptionally versatile platform
for various applications, thanks to the flexibility with which light-guiding
can be customised by modifying the fibre geometry. Here, we realise a PCF with
guided modes produced by photonic bandstructure topology rather than
conventional mode-trapping mechanisms. The design, which is compatible with the
stack-and-draw fabrication process, consists of a cross-sectional photonic
topological crystalline insulator with a disclination. A bulk-defect
correspondence produces degenerate topological modes, lying below the cladding
light line. We use various theoretical methods to confirm their topological
origins, including a spectral localiser that makes minimal assumptions about
the bandstructure. Our experiments on the fabricated topological fibre show it
transmitting visible to near-infrared light with low losses of 10--20 dB/km,
which do not increase much when the fibre is bent. A comparable solid-core PCF
of conventional design exhibits substantially higher bending losses. Optical
fibres based on topological modes thus hold promise for improved performance
and novel functionalities.",http://arxiv.org/abs/2501.15107v1
Generating Negative Samples for Multi-Modal Recommendation,2025-01-25T11:45:49Z,"Yanbiao Ji, Yue Ding, Dan Luo, Chang Liu, Jing Tong, Shaokai Wu, Hongtao Lu","Multi-modal recommender systems (MMRS) have gained significant attention due
to their ability to leverage information from various modalities to enhance
recommendation quality. However, existing negative sampling techniques often
struggle to effectively utilize the multi-modal data, leading to suboptimal
performance. In this paper, we identify two key challenges in negative sampling
for MMRS: (1) producing cohesive negative samples contrasting with positive
samples and (2) maintaining a balanced influence across different modalities.
To address these challenges, we propose NegGen, a novel framework that utilizes
multi-modal large language models (MLLMs) to generate balanced and contrastive
negative samples. We design three different prompt templates to enable NegGen
to analyze and manipulate item attributes across multiple modalities, and then
generate negative samples that introduce better supervision signals and ensure
modality balance. Furthermore, NegGen employs a causal learning module to
disentangle the effect of intervened key features and irrelevant item
attributes, enabling fine-grained learning of user preferences. Extensive
experiments on real-world datasets demonstrate the superior performance of
NegGen compared to state-of-the-art methods in both negative sampling and
multi-modal recommendation.",http://arxiv.org/abs/2501.15183v2
Towards Conscious Service Robots,2025-01-25T12:32:52Z,Sven Behnke,"Deep learning's success in perception, natural language processing, etc.
inspires hopes for advancements in autonomous robotics. However, real-world
robotics face challenges like variability, high-dimensional state spaces,
non-linear dependencies, and partial observability. A key issue is
non-stationarity of robots, environments, and tasks, leading to performance
drops with out-of-distribution data. Unlike current machine learning models,
humans adapt quickly to changes and new tasks due to a cognitive architecture
that enables systematic generalization and meta-cognition. Human brain's System
1 handles routine tasks unconsciously, while System 2 manages complex tasks
consciously, facilitating flexible problem-solving and self-monitoring. For
robots to achieve human-like learning and reasoning, they need to integrate
causal models, working memory, planning, and metacognitive processing. By
incorporating human cognition insights, the next generation of service robots
will handle novel situations and monitor themselves to avoid risks and mitigate
errors.",http://arxiv.org/abs/2501.15198v1
"Reinforcement Learning Controlled Adaptive PSO for Task Offloading in
  IIoT Edge Computing",2025-01-25T13:01:54Z,"Minod Perera, Sheik Mohammad Mostakim Fattah, Sajib Mistry, Aneesh Krishna","Industrial Internet of Things (IIoT) applications demand efficient task
offloading to handle heavy data loads with minimal latency. Mobile Edge
Computing (MEC) brings computation closer to devices to reduce latency and
server load, optimal performance requires advanced optimization techniques. We
propose a novel solution combining Adaptive Particle Swarm Optimization (APSO)
with Reinforcement Learning, specifically Soft Actor Critic (SAC), to enhance
task offloading decisions in MEC environments. This hybrid approach leverages
swarm intelligence and predictive models to adapt to dynamic variables such as
human interactions and environmental changes. Our method improves resource
management and service quality, achieving optimal task offloading and resource
distribution in IIoT edge computing.",http://arxiv.org/abs/2501.15203v1
"Advancing Understanding of Long COVID Pathophysiology Through Quantum
  Walk-Based Network Analysis",2025-01-25T13:23:39Z,"Jaesub Park, Woochang Hwang, Seokjun Lee, Hyun Chang Lee, Méabh MacMahon, Matthias Zilbauer, Namshik Han","Long COVID is a multisystem condition characterized by persistent symptoms
such as fatigue, cognitive impairment, and systemic inflammation, following
COVID-19 infection, yet its mechanisms remain poorly understood. In this study,
we applied quantum walk (QW), a computational approach leveraging quantum
interference, to explore large-scale SARS-CoV-2-induced protein (SIP) networks.
Compared to the conventional random walk with restart (RWR) method, QW
demonstrated superior capacity to traverse deeper regions of the network,
uncovering proteins and pathways implicated in Long COVID. Key findings include
mitochondrial dysfunction, thromboinflammatory responses, and neuronal
inflammation as central mechanisms. QW uniquely identified the CDGSH
iron-sulfur domain-containing protein family and VDAC1, a mitochondrial calcium
transporter, as critical regulators of these processes. VDAC1 emerged as a
potential biomarker and therapeutic target, supported by FDA-approved compounds
such as cannabidiol. These findings highlight QW as a powerful tool for
elucidating complex biological systems and identifying novel therapeutic
targets for conditions like Long COVID.",http://arxiv.org/abs/2501.15208v2
Heat Transfer in Composite Materials: Mechanisms and Applications,2025-01-25T14:29:03Z,"Mohammad Alaghemandi, Morgan Alamandi","Understanding heat transfer in composite materials is essential for
optimizing their performance in critical applications across industries such as
aerospace, automotive, renewable energy, and construction. This review offers a
comprehensive examination of the various heat transfer mechanisms within
composite materials and explores how these processes, spanning different length
and time scales, are influenced by the materials' composition and structure.
Both traditional and advanced analytical and numerical modeling techniques are
explored, emphasizing their importance in predicting and optimizing thermal
behavior across these scales. Furthermore, the review evaluates current
experimental methods for measuring thermal properties, discussing their
limitations and potential areas for enhancement. Significant attention is
devoted to the practical applications of composite materials, from thermal
management in electronic devices to heat-resistant components in aerospace
engineering. Recent innovations, such as the integration of phase change
materials and the development of nano-enhanced composites, are assessed for
their potential to transform heat transfer capabilities. Ongoing challenges are
addressed, and future research directions are outlined, highlighting the need
for advancements in material science and engineering to meet emerging demands.
This review aims to bridge the gap between fundamental research and practical
applications, providing a comprehensive understanding of heat transfer in
composite materials that is both rooted in current science and driven by future
possibilities.",http://arxiv.org/abs/2501.15231v1
"Three-dimensional core-collapse supernova models with phenomenological
  treatment of neutrino flavor conversions",2025-01-25T16:04:00Z,"Kanji Mori, Tomoya Takiwaki, Kei Kotake, Shunsaku Horiuchi","We perform three-dimensional supernova simulations with a phenomenological
treatment of neutrino flavor conversions. We show that the explosion energy can
increase to as high as ~10^51 erg depending on the critical density for the
onset of flavor conversions, due to a significant enhancement of the mean
energy of electron antineutrinos. Our results confirm previous studies showing
such energetic explosions, but for the first time in three-dimensional
configurations. In addition, we predict neutrino and gravitational wave (GW)
signals from a nearby supernova explosion aided by flavor conversions. We find
that the neutrino event number decreases because of the reduced flux of
heavy-lepton neutrinos. In order to detect GWs, next-generation GW telescopes
such as Cosmic Explorer and Einstein Telescope are needed even if the supernova
event is located at the Galactic center. These findings show that the neutrino
flavor conversions can significantly change supernova dynamics and highlight
the importance of further studies on the quantum kinetic equations to determine
the conditions of the conversions and their asymptotic states.",http://arxiv.org/abs/2501.15256v1
"Memory Reviver: Supporting Photo-Collection Reminiscence for People with
  Visual Impairment via a Proactive Chatbot",2025-01-26T05:31:31Z,"Shuchang Xu, Chang Chen, Zichen Liu, Xiaofu Jin, Linping Yuan, Yukang Yan, Huamin Qu","Reminiscing with photo collections offers significant psychological benefits
but poses challenges for people with visual impairment (PVI). Their current
reliance on sighted help restricts the flexibility of this activity. In
response, we explored using a chatbot in a preliminary study. We identified two
primary challenges that hinder effective reminiscence with a chatbot: the
scattering of information and a lack of proactive guidance. To address these
limitations, we present Memory Reviver, a proactive chatbot that helps PVI
reminisce with a photo collection through natural language communication.
Memory Reviver incorporates two novel features: (1) a Memory Tree, which uses a
hierarchical structure to organize the information in a photo collection; and
(2) a Proactive Strategy, which actively delivers information to users at
proper conversation rounds. Evaluation with twelve PVI demonstrated that Memory
Reviver effectively facilitated engaging reminiscence, enhanced understanding
of photo collections, and delivered natural conversational experiences. Based
on our findings, we distill implications for supporting photo reminiscence and
designing chatbots for PVI.",http://arxiv.org/abs/2501.15408v1
"Differentiable Low-computation Global Correlation Loss for Monotonicity
  Evaluation in Quality Assessment",2025-01-26T11:09:16Z,"Yipeng Liu, Qi Yang, Yiling Xu","In this paper, we propose a global monotonicity consistency training strategy
for quality assessment, which includes a differentiable, low-computation
monotonicity evaluation loss function and a global perception training
mechanism. Specifically, unlike conventional ranking loss and linear
programming approaches that indirectly implement the Spearman rank-order
correlation coefficient (SROCC) function, our method directly converts SROCC
into a loss function by making the sorting operation within SROCC
differentiable and functional. Furthermore, to mitigate the discrepancies
between batch optimization during network training and global evaluation of
SROCC, we introduce a memory bank mechanism. This mechanism stores
gradient-free predicted results from previous batches and uses them in the
current batch's training to prevent abrupt gradient changes. We evaluate the
performance of the proposed method on both images and point clouds quality
assessment tasks, demonstrating performance gains in both cases.",http://arxiv.org/abs/2501.15485v1
Quark-Antiquark Potential as a Probe for Holographic Phase Transitions,2025-01-26T13:55:02Z,"Andrés Anabalón, Mariano Chernicoff, Gaston Giribet, Julio Oliva, Martín Reyes","In the recent paper (Phys.Rev.Lett. 133 (2024) 12, 121601), a higher-order
phase transition between the planar, charged, 5-dimensional
Reissner-Nordstr\""om-Anti-de Sitter black hole and a hairy black hole solution
of the type IIB supergravity was investigated. Here, we set out to investigate
these two phases of the theory by means of the holographic probe that describes
a quark-antiquark in the dual gauge theory. We show that the study of the
quark-antiquark potential turns out to be a useful method to investigate the
change of behavior at different values of the parameter that controls the phase
transition, this parameter being the ratio between the chemical potential and
the temperature. In other words, the string probes detects the phase
transition.",http://arxiv.org/abs/2501.15533v1
"Commute Your Domains: Trajectory Optimality Criterion for Multi-Domain
  Learning",2025-01-26T15:12:06Z,"Alexey Rukhovich, Alexander Podolskiy, Irina Piontkovskaya","In multi-domain learning, a single model is trained on diverse data domains
to leverage shared knowledge and improve generalization. The order in which the
data from these domains is used for training can significantly affect the
model's performance on each domain. However, this dependence is under-studied.
In this paper, we investigate the influence of training order (or data mixing)
in multi-domain learning using the concept of Lie bracket of gradient vector
fields. By analyzing the infinitesimal effects of changing the training order,
we identify regions in the parameter space where altering the order between two
training domains can benefit the target loss. We validate the predictions of
our theoretical framework on the influence of training order (or data mixing)
both on a toy example and bilingual LLM pre-training.",http://arxiv.org/abs/2501.15556v1
"Cognitive Performance Measurements and the Impact of Sleep Quality Using
  Wearable and Mobile Sensors",2025-01-26T16:20:15Z,"Aku Visuri, Heli Koskimäki, Niels van Berkel, Andy Alorwu, Ella Peltonen, Saeed Abdullah, Simo Hosio","Human cognitive performance is an underlying factor in most of our daily
lives, and numerous factors influence cognitive performance. In this work, we
investigate how changes in sleep quality influence cognitive performance,
measured from a dataset collected during a 2-month field study. We collected
cognitive performance data (alertness) with the Psychomotor Vigilance Task
(PVT), mobile keyboard typing metrics from participants' smartphones, and sleep
quality metrics through a wearable sleep tracking ring. Our findings highlight
that specific sleep metrics like night-time heart rate, sleep latency, sleep
timing, sleep restfulness, and overall sleep quantity significantly influence
cognitive performance. To strengthen the current research on cognitive
measurements, we introduce smartphone typing metrics as a proxy or a
complementary method for continuous passive measurement of cognitive
performance. Together, our findings contribute to ubiquitous computing via a
longitudinal case study with a novel wearable device, the resulting findings on
the association between sleep and cognitive function, and the introduction of
smartphone keyboard typing as a proxy of cognitive function.",http://arxiv.org/abs/2501.15583v1
"Instability bands for periodic traveling waves in the modified
  Korteweg-de Vries equation",2025-01-26T18:03:54Z,"Shikun Cui, Dmitry E. Pelinovsky","Two families of periodic traveling waves exist in the focusing mKdV (modified
Korteweg-de Vries) equation. Spectral stability of these waveforms with respect
to co-periodic perturbations of the same period has been previously explored by
using spectral analysis and variational formulation. By using tools of
integrability such as a relation between squared eigenfunctions of the Lax pair
and eigenfunctions of the linearized stability problem, we revisit the spectral
stability of these waveforms with respect to perturbations of arbitrary
periods. In agreement with previous works, we find that one family is
spectrally stable for all parameter configurations, whereas the other family is
spectrally unstable for all parameter configurations. We show that the onset of
the co-periodic instability for the latter family changes the instability bands
from figure-$8$ (crossing at the imaginary axis) into figure-$\infty$ (crossing
at the real axis).",http://arxiv.org/abs/2501.15621v1
"Thermodynamics of deformed AdS-Schwarzschild black holes in the presence
  of Thermal fluctuations",2025-01-26T18:27:01Z,"Dhruba Jyoti Gogoi, Poppy Hazarika, Jyatsnasree Bora, Ranjan Changmai","This paper examines the thermodynamic properties and stability of deformed
AdS-Schwarzschild black holes, focusing on the effects of deformation
($\alpha$) and thermal correction parameters ($\beta_1$, $\beta_2$) on phase
transitions and heat capacity. The results show that higher $\alpha$ values
raise the Hawking-Page critical temperature, enhancing thermal stability.
Thermal corrections significantly affect smaller black holes but minimally
impact larger ones, leaving second-order phase transitions unchanged. Heat
capacity analysis identifies stability regions, with sign changes marking
instability. These findings highlight the role of deformation and thermal
corrections in black hole stability, offering insights for extending our
understanding of black hole thermodynamics.",http://arxiv.org/abs/2501.15629v1
"Sensitive particle shape dependence of growth-induced mesoscale nematic
  structure",2025-01-26T21:46:29Z,"Jonas Isensee, Philip Bittihn","Directed growth, anisotropic cell shapes, and confinement drive
self-organization in multicellular systems. We investigate the influence of
particle shape on the distribution and dynamics of nematic microdomains in a
minimal in-silico model of proliferating, sterically interacting particles,
akin to colonies of rod-shaped bacteria. By introducing continuously tuneable
tip variations around a common rod shape with spherical caps, we find that
subtle changes significantly impact the emergent dynamics, leading to distinct
patterns of microdomain formation and stability. Our analysis reveals separate
effects of particle shape and aspect ratio, as well as a transition from
exponential to scale-free size distributions, which we recapitulate using an
effective master equation model. This allows us to relate differences in
microdomain size distributions to different physical mechanisms of microdomain
breakup. Our results thereby contribute to the characterization of the
effective dynamics in growing aggregates at large and intermediate length
scales and the microscopic properties that control it. This could be relevant
both for biological self-organization and design strategies for future
artificial systems.",http://arxiv.org/abs/2501.15681v2
"Weight-based Analysis of Detokenization in Language Models:
  Understanding the First Stage of Inference Without Inference",2025-01-27T03:45:29Z,"Go Kamoda, Benjamin Heinzerling, Tatsuro Inaba, Keito Kudo, Keisuke Sakaguchi, Kentaro Inui","According to the stages-of-inference hypothesis, early layers of language
models map their subword-tokenized input, which does not necessarily correspond
to a linguistically meaningful segmentation, to more meaningful representations
that form the model's ""inner vocabulary"". Prior analysis of this detokenization
stage has predominantly relied on probing and interventions such as path
patching, which involve selecting particular inputs, choosing a subset of
components that will be patched, and then observing changes in model behavior.
Here, we show that several important aspects of the detokenization stage can be
understood purely by analyzing model weights, without performing any model
inference steps. Specifically, we introduce an analytical decomposition of
first-layer attention in GPT-2. Our decomposition yields interpretable terms
that quantify the relative contributions of position-related, token-related,
and mixed effects. By focusing on terms in this decomposition, we discover
weight-based explanations of attention bias toward close tokens and attention
for detokenization.",http://arxiv.org/abs/2501.15754v3
"Stationary scalar clouds around a rotating BTZ-like black hole in the
  Einstein-bumblebee gravity",2025-01-27T04:00:42Z,"Fangli Quan, Fengjiao Li, Qiyuan Pan, Mengjie Wang, Jiliang Jing","We have studied stationary clouds of massive scalar fields around a rotating
BTZ-like black hole in the Einstein-bumblebee gravity, by imposing the Robin
type boundary conditions at the AdS boundary. We establish, by scanning the
parameter space, the existence of \textit{fundamental} stationary scalar clouds
($i.e.$, the overtone number $n=0$). In particular, we observe that the Lorentz
symmetry breaking parameter $s$ and the quantum number $k$ play an opposite
role in determining scalar clouds, which indicates the existence of
\textit{degenerate} scalar clouds. To illustrate the fact that scalar clouds
may only be supported for the $n=0$ case, we have analyzed the impact of
various parameters on scalar quasinormal modes. It is shown that the Lorentz
symmetry breaking parameter $s$ does not change the superradiance condition,
and superradiant instabilities only appear for the fundamental modes. Our work
shows that the Lorentz symmetry breaking provides richer physics in stationary
scalar clouds around black holes.",http://arxiv.org/abs/2501.15759v1
"Advancing Portfolio Optimization: Adaptive Minimum-Variance Portfolios
  and Minimum Risk Rate Frameworks",2025-01-27T05:37:28Z,"Ayush Jha, Abootaleb Shirvani, Ali Jaffri, Svetlozar T. Rachev, Frank J. Fabozzi","This study presents the Adaptive Minimum-Variance Portfolio (AMVP) framework
and the Adaptive Minimum-Risk Rate (AMRR) metric, innovative tools designed to
optimize portfolios dynamically in volatile and nonstationary financial
markets. Unlike traditional minimum-variance approaches, the AMVP framework
incorporates real-time adaptability through advanced econometric models,
including ARFIMA-FIGARCH processes and non-Gaussian innovations. Empirical
applications on cryptocurrency and equity markets demonstrate the proposed
framework's superior performance in risk reduction and portfolio stability,
particularly during periods of structural market breaks and heightened
volatility. The findings highlight the practical implications of using the AMVP
and AMRR methodologies to address modern investment challenges, offering
actionable insights for portfolio managers navigating uncertain and rapidly
changing market conditions.",http://arxiv.org/abs/2501.15793v1
"Can Multimodal Large Language Models be Guided to Improve Industrial
  Anomaly Detection?",2025-01-27T05:41:10Z,"Zhiling Chen, Hanning Chen, Mohsen Imani, Farhad Imani","In industrial settings, the accurate detection of anomalies is essential for
maintaining product quality and ensuring operational safety. Traditional
industrial anomaly detection (IAD) models often struggle with flexibility and
adaptability, especially in dynamic production environments where new defect
types and operational changes frequently arise. Recent advancements in
Multimodal Large Language Models (MLLMs) hold promise for overcoming these
limitations by combining visual and textual information processing
capabilities. MLLMs excel in general visual understanding due to their training
on large, diverse datasets, but they lack domain-specific knowledge, such as
industry-specific defect tolerance levels, which limits their effectiveness in
IAD tasks. To address these challenges, we propose Echo, a novel multi-expert
framework designed to enhance MLLM performance for IAD. Echo integrates four
expert modules: Reference Extractor which provides a contextual baseline by
retrieving similar normal images, Knowledge Guide which supplies
domain-specific insights, Reasoning Expert which enables structured, stepwise
reasoning for complex queries, and Decision Maker which synthesizes information
from all modules to deliver precise, context-aware responses. Evaluated on the
MMAD benchmark, Echo demonstrates significant improvements in adaptability,
precision, and robustness, moving closer to meeting the demands of real-world
industrial anomaly detection.",http://arxiv.org/abs/2501.15795v1
"D-PLS: Decoupled Semantic Segmentation for
  4D-Panoptic-LiDAR-Segmentation",2025-01-27T08:46:22Z,"Maik Steinhauser, Laurenz Reichardt, Nikolas Ebert, Oliver Wasenmüller","This paper introduces a novel approach to 4D Panoptic LiDAR Segmentation that
decouples semantic and instance segmentation, leveraging single-scan semantic
predictions as prior information for instance segmentation. Our method D-PLS
first performs single-scan semantic segmentation and aggregates the results
over time, using them to guide instance segmentation. The modular design of
D-PLS allows for seamless integration on top of any semantic segmentation
architecture, without requiring architectural changes or retraining. We
evaluate our approach on the SemanticKITTI dataset, where it demonstrates
significant improvements over the baseline in both classification and
association tasks, as measured by the LiDAR Segmentation and Tracking Quality
(LSTQ) metric. Furthermore, we show that our decoupled architecture not only
enhances instance prediction but also surpasses the baseline due to
advancements in single-scan semantic segmentation.",http://arxiv.org/abs/2501.15870v1
"A Low-Cost, High-Precision Human-Machine Interaction Solution Based on
  Multi-Coil Wireless Charging Pads",2025-01-27T09:18:35Z,Bojun Zhang,"Wireless charging pads are common, yet their functionality is mainly
restricted to charging. Existing gesture recognition techniques, such as those
based on machine vision and WiFi, have drawbacks like high costs and poor
precision. This paper presents a new human machine interaction solution using
multicoil wireless charging pads. The proposed approach leverages the pads
existing modules without additional wearable sensors. It determines gestures by
monitoring current and power changes in different coils. The data processing
includes noise removal, sorting, highpass filtering, and slicing. A Bayesian
network and particle filtering are employed for motion tracking. Through
experiments, this solution proves to have wide applications, high recognition
accuracy, and low cost. It can effectively identify diverse gestures,
increasing the value of wireless charging pads. It outperforms traditional
methods, with a 0.73 improvement in recognition accuracy and better
environmental adaptability.",http://arxiv.org/abs/2501.15885v1
"Qualitative observations in university physics laboratories: an example
  from classical mechanics",2025-01-27T12:15:56Z,"K. Dunnett, M. H. Magnusson","One of the key skills of a researcher is noticing what's going on. Both in
the experiment one's performing and in one's data: is there something
interesting, reason to doubt one's data or suspect that one's theoretical
description is insufficient? Many experiments developed for undergraduate
teaching still focus on quantitative evaluation. Here we take an alternative
approach where careful observation identifies the interesting qualitative
behaviour of a ball dropped with a water bottle balanced on top of it, but
where numerical agreement with a simple theoretical model is impossible. Thus
'success' occurs when students are satisfied with their efforts and the
development of their experimental process. Laboratory note keeping can also be
introduced in a meaningful, non-formulaic way since students are making
independent observations and method changes. We describe pedagogical and
didactic considerations for the implementation of the experiment in a
classroom, including variations and extensions, and give examples of
experimental outcomes. We suggest that considering qualitative behaviour may be
a fruitful strategy for identifying experiments that are both amenable to
student autonomy and embedding skills such as laboratory note keeping in a
flexible and genuine way.",http://arxiv.org/abs/2501.15988v2
"Modeling and stability analysis of live systems with time-varying
  dimension",2025-01-27T12:22:49Z,Andrii Mironchenko,"A major limitation of the classical control theory is the assumption that the
state space and its dimension do not change with time. This prevents analyzing
and even formalizing the stability and control problems for open multi-agent
systems whose agents may enter or leave the network, industrial processes where
the sensors or actuators may be exchanged frequently, smart grids, etc. In this
work, we propose a framework of live systems that covers a rather general class
of systems with a time-varying state space. We argue that input-to-state
stability is a proper stability notion for this class of systems, and many of
the classic tools and results, such as Lyapunov methods and superposition
theorems, can be extended to this setting.",http://arxiv.org/abs/2501.15991v1
"Confocal Ellipsoidal Reflectors with Phased Array Vivaldi Antenna Source
  for Imaging Systems",2025-01-27T12:30:49Z,"Mohammad Hossein Koohi Ghamsari, Mahyar Mehri Pashaki, Mehdi Ahmadi-Boroujeni","In this paper, an on-axis dual-reflector confocal ellipsoidal structure is
presented for near-field imaging systems. In the proposed structure, the
backscattered electromagnetic wave problem, known as the blockage effect, is
reduced considerably using an elaborate design of the sub-reflector and precise
alignment of the reflectors. The proposed geometry is analyzed, followed by a
design example for the stand-off distance of 2 m. The blockage reduction
characteristic is verified using ray-tracing simulation. Next, the scanning
performance of the structure is investigated utilizing a Vivaldi phased array
antenna as the source designed at the central frequency of 28 GHz. The
full-wave simulations proved a field-of-view (FoV) of approximately 40 cm.
Furthermore, tuning the proposed reflectors configuration standoff distance is
examined with a point source. The ray-tracing simulations showed that stand-off
distance can be easily changed up to tens of centimeters with just a few
centimeters of source point lateral displacement.",http://arxiv.org/abs/2501.15997v1
"Epidemics on the Move: How Public Transport Demand and Capacity Shape
  Disease Spread",2025-01-27T12:43:13Z,"László Hajdu, Jovan Pavlović, Miklós Krész, András Bóta","Understanding the dynamics of passenger interactions and their
epidemiological impact throughout public transportation systems is crucial for
both service efficiency and public health. High passenger density and close
physical proximity has been shown to accelerate the spread of infectious
diseases. During the COVID-19 pandemic, many public transportation companies
took measures to slow down and minimize disease spreading. One of these
measures was introducing spacing and capacity constraints to public transit
vehicles. Our objective is to explore the effects of demand changes and
transportation measures from an epidemiological point of view, offering
alternative measures to public transportation companies to keep the system
alive while minimizing the epidemiological risk as much as possible.",http://arxiv.org/abs/2501.16004v1
Mass and Metal Flows in Isolated IllustrisTNG Halos,2025-01-27T13:38:41Z,"Jacob P. Morgan, Jeremy Bailin","The cicumgalactic medium (CGM) is a reservoir of metals and star-forming
fuel. Most baryons in the universe are in the circumgalactic medium (CGM) or
intergalactic medium (IGM). The baryon cycle -- how mass and metals reach the
CGM from the inner regions of the galaxy and how gas from the CGM replenishes
star-forming activity in the inner regions -- is an essential question in
galaxy evolution. In this paper, we study the flow of mass and metals in a
stacked sample of 2770 isolated halos from the IllustrisTNG cosmological
hydrodynamic simulation. The mean gas flow as a function of radius and angle is
similar across a large galactic mass range when accounting for different
feedback modes. Although both star formation and black holes cause powerful
outflows, the flows from star formation are more angularly restricted. Black
hole feedback dominates massflow throughout the halo, while star-formation
feedback mainly affects the inner region. When scaling by virial radius
($R_v$), large dynamical changes occur at $0.2R_v$ for most halos, suggesting a
characteristic size for the inner galaxy. Despite radio mode feedback from
black holes being the primary quenching mechanism in IllustrisTNG, a small
population of high mass radio mode disks are able to form stars.",http://arxiv.org/abs/2501.16045v1
Self-propelled particles undergoing cyclic transitions,2025-01-27T13:41:21Z,"Ye Zhang, Duanduan Wan","Cyclic transitions between active and passive states are central to many
natural and synthetic systems, ranging from light-driven active particles to
animal migrations. Here, we investigate a minimal model of self-propelled
Brownian particles undergoing cyclic transitions across three spatial zones:
gain, loss, and neutral regions. Particles become active in the gain region,
passive in the loss region, and retain their state in the neutral region. By
analyzing the steady-state behavior as a function of particle number and the
size of the loss region, we identify a threshold particle number, below and
above which distinct structural changes are observed. Interestingly, below this
threshold, increasing the particle number reduces the state-switching time (the
time required for a particle to transition from active to passive and back to
active). In contrast, above the threshold, further increases in particle number
result in longer switching times. In the subthreshold regime, our analytical
model predicts structural characteristics and switching dynamics that align
well with simulations. Above the threshold, we observe an emergent spatial
clustering, with particles transitioning from passive to active states in close
proximity. These findings provide insights into the collective dynamics of
cyclic processes between active and passive states across distinct spatial
zones in active matter systems.",http://arxiv.org/abs/2501.16048v1
"Hyperfine structure and collisions in three-photon Rydberg
  electromagnetically induced transparency",2025-01-27T13:51:37Z,"Alisher Duspayev, Georg Raithel","Multi-photon electromagnetically-induced transparency (EIT) of atomic vapors
involves several intermediate atomic levels. The sub-structure of these levels
and their collisional interactions can drastically alter experimental EIT
signals. Here, we report on hyperfine structure and collision effects in
three-photon Rydberg EIT on the cascade $5S_{1/2} \rightarrow$ $5P_{1/2}
\rightarrow 5D_{3/2}$ $\rightarrow 25F_{5/2}$ in a room temperature $^{85}$Rb
vapor cell. In our measurements of EIT spectra, we identify two types of EIT
signatures that correspond with distinct excitation pathways and atomic
velocity classes in the atomic vapor. The $5D_{3/2}$ hyperfine structure and
Autler-Townes splittings lead to complex patterns in the EIT spectra, which we
analyze with the aid of 10-level EIT simulations. Adding 50~mTorr of Ar gas
alters the EIT spectra and induces an additional, third EIT mode. Based on our
simulation results, we attribute these changes to hyperfine collisions in the
Rb $5D_{3/2}$ level. Our study may become useful in quantum technologies
involving Rydberg EIT and hyperfine collisions in vapor cells, including
non-invasive spatio-temporally resolved electric-field sensing of electric
fields in low-pressure plasmas.",http://arxiv.org/abs/2501.16054v1
"The stochastic skeleton model for the Madden-Julian Oscillation with
  time-dependent observation-based forcing",2025-01-27T13:58:55Z,"Noémie Ehstand, Reik V. Donner, Cristóbal López, Marcelo Barreiro, Emilio Hernández-García","We analyze solutions to the stochastic skeleton model, a minimal nonlinear
oscillator model for the Madden-Julian Oscillation (MJO). This model has been
recognized for its ability to reproduce several large-scale features of the
MJO. In previous studies, the model's forcings were predominantly chosen to be
mathematically simple and time-independent. Here, we present solutions to the
model with time-dependent observation-based forcing functions. Our results show
that the model, with these more realistic forcing functions, successfully
replicates key characteristics of MJO events, such as their lifetime, extent,
and amplitude, whose statistics agree well with observations. However, we find
that the seasonality of MJO events and the spatial variations in the MJO
properties are not well reproduced. Having implemented the model in the
presence of time-dependent forcings, we can analyze the impact of temporal
variability at different time scales. In particular, we study the model's
ability to reflect changes in MJO characteristics under the different phases of
ENSO. We find that it does not capture differences in studied characteristics
of MJO events in response to differences in conditions during El Ni\~no, La
Ni\~na, and neutral ENSO.",http://arxiv.org/abs/2501.16060v1
Challenging Assumptions in Learning Generic Text Style Embeddings,2025-01-27T14:21:34Z,"Phil Ostheimer, Marius Kloft, Sophie Fellenz","Recent advancements in language representation learning primarily emphasize
language modeling for deriving meaningful representations, often neglecting
style-specific considerations. This study addresses this gap by creating
generic, sentence-level style embeddings crucial for style-centric tasks. Our
approach is grounded on the premise that low-level text style changes can
compose any high-level style. We hypothesize that applying this concept to
representation learning enables the development of versatile text style
embeddings. By fine-tuning a general-purpose text encoder using contrastive
learning and standard cross-entropy loss, we aim to capture these low-level
style shifts, anticipating that they offer insights applicable to high-level
text styles. The outcomes prompt us to reconsider the underlying assumptions as
the results do not always show that the learned style representations capture
high-level text styles.",http://arxiv.org/abs/2501.16073v1
"Multi-Agent Meta-Offline Reinforcement Learning for Timely UAV Path
  Planning and Data Collection",2025-01-27T14:47:19Z,"Eslam Eldeeb, Hirley Alves","Multi-agent reinforcement learning (MARL) has been widely adopted in
high-performance computing and complex data-driven decision-making in the
wireless domain. However, conventional MARL schemes face many obstacles in
real-world scenarios. First, most MARL algorithms are online, which might be
unsafe and impractical. Second, MARL algorithms are environment-specific,
meaning network configuration changes require model retraining. This letter
proposes a novel meta-offline MARL algorithm that combines conservative
Q-learning (CQL) and model agnostic meta-learning (MAML). CQL enables offline
training by leveraging pre-collected datasets, while MAML ensures scalability
and adaptability to dynamic network configurations and objectives. We propose
two algorithm variants: independent training (M-I-MARL) and centralized
training decentralized execution (M-CTDE-MARL). Simulation results show that
the proposed algorithm outperforms conventional schemes, especially the CTDE
approach that achieves 50 % faster convergence in dynamic scenarios than the
benchmarks. The proposed framework enhances scalability, robustness, and
adaptability in wireless communication systems by optimizing UAV trajectories
and scheduling policies.",http://arxiv.org/abs/2501.16098v1
"Dynamic Neutrino Mass Ordering and Its Imprint on the Diffuse Supernova
  Neutrino Background",2025-01-27T19:00:00Z,"Yuber F. Perez-Gonzalez, Manibrata Sen","Neutrino masses may have evolved dynamically throughout the history of the
Universe, potentially leading to a mass spectrum distinct from the normal or
inverted ordering observed today. While cosmological measurements constrain the
total energy density of neutrinos, they are not directly sensitive to a
dynamically changing mass ordering unless future surveys achieve exceptional
precision in detecting the distinct imprints of each mass eigenstate on
large-scale structures. In this work, we investigate the impact of a dynamic
neutrino mass spectrum on the diffuse supernova neutrino background (DSNB),
which is composed of neutrinos from all supernova explosions throughout cosmic
history and is on the verge of experimental detection. Since neutrino
oscillations are highly sensitive to the mass spectrum, we show that the
electron neutrino survival probability carries distinct signatures of the
evolving neutrino mass spectrum. Our results indicate that the resulting
modifications to the DSNB spectrum would exhibit unique energy-dependent
features. These features are distinguishable from the effects of significant
astrophysical uncertainties, providing a potential avenue for probing the
dynamic nature of neutrino masses.",http://arxiv.org/abs/2501.16412v1
"Programming by Examples Meets Historical Linguistics: A Large Language
  Model Based Approach to Sound Law Induction",2025-01-27T21:48:39Z,"Atharva Naik, Darsh Agrawal, Hong Sng, Clayton Marr, Kexun Zhang, Nathaniel R Robinson, Kalvin Chang, Rebecca Byrnes, Aravind Mysore, Carolyn Rose, David R Mortensen","Historical linguists have long written ""programs"" that convert reconstructed
words in an ancestor language into their attested descendants via ordered
string rewrite functions (called sound laws) However, writing these programs is
time-consuming, motivating the development of automated Sound Law Induction
(SLI) which we formulate as Programming by Examples (PBE) with Large Language
Models (LLMs) in this paper. While LLMs have been effective for code
generation, recent work has shown that PBE is challenging but improvable by
fine-tuning, especially with training data drawn from the same distribution as
evaluation data. In this paper, we create a conceptual framework of what
constitutes a ""similar distribution"" for SLI and propose four kinds of
synthetic data generation methods with varying amounts of inductive bias to
investigate what leads to the best performance. Based on the results we create
a SOTA open-source model for SLI as PBE (+6% pass rate with a third of the
parameters of the second-best LLM) and also highlight exciting future
directions for PBE research.",http://arxiv.org/abs/2501.16524v1
"DialUp! Modeling the Language Continuum by Adapting Models to Dialects
  and Dialects to Models",2025-01-27T23:53:04Z,"Niyati Bafna, Emily Chang, Nathaniel R. Robinson, David R. Mortensen, Kenton Murray, David Yarowsky, Hale Sirin","Most of the world's languages and dialects are low-resource, and lack support
in mainstream machine translation (MT) models. However, many of them have a
closely-related high-resource language (HRL) neighbor, and differ in
linguistically regular ways from it. This underscores the importance of model
robustness to dialectical variation and cross-lingual generalization to the HRL
dialect continuum. We present DialUp, consisting of a training-time technique
for adapting a pretrained model to dialectical data (M->D), and an
inference-time intervention adapting dialectical data to the model expertise
(D->M). M->D induces model robustness to potentially unseen and unknown
dialects by exposure to synthetic data exemplifying linguistic mechanisms of
dialectical variation, whereas D->M treats dialectical divergence for known
target dialects. These methods show considerable performance gains for several
dialects from four language families, and modest gains for two other language
families. We also conduct feature and error analyses, which show that language
varieties with low baseline MT performance are more likely to benefit from
these approaches.",http://arxiv.org/abs/2501.16581v1
"Safety-Critical Control for Aerial Physical Interaction in Uncertain
  Environment",2025-01-28T05:53:29Z,"Jeonghyun Byun, Yeonjoon Kim, Dongjae Lee, H. Jin Kim","Aerial manipulation for safe physical interaction with their environments is
gaining significant momentum in robotics research. In this paper, we present a
disturbance-observer-based safety-critical control for a fully actuated aerial
manipulator interacting with both static and dynamic structures. Our approach
centers on a safety filter that dynamically adjusts the desired trajectory of
the vehicle's pose, accounting for the aerial manipulator's dynamics, the
disturbance observer's structure, and motor thrust limits. We provide rigorous
proof that the proposed safety filter ensures the forward invariance of the
safety set - representing motor thrust limits - even in the presence of
disturbance estimation errors. To demonstrate the superiority of our method
over existing control strategies for aerial physical interaction, we perform
comparative experiments involving complex tasks, such as pushing against a
static structure and pulling a plug firmly attached to an electric socket.
Furthermore, to highlight its repeatability in scenarios with sudden dynamic
changes, we perform repeated tests of pushing a movable cart and extracting a
plug from a socket. These experiments confirm that our method not only
outperforms existing methods but also excels in handling tasks with rapid
dynamic variations.",http://arxiv.org/abs/2501.16719v1
"B-RIGHT: Benchmark Re-evaluation for Integrity in Generalized
  Human-Object Interaction Testing",2025-01-28T06:04:08Z,"Yoojin Jang, Junsu Kim, Hayeon Kim, Eun-ki Lee, Eun-sol Kim, Seungryul Baek, Jaejun Yoo","Human-object interaction (HOI) is an essential problem in artificial
intelligence (AI) which aims to understand the visual world that involves
complex relationships between humans and objects. However, current benchmarks
such as HICO-DET face the following limitations: (1) severe class imbalance and
(2) varying number of train and test sets for certain classes. These issues can
potentially lead to either inflation or deflation of model performance during
evaluation, ultimately undermining the reliability of evaluation scores. In
this paper, we propose a systematic approach to develop a new class-balanced
dataset, Benchmark Re-evaluation for Integrity in Generalized Human-object
Interaction Testing (B-RIGHT), that addresses these imbalanced problems.
B-RIGHT achieves class balance by leveraging balancing algorithm and automated
generation-and-filtering processes, ensuring an equal number of instances for
each HOI class. Furthermore, we design a balanced zero-shot test set to
systematically evaluate models on unseen scenario. Re-evaluating existing
models using B-RIGHT reveals substantial the reduction of score variance and
changes in performance rankings compared to conventional HICO-DET. Our
experiments demonstrate that evaluation under balanced conditions ensure more
reliable and fair model comparisons.",http://arxiv.org/abs/2501.16724v1
Random attraction in TASEP with time-varying hopping rates,2025-01-28T08:00:29Z,"Lars Grüne, Kilian Pioch, Thomas Kriecherbauer, Michael Margaliot","The totally asymmetric simple exclusion principle (TASEP) is a fundamental
model in nonequilibrium statistical mechanics. It describes the stochastic
unidirectional movement of particles along a 1D chain of ordered sites. We
consider the continuous-time version of TASEP with a finite number of sites and
with time-varying hopping rates between the sites. We show how to formulate
this model as a nonautonomous random dynamical system (NRDS) with a finite
state-space. We provide conditions guaranteeing that random pullback and
forward attractors of such an NRDS exist and consist of singletons. In the
context of the nonautonomous TASEP these conditions imply almost sure
synchronization of the individual random paths. This implies in particular that
perturbations that change the state of the particles along the chain are
""filtered out"" in the long run. We demonstrate that the required conditions are
tight by providing examples where these conditions do not hold and consequently
the forward attractor does not exist or the pullback attractor is not a
singleton. The results in this paper generalize our earlier results for
autonomous TASEP in https://doi.org/10.1137/20M131446X and contain these as a
special case.",http://arxiv.org/abs/2501.16777v1
"A failed wind candidate in NGC 3783 from the 2001 year campaign with
  Chandra/HETGS",2025-01-28T12:07:43Z,"Chen Li, Jelle S. Kaastra, Liyi Gu, Daniele Rogantini, Anna Juráňová, Missagh Mehdipour, Jelle de Plaa","We reanalyze the Chandra/HETGS observations of NGC 3783 from the campaign in
the year 2001, identifying significant spectral variations in the Fe unresolved
transition array (UTA) over timescales of weeks to months. These changes
correlate with a $1.4-2$ fold increase in the ionizing continuum and exceed $10
\, \sigma$ significance. The variations primarily originate from a
low-ionization state ($\rm log \xi = 1.65$) component of the warm absorber.
Time-dependent photoionization modelling confirms the sensitivity of this
low-ionization component to continuum variations within the Fe UTA band. Local
fitting indicates a lower density limit of $>10^{12.3} \, \rm m^{-3}$ at $3 \,
\sigma$ statistical uncertainty, with the component located within $0.27 \, \rm
pc$. Our findings suggest that this low-ionization component is a potential
failed wind candidate.",http://arxiv.org/abs/2501.16880v1
"Emergent collective behavior of cohesive, aligning particles",2025-01-28T14:51:14Z,"Jeanine Shea, Holger Stark","Collective behavior is all around us, from flocks of birds to schools of
fish. These systems are immensely complex, which makes it pertinent to study
their behavior through minimal models. We introduce such a minimal model for
cohesive and aligning self-propelled particles in which group cohesion is
established through additive, non-reciprocal torques. These torques cause
constituents to effectively turn towards one another. We additionally
incorporate an alignment torque, which competes with the cohesive torque in the
same spatial range. By changing the strength and range of these torque
interactions, we uncover six states which we distinguish via their static and
dynamic properties: a disperse state, a multiple worm state, a line state, a
persistent worm state, a rotary worm state, and an aster state. Their
occurrence strongly depends on initial conditions and stochasticity, so the
model exhibits multistabilities. A number of the states exhibit collective
dynamics which are reminiscent of those seen in nature.",http://arxiv.org/abs/2501.16994v1
Tuning LLM Judge Design Decisions for 1/1000 of the Cost,2025-01-24T17:01:14Z,"David Salinas, Omar Swelam, Frank Hutter","Evaluating Large Language Models (LLMs) often requires costly human
annotations. To address this, LLM-based judges have been proposed, which
compare the outputs of two LLMs enabling the ranking of models without human
intervention. While several approaches have been proposed, many confounding
factors are present between different papers. For instance the model, the
prompt and other hyperparameters are typically changed at the same time making
apple-to-apple comparisons challenging. In this paper, we propose to
systematically analyze and tune hyperparameter of LLM judges. To alleviate the
high cost of evaluating a judge, we propose to leverage multi-objective
multi-fidelity which allows to find judges that trades accuracy for cost and
also reduce significantly the cost of the search. Our method identifies judges
that not only outperform existing benchmarks in accuracy and cost-efficiency
but also utilize open-weight models, ensuring greater accessibility and
reproducibility.",http://arxiv.org/abs/2501.17178v2
Unimodular JT gravity and de Sitter quantum cosmology,2025-01-28T16:17:51Z,"Bruno Alexandre, Altay Etkin, Farbod-Sayyed Rassouli","In this work, we show that a gauge-theoretic description of Jackiw-Teitelboim
(JT) gravity naturally yields a Henneaux-Teitelboim (HT) unimodular gravity via
a central extension of its isometry group, valid for both flat and curved
two-dimensional spacetimes. HT gravity introduces a unimodular time canonically
conjugate to the cosmological constant, serving as a physical time in quantum
cosmology. By studying the mini-superspace reduction of $\text{HT}_2$ gravity,
the Wheeler-DeWitt equation becomes a Schr\""odinger-like equation, giving a
consistent and unitary quantum theory. Analysis of the wavefunction's
probability density reveals a quantum distribution for the scale factor $a$,
offering a quantum perspective on the expansion and contraction of the
universe. In this perspective, the possibility of reaching the singular point
$a=0$ signals that topology change could occur. Finally, we give a consistent
quantum description of unimodular time that aligns seamlessly with
Page-Wootters formulation of quantum mechanics, where quantum correlations
between unimodular time and JT gravity are studied in $\text{HT}_2$ quantum
cosmology.",http://arxiv.org/abs/2501.17213v1
"An Efficient Numerical Function Optimization Framework for Constrained
  Nonlinear Robotic Problems",2025-01-28T23:51:44Z,"Sait Sovukluk, Christian Ott","This paper presents a numerical function optimization framework designed for
constrained optimization problems in robotics. The tool is designed with
real-time considerations and is suitable for online trajectory and control
input optimization problems. The proposed framework does not require any
analytical representation of the problem and works with constrained block-box
optimization functions. The method combines first-order gradient-based line
search algorithms with constraint prioritization through nullspace projections
onto constraint Jacobian space. The tool is implemented in C++ and provided
online for community use, along with some numerical and robotic example
implementations presented in this paper.",http://arxiv.org/abs/2501.17349v2
"Realtime Limb Trajectory Optimization for Humanoid Running Through
  Centroidal Angular Momentum Dynamics",2025-01-29T00:06:01Z,"Sait Sovukluk, Robert Schuller, Johannes Englsberger, Christian Ott","One of the essential aspects of humanoid robot running is determining the
limb-swinging trajectories. During the flight phases, where the ground reaction
forces are not available for regulation, the limb swinging trajectories are
significant for the stability of the next stance phase. Due to the conservation
of angular momentum, improper leg and arm swinging results in highly tilted and
unsustainable body configurations at the next stance phase landing. In such
cases, the robotic system fails to maintain locomotion independent of the
stability of the center of mass trajectories. This problem is more apparent for
fast and high flight time trajectories. This paper proposes a real-time
nonlinear limb trajectory optimization problem for humanoid running. The
optimization problem is tested on two different humanoid robot models, and the
generated trajectories are verified using a running algorithm for both robots
in a simulation environment.",http://arxiv.org/abs/2501.17351v2
Quantum Cross-section of Near-extremal Black Holes,2025-01-29T08:25:19Z,Roberto Emparan,"We explore how to detect the large quantum fluctuations in the throat of a
near-extremal black hole, where the dynamics are governed by the Schwarzian
theory. To this end, we scatter a low-frequency wave of a massless, minimal
scalar off the black hole and calculate the absorption cross-section. In the
semiclassical regime, where the Schwarzian is weakly coupled, we recover the
universal result that the cross-section equals the horizon area. However, in
the strongly coupled regime, where quantum fluctuations dominate, we find that
the absorption cross-section exceeds the semiclassical prediction. This result
may seem counterintuitive, given that the density of black hole states is
suppressed in this regime. Nevertheless, two effects outweigh this suppression.
First, quantum fluctuations enhance absorption transitions between individual
states, with the effect becoming stronger closer to the ground state. Second,
these fluctuations significantly reduce stimulated emission. We conclude that a
measurement showing an enhanced absorption cross-section serves as a clear
signature of the large quantum fluctuations in the geometry.",http://arxiv.org/abs/2501.17470v2
"Bacterial dimensions sensitively regulate surface diffusivity and
  residence time",2025-01-29T08:42:24Z,"Premkumar Leishangthem, Xuan Wang, Junan Chen, Shengqi Yang, Xinliang Xu","Run-and-tumble is a common but vital strategy that bacteria employ to explore
environment suffused with boundaries, as well as to escape from entrapment. In
this study we reveal how this strategy and the resulting dynamical behavior can
be sensitively regulated by bacterial dimensions. Our results demonstrate that
the logarithm of the surface residence time for bacteria with constant tumble
bias is linearly related to a dimensionless parameter of bacterial intrinsic
size characteristics, where a small variation in bacterial dimensions, which is
natural in a suspension, reproduces well the experimentally observed large
variation in bacterial residence time. Furthermore, our results predict that
the optimal tumble bias corresponding to the maximum surface diffusivity
depends strongly on bacterial dimensions, where the same small variation in
bacterial dimensions gives rise to a strongly diversified optimal tumble bias
and an order of magnitude change in surface diffusivity.",http://arxiv.org/abs/2501.17477v1
"System-environmental entanglement in critical spin systems under
  $ZZ$-decoherence and its relation to strong and weak symmetries",2025-01-29T08:45:46Z,"Yoshihito Kuno, Takahiro Orito, Ikuo Ichinose","Open quantum many-body system exhibits nontrivial behavior under decoherence.
In particular, system-environmental entanglement is one of quantities to
characterize mixed state properties under decoherence. In this study, we
investigate the behavior of the system-environmental entanglement for critical
spin chains under nearest-neighbor $ZZ$ -decoherence. We numerically find that
the system-environmental entanglement exhibits a specific scaling law including
a system-independent universal term (""$g$-function""). For the critical XXZ
model, transition to strong-to-weak spontaneously symmetry breaking mixed state
takes place. In that case, the $g$-function changes its value at decoherent
transition point and gets double the value of system under single-site
$Z$-decoherence, which was recently studied by conformal field theory. By
studying Shannon entropy, we clarify origin of this $g$-function behavior.",http://arxiv.org/abs/2501.17481v1
"Low-Complexity Event Detection and Identification in Coherent
  Correlation OTDR Measurements",2025-01-29T09:44:33Z,"Jasper Müller, Ognjen Jovanovic, Florian Azendorf, André Sandmann, Roman Ermakov, Sai Kireet Patri, Jörg-Peter Elbers, Jim Zou, Darko Zibar, Carmen Mas-Machuca","Pairing coherent correlation OTDR with low-complexity analysis methods, we
investigate the detection of fast temperature changes and vibrations in optical
fibers. A localization accuracy of ~2 m and extraction of vibration amplitudes
and frequencies is demonstrated.",http://arxiv.org/abs/2501.17519v1
"Mechanism of Oleic Acid-Mediated Sulfur Vacancy Healing in monolayer
  WS$_2$",2025-01-29T10:10:45Z,"Leon Daniel, Dedi Sutarma, Osamah Kharsah, Charleen Lintz, Peter Kratzer, Marika Schleberger","We uncover the mechanism behind the enhancement of photoluminescence yield in
monolayer WS$_2$ through oleic acid treatment, a promising scalable strategy
for defect healing. By inducing sulfur vacancies through thermal treatment and
monitoring the changes in photoluminescence yield and emission spectra, we
demonstrate that oleic acid heals the sulfur vacancy by providing
substitutional oxygen. Using density functional theory calculations, we provide
insight into the underlying mechanism governing the oleic acid-mediated sulfur
vacancy healing process. Our findings suggest that effective defect passivation
by oxygen doping can be achieved through chemical treatment, opening a pathway
for oxygen doping in transition metal dichalcogenides. However, we also
highlight the limitations of chemical treatment, which may only lead to small
increases in photoluminescence yield beyond a certain point.",http://arxiv.org/abs/2501.17536v1
"Towards post-growth policymaking: Barriers and enablers for sustainable
  wellbeing initiatives",2025-01-29T12:09:35Z,"Laura Angresius, Milena Buchs, Alessia Greselin, Daniel W. O'Neill","Providing wellbeing for all while safeguarding planetary boundaries may
require governments to pursue post-growth policies. Previous empirical studies
of sustainable wellbeing initiatives investigating enablers of and barriers to
post-growth policymaking are either based on a small number of empirical cases
or lack an explicit analytical framework. To better understand how post-growth
policymaking could be fostered, we investigate 29 initiatives across governance
scales in Europe, New Zealand, and Canada. We apply a framework that
distinguishes polity, politics, and policy to analyze the data. We find that
the main enablers and barriers relate to the economic growth paradigm, the
organization of government, attitudes towards policymaking, political
strategies, and policy tools and outcomes. Engaging in positive framings of
post-growth visions to change narratives and building broad-based alliances
could act as drivers. However, initiatives face a tension between the need to
connect to broad audiences and a risk of co-optation by depolitization.",http://arxiv.org/abs/2501.17600v1
"MuonSLab: A plastic scintillator based detector for muon measurement in
  the deep ocean",2025-01-29T13:17:56Z,"Jiacheng Wu, Weilun Huang, Ruike Cao, Qichao Chang, Wang Ding, Jingtao Huang, Liang Li, Xinchen Li, Hualin Mei, Cen Mo, Hengbin Shao, Wei Tian, Xinliang Tian, Yichen Tian, Xin Xiang, Donglian Xu, Fuyudi Zhang, Wei Zhi, Yiwei Zhu","Atmospheric muons are important probes for studying primary cosmic rays and
extensive air showers. Additionally, they constitute a significant background
for many underground and deep-sea neutrino experiments, such as TRopIcal
DEep-sea Neutrino Telescope (TRIDENT). Understanding the muon flux at various
depths in the deep sea is essential for validating TRIDENT simulations and
guiding the development of optimized trigger strategies. This paper introduces
a novel device based on plastic scintillalors and silicon photomultipliers
(SiPMs) named MuonSLab, which is designed to measure muon flux in the deep sea
and has the potential to be extended to other atmospheric muon property
measurements. We discuss the design and instrumentation of MuonSLab and present
results from several muon flux measurements, demonstrating its sensitivity to
muon detection and its stability during operations across multiple locations.",http://arxiv.org/abs/2501.17639v1
"Dynamic Competition between Cooper-Pair and Spin-Density-Wave
  Condensation",2025-01-29T15:53:01Z,"B. Decrausaz, M. Pikulski, O. Ivashko, N. B. Christensen, J. Choi, L. Udby, Ch. Niedermayer, K. Lefmann, H. M. Rønnow, J. Mesot, J. Ollivier, T. Kurosawa, N. Momono, M. Oda, J. Chang, D. G. Mazzone","Quantum matter phases may co-exist microscopically even when they display
competing tendencies. A fundamental question is whether such a competition can
be avoided through the elimination of one phase while the other one condenses
into the ground state. Here, we present a high-resolution neutron spectroscopy
study of the low-energy spin excitations in the high-temperature superconductor
La1.855Sr0.145CuO4. In the normal state, we find low-energy magnetic
fluctuations at incommensurate reciprocal lattice positions where
spin-density-wave order emerges at lower Sr concentration or at high magnetic
fields. While these spin excitations are largely suppressed by the emergence of
the superconducting spin gap, some low-energy magnetic fluctuations persist
deep inside the superconducting state. We interpret this result in terms of a
dynamic competition between superconductivity and magnetism, where
superconductivity impedes the condensation of low-energy magnetic fluctuations
through the formation of magnetically-mediated Cooper pairs.",http://arxiv.org/abs/2501.17724v1
"Analysis of Neural Activation in Time-dependent Membrane Capacitance
  Models",2025-01-29T17:45:10Z,"Matías Courdurier, Leonel E. Medina, Esteban Paduro","Most models of neurons incorporate a capacitor to account for the marked
capacitive behavior exhibited by the cell membrane. However, such capacitance
is widely considered constant, thereby neglecting the possible effects of
time-dependent membrane capacitance on neural excitability. This study presents
a modified formulation of a neuron model with time-dependent membrane
capacitance and shows that action potentials can be elicited for certain
capacitance dynamics. Our main results can be summarized as: (a) it is
necessary to have significant and abrupt variations in the capacitance to
generate action potentials; (b) certain simple and explicitly constructed
capacitance profiles with strong variations do generate action potentials; (c)
forcing abrupt changes in the capacitance too frequently may result in no
action potentials. These findings can have great implications for the design of
ultrasound-based or other neuromodulation strategies acting through transiently
altering the membrane capacitance of neurons.",http://arxiv.org/abs/2501.17803v1
"On heat coefficients, multiplicative anomaly and 4D Casimir energy for
  GJMS operators",2025-01-29T18:18:08Z,"Rodrigo Aros, Fabrizzio Bugini, Danilo E. Díaz, Camilo Nuñez-Barra","This note aims to verify a prediction on the total derivative term of the 4D
trace anomaly, and the corresponding heat coefficient, for GJMS operators. It
stems from the explicit computation of an {\it improved} Casimir (or vacuum)
energy on the sphere that takes into account the multiplicative anomaly among
the (shifted) Laplacian factors and connects, via the Cappelli-Coste relation,
with both the type A central charge and the total derivative term of the 4D
trace anomaly. The present heat coefficient computation is based on Juhl's
explicit formula for GJMS operators, Gilkey's formula for the integrated heat
coefficient of higher-order Laplacians, and the \textit{conformal principle} by
Branson and {\O}rsted.",http://arxiv.org/abs/2501.17828v2
"Aspects of Spatially-Correlated Random Fields: Extreme-Value Statistics
  and Clustering Properties",2025-01-29T19:00:56Z,"Ka Hei Choi, James Creswell, Florian Kuhnel, Dominik J. Schwarz","Rare events of large-scale spatially-correlated exponential random fields are
studied. The influence of spatial correlations on clustering and non-sphericity
is investigated. The size of the performed simulations permits to study
beyond-$7.5$-sigma events ($1$ in $10^{13}$). As an application, this allows to
resolve individual Hubble patches which fulfill the condition for primordial
black hole formation. It is argued that their mass spectrum is drastically
altered due to co-collapse of clustered overdensities as well as the mutual
threshold-lowering through the latter. Furthermore, the corresponding
non-sphericities imply possibly large changes in the initial black hole spin
distribution.",http://arxiv.org/abs/2501.17936v1
Gradient estimates for scalar curvature,2025-01-29T19:09:55Z,"Tobias Holck Colding, William P. Minicozzi II","A gradient estimate is a crucial tool used to control the rate of change of a
function on a manifold, paving the way for deeper analysis of geometric
properties. A celebrated result of Cheng and Yau gives gradient bounds on
manifolds with Ricci curvature $\geq 0$. The Cheng-Yau bound is not sharp, but
there is a gradient sharp estimate. To explain this, a Green's function $u$ on
a manifold can be used to define a regularized distance $b= u^{\frac{1}{2-n}}$
to the pole. On $\bf{R}^n$, the level sets of $b$ are spheres and $|\nabla
b|=1$. If $\text{Ric} \geq 0$, then [C3] proved the sharp gradient estimate
$|\nabla b| \leq 1$. We show that the average of $|\nabla b|$ is $\leq 1$ on a
three manifold with nonnegative scalar curvature. The average is over any level
set of $b$ and if the average is one on even one level set, then $M=\bf{R}^3$.",http://arxiv.org/abs/2501.17947v1
Topological Signatures of Adversaries in Multimodal Alignments,2025-01-29T21:45:10Z,"Minh Vu, Geigh Zollicoffer, Huy Mai, Ben Nebgen, Boian Alexandrov, Manish Bhattarai","Multimodal Machine Learning systems, particularly those aligning text and
image data like CLIP/BLIP models, have become increasingly prevalent, yet
remain susceptible to adversarial attacks. While substantial research has
addressed adversarial robustness in unimodal contexts, defense strategies for
multimodal systems are underexplored. This work investigates the topological
signatures that arise between image and text embeddings and shows how
adversarial attacks disrupt their alignment, introducing distinctive
signatures. We specifically leverage persistent homology and introduce two
novel Topological-Contrastive losses based on Total Persistence and Multi-scale
kernel methods to analyze the topological signatures introduced by adversarial
perturbations. We observe a pattern of monotonic changes in the proposed
topological losses emerging in a wide range of attacks on image-text
alignments, as more adversarial samples are introduced in the data. By
designing an algorithm to back-propagate these signatures to input samples, we
are able to integrate these signatures into Maximum Mean Discrepancy tests,
creating a novel class of tests that leverage topological signatures for better
adversarial detection.",http://arxiv.org/abs/2501.18006v1
"SAeUron: Interpretable Concept Unlearning in Diffusion Models with
  Sparse Autoencoders",2025-01-29T23:29:47Z,"Bartosz Cywiński, Kamil Deja","Diffusion models, while powerful, can inadvertently generate harmful or
undesirable content, raising significant ethical and safety concerns. Recent
machine unlearning approaches offer potential solutions but often lack
transparency, making it difficult to understand the changes they introduce to
the base model. In this work, we introduce SAeUron, a novel method leveraging
features learned by sparse autoencoders (SAEs) to remove unwanted concepts in
text-to-image diffusion models. First, we demonstrate that SAEs, trained in an
unsupervised manner on activations from multiple denoising timesteps of the
diffusion model, capture sparse and interpretable features corresponding to
specific concepts. Building on this, we propose a feature selection method that
enables precise interventions on model activations to block targeted content
while preserving overall performance. Evaluation with the competitive
UnlearnCanvas benchmark on object and style unlearning highlights SAeUron's
state-of-the-art performance. Moreover, we show that with a single SAE, we can
remove multiple concepts simultaneously and that in contrast to other methods,
SAeUron mitigates the possibility of generating unwanted content, even under
adversarial attack. Code and checkpoints are available at:
https://github.com/cywinski/SAeUron.",http://arxiv.org/abs/2501.18052v2
Synthesizing Grasps and Regrasps for Complex Manipulation Tasks,2025-01-30T00:58:31Z,"Aditya Patankar, Dasharadhan Mahalingam, Nilanjan Chakraborty","In complex manipulation tasks, e.g., manipulation by pivoting, the motion of
the object being manipulated has to satisfy path constraints that can change
during the motion. Therefore, a single grasp may not be sufficient for the
entire path, and the object may need to be regrasped. Additionally, geometric
data for objects from a sensor are usually available in the form of point
clouds. The problem of computing grasps and regrasps from point-cloud
representation of objects for complex manipulation tasks is a key problem in
endowing robots with manipulation capabilities beyond pick-and-place. In this
paper, we formalize the problem of grasping/regrasping for complex manipulation
tasks with objects represented by (partial) point clouds and present an
algorithm to solve it. We represent a complex manipulation task as a sequence
of constant screw motions. Using a manipulation plan skeleton as a sequence of
constant screw motions, we use a grasp metric to find graspable regions on the
object for every constant screw segment. The overlap of the graspable regions
for contiguous screws are then used to determine when and how many times the
object needs to be regrasped. We present experimental results on point cloud
data collected from RGB-D sensors to illustrate our approach.",http://arxiv.org/abs/2501.18075v1
"Beyond Turn-taking: Introducing Text-based Overlap into Human-LLM
  Interactions",2025-01-30T03:01:01Z,"JiWoo Kim, Minsuk Chang, JinYeong Bak","Traditional text-based human-AI interactions often adhere to a strict
turn-taking approach. In this research, we propose a novel approach that
incorporates overlapping messages, mirroring natural human conversations.
Through a formative study, we observed that even in text-based contexts, users
instinctively engage in overlapping behaviors like ""A: Today I went to-"" ""B:
yeah."" To capitalize on these insights, we developed OverlapBot, a prototype
chatbot where both AI and users can initiate overlapping. Our user study
revealed that OverlapBot was perceived as more communicative and immersive than
traditional turn-taking chatbot, fostering faster and more natural
interactions. Our findings contribute to the understanding of design space for
overlapping interactions. We also provide recommendations for implementing
overlap-capable AI interactions to enhance the fluidity and engagement of
text-based conversations.",http://arxiv.org/abs/2501.18103v1
Battery State of Health Estimation Using LLM Framework,2025-01-30T03:55:56Z,"Aybars Yunusoglu, Dexter Le, Karn Tiwari, Murat Isik, I. Can Dikmen","Battery health monitoring is critical for the efficient and reliable
operation of electric vehicles (EVs). This study introduces a transformer-based
framework for estimating the State of Health (SoH) and predicting the Remaining
Useful Life (RUL) of lithium titanate (LTO) battery cells by utilizing both
cycle-based and instantaneous discharge data. Testing on eight LTO cells under
various cycling conditions over 500 cycles, we demonstrate the impact of charge
durations on energy storage trends and apply Differential Voltage Analysis
(DVA) to monitor capacity changes (dQ/dV) across voltage ranges. Our LLM model
achieves superior performance, with a Mean Absolute Error (MAE) as low as
0.87\% and varied latency metrics that support efficient processing,
demonstrating its strong potential for real-time integration into EVs. The
framework effectively identifies early signs of degradation through anomaly
detection in high-resolution data, facilitating predictive maintenance to
prevent sudden battery failures and enhance energy efficiency.",http://arxiv.org/abs/2501.18123v1
"Fits of $α_s$ from event-shapes in the three-jet region: extension
  to all energies",2025-01-30T07:01:52Z,"Paolo Nason, Giulia Zanderighi","This work is an extension of a previous publication [1] where we fitted the
strong coupling $\alpha_s$ together with the non-perturbative parameter
$\alpha_0$ from event-shape and jet-shape distributions using power corrections
computed in the three-jet region. In ref. [1] only ALEPH data at the $Z$-pole
were used in the fit. Here, instead, we include a large data sample from
various $e^+e^-$ experiments at energies ranging from 22 to 207 GeV and
revisited the treatment of theoretical uncertainties. We find that the
inclusion of different energies, while not changing the central fit result
considerably, helps to disentangle the dependence of perturbative and
non-perturbative corrections. Our best fit result is $\alpha_s(M_Z) = 0.1181
(+0.0002 -0.0005) (+0.0018 -0.0021)$, where the first error includes
experimental uncertianties and the second one includes uncertainties associated
with scale variation, mass effects, fit limits, non-perturbative schemes and
non-perturbative uncertainties.",http://arxiv.org/abs/2501.18173v1
Exciton-polariton condensate in the van der Waals magnet CrSBr,2025-01-30T09:45:38Z,"Bo Han, Hangyong Shan, Kok Wee Song, Lukas Lackner, Martin Esmann, Vita Solovyeva, Falk Eilenberger, Jakub Regner, Zdeněk Sofer, Oleksandr Kyriienko, Christian Schneider","Van der Waals magnets are an emergent material class of paramount interest
for fundamental studies in coupling light with matter excitations, which are
uniquely linked to their underlying magnetic properties. Among these materials,
the magnetic semiconductor CrSBr is possibly a first playground where we can
study simultaneously the interaction of photons, magnons, and excitons at the
quantum level. Here we demonstrate a coherent macroscopic quantum phase, the
bosonic condensation of exciton-polaritons, which emerges in a CrSBr flake
embedded in a fully tunable cryogenic open optical cavity. The Bose condensate
is characterized by a highly non-linear threshold-like behavior, and coherence
manifests distinctly via its first and second order quantum coherence. We find
that the condensate's non-linearity is highly susceptible to the magnetic order
in CrSBr, and encounters a sign change depending on the antiferro- and
ferromagnetic ordering. Our findings open a route towards magnetically
controllable quantum fluids of light, and optomagnonic devices where spin
magnetism is coupled to on-chip Bose-Einstein condensates.",http://arxiv.org/abs/2501.18233v1
"Statistical multi-metric evaluation and visualization of LLM system
  predictive performance",2025-01-30T10:21:10Z,"Samuel Ackerman, Eitan Farchi, Orna Raz, Assaf Toledo","The evaluation of generative or discriminative large language model
(LLM)-based systems is often a complex multi-dimensional problem. Typically, a
set of system configuration alternatives are evaluated on one or more benchmark
datasets, each with one or more evaluation metrics, which may differ between
datasets. We often want to evaluate -- with a statistical measure of
significance -- whether systems perform differently either on a given dataset
according to a single metric, on aggregate across metrics on a dataset, or
across datasets. Such evaluations can be done to support decision-making, such
as deciding whether a particular system component change (e.g., choice of LLM
or hyperparameter values) significantly improves performance over the current
system configuration, or, more generally, whether a fixed set of system
configurations (e.g., a leaderboard list) have significantly different
performances according to metrics of interest. We present a framework
implementation that automatically performs the correct statistical tests,
properly aggregates the statistical results across metrics and datasets (a
nontrivial task), and can visualize the results. The framework is demonstrated
on the multi-lingual code generation benchmark CrossCodeEval, for several
state-of-the-art LLMs.",http://arxiv.org/abs/2501.18243v1
Curvature-sensing and generation of membrane proteins: a review,2025-01-30T12:38:09Z,Hiroshi Noguchi,"Membrane proteins are crucial in regulating biomembrane shapes and
controlling the dynamic changes in membrane morphology during essential
cellular processes. These proteins can localize to regions with their preferred
curvatures (curvature sensing) and induce localized membrane curvature. Thus,
this review describes the recent theoretical development in membrane remodeling
performed by membrane proteins. The mean-field theories of protein binding and
the resulting membrane deformations are reviewed. The effects of hydrophobic
insertions on the area-difference elasticity energy and that of intrinsically
disordered protein domains on the membrane bending energy are discussed. For
the crescent-shaped proteins, such as Bin/Amphiphysin/Rvs superfamily proteins,
anisotropic protein bending energy and orientation-dependent excluded volume
significantly contribute to curvature sensing and generation. Moreover,
simulation studies of membrane deformations caused by protein binding and
colloidal particle adhesion are reviewed, including domain formation, budding,
and tubulation.",http://arxiv.org/abs/2501.18311v1
"Adaptive Video Streaming with AI-Based Optimization for Dynamic Network
  Conditions",2025-01-30T13:20:23Z,"Mohammad Tarik, Qutaiba Ibrahim","The increase in video streaming has presented a challenge of handling stream
request effectively, especially over networks that are variable. This paper
describes a new adaptive video streaming architecture capable of changing the
video quality and buffer size depending on the data and latency of streamed
video. For video streaming VLC media player was used where network performance
data were obtained through Python scripts with very accurate data rate and
latency measurement. The collected data is analyzed using Gemini AI, containing
characteristics of the machine learning algorithm that recognizes the best
resolution of videos and the buffer sizes. Through the features of real-time
monitoring and artificial intelligence decision making, the proposed framework
improves the user experience by reducing the occurrence of buffering events
while at the same time increasing the video quality. Our findings therefore
confirm that the proposed solution based on artificial intelligence increases
video quality and flexibility. This study advances knowledge of adaptive
streaming and offers an argument about how intelligent datadriven approaches
and AI may be useful tools for enhancing the delivery of video in practical
environments.",http://arxiv.org/abs/2501.18332v1
"Optimal performance of thermoelectric devices with small external
  irreversibility",2025-01-30T15:43:59Z,"Rajeshree Chakraborty, Ramandeep S. Johal","In the thermodynamic analysis of thermoelectric devices, typical
irreversibilities are for the processes of finite-rate heat transfer and Joule
heating. Approximate analyses often focus on either internal or external
irreversibility, yielding well-known expressions for the efficiency at maximum
power (EMP), such as the Curzon-Ahlborn value for endoreversible model and the
Schmiedl-Seifert form for exoreversible model. Within the Constant Properties
model, we formulate a scenario that incorporates internal as well as external
irreversibilities simultaneously. We employ the approximation of a symmetric
and small external irreversibility (SEI), confining to the regime where the
external conductance of the heat exchangers is large in comparison to the
internal thermal conductance of the thermoelectric material. This approach
allows us to derive a general expression for EMP, which depends on the ratio of
internal to external conductance, apart from the figure of merit and ratio of
temperatures. Extending our study to thermoelectric refrigerators under the
similar assumptions, we also analyze the efficiency at maximum cooling power.",http://arxiv.org/abs/2501.18437v2
Track-On: Transformer-based Online Point Tracking with Memory,2025-01-30T17:04:11Z,"Görkay Aydemir, Xiongyi Cai, Weidi Xie, Fatma Güney","In this paper, we consider the problem of long-term point tracking, which
requires consistent identification of points across multiple frames in a video,
despite changes in appearance, lighting, perspective, and occlusions. We target
online tracking on a frame-by-frame basis, making it suitable for real-world,
streaming scenarios. Specifically, we introduce Track-On, a simple
transformer-based model designed for online long-term point tracking. Unlike
prior methods that depend on full temporal modeling, our model processes video
frames causally without access to future frames, leveraging two memory modules
-- spatial memory and context memory -- to capture temporal information and
maintain reliable point tracking over long time horizons. At inference time, it
employs patch classification and refinement to identify correspondences and
track points with high accuracy. Through extensive experiments, we demonstrate
that Track-On sets a new state-of-the-art for online models and delivers
superior or competitive results compared to offline approaches on seven
datasets, including the TAP-Vid benchmark. Our method offers a robust and
scalable solution for real-time tracking in diverse applications. Project page:
https://kuis-ai.github.io/track_on",http://arxiv.org/abs/2501.18487v1
"Unitarity triangle angles explained: a predictive new quark mass matrix
  texture",2025-01-30T17:19:45Z,"P. F. Harrison, W. G. Scott","We propose a novel quark mass matrix texture-pair with five free parameters,
which fits the four quark mass ratios $m_s/m_b$, $m_d/m_b$, $m_c/m_t$,
$m_u/m_t$, and the four CKM quark mixing observables. The matrices each have
one texture zero, but the main innovation here is a ``geometric'' ansatz
exploiting a pair of small complex expansion parameters, based on the geometry
of the Unitarity Triangle. The fit to the observables is in good agreement with
current experimental values renormalised to $\sim\!\!10^4$ TeV, and offers
decisive tests against future high-precision measurements of the unitarity
triangle angles at the weak scale. We identify two novel symmetries of these
mass matrices which explain the phenomenologically-successful relations
$\alpha\equiv\phi_2\simeq\pibytwo$ and $\beta\equiv\phi_1\simeq\pibyeight$.",http://arxiv.org/abs/2501.18508v3
"Bias-variance decompositions: the exclusive privilege of Bregman
  divergences",2025-01-30T18:52:44Z,Tom Heskes,"Bias-variance decompositions are widely used to understand the generalization
performance of machine learning models. While the squared error loss permits a
straightforward decomposition, other loss functions - such as zero-one loss or
$L_1$ loss - either fail to sum bias and variance to the expected loss or rely
on definitions that lack the essential properties of meaningful bias and
variance. Recent research has shown that clean decompositions can be achieved
for the broader class of Bregman divergences, with the cross-entropy loss as a
special case. However, the necessary and sufficient conditions for these
decompositions remain an open question.
  In this paper, we address this question by studying continuous, nonnegative
loss functions that satisfy the identity of indiscernibles under mild
regularity conditions. We prove that so-called $g$-Bregman divergences are the
only such loss functions that have a clean bias-variance decomposition. A
$g$-Bregman divergence can be transformed into a standard Bregman divergence
through an invertible change of variables. This makes the squared Mahalanobis
distance, up to such a variable transformation, the only symmetric loss
function with a clean bias-variance decomposition. We also examine the impact
of relaxing the restrictions on the loss functions and how this affects our
results.",http://arxiv.org/abs/2501.18581v1
Magnetic field evolution of X-ray emitting radio-quiet pulsars,2025-01-29T14:10:19Z,"Debasis Atta, Vinay Singh, D. N. Basu","The intense magnetic fields present in neutron stars are closely linked to
their observed temperature and spectral characteristics, timing properties,
including spin period and its derivatives. Therefore, a comprehensive
theoretical analysis of magnetic field evolution is essential for understanding
how the strength of the magnetic field change over time. The decay rate of
magnetic field in isolated, non-accreting neutron stars can be assessed by
evaluating the second derivative of the spin frequency. Another method to
estimate this rate involves monitoring an increase in thermal emission beyond
what is expected from standard cooling processes, assuming no additional
heating mechanisms are present. Our findings indicate that for X-ray emitting
isolated neutron stars, the evolution rate of spin period derivative aligns
with the dissipation rate of magnetic energy from the dipolar field, provided
that a substantial portion of the released energy is emitted as X-rays. The
time scale of magnetic field decay is found to be much shorter than typical age
of radio pulsars.",http://arxiv.org/abs/2501.18647v1
"Enhancing Large Language Model Efficiencyvia Symbolic Compression: A
  Formal Approach Towards Interpretability",2025-01-30T06:40:52Z,"Lumen AI, Tengzhou No. 1 Middle School, Shihao Ji, Zihui Song, Fucheng Zhong, Jisen Jia, Zhaobo Wu, Zheyi Cao, Tianhao Xu","Large language models (LLMs) face significant token efficiency bottlenecks in
code generation and logical reasoning tasks, a challenge that directly impacts
inference cost and model interpretability. This paper proposes a formal
framework based on symbolic compression,integrating combinatory logic,
information-theoretic optimal encoding, and context-aware inference techniques
to achieve a step-change improvement in token efficiency while preserving
semantic integrity. We establish a mathematical framework within a functional
programming paradigm, derive the quantitative relationship between symbolic
density and model interpretability, and propose a differentiable compression
factor metric to evaluate encoding efficiency. Furthermore, we leverage
parameter-efficient fine-tuning (PEFT) techniques to achieve a low-cost
application of the GAEL language. Experimental results show that this method
achieves a 78.3% token compression rate in code generation tasks while
improving logical traceability by 62% through structural explicitness. This
research provides new theoretical tools for efficient inference in LLMs and
opens a symbolic path for modelinterpretability research.",http://arxiv.org/abs/2501.18657v1
"Pneutouch: Exploring the affordances and interactions of haptic
  inflatables through a wrist-worn interface",2025-01-30T21:37:05Z,"Frank Wencheng Liu, Mason Manetta, Prasad Borkar, Byron Lahey, Assegid Kidane, Robert LiKamWa","Haptic sensations that align with virtual reality (VR) experiences have a
profound impact on presence and enjoyment. There is potential to explore the
dynamic capabilities of pneumatic inflatables to offer immersive sensations in
virtual environments, including variations in shape, size, and stiffness. We
introduce Pneutouch, an ungrounded and untethered wrist-worn device designed as
a pneumatic haptic interface for VR interactions. Pneutouch's dynamic inflation
ability enables programmable stiffness and shape change of haptic proxies.
Additionally, multiple haptic proxies can be delivered into and out of the
user's hand grasp. We describe the implementation of the Pneutouch device. We
conducted user studies to demonstrate the affordances of pneumatic inflatables
and assessed the device's efficacy in providing haptic feedback. With
Pneutouch, our goal is to expand what can be touched in the virtual space and
bring more immersion into virtual reality.",http://arxiv.org/abs/2501.18764v1
"One Stack, Diverse Vehicles: Checking Safe Portability of Automated
  Driving Software",2025-01-30T21:45:32Z,Vladislav Nenchev,"Integrating an automated driving software stack into vehicles with variable
configuration is challenging, especially due to different hardware
characteristics. Further, to provide software updates to a vehicle fleet in the
field, the functional safety of every affected configuration has to be ensured.
These additional demands for dependability and the increasing hardware
diversity in automated driving make rigorous automatic analysis essential. This
paper addresses this challenge by using formal portability checking of adaptive
cruise controller code for different vehicle configurations. Given a formal
specification of the safe behavior, models of target configurations are
derived, which capture relevant effects of sensors, actuators and computing
platforms. A corresponding safe set is obtained and used to check if the
desired behavior is achievable on all targets. In a case study, portability
checking of a traditional and a neural network controller are performed
automatically within minutes for each vehicle hardware configuration. The check
provides feedback for necessary adaptations of the controllers, thus, allowing
rapid integration and testing of software or parameter changes.",http://arxiv.org/abs/2501.18769v1
$CP$ violation in the $HZZ$ vertex and left-right asymmetries,2025-01-30T23:56:35Z,"A. I. Hernández-Juárez, R. Gaitán","We calculate new contributions to the $HZZ$ vertex from the Flavor Changing
Neutral Current (FCNC) of the Higgs and $Z$ bosons. It is found that the
$h_2^V$ and $h_3^V$ ($V=H$, $Z$) form factors can be induced through these
couplings, and we present our results in terms of the Passarino-Veltman scalar
functions. Using the current limits on $H\overline{t}c$ and $Z\overline{t}c$
couplings, we determine that the new contributions to the $CP$-conserving form
factor $h_2^V$ are small in comparison to the Standard Model (SM) predictions.
However, for the $CP$-violating form factor $h_3^V$, the contributions can
reach values as large as $10^{-6}$, five orders of magnitude larger than in the
SM. Furthermore, we examine how these results influence the left-right
asymmetries in the processes $H^\ast\to ZZ$ and $Z^\ast\to ZH$. Our findings
indicate that significant deviations from the SM predictions may arise when
FCNC contributions are considered.",http://arxiv.org/abs/2501.18807v1
"Integrated Communication and Binary State Detection Under Unequal Error
  Constraints",2025-01-31T06:20:51Z,"Daewon Seo, Sung Hoon Lim","This work considers a problem of integrated sensing and communication (ISAC)
in which the goal of sensing is to detect a binary state. Unlike most
approaches that minimize the total detection error probability, in our work, we
disaggregate the error probability into false alarm and missed detection
probabilities and investigate their information-theoretic three-way tradeoff
including communication data rate. We consider a broadcast channel that
consists of a transmitter, a communication receiver, and a detector where the
receiver's and the detector's channels are affected by an unknown binary state.
We consider and present results on two different state-dependent models. In the
first setting, the state is fixed throughout the entire transmission, for which
we fully characterize the optimal three-way tradeoff between the coding rate
for communication and the two possibly nonidentical error exponents for sensing
in the asymptotic regime. The achievability and converse proofs rely on the
analysis of the cumulant-generating function of the log-likelihood ratio. In
the second setting, the state changes every symbol in an independently and
identically distributed (i.i.d.) manner, for which we characterize the optimal
tradeoff region based on the analysis of the receiver operating characteristic
(ROC) curves.",http://arxiv.org/abs/2501.18911v1
"Optimizing Through Change: Bounds and Recommendations for Time-Varying
  Bayesian Optimization Algorithms",2025-01-31T08:49:33Z,"Anthony Bardou, Patrick Thiran","Time-Varying Bayesian Optimization (TVBO) is the go-to framework for
optimizing a time-varying, expensive, noisy black-box function. However, most
of the solutions proposed so far either rely on unrealistic assumptions on the
nature of the objective function or do not offer any theoretical guarantees. We
propose the first analysis that asymptotically bounds the cumulative regret of
TVBO algorithms under mild and realistic assumptions only. In particular, we
provide an algorithm-independent lower regret bound and an upper regret bound
that holds for a large class of TVBO algorithms. Based on this analysis, we
formulate recommendations for TVBO algorithms and show how an algorithm (BOLT)
that follows them performs better than the state-of-the-art of TVBO through
experiments on synthetic and real-world problems.",http://arxiv.org/abs/2501.18963v1
"A two-stage stochastic MINLP model to design and operate a multi-energy
  microgrid by addressing carbon emission regulatory policies uncertainty",2025-01-31T09:38:17Z,"Handan Akülker, Burak Alakent, Erdal Aydin","This study suggests a novel two-stage Mixed-Integer Nonlinear Programming
model considering uncertainty related to implementation of carbon dioxide
emission regulatory policies, which are carbon trading and emission taxing and
can change over the years, for the purpose of optimal equipment selection from
candidate equipment to design, size and operate a multi-energy microgrid. The
uncertain sources are air temperature, wind speed, solar radiation, carbon
dioxide trading price or tax, and natural gas price. Candidate equipment are
wind turbines, PV arrays, a biomass-fired generator, biomass combined cycles,
combined heat and power generators, conventional generators, an electricity
storage unit, integrated gasification combined cycles, a heat pump, and a
power-to-synthetic natural gas (P2G) system. Three case studies are
investigated. In the first case, the model selects the optimal equipment for
meeting the electricity and heat demands only. In the second case, the optimal
equipment selections are determined to couple with the P2G system to meet the
electricity, heat, and natural gas demands. In the third case, the model
selects the optimal equipment to run with sustainable energy generators: wind
turbines and solar panels. The optimal selections are compared between
deterministic and stochastic forms of the optimization models.",http://arxiv.org/abs/2501.18988v1
"VKFPos: A Learning-Based Monocular Positioning with Variational Bayesian
  Extended Kalman Filter Integration",2025-01-31T09:54:11Z,"Jian-Yu Chen, Yi-Ru Chen, Yin-Qiao Chang, Che-Ming Li, Jann-Long Chern, Chih-Wei Huang","This paper addresses the challenges in learning-based monocular positioning
by proposing VKFPos, a novel approach that integrates Absolute Pose Regression
(APR) and Relative Pose Regression (RPR) via an Extended Kalman Filter (EKF)
within a variational Bayesian inference framework. Our method shows that the
essential posterior probability of the monocular positioning problem can be
decomposed into APR and RPR components. This decomposition is embedded in the
deep learning model by predicting covariances in both APR and RPR branches,
allowing them to account for associated uncertainties. These covariances
enhance the loss functions and facilitate EKF integration. Experimental
evaluations on both indoor and outdoor datasets show that the single-shot APR
branch achieves accuracy on par with state-of-the-art methods. Furthermore, for
temporal positioning, where consecutive images allow for RPR and EKF
integration, VKFPos outperforms temporal APR and model-based integration
methods, achieving superior accuracy.",http://arxiv.org/abs/2501.18994v1
"Assessing Sensitivity of Brain-to-Scalp Blood Flows in Laser Speckle
  Imaging by Occluding the Superficial Temporal Artery",2025-01-31T10:16:48Z,"Yu Xi Huang, Simon Mahler, Maya Dickson, Aidin Abedi, Yu Tung Lo, Patrick D. Lyden, Jonathan Russin, Charles Liu, Changhuei Yang","Cerebral blood flow is a critical metric for cerebrovascular monitoring, with
applications in stroke detection, brain injury evaluation, aging, and
neurological disorders. Non-invasively measuring cerebral blood dynamics is
challenging due to the scalp and skull, which obstruct direct brain access and
contain their own blood dynamics that must be isolated. We developed an
aggregated seven-channel speckle contrast optical spectroscopy system to
measure blood flow and blood volume non-invasively. Each channel, with distinct
source-to-detector distance, targeted different depths to detect scalp and
brain blood dynamics separately. By briefly occluding the superficial temporal
artery, which supplies blood only to the scalp, we isolated surface blood
dynamics from brain signals. Results on 20 subjects show that scalp-sensitive
channels experienced significant reductions in blood dynamics during occlusion,
while brain-sensitive channels experienced minimal changes. This provides
experimental evidence of brain-to-scalp sensitivity in optical measurements,
highlighting optimal configuration for preferentially probing brain signals
non-invasively.",http://arxiv.org/abs/2501.19005v1
Entanglement Entropy and Cauchy-Hadamard Renormalization,2025-01-31T10:26:32Z,"Benoit Estienne, Jiasheng Lin","This note presents a purely geometric construction of the so-called
twist-field correlation functions in Conformal Field Theory (CFT), derived from
conical singularities. This approach provides a purely mathematical
interpretation of the seminal results in physics by Cardy and Calabrese on the
entanglement entropy of quantum systems. Specifically, we begin by defining CFT
partition functions on surfaces with conical singularities, using a
``Cauchy-Hadamard renormalization'' of the Polyakov anomaly integral. Next, we
demonstrate that for a branched cover $f:\Sigma_d\to \Sigma$ with $d$ sheets,
where the cover inherits the pullback of a smooth metric from the base, a
specific ratio of partition functions on the cover to the base transforms under
conformal changes of the base metric in the same way as a correlation function
of CFT primary fields with specific conformal weights. We also provide a
discussion of the physical background and motivation for entanglement entropy,
focusing on path integrals and the replica trick, which serves as an
introduction to these ideas for a mathematical audience.",http://arxiv.org/abs/2501.19014v1
"Towards Physiologically Sensible Predictions via the Rule-based
  Reinforcement Learning Layer",2025-01-31T11:29:26Z,"Lingwei Zhu, Zheng Chen, Yukie Nagai, Jimeng Sun","This paper adds to the growing literature of reinforcement learning (RL) for
healthcare by proposing a novel paradigm: augmenting any predictor with
Rule-based RL Layer (RRLL) that corrects the model's physiologically impossible
predictions. Specifically, RRLL takes as input states predicted labels and
outputs corrected labels as actions. The reward of the state-action pair is
evaluated by a set of general rules. RRLL is efficient, general and
lightweight: it does not require heavy expert knowledge like prior work but
only a set of impossible transitions. This set is much smaller than all
possible transitions; yet it can effectively reduce physiologically impossible
mistakes made by the state-of-the-art predictor models. We verify the utility
of RRLL on a variety of important healthcare classification problems and
observe significant improvements using the same setup, with only the
domain-specific set of impossibility changed. In-depth analysis shows that RRLL
indeed improves accuracy by effectively reducing the presence of
physiologically impossible predictions.",http://arxiv.org/abs/2501.19055v1
"SmartDelta Methodology: Automated Quality Assurance and Optimization for
  Incremental System Engineering",2025-01-31T13:47:48Z,"Benedikt Dornauer Michael Felderer, Mehrdad Saadatmand, Muhammad Abbas, Nicolas Bonnotte, Andreas Dreschinski, Eduard Paul Enoiu, Eray Tüzün, Baykal Mehmet Uçar, Ömercan Devran, Robin Gröpler","Modern software systems undergo frequent updates, continuously evolving with
new versions and variants to offer new features, improve functionality, and
expand usability. Given the rapid pace of software evolution, organizations
require effective tools and methods to mitigate the challenges associated with
these changes, also called deltas. To address these challenges, the
international SmartDelta Project joined industry and academia to develop and
test solutions for incremental development and quality assurance. This paper
provides insights into the SmartDelta project achievements and highlights one
main contribution: the SmartDelta Methodology, a domain-unspecific concept for
delta management in incremental software engineering. This methodology enables
companies to identify gaps in their continuous engineering environment across
six stages and helps to discover new tools in various technical areas.
Additionally, the paper presents seven selected tools at different stages of
the methodology.",http://arxiv.org/abs/2501.19139v1
"E2Former: A Linear-time Efficient and Equivariant Transformer for
  Scalable Molecular Modeling",2025-01-31T15:22:58Z,"Yunyang Li, Lin Huang, Zhihao Ding, Chu Wang, Xinran Wei, Han Yang, Zun Wang, Chang Liu, Yu Shi, Peiran Jin, Jia Zhang, Mark Gerstein, Tao Qin","Equivariant Graph Neural Networks (EGNNs) have demonstrated significant
success in modeling microscale systems, including those in chemistry, biology
and materials science. However, EGNNs face substantial computational challenges
due to the high cost of constructing edge features via spherical tensor
products, making them impractical for large-scale systems. To address this
limitation, we introduce E2Former, an equivariant and efficient transformer
architecture that incorporates the Wigner $6j$ convolution (Wigner $6j$ Conv).
By shifting the computational burden from edges to nodes, the Wigner $6j$ Conv
reduces the complexity from $O(|\mathcal{E}|)$ to $ O(| \mathcal{V}|)$ while
preserving both the model's expressive power and rotational equivariance. We
show that this approach achieves a 7x-30x speedup compared to conventional
$\mathrm{SO}(3)$ convolutions. Furthermore, our empirical results demonstrate
that the derived E2Former mitigates the computational challenges of existing
approaches without compromising the ability to capture detailed geometric
information. This development could suggest a promising direction for scalable
and efficient molecular modeling.",http://arxiv.org/abs/2501.19216v2
"DINAMO: Dynamic and INterpretable Anomaly MOnitoring for Large-Scale
  Particle Physics Experiments",2025-01-31T15:51:41Z,"Arsenii Gavrikov, Julián García Pardiñas, Alberto Garfagnini","Ensuring reliable data collection in large-scale particle physics experiments
demands Data Quality Monitoring (DQM) procedures to detect possible detector
malfunctions and preserve data integrity. Traditionally, this
resource-intensive task has been handled by human shifters that struggle with
frequent changes in operational conditions. We present novel, interpretable,
robust, and scalable DQM algorithms designed to automate anomaly detection in
time-dependent settings. Our approach constructs evolving histogram templates
with built-in uncertainties, featuring both a statistical variant - extending
the classical Exponentially Weighted Moving Average (EWMA) - and a machine
learning (ML)-enhanced version that leverages a transformer encoder for
improved adaptability. Experimental validations on synthetic datasets
demonstrate the high accuracy, adaptability, and interpretability of these
methods, with the statistical variant being commissioned in the LHCb experiment
at the Large Hadron Collider, underscoring its real-world impact. The code used
in this study is available at https://github.com/ArseniiGav/DINAMO.",http://arxiv.org/abs/2501.19237v1
Linear $Q$-Learning Does Not Diverge: Convergence Rates to a Bounded Set,2025-01-31T16:10:50Z,"Xinyu Liu, Zixuan Xie, Shangtong Zhang","$Q$-learning is one of the most fundamental reinforcement learning
algorithms. Previously, it is widely believed that $Q$-learning with linear
function approximation (i.e., linear $Q$-learning) suffers from possible
divergence. This paper instead establishes the first $L^2$ convergence rate of
linear $Q$-learning to a bounded set. Notably, we do not make any modification
to the original linear $Q$-learning algorithm, do not make any Bellman
completeness assumption, and do not make any near-optimality assumption on the
behavior policy. All we need is an $\epsilon$-softmax behavior policy with an
adaptive temperature. The key to our analysis is the general result of
stochastic approximations under Markovian noise with fast-changing transition
functions. As a side product, we also use this general result to establish the
$L^2$ convergence rate of tabular $Q$-learning with an $\epsilon$-softmax
behavior policy, for which we rely on a novel pseudo-contraction property of
the weighted Bellman optimality operator.",http://arxiv.org/abs/2501.19254v1
The Solo Revolution: A Theory of AI-Enabled Individual Entrepreneurship,2025-01-07T01:34:13Z,Venkat Ram Reddy Ganuthula,"This paper presents the AI Enabled Individual Entrepreneurship Theory (AIET),
a theoretical framework explaining how artificial intelligence technologies
transform individual entrepreneurial capability. The theory identifies two
foundational premises: knowledge democratization and resource requirements
evolution. Through three core mechanisms skill augmentation, capital structure
transformation, and risk profile modification AIET explains how individuals can
now undertake entrepreneurial activities at scales previously requiring
significant organizational infrastructure. The theory presents five testable
propositions addressing the changing relationship between organizational size
and competitive advantage, the expansion of individual entrepreneurial
capacity, the transformation of market entry barriers, the evolution of
traditional firm advantages, and the modification of entrepreneurial risk
profiles. Boundary conditions related to task characteristics and market
conditions define the theory's scope and applicability. The framework suggests
significant implications for entrepreneurship theory, organizational design,
and market structure as AI capabilities continue to advance. This theory
provides a foundation for understanding the evolving landscape of
entrepreneurship in an AI-enabled world.",http://arxiv.org/abs/2502.00009v1
"A Dynamic and High-Precision Method for Scenario-Based HRA Synthetic
  Data Collection in Multi-Agent Collaborative Environments Driven by LLMs",2025-01-16T09:23:48Z,"Xingyu Xiao, Peng Chen, Qianqian Jia, Jiejuan Tong, Jingang Liang, Haitao Wang","HRA (Human Reliability Analysis) data is crucial for advancing HRA
methodologies. however, existing data collection methods lack the necessary
granularity, and most approaches fail to capture dynamic features.
Additionally, many methods require expert knowledge as input, making them
time-consuming and labor-intensive. To address these challenges, we propose a
new paradigm for the automated collection of HRA data. Our approach focuses on
key indicators behind human error, specifically measuring workload in
collaborative settings. This study introduces a novel, scenario-driven method
for workload estimation, leveraging fine-tuned large language models (LLMs). By
training LLMs on real-world operational data from high-temperature gas-cooled
reactors (HTGRs), we simulate human behavior and cognitive load in real time
across various collaborative scenarios. The method dynamically adapts to
changes in operator workload, providing more accurate, flexible, and scalable
workload estimates. The results demonstrate that the proposed WELLA (Workload
Estimation with LLMs and Agents) outperforms existing commercial LLM-based
methods in terms of prediction accuracy.",http://arxiv.org/abs/2502.00022v1
"Evolving Performance Practices in Beethoven's Cello Sonatas: Tempo,
  Portamento, and Historical Interpretation of the First Movements",2025-01-23T13:49:57Z,Ignasi Sole,"This paper examines the evolving performance practices of Ludwig van
Beethoven's cello sonatas, with a particular focus on tempo and portamento
between 1930 and 2012. It integrates analyses of 22 historical recordings,
advancements in recording technology to shed light on changes in interpretative
approaches. By comparing Beethoven's metronome markings, as understood through
contemporaries such as Czerny and Moscheles, with their application in modern
performances, my research highlights notable deviations. These differences
prove the challenges performers face in reconciling historical tempos with the
demands of contemporary performance practice. My study pays special attention
to the diminishing use of audible portamento in the latter half of the 20th
century, contrasted with a gradual increase in tempo after 1970. This
development is linked to broader cultural and pedagogical shifts, including the
adoption of fingering techniques that reduce hand shifts, thereby facilitating
greater technical precision at faster tempos. Nonetheless, my study identifies
the persistence of 'silent portamento' as an expressive device, allowing
performers to retain stylistic expression without compromising rhythmic
integrity. My paper offers valuable insights for performers and scholars alike,
advocating a critical reassessment of Beethoven's tempo markings and the
nuanced application of portamento in modern performance practice.",http://arxiv.org/abs/2502.00030v1
HadamRNN: Binary and Sparse Ternary Orthogonal RNNs,2025-01-28T09:16:28Z,"Armand Foucault, Franck Mamalet, François Malgouyres","Binary and sparse ternary weights in neural networks enable faster
computations and lighter representations, facilitating their use on edge
devices with limited computational power. Meanwhile, vanilla RNNs are highly
sensitive to changes in their recurrent weights, making the binarization and
ternarization of these weights inherently challenging. To date, no method has
successfully achieved binarization or ternarization of vanilla RNN weights. We
present a new approach leveraging the properties of Hadamard matrices to
parameterize a subset of binary and sparse ternary orthogonal matrices. This
method enables the training of orthogonal RNNs (ORNNs) with binary and sparse
ternary recurrent weights, effectively creating a specific class of binary and
sparse ternary vanilla RNNs. The resulting ORNNs, called HadamRNN and
lock-HadamRNN, are evaluated on benchmarks such as the copy task, permuted and
sequential MNIST tasks, and IMDB dataset. Despite binarization or sparse
ternarization, these RNNs maintain performance levels comparable to
state-of-the-art full-precision models, highlighting the effectiveness of our
approach. Notably, our approach is the first solution with binary recurrent
weights capable of tackling the copy task over 1000 timesteps.",http://arxiv.org/abs/2502.00047v2
Hyperluminous Supersoft X-ray Sources in the Chandra Catalog,2025-01-31T19:00:00Z,"Andrea Sacchi, Kevin Paggeot, Steven Dillmann, Juan Rafael Martinez-Galarza, Peter Kosec","Hyperluminous supersoft X-ray sources, such as bright extragalactic sources
characterized by particularly soft X-ray spectra, offer a unique opportunity to
study accretion onto supermassive black holes in extreme conditions. Examples
of hyperluminous supersoft sources are tidal disruption events, systems
exhibiting quasi-periodic eruptions, changing-look AGN, and anomalous nuclear
transients. Although these objects are rare phenomena amongst the population of
X-ray sources, we developed an efficient algorithm to identify promising
candidates exploiting archival observations. In this work, we present the
results of a search for hyperluminous supersoft X-ray sources in the recently
released Chandra catalog of serendipitous X-ray sources. This archival search
has been performed via both a manual implementation of the algorithm we
developed and a novel machine-learning-based approach. This search identified a
new tidal disruption event, which might have occurred in an intermediate-mass
black hole. This event occurred between 2001 and 2002, making it one of the
first tidal disruption events ever observed by Chandra.",http://arxiv.org/abs/2502.00097v1
Homotopy connectivity of Čech complexes of spheres,2025-01-31T19:14:56Z,"Henry Adams, Ekansh Jauhari, Sucharita Mallick","Let $S^n$ be the $n$-sphere with the geodesic metric and of diameter $\pi$.
The intrinsic \v{C}ech complex of $S^n$ at scale $r$ is the nerve of all open
balls of radius $r$ in $S^n$. In this paper, we show how to control the
homotopy connectivity of \v{C}ech complexes of spheres at each scale between
$0$ and $\pi$ in terms of coverings of spheres. Our upper bound on the
connectivity, which is sharp in the case $n=1$, comes from the chromatic
numbers of Borsuk graphs of spheres. Our lower bound is obtained using the
conicity (in the sense of Barmak) of \v{C}ech complexes of the sufficiently
dense, finite subsets of $S^n$. Our bounds imply the new result that for $n\ge
1$, the homotopy type of the \v{C}ech complex of $S^n$ at scale $r$ changes
infinitely many times as $r$ varies over $(0,\pi)$; we conjecture only
countably many times. Additionally, we lower bound the homological dimension of
\v{C}ech complexes of finite subsets of $S^n$ in terms of their packings.",http://arxiv.org/abs/2502.00122v1
"A definition of the mass aspect function for weakly regular
  asymptotically hyperbolic manifolds",2025-01-31T19:19:00Z,"Romain Gicquaud, Anna Sakovich","In contrast to the well-known and unambiguous notion of ADM mass for
asymptotically Euclidean manifolds, the notion of mass for asymptotically
hyperbolic manifolds admits several interpretations. Historically, there are
two approaches to defining the mass in the asymptotically hyperbolic setting:
the mass aspect function of Wang defined on the conformal boundary at infinity,
and the mass functional of Chru\'sciel and Herzlich which may be thought of as
the closest asymptotically hyperbolic analogue of the ADM mass. In this paper
we unify these two approaches by introducing an ADM-style definition of the
mass aspect function that applies to a broad range of asymptotics and in very
low regularity. Additionally, we show that the mass aspect function can be
computed using the Ricci tensor. Finally, we demonstrate that this function
exhibits favorable covariance properties under changes of charts at infinity,
which includes a proof of the asymptotic rigidity of hyperbolic space in the
context of weakly regular metrics.",http://arxiv.org/abs/2502.00125v1
"INSIGHT: Enhancing Autonomous Driving Safety through Vision-Language
  Models on Context-Aware Hazard Detection and Edge Case Evaluation",2025-02-01T01:43:53Z,"Dianwei Chen, Zifan Zhang, Yuchen Liu, Xianfeng Terry Yang","Autonomous driving systems face significant challenges in handling
unpredictable edge-case scenarios, such as adversarial pedestrian movements,
dangerous vehicle maneuvers, and sudden environmental changes. Current
end-to-end driving models struggle with generalization to these rare events due
to limitations in traditional detection and prediction approaches. To address
this, we propose INSIGHT (Integration of Semantic and Visual Inputs for
Generalized Hazard Tracking), a hierarchical vision-language model (VLM)
framework designed to enhance hazard detection and edge-case evaluation. By
using multimodal data fusion, our approach integrates semantic and visual
representations, enabling precise interpretation of driving scenarios and
accurate forecasting of potential dangers. Through supervised fine-tuning of
VLMs, we optimize spatial hazard localization using attention-based mechanisms
and coordinate regression techniques. Experimental results on the BDD100K
dataset demonstrate a substantial improvement in hazard prediction
straightforwardness and accuracy over existing models, achieving a notable
increase in generalization performance. This advancement enhances the
robustness and safety of autonomous driving systems, ensuring improved
situational awareness and potential decision-making in complex real-world
scenarios.",http://arxiv.org/abs/2502.00262v2
"Distributive Fairness in Large Language Models: Evaluating Alignment
  with Human Values",2025-02-01T04:24:47Z,"Hadi Hosseini, Samarth Khanna","The growing interest in employing large language models (LLMs) for
decision-making in social and economic contexts has raised questions about
their potential to function as agents in these domains. A significant number of
societal problems involve the distribution of resources, where fairness, along
with economic efficiency, play a critical role in the desirability of outcomes.
In this paper, we examine whether LLM responses adhere to fundamental fairness
concepts such as equitability, envy-freeness, and Rawlsian maximin, and
investigate their alignment with human preferences. We evaluate the performance
of several LLMs, providing a comparative benchmark of their ability to reflect
these measures. Our results demonstrate a lack of alignment between current LLM
responses and human distributional preferences. Moreover, LLMs are unable to
utilize money as a transferable resource to mitigate inequality. Nonetheless,
we demonstrate a stark contrast when (some) LLMs are tasked with selecting from
a predefined menu of options rather than generating one. In addition, we
analyze the robustness of LLM responses to variations in semantic factors (e.g.
intentions or personas) or non-semantic prompting changes (e.g. templates or
orderings). Finally, we highlight potential strategies aimed at enhancing the
alignment of LLM behavior with well-established fairness concepts.",http://arxiv.org/abs/2502.00313v1
"Flexible delivery of high-power picosecond laser in purely-single
  optical mode of anti-resonant hollow-core fiber for micromachining",2025-02-01T07:16:21Z,"Xinshuo Chang, Qinan Jiang, Zhiyuan Huang, Jinyu Pan, Qingwei Zhang, Nan Li, Zhuozhao Luo, Ruochen Yin, Wenbin He, Jiapeng Huang, Yuxin Leng, Xin Jiang, Shanglu Yang, Meng Pang","We present the flexible delivery of picosecond laser pulses with up to 20 W
average power over a 3-m-long sample of anti-resonant hollow-core fiber
(AR-HCF) for laser micromachining applications. Our experiments highlight the
importance of optical mode purity of the AR-HCF for the manufacturing
precision. We demonstrate that compared with an AR-HCF sample with a capillary
to core (d/D) ratio of ~0.5, the AR-HCF with a d/D ratio of ~0.68 exhibits
better capability of high-order-mode suppression, giving rise to improved
micromachining quality. Moreover, the AR-HCF delivery system exhibits better
pointing stability and set-up flexibility than the free-space beam delivery
system. These results pave the way to practical applications of AR-HCF in
developing advanced equipment for ultrafast laser micromachining.",http://arxiv.org/abs/2502.00353v1
"Latent Action Learning Requires Supervision in the Presence of
  Distractors",2025-02-01T09:35:51Z,"Alexander Nikulin, Ilya Zisman, Denis Tarasov, Nikita Lyubaykin, Andrei Polubarov, Igor Kiselev, Vladislav Kurenkov","Recently, latent action learning, pioneered by Latent Action Policies (LAPO),
have shown remarkable pre-training efficiency on observation-only data,
offering potential for leveraging vast amounts of video available on the web
for embodied AI. However, prior work has focused on distractor-free data, where
changes between observations are primarily explained by ground-truth actions.
Unfortunately, real-world videos contain action-correlated distractors that may
hinder latent action learning. Using Distracting Control Suite (DCS) we
empirically investigate the effect of distractors on latent action learning and
demonstrate that LAPO struggle in such scenario. We propose LAOM, a simple LAPO
modification that improves the quality of latent actions by 8x, as measured by
linear probing. Importantly, we show that providing supervision with
ground-truth actions, as few as 2.5% of the full dataset, during latent action
learning improves downstream performance by 4.2x on average. Our findings
suggest that integrating supervision during Latent Action Models (LAM) training
is critical in the presence of distractors, challenging the conventional
pipeline of first learning LAM and only then decoding from latent to
ground-truth actions.",http://arxiv.org/abs/2502.00379v1
"Explorations of the Softmax Space: Knowing When the Neural Network
  Doesn't Know...",2025-02-01T15:25:03Z,"Daniel Sikar, Artur d'Avila Garcez, Tillman Weyde","Ensuring the reliability and safety of automated decision-making is crucial.
This paper proposes a new approach for measuring the reliability of predictions
in machine learning models. We analyze how the outputs of a trained neural
network change using clustering to measure distances between outputs and class
centroids. We propose this distance as a metric to evaluate the confidence of
predictions. We assign each prediction to a cluster with centroid representing
the mean softmax output for all correct predictions of a given class. We then
define a safety threshold for a class as the smallest distance from an
incorrect prediction to the given class centroid. We evaluate the approach on
the MNIST and CIFAR-10 datasets using a Convolutional Neural Network and a
Vision Transformer, respectively. The results show that our approach is
consistent across these data sets and network models, and indicate that the
proposed metric can offer an efficient way of determining when automated
predictions are acceptable and when they should be deferred to human operators.",http://arxiv.org/abs/2502.00456v1
Oscillations Make Neural Networks Robust to Quantization,2025-02-01T16:39:58Z,"Jonathan Wenshøj, Bob Pepin, Raghavendra Selvan","We challenge the prevailing view that oscillations in Quantization Aware
Training (QAT) are merely undesirable artifacts caused by the Straight-Through
Estimator (STE). Through theoretical analysis of QAT in linear models, we
demonstrate that the gradient of the loss function can be decomposed into two
terms: the original full-precision loss and a term that causes quantization
oscillations. Based on these insights, we propose a novel regularization method
that induces oscillations to improve quantization robustness. Contrary to
traditional methods that focuses on minimizing the effects of oscillations, our
approach leverages the beneficial aspects of weight oscillations to preserve
model performance under quantization. Our empirical results on ResNet-18 and
Tiny ViT demonstrate that this counter-intuitive strategy matches QAT accuracy
at >= 3-bit weight quantization, while maintaining close to full precision
accuracy at bits greater than the target bit. Our work therefore provides a new
perspective on model preparation for quantization, particularly for finding
weights that are robust to changes in the bit of the quantizer -- an area where
current methods struggle to match the accuracy of QAT at specific bits.",http://arxiv.org/abs/2502.00490v1
"Looking into the Future of Health-Care Services: Can Life-Like Agents
  Change the Future of Health-Care Services?",2025-02-01T17:11:49Z,"Mohammad Saleh Torkestani, Robert Davis, Abdolhossein Sarrafzadeh","Time constraints on doctor patient interaction and restricted access to
specialists under the managed care system led to increasingly referring to
computers as a medical information source and a self-health-care management
tool. However, research show that less than 40% of information seekers
indicated that online information helped them to make a decision about their
health. Searching multiple web sites that need basic computer skills, lack of
interaction and no face to face interaction in most search engines and some
social issues, led us to develop a specialized life-like agent that would
overcome mentioned problems.",http://arxiv.org/abs/2502.00495v1
"Boundary element formulation of the Mild-Slope Equation for harmonic
  water waves propagating over unidirectional variable bathymetries",2025-02-01T19:50:15Z,"Antonio Cerrato, José A. González, Luis Rodríguez-Temblequer","This paper presents a boundary element formulation for the solution of the
Mild-Slope equation in wave propagation problems with variable water depth in
one direction. Based on the Green's function approximation proposed by
Belibassakis \cite{Belibassakis2000}, a complete fundamental-solution kernel is
developed and combined with a boundary element scheme for the solution of water
wave propagation problems in closed and open domains where the bathymetry
changes arbitrarily and smoothly in a preferential direction. The ability of
the proposed formulation to accurately represent wave phenomena like
refraction, reflection, diffraction and shoaling, is demonstrated with the
solution of some example problems, in which arbitrary geometries and variable
seabed profiles with slopes up to 1:3 are considered. The obtained results are
also compared with theoretical solutions, showing an excellent agreement that
demonstrates its potential.",http://arxiv.org/abs/2502.00540v1
"The Influence of Stellar Chromospheres and Coronae on Exoplanet
  Transmission Spectroscopy",2025-02-01T20:48:23Z,"Volker Perdelwitz, Adam Chaikin-Lifshitz, Aviv Ofir, Oded Aharonson","A main source of bias in transmission spectroscopy of exoplanet atmospheres
is magnetic activity of the host star in the form of stellar spots, faculae or
flares. However, the fact that main-sequence stars have a chromosphere and a
corona, and that these optically thin layers are dominated by line emission may
alter the global interpretation of the planetary spectrum, has largely been
neglected. Using a JWST NIRISS/SOSS data set of hot Jupiter HAT-P-18 b, we show
that even at near-IR and IR wavelengths, the presence of these layers leads to
significant changes in the transmission spectrum of the planetary atmosphere.
Accounting for these stellar outer layers thus improves the atmospheric fit of
HAT-P-18 b, and increases its best-fit atmospheric temperature from 536 K to
736 K, a value much closer to the predicted equilibrium temperature of 852 K.
Our analysis also decreases the best-fit abundance of CO2 by almost an order of
magnitude. The approach provides a new window to the properties of
chromospheres/corona in stars other than our Sun.",http://arxiv.org/abs/2502.00553v1
"Defense Against the Dark Prompts: Mitigating Best-of-N Jailbreaking with
  Prompt Evaluation",2025-02-01T22:26:30Z,"Stuart Armstrong, Matija Franklin, Connor Stevens, Rebecca Gorman","Recent work showed Best-of-N (BoN) jailbreaking using repeated use of random
augmentations (such as capitalization, punctuation, etc) is effective against
all major large language models (LLMs). We have found that $100\%$ of the BoN
paper's successful jailbreaks (confidence interval $[99.65\%, 100.00\%]$) and
$99.8\%$ of successful jailbreaks in our replication (confidence interval
$[99.28\%, 99.98\%]$) were blocked with our Defense Against The Dark Prompts
(DATDP) method. The DATDP algorithm works by repeatedly utilizing an evaluation
LLM to evaluate a prompt for dangerous or manipulative behaviors--unlike some
other approaches, DATDP also explicitly looks for jailbreaking attempts--until
a robust safety rating is generated. This success persisted even when utilizing
smaller LLMs to power the evaluation (Claude and LLaMa-3-8B-instruct proved
almost equally capable). These results show that, though language models are
sensitive to seemingly innocuous changes to inputs, they seem also capable of
successfully evaluating the dangers of these inputs. Versions of DATDP can
therefore be added cheaply to generative AI systems to produce an immediate
significant increase in safety.",http://arxiv.org/abs/2502.00580v1
"Integrating Cybersecurity Frameworks into IT Security: A Comprehensive
  Analysis of Threat Mitigation Strategies and Adaptive Technologies",2025-02-02T03:38:48Z,"Amit Lokare, Shripad Bankar, Padmajeet Mhaske","The cybersecurity threat landscape is constantly actively making it
imperative to develop sound frameworks to protect the IT structures. Based on
this introduction, this paper aims to discuss the application of cybersecurity
frameworks into the IT security with focus placed on the role of such
frameworks in addressing the changing nature of cybersecurity threats. It
explores widely used models, including the NIST Cybersecurity Framework, Zero
Trust Architecture, and the ISO/IEC 27001, and how they apply to industries
including finance, healthcare and government. The discussion also singles out
such technologies as Artificial Intelligence (AI) and Machine Learning (ML) as
the core for real-time threat detection and response mechanisms. As these
integration challenges demonstrate, the study provides tangible and proven
approaches to tackle framework implementation issues such as legitimate
security issues, limited availability of funds and resources, and compliance
with legal requirements. By capturing current trends and exposures, the
findings promote strong, portfolio-based and risk-appropriate security
approaches adjusted for organizational goals and capable to prevent advanced
cyber threats.",http://arxiv.org/abs/2502.00651v1
"Topological flow data analysis for transient flow patterns: a
  graph-based approach",2025-02-02T04:36:33Z,"Takashi Sakajo, Takeshi Matsumoto, Shizuo Kaji, Tomoo Yokoyama, Tomoki Uda","We introduce a time-series analysis method for transient two-dimensional flow
patterns based on Topological Flow Data Analysis (TFDA), a new approach to
topological data analysis. TFDA identifies local topological flow structures
from an instantaneous streamline pattern and describes their global connections
as a unique planar tree and its string representation. With TFDA, the evolution
of two-dimensional flow patterns is reduced to a discrete dynamical system
represented as a transition graph between topologically equivalent streamline
patterns. We apply this method to study the lid-driven cavity flow at Reynolds
numbers ranging from $Re=14000$ to $Re=16000$, a benchmark problem in fluid
dynamics data analysis. Our approach reveals the transition from periodic to
chaotic flow at a critical Reynolds number when the reduced dynamical system is
modelled as a Markov process on the transition graph. Additionally, we perform
an observational causal inference to analyse changes in local flow patterns at
the cavity corners and discuss differences with a standard interventional
sensitivity analysis. This work demonstrates the potential of TFDA-based
time-series analysis for uncovering complex dynamical behaviours in fluid flow
data.",http://arxiv.org/abs/2502.00664v1
High-Order Matching for One-Step Shortcut Diffusion Models,2025-02-02T06:19:59Z,"Bo Chen, Chengyue Gong, Xiaoyu Li, Yingyu Liang, Zhizhou Sha, Zhenmei Shi, Zhao Song, Mingda Wan","One-step shortcut diffusion models [Frans, Hafner, Levine and Abbeel, ICLR
2025] have shown potential in vision generation, but their reliance on
first-order trajectory supervision is fundamentally limited. The Shortcut
model's simplistic velocity-only approach fails to capture intrinsic manifold
geometry, leading to erratic trajectories, poor geometric alignment, and
instability-especially in high-curvature regions. These shortcomings stem from
its inability to model mid-horizon dependencies or complex distributional
features, leaving it ill-equipped for robust generative modeling. In this work,
we introduce HOMO (High-Order Matching for One-Step Shortcut Diffusion), a
game-changing framework that leverages high-order supervision to revolutionize
distribution transportation. By incorporating acceleration, jerk, and beyond,
HOMO not only fixes the flaws of the Shortcut model but also achieves
unprecedented smoothness, stability, and geometric precision. Theoretically, we
prove that HOMO's high-order supervision ensures superior approximation
accuracy, outperforming first-order methods. Empirically, HOMO dominates in
complex settings, particularly in high-curvature regions where the Shortcut
model struggles. Our experiments show that HOMO delivers smoother trajectories
and better distributional alignment, setting a new standard for one-step
generative models.",http://arxiv.org/abs/2502.00688v1
"Magnetic-Field Dependence of Paramagnetic Properties Investigated by
  63/65Cu-NMR on the Yb Zigzag-Chain Semiconductor YbCuS2",2025-02-02T16:01:46Z,"Fumiya Hori, Shunsaku Kitagawa, Kenji Ishida, Yudai Ohmagari, Takahiro Onimaru","To investigate the paramagnetic properties of YbCuS2 under magnetic fields,
we have performed the 63/65Cu-nuclear magnetic resonance (NMR) measurements.
The NMR spectra can be reproduced by the simulations of the three-dimensional
powder pattern and the additional two-dimensional powder pattern, indicating
the partial sample orientation due to the anisotropy of the magnetic
properties. These simulations suggest that the ac plane is the easy plane in
YbCuS2. The Knight shift K is proportional to the bulk magnetic susceptibility
and field-independent. The broad maximum of the nuclear spin-lattice relaxation
rate 1/T1 at Tmax ~ 50 K (50 K anomaly) observed at zero magnetic field is
quickly suppressed by the magnetic fields. This indicates that the 50 K anomaly
is field-dependent. Furthermore, an anomalous enhancement of 1/T1 at low
temperatures was observed above 3 T. This field seemingly corresponds to the
magnetic field at which a field-induced phase transition occurs below the
antiferromagnetic transition temperature TN ~ 1 K. The changes in 1/T1 observed
in the paramagnetic state suggest the presence of the complex quantum phenomena
under magnetic fields in YbCuS2.",http://arxiv.org/abs/2502.00830v1
Developing Compelling Safety Cases,2025-02-02T20:47:30Z,Richard Hawkins,"This paper describes a method for creating compelling safety cases. The
method seeks to help improve safety case practice in order to address the
weaknesses identified in current practice, in particular confirmation bias,
after-the-fact assurance and safety cases as a paperwork exercise. Rather than
creating new notations and tools to address these issues, we contend that it is
improvements in the safety case process that will make the most significant
improvement to safety case practice. Our method builds upon established
approaches and best practice to create an approach that will ensure safety
cases are risk-focused, seek to identify ways in which the system may not be
safe (rather than just assuming it is), drive safe design and operation of the
system (influencing the system itself rather than just documenting what's
there), are used to support decisions made throughout the life of the system,
including system operation and change, and encourage developers and operators
to think about and understand why their system is safe (and when it isn't). A
simple example of an infusion pump system is used to illustrate how the new
method is applied in practice.",http://arxiv.org/abs/2502.00911v1
Huff-LLM: End-to-End Lossless Compression for Efficient LLM Inference,2025-02-02T21:23:42Z,"Patrick Yubeaton, Tareq Mahmoud, Shehab Naga, Pooria Taheri, Tianhua Xia, Arun George, Yasmein Khalil, Sai Qian Zhang, Siddharth Joshi, Chinmay Hegde, Siddharth Garg","As they become more capable, large language models (LLMs) have continued to
rapidly increase in size. This has exacerbated the difficulty in running state
of the art LLMs on small, edge devices. Standard techniques advocate solving
this problem through lossy compression techniques such as quantization or
pruning. However, such compression techniques are lossy, and have been shown to
change model behavior in unpredictable manners. We propose Huff-LLM, an
\emph{end-to-end, lossless} model compression method that lets users store LLM
weights in compressed format \emph{everywhere} -- cloud, disk, main memory, and
even in on-chip memory/buffers. This allows us to not only load larger models
in main memory, but also reduces bandwidth required to load weights on chip,
and makes more efficient use of on-chip weight buffers. In addition to the
memory savings achieved via compression, we also show latency and energy
efficiency improvements when performing inference with the compressed model.",http://arxiv.org/abs/2502.00922v1
Dark energy and cosmic acceleration,2025-02-02T21:27:16Z,"Rodrigo von Marttens, Jailson Alcaniz","The discovery that we live in an accelerating universe changed drastically
the paradigm of physics and introduced the concept of \textit{dark energy}. In
this work, we present a brief historical description of the main events related
to the discovery of cosmic acceleration and the basic elements of theoretical
and observational aspects of dark energy. Regarding the historical perspective,
we outline some of the key milestones for tracing the journey from Einstein's
proposal of the cosmological constant to the type Ia supernovae results.
Conversely, on the theoretical/observational side, we begin by analyzing cosmic
acceleration within the context of the standard cosmological model, i.e., in
terms of the cosmological constant. In this case, we show how a positive
cosmological constant drives accelerated expansion and discuss the main
observational aspects, such as updated results and current cosmological
tensions. We also explore alternative descriptions of dark energy, encompassing
dynamic and interacting dark energy models.",http://arxiv.org/abs/2502.00923v1
"Analysis of static and dynamic batching algorithms for graph neural
  networks",2025-02-02T22:34:17Z,"Daniel Speckhard, Tim Bechtel, Sebastian Kehl, Jonathan Godwin, Claudia Draxl","Graph neural networks (GNN) have shown promising results for several domains
such as materials science, chemistry, and the social sciences. GNN models often
contain millions of parameters, and like other neural network (NN) models, are
often fed only a fraction of the graphs that make up the training dataset in
batches to update model parameters. The effect of batching algorithms on
training time and model performance has been thoroughly explored for NNs but
not yet for GNNs. We analyze two different batching algorithms for graph based
models, namely static and dynamic batching. We use the Jraph library built on
JAX to perform our experiments, where we compare the two batching methods for
two datasets, the QM9 dataset of small molecules and the AFLOW materials
database. Our experiments show that significant training time savings can be
found from changing the batching algorithm, but the fastest algorithm depends
on the data, model, batch size and number of training steps run. Experiments
show no significant difference in model learning between the algorithms.",http://arxiv.org/abs/2502.00944v1
"SatFlow: Generative model based framework for producing High Resolution
  Gap Free Remote Sensing Imagery",2025-02-03T06:40:13Z,"Bharath Irigireddy, Varaprasad Bandaru","Frequent, high-resolution remote sensing imagery is crucial for agricultural
and environmental monitoring. Satellites from the Landsat collection offer
detailed imagery at 30m resolution but with lower temporal frequency, whereas
missions like MODIS and VIIRS provide daily coverage at coarser resolutions.
Clouds and cloud shadows contaminate about 55\% of the optical remote sensing
observations, posing additional challenges. To address these challenges, we
present SatFlow, a generative model-based framework that fuses low-resolution
MODIS imagery and Landsat observations to produce frequent, high-resolution,
gap-free surface reflectance imagery. Our model, trained via Conditional Flow
Matching, demonstrates better performance in generating imagery with preserved
structural and spectral integrity. Cloud imputation is treated as an image
inpainting task, where the model reconstructs cloud-contaminated pixels and
fills gaps caused by scan lines during inference by leveraging the learned
generative processes. Experimental results demonstrate the capability of our
approach in reliably imputing cloud-covered regions. This capability is crucial
for downstream applications such as crop phenology tracking, environmental
change detection etc.,",http://arxiv.org/abs/2502.01098v1
GTG: Generalizable Trajectory Generation Model for Urban Mobility,2025-02-03T06:53:35Z,"Jingyuan Wang, Yujing Lin, Yudong Li","Trajectory data mining is crucial for smart city management. However,
collecting large-scale trajectory datasets is challenging due to factors such
as commercial conflicts and privacy regulations. Therefore, we urgently need
trajectory generation techniques to address this issue. Existing trajectory
generation methods rely on the global road network structure of cities. When
the road network structure changes, these methods are often not transferable to
other cities. In fact, there exist invariant mobility patterns between
different cities: 1) People prefer paths with the minimal travel cost; 2) The
travel cost of roads has an invariant relationship with the topological
features of the road network. Based on the above insight, this paper proposes a
Generalizable Trajectory Generation model (GTG). The model consists of three
parts: 1) Extracting city-invariant road representation based on Space Syntax
method; 2) Cross-city travel cost prediction through disentangled adversarial
training; 3) Travel preference learning by shortest path search and preference
update. By learning invariant movement patterns, the model is capable of
generating trajectories in new cities. Experiments on three datasets
demonstrates that our model significantly outperforms existing models in terms
of generalization ability.",http://arxiv.org/abs/2502.01107v1
Dense and magnetized QCD from imaginary chemical potential,2025-02-03T07:57:44Z,"Szabolcs Borsányi, Bastian Brandt, Gergely Endrődi, Jana Guenther, Marc-André Petri, Adeilton Dean Marques Valois, Lukas Varnhorst","In this work, we computed the equation of state of dense QCD in the presence
of background magnetic fields using lattice QCD simulations at imaginary baryon
chemical potential. Our simulations include 2+1+1 flavors of stout-smeared
staggered fermions with masses at the physical point and a tree-level
Symanzik-improved gauge action. Using several expansion schemes, we tuned our
simulation parameters such that the equation of state satisfies strangeness
neutrality and isospin asymmetry constraints, which are relevant to the
phenomenology of heavy-ion collisions. Our results suggest a strong change in
the equation of state due to the magnetic field, in particular, around the
crossover temperature. A continuum extrapolation of our data is still needed
for future applications of our equation of state to heavy-ion-collision
phenomenology.",http://arxiv.org/abs/2502.01132v2
"Efficient and Scalable Density Functional Theory Hamiltonian Prediction
  through Adaptive Sparsity",2025-02-03T09:04:47Z,"Erpai Luo, Xinran Wei, Lin Huang, Yunyang Li, Han Yang, Zun Wang, Chang Liu, Zaishuo Xia, Jia Zhang, Bin Shao","Hamiltonian matrix prediction is pivotal in computational chemistry, serving
as the foundation for determining a wide range of molecular properties. While
SE(3) equivariant graph neural networks have achieved remarkable success in
this domain, their substantial computational cost-driven by high-order tensor
product (TP) operations-restricts their scalability to large molecular systems
with extensive basis sets. To address this challenge, we introduce SPHNet, an
efficient and scalable equivariant network that incorporates adaptive sparsity
into Hamiltonian prediction. SPHNet employs two innovative sparse gates to
selectively constrain non-critical interaction combinations, significantly
reducing tensor product computations while maintaining accuracy. To optimize
the sparse representation, we develop a Three-phase Sparsity Scheduler,
ensuring stable convergence and achieving high performance at sparsity rates of
up to 70 percent. Extensive evaluations on QH9 and PubchemQH datasets
demonstrate that SPHNet achieves state-of-the-art accuracy while providing up
to a 7x speedup over existing models. Beyond Hamiltonian prediction, the
proposed sparsification techniques also hold significant potential for
improving the efficiency and scalability of other SE(3) equivariant networks,
further broadening their applicability and impact.",http://arxiv.org/abs/2502.01171v1
"DRL-based Dolph-Tschebyscheff Beamforming in Downlink Transmission for
  Mobile Users",2025-02-03T11:50:43Z,"Nancy Nayak, Kin K. Leung, Lajos Hanzo","With the emergence of AI technologies in next-generation communication
systems, machine learning plays a pivotal role due to its ability to address
high-dimensional, non-stationary optimization problems within dynamic
environments while maintaining computational efficiency. One such application
is directional beamforming, achieved through learning-based blind beamforming
techniques that utilize already existing radio frequency (RF) fingerprints of
the user equipment obtained from the base stations and eliminate the need for
additional hardware or channel and angle estimations. However, as the number of
users and antenna dimensions increase, thereby expanding the problem's
complexity, the learning process becomes increasingly challenging, and the
performance of the learning-based method cannot match that of the optimal
solution. In such a scenario, we propose a deep reinforcement learning-based
blind beamforming technique using a learnable Dolph-Tschebyscheff antenna array
that can change its beam pattern to accommodate mobile users. Our simulation
results show that the proposed method can support data rates very close to the
best possible values.",http://arxiv.org/abs/2502.01278v1
"Improving the Effectiveness of Potential-Based Reward Shaping in
  Reinforcement Learning",2025-02-03T12:32:50Z,"Henrik Müller, Daniel Kudenko","Potential-based reward shaping is commonly used to incorporate prior
knowledge of how to solve the task into reinforcement learning because it can
formally guarantee policy invariance. As such, the optimal policy and the
ordering of policies by their returns are not altered by potential-based reward
shaping. In this work, we highlight the dependence of effective potential-based
reward shaping on the initial Q-values and external rewards, which determine
the agent's ability to exploit the shaping rewards to guide its exploration and
achieve increased sample efficiency. We formally derive how a simple linear
shift of the potential function can be used to improve the effectiveness of
reward shaping without changing the encoded preferences in the potential
function, and without having to adjust the initial Q-values, which can be
challenging and undesirable in deep reinforcement learning. We show the
theoretical limitations of continuous potential functions for correctly
assigning positive and negative reward shaping values. We verify our
theoretical findings empirically on Gridworld domains with sparse and
uninformative reward functions, as well as on the Cart Pole and Mountain Car
environments, where we demonstrate the application of our results in deep
reinforcement learning.",http://arxiv.org/abs/2502.01307v1
"Quantum Geometric Origin of Strain-Induced Ferroelectric Phase
  Transitions",2025-02-03T15:53:28Z,"Jiaming Hu, Ziye Zhu, Yubo Yuan, Wenbin Li, Hua Wang, Kai Chang","Strain-regulated ferroelectric (FE) materials have long attracted significant
attention due to their diverse applications. While soft-phonon theory and the
(pseudo) Jahn-Teller effect have achieved considerable success in providing
phenomenological descriptions and general understanding, the detailed
connection between these perspectives and their microscopic dependence on
strain regulation remains unclear. Here, under the framework of
density-functional perturbation theory (DFPT), we demonstrate that the Berry
curvature of electron-phonon coupling (EPC) plays a pivotal role in the
interatomic force matrix (IFM). A subsequent model analysis shows that external
strain can reverse the polarity of the EPC Berry curvature in
(quasi)-degenerate electronic subsystems through band inversion, thereby
directly leading to phonon softening. The general theory is then applied to the
BiOCl monolayer as a benchmark, which offers an accurate description of the
density functional theory (DFT) calculations. This mechanism is further
observed across a broad range of materials through ab initio calculations,
providing an insightful perspective on EPC quantum geometry in lattice dynamics
and FE phase transitions.",http://arxiv.org/abs/2502.01463v2
Off-shell phase diagram of BPS black holes in AdS$_5$,2025-02-03T16:53:06Z,"Debabrata Sahu, Chandrasekhar Bhamidipati","We construct the off-shell free energy of supersymmetric black holes in
AdS$_5$, and study the phase diagram in various limiting cases, with particular
emphasis on BPS thermodynamics. The changes to the free energy following from
the four-derivative corrections to five-dimensional minimal gauged supergravity
action are computed, and the modifications to the phase diagram are studied.
Starting from Landau's theory, an exact method is systematically developed to
construct the off shell BPS free energy, which in certain limiting cases, can
be rearranged in terms of an effective energy and entropy of the system, with
the later being conjugate to an effective BPS temperature. The off-shell BPS
phase diagram shows features which resemble the phases of general AdS
Schwarzschild black holes, with some nuances in the asymptotic structure,
modified by four-derivative corrections. Using AdS/CFT, phenomenological
effective potentials in the boundary gauge theory are proposed, dual to both
general black holes and their BPS counterparts. The saddle points of the
effective potential capture the various locally stable and unstable phases of
the gauge theory at finite temperature and chemical potential.",http://arxiv.org/abs/2502.01519v1
"Self-Improving Transformers Overcome Easy-to-Hard and Length
  Generalization Challenges",2025-02-03T18:45:22Z,"Nayoung Lee, Ziyang Cai, Avi Schwarzschild, Kangwook Lee, Dimitris Papailiopoulos","Large language models often struggle with length generalization and solving
complex problem instances beyond their training distribution. We present a
self-improvement approach where models iteratively generate and learn from
their own solutions, progressively tackling harder problems while maintaining a
standard transformer architecture. Across diverse tasks including arithmetic,
string manipulation, and maze solving, self-improving enables models to solve
problems far beyond their initial training distribution-for instance,
generalizing from 10-digit to 100-digit addition without apparent saturation.
We observe that in some cases filtering for correct self-generated examples
leads to exponential improvements in out-of-distribution performance across
training rounds. Additionally, starting from pretrained models significantly
accelerates this self-improvement process for several tasks. Our results
demonstrate how controlled weak-to-strong curricula can systematically teach a
model logical extrapolation without any changes to the positional embeddings,
or the model architecture.",http://arxiv.org/abs/2502.01612v2
AI Scaling: From Up to Down and Out,2025-02-02T02:14:00Z,"Yunke Wang, Yanxi Li, Chang Xu","AI Scaling has traditionally been synonymous with Scaling Up, which builds
larger and more powerful models. However, the growing demand for efficiency,
adaptability, and collaboration across diverse applications necessitates a
broader perspective. This position paper presents a holistic framework for AI
scaling, encompassing Scaling Up, Scaling Down, and Scaling Out. It argues that
while Scaling Up of models faces inherent bottlenecks, the future trajectory of
AI scaling lies in Scaling Down and Scaling Out. These paradigms address
critical technical and societal challenges, such as reducing carbon footprint,
ensuring equitable access, and enhancing cross-domain collaboration. We explore
transformative applications in healthcare, smart manufacturing, and content
creation, demonstrating how AI Scaling can enable breakthroughs in efficiency,
personalization, and global connectivity. Additionally, we highlight key
challenges, including balancing model complexity with interpretability,
managing resource constraints, and fostering ethical development. By
synthesizing these approaches, we propose a unified roadmap that redefines the
future of AI research and application, paving the way for advancements toward
Artificial General Intelligence (AGI).",http://arxiv.org/abs/2502.01677v1
On Bob Dylan: A Computational Perspective,2025-02-03T19:25:08Z,Prashant Garg,"Cass Sunstein's essay 'On Bob Dylan' describes Dylan's 'dishabituating' style
-- a constant refusal to conform to expectation and a penchant for reinventing
his musical and lyrical identity. In this paper, I extend Sunstein's
observations through a large-scale computational analysis of Dylan's lyrics
from 1962 to 2012. Using o3-mini-high (a large language model), I extract
concept-to-concept relationships from the lyrics and construct directed
knowledge graphs that capture Dylan's thematic structure. I then quantify
shifts in sentiment, metaphorical expression, thematic diversity, and network
complexity over time. The results indicate that Dylan's lyrics increasingly
rely on metaphor, display an evolving sentiment profile, and exhibit heightened
dishabituation -- measured here as a growing variance in the network centrality
of key concepts. I also find that references to movement, protest, and mythic
imagery fluctuate in ways that align with well-known phases of Dylan's career,
reflecting the dynamic and unpredictable quality of his art. These findings not
only deepen our empirical understanding of Sunstein's thesis but also introduce
a novel computational method for analyzing an artist's evolution-offering
broader applicability to the study of cultural and creative change.",http://arxiv.org/abs/2502.01772v1
Geometric Framework for 3D Cell Segmentation Correction,2025-02-03T23:47:45Z,"Peter Chen, Bryan Chang, Olivia Annette Creasey, Julie Beth Sneddon, Yining Liu","3D cellular image segmentation methods are commonly divided into non-2D-based
and 2D-based approaches, the latter reconstructing 3D shapes from the
segmentation results of 2D layers. However, errors in 2D results often
propagate, leading to oversegmentations in the final 3D results. To tackle this
issue, we introduce an interpretable geometric framework that addresses the
oversegmentations by correcting the 2D segmentation results based on geometric
information from adjacent layers. Leveraging both geometric (layer-to-layer,
2D) and topological (3D shape) features, we use binary classification to
determine whether neighboring cells should be stitched. We develop a
pre-trained classifier on public plant cell datasets and validate its
performance on animal cell datasets, confirming its effectiveness in correcting
oversegmentations under the transfer learning setting. Furthermore, we
demonstrate that our framework can be extended to correcting oversegmentation
on non-2D-based methods. A clear pipeline is provided for end-users to build
the pre-trained model to any labeled dataset.",http://arxiv.org/abs/2502.01890v1
"Generalizable and Fast Surrogates: Model Predictive Control of
  Articulated Soft Robots using Physics-Informed Neural Networks",2025-02-04T01:16:33Z,"Tim-Lukas Habich, Aran Mohammad, Simon F. G. Ehlers, Martin Bensch, Thomas Seel, Moritz Schappler","Soft robots can revolutionize several applications with high demands on
dexterity and safety. When operating these systems, real-time estimation and
control require fast and accurate models. However, prediction with
first-principles (FP) models is slow, and learned black-box models have poor
generalizability. Physics-informed machine learning offers excellent advantages
here, but it is currently limited to simple, often simulated systems without
considering changes after training. We propose physics-informed neural networks
(PINNs) for articulated soft robots (ASRs) with a focus on data efficiency. The
amount of expensive real-world training data is reduced to a minimum - one
dataset in one system domain. Two hours of data in different domains are used
for a comparison against two gold-standard approaches: In contrast to a
recurrent neural network, the PINN provides a high generalizability. The
prediction speed of an accurate FP model is improved with the PINN by up to a
factor of 466 at slightly reduced accuracy. This enables nonlinear model
predictive control (MPC) of the pneumatic ASR. In nine dynamic MPC experiments,
an average joint-tracking error of 1.3{\deg} is achieved.",http://arxiv.org/abs/2502.01916v1
"Improving Software Engineering Team Communication Through Stronger
  Social Networks",2025-02-04T01:46:26Z,"April Clarke, Tanja Mitrović, Fabian Gilson","Students working in teams in software engineering group project often
communicate ineffectively, which reduces the quality of deliverables, and is
therefore detrimental for project success. An important step towards addressing
areas of improvement is identifying which changes to communication will improve
team performance the most. We applied two different communication analysis
techniques, triad census and socio-technical congruence, to data gathered from
a two-semester software engineering group project. Triad census uses the
presence of edges between groups of three nodes as a measure of network
structure, while socio-technical congruence compares the fit of a team's
communication to their technical dependencies. Our findings suggest that each
team's triad census for a given sprint is promising as a predictor of the
percentage of story points they pass, which is closely linked to project
success. Meanwhile, socio-technical congruence is inadequate as the sole metric
for predicting project success in this context. We discuss these findings, and
their potential applications improve communication in a software engineering
group project.",http://arxiv.org/abs/2502.01923v1
"Mitigating Object Hallucinations in Large Vision-Language Models via
  Attention Calibration",2025-02-04T03:27:38Z,"Younan Zhu, Linwei Tao, Minjing Dong, Chang Xu","Large Vision-Language Models (LVLMs) exhibit impressive multimodal reasoning
capabilities but remain highly susceptible to object hallucination, where
models generate responses that are not factually aligned with the visual
content. Recent works attribute this issue to an inherent bias of LVLMs where
vision token attention map has a fixed correlation with spatial position, and
propose to mitigate this issue by reordering visual tokens. However, we find
that different LVLMs exhibit different correlations between attention and
spatial position, which makes the existing solution difficult to generalize to
other LVLMs. To address this issue, we first introduce a training-free
solution, Uniform Attention Calibration (UAC), that estimates the bias from
single meaningless input image and applies a calibration matrix to rectify
attention imbalances. To further alleviate the bias, we relax the assumption of
single meaningless input in UAC and introduce a fine-tuning solution, Dynamic
Attention Calibration (DAC), that enforces the consistent outputs wherever the
object locates in the image via a plug-and-plays module. Comprehensive
experiments across multiple benchmarks demonstrate that UAC and DAC
significantly reduce object hallucination while improving general multimodal
alignment. Our methods achieve state-of-the-art performance across diverse LVLM
architectures on various metrics.",http://arxiv.org/abs/2502.01969v1
"Normalized solutions to focusing Sobolev critical biharmonic
  Schrödinger equation with mixed dispersion",2025-02-04T06:30:43Z,"Jianlun Liu, Hong-Rui Sun, Ziheng Zhang","This paper is concerned with the following focusing biharmonic
Schr\""{o}dinger equation with mixed dispersion and Sobolev critical growth: $$
\begin{cases}
  {\Delta}^2u-\Delta u-\lambda u-\mu|u|^{p-2}u-|u|^{4^*-2}u=0\ \ \mbox{in}\
\mathbb{R}^N, \\[0.1cm]
  \int_{\mathbb{R}^N} u^2 dx = c, \end{cases} $$ where $N \geq 5$, $\mu,c>0$,
$2<p<4^*:=\frac{2N}{N-4}$ and $\lambda \in \mathbb{R}$ is a Lagrange
multiplier. For this problem, under the $L^2$-subcritical perturbation
($2<p<2+\frac{8}{N}$), we derive the existence and multiplicity of normalized
solutions via the truncation technique, concentration-compactness principle and
the genus theory presented by C.O. Alves et al. (Arxiv, (2021), doi:
2103.07940v2). Compared to the results of C.O. Alves et al. we obtain a more
general result after removing the further assumptions given in (3.2) of their
paper. In the case of $L^2$-supercritical perturbation ($2+\frac{8}{N}<p<4^*$),
we explore the existence results of normalized solutions by applying the
constrained variational methods and the mountain pass theorem. Moreover, we
propose a novel method to address the effects of the dispersion term $\Delta
u$. This approach allows us to extend the recent results obtained by X. Chang
et al. (Arxiv, (2023), doi: 2305.00327v1) to the mixed dispersion situation.",http://arxiv.org/abs/2502.02049v1
On Squared-Variable Formulations for Nonlinear Semidefinite programming,2025-02-04T08:30:34Z,"Lijun Ding, Stephen J. Wright","In optimization problems involving smooth functions and real and matrix
variables, that contain matrix semidefiniteness constraints, consider the
following change of variables: Replace the positive semidefinite matrix $X \in
\mathbb{S}^d$, where $\mathbb{S}^d$ is the set of symmetric matrices in
$\mathbb{R}^{d\times d}$, by a matrix product $FF^\top$, where $F \in
\mathbb{R}^{d \times d}$ or $F \in \mathbb{S}^d$. The formulation obtained in
this way is termed ``squared variable,"" by analogy with a similar idea that has
been proposed for real (scalar) variables. It is well known that points
satisfying first-order conditions for the squared-variable reformulation do not
necessarily yield first-order points for the original problem. There are closer
correspondences between second-order points for the squared-variable
reformulation and the original formulation. These are explored in this paper,
along with correspondences between local minimizers of the two formulations.",http://arxiv.org/abs/2502.02099v1
"Molecular Pseudorotation in Phthalocyanines as a Tool for Magnetic Field
  Control at the Nanoscale",2025-02-04T09:44:18Z,"Raphael Wilhelmer, Matthias Diez, Johannes K. Krondorfer, Andreas W. Hauser","Metal phthalocyanines, a highly versatile class of aromatic, planar,
macrocyclic molecules with a chelated central metal ion, are topical objects of
ongoing research and particularly interesting due to their magnetic properties.
However, while current focus lies almost exclusively on spin-Zeeman-related
effects, the high symmetry of the molecule and its circular shape suggests the
exploitation of light-induced excitation of twofold degenerate vibrational
states in order to generate, switch and manipulate magnetic fields at the
nanoscale. The underlying mechanism is a molecular pseudorotation that can be
triggered by infrared pulses and gives rise to a quantized, small but
controllable magnetic dipole moment. We investigate the optical stimulation of
vibrationally-induced molecular magnetism and estimate changes in the magnetic
shielding constants for confirmation by future experiments.",http://arxiv.org/abs/2502.02169v1
Mask-informed Deep Contrastive Incomplete Multi-view Clustering,2025-02-04T11:23:48Z,"Zhenglai Li, Yuqi Shi, Xiao He, Chang Tang","Multi-view clustering (MvC) utilizes information from multiple views to
uncover the underlying structures of data. Despite significant advancements in
MvC, mitigating the impact of missing samples in specific views on the
integration of knowledge from different views remains a critical challenge.
This paper proposes a novel Mask-informed Deep Contrastive Incomplete
Multi-view Clustering (Mask-IMvC) method, which elegantly identifies a
view-common representation for clustering. Specifically, we introduce a
mask-informed fusion network that aggregates incomplete multi-view information
while considering the observation status of samples across various views as a
mask, thereby reducing the adverse effects of missing values. Additionally, we
design a prior knowledge-assisted contrastive learning loss that boosts the
representation capability of the aggregated view-common representation by
injecting neighborhood information of samples from different views. Finally,
extensive experiments are conducted to demonstrate the superiority of the
proposed Mask-IMvC method over state-of-the-art approaches across multiple MvC
datasets, both in complete and incomplete scenarios.",http://arxiv.org/abs/2502.02234v1
"Asymptotic solution for three-dimensional reaction-diffusion-advection
  equation with periodic boundary conditions",2025-02-04T12:22:13Z,"Aleksei Liubavin, Mingkang Ni, Ye Zhang, Dmitrii Chaikovskii","In this study, we investigate the dynamics of moving fronts in
three-dimensional spaces, which form as a result of in-situ combustion during
oil production. This phenomenon is also observed in other contexts, such as
various autowave models and the propagation of acoustic waves. Our analysis
involves a singularly perturbed reaction-diffusion-advection type
initial-boundary value problem of a general form. We employ methods from
asymptotic theory to develop an approximate smooth solution with an internal
layer. Using local coordinates, we focus on the transition layer, where the
solution undergoes rapid changes. Once the location of the transition layer is
established, we can describe the solution across the full domain of the
problem. Numerical examples are provided, demonstrating the high accuracy of
the asymptotic method in predicting the behaviors of moving fronts.",http://arxiv.org/abs/2502.02263v1
"Mirai: A Wearable Proactive AI ""Inner-Voice"" for Contextual Nudging",2025-02-04T14:51:29Z,"Cathy Mengying Fang, Yasith Samaradivakara, Pattie Maes, Suranga Nanayakkara","People often find it difficult to turn their intentions into real actions --
a challenge that affects both personal growth and mental well-being. While
established methods like cognitive-behavioral therapy and mindfulness training
help people become more aware of their behaviors and set clear goals, these
approaches cannot provide immediate guidance when people fall into automatic
reactions or habits. We introduce Mirai, a novel wearable AI system with an
integrated camera, real-time speech processing, and personalized voice-cloning
to provide proactive and contextual nudges for positive behavior change. Mirai
continuously monitors and analyzes the user's environment to anticipate their
intentions, generating contextually-appropriate responses delivered in the
user's own cloned voice. We demonstrate the application of Mirai through three
scenarios focusing on dietary choices, work productivity, and communication
skills. We also discuss future work on improving the proactive agent via human
feedback and the need for a longitudinal study in naturalistic settings.",http://arxiv.org/abs/2502.02370v1
"Achieving Hiding and Smart Anti-Jamming Communication: A Parallel DRL
  Approach against Moving Reactive Jammer",2025-02-04T15:03:11Z,"Yangyang Li, Yuhua Xu, Wen Li, Guoxin Li, Zhibing Feng, Songyi Liu, Jiatao Du, Xinran Li","This paper addresses the challenge of anti-jamming in moving reactive jamming
scenarios. The moving reactive jammer initiates high-power tracking jamming
upon detecting any transmission activity, and when unable to detect a signal,
resorts to indiscriminate jamming. This presents dual imperatives: maintaining
hiding to avoid the jammer's detection and simultaneously evading
indiscriminate jamming. Spread spectrum techniques effectively reduce
transmitting power to elude detection but fall short in countering
indiscriminate jamming. Conversely, changing communication frequencies can help
evade indiscriminate jamming but makes the transmission vulnerable to tracking
jamming without spread spectrum techniques to remain hidden. Current
methodologies struggle with the complexity of simultaneously optimizing these
two requirements due to the expansive joint action spaces and the dynamics of
moving reactive jammers. To address these challenges, we propose a parallelized
deep reinforcement learning (DRL) strategy. The approach includes a
parallelized network architecture designed to decompose the action space. A
parallel exploration-exploitation selection mechanism replaces the $\varepsilon
$-greedy mechanism, accelerating convergence. Simulations demonstrate a nearly
90\% increase in normalized throughput.",http://arxiv.org/abs/2502.02385v1
"Constraints on minimally and conformally coupled ultralight dark matter
  with the EPTA",2025-02-04T15:41:55Z,Clemente Smarra,"Millisecond pulsars are extremely stable natural timekeepers. Pulsar Timing
Array experiments, tracking subtle changes in the pulsars' rotation periods,
can shed light on the presence of ultralight particles in our Galaxy. In this
conference paper, we start by reviewing the most conservative scenario, in
which ultralight particles interact only gravitationally. In this setting, we
show that Pulsar Timing Arrays are able to constrain the presence of ultralight
fields up to a few tenths of the observed dark matter abundance. Then, we
consider conformally coupled ultralight candidates, demonstrating that the
constraints on the universal scalar coupling of the field to Standard Model
particles improve on existing bounds by several orders of magnitude, in the
relevant mass range analyzed by Pulsar Timing Arrays. The discussion presented
here is based on [1,2].",http://arxiv.org/abs/2502.02420v1
"Distribution Transformers: Fast Approximate Bayesian Inference With
  On-The-Fly Prior Adaptation",2025-02-04T16:33:12Z,"George Whittle, Juliusz Ziomek, Jacob Rawling, Michael A Osborne","While Bayesian inference provides a principled framework for reasoning under
uncertainty, its widespread adoption is limited by the intractability of exact
posterior computation, necessitating the use of approximate inference. However,
existing methods are often computationally expensive, or demand costly
retraining when priors change, limiting their utility, particularly in
sequential inference problems such as real-time sensor fusion. To address these
challenges, we introduce the Distribution Transformer -- a novel architecture
that can learn arbitrary distribution-to-distribution mappings. Our method can
be trained to map a prior to the corresponding posterior, conditioned on some
dataset -- thus performing approximate Bayesian inference. Our novel
architecture represents a prior distribution as a (universally-approximating)
Gaussian Mixture Model (GMM), and transforms it into a GMM representation of
the posterior. The components of the GMM attend to each other via
self-attention, and to the datapoints via cross-attention. We demonstrate that
Distribution Transformers both maintain flexibility to vary the prior, and
significantly reduces computation times-from minutes to milliseconds-while
achieving log-likelihood performance on par with or superior to existing
approximate inference methods across tasks such as sequential inference,
quantum system parameter inference, and Gaussian Process predictive posterior
inference with hyperpriors.",http://arxiv.org/abs/2502.02463v1
"The $CP$ violations and branching ratios for $B_c^+\to
  D_{(s)}^+π^+π^-(K^{+}K^{-})$ from interference of the vector mesons in
  Perturbative QCD",2025-02-05T00:54:47Z,"Kun Shuai Ye, Gang Lü, Na-Wang, Jian Chai, Xin-Heng Guo","Within the framework of the perturbative QCD approach utilizing $K_T$
factorization, we have investigated the CP violations and branching ratios in
the decay processes of $B_{c}^{+}\to D_{(s)} ^{+}V(V\rightarrow\pi^{+}\pi^{-})$
and $B_{c}^{+}\to D_{(s)}^{+}V(V\rightarrow K^{+}K^{-})$, where V denotes three
vector mesons $\rho^0$, $\omega$, and $\phi$. During the $V\to \pi^+\pi^-$ and
$V\to K^+K^-$ decay processes, we incorporated the $\rho^{0}-\omega-\phi$
mixing mechanism to describe the amplitudes of these quasi-two-body decay
processes. Within the interference regime of the three vector particles, we
observed distinct changes in both CP violations and branching ratios.
Furthermore, our study presents evidence for local CP violations and branching
ratios that warrants further investigation through experiments.",http://arxiv.org/abs/2502.02800v1
"Consistent Client Simulation for Motivational Interviewing-based
  Counseling",2025-02-05T00:58:30Z,"Yizhe Yang, Palakorn Achananuparp, Heyan Huang, Jing Jiang, John Pinto, Jenny Giam, Kit Phey Leng, Nicholas Gabriel Lim, Cameron Tan Shi Ern, Ee-peng Lim","Simulating human clients in mental health counseling is crucial for training
and evaluating counselors (both human or simulated) in a scalable manner.
Nevertheless, past research on client simulation did not focus on complex
conversation tasks such as mental health counseling. In these tasks, the
challenge is to ensure that the client's actions (i.e., interactions with the
counselor) are consistent with with its stipulated profiles and negative
behavior settings. In this paper, we propose a novel framework that supports
consistent client simulation for mental health counseling. Our framework tracks
the mental state of a simulated client, controls its state transitions, and
generates for each state behaviors consistent with the client's motivation,
beliefs, preferred plan to change, and receptivity. By varying the client
profile and receptivity, we demonstrate that consistent simulated clients for
different counseling scenarios can be effectively created. Both our automatic
and expert evaluations on the generated counseling sessions also show that our
client simulation method achieves higher consistency than previous methods.",http://arxiv.org/abs/2502.02802v1
"LHIEM: the Longitudinal Health, Income, and Employment Model",2025-02-05T01:18:45Z,"Adrienne M. Propp, Raffaele Vardavas, Carter C. Price, Kandice A. Kapinos","Dynamic microsimulation has long been recognized as a powerful tool for
policy analysis, but in fact most major health policy simulations lack path
dependency, a critical feature for evaluating policies that depend on
accumulated outcomes such as retirement savings, wealth, or debt. We propose
LHIEM (the Longitudinal Health, Income and Employment Model), a path-dependent
discrete-time microsimulation that predicts annual health care expenditures,
family income, and health status for the U.S. population over a multi-year
period. LHIEM advances the population from year to year as a Markov chain with
modules capturing the particular dynamics of each predictive attribute. LHIEM
was designed to assess a health care financing proposal that would allow
individuals to borrow from the U.S. government to cover health care costs,
requiring careful tracking of medical expenditures and medical debt over time.
However, LHIEM is flexible enough to be used for a range of modeling needs
related to predicting health care spending and income over time. In this paper,
we present the details of the model and all dynamic modules, and include a case
study to demonstrate how LHIEM can be used to evaluate proposed policy changes.",http://arxiv.org/abs/2502.02812v1
Position: Editing Large Language Models Poses Serious Safety Risks,2025-02-05T07:51:32Z,"Paul Youssef, Zhixue Zhao, Daniel Braun, Jörg Schlötterer, Christin Seifert","Large Language Models (LLMs) contain large amounts of facts about the world.
These facts can become outdated over time, which has led to the development of
knowledge editing methods (KEs) that can change specific facts in LLMs with
limited side effects. This position paper argues that editing LLMs poses
serious safety risks that have been largely overlooked. First, we note the fact
that KEs are widely available, computationally inexpensive, highly performant,
and stealthy makes them an attractive tool for malicious actors. Second, we
discuss malicious use cases of KEs, showing how KEs can be easily adapted for a
variety of malicious purposes. Third, we highlight vulnerabilities in the AI
ecosystem that allow unrestricted uploading and downloading of updated models
without verification. Fourth, we argue that a lack of social and institutional
awareness exacerbates this risk, and discuss the implications for different
stakeholders. We call on the community to (i) research tamper-resistant models
and countermeasures against malicious model editing, and (ii) actively engage
in securing the AI ecosystem.",http://arxiv.org/abs/2502.02958v1
"Higgs boson precision analysis of two Higgs doublet models: Full LHC Run
  1 and Run 2 data",2025-02-05T08:42:03Z,"Yongtae Heo, Jae Sik Lee, Chan Beom Park","We present the results obtained by performing global fits of
two-Higgs-doublet models (2HDMs) using the full Run 1 and Run 2 Higgs datasets
collected at the LHC. Avoiding unwanted tree-level flavor-changing neutral
currents and including the wrong-sign cases, we consider 12 scenarios across
six types of 2HDMs: Inert, type I, type II, type III, type IV, and Aligned
2HDMs. Our main results are presented in Table 3 and Fig. 1. We find that the
type-I 2HDM provides the best fit, while the wrong-sign scenarios of the
type-II and type-IV 2HDMs, where the normalized Yukawa coupling to down-type
quarks is opposite in sign to the Standard Model (SM), are disfavored. We also
observe that the Aligned 2HDM gives the second-best fit when the Yukawa
couplings to down-type quarks take the same sign as in the SM, regardless of
the sign of the Yukawa couplings to the charged leptons.",http://arxiv.org/abs/2502.02992v1
Conformal Uncertainty Indicator for Continual Test-Time Adaptation,2025-02-05T08:47:18Z,"Fan Lyu, Hanyu Zhao, Ziqi Shi, Ye Liu, Fuyuan Hu, Zhang Zhang, Liang Wang","Continual Test-Time Adaptation (CTTA) aims to adapt models to sequentially
changing domains during testing, relying on pseudo-labels for self-adaptation.
However, incorrect pseudo-labels can accumulate, leading to performance
degradation. To address this, we propose a Conformal Uncertainty Indicator
(CUI) for CTTA, leveraging Conformal Prediction (CP) to generate prediction
sets that include the true label with a specified coverage probability. Since
domain shifts can lower the coverage than expected, making CP unreliable, we
dynamically compensate for the coverage by measuring both domain and data
differences. Reliable pseudo-labels from CP are then selectively utilized to
enhance adaptation. Experiments confirm that CUI effectively estimates
uncertainty and improves adaptation performance across various existing CTTA
methods.",http://arxiv.org/abs/2502.02998v1
"The NRQCD $Υ$ spectrum at non-zero temperature using
  Backus-Gilbert regularisations",2025-02-05T10:45:17Z,"Antonio Smecca, Gert Aarts, Chris Allton, Ryan Bignell, Timothy J. Burns, Benjamin Jäger, Rachel Horohan D'Arcy, Seyong Kim, Maria-Paola Lombardo, Ben Page, Sinéad M. Ryan, Tom Spriggs, Jon-Ivar Skullerud","Understanding how the properties of heavy mesons change as temperature
increases is crucial for gaining valuable insights into the quark-gluon plasma.
Information about meson masses and decay widths is encoded in the meson
spectral function, which, in principle, can be extracted from Euclidean
correlation functions via generalised Laplace transformations. However, this
inverse problem is ill-posed for lattice correlation functions and requires
regularisation. In this work, we present the latest results for bottomonium
spectral functions obtained within the lattice NRQCD framework using the
Backus-Gilbert regularisation, along with two other variants, one of which is
commonly referred to as the HLT method. Our analysis employs Generation 2L
anisotropic lattice configurations produced by the \textsc{Fastsum}
collaboration.",http://arxiv.org/abs/2502.03060v1
"A Robust Machine Learned Interatomic Potential for Nb: Collision Cascade
  Simulations with accurate Defect Configurations",2025-02-05T12:32:11Z,"Utkarsh Bhardwaj, Vinayak Mishra, Suman Mondal, Manoj Warrier","Niobium (Nb) and its alloys are extensively used in various technological
applications owing to their favorable mechanical, thermal and irradiation
properties. Accurately modeling Nb under irradiation is essential for
predicting microstructural changes, defect evolution, and overall material
performance. Traditional interatomic potentials for Nb fail to predict the
correct self-interstitial atom (SIA) configuration, a critical factor in
radiation damage simulations. We develop a machine learning interatomic
potential (MLIP) using the Spectral Neighbor Analysis Potential (SNAP)
framework, trained on ab-initio Density Functional Theory (DFT) calculations,
which accurately captures the relative stability of different SIA dumbbell
configurations. The resulting potential reproduces DFT-level accuracy while
maintaining computational efficiency for large-scale Molecular Dynamics (MD)
simulations. Through a series of validation tests involving elastic, thermal,
and defect properties -- including collision cascade simulations -- we show
that our SNAP potential resolves persistent limitations in existing Embedded
Atom Method (EAM) and Finnis--Sinclair (FS) potentials and is effective for MD
simulations of collision cascades. Notably, it accurately captures the
ground-state SIA configuration of Nb in the primary damage of a collision
cascade, offering a robust tool for predictive irradiation studies.",http://arxiv.org/abs/2502.03126v1
"Detection of the Extended $γ$-ray Emission around TeV source
  1LHAASO J0249+6022 with Fermi-LAT",2025-02-05T12:59:30Z,"Gong Yunlu, Zhou Liancheng, Xia Qi, Chang Shan, Fang Jun, Zhang Li","1LHAASO J0249+6022 is an extended very-high-energy gamma-ray source
discovered by the Large High-Altitude Air Shower Observatory. Based on nearly
16.1 years of data from the Fermi Large Area Telescope, we report the probable
gamma-ray emission from 1LHAASO J0249+6022 in the 0.03-1 TeV energy range. The
results show that its gamma-ray spectrum can be well fitted by a single power
law with an index of 1.54 $\pm$ 0.17, and integral photon flux is (4.28 $\pm$
1.03) $\times$ 10$^{-11}$ photons cm$^{-2}$ s$^{-1}$. We also considered
theoretically whether the non-thermal emission could originate from a pulsar
wind nebula (PWN) scenario. Assuming that the particles injected into the
nebula have a power-law distribution, the resulting spectrum from the inverse
Compton scattering is consistent with the detected GeV and TeV gamma-ray
fluxes. Our study shows that the PWN scenario is reasonable for 1LHAASO
J0249+6022.",http://arxiv.org/abs/2502.03138v1
"Easy-cone state mediating the spin reorientation in topological kagome
  magnet Fe$_3$Sn$_2$",2025-02-05T14:57:44Z,"L. Prodan, D. M. Evans, A. S. Sukhanov, S. E. Nikitin, A. A. Tsirlin, L. Puntingam, M. C. Rahn, L. Chioncel, V. Tsurkan, I. Kezsmarki","We investigated temperature-driven spin reorientation (SR) in the itinerant
kagome magnet Fe$_3$Sn$_2$ using high-resolution synchrotron x-ray diffraction,
neutron diffraction, magnetometry, and magnetic force microscopy (MFM), further
supported by phenomenological analysis. Our study reveals a crossover from the
state with easy-plane anisotropy to the high-temperature state with uniaxial
easy-axis anisotropy taking place between $\sim40-130$~ K through an
intermediate easy-cone (or tilted spin) state. This state, induced by the
interplay between the anisotropy constants $K_1$ and $K_2$, is clearly
manifested in the thermal evolution of the magnetic structure factor, which
reveals a gradual change of the SR angle $\mathbf{\theta}$ between $40-130$~K.
We also found that the SR is accompanied by a magnetoelastic effect. Zero-field
MFM images across the SR range show a transformation in surface magnetic
patterns from a dendritic structure at 120~K, to domain wall dominated MFM
contrast at 40~K.",http://arxiv.org/abs/2502.03239v1
"When Pre-trained Visual Representations Fall Short: Limitations in
  Visuo-Motor Robot Learning",2025-02-05T15:25:46Z,"Nikolaos Tsagkas, Andreas Sochopoulos, Duolikun Danier, Chris Xiaoxuan Lu, Oisin Mac Aodha","The integration of pre-trained visual representations (PVRs) into visuo-motor
robot learning has emerged as a promising alternative to training visual
encoders from scratch. However, PVRs face critical challenges in the context of
policy learning, including temporal entanglement and an inability to generalise
even in the presence of minor scene perturbations. These limitations hinder
performance in tasks requiring temporal awareness and robustness to scene
changes. This work identifies these shortcomings and proposes solutions to
address them. First, we augment PVR features with temporal perception and a
sense of task completion, effectively disentangling them in time. Second, we
introduce a module that learns to selectively attend to task-relevant local
features, enhancing robustness when evaluated on out-of-distribution scenes.
Our experiments demonstrate significant performance improvements, particularly
in PVRs trained with masking objectives, and validate the effectiveness of our
enhancements in addressing PVR-specific limitations.",http://arxiv.org/abs/2502.03270v1
Complementing an imperative process algebra with a rely/guarantee logic,2025-02-05T16:20:20Z,C. A. Middelburg,"This paper concerns the relation between imperative process algebra and
rely/guarantee logic. An imperative process algebra is complemented by a
rely/guarantee logic that can be used to reason about how data change in the
course of a process. The imperative process algebra used is the extension of
ACP (Algebra of Communicating Processes) that is used earlier in a paper about
the relation between imperative process algebra and Hoare logic. A
complementing rely/guarantee logic that concerns judgments of partial
correctness is treated in detail. The adaptation of this logic to weak and
strong total correctness is also addressed. A simple example is given that
suggests that a rely/guarantee logic is more suitable as a complementing logic
than a Hoare logic if interfering parallel processes are involved.",http://arxiv.org/abs/2502.03320v1
Statistical analysis of team formation and player roles in football,2025-02-05T16:36:39Z,Ali Baouan,"The availability of tracking data in football presents unique opportunities
for analyzing team shape and player roles, but leveraging it effectively
remains challenging. This difficulty arises from the significant overlap in
player positions, which complicates the identification of distinct roles and
team formations. In this work, we propose a novel model that incorporates a
hidden permutation matrix to simultaneously estimate team formations and assign
roles to players at the frame level. To address the cardinality of permutation
sets, we develop a statistical procedure to parsimoniously select relevant
matrices prior to parameter estimation. Additionally, to capture formation
changes during a match, we introduce a latent regime variable, enabling the
modeling of dynamic tactical adjustments. This framework disentangles player
locations from role-specific positions, providing a clear representation of
team structure. We demonstrate the applicability of our approach using player
tracking data, showcasing its potential for detailed team and player analysis.",http://arxiv.org/abs/2502.03342v1
Rethinking Approximate Gaussian Inference in Classification,2025-02-05T17:03:49Z,"Bálint Mucsányi, Nathaël Da Costa, Philipp Hennig","In classification tasks, softmax functions are ubiquitously used as output
activations to produce predictive probabilities. Such outputs only capture
aleatoric uncertainty. To capture epistemic uncertainty, approximate Gaussian
inference methods have been proposed, which output Gaussian distributions over
the logit space. Predictives are then obtained as the expectations of the
Gaussian distributions pushed forward through the softmax. However, such
softmax Gaussian integrals cannot be solved analytically, and Monte Carlo (MC)
approximations can be costly and noisy. We propose a simple change in the
learning objective which allows the exact computation of predictives and enjoys
improved training dynamics, with no runtime or memory overhead. This framework
is compatible with a family of output activation functions that includes the
softmax, as well as element-wise normCDF and sigmoid. Moreover, it allows for
approximating the Gaussian pushforwards with Dirichlet distributions by
analytic moment matching. We evaluate our approach combined with several
approximate Gaussian inference methods (Laplace, HET, SNGP) on large- and
small-scale datasets (ImageNet, CIFAR-10), demonstrating improved uncertainty
quantification capabilities compared to softmax MC sampling. Code is available
at https://github.com/bmucsanyi/probit.",http://arxiv.org/abs/2502.03366v1
Time scale competition in the Active Coagulation Model,2025-02-05T17:12:40Z,Matteo Paoluzzi,"Spreading processes on top of active dynamics provide a novel theoretical
framework for capturing emerging collective behavior in living systems. I
consider run-and-tumble dynamics coupled with coagulation/decoagulation
reactions that lead to an absorbing state phase transition. While the active
dynamics does not change the location of the transition point, the relaxation
toward the stationary state depends on motility parameters. Because of the
competition between spreading dynamics and active motion, the system can
support long-living currents whose typical time scale is a nontrivial function
of motility and reaction rates. Beyond the mean-field regime, instability at
finite length scales regulates a crossover from periodic to diffusive modes.
Finally, it is possible to individuate different mechanisms of pattern
formation on a large time scale, ranging from Fisher-Kolmogorov to
Kardar-Parisi-Zhang equation.",http://arxiv.org/abs/2502.03372v1
"Foundation for unbiased cross-validation of spatio-temporal models for
  species distribution modeling",2025-01-27T23:02:05Z,"Diana Koldasbayeva, Alexey Zaytsev","Species Distribution Models (SDMs) often suffer from spatial autocorrelation
(SAC), leading to biased performance estimates. We tested cross-validation (CV)
strategies - random splits, spatial blocking with varied distances,
environmental (ENV) clustering, and a novel spatio-temporal method - under two
proposed training schemes: LAST FOLD, widely used in spatial CV at the cost of
data loss, and RETRAIN, which maximizes data usage but risks reintroducing SAC.
LAST FOLD consistently yielded lower errors and stronger correlations. Spatial
blocking at an optimal distance (SP 422) and ENV performed best, achieving
Spearman and Pearson correlations of 0.485 and 0.548, respectively, although
ENV may be unsuitable for long-term forecasts involving major environmental
shifts. A spatio-temporal approach yielded modest benefits in our moderately
variable dataset, but may excel with stronger temporal changes. These findings
highlight the need to align CV approaches with the spatial and temporal
structure of SDM data, ensuring rigorous validation and reliable predictive
outcomes.",http://arxiv.org/abs/2502.03480v1
"TD-M(PC)$^2$: Improving Temporal Difference MPC Through Policy
  Constraint",2025-02-05T19:08:42Z,"Haotian Lin, Pengcheng Wang, Jeff Schneider, Guanya Shi","Model-based reinforcement learning algorithms that combine model-based
planning and learned value/policy prior have gained significant recognition for
their high data efficiency and superior performance in continuous control.
However, we discover that existing methods that rely on standard SAC-style
policy iteration for value learning, directly using data generated by the
planner, often result in \emph{persistent value overestimation}. Through
theoretical analysis and experiments, we argue that this issue is deeply rooted
in the structural policy mismatch between the data generation policy that is
always bootstrapped by the planner and the learned policy prior. To mitigate
such a mismatch in a minimalist way, we propose a policy regularization term
reducing out-of-distribution (OOD) queries, thereby improving value learning.
Our method involves minimum changes on top of existing frameworks and requires
no additional computation. Extensive experiments demonstrate that the proposed
approach improves performance over baselines such as TD-MPC2 by large margins,
particularly in 61-DoF humanoid tasks. View qualitative results at
https://darthutopian.github.io/tdmpc_square/.",http://arxiv.org/abs/2502.03550v1
Retina electronic paper with video-rate-tunable 45000 pixels per inch,2025-02-05T19:58:42Z,"Ade Satria Saloka Santosa, Yu-Wei Chang, Andreas B. Dahlin, Lars Osterlund, Giovanni Volpe, Kunli Xiong","As demand for immersive experiences grows, displays are moving closer to the
eye with smaller sizes and higher resolutions. However, shrinking pixel
emitters reduce intensity, making them harder to perceive. Electronic Papers
utilize ambient light for visibility, maintaining optical contrast regardless
of pixel size, but cannot achieve high resolution. We show electrically tunable
meta-pixels down to ~560 nm in size (>45,000 PPI) consisting of WO3 nanodiscs,
allowing one-to-one pixel-photodetector mapping on the retina when the display
size matches the pupil diameter, which we call Retina Electronic Paper. Our
technology also supports video display (25 Hz), high reflectance (~80%), and
optical contrast (~50%), which will help create the ultimate virtual reality
display.",http://arxiv.org/abs/2502.03580v1
"Towards Physical Understanding in Video Generation: A 3D Point
  Regularization Approach",2025-02-05T21:49:06Z,"Yunuo Chen, Junli Cao, Anil Kag, Vidit Goel, Sergei Korolev, Chenfanfu Jiang, Sergey Tulyakov, Jian Ren","We present a novel video generation framework that integrates 3-dimensional
geometry and dynamic awareness. To achieve this, we augment 2D videos with 3D
point trajectories and align them in pixel space. The resulting 3D-aware video
dataset, PointVid, is then used to fine-tune a latent diffusion model, enabling
it to track 2D objects with 3D Cartesian coordinates. Building on this, we
regularize the shape and motion of objects in the video to eliminate undesired
artifacts, \eg, nonphysical deformation. Consequently, we enhance the quality
of generated RGB videos and alleviate common issues like object morphing, which
are prevalent in current video models due to a lack of shape awareness. With
our 3D augmentation and regularization, our model is capable of handling
contact-rich scenarios such as task-oriented videos. These videos involve
complex interactions of solids, where 3D information is essential for
perceiving deformation and contact. Furthermore, our model improves the overall
quality of video generation by promoting the 3D consistency of moving objects
and reducing abrupt changes in shape and motion.",http://arxiv.org/abs/2502.03639v1
"Unveiling the complexity of Arnold's tongues in a breathing-soliton
  laser",2025-02-06T01:12:51Z,"Xiuqi Wu, Junsong Peng, Bo Yuan, Sonia Boscolo, Christophe Finot, Heping Zeng","Synchronization occurs ubiquitously in nature and science. The
synchronization regions generally broaden monotonically with the strength of
the forcing, thereby featuring a tongue-like shape in parameter space, known as
Arnold's tongue. Such a shape is universal, prevailing in many diverse
synchronized systems. Interestingly, theoretical studies suggest that under
strong external forcing, the shape of the synchronization regions can change
substantially and even holes can appear in the solid patterns. However,
experimentally accessing these abnormal regimes is quite challenging, mainly
because many real-world systems displaying synchronization become fragile under
strong forcing. Here, we are able to observe these intriguing regimes in a
breathing-soliton laser. Two types of abnormal synchronization regions are
unveiled, namely, a leaf- and a ray-like shape. High-resolution control of the
loss allows holes to be revealed in the synchronization regions. Our work opens
the possibility to study intriguing synchronization dynamics using a simple
breathing-soliton laser as a testbed.",http://arxiv.org/abs/2502.03697v1
"Co-existing topological and Volkov-Pankratov plasmonic edge states in
  magnetized graphene",2025-02-06T01:57:17Z,"Samyobrata Mukherjee, Viktoriia Savchuk, Jeffery W. Allen, Monica S. Allen, Gennady Shvets","Graphene placed in a perpendicular magnetic field supports optical modes
known as magnetoplasmons which are transversally confined to the graphene
layer. Unlike ordinary graphene plasmons, these magnetoplasmonic surface waves
are characterized by a band gap corresponding to the cyclotron frequency. In
addition, these magnetoplasmon bands are topological, characterized by a
non-zero Chern number. This leads to the existence of topologically protected
edge states at domain edges where the Chern number changes. Since the Chern
number is dependent on the direction of the magnetic field, edge states exist
at domain edges across which the magnetic field flips direction. Physically,
the magnetic field can only flip direction at gradual domain edges with finite
width creating topological heterojunctions. These topological heterojunctions
support extra edge states known as Volkov-Pankratov edge states which can enter
the band gap and support propagation in both directions. The number of
Volkov-Pankratov states at a heterojunction varies as a function of the width
of the gradual domain edge.",http://arxiv.org/abs/2502.03710v1
"Out-of-phase Plasmon Excitations in the Trilayer Cuprate
  Bi$_2$Sr$_2$Ca$_2$Cu$_3$O$_{10+δ}$",2025-02-06T04:59:54Z,"S. Nakata, M. Bejas, J. Okamoto, K. Yamamoto, D. Shiga, R. Takahashi, H. Y. Huang, H. Kumigashira, H. Wadati, J. Miyawaki, S. Ishida, H. Eisaki, A. Fujimori, A. Greco, H. Yamase, D. J. Huang, H. Suzuki","Within a homologous series of cuprate superconductors, variations in the
stacking of CuO$_2$ layers influence the collective charge dynamics through the
long-range Coulomb interactions. We use O $K$-edge resonant inelastic x-ray
scattering to reveal plasmon excitations in the optimally-doped trilayer
Bi$_2$Sr$_2$Ca$_2$Cu$_3$O$_{10+\delta}$. The observed plasmon exhibits nearly
$q_z$-independent dispersion and a large excitation gap of approximately 300
meV. This mode is primarily ascribed to the $\omega_{-}$ mode, where the charge
density on the outer CuO$_2$ sheets oscillates out of phase while the density
in the inner sheet remains unaltered at $q_z=0$. The intensity of the acoustic
$\omega_3$ mode is relatively weak and becomes vanishingly small near $(q_x,
q_y)=(0, 0)$. This result highlights a qualitative change in the eigenmode of
the dominant low-energy plasmon with the number of CuO$_2$ layers.",http://arxiv.org/abs/2502.03779v2
"Superior probabilistic computing using operationally stable
  probabilistic-bit constructed by manganite nanowire",2025-02-06T05:58:36Z,"Yadi Wang, Bin Chen, Wenping Gao, Biying Ye, Chang Niu, Wenbin Wang, Yinyan Zhu, Weichao Yu, Hangwen Guo, Jian Shen","Probabilistic computing has emerged as a viable approach to treat
optimization problems. To achieve superior computing performance, the key
aspect during computation is massive sampling and tuning on the probability
states of each probabilistic bit (p-bit), demanding its high stability under
extensive operations. Here, we demonstrate a p-bit constructed by manganite
nanowire that shows exceptionally high stability. The p-bit contains an
electronic domain that fluctuates between metallic (low resistance) and
insulating (high resistance) states near its transition temperature. The
probability for the two states can be directly controlled by nano-ampere
electrical current. Under extensive operations, the standard error of its
probability values is less than 1.3%. Simulations show that our operationally
stable p-bit plays the key role to achieve correct inference in Bayesian
network by strongly suppressing the relative error, displaying the potential
for superior computing performance. Our p-bit also serves as high quality
random number generator without extra data-processing, beneficial for
cryptographic applications.",http://arxiv.org/abs/2502.03797v1
"Knowing When to Stop Matters: A Unified Algorithm for Online Conversion
  under Horizon Uncertainty",2025-02-06T07:06:06Z,"Yanzhao Wang, Hasti Nourmohammadi Sigaroudi, Bo Sun, Omid Ardakanian, Xiaoqi Tan","This paper investigates the online conversion problem, which involves
sequentially trading a divisible resource (e.g., energy) under dynamically
changing prices to maximize profit. A key challenge in online conversion is
managing decisions under horizon uncertainty, where the duration of trading is
either known, revealed partway, or entirely unknown. We propose a unified
algorithm that achieves optimal competitive guarantees across these horizon
models, accounting for practical constraints such as box constraints, which
limit the maximum allowable trade per step. Additionally, we extend the
algorithm to a learning-augmented version, leveraging horizon predictions to
adaptively balance performance: achieving near-optimal results when predictions
are accurate while maintaining strong guarantees when predictions are
unreliable. These results advance the understanding of online conversion under
various degrees of horizon uncertainty and provide more practical strategies to
address real world constraints.",http://arxiv.org/abs/2502.03817v1
Counterfactual Query Rewriting to Use Historical Relevance Feedback,2025-02-06T09:05:41Z,"Jüri Keller, Maik Fröbe, Gijs Hendriksen, Daria Alexander, Martin Potthast, Matthias Hagen, Philipp Schaer","When a retrieval system receives a query it has encountered before, previous
relevance feedback, such as clicks or explicit judgments can help to improve
retrieval results. However, the content of a previously relevant document may
have changed, or the document might not be available anymore. Despite this
evolved corpus, we counterfactually use these previously relevant documents as
relevance signals. In this paper we proposed approaches to rewrite user queries
and compare them against a system that directly uses the previous qrels for the
ranking. We expand queries with terms extracted from the previously relevant
documents or derive so-called keyqueries that rank the previously relevant
documents to the top of the current corpus. Our evaluation in the CLEF LongEval
scenario shows that rewriting queries with historical relevance feedback
improves the retrieval effectiveness and even outperforms computationally
expensive transformer-based approaches.",http://arxiv.org/abs/2502.03891v1
Fairness Aware Reinforcement Learning via Proximal Policy Optimization,2025-02-06T10:45:55Z,"Gabriele La Malfa, Jie M. Zhang, Michael Luck, Elizabeth Black","Fairness in multi-agent systems (MAS) focuses on equitable reward
distribution among agents in scenarios involving sensitive attributes such as
race, gender, or socioeconomic status. This paper introduces fairness in
Proximal Policy Optimization (PPO) with a penalty term derived from demographic
parity, counterfactual fairness, and conditional statistical parity. The
proposed method balances reward maximisation with fairness by integrating two
penalty components: a retrospective component that minimises disparities in
past outcomes and a prospective component that ensures fairness in future
decision-making. We evaluate our approach in the Allelopathic Harvest game, a
cooperative and competitive MAS focused on resource collection, where some
agents possess a sensitive attribute. Experiments demonstrate that fair-PPO
achieves fairer policies across all fairness metrics than classic PPO. Fairness
comes at the cost of reduced rewards, namely the Price of Fairness, although
agents with and without the sensitive attribute renounce comparable amounts of
rewards. Additionally, the retrospective and prospective penalties effectively
change the agents' behaviour and improve fairness. These findings underscore
the potential of fair-PPO to address fairness challenges in MAS.",http://arxiv.org/abs/2502.03953v1
"Pre-Optimized Irregular Arrays versus Moveable Antennas in Multi-User
  MIMO Systems",2025-02-06T11:51:36Z,"Amna Irshad, Alva Kosasih, Vitaly Petrov, Emil Björnson","Massive multiple-input multiple-output (MIMO) systems exploit the spatial
diversity achieved with an array of many antennas to perform spatial
multiplexing of many users. Similar performance can be achieved using fewer
antennas if movable antenna (MA) elements are used instead. MA-enabled arrays
can dynamically change the antenna locations, mechanically or electrically, to
achieve maximum spatial diversity for the current propagation conditions.
However, optimizing the antenna locations for each channel realization is
computationally excessive, requires channel knowledge for all conceivable
locations, and requires rapid antenna movements, thus making real-time
implementation cumbersome. To overcome these challenges, we propose a
pre-optimized irregular array (PIA) concept, where the antenna locations at the
base station are optimized a priori for a given coverage area. The objective is
to maximize the average sum rate and we take a particle swarm optimization
approach to solve it. Simulation results show that PIA achieves performance
comparable to MA-enabled arrays while outperforming traditional uniform arrays.
Hence, PIA offers a fixed yet efficient array deployment approach without the
complexities associated with MA-enabled arrays.",http://arxiv.org/abs/2502.03994v1
"Near-optimal Regret Using Policy Optimization in Online MDPs with
  Aggregate Bandit Feedback",2025-02-06T12:03:24Z,"Tal Lancewicki, Yishay Mansour","We study online finite-horizon Markov Decision Processes with adversarially
changing loss and aggregate bandit feedback (a.k.a full-bandit). Under this
type of feedback, the agent observes only the total loss incurred over the
entire trajectory, rather than the individual losses at each intermediate step
within the trajectory. We introduce the first Policy Optimization algorithms
for this setting. In the known-dynamics case, we achieve the first
\textit{optimal} regret bound of $\tilde \Theta(H^2\sqrt{SAK})$, where $K$ is
the number of episodes, $H$ is the episode horizon, $S$ is the number of
states, and $A$ is the number of actions. In the unknown dynamics case we
establish regret bound of $\tilde O(H^3 S \sqrt{AK})$, significantly improving
the best known result by a factor of $H^2 S^5 A^2$.",http://arxiv.org/abs/2502.04004v1
Spontaneous helix formation in polar smectic phase,2025-02-06T13:02:42Z,"Ewa Gorecka, Magdalena Majewska, Ladislav Fekete, Jakub Karcz, Julia Żukowska, Jakub Herman Przemysław Kula, Damian Pociecha","In soft ferroelectric crystals, the depolarization field can be reduced by
periodic distortion of the polarization direction. In the polar nematic and
tilted smectic phases, this process is energetically favorured , as it only
requires changes in the director orientation. We demonstrate the spontaneous
formation of a helical structure in the proper ferroelectric tilted smectic
(SmCTBF) phase, the phase is formed below the heliconical polar nematic (NTBF)
phase. The helical pitch in the smectic phase is approximately 600 nm and
remains nearly constant across the entire temperature range of the phase. Under
weak electric fields, the helix reorients while its structure remains largely
intact; however, in stronger fields, the helix is destroyed as the electric
polarization aligns along the electric field.",http://arxiv.org/abs/2502.04042v1
"Non-renormalization of the fractional quantum Hall conductivity by
  interactions",2025-02-06T13:05:15Z,"M. Selch, M. A. Zubkov, Souvik Pramanik, M. Lewkowicz","We investigate the theory of the fractional quantum Hall effect (QHE)
proposed a long time ago by Lopez and Fradkin \cite{Fradkin1991chern}. The
magnetic fluxes of the statistical gauge field attached to electrons remain at
rest in the reference frame moving together with the electron liquid. In the
laboratory reference frame the electric field of the statistical gauge field
forms and screens the external electric field. The fractional QHE conductivity
appears as a consequence of this screening already on the mean field theory
level. We consider a relativistic extension of the model, and propose an
alternative description of the fractional QHE based on macroscopic motion of
the electron liquid within the Zubarev statistical operator approach. It is
this macroscopic motion of electrons which in this pattern gives rise to the
fractional QHE. Within this approach we propose the proof to all orders of
perturbation theory that the interaction corrections cannot change the above
mentioned mean field theory result for the QHE conductivity.",http://arxiv.org/abs/2502.04047v1
"CDIO: Cross-Domain Inference Optimization with Resource Preference
  Prediction for Edge-Cloud Collaboration",2025-02-06T13:42:07Z,"Zheming Yang, Wen Ji, Qi Guo, Dieli Hu, Chang Zhao, Xiaowei Li, Xuanlei Zhao, Yi Zhao, Chaoyu Gong, Yang You","Currently, massive video tasks are processed by edge-cloud collaboration.
However, the diversity of task requirements and the dynamics of resources pose
great challenges to efficient inference, resulting in many wasted resources. In
this paper, we present CDIO, a cross-domain inference optimization framework
designed for edge-cloud collaboration. For diverse input tasks, CDIO can
predict resource preference types by analyzing spatial complexity and
processing requirements of the task. Subsequently, a cross-domain collaborative
optimization algorithm is employed to guide resource allocation in the
edge-cloud system. By ensuring that each task is matched with the ideal
servers, the edge-cloud system can achieve higher efficiency inference. The
evaluation results on public datasets demonstrate that CDIO can effectively
meet the accuracy and delay requirements for task processing. Compared to
state-of-the-art edge-cloud solutions, CDIO achieves a computing and bandwidth
consumption reduction of 20%-40%. And it can reduce energy consumption by more
than 40%.",http://arxiv.org/abs/2502.04078v1
Impermanent loss and Loss-vs-Rebalancing II,2025-02-06T14:16:10Z,"Abe Alexander, Guillaume Lambert, Lars Fritz","This paper examines the relationship between impermanent loss (IL) and
loss-versus-rebalancing (LVR) in automated market makers (AMMs). Our main focus
is on statistical properties, the impact of fees, the role of block times, and,
related to the latter, the continuous time limit. We find there are three
relevant regimes: (i) very short times where LVR and IL are identical; (ii)
intermediate time where LVR and IL show distinct distribution functions but are
connected via the central limit theorem exhibiting the same expectation value;
(iii) long time behavior where both the distribution functions and averages are
distinct. Subsequently, we study how fees change this dynamics with a special
focus on competing time scales like block times and 'arbitrage times'.",http://arxiv.org/abs/2502.04097v2
Quadratic spin-phonon coupling and bipolarons in trapped ions,2025-02-06T14:34:34Z,"L. P. H. Gallagher, M. Mazzanti, Z. E. D. Ackerman, R. J. C. Spreeuw, A. Safavi-Naini, R. Gerritsma","We consider the quantum simulation of quadratic spin-phonon coupling in a
crystal of trapped ions. The coupling is implemented using tightly focused
optical tweezers on each ion that change the local trapping potential in a
state-dependent way. By encoding spins in the internal states of the ions and
adding a tunneling term via M{\o}lmer-S{\o}rensen-type interactions, we
calculate the emergence of mobile bipolarons driven by the zero-point energy of
the ion crystal phonons. We show that thermal occupation may pin the bipolarons
for ion crystals at finite temperature. Our scheme can be used to study and
illustrate the emergence of mobile bipolarons as a function of temperature.",http://arxiv.org/abs/2502.04109v1
UltraIF: Advancing Instruction Following from the Wild,2025-02-06T15:39:16Z,"Kaikai An, Li Sheng, Ganqu Cui, Shuzheng Si, Ning Ding, Yu Cheng, Baobao Chang","Instruction-following made modern large language models (LLMs) helpful
assistants. However, the key to taming LLMs on complex instructions remains
mysterious, for that there are huge gaps between models trained by open-source
community and those trained by leading companies. To bridge the gap, we propose
a simple and scalable approach UltraIF for building LLMs that can follow
complex instructions with open-source data. UltraIF first decomposes real-world
user prompts into simpler queries, constraints, and corresponding evaluation
questions for the constraints. Then, we train an UltraComposer to compose
constraint-associated prompts with evaluation questions. This prompt composer
allows us to synthesize complicated instructions as well as filter responses
with evaluation questions. In our experiment, for the first time, we
successfully align LLaMA-3.1-8B-Base to catch up with its instruct version on 5
instruction-following benchmarks without any benchmark information, using only
8B model as response generator and evaluator. The aligned model also achieved
competitive scores on other benchmarks. Moreover, we also show that UltraIF
could further improve LLaMA-3.1-8B-Instruct through self-alignment, motivating
broader use cases for the method. Our code will be available at
https://github.com/kkk-an/UltraIF.",http://arxiv.org/abs/2502.04153v1
"A Pseudo Markov-Chain Model and Time-Elapsed Measures of Mobility from
  Collective Data",2025-02-06T15:46:43Z,"Alisha Foster, David A. Meyer, Asif Shakeel","In this paper we develop a pseudo Markov-chain model to understand
time-elapsed flows, over multiple intervals, from time and space aggregated
collective inter-location trip data, given as a time-series. Building on the
model, we develop measures of mobility that parallel those known for individual
mobility data, such as the radius of gyration. We apply these measures to the
NetMob 2024 Data Challenge data, and obtain interesting results that are
consistent with published statistics and commuting patterns in cities. Besides
building a new framework, we foresee applications of this approach to an
improved understanding of human mobility in the context of environmental
changes and sustainable development.",http://arxiv.org/abs/2502.04162v1
Multi-task Online Learning for Probabilistic Load Forecasting,2025-02-06T15:47:02Z,"Onintze Zaballa, Verónica Álvarez, Santiago Mazuelas","Load forecasting is essential for the efficient, reliable, and cost-effective
management of power systems. Load forecasting performance can be improved by
learning the similarities among multiple entities (e.g., regions, buildings).
Techniques based on multi-task learning obtain predictions by leveraging
consumption patterns from the historical load demand of multiple entities and
their relationships. However, existing techniques cannot effectively assess
inherent uncertainties in load demand or account for dynamic changes in
consumption patterns. This paper proposes a multi-task learning technique for
online and probabilistic load forecasting. This technique provides accurate
probabilistic predictions for the loads of multiple entities by leveraging
their dynamic similarities. The method's performance is evaluated using
datasets that register the load demand of multiple entities and contain diverse
and dynamic consumption patterns. The experimental results show that the
proposed method can significantly enhance the effectiveness of current
multi-task learning approaches across a wide variety of load consumption
scenarios.",http://arxiv.org/abs/2502.04163v1
"Provably Robust Explainable Graph Neural Networks against Graph
  Perturbation Attacks",2025-02-06T17:07:52Z,"Jiate Li, Meng Pang, Yun Dong, Jinyuan Jia, Binghui Wang","Explaining Graph Neural Network (XGNN) has gained growing attention to
facilitate the trust of using GNNs, which is the mainstream method to learn
graph data. Despite their growing attention, Existing XGNNs focus on improving
the explanation performance, and its robustness under attacks is largely
unexplored. We noticed that an adversary can slightly perturb the graph
structure such that the explanation result of XGNNs is largely changed. Such
vulnerability of XGNNs could cause serious issues particularly in
safety/security-critical applications. In this paper, we take the first step to
study the robustness of XGNN against graph perturbation attacks, and propose
XGNNCert, the first provably robust XGNN. Particularly, our XGNNCert can
provably ensure the explanation result for a graph under the worst-case graph
perturbation attack is close to that without the attack, while not affecting
the GNN prediction, when the number of perturbed edges is bounded. Evaluation
results on multiple graph datasets and GNN explainers show the effectiveness of
XGNNCert.",http://arxiv.org/abs/2502.04224v1
"A Theoretical Framework for Data Efficient Multi-Source Transfer
  Learning Based on Cramér-Rao Bound",2025-02-06T17:32:49Z,"Qingyue Zhang, Haohao Fu, Guanbo Huang, Yaoyuan Liang, Chang Chu, Tianren Peng, Yanru Wu, Qi Li, Yang Li, Shao-Lun Huang","Multi-source transfer learning provides an effective solution to data
scarcity in real-world supervised learning scenarios by leveraging multiple
source tasks. In this field, existing works typically use all available samples
from sources in training, which constrains their training efficiency and may
lead to suboptimal results. To address this, we propose a theoretical framework
that answers the question: what is the optimal quantity of source samples
needed from each source task to jointly train the target model? Specifically,
we introduce a generalization error measure that aligns with cross-entropy
loss, and minimize it based on the Cram\'er-Rao Bound to determine the optimal
transfer quantity for each source task. Additionally, we develop an
architecture-agnostic and data-efficient algorithm OTQMS to implement our
theoretical results for training deep multi-source transfer learning models.
Experimental studies on diverse architectures and two real-world benchmark
datasets show that our proposed algorithm significantly outperforms
state-of-the-art approaches in both accuracy and data efficiency. The code and
supplementary materials are available in
https://anonymous.4open.science/r/Materials.",http://arxiv.org/abs/2502.04242v1
Prediction-Powered E-Values,2025-02-06T18:36:01Z,"Daniel Csillag, Claudio José Struchiner, Guilherme Tegoni Goedert","Quality statistical inference requires a sufficient amount of data, which can
be missing or hard to obtain. To this end, prediction-powered inference has
risen as a promising methodology, but existing approaches are largely limited
to Z-estimation problems such as inference of means and quantiles. In this
paper, we apply ideas of prediction-powered inference to e-values. By doing so,
we inherit all the usual benefits of e-values -- such as anytime-validity,
post-hoc validity and versatile sequential inference -- as well as greatly
expand the set of inferences achievable in a prediction-powered manner. In
particular, we show that every inference procedure that can be framed in terms
of e-values has a prediction-powered counterpart, given by our method. We
showcase the effectiveness of our framework across a wide range of inference
tasks, from simple hypothesis testing and confidence intervals to more involved
procedures for change-point detection and causal discovery, which were out of
reach of previous techniques. Our approach is modular and easily integrable
into existing algorithms, making it a compelling choice for practical
applications.",http://arxiv.org/abs/2502.04294v1
Can Large Language Models Capture Video Game Engagement?,2025-02-05T17:14:47Z,"David Melhart, Matthew Barthet, Georgios N. Yannakakis","Can out-of-the-box pretrained Large Language Models (LLMs) detect human
affect successfully when observing a video? To address this question, for the
first time, we evaluate comprehensively the capacity of popular LLMs to
annotate and successfully predict continuous affect annotations of videos when
prompted by a sequence of text and video frames in a multimodal fashion.
Particularly in this paper, we test LLMs' ability to correctly label changes of
in-game engagement in 80 minutes of annotated videogame footage from 20
first-person shooter games of the GameVibe corpus. We run over 2,400
experiments to investigate the impact of LLM architecture, model size, input
modality, prompting strategy, and ground truth processing method on engagement
prediction. Our findings suggest that while LLMs rightfully claim human-like
performance across multiple domains, they generally fall behind capturing
continuous experience annotations provided by humans. We examine some of the
underlying causes for the relatively poor overall performance, highlight the
cases where LLMs exceed expectations, and draw a roadmap for the further
exploration of automated emotion labelling via LLMs.",http://arxiv.org/abs/2502.04379v1
"Enhancing Reasoning to Adapt Large Language Models for Domain-Specific
  Applications",2025-02-05T19:27:24Z,"Bo Wen, Xin Zhang","This paper presents SOLOMON, a novel Neuro-inspired Large Language Model
(LLM) Reasoning Network architecture that enhances the adaptability of
foundation models for domain-specific applications. Through a case study in
semiconductor layout design, we demonstrate how SOLOMON enables swift
adaptation of general-purpose LLMs to specialized tasks by leveraging Prompt
Engineering and In-Context Learning techniques. Our experiments reveal the
challenges LLMs face in spatial reasoning and applying domain knowledge to
practical problems. Results show that SOLOMON instances significantly
outperform their baseline LLM counterparts and achieve performance comparable
to state-of-the-art reasoning model, o1-preview. We discuss future research
directions for developing more adaptive AI systems that can continually learn,
adapt, and evolve in response to new information and changing requirements.",http://arxiv.org/abs/2502.04384v1
"UniCP: A Unified Caching and Pruning Framework for Efficient Video
  Generation",2025-02-06T03:56:11Z,"Wenzhang Sun, Qirui Hou, Donglin Di, Jiahui Yang, Yongjia Ma, Jianxun Cui","Diffusion Transformers (DiT) excel in video generation but encounter
significant computational challenges due to the quadratic complexity of
attention. Notably, attention differences between adjacent diffusion steps
follow a U-shaped pattern. Current methods leverage this property by caching
attention blocks, however, they still struggle with sudden error spikes and
large discrepancies. To address these issues, we propose UniCP a unified
caching and pruning framework for efficient video generation. UniCP optimizes
both temporal and spatial dimensions through. Error Aware Dynamic Cache Window
(EDCW): Dynamically adjusts cache window sizes for different blocks at various
timesteps, adapting to abrupt error changes. PCA based Slicing (PCAS) and
Dynamic Weight Shift (DWS): PCAS prunes redundant attention components, and DWS
integrates caching and pruning by enabling dynamic switching between pruned and
cached outputs. By adjusting cache windows and pruning redundant components,
UniCP enhances computational efficiency and maintains video detail fidelity.
Experimental results show that UniCP outperforms existing methods in both
performance and efficiency.",http://arxiv.org/abs/2502.04393v1
"On the extension of the concept of rheological connections to a finite
  deformation framework using multiple natural configurations",2025-02-06T06:13:02Z,"Tarun Singh, Sandipan Paul","The constitutive behaviors of materials are often modeled using a network of
different rheological elements. These rheological models are mostly developed
within a one-dimensional small strain framework. One of the key impediments of
extending these models to a three-dimensional finite deformation setting is to
determine how the different types of connections, i.e., a series and a parallel
connection, are incorporated into the material models. The primary objective of
this article is to develop an appropriate strategy to address this issue. We
show that both the series and the parallel connection between two rheological
elements can be modeled within a multiple natural configurations framework
without changing or introducing new configurations. The difference in a series
and a parallel connection is manifested in the ratio of the stress powers
expended during the deformations of the associated rheological elements. Finite
deformation version of some well-known rheological models have been used to
demonstrate the utility of the proposed theory.",http://arxiv.org/abs/2502.04396v1
Compact protoplanetary discs can be produced by dead zones,2025-02-06T19:00:50Z,"Simin Tong, Richard Alexander","Radially compact protoplanetary discs (<=50 au) are ubiquitous in nearby
star-forming regions. Multiple mechanisms have been invoked to interpret
various compact discs. In this paper, we propose that fragmentation of fragile
dust grains in moderate turbulence, as expected beyond the dead zone, provides
an effective alternative mechanism to form compact discs which are consistent
with current observations. We run 1-D dust transport and collision models with
DustPy and generate synthetic observations, and find that discs formed by this
mechanism have sizes determined by the extent of their dead zones. Accounting
for dust porosity, and considering less fragile dust, do not change disc sizes
significantly. The smooth dust morphology can be altered only when pressure
bumps are present in the dead zone. However, when present at small radii (<=10
au), pressure bumps cannot effectively trap dust. Dust in these bumps fragments
and replenishes the inner discs, effectively hiding dust traps in the optically
thick inner disc from observations. We note a striking resemblance in the
radial intensity profile between our synthetic observations and some recent
high-resolution observations of compact discs. We discuss how such observations
can inform our understanding of the underlying disc physics.",http://arxiv.org/abs/2502.04452v1
Enhanced Axion-wind near Earth's Surface,2025-02-06T19:02:02Z,"Yeray Garcia del Castillo, Benjamin Hammett, Joerg Jaeckel","Several detection strategies for wave-like dark matter make use of gradients
in the dark matter field, e.g. searches for spin-dependent derivative
interactions in CASPEr-wind or experiments looking for oscillating forces.
These gradients are usually suppressed by the local dark matter velocity $\sim
10^{-3}$. In this note we investigate how these gradients are modified in the
presence of additional quadratic interactions of the dark matter field with
ordinary matter. In this case the dark matter density and field are modified in
the vicinity of Earth, affecting the detection sensitivity due to the change in
the local field value at the Earth's surface but also due to the gradient of
the field profile itself. We also use this opportunity to present results on
the expected field profiles in presence of a non-vanishing relative velocity of
the dark matter with respect to Earth. We also comment how this ameliorates the
divergences that appear for certain attractive coupling values.",http://arxiv.org/abs/2502.04456v1
"""In order that"" -- a data driven study of symptoms and causes of
  obsolescence",2025-02-06T19:03:45Z,Karolina Rudnicka,"The paper is an empirical case study of grammatical obsolescence in progress.
The main studied variable is the purpose subordinator in order that, which is
shown to be steadily decreasing in the frequency of use starting from the
beginning of the twentieth century. This work applies a data-driven approach
for the investigation and description of obsolescence, recently developed by
the Rudnicka (2019). The methodology combines philological analysis with
statistical methods used on data acquired from mega-corpora. Moving from the
description of possible symptoms of obsolescence to different causes for it,
the paper aims at presenting a comprehensive account of the studied phenomenon.
Interestingly, a very significant role in the decline of in order that can be
ascribed to the so-called higher-order processes, understood as processes
influencing the constructional level from above. Two kinds of higher-order
processes are shown to play an important role, namely i) an
externally-motivated higher-order process exemplified by the drastic
socio-cultural changes of the 19th and 20th centuries; ii) an
internally-motivated higher-order processes instantiated by the rise of the
to-infinitive (rise of infinite clauses).",http://arxiv.org/abs/2502.04457v1
"Discovering Physics Laws of Dynamical Systems via Invariant Function
  Learning",2025-02-06T20:46:50Z,"Shurui Gui, Xiner Li, Shuiwang Ji","We consider learning underlying laws of dynamical systems governed by
ordinary differential equations (ODE). A key challenge is how to discover
intrinsic dynamics across multiple environments while circumventing
environment-specific mechanisms. Unlike prior work, we tackle more complex
environments where changes extend beyond function coefficients to entirely
different function forms. For example, we demonstrate the discovery of ideal
pendulum's natural motion $\alpha^2 \sin{\theta_t}$ by observing pendulum
dynamics in different environments, such as the damped environment $\alpha^2
\sin(\theta_t) - \rho \omega_t$ and powered environment $\alpha^2
\sin(\theta_t) + \rho \frac{\omega_t}{\left|\omega_t\right|}$. Here, we
formulate this problem as an \emph{invariant function learning} task and
propose a new method, known as \textbf{D}isentanglement of \textbf{I}nvariant
\textbf{F}unctions (DIF), that is grounded in causal analysis. We propose a
causal graph and design an encoder-decoder hypernetwork that explicitly
disentangles invariant functions from environment-specific dynamics. The
discovery of invariant functions is guaranteed by our information-based
principle that enforces the independence between extracted invariant functions
and environments. Quantitative comparisons with meta-learning and invariant
learning baselines on three ODE systems demonstrate the effectiveness and
efficiency of our method. Furthermore, symbolic regression explanation results
highlight the ability of our framework to uncover intrinsic laws.",http://arxiv.org/abs/2502.04495v1
"Probing a Vision-Language-Action Model for Symbolic States and
  Integration into a Cognitive Architecture",2025-02-06T23:11:11Z,"Hong Lu, Hengxu Li, Prithviraj Singh Shahani, Stephanie Herbers, Matthias Scheutz","Vision-language-action (VLA) models hold promise as generalist robotics
solutions by translating visual and linguistic inputs into robot actions, yet
they lack reliability due to their black-box nature and sensitivity to
environmental changes. In contrast, cognitive architectures (CA) excel in
symbolic reasoning and state monitoring but are constrained by rigid predefined
execution. This work bridges these approaches by probing OpenVLA's hidden
layers to uncover symbolic representations of object properties, relations, and
action states, enabling integration with a CA for enhanced interpretability and
robustness. Through experiments on LIBERO-spatial pick-and-place tasks, we
analyze the encoding of symbolic states across different layers of OpenVLA's
Llama backbone. Our probing results show consistently high accuracies (> 0.90)
for both object and action states across most layers, though contrary to our
hypotheses, we did not observe the expected pattern of object states being
encoded earlier than action states. We demonstrate an integrated DIARC-OpenVLA
system that leverages these symbolic representations for real-time state
monitoring, laying the foundation for more interpretable and reliable robotic
manipulation.",http://arxiv.org/abs/2502.04558v1
Private Federated Learning In Real World Application -- A Case Study,2025-02-06T23:38:50Z,"An Ji, Bortik Bandyopadhyay, Congzheng Song, Natarajan Krishnaswami, Prabal Vashisht, Rigel Smiroldo, Isabel Litton, Sayantan Mahinder, Mona Chitnis, Andrew W Hill","This paper presents an implementation of machine learning model training
using private federated learning (PFL) on edge devices. We introduce a novel
framework that uses PFL to address the challenge of training a model using
users' private data. The framework ensures that user data remain on individual
devices, with only essential model updates transmitted to a central server for
aggregation with privacy guarantees. We detail the architecture of our app
selection model, which incorporates a neural network with attention mechanisms
and ambiguity handling through uncertainty management. Experiments conducted
through off-line simulations and on device training demonstrate the feasibility
of our approach in real-world scenarios. Our results show the potential of PFL
to improve the accuracy of an app selection model by adapting to changes in
user behavior over time, while adhering to privacy standards. The insights
gained from this study are important for industries looking to implement PFL,
offering a robust strategy for training a predictive model directly on edge
devices while ensuring user data privacy.",http://arxiv.org/abs/2502.04565v2
Learning Semantics-aware Search Operators for Genetic Programming,2025-02-06T23:46:04Z,"Piotr Wyrwiński, Krzysztof Krawiec","Fitness landscapes in test-based program synthesis are known to be extremely
rugged, with even minimal modifications of programs often leading to
fundamental changes in their behavior and, consequently, fitness values.
Relying on fitness as the only guidance in iterative search algorithms like
genetic programming is thus unnecessarily limiting, especially when combined
with purely syntactic search operators that are agnostic about their impact on
program behavior. In this study, we propose a semantics-aware search operator
that steers the search towards candidate programs that are valuable not only
actually (high fitness) but also only potentially, i.e. are likely to be turned
into high-quality solutions even if their current fitness is low. The key
component of the method is a graph neural network that learns to model the
interactions between program instructions and processed data, and produces a
saliency map over graph nodes that represents possible search decisions. When
applied to a suite of symbolic regression benchmarks, the proposed method
outperforms conventional tree-based genetic programming and the ablated variant
of the method.",http://arxiv.org/abs/2502.04568v1
Ludwig-Soret microscopy with vibrational photothermal effect,2025-02-07T00:19:18Z,"Keiichiro Toda, Takuro Ideguchi","Vibrational microscopy provides label-free, bond-selective chemical contrast
by detecting molecular vibrations, making it invaluable for biomedical
research. While conventional methods rely on the direct detection of Raman
scattering or infrared absorption, recently developed vibrational photothermal
(ViP) microscopy achieves chemical contrast indirectly through refractive index
(RI) changes. This indirect approach enables unique imaging capabilities beyond
traditional chemical imaging. Here, we introduce a novel application of ViP
microscopy: label-free intracellular thermophoretic (Soret) imaging, which
visualizes biomolecular transport driven by temperature gradients. ViP-induced
Soret (ViPS) imaging leverages a steady-state temperature distribution
generated by optical heating through vibrational photothermal effect, combined
with time-resolved RI imaging via optical diffraction tomography (ODT). Using
ViPS imaging, we measured thermophoretic behavior in living COS7 cells,
determining intracellular diffusion and Soret coefficients. Notably, we
observed a reversed direction of molecular transport (negative Soret effect) in
the cytoplasm compared to the nucleus, possibly driven by
thermophoresis-induced diffusiophoresis. Furthermore, time-lapse imaging under
CO2-depleted conditions revealed a remarkable reduction in thermophoretic
activity, suggesting glass formation during the dying process, likely due to
polymer aggregation. ViPS imaging represents a new frontier in intracellular
thermophoretic studies, expanding the capabilities of vibrational microscopy.",http://arxiv.org/abs/2502.04578v1
Flavor Constraints in a Generational Three Higgs Doublet Model,2025-02-07T00:26:04Z,"Wolfgang Altmannshofer, Kevin Toner","We propose a Three Higgs Doublet Model (3HDM) that goes beyond natural flavor
conservation and in which each of the three Higgs doublets couples mainly to a
single generation of fermions via non-standard Yukawa structures. A hierarchy
in the vacuum expectation values of the three Higgs doublets can partially
address the SM flavor puzzle. In light of the experimentally observed $125$ GeV
Higgs boson, we primarily work within a 3HDM alignment limit such that a
Standard Model-like Higgs is recovered. In order to reproduce the observed CKM
mixing among quarks, the neutral Higgs bosons of the theory necessarily mediate
flavor changing neutral currents at the tree level. We consider constraints
from neutral kaon, $B$ meson, and $D$ meson mixing as well as from the rare
leptonic decays $B_s/B^0/K_L\rightarrow\mu^+\mu^-/e^+e^-$. We identify regions
of parameter space in which the new physics Higgs bosons can be as light as a
TeV or even lighter.",http://arxiv.org/abs/2502.04579v1
"Pure momentum-shift bulk photovoltaic effect in ferroelectric flat-band
  Mott insulators",2025-02-07T02:51:23Z,"Zhuocheng Lu, Zhihao Gong, Jingshan Qi, Hua Wang, Kai Chang","The shift current photovoltaic effect is conventionally understood as the
real-space displacement of a wave packet induced by photoexcitation. However,
this interpretation becomes insufficient in flat-band systems, where
quasiparticles are too massive to accelerate in real space under the optical
electric field. Here, we developed a gauge-invariant method to decompose the
shift current into real-space and momentum-space components. A surprising pure
momentum-space shift current is found theoretically in flat-band Mott insulator
Nb3X8 (X = Cl, Br, I) monolayers. This work underscores that significant shift
current responses can emerge even in systems with minimal interband
polarization differences, highlighting the potential for exploring novel bulk
photovoltaic effects in flat-band Mott insulators.",http://arxiv.org/abs/2502.04624v1
"CCS: Controllable and Constrained Sampling with Diffusion Models via
  Initial Noise Perturbation",2025-02-07T05:30:48Z,"Bowen Song, Zecheng Zhang, Zhaoxu Luo, Jason Hu, Wei Yuan, Jing Jia, Zhengxu Tang, Guanyang Wang, Liyue Shen","Diffusion models have emerged as powerful tools for generative tasks,
producing high-quality outputs across diverse domains. However, how the
generated data responds to the initial noise perturbation in diffusion models
remains under-explored, which hinders understanding the controllability of the
sampling process. In this work, we first observe an interesting phenomenon: the
relationship between the change of generation outputs and the scale of initial
noise perturbation is highly linear through the diffusion ODE sampling. Then we
provide both theoretical and empirical study to justify this linearity property
of this input-output (noise-generation data) relationship. Inspired by these
new insights, we propose a novel Controllable and Constrained Sampling method
(CCS) together with a new controller algorithm for diffusion models to sample
with desired statistical properties while preserving good sample quality. We
perform extensive experiments to compare our proposed sampling approach with
other methods on both sampling controllability and sampled data quality.
Results show that our CCS method achieves more precisely controlled sampling
while maintaining superior sample quality and diversity.",http://arxiv.org/abs/2502.04670v1
G2PDiffusion: Genotype-to-Phenotype Prediction with Diffusion Models,2025-02-07T06:16:31Z,"Mengdi Liu, Zhangyang Gao, Hong Chang, Stan Z. Li, Shiguang Shan, Xilin Chen","Discovering the genotype-phenotype relationship is crucial for genetic
engineering, which will facilitate advances in fields such as crop breeding,
conservation biology, and personalized medicine. Current research usually
focuses on single species and small datasets due to limitations in phenotypic
data collection, especially for traits that require visual assessments or
physical measurements. Deciphering complex and composite phenotypes, such as
morphology, from genetic data at scale remains an open question. To break
through traditional generic models that rely on simplified assumptions, this
paper introduces G2PDiffusion, the first-of-its-kind diffusion model designed
for genotype-to-phenotype generation across multiple species. Specifically, we
use images to represent morphological phenotypes across species and redefine
phenotype prediction as conditional image generation. To this end, this paper
introduces an environment-enhanced DNA sequence conditioner and trains a stable
diffusion model with a novel alignment method to improve genotype-to-phenotype
consistency. Extensive experiments demonstrate that our approach enhances
phenotype prediction accuracy across species, capturing subtle genetic
variations that contribute to observable traits.",http://arxiv.org/abs/2502.04684v2
A Meta-learner for Heterogeneous Effects in Difference-in-Differences,2025-02-07T07:04:37Z,"Hui Lan, Haoge Chang, Eleanor Dillon, Vasilis Syrgkanis","We address the problem of estimating heterogeneous treatment effects in panel
data, adopting the popular Difference-in-Differences (DiD) framework under the
conditional parallel trends assumption. We propose a novel doubly robust
meta-learner for the Conditional Average Treatment Effect on the Treated
(CATT), reducing the estimation to a convex risk minimization problem involving
a set of auxiliary models. Our framework allows for the flexible estimation of
the CATT, when conditioning on any subset of variables of interest using
generic machine learning. Leveraging Neyman orthogonality, our proposed
approach is robust to estimation errors in the auxiliary models. As a
generalization to our main result, we develop a meta-learning approach for the
estimation of general conditional functionals under covariate shift. We also
provide an extension to the instrumented DiD setting with non-compliance.
Empirical results demonstrate the superiority of our approach over existing
baselines.",http://arxiv.org/abs/2502.04699v1
"Quasinormal Modes and Dynamical Evolution of Scalar Fields in the
  Einstein-Bumblebee Theory with a Cosmological Constant",2025-02-07T09:34:29Z,"Hao Hu, Guoxiong Zhu","This paper investigates the dynamic behavior of static, spherically symmetric
black holes within the Einstein-Bumblebee gravity model with a cosmological
constant, focusing on scalar field perturbations. Through separation of the
angular components, the scalar field perturbations outside the black hole are
reduced to a purely radial main equation. The quasinormal modes (QNMs) of the
system are then determined via the WKB approximation in the frequency domain,
while the dynamic evolution of the system is examined in the time domain using
finite difference methods. The eigenfrequencies of the waveforms from the
time-domain evolution are fitted to cross-validate the frequency-domain
results. The study finds that the Lorentz violation parameter $ \ell $ and the
cosmological constant $ \Lambda $ significantly influence the QNMs.
Specifically, as $ \ell $ increases, the real and imaginary components of the
lower modes decrease, while in higher modes, the real part changes minimally,
and the imaginary part decreases rapidly. An increase in $ \Lambda $ similarly
results in a decrease in the overall QNM values. These results are supported by
the time-domain analysis, providing a clearer picture of how Lorentz symmetry
breaking affects the QNMs of de Sitter spacetime.",http://arxiv.org/abs/2502.04782v1
Impact-induced Vaporization During Accretion of Planetary Bodies,2025-02-07T09:45:19Z,"Adrien Saurety, Razvan Caracas, Sean N. Raymond","Giant impacts dominate the late stages of accretion of rocky planets. They
contribute to the heating, melting, and sometimes vaporizing of the bodies
involved in the impacts. Due to fractionation during melting and vaporization,
planet-building impacts can significantly change the composition and
geochemical signatures of rocky objects. Using first-principles molecular
dynamics simulations, we analyze the shock behavior of complex realistic
silicate systems, representative of both rocky bodies. We introduce a novel
criterion for vapor formation that uses entropy calculations to determine the
minimum impact velocity required to pass the threshold for vapor production. We
derive impact velocity criteria for vapor formation (7.1 km per s for
chondritic bodies) and show that this threshold is reached in 61 and 89 percent
of impacts in dynamical simulations of the late stages of accretion with
classical and annulus starting configuration (respectively) for analogs of
Earth. These outcomes should be nuanced by factors such as the impact angle and
the mass of the impacting bodies, which further influence the vaporization
dynamics and the resultant material distribution. Our findings indicate that
vaporization was common during accretion and likely played a crucial role in
shaping the early environments and material properties of terrestrial planets.",http://arxiv.org/abs/2502.04787v1
Monotonicity for solutions to semilinear problems in epigraphs,2025-02-07T10:17:04Z,"Nicolas Beuvin, Alberto Farina, Berardino Sciunzi","We consider positive solutions, possibly unbounded, to the semilinear
equation $-\Delta u=f(u)$ on continuous epigraphs bounded from below. Under the
homogeneous Dirichlet boundary condition, we prove new monotonicity results for
$u$, when $f$ is a (locally or globally) Lipschitz-continuous function
satisfying $ f(0) \geq 0$. As an application of our new monotonicity theorems,
we prove some classification and/or non-existence results. To prove our
results, we first establish some new comparison principles for semilinear
problems on general unbounded open sets of $\mathbb{R}^N$, and then we use them
to start and to complete a modified version of the moving plane method adapted
to the geometry of the epigraph $\Omega$. As a by-product of our analysis, we
also prove some new results of uniqueness and symmetry for solutions (possibly
unbounded and sign-changing) to the homogeneous Dirichlet BVP for the
semilinear Poisson equation in fairly general unbounded domains.",http://arxiv.org/abs/2502.04805v1
Describing Nonstationary Data Streams in Frequency Domain,2025-02-07T10:38:14Z,Joanna Komorniczak,"Concept drift is among the primary challenges faced by the data stream
processing methods. The drift detection strategies, designed to counteract the
negative consequences of such changes, often rely on analyzing the problem
metafeatures. This work presents the Frequency Filtering Metadescriptor -- a
tool for characterizing the data stream that searches for the informative
frequency components visible in the sample's feature vector. The frequencies
are filtered according to their variance across all available data batches. The
presented solution is capable of generating a metadescription of the data
stream, separating chunks into groups describing specific concepts on its
basis, and visualizing the frequencies in the original spatial domain. The
experimental analysis compared the proposed solution with two state-of-the-art
strategies and with the PCA baseline in the post-hoc concept identification
task. The research is followed by the identification of concepts in the
real-world data streams. The generalization in the frequency domain adapted in
the proposed solution allows to capture the complex feature dependencies as a
reduced number of frequency components, while maintaining the semantic meaning
of data.",http://arxiv.org/abs/2502.04813v1
"Ultraviolet Renormalization of Spin Boson Models I. Normal and
  2-Nilpotent Interactions",2025-02-07T12:28:05Z,"Benjamin Hinrichs, Jonas Lampart, Javier Valentín Martín","We study the ultraviolet problem for models of a finite-dimensional quantum
mechanical system linearly coupled to a bosonic quantum field, such as the
(many-)spin boson model or its rotating-wave approximation. If the state change
of the system upon emission or absorption of a boson is either given by a
normal matrix or by a 2-nilpotent one, which is the case for the previously
named examples, we prove an optimal renormalization result. We complement it,
by proving the norm resolvent convergence of appropriately regularized models
to the renormalized one. Our method consists of a dressing transformation
argument in the normal case and an appropriate interior boundary condition for
the 2-nilpotent case.",http://arxiv.org/abs/2502.04876v1
"Claim Extraction for Fact-Checking: Data, Models, and Automated Metrics",2025-02-07T14:20:45Z,"Herbert Ullrich, Tomáš Mlynář, Jan Drchal","In this paper, we explore the problem of Claim Extraction using one-to-many
text generation methods, comparing LLMs, small summarization models finetuned
for the task, and a previous NER-centric baseline QACG. As the current
publications on Claim Extraction, Fact Extraction, Claim Generation and
Check-worthy Claim Detection are quite scattered in their means and
terminology, we compile their common objectives, releasing the FEVERFact
dataset, with 17K atomic factual claims extracted from 4K contextualised
Wikipedia sentences, adapted from the original FEVER. We compile the known
objectives into an Evaluation framework of: Atomicity, Fluency,
Decontextualization, Faithfulness checked for each generated claim separately,
and Focus and Coverage measured against the full set of predicted claims for a
single input. For each metric, we implement a scale using a reduction to an
already-explored NLP task. We validate our metrics against human grading of
generic claims, to see that the model ranking on $F_{fact}$, our hardest
metric, did not change and the evaluation framework approximates human grading
very closely in terms of $F_1$ and RMSE.",http://arxiv.org/abs/2502.04955v1
"Fast Adaptive Anti-Jamming Channel Access via Deep Q Learning and
  Coarse-Grained Spectrum Prediction",2025-02-07T14:25:28Z,"Jianshu Zhang, Xiaofu Wu, Junquan Hu","This paper investigates the anti-jamming channel access problem in complex
and unknown jamming environments, where the jammer could dynamically adjust its
strategies to target different channels. Traditional channel hopping
anti-jamming approaches using fixed patterns are ineffective against such
dynamic jamming attacks. Although the emerging deep reinforcement learning
(DRL) based dynamic channel access approach could achieve the Nash equilibrium
under fast-changing jamming attacks, it requires extensive training episodes.
To address this issue, we propose a fast adaptive anti-jamming channel access
approach guided by the intuition of ``learning faster than the jammer"", where a
synchronously updated coarse-grained spectrum prediction serves as an auxiliary
task for the deep Q learning (DQN) based anti-jamming model. This helps the
model identify a superior Q-function compared to standard DRL while
significantly reducing the number of training episodes. Numerical results
indicate that the proposed approach significantly accelerates the rate of
convergence in model training, reducing the required training episodes by up to
70% compared to standard DRL. Additionally, it also achieves a 10% improvement
in throughput over NE strategies, owing to the effective use of coarse-grained
spectrum prediction.",http://arxiv.org/abs/2502.04963v1
New Security Challenges Towards In-Sensor Computing Systems,2025-02-07T16:09:47Z,"Mashrafi Kajol, Qiaoyan Yu","Data collection and processing in advanced health monitoring systems are
experiencing revolutionary change. In-Sensor Computing (ISC) systems emerge as
a promising alternative to save energy on massive data transmission,
analog-to-digital conversion, and ineffective processing. While the new
paradigm shift of ISC systems gains increasing attention, the highly compacted
systems could incur new challenges from a hardware security perspective. This
work first conducts a literature review to highlight the research trend of this
topic and then performs comprehensive analyses on the root of security
challenges. This is the first work that compares the security challenges of
traditional sensor-involved computing systems and emerging ISC systems.
Furthermore, new attack scenarios are predicted for board-, chip-, and
device-level ISC systems. Two proof-of-concept demos are provided to inspire
new countermeasure designs against unique hardware security threats in ISC
systems.",http://arxiv.org/abs/2502.05046v1
"Mining a Decade of Event Impacts on Contributor Dynamics in Ethereum: A
  Longitudinal Study",2025-02-07T16:24:13Z,"Matteo Vaccargiu, Sabrina Aufiero, Cheick Ba, Silvia Bartolucci, Richard Clegg, Daniel Graziotin, Rumyana Neykova, Roberto Tonelli, Giuseppe Destefanis","We analyze developer activity across 10 major Ethereum repositories (totaling
129884 commits, 40550 issues) spanning 10 years to examine how events such as
technical upgrades, market events, and community decisions impact development.
Through statistical, survival, and network analyses, we find that technical
events prompt increased activity before the event, followed by reduced commit
rates afterwards, whereas market events lead to more reactive development. Core
infrastructure repositories like Go-Ethereum exhibit faster issue resolution
compared to developer tools, and technical events enhance core team
collaboration. Our findings show how different types of events shape
development dynamics, offering insights for project managers and developers in
maintaining development momentum through major transitions. This work
contributes to understanding the resilience of development communities and
their adaptation to ecosystem changes.",http://arxiv.org/abs/2502.05054v1
Use of Winsome Robots for Understanding Human Feedback (UWU),2025-02-07T17:41:29Z,"Jessica Eggers, Angela Dai, Matthew C. Gombolay","As social robots become more common, many have adopted cute aesthetics aiming
to enhance user comfort and acceptance. However, the effect of this aesthetic
choice on human feedback in reinforcement learning scenarios remains unclear.
Previous research has shown that humans tend to give more positive than
negative feedback, which can cause failure to reach optimal robot behavior. We
hypothesize that this positive bias may be exacerbated by the robot's level of
perceived cuteness. To investigate, we conducted a user study where
participants critique a robot's trajectories while it performs a task. We then
analyzed the impact of the robot's aesthetic cuteness on the type of
participant feedback. Our results suggest that there is a shift in the ratio of
positive to negative feedback when perceived cuteness changes. In light of
this, we experiment with a stochastic version of TAMER which adapts based on
the user's level of positive feedback bias to mitigate these effects.",http://arxiv.org/abs/2502.05118v1
"Modelling hydrogen integration in energy system models: Best practices
  for policy insights",2025-01-21T14:20:37Z,"Muhammad Maladoh Bah, Sheng Wang, Mohsen Kia, Andrew Keane, Terence O'Donnell","The rapid emergence of hydrogen in long-term energy strategies requires a
broad understanding on how hydrogen is currently modelled in national energy
system models. This study provides a review on hydrogen representation within
selected energy system models that are tailored towards providing policy
insights. The paper adopts a multi-layered review approach and selects eleven
notable models for the review. The review covers hydrogen production, storage,
transportation, trade, demand, modeling strategies, and hydrogen policies. The
review suggests existing models would often opt for a simplified representation
that can capture each stage of the hydrogen supply chain. This approach allows
models to strike a balance between accuracy and preserving computational
resources. The paper provides several suggestions for modeling hydrogen in
national energy system models.",http://arxiv.org/abs/2502.05183v2
Regression and Forecasting of U.S. Stock Returns Based on LSTM,2025-02-03T19:26:44Z,"Shicheng Zhou, Zizhou Zhang, Rong Zhang, Yuchen Yin, Chia Hong Chang, Qinyan Shen","This paper analyses the investment returns of three stock sectors, Manuf,
Hitec, and Other, in the U.S. stock market, based on the Fama-French
three-factor model, the Carhart four-factor model, and the Fama-French
five-factor model, in order to test the validity of the Fama-French
three-factor model, the Carhart four-factor model, and the Fama-French
five-factor model for the three sectors of the market. French five-factor model
for the three sectors of the market. Also, the LSTM model is used to explore
the additional factors affecting stock returns. The empirical results show that
the Fama-French five-factor model has better validity for the three segments of
the market under study, and the LSTM model has the ability to capture the
factors affecting the returns of certain industries, and can better regress and
predict the stock returns of the relevant industries. Keywords- Fama-French
model; Carhart model; Factor model; LSTM model.",http://arxiv.org/abs/2502.05210v1
"Teaching An Old Dog New Tricks: Porting Legacy Code to Heterogeneous
  Compute Architectures With Automated Code Translation",2025-02-07T19:28:46Z,"Nicolas Nytko, Andrew Reisner, J. David Moulton, Luke N. Olson, Matthew West","Legacy codes are in ubiquitous use in scientific simulations; they are
well-tested and there is significant time investment in their use. However, one
challenge is the adoption of new, sometimes incompatible computing paradigms,
such as GPU hardware. In this paper, we explore using automated code
translation to enable execution of legacy multigrid solver code on GPUs without
significant time investment and while avoiding intrusive changes to the
codebase. We developed a thin, reusable translation layer that parses Fortran
2003 at compile time, interfacing with the existing library Loopy to transpile
to C++/GPU code, which is then managed by a custom MPI runtime system that we
created. With this low-effort approach, we are able to achieve a payoff of an
approximately 2-3x speedup over a full CPU socket, and 6x in multi-node
settings.",http://arxiv.org/abs/2502.05279v1
"Speejis: Enhancing User Experience of Mobile Voice Messaging with
  Automatic Visual Speech Emotion Cues",2025-02-07T19:56:45Z,"Ilhan Aslan, Carla F. Griggio, Henning Pohl, Timothy Merritt, Niels van Berkel","Mobile messaging apps offer an increasing range of emotional expressions,
such as emojis to help users manually augment their texting experiences.
Accessibility of such augmentations is limited in voice messaging. With the
term ""speejis"" we refer to accessible emojis and other visual speech emotion
cues that are created automatically from speech input alone. The paper presents
an implementation of speejis and reports on a user study (N=12) comparing the
UX of voice messaging with and without speejis. Results show significant
differences in measures such as attractiveness and stimulation and a clear
preference of all participants for messaging with speejis. We highlight the
benefits of using paralinguistic speech processing and continuous emotion
models to enable finer grained augmentations of emotion changes and transitions
within a single message in addition to augmentations of the overall tone of the
message.",http://arxiv.org/abs/2502.05296v1
"Analyzing public sentiment to gauge key stock events and determine
  volatility in conjunction with time and options premiums",2025-02-08T01:48:10Z,"SriVarsha Mulakala, Umesh Vangapally, Benjamin Larkey, Aidan Henrichs, Corey Wojslaw","Analyzing stocks and making higher accurate predictions on where the price is
heading continues to become more and more challenging therefore, we designed a
new financial algorithm that leverages social media sentiment analysis to
enhance the prediction of key stock earnings and associated volatility. Our
model integrates sentiment analysis and data retrieval techniques to extract
critical information from social media, analyze company financials, and compare
sentiments between Wall Street and the general public. This approach aims to
provide investors with timely data to execute trades based on key events,
rather than relying on long-term stock holding strategies. The stock market is
characterized by rapid data flow and fluctuating community sentiments, which
can significantly impact trading outcomes. Stock forecasting is complex given
its stochastic dynamic. Standard traditional prediction methods often overlook
key events and media engagement, focusing its practice into long-term
investment options. Our research seeks to change the stochastic dynamic to a
more predictable environment by examining the impact of media on stock
volatility, understanding and identifying sentiment differences between Wall
Street and retail investors, and evaluating the impact of various media
networks in predicting earning reports.",http://arxiv.org/abs/2502.05403v1
A Framework for On the Fly Input Refinement for Deep Learning Models,2025-02-08T05:41:01Z,Ravishka Rathnasuriya,"Advancements in deep learning have significantly improved model performance
across tasks involving code, text, and image processing. However, these models
still exhibit notable mispredictions in real-world applications, even when
trained on up-to-date data. Such failures often arise from slight variations in
inputs such as minor syntax changes in code, rephrasing in text, or subtle
lighting shifts in images that reveal inherent limitations in these models'
capability to generalize effectively. Traditional approaches to address these
challenges involve retraining, a resource-intensive process that demands
significant investments in data labeling, model updates, and redeployment. This
research introduces an adaptive, on-the-fly input refinement framework aimed at
improving model performance through input validation and transformation. The
input validation component detects inputs likely to cause errors, while input
transformation applies domain-specific adjustments to better align these inputs
with the model's handling capabilities. This dual strategy reduces
mispredictions across various domains, boosting model performance without
necessitating retraining. As a scalable and resource-efficient solution, this
framework holds significant promise for high-stakes applications in software
engineering, natural language processing, and computer vision.",http://arxiv.org/abs/2502.05456v1
"Closing the Responsibility Gap in AI-based Network Management: An
  Intelligent Audit System Approach",2025-02-08T15:30:25Z,"Emanuel Figetakis, Ahmed Refaey Hussein","Existing network paradigms have achieved lower downtime as well as a higher
Quality of Experience (QoE) through the use of Artificial Intelligence
(AI)-based network management tools. These AI management systems, allow for
automatic responses to changes in network conditions, lowering operation costs
for operators, and improving overall performance. While adopting AI-based
management tools enhance the overall network performance, it also introduce
challenges such as removing human supervision, privacy violations, algorithmic
bias, and model inaccuracies. Furthermore, AI-based agents that fail to address
these challenges should be culpable themselves rather than the network as a
whole. To address this accountability gap, a framework consisting of a Deep
Reinforcement Learning (DRL) model and a Machine Learning (ML) model is
proposed to identify and assign numerical values of responsibility to the
AI-based management agents involved in any decision-making regarding the
network conditions, which eventually affects the end-user. A simulation
environment was created for the framework to be trained using simulated network
operation parameters. The DRL model had a 96% accuracy during testing for
identifying the AI-based management agents, while the ML model using gradient
descent learned the network conditions at an 83% accuracy during testing.",http://arxiv.org/abs/2502.05608v1
"Transition from Regular Black Holes to Wormholes in Covariant Effective
  Quantum Gravity: Scattering, Quasinormal Modes, and Hawking Radiation",2025-02-08T20:44:31Z,"R. A. Konoplya, O. S. Stashko","Utilizing the Hamiltonian constraints approach, a quantum-corrected solution
has been derived \cite{Zhang:2024ney}, which describes either a regular black
hole or a traversable wormhole, contingent upon the value of the quantum
parameter. In this work, we compute the quasinormal modes associated with axial
gravitational and test fields' perturbations of these objects. We see that due
to quantum corrections near the event horizon, the first several overtones
deviate from their Schwarzschild values at an increasing rate. The transition
between the black hole and wormhole states is marked by modifications in the
late-time signal. Our findings reveal that the fundamental quasinormal modes of
quantum-corrected black holes exhibit only slight deviations from those of the
classical Schwarzschild solution. However, at the transition, the spectrum
undergoes significant changes, with the wormhole state characterized by
exceptionally long-lived quasinormal modes. In addition, we calculate
absorption cross-sections of partial waves, grey-body factors and energy
emission rates of Hawking radiation.",http://arxiv.org/abs/2502.05689v1
"I3S: Importance Sampling Subspace Selection for Low-Rank Optimization in
  LLM Pretraining",2025-02-09T06:30:19Z,"Haochen Zhang, Junze Yin, Guanchu Wang, Zirui Liu, Tianyi Zhang, Anshumali Shrivastava, Lin Yang, Vladimir Braverman","Low-rank optimization has emerged as a promising approach to enabling
memory-efficient training of large language models (LLMs). Existing low-rank
optimization methods typically project gradients onto a low-rank subspace,
reducing the memory cost of storing optimizer states. A key challenge in these
methods is identifying suitable subspaces to ensure an effective optimization
trajectory. Most existing approaches select the dominant subspace to preserve
gradient information, as this intuitively provides the best approximation.
However, we find that in practice, the dominant subspace stops changing during
pretraining, thereby constraining weight updates to similar subspaces.
  In this paper, we propose importance sampling subspace selection (I3S) for
low-rank optimization, which theoretically offers a comparable convergence rate
to the dominant subspace approach. Empirically, we demonstrate that I3S
significantly outperforms previous methods in LLM pretraining tasks.",http://arxiv.org/abs/2502.05790v1
De Finetti's problem with fixed transaction costs and regime switching,2025-02-09T10:21:47Z,"Wenyuan Wang, Zuo Quan Xu, Kazutoshi Yamazaki, Kaixin Yan, Xiaowen Zhou","In this paper, we examine a modified version of de Finetti's optimal dividend
problem, incorporating fixed transaction costs and altering the surplus process
by introducing two-valued drift and two-valued volatility coefficients. This
modification aims to capture the transitions or adjustments in the company's
financial status. We identify the optimal dividend strategy, which maximizes
the expected total net dividend payments (after accounting for transaction
costs) until ruin, as a two-barrier impulsive dividend strategy. Notably, the
optimal strategy can be explicitly determined for almost all scenarios
involving different drifts and volatility coefficients. Our primary focus is on
exploring how changes in drift and volatility coefficients influence the
optimal dividend strategy.",http://arxiv.org/abs/2502.05839v1
"Uniqueness of generalized conformal restriction measures and
  Malliavin-Kontsevich-Suhov measures for $c \in (0,1]$",2025-02-09T13:08:45Z,"Gefei Cai, Yifan Gao","In this paper, we present a unified approach to establish the uniqueness of
generalized conformal restriction measures with central charge $c \in (0, 1]$
in both chordal and radial cases, by relating these measures to the Brownian
loop soup. Our method also applies to the uniqueness of the
Malliavin-Kontsevich-Suhov loop measures for $c \in (0,1]$, which was recently
obtained in [Baverez-Jego, arXiv:2407.09080] for all $c \leq 1$ from a CFT
framework of SLE loop measures. In contrast, though only valid for $c \in
(0,1]$, our approach provides additional probabilistic insights, as it directly
links natural quantities of MKS measures to loop-soup observables.",http://arxiv.org/abs/2502.05890v4
"Topology Optimization considering Shielding and Penetrating Features
  based on Fictitious Physical Model",2025-02-09T13:30:10Z,"Daiki Soma, Kota Sakai, Takayuki Yamada","This paper proposes topology optimization for considering shielding and
penetrating features. Based on the fictitious physical model, which is a useful
approach to control geometric features, the proposed method analyzes fictitious
steady-state temperature fields and interprets target geometric features by
examining the temperature change. First, the concept of topology optimization
based on the level set method is introduced. Next, the basic idea of the
fictitious physical model for considering geometric features is explained.
Then, the differences between the shielding and penetrating features are
clarified, and the fictitious physical model for evaluating these features is
proposed. Furthermore, topology optimization for the minimum mean compliance
problem with geometric conditions is formulated. Finally, 2D and 3D numerical
examples are presented to validate the proposed method.",http://arxiv.org/abs/2502.05899v1
"Detection of Physiological Data Tampering Attacks with Quantum Machine
  Learning",2025-02-09T17:26:41Z,"Md. Saif Hassan Onim, Himanshu Thapliyal","The widespread use of cloud-based medical devices and wearable sensors has
made physiological data susceptible to tampering. These attacks can compromise
the reliability of healthcare systems which can be critical and
life-threatening. Detection of such data tampering is of immediate need.
Machine learning has been used to detect anomalies in datasets but the
performance of Quantum Machine Learning (QML) is still yet to be evaluated for
physiological sensor data. Thus, our study compares the effectiveness of QML
for detecting physiological data tampering, focusing on two types of white-box
attacks: data poisoning and adversarial perturbation. The results show that QML
models are better at identifying label-flipping attacks, achieving accuracy
rates of 75%-95% depending on the data and attack severity. This superior
performance is due to the ability of quantum algorithms to handle complex and
high-dimensional data. However, both QML and classical models struggle to
detect more sophisticated adversarial perturbation attacks, which subtly alter
data without changing its statistical properties. Although QML performed poorly
against this attack with around 45%-65% accuracy, it still outperformed
classical algorithms in some cases.",http://arxiv.org/abs/2502.05966v1
"An assessment of observational coverage and gaps for robust Sun to
  heliosphere integrated science",2025-02-09T21:21:44Z,"Yeimy J. Rivera, Samuel T. Badman","Understanding the generation and development of the continuous outflow from
the Sun requires tracing the physical conditions from deep in the corona to the
heliosphere. Detailed global observations of plasma state variables and the
magnetic field are needed to provide critical constraints to the underlying
physics driving models of the corona and solar wind. Key diagnostics of the
solar wind require measurements at its formation site and during its outflow to
continuously track it across rapidly changing regions of space. A unified view
of the solar wind is only possible through coordinated remote and in situ
observations that probe these different regions. Here, we discuss current
observational coverage and gaps of different plasma properties and review
recent coordinated studies. We highlight how these efforts may become more
routine with the launch of upcoming and planned missions.",http://arxiv.org/abs/2502.06036v2
Effects of particle angularity on granular self-organization,2025-02-10T00:48:55Z,"Dominik Krengel, Haoran Jiang, Takashi Matsushima, Raphael Blumenfeld","Recent studies of two-dimensional poly-disperse disc systems revealed a
coordinated self-organisation of cell stresses and shapes, with certain
distributions collapsing onto a master form for many processes, size
distributions, friction coefficients, and cell orders. Here we examine the
effects of grain angularity on the indicators of self-organisation, using
simulations of bi-disperse regular $N$-polygons and varying $N$ systematically.
We find that: the strong correlation between local cell stresses and
orientations, as well as the collapses of the conditional distributions of
scaled cell stress ratios to a master Weibull form for all cell orders $k$, are
independent of angularity and friction coefficient. In contrast, increasing
angularity makes the collapses of the conditional distributions sensitive to
changes in the friction coefficient.",http://arxiv.org/abs/2502.06085v1
Nonlinearity-induced Fractional Thouless Pumping of Solitons,2025-02-10T03:45:29Z,"Yu-Liang Tao, Yongping Zhang, Yong Xu","Recent studies have shown that a soliton can be {\it fractionally}
transported by slowly varying a system parameter over one period in a nonlinear
system. This phenomenon is attributed to the nontrivial topology of the
corresponding energy bands of a linear Hamiltonian. Here we find the occurrence
of fractional Thouless pumping of solitons in a nonlinear off-diagonal
Aubry-Andr\'{e}-Harper model. Surprisingly, this happens despite the fact that
all the energy bands of the linear Hamiltonian are topologically trivial,
indicating that nonlinearity can induce fractional Thouless pumping of
solitons. Specifically, our results show that a soliton can be pumped across
one unit cell over one, two, three or four pump periods, implying an average
displacement of $1$, $1/2$, $1/3$ or $1/4$ unit cells per cycle, respectively.
We attribute these behaviors to changes in on-site potentials induced by a
soliton solution, leading to the nontrivial topology for the modified linear
Hamiltonian. Given that our model relies solely on varying nearest-neighbor
hoppings, it is readily implementable on existing state-of-the-art photonic
platforms.",http://arxiv.org/abs/2502.06131v1
"Timing Matters: How Using LLMs at Different Timings Influences Writers'
  Perceptions and Ideation Outcomes in AI-Assisted Ideation",2025-02-10T06:51:50Z,"Peinuan Qin, Chi-Lan Yang, Jingshu Li, Jing Wen, Yi-Chieh Lee","Large Language Models (LLMs) have been widely used to support ideation in the
writing process. However, whether generating ideas with the help of LLMs leads
to idea fixation or idea expansion is unclear. This study examines how
different timings of LLM usage - either at the beginning or after independent
ideation - affect people's perceptions and ideation outcomes in a writing task.
In a controlled experiment with 60 participants, we found that using LLMs from
the beginning reduced the number of original ideas and lowered creative
self-efficacy and self-credit, mediated by changes in autonomy and ownership.
We discuss the challenges and opportunities associated with using LLMs to
assist in idea generation. We propose delaying the use of LLMs to support
ideation while considering users' self-efficacy, autonomy, and ownership of the
ideation outcomes.",http://arxiv.org/abs/2502.06197v1
Performance Analysis of Multi-Hop Networks at Terahertz Frequencies,2025-02-10T10:29:46Z,"Sara Cavallero, Andrea Pumilia, Giampaolo Cuozzo, Alessia Tarozzi, Chiara Buratti, Roberto Verdone","The emergence of THz (Terahertz) frequency wireless networks holds great
potential for advancing various high-demand services, including Industrial
Internet of Things (IIoT) applications. These use cases benefit significantly
from the ultra-high data rates, low latency, and high spatial resolution
offered by THz frequencies. However, a primary well-known challenge of THz
networks is their limited coverage range due to high path loss and
vulnerability to obstructions. This paper addresses this limitation by
proposing two novel multi-hop protocols, Table-Less (TL) and Table-Based (TB),
respectively, both avoiding centralized control and/or control plane
transmissions. Indeed, both solutions are distributed, simple, and rapidly
adaptable to network changes. Simulation results demonstrate the effectiveness
of our approaches, as well as revealing interesting trade-offs between TL and
TB routing protocols, both in a real IIoT THz network and under static and
dynamic conditions.",http://arxiv.org/abs/2502.06330v1
"Tailoring indistinguishability of photons using longitudinal spatial
  coherence",2025-02-10T10:34:09Z,"Preeti Sharma, Gaytri Arya, Bhaskar Kanseri","Methods to generate photons with tailored indistinguishability are central to
developing photonic quantum technologies and making fundamental tests of
quantum physics. This study introduces a novel method for manipulating
effective longitudinal spatial coherence (LSC) of biphotons, controlling their
indistinguishability in a significant manner. The experimental results show
that, instead of tailoring the frequency spectrum of the interfering photons,
changing their LSC also leads to controlling the width of Hong-Ou-Mandel dip as
validated by the theoretical calculations. This powerful approach not only
modifies the conventional wisdom claiming only frequency width responsible for
indistinguishability control of photons but also positions the LSC as a
promising tool for fine-tuning the longitudinal coherence of photons, thereby
expanding their potential use in quantum science and technologies.",http://arxiv.org/abs/2502.06333v1
"New opportunities for high pressure hydrogen achieved by fullerane
  vibrating modes: an ab initio study",2025-02-10T13:18:00Z,"Leonard Constantin Gebac, Vasile Bercu","The encapsulation of hydrogen within fullerene/fullerane cages offers a
promising avenue for studying high pressure hydrogen dynamics. Through ab
initio molecular dynamics simulations, we investigate the behavior of a system
consisting of hydrogen atoms enclosed in a \ch{C20H20} dodecahedrane. Our
findings reveal significant structural and dynamical changes as the cage
undergoes compression, corresponding to radial symmetric vibration. We analyze
geometric, energetic, and thermodynamic parameters, highlighting correlations
and observing behavior analogous to high pressure phases of hydrogen. Notably,
our study bridges the gap between theory and experiment by proposing a novel
approach to achieving high pressures and temperatures experimentally. These
results not only contribute to the understanding of hydrogen behavior under
extreme conditions but also hold implications for the quest to attain metallic
hydrogen - a milestone in materials science with potential applications in
various fields.",http://arxiv.org/abs/2502.06441v1
"Interpretation of 95 GeV Excess within the Georgi-Machacek Model in
  Light of Positive Definiteness Constraints",2025-02-10T13:20:03Z,"Xiaokang Du, Huiling Liu, Qin Chang","The recent observation of a di-photon excess around 95 GeV by the CMS and
ATLAS Collaborations, along with the $b\bar{b}$ excess reported by the LEP
Collaboration in the same mass region, has drawn significant interest in the
possibility of new physics beyond the Standard Model (SM). The Georgi-Machacek
(GM) model, which extends the Higgs sector of the SM by introducing additional
triplet scalars while preserving custodial symmetry at tree level, provides a
compelling framework to explain both excesses simultaneously via a light
custodial singlet Higgs. In this work, we investigate whether the GM model can
still accommodate these excesses when taking into account newly proposed vacuum
stability constraints, particularly the positive definiteness conditions. Our
numerical analysis not only confirms the existence of a viable parameter space
capable of explaining the 95 GeV excesses, but also demonstrates that, compared
to traditional tree-level constraints at the electroweak scale, the positive
definiteness conditions further expand the allowed parameter space, thereby
enhancing the viability of the GM model. Furthermore, we emphasize that future
collider experiments will play a crucial role in testing this interpretation by
refining Higgs coupling measurements and searching for additional Higgs bosons.",http://arxiv.org/abs/2502.06444v1
Group-CLIP Uncertainty Modeling for Group Re-Identification,2025-02-10T13:41:35Z,"Qingxin Zhang, Haoyan Wei, Yang Qian","Group Re-Identification (Group ReID) aims matching groups of pedestrians
across non-overlapping cameras. Unlike single-person ReID, Group ReID focuses
more on the changes in group structure, emphasizing the number of members and
their spatial arrangement. However, most methods rely on certainty-based
models, which consider only the specific group structures in the group images,
often failing to match unseen group configurations. To this end, we propose a
novel Group-CLIP UncertaintyModeling (GCUM) approach that adapts group text
descriptions to undetermined accommodate member and layout variations.
Specifically, we design a Member Variant Simulation (MVS)module that simulates
member exclusions using a Bernoulli distribution and a Group Layout Adaptation
(GLA) module that generates uncertain group text descriptions with
identity-specific tokens. In addition, we design a Group
RelationshipConstruction Encoder (GRCE) that uses group features to refine
individual features, and employ cross-modal contrastive loss to obtain
generalizable knowledge from group text descriptions. It is worth noting that
we are the first to employ CLIP to GroupReID, and extensive experiments show
that GCUM significantly outperforms state-of-the-art Group ReID methods.",http://arxiv.org/abs/2502.06460v1
Quicker flocking in aligning active matters for noisier beginning,2025-02-10T13:59:33Z,"Sohini Chatterjee, Sohom Das, Purnendu Pathak, Tanay Paul, Subir K. Das","The constituents in a class of active matter systems change their directions
of motion by being influenced by the velocities of the neighbors. Such systems
may undergo phase transitions, with respect to ordering in the velocity field,
as well as clustering in the density field, when the strength of an externally
imposed noise is varied. Via computer simulations, with a well-known model,
that faithfully represents these systems, we show that evolutions in both
clustering and ordering exhibit certain interesting features that were hitherto
unrealized. The transformations occur quicker, following quenches to a fixed
final state, below the transition point, for disordered starting states that
are farther away from the ``critical"" noise strength. This implies earliest
arrival of the farthest, at a given destination. Detailed analysis of the
results, combined with the outcomes from a similar study of para- to
ferromagnetic transitions, show that the variation in critical fluctuations in
the initial configurations can lead to such interesting effect. We quantify
this via the Ornstein-Zernike theory.",http://arxiv.org/abs/2502.06482v1
Boost-and-Skip: A Simple Guidance-Free Diffusion for Minority Generation,2025-02-10T14:37:26Z,"Soobin Um, Beomsu Kim, Jong Chul Ye","Minority samples are underrepresented instances located in low-density
regions of a data manifold, and are valuable in many generative AI
applications, such as data augmentation, creative content generation, etc.
Unfortunately, existing diffusion-based minority generators often rely on
computationally expensive guidance dedicated for minority generation. To
address this, here we present a simple yet powerful guidance-free approach
called Boost-and-Skip for generating minority samples using diffusion models.
The key advantage of our framework requires only two minimal changes to
standard generative processes: (i) variance-boosted initialization and (ii)
timestep skipping. We highlight that these seemingly-trivial modifications are
supported by solid theoretical and empirical evidence, thereby effectively
promoting emergence of underrepresented minority features. Our comprehensive
experiments demonstrate that Boost-and-Skip greatly enhances the capability of
generating minority samples, even rivaling guidance-based state-of-the-art
approaches while requiring significantly fewer computations.",http://arxiv.org/abs/2502.06516v1
OpenMM-MiMiC Interface for Efficient and Flexible Multiscale Simulations,2025-02-10T15:04:39Z,"Andrea Levy, Andrej Antalík, Jógvan Magnus Haugaard Olsen, Ursula Rothlisberger","MiMiC is a flexible and efficient framework for multiscale simulations in
which different subsystems are treated by individual client programs. In this
work, we present a new interface with OpenMM to be used as an MM client program
and we demonstrate its efficiency for QM/MM MD simulations. Apart from its high
performance, especially on GPUs, and a wide selection of features, OpenMM is a
highly-flexible and easily-extensible program, ideal for the development of
novel multiscale methods. Thanks to the open-ended design of MiMiC, the
OpenMM-MiMiC interface will automatically support any new QM client program
interfaced with MiMiC for QM/MM and, with minimal changes needed, new
multiscale methods implemented, opening up new research directions beyond
electrostatic embedding QM/MM.",http://arxiv.org/abs/2502.06539v1
"LiveForesighter: Generating Future Information for Live-Streaming
  Recommendations at Kuaishou",2025-02-10T15:24:55Z,"Yucheng Lu, Jiangxia Cao, Xu Kuan, Wei Cheng, Wei Jiang, Jiaming Zhang, Yang Shuang, Liu Zhaojie, Liyin Hong","Live-streaming, as a new-generation media to connect users and authors, has
attracted a lot of attention and experienced rapid growth in recent years.
Compared with the content-static short-video recommendation, the live-streaming
recommendation faces more challenges in giving our users a satisfactory
experience: (1) Live-streaming content is dynamically ever-changing along time.
(2) valuable behaviors (e.g., send digital-gift, buy products) always require
users to watch for a long-time (>10 min). Combining the two attributes, here
raising a challenging question for live-streaming recommendation: How to
discover the live-streamings that the content user is interested in at the
current moment, and further a period in the future?",http://arxiv.org/abs/2502.06557v1
"Pinning Is Futile: You Need More Than Local Dependency Versioning to
  Defend against Supply Chain Attacks",2025-02-10T16:50:48Z,"Hao He, Bogdan Vasilescu, Christian Kästner","Recent high-profile incidents in open-source software have greatly raised
practitioner attention on software supply chain attacks. To guard against
potential malicious package updates, security practitioners advocate pinning
dependency to specific versions rather than floating in version ranges.
However, it remains controversial whether pinning carries a meaningful security
benefit that outweighs the cost of maintaining outdated and possibly vulnerable
dependencies. In this paper, we quantify, through counterfactual analysis and
simulations, the security and maintenance impact of version constraints in the
npm ecosystem. By simulating dependency resolutions over historical time
points, we find that pinning direct dependencies not only (as expected)
increases the cost of maintaining vulnerable and outdated dependencies, but
also (surprisingly) even increases the risk of exposure to malicious package
updates in larger dependency graphs due to the specifics of npm's dependency
resolution mechanism. Finally, we explore collective pinning strategies to
secure the ecosystem against supply chain attacks, suggesting specific changes
to npm to enable such interventions. Our study provides guidance for
practitioners and tool designers to manage their supply chains more securely.",http://arxiv.org/abs/2502.06662v1
Application of Artificial Intelligence (AI) in Civil Engineering,2025-02-10T17:55:52Z,"Temitope Funmilayo Awolusi, Bernard Chukwuemeka Finbarrs-Ezema, Isaac Munachimdinamma Chukwudulue, Marc Azab","Hard computing generally deals with precise data, which provides ideal
solutions to problems. However, in the civil engineering field, amongst other
disciplines, that is not always the case as real-world systems are continuously
changing. Here lies the need to explore soft computing methods and artificial
intelligence to solve civil engineering shortcomings. The integration of
advanced computational models, including Artificial Neural Networks (ANNs),
Fuzzy Logic, Genetic Algorithms (GAs), and Probabilistic Reasoning, has
revolutionized the domain of civil engineering. These models have significantly
advanced diverse sub-fields by offering innovative solutions and improved
analysis capabilities. Sub-fields such as: slope stability analysis, bearing
capacity, water quality and treatment, transportation systems, air quality,
structural materials, etc. ANNs predict non-linearities and provide accurate
estimates. Fuzzy logic uses an efficient decision-making process to provide a
more precise assessment of systems. Lastly, while GAs optimizes models (based
on evolutionary processes) for better outcomes, probabilistic reasoning lowers
their statistical uncertainties.",http://arxiv.org/abs/2502.06727v1
Institutional Preferences in the Laboratory,2025-02-10T18:17:16Z,"Qiankun Zhong, Nori Jacoby, Ofer Tchernichovski, Seth Frey","Getting a group to adopt cooperative norms is an enduring challenge. But in
real-world settings, individuals don't just passively accept static
environments, they act both within and upon the social systems that structure
their interactions. Should we expect the dynamism of player-driven changes to
the ""rules of the game"" to hinder cooperation -- because of the substantial
added complexity -- or help it, as prosocial agents tweak their environment
toward non-zero-sum games? We introduce a laboratory setting to test whether
groups can guide themselves to cooperative outcomes by manipulating the
environmental parameters that shape their emergent cooperation process. We test
for cooperation in a set of economic games that impose different social
dilemmas. These games vary independently in the institutional features of
stability, efficiency, and fairness. By offering agency over behavior along
with second-order agency over the rules of the game, we understand emergent
cooperation in naturalistic settings in which the rules of the game are
themselves dynamic and subject to choice. The literature on transfer learning
in games suggests that interactions between features are important and might
aid or hinder the transfer of cooperative learning to new settings.",http://arxiv.org/abs/2502.06748v1
DeepCell: Multiview Representation Learning for Post-Mapping Netlists,2025-02-05T02:39:47Z,"Zhengyuan Shi, Chengyu Ma, Ziyang Zheng, Lingfeng Zhou, Hongyang Pan, Wentao Jiang, Fan Yang, Xiaoyan Yang, Zhufei Chu, Qiang Xu","Representation learning for post-mapping (PM) netlists is a critical
challenge in Electronic Design Automation (EDA), driven by the diverse and
complex nature of modern circuit designs. Existing approaches focus on
intermediate representations like And-Inverter Graphs (AIGs), limiting their
applicability to post-synthesis stages. We introduce DeepCell, a multiview
representation learning framework that integrates structural and functional
insights from both PM netlists and AIGs to learn rich, generalizable
embeddings. At its core, DeepCell employs the novel Mask Circuit Modeling (MCM)
mechanism, which refines PM netlist representations in a self-supervised manner
using pretrained AIG encoders. DeepCell sets a new benchmark in PM netlist
representation, outperforming existing methods in predictive accuracy and
reconstruction fidelity. To validate its efficacy, we apply DeepCell to
functional Engineering Change Orders (ECO), achieving significant reductions in
patch generation costs and runtime while improving patch quality.",http://arxiv.org/abs/2502.06816v1
"Emergence of Episodic Memory in Transformers: Characterizing Changes in
  Temporal Structure of Attention Scores During Training",2025-02-09T20:20:37Z,"Deven Mahesh Mistry, Anooshka Bajaj, Yash Aggarwal, Sahaj Singh Maini, Zoran Tiganj","We investigate in-context temporal biases in attention heads and transformer
outputs. Using cognitive science methodologies, we analyze attention scores and
outputs of the GPT-2 models of varying sizes. Across attention heads, we
observe effects characteristic of human episodic memory, including temporal
contiguity, primacy and recency. Transformer outputs demonstrate a tendency
toward in-context serial recall. Importantly, this effect is eliminated after
the ablation of the induction heads, which are the driving force behind the
contiguity effect. Our findings offer insights into how transformers organize
information temporally during in-context learning, shedding light on their
similarities and differences with human memory and learning.",http://arxiv.org/abs/2502.06902v1
Quasilattices of the Spectre monotile,2025-02-10T18:45:55Z,"Henning U. Voss, Douglas J. Ballon","The Spectre is a family of recently discovered aperiodic monotiles that tile
the plane only in non-periodic ways, and novel physical phenomena have been
predicted for planar systems made of aperiodic monotiles. It is shown that
point decorations of Tile(1,1), the base tile for all Spectres, supports the
generation of a large variety of non-periodic quasilattices, in contrast to
Bravais-lattices in which all point decorations would be periodic. A lattice
generating function is introduced as a mapping from point decorations to
quasilattice space, and investigated systematically. It is found that some
lattices result from the properties of nearest-neighbor distances of point
decorations, and that other lattices show near-periodicity in projections along
one of the symmetry axes of the tiling. It is concluded that the lattice
generating function can serve as a template for the design of physical
potential landscapes that can be controlled by the point decoration as a
parameter.",http://arxiv.org/abs/2502.06926v2
"Collective flavor conversions are interactions of neutrinos with
  quantized flavor waves",2025-02-10T19:00:00Z,"Damiano F. G. Fiorillo, Georg G. Raffelt","Collective oscillations in dense neutrino gases (flavor waves) are notable
for their instabilities that cause fast flavor conversion. We develop a quantum
theory of interacting neutrinos and flavor wave quanta, which are analogous to
plasmons, but also carry flavor. The emission or absorption of such flavor
plasmons $\psi$, or flavomons, changes the neutrino flavor. When an angular
crossing occurs, the process $\nu_\mu\to\nu_e+\psi$ is more rapid than its
inverse along the direction of the crossing, triggering stimulated $\psi$
emission and fast instability. Calculating the rate via Feynman diagrams
matches the fast instability growth rate. Our novel $\nu$ and $\psi$ kinetic
equations, corresponding to quasi-linear theory, describe instability evolution
without resolving the small scales of the flavomon wavelength, potentially
overcoming the main challenge of fast flavor evolution.",http://arxiv.org/abs/2502.06935v1
Large thermoelectric spin-valve effect with a superconductor,2025-02-10T19:02:07Z,"Pablo Tuero, Johanne Bratland Tjernshaugen, Carlos Sanchez, César Gonzalez-Ruano, Yuan Lu, Jacob Linder, Farkhad G. Aliev","Recent studies have revealed magnetically controllable thermoelectric effects
in superconductor/ferromagnet (S/F) structures. A tunable cryogenic
thermoelectric generator needs not only a high conversion factor between
electricity and heat, but also a large change in the thermoelectric output when
switching the magnetic state of the device. Here, we experimentally measure and
numerically model thermoelectric effects in fully epitaxial F/S/F junctions
based on commercially available, easily grown materials, as well as their
dependence on the magnetic configuration of the F electrodes. We observe
sizeable Seebeck coefficients for the parallel alignment of the ferromagnetic
electrodes, reaching values of about $100$~$\mu$V/K. Importantly, we find a
decrease of the thermoelectric signal of more than an order of magnitude when
switching from a parallel to an antiparallel configuration, constituting a
large thermoelectric spin-valve effect. Theoretical modeling based on a
self-consistent non-equilibrium Keldysh-Usadel Green function theory, combined
with micromagnetic simulations, qualitatively reproduce the experimental
findings. These findings pave the way for the development of efficient and
versatile cryogenic thermoelectric heat engines.",http://arxiv.org/abs/2502.06962v1
"Representational Alignment with Chemical Induced Fit for Molecular
  Relational Learning",2025-02-07T09:29:21Z,"Peiliang Zhang, Jingling Yuan, Qing Xie, Yongjun Zhu, Lin Li","Molecular Relational Learning (MRL) is widely applied in natural sciences to
predict relationships between molecular pairs by extracting structural
features. The representational similarity between substructure pairs determines
the functional compatibility of molecular binding sites. Nevertheless, aligning
substructure representations by attention mechanisms lacks guidance from
chemical knowledge, resulting in unstable model performance in chemical space
(\textit{e.g.}, functional group, scaffold) shifted data. With theoretical
justification, we propose the \textbf{Re}presentational \textbf{Align}ment with
Chemical Induced \textbf{Fit} (ReAlignFit) to enhance the stability of MRL.
ReAlignFit dynamically aligns substructure representation in MRL by introducing
chemical Induced Fit-based inductive bias. In the induction process, we design
the Bias Correction Function based on substructure edge reconstruction to align
representations between substructure pairs by simulating chemical
conformational changes (dynamic combination of substructures). ReAlignFit
further integrates the Subgraph Information Bottleneck during fit process to
refine and optimize substructure pairs exhibiting high chemical functional
compatibility, leveraging them to generate molecular embeddings. Experimental
results on nine datasets demonstrate that ReAlignFit outperforms
state-of-the-art models in two tasks and significantly enhances model's
stability in both rule-shifted and scaffold-shifted data distributions.",http://arxiv.org/abs/2502.07027v1
"Leveraging Allophony in Self-Supervised Speech Models for Atypical
  Pronunciation Assessment",2025-02-10T20:46:42Z,"Kwanghee Choi, Eunjung Yeo, Kalvin Chang, Shinji Watanabe, David Mortensen","Allophony refers to the variation in the phonetic realization of a phoneme
based on its phonetic environment. Modeling allophones is crucial for atypical
pronunciation assessment, which involves distinguishing atypical from typical
pronunciations. However, recent phoneme classifier-based approaches often
simplify this by treating various realizations as a single phoneme, bypassing
the complexity of modeling allophonic variation. Motivated by the acoustic
modeling capabilities of frozen self-supervised speech model (S3M) features, we
propose MixGoP, a novel approach that leverages Gaussian mixture models to
model phoneme distributions with multiple subclusters. Our experiments show
that MixGoP achieves state-of-the-art performance across four out of five
datasets, including dysarthric and non-native speech. Our analysis further
suggests that S3M features capture allophonic variation more effectively than
MFCCs and Mel spectrograms, highlighting the benefits of integrating MixGoP
with S3M features.",http://arxiv.org/abs/2502.07029v1
SnipGen: A Mining Repository Framework for Evaluating LLMs for Code,2025-02-10T21:28:15Z,"Daniel Rodriguez-Cardenas, Alejandro Velasco, Denys Poshyvanyk","Language Models (LLMs), such as transformer-based neural networks trained on
billions of parameters, have become increasingly prevalent in software
engineering (SE). These models, trained on extensive datasets that include code
repositories, exhibit remarkable capabilities for SE tasks. However, evaluating
their effectiveness poses significant challenges, primarily due to the
potential overlap between the datasets used for training and those employed for
evaluation. To address this issue, we introduce SnipGen, a comprehensive
repository mining framework designed to leverage prompt engineering across
various downstream tasks for code generation. SnipGen aims to mitigate data
contamination by generating robust testbeds and crafting tailored data points
to assist researchers and practitioners in evaluating LLMs for code-related
tasks. In our exploratory study, SnipGen mined approximately 227K data points
from 338K recent code changes in GitHub commits, focusing on method-level
granularity. SnipGen features a collection of prompt templates that can be
combined to create a Chain-of-Thought-like sequence of prompts, enabling a
nuanced assessment of LLMs' code generation quality. By providing the mining
tool, the methodology, and the dataset, SnipGen empowers researchers and
practitioners to rigorously evaluate and interpret LLMs' performance in
software engineering contexts.",http://arxiv.org/abs/2502.07046v2
Autonomous Deep Agent,2025-02-10T21:46:54Z,"Amy Yu, Erik Lebedev, Lincoln Everett, Xiaoxin Chen, Terry Chen","This technical brief introduces Deep Agent, an advanced autonomous AI system
designed to manage complex multi-phase tasks through a novel hierarchical task
management architecture. The system's foundation is built on our Hierarchical
Task DAG (HTDAG) framework, which dynamically decomposes high-level objectives
into manageable sub-tasks while rigorously maintaining dependencies and
execution coherence. Deep Agent advances beyond traditional agent systems
through three key innovations: First, it implements a recursive two-stage
planner-executor architecture that enables continuous task refinement and
adaptation as circumstances change. Second, it features an Autonomous API &
Tool Creation (AATC) system that automatically generates reusable components
from UI interactions, substantially reducing operational costs for similar
tasks. Third, it incorporates Prompt Tweaking Engine and Autonomous Prompt
Feedback Learning components that optimize Large Language Model prompts for
specific scenarios, enhancing both inference accuracy and operational
stability. These components are integrated to form a service infrastructure
that manages user contexts, handles complex task dependencies, and orchestrates
end-to-end agentic workflow execution. Through this sophisticated architecture,
Deep Agent establishes a novel paradigm in self-governing AI systems,
demonstrating robust capability to independently handle intricate, multi-step
tasks while maintaining consistent efficiency and reliability through
continuous self-optimization.",http://arxiv.org/abs/2502.07056v1
"Precision Control of Resistive Power in Kibble Balance Coils: An
  Advanced Method for Minimizing Temperature-Related Magnetic Errors",2025-02-11T05:08:46Z,"Weibo Liu, Stephan Schlamminger, Shisong Li","Temperature changes affect the coercivity of permanent magnets, thereby
impacting the $Bl$ factor and potentially introducing systematic errors in
Kibble balance measurements. While the thermal-magnetic effect is negligible in
large magnet systems, it increases substantially as the magnet size decreases,
posing an engineering difficulty for tabletop Kibble balance systems. We
discuss the mechanism of thermal-magnetic effects through finite element
analysis, which has not been sufficiently emphasized in previous studies. A
bifilar-coil power regulator is proposed to eliminate thermal-magnetic errors
in Kibble balances. The approach aims to keep the power of the internal heating
source -- coil ohmic power -- constant over time, allowing the $Bl$ drift to be
mitigated through ABA or ABBA measurement sequences. Experimental results
validate the proposal, demonstrating that the thermal effect can be reduced by
more than two orders of magnitude compared to the conventional two-mode,
two-phase measurement scheme, and by about one order of magnitude compared to
the one-mode, two-phase scheme. The proposed approach can eliminate the
influence of thermal-magnetic effects on the measurement results, thus further
breaking down the limitations on the minimum size of tabletop Kibble balances.",http://arxiv.org/abs/2502.07264v1
Mixed-state geometric phases of coherent and squeezed spin states,2025-02-11T05:32:27Z,"Xin Wang, Jia-Chen Tang, Xu-Yang Hou, Hao Guo, Chih-Chun Chien","Two mixed-state geometric phases, known as the Uhlmann phase and
interferometric phase (IGP), of spin coherent states (CSSs) and spin squeezed
states (SSSs) are analyzed. While each phase follows its parallel-transport
condition, we also consider the non-adiabatic IGP for arbitrary unitary
evolution beyond parallel transport. For the $j=3/2$ CSS, the Uhlmann phase
shows temperature-induced topological phase transitions with jumps. The IGP and
non-adiabatic IGP for the $j=3/2$ CSS also exhibits temperature-induced jumps.
In contrast, the Uhlmann phase of the $j=1$ SSS exhibits smooth behavior
without any temperature-induced transition. Interestingly, the
parallel-transport condition of the IGP of the $j=1$ SSS in general does not
allow a solution at finite temperature. Instead, the non-adiabatic IGP for the
$j=1$ SSS has a solution showing smooth behavior as the squeezing parameter and
temperature change. We also briefly discuss possible experimental implications
and simulations.",http://arxiv.org/abs/2502.07268v1
"MIGT: Memory Instance Gated Transformer Framework for Financial
  Portfolio Management",2025-02-11T05:54:42Z,"Fengchen Gu, Angelos Stefanidis, Ángel García-Fernández, Jionglong Su, Huakang Li","Deep reinforcement learning (DRL) has been applied in financial portfolio
management to improve returns in changing market conditions. However, unlike
most fields where DRL is widely used, the stock market is more volatile and
dynamic as it is affected by several factors such as global events and investor
sentiment. Therefore, it remains a challenge to construct a DRL-based portfolio
management framework with strong return capability, stable training, and
generalization ability. This study introduces a new framework utilizing the
Memory Instance Gated Transformer (MIGT) for effective portfolio management. By
incorporating a novel Gated Instance Attention module, which combines a
transformer variant, instance normalization, and a Lite Gate Unit, our approach
aims to maximize investment returns while ensuring the learning process's
stability and reducing outlier impacts. Tested on the Dow Jones Industrial
Average 30, our framework's performance is evaluated against fifteen other
strategies using key financial metrics like the cumulative return and
risk-return ratios (Sharpe, Sortino, and Omega ratios). The results highlight
MIGT's advantage, showcasing at least a 9.75% improvement in cumulative returns
and a minimum 2.36% increase in risk-return ratios over competing strategies,
marking a significant advancement in DRL for portfolio management.",http://arxiv.org/abs/2502.07280v1
Spreading dynamics of information on online social networks,2025-02-11T06:30:48Z,"Fanhui Meng, Jiarong Xie, Jiachen Sun, Cong Xu, Yutian Zeng, Xiangrong Wang, Tao Jia, Shuhong Huang, Youjin Deng, Yanqing Hu","Social media is profoundly changing our society with its unprecedented
spreading power. Due to the complexity of human behaviors and the diversity of
massive messages, the information spreading dynamics are complicated, and the
reported mechanisms are different and even controversial. Based on data from
mainstream social media platforms, including WeChat, Weibo, and Twitter,
cumulatively encompassing a total of 7.45 billion users, we uncover a
ubiquitous mechanism that the information spreading dynamics are basically
driven by the interplay of social reinforcement and social weakening effects.
Accordingly, we propose a concise equation, which, surprisingly, can well
describe all the empirical large-scale spreading trajectories. Our theory
resolves a number of controversial claims and satisfactorily explains many
phenomena previously observed. It also reveals that the highly clustered nature
of social networks can lead to rapid and high-frequency information bursts with
relatively small coverage per burst. This vital feature enables social media to
have a high capacity and diversity for information dissemination, beneficial
for its ecological development.",http://arxiv.org/abs/2502.07291v1
"Aligning Large Language Models to Follow Instructions and Hallucinate
  Less via Effective Data Filtering",2025-02-11T08:05:56Z,"Shuzheng Si, Haozhe Zhao, Gang Chen, Cheng Gao, Yuzhuo Bai, Zhitong Wang, Kaikai An, Kangyang Luo, Chen Qian, Fanchao Qi, Baobao Chang, Maosong Sun","Training LLMs on data containing unfamiliar knowledge during the instruction
tuning stage can encourage hallucinations. To address this challenge, we
introduce NOVA, a novel framework designed to identify high-quality data that
aligns well with the LLM's learned knowledge to reduce hallucinations. NOVA
includes Internal Consistency Probing (ICP) and Semantic Equivalence
Identification (SEI) to measure how familiar the LLM is with instruction data.
Specifically, ICP evaluates the LLM's understanding of the given instruction by
calculating the tailored consistency among multiple self-generated responses.
SEI further assesses the familiarity of the LLM with the target response by
comparing it to the generated responses, using the proposed semantic clustering
and well-designed voting strategy. Finally, to ensure the quality of selected
samples, we introduce an expert-aligned reward model, considering
characteristics beyond just familiarity. By considering data quality and
avoiding unfamiliar data, we can utilize the selected data to effectively align
LLMs to follow instructions and hallucinate less.",http://arxiv.org/abs/2502.07340v2
"FedAPA: Server-side Gradient-Based Adaptive Personalized Aggregation for
  Federated Learning on Heterogeneous Data",2025-02-11T11:00:58Z,"Yuxia Sun, Aoxiang Sun, Siyi Pan, Zhixiao Fu, Jingcai Guo","Personalized federated learning (PFL) tailors models to clients' unique data
distributions while preserving privacy. However, existing
aggregation-weight-based PFL methods often struggle with heterogeneous data,
facing challenges in accuracy, computational efficiency, and communication
overhead. We propose FedAPA, a novel PFL method featuring a server-side,
gradient-based adaptive aggregation strategy to generate personalized models,
by updating aggregation weights based on gradients of client-parameter changes
with respect to the aggregation weights in a centralized manner. FedAPA
guarantees theoretical convergence and achieves superior accuracy and
computational efficiency compared to 10 PFL competitors across three datasets,
with competitive communication overhead.",http://arxiv.org/abs/2502.07456v2
"Non-Interchangeability between Heart Rate Variability and Pulse Rate
  Variability During Supine-to-Stand Tests",2025-02-11T13:21:19Z,"Runwei Lin, Frank Halfwerk, Gozewijn Dirk Laverman, Dirk Donker, Ying Wang","Heart rate variability (HRV) is widely recognized as a valuable biomarker for
assessing autonomic cardiac regulation. Pulse rate variability (PRV) is a
common surrogate of HRV given the wide usability of PPG in commercially
available devices. However, there is no clear conclusion on whether PRV can
replace HRV given their different physiological mechanisms. This study
evaluates the interchangeability of young adults HRV and PRV during
supine-to-stand (STS) tests which are known as common posture transitions in
daily life monitoring. Fifteen features from time, frequency and nonlinear
domains were extracted from both electrocardiography and PPG signals. Paired
t-tests and Wilcoxon signed-rank tests examined the difference between the
extracted HRV and PRV features during supine, transition and standing phases
separately. One feature showed significant difference in the supine phase, and
this discrepancy increased to four in the transition and standing phases. These
findings suggested that PRV is different from HRV in the STS tests, despite the
fact that both metrics can reflect the sympathetic activation triggered by the
posture changes.",http://arxiv.org/abs/2502.07535v1
"Exact Schwinger functions for a class of bounded interactions in $d\geq
  2$",2025-02-11T13:32:13Z,Wojciech Dybalski,"We consider a scalar Euclidean QFT with interaction given by a bounded,
measurable function $V$ such that $V^{\pm}:=\lim_{w\to \pm\infty}V(w)$ exist.
We find a field renormalization such that all the $n$-point connected Schwinger
functions for $n\neq 2$ exist non-perturbatively in the UV limit. They coincide
with the tree-level one-particle irreducible Schwinger functions of the
$\mathrm{erf}(\phi/\sqrt{2})$ interaction with a coupling constant $\frac{1}{2}
(V^+ - V^-)$. By a slight modification of our construction we can change this
coupling constant to $\frac{1}{2} (V_+ - V_-)$, where $V_{\pm}:= \lim_{w\to
0^{\pm}} V(w)$. Thereby non-Gaussianity of these latter theories is governed by
a discontinuity of $V$ at zero. The open problem of controlling also the
two-point function of these QFTs is discussed.",http://arxiv.org/abs/2502.07546v1
Early Stopping Against Label Noise Without Validation Data,2025-02-11T13:40:15Z,"Suqin Yuan, Lei Feng, Tongliang Liu","Early stopping methods in deep learning face the challenge of balancing the
volume of training and validation data, especially in the presence of label
noise. Concretely, sparing more data for validation from training data would
limit the performance of the learned model, yet insufficient validation data
could result in a sub-optimal selection of the desired model. In this paper, we
propose a novel early stopping method called Label Wave, which does not require
validation data for selecting the desired model in the presence of label noise.
It works by tracking the changes in the model's predictions on the training set
during the training process, aiming to halt training before the model unduly
fits mislabeled data. This method is empirically supported by our observation
that minimum fluctuations in predictions typically occur at the training epoch
before the model excessively fits mislabeled data. Through extensive
experiments, we show both the effectiveness of the Label Wave method across
various settings and its capability to enhance the performance of existing
methods for learning with noisy labels.",http://arxiv.org/abs/2502.07551v1
Navigating Semantic Drift in Task-Agnostic Class-Incremental Learning,2025-02-11T13:57:30Z,"Fangwen Wu, Lechao Cheng, Shengeng Tang, Xiaofeng Zhu, Chaowei Fang, Dingwen Zhang, Meng Wang","Class-incremental learning (CIL) seeks to enable a model to sequentially
learn new classes while retaining knowledge of previously learned ones.
Balancing flexibility and stability remains a significant challenge,
particularly when the task ID is unknown. To address this, our study reveals
that the gap in feature distribution between novel and existing tasks is
primarily driven by differences in mean and covariance moments. Building on
this insight, we propose a novel semantic drift calibration method that
incorporates mean shift compensation and covariance calibration. Specifically,
we calculate each class's mean by averaging its sample embeddings and estimate
task shifts using weighted embedding changes based on their proximity to the
previous mean, effectively capturing mean shifts for all learned classes with
each new task. We also apply Mahalanobis distance constraint for covariance
calibration, aligning class-specific embedding covariances between old and
current networks to mitigate the covariance shift. Additionally, we integrate a
feature-level self-distillation approach to enhance generalization.
Comprehensive experiments on commonly used datasets demonstrate the
effectiveness of our approach. The source code is available at
\href{https://github.com/fwu11/MACIL.git}{https://github.com/fwu11/MACIL.git}.",http://arxiv.org/abs/2502.07560v2
Distributed Coverage Control for Time-Varying Spatial Processes,2025-02-11T14:45:17Z,"Federico Pratissoli, Mattia Mantovani, Amanda Prorok, Lorenzo Sabattini","Multi-robot systems are essential for environmental monitoring, particularly
for tracking spatial phenomena like pollution, soil minerals, and water
salinity, and more. This study addresses the challenge of deploying a
multi-robot team for optimal coverage in environments where the density
distribution, describing areas of interest, is unknown and changes over time.
We propose a fully distributed control strategy that uses Gaussian Processes
(GPs) to model the spatial field and balance the trade-off between learning the
field and optimally covering it. Unlike existing approaches, we address a more
realistic scenario by handling time-varying spatial fields, where the
exploration-exploitation trade-off is dynamically adjusted over time. Each
robot operates locally, using only its own collected data and the information
shared by the neighboring robots. To address the computational limits of GPs,
the algorithm efficiently manages the volume of data by selecting only the most
relevant samples for the process estimation. The performance of the proposed
algorithm is evaluated through several simulations and experiments,
incorporating real-world data phenomena to validate its effectiveness.",http://arxiv.org/abs/2502.07595v1
"Causal-Informed Contrastive Learning: Towards Bias-Resilient
  Pre-training under Concept Drift",2025-02-11T15:09:05Z,"Xiaoyu Yang, Jie Lu, En Yu","The evolution of large-scale contrastive pre-training propelled by top-tier
datasets has reached a transition point in the scaling law. Consequently,
sustaining and enhancing a model's pre-training capabilities in drift
environments have surfaced as a notable challenge. In this paper, we initially
uncover that contrastive pre-training methods are significantly impacted by
concept drift wherein distributions change unpredictably, resulting in notable
biases in the feature space of the pre-trained model. Empowered by causal
inference, we construct a structural causal graph to analyze the impact of
concept drift to contrastive pre-training systemically, and propose the causal
interventional contrastive objective. Upon achieving this, we devise a
resilient contrastive pre-training approach to accommodate the data stream of
concept drift, with simple and scalable implementation. Extensive experiments
on various downstream tasks demonstrate our resilient contrastive pre-training
effectively mitigates the bias stemming from the concept drift data stream.
Codes are available at https://anonymous.4open.science/r/ResilientCL/.",http://arxiv.org/abs/2502.07620v1
"Divide and Merge: Motion and Semantic Learning in End-to-End Autonomous
  Driving",2025-02-11T15:21:31Z,"Yinzhe Shen, Ömer Şahin Taş, Kaiwen Wang, Royden Wagner, Christoph Stiller","Perceiving the environment and its changes over time corresponds to two
fundamental yet heterogeneous types of information: semantics and motion.
Previous end-to-end autonomous driving works represent both types of
information in a single feature vector. However, including motion tasks, such
as prediction and planning, always impairs detection and tracking performance,
a phenomenon known as negative transfer in multi-task learning. To address this
issue, we propose Neural-Bayes motion decoding, a novel parallel detection,
tracking, and prediction method separating semantic and motion learning,
similar to the Bayes filter. Specifically, we employ a set of learned motion
queries that operate in parallel with the detection and tracking queries,
sharing a unified set of recursively updated reference points. Moreover, we
employ interactive semantic decoding to enhance information exchange in
semantic tasks, promoting positive transfer. Experiments on the nuScenes
dataset show improvements of 5% in detection and 11% in tracking. Our method
achieves state-of-the-art collision rates in open-loop planning evaluation
without any modifications to the planning module.",http://arxiv.org/abs/2502.07631v1
The Impacts of Magnetogram Projection Effects on Solar Flare Forecasting,2025-02-11T15:39:57Z,"Griffin T. Goodwin, Viacheslav M. Sadykov, Petrus C. Martens","This work explores the impacts of magnetogram projection effects on machine
learning-based solar flare forecasting models. Utilizing a methodology proposed
by Falconer et al. (2016), we correct for projection effects present in Georgia
State University's Space Weather Analytics for Solar Flares (SWAN-SF) benchmark
data set. We then train and run a support vector machine classifier on the
corrected and uncorrected data, comparing differences in performance.
Additionally, we provide insight into several other methodologies that mitigate
projection effects, such as stacking ensemble classifiers and active region
location-informed models. Our analysis shows that data corrections slightly
increase both the true positive (correctly predicted flaring samples) and false
positive (non-flaring samples predicted as flaring) prediction rates, averaging
a few percent. Similarly, changes in performance metrics are minimal for the
stacking ensemble and location-based model. This suggests that a more
complicated correction methodology may be needed to see improvements. It may
also indicate inherent limitations when using magnetogram data for flare
forecasting.",http://arxiv.org/abs/2502.07651v1
A Nonparametric and Functional Wombling Methodology,2025-02-11T18:01:13Z,"Luke A. Barratt, John A. D. Aston","Wombling methods, first introduced in 1951, have been widely applied to
detect boundaries and variations across spatial domains, particularly in
biological, public health and meteorological studies. Traditional applications
focus on finite-dimensional observations, where significant changes in
measurable traits indicate structural boundaries. In this work, wombling
methodologies are extended to functional data, enabling the identification of
spatial variation in infinite-dimensional settings. Proposed is a nonparametric
approach that accommodates functional observations without imposing strict
distributional assumptions. This methodology successfully captures complex
spatial structures and discontinuities, demonstrating superior sensitivity and
robustness compared to existing finite-dimensional techniques. This methodology
is then applied to analyse regional epidemiological disparities between London
and the rest of the UK, identifying key spatial boundaries in the shape of the
first trajectory of Covid-19 incidence in 2020. Through extensive simulations
and empirical validation, demonstrated is the method's effectiveness in
uncovering meaningful spatial variations, with potential applications in a wide
variety of fields.",http://arxiv.org/abs/2502.07740v1
"TranSplat: Surface Embedding-guided 3D Gaussian Splatting for
  Transparent Object Manipulation",2025-02-11T03:43:56Z,"Jeongyun Kim, Jeongho Noh, Dong-Guw Lee, Ayoung Kim","Transparent object manipulation remains a significant challenge in robotics
due to the difficulty of acquiring accurate and dense depth measurements.
Conventional depth sensors often fail with transparent objects, resulting in
incomplete or erroneous depth data. Existing depth completion methods struggle
with interframe consistency and incorrectly model transparent objects as
Lambertian surfaces, leading to poor depth reconstruction. To address these
challenges, we propose TranSplat, a surface embedding-guided 3D Gaussian
Splatting method tailored for transparent objects. TranSplat uses a latent
diffusion model to generate surface embeddings that provide consistent and
continuous representations, making it robust to changes in viewpoint and
lighting. By integrating these surface embeddings with input RGB images,
TranSplat effectively captures the complexities of transparent surfaces,
enhancing the splatting of 3D Gaussians and improving depth completion.
Evaluations on synthetic and real-world transparent object benchmarks, as well
as robot grasping tasks, show that TranSplat achieves accurate and dense depth
completion, demonstrating its effectiveness in practical applications. We
open-source synthetic dataset and model: https://github.
com/jeongyun0609/TranSplat",http://arxiv.org/abs/2502.07840v1
"ADMN: A Layer-Wise Adaptive Multimodal Network for Dynamic Input Noise
  and Compute Resources",2025-02-11T17:19:44Z,"Jason Wu, Kang Yang, Lance Kaplan, Mani Srivastava","Multimodal deep learning systems are deployed in dynamic scenarios due to the
robustness afforded by multiple sensing modalities. Nevertheless, they struggle
with varying compute resource availability (due to multi-tenancy, device
heterogeneity, etc.) and fluctuating quality of inputs (from sensor feed
corruption, environmental noise, etc.). Current multimodal systems employ
static resource provisioning and cannot easily adapt when compute resources
change over time. Additionally, their reliance on processing sensor data with
fixed feature extractors is ill-equipped to handle variations in modality
quality. Consequently, uninformative modalities, such as those with high noise,
needlessly consume resources better allocated towards other modalities. We
propose ADMN, a layer-wise Adaptive Depth Multimodal Network capable of
tackling both challenges - it adjusts the total number of active layers across
all modalities to meet compute resource constraints, and continually
reallocates layers across input modalities according to their modality quality.
Our evaluations showcase ADMN can match the accuracy of state-of-the-art
networks while reducing up to 75% of their floating-point operations.",http://arxiv.org/abs/2502.07862v1
Long-Term X-ray Variability on the Benchmark YSO HL Tau,2025-02-11T19:15:29Z,"Steven M. Silverberg, Scott J. Wolk, David A. Principe, P. Christian Schneider, Hans Moritz Guenther, Jinyoung Serena Kim, Joel H. Kastner","HL Tau is one of the most well-studied Class I young stellar objects,
including frequent observations at near- and mid-infrared, (sub-) millimeter,
and X-ray wavelengths. We present the results of an X-ray variability
monitoring campaign with XMM-Newton in 2020 and X-ray gratings spectroscopy
from Chandra/HETGS in 2018. We find that the X-ray spectrum of HL Tau is
consistently hot (with characteristic plasma temperatures $T \gtrsim 30$ MK)
over 31 epochs spanning 20 years, which is consistent in temperature with most
Class I YSOs. The high-resolution HETG spectrum indicates the presence of some
cooler plasma. We characterize the variability of the star across the 31
observations and find a subset of observations with significant variability on
a $\sim$21-day timescale in the observed count rate and flux. We discuss the
possible origins of this variability, and identify further observations that
would better constrain the nature of the changes.",http://arxiv.org/abs/2502.07900v1
"SHACL-SKOS Based Knowledge Representation of Material Safety Data Sheet
  (SDS) for the Pharmaceutical Industry",2025-02-11T20:44:45Z,"Brian Lu, Dennis Pham, Ti-Chiun Chang, Michael Lovette, Terri Bui, Stephen Ma","We report the development of a knowledge representation and reasoning (KRR)
system built on hybrid SHACL-SKOS ontologies for globally harmonized system
(GHS) material Safety Data Sheets (SDS) to enhance chemical safety
communication and regulatory compliance. SDS are comprehensive documents
containing safety and handling information for chemical substances. Thus, they
are an essential part of workplace safety and risk management. However, the
vast number of Safety Data Sheets from multiple organizations, manufacturers,
and suppliers that produce and distribute chemicals makes it challenging to
centralize and access SDS documents through a single repository. To accomplish
the underlying issues of data exchange related to chemical shipping and
handling, we construct SDS related controlled vocabulary and conditions
validated by SHACL, and knowledge systems of similar domains linked via SKOS.
The resulting hybrid ontologies aim to provide standardized yet adaptable
representations of SDS information, facilitating better data sharing,
retrieval, and integration across various platforms. This paper outlines our
SHACL-SKOS system architectural design and showcases our implementation for an
industrial application streamlining the generation of a composite shipping
cover sheet.",http://arxiv.org/abs/2502.07944v1
"Optimal Pricing of Cloud Services: Committed Spend under Demand
  Uncertainty",2025-02-11T23:41:09Z,"Dirk Bergemann, Michael C. Wang","We consider a seller who offers services to a buyer with multi-unit demand.
Prior to the realization of demand, the buyer receives a noisy signal of their
future demand, and the seller can design contracts based on the reported value
of this signal. Thus, the buyer can contract with the service provider for an
unknown level of future consumption, such as in the market for cloud computing
resources or software services. We characterize the optimal dynamic contract,
extending the classic sequential screening framework to a nonlinear and
multi-unit setting. The optimal mechanism gives discounts to buyers who report
higher signals, but in exchange they must provide larger fixed payments. We
then describe how the optimal mechanism can be implemented by two common forms
of contracts observed in practice, the two-part tariff and the committed spend
contract. Finally, we use extensions of our base model to shed light on
policy-focused questions, such as analyzing how the optimal contract changes
when the buyer faces commitment costs, or when there are liquid spot markets.",http://arxiv.org/abs/2502.08022v1
"Initialization Matters: Unraveling the Impact of Pre-Training on
  Federated Learning",2025-02-11T23:53:16Z,"Divyansh Jhunjhunwala, Pranay Sharma, Zheng Xu, Gauri Joshi","Initializing with pre-trained models when learning on downstream tasks is
becoming standard practice in machine learning. Several recent works explore
the benefits of pre-trained initialization in a federated learning (FL)
setting, where the downstream training is performed at the edge clients with
heterogeneous data distribution. These works show that starting from a
pre-trained model can substantially reduce the adverse impact of data
heterogeneity on the test performance of a model trained in a federated
setting, with no changes to the standard FedAvg training algorithm. In this
work, we provide a deeper theoretical understanding of this phenomenon. To do
so, we study the class of two-layer convolutional neural networks (CNNs) and
provide bounds on the training error convergence and test error of such a
network trained with FedAvg. We introduce the notion of aligned and misaligned
filters at initialization and show that the data heterogeneity only affects
learning on misaligned filters. Starting with a pre-trained model typically
results in fewer misaligned filters at initialization, thus producing a lower
test error even when the model is trained in a federated setting with data
heterogeneity. Experiments in synthetic settings and practical FL training on
CNNs verify our theoretical findings.",http://arxiv.org/abs/2502.08024v1
"Break the Checkbox: Challenging Closed-Style Evaluations of Cultural
  Alignment in LLMs",2025-02-12T01:04:13Z,"Mohsinul Kabir, Ajwad Abrar, Sophia Ananiadou","A large number of studies rely on closed-style multiple-choice surveys to
evaluate cultural alignment in Large Language Models (LLMs). In this work, we
challenge this constrained evaluation paradigm and explore more realistic,
unconstrained approaches. Using the World Values Survey (WVS) and Hofstede
Cultural Dimensions as case studies, we demonstrate that LLMs exhibit stronger
cultural alignment in less constrained settings, where responses are not
forced. Additionally, we show that even minor changes, such as reordering
survey choices, lead to inconsistent outputs, exposing the limitations of
closed-style evaluations. Our findings advocate for more robust and flexible
evaluation frameworks that focus on specific cultural proxies, encouraging more
nuanced and accurate assessments of cultural alignment in LLMs.",http://arxiv.org/abs/2502.08045v2
Cognify: Supercharging Gen-AI Workflows With Hierarchical Autotuning,2025-02-12T01:36:27Z,"Zijian He, Reyna Abhyankar, Vikranth Srivatsa, Yiying Zhang","Today's gen-AI workflows that involve multiple ML model calls, tool/API
calls, data retrieval, or generic code execution are often tuned manually in an
ad-hoc way that is both time-consuming and error-prone. In this paper, we
propose a systematic approach for automatically tuning gen-AI workflows. Our
key insight is that gen-AI workflows can benefit from structure, operator, and
prompt changes, but unique properties of gen-AI workflows require new
optimization techniques. We propose AdaSeek, an adaptive hierarchical search
algorithm for autotuning gen-AI workflows. AdaSeek organizes workflow tuning
methods into different layers based on the user-specified total search budget
and distributes the budget across different layers based on the complexity of
each layer. During its hierarchical search, AdaSeek redistributes the search
budget from less useful to more promising tuning configurations based on
workflow-level evaluation results. We implement AdaSeek in a workflow
autotuning framework called Cognify and evaluate Cognify using six types of
workflows such as RAG-based QA and text-to-SQL transformation. Overall, Cognify
improves these workflows' generation quality by up to 2.8x, reduces execution
monetary cost by up to 10x, and reduces end-to-end latency by 2.7x.",http://arxiv.org/abs/2502.08056v1
RouteFlow: Trajectory-Aware Animated Transitions,2025-02-12T02:39:17Z,"Duan Li, Xinyuan Guo, Xinhuan Shu, Lanxi Xiao, Lingyun Yu, Shixia Liu","Animating objects' movements is widely used to facilitate tracking changes
and observing both the global trend and local hotspots where objects converge
or diverge. Existing methods, however, often obscure critical local hotspots by
only considering the start and end positions of objects' trajectories. To
address this gap, we propose RouteFlow, a trajectory-aware animated transition
method that effectively balances the global trend and local hotspots while
minimizing occlusion. RouteFlow is inspired by a real-world bus route analogy:
objects are regarded as passengers traveling together, with local hotspots
representing bus stops where these passengers get on and off. Based on this
analogy, animation paths are generated like bus routes, with the object layout
generated similarly to seat allocation according to their destinations.
Compared with state-of-the-art methods, RouteFlow better facilitates
identifying the global trend and locating local hotspots while performing
comparably in tracking objects' movements.",http://arxiv.org/abs/2502.08076v1
"Bring the noise: exact inference from noisy simulations in collider
  physics",2025-02-12T06:49:02Z,"Christopher Chang, Benjamin Farmer, Andrew Fowlie, Anders Kvellestad","We rely on Monte Carlo (MC) simulations to interpret searches for new physics
at the Large Hadron Collider (LHC) and elsewhere. These simulations result in
noisy and approximate estimators of selection efficiencies and likelihoods. In
this context we pioneer an exact-approximate computational method -
exact-approximate Markov Chain Monte Carlo - that returns exact inferences
despite noisy simulations. To do so, we introduce an unbiased estimator for a
Poisson likelihood. We demonstrate the new estimator and new techniques in
examples based on a search for neutralinos and charginos at the LHC using a
simplified model. We find attractive performance characteristics - exact
inferences are obtained for a similar computational cost to approximate ones
from existing methods and inferences are robust with respect to the number of
events generated per point.",http://arxiv.org/abs/2502.08157v1
Enhancing LLM Character-Level Manipulation via Divide and Conquer,2025-02-12T07:37:39Z,"Zhen Xiong, Yujun Cai, Bryan Hooi, Nanyun Peng, Kai-Wei Chang, Zhecheng Li, Yiwei Wang","Large Language Models (LLMs) have demonstrated strong generalization
capabilities across a wide range of natural language processing (NLP) tasks.
However, they exhibit notable weaknesses in character-level string
manipulation, struggling with fundamental operations such as character
deletion, insertion, and substitution. These challenges stem primarily from
tokenization constraints, despite the critical role of such operations in data
preprocessing and code generation. Through systematic analysis, we derive two
key insights: (1) LLMs face significant difficulties in leveraging intrinsic
token knowledge for character-level reasoning, and (2) atomized word structures
can substantially enhance LLMs' ability to process token-level structural
information. Building on these insights, we propose Character-Level
Manipulation via Divide and Conquer, a novel approach designed to bridge the
gap between token-level processing and character-level manipulation. Our method
decomposes complex operations into explicit character-level subtasks coupled
with controlled token reconstruction phases, leading to significant
improvements in accuracy. Without additional training, our method significantly
improves accuracies on the $\texttt{Deletion}$, $\texttt{Insertion}$, and
$\texttt{Substitution}$ tasks. To support further research, we open-source our
implementation and benchmarks.",http://arxiv.org/abs/2502.08180v1
"DualStream Contextual Fusion Network: Efficient Target Speaker
  Extraction by Leveraging Mixture and Enrollment Interactions",2025-02-12T08:03:27Z,"Ke Xue, Rongfei Fan, Shanping Yu, Chang Sun, Jianping An","Target speaker extraction focuses on extracting a target speech signal from
an environment with multiple speakers by leveraging an enrollment. Existing
methods predominantly rely on speaker embeddings obtained from the enrollment,
potentially disregarding the contextual information and the internal
interactions between the mixture and enrollment. In this paper, we propose a
novel DualStream Contextual Fusion Network (DCF-Net) in the time-frequency
(T-F) domain. Specifically, DualStream Fusion Block (DSFB) is introduced to
obtain contextual information and capture the interactions between
contextualized enrollment and mixture representation across both spatial and
channel dimensions, and then rich and consistent representations are utilized
to guide the extraction network for better extraction. Experimental results
demonstrate that DCF-Net outperforms state-of-the-art (SOTA) methods, achieving
a scale-invariant signal-to-distortion ratio improvement (SI-SDRi) of 21.6 dB
on the benchmark dataset, and exhibits its robustness and effectiveness in both
noise and reverberation scenarios. In addition, the wrong extraction results of
our model, called target confusion problem, reduce to 0.4%, which highlights
the potential of DCF-Net for practical applications.",http://arxiv.org/abs/2502.08191v1
"Superconductivity near an Ising nematic quantum critical point in two
  dimensions",2025-02-12T10:24:03Z,"Jie Huang, Zhao-Kun Yang, Jing-Rong Wang, Guo-Zhu Liu","Near a two-dimensional Ising-type nematic quantum critical point, the quantum
fluctuations of the nematic order parameter are coupled to the electrons,
leading to non-Fermi liquid behavior and unconventional superconductivity. The
interplay between these two effects has been extensively studied through the
Eliashberg equations for the superconducting gap. However, previous studies
often rely on various approximations that may introduce uncertainties in the
results. Here, we revisit this problem without these approximations and examine
how their removal changes the outcomes. We numerically solve four
self-consistent Eliashberg integral equations of the mass renormalization
$A_{1}(p)$, the chemical potential renormalization $A_{2}(p)$, the pairing
function $\Phi(p)$, and the nematic self-energy (polarization) function
$\Pi(q)$ using the iteration method. Our calculations retain the explicit
non-linearity and the full momentum dependence of these equations. We find that
discarding some commonly used approximations allows for a more accurate
determination of the superconducting gap $\Delta = \Phi/A_{1}$ and the critical
temperature $T_{c}$. The Eliashberg equations have two different convergent gap
solutions: an extended $s$-wave gap and a $d_{x^{2}-y^{2}}$-wave gap. The
latter is fragile, whereas the former is robust against small perturbations.",http://arxiv.org/abs/2502.08270v1
"Modification and Generated-Text Detection: Achieving Dual Detection
  Capabilities for the Outputs of LLM by Watermark",2025-02-12T11:56:40Z,"Yuhang Cai, Yaofei Wang, Donghui Hu, Gu Chen","The development of large language models (LLMs) has raised concerns about
potential misuse. One practical solution is to embed a watermark in the text,
allowing ownership verification through watermark extraction. Existing methods
primarily focus on defending against modification attacks, often neglecting
other spoofing attacks. For example, attackers can alter the watermarked text
to produce harmful content without compromising the presence of the watermark,
which could lead to false attribution of this malicious content to the LLM.
This situation poses a serious threat to the LLMs service providers and
highlights the significance of achieving modification detection and
generated-text detection simultaneously. Therefore, we propose a technique to
detect modifications in text for unbiased watermark which is sensitive to
modification. We introduce a new metric called ``discarded tokens"", which
measures the number of tokens not included in watermark detection. When a
modification occurs, this metric changes and can serve as evidence of the
modification. Additionally, we improve the watermark detection process and
introduce a novel method for unbiased watermark. Our experiments demonstrate
that we can achieve effective dual detection capabilities: modification
detection and generated-text detection by watermark.",http://arxiv.org/abs/2502.08332v1
"Local damage detection in rolling element bearings based on a Single
  Ensemble Empirical Mode Decomposition",2025-02-12T12:56:33Z,"Yaakoub Berrouche, Govind Vashishtha, Sumika Chauhan, Radoslaw Zimroz","A Single Ensemble Empirical Mode Decomposition (SEEMD) is proposed for
locating the damage in rolling element bearings. The SEEMD does not require a
number of ensembles from the addition or subtraction of noise every time while
processing the signals. The SEEMD requires just a single sifting process of a
modified raw signal to reduce the computation time significantly. The other
advantage of the SEEMD method is its success in dealing with non-Gaussian or
non-stationary perturbing signals. In SEEMD, initially, a fractional Gaussian
noise (FGN) is added to the raw signal to emphasize on high frequencies of the
signal. Then, a convoluted white Gaussian noise is multiplied to the resulting
signal which changes the spectral content of the signal which helps in
extraction of the weak periodic signal. Finally, the obtained signal is
decomposed by using a single sifting process. The proposed methodology is
applied to the raw signals obtained from the mining industry. These signals are
difficult to analyze since cyclic impulsive components are obscured by noise
and other interference. Based on the results, the proposed method can
effectively detect the fault where the signal of interest (SOI) has been
extracted with good quality.",http://arxiv.org/abs/2502.08368v1
"Full-cycle device-scale simulations of memory materials with a tailored
  atomic-cluster-expansion potential",2025-02-12T13:33:58Z,"Yuxing Zhou, Daniel F. Thomas du Toit, Stephen R. Elliott, Wei Zhang, Volker L. Deringer","Computer simulations have long been key to understanding and designing
phase-change materials (PCMs) for memory technologies. Machine learning is now
increasingly being used to accelerate the modelling of PCMs, and yet it remains
challenging to simultaneously reach the length and time scales required to
simulate the operation of real-world PCM devices. Here, we show how ultra-fast
machine-learned interatomic potentials, based on the atomic cluster expansion
(ACE) framework, enable simulations of PCMs reflecting applications in devices
with excellent scalability on high-performance computing platforms. We report
full-cycle simulations -- including the time-consuming crystallisation process
(from digital ""zeroes"" to ""ones"") -- thus representing the entire programming
cycle for cross-point memory devices. We also showcase a simulation of
full-cycle operations, relevant to neuromorphic computing, in a mushroom-type
device geometry. Our work provides a springboard for the atomistic modelling of
PCM-based memory and neuromorphic computing devices -- and, more widely, it
illustrates the power of highly efficient ACE ML models for materials science
and engineering.",http://arxiv.org/abs/2502.08393v1
"Robot-Initiated Social Control of Sedentary Behavior: Comparing the
  Impact of Relationship- and Target-Focused Strategies",2025-02-12T14:13:38Z,"Jiaxin Xu, Sterre Anna Mariam van der Horst, Chao Zhang, Raymond H. Cuijpers, Wijnand A. IJsselsteijn","To design social robots to effectively promote health behavior change, it is
essential to understand how people respond to various health communication
strategies employed by these robots. This study examines the effectiveness of
two types of social control strategies from a social robot,
relationship-focused strategies (emphasizing relational consequences) and
target-focused strategies (emphasizing health consequences), in encouraging
people to reduce sedentary behavior. A two-session lab experiment was conducted
(n = 135), where participants first played a game with a robot, followed by the
robot persuading them to stand up and move using one of the strategies. Half of
the participants joined a second session to have a repeated interaction with
the robot. Results showed that relationship-focused strategies motivated
participants to stay active longer. Repeated sessions did not strengthen
participants' relationship with the robot, but those who felt more attached to
the robot responded more actively to the target-focused strategies. These
findings offer valuable insights for designing persuasive strategies for social
robots in health communication contexts.",http://arxiv.org/abs/2502.08428v1
"Uniform confidence bands for joint angles across different fatigue
  phases",2025-02-12T14:15:56Z,"Patrick Bastian, Rupsa Basu, Holger Dette","We develop uniform confidence bands for the mean function of stationary time
series as a post-hoc analysis of multiple change point detection in functional
time series. In particular, the methodology in this work provides bands for
those segments where the jump size exceeds a certain threshold $\Delta$. In
\cite{bastian2024multiplechangepointdetection} such exceedences of $\Delta$
were related to fatigue states of a running athlete. The extension to
confidence bands stems from an interest in understanding the range of motion
(ROM) of lower-extremity joints of running athletes under fatiguing conditions.
From a biomechanical perspective, ROM serves as a proxy for joint flexibility
under varying fatigue states, offering individualized insights into potentially
problematic movement patterns. The new methodology provides a valuable tool for
understanding the dynamic behavior of joint motion and its relationship to
fatigue.",http://arxiv.org/abs/2502.08430v1
"How does the restriction of representations change under translations? A
  story for the general linear groups and the unitary groups",2025-02-12T15:14:17Z,"Toshiyuki Kobayashi, Birgit Speh","We present a new approach to symmetry breaking for pairs of real forms of
$(GL(n, \mathbb{C}), GL(n-1, \mathbb{C}))$. While translation functors are a
useful tool for studying a family of representations of a single reductive
group $G$, when applied to a pair of groups $G \supset G'$,translation functors
can significantly alter the nature of symmetry breaking between the
representations of $G$ and $G'$, even within the same Weyl chamber of the
direct product group $G \times G'$. We introduce the concept of \lq\lq{fences
for the interlacing pattern}\rq\rq,which provides a refinement of the usual
notion of \lq\lq{walls for Weyl chambers}\rq\rq. We then present a theorem that
states that multiplicity is constant unless these \lq\lq{fences}\rq\rq\ are
crossed. This general theorem is illustrated with examples of both tempered and
non-tempered representations. Additionally,we provide a new non-vanishing
theorem of period integrals for pairs of reductive symmetric spaces,which is
further strengthened through this approach.",http://arxiv.org/abs/2502.08479v1
"Impact of Electric Spatially Discordant Alternans on Cardiac Magnetic
  Field",2025-02-12T15:14:25Z,"Martina Nicoletti, Anna Crispino, Alessandro Loppini, Alessio Gizzi, Letizia Chiodo, Christian Cherubini, Simonetta Filippi","Spatially discordant alternans (SDA) play a crucial role in cardiac
arrhythmogenesis by creating steep repolarization gradients facilitating
conduction block and reentry. While traditionally studied using electrical
indicators, this work provides a novel perspective by characterizing SDA
through their magnetic field signatures. Using a one-dimensional cardiac fiber
model, we demonstrate that magnetic field measurements effectively detect SDA
and temperature dependent changes in cardiac action potentials, offering a
non-invasive alternative to conventional electrophysiological metrics. Our
results reveal that the spatial organization of SDA is mirrored in the magnetic
field distribution, with SDA nodes clearly identifiable via spatial mapping.
Notably, magnetic restitution curves exhibit a distinct pattern from APD-based
indicators, closely following the dynamics of the action potential upstroke.
These findings establish the cardiac magnetic field as a powerful diagnostic
tool for detecting SDA, opening new avenues for biomagnetic monitoring of
arrhythmic risk.",http://arxiv.org/abs/2502.08480v1
The Born rule -- 100 years ago and today,2025-02-12T16:28:49Z,Arnold Neumaier,"Details of the contents, and formulations of the Born rule changed
considerably from its inception by Born in 1926 to the present day. Based to a
large extent on little known results from the recent books 'Coherent Quantum
Physics' by Neumaier and 'Algebraic Quantum Physics', Vol. 1 by Neumaier and
Westra, this paper traces the early history 100 years ago, its generalization
(essential for today's quantum optics and quantum information theory) to POVMs
50 year ago, and a modern derivation from an intuitive definition of the notion
of a quantum detector. Also discussed is the extent to which the various forms
of the Born rule have, like any other statement in physics, a restricted domain
of validity, which leads to problems when applied outside this domain.",http://arxiv.org/abs/2502.08545v1
Poly-Autoregressive Prediction for Modeling Interactions,2025-02-12T18:59:43Z,"Neerja Thakkar, Tara Sadjadpour, Jathushan Rajasegaran, Shiry Ginosar, Jitendra Malik","We introduce a simple framework for predicting the behavior of an agent in
multi-agent settings. In contrast to autoregressive (AR) tasks, such as
language processing, our focus is on scenarios with multiple agents whose
interactions are shaped by physical constraints and internal motivations. To
this end, we propose Poly-Autoregressive (PAR) modeling, which forecasts an ego
agent's future behavior by reasoning about the ego agent's state history and
the past and current states of other interacting agents. At its core, PAR
represents the behavior of all agents as a sequence of tokens, each
representing an agent's state at a specific timestep. With minimal data
pre-processing changes, we show that PAR can be applied to three different
problems: human action forecasting in social situations, trajectory prediction
for autonomous vehicles, and object pose forecasting during hand-object
interaction. Using a small proof-of-concept transformer backbone, PAR
outperforms AR across these three scenarios. The project website can be found
at https://neerja.me/PAR/.",http://arxiv.org/abs/2502.08646v1
Scientific Map of Artificial Intelligence in Communication (2004-2024),2025-01-14T10:18:40Z,Carmen Gálvez,"Introduction: Artificial Intelligence (AI) is having a significant impact in
the field of communication, causing transcendental changes in the processing
and consumption of information. The objective of this work was to analyze the
most influential AI topic areas in the field of communication based on
scientific literature. Methodology: 996 references indexed in Web of Science
between 2004-2024 were selected, a bibliometric analysis of co-words was
carried out and visualization techniques were applied to build scientific maps.
Results: The most relevant thematic areas were datafication, the linking of AI
with social media and digital journalism. The emerging area of generative AI
was identified, linked to new AI models, such as ChatGPT, designed to generate
content in the form of written text, audio, images or videos. Another emerging
topic area was China's impact on the use of AI in communication. Discussions:
Despite the impact of AI in communication, the field is still in the process of
structuring, with few consolidated topics. Conclusions: This study made it
possible to identify the thematic areas of the field studied, as well as the
detection of emerging trends.",http://arxiv.org/abs/2502.08648v1
"Deep Learning-Driven Malware Classification with API Call Sequence
  Analysis and Concept Drift Handling",2025-02-12T08:56:35Z,"Bishwajit Prasad Gond, Durga Prasad Mohapatra","Malware classification in dynamic environments presents a significant
challenge due to concept drift, where the statistical properties of malware
data evolve over time, complicating detection efforts. To address this issue,
we propose a deep learning framework enhanced with a genetic algorithm to
improve malware classification accuracy and adaptability. Our approach
incorporates mutation operations and fitness score evaluations within genetic
algorithms to continuously refine the deep learning model, ensuring robustness
against evolving malware threats. Experimental results demonstrate that this
hybrid method significantly enhances classification performance and
adaptability, outperforming traditional static models. Our proposed approach
offers a promising solution for real-time malware classification in
ever-changing cybersecurity landscapes.",http://arxiv.org/abs/2502.08679v1
"A Comparative Study of Machine Learning Algorithms for Stock Price
  Prediction Using Insider Trading Data",2025-02-12T19:03:09Z,"Amitabh Chakravorty, Nelly Elsayed","The research paper empirically investigates several machine learning
algorithms to forecast stock prices depending on insider trading information.
Insider trading offers special insights into market sentiment, pointing to
upcoming changes in stock prices. This study examines the effectiveness of
algorithms like decision trees, random forests, support vector machines (SVM)
with different kernels, and K-Means Clustering using a dataset of Tesla stock
transactions. Examining past data from April 2020 to March 2023, this study
focuses on how well these algorithms identify trends and forecast stock price
fluctuations. The paper uses Recursive Feature Elimination (RFE) and feature
importance analysis to optimize the feature set and, hence, increase prediction
accuracy. While it requires substantially greater processing time than other
models, SVM with the Radial Basis Function (RBF) kernel displays the best
accuracy. This paper highlights the trade-offs between accuracy and efficiency
in machine learning models and proposes the possibility of pooling multiple
data sources to raise prediction performance. The results of this paper aim to
help financial analysts and investors in choosing strong algorithms to optimize
investment strategies.",http://arxiv.org/abs/2502.08728v1
"Vacuum Polarization, Geodesic Equation and Sachs-Wolfe Effect",2025-02-12T19:38:21Z,Ali Kaya,"We show that the null geodesic equation for photons is modified in the
presence of a charged scalar field, with quantum fluctuations acting as an
effective mass term that changes the null paths to timelike curves. This effect
can be interpreted as a vacuum polarization phenomenon in curved spacetime. The
resulting contribution to the Sachs-Wolfe effect varies with photon frequency,
leading to frequency-dependent corrections to the cosmic microwave background
(CMB) blackbody spectrum in the form of a $\mu$-distortion, as well as
modifications to the CMB power spectrum. We estimate these within a standard
inflationary scenario and find that while the correction to the CMB power
spectrum is significant when the scalar field is light, the magnitude of the
$\mu$-distortion depends strongly on the regularization prescription.",http://arxiv.org/abs/2502.08748v1
Temporal Interface in Dispersive Hyperbolic Media,2025-02-12T20:34:57Z,"Grigorii Ptitcyn, Diego Martinez Solís, Mohammad Sajjad Mirmoosa, Nader Engheta","Spatial inhomogeneity, temporal modulation, and engineered anisotropy of
parameters of electromagnetic media offer numerous opportunities for
manipulating light-matter interaction over the past decades. Here, we
investigate a scenario in which we deal with the temporal interface, hyperbolic
anisotropy in the form of layered structures, and frequency dispersion. We
theoretically investigate how a monochromatic uniform plane wave - propagating
in an unbounded, homogeneous, isotropic dielectric medium - undergoes changes
due to the rapid temporal variation of such medium into a hyperbolic dispersive
medium formed by the stack of thin metal-dielectric bilayers, in which the
metal follows the lossless Drude dispersion and the dielectric is assumed to be
dispersionless. We corroborate our analytical results by numerical simulations.
We observe several interesting phenomena, such as the conversion of the
original frequency into three pairs of frequencies, resulting in three sets of
forward (FW) and backward (BW) waves. We present the amplitudes and the
time-average Poynting vectors for such FW and BW waves and discuss some of the
salient features of such temporal interface.",http://arxiv.org/abs/2502.08775v1
Spectral Journey: How Transformers Predict the Shortest Path,2025-02-12T21:17:30Z,"Andrew Cohen, Andrey Gromov, Kaiyu Yang, Yuandong Tian","Decoder-only transformers lead to a step-change in capability of large
language models. However, opinions are mixed as to whether they are really
planning or reasoning. A path to making progress in this direction is to study
the model's behavior in a setting with carefully controlled data. Then
interpret the learned representations and reverse-engineer the computation
performed internally. We study decoder-only transformer language models trained
from scratch to predict shortest paths on simple, connected and undirected
graphs. In this setting, the representations and the dynamics learned by the
model are interpretable. We present three major results: (1) Two-layer
decoder-only language models can learn to predict shortest paths on simple,
connected graphs containing up to 10 nodes. (2) Models learn a graph embedding
that is correlated with the spectral decomposition of the line graph. (3)
Following the insights, we discover a novel approximate path-finding algorithm
Spectral Line Navigator (SLN) that finds shortest path by greedily selecting
nodes in the space of spectral embedding of the line graph.",http://arxiv.org/abs/2502.08794v1
"Examining and Adapting Time for Multilingual Classification via Mixture
  of Temporal Experts",2025-02-12T22:30:18Z,"Weisi Liu, Guangzeng Han, Xiaolei Huang","Time is implicitly embedded in classification process: classifiers are
usually built on existing data while to be applied on future data whose
distributions (e.g., label and token) may change. However, existing
state-of-the-art classification models merely consider the temporal variations
and primarily focus on English corpora, which leaves temporal studies less
explored, let alone under multilingual settings. In this study, we fill the gap
by treating time as domains (e.g., 2024 vs. 2025), examining temporal effects,
and developing a domain adaptation framework to generalize classifiers over
time on multiple languages. Our framework proposes Mixture of Temporal Experts
(MoTE) to leverage both semantic and data distributional shifts to learn and
adapt temporal trends into classification models. Our analysis shows
classification performance varies over time across different languages, and we
experimentally demonstrate that MoTE can enhance classifier generalizability
over temporal data shifts. Our study provides analytic insights and addresses
the need for time-aware models that perform robustly in multilingual scenarios.",http://arxiv.org/abs/2502.08825v1
"Generative AI & Changing Work: Systematic Review of Practitioner-led
  Work Transformations through the Lens of Job Crafting",2025-02-13T00:13:49Z,"Matthew Law, Rama Adithya Varanasi","Widespread integration of Generative AI tools is transforming white-collar
work, reshaping how workers define their roles, manage their tasks, and
collaborate with peers. This has created a need to develop an overarching
understanding of common worker-driven patterns around these transformations. To
fill this gap, we conducted a systematic literature review of 23 studies from
the ACM Digital Library that focused on workers' lived-experiences and
practitioners with GenAI. Our findings reveal that while many professionals
have delegated routine tasks to GenAI to focus on core responsibilities, they
have also taken on new forms of AI managerial labor to monitor and refine GenAI
outputs. Additionally, practitioners have restructured collaborations,
sometimes bypassing traditional peer and subordinate interactions in favor of
GenAI assistance. These shifts have fragmented cohesive tasks into piecework
creating tensions around role boundaries and professional identity. Our
analysis suggests that current frameworks, like job crafting, need to evolve to
address the complexities of GenAI-driven transformations.",http://arxiv.org/abs/2502.08854v1
"Utilizing Pre-trained and Large Language Models for 10-K Items
  Segmentation",2025-02-13T01:21:15Z,"Hsin-Min Lu, Yu-Tai Chien, Huan-Hsun Yen, Yen-Hsiu Chen","Extracting specific items from 10-K reports remains challenging due to
variations in document formats and item presentation. Traditional rule-based
item segmentation approaches often yield suboptimal results. This study
introduces two advanced item segmentation methods leveraging language models:
(1) GPT4ItemSeg, using a novel line-ID-based prompting mechanism to utilize
GPT4 for item segmentation, and (2) BERT4ItemSeg, combining BERT embeddings
with a Bi-LSTM model in a hierarchical structure to overcome context window
constraints. Trained and evaluated on 3,737 annotated 10-K reports,
BERT4ItemSeg achieved a macro-F1 of 0.9825, surpassing GPT4ItemSeg (0.9567),
conditional random field (0.9818), and rule-based methods (0.9048) for core
items (1, 1A, 3, and 7). These approaches enhance item segmentation
performance, improving text analytics in accounting and finance. BERT4ItemSeg
offers satisfactory item segmentation performance, while GPT4ItemSeg can easily
adapt to regulatory changes. Together, they offer practical benefits for
researchers and practitioners, enabling reliable empirical studies and
automated 10-K item segmentation functionality.",http://arxiv.org/abs/2502.08875v1
"CoCreatAR: Enhancing Authoring of Outdoor Augmented Reality Experiences
  Through Asymmetric Collaboration",2025-02-13T05:38:45Z,"Nels Numan, Gabriel Brostow, Suhyun Park, Simon Julier, Anthony Steed, Jessica Van Brummelen","Authoring site-specific outdoor augmented reality (AR) experiences requires a
nuanced understanding of real-world context to create immersive and relevant
content. Existing ex-situ authoring tools typically rely on static 3D models to
represent spatial information. However, in our formative study (n=25), we
identified key limitations of this approach: models are often outdated,
incomplete, or insufficient for capturing critical factors such as safety
considerations, user flow, and dynamic environmental changes. These issues
necessitate frequent on-site visits and additional iterations, making the
authoring process more time-consuming and resource-intensive. To mitigate these
challenges, we introduce CoCreatAR, an asymmetric collaborative mixed reality
authoring system that integrates the flexibility of ex-situ workflows with the
immediate contextual awareness of in-situ authoring. We conducted an
exploratory study (n=32) comparing CoCreatAR to an asynchronous workflow
baseline, finding that it enhances engagement, creativity, and confidence in
the authored output while also providing preliminary insights into its impact
on task load. We conclude by discussing the implications of our findings for
integrating real-world context into site-specific AR authoring systems.",http://arxiv.org/abs/2502.08981v1
Gauss-Bonnet-induced symmetry breaking/restoration during inflation,2025-02-13T05:48:58Z,"Yermek Aldabergenov, Daulet Berkimbayev","We propose a mechanism of symmetry breaking or restoration that can occur in
the middle of inflation due to the coupling of the Gauss-Bonnet term to a
charged scalar. The Gauss-Bonnet coupling results in an inflaton-dependent
effective squared mass of the charged scalar, which can change its sign (around
the symmetric point) during inflation. This can lead to spontaneous breaking of
the symmetry, or to its restoration, if it is initially broken. We show the
conditions under which the backreaction of the Gauss-Bonnet coupling on the
inflationary background is negligible, such that the predictions of a given
inflationary model are unaffected by the symmetry breaking/restoration process.",http://arxiv.org/abs/2502.08986v1
"Mechanistic Unveiling of Transformer Circuits: Self-Influence as a Key
  to Model Reasoning",2025-02-13T07:19:05Z,"Lin Zhang, Lijie Hu, Di Wang","Transformer-based language models have achieved significant success; however,
their internal mechanisms remain largely opaque due to the complexity of
non-linear interactions and high-dimensional operations. While previous studies
have demonstrated that these models implicitly embed reasoning trees, humans
typically employ various distinct logical reasoning mechanisms to complete the
same task. It is still unclear which multi-step reasoning mechanisms are used
by language models to solve such tasks. In this paper, we aim to address this
question by investigating the mechanistic interpretability of language models,
particularly in the context of multi-step reasoning tasks. Specifically, we
employ circuit analysis and self-influence functions to evaluate the changing
importance of each token throughout the reasoning process, allowing us to map
the reasoning paths adopted by the model. We apply this methodology to the
GPT-2 model on a prediction task (IOI) and demonstrate that the underlying
circuits reveal a human-interpretable reasoning process used by the model.",http://arxiv.org/abs/2502.09022v2
"From Visuals to Vocabulary: Establishing Equivalence Between Image and
  Text Token Through Autoregressive Pre-training in MLLMs",2025-02-13T09:04:28Z,"Mingxiao Li, Fang Qu, Zhanpeng Chen, Na Su, Zhizhou Zhong, Ziyang Chen, Nan Du, Xiaolong Li","While MLLMs perform well on perceptual tasks, they lack precise multimodal
alignment, limiting performance. To address this challenge, we propose Vision
Dynamic Embedding-Guided Pretraining (VDEP), a hybrid autoregressive training
paradigm for MLLMs. Utilizing dynamic embeddings from the MLP following the
visual encoder, this approach supervises image hidden states and integrates
image tokens into autoregressive training. Existing MLLMs primarily focused on
recovering information from textual inputs, often neglecting the effective
processing of image data. In contrast, the key improvement of this work is the
reinterpretation of multimodal alignment as a process of recovering information
from input data, with particular emphasis on reconstructing detailed visual
features.The proposed method seamlessly integrates into standard models without
architectural changes. Experiments on 13 benchmarks show VDEP outperforms
baselines, surpassing existing methods.",http://arxiv.org/abs/2502.09093v1
"Mathematical modeling and simulation of coupled aqueous humor flow and
  temperature distribution in a realistic 3D human eye geometry",2025-02-13T09:55:16Z,"Thomas Saigre, Vincent Chabannes, Christophe Prud'Homme, Marcela Szopos","We present a comprehensive computational model to simulate the coupled
dynamics of aqueous humor flow and heat transfer in the human eye. To manage
the complexity of the model, we make significant efforts in meshing and
efficient solution of the discrete problem using high-performance resources.
The model accurately describes the dynamics of the aqueous humor in the
anterior and posterior chambers and accounts for convective effects due to
temperature variations. Results for fluid velocity, pressure, and temperature
distribution are in good agreement with existing numerical results in the
literature. Furthermore, the effects of postural changes and wall shear stress
behavior are analyzed, providing new insights into the mechanical forces acting
on ocular tissues. Overall, the present contribution provides a detailed
three-dimensional simulation that enhances the understanding of ocular
physiology and may contribute to further progress in clinical research and
treatment optimization in ophthalmology.",http://arxiv.org/abs/2502.09119v1
"Two-level control over quantum state creation via entangled
  equal-probability state",2025-02-13T09:59:00Z,"S. I. Doronin, E. B. Fel'dman, A. I. Zenchuk","We propose the scheme realizing the two-level control over the unitary
operators $U_k$ creating the required quantum state of the system $S$. These
operators are controlled by the superposition state of the auxiliary subsystem
$R$ which is governed by two control centers. The
  first-level control center (main control) creates the equal-probability pure
state of $R$ with certain distribution of phase factors that, in turn, govern
the power of the second-level control center $C$ that applies the special
$V$-operators to the same subsystem $R$ changing its state and thus controlling
the applicability of $U_k$. In addition, the above phases are responsible for
the entanglement in the subsystem $R$. We find the direct relation between this
entanglement and the number of operators $U_k$ that can be controlled by $C$.
The simple example of a two-level control system governing the creation of
entangled state of the two-qubit system $S$ is presented.",http://arxiv.org/abs/2502.09124v1
"E-MD3C: Taming Masked Diffusion Transformers for Efficient Zero-Shot
  Object Customization",2025-02-13T10:48:11Z,"Trung X. Pham, Zhang Kang, Ji Woo Hong, Xuran Zheng, Chang D. Yoo","We propose E-MD3C ($\underline{E}$fficient $\underline{M}$asked
$\underline{D}$iffusion Transformer with Disentangled $\underline{C}$onditions
and $\underline{C}$ompact $\underline{C}$ollector), a highly efficient
framework for zero-shot object image customization. Unlike prior works reliant
on resource-intensive Unet architectures, our approach employs lightweight
masked diffusion transformers operating on latent patches, offering
significantly improved computational efficiency. The framework integrates three
core components: (1) an efficient masked diffusion transformer for processing
autoencoder latents, (2) a disentangled condition design that ensures
compactness while preserving background alignment and fine details, and (3) a
learnable Conditions Collector that consolidates multiple inputs into a compact
representation for efficient denoising and learning. E-MD3C outperforms the
existing approach on the VITON-HD dataset across metrics such as PSNR, FID,
SSIM, and LPIPS, demonstrating clear advantages in parameters, memory
efficiency, and inference speed. With only $\frac{1}{4}$ of the parameters, our
Transformer-based 468M model delivers $2.5\times$ faster inference and uses
$\frac{2}{3}$ of the GPU memory compared to an 1720M Unet-based latent
diffusion model.",http://arxiv.org/abs/2502.09164v1
"Orbital-selective correlation effects and superconducting pairing
  symmetry in a multiorbital $t$-$J$ model for bilayer nickelates",2025-02-13T11:36:17Z,"Guijing Duan, Zhiguang Liao, Lei Chen, Yiming Wang, Rong Yu, Qimiao Si","The recent discovery of superconductivity in La$_3$Ni$_2$O$_7$ raises key
questions about its mechanism and the nature of pairing symmetry. This system
is believed to be described by a bilayer two-orbital Hubbard model. The
considerations of orbital-selective Mott correlations motivate a bilayer
two-orbital $t$-$J$ model and, accordingly, we study the superconducting
pairing in this model. We obtain an overall phase diagram of superconductivity,
where the leading channel has either extended $s$-wave or $d_{x^2-y^2}$-wave
symmetry. Our analysis highlights how the orbital-selective correlations affect
the superconducting pairing via the interlayer exchange couplings and
low-energy electronic structure. In particular, we find that the dominant
orbital for the pairing may change between $z^2$ and $x^2-y^2$ when the
position of the bonding $z^2$ band is varied by tuning either the $c$-axis
lattice constant or electron concentration strength. We discuss the
implications of these results for the superconductivity in both bulk
La$_{3}$Ni$_{2}$O$_{7}$ and its thin film counterpart.",http://arxiv.org/abs/2502.09195v1
"Transactional Dynamics in Hyperledger Fabric: A Stochastic Modeling and
  Performance Evaluation of Permissioned Blockchains",2025-02-13T12:41:48Z,"Carlos Melo, Glauber Gonçalves, Francisco Airton Silva, Iure Fé, Ericksulino Moura, André Soares, Eunmi Choi, Dugki Min, Jae-Woo Lee, Tuan Anh Nguyen","Blockchain, often integrated with distributed systems and security
enhancements, has significant potential in various industries. However,
environmental concerns and the efficiency of consortia-controlled permissioned
networks remain critical issues. We use a Stochastic Petri Net model to analyze
transaction flows in Hyperledger Fabric networks, achieving a 95% confidence
interval for response times. This model enables administrators to assess the
impact of system changes on resource utilization. Sensitivity analysis reveals
major factors influencing response times and throughput. Our case studies
demonstrate that block size can alter throughput and response times by up to
200%, underscoring the need for performance optimization with resource
efficiency.",http://arxiv.org/abs/2502.09276v1
Trajectory Inference for Single Cell Omics,2025-02-13T14:19:33Z,"Alexandre Hutton, Jesse G. Meyer","Trajectory inference is used to order single-cell omics data along a path
that reflects a continuous transition between cells. This approach is useful
for studying processes like cell differentiation, where a stem cell matures
into a specialized cell type, or investigating state changes in pathological
conditions. In the current article, we provide a general introduction to
trajectory inference, explaining the concepts and assumptions underlying the
different methods. We then briefly discuss the strengths and weaknesses of
different trajectory inference methods. We also describe best practices for
using trajectory inference, such as how to validate the results and how to
interpret them in the context of biological knowledge. Finally, the article
will discuss some of the applications of trajectory inference in single-cell
omics research. These applications include studying cell differentiation,
development, and disease. We provide examples of how trajectory inference has
been used to gain new insights into these processes.",http://arxiv.org/abs/2502.09354v1
"Superconducting diode efficiency from singlet-triplet mixing in
  disordered systems",2025-02-13T15:44:21Z,"Jaglul Hasan, Daniel Shaffer, Maxim Khodas, Alex Levchenko","The superconducting diode effect (SDE) -- the nonreciprocity of the critical
current in a bulk superconductor -- has garnered significant attention due to
its potential applications in superconducting electronics. However, the role of
disorder scattering in SDE has rarely been considered, despite its potential
qualitative impact, as we demonstrate in this work. We investigate SDE in a
disordered Rashba superconductor under an in-plane magnetic field, employing a
self-consistent Born approximation to derive the corresponding Ginzburg-Landau
theory. Our analysis reveals two surprising effects. First, in the weak Rashba
spin-orbit coupling (SOC) regime, disorder can reverse the direction of the
diode effect, indicated by a sign change in the superconducting diode
efficiency coefficient. Second, in the strong Rashba SOC regime, disorder
becomes the driving mechanism of SDE, which vanishes in its absence. In this
case, we show that disorder-induced mixing of singlet and triplet
superconducting orders underlies the effect.",http://arxiv.org/abs/2502.09421v1
Relational Conformal Prediction for Correlated Time Series,2025-02-13T16:12:17Z,"Andrea Cini, Alexander Jenkins, Danilo Mandic, Cesare Alippi, Filippo Maria Bianchi","We address the problem of uncertainty quantification in time series
forecasting by exploiting observations at correlated sequences. Relational deep
learning methods leveraging graph representations are among the most effective
tools for obtaining point estimates from spatiotemporal data and correlated
time series. However, the problem of exploiting relational structures to
estimate the uncertainty of such predictions has been largely overlooked in the
same context. To this end, we propose a novel distribution-free approach based
on the conformal prediction framework and quantile regression. Despite the
recent applications of conformal prediction to sequential data, existing
methods operate independently on each target time series and do not account for
relationships among them when constructing the prediction interval. We fill
this void by introducing a novel conformal prediction method based on graph
deep learning operators. Our method, named Conformal Relational Prediction
(CoRel), does not require the relational structure (graph) to be known as a
prior and can be applied on top of any pre-trained time series predictor.
Additionally, CoRel includes an adaptive component to handle non-exchangeable
data and changes in the input time series. Our approach provides accurate
coverage and archives state-of-the-art uncertainty quantification in relevant
benchmarks.",http://arxiv.org/abs/2502.09443v1
Pixel-Level Reasoning Segmentation via Multi-turn Conversations,2025-02-13T16:16:54Z,"Dexian Cai, Xiaocui Yang, Yongkang Liu, Daling Wang, Shi Feng, Yifei Zhang, Soujanya Poria","Existing visual perception systems focus on region-level segmentation in
single-turn dialogues, relying on complex and explicit query instructions. Such
systems cannot reason at the pixel level and comprehend dynamic user intent
that changes over interaction. Our work tackles this issue by introducing a
novel task, Pixel-level Reasoning Segmentation (Pixel-level RS) based on
multi-turn conversations, tracking evolving user intent via multi-turn
interactions for fine-grained segmentation. To establish a benchmark for this
novel task, we build a Pixel-level ReasonIng Segmentation Dataset Based on
Multi-Turn Conversations (PRIST), comprising 24k utterances from 8.3k
multi-turn conversational scenarios with segmentation targets. Building on
PRIST, we further propose MIRAS, a Multi-turn Interactive ReAsoning
Segmentation framework, integrates pixel-level segmentation with robust
multi-turn conversation understanding, generating pixel-grounded explanations
aligned with user intent. The PRIST dataset and MIRSA framework fill the gap in
pixel-level reasoning segmentation. Experimental results on the PRIST dataset
demonstrate that our method outperforms current segmentation-specific baselines
in terms of segmentation and LLM-based reasoning metrics. The code and data are
available at: https://github.com/ccccai239/PixelRIST.",http://arxiv.org/abs/2502.09447v1
"Counterflow of lattice polarons in harmonically confined optical
  lattices",2025-02-13T16:17:27Z,"Felipe Isaule, Abel Rojo-Francàs, Luis Morales-Molina, Bruno Juliá-Díaz","We study a mobile impurity in a one-dimensional harmonically confined optical
lattice interacting repulsively with a bosonic bath. The behavior of the
impurity across baths with superfluid and Mott-insulator domains is examined,
including its full back-action effect on the bath. We characterize the
bath-impurity phase diagram and reveal the appearance of a correlated
counterflow phase, which we support with an analytical model for a mobile
impurity-hole pair. This phase shows a combined insulator domain of unity
filling but no independent domain of constant density. The transition to this
phase features a sudden orthogonality catastrophe and the change of the shape
of the impurity's profile to that of a free particle in an infinite square
well. The findings of this work suggest the appearance of unconventional
counterflow in trapped imbalanced atomic mixtures.",http://arxiv.org/abs/2502.09448v1
"MorphNLI: A Stepwise Approach to Natural Language Inference Using Text
  Morphing",2025-02-13T18:22:31Z,"Vlad Andrei Negru, Robert Vacareanu, Camelia Lemnaru, Mihai Surdeanu, Rodica Potolea","We introduce MorphNLI, a modular step-by-step approach to natural language
inference (NLI). When classifying the premise-hypothesis pairs into
{entailment, contradiction, neutral}, we use a language model to generate the
necessary edits to incrementally transform (i.e., morph) the premise into the
hypothesis. Then, using an off-the-shelf NLI model we track how the entailment
progresses with these atomic changes, aggregating these intermediate labels
into a final output. We demonstrate the advantages of our proposed method
particularly in realistic cross-domain settings, where our method always
outperforms strong baselines with improvements up to 12.6% (relative). Further,
our proposed approach is explainable as the atomic edits can be used to
understand the overall NLI label.",http://arxiv.org/abs/2502.09567v1
Learning to Coordinate with Experts,2025-02-13T18:41:55Z,"Mohamad H. Danesh, Tu Trinh, Benjamin Plaut, Nguyen X. Khanh","When deployed in dynamic environments, AI agents will inevitably encounter
challenges that exceed their individual capabilities. Leveraging assistance
from expert agents-whether human or AI-can significantly enhance safety and
performance in such situations. However, querying experts is often costly,
necessitating the development of agents that can efficiently request and
utilize expert guidance. In this paper, we introduce a fundamental coordination
problem called Learning to Yield and Request Control (YRC), where the objective
is to learn a strategy that determines when to act autonomously and when to
seek expert assistance. We consider a challenging practical setting in which an
agent does not interact with experts during training but must adapt to novel
environmental changes and expert interventions at test time. To facilitate
empirical research, we introduce YRC-Bench, an open-source benchmark featuring
diverse domains. YRC-Bench provides a standardized Gym-like API, simulated
experts, evaluation pipeline, and implementation of competitive baselines.
Towards tackling the YRC problem, we propose a novel validation approach and
investigate the performance of various learning methods across diverse
environments, yielding insights that can guide future research.",http://arxiv.org/abs/2502.09583v1
"$B\to K\sf{+}invisible$, dark matter, and $CP$ violation in hyperon
  decays",2025-02-13T18:53:47Z,"Xiao-Gang He, Xiao-Dong Ma, Jusak Tandean, German Valencia","Recently the Belle II Collaboration has reported a measurement of the $B^+\to
K^+\nu\bar\nu$ rate that is higher than the standard-model expectation. Since
the emitted neutrinos are unobserved, the excess could be due to the $B^+$
decaying into a $K^+$ and a dark-matter pair. We entertain this possibility in
a two-Higgs-doublet model supplemented with a real singlet scalar boson acting
as the dark matter. This model also accommodates strangeness-changing
interactions providing new sources of $CP$ violation which can affect hyperon
and kaon nonleptonic transitions. We find that the resulting $CP$ violation in
the hyperon sector can be significant, reaching the current empirical bounds,
after taking into account constraints from kaon mixing and decay and from
dark-matter relic-density data and direct searches including the Migdal effect.
We demonstrate that the hyperon and kaon processes are complementary probes of
this new-physics scenario. Its prediction for sizable hyperon $CP$ violation is
potentially testable in ongoing experiments, such as BESIII, Belle II, and
LHCb, and in next-generation ones like PANDA and at the Super Tau Charm
Facility.",http://arxiv.org/abs/2502.09603v1
"Neuro-Conceptual Artificial Intelligence: Integrating OPM with Deep
  Learning to Enhance Question Answering Quality",2025-02-12T06:10:09Z,"Xin Kang, Veronika Shteingardt, Yuhan Wang, Dov Dori","Knowledge representation and reasoning are critical challenges in Artificial
Intelligence (AI), particularly in integrating neural and symbolic approaches
to achieve explainable and transparent AI systems. Traditional knowledge
representation methods often fall short of capturing complex processes and
state changes. We introduce Neuro-Conceptual Artificial Intelligence (NCAI), a
specialization of the neuro-symbolic AI approach that integrates conceptual
modeling using Object-Process Methodology (OPM) ISO 19450:2024 with deep
learning to enhance question-answering (QA) quality. By converting natural
language text into OPM models using in-context learning, NCAI leverages the
expressive power of OPM to represent complex OPM elements-processes, objects,
and states-beyond what traditional triplet-based knowledge graphs can easily
capture. This rich structured knowledge representation improves reasoning
transparency and answer accuracy in an OPM-QA system. We further propose
transparency evaluation metrics to quantitatively measure how faithfully the
predicted reasoning aligns with OPM-based conceptual logic. Our experiments
demonstrate that NCAI outperforms traditional methods, highlighting its
potential for advancing neuro-symbolic AI by providing rich knowledge
representations, measurable transparency, and improved reasoning.",http://arxiv.org/abs/2502.09658v1
"Revealing Subtle Phenotypes in Small Microscopy Datasets Using Latent
  Diffusion Models",2025-02-12T15:45:19Z,"Anis Bourou, Biel Castaño Segade, Thomas Boye, Valérie Mezger, Auguste Genovesio","Identifying subtle phenotypic variations in cellular images is critical for
advancing biological research and accelerating drug discovery. These variations
are often masked by the inherent cellular heterogeneity, making it challenging
to distinguish differences between experimental conditions. Recent advancements
in deep generative models have demonstrated significant potential for revealing
these nuanced phenotypes through image translation, opening new frontiers in
cellular and molecular biology as well as the identification of novel
biomarkers. Among these generative models, diffusion models stand out for their
ability to produce high-quality, realistic images. However, training diffusion
models typically requires large datasets and substantial computational
resources, both of which can be limited in biological research. In this work,
we propose a novel approach that leverages pre-trained latent diffusion models
to uncover subtle phenotypic changes. We validate our approach qualitatively
and quantitatively on several small datasets of microscopy images. Our findings
reveal that our approach enables effective detection of phenotypic variations,
capturing both visually apparent and imperceptible differences. Ultimately, our
results highlight the promising potential of this approach for phenotype
detection, especially in contexts constrained by limited data and computational
capacity.",http://arxiv.org/abs/2502.09665v1
"Channel Dependence, Limited Lookback Windows, and the Simplicity of
  Datasets: How Biased is Time Series Forecasting?",2025-02-13T13:35:10Z,"Ibram Abdelmalak, Kiran Madhusudhanan, Jungmin Choi, Maximilian Stubbemann, Lars Schmidt-Thieme","Time-series forecasting research has converged to a small set of datasets and
a standardized collection of evaluation scenarios. Such a standardization is to
a specific extent needed for comparable research. However, the underlying
assumption is, that the considered setting is a representative for the problem
as a whole. In this paper, we challenge this assumption and show that the
current scenario gives a strongly biased perspective on the state of
time-series forecasting research. To be more detailed, we show that the current
evaluation scenario is heavily biased by the simplicity of the current
datasets. We furthermore emphasize, that when the lookback-window is properly
tuned, current models usually do not need any information flow across channels.
However, when using more complex benchmark data, the situation changes: Here,
modeling channel-interactions in a sophisticated manner indeed enhances
performances. Furthermore, in this complex evaluation scenario, Crossformer, a
method regularly neglected as an important baseline, is the SOTA method for
time series forecasting. Based on this, we present the Fast Channel-dependent
Transformer (FaCT), a simplified version of Crossformer which closes the
runtime gap between Crossformer and TimeMixer, leading to an efficient model
for complex forecasting datasets.",http://arxiv.org/abs/2502.09683v1
Lattice Schwinger Model and Spacetime Supersymmetry,2025-02-13T19:00:00Z,"Yanting Cheng, Shang Liu","Gauge theories in (1+1)D have attracted renewed attention partially due to
their experimental realizations in quantum simulation platforms. In this work,
we revisit the lattice massive Schwinger model and the (1+1)D lattice
Abelian-Higgs model, uncovering previously overlooked universal features,
including the emergence of a supersymmetric quantum critical point when the
Maxwell term's coefficient changes sign. To facilitate the quantum simulation
of these theories, we adopt a strategy of truncating the electric field
eigenvalues to a finite subset, preserving the exact gauge and global
symmetries. Our primary focus is the truncated lattice Schwinger model at
$\theta=0$, a model not equivalent to familiar spin models. We find that upon
reversing the sign of the Maxwell term, the second-order
deconfinement-confinement transition can become first-order, and the two types
of transitions are connected by a supersymmetric critical point in the
tricritical Ising universality class. In the case of truncated abelian-Higgs
model at $\theta=0$, which turns out to be equivalent to the quantum
Blume-Capel model, the very existence of a deconfined phase requires a
negative-sign Maxwell term. Similarly, there is a tricritical Ising point
separating first-order and second-order phase transitions.",http://arxiv.org/abs/2502.09697v1
Revealing correlated noise with single-qubit operations,2025-02-13T19:00:10Z,"Balázs Gulácsi, Joris Kattemölle, Guido Burkard","Spatially correlated noise poses a significant challenge to fault-tolerant
quantum computation by breaking the assumption of independent errors. Existing
methods such as cycle benchmarking and quantum process tomography can
characterize noise correlations but require substantial resources. We propose
straightforward and efficient techniques to detect and quantify these
correlations by leveraging collective phenomena arising from environmental
correlations in a qubit register. In these techniques, single-qubit state
preparations, single-qubit gates, and single-qubit measurements, combined with
classical post-processing, suffice to uncover correlated relaxation and
dephasing. Specifically, we use that correlated relaxation is connected to the
superradiance effect which we show to be accessible by single-qubit
measurements. Analogously, the established parity oscillation protocol can be
refined to reveal correlated dephasing through characteristic changes in the
oscillation line shape, without requiring the preparation of complex and
entangled states.",http://arxiv.org/abs/2502.09706v1
"Transtiff: A Stylus-shaped Interface for Rendering Perceived Stiffness
  of Virtual Objects via Stylus Stiffness Control",2025-02-14T04:14:30Z,"Ryoya Komatsu, Ayumu Ogura, Shigeo Yoshida, Kazutoshi Tanaka, Yuichi Itoh","The replication of object stiffness is essential for enhancing haptic
feedback in virtual environments. However, existing research has overlooked how
stylus stiffness influences the perception of virtual object stiffness during
tool-mediated interactions. To address this, we conducted a psychophysical
experiment demonstrating that changing stylus stiffness combined with visual
stimuli altered users' perception of virtual object stiffness. Based on these
insights, we developed Transtiff, a stylus-shaped interface capable of
on-demand stiffness control using a McKibben artificial muscle mechanism.
Unlike previous approaches, our method manipulates the perceived stiffness of
virtual objects via the stylus by controlling the stiffness of the stylus
without altering the properties of the real object being touched, creating the
illusion of a hard object feeing soft. Our user study confirmed that Transtiff
effectively simulates a range of material properties, such as sponge, plastic,
and tennis balls, providing haptic rendering that is closely aligned with the
perceived material characteristics. By addressing the challenge of delivering
realistic haptic feedback through tool-based interactions, Transtiff represents
a significant advancement in the haptic interface design for VR applications.",http://arxiv.org/abs/2502.09899v1
"Pressure-Induced Structural and Dielectric Changes in Liquid Water at
  Room Temperature",2025-02-14T05:02:28Z,"Yizhi Song, Xifan Wu","Understanding the pressure-dependent dielectric properties of water is
crucial for a wide range of scientific and practical applications. In this
study, we employ a deep neural network trained on density functional theory
data to investigate the dielectric properties of liquid water at room
temperature across a pressure range of 0.1 MPa to 1000 MPa. We observe a
nonlinear increase in the static dielectric constant $\epsilon_0$ with
increasing pressure, a trend that is qualitatively consistent with experimental
observations. This increase in $\epsilon_0$ is primarily attributed to the
increase in water density under compression, which enhances collective dipole
fluctuations within the hydrogen-bonding network as well as the dielectric
response. Despite the increase in $\epsilon_0$, our results reveal a decrease
in the Kirkwood correlation factor $G_K$ with increasing pressure. This
decrease in $G_K$ is attributed to pressure-induced structural distortions in
the hydrogen-bonding network, which weaken dipolar correlations by disrupting
the ideal tetrahedral arrangement of water molecules.",http://arxiv.org/abs/2502.09915v1
"Sensitivity study of a sapphire detector using Coherent Elastic
  Neutrino-Nucleus Scattering process",2025-02-14T07:58:53Z,S. P. Behera,"The Indian Coherent Neutrino-nucleus Scattering Experiment(ICNSE) has been
proposed at Bhabha Atomic Research Centre in India to measure the coherent
elastic neutrino-nucleus scattering process using electron antineutrinos
produced from reactors. Phenomenological studies are performed to find out the
sensitivity of sapphire detector for various fundamental physics parameters at
an exposure of one year. Reactors of different core compositions, sizes, and
thermal powers have been considered as sources of electron antineutrinos. The
potential of the ICNSE to measure the weak mixing angle at a low energy regime
has been extracted. Furthermore, the detector's capability has been
investigated for examining the electromagnetic properties of neutrinos,
including their magnetic moment. Additionally, an exploration has been
conducted on the detector's sensitivity in restricting new interactions between
neutrinos and electrons or nuclei, thereby constraining the parameter space
related to light mediators. It is found that the ICNSE detector can put a
stronger constraints on the scalar and vector mediators masses.",http://arxiv.org/abs/2502.09972v2
"Has My System Prompt Been Used? Large Language Model Prompt Membership
  Inference",2025-02-14T08:00:42Z,"Roman Levin, Valeriia Cherepanova, Abhimanyu Hans, Avi Schwarzschild, Tom Goldstein","Prompt engineering has emerged as a powerful technique for optimizing large
language models (LLMs) for specific applications, enabling faster prototyping
and improved performance, and giving rise to the interest of the community in
protecting proprietary system prompts. In this work, we explore a novel
perspective on prompt privacy through the lens of membership inference. We
develop Prompt Detective, a statistical method to reliably determine whether a
given system prompt was used by a third-party language model. Our approach
relies on a statistical test comparing the distributions of two groups of model
outputs corresponding to different system prompts. Through extensive
experiments with a variety of language models, we demonstrate the effectiveness
of Prompt Detective for prompt membership inference. Our work reveals that even
minor changes in system prompts manifest in distinct response distributions,
enabling us to verify prompt usage with statistical significance.",http://arxiv.org/abs/2502.09974v1
"Wavefront Solutions for Reaction-diffusion-convection Models with
  Accumulation Term and Aggregative Movements",2025-02-14T09:12:37Z,"Marco Cantarini, Cristina Marcelli, Francesca Papalini","In this paper we analyze the wavefront solutions of parabolic partial
differential equations of the type \[
g(u)u_{\tau}+f(u)u_{x}=\left(D(u)u_{x}\right)_{x}+\rho(u),\quad
u\left(\tau,x\right)\in[0,1] \] where the reaction term $\rho$ is of
monostable-type. We allow the diffusivity $D$ and the accumulation term $g$ to
have a finite number of changes of sign.
  We provide an existence result of travelling wave solutions (t.w.s.) together
with an estimate of the threshold wave speed. Finally, we classify the t.w.s.
between classical and sharp ones.",http://arxiv.org/abs/2502.10026v1
"Structuring the Environment Nudges Participants Toward Hierarchical Over
  Shortest Path Planning",2025-02-14T11:45:46Z,"Valeria Simonelli, Davide Nuzzi, Gian Luca Lancia, Giovanni Pezzulo","Effective planning is crucial for navigating complex environments and
achieving goals efficiently. In this study, we investigated how environmental
structure influences the selection of planning strategies. Participants
navigated a space station to collect colored spheres, with environments either
structured (spheres grouped by color) or unstructured (spheres scattered
randomly). We tested three types of plans: hierarchical (grouping spheres by
color), shortest path (minimizing travel distance), and neutral (none of the
above). By manipulating environmental structure, we were able to nudge
participants toward a preference for hierarchical planning in structured
environments, while shortest path plans were favored in unstructured
environments. A mismatch between self-reported preferences and actual choices
indicated that participants often adopted implicit strategies, unaware of their
decision-making processes. These findings highlight the powerful effect of
environmental cues on planning and suggest that even subtle changes in
structure can guide the selection of planning strategies.",http://arxiv.org/abs/2502.10098v1
A Recolouring Version of a Conjecture of Reed,2025-02-14T13:19:30Z,"Lucas De Meyer, Clément Legrand-Duchesne, Jared León, Tim Planken, Youri Tamitegama","Reed conjectured that the chromatic number of any graph is closer to its
clique number than to its maximum degree plus one. We consider a recolouring
version of this conjecture, with respect to Kempe changes. Namely, we
investigate the largest $\varepsilon$ such that all graphs $G$ are
$k$-recolourable for all $k \ge \lceil \varepsilon \omega(G) + (1
-\varepsilon)(\Delta(G)+1) \rceil$. For general graphs, an existing
construction of a frozen colouring shows that $\varepsilon \le 1/3$. We show
that this construction is optimal in the sense that there are no frozen
colourings below that threshold. For this reason, we conjecture that
$\varepsilon = 1/3$. For triangle-free graphs, we give a construction of frozen
colourings that shows that $\varepsilon \le 4/9$, and prove that it is also
optimal. In the special case of odd-hole-free graphs, we show that $\varepsilon
= 1/2$, and that this is tight up to one colour.",http://arxiv.org/abs/2502.10147v1
"STMA: A Spatio-Temporal Memory Agent for Long-Horizon Embodied Task
  Planning",2025-02-14T14:12:09Z,"Mingcong Lei, Yiming Zhao, Ge Wang, Zhixin Mai, Shuguang Cui, Yatong Han, Jinke Ren","A key objective of embodied intelligence is enabling agents to perform
long-horizon tasks in dynamic environments while maintaining robust
decision-making and adaptability. To achieve this goal, we propose the
Spatio-Temporal Memory Agent (STMA), a novel framework designed to enhance task
planning and execution by integrating spatio-temporal memory. STMA is built
upon three critical components: (1) a spatio-temporal memory module that
captures historical and environmental changes in real time, (2) a dynamic
knowledge graph that facilitates adaptive spatial reasoning, and (3) a
planner-critic mechanism that iteratively refines task strategies. We evaluate
STMA in the TextWorld environment on 32 tasks, involving multi-step planning
and exploration under varying levels of complexity. Experimental results
demonstrate that STMA achieves a 31.25% improvement in success rate and a 24.7%
increase in average score compared to the state-of-the-art model. The results
highlight the effectiveness of spatio-temporal memory in advancing the memory
capabilities of embodied agents.",http://arxiv.org/abs/2502.10177v1
"Looking around you: external information enhances representations for
  event sequences",2025-02-14T14:59:37Z,"Maria Kovaleva, Petr Sokerin, Sofia Krehova, Alexey Zaytsev","Representation learning produces models in different domains, such as store
purchases, client transactions, and general people's behaviour. However, such
models for sequential data usually process a single sequence, ignoring context
from other relevant ones, even in domains with rapidly changing external
environments like finance or misguiding the prediction for a user with no
recent events.
  We are the first to propose a method that aggregates information from
multiple user representations augmenting a specific user one for a scenario of
multiple co-occurring event sequences. Our study considers diverse aggregation
approaches, ranging from simple pooling techniques to trainable attention-based
approaches, especially Kernel attention aggregation, that can highlight more
complex information flow from other users. The proposed method operates atop an
existing encoder and supports its efficient fine-tuning. Across considered
datasets of financial transactions and downstream tasks, Kernel attention
improves ROC AUC scores, both with and without fine-tuning, while mean pooling
yields a smaller but still significant gain.",http://arxiv.org/abs/2502.10205v1
"Understanding the relationships between the perceptions of burnout and
  instability in Software Engineering",2025-02-14T15:59:30Z,Danilo Monteiro Ribeiro,"Changes are inherent in software development, often increasing developers'
perception of instability. Understanding the relationship between human factors
and Software Engineering processes is crucial to mitigating and preventing
issues. One such factor is burnout, a recognized disease that impacts
productivity, turnover, and, most importantly, developers' well-being.
Investigating the link between instability and burnout can help organizations
implement strategies to improve developers' work conditions and performance.
  This study aims to identify and describe the relationship between perceived
instability and burnout among software developers. A cross-sectional survey was
conducted with 411 respondents, using convenience sampling and self-selection.
In addition to analyzing variable relationships, confirmatory factor analysis
was applied.
  Key findings include: (1) A significant positive relationship between burnout
(exhaustion and cynicism) and team, technological, and task instability; (2) A
weak negative relationship between efficacy and technological/team instability,
with no correlation to task instability; (3) Exhaustion was the most frequently
reported burnout symptom, while task instability was the most perceived type of
instability.
  These results are valuable for both industry and academia, providing insights
to reduce burnout and instability among software engineers. Future research can
further explore the impact of instability, offering new perspectives on
monitoring and mitigating its effects in software development.",http://arxiv.org/abs/2502.10249v1
Analog Quantum Teleportation,2025-02-14T16:03:05Z,"Uesli Alushi, Simone Felicetti, Roberto Di Candia","Digital teleportation protocols make use of entanglement, local measurements
and a classical communication channel to transfer quantum states between remote
parties. We consider analog teleportation protocols, where classical
communication is replaced by transmission through a noisy quantum channel. We
show that analog teleportation protocols outperform digital protocols if and
only if Alice and Bob are linked by a channel that does not reduce entanglement
when applied to a part of the resource state. We first derive general
analytical results in the broader context of Gaussian-channel simulation. Then,
we apply it to the quantum teleportation of a uniformly distributed codebook of
coherent states, showing that an analog protocol is optimal for a wide range of
communication channel transmissivities. Our result contributes to mitigating
noise in the intermediate case when the communication channel is far from being
ideal but is not too lossy, as is the case of cryogenic links in microwave
superconducting circuits.",http://arxiv.org/abs/2502.10253v2
Probing Perceptual Constancy in Large Vision Language Models,2025-02-14T16:31:43Z,"Haoran Sun, Suyang Yu, Yijiang Li, Qingying Gao, Haiyun Lyu, Hokin Deng, Dezhi Luo","Perceptual constancy is the ability to maintain stable perceptions of objects
despite changes in sensory input, such as variations in distance, angle, or
lighting. This ability is crucial for recognizing visual information in a
dynamic world, making it essential for Vision-Language Models (VLMs). However,
whether VLMs are currently and theoretically capable of mastering this ability
remains underexplored. In this study, we evaluated 33 VLMs using 253
experiments across three domains: color, size, and shape constancy. The
experiments included single-image and video adaptations of classic cognitive
tasks, along with novel tasks in in-the-wild conditions, to evaluate the
models' recognition of object properties under varying conditions. We found
significant variability in VLM performance, with models performance in shape
constancy clearly dissociated from that of color and size constancy.",http://arxiv.org/abs/2502.10273v1
"Detection of a peculiar noise type in the TESS ""fast"" light curves",2025-02-14T17:36:33Z,"Sz. Kálmán, Sz. Csizmadia, A. Pál, Gy. M. Szabó","We present the detection of a peculiar high-frequency noise component in the
20 second cadence SAP (Simple Aperture Photometry) light curve of TESS
(Transiting Exoplanets Survey Satellite). This effect (labeled as blue noise)
may be attributed to the pointing instability (also known as satellite jiiter)
of the satellite. We present a common technique used in the mitigation of the
jitter, by decorrelating against the subpixel position of the photo-center of
the point spread function of the star. We also show that a simple linear or
polynomial technique may not yield satisfactory corrections, as the behavior or
attitude of the noise properties may change considerably throughout the light
curve.",http://arxiv.org/abs/2502.10326v1
"Organize the Web: Constructing Domains Enhances Pre-Training Data
  Curation",2025-02-14T18:02:37Z,"Alexander Wettig, Kyle Lo, Sewon Min, Hannaneh Hajishirzi, Danqi Chen, Luca Soldaini","Modern language models are trained on large, unstructured datasets consisting
of trillions of tokens and obtained by crawling the web. The unstructured
nature makes it difficult to reason about their contents and develop systematic
approaches to data curation. In this paper, we unpack monolithic web corpora by
developing taxonomies of their contents and organizing them into domains. We
introduce WebOrganizer, a framework for organizing web pages in terms of both
their topic and format. Using these two complementary notions of domains, we
automatically annotate pre-training data by distilling annotations from a large
language model into efficient classifiers. This allows us to study how data
from different domains should be mixed to improve models on downstream tasks,
and we show that we can combine insights about effective topics and formats to
further boost performance. We demonstrate that our domain mixing also improves
existing methods that select data based on quality. Furthermore, we study and
compare how quality-based methods will implicitly change the domain mixture.
Overall, our work demonstrates that constructing and mixing domains provides a
valuable complement to quality-based data curation methods, opening new avenues
for effective and insightful pre-training data curation.",http://arxiv.org/abs/2502.10341v1
DRiVE: Dynamic Recognition in VEhicles using snnTorch,2025-02-04T11:01:13Z,"Heerak Vora, Param Pathak, Parul Bakaraniya","Spiking Neural Networks (SNNs) mimic biological brain activity, processing
data efficiently through an event-driven design, wherein the neurons activate
only when inputs exceed specific thresholds. Their ability to track voltage
changes over time via membrane potential dynamics helps retain temporal
information. This study combines SNNs with PyTorch's adaptable framework,
snnTorch, to test their potential for image-based tasks. We introduce DRiVE, a
vehicle detection model that uses spiking neuron dynamics to classify images,
achieving 94.8% accuracy and a near-perfect 0.99 AUC score. These results
highlight DRiVE's ability to distinguish vehicle classes effectively,
challenging the notion that SNNs are limited to temporal data. As interest
grows in energy-efficient neural models, DRiVE's success emphasizes the need to
refine SNN optimization for visual tasks. This work encourages broader
exploration of SNNs in scenarios where conventional networks struggle,
particularly for real-world applications requiring both precision and
efficiency.",http://arxiv.org/abs/2502.10421v1
A Robust Attack: Displacement Backdoor Attack,2025-02-14T13:15:13Z,"Yong Li, Han Gao","As artificial intelligence becomes more prevalent in our lives, people are
enjoying the convenience it brings, but they are also facing hidden threats,
such as data poisoning and adversarial attacks. These threats can have
disastrous consequences for the application of artificial intelligence,
especially for some applications that take effect immediately, such as
autonomous driving and medical fields. Among these threats, backdoor attacks
have left a deep impression on people with their concealment and simple
deployment, making them a threat that cannot be ignored, however, in the
process of deploying the backdoor model, the backdoor attack often has some
reasons that make it unsatisfactory in real-world applications, such as jitter
and brightness changes. Based on this, we propose a highly robust backdoor
attack that shifts the target sample and combines it with itself to form a
backdoor sample, the Displacement Backdoor Attack(DBA). Experimental results
show that the DBA attack can resist data augmentation that simulates real-world
differences, such as rotation and cropping.",http://arxiv.org/abs/2502.10490v1
SWA-LDM: Toward Stealthy Watermarks for Latent Diffusion Models,2025-02-14T16:55:45Z,"Zhonghao Yang, Linye Lyu, Xuanhang Chang, Daojing He, YU LI","In the rapidly evolving landscape of image generation, Latent Diffusion
Models (LDMs) have emerged as powerful tools, enabling the creation of highly
realistic images. However, this advancement raises significant concerns
regarding copyright infringement and the potential misuse of generated content.
Current watermarking techniques employed in LDMs often embed constant signals
to the generated images that compromise their stealthiness, making them
vulnerable to detection by malicious attackers. In this paper, we introduce
SWA-LDM, a novel approach that enhances watermarking by randomizing the
embedding process, effectively eliminating detectable patterns while preserving
image quality and robustness. Our proposed watermark presence attack reveals
the inherent vulnerabilities of existing latent-based watermarking methods,
demonstrating how easily these can be exposed. Through comprehensive
experiments, we validate that SWA-LDM not only fortifies watermark stealthiness
but also maintains competitive performance in watermark robustness and visual
fidelity. This work represents a pivotal step towards securing LDM-generated
images against unauthorized use, ensuring both copyright protection and content
integrity in an era where digital image authenticity is paramount.",http://arxiv.org/abs/2502.10495v1
"A Comprehensive Hyperledger Fabric Performance Evaluation based on
  Resources Capacity Planning",2025-02-14T19:14:06Z,"Carlos Melo, Glauber Gonçalves, Francisco A. Silva, André Soares","Hyperledger Fabric is a platform for permissioned blockchain networks that
enables secure and auditable distributed data storage for enterprise
applications. There is a growing interest in applications based on this
platform, but its use requires the configuration of different blockchain
parameters. Various configurations impact the system's non-functional
qualities, especially performance and cost. In this article, we propose a
Stochastic Petri Net to model the performance of the Hyperledger Fabric
platform with different blockchain parameters, computer capacity, and
transaction rates. We also present a set of case studies to demonstrate the
feasibility of the proposed model. This model serves as a practical guide to
help administrators of permissioned blockchain networks find the best
performance for their applications. The proposed model allowed us to identify
the block size that leads to a high mean response time (ranging from 1 to 25
seconds) caused by a change in the arrival rate.",http://arxiv.org/abs/2502.10509v1
"VisiMark: Characterizing and Augmenting Landmarks for People with Low
  Vision in Augmented Reality to Support Indoor Navigation",2025-02-14T21:23:55Z,"Ruijia Chen, Junru Jiang, Pragati Maheshwary, Brianna R. Cochran, Yuhang Zhao","Landmarks are critical in navigation, supporting self-orientation and mental
model development. Similar to sighted people, people with low vision (PLV)
frequently look for landmarks via visual cues but face difficulties identifying
some important landmarks due to vision loss. We first conducted a formative
study with six PLV to characterize their challenges and strategies in landmark
selection, identifying their unique landmark categories (e.g., area
silhouettes, accessibility-related objects) and preferred landmark
augmentations. We then designed VisiMark, an AR interface that supports
landmark perception for PLV by providing both overviews of space structures and
in-situ landmark augmentations. We evaluated VisiMark with 16 PLV and found
that VisiMark enabled PLV to perceive landmarks they preferred but could not
easily perceive before, and changed PLV's landmark selection from only
visually-salient objects to cognitive landmarks that are more important and
meaningful. We further derive design considerations for AR-based landmark
augmentation systems for PLV.",http://arxiv.org/abs/2502.10561v1
Observer-Aware Probabilistic Planning Under Partial Observability,2025-02-14T21:41:04Z,"Salomé Lepers, Vincent Thomas, Olivier Buffet","In this article, we are interested in planning problems where the agent is
aware of the presence of an observer, and where this observer is in a partial
observability situation. The agent has to choose its strategy so as to optimize
the information transmitted by observations. Building on observer-aware Markov
decision processes (OAMDPs), we propose a framework to handle this type of
problems and thus formalize properties such as legibility, explicability and
predictability. This extension of OAMDPs to partial observability can not only
handle more realistic problems, but also permits considering dynamic hidden
variables of interest. These dynamic target variables allow, for instance,
working with predictability, or with legibility problems where the goal might
change during execution. We discuss theoretical properties of PO-OAMDPs and,
experimenting with benchmark problems, we analyze HSVI's convergence behavior
with dedicated initializations and study the resulting strategies.",http://arxiv.org/abs/2502.10568v1
"Tusqh: Topological Control of Volume-Fraction Meshes Near Small Features
  and Dirty Geometry",2025-02-14T23:54:48Z,"Brian Shawcroft, Kendrick M. Shepherd, Scott Mitchell","This work develops a framework to create meshes with user-specified homology
from potentially dirty geometry by coupling background grids, persistent
homology, and a generalization of volume fractions. For a mesh with fixed grid
size, the topology of the output mesh changes predictably and monotonically as
its volume-fraction threshold decreases. Topological anti-aliasing methods are
introduced to resolve pinch points and disconnected regions that are artifacts
of user choice of grid size and orientation, making the output meshes suitable
for downstream processes including analysis. The methodology is demonstrated on
geographical, mechanical, and graphics models in 2D and 3D using a custom-made
software called Tusqh. The work demonstrates that the proposed framework is
viable for generating meshes on topologically invalid geometries and for
automatic defeaturing of small geometric artifacts. Finally, the work shows
that although subdividing the background grid frequently improves the
topological and geometrical fidelity of the output mesh, there are simple 2D
examples for which the topology does not converge under refinement for
volume-fraction codes.",http://arxiv.org/abs/2502.10609v1
"Dynamic Influence Tracker: Measuring Time-Varying Sample Influence
  During Training",2025-02-15T13:24:21Z,"Jie Xu, Zihan Wu","Existing methods for measuring training sample influence on models only
provide static, overall measurements, overlooking how sample influence changes
during training. We propose Dynamic Influence Tracker (DIT), which captures the
time-varying sample influence across arbitrary time windows during training.
  DIT offers three key insights: 1) Samples show different time-varying
influence patterns, with some samples important in the early training stage
while others become important later. 2) Sample influences show a weak
correlation between early and late stages, demonstrating that the model
undergoes distinct learning phases with shifting priorities. 3) Analyzing
influence during the convergence period provides more efficient and accurate
detection of corrupted samples than full-training analysis. Supported by
theoretical guarantees without assuming loss convexity or model convergence,
DIT significantly outperforms existing methods, achieving up to 0.99
correlation with ground truth and above 98\% accuracy in detecting corrupted
samples in complex architectures.",http://arxiv.org/abs/2502.10793v1
"Quantum phase transitions in a Dicke trimer with both photon and atom
  hoppings",2025-02-15T16:03:48Z,"Jun-Wen Luo, Bo Wang, Ze-Liang Xiang","We investigate superradiant quantum phase transitions in a Dicke trimer model
consisting of two types of hoppings, i.e., photon hoppings and atom hoppings.
In the superradiant regime, the system can exist in two distinct phases: normal
and frustrated superradiant phases, which are governed by both types of
hoppings. Particularly, the interplay between these hoppings gives rise to
interesting effects, such as triggering superradiance with much lower coupling
strengths when both hoppings exhibit the same tendency. In contrast, with
opposite tendencies, the competition between hoppings leads to a first-order
phase transition between two different superradiant phases with translational
symmetry broken. These findings enable the system to undergo a sequence of
transitions across three phases by changing the coupling strength. Our work
provides deep insights into competing interactions and quantum phase
transitions in multi-cavity systems with geometric structures.",http://arxiv.org/abs/2502.10839v1
Accelerated co-design of robots through morphological pretraining,2025-02-15T17:20:56Z,"Luke Strgar, Sam Kriegman","The co-design of robot morphology and neural control typically requires using
reinforcement learning to approximate a unique control policy gradient for each
body plan, demanding massive amounts of training data to measure the
performance of each design. Here we show that a universal, morphology-agnostic
controller can be rapidly and directly obtained by gradient-based optimization
through differentiable simulation. This process of morphological pretraining
allows the designer to explore non-differentiable changes to a robot's physical
layout (e.g. adding, removing and recombining discrete body parts) and
immediately determine which revisions are beneficial and which are deleterious
using the pretrained model. We term this process ""zero-shot evolution"" and
compare it with the simultaneous co-optimization of a universal controller
alongside an evolving design population. We find the latter results in
diversity collapse, a previously unknown pathology whereby the population --
and thus the controller's training data -- converges to similar designs that
are easier to steer with a shared universal controller. We show that zero-shot
evolution with a pretrained controller quickly yields a diversity of highly
performant designs, and by fine-tuning the pretrained controller on the current
population throughout evolution, diversity is not only preserved but
significantly increased as superior performance is achieved.",http://arxiv.org/abs/2502.10862v1
"""Business on WhatsApp is tough now -- but am I really a businesswoman?""
  Exploring Challenges with Adapting to Changes in WhatsApp Business",2025-02-15T21:46:42Z,Ankolika De,"This study examines how WhatsApp has evolved from a personal communication
tool to a professional platform, focusing on its use by small business owners
in India. Initially embraced in smaller, rural communities for its ease of use
and familiarity, WhatsApp played a crucial role in local economies. However, as
Meta introduced WhatsApp Business with new, formalized features, users
encountered challenges in adapting to the more complex and costly platform.
Interviews with 14 small business owners revealed that while they adapted
creatively, they felt marginalized by the advanced tools. This research
contributes to HCI literature by exploring the transition from personal to
professional use and introduces the concept of Coercive Professionalization. It
highlights how standardization by large tech companies affects marginalized
users, exacerbating power imbalances and reinforcing digital colonialism,
concluding with design implications for supporting community-based
appropriations.",http://arxiv.org/abs/2502.10913v1
"Density-dependent spin susceptibility and effective mass in monolayer
  MoSe2",2025-02-16T03:23:16Z,"Chang Liu, Tongtong Jia, Zheng Sun, Yu Gu, Fan Xu, Kenji Watanabe, Takashi Taniguchi, Jinfeng Jia, Shiyong Wang, Xiaoxue Liu, Tingxin Li","Atomically thin MoSe2 is a promising platform for investigating quantum
phenomena due to its large effective mass, high crystal quality, and strong
spin-orbit coupling. In this work, we demonstrate a triple-gate device design
with bismuth contacts, enabling reliable ohmic contact down to low electron
densities, with a maximum Hall mobility of approximately 22,000 cm2/Vs.
Low-temperature transport measurements illustrate metal-insulator transitions,
and density-dependent quantum oscillation sequences. Enhanced spin
susceptibility and density-dependent effective mass are observed, attributed to
interaction effects and valley polarization. These findings establish monolayer
MoSe2 as a versatile platform for further exploring interaction-driven quantum
states.",http://arxiv.org/abs/2502.10972v1
"Streamlining the Collaborative Chain of Models into A Single Forward
  Pass in Generation-Based Tasks",2025-02-16T11:37:14Z,"Yuanjie Lyu, Chao Zhang, Yuhao Chen, Yong Chen, Tong Xu","In Retrieval-Augmented Generation (RAG) and agent-based frameworks, the
""Chain of Models"" approach is widely used, where multiple specialized models
work sequentially on distinct sub-tasks. This approach is effective but
increases resource demands as each model must be deployed separately. Recent
advancements attempt to address this by applying prompt tuning, which allows a
shared base model to adapt to multiple tasks with minimal parameter changes.
However, a key challenge remains: intermediate outputs, passed between models
as plain text, require recomputation of hidden states (i.e., Key and Value (KV)
states in Transformers) during inference. In this paper, we introduce FTHSS, a
novel prompt-tuning method that enables models to share KV hidden states,
eliminating redundant forward passes and reducing KV cache storage. By
modifying input and attention masks during training, FTHSS allows models to
effectively utilize KV hidden states from prior models in both single- and
multi-round scenarios. Empirical results on four tasks show that FTHSS matches
the performance of traditional model chains while improving inference
efficiency.",http://arxiv.org/abs/2502.11083v1
Parametric Analysis of Network Evolution Processes,2025-02-16T12:58:03Z,"Peter Williams, Zhan Chen","We present a comprehensive parametric analysis of node and edge lifetimes
processes in two large-scale collaboration networks: the Microsoft Academic
Graph (1800-2020) and Internet Movie Database (1900-2020). Node and edge
lifetimes (career and collaboration durations) follow Weibull distributions
with consistent shape parameters ($k \approx 0.2$ for academic, $k \approx 0.5$
for entertainment careers) across centuries of evolution. These distributions
persist despite dramatic changes in network size and structure. Edge processes
show domain-specific evolution: academic collaboration durations increase over
time (power-law index $1.6$ to $2.3$) while entertainment collaborations
maintain more stable patterns (index $2.6$ to $2.1$). These findings indicate
that while career longevity exhibits consistent patterns, collaboration
dynamics appear to be influenced by domain-specific factors. The results
provide new constraints for models of social network evolution, requiring
incorporation of both universal lifetime distributions and domain-specific
growth dynamics.",http://arxiv.org/abs/2502.11112v1
"Hierarchical Expert Prompt for Large-Language-Model: An Approach Defeat
  Elite AI in TextStarCraft II for the First Time",2025-02-16T13:36:31Z,"Zongyuan Li, Chang Lu, Xiaojie Xu, Runnan Qi, Yanan Ni, Lumin Jiang, Xiangbei Liu, Xuebo Zhang, Yongchun Fang, Kuihua Huang, Xian Guo","Since the emergence of the Large Language Model (LLM), LLM has been widely
used in fields such as writing, translating, and searching. However, there is
still great potential for LLM-based methods in handling complex tasks such as
decision-making in the StarCraft II environment. To address problems such as
lack of relevant knowledge and poor control over subtasks of varying
importance, we propose a Hierarchical Expert Prompt (HEP) for LLM. Our method
improves the understanding of game situations through expert-level tactical
knowledge, improving the processing quality of tasks of varying importance
through a hierarchical framework. Our approach defeated the highest level
(Elite) standard built-in agent in TextStarCraft II for the first time and
consistently outperformed the baseline method in other difficulties. Our
experiments suggest that the proposed method is a practical solution for
tackling complex decision-making challenges. The replay video can be viewed on
https://www.bilibili.com/video/BV1uz42187EF and https://youtu.be/dO3PshWLV5M,
and our codes have been open-sourced on
https://github.com/luchang1113/HEP-LLM-play-StarCraftII.",http://arxiv.org/abs/2502.11122v1
"Site-Decorated Model for Unconventional Frustrated Magnets with
  Ultranarrow Phase Crossover and Spin Reversal Transition",2025-02-16T21:10:42Z,Weiguo Yin,"The site-decorated Ising model is introduced to advance the understanding and
physical realization of the recently discovered one-dimensional
finite-temperature ultranarrow phase crossover in an external magnetic field,
overcoming the complexity of the traditional bond-decorated models from
geometric consideration. Furthermore, for higher-dimensional Ising models in
the presence of an external magnetic field, while they remain unsolved, an
exact solution about a novel spin-reversal transition -- accessible by a slight
change in temperature or the magnetic field, even in the weak field limit -- is
found to exist upon the site decoration. These results suggest a new route to
energy-efficient applications in, e.g., data storage and processing, and call
for materialization and device design with site decoration in, e.g., mixed
$d$-$f$ compounds, optical lattices, or neural networks.",http://arxiv.org/abs/2502.11270v1
"Targeting C99 Mediated Metabolic Disruptions with Ketone Therapy in
  Alzheimer's Disease",2025-02-17T03:25:46Z,"Hao Huang, Kaijing Xu, Michael Lardelli","INTRODUCTION: Alzheimer's disease (AD) involves neurodegeneration, metabolic
dysfunction, and proteostasis failure. While amyloid and tau pathology are well
studied, the role of metabolic dysregulation as an upstream driver remains
unclear.
  METHODS:We used Drosophila AD models expressing APP and BACE1 under the
neuron-specific driver, applying quantitative mass spectrometry (MS) to analyze
C99-induced proteomic changes and metabolic disruption. Additional biochemical
and imaging analyses were performed to assess mitochondrial function and
autophagy.
  RESULTS: C99 disrupted mitochondrial proteostasis, impairing TCA cycle
enzymes, fatty acid oxidation, and lysosomal clearance. Immunoprecipitation
confirmed C99's interaction with proteostasis regulators, leading to
neurodegenerative stress.
  DISCUSSION: Our findings extend previous models of AD pathogenesis by
demonstrating that C99 impairs lipid metabolism, disrupting ketone availability
and neuronal energy balance.",http://arxiv.org/abs/2502.11395v1
Does Editing Provide Evidence for Localization?,2025-02-17T05:09:46Z,"Zihao Wang, Victor Veitch","A basic aspiration for interpretability research in large language models is
to ""localize"" semantically meaningful behaviors to particular components within
the LLM. There are various heuristics for finding candidate locations within
the LLM. Once a candidate localization is found, it can be assessed by editing
the internal representations at the corresponding localization and checking
whether this induces model behavior that is consistent with the semantic
interpretation of the localization. The question we address here is: how strong
is the evidence provided by such edits? To evaluate the localization claim, we
want to assess the effect of the optimal intervention at a particular location.
The key new technical tool is a way of adapting LLM alignment techniques to
find such optimal localized edits. With this tool in hand, we give an example
where the edit-based evidence for localization appears strong, but where
localization clearly fails. Indeed, we find that optimal edits at random
localizations can be as effective as aligning the full model. In aggregate, our
results suggest that merely observing that localized edits induce targeted
changes in behavior provides little to no evidence that these locations
actually encode the target behavior.",http://arxiv.org/abs/2502.11447v2
"Semantically Robust Unsupervised Image Translation for Paired Remote
  Sensing Images",2025-02-17T05:57:57Z,"Sheng Fang, Kaiyu Li, Zhe Li, Jianli Zhao, Xingli Zhang","Image translation for change detection or classification in bi-temporal
remote sensing images is unique. Although it can acquire paired images, it is
still unsupervised. Moreover, strict semantic preservation in translation is
always needed instead of multimodal outputs. In response to these problems,
this paper proposes a new method, SRUIT (Semantically Robust Unsupervised
Image-to-image Translation), which ensures semantically robust translation and
produces deterministic output. Inspired by previous works, the method explores
the underlying characteristics of bi-temporal Remote Sensing images and designs
the corresponding networks. Firstly, we assume that bi-temporal Remote Sensing
images share the same latent space, for they are always acquired from the same
land location. So SRUIT makes the generators share their high-level layers, and
this constraint will compel two domain mapping to fall into the same latent
space. Secondly, considering land covers of bi-temporal images could evolve
into each other, SRUIT exploits the cross-cycle-consistent adversarial networks
to translate from one to the other and recover them. Experimental results show
that constraints of sharing weights and cross-cycle consistency enable
translated images with both good perceptual image quality and semantic
preservation for significant differences.",http://arxiv.org/abs/2502.11468v1
Effect of Numerically Controlled Oscillator Bit Width in Phase Meters,2025-02-17T09:51:12Z,"Yuan-Ze Jiang, Yu-Jie Feng, Liu-Yang Chen, Bai-Fu Lu, Qi Xia, Ze-Bing Zhou, Yu-Rong Liang","Projects aiming to detect gravitational waves (GWs) in space in the
millihertz range will utilize interferometers to measure the separations
between free-falling test masses. The phasemeter measures the phase changes of
the interference signals caused by the test masses' relative movements. The
measurement sensitivity of the phasemeter is one of the key factors in the
detection. In this work, we reviewed the core metrology of the phasemeter and
evaluated the ultra-low noise performance of the phasemeter with analog
signals. Frequency readout noise related to the bit width of the numerically
controlled oscillator (NCO) inside the phasemeter is identified as one of the
main noise sources of phase measurement theoretically and experimentally. After
increasing the NCO bit widths, the single-channel phase noise of the phasemeter
reached 2.0 {\mu}rad/Hz^{1/2} at 6 mHz, and the differential phase noise
reached 0.4 {\mu}rad/Hz^{1/2} at 6 mHz. The phase noise performances remained
consistent within the carrier frequency range of 4.9 MHz to 25.1 MHz.",http://arxiv.org/abs/2502.11608v1
"A Cholesky decomposition-based asset selection heuristic for sparse
  tangent portfolio optimization",2025-02-17T11:39:50Z,"Hyunglip Bae, Haeun Jeon, Minsu Park, Yongjae Lee, Woo Chang Kim","In practice, including large number of assets in mean-variance portfolios can
lead to higher transaction costs and management fees. To address this, one
common approach is to select a smaller subset of assets from the larger pool,
constructing more efficient portfolios. As a solution, we propose a new asset
selection heuristic which generates a pre-defined list of asset candidates
using a surrogate formulation and re-optimizes the cardinality-constrained
tangent portfolio with these selected assets. This method enables faster
optimization and effectively constructs portfolios with fewer assets, as
demonstrated by numerical analyses on historical stock returns. Finally, we
discuss a quantitative metric that can provide a initial assessment of the
performance of the proposed heuristic based on asset covariance.",http://arxiv.org/abs/2502.11701v1
"Component-aware Unsupervised Logical Anomaly Generation for Industrial
  Anomaly Detection",2025-02-17T11:54:43Z,"Xuan Tong, Yang Chang, Qing Zhao, Jiawen Yu, Boyang Wang, Junxiong Lin, Yuxuan Lin, Xinji Mai, Haoran Wang, Zeng Tao, Yan Wang, Wenqiang Zhang","Anomaly detection is critical in industrial manufacturing for ensuring
product quality and improving efficiency in automated processes. The scarcity
of anomalous samples limits traditional detection methods, making anomaly
generation essential for expanding the data repository. However, recent
generative models often produce unrealistic anomalies increasing false
positives, or require real-world anomaly samples for training. In this work, we
treat anomaly generation as a compositional problem and propose ComGEN, a
component-aware and unsupervised framework that addresses the gap in logical
anomaly generation. Our method comprises a multi-component learning strategy to
disentangle visual components, followed by subsequent generation editing
procedures. Disentangled text-to-component pairs, revealing intrinsic logical
constraints, conduct attention-guided residual mapping and model training with
iteratively matched references across multiple scales. Experiments on the
MVTecLOCO dataset confirm the efficacy of ComGEN, achieving the best AUROC
score of 91.2%. Additional experiments on the real-world scenario of Diesel
Engine and widely-used MVTecAD dataset demonstrate significant performance
improvements when integrating simulated anomalies generated by ComGEN into
automated production workflows.",http://arxiv.org/abs/2502.11712v1
"Bi-invariant Geodesic Regression with Data from the Osteoarthritis
  Initiative",2025-02-17T14:20:54Z,"Johannes Schade, Christoph von Tycowicz, Martin Hanik","Many phenomena are naturally characterized by measuring continuous
transformations such as shape changes in medicine or articulated systems in
robotics. Modeling the variability in such datasets requires performing
statistics on Lie groups, that is, manifolds carrying an additional group
structure. As the Lie group captures the symmetries in the data, it is
essential from a theoretical and practical perspective to ask for statistical
methods that respect these symmetries; this way they are insensitive to
confounding effects, e.g., due to the choice of reference coordinate systems.
In this work, we investigate geodesic regression -- a generalization of linear
regression originally derived for Riemannian manifolds. While Lie groups can be
endowed with Riemannian metrics, these are generally incompatible with the
group structure. We develop a non-metric estimator using an affine connection
setting. It captures geodesic relationships respecting the symmetries given by
left and right translations. For its computation, we propose an efficient fixed
point algorithm requiring simple differential expressions that can be
calculated through automatic differentiation. We perform experiments on a
synthetic example and evaluate our method on an open-access, clinical dataset
studying knee joint configurations under the progression of osteoarthritis.",http://arxiv.org/abs/2502.11826v1
Pulse Compression by an Optical Push Broom On a Chip,2025-02-17T15:19:57Z,"Boyi Zhang, Maurice Pfeiffer, Mahmoud A. Gaafar, He Li, Xinlun Cai, Juntao Li, Manfred Eich, Alexander Yu. Petrov","In this study, we report a first experimental demonstration of pulse
compression by a gradual refractive index front moving in a periodically
modulated silicon waveguide, the so-called optical push broom effect. Optical
push broom captures and confines the input signal pulse in a faster propagating
refractive index front, driven by a pump pulse. This is a spatio-temporal
analogue of light trapping in a tapered plasmonic waveguide where light is
continuously changing its wavevector approaching zero group velocity and, thus,
stopped without reflection. Here the signal is accelerated by the front until
the signal velocity matches the front velocity, thus stopping the light in
respect to the front. We employ the slowly varying envelope approximation to
model this phenomenon. Notably, we well reproduced the experimental frequency
shift at the output corresponding to the temporal delay at the input.",http://arxiv.org/abs/2502.11892v1
"Reconfigurable Intelligent Surfaces-Assisted Integrated Access and
  Backhaul",2025-02-17T16:46:15Z,"Charitha Madapatha, Behrooz Makki, Hao Guo, Tommy Svensson","In this paper, we study the impact of reconfigurable intelligent surfaces
(RISs) on the coverage extension of integrated access and backhaul (IAB)
networks. Particularly, using a finite stochastic geometry model, with random
distributions of user equipments (UEs) in a finite region, and planned
hierachical architecture for IAB, we study the service coverage probability
defined as the probability of the event that the UEs' minimum rate requirements
are satisfied. We present comparisons between different cases including
IAB-only, IAB assisted with RIS for backhaul as well as IAB assisted by network
controlled repeaters (NCRs). Our investigations focus on wide-area IAB assisted
with RIS through the lens of different design architectures and deployments,
revealing both conflicts and synergies for minimizing the effect of tree
foliage over seasonal changes. Our simulation results reveal both opportunities
and challenges towards the implementation of RIS in IAB.",http://arxiv.org/abs/2502.12011v1
Culture is Not Trivia: Sociocultural Theory for Cultural NLP,2025-02-17T17:25:11Z,"Naitian Zhou, David Bamman, Isaac L. Bleaman","The field of cultural NLP has recently experienced rapid growth, driven by a
pressing need to ensure that language technologies are effective and safe
across a pluralistic user base. This work has largely progressed without a
shared conception of culture, instead choosing to rely on a wide array of
cultural proxies. However, this leads to a number of recurring limitations:
coarse national boundaries fail to capture nuanced differences that lay within
them, limited coverage restricts datasets to only a subset of usually
highly-represented cultures, and a lack of dynamicity results in static
cultural benchmarks that do not change as culture evolves. In this position
paper, we argue that these methodological limitations are symptomatic of a
theoretical gap. We draw on a well-developed theory of culture from
sociocultural linguistics to fill this gap by 1) demonstrating in a case study
how it can clarify methodological constraints and affordances, 2) offering
theoretically-motivated paths forward to achieving cultural competence, and 3)
arguing that localization is a more useful framing for the goals of much
current work in cultural NLP.",http://arxiv.org/abs/2502.12057v1
Optimal Brain Iterative Merging: Mitigating Interference in LLM Merging,2025-02-17T09:07:49Z,"Zhixiang Wang, Zhenyu Mao, Yixuan Qiao, Yunfang Wu, Biye Li","Large Language Models (LLMs) have demonstrated impressive capabilities, but
their high computational costs pose challenges for customization. Model merging
offers a cost-effective alternative, yet existing methods suffer from
interference among parameters, leading to performance degradation. In this
work, we propose Optimal Brain Iterative Merging (OBIM), a novel method
designed to mitigate both intra-model and inter-model interference. OBIM
consists of two key components: (1) A saliency measurement mechanism that
evaluates parameter importance based on loss changes induced by individual
weight alterations, reducing intra-model interference by preserving only
high-saliency parameters. (2) A mutually exclusive iterative merging framework,
which incrementally integrates models using a binary mask to avoid direct
parameter averaging, thereby mitigating inter-model interference. We validate
OBIM through experiments on both Supervised Fine-Tuned (SFT) models and
post-pretrained checkpoints. The results show that OBIM significantly
outperforms existing merging techniques. Overall, OBIM provides an effective
and practical solution for enhancing LLM merging.",http://arxiv.org/abs/2502.12217v1
Multi-dimensional Test Design,2025-02-17T19:03:39Z,"Xiaoyun Qiu, Liren Shan","How should one jointly design tests and the arrangement of agencies to
administer these tests (testing procedure)? To answer this question, we analyze
a model where a principal must use multiple tests to screen an agent with a
multi-dimensional type, knowing that the agent can change his type at a cost.
We identify a new tradeoff between setting difficult tests and using a
difficult testing procedure. We compare two settings: (1) the agent only
misrepresents his type (manipulation) and (2) the agent improves his actual
type (investment). Examples include interviews, regulations, and data
classification. We show that in the manipulation setting, stringent tests
combined with an easy procedure, i.e., offering tests sequentially in a fixed
order, is optimal. In contrast, in the investment setting, non-stringent tests
with a difficult procedure, i.e., offering tests simultaneously, is optimal;
however, under mild conditions offering them sequentially in a random order may
be as good. Our results suggest that whether the agent manipulates or invests
in his type determines which arrangement of agencies is optimal.",http://arxiv.org/abs/2502.12264v1
"Asymptotic safety, quantum gravity, and the swampland: a conceptual
  assessment",2025-02-17T20:00:06Z,"Ivano Basile, Benjamin Knorr, Alessia Platania, Marc Schiffer","We provide a conceptual assessment of some aspects of fundamental quantum
field theories of gravity in light of foundational aspects of the swampland
program. On the one hand, asymptotically safe quantum gravity may provide a
simple and predictive framework, thanks to a finite number of relevant
parameters. On the other hand, a (sub-)set of intertwined swampland conjectures
on the consistency of quantum gravity can be argued to be universal via
effective field theory considerations. We answer whether some foundational
features of these frameworks are compatible. This involves revisiting and
refining several arguments (and loopholes) concerning the relation between
field-theoretic descriptions of gravity and general swampland ideas. We
identify the thermodynamics of black holes, spacetime topology change, and
holography as the core aspects of this relation. We draw lessons on the
features that a field theoretic description of gravity must (not) have to be
consistent with fundamental principles underlying the swampland program, and on
the universality of the latter.",http://arxiv.org/abs/2502.12290v1
Sensing-based Robustness Challenges in Agricultural Robotic Harvesting,2025-02-18T00:32:32Z,"C. Beldek, J. Cunningham, M. Aydin, E. Sariyildiz, S. L. Phung, G. Alici","This paper presents the challenges agricultural robotic harvesters face in
detecting and localising fruits under various environmental disturbances. In
controlled laboratory settings, both the traditional HSV (Hue Saturation Value)
transformation and the YOLOv8 (You Only Look Once) deep learning model were
employed. However, only YOLOv8 was utilised in outdoor experiments, as the HSV
transformation was not capable of accurately drawing fruit contours.
Experiments include ten distinct fruit patterns with six apples and six
oranges. A grid structure for homography (perspective) transformation was
employed to convert detected midpoints into 3D world coordinates. The
experiments evaluated detection and localisation under varying lighting and
background disturbances, revealing accurate performance indoors, but
significant challenges outdoors. Our results show that indoor experiments using
YOLOv8 achieved 100% detection accuracy, while outdoor conditions decreased
performance, with an average accuracy of 69.15% for YOLOv8 under direct
sunlight. The study demonstrates that real-world applications reveal
significant limitations due to changing lighting, background disturbances, and
colour and shape variability. These findings underscore the need for further
refinement of algorithms and sensors to enhance the robustness of robotic
harvesters for agricultural use.",http://arxiv.org/abs/2502.12403v1
Impurity-induced non-unitary criticality,2025-02-18T02:56:51Z,"Heng-Hsi Li, Kuang-Hung Chou, Xueda Wen, Po-Yao Chang","Quantum impurities give rise to rich physical phenomena, with some exhibiting
critical behavior described by conformal field theories (CFTs) in the
low-energy limit. In parallel, party-time ($\mathcal{PT}$) symmetric
non-Hermitian systems host exceptional points (EPs) at criticality, leading to
exotic features governed by non-unitary CFTs. Here, we establish a connection
between non-Hermitian impurities and CFTs by demonstrating that the critical
properties of a (1+1)-dimensional free-fermion chain with central charge $c=1$
can be drastically altered by the presence of a local non-Hermitian impurity.
Through a systematic analysis of entanglement/R\'enyi entropy, the finite-size
scaling of the many-body spectrum, and fidelity susceptibility, we identify
that this impurity-induced non-Hermitian criticality is characterized by a
non-unitary CFT with central charge $c=-2$. Furthermore, we find that these
non-unitary critical properties exhibit strong sensitivity to boundary
conditions.",http://arxiv.org/abs/2502.12469v1
Ultrasound measurement technique for the single-turn-coil magnets,2025-02-18T04:37:59Z,"T. Nomura, A. Hauspurg, D. I. Gorbunov, A. Miyata, E. Schulze, S. A. Zvyagin, V. Tsurkan, Y. H. Matsuda, Y. Kohama, S. Zherlitsyn","Ultrasound is a powerful means to study numerous phenomena of
condensed-matter physics as acoustic waves couple strongly to structural,
magnetic, orbital, and charge degrees of freedom. In this paper, we present
such technique combined with single-turn coils (STC) which generate magnetic
fields beyond 100 T with the typical pulse duration of 6 us. As a benchmark of
this technique, the ultrasound results for MnCr2S4, Cu6[Si6O18]6H2O, and liquid
oxygen are shown. The resolution for the relative sound-velocity change in the
STC is estimated as Delta v/v~10^-3, which is sufficient to study various
field-induced phase transitions and critical phenomena.",http://arxiv.org/abs/2502.12533v1
An Algorithm Board in Neural Decoding,2025-02-18T04:39:35Z,"Jingyi Feng, Kai Yang","Understanding the mechanisms of neural encoding and decoding has always been
a highly interesting research topic in fields such as neuroscience and
cognitive intelligence. In prior studies, some researchers identified a
symmetry in neural data decoded by unsupervised methods in motor scenarios and
constructed a cognitive learning system based on this pattern (i.e., symmetry).
Nevertheless, the distribution state of the data flow that significantly
influences neural decoding positions still remains a mystery within the system,
which further restricts the enhancement of the system's interpretability. Based
on this, this paper mainly explores changes in the distribution state within
the system from the machine learning and mathematical statistics perspectives.
In the experiment, we assessed the correctness of this symmetry using various
tools and indicators commonly utilized in mathematics and statistics. According
to the experimental results, the normal distribution (or Gaussian distribution)
plays a crucial role in the decoding of prediction positions within the system.
Eventually, an algorithm board similar to the Galton board was built to serve
as the mathematical foundation of the discovered symmetry.",http://arxiv.org/abs/2502.12536v1
"RM-PoT: Reformulating Mathematical Problems and Solving via Program of
  Thoughts",2025-02-18T06:54:32Z,"Yu Zhang, Shujun Peng, Nengwu Wu, Xinhan Lin, Yang Hu, Jie Tang","Recently, substantial advancements have been made in training language models
to carry out step-by-step reasoning for solving intricate numerical reasoning
tasks. Beyond the methods used to solve these problems, the structure and
formulation of the problems themselves also play a crucial role in determining
the performance of large language models. We observe that even small changes in
the surface form of mathematical problems can have a profound impact on both
the answer distribution and solve rate. This highlights the vulnerability of
LLMs to surface-level variations, revealing its limited robustness when
reasoning through complex problems. In this paper, we propose RM-PoT, a
three-stage framework that integrates problem reformulation (RM), code-aided
reasoning (PoT), and domain-aware few-shot learning to address these
limitations. Our approach first reformulates the input problem into diverse
surface forms to reduce structural bias, then retrieves five semantically
aligned examples from a pre-constructed domain-specific question bank to
provide contextual guidance, and finally generates executable Python code for
precise computation.",http://arxiv.org/abs/2502.12589v1
"Generalized Kernel Inducing Points by Duality Gap for Dataset
  Distillation",2025-02-18T07:43:13Z,"Tatsuya Aoyama, Hanting Yang, Hiroyuki Hanada, Satoshi Akahane, Tomonari Tanaka, Yoshito Okura, Yu Inatsu, Noriaki Hashimoto, Taro Murayama, Hanju Lee, Shinya Kojima, Ichiro Takeuchi","We propose Duality Gap KIP (DGKIP), an extension of the Kernel Inducing
Points (KIP) method for dataset distillation. While existing dataset
distillation methods often rely on bi-level optimization, DGKIP eliminates the
need for such optimization by leveraging duality theory in convex programming.
The KIP method has been introduced as a way to avoid bi-level optimization;
however, it is limited to the squared loss and does not support other loss
functions (e.g., cross-entropy or hinge loss) that are more suitable for
classification tasks. DGKIP addresses this limitation by exploiting an upper
bound on parameter changes after dataset distillation using the duality gap,
enabling its application to a wider range of loss functions. We also
characterize theoretical properties of DGKIP by providing upper bounds on the
test error and prediction consistency after dataset distillation. Experimental
results on standard benchmarks such as MNIST and CIFAR-10 demonstrate that
DGKIP retains the efficiency of KIP while offering broader applicability and
robust performance.",http://arxiv.org/abs/2502.12607v1
"Perovskite-LLM: Knowledge-Enhanced Large Language Models for Perovskite
  Solar Cell Research",2025-02-18T09:19:24Z,"Xiang Liu, Penglei Sun, Shuyan Chen, Longhan Zhang, Peijie Dong, Huajie You, Yongqi Zhang, Chang Yan, Xiaowen Chu, Tong-yi Zhang","The rapid advancement of perovskite solar cells (PSCs) has led to an
exponential growth in research publications, creating an urgent need for
efficient knowledge management and reasoning systems in this domain. We present
a comprehensive knowledge-enhanced system for PSCs that integrates three key
components. First, we develop Perovskite-KG, a domain-specific knowledge graph
constructed from 1,517 research papers, containing 23,789 entities and 22,272
relationships. Second, we create two complementary datasets: Perovskite-Chat,
comprising 55,101 high-quality question-answer pairs generated through a novel
multi-agent framework, and Perovskite-Reasoning, containing 2,217 carefully
curated materials science problems. Third, we introduce two specialized large
language models: Perovskite-Chat-LLM for domain-specific knowledge assistance
and Perovskite-Reasoning-LLM for scientific reasoning tasks. Experimental
results demonstrate that our system significantly outperforms existing models
in both domain-specific knowledge retrieval and scientific reasoning tasks,
providing researchers with effective tools for literature review, experimental
design, and complex problem-solving in PSC research.",http://arxiv.org/abs/2502.12669v1
"RadSplatter: Extending 3D Gaussian Splatting to Radio Frequencies for
  Wireless Radiomap Extrapolation",2025-02-18T09:44:38Z,"Yiheng Wang, Ye Xue, Shutao Zhang, Tsung-Hui Chang","A radiomap represents the spatial distribution of wireless signal strength,
critical for applications like network optimization and autonomous driving.
However, constructing radiomap relies on measuring radio signal power across
the entire system, which is costly in outdoor environments due to large network
scales. We present RadSplatter, a framework that extends 3D Gaussian Splatting
(3DGS) to radio frequencies for efficient and accurate radiomap extrapolation
from sparse measurements. RadSplatter models environmental scatterers and radio
paths using 3D Gaussians, capturing key factors of radio wave propagation. It
employs a relaxed-mean (RM) scheme to reparameterize the positions of 3D
Gaussians from noisy and dense 3D point clouds. A camera-free 3DGS-based
projection is proposed to map 3D Gaussians onto 2D radio beam patterns.
Furthermore, a regularized loss function and recursive fine-tuning using highly
structured sparse measurements in real-world settings are applied to ensure
robust generalization. Experiments on synthetic and real-world data show
state-of-the-art extrapolation accuracy and execution speed.",http://arxiv.org/abs/2502.12686v1
CausalMan: A physics-based simulator for large-scale causality,2025-02-18T10:20:22Z,"Nicholas Tagliapietra, Juergen Luettin, Lavdim Halilaj, Moritz Willig, Tim Pychynski, Kristian Kersting","A comprehensive understanding of causality is critical for navigating and
operating within today's complex real-world systems. The absence of realistic
causal models with known data generating processes complicates fair
benchmarking. In this paper, we present the CausalMan simulator, modeled after
a real-world production line. The simulator features a diverse range of linear
and non-linear mechanisms and challenging-to-predict behaviors, such as
discrete mode changes. We demonstrate the inadequacy of many state-of-the-art
approaches and analyze the significant differences in their performance and
tractability, both in terms of runtime and memory complexity. As a
contribution, we will release the CausalMan large-scale simulator. We present
two derived datasets, and perform an extensive evaluation of both.",http://arxiv.org/abs/2502.12707v1
"FedHC: A Hierarchical Clustered Federated Learning Framework for
  Satellite Networks",2025-02-18T11:44:09Z,"Zhuocheng Liu, Zhishu Shen, Pan Zhou, Qiushi Zheng, Jiong Jin","With the proliferation of data-driven services, the volume of data that needs
to be processed by satellite networks has significantly increased. Federated
learning (FL) is well-suited for big data processing in distributed,
resource-constrained satellite environments. However, ensuring its convergence
performance while minimizing processing time and energy consumption remains a
challenge. To this end, we propose a hierarchical clustered federated learning
framework, FedHC. This framework employs a satellite-clustered parameter server
(PS) selection algorithm at the cluster aggregation stage, grouping nearby
satellites into distinct clusters and designating a cluster center as the PS to
accelerate model aggregation. Several communicable cluster PS satellites are
then selected through ground stations to aggregate global parameters,
facilitating the FL process. Moreover, a meta-learning-driven satellite
re-clustering algorithm is introduced to enhance adaptability to dynamic
satellite cluster changes. The extensive experiments on satellite networks
testbed demonstrate that FedHC can significantly reduce processing time (up to
3x) and energy consumption (up to 2x) compared to other comparative methods
while maintaining model accuracy.",http://arxiv.org/abs/2502.12783v1
"Reasoning and the Trusting Behavior of DeepSeek and GPT: An Experiment
  Revealing Hidden Fault Lines in Large Language Models",2025-02-18T12:46:18Z,"Rubing Li, João Sedoc, Arun Sundararajan","When encountering increasingly frequent performance improvements or cost
reductions from a new large language model (LLM), developers of applications
leveraging LLMs must decide whether to take advantage of these improvements or
stay with older tried-and-tested models. Low perceived switching frictions can
lead to choices that do not consider more subtle behavior changes that the
transition may induce. Our experiments use a popular game-theoretic behavioral
economics model of trust to show stark differences in the trusting behavior of
OpenAI's and DeepSeek's models. We highlight a collapse in the economic trust
behavior of the o1-mini and o3-mini models as they reconcile profit-maximizing
and risk-seeking with future returns from trust, and contrast it with
DeepSeek's more sophisticated and profitable trusting behavior that stems from
an ability to incorporate deeper concepts like forward planning and
theory-of-mind. As LLMs form the basis for high-stakes commercial systems, our
results highlight the perils of relying on LLM performance benchmarks that are
too narrowly defined and suggest that careful analysis of their hidden fault
lines should be part of any organization's AI strategy.",http://arxiv.org/abs/2502.12825v2
A Survey of Text Classification Under Class Distribution Shift,2025-02-18T15:46:54Z,"Adriana Valentina Costache, Silviu Florin Gheorghe, Eduard Gabriel Poesina, Paul Irofti, Radu Tudor Ionescu","The basic underlying assumption of machine learning (ML) models is that the
training and test data are sampled from the same distribution. However, in
daily practice, this assumption is often broken, i.e.~the distribution of the
test data changes over time, which hinders the application of conventional ML
models. One domain where the distribution shift naturally occurs is text
classification, since people always find new topics to discuss. To this end, we
survey research articles studying open-set text classification and related
tasks. We divide the methods in this area based on the constraints that define
the kind of distribution shift and the corresponding problem formulation,
i.e.~learning with the Universum, zero-shot learning, and open-set learning. We
next discuss the predominant mitigation approaches for each problem setup.
Finally, we identify several future work directions, aiming to push the
boundaries beyond the state of the art. Interestingly, we find that continual
learning can solve many of the issues caused by the shifting class
distribution. We maintain a list of relevant papers at
https://github.com/Eduard6421/Open-Set-Survey.",http://arxiv.org/abs/2502.12965v1
"Recurrence threshold selection for obtaining robust recurrence
  characteristics in different embedding dimensions",2025-02-18T16:49:22Z,"K. Hauke Kraemer, Reik V. Donner, Jobst Heitzig, Norbert Marwan","The appropriate selection of recurrence thresholds is a key problem in
applications of recurrence quantification analysis and related methods across
disciplines. Here, we discuss the distribution of pairwise distances between
state vectors in the studied system's state space reconstructed by means of
time-delay embedding as the key characteristic that should guide the
corresponding choice for obtaining an adequate resolution of a recurrence plot.
Specifically, we present an empirical description of the distance distribution,
focusing on characteristic changes of its shape with increasing embedding
dimension. Our results suggest that selecting the recurrence threshold
according to a fixed percentile of this distribution reduces the dependence of
recurrence characteristics on the embedding dimension in comparison with other
commonly used threshold selection methods. Numerical investigations on some
paradigmatic model systems with time-dependent parameters support these
empirical findings.",http://arxiv.org/abs/2502.13036v1
"Hardy--Littlewood maximal operators on certain manifolds with bounded
  geometry",2025-02-18T18:22:20Z,"Stefano Meda, Stefano Pigola, Alberto G. Setti, Giona Veronelli","In this paper we study the $L^p$ boundedness of the centred and the uncentred
Hardy--Littlewood maximal operators on certain Riemannian manifolds with
bounded geometry. Our results complement those of various authors. We show
that, under mild assumptions, $L^p$ estimates for the centred operator are
``stable'' under conformal changes of the metric, and prove sharp~$L^p$
estimates for the centred operator on Riemannian models with pinched negative
scalar curvature. Furthermore, we prove that the centred operator is of weak
type $(1,1)$ on the connected sum of two space forms with negative curvature,
whereas the uncentred operator is, perhaps surprisingly, bounded only on
$L^\infty$. We also prove that if two locally doubling geodesic metric measure
spaces enjoying the uniform ball size condition are strictly quasi-isometric,
then they share the same boundedness properties for both the centred and the
uncentred maximal operator. Finally, we discuss some $L^p$ mapping properties
for the centred operator on a specific Riemannian surface introduced by
Str\""omberg, providing new interesting results.",http://arxiv.org/abs/2502.13109v1
"Global Well-Posedness of a Nonlinear Fokker-Planck Type Model of Grain
  Growth",2025-02-12T19:06:31Z,"Batuhan Bayir, Yekaterina Epshteyn, William M Feldman","Most technologically useful materials spanning multiple length scales are
polycrystalline. Polycrystalline microstructures are composed of a myriad of
small crystals or grains with different lattice orientations which are
separated by interfaces or grain boundaries. The changes in the grain and grain
boundary structure of polycrystals highly influence the materials properties
including, but not limited to, electrical, mechanical, and thermal. Thus, an
understanding of how microstructures evolve is essential for the engineering of
new materials. In this paper, we consider a recently introduced nonlinear
Fokker-Planck-type system and establish a global well-posedness result for it.
Such systems under specific energy laws emerge in the modeling of the grain
boundary dynamics in polycrystals.",http://arxiv.org/abs/2502.13151v1
"Wormholes in finite cutoff JT gravity: A study of baby universes and
  (Krylov) complexity",2025-02-18T19:00:02Z,"Arpan Bhattacharyya, Saptaswa Ghosh, Sounak Pal, Anandu Vinod","In this paper, as an application of the `Complexity = Volume' proposal, we
calculate the growth of the interior of a black hole at late times for finite
cutoff JT gravity. Due to this integrable, irrelevant deformation, the spectral
properties are modified non-trivially. The Einstein-Rosen Bridge (ERB) length
saturates faster than pure JT gravity. We comment on the possible connection
between Krylov Complexity and ERB length for deformed theory. Apart from this,
we calculate the emission probability of baby universes for the deformed theory
and make remarks on its implications for the ramp of the Spectral Form Factor.
Finally, we compute the correction to the volume of the moduli space due to the
non-perturbative change of the spectral curve because of the finite cutoff at
the boundary.",http://arxiv.org/abs/2502.13208v1
"Probing Structural Dynamics in Photocatalytic Water Splitting: X-ray vs.
  Neutron Scattering",2025-02-18T19:28:22Z,Zhihao Shen,"Photocatalytic water splitting represents a pivotal pathway for converting
solar energy into chemical energy, with the core challenge lying in the design
and optimization of photocatalysts [1] . TiO2, as a quintessential
photocatalytic material, undergoes significant alterations in its electronic
and crystalline structures under intense light irradiation, which may directly
impacts its photocatalytic efficiency [2] . To gain a profound understanding of
these transformations, in situ characterization techniques such as X-ray
scattering and neutron scattering have emerged as crucial tools. This paper,
from a combined perspective of theoretical computation and experimental
characterization, explores the differential capabilities of X-ray scattering
and neutron scattering in characterizing the pair distribution function (PDF)
of materials during photocatalytic water splitting. Furthermore, through
simulation calculations, it aims to unveil the changes in the electronic and
crystalline structures under intense light irradiation. This initial draft of
the paper is subject to subsequent revisions.",http://arxiv.org/abs/2502.13253v1
"BoundPlanner: A convex-set-based approach to bounded manipulator
  trajectory planning",2025-02-18T21:16:11Z,"Thies Oelerich, Christian Hartl-Nesic, Florian Beck, Andreas Kugi","Online trajectory planning enables robot manipulators to react quickly to
changing environments or tasks. Many robot trajectory planners exist for known
environments but are often too slow for online computations. Current methods in
online trajectory planning do not find suitable trajectories in challenging
scenarios that respect the limits of the robot and account for collisions. This
work proposes a trajectory planning framework consisting of the novel Cartesian
path planner based on convex sets, called BoundPlanner, and the online
trajectory planner BoundMPC. BoundPlanner explores and maps the collision-free
space using convex sets to compute a reference path with bounds. BoundMPC is
extended in this work to handle convex sets for path deviations, which allows
the robot to optimally follow the path within the bounds while accounting for
the robot's kinematics. Collisions of the robot's kinematic chain are
considered by a novel convex-set-based collision avoidance formulation
independent on the number of obstacles. Simulations and experiments with a
7-DoF manipulator show the performance of the proposed planner compared to
state-of-the-art methods. The source code is available at
github.com/Thieso/BoundPlanner and videos of the experiments can be found at
www.acin.tuwien.ac.at/42d4",http://arxiv.org/abs/2502.13286v1
"Capturing Human Cognitive Styles with Language: Towards an Experimental
  Evaluation Paradigm",2025-02-18T23:08:15Z,"Vasudha Varadarajan, Syeda Mahwish, Xiaoran Liu, Julia Buffolino, Christian C. Luhmann, Ryan L. Boyd, H. Andrew Schwartz","While NLP models often seek to capture cognitive states via language, the
validity of predicted states is determined by comparing them to annotations
created without access the cognitive states of the authors. In behavioral
sciences, cognitive states are instead measured via experiments. Here, we
introduce an experiment-based framework for evaluating language-based cognitive
style models against human behavior. We explore the phenomenon of decision
making, and its relationship to the linguistic style of an individual talking
about a recent decision they made. The participants then follow a classical
decision-making experiment that captures their cognitive style, determined by
how preferences change during a decision exercise. We find that language
features, intended to capture cognitive style, can predict participants'
decision style with moderate-to-high accuracy (AUC ~ 0.8), demonstrating that
cognitive style can be partly captured and revealed by discourse patterns.",http://arxiv.org/abs/2502.13326v1
"Reflection of Episodes: Learning to Play Game from Expert and Self
  Experiences",2025-02-19T02:53:43Z,"Xiaojie Xu, Zongyuan Li, Chang Lu, Runnan Qi, Yanan Ni, Lumin Jiang, Xiangbei Liu, Xuebo Zhang, Yongchun Fang, Kuihua Huang, Xian Guo, Zhanghua Wu, Zhenya Li","StarCraft II is a complex and dynamic real-time strategy (RTS) game
environment, which is very suitable for artificial intelligence and
reinforcement learning research. To address the problem of Large Language
Model(LLM) learning in complex environments through self-reflection, we propose
a Reflection of Episodes(ROE) framework based on expert experience and
self-experience. This framework first obtains key information in the game
through a keyframe selection method, then makes decisions based on expert
experience and self-experience. After a game is completed, it reflects on the
previous experience to obtain new self-experience. Finally, in the experiment,
our method beat the robot under the Very Hard difficulty in TextStarCraft II.
We analyze the data of the LLM in the process of the game in detail, verified
its effectiveness.",http://arxiv.org/abs/2502.13388v1
"CipherGuard: Compiler-aided Mitigation against Ciphertext Side-channel
  Attacks",2025-02-19T03:22:36Z,"Ke Jiang, Sen Deng, Yinshuai Li, Shuai Wang, Tianwei Zhang, Yinqian Zhang","Cryptographic implementations bolster security against timing side-channel
attacks by integrating constant-time components. However, the new ciphertext
side channels resulting from the deterministic memory encryption in Trusted
Execution Environments (TEEs), enable ciphertexts to manifest identifiable
patterns when being sequentially written to the same memory address. Attackers
with read access to encrypted memory in TEEs can potentially deduce plaintexts
by analyzing these changing ciphertext patterns.
  In this paper, we design CipherGuard, a compiler-aided mitigation methodology
to counteract ciphertext side channels with high efficiency and security.
CipherGuard is based on the LLVM ecosystem, and encompasses multiple mitigation
strategies, including software-based probabilistic encryption and secret-aware
register allocation. Through a comprehensive evaluation, we demonstrate that
CipherGuard can strengthen the security of various cryptographic
implementations more efficiently than existing state-of-the-art defense
mechanism, i.e., CipherFix.",http://arxiv.org/abs/2502.13401v1
Relaxation Critical Dynamics in Measurement-induced Phase Transitions,2025-02-19T03:39:47Z,"Wantao Wang, Shuo Liu, Jiaqiang Li, Shi-Xin Zhang, Shuai Yin","Measurement-induced phase transition (MIPT) describes the nonanalytical
change of the entanglement entropy resulting from the interplay between
measurement and unitary evolution. In this paper, we investigate the relaxation
critical dynamics near the MIPT for different initial states in a
one-dimensional quantum circuit. Specifically, when the initial state is in the
volume-law phase with vanishing measurement probability, we find that the
half-chain entanglement entropy $S$ decays as $S\propto t^{-1}$ with the
coefficients proportional to the size of the system in the short-time stage; In
contrast, when the initial state is the product state, $S$ increases with time
as $S\propto \ln{t}$, consistent with previous studies. Despite these
contrasting behaviors, we develop a unified scaling form to describe these
scaling behaviors for different initial states where the off-critical-point
effects can also be incorporated. This framework offers significant advantages
for experimental MIPT detection. Our novel scheme, leveraging relaxation
dynamical scaling, drastically reduces post-selection overhead, and can
eliminate it completely with trackable classical simulation.",http://arxiv.org/abs/2502.13408v1
MATS: An Audio Language Model under Text-only Supervision,2025-02-19T05:07:56Z,"Wen Wang, Ruibing Hou, Hong Chang, Shiguang Shan, Xilin Chen","Large audio-language models (LALMs), built upon powerful Large Language
Models (LLMs), have exhibited remarkable audio comprehension and reasoning
capabilities. However, the training of LALMs demands a large corpus of
audio-language pairs, which requires substantial costs in both data collection
and training resources. In this paper, we propose MATS, an audio-language
multimodal LLM designed to handle Multiple Audio task using solely Text-only
Supervision. By leveraging pre-trained audio-language alignment models such as
CLAP, we develop a text-only training strategy that projects the shared
audio-language latent space into LLM latent space, endowing the LLM with audio
comprehension capabilities without relying on audio data during training. To
further bridge the modality gap between audio and language embeddings within
CLAP, we propose the Strongly-related noisy text with audio (Santa) mechanism.
Santa maps audio embeddings into CLAP language embedding space while preserving
essential information from the audio input. Extensive experiments demonstrate
that MATS, despite being trained exclusively on text data, achieves competitive
performance compared to recent LALMs trained on large-scale audio-language
pairs.",http://arxiv.org/abs/2502.13433v2
Cloth Animation with Time-dependent Persistent Wrinkles,2025-02-19T07:24:44Z,"Deshan Gong, Yin Yang, Tianjia Shao, He Wang","Persistent wrinkles are often observed on crumpled garments e.g., the
wrinkles around the knees after sitting for a while. Such wrinkles can be
easily recovered if not deformed for long, and otherwise be persistent. Since
they are vital to the visual realism of cloth animation, we aim to simulate
realistic looking persistent wrinkles. To this end, we present a
physics-inspired fine-grained wrinkle model. Different from existing methods,
we recognize the importance of the interplay between internal friction and
plasticity during wrinkle formation. Furthermore, we model their time
dependence for persistent wrinkles. Our model is capable of not only simulating
realistic wrinkle patterns, but also their time-dependent changes according to
how long the deformation is maintained. Through extensive experiments, we show
that our model is effective in simulating realistic spatial and temporal
varying wrinkles, versatile in simulating different materials, and capable of
generating more fine-grained wrinkles than the state of the art.",http://arxiv.org/abs/2502.13491v1
"Environmental Influences on Collaboration Network Evolution: A
  Historical Analysis",2025-02-19T10:38:29Z,"Peter R Williams, Zhan Chen","We analysed two large collaboration networks -- the Microsoft Academic Graph
(1800-2020) and Internet Movie Database (1900-2020) -- to quantify network
responses to major historical events. Our analysis revealed four properties of
network-environment interaction. First, historical events can influence network
evolution, with effects persisting far longer than previously recognised; the
academic network showed 45\% declines during World Wars and 90\% growth during
La Belle Epoque. Second, node and edge processes exhibited different
environmental sensitivities; while node addition/removal tracked historical
events, edge formation maintained stable statistical properties even during
major disruptions. Third, different collaboration networks showed distinct
response patterns; academic networks displayed sharp disruptions and rapid
recoveries, while entertainment networks showed gradual changes and greater
resilience. Fourth, both networks developed increasing resilience. Our results
provide new insights for modelling network evolution and managing collaborative
systems during periods of external disruption.",http://arxiv.org/abs/2502.13607v1
"Emergence of ecological structure and species rarity from fluctuating
  metabolic strategies",2025-02-19T13:48:03Z,"Davide Zanchetta, Deepak Gupta, Sofia Moschin, Samir Suweis, Amos Maritan, Sandro Azaele","Ecosystems often demonstrate the coexistence of numerous species competing
for limited resources, with pronounced rarity and abundance patterns. A
potential driver of such coexistence is environmental fluctuations that favor
different species over time. However, how to include and treat such temporal
variability in existing consumer-resource models is still an open problem. In
this study, we examine the role of correlated temporal fluctuations in
metabolic strategies within a stochastic consumer-resource framework,
reflecting change of species behavior in response to the environment. In some
conditions, we are able to solve analytically the species abundance
distributions, through path integral formalism. Our results reveal that
stochastic dynamic metabolic strategies induce community structures that align
more closely with empirical ecological observations and contribute to the
violation of the Competitive Exclusion Principle (CEP). The degree of CEP
violation is maximized under intermediate competition strength, leading to an
intermediate competition hypothesis. Furthermore, when non-neutral effects are
present, maximal biodiversity is achieved for intermediate values of the
amplitude of fluctuations. This work not only challenges traditional ecological
paradigms, but also establishes a robust theoretical framework for exploring
how temporal dynamics and stochasticity drive biodiversity and community.",http://arxiv.org/abs/2502.13720v1
GPA: Grover Policy Agent for Generating Optimal Quantum Sensor Circuits,2025-02-19T14:20:07Z,"Ahmad Alomari, Sathish A. P. Kumar","This study proposes a GPA for designing optimal Quantum Sensor Circuits
(QSCs) to address complex quantum physics problems. The GPA consists of two
parts: the Quantum Policy Evaluation (QPE) and the Quantum Policy Improvement
(QPI). The QPE performs phase estimation to generate the search space, while
the QPI utilizes Grover search and amplitude amplification techniques to
efficiently identify an optimal policy that generates optimal QSCs. The GPA
generates QSCs by selecting sequences of gates that maximize the Quantum Fisher
Information (QFI) while minimizing the number of gates. The QSCs generated by
the GPA are capable of producing entangled quantum states, specifically the
squeezed states. High QFI indicates increased sensitivity to parameter changes,
making the circuit useful for quantum state estimation and control tasks.
Evaluation of the GPA on a QSC that consists of two qubits and a sequence of
R_x, R_y, and S gates demonstrates its efficiency in generating optimal QSCs
with a QFI of 1. Compared to existing quantum agents, the GPA achieves higher
QFI with fewer gates, demonstrating a more efficient and scalable approach to
the design of QSCs. This work illustrates the potential computational power of
quantum agents for solving quantum physics problems",http://arxiv.org/abs/2502.13755v1
Identifying metric structures of deep latent variable models,2025-02-19T14:20:28Z,"Stas Syrota, Yevgen Zainchkovskyy, Johnny Xi, Benjamin Bloem-Reddy, Søren Hauberg","Deep latent variable models learn condensed representations of data that,
hopefully, reflect the inner workings of the studied phenomena. Unfortunately,
these latent representations are not statistically identifiable, meaning they
cannot be uniquely determined. Domain experts, therefore, need to tread
carefully when interpreting these. Current solutions limit the lack of
identifiability through additional constraints on the latent variable model,
e.g. by requiring labeled training data, or by restricting the expressivity of
the model. We change the goal: instead of identifying the latent variables, we
identify relationships between them such as meaningful distances, angles, and
volumes. We prove this is feasible under very mild model conditions and without
additional labeled data. We empirically demonstrate that our theory results in
more reliable latent distances, offering a principled path forward in
extracting trustworthy conclusions from deep latent variable models.",http://arxiv.org/abs/2502.13757v2
Multi-Covering a Point Set by $m$ Disks with Minimum Total Area,2025-02-19T14:34:32Z,"Mariem Guitouni, Chek-Manh Loi, Sándor P. Fekete, Michael Perk, Aaron T. Becker","A common robotics sensing problem is to place sensors to robustly monitor a
set of assets, where robustness is assured by requiring asset $p$ to be
monitored by at least $\kappa(p)$ sensors. Given $n$ assets that must be
observed by $m$ sensors, each with a disk-shaped sensing region, where should
the sensors be placed to minimize the total area observed? We provide and
analyze a fast heuristic for this problem. We then use the heuristic to
initialize an exact Integer Programming solution. Subsequently, we enforce
separation constraints between the sensors by modifying the integer program
formulation and by changing the disk candidate set.",http://arxiv.org/abs/2502.13773v1
"Translation in the Hands of Many:Centering Lay Users in Machine
  Translation Interactions",2025-02-19T14:45:17Z,"Beatrice Savoldi, Alan Ramponi, Matteo Negri, Luisa Bentivogli","Converging societal and technical factors have transformed language
technologies into user-facing applications employed across languages. Machine
Translation (MT) has become a global tool, with cross-lingual services now also
supported by dialogue systems powered by multilingual Large Language Models
(LLMs). This accessibility has expanded MT's reach to a vast base of lay users,
often with little to no expertise in the languages or the technology itself.
Despite this, the understanding of MT consumed by this diverse group of users
-- their needs, experiences, and interactions with these systems -- remains
limited. This paper traces the shift in MT user profiles, focusing on
non-expert users and how their engagement with these systems may change with
LLMs. We identify three key factors -- usability, trust, and literacy -- that
shape these interactions and must be addressed to align MT with user needs. By
exploring these dimensions, we offer insights to guide future MT with a
user-centered approach.",http://arxiv.org/abs/2502.13780v1
"Extending the RANGE of Graph Neural Networks: Relaying Attention Nodes
  for Global Encoding",2025-02-19T15:05:47Z,"Alessandro Caruso, Jacopo Venturin, Lorenzo Giambagli, Edoardo Rolando, Frank Noé, Cecilia Clementi","Graph Neural Networks (GNNs) are routinely used in molecular physics, social
sciences, and economics to model many-body interactions in graph-like systems.
However, GNNs are inherently local and can suffer from information flow
bottlenecks. This is particularly problematic when modeling large molecular
systems, where dispersion forces and local electric field variations drive
collective structural changes. Existing solutions face challenges related to
computational cost and scalability. We introduce RANGE, a model-agnostic
framework that employs an attention-based aggregation-broadcast mechanism that
significantly reduces oversquashing effects, and achieves remarkable accuracy
in capturing long-range interactions at a negligible computational cost.
Notably, RANGE is the first virtual-node message-passing implementation to
integrate attention with positional encodings and regularization to dynamically
expand virtual representations. This work lays the foundation for
next-generation of machine-learned force fields, offering accurate and
efficient modeling of long-range interactions for simulating large molecular
systems.",http://arxiv.org/abs/2502.13797v2
"Theory of composite Ramsey sequences of radiofrequency pulses beyond the
  rotating wave approximation",2025-02-04T16:53:47Z,"V. I. Yudin, O. N. Prudnikov, A. V. Taichenachev, M. Yu. Basalaev, V. G. Pal'chikov, S. N. Bagayev","We develop a theory of composite Ramsey sequences of rf pulses interacting
with the Zeeman structure at the long-lived atomic level, beyond the rotating
wave approximation. Such sequences are proposed in experiments to detect the
violation of local Lorentz invariance [R. Shaniv, et al., Phys. Rev. Lett. 120,
103202 (2018)]. Based on Fourier analysis, we have shown that taking into
account non-resonant contributions leads to a radical change in the dynamics of
the quantum system (with respect to the rotating wave approximation) in the
case when the number of Ramsey pulses exceeds several tens. As a result, the
effectiveness of using such rf pulses sequences to test local Lorentz
invariance has not yet been fully determined and requires additional research.",http://arxiv.org/abs/2502.13973v1
"Elastic Quantum Criticality in Nematics and Altermagnets via the
  Elasto-Caloric Effect",2025-02-19T19:00:01Z,"Charles R. W. Steward, Grgur Palle, Markus Garst, Joerg Schmalian, Iksu Jang","The coupling between electronic nematic degrees of freedom and acoustic
phonons is known to significantly alter the universality class of a nematic
quantum critical point (QCP). While non-Fermi-liquid behaviour emerges in the
absence of lattice coupling, the inclusion of interactions with acoustic
phonons results in observables such as heat capacity and single-particle
scattering rate exhibiting only subleading non-analytic corrections to dominant
Fermi-liquid terms. In this work, we demonstrate that the elastocaloric effect
(ECE) -- the adiabatic temperature change under varying strain -- and the
thermal expansion deviate from this pattern. Despite lattice coupling weakening
the singularity of the ECE, it preserves a dominant non-Fermi-liquid
temperature dependence. By drawing analogies between nematic systems and
field-tuned altermagnets, we further show that similar responses are expected
for the ECE near altermagnetic QCPs. We classify the types of piezomagnetic
couplings and analyse the regimes arising from field-tuned magnetoelastic
interactions. Our findings are shown to be consistent with the scaling theory
for elastic quantum criticality and they further emphasize the suitability of
the ECE as a sensitive probe near QCPs.",http://arxiv.org/abs/2502.14033v1
Position: There are no Champions in Long-Term Time Series Forecasting,2025-02-19T19:08:37Z,"Lorenzo Brigato, Rafael Morand, Knut Strømmen, Maria Panagiotou, Markus Schmidt, Stavroula Mougiakakou","Recent advances in long-term time series forecasting have introduced numerous
complex prediction models that consistently outperform previously published
architectures. However, this rapid progression raises concerns regarding
inconsistent benchmarking and reporting practices, which may undermine the
reliability of these comparisons. Our position emphasizes the need to shift
focus away from pursuing ever-more complex models and towards enhancing
benchmarking practices through rigorous and standardized evaluation methods. To
support our claim, we first perform a broad, thorough, and reproducible
evaluation of the top-performing models on the most popular benchmark by
training 3,500+ networks over 14 datasets. Then, through a comprehensive
analysis, we find that slight changes to experimental setups or current
evaluation metrics drastically shift the common belief that newly published
results are advancing the state of the art. Our findings suggest the need for
rigorous and standardized evaluation methods that enable more substantiated
claims, including reproducible hyperparameter setups and statistical testing.",http://arxiv.org/abs/2502.14045v1
"PedDet: Adaptive Spectral Optimization for Multimodal Pedestrian
  Detection",2025-02-19T19:31:51Z,"Rui Zhao, Zeyu Zhang, Yi Xu, Yi Yao, Yan Huang, Wenxin Zhang, Zirui Song, Xiuying Chen, Yang Zhao","Pedestrian detection in intelligent transportation systems has made
significant progress but faces two critical challenges: (1) insufficient fusion
of complementary information between visible and infrared spectra, particularly
in complex scenarios, and (2) sensitivity to illumination changes, such as
low-light or overexposed conditions, leading to degraded performance. To
address these issues, we propose PedDet, an adaptive spectral optimization
complementarity framework specifically enhanced and optimized for multispectral
pedestrian detection. PedDet introduces the Multi-scale Spectral Feature
Perception Module (MSFPM) to adaptively fuse visible and infrared features,
enhancing robustness and flexibility in feature extraction. Additionally, the
Illumination Robustness Feature Decoupling Module (IRFDM) improves detection
stability under varying lighting by decoupling pedestrian and background
features. We further design a contrastive alignment to enhance intermodal
feature discrimination. Experiments on LLVIP and MSDS datasets demonstrate that
PedDet achieves state-of-the-art performance, improving the mAP by 6.6% with
superior detection accuracy even in low-light conditions, marking a significant
step forward for road safety. Code will be available at
https://github.com/AIGeeksGroup/PedDet.",http://arxiv.org/abs/2502.14063v1
Hybrid Visual Servoing of Tendon-driven Continuum Robots,2025-02-19T20:35:41Z,"Rana Danesh, Farrokh Janabi-Sharifi, Farhad Aghili","This paper introduces a novel Hybrid Visual Servoing (HVS) approach for
controlling tendon-driven continuum robots (TDCRs). The HVS system combines
Image-Based Visual Servoing (IBVS) with Deep Learning-Based Visual Servoing
(DLBVS) to overcome the limitations of each method and improve overall
performance. IBVS offers higher accuracy and faster convergence in feature-rich
environments, while DLBVS enhances robustness against disturbances and offers a
larger workspace. By enabling smooth transitions between IBVS and DLBVS, the
proposed HVS ensures effective control in dynamic, unstructured environments.
The effectiveness of this approach is validated through simulations and
real-world experiments, demonstrating that HVS achieves reduced iteration time,
faster convergence, lower final error, and smoother performance compared to
DLBVS alone, while maintaining DLBVS's robustness in challenging conditions
such as occlusions, lighting changes, actuator noise, and physical impacts.",http://arxiv.org/abs/2502.14092v1
Can Community Notes Replace Professional Fact-Checkers?,2025-02-19T22:26:39Z,"Nadav Borenstein, Greta Warren, Desmond Elliott, Isabelle Augenstein","Two commonly-employed strategies to combat the rise of misinformation on
social media are (i) fact-checking by professional organisations and (ii)
community moderation by platform users. Policy changes by Twitter/X and, more
recently, Meta, signal a shift away from partnerships with fact-checking
organisations and towards an increased reliance on crowdsourced community
notes. However, the extent and nature of dependencies between fact-checking and
helpful community notes remain unclear. To address these questions, we use
language models to annotate a large corpus of Twitter/X community notes with
attributes such as topic, cited sources, and whether they refute claims tied to
broader misinformation narratives. Our analysis reveals that community notes
cite fact-checking sources up to five times more than previously reported.
Fact-checking is especially crucial for notes on posts linked to broader
narratives, which are twice as likely to reference fact-checking sources
compared to other sources. In conclusion, our results show that successful
community moderation heavily relies on professional fact-checking.",http://arxiv.org/abs/2502.14132v1
Cluster Analysis and Concept Drift Detection in Malware,2025-02-19T22:42:30Z,"Aniket Mishra, Mark Stamp","Concept drift refers to gradual or sudden changes in the properties of data
that affect the accuracy of machine learning models. In this paper, we address
the problem of concept drift detection in the malware domain. Specifically, we
propose and analyze a clustering-based approach to detecting concept drift.
Using a subset of the KronoDroid dataset, malware samples are partitioned into
temporal batches and analyzed using MiniBatch $K$-Means clustering. The
silhouette coefficient is used as a metric to identify points in time where
concept drift has likely occurred. To verify our drift detection results, we
train learning models under three realistic scenarios, which we refer to as
static training, periodic retraining, and drift-aware retraining. In each
scenario, we consider four supervised classifiers, namely, Multilayer
Perceptron (MLP), Support Vector Machine (SVM), Random Forest, and XGBoost.
Experimental results demonstrate that drift-aware retraining guided by
silhouette coefficient thresholding achieves classification accuracy far
superior to static models, and generally within 1% of periodic retraining,
while also being far more efficient than periodic retraining. These results
provide strong evidence that our clustering-based approach is effective at
detecting concept drift, while also illustrating a highly practical and
efficient fully automated approach to improved malware classification via
concept drift detection.",http://arxiv.org/abs/2502.14135v1
Learning the P2D Model for Lithium-Ion Batteries with SOH Detection,2025-02-19T23:17:30Z,"Maricela Best McKay, Bhushan Gopaluni, Brian Wetton","Lithium ion batteries are widely used in many applications. Battery
management systems control their optimal use and charging and predict when the
battery will cease to deliver the required output on a planned duty or driving
cycle. Such systems use a simulation of a mathematical model of battery
performance. These models can be electrochemical or data-driven.
Electrochemical models for batteries running at high currents are
mathematically and computationally complex. In this work, we show that a
well-regarded electrochemical model, the Pseudo Two Dimensional (P2D) model,
can be replaced by a computationally efficient Convolutional Neural Network
(CNN) surrogate model fit to accurately simulated data from a class of random
driving cycles. We demonstrate that a CNN is an ideal choice for accurately
capturing Lithium ion concentration profiles. Additionally, we show how the
neural network model can be adjusted to correspond to battery changes in State
of Health (SOH).",http://arxiv.org/abs/2502.14147v1
Real-Time Sampling-based Online Planning for Drone Interception,2025-02-20T03:48:38Z,"Gilhyun Ryou, Lukas Lao Beyer, Sertac Karaman","This paper studies high-speed online planning in dynamic environments. The
problem requires finding time-optimal trajectories that conform to system
dynamics, meeting computational constraints for real-time adaptation, and
accounting for uncertainty from environmental changes. To address these
challenges, we propose a sampling-based online planning algorithm that
leverages neural network inference to replace time-consuming nonlinear
trajectory optimization, enabling rapid exploration of multiple trajectory
options under uncertainty. The proposed method is applied to the drone
interception problem, where a defense drone must intercept a target while
avoiding collisions and handling imperfect target predictions. The algorithm
efficiently generates trajectories toward multiple potential target drone
positions in parallel. It then assesses trajectory reachability by comparing
traversal times with the target drone's predicted arrival time, ultimately
selecting the minimum-time reachable trajectory. Through extensive validation
in both simulated and real-world environments, we demonstrate our method's
capability for high-rate online planning and its adaptability to unpredictable
movements in unstructured settings.",http://arxiv.org/abs/2502.14231v1
"Does Time Have Its Place? Temporal Heads: Where Language Models Recall
  Time-specific Information",2025-02-20T04:52:05Z,"Yein Park, Chanwoong Yoon, Jungwoo Park, Minbyul Jeong, Jaewoo Kang","While the ability of language models to elicit facts has been widely
investigated, how they handle temporally changing facts remains underexplored.
We discover Temporal Heads, specific attention heads primarily responsible for
processing temporal knowledge through circuit analysis. We confirm that these
heads are present across multiple models, though their specific locations may
vary, and their responses differ depending on the type of knowledge and its
corresponding years. Disabling these heads degrades the model's ability to
recall time-specific knowledge while maintaining its general capabilities
without compromising time-invariant and question-answering performances.
Moreover, the heads are activated not only numeric conditions (""In 2004"") but
also textual aliases (""In the year ...""), indicating that they encode a
temporal dimension beyond simple numerical representation. Furthermore, we
expand the potential of our findings by demonstrating how temporal knowledge
can be edited by adjusting the values of these heads.",http://arxiv.org/abs/2502.14258v1
"ODVerse33: Is the New YOLO Version Always Better? A Multi Domain
  benchmark from YOLO v5 to v11",2025-02-20T06:57:58Z,"Tianyou Jiang, Yang Zhong","You Look Only Once (YOLO) models have been widely used for building real-time
object detectors across various domains. With the increasing frequency of new
YOLO versions being released, key questions arise. Are the newer versions
always better than their previous versions? What are the core innovations in
each YOLO version and how do these changes translate into real-world
performance gains? In this paper, we summarize the key innovations from YOLOv1
to YOLOv11, introduce a comprehensive benchmark called ODverse33, which
includes 33 datasets spanning 11 diverse domains (Autonomous driving,
Agricultural, Underwater, Medical, Videogame, Industrial, Aerial, Wildlife,
Retail, Microscopic, and Security), and explore the practical impact of model
improvements in real-world, multi-domain applications through extensive
experimental results. We hope this study can provide some guidance to the
extensive users of object detection models and give some references for future
real-time object detector development.",http://arxiv.org/abs/2502.14314v1
ChemHTS: Hierarchical Tool Stacking for Enhancing Chemical Agents,2025-02-20T07:24:26Z,"Zhucong Li, Jin Xiao, Bowei Zhang, Zhijian Zhou, Qianyu He, Fenglei Cao, Jiaqing Liang, Yuan Qi","Large Language Models (LLMs) have demonstrated remarkable potential in
scientific research, particularly in chemistry-related tasks such as molecular
design, reaction prediction, and property estimation. While tool-augmented LLMs
have been introduced to enhance reasoning and computation in these domains,
existing approaches suffer from tool invocation errors and lack effective
collaboration among diverse tools, limiting their overall performance. To
address these challenges, we propose ChemHTS (Chemical Hierarchical Tool
Stacking), a novel method that optimizes tool invocation pathways through a
hierarchical stacking strategy. ChemHTS consists of two key stages: tool
self-stacking warmup and multi-layer decision optimization, enabling LLMs to
refine tool usage dynamically. We evaluate ChemHTS across four classical
chemistry tasks and demonstrate its superiority over strong baselines,
including GPT-4o, DeepSeek-R1, and chemistry-specific models, including
ChemDFM. Furthermore, we define four distinct tool-stacking behaviors to
enhance interpretability, providing insights into the effectiveness of tool
collaboration. Our dataset and code are publicly available at
\url{https://github.com/Chang-pw/ChemHTS}.",http://arxiv.org/abs/2502.14327v1
A Survey on Data Contamination for Large Language Models,2025-02-20T10:23:27Z,"Yuxing Cheng, Yi Chang, Yuan Wu","Recent advancements in Large Language Models (LLMs) have demonstrated
significant progress in various areas, such as text generation and code
synthesis. However, the reliability of performance evaluation has come under
scrutiny due to data contamination-the unintended overlap between training and
test datasets. This overlap has the potential to artificially inflate model
performance, as LLMs are typically trained on extensive datasets scraped from
publicly available sources. These datasets often inadvertently overlap with the
benchmarks used for evaluation, leading to an overestimation of the models'
true generalization capabilities. In this paper, we first examine the
definition and impacts of data contamination. Secondly, we review methods for
contamination-free evaluation, focusing on three strategies: data
updating-based methods, data rewriting-based methods, and prevention-based
methods. Specifically, we highlight dynamic benchmarks and LLM-driven
evaluation methods. Finally, we categorize contamination detecting methods
based on model information dependency: white-Box, gray-Box, and black-Box
detection approaches. Our survey highlights the requirements for more rigorous
evaluation protocols and proposes future directions for addressing data
contamination challenges.",http://arxiv.org/abs/2502.14425v1
NLoRA: Nyström-Initiated Low-Rank Adaptation for Large Language Models,2025-02-20T12:01:11Z,"Chenlu Guo, Yuan Wu, Yi Chang","Parameter-efficient fine-tuning (PEFT) is essential for adapting large
language models (LLMs), with low-rank adaptation (LoRA) being the most popular
approach. However, LoRA suffers from slow convergence, and some recent LoRA
variants, such as PiSSA, primarily rely on Singular Value Decomposition (SVD)
for initialization, leading to expensive computation. To mitigate these
problems, we use the Nystr\""om method, which follows a three-matrix
manipulation. We first introduce StructuredLoRA (SLoRA), which investigates
adding a small intermediate matrix between the low-rank matrices A and B.
Secondly, we propose Nystr\""omLoRA (NLoRA), which leverages Nystr\""om-based
initialization for SLoRA to improve its effectiveness and efficiency. Finally,
we propose IntermediateTune (IntTune), which explores fine-tuning exclusively
on the intermediate matrix of NLoRA to further boost LLM efficiency. We
evaluate our methods on five natural language generation (NLG) tasks and eight
natural language understanding (NLU) tasks. On GSM8K, SLoRA and NLoRA achieve
accuracies of 56.48% and 57.70%, surpassing LoRA by 33.52% and 36.41%, with
only 3.67 million additional trainable parameters. IntTune improves average NLG
performance over LoRA by 7.45% while using only 1.25% of its parameters. These
results demonstrate the efficiency and effectiveness of our approach in
enhancing model performance with minimal parameter overhead.",http://arxiv.org/abs/2502.14482v1
"StructFlowBench: A Structured Flow Benchmark for Multi-turn Instruction
  Following",2025-02-20T12:22:18Z,"Jinnan Li, Jinzhe Li, Yue Wang, Yi Chang, Yuan Wu","Multi-turn instruction following capability constitutes a core competency of
large language models (LLMs) in real-world applications. Existing evaluation
benchmarks predominantly focus on fine-grained constraint satisfaction and
domain-specific capability assessment, yet overlook the crucial structural
dependency between dialogue turns that distinguishes multi-turn from
single-turn interactions. This structural dependency not only reflects user
intent but also establishes a second dimension for instruction following
evaluation beyond constraint satisfaction. To address this gap, we propose
StructFlowBench, a multi-turn instruction following benchmark with structural
flow modeling. The benchmark innovatively defines a structural flow framework
comprising six fundamental inter-turn relationships, which not only introduces
novel structural constraints for model evaluation but also serves as generation
parameters for creating customized dialogue flows tailored to specific
scenarios. Adopting established LLM-based automatic evaluation methodologies,
we conduct systematic evaluations of 13 leading open-source and closed-source
LLMs. Experimental results reveal significant deficiencies in current models'
comprehension of multi-turn dialogue structures. The code is available at
\url{https://github.com/MLGroupJLU/StructFlowBench}.",http://arxiv.org/abs/2502.14494v1
"The life cycle of scientific principles -- a template for characterizing
  physical principles",2025-02-20T14:00:36Z,"Radin Dardashti, Enno Fischer, Robert Harlander","Scientific principles can undergo various developments. While philosophers of
science have acknowledged that such changes occur, there is no systematic
account of the development of scientific principles. Here we propose a template
for analyzing the development of scientific principles called the 'life cycle'
of principles. It includes a series of processes that principles can go
through: prehistory, elevation, formalization, generalization, and challenge.
The life cycle, we argue, is a useful heuristic for the analysis of the
development of scientific principles. We illustrate this by discussing examples
from foundational physics including Lorentz invariance, Mach's principle, the
naturalness principle, and the perfect cosmological principle. We also explore
two applications of the template. First, we propose that the template can be
employed to diagnose the quality of scientific principles. Second, we discuss
the ramifications of the life cycle's processes for the empirical testability
of principles.",http://arxiv.org/abs/2502.14575v1
"Constraints on the fractional changes of the fundamental constants at a
  look-back time of 2.5 Myrs",2025-02-20T14:00:45Z,"Renzhi Su, Tao An, Stephen J. Curran, Michael P. Busch, Minfeng Gu, Di Li","The quantum nature of gravity remains one of the greatest mysteries of modern
physics, with many unified theories predicting variations in fundamental
constants across space and time. Here we present precise measurements of these
variations at galactic dynamical timescales - a critical but previously
unexplored regime. Using simultaneous observations of H \textsc{i} and OH lines
in M31, we probe potential variations of fundamental constants at a lookback
time of 2.5 million years. We obtained
$\Delta(\mu\alpha^2g_p^{0.64})/(\mu\alpha^2g_p^{0.64}) < 3.6 \times 10^{-6}$,
with complementary constraints on $\Delta(\mu\alpha^2)/(\mu\alpha^2) < 4.6
\times 10^{-3}$, and $\Delta g_p/g_p < 7.2 \times 10^{-3}$, where $\alpha$ is
the fine structure constant, $\mu$ is the proton-electron mass ratio, and $g_p$
is the proton $g$-factor. These results bridge the gap between laboratory tests
and cosmological observations, providing unique insights into the coupling
between local dynamics and fundamental physics. Our findings challenge theories
predicting significant variations over galactic timescales, while demonstrating
a powerful new probe of quantum gravity models.",http://arxiv.org/abs/2502.14576v1
"Spatially Varying Coefficient Models for Estimating Heterogeneous
  Mixture Effects",2025-02-20T15:40:57Z,"Jacob Englert, Howard Chang","Recent studies of associations between environmental exposures and health
outcomes have shifted toward estimating the effect of simultaneous exposure to
multiple chemicals. Summary index methods, such as the weighted quantile sum
and quantile g-computation, are now commonly used to analyze environmental
exposure mixtures in a broad range of applications. These methods provide a
simple and interpretable framework for quantifying mixture effects. However,
when data arise from a large geographical study region, it may be unreasonable
to expect a common mixture effect. In this work, we explore the use of a
recently developed spatially varying coefficient model based on Bayesian
additive regression trees to estimate spatially heterogeneous mixture effects
using quantile g-computation. We conducted simulation studies to evaluate the
method's performance. We then applied this model to an analysis of multiple
ambient air pollutants and birthweight in Georgia, USA from 2005-2016. We find
evidence of county-level spatially varying mixture associations, where for 17
of 159 counties in Georgia, elevated concentrations of a mixture of PM2.5,
nitrogen dioxide, sulfur dioxide, ozone, and carbon monoxide were associated
with a reduction in birthweight by as much as -16.65 grams (95% credible
interval: -33.93, -0.40) per decile increase in all five air pollutants.",http://arxiv.org/abs/2502.14651v1
Parallelizing a modern GPU simulator,2025-02-20T16:18:15Z,"Rodrigo Huerta, Antonio González","Simulators are a primary tool in computer architecture research but are
extremely computationally intensive. Simulating modern architectures with
increased core counts and recent workloads can be challenging, even on modern
hardware. This paper demonstrates that simulating some GPGPU workloads in a
single-threaded state-of-the-art simulator such as Accel-sim can take more than
five days. In this paper we present a simple approach to parallelize this
simulator with minimal code changes by using OpenMP. Moreover, our
parallelization technique is deterministic, so the simulator provides the same
results for single-threaded and multi-threaded simulations. Compared to
previous works, we achieve a higher speed-up, and, more importantly, the
parallel simulation does not incur any inaccuracies. When we run the simulator
with 16 threads, we achieve an average speed-up of 5.8x and reach 14x in some
workloads. This allows researchers to simulate applications that take five days
in less than 12 hours. By speeding up simulations, researchers can model larger
systems, simulate bigger workloads, add more detail to the model, increase the
efficiency of the hardware platform where the simulator is run, and obtain
results sooner.",http://arxiv.org/abs/2502.14691v1
General Uncertainty Estimation with Delta Variances,2025-02-20T16:22:40Z,"Simon Schmitt, John Shawe-Taylor, Hado van Hasselt","Decision makers may suffer from uncertainty induced by limited data. This may
be mitigated by accounting for epistemic uncertainty, which is however
challenging to estimate efficiently for large neural networks. To this extent
we investigate Delta Variances, a family of algorithms for epistemic
uncertainty quantification, that is computationally efficient and convenient to
implement. It can be applied to neural networks and more general functions
composed of neural networks. As an example we consider a weather simulator with
a neural-network-based step function inside -- here Delta Variances empirically
obtain competitive results at the cost of a single gradient computation. The
approach is convenient as it requires no changes to the neural network
architecture or training procedure. We discuss multiple ways to derive Delta
Variances theoretically noting that special cases recover popular techniques
and present a unified perspective on multiple related methods. Finally we
observe that this general perspective gives rise to a natural extension and
empirically show its benefit.",http://arxiv.org/abs/2502.14698v1
Entanglement entropy evolution during gravitational collapse,2025-02-20T18:18:16Z,"Alessio Belfiglio, Orlando Luongo, Stefano Mancini, Sebastiano Tomasi","We investigate the dynamics of the ground state entanglement entropy for a
discretized scalar field propagating within the Oppenheimer-Snyder collapse
metric. Starting from a well-controlled initial configuration, we follow the
system as it evolves toward the formation of a horizon and, eventually, a
singularity. Our approach employs an Ermakov-like equation to determine the
time-dependent ground state of the field and calculates the resulting
entanglement entropy by tracing out the degrees of freedom inside a spherical
region within the matter sphere. We find that the entanglement entropy exhibits
nontrivial scaling and time dependence during collapse. Close to the horizon,
the entropy can deviate from the simple area law, reflecting the rapid changes
in geometry and field configuration. Although the model is idealized, these
results provide insights into the generation and scaling of entanglement in the
presence of realistic, dynamically evolving gravitational fields.",http://arxiv.org/abs/2502.14797v1
"Measuring Faithfulness of Chains of Thought by Unlearning Reasoning
  Steps",2025-02-20T18:45:05Z,"Martin Tutek, Fateme Hashemi Chaleshtori, Ana Marasović, Yonatan Belinkov","When prompted to think step-by-step, language models (LMs) produce a chain of
thought (CoT), a sequence of reasoning steps that the model supposedly used to
produce its prediction. However, despite much work on CoT prompting, it is
unclear if CoT reasoning is faithful to the models' parameteric beliefs. We
introduce a framework for measuring parametric faithfulness of generated
reasoning, and propose Faithfulness by Unlearning Reasoning steps (FUR), an
instance of this framework. FUR erases information contained in reasoning steps
from model parameters. We perform experiments unlearning CoTs of four LMs
prompted on four multi-choice question answering (MCQA) datasets. Our
experiments show that FUR is frequently able to change the underlying models'
prediction by unlearning key steps, indicating when a CoT is parametrically
faithful. Further analysis shows that CoTs generated by models post-unlearning
support different answers, hinting at a deeper effect of unlearning.
Importantly, CoT steps identified as important by FUR do not align well with
human notions of plausbility, emphasizing the need for specialized alignment",http://arxiv.org/abs/2502.14829v1
Improving the Diffusability of Autoencoders,2025-02-20T18:45:44Z,"Ivan Skorokhodov, Sharath Girish, Benran Hu, Willi Menapace, Yanyu Li, Rameen Abdal, Sergey Tulyakov, Aliaksandr Siarohin","Latent diffusion models have emerged as the leading approach for generating
high-quality images and videos, utilizing compressed latent representations to
reduce the computational burden of the diffusion process. While recent
advancements have primarily focused on scaling diffusion backbones and
improving autoencoder reconstruction quality, the interaction between these
components has received comparatively less attention. In this work, we perform
a spectral analysis of modern autoencoders and identify inordinate
high-frequency components in their latent spaces, which are especially
pronounced in the autoencoders with a large bottleneck channel size. We
hypothesize that this high-frequency component interferes with the
coarse-to-fine nature of the diffusion synthesis process and hinders the
generation quality. To mitigate the issue, we propose scale equivariance: a
simple regularization strategy that aligns latent and RGB spaces across
frequencies by enforcing scale equivariance in the decoder. It requires minimal
code changes and only up to 20K autoencoder fine-tuning steps, yet
significantly improves generation quality, reducing FID by 19% for image
generation on ImageNet-1K 256x256 and FVD by at least 44% for video generation
on Kinetics-700 17x256x256.",http://arxiv.org/abs/2502.14831v1
CLIPPER: Compression enables long-context synthetic data generation,2025-02-20T18:58:03Z,"Chau Minh Pham, Yapei Chang, Mohit Iyyer","LLM developers are increasingly reliant on synthetic data, but generating
high-quality data for complex long-context reasoning tasks remains challenging.
We introduce CLIPPER, a compression-based approach for generating synthetic
data tailored to narrative claim verification - a task that requires reasoning
over a book to verify a given claim. Instead of generating claims directly from
the raw text of the book, which results in artifact-riddled claims, CLIPPER
first compresses the book into chapter outlines and book summaries and then
uses these intermediate representations to generate complex claims and
corresponding chain-of-thoughts. Compared to naive approaches, CLIPPER produces
claims that are more valid, grounded, and complex. Using CLIPPER, we construct
a dataset of 19K synthetic book claims paired with their source texts and
chain-of-thought reasoning, and use it to fine-tune three open-weight models.
Our best model achieves breakthrough results on narrative claim verification
(from 28% to 76% accuracy on our test set) and sets a new state-of-the-art for
sub-10B models on the NoCha leaderboard. Further analysis shows that our models
generate more detailed and grounded chain-of-thought reasoning while also
improving performance on other narrative understanding tasks (e.g.,
NarrativeQA).",http://arxiv.org/abs/2502.14854v1
"Multi-wavelength observations of a jet launch in real time from the
  post-changing-look Active Galaxy 1ES 1927+654",2025-01-04T17:31:25Z,"Sibasish Laha, Eileen T. Meyer, Dev R. Sadaula, Ritesh Ghosh, Dhrubojyoti Sengupta, Megan Masterson, Onic I. Shuvo, Matteo Guainazzi, Claudio Ricci, Mitchell C. Begelman, Alexander Philippov, Rostom Mbarek, Amelia M. Hankla, Erin Kara, Francesca Panessa, Ehud Behar, Haocheng Zhang, Fabio Pacucci, Main Pal, Federica Ricci, Ilaria Villani, Susanna Bisogni, Fabio La Franca, Stefano Bianchi, Gabriele Bruni, Samantha Oates, Cameron Hahn, Matt Nicholl, S. Bradley Cenko, Sabyasachi Chattopadhyay, Josefa Becerra Gonzalez, J. A. Acosta-Pulido, Suvendu Rakshit, Jiri Svoboda, Luigi Gallo, Adam Ingram, Darshan Kakkad","We present results from a high cadence multi-wavelength observational
campaign of the enigmatic changing look AGN 1ES 1927+654 from May 2022- April
2024, coincident with an unprecedented radio flare (an increase in flux by a
factor of $\sim 60$ over a few months) and the emergence of a spatially
resolved jet at $0.1-0.3$ pc scales (Meyer et al. 2024). Companion work has
also detected a recurrent quasi-periodic oscillation (QPO) in the $2-10$ keV
band with an increasing frequency ($1-2$ mHz) over the same period (Masterson
et al., 2025). During this time, the soft X-rays ($0.3-2$ keV) monotonically
increased by a factor of $\sim 8$, while the UV emission remained near-steady
with $<30\%$ variation and the $2-10$ keV flux showed variation by a factor
$\lesssim 2$. The weak variation of the $2-10$ keV X-ray emission and the
stability of the UV emission suggest that the magnetic energy density and
accretion rate are relatively unchanged, and that the jet could be launched due
to a reconfiguration of the magnetic field (toroidal to poloidal) close to the
black hole. Advecting poloidal flux onto the event horizon would trigger the
Blandford-Znajek (BZ) mechanism, leading to the onset of the jet. The
concurrent softening of the coronal slope (from $\Gamma= 2.70\pm 0.04$ to
$\Gamma=3.27\pm 0.04$), the appearance of a QPO, and low coronal temperature
($kT_{e}=8_{-3}^{+8}$ keV) during the radio outburst suggest that the poloidal
field reconfiguration can significantly impact coronal properties and thus
influence jet dynamics. These extraordinary findings in real time are crucial
for coronal and jet plasma studies, particularly as our results are independent
of coronal geometry.",http://arxiv.org/abs/2501.02340v1
"A comprehensive survey of the GEO-belt using simultaneous four-colour
  observations with STING",2025-02-17T21:01:54Z,"Robert J. S. Airey, Paul Chote, James A. Blake, Benjamin F. Cooke, James McCormac, Phineas Allen, Alex MacManus, Don Pollacco, Billy Shrive, Richard West","Colour light curves of resident space objects (RSOs) encapsulate distinctive
features that can offer insights into an object's structure and design, making
them an invaluable tool for classification and characterisation. We present the
results of the first large systematic colour survey of the GEO belt in which we
obtain full-night multi-colour light curves for 112 active geostationary
objects between April and May 2023. Colour light curve maps were created to
compare and contrast the colours between different satellites and bus
configurations. We find that satellites with BSS-702 and STAR-2 buses can be
effectively distinguished from the colour measurements on these maps, but
comparing the average colour of individual satellites within given solar
equatorial phase angle ranges shows that it is difficult to distinguish between
bus configurations based on colour alone. We also find tentative evidence to
suggest that there is a relationship between colour and time spent on orbit for
the Eurostar-3000 class satellites, which is unseen behaviour within other bus
configuration classes. The satellites in our sample exhibit `redder' colours
than the Sun, which is in agreement with previous findings. We found common
light curve features such as symmetrical colour changes as well as unique
regions of short timescale glinting which are `bluer' than other regimes within
the colour light curves. If these features are indeed seasonal, this would be a
powerful characterisation tool. We are able to detect and resolve features in
the light curve of the LDPE-3A satellite related to manoeuvres being performed.
Finally, we measured the solar panel offsets of 54 satellites in our sample and
found variation in the type of colour response. The majority of which did not
exhibit any colour change across the solar panel glints compared to them
shifting towards 'redder' or 'bluer' colours.",http://arxiv.org/abs/2502.12324v1
"Exploring QGP-like phenomena with Charmonia in $p+p$ collisions at
  $\sqrt{s} = 13$ TeV",2025-01-01T06:47:29Z,"Captain R. Singh, Partha Bagchi, Raghunath Sahoo, Jan-e Alam","In ultra-relativistic collisions of nuclei at the Large Hadron Collider, the
created QCD environment rapidly changes, leading to a non-adiabatic evolution
of the quantum states involved. Considering this, we first examine the
pre-equilibrium state of QCD matter and its effect on the initially produced
charmonium using a temperature-independent Hamiltonian. As the QCD matter
reaches local thermal equilibrium, this Hamiltonian transforms to its finite
temperature counterpart. To model the pre-equilibrium stage, we use the
bottom-up thermalization approach to determine the effective temperature of the
QCD matter, followed by a Gubser-type expansion for the thermalized medium.
Additionally, we consider collisional damping, gluonic dissociation, and
regeneration mechanisms, which specifically modify the charmonium yield in the
thermalized medium. Mainly, the gluonic dissociation and collisional damping
cause a reduction in the yield conversely, regeneration through gluonic
de-excitation enhances the yield of charmonium. Further, we explore the
combined effects of these mechanisms on the collective yield of charmonium
states with transverse momentum ($p_{\rm T}$) and event multiplicity in the
proton-proton collisions at $\sqrt{s} = 13$ TeV. Based on our findings, we
contend that the combined effects of these mechanisms can serve as a robust
probe for determining the possible existence of a thermalized QCD medium in
such a small collision system.",http://arxiv.org/abs/2501.00753v1
"An AI-powered Bayesian generative modeling approach for causal inference
  in observational studies",2025-01-01T06:52:45Z,"Qiao Liu, Wing Hung Wong","Causal inference in observational studies with high-dimensional covariates
presents significant challenges. We introduce CausalBGM, an AI-powered Bayesian
generative modeling approach that captures the causal relationship among
covariates, treatment, and outcome variables. The core innovation of CausalBGM
lies in its ability to estimate the individual treatment effect (ITE) by
learning individual-specific distributions of a low-dimensional latent feature
set (e.g., latent confounders) that drives changes in both treatment and
outcome. This approach not only effectively mitigates confounding effects but
also provides comprehensive uncertainty quantification, offering reliable and
interpretable causal effect estimates at the individual level. CausalBGM adopts
a Bayesian model and uses a novel iterative algorithm to update the model
parameters and the posterior distribution of latent features until convergence.
This framework leverages the power of AI to capture complex dependencies among
variables while adhering to the Bayesian principles. Extensive experiments
demonstrate that CausalBGM consistently outperforms state-of-the-art methods,
particularly in scenarios with high-dimensional covariates and large-scale
datasets. Its Bayesian foundation ensures statistical rigor, providing robust
and well-calibrated posterior intervals. By addressing key limitations of
existing methods, CausalBGM emerges as a robust and promising framework for
advancing causal inference in modern applications in fields such as genomics,
healthcare, and social sciences. CausalBGM is maintained at the website
https://causalbgm.readthedocs.io/.",http://arxiv.org/abs/2501.00755v1
"Deep UV Silicon Polaritonic Metasurfaces for Enhancing Biomolecule
  Autofluorescence and Two-Dimensional Material Double-Resonance Raman
  Scattering",2025-01-01T07:49:49Z,"Bo-Ray Lee, Mao Feng Chiang, Pei Ying Ho, Kuan-Heng Chen, Jia-Hua Lee, Po Hsiang Hsu, Yu Chieh Peng, Jun-Yi Hou, Shih-Chieh Chen, Qian-Yo Lee, Chun-Hao Chang, Bor-Ran Li, Tzu-En Lin, Chieh-Ting Lin, Min-Hsiung Shih, Der-Hsien Lien, Yu-Chuan Lin, Ray-Hua Horng, Yuri Kivshar, Ming Lun Tseng","High-performance DUV spectroscopy drives advancements in biomedical research,
clinical diagnosis, and material science. Existing DUV resonant nanostructures
face instability and photoluminescent noise challenges. We propose robust Si
metasurfaces leveraging polaritonic resonances, a unique property driven by
interband transitions, for enhanced nanophotonic sensing. Our polaritonic
Kerker-type void metasurface enables double-resonance Raman scattering to
analyze 2D semiconductors, improves biomolecule autofluorescence, and offers
superior stability. This scalable platform unlocks versatile applications in
interdisciplinary DUV spectroscopy and emerging nanomaterials research.",http://arxiv.org/abs/2501.00764v1
"Hybridising Reinforcement Learning and Heuristics for Hierarchical
  Directed Arc Routing Problems",2025-01-01T14:29:54Z,"Van Quang Nguyen, Quoc Chuong Nguyen, Thu Huong Dang, Truong-Son Hy","The Hierarchical Directed Capacitated Arc Routing Problem (HDCARP) is an
extension of the Capacitated Arc Routing Problem (CARP), where the arcs of a
graph are divided into classes based on their priority. The traversal of these
classes is determined by either precedence constraints or a hierarchical
objective, resulting in two distinct HDCARP variants. To the best of our
knowledge, only one matheuristic has been proposed for these variants, but it
performs relatively slowly, particularly for large-scale instances (Ha et al.,
2024). In this paper, we propose a fast heuristic to efficiently address the
computational challenges of HDCARP. Furthermore, we incorporate Reinforcement
Learning (RL) into our heuristic to effectively guide the selection of local
search operators, resulting in a hybrid algorithm. We name this hybrid
algorithm as the Hybrid Reinforcement Learning and Heuristic Algorithm for
Directed Arc Routing (HRDA). The hybrid algorithm adapts to changes in the
problem dynamically, using real-time feedback to improve routing strategies and
solution's quality by integrating heuristic methods. Extensive computational
experiments on artificial instances demonstrate that this hybrid approach
significantly improves the speed of the heuristic without deteriorating the
solution quality. Our source code is publicly available at:
https://github.com/HySonLab/ArcRoute",http://arxiv.org/abs/2501.00852v1
Diffusion Policies for Generative Modeling of Spacecraft Trajectories,2025-01-01T18:22:37Z,"Julia Briden, Breanna Johnson, Richard Linares, Abhishek Cauligi","Machine learning has demonstrated remarkable promise for solving the
trajectory generation problem and in paving the way for online use of
trajectory optimization for resource-constrained spacecraft. However, a key
shortcoming in current machine learning-based methods for trajectory generation
is that they require large datasets and even small changes to the original
trajectory design requirements necessitate retraining new models to learn the
parameter-to-solution mapping. In this work, we leverage compositional
diffusion modeling to efficiently adapt out-of-distribution data and problem
variations in a few-shot framework for 6 degree-of-freedom (DoF) powered
descent trajectory generation. Unlike traditional deep learning methods that
can only learn the underlying structure of one specific trajectory optimization
problem, diffusion models are a powerful generative modeling framework that
represents the solution as a probability density function (PDF) and this allows
for the composition of PDFs encompassing a variety of trajectory design
specifications and constraints. We demonstrate the capability of compositional
diffusion models for inference-time 6 DoF minimum-fuel landing site selection
and composable constraint representations. Using these samples as initial
guesses for 6 DoF powered descent guidance enables dynamically feasible and
computationally efficient trajectory generation.",http://arxiv.org/abs/2501.00915v1
"Topological Insights into Black Hole Thermodynamics: Non-Extensive
  Entropy in CFT framework",2025-01-01T21:15:33Z,"Mohammad Ali S. Afshar, Mohammad Reza Alipour, Saeed Noori Gashti, Jafar Sadeghi","In this paper, We conducted an in-depth investigation into the thermodynamic
topology of Einstein-Gauss-Bonnet black holes within the framework of Conformal
Field Theory (CFT), considering the implications of non-extensive entropy
formulations. Our study reveals that the parameter $\lambda$ (R\'{e}nyi
entropy) plays a crucial role in the phase behavior of black holes.
Specifically, when $\lambda$ is below the critical value (C), it has a
negligible impact on the phase behavior. However, when $\lambda$ exceeds the
critical value, it significantly alters the phase transition outcomes.
Determining the most physically representative values of $\lambda$ will require
experimental validation, but this parameter flexibility allows researchers to
better explain black hole phase transitions under varying physical conditions.
Furthermore, the parameters $\alpha$ and $\beta$ affect the phase structure and
topological charge for the Sharma-Mittal entropy. Only in the case of $C>C_c$
and in the condition of $\alpha\approx\beta$ will we have a first-order phase
transition with topological charge + 1. Additionally, for the loop quantum
gravity non-extensive entropy as the parameter $q$ approaches 1, the
classification of topological charges changes. We observe configurations with
one and three topological charges with respect to critical value $C$, resulting
in a total topological charge $W = +1$, and configurations with two topological
charges $(\omega = +1, -1)$, leading to a total topological charge $W = 0$.
These findings provide new insights into the complex phase behavior and
topological characteristics of black holes in the context of CFT and
non-extensive entropy formulations.",http://arxiv.org/abs/2501.00955v1
"Strain Mediated Voltage Control of Magnetic Anisotropy and Magnetization
  Reversal in Bismuth Substituted Yttrium Iron Garnet Films and Meso-structures",2025-01-01T23:41:06Z,"Walid Al Misba, Miela Josephine Gross, Kensuke Hayashi, Daniel B. Gopman, Caroline A. Ross, Jayasimha Atulasimha","We report on magnetic anisotropy modulation in Bismuth substituted Yttrium
Iron Garnet (Bi-YIG) thin films and mesoscale patterned structures deposited on
a PMN-PT substrate with the application of voltage-induced strain. The Bi
content is selected for low coercivity and higher magnetostriction than that of
YIG, yielding significant changes in the hysteresis loops through the
magnetoelastic effect. The piezoelectric substrate is poled along its
thickness, which is the [011] direction, by applying a voltage across the
PMN-PT/SiO2/Bi-YIG/Pt heterostructure. In-situ magneto-optical Kerr effect
microscopy (MOKE) shows the modulation of magnetic anisotropy with
voltage-induced strain. Furthermore, voltage control of the magnetic domain
state of the Bi-YIG film at a fixed magnetic field produces a 90{\deg}
switching of the magnetization easy axis above a threshold voltage. The
magnetoelectric coefficient of the heterostructure is 1.05x10^(-7)s/m which is
competitive with that of other ferromagnetic oxide films on ferroelectric
substrates such as La0.67Sr0.33MnO3/PMNPT and YIG/PMN-PZT. Voltage-control of
magnetization reversal fields in 5-30 microns wide dots and racetracks of
Bi-YIG show potential for energy efficient non-volatile memory and neuromorphic
computing devices.",http://arxiv.org/abs/2501.00980v1
"Deep Reinforcement Learning for Job Scheduling and Resource Management
  in Cloud Computing: An Algorithm-Level Review",2025-01-02T02:08:00Z,"Yan Gu, Zhaoze Liu, Shuhong Dai, Cong Liu, Ying Wang, Shen Wang, Georgios Theodoropoulos, Long Cheng","Cloud computing has revolutionized the provisioning of computing resources,
offering scalable, flexible, and on-demand services to meet the diverse
requirements of modern applications. At the heart of efficient cloud operations
are job scheduling and resource management, which are critical for optimizing
system performance and ensuring timely and cost-effective service delivery.
However, the dynamic and heterogeneous nature of cloud environments presents
significant challenges for these tasks, as workloads and resource availability
can fluctuate unpredictably. Traditional approaches, including heuristic and
meta-heuristic algorithms, often struggle to adapt to these real-time changes
due to their reliance on static models or predefined rules. Deep Reinforcement
Learning (DRL) has emerged as a promising solution to these challenges by
enabling systems to learn and adapt policies based on continuous observations
of the environment, facilitating intelligent and responsive decision-making.
This survey provides a comprehensive review of DRL-based algorithms for job
scheduling and resource management in cloud computing, analyzing their
methodologies, performance metrics, and practical applications. We also
highlight emerging trends and future research directions, offering valuable
insights into leveraging DRL to advance both job scheduling and resource
management in cloud computing.",http://arxiv.org/abs/2501.01007v1
"Event Masked Autoencoder: Point-wise Action Recognition with Event-Based
  Cameras",2025-01-02T03:49:03Z,"Jingkai Sun, Qiang Zhang, Jiaxu Wang, Jiahang Cao, Renjing Xu","Dynamic vision sensors (DVS) are bio-inspired devices that capture visual
information in the form of asynchronous events, which encode changes in pixel
intensity with high temporal resolution and low latency. These events provide
rich motion cues that can be exploited for various computer vision tasks, such
as action recognition. However, most existing DVS-based action recognition
methods lose temporal information during data transformation or suffer from
noise and outliers caused by sensor imperfections or environmental factors. To
address these challenges, we propose a novel framework that preserves and
exploits the spatiotemporal structure of event data for action recognition. Our
framework consists of two main components: 1) a point-wise event masked
autoencoder (MAE) that learns a compact and discriminative representation of
event patches by reconstructing them from masked raw event camera points data;
2) an improved event points patch generation algorithm that leverages an event
data inlier model and point-wise data augmentation techniques to enhance the
quality and diversity of event points patches. To the best of our knowledge,
our approach introduces the pre-train method into event camera raw points data
for the first time, and we propose a novel event points patch embedding to
utilize transformer-based models on event cameras.",http://arxiv.org/abs/2501.01040v1
"Studying the $B^{0} \to J/ψh_{1}$ decays with
  $h_{1}(1170)-h_{1}(1415)$ mixing in the perturbative QCD approach",2025-01-02T05:46:52Z,"Qin Chang, De-Hua Yao, Xin Liu","In this paper, we study the $B^{0} \to J/\psi h_{1}$ decays for the first
time by using perturbative QCD approach up to the presently known
next-to-leading order accuracy. The vertex corrections present significant
contribution to the amplitude. In the calculation, the mixing between two light
axial-vector mesons $h_{1}(1170)$ and $h_{1}(1415)$ are also studied in detail.
The observables including the branching ratios, polarization fractions and $CP$
asymmetries are predicted and discussed explicitly. It is found that the $B^{0}
\to J/\psi h_{1}$ decays have relatively large branching fractions, which are
generally at the order of ${\cal O}(10^{-6}\sim10^{-3})$, and thus are possible
to be observed by the LHCb and Belle-II experiments in the near future.
Moreover, they are very sensitive to the mixing angle $\theta$ and can be used
to test the values of $\theta$. In addition, some ratios between the branching
fractions of $B^{0} \to J/\psi h_{1}$ decays can provide much stronger
constraints on $\theta$ due to their relatively small theoretical errors. The
$B^{0} \to J/\psi h_{1}$ decays are generally dominated by the longitudinal
polarization contributions, specifically, $f_{L}(B^{0} \to J/\psi h_{1})>80\%$,
except for the case that $\theta\sim 35^\circ$ and $-55^\circ$. Unfortunately,
the direct $CP$ asymmetries of $B^{0} \to J/\psi h_{1}$ decays are too small to
be observed soon even if the effect of $\theta$ is considered. The future
precise measurements on $B^{0} \to J/\psi h_{1}$ decays are expected for
testing these theoretical findings and exploring the interesting nature of
$h_{1}(1170)$ and $h_{1}(1415)$.",http://arxiv.org/abs/2501.01075v2
"The effect of turbulence, gravity, and non-continuum hydrodynamic
  interactions on the drop size distribution in clouds",2025-01-02T06:07:58Z,"Johnson Dhanasekaran, Donald. L. Koch","The evolution of micron-sized droplets in clouds is studied with focus on the
'size-gap' regime of 15-40 $\mu m$ radius, where condensation and differential
sedimentation are least effective in promoting growth. This bottleneck leads to
inaccurate growth models and turbulence can potentially rectify disagreement
with in-situ cloud measurements. The role of turbulent collisions, mixing of
droplets, and water vapour fluctuations in crossing the 'size-gap' has been
analysed in detail. Collisions driven by the coupled effects of turbulent shear
and differential sedimentation are shown to grow drizzle sized droplets. Growth
is also promoted by turbulence-induced water vapour fluctuations, which
maintain polydispersity during the initial condensation driven growth and
facilitate subsequent growth by differential sedimentation driven coalescence.
The collision rate of droplets is strongly influenced by non-continuum
hydrodynamics and so the size evolution beyond the condensation regime is found
to be very sensitive to the mean free path of air. Turbulence-induced inertial
clustering leads to a moderate enhancement in the growth rate but the
intermittency of the turbulent shear rate does not change the coalescence rate
significantly. The coupled influence of all these phenomena is evaluated by
evolving a large number of droplets within an adiabatically rising parcel of
air using a Monte Carlo scheme that captures turbulent intermittency and
mixing.",http://arxiv.org/abs/2501.01086v1
"A Sysmon Incremental Learning System for Ransomware Analysis and
  Detection",2025-01-02T06:22:58Z,"Jamil Ispahany, MD Rafiqul Islam, M. Arif Khan, MD Zahidul Islam","In the face of increasing cyber threats, particularly ransomware attacks,
there is a pressing need for advanced detection and analysis systems that adapt
to evolving malware behaviours. Throughout the literature, using machine
learning (ML) to obviate ransomware attacks has increased in popularity.
Unfortunately, most of these proposals leverage non-incremental learning
approaches that require the underlying models to be updated from scratch to
detect new ransomware, wasting time and resources. This approach is problematic
because it leaves sensitive data vulnerable to attack during retraining, as
newly emerging ransomware strains may go undetected until the model is updated.
Furthermore, most of these approaches are not designed to detect ransomware in
real-time data streams, limiting their effectiveness in complex network
environments. To address this challenge, we present the Sysmon Incremental
Learning System for Ransomware Analysis and Detection (SILRAD), which enables
continuous updates to the underlying model and effectively closes the training
gap. By leveraging the capabilities of Sysmon for detailed monitoring of system
activities, our approach integrates online incremental learning techniques to
enhance the adaptability and efficiency of ransomware detection. The most
valuable features for detection were selected using the Pearson Correlation
Coefficient (PCC), and concept drift detection was implemented through the
ADWIN algorithm, ensuring that the model remains responsive to changes in
ransomware behaviour. We compared our results to other popular techniques, such
as Hoeffding Trees (HT) and Leveraging Bagging Classifier (LB), observing a
detection accuracy of 98.89% and a Matthews Correlation Coefficient (MCC) rate
of 94.11%, demonstrating the effectiveness of our technique.",http://arxiv.org/abs/2501.01089v1
"Deformable Gaussian Splatting for Efficient and High-Fidelity
  Reconstruction of Surgical Scenes",2025-01-02T06:50:25Z,"Jiwei Shan, Zeyu Cai, Cheng-Tai Hsieh, Shing Shin Cheng, Hesheng Wang","Efficient and high-fidelity reconstruction of deformable surgical scenes is a
critical yet challenging task. Building on recent advancements in 3D Gaussian
splatting, current methods have seen significant improvements in both
reconstruction quality and rendering speed. However, two major limitations
remain: (1) difficulty in handling irreversible dynamic changes, such as tissue
shearing, which are common in surgical scenes; and (2) the lack of hierarchical
modeling for surgical scene deformation, which reduces rendering speed. To
address these challenges, we introduce EH-SurGS, an efficient and high-fidelity
reconstruction algorithm for deformable surgical scenes. We propose a
deformation modeling approach that incorporates the life cycle of 3D Gaussians,
effectively capturing both regular and irreversible deformations, thus
enhancing reconstruction quality. Additionally, we present an adaptive motion
hierarchy strategy that distinguishes between static and deformable regions
within the surgical scene. This strategy reduces the number of 3D Gaussians
passing through the deformation field, thereby improving rendering speed.
Extensive experiments demonstrate that our method surpasses existing
state-of-the-art approaches in both reconstruction quality and rendering speed.
Ablation studies further validate the effectiveness and necessity of our
proposed components. We will open-source our code upon acceptance of the paper.",http://arxiv.org/abs/2501.01101v1
"From Interaction to Attitude: Exploring the Impact of Human-AI
  Cooperation on Mental Illness Stigma",2025-01-02T12:08:57Z,"Tianqi Song, Jack Jamieson, Tianwen Zhu, Naomi Yamashita, Yi-Chieh Lee","AI conversational agents have demonstrated efficacy in social contact
interventions for stigma reduction at a low cost. However, the underlying
mechanisms of how interaction designs contribute to these effects remain
unclear. This study investigates how participating in three human-chatbot
interactions affects attitudes toward mental illness. We developed three
chatbots capable of engaging in either one-way information dissemination from
chatbot to a human or two-way cooperation where the chatbot and a human
exchange thoughts and work together on a cooperation task. We then conducted a
two-week mixed-methods study to investigate variations over time and across
different group memberships. The results indicate that human-AI cooperation can
effectively reduce stigma toward individuals with mental illness by fostering
relationships between humans and AI through social contact. Additionally,
compared to a one-way chatbot, interacting with a cooperative chatbot led
participants to perceive it as more competent and likable, promoting greater
empathy during the conversation. However, despite the success in reducing
stigma, inconsistencies between the chatbot's role and the mental health
context raised concerns. We discuss the implications of our findings for
human-chatbot interaction designs aimed at changing human attitudes.",http://arxiv.org/abs/2501.01220v1
Does a Large Language Model Really Speak in Human-Like Language?,2025-01-02T14:13:44Z,"Mose Park, Yunjin Choi, Jong-June Jeon","Large Language Models (LLMs) have recently emerged, attracting considerable
attention due to their ability to generate highly natural, human-like text.
This study compares the latent community structures of LLM-generated text and
human-written text within a hypothesis testing procedure. Specifically, we
analyze three text sets: original human-written texts ($\mathcal{O}$), their
LLM-paraphrased versions ($\mathcal{G}$), and a twice-paraphrased set
($\mathcal{S}$) derived from $\mathcal{G}$. Our analysis addresses two key
questions: (1) Is the difference in latent community structures between
$\mathcal{O}$ and $\mathcal{G}$ the same as that between $\mathcal{G}$ and
$\mathcal{S}$? (2) Does $\mathcal{G}$ become more similar to $\mathcal{O}$ as
the LLM parameter controlling text variability is adjusted? The first question
is based on the assumption that if LLM-generated text truly resembles human
language, then the gap between the pair ($\mathcal{O}$, $\mathcal{G}$) should
be similar to that between the pair ($\mathcal{G}$, $\mathcal{S}$), as both
pairs consist of an original text and its paraphrase. The second question
examines whether the degree of similarity between LLM-generated and human text
varies with changes in the breadth of text generation. To address these
questions, we propose a statistical hypothesis testing framework that leverages
the fact that each text has corresponding parts across all datasets due to
their paraphrasing relationship. This relationship enables the mapping of one
dataset's relative position to another, allowing two datasets to be mapped to a
third dataset. As a result, both mapped datasets can be quantified with respect
to the space characterized by the third dataset, facilitating a direct
comparison between them. Our results indicate that GPT-generated text remains
distinct from human-authored text.",http://arxiv.org/abs/2501.01273v1
Marketing Mix Modeling in Lemonade,2025-01-02T14:17:31Z,Roy Ravid,"Marketing mix modeling (MMM) is a widely used method to assess the
effectiveness of marketing campaigns and optimize marketing strategies.
Bayesian MMM is an advanced approach that allows for the incorporation of prior
information, uncertainty quantification, and probabilistic predictions (1). In
this paper, we describe the process of building a Bayesian MMM model for the
online insurance company Lemonade. We first collected data on Lemonade's
marketing activities, such as online advertising, social media, and brand
marketing, as well as performance data. We then used a Bayesian framework to
estimate the contribution of each marketing channel on total performance, while
accounting for various factors such as seasonality, market trends, and
macroeconomic indicators. To validate the model, we compared its predictions
with the actual performance data from A/B-testing and sliding window holdout
data (2). The results showed that the predicted contribution of each marketing
channel is aligned with A/B test performance and is actionable. Furthermore, we
conducted several scenario analyses using convex optimization to test the
sensitivity of the model to different assumptions and to evaluate the impact of
changes in the marketing mix on sales. The insights gained from the model
allowed Lemonade to adjust their marketing strategy and allocate their budget
more effectively. Our case study demonstrates the benefits of using Bayesian
MMM for marketing attribution and optimization in a data-driven company like
Lemonade. The approach is flexible, interpretable, and can provide valuable
insights for decision-making.",http://arxiv.org/abs/2501.01276v1
"Tracking behavioural differences across chronotypes: A case study in
  Finland using Oura rings",2025-01-02T17:02:28Z,"Chandreyee Roy, Kunal Bhattacharya, Kimmo Kaski","Non-invasive mobile wearables like fitness trackers, smart watches and rings
allow an easy and less expensive approach to study everyday human behaviour.
This alternative approach not only supplements clinical studies, but also
provides an opportunity to overcome some of the limitations in them. One of the
major challenges faced by them is studying long-term human health and behaviour
in realistic settings. Here we have utilised Oura rings to obtain granular data
from nineteen healthy participants over the span of one year (October 2023 -
September 2024) along with monthly surveys for nine months to track their
subjective stress within the duration of the study. We have studied
longitudinal sleep and activity patterns of three chronotype groups of
participating individuals: morning type (MT), neither type (NT) and evening
type (ET). We find that while ET individuals do not seem to lead as healthy
life as the MT or NT individuals, they have seemingly improved their habits
during the duration of the study. We also show that the Daylight Saving Time
changes affect the chronotypes differently. Finally, by utilising mixed effects
regression model, we have shown that the stress an individual experiences has a
significant correlation with his or her total sleep duration, monthly survey
response time, and age.",http://arxiv.org/abs/2501.01350v1
"A flow-kick model of dryland vegetation patterns: the impact of rainfall
  variability on resilience",2025-01-02T23:07:25Z,"Punit Gandhi, Matthew Oline, Mary Silber","In many drylands around the globe, vegetation self-organizes into regular
spatial patterns in response to aridity stress. We consider the
regularly-spaced vegetation bands, on gentle hill-slopes, that survive low
rainfall conditions by harvesting additional stormwater from upslope
low-infiltration bare zones. We are interested in the robustness of this
pattern formation survival mechanism to changes in rainfall variability. For
this, we use a flow-kick modeling framework that treats storms as instantaneous
kicks to the soil water. The positive feedbacks in the storm-level hydrology,
that act to concentrate water within the vegetation bands, are captured through
the spatial profiles of the soil water kicks. Between storms, the soil water
and vegetation, modeled by a two-component reaction-diffusion system, evolve
together. We use a combination of linear stability analysis and numerical
simulation to compare predictions of idealized periodic rainfall, with no
variability, to predictions when there is randomness in the timing and
magnitude of water input from storms. We show that including these random
elements leads to a decrease in the parameter range over which patterns appear.
This suggests that an increase in storm variability, even with the same mean
annual rainfall, may negatively impact the resilience of these pattern-forming
dryland ecosystems.",http://arxiv.org/abs/2501.01569v1
"Prism: Mining Task-aware Domains in Non-i.i.d. IMU Data for Flexible
  User Perception",2025-01-03T02:07:42Z,"Yunzhe Li, Facheng Hu, Hongzi Zhu, Quan Liu, Xiaoke Zhao, Jiangang Shen, Shan Chang, Minyi Guo","A wide range of user perception applications leverage inertial measurement
unit (IMU) data for online prediction. However, restricted by the non-i.i.d.
nature of IMU data collected from mobile devices, most systems work well only
in a controlled setting (e.g., for a specific user in particular postures),
limiting application scenarios. To achieve uncontrolled online prediction on
mobile devices, referred to as the flexible user perception (FUP) problem, is
attractive but hard. In this paper, we propose a novel scheme, called Prism,
which can obtain high FUP accuracy on mobile devices. The core of Prism is to
discover task-aware domains embedded in IMU dataset, and to train a
domain-aware model on each identified domain. To this end, we design an
expectation-maximization (EM) algorithm to estimate latent domains with respect
to the specific downstream perception task. Finally, the best-fit model can be
automatically selected for use by comparing the test sample and all identified
domains in the feature space. We implement Prism on various mobile devices and
conduct extensive experiments. Results demonstrate that Prism can achieve the
best FUP performance with a low latency.",http://arxiv.org/abs/2501.01598v1
"Online Meta-Learning Channel Autoencoder for Dynamic End-to-end Physical
  Layer Optimization",2025-01-03T02:58:22Z,"Ali Owfi, Jonathan Ashdown, Kurt Turck, Fatemeh Afghah","Channel Autoencoders (CAEs) have shown significant potential in optimizing
the physical layer of a wireless communication system for a specific channel
through joint end-to-end training. However, the practical implementation of
CAEs faces several challenges, particularly in realistic and dynamic scenarios.
Channels in communication systems are dynamic and change with time. Still, most
proposed CAE designs assume stationary scenarios, meaning they are trained and
tested for only one channel realization without regard for the dynamic nature
of wireless communication systems. Moreover, conventional CAEs are designed
based on the assumption of having access to a large number of pilot signals,
which act as training samples in the context of CAEs. However, in real-world
applications, it is not feasible for a CAE operating in real-time to acquire
large amounts of training samples for each new channel realization. Hence, the
CAE has to be deployable in few-shot learning scenarios where only limited
training samples are available. Furthermore, most proposed conventional CAEs
lack fast adaptability to new channel realizations, which becomes more
pronounced when dealing with a limited number of pilots. To address these
challenges, this paper proposes the Online Meta Learning channel AE (OML-CAE)
framework for few-shot CAE scenarios with dynamic channels. The OML-CAE
framework enhances adaptability to varying channel conditions in an online
manner, allowing for dynamic adjustments in response to evolving communication
scenarios. Moreover, it can adapt to new channel conditions using only a few
pilots, drastically increasing pilot efficiency and making the CAE design
feasible in realistic scenarios.",http://arxiv.org/abs/2501.01608v1
"VidFormer: A novel end-to-end framework fused by 3DCNN and Transformer
  for Video-based Remote Physiological Measurement",2025-01-03T08:18:08Z,"Jiachen Li, Shisheng Guo, Longzhen Tang, Cuolong Cui, Lingjiang Kong, Xiaobo Yang","Remote physiological signal measurement based on facial videos, also known as
remote photoplethysmography (rPPG), involves predicting changes in facial
vascular blood flow from facial videos. While most deep learning-based methods
have achieved good results, they often struggle to balance performance across
small and large-scale datasets due to the inherent limitations of convolutional
neural networks (CNNs) and Transformer. In this paper, we introduce VidFormer,
a novel end-to-end framework that integrates 3-Dimension Convolutional Neural
Network (3DCNN) and Transformer models for rPPG tasks. Initially, we conduct an
analysis of the traditional skin reflection model and subsequently introduce an
enhanced model for the reconstruction of rPPG signals. Based on this improved
model, VidFormer utilizes 3DCNN and Transformer to extract local and global
features from input data, respectively. To enhance the spatiotemporal feature
extraction capabilities of VidFormer, we incorporate temporal-spatial attention
mechanisms tailored for both 3DCNN and Transformer. Additionally, we design a
module to facilitate information exchange and fusion between the 3DCNN and
Transformer. Our evaluation on five publicly available datasets demonstrates
that VidFormer outperforms current state-of-the-art (SOTA) methods. Finally, we
discuss the essential roles of each VidFormer module and examine the effects of
ethnicity, makeup, and exercise on its performance.",http://arxiv.org/abs/2501.01691v2
"Optimal Fiducial Marker Placement for Satellite Proximity Operations
  Using Observability Gramians",2025-01-03T09:03:48Z,"Nicholas B. Andrews, Kristi A. Morgansen","This paper investigates optimal fiducial marker placement on the surface of a
satellite performing relative proximity operations with an observer satellite.
The absolute and relative translation and attitude equations of motion for the
satellite pair are modeled using dual quaternions. The observability of the
relative dual quaternion system is analyzed using empirical observability
Gramian methods. The optimal placement of a fiducial marker set, in which each
marker gives simultaneous optical range and attitude measurements, is
determined for the pair of satellites. A geostationary flyby between the
observing body (chaser) and desired (target) satellites is numerically
simulated and the optimal fiducial placement sets of five and ten on the
surface of the desired satellite are solved. It is shown that the optimal
solution maximizes the distance between fiducial markers and selects marker
locations that are most sensitive to measuring changes in the state during the
nonlinear trajectory, despite being visible for less time than other candidate
marker locations. Definitions and properties of quaternions and dual
quaternions, and parallels between the two, are presented alongside the
relative motion model.",http://arxiv.org/abs/2501.01704v1
"Quasi-two-dimensional magnetism and antiferromagnetic ground state in
  Li$_2$FeSiO$_4$",2025-01-03T11:13:20Z,"W. Hergett, N. Bouldi, M. Jonak, C. Neef, C. Ritter, M. Abdel-Hafiez, F. Seewald, H. -H. Klauss, M. W. -Haverkort, R. Klingeler","Our experimental (neutron diffraction, M\""ossbauer spectroscopy, magnetic
susceptibility, specific heat) and numerical studies on the evolution of short-
and long-range magnetic order in $\gamma_{\rm II}$-Li\(_2\)FeSiO\(_4\) suggest
a quasi-two-dimensional (2D) nature of magnetism. The experimental data
obtained on single crystals imply long-range antiferromagnetic order below
$T_{\rm N}= 17$~K. A broad maximum in magnetic susceptibility $\chi$ at $T_{\rm
m}\simeq 28$~K, observation of magnetic entropy changes up to 100~K and
anisotropy in $\chi$ are indicative of low-dimensional magnetism and suggest
short-range magnetic correlations up to 200~K. Neutron diffraction shows that
long-range antiferromagnetic order is characterised by the propagation vector
k=(1/2,0,1/2). The ordered moment $\mu = 2.50(2) \mu_B$ /Fe, at $T = 1.5$~K, is
along the crystallographic $a$-axis. This is consistent with the observed
static hyperfine field of $B_{\rm hyp}=14.8(3)$\,T by M\""ossbauer spectroscopy
which indicates significant orbital contributions. The temperature dependence
of $B_{\rm hyp}$ yields the critical exponent $\beta=0.116(12)$ which is in the
regime of the 2D Ising behaviour. LSDA+U studies exploiting the experimental
spin structure suggest dominating magnetic exchange coupling within the
$ac$-layers (i.e., $J_3\simeq -6$~K and $J_6\simeq-2$~K) while interlayer
coupling is much smaller and partly frustrated. This confirms the 2D nature of
magnetism and is in full agreement with the experimental findings.",http://arxiv.org/abs/2501.01758v1
Leveraging Sustainable Systematic Literature Reviews,2025-01-03T14:03:15Z,"Vinicius dos Santos, Rick Kazman, Elisa Yumi Nakagawa","Systematic Literature Reviews (SLRs) are a widely employed research method in
software engineering. However, there are several problems with SLRs, including
the enormous time and effort to conduct them and the lack of obvious impacts of
SLR results on software engineering practices and industry projects. To address
these problems, the concepts of \textit{sustainability} and \textit{sustainable
SLR} have been proposed, aiming to raise awareness among researchers about the
importance of dealing with SLR problems in a consistent way; however, practical
and concrete actions are still lacking. This paper presents concrete directions
towards sustainable SLRs. We first identified 18 ``green drivers'' (GD) that
could directly impact SLR sustainability, and we distilled 25 sustainability
indicators (SI) associated with the GD to assess SLRs regarding their
sustainability. A preliminary evaluation was conducted on the ten top-cited
SLRs in software engineering published over the last decade. From this
analysis, we synthesized our insights into 12 leverage points for
sustainability. Our results indicate that even in high-quality reviews, there
are threats to sustainability, such as: flaws in the search process, lack of
essential details in the documentation, weak collaboration with stakeholders,
poor knowledge management, lack of use of supporting tools, and a dearth of
practical insights for software engineering practitioners. The good news is
that moving towards sustainable SLRs only requires some simple actions, which
can pave the way for a profound change in the software engineering community's
mindset about how to create and sustain SLRs.",http://arxiv.org/abs/2501.01819v1
"Age-Based Device Selection and Transmit Power Optimization in
  Over-the-Air Federated Learning",2025-01-03T14:27:13Z,"Jingyuan Liu, Zheng Chang, Ying-Chang Liang","Recently, over-the-air federated learning (FL) has attracted significant
attention for its ability to enhance communication efficiency. However, the
performance of over-the-air FL is often constrained by device selection
strategies and signal aggregation errors. In particular, neglecting straggler
devices in FL can lead to a decline in the fairness of model updates and
amplify the global model's bias toward certain devices' data, ultimately
impacting the overall system performance. To address this issue, we propose a
joint device selection and transmit power optimization framework that ensures
the appropriate participation of straggler devices, maintains efficient
training performance, and guarantees timely updates. First, we conduct a
theoretical analysis to quantify the convergence upper bound of over-the-air FL
under age-of-information (AoI)-based device selection. Our analysis further
reveals that both the number of selected devices and the signal aggregation
errors significantly influence the convergence upper bound. To minimize the
expected weighted sum peak age of information, we calculate device priorities
for each communication round using Lyapunov optimization and select the
highest-priority devices via a greedy algorithm. Then, we formulate and solve a
transmit power and normalizing factor optimization problem for selected devices
to minimize the time-average mean squared error (MSE). Experimental results
demonstrate that our proposed method offers two significant advantages: (1) it
reduces MSE and improves model performance compared to baseline methods, and
(2) it strikes a balance between fairness and training efficiency while
maintaining satisfactory timeliness, ensuring stable model performance.",http://arxiv.org/abs/2501.01828v1
"A self-learning magnetic Hopfield neural network with intrinsic gradient
  descent adaption",2025-01-03T15:08:06Z,"Chang Niu, Huanyu Zhang, Chuanlong Xu, Wenjie Hu, Yunzhuo Wu, Yu Wu, Yadi Wang, Tong Wu, Yi Zhu, Yinyan Zhu, Wenbin Wang, Yizheng Wu, Lifeng Yin, Jiang Xiao, Weichao Yu, Hangwen Guo, Jian Shen","Physical neural networks using physical materials and devices to mimic
synapses and neurons offer an energy-efficient way to implement artificial
neural networks. Yet, training physical neural networks are difficult and
heavily relies on external computing resources. An emerging concept to solve
this issue is called physical self-learning that uses intrinsic physical
parameters as trainable weights. Under external inputs (i.e. training data),
training is achieved by the natural evolution of physical parameters that
intrinsically adapt modern learning rules via autonomous physical process,
eliminating the requirements on external computation resources.Here, we
demonstrate a real spintronic system that mimics Hopfield neural networks (HNN)
and unsupervised learning is intrinsically performed via the evolution of
physical process. Using magnetic texture defined conductance matrix as
trainable weights, we illustrate that under external voltage inputs, the
conductance matrix naturally evolves and adapts Oja's learning algorithm in a
gradient descent manner. The self-learning HNN is scalable and can achieve
associative memories on patterns with high similarities. The fast spin dynamics
and reconfigurability of magnetic textures offer an advantageous platform
towards efficient autonomous training directly in materials.",http://arxiv.org/abs/2501.01853v2
"Identification of the interstellar 1-cyano propargyl radical (HCCCHCN)
  in TMC-1",2025-01-03T18:24:14Z,"C. Cabezas, M. Agúndez, N. Marcelino, C. H. Chang, R. Fuentetaja, B. Tercero, M. Nakajima, Y. Endo, P. de Vicente, J. Cernicharo","We report the first detection in interstellar medium of the 1-cyano propargyl
radical, HC$_3$HCN. This species is an isomer of the 3-cyano propargyl radical
(CH$_2$C$_3$N), which was recently discovered in TMC-1. The 1-cyano propargyl
radical was observed in the cold dark cloud TMC-1 using data from the ongoing
QUIJOTE line survey, which is being carried out with the Yebes 40m telescope. A
total of seven rotational transitions with multiple hyperfine components were
detected in the 31.0-50.4 GHz range. We derived a column density of
(2.2$\pm$0.2)$\times$10$^{11}$ cm$^{-2}$ and a rotational temperature of
7$\pm$1\,K. The abundance ratio between HC$_3$HCN and CH$_2$C$_3$N is 1.4. The
almost equal abundance of these isomers indicates that the two species may be
produced in the same reaction with a similar efficiency, probably in the
reaction C + CH$_2$CHCN and perhaps also in the reaction C$_2$ + CH$_3$CN and
the dissociative recombination with electrons of CH$_2$C$_3$NH$^+$",http://arxiv.org/abs/2501.01938v1
"Machine Learning-Based Differential Diagnosis of Parkinson's Disease
  Using Kinematic Feature Extraction and Selection",2025-01-02T14:43:39Z,"Masahiro Matsumoto, Abu Saleh Musa Miah, Nobuyoshi Asai, Jungpil Shin","Parkinson's disease (PD), the second most common neurodegenerative disorder,
is characterized by dopaminergic neuron loss and the accumulation of abnormal
synuclein. PD presents both motor and non-motor symptoms that progressively
impair daily functioning. The severity of these symptoms is typically assessed
using the MDS-UPDRS rating scale, which is subjective and dependent on the
physician's experience. Additionally, PD shares symptoms with other
neurodegenerative diseases, such as progressive supranuclear palsy (PSP) and
multiple system atrophy (MSA), complicating accurate diagnosis. To address
these diagnostic challenges, we propose a machine learning-based system for
differential diagnosis of PD, PSP, MSA, and healthy controls (HC). This system
utilizes a kinematic feature-based hierarchical feature extraction and
selection approach. Initially, 18 kinematic features are extracted, including
two newly proposed features: Thumb-to-index vector velocity and acceleration,
which provide insights into motor control patterns. In addition, 41 statistical
features were extracted here from each kinematic feature, including some new
approaches such as Average Absolute Change, Rhythm, Amplitude, Frequency,
Standard Deviation of Frequency, and Slope. Feature selection is performed
using One-way ANOVA to rank features, followed by Sequential Forward Floating
Selection (SFFS) to identify the most relevant ones, aiming to reduce the
computational complexity. The final feature set is used for classification,
achieving a classification accuracy of 66.67% for each dataset and 88.89% for
each patient, with particularly high performance for the MSA and HC groups
using the SVM algorithm. This system shows potential as a rapid and accurate
diagnostic tool in clinical practice, though further data collection and
refinement are needed to enhance its reliability.",http://arxiv.org/abs/2501.02014v1
"Towards Robust and Accurate Stability Estimation of Local Surrogate
  Models in Text-based Explainable AI",2025-01-03T17:44:57Z,"Christopher Burger, Charles Walter, Thai Le, Lingwei Chen","Recent work has investigated the concept of adversarial attacks on
explainable AI (XAI) in the NLP domain with a focus on examining the
vulnerability of local surrogate methods such as Lime to adversarial
perturbations or small changes on the input of a machine learning (ML) model.
In such attacks, the generated explanation is manipulated while the meaning and
structure of the original input remain similar under the ML model. Such attacks
are especially alarming when XAI is used as a basis for decision making (e.g.,
prescribing drugs based on AI medical predictors) or for legal action (e.g.,
legal dispute involving AI software). Although weaknesses across many XAI
methods have been shown to exist, the reasons behind why remain little
explored. Central to this XAI manipulation is the similarity measure used to
calculate how one explanation differs from another. A poor choice of similarity
measure can lead to erroneous conclusions about the stability or adversarial
robustness of an XAI method. Therefore, this work investigates a variety of
similarity measures designed for text-based ranked lists referenced in related
work to determine their comparative suitability for use. We find that many
measures are overly sensitive, resulting in erroneous estimates of stability.
We then propose a weighting scheme for text-based data that incorporates the
synonymity between the features within an explanation, providing more accurate
estimates of the actual weakness of XAI methods to adversarial examples.",http://arxiv.org/abs/2501.02042v1
Instruction-Following Pruning for Large Language Models,2025-01-03T20:19:14Z,"Bairu Hou, Qibin Chen, Jianyu Wang, Guoli Yin, Chong Wang, Nan Du, Ruoming Pang, Shiyu Chang, Tao Lei","With the rapid scaling of large language models (LLMs), structured pruning
has become a widely used technique to learn efficient, smaller models from
larger ones, delivering superior performance compared to training similarly
sized models from scratch. In this paper, we move beyond the traditional static
pruning approach of determining a fixed pruning mask for a model, and propose a
dynamic approach to structured pruning. In our method, the pruning mask is
input-dependent and adapts dynamically based on the information described in a
user instruction. Our approach, termed ""instruction-following pruning"",
introduces a sparse mask predictor that takes the user instruction as input and
dynamically selects the most relevant model parameters for the given task. To
identify and activate effective parameters, we jointly optimize the sparse mask
predictor and the LLM, leveraging both instruction-following data and the
pre-training corpus. Experimental results demonstrate the effectiveness of our
approach on a wide range of evaluation benchmarks. For example, our 3B
activated model improves over the 3B dense model by 5-8 points of absolute
margin on domains such as math and coding, and rivals the performance of a 9B
model.",http://arxiv.org/abs/2501.02086v2
Optimally time-dependent modes of vortex gust-airfoil interactions,2025-01-03T20:44:06Z,"Yonghong Zhong, Alireza Amiri-Margavi, Hessam Babaee, Kunihiko Taira","We find the optimally time-dependent (OTD) orthogonal modes about a
time-varying flow generated by a strong gust vortex impacting a NACA 0012
airfoil. This OTD analysis reveals the amplification characteristics of
perturbations about the unsteady base flow and their amplified spatiotemporal
structures that evolve over time. We consider four time-varying laminar base
flows in which a vortex with a strength corresponding to the gust ratio $G$ of
$\{-1,-0.5,0.5,1\}$ impinges on the leading edge of the airfoil at an angle of
attack of $12^\circ$. In these cases, the impingement of the strong gust vortex
causes massive separation and the generation of large-scale vortices around the
airfoil within two convective time units. The highly unsteady nature of these
vortex-airfoil interactions necessitates an advanced analytical technique
capable of capturing the transient perturbation dynamics. For each of the
considered gust ratios, the OTD analysis identifies the most amplified region
to perturbations, the location of which changes as the wake evolves
differently. For interactions between a moderate positive vortex gust ($G=0.5$)
and the airfoil, the area where perturbations are amplified transitions from
the leading-edge vortex sheet to the forming leading-edge vortex. Later, this
most amplified structure becomes supported in the airfoil wake directly behind
the trailing edge. In contrast, a strong vortex gust ($G=\pm 1$) encountered by
the airfoil shows the most amplified OTD mode to appear around the core of the
shed vortices. This study provides an analysis technique and fundamental
insights into the broader family of unsteady aerodynamic problems.",http://arxiv.org/abs/2501.02095v1
"Role of internal space correlations in the dynamics of a
  higher-dimensional Bianchi type-I universe: shear scalar and Hubble parameter
  perspectives",2025-01-03T21:31:28Z,Nihan Katırcı,"We investigate exact solutions of the Einstein field equations in
higher-dimensional, spatially homogeneous Bianchi type-I spacetimes,
introducing a real parameter $\lambda$ that correlates the expansion rates of
external and internal spaces. Extending beyond Robertson--Walker spacetime, our
approach includes positive and negative correlations, suggesting a broader and
isotropic/anisotropic cosmological model space. Positively correlated
dimensions manifest as a cosmological constant at late times, while at early
times, they mimic stiff-fluid-like dark energy that dilutes faster than
radiation, paralleling early dark energy models. This suggests a pathway for
alleviating the Hubble tension by tailoring higher-dimensional dynamics to
reduce the sound horizon. When anisotropic expansion is allowed, these models
achieve isotropization more efficiently than predicted by Wald's cosmic no-hair
theorem. Negative correlations, in contrast, yield a higher-dimensional
steady-state universe where the shear scalar remains constant, effectively
emulating a negative cosmological constant. These distinct behaviors arise from
a simple signature change: positive correlation accelerates shear scalar decay,
while negative correlation stabilizes it. We demonstrate that the solutions
admit analytic continuation from the Lorentzian to Euclidean regime ($t \to
-i\tau$), revealing a wormhole-like topology that connects two asymptotic
regions via a throat, with $\lambda \to -\lambda$.",http://arxiv.org/abs/2501.02109v1
"The underappreciated role of nonspecific interactions in the
  crystallization of DNA-coated colloids",2025-01-04T07:43:19Z,"Hunter Seyforth, Sambarta Chatterjee, Thomas E. Videbæk, Manodeep Mondal, William M. Jacobs, W. Benjamin Rogers","Over the last decade, the field of programmable self-assembly has seen an
explosion in the diversity of crystal lattices that can be synthesized from
DNA-coated colloidal nanometer- and micrometer-scale particles. The prevailing
wisdom has been that a particular crystal structure can be targeted by
designing the DNA-mediated interactions, to enforce binding between specific
particle pairs, and the particle diameters, to control the packing of the
various species. In this article, we show that other ubiquitous nonspecific
interactions can play equally important roles in determining the relative
stability of different crystal polymorphs and therefore what crystal structure
is most likely to form in an experiment. For a binary mixture of same-sized
DNA-coated colloidal micrometer-scale particles, we show how changing the
magnitudes of nonspecific steric and van der Waals interactions gives rise to a
family of binary body-centered tetragonal crystals, including both
cesium-chloride and copper-gold crystals. Simulations using pair potentials
that account for these interactions reproduce our experimental observations
quantitatively, and a theoretical model reveals how a subtle balance between
specific and nonspecific forces determines the equilibrium crystal structure.
These results highlight the importance of accounting for nonspecific
interactions in the crystal-engineering design process.",http://arxiv.org/abs/2501.02220v1
"Tertiary EOR-like microfluidic experiments: influence of viscosity ratio
  on oil clusters mobilization",2025-01-04T14:20:59Z,"Haohong Pi, Abdelaziz Omari, Giuseppe Sciumè","Understanding the pore-scale dynamics of immiscible two-phase flow in porous
media is crucial 9 for optimizing EOR strategies. In this work, we investigate
the mobilization dynamics of oil clusters by 10 means of microfluidic devices
that allow pore scale direct characterization of flow in water-wet chips. We
varied both flow rates during waterflooding and the viscosity ratio by
injecting Glycerol/water mixtures of various compositions right after the
waterflooding period. During waterflooding, the flow rate has only a limited
impact on residual oil. With a subsequent injection of a Glycerol/water
mixture, the oil recovery is significantly enhanced. To better understand the
recovery mechanisms, oil clusters were categorized into droplets, blobs and
ganglia. Increasing the viscosity of the injected mixture resulted in only a
slight reduction in the number of ganglia but significantly decreased their
total volume, thus reducing overall oil saturation. This is due to ganglia
breakup into smaller ganglia, blobs and droplets that are subsequently
mobilized and transported away, while remaining parts of original ganglia still
remain trapped. As long as droplets and blobs are considered, their number is
seen to only weakly change by the increase of mixture viscosity and even their
number may temporarily increase as they result from ganglia rupture. So, the
process can be separated in two main steps: ganglia breakage that feed the
medium in blobs and droplets and a second step where such moving oil entities
are transported. The characteristic time for oil transport is believed to be
longer than that required for ganglia breakage.",http://arxiv.org/abs/2501.02296v1
The parenthood effect in urban mobility,2025-01-04T14:37:06Z,"Mariana Macedo, Ronaldo Menezes, Alessio Cardillo","The modelling of human mobility is vital for the understanding of the
complexity of urban dynamics and guiding effective interventions to improve
quality of life. Traditional modelling approaches focus on `average citizens,'
which overlook the multitude of experiences from distinct sociodemographic
groups. Recent studies have unveiled significant variations in mobility
patterns related to gender and socioeconomic status, yet the impact of
parenthood remains under-explored. Parenthood brings profound changes to daily
routines, influenced by factors such as increased caregiving responsibilities,
altered work-life balance, and the need for family-friendly environments.
Parents often prioritise considerations such as cost of living, social
wellbeing, environmental quality, and safety. Quantifying how `friendly' a city
is becomes more and more important for parents, especially in the context of
rising remote work opportunities which, in turn, reverberate on the choices on
where to settle. This work investigates whether these considerations lead to
distinct mobility patterns between parents and non-parents, also accounting for
the impact of partnership. Using extensive census data across American cities,
we analyse how parenthood and partnership reshape their urban experiences. Our
findings indicate that cities can indeed be classified by their level of
friendliness towards parents and partners. For example, Dallas and Nashville
can be more suited for single individuals, New York and Chicago can be more
accommodating to parents, while Washington and Baltimore favour married people.
These insights contribute to the growing body of research advocating for more
nuanced and equitable urban planning. By recognising the diverse needs of
different demographic groups, particularly parents, our study underscores the
importance of tailored urban design strategies over universal solutions.",http://arxiv.org/abs/2501.02299v1
"Monolayer control of spin-charge conversion in van der Waals
  heterostructures",2025-01-04T17:11:01Z,"K. Abdukayumov, O. Paull, M. Mičica, F. Ibrahim, L. Vojáček, A. Wright, S. Massabeau, F. Mazzola, V. Polewczyk, C. Jego, R. Sharma, C. Vergnaud, A. Marty, I. Gomes de Moraes, A. Ouerghi, H. Okuno, A. Jana, I. Kar, J. Fuji, I. Vobornik, J. Li, F. Bonell, M. Chshiev, M. Bibes, J. -M. George, H. Jaffrès, S. Dhillon, M. Jamet","The diversity of 2D materials and their van der Waals (vdW) stacking presents
a fertile ground for engineering novel multifunctional materials and quantum
states of matter. This permits unique opportunities to tailor the electronic
properties of vdW heterostructures by the insertion of only a single 2D
material layer. However, such vdW materials engineering at the atomic scale has
yet to be investigated for spin-charge interconversion phenomena. Here, we
report on the control of these effects at the monolayer level, where drastic
increase in intensity and change in sign of THz spintronic emission are
demonstrated by inserting a single layer of MoSe$_2$ between PtSe$_2$ and
graphene in a fully epitaxial, large area stacked structure. By using a
combination of spin and angle resolved photoemission and density functional
theory to reveal the electronic and spin structures, we illustrate two
different mechanisms relying on charge transfer and electronic hybridization
for the formation of Rashba states, which are responsible for spin-charge
conversion and hence the THz spintronic emission. These findings open new
pathways to design, at the atomic scale, efficient THz spintronic emitters made
of 2D materials and other spintronic devices based on spin-charge
interconversion phenomena.",http://arxiv.org/abs/2501.02337v1
"Experiences and attitudes toward working remotely from home in a time of
  pandemic: A snapshot from a New Zealand-based online survey",2025-01-05T01:56:59Z,Edgar Pacheco,"Due to the Covid-19 pandemic, employees from around the world were compelled
to work remotely from home and, in many cases, without much preparation. A
substantial body of international research has been conducted on the
experiences and attitudes of remote workers as well as the implications of this
phenomenon for organisations. While New Zealand research evidence is growing,
most existing inquiry is qualitative. This paper provides a quantitative
snapshot of remote working using survey data from participants whose jobs can
be done from home (n=415). Data collection took place when the country was
facing Covid-related measures.
  Based on descriptive and inferential statistics, it was found that, not only
was remote working common, but that hybrid working arrangements were also more
prevalent. While half of the participants wanted to work from home more
frequently, age, but not gender, was significantly associated with this
preference. Another relevant finding is that perceived change in the workplace
culture due to flexible work arrangements was significantly associated with
preference for working remotely more often. Finally, the most common perceived
barriers to working from home were slow internet speed, the need to attend
face-to-face meetings, and limited space at home to work. The implications of
the results are discussed and some directions for future research are proposed.",http://arxiv.org/abs/2501.02418v1
"MetaNeRV: Meta Neural Representations for Videos with Spatial-Temporal
  Guidance",2025-01-05T03:12:30Z,"Jialong Guo, Ke liu, Jiangchao Yao, Zhihua Wang, Jiajun Bu, Haishuai Wang","Neural Representations for Videos (NeRV) has emerged as a promising implicit
neural representation (INR) approach for video analysis, which represents
videos as neural networks with frame indexes as inputs. However, NeRV-based
methods are time-consuming when adapting to a large number of diverse videos,
as each video requires a separate NeRV model to be trained from scratch. In
addition, NeRV-based methods spatially require generating a high-dimension
signal (i.e., an entire image) from the input of a low-dimension timestamp, and
a video typically consists of tens of frames temporally that have a minor
change between adjacent frames. To improve the efficiency of video
representation, we propose Meta Neural Representations for Videos, named
MetaNeRV, a novel framework for fast NeRV representation for unseen videos.
MetaNeRV leverages a meta-learning framework to learn an optimal parameter
initialization, which serves as a good starting point for adapting to new
videos. To address the unique spatial and temporal characteristics of video
modality, we further introduce spatial-temporal guidance to improve the
representation capabilities of MetaNeRV. Specifically, the spatial guidance
with a multi-resolution loss aims to capture the information from different
resolution stages, and the temporal guidance with an effective progressive
learning strategy could gradually refine the number of fitted frames during the
meta-learning process. Extensive experiments conducted on multiple datasets
demonstrate the superiority of MetaNeRV for video representations and video
compression.",http://arxiv.org/abs/2501.02427v2
"Semi-analytic construction of global transfers between quasi-periodic
  orbits in the spatial R3BP",2025-01-05T09:34:23Z,"Amadeu Delshams, Marian Gidea, Pablo Roldan","Consider the spatial restricted three-body problem, as a model for the motion
of a spacecraft relative to the Sun-Earth system. We focus on the dynamics near
the equilibrium point $L_1$, located between the Sun and the Earth. We show
that we can transfer the spacecraft from a quasi-periodic orbit that is nearly
planar relative to the ecliptic to a quasi-periodic orbit that has large
out-of-plane amplitude, at zero energy cost. (In fact, the final orbit has the
maximum out-of-plane amplitude that can be obtained through the particular
mechanism that we consider. Moreover, the transfer can be made through any
prescribed sequence of quasi-periodic orbits in between).
  Our transfer mechanism is based on selecting trajectories homoclinic to a
normally hyperbolic invariant manifold (NHIM) near $L_1$, and then gluing them
together. We provide several explicit constructions of such transfers, and also
develop an algorithm to design trajectories that achieve the \emph{shortest
transfer time} for this particular mechanism.
  The change in the out-of-plane amplitude along a homoclic trajectory can be
described via the scattering map. We develop a new tool, the `Standard
Scattering Map' (SSM), which is a series representation of the exact scattering
map. We use the SSM to obtain a complete description of the dynamics along
homoclinic trajectories. The SSM can be used in many other situations, from
Arnold diffusion problems to transport phenomena in applications.",http://arxiv.org/abs/2501.02485v1
"Materials Discovery in Combinatorial and High-throughput Synthesis and
  Processing: A New Frontier for SPM",2025-01-05T10:59:05Z,"Boris N. Slautin, Yongtao Liu, Yu Liu, Reece Emery, Seungbum Hong, Astita Dubey, Vladimir V. Shvartsman, Doru C. Lupascu, Sheryl L. Sanchez, Mahshid Ahmadi, Yunseok Kim, Evgheni Strelcov, Keith A. Brown, Philip D. Rack, Sergei V. Kalinin","For over three decades, scanning probe microscopy (SPM) has been a key method
for exploring material structures and functionalities at nanometer and often
atomic scales in ambient, liquid, and vacuum environments. Historically, SPM
applications have predominantly been downstream, with images and spectra
serving as a qualitative source of data on the microstructure and properties of
materials, and in rare cases of fundamental physical knowledge. However, the
fast growing developments in accelerated material synthesis via self-driving
labs and established applications such as combinatorial spread libraries are
poised to change this paradigm. Rapid synthesis demands matching capabilities
to probe structure and functionalities of materials on small scales and with
high throughput, which are characteristically inherent to SPM. Here, we
overview SPM methods applicable to these emerging applications and emphasize
their quantitativeness, focusing on piezoresponse force microscopy,
electrochemical strain microscopy, conductive, and surface photovoltage
measurements. We discuss the challenges and opportunities ahead, asserting that
SPM will play a crucial role in closing the loop from material prediction and
synthesis to characterization.",http://arxiv.org/abs/2501.02503v1
"Evolutions of in-medium baryon-baryon scattering cross sections and
  stiffness of dense nuclear matter from Bayesian analyses of FOPI proton flow
  excitation functions",2025-01-05T15:25:52Z,"Bao-An Li, Wen-Jie Xie","Within a Bayesian statistical framework using a Gaussian Process (GP)
emulator for an isospin-dependent Boltzmann-Uehling-Uhlenbeck (IBUU) transport
model simulator of heavy-ion reactions, we infer from the proton directed and
elliptical flow in mid-central Au+Au reactions at beam energies from 150 to
1200 MeV/nucleon taken by the FOPI Collaboration the posterior probability
distribution functions (PDFs) of the in-medium baryon-baryon scattering cross
section modification factor $X$ (with respect to their free-space values) and
the stiffness parameter $K$ of dense nuclear matter. We find that the most
probable value of $X$ evolves from around 0.7 to 1.0 as the beam energy
$E_{beam}/A$ increases. On the other hand, the posterior PDF($K$) may have dual
peaks having roughly the same height or extended shoulders at high $K$ values.
More quantitatively, the posterior PDF($K$) changes from having a major peak
around 220 MeV characterizing a soft EOS in the reaction at $E_{beam}/A$=150
MeV to one that peaks around 320 MeV indicating a stiff EOS in the reactions at
$E_{beam}/A$ higher than about 600 MeV. The transition from soft to stiff
happens in mid-central Au+Au reactions at beam energies around 250 MeV/nucleon
in which $K=220$ MeV and $K=320$ MeV are approximately equally probable.
Altogether, the FOPI proton flow excitation function data indicate a gradual
hardening of hot and dense nuclear matter as its density and temperature
increase in reactions with higher beam energies.",http://arxiv.org/abs/2501.02579v1
"Emergence of Giant Magnetic Chirality during Dimensionality Crossover of
  Magnetic Materials",2025-01-06T05:20:17Z,"Dae-Yun Kim, Yun-Seok Nam, Younghak Kim, Kyoung-Whan Kim, Gyungchoon Go, Seong-Hyub Lee, Joon Moon, Jun-Young Chang, Ah-Yeon Lee, Seung-Young Park, Byoung-Chul Min, Kyung-Jin Lee, Hyunsoo Yang, Duck-Ho Kim, Sug-Bong Choe","Chirality, an intrinsic preference for a specific handedness, is a
fundamental characteristic observed in nature. In magnetism, magnetic chirality
arises from the anti-symmetric Dzyaloshinskii-Moriya interaction in competition
with the symmetric Heisenberg exchange interaction. Traditionally, the
anti-symmetric interaction has been considered minor relative to the symmetric
interaction. In this study, we demonstrate an observation of giant magnetic
chirality during the dimensionality crossover of magnetic materials from
three-dimensional to two-dimensional. The ratio between the anti-symmetric and
symmetric interactions exhibits a reversal in their dominance over this
crossover, overturning the traditional consideration. This observation is
validated theoretically using a non-local interaction model and tight-binding
calculation with distinct pairing schemes for each exchange interaction
throughout the crossover. Additional experiments investigating the asphericity
of orbital moments corroborate the robustness of our findings. Our findings
highlight the critical role of dimensionality in shaping magnetic chirality and
offer strategies for engineering chiral magnet states with unprecedented
strength, desired for the design of spintronic materials.",http://arxiv.org/abs/2501.02768v1
"Forward Once for All: Structural Parameterized Adaptation for Efficient
  Cloud-coordinated On-device Recommendation",2025-01-06T08:32:16Z,"Kairui Fu, Zheqi Lv, Shengyu Zhang, Fan Wu, Kun Kuang","In cloud-centric recommender system, regular data exchanges between user
devices and cloud could potentially elevate bandwidth demands and privacy
risks. On-device recommendation emerges as a viable solution by performing
reranking locally to alleviate these concerns. Existing methods primarily focus
on developing local adaptive parameters, while potentially neglecting the
critical role of tailor-made model architecture. Insights from broader research
domains suggest that varying data distributions might favor distinct
architectures for better fitting. In addition, imposing a uniform model
structure across heterogeneous devices may result in risking inefficacy on less
capable devices or sub-optimal performance on those with sufficient
capabilities. In response to these gaps, our paper introduces Forward-OFA, a
novel approach for the dynamic construction of device-specific networks (both
structure and parameters). Forward-OFA employs a structure controller to
selectively determine whether each block needs to be assembled for a given
device. However, during the training of the structure controller, these
assembled heterogeneous structures are jointly optimized, where the co-adaption
among blocks might encounter gradient conflicts. To mitigate this, Forward-OFA
is designed to establish a structure-guided mapping of real-time behaviors to
the parameters of assembled networks. Structure-related parameters and parallel
components within the mapper prevent each part from receiving heterogeneous
gradients from others, thus bypassing the gradient conflicts for coupled
optimization. Besides, direct mapping enables Forward-OFA to achieve adaptation
through only one forward pass, allowing for swift adaptation to changing
interests and eliminating the requirement for on-device backpropagation.
Experiments on real-world datasets demonstrate the effectiveness and efficiency
of Forward-OFA.",http://arxiv.org/abs/2501.02837v1
"The importance of shear on the collective charge transport in CDWs
  revealed by an XFEL source",2025-01-06T09:21:45Z,"David Le Bolloc'h, Ewen Bellec, Darine Ghoneim, Antoine Gallo-Frantz, Pawel Wzietek, Luc Ortega, Anders Madsen, Pierre Monceau, Mathieu Chollet, Isabel Gonzales-Vallejo, Vincent. L. R. Jacques, Aleksandr Sinchenko","Charge transport in materials has an impact on a wide range of devices based
on semiconductor, battery or superconductor technology. Charge transport in
sliding Charge Density Waves (CDW) differs from all others in that the atomic
lattice is directly involved in the transport process. To obtain an overall
picture of the structural changes associated to the collective transport, the
large coherent X-ray beam generated by an X-ray free-electron laser (XFEL)
source was used. The CDW phase can be retrieved over the entire sample from
diffracted intensities using a genetic algorithm. For currents below threshold,
increasing shear deformation is observed in the central part of the sample
while longitudinal deformation appears above threshold when shear relaxes.
Shear thus precedes longitudinal deformation, with relaxation of one leading to
the appearance of the other. Moreover, strain accumulates on surface steps in
the sliding regime, demonstrating the strong pinning character of these surface
discontinuities. The sliding process of nanometric CDW is based on an
impressive spatial coherence involving the macroscopic sample dimensions.",http://arxiv.org/abs/2501.02868v1
"LOHA: Direct Graph Spectral Contrastive Learning Between Low-pass and
  High-pass Views",2025-01-06T12:25:02Z,"Ziyun Zou, Yinghui Jiang, Lian Shen, Juan Liu, Xiangrong Liu","Spectral Graph Neural Networks effectively handle graphs with different
homophily levels, with low-pass filter mining feature smoothness and high-pass
filter capturing differences. When these distinct filters could naturally form
two opposite views for self-supervised learning, the commonalities between the
counterparts for the same node remain unexplored, leading to suboptimal
performance. In this paper, a simple yet effective self-supervised contrastive
framework, LOHA, is proposed to address this gap. LOHA optimally leverages
low-pass and high-pass views by embracing ""harmony in diversity"". Rather than
solely maximizing the difference between these distinct views, which may lead
to feature separation, LOHA harmonizes the diversity by treating the
propagation of graph signals from both views as a composite feature.
Specifically, a novel high-dimensional feature named spectral signal trend is
proposed to serve as the basis for the composite feature, which remains
relatively unaffected by changing filters and focuses solely on original
feature differences. LOHA achieves an average performance improvement of 2.8%
over runner-up models on 9 real-world datasets with varying homophily levels.
Notably, LOHA even surpasses fully-supervised models on several datasets, which
underscores the potential of LOHA in advancing the efficacy of spectral GNNs
for diverse graph structures.",http://arxiv.org/abs/2501.02969v1
"Probing Magnetism in Self-Assembled Organometallic Complexes using Kondo
  Spectroscopy",2025-01-06T16:09:59Z,"Wantong Huang, Paul Greule, Máté Stark, Joris van Slageren, Christoph Sürgers, Wolfgang Wernsdorfer, Giorgio Sangiovanni, Christoph Wolf, Philip Willke","Control of individual spins at the atomic level holds great promise for
miniaturized spintronics, quantum sensing, and quantum information processing.
Both single atomic and molecular spin centers are prime candidates for these
applications and are often individually addressed and manipulated using
scanning tunneling microscopy (STM). In this work, we present a hybrid approach
and demonstrate a robust method for self-assembly of magnetic organometallic
complexes consisting of individual iron (Fe) atoms and molecules on a silver
substrate using STM. We employ two types of molecules, bis(dibenzoylmethane)
copper(II) [Cu(dbm)2] and iron phthalocyanine (FePc). We show that in both
cases the Fe atoms preferentially attach underneath the benzene ring ligand of
the molecules, effectively forming an organometallic half-sandwich arene
complex, Fe(C6H6), that is akin to the properties of metallocenes. In both
situations, a molecule can be combined with up to two Fe atoms. In addition, we
observe a change in the magnetic properties of the attached Fe atoms in
scanning tunneling spectroscopy, revealing a distinct Kondo signature at the Fe
sites. We explain the latter using density functional theory calculations, and
find that the bond formation between the Fe 3d-orbitals and the benzene
{\pi}-molecular orbitals creates a favorable situation for Kondo screening of
the d_xz- and d_yz-like orbitals. Thus, this work establishes a reliable design
principle for forming hybrid organometallic complexes and simultaneous tuning
of their atomic spin states.",http://arxiv.org/abs/2501.03104v1
The Scaling Law for LoRA Base on Mutual Information Upper Bound,2025-01-06T17:19:19Z,"Jing Zhang, Hui Gao, Peng Zhang, Shuzhen Sun, Chang Yang, Yuexian Hou","LoRA (Low-Rank Adaptation) is a widely used model fine-tuning method. In
fine-tuning, the law among model performance, model parameters, and data
complexity has been a focal issue in the field. Existing methods often leverage
external metrics (such as cross-entropy or perplexity) to evaluate model
performance. In the fine-tuning process for large models, two types of
knowledge are typically involved: the frozen, general knowledge acquired by the
model during pre-training and the new knowledge learned through the LoRA module
from the current data. Generally, the less LoRA's learned knowledge relies on
the large model, the more it captures the specific knowledge of new data,
thereby enhancing its adaptability to new tasks. However, external metrics do
not readily capture the dependency relationship between these two types of
knowledge. Therefore, we designed an internal metric based on the Mutual
Information Upper Bound (MIUB) theory to investigate the scaling law of
large-model LoRA fine-tuning. In our experiments, we validated this approach on
benchmark datasets, using the Llama3-8B and Phi3-3B models. The results show
that the proposed MIUB metric aligns more accurately and stably with the
scaling law of LoRA fine-tuning compared to cross-entropy and perplexity.",http://arxiv.org/abs/2501.03152v1
MEMSDuino: An Arduino-Based MEMS Switch Controller,2025-01-06T19:07:34Z,"Lafe Spietz, Adam Sirois, Nathan Flowers-Jacobs, Steve Waltman, Samuel Benz, Peter Hopkins","Radio frequency cryogenic switches are a critical enabling technology for
quantum information science for both calibration and high throughput testing of
samples. Traditionally, solenoid-based switches have been used [1,2], but a
transition is being made to MEMS-based (Micro Electro Mechanical Systems)
switches due to their lower power dissipation and smaller size, and to minimize
the risk that solenoid switches tend to produce current pulses that destroy
expensive cryogenic amplifiers and can cause electrostatic damage to devices.
These MEMS switches require a 90-volt signal to be applied to the control lines
to determine the state of the switches. Switches exist that have built-in
CMOS-based (Complimentary Metal Oxide Semiconductor) control electronics to
drive the 90 V, but these do not work at the cryogenic temperatures used in
quantum information science.
  There is no currently available room temperature control system with direct
control of the switches. The instrument presented here is a 19-inch rack-mount
controller for a cryogenic MEMS switch network that allows a human operator to
see the state of the switch via a row of clearly marked indicator lights and to
change the state manually via buttons on an LED-based indicator board or
automatically via Python-based serial port commands to the Arduino, an open
source microcontroller platform available from multiple vendors. The design can
also be modified to control other switches that require either a large voltage
or current to switch.",http://arxiv.org/abs/2501.03340v1
"Demonstration of Quantum Polarization Microscopy using an
  Entangled-Photon Source",2025-01-07T02:43:19Z,"Mousume Samad, Maki Shimizu, Yasuto Hijikata","With the advancement of non-classical light sources such as single-photon and
entangled-photon sources, innovative microscopy based on the quantum principles
has been proposed over traditional microscopy. This paper introduces the
experimental demonstration of a quantum polarization microscopic technique that
incorporates a quantum-entangled photon source. Although the point that employs
the variation of polarization angle due to reflection or transmission at the
sample is similar to classical polarization microscopy, the method for
constructing image contrast is significantly different. Image contrast is
constructed by the coincidence count of signal and idler photons. In the case
that coincidence count is recorded from both the signal and idler photons, the
photon statistics resemble a thermal state, similar to the blackbody radiation,
but with a significantly higher peak intensity in the second order
autocorrelation function at zero delay that is derived from coincidence count.
While, when the coincidence count is taken from either the signal or idler
photon only, though the photon state exhibits a thermal state again, the photon
statistics become more dispersive and result in a lower peak intensity of the
autocorrelation function. These different thermal states can be switched by
slightly changing the photon polarization, which is suddenly aroused within
narrow range of analyzer angle. This polarization microscopic technique can
provide a superior imaging technique compared to the classical method, opening
a new frontier for research in material sciences, biology, and other fields
requiring high-resolution imaging.",http://arxiv.org/abs/2501.03478v1
The ubiquity of variable radio emission and spin-down rates in pulsars,2025-01-07T03:42:34Z,"M. E. Lower, A. Karastergiou, S. Johnston, P. R. Brook, S. Dai, M. Kerr, R. N. Manchester, L. S. Oswald, R. M. Shannon, C. Sobey, P. Weltevrede","Pulsars are often lauded for their (relative) rotational and radio emission
stability over long time scales. However, long-term observing programmes are
identifying an increasing number that deviate from this preconceived notion.
Using Gaussian process regression and Bayesian inference techniques, we
investigated the emission and rotational stability of 259 radio pulsars that
have been monitored using Murriyang, the Parkes 64 m radio telescope, over the
past three decades. We found 238 pulsars display significant variability in
their spin-down rates, 52 of which also exhibit changes in profile shape.
Including 23 known state-switching pulsars, this represents the largest
catalogue of variable pulsars identified to date and indicates that these
behaviours are ubiquitous among the wider population. The intensity of
spin-down fluctuations positively scales with increasing pulsar spin-down rate,
with only a marginal dependence on spin-frequency. This may have substantial
implications for ongoing searches for gravitational waves in the ensemble
timing of millisecond pulsars. We also discuss challenges in explaining the
physical origins of quasi-periodic and transient profile/spin-down variations
detected among a subset of our pulsars.",http://arxiv.org/abs/2501.03500v1
"High Resolution {\it BOES} Spectroscopy of Raman-scattered
  He~II$λ$6545 in Young Planetary Nebulae",2025-01-07T06:15:53Z,"Jin Lim, Seok-Jun Chang, Jaejin Shin, Hee-Won Lee, Jiyu Kim, Hak-Sub Kim, Bo-Eun Choi, Ho-Gyu Lee","Young planetary nebulae (PNe) are characterized by their hot central stars
and the presence of abundant neutral and molecular components, which result
from significant mass loss during the asymptotic giant branch (AGB) phase of
stellar evolution. Far-UV \ion{He}{2}$\lambda$1025 line photons produced near
the central star can undergo Raman scattering by hydrogen atoms, creating a
broad emission feature centered at $\sim$ 6545~\AA. We conducted
high-resolution spectroscopy of 12 young PNe from April 2019 to March 2020
using the Bohyunsan Observatory Echelle Spectrograph ({\it BOES}). Building on
the study by Choi and Lee, who identified Raman-scattered \ion{He}{2} at
6545~\AA\ in NGC~6881 and NGC~6886, we report new detections of this feature in
NGC~6741 and NGC~6884. Profile fitting reveals that the velocity of the
\ion{H}{1} component relative to the \ion{He}{2} emission region ranges from
$26-33~{\rm km~s^{-1}}$ in these PNe. Using photoionization modeling, we
estimate the line flux of \ion{He}{2}$\lambda$1025 and derive Raman conversion
efficiencies of 0.39, 0.21, 0.24, and 0.07 for NGC~6881, NGC~6741, NGC~6886,
and NGC~6884, respectively. These results, combined with radiative transfer
modeling, suggest the presence of \ion{H}{1} components with masses around
$10^{-2}~M_\odot$, moving outward from the central \ion{He}{2} emission region
at speeds characteristic of the slow stellar wind from a mass-losing giant
star.",http://arxiv.org/abs/2501.03558v1
"A case study on the transformative potential of AI in software
  engineering on LeetCode and ChatGPT",2025-01-07T09:15:25Z,"Manuel Merkel, Jens Dörpinghaus","The recent surge in the field of generative artificial intelligence (GenAI)
has the potential to bring about transformative changes across a range of
sectors, including software engineering and education. As GenAI tools, such as
OpenAI's ChatGPT, are increasingly utilised in software engineering, it becomes
imperative to understand the impact of these technologies on the software
product. This study employs a methodological approach, comprising web scraping
and data mining from LeetCode, with the objective of comparing the software
quality of Python programs produced by LeetCode users with that generated by
GPT-4o. In order to gain insight into these matters, this study addresses the
question whether GPT-4o produces software of superior quality to that produced
by humans.
  The findings indicate that GPT-4o does not present a considerable impediment
to code quality, understandability, or runtime when generating code on a
limited scale. Indeed, the generated code even exhibits significantly lower
values across all three metrics in comparison to the user-written code.
However, no significantly superior values were observed for the generated code
in terms of memory usage in comparison to the user code, which contravened the
expectations. Furthermore, it will be demonstrated that GPT-4o encountered
challenges in generalising to problems that were not included in the training
data set.
  This contribution presents a first large-scale study comparing generated code
with human-written code based on LeetCode platform based on multiple measures
including code quality, code understandability, time behaviour and resource
utilisation. All data is publicly available for further research.",http://arxiv.org/abs/2501.03639v1
Jet properties of FR0 radio galaxies: need for VLBI data,2025-01-07T13:51:42Z,"R. D. Baldi, G. Giovannini, A. Capetti, R. Lico","Fanaroff-Riley (FR) type 0 radio galaxies are a subclass of radio-loud active
galactic nuclei (AGN) that lack extended kpc-scale jets, different from the
classical FRI and FRII radio galaxies. They constitute the most abundant
population of radio galaxies in the local Universe (z<0.1), yet remain largely
unexplored. VLBI observations of a limited number of FR0s demonstrated that
their central supermassive black hole (SMBH) are able to lunch mostly two-sided
jets, with mildly relativistic bulk speed. In this work, we highlight the need
of further high-resolution radio observations to probe the jet structures of
these compact radio galaxies, by showing exploratory results of our EVN+eMERLIN
observation campaign of FR0s. A preliminary analysis of these recent data
reveals a possible change of the jet direction at different scales. We shortly
discuss their physical conditions to explain the observed jet compactness,
stressing the role of the SMBH spin vector in shaping their radio morphology",http://arxiv.org/abs/2501.03787v1
"Online Reinforcement Learning-Based Dynamic Adaptive Evaluation Function
  for Real-Time Strategy Tasks",2025-01-07T14:36:33Z,"Weilong Yang, Jie Zhang, Xunyun Liu, Yanqing Ye","Effective evaluation of real-time strategy tasks requires adaptive mechanisms
to cope with dynamic and unpredictable environments. This study proposes a
method to improve evaluation functions for real-time responsiveness to
battle-field situation changes, utilizing an online reinforcement
learning-based dynam-ic weight adjustment mechanism within the real-time
strategy game. Building on traditional static evaluation functions, the method
employs gradient descent in online reinforcement learning to update weights
dynamically, incorporating weight decay techniques to ensure stability.
Additionally, the AdamW optimizer is integrated to adjust the learning rate and
decay rate of online reinforcement learning in real time, further reducing the
dependency on manual parameter tun-ing. Round-robin competition experiments
demonstrate that this method signifi-cantly enhances the application
effectiveness of the Lanchester combat model evaluation function, Simple
evaluation function, and Simple Sqrt evaluation function in planning algorithms
including IDABCD, IDRTMinimax, and Port-folio AI. The method achieves a notable
improvement in scores, with the en-hancement becoming more pronounced as the
map size increases. Furthermore, the increase in evaluation function
computation time induced by this method is kept below 6% for all evaluation
functions and planning algorithms. The pro-posed dynamic adaptive evaluation
function demonstrates a promising approach for real-time strategy task
evaluation.",http://arxiv.org/abs/2501.03824v1
"Surface-dependent Majorana vortex phases in topological crystalline
  insulators",2025-01-07T15:29:08Z,"Xun-Jiang Luo, Xiao-Hong Pan, Yilin Shi, Fengcheng Wu","The topological crystalline insulator SnTe exhibits two types of surface
Dirac cones: one located at non-time-reversal-invariant momenta on the (001)
and (110) surfaces, and the other at time-reversal-invariant momenta on the
(111) surface. Motivated by the recent experimental evidence of Majorana vortex
end modes (MVEMs) and their hybridization on the (001) surface [Nature 633, 71
(2024)], we present a comprehensive investigation of Majorana vortex phases in
SnTe, including topological classification, surface-state Hamiltonians
analysis, and lattice model calculations. By utilizing rotational and magnetic
mirror symmetries, we present two equivalent methods to reveal the topology of
Majorana phases on different surfaces. We find that the MVEMs on the (001) and
(110) surfaces are protected by both magnetic group and rotational symmetries.
In contrast, the MVEMs on the (111) surface are protected by magnetic group or
particle-hole symmetry. Due to the different properties of Dirac fermions in
the $\bar{\Gamma}$ and $\bar{M}$ valleys on the (111) surfaces, including Fermi
velocities and energy levels, we find that abundant vortex phase transitions
can occur for the [111]-direction vortex. As the chemical potential increases,
the number of robust MVEMs can change from $0\rightarrow 1\rightarrow 2$. These
vortex transitions are characterized by both $Z$ winding number and $Z_2$
pfaffian topological invariants.",http://arxiv.org/abs/2501.03868v1
"SPECTRE: A Hybrid System for an Adaptative and Optimised Cyber Threats
  Detection, Response and Investigation in Volatile Memory",2025-01-07T16:05:27Z,"Arslan Tariq Syed, Mohamed Chahine Ghanem, Elhadj Benkhelifa, Fauzia Idrees Abro","The increasing sophistication of modern cyber threats, particularly file-less
malware relying on living-off-the-land techniques, poses significant challenges
to traditional detection mechanisms. Memory forensics has emerged as a crucial
method for uncovering such threats by analysing dynamic changes in memory. This
research introduces SPECTRE (Snapshot Processing, Emulation, Comparison, and
Threat Reporting Engine), a modular Cyber Incident Response System designed to
enhance threat detection, investigation, and visualization. By adopting
Volatility JSON format as an intermediate output, SPECTRE ensures compatibility
with widely used DFIR tools, minimizing manual data transformations and
enabling seamless integration into established workflows. Its emulation
capabilities safely replicate realistic attack scenarios, such as credential
dumping and malicious process injections, for controlled experimentation and
validation. The anomaly detection module addresses critical attack vectors,
including RunDLL32 abuse and malicious IP detection, while the IP forensics
module enhances threat intelligence by integrating tools like Virus Total and
geolocation APIs. SPECTRE advanced visualization techniques transform raw
memory data into actionable insights, aiding Red, Blue and Purple teams in
refining strategies and responding effectively to threats. Bridging gaps
between memory and network forensics, SPECTRE offers a scalable, robust
platform for advancing threat detection, team training, and forensic research
in combating sophisticated cyber threats.",http://arxiv.org/abs/2501.03898v1
"From Newswire to Nexus: Using text-based actor embeddings and
  transformer networks to forecast conflict dynamics",2025-01-07T16:45:37Z,"Mihai Croicu, Simon Polichinel von der Maase","This study advances the field of conflict forecasting by using text-based
actor embeddings with transformer models to predict dynamic changes in violent
conflict patterns at the actor level. More specifically, we combine newswire
texts with structured conflict event data and leverage recent advances in
Natural Language Processing (NLP) techniques to forecast escalations and
de-escalations among conflicting actors, such as governments, militias,
separatist movements, and terrorists. This new approach accurately and promptly
captures the inherently volatile patterns of violent conflicts, which existing
methods have not been able to achieve. To create this framework, we began by
curating and annotating a vast international newswire corpus, leveraging
hand-labeled event data from the Uppsala Conflict Data Program. By using this
hybrid dataset, our models can incorporate the textual context of news sources
along with the precision and detail of structured event data. This combination
enables us to make both dynamic and granular predictions about conflict
developments. We validate our approach through rigorous back-testing against
historical events, demonstrating superior out-of-sample predictive power. We
find that our approach is quite effective in identifying and predicting phases
of conflict escalation and de-escalation, surpassing the capabilities of
traditional models. By focusing on actor interactions, our explicit goal is to
provide actionable insights to policymakers, humanitarian organizations, and
peacekeeping operations in order to enable targeted and effective intervention
strategies.",http://arxiv.org/abs/2501.03928v1
"The Power of Negative Zero: Datatype Customization for Quantized Large
  Language Models",2025-01-06T22:40:40Z,"Yuzong Chen, Xilai Dai, Chi-chih Chang, Yash Akhauri, Mohamed S. Abdelfattah","Large language models (LLMs) have demonstrated remarkable performance across
various machine learning tasks, quickly becoming one of the most prevalent AI
workloads. Yet the substantial memory requirement of LLMs significantly hinders
their deployment for end users. Post-training quantization (PTQ) serves as one
of the most hardware-efficient methods to mitigate the memory and computational
demands of LLMs. Although the traditional integer (INT) datatype has received
widespread adoption in PTQ methods, floating-point (FP) quantization has
emerged as a viable alternative thanks to its effectiveness in fitting LLM
numerical distributions. However, the FP datatype in sign-magnitude binary
representation contains both positive and negative zero, which constrains its
representation capability, particularly under low precision (3 and 4 bits). In
this paper, we extend the basic FP datatype to perform Redundant Zero Remapping
(RaZeR), which remaps the negative zero FP encoding to a set of pre-defined
special values to maximally utilize FP quantization encodings and to better fit
LLM numerical distributions. Through careful selection of special values, RaZeR
outperforms conventional asymmetric INT quantization while achieving high
computational efficiency. We demonstrate that RaZeR can be seamlessly
integrated with quantization algorithms for both weights and KV-cache,
including advanced methods with clipping and transformations, and consistently
achieve better model accuracy. Additionally, we implement a fast GEMV kernel
with fused dequantization that efficiently converts the 4-bit RaZeR value to
FP16 through novel bit-level manipulation. On modern GPUs, our evaluation shows
that RaZeR improves the GEMV speed by up to 7.56$\times$ compared to the FP16
implementation, while achieving up to 2.72$\times$ speedup in the LLM decoding
throughput.",http://arxiv.org/abs/2501.04052v1
"Hermitian and Non-Hermitian Topological Transitions Characterized by
  Manifold Distance",2025-01-07T03:05:45Z,"ZhaoXiang Fang, Ming Gong, Guang-Can Guo, Yongxu Fu, Long Xiong","Topological phases are generally characterized by topological invariants
denoted by integer numbers. However, different topological systems often
require different topological invariants to measure, and theses definition
usually fail at critical points. Therefore, it's challenging to predict what
would occur during the transformation between two different topological phases.
To address these issues, we propose a general definition based on fidelity and
trace distance from quantum information theory: manifold distance (MD). This
definition does not rely on the berry connection but rather on the information
of the two manifolds - their ground state wave functions. Thus, it can measure
different topological systems (including traditional band topology models,
non-Hermitian systems, and gapless systems, etc.) and exhibit some universal
laws during the transformation between two topological phases. Our research
demonstrates for different topological manifolds, the change rate (first-order
derivative) or susceptibility (second-order derivative) of MD exhibit various
divergent behaviors near the critical points. Compared to the strange
correlator, which could be used as a diagnosis for short-range entangled states
in 1D and 2D, MD is more universal and could be applied to non-Hermitian
systems and long-range entangled states. For subsequent studies, we expect the
method to be generalized to real-space or non-lattice models, in order to
facilitate the study of a wider range of physical platforms such as open
systems and many-body localization.",http://arxiv.org/abs/2501.04054v1
Postsingular Science,2025-01-07T19:38:57Z,Eldar Knar,"This study presents, for the first time, a conceptual and formal model of
postsingular science (PSS), which analyses and interprets changes in scientific
knowledge driven by accelerating technological progress, singularity, and the
integration of artificial intelligence (AI) into scientific processes. The PSS
model is based on the interplay of six key components: cumulative knowledge,
intelligence, technological synergy, quantum information, social dynamics, and
environmental sustainability. The interaction of these variables is described
through a system of nonlinear differential equations, reflecting the complex
feedback loops and synergetic effects characteristic of the postsingular world.
A differentiation table contrasting postsingular and classical science is also
presented, highlighting the most fundamental differences between contemporary
classical science and future postsingular science. The model emphasizes the
synergy between humans and artificial intelligence, the role of quantum
technologies in accelerating scientific discovery, and the impact of social and
ecological factors that either constrain or stimulate scientific progress. It
is anticipated that new forms of scientific information dissemination will
replace traditional academic publications and that scientific processing will
reach an entirely new level of development following the singularity-driven
acceleration of technological progress and the integration of AI into R&D. This
will herald an era of nonstop, ultrarapid science operating 24/7. The synergy
of humans and artificial intelligence will create a scientific union on the
basis of fundamentally new principles and methods. This research provides an
initial theoretical foundation for further interdisciplinary studies aimed at
developing sustainable strategies and effectively managing scientific progress
in the postsingular era.",http://arxiv.org/abs/2501.04111v2
"Revisiting The Cosmological Time Dilation of Distant Quasars: Influence
  of Source Properties and Evolution",2025-01-07T22:41:54Z,"Brendon J. Brewer, Geraint F. Lewis, Yuan, Li","After decades of searching, cosmological time dilation was recently
identified in the timescale of variability seen in distant quasars. Here, we
expand on the previous analysis to disentangle this cosmological signal from
the influence of the properties of the source population, specifically the
quasar bolometric luminosity and the rest-frame emission wavelength at which
the variability was observed. Furthermore, we consider the potential influence
of the evolution of the quasar population over cosmic time. We find that a
significant intrinsic scatter of 0.288 +- 0.021 dex in the variability
timescales, which was not considered in the previous analysis, is favoured by
the data. This slightly increases the uncertainty in the results. However, the
expected cosmological dependence of the variability timescales is confirmed to
be robust to changes in the underlying assumptions. We find that the
variability timescales increase smoothly with both wavelength and bolometric
luminosity, and that black hole mass has no effect on the variability timescale
once rest wavelength and bolometric luminosity are accounted for. Moreover, if
the standard cosmological model is correct, governed by relativistic expansion,
we also find very little cosmological evolution in the intrinsic variability
timescales of distant quasars.",http://arxiv.org/abs/2501.04171v1
Biglobal resolvent analysis of separated flow over a NACA0012 airfoil,2025-01-08T03:36:33Z,"Laura Victoria Rolandi, Luke Smith, Michael Amitay, Vassilios Theofilis, Kunihiko Taira","The effects of Reynolds number across $Re=1000$, $2500$, $5000$, and $10000$
on separated flow over a two-dimensional NACA0012 airfoil at an angle of attack
of $\alpha=14^\circ$ are investigated through the biglobal resolvent analysis.
We identify modal structures and energy amplifications over a range of
frequency, spanwise wavenumber, and discount parameter, providing insights
across various timescales. Using temporal discounting, we find that the shear
layer dynamics dominates over short time horizons, while the wake dynamics
becomes the primary amplification mechanism over long time horizons. Spanwise
effects also appear over long time horizon, sustained by low frequencies. At a
fixed timescale, we investigate the influence of Reynolds number on response
and forcing mode structures, as well as the energy gain over different
frequencies. Across all Reynolds numbers, the response modes shift from
wake-dominated structures at low frequencies to shear layer-dominated
structures at higher frequencies. The frequency at which the dominant mechanism
changes is independent of the Reynolds number. The response mode structures
show similarities across different Reynolds numbers, with local streamwise
wavelengths only depending on frequency. Comparisons at a different angle of
attack ($\alpha=9^\circ$) show that the transition from wake to shear layer
dynamics with increasing frequency only occurs if the unsteady flow is
three-dimensional. We also study the dominant frequencies associated with wake
and shear layer dynamics across the angles of attack and Reynolds numbers, and
present the characteristic scaling for each mechanism.",http://arxiv.org/abs/2501.04255v1
"H-MBA: Hierarchical MamBa Adaptation for Multi-Modal Video Understanding
  in Autonomous Driving",2025-01-08T06:26:16Z,"Siran Chen, Yuxiao Luo, Yue Ma, Yu Qiao, Yali Wang","With the prevalence of Multimodal Large Language Models(MLLMs), autonomous
driving has encountered new opportunities and challenges. In particular,
multi-modal video understanding is critical to interactively analyze what will
happen in the procedure of autonomous driving. However, videos in such a
dynamical scene that often contains complex spatial-temporal movements, which
restricts the generalization capacity of the existing MLLMs in this field. To
bridge the gap, we propose a novel Hierarchical Mamba Adaptation (H-MBA)
framework to fit the complicated motion changes in autonomous driving videos.
Specifically, our H-MBA consists of two distinct modules, including Context
Mamba (C-Mamba) and Query Mamba (Q-Mamba). First, C-Mamba contains various
types of structure state space models, which can effectively capture
multi-granularity video context for different temporal resolutions. Second,
Q-Mamba flexibly transforms the current frame as the learnable query, and
attentively selects multi-granularity video context into query. Consequently,
it can adaptively integrate all the video contexts of multi-scale temporal
resolutions to enhance video understanding. Via a plug-and-play paradigm in
MLLMs, our H-MBA shows the remarkable performance on multi-modal video tasks in
autonomous driving, e.g., for risk object detection, it outperforms the
previous SOTA method with 5.5% mIoU improvement.",http://arxiv.org/abs/2501.04302v1
"Eccentricity Effects on Modeling Dynamic Quantities and Their
  Correlations in Binary Black Hole Mergers",2025-01-08T13:28:08Z,"Hao Wang, Yuan Chuan Zou, Qing Wen Wu","In this study, we begin by revisiting the oscillatory behavior of radiative
quantities-energy, angular momentum, and linear momentum-linked with initial
eccentricities in binary black hole (BBH) mergers. By varying the mean anomaly
$l_0$ across the parameter range $[0,2\pi]$ from a post-Newtonian perspective,
we establish an envelope that encapsulates the oscillations of these radiative
quantities. Our analysis reveals that while the oscillations are influenced by
the specific initial condition $l_0$, the effect of eccentricity contributes to
the formation of this envelope. Subsequently, we model dynamical quantities
such as peak luminosity $L_{\text{peak}}$, remnant mass $M_{\text{rem}}$, spin
$\alpha_{\text{rem}}$, and recoil velocity $V_{\text{rem}}$ in circular orbits.
Through polynomial modeling, we explore their relationships with mass ratios
and correlations. Our results demonstrate the effectiveness of these
polynomials in capturing the intricate relationships and correlations among
these quantities in circular orbits. Furthermore, we synthesize and analyze
dynamical quantities for both circular and eccentric orbits, revealing
continuous variations within specific ranges corresponding to distinct mass
ratios. These variations are influenced by continuous changes in initial
eccentricity and the associated envelope, which can be extrapolated to
encompass other mass ratios. By interpolating the maximum and minimum values of
these dynamical quantities, we unveil considerably broad domains relative to
circular orbits in both orbital and non-orbital BBH mergers. These domains
provide robust constraints on the relationships between dynamical quantities,
mass ratios, and their correlations. Finally, we discuss the extension of this
eccentricity effect to spin alignment and spin precession configurations of
BBHs.",http://arxiv.org/abs/2501.04495v1
"Effective Two-Stage Double Auction for Dynamic Resource Trading in Edge
  Networks via Overbooking",2025-01-08T13:52:55Z,"Sicheng Wu, Minghui Liwang, Deqing Wang, Xianbin Wang, Chao Wu, Junyi Tang, Li Li, Zhenzhen Jiao","To facilitate responsive and cost-effective computing resource scheduling and
service delivery over edge-assisted mobile networks, this paper investigates a
novel two-stage double auction methodology via utilizing an interesting idea of
resource overbooking to overcome dynamic and uncertain nature from edge servers
(sellers) and demand from mobile devices (as buyers). The proposed auction
integrates multiple essential factors such as social welfare maximization and
decision-making latency (e.g., the time for determining winning seller-buyer
pairs) reduction, by introducing a stagewise strategy: an overbooking-driven
pre-double auction (OPDAuction) for determining long-term cooperations between
sellers and buyers before practical resource transactions as Stage I, and a
real-time backup double auction (RBDAuction) for handling residual resource
demands during actual transactions. In particular, by applying a proper
overbooking rate, OPDAuction helps with facilitating trading contracts between
appropriate sellers and buyers as guidance for future transactions, by allowing
the booked resources to exceed supply. Then, since pre-auctions may cause
risks, our RBDAuction adjusts to real-time market changes, further enhancing
the overall social welfare. More importantly, we offer an interesting view to
show that our proposed two-stage auction can support significant design
properties such as truthfulness, individual rationality, and budget balance.
Through extensive experiments, we demonstrate good performance in social
welfare, time efficiency, and computational scalability, outstripping
conventional methods in dynamic edge computing settings.",http://arxiv.org/abs/2501.04507v1
"Spherical Double K-Means: a co-clustering approach for text data
  analysis",2025-01-08T15:21:00Z,"Ilaria Bombelli, Domenica Fioredistella Iezzi, Emiliano Seri, Maurizio Vichi","In text analysis, Spherical K-means (SKM) is a specialized k-means clustering
algorithm widely utilized for grouping documents represented in
high-dimensional, sparse term-document matrices, often normalized using
techniques like TF-IDF. Researchers frequently seek to cluster not only
documents but also the terms associated with them into coherent groups. To
address this dual clustering requirement, we introduce Spherical Double K-Means
(SDKM), a novel methodology that simultaneously clusters documents and terms.
This approach offers several advantages: first, by integrating the clustering
of documents and terms, SDKM provides deeper insights into the relationships
between content and vocabulary, enabling more effective topic identification
and keyword extraction. Additionally, the two-level clustering assists in
understanding both overarching themes and specific terminologies within
document clusters, enhancing interpretability. SDKM effectively handles the
high dimensionality and sparsity inherent in text data by utilizing cosine
similarity, leading to improved computational efficiency. Moreover, the method
captures dynamic changes in thematic content over time, making it well-suited
for applications in rapidly evolving fields. Ultimately, SDKM presents a
comprehensive framework for advancing text mining efforts, facilitating the
uncovering of nuanced patterns and structures that are critical for robust data
analysis. We apply SDKM to the corpus of US presidential inaugural addresses,
spanning from George Washington in 1789 to Joe Biden in 2021. Our analysis
reveals distinct clusters of words and documents that correspond to significant
historical themes and periods, showcasing the method's ability to facilitate a
deeper understanding of the data. Our findings demonstrate the efficacy of SDKM
in uncovering underlying patterns in textual data.",http://arxiv.org/abs/2501.04562v2
"Large-Scale Spectral Graph Neural Networks via Laplacian Sparsification:
  Technical Report",2025-01-08T15:36:19Z,"Haipeng Ding, Zhewei Wei, Yuhang Ye","Graph Neural Networks (GNNs) play a pivotal role in graph-based tasks for
their proficiency in representation learning. Among the various GNN methods,
spectral GNNs employing polynomial filters have shown promising performance on
tasks involving both homophilous and heterophilous graph structures. However,
The scalability of spectral GNNs on large graphs is limited because they learn
the polynomial coefficients through multiple forward propagation executions
during forward propagation. Existing works have attempted to scale up spectral
GNNs by eliminating the linear layers on the input node features, a change that
can disrupt end-to-end training, potentially impact performance, and become
impractical with high-dimensional input features. To address the above
challenges, we propose ""Spectral Graph Neural Networks with Laplacian
Sparsification (SGNN-LS)"", a novel graph spectral sparsification method to
approximate the propagation patterns of spectral GNNs. We prove that our
proposed method generates Laplacian sparsifiers that can approximate both fixed
and learnable polynomial filters with theoretical guarantees. Our method allows
the application of linear layers on the input node features, enabling
end-to-end training as well as the handling of raw text features. We conduct an
extensive experimental analysis on datasets spanning various graph scales and
properties to demonstrate the superior efficiency and effectiveness of our
method. The results show that our method yields superior results in comparison
with the corresponding approximated base models, especially on dataset
Ogbn-papers100M(111M nodes, 1.6B edges) and MAG-scholar-C (2.8M features).",http://arxiv.org/abs/2501.04570v1
"Mediation analysis in longitudinal intervention studies with an ordinal
  treatment-dependent confounder",2025-01-08T15:55:57Z,"Mikko Valtanen, Tommi Härkänen, Matti Uusitupa, Jaakko Tuomilehto, Jaana Lindström, Kari Auranen","In interventional health studies, causal mediation analysis can be employed
to investigate mechanisms through which the intervention affects the targeted
health outcome. Identifying direct and indirect (i.e. mediated) effects from
empirical data, however, becomes complicated if the mediator-outcome
association is confounded by a variable itself affected by the treatment. Here,
we investigate identification of mediational effects under such post-treatment
confounding in a setting with a longitudinal mediator, time-to-event outcome
and a trichotomous ordinal treatment-dependent confounder. We show that if the
intervention always affects the treatment-dependent confounder only in one
direction (monotonicity), the mediational effects are identified up to a
sensitivity parameter and derive their empirical non-parametric expressions.
The monotonicity assumption can be assessed from empirical data, based on
restrictions on the conditional distribution of the treatment-dependent
confounder. We avoid pitfalls related to post-treatment conditioning by
treating the mediator as a functional entity and defining the time-to-event
outcome as a restricted disease-free time. In an empirical analysis, we use
data from the Finnish Diabetes Prevention Study to assess the extent to which
the effect of a lifestyle intervention on avoiding type 2 diabetes is mediated
through weight reduction in a high-risk population, with other health-related
changes acting as treatment-dependent confounders.",http://arxiv.org/abs/2501.04581v1
"Modeling temporal dependence in a sequence of spatial random partitions
  driven by spanning tree: an application to mosquito-borne diseases",2025-01-08T16:33:00Z,"Jessica Pavani, Rosangela Helena Loschi, Fernando Andres Quintana","Spatially constrained clustering is an important field of research,
particularly when it involves changes over time. Partitioning a map is not
simple since there is a vast number of possible partitions within the search
space. In spatio-temporal clustering, this task becomes even more difficult, as
we must consider sequences of partitions. Motivated by these challenges, we
introduce a Bayesian model for time-dependent sequences of spatial random
partitions by proposing a prior distribution based on product partition models
that correlates partitions. Additionally, we employ random spanning trees to
facilitate the exploration of the partition search space and to guarantee
spatially constrained clustering. This work is motivated by a relevant applied
problem: identifying spatial and temporal patterns of mosquito-borne diseases.
Given the overdispersion present in this type of data, we introduce a
spatio-temporal Poisson mixture model in which mean and dispersion parameters
vary according to spatio-temporal covariates. The proposed model is applied to
analyze the number of dengue cases reported weekly from 2018 to 2023 in the
Southeast region of Brazil. We also evaluate model performance using simulated
data. Overall, the proposed model has proven to be a competitive approach for
analyzing the temporal evolution of spatial clustering.",http://arxiv.org/abs/2501.04601v1
"Fast physics-based launcher optimization for electron cyclotron current
  drive",2025-01-08T17:03:08Z,"N A Lopez, A Alieva, S A M McNamara, X Zhang","With the increased urgency to design fusion pilot plants, fast optimization
of electron cyclotron current drive (ECCD) launchers is paramount.
Traditionally, this is done by coarsely sampling the 4-D parameter space of
possible launch conditions consisting of (1) the launch location (constrained
to lie along the reactor vessel), (2) the launch frequency, (3) the toroidal
launch angle, and (4) the poloidal launch angle. For each initial condition, a
ray-tracing simulation is performed to evaluate the ECCD efficiency.
Unfortunately, this approach often requires millions of simulations to build up
a dataset that adequately covers the plasma volume, which must then be repeated
every time the design point changes. Here we adopt a different approach. Rather
than launching rays from the plasma periphery and hoping for the best, we
instead directly reconstruct the optimal ray for driving current at a given
flux surface using a reduced physics model coupled with a commercial
ray-tracing code. Repeating this throughout the plasma volume requires only
hundreds of simulations, constituting a ten-thousand-fold speedup. The new
method is validated on two separate example tokamak profiles, and is shown to
reliably drive localized current at the specified flux surface with the same
optimal efficiency as obtained from the traditional approach.",http://arxiv.org/abs/2501.04619v1
"Framework for Integrating Machine Learning Methods for Path-Aware Source
  Routing",2025-01-08T17:10:18Z,"Anees Al-Najjar, Domingos Paraiso, Mariam Kiran, Cristina Dominicini, Everson Borges, Rafael Guimaraes, Magnos Martinello, Harvey Newman","Since the advent of software-defined networking (SDN), Traffic Engineering
(TE) has been highlighted as one of the key applications that can be achieved
through software-controlled protocols (e.g. PCEP and MPLS). Being one of the
most complex challenges in networking, TE problems involve difficult decisions
such as allocating flows, either via splitting them among multiple paths or by
using a reservation system, to minimize congestion. However, creating an
optimized solution is cumbersome and difficult as traffic patterns vary and
change with network scale, capacity, and demand. AI methods can help alleviate
this by finding optimized TE solutions for the best network performance.
SDN-based TE tools such as Teal, Hecate and more, use classification techniques
or deep reinforcement learning to find optimal network TE solutions that are
demonstrated in simulation. Routing control conducted via source routing tools,
e.g., PolKA, can help dynamically divert network flows. In this paper, we
propose a novel framework that leverages Hecate to practically demonstrate TE
on a real network, collaborating with PolKA, a source routing tool. With
real-time traffic statistics, Hecate uses this data to compute optimal paths
that are then communicated to PolKA to allocate flows. Several contributions
are made to show a practical implementation of how this framework is tested
using an emulated ecosystem mimicking a real P4 testbed scenario. This work
proves valuable for truly engineered self-driving networks helping translate
theory to practice.",http://arxiv.org/abs/2501.04624v1
Cosmic deceptions due to peculiar motions,2025-01-08T18:40:41Z,Christos G. Tsagas,"Relative motions have long been known to mislead the unsuspecting observers
to false interpretations of reality. The deceptions are usually brief and
unimportant, though relative motions have also led to illusions that were both
long-lasting and important. Indeed, in the history of astronomy there are
several examples where relative-motion effects have misled us to gross
misinterpretations. Here, we consider the possibility that our peculiar motion
relative to the cosmic rest-frame can trigger deceptions on cosmological
scales. In so doing, we will demonstrate that unsuspecting observers inside
bulk peculiar flows may come to the false conclusion of recent accelerated
expansion, when their host universe is actually decelerating. The same
observers may then erroneously attribute their apparent acceleration to an also
recent dramatic change in the nature of the cosmic medium. In reality, however,
nothing has really happened. Despite the appearances, the host universe keeps
decelerating and its material content retains its conventional form.
Nevertheless, there are ways out of these illusions. Our observers can find out
that they have been deceived by their own peculiar flow, by looking for the
trademark signature of relative motion in their data. This signature is nothing
else but a Doppler-like anisotropy in the sky distribution of the measured
deceleration parameter. To the bulk-flow observers, the universe should appear
to accelerate faster along a certain point on the celestial sphere and equally
slower along the antipodal. Moreover, the magnitude of the apparent dipole
should decrease with increasing redshift.",http://arxiv.org/abs/2501.04680v1
"A Shape-Based Functional Index for Objective Assessment of Pediatric
  Motor Function",2025-01-02T21:42:04Z,"Shashwat Kumar, Arafat Rahman, Robert Gutierrez, Sarah Livermon, Allison N. McCrady, Silvia Blemker, Rebecca Scharf, Anuj Srivastava, Laura E. Barnes","Clinical assessments for neuromuscular disorders, such as Spinal Muscular
Atrophy (SMA) and Duchenne Muscular Dystrophy (DMD), continue to rely on
subjective measures to monitor treatment response and disease progression. We
introduce a novel method using wearable sensors to objectively assess motor
function during daily activities in 19 patients with DMD, 9 with SMA, and 13
age-matched controls. Pediatric movement data is complex due to confounding
factors such as limb length variations in growing children and variability in
movement speed. Our approach uses Shape-based Principal Component Analysis to
align movement trajectories and identify distinct kinematic patterns, including
variations in motion speed and asymmetry. Both DMD and SMA cohorts have
individuals with motor function on par with healthy controls. Notably, patients
with SMA showed greater activation of the motion asymmetry pattern. We further
combined projections on these principal components with partial least squares
(PLS) to identify a covariation mode with a canonical correlation of r = 0.78
(95% CI: [0.34, 0.94]) with muscle fat infiltration, the Brooke score (a motor
function score), and age-related degenerative changes, proposing a novel motor
function index. This data-driven method can be deployed in home settings,
enabling better longitudinal tracking of treatment efficacy for children with
neuromuscular disorders.",http://arxiv.org/abs/2501.04721v1
Intrinsic Direct Air Capture,2025-01-08T20:24:02Z,"Austin McDannald, Daniel W. Siderius, Brian DeCost, Kamal Choudhary, Diana L. Ortiz-Montalvo","We present new metrics to evaluate solid sorbent materials for Direct Air
Capture (DAC). These new metrics provide a theoretical upper bound on CO2
captured per energy as well as a theoretical upper limit on the purity of the
captured CO2. These new metrics are based entirely on intrinsic material
properties and are therefore agnostic to the design of the DAC system. These
metrics apply to any adsorption-refresh cycle design. In this work we
demonstrate the use of these metrics with the example of temperature-pressure
swing refresh cycles. The main requirement for applying these metrics is to
describe the equilibrium uptake (along with a few other materials properties)
of each species in terms of the thermodynamic variables (e.g. temperature,
pressure). We derive these metrics from thermodynamic energy balances. To apply
these metrics on a set of examples, we first generated approximations of the
necessary materials properties for 11 660 metal-organic framework materials
(MOFs). We find that the performance of the sorbents is highly dependent on the
path through thermodynamic parameter space. These metrics allow for: 1) finding
the optimum materials given a particular refresh cycle, and 2) finding the
optimum refresh cycles given a particular sorbent. Applying these metrics to
the database of MOFs lead to the following insights: 1) start cold - the
equilibrium uptake of CO2 diverges from that of N2 at lower temperatures, and
2) selectivity of CO2 vs other gases at any one point in the cycle does not
matter - what matters is the relative change in uptake along the cycle.",http://arxiv.org/abs/2501.04825v1
"Balancing Exploration and Cybersickness: Investigating Curiosity-Driven
  Behavior in Virtual Environments",2025-01-09T01:38:34Z,"Tangyao Li, Yuyang Wang","During virtual navigation, users exhibit varied interaction and navigation
behaviors influenced by several factors. Existing theories and models have been
developed to explain and predict these diverse patterns. While users often
experience uncomfortable sensations, such as cybersickness, during virtual
reality (VR) use, they do not always make optimal decisions to mitigate these
effects. Although methods like reinforcement learning have been used to model
decision-making processes, they typically rely on random selection to simulate
actions, failing to capture the complexities of real navigation behavior. In
this study, we propose curiosity as a key factor driving irrational
decision-making, suggesting that users continuously balance exploration and
cybersickness according to the free energy principle during virtual navigation.
Our findings show that VR users generally adopt conservative strategies when
navigating, with most participants displaying negative curiosity across trials.
However, curiosity levels tend to rise when the virtual environment changes,
illustrating the dynamic interplay between exploration and discomfort. This
study provides a quantitative approach to decoding curiosity-driven behavior
during virtual navigation, offering insights into how users balance exploration
and the avoidance of cybersickness. Future research will further refine this
model by incorporating additional psychological and environmental factors to
improve the accuracy of navigation pattern predictions.",http://arxiv.org/abs/2501.04905v2
"Topology-aware Microservice Architecture in Edge Networks: Deployment
  Optimization and Implementation",2025-01-09T04:16:55Z,"Yuang Chen, Chang Wu, Fangyu Zhang, Chengdi Lu, Yongsheng Huang, Hancheng Lu","As a ubiquitous deployment paradigm, integrating microservice architecture
(MSA) into edge networks promises to enhance the flexibility and scalability of
services. However, it also presents significant challenges stemming from
dispersed node locations and intricate network topologies. In this paper, we
have proposed a topology-aware MSA characterized by a three-tier network
traffic model encompassing the service, microservices, and edge node layers.
This model meticulously characterizes the complex dependencies between edge
network topologies and microservices, mapping microservice deployment onto link
traffic to accurately estimate communication delay. Building upon this model,
we have formulated a weighted sum communication delay optimization problem
considering different types of services. Then, a novel topology-aware and
individual-adaptive microservices deployment (TAIA-MD) scheme is proposed to
solve the problem efficiently, which accurately senses the network topology and
incorporates an individual-adaptive mechanism in a genetic algorithm to
accelerate the convergence and avoid local optima. Extensive simulations show
that, compared to the existing deployment schemes, TAIA-MD improves the
communication delay performance by approximately 30% to 60% and effectively
enhances the overall network performance. Furthermore, we implement the TAIA-MD
scheme on a practical microservice physical platform. The experimental results
demonstrate that TAIA-MD achieves superior robustness in withstanding link
failures and network fluctuations.",http://arxiv.org/abs/2501.04956v1
"A CT Image Classification Network Framework for Lung Tumors Based on
  Pre-trained MobileNetV2 Model and Transfer learning, And Its Application and
  Market Analysis in the Medical field",2025-01-09T06:22:50Z,"Ziyang Gao, Yong Tian, Shih-Chi Lin, Junghua Lin","In the medical field, accurate diagnosis of lung cancer is crucial for
treatment. Traditional manual analysis methods have significant limitations in
terms of accuracy and efficiency. To address this issue, this paper proposes a
deep learning network framework based on the pre-trained MobileNetV2 model,
initialized with weights from the ImageNet-1K dataset (version 2). The last
layer of the model (the fully connected layer) is replaced with a new fully
connected layer, and a softmax activation function is added to efficiently
classify three types of lung cancer CT scan images. Experimental results show
that the model achieves an accuracy of 99.6% on the test set, with significant
improvements in feature extraction compared to traditional models.With the
rapid development of artificial intelligence technologies, deep learning
applications in medical image processing are bringing revolutionary changes to
the healthcare industry. AI-based lung cancer detection systems can
significantly improve diagnostic efficiency, reduce the workload of doctors,
and occupy an important position in the global healthcare market. The potential
of AI to improve diagnostic accuracy, reduce medical costs, and promote
precision medicine will have a profound impact on the future development of the
healthcare industry.",http://arxiv.org/abs/2501.04996v1
"Finite strain continuum phenomenological model describing the
  shape-memory effects in multi-phase semi-crystalline networks",2025-01-09T07:58:43Z,"Matteo Arricca, Nicoletta Inverardi, Stefano Pandini, Maurizio Toselli, Massimo Messori, Giulia Scalet","Thermally-driven semi-crystalline polymer networks are capable to achieve
both the one-way shape-memory effect and two-way shape-memory effect under
stress and stress-free conditions, therefore representing an appealing class of
polymers for applications requiring autonomous reversible actuation and shape
changes. In these materials, the shape-memory effects are achieved by
leveraging the synergistic interaction between one or more crystalline phases
and the surrounding amorphous ones that are present within the network itself.
The present paper introduces a general framework for the finite strain
continuum phenomenological modeling of the thermo-mechanical and shape-memory
behavior of multi-phase semi-crystalline polymer networks. Model formulation,
including the definition of phase and control variables, kinematic assumptions,
and constitutive specifications, is introduced and thoroughly discussed.
Theoretical derivations are general and easily adaptable to all cross-linked
systems which include two or more crystalline domains or a single crystalline
phase with a wide melting range and manifest macroscopically the one-way
shape-memory effect and the two-way shape-memory effect under stress and
stress-free conditions. Model capabilities are validated against experimental
data for copolymer networks with two different crystalline phases characterized
by well-separated melting and crystallization transitions. Results demonstrate
the accuracy of the proposed model in predicting all the phenomena involved and
in furnishing a useful support for future material and application design
purposes.",http://arxiv.org/abs/2501.05043v1
"Existence and multiplicity of solutions for a critical Kirchhoff type
  elliptic equation with a logarithmic perturbation",2025-01-09T09:04:45Z,"Qian Zhang, Yuzhu Han","In this paper, we are interested in the following critical Kirchhoff type
elliptic equation with a logarithmic perturbation \begin{equation}\label{eq0}
\begin{cases} -\left(1+b\int_{\Omega}|\nabla{u}|^2\mathrm{d}x\right)
\Delta{u}=\lambda u+\mu u\log{u^2}+|u|^{2^{*}-2}u, &x\in\Omega,\\
u=0,&x\in\partial\Omega, \end{cases} \end{equation} where $\Omega$ is a bounded
domain in $\mathbb{R}^{N}(N\geq3)$ with smooth boundary $\partial \Omega$, $b$,
$\lambda$ and $\mu$ are parameters and $2^{*}=\frac{2N}{N-2}$ is the critical
Sobolev exponent. The presence of a nonlocal term, together with a critical
nonlinearity and a logarithmic term, prevents to apply in a straightforward way
the classical critical point theory. Moreover, the geometry structure of the
energy functional changes as the space dimension $N$ varies, which has a
crucial influence on the existence of solutions to the problem. On the basis of
some careful analysis on the structure of the energy functional, existence and
(or) multiplicity results are obtained by using variational methods. More
precisely, if $N=3$, the problem admits a local minimum solution, a ground
state solution and a sequence of solutions with their $H_0^1(\Omega)$-norms
converging to $0$. If $N=4$, the existence of infinitely many solutions is also
obtained. When $N\geq5$, the problem admits a local minimum solution with
negative energy. Sufficient conditions are also derived for the local minimum
solution to be a ground state solution.",http://arxiv.org/abs/2501.05083v1
"The impact of the redshift-dependent selection effect of halos on the
  redshift-space power spectrum",2025-01-09T09:11:23Z,"Kanmi Nose, Masahiro Takada, Ryo Terasawa","In a wide-area spectroscopic survey of galaxies, it is nearly impossible to
obtain a homogeneous sample of galaxies with respect to galaxy properties such
as stellar mass and host halo mass across a range of redshifts. Despite the
selection effect, theoretical templates in most analyses assume single tracers
when compared with the measured clustering quantities. We demonstrate
analytically that the selection effect inevitably introduces a bias in the
redshift-space power spectrum on scales from linear to nonlinear scales. To
quantitatively assess the impact of the selection effect, we construct mock
galaxy catalogs from halos in N-body simulations by selecting halos above
redshift-dependent mass thresholds such that the resulting redshift
distribution of the halos, $n(z)$, matches that of SDSS-like galaxies. We find
that the selection effect causes fractional changes of up to only 1% and 2% in
the monopole and quadrupole moments of the redshift-space power spectrum at
$k\lesssim 0.3~h{\rm{Mpc}}^{-1}$, respectively, compared to the moments for the
single mass-threshold (therefore single tracer) sample, for $n_{\rm g}(z)$ of
the SDSS-like galaxy samples. We also argue that the selection effect is
unlikely to cause a significant bias in the estimation of cosmological
parameters using the Fisher matrix method, provided that the redshift-dependent
selection effect is modest.",http://arxiv.org/abs/2501.05086v1
"Recovery of activation propagation and self-sustained oscillation
  abilities in stroke brain networks",2025-01-09T09:38:07Z,"Yingpeng Liu, Jiao Wu, Kesheng Xu, Muhua Zheng","Healthy brain networks usually show highly efficient information
communication and self-sustained oscillation abilities. However, how the brain
network structure affects these dynamics after an injury (stroke) is not very
clear. The recovery of structure and dynamics of stroke brain networks over
time is still not known precisely. Based on the analysis of a large number of
strokes' brain network data, we show that stroke changes the network properties
in connection weights, average degree, clustering, community, etc. Yet, they
will recover gradually over time to some extent. We then adopt a simplified
reaction-diffusion model to investigate stroke patients' activation propagation
and self-sustained oscillation abilities. Our results reveal that the stroke
slows the adoption time across different brain scales, indicating a weakened
brain's activation propagation ability. In addition, we show that the lifetime
of self-sustained oscillatory patterns at three months post-stroke patients'
brains significantly departs from the healthy one. Finally, we examine the
properties of core networks of self-sustained oscillatory patterns, in which
the directed edges denote the main pathways of activation propagation. Our
results demonstrate that the lifetime and recovery of self-sustaining patterns
are related to the properties of core networks, and the properties in the
post-stroke greatly vary from those in the healthy group. Most importantly, the
strokes' activation propagation and self-sustained oscillation abilities
significantly improve at one year post-stroke, driven by structural connection
repair. This work may help us to understand the relationship between structure
and function in brain disorders.",http://arxiv.org/abs/2501.05099v1
FaceMe: Robust Blind Face Restoration with Personal Identification,2025-01-09T11:52:54Z,"Siyu Liu, Zheng-Peng Duan, Jia OuYang, Jiayi Fu, Hyunhee Park, Zikun Liu, Chun-Le Guo, Chongyi Li","Blind face restoration is a highly ill-posed problem due to the lack of
necessary context. Although existing methods produce high-quality outputs, they
often fail to faithfully preserve the individual's identity. In this paper, we
propose a personalized face restoration method, FaceMe, based on a diffusion
model. Given a single or a few reference images, we use an identity encoder to
extract identity-related features, which serve as prompts to guide the
diffusion model in restoring high-quality and identity-consistent facial
images. By simply combining identity-related features, we effectively minimize
the impact of identity-irrelevant features during training and support any
number of reference image inputs during inference. Additionally, thanks to the
robustness of the identity encoder, synthesized images can be used as reference
images during training, and identity changing during inference does not require
fine-tuning the model. We also propose a pipeline for constructing a reference
image training pool that simulates the poses and expressions that may appear in
real-world scenarios. Experimental results demonstrate that our FaceMe can
restore high-quality facial images while maintaining identity consistency,
achieving excellent performance and robustness.",http://arxiv.org/abs/2501.05177v2
"HipyrNet: Hypernet-Guided Feature Pyramid network for mixed-exposure
  correction",2025-01-09T12:33:46Z,"Shaurya Singh Rathore, Aravind Shenoy, Krish Didwania, Aditya Kasliwal, Ujjwal Verma","Recent advancements in image translation for enhancing mixed-exposure images
have demonstrated the transformative potential of deep learning algorithms.
However, addressing extreme exposure variations in images remains a significant
challenge due to the inherent complexity and contrast inconsistencies across
regions. Current methods often struggle to adapt effectively to these
variations, resulting in suboptimal performance. In this work, we propose
HipyrNet, a novel approach that integrates a HyperNetwork within a Laplacian
Pyramid-based framework to tackle the challenges of mixed-exposure image
enhancement. The inclusion of a HyperNetwork allows the model to adapt to these
exposure variations. HyperNetworks dynamically generates weights for another
network, allowing dynamic changes during deployment. In our model, the
HyperNetwork employed is used to predict optimal kernels for Feature Pyramid
decomposition, which enables a tailored and adaptive decomposition process for
each input image. Our enhanced translational network incorporates multiscale
decomposition and reconstruction, leveraging dynamic kernel prediction to
capture and manipulate features across varying scales. Extensive experiments
demonstrate that HipyrNet outperforms existing methods, particularly in
scenarios with extreme exposure variations, achieving superior results in both
qualitative and quantitative evaluations. Our approach sets a new benchmark for
mixed-exposure image enhancement, paving the way for future research in
adaptive image translation.",http://arxiv.org/abs/2501.05195v1
"Automated external cervical resorption segmentation in cone-beam CT
  using local texture features",2025-01-09T13:43:01Z,"Sadhana Ravikumar, Asma A. Khan, Matthew C. Davis, Beatriz Paniagua","External cervical resorption (ECR) is a resorptive process affecting teeth.
While in some patients, active resorption ceases and gets replaced by osseous
tissue, in other cases, the resorption progresses and ultimately results in
tooth loss. For proper ECR assessment, cone-beam computed tomography (CBCT) is
the recommended imaging modality, enabling a 3-D characterization of these
lesions. While it is possible to manually identify and measure ECR resorption
in CBCT scans, this process can be time intensive and highly subject to human
error. Therefore, there is an urgent need to develop an automated method to
identify and quantify the severity of ECR resorption using CBCT. Here, we
present a method for ECR lesion segmentation that is based on automatic, binary
classification of locally extracted voxel-wise texture features. We evaluate
our method on 6 longitudinal CBCT datasets and show that certain
texture-features can be used to accurately detect subtle CBCT signal changes
due to ECR. We also present preliminary analyses clustering texture features
within a lesion to stratify the defects and identify patterns indicative of
calcification. These methods are important steps in developing prognostic
biomarkers to predict whether ECR will continue to progress or cease,
ultimately informing treatment decisions.",http://arxiv.org/abs/2501.05236v1
Private Selection with Heterogeneous Sensitivities,2025-01-09T15:25:07Z,"Daniela Antonova, Allegra Laro, Audra McMillan, Lorenz Wolf","Differentially private (DP) selection involves choosing a high-scoring
candidate from a finite candidate pool, where each score depends on a sensitive
dataset. This problem arises naturally in a variety of contexts including model
selection, hypothesis testing, and within many DP algorithms. Classical
methods, such as Report Noisy Max (RNM), assume all candidates' scores are
equally sensitive to changes in a single individual's data, but this often
isn't the case. To address this, algorithms like the Generalised Exponential
Mechanism (GEM) leverage variability in candidate sensitivities. However, we
observe that while these algorithms can outperform RNM in some situations, they
may underperform in others - they can even perform worse than random selection.
In this work, we explore how the distribution of scores and sensitivities
impacts DP selection mechanisms. In all settings we study, we find that there
exists a mechanism that utilises heterogeneity in the candidate sensitivities
that outperforms standard mechanisms like RNM. However, no single mechanism
uniformly outperforms RNM. We propose using the correlation between the scores
and sensitivities as the basis for deciding which DP selection mechanism to
use. Further, we design a slight variant of GEM, modified GEM that generally
performs well whenever GEM performs poorly. Relying on the correlation
heuristic we propose combined GEM, which adaptively chooses between GEM and
modified GEM and outperforms both in polarised settings.",http://arxiv.org/abs/2501.05309v1
"Data-driven methods to discover stable linear models of the helicity
  injectors on HIT-SIU",2025-01-09T17:58:37Z,"Zachary L. Daniel, Alan A. Kaptanoglu, Christopher J. Hansen, Kyle D. Morgan, Steven L. Brunton, J. Nathan Kutz","Accurate and efficient circuit models are necessary to control the power
electronic circuits found on plasma physics experiments. Tuning and controlling
the behavior of these circuits is inextricably linked to plasma performance.
Linear models are greatly preferred for control applications due to their
well-established performance guarantees, but they typically fail to capture
nonlinear dynamics and changes in experimental parameters. Data-driven system
identification can help mitigate these shortcomings by learning interpretable
and accurate reduced-order models of a complex system, in this case the
injector circuits of the Helicity Injected Torus - Steady Inductive Upgrade
(HIT-SIU) experiment. Specifically, the Bagging Optimized Dynamic Mode
Decomposition (BOP-DMD), is leveraged to learn stable, reduced order models of
the interaction between the spheromak plasma formed in the confinement volume,
and the injector circuits of the device. BOP-DMD is trained and evaluated on an
analytic model of the vacuum dynamics of the injector circuits of HIT-SIU, as
well as an analytic linear reduced-order model for the injector dynamics when a
plasma is present. BOP-DMD is then fit on experimental data, both on shots with
and without a plasma in the confinement volume. In doing so, we demonstrate the
capability of data-driven methods to produce stable, linear models for control
and uncertainty quantification in plasma experiments.",http://arxiv.org/abs/2501.05405v2
"How quantum selection rules influence the magneto-optical effects of
  driven, ultrafast magnetization dynamics",2025-01-09T18:47:51Z,"Mohamed F. Elhanoty, Olle Eriksson, Chin Shen Ong, Oscar Grånäs","Ultrafast magnetization dynamics driven by ultrashort pump lasers is
typically explained by changes in electronic populations and scattering
pathways of excited conduction electrons. This conventional approach overlooks
the fundamental role of quantum mechanical selection rules, governing
transitions from core states to the conduction band, that forms the key method
of the probing step in these experiments. By employing fully ab initio
time-dependent density functional theory, we reveal that these selection rules
profoundly influence the interpretation of ultrafast spin dynamics at specific
probe energies. Our analysis for hcp Co and fcc Ni at the M edge demonstrates
that the transient dynamics, as revealed in pump-probe experiments, arise from
a complex interplay of optical excitations of the M shell. Taking into account
the selection rules and conduction electron spin flips, this leads to highly
energy-dependent dynamics. These findings address longstanding discrepancies in
experimental TMOKE measurements and show that only through meticulous
consideration of matrix elements at the probe stage, can one ensure that
magnetization dynamics is revealed in its true nature, instead of being muddled
by artifacts arising from the choice of probe energy.",http://arxiv.org/abs/2501.05433v3
"Towards an Ontology of Traceable Impact Management in the Food Supply
  Chain",2025-01-08T16:53:25Z,"Bart Gajderowicz, Mark S Fox, Yongchao Gao","The pursuit of quality improvements and accountability in the food supply
chains, especially how they relate to food-related outcomes, such as hunger,
has become increasingly vital, necessitating a comprehensive approach that
encompasses product quality and its impact on various stakeholders and their
communities. Such an approach offers numerous benefits in increasing product
quality and eliminating superfluous measurements while appraising and
alleviating the broader societal and environmental repercussions. A traceable
impact management model (TIMM) provides an impact structure and a reporting
mechanism that identifies each stakeholder's role in the total impact of food
production and consumption stages.
  The model aims to increase traceability's utility in understanding the impact
of changes on communities affected by food production and consumption, aligning
with current and future government requirements, and addressing the needs of
communities and consumers. This holistic approach is further supported by an
ontological model that forms the logical foundation and a unified terminology.
By proposing a holistic and integrated solution across multiple stakeholders,
the model emphasizes quality and the extensive impact of championing
accountability, sustainability, and responsible practices with global
traceability.
  With these combined efforts, the food supply chain moves toward a global
tracking and tracing process that not only ensures product quality but also
addresses its impact on a broader scale, fostering accountability,
sustainability, and responsible food production and consumption.",http://arxiv.org/abs/2501.05486v1
X-ray Dips and Polarization Angle Swings in GX 13+1,2025-01-09T19:00:01Z,"Alessandro Di Marco, Fabio La Monaca, Anna Bobrikova, Luigi Stella, Alessandro Papitto, Juri Poutanen, Maria Cristina Baglio, Matteo Bachetti, Vladislav Loktev, Maura Pilia, Daniele Rogantini","We present the result from the April 2024 observation of the low-mass X-ray
binary GX 13+1 with the Imaging X-ray Polarimetry Explorer (IXPE), together
with NICER and Swift-XRT coordinated observations. Two light curve dips were
observed; during them, the harder Comptonized spectral component was dominant
and the polarization degree higher than in the softer, off-dip intervals.
Through a joint analysis of the three IXPE observations, which also included
the dip from the first observation, we demonstrate that the polarization
properties varied in response to the intensity and spectral hardness changes
associated with the dips. The polarization degree attained values up to ~4%.
The polarization angle showed a swing of ~70{\deg} across the dip and off-dip
states, comparable to the continuous rotation seen during the first IXPE
observation. We discuss these results in the context of models for polarized
emission from the accretion disk and the boundary/spreading layer on the
neutron star surface. We also draw attention to the role that an extended
accretion disk corona or disk wind can play in generating high polarization
degrees and, possibly, swings of the polarization angle.",http://arxiv.org/abs/2501.05511v2
"Off-resonant photoluminescence spectroscopy of high-optical quality
  single photon emitters in GaN",2025-01-09T19:36:34Z,"Nilesh Dalla, Paweł Kulboka, Michał Kobecki, Jan Misiak, Paweł Prystawko, Henryk Turski, Piotr Kossacki, Tomasz Jakubczyk","In this work, we analyze the relevance of excitation parameters on the
emission from single-photon emitting defect centers in GaN. We investigate the
absorption spectrum of different emitters by photoluminescence excitation
technique at 10\,K. We report large spectral jumps (shifts up to 22\,meV) in
the emitters' zero-phonon line (ZPL). The likelihood of such jumps is increased
by the change in excitation energy. The shifts indicate a large built-in dipole
moment of the defects and suggest a possibility to electrically tune their ZPL
in a wide range. From the photoluminescence excitation studies, we observe that
for majority of the emitters the absorption peaks exist between 2 and 2.55\,eV.
The absorption peaks vary from emitter to emitter, and no universal absorption
pattern is apparent. Finally, for selected emitters we observe significantly
reduced spectral diffusion and instrument-limited linewidth of $138\,\mu eV$
(0.04\,nm).These findings show a new perspective for atomic defect GaN emitters
as sources of coherent photons, shine new light on their energy level structure
and show the possibility of tuning the ZPL, paving the way to fully harness
their potential for applications in quantum technologies.",http://arxiv.org/abs/2501.05546v2
"LGL-BCI: A Motor-Imagery-Based Brain-Computer Interface with Geometric
  Learning",2025-01-09T21:51:45Z,"Jianchao Lu, Yuzhe Tian, Yang Zhang, Quan Z. Sheng, Xi Zheng","Brain--computer interfaces are groundbreaking technology whereby brain
signals are used to control external devices. Despite some advances in recent
years, electroencephalogram (EEG)-based motor-imagery tasks face challenges,
such as amplitude and phase variability and complex spatial correlations, with
a need for smaller models and faster inference. In this study, we develop a
prototype, called the Lightweight Geometric Learning Brain--Computer Interface
(LGL-BCI), which uses our customized geometric deep learning architecture for
swift model inference without sacrificing accuracy. LGL-BCI contains an EEG
channel selection module via a feature decomposition algorithm to reduce the
dimensionality of a symmetric positive definite matrix, providing adaptiveness
among the continuously changing EEG signal. Meanwhile, a built-in lossless
transformation helps boost the inference speed. The performance of our solution
was evaluated using two real-world EEG devices and two public EEG datasets.
LGL-BCI demonstrated significant improvements, achieving an accuracy of 82.54%
compared to 62.22% for the state-of-the-art approach. Furthermore, LGL-BCI uses
fewer parameters (64.9K vs. 183.7K), highlighting its computational efficiency.
These findings underscore both the superior accuracy and computational
efficiency of LGL-BCI, demonstrating the feasibility and robustness of
geometric deep learning in motor-imagery brain--computer interface
applications.",http://arxiv.org/abs/2501.05589v1
"Tailored Thin Films: Modulating Soft Photonics with Dynamically Tunable
  Large Area Microstructures via Controlled Thermal Processing",2025-01-10T06:04:49Z,"Srijeeta Biswas, Renu Raman Sahu, Omkar Deokinandan Nayak Shinkre, Shubham Meena, Ramnishanth, Mark Vailshery, Tapajyoti Das Gupta","Self-assembled nano and micro-structures, particularly those capable of
responsive erasure and regeneration, have garnered significant interest for
their applications in smart photonics and electronics. However, current
techniques for modulating these architectures largely depend on network
rearrangement, posing challenges for in situ regeneration. Furthermore, their
common fabrication techniques are complex and uncontrolled with the structures
formed not being amenable for large area applications, thus compromising their
economic viability. Herein, we present a controlled thermal process strategy
for fabricating large-area, dynamically tunable, 1D,2D and 3D micro and
nanostructures on a wide range of compatible materials including metals,
semiconductors and polymers. By tuning the temperature changes in the system,
thermal expansion coefficients of thin films and substrates, surface energy,
Youngs modulus and thickness of the thin films we achieve robust, uniform,
periodic structures over extensive areas on soft and stretchable substrates.
The process is further supported by a theoretical model that we developed and
validated by experiments and simulations. To showcase the robustness of our
approach, we present prototypes of dynamically tunable diffraction gratings,
optical diffusers, large-area reflective displays, camouflage devices,
out-coupling efficiency enhancers, wearable devices and mechanochromic sensors.",http://arxiv.org/abs/2501.05736v2
"Magnetism based on nitrate-nitrate interactions: The cases of LiNO$_3$,
  K$_{0.5}$Rb$_{0.5}$NO$_3$, Ca(NO$_3$)$_2$ and C(NH$_2$)$_3$NO$_3$",2025-01-10T07:11:12Z,"Na Du, Xintian Wang, Ruo Tong Wang, Enting Xu, Yu Ying Zhu, Yan Zhao, Peng Ren, Fei Yen","Long-range magnetic ordering of the orbital motion of oxygen atoms within
NO$_3$$^-$ cations is identified from experimental measurements of the magnetic
susceptibility $\chi$($T$) in LiNO$_3$, Ca(NO$_3$)$_2$,
K$_{0.5}$Rb$_{0.5}$NO$_3$ and C(NH$_2$)$_3$NO$_3$ at their respective
order-disorder, solid-solid phase transitions $T$$_N$. The observed sharp
changes in $\chi$($T$) and accompanying hysteretic behavior indicate the phase
transitions to be first order. A model employing the law of conservation of
angular momentum is used to explain why the librations between neighboring
NO$_3$$^-$ become geared below $T$$_N$. Since the periodic motions involve
concerted motion of net charges, the associated magnetic moments of the
NO$_3$$^-$ ions indirectly establish an antiferromagnetic structure below
$T$$_N$. Our findings identify a previously unidentified type of molecular
interaction which may be exploited to further increase the enthalpy of the
widely-popular hydrated salts employed as energy storage devices.",http://arxiv.org/abs/2501.05754v1
"TakuNet: an Energy-Efficient CNN for Real-Time Inference on Embedded UAV
  systems in Emergency Response Scenarios",2025-01-10T11:32:56Z,"Daniel Rossi, Guido Borghi, Roberto Vezzani","Designing efficient neural networks for embedded devices is a critical
challenge, particularly in applications requiring real-time performance, such
as aerial imaging with drones and UAVs for emergency responses. In this work,
we introduce TakuNet, a novel light-weight architecture which employs
techniques such as depth-wise convolutions and an early downsampling stem to
reduce computational complexity while maintaining high accuracy. It leverages
dense connections for fast convergence during training and uses 16-bit
floating-point precision for optimization on embedded hardware accelerators.
Experimental evaluation on two public datasets shows that TakuNet achieves
near-state-of-the-art accuracy in classifying aerial images of emergency
situations, despite its minimal parameter count. Real-world tests on embedded
devices, namely Jetson Orin Nano and Raspberry Pi, confirm TakuNet's
efficiency, achieving more than 650 fps on the 15W Jetson board, making it
suitable for real-time AI processing on resource-constrained platforms and
advancing the applicability of drones in emergency scenarios. The code and
implementation details are publicly released.",http://arxiv.org/abs/2501.05880v2
"Characterisation of H$β$ spectra from EXO 051910+3737.7 X-rays
  binaries",2025-01-10T11:34:33Z,"Pornisara Nuchvanichakul, Puji Irawati, Pakakaew Rittipruk, Poshak Gandhi, Christian Knigge, Phil Charles, Suwicha Wannawichian","We investigate the spectral characteristics of the Be/X-ray binary system,
EXO 051910+3737.7, in which Be/X-ray systems are the largest sub-class of
high-mass X-ray binaries. Spectroscopic observations are taken by the Thai
National Telescope (TNT) with a Medium-RESolution spectrograph (MRES)
instrument for seven nights spanning from 2020 to 2021. Our primary focus is
directed towards the analysis of two Balmer lines, namely H$\alpha$ and
H$\beta$, given that Be stars typically exhibit emission features in at least
one of these hydrogen Balmer lines during certain phases. Our observations
reveal split Balmer emission lines throughout the entire duration of our
monitoring. Double Gaussian profiles were employed for line fitting to
characterize these lines. The presence of double peaks in the Balmer lines
indicates the presence of asymmetries within the circumstellar disc. We then
analyze V/R variations and the changes in H$\beta$ spectra. Our analysis of V/R
variation which Violet (V) and Red (R) peak intensity components, revealed
rapid fluctuations occurring within a single day, although determining the
precise periodicity was constrained by instrumental limitations and the
duration of observability. Furthermore, employing observed the wavelength
differences ($\Delta\lambda$) in conjunction with typical Be star parameters
allowed us to estimate the radius ($r_{\beta}$) of the H$\beta$ emitting
envelope. The average value was calculated to be 2.585$r_*$, with a standard
deviation of 0.050$r_*$.",http://arxiv.org/abs/2501.05883v1
Towards Backdoor Stealthiness in Model Parameter Space,2025-01-10T12:49:12Z,"Xiaoyun Xu, Zhuoran Liu, Stefanos Koffas, Stjepan Picek","Recent research on backdoor stealthiness focuses mainly on indistinguishable
triggers in input space and inseparable backdoor representations in feature
space, aiming to circumvent backdoor defenses that examine these respective
spaces. However, existing backdoor attacks are typically designed to resist a
specific type of backdoor defense without considering the diverse range of
defense mechanisms. Based on this observation, we pose a natural question: Are
current backdoor attacks truly a real-world threat when facing diverse
practical defenses?
  To answer this question, we examine 12 common backdoor attacks that focus on
input-space or feature-space stealthiness and 17 diverse representative
defenses. Surprisingly, we reveal a critical blind spot: Backdoor attacks
designed to be stealthy in input and feature spaces can be mitigated by
examining backdoored models in parameter space. To investigate the underlying
causes behind this common vulnerability, we study the characteristics of
backdoor attacks in the parameter space. Notably, we find that input- and
feature-space attacks introduce prominent backdoor-related neurons in parameter
space, which are not thoroughly considered by current backdoor attacks. Taking
comprehensive stealthiness into account, we propose a novel supply-chain attack
called Grond. Grond limits the parameter changes by a simple yet effective
module, Adversarial Backdoor Injection (ABI), which adaptively increases the
parameter-space stealthiness during the backdoor injection. Extensive
experiments demonstrate that Grond outperforms all 12 backdoor attacks against
state-of-the-art (including adaptive) defenses on CIFAR-10, GTSRB, and a subset
of ImageNet. In addition, we show that ABI consistently improves the
effectiveness of common backdoor attacks.",http://arxiv.org/abs/2501.05928v1
CamCtrl3D: Single-Image Scene Exploration with Precise 3D Camera Control,2025-01-10T14:37:32Z,"Stefan Popov, Amit Raj, Michael Krainin, Yuanzhen Li, William T. Freeman, Michael Rubinstein","We propose a method for generating fly-through videos of a scene, from a
single image and a given camera trajectory. We build upon an image-to-video
latent diffusion model. We condition its UNet denoiser on the camera
trajectory, using four techniques. (1) We condition the UNet's temporal blocks
on raw camera extrinsics, similar to MotionCtrl. (2) We use images containing
camera rays and directions, similar to CameraCtrl. (3) We reproject the initial
image to subsequent frames and use the resulting video as a condition. (4) We
use 2D<=>3D transformers to introduce a global 3D representation, which
implicitly conditions on the camera poses. We combine all conditions in a
ContolNet-style architecture. We then propose a metric that evaluates overall
video quality and the ability to preserve details with view changes, which we
use to analyze the trade-offs of individual and combined conditions. Finally,
we identify an optimal combination of conditions. We calibrate camera positions
in our datasets for scale consistency across scenes, and we train our scene
exploration model, CamCtrl3D, demonstrating state-of-theart results.",http://arxiv.org/abs/2501.06006v2
SECRET: Stochasticity Emulator for Cosmic Ray Electrons,2025-01-10T14:48:22Z,"Nikolas Frediani, Michael Krämer, Philipp Mertsch, Kathrin Nippel","The spectrum of cosmic-ray electrons depends sensitively on the history and
spatial distribution of nearby sources. Given our limited observational handle
on cosmic-ray sources, any model remains necessarily probabilistic. Previously,
predictions were performed in a Monte Carlo fashion, summing the contributions
from individual, simulated sources to generate samples from the statistical
ensemble of possible electron spectra. Such simulations need to be re-run if
the cosmic-ray transport parameters (e.g. diffusion coefficient, maximum
energy) are changed, rendering any parameter study computationally expensive.
In addition, a proper statistical analysis of observations and comparison with
such probabilistic models requires the joint probability distribution of the
full spectrum instead of only samples. Note that parametrising this joint
distribution is rendered difficult by the non-Gaussian statistics of the
cosmic-ray fluxes. Here, we employ machine learning to compute the joint
probability distribution of cosmic-ray electron fluxes. Specifically, we employ
masked autoregressive density estimation (MADE) for a representation of the
high-dimensional joint probability distribution. In a first step, we train the
network on a Monte Carlo simulation for a fixed set of transport parameters,
thus significantly accelerating the generation of samples. In a second step, we
extend this setup to SECRET (Stochasticity Emulator for Cosmic Ray Electrons),
allowing to reliably interpolate over the space of transport parameters. We
make the MADE and SECRET codes available at
https://git.rwth-aachen.de/pmertsch/secret .",http://arxiv.org/abs/2501.06011v1
"Timing and spectral studies of the Be/X-ray binary EXO 2030+375 using
  Insight-HXMT observations",2025-01-10T14:49:43Z,"Yu-Jia Du, Lorenzo Ducci, Long Ji, Qing-Cui Bu, Ling-Da Kong, Peng-Ju Wang, Youli Tuo, Andrea Santangelo","We report the X-ray spectral and timing analysis of the high mass X-ray
binary EXO 2030+375 during the 2021 type-II outburst based on the Insight-HXMT
observations. Pulsations can be detected in the energy band of 1-150 keV. The
pulse profile shows energy and luminosity dependence and variability. We
observed transitions in the pulse profile shape during the rising and the
decaying phase of the outburst. The pulse fraction exhibits an anti-correlation
with luminosity and a non-monotonic energy dependence, with a possible dip near
30 keV during the outburst peak. The hardness-intensity diagrams (7-10 keV/4-7
keV) suggest state transitions during the early and late phases of the
outburst. These transitions are consistent with the luminosity at which the
pulse profile shape changes occur, revealing the source reaching the critical
luminosity and transitioning between super-critical and sub-critical accretion
regimes. We performed the average and phase-resolved spectral analysis, where
the flux-resolved average spectra show a stable spectral evolution with
luminosity. The phase-resolved spectral analysis reveals that the dependence of
spectral parameters on the pulse phase varies with different luminosities.",http://arxiv.org/abs/2501.06013v1
"Variation of the low-mass end of the stellar initial mass function with
  redshift and metallicity",2025-01-10T16:16:42Z,Matthew R. Bate,"We report the stellar mass functions obtained from 20 radiation
hydrodynamical simulations of star cluster formation in 500 M$_\odot$ molecular
clouds with metallicities of 3, 1, 1/10 and 1/100 of the solar value, with the
clouds subjected to levels of the cosmic microwave background radiation that
are appropriate for star formation at redshifts z=0, 3, 5, 7, and 10. The
calculations include a thermochemical model of the diffuse interstellar medium
and treat dust and gas temperatures separately. We find that the stellar mass
distributions obtained become increasingly bottom light as the redshift and/or
metallicity are increased. Mass functions that are similar to a typical
Galactic initial mass function are obtained for present-day star formation
(z=0) independent of metallicity, and also for the lowest-metallicity (1/100
solar) at all redshifts up to z=10, but for higher metallicities there is a
larger deficit of brown dwarfs and low-mass stars as the metallicity and
redshift are increased. These effects are a result of metal-rich gas being
unable to cool to as lower temperatures at higher redshift due to the warmer
cosmic microwave background radiation. Based on the numerical results we
provide a parameterisation that may be used to vary the stellar initial mass
function with redshift and metallicity; this could be used in simulations of
galaxy formation. For example, a bottom-light mass function reduces the
mass-to-light ratio compared to a typical Galactic stellar initial mass
function, which may reduce the estimated masses of high-redshift galaxies.",http://arxiv.org/abs/2501.06082v2
"Detection, Retrieval, and Explanation Unified: A Violence Detection
  System Based on Knowledge Graphs and GAT",2025-01-07T09:21:20Z,"Wen-Dong Jiang, Chih-Yung Chang, Diptendu Sinha Roy","Recently, violence detection systems developed using unified multimodal
models have achieved significant success and attracted widespread attention.
However, most of these systems face two critical challenges: the lack of
interpretability as black-box models and limited functionality, offering only
classification or retrieval capabilities. To address these challenges, this
paper proposes a novel interpretable violence detection system, termed the
Three-in-One (TIO) System. The TIO system integrates knowledge graphs (KG) and
graph attention networks (GAT) to provide three core functionalities:
detection, retrieval, and explanation. Specifically, the system processes each
video frame along with text descriptions generated by a large language model
(LLM) for videos containing potential violent behavior. It employs ImageBind to
generate high-dimensional embeddings for constructing a knowledge graph, uses
GAT for reasoning, and applies lightweight time series modules to extract video
embedding features. The final step connects a classifier and retriever for
multi-functional outputs. The interpretability of KG enables the system to
verify the reasoning process behind each output. Additionally, the paper
introduces several lightweight methods to reduce the resource consumption of
the TIO system and enhance its efficiency. Extensive experiments conducted on
the XD-Violence and UCF-Crime datasets validate the effectiveness of the
proposed system. A case study further reveals an intriguing phenomenon: as the
number of bystanders increases, the occurrence of violent behavior tends to
decrease.",http://arxiv.org/abs/2501.06224v3
The Convergence of Dynamic Routing between Capsules,2025-01-08T13:26:56Z,"Daoyuan Ye, Juntao Li, Yiting Shen","Capsule networks(CapsNet) are recently proposed neural network models with
new processing layers, specifically for entity representation and discovery of
images. It is well known that CapsNet have some advantages over traditional
neural networks, especially in generalization capability. At the same time,
some studies report negative experimental results. The causes of this
contradiction have not been thoroughly analyzed. The preliminary experimental
results show that the behavior of routing algorithms does not always produce
good results as expected, and in most cases, different routing algorithms do
not change the classification results, but simply polarize the link strength,
especially when they continue to repeat without stopping. To realize the true
potential of the CapsNet, deep mathematical analysis of the routing algorithms
is crucial. In this paper, we will give the objective function that is
minimized by the dynamic routing algorithm, which is a concave function. The
dynamic routing algorithm can be regarded as nonlinear gradient method to
solving an optimization algorithm under linear constraints, and its convergence
can be strictly proved mathematically. Furthermore, the mathematically rigorous
proof of the convergence is given for this class of iterative routing
procedures. We analyze the relation between the objective function and the
constraints solved by the dynamic routing algorithm in detail, and perform the
corresponding routing experiment to analyze the effect of our convergence
proof.",http://arxiv.org/abs/2501.06240v1
"Monolayer-Defined Flat Colloidal PbSe Quantum Dots in Extreme
  Confinement",2025-01-10T20:51:38Z,"Leon Biesterfeld, Huu Thoai Ngo, Ahmed Addad, Wolfgang Leis, Michael Seitz, Gang Ji, Bruno Grandidier, Christophe Delerue, Jannika Lauth, Louis Biadala","Colloidal two-dimensional lead chalcogenide nanocrystals represent an
intriguing new class of materials that push the boundaries of quantum
confinement by combining a crystal thickness down to the monolayer with
confinement in the lateral dimension. In particular flat PbSe quantum dots
exhibit efficient telecommunication band-friendly photoluminescence (1.43 -
0.83 eV with up to 61% quantum yield) that is highly interesting for
fiber-optics information processing. By using cryogenic scanning tunneling
microscopy and spectroscopy, we probe distinct single layer-defined PbSe
quantum dot populations down to a monolayer with in-gap state free quantum
dot-like density of states, in agreement with theoretical tight binding
calculations. Cryogenic ensemble photoluminescence spectra reveal mono-, bi-,
and trilayer contribution, confirming the structural, electronic and
theoretical results. From larger timescale shifts and ratio changes in the
optical spectra we infer Ostwald ripening in solution and fusing in deposited
samples of thinner flat PbSe quantum dots, which can be slowed down by surface
passivation with PbI2. By uncovering the interplay between thickness, lateral
size and density of states, as well as the synthetic conditions and
post-synthetic handling, our findings enable the target-oriented synthesis of
two-dimensional PbSe quantum dots with precisely tailored optical properties at
telecom wavelengths.",http://arxiv.org/abs/2501.06341v1
A Predicted Great Dimming of T Tauri: Has it Begun?,2025-01-10T22:57:48Z,Tracy L. Beck,"The optical star in the T Tauri triple system is the prototype of young
sun-like stars in our galaxy. This complex and dynamic system has evidence for
misaligned disks and outflows, and molecular material in a circumbinary ring
that obscures the southern infrared binary, T Tau South. Observations by
members of the American Association of Variable Star Observers (AAVSO) show
that T Tau North, the optical star, has dimmed by up to ~2 magnitudes in the
visual over the course of the past decade. The dimming across the B, V, R and I
bands has a color character typical of changes in ISM extinction, suggesting an
increase in obscuration along the line of sight to T Tau North. Material
associated with the circumbinary ring around T Tau South has been predicted to
occult the optical star via wide-scale orbital motion of the system. Through
analysis of the geometrical configuration and motion of dust structures in the
system, it seems that a great dimming of T Tau North by line-of-sight material
associated with the T Tau South binary has, in fact, begun. Based on the extent
and motion of the circumbinary ring material associated with the southern
binary, T Tau North will likely experience dimming events for decades to come
and may disappear entirely from the optical sky as the densest mid-plane region
of the ring traverses our line of sight.",http://arxiv.org/abs/2501.06378v1
Influencing Humans to Conform to Preference Models for RLHF,2025-01-11T03:12:53Z,"Stephane Hatgis-Kessell, W. Bradley Knox, Serena Booth, Scott Niekum, Peter Stone","Designing a reinforcement learning from human feedback (RLHF) algorithm to
approximate a human's unobservable reward function requires assuming,
implicitly or explicitly, a model of human preferences. A preference model that
poorly describes how humans generate preferences risks learning a poor
approximation of the human's reward function. In this paper, we conduct three
human studies to asses whether one can influence the expression of real human
preferences to more closely conform to a desired preference model. Importantly,
our approach does not seek to alter the human's unobserved reward function.
Rather, we change how humans use this reward function to generate preferences,
such that they better match whatever preference model is assumed by a
particular RLHF algorithm. We introduce three interventions: showing humans the
quantities that underlie a preference model, which is normally unobservable
information derived from the reward function; training people to follow a
specific preference model; and modifying the preference elicitation question.
All intervention types show significant effects, providing practical tools to
improve preference data quality and the resultant alignment of the learned
reward functions. Overall we establish a novel research direction in model
alignment: designing interfaces and training interventions to increase human
conformance with the modeling assumptions of the algorithm that will learn from
their input.",http://arxiv.org/abs/2501.06416v2
"Optimizing digital experiences with content delivery networks:
  Architectures, performance strategies, and future trends",2025-01-11T03:47:04Z,Anuj Tyagi,"This research investigates how CDNs (Content Delivery Networks) can improve
the digital experience, as consumers increasingly expect fast, efficient, and
effortless access to online resources. CDNs play a crucial role in reducing
latency, enhancing scalability, and optimizing delivery mechanisms, which is
evident across various platforms and regions. The study focuses on key CDN
concerns, such as foundational and modern CDN architectures, edge computing,
hybrid CDNs, and multi-CDN strategies. It also explores performance-enhancing
topics, including caching, load balancing, and the novel features of HTTP/3 and
QUIC.
  Current trends, such as integrating CDNs with 5G networks, serverless
architectures, and AI-driven traffic management, are examined to demonstrate
how CDN technology is likely to evolve. The study also addresses challenges
related to security, cost, and global regulations. Practical examples from the
e-commerce, streaming, and gaming industries highlight how enhanced CDNs are
transforming these sectors.
  The conclusions emphasize the need to evolve CDN strategies to meet growing
user expectations and adapt to the rapidly changing digital landscape.
Additionally, the research identifies future research opportunities,
particularly in exploring the impact of QC, the enhancement of AI services, and
the sustainability of CDN solutions. Overall, the study situates architectural
design, performance strategies, and emerging trends to address gaps and create
a more efficient and secure approach for improving digital experiences.",http://arxiv.org/abs/2501.06428v1
"Not real or too soft? On the challenges of publishing interdisciplinary
  software engineering research",2025-01-11T12:18:46Z,"Sonja M. Hyrynsalmi, Grischa Liebel, Ronnie de Souza Santos, Sebastian Baltes","The discipline of software engineering (SE) combines social and technological
dimensions. It is an interdisciplinary research field. However,
interdisciplinary research submitted to software engineering venues may not
receive the same level of recognition as more traditional or technical topics
such as software testing. For this paper, we conducted an online survey of 73
SE researchers and used a mixed-method data analysis approach to investigate
their challenges and recommendations when publishing interdisciplinary research
in SE. We found that the challenges of publishing interdisciplinary research in
SE can be divided into topic-related and reviewing-related challenges.
Furthermore, while our initial focus was on publishing interdisciplinary
research, the impact of current reviewing practices on marginalized groups
emerged from our data, as we found that marginalized groups are more likely to
receive negative feedback. In addition, we found that experienced researchers
are less likely to change their research direction due to feedback they
receive. To address the identified challenges, our participants emphasize the
importance of highlighting the impact and value of interdisciplinary work for
SE, collaborating with experienced researchers, and establishing clearer
submission guidelines and new interdisciplinary SE publication venues. Our
findings contribute to the understanding of the current state of the SE
research community and how we could better support interdisciplinary research
in our field.",http://arxiv.org/abs/2501.06523v1
Origin likelihood functions for extreme-energy cosmic rays,2025-01-12T00:47:40Z,Leonel Morejon,"Unlike neutrinos and photons arriving from extra-galactic sources, ultra-high
energy cosmic rays (UHECRs) do not trace back to their origins due to
propagation effects such as magnetic deflections and energy losses. For ankle
energies, UHECRs can propagate for hundreds of megaparsecs with negligible
energy losses but the directional information is lost after a few megaparsecs.
On the other hand, at the highest energies the directions are kept for larger
distances due to the increased rigidity but the interaction rates with the
cosmic microwave background strongly suppress the cosmic rays within a few to
tens of megaparsecs. Therefore, UHECRs with energies $E > 10^{20}$ eV
(extreme-energy cosmic rays (ExECRs)) such as the Amaterasu event recently
reported by Telescope Array, are of particular interest to identify the sources
within our galactic neighborhood. However, photonuclear interactions are
stochastic in nature and produce changes in the nuclear species emitted, which
makes it difficult the task of estimating the likelihood distribution of its
origin. This work discusses a novel procedure to estimate the likelihood of the
origin for extreme-energy cosmic rays based on probability distributions for
UHECR stochastic interactions. The method is applied to the Amaterasu event and
compared to recently published works which employ Monte Carlo codes (e.g.
CRPropa) in their analysis. The advantages of the method presented here are
demonstrated by the increased resolution and the ease of computation unlike
other approaches employed so far. The results presented indicate that the
localization of the origin of extreme energy cosmic rays could be possible in
some cases without knowledge of the original composition.",http://arxiv.org/abs/2501.06677v1
"Precise measurement of CP violating $τ$ EDM through $e^+ e^- \to
  γ^*, ψ(2s) \to τ^+ τ^-$",2025-01-12T02:35:20Z,"Xiao-Gang He, Chia-Wei Liu, Jian-Ping Ma, Chang Yang, Zi-Yue Zou","A nonzero electric dipole moment of a tauon, $d_\tau$, signals CP violation
and provides an important probe for new physics. We study methods to measure
$d_\tau$ at low energy $e^+ e^-$ colliders through the processes $e^+e^- \to
\gamma^*, \psi(2S) \to \tau^+\tau^-$ with $\tau^\pm$ decays into a charged
hadron and a tau neutrino. We point out that, with measuring energies of the
charged hadron, Im$(d_\tau)$ can be measured. On the other hand, selecting
events of $\tau$ decays after traveling more than the detector resolution
distance, Re$(d_\tau)$ can also be determined. We find that the precision at
Super Tau-Charm Facility (STCF) running at the center energy of $m_{\psi (2S)}$
for 10 year data accumulation, the precision of Im$(d_\tau)$ and Re$(d_\tau)$
are found to be 3.5 and 11 in unit of $10^{-18}~e\,\text{cm}$, respectively.
The sensitivity for $d_\tau$ measurement precision at the STCF can be reached
its optimum at a central energy of $6.3~\text{GeV}$, achieving a precision of
$1.3$ for Im$(d_\tau)$ and $2.9$ for Re$(d_\tau)$ in unit of $
10^{-18}~e\,\text{cm}$.",http://arxiv.org/abs/2501.06687v1
"Impact of Coulomb Correction Factor on Rate of Change of Lepton Fraction
  during Presupernova Evolution",2025-01-12T07:55:31Z,"Asim Ullah, Jameel-Un Nabi","We reexamine the weak interaction nuclei having largest contribution to the
lepton to baryon fraction Ye by coupling the stellar weak rates and mass
abundances for post silicon burning conditions during the presupernova
evolution of massive stars. The stellar weak rates were recently calculated by
Nabi et al. 2021 employing the fully microscopic pnQRPA model without invoking
the Brink Axel hypothesis. We compute the mass abundances for a total of 728
nuclei, with A equal 1to 100, using Sahas equation and assuming nuclear
statistical equilibrium with the incorporation of Coulomb correction factor to
the chemical potential. We compile a list of top 50 electron capture ec and
\b{eta} decay bd nuclei on the basis of largest contribution to Ye forpost
silicon burning conditions where 11 percent ec and 6percent bd nuclei debuted
dueto Coulomb corrections. The calculated mass abundances and corresponding Ye
values are enhanced up to 3 orders of magnitude for heavier nuclei once Coulomb
corrections were incorporated. This enhancement led to anincrement in total Y
bde and Yece values, at Ye equal to 0.425 (\r{ho} equal 2.20 multiply 109 g/cm3
of 80percent and 91percent respectively. After incorporating the Coulomb
corrections we propose a revised interval of Ye equal 0.423 0.455 where bd
rates surpass thecompeting ec rates and is 3.2 percent bigger than the one
suggested by Nabi et al. (2021).",http://arxiv.org/abs/2501.06742v1
"Improving the adaptive and continuous learning capabilities of
  artificial neural networks: Lessons from multi-neuromodulatory dynamics",2025-01-12T10:10:01Z,"Jie Mei, Alejandro Rodriguez-Garcia, Daigo Takeuchi, Gabriel Wainstein, Nina Hubig, Yalda Mohsenzadeh, Srikanth Ramaswamy","Continuous, adaptive learning-the ability to adapt to the environment and
improve performance-is a hallmark of both natural and artificial intelligence.
Biological organisms excel in acquiring, transferring, and retaining knowledge
while adapting to dynamic environments, making them a rich source of
inspiration for artificial neural networks (ANNs). This study explores how
neuromodulation, a fundamental feature of biological learning systems, can help
address challenges such as catastrophic forgetting and enhance the robustness
of ANNs in continuous learning scenarios. Driven by neuromodulators including
dopamine (DA), acetylcholine (ACh), serotonin (5-HT) and noradrenaline (NA),
neuromodulatory processes in the brain operate at multiple scales, facilitating
dynamic responses to environmental changes through mechanisms ranging from
local synaptic plasticity to global network-wide adaptability. Importantly, the
relationship between neuromodulators, and their interplay in the modulation of
sensory and cognitive processes are more complex than expected, demonstrating a
""many-to-one"" neuromodulator-to-task mapping. To inspire the design of novel
neuromodulation-aware learning rules, we highlight (i) how
multi-neuromodulatory interactions enrich single-neuromodulator-driven
learning, (ii) the impact of neuromodulators at multiple spatial and temporal
scales, and correspondingly, (iii) strategies to integrate neuromodulated
learning into or approximate it in ANNs. To illustrate these principles, we
present a case study to demonstrate how neuromodulation-inspired mechanisms,
such as DA-driven reward processing and NA-based cognitive flexibility, can
enhance ANN performance in a Go/No-Go task. By integrating multi-scale
neuromodulation, we aim to bridge the gap between biological learning and
artificial systems, paving the way for ANNs with greater flexibility,
robustness, and adaptability.",http://arxiv.org/abs/2501.06762v1
"SuperNeRF-GAN: A Universal 3D-Consistent Super-Resolution Framework for
  Efficient and Enhanced 3D-Aware Image Synthesis",2025-01-12T10:31:33Z,"Peng Zheng, Linzhi Huang, Yizhou Yu, Yi Chang, Yilin Wang, Rui Ma","Neural volume rendering techniques, such as NeRF, have revolutionized
3D-aware image synthesis by enabling the generation of images of a single scene
or object from various camera poses. However, the high computational cost of
NeRF presents challenges for synthesizing high-resolution (HR) images. Most
existing methods address this issue by leveraging 2D super-resolution, which
compromise 3D-consistency. Other methods propose radiance manifolds or
two-stage generation to achieve 3D-consistent HR synthesis, yet they are
limited to specific synthesis tasks, reducing their universality. To tackle
these challenges, we propose SuperNeRF-GAN, a universal framework for
3D-consistent super-resolution. A key highlight of SuperNeRF-GAN is its
seamless integration with NeRF-based 3D-aware image synthesis methods and it
can simultaneously enhance the resolution of generated images while preserving
3D-consistency and reducing computational cost. Specifically, given a
pre-trained generator capable of producing a NeRF representation such as
tri-plane, we first perform volume rendering to obtain a low-resolution image
with corresponding depth and normal map. Then, we employ a NeRF
Super-Resolution module which learns a network to obtain a high-resolution
NeRF. Next, we propose a novel Depth-Guided Rendering process which contains
three simple yet effective steps, including the construction of a
boundary-correct multi-depth map through depth aggregation, a normal-guided
depth super-resolution and a depth-guided NeRF rendering. Experimental results
demonstrate the superior efficiency, 3D-consistency, and quality of our
approach. Additionally, ablation studies confirm the effectiveness of our
proposed components.",http://arxiv.org/abs/2501.06770v2
"Improved joint modelling of breast cancer radiomics features and hazard
  by image registration aided longitudinal CT data",2025-01-12T14:07:30Z,Subrata Mukherjee,"Patients with metastatic breast cancer (mBC) undergo continuous medical
imaging during treatment, making accurate lesion detection and monitoring over
time critical for clinical decisions. Predicting drug response from
post-treatment data is essential for personalized care and pharmacological
research. In collaboration with the U.S. Food and Drug Administration and
Novartis Pharmaceuticals, we analyzed serial chest CT scans from two
large-scale Phase III trials, MONALEESA 3 and MONALEESA 7. This paper has two
objectives (a) Data Structuring developing a Registration Aided Automated
Correspondence (RAMAC) algorithm for precise lesion tracking in longitudinal CT
data, and (b) Survival Analysis creating imaging features and models from RAMAC
structured data to predict patient outcomes. The RAMAC algorithm uses a two
phase pipeline: three dimensional rigid registration aligns CT images, and a
distance metric-based Hungarian algorithm tracks lesion correspondence. Using
structured data, we developed interpretable models to assess progression-free
survival (PFS) in mBC patients by combining baseline radiomics, post-treatment
changes (Weeks 8, 16, 24), and demographic features. Radiomics effects were
studied across time points separately and through a non-correlated additive
framework. Radiomics features were reduced using (a) a regularized
(L1-penalized) additive Cox proportional hazards model, and (b) variable
selection via best subset selection. Performance, measured using the
concordance index (C-index), improved with additional time points. Joint
modeling, considering correlations among radiomics effects over time, provided
insights into relationships between longitudinal radiomics and survival
outcomes.",http://arxiv.org/abs/2501.06814v2
"Towards Counterfactual and Contrastive Explainability and Transparency
  of DCNN Image Classifiers",2025-01-12T14:54:02Z,"Syed Ali Tariq, Tehseen Zia, Mubeen Ghafoor","Explainability of deep convolutional neural networks (DCNNs) is an important
research topic that tries to uncover the reasons behind a DCNN model's
decisions and improve their understanding and reliability in high-risk
environments. In this regard, we propose a novel method for generating
interpretable counterfactual and contrastive explanations for DCNN models. The
proposed method is model intrusive that probes the internal workings of a DCNN
instead of altering the input image to generate explanations. Given an input
image, we provide contrastive explanations by identifying the most important
filters in the DCNN representing features and concepts that separate the
model's decision between classifying the image to the original inferred class
or some other specified alter class. On the other hand, we provide
counterfactual explanations by specifying the minimal changes necessary in such
filters so that a contrastive output is obtained.
  Using these identified filters and concepts, our method can provide
contrastive and counterfactual reasons behind a model's decisions and makes the
model more transparent. One of the interesting applications of this method is
misclassification analysis, where we compare the identified concepts from a
particular input image and compare them with class-specific concepts to
establish the validity of the model's decisions. The proposed method is
compared with state-of-the-art and evaluated on the Caltech-UCSD Birds (CUB)
2011 dataset to show the usefulness of the explanations provided.",http://arxiv.org/abs/2501.06831v1
"A novel multi-agent dynamic portfolio optimization learning system based
  on hierarchical deep reinforcement learning",2025-01-12T15:00:02Z,"Ruoyu Sun, Yue Xi, Angelos Stefanidis, Zhengyong Jiang, Jionglong Su","Deep Reinforcement Learning (DRL) has been extensively used to address
portfolio optimization problems. The DRL agents acquire knowledge and make
decisions through unsupervised interactions with their environment without
requiring explicit knowledge of the joint dynamics of portfolio assets. Among
these DRL algorithms, the combination of actor-critic algorithms and deep
function approximators is the most widely used DRL algorithm. Here, we find
that training the DRL agent using the actor-critic algorithm and deep function
approximators may lead to scenarios where the improvement in the DRL agent's
risk-adjusted profitability is not significant. We propose that such situations
primarily arise from the following two problems: sparsity in positive reward
and the curse of dimensionality. These limitations prevent DRL agents from
comprehensively learning asset price change patterns in the training
environment. As a result, the DRL agents cannot explore the dynamic portfolio
optimization policy to improve the risk-adjusted profitability in the training
process. To address these problems, we propose a novel multi-agent Hierarchical
Deep Reinforcement Learning (HDRL) algorithmic framework in this research.
Under this framework, the agents work together as a learning system for
portfolio optimization. Specifically, by designing an auxiliary agent that
works together with the executive agent for optimal policy exploration, the
learning system can focus on exploring the policy with higher risk-adjusted
return in the action space with positive return and low variance. In this way,
we can overcome the issue of the curse of dimensionality and improve the
training efficiency in the positive reward sparse environment.",http://arxiv.org/abs/2501.06832v1
Integrators at War: Mediating in AI-assisted Resort-to-Force Decisions,2025-01-12T16:21:33Z,"Dennis Müller, Maurice Chiodo, Mitja Sienknecht","The integration of AI systems into the military domain is changing the way
war-related decisions are made. It binds together three disparate groups of
actors - developers, integrators, users - and creates a relationship between
these groups and the machine, embedded in the (pre-)existing organisational and
system structures. In this article, we focus on the important, but often
neglected, group of integrators within such a sociotechnical system. In complex
human-machine configurations, integrators carry responsibility for linking the
disparate groups of developers and users in the political and military system.
To act as the mediating group requires a deep understanding of the other
groups' activities, perspectives and norms. We thus ask which challenges and
shortcomings emerge from integrating AI systems into resort-to-force (RTF)
decision-making processes, and how to address them. To answer this, we proceed
in three steps. First, we conceptualise the relationship between different
groups of actors and AI systems as a sociotechnical system. Second, we identify
challenges within such systems for human-machine teaming in RTF decisions. We
focus on challenges that arise a) from the technology itself, b) from the
integrators' role in the sociotechnical system, c) from the human-machine
interaction. Third, we provide policy recommendations to address these
shortcomings when integrating AI systems into RTF decision-making structures.",http://arxiv.org/abs/2501.06861v1
A Flux-Tunable cavity for Dark matter detection,2025-01-12T17:30:51Z,"Fang Zhao, Ziqian Li, Akash V. Dixit, Tanay Roy, Andrei Vrajitoarea, Riju Banerjee, Alexander Anferov, Kan-Heng Lee, David I. Schuster, Aaron Chou","Developing a dark matter detector with wide mass tunability is an immensely
desirable property, yet it is challenging due to maintaining strong
sensitivity. Resonant cavities for dark matter detection have traditionally
employed mechanical tuning, moving parts around to change electromagnetic
boundary conditions. However, these cavities have proven challenging to operate
in sub-Kelvin cryogenic environments due to differential thermal contraction,
low heat capacities, and low thermal conductivities. Instead, we develop an
electronically tunable cavity architecture by coupling a superconducting 3D
microwave cavity with a DC flux tunable SQUID. With a flux delivery system
engineered to maintain high coherence in the cavity, we perform a hidden-photon
dark matter search below the quantum-limited threshold. A microwave photon
counting technique is employed through repeated quantum non-demolition
measurements using a transmon qubit. With this device, we perform a
hidden-photon search with a dark count rate of around 64 counts/s and constrain
the kinetic mixing angle to ${\varepsilon}< 4\times 10^{-13}$ in a tunable band
from 5.672 GHz to 5.694 GHz. By coupling multimode tunable cavities to the
transmon, wider hidden-photon searching ranges are possible.",http://arxiv.org/abs/2501.06882v1
"TFLAG:Towards Practical APT Detection via Deviation-Aware Learning on
  Temporal Provenance Graph",2025-01-13T01:08:06Z,"Wenhan Jiang, Tingting Chai, Hongri Liu, Kai Wang, Hongke Zhang","Advanced Persistent Threat (APT) have grown increasingly complex and
concealed, posing formidable challenges to existing Intrusion Detection Systems
in identifying and mitigating these attacks. Recent studies have incorporated
graph learning techniques to extract detailed information from provenance
graphs, enabling the detection of attacks with greater granularity.
Nevertheless, existing studies have largely overlooked the continuous yet
subtle temporal variations in the structure of provenance graphs, which may
correspond to surreptitious perturbation anomalies in ongoing APT attacks.
Therefore, we introduce TFLAG, an advanced anomaly detection framework that for
the first time integrates the structural dynamic extraction capabilities of
temporal graph model with the anomaly delineation abilities of deviation
networks to pinpoint covert attack activities in provenance graphs. This
self-supervised integration framework leverages the graph model to extract
neighbor interaction data under continuous temporal changes from historical
benign behaviors within provenance graphs, while simultaneously utilizing
deviation networks to accurately distinguish authentic attack activities from
false positive deviations due to unexpected subtle perturbations. The
experimental results indicate that, through a comprehensive design that
utilizes both attribute and temporal information, it can accurately identify
the time windows associated with APT attack behaviors without prior knowledge
(e.g., labeled data samples), demonstrating superior accuracy compared to
current state-of-the-art methods in differentiating between attack events and
system false positive events.",http://arxiv.org/abs/2501.06997v1
"Detection of AI Deepfake and Fraud in Online Payments Using GAN-Based
  Models",2025-01-13T03:10:54Z,"Zong Ke, Shicheng Zhou, Yining Zhou, Chia Hong Chang, Rong Zhang","This study explores the use of Generative Adversarial Networks (GANs) to
detect AI deepfakes and fraudulent activities in online payment systems. With
the growing prevalence of deepfake technology, which can manipulate facial
features in images and videos, the potential for fraud in online transactions
has escalated. Traditional security systems struggle to identify these
sophisticated forms of fraud. This research proposes a novel GAN-based model
that enhances online payment security by identifying subtle manipulations in
payment images. The model is trained on a dataset consisting of real-world
online payment images and deepfake images generated using advanced GAN
architectures, such as StyleGAN and DeepFake. The results demonstrate that the
proposed model can accurately distinguish between legitimate transactions and
deepfakes, achieving a high detection rate above 95%. This approach
significantly improves the robustness of payment systems against AI-driven
fraud. The paper contributes to the growing field of digital security, offering
insights into the application of GANs for fraud detection in financial
services. Keywords- Payment Security, Image Recognition, Generative Adversarial
Networks, AI Deepfake, Fraudulent Activities",http://arxiv.org/abs/2501.07033v1
"From trees to traits: A review of advances in PhyloG2P methods and
  future directions",2025-01-13T03:51:07Z,"Arlie R. Macdonald, Maddie E. James, Jonathan D. Mitchell, Barbara R. Holland","Mapping genotypes to phenotypes (G2P) is a fundamental goal in biology. So
called PhyloG2P methods are a relatively new set of tools that leverage
replicated evolution in phylogenetically independent lineages to identify
genomic regions associated with traits of interest. Here, we review recent
developments in PhyloG2P methods, focusing on three key areas: methods based on
replicated amino acid substitutions, methods detecting changes in evolutionary
rates, and methods analysing gene duplication and loss. We discuss how the
definition and measurement of traits impacts the utility of these methods,
arguing that focusing on simple rather than compound traits will lead to more
meaningful genotype-phenotype associations. We advocate for the use of methods
that work with continuous traits directly rather than collapsing them to binary
representations. We examine the strengths and limitations of different
approaches to modeling genetic replication, highlighting the importance of
explicit modeling of evolutionary processes. Finally, we outline promising
future directions, including the integration of population-level variation, as
well as epigenetic and environmental information. No one method is likely to
identify all genomic regions of interest, so we encourage users to apply
multiple methods that are capable of detecting a wide range of associations.
The overall aim of this review is to provide practitioners a roadmap for
understanding and applying PhyloG2P methods.",http://arxiv.org/abs/2501.07043v1
"Collaborative Learning for 3D Hand-Object Reconstruction and
  Compositional Action Recognition from Egocentric RGB Videos Using
  Superquadrics",2025-01-13T07:26:05Z,"Tze Ho Elden Tse, Runyang Feng, Linfang Zheng, Jiho Park, Yixing Gao, Jihie Kim, Ales Leonardis, Hyung Jin Chang","With the availability of egocentric 3D hand-object interaction datasets,
there is increasing interest in developing unified models for hand-object pose
estimation and action recognition. However, existing methods still struggle to
recognise seen actions on unseen objects due to the limitations in representing
object shape and movement using 3D bounding boxes. Additionally, the reliance
on object templates at test time limits their generalisability to unseen
objects. To address these challenges, we propose to leverage superquadrics as
an alternative 3D object representation to bounding boxes and demonstrate their
effectiveness on both template-free object reconstruction and action
recognition tasks. Moreover, as we find that pure appearance-based methods can
outperform the unified methods, the potential benefits from 3D geometric
information remain unclear. Therefore, we study the compositionality of actions
by considering a more challenging task where the training combinations of verbs
and nouns do not overlap with the testing split. We extend H2O and FPHA
datasets with compositional splits and design a novel collaborative learning
framework that can explicitly reason about the geometric relations between
hands and the manipulated object. Through extensive quantitative and
qualitative evaluations, we demonstrate significant improvements over the
state-of-the-arts in (compositional) action recognition.",http://arxiv.org/abs/2501.07100v1
How GPT learns layer by layer,2025-01-13T07:42:55Z,"Jason Du, Kelly Hong, Alishba Imran, Erfan Jahanparast, Mehdi Khfifi, Kaichun Qiao","Large Language Models (LLMs) excel at tasks like language processing,
strategy games, and reasoning but struggle to build generalizable internal
representations essential for adaptive decision-making in agents. For agents to
effectively navigate complex environments, they must construct reliable world
models. While LLMs perform well on specific benchmarks, they often fail to
generalize, leading to brittle representations that limit their real-world
effectiveness. Understanding how LLMs build internal world models is key to
developing agents capable of consistent, adaptive behavior across tasks. We
analyze OthelloGPT, a GPT-based model trained on Othello gameplay, as a
controlled testbed for studying representation learning. Despite being trained
solely on next-token prediction with random valid moves, OthelloGPT shows
meaningful layer-wise progression in understanding board state and gameplay.
Early layers capture static attributes like board edges, while deeper layers
reflect dynamic tile changes. To interpret these representations, we compare
Sparse Autoencoders (SAEs) with linear probes, finding that SAEs offer more
robust, disentangled insights into compositional features, whereas linear
probes mainly detect features useful for classification. We use SAEs to decode
features related to tile color and tile stability, a previously unexamined
feature that reflects complex gameplay concepts like board control and
long-term planning. We study the progression of linear probe accuracy and tile
color using both SAE's and linear probes to compare their effectiveness at
capturing what the model is learning. Although we begin with a smaller language
model, OthelloGPT, this study establishes a framework for understanding the
internal representations learned by GPT models, transformers, and LLMs more
broadly. Our code is publicly available: https://github.com/ALT-JS/OthelloSAE.",http://arxiv.org/abs/2501.07108v1
ListConRanker: A Contrastive Text Reranker with Listwise Encoding,2025-01-13T07:51:46Z,"Junlong Liu, Yue Ma, Ruihui Zhao, Junhao Zheng, Qianli Ma, Yangyang Kang","Reranker models aim to re-rank the passages based on the semantics similarity
between the given query and passages, which have recently received more
attention due to the wide application of the Retrieval-Augmented Generation.
Most previous methods apply pointwise encoding, meaning that it can only encode
the context of the query for each passage input into the model. However, for
the reranker model, given a query, the comparison results between passages are
even more important, which is called listwise encoding. Besides, previous
models are trained using the cross-entropy loss function, which leads to issues
of unsmooth gradient changes during training and low training efficiency. To
address these issues, we propose a novel Listwise-encoded Contrastive text
reRanker (ListConRanker). It can help the passage to be compared with other
passages during the encoding process, and enhance the contrastive information
between positive examples and between positive and negative examples. At the
same time, we use the circle loss to train the model to increase the
flexibility of gradients and solve the problem of training efficiency.
Experimental results show that ListConRanker achieves state-of-the-art
performance on the reranking benchmark of Chinese Massive Text Embedding
Benchmark, including the cMedQA1.0, cMedQA2.0, MMarcoReranking, and T2Reranking
datasets.",http://arxiv.org/abs/2501.07111v1
"An Enhanced Zeroth-Order Stochastic Frank-Wolfe Framework for
  Constrained Finite-Sum Optimization",2025-01-13T10:53:19Z,"Haishan Ye, Yinghui Huang, Hao Di, Xiangyu Chang","We propose an enhanced zeroth-order stochastic Frank-Wolfe framework to
address constrained finite-sum optimization problems, a structure prevalent in
large-scale machine-learning applications. Our method introduces a novel double
variance reduction framework that effectively reduces the gradient
approximation variance induced by zeroth-order oracles and the stochastic
sampling variance from finite-sum objectives. By leveraging this framework, our
algorithm achieves significant improvements in query efficiency, making it
particularly well-suited for high-dimensional optimization tasks. Specifically,
for convex objectives, the algorithm achieves a query complexity of O(d
\sqrt{n}/\epsilon ) to find an epsilon-suboptimal solution, where d is the
dimensionality and n is the number of functions in the finite-sum objective.
For non-convex objectives, it achieves a query complexity of
O(d^{3/2}\sqrt{n}/\epsilon^2 ) without requiring the computation ofd partial
derivatives at each iteration. These complexities are the best known among
zeroth-order stochastic Frank-Wolfe algorithms that avoid explicit gradient
calculations. Empirical experiments on convex and non-convex machine learning
tasks, including sparse logistic regression, robust classification, and
adversarial attacks on deep networks, validate the computational efficiency and
scalability of our approach. Our algorithm demonstrates superior performance in
both convergence rate and query complexity compared to existing methods.",http://arxiv.org/abs/2501.07201v2
EdgeTAM: On-Device Track Anything Model,2025-01-13T12:11:07Z,"Chong Zhou, Chenchen Zhu, Yunyang Xiong, Saksham Suri, Fanyi Xiao, Lemeng Wu, Raghuraman Krishnamoorthi, Bo Dai, Chen Change Loy, Vikas Chandra, Bilge Soran","On top of Segment Anything Model (SAM), SAM 2 further extends its capability
from image to video inputs through a memory bank mechanism and obtains a
remarkable performance compared with previous methods, making it a foundation
model for video segmentation task. In this paper, we aim at making SAM 2 much
more efficient so that it even runs on mobile devices while maintaining a
comparable performance. Despite several works optimizing SAM for better
efficiency, we find they are not sufficient for SAM 2 because they all focus on
compressing the image encoder, while our benchmark shows that the newly
introduced memory attention blocks are also the latency bottleneck. Given this
observation, we propose EdgeTAM, which leverages a novel 2D Spatial Perceiver
to reduce the computational cost. In particular, the proposed 2D Spatial
Perceiver encodes the densely stored frame-level memories with a lightweight
Transformer that contains a fixed set of learnable queries. Given that video
segmentation is a dense prediction task, we find preserving the spatial
structure of the memories is essential so that the queries are split into
global-level and patch-level groups. We also propose a distillation pipeline
that further improves the performance without inference overhead. As a result,
EdgeTAM achieves 87.7, 70.0, 72.3, and 71.7 J&F on DAVIS 2017, MOSE, SA-V val,
and SA-V test, while running at 16 FPS on iPhone 15 Pro Max.",http://arxiv.org/abs/2501.07256v1
"PO-GVINS: Tightly Coupled GNSS-Visual-Inertial Integration with
  Pose-Only Representation",2025-01-13T12:14:48Z,"Zhuo Xu, Feng Zhu, Zihang Zhang, Chang Jian, Jiarui Lv, Yuantai Zhang, Xiaohong Zhang","Accurate and reliable positioning is crucial for perception, decision-making,
and other high-level applications in autonomous driving, unmanned aerial
vehicles, and intelligent robots. Given the inherent limitations of standalone
sensors, integrating heterogeneous sensors with complementary capabilities is
one of the most effective approaches to achieving this goal. In this paper, we
propose a filtering-based, tightly coupled global navigation satellite system
(GNSS)-visual-inertial positioning framework with a pose-only formulation
applied to the visual-inertial system (VINS), termed PO-GVINS. Specifically,
multiple-view imaging used in current VINS requires a priori of 3D feature,
then jointly estimate camera poses and 3D feature position, which inevitably
introduces linearization error of the feature as well as facing dimensional
explosion. However, the pose-only (PO) formulation, which is demonstrated to be
equivalent to the multiple-view imaging and has been applied in visual
reconstruction, represent feature depth using two camera poses and thus 3D
feature position is removed from state vector avoiding aforementioned
difficulties. Inspired by this, we first apply PO formulation in our VINS,
i.e., PO-VINS. GNSS raw measurements are then incorporated with integer
ambiguity resolved to achieve accurate and drift-free estimation. Extensive
experiments demonstrate that the proposed PO-VINS significantly outperforms the
multi-state constrained Kalman filter (MSCKF). By incorporating GNSS
measurements, PO-GVINS achieves accurate, drift-free state estimation, making
it a robust solution for positioning in challenging environments.",http://arxiv.org/abs/2501.07259v2
Synesthesia of Machines Based Multi-Modal Intelligent V2V Channel Model,2025-01-13T13:46:47Z,"Zengrui Han, Lu Bai, Ziwei Huang, Xiang Cheng","This paper proposes a novel sixth-generation (6G) multi-modal intelligent
vehicle-to-vehicle (V2V) channel model from light detection and ranging (LiDAR)
point clouds based on Synesthesia of Machines (SoM). To explore the mapping
relationship between physical environment and electromagnetic space, a new V2V
high-fidelity mixed sensing-communication integration simulation dataset with
different vehicular traffic densities (VTDs) is constructed. Based on the
constructed dataset, a novel scatterer recognition (ScaR) algorithm utilizing
neural network SegNet is developed to recognize scatterer spatial attributes
from LiDAR point clouds via SoM. In the developed ScaR algorithm, the mapping
relationship between LiDAR point clouds and scatterers is explored, where the
distribution of scatterers is obtained in the form of grid maps. Furthermore,
scatterers are distinguished into dynamic and static scatterers based on LiDAR
point cloud features, where parameters, e.g., distance, angle, and number,
related to scatterers are determined. Through ScaR, dynamic and static
scatterers change with the variation of LiDAR point clouds over time, which
precisely models channel non-stationarity and consistency under different VTDs.
Some important channel statistical properties, such as time-frequency
correlation function (TF-CF) and Doppler power spectral density (DPSD), are
obtained. Simulation results match well with ray-tracing (RT)-based results,
thus demonstrating the necessity of exploring the mapping relationship and the
utility of the proposed model.",http://arxiv.org/abs/2501.07333v1
"MVICAD2: Multi-View Independent Component Analysis with Delays and
  Dilations",2025-01-13T15:47:02Z,"Ambroise Heurtebise, Omar Chehab, Pierre Ablin, Alexandre Gramfort","Machine learning techniques in multi-view settings face significant
challenges, particularly when integrating heterogeneous data, aligning feature
spaces, and managing view-specific biases. These issues are prominent in
neuroscience, where data from multiple subjects exposed to the same stimuli are
analyzed to uncover brain activity dynamics. In magnetoencephalography (MEG),
where signals are captured at the scalp level, estimating the brain's
underlying sources is crucial, especially in group studies where sources are
assumed to be similar for all subjects. Common methods, such as Multi-View
Independent Component Analysis (MVICA), assume identical sources across
subjects, but this assumption is often too restrictive due to individual
variability and age-related changes. Multi-View Independent Component Analysis
with Delays (MVICAD) addresses this by allowing sources to differ up to a
temporal delay. However, temporal dilation effects, particularly in auditory
stimuli, are common in brain dynamics, making the estimation of time delays
alone insufficient. To address this, we propose Multi-View Independent
Component Analysis with Delays and Dilations (MVICAD2), which allows sources to
differ across subjects in both temporal delays and dilations. We present a
model with identifiable sources, derive an approximation of its likelihood in
closed form, and use regularization and optimization techniques to enhance
performance. Through simulations, we demonstrate that MVICAD2 outperforms
existing multi-view ICA methods. We further validate its effectiveness using
the Cam-CAN dataset, and showing how delays and dilations are related to aging.",http://arxiv.org/abs/2501.07426v1
"Gravitational-wave memory effects in the Damour-Esposito-Farèse
  extension of Brans-Dicke theory",2025-01-13T17:05:56Z,"Shammi Tahura, David A. Nichols, Kent Yagi","Gravitational-wave memory effects are lasting changes in the strain and its
time integrals. They can be computed in asymptotically flat spacetimes using
the conservation and evolution equations in the Bondi-Sachs framework. Modified
theories of gravity have additional degrees of freedom with their own
asymptotic evolution equations; these additional fields can produce differences
in the memory effects in these theories from those in general relativity. In
this work, we study a scalar-tensor theory of gravity known as the
Damour-Esposito-Far\`ese extension of Brans-Dicke theory. We use the
Bondi-Sachs framework to compute the field equations in Bondi-Sachs form, the
asymptotically flat solutions, and the leading gravitational-wave memory
effects. Although Damour-Esposito-Far\`ese theory has additional nonlinearities
not present in Brans-Dicke theory, these nonlinearities are subleading effects;
thus, the two theories share many similarities in the leading (and some
subleading) solutions to hypersurface equations, asymptotic symmetries, and
types of memory effects. The conservation equations for the mass and angular
momentum aspects differ between the two theories, primarily because of the
differences in the evolution equation for the scalar field. This leads to
differences in the time dependence of the gravitational-wave memory signals
that are produced during the quasicircular inspiral of compact binaries. These
differences, however, are of second-order in a small coupling parameter of
these theories, which suggests that it would be challenging to use memory
effects to distinguish between these two theories.",http://arxiv.org/abs/2501.07488v1
Evaluating Agent-based Program Repair at Google,2025-01-13T18:09:25Z,"Pat Rondon, Renyao Wei, José Cambronero, Jürgen Cito, Aaron Sun, Siddhant Sanyam, Michele Tufano, Satish Chandra","Agent-based program repair offers to automatically resolve complex bugs
end-to-end by combining the planning, tool use, and code generation abilities
of modern LLMs. Recent work has explored the use of agent-based repair
approaches on the popular open-source SWE-Bench, a collection of bugs from
highly-rated GitHub Python projects. In addition, various agentic approaches
such as SWE-Agent have been proposed to solve bugs in this benchmark. This
paper explores the viability of using an agentic approach to address bugs in an
enterprise context. To investigate this, we curate an evaluation set of 178
bugs drawn from Google's issue tracking system. This dataset spans both
human-reported (78) and machine-reported bugs (100).
  To establish a repair performance baseline on this benchmark, we implement
Passerine, an agent similar in spirit to SWE-Agent that can work within
Google's development environment. We show that with 20 trajectory samples and
Gemini 1.5 Pro, Passerine can produce a patch that passes bug tests (i.e.,
plausible) for 73% of machine-reported and 25.6% of human-reported bugs in our
evaluation set. After manual examination, we found that 43% of machine-reported
bugs and 17.9% of human-reported bugs have at least one patch that is
semantically equivalent to the ground-truth patch.
  These results establish a baseline on an industrially relevant benchmark,
which as we show, contains bugs drawn from a different distribution -- in terms
of language diversity, size, and spread of changes, etc. -- compared to those
in the popular SWE-Bench dataset.",http://arxiv.org/abs/2501.07531v1
"MatchAnything: Universal Cross-Modality Image Matching with Large-Scale
  Pre-Training",2025-01-13T18:37:36Z,"Xingyi He, Hao Yu, Sida Peng, Dongli Tan, Zehong Shen, Hujun Bao, Xiaowei Zhou","Image matching, which aims to identify corresponding pixel locations between
images, is crucial in a wide range of scientific disciplines, aiding in image
registration, fusion, and analysis. In recent years, deep learning-based image
matching algorithms have dramatically outperformed humans in rapidly and
accurately finding large amounts of correspondences. However, when dealing with
images captured under different imaging modalities that result in significant
appearance changes, the performance of these algorithms often deteriorates due
to the scarcity of annotated cross-modal training data. This limitation hinders
applications in various fields that rely on multiple image modalities to obtain
complementary information. To address this challenge, we propose a large-scale
pre-training framework that utilizes synthetic cross-modal training signals,
incorporating diverse data from various sources, to train models to recognize
and match fundamental structures across images. This capability is transferable
to real-world, unseen cross-modality image matching tasks. Our key finding is
that the matching model trained with our framework achieves remarkable
generalizability across more than eight unseen cross-modality registration
tasks using the same network weight, substantially outperforming existing
methods, whether designed for generalization or tailored for specific tasks.
This advancement significantly enhances the applicability of image matching
technologies across various scientific disciplines and paves the way for new
applications in multi-modality human and artificial intelligence analysis and
beyond.",http://arxiv.org/abs/2501.07556v1
"Multi-task Domain Adaptation for Computation Offloading in
  Edge-intelligence Networks",2025-01-02T13:20:29Z,"Runxin Han, Bo Yang, Zhiwen Yu, Xuelin Cao, George C. Alexandropoulos, Chau Yuen","In the field of multi-access edge computing (MEC), efficient computation
offloading is crucial for improving resource utilization and reducing latency
in dynamically changing environments. This paper introduces a new approach,
termed as Multi-Task Domain Adaptation (MTDA), aiming to enhance the ability of
computational offloading models to generalize in the presence of domain shifts,
i.e., when new data in the target environment significantly differs from the
data in the source domain. The proposed MTDA model incorporates a
teacher-student architecture that allows continuous adaptation without
necessitating access to the source domain data during inference, thereby
maintaining privacy and reducing computational overhead. Utilizing a multi-task
learning framework that simultaneously manages offloading decisions and
resource allocation, the proposed MTDA approach outperforms benchmark methods
regarding mean squared error and accuracy, particularly in environments with
increasing numbers of users. It is observed by means of computer simulation
that the proposed MTDA model maintains high performance across various
scenarios, demonstrating its potential for practical deployment in emerging MEC
applications.",http://arxiv.org/abs/2501.07585v1
"NuSTAR observations of a varying-flux quasar in the Epoch of
  Reionization",2025-01-13T19:01:03Z,"Lea Marcotulli, Thomas Connor, Eduardo Bañados, Peter G. Boorman, Giulia Migliori, Brian W. Grefenstette, Emmanuel Momjian, Aneta Siemiginowska, Daniel Stern, Silvia Belladitta, C. C. Cheung, Andrew Fabian, Yana Khusanova, Chiara Mazzucchelli, Sofía Rojas-Ruiz, C. Megan Urry","With enough X-ray flux to be detected in a 160s scan by SRG/eROSITA, the $z =
6.19$ quasar CFHQS J142952+544717 is, by far, the most luminous X-ray source
known at $z > 6$. We present deep (245 ks) NuSTAR observations of this source;
with $\sim180$ net counts in the combined observations, CFHQS J142952+544717 is
the most distant object ever observed by the observatory. Fortuitously, this
source was independently observed by Chandra $\sim110$ days earlier, enabling
the identification of two nearby (30'' and 45'' away), fainter X-ray sources.
We jointly fit both Chandra and NuSTAR observations--self-consistently
including interloper sources--and find that, to greater than 90% confidence,
the observed 3-7 keV flux varied by a factor of $\sim2.6$ during that period,
corresponding to approximately two weeks in the quasar rest-frame. This
brightening is one the most extreme instances of statistically significant
X-ray variability seen in the Epoch of Reionization. We discuss possible
scenarios that could produce such rapid change, including X-ray emission from
jets too faint at radio frequencies to be observed.",http://arxiv.org/abs/2501.07637v1
"Using Statistical Precision Medicine to Identify Optimal Treatments in a
  Heart Failure Setting",2025-01-14T02:14:14Z,"Arti Virkud, Jessie K. Edwards, Michele Jonsson Funk, Patricia Chang, Abhijit V. Kshirsagar, Emily W. Gower, Michael R. Kosorok","Identifying optimal medical treatments to improve survival has long been a
critical goal of pharmacoepidemiology. Traditionally, we use an average
treatment effect measure to compare outcomes between treatment plans. However,
new methods leveraging advantages of machine learning combined with the
foundational tenets of causal inference are offering an alternative to the
average treatment effect. Here, we use three unique, precision medicine
algorithms (random forests, residual weighted learning, efficient augmentation
relaxed learning) to identify optimal treatment rules where patients receive
the optimal treatment as indicated by their clinical history. First, we present
a simple hypothetical example and a real-world application among heart failure
patients using Medicare claims data. We next demonstrate how the optimal
treatment rule improves the absolute risk in a hypothetical, three-modifier
setting. Finally, we identify an optimal treatment rule that optimizes the time
to outcome in a real-world heart failure setting. In both examples, we compare
the average time to death under the optimized, tailored treatment rule with the
average time to death under a universal treatment rule to show the benefit of
precision medicine methods. The improvement under the optimal treatment rule in
the real-world setting is greatest (additional ~9 days under the tailored rule)
for survival time free of heart failure readmission.",http://arxiv.org/abs/2501.07789v1
"A Low-cost and Ultra-lightweight Binary Neural Network for Traffic
  Signal Recognition",2025-01-14T03:19:10Z,"Mingke Xiao, Yue Su, Liang Yu, Guanglong Qu, Yutong Jia, Yukuan Chang, Xu Zhang","The deployment of neural networks in vehicle platforms and wearable
Artificial Intelligence-of-Things (AIOT) scenarios has become a research area
that has attracted much attention. With the continuous evolution of deep
learning technology, many image classification models are committed to
improving recognition accuracy, but this is often accompanied by problems such
as large model resource usage, complex structure, and high power consumption,
which makes it challenging to deploy on resource-constrained platforms. Herein,
we propose an ultra-lightweight binary neural network (BNN) model designed for
hardware deployment, and conduct image classification research based on the
German Traffic Sign Recognition Benchmark (GTSRB) dataset. In addition, we also
verify it on the Chinese Traffic Sign (CTS) and Belgian Traffic Sign (BTS)
datasets. The proposed model shows excellent recognition performance with an
accuracy of up to 97.64%, making it one of the best performing BNN models in
the GTSRB dataset. Compared with the full-precision model, the accuracy loss is
controlled within 1%, and the parameter storage overhead of the model is only
10% of that of the full-precision model. More importantly, our network model
only relies on logical operations and low-bit width fixed-point addition and
subtraction operations during the inference phase, which greatly simplifies the
design complexity of the processing element (PE). Our research shows the great
potential of BNN in the hardware deployment of computer vision models,
especially in the field of computer vision tasks related to autonomous driving.",http://arxiv.org/abs/2501.07808v1
"Low-Contact Grasping of Soft Tissue with Complex Geometry using a Vortex
  Gripper",2025-01-14T04:26:49Z,"Roman Mykhailyshyn, Ann Majewicz Fey","Soft tissue manipulation is an integral aspect of most surgical procedures;
however, the vast majority of surgical graspers used today are made of hard
materials, such as metals or hard plastics. Furthermore, these graspers
predominately function by pinching tissue between two hard objects as a method
for tissue manipulation. As such, the potential to apply too much force during
contact, and thus damage tissue, is inherently high. As an alternative
approach, gaspers developed using a pneumatic vortex could potentially levitate
soft tissue, enabling manipulation with low or even no contact force. In this
paper, we present the design and well as a full factorial study of the force
characteristics of the vortex gripper grasping soft surfaces with four common
shapes, with convex and concave curvature, and ranging over 10 different radii
of curvature, for a total of 40 unique surfaces. By changing the parameters of
the nozzle elements in the design of the gripper, it was possible to
investigate the influence of the mass flow parameters of the vortex gripper on
the lifting force for all of these different soft surfaces. An $\pmb{ex}$
$\pmb{vivo}$ experiment was conducted on grasping biological tissues and soft
balls of various shapes to show the advantages and disadvantages of the
proposed technology. The obtained results allowed us to find limitations in the
use of vortex technology and the following stages of its improvement for
medical use.",http://arxiv.org/abs/2501.07832v1
"GeoWarp: Warped spatial processes for inferring subsea sediment
  properties",2025-01-14T04:56:22Z,"Michael Bertolacci, Andrew Zammit-Mangion, Juan Valderrama Giraldo, Michael O'Neill, Fraser Bransby, Phil Watson","For offshore structures like wind turbines, subsea infrastructure, pipelines,
and cables, it is crucial to quantify the properties of the seabed sediments at
a proposed site. However, data collection offshore is costly, so analysis of
the seabed sediments must be made from measurements that are spatially sparse.
Adding to this challenge, the structure of the seabed sediments exhibits both
nonstationarity and anisotropy. To address these issues, we propose GeoWarp, a
hierarchical spatial statistical modeling framework for inferring the 3-D
geotechnical properties of subsea sediments. GeoWarp decomposes the seabed
properties into a region-wide vertical mean profile (modeled using B-splines),
and a nonstationary 3-D spatial Gaussian process. Process nonstationarity and
anisotropy are accommodated by warping space in three dimensions and by
allowing the process variance to change with depth. We apply GeoWarp to
measurements of the seabed made using cone penetrometer tests (CPTs) at six
sites on the North West Shelf of Australia. We show that GeoWarp captures the
complex spatial distribution of the sediment properties, and produces realistic
3-D simulations suitable for downstream engineering analyses. Through
cross-validation, we show that GeoWarp has predictive performance superior to
other state-of-the-art methods, demonstrating its value as a tool in offshore
geotechnical engineering.",http://arxiv.org/abs/2501.07841v1
"Healing of the edge magnetic island in the island divertor configuration
  on J-TEXT",2025-01-14T05:29:35Z,"Zhangrong Hou, Song Zhou, Nengchao Wang, Yonghua Ding, Zhonghe Jiang, Yunfeng Liang, Zhengkang Ren, Feiyue Mao, Qinghu Yang, Jiaming Wang, Xin Xu, Yutong Yang, Jiankun Hua, Zijian Xuan, Chuanxu Zhao, Yangbo Li, Lei Yu, Donghui Xia, Zhipeng Chen, Zhoujun Yang, the J-TEXT team","The phenomena of island healing and configuration transition induced by
high-power electron cyclotron resonance heating (ECRH) have been investigated
in the island divertor configuration on the J-TEXT tokamak. Experimental
results reveal that the size of the edge open magnetic island with mode number
m/n = 3/1 decreases substantially under specific ECRH conditions. This process,
referred to as island healing, occurs when ECRH with a power of 500~600 kW is
deposited in the plasma core or when 250 kW of ECRH is deposited at r = 0.5 a,
where a is the minor radius. The reduction of the island width makes the island
divertor ineffective and transition into the limiter configuration. A model
incorporating the influence of ECRH on the scrape-off layer (SOL)
thermoelectric current is proposed to explain the observed changes in the edge
magnetic topology of the island divertor configuration. These findings suggest
that ECRH should be deposited at the plasma core with carefully controlled
power to ensure the stable and compatible operation of ECRH and the island
divertor configuration in tokamaks. The results can provide insights into
achieving robust operation of an island divertor in tokamaks.",http://arxiv.org/abs/2501.07852v1
The Wigner Little Group for Photons Is a Projective Subalgebra,2025-01-14T07:52:09Z,"Moab Croft, Hamish Todd, Edward Corbett","This paper presents the Geometric Algebra approach to the Wigner little group
for photons using the Spacetime Algebra, incorporating a mirror-based view for
physical interpretation. The shift from a point-based view to a mirror-based
view is a modern movement that allows for a more intuitive representation of
geometric and physical entities, with vectors and their higher-grade
counterparts viewed as hyperplanes. This reinterpretation simplifies the
implementation of homogeneous representations of geometric objects within the
Spacetime Algebra and enables a relative view via projective geometry. Then,
after utilizing the intrinsic properties of Geometric Algebra, the Wigner
little group is seen to induce a projective geometric algebra as a subalgebra
of the Spacetime Algebra. However, the dimension-agnostic nature of Geometric
Algebra enables the generalization of induced subalgebras to (1+n)-dimensional
Minkowski geometric algebras, termed little photon algebras. The lightlike
transformations (translations) in these little photon algebras are seen to
leave invariant the (pseudo)canonical electromagetic field bivector.
Geometrically, this corresponds to Lorentz transformations that do not change
the intersection of the spacelike polarization hyperplane with the lightlike
wavevector hyperplane while simultaneously not affecting the lightlike
wavevector hyperplane. This provides for a framework that unifies the analysis
of symmetries and substructures of point-based Geometric Algebra with
mirror-based Geometric Algebra.",http://arxiv.org/abs/2501.07909v1
"Gravitational Waves dynamics with Higgs portal and U(1) X SU(2)
  interactions",2025-01-14T10:43:14Z,Lucia A. Popa,"We show that a mixture of Higgs boson with a heavy scalar singlet with large
vacuum expectation value ( vev) is a viable model of inflation that satisfy the
existing observational data, the perturbativity constraints, avoiding in the
same time the EW vacuum metastability as long as the Higgs portal interactions
lead to positive tree-level threshold corrections for SM Higgs quartic
coupling. The tree-level threshold corrections lead to the change of Hubble
expansion rate during inflation with impact on the evolution of the axion-gauge
field spectator sector, modifying the time-dependent mass parameter of the
gauge field fluctuation. We evaluate this effect on the GW sourced tensor modes
while accounting for the consistency and backreaction constraints and show that
the Higgs portal interactions enhance the GW signal sourced by the gauge field
fluctuations in the CMB B-mode ploarization power spectra. We address the
detectability of the GW sourced by the gauge field fluctuations in presence of
Higgs portal interactions for the experimental configuration of the future CMB
polarization LiteBird space mission. We find that the sourced GW
tensor-to-scalar ratio in presence of Higgs portal interactions is enhanced to
a level that overcomes the vacuum tensor-to-scalar ratio by a factor of 10,
much above the detection threshold of the LiteBird experiment, in agreement
with the existing observational constraints on the curvature fluctuations and
the allowed parameter space of Higgs portal interactions. We also show that a
large enhancement of the sourced GW can be also detected by experiments such as
pulsar timing arrays and laser/atomic interferometers. Moreover, a significant
Higgs-singlet mixing can be probed by the LHC Higgs searchers.",http://arxiv.org/abs/2501.08000v1
"Improvements to SHINS, the SHARK-NIR Instrument Software, during the AIT
  phase",2025-01-14T10:55:12Z,"Davide Ricci, Fulvio Laudisio, Marco De Pascale, Sona Shivaji Rao Chavan, Andrea Baruffolo","In the context of SHARK-NIR (System for coronagraphy with High Order adaptive
optics in Z and H band), we present the development of SHINS, the SHARK-NIR
INstrument control Software, in particular focusing on the changes introduced
during the Assembly, Integration, and Test (AIT) phase. SHARK-NIR observing
sessions will be carried out with ""ESO-style"" Observation Blocks (OBs) based on
so-called Templates scripts that will be prepared by observers. We decided to
develop Templates also for the large number of AIT tests (flexures,
coronagraphic mask alignment, scientific camera performances...). Here we
present the adopted HTTP API for the OBs generation and a web-based frontend
that implements it. Taking advantage of this approach, we decided to expose
APIs also for individual device movement and monitoring, as well as for general
status. These APIs are then used in the web-based instrument control and
synoptic panels. During the recent AIT phase, a potential collision issue
between two motorized components emerged. While we are exploring the
possibility of a hardware interlock, we present a software solution developed
at the Observation Software level, that is also available while using other
software such as engineering panels. The system is based on three protection
layers and it has been successfully tested.",http://arxiv.org/abs/2501.08010v1
"An AI-driven framework for rapid and localized optimizations of urban
  open spaces",2025-01-14T11:19:52Z,"Pegah Eshraghi, Arman Nikkhah Dehnavi, Maedeh Mirdamadi, Riccardo Talami, Zahra-Sadat Zomorodian","As urbanization accelerates, open spaces are increasingly recognized for
their role in enhancing sustainability and well-being, yet they remain
underexplored compared to built spaces. This study introduces an AI-driven
framework that integrates machine learning models (MLMs) and explainable AI
techniques to optimize Sky View Factor (SVF) and visibility, key spatial
metrics influencing thermal comfort and perceived safety in urban spaces.
Unlike global optimization methods, which are computationally intensive and
impractical for localized adjustments, this framework supports incremental
design improvements with lower computational costs and greater flexibility. The
framework employs SHapley Adaptive Explanations (SHAP) to analyze feature
importance and Counterfactual Explanations (CFXs) to propose minimal design
changes. Simulations tested five MLMs, identifying XGBoost as the most
accurate, with building width, park area, and heights of surrounding buildings
as critical for SVF, and distances from southern buildings as key for
visibility. Compared to Genetic Algorithms, which required approximately 15/30
minutes across 3/4 generations to converge, the tested CFX approach achieved
optimized results in 1 minute with a 5% RMSE error, demonstrating significantly
faster performance and suitability for scalable retrofitting strategies. This
interpretable and computationally efficient framework advances urban
performance optimization, providing data-driven insights and practical
retrofitting solutions for enhancing usability and environmental quality across
diverse urban contexts.",http://arxiv.org/abs/2501.08019v1
"Continual Reinforcement Learning for Digital Twin Synchronization
  Optimization",2025-01-14T11:53:07Z,"Haonan Tong, Mingzhe Chen, Jun Zhao, Ye Hu, Zhaohui Yang, Yuchen Liu, Changchuan Yin","This article investigates the adaptive resource allocation scheme for digital
twin (DT) synchronization optimization over dynamic wireless networks. In our
considered model, a base station (BS) continuously collects factory physical
object state data from wireless devices to build a real-time virtual DT system
for factory event analysis. Due to continuous data transmission, maintaining DT
synchronization must use extensive wireless resources. To address this issue, a
subset of devices is selected to transmit their sensing data, and resource
block (RB) allocation is optimized. This problem is formulated as a constrained
Markov process (CMDP) problem that minimizes the long-term mismatch between the
physical and virtual systems. To solve this CMDP, we first transform the
problem into a dual problem that refines RB constraint impacts on device
scheduling strategies. We then propose a continual reinforcement learning (CRL)
algorithm to solve the dual problem. The CRL algorithm learns a stable policy
across historical experiences for quick adaptation to dynamics in physical
states and network capacity. Simulation results show that the CRL can adapt
quickly to network capacity changes and reduce normalized root mean square
error (NRMSE) between physical and virtual states by up to 55.2%, using the
same RB number as traditional methods.",http://arxiv.org/abs/2501.08045v1
"Hydrodynamics-driven phase-locking and collective motility of sessile
  active dumbbells",2025-01-14T12:27:18Z,"Urvi Mahendra Bora, Mohd Suhail Rizvi","Collective motion is a phenomenon observed across length scales in nature,
from bacterial swarming and tissue migration to the flocking of animals. The
mechanisms underlying this behavior vary significantly depending on the
biological system, ranging from hydrodynamic and chemical interactions in
bacteria to mechanical forces in epithelial tissues and social alignment in
animal groups. While collective motion often arises from the coordinated
activity of independently motile agents, this work explores a novel context:
the emergence of collective motion in systems of non-motile active agents.
Inspired by the oscillatory shape dynamics observed in suspended cells such as
neutrophils and fibroblasts, we model active dumbbells exhibiting limit-cycle
oscillations in shape as a minimal representation of such systems.Through
computational simulations, we demonstrate that hydrodynamic interactions
between these dumbbells lead to three key phenomena: a density-dependent
transition from sessile to collective motion, hydrodynamics-induced phase
separation, and synchronization of oscillatory shape changes. We have explored
the role of hydrodynamic interactions on these emergent properties of sessile
active dumbbells. These results underscore the critical role of hydrodynamic
coupling in enabling and organizing collective behaviors in systems lacking
intrinsic motility. This study lays the groundwork for future investigations
into the emergent behavior of active matter and its implications for
understanding cell motility, tissue dynamics, and the development of
bio-inspired materials.",http://arxiv.org/abs/2501.08065v1
"Probing Spectral Evolution and Intrinsic Variability of Mkn\,421: A
  Multi-Epoch AstroSat Study of X-ray Spectra",2025-01-14T12:41:55Z,"Sikandar Akbar, Zahir Shah, Ranjeev Misra, Naseer Iqbal, Javaid Tantry","Our study presents a time-resolved X-ray spectral analysis of Mkn 421, using
AstroSat observations taken during different epochs between 2016 and 2019. The
variability of the source in X-rays is utilized to investigate the evolution of
its spectral properties. Each observation period was divided into segments of
about 10 ks, and we employed three forms of particle distributions:
broken-power law (BPL), log-parabola (LP), and power-law with maximum electron
energy (xi-max model) undergoing synchrotron losses to fit the broad X-ray
spectrum in each segment. We observed that all of these models provided good
fits to the spectra. In the case of the broken-power law model, we investigated
the relationship between normalized particle density at an energy less than the
break energy and the index before the break. The results revealed an inverse
correlation between the index and particle density with no time delay.
Additionally, correlations between spectral parameters were used to determine
the pivot energy. We observed that the pivot energy remained the same across
the observations. For xi-max and LP models, we define analogous pivot energies
and show that they also do not vary, indicating the model-independent nature of
the result. The constant pivot energy suggests that the source's variability
arises from index variations and not due to changes in the normalization.
Consequently, parameters such as magnetic field strength, Doppler factor, etc.,
do not contribute to the source's variability. Instead, variations are
primarily associated with the acceleration or escape timescales of emitted
particles within the source.",http://arxiv.org/abs/2501.08073v1
"Dynamical evolution of the open clusters with different star formation
  efficiencies and orbital parameters",2025-01-14T12:52:38Z,"M. Ishchenko, V. Masliukh, M. Hradov, P. Berczik, B. Shukirgaliyev, C. Omarov","Open star clusters are dynamic systems whose evolution is critically
influenced by initial conditions such as star formation efficiency and orbital
parameters. Understanding their dissolution mechanisms provides insight into
stellar population dynamical mixing in the Milky Way. We aim to investigate the
dynamical evolution and dissolution of initially non-virialised open clusters
by examining how different global star formation efficiencies and orbital
characteristics impact the cluster longevity and structural changes. We
followed the evolution of the clusters up to their dissolution time on the
basis of our calculations. We compare our open cluster dynamical evolutionary
models with the observed open clusters in our Galaxy's solar vicinity. Using
high-order direct N-body simulations, we modelled cluster evolution across
different Galactic orbits, systematically varying initial star formation
efficiencies to comprehensively explore dissolution mechanisms. Our simulations
reveal that open clusters typically survive approximately ten orbital periods,
with cluster lifetime being strongly dependent on global star formation
efficiency and only marginally influenced by orbital eccentricity. We estimate
gas expulsion timescales of 0.9 Myr, with initial supernova explosions
efficiently removing gaseous components from the cluster. The expected lifetime
of the cluster (in units of orbital periods) strongly depends on the cluster
global star-formation efficiency and only slightly on the orbital
eccentricities of the cluster. The theoretical models demonstrate a remarkable
agreement of the Roche-volobe filling parameter with the recent observed Gaia
DR3 cluster catalogues in the solar vicinity. By incorporating a mixed sample
of clusters with varying star formation efficiencies, we provide a more nuanced
understanding of open cluster evolution in the Galactic disc.",http://arxiv.org/abs/2501.08084v1
Mobility Management in Integrated Sensing and Communications Networks,2025-01-14T14:37:31Z,"Yuri S. Ribeiro, Behrooz Makki, Andre L. F. de Almeida, Gabor Fodor","The performance of the integrated sensing and communication (ISAC) networks
is considerably affected by the mobility of the transceiver nodes, user
equipment devices (UEs) and the passive objects that are sensed. For instance,
the sensing efficiency is considerably affected by the presence or absence of a
line-of-sight connection between the sensing transceivers and the object; a
condition that may change quickly due to mobility. Moreover, the mobility of
the UEs and objects may result in dynamically varying communication-to-sensing
and sensing-to communication interference, deteriorating the network
performance. In such cases, there may be a need to handover the sensing process
to neighbor nodes. In this article, we develop the concept of mobility
management in ISAC networks. Here, depending on the mobility of objects and/or
the transceiver nodes, the data traffic, the sensing or communication coverage
area of the transceivers, and the network interference, the transmission and/or
the reception of the sensing signals may be handed over to neighbor nodes.
Also, the ISAC configuration and modality - that is, using monostatic or
bistatic sensing - are updated accordingly, such that the sensed objects can be
continuously sensed with low overhead. We show that mobility management reduces
the sensing interruption and boosts the communication and sensing efficiency of
ISAC networks.",http://arxiv.org/abs/2501.08159v1
"FramePainter: Endowing Interactive Image Editing with Video Diffusion
  Priors",2025-01-14T16:09:16Z,"Yabo Zhang, Xinpeng Zhou, Yihan Zeng, Hang Xu, Hui Li, Wangmeng Zuo","Interactive image editing allows users to modify images through visual
interaction operations such as drawing, clicking, and dragging. Existing
methods construct such supervision signals from videos, as they capture how
objects change with various physical interactions. However, these models are
usually built upon text-to-image diffusion models, so necessitate (i) massive
training samples and (ii) an additional reference encoder to learn real-world
dynamics and visual consistency. In this paper, we reformulate this task as an
image-to-video generation problem, so that inherit powerful video diffusion
priors to reduce training costs and ensure temporal consistency. Specifically,
we introduce FramePainter as an efficient instantiation of this formulation.
Initialized with Stable Video Diffusion, it only uses a lightweight sparse
control encoder to inject editing signals. Considering the limitations of
temporal attention in handling large motion between two frames, we further
propose matching attention to enlarge the receptive field while encouraging
dense correspondence between edited and source image tokens. We highlight the
effectiveness and efficiency of FramePainter across various of editing signals:
it domainantly outperforms previous state-of-the-art methods with far less
training data, achieving highly seamless and coherent editing of images, \eg,
automatically adjust the reflection of the cup. Moreover, FramePainter also
exhibits exceptional generalization in scenarios not present in real-world
videos, \eg, transform the clownfish into shark-like shape. Our code will be
available at https://github.com/YBYBZhang/FramePainter.",http://arxiv.org/abs/2501.08225v1
"Text-Diffusion Red-Teaming of Large Language Models: Unveiling Harmful
  Behaviors with Proximity Constraints",2025-01-14T16:32:01Z,"Jonathan Nöther, Adish Singla, Goran Radanović","Recent work has proposed automated red-teaming methods for testing the
vulnerabilities of a given target large language model (LLM). These methods use
red-teaming LLMs to uncover inputs that induce harmful behavior in a target
LLM. In this paper, we study red-teaming strategies that enable a targeted
security assessment. We propose an optimization framework for red-teaming with
proximity constraints, where the discovered prompts must be similar to
reference prompts from a given dataset. This dataset serves as a template for
the discovered prompts, anchoring the search for test-cases to specific topics,
writing styles, or types of harmful behavior. We show that established
auto-regressive model architectures do not perform well in this setting. We
therefore introduce a black-box red-teaming method inspired by text-diffusion
models: Diffusion for Auditing and Red-Teaming (DART). DART modifies the
reference prompt by perturbing it in the embedding space, directly controlling
the amount of change introduced. We systematically evaluate our method by
comparing its effectiveness with established methods based on model fine-tuning
and zero- and few-shot prompting. Our results show that DART is significantly
more effective at discovering harmful inputs in close proximity to the
reference prompt.",http://arxiv.org/abs/2501.08246v1
Toward Zero-Shot User Intent Recognition in Shared Autonomy,2025-01-14T19:06:44Z,"Atharv Belsare, Zohre Karimi, Connor Mattson, Daniel S. Brown","A fundamental challenge of shared autonomy is to use high-DoF robots to
assist, rather than hinder, humans by first inferring user intent and then
empowering the user to achieve their intent. Although successful, prior methods
either rely heavily on a priori knowledge of all possible human intents or
require many demonstrations and interactions with the human to learn these
intents before being able to assist the user. We propose and study a zero-shot,
vision-only shared autonomy (VOSA) framework designed to allow robots to use
end-effector vision to estimate zero-shot human intents in conjunction with
blended control to help humans accomplish manipulation tasks with unknown and
dynamically changing object locations. To demonstrate the effectiveness of our
VOSA framework, we instantiate a simple version of VOSA on a Kinova Gen3
manipulator and evaluate our system by conducting a user study on three
tabletop manipulation tasks. The performance of VOSA matches that of an oracle
baseline model that receives privileged knowledge of possible human intents
while also requiring significantly less effort than unassisted teleoperation.
In more realistic settings, where the set of possible human intents is fully or
partially unknown, we demonstrate that VOSA requires less human effort and time
than baseline approaches while being preferred by a majority of the
participants. Our results demonstrate the efficacy and efficiency of using
off-the-shelf vision algorithms to enable flexible and beneficial shared
control of a robot manipulator. Code and videos available here:
https://sites.google.com/view/zeroshot-sharedautonomy/home.",http://arxiv.org/abs/2501.08389v1
"Heterogeneous Update Processes Shape Information Cascades in Social
  Networks",2025-01-15T00:19:04Z,"Flávio L. Pinheiro, Vítor V. Vasconcelos","A common assumption in the literature on information diffusion is that
populations are homogeneous regarding individuals' information acquisition and
propagation process: Individuals update their informed and actively
communicating state either through imitation (simple contagion) or peer
influence (complex contagion). Here, we study the impact of the mixing and
placement of individuals with different update processes on how information
cascades in social networks. We consider Simple Spreaders, which take
information from a random neighbor and communicate it, and Threshold-based
Spreaders, which require a threshold number of active neighbors to change their
state to active communication. Even though, in a population made exclusively of
Simple Spreaders, information reaches all elements of any (connected) network,
we show that, when Simple and Threshold-based Spreaders coexist and occupy
random positions in a social network, the number of Simple Spreaders
systematically amplifies the cascades only in degree heterogeneous networks
(exponential and scale-free). In random and modular structures, this cascading
effect originated by Simple Spreaders only exists above a critical mass of
these individuals. In contrast, when Threshold-based Spreaders are assorted
preferentially in the nodes with a higher degree, the cascading effect of
Simple Spreaders vanishes, and the spread of information is drastically
impaired. Overall, the study highlights the significance of the strategic
placement of different roles in networked structures, with Simple Spreaders
driving widespread cascades in heterogeneous networks and Threshold-based
Spreaders playing a critical regulatory role in information spread with a
tunable effect based on the threshold value.",http://arxiv.org/abs/2501.08498v1
"Unconventional bias-dependent tunneling magnetoresistance in van der
  Waals ferromagnetic/semiconductor heterojunctions",2025-01-15T13:11:39Z,"Wenkai Zhu, Hui Wen, Shouguo Zhu, Qirui Cui, Shihong Xie, Meng Ye, Gaojie Zhang, Hao Wu, Xiaomin Zhang, Weihao Li, Yuqing Huang, Jing Zhang, Lixia Zhao, Amalia Patanè, Haixin Chang, Lin-Wang Wang, Kaiyou Wang","Two-dimensional van der Waals (vdW) ferromagnetic/semiconductor
heterojunctions represent an ideal platform for studying and exploiting
tunneling magnetoresistance (TMR) effects due to the versatile band structure
of semiconductors and their high-quality interfaces. In the all-vdW magnetic
tunnel junction (MTJ) devices, both the magnitude and sign of the TMR can be
tuned by an applied voltage. Typically, as the bias voltage increases, first
the amplitude of the TMR decreases, then the sign of the TMR reverses and/or
oscillates. Here, we report on an unconventional bias-dependent TMR in the
all-vdW Fe3GaTe2/GaSe/Fe3GaTe2 MTJs, where the TMR first increases, then
decreases, and finally undergoes a sign reversal as the bias voltage increases.
This dependence cannot be explained by traditional models of MTJs. We propose
an in-plane electron momentum (k//) resolved tunneling model that considers
both the coherent degree of k// and the decay of the electron wave function
through the semiconductor spacer layer. This can explain well the conventional
and unconventional bias-dependent TMR. Our results thus provide a deeper
understanding of the bias-dependent spin-transport in semiconductor-based MTJs
and offer new insights into semiconductor spintronics.",http://arxiv.org/abs/2501.08784v1
MMDocIR: Benchmarking Multi-Modal Retrieval for Long Documents,2025-01-15T14:30:13Z,"Kuicai Dong, Yujing Chang, Xin Deik Goh, Dexun Li, Ruiming Tang, Yong Liu","Multi-modal document retrieval is designed to identify and retrieve various
forms of multi-modal content, such as figures, tables, charts, and layout
information from extensive documents. Despite its significance, there is a
notable lack of a robust benchmark to effectively evaluate the performance of
systems in multi-modal document retrieval. To address this gap, this work
introduces a new benchmark, named as MMDocIR, encompassing two distinct tasks:
page-level and layout-level retrieval. The former focuses on localizing the
most relevant pages within a long document, while the latter targets the
detection of specific layouts, offering a more fine-grained granularity than
whole-page analysis. A layout can refer to a variety of elements such as
textual paragraphs, equations, figures, tables, or charts. The MMDocIR
benchmark comprises a rich dataset featuring expertly annotated labels for
1,685 questions and bootstrapped labels for 173,843 questions, making it a
pivotal resource for advancing multi-modal document retrieval for both training
and evaluation. Through rigorous experiments, we reveal that (i) visual
retrievers significantly outperform their text counterparts, (ii) MMDocIR train
set can effectively benefit the training process of multi-modal document
retrieval and (iii) text retrievers leveraging on VLM-text perform much better
than those using OCR-text. These findings underscores the potential advantages
of integrating visual elements for multi-modal document retrieval.",http://arxiv.org/abs/2501.08828v1
Dispersive vacuum as a decoherence amplifier of an Unruh-DeWitt detector,2025-01-15T14:32:32Z,"Pedro H. M. Barros, Helder A. S. Costa","Recently, interest has been growing in studies on discrete or ""pixelated""
space-time that, through modifications in the dispersion relation, can treat
the vacuum as a dispersive medium. Discrete spacetime considers that spacetime
has a cellular structure on the order of the Planck length, and if this is true
we should certainly have observable effects. In this paper, we investigated the
effects caused by the dispersive vacuum on the decoherence process of an
Unruh-DeWitt detector, our setup consists of a uniformly accelerated detector,
initially in a qubit state, which interacts with a massless scalar field during
a time interval finite. We use dispersion relations drawn from doubly special
relativity and Ho\v{r}ava-Lifshitz gravity, with these modifications the vacuum
becomes dispersive and has a corresponding refractive index. We calculate the
probability transition rates, the probability of finding the detector in the
ground state, and the quantum coherence variation. Our results indicate that
the decoherence process occurs more quickly in cases with changes in the
dispersion relation in the regime of high accelerations and interaction time.
Additionally, the decoherence increases as the vacuum becomes more dispersive
due to the increase in the order of modification in the dispersion relation,
and this happens because the dispersive vacuum amplifies the effects of quantum
fluctuations that are captured by the detector when interacting with the field.",http://arxiv.org/abs/2501.08829v1
Graph Counterfactual Explainable AI via Latent Space Traversal,2025-01-15T15:04:10Z,"Andreas Abildtrup Hansen, Paraskevas Pegios, Anna Calissano, Aasa Feragen","Explaining the predictions of a deep neural network is a nontrivial task, yet
high-quality explanations for predictions are often a prerequisite for
practitioners to trust these models. Counterfactual explanations aim to explain
predictions by finding the ''nearest'' in-distribution alternative input whose
prediction changes in a pre-specified way. However, it remains an open question
how to define this nearest alternative input, whose solution depends on both
the domain (e.g. images, graphs, tabular data, etc.) and the specific
application considered. For graphs, this problem is complicated i) by their
discrete nature, as opposed to the continuous nature of state-of-the-art graph
classifiers; and ii) by the node permutation group acting on the graphs. We
propose a method to generate counterfactual explanations for any differentiable
black-box graph classifier, utilizing a case-specific permutation equivariant
graph variational autoencoder. We generate counterfactual explanations in a
continuous fashion by traversing the latent space of the autoencoder across the
classification boundary of the classifier, allowing for seamless integration of
discrete graph structure and continuous graph attributes. We empirically
validate the approach on three graph datasets, showing that our model is
consistently high-performing and more robust than the baselines.",http://arxiv.org/abs/2501.08850v1
"Silent Abandonment in Text-Based Contact Centers: Identifying,
  Quantifying, and Mitigating its Operational Impacts",2025-01-15T15:38:56Z,"Antonio Castellanos, Galit B. Yom-Tov, Yair Goldberg, Jaeyoung Park","In the quest to improve services, companies offer customers the option to
interact with agents via texting. Such contact centers face unique challenges
compared to traditional call centers, as measuring customer experience proxies
like abandonment and patience involves uncertainty. A key source of this
uncertainty is silent abandonment, where customers leave without notifying the
system, wasting agent time and leaving their status unclear. Silent abandonment
also obscures whether a customer was served or left. Our goals are to measure
the magnitude of silent abandonment and mitigate its effects. Classification
models show that 3%-70% of customers across 17 companies abandon silently. In
one study, 71.3% of abandoning customers did so silently, reducing agent
efficiency by 3.2% and system capacity by 15.3%, incurring $5,457 in annual
costs per agent. We develop an expectation-maximization (EM) algorithm to
estimate customer patience under uncertainty and identify influencing
covariates. We find that companies should use classification models to estimate
abandonment scope and our EM algorithm to assess patience. We suggest
strategies to operationally mitigate the impact of silent abandonment by
predicting suspected silent-abandonment behavior or changing service design.
Specifically, we show that while allowing customers to write while waiting in
the queue creates a missing data challenge, it also significantly increases
patience and reduces service time, leading to reduced abandonment and lower
staffing requirements.",http://arxiv.org/abs/2501.08869v2
"Compositional dependence of magnetic damping in sputter-deposited
  CoxFe1-x thin films",2025-01-15T16:51:08Z,"Samanvaya S. Gaur, Rosa Diaz, Ernesto E. Marinero","Co25Fe75 ferromagnetic films exhibit ultralow magnetic damping. The magnetic
damping dependence of Cobalt Iron thin films over a Co composition (23 to 36%)
is here reported. The thin film structures were sputter deposited at ambient
temperature and FMR measurements in both in plane and out of plane geometries
were utilized to measure magnetic damping parameters, which include intrinsic
damping and contributions from spin pumping. The damping parameters, decrease
as the Co content is increased, except for Co31Fe69. The smallest values of
damping correspond to alloys exhibiting interface perpendicular magnetic
anisotropy. A value of 0.00091 was measured for Co36Fe64, whereas for Co31Fe69
was measured as 0.002, this composition exhibits the largest in-plane
anisotropy. HAADF-STEM cross-section analysis of the Co36Fe64 thin film stack
revealed Cu interdiffusion into the magnetic layer. The degree of
interdiffusion was found to be up to 7x higher at grain boundaries as compared
the bulk of the polycrystalline grains. The incorporation of Cu into the
ferromagnetic layer adversely impacts magnetic damping. Reducing impurities in
the magnetic layer by improving the growth chamber base pressure resulted in a
reduction of magnetic damping of 18%. The diffraction analysis revealed that
the primary growth direction of Co36Fe64 is [101] and that of Cu buffer layer
is [111], these planes are perpendicular to their respective [101] planes and
for this composition the lattice mismatch was determined to be 0.9325%. The
lattice mismatch decreases with increasing Co content and hence the lattice
strain. The diffusion of Cu into the ferromagnet creates magnon scattering
centers and local changes in magnetic properties. Both factors negatively
influence magnetic damping.",http://arxiv.org/abs/2501.08948v1
"Discretionary vs nondiscretionary in fiscal mechanism. Non-automatic
  fiscal stabilisers vs automatic fiscal stabilisers",2025-01-15T17:53:29Z,"Vasile Bratian, Amelia Bucur, Camelia Oprean, Cristina Tanasescu","The goal of the present study is to increase the intelligibility of
macroeconomic phenomena triggered by governmental intervention in economy by
means of fiscal policies. During cyclical movements, fiscal policy can play an
important role in order to help stabilise the economy. But discretionary policy
usually implies implementation lags and is not automatically reversed when
economic conditions change. In contrast, automatic fiscal stabilisers (SFA)
ensure a prompter, and self-correcting fiscal response. The present study aims
to tackle the topic of discretionary vs nondiscretionary characteristic of
fiscal stabilisers (SF). In this context, the scope of the research undertaking
is to launch a scientific debate over the definitions of the concepts of
non-automatic fiscal stabilisers (SfnA) and SFAs. We describe how we can
quantify the discretionary and non-discretionary character of the fiscal
policy, by the analysis of the structure of the conventional budget balance
(SBc), budget balance associated with the current GDP. In the final part of
this article, we propose a quantitative equilibrium model for establishing the
mathematical prerequisites for an SF to become automatic. Likewise, on the
basis of the proposed mathematical model we have performed a qualitative
analysis of the influence factors.",http://arxiv.org/abs/2501.08981v1
"Landauer resistivity dipole at one dimensional defect revealed via
  near-field photocurrent nanoscopy",2025-01-15T20:02:33Z,"Francesca Falorsi, Marco Dembecki, Christian Eckel, Monica Kolek Martinez de Azagra, Kenji Watanabe, Takashi Taniguchi, Martin Statz, R. Thomas Weitz","The fundamental question how to describe Ohmic resistance at the nanoscale
has been answered by Landauer in his seminal picture of the so-called Landauer
resistivity dipole. This picture has been theoretically well understood,
however experimentally there are only few studies due to the need for a
non-invasive local probe. Here we use the nanometer lateral resolution of
near-field photocurrent imaging to thoroughly characterize a buried monolayer -
bilayer graphene interface as an ideal one dimensional defect for the Landauer
resistivity dipole. Via systematic tuning of the overall charge carrier density
and the current flow we are able to detect the formation of Landauer
resistivity dipoles due to charge carrier accumulation around the one
dimensional defects. We found that, for Fermi energy values near the charge
neutrality point (i.e. at low hole or electron doping), the photocurrent
exhibits the same polarity as the applied source-drain voltage, which is
consistent with changes in carrier concentration induced by the Landauer
resistivity dipoles. This signature is no longer evident at higher charge
carrier density in agreement with the performed numerical calculations.
Photocurrent nanoscopy can thus serve as non-invasive technique to study local
dissipation at hidden interfaces.",http://arxiv.org/abs/2501.09124v1
"A Dynamic Unmanned Aerial Vehicle Routing Framework for Urban Traffic
  Monitoring",2025-01-16T02:20:25Z,"Yumeng Bai, Yiheng Feng","Unmanned Aerial Vehicles (UAVs) have great potential in urban traffic
monitoring due to their rapid speed, cost-effectiveness, and extensive
field-of-view, while being unconstrained by traffic congestion. However, their
limited flight duration presents critical challenges in sustainable recharging
strategies and efficient route planning in long-term monitoring tasks.
Additionally, existing approaches for long-term monitoring often neglect the
evolving nature of urban traffic networks. In this study, we introduce a novel
dynamic UAV routing framework for long-term, network-wide urban traffic
monitoring, leveraging existing ground vehicles as mobile charging stations
without disrupting their operations. To address the complexity of long-term
monitoring scenarios involving multiple flights, we decompose the problem into
manageable single-flight tasks, in which each flight is modeled as a Team Arc
Orienteering Problem with Decreasing Profits with the objective to collectively
maximize the spatiotemporal network coverage. Between flights, we adaptively
update the edge weights to incorporate real-time traffic changes and revisit
intervals. We validate our framework through extensive microscopic simulations
in a modified Sioux Falls network under various scenarios. Comparative results
demonstrate that our model outperforms three baseline approaches, especially
when historical information is incomplete or absent. Moreover, we show that our
monitoring framework can capture network-wide traffic trends and construct
accurate Macroscopic Fundamental Diagrams (MFDs). These findings demonstrate
the effectiveness of the proposed dynamic UAV routing framework, underscoring
its suitability for efficient and reliable long-term traffic monitoring. Our
approach's adaptability and high accuracy in capturing the MFD highlight its
potential in network-wide traffic control and management applications.",http://arxiv.org/abs/2501.09249v1
"Interoceptive Robots for Convergent Shared Control in Collaborative
  Construction Work",2025-01-16T04:50:15Z,"Xiaoshan Zhou, Carol C. Menassa, Vineet R. Kamat","Building autonomous mobile robots (AMRs) with optimized efficiency and
adaptive capabilities-able to respond to changing task demands and dynamic
environments-is a strongly desired goal for advancing construction robotics.
Such robots can play a critical role in enabling automation, reducing
operational carbon footprints, and supporting modular construction processes.
Inspired by the adaptive autonomy of living organisms, we introduce
interoception, which centers on the robot's internal state representation, as a
foundation for developing self-reflection and conscious learning to enable
continual learning and adaptability in robotic agents. In this paper, we
factorize internal state variables and mathematical properties as ""cognitive
dissonance"" in shared control paradigms, where human interventions occasionally
occur. We offer a new perspective on how interoception can help build adaptive
motion planning in AMRs by integrating the legacy of heuristic costs from
grid/graph-based algorithms with recent advances in neuroscience and
reinforcement learning. Declarative and procedural knowledge extracted from
human semantic inputs is encoded into a hypergraph model that overlaps with the
spatial configuration of onsite layout for path planning. In addition, we
design a velocity-replay module using an encoder-decoder architecture with
few-shot learning to enable robots to replicate velocity profiles in
contextualized scenarios for multi-robot synchronization and handover
collaboration. These ""cached"" knowledge representations are demonstrated in
simulated environments for multi-robot motion planning and stacking tasks. The
insights from this study pave the way toward artificial general intelligence in
AMRs, fostering their progression from complexity to competence in construction
automation.",http://arxiv.org/abs/2501.09290v1
"High-speed readout for direct light orbital angular momentum
  photodetector via photoelastic modulation",2025-01-16T05:06:58Z,"Dehong Yang, Chang Xu, Jiawei Lai, Zipu Fan, Delang Liang, Shiyu Wang, Jinluo Cheng, Dong Sun","Recent progress in direct photodetection of light orbital angular momentum
(OAM) based on the orbital photogalvanic effect (OPGE) provides an effective
way for on-chip direct electric readout of orbital angular momentum, as well as
large-scale integration focal-plane array devices. However, the recognition of
OAM order from photocurrent response requires the extraction of circular
polarization-dependent response. To date, the operation speed of such detector
is currently at the minute level and is limited by slow mechanical polarization
modulation and low OAM recognition capability. In this work, we demonstrate
that the operation speed can be greatly improved via electrical polarization
modulation strategy with photoelasitc modulator accompanied by phase-locked
readout approach with lock-in amplifier. We demonstrate an operation speed of
up to 1 kHz with this new technology in the mid-infrared region (4 {\mu}m) on
an OAM detector using multilayer graphene (MLG) as photosensitive material. In
principle, with new modulation and readout scheme, we can potentially increase
the operation speed to 50.14 kHz with a PEM that operates at a state-of-the-art
speed. Our work paves the way toward high-speed operation of direct OAM
detection devices based on OPGE effect and pushes such technology to a more
practical stage for focal plane array applications.",http://arxiv.org/abs/2501.09297v1
"Community attitudes towards the environmental cost of computational
  fluid dynamics research",2025-01-16T06:13:46Z,"Miranda van Heel, Jack R. C. King","Numerical simulations underpin much fluid dynamics research today. Such
simulations often rely on large scale high performance computing (HPC) systems,
and have a significant carbon footprint. Increasing the efficiency of data
centers or the proportion of electricity coming from renewable sources can
lessen the environmental impact of scientific computing to a degree, but the
attitudes of researchers also play a role. There are many choices researchers
make which influence the carbon footprint of simulations. To change behaviours
around simulation use, it is first necessary to understand attitudes toward
them. Here, we present a case study on fluid dynamics researchers based in the
University of Manchester, UK. We find a low awareness of the carbon footprint
of computations, compounded by a lack of knowledge of the specific hardware
used to run simulations. There is a discrepancy between researchers
self-declared attitudes towards reducing the carbon footprint of their work,
and their actions and choices. Overall, researchers did not consider carbon
footprint as important in their decision making, and we found no correlation
between the impact and carbon cost of simulations. Improved education and
awareness of the environmental impact of simulations is imperative in the
interests of the sustainability of this field.",http://arxiv.org/abs/2501.09314v2
"A Novel Simulation Approach for Evaporation Processes in Small Gaps of
  Industrial Applications",2025-01-16T07:32:42Z,"Phil Namesnik, Alexander Eifert, Anja Lippert, Tobias Tolle, Louis Mett, Uwe Janoske","Long liquid retention times in industrial gaps, due to capillary effects,
significantly affect product lifetime by facilitating corrosion on solid
surfaces. Concentration-driven evaporation plays a major role in mitigating
this corrosion. Accurate evaporation rate predictions are crucial for improved
product design. However, simulating capillary-driven flows with evaporation in
complex geometries is challenging, requiring consideration of surface tension,
wetting, and phase-change effects. Traditional approaches, such as the
Volume-of-Fluid method, are prone to curvature calculation errors and have long
simulation times due to strict time step limitations. This study introduces a
novel semi-transient simulation approach for fast evaporation rate prediction
in arbitrarily shaped cavities. The approach involves a unidirectional coupling
circuit, simulating the fluid surface in Surface Evolver and combining it with
a vapor-in-gas diffusion simulation in OpenFOAM. The approach assumes that the
evaporation rate is calculated solely based on the conditions at a given liquid
filling level, without considering the evaporation history. This allows for
highly parallelized simulations, achieving simulation runtimes in the order of
10 minutes to cover up to 150 hours of physical time. Numerical investigations
are conducted for water evaporation in air at a temperature of 23{\deg}C and a
relative humidity of 17%, for round and polygonal-shaped capillaries with inner
diameters ranging from 1 mm to 13 mm. The results are validated using
experimental data and show strong agreement. Simulations are also performed for
complex industrial relevant gaps, demonstrating the applicability of the
approach to a wide range of crevice geometries.",http://arxiv.org/abs/2501.09337v1
"SE-BSFV: Online Subspace Learning based Shadow Enhancement and
  Background Suppression for ViSAR under Complex Background",2025-01-16T07:50:56Z,"Shangqu Yan, Chenyang Luo, Yaowen Fu, Wenpeng Zhang, Wei Yang, Ruofeng Yu","Video synthetic aperture radar (ViSAR) has attracted substantial attention in
the moving target detection (MTD) field due to its ability to continuously
monitor changes in the target area. In ViSAR, the moving targets' shadows will
not offset and defocus, which is widely used as a feature for MTD. However, the
shadows are difficult to distinguish from the low scattering region in the
background, which will cause more missing and false alarms. Therefore, it is
worth investigating how to enhance the distinction between the shadows and
background. In this study, we proposed the Shadow Enhancement and Background
Suppression for ViSAR (SE-BSFV) algorithm. The SE-BSFV algorithm is based on
the low-rank representation (LRR) theory and adopts online subspace learning
technique to enhance shadows and suppress background for ViSAR images. Firstly,
we use a registration algorithm to register the ViSAR images and utilize
Gaussian mixture distribution (GMD) to model the ViSAR data. Secondly, the
knowledge learned from the previous frames is leveraged to estimate the GMD
parameters of the current frame, and the Expectation-maximization (EM)
algorithm is used to estimate the subspace parameters. Then, the foreground
matrix of the current frame can be obtained. Finally, the alternating direction
method of multipliers (ADMM) is used to eliminate strong scattering objects in
the foreground matrix to obtain the final results. The experimental results
indicate that the SE-BSFV algorithm significantly enhances the shadows'
saliency and greatly improves the detection performance while ensuring
efficiency compared with several other advanced pre-processing algorithms.",http://arxiv.org/abs/2501.09341v1
Maxwell-$f(Q)$ theory,2025-01-16T08:37:02Z,G. G. L. Nashed,"Exploring the four-dimensional AdS black hole is crucial within the framework
of the AdS/CFT correspondence. In this research, considering the charged
scenario, we investigate the four-dimensional stationary and rotating AdS
solutions in the framework of the $f(Q)$ gravitational theory. Our emphasis is
on the power-law ansatz, which is consistent with observations and is deemed
the most viable. Because this solution does not have an uncharged version or
relate to general relativity, it falls into a new category, which derives its
features from changes in non-metricity and incorporates the Maxwell domain. We
analyze the singularities of such a solution, computing all the quantities of
different curvature and non-metricity invariants. Our results indicate the
presence of a central singularity, albeit with a softer nature compared to
standard non-metricity or Einstein general relativity, attributed to the
influence of the effect of $f(Q)$. We examine several physical characteristics
of black holes from a thermodynamics perspective and demonstrate the existence
of an outer event horizon in addition to the inner Cauchy horizons. However,
under the conditions of a sufficiently large electric charge, a naked
singularity emerges. Finally, we derive a class of rotating black hole in
four-dimensional $f(Q)$ gravity that are asymptotically anti-de Sitter charged.",http://arxiv.org/abs/2501.09373v1
"Joint Transmission and Deblurring: A Semantic Communication Approach
  Using Events",2025-01-16T09:07:01Z,"Pujing Yang, Guangyi Zhang, Yunlong Cai, Lei Yu, Guanding Yu","Deep learning-based joint source-channel coding (JSCC) is emerging as a
promising technology for effective image transmission. However, most existing
approaches focus on transmitting clear images, overlooking real-world
challenges such as motion blur caused by camera shaking or fast-moving objects.
Motion blur often degrades image quality, making transmission and
reconstruction more challenging. Event cameras, which asynchronously record
pixel intensity changes with extremely low latency, have shown great potential
for motion deblurring tasks. However, the efficient transmission of the
abundant data generated by event cameras remains a significant challenge. In
this work, we propose a novel JSCC framework for the joint transmission of
blurry images and events, aimed at achieving high-quality reconstructions under
limited channel bandwidth. This approach is designed as a deblurring
task-oriented JSCC system. Since RGB cameras and event cameras capture the same
scene through different modalities, their outputs contain both shared and
domain-specific information. To avoid repeatedly transmitting the shared
information, we extract and transmit their shared information and
domain-specific information, respectively. At the receiver, the received
signals are processed by a deblurring decoder to generate clear images.
Additionally, we introduce a multi-stage training strategy to train the
proposed model. Simulation results demonstrate that our method significantly
outperforms existing JSCC-based image transmission schemes, addressing motion
blur effectively.",http://arxiv.org/abs/2501.09396v1
"Fast Searching of Extreme Operating Conditions for Relay Protection
  Setting Calculation Based on Graph Neural Network and Reinforcement Learning",2025-01-16T09:11:48Z,"Yan Li, Jingyu Wang, Jiankang Zhang, Huaiqiang Li, Longfei Ren, Yinhong Li, Dongyuan Shi, Xianzhong Duan","Searching for the Extreme Operating Conditions (EOCs) is one of the core
problems of power system relay protection setting calculation. The current
methods based on brute-force search, heuristic algorithms, and mathematical
programming can hardly meet the requirements of today's power systems in terms
of computation speed due to the drastic changes in operating conditions induced
by renewables and power electronics. This paper proposes an EOC fast search
method, named Graph Dueling Double Deep Q Network (Graph D3QN), which combines
graph neural network and deep reinforcement learning to address this challenge.
First, the EOC search problem is modeled as a Markov decision process, where
the information of the underlying power system is extracted using graph neural
networks, so that the EOC of the system can be found via deep reinforcement
learning. Then, a two-stage Guided Learning and Free Exploration (GLFE)
training framework is constructed to accelerate the convergence speed of
reinforcement learning. Finally, the proposed Graph D3QN method is validated
through case studies of searching maximum fault current for relay protection
setting calculation on the IEEE 39-bus and 118-bus systems. The experimental
results demonstrate that Graph D3QN can reduce the computation time by 10 to
1000 times while guaranteeing the accuracy of the selected EOCs.",http://arxiv.org/abs/2501.09399v1
"Mixed atomic-scale electronic configuration as a strategy to avoid
  cocatalyst utilization in photocatalysis by high-entropy oxides",2025-01-16T10:14:07Z,"Jacqueline Hidalgo-Jiménez, Taner Akbay, Xavier Sauvage, Tatsumi Ishihara, Kaveh Edalati","To enhance the activity of photocatalysts for hydrogen production and CO2
conversion, noble metal cocatalysts as electron traps and/or acceptors such as
platinum or gold are usually utilized. This study hypothesizes that mixing
elements with heterogeneous electronic configurations and diverse
electronegativities can provide both acceptor and donor sites of electrons to
avoid using cocatalysts. This hypothesis was examined in high-entropy oxides
(HEOs), which show high flexibility for atomic-scale compositional changes by
keeping their single-or dual-phase structure. A new highentropy oxide was
designed and synthesized by mixing elements with an empty d orbital (titanium,
zirconium, niobium and tantalum) and a fully occupied d orbital (gallium). The
oxide, synthesized by high-pressure torsion followed by calcination, had two
phases (88 wt% orthorhombic (Pbcn) and 12 wt% monoclinic (I2/m)) with an
overall composition of TiZrNbTaGaO10.5. It exhibited UV and visible light
absorbance with a low bandgap of 2.5 eV, low radiative electron-hole
recombination and oxygen vacancy generation due to mixed valences of cations.
It successfully acted as a photocatalyst for CO and CH4 production from CO2
conversion and hydrogen production from water splitting without cocatalyst
addition. These findings confirm that introducing heterogeneous electronic
configurations and electronegativities can be considered as a design criterion
to avoid the need to use cocatalysts.",http://arxiv.org/abs/2501.09441v1
An Asymptotic Analysis of Bivalent Monoclonal Antibody-Antigen Binding,2025-01-16T11:23:55Z,"Luke A Heirene, Helen M Byrne, James W T Yates, Eamonn A Gaffney","Ligand-receptor interactions are fundamental to many biological processes.
For example in antibody-based immunotherapies, the dynamics of an antibody
binding with its target antigen directly influence the potency and efficacy of
monoclonal antibody (mAb) therapies. In this paper, we present an asymptotic
analysis of an ordinary differential equation (ODE) model of bivalent
antibody-antigen binding in the context of mAb cancer therapies, highlighting
the added complexity associated with bivalency of the antibody. To understand
what drives the complex temporal dynamics of bivalent antibody-antigen binding,
we construct asymptotic approximations to the model's solutions at different
timescales and antibody concentrations that are in good agreement with
numerical simulations of the full model. We show how the dynamics differ
between two scenarios; a region where unbound antigens are abundant, and one
where the number of unbound antigens is small such that the dominant balance
within the model equations changes. Of particular importance to the potency and
efficacy of mAb treatments are the values of quantities such as antigen
occupancy and bound antibody number. We use the results of our asymptotic
analysis to approximate the long-time values of these quantities that could be
combined with experimental data to facilitate parameter estimation.",http://arxiv.org/abs/2501.09473v1
"Spectro-polarimetry of GRB 180427A: evidence for distinct emission sites
  with varying polarisation",2025-01-16T12:02:16Z,"Rushikesh Sonawane, Shabnam Iyyani, Soumya Gupta, Tanmoy Chattopadhyay, Dipankar Bhattacharya, Varun. B. Bhalerao, Santosh V. Vadawale, G. C. Dewangan","The dynamics of the origin of gamma-ray emissions in gamma-ray bursts (GRBs)
remains an enigma. Through a joint analysis of GRB 180427A, observed by the
Fermi Gamma-ray Space Telescope and AstroSat's Cadmium Zinc Telluride Imager,
we identify emissions from two distinct regions with varying polarisation
properties. Time-resolved polarisation analysis reveals a synchronous evolution
of the polarisation angle (PA) and fraction (PF) with two emission pulses,
peaking with a delay of $4.82 \pm 0.12\, \mathrm{s}$. Spectral analysis
indicates that the first pulse is dominated by blackbody radiation, while the
second pulse exhibits a non-thermal spectrum (power law with an exponential
cutoff). Using a bottom-to-top approach through simulations, we decouple the
polarisation properties of the individual spectral components, revealing
polarisation fractions of 25\% - 40\% for the blackbody spectrum and 30\% -
60\% for the non-thermal spectrum. At a redshift of $z \sim 0.05$, the
blackbody emission originates from the jet photosphere at $10^{11}\,
\mathrm{cm}$, whereas the non-thermal emission arises from an optically thin
region at $10^{15}\, \mathrm{cm}$. The changing dominance of these emissions
explains the observed PA shift of $60^\circ \pm 22.3^\circ$. The spectral
cutoff at 1 MeV suggests pair opacity due to the jet's low bulk Lorentz factor
($\Gamma \sim$ tens). The high polarisation and hard spectral slopes ($\alpha >
-0.5$) imply a top-hat jet structure observed off-axis, near the jet's edge.
This off-axis viewing introduces anisotropy in the radiation within the viewing
cone ($1/\Gamma$), accounting for the observed polarisation.",http://arxiv.org/abs/2501.09492v1
"Local US officials' views on the impacts and governance of AI: Evidence
  from 2022 and 2023 survey waves",2025-01-16T15:25:58Z,"Sophia Hatz, Noemi Dreksler, Kevin Wei, Baobao Zhang","This paper presents a survey of local US policymakers' views on the future
impact and regulation of AI. Our survey provides insight into US policymakers'
expectations regarding the effects of AI on local communities and the nation,
as well as their attitudes towards specific regulatory policies. Conducted in
two waves (2022 and 2023), the survey captures changes in attitudes following
the release of ChatGPT and the subsequent surge in public awareness of AI.
Local policymakers express a mix of concern, optimism, and uncertainty about
AI's impacts, anticipating significant societal risks such as increased
surveillance, misinformation, and political polarization, alongside potential
benefits in innovation and infrastructure. Many also report feeling
underprepared and inadequately informed to make AI-related decisions. On
regulation, a majority of policymakers support government oversight and favor
specific policies addressing issues such as data privacy, AI-related
unemployment, and AI safety and fairness. Democrats show stronger and more
consistent support for regulation than Republicans, but the latter experienced
a notable shift towards majority support between 2022 and 2023. Our study
contributes to understanding the perspectives of local policymakers-key players
in shaping state and federal AI legislation-by capturing evolving attitudes,
partisan dynamics, and their implications for policy formation. The findings
highlight the need for capacity-building initiatives and bi-partisan
coordination to mitigate policy fragmentation and build a cohesive framework
for AI governance in the US.",http://arxiv.org/abs/2501.09606v1
"Unitary Expressions: A Necessary Abstraction for Extensible Quantum
  Programming Languages and Systems",2025-01-16T17:05:41Z,Ed Younis,"Quantum gates are the fundamental instructions of digital quantum computers.
Current programming languages, systems, and software development toolkits
identify these operational gates by their titles, which requires a shared
understanding of their meanings. However, in the continuously developing
software ecosystem surrounding quantum computing -- spanning high-level
programming systems to low-level control stacks -- this identification process
is often error-prone, challenging to debug, maintenance-heavy, and resistant to
change. In this paper, we propose replacing this nominal gate representation
with a functional one. We introduce the OpenQudit system for describing,
parsing, optimizing, analyzing, and utilizing programs comprising gates
described as symbolic unitary expressions. As part of this effort, we design
the Qudit Gate Language (QGL), a unitary-specific expression language, and
implement a differentiating just-in-time compiler in OpenQudit towards
embedding this language in quantum programming languages and systems.
Additionally, we have precisely designed and implemented the Qudit Virtual
Machine (QVM) to evaluate quantum programs and their gradients efficiently.
This evaluation is performed millions of times during the compilation of
quantum programs. Our QVM can compute gradients approximately ten times faster
than current leading numerical quantum compilation frameworks in the most
common use cases. Altogether, the OpenQudit system is envisioned to (1) support
many-level or qudit-based quantum systems, (2) enable the safe composition of
program transformation tools, (3) accelerate circuit optimizers and
transpilers, (4) enable compiler extensibility, and (5) provide a productive,
simple-to-use interface to quantum practitioners.",http://arxiv.org/abs/2501.09667v1
Data mining the functional architecture of the brain's circuitry,2025-01-16T17:37:09Z,Adam S. Charles,"The brain is a highly complex organ consisting of a myriad of subsystems that
flexibly interact and adapt over time and context to enable perception,
cognition, and behavior. Understanding the multi-scale nature of the brain,
i.e., how circuit- and moleclular-level interactions build up the fundamental
components of brain function, holds incredible potential for developing
interventions for neurodegenerative and psychiatric diseases, as well as open
new understanding into our very nature. Historically technological limitations
have forced systems neuroscience to be local in anatomy (localized, small
neural populations in single brain areas), in behavior (studying single tasks),
in time (focusing on specific stages of learning or development), and in
modality (focusing on imaging single biological quantities). New developments
in neural recording technology and behavioral monitoring now provide the data
needed to break free of local neuroscience to global neuroscience: i.e.,
understanding how the brain's many subsystem interact, adapt, and change across
the multitude of behaviors animals and humans must perform to thrive.
Specifically, while we have much knowledge of the anatomical architecture of
the brain (i.e., the hardware), we finally are approaching the data needed to
find the functional architecture and discover the fundamental properties of the
software that runs on the hardware. We must take this opportunity to bridge
between the vast amounts of data to discover this functional architecture which
will face numerous challenges from low-level data alignment up to high level
questions of interpretable mathematical models of behavior that can synthesize
the myriad of datasets together.",http://arxiv.org/abs/2501.09684v1
Intelligent OLSR Routing Protocol Optimization for VANETs,2025-01-16T18:05:28Z,"Jamal Toutouh, José García-Nieto, Enrique Alba","Recent advances in wireless technologies have given rise to the emergence of
vehicular ad hoc networks (VANETs). In such networks, the limited coverage of
WiFi and the high mobility of the nodes generate frequent topology changes and
network fragmentations. For these reasons, and taking into account that there
is no central manager entity, routing packets through the network is a
challenging task. Therefore, offering an efficient routing strategy is crucial
to the deployment of VANETs. This paper deals with the optimal parameter
setting of the optimized link state routing (OLSR), which is a well-known
mobile ad hoc network routing protocol, by defining an optimization problem.
This way, a series of representative metaheuristic algorithms (particle swarm
optimization, differential evolution, genetic algorithm, and simulated
annealing) are studied in this paper to find automatically optimal
configurations of this routing protocol. In addition, a set of realistic VANET
scenarios (based in the city of M\'alaga) have been defined to accurately
evaluate the performance of the network under our automatic OLSR. In the
experiments, our tuned OLSR configurations result in better quality of service
(QoS) than the standard request for comments (RFC 3626), as well as several
human experts, making it amenable for utilization in VANET configurations.",http://arxiv.org/abs/2501.09716v1
"Suggesting Code Edits in Interactive Machine Learning Notebooks Using
  Large Language Models",2025-01-16T18:55:38Z,"Bihui Jin, Jiayue Wang, Pengyu Nie","Machine learning developers frequently use interactive computational
notebooks, such as Jupyter notebooks, to host code for data processing and
model training. Jupyter notebooks provide a convenient tool for writing machine
learning pipelines and interactively observing outputs, however, maintaining
Jupyter notebooks, e.g., to add new features or fix bugs, can be challenging
due to the length and complexity of the notebooks. Moreover, there is no
existing benchmark related to developer edits on Jupyter notebooks. To address
this, we present the first dataset of 48,398 Jupyter notebook edits derived
from 20,095 revisions of 792 machine learning repositories on GitHub, and
perform the first study of the using LLMs to predict code edits in Jupyter
notebooks. Our dataset captures granular details of cell-level and line-level
modifications, offering a foundation for understanding real-world maintenance
patterns in machine learning workflows. We observed that the edits on Jupyter
notebooks are highly localized, with changes averaging only 166 lines of code
in repositories. While larger models outperform smaller counterparts in code
editing, all models have low accuracy on our dataset even after finetuning,
demonstrating the complexity of real-world machine learning maintenance tasks.
Our findings emphasize the critical role of contextual information in improving
model performance and point toward promising avenues for advancing large
language models' capabilities in engineering machine learning code.",http://arxiv.org/abs/2501.09745v1
VideoWorld: Exploring Knowledge Learning from Unlabeled Videos,2025-01-16T18:59:10Z,"Zhongwei Ren, Yunchao Wei, Xun Guo, Yao Zhao, Bingyi Kang, Jiashi Feng, Xiaojie Jin","This work explores whether a deep generative model can learn complex
knowledge solely from visual input, in contrast to the prevalent focus on
text-based models like large language models (LLMs). We develop VideoWorld, an
auto-regressive video generation model trained on unlabeled video data, and
test its knowledge acquisition abilities in video-based Go and robotic control
tasks. Our experiments reveal two key findings: (1) video-only training
provides sufficient information for learning knowledge, including rules,
reasoning and planning capabilities, and (2) the representation of visual
change is crucial for knowledge acquisition. To improve both the efficiency and
efficacy of this process, we introduce the Latent Dynamics Model (LDM) as a key
component of VideoWorld. Remarkably, VideoWorld reaches a 5-dan professional
level in the Video-GoBench with just a 300-million-parameter model, without
relying on search algorithms or reward mechanisms typical in reinforcement
learning. In robotic tasks, VideoWorld effectively learns diverse control
operations and generalizes across environments, approaching the performance of
oracle models in CALVIN and RLBench. This study opens new avenues for knowledge
acquisition from visual data, with all code, data, and models open-sourced for
further research.",http://arxiv.org/abs/2501.09781v1
"On the seismic modelling of subgiant stars: testing different grid
  interpolation methods",2025-01-16T19:43:06Z,"Miguel Clara, Margarida S. Cunha, Pedro P. Avelino, Tiago L. Campante, Sébastien Deheuvels, Daniel R. Reese","Context. The emergence of mixed modes during the subgiant phase, whose
frequencies are characterized by a fast evolution with age, can potentially
enable a precise determination of stellar properties, a key goal for future
missions like PLATO. However, current modelling techniques often consider grids
that lack the resolution to properly account for the fast mode frequency
evolution, consequently requiring the use of interpolation algorithms to cover
the parameter space in between the grid models when applying model-data
comparison methods. Aims. We aim at reproducing the $\ell$=1 mode frequencies
within the accuracy limits associated with the typical observational errors
($\sim$0.1 $\mu$Hz) through interpolation on a grid of subgiant models.
Methods. With that aim, we used variations of a two-step interpolation
algorithm, which considered linear and cubic splines interpolation methods and
different age proxies (physical age, scaled age, and central density). Results.
The best results were obtained using an algorithm that considers cubic splines
interpolation along tracks, linear interpolation across tracks, and central
density $\rho_\text{c}$ as the age proxy. This combination yielded, on average,
an absolute error of 0.14 $\mu$Hz, but reached maximum absolute errors on the
interpolated frequencies of 1.2 $\mu$Hz for some models, which is an order of
magnitude higher than the typical observational errors. Furthermore, we
investigated the impact on the accuracy of the interpolation from changes in
the physical properties of the stars, showing, in particular, how the addition
of core overshoot can affect significantly the interpolation results.",http://arxiv.org/abs/2501.09809v1
"IE-Bench: Advancing the Measurement of Text-Driven Image Editing for
  Human Perception Alignment",2025-01-17T02:47:25Z,"Shangkun Sun, Bowen Qu, Xiaoyu Liang, Songlin Fan, Wei Gao","Recent advances in text-driven image editing have been significant, yet the
task of accurately evaluating these edited images continues to pose a
considerable challenge. Different from the assessment of text-driven image
generation, text-driven image editing is characterized by simultaneously
conditioning on both text and a source image. The edited images often retain an
intrinsic connection to the original image, which dynamically change with the
semantics of the text. However, previous methods tend to solely focus on
text-image alignment or have not aligned with human perception. In this work,
we introduce the Text-driven Image Editing Benchmark suite (IE-Bench) to
enhance the assessment of text-driven edited images. IE-Bench includes a
database contains diverse source images, various editing prompts and the
corresponding results different editing methods, and total 3,010 Mean Opinion
Scores (MOS) provided by 25 human subjects. Furthermore, we introduce IE-QA, a
multi-modality source-aware quality assessment method for text-driven image
editing. To the best of our knowledge, IE-Bench offers the first IQA dataset
and model tailored for text-driven image editing. Extensive experiments
demonstrate IE-QA's superior subjective-alignments on the text-driven image
editing task compared with previous metrics. We will make all related data and
code available to the public.",http://arxiv.org/abs/2501.09927v1
"Metamorphic Testing for Smart Contract Validation:A Case Study of
  Ethereum-Based Crowdfunding Contracts",2025-01-17T05:04:23Z,"Irving Jared Villanueva, Madhusudan Srinivasan, Faqeer Ur Rehman","Blockchain smart contracts play a crucial role in automating and securing
agreements in diverse domains such as finance, healthcare, and supply chains.
Despite their critical applications, testing these contracts often receives
less attention than their development, leaving significant risks due to the
immutability of smart contracts post-deployment. A key challenge in the testing
of smart contracts is the oracle problem, where the exact expected outcomes are
not well defined, complicating systematic testing efforts.
  Metamorphic Testing (MT) addresses the oracle problem by using Metamorphic
Relations (MRs) to validate smart contracts. MRs define how output should
change relative to specific input modifications, determining whether the tests
pass or fail. In this work, we apply MT to test an Ethereum-based crowdfunding
smart contract, focusing on core functionalities such as state transitions and
donation tracking.
  We identify a set of MRs tailored for smart contract testing and generate
test cases for these MRs. To assess the effectiveness of this approach, we use
the Vertigo mutation testing tool to create faulty versions of the smart
contract. The experimental results show that our MRs detected 25.65% of the
total mutants generated, with the most effective MRs achieving a mutant-killing
rate of 89%. These results highlight the utility of MT to ensure the
reliability and quality of blockchain-based smart contracts.",http://arxiv.org/abs/2501.09955v1
"Giant topological Hall effect in epitaxial
  Ni$_{80}$Fe$_{20}$/La$_{0.65}$Sr$_{0.35}$MnO$_3$ thin film heterostructures",2025-01-17T06:27:10Z,"Kusampal Yadav, Dilruba Hasina, Nasiruddin Mondal, Sayantika Bhowal, Devajyoti Mukherjee","The emergence of new physical properties at the interfaces between complex
oxides has always been of both fundamental and practical importance. Here, we
report the observation of a giant topological Hall resistivity of $\sim 2.8 \mu
\Omega$ \text{cm} at room temperature in an epitaxial thin-film heterostructure
of permalloy (Py, Ni$_{80}$Fe$_{20}$) and the half-metallic ferromagnet
La$_{0.65}$Sr$_{0.35}$MnO$_3$ (LSMO). This large magnitude of the topological
Hall effect in the Py/LSMO heterostructure, compared to a single-layer Py thin
film, is attributed to the optimized combination of ferromagnetism in LSMO and
the strong spin-orbit-coupling-driven Rashba interaction at the interface. The
introduction of a ferroelectric BaTiO$_3$ (BTO) sandwich layer in the Py/LSMO
heterostructure also leads to an enhanced topological Hall resistivity compared
to the single-layer Py thin film. Interestingly, magnetic force microscopy
measurements reveal skyrmion-like features, suggesting the origin of the
topological Hall effect. Our theoretical model calculations for the skyrmion
lattice further indicate that the Rashba interaction, driven by the broken
inversion symmetry in the Py/LSMO films, can account for the observed changes
in the topological Hall effect at the interface. Our work opens the door for
the potential use of Py/LSMO thin films in spintronic applications.",http://arxiv.org/abs/2501.09969v1
"LWGANet: A Lightweight Group Attention Backbone for Remote Sensing
  Visual Tasks",2025-01-17T08:56:17Z,"Wei Lu, Si-Bao Chen, Chris H. Q. Ding, Jin Tang, Bin Luo","Remote sensing (RS) visual tasks have gained significant academic and
practical importance. However, they encounter numerous challenges that hinder
effective feature extraction, including the detection and recognition of
multiple objects exhibiting substantial variations in scale within a single
image. While prior dual-branch or multi-branch architectural strategies have
been effective in managing these object variances, they have concurrently
resulted in considerable increases in computational demands and parameter
counts. Consequently, these architectures are rendered less viable for
deployment on resource-constrained devices. Contemporary lightweight backbone
networks, designed primarily for natural images, frequently encounter
difficulties in effectively extracting features from multi-scale objects, which
compromises their efficacy in RS visual tasks. This article introduces LWGANet,
a specialized lightweight backbone network tailored for RS visual tasks,
incorporating a novel lightweight group attention (LWGA) module designed to
address these specific challenges. LWGA module, tailored for RS imagery,
adeptly harnesses redundant features to extract a wide range of spatial
information, from local to global scales, without introducing additional
complexity or computational overhead. This facilitates precise feature
extraction across multiple scales within an efficient framework.LWGANet was
rigorously evaluated across twelve datasets, which span four crucial RS visual
tasks: scene classification, oriented object detection, semantic segmentation,
and change detection. The results confirm LWGANet's widespread applicability
and its ability to maintain an optimal balance between high performance and low
complexity, achieving SOTA results across diverse datasets. LWGANet emerged as
a novel solution for resource-limited scenarios requiring robust RS image
processing capabilities.",http://arxiv.org/abs/2501.10040v1
The role of dry mergers in shaping the scaling relations of galaxies,2025-01-17T09:07:18Z,"Mauro D'Onofrio, Cesare Chiosi, Francesco Brevi","In the context of the hierarchical formation of galaxies, we investigated the
role played by mergers in shaping the scaling relations of galaxies, that is
the projections of their Fundamental Plane onto the Ie-Re, Ie-Sigma, Ms-Re and
L-Sigma planes. To this aim, based on the scalar Virial Theorem, we developed a
simple theory of multiple dry mergers to read both the large scale simulations
and the companion scaling relations. The aim was to compare the results of this
approach with the observational data and with two of the most recent and
detailed numerical cosmo-hydro-dynamical simulations, that is Illustris-TNG and
EAGLE (Evolution and Assembly of GaLaxies and their Environments). We derived
the above scaling relations for the galaxies of the MaNGA (Mapping Nearby
Galaxies at APO) and WINGS (Wide-field Imaging of Nearby Galaxy-Clusters
Survey) databases and compared them with the observational data, the numerical
simulations, and the results of our simple theory of dry mergers. The multiple
dry merging mechanism is able to explain all the main characteristics of the
observed scaling relations of galaxies, such as slopes, scatters, curvatures
and zones of exclusion. The distribution of galaxies in these planes is
continuously changing across time because of the merging activity and other
physical processes, such as star formation, quenching, energy feedback, and so
forth. The simple merger theory presented here yields the correct distribution
of galaxies in the main scaling relations at all cosmic epochs. The precision
is comparable with that obtained by the modern cosmo-hydro-dynamical
simulations, with the advantage of providing a rapid exploratory response on
the consequences engendered by different physical effects.",http://arxiv.org/abs/2501.10047v1
"Two-level Solar Irradiance Clustering with Season Identification: A
  Comparative Analysis",2025-01-17T10:05:11Z,"Roshni Agrawal, Sivakumar Subramanian, Venkataramana Runkana","Solar irradiance clustering can enhance solar power capacity planning and
help improve forecasting models by identifying similar irradiance patterns
influenced by seasonal and weather changes. In this study, we adopt an
efficient two-level clustering approach to automatically identify seasons using
the clear sky irradiance in first level and subsequently to identify daily
cloud level as clear, cloudy and partly cloudy within each season in second
level. In the second level of clustering, three methods are compared, namely,
Daily Irradiance Index (DII or $\beta$), Euclidean Distance (ED), and Dynamic
Time Warping (DTW) distance. The DII is computed as the ratio of time integral
of measured irradiance to time integral of the clear sky irradiance. The
identified clusters were compared quantitatively using established clustering
metrics and qualitatively by comparing the mean irradiance profiles. The
results clearly establish the superiority of the $\beta$-based clustering
approach as the leader, setting a new benchmark for solar irradiance clustering
studies. Moreover, $\beta$-based clustering remains effective even for annual
data unlike the time-series methods which suffer significant performance
degradation. Interestingly, contrary to expectations, ED-based clustering
outperforms the more compute-intensive DTW distance-based clustering. The
method has been rigorously validated using data from two distinct US locations,
demonstrating robust scalability for larger datasets and potential
applicability for other locations.",http://arxiv.org/abs/2501.10084v1
"The steady inviscid compressible self-similar flows and the stability
  analysis",2025-01-17T11:28:45Z,"Shangkun Weng, Hongwei Yuan","We investigate the steady inviscid compressible self-similar flows which
depends only on the polar angle in spherical coordinates. It is shown that
besides the purely supersonic and subsonic self-similar flows, there exists
purely sonic flows, Beltrami flows with a nonconstant proportionnality factor
and smooth transonic self-similar flows with large vorticity. For a constant
supersonic incoming flow past an infinitely long circular cone, a conic shock
attached to the tip of the cone will form, provided the opening angle of the
cone is less than a critical value. We introduce the shock polar for the radial
and polar components of the velocity and show that there exists a monotonicity
relation between the shock angle and the radial velocity, which seems to be new
and not been observed before. If a supersonic incoming flow is self-similar
with nonzero azimuthal velocity, a conic shock also form attached to the tip of
the cone. The state at the downstream may change smoothly from supersonic to
subsonic, thus the shock can be supersonic-supersonic, supersonic-subsonic and
even supersonic-sonic where the shock front and the sonic front coincide. We
further investigate the structural stability of smooth self-similar
irrotational transonic flows and analyze the corresponding linear mixed type
second order equation of Tricomi type. By exploring some key properties of the
self-similar solutions, we find a multiplier and identify a class of admissible
boundary conditions for the linearized mixed type second-order equation. We
also prove the existence and uniqueness of a class of smooth transonic flows
with nonzero vorticity which depends only on the polar and azimuthal angles in
spherical coordinates.",http://arxiv.org/abs/2501.10125v1
"A Simple but Effective Closed-form Solution for Extreme Multi-label
  Learning",2025-01-17T13:24:13Z,"Kazuma Onishi, Katsuhiko Hayashi","Extreme multi-label learning (XML) is a task of assigning multiple labels
from an extremely large set of labels to each data instance. Many current
high-performance XML models are composed of a lot of hyperparameters, which
complicates the tuning process. Additionally, the models themselves are adapted
specifically to XML, which complicates their reimplementation. To remedy this
problem, we propose a simple method based on ridge regression for XML. The
proposed method not only has a closed-form solution but also is composed of a
single hyperparameter. Since there are no precedents on applying ridge
regression to XML, this paper verified the performance of the method by using
various XML benchmark datasets. Furthermore, we enhanced the prediction of
low-frequency labels in XML, which hold informative content. This prediction is
essential yet challenging because of the limited amount of data. Here, we
employed a simple frequency-based weighting. This approach greatly simplifies
the process compared with existing techniques. Experimental results revealed
that it can achieve levels of performance comparable to, or even exceeding,
those of models with numerous hyperparameters. Additionally, we found that the
frequency-based weighting significantly improved the predictive performance for
low-frequency labels, while requiring almost no changes in implementation. The
source code for the proposed method is available on github at
https://github.com/cars1015/XML-ridge.",http://arxiv.org/abs/2501.10179v1
"Modeling the drying process in hard carbon electrodes based on the
  phase-field method",2025-01-17T13:29:42Z,"Marcel Weichel, Martin Reder, Simon Daubner, Julian Klemens, David Burger, Philip Scharfer, Wilhelm Schabel, Britta Nestler, Daniel Schneider","The present work addresses the simulation of pore emptying during the drying
of battery electrodes. For this purpose, a model based on the multiphase-field
method (MPF) is used, since it is an established approach for modeling and
simulating multiphysical problems. A model based on phase fields is introduced
that takes into account fluid flow, capillary effects, and wetting behavior,
all of which play an important role in drying. In addition, the MPF makes it
possible to track the movement of the liquid-air interface without
computationally expensive adaptive mesh generation. The presented model is used
for the first time to investigate pore emptying in real hard carbon
microstructures. For this purpose, the microstructures of real dried electrodes
are used as input for the simulations. The simulations performed here
demonstrate the importance of considering the resolved microstructural
information compared to models that rely only on statistical geometry
parameters such as pore size distributions. The influence of various parameters
such as different microstructures, fluid viscosity, and the contact angle on
pore emptying are investigated. In addition, this work establishes a
correlation between the capillary number and the breakthrough time of the
solvent as well as the height difference of the solvent front at the time of
breakthrough. The results indicate that the drying process can be optimized by
doping the particle surface, which changes the contact angle between the fluids
and the particles.",http://arxiv.org/abs/2501.10185v1
"Investigation of Polymer Association Behaviors in Solvents Using a
  Coarse-Grained Model",2025-01-17T16:28:53Z,"Xiangyu Zhang, Dong Meng","The associative interaction, such as hydrogen bonding, can bring about
versatile functionalities to polymer systems, which has been investigated by
tremendous researches, but the fundamental understanding on association process
is still lacking. In this study, a reaction-controlled association model is
proposed to delve into the polymer association activities in solvents, which is
proved to obey the principle of thermodynamics. Additionally, associative
polymer chain configurational bias method is developed to improve sampling
efficiency, demonstrating a significantly faster relaxation process. First, we
set non-bonded interactions to be zero, and only keep the chain connectivity
and association. It is found that the association process intrinsically follows
Bernoulli process by comparing the simulation results and analytic results.
Next, we include non-bonded interactions into the simulation to examine its
effects. It emerged that the excluded volume effect and solvents immiscibility
effects can result in inhomogeneous associating probability distribution along
the chain contour, in contrast to the homogeneity observed in ideal systems,
thereby shifting from the binomial distribution to Poisson binomial
distribution. At last, the study is extended to cooperative association
systems. The incorporation of cooperative association can lead to the
coexistence of coil and globule state at the transition point, verified by the
potential of mean force calculation. Finally, a mathematical model is proposed,
illustrating the changes in statistical weight induced by sequence enthalpy
bias, which is the consequence of cooperative behaviors.",http://arxiv.org/abs/2501.10286v1
"Elucidating the high compliance mechanism by which the urinary bladder
  fills under low pressures",2025-01-17T17:34:48Z,"Fatemeh Azari, Anne M. Robertson, Yasutaka Tobe, Paul N. Watton, Lori A. Birder, Naoki Yoshimura, Kanako Matsuoka, Christopher Hardin, Simon Watkins","The high compliance of the urinary bladder during filling is essential for
its proper function, enabling it to accommodate significant volumetric
increases with minimal rise in transmural pressure. This study aimed to
elucidate the physical mechanisms underlying this phenomenon by analyzing the
ex vivo filling process in rat from a fully voided state to complete
distension, without preconditioning, using three complementary imaging
modalities. High-resolution micro-CT at 10.8 {\mu}m resolution was used to
generate detailed 3D reconstructions of the bladder lumen, revealing a 62 fold
increase in bladder volume during filling. Pressure-volume studies of whole
bladder delineated three mechanical filling regimes: an initial high-compliance
phase, a transitional phase, and a final high-pressure phase. While prior
studies conjectured small mucosal rugae (450 {\mu}m) are responsible for the
high compliance phase, multiphoton microscopy (MPM) of the dome of the voided
bladder revealed large folds an order of magnitude larger than these rugae.
Bladder imaging during the inflation process demonstrated flattening of these
large scale folds is responsible for volume increases in the initial high
compliance phase. The 3D reconstructions of the bladder lumen in the filled and
voided state revealed a high voiding efficiency of 97.13%. The MPM imaging
results suggest the large scale folds in the dome enable this high voiding
fraction by driving urine toward the bladder outlet. These insights are vital
for computational models of bladder biomechanics and understanding changes to
bladder function due to pathological conditions such as bladder outlet
obstruction and age-related dysfunction.",http://arxiv.org/abs/2501.10312v1
"Improving Student Self-Efficacy in Quantum Computing with the Qubit
  Touchdown Board Game",2025-01-14T15:19:59Z,"Kristina Armbruster, Gintaras Duda, Thomas G. Wong","Qubit Touchdown is a two-player, competitive board game that was developed to
introduce students to quantum computing. A quantum computer is a new kind of
computer that is based on the laws of quantum physics, and it can solve certain
problems faster than normal computers because it follows a different set of
rules. Qubit Touchdown's game play mirrors the rules of (American) football,
with players taking turns moving the football to score the most touchdowns, and
no knowledge of quantum computing is needed to play the game. We evaluated the
game with 107 public high school students in Precalculus, Advanced Placement
(AP) Statistics, and/or AP Physics 1 courses, assessing whether their interest
in and self-efficacy toward quantum computing changed as a result of playing
the game and learning about its connections to quantum computing. We also
assessed whether the game was easy to learn and enjoyable. We found that
students' self-efficacy was improved by 33.4%, and they widely considered the
game accessible and fun. Thus, Qubit Touchdown could be an effective resource
to introduce students to Quantum Computing and boost their confidence in
learning about the field. Free printables of the game are available, and
professionally produced copies can be purchased on demand.",http://arxiv.org/abs/2501.10449v1
"Driving a Quantum Phase Transition at Arbitrary Rate: Exact solution of
  the Transverse-Field Ising model",2025-01-16T19:03:37Z,"András Grabarits, Federico Balducci, Adolfo del Campo","We study the crossing of the quantum phase transition in the transverse-field
Ising model after modulating the magnetic field at an arbitrary rate, exploring
the critical dynamics from the slow to the sudden quench regime. We do so by
analyzing the defect density, the complete kink number distribution, and its
cumulants upon completion of a linearized quench. Our analysis relies on the
diagonalization of the model using the standard Jordan-Wigner and Fourier
transformations, along with the exact solution of the time evolution in each
mode in terms of parabolic cylinder functions. The free-fermion nature of the
problem dictates that the kink number distribution is associated with
independent and distinguishable Bernoulli variables, each with a success
probability $p_k$. We employ a combination of convergent and asymptotic series
expansions to characterize $p_k$ without restrictions on the driving rate. When
the latter is approximated by the Landau-Zener formula, the kink density is
described by the Kibble-Zurek mechanism, and higher-order cumulants follow a
universal power-law behavior, as recently predicted theoretically and verified
in the laboratory. By contrast, for moderate and sudden driving protocols, the
cumulants exhibit a nonuniversal behavior that is not monotonic on the driving
rate and changes qualitatively with the cumulant order. The kink number
statistics remain sub-Poissonian for any driving rate, as revealed by an
analysis of the cumulant rations that vary nonmonotonically from the sudden to
the slow-driving regime. Thanks to the determination of $p_k$ for an arbitrary
rate, our study provides a complete analytical understanding of kink number
statistics from the slow driving regime to the sudden quench limit.",http://arxiv.org/abs/2501.10478v1
"AI Technicians: Developing Rapid Occupational Training Methods for a
  Competitive AI Workforce",2025-01-17T22:14:56Z,"Jaromir Savelka, Can Kultur, Arav Agarwal, Christopher Bogart, Heather Burte, Adam Zhang, Majd Sakr","The accelerating pace of developments in Artificial Intelligence~(AI) and the
increasing role that technology plays in society necessitates substantial
changes in the structure of the workforce. Besides scientists and engineers,
there is a need for a very large workforce of competent AI technicians (i.e.,
maintainers, integrators) and users~(i.e., operators). As traditional 4-year
and 2-year degree-based education cannot fill this quickly opening gap,
alternative training methods have to be developed. We present the results of
the first four years of the AI Technicians program which is a unique
collaboration between the U.S. Army's Artificial Intelligence Integration
Center (AI2C) and Carnegie Mellon University to design, implement and evaluate
novel rapid occupational training methods to create a competitive AI workforce
at the technicians level. Through this multi-year effort we have already
trained 59 AI Technicians. A key observation is that ongoing frequent updates
to the training are necessary as the adoption of AI in the U.S. Army and within
the society at large is evolving rapidly. A tight collaboration among the
stakeholders from the army and the university is essential for successful
development and maintenance of the training for the evolving role. Our findings
can be leveraged by large organizations that face the challenge of developing a
competent AI workforce as well as educators and researchers engaged in solving
the challenge.",http://arxiv.org/abs/2501.10579v1
Selecting samples of galaxies with fewer Fingers-of-God,2025-01-17T22:39:06Z,"Antón Baleato Lizancos, Uroš Seljak, Minas Karamanis, Marco Bonici, Simone Ferraro","The radial positions of galaxies inferred from their measured redshift appear
distorted due to their peculiar velocities. We argue that the contribution from
stochastic velocities -- which gives rise to `Fingers-of-God' (FoG) anisotropy
in the inferred maps -- does not lend itself to perturbative modelling already
on scales targeted by current experiments. To get around this limitation, we
propose to remove FoG using data-driven indicators of their abundance that are
local in nature and thus avoid selection biases. In particular, we show that
the scale where the measured power spectrum quadrupole changes sign is tightly
anti-correlated with both the satellite fraction and the velocity dispersion,
and can thus be used to select galaxy samples with fewer FoG. In addition, we
show that maps of the thermal Sunyaev-Zel'dovich distortion of the cosmic
microwave background frequency spectrum can be used to identify and discard
many of the most problematic galaxies. These techniques could potentially
extend the reach of perturbative models for galaxy clustering and improve
reconstructions of the large-scale velocity and displacement fields from the
redshift-space positions of galaxies.",http://arxiv.org/abs/2501.10587v2
"Building Short Value Chains for Animal Welfare-Friendly Products
  Adoption: Insights from a Restaurant-Based Study in Japan",2025-01-18T07:12:47Z,"Takuya Washio, Sota Takagi, Miki Saijo, Ken Wako, Keitaro Sato, Hiroyuki Ito, Ken-ichi Takeda, Takumi Ohashi","As global attention on sustainable and ethical food systems grows, animal
welfare-friendly products (AWFP) are increasingly recognized as essential to
addressing consumer and producer concerns. However, traditional research often
neglects the interdependencies between production, retail, and consumption
stages within the supply chain. This study examined how cross-stage
interactions among producers, consumers, and retail intermediaries can promote
AWFP adoption. By establishing a short value chain from production to
consumption, we conducted a two-month choice experiment in the operational
restaurant, employing a mixed-method approach to quantitatively and
qualitatively assess stakeholder responses. The results revealed that providing
information about AWFP practices significantly influenced consumer behavior,
increasing both product selection and perceived value. Retailers recognized the
potential for economic benefits and strengthened customer loyalty, while
producers identified new revenue opportunities by re-fattening delivered cow.
These coordinated changes - defined as synchronized actions and mutual
reinforcement across production, retail, and consumption - generated positive
feedback loops that motivated stakeholders to adopt AWFP practices. This
research underscores the potential of strategically designed short value chain
to foster cross-stage coordination and highlights their role as practical entry
points for promoting sustainable and ethical food systems on a larger scale.",http://arxiv.org/abs/2501.10680v1
"Simulation of Binary-Single Interactions in AGN Disk I: Gas-Enhanced
  Binary Orbital Hardening",2025-01-18T09:12:47Z,"Mengye Wang, Yiqiu Ma, Hui Li, Qingwen Wu, Ya-Ping Li, Xiangli Lei, Jiancheng Wu","Stellar-mass binary black hole\,(BBH) mergers within the accretion disks of
active galactic nuclei may contribute to gravitational wave\,(GW) events
detected by grounded-based GW detectors. In particular, the interaction between
a BBH and a single stellar-mass black hole\,(sBH), known as the binary-single
interaction\,(BSI) process, can potentially lead to GW events with detectable
non-zero eccentricity. Previous studies of the BSI process, which neglected the
effects of gas, showed that BSIs contribute non-negligibly to GW events in a
coplanar disk environment. In this work, we conduct a series of 2-dimensional
hydrodynamical and N-body simulations to explore the BSI in a gas environment
by coupling REBOUND with Athena++. We perform 360 simulation runs, spanning
parameters in disk surface density \(\Sigma_0\) and impact parameter \(b\). We
find that the gas-induced energy dissipation within the three-body system
becomes significant if the encounter velocity between the sBHs is sufficiently
large\,($\gg c_s$). Our simulation results indicate that approximately half of
the end states of the BSI are changed by gas. Furthermore, at higher gas
density, the number of encounters during the BSI process will increase and the
end-state BBHs tend to be more compact. Consequently, the presence of gas may
shorten the GW merger timescale for end-state BBHs and increase the three-body
merger rate.",http://arxiv.org/abs/2501.10703v1
"Changing the ranking in eigenvector centrality of a weighted graph by
  small perturbations",2025-01-18T12:11:01Z,"Michele Benzi, Nicola Guglielmi","In this article, we consider eigenvector centrality for the nodes of a graph
and study the robustness (and stability) of this popular centrality measure.
For a given weighted graph $\G$ (both directed and undirected), we consider the
associated weighted adiacency matrix $A$, which by definition is a non-negative
matrix. Eigenvector centrality consists of ranking the elements of the graph
according to the corresponding entries of the Perron eigenvector of $A$, which
is associated with the positive eigenvalue with largest modulus.
  An indicator of the robustness of eigenvector centrality consists in looking
for a nearby perturbed graph $\widetilde{\G}$, with the same structure as $\G$
(i.e., with the same vertices and edges), but with a weighted adiacency matrix
$\widetilde A$ such that the highest $m$ entries ($m \ge 2$) of the Perron
eigenvector of $\widetilde A$ coalesce, making the ranking at the highest level
ambiguous. To compute a solution to this matrix nearness problem, a nested
iterative algorithm is proposed that makes use of a constrained gradient system
of matrix differential equations (possibly on a low-rank manifold) in the inner
iteration and a one-dimensional optimization of the perturbation size in the
outer iteration.
  The proposed algorithm produces the {\em optimal} perturbation (i.e., the one
with smallest Frobenius norm) of the graph, which causes the looked-for
coalescence, which is a measure of the sensitivity of the graph. The
methodology is formulated in terms of graphs but applies to any nonnegative
matrix, with potential applications in fields like population models, consensus
dynamics, economics, etc.",http://arxiv.org/abs/2501.10745v1
"Energy-Threshold Bias Calculator: A Physics-Model Based Adaptive
  Correction Scheme for Photon-Counting CT",2025-01-18T13:32:17Z,"Yuting Chen, Yuxiang Xing, Li Zhang, Zhi Deng, Hewei Gao","Photon-counting detector based computed tomography (PCCT) has greatly
advanced in recent years. However, the spectral inconsistency is still a
serious challenge for PCCT that could directly introduce obvious artifacts and
severe inaccuracies. This work attempts to overcome the challenge by modeling
the spectral inconsistency in a novel, unified, and two-term factorized
framework, with a spectral skew term independent of the energy threshold, and
an energy-threshold bias analytical characterization term. To solve the
spectral inconsistency, a two-step decomposition algorithm called
energy-threshold bias calculator (ETB-Cal) is derived here, in which the
spectral skew term is grossly determined at a relatively low energy threshold
and only the energy-threshold bias is needed to be calculated as the energy
threshold changes. After the two terms being computed out in calibration stage,
they will be incorporated into our spectral model to generate the spectral
correction vectors as well as the material decomposition vectors if needed, for
PCCT projection data. To validate our method, both numerical simulations
physics experiments were carried out on a tabletop PCCT system. Preliminary
results showed that the spectral inconsistency can be significantly reduced,
for example, with an non-uniformity quantitative indicators decreasing from
26.27 to 5.80 HU for Gammex multi-energy phantom and from 27.88 to 3.16 HU for
kyoto head phantom. The considerable improvements consistently demonstrate a
great potential of the proposed novel physics-model based correction scheme in
practical applications, as computationally efficient, calibration-wise
convenient with high degree of generality, and substantially avoiding the use
of X-ray florescence material in the energy-threshold calibration.",http://arxiv.org/abs/2501.10764v1
Tuning magnetism in graphene nanoribbons via strain and adatoms,2025-01-18T15:46:34Z,"Pablo Moles, Hernán Santos, Francisco Domínguez-Adame, Leonor Chico","We investigate the impact of strain and adsorbed H adatoms on the magnetic
properties of zigzag graphene nanoribbons (ZGNRs) using a combination of
tight-binding and density functional theory methods for both, ferromagnetic
(FM) and antiferromagnetic edge configurations (AFM). Our study reveals that
longitudinal strain induces a significant enhancement in the edge magnetic
moment, that we attribute to strain-driven modifications in the band structure.
In addition, we describe H~adatoms within the tight-binding approach by
employing both an unrelaxed vacancy model and the Anderson impurity model. By
comparing to density functional theory results, we corroborate that the
Anderson impurity model is best suited to describe H adsorption. We then focus
on the metallic FM edge configuration of the ZGNRs to better exploit the tuning
of its properties. We find that the magnetic configuration of H~adatoms is
strongly influenced by the edges, with an AFM coupling between edges and the
H~adatom. In fact, the magnetic spatial pattern of the H adatom differs to that
found in graphene due to this edge coupling. Importantly, we find robust
discrete plateaus of integer magnetic moment as strain is varied in the
defected ZGNRs, that we relate to changes in the band structure, namely, a
half-metallic character or the opening of a gap. This behavior can be of
interest for magnetic applications of carbon-based nanostructures",http://arxiv.org/abs/2501.10801v1
Distributed Quasi-Newton Method for Fair and Fast Federated Learning,2025-01-18T20:59:07Z,"Shayan Mohajer Hamidi, Linfeng Ye","Federated learning (FL) is a promising technology that enables edge
devices/clients to collaboratively and iteratively train a machine learning
model under the coordination of a central server. The most common approach to
FL is first-order methods, where clients send their local gradients to the
server in each iteration. However, these methods often suffer from slow
convergence rates. As a remedy, second-order methods, such as quasi-Newton, can
be employed in FL to accelerate its convergence. Unfortunately, similarly to
the first-order FL methods, the application of second-order methods in FL can
lead to unfair models, achieving high average accuracy while performing poorly
on certain clients' local datasets. To tackle this issue, in this paper we
introduce a novel second-order FL framework, dubbed \textbf{d}istributed
\textbf{q}uasi-\textbf{N}ewton \textbf{fed}erated learning (DQN-Fed). This
approach seeks to ensure fairness while leveraging the fast convergence
properties of quasi-Newton methods in the FL context. Specifically, DQN-Fed
helps the server update the global model in such a way that (i) all local loss
functions decrease to promote fairness, and (ii) the rate of change in local
loss functions aligns with that of the quasi-Newton method. We prove the
convergence of DQN-Fed and demonstrate its \textit{linear-quadratic}
convergence rate. Moreover, we validate the efficacy of DQN-Fed across a range
of federated datasets, showing that it surpasses state-of-the-art fair FL
methods in fairness, average accuracy and convergence speed.",http://arxiv.org/abs/2501.10877v1
Observing cities as a complex system,2025-01-19T00:01:45Z,Rafael Prieto-Curiel,"Cities are some of the most intricate and advanced creations of humanity.
Most objects in cities are perfectly synchronised to coordinate activities like
jobs, education, transportation, entertainment or waste management. Although
each city has its characteristics, some commonalities can be observed across
most cities, like issues related to noise, pollution, segregation and others.
Further, some of these issues might be accentuated in larger or smaller cities.
For example, with more people, a city might experience more competition for
space so rents would be higher. The urban scaling theory gives a framework to
analyse cities in the context of their size. New data for analysing urban
scaling theory allow an understanding of how urban metrics change with their
population size, whether they apply across most regions or if patterns
correspond only to some country or region. Yet, reducing a city and all its
complexity into a single indicator might simplify urban areas to an extent
where their disparities and variations are overlooked. Often, the differences
between the living conditions in different parts of the same city are bigger
than the degree of variation observed between cities. For example, in terms of
rent or crime, within-city variations might be more significant than between
cities. Here, we review some urban scaling principles and explore ways to
analyse variations within the same city.",http://arxiv.org/abs/2501.10902v1
Generalized Entropic Quantum Speed Limits,2025-01-19T13:51:18Z,"Jucelino Ferreira de Sousa, Diego Paiva Pires","We present a class of generalized entropic quantum speed limits based on
$\alpha$-$z$-R\'{e}nyi relative entropy, a real-valued, contractive,
two-parameter family of distinguishability measures. The QSL falls into the
class of Mandelstam-Tamm bounds, and applies to finite-dimensional quantum
systems that undergo general physical process, i.e., their effective dynamics
can be modeled by unitary or nonunitary evolutions. The results cover pure or
mixed, separable and entangled probe quantum states. The QSL time depends on
the smallest and largest eigenvalues of probe and instantaneous states of the
system, and its evaluation requires low computational cost. In addition, it is
inversely proportional to the time-average of the Schatten speed of the
instantaneous state, which in turn is fully characterized by the considered
dynamics. We specialize our results to the case of unitary and nonunitary
evolutions. In the former case, the QSL scales with the inverse of the energy
fluctuations, while the latter depends on the operator norm of the rate of
change of the quantum channel Kraus operators. We illustrate our findings for
single-qubit and two-qubit states, unitary and nonunitary evolutions. Our
results may find applications in the study of entropic uncertainty relations,
quantum metrology, and also entanglement entropies signaled by generalized
entropies.",http://arxiv.org/abs/2501.11049v2
"Clustering indications before the Mw7.0 2020 Samos, Greece, main shock
  as revealed in an equivalent dimensions space",2025-01-19T18:26:25Z,"Stanislaw Lasocki, Vasileios G. Karakostas, Eleftheria E. Papadimitriou","The transformation to equivalent dimensions that offers a novel approach for
investigating earthquake clustering was engaged to analyze the preparatory
phase of the 2020 Samos, Greece, Mw7.0 main shock. The analysis considered
earthquakes that occurred between 2006 and October 2020, covering an area
extended three times the length of the main rupture. Each earthquake was
parameterized by its magnitude, the interevent time (interval since the
previous earthquake), and the interevent spatial distance (distance between the
epicenters of consecutive earthquakes). Transforming these parameters into
equivalent dimensions allowed them to be directly compared. The degree of
clustering was quantified using the average distance between earthquakes in
this transformed parameter space, calculated within consecutive 100 events data
windows. Results revealed a distinct pattern, the average distance was
increasing steadily during the twelve year period before the main shock. These
temporal changes in the average distance were driven by a systematic evolution
of earthquake clustering in the used parameter space. Beginning from a
two-cluster system, when the distance was minimal, the clustering development
continued along two branches and ended before the main shock with the formation
of five earthquake clusters of different characteristics.",http://arxiv.org/abs/2501.11137v1
