{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DS195XeLXFFQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.tokenize import wordpunct_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "ZfcJIevQXJBB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df = pd.read_csv('combined_df_processed.csv')"
      ],
      "metadata": {
        "id": "xgBY-2JKXRB5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df['combined_text'] = combined_df['Processed_Title'] + \" \" + combined_df['Processed_Abstract']"
      ],
      "metadata": {
        "id": "NFTo8OzaXnaJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a TF-IDF vectorizer on the combined text\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(combined_df['combined_text'])"
      ],
      "metadata": {
        "id": "kl8T1kIsXqvK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PV2DS6IXsAK",
        "outputId": "b32c3a58-2de2-4a23-96a0-84d748dddf14"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<5120x35924 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 399518 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "# Define our text processing functions\n",
        "def clean_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    text = text.lower()\n",
        "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text.strip()\n",
        "\n",
        "def tokenize_text(text):\n",
        "    return wordpunct_tokenize(text)\n",
        "\n",
        "def remove_stopwords(tokens):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    return [word for word in tokens if word not in stop_words]\n",
        "\n",
        "def lemmatize_tokens(tokens):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "def preprocess_text(text):\n",
        "    cleaned = clean_text(text)\n",
        "    tokens = tokenize_text(cleaned)\n",
        "    tokens = remove_stopwords(tokens)\n",
        "    lemmatized = lemmatize_tokens(tokens)\n",
        "    return ' '.join(lemmatized)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5xc3BqvYWv4",
        "outputId": "fc679792-7110-4adf-d50d-2e36cd56f74e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## user input = query string, preprocess it, vectorize it, and return the top_n most similar articles.\n",
        "def search_articles(query, vectorizer, tfidf_matrix, df, top_n=5):\n",
        "\n",
        "    # Preprocess the query using the same pipeline\n",
        "    query_processed = preprocess_text(query)\n",
        "    query_vector = vectorizer.transform([query_processed])\n",
        "\n",
        "    #cosine similarities between the query and all articles\n",
        "    similarities = cosine_similarity(query_vector, tfidf_matrix).flatten()\n",
        "\n",
        "    top_indices = similarities.argsort()[::-1][:top_n]\n",
        "    return df.iloc[top_indices]\n",
        "\n",
        "#Example:\n",
        "if __name__ == \"__main__\":\n",
        "    user_query = \"Rising global temperatures affecting ocean\"\n",
        "\n",
        "    #top 5 matching articles\n",
        "    results = search_articles(user_query, vectorizer, tfidf_matrix, combined_df, top_n=5)\n",
        "    print(results[['Title', 'Abstract']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbfSppf5UMG8",
        "outputId": "627be868-ca9b-45de-acd9-dfdb9f955a7b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  Title  \\\n",
            "2491  Coupling Oceanic Observation Systems to Study ...   \n",
            "2171  Data-driven Global Ocean Modeling for Seasonal...   \n",
            "2470  Forecasting the effect of heat stress index an...   \n",
            "2254  A dynamical geography of observed trends in th...   \n",
            "129   Towards Optimally Weighted Physics-Informed Ne...   \n",
            "\n",
            "                                               Abstract  \n",
            "2491  Understanding local currents in the North Atla...  \n",
            "2171  Accurate ocean dynamics modeling is crucial fo...  \n",
            "2470  In this paper, we estimate the effect of heat ...  \n",
            "2254  Revealing the ongoing changes in ocean dynamic...  \n",
            "129   The carbon pump of the world's ocean plays a v...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0eZ1WtQtYDLP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}